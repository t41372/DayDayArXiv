{
  "date": "2024-04-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，尤其是 Large Language Models (LLMs) 在生成、优化和应用中的创新进展，令人印象深刻的作品包括 BLINK（评估 LLMs 的视觉感知能力）和 Lean Copilot（Anima Anandkumar 等学者参与的定理证明框架），这些论文突出了 LLMs 在处理复杂任务和多模态数据的潜力，同时也涉及交通预测、图像处理和医疗应用的优化方法。\n\n下面，我将挑选并简要讨论部分重要或相关论文，先从 AI 和 LLMs 主题入手，再快速掠过其他领域的高潜力作品。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### AI 和 LLMs 相关论文\n- **Is There No Such Thing as a Bad Question? H4R: HalluciBot For Ratiocination, Rewriting, Ranking, and Routing**（中文：没有坏问题吗？H4R：用于推理、重写、排名和路由的 HalluciBot）  \n  这篇论文提出 HalluciBot，一种预估查询是否会导致 LLM 幻觉的模型，通过查询重写和多代理模拟实现 95.7% 的多选题准确率，主要贡献在于减少 LLM 生成错误，提升查询质量。\n\n- **Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean**（中文：Lean Copilot：LLMs 作为 Lean 定理证明的辅助工具）  \n  作者包括 Anima Anandkumar，这篇论文构建 Lean Copilot 框架，让 LLMs 辅助定理证明，显著提高效率（如在数学任务中自动化 74.2% 的证明步骤），关键发现是 LLMs 在协作环境中超越传统规则方法。\n\n- **Neural Active Learning Beyond Bandits**（中文：超越 Bandits 的神经主动学习）  \n  论文引入基于神经网络的主动学习算法，针对多类问题减少错误增长率，提供更强的探索保证，主要贡献是改进流式和池式主动学习，实验显示其优于现有基准。\n\n- **BLINK: Multimodal Large Language Models Can See but Not Perceive**（中文：BLINK：多模态 LLMs 可以看见但不能感知）  \n  这篇话题度高的论文测试 LLMs 在视觉感知任务上的局限性，使用 14 个经典计算机视觉任务，发现 GPT-4V 等模型的准确率仅略高于随机猜测，主要发现是 LLMs 需要改进感知能力。\n\n- **mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?**（中文：mOthello：多语言模型中跨语言表示对齐和转移何时出现）  \n  论文通过合成任务 mOthello 研究多语言模型的跨语言转移，发现引入锚点标记可提升对齐效果，主要贡献是提出统一输出空间方法，改善模型的泛化性能。\n\n- **Advancing the Robustness of Large Language Models through Self-Denoised Smoothing**（中文：通过自去噪平滑提升 LLMs 的鲁棒性）  \n  该工作提出自去噪平滑方法，提升 LLMs 对对抗攻击的抵抗力，实验显示其在鲁棒性和准确性上优于传统方法，主要发现是噪声处理能显著改善模型性能。\n\n- **FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom**（中文：FedEval-LLM：使用集体智慧的联邦评估 LLMs 在下游任务上的性能）  \n  论文开发 FedEval-LLM 框架，通过联邦学习评估 LLMs，实现隐私保护和任务对齐，主要贡献是使用个性化模型作为裁判，提升下游任务的准确性。\n\n### 图像和生成模型相关论文\n- **Compositional Neural Textures**（中文：组合神经纹理）  \n  这篇论文提出无监督方法表示纹理，使用高斯函数捕捉局部模式，支持纹理编辑和合成，主要发现是其在图像编辑应用中的高效性，如纹理转移和动画。\n\n- **Lazy Diffusion Transformer for Interactive Image Editing**（中文：Lazy Diffusion Transformer 用于交互式图像编辑）  \n  论文引入 LazyDiffusion 模型，仅生成图像的遮罩区域，实现快速编辑，主要贡献是减少计算开销，提供 10 倍加速，同时保持高质量输出。\n\n- **ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity**（中文：ParaFusion：基于 LLMs 的高质量词汇和句法多样性英文改写数据集）  \n  该工作构建大型改写数据集，提升词汇和句法多样性，主要发现是其在 NLP 任务中改善模型性能，相比现有数据集提升 25%。\n\n### 其他领域快速掠过\n- **Centralized vs. Decentralized Multi-Agent Reinforcement Learning for Enhanced Control of Electric Vehicle Charging Networks**（中文：集中 vs. 分散式多代理强化学习用于电动汽车充电网络控制）  \n  论文比较 MARL 方法，发现 CTDE-DDPG 框架降低充电成本 9.1%，主要贡献是提升充电效率。\n\n- **MP-DPD: Low-Complexity Mixed-Precision Neural Networks for Energy-Efficient Digital Predistortion of Wideband Power Amplifiers**（中文：MP-DPD：用于宽带功率放大器的低复杂度混合精度神经网络）  \n  该工作提出混合精度网络，减少功耗同时保持线性化性能，主要发现是其在射频系统中实现 2.8 倍功率节省。\n\n- **A Configurable Pythonic Data Center Model for Sustainable Cooling and ML Integration**（中文：用于可持续冷却和 ML 集成的可配置 Python 数据中心模型）  \n  论文开发 PyDCM 库，支持数据中心冷却优化，主要贡献是结合强化学习评估碳足迹。\n\n- **EnriCo: Enriched Representation and Globally Constrained Inference for Entity and Relation Extraction**（中文：EnriCo：用于实体和关系提取的丰富表示和全局约束推理）  \n  该方法提升实体关系提取的准确性，通过注意力机制和约束算法，主要发现是其在知识图谱构建中的鲁棒性。\n\n- **GraphER: A Structure-aware Text-to-Graph Model for Entity and Relation Extraction**（中文：GraphER：结构感知的文本到图模型用于实体和关系提取）  \n  论文将提取任务视为图结构学习，提高交互性，主要贡献是端到端预测实体和关系。\n\n总体来说，今天的论文突显了 AI 模型在效率、鲁棒性和多模态处理上的进展，但也暴露了感知和泛化能力的挑战。更多细节可查阅 arXiv，以探索感兴趣的领域！",
  "papers": [
    {
      "arxiv_id": "2404.12535v3",
      "title": "Is There No Such Thing as a Bad Question? H4R: HalluciBot For Ratiocination, Rewriting, Ranking, and Routing",
      "title_zh": "翻译失败",
      "authors": [
        "William Watson",
        "Nicole Cho",
        "Nishan Srishankar"
      ],
      "abstract": "Hallucination continues to be one of the most critical challenges in the\ninstitutional adoption journey of Large Language Models (LLMs). While prior\nstudies have primarily focused on the post-generation analysis and refinement\nof outputs, this paper centers on the effectiveness of queries in eliciting\naccurate responses from LLMs. We present HalluciBot, a model that estimates the\nquery's propensity to hallucinate before generation, without invoking any LLMs\nduring inference. HalluciBot can serve as a proxy reward model for query\nrewriting, offering a general framework to estimate query quality based on\naccuracy and consensus. In essence, HalluciBot investigates how poorly\nconstructed queries can lead to erroneous outputs - moreover, by employing\nquery rewriting guided by HalluciBot's empirical estimates, we demonstrate that\n95.7% output accuracy can be achieved for Multiple Choice questions. The\ntraining procedure for HalluciBot consists of perturbing 369,837 queries n\ntimes, employing n+1 independent LLM agents, sampling an output from each\nquery, conducting a Multi-Agent Monte Carlo simulation on the sampled outputs,\nand training an encoder classifier. The idea of perturbation is the outcome of\nour ablation studies that measures the increase in output diversity (+12.5\nagreement spread) by perturbing a query in lexically different but semantically\nsimilar ways. Therefore, HalluciBot paves the way to ratiocinate (76.0% test F1\nscore, 46.6% in saved computation on hallucinatory queries), rewrite (+30.2%\npositive class transition from hallucinatory to non-hallucinatory), rank\n(+50.6% positive class transition from hallucinatory to non-hallucinatory), and\nroute queries to effective pipelines.",
      "tldr_zh": "该论文探讨了Large Language Models (LLMs)中幻觉问题的核心挑战，提出HalluciBot模型，用于在响应生成前评估查询的幻觉倾向，而无需调用LLMs。HalluciBot作为代理奖励模型，通过查询扰动和多代理Monte Carlo模拟训练编码器分类器，实现基于准确性和共识的查询质量评估。实验结果显示，通过HalluciBot引导的查询重写，可将多选题输出准确率提升至95.7%，并在推理（76.0%测试F1分数，节省46.6%计算）、重写（+30.2%正类转换）和排名（+50.6%正类转换）等方面显著改善查询处理效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at The 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2404.12535v3",
      "published_date": "2024-04-18 22:56:57 UTC",
      "updated_date": "2024-12-16 02:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:00.236159"
    },
    {
      "arxiv_id": "2404.12534v3",
      "title": "Lean Copilot: Large Language Models as Copilots for Theorem Proving in Lean",
      "title_zh": "Lean Copilot：大型语言模型作为 Lean 中定理证明的辅助工具",
      "authors": [
        "Peiyang Song",
        "Kaiyu Yang",
        "Anima Anandkumar"
      ],
      "abstract": "Neural theorem proving combines large language models (LLMs) with proof\nassistants such as Lean, where the correctness of formal proofs can be\nrigorously verified, leaving no room for hallucination. With existing neural\ntheorem provers pretrained on a fixed collection of data and offering valuable\nsuggestions at times, it is challenging for them to continually prove novel\ntheorems in a fully autonomous mode, where human insights may be critical. In\nthis paper, we explore LLMs as copilots that assist humans in proving theorems.\nWe introduce Lean Copilot, a general framework for running LLM inference\nnatively in Lean. It enables programmers to build various LLM-based proof\nautomation tools that integrate seamlessly into the workflow of Lean users.\nLean users can use our pretrained models or bring their own ones that run\neither locally (with or without GPUs) or on the cloud. Using Lean Copilot, we\nbuild LLM-based tools that suggest proof steps, complete proof goals, and\nselect relevant premises. Experimental results on the Mathematics in Lean\ntextbook demonstrate the effectiveness of our method compared to existing\nrule-based proof automation in Lean (aesop). When assisting humans, Lean\nCopilot requires only 2.08 manually-entered proof steps on average (3.86\nrequired by aesop); when automating the theorem proving process, Lean Copilot\nautomates 74.2% proof steps on average, 85% better than aesop (40.1%). We open\nsource all code and artifacts under a permissive MIT license to facilitate\nfurther research.",
      "tldr_zh": "本论文提出 Lean Copilot 框架，将 Large Language Models (LLMs) 作为辅助工具（copilots），帮助人类在 Lean 证明系统中证明定理，从而克服现有神经定理证明器的局限性。框架允许在 Lean 中原生运行 LLM 推理，构建工具来建议证明步骤、完成证明目标和选择相关前提，与用户工作流程无缝集成。实验结果显示，在 Mathematics in Lean 教材上，Lean Copilot 辅助人类时平均只需 2.08 步手动输入（比 aesop 系统减少约 46%），并在自动化证明步骤方面达到 74.2% 的比率，比 aesop 高出 85%。论文开源所有代码，以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at NeuS 2025. All code and artifacts open-sourced at\n  https://github.com/lean-dojo/LeanCopilot. All evaluation details are made\n  public at\n  https://github.com/Peiyang-Song/mathematics_in_lean/tree/full-scale-experiment",
      "pdf_url": "http://arxiv.org/pdf/2404.12534v3",
      "published_date": "2024-04-18 22:54:08 UTC",
      "updated_date": "2025-05-11 09:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:12.069636"
    },
    {
      "arxiv_id": "2404.12522v1",
      "title": "Neural Active Learning Beyond Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Yikun Ban",
        "Ishika Agarwal",
        "Ziwei Wu",
        "Yada Zhu",
        "Kommy Weldemariam",
        "Hanghang Tong",
        "Jingrui He"
      ],
      "abstract": "We study both stream-based and pool-based active learning with neural network\napproximations. A recent line of works proposed bandit-based approaches that\ntransformed active learning into a bandit problem, achieving both theoretical\nand empirical success. However, the performance and computational costs of\nthese methods may be susceptible to the number of classes, denoted as $K$, due\nto this transformation. Therefore, this paper seeks to answer the question:\n\"How can we mitigate the adverse impacts of $K$ while retaining the advantages\nof principled exploration and provable performance guarantees in active\nlearning?\" To tackle this challenge, we propose two algorithms based on the\nnewly designed exploitation and exploration neural networks for stream-based\nand pool-based active learning. Subsequently, we provide theoretical\nperformance guarantees for both algorithms in a non-parametric setting,\ndemonstrating a slower error-growth rate concerning $K$ for the proposed\napproaches. We use extensive experiments to evaluate the proposed algorithms,\nwhich consistently outperform state-of-the-art baselines.",
      "tldr_zh": "本论文探讨了 Neural Active Learning 的新方法，超越传统的 Bandit-based 策略，以缓解类数 $K$ 对性能和计算成本的负面影响。研究提出两种算法：分别基于新设计的 exploitation 和 exploration 神经网络，适用于 stream-based 和 pool-based 主动学习。这些算法在非参数设置下提供了理论性能保证，显示出错误增长率对 $K$ 的依赖更慢。通过广泛实验，证明了所提算法 consistently outperform 现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published on ICLR 2024, 40 Pages",
      "pdf_url": "http://arxiv.org/pdf/2404.12522v1",
      "published_date": "2024-04-18 21:52:14 UTC",
      "updated_date": "2024-04-18 21:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:22.343765"
    },
    {
      "arxiv_id": "2404.12520v1",
      "title": "Centralized vs. Decentralized Multi-Agent Reinforcement Learning for Enhanced Control of Electric Vehicle Charging Networks",
      "title_zh": "集中式 vs. 分散式多智能体强化学习用于增强电动汽车充电网络的控制",
      "authors": [
        "Amin Shojaeighadikolaei",
        "Zsolt Talata",
        "Morteza Hashemi"
      ],
      "abstract": "The widespread adoption of electric vehicles (EVs) poses several challenges\nto power distribution networks and smart grid infrastructure due to the\npossibility of significantly increasing electricity demands, especially during\npeak hours. Furthermore, when EVs participate in demand-side management\nprograms, charging expenses can be reduced by using optimal charging control\npolicies that fully utilize real-time pricing schemes. However, devising\noptimal charging methods and control strategies for EVs is challenging due to\nvarious stochastic and uncertain environmental factors. Currently, most EV\ncharging controllers operate based on a centralized model. In this paper, we\nintroduce a novel approach for distributed and cooperative charging strategy\nusing a Multi-Agent Reinforcement Learning (MARL) framework. Our method is\nbuilt upon the Deep Deterministic Policy Gradient (DDPG) algorithm for a group\nof EVs in a residential community, where all EVs are connected to a shared\ntransformer. This method, referred to as CTDE-DDPG, adopts a Centralized\nTraining Decentralized Execution (CTDE) approach to establish cooperation\nbetween agents during the training phase, while ensuring a distributed and\nprivacy-preserving operation during execution. We theoretically examine the\nperformance of centralized and decentralized critics for the DDPG-based MARL\nimplementation and demonstrate their trade-offs. Furthermore, we numerically\nexplore the efficiency, scalability, and performance of centralized and\ndecentralized critics. Our theoretical and numerical results indicate that,\ndespite higher policy gradient variances and training complexity, the CTDE-DDPG\nframework significantly improves charging efficiency by reducing total\nvariation by approximately %36 and charging cost by around %9.1 on average...",
      "tldr_zh": "本论文探讨了 Multi-Agent Reinforcement Learning (MARL) 在电动汽车 (EVs) 充电网络控制中的集中式与分散式方法，以应对电力需求高峰期带来的挑战。研究提出了一种基于 Deep Deterministic Policy Gradient (DDPG) 算法的 CTDE-DDPG 框架，该框架采用 Centralized Training Decentralized Execution (CTDE) 策略，实现 EVs 之间的分布式合作充电，同时确保训练阶段的协作和执行阶段的隐私保护。理论分析比较了集中式和分散式 critic 的性能权衡，而数值实验显示，CTDE-DDPG 显著提升了充电效率，平均减少总变化约 36% 和充电成本约 9.1%。这项工作为优化 EVs 充电策略提供了可扩展的解决方案。",
      "categories": [
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12520v1",
      "published_date": "2024-04-18 21:50:03 UTC",
      "updated_date": "2024-04-18 21:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:35.204022"
    },
    {
      "arxiv_id": "2404.12509v2",
      "title": "Compositional Neural Textures",
      "title_zh": "翻译失败",
      "authors": [
        "Peihan Tu",
        "Li-Yi Wei",
        "Matthias Zwicker"
      ],
      "abstract": "Texture plays a vital role in enhancing visual richness in both real\nphotographs and computer-generated imagery. However, the process of editing\ntextures often involves laborious and repetitive manual adjustments of textons,\nwhich are the recurring local patterns that characterize textures. This work\nintroduces a fully unsupervised approach for representing textures using a\ncompositional neural model that captures individual textons. We represent each\ntexton as a 2D Gaussian function whose spatial support approximates its shape,\nand an associated feature that encodes its detailed appearance. By modeling a\ntexture as a discrete composition of Gaussian textons, the representation\noffers both expressiveness and ease of editing. Textures can be edited by\nmodifying the compositional Gaussians within the latent space, and new textures\ncan be efficiently synthesized by feeding the modified Gaussians through a\ngenerator network in a feed-forward manner. This approach enables a wide range\nof applications, including transferring appearance from an image texture to\nanother image, diversifying textures,texture interpolation, revealing/modifying\ntexture variations, edit propagation, texture animation, and direct texton\nmanipulation. The proposed approach contributes to advancing texture analysis,\nmodeling, and editing techniques, and opens up new possibilities for creating\nvisually appealing images with controllable textures.",
      "tldr_zh": "本文提出了一种完全无监督的组合神经模型，用于表示和编辑纹理（textures），通过将每个texton表示为一个2D Gaussian函数及其关联特征，来捕捉纹理的局部模式和详细外观。模型将纹理建模为离散的Gaussian textons组合，从而实现高效编辑，如在潜在空间修改Gaussians并通过生成器网络前向合成新纹理。实验展示了广泛的应用，包括纹理外观转移、多样化、插值、动画以及直接texton操作，为纹理分析、建模和编辑技术提供了新进展。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "Project page: https://phtu-cs.github.io/cnt-siga24/",
      "pdf_url": "http://arxiv.org/pdf/2404.12509v2",
      "published_date": "2024-04-18 21:09:34 UTC",
      "updated_date": "2024-09-23 03:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:45.185089"
    },
    {
      "arxiv_id": "2404.15364v1",
      "title": "MP-DPD: Low-Complexity Mixed-Precision Neural Networks for Energy-Efficient Digital Predistortion of Wideband Power Amplifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhuo Wu",
        "Ang Li",
        "Mohammadreza Beikmirza",
        "Gagan Deep Singh",
        "Qinyu Chen",
        "Leo C. N. de Vreede",
        "Morteza Alavi",
        "Chang Gao"
      ],
      "abstract": "Digital Pre-Distortion (DPD) enhances signal quality in wideband RF power\namplifiers (PAs). As signal bandwidths expand in modern radio systems, DPD's\nenergy consumption increasingly impacts overall system efficiency. Deep Neural\nNetworks (DNNs) offer promising advancements in DPD, yet their high complexity\nhinders their practical deployment. This paper introduces open-source\nmixed-precision (MP) neural networks that employ quantized low-precision\nfixed-point parameters for energy-efficient DPD. This approach reduces\ncomputational complexity and memory footprint, thereby lowering power\nconsumption without compromising linearization efficacy. Applied to a 160MHz-BW\n1024-QAM OFDM signal from a digital RF PA, MP-DPD gives no performance loss\nagainst 32-bit floating-point precision DPDs, while achieving -43.75 (L)/-45.27\n(R) dBc in Adjacent Channel Power Ratio (ACPR) and -38.72 dB in Error Vector\nMagnitude (EVM). A 16-bit fixed-point-precision MP-DPD enables a 2.8X reduction\nin estimated inference power. The PyTorch learning and testing code is publicly\navailable at \\url{https://github.com/lab-emi/OpenDPD}.",
      "tldr_zh": "本论文提出 MP-DPD，一种低复杂度混合精度神经网络，用于能源高效的宽带功率放大器 Digital Pre-Distortion (DPD)。该方法通过量化低精度固定点参数，减少计算复杂度和内存占用，同时保持 DPD 的线性化效能。实验结果显示，在 160MHz-BW 1024-QAM OFDM 信号上，MP-DPD 与 32-bit 浮点精度相当，实现了 -43.75 (L)/-45.27 (R) dBc 的 Adjacent Channel Power Ratio (ACPR) 和 -38.72 dB 的 Error Vector Magnitude (EVM)，并通过 16-bit 版本降低了 2.8 倍的推理功耗。该框架的 PyTorch 代码已开源，提供于 GitHub。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted to IEEE Microwave and Wireless Technology Letters (MWTL)",
      "pdf_url": "http://arxiv.org/pdf/2404.15364v1",
      "published_date": "2024-04-18 21:04:39 UTC",
      "updated_date": "2024-04-18 21:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:30:58.416673"
    },
    {
      "arxiv_id": "2404.12498v1",
      "title": "A Configurable Pythonic Data Center Model for Sustainable Cooling and ML Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Avisek Naug",
        "Antonio Guillen",
        "Ricardo Luna Gutierrez",
        "Vineet Gundecha",
        "Sahand Ghorbanpour",
        "Sajad Mousavi",
        "Ashwin Ramesh Babu",
        "Soumyendu Sarkar"
      ],
      "abstract": "There have been growing discussions on estimating and subsequently reducing\nthe operational carbon footprint of enterprise data centers. The design and\nintelligent control for data centers have an important impact on data center\ncarbon footprint. In this paper, we showcase PyDCM, a Python library that\nenables extremely fast prototyping of data center design and applies\nreinforcement learning-enabled control with the purpose of evaluating key\nsustainability metrics including carbon footprint, energy consumption, and\nobserving temperature hotspots. We demonstrate these capabilities of PyDCM and\ncompare them to existing works in EnergyPlus for modeling data centers. PyDCM\ncan also be used as a standalone Gymnasium environment for demonstrating\nsustainability-focused data center control.",
      "tldr_zh": "本文介绍了 PyDCM，这是一个可配置的 Python 库，旨在通过快速原型设计数据中心模型来优化可持续冷却和 ML 集成。PyDCM 利用 reinforcement learning 进行智能控制，评估关键可持续性指标，包括碳足迹、能源消耗和温度热点，并与 EnergyPlus 进行比较以展示其优势。该库还可作为 Gymnasium 环境，用于演示可持续性数据中心控制策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2023 Workshop on Tackling Climate Change with Machine\n  Learning https://www.climatechange.ai/papers/neurips2023/15. arXiv admin\n  note: substantial text overlap with arXiv:2310.03906",
      "pdf_url": "http://arxiv.org/pdf/2404.12498v1",
      "published_date": "2024-04-18 20:25:33 UTC",
      "updated_date": "2024-04-18 20:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:31:09.680251"
    },
    {
      "arxiv_id": "2404.12493v1",
      "title": "EnriCo: Enriched Representation and Globally Constrained Inference for Entity and Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Urchade Zaratiana",
        "Nadi Tomeh",
        "Yann Dauxais",
        "Pierre Holat",
        "Thierry Charnois"
      ],
      "abstract": "Joint entity and relation extraction plays a pivotal role in various\napplications, notably in the construction of knowledge graphs. Despite recent\nprogress, existing approaches often fall short in two key aspects: richness of\nrepresentation and coherence in output structure. These models often rely on\nhandcrafted heuristics for computing entity and relation representations,\npotentially leading to loss of crucial information. Furthermore, they disregard\ntask and/or dataset-specific constraints, resulting in output structures that\nlack coherence. In our work, we introduce EnriCo, which mitigates these\nshortcomings. Firstly, to foster rich and expressive representation, our model\nleverage attention mechanisms that allow both entities and relations to\ndynamically determine the pertinent information required for accurate\nextraction. Secondly, we introduce a series of decoding algorithms designed to\ninfer the highest scoring solutions while adhering to task and dataset-specific\nconstraints, thus promoting structured and coherent outputs. Our model\ndemonstrates competitive performance compared to baselines when evaluated on\nJoint IE datasets.",
      "tldr_zh": "该论文提出EnriCo模型，用于提升联合entity and relation extraction的表现，以支持知识图谱构建。现有方法依赖手工设计的表示，可能丢失关键信息，且忽略任务和数据集特定的约束，导致输出结构不连贯。EnriCo通过attention mechanisms动态丰富实体和关系的表示，并引入一系列解码算法，确保输出符合特定约束，从而生成结构化且连贯的结果。在Joint IE数据集上的评估中，EnriCo显示出与基线模型相当的竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2404.12493v1",
      "published_date": "2024-04-18 20:15:48 UTC",
      "updated_date": "2024-04-18 20:15:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:31:20.226931"
    },
    {
      "arxiv_id": "2404.12491v1",
      "title": "GraphER: A Structure-aware Text-to-Graph Model for Entity and Relation Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Urchade Zaratiana",
        "Nadi Tomeh",
        "Niama El Khbir",
        "Pierre Holat",
        "Thierry Charnois"
      ],
      "abstract": "Information extraction (IE) is an important task in Natural Language\nProcessing (NLP), involving the extraction of named entities and their\nrelationships from unstructured text. In this paper, we propose a novel\napproach to this task by formulating it as graph structure learning (GSL). By\nformulating IE as GSL, we enhance the model's ability to dynamically refine and\noptimize the graph structure during the extraction process. This formulation\nallows for better interaction and structure-informed decisions for entity and\nrelation prediction, in contrast to previous models that have separate or\nuntied predictions for these tasks. When compared against state-of-the-art\nbaselines on joint entity and relation extraction benchmarks, our model,\nGraphER, achieves competitive results.",
      "tldr_zh": "本文提出GraphER，一种结构感知的文本到图模型，用于信息提取（IE）的实体和关系提取任务。通过将IE表述为图结构学习（GSL），GraphER允许模型在提取过程中动态优化图结构，从而增强实体和关系的交互预测，并与传统分离式预测方法形成对比。在联合实体和关系提取基准测试中，GraphER取得了与最先进模型相当的竞争性性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2404.12491v1",
      "published_date": "2024-04-18 20:09:37 UTC",
      "updated_date": "2024-04-18 20:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:31:32.093432"
    },
    {
      "arxiv_id": "2404.12488v3",
      "title": "Global Counterfactual Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Bartlomiej Sobieski",
        "Przemysław Biecek"
      ],
      "abstract": "Despite increasing progress in development of methods for generating visual\ncounterfactual explanations, especially with the recent rise of Denoising\nDiffusion Probabilistic Models, previous works consider them as an entirely\nlocal technique. In this work, we take the first step at globalizing them.\nSpecifically, we discover that the latent space of Diffusion Autoencoders\nencodes the inference process of a given classifier in the form of global\ndirections. We propose a novel proxy-based approach that discovers two types of\nthese directions with the use of only single image in an entirely black-box\nmanner. Precisely, g-directions allow for flipping the decision of a given\nclassifier on an entire dataset of images, while h-directions further increase\nthe diversity of explanations. We refer to them in general as Global\nCounterfactual Directions (GCDs). Moreover, we show that GCDs can be naturally\ncombined with Latent Integrated Gradients resulting in a new black-box\nattribution method, while simultaneously enhancing the understanding of\ncounterfactual explanations. We validate our approach on existing benchmarks\nand show that it generalizes to real-world use-cases.",
      "tldr_zh": "本研究首次将视觉反事实解释从局部扩展到全局，针对Denoising Diffusion Probabilistic Models等方法提出Global Counterfactual Directions (GCDs)。作者发现Diffusion Autoencoders的潜在空间中存在编码分类器推理的全局方向，并通过一种黑箱代理-based方法，仅使用单张图像发现两种方向：g-directions用于翻转分类器对整个数据集的决策，h-directions进一步提升解释多样性。实验结果显示，GCDs可与Latent Integrated Gradients结合，形成新的黑箱归因方法，并在现有基准上验证了其泛化能力，适用于真实世界场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12488v3",
      "published_date": "2024-04-18 20:03:56 UTC",
      "updated_date": "2025-02-05 07:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:31:45.488994"
    },
    {
      "arxiv_id": "2404.12486v2",
      "title": "Follow-Me AI: Energy-Efficient User Interaction with Smart Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Saleh",
        "Praveen Kumar Donta",
        "Roberto Morabito",
        "Naser Hossein Motlagh",
        "Lauri Lovén"
      ],
      "abstract": "This article introduces Follow-Me AI, a concept designed to enhance user\ninteractions with smart environments, optimize energy use, and provide better\ncontrol over data captured by these environments. Through AI agents that\naccompany users, Follow-Me AI negotiates data management based on user consent,\naligns environmental controls as well as user communication and computes\nresources available in the environment with user preferences, and predicts user\nbehavior to proactively adjust the smart environment. The manuscript\nillustrates this concept with a detailed example of Follow-Me AI in a smart\ncampus setting, detailing the interactions with the building's management\nsystem for optimal comfort and efficiency. Finally, this article looks into the\nchallenges and opportunities related to Follow-Me AI.",
      "tldr_zh": "这篇文章介绍了 Follow-Me AI 概念，该系统通过 AI agents 跟随用户，优化智能环境中的能源使用、增强用户交互并根据用户同意管理数据。AI agents 会协商数据处理、调整环境控制和计算资源以匹配用户偏好，并预测用户行为以主动优化舒适度和效率。文章以智能校园场景为例，详细说明了与建筑管理系统的交互，并探讨了 Follow-Me AI 的潜在挑战和机会。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12486v2",
      "published_date": "2024-04-18 20:00:25 UTC",
      "updated_date": "2024-04-22 19:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:31:57.746099"
    },
    {
      "arxiv_id": "2404.12485v1",
      "title": "Contract Scheduling with Distributional and Multiple Advice",
      "title_zh": "翻译失败",
      "authors": [
        "Spyros Angelopoulos",
        "Marcin Bienkowski",
        "Christoph Dürr",
        "Bertrand Simon"
      ],
      "abstract": "Contract scheduling is a widely studied framework for designing real-time\nsystems with interruptible capabilities. Previous work has showed that a\nprediction on the interruption time can help improve the performance of\ncontract-based systems, however it has relied on a single prediction that is\nprovided by a deterministic oracle. In this work, we introduce and study more\ngeneral and realistic learning-augmented settings in which the prediction is in\nthe form of a probability distribution, or it is given as a set of multiple\npossible interruption times. For both prediction settings, we design and\nanalyze schedules which perform optimally if the prediction is accurate, while\nsimultaneously guaranteeing the best worst-case performance if the prediction\nis adversarial. We also provide evidence that the resulting system is robust to\nprediction errors in the distributional setting. Last, we present an\nexperimental evaluation that confirms the theoretical findings, and illustrates\nthe performance improvements that can be attained in practice.",
      "tldr_zh": "本文扩展了合同调度框架，引入了更一般的学习增强设置，包括基于概率分布的预测（distributional advice）和多个可能中断时间的预测（multiple advice），以提升实时系统的中断处理性能。研究设计了优化调度算法，确保在预测准确时实现最佳性能，同时在预测错误时提供最佳最坏情况保证，并证明了系统对预测错误的稳健性。通过实验评估，证实了理论发现并展示了实际性能的显著改进。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "To appear in Proceedings of IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12485v1",
      "published_date": "2024-04-18 19:58:11 UTC",
      "updated_date": "2024-04-18 19:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:32:10.588183"
    },
    {
      "arxiv_id": "2404.14432v1",
      "title": "Monitoring Critical Infrastructure Facilities During Disasters Using Large Language Models",
      "title_zh": "使用大型语言模型监控灾害期间的关键基础设施设施",
      "authors": [
        "Abdul Wahab Ziaullah",
        "Ferda Ofli",
        "Muhammad Imran"
      ],
      "abstract": "Critical Infrastructure Facilities (CIFs), such as healthcare and\ntransportation facilities, are vital for the functioning of a community,\nespecially during large-scale emergencies. In this paper, we explore a\npotential application of Large Language Models (LLMs) to monitor the status of\nCIFs affected by natural disasters through information disseminated in social\nmedia networks. To this end, we analyze social media data from two disaster\nevents in two different countries to identify reported impacts to CIFs as well\nas their impact severity and operational status. We employ state-of-the-art\nopen-source LLMs to perform computational tasks including retrieval,\nclassification, and inference, all in a zero-shot setting. Through extensive\nexperimentation, we report the results of these tasks using standard evaluation\nmetrics and reveal insights into the strengths and weaknesses of LLMs. We note\nthat although LLMs perform well in classification tasks, they encounter\nchallenges with inference tasks, especially when the context/prompt is complex\nand lengthy. Additionally, we outline various potential directions for future\nexploration that can be beneficial during the initial adoption phase of LLMs\nfor disaster response tasks.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）监控关键基础设施设施（CIFs，如医疗和交通设施）在自然灾害期间的状态，通过分析社交媒体数据。研究团队分析了两个不同国家灾害事件的社交媒体信息，采用零样本设置让 LLMs 执行检索、分类和推理任务。实验结果显示，LLMs 在分类任务中表现出色，但面临复杂上下文时的推理挑战，揭示了其优势和局限性。该工作为灾害响应任务的初始应用提供了宝贵见解，并提出了未来探索方向，以提升 LLMs 的可靠性和有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted to appear at the 2024 ISCRAM conference",
      "pdf_url": "http://arxiv.org/pdf/2404.14432v1",
      "published_date": "2024-04-18 19:41:05 UTC",
      "updated_date": "2024-04-18 19:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:32:22.338089"
    },
    {
      "arxiv_id": "2404.12474v2",
      "title": "Learning a Stable, Safe, Distributed Feedback Controller for a Heterogeneous Platoon of Autonomous Vehicles",
      "title_zh": "为异构自治车辆车队学习一个稳定、安全、分布式的反馈控制器",
      "authors": [
        "Michael H. Shaham",
        "Taskin Padir"
      ],
      "abstract": "Platooning of autonomous vehicles has the potential to increase safety and\nfuel efficiency on highways. The goal of platooning is to have each vehicle\ndrive at a specified speed (set by the leader) while maintaining a safe\ndistance from its neighbors. Many prior works have analyzed various controllers\nfor platooning, most commonly linear feedback and distributed model predictive\ncontrollers. In this work, we introduce an algorithm for learning a stable,\nsafe, distributed controller for a heterogeneous platoon. Our algorithm relies\non recent developments in learning neural network stability certificates. We\ntrain a controller for autonomous platooning in simulation and evaluate its\nperformance on hardware with a platoon of four F1Tenth vehicles. We then\nperform further analysis in simulation with a platoon of 100 vehicles.\nExperimental results demonstrate the practicality of the algorithm and the\nlearned controller by comparing the performance of the neural network\ncontroller to linear feedback and distributed model predictive controllers.",
      "tldr_zh": "该研究提出了一种算法，用于学习一个稳定、安全、分布式的反馈控制器（distributed feedback controller），以管理异构自治车辆编队（heterogeneous platoon of autonomous vehicles），目标是提高高速公路的安全性和燃油效率，同时确保车辆保持指定速度和安全距离。算法基于神经网络稳定性证书（neural network stability certificates）的最新发展，通过模拟训练控制器，并在硬件上测试四辆 F1Tenth 车辆，以及模拟100辆车辆的场景。实验结果显示，该神经网络控制器在性能上优于线性反馈和分布式模型预测控制器，证明了其实用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the International Symposium of Robotics Research (ISRR)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12474v2",
      "published_date": "2024-04-18 19:11:34 UTC",
      "updated_date": "2024-10-17 18:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:32:34.819738"
    },
    {
      "arxiv_id": "2406.15382v1",
      "title": "Enhancing Educational Efficiency: Generative AI Chatbots and DevOps in Education 4.0",
      "title_zh": "翻译失败",
      "authors": [
        "Edis Mekić",
        "Mihailo Jovanović",
        "Kristijan Kuk",
        "Bojan Prlinčević",
        "Ana Savić"
      ],
      "abstract": "This research paper will bring forth the innovative pedagogical approach in\ncomputer science education, which uses a combination of methodologies borrowed\nfrom Artificial Intelligence (AI) and DevOps to enhance the learning experience\nin Content Management Systems (CMS) Development. It has been done over three\nacademic years, comparing the traditional way of teaching with the lately\nintroduced AI-supported techniques. This had three structured sprints, each one\nof them covering the major parts of the sprint: object-oriented PHP, theme\ndevelopment, and plugin development. In each sprint, the student deals with\npart of the theoretical content and part of the practical task, using ChatGPT\nas an auxiliary tool. In that sprint, the model will provide solutions in code\ndebugging and extensions of complex problems. The course includes practical\nexamples like code replication with PHP, functionality expansion of the CMS,\neven development of custom plugins, and themes. The course practice includes\nversions' control with Git repositories. Efficiency will touch the theme and\nplugin output rates during development and mobile/web application development.\nComparative analysis indicates that there is a marked increase in efficiency\nand shows effectiveness with the proposed AI- and DevOps-supported methodology.\nThe study is very informative since education in computer science and its\nlandscape change embodies an emerging technology that could have transformation\nimpacts on amplifying the potential for scalable and adaptive learning\napproaches.",
      "tldr_zh": "这篇论文提出了一种创新的计算机科学教育方法，结合 Generative AI Chatbots（如 ChatGPT）和 DevOps 技术，以提升 Content Management Systems (CMS) 开发的教学效率。研究通过三年的实验比较传统教学与 AI 支持方法，包括三个结构化的冲刺：面向对象的 PHP、主题开发和插件开发，其中学生使用 ChatGPT 辅助代码调试、任务扩展及 Git 版本控制。课程实践涉及实际例子，如 PHP 代码复制、CMS 功能扩展和自定义插件主题开发。结果显示，该方法显著提高了开发效率，并为 Education 4.0 提供了可扩展和适应性的学习途径。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15382v1",
      "published_date": "2024-04-18 18:45:39 UTC",
      "updated_date": "2024-04-18 18:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:32:47.689024"
    },
    {
      "arxiv_id": "2404.12460v4",
      "title": "NLP-enabled Trajectory Map-matching in Urban Road Networks using a Transformer-based Encoder-decoder",
      "title_zh": "翻译失败",
      "authors": [
        "Sevin Mohammadi",
        "Andrew W. Smyth"
      ],
      "abstract": "Vehicular trajectory data from geolocation telematics is vital for analyzing\nurban mobility patterns. Map-matching aligns noisy, sparsely sampled GPS\ntrajectories with digital road maps to reconstruct accurate vehicle paths.\nTraditional methods rely on geometric proximity, topology, and shortest-path\nheuristics, but they overlook two key factors: (1) drivers may prefer routes\nbased on local road characteristics rather than shortest paths, revealing\nlearnable shared preferences, and (2) GPS noise varies spatially due to\nmultipath effects. These factors can reduce the effectiveness of conventional\nmethods in complex scenarios and increase the effort required for\nheuristic-based implementations. This study introduces a data-driven, deep\nlearning-based map-matching framework, formulating the task as machine\ntranslation, inspired by NLP. Specifically, a transformer-based encoder-decoder\nmodel learns contextual representations of noisy GPS points to infer trajectory\nbehavior and road structures in an end-to-end manner. Trained on large-scale\ntrajectory data, the method improves path estimation accuracy. Experiments on\nsynthetic trajectories show that this approach outperforms conventional methods\nby integrating contextual awareness. Evaluation on real-world GPS traces from\nManhattan, New York, achieves 75% accuracy in reconstructing navigated routes.\nThese results highlight the effectiveness of transformers in capturing drivers'\ntrajectory behaviors, spatial dependencies, and noise patterns, offering a\nscalable, robust solution for map-matching. This work contributes to advancing\ntrajectory-driven foundation models for geospatial modeling and urban mobility\napplications.",
      "tldr_zh": "这篇论文提出了一种基于 NLP 的轨迹 map-matching 方法，使用 Transformer-based encoder-decoder 模型，将嘈杂的 GPS 轨迹对齐到城市道路网络中，解决传统方法忽略驾驶员偏好和空间噪声问题。模型将任务视为机器翻译，学习 GPS 点的上下文表示，以端到端方式推断轨迹行为和道路结构。实验结果显示，该方法在合成轨迹上优于传统方法，在曼哈顿真实数据上达到 75% 的准确率。总体上，这为轨迹驱动的地理空间建模和城市移动应用提供了可扩展、鲁棒的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12460v4",
      "published_date": "2024-04-18 18:39:23 UTC",
      "updated_date": "2025-03-07 20:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:32:59.890856"
    },
    {
      "arxiv_id": "2404.12458v2",
      "title": "The collective use and perceptions of generative AI tools in digital humanities research: Survey-based results",
      "title_zh": "翻译失败",
      "authors": [
        "Meredith Dedema",
        "Rongqian Ma"
      ],
      "abstract": "Generative artificial intelligence technologies have revolutionized the\nresearch landscape, with significant implications for Digital Humanities, a\nfield inherently intertwined with technological progress. This article\ninvestigates how DH scholars adopt and critically evaluate generative AI\ntechnologies such as ChatGPT in research. Drawing on 76 responses collected\nfrom an international survey study, we explored DH scholars' rationale for\nadopting or not adopting generative AI tools in research, identified the\nspecific practices of using generative AI tools to support various DH research\ntasks, and analyzed scholars' collective perceptions regarding the benefits,\nrisks, and challenges of using generative AI tools in DH research. The survey\nresults reveal two key findings: first, DH research communities hold divisive\nopinions about the value of generative AI in DH scholarship; second, scholars\nhave developed new practices and perceptions for using generative AI tools,\nwhich differ from those associated with traditional AI-based tools. Our survey\nrepresents one of the first survey-based analyses on this topic. It has the\npotential to serve as a building block for future empirical inquiries into the\nimpact of generative AI on DH scholarship.",
      "tldr_zh": "本研究调查了数字人文（DH）学者对生成式 AI 工具（如 ChatGPT）的采用和感知，基于 76 个国际调查响应，探讨了使用理由、具体实践以及益处、风险和挑战。结果显示，DH 社区对生成式 AI 在学术中的价值存在分歧意见。学者们开发了与传统 AI-based tools 不同的新实践，用于支持各种 DH 研究任务。该调查作为首批针对该主题的实证分析之一，为未来探究生成式 AI 对 DH 领域的影响提供了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12458v2",
      "published_date": "2024-04-18 18:33:00 UTC",
      "updated_date": "2024-10-07 18:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:33:10.194172"
    },
    {
      "arxiv_id": "2404.12450v1",
      "title": "Enhancing AI Diagnostics: Autonomous Lesion Masking via Semi-Supervised Deep Learning",
      "title_zh": "增强 AI 诊断：通过半监督深度学习的自主病变掩码生成",
      "authors": [
        "Ting-Ruen Wei",
        "Michele Hell",
        "Dang Bich Thuy Le",
        "Aren Vierra",
        "Ran Pang",
        "Mahesh Patel",
        "Young Kang",
        "Yuling Yan"
      ],
      "abstract": "This study presents an unsupervised domain adaptation method aimed at\nautonomously generating image masks outlining regions of interest (ROIs) for\ndifferentiating breast lesions in breast ultrasound (US) imaging. Our\nsemi-supervised learning approach utilizes a primitive model trained on a small\npublic breast US dataset with true annotations. This model is then iteratively\nrefined for the domain adaptation task, generating pseudo-masks for our\nprivate, unannotated breast US dataset. The dataset, twice the size of the\npublic one, exhibits considerable variability in image acquisition perspectives\nand demographic representation, posing a domain-shift challenge. Unlike typical\ndomain adversarial training, we employ downstream classification outcomes as a\nbenchmark to guide the updating of pseudo-masks in subsequent iterations. We\nfound the classification precision to be highly correlated with the\ncompleteness of the generated ROIs, which promotes the explainability of the\ndeep learning classification model. Preliminary findings demonstrate the\nefficacy and reliability of this approach in streamlining the ROI annotation\nprocess, thereby enhancing the classification and localization of breast\nlesions for more precise and interpretable diagnoses.",
      "tldr_zh": "本研究提出了一种基于半监督深度学习的无监督域适应方法，用于自动生成乳腺超声图像中乳腺病变区域的图像掩码(ROIs)，以提升AI诊断性能。该方法先利用小型公共数据集训练原始模型，然后通过迭代精炼生成私有无标注数据集的伪掩码，并以下游分类结果作为基准指导更新，解决域移位(domain-shift)挑战。研究发现，分类精度与ROIs完整性高度相关，提高了深度学习模型的可解释性；初步结果表明，此方法能简化ROI标注过程，并改善乳腺病变的分类和定位，实现更精确的诊断。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12450v1",
      "published_date": "2024-04-18 18:25:00 UTC",
      "updated_date": "2024-04-18 18:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:33:23.794648"
    },
    {
      "arxiv_id": "2404.12444v1",
      "title": "mOthello: When Do Cross-Lingual Representation Alignment and Cross-Lingual Transfer Emerge in Multilingual Models?",
      "title_zh": "mOthello：",
      "authors": [
        "Tianze Hua",
        "Tian Yun",
        "Ellie Pavlick"
      ],
      "abstract": "Many pretrained multilingual models exhibit cross-lingual transfer ability,\nwhich is often attributed to a learned language-neutral representation during\npretraining. However, it remains unclear what factors contribute to the\nlearning of a language-neutral representation, and whether the learned\nlanguage-neutral representation suffices to facilitate cross-lingual transfer.\nWe propose a synthetic task, Multilingual Othello (mOthello), as a testbed to\ndelve into these two questions. We find that: (1) models trained with naive\nmultilingual pretraining fail to learn a language-neutral representation across\nall input languages; (2) the introduction of \"anchor tokens\" (i.e., lexical\nitems that are identical across languages) helps cross-lingual representation\nalignment; and (3) the learning of a language-neutral representation alone is\nnot sufficient to facilitate cross-lingual transfer. Based on our findings, we\npropose a novel approach - multilingual pretraining with unified output space -\nthat both induces the learning of language-neutral representation and\nfacilitates cross-lingual transfer.",
      "tldr_zh": "该论文探讨了多语言模型中跨语言表示对齐（cross-lingual representation alignment）和跨语言转移（cross-lingual transfer）的出现条件，通过合成任务 Multilingual Othello (mOthello) 作为测试平台。研究发现，简单的多语言预训练（multilingual pretraining）无法在所有输入语言中学习语言中性表示，而引入 anchor tokens（跨语言相同的词汇项）有助于改善表示对齐，但语言中性表示本身不足以促进跨语言转移。基于这些发现，作者提出了一种新方法——多语言预训练与统一输出空间（multilingual pretraining with unified output space），该方法既能诱导语言中性表示的学习，又能有效提升跨语言转移性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of NAACL 2024. Project Webpage:\n  https://multilingual-othello.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.12444v1",
      "published_date": "2024-04-18 18:03:08 UTC",
      "updated_date": "2024-04-18 18:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:33:35.618716"
    },
    {
      "arxiv_id": "2404.12390v4",
      "title": "BLINK: Multimodal Large Language Models Can See but Not Perceive",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Fu",
        "Yushi Hu",
        "Bangzheng Li",
        "Yu Feng",
        "Haoyu Wang",
        "Xudong Lin",
        "Dan Roth",
        "Noah A. Smith",
        "Wei-Chiu Ma",
        "Ranjay Krishna"
      ],
      "abstract": "We introduce Blink, a new benchmark for multimodal language models (LLMs)\nthat focuses on core visual perception abilities not found in other\nevaluations. Most of the Blink tasks can be solved by humans \"within a blink\"\n(e.g., relative depth estimation, visual correspondence, forensics detection,\nand multi-view reasoning). However, we find these perception-demanding tasks\ncast significant challenges for current multimodal LLMs because they resist\nmediation through natural language. Blink reformats 14 classic computer vision\ntasks into 3,807 multiple-choice questions, paired with single or multiple\nimages and visual prompting. While humans get 95.70% accuracy on average, Blink\nis surprisingly challenging for existing multimodal LLMs: even the\nbest-performing GPT-4V and Gemini achieve accuracies of 51.26% and 45.72%, only\n13.17% and 7.63% higher than random guessing, indicating that such perception\nabilities have not \"emerged\" yet in recent multimodal LLMs. Our analysis also\nhighlights that specialist CV models could solve these problems much better,\nsuggesting potential pathways for future improvements. We believe Blink will\nstimulate the community to help multimodal LLMs catch up with human-level\nvisual perception.",
      "tldr_zh": "该研究引入了 BLINK，这是一个专注于多模态语言模型（Multimodal LLMs）的基准测试，评估其核心视觉感知能力，如相对深度估计（relative depth estimation）、视觉对应（visual correspondence）和多视图推理（multi-view reasoning）。BLINK 将 14 个经典计算机视觉任务转化为 3,807 个多选题，并结合单张或多张图像及视觉提示；人类在这些任务上平均准确率达 95.70%。然而，现有顶级模型如 GPT-4V 和 Gemini 的准确率仅为 51.26% 和 45.72%，比随机猜测高出不多，表明这些感知能力在 Multimodal LLMs 中尚未充分显现。论文分析显示，专业计算机视觉模型表现更佳，并建议此基准可指导未来改进，帮助 Multimodal LLMs 达到人类水平的视觉感知。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Multimodal Benchmark, Project Url: https://zeyofu.github.io/blink/,\n  ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12390v4",
      "published_date": "2024-04-18 17:59:54 UTC",
      "updated_date": "2024-07-03 08:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:33:47.649791"
    },
    {
      "arxiv_id": "2404.12382v1",
      "title": "Lazy Diffusion Transformer for Interactive Image Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Yotam Nitzan",
        "Zongze Wu",
        "Richard Zhang",
        "Eli Shechtman",
        "Daniel Cohen-Or",
        "Taesung Park",
        "Michaël Gharbi"
      ],
      "abstract": "We introduce a novel diffusion transformer, LazyDiffusion, that generates\npartial image updates efficiently. Our approach targets interactive image\nediting applications in which, starting from a blank canvas or an image, a user\nspecifies a sequence of localized image modifications using binary masks and\ntext prompts. Our generator operates in two phases. First, a context encoder\nprocesses the current canvas and user mask to produce a compact global context\ntailored to the region to generate. Second, conditioned on this context, a\ndiffusion-based transformer decoder synthesizes the masked pixels in a \"lazy\"\nfashion, i.e., it only generates the masked region. This contrasts with\nprevious works that either regenerate the full canvas, wasting time and\ncomputation, or confine processing to a tight rectangular crop around the mask,\nignoring the global image context altogether. Our decoder's runtime scales with\nthe mask size, which is typically small, while our encoder introduces\nnegligible overhead. We demonstrate that our approach is competitive with\nstate-of-the-art inpainting methods in terms of quality and fidelity while\nproviding a 10x speedup for typical user interactions, where the editing mask\nrepresents 10% of the image.",
      "tldr_zh": "本文提出了一种新型的扩散transformer模型LazyDiffusion，用于高效的交互式图像编辑。该方法分为两个阶段：首先，上下文编码器处理当前画布和用户掩码，生成一个紧凑的全局上下文；其次，基于此上下文的扩散-based transformer解码器以“lazy”方式仅合成被掩码的像素，从而避免了全图像重新生成或忽略全局信息的局限。与现有重绘方法相比，LazyDiffusion在图像质量和保真度上具有竞争力，并为典型用户交互（如掩码占图像10%）提供了10倍的加速。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12382v1",
      "published_date": "2024-04-18 17:59:27 UTC",
      "updated_date": "2024-04-18 17:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:34:02.646604"
    },
    {
      "arxiv_id": "2404.12378v2",
      "title": "6Img-to-3D: Few-Image Large-Scale Outdoor Driving Scene Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Gieruc",
        "Marius Kästingschäfer",
        "Sebastian Bernhard",
        "Mathieu Salzmann"
      ],
      "abstract": "Current 3D reconstruction techniques struggle to infer unbounded scenes from\na few images faithfully. Specifically, existing methods have high computational\ndemands, require detailed pose information, and cannot reconstruct occluded\nregions reliably. We introduce 6Img-to-3D, an efficient, scalable\ntransformer-based encoder-renderer method for single-shot image to 3D\nreconstruction. Our method outputs a 3D-consistent parameterized triplane from\nonly six outward-facing input images for large-scale, unbounded outdoor driving\nscenarios. We take a step towards resolving existing shortcomings by combining\ncontracted custom cross- and self-attention mechanisms for triplane\nparameterization, differentiable volume rendering, scene contraction, and image\nfeature projection. We showcase that six surround-view vehicle images from a\nsingle timestamp without global pose information are enough to reconstruct\n360$^{\\circ}$ scenes during inference time, taking 395 ms. Our method allows,\nfor example, rendering third-person images and birds-eye views. Our code is\navailable at https://github.com/continental/6Img-to-3D, and more examples can\nbe found at our website here https://6Img-to-3D.GitHub.io/.",
      "tldr_zh": "本文提出6Img-to-3D，一种高效、可扩展的基于Transformer的编码器-渲染器方法，用于从少量图像重建大规模无界户外驾驶场景，解决了现有技术的高计算需求、依赖详细姿态信息以及重建遮挡区域不准确的问题。核心创新包括结合收缩的自定义跨注意力和自注意力机制、三平面参数化、可微体积渲染、场景收缩以及图像特征投影，仅需六个外向车辆图像即可在395毫秒内生成3D一致的360°场景重建。实验结果显示，该方法无需全局姿态信息即可实现高质量重建，并支持渲染第三人称图像和鸟瞰视图，为户外场景3D重建提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "IV 2025. Joint first authorship. Project page:\n  https://6Img-to-3D.GitHub.io/ Code https://github.com/continental/6Img-to-3D",
      "pdf_url": "http://arxiv.org/pdf/2404.12378v2",
      "published_date": "2024-04-18 17:58:16 UTC",
      "updated_date": "2025-04-07 14:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:34:13.797899"
    },
    {
      "arxiv_id": "2404.12365v1",
      "title": "When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes",
      "title_zh": "翻译失败",
      "authors": [
        "Asaf Yehudai",
        "Elron Bendel"
      ],
      "abstract": "We present FastFit, a method, and a Python package design to provide fast and\naccurate few-shot classification, especially for scenarios with many\nsemantically similar classes. FastFit utilizes a novel approach integrating\nbatch contrastive learning and token-level similarity score. Compared to\nexisting few-shot learning packages, such as SetFit, Transformers, or few-shot\nprompting of large language models via API calls, FastFit significantly\nimproves multiclass classification performance in speed and accuracy across\nFewMany, our newly curated English benchmark, and Multilingual datasets.\nFastFit demonstrates a 3-20x improvement in training speed, completing training\nin just a few seconds. The FastFit package is now available on GitHub and PyPi,\npresenting a user-friendly solution for NLP practitioners.",
      "tldr_zh": "本研究提出 FastFit，一种快速有效的少样本文本分类方法，特别适用于具有许多语义相似的类别的场景。FastFit 整合了 batch contrastive learning 和 token-level similarity score，显著提升了多类分类的准确性和速度。与现有方法如 SetFit、Transformers 或大型语言模型的少样本提示相比，在新编制的 FewMany 基准和 Multilingual 数据集上，FastFit 的训练速度提高了 3-20 倍，仅需几秒钟完成。FastFit 作为用户友好的 Python 包，已在 GitHub 和 PyPi 上提供，适用于 NLP 实践者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL",
      "pdf_url": "http://arxiv.org/pdf/2404.12365v1",
      "published_date": "2024-04-18 17:48:05 UTC",
      "updated_date": "2024-04-18 17:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:34:26.997966"
    },
    {
      "arxiv_id": "2404.12361v2",
      "title": "Learning the Domain Specific Inverse NUFFT for Accelerated Spiral MRI using Diffusion Models",
      "title_zh": "基于扩散模型学习特定领域的逆 NUFFT 以加速螺旋 MRI",
      "authors": [
        "Trevor J. Chan",
        "Chamith S. Rajapakse"
      ],
      "abstract": "Deep learning methods for accelerated MRI achieve state-of-the-art results\nbut largely ignore additional speedups possible with noncartesian sampling\ntrajectories. To address this gap, we created a generative diffusion\nmodel-based reconstruction algorithm for multi-coil highly undersampled spiral\nMRI. This model uses conditioning during training as well as frequency-based\nguidance to ensure consistency between images and measurements. Evaluated on\nretrospective data, we show high quality (structural similarity > 0.87) in\nreconstructed images with ultrafast scan times (0.02 seconds for a 2D image).\nWe use this algorithm to identify a set of optimal variable-density spiral\ntrajectories and show large improvements in image quality compared to\nconventional reconstruction using the non-uniform fast Fourier transform. By\ncombining efficient spiral sampling trajectories, multicoil imaging, and deep\nlearning reconstruction, these methods could enable the extremely high\nacceleration factors needed for real-time 3D imaging.",
      "tldr_zh": "本研究提出了一种基于Diffusion Models的领域特定逆非均匀快速傅立叶变换（Inverse NUFFT）方法，用于加速Spiral MRI成像。该方法利用生成扩散模型结合条件训练和频率指导，确保重建图像与测量数据一致，并在回顾性数据上实现了高质量重建（结构相似性SSIM > 0.87）和超快扫描时间（0.02秒用于2D图像）。通过优化可变密度螺旋轨迹，该算法与传统NUFFT重建相比显著提升图像质量，并展示了结合多线圈成像和深度学习的可行性，有望实现实时3D成像的高加速因子。",
      "categories": [
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12361v2",
      "published_date": "2024-04-18 17:40:23 UTC",
      "updated_date": "2024-05-10 18:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:34:37.643205"
    },
    {
      "arxiv_id": "2404.12353v2",
      "title": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Hua",
        "Yunlong Tang",
        "Chenliang Xu",
        "Jiebo Luo"
      ],
      "abstract": "Video summarization aims to create short, accurate, and cohesive summaries of\nlonger videos. Despite the existence of various video summarization datasets, a\nnotable limitation is their limited amount of source videos, which hampers the\neffective training of advanced large vision-language models (VLMs).\nAdditionally, most existing datasets are created for video-to-video\nsummarization, overlooking the contemporary need for multimodal video content\nsummarization. Recent efforts have been made to expand from unimodal to\nmultimodal video summarization, categorizing the task into three sub-tasks\nbased on the summary's modality: video-to-video (V2V), video-to-text (V2T), and\na combination of video and text summarization (V2VT). However, the textual\nsummaries in previous multimodal datasets are inadequate. To address these\nissues, we introduce Instruct-V2Xum, a cross-modal video summarization dataset\nfeaturing 30,000 diverse videos sourced from YouTube, with lengths ranging from\n40 to 940 seconds and an average summarization ratio of 16.39%. Each video\nsummary in Instruct-V2Xum is paired with a textual summary that references\nspecific frame indexes, facilitating the generation of aligned video and\ntextual summaries. In addition, we propose a new video summarization framework\nnamed V2Xum-LLM. V2Xum-LLM, specifically V2Xum-LLaMA in this study, is the\nfirst framework that unifies different video summarization tasks into one large\nlanguage model's (LLM) text decoder and achieves task-controllable video\nsummarization with temporal prompts and task instructions. Experiments show\nthat V2Xum-LLaMA outperforms strong baseline models on multiple video\nsummarization tasks. Furthermore, we propose an enhanced evaluation metric for\nV2V and V2VT summarization tasks.",
      "tldr_zh": "本文提出 Instruct-V2Xum 数据集，包含 30,000 个 YouTube 视频，用于跨模态视频总结（Cross-Modal Video Summarization），每个视频配有引用特定帧索引的文本摘要，解决了现有数据集视频数量有限和多模态不足的问题。作者引入 V2Xum-LLM 框架（具体为 V2Xum-LLaMA），通过 Temporal Prompt Instruction Tuning 将视频总结任务（如 V2V、V2T 和 V2VT）统一到一个 LLM 的文本解码器中，实现任务可控的视频摘要生成。实验结果显示，该框架在多个任务上优于基线模型，并提出增强的评估指标提升 V2V 和 V2VT 任务的评估准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12353v2",
      "published_date": "2024-04-18 17:32:46 UTC",
      "updated_date": "2024-08-20 23:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:34:50.390673"
    },
    {
      "arxiv_id": "2404.12349v1",
      "title": "Evaluating AI for Law: Bridging the Gap with Open-Source Solutions",
      "title_zh": "评估AI在法律领域：",
      "authors": [
        "Rohan Bhambhoria",
        "Samuel Dahan",
        "Jonathan Li",
        "Xiaodan Zhu"
      ],
      "abstract": "This study evaluates the performance of general-purpose AI, like ChatGPT, in\nlegal question-answering tasks, highlighting significant risks to legal\nprofessionals and clients. It suggests leveraging foundational models enhanced\nby domain-specific knowledge to overcome these issues. The paper advocates for\ncreating open-source legal AI systems to improve accuracy, transparency, and\nnarrative diversity, addressing general AI's shortcomings in legal contexts.",
      "tldr_zh": "这篇论文评估了通用 AI（如 ChatGPT）在法律问答任务中的表现，突出了其潜在风险，包括对法律专业人士和客户的不准确性影响。论文建议通过增强基础模型(domain-specific knowledge)来克服这些问题，并倡导开发开源法律 AI 系统，以提升准确性、透明性和叙事多样性。最终，这为桥接通用 AI 与法律领域的应用提供了可行的解决方案。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12349v1",
      "published_date": "2024-04-18 17:26:01 UTC",
      "updated_date": "2024-04-18 17:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:35:00.263209"
    },
    {
      "arxiv_id": "2404.12322v2",
      "title": "Generalizable Face Landmarking Guided by Conditional Face Warping",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Liang",
        "Haotian Liu",
        "Hongteng Xu",
        "Dixin Luo"
      ],
      "abstract": "As a significant step for human face modeling, editing, and generation, face\nlandmarking aims at extracting facial keypoints from images. A generalizable\nface landmarker is required in practice because real-world facial images, e.g.,\nthe avatars in animations and games, are often stylized in various ways.\nHowever, achieving generalizable face landmarking is challenging due to the\ndiversity of facial styles and the scarcity of labeled stylized faces. In this\nstudy, we propose a simple but effective paradigm to learn a generalizable face\nlandmarker based on labeled real human faces and unlabeled stylized faces. Our\nmethod learns the face landmarker as the key module of a conditional face\nwarper. Given a pair of real and stylized facial images, the conditional face\nwarper predicts a warping field from the real face to the stylized one, in\nwhich the face landmarker predicts the ending points of the warping field and\nprovides us with high-quality pseudo landmarks for the corresponding stylized\nfacial images. Applying an alternating optimization strategy, we learn the face\nlandmarker to minimize $i)$ the discrepancy between the stylized faces and the\nwarped real ones and $ii)$ the prediction errors of both real and pseudo\nlandmarks. Experiments on various datasets show that our method outperforms\nexisting state-of-the-art domain adaptation methods in face landmarking tasks,\nleading to a face landmarker with better generalizability. Code is available at\nhttps://plustwo0.github.io/project-face-landmarker.",
      "tldr_zh": "这篇论文针对面部关键点检测（face landmarking）提出了一种通用化方法，以处理真实世界中风格化面部图像（如动画或游戏头像）的多样性挑战。方法将面部关键点检测器整合到条件面部扭曲（conditional face warping）框架中，利用标注的真实人脸图像和无标注的风格化图像，通过预测扭曲场（warping field）的结束点生成高质量伪关键点。采用交替优化策略，该方法最小化风格化图像与扭曲真实图像的差异，以及真实和伪关键点的预测错误；在多个数据集上的实验显示，该方法优于现有最先进领域适应技术，提高了面部关键点检测的通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12322v2",
      "published_date": "2024-04-18 16:53:08 UTC",
      "updated_date": "2024-04-21 08:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:35:15.627887"
    },
    {
      "arxiv_id": "2404.12317v4",
      "title": "Synthetic Participatory Planning of Shard Automated Electric Mobility Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangbo Yu",
        "Graeme McKinley"
      ],
      "abstract": "Unleashing the synergies among rapidly evolving mobility technologies in a\nmulti-stakeholder setting presents unique challenges and opportunities for\naddressing urban transportation problems. This paper introduces a novel\nsynthetic participatory method that critically leverages large language models\n(LLMs) to create digital avatars representing diverse stakeholders to plan\nshared automated electric mobility systems (SAEMS). These calibratable agents\ncollaboratively identify objectives, envision and evaluate SAEMS alternatives,\nand strategize implementation under risks and constraints. The results of a\nMontreal case study indicate that a structured and parameterized workflow\nprovides outputs with higher controllability and comprehensiveness on an SAEMS\nplan than that generated using a single LLM-enabled expert agent. Consequently,\nthis approach provides a promising avenue for cost-efficiently improving the\ninclusivity and interpretability of multi-objective transportation planning,\nsuggesting a paradigm shift in how we envision and strategize for sustainable\ntransportation systems.",
      "tldr_zh": "本论文提出了一种合成参与式规划方法，利用大型语言模型(LLMs)创建数字代理人来代表多利益相关者，共同设计共享自动化电动移动系统(SAEMS)，包括识别目标、评估备选方案并制定风险下的实施策略。该方法通过结构化和参数化的工作流程，提高了规划过程的可控性和全面性。蒙特利尔案例研究显示，与单一LLM专家代理相比，该方法在SAEMS计划输出上表现出显著优势。该创新途径为多目标交通规划提供了更具包容性和可解释性的解决方案，推动可持续交通系统的范式转变。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12317v4",
      "published_date": "2024-04-18 16:51:23 UTC",
      "updated_date": "2024-07-07 21:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:35:26.082889"
    },
    {
      "arxiv_id": "2404.12299v1",
      "title": "Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuke Sakai",
        "Mana Makinae",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "In Simultaneous Machine Translation (SiMT) systems, training with a\nsimultaneous interpretation (SI) corpus is an effective method for achieving\nhigh-quality yet low-latency systems. However, it is very challenging to curate\nsuch a corpus due to limitations in the abilities of annotators, and hence,\nexisting SI corpora are limited. Therefore, we propose a method to convert\nexisting speech translation corpora into interpretation-style data, maintaining\nthe original word order and preserving the entire source content using Large\nLanguage Models (LLM-SI-Corpus). We demonstrate that fine-tuning SiMT models in\ntext-to-text and speech-to-text settings with the LLM-SI-Corpus reduces\nlatencies while maintaining the same level of quality as the models trained\nwith offline datasets. The LLM-SI-Corpus is available at\n\\url{https://github.com/yusuke1997/LLM-SI-Corpus}.",
      "tldr_zh": "该研究针对同时机器翻译 (SiMT) 系统，提出了一种使用大型语言模型 (LLM) 的方法来构建同时口译 (SI) 语料库，特别是针对远距离语言对。方法涉及将现有语音翻译语料库转换为解释风格数据 (LLM-SI-Corpus)，以保持原词顺序并保留全部源内容。实验结果显示，通过在文本到文本和语音到文本设置中微调 SiMT 模型，该语料库能显著降低延迟，同时维持与离线数据集训练模型相同的质量水平。该语料库已在 GitHub 上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12299v1",
      "published_date": "2024-04-18 16:24:12 UTC",
      "updated_date": "2024-04-18 16:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:35:37.436765"
    },
    {
      "arxiv_id": "2404.12291v2",
      "title": "Augmenting emotion features in irony detection with Large language modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Lin",
        "Yuhan Xia",
        "Yunfei Long"
      ],
      "abstract": "This study introduces a novel method for irony detection, applying Large\nLanguage Models (LLMs) with prompt-based learning to facilitate emotion-centric\ntext augmentation. Traditional irony detection techniques typically fall short\ndue to their reliance on static linguistic features and predefined knowledge\nbases, often overlooking the nuanced emotional dimensions integral to irony. In\ncontrast, our methodology augments the detection process by integrating subtle\nemotional cues, augmented through LLMs, into three benchmark pre-trained NLP\nmodels - BERT, T5, and GPT-2 - which are widely recognized as foundational in\nirony detection. We assessed our method using the SemEval-2018 Task 3 dataset\nand observed substantial enhancements in irony detection capabilities.",
      "tldr_zh": "本研究提出了一种新颖的讽刺检测方法，通过 Large Language Models (LLMs) 和基于提示的学习来增强文本中的情感特征。传统方法依赖静态语言特征和预定义知识库，往往忽略讽刺的核心情感维度；相比之下，该方法将 LLMs 扩充的情感线索整合到 BERT、T5 和 GPT-2 等预训练模型中。研究使用 SemEval-2018 Task 3 数据集进行评估，结果显示讽刺检测性能显著提升。总的来说，这一方法为更 nuanced 的讽刺识别提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 tables, 2 figures. Accepted by the 25th Chinese Lexical\n  Semantics Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.12291v2",
      "published_date": "2024-04-18 16:11:17 UTC",
      "updated_date": "2024-04-20 01:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:35:48.961923"
    },
    {
      "arxiv_id": "2404.12278v2",
      "title": "DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era",
      "title_zh": "DF-DM：人工智能时代多模态数据融合的基础过程模型",
      "authors": [
        "David Restrepo",
        "Chenwei Wu",
        "Constanza Vásquez-Venegas",
        "Luis Filipe Nakayama",
        "Leo Anthony Celi",
        "Diego M López"
      ],
      "abstract": "In the big data era, integrating diverse data modalities poses significant\nchallenges, particularly in complex fields like healthcare. This paper\nintroduces a new process model for multimodal Data Fusion for Data Mining,\nintegrating embeddings and the Cross-Industry Standard Process for Data Mining\nwith the existing Data Fusion Information Group model. Our model aims to\ndecrease computational costs, complexity, and bias while improving efficiency\nand reliability. We also propose \"disentangled dense fusion\", a novel embedding\nfusion method designed to optimize mutual information and facilitate dense\ninter-modality feature interaction, thereby minimizing redundant information.\n  We demonstrate the model's efficacy through three use cases: predicting\ndiabetic retinopathy using retinal images and patient metadata, domestic\nviolence prediction employing satellite imagery, internet, and census data, and\nidentifying clinical and demographic features from radiography images and\nclinical notes. The model achieved a Macro F1 score of 0.92 in diabetic\nretinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic\nviolence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction\nand sex classification, respectively, in radiological analysis.\n  These results underscore the Data Fusion for Data Mining model's potential to\nsignificantly impact multimodal data processing, promoting its adoption in\ndiverse, resource-constrained settings.",
      "tldr_zh": "本文提出 DF-DM 模型，这是一种基础过程模型，用于多模态数据融合，整合 embeddings、Cross-Industry Standard Process for Data Mining 和 Data Fusion Information Group 模型，旨在降低计算成本、复杂性和偏差，同时提升效率和可靠性。作者引入 \"disentangled dense fusion\" 方法，优化 mutual information 并促进 dense inter-modality feature interaction，以最小化冗余信息。实验通过三个用例验证：预测糖尿病视网膜病变（Macro F1 score 0.92）、家庭暴力预测（R-squared 0.854 和 sMAPE 24.868）、以及放射图像分析（macro AUC 0.92 和 0.99），展示了模型在多模态数据处理中的显著潜力，特别适合资源受限环境。",
      "categories": [
        "cs.AI",
        "68T30",
        "I.2.0; I.3.6"
      ],
      "primary_category": "cs.AI",
      "comment": "6 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.12278v2",
      "published_date": "2024-04-18 15:52:42 UTC",
      "updated_date": "2024-06-02 16:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:36:04.462886"
    },
    {
      "arxiv_id": "2404.12274v1",
      "title": "Advancing the Robustness of Large Language Models through Self-Denoised Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabao Ji",
        "Bairu Hou",
        "Zhen Zhang",
        "Guanhua Zhang",
        "Wenqi Fan",
        "Qing Li",
        "Yang Zhang",
        "Gaowen Liu",
        "Sijia Liu",
        "Shiyu Chang"
      ],
      "abstract": "Although large language models (LLMs) have achieved significant success,\ntheir vulnerability to adversarial perturbations, including recent jailbreak\nattacks, has raised considerable concerns. However, the increasing size of\nthese models and their limited access make improving their robustness a\nchallenging task. Among various defense strategies, randomized smoothing has\nshown great potential for LLMs, as it does not require full access to the\nmodel's parameters or fine-tuning via adversarial training. However, randomized\nsmoothing involves adding noise to the input before model prediction, and the\nfinal model's robustness largely depends on the model's performance on these\nnoise corrupted data. Its effectiveness is often limited by the model's\nsub-optimal performance on noisy data. To address this issue, we propose to\nleverage the multitasking nature of LLMs to first denoise the noisy inputs and\nthen to make predictions based on these denoised versions. We call this\nprocedure self-denoised smoothing. Unlike previous denoised smoothing\ntechniques in computer vision, which require training a separate model to\nenhance the robustness of LLMs, our method offers significantly better\nefficiency and flexibility. Our experimental results indicate that our method\nsurpasses existing methods in both empirical and certified robustness in\ndefending against adversarial attacks for both downstream tasks and human\nalignments (i.e., jailbreak attacks). Our code is publicly available at\nhttps://github.com/UCSB-NLP-Chang/SelfDenoise",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 易受对抗性扰动和越狱攻击的脆弱性，提出了一种self-denoised smoothing方法。该方法利用LLMs的多任务能力，先对噪声输入进行去噪处理，然后基于去噪版本进行预测，从而提升模型在噪声数据上的性能。与传统randomized smoothing不同，该方法无需训练额外模型，提供更高的效率和灵活性。实验结果显示，该方法在对抗攻击下，超过了现有技术，在经验鲁棒性和认证鲁棒性上表现出色，包括下游任务和越狱攻击防御。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2024. Jiabao, Bairu, Zhen, Guanhua contributed\n  equally. This is an updated version of the paper: arXiv:2307.07171",
      "pdf_url": "http://arxiv.org/pdf/2404.12274v1",
      "published_date": "2024-04-18 15:47:00 UTC",
      "updated_date": "2024-04-18 15:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:36:14.230293"
    },
    {
      "arxiv_id": "2404.12273v1",
      "title": "FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanqin He",
        "Yan Kang",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising solution for collaborative\ntraining of large language models (LLMs). However, the integration of LLMs into\nFL introduces new challenges, particularly concerning the evaluation of LLMs.\nTraditional evaluation methods that rely on labeled test sets and\nsimilarity-based metrics cover only a subset of the acceptable answers, thereby\nfailing to accurately reflect the performance of LLMs on generative tasks.\nMeanwhile, although automatic evaluation methods that leverage advanced LLMs\npresent potential, they face critical risks of data leakage due to the need to\ntransmit data to external servers and suboptimal performance on downstream\ntasks due to the lack of domain knowledge. To address these issues, we propose\na Federated Evaluation framework of Large Language Models, named FedEval-LLM,\nthat provides reliable performance measurements of LLMs on downstream tasks\nwithout the reliance on labeled test sets and external tools, thus ensuring\nstrong privacy-preserving capability. FedEval-LLM leverages a consortium of\npersonalized LLMs from participants as referees to provide domain knowledge and\ncollective evaluation capability, thus aligning to the respective downstream\ntasks and mitigating uncertainties and biases associated with a single referee.\nExperimental results demonstrate a significant improvement in the evaluation\ncapability of personalized evaluation models on downstream tasks. When applied\nto FL, these evaluation models exhibit strong agreement with human preference\nand RougeL-score on meticulously curated test sets. FedEval-LLM effectively\novercomes the limitations of traditional metrics and the reliance on external\nservices, making it a promising framework for the evaluation of LLMs within\ncollaborative training scenarios.",
      "tldr_zh": "这篇论文提出了 FedEval-LLM，一种联邦评估框架，用于在 Federated Learning (FL) 环境中评估大型语言模型 (LLMs) 在下游任务上的性能，解决了传统评估方法依赖标记测试集和外部工具的问题，从而避免数据泄露风险并增强隐私保护。框架通过利用参与者的个性化 LLMs 作为裁判，提供领域知识和集体智慧，实现更准确的集体评估并减少不确定性和偏差。实验结果表明，FedEval-LLM 显著提高了评估模型的性能，与人类偏好和 RougeL-score 高度一致，为 FL 中的 LLM 评估提供了可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "In Progress",
      "pdf_url": "http://arxiv.org/pdf/2404.12273v1",
      "published_date": "2024-04-18 15:46:26 UTC",
      "updated_date": "2024-04-18 15:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:36:26.314073"
    },
    {
      "arxiv_id": "2404.12272v1",
      "title": "Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Shankar",
        "J. D. Zamfirescu-Pereira",
        "Björn Hartmann",
        "Aditya G. Parameswaran",
        "Ian Arawjo"
      ],
      "abstract": "Due to the cumbersome nature of human evaluation and limitations of\ncode-based evaluation, Large Language Models (LLMs) are increasingly being used\nto assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply\ninherit all the problems of the LLMs they evaluate, requiring further human\nvalidation. We present a mixed-initiative approach to ``validate the\nvalidators'' -- aligning LLM-generated evaluation functions (be it prompts or\ncode) with human requirements. Our interface, EvalGen, provides automated\nassistance to users in generating evaluation criteria and implementing\nassertions. While generating candidate implementations (Python functions, LLM\ngrader prompts), EvalGen asks humans to grade a subset of LLM outputs; this\nfeedback is used to select implementations that better align with user grades.\nA qualitative study finds overall support for EvalGen but underscores the\nsubjectivity and iterative process of alignment. In particular, we identify a\nphenomenon we dub \\emph{criteria drift}: users need criteria to grade outputs,\nbut grading outputs helps users define criteria. What is more, some criteria\nappears \\emph{dependent} on the specific LLM outputs observed (rather than\nindependent criteria that can be defined \\emph{a priori}), raising serious\nquestions for approaches that assume the independence of evaluation from\nobservation of model outputs. We present our interface and implementation\ndetails, a comparison of our algorithm with a baseline approach, and\nimplications for the design of future LLM evaluation assistants.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLM)评估其他LLM输出时的问题，即LLM评估器本身可能存在偏差，需要人类验证。作者提出了一种混合主动方法，通过EvalGen接口自动生成评估标准和实现（如Python函数或LLM评分提示），并利用人类对部分输出的反馈来选择与用户偏好对齐的实现。研究发现，尽管EvalGen获得整体支持，但评估过程存在“criteria drift”现象，即标准定义依赖于具体输出观察，这质疑了评估独立性的假设，并为未来LLM评估助手的设计提供了关键启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.12272v1",
      "published_date": "2024-04-18 15:45:27 UTC",
      "updated_date": "2024-04-18 15:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:36:38.973919"
    },
    {
      "arxiv_id": "2404.12267v1",
      "title": "Physics-integrated generative modeling using attentive planar normalizing flow based variational autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Sheikh Waqas Akhtar"
      ],
      "abstract": "Physics-integrated generative modeling is a class of hybrid or grey-box\nmodeling in which we augment the the data-driven model with the physics\nknowledge governing the data distribution. The use of physics knowledge allows\nthe generative model to produce output in a controlled way, so that the output,\nby construction, complies with the physical laws. It imparts improved\ngeneralization ability to extrapolate beyond the training distribution as well\nas improved interpretability because the model is partly grounded in firm\ndomain knowledge. In this work, we aim to improve the fidelity of\nreconstruction and robustness to noise in the physics integrated generative\nmodel. To this end, we use variational-autoencoder as a generative model. To\nimprove the reconstruction results of the decoder, we propose to learn the\nlatent posterior distribution of both the physics as well as the trainable\ndata-driven components using planar normalizng flow. Normalizng flow based\nposterior distribution harnesses the inherent dynamical structure of the data\ndistribution, hence the learned model gets closer to the true underlying data\ndistribution. To improve the robustness of generative model against noise\ninjected in the model, we propose a modification in the encoder part of the\nnormalizing flow based VAE. We designed the encoder to incorporate scaled dot\nproduct attention based contextual information in the noisy latent vector which\nwill mitigate the adverse effect of noise in the latent vector and make the\nmodel more robust. We empirically evaluated our models on human locomotion\ndataset [33] and the results validate the efficacy of our proposed models in\nterms of improvement in reconstruction quality as well as robustness against\nnoise injected in the model.",
      "tldr_zh": "本研究提出了一种整合物理知识的生成模型，使用基于 attentive planar normalizing flow 的 variational autoencoder (VAE)，旨在提升重建保真度和对噪声的鲁棒性。通过学习物理组件和数据驱动组件的潜在后验分布，该方法利用 normalizing flow 捕捉数据分布的动态结构，从而更接近真实数据分布。为提高模型鲁棒性，研究者在 VAE 的编码器中加入 scaled dot product attention 处理噪声干扰。在人类运动数据集上的实验验证了该模型在重建质量和噪声抵抗方面的显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12267v1",
      "published_date": "2024-04-18 15:38:14 UTC",
      "updated_date": "2024-04-18 15:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:36:50.345448"
    },
    {
      "arxiv_id": "2404.12259v1",
      "title": "Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle S. Lam",
        "Janice Teoh",
        "James Landay",
        "Jeffrey Heer",
        "Michael S. Bernstein"
      ],
      "abstract": "Data analysts have long sought to turn unstructured text data into meaningful\nconcepts. Though common, topic modeling and clustering focus on lower-level\nkeywords and require significant interpretative work. We introduce concept\ninduction, a computational process that instead produces high-level concepts,\ndefined by explicit inclusion criteria, from unstructured text. For a dataset\nof toxic online comments, where a state-of-the-art BERTopic model outputs\n\"women, power, female,\" concept induction produces high-level concepts such as\n\"Criticism of traditional gender roles\" and \"Dismissal of women's concerns.\" We\npresent LLooM, a concept induction algorithm that leverages large language\nmodels to iteratively synthesize sampled text and propose human-interpretable\nconcepts of increasing generality. We then instantiate LLooM in a\nmixed-initiative text analysis tool, enabling analysts to shift their attention\nfrom interpreting topics to engaging in theory-driven analysis. Through\ntechnical evaluations and four analysis scenarios ranging from literature\nreview to content moderation, we find that LLooM's concepts improve upon the\nprior art of topic models in terms of quality and data coverage. In expert case\nstudies, LLooM helped researchers to uncover new insights even from familiar\ndatasets, for example by suggesting a previously unnoticed concept of attacks\non out-party stances in a political social media dataset.",
      "tldr_zh": "该论文引入了Concept Induction，一种从非结构化文本中生成高层概念的计算过程，这些概念由明确的包含标准定义，从而避免了传统主题建模（如BERTopic）对低级关键词的解释工作。作者提出了LLooM算法，利用大语言模型迭代合成采样文本，逐步生成越来越通用的可解释概念，并将其整合到一个混合式主动文本分析工具中，支持分析师进行理论驱动分析。通过技术评估和四个分析场景（如文献综述和内容审核），LLooM在概念质量和数据覆盖上优于现有模型，并在专家案例研究中帮助发现新洞见，例如在政治社交媒体数据中识别对反对党立场的攻击。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To appear at CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12259v1",
      "published_date": "2024-04-18 15:26:02 UTC",
      "updated_date": "2024-04-18 15:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:37:02.266280"
    },
    {
      "arxiv_id": "2404.12257v2",
      "title": "Food Portion Estimation via 3D Object Scaling",
      "title_zh": "通过 3D 物体缩放的食物份量估算",
      "authors": [
        "Gautham Vinod",
        "Jiangpeng He",
        "Zeman Shao",
        "Fengqing Zhu"
      ],
      "abstract": "Image-based methods to analyze food images have alleviated the user burden\nand biases associated with traditional methods. However, accurate portion\nestimation remains a major challenge due to the loss of 3D information in the\n2D representation of foods captured by smartphone cameras or wearable devices.\nIn this paper, we propose a new framework to estimate both food volume and\nenergy from 2D images by leveraging the power of 3D food models and physical\nreference in the eating scene. Our method estimates the pose of the camera and\nthe food object in the input image and recreates the eating occasion by\nrendering an image of a 3D model of the food with the estimated poses. We also\nintroduce a new dataset, SimpleFood45, which contains 2D images of 45 food\nitems and associated annotations including food volume, weight, and energy. Our\nmethod achieves an average error of 31.10 kCal (17.67%) on this dataset,\noutperforming existing portion estimation methods. The dataset can be accessed\nat: https://lorenz.ecn.purdue.edu/~gvinod/simplefood45/ and the code can be\naccessed at: https://gitlab.com/viper-purdue/monocular-food-volume-3d",
      "tldr_zh": "这篇论文提出了一种通过3D物体缩放的方法来估计食物份量的新框架，以解决2D图像中丢失3D信息导致的精确度问题。框架利用3D食物模型和物理参考，估计相机和食物物体的姿势，并通过渲染图像来计算食物的体积和能量。研究者引入了SimpleFood45数据集，包含45种食物的2D图像及其体积、重量和能量标注；该方法在数据集上实现了31.10 kCal（17.67%）的平均错误率，优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12257v2",
      "published_date": "2024-04-18 15:23:37 UTC",
      "updated_date": "2024-10-10 20:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:37:14.914863"
    },
    {
      "arxiv_id": "2404.12256v1",
      "title": "An Online Spatial-Temporal Graph Trajectory Planner for Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Jilan Samiuddin",
        "Benoit Boulet",
        "Di Wu"
      ],
      "abstract": "The autonomous driving industry is expected to grow by over 20 times in the\ncoming decade and, thus, motivate researchers to delve into it. The primary\nfocus of their research is to ensure safety, comfort, and efficiency. An\nautonomous vehicle has several modules responsible for one or more of the\naforementioned items. Among these modules, the trajectory planner plays a\npivotal role in the safety of the vehicle and the comfort of its passengers.\nThe module is also responsible for respecting kinematic constraints and any\napplicable road constraints. In this paper, a novel online spatial-temporal\ngraph trajectory planner is introduced to generate safe and comfortable\ntrajectories. First, a spatial-temporal graph is constructed using the\nautonomous vehicle, its surrounding vehicles, and virtual nodes along the road\nwith respect to the vehicle itself. Next, the graph is forwarded into a\nsequential network to obtain the desired states. To support the planner, a\nsimple behavioral layer is also presented that determines kinematic constraints\nfor the planner. Furthermore, a novel potential function is also proposed to\ntrain the network. Finally, the proposed planner is tested on three different\ncomplex driving tasks, and the performance is compared with two frequently used\nmethods. The results show that the proposed planner generates safe and feasible\ntrajectories while achieving similar or longer distances in the forward\ndirection and comparable comfort ride.",
      "tldr_zh": "本研究提出了一种在线空间-时间图(Spatial-Temporal Graph)轨迹规划器，用于提升自动驾驶车辆的安全、舒适和效率。该规划器通过构建包含车辆、周围车辆和道路虚拟节点的图结构，并结合顺序网络(Sequential Network)来生成期望状态，同时引入一个简单行为层确定运动学约束和一个新颖潜力函数进行网络训练。在三个复杂驾驶任务的实验中，该规划器与两种常用方法相比，产生了安全、可行且舒适的轨迹，实现了相似的或更长的前进距离。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This is the accepted version and published in the \"Early Access\" area\n  of IEEE Xplore for the IEEE Transactions on Intelligent Vehicles on 16 April\n  2024. Article statistics: 11 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.12256v1",
      "published_date": "2024-04-18 15:22:29 UTC",
      "updated_date": "2024-04-18 15:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:37:25.507955"
    },
    {
      "arxiv_id": "2404.12241v2",
      "title": "Introducing v0.5 of the AI Safety Benchmark from MLCommons",
      "title_zh": "翻译失败",
      "authors": [
        "Bertie Vidgen",
        "Adarsh Agrawal",
        "Ahmed M. Ahmed",
        "Victor Akinwande",
        "Namir Al-Nuaimi",
        "Najla Alfaraj",
        "Elie Alhajjar",
        "Lora Aroyo",
        "Trupti Bavalatti",
        "Max Bartolo",
        "Borhane Blili-Hamelin",
        "Kurt Bollacker",
        "Rishi Bomassani",
        "Marisa Ferrara Boston",
        "Siméon Campos",
        "Kal Chakra",
        "Canyu Chen",
        "Cody Coleman",
        "Zacharie Delpierre Coudert",
        "Leon Derczynski",
        "Debojyoti Dutta",
        "Ian Eisenberg",
        "James Ezick",
        "Heather Frase",
        "Brian Fuller",
        "Ram Gandikota",
        "Agasthya Gangavarapu",
        "Ananya Gangavarapu",
        "James Gealy",
        "Rajat Ghosh",
        "James Goel",
        "Usman Gohar",
        "Sujata Goswami",
        "Scott A. Hale",
        "Wiebke Hutiri",
        "Joseph Marvin Imperial",
        "Surgan Jandial",
        "Nick Judd",
        "Felix Juefei-Xu",
        "Foutse Khomh",
        "Bhavya Kailkhura",
        "Hannah Rose Kirk",
        "Kevin Klyman",
        "Chris Knotz",
        "Michael Kuchnik",
        "Shachi H. Kumar",
        "Srijan Kumar",
        "Chris Lengerich",
        "Bo Li",
        "Zeyi Liao",
        "Eileen Peters Long",
        "Victor Lu",
        "Sarah Luger",
        "Yifan Mai",
        "Priyanka Mary Mammen",
        "Kelvin Manyeki",
        "Sean McGregor",
        "Virendra Mehta",
        "Shafee Mohammed",
        "Emanuel Moss",
        "Lama Nachman",
        "Dinesh Jinenhally Naganna",
        "Amin Nikanjam",
        "Besmira Nushi",
        "Luis Oala",
        "Iftach Orr",
        "Alicia Parrish",
        "Cigdem Patlak",
        "William Pietri",
        "Forough Poursabzi-Sangdeh",
        "Eleonora Presani",
        "Fabrizio Puletti",
        "Paul Röttger",
        "Saurav Sahay",
        "Tim Santos",
        "Nino Scherrer",
        "Alice Schoenauer Sebag",
        "Patrick Schramowski",
        "Abolfazl Shahbazi",
        "Vin Sharma",
        "Xudong Shen",
        "Vamsi Sistla",
        "Leonard Tang",
        "Davide Testuggine",
        "Vithursan Thangarasa",
        "Elizabeth Anne Watkins",
        "Rebecca Weiss",
        "Chris Welty",
        "Tyler Wilbers",
        "Adina Williams",
        "Carole-Jean Wu",
        "Poonam Yadav",
        "Xianjun Yang",
        "Yi Zeng",
        "Wenhui Zhang",
        "Fedor Zhdanov",
        "Jiacheng Zhu",
        "Percy Liang",
        "Peter Mattson",
        "Joaquin Vanschoren"
      ],
      "abstract": "This paper introduces v0.5 of the AI Safety Benchmark, which has been created\nby the MLCommons AI Safety Working Group. The AI Safety Benchmark has been\ndesigned to assess the safety risks of AI systems that use chat-tuned language\nmodels. We introduce a principled approach to specifying and constructing the\nbenchmark, which for v0.5 covers only a single use case (an adult chatting to a\ngeneral-purpose assistant in English), and a limited set of personas (i.e.,\ntypical users, malicious users, and vulnerable users). We created a new\ntaxonomy of 13 hazard categories, of which 7 have tests in the v0.5 benchmark.\nWe plan to release version 1.0 of the AI Safety Benchmark by the end of 2024.\nThe v1.0 benchmark will provide meaningful insights into the safety of AI\nsystems. However, the v0.5 benchmark should not be used to assess the safety of\nAI systems. We have sought to fully document the limitations, flaws, and\nchallenges of v0.5. This release of v0.5 of the AI Safety Benchmark includes\n(1) a principled approach to specifying and constructing the benchmark, which\ncomprises use cases, types of systems under test (SUTs), language and context,\npersonas, tests, and test items; (2) a taxonomy of 13 hazard categories with\ndefinitions and subcategories; (3) tests for seven of the hazard categories,\neach comprising a unique set of test items, i.e., prompts. There are 43,090\ntest items in total, which we created with templates; (4) a grading system for\nAI systems against the benchmark; (5) an openly available platform, and\ndownloadable tool, called ModelBench that can be used to evaluate the safety of\nAI systems on the benchmark; (6) an example evaluation report which benchmarks\nthe performance of over a dozen openly available chat-tuned language models;\n(7) a test specification for the benchmark.",
      "tldr_zh": "该论文介绍了 MLCommons AI Safety Working Group 发布的 AI Safety Benchmark v0.5 版本，该基准采用原则性方法评估基于聊天调优语言模型的 AI 系统安全风险，仅覆盖单一用例（如成人与通用助手聊天）和有限角色（如典型用户、恶意用户和易受损用户）。他们创建了一个包含 13 个 hazard categories 的分类，并为 7 个类别开发了 43,090 个测试项，使用模板生成，并提供了评分系统、评估平台 ModelBench 和示例报告。v0.5 版本已全面记录其局限性，不适合用于实际 AI 安全评估，计划于 2024 年底发布 v1.0 版本，以提供更深入的洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12241v2",
      "published_date": "2024-04-18 15:01:00 UTC",
      "updated_date": "2024-05-13 20:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:37:41.088033"
    },
    {
      "arxiv_id": "2404.12240v1",
      "title": "A Time-Inhomogeneous Markov Model for Resource Availability under Sparse Observations",
      "title_zh": "时间非齐次的马尔可夫模型用于稀疏观察下的资源可用性",
      "authors": [
        "Lukas Rottkamp",
        "Matthias Schubert"
      ],
      "abstract": "Accurate spatio-temporal information about the current situation is crucial\nfor smart city applications such as modern routing algorithms. Often, this\ninformation describes the state of stationary resources, e.g. the availability\nof parking bays, charging stations or the amount of people waiting for a\nvehicle to pick them up near a given location. To exploit this kind of\ninformation, predicting future states of the monitored resources is often\nmandatory because a resource might change its state within the time until it is\nneeded. To train an accurate predictive model, it is often not possible to\nobtain a continuous time series on the state of the resource. For example, the\ninformation might be collected from traveling agents visiting the resource with\nan irregular frequency. Thus, it is necessary to develop methods which work on\nsparse observations for training and prediction. In this paper, we propose\ntime-inhomogeneous discrete Markov models to allow accurate prediction even\nwhen the frequency of observation is very rare. Our new model is able to blend\nrecent observations with historic data and also provide useful probabilistic\nestimates for future states. Since resources availability in a city is\ntypically time-dependent, our Markov model is time-inhomogeneous and cyclic\nwithin a predefined time interval. To train our model, we propose a modified\nBaum-Welch algorithm. Evaluations on real-world datasets of parking bay\navailability show that our new method indeed yields good results compared to\nmethods being trained on complete data and non-cyclic variants.",
      "tldr_zh": "本研究针对智能城市应用中资源可用性（如停车位或充电站）的预测问题，提出了一种处理稀疏观察（sparse observations）的时间非均匀Markov模型（time-inhomogeneous Markov model），该模型能融合最近观察数据与历史信息，提供未来状态的概率估计。模型设计为时间相关的周期性结构，并采用修改后的Baum-Welch算法进行训练，以适应不规则数据采集场景。实验结果显示，在真实停车位可用性数据集上，该方法比基于完整数据或非周期性变体的基准模型表现出色，证明了其在稀疏数据下的预测准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, long version of a paper published at 26th ACM SIGSPATIAL\n  International Conference on Advances in Geographic Information Systems\n  (SIGSPATIAL 2018)",
      "pdf_url": "http://arxiv.org/pdf/2404.12240v1",
      "published_date": "2024-04-18 15:00:59 UTC",
      "updated_date": "2024-04-18 15:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:37:49.843554"
    },
    {
      "arxiv_id": "2404.12237v2",
      "title": "De-DSI: Decentralised Differentiable Search Index",
      "title_zh": "De-DSI：去中心化可微搜索索引",
      "authors": [
        "Petru Neague",
        "Marcel Gregoriadis",
        "Johan Pouwelse"
      ],
      "abstract": "This study introduces De-DSI, a novel framework that fuses large language\nmodels (LLMs) with genuine decentralization for information retrieval,\nparticularly employing the differentiable search index (DSI) concept in a\ndecentralized setting. Focused on efficiently connecting novel user queries\nwith document identifiers without direct document access, De-DSI operates\nsolely on query-docid pairs. To enhance scalability, an ensemble of DSI models\nis introduced, where the dataset is partitioned into smaller shards for\nindividual model training. This approach not only maintains accuracy by\nreducing the number of data each model needs to handle but also facilitates\nscalability by aggregating outcomes from multiple models. This aggregation uses\na beam search to identify top docids and applies a softmax function for score\nnormalization, selecting documents with the highest scores for retrieval. The\ndecentralized implementation demonstrates that retrieval success is comparable\nto centralized methods, with the added benefit of the possibility of\ndistributing computational complexity across the network. This setup also\nallows for the retrieval of multimedia items through magnet links, eliminating\nthe need for platforms or intermediaries.",
      "tldr_zh": "本研究提出 De-DSI 框架，将大型语言模型 (LLMs) 与去中心化技术相结合，用于信息检索，基于可微搜索索引 (DSI) 概念，仅使用查询-docid 对高效连接用户查询和文档标识符。该框架通过将数据集分区成较小碎片并训练多个 DSI 模型的集合来提升可扩展性，并采用 beam search 识别顶层 docids 以及 softmax 函数进行分数归一化，以聚合结果。实验结果表明，De-DSI 的检索成功率与中心化方法相当，同时实现了计算复杂度的分布，并支持通过 magnet links 检索多媒体项目，无需平台或中间人干预。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DC",
        "I.2.7; I.2.11; H.3.3; C.2.4"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at the 4th Workshop on Machine Learning and Systems\n  (EuroMLSys), EuroSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12237v2",
      "published_date": "2024-04-18 14:51:55 UTC",
      "updated_date": "2024-04-19 11:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:38:03.927775"
    },
    {
      "arxiv_id": "2404.12228v3",
      "title": "CausalMed: Causality-Based Personalized Medication Recommendation Centered on Patient health state",
      "title_zh": "CausalMed: 基于因果关系的个性化药物推荐，以患者健康状态为中心",
      "authors": [
        "Xiang Li",
        "Shunpan Liang",
        "Yu Lei",
        "Chen Li",
        "Yulei Hou",
        "Tengfei Ma"
      ],
      "abstract": "Medication recommendation systems are developed to recommend suitable\nmedications tailored to specific patient. Previous researches primarily focus\non learning medication representations, which have yielded notable advances.\nHowever, these methods are limited to capturing personalized patient\nrepresentations due to the following primary limitations: (i) unable to capture\nthe differences in the impact of diseases/procedures on patients across various\npatient health states; (ii) fail to model the direct causal relationships\nbetween medications and specific health state of patients, resulting in an\ninability to determine which specific disease each medication is treating. To\naddress these limitations, we propose CausalMed, a patient health state-centric\nmodel capable of enhancing the personalization of patient representations.\nSpecifically, CausalMed first captures the causal relationship between\ndiseases/procedures and medications through causal discovery and evaluates\ntheir causal effects. Building upon this, CausalMed focuses on analyzing the\nhealth state of patients, capturing the dynamic differences of\ndiseases/procedures in different health states of patients, and transforming\ndiseases/procedures into medications on direct causal relationships.\nUltimately, CausalMed integrates information from longitudinal visits to\nrecommend medication combinations. Extensive experiments on real-world datasets\nshow that our method learns more personalized patient representation and\noutperforms state-of-the-art models in accuracy and safety.",
      "tldr_zh": "该论文提出 CausalMed 模型，一种基于因果关系的个性化药物推荐系统，以患者健康状态为中心，解决现有方法无法捕捉疾病/程序对不同健康状态影响差异以及忽略药物与健康状态直接因果关系的问题。具体而言，CausalMed 通过因果发现捕获疾病/程序与药物的因果关系、评估因果效果，并分析患者健康状态的动态差异，最终整合纵向就诊信息来推荐药物组合。实验在真实数据集上表明，该模型学习了更个性化的患者表示，并在准确性和安全性方面优于现有最先进模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "CIKM 2024 Full Research Paper",
      "pdf_url": "http://arxiv.org/pdf/2404.12228v3",
      "published_date": "2024-04-18 14:44:08 UTC",
      "updated_date": "2024-07-21 03:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:38:14.485748"
    },
    {
      "arxiv_id": "2404.12185v1",
      "title": "An Adaptive Metaheuristic Framework for Changing Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Bestoun S. Ahmed"
      ],
      "abstract": "The rapidly changing landscapes of modern optimization problems require\nalgorithms that can be adapted in real-time. This paper introduces an Adaptive\nMetaheuristic Framework (AMF) designed for dynamic environments. It is capable\nof intelligently adapting to changes in the problem parameters. The AMF\ncombines a dynamic representation of problems, a real-time sensing system, and\nadaptive techniques to navigate continuously changing optimization\nenvironments. Through a simulated dynamic optimization problem, the AMF's\ncapability is demonstrated to detect environmental changes and proactively\nadjust its search strategy. This framework utilizes a differential evolution\nalgorithm that is improved with an adaptation module that adjusts solutions in\nresponse to detected changes. The capability of the AMF to adjust is tested\nthrough a series of iterations, demonstrating its resilience and robustness in\nsustaining solution quality despite the problem's development. The\neffectiveness of AMF is demonstrated through a series of simulations on a\ndynamic optimization problem. Robustness and agility characterize the\nalgorithm's performance, as evidenced by the presented fitness evolution and\nsolution path visualizations. The findings show that AMF is a practical\nsolution to dynamic optimization and a major step forward in the creation of\nalgorithms that can handle the unpredictability of real-world problems.",
      "tldr_zh": "这篇论文引入了Adaptive Metaheuristic Framework (AMF)，一个针对动态优化环境的框架，能够实时适应问题参数的变化。AMF 结合动态问题表示、实时感知系统和适应技术，并基于改进的differential evolution algorithm 来检测环境变化并调整搜索策略。通过模拟实验，AMF 展示了其在迭代过程中的韧性和鲁棒性，能够维持解决方案质量并显著提升性能。研究结果表明，AMF 是动态优化问题的实用解决方案，推动了处理真实世界不确定性的算法发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in 2024 IEEE Congress on Evolutionary Computation (CEC)",
      "pdf_url": "http://arxiv.org/pdf/2404.12185v1",
      "published_date": "2024-04-18 13:47:53 UTC",
      "updated_date": "2024-04-18 13:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:38:27.238759"
    },
    {
      "arxiv_id": "2404.12172v2",
      "title": "How to Benchmark Vision Foundation Models for Semantic Segmentation?",
      "title_zh": "翻译失败",
      "authors": [
        "Tommie Kerssies",
        "Daan de Geus",
        "Gijs Dubbelman"
      ],
      "abstract": "Recent vision foundation models (VFMs) have demonstrated proficiency in\nvarious tasks but require supervised fine-tuning to perform the task of\nsemantic segmentation effectively. Benchmarking their performance is essential\nfor selecting current models and guiding future model developments for this\ntask. The lack of a standardized benchmark complicates comparisons. Therefore,\nthe primary objective of this paper is to study how VFMs should be benchmarked\nfor semantic segmentation. To do so, various VFMs are fine-tuned under various\nsettings, and the impact of individual settings on the performance ranking and\ntraining time is assessed. Based on the results, the recommendation is to\nfine-tune the ViT-B variants of VFMs with a 16x16 patch size and a linear\ndecoder, as these settings are representative of using a larger model, more\nadvanced decoder and smaller patch size, while reducing training time by more\nthan 13 times. Using multiple datasets for training and evaluation is also\nrecommended, as the performance ranking across datasets and domain shifts\nvaries. Linear probing, a common practice for some VFMs, is not recommended, as\nit is not representative of end-to-end fine-tuning. The benchmarking setup\nrecommended in this paper enables a performance analysis of VFMs for semantic\nsegmentation. The findings of such an analysis reveal that pretraining with\npromptable segmentation is not beneficial, whereas masked image modeling (MIM)\nwith abstract representations is crucial, even more important than the type of\nsupervision used. The code for efficiently fine-tuning VFMs for semantic\nsegmentation can be accessed through the project page at:\nhttps://tue-mps.github.io/benchmark-vfm-ss/.",
      "tldr_zh": "这篇论文探讨了如何基准测试视觉基础模型（VFMs）用于语义分割（Semantic Segmentation），以便于模型选择和未来开发。作者通过对各种 VFMs 进行不同设置的监督细调，评估了这些设置对性能排名和训练时间的影响，并推荐使用 ViT-B 变体、16x16 补丁大小和线性解码器，这能代表更大模型、更先进解码器和更小补丁大小，同时将训练时间减少超过13倍。论文还建议采用多个数据集进行训练和评估，因为性能排名会因数据集和领域转移而变化；此外，不推荐线性探测（Linear Probing），并发现掩码图像建模（MIM）使用抽象表示比预训练的提示式分割更重要。该基准测试框架有助于分析 VFMs 的性能，并提供了相关代码以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024 Workshop Proceedings for the Second Workshop on Foundation\n  Models. v2 updates image normalization preprocessing for linear probing with\n  EVA-02, EVA-02-CLIP, SigLIP, DFN (the impact on end-to-end fine-tuning is\n  negligible; no changes made)",
      "pdf_url": "http://arxiv.org/pdf/2404.12172v2",
      "published_date": "2024-04-18 13:27:29 UTC",
      "updated_date": "2024-06-10 10:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:38:41.145888"
    },
    {
      "arxiv_id": "2404.12168v1",
      "title": "Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization",
      "title_zh": "翻译失败",
      "authors": [
        "Insoo Kim",
        "Jae Seok Choi",
        "Geonseok Seo",
        "Kinam Kwon",
        "Jinwoo Shin",
        "Hyong-Euk Lee"
      ],
      "abstract": "As recent advances in mobile camera technology have enabled the capability to\ncapture high-resolution images, such as 4K images, the demand for an efficient\ndeblurring model handling large motion has increased. In this paper, we\ndiscover that the image residual errors, i.e., blur-sharp pixel differences,\ncan be grouped into some categories according to their motion blur type and how\ncomplex their neighboring pixels are. Inspired by this, we decompose the\ndeblurring (regression) task into blur pixel discretization (pixel-level blur\nclassification) and discrete-to-continuous conversion (regression with blur\nclass map) tasks. Specifically, we generate the discretized image residual\nerrors by identifying the blur pixels and then transform them to a continuous\nform, which is computationally more efficient than naively solving the original\nregression problem with continuous values. Here, we found that the\ndiscretization result, i.e., blur segmentation map, remarkably exhibits visual\nsimilarity with the image residual errors. As a result, our efficient model\nshows comparable performance to state-of-the-art methods in realistic\nbenchmarks, while our method is up to 10 times computationally more efficient.",
      "tldr_zh": "本论文针对移动相机捕获的高分辨率图像（如4K）中的运动模糊问题，提出了一种高效的盲运动去模糊方法，通过对图像残差错误（blur-sharp pixel differences）进行分类和模糊像素离散化（blur pixel discretization）。该方法将去模糊任务分解为像素级模糊分类和离散到连续转换（discrete-to-continuous conversion），从而生成离散化图像残差错误并高效转换为连续形式。实验结果表明，该方法在现实基准上与最先进模型性能相当，但计算效率提高了10倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024 Camera-Ready",
      "pdf_url": "http://arxiv.org/pdf/2404.12168v1",
      "published_date": "2024-04-18 13:22:56 UTC",
      "updated_date": "2024-04-18 13:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:38:52.383252"
    },
    {
      "arxiv_id": "2405.04540v2",
      "title": "Is artificial consciousness achievable? Lessons from the human brain",
      "title_zh": "人工智能意识是否可实现？从人类大脑中吸取的教训",
      "authors": [
        "Michele Farisco",
        "Kathinka Evers",
        "Jean-Pierre Changeux"
      ],
      "abstract": "We here analyse the question of developing artificial consciousness from an\nevolutionary perspective, taking the evolution of the human brain and its\nrelation with consciousness as a reference model. This kind of analysis reveals\nseveral structural and functional features of the human brain that appear to be\nkey for reaching human-like complex conscious experience and that current\nresearch on Artificial Intelligence (AI) should take into account in its\nattempt to develop systems capable of conscious processing. We argue that, even\nif AI is limited in its ability to emulate human consciousness for both\nintrinsic (structural and architectural) and extrinsic (related to the current\nstage of scientific and technological knowledge) reasons, taking inspiration\nfrom those characteristics of the brain that make conscious processing possible\nand/or modulate it, is a potentially promising strategy towards developing\nconscious AI. Also, it is theoretically possible that AI research can develop\npartial or potentially alternative forms of consciousness that is qualitatively\ndifferent from the human, and that may be either more or less sophisticated\ndepending on the perspectives. Therefore, we recommend neuroscience-inspired\ncaution in talking about artificial consciousness: since the use of the same\nword consciousness for humans and AI becomes ambiguous and potentially\nmisleading, we propose to clearly specify what is common and what differs in AI\nconscious processing from full human conscious experience.",
      "tldr_zh": "本论文从进化视角探讨人工意识（artificial consciousness）的可行性，以人类大脑的演化作为参考模型，分析其结构和功能特征，这些特征对复杂意识体验至关重要。研究指出，AI 在内在（结构架构）和外在（科学技术水平）因素的限制下，可能无法完全模拟人类意识，但可以通过借鉴大脑特性来开发部分或替代形式的意识，这些形式可能在复杂性上有所不同。作者建议，AI 研究应谨慎使用“意识”一词，并明确人工意识与人类意识的共同点和差异，以避免歧义。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04540v2",
      "published_date": "2024-04-18 12:59:44 UTC",
      "updated_date": "2024-07-29 17:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:39:02.948252"
    },
    {
      "arxiv_id": "2404.12149v5",
      "title": "AccidentBlip: Agent of Accident Warning based on MA-former",
      "title_zh": "AccidentBlip：基于 MA-former 的事故警告代理",
      "authors": [
        "Yihua Shao",
        "Yeling Xu",
        "Xinwei Long",
        "Siyu Chen",
        "Ziyang Yan",
        "Yang Yang",
        "Haoting Liu",
        "Yan Wang",
        "Hao Tang",
        "Zhen Lei"
      ],
      "abstract": "In complex transportation systems, accurately sensing the surrounding\nenvironment and predicting the risk of potential accidents is crucial. Most\nexisting accident prediction methods are based on temporal neural networks,\nsuch as RNN and LSTM. Recent multimodal fusion approaches improve vehicle\nlocalization through 3D target detection and assess potential risks by\ncalculating inter-vehicle distances. However, these temporal networks and\nmultimodal fusion methods suffer from limited detection robustness and high\neconomic costs. To address these challenges, we propose AccidentBlip, a\nvision-only framework that employs our self-designed Motion Accident\nTransformer (MA-former) to process each frame of video. Unlike conventional\nself-attention mechanisms, MA-former replaces Q-former's self-attention with\ntemporal attention, allowing the query corresponding to the previous frame to\ngenerate the query input for the next frame. Additionally, we introduce a\nresidual module connection between queries of consecutive frames to enhance the\nmodel's temporal processing capabilities. For complex V2V and V2X scenarios,\nAccidentBlip adapts by concatenating queries from multiple cameras, effectively\ncapturing spatial and temporal relationships. In particular, AccidentBlip\nachieves SOTA performance in both accident detection and prediction tasks on\nthe DeepAccident dataset. It also outperforms current SOTA methods in V2V and\nV2X scenarios, demonstrating a superior capability to understand complex\nreal-world environments.",
      "tldr_zh": "本研究针对复杂交通系统中事故预测的鲁棒性和经济成本问题，提出了一种基于视觉的框架AccidentBlip，利用自设计的Motion Accident Transformer (MA-former)处理视频帧。MA-former通过替换传统自注意力机制为时间注意力，并添加查询之间的残差模块连接，提升了模型对连续帧的时间处理能力，同时支持多摄像头查询拼接以适应V2V和V2X场景。实验结果显示，AccidentBlip在DeepAccident数据集上实现了SOTA性能，在事故检测和预测任务中超越现有方法，展示了其在真实复杂环境中的优越理解能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12149v5",
      "published_date": "2024-04-18 12:54:25 UTC",
      "updated_date": "2025-01-28 02:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:39:14.970184"
    },
    {
      "arxiv_id": "2404.12145v1",
      "title": "From Form(s) to Meaning: Probing the Semantic Depths of Language Models Using Multisense Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Xenia Ohmer",
        "Elia Bruni",
        "Dieuwke Hupkes"
      ],
      "abstract": "The staggering pace with which the capabilities of large language models\n(LLMs) are increasing, as measured by a range of commonly used natural language\nunderstanding (NLU) benchmarks, raises many questions regarding what\n\"understanding\" means for a language model and how it compares to human\nunderstanding. This is especially true since many LLMs are exclusively trained\non text, casting doubt on whether their stellar benchmark performances are\nreflective of a true understanding of the problems represented by these\nbenchmarks, or whether LLMs simply excel at uttering textual forms that\ncorrelate with what someone who understands the problem would say. In this\nphilosophically inspired work, we aim to create some separation between form\nand meaning, with a series of tests that leverage the idea that world\nunderstanding should be consistent across presentational modes - inspired by\nFregean senses - of the same meaning. Specifically, we focus on consistency\nacross languages as well as paraphrases. Taking GPT-3.5 as our object of study,\nwe evaluate multisense consistency across five different languages and various\ntasks. We start the evaluation in a controlled setting, asking the model for\nsimple facts, and then proceed with an evaluation on four popular NLU\nbenchmarks. We find that the model's multisense consistency is lacking and run\nseveral follow-up analyses to verify that this lack of consistency is due to a\nsense-dependent task understanding. We conclude that, in this aspect, the\nunderstanding of LLMs is still quite far from being consistent and human-like,\nand deliberate on how this impacts their utility in the context of learning\nabout human language and understanding.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否真正理解语言意义，而非仅停留在形式层面，通过引入 multisense consistency 的概念来评估模型的跨语言和改述一致性。研究者以 GPT-3.5 为对象，设计了一系列测试，从简单事实查询到四个流行 NLU benchmarks，检验模型在五种不同语言下的表现。结果显示，模型的多感一致性不足，这表明其任务理解依赖于表达方式，与人类理解存在显著差距。最终，论文强调这种局限性会影响 LLMs 在学习人类语言和理解方面的实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12145v1",
      "published_date": "2024-04-18 12:48:17 UTC",
      "updated_date": "2024-04-18 12:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:39:28.056846"
    },
    {
      "arxiv_id": "2404.12143v1",
      "title": "The Neutrality Fallacy: When Algorithmic Fairness Interventions are (Not) Positive Action",
      "title_zh": "中立谬误：算法公平干预何时（不）构成积极行动",
      "authors": [
        "Hilde Weerts",
        "Raphaële Xenidis",
        "Fabien Tarissan",
        "Henrik Palmer Olsen",
        "Mykola Pechenizkiy"
      ],
      "abstract": "Various metrics and interventions have been developed to identify and\nmitigate unfair outputs of machine learning systems. While individuals and\norganizations have an obligation to avoid discrimination, the use of\nfairness-aware machine learning interventions has also been described as\namounting to 'algorithmic positive action' under European Union (EU)\nnon-discrimination law. As the Court of Justice of the European Union has been\nstrict when it comes to assessing the lawfulness of positive action, this would\nimpose a significant legal burden on those wishing to implement fair-ml\ninterventions. In this paper, we propose that algorithmic fairness\ninterventions often should be interpreted as a means to prevent discrimination,\nrather than a measure of positive action. Specifically, we suggest that this\ncategory mistake can often be attributed to neutrality fallacies: faulty\nassumptions regarding the neutrality of fairness-aware algorithmic\ndecision-making. Our findings raise the question of whether a negative\nobligation to refrain from discrimination is sufficient in the context of\nalgorithmic decision-making. Consequently, we suggest moving away from a duty\nto 'not do harm' towards a positive obligation to actively 'do no harm' as a\nmore adequate framework for algorithmic decision-making and fair\nml-interventions.",
      "tldr_zh": "这篇论文探讨了算法公平性干预（algorithmic fairness interventions）在欧盟（EU）非歧视法下的法律解读，指出这些干预通常被错误地视为积极行动（positive action），而实际上是为了防止歧视。论文引入中性谬误（neutrality fallacies）的概念，揭示了人们对算法决策中立性的错误假设，从而导致了对干预措施的误分类。主要贡献在于建议将算法决策框架从单纯的消极义务（refrain from discrimination）转向积极义务（actively 'do no harm'），以更有效地确保公平性和合规性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12143v1",
      "published_date": "2024-04-18 12:44:35 UTC",
      "updated_date": "2024-04-18 12:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:39:40.363876"
    },
    {
      "arxiv_id": "2404.12138v2",
      "title": "Character is Destiny: Can Role-Playing Language Agents Make Persona-Driven Decisions?",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Xu",
        "Xintao Wang",
        "Jiangjie Chen",
        "Siyu Yuan",
        "Xinfeng Yuan",
        "Jiaqing Liang",
        "Zulong Chen",
        "Xiaoqing Dong",
        "Yanghua Xiao"
      ],
      "abstract": "Can Large Language Models (LLMs) simulate humans in making important\ndecisions? Recent research has unveiled the potential of using LLMs to develop\nrole-playing language agents (RPLAs), mimicking mainly the knowledge and tones\nof various characters. However, imitative decision-making necessitates a more\nnuanced understanding of personas. In this paper, we benchmark the ability of\nLLMs in persona-driven decision-making. Specifically, we investigate whether\nLLMs can predict characters' decisions provided by the preceding stories in\nhigh-quality novels. Leveraging character analyses written by literary experts,\nwe construct a dataset LIFECHOICE comprising 1,462 characters' decision points\nfrom 388 books. Then, we conduct comprehensive experiments on LIFECHOICE, with\nvarious LLMs and RPLA methodologies. The results demonstrate that\nstate-of-the-art LLMs exhibit promising capabilities in this task, yet\nsubstantial room for improvement remains. Hence, we further propose the CHARMAP\nmethod, which adopts persona-based memory retrieval and significantly advances\nRPLAs on this task, achieving 5.03% increase in accuracy.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能通过角色扮演语言代理 (RPLAs) 模拟人类在基于角色的决策中表现。研究者构建了 LIFECHOICE 数据集，包含从 388 本小说中提取的 1,462 个角色决策点，并利用各种 LLMs 和 RPLA 方法进行基准测试，结果显示先进 LLMs 在此任务中表现出色，但仍有改进空间。为提升性能，论文提出 CHARMAP 方法，该方法采用基于角色的记忆检索技术，使准确率提高 5.03%。这项工作为 LLMs 在个性化决策模拟方面提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12138v2",
      "published_date": "2024-04-18 12:40:59 UTC",
      "updated_date": "2024-11-18 11:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:39:51.360793"
    },
    {
      "arxiv_id": "2404.12134v1",
      "title": "Warped Time Series Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Charlotte Lacoquelle",
        "Xavier Pucel",
        "Louise Travé-Massuyès",
        "Axel Reymonet",
        "Benoît Enaux"
      ],
      "abstract": "This paper addresses the problem of detecting time series outliers, focusing\non systems with repetitive behavior, such as industrial robots operating on\nproduction lines.Notable challenges arise from the fact that a task performed\nmultiple times may exhibit different duration in each repetition and that the\ntime series reported by the sensors are irregularly sampled because of data\ngaps. The anomaly detection approach presented in this paper consists of three\nstages.The first stage identifies the repetitive cycles in the lengthy time\nseries and segments them into individual time series corresponding to one task\ncycle, while accounting for possible temporal distortions.The second stage\ncomputes a prototype for the cycles using a GPU-based barycenter algorithm,\nspecifically tailored for very large time series.The third stage uses the\nprototype to detect abnormal cycles by computing an anomaly score for each\ncycle.The overall approach, named WarpEd Time Series ANomaly Detection\n(WETSAND), makes use of the Dynamic Time Warping algorithm and its variants\nbecause they are suited to the distorted nature of the time series.The\nexperiments show that \\wetsand scales to large signals, computes human-friendly\nprototypes, works with very little data, and outperforms some general purpose\nanomaly detection approaches such as autoencoders.",
      "tldr_zh": "这篇论文针对重复行为系统（如工业机器人）的异常检测问题，提出了一种名为WETSAND的方法，用于处理时间序列中的时间扭曲和不规则采样。该方法包括三个阶段：首先识别并分割重复周期；其次使用GPU-based barycenter算法计算周期原型；最后基于原型计算每个周期的异常分数，并利用Dynamic Time Warping算法及其变体来适应序列变形。实验结果显示，WETSAND适用于大型信号，能够生成用户友好的原型，仅需少量数据，且在性能上优于autoencoders等通用异常检测方法。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12134v1",
      "published_date": "2024-04-18 12:35:24 UTC",
      "updated_date": "2024-04-18 12:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:40:05.042736"
    },
    {
      "arxiv_id": "2404.12127v2",
      "title": "Personalized Forgetting Mechanism with Concept-Driven Knowledge Tracing",
      "title_zh": "概念驱动的个性化遗忘机制知识追踪",
      "authors": [
        "Shanshan Wang",
        "Ying Hu",
        "Xun Yang",
        "Zhongzhou Zhang",
        "Keyang Wang",
        "Xingyi Zhang"
      ],
      "abstract": "Knowledge Tracing (KT) aims to trace changes in students' knowledge states\nthroughout their entire learning process by analyzing their historical learning\ndata and predicting their future learning performance. Existing forgetting\ncurve theory based knowledge tracing models only consider the general\nforgetting caused by time intervals, ignoring the individualization of students\nand the causal relationship of the forgetting process. To address these\nproblems, we propose a Concept-driven Personalized Forgetting knowledge tracing\nmodel (CPF) which integrates hierarchical relationships between knowledge\nconcepts and incorporates students' personalized cognitive abilities. First, we\nintegrate the students' personalized capabilities into both the learning and\nforgetting processes to explicitly distinguish students' individual learning\ngains and forgetting rates according to their cognitive abilities. Second, we\ntake into account the hierarchical relationships between knowledge points and\ndesign a precursor-successor knowledge concept matrix to simulate the causal\nrelationship in the forgetting process, while also integrating the potential\nimpact of forgetting prior knowledge points on subsequent ones. The proposed\npersonalized forgetting mechanism can not only be applied to the learning of\nspecifc knowledge concepts but also the life-long learning process. Extensive\nexperimental results on three public datasets show that our CPF outperforms\ncurrent forgetting curve theory based methods in predicting student\nperformance, demonstrating CPF can better simulate changes in students'\nknowledge status through the personalized forgetting mechanism.",
      "tldr_zh": "本研究针对现有 Knowledge Tracing (KT) 模型的局限性，提出了一种 Concept-driven Personalized Forgetting (CPF) 模型，以更好地追踪学生知识状态变化。CPF 通过整合学生的个性化认知能力，将其应用到学习和遗忘过程，区分个体差异的学习收益和遗忘率；同时，设计前驱-后继知识概念矩阵来模拟知识点之间的层次关系和遗忘因果关系。实验结果显示，在三个公共数据集上，CPF 在预测学生表现方面优于传统遗忘曲线理论方法，证明了其在模拟学生知识动态方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2404.12127v2",
      "published_date": "2024-04-18 12:28:50 UTC",
      "updated_date": "2024-04-25 13:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:40:16.917157"
    },
    {
      "arxiv_id": "2404.12125v1",
      "title": "Intelligence Education made in Europe",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Berger",
        "Uwe M. Borghoff",
        "Gerhard Conrad",
        "Stefan Pickl"
      ],
      "abstract": "Global conflicts and trouble spots have thrown the world into turmoil.\nIntelligence services have never been as necessary as they are today when it\ncomes to providing political decision-makers with concrete, accurate, and\nup-to-date decision-making knowledge. This requires a common co-operation, a\ncommon working language and a common understanding of each other. The best way\nto create this \"intelligence community\" is through a harmonized intelligence\neducation.\n  In this paper, we show how joint intelligence education can succeed. We draw\non the experience of Germany, where all intelligence services and the\nBundeswehr are academically educated together in a single degree program that\nlays the foundations for a common working language. We also show how these\nexperiences have been successfully transferred to a European level, namely to\nICE, the Intelligence College in Europe. Our experience has shown that three\naspects are particularly important: firstly, interdisciplinarity or better,\ntransdisciplinarity, secondly, the integration of IT knowhow and thirdly, the\ndevelopment and learning of methodological skills. Using the example of the\ncyber intelligence module with a special focus on data-driven decision support,\nadditionally with its many points of reference to numerous other academic\nmodules, we show how the specific analytic methodology presented is embedded in\nour specific European teaching context.",
      "tldr_zh": "该论文探讨了在全球冲突背景下，协调的情报教育（harmonized intelligence education）如何促进情报服务之间的合作、共同语言和相互理解，以支持决策者。作者借鉴德国的经验，其中所有情报服务和军队通过单一学位课程进行联合学术教育，并成功扩展到欧洲层面，即Intelligence College in Europe (ICE)。关键方面包括transdisciplinarity、IT knowhow的整合以及方法技能（methodological skills）的培养；论文以cyber intelligence模块为例，展示其在数据驱动决策支持（data-driven decision support）中的应用，并强调这种方法在欧洲教学语境中的嵌入。总的来说，该研究为构建统一的“情报社区”提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 2 figures. No potential conflict of interest was reported\n  by the authors",
      "pdf_url": "http://arxiv.org/pdf/2404.12125v1",
      "published_date": "2024-04-18 12:25:46 UTC",
      "updated_date": "2024-04-18 12:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:40:28.715039"
    },
    {
      "arxiv_id": "2404.12120v2",
      "title": "Fortify the Guardian, Not the Treasure: Resilient Adversarial Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Raz Lapid",
        "Almog Dubin",
        "Moshe Sipper"
      ],
      "abstract": "This paper presents RADAR-Robust Adversarial Detection via Adversarial\nRetraining-an approach designed to enhance the robustness of adversarial\ndetectors against adaptive attacks, while maintaining classifier performance.\nAn adaptive attack is one where the attacker is aware of the defenses and\nadapts their strategy accordingly. Our proposed method leverages adversarial\ntraining to reinforce the ability to detect attacks, without compromising clean\naccuracy. During the training phase, we integrate into the dataset adversarial\nexamples, which were optimized to fool both the classifier and the adversarial\ndetector, enabling the adversarial detector to learn and adapt to potential\nattack scenarios. Experimental evaluations on the CIFAR-10 and SVHN datasets\ndemonstrate that our proposed algorithm significantly improves a detector's\nability to accurately identify adaptive adversarial attacks -- without\nsacrificing clean accuracy.",
      "tldr_zh": "本文提出 RADAR-Robust Adversarial Detection via Adversarial Retraining 方法，旨在增强对抗检测器的鲁棒性，使其能有效抵御 adaptive attacks，同时保持分类器的性能。RADAR 通过 adversarial training 将针对分类器和检测器优化的对抗样本整合到训练数据中，帮助检测器学习适应潜在攻击场景。在 CIFAR-10 和 SVHN 数据集上的实验表明，该方法显著提高了准确识别 adaptive adversarial attacks 的能力，而不牺牲 clean accuracy。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12120v2",
      "published_date": "2024-04-18 12:13:09 UTC",
      "updated_date": "2024-06-30 15:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:40:40.557197"
    },
    {
      "arxiv_id": "2404.12090v3",
      "title": "X-Light: Cross-City Traffic Signal Control Using Transformer on Transformer as Meta Multi-Agent Reinforcement Learner",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyuan Jiang",
        "Ziyue Li",
        "Hua Wei",
        "Xuantang Xiong",
        "Jingqing Ruan",
        "Jiaming Lu",
        "Hangyu Mao",
        "Rui Zhao"
      ],
      "abstract": "The effectiveness of traffic light control has been significantly improved by\ncurrent reinforcement learning-based approaches via better cooperation among\nmultiple traffic lights. However, a persisting issue remains: how to obtain a\nmulti-agent traffic signal control algorithm with remarkable transferability\nacross diverse cities? In this paper, we propose a Transformer on Transformer\n(TonT) model for cross-city meta multi-agent traffic signal control, named as\nX-Light: We input the full Markov Decision Process trajectories, and the Lower\nTransformer aggregates the states, actions, rewards among the target\nintersection and its neighbors within a city, and the Upper Transformer learns\nthe general decision trajectories across different cities. This dual-level\napproach bolsters the model's robust generalization and transferability.\nNotably, when directly transferring to unseen scenarios, ours surpasses all\nbaseline methods with +7.91% on average, and even +16.3% in some cases,\nyielding the best results.",
      "tldr_zh": "本研究针对多智能体强化学习在交通信号控制中的跨城市转移问题，提出X-Light框架，使用Transformer on Transformer (TonT)作为元学习器。框架包括Lower Transformer，用于聚合目标路口及其邻居的状态、动作和奖励，以及Upper Transformer，用于学习不同城市间的通用决策轨迹，从而提升模型的泛化和转移能力。在实验中，X-Light直接应用于未见场景时，比基线方法平均提高7.91%的性能，在某些情况下甚至达到16.3%的提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12090v3",
      "published_date": "2024-04-18 11:17:58 UTC",
      "updated_date": "2024-06-17 09:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:40:51.761043"
    },
    {
      "arxiv_id": "2404.12077v1",
      "title": "TIMIT Speaker Profiling: A Comparison of Multi-task learning and Single-task learning Approaches",
      "title_zh": "TIMIT 说话者剖析：多任务学习与单任务学习方法的比较",
      "authors": [
        "Rong Wang",
        "Kun Sun"
      ],
      "abstract": "This study employs deep learning techniques to explore four speaker profiling\ntasks on the TIMIT dataset, namely gender classification, accent\nclassification, age estimation, and speaker identification, highlighting the\npotential and challenges of multi-task learning versus single-task models. The\nmotivation for this research is twofold: firstly, to empirically assess the\nadvantages and drawbacks of multi-task learning over single-task models in the\ncontext of speaker profiling; secondly, to emphasize the undiminished\nsignificance of skillful feature engineering for speaker recognition tasks. The\nfindings reveal challenges in accent classification, and multi-task learning is\nfound advantageous for tasks of similar complexity. Non-sequential features are\nfavored for speaker recognition, but sequential ones can serve as starting\npoints for complex models. The study underscores the necessity of meticulous\nexperimentation and parameter tuning for deep learning models.",
      "tldr_zh": "本研究使用深度学习技术比较多任务学习(multi-task learning)和单任务学习(single-task learning)在 TIMIT 数据集上的四个说话者剖析任务，包括 gender classification、accent classification、age estimation 和 speaker identification。研究动机在于评估多任务学习相对于单任务学习的优势与挑战，并强调特征工程在说话者识别中的重要性。结果显示，accent classification 任务存在显著挑战，而多任务学习在复杂度相似的任务中表现出优势；非序列特征更适合说话者识别，但序列特征可作为复杂模型的起点。该研究突出了深度学习模型中细致实验和参数调整的必要性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12077v1",
      "published_date": "2024-04-18 10:59:54 UTC",
      "updated_date": "2024-04-18 10:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:41:05.264984"
    },
    {
      "arxiv_id": "2404.12076v1",
      "title": "Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting Memory Classifiers in Data Streams",
      "title_zh": "针对数据流中公平感知自",
      "authors": [
        "Pivithuru Thejan Amarasinghe",
        "Diem Pham",
        "Binh Tran",
        "Su Nguyen",
        "Yuan Sun",
        "Damminda Alahakoon"
      ],
      "abstract": "This paper introduces a novel approach, evolutionary multi-objective\noptimisation for fairness-aware self-adjusting memory classifiers, designed to\nenhance fairness in machine learning algorithms applied to data stream\nclassification. With the growing concern over discrimination in algorithmic\ndecision-making, particularly in dynamic data stream environments, there is a\nneed for methods that ensure fair treatment of individuals across sensitive\nattributes like race or gender. The proposed approach addresses this challenge\nby integrating the strengths of the self-adjusting memory K-Nearest-Neighbour\nalgorithm with evolutionary multi-objective optimisation. This combination\nallows the new approach to efficiently manage concept drift in streaming data\nand leverage the flexibility of evolutionary multi-objective optimisation to\nmaximise accuracy and minimise discrimination simultaneously. We demonstrate\nthe effectiveness of the proposed approach through extensive experiments on\nvarious datasets, comparing its performance against several baseline methods in\nterms of accuracy and fairness metrics. Our results show that the proposed\napproach maintains competitive accuracy and significantly reduces\ndiscrimination, highlighting its potential as a robust solution for\nfairness-aware data stream classification. Further analyses also confirm the\neffectiveness of the strategies to trigger evolutionary multi-objective\noptimisation and adapt classifiers in the proposed approach.",
      "tldr_zh": "本论文提出了一种名为“Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting Memory Classifiers”的新方法，旨在提升数据流分类中机器学习算法的公平性，特别是在处理动态环境和敏感属性（如种族或性别）时减少歧视。方法通过整合自调整记忆K-Nearest-Neighbour算法与Evolutionary Multi-Objective Optimisation，实现了对概念漂移的有效管理，同时优化准确性和歧视最小化。实验结果显示，该方法在多种数据集上与基线方法相比，保持了竞争性的准确率并显著降低了歧视，同时验证了触发优化和适应分类器的策略有效性。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted by GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12076v1",
      "published_date": "2024-04-18 10:59:04 UTC",
      "updated_date": "2024-04-18 10:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:41:16.415571"
    },
    {
      "arxiv_id": "2404.12065v2",
      "title": "RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "M. Abdul Khaliq",
        "P. Chang",
        "M. Ma",
        "B. Pflugfelder",
        "F. Miletić"
      ],
      "abstract": "The escalating challenge of misinformation, particularly in political\ndiscourse, requires advanced fact-checking solutions; this is even clearer in\nthe more complex scenario of multimodal claims. We tackle this issue using a\nmultimodal large language model in conjunction with retrieval-augmented\ngeneration (RAG), and introduce two novel reasoning techniques: Chain of RAG\n(CoRAG) and Tree of RAG (ToRAG). They fact-check multimodal claims by\nextracting both textual and image content, retrieving external information, and\nreasoning subsequent questions to be answered based on prior evidence. We\nachieve a weighted F1-score of 0.85, surpassing a baseline reasoning technique\nby 0.14 points. Human evaluation confirms that the vast majority of our\ngenerated fact-check explanations contain all information from gold standard\ndata.",
      "tldr_zh": "该论文提出RAGAR框架，利用Multimodal Large Language Models结合Retrieval-Augmented Generation (RAG)技术，对政治话语中的多模态虚假信息进行事实检查。研究引入两种新推理方法：Chain of RAG (CoRAG)和Tree of RAG (ToRAG)，通过提取文本和图像内容、检索外部信息，并基于先前证据推理后续问题，实现高效的验证过程。实验结果显示，该方法达到0.85的加权F1-score，比基线提升0.14点，且人类评估确认其生成的fact-check解释包含了金标准数据的所有信息。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, submitted to ACL Rolling Review June 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12065v2",
      "published_date": "2024-04-18 10:25:42 UTC",
      "updated_date": "2024-07-11 20:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:41:30.543746"
    },
    {
      "arxiv_id": "2404.12056v1",
      "title": "Deconstructing Human-AI Collaboration: Agency, Interaction, and Adaptation",
      "title_zh": "解构人类-人工智能协作：代理",
      "authors": [
        "Steffen Holter",
        "Mennatallah El-Assady"
      ],
      "abstract": "As full AI-based automation remains out of reach in most real-world\napplications, the focus has instead shifted to leveraging the strengths of both\nhuman and AI agents, creating effective collaborative systems. The rapid\nadvances in this area have yielded increasingly more complex systems and\nframeworks, while the nuance of their characterization has gotten more vague.\nSimilarly, the existing conceptual models no longer capture the elaborate\nprocesses of these systems nor describe the entire scope of their collaboration\nparadigms. In this paper, we propose a new unified set of dimensions through\nwhich to analyze and describe human-AI systems. Our conceptual model is\ncentered around three high-level aspects - agency, interaction, and adaptation\n- and is developed through a multi-step process. Firstly, an initial design\nspace is proposed by surveying the literature and consolidating existing\ndefinitions and conceptual frameworks. Secondly, this model is iteratively\nrefined and validated by conducting semi-structured interviews with nine\nresearchers in this field. Lastly, to illustrate the applicability of our\ndesign space, we utilize it to provide a structured description of selected\nhuman-AI systems.",
      "tldr_zh": "该论文探讨了人类-AI 协作的复杂性，因为全自动化在现实应用中难以实现，转而强调结合双方优势的系统设计。作者提出一个新的统一维度集合，以 agency（代理性）、interaction（交互）和 adaptation（适应）为核心方面，用于分析和描述人类-AI systems。模型通过文献调研整合现有框架、进行九次半结构化访谈迭代完善，并应用于选定系统的结构化描述，提供更全面的协作范式理解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 4 figures. Accepted to Proceedings of EuroVis 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12056v1",
      "published_date": "2024-04-18 10:12:18 UTC",
      "updated_date": "2024-04-18 10:12:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:41:40.277524"
    },
    {
      "arxiv_id": "2404.12045v2",
      "title": "RAM: Towards an Ever-Improving Memory System by Learning from Communications",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Li",
        "Xiaobo Wang",
        "Wentao Ding",
        "Zihao Wang",
        "Yipeng Kang",
        "Zixia Jia",
        "Zilong Zheng"
      ],
      "abstract": "We introduce an innovative RAG-based framework with an ever-improving memory.\nInspired by humans'pedagogical process, RAM utilizes recursively\nreasoning-based retrieval and experience reflections to continually update the\nmemory and learn from users' communicative feedback, namely communicative\nlearning. Extensive experiments with both simulated and real users demonstrate\nsignificant improvements over traditional RAG and self-knowledge methods,\nparticularly excelling in handling false premise and multi-hop questions.\nFurthermore, RAM exhibits promising adaptability to various feedback and\nretrieval methods, showcasing its potential for advancing AI capabilities in\ndynamic knowledge acquisition and lifelong learning.",
      "tldr_zh": "本研究引入了RAM框架，这是一个基于RAG的创新记忆系统，旨在通过递归推理-based检索、经验反思和communicative learning从用户沟通反馈中持续更新和改进记忆。受人类教学过程启发，RAM能够处理复杂的查询，如false premise和multi-hop questions，并在实验中显著优于传统RAG和自知识方法。实验结果显示，在模拟和真实用户场景下，RAM表现出色，并展示了其对各种反馈和检索方法的强大适应性，从而为AI在动态知识获取和终身学习方面的能力提升提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12045v2",
      "published_date": "2024-04-18 09:58:51 UTC",
      "updated_date": "2024-07-05 04:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:41:52.201680"
    },
    {
      "arxiv_id": "2404.12041v2",
      "title": "Can We Catch the Elephant? A Survey of the Evolvement of Hallucination Evaluation on Natural Language Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Siya Qi",
        "Yulan He",
        "Zheng Yuan"
      ],
      "abstract": "Hallucination in Natural Language Generation (NLG) is like the elephant in\nthe room, obvious but often overlooked until recent achievements significantly\nimproved the fluency and grammaticality of generated text. As the capabilities\nof text generation models have improved, researchers have begun to pay more\nattention to the phenomenon of hallucination. Despite significant progress in\nthis field in recent years, the evaluation system for hallucination is complex\nand diverse, lacking clear organization. We are the first to comprehensively\nsurvey how various evaluation methods have evolved with the development of text\ngeneration models from three dimensions, including hallucinated fact\ngranularity, evaluator design principles, and assessment facets. This survey\naims to help researchers identify current limitations in hallucination\nevaluation and highlight future research directions.",
      "tldr_zh": "这篇调查论文探讨了Natural Language Generation (NLG)中hallucination（幻觉）现象的评估演变，强调这种问题虽显而易见却长期被忽视，直到文本生成模型的进步才引起关注。论文首次从hallucinated fact granularity（幻觉事实粒度）、evaluator design principles（评估器设计原则）和assessment facets（评估方面）三个维度，系统整理了各种评估方法的演变过程。最终，它旨在帮助研究者识别现有评估系统的复杂性和局限性，并为未来研究方向提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12041v2",
      "published_date": "2024-04-18 09:52:18 UTC",
      "updated_date": "2024-06-15 22:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:42:05.290733"
    },
    {
      "arxiv_id": "2404.16866v4",
      "title": "Annotation-guided Protein Design with Multi-Level Domain Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Chaohao Yuan",
        "Songyou Li",
        "Geyan Ye",
        "Yikun Zhang",
        "Long-Kai Huang",
        "Wenbing Huang",
        "Wei Liu",
        "Jianhua Yao",
        "Yu Rong"
      ],
      "abstract": "The core challenge of de novo protein design lies in creating proteins with\nspecific functions or properties, guided by certain conditions. Current models\nexplore to generate protein using structural and evolutionary guidance, which\nonly provide indirect conditions concerning functions and properties. However,\ntextual annotations of proteins, especially the annotations for protein\ndomains, which directly describe the protein's high-level functionalities,\nproperties, and their correlation with target amino acid sequences, remain\nunexplored in the context of protein design tasks. In this paper, we propose\nProtein-Annotation Alignment Generation, PAAG, a multi-modality protein design\nframework that integrates the textual annotations extracted from protein\ndatabase for controllable generation in sequence space. Specifically, within a\nmulti-level alignment module, PAAG can explicitly generate proteins containing\nspecific domains conditioned on the corresponding domain annotations, and can\neven design novel proteins with flexible combinations of different kinds of\nannotations. Our experimental results underscore the superiority of the aligned\nprotein representations from PAAG over 7 prediction tasks. Furthermore, PAAG\ndemonstrates a significant increase in generation success rate (24.7% vs 4.7%\nin zinc finger, and 54.3% vs 22.0% in the immunoglobulin domain) in comparison\nto the existing model. We anticipate that PAAG will broaden the horizons of\nprotein design by leveraging the knowledge from between textual annotation and\nproteins.",
      "tldr_zh": "这篇论文针对 de novo protein design 的核心挑战，即在特定条件下创建具有功能或属性的蛋白质，提出了一种多模态框架 Protein-Annotation Alignment Generation (PAAG)。PAAG 通过多级对齐模块整合从蛋白质数据库提取的文本注释，特别是蛋白质域的注释，来实现可控生成，确保生成的蛋白质包含特定域或灵活组合不同注释。实验结果显示，PAAG 在 7 个预测任务中表现出色，并显著提高了生成成功率，例如锌指蛋白从 4.7% 提升到 24.7%，免疫球蛋白域从 22.0% 提升到 54.3%。该框架有望通过文本注释与蛋白质知识的整合，扩展蛋白质设计的应用前景。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Accepted by KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.16866v4",
      "published_date": "2024-04-18 09:37:54 UTC",
      "updated_date": "2024-12-12 07:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:42:19.345778"
    },
    {
      "arxiv_id": "2404.12030v1",
      "title": "Mapping back and forth between model predictive control and neural networks",
      "title_zh": "模型预测控制与神经网络之间的双",
      "authors": [
        "Ross Drummond",
        "Pablo R Baldivieso-Monasterios",
        "Giorgio Valmorbida"
      ],
      "abstract": "Model predictive control (MPC) for linear systems with quadratic costs and\nlinear constraints is shown to admit an exact representation as an implicit\nneural network. A method to \"unravel\" the implicit neural network of MPC into\nan explicit one is also introduced. As well as building links between\nmodel-based and data-driven control, these results emphasize the capability of\nimplicit neural networks for representing solutions of optimisation problems,\nas such problems are themselves implicitly defined functions.",
      "tldr_zh": "该论文证明了模型预测控制 (MPC) 在线性系统、二次成本和线性约束条件下，可以精确表示为隐式神经网络。研究还引入了一种方法，将隐式神经网络“展开”为显式神经网络，从而建立起基于模型的控制和数据驱动控制之间的桥梁。这些发现强调了隐式神经网络在表示优化问题解决方案方面的强大能力，因为这些问题本身是隐式定义的函数。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.12030v1",
      "published_date": "2024-04-18 09:29:08 UTC",
      "updated_date": "2024-04-18 09:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:42:29.092640"
    },
    {
      "arxiv_id": "2404.12023v1",
      "title": "Context-Aware Orchestration of Energy-Efficient Gossip Learning Schemes",
      "title_zh": "翻译失败",
      "authors": [
        "Mina Aghaei Dinani",
        "Adrian Holzer",
        "Hung Nguyen",
        "Marco Ajmone Marsan",
        "Gianluca Rizzo"
      ],
      "abstract": "Fully distributed learning schemes such as Gossip Learning (GL) are gaining\nmomentum due to their scalability and effectiveness even in dynamic settings.\nHowever, they often imply a high utilization of communication and computing\nresources, whose energy footprint may jeopardize the learning process,\nparticularly on battery-operated IoT devices. To address this issue, we present\nOptimized Gossip Learning (OGL)}, a distributed training approach based on the\ncombination of GL with adaptive optimization of the learning process, which\nallows for achieving a target accuracy while minimizing the energy consumption\nof the learning process. We propose a data-driven approach to OGL management\nthat relies on optimizing in real-time for each node the number of training\nepochs and the choice of which model to exchange with neighbors based on\npatterns of node contacts, models' quality, and available resources at each\nnode. Our approach employs a DNN model for dynamic tuning of the aforementioned\nparameters, trained by an infrastructure-based orchestrator function. We\nperformed our assessments on two different datasets, leveraging time-varying\nrandom graphs and a measurement-based dynamic urban scenario. Results suggest\nthat our approach is highly efficient and effective in a broad spectrum of\nnetwork scenarios.",
      "tldr_zh": "本文针对 Gossip Learning (GL) 的高通信和计算资源消耗问题，提出 Optimized Gossip Learning (OGL) 方法，通过结合 GL 与自适应优化，实现目标准确率的同时最小化能源消耗。OGL 采用数据驱动策略，使用 DNN 模型实时调整每个节点的训练周期数和模型交换选择，基于节点联系模式、模型质量以及可用资源。实验结果显示，该方法在不同数据集和动态网络场景（如时间变化的随机图和城市环境）中表现出高效性和有效性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NI",
      "comment": "IEEE AIIOT 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12023v1",
      "published_date": "2024-04-18 09:17:46 UTC",
      "updated_date": "2024-04-18 09:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:42:42.547926"
    },
    {
      "arxiv_id": "2404.12010v1",
      "title": "ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Lasal Jayawardena",
        "Prasan Yapa"
      ],
      "abstract": "Paraphrase generation is a pivotal task in natural language processing (NLP).\nExisting datasets in the domain lack syntactic and lexical diversity, resulting\nin paraphrases that closely resemble the source sentences. Moreover, these\ndatasets often contain hate speech and noise, and may unintentionally include\nnon-English language sentences. This research introduces ParaFusion, a\nlarge-scale, high-quality English paraphrase dataset developed using Large\nLanguage Models (LLM) to address these challenges. ParaFusion augments existing\ndatasets with high-quality data, significantly enhancing both lexical and\nsyntactic diversity while maintaining close semantic similarity. It also\nmitigates the presence of hate speech and reduces noise, ensuring a cleaner and\nmore focused English dataset. Results show that ParaFusion offers at least a\n25% improvement in both syntactic and lexical diversity, measured across\nseveral metrics for each data source. The paper also aims to set a gold\nstandard for paraphrase evaluation as it contains one of the most comprehensive\nevaluation strategies to date. The results underscore the potential of\nParaFusion as a valuable resource for improving NLP applications.",
      "tldr_zh": "本文提出ParaFusion，一种由Large Language Models (LLM)驱动的大规模英语paraphrase数据集，旨在解决现有数据集的lexical和syntactic多样性不足、包含仇恨言论和噪音等问题。ParaFusion通过增强现有数据并优化生成过程，确保paraphrases在保持语义相似性的同时显著提升多样性，并专注于纯英语内容。实验结果显示，该数据集在syntactic和lexical多样性上至少提高了25%，并引入了全面的评估策略，作为NLP应用改进的宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12010v1",
      "published_date": "2024-04-18 09:02:45 UTC",
      "updated_date": "2024-04-18 09:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:42:54.397951"
    },
    {
      "arxiv_id": "2404.12008v6",
      "title": "How Do Recommendation Models Amplify Popularity Bias? An Analysis from the Spectral Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Siyi Lin",
        "Chongming Gao",
        "Jiawei Chen",
        "Sheng Zhou",
        "Binbin Hu",
        "Yan Feng",
        "Chun Chen",
        "Can Wang"
      ],
      "abstract": "Recommendation Systems (RS) are often plagued by popularity bias. When\ntraining a recommendation model on a typically long-tailed dataset, the model\ntends to not only inherit this bias but often exacerbate it, resulting in\nover-representation of popular items in the recommendation lists. This study\nconducts comprehensive empirical and theoretical analyses to expose the root\ncauses of this phenomenon, yielding two core insights: 1) Item popularity is\nmemorized in the principal spectrum of the score matrix predicted by the\nrecommendation model; 2) The dimension collapse phenomenon amplifies the\nrelative prominence of the principal spectrum, thereby intensifying the\npopularity bias. Building on these insights, we propose a novel debiasing\nstrategy that leverages a spectral norm regularizer to penalize the magnitude\nof the principal singular value. We have developed an efficient algorithm to\nexpedite the calculation of the spectral norm by exploiting the spectral\nproperty of the score matrix. Extensive experiments across seven real-world\ndatasets and three testing paradigms have been conducted to validate the\nsuperiority of the proposed method.",
      "tldr_zh": "这篇论文从谱视角分析了推荐系统（RS）如何放大流行度偏差，即在长尾数据集上训练模型时，导致流行物品在推荐列表中过度代表。研究通过实证和理论分析揭示了两个核心洞见：物品流行度被记录在推荐模型预测分数矩阵的主谱中，而维度坍缩现象进一步放大了主谱的相对重要性。作者提出了一种新去偏差策略，使用谱范数正则化来惩罚主奇异值的幅度，并开发了高效算法利用分数矩阵的谱属性加速计算。在七个真实数据集和三种测试范式上的实验验证了该方法的优越性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12008v6",
      "published_date": "2024-04-18 08:59:32 UTC",
      "updated_date": "2025-04-14 17:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:43:06.658688"
    },
    {
      "arxiv_id": "2404.11999v5",
      "title": "Token-level Direct Preference Optimization",
      "title_zh": "标记级别的直接偏好优化",
      "authors": [
        "Yongcheng Zeng",
        "Guoqing Liu",
        "Weiyu Ma",
        "Ning Yang",
        "Haifeng Zhang",
        "Jun Wang"
      ],
      "abstract": "Fine-tuning pre-trained Large Language Models (LLMs) is essential to align\nthem with human values and intentions. This process often utilizes methods like\npairwise comparisons and KL divergence against a reference LLM, focusing on the\nevaluation of full answers generated by the models. However, the generation of\nthese responses occurs in a token level, following a sequential,\nauto-regressive fashion. In this paper, we introduce Token-level Direct\nPreference Optimization (TDPO), a novel approach to align LLMs with human\npreferences by optimizing policy at the token level. Unlike previous methods,\nwhich face challenges in divergence efficiency, TDPO incorporates forward KL\ndivergence constraints for each token, improving alignment and diversity.\nUtilizing the Bradley-Terry model for a token-based reward system, TDPO\nenhances the regulation of KL divergence, while preserving simplicity without\nthe need for explicit reward modeling. Experimental results across various text\ntasks demonstrate TDPO's superior performance in balancing alignment with\ngeneration diversity. Notably, fine-tuning with TDPO strikes a better balance\nthan DPO in the controlled sentiment generation and single-turn dialogue\ndatasets, and significantly improves the quality of generated responses\ncompared to both DPO and PPO-based RLHF methods. Our code is open-sourced at\nhttps://github.com/Vance0124/Token-level-Direct-Preference-Optimization.",
      "tldr_zh": "本研究提出了一种新型方法Token-level Direct Preference Optimization (TDPO)，旨在通过在token级别优化策略来微调Large Language Models (LLMs)，以更好地与人类偏好对齐，同时解决传统方法在生成完整响应时存在的KL divergence效率问题。TDPO利用每个token的前向KL divergence约束和Bradley-Terry模型构建token级奖励系统，实现对齐的提升和生成多样性的保持，而无需显式奖励模型。实验结果显示，TDPO在各种文本任务中优于DPO和PPO-based RLHF方法，尤其在控制情感生成和单轮对话数据集上取得了更好的平衡，并在生成响应质量方面显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11999v5",
      "published_date": "2024-04-18 08:49:38 UTC",
      "updated_date": "2024-08-30 03:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:43:17.527219"
    },
    {
      "arxiv_id": "2404.11996v1",
      "title": "DST-GTN: Dynamic Spatio-Temporal Graph Transformer Network for Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Songtao Huang",
        "Hongjin Song",
        "Tianqi Jiang",
        "Akbar Telikani",
        "Jun Shen",
        "Qingguo Zhou",
        "Binbin Yong",
        "Qiang Wu"
      ],
      "abstract": "Accurate traffic forecasting is essential for effective urban planning and\ncongestion management. Deep learning (DL) approaches have gained colossal\nsuccess in traffic forecasting but still face challenges in capturing the\nintricacies of traffic dynamics. In this paper, we identify and address this\nchallenges by emphasizing that spatial features are inherently dynamic and\nchange over time. A novel in-depth feature representation, called Dynamic\nSpatio-Temporal (Dyn-ST) features, is introduced, which encapsulates spatial\ncharacteristics across varying times. Moreover, a Dynamic Spatio-Temporal Graph\nTransformer Network (DST-GTN) is proposed by capturing Dyn-ST features and\nother dynamic adjacency relations between intersections. The DST-GTN can model\ndynamic ST relationships between nodes accurately and refine the representation\nof global and local ST characteristics by adopting adaptive weights in low-pass\nand all-pass filters, enabling the extraction of Dyn-ST features from traffic\ntime-series data. Through numerical experiments on public datasets, the DST-GTN\nachieves state-of-the-art performance for a range of traffic forecasting tasks\nand demonstrates enhanced stability.",
      "tldr_zh": "这项研究针对交通预测的挑战，强调空间特征的动态变化，引入了Dynamic Spatio-Temporal (Dyn-ST)特征来捕捉不同时间下的空间特性。作者提出了一种Dynamic Spatio-Temporal Graph Transformer Network (DST-GTN)，通过动态邻接关系和适应性权重在低通和全通滤波器中建模节点间的动态时空关系，从而精确提取Dyn-ST特征。实验结果显示，DST-GTN在公共数据集上实现了最先进的性能，并在各种交通预测任务中展现出更高的稳定性和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11996v1",
      "published_date": "2024-04-18 08:44:52 UTC",
      "updated_date": "2024-04-18 08:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:43:28.220025"
    },
    {
      "arxiv_id": "2404.11988v3",
      "title": "The Emerging Generative Artificial Intelligence Divide in the United States",
      "title_zh": "翻译失败",
      "authors": [
        "Madeleine I. G. Daepp",
        "Scott Counts"
      ],
      "abstract": "The digital divide refers to disparities in access to and use of digital\ntooling across social and economic groups. This divide can reinforce\nmarginalization both at the individual level and at the level of places,\nbecause persistent economic advantages accrue to places where new technologies\nare adopted early. To what extent are emerging generative artificial\nintelligence (AI) tools subject to these social and spatial divides? We\nleverage a large-scale search query database to characterize U.S. residents'\nknowledge of a novel generative AI tool, ChatGPT, during its first six months\nof release. We identify hotspots of higher-than-expected search volumes for\nChatGPT in coastal metropolitan areas, while coldspots are evident in the\nAmerican South, Appalachia, and the Midwest. Nationwide, counties with the\nhighest rates of search have proportionally more educated and more economically\nadvantaged populations, as well as proportionally more technology and\nfinance-sector jobs in comparison with other counties or with the national\naverage. Observed associations with race/ethnicity and urbanicity are\nattenuated in fully adjusted hierarchical models, but education emerges as the\nstrongest positive predictor of generative AI awareness. In the absence of\nintervention, early differences in uptake show a potential to reinforce\nexisting spatial and socioeconomic divides.",
      "tldr_zh": "本研究探讨了生成式人工智能（AI）在美国的采用鸿沟，分析了ChatGPT等新兴工具的搜索查询数据，揭示了沿海都市地区搜索量较高，而美国南部、阿巴拉契亚和中西部地区明显较低。结果显示，高教育程度、经济优势以及科技和金融行业密集的县份更可能表现出对生成式 AI 的意识；在调整后模型中，教育是预测因素中最显著的。作者警告，如果缺乏干预，这种早期差异可能加剧现有的社会、经济和空间不平等。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "K.4.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11988v3",
      "published_date": "2024-04-18 08:33:35 UTC",
      "updated_date": "2025-04-18 19:41:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:43:42.326536"
    },
    {
      "arxiv_id": "2404.11973v1",
      "title": "Exploring the landscape of large language models: Foundations, techniques, and challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Moradi",
        "Ke Yan",
        "David Colwell",
        "Matthias Samwald",
        "Rhona Asgari"
      ],
      "abstract": "In this review paper, we delve into the realm of Large Language Models\n(LLMs), covering their foundational principles, diverse applications, and\nnuanced training processes. The article sheds light on the mechanics of\nin-context learning and a spectrum of fine-tuning approaches, with a special\nfocus on methods that optimize efficiency in parameter usage. Additionally, it\nexplores how LLMs can be more closely aligned with human preferences through\ninnovative reinforcement learning frameworks and other novel methods that\nincorporate human feedback. The article also examines the emerging technique of\nretrieval augmented generation, integrating external knowledge into LLMs. The\nethical dimensions of LLM deployment are discussed, underscoring the need for\nmindful and responsible application. Concluding with a perspective on future\nresearch trajectories, this review offers a succinct yet comprehensive overview\nof the current state and emerging trends in the evolving landscape of LLMs,\nserving as an insightful guide for both researchers and practitioners in\nartificial intelligence.",
      "tldr_zh": "这篇评论论文探讨了 Large Language Models (LLMs) 的基础原则、应用和训练过程，包括 in-context learning、各种 fine-tuning 方法以及参数效率优化技术。\n论文重点介绍了通过 reinforcement learning 框架和人类反馈机制来提升 LLMs 与人类偏好对齐，以及 retrieval augmented generation 等创新方法来整合外部知识。\n同时，它分析了 LLMs 部署中的伦理挑战，并为人工智能领域的研究者和从业者提供了未来研究趋势的指导性概述。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11973v1",
      "published_date": "2024-04-18 08:01:20 UTC",
      "updated_date": "2024-04-18 08:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:43:53.434233"
    },
    {
      "arxiv_id": "2404.11964v1",
      "title": "From Language Models to Practical Self-Improving Computer Agents",
      "title_zh": "从语言模型到实用的自我改进计算机代理",
      "authors": [
        "Alex Sheng"
      ],
      "abstract": "We develop a simple and straightforward methodology to create AI computer\nagents that can carry out diverse computer tasks and self-improve by developing\ntools and augmentations to enable themselves to solve increasingly complex\ntasks. As large language models (LLMs) have been shown to benefit from\nnon-parametric augmentations, a significant body of recent work has focused on\ndeveloping software that augments LLMs with various capabilities. Rather than\nmanually developing static software to augment LLMs through human engineering\neffort, we propose that an LLM agent can systematically generate software to\naugment itself. We show, through a few case studies, that a minimal querying\nloop with appropriate prompt engineering allows an LLM to generate and use\nvarious augmentations, freely extending its own capabilities to carry out\nreal-world computer tasks. Starting with only terminal access, we prompt an LLM\nagent to augment itself with retrieval, internet search, web navigation, and\ntext editor capabilities. The agent effectively uses these various tools to\nsolve problems including automated software development and web-based tasks.",
      "tldr_zh": "该论文提出了一种简单方法，使用大型语言模型(LLMs)创建实用的自改进计算机代理，这些代理能执行多样化任务并通过生成工具和增强来提升自身能力。研究者设计了一个最小查询循环结合适当的提示工程(prompt engineering)，让LLM代理系统性地生成软件增强，如检索、互联网搜索、网页导航和文本编辑器，从而扩展其功能。实验案例显示，从仅终端访问开始，该代理成功应用于自动化软件开发和网络任务，证明了LLM代理能自主改进而非依赖人工工程。",
      "categories": [
        "cs.AI",
        "68T01",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11964v1",
      "published_date": "2024-04-18 07:50:10 UTC",
      "updated_date": "2024-04-18 07:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:44:05.062794"
    },
    {
      "arxiv_id": "2404.11962v2",
      "title": "©Plug-in Authorization for Human Content Copyright Protection in Text-to-Image Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Zhou",
        "Huishuai Zhang",
        "Jiang Bian",
        "Weiming Zhang",
        "Nenghai Yu"
      ],
      "abstract": "This paper addresses the contentious issue of copyright infringement in\nimages generated by text-to-image models, sparking debates among AI developers,\ncontent creators, and legal entities. State-of-the-art models create\nhigh-quality content without crediting original creators, causing concern in\nthe artistic community. To mitigate this, we propose the \\copyright Plug-in\nAuthorization framework, introducing three operations: addition, extraction,\nand combination. Addition involves training a \\copyright plug-in for specific\ncopyright, facilitating proper credit attribution. Extraction allows creators\nto reclaim copyright from infringing models, and combination enables users to\nmerge different \\copyright plug-ins. These operations act as permits,\nincentivizing fair use and providing flexibility in authorization. We present\ninnovative approaches,\"Reverse LoRA\" for extraction and \"EasyMerge\" for\nseamless combination. Experiments in artist-style replication and cartoon IP\nrecreation demonstrate \\copyright plug-ins' effectiveness, offering a valuable\nsolution for human copyright protection in the age of generative AIs. The code\nis available at https://github.com/zc1023/-Plug-in-Authorization.git.",
      "tldr_zh": "本研究针对文本到图像模型中生成的图像可能侵犯人类内容版权的问题，提出了一种 \\copyright Plug-in Authorization 框架，以确保原作者获得适当归功。该框架包括三个关键操作：addition（训练特定版权的 \\copyright plug-in）、extraction（允许创作者从侵权模型中收回版权）和combination（合并不同 \\copyright plug-ins），从而促进公平使用和灵活授权。创新方法包括 Reverse LoRA 用于 extraction 操作，以及 EasyMerge 用于无缝组合操作；实验在艺术家风格复制和卡通 IP 再创作场景中验证了框架的有效性，为生成式 AI 时代的人类版权保护提供了实用解决方案。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.11962v2",
      "published_date": "2024-04-18 07:48:00 UTC",
      "updated_date": "2025-01-30 14:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:44:18.329069"
    },
    {
      "arxiv_id": "2404.11960v3",
      "title": "MCRanker: Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers",
      "title_zh": "翻译失败",
      "authors": [
        "Fang Guo",
        "Wenyu Li",
        "Honglei Zhuang",
        "Yun Luo",
        "Yafu Li",
        "Le Yan",
        "Qi Zhu",
        "Yue Zhang"
      ],
      "abstract": "The most recent pointwise Large Language Model (LLM) rankers have achieved\nremarkable ranking results. However, these rankers are hindered by two major\ndrawbacks: (1) they fail to follow a standardized comparison guidance during\nthe ranking process, and (2) they struggle with comprehensive considerations\nwhen dealing with complicated passages. To address these shortcomings, we\npropose to build a ranker that generates ranking scores based on a set of\ncriteria from various perspectives. These criteria are intended to direct each\nperspective in providing a distinct yet synergistic evaluation. Our research,\nwhich examines eight datasets from the BEIR benchmark demonstrates that\nincorporating this multi-perspective criteria ensemble approach markedly\nenhanced the performance of pointwise LLM rankers.",
      "tldr_zh": "本文提出 MCRanker，一种动态生成多视角 criteria 的框架，用于提升 pointwise LLM rankers 的性能，以解决现有模型在缺乏标准化比较指导和处理复杂段落时的不足。MCRanker 通过生成多样化的 criteria，确保每个视角提供独特且协同的评估，从而改善排名过程的全面性和准确性。在 BEIR benchmark 的八个数据集上实验结果显示，这种多视角 criteria 集成方法显著提高了 pointwise LLM rankers 的整体表现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11960v3",
      "published_date": "2024-04-18 07:42:46 UTC",
      "updated_date": "2025-03-25 06:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:44:29.558578"
    },
    {
      "arxiv_id": "2404.11949v1",
      "title": "Sketch-guided Image Inpainting with Partial Discrete Diffusion Process",
      "title_zh": "翻译失败",
      "authors": [
        "Nakul Sharma",
        "Aditay Tripathi",
        "Anirban Chakraborty",
        "Anand Mishra"
      ],
      "abstract": "In this work, we study the task of sketch-guided image inpainting. Unlike the\nwell-explored natural language-guided image inpainting, which excels in\ncapturing semantic details, the relatively less-studied sketch-guided\ninpainting offers greater user control in specifying the object's shape and\npose to be inpainted. As one of the early solutions to this task, we introduce\na novel partial discrete diffusion process (PDDP). The forward pass of the PDDP\ncorrupts the masked regions of the image and the backward pass reconstructs\nthese masked regions conditioned on hand-drawn sketches using our proposed\nsketch-guided bi-directional transformer. The proposed novel transformer module\naccepts two inputs -- the image containing the masked region to be inpainted\nand the query sketch to model the reverse diffusion process. This strategy\neffectively addresses the domain gap between sketches and natural images,\nthereby, enhancing the quality of inpainting results. In the absence of a\nlarge-scale dataset specific to this task, we synthesize a dataset from the\nMS-COCO to train and extensively evaluate our proposed framework against\nvarious competent approaches in the literature. The qualitative and\nquantitative results and user studies establish that the proposed method\ninpaints realistic objects that fit the context in terms of the visual\nappearance of the provided sketch. To aid further research, we have made our\ncode publicly available at https://github.com/vl2g/Sketch-Inpainting .",
      "tldr_zh": "本研究探讨了基于草图的图像修复任务（Sketch-guided Image Inpainting），强调其比自然语言引导方法提供更强的用户控制力，能精确指定对象的形状和姿势。作者提出了一种新颖的Partial Discrete Diffusion Process (PDDP)，其正向过程破坏图像masked区域，反向过程则利用Sketch-guided Bi-directional Transformer重建这些区域，从而解决草图与自然图像的领域差距问题。实验通过从MS-COCO数据集合成的数据进行训练和评估，结果显示该方法在定性和定量指标上优于现有方法，能生成与草图外观相符的真实修复对象；代码已公开以支持进一步研究（https://github.com/vl2g/Sketch-Inpainting）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NTIRE Workshop @ CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.11949v1",
      "published_date": "2024-04-18 07:07:38 UTC",
      "updated_date": "2024-04-18 07:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:44:43.133899"
    },
    {
      "arxiv_id": "2404.11936v1",
      "title": "LD-Pruner: Efficient Pruning of Latent Diffusion Models using Task-Agnostic Insights",
      "title_zh": "LD-Pruner：",
      "authors": [
        "Thibault Castells",
        "Hyoung-Kyu Song",
        "Bo-Kyeong Kim",
        "Shinkook Choi"
      ],
      "abstract": "Latent Diffusion Models (LDMs) have emerged as powerful generative models,\nknown for delivering remarkable results under constrained computational\nresources. However, deploying LDMs on resource-limited devices remains a\ncomplex issue, presenting challenges such as memory consumption and inference\nspeed. To address this issue, we introduce LD-Pruner, a novel\nperformance-preserving structured pruning method for compressing LDMs.\nTraditional pruning methods for deep neural networks are not tailored to the\nunique characteristics of LDMs, such as the high computational cost of training\nand the absence of a fast, straightforward and task-agnostic method for\nevaluating model performance. Our method tackles these challenges by leveraging\nthe latent space during the pruning process, enabling us to effectively\nquantify the impact of pruning on model performance, independently of the task\nat hand. This targeted pruning of components with minimal impact on the output\nallows for faster convergence during training, as the model has less\ninformation to re-learn, thereby addressing the high computational cost of\ntraining. Consequently, our approach achieves a compressed model that offers\nimproved inference speed and reduced parameter count, while maintaining minimal\nperformance degradation. We demonstrate the effectiveness of our approach on\nthree different tasks: text-to-image (T2I) generation, Unconditional Image\nGeneration (UIG) and Unconditional Audio Generation (UAG). Notably, we reduce\nthe inference time of Stable Diffusion (SD) by 34.9% while simultaneously\nimproving its FID by 5.2% on MS-COCO T2I benchmark. This work paves the way for\nmore efficient pruning methods for LDMs, enhancing their applicability.",
      "tldr_zh": "该研究引入了 LD-Pruner，一种高效的结构化剪枝方法，针对 Latent Diffusion Models (LDMs) 的压缩问题，通过利用潜在空间进行任务无关的性能评估，减少了对模型输出影响小的组件，从而加速训练并降低计算成本。\n与传统剪枝方法不同，LD-Pruner 强调任务-agnostic 见解，确保在不依赖特定任务的情况下量化剪枝效果。\n实验结果显示，该方法在文本到图像 (T2I) 生成、无条件图像生成 (UIG) 和无条件音频生成 (UAG) 等任务上，使 Stable Diffusion 的推理时间减少 34.9%，并将 FID 分数改善 5.2%，为 LDMs 的高效部署铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, accepted to CVPR24 First Workshop on Efficient and On-Device\n  Generation (EDGE)",
      "pdf_url": "http://arxiv.org/pdf/2404.11936v1",
      "published_date": "2024-04-18 06:35:37 UTC",
      "updated_date": "2024-04-18 06:35:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:44:56.210610"
    },
    {
      "arxiv_id": "2404.11932v3",
      "title": "CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Geyu Lin",
        "Bin Wang",
        "Zhengyuan Liu",
        "Nancy F. Chen"
      ],
      "abstract": "Multilingual proficiency presents a significant challenge for large language\nmodels (LLMs). English-centric models are usually suboptimal in other\nlanguages, particularly those that are linguistically distant from English.\nThis performance discrepancy mainly stems from the imbalanced distribution of\ntraining data across languages during pre-training and instruction tuning\nstages. To address this problem, we propose a novel approach called CrossIn,\nwhich utilizes a mixed composition of cross-lingual instruction tuning data.\nOur method leverages the compressed representation shared by various languages\nto efficiently enhance the model's task-solving capabilities and multilingual\nproficiency within a single process. In addition, we introduce a multi-task and\nmulti-faceted benchmark to evaluate the effectiveness of CrossIn. Experimental\nresults demonstrate that our method substantially improves performance across\ntasks and languages, and we provide extensive insights into the impact of\ncross-lingual data volume and the integration of translation data on enhancing\nmultilingual consistency and accuracy.",
      "tldr_zh": "这篇论文提出了一种高效的指令微调方法CrossIn，用于解决大型语言模型(LLMs)在多语言能力上的挑战，特别是由于训练数据分布不均衡导致的英语中心模型在其他语言中的表现不佳。CrossIn通过利用混合的跨语言指令微调数据和各种语言共享的压缩表示，在单一过程中提升模型的任务解决能力和多语言熟练度，同时引入了一个多任务多方面的基准进行评估。实验结果显示，该方法显著提高了跨任务和语言的性能，并提供了关于跨语言数据量和翻译数据整合对多语言一致性和准确性的深入见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.11932v3",
      "published_date": "2024-04-18 06:20:50 UTC",
      "updated_date": "2025-01-06 06:33:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:45:05.823147"
    },
    {
      "arxiv_id": "2404.11929v3",
      "title": "A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease With Enhanced Uncertainty Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Walid Abdullah Al",
        "Il Dong Yun",
        "Yun Jung Bae"
      ],
      "abstract": "Dopamine transporter (DAT) imaging is commonly used for monitoring\nParkinson's disease (PD), where striatal DAT uptake amount is computed to\nassess PD severity. However, DAT imaging has a high cost and the risk of\nradiance exposure and is not available in general clinics. Recently, MRI patch\nof the nigral region has been proposed as a safer and easier alternative. This\npaper proposes a symmetric regressor for predicting the DAT uptake amount from\nthe nigral MRI patch. Acknowledging the symmetry between the right and left\nnigrae, the proposed regressor incorporates a paired input-output model that\nsimultaneously predicts the DAT uptake amounts for both the right and left\nstriata. Moreover, it employs a symmetric loss that imposes a constraint on the\ndifference between right-to-left predictions, resembling the high correlation\nin DAT uptake amounts in the two lateral sides. Additionally, we propose a\nsymmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty\nestimate of the DAT uptake prediction, which utilizes the above symmetry. We\nevaluated the proposed approach on 734 nigral patches, which demonstrated\nsignificantly improved performance of the symmetric regressor compared with the\nstandard regressors while giving better explainability and feature\nrepresentation. The symmetric MC dropout also gave precise uncertainty ranges\nwith a high probability of including the true DAT uptake amounts within the\nrange.",
      "tldr_zh": "本研究提出了一种对称回归器（symmetric regressor），用于从MRI的黑质区域（nigral MRI patch）预测帕金森病（PD）患者的纹状体多巴胺转运体（DAT）摄取量，以替代昂贵且涉及辐射风险的DAT成像方法。模型通过paired input-output设计同时预测左右侧DAT摄取量，并引入symmetric loss来约束预测差异，利用左右黑质的对称性提升准确性和特征表示；此外，symmetric Monte-Carlo (MC) dropout方法提供了精确的不确定性估计。实验在734个nigral patches上显示，该回归器比标准模型性能提升显著，并提高了预测的可解释性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11929v3",
      "published_date": "2024-04-18 06:18:48 UTC",
      "updated_date": "2025-04-04 23:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:45:19.996855"
    },
    {
      "arxiv_id": "2404.11925v1",
      "title": "EdgeFusion: On-Device Text-to-Image Generation",
      "title_zh": "EdgeFusion: 设备端文本到图像生成",
      "authors": [
        "Thibault Castells",
        "Hyoung-Kyu Song",
        "Tairen Piao",
        "Shinkook Choi",
        "Bo-Kyeong Kim",
        "Hanyoung Yim",
        "Changgwun Lee",
        "Jae Gon Kim",
        "Tae-Ho Kim"
      ],
      "abstract": "The intensive computational burden of Stable Diffusion (SD) for text-to-image\ngeneration poses a significant hurdle for its practical application. To tackle\nthis challenge, recent research focuses on methods to reduce sampling steps,\nsuch as Latent Consistency Model (LCM), and on employing architectural\noptimizations, including pruning and knowledge distillation. Diverging from\nexisting approaches, we uniquely start with a compact SD variant, BK-SDM. We\nobserve that directly applying LCM to BK-SDM with commonly used crawled\ndatasets yields unsatisfactory results. It leads us to develop two strategies:\n(1) leveraging high-quality image-text pairs from leading generative models and\n(2) designing an advanced distillation process tailored for LCM. Through our\nthorough exploration of quantization, profiling, and on-device deployment, we\nachieve rapid generation of photo-realistic, text-aligned images in just two\nsteps, with latency under one second on resource-limited edge devices.",
      "tldr_zh": "这篇论文提出EdgeFusion方法，针对Stable Diffusion (SD)的计算密集问题，实现文本到图像生成在边缘设备上的高效运行。作者从紧凑的SD变体BK-SDM入手，发现直接应用Latent Consistency Model (LCM)效果不佳，因此开发了两个策略：利用高质量图像-文本对和定制的知识蒸馏过程。最终，通过量化、分析和部署优化，他们实现了仅两步生成逼真且文本对齐的图像，在资源有限的设备上延迟小于一秒。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, accepted to CVPR24 First Workshop on Efficient and On-Device\n  Generation (EDGE)",
      "pdf_url": "http://arxiv.org/pdf/2404.11925v1",
      "published_date": "2024-04-18 06:02:54 UTC",
      "updated_date": "2024-04-18 06:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:45:31.975993"
    },
    {
      "arxiv_id": "2404.11924v1",
      "title": "Toward Short-Term Glucose Prediction Solely Based on CGM Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Cheng",
        "Xingjian Diao",
        "Ziyi Zhou",
        "Yanjun Cui",
        "Wenjun Liu",
        "Shitong Cheng"
      ],
      "abstract": "The global diabetes epidemic highlights the importance of maintaining good\nglycemic control. Glucose prediction is a fundamental aspect of diabetes\nmanagement, facilitating real-time decision-making. Recent research has\nintroduced models focusing on long-term glucose trend prediction, which are\nunsuitable for real-time decision-making and result in delayed responses.\nConversely, models designed to respond to immediate glucose level changes\ncannot analyze glucose variability comprehensively. Moreover, contemporary\nresearch generally integrates various physiological parameters (e.g. insulin\ndoses, food intake, etc.), which inevitably raises data privacy concerns. To\nbridge such a research gap, we propose TimeGlu -- an end-to-end pipeline for\nshort-term glucose prediction solely based on CGM time series data. We\nimplement four baseline methods to conduct a comprehensive comparative analysis\nof the model's performance. Through extensive experiments on two contrasting\ndatasets (CGM Glucose and Colas dataset), TimeGlu achieves state-of-the-art\nperformance without the need for additional personal data from patients,\nproviding effective guidance for real-world diabetic glucose management.",
      "tldr_zh": "该论文针对糖尿病管理的血糖预测问题，指出现有模型要么侧重长期趋势（不适合实时决策），要么仅响应即时变化（无法全面分析变异性），且常整合多种生理参数（如胰岛素剂量）引发数据隐私担忧。作者提出 TimeGlu，一个端到端的管道，仅基于 CGM 时间序列数据进行短期血糖预测，并实现了四个基线方法进行比较分析。在两个数据集（CGM Glucose 和 Colas 数据集）上的广泛实验中，TimeGlu 达到了最先进性能（state-of-the-art），为现实世界糖尿病管理提供有效的隐私友好指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11924v1",
      "published_date": "2024-04-18 06:02:12 UTC",
      "updated_date": "2024-04-18 06:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:45:43.328633"
    },
    {
      "arxiv_id": "2404.11917v2",
      "title": "Expected Coordinate Improvement for High-Dimensional Bayesian Optimization",
      "title_zh": "高维贝叶斯优化的期望坐标改进",
      "authors": [
        "Dawei Zhan"
      ],
      "abstract": "Bayesian optimization (BO) algorithm is very popular for solving\nlow-dimensional expensive optimization problems. Extending Bayesian\noptimization to high dimension is a meaningful but challenging task. One of the\nmajor challenges is that it is difficult to find good infill solutions as the\nacquisition functions are also high-dimensional. In this work, we propose the\nexpected coordinate improvement (ECI) criterion for high-dimensional Bayesian\noptimization. The proposed ECI criterion measures the potential improvement we\ncan get by moving the current best solution along one coordinate. The proposed\napproach selects the coordinate with the highest ECI value to refine in each\niteration and covers all the coordinates gradually by iterating over the\ncoordinates. The greatest advantage of the proposed ECI-BO (expected coordinate\nimprovement based Bayesian optimization) algorithm over the standard BO\nalgorithm is that the infill selection problem of the proposed algorithm is\nalways a one-dimensional problem thus can be easily solved. Numerical\nexperiments show that the proposed algorithm can achieve significantly better\nresults than the standard BO algorithm and competitive results when compared\nwith five state-of-the-art high-dimensional BOs. This work provides a simple\nbut efficient approach for high-dimensional Bayesian optimization.",
      "tldr_zh": "这篇论文针对高维 Bayesian Optimization 的挑战，提出了一种新的 Expected Coordinate Improvement (ECI) 标准，用于评估沿单个坐标移动当前最佳解决方案的潜在改进。ECI-BO 算法在每个迭代中选择 ECI 值最高的坐标进行优化，并逐步覆盖所有坐标，从而将原本高维的 infill 选择问题简化为一维问题，便于高效解决。实验结果表明，ECI-BO 比标准 Bayesian Optimization 算法表现显著更好，并在与五种最先进高维 BO 方法的比较中显示出竞争力，为高维优化提供了一个简单而高效的方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11917v2",
      "published_date": "2024-04-18 05:48:15 UTC",
      "updated_date": "2025-01-10 02:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:45:55.212660"
    },
    {
      "arxiv_id": "2404.11916v2",
      "title": "Skeleton: A New Framework for Accelerating Language Models via Task Neuron Localized Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Nakyeong Yang",
        "Jiwon Moon",
        "Junseok Kim",
        "Yunah Jang",
        "Kyomin Jung"
      ],
      "abstract": "Prompt tuning methods have shown comparable performance to general training\nmethods as parameter-efficient fine-tuning (PEFT) methods in various natural\nlanguage understanding tasks. However, existing prompt tuning methods still\nutilize the entire model architecture even when solving a specific task, which\nprevents them from accelerating inference speed during the application\nprocedure. In this paper, we propose a novel prompt tuning framework called\nSkeleton to efficiently utilize a language model in terms of memory and time\ncomplexity for solving various tasks, retaining only task-relevant neurons by\nusing an explainability method. From our framework, we can efficiently solve\nvarious tasks by using only task-relevant neurons and prepending adequate\ntask-specific prompt tokens with only a single language model. Experiments\nreveal that our method significantly enhances inference efficiency (at most x\n1.73 speed up) for various widely used benchmarks, showing comparable\nperformance to the prompt tuning method. Moreover, our method is applicable\nacross various transformer-based architectures, confirming its practicality and\nscalability.",
      "tldr_zh": "本研究提出了一种新框架Skeleton，通过任务神经元本地化提示调优(Task Neuron Localized Prompt Tuning)来加速语言模型。Skeleton框架利用可解释性方法仅保留任务相关的神经元，并添加特定提示标记，从而显著降低内存和时间复杂度，仅使用单个语言模型即可处理多种任务。实验结果显示，该方法在各种基准测试中实现了最多1.73倍的推理速度提升，同时性能与传统prompt tuning方法相当，且适用于多种基于Transformer的架构。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.11916v2",
      "published_date": "2024-04-18 05:43:50 UTC",
      "updated_date": "2024-10-17 09:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:46:08.109874"
    },
    {
      "arxiv_id": "2404.11907v1",
      "title": "Sampling-based Pareto Optimization for Chance-constrained Monotone Submodular Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Xiankun Yan",
        "Aneta Neumann",
        "Frank Neumann"
      ],
      "abstract": "Recently surrogate functions based on the tail inequalities were developed to\nevaluate the chance constraints in the context of evolutionary computation and\nseveral Pareto optimization algorithms using these surrogates were successfully\napplied in optimizing chance-constrained monotone submodular problems. However,\nthe difference in performance between algorithms using the surrogates and those\nemploying the direct sampling-based evaluation remains unclear. Within the\npaper, a sampling-based method is proposed to directly evaluate the chance\nconstraint. Furthermore, to address the problems with more challenging\nsettings, an enhanced GSEMO algorithm integrated with an adaptive sliding\nwindow, called ASW-GSEMO, is introduced. In the experiments, the ASW-GSEMO\nemploying the sampling-based approach is tested on the chance-constrained\nversion of the maximum coverage problem with different settings. Its results\nare compared with those from other algorithms using different surrogate\nfunctions. The experimental findings indicate that the ASW-GSEMO with the\nsampling-based evaluation approach outperforms other algorithms, highlighting\nthat the performances of algorithms using different evaluation methods are\ncomparable. Additionally, the behaviors of ASW-GSEMO are visualized to explain\nthe distinctions between it and the algorithms utilizing the surrogate\nfunctions.",
      "tldr_zh": "本论文针对机会约束（Chance-constrained）的单调子模函数（Monotone Submodular）问题，提出了一种基于采样的方法来直接评估约束，从而解决现有代理函数方法的性能不确定性。作者引入了增强型GSEMO算法，名为ASW-GSEMO，集成了自适应滑动窗口，以适应更复杂的优化场景。在实验中，ASW-GSEMO在机会约束版本的最大覆盖问题上表现出色，比使用代理函数的其他算法提高了性能，并通过可视化分析解释了其行为差异。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11907v1",
      "published_date": "2024-04-18 05:15:20 UTC",
      "updated_date": "2024-04-18 05:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:46:22.203858"
    },
    {
      "arxiv_id": "2404.11898v1",
      "title": "Enhancing Financial Inclusion and Regulatory Challenges: A Critical Analysis of Digital Banks and Alternative Lenders Through Digital Platforms, Machine Learning, and Large Language Models Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Lee"
      ],
      "abstract": "This paper explores the dual impact of digital banks and alternative lenders\non financial inclusion and the regulatory challenges posed by their business\nmodels. It discusses the integration of digital platforms, machine learning\n(ML), and Large Language Models (LLMs) in enhancing financial services\naccessibility for underserved populations. Through a detailed analysis of\noperational frameworks and technological infrastructures, this research\nidentifies key mechanisms that facilitate broader financial access and mitigate\ntraditional barriers. Additionally, the paper addresses significant regulatory\nconcerns involving data privacy, algorithmic bias, financial stability, and\nconsumer protection. Employing a mixed-methods approach, which combines\nquantitative financial data analysis with qualitative insights from industry\nexperts, this paper elucidates the complexities of leveraging digital\ntechnology to foster financial inclusivity. The findings underscore the\nnecessity of evolving regulatory frameworks that harmonize innovation with\ncomprehensive risk management. This paper concludes with policy recommendations\nfor regulators, financial institutions, and technology providers, aiming to\ncultivate a more inclusive and stable financial ecosystem through prudent\ndigital technology integration.",
      "tldr_zh": "本研究分析了数字银行和替代贷款机构通过整合数字平台、机器学习 (ML) 和大型语言模型 (LLMs) 如何提升金融包容性，同时探讨了其商业模式带来的监管挑战。论文采用混合方法，结合定量金融数据分析和定性行业专家见解，识别了关键机制来扩大金融服务可及性并缓解传统障碍，但也突出了数据隐私、算法偏差、金融稳定和消费者保护等风险。研究结论强调需要演进监管框架以平衡创新与风险管理，并为监管者、金融机构和技术提供者提出政策建议，以构建一个更具包容性和稳定的金融生态系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.11898v1",
      "published_date": "2024-04-18 05:00:53 UTC",
      "updated_date": "2024-04-18 05:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:46:32.601756"
    },
    {
      "arxiv_id": "2404.11891v3",
      "title": "Large Language Models Can Solve Real-World Planning Rigorously with Formal Verification Tools",
      "title_zh": "大语言模型可以通过形式验证工具严格解决真实世界规划问题",
      "authors": [
        "Yilun Hao",
        "Yongchao Chen",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "abstract": "Large Language Models (LLMs) struggle to directly generate correct plans for\ncomplex multi-constraint planning problems, even with self-verification and\nself-critique. For example, a U.S. domestic travel planning benchmark\nTravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI\no1-preview can only find viable travel plans with a 10% success rate given all\nneeded information. In this work, we tackle this by proposing an LLM-based\nplanning framework that formalizes and solves complex multi-constraint planning\nproblems as constrained satisfiability problems, which are further consumed by\nsound and complete satisfiability solvers. We start with TravelPlanner as the\nprimary use case and show that our framework achieves a success rate of 93.9%\nand is effective with diverse paraphrased prompts. More importantly, our\nframework has strong zero-shot generalizability, successfully handling unseen\nconstraints in our newly created unseen international travel dataset and\ngeneralizing well to new fundamentally different domains. Moreover, when user\ninput queries are infeasible, our framework can identify the unsatisfiable\ncore, provide failure reasons, and offers personalized modification\nsuggestions. We show that our framework can modify and solve for an average of\n81.6% and 91.7% unsatisfiable queries from two datasets and prove with\nablations that all key components of our framework are effective and necessary.\nProject page: https://sites.google.com/view/llm-rwplanning.",
      "tldr_zh": "本研究提出了一种基于 Large Language Models (LLMs) 的规划框架，将复杂多约束规划问题形式化为 constrained satisfiability problems，并利用可靠的 satisfiability solvers 进行求解，以解决 LLMs 在直接生成正确计划时的局限性，例如 TravelPlanner 基准测试中成功率仅为 10%。在实验中，该框架在 TravelPlanner 上实现了 93.9% 的成功率，并对多样化的提示表现出色，同时展现出强大的零样本泛化能力，能处理新数据集中的未见约束并扩展到其他领域。当用户查询不可行时，框架能识别 unsatisfiable core，提供失败原因和个性化修改建议，并在两个数据集上成功修改并解决平均 81.6% 和 91.7% 的查询。整体而言，通过消融实验证明了框架关键组件的有效性和必要性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "50 pages, 6 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.11891v3",
      "published_date": "2024-04-18 04:36:37 UTC",
      "updated_date": "2025-01-29 17:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:46:46.733783"
    },
    {
      "arxiv_id": "2404.11888v2",
      "title": "FedEGG: Federated Learning with Explicit Global Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Zhai",
        "Yifeng Gao",
        "Difan Zou",
        "Guangnan Ye",
        "Siheng Chen",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "abstract": "Federated Learning (FL) holds great potential for diverse applications owing\nto its privacy-preserving nature. However, its convergence is often challenged\nby non-IID data distributions, limiting its effectiveness in real-world\ndeployments. Existing methods help address these challenges via\noptimization-based client constraints, adaptive client selection, or the use of\npre-trained models or synthetic data. In this work, we reinterpret these\napproaches as all introducing an \\emph{implicit guiding task} to regularize and\nsteer client learning. Following this insight, we propose to introduce an\n\\emph{explicit global guiding task} into the current FL framework to improve\nconvergence and performance. To this end, we present \\textbf{FedEGG}, a new FL\nalgorithm that constructs a global guiding task using a well-defined,\neasy-to-converge learning task based on a public dataset and Large Language\nModels (LLMs). This approach effectively combines the strengths of federated\n(the original FL task) and centralized (the global guiding task) learning. We\nprovide a theoretical analysis of FedEGG's convergence, examining the impact of\ndata heterogeneity between the guiding and FL tasks and the guiding strength.\nOur analysis derives an upper bound for the optimal guiding strength, offering\npractical insights for implementation. Empirically, FedEGG demonstrates\nsuperior performance over state-of-the-art FL methods under both IID and\nnon-IID settings, and further improves their performances when combined.",
      "tldr_zh": "这项研究针对Federated Learning (FL)中non-IID数据分布导致的收敛挑战，提出了一种新算法FedEGG，通过引入显式全局引导任务(explicit global guiding task)来提升模型性能和收敛速度。FedEGG利用公共数据集和Large Language Models (LLMs)构建一个易收敛的全局引导任务，从而结合联邦学习和集中式学习的优势。理论分析提供了收敛性的上界，并考察了数据异质性和引导强度对系统的影响。实验结果显示，FedEGG在IID和non-IID设置下优于现有FL方法，并能进一步提升它们的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11888v2",
      "published_date": "2024-04-18 04:25:21 UTC",
      "updated_date": "2025-04-20 06:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:46:56.635962"
    },
    {
      "arxiv_id": "2404.11875v2",
      "title": "Concept Induction using LLMs: a user experiment for assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Adrita Barua",
        "Cara Widmer",
        "Pascal Hitzler"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) poses a significant challenge in\nproviding transparent and understandable insights into complex AI models.\nTraditional post-hoc algorithms, while useful, often struggle to deliver\ninterpretable explanations. Concept-based models offer a promising avenue by\nincorporating explicit representations of concepts to enhance interpretability.\nHowever, existing research on automatic concept discovery methods is often\nlimited by lower-level concepts, costly human annotation requirements, and a\nrestricted domain of background knowledge. In this study, we explore the\npotential of a Large Language Model (LLM), specifically GPT-4, by leveraging\nits domain knowledge and common-sense capability to generate high-level\nconcepts that are meaningful as explanations for humans, for a specific setting\nof image classification. We use minimal textual object information available in\nthe data via prompting to facilitate this process. To evaluate the output, we\ncompare the concepts generated by the LLM with two other methods: concepts\ngenerated by humans and the ECII heuristic concept induction system. Since\nthere is no established metric to determine the human understandability of\nconcepts, we conducted a human study to assess the effectiveness of the\nLLM-generated concepts. Our findings indicate that while human-generated\nexplanations remain superior, concepts derived from GPT-4 are more\ncomprehensible to humans compared to those generated by ECII.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Model (LLM) 如 GPT-4 生成高级概念以提升 Explainable Artificial Intelligence (XAI) 的可解释性，针对传统概念发现方法的局限性，如低级概念和人工标注成本。研究方法通过提示利用图像分类数据中的最小文本信息，生成人类友好的概念，并与人类生成的概念以及 ECII 系统生成的概念进行比较。由于缺乏标准评估指标，论文开展了人类实验来评估概念的可理解性。结果显示，GPT-4 生成的概念比 ECII 的更易于人类理解，但仍不如人类生成的解释表现优越。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11875v2",
      "published_date": "2024-04-18 03:22:02 UTC",
      "updated_date": "2024-09-20 20:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:47:08.912998"
    },
    {
      "arxiv_id": "2404.11630v1",
      "title": "SNP: Structured Neuron-level Pruning to Preserve Attention Scores",
      "title_zh": "翻译失败",
      "authors": [
        "Kyunghwan Shim",
        "Jaewoong Yun",
        "Shinkook Choi"
      ],
      "abstract": "Multi-head self-attention (MSA) is a key component of Vision Transformers\n(ViTs), which have achieved great success in various vision tasks. However,\ntheir high computational cost and memory footprint hinder their deployment on\nresource-constrained devices. Conventional pruning approaches can only compress\nand accelerate the MSA module using head pruning, although the head is not an\natomic unit. To address this issue, we propose a novel graph-aware neuron-level\npruning method, Structured Neuron-level Pruning (SNP). SNP prunes neurons with\nless informative attention scores and eliminates redundancy among heads.\nSpecifically, it prunes graphically connected query and key layers having the\nleast informative attention scores while preserving the overall attention\nscores. Value layers, which can be pruned independently, are pruned to\neliminate inter-head redundancy. Our proposed method effectively compresses and\naccelerates Transformer-based models for both edge devices and server\nprocessors. For instance, the DeiT-Small with SNP runs 3.1$\\times$ faster than\nthe original model and achieves performance that is 21.94\\% faster and 1.12\\%\nhigher than the DeiT-Tiny. Additionally, SNP combine successfully with\nconventional head or block pruning approaches. SNP with head pruning could\ncompress the DeiT-Base by 80\\% of the parameters and computational costs and\nachieve 3.85$\\times$ faster inference speed on RTX3090 and 4.93$\\times$ on\nJetson Nano.",
      "tldr_zh": "该论文提出了一种新型剪枝方法Structured Neuron-level Pruning (SNP)，旨在压缩和加速Vision Transformers (ViTs)中的Multi-head Self-Attention (MSA)模块，同时保留注意力分数，以解决传统头剪枝方法的局限性。SNP通过针对图上连接的查询和键层剪枝信息量小的神经元，并独立剪枝值层来消除头间冗余，从而实现高效模型优化。实验结果显示，应用SNP后DeiT-Small模型比原版快3.1倍，且性能优于DeiT-Tiny；此外，与传统头或块剪枝结合时，可将DeiT-Base参数和计算成本压缩80%，在RTX3090上加速3.85倍，在Jetson Nano上加速4.93倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11630v1",
      "published_date": "2024-04-18 03:21:28 UTC",
      "updated_date": "2024-04-18 03:21:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:47:22.253959"
    },
    {
      "arxiv_id": "2404.11874v1",
      "title": "Using a Local Surrogate Model to Interpret Temporal Shifts in Global Annual Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shou Nakano",
        "Yang Liu"
      ],
      "abstract": "This paper focuses on explaining changes over time in globally-sourced,\nannual temporal data, with the specific objective of identifying pivotal\nfactors that contribute to these temporal shifts. Leveraging such analytical\nframeworks can yield transformative impacts, including the informed refinement\nof public policy and the identification of key drivers affecting a country's\neconomic evolution. We employ Local Interpretable Model-agnostic Explanations\n(LIME) to shed light on national happiness indices, economic freedom, and\npopulation metrics, spanning variable time frames. Acknowledging the presence\nof missing values, we employ three imputation approaches to generate robust\nmultivariate time-series datasets apt for LIME's input requirements. Our\nmethodology's efficacy is substantiated through a series of empirical\nevaluations involving multiple datasets. These evaluations include comparative\nanalyses against random feature selection, correlation with real-world events\nas elucidated by LIME, and validation through Individual Conditional\nExpectation (ICE) plots, a state-of-the-art technique proficient in feature\nimportance detection.",
      "tldr_zh": "这篇论文提出了一种使用本地可解释模型无关解释（LIME）来解读全球年度数据中时间变化的方法，旨在识别影响国家幸福指数、经济自由和人口指标的关键因素，从而支持公共政策优化和国家经济演变分析。为处理数据中的缺失值，作者应用了三种插值方法生成适合LIME的多变量时间序列数据集。实验评估通过与随机特征选择比较、真实事件相关性分析以及Individual Conditional Expectation (ICE)图验证，证明了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "There are 9 pages and 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.11874v1",
      "published_date": "2024-04-18 03:17:45 UTC",
      "updated_date": "2024-04-18 03:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:47:33.119404"
    },
    {
      "arxiv_id": "2404.11854v1",
      "title": "SGRU: A High-Performance Structured Gated Recurrent Unit for Traffic Flow Prediction",
      "title_zh": "SGRU",
      "authors": [
        "Wenfeng Zhang",
        "Xin Li",
        "Anqi Li",
        "Xiaoting Huang",
        "Ti Wang",
        "Honglei Gao"
      ],
      "abstract": "Traffic flow prediction is an essential task in constructing smart cities and\nis a typical Multivariate Time Series (MTS) Problem. Recent research has\nabandoned Gated Recurrent Units (GRU) and utilized dilated convolutions or\ntemporal slicing for feature extraction, and they have the following drawbacks:\n(1) Dilated convolutions fail to capture the features of adjacent time steps,\nresulting in the loss of crucial transitional data. (2) The connections within\nthe same temporal slice are strong, while the connections between different\ntemporal slices are too loose. In light of these limitations, we emphasize the\nimportance of analyzing a complete time series repeatedly and the crucial role\nof GRU in MTS. Therefore, we propose SGRU: Structured Gated Recurrent Units,\nwhich involve structured GRU layers and non-linear units, along with multiple\nlayers of time embedding to enhance the model's fitting performance. We\nevaluate our approach on four publicly available California traffic datasets:\nPeMS03, PeMS04, PeMS07, and PeMS08 for regression prediction. Experimental\nresults demonstrate that our model outperforms baseline models with average\nimprovements of 11.7%, 18.6%, 18.5%, and 12.0% respectively.",
      "tldr_zh": "交通流量预测是构建智能城市的关键任务，属于典型的多变量时间序列 (MTS) 问题，但现有基于 dilated convolutions 或 temporal slicing 的方法存在捕获相邻时间步特征不足和不同 temporal slice 连接松散的缺点。针对这些问题，本文提出 SGRU（Structured Gated Recurrent Units），通过整合结构化的 GRU 层、非线性单元以及多层时间嵌入，增强模型对完整时间序列的分析能力。在 PeMS03、PeMS04、PeMS07 和 PeMS08 等加州交通数据集上的实验表明，SGRU 比基线模型平均提高了 11.7% 到 18.6% 的预测性能，为交通预测提供了高效解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 6 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2404.11854v1",
      "published_date": "2024-04-18 02:15:40 UTC",
      "updated_date": "2024-04-18 02:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:47:46.945052"
    },
    {
      "arxiv_id": "2404.11835v2",
      "title": "CAUS: A Dataset for Question Generation based on Human Cognition Leveraging Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minjung Shin",
        "Donghyun Kim",
        "Jeh-Kwang Ryu"
      ],
      "abstract": "We introduce the Curious About Uncertain Scene (CAUS) dataset, designed to\nenable Large Language Models, specifically GPT-4, to emulate human cognitive\nprocesses for resolving uncertainties. Leveraging this dataset, we investigate\nthe potential of LLMs to engage in questioning effectively. Our approach\ninvolves providing scene descriptions embedded with uncertainties to stimulate\nthe generation of reasoning and queries. The queries are then classified\naccording to multi-dimensional criteria. All procedures are facilitated by a\ncollaborative system involving both LLMs and human researchers. Our results\ndemonstrate that GPT-4 can effectively generate pertinent questions and grasp\ntheir nuances, particularly when given appropriate context and instructions.\nThe study suggests that incorporating human-like questioning into AI models\nimproves their ability to manage uncertainties, paving the way for future\nadvancements in Artificial Intelligence (AI).",
      "tldr_zh": "本文介绍了 CAUS 数据集，该数据集旨在利用大型语言模型（如 GPT-4）模拟人类认知过程，以生成基于不确定场景的问题。研究方法涉及提供嵌入不确定性的场景描述，刺激模型生成推理和查询，并通过多维标准分类查询，同时结合 LLMs 与人类研究者的协作系统。结果表明，GPT-4 在适当上下文和指令下，能有效生成相关问题并把握其细微差别，这有助于提升 AI 处理不确定性的能力，并为未来 AI 发展铺平道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures and 3 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2024. This is\n  the final submission",
      "pdf_url": "http://arxiv.org/pdf/2404.11835v2",
      "published_date": "2024-04-18 01:31:19 UTC",
      "updated_date": "2024-05-19 04:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:47:57.010769"
    },
    {
      "arxiv_id": "2404.11833v2",
      "title": "Thought of Search: Planning with Language Models Through The Lens of Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Katz",
        "Harsha Kokel",
        "Kavitha Srinivas",
        "Shirin Sohrabi"
      ],
      "abstract": "Among the most important properties of algorithms investigated in computer\nscience are soundness, completeness, and complexity. These properties, however,\nare rarely analyzed for the vast collection of recently proposed methods for\nplanning with large language models. In this work, we alleviate this gap. We\nanalyse these properties of using LLMs for planning and highlight that recent\ntrends abandon both soundness and completeness for the sake of inefficiency. We\npropose a significantly more efficient approach that can, at the same time,\nmaintain both soundness and completeness. We exemplify on four representative\nsearch problems, comparing to the LLM-based solutions from the literature that\nattempt to solve these problems. We show that by using LLMs to produce the code\nfor the search components we can solve the entire datasets with 100\\% accuracy\nwith only a few calls to the LLM. We argue for a responsible use of compute\nresources; urging research community to investigate sound and complete\nLLM-based approaches that uphold efficiency.",
      "tldr_zh": "该研究分析了使用大型语言模型（LLMs）进行规划的算法属性，包括soundness（正确性）、completeness（完整性）和complexity（复杂度），并指出现有方法往往为了效率而牺牲前两者。作者提出了一种更高效的LLM-based方法，通过让LLMs生成搜索组件的代码，同时保持soundness和completeness，在四个代表性搜索问题上实现了100%的准确率，仅需少量LLM调用。研究呼吁学术界负责任地使用计算资源，优先开发高效且sound、complete的LLM规划方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11833v2",
      "published_date": "2024-04-18 01:27:29 UTC",
      "updated_date": "2024-05-21 18:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:48:10.115142"
    },
    {
      "arxiv_id": "2405.02318v3",
      "title": "Autoformalizing Natural Language to First-Order Logic: A Case Study in Logical Fallacy Detection",
      "title_zh": "自动形式化自然语言至一阶逻辑：逻辑谬误检测的案例研究",
      "authors": [
        "Abhinav Lalwani",
        "Tasha Kim",
        "Lovish Chopra",
        "Christopher Hahn",
        "Zhijing Jin",
        "Mrinmaya Sachan"
      ],
      "abstract": "Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.",
      "tldr_zh": "本研究提出 NL2FOL 框架，使用 Large Language Models (LLMs) 将自然语言逐步转换为 First-Order Logic (FOL)，以解决自动推理和知识验证中的关键挑战，包括整合隐含背景知识。框架通过 Satisfiability Modulo Theory (SMT) 求解器进行逻辑推理，并以逻辑谬误检测作为案例研究，提供可解释的神经符号方法，同时无需模型微调或标记训练数据。实验结果显示，NL2FOL 在 LOGIC 数据集上获得 78% 的 F1-score，在 LOGICCLIMATE 数据集上达到 80%，展现出良好的泛化性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02318v3",
      "published_date": "2024-04-18 00:20:48 UTC",
      "updated_date": "2025-03-06 07:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:48:24.908610"
    },
    {
      "arxiv_id": "2404.11812v1",
      "title": "Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Qing En",
        "Yuhong Guo"
      ],
      "abstract": "Medical image segmentation typically demands extensive dense annotations for\nmodel training, which is both time-consuming and skill-intensive. To mitigate\nthis burden, exemplar-based medical image segmentation methods have been\nintroduced to achieve effective training with only one annotated image. In this\npaper, we introduce a novel Cross-model Mutual learning framework for\nExemplar-based Medical image Segmentation (CMEMS), which leverages two models\nto mutually excavate implicit information from unlabeled data at multiple\ngranularities. CMEMS can eliminate confirmation bias and enable collaborative\ntraining to learn complementary information by enforcing consistency at\ndifferent granularities across models. Concretely, cross-model image\nperturbation based mutual learning is devised by using weakly perturbed images\nto generate high-confidence pseudo-labels, supervising predictions of strongly\nperturbed images across models. This approach enables joint pursuit of\nprediction consistency at the image granularity. Moreover, cross-model\nmulti-level feature perturbation based mutual learning is designed by letting\npseudo-labels supervise predictions from perturbed multi-level features with\ndifferent resolutions, which can broaden the perturbation space and enhance the\nrobustness of our framework. CMEMS is jointly trained using exemplar data,\nsynthetic data, and unlabeled data in an end-to-end manner. Experimental\nresults on two medical image datasets indicate that the proposed CMEMS\noutperforms the state-of-the-art segmentation methods with extremely limited\nsupervision.",
      "tldr_zh": "该论文针对医疗图像分割中标注数据需求过高的问题，提出了一种基于单个标注图像的 CMEMS（Cross-model Mutual Learning）框架，利用两个模型在多个粒度上相互学习，以从无标注数据中挖掘隐含信息。CMEMS 通过跨模型图像扰动机制生成高置信伪标签来监督强扰动图像的预测，并设计跨模型多级特征扰动机制，让伪标签指导不同分辨率特征的预测，从而消除确认偏差并增强模型鲁棒性。该框架采用端到端联合训练，结合示例数据、合成数据和无标注数据，在两个医疗图像数据集上的实验结果表明，CMEMS 超过了最先进的方法，即使在极少监督下也能实现优异性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.11812v1",
      "published_date": "2024-04-18 00:18:07 UTC",
      "updated_date": "2024-04-18 00:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:48:35.255917"
    },
    {
      "arxiv_id": "2404.11811v2",
      "title": "Physics-informed active learning for accelerating quantum chemical simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Fan Hou",
        "Lina Zhang",
        "Quanhao Zhang",
        "Fuchun Ge",
        "Pavlo O. Dral"
      ],
      "abstract": "Quantum chemical simulations can be greatly accelerated by constructing\nmachine learning potentials, which is often done using active learning (AL).\nThe usefulness of the constructed potentials is often limited by the high\neffort required and their insufficient robustness in the simulations. Here we\nintroduce the end-to-end AL for constructing robust data-efficient potentials\nwith affordable investment of time and resources and minimum human\ninterference. Our AL protocol is based on the physics-informed sampling of\ntraining points, automatic selection of initial data, uncertainty\nquantification, and convergence monitoring. The versatility of this protocol is\nshown in our implementation of quasi-classical molecular dynamics for\nsimulating vibrational spectra, conformer search of a key biochemical molecule,\nand time-resolved mechanism of the Diels-Alder reactions. These investigations\ntook us days instead of weeks of pure quantum chemical calculations on a\nhigh-performance computing cluster. The code in MLatom and tutorials are\navailable at https://github.com/dralgroup/mlatom.",
      "tldr_zh": "该研究提出了一种基于物理信息（physics-informed）的主动学习（active learning）协议，用于加速量子化学模拟。该协议通过物理信息采样、自动初始数据选择、不确定性量化（uncertainty quantification）和收敛监控（convergence monitoring）来构建鲁棒且数据高效的机器学习势能，减少了人力干预和计算资源需求。在实际应用中，该方法显著缩短了模拟时间，例如在准经典分子动力学（quasi-classical molecular dynamics）模拟振动谱、生物分子构象搜索和Diels-Alder反应机制的实验中，仅需数天而非数周。代码和教程已在GitHub上公开，展示了该协议的通用性和实用性。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.11811v2",
      "published_date": "2024-04-18 00:17:01 UTC",
      "updated_date": "2024-07-16 07:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T01:48:47.017789"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 94,
  "processed_papers_count": 94,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T01:49:12.433142"
}