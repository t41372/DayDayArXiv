[
  {
    "arxiv_id": "2504.04645v1",
    "title": "Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical Image Segmentation",
    "authors": [
      "Tianyi Ren",
      "Juampablo Heras Rivera",
      "Hitender Oswal",
      "Yutong Pan",
      "Agamdeep Chopra",
      "Jacob Ruzevick",
      "Mehmet Kurt"
    ],
    "abstract": "Deep learning has been successfully applied to medical image segmentation,\nenabling accurate identification of regions of interest such as organs and\nlesions. This approach works effectively across diverse datasets, including\nthose with single-image contrast, multi-contrast, and multimodal imaging data.\nTo improve human understanding of these black-box models, there is a growing\nneed for Explainable AI (XAI) techniques for model transparency and\naccountability. Previous research has primarily focused on post hoc pixel-level\nexplanations, using methods gradient-based and perturbation-based apporaches.\nThese methods rely on gradients or perturbations to explain model predictions.\nHowever, these pixel-level explanations often struggle with the complexity\ninherent in multi-contrast magnetic resonance imaging (MRI) segmentation tasks,\nand the sparsely distributed explanations have limited clinical relevance. In\nthis study, we propose using contrast-level Shapley values to explain\nstate-of-the-art models trained on standard metrics used in brain tumor\nsegmentation. Our results demonstrate that Shapley analysis provides valuable\ninsights into different models' behavior used for tumor segmentation. We\ndemonstrated a bias for U-Net towards over-weighing T1-contrast and FLAIR,\nwhile Swin-UNETR provided a cross-contrast understanding with balanced Shapley\ndistribution.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04645v1",
    "published_date": "2025-04-06 23:52:07 UTC",
    "updated_date": "2025-04-06 23:52:07 UTC"
  },
  {
    "arxiv_id": "2504.04640v1",
    "title": "Splits! A Flexible Dataset for Evaluating a Model's Demographic Social Inference",
    "authors": [
      "Eylon Caplan",
      "Tania Chakraborty",
      "Dan Goldwasser"
    ],
    "abstract": "Understanding how people of various demographics think, feel, and express\nthemselves (collectively called group expression) is essential for social\nscience and underlies the assessment of bias in Large Language Models (LLMs).\nWhile LLMs can effectively summarize group expression when provided with\nempirical examples, coming up with generalizable theories of how a group's\nexpression manifests in real-world text is challenging. In this paper, we\ndefine a new task called Group Theorization, in which a system must write\ntheories that differentiate expression across demographic groups. We make\navailable a large dataset on this task, Splits!, constructed by splitting\nReddit posts by neutral topics (e.g. sports, cooking, and movies) and by\ndemographics (e.g. occupation, religion, and race). Finally, we suggest a\nsimple evaluation framework for assessing how effectively a method can generate\n'better' theories about group expression, backed by human validation. We\npublicly release the raw corpora and evaluation scripts for Splits! to help\nresearchers assess how methods infer--and potentially misrepresent--group\ndifferences in expression. We make Splits! and our evaluation module available\nat https://github.com/eyloncaplan/splits.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review for COLM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04640v1",
    "published_date": "2025-04-06 23:17:07 UTC",
    "updated_date": "2025-04-06 23:17:07 UTC"
  },
  {
    "arxiv_id": "2504.16093v1",
    "title": "Efficient Portfolio Selection through Preference Aggregation with Quicksort and the Bradley--Terry Model",
    "authors": [
      "Yurun Ge",
      "Lucas BÃ¶ttcher",
      "Tom Chou",
      "Maria R. D'Orsogna"
    ],
    "abstract": "How to allocate limited resources to projects that will yield the greatest\nlong-term benefits is a problem that often arises in decision-making under\nuncertainty. For example, organizations may need to evaluate and select\ninnovation projects with risky returns. Similarly, when allocating resources to\nresearch projects, funding agencies are tasked with identifying the most\npromising proposals based on idiosyncratic criteria. Finally, in participatory\nbudgeting, a local community may need to select a subset of public projects to\nfund. Regardless of context, agents must estimate the uncertain values of a\npotentially large number of projects. Developing parsimonious methods to\ncompare these projects, and aggregating agent evaluations so that the overall\nbenefit is maximized, are critical in assembling the best project portfolio.\nUnlike in standard sorting algorithms, evaluating projects on the basis of\nuncertain long-term benefits introduces additional complexities. We propose\ncomparison rules based on Quicksort and the Bradley--Terry model, which\nconnects rankings to pairwise \"win\" probabilities. In our model, each agent\ndetermines win probabilities of a pair of projects based on his or her specific\nevaluation of the projects' long-term benefit. The win probabilities are then\nappropriately aggregated and used to rank projects. Several of the methods we\npropose perform better than the two most effective aggregation methods\ncurrently available. Additionally, our methods can be combined with sampling\ntechniques to significantly reduce the number of pairwise comparisons. We also\ndiscuss how the Bradley--Terry portfolio selection approach can be implemented\nin practice.",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "math.PR",
      "60-08, 90-08",
      "G.3; I.6.1; J.4"
    ],
    "primary_category": "q-fin.PM",
    "comment": "15pp, 4 figs",
    "pdf_url": "http://arxiv.org/pdf/2504.16093v1",
    "published_date": "2025-04-06 23:16:30 UTC",
    "updated_date": "2025-04-06 23:16:30 UTC"
  },
  {
    "arxiv_id": "2504.04634v1",
    "title": "DanceMosaic: High-Fidelity Dance Generation with Multimodal Editability",
    "authors": [
      "Foram Niravbhai Shah",
      "Parshwa Shah",
      "Muhammad Usama Saleem",
      "Ekkasit Pinyoanuntapong",
      "Pu Wang",
      "Hongfei Xue",
      "Ahmed Helmy"
    ],
    "abstract": "Recent advances in dance generation have enabled automatic synthesis of 3D\ndance motions. However, existing methods still struggle to produce\nhigh-fidelity dance sequences that simultaneously deliver exceptional realism,\nprecise dance-music synchronization, high motion diversity, and physical\nplausibility. Moreover, existing methods lack the flexibility to edit dance\nsequences according to diverse guidance signals, such as musical prompts, pose\nconstraints, action labels, and genre descriptions, significantly restricting\ntheir creative utility and adaptability. Unlike the existing approaches,\nDanceMosaic enables fast and high-fidelity dance generation, while allowing\nmultimodal motion editing. Specifically, we propose a multimodal masked motion\nmodel that fuses the text-to-motion model with music and pose adapters to learn\nprobabilistic mapping from diverse guidance signals to high-quality dance\nmotion sequences via progressive generative masking training. To further\nenhance the motion generation quality, we propose multimodal classifier-free\nguidance and inference-time optimization mechanism that further enforce the\nalignment between the generated motions and the multimodal guidance. Extensive\nexperiments demonstrate that our method establishes a new state-of-the-art\nperformance in dance generation, significantly advancing the quality and\neditability achieved by existing approaches.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04634v1",
    "published_date": "2025-04-06 22:05:37 UTC",
    "updated_date": "2025-04-06 22:05:37 UTC"
  },
  {
    "arxiv_id": "2504.04633v1",
    "title": "M2IV: Towards Efficient and Fine-grained Multimodal In-Context Learning in Large Vision-Language Models",
    "authors": [
      "Yanshu Li",
      "Hongyang He",
      "Yi Cao",
      "Qisen Cheng",
      "Xiang Fu",
      "Ruixiang Tang"
    ],
    "abstract": "Multimodal in-context learning (ICL) is a vital capability for Large\nVision-Language Models (LVLMs), allowing task adaptation via contextual prompts\nwithout parameter retraining. However, its application is hindered by the\ntoken-intensive nature of inputs and the high complexity of cross-modal\nfew-shot learning, which limits the expressive power of representation methods.\nTo tackle these challenges, we propose \\textbf{M2IV}, a method that substitutes\nexplicit demonstrations with learnable \\textbf{I}n-context \\textbf{V}ectors\ndirectly integrated into LVLMs. By exploiting the complementary strengths of\nmulti-head attention (\\textbf{M}HA) and multi-layer perceptrons (\\textbf{M}LP),\nM2IV achieves robust cross-modal fidelity and fine-grained semantic\ndistillation through training. This significantly enhances performance across\ndiverse LVLMs and tasks and scales efficiently to many-shot scenarios,\nbypassing the context window limitations. We also introduce \\textbf{VLibrary},\na repository for storing and retrieving M2IV, enabling flexible LVLM steering\nfor tasks like cross-modal alignment, customized generation and safety\nimprovement. Experiments across seven benchmarks and three LVLMs show that M2IV\nsurpasses Vanilla ICL and prior representation engineering approaches, with an\naverage accuracy gain of \\textbf{3.74\\%} over ICL with the same shot count,\nalongside substantial efficiency advantages.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint, 28 pages, 10 figures, 15 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.04633v1",
    "published_date": "2025-04-06 22:02:21 UTC",
    "updated_date": "2025-04-06 22:02:21 UTC"
  },
  {
    "arxiv_id": "2504.04612v1",
    "title": "Tool-as-Interface: Learning Robot Policies from Human Tool Usage through Imitation Learning",
    "authors": [
      "Haonan Chen",
      "Cheng Zhu",
      "Yunzhu Li",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "Tool use is critical for enabling robots to perform complex real-world tasks,\nand leveraging human tool-use data can be instrumental for teaching robots.\nHowever, existing data collection methods like teleoperation are slow, prone to\ncontrol delays, and unsuitable for dynamic tasks. In contrast, human natural\ndata, where humans directly perform tasks with tools, offers natural,\nunstructured interactions that are both efficient and easy to collect. Building\non the insight that humans and robots can share the same tools, we propose a\nframework to transfer tool-use knowledge from human data to robots. Using two\nRGB cameras, our method generates 3D reconstruction, applies Gaussian splatting\nfor novel view augmentation, employs segmentation models to extract\nembodiment-agnostic observations, and leverages task-space tool-action\nrepresentations to train visuomotor policies. We validate our approach on\ndiverse real-world tasks, including meatball scooping, pan flipping, wine\nbottle balancing, and other complex tasks. Our method achieves a 71\\% higher\naverage success rate compared to diffusion policies trained with teleoperation\ndata and reduces data collection time by 77\\%, with some tasks solvable only by\nour framework. Compared to hand-held gripper, our method cuts data collection\ntime by 41\\%. Additionally, our method bridges the embodiment gap, improves\nrobustness to variations in camera viewpoints and robot configurations, and\ngeneralizes effectively across objects and spatial setups.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Page: https://tool-as-interface.github.io. 17 pages, 14\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04612v1",
    "published_date": "2025-04-06 20:40:19 UTC",
    "updated_date": "2025-04-06 20:40:19 UTC"
  },
  {
    "arxiv_id": "2504.04608v1",
    "title": "AI in a vat: Fundamental limits of efficient world modelling for agent sandboxing and interpretability",
    "authors": [
      "Fernando Rosas",
      "Alexander Boyd",
      "Manuel Baltieri"
    ],
    "abstract": "Recent work proposes using world models to generate controlled virtual\nenvironments in which AI agents can be tested before deployment to ensure their\nreliability and safety. However, accurate world models often have high\ncomputational demands that can severely restrict the scope and depth of such\nassessments. Inspired by the classic `brain in a vat' thought experiment, here\nwe investigate ways of simplifying world models that remain agnostic to the AI\nagent under evaluation. By following principles from computational mechanics,\nour approach reveals a fundamental trade-off in world model construction\nbetween efficiency and interpretability, demonstrating that no single world\nmodel can optimise all desirable characteristics. Building on this trade-off,\nwe identify procedures to build world models that either minimise memory\nrequirements, delineate the boundaries of what is learnable, or allow tracking\ncauses of undesirable outcomes. In doing so, this work establishes fundamental\nlimits in world modelling, leading to actionable guidelines that inform core\ndesign choices related to effective agent evaluation.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04608v1",
    "published_date": "2025-04-06 20:35:44 UTC",
    "updated_date": "2025-04-06 20:35:44 UTC"
  },
  {
    "arxiv_id": "2504.04600v1",
    "title": "Capturing AI's Attention: Physics of Repetition, Hallucination, Bias and Beyond",
    "authors": [
      "Frank Yingjie Huo",
      "Neil F. Johnson"
    ],
    "abstract": "We derive a first-principles physics theory of the AI engine at the heart of\nLLMs' 'magic' (e.g. ChatGPT, Claude): the basic Attention head. The theory\nallows a quantitative analysis of outstanding AI challenges such as output\nrepetition, hallucination and harmful content, and bias (e.g. from training and\nfine-tuning). Its predictions are consistent with large-scale LLM outputs. Its\n2-body form suggests why LLMs work so well, but hints that a generalized 3-body\nAttention would make such AI work even better. Its similarity to a spin-bath\nmeans that existing Physics expertise could immediately be harnessed to help\nSociety ensure AI is trustworthy and resilient to manipulation.",
    "categories": [
      "cs.AI",
      "cond-mat.other",
      "math-ph",
      "math.MP",
      "nlin.AO",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Comments welcome to neiljohnson@gwu.edu",
    "pdf_url": "http://arxiv.org/pdf/2504.04600v1",
    "published_date": "2025-04-06 20:10:05 UTC",
    "updated_date": "2025-04-06 20:10:05 UTC"
  },
  {
    "arxiv_id": "2504.04596v1",
    "title": "SECQUE: A Benchmark for Evaluating Real-World Financial Analysis Capabilities",
    "authors": [
      "Noga Ben Yoash",
      "Meni Brief",
      "Oded Ovadia",
      "Gil Shenderovitz",
      "Moshik Mishaeli",
      "Rachel Lemberg",
      "Eitam Sheetrit"
    ],
    "abstract": "We introduce SECQUE, a comprehensive benchmark for evaluating large language\nmodels (LLMs) in financial analysis tasks. SECQUE comprises 565 expert-written\nquestions covering SEC filings analysis across four key categories: comparison\nanalysis, ratio calculation, risk assessment, and financial insight generation.\nTo assess model performance, we develop SECQUE-Judge, an evaluation mechanism\nleveraging multiple LLM-based judges, which demonstrates strong alignment with\nhuman evaluations. Additionally, we provide an extensive analysis of various\nmodels' performance on our benchmark. By making SECQUE publicly available, we\naim to facilitate further research and advancements in financial AI.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Benchmark available at:\n  https://huggingface.co/datasets/nogabenyoash/SecQue",
    "pdf_url": "http://arxiv.org/pdf/2504.04596v1",
    "published_date": "2025-04-06 19:59:41 UTC",
    "updated_date": "2025-04-06 19:59:41 UTC"
  },
  {
    "arxiv_id": "2504.04592v2",
    "title": "\"Trust me on this\" Explaining Agent Behavior to a Human Terminator",
    "authors": [
      "Uri Menkes",
      "Assaf Hallak",
      "Ofra Amir"
    ],
    "abstract": "Consider a setting where a pre-trained agent is operating in an environment\nand a human operator can decide to temporarily terminate its operation and\ntake-over for some duration of time. These kind of scenarios are common in\nhuman-machine interactions, for example in autonomous driving, factory\nautomation and healthcare. In these settings, we typically observe a trade-off\nbetween two extreme cases -- if no take-overs are allowed, then the agent might\nemploy a sub-optimal, possibly dangerous policy. Alternatively, if there are\ntoo many take-overs, then the human has no confidence in the agent, greatly\nlimiting its usefulness. In this paper, we formalize this setup and propose an\nexplainability scheme to help optimize the number of human interventions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "6 pages, 3 figures, in proceedings of ICML 2024 Workshop on Models of\n  Human Feedback for AI Alignment",
    "pdf_url": "http://arxiv.org/pdf/2504.04592v2",
    "published_date": "2025-04-06 19:29:45 UTC",
    "updated_date": "2025-05-05 17:48:40 UTC"
  },
  {
    "arxiv_id": "2504.04582v2",
    "title": "Your Image Generator Is Your New Private Dataset",
    "authors": [
      "Nicolo Resmini",
      "Eugenio Lomurno",
      "Cristian Sbrolli",
      "Matteo Matteucci"
    ],
    "abstract": "Generative diffusion models have emerged as powerful tools to synthetically\nproduce training data, offering potential solutions to data scarcity and\nreducing labelling costs for downstream supervised deep learning applications.\nHowever, effectively leveraging text-conditioned image generation for building\nclassifier training sets requires addressing key issues: constructing\ninformative textual prompts, adapting generative models to specific domains,\nand ensuring robust performance. This paper proposes the Text-Conditioned\nKnowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines\ndynamic image captioning, parameter-efficient diffusion model fine-tuning, and\nGenerative Knowledge Distillation techniques to create synthetic datasets\ntailored for image classification. The pipeline is rigorously evaluated on ten\ndiverse image classification benchmarks. The results demonstrate that models\ntrained solely on TCKR-generated data achieve classification accuracies on par\nwith (and in several cases exceeding) models trained on real images.\nFurthermore, the evaluation reveals that these synthetic-data-trained models\nexhibit substantially enhanced privacy characteristics: their vulnerability to\nMembership Inference Attacks is significantly reduced, with the membership\ninference AUC lowered by 5.49 points on average compared to using real training\ndata, demonstrating a substantial improvement in the performance-privacy\ntrade-off. These findings indicate that high-fidelity synthetic data can\neffectively replace real data for training classifiers, yielding strong\nperformance whilst simultaneously providing improved privacy protection as a\nvaluable emergent property. The code and trained models are available in the\naccompanying open-source repository.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04582v2",
    "published_date": "2025-04-06 18:46:08 UTC",
    "updated_date": "2025-04-08 08:35:53 UTC"
  },
  {
    "arxiv_id": "2504.04578v1",
    "title": "Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification",
    "authors": [
      "Cristina Cornelio",
      "Flavio Petruzzellis",
      "Pietro Lio"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise as robotic planners but often\nstruggle with long-horizon and complex tasks, especially in specialized\nenvironments requiring external knowledge. While hierarchical planning and\nRetrieval-Augmented Generation (RAG) address some of these challenges, they\nremain insufficient on their own and a deeper integration is required for\nachieving more reliable systems. To this end, we propose a neuro-symbolic\napproach that enhances LLMs-based planners with Knowledge Graph-based RAG for\nhierarchical plan generation. This method decomposes complex tasks into\nmanageable subtasks, further expanded into executable atomic action sequences.\nTo ensure formal correctness and proper decomposition, we integrate a Symbolic\nValidator, which also functions as a failure detector by aligning expected and\nobserved world states. Our evaluation against baseline methods demonstrates the\nconsistent significant advantages of integrating hierarchical planning,\nsymbolic verification, and RAG across tasks of varying complexity and different\nLLMs. Additionally, our experimental setup and novel metrics not only validate\nour approach for complex planning but also serve as a tool for assessing LLMs'\nreasoning and compositional capabilities.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04578v1",
    "published_date": "2025-04-06 18:36:30 UTC",
    "updated_date": "2025-04-06 18:36:30 UTC"
  },
  {
    "arxiv_id": "2504.04562v1",
    "title": "Planning Safety Trajectories with Dual-Phase, Physics-Informed, and Transportation Knowledge-Driven Large Language Models",
    "authors": [
      "Rui Gan",
      "Pei Li",
      "Keke Long",
      "Bocheng An",
      "Junwei You",
      "Keshu Wu",
      "Bin Ran"
    ],
    "abstract": "Foundation models have demonstrated strong reasoning and generalization\ncapabilities in driving-related tasks, including scene understanding, planning,\nand control. However, they still face challenges in hallucinations,\nuncertainty, and long inference latency. While existing foundation models have\ngeneral knowledge of avoiding collisions, they often lack\ntransportation-specific safety knowledge. To overcome these limitations, we\nintroduce LetsPi, a physics-informed, dual-phase, knowledge-driven framework\nfor safe, human-like trajectory planning. To prevent hallucinations and\nminimize uncertainty, this hybrid framework integrates Large Language Model\n(LLM) reasoning with physics-informed social force dynamics. LetsPi leverages\nthe LLM to analyze driving scenes and historical information, providing\nappropriate parameters and target destinations (goals) for the social force\nmodel, which then generates the future trajectory. Moreover, the dual-phase\narchitecture balances reasoning and computational efficiency through its Memory\nCollection phase and Fast Inference phase. The Memory Collection phase\nleverages the physics-informed LLM to process and refine planning results\nthrough reasoning, reflection, and memory modules, storing safe, high-quality\ndriving experiences in a memory bank. Surrogate safety measures and\nphysics-informed prompt techniques are introduced to enhance the LLM's\nknowledge of transportation safety and physical force, respectively. The Fast\nInference phase extracts similar driving experiences as few-shot examples for\nnew scenarios, while simplifying input-output requirements to enable rapid\ntrajectory planning without compromising safety. Extensive experiments using\nthe HighD dataset demonstrate that LetsPi outperforms baseline models across\nfive safety metrics.See PDF for project Github link.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04562v1",
    "published_date": "2025-04-06 17:34:33 UTC",
    "updated_date": "2025-04-06 17:34:33 UTC"
  },
  {
    "arxiv_id": "2504.04550v1",
    "title": "Advancing Egocentric Video Question Answering with Multimodal Large Language Models",
    "authors": [
      "Alkesh Patel",
      "Vibhav Chitalia",
      "Yinfei Yang"
    ],
    "abstract": "Egocentric Video Question Answering (QA) requires models to handle\nlong-horizon temporal reasoning, first-person perspectives, and specialized\nchallenges like frequent camera movement. This paper systematically evaluates\nboth proprietary and open-source Multimodal Large Language Models (MLLMs) on\nQaEgo4Dv2 - a refined dataset of egocentric videos derived from QaEgo4D. Four\npopular MLLMs (GPT-4o, Gemini-1.5-Pro, Video-LLaVa-7B and Qwen2-VL-7B-Instruct)\nare assessed using zero-shot and fine-tuned approaches for both OpenQA and\nCloseQA settings. We introduce QaEgo4Dv2 to mitigate annotation noise in\nQaEgo4D, enabling more reliable comparison. Our results show that fine-tuned\nVideo-LLaVa-7B and Qwen2-VL-7B-Instruct achieve new state-of-the-art\nperformance, surpassing previous benchmarks by up to +2.6% ROUGE/METEOR (for\nOpenQA) and +13% accuracy (for CloseQA). We also present a thorough error\nanalysis, indicating the model's difficulty in spatial reasoning and\nfine-grained object recognition - key areas for future improvement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04550v1",
    "published_date": "2025-04-06 16:58:23 UTC",
    "updated_date": "2025-04-06 16:58:23 UTC"
  },
  {
    "arxiv_id": "2504.04540v1",
    "title": "The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models?",
    "authors": [
      "Weichen Zhang",
      "Ruiying Peng",
      "Chen Gao",
      "Jianjie Fang",
      "Xin Zeng",
      "Kaiyuan Li",
      "Ziyou Wang",
      "Jinqiang Cui",
      "Xin Wang",
      "Xinlei Chen",
      "Yong Li"
    ],
    "abstract": "3D Large Language Models (LLMs) leveraging spatial information in point\nclouds for 3D spatial reasoning attract great attention. Despite some promising\nresults, the role of point clouds in 3D spatial reasoning remains\nunder-explored. In this work, we comprehensively evaluate and analyze these\nmodels to answer the research question: \\textit{Does point cloud truly boost\nthe spatial reasoning capacities of 3D LLMs?} We first evaluate the spatial\nreasoning capacity of LLMs with different input modalities by replacing the\npoint cloud with the visual and text counterparts. We then propose a novel 3D\nQA (Question-answering) benchmark, ScanReQA, that comprehensively evaluates\nmodels' understanding of binary spatial relationships. Our findings reveal\nseveral critical insights: 1) LLMs without point input could even achieve\ncompetitive performance even in a zero-shot manner; 2) existing 3D LLMs\nstruggle to comprehend the binary spatial relationships; 3) 3D LLMs exhibit\nlimitations in exploiting the structural coordinates in point clouds for\nfine-grained spatial reasoning. We think these conclusions can help the next\nstep of 3D LLMs and also offer insights for foundation models in other\nmodalities. We release datasets and reproducible codes in the anonymous project\npage: https://3d-llm.xyz.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04540v1",
    "published_date": "2025-04-06 16:38:48 UTC",
    "updated_date": "2025-04-06 16:38:48 UTC"
  },
  {
    "arxiv_id": "2504.04535v1",
    "title": "SnapPix: Efficient-Coding--Inspired In-Sensor Compression for Edge Vision",
    "authors": [
      "Weikai Lin",
      "Tianrui Ma",
      "Adith Boloor",
      "Yu Feng",
      "Ruofan Xing",
      "Xuan Zhang",
      "Yuhao Zhu"
    ],
    "abstract": "Energy-efficient image acquisition on the edge is crucial for enabling remote\nsensing applications where the sensor node has weak compute capabilities and\nmust transmit data to a remote server/cloud for processing. To reduce the edge\nenergy consumption, this paper proposes a sensor-algorithm co-designed system\ncalled SnapPix, which compresses raw pixels in the analog domain inside the\nsensor. We use coded exposure (CE) as the in-sensor compression strategy as it\noffers the flexibility to sample, i.e., selectively expose pixels, both\nspatially and temporally. SNAPPIX has three contributions. First, we propose a\ntask-agnostic strategy to learn the sampling/exposure pattern based on the\nclassic theory of efficient coding. Second, we co-design the downstream vision\nmodel with the exposure pattern to address the pixel-level non-uniformity\nunique to CE-compressed images. Finally, we propose lightweight augmentations\nto the image sensor hardware to support our in-sensor CE compression.\nEvaluating on action recognition and video reconstruction, SnapPix outperforms\nstate-of-the-art video-based methods at the same speed while reducing the\nenergy by up to 15.4x. We have open-sourced the code at:\nhttps://github.com/horizon-research/SnapPix.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, Accepted to Design Automation Conference (DAC), 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04535v1",
    "published_date": "2025-04-06 16:24:45 UTC",
    "updated_date": "2025-04-06 16:24:45 UTC"
  },
  {
    "arxiv_id": "2504.04534v1",
    "title": "An Empirical Comparison of Text Summarization: A Multi-Dimensional Evaluation of Large Language Models",
    "authors": [
      "Anantharaman Janakiraman",
      "Behnaz Ghoraani"
    ],
    "abstract": "Text summarization is crucial for mitigating information overload across\ndomains like journalism, medicine, and business. This research evaluates\nsummarization performance across 17 large language models (OpenAI, Google,\nAnthropic, open-source) using a novel multi-dimensional framework. We assessed\nmodels on seven diverse datasets (BigPatent, BillSum, CNN/DailyMail, PubMed,\nSAMSum, WikiHow, XSum) at three output lengths (50, 100, 150 tokens) using\nmetrics for factual consistency, semantic similarity, lexical overlap, and\nhuman-like quality, while also considering efficiency factors. Our findings\nreveal significant performance differences, with specific models excelling in\nfactual accuracy (deepseek-v3), human-like quality (claude-3-5-sonnet), and\nprocessing efficiency/cost-effectiveness (gemini-1.5-flash, gemini-2.0-flash).\nPerformance varies dramatically by dataset, with models struggling on technical\ndomains but performing well on conversational content. We identified a critical\ntension between factual consistency (best at 50 tokens) and perceived quality\n(best at 150 tokens). Our analysis provides evidence-based recommendations for\ndifferent use cases, from high-stakes applications requiring factual accuracy\nto resource-constrained environments needing efficient processing. This\ncomprehensive approach enhances evaluation methodology by integrating quality\nmetrics with operational considerations, incorporating trade-offs between\naccuracy, efficiency, and cost-effectiveness to guide model selection for\nspecific applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04534v1",
    "published_date": "2025-04-06 16:24:22 UTC",
    "updated_date": "2025-04-06 16:24:22 UTC"
  },
  {
    "arxiv_id": "2504.05350v1",
    "title": "Non-linear Phillips Curve for India: Evidence from Explainable Machine Learning",
    "authors": [
      "Shovon Sengupta",
      "Bhanu Pratap",
      "Amit Pawar"
    ],
    "abstract": "The conventional linear Phillips curve model, while widely used in\npolicymaking, often struggles to deliver accurate forecasts in the presence of\nstructural breaks and inherent nonlinearities. This paper addresses these\nlimitations by leveraging machine learning methods within a New Keynesian\nPhillips Curve framework to forecast and explain headline inflation in India, a\nmajor emerging economy. Our analysis demonstrates that machine learning-based\napproaches significantly outperform standard linear models in forecasting\naccuracy. Moreover, by employing explainable machine learning techniques, we\nreveal that the Phillips curve relationship in India is highly nonlinear,\ncharacterized by thresholds and interaction effects among key variables.\nHeadline inflation is primarily driven by inflation expectations, followed by\npast inflation and the output gap, while supply shocks, except rainfall, exert\nonly a marginal influence. These findings highlight the ability of machine\nlearning models to improve forecast accuracy and uncover complex, nonlinear\ndynamics in inflation data, offering valuable insights for policymakers.",
    "categories": [
      "econ.EM",
      "cs.AI",
      "cs.LG",
      "F.2.2"
    ],
    "primary_category": "econ.EM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05350v1",
    "published_date": "2025-04-06 16:17:36 UTC",
    "updated_date": "2025-04-06 16:17:36 UTC"
  },
  {
    "arxiv_id": "2504.05349v1",
    "title": "Hyperflows: Pruning Reveals the Importance of Weights",
    "authors": [
      "Eugen Barbulescu",
      "Antonio Alexoaie"
    ],
    "abstract": "Network pruning is used to reduce inference latency and power consumption in\nlarge neural networks. However, most existing methods struggle to accurately\nassess the importance of individual weights due to their inherent\ninterrelatedness, leading to poor performance, especially at extreme sparsity\nlevels. We introduce Hyperflows, a dynamic pruning approach that estimates each\nweight's importance by observing the network's gradient response to the\nweight's removal. A global pressure term continuously drives all weights toward\npruning, with those critical for accuracy being automatically regrown based on\ntheir flow, the aggregated gradient signal when they are absent. We explore the\nrelationship between final sparsity and pressure, deriving power-law equations\nsimilar to those found in neural scaling laws. Empirically, we demonstrate\nstate-of-the-art results with ResNet-50 and VGG-19 on CIFAR-10 and CIFAR-100.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05349v1",
    "published_date": "2025-04-06 16:09:18 UTC",
    "updated_date": "2025-04-06 16:09:18 UTC"
  },
  {
    "arxiv_id": "2504.04528v1",
    "title": "A Consequentialist Critique of Binary Classification Evaluation Practices",
    "authors": [
      "Gerardo Flores",
      "Abigail Schiff",
      "Alyssa H. Smith",
      "Julia A Fukuyama",
      "Ashia C. Wilson"
    ],
    "abstract": "ML-supported decisions, such as ordering tests or determining preventive\ncustody, often involve binary classification based on probabilistic forecasts.\nEvaluation frameworks for such forecasts typically consider whether to\nprioritize independent-decision metrics (e.g., Accuracy) or top-K metrics\n(e.g., Precision@K), and whether to focus on fixed thresholds or\nthreshold-agnostic measures like AUC-ROC. We highlight that a consequentialist\nperspective, long advocated by decision theorists, should naturally favor\nevaluations that support independent decisions using a mixture of thresholds\ngiven their prevalence, such as Brier scores and Log loss. However, our\nempirical analysis reveals a strong preference for top-K metrics or fixed\nthresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To\naddress this gap, we use this decision-theoretic framework to map evaluation\nmetrics to their optimal use cases, along with a Python package, briertools, to\npromote the broader adoption of Brier scores. In doing so, we also uncover new\ntheoretical connections, including a reconciliation between the Brier Score and\nDecision Curve Analysis, which clarifies and responds to a longstanding\ncritique by (Assel, et al. 2017) regarding the clinical utility of proper\nscoring rules.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04528v1",
    "published_date": "2025-04-06 15:58:01 UTC",
    "updated_date": "2025-04-06 15:58:01 UTC"
  },
  {
    "arxiv_id": "2504.04524v1",
    "title": "Trust Region Preference Approximation: A simple and stable reinforcement learning algorithm for LLM reasoning",
    "authors": [
      "Xuerui Su",
      "Shufang Xie",
      "Guoqing Liu",
      "Yingce Xia",
      "Renqian Luo",
      "Peiran Jin",
      "Zhiming Ma",
      "Yue Wang",
      "Zun Wang",
      "Yuting Liu"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have rapidly evolved, approaching\nArtificial General Intelligence (AGI) while benefiting from large-scale\nreinforcement learning to enhance Human Alignment (HA) and Reasoning. Recent\nreward-based optimization algorithms, such as Proximal Policy Optimization\n(PPO) and Group Relative Policy Optimization (GRPO) have achieved significant\nperformance on reasoning tasks, whereas preference-based optimization\nalgorithms such as Direct Preference Optimization (DPO) significantly improve\nthe performance of LLMs on human alignment. However, despite the strong\nperformance of reward-based optimization methods in alignment tasks , they\nremain vulnerable to reward hacking. Furthermore, preference-based algorithms\n(such as Online DPO) haven't yet matched the performance of reward-based\noptimization algorithms (like PPO) on reasoning tasks, making their exploration\nin this specific area still a worthwhile pursuit. Motivated by these\nchallenges, we propose the Trust Region Preference Approximation (TRPA)\nalgorithm, which integrates rule-based optimization with preference-based\noptimization for reasoning tasks. As a preference-based algorithm, TRPA\nnaturally eliminates the reward hacking issue. TRPA constructs preference\nlevels using predefined rules, forms corresponding preference pairs, and\nleverages a novel optimization algorithm for RL training with a theoretical\nmonotonic improvement guarantee. Experimental results demonstrate that TRPA not\nonly achieves competitive performance on reasoning tasks but also exhibits\nrobust stability. The code of this paper are released and updating on\nhttps://github.com/XueruiSu/Trust-Region-Preference-Approximation.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04524v1",
    "published_date": "2025-04-06 15:48:26 UTC",
    "updated_date": "2025-04-06 15:48:26 UTC"
  },
  {
    "arxiv_id": "2504.04520v1",
    "title": "Hessian of Perplexity for Large Language Models by PyTorch autograd (Open Source)",
    "authors": [
      "Ivan Ilin"
    ],
    "abstract": "Computing the full Hessian matrix -- the matrix of second-order derivatives\nfor an entire Large Language Model (LLM) is infeasible due to its sheer size.\nIn this technical report, we aim to provide a comprehensive guide on how to\naccurately compute at least a small portion of the Hessian for LLMs using\nPyTorch autograd library. We also demonstrate how to compute the full diagonal\nof the Hessian matrix using multiple samples of vector-Hessian Products (HVPs).\nWe hope that both this guide and the accompanying GitHub code will be valuable\nresources for practitioners and researchers interested in better understanding\nthe behavior and structure of the Hessian in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T07, 65K10, 65Y05"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 3 figures, open source code on GitHub",
    "pdf_url": "http://arxiv.org/pdf/2504.04520v1",
    "published_date": "2025-04-06 15:37:04 UTC",
    "updated_date": "2025-04-06 15:37:04 UTC"
  },
  {
    "arxiv_id": "2504.04517v1",
    "title": "Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection",
    "authors": [
      "Jiancheng Pan",
      "Yanxing Liu",
      "Xiao He",
      "Long Peng",
      "Jiahao Li",
      "Yuze Sun",
      "Xiaomeng Huang"
    ],
    "abstract": "Foundation models pretrained on extensive datasets, such as GroundingDINO and\nLAE-DINO, have performed remarkably in the cross-domain few-shot object\ndetection (CD-FSOD) task. Through rigorous few-shot training, we found that the\nintegration of image-based data augmentation techniques and grid-based\nsub-domain search strategy significantly enhances the performance of these\nfoundation models. Building upon GroundingDINO, we employed several widely used\nimage augmentation methods and established optimization objectives to\neffectively navigate the expansive domain space in search of optimal\nsub-domains. This approach facilitates efficient few-shot object detection and\nintroduces an approach to solving the CD-FSOD problem by efficiently searching\nfor the optimal parameter configuration from the foundation model. Our findings\nsubstantially advance the practical deployment of vision-language models in\ndata-scarce environments, offering critical insights into optimizing their\ncross-domain generalization capabilities without labor-intensive retraining.\nCode is available at https://github.com/jaychempan/ETS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04517v1",
    "published_date": "2025-04-06 15:30:35 UTC",
    "updated_date": "2025-04-06 15:30:35 UTC"
  },
  {
    "arxiv_id": "2504.04514v2",
    "title": "Saliency-driven Dynamic Token Pruning for Large Language Models",
    "authors": [
      "Yao Tao",
      "Yehui Tang",
      "Yun Wang",
      "Mingjian Zhu",
      "Hailin Hu",
      "Yunhe Wang"
    ],
    "abstract": "Despite the recent success of large language models (LLMs), LLMs are\nparticularly challenging in long-sequence inference scenarios due to the\nquadratic computational complexity of the attention mechanism. Inspired by the\ninterpretability theory of feature attribution in neural network models, we\nobserve that not all tokens have the same contribution. Based on this\nobservation, we propose a novel token pruning framework, namely Saliency-driven\nDynamic Token Pruning (SDTP), to gradually and dynamically prune redundant\ntokens based on the input context. Specifically, a lightweight saliency-driven\nprediction module is designed to estimate the importance score of each token\nwith its hidden state, which is added to different layers of the LLM to\nhierarchically prune redundant tokens. Furthermore, a ranking-based\noptimization strategy is proposed to minimize the ranking divergence of the\nsaliency score and the predicted importance score. Extensive experiments have\nshown that our framework is generalizable to various models and datasets. By\nhierarchically pruning 65\\% of the input tokens, our method greatly reduces\n33\\% $\\sim$ 47\\% FLOPs and achieves speedup up to 1.75$\\times$ during\ninference, while maintaining comparable performance. We further demonstrate\nthat SDTP can be combined with KV cache compression method for further\ncompression.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04514v2",
    "published_date": "2025-04-06 15:15:07 UTC",
    "updated_date": "2025-04-09 14:36:19 UTC"
  },
  {
    "arxiv_id": "2504.04482v2",
    "title": "Statistical Management of the False Discovery Rate in Medical Instance Segmentation Based on Conformal Risk Control",
    "authors": [
      "Mengxia Dai",
      "Wenqian Luo",
      "Tianyang Li"
    ],
    "abstract": "Instance segmentation plays a pivotal role in medical image analysis by\nenabling precise localization and delineation of lesions, tumors, and\nanatomical structures. Although deep learning models such as Mask R-CNN and\nBlendMask have achieved remarkable progress, their application in high-risk\nmedical scenarios remains constrained by confidence calibration issues, which\nmay lead to misdiagnosis. To address this challenge, we propose a robust\nquality control framework based on conformal prediction theory. This framework\ninnovatively constructs a risk-aware dynamic threshold mechanism that\nadaptively adjusts segmentation decision boundaries according to clinical\nrequirements.Specifically, we design a \\textbf{calibration-aware loss function}\nthat dynamically tunes the segmentation threshold based on a user-defined risk\nlevel $\\alpha$. Utilizing exchangeable calibration data, this method ensures\nthat the expected FNR or FDR on test data remains below $\\alpha$ with high\nprobability. The framework maintains compatibility with mainstream segmentation\nmodels (e.g., Mask R-CNN, BlendMask+ResNet-50-FPN) and datasets (PASCAL VOC\nformat) without requiring architectural modifications. Empirical results\ndemonstrate that we rigorously bound the FDR metric marginally over the test\nset via our developed calibration framework.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2025 IEEE 3rd International Conference on Image\n  Processing and Computer Applications (ICIPCA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.04482v2",
    "published_date": "2025-04-06 13:31:19 UTC",
    "updated_date": "2025-04-27 15:17:37 UTC"
  },
  {
    "arxiv_id": "2504.04473v1",
    "title": "Directed Graph-alignment Approach for Identification of Gaps in Short Answers",
    "authors": [
      "Archana Sahu",
      "Plaban Kumar Bhowmick"
    ],
    "abstract": "In this paper, we have presented a method for identifying missing items known\nas gaps in the student answers by comparing them against the corresponding\nmodel answer/reference answers, automatically. The gaps can be identified at\nword, phrase or sentence level. The identified gaps are useful in providing\nfeedback to the students for formative assessment. The problem of gap\nidentification has been modelled as an alignment of a pair of directed graphs\nrepresenting a student answer and the corresponding model answer for a given\nquestion. To validate the proposed approach, the gap annotated student answers\nconsidering answers from three widely known datasets in the short answer\ngrading domain, namely, University of North Texas (UNT), SciEntsBank, and\nBeetle have been developed and this gap annotated student answers' dataset is\navailable at: https://github.com/sahuarchana7/gaps-answers-dataset. Evaluation\nmetrics used in the traditional machine learning tasks have been adopted to\nevaluate the task of gap identification. Though performance of the proposed\napproach varies across the datasets and the types of the answers, overall the\nperformance is observed to be promising.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04473v1",
    "published_date": "2025-04-06 13:04:28 UTC",
    "updated_date": "2025-04-06 13:04:28 UTC"
  },
  {
    "arxiv_id": "2504.04469v1",
    "title": "AI2STOW: End-to-End Deep Reinforcement Learning to Construct Master Stowage Plans under Demand Uncertainty",
    "authors": [
      "Jaike Van Twiller",
      "Djordje Grbic",
      "Rune MÃ¸ller Jensen"
    ],
    "abstract": "The worldwide economy and environmental sustainability depend on eff icient\nand reliable supply chains, in which container shipping plays a crucial role as\nan environmentally friendly mode of transport. Liner shipping companies seek to\nimprove operational efficiency by solving the stowage planning problem. Due to\nmany complex combinatorial aspects, stowage planning is challenging and often\ndecomposed into two NP-hard subproblems: master and slot planning. This article\nproposes AI2STOW, an end-to-end deep reinforcement learning model with\nfeasibility projection and an action mask to create master plans under demand\nuncertainty with global objectives and constraints, including paired block\nstowage patterms. Our experimental results demonstrate that AI2STOW outperforms\nbaseline methods from reinforcement learning and stochastic programming in\nobjective performance and computational efficiency, based on simulated\ninstances reflecting the scale of realistic vessels and operational planning\nhorizons.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "Submitted to a journal",
    "pdf_url": "http://arxiv.org/pdf/2504.04469v1",
    "published_date": "2025-04-06 12:45:25 UTC",
    "updated_date": "2025-04-06 12:45:25 UTC"
  },
  {
    "arxiv_id": "2504.04466v2",
    "title": "LoopGen: Training-Free Loopable Music Generation",
    "authors": [
      "Davide Marincione",
      "Giorgio Strano",
      "Donato Crisostomi",
      "Roberto Ribuoli",
      "Emanuele RodolÃ "
    ],
    "abstract": "Loops--short audio segments designed for seamless repetition--are central to\nmany music genres, particularly those rooted in dance and electronic styles.\nHowever, current generative music models struggle to produce truly loopable\naudio, as generating a short waveform alone does not guarantee a smooth\ntransition from its endpoint back to its start, often resulting in audible\ndiscontinuities. Loops--short audio segments designed for seamless\nrepetition--are central to many music genres, particularly those rooted in\ndance and electronic styles. However, current generative music models struggle\nto produce truly loopable audio, as generating a short waveform alone does not\nguarantee a smooth transition from its endpoint back to its start, often\nresulting in audible discontinuities. We address this gap by modifying a\nnon-autoregressive model (MAGNeT) to generate tokens in a circular pattern,\nletting the model attend to the beginning of the audio when creating its\nending. This inference-only approach results in generations that are aware of\nfuture context and loop naturally, without the need for any additional training\nor data. We evaluate the consistency of loop transitions by computing token\nperplexity around the seam of the loop, observing a 55% improvement. Blind\nlistening tests further confirm significant perceptual gains over baseline\nmethods, improving mean ratings by 70%. Taken together, these results highlight\nthe effectiveness of inference-only approaches in improving generative models\nand underscore the advantages of non-autoregressive methods for context-aware\nmusic generation.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04466v2",
    "published_date": "2025-04-06 12:34:23 UTC",
    "updated_date": "2025-04-08 06:13:10 UTC"
  },
  {
    "arxiv_id": "2504.04462v1",
    "title": "An overview of model uncertainty and variability in LLM-based sentiment analysis. Challenges, mitigation strategies and the role of explainability",
    "authors": [
      "David Herrera-Poyatos",
      "Carlos PelÃ¡ez-GonzÃ¡lez",
      "Cristina Zuheros",
      "AndrÃ©s Herrera-Poyatos",
      "Virilo Tejedor",
      "Francisco Herrera",
      "Rosana Montes"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced sentiment analysis,\nyet their inherent uncertainty and variability pose critical challenges to\nachieving reliable and consistent outcomes. This paper systematically explores\nthe Model Variability Problem (MVP) in LLM-based sentiment analysis,\ncharacterized by inconsistent sentiment classification, polarization, and\nuncertainty arising from stochastic inference mechanisms, prompt sensitivity,\nand biases in training data. We analyze the core causes of MVP, presenting\nillustrative examples and a case study to highlight its impact. In addition, we\ninvestigate key challenges and mitigation strategies, paying particular\nattention to the role of temperature as a driver of output randomness and\nemphasizing the crucial role of explainability in improving transparency and\nuser trust. By providing a structured perspective on stability,\nreproducibility, and trustworthiness, this study helps develop more reliable,\nexplainable, and robust sentiment analysis models, facilitating their\ndeployment in high-stakes domains such as finance, healthcare, and\npolicymaking, among others.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages and 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04462v1",
    "published_date": "2025-04-06 12:20:39 UTC",
    "updated_date": "2025-04-06 12:20:39 UTC"
  },
  {
    "arxiv_id": "2504.04455v1",
    "title": "EclipseNETs: Learning Irregular Small Celestial Body Silhouettes",
    "authors": [
      "Giacomo Acciarini",
      "Dario Izzo",
      "Francesco Biscani"
    ],
    "abstract": "Accurately predicting eclipse events around irregular small bodies is crucial\nfor spacecraft navigation, orbit determination, and spacecraft systems\nmanagement. This paper introduces a novel approach leveraging neural implicit\nrepresentations to model eclipse conditions efficiently and reliably. We\npropose neural network architectures that capture the complex silhouettes of\nasteroids and comets with high precision. Tested on four well-characterized\nbodies - Bennu, Itokawa, 67P/Churyumov-Gerasimenko, and Eros - our method\nachieves accuracy comparable to traditional ray-tracing techniques while\noffering orders of magnitude faster performance. Additionally, we develop an\nindirect learning framework that trains these models directly from sparse\ntrajectory data using Neural Ordinary Differential Equations, removing the\nrequirement to have prior knowledge of an accurate shape model. This approach\nallows for the continuous refinement of eclipse predictions, progressively\nreducing errors and improving accuracy as new trajectory data is incorporated.",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04455v1",
    "published_date": "2025-04-06 11:51:44 UTC",
    "updated_date": "2025-04-06 11:51:44 UTC"
  },
  {
    "arxiv_id": "2504.04453v2",
    "title": "Prot42: a Novel Family of Protein Language Models for Target-aware Protein Binder Generation",
    "authors": [
      "Mohammad Amaan Sayeed",
      "Engin Tekin",
      "Maryam Nadeem",
      "Nancy A. ElNaker",
      "Aahan Singh",
      "Natalia Vassilieva",
      "Boulbaba Ben Amor"
    ],
    "abstract": "Unlocking the next generation of biotechnology and therapeutic innovation\ndemands overcoming the inherent complexity and resource-intensity of\nconventional protein engineering methods. Recent GenAI-powered computational\ntechniques often rely on the availability of the target protein's 3D structures\nand specific binding sites to generate high-affinity binders, constraints\nexhibited by models such as AlphaProteo and RFdiffusion. In this work, we\nexplore the use of Protein Language Models (pLMs) for high-affinity binder\ngeneration. We introduce Prot42, a novel family of Protein Language Models\n(pLMs) pretrained on vast amounts of unlabeled protein sequences. By capturing\ndeep evolutionary, structural, and functional insights through an advanced\nauto-regressive, decoder-only architecture inspired by breakthroughs in natural\nlanguage processing, Prot42 dramatically expands the capabilities of\ncomputational protein design based on language only. Remarkably, our models\nhandle sequences up to 8,192 amino acids, significantly surpassing standard\nlimitations and enabling precise modeling of large proteins and complex\nmulti-domain sequences. Demonstrating powerful practical applications, Prot42\nexcels in generating high-affinity protein binders and sequence-specific\nDNA-binding proteins. Our innovative models are publicly available, offering\nthe scientific community an efficient and precise computational toolkit for\nrapid protein engineering.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04453v2",
    "published_date": "2025-04-06 11:43:12 UTC",
    "updated_date": "2025-05-18 14:39:42 UTC"
  },
  {
    "arxiv_id": "2504.05346v1",
    "title": "Thanos: A Block-wise Pruning Algorithm for Efficient Large Language Model Compression",
    "authors": [
      "Ivan Ilin",
      "Peter Richtarik"
    ],
    "abstract": "This paper presents Thanos, a novel weight-pruning algorithm designed to\nreduce the memory footprint and enhance the computational efficiency of large\nlanguage models (LLMs) by removing redundant weights while maintaining\naccuracy. Thanos introduces a block-wise pruning strategy with adaptive masks\nthat dynamically adjust to weight importance, enabling flexible sparsity\npatterns and structured formats, such as $n:m$ sparsity, optimized for hardware\nacceleration. Experimental evaluations demonstrate that Thanos achieves\nstate-of-the-art performance in structured pruning and outperforms existing\nmethods in unstructured pruning. By providing an efficient and adaptable\napproach to model compression, Thanos offers a practical solution for deploying\nlarge models in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.PF",
      "68T07, 68Q32"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 Figures, 3 Tables, 2 Algorithms, paper comes with Appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.05346v1",
    "published_date": "2025-04-06 11:38:44 UTC",
    "updated_date": "2025-04-06 11:38:44 UTC"
  },
  {
    "arxiv_id": "2504.04444v1",
    "title": "On the Spatial Structure of Mixture-of-Experts in Transformers",
    "authors": [
      "Daniel Bershatsky",
      "Ivan Oseledets"
    ],
    "abstract": "A common assumption is that MoE routers primarily leverage semantic features\nfor expert selection. However, our study challenges this notion by\ndemonstrating that positional token information also plays a crucial role in\nrouting decisions. Through extensive empirical analysis, we provide evidence\nsupporting this hypothesis, develop a phenomenological explanation of the\nobserved behavior, and discuss practical implications for MoE-based\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2025 Workshop on Sparsity in LLMs (SLLM)",
    "pdf_url": "http://arxiv.org/pdf/2504.04444v1",
    "published_date": "2025-04-06 11:31:55 UTC",
    "updated_date": "2025-04-06 11:31:55 UTC"
  },
  {
    "arxiv_id": "2504.04440v1",
    "title": "Do We Need Responsible XR? Drawing on Responsible AI to Inform Ethical Research and Practice into XRAI / the Metaverse",
    "authors": [
      "Mark McGill",
      "Joseph O'Hagan",
      "Thomas Goodge",
      "Graham Wilson",
      "Mohamed Khamis",
      "Veronika KrauÃ",
      "Jan Gugenheimer"
    ],
    "abstract": "This position paper for the CHI 2025 workshop \"Everyday AR through\nAI-in-the-Loop\" reflects on whether as a field HCI needs to define Responsible\nXR as a parallel to, and in conjunction with, Responsible AI, addressing the\nunique vulnerabilities posed by mass adoption of wearable AI-enabled AR glasses\nand XR devices that could enact AI-driven human perceptual augmentation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04440v1",
    "published_date": "2025-04-06 10:37:09 UTC",
    "updated_date": "2025-04-06 10:37:09 UTC"
  },
  {
    "arxiv_id": "2504.04430v3",
    "title": "AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence",
    "authors": [
      "Matej Å progar"
    ],
    "abstract": "Despite remarkable progress in machine learning, current AI systems continue\nto fall short of true human-like intelligence. While Large Language Models\n(LLMs) excel in pattern recognition and response generation, they lack genuine\nunderstanding - an essential hallmark of Artificial General Intelligence (AGI).\nExisting AGI evaluation methods fail to offer a practical, gradual, and\ninformative metric. This paper introduces the Artificial General Intelligence\nTest Bed (AGITB), comprising twelve rigorous tests that form a\nsignal-processing-level foundation for the potential emergence of cognitive\ncapabilities. AGITB evaluates intelligence through a model's ability to predict\nbinary signals across time without relying on symbolic representations or\npretraining. Unlike high-level tests grounded in language or perception, AGITB\nfocuses on core computational invariants reflective of biological intelligence,\nsuch as determinism, sensitivity, and generalisation. The test bed assumes no\nprior bias, operates independently of semantic meaning, and ensures\nunsolvability through brute force or memorization. While humans pass AGITB by\ndesign, no current AI system has met its criteria, making AGITB a compelling\nbenchmark for guiding and recognizing progress toward AGI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04430v3",
    "published_date": "2025-04-06 10:01:15 UTC",
    "updated_date": "2025-05-09 11:25:57 UTC"
  },
  {
    "arxiv_id": "2504.04428v1",
    "title": "Formula-Supervised Sound Event Detection: Pre-Training Without Real Data",
    "authors": [
      "Yuto Shibata",
      "Keitaro Tanaka",
      "Yoshiaki Bando",
      "Keisuke Imoto",
      "Hirokatsu Kataoka",
      "Yoshimitsu Aoki"
    ],
    "abstract": "In this paper, we propose a novel formula-driven supervised learning (FDSL)\nframework for pre-training an environmental sound analysis model by leveraging\nacoustic signals parametrically synthesized through formula-driven methods.\nSpecifically, we outline detailed procedures and evaluate their effectiveness\nfor sound event detection (SED). The SED task, which involves estimating the\ntypes and timings of sound events, is particularly challenged by the difficulty\nof acquiring a sufficient quantity of accurately labeled training data.\nMoreover, it is well known that manually annotated labels often contain noises\nand are significantly influenced by the subjective judgment of annotators. To\naddress these challenges, we propose a novel pre-training method that utilizes\na synthetic dataset, Formula-SED, where acoustic data are generated solely\nbased on mathematical formulas. The proposed method enables large-scale\npre-training by using the synthesis parameters applied at each time step as\nground truth labels, thereby eliminating label noise and bias. We demonstrate\nthat large-scale pre-training with Formula-SED significantly enhances model\naccuracy and accelerates training, as evidenced by our results in the DESED\ndataset used for DCASE2023 Challenge Task 4. The project page is at\nhttps://yutoshibata07.github.io/Formula-SED/",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04428v1",
    "published_date": "2025-04-06 09:47:26 UTC",
    "updated_date": "2025-04-06 09:47:26 UTC"
  },
  {
    "arxiv_id": "2504.04427v1",
    "title": "FluentLip: A Phonemes-Based Two-stage Approach for Audio-Driven Lip Synthesis with Optical Flow Consistency",
    "authors": [
      "Shiyan Liu",
      "Rui Qu",
      "Yan Jin"
    ],
    "abstract": "Generating consecutive images of lip movements that align with a given speech\nin audio-driven lip synthesis is a challenging task. While previous studies\nhave made strides in synchronization and visual quality, lip intelligibility\nand video fluency remain persistent challenges. This work proposes FluentLip, a\ntwo-stage approach for audio-driven lip synthesis, incorporating three featured\nstrategies. To improve lip synchronization and intelligibility, we integrate a\nphoneme extractor and encoder to generate a fusion of audio and phoneme\ninformation for multimodal learning. Additionally, we employ optical flow\nconsistency loss to ensure natural transitions between image frames.\nFurthermore, we incorporate a diffusion chain during the training of Generative\nAdversarial Networks (GANs) to improve both stability and efficiency. We\nevaluate our proposed FluentLip through extensive experiments, comparing it\nwith five state-of-the-art (SOTA) approaches across five metrics, including a\nproposed metric called Phoneme Error Rate (PER) that evaluates lip pose\nintelligibility and video fluency. The experimental results demonstrate that\nour FluentLip approach is highly competitive, achieving significant\nimprovements in smoothness and naturalness. In particular, it outperforms these\nSOTA approaches by approximately $\\textbf{16.3%}$ in Fr\\'echet Inception\nDistance (FID) and $\\textbf{35.2%}$ in PER.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04427v1",
    "published_date": "2025-04-06 09:44:30 UTC",
    "updated_date": "2025-04-06 09:44:30 UTC"
  },
  {
    "arxiv_id": "2504.05344v1",
    "title": "Divergent Paths: Separating Homophilic and Heterophilic Learning for Enhanced Graph-level Representations",
    "authors": [
      "Han Lei",
      "Jiaxing Xu",
      "Xia Dong",
      "Yiping Ke"
    ],
    "abstract": "Graph Convolutional Networks (GCNs) are predominantly tailored for graphs\ndisplaying homophily, where similar nodes connect, but often fail on\nheterophilic graphs. The strategy of adopting distinct approaches to learn from\nhomophilic and heterophilic components in node-level tasks has been widely\ndiscussed and proven effective both theoretically and experimentally. However,\nin graph-level tasks, research on this topic remains notably scarce. Addressing\nthis gap, our research conducts an analysis on graphs with nodes' category ID\navailable, distinguishing intra-category and inter-category components as\nembodiment of homophily and heterophily, respectively. We find while GCNs excel\nat extracting information within categories, they frequently capture noise from\ninter-category components. Consequently, it is crucial to employ distinct\nlearning strategies for intra- and inter-category elements. To alleviate this\nproblem, we separately learn the intra- and inter-category parts by a\ncombination of an intra-category convolution (IntraNet) and an inter-category\nhigh-pass graph convolution (InterNet). Our IntraNet is supported by\nsophisticated graph preprocessing steps and a novel category-based graph\nreadout function. For the InterNet, we utilize a high-pass filter to amplify\nthe node disparities, enhancing the recognition of details in the\nhigh-frequency components. The proposed approach, DivGNN, combines the IntraNet\nand InterNet with a gated mechanism and substantially improves classification\nperformance on graph-level tasks, surpassing traditional GNN baselines in\neffectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05344v1",
    "published_date": "2025-04-06 09:31:10 UTC",
    "updated_date": "2025-04-06 09:31:10 UTC"
  },
  {
    "arxiv_id": "2504.04423v1",
    "title": "UniToken: Harmonizing Multimodal Understanding and Generation through Unified Visual Encoding",
    "authors": [
      "Yang Jiao",
      "Haibo Qiu",
      "Zequn Jie",
      "Shaoxiang Chen",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "abstract": "We introduce UniToken, an auto-regressive generation model that encodes\nvisual inputs through a combination of discrete and continuous representations,\nenabling seamless integration of unified visual understanding and image\ngeneration tasks. Unlike previous approaches that rely on unilateral visual\nrepresentations, our unified visual encoding framework captures both high-level\nsemantics and low-level details, delivering multidimensional information that\nempowers heterogeneous tasks to selectively assimilate domain-specific\nknowledge based on their inherent characteristics. Through in-depth\nexperiments, we uncover key principles for developing a unified model capable\nof both visual understanding and image generation. Extensive evaluations across\na diverse range of prominent benchmarks demonstrate that UniToken achieves\nstate-of-the-art performance, surpassing existing approaches. These results\nestablish UniToken as a robust foundation for future research in this domain.\nThe code and models are available at https://github.com/SxJyJay/UniToken.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accpeted to CVPR 2025 workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.04423v1",
    "published_date": "2025-04-06 09:20:49 UTC",
    "updated_date": "2025-04-06 09:20:49 UTC"
  },
  {
    "arxiv_id": "2504.05343v2",
    "title": "AROMA: Autonomous Rank-one Matrix Adaptation",
    "authors": [
      "Hao Nan Sheng",
      "Zhi-yong Wang",
      "Mingrui Yang",
      "Hing Cheung So"
    ],
    "abstract": "As large language models continue to grow in size, parameter-efficient\nfine-tuning (PEFT) has become increasingly crucial. While low-rank adaptation\n(LoRA) offers a solution through low-rank updates, its static rank allocation\nmay yield suboptimal results. Adaptive low-rank adaptation (AdaLoRA) improves\nthis with dynamic allocation but remains sensitive to initial and target rank\nconfigurations. We introduce AROMA, a framework that automatically constructs\nlayer-specific updates by iteratively building up rank-one components with very\nfew trainable parameters that gradually diminish to zero. Unlike existing\nmethods that employ rank reduction mechanisms, AROMA introduces a dual-loop\narchitecture for rank growth. The inner loop extracts information from each\nrank-one subspace, while the outer loop determines the number of rank-one\nsubspaces, i.e., the optimal rank. We reset optimizer states to maintain\nsubspace independence. AROMA significantly reduces parameters compared to LoRA\nand AdaLoRA while achieving superior performance on natural language\nunderstanding and commonsense reasoning tasks, offering new insights into\nadaptive PEFT. The code is available at\n\\href{https://github.com/ShuDun23/AROMA}{AROMA}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05343v2",
    "published_date": "2025-04-06 09:14:43 UTC",
    "updated_date": "2025-04-11 06:26:08 UTC"
  },
  {
    "arxiv_id": "2504.04419v1",
    "title": "Driving-RAG: Driving Scenarios Embedding, Search, and RAG Applications",
    "authors": [
      "Cheng Chang",
      "Jingwei Ge",
      "Jiazhe Guo",
      "Zelin Guo",
      "Binghong Jiang",
      "Li Li"
    ],
    "abstract": "Driving scenario data play an increasingly vital role in the development of\nintelligent vehicles and autonomous driving. Accurate and efficient scenario\ndata search is critical for both online vehicle decision-making and planning,\nand offline scenario generation and simulations, as it allows for leveraging\nthe scenario experiences to improve the overall performance. Especially with\nthe application of large language models (LLMs) and\nRetrieval-Augmented-Generation (RAG) systems in autonomous driving, urgent\nrequirements are put forward. In this paper, we introduce the Driving-RAG\nframework to address the challenges of efficient scenario data embedding,\nsearch, and applications for RAG systems. Our embedding model aligns\nfundamental scenario information and scenario distance metrics in the vector\nspace. The typical scenario sampling method combined with hierarchical\nnavigable small world can perform efficient scenario vector search to achieve\nhigh efficiency without sacrificing accuracy. In addition, the reorganization\nmechanism by graph knowledge enhances the relevance to the prompt scenarios and\naugment LLM generation. We demonstrate the effectiveness of the proposed\nframework on typical trajectory planning task for complex interactive scenarios\nsuch as ramps and intersections, showcasing its advantages for RAG\napplications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04419v1",
    "published_date": "2025-04-06 09:05:33 UTC",
    "updated_date": "2025-04-06 09:05:33 UTC"
  },
  {
    "arxiv_id": "2504.05342v1",
    "title": "MASS: MoErging through Adaptive Subspace Selection",
    "authors": [
      "Donato Crisostomi",
      "Alessandro Zirilli",
      "Antonio Andrea Gargiulo",
      "Maria Sofia Bucarelli",
      "Simone Scardapane",
      "Fabrizio Silvestri",
      "Iacopo Masi",
      "Emanuele RodolÃ "
    ],
    "abstract": "Model merging has recently emerged as a lightweight alternative to\nensembling, combining multiple fine-tuned models into a single set of\nparameters with no additional training overhead. Yet, existing merging methods\nfall short of matching the full accuracy of separately fine-tuned endpoints. We\npresent MASS (MoErging through Adaptive Subspace Selection), a new approach\nthat closes this gap by unifying multiple fine-tuned models while retaining\nnear state-of-the-art performance across tasks. Building on the low-rank\ndecomposition of per-task updates, MASS stores only the most salient singular\ncomponents for each task and merges them into a shared model. At inference\ntime, a non-parametric, data-free router identifies which subspace (or\ncombination thereof) best explains an input's intermediate features and\nactivates the corresponding task-specific block. This procedure is fully\ntraining-free and introduces only a two-pass inference overhead plus a ~2\nstorage factor compared to a single pretrained model, irrespective of the\nnumber of tasks. We evaluate MASS on CLIP-based image classification using\nViT-B-16, ViT-B-32 and ViT-L-14 for benchmarks of 8, 14 and 20 tasks\nrespectively, establishing a new state-of-the-art. Most notably, MASS recovers\nup to ~98% of the average accuracy of individual fine-tuned models, making it a\npractical alternative to ensembling at a fraction of the storage cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05342v1",
    "published_date": "2025-04-06 08:49:52 UTC",
    "updated_date": "2025-04-06 08:49:52 UTC"
  },
  {
    "arxiv_id": "2504.05341v2",
    "title": "Three-Factor Learning in Spiking Neural Networks: An Overview of Methods and Trends from a Machine Learning Perspective",
    "authors": [
      "Szymon Mazurek",
      "Jakub Caputa",
      "Jan K. ArgasiÅski",
      "Maciej Wielgosz"
    ],
    "abstract": "Three-factor learning rules in Spiking Neural Networks (SNNs) have emerged as\na crucial extension to traditional Hebbian learning and Spike-Timing-Dependent\nPlasticity (STDP), incorporating neuromodulatory signals to improve adaptation\nand learning efficiency. These mechanisms enhance biological plausibility and\nfacilitate improved credit assignment in artificial neural systems. This paper\ntakes a view on this topic from a machine learning perspective, providing an\noverview of recent advances in three-factor learning, discusses theoretical\nfoundations, algorithmic implementations, and their relevance to reinforcement\nlearning and neuromorphic computing. In addition, we explore interdisciplinary\napproaches, scalability challenges, and potential applications in robotics,\ncognitive modeling, and AI systems. Finally, we highlight key research gaps and\npropose future directions for bridging the gap between neuroscience and\nartificial intelligence.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "92B20, 68T05, 92B25, 37N25, 60J22, 68Q32",
      "I.2.6; I.2.10; I.2.9; I.2.3; C.1.3; F.4.1; J.2"
    ],
    "primary_category": "cs.NE",
    "comment": "Pre-print",
    "pdf_url": "http://arxiv.org/pdf/2504.05341v2",
    "published_date": "2025-04-06 08:10:16 UTC",
    "updated_date": "2025-04-25 07:36:00 UTC"
  },
  {
    "arxiv_id": "2504.04405v2",
    "title": "Universal Item Tokenization for Transferable Generative Recommendation",
    "authors": [
      "Bowen Zheng",
      "Hongyu Lu",
      "Yu Chen",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, generative recommendation has emerged as a promising paradigm,\nattracting significant research attention. The basic framework involves an item\ntokenizer, which represents each item as a sequence of codes serving as its\nidentifier, and a generative recommender that predicts the next item by\nautoregressively generating the target item identifier. However, in existing\nmethods, both the tokenizer and the recommender are typically domain-specific,\nlimiting their ability for effective transfer or adaptation to new domains. To\nthis end, we propose UTGRec, a Universal item Tokenization approach for\ntransferable Generative Recommendation. Specifically, we design a universal\nitem tokenizer for encoding rich item semantics by adapting a multimodal large\nlanguage model (MLLM). By devising tree-structured codebooks, we discretize\ncontent representations into corresponding codes for item tokenization. To\neffectively learn the universal item tokenizer on multiple domains, we\nintroduce two key techniques in our approach. For raw content reconstruction,\nwe employ dual lightweight decoders to reconstruct item text and images from\ndiscrete representations to capture general knowledge embedded in the content.\nFor collaborative knowledge integration, we assume that co-occurring items are\nsimilar and integrate collaborative signals through co-occurrence alignment and\nreconstruction. Finally, we present a joint learning framework to pre-train and\nadapt the transferable generative recommender across multiple domains.\nExtensive experiments on four public datasets demonstrate the superiority of\nUTGRec compared to both traditional and generative recommendation baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04405v2",
    "published_date": "2025-04-06 08:07:49 UTC",
    "updated_date": "2025-04-14 02:50:20 UTC"
  },
  {
    "arxiv_id": "2504.04400v2",
    "title": "Pre-training Generative Recommender with Multi-Identifier Item Tokenization",
    "authors": [
      "Bowen Zheng",
      "Enze Liu",
      "Zhongfu Chen",
      "Zhongrui Ma",
      "Yue Wang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "abstract": "Generative recommendation autoregressively generates item identifiers to\nrecommend potential items. Existing methods typically adopt a one-to-one\nmapping strategy, where each item is represented by a single identifier.\nHowever, this scheme poses issues, such as suboptimal semantic modeling for\nlow-frequency items and limited diversity in token sequence data. To overcome\nthese limitations, we propose MTGRec, which leverages Multi-identifier item\nTokenization to augment token sequence data for Generative Recommender\npre-training. Our approach involves two key innovations: multi-identifier item\ntokenization and curriculum recommender pre-training. For multi-identifier item\ntokenization, we leverage the RQ-VAE as the tokenizer backbone and treat model\ncheckpoints from adjacent training epochs as semantically relevant tokenizers.\nThis allows each item to be associated with multiple identifiers, enabling a\nsingle user interaction sequence to be converted into several token sequences\nas different data groups. For curriculum recommender pre-training, we introduce\na curriculum learning scheme guided by data influence estimation, dynamically\nadjusting the sampling probability of each data group during recommender\npre-training. After pre-training, we fine-tune the model using a single\ntokenizer to ensure accurate item identification for recommendation. Extensive\nexperiments on three public benchmark datasets demonstrate that MTGRec\nsignificantly outperforms both traditional and generative recommendation\nbaselines in terms of effectiveness and scalability.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04400v2",
    "published_date": "2025-04-06 08:03:03 UTC",
    "updated_date": "2025-04-14 02:51:58 UTC"
  },
  {
    "arxiv_id": "2504.10497v2",
    "title": "Exploring Generative AI Techniques in Government: A Case Study",
    "authors": [
      "Sunyi Liu",
      "Mengzhe Geng",
      "Rebecca Hart"
    ],
    "abstract": "The swift progress of Generative Artificial intelligence (GenAI), notably\nLarge Language Models (LLMs), is reshaping the digital landscape. Recognizing\nthis transformative potential, the National Research Council of Canada (NRC)\nlaunched a pilot initiative to explore the integration of GenAI techniques into\nits daily operation for performance excellence, where 22 projects were launched\nin May 2024. Within these projects, this paper presents the development of the\nintelligent agent Pubbie as a case study, targeting the automation of\nperformance measurement, data management and insight reporting at the NRC.\nCutting-edge techniques are explored, including LLM orchestration and semantic\nembedding via RoBERTa, while strategic fine-tuning and few-shot learning\napproaches are incorporated to infuse domain knowledge at an affordable cost.\nThe user-friendly interface of Pubbie allows general government users to input\nqueries in natural language and easily upload or download files with a simple\nbutton click, greatly reducing manual efforts and accessibility barriers.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.IR",
    "comment": "In submission to IEEE Intelligent Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.10497v2",
    "published_date": "2025-04-06 06:52:38 UTC",
    "updated_date": "2025-05-12 21:51:32 UTC"
  },
  {
    "arxiv_id": "2504.04383v2",
    "title": "Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning",
    "authors": [
      "Ximing Lu",
      "Seungju Han",
      "David Acuna",
      "Hyunwoo Kim",
      "Jaehun Jung",
      "Shrimai Prabhumoye",
      "Niklas Muennighoff",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Yejin Choi"
    ],
    "abstract": "Large reasoning models exhibit remarkable reasoning capabilities via long,\nelaborate reasoning trajectories. Supervised fine-tuning on such reasoning\ntraces, also known as distillation, can be a cost-effective way to boost\nreasoning capabilities of student models. However, empirical observations\nreveal that these reasoning trajectories are often suboptimal, switching\nexcessively between different lines of thought, resulting in under-thinking,\nover-thinking, and even degenerate responses. We introduce Retro-Search, an\nMCTS-inspired search algorithm, for distilling higher quality reasoning paths\nfrom large reasoning models. Retro-Search retrospectively revises reasoning\npaths to discover better, yet shorter traces, which can then lead to student\nmodels with enhanced reasoning capabilities with shorter, thus faster\ninference. Our approach can enable two use cases: self-improvement, where\nmodels are fine-tuned on their own Retro-Search-ed thought traces, and\nweak-to-strong improvement, where a weaker model revises stronger model's\nthought traces via Retro-Search. For self-improving, R1-distill-7B, fine-tuned\non its own Retro-Search-ed traces, reduces the average reasoning length by\n31.2% while improving performance by 7.7% across seven math benchmarks. For\nweak-to-strong improvement, we retrospectively revise R1-671B's traces from the\nOpenThoughts dataset using R1-distill-32B as the Retro-Search-er, a model 20x\nsmaller. Qwen2.5-32B, fine-tuned on this refined data, achieves performance\ncomparable to R1-distill-32B, yielding an 11.3% reduction in reasoning length\nand a 2.4% performance improvement compared to fine-tuning on the original\nOpenThoughts data. Our work counters recently emergent viewpoints that question\nthe relevance of search algorithms in the era of large reasoning models, by\ndemonstrating that there are still opportunities for algorithmic advancements,\neven for frontier models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Code and data will be publicly released upon internal approval",
    "pdf_url": "http://arxiv.org/pdf/2504.04383v2",
    "published_date": "2025-04-06 06:23:27 UTC",
    "updated_date": "2025-04-15 14:07:31 UTC"
  },
  {
    "arxiv_id": "2504.04378v1",
    "title": "Future-Proof Yourself: An AI Era Survival Guide",
    "authors": [
      "Taehoon Kim"
    ],
    "abstract": "Future-Proof Yourself is a practical guide that helps readers navigate the\nfast-changing world of artificial intelligence in everyday life. The book\nbegins by explaining how computers learn from data in simple, relatable terms,\nand gradually introduces the methods used in modern AI. It shows how basic\nideas in machine learning evolve into advanced systems that can recognize\nimages, understand language, and even make decisions. The guide also reviews\nthe history of AI and highlights the major breakthroughs that have shaped its\ngrowth. Looking ahead, the book explores emerging trends such as the\nintegration of AI with digital twins, wearable devices, and virtual\nenvironments. Designed for a general audience, the text avoids heavy technical\njargon and presents complex ideas in clear, straightforward language so that\nanyone can gain a solid understanding of the technology that is set to\ntransform our future.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "10 chapters, 259 pages, Textbook for \"Data & AI\" and \"Artificial\n  Intelligence\" at Sogang University Graduate School of Metaverse",
    "pdf_url": "http://arxiv.org/pdf/2504.04378v1",
    "published_date": "2025-04-06 06:11:29 UTC",
    "updated_date": "2025-04-06 06:11:29 UTC"
  },
  {
    "arxiv_id": "2504.04374v1",
    "title": "iADCPS: Time Series Anomaly Detection for Evolving Cyber-physical Systems via Incremental Meta-learning",
    "authors": [
      "Jiyu Tian",
      "Mingchu Li",
      "Liming Chen",
      "Zumin Wang"
    ],
    "abstract": "Anomaly detection for cyber-physical systems (ADCPS) is crucial in\nidentifying faults and potential attacks by analyzing the time series of sensor\nmeasurements and actuator states. However, current methods lack adaptation to\ndata distribution shifts in both temporal and spatial dimensions as\ncyber-physical systems evolve. To tackle this issue, we propose an incremental\nmeta-learning-based approach, namely iADCPS, which can continuously update the\nmodel through limited evolving normal samples to reconcile the distribution gap\nbetween evolving and historical time series. Specifically, We first introduce a\ntemporal mixup strategy to align data for data-level generalization which is\nthen combined with the one-class meta-learning approach for model-level\ngeneralization. Furthermore, we develop a non-parametric dynamic threshold to\nadaptively adjust the threshold based on the probability density of the\nabnormal scores without any anomaly supervision. We empirically evaluate the\neffectiveness of the iADCPS using three publicly available datasets PUMP, SWaT,\nand WADI. The experimental results demonstrate that our method achieves 99.0%,\n93.1%, and 78.7% F1-Score, respectively, which outperforms the state-of-the-art\n(SOTA) ADCPS method, especially in the context of the evolving CPSs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04374v1",
    "published_date": "2025-04-06 06:02:31 UTC",
    "updated_date": "2025-04-06 06:02:31 UTC"
  },
  {
    "arxiv_id": "2504.04373v1",
    "title": "StyleRec: A Benchmark Dataset for Prompt Recovery in Writing Style Transformation",
    "authors": [
      "Shenyang Liu",
      "Yang Gao",
      "Shaoyan Zhai",
      "Liqiang Wang"
    ],
    "abstract": "Prompt Recovery, reconstructing prompts from the outputs of large language\nmodels (LLMs), has grown in importance as LLMs become ubiquitous. Most users\naccess LLMs through APIs without internal model weights, relying only on\noutputs and logits, which complicates recovery. This paper explores a unique\nprompt recovery task focused on reconstructing prompts for style transfer and\nrephrasing, rather than typical question-answering. We introduce a dataset\ncreated with LLM assistance, ensuring quality through multiple techniques, and\ntest methods like zero-shot, few-shot, jailbreak, chain-of-thought,\nfine-tuning, and a novel canonical-prompt fallback for poor-performing cases.\nOur results show that one-shot and fine-tuning yield the best outcomes but\nhighlight flaws in traditional sentence similarity metrics for evaluating\nprompt recovery. Contributions include (1) a benchmark dataset, (2)\ncomprehensive experiments on prompt recovery strategies, and (3) identification\nof limitations in current evaluation metrics, all of which advance general\nprompt recovery research, where the structure of the input prompt is\nunrestricted.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 IEEE International Conference on Big Data (BigData)",
    "pdf_url": "http://arxiv.org/pdf/2504.04373v1",
    "published_date": "2025-04-06 06:02:28 UTC",
    "updated_date": "2025-04-06 06:02:28 UTC"
  },
  {
    "arxiv_id": "2504.04372v2",
    "title": "How Accurately Do Large Language Models Understand Code?",
    "authors": [
      "Sabaat Haroon",
      "Ahmad Faraz Khan",
      "Ahmad Humayun",
      "Waris Gill",
      "Abdul Haddi Amjad",
      "Ali R. Butt",
      "Mohammad Taha Khan",
      "Muhammad Ali Gulzar"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in post-development tasks\nsuch as code repair and testing. A key factor in these tasks' success is the\nmodel's deep understanding of code. However, the extent to which LLMs truly\nunderstand code remains largely unevaluated. Quantifying code comprehension is\nchallenging due to its abstract nature and the lack of a standardized metric.\nPreviously, this was assessed through developer surveys, which are not feasible\nfor evaluating LLMs. Existing LLM benchmarks focus primarily on code\ngeneration, fundamentally different from code comprehension. Additionally,\nfixed benchmarks quickly become obsolete as they become part of the training\ndata. This paper presents the first large-scale empirical investigation into\nLLMs' ability to understand code. Inspired by mutation testing, we use an LLM's\nfault-finding ability as a proxy for its deep code understanding. This approach\nis based on the insight that a model capable of identifying subtle functional\ndiscrepancies must understand the code well. We inject faults in real-world\nprograms and ask the LLM to localize them, ensuring the specifications suffice\nfor fault localization. Next, we apply semantic-preserving code mutations\n(SPMs) to the faulty programs and test whether the LLMs still locate the\nfaults, verifying their confidence in code understanding. We evaluate nine\npopular LLMs on 600,010 debugging tasks from 670 Java and 637 Python programs.\nWe find that LLMs lose the ability to debug the same bug in 78% of faulty\nprograms when SPMs are applied, indicating a shallow understanding of code and\nreliance on features irrelevant to semantics. We also find that LLMs understand\ncode earlier in the program better than later. This suggests that LLMs' code\ncomprehension remains tied to lexical and syntactic features due to\ntokenization designed for natural languages, which overlooks code semantics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper is currently Under Review. It consists of 11 pages, 12\n  Figures, and 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.04372v2",
    "published_date": "2025-04-06 05:59:29 UTC",
    "updated_date": "2025-04-09 18:27:43 UTC"
  },
  {
    "arxiv_id": "2504.04367v2",
    "title": "WeiDetect: Weibull Distribution-Based Defense against Poisoning Attacks in Federated Learning for Network Intrusion Detection Systems",
    "authors": [
      "Sameera K. M.",
      "Vinod P.",
      "Anderson Rocha",
      "Rafidha Rehiman K. A.",
      "Mauro Conti"
    ],
    "abstract": "In the era of data expansion, ensuring data privacy has become increasingly\ncritical, posing significant challenges to traditional AI-based applications.\nIn addition, the increasing adoption of IoT devices has introduced significant\ncybersecurity challenges, making traditional Network Intrusion Detection\nSystems (NIDS) less effective against evolving threats, and privacy concerns\nand regulatory restrictions limit their deployment. Federated Learning (FL) has\nemerged as a promising solution, allowing decentralized model training while\nmaintaining data privacy to solve these issues. However, despite implementing\nprivacy-preserving technologies, FL systems remain vulnerable to adversarial\nattacks. Furthermore, data distribution among clients is not heterogeneous in\nthe FL scenario. We propose WeiDetect, a two-phase, server-side defense\nmechanism for FL-based NIDS that detects malicious participants to address\nthese challenges. In the first phase, local models are evaluated using a\nvalidation dataset to generate validation scores. These scores are then\nanalyzed using a Weibull distribution, identifying and removing malicious\nmodels. We conducted experiments to evaluate the effectiveness of our approach\nin diverse attack settings. Our evaluation included two popular datasets,\nCIC-Darknet2020 and CSE-CIC-IDS2018, tested under non-IID data distributions.\nOur findings highlight that WeiDetect outperforms state-of-the-art defense\napproaches, improving higher target class recall up to 70% and enhancing the\nglobal model's F1 score by 1% to 14%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04367v2",
    "published_date": "2025-04-06 05:31:24 UTC",
    "updated_date": "2025-04-19 15:07:05 UTC"
  },
  {
    "arxiv_id": "2504.04366v1",
    "title": "Solving Sokoban using Hierarchical Reinforcement Learning with Landmarks",
    "authors": [
      "Sergey Pastukhov"
    ],
    "abstract": "We introduce a novel hierarchical reinforcement learning (HRL) framework that\nperforms top-down recursive planning via learned subgoals, successfully applied\nto the complex combinatorial puzzle game Sokoban. Our approach constructs a\nsix-level policy hierarchy, where each higher-level policy generates subgoals\nfor the level below. All subgoals and policies are learned end-to-end from\nscratch, without any domain knowledge. Our results show that the agent can\ngenerate long action sequences from a single high-level call. While prior work\nhas explored 2-3 level hierarchies and subgoal-based planning heuristics, we\ndemonstrate that deep recursive goal decomposition can emerge purely from\nlearning, and that such hierarchies can scale effectively to hard puzzle\ndomains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04366v1",
    "published_date": "2025-04-06 05:30:21 UTC",
    "updated_date": "2025-04-06 05:30:21 UTC"
  },
  {
    "arxiv_id": "2504.04365v1",
    "title": "AutoPDL: Automatic Prompt Optimization for LLM Agents",
    "authors": [
      "Claudio Spiess",
      "Mandana Vaziri",
      "Louis Mandel",
      "Martin Hirzel"
    ],
    "abstract": "The performance of large language models (LLMs) depends on how they are\nprompted, with choices spanning both the high-level prompting pattern (e.g.,\nZero-Shot, CoT, ReAct, ReWOO) and the specific prompt content (instructions and\nfew-shot demonstrations). Manually tuning this combination is tedious,\nerror-prone, and non-transferable across LLMs or tasks. Therefore, this paper\nproposes AutoPDL, an automated approach to discover good LLM agent\nconfigurations. Our method frames this as a structured AutoML problem over a\ncombinatorial space of agentic and non-agentic prompting patterns and\ndemonstrations, using successive halving to efficiently navigate this space. We\nintroduce a library implementing common prompting patterns using the PDL prompt\nprogramming language. AutoPDL solutions are human-readable, editable, and\nexecutable PDL programs that use this library. This approach also enables\nsource-to-source optimization, allowing human-in-the-loop refinement and reuse.\nEvaluations across three tasks and six LLMs (ranging from 8B to 70B parameters)\nshow consistent accuracy gains ($9.5\\pm17.5$ percentage points), up to 68.9pp,\nand reveal that selected prompting strategies vary across models and tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04365v1",
    "published_date": "2025-04-06 05:30:10 UTC",
    "updated_date": "2025-04-06 05:30:10 UTC"
  },
  {
    "arxiv_id": "2504.04363v1",
    "title": "REFORMER: A ChatGPT-Driven Data Synthesis Framework Elevating Text-to-SQL Models",
    "authors": [
      "Shenyang Liu",
      "Saleh Almohaimeed",
      "Liqiang Wang"
    ],
    "abstract": "The existing Text-to-SQL models suffer from a shortage of training data,\ninhibiting their ability to fully facilitate the applications of SQL queries in\nnew domains. To address this challenge, various data synthesis techniques have\nbeen employed to generate more diverse and higher quality data. In this paper,\nwe propose REFORMER, a framework that leverages ChatGPT's prowess without the\nneed for additional training, to facilitate the synthesis of (question, SQL\nquery) pairs tailored to new domains. Our data augmentation approach is based\non a \"retrieve-and-edit\" method, where we generate new questions by filling\nmasked question using explanation of SQL queries with the help of ChatGPT.\nFurthermore, we demonstrate that cycle consistency remains a valuable method of\nvalidation when applied appropriately. Our experimental results show that\nREFORMER consistently outperforms previous data augmentation methods. To\nfurther investigate the power of ChatGPT and create a general data augmentation\nmethod, we also generate the new data by paraphrasing the question in the\ndataset and by paraphrasing the description of a new SQL query that is\ngenerated by ChatGPT as well. Our results affirm that paraphrasing questions\ngenerated by ChatGPT help augment the original data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2024 International Conference on Machine Learning and Applications\n  (ICMLA)",
    "pdf_url": "http://arxiv.org/pdf/2504.04363v1",
    "published_date": "2025-04-06 05:27:37 UTC",
    "updated_date": "2025-04-06 05:27:37 UTC"
  },
  {
    "arxiv_id": "2504.10496v1",
    "title": "ArxivBench: Can LLMs Assist Researchers in Conducting Research?",
    "authors": [
      "Ning Li",
      "Jingran Zhang",
      "Justin Cui"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable effectiveness in\ncompleting various tasks such as reasoning, translation, and question\nanswering. However the issue of factual incorrect content in LLM-generated\nresponses remains a persistent challenge. In this study, we evaluate both\nproprietary and open-source LLMs on their ability to respond with relevant\nresearch papers and accurate links to articles hosted on the arXiv platform,\nbased on high level prompts. To facilitate this evaluation, we introduce\narXivBench, a benchmark specifically designed to assess LLM performance across\neight major subject categories on arXiv and five subfields within computer\nscience, one of the most popular categories among them. Our findings reveal a\nconcerning accuracy of LLM-generated responses depending on the subject, with\nsome subjects experiencing significantly lower accuracy than others. Notably,\nClaude-3.5-Sonnet exhibits a substantial advantage in generating both relevant\nand accurate responses. And interestingly, most LLMs achieve a much higher\naccuracy in the Artificial Intelligence sub-field than other sub-fields. This\nbenchmark provides a standardized tool for evaluating the reliability of\nLLM-generated scientific responses, promoting more dependable use of LLMs in\nacademic and research environments. Our code is open-sourced at\nhttps://github.com/arxivBenchLLM/arXivBench and our dataset is available on\nhuggingface at https://huggingface.co/datasets/arXivBenchLLM/arXivBench.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10496v1",
    "published_date": "2025-04-06 05:00:10 UTC",
    "updated_date": "2025-04-06 05:00:10 UTC"
  },
  {
    "arxiv_id": "2504.07131v1",
    "title": "Embedding Reliability Verification Constraints into Generation Expansion Planning",
    "authors": [
      "Peng Liu",
      "Lian Cheng",
      "Benjamin P. Omell",
      "Anthony P. Burgard"
    ],
    "abstract": "Generation planning approaches face challenges in managing the incompatible\nmathematical structures between stochastic production simulations for\nreliability assessment and optimization models for generation planning, which\nhinders the integration of reliability constraints. This study proposes an\napproach to embedding reliability verification constraints into generation\nexpansion planning by leveraging a weighted oblique decision tree (WODT)\ntechnique. For each planning year, a generation mix dataset, labeled with\nreliability assessment simulations, is generated. An WODT model is trained\nusing this dataset. Reliability-feasible regions are extracted via depth-first\nsearch technique and formulated as disjunctive constraints. These constraints\nare then transformed into mixed-integer linear form using a convex hull\nmodeling technique and embedded into a unit commitment-integrated generation\nexpansion planning model. The proposed approach is validated through a\nlong-term generation planning case study for the Electric Reliability Council\nof Texas (ERCOT) region, demonstrating its effectiveness in achieving reliable\nand optimal planning solutions.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages,3 figures. IEEE PES general meeting 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07131v1",
    "published_date": "2025-04-06 04:58:45 UTC",
    "updated_date": "2025-04-06 04:58:45 UTC"
  },
  {
    "arxiv_id": "2504.04351v1",
    "title": "DDPT: Diffusion-Driven Prompt Tuning for Large Language Model Code Generation",
    "authors": [
      "Jinyang Li",
      "Sangwon Hyun",
      "M. Ali Babar"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation. However, the quality of the generated code is heavily\ndependent on the structure and composition of the prompts used. Crafting\nhigh-quality prompts is a challenging task that requires significant knowledge\nand skills of prompt engineering. To advance the automation support for the\nprompt engineering for LLM-based code generation, we propose a novel solution\nDiffusion-Driven Prompt Tuning (DDPT) that learns how to generate optimal\nprompt embedding from Gaussian Noise to automate the prompt engineering for\ncode generation. We evaluate the feasibility of diffusion-based optimization\nand abstract the optimal prompt embedding as a directional vector toward the\noptimal embedding. We use the code generation loss given by the LLMs to help\nthe diffusion model capture the distribution of optimal prompt embedding during\ntraining. The trained diffusion model can build a path from the noise\ndistribution to the optimal distribution at the sampling phrase, the evaluation\nresult demonstrates that DDPT helps improve the prompt optimization for code\ngeneration.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "ICSE CAIN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04351v1",
    "published_date": "2025-04-06 04:19:19 UTC",
    "updated_date": "2025-04-06 04:19:19 UTC"
  },
  {
    "arxiv_id": "2504.04346v2",
    "title": "Crowdsourcing-Based Knowledge Graph Construction for Drug Side Effects Using Large Language Models with an Application on Semaglutide",
    "authors": [
      "Zhijie Duan",
      "Kai Wei",
      "Zhaoqian Xue",
      "Jiayan Zhou",
      "Shu Yang",
      "Siyuan Ma",
      "Jin Jin",
      "Lingyao li"
    ],
    "abstract": "Social media is a rich source of real-world data that captures valuable\npatient experience information for pharmacovigilance. However, mining data from\nunstructured and noisy social media content remains a challenging task. We\npresent a systematic framework that leverages large language models (LLMs) to\nextract medication side effects from social media and organize them into a\nknowledge graph (KG). We apply this framework to semaglutide for weight loss\nusing data from Reddit. Using the constructed knowledge graph, we perform\ncomprehensive analyses to investigate reported side effects across different\nsemaglutide brands over time. These findings are further validated through\ncomparison with adverse events reported in the FAERS database, providing\nimportant patient-centered insights into semaglutide's side effects that\ncomplement its safety profile and current knowledge base of semaglutide for\nboth healthcare professionals and patients. Our work demonstrates the\nfeasibility of using LLMs to transform social media data into structured KGs\nfor pharmacovigilance.",
    "categories": [
      "cs.AI",
      "cs.SI",
      "J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04346v2",
    "published_date": "2025-04-06 03:47:44 UTC",
    "updated_date": "2025-04-08 03:11:32 UTC"
  },
  {
    "arxiv_id": "2504.04336v1",
    "title": "Generative Large Language Models Trained for Detecting Errors in Radiology Reports",
    "authors": [
      "Cong Sun",
      "Kurt Teichman",
      "Yiliang Zhou",
      "Brian Critelli",
      "David Nauheim",
      "Graham Keir",
      "Xindi Wang",
      "Judy Zhong",
      "Adam E Flanders",
      "George Shih",
      "Yifan Peng"
    ],
    "abstract": "In this retrospective study, a dataset was constructed with two parts. The\nfirst part included 1,656 synthetic chest radiology reports generated by GPT-4\nusing specified prompts, with 828 being error-free synthetic reports and 828\ncontaining errors. The second part included 614 reports: 307 error-free reports\nbetween 2011 and 2016 from the MIMIC-CXR database and 307 corresponding\nsynthetic reports with errors generated by GPT-4 on the basis of these\nMIMIC-CXR reports and specified prompts. All errors were categorized into four\ntypes: negation, left/right, interval change, and transcription errors. Then,\nseveral models, including Llama-3, GPT-4, and BiomedBERT, were refined using\nzero-shot prompting, few-shot prompting, or fine-tuning strategies. Finally,\nthe performance of these models was evaluated using the F1 score, 95\\%\nconfidence interval (CI) and paired-sample t-tests on our constructed dataset,\nwith the prediction results further assessed by radiologists. Using zero-shot\nprompting, the fine-tuned Llama-3-70B-Instruct model achieved the best\nperformance with the following F1 scores: 0.769 for negation errors, 0.772 for\nleft/right errors, 0.750 for interval change errors, 0.828 for transcription\nerrors, and 0.780 overall. In the real-world evaluation phase, two radiologists\nreviewed 200 randomly selected reports output by the model. Of these, 99 were\nconfirmed to contain errors detected by the models by both radiologists, and\n163 were confirmed to contain model-detected errors by at least one\nradiologist. Generative LLMs, fine-tuned on synthetic and MIMIC-CXR radiology\nreports, greatly enhanced error detection in radiology reports.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04336v1",
    "published_date": "2025-04-06 03:02:36 UTC",
    "updated_date": "2025-04-06 03:02:36 UTC"
  },
  {
    "arxiv_id": "2504.04335v1",
    "title": "Hallucination Detection using Multi-View Attention Features",
    "authors": [
      "Yuya Ogasa",
      "Yuki Arase"
    ],
    "abstract": "This study tackles token-level hallucination detection in outputs of large\nlanguage models. Previous studies revealed that attention exhibits irregular\npatterns when hallucination occurs. Inspired by this, we extract features from\nthe attention matrix that provide complementary views of (a) the average\nattention each token receives, which helps identify whether certain tokens are\noverly influential or ignored, (b) the diversity of attention each token\nreceives, which reveals whether attention is biased toward specific subsets,\nand (c) the diversity of tokens a token attends to during generation, which\nindicates whether the model references a narrow or broad range of information.\nThese features are input to a Transformer-based classifier to conduct\ntoken-level classification to identify hallucinated spans. Experimental results\nindicate that the proposed method outperforms strong baselines on hallucination\ndetection with longer input contexts, i.e., data-to-text and summarization\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04335v1",
    "published_date": "2025-04-06 03:00:58 UTC",
    "updated_date": "2025-04-06 03:00:58 UTC"
  },
  {
    "arxiv_id": "2504.04332v2",
    "title": "IMPersona: Evaluating Individual Level LM Impersonation",
    "authors": [
      "Quan Shi",
      "Carlos E. Jimenez",
      "Stephen Dong",
      "Brian Seo",
      "Caden Yao",
      "Adam Kelch",
      "Karthik Narasimhan"
    ],
    "abstract": "As language models achieve increasingly human-like capabilities in\nconversational text generation, a critical question emerges: to what extent can\nthese systems simulate the characteristics of specific individuals? To evaluate\nthis, we introduce IMPersona, a framework for evaluating LMs at impersonating\nspecific individuals' writing style and personal knowledge. Using supervised\nfine-tuning and a hierarchical memory-inspired retrieval system, we demonstrate\nthat even modestly sized open-source models, such as Llama-3.1-8B-Instruct, can\nachieve impersonation abilities at concerning levels. In blind conversation\nexperiments, participants (mis)identified our fine-tuned models with memory\nintegration as human in 44.44% of interactions, compared to just 25.00% for the\nbest prompting-based approach. We analyze these results to propose detection\nmethods and defense strategies against such impersonation attempts. Our\nfindings raise important questions about both the potential applications and\nrisks of personalized language models, particularly regarding privacy,\nsecurity, and the ethical deployment of such technologies in real-world\ncontexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 9 pages main",
    "pdf_url": "http://arxiv.org/pdf/2504.04332v2",
    "published_date": "2025-04-06 02:57:58 UTC",
    "updated_date": "2025-04-08 03:29:25 UTC"
  },
  {
    "arxiv_id": "2504.04319v1",
    "title": "Geo-OLM: Enabling Sustainable Earth Observation Studies with Cost-Efficient Open Language Models & State-Driven Workflows",
    "authors": [
      "Dimitrios Stamoulis",
      "Diana Marculescu"
    ],
    "abstract": "Geospatial Copilots hold immense potential for automating Earth observation\n(EO) and climate monitoring workflows, yet their reliance on large-scale models\nsuch as GPT-4o introduces a paradox: tools intended for sustainability studies\noften incur unsustainable costs. Using agentic AI frameworks in geospatial\napplications can amass thousands of dollars in API charges or requires\nexpensive, power-intensive GPUs for deployment, creating barriers for\nresearchers, policymakers, and NGOs. Unfortunately, when geospatial Copilots\nare deployed with open language models (OLMs), performance often degrades due\nto their dependence on GPT-optimized logic. In this paper, we present Geo-OLM,\na tool-augmented geospatial agent that leverages the novel paradigm of\nstate-driven LLM reasoning to decouple task progression from tool calling. By\nalleviating the workflow reasoning burden, our approach enables low-resource\nOLMs to complete geospatial tasks more effectively. When downsizing to small\nmodels below 7B parameters, Geo-OLM outperforms the strongest prior geospatial\nbaselines by 32.8% in successful query completion rates. Our method performs\ncomparably to proprietary models achieving results within 10% of GPT-4o, while\nreducing inference costs by two orders of magnitude from \\$500-\\$1000 to under\n\\$10. We present an in-depth analysis with geospatial downstream benchmarks,\nproviding key insights to help practitioners effectively deploy OLMs for EO\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04319v1",
    "published_date": "2025-04-06 01:31:04 UTC",
    "updated_date": "2025-04-06 01:31:04 UTC"
  },
  {
    "arxiv_id": "2504.04314v1",
    "title": "Balancing Complexity and Informativeness in LLM-Based Clustering: Finding the Goldilocks Zone",
    "authors": [
      "Justin Miller",
      "Tristram Alexander"
    ],
    "abstract": "The challenge of clustering short text data lies in balancing informativeness\nwith interpretability. Traditional evaluation metrics often overlook this\ntrade-off. Inspired by linguistic principles of communicative efficiency, this\npaper investigates the optimal number of clusters by quantifying the trade-off\nbetween informativeness and cognitive simplicity. We use large language models\n(LLMs) to generate cluster names and evaluate their effectiveness through\nsemantic density, information theory, and clustering accuracy. Our results show\nthat Gaussian Mixture Model (GMM) clustering on embeddings generated by a LLM,\nincreases semantic density compared to random assignment, effectively grouping\nsimilar bios. However, as clusters increase, interpretability declines, as\nmeasured by a generative LLM's ability to correctly assign bios based on\ncluster names. A logistic regression analysis confirms that classification\naccuracy depends on the semantic similarity between bios and their assigned\ncluster names, as well as their distinction from alternatives.\n  These findings reveal a \"Goldilocks zone\" where clusters remain distinct yet\ninterpretable. We identify an optimal range of 16-22 clusters, paralleling\nlinguistic efficiency in lexical categorization. These insights inform both\ntheoretical models and practical applications, guiding future research toward\noptimising cluster interpretability and usefulness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.04314v1",
    "published_date": "2025-04-06 01:16:22 UTC",
    "updated_date": "2025-04-06 01:16:22 UTC"
  },
  {
    "arxiv_id": "2504.04311v1",
    "title": "A Survey of Social Cybersecurity: Techniques for Attack Detection, Evaluations, Challenges, and Future Prospects",
    "authors": [
      "Aos Mulahuwaish",
      "Basheer Qolomany",
      "Kevin Gyorick",
      "Jacques Bou Abdo",
      "Mohammed Aledhari",
      "Junaid Qadir",
      "Kathleen Carley",
      "Ala Al-Fuqaha"
    ],
    "abstract": "In today's digital era, the Internet, especially social media platforms,\nplays a significant role in shaping public opinions, attitudes, and beliefs.\nUnfortunately, the credibility of scientific information sources is often\nundermined by the spread of misinformation through various means, including\ntechnology-driven tools like bots, cyborgs, trolls, sock-puppets, and deep\nfakes. This manipulation of public discourse serves antagonistic business\nagendas and compromises civil society. In response to this challenge, a new\nscientific discipline has emerged: social cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04311v1",
    "published_date": "2025-04-06 00:53:09 UTC",
    "updated_date": "2025-04-06 00:53:09 UTC"
  },
  {
    "arxiv_id": "2504.04310v1",
    "title": "CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization",
    "authors": [
      "Weiwei Sun",
      "Shengyu Feng",
      "Shanda Li",
      "Yiming Yang"
    ],
    "abstract": "Although LLM-based agents have attracted significant attention in domains\nsuch as software engineering and machine learning research, their role in\nadvancing combinatorial optimization (CO) remains relatively underexplored.\nThis gap underscores the need for a deeper understanding of their potential in\ntackling structured, constraint-intensive problems-a pursuit currently limited\nby the absence of comprehensive benchmarks for systematic investigation. To\naddress this, we introduce CO-Bench, a benchmark suite featuring 36 real-world\nCO problems drawn from a broad range of domains and complexity levels. CO-Bench\nincludes structured problem formulations and curated data to support rigorous\ninvestigation of LLM agents. We evaluate multiple agent frameworks against\nestablished human-designed algorithms, revealing key strengths and limitations\nof current approaches and identifying promising directions for future research.\nCO-Bench is publicly available at https://github.com/sunnweiwei/CO-Bench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04310v1",
    "published_date": "2025-04-06 00:47:43 UTC",
    "updated_date": "2025-04-06 00:47:43 UTC"
  },
  {
    "arxiv_id": "2504.04308v1",
    "title": "Gating is Weighting: Understanding Gated Linear Attention through In-context Learning",
    "authors": [
      "Yingcong Li",
      "Davoud Ataee Tarzanagh",
      "Ankit Singh Rawat",
      "Maryam Fazel",
      "Samet Oymak"
    ],
    "abstract": "Linear attention methods offer a compelling alternative to softmax attention\ndue to their efficiency in recurrent decoding. Recent research has focused on\nenhancing standard linear attention by incorporating gating while retaining its\ncomputational benefits. Such Gated Linear Attention (GLA) architectures include\ncompetitive models such as Mamba and RWKV. In this work, we investigate the\nin-context learning capabilities of the GLA model and make the following\ncontributions. We show that a multilayer GLA can implement a general class of\nWeighted Preconditioned Gradient Descent (WPGD) algorithms with data-dependent\nweights. These weights are induced by the gating mechanism and the input,\nenabling the model to control the contribution of individual tokens to\nprediction. To further understand the mechanics of this weighting, we introduce\na novel data model with multitask prompts and characterize the optimization\nlandscape of learning a WPGD algorithm. Under mild conditions, we establish the\nexistence and uniqueness (up to scaling) of a global minimum, corresponding to\na unique WPGD solution. Finally, we translate these findings to explore the\noptimization landscape of GLA and shed light on how gating facilitates\ncontext-aware learning and when it is provably better than vanilla linear\nattention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04308v1",
    "published_date": "2025-04-06 00:37:36 UTC",
    "updated_date": "2025-04-06 00:37:36 UTC"
  },
  {
    "arxiv_id": "2504.08786v1",
    "title": "AdaptRec: A Self-Adaptive Framework for Sequential Recommendations with Large Language Models",
    "authors": [
      "Tong Zhang"
    ],
    "abstract": "The recent advancements in Large Language Models (LLMs) have generated\nconsiderable interest in their utilization for sequential recommendation tasks.\nWhile collaborative signals from similar users are central to recommendation\nmodeling, effectively transforming these signals into a format that LLMs can\nunderstand and utilize remains challenging. The critical challenges include\nselecting relevant demonstrations from large-scale user interactions and\nensuring their alignment with LLMs' reasoning process. To address these\nchallenges, we introduce AdaptRec, a self-adaptive fram-ework that leverages\nLLMs for sequential recommendations by incorporating explicit collaborative\nsignals. AdaptRec employs a two-phase user selection mechanism -- User\nSimilarity Retrieval and Self-Adaptive User Selection -- to efficiently\nidentify relevant user sequences in large-scale datasets from multi-metric\nevaluation. We also develop a User-Based Similarity Retrieval Prompt, enabling\nthe model to actively select similar users and continuously refine its\nselection criteria during training. Using the collaborative signals from\nsimilar users, we construct a User-Contextualized Recommendation Prompt that\ntranslates their behavior sequences into natural language, explicitly\nintegrating this information into the recommendation process. Experiments\ndemonstrate AdaptRec's superior performance, with significant improvements in\nHitRatio@1 scores of 7.13\\%, 18.16\\%, and 10.41\\% across real-world datasets\nwith full fine-tuning, and even higher gains of 23.00\\%, 15.97\\%, and 17.98\\%\nin few-shot scenarios.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08786v1",
    "published_date": "2025-04-06 00:30:50 UTC",
    "updated_date": "2025-04-06 00:30:50 UTC"
  }
]