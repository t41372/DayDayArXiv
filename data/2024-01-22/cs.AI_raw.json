[
  {
    "arxiv_id": "2401.12406v1",
    "title": "Enhancing In-context Learning via Linear Probe Calibration",
    "authors": [
      "Momin Abbas",
      "Yi Zhou",
      "Parikshit Ram",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Theodoros Salonidis",
      "Tianyi Chen"
    ],
    "abstract": "In-context learning (ICL) is a new paradigm for natural language processing\nthat utilizes Generative Pre-trained Transformer (GPT)-like models. This\napproach uses prompts that include in-context demonstrations to generate the\ncorresponding output for a new query input. However, applying ICL in real cases\ndoes not scale with the number of samples, and lacks robustness to different\nprompt templates and demonstration permutations. In this paper, we first show\nthat GPT-like models using ICL result in unreliable predictions based on a new\nmetric based on Shannon entropy. Then, to solve this problem, we propose a new\ntechnique called the Linear Probe Calibration (LinC), a method that calibrates\nthe model's output probabilities, resulting in reliable predictions and\nimproved performance, while requiring only minimal additional samples (as few\nas five labeled data samples). LinC significantly enhances the ICL test\nperformance of GPT models on various benchmark datasets, with an average\nimprovement of up to 21%, and up to a 50% improvement in some cases, and\nsignificantly boosts the performance of PEFT methods, especially in the low\nresource regime. Moreover, LinC achieves lower expected calibration error, and\nis highly robust to varying label proportions, prompt templates, and\ndemonstration permutations. Our code is available at\n\\url{https://github.com/mominabbass/LinC}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AISTATS2024",
    "pdf_url": "http://arxiv.org/pdf/2401.12406v1",
    "published_date": "2024-01-22 23:35:09 UTC",
    "updated_date": "2024-01-22 23:35:09 UTC"
  },
  {
    "arxiv_id": "2401.12393v3",
    "title": "Declarative Privacy-Preserving Inference Queries",
    "authors": [
      "Hong Guan",
      "Ansh Tiwari",
      "Summer Gautier",
      "Rajan Hari Ambrish",
      "Lixi Zhou",
      "Yancheng Wang",
      "Deepti Gupta",
      "Yingzhen Yang",
      "Chaowei Xiao",
      "Kanchan Chowdhury",
      "Jia Zou"
    ],
    "abstract": "Detecting inference queries running over personal attributes and protecting\nsuch queries from leaking individual information requires tremendous effort\nfrom practitioners. To tackle this problem, we propose an end-to-end workflow\nfor automating privacy-preserving inference queries including the detection of\nsubqueries that involve AI/ML model inferences on sensitive attributes. Our\nproposed novel declarative privacy-preserving workflow allows users to specify\n\"what private information to protect\" rather than \"how to protect\". Under the\nhood, the system automatically chooses privacy-preserving plans and\nhyper-parameters.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12393v3",
    "published_date": "2024-01-22 22:50:59 UTC",
    "updated_date": "2025-02-18 00:19:20 UTC"
  },
  {
    "arxiv_id": "2401.12392v1",
    "title": "Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing",
    "authors": [
      "Rusheng Zhang",
      "Depu Meng",
      "Shengyin Shen",
      "Tinghan Wang",
      "Tai Karir",
      "Michael Maile",
      "Henry X. Liu"
    ],
    "abstract": "Roadside perception systems are increasingly crucial in enhancing traffic\nsafety and facilitating cooperative driving for autonomous vehicles. Despite\nrapid technological advancements, a major challenge persists for this newly\narising field: the absence of standardized evaluation methods and benchmarks\nfor these systems. This limitation hampers the ability to effectively assess\nand compare the performance of different systems, thus constraining progress in\nthis vital field. This paper introduces a comprehensive evaluation methodology\nspecifically designed to assess the performance of roadside perception systems.\nOur methodology encompasses measurement techniques, metric selection, and\nexperimental trial design, all grounded in real-world field testing to ensure\nthe practical applicability of our approach.\n  We applied our methodology in Mcity\\footnote{\\url{https://mcity.umich.edu/}},\na controlled testing environment, to evaluate various off-the-shelf perception\nsystems. This approach allowed for an in-depth comparative analysis of their\nperformance in realistic scenarios, offering key insights into their respective\nstrengths and limitations. The findings of this study are poised to inform the\ndevelopment of industry-standard benchmarks and evaluation methods, thereby\nenhancing the effectiveness of roadside perception system development and\ndeployment for autonomous vehicles. We anticipate that this paper will\nstimulate essential discourse on standardizing evaluation methods for roadside\nperception systems, thus pushing the frontiers of this technology. Furthermore,\nour results offer both academia and industry a comprehensive understanding of\nthe capabilities of contemporary infrastructure-based perception systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 figures, 8 tables, 14 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.12392v1",
    "published_date": "2024-01-22 22:47:02 UTC",
    "updated_date": "2024-01-22 22:47:02 UTC"
  },
  {
    "arxiv_id": "2401.12379v1",
    "title": "Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis",
    "authors": [
      "Richard Roberson",
      "Gowtham Kaki",
      "Ashutosh Trivedi"
    ],
    "abstract": "This study investigates various approaches to using Large Language Models\n(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights\nderived. Employing the popular Text-to-SQL dataset, spider, the goal was to\ninput a natural language question along with the database schema and output the\ncorrect SQL SELECT query. The initial approach was to fine-tune a local and\nopen-source model to generate the SELECT query. After QLoRa fine-tuning\nWizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy\nfor generated queries rose to a high of 61%. With the second approach, using\nthe fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error\ncorrection), the execution accuracy reached a high of 82.1%. Of all the\nincorrect queries, most can be categorized into a seven different categories of\nwhat went wrong: selecting the wrong columns or wrong order of columns,\ngrouping by the wrong column, predicting the wrong values in conditionals,\nusing different aggregates than the ground truth, extra or too few JOIN\nclauses, inconsistencies in the Spider dataset, and lastly completely incorrect\nquery structure. Most if not all of the queries fall into these categories and\nit is insightful to understanding where the faults still lie with LLM program\nsynthesis and where they can be improved.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12379v1",
    "published_date": "2024-01-22 22:05:42 UTC",
    "updated_date": "2024-01-22 22:05:42 UTC"
  },
  {
    "arxiv_id": "2401.12375v1",
    "title": "Development of an NLP-driven computer-based test guide for visually impaired students",
    "authors": [
      "Tubo Faustinah Nemieboka",
      "Ikechukwu E. Onyenwe",
      "Doris C. Asogwa"
    ],
    "abstract": "In recent years, advancements in Natural Language Processing (NLP) techniques\nhave revolutionized the field of accessibility and exclusivity of testing,\nparticularly for visually impaired students (VIS). CBT has shown in years back\nits relevance in terms of administering exams electronically, making the test\nprocess easier, providing quicker and more accurate results, and offering\ngreater flexibility and accessibility for candidates. Yet, its relevance was\nnot felt by the visually impaired students as they cannot access printed\ndocuments. Hence, in this paper, we present an NLP-driven Computer-Based Test\nguide for visually impaired students. It employs a speech technology\npre-trained methods to provide real-time assistance and support to visually\nimpaired students. The system utilizes NLP technologies to convert the\ntext-based questions and the associated options in a machine-readable format.\nSubsequently, the speech technology pre-trained model processes the converted\ntext enabling the VIS to comprehend and analyze the content. Furthermore, we\nvalidated that this pre-trained model is not perverse by testing for accuracy\nusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with the\nvoice recordings obtained from 20 VIS which is been predicted by the system to\nattain values for precision, recall, and F1-scores. These metrics are used to\nassess the performance of the pre-trained model and have indicated that it is\nproficient enough to give its better performance to the evaluated system. The\nmethodology adopted for this system is Object Oriented Analysis and Design\nMethodology (OOADM) where Objects are discussed and built by modeling\nreal-world instances.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12375v1",
    "published_date": "2024-01-22 21:59:00 UTC",
    "updated_date": "2024-01-22 21:59:00 UTC"
  },
  {
    "arxiv_id": "2401.12344v1",
    "title": "OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection",
    "authors": [
      "Fatema-E Jannat",
      "Sina Gholami",
      "Minhaj Nur Alam",
      "Hamed Tabkhi"
    ],
    "abstract": "Despite the revolutionary impact of AI and the development of locally trained\nalgorithms, achieving widespread generalized learning from multi-modal data in\nmedical AI remains a significant challenge. This gap hinders the practical\ndeployment of scalable medical AI solutions. Addressing this challenge, our\nresearch contributes a self-supervised robust machine learning framework,\nOCT-SelfNet, for detecting eye diseases using optical coherence tomography\n(OCT) images. In this work, various data sets from various institutions are\ncombined enabling a more comprehensive range of representation. Our method\naddresses the issue using a two-phase training approach that combines\nself-supervised pretraining and supervised fine-tuning with a mask autoencoder\nbased on the SwinV2 backbone by providing a solution for real-world clinical\ndeployment. Extensive experiments on three datasets with different encoder\nbackbones, low data settings, unseen data settings, and the effect of\naugmentation show that our method outperforms the baseline model, Resnet-50 by\nconsistently attaining AUC-ROC performance surpassing 77% across all tests,\nwhereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PR\nmetric, our proposed method exceeded 42%, showcasing a substantial increase of\nat least 10% in performance compared to the baseline, which exceeded only 33%.\nThis contributes to our understanding of our approach's potential and\nemphasizes its usefulness in clinical settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.12344v1",
    "published_date": "2024-01-22 20:17:14 UTC",
    "updated_date": "2024-01-22 20:17:14 UTC"
  },
  {
    "arxiv_id": "2401.12340v1",
    "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation",
    "authors": [
      "Shoaib Meraj Sami",
      "Md Mahedi Hasan",
      "Nasser M. Nasrabadi",
      "Raghuveer Rao"
    ],
    "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task,\nprimarily due to the unavailability of labeled data in the target domain.\nHence, it is essential to construct an optimal target domain classifier by\nutilizing the labeled information of the source domain images. The transductive\ntransfer learning (TTL) method that incorporates a CycleGAN-based unpaired\ndomain translation network has been previously proposed in the literature for\neffective ATR annotation. Although this method demonstrates great potential for\nATR, it severely suffers from lower annotation performance, higher Fr\\'echet\nInception Distance (FID) score, and the presence of visual artifacts in the\nsynthetic images. To address these issues, we propose a hybrid contrastive\nlearning base unpaired domain translation (H-CUT) network that achieves a\nsignificantly lower FID score. It incorporates both attention and entropy to\nemphasize the domain-specific region, a noisy feature mixup module to generate\nhigh variational synthetic negative patches, and a modulated noise contrastive\nestimation (MoNCE) loss to reweight all negative patches using optimal\ntransport for better performance. Our proposed contrastive learning and\ncycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks\nand two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and\nidentity losses. In C3TTL, two H-CUT networks have been employed through a\nbijection mapping to feed the reconstructed source domain images into a\npretrained classifier to guide the optimal target domain classifier. Extensive\nexperimental analysis conducted on three ATR datasets demonstrates that the\nproposed C3TTL method is effective in annotating civilian and military\nvehicles, as well as ship targets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "This Paper is Accepted in IEEE TRANSACTIONS ON AEROSPACE AND\n  ELECTRONIC SYSTEMS. This Arxiv version is an older version than the reviewed\n  version",
    "pdf_url": "http://arxiv.org/pdf/2401.12340v1",
    "published_date": "2024-01-22 20:08:57 UTC",
    "updated_date": "2024-01-22 20:08:57 UTC"
  },
  {
    "arxiv_id": "2401.12329v1",
    "title": "Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres",
    "authors": [
      "Holger Billhardt",
      "Alberto Fernández",
      "Pasqual Martí",
      "Javier Prieto Tejedor",
      "Sascha Ossowski"
    ],
    "abstract": "One of the main problems that local authorities of large cities have to face\nis the regulation of urban mobility. They need to provide the means to allow\nfor the efficient movement of people and distribution of goods. However, the\nprovisioning of transportation services needs to take into account general\nglobal objectives, like reducing emissions and having more healthy living\nenvironments, which may not always be aligned with individual interests. Urban\nmobility is usually provided through a transport infrastructure that includes\nall the elements that support mobility. On many occasions, the capacity of the\nelements of this infrastructure is lower than the actual demand and thus\ndifferent transportation activities compete for their use. In this paper, we\nargue that scarce transport infrastructure elements should be assigned\ndynamically and in a prioritised manner to transport activities that have a\nhigher utility from the point of view of society; for example, activities that\nproduce less pollution and provide more value to society. In this paper, we\ndefine a general model for prioritizing the use of a particular type of\ntransportation infrastructure element called time-unlimited elements, whose\nusage time is unknown a priori, and illustrate its dynamics through two use\ncases: vehicle-specific dynamic access restriction in city centres (i) based on\nthe usage levels of available parking spaces and (ii) to assure sustained\nadmissible air quality levels in the city centre. We carry out several\nexperiments using the SUMO traffic simulation tool to evaluate our proposal.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12329v1",
    "published_date": "2024-01-22 19:43:54 UTC",
    "updated_date": "2024-01-22 19:43:54 UTC"
  },
  {
    "arxiv_id": "2401.12326v1",
    "title": "Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection",
    "authors": [
      "Feng Xiong",
      "Thanet Markchom",
      "Ziwei Zheng",
      "Subin Jung",
      "Varun Ojha",
      "Huizhi Liang"
    ],
    "abstract": "SemEval-2024 Task 8 introduces the challenge of identifying machine-generated\ntexts from diverse Large Language Models (LLMs) in various languages and\ndomains. The task comprises three subtasks: binary classification in\nmonolingual and multilingual (Subtask A), multi-class classification (Subtask\nB), and mixed text detection (Subtask C). This paper focuses on Subtask A & B.\nEach subtask is supported by three datasets for training, development, and\ntesting. To tackle this task, two methods: 1) using traditional machine\nlearning (ML) with natural language preprocessing (NLP) for feature extraction,\nand 2) fine-tuning LLMs for text classification. The results show that\ntransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in\neffectiveness, with majority voting being particularly effective in\nmultilingual contexts for identifying machine-generated texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12326v1",
    "published_date": "2024-01-22 19:39:05 UTC",
    "updated_date": "2024-01-22 19:39:05 UTC"
  },
  {
    "arxiv_id": "2401.12324v1",
    "title": "Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis",
    "authors": [
      "Holger Billhardt",
      "José-Antonio Santos",
      "Alberto Fernández",
      "Mar Moreno",
      "Sascha Ossowski",
      "José A. Rodríguez"
    ],
    "abstract": "In recent years many novel applications have appeared that promote the\nprovision of services and activities in a collaborative manner. The key idea\nbehind such systems is to take advantage of idle or underused capacities of\nexisting resources, in order to provide improved services that assist people in\ntheir daily tasks, with additional functionality, enhanced efficiency, and/or\nreduced cost. Particularly in the domain of urban transportation, many\nresearchers have put forward novel ideas, which are then implemented and\nevaluated through prototypes that usually draw upon AI methods and tools.\nHowever, such proposals also bring up multiple non-technical issues that need\nto be identified and addressed adequately if such systems are ever meant to be\napplied to the real world. While, in practice, legal and ethical aspects\nrelated to such AI-based systems are seldomly considered in the beginning of\nthe research and development process, we argue that they not only restrict\ndesign decisions, but can also help guiding them. In this manuscript, we set\nout from a prototype of a taxi coordination service that mediates between\nindividual (and autonomous) taxis and potential customers. After representing\nkey aspects of its operation in a semi-structured manner, we analyse its\nviability from the viewpoint of current legal restrictions and constraints, so\nas to identify additional non-functional requirements as well as options to\naddress them. Then, we go one step ahead, and actually modify the existing\nprototype to incorporate the previously identified recommendations. Performing\nexperiments with this improved system helps us identify the most adequate\noption among several legally admissible alternatives.",
    "categories": [
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12324v1",
    "published_date": "2024-01-22 19:35:28 UTC",
    "updated_date": "2024-01-22 19:35:28 UTC"
  },
  {
    "arxiv_id": "2401.12322v1",
    "title": "Smart Recommendations for Renting Bikes in Bike Sharing Systems",
    "authors": [
      "Holger Billhardt",
      "Alberto Fernández",
      "Sascha Ossowski"
    ],
    "abstract": "Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems\n-- have become increasingly popular in big cities in recent years. On the one\nhand, they provide a cheaper and environmentally friendlier means of\ntransportation than private cars, and on the other hand, they satisfy the\nindividual mobility demands of citizens better than traditional public\ntransport systems. One of their advantages in this regard is their\navailability, e.g., the possibility of taking (or leaving) a vehicle almost\nanywhere in a city. This availability obviously depends on different strategic\nand operational management decisions and policies, such as the dimension of the\nfleet or the (re)distribution of vehicles. Agglutination problems -- where, due\nto usage patterns, available vehicles are concentrated in certain areas,\nwhereas no vehicles are available in others -- are quite common in such\nsystems, and need to be dealt with. Research has been dedicated to this\nproblem, specifying different techniques to reduce imbalanced situations. In\nthis paper, we present and compare strategies for recommending stations to\nusers who wish to rent or return bikes in station-based bike-sharing systems.\nOur first contribution is a novel recommendation strategy based on queuing\ntheory that recommends stations based on their utility to the user in terms of\nlower distance and higher probability of finding a bike or slot. Then, we go\none step further, defining a strategy that recommends stations by combining the\nutility of a particular user with the utility of the global system, measured in\nterms of the improvement in the distribution of bikes and slots with respect to\nthe expected future demand, with the aim of implicitly avoiding or alleviating\nbalancing problems. We present several experiments to evaluate our proposal\nwith real data from the bike sharing system BiciMAD in Madrid.",
    "categories": [
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12322v1",
    "published_date": "2024-01-22 19:29:33 UTC",
    "updated_date": "2024-01-22 19:29:33 UTC"
  },
  {
    "arxiv_id": "2401.12292v2",
    "title": "GRATH: Gradual Self-Truthifying for Large Language Models",
    "authors": [
      "Weixin Chen",
      "Dawn Song",
      "Bo Li"
    ],
    "abstract": "Truthfulness is paramount for large language models (LLMs) as they are\nincreasingly deployed in real-world applications. However, existing LLMs still\nstruggle with generating truthful content, as evidenced by their modest\nperformance on benchmarks like TruthfulQA. To address this issue, we propose\nGRAdual self-truTHifying (GRATH), a novel post-processing method to enhance\ntruthfulness of LLMs. GRATH utilizes out-of-domain question prompts to generate\npairwise truthfulness training data with each pair containing a question and\nits correct and incorrect answers, and then optimizes the model via direct\npreference optimization (DPO) to learn from the truthfulness difference between\nanswer pairs. GRATH iteratively refines truthfulness data and updates the\nmodel, leading to a gradual improvement in model truthfulness in a\nself-supervised manner. Empirically, we evaluate GRATH using different 7B-LLMs\nand compare with LLMs with similar or even larger sizes on benchmark datasets.\nOur results show that GRATH effectively improves LLMs' truthfulness without\ncompromising other core capabilities. Notably, GRATH achieves state-of-the-art\nperformance on TruthfulQA, with MC1 accuracy of 54.71% and MC2 accuracy of\n69.10%, which even surpass those on 70B-LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12292v2",
    "published_date": "2024-01-22 19:00:08 UTC",
    "updated_date": "2024-01-31 06:44:42 UTC"
  },
  {
    "arxiv_id": "2401.12275v2",
    "title": "Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation",
    "authors": [
      "Jiachen Li",
      "Chuanbo Hua",
      "Jianpeng Yao",
      "Hengbo Ma",
      "Jinkyoo Park",
      "Victoria Dax",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "Social robot navigation can be helpful in various contexts of daily life but\nrequires safe human-robot interactions and efficient trajectory planning. While\nmodeling pairwise relations has been widely studied in multi-agent interacting\nsystems, the ability to capture larger-scale group-wise activities is limited.\nIn this paper, we propose a systematic relational reasoning approach with\nexplicit inference of the underlying dynamically evolving relational\nstructures, and we demonstrate its effectiveness for multi-agent trajectory\nprediction and social robot navigation. In addition to the edges between pairs\nof nodes (i.e., agents), we propose to infer hyperedges that adaptively connect\nmultiple nodes to enable group-wise reasoning in an unsupervised manner. Our\napproach infers dynamically evolving relation graphs and hypergraphs to capture\nthe evolution of relations, which the trajectory predictor employs to generate\nfuture states. Meanwhile, we propose to regularize the sharpness and sparsity\nof the learned relations and the smoothness of the relation evolution, which\nproves to enhance training stability and model performance. The proposed\napproach is validated on synthetic crowd simulations and real-world benchmark\ndatasets. Experiments demonstrate that the approach infers reasonable relations\nand achieves state-of-the-art prediction performance. In addition, we present a\ndeep reinforcement learning (DRL) framework for social robot navigation, which\nincorporates relational reasoning and trajectory prediction systematically. In\na group-based crowd simulation, our method outperforms the strongest baseline\nby a significant margin in terms of safety, efficiency, and social compliance\nin dense, interactive scenarios. We also demonstrate the practical\napplicability of our method with real-world robot experiments. The code and\nvideos can be found at https://relational-reasoning-nav.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://relational-reasoning-nav.github.io/; 20\n  pages, 9 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.12275v2",
    "published_date": "2024-01-22 18:58:22 UTC",
    "updated_date": "2024-11-11 18:59:07 UTC"
  },
  {
    "arxiv_id": "2401.12205v1",
    "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
    "authors": [
      "Animesh Basak Chowdhury",
      "Marco Romanelli",
      "Benjamin Tan",
      "Ramesh Karri",
      "Siddharth Garg"
    ],
    "abstract": "Logic synthesis, a pivotal stage in chip design, entails optimizing chip\nspecifications encoded in hardware description languages like Verilog into\nhighly efficient implementations using Boolean logic gates. The process\ninvolves a sequential application of logic minimization heuristics (``synthesis\nrecipe\"), with their arrangement significantly impacting crucial metrics such\nas area and delay. Addressing the challenge posed by the broad spectrum of\ndesign complexities - from variations of past designs (e.g., adders and\nmultipliers) to entirely novel configurations (e.g., innovative processor\ninstructions) - requires a nuanced `synthesis recipe` guided by human expertise\nand intuition. This study conducts a thorough examination of learning and\nsearch techniques for logic synthesis, unearthing a surprising revelation:\npre-trained agents, when confronted with entirely novel designs, may veer off\ncourse, detrimentally affecting the search trajectory. We present ABC-RL, a\nmeticulously tuned $\\alpha$ parameter that adeptly adjusts recommendations from\npre-trained agents during the search process. Computed based on similarity\nscores through nearest neighbor retrieval from the training dataset, ABC-RL\nyields superior synthesis recipes tailored for a wide array of hardware\ndesigns. Our findings showcase substantial enhancements in the\nQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to\n24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an\nimpressive up to 9x reduction in runtime (iso-QoR) when compared to current\nstate-of-the-art methodologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.12205v1",
    "published_date": "2024-01-22 18:46:30 UTC",
    "updated_date": "2024-01-22 18:46:30 UTC"
  },
  {
    "arxiv_id": "2401.12203v1",
    "title": "Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources",
    "authors": [
      "Víctor Samuel Pérez-Díaz",
      "Juan Rafael Martínez-Galarza",
      "Alexander Caicedo",
      "Raffaele D'Abrusco"
    ],
    "abstract": "The automatic classification of X-ray detections is a necessary step in\nextracting astrophysical information from compiled catalogs of astrophysical\nsources. Classification is useful for the study of individual objects,\nstatistics for population studies, as well as for anomaly detection, i.e., the\nidentification of new unexplored phenomena, including transients and spectrally\nextreme sources. Despite the importance of this task, classification remains\nchallenging in X-ray astronomy due to the lack of optical counterparts and\nrepresentative training sets. We develop an alternative methodology that\nemploys an unsupervised machine learning approach to provide probabilistic\nclasses to Chandra Source Catalog sources with a limited number of labeled\nsources, and without ancillary information from optical and infrared catalogs.\nWe provide a catalog of probabilistic classes for 8,756 sources, comprising a\ntotal of 14,507 detections, and demonstrate the success of the method at\nidentifying emission from young stellar objects, as well as distinguishing\nbetween small-scale and large-scale compact accretors with a significant level\nof confidence. We investigate the consistency between the distribution of\nfeatures among classified objects and well-established astrophysical hypotheses\nsuch as the unified AGN model. This provides interpretability to the\nprobabilistic classifier. Code and tables are available publicly through\nGitHub. We provide a web playground for readers to explore our final\nclassification at https://umlcaxs-playground.streamlit.app.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "21 pages, 11 figures. Accepted in MNRAS",
    "pdf_url": "http://arxiv.org/pdf/2401.12203v1",
    "published_date": "2024-01-22 18:42:31 UTC",
    "updated_date": "2024-01-22 18:42:31 UTC"
  },
  {
    "arxiv_id": "2401.12202v2",
    "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
    "authors": [
      "Peiqi Liu",
      "Yaswanth Orru",
      "Jay Vakil",
      "Chris Paxton",
      "Nur Muhammad Mahi Shafiullah",
      "Lerrel Pinto"
    ],
    "abstract": "Remarkable progress has been made in recent years in the fields of vision,\nlanguage, and robotics. We now have vision models capable of recognizing\nobjects based on language queries, navigation systems that can effectively\ncontrol mobile systems, and grasping models that can handle a wide range of\nobjects. Despite these advancements, general-purpose applications of robotics\nstill lag behind, even though they rely on these fundamental capabilities of\nrecognition, navigation, and grasping. In this paper, we adopt a systems-first\napproach to develop a new Open Knowledge-based robotics framework called\nOK-Robot. By combining Vision-Language Models (VLMs) for object detection,\nnavigation primitives for movement, and grasping primitives for object\nmanipulation, OK-Robot offers a integrated solution for pick-and-drop\noperations without requiring any training. To evaluate its performance, we run\nOK-Robot in 10 real-world home environments. The results demonstrate that\nOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,\nrepresenting a new state-of-the-art in Open Vocabulary Mobile Manipulation\n(OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered\nenvironments, OK-Robot's performance increases to 82%. However, the most\nimportant insight gained from OK-Robot is the critical role of nuanced details\nwhen combining Open Knowledge systems like VLMs with robotic modules. Videos of\nour experiments and code are available on our website:\nhttps://ok-robot.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Github repo: https://github.com/ok-robot/ok-robot",
    "pdf_url": "http://arxiv.org/pdf/2401.12202v2",
    "published_date": "2024-01-22 18:42:20 UTC",
    "updated_date": "2024-02-29 17:20:08 UTC"
  },
  {
    "arxiv_id": "2401.12192v4",
    "title": "Text Embedding Inversion Security for Multilingual Language Models",
    "authors": [
      "Yiyi Chen",
      "Heather Lent",
      "Johannes Bjerva"
    ],
    "abstract": "Textual data is often represented as real-numbered embeddings in NLP,\nparticularly with the popularity of large language models (LLMs) and Embeddings\nas a Service (EaaS). However, storing sensitive information as embeddings can\nbe susceptible to security breaches, as research shows that text can be\nreconstructed from embeddings, even without knowledge of the underlying model.\nWhile defence mechanisms have been explored, these are exclusively focused on\nEnglish, leaving other languages potentially exposed to attacks. This work\nexplores LLM security through multilingual embedding inversion. We define the\nproblem of black-box multilingual and cross-lingual inversion attacks, and\nexplore their potential implications. Our findings suggest that multilingual\nLLMs may be more vulnerable to inversion attacks, in part because English-based\ndefences may be ineffective. To alleviate this, we propose a simple masking\ndefense effective for both monolingual and multilingual models. This study is\nthe first to investigate multilingual inversion attacks, shedding light on the\ndifferences in attacks and defenses across monolingual and multilingual\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 17 Tables, 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12192v4",
    "published_date": "2024-01-22 18:34:42 UTC",
    "updated_date": "2024-06-05 10:22:00 UTC"
  },
  {
    "arxiv_id": "2401.12187v1",
    "title": "WARM: On the Benefits of Weight Averaged Reward Models",
    "authors": [
      "Alexandre Ramé",
      "Nino Vieillard",
      "Léonard Hussenot",
      "Robert Dadashi",
      "Geoffrey Cideron",
      "Olivier Bachem",
      "Johan Ferret"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences through\nreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit\nfailures in the reward model (RM) to achieve seemingly high rewards without\nmeeting the underlying objectives. We identify two primary challenges when\ndesigning RMs to mitigate reward hacking: distribution shifts during the RL\nprocess and inconsistencies in human preferences. As a solution, we propose\nWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then\naveraging them in the weight space. This strategy follows the observation that\nfine-tuned weights remain linearly mode connected when sharing the same\npre-training. By averaging weights, WARM improves efficiency compared to the\ntraditional ensembling of predictions, while improving reliability under\ndistribution shifts and robustness to preference inconsistencies. Our\nexperiments on summarization tasks, using best-of-N and RL methods, shows that\nWARM improves the overall quality and alignment of LLM predictions; for\nexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy\nRL fine-tuned with a single RM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12187v1",
    "published_date": "2024-01-22 18:27:08 UTC",
    "updated_date": "2024-01-22 18:27:08 UTC"
  },
  {
    "arxiv_id": "2401.12181v1",
    "title": "Universal Neurons in GPT2 Language Models",
    "authors": [
      "Wes Gurnee",
      "Theo Horsley",
      "Zifan Carl Guo",
      "Tara Rezaei Kheirkhah",
      "Qinyi Sun",
      "Will Hathaway",
      "Neel Nanda",
      "Dimitris Bertsimas"
    ],
    "abstract": "A basic question within the emerging field of mechanistic interpretability is\nthe degree to which neural networks learn the same underlying mechanisms. In\nother words, are neural mechanisms universal across different models? In this\nwork, we study the universality of individual neurons across GPT2 models\ntrained from different initial random seeds, motivated by the hypothesis that\nuniversal neurons are likely to be interpretable. In particular, we compute\npairwise correlations of neuron activations over 100 million tokens for every\nneuron pair across five different seeds and find that 1-5\\% of neurons are\nuniversal, that is, pairs of neurons which consistently activate on the same\ninputs. We then study these universal neurons in detail, finding that they\nusually have clear interpretations and taxonomize them into a small number of\nneuron families. We conclude by studying patterns in neuron weights to\nestablish several universal functional roles of neurons in simple circuits:\ndeactivating attention heads, changing the entropy of the next token\ndistribution, and predicting the next token to (not) be within a particular\nset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12181v1",
    "published_date": "2024-01-22 18:11:01 UTC",
    "updated_date": "2024-01-22 18:11:01 UTC"
  },
  {
    "arxiv_id": "2401.12179v2",
    "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
    "authors": [
      "Zachary Novack",
      "Julian McAuley",
      "Taylor Berg-Kirkpatrick",
      "Nicholas J. Bryan"
    ],
    "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose\nframe-work for controlling pre-trained text-to-music diffusion models at\ninference-time via optimizing initial noise latents. Our method can be used to\noptimize through any differentiable feature matching loss to achieve a target\n(stylized) output and leverages gradient checkpointing for memory efficiency.\nWe demonstrate a surprisingly wide-range of applications for music generation\nincluding inpainting, outpainting, and looping as well as intensity, melody,\nand musical structure control - all without ever fine-tuning the underlying\nmodel. When we compare our approach against related training, guidance, and\noptimization-based methods, we find DITTO achieves state-of-the-art performance\non nearly all tasks, including outperforming comparable approaches on\ncontrollability, audio quality, and computational efficiency, thus opening the\ndoor for high-quality, flexible, training-free control of diffusion models.\nSound examples can be found at https://DITTO-Music.github.io/web/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Oral at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.12179v2",
    "published_date": "2024-01-22 18:10:10 UTC",
    "updated_date": "2024-06-03 17:37:53 UTC"
  },
  {
    "arxiv_id": "2401.12178v1",
    "title": "In-Context Learning for Extreme Multi-Label Classification",
    "authors": [
      "Karel D'Oosterlinck",
      "Omar Khattab",
      "François Remy",
      "Thomas Demeester",
      "Chris Develder",
      "Christopher Potts"
    ],
    "abstract": "Multi-label classification problems with thousands of classes are hard to\nsolve with in-context learning alone, as language models (LMs) might lack prior\nknowledge about the precise classes or how to assign them, and it is generally\ninfeasible to demonstrate every class in a prompt. We propose a general\nprogram, $\\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactions\nbetween LMs and retrievers to efficiently tackle such problems. We implement\nthis program using the $\\texttt{DSPy}$ programming model, which specifies\nin-context systems in a declarative manner, and use $\\texttt{DSPy}$ optimizers\nto tune it towards specific datasets by bootstrapping only tens of few-shot\nexamples. Our primary extreme classification program, optimized separately for\neach task, attains state-of-the-art results across three benchmarks (HOUSE,\nTECH, TECHWOLF). We apply the same program to a benchmark with vastly different\ncharacteristics and attain competitive performance as well (BioDEX). Unlike\nprior work, our proposed solution requires no finetuning, is easily applicable\nto new tasks, alleviates prompt engineering, and requires only tens of labeled\nexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12178v1",
    "published_date": "2024-01-22 18:09:52 UTC",
    "updated_date": "2024-01-22 18:09:52 UTC"
  },
  {
    "arxiv_id": "2401.12176v1",
    "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
    "authors": [
      "Tahereh Zarrat Ehsan",
      "Seyed Mehdi Mohtavipour"
    ],
    "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal\nchicken health conditions, minimizing economic losses and bolstering\nprofitability. This paper presents a novel real-time framework for analyzing\nchicken behavior in cage-free poultry houses to detect abnormal behaviors.\nSpecifically, two significant abnormalities, namely inactive broiler and\nhuddling behavior, are investigated in this study. The proposed framework\ncomprises three key steps: (1) chicken detection utilizing a state-of-the-art\ndeep learning model, (2) tracking individual chickens across consecutive frames\nwith a fast tracker module, and (3) detecting abnormal behaviors within the\nvideo stream. Experimental studies are conducted to evaluate the efficacy of\nthe proposed algorithm in accurately assessing chicken behavior. The results\nillustrate that our framework provides a precise and efficient solution for\nreal-time anomaly detection, facilitating timely interventions to maintain\nchicken health and enhance overall productivity on poultry farms. Github:\nhttps://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12176v1",
    "published_date": "2024-01-22 18:09:15 UTC",
    "updated_date": "2024-01-22 18:09:15 UTC"
  },
  {
    "arxiv_id": "2401.12170v1",
    "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems",
    "authors": [
      "Raphaël Berthon",
      "Joost-Pieter Katoen",
      "Munyque Mittelmann",
      "Aniello Murano"
    ],
    "abstract": "Strategies synthesized using formal methods can be complex and often require\ninfinite memory, which does not correspond to the expected behavior when trying\nto model Multi-Agent Systems (MAS). To capture such behaviors, natural\nstrategies are a recently proposed framework striking a balance between the\nability of agents to strategize with memory and the model-checking complexity,\nbut until now has been restricted to fully deterministic settings. For the\nfirst time, we consider the probabilistic temporal logics PATL and PATL* under\nnatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,\nin stochastic MAS, NatPATL model-checking is NP-complete when the active\ncoalition is restricted to deterministic strategies. We also give a 2NEXPTIME\ncomplexity result for NatPATL* with the same restriction. In the unrestricted\ncase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for\nNatPATL*.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Extended version of the paper accepted at AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.12170v1",
    "published_date": "2024-01-22 18:04:26 UTC",
    "updated_date": "2024-01-22 18:04:26 UTC"
  },
  {
    "arxiv_id": "2401.12164v1",
    "title": "Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE",
    "authors": [
      "Hong Wei",
      "James Xiao",
      "Yichao Zhang",
      "Xia Hong"
    ],
    "abstract": "Image segmentation is a clustering task whereby each pixel is assigned a\ncluster label. Remote sensing data usually consists of multiple bands of\nspectral images in which there exist semantically meaningful land cover\nsubregions, co-registered with other source data such as LIDAR (LIght Detection\nAnd Ranging) data, where available. This suggests that, in order to account for\nspatial correlation between pixels, a feature vector associated with each pixel\nmay be a vectorized tensor representing the multiple bands and a local patch as\nappropriate. Similarly, multiple types of texture features based on a pixel's\nlocal patch would also be beneficial for encoding locally statistical\ninformation and spatial variations, without necessarily labelling pixel-wise a\nlarge amount of ground truth, then training a supervised model, which is\nsometimes impractical. In this work, by resorting to label only a small\nquantity of pixels, a new semi-supervised segmentation approach is proposed.\nInitially, over all pixels, an image data matrix is created in high dimensional\nfeature space. Then, t-SNE projects the high dimensional data onto 3D\nembedding. By using radial basis functions as input features, which use the\nlabelled data samples as centres, to pair with the output class labels, a\nmodified canonical correlation analysis algorithm, referred to as RBF-CCA, is\nintroduced which learns the associated projection matrix via the small labelled\ndata set. The associated canonical variables, obtained for the full image, are\napplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA\nalgorithm has been implemented on several remotely sensed multispectral images,\ndemonstrating excellent segmentation results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12164v1",
    "published_date": "2024-01-22 17:56:07 UTC",
    "updated_date": "2024-01-22 17:56:07 UTC"
  },
  {
    "arxiv_id": "2401.12132v1",
    "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
    "authors": [
      "John D. Mayfield",
      "Issam El Naqa"
    ],
    "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term\nMemory (LSTM) models were studied to provide sequential relationships for each\ntimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot\nstudy, we compared three QCNN-LSTM models for binary classification of MS\ndisability benchmarked against classical neural network architectures. Our\nhypothesis is that quantum models will provide competitive performance. Methods\nMatrix Product State (MPS), reverse Multistate Entanglement Renormalization\nAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM\nlayer to process near-annual MRI data of patients diagnosed with MS. These were\nbenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision\nTransformer (ViViT). Predicted logits were measured against ground truth labels\nof each patient's Extended Disability Severity Score (EDSS) using binary\ncross-entropy loss. Training/validation/holdout testing was partitioned using\n5-fold cross validation with a total split of 60:20:20. Levene's test of\nvariance was used to measure statistical difference and Student's t-test for\npaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and\nTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively\n(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73\nand 0.77, respectively (p-value 0.631). Overall variance and mean were not\nstatistically significant (p-value 0.713), however, time to train was\nsignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,\nrespectively, p-value <0.001). Conclusion QCNN-LSTM models perform\ncompetitively to their classical counterparts with greater efficiency in train\ntime. Clinically, these can add value in terms of efficiency to time-dependent\ndeep learning prediction of disease progression based upon medical imaging.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "eess.IV",
      "I.2.0; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12132v1",
    "published_date": "2024-01-22 17:14:47 UTC",
    "updated_date": "2024-01-22 17:14:47 UTC"
  },
  {
    "arxiv_id": "2401.12273v2",
    "title": "The Ethics of Interaction: Mitigating Security Threats in LLMs",
    "authors": [
      "Ashutosh Kumar",
      "Shiv Vignesh Murthy",
      "Sagarika Singh",
      "Swathy Ragupathy"
    ],
    "abstract": "This paper comprehensively explores the ethical challenges arising from\nsecurity threats to Large Language Models (LLMs). These intricate digital\nrepositories are increasingly integrated into our daily lives, making them\nprime targets for attacks that can compromise their training data and the\nconfidentiality of their data sources. The paper delves into the nuanced\nethical repercussions of such security threats on society and individual\nprivacy. We scrutinize five major threats--prompt injection, jailbreaking,\nPersonal Identifiable Information (PII) exposure, sexually explicit content,\nand hate-based content--going beyond mere identification to assess their\ncritical ethical consequences and the urgency they create for robust defensive\nstrategies. The escalating reliance on LLMs underscores the crucial need for\nensuring these systems operate within the bounds of ethical norms, particularly\nas their misuse can lead to significant societal and individual harm. We\npropose conceptualizing and developing an evaluative tool tailored for LLMs,\nwhich would serve a dual purpose: guiding developers and designers in\npreemptive fortification of backend systems and scrutinizing the ethical\ndimensions of LLM chatbot responses during the testing phase. By comparing LLM\nresponses with those expected from humans in a moral context, we aim to discern\nthe degree to which AI behaviors align with the ethical values held by a\nbroader society. Ultimately, this paper not only underscores the ethical\ntroubles presented by LLMs; it also highlights a path toward cultivating trust\nin these systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12273v2",
    "published_date": "2024-01-22 17:11:37 UTC",
    "updated_date": "2024-07-10 09:07:52 UTC"
  },
  {
    "arxiv_id": "2401.12113v2",
    "title": "Extracting Formulae in Many-Valued Logic from Deep Neural Networks",
    "authors": [
      "Yani Zhang",
      "Helmut Bölcskei"
    ],
    "abstract": "We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "Signicant extension of the previous version",
    "pdf_url": "http://arxiv.org/pdf/2401.12113v2",
    "published_date": "2024-01-22 16:51:01 UTC",
    "updated_date": "2025-03-06 11:33:28 UTC"
  },
  {
    "arxiv_id": "2401.12108v1",
    "title": "On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using Streaming Data",
    "authors": [
      "Jeremias Dötterl",
      "Ralf Bruns",
      "Jürgen Dunkel",
      "Sascha Ossowski"
    ],
    "abstract": "In parcel delivery, the \"last mile\" from the parcel hub to the customer is\ncostly, especially for time-sensitive delivery tasks that have to be completed\nwithin hours after arrival. Recently, crowdshipping has attracted increased\nattention as a new alternative to traditional delivery modes. In crowdshipping,\nprivate citizens (\"the crowd\") perform short detours in their daily lives to\ncontribute to parcel delivery in exchange for small incentives. However,\nachieving desirable crowd behavior is challenging as the crowd is highly\ndynamic and consists of autonomous, self-interested individuals. Leveraging\ncrowdshipping for time-sensitive deliveries remains an open challenge. In this\npaper, we present an agent-based approach to on-time parcel delivery with\ncrowds. Our system performs data stream processing on the couriers' smartphone\nsensor data to predict delivery delays. Whenever a delay is predicted, the\nsystem attempts to forge an agreement for transferring the parcel from the\ncurrent deliverer to a more promising courier nearby. Our experiments show that\nthrough accurate delay predictions and purposeful task transfers many delays\ncan be prevented that would occur without our approach.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12108v1",
    "published_date": "2024-01-22 16:45:15 UTC",
    "updated_date": "2024-01-22 16:45:15 UTC"
  },
  {
    "arxiv_id": "2401.12086v2",
    "title": "West-of-N: Synthetic Preferences for Self-Improving Reward Models",
    "authors": [
      "Alizée Pace",
      "Jonathan Mallinson",
      "Eric Malmi",
      "Sebastian Krause",
      "Aliaksei Severyn"
    ],
    "abstract": "The success of reinforcement learning from human feedback (RLHF) in language\nmodel alignment is strongly dependent on the quality of the underlying reward\nmodel. In this paper, we present a novel approach to improve reward model\nquality by generating synthetic preference data, thereby augmenting the\ntraining dataset with on-policy, high-quality preference pairs. Motivated by\nthe promising results of Best-of-N sampling strategies in language model\ntraining, we extend their application to reward model training. This results in\na self-training strategy to generate preference pairs by selecting the best and\nworst candidates in a pool of responses to a given query. Empirically, we find\nthat this approach improves the performance of any reward model, with an effect\ncomparable to the addition of a similar quantity of human preference data. This\nwork opens up new avenues of research for improving RLHF for language model\nalignment, by offering synthetic preference generation as a solution to reward\nmodeling challenges.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12086v2",
    "published_date": "2024-01-22 16:24:43 UTC",
    "updated_date": "2024-10-25 12:04:26 UTC"
  },
  {
    "arxiv_id": "2401.12070v3",
    "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text",
    "authors": [
      "Abhimanyu Hans",
      "Avi Schwarzschild",
      "Valeriia Cherepanova",
      "Hamid Kazemi",
      "Aniruddha Saha",
      "Micah Goldblum",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "abstract": "Detecting text generated by modern large language models is thought to be\nhard, as both LLMs and humans can exhibit a wide range of complex behaviors.\nHowever, we find that a score based on contrasting two closely related language\nmodels is highly accurate at separating human-generated and machine-generated\ntext. Based on this mechanism, we propose a novel LLM detector that only\nrequires simple calculations using a pair of pre-trained LLMs. The method,\ncalled Binoculars, achieves state-of-the-art accuracy without any training\ndata. It is capable of spotting machine text from a range of modern LLMs\nwithout any model-specific modifications. We comprehensively evaluate\nBinoculars on a number of text sources and in varied situations. Over a wide\nrange of document types, Binoculars detects over 90% of generated samples from\nChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being\ntrained on any ChatGPT data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, code available at https://github.com/ahans30/Binoculars",
    "pdf_url": "http://arxiv.org/pdf/2401.12070v3",
    "published_date": "2024-01-22 16:09:47 UTC",
    "updated_date": "2024-10-13 19:12:59 UTC"
  },
  {
    "arxiv_id": "2401.12051v1",
    "title": "CloSe: A 3D Clothing Segmentation Dataset and Model",
    "authors": [
      "Dimitrije Antić",
      "Garvita Tiwari",
      "Batuhan Ozcomlekci",
      "Riccardo Marin",
      "Gerard Pons-Moll"
    ],
    "abstract": "3D Clothing modeling and datasets play crucial role in the entertainment,\nanimation, and digital fashion industries. Existing work often lacks detailed\nsemantic understanding or uses synthetic datasets, lacking realism and\npersonalization. To address this, we first introduce CloSe-D: a novel\nlarge-scale dataset containing 3D clothing segmentation of 3167 scans, covering\na range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,\nthe first learning-based 3D clothing segmentation model for fine-grained\nsegmentation from colored point clouds. CloSe-Net uses local point features,\nbody-clothing correlation, and a garment-class and point features-based\nattention module, improving performance over baselines and prior work. The\nproposed attention module enables our model to learn appearance and\ngeometry-dependent clothing prior from data. We further validate the efficacy\nof our approach by successfully segmenting publicly available datasets of\npeople in clothing. We also introduce CloSe-T, a 3D interactive tool for\nrefining segmentation labels. Combining the tool with CloSe-T in a continual\nlearning setup demonstrates improved generalization on real-world data.\nDataset, model, and tool can be found at\nhttps://virtualhumans.mpi-inf.mpg.de/close3dv24/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12051v1",
    "published_date": "2024-01-22 15:42:21 UTC",
    "updated_date": "2024-01-22 15:42:21 UTC"
  },
  {
    "arxiv_id": "2402.10067v1",
    "title": "LLM-based policy generation for intent-based management of applications",
    "authors": [
      "Kristina Dzeparoska",
      "Jieyu Lin",
      "Ali Tizghadam",
      "Alberto Leon-Garcia"
    ],
    "abstract": "Automated management requires decomposing high-level user requests, such as\nintents, to an abstraction that the system can understand and execute. This is\nchallenging because even a simple intent requires performing a number of\nordered steps. And the task of identifying and adapting these steps (as\nconditions change) requires a decomposition approach that cannot be exactly\npre-defined beforehand. To tackle these challenges and support automated intent\ndecomposition and execution, we explore the few-shot capability of Large\nLanguage Models (LLMs). We propose a pipeline that progressively decomposes\nintents by generating the required actions using a policy-based abstraction.\nThis allows us to automate the policy execution by creating a closed control\nloop for the intent deployment. To do so, we generate and map the policies to\nAPIs and form application management loops that perform the necessary\nmonitoring, analysis, planning and execution. We evaluate our proposal with a\nuse-case to fulfill and assure an application service chain of virtual network\nfunctions. Using our approach, we can generalize and generate the necessary\nsteps to realize intents, thereby enabling intent automation for application\nmanagement.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.FL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "This article has been accepted for publication in 2023 19th\n  International Conference on Network and Service Management (CNSM), 3rd\n  International Workshop on Analytics for Service and Application Management\n  (AnServApp 2023)",
    "pdf_url": "http://arxiv.org/pdf/2402.10067v1",
    "published_date": "2024-01-22 15:37:04 UTC",
    "updated_date": "2024-01-22 15:37:04 UTC"
  },
  {
    "arxiv_id": "2402.01688v1",
    "title": "An Online Hierarchical Energy Management System for Energy Communities, Complying with the Current Technical Legislation Framework",
    "authors": [
      "Antonino Capillo",
      "Enrico De Santis",
      "Fabio Massimo Frattale Mascioli",
      "Antonello Rizzi"
    ],
    "abstract": "Efforts in the fight against Climate Change are increasingly oriented towards\nnew energy efficiency strategies in Smart Grids (SGs). In 2018, with proper\nlegislation, the European Union (EU) defined the Renewable Energy Community\n(REC) as a local electrical grid whose participants share their self-produced\nrenewable energy, aiming at reducing bill costs by taking advantage of proper\nincentives. That action aspires to accelerate the spread of local renewable\nenergy exploitation, whose costs could not be within everyone's reach. Since a\nREC is technically an SG, the strategies above can be applied, and\nspecifically, practical Energy Management Systems (EMSs) are required.\nTherefore, in this work, an online Hierarchical EMS (HEMS) is synthesized for\nREC cost minimization to evaluate its superiority over a local self-consumption\napproach. EU technical indications (as inherited from Italy) are diligently\nfollowed, aiming for results that are as realistic as possible. Power flows\nbetween REC nodes, or Microgrids (MGs) are optimized by taking Energy Storage\nSystems (ESSs) and PV plant costs, energy purchase costs, and REC incentives. A\nhybrid Fuzzy Inference System - Genetic Algorithm (FIS-GA) model is implemented\nwith the GA encoding the FIS parameters. Power generation and consumption,\nwhich are the overall system input, are predicted by a LSTM trained on\nhistorical data. The proposed hierarchical model achieves good precision in\nshort computation times and outperforms the self-consumption approach, leading\nto about 20% savings compared to the latter. In addition, the Explainable AI\n(XAI), which characterizes the model through the FIS, makes results more\nreliable thanks to an excellent human interpretation level. To finish, the HEMS\nis parametrized so that it is straightforward to switch to another Country's\ntechnical legislation framework.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "26 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01688v1",
    "published_date": "2024-01-22 15:29:54 UTC",
    "updated_date": "2024-01-22 15:29:54 UTC"
  },
  {
    "arxiv_id": "2401.12032v1",
    "title": "MINT: A wrapper to make multi-modal and multi-image AI models interactive",
    "authors": [
      "Jan Freyberg",
      "Abhijit Guha Roy",
      "Terry Spitz",
      "Beverly Freeman",
      "Mike Schaekermann",
      "Patricia Strachan",
      "Eva Schnider",
      "Renee Wong",
      "Dale R Webster",
      "Alan Karthikesalingam",
      "Yun Liu",
      "Krishnamurthy Dvijotham",
      "Umesh Telang"
    ],
    "abstract": "During the diagnostic process, doctors incorporate multimodal information\nincluding imaging and the medical history - and similarly medical AI\ndevelopment has increasingly become multimodal. In this paper we tackle a more\nsubtle challenge: doctors take a targeted medical history to obtain only the\nmost pertinent pieces of information; how do we enable AI to do the same? We\ndevelop a wrapper method named MINT (Make your model INTeractive) that\nautomatically determines what pieces of information are most valuable at each\nstep, and ask for only the most useful information. We demonstrate the efficacy\nof MINT wrapping a skin disease prediction model, where multiple images and a\nset of optional answers to $25$ standard metadata questions (i.e., structured\nmedical history) are used by a multi-modal deep network to provide a\ndifferential diagnosis. We show that MINT can identify whether metadata inputs\nare needed and if so, which question to ask next. We also demonstrate that when\ncollecting multiple images, MINT can identify if an additional image would be\nbeneficial, and if so, which type of image to capture. We showed that MINT\nreduces the number of metadata and image inputs needed by 82% and 36.2%\nrespectively, while maintaining predictive performance. Using real-world AI\ndermatology system data, we show that needing fewer inputs can retain users\nthat may otherwise fail to complete the system submission and drop off without\na diagnosis. Qualitative examples show MINT can closely mimic the step-by-step\ndecision making process of a clinical workflow and how this is different for\nstraight forward cases versus more difficult, ambiguous cases. Finally we\ndemonstrate how MINT is robust to different underlying multi-model classifiers\nand can be easily adapted to user requirements without significant model\nre-training.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.12032v1",
    "published_date": "2024-01-22 15:17:54 UTC",
    "updated_date": "2024-01-22 15:17:54 UTC"
  },
  {
    "arxiv_id": "2401.12024v1",
    "title": "Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training",
    "authors": [
      "Vedant Dave",
      "Fotios Lygerakis",
      "Elmar Rueckert"
    ],
    "abstract": "The rapidly evolving field of robotics necessitates methods that can\nfacilitate the fusion of multiple modalities. Specifically, when it comes to\ninteracting with tangible objects, effectively combining visual and tactile\nsensory data is key to understanding and navigating the complex dynamics of the\nphysical world, enabling a more nuanced and adaptable response to changing\nenvironments. Nevertheless, much of the earlier work in merging these two\nsensory modalities has relied on supervised methods utilizing datasets labeled\nby humans.This paper introduces MViTac, a novel methodology that leverages\ncontrastive learning to integrate vision and touch sensations in a\nself-supervised fashion. By availing both sensory inputs, MViTac leverages\nintra and inter-modality losses for learning representations, resulting in\nenhanced material property classification and more adept grasping prediction.\nThrough a series of experiments, we showcase the effectiveness of our method\nand its superiority over existing state-of-the-art self-supervised and\nsupervised techniques. In evaluating our methodology, we focus on two distinct\ntasks: material classification and grasping success prediction. Our results\nindicate that MViTac facilitates the development of improved modality encoders,\nyielding more robust representations as evidenced by linear probing\nassessments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12024v1",
    "published_date": "2024-01-22 15:11:57 UTC",
    "updated_date": "2024-01-22 15:11:57 UTC"
  },
  {
    "arxiv_id": "2402.00045v5",
    "title": "Detecting Multimedia Generated by Large AI Models: A Survey",
    "authors": [
      "Li Lin",
      "Neeraj Gupta",
      "Yue Zhang",
      "Hainan Ren",
      "Chun-Hao Liu",
      "Feng Ding",
      "Xin Wang",
      "Xin Li",
      "Luisa Verdoliva",
      "Shu Hu"
    ],
    "abstract": "The rapid advancement of Large AI Models (LAIMs), particularly diffusion\nmodels and large language models, has marked a new era where AI-generated\nmultimedia is increasingly integrated into various aspects of daily life.\nAlthough beneficial in numerous fields, this content presents significant\nrisks, including potential misuse, societal disruptions, and ethical concerns.\nConsequently, detecting multimedia generated by LAIMs has become crucial, with\na marked rise in related research. Despite this, there remains a notable gap in\nsystematic surveys that focus specifically on detecting LAIM-generated\nmultimedia. Addressing this, we provide the first survey to comprehensively\ncover existing research on detecting multimedia (such as text, images, videos,\naudio, and multimodal content) created by LAIMs. Specifically, we introduce a\nnovel taxonomy for detection methods, categorized by media modality, and\naligned with two perspectives: pure detection (aiming to enhance detection\nperformance) and beyond detection (adding attributes like generalizability,\nrobustness, and interpretability to detectors). Additionally, we have presented\na brief overview of generation mechanisms, public datasets, online detection\ntools, and evaluation metrics to provide a valuable resource for researchers\nand practitioners in this field. Most importantly, we offer a focused analysis\nfrom a social media perspective to highlight their broader societal impact.\nFurthermore, we identify current challenges in detection and propose directions\nfor future research that address unexplored, ongoing, and emerging issues in\ndetecting multimedia generated by LAIMs. Our aim for this survey is to fill an\nacademic gap and contribute to global AI security efforts, helping to ensure\nthe integrity of information in the digital realm. The project link is\nhttps://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00045v5",
    "published_date": "2024-01-22 15:08:19 UTC",
    "updated_date": "2025-05-14 16:37:28 UTC"
  },
  {
    "arxiv_id": "2402.01686v1",
    "title": "A Systematic Mapping Study of Digital Twins for Diagnosis in Transportation",
    "authors": [
      "Liliana Marie Prikler",
      "Franz Wotawa"
    ],
    "abstract": "In recent years, digital twins have been proposed and implemented in various\nfields with potential applications ranging from prototyping to maintenance.\nGoing forward, they are to enable numerous efficient and sustainable\ntechnologies, among them autonomous cars. However, despite a large body of\nresearch in many fields, academics have yet to agree on what exactly a digital\ntwin is -- and as a result, what its capabilities and limitations might be. To\nfurther our understanding, we explore the capabilities of digital twins\nconcerning diagnosis in the field of transportation. We conduct a systematic\nmapping study including digital twins of vehicles and their components, as well\nas transportation infrastructure. We discovered that few papers on digital\ntwins describe any diagnostic process. Furthermore, most existing approaches\nappear limited to system monitoring or fault detection. These findings suggest\nthat we need more research for diagnostic reasoning utilizing digital twins.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01686v1",
    "published_date": "2024-01-22 15:01:37 UTC",
    "updated_date": "2024-01-22 15:01:37 UTC"
  },
  {
    "arxiv_id": "2401.12014v1",
    "title": "Robustness to distribution shifts of compressed networks for edge devices",
    "authors": [
      "Lulan Shen",
      "Ali Edalati",
      "Brett Meyer",
      "Warren Gross",
      "James J. Clark"
    ],
    "abstract": "It is necessary to develop efficient DNNs deployed on edge devices with\nlimited computation resources. However, the compressed networks often execute\nnew tasks in the target domain, which is different from the source domain where\nthe original network is trained. It is important to investigate the robustness\nof compressed networks in two types of data distribution shifts: domain shifts\nand adversarial perturbations. In this study, we discover that compressed\nmodels are less robust to distribution shifts than their original networks.\nInterestingly, larger networks are more vulnerable to losing robustness than\nsmaller ones, even when they are compressed to a similar size as the smaller\nnetworks. Furthermore, compact networks obtained by knowledge distillation are\nmuch more robust to distribution shifts than pruned networks. Finally,\npost-training quantization is a reliable method for achieving significant\nrobustness to distribution shifts, and it outperforms both pruned and distilled\nmodels in terms of robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12014v1",
    "published_date": "2024-01-22 15:00:32 UTC",
    "updated_date": "2024-01-22 15:00:32 UTC"
  },
  {
    "arxiv_id": "2401.12007v3",
    "title": "Tensor-view Topological Graph Neural Network",
    "authors": [
      "Tao Wen",
      "Elynn Chen",
      "Yuzhou Chen"
    ],
    "abstract": "Graph classification is an important learning task for graph-structured data.\nGraph neural networks (GNNs) have recently gained growing attention in graph\nlearning and have shown significant improvements in many important graph\nproblems. Despite their state-of-the-art performances, existing GNNs only use\nlocal information from a very limited neighborhood around each node, suffering\nfrom loss of multi-modal information and overheads of excessive computation. To\naddress these issues, we propose a novel Tensor-view Topological Graph Neural\nNetwork (TTG-NN), a class of simple yet effective topological deep learning\nbuilt upon persistent homology, graph convolution, and tensor operations. This\nnew method incorporates tensor learning to simultaneously capture Tensor-view\nTopological (TT), as well as Tensor-view Graph (TG) structural information on\nboth local and global levels. Computationally, to fully exploit graph topology\nand structure, we propose two flexible TT and TG representation learning\nmodules that disentangle feature tensor aggregation and transformation and\nlearn to preserve multi-modal structure with less computation. Theoretically,\nwe derive high probability bounds on both the out-of-sample and in-sample mean\nsquared approximation errors for our proposed Tensor Transformation Layer\n(TTL). Real data experiments show that the proposed TTG-NN outperforms 20\nstate-of-the-art methods on various graph benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.12007v3",
    "published_date": "2024-01-22 14:55:01 UTC",
    "updated_date": "2024-01-30 03:10:15 UTC"
  },
  {
    "arxiv_id": "2401.11963v4",
    "title": "Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey on Hybrid Algorithms",
    "authors": [
      "Pengyi Li",
      "Jianye Hao",
      "Hongyao Tang",
      "Xian Fu",
      "Yan Zheng",
      "Ke Tang"
    ],
    "abstract": "Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary\nAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, has\ndemonstrated remarkable performance advancements. By fusing both approaches,\nERL has emerged as a promising research direction. This survey offers a\ncomprehensive overview of the diverse research branches in ERL. Specifically,\nwe systematically summarize recent advancements in related algorithms and\nidentify three primary research directions: EA-assisted Optimization of RL,\nRL-assisted Optimization of EA, and synergistic optimization of EA and RL.\nFollowing that, we conduct an in-depth analysis of each research direction,\norganizing multiple research branches. We elucidate the problems that each\nbranch aims to tackle and how the integration of EAs and RL addresses these\nchallenges. In conclusion, we discuss potential challenges and prospective\nfuture research directions across various research directions. To facilitate\nresearchers in delving into ERL, we organize the algorithms and codes involved\non https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11963v4",
    "published_date": "2024-01-22 14:06:37 UTC",
    "updated_date": "2024-06-22 03:56:22 UTC"
  },
  {
    "arxiv_id": "2401.14417v1",
    "title": "Fuzzy Logic Function as a Post-hoc Explanator of the Nonlinear Classifier",
    "authors": [
      "Martin Klimo",
      "Lubomir Kralik"
    ],
    "abstract": "Pattern recognition systems implemented using deep neural networks achieve\nbetter results than linear models. However, their drawback is the black box\nproperty. This property means that one with no experience utilising nonlinear\nsystems may need help understanding the outcome of the decision. Such a\nsolution is unacceptable to the user responsible for the final decision. He\nmust not only believe in the decision but also understand it. Therefore,\nrecognisers must have an architecture that allows interpreters to interpret the\nfindings. The idea of post-hoc explainable classifiers is to design an\ninterpretable classifier parallel to the black box classifier, giving the same\ndecisions as the black box classifier. This paper shows that the explainable\nclassifier completes matching classification decisions with the black box\nclassifier on the MNIST and FashionMNIST databases if Zadeh`s fuzzy logic\nfunction forms the classifier and DeconvNet importance gives the truth values.\nSince the other tested significance measures achieved lower performance than\nDeconvNet, it is the optimal transformation of the feature values to their\ntruth values as inputs to the fuzzy logic function for the databases and\nrecogniser architecture used.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.14417v1",
    "published_date": "2024-01-22 13:58:03 UTC",
    "updated_date": "2024-01-22 13:58:03 UTC"
  },
  {
    "arxiv_id": "2403.08776v1",
    "title": "Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection",
    "authors": [
      "Fatma Shalabi",
      "Hichem Felouat",
      "Huy H. Nguyen",
      "Isao Echizen"
    ],
    "abstract": "Out-of-context (OOC) detection is a challenging task involving identifying\nimages and texts that are irrelevant to the context in which they are\npresented. Large vision-language models (LVLMs) are effective at various tasks,\nincluding image classification and text generation. However, the extent of\ntheir proficiency in multimodal OOC detection tasks is unclear. In this paper,\nwe investigate the ability of LVLMs to detect multimodal OOC and show that\nthese models cannot achieve high accuracy on OOC detection tasks without\nfine-tuning. However, we demonstrate that fine-tuning LVLMs on multimodal OOC\ndatasets can further improve their OOC detection accuracy. To evaluate the\nperformance of LVLMs on OOC detection tasks, we fine-tune MiniGPT-4 on the\nNewsCLIPpings dataset, a large dataset of multimodal OOC. Our results show that\nfine-tuning MiniGPT-4 on the NewsCLIPpings dataset significantly improves the\nOOC detection accuracy in this dataset. This suggests that fine-tuning can\nsignificantly improve the performance of LVLMs on OOC detection tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 6 figures , conference",
    "pdf_url": "http://arxiv.org/pdf/2403.08776v1",
    "published_date": "2024-01-22 13:54:40 UTC",
    "updated_date": "2024-01-22 13:54:40 UTC"
  },
  {
    "arxiv_id": "2401.11944v4",
    "title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark",
    "authors": [
      "Ge Zhang",
      "Xinrun Du",
      "Bei Chen",
      "Yiming Liang",
      "Tongxu Luo",
      "Tianyu Zheng",
      "Kang Zhu",
      "Yuyang Cheng",
      "Chunpu Xu",
      "Shuyue Guo",
      "Haoran Zhang",
      "Xingwei Qu",
      "Junjie Wang",
      "Ruibin Yuan",
      "Yizhi Li",
      "Zekun Wang",
      "Yudong Liu",
      "Yu-Hsuan Tsai",
      "Fengji Zhang",
      "Chenghua Lin",
      "Wenhao Huang",
      "Jie Fu"
    ],
    "abstract": "As the capabilities of large multimodal models (LMMs) continue to advance,\nevaluating the performance of LMMs emerges as an increasing need. Additionally,\nthere is an even larger gap in evaluating the advanced knowledge and reasoning\nabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,\na new Chinese Massive Multi-discipline Multimodal Understanding benchmark\ndesigned to evaluate LMMs on tasks demanding college-level subject knowledge\nand deliberate reasoning in a Chinese context. CMMMU is inspired by and\nstrictly follows the annotation and analysis pattern of MMMU. CMMMU includes\n12k manually collected multimodal questions from college exams, quizzes, and\ntextbooks, covering six core disciplines: Art & Design, Business, Science,\nHealth & Medicine, Humanities & Social Science, and Tech & Engineering, like\nits companion, MMMU. These questions span 30 subjects and comprise 39 highly\nheterogeneous image types, such as charts, diagrams, maps, tables, music\nsheets, and chemical structures. CMMMU focuses on complex perception and\nreasoning with domain-specific knowledge in the Chinese context. We evaluate 11\nopen-source LLMs and one proprietary GPT-4V(ision). Even GPT-4V only achieves\naccuracies of 42%, indicating a large space for improvement. CMMMU will boost\nthe community to build the next-generation LMMs towards expert artificial\nintelligence and promote the democratization of LMMs by providing diverse\nlanguage contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11944v4",
    "published_date": "2024-01-22 13:34:34 UTC",
    "updated_date": "2024-11-04 13:28:48 UTC"
  },
  {
    "arxiv_id": "2401.11913v2",
    "title": "Large receptive field strategy and important feature extraction strategy in 3D object detection",
    "authors": [
      "Leichao Cui",
      "Xiuxian Li",
      "Min Meng",
      "Guangyu Jia"
    ],
    "abstract": "The enhancement of 3D object detection is pivotal for precise environmental\nperception and improved task execution capabilities in autonomous driving.\nLiDAR point clouds, offering accurate depth information, serve as a crucial\ninformation for this purpose. Our study focuses on key challenges in 3D target\ndetection. To tackle the challenge of expanding the receptive field of a 3D\nconvolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).\nThis module achieves adaptive expansion of the 3D convolutional kernel's\nreceptive field, balancing the expansion with acceptable computational loads.\nThis innovation reduces operations, expands the receptive field, and allows the\nmodel to dynamically adjust to different object requirements. Simultaneously,\nwe identify redundant information in 3D features. Employing the Feature\nSelection Module (FSM) quantitatively evaluates and eliminates non-important\nfeatures, achieving the separation of output box fitting and feature\nextraction. This innovation enables the detector to focus on critical features,\nresulting in model compression, reduced computational burden, and minimized\ncandidate frame interference. Extensive experiments confirm that both DFFM and\nFSM not only enhance current benchmarks, particularly in small target\ndetection, but also accelerate network performance. Importantly, these modules\nexhibit effective complementarity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11913v2",
    "published_date": "2024-01-22 13:01:28 UTC",
    "updated_date": "2024-03-10 10:37:21 UTC"
  },
  {
    "arxiv_id": "2401.11911v6",
    "title": "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?",
    "authors": [
      "Hexiang Tan",
      "Fei Sun",
      "Wanli Yang",
      "Yuanzhuo Wang",
      "Qi Cao",
      "Xueqi Cheng"
    ],
    "abstract": "While auxiliary information has become a key to enhancing Large Language\nModels (LLMs), relatively little is known about how LLMs merge these contexts,\nspecifically contexts generated by LLMs and those retrieved from external\nsources. To investigate this, we formulate a systematic framework to identify\nwhether LLMs' responses are attributed to either generated or retrieved\ncontexts. To easily trace the origin of the response, we construct datasets\nwith conflicting contexts, i.e., each question is paired with both generated\nand retrieved contexts, yet only one of them contains the correct answer. Our\nexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) to\nfavor generated contexts, even when they provide incorrect information. We\nfurther identify two key factors contributing to this bias: i) contexts\ngenerated by LLMs typically show greater similarity to the questions,\nincreasing their likelihood of being selected; ii) the segmentation process\nused in retrieved contexts disrupts their completeness, thereby hindering their\nfull utilization in LLMs. Our analysis enhances the understanding of how LLMs\nmerge diverse contexts, offers valuable insights for advancing current LLM\naugmentation methods, and highlights the risk of generated misinformation for\nretrieval-augmented LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 Main, Homepage\n  (https://tan-hexiang.github.io/Blinded_by_Generated_Contexts/)",
    "pdf_url": "http://arxiv.org/pdf/2401.11911v6",
    "published_date": "2024-01-22 12:54:04 UTC",
    "updated_date": "2024-06-11 02:52:58 UTC"
  },
  {
    "arxiv_id": "2401.13002v1",
    "title": "Theorem Discovery Amongst Cyclic Polygons",
    "authors": [
      "Philip Todd"
    ],
    "abstract": "We examine a class of geometric theorems on cyclic 2n-gons. We prove that if\nwe take n disjoint pairs of sides, each pair separated by an even number of\npolygon sides, then there is a linear combination of the angles between those\nsides which is constant. We present a formula for the linear combination, which\nprovides a theorem statement in terms of those angles. We describe a program\nwhich uses this result to generate new geometry proof problems and their\nsolutions.",
    "categories": [
      "cs.CG",
      "cs.AI"
    ],
    "primary_category": "cs.CG",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.13002v1",
    "published_date": "2024-01-22 12:52:55 UTC",
    "updated_date": "2024-01-22 12:52:55 UTC"
  },
  {
    "arxiv_id": "2401.13704v1",
    "title": "Using Java Geometry Expert as Guide in the Preparations for Math Contests",
    "authors": [
      "Ines Ganglmayr",
      "Zoltán Kovács"
    ],
    "abstract": "We give an insight into Java Geometry Expert (JGEX) in use in a school\ncontext, focusing on the Austrian school system. JGEX can offer great support\nin some classroom situations, especially for solving mathematical competition\ntasks. Also, we discuss some limitations of the program.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CG",
      "cs.SC"
    ],
    "primary_category": "cs.CY",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.13704v1",
    "published_date": "2024-01-22 12:52:07 UTC",
    "updated_date": "2024-01-22 12:52:07 UTC"
  },
  {
    "arxiv_id": "2401.13703v1",
    "title": "Solving Some Geometry Problems of the Náboj 2023 Contest with Automated Deduction in GeoGebra Discovery",
    "authors": [
      "Amela Hota",
      "Zoltán Kovács",
      "Alexander Vujic"
    ],
    "abstract": "In this article, we solve some of the geometry problems of the N\\'aboj 2023\ncompetition with the help of a computer, using examples that the software tool\nGeoGebra Discovery can calculate. In each case, the calculation requires\nsymbolic computations. We analyze the difficulty of feeding the problem into\nthe machine and set further goals to make the problems of this type of contests\neven more tractable in the future.",
    "categories": [
      "math.HO",
      "cs.AI",
      "cs.CG",
      "cs.SC"
    ],
    "primary_category": "math.HO",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.13703v1",
    "published_date": "2024-01-22 12:51:51 UTC",
    "updated_date": "2024-01-22 12:51:51 UTC"
  },
  {
    "arxiv_id": "2401.11906v1",
    "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad problem: Lessons Learned",
    "authors": [
      "Belén Ariño-Morera",
      "Zoltán Kovács",
      "Tomás Recio",
      "Piedad Tolmos"
    ],
    "abstract": "We address, through the automated reasoning tools in GeoGebra Discovery, a\nproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying\nto solve this problem gives rise to four different kind of feedback: the almost\ninstantaneous, automated solution of the proposed problem; the measure of its\ncomplexity, according to some recent proposals; the automated discovery of a\ngeneralization of the given assertion, showing that the same statement is true\nover more general polygons than those mentioned in the problem; and the\ndifficulties associated to the analysis of the surprising and involved high\nnumber of degenerate cases that appear when using the LocusEquation command in\nthis problem. In our communication we will describe and reflect on these\ndiverse issues, enhancing its exemplar role for showing some of the advantages,\nproblems, and current fields of development of GeoGebra Discovery.",
    "categories": [
      "cs.SC",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.SC",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.11906v1",
    "published_date": "2024-01-22 12:51:35 UTC",
    "updated_date": "2024-01-22 12:51:35 UTC"
  },
  {
    "arxiv_id": "2401.11905v1",
    "title": "Considerations on Approaches and Metrics in Automated Theorem Generation/Finding in Geometry",
    "authors": [
      "Pedro Quaresma",
      "Pierluigi Graziani",
      "Stefano M. Nicoletti"
    ],
    "abstract": "The pursue of what are properties that can be identified to permit an\nautomated reasoning program to generate and find new and interesting theorems\nis an interesting research goal (pun intended). The automatic discovery of new\ntheorems is a goal in itself, and it has been addressed in specific areas, with\ndifferent methods. The separation of the \"weeds\", uninteresting, trivial facts,\nfrom the \"wheat\", new and interesting facts, is much harder, but is also being\naddressed by different authors using different approaches. In this paper we\nwill focus on geometry. We present and discuss different approaches for the\nautomatic discovery of geometric theorems (and properties), and different\nmetrics to find the interesting theorems among all those that were generated.\nAfter this description we will introduce the first result of this article: an\nundecidability result proving that having an algorithmic procedure that decides\nfor every possible Turing Machine that produces theorems, whether it is able to\nproduce also interesting theorems, is an undecidable problem. Consequently, we\nwill argue that judging whether a theorem prover is able to produce interesting\ntheorems remains a non deterministic task, at best a task to be addressed by\nprogram based in an algorithm guided by heuristics criteria. Therefore, as a\nhuman, to satisfy this task two things are necessary: an expert survey that\nsheds light on what a theorem prover/finder of interesting geometric theorems\nis, and - to enable this analysis - other surveys that clarify metrics and\napproaches related to the interestingness of geometric theorems. In the\nconclusion of this article we will introduce the structure of two of these\nsurveys - the second result of this article - and we will discuss some future\nwork.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "I.2.3; F4"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.11905v1",
    "published_date": "2024-01-22 12:51:19 UTC",
    "updated_date": "2024-01-22 12:51:19 UTC"
  },
  {
    "arxiv_id": "2401.11903v1",
    "title": "Automation of Triangle Ruler-and-Compass Constructions Using Constraint Solvers",
    "authors": [
      "Milan Banković"
    ],
    "abstract": "In this paper, we present an approach to automated solving of triangle\nruler-and-compass construction problems using finite-domain constraint solvers.\nThe constraint model is described in the MiniZinc modeling language, and is\nbased on the automated planning. The main benefit of using general constraint\nsolvers for such purpose, instead of developing dedicated tools, is that we can\nrely on the efficient search that is already implemented within the solver,\nenabling us to focus on geometric aspects of the problem. We may also use the\nsolver's built-in optimization capabilities to search for the shortest possible\nconstructions. We evaluate our approach on 74 solvable problems from the\nWernick's list, and compare it to the dedicated triangle construction solver\nArgoTriCS. The results show that our approach is comparable to dedicated tools,\nwhile it requires much less effort to implement. Also, our model often finds\nshorter constructions, thanks to the optimization capabilities offered by the\nconstraint solvers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.11903v1",
    "published_date": "2024-01-22 12:50:46 UTC",
    "updated_date": "2024-01-22 12:50:46 UTC"
  },
  {
    "arxiv_id": "2401.11900v1",
    "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery",
    "authors": [
      "Zoltán Kovács",
      "Tomás Recio",
      "M. Pilar Vélez"
    ],
    "abstract": "In our contribution we describe some on-going improvements concerning the\nAutomated Reasoning Tools developed in GeoGebra Discovery, providing different\nexamples of the performance of these new features. We describe the new\nShowProof command, that outputs both the sequence of the different steps\nperformed by GeoGebra Discovery to confirm a certain statement, as well as a\nnumber intending to grade the difficulty or interest of the assertion. The\nproposal of this assessment measure, involving the comparison of the expression\nof the thesis (or conclusion) as a combination of the hypotheses, will be\ndeveloped.",
    "categories": [
      "cs.SC",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.SC",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.11900v1",
    "published_date": "2024-01-22 12:50:12 UTC",
    "updated_date": "2024-01-22 12:50:12 UTC"
  },
  {
    "arxiv_id": "2401.11898v1",
    "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving",
    "authors": [
      "Salwa Tabet Gonzalez",
      "Predrag Janičić",
      "Julien Narboux"
    ],
    "abstract": "Conjecturing and theorem proving are activities at the center of mathematical\npractice and are difficult to separate. In this paper, we propose a framework\nfor completing incomplete conjectures and incomplete proofs. The framework can\nturn a conjecture with missing assumptions and with an under-specified goal\ninto a proper theorem. Also, the proposed framework can help in completing a\nproof sketch into a human-readable and machine-checkable proof. Our approach is\nfocused on synthetic geometry, and uses coherent logic and constraint solving.\nThe proposed approach is uniform for all three kinds of tasks, flexible and, to\nour knowledge, unique such approach.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.11898v1",
    "published_date": "2024-01-22 12:49:08 UTC",
    "updated_date": "2024-01-22 12:49:08 UTC"
  },
  {
    "arxiv_id": "2401.13700v1",
    "title": "Towards Automated Readable Proofs of Ruler and Compass Constructions",
    "authors": [
      "Vesna Marinković",
      "Tijana Šukilović",
      "Filip Marić"
    ],
    "abstract": "Although there are several systems that successfully generate construction\nsteps for ruler and compass construction problems, none of them provides\nreadable synthetic correctness proofs for generated constructions. In the\npresent work, we demonstrate how our triangle construction solver ArgoTriCS can\ncooperate with automated theorem provers for first order logic and coherent\nlogic so that it generates construction correctness proofs, that are both\nhuman-readable and formal (can be checked by interactive theorem provers such\nas Coq or Isabelle/HOL). These proofs currently rely on many high-level lemmas\nand our goal is to have them all formally shown from the basic axioms of\ngeometry.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4.1"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
    "pdf_url": "http://arxiv.org/pdf/2401.13700v1",
    "published_date": "2024-01-22 12:48:51 UTC",
    "updated_date": "2024-01-22 12:48:51 UTC"
  },
  {
    "arxiv_id": "2401.13001v1",
    "title": "PatternPortrait: Draw Me Like One of Your Scribbles",
    "authors": [
      "Sabine Wieluch",
      "Friedhelm Schwenker"
    ],
    "abstract": "This paper introduces a process for generating abstract portrait drawings\nfrom pictures. Their unique style is created by utilizing single freehand\npattern sketches as references to generate unique patterns for shading. The\nmethod involves extracting facial and body features from images and\ntransforming them into vector lines. A key aspect of the research is the\ndevelopment of a graph neural network architecture designed to learn sketch\nstroke representations in vector form, enabling the generation of diverse\nstroke variations. The combination of these two approaches creates joyful\nabstract drawings that are realized via a pen plotter. The presented process\ngarnered positive feedback from an audience of approximately 280 participants.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.13001v1",
    "published_date": "2024-01-22 12:33:11 UTC",
    "updated_date": "2024-01-22 12:33:11 UTC"
  },
  {
    "arxiv_id": "2402.16868v2",
    "title": "Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer",
    "authors": [
      "Peigen Ye",
      "Yaping Sun",
      "Shumin Yao",
      "Hao Chen",
      "Xiaodong Xu",
      "Shuguang Cui"
    ],
    "abstract": "Codebook-based generative semantic communication attracts increasing\nattention, since only indices are required to be transmitted when the codebook\nis shared between transmitter and receiver. However, due to the fact that the\nsemantic relations among code vectors are not necessarily related to the\ndistance of the corresponding code indices, the performance of the\ncodebook-enabled semantic communication system is susceptible to the channel\nnoise. Thus, how to improve the system robustness against the noise requires\ncareful design. This paper proposes a robust codebook-assisted image semantic\ncommunication system, where semantic codec and codebook are first jointly\nconstructed, and then vector-to-index transformer is designed guided by the\ncodebook to eliminate the effects of channel noise, and achieve image\ngeneration. Thanks to the assistance of the high-quality codebook to the\nTransformer, the generated images at the receiver outperform those of the\ncompared methods in terms of visual perception. In the end, numerical results\nand generated images demonstrate the advantages of the generative semantic\ncommunication method over JPEG+LDPC and traditional joint source channel coding\n(JSCC) methods.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "IEEE INFOCOM PerAI6G 2024(accepted)",
    "pdf_url": "http://arxiv.org/pdf/2402.16868v2",
    "published_date": "2024-01-22 12:19:21 UTC",
    "updated_date": "2024-03-05 18:10:21 UTC"
  },
  {
    "arxiv_id": "2401.11880v3",
    "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",
    "authors": [
      "Zaibin Zhang",
      "Yongting Zhang",
      "Lijun Li",
      "Hongzhi Gao",
      "Lijun Wang",
      "Huchuan Lu",
      "Feng Zhao",
      "Yu Qiao",
      "Jing Shao"
    ],
    "abstract": "Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit\nprofound capabilities in collective intelligence. However, the potential misuse\nof this intelligence for malicious purposes presents significant risks. To\ndate, comprehensive research on the safety issues associated with multi-agent\nsystems remains limited. In this paper, we explore these concerns through the\ninnovative lens of agent psychology, revealing that the dark psychological\nstates of agents constitute a significant threat to safety. To tackle these\nconcerns, we propose a comprehensive framework (PsySafe) grounded in agent\npsychology, focusing on three key areas: firstly, identifying how dark\npersonality traits in agents can lead to risky behaviors; secondly, evaluating\nthe safety of multi-agent systems from the psychological and behavioral\nperspectives, and thirdly, devising effective strategies to mitigate these\nrisks. Our experiments reveal several intriguing phenomena, such as the\ncollective dangerous behaviors among agents, agents' self-reflection when\nengaging in dangerous behavior, and the correlation between agents'\npsychological assessments and dangerous behaviors. We anticipate that our\nframework and observations will provide valuable insights for further research\ninto the safety of multi-agent systems. We will make our data and code publicly\naccessible at https://github.com/AI4Good24/PsySafe.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11880v3",
    "published_date": "2024-01-22 12:11:55 UTC",
    "updated_date": "2024-08-20 06:45:50 UTC"
  },
  {
    "arxiv_id": "2401.11865v1",
    "title": "Toward Semantic Interoperability of Electronic Health Records",
    "authors": [
      "Idoia Berges",
      "Jesús Bermúdez",
      "Arantza Illarramendi"
    ],
    "abstract": "Although the goal of achieving semantic interoperability of electronic health\nrecords (EHRs) is pursued by many researchers, it has not been accomplished\nyet. In this paper, we present a proposal that smoothes out the way toward the\nachievement of that goal. In particular, our study focuses on medical diagnoses\nstatements. In summary, the main contributions of our ontology-based proposal\nare the following: first, it includes a canonical ontology whose EHR-related\nterms focus on semantic aspects. As a result, their descriptions are\nindependent of languages and technology aspects used in different organizations\nto represent EHRs. Moreover, those terms are related to their corresponding\ncodes in well-known medical terminologies. Second, it deals with modules that\nallow obtaining rich ontological representations of EHR information managed by\nproprietary models of health information systems. The features of one specific\nmodule are shown as reference. Third, it considers the necessary mapping axioms\nbetween ontological terms enhanced with so-called path mappings. This feature\nsmoothes out structural differences between heterogeneous EHR representations,\nallowing proper alignment of information.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is the Accepted Manuscript. The definitive, peer reviewed and\n  edited version of this article is: Idoia Berges, Jes\\'us Berm\\'udez, Arantza\n  Illarramendi: Toward Semantic Interoperability of Electronic Health Records.\n  IEEE Trans. Inf. Technol. Biomed. 16(3): 424-431 (2012).\n  DOI:10.1109/TITB.2011.2180917. Copyright 2011 IEEE",
    "pdf_url": "http://arxiv.org/pdf/2401.11865v1",
    "published_date": "2024-01-22 11:39:55 UTC",
    "updated_date": "2024-01-22 11:39:55 UTC"
  },
  {
    "arxiv_id": "2401.11864v5",
    "title": "Distilling Mathematical Reasoning Capabilities into Small Language Models",
    "authors": [
      "Xunyu Zhu",
      "Jian Li",
      "Yong Liu",
      "Can Ma",
      "Weiping Wang"
    ],
    "abstract": "This work addresses the challenge of democratizing advanced Large Language\nModels (LLMs) by compressing their mathematical reasoning capabilities into\nsub-billion parameter Small Language Models (SLMs) without compromising\nperformance. We introduce Equation-of-Thought Distillation (EoTD), a novel\ntechnique that encapsulates the reasoning process into equation-based\nrepresentations to construct an EoTD dataset for fine-tuning SLMs.\nAdditionally, we propose the Ensemble Thoughts Distillation (ETD) framework to\nenhance the reasoning performance of SLMs. This involves creating a reasoning\ndataset with multiple thought processes, including Chain-of-Thought (CoT),\nProgram-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for\nfine-tuning. Our experimental performance demonstrates that EoTD significantly\nboosts the reasoning abilities of SLMs, while ETD enables these models to\nachieve state-of-the-art reasoning performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in Neural Networks",
    "pdf_url": "http://arxiv.org/pdf/2401.11864v5",
    "published_date": "2024-01-22 11:37:18 UTC",
    "updated_date": "2024-08-01 04:03:32 UTC"
  },
  {
    "arxiv_id": "2401.11860v1",
    "title": "A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection",
    "authors": [
      "Yuandi Wu",
      "Brett Sicard",
      "Stephen Andrew Gadsden"
    ],
    "abstract": "This study presents a comprehensive overview of PIML techniques in the\ncontext of condition monitoring. The central concept driving PIML is the\nincorporation of known physical laws and constraints into machine learning\nalgorithms, enabling them to learn from available data while remaining\nconsistent with physical principles. Through fusing domain knowledge with\ndata-driven learning, PIML methods offer enhanced accuracy and interpretability\nin comparison to purely data-driven approaches. In this comprehensive survey,\ndetailed examinations are performed with regard to the methodology by which\nknown physical principles are integrated within machine learning frameworks, as\nwell as their suitability for specific tasks within condition monitoring.\nIncorporation of physical knowledge into the ML model may be realized in a\nvariety of methods, with each having its unique advantages and drawbacks. The\ndistinct advantages and limitations of each methodology for the integration of\nphysics within data-driven models are detailed, considering factors such as\ncomputational efficiency, model interpretability, and generalizability to\ndifferent systems in condition monitoring and fault detection. Several case\nstudies and works of literature utilizing this emerging concept are presented\nto demonstrate the efficacy of PIML in condition monitoring applications. From\nthe literature reviewed, the versatility and potential of PIML in condition\nmonitoring may be demonstrated. Novel PIML methods offer an innovative solution\nfor addressing the complexities of condition monitoring and associated\nchallenges. This comprehensive survey helps form the foundation for future work\nin the field. As the technology continues to advance, PIML is expected to play\na crucial role in enhancing maintenance strategies, system reliability, and\noverall operational efficiency in engineering systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper has been submitted for review to the journal Expert Systems\n  with Applications (December 31, 2023). 90 pages, 22 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.11860v1",
    "published_date": "2024-01-22 11:29:44 UTC",
    "updated_date": "2024-01-22 11:29:44 UTC"
  },
  {
    "arxiv_id": "2401.11852v1",
    "title": "The Right Model for the Job: An Evaluation of Legal Multi-Label Classification Baselines",
    "authors": [
      "Martina Forster",
      "Claudia Schulz",
      "Prudhvi Nokku",
      "Melicaalsadat Mirsafian",
      "Jaykumar Kasundra",
      "Stavroula Skylaki"
    ],
    "abstract": "Multi-Label Classification (MLC) is a common task in the legal domain, where\nmore than one label may be assigned to a legal document. A wide range of\nmethods can be applied, ranging from traditional ML approaches to the latest\nTransformer-based architectures. In this work, we perform an evaluation of\ndifferent MLC methods using two public legal datasets, POSTURE50K and\nEURLEX57K. By varying the amount of training data and the number of labels, we\nexplore the comparative advantage offered by different approaches in relation\nto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT\nas performing consistently well in legal MLC with reasonable computational\ndemands. T5 also demonstrates comparable performance while offering advantages\nas a generative model in the presence of changing label sets. Finally, we show\nthat the CrossEncoder exhibits potential for notable macro-F1 score\nimprovements, albeit with increased computational costs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11852v1",
    "published_date": "2024-01-22 11:15:07 UTC",
    "updated_date": "2024-01-22 11:15:07 UTC"
  },
  {
    "arxiv_id": "2401.11851v2",
    "title": "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge",
    "authors": [
      "Yuhao Ji",
      "Chao Fang",
      "Zhongfeng Wang"
    ],
    "abstract": "Existing binary Transformers are promising in edge deployment due to their\ncompact model size, low computational complexity, and considerable inference\naccuracy. However, deploying binary Transformers faces challenges on prior\nprocessors due to inefficient execution of quantized matrix multiplication\n(QMM) and the energy consumption overhead caused by multi-precision\nactivations. To tackle the challenges above, we first develop a computation\nflow abstraction method for binary Transformers to improve QMM execution\nefficiency by optimizing the computation order. Furthermore, a binarized\nenergy-efficient Transformer accelerator, namely BETA, is proposed to boost the\nefficient deployment at the edge. Notably, BETA features a configurable QMM\nengine, accommodating diverse activation precisions of binary Transformers and\noffering high-parallelism and high-speed for QMMs with impressive energy\nefficiency. Experimental results evaluated on ZCU102 FPGA show BETA achieves an\naverage energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior\nFPGA-based accelerators, showing BETA's good potential for edge Transformer\nacceleration.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "This paper is accepted by 2024 IEEE International Symposium on\n  Circuits and Systems (ISCAS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11851v2",
    "published_date": "2024-01-22 11:14:08 UTC",
    "updated_date": "2024-01-23 04:17:07 UTC"
  },
  {
    "arxiv_id": "2401.11849v3",
    "title": "Self-Labeling the Job Shop Scheduling Problem",
    "authors": [
      "Andrea Corsini",
      "Angelo Porrello",
      "Simone Calderara",
      "Mauro Dell'Amico"
    ],
    "abstract": "This work proposes a self-supervised training strategy designed for\ncombinatorial problems. An obstacle in applying supervised paradigms to such\nproblems is the need for costly target solutions often produced with exact\nsolvers. Inspired by semi- and self-supervised learning, we show that\ngenerative models can be trained by sampling multiple solutions and using the\nbest one according to the problem objective as a pseudo-label. In this way, we\niteratively improve the model generation capability by relying only on its\nself-supervision, eliminating the need for optimality information. We validate\nthis Self-Labeling Improvement Method (SLIM) on the Job Shop Scheduling (JSP),\na complex combinatorial problem that is receiving much attention from the\nneural combinatorial community. We propose a generative model based on the\nwell-known Pointer Network and train it with SLIM. Experiments on popular\nbenchmarks demonstrate the potential of this approach as the resulting models\noutperform constructive heuristics and state-of-the-art learning proposals for\nthe JSP. Lastly, we prove the robustness of SLIM to various parameters and its\ngenerality by applying it to the Traveling Salesman Problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CO",
      "I.2; G.2"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 38th Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11849v3",
    "published_date": "2024-01-22 11:08:36 UTC",
    "updated_date": "2024-10-31 11:33:24 UTC"
  },
  {
    "arxiv_id": "2401.11848v1",
    "title": "ExtruOnt: An ontology for describing a type of manufacturing machine for Industry 4.0 systems",
    "authors": [
      "Víctor Julio Ramírez-Durán",
      "Idoia Berges",
      "Arantza Illarramendi"
    ],
    "abstract": "Semantically rich descriptions of manufacturing machines, offered in a\nmachine-interpretable code, can provide interesting benefits in Industry 4.0\nscenarios. However, the lack of that type of descriptions is evident. In this\npaper we present the development effort made to build an ontology, called\nExtruOnt, for describing a type of manufacturing machine, more precisely, a\ntype that performs an extrusion process (extruder). Although the scope of the\nontology is restricted to a concrete domain, it could be used as a model for\nthe development of other ontologies for describing manufacturing machines in\nIndustry 4.0 scenarios. The terms of the ExtruOnt ontology provide different\ntypes of information related with an extruder, which are reflected in distinct\nmodules that constitute the ontology. Thus, it contains classes and properties\nfor expressing descriptions about components of an extruder, spatial\nconnections, features, and 3D representations of those components, and finally\nthe sensors used to capture indicators about the performance of this type of\nmachine. The ontology development process has been carried out in close\ncollaboration with domain experts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is the accepted manuscript. The definitive, peer reviewed and\n  edited version of this article is published in Semantic Web 11(6): 887-909\n  (2020) https://doi.org/10.3233/sw-200376",
    "pdf_url": "http://arxiv.org/pdf/2401.11848v1",
    "published_date": "2024-01-22 11:05:54 UTC",
    "updated_date": "2024-01-22 11:05:54 UTC"
  },
  {
    "arxiv_id": "2401.11844v1",
    "title": "Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction",
    "authors": [
      "Francisco Mena",
      "Deepak Pathak",
      "Hiba Najjar",
      "Cristhian Sanchez",
      "Patrick Helber",
      "Benjamin Bischke",
      "Peter Habelitz",
      "Miro Miranda",
      "Jayanth Siddamsetty",
      "Marlon Nuske",
      "Marcela Charfuelan",
      "Diego Arenas",
      "Michaela Vollmer",
      "Andreas Dengel"
    ],
    "abstract": "Accurate crop yield prediction is of utmost importance for informed\ndecision-making in agriculture, aiding farmers, and industry stakeholders.\nHowever, this task is complex and depends on multiple factors, such as\nenvironmental conditions, soil properties, and management practices. Combining\nheterogeneous data views poses a fusion challenge, like identifying the\nview-specific contribution to the predictive task. We present a novel\nmulti-view learning approach to predict crop yield for different crops\n(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our\nmulti-view input data includes multi-spectral optical images from Sentinel-2\nsatellites and weather data as dynamic features during the crop growing season,\ncomplemented by static features like soil properties and topographic\ninformation. To effectively fuse the data, we introduce a Multi-view Gated\nFusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)\nmodule. The view-encoders handle the heterogeneity of data sources with varying\ntemporal resolutions by learning a view-specific representation. These\nrepresentations are adaptively fused via a weighted sum. The fusion weights are\ncomputed for each sample by the GU using a concatenation of the\nview-representations. The MVGF model is trained at sub-field level with 10 m\nresolution pixels. Our evaluations show that the MVGF outperforms conventional\nmodels on the same task, achieving the best results by incorporating all the\ndata sources, unlike the usual fusion results in the literature. For Argentina,\nthe MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,\nwhile at field level evaluation (comparing field averages), it reaches around\n0.80 across different countries. The GU module learned different weights based\non the country and crop-type, aligning with the variable significance of each\ndata source to the prediction task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11844v1",
    "published_date": "2024-01-22 11:01:52 UTC",
    "updated_date": "2024-01-22 11:01:52 UTC"
  },
  {
    "arxiv_id": "2401.11840v1",
    "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs",
    "authors": [
      "Jaeyoon Sim",
      "Sooyeon Jeon",
      "InJun Choi",
      "Guorong Wu",
      "Won Hwa Kim"
    ],
    "abstract": "Various Graph Neural Networks (GNNs) have been successful in analyzing data\nin non-Euclidean spaces, however, they have limitations such as oversmoothing,\ni.e., information becomes excessively averaged as the number of hidden layers\nincreases. The issue stems from the intrinsic formulation of conventional graph\nconvolution where the nodal features are aggregated from a direct neighborhood\nper layer across the entire nodes in the graph. As setting different number of\nhidden layers per node is infeasible, recent works leverage a diffusion kernel\nto redefine the graph structure and incorporate information from farther nodes.\nUnfortunately, such approaches suffer from heavy diagonalization of a graph\nLaplacian or learning a large transform matrix. In this regards, we propose a\ndiffusion learning framework, where the range of feature aggregation is\ncontrolled by the scale of a diffusion kernel. For efficient computation, we\nderive closed-form derivatives of approximations of the graph convolution with\nrespect to the scale, so that node-wise range can be adaptively learned. With a\ndownstream classifier, the entire framework is made trainable in an end-to-end\nmanner. Our model is tested on various standard datasets for node-wise\nclassification for the state-of-the-art performance, and it is also validated\non a real-world brain network data for graph classifications to demonstrate its\npracticality for Alzheimer classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, Accepted to AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11840v1",
    "published_date": "2024-01-22 10:57:11 UTC",
    "updated_date": "2024-01-22 10:57:11 UTC"
  },
  {
    "arxiv_id": "2401.11819v2",
    "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese",
    "authors": [
      "Liang Xu",
      "Hang Xue",
      "Lei Zhu",
      "Kangkang Zhao"
    ],
    "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate\nthe mathematical reasoning abilities of Chinese language models. SC-Math6 is\ndesigned as an upgraded Chinese version of the GSM8K dataset with enhanced\ndifficulty, diversity, and application scope. It consists of over 2000\nmathematical word problems requiring multi-step reasoning and providing natural\nlanguage solutions. We propose an innovative scheme to quantify the reasoning\ncapability of large models based on performance over problems with different\nreasoning steps. Experiments on 13 representative Chinese models demonstrate a\nclear stratification of reasoning levels, with top models like GPT-4 showing\nsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoning\nbenchmarks and provides a comprehensive testbed to advance the intelligence of\nChinese language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Dataset revised and finalized, results updated with new model; 8\n  pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.11819v2",
    "published_date": "2024-01-22 10:30:11 UTC",
    "updated_date": "2024-02-02 02:35:13 UTC"
  },
  {
    "arxiv_id": "2401.11817v2",
    "title": "Hallucination is Inevitable: An Innate Limitation of Large Language Models",
    "authors": [
      "Ziwei Xu",
      "Sanjay Jain",
      "Mohan Kankanhalli"
    ],
    "abstract": "Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all the computable functions and will\ntherefore inevitably hallucinate if used as general problem solvers. Since the\nformal world is a part of the real world which is much more complicated,\nhallucinations are also inevitable for real world LLMs. Furthermore, for real\nworld LLMs constrained by provable time complexity, we describe the\nhallucination-prone tasks and empirically validate our claims. Finally, using\nthe formal world framework, we discuss the possible mechanisms and efficacies\nof existing hallucination mitigators as well as the practical implications on\nthe safe deployment of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11817v2",
    "published_date": "2024-01-22 10:26:14 UTC",
    "updated_date": "2025-02-13 08:11:25 UTC"
  },
  {
    "arxiv_id": "2401.11814v1",
    "title": "Symbrain: A large-scale dataset of MRI images for neonatal brain symmetry analysis",
    "authors": [
      "Arnaud Gucciardi",
      "Safouane El Ghazouali",
      "Francesca Venturini",
      "Vida Groznik",
      "Umberto Michelucci"
    ],
    "abstract": "This paper presents an annotated dataset of brain MRI images designed to\nadvance the field of brain symmetry study. Magnetic resonance imaging (MRI) has\ngained interest in analyzing brain symmetry in neonatal infants, and challenges\nremain due to the vast size differences between fetal and adult brains.\nClassification methods for brain structural MRI use scales and visual cues to\nassess hemisphere symmetry, which can help diagnose neonatal patients by\ncomparing hemispheres and anatomical regions of interest in the brain. Using\nthe Developing Human Connectome Project dataset, this work presents a dataset\ncomprising cerebral images extracted as slices across selected portions of\ninterest for clinical evaluation . All the extracted images are annotated with\nthe brain's midline. All the extracted images are annotated with the brain's\nmidline. From the assumption that a decrease in symmetry is directly related to\npossible clinical pathologies, the dataset can contribute to a more precise\ndiagnosis because it can be used to train deep learning model application in\nneonatal cerebral MRI anomaly detection from postnatal infant scans thanks to\ncomputer vision. Such models learn to identify and classify anomalies by\nidentifying potential asymmetrical patterns in medical MRI images. Furthermore,\nthis dataset can contribute to the research and development of methods using\nthe relative symmetry of the two brain hemispheres for crucial diagnosis and\ntreatment planning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 2 figures, Dataset Paper, Medical AI",
    "pdf_url": "http://arxiv.org/pdf/2401.11814v1",
    "published_date": "2024-01-22 10:22:14 UTC",
    "updated_date": "2024-01-22 10:22:14 UTC"
  },
  {
    "arxiv_id": "2401.11810v1",
    "title": "Generalization and Informativeness of Conformal Prediction",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Fredrik Hellström"
    ],
    "abstract": "The safe integration of machine learning modules in decision-making processes\nhinges on their ability to quantify uncertainty. A popular technique to achieve\nthis goal is conformal prediction (CP), which transforms an arbitrary base\npredictor into a set predictor with coverage guarantees. While CP certifies the\npredicted set to contain the target quantity with a user-defined tolerance, it\ndoes not provide control over the average size of the predicted sets, i.e.,\nover the informativeness of the prediction. In this work, a theoretical\nconnection is established between the generalization properties of the base\npredictor and the informativeness of the resulting CP prediction sets. To this\nend, an upper bound is derived on the expected size of the CP set predictor\nthat builds on generalization error bounds for the base predictor. The derived\nupper bound provides insights into the dependence of the average size of the CP\nset predictor on the amount of calibration data, the target reliability, and\nthe generalization performance of the base predictor. The theoretical insights\nare validated using simple numerical regression and classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11810v1",
    "published_date": "2024-01-22 10:14:45 UTC",
    "updated_date": "2024-01-22 10:14:45 UTC"
  },
  {
    "arxiv_id": "2401.11798v4",
    "title": "Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction",
    "authors": [
      "Mohammad Izadi",
      "Mehran Safayani",
      "Abdolreza Mirzaei"
    ],
    "abstract": "Efficient real-time traffic prediction is crucial for reducing transportation\ntime. To predict traffic conditions, we employ a spatio-temporal graph neural\nnetwork (ST-GNN) to model our real-time traffic data as temporal graphs.\nDespite its capabilities, it often encounters challenges in delivering\nefficient real-time predictions for real-world traffic data. Recognizing the\nsignificance of timely prediction due to the dynamic nature of real-time data,\nwe employ knowledge distillation (KD) as a solution to enhance the execution\ntime of ST-GNNs for traffic prediction. In this paper, We introduce a cost\nfunction designed to train a network with fewer parameters (the student) using\ndistilled data from a complex network (the teacher) while maintaining its\naccuracy close to that of the teacher. We use knowledge distillation,\nincorporating spatial-temporal correlations from the teacher network to enable\nthe student to learn the complex patterns perceived by the teacher. However, a\nchallenge arises in determining the student network architecture rather than\nconsidering it inadvertently. To address this challenge, we propose an\nalgorithm that utilizes the cost function to calculate pruning scores,\naddressing small network architecture search issues, and jointly fine-tunes the\nnetwork resulting from each pruning stage using KD. Ultimately, we evaluate our\nproposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results\nindicate that our method can maintain the student's accuracy close to that of\nthe teacher, even with the retention of only 3% of network parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11798v4",
    "published_date": "2024-01-22 09:54:49 UTC",
    "updated_date": "2024-09-24 08:30:19 UTC"
  },
  {
    "arxiv_id": "2401.11792v6",
    "title": "Efficient and Generalized end-to-end Autonomous Driving System with Latent Deep Reinforcement Learning and Demonstrations",
    "authors": [
      "Zuojin Tang",
      "Xiaoyu Chen",
      "YongQiang Li",
      "Jianyu Chen"
    ],
    "abstract": "An intelligent driving system should dynamically formulate appropriate\ndriving strategies based on the current environment and vehicle status while\nensuring system security and reliability. However, methods based on\nreinforcement learning and imitation learning often suffer from high sample\ncomplexity, poor generalization, and low safety. To address these challenges,\nthis paper introduces an Efficient and Generalized end-to-end Autonomous\nDriving System (EGADS) for complex and varied scenarios. The RL agent in our\nEGADS combines variational inference with normalizing flows, which are\nindependent of distribution assumptions. This combination allows the agent to\ncapture historical information relevant to driving in latent space effectively,\nthereby significantly reducing sample complexity. Additionally, we enhance\nsafety by formulating robust safety constraints and improve generalization and\nperformance by integrating RL with expert demonstrations. Experimental results\ndemonstrate that, compared to existing methods, EGADS significantly reduces\nsample complexity, greatly improves safety performance, and exhibits strong\ngeneralization capabilities in complex urban scenarios. Particularly, we\ncontributed an expert dataset collected through human expert steering wheel\ncontrol, specifically using the G29 steering wheel.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11792v6",
    "published_date": "2024-01-22 09:44:16 UTC",
    "updated_date": "2024-06-16 12:48:53 UTC"
  },
  {
    "arxiv_id": "2401.12999v2",
    "title": "Quantum-Inspired Machine Learning for Molecular Docking",
    "authors": [
      "Runqiu Shu",
      "Bowen Liu",
      "Zhaoping Xiong",
      "Xiaopeng Cui",
      "Yunting Li",
      "Wei Cui",
      "Man-Hong Yung",
      "Nan Qiao"
    ],
    "abstract": "Molecular docking is an important tool for structure-based drug design,\naccelerating the efficiency of drug development. Complex and dynamic binding\nprocesses between proteins and small molecules require searching and sampling\nover a wide spatial range. Traditional docking by searching for possible\nbinding sites and conformations is computationally complex and results poorly\nunder blind docking. Quantum-inspired algorithms combining quantum properties\nand annealing show great advantages in solving combinatorial optimization\nproblems. Inspired by this, we achieve an improved in blind docking by using\nquantum-inspired combined with gradients learned by deep learning in the\nencoded molecular space. Numerical simulation shows that our method outperforms\ntraditional docking algorithms and deep learning-based algorithms over 10\\%.\nCompared to the current state-of-the-art deep learning-based docking algorithm\nDiffDock, the success rate of Top-1 (RMSD<2) achieves an improvement from 33\\%\nto 35\\% in our same setup. In particular, a 6\\% improvement is realized in the\nhigh-precision region(RMSD<1) on molecules data unseen in DiffDock, which\ndemonstrates the well-generalized of our method.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12999v2",
    "published_date": "2024-01-22 09:16:41 UTC",
    "updated_date": "2024-02-22 02:56:06 UTC"
  },
  {
    "arxiv_id": "2401.11772v2",
    "title": "LightDiC: A Simple yet Effective Approach for Large-scale Digraph Representation Learning",
    "authors": [
      "Xunkai Li",
      "Meihao Liao",
      "Zhengyu Wu",
      "Daohan Su",
      "Wentao Zhang",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Most existing graph neural networks (GNNs) are limited to undirected graphs,\nwhose restricted scope of the captured relational information hinders their\nexpressive capabilities and deployments in real-world scenarios. Compared with\nundirected graphs, directed graphs (digraphs) fit the demand for modeling more\ncomplex topological systems by capturing more intricate relationships between\nnodes, such as formulating transportation and financial networks. While some\ndirected GNNs have been introduced, their inspiration mainly comes from deep\nlearning architectures, which lead to redundant complexity and computation,\nmaking them inapplicable to large-scale databases. To address these issues, we\npropose LightDiC, a scalable variant of the digraph convolution based on the\nmagnetic Laplacian. Since topology-related computations are conducted solely\nduring offline pre-processing, LightDiC achieves exceptional scalability,\nenabling downstream predictions to be trained separately without incurring\nrecursive computational costs. Theoretical analysis shows that LightDiC\nutilizes directed information to achieve message passing based on the complex\nfield, which corresponds to the proximal gradient descent process of the\nDirichlet energy optimization function from the perspective of digraph signal\ndenoising, ensuring its expressiveness. Experimental results demonstrate that\nLightDiC performs comparably well or even outperforms other SOTA methods in\nvarious downstream tasks, with fewer learnable parameters and higher training\nefficiency. Notably, LightDiC is the first DiGNN to provide satisfactory\nresults in the most representative large-scale database (ogbn-papers100M).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by VLDB 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11772v2",
    "published_date": "2024-01-22 09:09:10 UTC",
    "updated_date": "2024-02-18 01:40:24 UTC"
  },
  {
    "arxiv_id": "2402.01685v3",
    "title": "SMUTF: Schema Matching Using Generative Tags and Hybrid Features",
    "authors": [
      "Yu Zhang",
      "Mei Di",
      "Haozheng Luo",
      "Chenwei Xu",
      "Richard Tzong-Han Tsai"
    ],
    "abstract": "We introduce SMUTF (Schema Matching Using Generative Tags and Hybrid\nFeatures), a unique approach for large-scale tabular data schema matching (SM),\nwhich assumes that supervised learning does not affect performance in\nopen-domain tasks, thereby enabling effective cross-domain matching. This\nsystem uniquely combines rule-based feature engineering, pre-trained language\nmodels, and generative large language models. In an innovative adaptation\ninspired by the Humanitarian Exchange Language, we deploy \"generative tags\" for\neach data column, enhancing the effectiveness of SM. SMUTF exhibits extensive\nversatility, working seamlessly with any pre-existing pre-trained embeddings,\nclassification methods, and generative models.\n  Recognizing the lack of extensive, publicly available datasets for SM, we\nhave created and open-sourced the HDXSM dataset from the public humanitarian\ndata. We believe this to be the most exhaustive SM dataset currently available.\nIn evaluations across various public datasets and the novel HDXSM dataset,\nSMUTF demonstrated exceptional performance, surpassing existing\nstate-of-the-art models in terms of accuracy and efficiency, and improving the\nF1 score by 11.84% and the AUC of ROC by 5.08%. Code is available at\nhttps://github.com/fireindark707/Python-Schema-Matching.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "Information Systems",
    "pdf_url": "http://arxiv.org/pdf/2402.01685v3",
    "published_date": "2024-01-22 08:47:50 UTC",
    "updated_date": "2025-05-03 07:53:12 UTC"
  },
  {
    "arxiv_id": "2401.11755v1",
    "title": "FedGTA: Topology-aware Averaging for Federated Graph Learning",
    "authors": [
      "Xunkai Li",
      "Zhengyu Wu",
      "Wentao Zhang",
      "Yinlin Zhu",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Federated Graph Learning (FGL) is a distributed machine learning paradigm\nthat enables collaborative training on large-scale subgraphs across multiple\nlocal systems. Existing FGL studies fall into two categories: (i) FGL\nOptimization, which improves multi-client training in existing machine learning\nmodels; (ii) FGL Model, which enhances performance with complex local models\nand multi-client interactions. However, most FGL optimization strategies are\ndesigned specifically for the computer vision domain and ignore graph\nstructure, presenting dissatisfied performance and slow convergence. Meanwhile,\ncomplex local model architectures in FGL Models studies lack scalability for\nhandling large-scale subgraphs and have deployment limitations. To address\nthese issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a\npersonalized optimization strategy that optimizes through topology-aware local\nsmoothing confidence and mixed neighbor features. During experiments, we deploy\nFedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.\nThis allows us to evaluate the performance and robustness of FedGTA across a\nrange of scenarios. Extensive experiments demonstrate that FedGTA achieves\nstate-of-the-art performance while exhibiting high scalability and efficiency.\nThe experiment includes ogbn-papers100M, the most representative large-scale\ngraph database so that we can verify the applicability of our method to\nlarge-scale graph learning. To the best of our knowledge, our study is the\nfirst to bridge large-scale graph learning with FGL using this optimization\nstrategy, contributing to the development of efficient and scalable FGL\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by VLDB 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11755v1",
    "published_date": "2024-01-22 08:31:53 UTC",
    "updated_date": "2024-01-22 08:31:53 UTC"
  },
  {
    "arxiv_id": "2401.11753v1",
    "title": "From Knowledge Organization to Knowledge Representation and Back",
    "authors": [
      "Fausto Giunchiglia",
      "Mayukh Bagchi",
      "Subhashis Das"
    ],
    "abstract": "Knowledge Organization (KO) and Knowledge Representation (KR) have been the\ntwo mainstream methodologies of knowledge modelling in the Information Science\ncommunity and the Artificial Intelligence community, respectively. The\nfacet-analytical tradition of KO has developed an exhaustive set of guiding\ncanons for ensuring quality in organising and managing knowledge but has\nremained limited in terms of technology-driven activities to expand its scope\nand services beyond the bibliographic universe of knowledge. KR, on the other\nhand, boasts of a robust ecosystem of technologies and technology-driven\nservice design which can be tailored to model any entity or scale to any\nservice in the entire universe of knowledge. This paper elucidates both the\nfacet-analytical KO and KR methodologies in detail and provides a functional\nmapping between them. Out of the mapping, the paper proposes an integrated\nKR-enriched KO methodology with all the standard components of a KO methodology\nplus the advanced technologies provided by the KR approach. The practical\nbenefits of the methodological integration has been exemplified through the\nflagship application of the Digital University at the University of Trento,\nItaly.",
    "categories": [
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted @ Annals of Library and Information Studies (ALIS) Journal -\n  Ranganathan Commemorative Issue (2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11753v1",
    "published_date": "2024-01-22 08:28:28 UTC",
    "updated_date": "2024-01-22 08:28:28 UTC"
  },
  {
    "arxiv_id": "2401.11750v1",
    "title": "AdaFGL: A New Paradigm for Federated Node Classification with Topology Heterogeneity",
    "authors": [
      "Xunkai Li",
      "Zhengyu Wu",
      "Wentao Zhang",
      "Henan Sun",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Recently, Federated Graph Learning (FGL) has attracted significant attention\nas a distributed framework based on graph neural networks, primarily due to its\ncapability to break data silos. Existing FGL studies employ community split on\nthe homophilous global graph by default to simulate federated semi-supervised\nnode classification settings. Such a strategy assumes the consistency of\ntopology between the multi-client subgraphs and the global graph, where\nconnected nodes are highly likely to possess similar feature distributions and\nthe same label. However, in real-world implementations, the varying\nperspectives of local data engineering result in various subgraph topologies,\nposing unique heterogeneity challenges in FGL. Unlike the well-known label\nNon-independent identical distribution (Non-iid) problems in federated\nlearning, FGL heterogeneity essentially reveals the topological divergence\namong multiple clients, namely homophily or heterophily. To simulate and handle\nthis unique challenge, we introduce the concept of structure Non-iid split and\nthen present a new paradigm called \\underline{Ada}ptive \\underline{F}ederated\n\\underline{G}raph \\underline{L}earning (AdaFGL), a decoupled two-step\npersonalized approach. To begin with, AdaFGL employs standard multi-client\nfederated collaborative training to acquire the federated knowledge extractor\nby aggregating uploaded models in the final round at the server. Then, each\nclient conducts personalized training based on the local subgraph and the\nfederated knowledge extractor. Extensive experiments on the 12 graph benchmark\ndatasets validate the superior performance of AdaFGL over state-of-the-art\nbaselines. Specifically, in terms of test accuracy, our proposed AdaFGL\noutperforms baselines by significant margins of 3.24\\% and 5.57\\% on community\nsplit and structure Non-iid split, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICDE 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11750v1",
    "published_date": "2024-01-22 08:23:31 UTC",
    "updated_date": "2024-01-22 08:23:31 UTC"
  },
  {
    "arxiv_id": "2401.11748v3",
    "title": "GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?",
    "authors": [
      "Yu Sun",
      "Gaojian Xiong",
      "Xianxun Yao",
      "Kailang Ma",
      "Jian Cui"
    ],
    "abstract": "Deep gradient inversion attacks expose a serious threat to Federated Learning\n(FL) by accurately recovering private data from shared gradients. However, the\nstate-of-the-art heavily relies on impractical assumptions to access excessive\nauxiliary data, which violates the basic data partitioning principle of FL. In\nthis paper, a novel method, Gradient Inversion Attack using Practical Image\nPrior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits\nanomaly detection models to capture the underlying distribution from fewer\ndata, while GAN-based methods consume significant more data to synthesize\nimages. The extracted distribution is then leveraged to regulate the attack\nprocess as Anomaly Score loss. Experimental results show that GI-PIP achieves a\n16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based\nmethods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on\ndistribution generalization compared to GAN-based methods. Our approach\nsignificantly alleviates the auxiliary data requirement on both amount and\ndistribution in gradient inversion attacks, hence posing more substantial\nthreat to real-world FL.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11748v3",
    "published_date": "2024-01-22 08:20:47 UTC",
    "updated_date": "2024-04-01 12:15:44 UTC"
  },
  {
    "arxiv_id": "2402.01684v1",
    "title": "A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using the CGC-LORA Algorithm",
    "authors": [
      "Chao Song",
      "Zhihao Ye",
      "Qiqiang Lin",
      "Qiuying Peng",
      "Jun Wang"
    ],
    "abstract": "With the productive evolution of large language models (LLMs) in the field of\nnatural language processing (NLP), tons of effort has been made to effectively\nfine-tune common pre-trained LLMs to fulfill a variety of tasks in one or\nmultiple specific domain. In practice, there are two prevailing ways, in which\nthe adaptation can be achieved: (i) Multiple Independent Models: Pre-trained\nLLMs are fine-tuned a few times independently using the corresponding training\nsamples from each task. (ii) An Integrated Model: Samples from all tasks are\nemployed to fine-tune a pre-trianed LLM unitedly. To address the high computing\ncost and seesawing issue simultaneously, we propose a unified framework that\nimplements a 1 + N mutli-task fine-tuning pattern in LLMs using a novel\nCustomized Gate Control (CGC) Low-rank Adaptation (LoRA) algorithm. Our work\naims to take an advantage of both MTL (i.e., CGC) and PEFT (i.e., LoRA) scheme.\nFor a given cluster of tasks, we design an innovative layer that contains two\ntypes of experts as additional trainable parameters to make LoRA be compatible\nwith MTL. To comprehensively evaluate the proposed framework, we conduct\nwell-designed experiments on two public datasets. The experimental results\ndemonstrate that the unified framework with CGC-LoRA modules achieves higher\nevaluation scores than all benchmarks on both two datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01684v1",
    "published_date": "2024-01-22 07:58:31 UTC",
    "updated_date": "2024-01-22 07:58:31 UTC"
  },
  {
    "arxiv_id": "2402.06638v1",
    "title": "Transformers with Attentive Federated Aggregation for Time Series Stock Forecasting",
    "authors": [
      "Chu Myaet Thwal",
      "Ye Lin Tun",
      "Kitae Kim",
      "Seong-Bae Park",
      "Choong Seon Hong"
    ],
    "abstract": "Recent innovations in transformers have shown their superior performance in\nnatural language processing (NLP) and computer vision (CV). The ability to\ncapture long-range dependencies and interactions in sequential data has also\ntriggered a great interest in time series modeling, leading to the widespread\nuse of transformers in many time series applications. However, being the most\ncommon and crucial application, the adaptation of transformers to time series\nforecasting has remained limited, with both promising and inconsistent results.\nIn contrast to the challenges in NLP and CV, time series problems not only add\nthe complexity of order or temporal dependence among input sequences but also\nconsider trend, level, and seasonality information that much of this data is\nvaluable for decision making. The conventional training scheme has shown\ndeficiencies regarding model overfitting, data scarcity, and privacy issues\nwhen working with transformers for a forecasting task. In this work, we propose\nattentive federated transformers for time series stock forecasting with better\nperformance while preserving the privacy of participating enterprises.\nEmpirical results on various stock data from the Yahoo! Finance website\nindicate the superiority of our proposed scheme in dealing with the above\nchallenges and data heterogeneity in federated learning.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CE",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "Published in IEEE ICOIN 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.06638v1",
    "published_date": "2024-01-22 07:33:28 UTC",
    "updated_date": "2024-01-22 07:33:28 UTC"
  },
  {
    "arxiv_id": "2401.11736v1",
    "title": "Attention on Personalized Clinical Decision Support System: Federated Learning Approach",
    "authors": [
      "Chu Myaet Thwal",
      "Kyi Thar",
      "Ye Lin Tun",
      "Choong Seon Hong"
    ],
    "abstract": "Health management has become a primary problem as new kinds of diseases and\ncomplex symptoms are introduced to a rapidly growing modern society. Building a\nbetter and smarter healthcare infrastructure is one of the ultimate goals of a\nsmart city. To the best of our knowledge, neural network models are already\nemployed to assist healthcare professionals in achieving this goal. Typically,\ntraining a neural network requires a rich amount of data but heterogeneous and\nvulnerable properties of clinical data introduce a challenge for the\ntraditional centralized network. Moreover, adding new inputs to a medical\ndatabase requires re-training an existing model from scratch. To tackle these\nchallenges, we proposed a deep learning-based clinical decision support system\ntrained and managed under a federated learning paradigm. We focused on a novel\nstrategy to guarantee the safety of patient privacy and overcome the risk of\ncyberattacks while enabling large-scale clinical data mining. As a result, we\ncan leverage rich clinical data for training each local neural network without\nthe need for exchanging the confidential data of patients. Moreover, we\nimplemented the proposed scheme as a sequence-to-sequence model architecture\nintegrating the attention mechanism. Thus, our objective is to provide a\npersonalized clinical decision support system with evolvable characteristics\nthat can deliver accurate solutions and assist healthcare professionals in\nmedical diagnosing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in IEEE BigComp 2021",
    "pdf_url": "http://arxiv.org/pdf/2401.11736v1",
    "published_date": "2024-01-22 07:24:15 UTC",
    "updated_date": "2024-01-22 07:24:15 UTC"
  },
  {
    "arxiv_id": "2401.11731v1",
    "title": "Fast and Scalable Network Slicing by Integrating Deep Learning with Lagrangian Methods",
    "authors": [
      "Tianlun Hu",
      "Qi Liao",
      "Qiang Liu",
      "Antonio Massaro",
      "Georg Carle"
    ],
    "abstract": "Network slicing is a key technique in 5G and beyond for efficiently\nsupporting diverse services. Many network slicing solutions rely on deep\nlearning to manage complex and high-dimensional resource allocation problems.\nHowever, deep learning models suffer limited generalization and adaptability to\ndynamic slicing configurations. In this paper, we propose a novel framework\nthat integrates constrained optimization methods and deep learning models,\nresulting in strong generalization and superior approximation capability. Based\non the proposed framework, we design a new neural-assisted algorithm to\nallocate radio resources to slices to maximize the network utility under\ninter-slice resource constraints. The algorithm exhibits high scalability,\naccommodating varying numbers of slices and slice configurations with ease. We\nimplement the proposed solution in a system-level network simulator and\nevaluate its performance extensively by comparing it to state-of-the-art\nsolutions including deep reinforcement learning approaches. The numerical\nresults show that our solution obtains near-optimal quality-of-service\nsatisfaction and promising generalization performance under different network\nslicing scenarios.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages, 5 figures, IEEE Global Communications Conference 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.11731v1",
    "published_date": "2024-01-22 07:19:16 UTC",
    "updated_date": "2024-01-22 07:19:16 UTC"
  },
  {
    "arxiv_id": "2401.11724v1",
    "title": "Augmenting Prototype Network with TransMix for Few-shot Hyperspectral Image Classification",
    "authors": [
      "Chun Liu",
      "Longwei Yang",
      "Dongmei Dong",
      "Zheng Li",
      "Wei Yang",
      "Zhigang Han",
      "Jiayao Wang"
    ],
    "abstract": "Few-shot hyperspectral image classification aims to identify the classes of\neach pixel in the images by only marking few of these pixels. And in order to\nobtain the spatial-spectral joint features of each pixel, the fixed-size\npatches centering around each pixel are often used for classification. However,\nobserving the classification results of existing methods, we found that\nboundary patches corresponding to the pixels which are located at the boundary\nof the objects in the hyperspectral images, are hard to classify. These\nboundary patchs are mixed with multi-class spectral information. Inspired by\nthis, we propose to augment the prototype network with TransMix for few-shot\nhyperspectrial image classification(APNT). While taking the prototype network\nas the backbone, it adopts the transformer as feature extractor to learn the\npixel-to-pixel relation and pay different attentions to different pixels. At\nthe same time, instead of directly using the patches which are cut from the\nhyperspectral images for training, it randomly mixs up two patches to imitate\nthe boundary patches and uses the synthetic patches to train the model, with\nthe aim to enlarge the number of hard training samples and enhance their\ndiversity. And by following the data agumentation technique TransMix, the\nattention returned by the transformer is also used to mix up the labels of two\npatches to generate better labels for synthetic patches. Compared with existing\nmethods, the proposed method has demonstrated sate of the art performance and\nbetter robustness for few-shot hyperspectral image classification in our\nexperiments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11724v1",
    "published_date": "2024-01-22 06:56:52 UTC",
    "updated_date": "2024-01-22 06:56:52 UTC"
  },
  {
    "arxiv_id": "2401.11723v2",
    "title": "Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them",
    "authors": [
      "Chao Liu",
      "Boxi Chen",
      "Wei Shao",
      "Chris Zhang",
      "Kelvin Wong",
      "Yi Zhang"
    ],
    "abstract": "The advent of the Internet of Things (IoT) has brought forth an era of\nunprecedented connectivity, with an estimated 80 billion smart devices expected\nto be in operation by the end of 2025. These devices facilitate a multitude of\nsmart applications, enhancing the quality of life and efficiency across various\ndomains. Machine Learning (ML) serves as a crucial technology, not only for\nanalyzing IoT-generated data but also for diverse applications within the IoT\necosystem. For instance, ML finds utility in IoT device recognition, anomaly\ndetection, and even in uncovering malicious activities. This paper embarks on a\ncomprehensive exploration of the security threats arising from ML's integration\ninto various facets of IoT, spanning various attack types including membership\ninference, adversarial evasion, reconstruction, property inference, model\nextraction, and poisoning attacks. Unlike previous studies, our work offers a\nholistic perspective, categorizing threats based on criteria such as adversary\nmodels, attack targets, and key security attributes (confidentiality,\navailability, and integrity). We delve into the underlying techniques of ML\nattacks in IoT environment, providing a critical evaluation of their mechanisms\nand impacts. Furthermore, our research thoroughly assesses 65 libraries, both\nauthor-contributed and third-party, evaluating their role in safeguarding model\nand data privacy. We emphasize the availability and usability of these\nlibraries, aiming to arm the community with the necessary tools to bolster\ntheir defenses against the evolving threat landscape. Through our comprehensive\nreview and analysis, this paper seeks to contribute to the ongoing discourse on\nML-based IoT security, offering valuable insights and practical solutions to\nsecure ML models and data in the rapidly expanding field of artificial\nintelligence in IoT.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11723v2",
    "published_date": "2024-01-22 06:52:35 UTC",
    "updated_date": "2024-01-27 01:22:25 UTC"
  },
  {
    "arxiv_id": "2401.11720v3",
    "title": "Graph Condensation: A Survey",
    "authors": [
      "Xinyi Gao",
      "Junliang Yu",
      "Tong Chen",
      "Guanhua Ye",
      "Wentao Zhang",
      "Hongzhi Yin"
    ],
    "abstract": "The rapid growth of graph data poses significant challenges in storage,\ntransmission, and particularly the training of graph neural networks (GNNs). To\naddress these challenges, graph condensation (GC) has emerged as an innovative\nsolution. GC focuses on synthesizing a compact yet highly representative graph,\nenabling GNNs trained on it to achieve performance comparable to those trained\non the original large graph. The notable efficacy of GC and its broad prospects\nhave garnered significant attention and spurred extensive research. This survey\npaper provides an up-to-date and systematic overview of GC, organizing existing\nresearch into five categories aligned with critical GC evaluation criteria:\neffectiveness, generalization, efficiency, fairness, and robustness. To\nfacilitate an in-depth and comprehensive understanding of GC, this paper\nexamines various methods under each category and thoroughly discusses two\nessential components within GC: optimization strategies and condensed graph\ngeneration. We also empirically compare and analyze representative GC methods\nwith diverse optimization strategies based on the five proposed GC evaluation\ncriteria. Finally, we explore the applications of GC in various fields, outline\nthe related open-source libraries, and highlight the present challenges and\nnovel insights, with the aim of promoting advancements in future research. The\nrelated resources can be found at\nhttps://github.com/XYGaoG/Graph-Condensation-Papers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Transactions on Knowledge and Data Engineering (TKDE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2401.11720v3",
    "published_date": "2024-01-22 06:47:00 UTC",
    "updated_date": "2025-01-27 09:40:25 UTC"
  },
  {
    "arxiv_id": "2401.11719v1",
    "title": "SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation",
    "authors": [
      "Xinqiao Zhao",
      "Feilong Tang",
      "Xiaoyang Wang",
      "Jimin Xiao"
    ],
    "abstract": "Image-level weakly supervised semantic segmentation has received increasing\nattention due to its low annotation cost. Existing methods mainly rely on Class\nActivation Mapping (CAM) to obtain pseudo-labels for training semantic\nsegmentation models. In this work, we are the first to demonstrate that\nlong-tailed distribution in training data can cause the CAM calculated through\nclassifier weights over-activated for head classes and under-activated for tail\nclasses due to the shared features among head- and tail- classes. This degrades\npseudo-label quality and further influences final semantic segmentation\nperformance. To address this issue, we propose a Shared Feature Calibration\n(SFC) method for CAM generation. Specifically, we leverage the class prototypes\nthat carry positive shared features and propose a Multi-Scaled\nDistribution-Weighted (MSDW) consistency loss for narrowing the gap between the\nCAMs generated through classifier weights and class prototypes during training.\nThe MSDW loss counterbalances over-activation and under-activation by\ncalibrating the shared features in head-/tail-class classifier weights.\nExperimental results show that our SFC significantly improves CAM boundaries\nand achieves new state-of-the-art performances. The project is available at\nhttps://github.com/Barrett-python/SFC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11719v1",
    "published_date": "2024-01-22 06:43:13 UTC",
    "updated_date": "2024-01-22 06:43:13 UTC"
  },
  {
    "arxiv_id": "2401.11713v1",
    "title": "Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council",
    "authors": [
      "Luyang Luo",
      "Xin Huang",
      "Minghao Wang",
      "Zhuoyue Wan",
      "Hao Chen"
    ],
    "abstract": "Deep learning could be prone to learning shortcuts raised by dataset bias and\nresult in inaccurate, unreliable, and unfair models, which impedes its adoption\nin real-world clinical applications. Despite its significance, there is a\ndearth of research in the medical image classification domain to address\ndataset bias. Furthermore, the bias labels are often agnostic, as identifying\nbiases can be laborious and depend on post-hoc interpretation. This paper\nproposes learning Adaptive Agreement from a Biased Council (Ada-ABC), a\ndebiasing framework that does not rely on explicit bias labels to tackle\ndataset bias in medical images. Ada-ABC develops a biased council consisting of\nmultiple classifiers optimized with generalized cross entropy loss to learn the\ndataset bias. A debiasing model is then simultaneously trained under the\nguidance of the biased council. Specifically, the debiasing model is required\nto learn adaptive agreement with the biased council by agreeing on the\ncorrectly predicted samples and disagreeing on the wrongly predicted samples by\nthe biased council. In this way, the debiasing model could learn the target\nattribute on the samples without spurious correlations while also avoiding\nignoring the rich information in samples with spurious correlations. We\ntheoretically demonstrated that the debiasing model could learn the target\nfeatures when the biased model successfully captures dataset bias. Moreover, to\nour best knowledge, we constructed the first medical debiasing benchmark from\nfour datasets containing seven different bias scenarios. Our extensive\nexperiments practically showed that our proposed Ada-ABC outperformed\ncompetitive approaches, verifying its effectiveness in mitigating dataset bias\nfor medical image classification. The codes and organized benchmark datasets\nwill be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, 3 tables. Code and benchmark will be released\n  via https://github.com/LLYXC/Ada-ABC/tree/main",
    "pdf_url": "http://arxiv.org/pdf/2401.11713v1",
    "published_date": "2024-01-22 06:29:52 UTC",
    "updated_date": "2024-01-22 06:29:52 UTC"
  },
  {
    "arxiv_id": "2401.11708v3",
    "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",
    "authors": [
      "Ling Yang",
      "Zhaochen Yu",
      "Chenlin Meng",
      "Minkai Xu",
      "Stefano Ermon",
      "Bin Cui"
    ],
    "abstract": "Diffusion models have exhibit exceptional performance in text-to-image\ngeneration and editing. However, existing methods often face challenges when\nhandling complex text prompts that involve multiple objects with multiple\nattributes and relationships. In this paper, we propose a brand new\ntraining-free text-to-image generation/editing framework, namely Recaption,\nPlan and Generate (RPG), harnessing the powerful chain-of-thought reasoning\nability of multimodal LLMs to enhance the compositionality of text-to-image\ndiffusion models. Our approach employs the MLLM as a global planner to\ndecompose the process of generating complex images into multiple simpler\ngeneration tasks within subregions. We propose complementary regional diffusion\nto enable region-wise compositional generation. Furthermore, we integrate\ntext-guided image generation and editing within the proposed RPG in a\nclosed-loop fashion, thereby enhancing generalization ability. Extensive\nexperiments demonstrate our RPG outperforms state-of-the-art text-to-image\ndiffusion models, including DALL-E 3 and SDXL, particularly in multi-category\nobject composition and text-image semantic alignment. Notably, our RPG\nframework exhibits wide compatibility with various MLLM architectures (e.g.,\nMiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available\nat: https://github.com/YangLing0818/RPG-DiffusionMaster",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2024. Project:\n  https://github.com/YangLing0818/RPG-DiffusionMaster",
    "pdf_url": "http://arxiv.org/pdf/2401.11708v3",
    "published_date": "2024-01-22 06:16:29 UTC",
    "updated_date": "2024-05-05 04:50:54 UTC"
  },
  {
    "arxiv_id": "2401.11705v1",
    "title": "Domain-Aware Cross-Attention for Cross-domain Recommendation",
    "authors": [
      "Yuhao Luo",
      "Shiwei Ma",
      "Mingjun Nie",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao",
      "Qianfang Xu"
    ],
    "abstract": "Cross-domain recommendation (CDR) is an important method to improve\nrecommender system performance, especially when observations in target domains\nare sparse. However, most existing cross-domain recommendations fail to fully\nutilize the target domain's special features and are hard to be generalized to\nnew domains. The designed network is complex and is not suitable for rapid\nindustrial deployment. Our method introduces a two-step domain-aware\ncross-attention, extracting transferable features of the source domain from\ndifferent granularity, which allows the efficient expression of both domain and\nuser interests. In addition, we simplify the training process, and our model\ncan be easily deployed on new domains. We conduct experiments on both public\ndatasets and industrial datasets, and the experimental results demonstrate the\neffectiveness of our method. We have also deployed the model in an online\nadvertising system and observed significant improvements in both\nClick-Through-Rate (CTR) and effective cost per mille (ECPM).",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2401.11705v1",
    "published_date": "2024-01-22 06:12:48 UTC",
    "updated_date": "2024-01-22 06:12:48 UTC"
  },
  {
    "arxiv_id": "2402.01681v3",
    "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications",
    "authors": [
      "Yuhang Zhou",
      "Paiheng Xu",
      "Xiyao Wang",
      "Xuan Lu",
      "Ge Gao",
      "Wei Ai"
    ],
    "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become\nprevalent in social network communications. This has spurred increasing\nscholarly interest in exploring their attributes and functionalities. However,\nemoji-related research and application face two primary challenges. First,\nresearchers typically rely on crowd-sourcing to annotate emojis in order to\nunderstand their sentiments, usage intentions, and semantic meanings. Second,\nsubjective interpretations by users can often lead to misunderstandings of\nemojis and cause the communication barrier. Large Language Models (LLMs) have\nachieved significant success in various annotation tasks, with ChatGPT\ndemonstrating expertise across multiple domains. In our study, we assess\nChatGPT's effectiveness in handling previously annotated and downstream tasks.\nOur objective is to validate the hypothesis that ChatGPT can serve as a viable\nalternative to human annotators in emoji research and that its ability to\nexplain emoji meanings can enhance clarity and transparency in online\ncommunications. Our findings indicate that ChatGPT has extensive knowledge of\nemojis. It is adept at elucidating the meaning of emojis across various\napplication scenarios and demonstrates the potential to replace human\nannotators in a range of tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by the 19th International AAAI Conference on Web and Social\n  Media (ICWSM 2025)",
    "pdf_url": "http://arxiv.org/pdf/2402.01681v3",
    "published_date": "2024-01-22 06:02:39 UTC",
    "updated_date": "2025-04-07 15:00:36 UTC"
  },
  {
    "arxiv_id": "2401.11698v1",
    "title": "Admission Prediction in Undergraduate Applications: an Interpretable Deep Learning Approach",
    "authors": [
      "Amisha Priyadarshini",
      "Barbara Martinez-Neda",
      "Sergio Gago-Masague"
    ],
    "abstract": "This article addresses the challenge of validating the admission committee's\ndecisions for undergraduate admissions. In recent years, the traditional review\nprocess has struggled to handle the overwhelmingly large amount of applicants'\ndata. Moreover, this traditional assessment often leads to human bias, which\nmight result in discrimination among applicants. Although classical machine\nlearning-based approaches exist that aim to verify the quantitative assessment\nmade by the application reviewers, these methods lack scalability and suffer\nfrom performance issues when a large volume of data is in place. In this\ncontext, we propose deep learning-based classifiers, namely Feed-Forward and\nInput Convex neural networks, which overcome the challenges faced by the\nexisting methods. Furthermore, we give additional insights into our model by\nincorporating an interpretability module, namely LIME. Our training and test\ndatasets comprise applicants' data with a wide range of variables and\ninformation. Our models achieve higher accuracy compared to the best-performing\ntraditional machine learning-based approach by a considerable margin of 3.03\\%.\nAdditionally, we show the sensitivity of different features and their relative\nimpacts on the overall admission decision using the LIME technique.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for Transdisciplinary AI 2023 conference",
    "pdf_url": "http://arxiv.org/pdf/2401.11698v1",
    "published_date": "2024-01-22 05:44:43 UTC",
    "updated_date": "2024-01-22 05:44:43 UTC"
  },
  {
    "arxiv_id": "2402.16866v1",
    "title": "Computation Rate Maximization for Wireless Powered Edge Computing With Multi-User Cooperation",
    "authors": [
      "Yang Li",
      "Xing Zhang",
      "Bo Lei",
      "Qianying Zhao",
      "Min Wei",
      "Zheyan Qu",
      "Wenbo Wang"
    ],
    "abstract": "The combination of mobile edge computing (MEC) and radio frequency-based\nwireless power transfer (WPT) presents a promising technique for providing\nsustainable energy supply and computing services at the network edge. This\nstudy considers a wireless-powered mobile edge computing system that includes a\nhybrid access point (HAP) equipped with a computing unit and multiple Internet\nof Things (IoT) devices. In particular, we propose a novel muti-user\ncooperation scheme to improve computation performance, where collaborative\nclusters are dynamically formed. Each collaborative cluster comprises a source\ndevice (SD) and an auxiliary device (AD), where the SD can partition the\ncomputation task into various segments for local processing, offloading to the\nHAP, and remote execution by the AD with the assistance of the HAP.\nSpecifically, we aims to maximize the weighted sum computation rate (WSCR) of\nall the IoT devices in the network. This involves jointly optimizing\ncollaboration, time and data allocation among multiple IoT devices and the HAP,\nwhile considering the energy causality property and the minimum data processing\nrequirement of each device. Initially, an optimization algorithm based on the\ninterior-point method is designed for time and data allocation. Subsequently, a\npriority-based iterative algorithm is developed to search for a near-optimal\nsolution to the multi-user collaboration scheme. Finally, a deep learning-based\napproach is devised to further accelerate the algorithm's operation, building\nupon the initial two algorithms. Simulation results show that the performance\nof the proposed algorithms is comparable to that of the exhaustive search\nmethod, and the deep learning-based algorithm significantly reduces the\nexecution time of the algorithm.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Accepted to IEEE Open Journal of the Communications Society",
    "pdf_url": "http://arxiv.org/pdf/2402.16866v1",
    "published_date": "2024-01-22 05:22:19 UTC",
    "updated_date": "2024-01-22 05:22:19 UTC"
  },
  {
    "arxiv_id": "2401.11674v1",
    "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
    "authors": [
      "Yu Zhu",
      "Kang Li",
      "Lequan Yu",
      "Pheng-Ann Heng"
    ],
    "abstract": "Recent studies have made remarkable progress in histopathology\nclassification. Based on current successes, contemporary works proposed to\nfurther upgrade the model towards a more generalizable and robust direction\nthrough incrementally learning from the sequentially delivered domains. Unlike\nprevious parameter isolation based approaches that usually demand massive\ncomputation resources during model updating, we present a memory-efficient\nprompt tuning framework to cultivate model generalization potential in\neconomical memory cost. For each incoming domain, we reuse the existing\nparameters of the initial classification model and attach lightweight trainable\nprompts into it for customized tuning. Considering the domain heterogeneity, we\nperform decoupled prompt tuning, where we adopt a domain-specific prompt for\neach domain to independently investigate its distinctive characteristics, and\none domain-invariant prompt shared across all domains to continually explore\nthe common content embedding throughout time. All domain-specific prompts will\nbe appended to the prompt bank and isolated from further changes to prevent\nforgetting the distinctive features of early-seen domains. While the\ndomain-invariant prompt will be passed on and iteratively evolve by\nstyle-augmented prompt refining to improve model generalization capability over\ntime. In specific, we construct a graph with existing prompts and build a\nstyle-augmented graph attention network to guide the domain-invariant prompt\nexploring the overlapped latent embedding among all delivered domains for more\ndomain generic representations. We have extensively evaluated our framework\nwith two histopathology tasks, i.e., breast cancer metastasis classification\nand epithelium-stroma tissue classification, where our approach yielded\nsuperior performance and memory efficiency over the competing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11674v1",
    "published_date": "2024-01-22 03:24:45 UTC",
    "updated_date": "2024-01-22 03:24:45 UTC"
  },
  {
    "arxiv_id": "2401.13699v2",
    "title": "Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey",
    "authors": [
      "Jiayuan Chen",
      "You Shi",
      "Changyan Yi",
      "Hongyang Du",
      "Jiawen Kang",
      "Dusit Niyato"
    ],
    "abstract": "The Internet of things (IoT) can significantly enhance the quality of human\nlife, specifically in healthcare, attracting extensive attentions to\nIoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as\nan innovative paradigm that can comprehensively characterize the replication of\nthe individual human body in the digital world and reflect its physical status\nin real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the\napplication of healthcare monitoring by acting as a versatile and vivid human\ndigital testbed, simulating the outcomes and guiding the practical treatments.\nHowever, successfully establishing HDT requires high-fidelity virtual modeling\nand strong information interactions but possibly with scarce, biased and noisy\ndata. Fortunately, a recent popular technology called generative artificial\nintelligence (GAI) may be a promising solution because it can leverage advanced\nAI algorithms to automatically create, manipulate, and modify valuable while\ndiverse data. This survey particularly focuses on the implementation of\nGAI-driven HDT in IoT-healthcare. We start by introducing the background of\nIoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the\nfundamental techniques and present the overall framework of GAI-driven HDT.\nAfter that, we explore the realization of GAI-driven HDT in detail, including\nGAI-enabled data acquisition, communication, data management, digital modeling,\nand data analysis. Besides, we discuss typical IoT-healthcare applications that\ncan be revolutionized by GAI-driven HDT, namely personalized health monitoring\nand diagnosis, personalized prescription, and personalized rehabilitation.\nFinally, we conclude this survey by highlighting some future research\ndirections.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.13699v2",
    "published_date": "2024-01-22 03:17:41 UTC",
    "updated_date": "2024-06-28 11:49:52 UTC"
  },
  {
    "arxiv_id": "2401.11669v1",
    "title": "An Improved Grey Wolf Optimization Algorithm for Heart Disease Prediction",
    "authors": [
      "Sihan Niu",
      "Yifan Zhou",
      "Zhikai Li",
      "Shuyao Huang",
      "Yujun Zhou"
    ],
    "abstract": "This paper presents a unique solution to challenges in medical image\nprocessing by incorporating an adaptive curve grey wolf optimization (ACGWO)\nalgorithm into neural network backpropagation. Neural networks show potential\nin medical data but suffer from issues like overfitting and lack of\ninterpretability due to imbalanced and scarce data. Traditional Gray Wolf\nOptimization (GWO) also has its drawbacks, such as a lack of population\ndiversity and premature convergence. This paper addresses these problems by\nintroducing an adaptive algorithm, enhancing the standard GWO with a sigmoid\nfunction. This algorithm was extensively compared to four leading algorithms\nusing six well-known test functions, outperforming them effectively. Moreover,\nby utilizing the ACGWO, we increase the robustness and generalization of the\nneural network, resulting in more interpretable predictions. Applied to the\npublicly accessible Cleveland Heart Disease dataset, our technique surpasses\nten other methods, achieving 86.8% accuracy, indicating its potential for\nefficient heart disease prediction in the clinical setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11669v1",
    "published_date": "2024-01-22 03:07:24 UTC",
    "updated_date": "2024-01-22 03:07:24 UTC"
  },
  {
    "arxiv_id": "2401.11666v1",
    "title": "P2DT: Mitigating Forgetting in task-incremental Learning with progressive prompt Decision Transformer",
    "authors": [
      "Zhiyuan Wang",
      "Xiaoyang Qu",
      "Jing Xiao",
      "Bokui Chen",
      "Jianzong Wang"
    ],
    "abstract": "Catastrophic forgetting poses a substantial challenge for managing\nintelligent agents controlled by a large model, causing performance degradation\nwhen these agents face new tasks. In our work, we propose a novel solution -\nthe Progressive Prompt Decision Transformer (P2DT). This method enhances a\ntransformer-based model by dynamically appending decision tokens during new\ntask training, thus fostering task-specific policies. Our approach mitigates\nforgetting in continual and offline reinforcement learning scenarios. Moreover,\nP2DT leverages trajectories collected via traditional reinforcement learning\nfrom all tasks and generates new task-specific tokens during training, thereby\nretaining knowledge from previous studies. Preliminary results demonstrate that\nour model effectively alleviates catastrophic forgetting and scales well with\nincreasing task environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 49th IEEE International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.11666v1",
    "published_date": "2024-01-22 02:58:53 UTC",
    "updated_date": "2024-01-22 02:58:53 UTC"
  },
  {
    "arxiv_id": "2401.11665v3",
    "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
    "authors": [
      "Haoyang Zheng",
      "Wei Deng",
      "Christian Moya",
      "Guang Lin"
    ],
    "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach\nfrom Gaussian posterior sampling to encompass more general smooth posteriors.\nHowever, it still encounters scalability issues in high-dimensional problems\nwhen demanding high accuracy. To address this, we propose an approximate\nThompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where\nthe latter is the go-to workhorse for simulations of high-dimensional\nposteriors. Based on the standard smoothness and log-concavity conditions, we\nstudy the accelerated posterior concentration and sampling using a specific\npotential function. This design improves the sample complexity for realizing\nlogarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde\nO}(\\sqrt{d})$. The scalability and robustness of our algorithm are also\nempirically validated through synthetic experiments in high-dimensional bandit\nproblems.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "52 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.11665v3",
    "published_date": "2024-01-22 02:54:58 UTC",
    "updated_date": "2024-06-21 01:54:15 UTC"
  },
  {
    "arxiv_id": "2401.11664v1",
    "title": "Zero-Space Cost Fault Tolerance for Transformer-based Language Models on ReRAM",
    "authors": [
      "Bingbing Li",
      "Geng Yuan",
      "Zigeng Wang",
      "Shaoyi Huang",
      "Hongwu Peng",
      "Payman Behnam",
      "Wujie Wen",
      "Hang Liu",
      "Caiwen Ding"
    ],
    "abstract": "Resistive Random Access Memory (ReRAM) has emerged as a promising platform\nfor deep neural networks (DNNs) due to its support for parallel in-situ\nmatrix-vector multiplication. However, hardware failures, such as\nstuck-at-fault defects, can result in significant prediction errors during\nmodel inference. While additional crossbars can be used to address these\nfailures, they come with storage overhead and are not efficient in terms of\nspace, energy, and cost. In this paper, we propose a fault protection mechanism\nthat incurs zero space cost. Our approach includes: 1) differentiable structure\npruning of rows and columns to reduce model redundancy, 2) weight duplication\nand voting for robust output, and 3) embedding duplicated most significant bits\n(MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE\nbenchmark with the BERT model, and experimental results prove its\neffectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11664v1",
    "published_date": "2024-01-22 02:50:38 UTC",
    "updated_date": "2024-01-22 02:50:38 UTC"
  },
  {
    "arxiv_id": "2401.11660v2",
    "title": "Differentiable Tree Search Network",
    "authors": [
      "Dixant Mittal",
      "Wee Sun Lee"
    ],
    "abstract": "In decision-making problems with limited training data, policy functions\napproximated using deep neural networks often exhibit suboptimal performance.\nAn alternative approach involves learning a world model from the limited data\nand determining actions through online search. However, the performance is\nadversely affected by compounding errors arising from inaccuracies in the\nlearned world model. While methods like TreeQN have attempted to address these\ninaccuracies by incorporating algorithmic inductive biases into the neural\nnetwork architectures, the biases they introduce are often weak and\ninsufficient for complex decision-making tasks. In this work, we introduce\nDifferentiable Tree Search Network (D-TSN), a novel neural network architecture\nthat significantly strengthens the inductive bias by embedding the algorithmic\nstructure of a best-first online search algorithm. D-TSN employs a learned\nworld model to conduct a fully differentiable online search. The world model is\njointly optimized with the search algorithm, enabling the learning of a robust\nworld model and mitigating the effect of prediction inaccuracies. Further, we\nnote that a naive incorporation of best-first search could lead to a\ndiscontinuous loss function in the parameter space. We address this issue by\nadopting a stochastic tree expansion policy, formulating search tree expansion\nas another decision-making task, and introducing an effective variance\nreduction technique for the gradient computation. We evaluate D-TSN in an\noffline-RL setting with a limited training data scenario on Procgen games and\ngrid navigation task, and demonstrate that D-TSN outperforms popular model-free\nand model-based baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11660v2",
    "published_date": "2024-01-22 02:33:38 UTC",
    "updated_date": "2024-08-02 07:42:37 UTC"
  },
  {
    "arxiv_id": "2401.11652v1",
    "title": "OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning",
    "authors": [
      "Chu Myaet Thwal",
      "Minh N. H. Nguyen",
      "Ye Lin Tun",
      "Seong Tae Kim",
      "My T. Thai",
      "Choong Seon Hong"
    ],
    "abstract": "Federated learning (FL) has emerged as a promising approach to\ncollaboratively train machine learning models across multiple edge devices\nwhile preserving privacy. The success of FL hinges on the efficiency of\nparticipating models and their ability to handle the unique challenges of\ndistributed learning. While several variants of Vision Transformer (ViT) have\nshown great potential as alternatives to modern convolutional neural networks\n(CNNs) for centralized training, the unprecedented size and higher\ncomputational demands hinder their deployment on resource-constrained edge\ndevices, challenging their widespread application in FL. Since client devices\nin FL typically have limited computing resources and communication bandwidth,\nmodels intended for such devices must strike a balance between model size,\ncomputational efficiency, and the ability to adapt to the diverse and non-IID\ndata distributions encountered in FL. To address these challenges, we propose\nOnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks\nwith limited training data and resources. Our models incorporate image-specific\ninductive biases through the LCT tokenizer by leveraging efficient depthwise\nseparable convolutions in residual linear bottleneck blocks to extract local\nfeatures, while the multi-head self-attention (MHSA) mechanism in the LCT\nencoder implicitly facilitates capturing global representations of images.\nExtensive experiments on benchmark image datasets indicate that our models\noutperform existing lightweight vision models while having fewer parameters and\nlower computational demands, making them suitable for FL scenarios with data\nheterogeneity and communication bottlenecks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CC",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in Neural Networks",
    "pdf_url": "http://arxiv.org/pdf/2401.11652v1",
    "published_date": "2024-01-22 02:17:36 UTC",
    "updated_date": "2024-01-22 02:17:36 UTC"
  },
  {
    "arxiv_id": "2401.11648v5",
    "title": "Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation",
    "authors": [
      "Heejoon Koo"
    ],
    "abstract": "Predicting next visit diagnosis using Electronic Health Records (EHR) is an\nessential task in healthcare, critical for devising proactive future plans for\nboth healthcare providers and patients. Nonetheless, many preceding studies\nhave not sufficiently addressed the heterogeneous and hierarchical\ncharacteristics inherent in EHR data, inevitably leading to sub-optimal\nperformance. To this end, we propose NECHO, a novel medical code-centric\nmultimodal contrastive EHR learning framework with hierarchical regularisation.\nFirst, we integrate multifaceted information encompassing medical codes,\ndemographics, and clinical notes using a tailored network design and a pair of\nbimodal contrastive losses, all of which pivot around a medical codes\nrepresentation. We also regularise modality-specific encoders using a parental\nlevel information in medical ontology to learn hierarchical structure of EHR\ndata. A series of experiments on MIMIC-III data demonstrates effectiveness of\nour approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EACL 2024 (The 18th Conference of the European Chapter of\n  the Association for Computational Linguistics)",
    "pdf_url": "http://arxiv.org/pdf/2401.11648v5",
    "published_date": "2024-01-22 01:58:32 UTC",
    "updated_date": "2024-05-01 01:44:46 UTC"
  },
  {
    "arxiv_id": "2401.11647v4",
    "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised Learning",
    "authors": [
      "Ye Lin Tun",
      "Chu Myaet Thwal",
      "Huy Q. Le",
      "Minh N. H. Nguyen",
      "Choong Seon Hong"
    ],
    "abstract": "Many studies integrate federated learning (FL) with self-supervised learning\n(SSL) to take advantage of raw data distributed across edge devices. However,\nedge devices often struggle with high computational and communication costs\nimposed by SSL and FL algorithms. With the deployment of more complex and\nlarge-scale models, such as Transformers, these challenges are exacerbated. To\ntackle this, we propose the Layer-Wise Federated Self-Supervised Learning\n(LW-FedSSL) approach, which allows edge devices to incrementally train a small\npart of the model at a time. Specifically, in LW-FedSSL, training is decomposed\ninto multiple stages, with each stage responsible for only a specific layer (or\na block of layers) of the model. Since only a portion of the model is active\nfor training at any given time, LW-FedSSL significantly reduces computational\nrequirements. Additionally, only the active model portion needs to be exchanged\nbetween the FL server and clients, reducing the communication overhead. This\nenables LW-FedSSL to jointly address both computational and communication\nchallenges in FL. Depending on the SSL algorithm used, it can achieve up to a\n$3.34 \\times$ reduction in memory usage, $4.20 \\times$ fewer computational\noperations (GFLOPs), and a $5.07 \\times$ lower communication cost while\nmaintaining performance comparable to its end-to-end training counterpart.\nFurthermore, we explore a progressive training strategy called Prog-FedSSL,\nwhich offers a $1.84\\times$ reduction in GFLOPs and a $1.67\\times$ reduction in\ncommunication costs while maintaining the same memory requirements as\nend-to-end training. While the resource efficiency of Prog-FedSSL is lower than\nthat of LW-FedSSL, its performance improvements make it a viable candidate for\nFL environments with more lenient resource constraints.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11647v4",
    "published_date": "2024-01-22 01:57:31 UTC",
    "updated_date": "2025-02-26 05:20:00 UTC"
  },
  {
    "arxiv_id": "2401.12261v4",
    "title": "Cloud-based XAI Services for Assessing Open Repository Models Under Adversarial Attacks",
    "authors": [
      "Zerui Wang",
      "Yan Liu"
    ],
    "abstract": "The opacity of AI models necessitates both validation and evaluation before\ntheir integration into services. To investigate these models, explainable AI\n(XAI) employs methods that elucidate the relationship between input features\nand output predictions. The operations of XAI extend beyond the execution of a\nsingle algorithm, involving a series of activities that include preprocessing\ndata, adjusting XAI to align with model parameters, invoking the model to\ngenerate predictions, and summarizing the XAI results. Adversarial attacks are\nwell-known threats that aim to mislead AI models. The assessment complexity,\nespecially for XAI, increases when open-source AI models are subject to\nadversarial attacks, due to various combinations. To automate the numerous\nentities and tasks involved in XAI-based assessments, we propose a cloud-based\nservice framework that encapsulates computing components as microservices and\norganizes assessment tasks into pipelines. The current XAI tools are not\ninherently service-oriented. This framework also integrates open XAI tool\nlibraries as part of the pipeline composition. We demonstrate the application\nof XAI services for assessing five quality attributes of AI models: (1)\ncomputational cost, (2) performance, (3) robustness, (4) explanation deviation,\nand (5) explanation resilience across computer vision and tabular cases. The\nservice framework generates aggregated analysis that showcases the quality\nattributes for more than a hundred combination scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "2024 IEEE International Conference on Software Services Engineering\n  (SSE)",
    "pdf_url": "http://arxiv.org/pdf/2401.12261v4",
    "published_date": "2024-01-22 00:37:01 UTC",
    "updated_date": "2024-10-01 03:41:26 UTC"
  },
  {
    "arxiv_id": "2401.11633v1",
    "title": "Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to Vision Encoders with Multimodal Loss",
    "authors": [
      "Jordan Shipard",
      "Arnold Wiliem",
      "Kien Nguyen Thanh",
      "Wei Xiang",
      "Clinton Fookes"
    ],
    "abstract": "The fusion of vision and language has brought about a transformative shift in\ncomputer vision through the emergence of Vision-Language Models (VLMs).\nHowever, the resource-intensive nature of existing VLMs poses a significant\nchallenge. We need an accessible method for developing the next generation of\nVLMs. To address this issue, we propose Zoom-shot, a novel method for\ntransferring the zero-shot capabilities of CLIP to any pre-trained vision\nencoder. We do this by exploiting the multimodal information (i.e. text and\nimage) present in the CLIP latent space through the use of specifically\ndesigned multimodal loss functions. These loss functions are (1)\ncycle-consistency loss and (2) our novel prompt-guided knowledge distillation\nloss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP's\nzero-shot classification, to capture the interactions between text and image\nfeatures. With our multimodal losses, we train a $\\textbf{linear mapping}$\nbetween the CLIP latent space and the latent space of a pre-trained vision\nencoder, for only a $\\textbf{single epoch}$. Furthermore, Zoom-shot is entirely\nunsupervised and is trained using $\\textbf{unpaired}$ data. We test the\nzero-shot capabilities of a range of vision encoders augmented as new VLMs, on\ncoarse and fine-grained classification datasets, outperforming the previous\nstate-of-the-art in this problem domain. In our ablations, we find Zoom-shot\nallows for a trade-off between data and compute during training; and our\nstate-of-the-art results can be obtained by reducing training from 20% to 1% of\nthe ImageNet training data with 20 epochs. All code and models are available on\nGitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.11633v1",
    "published_date": "2024-01-22 00:00:30 UTC",
    "updated_date": "2024-01-22 00:00:30 UTC"
  }
]