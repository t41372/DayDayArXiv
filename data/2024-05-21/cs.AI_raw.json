[
  {
    "arxiv_id": "2405.13254v3",
    "title": "System Safety Monitoring of Learned Components Using Temporal Metric Forecasting",
    "authors": [
      "Sepehr Sharifi",
      "Andrea Stocco",
      "Lionel C. Briand"
    ],
    "abstract": "In learning-enabled autonomous systems, safety monitoring of learned\ncomponents is crucial to ensure their outputs do not lead to system safety\nviolations, given the operational context of the system. However, developing a\nsafety monitor for practical deployment in real-world applications is\nchallenging. This is due to limited access to internal workings and training\ndata of the learned component. Furthermore, safety monitors should predict\nsafety violations with low latency, while consuming a reasonable amount of\ncomputation. To address the challenges, we propose a safety monitoring method\nbased on probabilistic time series forecasting. Given the learned component\noutputs and an operational context, we empirically investigate different Deep\nLearning (DL)-based probabilistic forecasting to predict the objective measure\ncapturing the satisfaction or violation of a safety requirement (safety\nmetric). We empirically evaluate safety metric and violation prediction\naccuracy, and inference latency and resource usage of four state-of-the-art\nmodels, with varying horizons, using autonomous aviation and autonomous driving\ncase studies. Our results suggest that probabilistic forecasting of safety\nmetrics, given learned component outputs and scenarios, is effective for safety\nmonitoring. Furthermore, for both case studies, Temporal Fusion Transformer\n(TFT) was the most accurate model for predicting imminent safety violations,\nwith acceptable latency and resource consumption.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication by ACM Transactions on Software Engineering\n  and Methodology (TOSEM)",
    "pdf_url": "http://arxiv.org/pdf/2405.13254v3",
    "published_date": "2024-05-21 23:48:26 UTC",
    "updated_date": "2024-12-20 03:10:32 UTC"
  },
  {
    "arxiv_id": "2405.13245v2",
    "title": "A Survey of Robotic Language Grounding: Tradeoffs between Symbols and Embeddings",
    "authors": [
      "Vanya Cohen",
      "Jason Xinyu Liu",
      "Raymond Mooney",
      "Stefanie Tellex",
      "David Watkins"
    ],
    "abstract": "With large language models, robots can understand language more flexibly and\nmore capable than ever before. This survey reviews and situates recent\nliterature into a spectrum with two poles: 1) mapping between language and some\nmanually defined formal representation of meaning, and 2) mapping between\nlanguage and high-dimensional vector spaces that translate directly to\nlow-level robot policy. Using a formal representation allows the meaning of the\nlanguage to be precisely represented, limits the size of the learning problem,\nand leads to a framework for interpretability and formal safety guarantees.\nMethods that embed language and perceptual data into high-dimensional spaces\navoid this manually specified symbolic structure and thus have the potential to\nbe more general when fed enough data but require more data and computing to\ntrain. We discuss the benefits and tradeoffs of each approach and finish by\nproviding directions for future work that achieves the best of both worlds.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "IJCAI 2024 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2405.13245v2",
    "published_date": "2024-05-21 23:12:03 UTC",
    "updated_date": "2024-06-22 13:03:53 UTC"
  },
  {
    "arxiv_id": "2405.13242v3",
    "title": "Goals as Reward-Producing Programs",
    "authors": [
      "Guy Davidson",
      "Graham Todd",
      "Julian Togelius",
      "Todd M. Gureckis",
      "Brenden M. Lake"
    ],
    "abstract": "People are remarkably capable of generating their own goals, beginning with\nchild's play and continuing into adulthood. Despite considerable empirical and\ncomputational work on goals and goal-oriented behavior, models are still far\nfrom capturing the richness of everyday human goals. Here, we bridge this gap\nby collecting a dataset of human-generated playful goals (in the form of\nscorable, single-player games), modeling them as reward-producing programs, and\ngenerating novel human-like goals through program synthesis. Reward-producing\nprograms capture the rich semantics of goals through symbolic operations that\ncompose, add temporal constraints, and allow for program execution on\nbehavioral traces to evaluate progress. To build a generative model of goals,\nwe learn a fitness function over the infinite set of possible goal programs and\nsample novel goals with a quality-diversity algorithm. Human evaluators found\nthat model-generated goals, when sampled from partitions of program space\noccupied by human examples, were indistinguishable from human-created games. We\nalso discovered that our model's internal fitness scores predict games that are\nevaluated as more fun to play and more human-like.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Project website and goal program viewer:\n  https://exps.gureckislab.org/guydav/goal_programs_viewer/main/",
    "pdf_url": "http://arxiv.org/pdf/2405.13242v3",
    "published_date": "2024-05-21 23:09:12 UTC",
    "updated_date": "2024-09-10 22:29:43 UTC"
  },
  {
    "arxiv_id": "2405.13231v1",
    "title": "Multiple Realizability and the Rise of Deep Learning",
    "authors": [
      "Sam Whitman McGrath",
      "Jacob Russin"
    ],
    "abstract": "The multiple realizability thesis holds that psychological states may be\nimplemented in a diversity of physical systems. The deep learning revolution\nseems to be bringing this possibility to life, offering the most plausible\nexamples of man-made realizations of sophisticated cognitive functions to date.\nThis paper explores the implications of deep learning models for the multiple\nrealizability thesis. Among other things, it challenges the widely held view\nthat multiple realizability entails that the study of the mind can and must be\npursued independently of the study of its implementation in the brain or in\nartificial analogues. Although its central contribution is philosophical, the\npaper has substantial methodological upshots for contemporary cognitive\nscience, suggesting that deep neural networks may play a crucial role in\nformulating and evaluating hypotheses about cognition, even if they are\ninterpreted as implementation-level models. In the age of deep learning,\nmultiple realizability possesses a renewed significance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13231v1",
    "published_date": "2024-05-21 22:36:49 UTC",
    "updated_date": "2024-05-21 22:36:49 UTC"
  },
  {
    "arxiv_id": "2405.13229v1",
    "title": "Transfer Learning Approach for Railway Technical Map (RTM) Component Identification",
    "authors": [
      "Obadage Rochana Rumalshan",
      "Pramuka Weerasinghe",
      "Mohamed Shaheer",
      "Prabhath Gunathilake",
      "Erunika Dayaratna"
    ],
    "abstract": "The extreme popularity over the years for railway transportation urges the\nnecessity to maintain efficient railway management systems around the globe.\nEven though, at present, there exist a large collection of Computer Aided\nDesigned Railway Technical Maps (RTMs) but available only in the portable\ndocument format (PDF). Using Deep Learning and Optical Character Recognition\ntechniques, this research work proposes a generic system to digitize the\nrelevant map component data from a given input image and create a formatted\ntext file per image. Out of YOLOv3, SSD and Faster-RCNN object detection models\nused, Faster-RCNN yields the highest mean Average Precision (mAP) and the\nhighest F1 score values 0.68 and 0.76 respectively. Further it is proven from\nthe results obtained that, one can improve the results with OCR when the text\ncontaining image is being sent through a sophisticated pre-processing pipeline\nto remove distortions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13229v1",
    "published_date": "2024-05-21 22:35:08 UTC",
    "updated_date": "2024-05-21 22:35:08 UTC"
  },
  {
    "arxiv_id": "2405.13220v2",
    "title": "Paired Autoencoders for Likelihood-free Estimation in Inverse Problems",
    "authors": [
      "Matthias Chung",
      "Emma Hart",
      "Julianne Chung",
      "Bas Peters",
      "Eldad Haber"
    ],
    "abstract": "We consider the solution of nonlinear inverse problems where the forward\nproblem is a discretization of a partial differential equation. Such problems\nare notoriously difficult to solve in practice and require minimizing a\ncombination of a data-fit term and a regularization term. The main\ncomputational bottleneck of typical algorithms is the direct estimation of the\ndata misfit. Therefore, likelihood-free approaches have become appealing\nalternatives. Nonetheless, difficulties in generalization and limitations in\naccuracy have hindered their broader utility and applicability. In this work,\nwe use a paired autoencoder framework as a likelihood-free estimator for\ninverse problems. We show that the use of such an architecture allows us to\nconstruct a solution efficiently and to overcome some known open problems when\nusing likelihood-free estimators. In particular, our framework can assess the\nquality of the solution and improve on it if needed. We demonstrate the\nviability of our approach using examples from full waveform inversion and\ninverse electromagnetic imaging.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13220v2",
    "published_date": "2024-05-21 22:00:34 UTC",
    "updated_date": "2024-12-03 16:00:40 UTC"
  },
  {
    "arxiv_id": "2405.13219v1",
    "title": "How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?",
    "authors": [
      "Ayesha Siddika Nipu",
      "K M Sajjadul Islam",
      "Praveen Madiraju"
    ],
    "abstract": "Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)\nare gaining traction in healthcare for their potential to automate patient\ninteractions and aid clinical decision-making. This study examines the\nreliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini\nUltra 1.0, in predicting diseases from patient complaints in the emergency\ndepartment. The methodology includes few-shot learning techniques to evaluate\nthe chatbots' effectiveness in disease prediction. We also fine-tune the\ntransformer-based model BERT and compare its performance with the AI chatbots.\nResults suggest that GPT 4.0 achieves high accuracy with increased few-shot\ndata, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3\nOpus maintains consistent performance. BERT's performance, however, is lower\nthan all the chatbots, indicating limitations due to limited labeled data.\nDespite the chatbots' varying accuracy, none of them are sufficiently reliable\nfor critical medical decision-making, underscoring the need for rigorous\nvalidation and human oversight. This study reflects that while AI chatbots have\npotential in healthcare, they should complement, not replace, human expertise\nto ensure patient safety. Further refinement and research are needed to improve\nAI-based healthcare applications' reliability for disease prediction.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "24th IEEE International Conference on Information Reuse and\n  Integration (IEEE IRI 2024), San Jose, CA, USA",
    "pdf_url": "http://arxiv.org/pdf/2405.13219v1",
    "published_date": "2024-05-21 22:00:13 UTC",
    "updated_date": "2024-05-21 22:00:13 UTC"
  },
  {
    "arxiv_id": "2405.13202v1",
    "title": "Empowering Urban Traffic Management: Elevated 3D LiDAR for Data Collection and Advanced Object Detection Analysis",
    "authors": [
      "Nawfal Guefrachi",
      "Hakim Ghazzai",
      "Ahmad Alsharoa"
    ],
    "abstract": "The 3D object detection capabilities in urban environments have been\nenormously improved by recent developments in Light Detection and Range (LiDAR)\ntechnology. This paper presents a novel framework that transforms the detection\nand analysis of 3D objects in traffic scenarios by utilizing the power of\nelevated LiDAR sensors. We are presenting our methodology's remarkable capacity\nto collect complex 3D point cloud data, which allows us to accurately and in\ndetail capture the dynamics of urban traffic. Due to the limitation in\nobtaining real-world traffic datasets, we utilize the simulator to generate 3D\npoint cloud for specific scenarios. To support our experimental analysis, we\nfirstly simulate various 3D point cloud traffic-related objects. Then, we use\nthis dataset as a basis for training and evaluating our 3D object detection\nmodels, in identifying and monitoring both vehicles and pedestrians in\nsimulated urban traffic environments. Next, we fine tune the Point\nVoxel-Region-based Convolutional Neural Network (PV-RCNN) architecture, making\nit more suited to handle and understand the massive volumes of point cloud data\ngenerated by our urban traffic simulations. Our results show the effectiveness\nof the proposed solution in accurately detecting objects in traffic scenes and\nhighlight the role of LiDAR in improving urban safety and advancing intelligent\ntransportation systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13202v1",
    "published_date": "2024-05-21 21:12:09 UTC",
    "updated_date": "2024-05-21 21:12:09 UTC"
  },
  {
    "arxiv_id": "2405.13196v2",
    "title": "Practical and efficient quantum circuit synthesis and transpiling with Reinforcement Learning",
    "authors": [
      "David Kremer",
      "Victor Villar",
      "Hanhee Paik",
      "Ivan Duran",
      "Ismael Faro",
      "Juan Cruz-Benito"
    ],
    "abstract": "This paper demonstrates the integration of Reinforcement Learning (RL) into\nquantum transpiling workflows, significantly enhancing the synthesis and\nrouting of quantum circuits. By employing RL, we achieve near-optimal synthesis\nof Linear Function, Clifford, and Permutation circuits, up to 9, 11 and 65\nqubits respectively, while being compatible with native device instruction sets\nand connectivity constraints, and orders of magnitude faster than optimization\nmethods such as SAT solvers. We also achieve significant reductions in\ntwo-qubit gate depth and count for circuit routing up to 133 qubits with\nrespect to other routing heuristics such as SABRE. We find the method to be\nefficient enough to be useful in practice in typical quantum transpiling\npipelines. Our results set the stage for further AI-powered enhancements of\nquantum computing workflows.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13196v2",
    "published_date": "2024-05-21 20:59:12 UTC",
    "updated_date": "2025-02-26 15:38:25 UTC"
  },
  {
    "arxiv_id": "2405.13195v1",
    "title": "CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers",
    "authors": [
      "Andrew Marmon",
      "Grant Schindler",
      "José Lezama",
      "Dan Kondratyuk",
      "Bryan Seybold",
      "Irfan Essa"
    ],
    "abstract": "We extend multimodal transformers to include 3D camera motion as a\nconditioning signal for the task of video generation. Generative video models\nare becoming increasingly powerful, thus focusing research efforts on methods\nof controlling the output of such models. We propose to add virtual 3D camera\ncontrols to generative video methods by conditioning generated video on an\nencoding of three-dimensional camera movement over the course of the generated\nvideo. Results demonstrate that we are (1) able to successfully control the\ncamera during video generation, starting from a single frame and a camera\nsignal, and (2) we demonstrate the accuracy of the generated 3D camera paths\nusing traditional computer vision methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13195v1",
    "published_date": "2024-05-21 20:54:27 UTC",
    "updated_date": "2024-05-21 20:54:27 UTC"
  },
  {
    "arxiv_id": "2405.13190v1",
    "title": "Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation",
    "authors": [
      "Haoteng Tang",
      "Guodong Liu",
      "Siyuan Dai",
      "Kai Ye",
      "Kun Zhao",
      "Wenlu Wang",
      "Carl Yang",
      "Lifang He",
      "Alex Leow",
      "Paul Thompson",
      "Heng Huang",
      "Liang Zhan"
    ],
    "abstract": "The MRI-derived brain network serves as a pivotal instrument in elucidating\nboth the structural and functional aspects of the brain, encompassing the\nramifications of diseases and developmental processes. However, prevailing\nmethodologies, often focusing on synchronous BOLD signals from functional MRI\n(fMRI), may not capture directional influences among brain regions and rarely\ntackle temporal functional dynamics. In this study, we first construct the\nbrain-effective network via the dynamic causal model. Subsequently, we\nintroduce an interpretable graph learning framework termed Spatio-Temporal\nEmbedding ODE (STE-ODE). This framework incorporates specifically designed\ndirected node embedding layers, aiming at capturing the dynamic interplay\nbetween structural and effective networks via an ordinary differential equation\n(ODE) model, which characterizes spatial-temporal brain dynamics. Our framework\nis validated on several clinical phenotype prediction tasks using two\nindependent publicly available datasets (HCP and OASIS). The experimental\nresults clearly demonstrate the advantages of our model compared to several\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13190v1",
    "published_date": "2024-05-21 20:37:07 UTC",
    "updated_date": "2024-05-21 20:37:07 UTC"
  },
  {
    "arxiv_id": "2407.12999v1",
    "title": "Securing the Future of GenAI: Policy and Technology",
    "authors": [
      "Mihai Christodorescu",
      "Ryan Craven",
      "Soheil Feizi",
      "Neil Gong",
      "Mia Hoffmann",
      "Somesh Jha",
      "Zhengyuan Jiang",
      "Mehrdad Saberi Kamarposhti",
      "John Mitchell",
      "Jessica Newman",
      "Emelia Probasco",
      "Yanjun Qi",
      "Khawaja Shams",
      "Matthew Turek"
    ],
    "abstract": "The rise of Generative AI (GenAI) brings about transformative potential\nacross sectors, but its dual-use nature also amplifies risks. Governments\nglobally are grappling with the challenge of regulating GenAI, balancing\ninnovation against safety. China, the United States (US), and the European\nUnion (EU) are at the forefront with initiatives like the Management of\nAlgorithmic Recommendations, the Executive Order, and the AI Act, respectively.\nHowever, the rapid evolution of GenAI capabilities often outpaces the\ndevelopment of comprehensive safety measures, creating a gap between regulatory\nneeds and technical advancements.\n  A workshop co-organized by Google, University of Wisconsin, Madison\n(UW-Madison), and Stanford University aimed to bridge this gap between GenAI\npolicy and technology. The diverse stakeholders of the GenAI space -- from the\npublic and governments to academia and industry -- make any safety measures\nunder consideration more complex, as both technical feasibility and regulatory\nguidance must be realized. This paper summarizes the discussions during the\nworkshop which addressed questions, such as: How regulation can be designed\nwithout hindering technological progress? How technology can evolve to meet\nregulatory standards? The interplay between legislation and technology is a\nvery vast topic, and we don't claim that this paper is a comprehensive\ntreatment on this topic. This paper is meant to capture findings based on the\nworkshop, and hopefully, can guide discussion on this topic.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12999v1",
    "published_date": "2024-05-21 20:30:01 UTC",
    "updated_date": "2024-05-21 20:30:01 UTC"
  },
  {
    "arxiv_id": "2405.13178v2",
    "title": "One-Shot Imitation Learning with Invariance Matching for Robotic Manipulation",
    "authors": [
      "Xinyu Zhang",
      "Abdeslam Boularias"
    ],
    "abstract": "Learning a single universal policy that can perform a diverse set of\nmanipulation tasks is a promising new direction in robotics. However, existing\ntechniques are limited to learning policies that can only perform tasks that\nare encountered during training, and require a large number of demonstrations\nto learn new tasks. Humans, on the other hand, often can learn a new task from\na single unannotated demonstration. In this work, we propose the\nInvariance-Matching One-shot Policy Learning (IMOP) algorithm. In contrast to\nthe standard practice of learning the end-effector's pose directly, IMOP first\nlearns invariant regions of the state space for a given task, and then computes\nthe end-effector's pose through matching the invariant regions between\ndemonstrations and test scenes. Trained on the 18 RLBench tasks, IMOP achieves\na success rate that outperforms the state-of-the-art consistently, by 4.5% on\naverage over the 18 tasks. More importantly, IMOP can learn a novel task from a\nsingle unannotated demonstration, and without any fine-tuning, and achieves an\naverage success rate improvement of $11.5\\%$ over the state-of-the-art on 22\nnovel tasks selected across nine categories. IMOP can also generalize to new\nshapes and learn to manipulate objects that are different from those in the\ndemonstration. Further, IMOP can perform one-shot sim-to-real transfer using a\nsingle real-robot demonstration.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "RSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13178v2",
    "published_date": "2024-05-21 20:01:03 UTC",
    "updated_date": "2024-06-05 01:11:10 UTC"
  },
  {
    "arxiv_id": "2407.12687v2",
    "title": "Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach",
    "authors": [
      "Irina Jurenka",
      "Markus Kunesch",
      "Kevin R. McKee",
      "Daniel Gillick",
      "Shaojian Zhu",
      "Sara Wiltberger",
      "Shubham Milind Phal",
      "Katherine Hermann",
      "Daniel Kasenberg",
      "Avishkar Bhoopchand",
      "Ankit Anand",
      "Miruna Pîslar",
      "Stephanie Chan",
      "Lisa Wang",
      "Jennifer She",
      "Parsa Mahmoudieh",
      "Aliya Rysbek",
      "Wei-Jen Ko",
      "Andrea Huber",
      "Brett Wiltshire",
      "Gal Elidan",
      "Roni Rabin",
      "Jasmin Rubinovitz",
      "Amit Pitaru",
      "Mac McAllister",
      "Julia Wilkowski",
      "David Choi",
      "Roee Engelberg",
      "Lidan Hackmon",
      "Adva Levin",
      "Rachel Griffin",
      "Michael Sears",
      "Filip Bar",
      "Mia Mesar",
      "Mana Jabbour",
      "Arslan Chaudhry",
      "James Cohan",
      "Sridhar Thiagarajan",
      "Nir Levine",
      "Ben Brown",
      "Dilan Gorur",
      "Svetlana Grant",
      "Rachel Hashimshoni",
      "Laura Weidinger",
      "Jieru Hu",
      "Dawn Chen",
      "Kuba Dolecki",
      "Canfer Akbulut",
      "Maxwell Bileschi",
      "Laura Culp",
      "Wen-Xin Dong",
      "Nahema Marchal",
      "Kelsie Van Deman",
      "Hema Bajaj Misra",
      "Michael Duah",
      "Moran Ambar",
      "Avi Caciularu",
      "Sandra Lefdal",
      "Chris Summerfield",
      "James An",
      "Pierre-Alexandre Kamienny",
      "Abhinit Mohdi",
      "Theofilos Strinopoulous",
      "Annie Hale",
      "Wayne Anderson",
      "Luis C. Cobo",
      "Niv Efron",
      "Muktha Ananda",
      "Shakir Mohamed",
      "Maureen Heymans",
      "Zoubin Ghahramani",
      "Yossi Matias",
      "Ben Gomes",
      "Lila Ibrahim"
    ],
    "abstract": "A major challenge facing the world is the provision of equitable and\nuniversal access to quality education. Recent advances in generative AI (gen\nAI) have created excitement about the potential of new technologies to offer a\npersonal tutor for every learner and a teaching assistant for every teacher.\nThe full extent of this dream, however, has not yet materialised. We argue that\nthis is primarily due to the difficulties with verbalising pedagogical\nintuitions into gen AI prompts and the lack of good evaluation practices,\nreinforced by the challenges in defining excellent pedagogy. Here we present\nour work collaborating with learners and educators to translate high level\nprinciples from learning science into a pragmatic set of seven diverse\neducational benchmarks, spanning quantitative, qualitative, automatic and human\nevaluations; and to develop a new set of fine-tuning datasets to improve the\npedagogical capabilities of Gemini, introducing LearnLM-Tutor. Our evaluations\nshow that LearnLM-Tutor is consistently preferred over a prompt tuned Gemini by\neducators and learners on a number of pedagogical dimensions. We hope that this\nwork can serve as a first step towards developing a comprehensive educational\nevaluation framework, and that this can enable rapid progress within the AI and\nEdTech communities towards maximising the positive impact of gen AI in\neducation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12687v2",
    "published_date": "2024-05-21 19:27:59 UTC",
    "updated_date": "2024-07-19 14:03:41 UTC"
  },
  {
    "arxiv_id": "2405.13166v2",
    "title": "FairLENS: Assessing Fairness in Law Enforcement Speech Recognition",
    "authors": [
      "Yicheng Wang",
      "Mark Cusick",
      "Mohamed Laila",
      "Kate Puech",
      "Zhengping Ji",
      "Xia Hu",
      "Michael Wilson",
      "Noah Spitzer-Williams",
      "Bryan Wheeler",
      "Yasser Ibrahim"
    ],
    "abstract": "Automatic speech recognition (ASR) techniques have become powerful tools,\nenhancing efficiency in law enforcement scenarios. To ensure fairness for\ndemographic groups in different acoustic environments, ASR engines must be\ntested across a variety of speakers in realistic settings. However, describing\nthe fairness discrepancies between models with confidence remains a challenge.\nMeanwhile, most public ASR datasets are insufficient to perform a satisfying\nfairness evaluation. To address the limitations, we built FairLENS - a\nsystematic fairness evaluation framework. We propose a novel and adaptable\nevaluation method to examine the fairness disparity between different models.\nWe also collected a fairness evaluation dataset covering multiple scenarios and\ndemographic dimensions. Leveraging this framework, we conducted fairness\nassessments on 1 open-source and 11 commercially available state-of-the-art ASR\nmodels. Our results reveal that certain models exhibit more biases than others,\nserving as a fairness guideline for users to make informed choices when\nselecting ASR models for a given real-world scenario. We further explored model\nbiases towards specific demographic groups and observed that shifts in the\nacoustic domain can lead to the emergence of new biases.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13166v2",
    "published_date": "2024-05-21 19:23:40 UTC",
    "updated_date": "2024-05-28 19:10:30 UTC"
  },
  {
    "arxiv_id": "2405.13162v1",
    "title": "Non-autoregressive real-time Accent Conversion model with voice cloning",
    "authors": [
      "Vladimir Nechaev",
      "Sergey Kosyakov"
    ],
    "abstract": "Currently, the development of Foreign Accent Conversion (FAC) models utilizes\ndeep neural network architectures, as well as ensembles of neural networks for\nspeech recognition and speech generation. The use of these models is limited by\narchitectural features, which does not allow flexible changes in the timbre of\nthe generated speech and requires the accumulation of context, leading to\nincreased delays in generation and makes these systems unsuitable for use in\nreal-time multi-user communication scenarios. We have developed the\nnon-autoregressive model for real-time accent conversion with voice cloning.\nThe model generates native-sounding L1 speech with minimal latency based on\ninput L2 accented speech. The model consists of interconnected modules for\nextracting accent, gender, and speaker embeddings, converting speech,\ngenerating spectrograms, and decoding the resulting spectrogram into an audio\nsignal. The model has the ability to save, clone and change the timbre, gender\nand accent of the speaker's voice in real time. The results of the objective\nassessment show that the model improves speech quality, leading to enhanced\nrecognition performance in existing ASR systems. The results of subjective\ntests show that the proposed accent and gender encoder improves the generation\nquality. The developed model demonstrates high-quality low-latency accent\nconversion, voice cloning, and speech enhancement capabilities, making it\nsuitable for real-time multi-user communication scenarios.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.13162v1",
    "published_date": "2024-05-21 19:07:26 UTC",
    "updated_date": "2024-05-21 19:07:26 UTC"
  },
  {
    "arxiv_id": "2405.17451v1",
    "title": "Green AI in Action: Strategic Model Selection for Ensembles in Production",
    "authors": [
      "Nienke Nijkamp",
      "June Sallou",
      "Niels van der Heijden",
      "Luís Cruz"
    ],
    "abstract": "Integrating Artificial Intelligence (AI) into software systems has\nsignificantly enhanced their capabilities while escalating energy demands.\nEnsemble learning, combining predictions from multiple models to form a single\nprediction, intensifies this problem due to cumulative energy consumption. This\npaper presents a novel approach to model selection that addresses the challenge\nof balancing the accuracy of AI models with their energy consumption in a live\nAI ensemble system. We explore how reducing the number of models or improving\nthe efficiency of model usage within an ensemble during inference can reduce\nenergy demands without substantially sacrificing accuracy. This study\nintroduces and evaluates two model selection strategies, Static and Dynamic,\nfor optimizing ensemble learning systems performance while minimizing energy\nusage. Our results demonstrate that the Static strategy improves the F1 score\nbeyond the baseline, reducing average energy usage from 100\\% from the full\nensemble to 6\\2%. The Dynamic strategy further enhances F1 scores, using on\naverage 76\\% compared to 100% of the full ensemble. Moreover, we propose an\napproach that balances accuracy with resource consumption, significantly\nreducing energy usage without substantially impacting accuracy. This method\ndecreased the average energy usage of the Static strategy from approximately\n62\\% to 14\\%, and for the Dynamic strategy, from around 76\\% to 57\\%. Our field\nstudy of Green AI using an operational AI system developed by a large\nprofessional services provider shows the practical applicability of adopting\nenergy-conscious model selection strategies in live production environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages. Accepted at the 1st ACM International Conference on\n  AI-powered Software (AIware), 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.17451v1",
    "published_date": "2024-05-21 18:57:43 UTC",
    "updated_date": "2024-05-21 18:57:43 UTC"
  },
  {
    "arxiv_id": "2405.13152v4",
    "title": "Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient",
    "authors": [
      "Shiji Huang",
      "Lei Ye",
      "Min Chen",
      "Wenhai Luo",
      "Dihong Wang",
      "Chenqi Xu",
      "Deyuan Liang"
    ],
    "abstract": "A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they assign correlation coefficients\nto surrounding agents in a purely learning-based manner. In this study, we\npresent ASPILin, which manually selects interacting agents and replaces the\nattention scores in Transformer with a newly computed physical correlation\ncoefficient, enhancing the interpretability of interaction modeling.\nSurprisingly, these simple modifications can significantly improve prediction\nperformance and substantially reduce computational costs. We intentionally\nsimplified our model in other aspects, such as map encoding. Remarkably,\nexperiments conducted on the INTERACTION, highD, and CitySim datasets\ndemonstrate that our method is efficient and straightforward, outperforming\nother state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "code:https://github.com/kkk00714/ASPILin",
    "pdf_url": "http://arxiv.org/pdf/2405.13152v4",
    "published_date": "2024-05-21 18:45:18 UTC",
    "updated_date": "2025-03-04 13:07:09 UTC"
  },
  {
    "arxiv_id": "2405.13144v3",
    "title": "LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages",
    "authors": [
      "Xuhan Huang",
      "Qingning Shen",
      "Yan Hu",
      "Anningzhe Gao",
      "Benyou Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance across\nvarious natural language processing tasks, yet their proficiency in\nmathematical reasoning remains a key challenge. Addressing the gap between\nnatural and mathematical language requires advanced reasoning capabilities,\napproaching those of Artificial General Intelligence (AGI). However, the\nevaluation remains challenging, as perfectly representing reality is inherently\nelusive, and traditional methods like manual or direct comparison of\nmathematical statements (Ramamonjison et al., 2023) are insufficient for\nassessing true modeling ability. We propose a process-oriented framework to\nevaluate LLMs' ability to construct mathematical models, using solvers to\ncompare outputs with ground truth. Introducing Mamo, a benchmark with 1,209\nquestions covering ordinary differential equations, linear programming, and\nmixed-integer linear programming, we enable automatic evaluation of modeling\naccuracy. The results show that existing LLMs struggle with complex\nmathematical modeling tasks, with larger models demonstrating superior\nperformance, while open-source models remain competitive in simpler cases but\nstill fall short of proprietary models in more challenging problems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Findings of NAACL2025. Project:\n  https://github.com/FreedomIntelligence/Mamo",
    "pdf_url": "http://arxiv.org/pdf/2405.13144v3",
    "published_date": "2024-05-21 18:29:54 UTC",
    "updated_date": "2025-02-15 13:45:56 UTC"
  },
  {
    "arxiv_id": "2405.13127v1",
    "title": "Towards Retrieval-Augmented Architectures for Image Captioning",
    "authors": [
      "Sara Sarto",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Alessandro Nicolosi",
      "Rita Cucchiara"
    ],
    "abstract": "The objective of image captioning models is to bridge the gap between the\nvisual and linguistic modalities by generating natural language descriptions\nthat accurately reflect the content of input images. In recent years,\nresearchers have leveraged deep learning-based models and made advances in the\nextraction of visual features and the design of multimodal connections to\ntackle this task. This work presents a novel approach towards developing image\ncaptioning models that utilize an external kNN memory to improve the generation\nprocess. Specifically, we propose two model variants that incorporate a\nknowledge retriever component that is based on visual similarities, a\ndifferentiable encoder to represent input images, and a kNN-augmented language\nmodel to predict tokens based on contextual cues and text retrieved from the\nexternal memory. We experimentally validate our approach on COCO and nocaps\ndatasets and demonstrate that incorporating an explicit external memory can\nsignificantly enhance the quality of captions, especially with a larger\nretrieval corpus. This work provides valuable insights into retrieval-augmented\ncaptioning models and opens up new avenues for improving image captioning at a\nlarger scale.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM Transactions on Multimedia Computing, Communications and\n  Applications (2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.13127v1",
    "published_date": "2024-05-21 18:02:07 UTC",
    "updated_date": "2024-05-21 18:02:07 UTC"
  },
  {
    "arxiv_id": "2405.12961v2",
    "title": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment",
    "authors": [
      "Shriram Chennakesavalu",
      "Frank Hu",
      "Sebastian Ibarraran",
      "Grant M. Rotskoff"
    ],
    "abstract": "Searching through chemical space is an exceptionally challenging problem\nbecause the number of possible molecules grows combinatorially with the number\nof atoms. Large, autoregressive models trained on databases of chemical\ncompounds have yielded powerful generators, but we still lack robust strategies\nfor generating molecules with desired properties. This molecular search problem\nclosely resembles the \"alignment\" problem for large language models, though for\nmany chemical tasks we have a specific and easily evaluable reward function.\nHere, we introduce an algorithm called energy rank alignment (ERA) that\nleverages an explicit reward function to produce a gradient-based objective\nthat we use to optimize autoregressive policies. We show theoretically that\nthis algorithm is closely related to proximal policy optimization (PPO) and\ndirect preference optimization (DPO), but has a minimizer that converges to an\nideal Gibbs-Boltzmann distribution with the reward playing the role of an\nenergy function. Furthermore, this algorithm is highly scalable, does not\nrequire reinforcement learning, and performs well relative to DPO when the\nnumber of preference observations per pairing is small. We deploy this approach\nto align molecular transformers and protein language models to generate\nmolecules and protein sequences, respectively, with externally specified\nproperties and find that it does so robustly, searching through diverse parts\nof chemical space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12961v2",
    "published_date": "2024-05-21 17:35:20 UTC",
    "updated_date": "2025-05-14 20:23:34 UTC"
  },
  {
    "arxiv_id": "2405.12951v1",
    "title": "Strategic Deployment of Honeypots in Blockchain-based IoT Systems",
    "authors": [
      "Daniel Commey",
      "Sena Hounsinou",
      "Garth V. Crosby"
    ],
    "abstract": "This paper addresses the challenge of enhancing cybersecurity in\nBlockchain-based Internet of Things (BIoTs) systems, which are increasingly\nvulnerable to sophisticated cyberattacks. It introduces an AI-powered system\nmodel for the dynamic deployment of honeypots, utilizing an Intrusion Detection\nSystem (IDS) integrated with smart contract functionalities on IoT nodes. This\nmodel enables the transformation of regular nodes into decoys in response to\nsuspicious activities, thereby strengthening the security of BIoT networks. The\npaper analyses strategic interactions between potential attackers and the\nAI-enhanced IDS through a game-theoretic model, specifically Bayesian games.\nThe model focuses on understanding and predicting sophisticated attacks that\nmay initially appear normal, emphasizing strategic decision-making, optimized\nhoneypot deployment, and adaptive strategies in response to evolving attack\npatterns.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12951v1",
    "published_date": "2024-05-21 17:27:00 UTC",
    "updated_date": "2024-05-21 17:27:00 UTC"
  },
  {
    "arxiv_id": "2405.17449v1",
    "title": "Image Based Character Recognition, Documentation System To Decode Inscription From Temple",
    "authors": [
      "Velmathi G",
      "Shangavelan M",
      "Harish D",
      "Krithikshun M S"
    ],
    "abstract": "This project undertakes the training and analysis of optical character\nrecognition OCR methods applied to 10th century ancient Tamil inscriptions\ndiscovered on the walls of the Brihadeeswarar Temple.The chosen OCR methods\ninclude Tesseract,a widely used OCR engine,using modern ICR techniques to pre\nprocess the raw data and a box editing software to finetune our model.The\nanalysis with Tesseract aims to evaluate their effectiveness in accurately\ndeciphering the nuances of the ancient Tamil characters.The performance of our\nmodel for the dataset are determined by their accuracy rate where the evaluated\ndataset divided into training set and testing set.By addressing the unique\nchallenges posed by the script's historical context,this study seeks to\ncontribute valuable insights to the broader field of OCR,facilitating improved\npreservation and interpretation of ancient inscriptions",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This research paper is a part of capstone project submitted to VIT\n  Chennai, VIT University",
    "pdf_url": "http://arxiv.org/pdf/2405.17449v1",
    "published_date": "2024-05-21 17:20:35 UTC",
    "updated_date": "2024-05-21 17:20:35 UTC"
  },
  {
    "arxiv_id": "2405.12933v2",
    "title": "Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs",
    "authors": [
      "Bilgehan Sel",
      "Priya Shanmugasundaram",
      "Mohammad Kachuee",
      "Kun Zhou",
      "Ruoxi Jia",
      "Ming Jin"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tasks such\nas summarization, arithmetic reasoning, and question answering. However, they\nencounter significant challenges in the domain of moral reasoning and ethical\ndecision-making, especially in complex scenarios with multiple stakeholders.\nThis paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing\nmoral reasoning in LLMs by exploring decisions' consequences from multiple\nstakeholder perspectives. Central to SKIG's mechanism is simulating\naccountability for actions, which, alongside empathy exercises and risk\nassessment, is pivotal to its effectiveness. We validate SKIG's performance\nacross various moral reasoning benchmarks with proprietary and opensource LLMs,\nand investigate its crucial components through extensive ablation analyses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024, long paper",
    "pdf_url": "http://arxiv.org/pdf/2405.12933v2",
    "published_date": "2024-05-21 17:04:44 UTC",
    "updated_date": "2024-06-02 18:48:56 UTC"
  },
  {
    "arxiv_id": "2405.13101v2",
    "title": "Evaluating AI-generated code for C++, Fortran, Go, Java, Julia, Matlab, Python, R, and Rust",
    "authors": [
      "Patrick Diehl",
      "Noujoud Nader",
      "Steve Brandt",
      "Hartmut Kaiser"
    ],
    "abstract": "This study evaluates the capabilities of ChatGPT versions 3.5 and 4 in\ngenerating code across a diverse range of programming languages. Our objective\nis to assess the effectiveness of these AI models for generating scientific\nprograms. To this end, we asked ChatGPT to generate three distinct codes: a\nsimple numerical integration, a conjugate gradient solver, and a parallel 1D\nstencil-based heat equation solver. The focus of our analysis was on the\ncompilation, runtime performance, and accuracy of the codes. While both\nversions of ChatGPT successfully created codes that compiled and ran (with some\nhelp), some languages were easier for the AI to use than others (possibly\nbecause of the size of the training sets used). Parallel codes -- even the\nsimple example we chose to study here -- also difficult for the AI to generate\ncorrectly.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13101v2",
    "published_date": "2024-05-21 17:04:37 UTC",
    "updated_date": "2024-07-05 18:04:56 UTC"
  },
  {
    "arxiv_id": "2405.12926v3",
    "title": "Trusting Fair Data: Leveraging Quality in Fairness-Driven Data Removal Techniques",
    "authors": [
      "Manh Khoi Duong",
      "Stefan Conrad"
    ],
    "abstract": "In this paper, we deal with bias mitigation techniques that remove specific\ndata points from the training set to aim for a fair representation of the\npopulation in that set. Machine learning models are trained on these\npre-processed datasets, and their predictions are expected to be fair. However,\nsuch approaches may exclude relevant data, making the attained subsets less\ntrustworthy for further usage. To enhance the trustworthiness of prior methods,\nwe propose additional requirements and objectives that the subsets must fulfill\nin addition to fairness: (1) group coverage, and (2) minimal data loss. While\nremoving entire groups may improve the measured fairness, this practice is very\nproblematic as failing to represent every group cannot be considered fair. In\nour second concern, we advocate for the retention of data while minimizing\ndiscrimination. By introducing a multi-objective optimization problem that\nconsiders fairness and data loss, we propose a methodology to find\nPareto-optimal solutions that balance these objectives. By identifying such\nsolutions, users can make informed decisions about the trade-off between\nfairness and data quality and select the most suitable subset for their\napplication. Our method is distributed as a Python package via PyPI under the\nname FairDo (https://github.com/mkduong-ai/fairdo).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The Version of Record of this contribution is published in Springer\n  LNCS 14912 and is available online at\n  https://doi.org/10.1007/978-3-031-68323-7_33",
    "pdf_url": "http://arxiv.org/pdf/2405.12926v3",
    "published_date": "2024-05-21 16:51:28 UTC",
    "updated_date": "2024-09-19 11:31:09 UTC"
  },
  {
    "arxiv_id": "2405.12923v1",
    "title": "Panmodal Information Interaction",
    "authors": [
      "Chirag Shah",
      "Ryen W. White"
    ],
    "abstract": "The emergence of generative artificial intelligence (GenAI) is transforming\ninformation interaction. For decades, search engines such as Google and Bing\nhave been the primary means of locating relevant information for the general\npopulation. They have provided search results in the same standard format (the\nso-called \"10 blue links\"). The recent ability to chat via natural language\nwith AI-based agents and have GenAI automatically synthesize answers in\nreal-time (grounded in top-ranked results) is changing how people interact with\nand consume information at massive scale. These two information interaction\nmodalities (traditional search and AI-powered chat) coexist in current search\nengines, either loosely coupled (e.g., as separate options/tabs) or tightly\ncoupled (e.g., integrated as a chat answer embedded directly within a\ntraditional search result page). We believe that the existence of these two\ndifferent modalities, and potentially many others, is creating an opportunity\nto re-imagine the search experience, capitalize on the strengths of many\nmodalities, and develop systems and strategies to support seamless flow between\nthem. We refer to these as panmodal experiences. Unlike monomodal experiences,\nwhere only one modality is available and/or used for the task at hand, panmodal\nexperiences make multiple modalities available to users (multimodal), directly\nsupport transitions between modalities (crossmodal), and seamlessly combine\nmodalities to tailor task assistance (transmodal). While our focus is search\nand chat, with learnings from insights from a survey of over 100 individuals\nwho have recently performed common tasks on these two modalities, we also\npresent a more general vision for the future of information interaction using\nmultiple modalities and the emergent capabilities of GenAI.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12923v1",
    "published_date": "2024-05-21 16:49:14 UTC",
    "updated_date": "2024-05-21 16:49:14 UTC"
  },
  {
    "arxiv_id": "2405.12910v3",
    "title": "Topic Classification of Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment",
    "authors": [
      "Holli Sargeant",
      "Ahmed Izzidien",
      "Felix Steffek"
    ],
    "abstract": "This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12910v3",
    "published_date": "2024-05-21 16:30:25 UTC",
    "updated_date": "2025-02-27 10:56:25 UTC"
  },
  {
    "arxiv_id": "2405.12900v1",
    "title": "Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents",
    "authors": [
      "San Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "Recent advancements in open-domain dialogue systems have been propelled by\nthe emergence of high-quality large language models (LLMs) and various\neffective training methodologies. Nevertheless, the presence of toxicity within\nthese models presents a significant challenge that can potentially diminish the\nuser experience. In this study, we introduce an innovative training algorithm,\nan improvement upon direct preference optimization (DPO), called adversarial\nDPO (ADPO). The ADPO algorithm is designed to train models to assign higher\nprobability distributions to preferred responses and lower distributions to\nunsafe responses, which are self-generated using the toxic control token. We\ndemonstrate that ADPO enhances the model's resilience against harmful\nconversations while minimizing performance degradation. Furthermore, we\nillustrate that ADPO offers a more stable training procedure compared to the\ntraditional DPO. To the best of our knowledge, this is the first adaptation of\nthe DPO algorithm that directly incorporates harmful data into the generative\nmodel, thereby reducing the need to artificially create safe dialogue data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures, accepted to NAACL findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12900v1",
    "published_date": "2024-05-21 16:14:55 UTC",
    "updated_date": "2024-05-21 16:14:55 UTC"
  },
  {
    "arxiv_id": "2405.13100v1",
    "title": "Better Simulations for Validating Causal Discovery with the DAG-Adaptation of the Onion Method",
    "authors": [
      "Bryan Andrews",
      "Erich Kummerfeld"
    ],
    "abstract": "The number of artificial intelligence algorithms for learning causal models\nfrom data is growing rapidly. Most ``causal discovery'' or ``causal structure\nlearning'' algorithms are primarily validated through simulation studies.\nHowever, no widely accepted simulation standards exist and publications often\nreport conflicting performance statistics -- even when only considering\npublications that simulate data from linear models. In response, several\nmanuscripts have criticized a popular simulation design for validating\nalgorithms in the linear case.\n  We propose a new simulation design for generating linear models for directed\nacyclic graphs (DAGs): the DAG-adaptation of the Onion (DaO) method. DaO\nsimulations are fundamentally different from existing simulations because they\nprioritize the distribution of correlation matrices rather than the\ndistribution of linear effects. Specifically, the DaO method uniformly samples\nthe space of all correlation matrices consistent with (i.e. Markov to) a DAG.\nWe also discuss how to sample DAGs and present methods for generating DAGs with\nscale-free in-degree or out-degree. We compare the DaO method against two\nalternative simulation designs and provide implementations of the DaO method in\nPython and R: https://github.com/bja43/DaO_simulation. We advocate for others\nto adopt DaO simulations as a fair universal benchmark.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13100v1",
    "published_date": "2024-05-21 16:04:25 UTC",
    "updated_date": "2024-05-21 16:04:25 UTC"
  },
  {
    "arxiv_id": "2405.12884v1",
    "title": "Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models",
    "authors": [
      "Abdurahmman Alzahrani",
      "Eyad Babkier",
      "Faisal Yanbaawi",
      "Firas Yanbaawi",
      "Hassan Alhuzali"
    ],
    "abstract": "In the current era of digital communication and widespread use of social\nmedia, it is crucial to develop an understanding of persuasive techniques\nemployed in written text. This knowledge is essential for effectively\ndiscerning accurate information and making informed decisions. To address this\nneed, this paper presents a comprehensive empirical study focused on\nidentifying persuasive techniques in Arabic social media content. To achieve\nthis objective, we utilize Pre-trained Language Models (PLMs) and leverage the\nArAlEval dataset, which encompasses two tasks: binary classification to\ndetermine the presence or absence of persuasion techniques, and multi-label\nclassification to identify the specific types of techniques employed in the\ntext. Our study explores three different learning approaches by harnessing the\npower of PLMs: feature extraction, fine-tuning, and prompt engineering\ntechniques. Through extensive experimentation, we find that the fine-tuning\napproach yields the highest results on the aforementioned dataset, achieving an\nf1-micro score of 0.865 and an f1-weighted score of 0.861. Furthermore, our\nanalysis sheds light on an interesting finding. While the performance of the\nGPT model is relatively lower compared to the other approaches, we have\nobserved that by employing few-shot learning techniques, we can enhance its\nresults by up to 20\\%. This offers promising directions for future research and\nexploration in this topic\\footnote{Upon Acceptance, the source code will be\nreleased on GitHub.}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12884v1",
    "published_date": "2024-05-21 15:55:09 UTC",
    "updated_date": "2024-05-21 15:55:09 UTC"
  },
  {
    "arxiv_id": "2405.12881v1",
    "title": "Explaining Expert Search and Team Formation Systems with ExES",
    "authors": [
      "Kiarash Golzadeh",
      "Lukasz Golab",
      "Jaroslaw Szlichta"
    ],
    "abstract": "Expert search and team formation systems operate on collaboration networks,\nwith nodes representing individuals, labeled with their skills, and edges\ndenoting collaboration relationships. Given a keyword query corresponding to\nthe desired skills, these systems identify experts that best match the query.\nHowever, state-of-the-art solutions to this problem lack transparency. To\naddress this issue, we propose ExES, a tool designed to explain expert search\nand team formation systems using factual and counterfactual methods from the\nfield of explainable artificial intelligence (XAI). ExES uses factual\nexplanations to highlight important skills and collaborations, and\ncounterfactual explanations to suggest new skills and collaborations to\nincrease the likelihood of being identified as an expert. Towards a practical\ndeployment as an interactive explanation tool, we present and experimentally\nevaluate a suite of pruning strategies to speed up the explanation search. In\nmany cases, our pruning strategies make ExES an order of magnitude faster than\nexhaustive search, while still producing concise and actionable explanations.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12881v1",
    "published_date": "2024-05-21 15:53:35 UTC",
    "updated_date": "2024-05-21 15:53:35 UTC"
  },
  {
    "arxiv_id": "2405.12868v1",
    "title": "Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics",
    "authors": [
      "Liming Wu",
      "Zhichao Hou",
      "Jirui Yuan",
      "Yu Rong",
      "Wenbing Huang"
    ],
    "abstract": "Learning to represent and simulate the dynamics of physical systems is a\ncrucial yet challenging task. Existing equivariant Graph Neural Network (GNN)\nbased methods have encapsulated the symmetry of physics, \\emph{e.g.},\ntranslations, rotations, etc, leading to better generalization ability.\nNevertheless, their frame-to-frame formulation of the task overlooks the\nnon-Markov property mainly incurred by unobserved dynamics in the environment.\nIn this paper, we reformulate dynamics simulation as a spatio-temporal\nprediction task, by employing the trajectory in the past period to recover the\nNon-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive\nGraph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to\nfulfill our purpose. At its core, we design a novel Equivariant Discrete\nFourier Transform (EDFT) to extract periodic patterns from the history frames,\nand then construct an Equivariant Spatial Module (ESM) to accomplish spatial\nmessage passing, and an Equivariant Temporal Module (ETM) with the forward\nattention and equivariant pooling mechanisms to aggregate temporal message. We\nevaluate our model on three real datasets corresponding to the molecular-,\nprotein- and macro-level. Experimental results verify the effectiveness of\nESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been published to the conference of NeurIPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.12868v1",
    "published_date": "2024-05-21 15:33:21 UTC",
    "updated_date": "2024-05-21 15:33:21 UTC"
  },
  {
    "arxiv_id": "2405.12862v2",
    "title": "Toward Constraint Compliant Goal Formulation and Planning",
    "authors": [
      "Steven J. Jones",
      "Robert E. Wray"
    ],
    "abstract": "One part of complying with norms, rules, and preferences is incorporating\nconstraints (such as knowledge of ethics) into one's goal formulation and\nplanning processing. We explore in a simple domain how the encoding of\nknowledge in different ethical frameworks influences an agent's goal\nformulation and planning processing and demonstrate ability of an agent to\nsatisfy and satisfice when its collection of relevant constraints includes a\nmix of \"hard\" and \"soft\" constraints of various types. How the agent attempts\nto comply with ethical constraints depends on the ethical framing and we\ninvestigate tradeoffs between deontological framing and utilitarian framing for\ncomplying with an ethical norm. Representative scenarios highlight how\nperforming the same task with different framings of the same norm leads to\ndifferent behaviors. Our explorations suggest an important role for\nmetacognitive judgments in resolving ethical conflicts during goal formulation\nand planning.",
    "categories": [
      "cs.AI",
      "I.2.11; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages + refs. 5 figures, 2 tables. Minor revisions based on\n  reviewer feedback. Accepted for presentation at Advances in Cognitive Systems\n  (Jun 2024, Palermo)",
    "pdf_url": "http://arxiv.org/pdf/2405.12862v2",
    "published_date": "2024-05-21 15:26:06 UTC",
    "updated_date": "2024-06-10 19:26:05 UTC"
  },
  {
    "arxiv_id": "2405.13099v1",
    "title": "The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach",
    "authors": [
      "Mohsen Jozani",
      "Jason A. Williams",
      "Ahmed Aleroud",
      "Sarbottam Bhagat"
    ],
    "abstract": "This study explores the relationship between informational support seeking\nquestions, responses, and helpfulness ratings in online health communities. We\ncreated a labeled data set of question-response pairs and developed multimodal\nmachine learning and deep learning models to reliably predict informational\nsupport questions and responses. We employed explainable AI to reveal the\nemotions embedded in informational support exchanges, demonstrating the\nimportance of emotion in providing informational support. This complex\ninterplay between emotional and informational support has not been previously\nresearched. The study refines social support theory and lays the groundwork for\nthe development of user decision aids. Further implications are discussed.",
    "categories": [
      "cs.AI",
      "cs.SI",
      "H.4.3; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13099v1",
    "published_date": "2024-05-21 15:15:08 UTC",
    "updated_date": "2024-05-21 15:15:08 UTC"
  },
  {
    "arxiv_id": "2405.12849v2",
    "title": "Adaptive Robotic Arm Control with a Spiking Recurrent Neural Network on a Digital Accelerator",
    "authors": [
      "Alejandro Linares-Barranco",
      "Luciano Prono",
      "Robert Lengenstein",
      "Giacomo Indiveri",
      "Charlotte Frenkel"
    ],
    "abstract": "With the rise of artificial intelligence, neural network simulations of\nbiological neuron models are being explored to reduce the footprint of learning\nand inference in resource-constrained task scenarios. A mainstream type of such\nnetworks are spiking neural networks (SNNs) based on simplified Integrate and\nFire models for which several hardware accelerators have emerged. Among them,\nthe ReckOn chip was introduced as a recurrent SNN allowing for both online\ntraining and execution of tasks based on arbitrary sensory modalities,\ndemonstrated for vision, audition, and navigation. As a fully digital and\nopen-source chip, we adapted ReckOn to be implemented on a Xilinx\nMultiprocessor System on Chip system (MPSoC), facilitating its deployment in\nembedded systems and increasing the setup flexibility. We present an overview\nof the system, and a Python framework to use it on a Pynq ZU platform. We\nvalidate the architecture and implementation in the new scenario of robotic arm\ncontrol, and show how the simulated accuracy is preserved with a peak\nperformance of 3.8M events processed per second.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Under review at ICECS'24",
    "pdf_url": "http://arxiv.org/pdf/2405.12849v2",
    "published_date": "2024-05-21 14:59:39 UTC",
    "updated_date": "2024-06-02 18:57:00 UTC"
  },
  {
    "arxiv_id": "2406.01601v3",
    "title": "Backpropagation-Free Multi-modal On-Device Model Adaptation via Cloud-Device Collaboration",
    "authors": [
      "Wei Ji",
      "Li Li",
      "Zheqi Lv",
      "Wenqiao Zhang",
      "Mengze Li",
      "Zhen Wan",
      "Wenqiang Lei",
      "Roger Zimmermann"
    ],
    "abstract": "In our increasingly interconnected world, where intelligent devices\ncontinually amass copious personalized multi-modal data, a pressing need arises\nto deliver high-quality, personalized device-aware services. However, this\nendeavor presents a multifaceted challenge to prevailing artificial\nintelligence (AI) systems primarily rooted in the cloud. As these systems\ngrapple with shifting data distributions between the cloud and devices, the\ntraditional approach of fine-tuning-based adaptation (FTA) exists the following\nissues: the costly and time-consuming data annotation required by FTA and the\nlooming risk of model overfitting. To surmount these challenges, we introduce a\nUniversal On-Device Multi-modal Model Adaptation Framework, revolutionizing\non-device model adaptation by striking a balance between efficiency and\neffectiveness. The framework features the Fast Domain Adaptor (FDA) hosted in\nthe cloud, providing tailored parameters for the Lightweight Multi-modal Model\non devices. To enhance adaptability across multi-modal tasks, the AnchorFrame\nDistribution Reasoner (ADR) minimizes communication costs. Our contributions,\nencapsulated in the Cloud-Device Collaboration Multi-modal Parameter Generation\n(CDC-MMPG) framework, represent a pioneering solution for on-Device Multi-modal\nModel Adaptation (DMMA). Extensive experiments validate the efficiency and\neffectiveness of our method, particularly in video question answering and\nretrieval tasks, driving forward the integration of intelligent devices into\nour daily lives.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01601v3",
    "published_date": "2024-05-21 14:42:18 UTC",
    "updated_date": "2024-11-18 23:06:46 UTC"
  },
  {
    "arxiv_id": "2405.12832v2",
    "title": "Wav-KAN: Wavelet Kolmogorov-Arnold Networks",
    "authors": [
      "Zavareh Bozorgasl",
      "Hao Chen"
    ],
    "abstract": "In this paper, we introduce Wav-KAN, an innovative neural network\narchitecture that leverages the Wavelet Kolmogorov-Arnold Networks (Wav-KAN)\nframework to enhance interpretability and performance. Traditional multilayer\nperceptrons (MLPs) and even recent advancements like Spl-KAN face challenges\nrelated to interpretability, training speed, robustness, computational\nefficiency, and performance. Wav-KAN addresses these limitations by\nincorporating wavelet functions into the Kolmogorov-Arnold network structure,\nenabling the network to capture both high-frequency and low-frequency\ncomponents of the input data efficiently. Wavelet-based approximations employ\northogonal or semi-orthogonal basis and maintain a balance between accurately\nrepresenting the underlying data structure and avoiding overfitting to the\nnoise. While continuous wavelet transform (CWT) has a lot of potentials, we\nalso employed discrete wavelet transform (DWT) for multiresolution analysis,\nwhich obviated the need for recalculation of the previous steps in finding the\ndetails. Analogous to how water conforms to the shape of its container, Wav-KAN\nadapts to the data structure, resulting in enhanced accuracy, faster training\nspeeds, and increased robustness compared to Spl-KAN and MLPs. Our results\nhighlight the potential of Wav-KAN as a powerful tool for developing\ninterpretable and high-performance neural networks, with applications spanning\nvarious fields. This work sets the stage for further exploration and\nimplementation of Wav-KAN in frameworks such as PyTorch and TensorFlow, aiming\nto make wavelets in KAN as widespread as activation functions like ReLU and\nsigmoid in universal approximation theory (UAT). The codes to replicate the\nsimulations are available at https://github.com/zavareh1/Wav-KAN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress; codes are available at are available at\n  https://github.com/zavareh1/Wav-KAN",
    "pdf_url": "http://arxiv.org/pdf/2405.12832v2",
    "published_date": "2024-05-21 14:36:16 UTC",
    "updated_date": "2024-05-27 15:12:55 UTC"
  },
  {
    "arxiv_id": "2405.12819v1",
    "title": "Large Language Models Meet NLP: A Survey",
    "authors": [
      "Libo Qin",
      "Qiguang Chen",
      "Xiachong Feng",
      "Yang Wu",
      "Yongheng Zhang",
      "Yinghui Li",
      "Min Li",
      "Wanxiang Che",
      "Philip S. Yu"
    ],
    "abstract": "While large language models (LLMs) like ChatGPT have shown impressive\ncapabilities in Natural Language Processing (NLP) tasks, a systematic\ninvestigation of their potential in this field remains largely unexplored. This\nstudy aims to address this gap by exploring the following questions: (1) How\nare LLMs currently applied to NLP tasks in the literature? (2) Have traditional\nNLP tasks already been solved with LLMs? (3) What is the future of the LLMs for\nNLP? To answer these questions, we take the first step to provide a\ncomprehensive overview of LLMs in NLP. Specifically, we first introduce a\nunified taxonomy including (1) parameter-frozen application and (2)\nparameter-tuning application to offer a unified perspective for understanding\nthe current progress of LLMs in NLP. Furthermore, we summarize the new\nfrontiers and the associated challenges, aiming to inspire further\ngroundbreaking advancements. We hope this work offers valuable insights into\nthe {potential and limitations} of LLMs in NLP, while also serving as a\npractical guide for building effective LLMs in NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12819v1",
    "published_date": "2024-05-21 14:24:01 UTC",
    "updated_date": "2024-05-21 14:24:01 UTC"
  },
  {
    "arxiv_id": "2405.17221v1",
    "title": "Efficient Orchestrated AI Workflows Execution on Scale-out Spatial Architecture",
    "authors": [
      "Jinyi Deng",
      "Xinru Tang",
      "Zhiheng Yue",
      "Guangyang Lu",
      "Qize Yang",
      "Jiahao Zhang",
      "Jinxi Li",
      "Chao Li",
      "Shaojun Wei",
      "Yang Hu",
      "Shouyi Yin"
    ],
    "abstract": "Given the increasing complexity of AI applications, traditional spatial\narchitectures frequently fall short. Our analysis identifies a pattern of\ninterconnected, multi-faceted tasks encompassing both AI and general\ncomputational processes. In response, we have conceptualized \"Orchestrated AI\nWorkflows,\" an approach that integrates various tasks with logic-driven\ndecisions into dynamic, sophisticated workflows. Specifically, we find that the\nintrinsic Dual Dynamicity of Orchestrated AI Workflows, namely dynamic\nexecution times and frequencies of Task Blocks, can be effectively represented\nusing the Orchestrated Workflow Graph. Furthermore, the intrinsic Dual\nDynamicity poses challenges to existing spatial architecture, namely\nIndiscriminate Resource Allocation, Reactive Load Rebalancing, and Contagious\nPEA Idleness.\n  To overcome these challenges, we present Octopus, a scale-out spatial\narchitecture and a suite of advanced scheduling strategies optimized for\nexecuting Orchestrated AI Workflows, such as the Discriminate Dual-Scheduling\nMechanism, Adaptive TBU Scheduling Strategy, and Proactive Cluster Scheduling\nStrategy. Our evaluations demonstrate that Octopus significantly outperforms\ntraditional architectures in handling the dynamic demands of Orchestrated AI\nWorkflows, and possesses robust scalability in large scale hardware such as\nwafer-scale chip.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17221v1",
    "published_date": "2024-05-21 14:09:31 UTC",
    "updated_date": "2024-05-21 14:09:31 UTC"
  },
  {
    "arxiv_id": "2405.12807v11",
    "title": "FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information",
    "authors": [
      "Dongseong Hwang"
    ],
    "abstract": "This paper establishes a mathematical foundation for the Adam optimizer,\nelucidating its connection to natural gradient descent through Riemannian and\ninformation geometry. We provide an accessible and detailed analysis of the\ndiagonal empirical Fisher information matrix (FIM) in Adam, clarifying all\ndetailed approximations and advocating for the use of log probability functions\nas loss, which should be based on discrete distributions, due to the\nlimitations of empirical FIM. Our analysis uncovers flaws in the original Adam\nalgorithm, leading to proposed corrections such as enhanced momentum\ncalculations, adjusted bias corrections, adaptive epsilon, and gradient\nclipping. We refine the weight decay term based on our theoretical framework.\nOur modified algorithm, Fisher Adam (FAdam), demonstrates superior performance\nacross diverse domains including LLM, ASR, and VQ-VAE, achieving\nstate-of-the-art results in ASR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 4 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.12807v11",
    "published_date": "2024-05-21 13:58:17 UTC",
    "updated_date": "2024-09-03 21:00:39 UTC"
  },
  {
    "arxiv_id": "2405.13095v1",
    "title": "Presentations are not always linear! GNN meets LLM for Document-to-Presentation Transformation with Attribution",
    "authors": [
      "Himanshu Maheshwari",
      "Sambaran Bandyopadhyay",
      "Aparna Garimella",
      "Anandhavelu Natarajan"
    ],
    "abstract": "Automatically generating a presentation from the text of a long document is a\nchallenging and useful problem. In contrast to a flat summary, a presentation\nneeds to have a better and non-linear narrative, i.e., the content of a slide\ncan come from different and non-contiguous parts of the given document.\nHowever, it is difficult to incorporate such non-linear mapping of content to\nslides and ensure that the content is faithful to the document. LLMs are prone\nto hallucination and their performance degrades with the length of the input\ndocument. Towards this, we propose a novel graph based solution where we learn\na graph from the input document and use a combination of graph neural network\nand LLM to generate a presentation with attribution of content for each slide.\nWe conduct thorough experiments to show the merit of our approach compared to\ndirectly using LLMs for this task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is under review in a conference",
    "pdf_url": "http://arxiv.org/pdf/2405.13095v1",
    "published_date": "2024-05-21 13:52:33 UTC",
    "updated_date": "2024-05-21 13:52:33 UTC"
  },
  {
    "arxiv_id": "2405.12785v1",
    "title": "Artificial Intelligence Approaches for Predictive Maintenance in the Steel Industry: A Survey",
    "authors": [
      "Jakub Jakubowski",
      "Natalia Wojak-Strzelecka",
      "Rita P. Ribeiro",
      "Sepideh Pashami",
      "Szymon Bobek",
      "Joao Gama",
      "Grzegorz J Nalepa"
    ],
    "abstract": "Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,\nand became crucial for enhancing operational efficiency, allowing to minimize\ndowntime, extend lifespan of equipment, and prevent failures. A wide range of\nPdM tasks can be performed using Artificial Intelligence (AI) methods, which\noften use data generated from industrial sensors. The steel industry, which is\nan important branch of the global economy, is one of the potential\nbeneficiaries of this trend, given its large environmental footprint, the\nglobalized nature of the market, and the demanding working conditions. This\nsurvey synthesizes the current state of knowledge in the field of AI-based PdM\nwithin the steel industry and is addressed to researchers and practitioners. We\nidentified 219 articles related to this topic and formulated five research\nquestions, allowing us to gain a global perspective on current trends and the\nmain research gaps. We examined equipment and facilities subjected to PdM,\ndetermined common PdM approaches, and identified trends in the AI methods used\nto develop these solutions. We explored the characteristics of the data used in\nthe surveyed articles and assessed the practical implications of the research\npresented there. Most of the research focuses on the blast furnace or hot\nrolling, using data from industrial sensors. Current trends show increasing\ninterest in the domain, especially in the use of deep learning. The main\nchallenges include implementing the proposed methods in a production\nenvironment, incorporating them into maintenance plans, and enhancing the\naccessibility and reproducibility of the research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2405.12785v1",
    "published_date": "2024-05-21 13:32:46 UTC",
    "updated_date": "2024-05-21 13:32:46 UTC"
  },
  {
    "arxiv_id": "2405.12779v1",
    "title": "Transformer in Touch: A Survey",
    "authors": [
      "Jing Gao",
      "Ning Cheng",
      "Bin Fang",
      "Wenjuan Han"
    ],
    "abstract": "The Transformer model, initially achieving significant success in the field\nof natural language processing, has recently shown great potential in the\napplication of tactile perception. This review aims to comprehensively outline\nthe application and development of Transformers in tactile technology. We first\nintroduce the two fundamental concepts behind the success of the Transformer:\nthe self-attention mechanism and large-scale pre-training. Then, we delve into\nthe application of Transformers in various tactile tasks, including but not\nlimited to object recognition, cross-modal generation, and object manipulation,\noffering a concise summary of the core methodologies, performance benchmarks,\nand design highlights. Finally, we suggest potential areas for further research\nand future work, aiming to generate more interest within the community, tackle\nexisting challenges, and encourage the use of Transformer models in the tactile\nfield.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 2 tables, 5 figures, accepted by ICIC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12779v1",
    "published_date": "2024-05-21 13:26:27 UTC",
    "updated_date": "2024-05-21 13:26:27 UTC"
  },
  {
    "arxiv_id": "2405.12775v1",
    "title": "Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances",
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Fei Long",
      "Xin Wang",
      "Kai Gao"
    ],
    "abstract": "Discovering the semantics of multimodal utterances is essential for\nunderstanding human language and enhancing human-machine interactions. Existing\nmethods manifest limitations in leveraging nonverbal information for discerning\ncomplex semantics in unsupervised scenarios. This paper introduces a novel\nunsupervised multimodal clustering method (UMC), making a pioneering\ncontribution to this field. UMC introduces a unique approach to constructing\naugmentation views for multimodal data, which are then used to perform\npre-training to establish well-initialized representations for subsequent\nclustering. An innovative strategy is proposed to dynamically select\nhigh-quality samples as guidance for representation learning, gauged by the\ndensity of each sample's nearest neighbors. Besides, it is equipped to\nautomatically determine the optimal value for the top-$K$ parameter in each\ncluster to refine sample selection. Finally, both high- and low-quality samples\nare used to learn representations conducive to effective clustering. We build\nbaselines on benchmark multimodal intent and dialogue act datasets. UMC shows\nremarkable improvements of 2-6\\% scores in clustering metrics over\nstate-of-the-art methods, marking the first successful endeavor in this domain.\nThe complete code and data are available at https://github.com/thuiar/UMC.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by ACL 2024, Main Conference, Long Paper",
    "pdf_url": "http://arxiv.org/pdf/2405.12775v1",
    "published_date": "2024-05-21 13:24:07 UTC",
    "updated_date": "2024-05-21 13:24:07 UTC"
  },
  {
    "arxiv_id": "2405.12774v1",
    "title": "Blind Separation of Vibration Sources using Deep Learning and Deconvolution",
    "authors": [
      "Igor Makienko",
      "Michael Grebshtein",
      "Eli Gildish"
    ],
    "abstract": "Vibrations of rotating machinery primarily originate from two sources, both\nof which are distorted by the machine's transfer function on their way to the\nsensor: the dominant gear-related vibrations and a low-energy signal linked to\nbearing faults. The proposed method facilitates the blind separation of\nvibration sources, eliminating the need for any information about the monitored\nequipment or external measurements. This method estimates both sources in two\nstages: initially, the gear signal is isolated using a dilated CNN, followed by\nthe estimation of the bearing fault signal using the squared log envelope of\nthe residual. The effect of the transfer function is removed from both sources\nusing a novel whitening-based deconvolution method (WBD). Both simulation and\nexperimental results demonstrate the method's ability to detect bearing\nfailures early when no additional information is available. This study\nconsiders both local and distributed bearing faults, assuming that the\nvibrations are recorded under stable operating conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.12774v1",
    "published_date": "2024-05-21 13:24:05 UTC",
    "updated_date": "2024-05-21 13:24:05 UTC"
  },
  {
    "arxiv_id": "2405.13094v1",
    "title": "KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning",
    "authors": [
      "Yusong Zhang",
      "Kun Xie",
      "Xingyi Zhang",
      "Xiangyu Dong",
      "Sibo Wang"
    ],
    "abstract": "The proliferation of rumors on social media platforms during significant\nevents, such as the US elections and the COVID-19 pandemic, has a profound\nimpact on social stability and public health. Existing approaches for rumor\ndetection primarily rely on propagation graphs to enhance model effectiveness.\nHowever, the presence of noisy and irrelevant structures during the propagation\nprocess limits the efficacy of these approaches. To tackle this issue,\ntechniques such as weight adjustment and data augmentation have been proposed.\nHowever, these techniques heavily depend on rich original propagation\nstructures, thus hindering performance when dealing with rumors that lack\nsufficient propagation information in the early propagation stages. In this\npaper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement\nlearning-based rumor detection framework that generates contextually coherent\nand informative propagation patterns for events with insufficient topology\ninformation, while also identifies indicative substructures for events with\nredundant and noisy propagation structures. KPG consists of two key components:\nthe Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG\nlearns the latent distribution from refined propagation patterns, filtering out\nnoise and generating new candidates for ENS. Simultaneously, ENS identifies the\nmost influential substructures within propagation graphs and generates training\ndata for CRG. Moreover, we introduce an end-to-end framework that utilizes\nrewards to guide the entire training process via a pre-trained graph neural\nnetwork. Extensive experiments conducted on four datasets demonstrate the\nsuperiority of our KPG compared to the state-of-the-art approaches.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13094v1",
    "published_date": "2024-05-21 13:13:43 UTC",
    "updated_date": "2024-05-21 13:13:43 UTC"
  },
  {
    "arxiv_id": "2405.12755v2",
    "title": "Progress Measures for Grokking on Real-world Tasks",
    "authors": [
      "Satvik Golechha"
    ],
    "abstract": "Grokking, a phenomenon where machine learning models generalize long after\noverfitting, has been primarily observed and studied in algorithmic tasks. This\npaper explores grokking in real-world datasets using deep neural networks for\nclassification under the cross-entropy loss. We challenge the prevalent\nhypothesis that the $L_2$ norm of weights is the primary cause of grokking by\ndemonstrating that grokking can occur outside the expected range of weight\nnorms. To better understand grokking, we introduce three new progress measures:\nactivation sparsity, absolute weight entropy, and approximate local circuit\ncomplexity. These measures are conceptually related to generalization and\ndemonstrate a stronger correlation with grokking in real-world datasets\ncompared to weight norms. Our findings suggest that while weight norms might\nusually correlate with grokking and our progress measures, they are not\ncausative, and our proposed measures provide a better understanding of the\ndynamics of grokking.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.12755v2",
    "published_date": "2024-05-21 13:06:41 UTC",
    "updated_date": "2024-06-20 07:39:05 UTC"
  },
  {
    "arxiv_id": "2405.12754v3",
    "title": "Global-local Fourier Neural Operator for Accelerating Coronal Magnetic Field Model",
    "authors": [
      "Yutao Du",
      "Qin Li",
      "Raghav Gnanasambandam",
      "Mengnan Du",
      "Haimin Wang",
      "Bo Shen"
    ],
    "abstract": "Exploring the outer atmosphere of the sun has remained a significant\nbottleneck in astrophysics, given the intricate magnetic formations that\nsignificantly influence diverse solar events. Magnetohydrodynamics (MHD)\nsimulations allow us to model the complex interactions between the sun's\nplasma, magnetic fields, and the surrounding environment. However, MHD\nsimulation is extremely time-consuming, taking days or weeks for simulation.\nThe goal of this study is to accelerate coronal magnetic field simulation using\ndeep learning, specifically, the Fourier Neural Operator (FNO). FNO has been\nproven to be an ideal tool for scientific computing and discovery in the\nliterature. In this paper, we proposed a global-local Fourier Neural Operator\n(GL-FNO) that contains two branches of FNOs: the global FNO branch takes\ndownsampled input to reconstruct global features while the local FNO branch\ntakes original resolution input to capture fine details. The performance of the\nGLFNO is compared with state-of-the-art deep learning methods, including FNO,\nU-NO, U-FNO, Vision Transformer, CNN-RNN, and CNN-LSTM, to demonstrate its\naccuracy, computational efficiency, and scalability. Furthermore, physics\nanalysis from domain experts is also performed to demonstrate the reliability\nof GL-FNO. The results demonstrate that GL-FNO not only accelerates the MHD\nsimulation (a few seconds for prediction, more than \\times 20,000 speed up) but\nalso provides reliable prediction capabilities, thus greatly contributing to\nthe understanding of space weather dynamics. Our code implementation is\navailable at https://github.com/Yutao-0718/GL-FNO",
    "categories": [
      "astro-ph.SR",
      "cs.AI",
      "cs.LG",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.12754v3",
    "published_date": "2024-05-21 13:04:53 UTC",
    "updated_date": "2024-09-08 15:28:18 UTC"
  },
  {
    "arxiv_id": "2405.12750v2",
    "title": "Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities",
    "authors": [
      "Mohamed Amine Ferrag",
      "Fatima Alwahedi",
      "Ammar Battah",
      "Bilel Cherif",
      "Abdechakour Mechri",
      "Norbert Tihanyi",
      "Tamas Bisztray",
      "Merouane Debbah"
    ],
    "abstract": "This paper provides a comprehensive review of the future of cybersecurity\nthrough Generative AI and Large Language Models (LLMs). We explore LLM\napplications across various domains, including hardware design security,\nintrusion detection, software engineering, design verification, cyber threat\nintelligence, malware detection, and phishing detection. We present an overview\nof LLM evolution and its current state, focusing on advancements in models such\nas GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends\nto LLM vulnerabilities, such as prompt injection, insecure output handling,\ndata poisoning, DDoS attacks, and adversarial instructions. We delve into\nmitigation strategies to protect these models, providing a comprehensive look\nat potential attack scenarios and prevention techniques. Furthermore, we\nevaluate the performance of 42 LLM models in cybersecurity knowledge and\nhardware security, highlighting their strengths and weaknesses. We thoroughly\nevaluate cybersecurity datasets for LLM training and testing, covering the\nlifecycle from data creation to usage and identifying gaps for future research.\nIn addition, we review new strategies for leveraging LLMs, including techniques\nlike Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human\nFeedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank\nAdapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim\nto enhance real-time cybersecurity defenses and improve the sophistication of\nLLM applications in threat detection and response. Our paper provides a\nfoundational understanding and strategic direction for integrating LLMs into\nfuture cybersecurity frameworks, emphasizing innovation and robust model\ndeployment to safeguard against evolving cyber threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "52 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.12750v2",
    "published_date": "2024-05-21 13:02:27 UTC",
    "updated_date": "2025-01-17 11:10:05 UTC"
  },
  {
    "arxiv_id": "2405.13093v2",
    "title": "Graph neural networks informed locally by thermodynamics",
    "authors": [
      "Alicia Tierz",
      "Iciar Alfaro",
      "David González",
      "Francisco Chinesta",
      "Elías Cueto"
    ],
    "abstract": "Thermodynamics-informed neural networks employ inductive biases for the\nenforcement of the first and second principles of thermodynamics. To construct\nthese biases, a metriplectic evolution of the system is assumed. This provides\nexcellent results, when compared to uninformed, black box networks. While the\ndegree of accuracy can be increased in one or two orders of magnitude, in the\ncase of graph networks, this requires assembling global Poisson and dissipation\nmatrices, which breaks the local structure of such networks. In order to avoid\nthis drawback, a local version of the metriplectic biases has been developed in\nthis work, which avoids the aforementioned matrix assembly, thus preserving the\nnode-by-node structure of the graph networks. We apply this framework for\nexamples in the fields of solid and fluid mechanics. Our approach demonstrates\nsignificant computational efficiency and strong generalization capabilities,\naccurately making inferences on examples significantly different from those\nencountered during training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13093v2",
    "published_date": "2024-05-21 12:57:10 UTC",
    "updated_date": "2025-01-20 11:03:41 UTC"
  },
  {
    "arxiv_id": "2405.15812v2",
    "title": "Pseudo Channel: Time Embedding for Motor Imagery Decoding",
    "authors": [
      "Zhengqing Miao",
      "Meirong Zhao"
    ],
    "abstract": "Motor imagery (MI) based EEG represents a frontier in enabling direct neural\ncontrol of external devices and advancing neural rehabilitation. This study\nintroduces a novel time embedding technique, termed traveling-wave based time\nembedding, utilized as a pseudo channel to enhance the decoding accuracy of\nMI-EEG signals across various neural network architectures. Unlike traditional\nneural network methods that fail to account for the temporal dynamics in MI-EEG\nin individual difference, our approach captures time-related changes for\ndifferent participants based on a priori knowledge. Through extensive\nexperimentation with multiple participants, we demonstrate that this method not\nonly improves classification accuracy but also exhibits greater adaptability to\nindividual differences compared to position encoding used in Transformer\narchitecture. Significantly, our results reveal that traveling-wave based time\nembedding crucially enhances decoding accuracy, particularly for participants\ntypically considered \"EEG-illiteracy\". As a novel direction in EEG research,\nthe traveling-wave based time embedding not only offers fresh insights for\nneural network decoding strategies but also expands new avenues for research\ninto attention mechanisms in neuroscience and a deeper understanding of EEG\nsignals.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.15812v2",
    "published_date": "2024-05-21 12:55:11 UTC",
    "updated_date": "2024-08-23 11:53:26 UTC"
  },
  {
    "arxiv_id": "2405.12716v1",
    "title": "Reinforcement Learning Enabled Peer-to-Peer Energy Trading for Dairy Farms",
    "authors": [
      "Mian Ibad Ali Shah",
      "Enda Barrett",
      "Karl Mason"
    ],
    "abstract": "Farm businesses are increasingly adopting renewables to enhance energy\nefficiency and reduce reliance on fossil fuels and the grid. This shift aims to\ndecrease dairy farms' dependence on traditional electricity grids by enabling\nthe sale of surplus renewable energy in Peer-to-Peer markets. However, the\ndynamic nature of farm communities poses challenges, requiring specialized\nalgorithms for P2P energy trading. To address this, the Multi-Agent\nPeer-to-Peer Dairy Farm Energy Simulator (MAPDES) has been developed, providing\na platform to experiment with Reinforcement Learning techniques. The\nsimulations demonstrate significant cost savings, including a 43% reduction in\nelectricity expenses, a 42% decrease in peak demand, and a 1.91% increase in\nenergy sales compared to baseline scenarios lacking peer-to-peer energy trading\nor renewable energy sources.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Proc. of the Main Track of 22nd International Conference on Practical\n  Applications of Agents and Multi-Agent Systems, 26th-28th June, 2024,\n  https://www.paams.net/. Includes 6 figures, 1 table and 32 references",
    "pdf_url": "http://arxiv.org/pdf/2405.12716v1",
    "published_date": "2024-05-21 12:19:17 UTC",
    "updated_date": "2024-05-21 12:19:17 UTC"
  },
  {
    "arxiv_id": "2405.13092v1",
    "title": "CausalPlayground: Addressing Data-Generation Requirements in Cutting-Edge Causality Research",
    "authors": [
      "Andreas W M Sauter",
      "Erman Acar",
      "Aske Plaat"
    ],
    "abstract": "Research on causal effects often relies on synthetic data due to the scarcity\nof real-world datasets with ground-truth effects. Since current data-generating\ntools do not always meet all requirements for state-of-the-art research, ad-hoc\nmethods are often employed. This leads to heterogeneity among datasets and\ndelays research progress. We address the shortcomings of current\ndata-generating libraries by introducing CausalPlayground, a Python library\nthat provides a standardized platform for generating, sampling, and sharing\nstructural causal models (SCMs). CausalPlayground offers fine-grained control\nover SCMs, interventions, and the generation of datasets of SCMs for learning\nand quantitative research. Furthermore, by integrating with Gymnasium, the\nstandard framework for reinforcement learning (RL) environments, we enable\nonline interaction with the SCMs. Overall, by introducing CausalPlayground we\naim to foster more efficient and comparable research in the field. All code and\nAPI documentation is available at https://github.com/sa-and/CausalPlayground.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13092v1",
    "published_date": "2024-05-21 12:08:48 UTC",
    "updated_date": "2024-05-21 12:08:48 UTC"
  },
  {
    "arxiv_id": "2405.12712v1",
    "title": "From Human-to-Human to Human-to-Bot Conversations in Software Engineering",
    "authors": [
      "Ranim Khojah",
      "Francisco Gomes de Oliveira Neto",
      "Philipp Leitner"
    ],
    "abstract": "Software developers use natural language to interact not only with other\nhumans, but increasingly also with chatbots. These interactions have different\nproperties and flow differently based on what goal the developer wants to\nachieve and who they interact with. In this paper, we aim to understand the\ndynamics of conversations that occur during modern software development after\nthe integration of AI and chatbots, enabling a deeper recognition of the\nadvantages and disadvantages of including chatbot interactions in addition to\nhuman conversations in collaborative work. We compile existing conversation\nattributes with humans and NLU-based chatbots and adapt them to the context of\nsoftware development. Then, we extend the comparison to include LLM-powered\nchatbots based on an observational study. We present similarities and\ndifferences between human-to-human and human-to-bot conversations, also\ndistinguishing between NLU- and LLM-based chatbots. Furthermore, we discuss how\nunderstanding the differences among the conversation styles guides the\ndeveloper on how to shape their expectations from a conversation and\nconsequently support the communication within a software team. We conclude that\nthe recent conversation styles that we observe with LLM-chatbots can not\nreplace conversations with humans due to certain attributes regarding social\naspects despite their ability to support productivity and decrease the\ndevelopers' mental load.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the 1st ACM International Conference on AI-powered\n  Software (AIware) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12712v1",
    "published_date": "2024-05-21 12:04:55 UTC",
    "updated_date": "2024-05-21 12:04:55 UTC"
  },
  {
    "arxiv_id": "2405.12711v2",
    "title": "A Masked Semi-Supervised Learning Approach for Otago Micro Labels Recognition",
    "authors": [
      "Meng Shang",
      "Lenore Dedeyne",
      "Jolan Dupont",
      "Laura Vercauteren",
      "Nadjia Amini",
      "Laurence Lapauw",
      "Evelien Gielen",
      "Sabine Verschueren",
      "Carolina Varon",
      "Walter De Raedt",
      "Bart Vanrumste"
    ],
    "abstract": "The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative\nfor older adults, aiming to enhance their strength and balance, and\nconsequently prevent falls. While Human Activity Recognition (HAR) systems have\nbeen widely employed in recognizing the activities of individuals, existing\nsystems focus on the duration of macro activities (i.e. a sequence of\nrepetitions of the same exercise), neglecting the ability to discern micro\nactivities (i.e. the individual repetitions of the exercises), in the case of\nOEP. This study presents a novel semi-supervised machine learning approach\naimed at bridging this gap in recognizing the micro activities of OEP. To\nmanage the limited dataset size, our model utilizes a Transformer encoder for\nfeature extraction, subsequently classified by a Temporal Convolutional Network\n(TCN). Simultaneously, the Transformer encoder is employed for masked\nunsupervised learning to reconstruct input signals. Results indicate that the\nmasked unsupervised learning task enhances the performance of the supervised\nlearning (classification task), as evidenced by f1-scores surpassing the\nclinically applicable threshold of 0.8. From the micro activities, two\nclinically relevant outcomes emerge: counting the number of repetitions of each\nexercise and calculating the velocity during chair rising. These outcomes\nenable the automatic monitoring of exercise intensity and difficulty in the\ndaily lives of older adults.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12711v2",
    "published_date": "2024-05-21 12:00:01 UTC",
    "updated_date": "2024-05-22 19:35:34 UTC"
  },
  {
    "arxiv_id": "2405.12701v3",
    "title": "OLAPH: Improving Factuality in Biomedical Long-form Question Answering",
    "authors": [
      "Minbyul Jeong",
      "Hyeon Hwang",
      "Chanwoong Yoon",
      "Taewhoo Lee",
      "Jaewoo Kang"
    ],
    "abstract": "In the medical domain, numerous scenarios necessitate the long-form\ngeneration ability of large language models (LLMs). Specifically, when\naddressing patients' questions, it is essential that the model's response\nconveys factual claims, highlighting the need for an automated method to\nevaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset\nreconstructed using long-form question-answering datasets related to the\nbiomedical domain. We use MedLFQA to facilitate a cost-effective automatic\nevaluations of factuality. We also propose OLAPH, a simple and novel framework\nthat utilizes cost-effective and multifaceted automatic evaluation to construct\na synthetic preference set and answers questions in our preferred manner. Our\nframework leads us to train LLMs step-by-step to reduce hallucinations and\ninclude crucial medical claims. We highlight that, even on evaluation metrics\nnot used during training, LLMs trained with our OLAPH framework demonstrate\nsignificant performance improvement in factuality. Our findings reveal that a\n7B LLM trained with our OLAPH framework can provide long answers comparable to\nthe medical experts' answers in terms of factuality. We believe that our work\ncould shed light on gauging the long-text generation ability of LLMs in the\nmedical domain. Our code and datasets are available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12701v3",
    "published_date": "2024-05-21 11:50:16 UTC",
    "updated_date": "2024-10-15 14:21:54 UTC"
  },
  {
    "arxiv_id": "2405.13090v2",
    "title": "FedASTA: Federated adaptive spatial-temporal attention for traffic flow prediction",
    "authors": [
      "Kaiyuan Li",
      "Yihan Zhang",
      "Huandong Wang",
      "Yan Zhuo",
      "Xinlei Chen"
    ],
    "abstract": "Mobile devices and the Internet of Things (IoT) devices nowadays generate a\nlarge amount of heterogeneous spatial-temporal data. It remains a challenging\nproblem to model the spatial-temporal dynamics under privacy concern. Federated\nlearning (FL) has been proposed as a framework to enable model training across\ndistributed devices without sharing original data which reduce privacy concern.\nPersonalized federated learning (PFL) methods further address data heterogenous\nproblem. However, these methods don't consider natural spatial relations among\nnodes. For the sake of modeling spatial relations, Graph Neural Netowork (GNN)\nbased FL approach have been proposed. But dynamic spatial-temporal relations\namong edge nodes are not taken into account. Several approaches model\nspatial-temporal dynamics in a centralized environment, while less effort has\nbeen made under federated setting. To overcome these challeges, we propose a\nnovel Federated Adaptive Spatial-Temporal Attention (FedASTA) framework to\nmodel the dynamic spatial-temporal relations. On the client node, FedASTA\nextracts temporal relations and trend patterns from the decomposed terms of\noriginal time series. Then, on the server node, FedASTA utilize trend patterns\nfrom clients to construct adaptive temporal-spatial aware graph which captures\ndynamic correlation between clients. Besides, we design a masked spatial\nattention module with both static graph and constructed adaptive graph to model\nspatial dependencies among clients. Extensive experiments on five real-world\npublic traffic flow datasets demonstrate that our method achieves state-of-art\nperformance in federated scenario. In addition, the experiments made in\ncentralized setting show the effectiveness of our novel adaptive graph\nconstruction approach compared with other popular dynamic spatial-temporal\naware methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13090v2",
    "published_date": "2024-05-21 11:44:07 UTC",
    "updated_date": "2024-11-04 02:10:00 UTC"
  },
  {
    "arxiv_id": "2405.12689v2",
    "title": "Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text",
    "authors": [
      "Yafu Li",
      "Zhilin Wang",
      "Leyang Cui",
      "Wei Bi",
      "Shuming Shi",
      "Yue Zhang"
    ],
    "abstract": "AI-generated text detection has attracted increasing attention as powerful\nlanguage models approach human-level generation. Limited work is devoted to\ndetecting (partially) AI-paraphrased texts. However, AI paraphrasing is\ncommonly employed in various application scenarios for text refinement and\ndiversity. To this end, we propose a novel detection framework, paraphrased\ntext span detection (PTD), aiming to identify paraphrased text spans within a\ntext. Different from text-level detection, PTD takes in the full text and\nassigns each of the sentences with a score indicating the paraphrasing degree.\nWe construct a dedicated dataset, PASTED, for paraphrased text span detection.\nBoth in-distribution and out-of-distribution results demonstrate the\neffectiveness of PTD models in identifying AI-paraphrased text spans.\nStatistical and model analysis explains the crucial role of the surrounding\ncontext of the paraphrased text spans. Extensive experiments show that PTD\nmodels can generalize to versatile paraphrasing prompts and multiple\nparaphrased text spans. We release our resources at\nhttps://github.com/Linzwcs/PASTED.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2405.12689v2",
    "published_date": "2024-05-21 11:22:27 UTC",
    "updated_date": "2024-05-29 07:09:59 UTC"
  },
  {
    "arxiv_id": "2405.12658v1",
    "title": "Mitigating Overconfidence in Out-of-Distribution Detection by Capturing Extreme Activations",
    "authors": [
      "Mohammad Azizmalayeri",
      "Ameen Abu-Hanna",
      "Giovanni Cinà"
    ],
    "abstract": "Detecting out-of-distribution (OOD) instances is crucial for the reliable\ndeployment of machine learning models in real-world scenarios. OOD inputs are\ncommonly expected to cause a more uncertain prediction in the primary task;\nhowever, there are OOD cases for which the model returns a highly confident\nprediction. This phenomenon, denoted as \"overconfidence\", presents a challenge\nto OOD detection. Specifically, theoretical evidence indicates that\noverconfidence is an intrinsic property of certain neural network\narchitectures, leading to poor OOD detection. In this work, we address this\nissue by measuring extreme activation values in the penultimate layer of neural\nnetworks and then leverage this proxy of overconfidence to improve on several\nOOD detection baselines. We test our method on a wide array of experiments\nspanning synthetic data and real-world data, tabular and image datasets,\nmultiple architectures such as ResNet and Transformer, different training loss\nfunctions, and include the scenarios examined in previous theoretical work.\nCompared to the baselines, our method often grants substantial improvements,\nwith double-digit increases in OOD detection AUC, and it does not damage\nperformance in any scenario.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for the 40th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.12658v1",
    "published_date": "2024-05-21 10:14:50 UTC",
    "updated_date": "2024-05-21 10:14:50 UTC"
  },
  {
    "arxiv_id": "2405.12656v1",
    "title": "Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction",
    "authors": [
      "Yu-Hsiang Lin",
      "Huang-Ting Shieh",
      "Chih-Yu Liu",
      "Kuang-Ting Lee",
      "Hsiao-Cheng Chang",
      "Jing-Lun Yang",
      "Yu-Sheng Lin"
    ],
    "abstract": "Extrapolation in Large language models (LLMs) for open-ended inquiry\nencounters two pivotal issues: (1) hallucination and (2) expensive training\ncosts. These issues present challenges for LLMs in specialized domains and\npersonalized data, requiring truthful responses and low fine-tuning costs.\nExisting works attempt to tackle the problem by augmenting the input of a\nsmaller language model with information from a knowledge graph (KG). However,\nthey have two limitations: (1) failing to extract relevant information from a\nlarge one-hop neighborhood in KG and (2) applying the same augmentation\nstrategy for KGs with different characteristics that may result in low\nperformance. Moreover, open-ended inquiry typically yields multiple responses,\nfurther complicating extrapolation. We propose a new task, the extreme\nmulti-label KG link prediction task, to enable a model to perform extrapolation\nwith multiple responses using structured real-world knowledge. Our retriever\nidentifies relevant one-hop neighbors by considering entity, relation, and\ntextual data together. Our experiments demonstrate that (1) KGs with different\ncharacteristics require different augmenting strategies, and (2) augmenting the\nlanguage model's input with textual data improves task performance\nsignificantly. By incorporating the retrieval-augmented framework with KG, our\nframework, with a small parameter size, is able to extrapolate based on a given\nKG. The code can be obtained on GitHub:\nhttps://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12656v1",
    "published_date": "2024-05-21 10:10:56 UTC",
    "updated_date": "2024-05-21 10:10:56 UTC"
  },
  {
    "arxiv_id": "2405.12654v1",
    "title": "Utilizing Description Logics for Global Explanations of Heterogeneous Graph Neural Networks",
    "authors": [
      "Dominik Köhler",
      "Stefan Heindorf"
    ],
    "abstract": "Graph Neural Networks (GNNs) are effective for node classification in\ngraph-structured data, but they lack explainability, especially at the global\nlevel. Current research mainly utilizes subgraphs of the input as local\nexplanations or generates new graphs as global explanations. However, these\ngraph-based methods are limited in their ability to explain classes with\nmultiple sufficient explanations. To provide more expressive explanations, we\npropose utilizing class expressions (CEs) from the field of description logic\n(DL). Our approach explains heterogeneous graphs with different types of nodes\nusing CEs in the EL description logic. To identify the best explanation among\nmultiple candidate explanations, we employ and compare two different scoring\nfunctions: (1) For a given CE, we construct multiple graphs, have the GNN make\na prediction for each graph, and aggregate the predicted scores. (2) We score\nthe CE in terms of fidelity, i.e., we compare the predictions of the GNN to the\npredictions by the CE on a separate validation set. Instead of subgraph-based\nexplanations, we offer CE-based explanations.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12654v1",
    "published_date": "2024-05-21 10:07:29 UTC",
    "updated_date": "2024-05-21 10:07:29 UTC"
  },
  {
    "arxiv_id": "2405.12648v1",
    "title": "Scene Graph Generation Strategy with Co-occurrence Knowledge and Learnable Term Frequency",
    "authors": [
      "Hyeongjin Kim",
      "Sangwon Kim",
      "Dasom Ahn",
      "Jong Taek Lee",
      "Byoung Chul Ko"
    ],
    "abstract": "Scene graph generation (SGG) is an important task in image understanding\nbecause it represents the relationships between objects in an image as a graph\nstructure, making it possible to understand the semantic relationships between\nobjects intuitively. Previous SGG studies used a message-passing neural\nnetworks (MPNN) to update features, which can effectively reflect information\nabout surrounding objects. However, these studies have failed to reflect the\nco-occurrence of objects during SGG generation. In addition, they only\naddressed the long-tail problem of the training dataset from the perspectives\nof sampling and learning methods. To address these two problems, we propose\nCooK, which reflects the Co-occurrence Knowledge between objects, and the\nlearnable term frequency-inverse document frequency (TF-l-IDF) to solve the\nlong-tail problem. We applied the proposed model to the SGG benchmark dataset,\nand the results showed a performance improvement of up to 3.8% compared with\nexisting state-of-the-art models in SGGen subtask. The proposed method exhibits\ngeneralization ability from the results obtained, showing uniform performance\nimprovement for all MPNN models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12648v1",
    "published_date": "2024-05-21 09:56:48 UTC",
    "updated_date": "2024-05-21 09:56:48 UTC"
  },
  {
    "arxiv_id": "2405.12633v1",
    "title": "Automating Attendance Management in Human Resources: A Design Science Approach Using Computer Vision and Facial Recognition",
    "authors": [
      "Bao-Thien Nguyen-Tat",
      "Minh-Quoc Bui",
      "Vuong M. Ngo"
    ],
    "abstract": "Haar Cascade is a cost-effective and user-friendly machine learning-based\nalgorithm for detecting objects in images and videos. Unlike Deep Learning\nalgorithms, which typically require significant resources and expensive\ncomputing costs, it uses simple image processing techniques like edge detection\nand Haar features that are easy to comprehend and implement. By combining Haar\nCascade with OpenCV2 on an embedded computer like the NVIDIA Jetson Nano, this\nsystem can accurately detect and match faces in a database for attendance\ntracking. This system aims to achieve several specific objectives that set it\napart from existing solutions. It leverages Haar Cascade, enriched with\ncarefully selected Haar features, such as Haar-like wavelets, and employs\nadvanced edge detection techniques. These techniques enable precise face\ndetection and matching in both images and videos, contributing to high accuracy\nand robust performance. By doing so, it minimizes manual intervention and\nreduces errors, thereby strengthening accountability. Additionally, the\nintegration of OpenCV2 and the NVIDIA Jetson Nano optimizes processing\nefficiency, making it suitable for resource-constrained environments. This\nsystem caters to a diverse range of educational institutions, including\nschools, colleges, vocational training centers, and various workplace settings\nsuch as small businesses, offices, and factories. ... The system's\naffordability and efficiency democratize attendance management technology,\nmaking it accessible to a broader audience. Consequently, it has the potential\nto transform attendance tracking and management practices, ultimately leading\nto heightened productivity and accountability. In conclusion, this system\nrepresents a groundbreaking approach to attendance tracking and management...",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.AR",
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages, accepted to publish by the International Journal of\n  Information Management Data Insights (IJIMDS) in 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12633v1",
    "published_date": "2024-05-21 09:38:56 UTC",
    "updated_date": "2024-05-21 09:38:56 UTC"
  },
  {
    "arxiv_id": "2405.12630v2",
    "title": "Exploration of Masked and Causal Language Modelling for Text Generation",
    "authors": [
      "Nicolo Micheletti",
      "Samuel Belkadi",
      "Lifeng Han",
      "Goran Nenadic"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionised the field of Natural\nLanguage Processing (NLP) and have achieved state-of-the-art performance in\npractically every task in this field. However, the prevalent approach used in\ntext generation, Causal Language Modelling (CLM), which generates text\nsequentially from left to right, inherently limits the freedom of the model,\nwhich does not decide when and where each token is generated. In contrast,\nMasked Language Modelling (MLM), primarily used for language understanding\ntasks, can generate tokens anywhere in the text and any order. This paper\nconducts an extensive comparison of MLM and CLM approaches for text generation\ntasks. To do so, we pre-train several language models of comparable sizes on\nthree different datasets, namely 1) medical discharge summaries, 2) movie plot\nsynopses, and 3) authorship verification datasets. To assess the quality of the\ngenerations, we first employ quantitative metrics and then perform a\nqualitative human evaluation to analyse coherence and grammatical correctness.\nIn addition, we evaluate the usefulness of the generated texts by using them in\nthree different downstream tasks: 1) Entity Recognition, 2) Text\nClassification, and 3) Authorship Verification. The results show that MLM\nconsistently outperforms CLM in text generation across all datasets, with\nhigher quantitative scores and better coherence in the generated text. The\nstudy also finds \\textit{no strong correlation} between the quality of the\ngenerated text and the performance of the models in the downstream tasks. With\nthis study, we show that MLM for text generation has great potential for future\nresearch and provides direction for future studies in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "working paper - under review",
    "pdf_url": "http://arxiv.org/pdf/2405.12630v2",
    "published_date": "2024-05-21 09:33:31 UTC",
    "updated_date": "2024-08-09 00:01:58 UTC"
  },
  {
    "arxiv_id": "2405.12628v1",
    "title": "Play Everywhere: A Temporal Logic based Game Environment Independent Approach for Playing Soccer with Robots",
    "authors": [
      "Vincenzo Suriani",
      "Emanuele Musumeci",
      "Daniele Nardi",
      "Domenico Daniele Bloisi"
    ],
    "abstract": "Robots playing soccer often rely on hard-coded behaviors that struggle to\ngeneralize when the game environment change. In this paper, we propose a\ntemporal logic based approach that allows robots' behaviors and goals to adapt\nto the semantics of the environment. In particular, we present a hierarchical\nrepresentation of soccer in which the robot selects the level of operation\nbased on the perceived semantic characteristics of the environment, thus\nmodifying dynamically the set of rules and goals to apply. The proposed\napproach enables the robot to operate in unstructured environments, just as it\nhappens when humans go from soccer played on an official field to soccer played\non a street. Three different use cases set in different scenarios are presented\nto demonstrate the effectiveness of the proposed approach.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "RoboCup 2023: Robot World Cup XXVI Best Paper",
    "pdf_url": "http://arxiv.org/pdf/2405.12628v1",
    "published_date": "2024-05-21 09:30:47 UTC",
    "updated_date": "2024-05-21 09:30:47 UTC"
  },
  {
    "arxiv_id": "2407.05426v1",
    "title": "AI in Manufacturing: Market Analysis and Opportunities",
    "authors": [
      "Mohamed Abdelaal"
    ],
    "abstract": "In this paper, we explore the transformative impact of Artificial\nIntelligence (AI) in the manufacturing sector, highlighting its potential to\nrevolutionize industry practices and enhance operational efficiency. We delve\ninto various applications of AI in manufacturing, with a particular emphasis on\nhuman-machine interfaces (HMI) and AI-powered milling machines, showcasing how\nthese technologies contribute to more intuitive operations and precision in\nproduction processes. Through rigorous market analysis, the paper presents\ninsightful data on AI adoption rates among German manufacturers, comparing\nthese figures with global trends and exploring the specific uses of AI in\nproduction, maintenance, customer service, and more. In addition, the paper\nexamines the emerging field of Generative AI and the potential applications of\nlarge language models in manufacturing processes. The findings indicate a\nsignificant increase in AI adoption from 6% in 2020 to 13.3% in 2023 among\nGerman companies, with a projection of substantial economic impact by 2030. The\nstudy also addresses the challenges faced by companies, such as data quality\nand integration hurdles, providing a balanced view of the opportunities and\nobstacles in AI implementation.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05426v1",
    "published_date": "2024-05-21 09:26:52 UTC",
    "updated_date": "2024-05-21 09:26:52 UTC"
  },
  {
    "arxiv_id": "2405.12621v2",
    "title": "Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan Acquisition",
    "authors": [
      "Matteo Bortoletto",
      "Constantin Ruhdorfer",
      "Adnen Abdessaied",
      "Lei Shi",
      "Andreas Bulling"
    ],
    "abstract": "Recent work on dialogue-based collaborative plan acquisition (CPA) has\nsuggested that Theory of Mind (ToM) modelling can improve missing knowledge\nprediction in settings with asymmetric skill-sets and knowledge. Although ToM\nwas claimed to be important for effective collaboration, its real impact on\nthis novel task remains under-explored. By representing plans as graphs and by\nexploiting task-specific constraints we show that, as performance on CPA nearly\ndoubles when predicting one's own missing knowledge, the improvements due to\nToM modelling diminish. This phenomenon persists even when evaluating existing\nbaseline methods. To better understand the relevance of ToM for CPA, we report\na principled performance comparison of models with and without ToM features.\nResults across different models and ablations consistently suggest that learned\nToM features are indeed more likely to reflect latent patterns in the data with\nno perceivable link to ToM. This finding calls for a deeper understanding of\nthe role of ToM in CPA and beyond, as well as new methods for modelling and\nevaluating mental states in computational collaborative agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12621v2",
    "published_date": "2024-05-21 09:23:39 UTC",
    "updated_date": "2024-05-28 18:33:23 UTC"
  },
  {
    "arxiv_id": "2405.12617v2",
    "title": "Quantifying Semantic Emergence in Language Models",
    "authors": [
      "Hang Chen",
      "Xinyu Yang",
      "Jiaying Zhu",
      "Wenya Wang"
    ],
    "abstract": "Large language models (LLMs) are widely recognized for their exceptional\ncapacity to capture semantics meaning. Yet, there remains no established metric\nto quantify this capability. In this work, we introduce a quantitative metric,\nInformation Emergence (IE), designed to measure LLMs' ability to extract\nsemantics from input tokens. We formalize ``semantics'' as the meaningful\ninformation abstracted from a sequence of tokens and quantify this by comparing\nthe entropy reduction observed for a sequence of tokens (macro-level) and\nindividual tokens (micro-level). To achieve this, we design a lightweight\nestimator to compute the mutual information at each transformer layer, which is\nagnostic to different tasks and language model architectures. We apply IE in\nboth synthetic in-context learning (ICL) scenarios and natural sentence\ncontexts. Experiments demonstrate informativeness and patterns about semantics.\nWhile some of these patterns confirm the conventional prior linguistic\nknowledge, the rest are relatively unexpected, which may provide new insights.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.12617v2",
    "published_date": "2024-05-21 09:12:20 UTC",
    "updated_date": "2024-12-18 03:03:08 UTC"
  },
  {
    "arxiv_id": "2405.12612v1",
    "title": "Tagengo: A Multilingual Chat Dataset",
    "authors": [
      "Peter Devine"
    ],
    "abstract": "Open source large language models (LLMs) have shown great improvements in\nrecent times. However, many of these models are focused solely on popular\nspoken languages. We present a high quality dataset of more than 70k\nprompt-response pairs in 74 languages which consist of human generated prompts\nand synthetic responses. We use this dataset to train a state-of-the-art open\nsource English LLM to chat multilingually. We evaluate our model on MT-Bench\nchat benchmarks in 6 languages, finding that our multilingual model outperforms\nprevious state-of-the-art open source LLMs across each language. We further\nfind that training on more multilingual data is beneficial to the performance\nin a chosen target language (Japanese) compared to simply training on only data\nin that language. These results indicate the necessity of training on large\namounts of high quality multilingual data to make a more accessible LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12612v1",
    "published_date": "2024-05-21 09:06:36 UTC",
    "updated_date": "2024-05-21 09:06:36 UTC"
  },
  {
    "arxiv_id": "2405.12604v2",
    "title": "Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming",
    "authors": [
      "Jiaxu Liu",
      "Xiangyu Yin",
      "Sihao Wu",
      "Jianhong Wang",
      "Meng Fang",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "abstract": "With the proliferation of red-teaming strategies for Large Language Models\n(LLMs), the deficiency in the literature about improving the safety and\nrobustness of LLM defense strategies is becoming increasingly pronounced. This\npaper introduces the LLM-based \\textbf{sentinel} model as a plug-and-play\nprefix module designed to reconstruct the input prompt with just a few ($<30$)\nadditional tokens, effectively reducing toxicity in responses from target LLMs.\nThe sentinel model naturally overcomes the \\textit{parameter inefficiency} and\n\\textit{limited model accessibility} for fine-tuning large target models. We\nemploy an interleaved training regimen using Proximal Policy Optimization (PPO)\nto optimize both red team and sentinel models dynamically, incorporating a\nvalue head-sharing mechanism inspired by the multi-agent centralized critic to\nmanage the complex interplay between agents. Our extensive experiments across\ntext-to-text and text-to-image demonstrate the effectiveness of our approach in\nmitigating toxic outputs, even when dealing with larger models like\n\\texttt{Llama-2}, \\texttt{GPT-3.5} and \\texttt{Stable-Diffusion}, highlighting\nthe potential of our framework in enhancing safety and robustness in various\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, 10 pages main with 10 pages appendix",
    "pdf_url": "http://arxiv.org/pdf/2405.12604v2",
    "published_date": "2024-05-21 08:57:44 UTC",
    "updated_date": "2024-06-17 18:52:45 UTC"
  },
  {
    "arxiv_id": "2405.13085v1",
    "title": "Multi-domain Knowledge Graph Collaborative Pre-training and Prompt Tuning for Diverse Downstream Tasks",
    "authors": [
      "Yichi Zhang",
      "Binbin Hu",
      "Zhuo Chen",
      "Lingbing Guo",
      "Ziqi Liu",
      "Zhiqiang Zhang",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "Knowledge graphs (KGs) provide reliable external knowledge for a wide variety\nof AI tasks in the form of structured triples. Knowledge graph pre-training\n(KGP) aims to pre-train neural networks on large-scale KGs and provide unified\ninterfaces to enhance different downstream tasks, which is a key direction for\nKG management, maintenance, and applications. Existing works often focus on\npurely research questions in open domains, or they are not open source due to\ndata security and privacy in real scenarios. Meanwhile, existing studies have\nnot explored the training efficiency and transferability of KGP models in\ndepth. To address these problems, We propose a framework MuDoK to achieve\nmulti-domain collaborative pre-training and efficient prefix prompt tuning to\nserve diverse downstream tasks like recommendation and text understanding. Our\ndesign is a plug-and-play prompt learning approach that can be flexibly adapted\nto different downstream task backbones. In response to the lack of open-source\nbenchmarks, we constructed a new multi-domain KGP benchmark called KPI with two\nlarge-scale KGs and six different sub-domain tasks to evaluate our method and\nopen-sourced it for subsequent research. We evaluated our approach based on\nconstructed KPI benchmarks using diverse backbone models in heterogeneous\ndownstream tasks. The experimental results show that our framework brings\nsignificant performance gains, along with its generality, efficiency, and\ntransferability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Code and data will be open-sourced at\n  https://github.com/zjukg/MuDoK",
    "pdf_url": "http://arxiv.org/pdf/2405.13085v1",
    "published_date": "2024-05-21 08:22:14 UTC",
    "updated_date": "2024-05-21 08:22:14 UTC"
  },
  {
    "arxiv_id": "2407.17585v1",
    "title": "Quelle {é}thique pour quelle IA ?",
    "authors": [
      "David Doat"
    ],
    "abstract": "This study proposes an analysis of the different types of ethical approaches\ninvolved in the ethics of AI, and situates their interests and limits. First,\nthe author introduces to the contemporary need for and meaning of ethics. He\ndistinguishes it from other registers of normativities and underlines its\ninadequacy to formalization. He then presents a cartography of the landscape of\nethical theories covered by moral philosophy, taking care to distinguish\nmeta-ethics, normative ethics and applied ethics. In drawing up this overview,\nthe author questions the relationship between ethics and artificial\nintelligence. The analysis focuses in particular on the main ethical currents\nthat have imposed themselves in the ways of doing digital ethics and AI in our\nWestern democracies. The author asks whether these practices of ethics, as they\nseem to crystallize today in a precise pattern, constitute a sufficient and\nsufficiently satisfactory response to our needs for ethics in AI. The study\nconcludes with a reflection on the reasons why a human ethics of AI based on a\npragmatic practice of contextual ethics remains necessary and irreducible to\nany formalization or automated treatment of the ethical questions that arise\nfor humans.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "in French language. Workshop Ethique et Morale de la Chaire IA\n  Responsable, Nathalie Nevejans, May 2021, Distanciel, France",
    "pdf_url": "http://arxiv.org/pdf/2407.17585v1",
    "published_date": "2024-05-21 08:13:02 UTC",
    "updated_date": "2024-05-21 08:13:02 UTC"
  },
  {
    "arxiv_id": "2405.13084v2",
    "title": "The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)",
    "authors": [
      "Yucheng Cai",
      "Si Chen",
      "Yuxuan Wu",
      "Yi Huang",
      "Junlan Feng",
      "Zhijian Ou"
    ],
    "abstract": "Recently, increasing research interests have focused on retrieval augmented\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\naims at promoting the study of RAG for dialog systems. The challenge builds\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\n3000 high-quality dialogs containing annotations for knowledge base query and\ncorresponding results. Over the dataset, we define two tasks, track 1 for\nknowledge retrieval and track 2 for response generation, which are core\nresearch questions in dialog systems with RAG. We build baseline systems for\nthe two tracks and design metrics to measure whether the systems can perform\naccurate retrieval and generate informative and coherent response. The baseline\nresults show that it is very challenging to perform well on the two tasks,\nwhich encourages the participating teams and the community to study how to make\nbetter use of RAG for real-life dialog systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by SLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.13084v2",
    "published_date": "2024-05-21 07:35:21 UTC",
    "updated_date": "2024-09-15 15:03:59 UTC"
  },
  {
    "arxiv_id": "2405.12543v2",
    "title": "Like Humans to Few-Shot Learning through Knowledge Permeation of Vision and Text",
    "authors": [
      "Yuyu Jia",
      "Qing Zhou",
      "Wei Huang",
      "Junyu Gao",
      "Qi Wang"
    ],
    "abstract": "Few-shot learning aims to generalize the recognizer from seen categories to\nan entirely novel scenario. With only a few support samples, several advanced\nmethods initially introduce class names as prior knowledge for identifying\nnovel classes. However, obstacles still impede achieving a comprehensive\nunderstanding of how to harness the mutual advantages of visual and textual\nknowledge. In this paper, we propose a coherent Bidirectional Knowledge\nPermeation strategy called BiKop, which is grounded in a human intuition: A\nclass name description offers a general representation, whereas an image\ncaptures the specificity of individuals. BiKop primarily establishes a\nhierarchical joint general-specific representation through bidirectional\nknowledge permeation. On the other hand, considering the bias of joint\nrepresentation towards the base set, we disentangle base-class-relevant\nsemantics during training, thereby alleviating the suppression of potential\nnovel-class-relevant information. Experiments on four challenging benchmarks\ndemonstrate the remarkable superiority of BiKop. Our code will be publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12543v2",
    "published_date": "2024-05-21 07:18:26 UTC",
    "updated_date": "2024-05-22 14:08:36 UTC"
  },
  {
    "arxiv_id": "2405.12541v1",
    "title": "DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge",
    "authors": [
      "Bufang Yang",
      "Siyang Jiang",
      "Lilin Xu",
      "Kaiwei Liu",
      "Hai Li",
      "Guoliang Xing",
      "Hongkai Chen",
      "Xiaofan Jiang",
      "Zhenyu Yan"
    ],
    "abstract": "Large language models (LLMs) have the potential to transform digital\nhealthcare, as evidenced by recent advances in LLM-based virtual doctors.\nHowever, current approaches rely on patient's subjective descriptions of\nsymptoms, causing increased misdiagnosis. Recognizing the value of daily data\nfrom smart devices, we introduce a novel LLM-based multi-turn consultation\nvirtual doctor system, DrHouse, which incorporates three significant\ncontributions: 1) It utilizes sensor data from smart devices in the diagnosis\nprocess, enhancing accuracy and reliability. 2) DrHouse leverages continuously\nupdating medical databases such as Up-to-Date and PubMed to ensure our model\nremains at diagnostic standard's forefront. 3) DrHouse introduces a novel\ndiagnostic algorithm that concurrently evaluates potential diseases and their\nlikelihood, facilitating more nuanced and informed medical assessments. Through\nmulti-turn interactions, DrHouse determines the next steps, such as accessing\ndaily data from smart devices or requesting in-lab tests, and progressively\nrefines its diagnoses. Evaluations on three public datasets and our\nself-collected datasets show that DrHouse can achieve up to an 18.8% increase\nin diagnosis accuracy over the state-of-the-art baselines. The results of a\n32-participant user study show that 75% medical experts and 91.7% patients are\nwilling to use DrHouse.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12541v1",
    "published_date": "2024-05-21 07:16:12 UTC",
    "updated_date": "2024-05-21 07:16:12 UTC"
  },
  {
    "arxiv_id": "2405.13082v5",
    "title": "A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis",
    "authors": [
      "Haocong Rao",
      "Minlin Zeng",
      "Xuejiao Zhao",
      "Chunyan Miao"
    ],
    "abstract": "Recent years have witnessed an increasing global population affected by\nneurodegenerative diseases (NDs), which traditionally require extensive\nhealthcare resources and human effort for medical diagnosis and monitoring. As\na crucial disease-related motor symptom, human gait can be exploited to\ncharacterize different NDs. The current advances in artificial intelligence\n(AI) models enable automatic gait analysis for NDs identification and\nclassification, opening a new avenue to facilitate faster and more\ncost-effective diagnosis of NDs. In this paper, we provide a comprehensive\nsurvey on recent progress of machine learning and deep learning based AI\ntechniques applied to diagnosis of five typical NDs through gait. We provide an\noverview of the process of AI-assisted NDs diagnosis, and present a systematic\ntaxonomy of existing gait data and AI models. Meanwhile, a novel quality\nevaluation criterion is proposed to quantitatively assess the quality of\nexisting studies. Through an extensive review and analysis of 169 studies, we\npresent recent technical advancements, discuss existing challenges, potential\nsolutions, and future directions in this field. Finally, we envision the\nprospective utilization of 3D skeleton data for human gait representation and\nthe development of more efficient AI models for NDs diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Neurocomputing journal. Article: 57 pages, citing 290\n  papers. Appendix: 30 pages. A up-to-date resource (papers, data, etc.) of\n  this survey (AI4NDD) is provided at\n  https://github.com/minlinzeng/AI4NDD-Survey",
    "pdf_url": "http://arxiv.org/pdf/2405.13082v5",
    "published_date": "2024-05-21 06:44:40 UTC",
    "updated_date": "2025-02-06 13:34:48 UTC"
  },
  {
    "arxiv_id": "2405.12523v3",
    "title": "Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models",
    "authors": [
      "Jiaqi Li",
      "Qianshan Wei",
      "Chuanyi Zhang",
      "Guilin Qi",
      "Miaozeng Du",
      "Yongrui Chen",
      "Sheng Bi",
      "Fan Liu"
    ],
    "abstract": "Machine unlearning empowers individuals with the `right to be forgotten' by\nremoving their private or sensitive information encoded in machine learning\nmodels. However, it remains uncertain whether MU can be effectively applied to\nMultimodal Large Language Models (MLLMs), particularly in scenarios of\nforgetting the leaked visual data of concepts. To overcome the challenge, we\npropose an efficient method, Single Image Unlearning (SIU), to unlearn the\nvisual recognition of a concept by fine-tuning a single associated image for\nfew steps. SIU consists of two key aspects: (i) Constructing Multifaceted\nfine-tuning data. We introduce four targets, based on which we construct\nfine-tuning data for the concepts to be forgotten; (ii) Jointly training loss.\nTo synchronously forget the visual recognition of concepts and preserve the\nutility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence\nLoss combined with Cross Entropy loss. Alongside our method, we establish\nMMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics\nfor its evaluation. Experimental results on MMUBench show that SIU completely\nsurpasses the performance of existing methods. Furthermore, we surprisingly\nfind that SIU can avoid invasive membership inference attacks and jailbreak\nattacks. To the best of our knowledge, we are the first to explore MU in MLLMs.\nWe will release the code and benchmark in the near future.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12523v3",
    "published_date": "2024-05-21 06:27:12 UTC",
    "updated_date": "2025-03-28 04:13:29 UTC"
  },
  {
    "arxiv_id": "2405.19347v3",
    "title": "Near-Field Spot Beamfocusing: A Correlation-Aware Transfer Learning Approach",
    "authors": [
      "Mohammad Amir Fallah",
      "Mehdi Monemi",
      "Mehdi Rasti",
      "Matti Latva-Aho"
    ],
    "abstract": "Three-dimensional (3D) spot beamfocusing (SBF), in contrast to conventional\nangular-domain beamforming, concentrates radiating power within a very small\nvolume in both radial and angular domains in the near-field zone. Recently the\nimplementation of channel-state-information (CSI)-independent machine learning\n(ML)-based approaches have been developed for effective SBF using extremely\nlarge-scale programmable metasurface (ELPMs). These methods involve dividing\nthe ELPMs into subarrays and independently training them with Deep\nReinforcement Learning to jointly focus the beam at the desired focal point\n(DFP).\n  This paper explores near-field SBF using ELPMs, addressing challenges\nassociated with lengthy training times resulting from independent training of\nsubarrays. To achieve a faster CSI-independent solution, inspired by the\ncorrelation between the beamfocusing matrices of the subarrays, we leverage\ntransfer learning techniques. First, we introduce a novel similarity criterion\nbased on the phase distribution image (PDI) of subarray apertures. Then we\ndevise a subarray policy propagation scheme that transfers the knowledge from\ntrained to untrained subarrays. We further enhance learning by introducing\nquasi-liquid layers as a revised version of the adaptive policy reuse\ntechnique. We show through simulations that the proposed scheme improves the\ntraining speed about 5 times. Furthermore, for dynamic DFP management, we\ndevised a DFP policy blending process, which augments the convergence rate up\nto 8-fold.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19347v3",
    "published_date": "2024-05-21 06:27:07 UTC",
    "updated_date": "2024-12-16 05:56:32 UTC"
  },
  {
    "arxiv_id": "2405.13081v1",
    "title": "Children's Mental Models of Generative Visual and Text Based AI Models",
    "authors": [
      "Eliza Kosoy",
      "Soojin Jeong",
      "Anoop Sinha",
      "Alison Gopnik",
      "Tanya Kraljic"
    ],
    "abstract": "In this work we investigate how children ages 5-12 perceive, understand, and\nuse generative AI models such as a text-based LLMs ChatGPT and a visual-based\nmodel DALL-E. Generative AI is newly being used widely since chatGPT. Children\nare also building mental models of generative AI. Those haven't been studied\nbefore and it is also the case that the children's models are dynamic as they\nuse the tools, even with just very short usage. Upon surveying and\nexperimentally observing over 40 children ages 5-12, we found that children\ngenerally have a very positive outlook towards AI and are excited about the\nways AI may benefit and aid them in their everyday lives. In a forced choice,\nchildren robustly associated AI with positive adjectives versus negative ones.\nWe also categorize what children are querying AI models for and find that\nchildren search for more imaginative things that don't exist when using a\nvisual-based AI and not when using a text-based one. Our follow-up study\nmonitored children's responses and feelings towards AI before and after\ninteracting with GenAI models. We even find that children find AI to be less\nscary after interacting with it. We hope that these findings will shine a light\non children's mental models of AI and provide insight for how to design the\nbest possible tools for children who will inevitably be using AI in their\nlifetimes. The motivation of this work is to bridge the gap between\nHuman-Computer Interaction (HCI) and Psychology in an effort to study the\neffects of AI on society. We aim to identify the gaps in humans' mental models\nof what AI is and how it works. Previous work has investigated how both adults\nand children perceive various kinds of robots, computers, and other\ntechnological concepts. However, there is very little work investigating these\nconcepts for generative AI models and not simply embodied robots or physical\ntechnology.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13081v1",
    "published_date": "2024-05-21 06:18:00 UTC",
    "updated_date": "2024-05-21 06:18:00 UTC"
  },
  {
    "arxiv_id": "2405.12519v2",
    "title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation",
    "authors": [
      "Zhaoning Yu",
      "Hongyang Gao"
    ],
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in molecular\ntasks, yet their interpretability remains challenging. Traditional model-level\nexplanation methods like XGNN and GNNInterpreter often fail to identify valid\nsubstructures like rings, leading to questionable interpretability. This\nlimitation stems from XGNN's atom-by-atom approach and GNNInterpreter's\nreliance on average graph embeddings, which overlook the essential structural\nelements crucial for molecules. To address these gaps, we introduce an\ninnovative \\textbf{M}otif-b\\textbf{A}sed \\textbf{G}NN \\textbf{E}xplainer (MAGE)\nthat uses motifs as fundamental units for generating explanations. Our approach\nbegins with extracting potential motifs through a motif decomposition\ntechnique. Then, we utilize an attention-based learning method to identify\nclass-specific motifs. Finally, we employ a motif-based graph generator for\neach class to create molecular graph explanations based on these class-specific\nmotifs. This novel method not only incorporates critical substructures into the\nexplanations but also guarantees their validity, yielding results that are\nhuman-understandable. Our proposed method's effectiveness is demonstrated\nthrough quantitative and qualitative assessments conducted on six real-world\nmolecular datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2405.08419 The Thirteenth\n  International Conference on Learning Representations 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.12519v2",
    "published_date": "2024-05-21 06:12:24 UTC",
    "updated_date": "2025-04-24 06:35:27 UTC"
  },
  {
    "arxiv_id": "2405.12514v4",
    "title": "Future You: A Conversation with an AI-Generated Future Self Reduces Anxiety, Negative Emotions, and Increases Future Self-Continuity",
    "authors": [
      "Pat Pataranutaporn",
      "Kavin Winson",
      "Peggy Yin",
      "Auttasak Lapapirojn",
      "Pichayoot Ouppaphan",
      "Monchai Lertsutthiwong",
      "Pattie Maes",
      "Hal Hershfield"
    ],
    "abstract": "We introduce \"Future You,\" an interactive, brief, single-session, digital\nchat intervention designed to improve future self-continuity--the degree of\nconnection an individual feels with a temporally distant future self--a\ncharacteristic that is positively related to mental health and wellbeing. Our\nsystem allows users to chat with a relatable yet AI-powered virtual version of\ntheir future selves that is tuned to their future goals and personal qualities.\nTo make the conversation realistic, the system generates a \"synthetic\nmemory\"--a unique backstory for each user--that creates a throughline between\nthe user's present age (between 18-30) and their life at age 60. The \"Future\nYou\" character also adopts the persona of an age-progressed image of the user's\npresent self. After a brief interaction with the \"Future You\" character, users\nreported decreased anxiety, and increased future self-continuity. This is the\nfirst study successfully demonstrating the use of personalized AI-generated\ncharacters to improve users' future self-continuity and wellbeing.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12514v4",
    "published_date": "2024-05-21 06:00:51 UTC",
    "updated_date": "2024-10-01 09:00:57 UTC"
  },
  {
    "arxiv_id": "2405.12512v1",
    "title": "Rethink Predicting the Optical Flow with the Kinetics Perspective",
    "authors": [
      "Yuhao Cheng",
      "Siru Zhang",
      "Yiqiang Yan"
    ],
    "abstract": "Optical flow estimation is one of the fundamental tasks in low-level computer\nvision, which describes the pixel-wise displacement and can be used in many\nother tasks. From the apparent aspect, the optical flow can be viewed as the\ncorrelation between the pixels in consecutive frames, so continuously refining\nthe correlation volume can achieve an outstanding performance. However, it will\nmake the method have a catastrophic computational complexity. Not only that,\nthe error caused by the occlusion regions of the successive frames will be\namplified through the inaccurate warp operation. These challenges can not be\nsolved only from the apparent view, so this paper rethinks the optical flow\nestimation from the kinetics viewpoint.We propose a method combining the\napparent and kinetics information from this motivation. The proposed method\ndirectly predicts the optical flow from the feature extracted from images\ninstead of building the correlation volume, which will improve the efficiency\nof the whole network. Meanwhile, the proposed method involves a new\ndifferentiable warp operation that simultaneously considers the warping and\nocclusion. Moreover, the proposed method blends the kinetics feature with the\napparent feature through the novel self-supervised loss function. Furthermore,\ncomprehensive experiments and ablation studies prove that the proposed novel\ninsight into how to predict the optical flow can achieve the better performance\nof the state-of-the-art methods, and in some metrics, the proposed method\noutperforms the correlation-based method, especially in situations containing\nocclusion and fast moving. The code will be public.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12512v1",
    "published_date": "2024-05-21 05:47:42 UTC",
    "updated_date": "2024-05-21 05:47:42 UTC"
  },
  {
    "arxiv_id": "2405.12502v3",
    "title": "EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy",
    "authors": [
      "Yihong Huang",
      "Yuang Zhang",
      "Liping Wang",
      "Fan Zhang",
      "Xuemin Lin"
    ],
    "abstract": "Unsupervised Outlier Detection (UOD) is an important data mining task. With\nthe advance of deep learning, deep Outlier Detection (OD) has received broad\ninterest. Most deep UOD models are trained exclusively on clean datasets to\nlearn the distribution of the normal data, which requires huge manual efforts\nto clean the real-world data if possible. Instead of relying on clean datasets,\nsome approaches directly train and detect on unlabeled contaminated datasets,\nleading to the need for methods that are robust to such conditions. Ensemble\nmethods emerged as a superior solution to enhance model robustness against\ncontaminated training sets. However, the training time is greatly increased by\nthe ensemble.\n  In this study, we investigate the impact of outliers on the training phase,\naiming to halt training on unlabeled contaminated datasets before performance\ndegradation. Initially, we noted that blending normal and anomalous data causes\nAUC fluctuations, a label-dependent measure of detection accuracy. To\ncircumvent the need for labels, we propose a zero-label entropy metric named\nLoss Entropy for loss distribution, enabling us to infer optimal stopping\npoints for training without labels. Meanwhile, we theoretically demonstrate\nnegative correlation between entropy metric and the label-based AUC. Based on\nthis, we develop an automated early-stopping algorithm, EntropyStop, which\nhalts training when loss entropy suggests the maximum model detection\ncapability. We conduct extensive experiments on ADBench (including 47 real\ndatasets), and the overall results indicate that AutoEncoder (AE) enhanced by\nour approach not only achieves better performance than ensemble AEs but also\nrequires under 2\\% of training time. Lastly, our proposed metric and\nearly-stopping approach are evaluated on other deep OD models, exhibiting their\nbroad potential applicability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12502v3",
    "published_date": "2024-05-21 05:17:43 UTC",
    "updated_date": "2024-06-29 01:40:46 UTC"
  },
  {
    "arxiv_id": "2405.12489v4",
    "title": "Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks",
    "authors": [
      "Xin-Chun Li",
      "Jin-Lin Tang",
      "Bo Zhang",
      "Lan Li",
      "De-Chuan Zhan"
    ],
    "abstract": "Exploring the loss landscape offers insights into the inherent principles of\ndeep neural networks (DNNs). Recent work suggests an additional asymmetry of\nthe valley beyond the flat and sharp ones, yet without thoroughly examining its\ncauses or implications. Our study methodically explores the factors affecting\nthe symmetry of DNN valleys, encompassing (1) the dataset, network\narchitecture, initialization, and hyperparameters that influence the\nconvergence point; and (2) the magnitude and direction of the noise for 1D\nvisualization. Our major observation shows that the {\\it degree of sign\nconsistency} between the noise and the convergence point is a critical\nindicator of valley symmetry. Theoretical insights from the aspects of ReLU\nactivation and softmax function could explain the interesting phenomenon. Our\ndiscovery propels novel understanding and applications in the scenario of Model\nFusion: (1) the efficacy of interpolating separate models significantly\ncorrelates with their sign consistency ratio, and (2) imposing sign alignment\nduring federated learning emerges as an innovative approach for model parameter\nalignment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.12489v4",
    "published_date": "2024-05-21 04:18:57 UTC",
    "updated_date": "2024-10-09 13:04:29 UTC"
  },
  {
    "arxiv_id": "2405.12486v1",
    "title": "Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection",
    "authors": [
      "Hao Jiang",
      "Chuanzhen Li",
      "Mingxiao An"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized text comprehension, leading\nto State-of-the-Art (SOTA) news recommendation models that utilize LLMs for\nin-depth news understanding. Despite this, accurately modeling user preferences\nremains challenging due to the inherent uncertainty of click behaviors.\nTechniques like multi-head attention in Transformers seek to alleviate this by\ncapturing interactions among clicks, yet they fall short in integrating\nexplicit feedback signals. User Dwell Time emerges as a powerful indicator,\noffering the potential to enhance the weak signals emanating from clicks.\nNonetheless, its real-world applicability is questionable, especially when\ndwell time data collection is subject to delays. To bridge this gap, this paper\nproposes two novel and robust dwell time injection strategies, namely Dwell\ntime Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining\nEffective User Clicks through detailed analysis of dwell time, integrating with\ninitial behavioral inputs to construct a more robust user preference. DweA\nempowers the model with awareness of dwell time information, thereby\nfacilitating autonomous adjustment of attention values in user modeling. This\nenhancement sharpens the model's ability to accurately identify user\npreferences. In our experiment using the real-world news dataset from MSN\nwebsite, we validated that our two strategies significantly improve\nrecommendation performance, favoring high-quality news. Crucially, our\napproaches exhibit robustness to user dwell time information, maintaining their\nability to recommend high-quality content even in extreme cases where dwell\ntime data is entirely missing.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages,5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.12486v1",
    "published_date": "2024-05-21 04:08:07 UTC",
    "updated_date": "2024-05-21 04:08:07 UTC"
  },
  {
    "arxiv_id": "2405.12475v1",
    "title": "GASE: Graph Attention Sampling with Edges Fusion for Solving Vehicle Routing Problems",
    "authors": [
      "Zhenwei Wang",
      "Ruibin Bai",
      "Fazlullah Khan",
      "Ender Ozcan",
      "Tiehua Zhang"
    ],
    "abstract": "Learning-based methods have become increasingly popular for solving vehicle\nrouting problems due to their near-optimal performance and fast inference\nspeed. Among them, the combination of deep reinforcement learning and graph\nrepresentation allows for the abstraction of node topology structures and\nfeatures in an encoder-decoder style. Such an approach makes it possible to\nsolve routing problems end-to-end without needing complicated heuristic\noperators designed by domain experts. Existing research studies have been\nfocusing on novel encoding and decoding structures via various neural network\nmodels to enhance the node embedding representation. Despite the sophisticated\napproaches applied, there is a noticeable lack of consideration for the\ngraph-theoretic properties inherent to routing problems. Moreover, the\npotential ramifications of inter-nodal interactions on the decision-making\nefficacy of the models have not been adequately explored. To bridge this gap,\nwe propose an adaptive Graph Attention Sampling with the Edges Fusion framework\n(GASE),where nodes' embedding is determined through attention calculation from\ncertain highly correlated neighbourhoods and edges, utilizing a filtered\nadjacency matrix. In detail, the selections of particular neighbours and\nadjacency edges are led by a multi-head attention mechanism, contributing\ndirectly to the message passing and node embedding in graph attention sampling\nnetworks. Furthermore, we incorporate an adaptive actor-critic algorithm with\npolicy improvements to expedite the training convergence. We then conduct\ncomprehensive experiments against baseline methods on learning-based VRP tasks\nfrom different perspectives. Our proposed model outperforms the existing\nmethods by 2.08\\%-6.23\\% and shows stronger generalization ability, achieving\nstate-of-the-art performance on randomly generated instances and real-world\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 5figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.12475v1",
    "published_date": "2024-05-21 03:33:07 UTC",
    "updated_date": "2024-05-21 03:33:07 UTC"
  },
  {
    "arxiv_id": "2405.12473v3",
    "title": "Learning Partially Aligned Item Representation for Cross-Domain Sequential Recommendation",
    "authors": [
      "Mingjia Yin",
      "Hao Wang",
      "Wei Guo",
      "Yong Liu",
      "Zhi Li",
      "Sirui Zhao",
      "Zhen Wang",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "Cross-domain sequential recommendation (CDSR) aims to uncover and transfer\nusers' sequential preferences across multiple recommendation domains. While\nsignificant endeavors have been made, they primarily concentrated on developing\nadvanced transfer modules and aligning user representations using\nself-supervised learning techniques. However, the problem of aligning item\nrepresentations has received limited attention, and misaligned item\nrepresentations can potentially lead to sub-optimal sequential modeling and\nuser representation alignment. To this end, we propose a model-agnostic\nframework called \\textbf{C}ross-domain item representation \\textbf{A}lignment\nfor \\textbf{C}ross-\\textbf{D}omain \\textbf{S}equential \\textbf{R}ecommendation\n(\\textbf{CA-CDSR}), which achieves sequence-aware generation and adaptively\npartial alignment for item representations. Specifically, we first develop a\nsequence-aware feature augmentation strategy, which captures both collaborative\nand sequential item correlations, thus facilitating holistic item\nrepresentation generation. Next, we conduct an empirical study to investigate\nthe partial representation alignment problem from a spectrum perspective. It\nmotivates us to devise an adaptive spectrum filter, achieving partial alignment\nadaptively. Furthermore, the aligned item representations can be fed into\ndifferent sequential encoders to obtain user representations. The entire\nframework is optimized in a multi-task learning paradigm with an annealing\nstrategy. Extensive experiments have demonstrated that CA-CDSR can surpass\nstate-of-the-art baselines by a significant margin and can effectively align\nitems in representation spaces to enhance performance.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12473v3",
    "published_date": "2024-05-21 03:25:32 UTC",
    "updated_date": "2024-08-21 06:31:40 UTC"
  },
  {
    "arxiv_id": "2405.13077v2",
    "title": "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation",
    "authors": [
      "Govind Ramesh",
      "Yao Dou",
      "Wei Xu"
    ],
    "abstract": "Research on jailbreaking has been valuable for testing and understanding the\nsafety and security issues of large language models (LLMs). In this paper, we\nintroduce Iterative Refinement Induced Self-Jailbreak (IRIS), a novel approach\nthat leverages the reflective capabilities of LLMs for jailbreaking with only\nblack-box access. Unlike previous methods, IRIS simplifies the jailbreaking\nprocess by using a single model as both the attacker and target. This method\nfirst iteratively refines adversarial prompts through self-explanation, which\nis crucial for ensuring that even well-aligned LLMs obey adversarial\ninstructions. IRIS then rates and enhances the output given the refined prompt\nto increase its harmfulness. We find that IRIS achieves jailbreak success rates\nof 98% on GPT-4, 92% on GPT-4 Turbo, and 94% on Llama-3.1-70B in under 7\nqueries. It significantly outperforms prior approaches in automatic, black-box,\nand interpretable jailbreaking, while requiring substantially fewer queries,\nthereby establishing a new standard for interpretable jailbreaking methods.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.13077v2",
    "published_date": "2024-05-21 03:16:35 UTC",
    "updated_date": "2024-10-15 22:50:58 UTC"
  },
  {
    "arxiv_id": "2405.12463v1",
    "title": "Stochastic Learning of Computational Resource Usage as Graph Structured Multimarginal Schrödinger Bridge",
    "authors": [
      "Georgiy A. Bondar",
      "Robert Gifford",
      "Linh Thi Xuan Phan",
      "Abhishek Halder"
    ],
    "abstract": "We propose to learn the time-varying stochastic computational resource usage\nof software as a graph structured Schr\\\"odinger bridge problem. In general,\nlearning the computational resource usage from data is challenging because\nresources such as the number of CPU instructions and the number of last level\ncache requests are both time-varying and statistically correlated. Our proposed\nmethod enables learning the joint time-varying stochasticity in computational\nresource usage from the measured profile snapshots in a nonparametric manner.\nThe method can be used to predict the most-likely time-varying distribution of\ncomputational resource availability at a desired time. We provide detailed\nalgorithms for stochastic learning in both single and multi-core cases, discuss\nthe convergence guarantees, computational complexities, and demonstrate their\npractical use in two case studies: a single-core nonlinear model predictive\ncontroller, and a synthetic multi-core software.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12463v1",
    "published_date": "2024-05-21 02:39:45 UTC",
    "updated_date": "2024-05-21 02:39:45 UTC"
  },
  {
    "arxiv_id": "2405.12462v4",
    "title": "Enhancing Transformer-based models for Long Sequence Time Series Forecasting via Structured Matrix",
    "authors": [
      "Zhicheng Zhang",
      "Yong Wang",
      "Shaoqi Tan",
      "Bowei Xia",
      "Yujie Luo"
    ],
    "abstract": "Recently, Transformer-based models for long sequence time series forecasting\nhave demonstrated promising results. The self-attention mechanism as the core\ncomponent of these Transformer-based models exhibits great potential in\ncapturing various dependencies among data points. Despite these advancements,\nit has been a subject of concern to improve the efficiency of the\nself-attention mechanism. Unfortunately, current specific optimization methods\nare facing the challenges in applicability and scalability for the future\ndesign of long sequence time series forecasting models. Hence, in this article,\nwe propose a novel architectural framework that enhances Transformer-based\nmodels through the integration of Surrogate Attention Blocks (SAB) and\nSurrogate Feed-Forward Neural Network Blocks (SFB). The framework reduces both\ntime and space complexity by the replacement of the self-attention and\nfeed-forward layers with SAB and SFB while maintaining their expressive power\nand architectural advantages. The equivalence of this substitution is fully\ndemonstrated. The extensive experiments on 10 Transformer-based models across\nfive distinct time series tasks demonstrate an average performance improvement\nof 12.4%, alongside 61.3% reduction in parameter counts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12462v4",
    "published_date": "2024-05-21 02:37:47 UTC",
    "updated_date": "2024-12-16 13:47:34 UTC"
  },
  {
    "arxiv_id": "2405.12461v1",
    "title": "WorldAfford: Affordance Grounding based on Natural Language Instructions",
    "authors": [
      "Changmao Chen",
      "Yuren Cong",
      "Zhen Kan"
    ],
    "abstract": "Affordance grounding aims to localize the interaction regions for the\nmanipulated objects in the scene image according to given instructions. A\ncritical challenge in affordance grounding is that the embodied agent should\nunderstand human instructions and analyze which tools in the environment can be\nused, as well as how to use these tools to accomplish the instructions. Most\nrecent works primarily supports simple action labels as input instructions for\nlocalizing affordance regions, failing to capture complex human objectives.\nMoreover, these approaches typically identify affordance regions of only a\nsingle object in object-centric images, ignoring the object context and\nstruggling to localize affordance regions of multiple objects in complex scenes\nfor practical applications. To address this concern, for the first time, we\nintroduce a new task of affordance grounding based on natural language\ninstructions, extending it from previously using simple labels for complex\nhuman instructions. For this new task, we propose a new framework, WorldAfford.\nWe design a novel Affordance Reasoning Chain-of-Thought Prompting to reason\nabout affordance knowledge from LLMs more precisely and logically.\nSubsequently, we use SAM and CLIP to localize the objects related to the\naffordance knowledge in the image. We identify the affordance regions of the\nobjects through an affordance region localization module. To benchmark this new\ntask and validate our framework, an affordance grounding dataset, LLMaFF, is\nconstructed. We conduct extensive experiments to verify that WorldAfford\nperforms state-of-the-art on both the previous AGD20K and the new LLMaFF\ndataset. In particular, WorldAfford can localize the affordance regions of\nmultiple objects and provide an alternative when objects in the environment\ncannot fully match the given instruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12461v1",
    "published_date": "2024-05-21 02:37:45 UTC",
    "updated_date": "2024-05-21 02:37:45 UTC"
  },
  {
    "arxiv_id": "2405.12458v1",
    "title": "Studying Up Public Sector AI: How Networks of Power Relations Shape Agency Decisions Around AI Design and Use",
    "authors": [
      "Anna Kawakami",
      "Amanda Coston",
      "Hoda Heidari",
      "Kenneth Holstein",
      "Haiyi Zhu"
    ],
    "abstract": "As public sector agencies rapidly introduce new AI tools in high-stakes\ndomains like social services, it becomes critical to understand how decisions\nto adopt these tools are made in practice. We borrow from the anthropological\npractice to ``study up'' those in positions of power, and reorient our study of\npublic sector AI around those who have the power and responsibility to make\ndecisions about the role that AI tools will play in their agency. Through\nsemi-structured interviews and design activities with 16 agency\ndecision-makers, we examine how decisions about AI design and adoption are\ninfluenced by their interactions with and assumptions about other actors within\nthese agencies (e.g., frontline workers and agency leaders), as well as those\nabove (legal systems and contracted companies), and below (impacted\ncommunities). By centering these networks of power relations, our findings shed\nlight on how infrastructural, legal, and social factors create barriers and\ndisincentives to the involvement of a broader range of stakeholders in\ndecisions about AI design and adoption. Agency decision-makers desired more\npractical support for stakeholder involvement around public sector AI to help\novercome the knowledge and power differentials they perceived between them and\nother stakeholders (e.g., frontline workers and impacted community members).\nBuilding on these findings, we discuss implications for future research and\npolicy around actualizing participatory AI approaches in public sector\ncontexts.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12458v1",
    "published_date": "2024-05-21 02:31:26 UTC",
    "updated_date": "2024-05-21 02:31:26 UTC"
  },
  {
    "arxiv_id": "2405.12452v2",
    "title": "Prompt-Based Spatio-Temporal Graph Transfer Learning",
    "authors": [
      "Junfeng Hu",
      "Xu Liu",
      "Zhencheng Fan",
      "Yifang Yin",
      "Shili Xiang",
      "Savitha Ramasamy",
      "Roger Zimmermann"
    ],
    "abstract": "Spatio-temporal graph neural networks have proven efficacy in capturing\ncomplex dependencies for urban computing tasks such as forecasting and kriging.\nYet, their performance is constrained by the reliance on extensive data for\ntraining on a specific task, thereby limiting their adaptability to new urban\ndomains with varied task demands. Although transfer learning has been proposed\nto remedy this problem by leveraging knowledge across domains, the cross-task\ngeneralization still remains under-explored in spatio-temporal graph transfer\nlearning due to the lack of a unified framework. To bridge the gap, we propose\nSpatio-Temporal Graph Prompting (STGP), a prompt-based framework capable of\nadapting to multi-diverse tasks in a data-scarce domain. Specifically, we first\nunify different tasks into a single template and introduce a task-agnostic\nnetwork architecture that aligns with this template. This approach enables\ncapturing dependencies shared across tasks. Furthermore, we employ learnable\nprompts to achieve domain and task transfer in a two-stage prompting pipeline,\nfacilitating the prompts to effectively capture domain knowledge and\ntask-specific properties. Our extensive experiments demonstrate that STGP\noutperforms state-of-the-art baselines in three tasks-forecasting, kriging, and\nextrapolation-achieving an improvement of up to 10.7%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12452v2",
    "published_date": "2024-05-21 02:06:40 UTC",
    "updated_date": "2024-11-07 06:41:07 UTC"
  },
  {
    "arxiv_id": "2405.12450v2",
    "title": "PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4",
    "authors": [
      "Seif Abukhalaf",
      "Mohammad Hamdaqa",
      "Foutse Khomh"
    ],
    "abstract": "The rapid progress of AI-powered programming assistants, such as GitHub\nCopilot, has facilitated the development of software applications. These\nassistants rely on large language models (LLMs), which are foundation models\n(FMs) that support a wide range of tasks related to understanding and\ngenerating language. LLMs have demonstrated their ability to express UML model\nspecifications using formal languages like the Object Constraint Language\n(OCL). However, the context size of the prompt is limited by the number of\ntokens an LLM can process. This limitation becomes significant as the size of\nUML class models increases. In this study, we introduce PathOCL, a novel\npath-based prompt augmentation technique designed to facilitate OCL generation.\nPathOCL addresses the limitations of LLMs, specifically their token processing\nlimit and the challenges posed by large UML class models. PathOCL is based on\nthe concept of chunking, which selectively augments the prompts with a subset\nof UML classes relevant to the English specification. Our findings demonstrate\nthat PathOCL, compared to augmenting the complete UML class model\n(UML-Augmentation), generates a higher number of valid and correct OCL\nconstraints using the GPT-4 model. Moreover, the average prompt size crafted\nusing PathOCL significantly decreases when scaling the size of the UML class\nmodels.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Updated affiliations. This paper has been accepted to be published in\n  the 2024 IEEE/ACM First International Conference on AI Foundation Models and\n  Software Engineering (Forge)",
    "pdf_url": "http://arxiv.org/pdf/2405.12450v2",
    "published_date": "2024-05-21 02:00:54 UTC",
    "updated_date": "2024-06-06 23:10:24 UTC"
  },
  {
    "arxiv_id": "2405.12442v1",
    "title": "Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation",
    "authors": [
      "Qingyao Li",
      "Wei Xia",
      "Kounianhua Du",
      "Qiji Zhang",
      "Weinan Zhang",
      "Ruiming Tang",
      "Yong Yu"
    ],
    "abstract": "Concept recommendation aims to suggest the next concept for learners to study\nbased on their knowledge states and the human knowledge system. While knowledge\nstates can be predicted using knowledge tracing models, previous approaches\nhave not effectively integrated the human knowledge system into the process of\ndesigning these educational models. In the era of rapidly evolving Large\nLanguage Models (LLMs), many fields have begun using LLMs to generate and\nencode text, introducing external knowledge. However, integrating LLMs into\nconcept recommendation presents two urgent challenges: 1) How to construct text\nfor concepts that effectively incorporate the human knowledge system? 2) How to\nadapt non-smooth, anisotropic text encodings effectively for concept\nrecommendation? In this paper, we propose a novel Structure and Knowledge Aware\nRepresentation learning framework for concept Recommendation (SKarREC). We\nleverage factual knowledge from LLMs as well as the precedence and succession\nrelationships between concepts obtained from the knowledge graph to construct\ntextual representations of concepts. Furthermore, we propose a graph-based\nadapter to adapt anisotropic text embeddings to the concept recommendation\ntask. This adapter is pre-trained through contrastive learning on the knowledge\ngraph to get a smooth and structure-aware concept representation. Then, it's\nfine-tuned through the recommendation task, forming a\ntext-to-knowledge-to-recommendation adaptation pipeline, which effectively\nconstructs a structure and knowledge-aware concept representation. Our method\ndoes a better job than previous adapters in transforming text encodings for\napplication in concept recommendation. Extensive experiments on real-world\ndatasets demonstrate the effectiveness of the proposed approach.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.12442v1",
    "published_date": "2024-05-21 01:35:36 UTC",
    "updated_date": "2024-05-21 01:35:36 UTC"
  },
  {
    "arxiv_id": "2405.12438v1",
    "title": "CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with Intelligent Agents",
    "authors": [
      "Ruyuan Wan",
      "Simret Gebreegziabhe",
      "Toby Jia-Jun Li",
      "Karla Badillo-Urquiola"
    ],
    "abstract": "In recent years, there has been a growing interest in employing intelligent\nagents in writing. Previous work emphasizes the evaluation of the quality of\nend product-whether it was coherent and polished, overlooking the journey that\nled to the product, which is an invaluable dimension of the creative process.\nTo understand how to recognize human efforts in co-writing with intelligent\nwriting systems, we adapt Flower and Hayes' cognitive process theory of writing\nand propose CoCo Matrix, a two-dimensional taxonomy of entropy and information\ngain, to depict the new human-agent co-writing model. We define four quadrants\nand situate thirty-four published systems within the taxonomy. Our research\nfound that low entropy and high information gain systems are under-explored,\nyet offer promising future directions in writing tasks that benefit from the\nagent's divergent planning and the human's focused translation. CoCo Matrix,\nnot only categorizes different writing systems but also deepens our\nunderstanding of the cognitive processes in human-agent co-writing. By\nanalyzing minimal changes in the writing process, CoCo Matrix serves as a proxy\nfor the writer's mental model, allowing writers to reflect on their\ncontributions. This reflection is facilitated through the measured metrics of\ninformation gain and entropy, which provide insights irrespective of the\nwriting system used.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.12438v1",
    "published_date": "2024-05-21 01:31:17 UTC",
    "updated_date": "2024-05-21 01:31:17 UTC"
  },
  {
    "arxiv_id": "2405.12433v3",
    "title": "LLM+Reasoning+Planning for Supporting Incomplete User Queries in Presence of APIs",
    "authors": [
      "Sudhir Agarwal",
      "Anu Sreepathy",
      "David H. Alonso",
      "Prarit Lamba"
    ],
    "abstract": "Recent availability of Large Language Models (LLMs) has led to the\ndevelopment of numerous LLM-based approaches aimed at providing natural\nlanguage interfaces for various end-user tasks. These end-user tasks in turn\ncan typically be accomplished by orchestrating a given set of APIs. In\npractice, natural language task requests (user queries) are often incomplete,\ni.e., they may not contain all the information required by the APIs. While LLMs\nexcel at natural language processing (NLP) tasks, they frequently hallucinate\non missing information or struggle with orchestrating the APIs. The key idea\nbehind our proposed approach is to leverage logical reasoning and classical AI\nplanning along with an LLM for accurately answering user queries including\nidentification and gathering of any missing information in these queries. Our\napproach uses an LLM and ASP (Answer Set Programming) solver to translate a\nuser query to a representation in Planning Domain Definition Language (PDDL)\nvia an intermediate representation in ASP. We introduce a special API\n\"get_info_api\" for gathering missing information. We model all the APIs as PDDL\nactions in a way that supports dataflow between the APIs. Our approach then\nuses a classical AI planner to generate an orchestration of API calls\n(including calls to get_info_api) to answer the user query. Our evaluation\nresults show that our approach significantly outperforms a pure LLM based\napproach by achieving over 95% success rate in most cases on a dataset\ncontaining complete and incomplete single goal and multi-goal queries where the\nmulti-goal queries may or may not require dataflow among the APIs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings ICLP 2024, arXiv:2502.08453",
    "pdf_url": "http://arxiv.org/pdf/2405.12433v3",
    "published_date": "2024-05-21 01:16:34 UTC",
    "updated_date": "2025-02-13 11:48:15 UTC"
  }
]