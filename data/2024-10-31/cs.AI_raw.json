[
  {
    "arxiv_id": "2411.00265v1",
    "title": "Quantifying calibration error in modern neural networks through evidence based theory",
    "authors": [
      "Koffi Ismael Ouattara"
    ],
    "abstract": "Trustworthiness in neural networks is crucial for their deployment in\ncritical applications, where reliability, confidence, and uncertainty play\npivotal roles in decision-making. Traditional performance metrics such as\naccuracy and precision fail to capture these aspects, particularly in cases\nwhere models exhibit overconfidence. To address these limitations, this paper\nintroduces a novel framework for quantifying the trustworthiness of neural\nnetworks by incorporating subjective logic into the evaluation of Expected\nCalibration Error (ECE). This method provides a comprehensive measure of trust,\ndisbelief, and uncertainty by clustering predicted probabilities and fusing\nopinions using appropriate fusion operators. We demonstrate the effectiveness\nof this approach through experiments on MNIST and CIFAR-10 datasets, where\npost-calibration results indicate improved trustworthiness. The proposed\nframework offers a more interpretable and nuanced assessment of AI models, with\npotential applications in sensitive domains such as healthcare and autonomous\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00265v1",
    "published_date": "2024-10-31 23:54:21 UTC",
    "updated_date": "2024-10-31 23:54:21 UTC"
  },
  {
    "arxiv_id": "2411.00264v2",
    "title": "TurtleBench: A Visual Programming Benchmark in Turtle Geometry",
    "authors": [
      "Sina Rismanchian",
      "Yasaman Razeghi",
      "Sameer Singh",
      "Shayan Doroudi"
    ],
    "abstract": "Humans have the ability to reason about geometric patterns in images and\nscenes from a young age. However, developing large multimodal models (LMMs)\ncapable of similar reasoning remains a challenge, highlighting the need for\nrobust evaluation methods to assess these capabilities. We introduce \\Turtle, a\nbenchmark designed to evaluate LMMs' capacity to interpret geometric patterns\n-- given visual examples, textual instructions, or both -- and generate precise\ncode outputs. Inspired by turtle geometry, a notion used to teach children\nfoundational coding and geometric concepts, TurtleBench features tasks with\npatterned shapes that have underlying algorithmic logic. Our evaluation reveals\nthat leading LMMs struggle significantly with these tasks, with GPT-4o\nachieving only 19\\% accuracy on the simplest tasks and few-shot prompting only\nmarginally improves their performance ($<2\\%$). \\Turtle highlights the gap\nbetween human and AI performance in intuitive and visual geometrical\nunderstanding, setting the stage for future research in this area. \\Turtle\nstands as one of the few benchmarks to evaluate the integration of visual\nunderstanding and code generation capabilities in LMMs, setting the stage for\nfuture research. Code and Dataset for this paper is provided here:\n\\href{https://github.com/sinaris76/TurtleBench}{https://github.com/sinaris76/TurtleBench}",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00264v2",
    "published_date": "2024-10-31 23:52:06 UTC",
    "updated_date": "2025-04-11 21:25:02 UTC"
  },
  {
    "arxiv_id": "2411.00257v1",
    "title": "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models",
    "authors": [
      "Grace Guo",
      "Jenna Jiayi Kang",
      "Raj Sanjay Shah",
      "Hanspeter Pfister",
      "Sashank Varma"
    ],
    "abstract": "Vision Language Models (VLMs) have been successful at many chart\ncomprehension tasks that require attending to both the images of charts and\ntheir accompanying textual descriptions. However, it is not well established\nhow VLM performance profiles map to human-like behaviors. If VLMs can be shown\nto have human-like chart comprehension abilities, they can then be applied to a\nbroader range of tasks, such as designing and evaluating visualizations for\nhuman readers. This paper lays the foundations for such applications by\nevaluating the accuracy of zero-shot prompting of VLMs on graphical perception\ntasks with established human performance profiles. Our findings reveal that\nVLMs perform similarly to humans under specific task and style combinations,\nsuggesting that they have the potential to be used for modeling human\nperformance. Additionally, variations to the input stimuli show that VLM\naccuracy is sensitive to stylistic changes such as fill color and chart\ncontiguity, even when the underlying data and data mappings are the same.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00257v1",
    "published_date": "2024-10-31 23:24:46 UTC",
    "updated_date": "2024-10-31 23:24:46 UTC"
  },
  {
    "arxiv_id": "2411.00247v1",
    "title": "Deep Learning Through A Telescoping Lens: A Simple Model Provides Empirical Insights On Grokking, Gradient Boosting & Beyond",
    "authors": [
      "Alan Jeffares",
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "abstract": "Deep learning sometimes appears to work in unexpected ways. In pursuit of a\ndeeper understanding of its surprising behaviors, we investigate the utility of\na simple yet accurate model of a trained neural network consisting of a\nsequence of first-order approximations telescoping out into a single\nempirically operational tool for practical analysis. Across three case studies,\nwe illustrate how it can be applied to derive new empirical insights on a\ndiverse range of prominent phenomena in the literature -- including double\ndescent, grokking, linear mode connectivity, and the challenges of applying\ndeep learning on tabular data -- highlighting that this model allows us to\nconstruct and extract metrics that help predict and understand the a priori\nunexpected performance of neural networks. We also demonstrate that this model\npresents a pedagogical formalism allowing us to isolate components of the\ntraining process even in complex contemporary settings, providing a lens to\nreason about the effects of design choices such as architecture & optimization\nstrategy, and reveals surprising parallels between neural network learning and\ngradient boosting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Conference on Neural Information Processing Systems\n  (NeurIPS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00247v1",
    "published_date": "2024-10-31 22:54:34 UTC",
    "updated_date": "2024-10-31 22:54:34 UTC"
  },
  {
    "arxiv_id": "2411.00238v2",
    "title": "Understanding the Limits of Vision Language Models Through the Lens of the Binding Problem",
    "authors": [
      "Declan Campbell",
      "Sunayana Rane",
      "Tyler Giallanza",
      "NicolÃ² De Sabbata",
      "Kia Ghods",
      "Amogh Joshi",
      "Alexander Ku",
      "Steven M. Frankland",
      "Thomas L. Griffiths",
      "Jonathan D. Cohen",
      "Taylor W. Webb"
    ],
    "abstract": "Recent work has documented striking heterogeneity in the performance of\nstate-of-the-art vision language models (VLMs), including both multimodal\nlanguage models and text-to-image models. These models are able to describe and\ngenerate a diverse array of complex, naturalistic images, yet they exhibit\nsurprising failures on basic multi-object reasoning tasks -- such as counting,\nlocalization, and simple forms of visual analogy -- that humans perform with\nnear perfect accuracy. To better understand this puzzling pattern of successes\nand failures, we turn to theoretical accounts of the binding problem in\ncognitive science and neuroscience, a fundamental problem that arises when a\nshared set of representational resources must be used to represent distinct\nentities (e.g., to represent multiple objects in an image), necessitating the\nuse of serial processing to avoid interference. We find that many of the\npuzzling failures of state-of-the-art VLMs can be explained as arising due to\nthe binding problem, and that these failure modes are strikingly similar to the\nlimitations exhibited by rapid, feedforward processing in the human brain.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00238v2",
    "published_date": "2024-10-31 22:24:47 UTC",
    "updated_date": "2025-04-16 21:59:00 UTC"
  },
  {
    "arxiv_id": "2411.00230v2",
    "title": "Reinforcement learning with learned gadgets to tackle hard quantum problems on real hardware",
    "authors": [
      "Akash Kundu",
      "Leopoldo Sarra"
    ],
    "abstract": "Designing quantum circuits for specific tasks is challenging due to the\nexponential growth of the state space. We introduce gadget reinforcement\nlearning (GRL), which integrates reinforcement learning with program synthesis\nto automatically generate and incorporate composite gates (gadgets) into the\naction space. This enhances the exploration of parameterized quantum circuits\n(PQCs) for complex tasks like approximating ground states of quantum\nHamiltonians, an NP-hard problem. We evaluate GRL using the transverse field\nIsing model under typical computational budgets (e.g., 2- 3 days of GPU\nruntime). Our results show improved accuracy, hardware compatibility and\nscalability. GRL exhibits robust performance as the size and complexity of the\nproblem increases, even with constrained computational resources. By\nintegrating gadget extraction, GRL facilitates the discovery of reusable\ncircuit components tailored for specific hardware, bridging the gap between\nalgorithmic design and practical implementation. This makes GRL a versatile\nframework for optimizing quantum circuits with applications in\nhardware-specific optimizations and variational quantum algorithms. The code is\navailable at: https://github.com/Aqasch/Gadget_RL",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "23 pages, 13 figures. Comments are encouraged",
    "pdf_url": "http://arxiv.org/pdf/2411.00230v2",
    "published_date": "2024-10-31 22:02:32 UTC",
    "updated_date": "2025-05-02 06:39:57 UTC"
  },
  {
    "arxiv_id": "2411.00222v1",
    "title": "Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding",
    "authors": [
      "Ehsan Ganjidoost",
      "Jeff Orchard"
    ],
    "abstract": "An adversarial example is a modified input image designed to cause a Machine\nLearning (ML) model to make a mistake; these perturbations are often invisible\nor subtle to human observers and highlight vulnerabilities in a model's ability\nto generalize from its training data. Several adversarial attacks can create\nsuch examples, each with a different perspective, effectiveness, and\nperceptibility of changes. Conversely, defending against such adversarial\nattacks improves the robustness of ML models in image processing and other\ndomains of deep learning. Most defence mechanisms require either a level of\nmodel awareness, changes to the model, or access to a comprehensive set of\nadversarial examples during training, which is impractical. Another option is\nto use an auxiliary model in a preprocessing manner without changing the\nprimary model. This study presents a practical and effective solution -- using\npredictive coding networks (PCnets) as an auxiliary step for adversarial\ndefence. By seamlessly integrating PCnets into feed-forward networks as a\npreprocessing step, we substantially bolster resilience to adversarial\nperturbations. Our experiments on MNIST and CIFAR10 demonstrate the remarkable\neffectiveness of PCnets in mitigating adversarial examples with about 82% and\n65% improvements in robustness, respectively. The PCnet, trained on a small\nsubset of the dataset, leverages its generative nature to effectively counter\nadversarial efforts, reverting perturbed images closer to their original forms.\nThis innovative approach holds promise for enhancing the security and\nreliability of neural network classifiers in the face of the escalating threat\nof adversarial attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00222v1",
    "published_date": "2024-10-31 21:38:05 UTC",
    "updated_date": "2024-10-31 21:38:05 UTC"
  },
  {
    "arxiv_id": "2411.00217v1",
    "title": "ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing",
    "authors": [
      "Haozhe Lei",
      "Yunfei Ge",
      "Quanyan Zhu"
    ],
    "abstract": "The integration of AI into modern critical infrastructure systems, such as\nhealthcare, has introduced new vulnerabilities that can significantly impact\nworkflow, efficiency, and safety. Additionally, the increased connectivity has\nmade traditional human-driven penetration testing insufficient for assessing\nrisks and developing remediation strategies. Consequently, there is a pressing\nneed for a distributed, adaptive, and efficient automated penetration testing\nframework that not only identifies vulnerabilities but also provides\ncountermeasures to enhance security posture. This work presents ADAPT, a\ngame-theoretic and neuro-symbolic framework for automated distributed adaptive\npenetration testing, specifically designed to address the unique cybersecurity\nchallenges of AI-enabled healthcare infrastructure networks. We use a\nhealthcare system case study to illustrate the methodologies within ADAPT. The\nproposed solution enables a learning-based risk assessment. Numerical\nexperiments are used to demonstrate effective countermeasures against various\ntactical techniques employed by adversarial AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00217v1",
    "published_date": "2024-10-31 21:32:17 UTC",
    "updated_date": "2024-10-31 21:32:17 UTC"
  },
  {
    "arxiv_id": "2411.00891v2",
    "title": "Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images",
    "authors": [
      "Arianna Bunnell",
      "Dustin Valdez",
      "Thomas K. Wolfgruber",
      "Brandon Quon",
      "Kailee Hung",
      "Brenda Y. Hernandez",
      "Todd B. Seto",
      "Jeffrey Killeen",
      "Marshall Miyoshi",
      "Peter Sadowski",
      "John A. Shepherd"
    ],
    "abstract": "Background: Breast density, as derived from mammographic images and defined\nby the American College of Radiology's Breast Imaging Reporting and Data System\n(BI-RADS), is one of the strongest risk factors for breast cancer. Breast\nultrasound (BUS) is an alternative breast cancer screening modality,\nparticularly useful for early detection in low-resource, rural contexts. The\npurpose of this study was to explore an artificial intelligence (AI) model to\npredict BI-RADS mammographic breast density category from clinical, handheld\nBUS imaging. Methods: All data are sourced from the Hawaii and Pacific Islands\nMammography Registry. We compared deep learning methods from BUS imaging, as\nwell as machine learning models from image statistics alone. The use of\nAI-derived BUS density as a risk factor for breast cancer was then compared to\nclinical BI-RADS breast density while adjusting for age. The BUS data were\nsplit by individual into 70/20/10% groups for training, validation, and\ntesting. Results: 405,120 clinical BUS images from 14.066 women were selected\nfor inclusion in this study, resulting in 9.846 women for training (302,574\nimages), 2,813 for validation (11,223 images), and 1,406 for testing (4,042\nimages). On the held-out testing set, the strongest AI model achieves AUROC\n0.854 predicting BI-RADS mammographic breast density from BUS imaging and\noutperforms all shallow machine learning methods based on image statistics. In\ncancer risk prediction, age-adjusted AI BUS breast density predicted 5-year\nbreast cancer risk with 0.633 AUROC, as compared to 0.637 AUROC from\nage-adjusted clinical breast density. Conclusions: BI-RADS mammographic breast\ndensity can be estimated from BUS imaging with high accuracy using a deep\nlearning model. Furthermore, we demonstrate that AI-derived BUS breast density\nis predictive of 5-year breast cancer risk in our population.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00891v2",
    "published_date": "2024-10-31 21:28:20 UTC",
    "updated_date": "2024-11-07 21:25:07 UTC"
  },
  {
    "arxiv_id": "2411.00208v2",
    "title": "Using Large Language Models for a standard assessment mapping for sustainable communities",
    "authors": [
      "Luc Jonveaux"
    ],
    "abstract": "This paper presents a new approach to urban sustainability assessment through\nthe use of Large Language Models (LLMs) to streamline the use of the ISO 37101\nframework to automate and standardise the assessment of urban initiatives\nagainst the six \"sustainability purposes\" and twelve \"issues\" outlined in the\nstandard. The methodology includes the development of a custom prompt based on\nthe standard definitions and its application to two different datasets: 527\nprojects from the Paris Participatory Budget and 398 activities from the\nPROBONO Horizon 2020 project. The results show the effectiveness of LLMs in\nquickly and consistently categorising different urban initiatives according to\nsustainability criteria. The approach is particularly promising when it comes\nto breaking down silos in urban planning by providing a holistic view of the\nimpact of projects. The paper discusses the advantages of this method over\ntraditional human-led assessments, including significant time savings and\nimproved consistency. However, it also points out the importance of human\nexpertise in interpreting results and ethical considerations. This study\nhopefully can contribute to the growing body of work on AI applications in\nurban planning and provides a novel method for operationalising standardised\nsustainability frameworks in different urban contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.3"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00208v2",
    "published_date": "2024-10-31 21:07:58 UTC",
    "updated_date": "2024-11-25 12:04:18 UTC"
  },
  {
    "arxiv_id": "2412.19808v1",
    "title": "AI-driven Automation as a Pre-condition for Eudaimonia",
    "authors": [
      "Anastasia Siapka"
    ],
    "abstract": "The debate surrounding the 'future of work' is saturated with alarmist\nwarnings about the loss of work as an intrinsically valuable activity. Instead,\nthe present doctoral research approaches this debate from the perspective of\nhuman flourishing (eudaimonia). It articulates a neo-Aristotelian\ninterpretation according to which the prospect of mass AI-driven automation,\nfar from being a threat, is rather desirable insofar as it facilitates humans'\nflourishing and, subsequently, their engagement in leisure. Drawing on virtue\njurisprudence, this research further explores what this desirability may imply\nfor the current legal order.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19808v1",
    "published_date": "2024-10-31 20:57:38 UTC",
    "updated_date": "2024-10-31 20:57:38 UTC"
  },
  {
    "arxiv_id": "2411.00205v2",
    "title": "Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Beyazit Yalcinkaya",
      "Niklas Lauffer",
      "Marcell Vazquez-Chanlatte",
      "Sanjit A. Seshia"
    ],
    "abstract": "Goal-conditioned reinforcement learning is a powerful way to control an AI\nagent's behavior at runtime. That said, popular goal representations, e.g.,\ntarget states or natural language, are either limited to Markovian tasks or\nrely on ambiguous task semantics. We propose representing temporal goals using\ncompositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL\nagents. cDFAs balance the need for formal temporal semantics with ease of\ninterpretation: if one can understand a flow chart, one can understand a cDFA.\nOn the other hand, cDFAs form a countably infinite concept class with Boolean\nsemantics, and subtle changes to the automaton can result in very different\ntasks, making them difficult to condition agent behavior on. To address this,\nwe observe that all paths through a DFA correspond to a series of reach-avoid\ntasks and propose pre-training graph neural network embeddings on \"reach-avoid\nderived\" DFAs. Through empirical evaluation, we demonstrate that the proposed\npre-training method enables zero-shot generalization to various cDFA task\nclasses and accelerated policy specialization without the myopic suboptimality\nof hierarchical methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00205v2",
    "published_date": "2024-10-31 20:56:07 UTC",
    "updated_date": "2025-01-15 01:46:25 UTC"
  },
  {
    "arxiv_id": "2411.00196v1",
    "title": "Whole-Herd Elephant Pose Estimation from Drone Data for Collective Behavior Analysis",
    "authors": [
      "Brody McNutt",
      "Libby Zhang",
      "Angus Carey-Douglas",
      "Fritz Vollrath",
      "Frank Pope",
      "Leandra Brickson"
    ],
    "abstract": "This research represents a pioneering application of automated pose\nestimation from drone data to study elephant behavior in the wild, utilizing\nvideo footage captured from Samburu National Reserve, Kenya. The study\nevaluates two pose estimation workflows: DeepLabCut, known for its application\nin laboratory settings and emerging wildlife fieldwork, and YOLO-NAS-Pose, a\nnewly released pose estimation model not previously applied to wildlife\nbehavioral studies. These models are trained to analyze elephant herd behavior,\nfocusing on low-resolution ($\\sim$50 pixels) subjects to detect key points such\nas the head, spine, and ears of multiple elephants within a frame. Both\nworkflows demonstrated acceptable quality of pose estimation on the test set,\nfacilitating the automated detection of basic behaviors crucial for studying\nelephant herd dynamics. For the metrics selected for pose estimation evaluation\non the test set -- root mean square error (RMSE), percentage of correct\nkeypoints (PCK), and object keypoint similarity (OKS) -- the YOLO-NAS-Pose\nworkflow outperformed DeepLabCut. Additionally, YOLO-NAS-Pose exceeded\nDeepLabCut in object detection evaluation. This approach introduces a novel\nmethod for wildlife behavioral research, including the burgeoning field of\nwildlife drone monitoring, with significant implications for wildlife\nconservation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CV4Animals: Computer Vision for Animal Behavior Tracking\n  and Modeling Workshop in conjunction with Computer Vision and Pattern\n  Recognition 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00196v1",
    "published_date": "2024-10-31 20:26:59 UTC",
    "updated_date": "2024-10-31 20:26:59 UTC"
  },
  {
    "arxiv_id": "2411.00890v1",
    "title": "Rethinking Scale: The Efficacy of Fine-Tuned Open-Source LLMs in Large-Scale Reproducible Social Science Research",
    "authors": [
      "Marcello Carammia",
      "Stefano Maria Iacus",
      "Giuseppe Porro"
    ],
    "abstract": "Large Language Models (LLMs) are distinguished by their architecture, which\ndictates their parameter size and performance capabilities. Social scientists\nhave increasingly adopted LLMs for text classification tasks, which are\ndifficult to scale with human coders. While very large, closed-source models\noften deliver superior performance, their use presents significant risks. These\ninclude lack of transparency, potential exposure of sensitive data, challenges\nto replicability, and dependence on proprietary systems. Additionally, their\nhigh costs make them impractical for large-scale research projects.\n  In contrast, open-source models, although available in various sizes, may\nunderperform compared to commercial alternatives if used without further\nfine-tuning. However, open-source models offer distinct advantages: they can be\nrun locally (ensuring data privacy), fine-tuned for specific tasks, shared\nwithin the research community, and integrated into reproducible workflows.\n  This study demonstrates that small, fine-tuned open-source LLMs can achieve\nequal or superior performance to models such as ChatGPT-4. We further explore\nthe relationship between training set size and fine-tuning efficacy in\nopen-source models. Finally, we propose a hybrid workflow that leverages the\nstrengths of both open and closed models, offering a balanced approach to\nperformance, transparency, and reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00890v1",
    "published_date": "2024-10-31 20:26:30 UTC",
    "updated_date": "2024-10-31 20:26:30 UTC"
  },
  {
    "arxiv_id": "2411.00190v2",
    "title": "Monitoring fairness in machine learning models that predict patient mortality in the ICU",
    "authors": [
      "Tempest A. van Schaik",
      "Xinggang Liu",
      "Louis Atallah",
      "Omar Badawi"
    ],
    "abstract": "This work proposes a fairness monitoring approach for machine learning models\nthat predict patient mortality in the ICU. We investigate how well models\nperform for patient groups with different race, sex and medical diagnoses. We\ninvestigate Documentation bias in clinical measurement, showing how fairness\nanalysis provides a more detailed and insightful comparison of model\nperformance than traditional accuracy metrics alone.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.00190v2",
    "published_date": "2024-10-31 20:17:12 UTC",
    "updated_date": "2024-11-06 20:32:55 UTC"
  },
  {
    "arxiv_id": "2411.00188v1",
    "title": "Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis",
    "authors": [
      "Yu Pan",
      "Jianxin Sun",
      "Hongfeng Yu",
      "Joe Luck",
      "Geng Bai",
      "Nipuna Chamara",
      "Yufeng Ge",
      "Tala Awada"
    ],
    "abstract": "Current agricultural data management and analysis paradigms are to large\nextent traditional, in which data collecting, curating, integration, loading,\nstoring, sharing and analyzing still involve too much human effort and\nknow-how. The experts, researchers and the farm operators need to understand\nthe data and the whole process of data management pipeline to make fully use of\nthe data. The essential problem of the traditional paradigm is the lack of a\nlayer of orchestrational intelligence which can understand, organize and\ncoordinate the data processing utilities to maximize data management and\nanalysis outcome. The emerging reasoning and tool mastering abilities of large\nlanguage models (LLM) make it a potentially good fit to this position, which\nhelps a shift from the traditional user-driven paradigm to AI-driven paradigm.\nIn this paper, we propose and explore the idea of a LLM based copilot for\nautonomous agricultural data management and analysis. Based on our previously\ndeveloped platform of Agricultural Data Management and Analytics (ADMA), we\nbuild a proof-of-concept multi-agent system called ADMA Copilot, which can\nunderstand user's intent, makes plans for data processing pipeline and\naccomplishes tasks automatically, in which three agents: a LLM based\ncontroller, an input formatter and an output formatter collaborate together.\nDifferent from existing LLM based solutions, by defining a meta-program graph,\nour work decouples control flow and data flow to enhance the predictability of\nthe behaviour of the agents. Experiments demonstrates the intelligence,\nautonomy, efficacy, efficiency, extensibility, flexibility and privacy of our\nsystem. Comparison is also made between ours and existing systems to show the\nsuperiority and potential of our system.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00188v1",
    "published_date": "2024-10-31 20:15:14 UTC",
    "updated_date": "2024-10-31 20:15:14 UTC"
  },
  {
    "arxiv_id": "2411.00186v1",
    "title": "Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments",
    "authors": [
      "Paulius Rauba",
      "Nabeel Seedat",
      "Krzysztof Kacprzyk",
      "Mihaela van der Schaar"
    ],
    "abstract": "Real-world machine learning systems often encounter model performance\ndegradation due to distributional shifts in the underlying data generating\nprocess (DGP). Existing approaches to addressing shifts, such as concept drift\nadaptation, are limited by their reason-agnostic nature. By choosing from a\npre-defined set of actions, such methods implicitly assume that the causes of\nmodel degradation are irrelevant to what actions should be taken, limiting\ntheir ability to select appropriate adaptations. In this paper, we propose an\nalternative paradigm to overcome these limitations, called self-healing machine\nlearning (SHML). Contrary to previous approaches, SHML autonomously diagnoses\nthe reason for degradation and proposes diagnosis-based corrective actions. We\nformalize SHML as an optimization problem over a space of adaptation actions to\nminimize the expected risk under the shifted DGP. We introduce a theoretical\nframework for self-healing systems and build an agentic self-healing solution\nH-LLM which uses large language models to perform self-diagnosis by reasoning\nabout the structure underlying the DGP, and self-adaptation by proposing and\nevaluating corrective actions. Empirically, we analyze different components of\nH-LLM to understand why and when it works, demonstrating the potential of\nself-healing ML.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Advances in Neural Information Processing Systems 38 (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.00186v1",
    "published_date": "2024-10-31 20:05:51 UTC",
    "updated_date": "2024-10-31 20:05:51 UTC"
  },
  {
    "arxiv_id": "2411.00178v2",
    "title": "Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy",
    "authors": [
      "Panagiota Gatoula",
      "Dimitrios E. Diamantis",
      "Anastasios Koulaouzidis",
      "Cristina Carretero",
      "Stefania Chetcuti-Zammit",
      "Pablo Cortegoso Valdivia",
      "BegoÃ±a GonzÃ¡lez-SuÃ¡rez",
      "Alessandro Mussetto",
      "John Plevris",
      "Alexander Robertson",
      "Bruno Rosa",
      "Ervin Toth",
      "Dimitris K. Iakovidis"
    ],
    "abstract": "Synthetic Data Generation (SDG) based on Artificial Intelligence (AI) can\ntransform the way clinical medicine is delivered by overcoming privacy barriers\nthat currently render clinical data sharing difficult. This is the key to\naccelerating the development of digital tools contributing to enhanced patient\nsafety. Such tools include robust data-driven clinical decision support\nsystems, and example-based digital training tools that will enable healthcare\nprofessionals to improve their diagnostic performance for enhanced patient\nsafety. This study focuses on the clinical evaluation of medical SDG, with a\nproof-of-concept investigation on diagnosing Inflammatory Bowel Disease (IBD)\nusing Wireless Capsule Endoscopy (WCE) images. Its scientific contributions\ninclude a) a novel protocol for the systematic Clinical Evaluation of Medical\nImage Synthesis (CEMIS); b) a novel variational autoencoder-based model for the\ngeneration of high-resolution synthetic WCE images; and c) a comprehensive\nevaluation of the synthetic images using the CEMIS protocol by 10 international\nWCE specialists, in terms of image quality, diversity, and realism, as well as\ntheir utility for clinical decision-making. The results show that TIDE-II\ngenerates clinically plausible, very realistic WCE images, of improved quality\ncompared to relevant state-of-the-art generative models. Concludingly, CEMIS\ncan serve as a reference for future research on medical image-generation\ntechniques, while the adaptation/extension of the architecture of TIDE-II to\nother imaging domains can be promising.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted for possible journal publication",
    "pdf_url": "http://arxiv.org/pdf/2411.00178v2",
    "published_date": "2024-10-31 19:48:50 UTC",
    "updated_date": "2025-03-09 06:23:54 UTC"
  },
  {
    "arxiv_id": "2411.00173v2",
    "title": "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning",
    "authors": [
      "John Wu",
      "David Wu",
      "Jimeng Sun"
    ],
    "abstract": "Medical coding, the translation of unstructured clinical text into\nstandardized medical codes, is a crucial but time-consuming healthcare\npractice. Though large language models (LLM) could automate the coding process\nand improve the efficiency of such tasks, interpretability remains paramount\nfor maintaining patient trust. Current efforts in interpretability of medical\ncoding applications rely heavily on label attention mechanisms, which often\nleads to the highlighting of extraneous tokens irrelevant to the ICD code. To\nfacilitate accurate interpretability in medical language models, this paper\nleverages dictionary learning that can efficiently extract sparsely activated\nrepresentations from dense language model embeddings in superposition. Compared\nwith common label attention mechanisms, our model goes beyond token-level\nrepresentations by building an interpretable dictionary which enhances the\nmechanistic-based explanations for each ICD code prediction, even when the\nhighlighted tokens are medically irrelevant. We show that dictionary features\ncan steer model behavior, elucidate the hidden meanings of upwards of 90% of\nmedically irrelevant tokens, and are human interpretable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "https://aclanthology.org/2024.emnlp-main.500/",
    "pdf_url": "http://arxiv.org/pdf/2411.00173v2",
    "published_date": "2024-10-31 19:39:40 UTC",
    "updated_date": "2025-03-22 20:20:38 UTC"
  },
  {
    "arxiv_id": "2411.00168v1",
    "title": "Creativity in the Age of AI: Evaluating the Impact of Generative AI on Design Outputs and Designers' Creative Thinking",
    "authors": [
      "Yue Fu",
      "Han Bin",
      "Tony Zhou",
      "Marx Wang",
      "Yixin Chen",
      "Zelia Gomes Da Costa Lai",
      "Jacob O. Wobbrock",
      "Alexis Hiniker"
    ],
    "abstract": "As generative AI (GenAI) increasingly permeates design workflows, its impact\non design outcomes and designers' creative capabilities warrants investigation.\nWe conducted a within-subjects experiment where we asked participants to design\nadvertisements both with and without GenAI support. Our results show that\nexpert evaluators rated GenAI-supported designs as more creative and\nunconventional (\"weird\") despite no significant differences in visual appeal,\nbrand alignment, or usefulness, which highlights the decoupling of novelty from\nusefulness-traditional dual components of creativity-in the context of GenAI\nusage. Moreover, while GenAI does not significantly enhance designers' overall\ncreative thinking abilities, users were affected differently based on native\nlanguage and prior AI exposure. Native English speakers experienced reduced\nrelaxation when using AI, whereas designers new to GenAI exhibited gains in\ndivergent thinking, such as idea fluency and flexibility. These findings\nunderscore the variable impact of GenAI on different user groups, suggesting\nthe potential for customized AI tools.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00168v1",
    "published_date": "2024-10-31 19:23:34 UTC",
    "updated_date": "2024-10-31 19:23:34 UTC"
  },
  {
    "arxiv_id": "2411.00163v1",
    "title": "PSL: Rethinking and Improving Softmax Loss from Pairwise Perspective for Recommendation",
    "authors": [
      "Weiqin Yang",
      "Jiawei Chen",
      "Xin Xin",
      "Sheng Zhou",
      "Binbin Hu",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "abstract": "Softmax Loss (SL) is widely applied in recommender systems (RS) and has\ndemonstrated effectiveness. This work analyzes SL from a pairwise perspective,\nrevealing two significant limitations: 1) the relationship between SL and\nconventional ranking metrics like DCG is not sufficiently tight; 2) SL is\nhighly sensitive to false negative instances. Our analysis indicates that these\nlimitations are primarily due to the use of the exponential function. To\naddress these issues, this work extends SL to a new family of loss functions,\ntermed Pairwise Softmax Loss (PSL), which replaces the exponential function in\nSL with other appropriate activation functions. While the revision is minimal,\nwe highlight three merits of PSL: 1) it serves as a tighter surrogate for DCG\nwith suitable activation functions; 2) it better balances data contributions;\nand 3) it acts as a specific BPR loss enhanced by Distributionally Robust\nOptimization (DRO). We further validate the effectiveness and robustness of PSL\nthrough empirical experiments. The code is available at\nhttps://github.com/Tiny-Snow/IR-Benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00163v1",
    "published_date": "2024-10-31 19:11:26 UTC",
    "updated_date": "2024-10-31 19:11:26 UTC"
  },
  {
    "arxiv_id": "2411.00156v1",
    "title": "Unlocking the Potential of Global Human Expertise",
    "authors": [
      "Elliot Meyerson",
      "Olivier Francon",
      "Darren Sargent",
      "Babak Hodjat",
      "Risto Miikkulainen"
    ],
    "abstract": "Solving societal problems on a global scale requires the collection and\nprocessing of ideas and methods from diverse sets of international experts. As\nthe number and diversity of human experts increase, so does the likelihood that\nelements in this collective knowledge can be combined and refined to discover\nnovel and better solutions. However, it is difficult to identify, combine, and\nrefine complementary information in an increasingly large and diverse knowledge\nbase. This paper argues that artificial intelligence (AI) can play a crucial\nrole in this process. An evolutionary AI framework, termed RHEA, fills this\nrole by distilling knowledge from diverse models created by human experts into\nequivalent neural networks, which are then recombined and refined in a\npopulation-based search. The framework was implemented in a formal synthetic\ndomain, demonstrating that it is transparent and systematic. It was then\napplied to the results of the XPRIZE Pandemic Response Challenge, in which over\n100 teams of experts across 23 countries submitted models based on diverse\nmethodologies to predict COVID-19 cases and suggest non-pharmaceutical\nintervention policies for 235 nations, states, and regions across the globe.\nBuilding upon this expert knowledge, by recombining and refining the 169\nresulting policy suggestion models, RHEA discovered a broader and more\neffective set of policies than either AI or human experts alone, as evaluated\nbased on real-world data. The results thus suggest that AI can play a crucial\nrole in realizing the potential of human expertise in global problem-solving.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024; Main Paper 15 pages, Appendix 11 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.00156v1",
    "published_date": "2024-10-31 19:02:00 UTC",
    "updated_date": "2024-10-31 19:02:00 UTC"
  },
  {
    "arxiv_id": "2411.00154v2",
    "title": "Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models",
    "authors": [
      "Haritz Puerto",
      "Martin Gubri",
      "Sangdoo Yun",
      "Seong Joon Oh"
    ],
    "abstract": "Membership inference attacks (MIA) attempt to verify the membership of a\ngiven data sample in the training set for a model. MIA has become relevant in\nrecent years, following the rapid development of large language models (LLM).\nMany are concerned about the usage of copyrighted materials for training them\nand call for methods for detecting such usage. However, recent research has\nlargely concluded that current MIA methods do not work on LLMs. Even when they\nseem to work, it is usually because of the ill-designed experimental setup\nwhere other shortcut features enable \"cheating.\" In this work, we argue that\nMIA still works on LLMs, but only when multiple documents are presented for\ntesting. We construct new benchmarks that measure the MIA performances at a\ncontinuous scale of data samples, from sentences (n-grams) to a collection of\ndocuments (multiple chunks of tokens). To validate the efficacy of current MIA\napproaches at greater scales, we adapt a recent work on Dataset Inference (DI)\nfor the task of binary membership detection that aggregates paragraph-level MIA\nfeatures to enable MIA at document and collection of documents level. This\nbaseline achieves the first successful MIA on pre-trained and fine-tuned LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of NAACL 2025. Our code is available at\n  https://github.com/parameterlab/mia-scaling",
    "pdf_url": "http://arxiv.org/pdf/2411.00154v2",
    "published_date": "2024-10-31 18:59:46 UTC",
    "updated_date": "2025-02-03 15:33:59 UTC"
  },
  {
    "arxiv_id": "2411.00150v2",
    "title": "Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking",
    "authors": [
      "Christopher Richardson",
      "Roshan Sharma",
      "Neeraj Gaur",
      "Parisa Haghani",
      "Anirudh Sundar",
      "Bhuvana Ramabhadran"
    ],
    "abstract": "Zero-shot domain adaptation for dialogue state tracking (DST) remains a\nchallenging problem in task-oriented dialogue (TOD) systems, where models must\ngeneralize to target domains unseen at training time. Current large language\nmodel approaches for zero-shot domain adaptation rely on prompting to introduce\nknowledge pertaining to the target domains. However, their efficacy strongly\ndepends on prompt engineering, as well as the zero-shot ability of the\nunderlying language model. In this work, we devise a novel data augmentation\napproach, Schema Augmentation, that improves the zero-shot domain adaptation of\nlanguage models through fine-tuning. Schema Augmentation is a simple but\neffective technique that enhances generalization by introducing variations of\nslot names within the schema provided in the prompt. Experiments on MultiWOZ\nand SpokenWOZ showed that the proposed approach resulted in a substantial\nimprovement over the baseline, in some experiments achieving over a twofold\naccuracy gain over unseen domains while maintaining equal or superior\nperformance over all domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "short paper (4 pages) submitted to ARR",
    "pdf_url": "http://arxiv.org/pdf/2411.00150v2",
    "published_date": "2024-10-31 18:57:59 UTC",
    "updated_date": "2025-02-21 18:54:37 UTC"
  },
  {
    "arxiv_id": "2411.00146v2",
    "title": "Responsibility-aware Strategic Reasoning in Probabilistic Multi-Agent Systems",
    "authors": [
      "Chunyan Mu",
      "Muhammad Najib",
      "Nir Oren"
    ],
    "abstract": "Responsibility plays a key role in the development and deployment of\ntrustworthy autonomous systems. In this paper, we focus on the problem of\nstrategic reasoning in probabilistic multi-agent systems with\nresponsibility-aware agents. We introduce the logic PATL+R, a variant of\nProbabilistic Alternating-time Temporal Logic. The novelty of PATL+R lies in\nits incorporation of modalities for causal responsibility, providing a\nframework for responsibility-aware multi-agent strategic reasoning. We present\nan approach to synthesise joint strategies that satisfy an outcome specified in\nPATL+R, while optimising the share of expected causal responsibility and\nreward. This provides a notion of balanced distribution of responsibility and\nreward gain among agents. To this end, we utilise the Nash equilibrium as the\nsolution concept for our strategic reasoning problem and demonstrate how to\ncompute responsibility-aware Nash equilibrium strategies via a reduction to\nparametric model checking of concurrent stochastic multi-player games.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00146v2",
    "published_date": "2024-10-31 18:49:12 UTC",
    "updated_date": "2024-12-20 10:50:09 UTC"
  },
  {
    "arxiv_id": "2411.00887v1",
    "title": "Measuring Responsibility in Multi-Agent Systems",
    "authors": [
      "Chunyan Mu",
      "Nir Oren"
    ],
    "abstract": "We introduce a family of quantitative measures of responsibility in\nmulti-agent planning, building upon the concepts of causal responsibility\nproposed by Parker et al.~[ParkerGL23]. These concepts are formalised within a\nvariant of probabilistic alternating-time temporal logic. Unlike existing\napproaches, our framework ascribes responsibility to agents for a given outcome\nby linking probabilities between behaviours and responsibility through three\nmetrics, including an entropy-based measurement of responsibility. This latter\nmeasure is the first to capture the causal responsibility properties of\noutcomes over time, offering an asymptotic measurement that reflects the\ndifficulty of achieving these outcomes. Our approach provides a fresh\nunderstanding of responsibility in multi-agent systems, illuminating both the\nqualitative and quantitative aspects of agents' roles in achieving or\npreventing outcomes.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00887v1",
    "published_date": "2024-10-31 18:45:34 UTC",
    "updated_date": "2024-10-31 18:45:34 UTC"
  },
  {
    "arxiv_id": "2411.00142v1",
    "title": "JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking",
    "authors": [
      "Tong Niu",
      "Shafiq Joty",
      "Ye Liu",
      "Caiming Xiong",
      "Yingbo Zhou",
      "Semih Yavuz"
    ],
    "abstract": "Accurate document retrieval is crucial for the success of retrieval-augmented\ngeneration (RAG) applications, including open-domain question answering and\ncode completion. While large language models (LLMs) have been employed as dense\nencoders or listwise rerankers in RAG systems, they often struggle with\nreasoning-intensive tasks because they lack nuanced analysis when judging\ndocument relevance. To address this limitation, we introduce JudgeRank, a novel\nagentic reranker that emulates human cognitive processes when assessing\ndocument relevance. Our approach consists of three key steps: (1) query\nanalysis to identify the core problem, (2) document analysis to extract a\nquery-aware summary, and (3) relevance judgment to provide a concise assessment\nof document relevance. We evaluate JudgeRank on the reasoning-intensive BRIGHT\nbenchmark, demonstrating substantial performance improvements over first-stage\nretrieval methods and outperforming other popular reranking approaches. In\naddition, JudgeRank performs on par with fine-tuned state-of-the-art rerankers\non the popular BEIR benchmark, validating its zero-shot generalization\ncapability. Through comprehensive ablation studies, we demonstrate that\nJudgeRank's performance generalizes well across LLMs of various sizes while\nensembling them yields even more accurate reranking than individual models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00142v1",
    "published_date": "2024-10-31 18:43:12 UTC",
    "updated_date": "2024-10-31 18:43:12 UTC"
  },
  {
    "arxiv_id": "2411.00138v4",
    "title": "Learning Low-Dimensional Strain Models of Soft Robots by Looking at the Evolution of Their Shape with Application to Model-Based Control",
    "authors": [
      "Ricardo Valadas",
      "Maximilian StÃ¶lzle",
      "Jingyue Liu",
      "Cosimo Della Santina"
    ],
    "abstract": "Obtaining dynamic models of continuum soft robots is central to the analysis\nand control of soft robots, and researchers have devoted much attention to the\nchallenge of proposing both data-driven and first-principle solutions. Both\navenues have, however, shown their limitations; the former lacks structure and\nperforms poorly outside training data, while the latter requires significant\nsimplifications and extensive expert knowledge to be used in practice. This\npaper introduces a streamlined method for learning low-dimensional,\nphysics-based models that are both accurate and easy to interpret. We start\nwith an algorithm that uses image data (i.e., shape evolutions) to determine\nthe minimal necessary segments for describing a soft robot's movement.\nFollowing this, we apply a dynamic regression and strain sparsification\nalgorithm to identify relevant strains and define the model's dynamics. We\nvalidate our approach through simulations with various planar soft\nmanipulators, comparing its performance against other learning strategies,\nshowing that our models are both computationally efficient and 25x more\naccurate on out-of-training distribution inputs. Finally, we demonstrate that\nthanks to the capability of the method of generating physically compatible\nmodels, the learned models can be straightforwardly combined with model-based\ncontrol policies.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, appearing in Proceedings of the 2025 IEEE 8th International\n  Conference on Soft Robotics (RoboSoft)",
    "pdf_url": "http://arxiv.org/pdf/2411.00138v4",
    "published_date": "2024-10-31 18:37:22 UTC",
    "updated_date": "2025-02-20 12:49:55 UTC"
  },
  {
    "arxiv_id": "2411.00132v2",
    "title": "Beyond Accuracy: Ensuring Correct Predictions With Correct Rationales",
    "authors": [
      "Tang Li",
      "Mengmeng Ma",
      "Xi Peng"
    ],
    "abstract": "Large pretrained foundation models demonstrate exceptional performance and,\nin some high-stakes applications, even surpass human experts. However, most of\nthese models are currently evaluated primarily on prediction accuracy,\noverlooking the validity of the rationales behind their accurate predictions.\nFor the safe deployment of foundation models, there is a pressing need to\nensure double-correct predictions, i.e., correct prediction backed by correct\nrationales. To achieve this, we propose a two-phase scheme: First, we curate a\nnew dataset that offers structured rationales for visual recognition tasks.\nSecond, we propose a rationale-informed optimization method to guide the model\nin disentangling and localizing visual evidence for each rationale, without\nrequiring manual annotations. Extensive experiments and ablation studies\ndemonstrate that our model outperforms state-of-the-art models by up to 10.1%\nin prediction accuracy across a wide range of tasks. Furthermore, our method\nsignificantly improves the model's rationale correctness, improving\nlocalization by 7.5% and disentanglement by 36.5%. Our dataset, source code,\nand pretrained weights: https://github.com/deep-real/DCP",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.00132v2",
    "published_date": "2024-10-31 18:33:39 UTC",
    "updated_date": "2024-11-07 03:22:56 UTC"
  },
  {
    "arxiv_id": "2411.00126v1",
    "title": "Training and Evaluating Causal Forecasting Models for Time-Series",
    "authors": [
      "Thomas Crasson",
      "Yacine Nabet",
      "Mathias LÃ©cuyer"
    ],
    "abstract": "Deep learning time-series models are often used to make forecasts that inform\ndownstream decisions. Since these decisions can differ from those in the\ntraining set, there is an implicit requirement that time-series models will\ngeneralize outside of their training distribution. Despite this core\nrequirement, time-series models are typically trained and evaluated on\nin-distribution predictive tasks. We extend the orthogonal statistical learning\nframework to train causal time-series models that generalize better when\nforecasting the effect of actions outside of their training distribution. To\nevaluate these models, we leverage Regression Discontinuity Designs popular in\neconomics to construct a test set of causal treatment effects.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00126v1",
    "published_date": "2024-10-31 18:27:54 UTC",
    "updated_date": "2024-10-31 18:27:54 UTC"
  },
  {
    "arxiv_id": "2411.00121v1",
    "title": "I Can Hear You: Selective Robust Training for Deepfake Audio Detection",
    "authors": [
      "Zirui Zhang",
      "Wei Hao",
      "Aroon Sankoh",
      "William Lin",
      "Emanuel Mendiola-Ortiz",
      "Junfeng Yang",
      "Chengzhi Mao"
    ],
    "abstract": "Recent advances in AI-generated voices have intensified the challenge of\ndetecting deepfake audio, posing risks for scams and the spread of\ndisinformation. To tackle this issue, we establish the largest public voice\ndataset to date, named DeepFakeVox-HQ, comprising 1.3 million samples,\nincluding 270,000 high-quality deepfake samples from 14 diverse sources.\nDespite previously reported high accuracy, existing deepfake voice detectors\nstruggle with our diversely collected dataset, and their detection success\nrates drop even further under realistic corruptions and adversarial attacks. We\nconduct a holistic investigation into factors that enhance model robustness and\nshow that incorporating a diversified set of voice augmentations is beneficial.\nMoreover, we find that the best detection models often rely on high-frequency\nfeatures, which are imperceptible to humans and can be easily manipulated by an\nattacker. To address this, we propose the F-SAT: Frequency-Selective\nAdversarial Training method focusing on high-frequency components. Empirical\nresults demonstrate that using our training dataset boosts baseline model\nperformance (without robust training) by 33%, and our robust training further\nimproves accuracy by 7.7% on clean samples and by 29.3% on corrupted and\nattacked samples, over the state-of-the-art RawNet3 model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00121v1",
    "published_date": "2024-10-31 18:21:36 UTC",
    "updated_date": "2024-10-31 18:21:36 UTC"
  },
  {
    "arxiv_id": "2411.00885v1",
    "title": "Revolutionizing Personalized Cancer Vaccines with NEO: Novel Epitope Optimization Using an Aggregated Feed Forward and Recurrent Neural Network with LSTM Architecture",
    "authors": [
      "Nishanth Basava"
    ],
    "abstract": "As cancer cases continue to rise, with a 2023 study from Zhejiang and Harvard\npredicting a 31 percent increase in cases and a 21 percent increase in deaths\nby 2030, the need to find more effective treatments for cancer is greater than\never before. Traditional approaches to treating cancer, such as chemotherapy,\noften kill healthy cells because of their lack of targetability. In contrast,\npersonalized cancer vaccines can utilize neoepitopes - distinctive peptides on\ncancer cells that are often missed by the body's immune system - that have\nstrong binding affinities to a patient's MHC to provide a more targeted\ntreatment approach. The selection of optimal neoepitopes that elicit an immune\nresponse is a time-consuming and costly process due to the required inputs of\nmodern predictive methods. This project aims to facilitate faster, cheaper, and\nmore accurate neoepitope binding predictions using Feed Forward Neural Networks\n(FFNN) and Recurrent Neural Networks (RNN).\n  To address this, NEO was created. NEO requires next-generation sequencing\ndata and uses a stacking ensemble method by calculating scores from\nstate-of-the-art models (MHCFlurry 1.6, NetMHCstabpan 1.0, and IEDB). The\nmodel's architecture includes an FFNN and an RNN with LSTM layers capable of\nanalyzing both sequential and non-sequential data. The results from both models\nare aggregated to produce predictions. Using this model, personalized cancer\nvaccines can be produced with improved results (AUC = 0.9166, recall = 91.67\npercent).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00885v1",
    "published_date": "2024-10-31 18:11:57 UTC",
    "updated_date": "2024-10-31 18:11:57 UTC"
  },
  {
    "arxiv_id": "2411.00114v1",
    "title": "Project Sid: Many-agent simulations toward AI civilization",
    "authors": [
      "Altera. AL",
      "Andrew Ahn",
      "Nic Becker",
      "Stephanie Carroll",
      "Nico Christie",
      "Manuel Cortes",
      "Arda Demirci",
      "Melissa Du",
      "Frankie Li",
      "Shuying Luo",
      "Peter Y Wang",
      "Mathew Willows",
      "Feitong Yang",
      "Guangyu Robert Yang"
    ],
    "abstract": "AI agents have been evaluated in isolation or within small groups, where\ninteractions remain limited in scope and complexity. Large-scale simulations\ninvolving many autonomous agents -- reflecting the full spectrum of\ncivilizational processes -- have yet to be explored. Here, we demonstrate how\n10 - 1000+ AI agents behave and progress within agent societies. We first\nintroduce the PIANO (Parallel Information Aggregation via Neural Orchestration)\narchitecture, which enables agents to interact with humans and other agents in\nreal-time while maintaining coherence across multiple output streams. We then\nevaluate agent performance in agent simulations using civilizational benchmarks\ninspired by human history. These simulations, set within a Minecraft\nenvironment, reveal that agents are capable of meaningful progress --\nautonomously developing specialized roles, adhering to and changing collective\nrules, and engaging in cultural and religious transmission. These preliminary\nresults show that agents can achieve significant milestones towards AI\ncivilizations, opening new avenues for large simulations, agentic\norganizational intelligence, and integrating AI into human civilizations.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00114v1",
    "published_date": "2024-10-31 18:11:22 UTC",
    "updated_date": "2024-10-31 18:11:22 UTC"
  },
  {
    "arxiv_id": "2411.00109v2",
    "title": "Prospective Learning: Learning for a Dynamic Future",
    "authors": [
      "Ashwin De Silva",
      "Rahul Ramesh",
      "Rubing Yang",
      "Siyu Yu",
      "Joshua T Vogelstein",
      "Pratik Chaudhari"
    ],
    "abstract": "In real-world applications, the distribution of the data, and our goals,\nevolve over time. The prevailing theoretical framework for studying machine\nlearning, namely probably approximately correct (PAC) learning, largely ignores\ntime. As a consequence, existing strategies to address the dynamic nature of\ndata and goals exhibit poor real-world performance. This paper develops a\ntheoretical framework called \"Prospective Learning\" that is tailored for\nsituations when the optimal hypothesis changes over time. In PAC learning,\nempirical risk minimization (ERM) is known to be consistent. We develop a\nlearner called Prospective ERM, which returns a sequence of predictors that\nmake predictions on future data. We prove that the risk of prospective ERM\nconverges to the Bayes risk under certain assumptions on the stochastic process\ngenerating the data. Prospective ERM, roughly speaking, incorporates time as an\ninput in addition to the data. We show that standard ERM as done in PAC\nlearning, without incorporating time, can result in failure to learn when\ndistributions are dynamic. Numerical experiments illustrate that prospective\nERM can learn synthetic and visual recognition problems constructed from MNIST\nand CIFAR-10. Code at https://github.com/neurodata/prolearn.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00109v2",
    "published_date": "2024-10-31 18:03:17 UTC",
    "updated_date": "2025-01-30 14:36:04 UTC"
  },
  {
    "arxiv_id": "2410.24220v1",
    "title": "Bridging Geometric States via Geometric Diffusion Bridge",
    "authors": [
      "Shengjie Luo",
      "Yixian Xu",
      "Di He",
      "Shuxin Zheng",
      "Tie-Yan Liu",
      "Liwei Wang"
    ],
    "abstract": "The accurate prediction of geometric state evolution in complex systems is\ncritical for advancing scientific domains such as quantum chemistry and\nmaterial modeling. Traditional experimental and computational methods face\nchallenges in terms of environmental constraints and computational demands,\nwhile current deep learning approaches still fall short in terms of precision\nand generality. In this work, we introduce the Geometric Diffusion Bridge\n(GDB), a novel generative modeling framework that accurately bridges initial\nand target geometric states. GDB leverages a probabilistic approach to evolve\ngeometric state distributions, employing an equivariant diffusion bridge\nderived by a modified version of Doob's $h$-transform for connecting geometric\nstates. This tailored diffusion process is anchored by initial and target\ngeometric states as fixed endpoints and governed by equivariant transition\nkernels. Moreover, trajectory data can be seamlessly leveraged in our GDB\nframework by using a chain of equivariant diffusion bridges, providing a more\ndetailed and accurate characterization of evolution dynamics. Theoretically, we\nconduct a thorough examination to confirm our framework's ability to preserve\njoint distributions of geometric states and capability to completely model the\nunderlying dynamics inducing trajectory distributions with negligible error.\nExperimental evaluations across various real-world scenarios show that GDB\nsurpasses existing state-of-the-art approaches, opening up a new pathway for\naccurately bridging geometric states and tackling crucial scientific challenges\nwith improved accuracy and applicability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 5 tables; NeurIPS 2024 Camera Ready version",
    "pdf_url": "http://arxiv.org/pdf/2410.24220v1",
    "published_date": "2024-10-31 17:59:53 UTC",
    "updated_date": "2024-10-31 17:59:53 UTC"
  },
  {
    "arxiv_id": "2410.24218v1",
    "title": "Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use",
    "authors": [
      "Jiajun Xi",
      "Yinong He",
      "Jianing Yang",
      "Yinpei Dai",
      "Joyce Chai"
    ],
    "abstract": "In real-world scenarios, it is desirable for embodied agents to have the\nability to leverage human language to gain explicit or implicit knowledge for\nlearning tasks. Despite recent progress, most previous approaches adopt simple\nlow-level instructions as language inputs, which may not reflect natural human\ncommunication. It's not clear how to incorporate rich language use to\nfacilitate task learning. To address this question, this paper studies\ndifferent types of language inputs in facilitating reinforcement learning (RL)\nembodied agents. More specifically, we examine how different levels of language\ninformativeness (i.e., feedback on past behaviors and future guidance) and\ndiversity (i.e., variation of language expressions) impact agent learning and\ninference. Our empirical results based on four RL benchmarks demonstrate that\nagents trained with diverse and informative language feedback can achieve\nenhanced generalization and fast adaptation to new tasks. These findings\nhighlight the pivotal role of language use in teaching embodied agents new\ntasks in an open world. Project website:\nhttps://github.com/sled-group/Teachable_RL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main. Project website:\n  https://github.com/sled-group/Teachable_RL",
    "pdf_url": "http://arxiv.org/pdf/2410.24218v1",
    "published_date": "2024-10-31 17:59:52 UTC",
    "updated_date": "2024-10-31 17:59:52 UTC"
  },
  {
    "arxiv_id": "2410.24206v1",
    "title": "Understanding Optimization in Deep Learning with Central Flows",
    "authors": [
      "Jeremy M. Cohen",
      "Alex Damian",
      "Ameet Talwalkar",
      "Zico Kolter",
      "Jason D. Lee"
    ],
    "abstract": "Optimization in deep learning remains poorly understood, even in the simple\nsetting of deterministic (i.e. full-batch) training. A key difficulty is that\nmuch of an optimizer's behavior is implicitly determined by complex oscillatory\ndynamics, referred to as the \"edge of stability.\" The main contribution of this\npaper is to show that an optimizer's implicit behavior can be explicitly\ncaptured by a \"central flow:\" a differential equation which models the\ntime-averaged optimization trajectory. We show that these flows can empirically\npredict long-term optimization trajectories of generic neural networks with a\nhigh degree of numerical accuracy. By interpreting these flows, we reveal for\nthe first time 1) the precise sense in which RMSProp adapts to the local loss\nlandscape, and 2) an \"acceleration via regularization\" mechanism, wherein\nadaptive optimizers implicitly navigate towards low-curvature regions in which\nthey can take larger steps. This mechanism is key to the efficacy of these\nadaptive optimizers. Overall, we believe that central flows constitute a\npromising tool for reasoning about optimization in deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "first two authors contributed equally; author order determined by\n  coin flip",
    "pdf_url": "http://arxiv.org/pdf/2410.24206v1",
    "published_date": "2024-10-31 17:58:13 UTC",
    "updated_date": "2024-10-31 17:58:13 UTC"
  },
  {
    "arxiv_id": "2410.24205v1",
    "title": "Zonal RL-RRT: Integrated RL-RRT Path Planning with Collision Probability and Zone Connectivity",
    "authors": [
      "AmirMohammad Tahmasbi",
      "MohammadSaleh Faghfoorian",
      "Saeed Khodaygan",
      "Aniket Bera"
    ],
    "abstract": "Path planning in high-dimensional spaces poses significant challenges,\nparticularly in achieving both time efficiency and a fair success rate. To\naddress these issues, we introduce a novel path-planning algorithm, Zonal\nRL-RRT, that leverages kd-tree partitioning to segment the map into zones while\naddressing zone connectivity, ensuring seamless transitions between zones. By\nbreaking down the complex environment into multiple zones and using Q-learning\nas the high-level decision-maker, our algorithm achieves a 3x improvement in\ntime efficiency compared to basic sampling methods such as RRT and RRT* in\nforest-like maps. Our approach outperforms heuristic-guided methods like BIT*\nand Informed RRT* by 1.5x in terms of runtime while maintaining robust and\nreliable success rates across 2D to 6D environments. Compared to learning-based\nmethods like NeuralRRT* and MPNetSMP, as well as the heuristic RRT*J, our\nalgorithm demonstrates, on average, 1.5x better performance in the same\nenvironments. We also evaluate the effectiveness of our approach through\nsimulations of the UR10e arm manipulator in the MuJoCo environment. A key\nobservation of our approach lies in its use of zone partitioning and\nReinforcement Learning (RL) for adaptive high-level planning allowing the\nalgorithm to accommodate flexible policies across diverse environments, making\nit a versatile tool for advanced path planning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24205v1",
    "published_date": "2024-10-31 17:57:51 UTC",
    "updated_date": "2024-10-31 17:57:51 UTC"
  },
  {
    "arxiv_id": "2410.24203v1",
    "title": "DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion",
    "authors": [
      "Weicai Ye",
      "Chenhao Ji",
      "Zheng Chen",
      "Junyao Gao",
      "Xiaoshui Huang",
      "Song-Hai Zhang",
      "Wanli Ouyang",
      "Tong He",
      "Cairong Zhao",
      "Guofeng Zhang"
    ],
    "abstract": "Diffusion-based methods have achieved remarkable achievements in 2D image or\n3D object generation, however, the generation of 3D scenes and even\n$360^{\\circ}$ images remains constrained, due to the limited number of scene\ndatasets, the complexity of 3D scenes themselves, and the difficulty of\ngenerating consistent multi-view images. To address these issues, we first\nestablish a large-scale panoramic video-text dataset containing millions of\nconsecutive panoramic keyframes with corresponding panoramic depths, camera\nposes, and text descriptions. Then, we propose a novel text-driven panoramic\ngeneration framework, termed DiffPano, to achieve scalable, consistent, and\ndiverse panoramic scene generation. Specifically, benefiting from the powerful\ngenerative capabilities of stable diffusion, we fine-tune a single-view\ntext-to-panorama diffusion model with LoRA on the established panoramic\nvideo-text dataset. We further design a spherical epipolar-aware multi-view\ndiffusion model to ensure the multi-view consistency of the generated panoramic\nimages. Extensive experiments demonstrate that DiffPano can generate scalable,\nconsistent, and diverse panoramic images with given unseen text descriptions\nand camera poses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS2024, Project: https://github.com/zju3dv/DiffPano; Code:\n  https://github.com/zju3dv/DiffPano",
    "pdf_url": "http://arxiv.org/pdf/2410.24203v1",
    "published_date": "2024-10-31 17:57:02 UTC",
    "updated_date": "2024-10-31 17:57:02 UTC"
  },
  {
    "arxiv_id": "2410.24200v1",
    "title": "Length-Induced Embedding Collapse in Transformer-based Models",
    "authors": [
      "Yuqi Zhou",
      "Sunhao Dai",
      "Zhanshuo Cao",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Text embeddings enable various applications, but their performance\ndeteriorates on longer texts. In this paper, we find that the performance\ndegradation is due to a phenomenon called Length Collapse, where longer text\nembeddings collapse into a narrow space. This collapse results in a\ndistributional inconsistency between embeddings of different text lengths,\nultimately hurting the performance of downstream tasks. Theoretically, by\nconsidering the self-attention mechanism inherently functions as a low-pass\nfilter, we prove that long sequences increase the attenuation rate of the\nlow-pass filter effect of the self-attention mechanism. With layers going\ndeeper, excessive low-pass filtering causes the token signals to retain only\ntheir Direct-Current (DC) component, which means the input token feature maps\nwill collapse into a narrow space, especially in long texts. Based on the above\nanalysis, we propose to mitigate the undesirable length collapse limitation by\nintroducing a temperature in softmax(), which achieves a higher low-filter\nattenuation rate. The tuning-free method, called TempScale, can be plugged into\nmultiple transformer-based embedding models. Empirically, we demonstrate that\nTempScale can improve existing embedding models, especially on long text\ninputs, bringing up to 0.53% performance gains on 40 datasets from Massive Text\nEmbedding Benchmark (MTEB) and 0.82% performance gains on 4 datasets from\nLongEmbed, which specifically focuses on long context retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24200v1",
    "published_date": "2024-10-31 17:55:36 UTC",
    "updated_date": "2024-10-31 17:55:36 UTC"
  },
  {
    "arxiv_id": "2411.00081v1",
    "title": "PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks",
    "authors": [
      "Matthew Chang",
      "Gunjan Chhablani",
      "Alexander Clegg",
      "Mikael Dallaire Cote",
      "Ruta Desai",
      "Michal Hlavac",
      "Vladimir Karashchuk",
      "Jacob Krantz",
      "Roozbeh Mottaghi",
      "Priyam Parashar",
      "Siddharth Patki",
      "Ishita Prasad",
      "Xavier Puig",
      "Akshara Rai",
      "Ram Ramrakhya",
      "Daniel Tran",
      "Joanne Truong",
      "John M. Turner",
      "Eric Undersander",
      "Tsung-Yen Yang"
    ],
    "abstract": "We present a benchmark for Planning And Reasoning Tasks in humaN-Robot\ncollaboration (PARTNR) designed to study human-robot coordination in household\nactivities. PARTNR tasks exhibit characteristics of everyday tasks, such as\nspatial, temporal, and heterogeneous agent capability constraints. We employ a\nsemi-automated task generation pipeline using Large Language Models (LLMs),\nincorporating simulation in the loop for grounding and verification. PARTNR\nstands as the largest benchmark of its kind, comprising 100,000 natural\nlanguage tasks, spanning 60 houses and 5,819 unique objects. We analyze\nstate-of-the-art LLMs on PARTNR tasks, across the axes of planning, perception\nand skill execution. The analysis reveals significant limitations in SoTA\nmodels, such as poor coordination and failures in task tracking and recovery\nfrom errors. When LLMs are paired with real humans, they require 1.5x as many\nsteps as two humans collaborating and 1.1x more steps than a single human,\nunderscoring the potential for improvement in these models. We further show\nthat fine-tuning smaller LLMs with planning data can achieve performance on par\nwith models 9 times larger, while being 8.6x faster at inference. Overall,\nPARTNR highlights significant challenges facing collaborative embodied agents\nand aims to drive research in this direction.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Alphabetical author order",
    "pdf_url": "http://arxiv.org/pdf/2411.00081v1",
    "published_date": "2024-10-31 17:53:12 UTC",
    "updated_date": "2024-10-31 17:53:12 UTC"
  },
  {
    "arxiv_id": "2410.24187v1",
    "title": "Chasing Better Deep Image Priors between Over- and Under-parameterization",
    "authors": [
      "Qiming Wu",
      "Xiaohan Chen",
      "Yifan Jiang",
      "Zhangyang Wang"
    ],
    "abstract": "Deep Neural Networks (DNNs) are well-known to act as over-parameterized deep\nimage priors (DIP) that regularize various image inverse problems. Meanwhile,\nresearchers also proposed extremely compact, under-parameterized image priors\n(e.g., deep decoder) that are strikingly competent for image restoration too,\ndespite a loss of accuracy. These two extremes push us to think whether there\nexists a better solution in the middle: between over- and under-parameterized\nimage priors, can one identify \"intermediate\" parameterized image priors that\nachieve better trade-offs between performance, efficiency, and even preserving\nstrong transferability? Drawing inspirations from the lottery ticket hypothesis\n(LTH), we conjecture and study a novel \"lottery image prior\" (LIP) by\nexploiting DNN inherent sparsity, stated as: given an over-parameterized\nDNN-based image prior, it will contain a sparse subnetwork that can be trained\nin isolation, to match the original DNN's performance when being applied as a\nprior to various image inverse problems. Our results validate the superiority\nof LIPs: we can successfully locate the LIP subnetworks from over-parameterized\nDIPs at substantial sparsity ranges. Those LIP subnetworks significantly\noutperform deep decoders under comparably compact model sizes (by often fully\npreserving the effectiveness of their over-parameterized counterparts), and\nthey also possess high transferability across different images as well as\nrestoration task types. Besides, we also extend LIP to compressive sensing\nimage reconstruction, where a pre-trained GAN generator is used as the prior\n(in contrast to untrained DIP or deep decoder), and confirm its validity in\nthis setting too. To our best knowledge, this is the first time that LTH is\ndemonstrated to be relevant in the context of inverse problems or image priors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Codes are available at\n  https://github.com/VITA-Group/Chasing-Better-DIPs",
    "pdf_url": "http://arxiv.org/pdf/2410.24187v1",
    "published_date": "2024-10-31 17:49:44 UTC",
    "updated_date": "2024-10-31 17:49:44 UTC"
  },
  {
    "arxiv_id": "2410.24185v2",
    "title": "DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning",
    "authors": [
      "Zhenyu Jiang",
      "Yuqi Xie",
      "Kevin Lin",
      "Zhenjia Xu",
      "Weikang Wan",
      "Ajay Mandlekar",
      "Linxi Fan",
      "Yuke Zhu"
    ],
    "abstract": "Imitation learning from human demonstrations is an effective means to teach\nrobots manipulation skills. But data acquisition is a major bottleneck in\napplying this paradigm more broadly, due to the amount of cost and human effort\ninvolved. There has been significant interest in imitation learning for\nbimanual dexterous robots, like humanoids. Unfortunately, data collection is\neven more challenging here due to the challenges of simultaneously controlling\nmultiple arms and multi-fingered hands. Automated data generation in simulation\nis a compelling, scalable alternative to fuel this need for data. To this end,\nwe introduce DexMimicGen, a large-scale automated data generation system that\nsynthesizes trajectories from a handful of human demonstrations for humanoid\nrobots with dexterous hands. We present a collection of simulation environments\nin the setting of bimanual dexterous manipulation, spanning a range of\nmanipulation behaviors and different requirements for coordination among the\ntwo arms. We generate 21K demos across these tasks from just 60 source human\ndemos and study the effect of several data generation and policy learning\ndecisions on agent performance. Finally, we present a real-to-sim-to-real\npipeline and deploy it on a real-world humanoid can sorting task. Generated\ndatasets, simulation environments and additional results are at\nhttps://dexmimicgen.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2025. Project website: https://dexmimicgen.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.24185v2",
    "published_date": "2024-10-31 17:48:45 UTC",
    "updated_date": "2025-03-06 05:34:17 UTC"
  },
  {
    "arxiv_id": "2410.24175v2",
    "title": "Constraint Back-translation Improves Complex Instruction Following of Large Language Models",
    "authors": [
      "Yunjia Qi",
      "Hao Peng",
      "Xiaozhi Wang",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Large language models (LLMs) struggle to follow instructions with complex\nconstraints in format, length, etc. Following the conventional\ninstruction-tuning practice, previous works conduct post-training on complex\ninstruction-response pairs generated by feeding complex instructions to\nadvanced LLMs. However, even advanced LLMs cannot follow complex instructions\nwell, thus limiting the quality of generated data. In this work, we find that\nexisting datasets inherently contain implicit complex constraints and propose a\nnovel data generation technique, constraint back-translation. Specifically, we\ntake the high-quality instruction-response pairs in existing datasets and only\nadopt advanced LLMs to add complex constraints already met by the responses to\nthe instructions, which naturally reduces costs and data noise. In the\nexperiments, we adopt Llama3-70B-Instruct to back-translate constraints and\ncreate a high-quality complex instruction-response dataset, named CRAB. We\npresent that post-training on CRAB improves multiple backbone LLMs' complex\ninstruction-following ability, evaluated on extensive instruction-following\nbenchmarks. We further find that constraint back-translation also serves as a\nuseful auxiliary training objective in post-training. Our code, data, and\nmodels will be released to facilitate future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.24175v2",
    "published_date": "2024-10-31 17:42:26 UTC",
    "updated_date": "2025-04-29 15:38:34 UTC"
  },
  {
    "arxiv_id": "2411.02429v1",
    "title": "IdeaBench: Benchmarking Large Language Models for Research Idea Generation",
    "authors": [
      "Sikun Guo",
      "Amir Hassan Shariatmadari",
      "Guangzhi Xiong",
      "Albert Huang",
      "Eric Xie",
      "Stefan Bekiranov",
      "Aidong Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have transformed how people interact with\nartificial intelligence (AI) systems, achieving state-of-the-art results in\nvarious tasks, including scientific discovery and hypothesis generation.\nHowever, the lack of a comprehensive and systematic evaluation framework for\ngenerating research ideas using LLMs poses a significant obstacle to\nunderstanding and assessing their generative capabilities in scientific\ndiscovery. To address this gap, we propose IdeaBench, a benchmark system that\nincludes a comprehensive dataset and an evaluation framework for standardizing\nthe assessment of research idea generation using LLMs. Our dataset comprises\ntitles and abstracts from a diverse range of influential papers, along with\ntheir referenced works. To emulate the human process of generating research\nideas, we profile LLMs as domain-specific researchers and ground them in the\nsame context considered by human researchers. This maximizes the utilization of\nthe LLMs' parametric knowledge to dynamically generate new research ideas. We\nalso introduce an evaluation framework for assessing the quality of generated\nresearch ideas. Our evaluation framework is a two-stage process: first, using\nGPT-4o to rank ideas based on user-specified quality indicators such as novelty\nand feasibility, enabling scalable personalization; and second, calculating\nrelative ranking based \"Insight Score\" to quantify the chosen quality\nindicator. The proposed benchmark system will be a valuable asset for the\ncommunity to measure and compare different LLMs, ultimately advancing the\nautomation of the scientific discovery process.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02429v1",
    "published_date": "2024-10-31 17:04:59 UTC",
    "updated_date": "2024-10-31 17:04:59 UTC"
  },
  {
    "arxiv_id": "2411.00078v1",
    "title": "How Good Are We? Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment",
    "authors": [
      "Junlin Guo",
      "Siqi Lu",
      "Can Cui",
      "Ruining Deng",
      "Tianyuan Yao",
      "Zhewen Tao",
      "Yizhe Lin",
      "Marilyn Lionts",
      "Quan Liu",
      "Juming Xiong",
      "Yu Wang",
      "Shilin Zhao",
      "Catie Chang",
      "Mitchell Wilkes",
      "Mengmeng Yin",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "abstract": "Training AI foundation models has emerged as a promising large-scale learning\napproach for addressing real-world healthcare challenges, including digital\npathology. While many of these models have been developed for tasks like\ndisease diagnosis and tissue quantification using extensive and diverse\ntraining datasets, their readiness for deployment on some arguably simplest\ntasks, such as nuclei segmentation within a single organ (e.g., the kidney),\nremains uncertain. This paper seeks to answer this key question, \"How good are\nwe?\", by thoroughly evaluating the performance of recent cell foundation models\non a curated multi-center, multi-disease, and multi-species external testing\ndataset. Additionally, we tackle a more challenging question, \"How can we\nimprove?\", by developing and assessing human-in-the-loop data enrichment\nstrategies aimed at enhancing model performance while minimizing the reliance\non pixel-level human annotation. To address the first question, we curated a\nmulticenter, multidisease, and multispecies dataset consisting of 2,542 kidney\nwhole slide images (WSIs). Three state-of-the-art (SOTA) cell foundation\nmodels-Cellpose, StarDist, and CellViT-were selected for evaluation. To tackle\nthe second question, we explored data enrichment algorithms by distilling\npredictions from the different foundation models with a human-in-the-loop\nframework, aiming to further enhance foundation model performance with minimal\nhuman efforts. Our experimental results showed that all three foundation models\nimproved over their baselines with model fine-tuning with enriched data.\nInterestingly, the baseline model with the highest F1 score does not yield the\nbest segmentation outcomes after fine-tuning. This study establishes a\nbenchmark for the development and deployment of cell vision foundation models\ntailored for real-world data applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00078v1",
    "published_date": "2024-10-31 17:00:33 UTC",
    "updated_date": "2024-10-31 17:00:33 UTC"
  },
  {
    "arxiv_id": "2410.24119v2",
    "title": "Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing",
    "authors": [
      "Akash Dhruv",
      "Anshu Dubey"
    ],
    "abstract": "The emergence of foundational models and generative artificial intelligence\n(GenAI) is poised to transform productivity in scientific computing, especially\nin code development, refactoring, and translating from one programming language\nto another. However, because the output of GenAI cannot be guaranteed to be\ncorrect, manual intervention remains necessary. Some of this intervention can\nbe automated through task-specific tools, alongside additional methodologies\nfor correctness verification and effective prompt development. We explored the\napplication of GenAI in assisting with code translation, language\ninteroperability, and codebase inspection within a legacy Fortran codebase used\nto simulate particle interactions at the Large Hadron Collider (LHC). In the\nprocess, we developed a tool, CodeScribe, which combines prompt engineering\nwith user supervision to establish an efficient process for code conversion. In\nthis paper, we demonstrate how CodeScribe assists in converting Fortran code to\nC++, generating Fortran-C APIs for integrating legacy systems with modern C++\nlibraries, and providing developer support for code organization and algorithm\nimplementation. We also address the challenges of AI-driven code translation\nand highlight its benefits for enhancing productivity in scientific computing\nworkflows.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24119v2",
    "published_date": "2024-10-31 16:48:41 UTC",
    "updated_date": "2025-03-17 02:38:43 UTC"
  },
  {
    "arxiv_id": "2410.24116v1",
    "title": "AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization",
    "authors": [
      "Amir Kazemi",
      "Qurat ul ain Fatima",
      "Volodymyr Kindratenko",
      "Christopher Tessum"
    ],
    "abstract": "Image labeling is a critical bottleneck in the development of computer vision\ntechnologies, often constraining the potential of machine learning models due\nto the time-intensive nature of manual annotations. This work introduces a\nnovel approach that leverages outpainting to address the problem of annotated\ndata scarcity by generating artificial contexts and annotations, significantly\nreducing manual labeling efforts. We apply this technique to a particularly\nacute challenge in autonomous driving, urban planning, and environmental\nmonitoring: the lack of diverse, eye-level vehicle images in desired classes.\nOur dataset comprises AI-generated vehicle images obtained by detecting and\ncropping vehicles from manually selected seed images, which are then outpainted\nonto larger canvases to simulate varied real-world conditions. The outpainted\nimages include detailed annotations, providing high-quality ground truth data.\nAdvanced outpainting techniques and image quality assessments ensure visual\nfidelity and contextual relevance. Augmentation with outpainted vehicles\nimproves overall performance metrics by up to 8\\% and enhances prediction of\nunderrepresented classes by up to 20\\%. This approach, exemplifying outpainting\nas a self-annotating paradigm, presents a solution that enhances dataset\nversatility across multiple domains of machine learning. The code and links to\ndatasets used in this study are available for further research and replication\nat https://github.com/amir-kazemi/aidovecl.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T01, 68T45, 68U01, 68U10",
      "I.2.10; I.3.3; I.4.8; I.5.4"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.24116v1",
    "published_date": "2024-10-31 16:46:23 UTC",
    "updated_date": "2024-10-31 16:46:23 UTC"
  },
  {
    "arxiv_id": "2410.24114v1",
    "title": "Nearest Neighbor Normalization Improves Multimodal Retrieval",
    "authors": [
      "Neil Chowdhury",
      "Franklin Wang",
      "Sumedh Shenoy",
      "Douwe Kiela",
      "Sarah Schwettmann",
      "Tristan Thrush"
    ],
    "abstract": "Multimodal models leverage large-scale pre-training to achieve strong but\nstill imperfect performance on tasks such as image captioning, visual question\nanswering, and cross-modal retrieval. In this paper, we present a simple and\nefficient method for correcting errors in trained contrastive image-text\nretrieval models with no additional training, called Nearest Neighbor\nNormalization (NNN). We show an improvement on retrieval metrics in both text\nretrieval and image retrieval for all of the contrastive models that we tested\n(CLIP, BLIP, ALBEF, SigLIP, BEiT) and for both of the datasets that we used\n(MS-COCO and Flickr30k). NNN requires a reference database, but does not\nrequire any training on this database, and can even increase the retrieval\naccuracy of a model after finetuning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24114v1",
    "published_date": "2024-10-31 16:44:10 UTC",
    "updated_date": "2024-10-31 16:44:10 UTC"
  },
  {
    "arxiv_id": "2410.24108v1",
    "title": "Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers",
    "authors": [
      "Kai Yan",
      "Alexander G. Schwing",
      "Yu-Xiong Wang"
    ],
    "abstract": "Decision Transformers have recently emerged as a new and compelling paradigm\nfor offline Reinforcement Learning (RL), completing a trajectory in an\nautoregressive way. While improvements have been made to overcome initial\nshortcomings, online finetuning of decision transformers has been surprisingly\nunder-explored. The widely adopted state-of-the-art Online Decision Transformer\n(ODT) still struggles when pretrained with low-reward offline data. In this\npaper, we theoretically analyze the online-finetuning of the decision\ntransformer, showing that the commonly used Return-To-Go (RTG) that's far from\nthe expected return hampers the online fine-tuning process. This problem,\nhowever, is well-addressed by the value function and advantage of standard RL\nalgorithms. As suggested by our analysis, in our experiments, we hence find\nthat simply adding TD3 gradients to the finetuning process of ODT effectively\nimproves the online finetuning performance of ODT, especially if ODT is\npretrained with low-reward offline data. These findings provide new directions\nto further improve decision transformers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as NeurIPS 2024 spotlight. 33 pages, 26 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.24108v1",
    "published_date": "2024-10-31 16:38:51 UTC",
    "updated_date": "2024-10-31 16:38:51 UTC"
  },
  {
    "arxiv_id": "2411.00074v1",
    "title": "RPS: A Generic Reservoir Patterns Sampler",
    "authors": [
      "Lamine Diop",
      "Marc Plantevit",
      "Arnaud Soulet"
    ],
    "abstract": "Efficient learning from streaming data is important for modern data analysis\ndue to the continuous and rapid evolution of data streams. Despite significant\nadvancements in stream pattern mining, challenges persist, particularly in\nmanaging complex data streams like sequential and weighted itemsets. While\nreservoir sampling serves as a fundamental method for randomly selecting\nfixed-size samples from data streams, its application to such complex patterns\nremains largely unexplored. In this study, we introduce an approach that\nharnesses a weighted reservoir to facilitate direct pattern sampling from\nstreaming batch data, thus ensuring scalability and efficiency. We present a\ngeneric algorithm capable of addressing temporal biases and handling various\npattern types, including sequential, weighted, and unweighted itemsets. Through\ncomprehensive experiments conducted on real-world datasets, we evaluate the\neffectiveness of our method, showcasing its ability to construct accurate\nincremental online classifiers for sequential data. Our approach not only\nenables previously unusable online machine learning models for sequential data\nto achieve accuracy comparable to offline baselines but also represents\nsignificant progress in the development of incremental online sequential\nitemset classifiers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CO",
      "math.PR",
      "60: Probability theory",
      "G.3; E.1; E.2; F.2"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at 2024 IEEE International Conference on Big Data",
    "pdf_url": "http://arxiv.org/pdf/2411.00074v1",
    "published_date": "2024-10-31 16:25:21 UTC",
    "updated_date": "2024-10-31 16:25:21 UTC"
  },
  {
    "arxiv_id": "2410.24091v2",
    "title": "3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing",
    "authors": [
      "Binghao Huang",
      "Yixuan Wang",
      "Xinyi Yang",
      "Yiyue Luo",
      "Yunzhu Li"
    ],
    "abstract": "Tactile and visual perception are both crucial for humans to perform\nfine-grained interactions with their environment. Developing similar\nmulti-modal sensing capabilities for robots can significantly enhance and\nexpand their manipulation skills. This paper introduces \\textbf{3D-ViTac}, a\nmulti-modal sensing and learning system designed for dexterous bimanual\nmanipulation. Our system features tactile sensors equipped with dense sensing\nunits, each covering an area of 3$mm^2$. These sensors are low-cost and\nflexible, providing detailed and extensive coverage of physical contacts,\neffectively complementing visual information. To integrate tactile and visual\ndata, we fuse them into a unified 3D representation space that preserves their\n3D structures and spatial relationships. The multi-modal representation can\nthen be coupled with diffusion policies for imitation learning. Through\nconcrete hardware experiments, we demonstrate that even low-cost robots can\nperform precise manipulations and significantly outperform vision-only\npolicies, particularly in safe interactions with fragile items and executing\nlong-horizon tasks involving in-hand manipulation. Our project page is\navailable at \\url{https://binghao-huang.github.io/3D-ViTac/}.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at Conference on Robot Learning (CoRL) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.24091v2",
    "published_date": "2024-10-31 16:22:53 UTC",
    "updated_date": "2025-01-06 22:23:50 UTC"
  },
  {
    "arxiv_id": "2411.00073v2",
    "title": "RSL-SQL: Robust Schema Linking in Text-to-SQL Generation",
    "authors": [
      "Zhenbiao Cao",
      "Yuanlei Zheng",
      "Zhihao Fan",
      "Xiaojin Zhang",
      "Wei Chen",
      "Xiang Bai"
    ],
    "abstract": "Text-to-SQL generation aims to translate natural language questions into SQL\nstatements. In Text-to-SQL based on large language models, schema linking is a\nwidely adopted strategy to streamline the input for LLMs by selecting only\nrelevant schema elements, therefore reducing noise and computational overhead.\nHowever, schema linking faces risks that require caution, including the\npotential omission of necessary elements and disruption of database structural\nintegrity. To address these challenges, we propose a novel framework called\nRSL-SQL that combines bidirectional schema linking, contextual information\naugmentation, binary selection strategy, and multi-turn self-correction. We\nimprove the recall of pattern linking using forward and backward pruning\nmethods, achieving a strict recall of 94% while reducing the number of input\ncolumns by 83%. Furthermore, it hedges the risk by voting between a full mode\nand a simplified mode enhanced with contextual information. Experiments on the\nBIRD and Spider benchmarks demonstrate that our approach achieves SOTA\nexecution accuracy among open-source solutions, with 67.2% on BIRD and 87.9% on\nSpider using GPT-4o. Furthermore, our approach outperforms a series of GPT-4\nbased Text-to-SQL systems when adopting DeepSeek (much cheaper) with same\nintact prompts. Extensive analysis and ablation studies confirm the\neffectiveness of each component in our framework. The codes are available at\nhttps://github.com/Laqcce-cao/RSL-SQL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00073v2",
    "published_date": "2024-10-31 16:22:26 UTC",
    "updated_date": "2024-11-26 13:55:29 UTC"
  },
  {
    "arxiv_id": "2410.24087v1",
    "title": "In-Context Fine-Tuning for Time-Series Foundation Models",
    "authors": [
      "Abhimanyu Das",
      "Matthew Faw",
      "Rajat Sen",
      "Yichen Zhou"
    ],
    "abstract": "Motivated by the recent success of time-series foundation models for\nzero-shot forecasting, we present a methodology for $\\textit{in-context\nfine-tuning}$ of a time-series foundation model. In particular, we design a\npretrained foundation model that can be prompted (at inference time) with\nmultiple time-series examples, in order to forecast a target time-series into\nthe future. Our foundation model is specifically trained to utilize examples\nfrom multiple related time-series in its context window (in addition to the\nhistory of the target time-series) to help it adapt to the specific\ndistribution of the target domain at inference time. We show that such a\nfoundation model that uses in-context examples at inference time can obtain\nmuch better performance on popular forecasting benchmarks compared to\nsupervised deep learning methods, statistical models, as well as other\ntime-series foundation models. Interestingly, our in-context fine-tuning\napproach even rivals the performance of a foundation model that is explicitly\nfine-tuned on the target domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24087v1",
    "published_date": "2024-10-31 16:20:04 UTC",
    "updated_date": "2024-10-31 16:20:04 UTC"
  },
  {
    "arxiv_id": "2410.24080v2",
    "title": "Graph Learning for Numeric Planning",
    "authors": [
      "Dillon Z. Chen",
      "Sylvie ThiÃ©baux"
    ],
    "abstract": "Graph learning is naturally well suited for use in symbolic, object-centric\nplanning due to its ability to exploit relational structures exhibited in\nplanning domains and to take as input planning instances with arbitrary numbers\nof objects. Numeric planning is an extension of symbolic planning in which\nstates may now also exhibit numeric variables. In this work, we propose\ndata-efficient and interpretable machine learning models for learning to solve\nnumeric planning tasks. This involves constructing a new graph kernel for\ngraphs with both continuous and categorical attributes, as well as new\noptimisation methods for learning heuristic functions for numeric planning.\nExperiments show that our graph kernels are vastly more efficient and\ngeneralise better than graph neural networks for numeric planning, and also\nyield competitive coverage performance compared to domain-independent numeric\nplanners. Code is available at https://github.com/DillonZChen/goose",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of NeurIPS 2024 paper",
    "pdf_url": "http://arxiv.org/pdf/2410.24080v2",
    "published_date": "2024-10-31 16:16:51 UTC",
    "updated_date": "2025-01-07 03:33:00 UTC"
  },
  {
    "arxiv_id": "2411.10454v1",
    "title": "Biotic Browser: Applying StreamingLLM as a Persistent Web Browsing Co-Pilot",
    "authors": [
      "Kevin F. Dunnell",
      "Andrew P. Stoddard"
    ],
    "abstract": "This paper presents \"Biotic Browser,\" an innovative AI assistant leveraging\nStreamingLLM to transform web navigation and task execution. Characterized by\nits ability to simulate the experience of a passenger in an autonomous vehicle,\nthe Biotic Browser excels in managing extended interactions and complex,\nmulti-step web-based tasks. It marks a significant advancement in AI\ntechnology, particularly in the realm of long-term context management, and\noffers promising applications for enhancing productivity and efficiency in both\npersonal and professional settings.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Written December 2023",
    "pdf_url": "http://arxiv.org/pdf/2411.10454v1",
    "published_date": "2024-10-31 16:12:02 UTC",
    "updated_date": "2024-10-31 16:12:02 UTC"
  },
  {
    "arxiv_id": "2410.24070v4",
    "title": "Dynamical similarity analysis can identify compositional dynamics developing in RNNs",
    "authors": [
      "Quentin Guilhot",
      "MichaÅ WÃ³jcik",
      "Jascha Achterberg",
      "Rui Ponte Costa"
    ],
    "abstract": "Methods for analyzing representations in neural systems have become a popular\ntool in both neuroscience and mechanistic interpretability. Having measures to\ncompare how similar activations of neurons are across conditions,\narchitectures, and species, gives us a scalable way of learning how information\nis transformed within different neural networks. In contrast to this trend,\nrecent investigations have revealed how some metrics can respond to spurious\nsignals and hence give misleading results. To identify the most reliable metric\nand understand how measures could be improved, it is going to be important to\nidentify specific test cases which can serve as benchmarks. Here we propose\nthat the phenomena of compositional learning in recurrent neural networks\n(RNNs) allows us to build a test case for dynamical representation alignment\nmetrics. By implementing this case, we show it enables us to test whether\nmetrics can identify representations which gradually develop throughout\nlearning and probe whether representations identified by metrics are relevant\nto computations executed by networks. By building both an attractor- and\nRNN-based test case, we show that the new Dynamical Similarity Analysis (DSA)\nis more noise robust and identifies behaviorally relevant representations more\nreliably than prior metrics (Procrustes, CKA). We also show how test cases can\nbe used beyond evaluating metrics to study new architectures. Specifically,\nresults from applying DSA to modern (Mamba) state space models, suggest that,\nin contrast to RNNs, these models may not exhibit changes to their recurrent\ndynamics due to their expressiveness. Overall, by developing test cases, we\nshow DSA's exceptional ability to detect compositional dynamical motifs,\nthereby enhancing our understanding of how computations unfold in RNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.24070v4",
    "published_date": "2024-10-31 16:07:21 UTC",
    "updated_date": "2024-12-21 17:53:26 UTC"
  },
  {
    "arxiv_id": "2410.24059v2",
    "title": "Identifying General Mechanism Shifts in Linear Causal Representations",
    "authors": [
      "Tianyu Chen",
      "Kevin Bello",
      "Francesco Locatello",
      "Bryon Aragam",
      "Pradeep Ravikumar"
    ],
    "abstract": "We consider the linear causal representation learning setting where we\nobserve a linear mixing of $d$ unknown latent factors, which follow a linear\nstructural causal model. Recent work has shown that it is possible to recover\nthe latent factors as well as the underlying structural causal model over them,\nup to permutation and scaling, provided that we have at least $d$ environments,\neach of which corresponds to perfect interventions on a single latent node\n(factor). After this powerful result, a key open problem faced by the community\nhas been to relax these conditions: allow for coarser than perfect single-node\ninterventions, and allow for fewer than $d$ of them, since the number of latent\nfactors $d$ could be very large. In this work, we consider precisely such a\nsetting, where we allow a smaller than $d$ number of environments, and also\nallow for very coarse interventions that can very coarsely \\textit{change the\nentire causal graph over the latent factors}. On the flip side, we relax what\nwe wish to extract to simply the \\textit{list of nodes that have shifted\nbetween one or more environments}. We provide a surprising identifiability\nresult that it is indeed possible, under some very mild standard assumptions,\nto identify the set of shifted nodes. Our identifiability proof moreover is a\nconstructive one: we explicitly provide necessary and sufficient conditions for\na node to be a shifted node, and show that we can check these conditions given\nobserved data. Our algorithm lends itself very naturally to the sample setting\nwhere instead of just interventional distributions, we are provided datasets of\nsamples from each of these distributions. We corroborate our results on both\nsynthetic experiments as well as an interesting psychometric dataset. The code\ncan be found at https://github.com/TianyuCodings/iLCS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.24059v2",
    "published_date": "2024-10-31 15:56:50 UTC",
    "updated_date": "2024-11-02 02:52:26 UTC"
  },
  {
    "arxiv_id": "2410.24035v1",
    "title": "State- and context-dependent robotic manipulation and grasping via uncertainty-aware imitation learning",
    "authors": [
      "Tim R. Winter",
      "Ashok M. Sundaram",
      "Werner Friedl",
      "Maximo A. Roa",
      "Freek Stulp",
      "JoÃ£o SilvÃ©rio"
    ],
    "abstract": "Generating context-adaptive manipulation and grasping actions is a\nchallenging problem in robotics. Classical planning and control algorithms tend\nto be inflexible with regard to parameterization by external variables such as\nobject shapes. In contrast, Learning from Demonstration (LfD) approaches, due\nto their nature as function approximators, allow for introducing external\nvariables to modulate policies in response to the environment. In this paper,\nwe utilize this property by introducing an LfD approach to acquire\ncontext-dependent grasping and manipulation strategies. We treat the problem as\na kernel-based function approximation, where the kernel inputs include generic\ncontext variables describing task-dependent parameters such as the object\nshape. We build on existing work on policy fusion with uncertainty\nquantification to propose a state-dependent approach that automatically returns\nto demonstrations, avoiding unpredictable behavior while smoothly adapting to\ncontext changes. The approach is evaluated against the LASA handwriting dataset\nand on a real 7-DoF robot in two scenarios: adaptation to slippage while\ngrasping and manipulating a deformable food item.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24035v1",
    "published_date": "2024-10-31 15:32:32 UTC",
    "updated_date": "2024-10-31 15:32:32 UTC"
  },
  {
    "arxiv_id": "2411.00069v1",
    "title": "Meta-Sealing: A Revolutionizing Integrity Assurance Protocol for Transparent, Tamper-Proof, and Trustworthy AI System",
    "authors": [
      "Mahesh Vaijainthymala Krishnamoorthy"
    ],
    "abstract": "The Artificial intelligence in critical sectors-healthcare, finance, and\npublic safety-has made system integrity paramount for maintaining societal\ntrust. Current verification methods for AI systems lack comprehensive lifecycle\nassurance, creating significant vulnerabilities in deployment of both powerful\nand trustworthy AI. This research introduces Meta-Sealing, a cryptographic\nframework that fundamentally changes integrity verification in AI systems\nthroughout their operational lifetime. Meta-Sealing surpasses traditional\nintegrity protocols through its implementation of cryptographic seal chains,\nestablishing verifiable, immutable records for all system decisions and\ntransformations. The framework combines advanced cryptography with distributed\nverification, delivering tamper-evident guarantees that achieve both\nmathematical rigor and computational efficiency. Our implementation addresses\nurgent regulatory requirements for AI system transparency and auditability. The\nframework integrates with current AI governance standards, specifically the\nEU's AI Act and FDA's healthcare AI guidelines, enabling organizations to\nmaintain operational efficiency while meeting compliance requirements. Testing\non financial institution data demonstrated Meta-Sealing's capability to reduce\naudit timeframes by 62% while enhancing stakeholder confidence by 47%. Results\ncan establish a new benchmark for integrity assurance in enterprise AI\ndeployments. This research presents Meta-Sealing not merely as a technical\nsolution, but as a foundational framework ensuring AI system integrity aligns\nwith human values and regulatory requirements. As AI continues to influence\ncritical decisions, provides the necessary bridge between technological\nadvancement and verifiable trust. Meta-Sealing serves as a guardian of trust,\nensuring that the AI systems we depend on are as reliable and transparent as\nthey are powerful.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 3 figures and 10 Code blocks, to be presented in the\n  conference",
    "pdf_url": "http://arxiv.org/pdf/2411.00069v1",
    "published_date": "2024-10-31 15:31:22 UTC",
    "updated_date": "2024-10-31 15:31:22 UTC"
  },
  {
    "arxiv_id": "2410.24032v1",
    "title": "Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks",
    "authors": [
      "Yingzhe Peng",
      "Xiaoting Qin",
      "Zhiyang Zhang",
      "Jue Zhang",
      "Qingwei Lin",
      "Xu Yang",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "The rise of large language models (LLMs) has revolutionized user interactions\nwith knowledge-based systems, enabling chatbots to synthesize vast amounts of\ninformation and assist with complex, exploratory tasks. However, LLM-based\nchatbots often struggle to provide personalized support, particularly when\nusers start with vague queries or lack sufficient contextual information. This\npaper introduces the Collaborative Assistant for Personalized Exploration\n(CARE), a system designed to enhance personalization in exploratory tasks by\ncombining a multi-agent LLM framework with a structured user interface. CARE's\ninterface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling\niterative query refinement and dynamic solution generation. The multi-agent\nframework collaborates to identify both explicit and implicit user needs,\ndelivering tailored, actionable solutions. In a within-subject user study with\n22 participants, CARE was consistently preferred over a baseline LLM chatbot,\nwith users praising its ability to reduce cognitive load, inspire creativity,\nand provide more tailored solutions. Our findings highlight CARE's potential to\ntransform LLM-based systems from passive information retrievers to proactive\npartners in personalized problem-solving and exploration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24032v1",
    "published_date": "2024-10-31 15:30:55 UTC",
    "updated_date": "2024-10-31 15:30:55 UTC"
  },
  {
    "arxiv_id": "2410.24031v3",
    "title": "A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps",
    "authors": [
      "Ariel Larey",
      "Eyal Rond",
      "Omer Achrack"
    ],
    "abstract": "Face recognition technologies are increasingly used in various applications,\nyet they are vulnerable to face spoofing attacks. These spoofing attacks often\ninvolve unique 3D structures, such as printed papers or mobile device screens.\nAlthough stereo-depth cameras can detect such attacks effectively, their\nhigh-cost limits their widespread adoption. Conversely, two-sensor systems\nwithout extrinsic calibration offer a cost-effective alternative but are unable\nto calculate depth using stereo techniques. In this work, we propose a method\nto overcome this challenge by leveraging facial attributes to derive disparity\ninformation and estimate relative depth for anti-spoofing purposes, using\nnon-calibrated systems. We introduce a multi-modal anti-spoofing model, coined\nDisparity Model, that incorporates created disparity maps as a third modality\nalongside the two original sensor modalities. We demonstrate the effectiveness\nof the Disparity Model in countering various spoof attacks using a\ncomprehensive dataset collected from the Intel RealSense ID Solution F455. Our\nmethod outperformed existing methods in the literature, achieving an Equal\nError Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False\nPositive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the\nerrors of the best comparison method, respectively. Additionally, we introduce\na model ensemble that addresses 3D spoof attacks as well, achieving an EER of\n2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a\nstate-of-the-art solution for the challenging task of anti-spoofing in\nnon-calibrated systems that lack depth information.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24031v3",
    "published_date": "2024-10-31 15:29:51 UTC",
    "updated_date": "2025-01-16 13:20:56 UTC"
  },
  {
    "arxiv_id": "2410.24024v2",
    "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
    "authors": [
      "Yifan Xu",
      "Xiao Liu",
      "Xueqiao Sun",
      "Siyi Cheng",
      "Hao Yu",
      "Hanyu Lai",
      "Shudan Zhang",
      "Dan Zhang",
      "Jie Tang",
      "Yuxiao Dong"
    ],
    "abstract": "Autonomous agents have become increasingly important for interacting with the\nreal world. Android agents, in particular, have been recently a\nfrequently-mentioned interaction method. However, existing studies for training\nand evaluating Android agents lack systematic research on both open-source and\nclosed-source models. In this work, we propose AndroidLab as a systematic\nAndroid agent framework. It includes an operation environment with different\nmodalities, action space, and a reproducible benchmark. It supports both large\nlanguage models (LLMs) and multimodal models (LMMs) in the same action space.\nAndroidLab benchmark includes predefined Android virtual devices and 138 tasks\nacross nine apps built on these devices. By using the AndroidLab environment,\nwe develop an Android Instruction dataset and train six open-source LLMs and\nLMMs, lifting the average success rates from 4.59% to 21.50% for LLMs and from\n1.93% to 13.28% for LMMs. AndroidLab is open-sourced and publicly available at\nhttps://github.com/THUDM/Android-Lab.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24024v2",
    "published_date": "2024-10-31 15:25:20 UTC",
    "updated_date": "2024-11-04 05:57:31 UTC"
  },
  {
    "arxiv_id": "2410.24022v1",
    "title": "SFM-Protein: Integrative Co-evolutionary Pre-training for Advanced Protein Sequence Representation",
    "authors": [
      "Liang He",
      "Peiran Jin",
      "Yaosen Min",
      "Shufang Xie",
      "Lijun Wu",
      "Tao Qin",
      "Xiaozhuan Liang",
      "Kaiyuan Gao",
      "Yuliang Jiang",
      "Tie-Yan Liu"
    ],
    "abstract": "Proteins, essential to biological systems, perform functions intricately\nlinked to their three-dimensional structures. Understanding the relationship\nbetween protein structures and their amino acid sequences remains a core\nchallenge in protein modeling. While traditional protein foundation models\nbenefit from pre-training on vast unlabeled datasets, they often struggle to\ncapture critical co-evolutionary information, which evolutionary-based methods\nexcel at. In this study, we introduce a novel pre-training strategy for protein\nfoundation models that emphasizes the interactions among amino acid residues to\nenhance the extraction of both short-range and long-range co-evolutionary\nfeatures from sequence data. Trained on a large-scale protein sequence dataset,\nour model demonstrates superior generalization ability, outperforming\nestablished baselines of similar size, including the ESM model, across diverse\ndownstream tasks. Experimental results confirm the model's effectiveness in\nintegrating co-evolutionary information, marking a significant step forward in\nprotein sequence-based modeling.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24022v1",
    "published_date": "2024-10-31 15:22:03 UTC",
    "updated_date": "2024-10-31 15:22:03 UTC"
  },
  {
    "arxiv_id": "2410.24017v1",
    "title": "Assessing the Impact of Packing on Machine Learning-Based Malware Detection and Classification Systems",
    "authors": [
      "Daniel Gibert",
      "Nikolaos Totosis",
      "Constantinos Patsakis",
      "Giulio Zizzo",
      "Quan Le"
    ],
    "abstract": "The proliferation of malware, particularly through the use of packing,\npresents a significant challenge to static analysis and signature-based malware\ndetection techniques. The application of packing to the original executable\ncode renders extracting meaningful features and signatures challenging. To deal\nwith the increasing amount of malware in the wild, researchers and anti-malware\ncompanies started harnessing machine learning capabilities with very promising\nresults. However, little is known about the effects of packing on static\nmachine learning-based malware detection and classification systems. This work\naddresses this gap by investigating the impact of packing on the performance of\nstatic machine learning-based models used for malware detection and\nclassification, with a particular focus on those using visualisation\ntechniques. To this end, we present a comprehensive analysis of various packing\ntechniques and their effects on the performance of machine learning-based\ndetectors and classifiers. Our findings highlight the limitations of current\nstatic detection and classification systems and underscore the need to be\nproactive to effectively counteract the evolving tactics of malware authors.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.24017v1",
    "published_date": "2024-10-31 15:19:33 UTC",
    "updated_date": "2024-10-31 15:19:33 UTC"
  },
  {
    "arxiv_id": "2410.23996v2",
    "title": "An Information Criterion for Controlled Disentanglement of Multimodal Data",
    "authors": [
      "Chenyu Wang",
      "Sharut Gupta",
      "Xinyi Zhang",
      "Sana Tonekaboni",
      "Stefanie Jegelka",
      "Tommi Jaakkola",
      "Caroline Uhler"
    ],
    "abstract": "Multimodal representation learning seeks to relate and decompose information\ninherent in multiple modalities. By disentangling modality-specific information\nfrom information that is shared across modalities, we can improve\ninterpretability and robustness and enable downstream tasks such as the\ngeneration of counterfactual outcomes. Separating the two types of information\nis challenging since they are often deeply entangled in many real-world\napplications. We propose Disentangled Self-Supervised Learning\n(DisentangledSSL), a novel self-supervised approach for learning disentangled\nrepresentations. We present a comprehensive analysis of the optimality of each\ndisentangled representation, particularly focusing on the scenario not covered\nin prior work where the so-called Minimum Necessary Information (MNI) point is\nnot attainable. We demonstrate that DisentangledSSL successfully learns shared\nand modality-specific features on multiple synthetic and real-world datasets\nand consistently outperforms baselines on various downstream tasks, including\nprediction tasks for vision-language data, as well as molecule-phenotype\nretrieval tasks for biological data. The code is available at\nhttps://github.com/uhlerlab/DisentangledSSL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.23996v2",
    "published_date": "2024-10-31 14:57:31 UTC",
    "updated_date": "2025-03-17 16:27:27 UTC"
  },
  {
    "arxiv_id": "2410.23991v1",
    "title": "Localization, balance and affinity: a stronger multifaceted collaborative salient object detector in remote sensing images",
    "authors": [
      "Yakun Xie",
      "Suning Liu",
      "Hongyu Chen",
      "Shaohan Cao",
      "Huixin Zhang",
      "Dejun Feng",
      "Qian Wan",
      "Jun Zhu",
      "Qing Zhu"
    ],
    "abstract": "Despite significant advancements in salient object detection(SOD) in optical\nremote sensing images(ORSI), challenges persist due to the intricate edge\nstructures of ORSIs and the complexity of their contextual relationships.\nCurrent deep learning approaches encounter difficulties in accurately\nidentifying boundary features and lack efficiency in collaboratively modeling\nthe foreground and background by leveraging contextual features. To address\nthese challenges, we propose a stronger multifaceted collaborative salient\nobject detector in ORSIs, termed LBA-MCNet, which incorporates aspects of\nlocalization, balance, and affinity. The network focuses on accurately locating\ntargets, balancing detailed features, and modeling image-level global context\ninformation. Specifically, we design the Edge Feature Adaptive Balancing and\nAdjusting(EFABA) module for precise edge localization, using edge features to\nguide attention to boundaries and preserve spatial details. Moreover, we design\nthe Global Distributed Affinity Learning(GDAL) module to model global context.\nIt captures global context by generating an affinity map from the encoders\nfinal layer, ensuring effective modeling of global patterns. Additionally, deep\nsupervision during deconvolution further enhances feature representation.\nFinally, we compared with 28 state of the art approaches on three publicly\navailable datasets. The results clearly demonstrate the superiority of our\nmethod.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23991v1",
    "published_date": "2024-10-31 14:50:48 UTC",
    "updated_date": "2024-10-31 14:50:48 UTC"
  },
  {
    "arxiv_id": "2410.23975v1",
    "title": "Average Controlled and Average Natural Micro Direct Effects in Summary Causal Graphs",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "abstract": "In this paper, we investigate the identifiability of average controlled\ndirect effects and average natural direct effects in causal systems represented\nby summary causal graphs, which are abstractions of full causal graphs, often\nused in dynamic systems where cycles and omitted temporal information\ncomplicate causal inference. Unlike in the traditional linear setting, where\ndirect effects are typically easier to identify and estimate, non-parametric\ndirect effects, which are crucial for handling real-world complexities,\nparticularly in epidemiological contexts where relationships between variables\n(e.g, genetic, environmental, and behavioral factors) are often non-linear, are\nmuch harder to define and identify. In particular, we give sufficient\nconditions for identifying average controlled micro direct effect and average\nnatural micro direct effect from summary causal graphs in the presence of\nhidden confounding. Furthermore, we show that the conditions given for the\naverage controlled micro direct effect become also necessary in the setting\nwhere there is no hidden confounding and where we are only interested in\nidentifiability by adjustment.",
    "categories": [
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23975v1",
    "published_date": "2024-10-31 14:30:33 UTC",
    "updated_date": "2024-10-31 14:30:33 UTC"
  },
  {
    "arxiv_id": "2410.23962v1",
    "title": "Image Synthesis with Class-Aware Semantic Diffusion Models for Surgical Scene Segmentation",
    "authors": [
      "Yihang Zhou",
      "Rebecca Towning",
      "Zaid Awad",
      "Stamatia Giannarou"
    ],
    "abstract": "Surgical scene segmentation is essential for enhancing surgical precision,\nyet it is frequently compromised by the scarcity and imbalance of available\ndata. To address these challenges, semantic image synthesis methods based on\ngenerative adversarial networks and diffusion models have been developed.\nHowever, these models often yield non-diverse images and fail to capture small,\ncritical tissue classes, limiting their effectiveness. In response, we propose\nthe Class-Aware Semantic Diffusion Model (CASDM), a novel approach which\nutilizes segmentation maps as conditions for image synthesis to tackle data\nscarcity and imbalance. Novel class-aware mean squared error and class-aware\nself-perceptual loss functions have been defined to prioritize critical, less\nvisible classes, thereby enhancing image quality and relevance. Furthermore, to\nour knowledge, we are the first to generate multi-class segmentation maps using\ntext prompts in a novel fashion to specify their contents. These maps are then\nused by CASDM to generate surgical scene images, enhancing datasets for\ntraining and validating segmentation models. Our evaluation, which assesses\nboth image quality and downstream segmentation performance, demonstrates the\nstrong effectiveness and generalisability of CASDM in producing realistic\nimage-map pairs, significantly advancing surgical scene segmentation across\ndiverse and challenging datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23962v1",
    "published_date": "2024-10-31 14:14:30 UTC",
    "updated_date": "2024-10-31 14:14:30 UTC"
  },
  {
    "arxiv_id": "2410.23953v3",
    "title": "Representative Social Choice: From Learning Theory to AI Alignment",
    "authors": [
      "Tianyi Qiu"
    ],
    "abstract": "Social choice theory is the study of preference aggregation across a\npopulation, used both in mechanism design for human agents and in the\ndemocratic alignment of language models. In this study, we propose the\nrepresentative social choice framework for the modeling of democratic\nrepresentation in collective decisions, where the number of issues and\nindividuals are too large for mechanisms to consider all preferences directly.\nThese scenarios are widespread in real-world decision-making processes, such as\njury trials, indirect elections, legislation processes, corporate governance,\nand, more recently, language model alignment. In representative social choice,\nthe population is represented by a finite sample of individual-issue pairs\nbased on which social choice decisions are made. We show that many of the\ndeepest questions in representative social choice can be naturally formulated\nas statistical learning problems, and prove the generalization properties of\nsocial choice mechanisms using the theory of machine learning. We further\nformulate axioms for representative social choice, and prove Arrow-like\nimpossibility theorems with new combinatorial tools of analysis. Our framework\nintroduces the representative approach to social choice, opening up research\ndirections at the intersection of social choice, learning theory, and AI\nalignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Full version (20 pages). Under review. Received Best Paper Award at\n  NeurIPS 2024 Pluralistic Alignment Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.23953v3",
    "published_date": "2024-10-31 14:07:26 UTC",
    "updated_date": "2024-12-18 18:41:48 UTC"
  },
  {
    "arxiv_id": "2410.23934v1",
    "title": "Towards Fast Algorithms for the Preference Consistency Problem Based on Hierarchical Models",
    "authors": [
      "Anne-Marie George",
      "Nic Wilson",
      "Barry O'Sullivan"
    ],
    "abstract": "In this paper, we construct and compare algorithmic approaches to solve the\nPreference Consistency Problem for preference statements based on hierarchical\nmodels. Instances of this problem contain a set of preference statements that\nare direct comparisons (strict and non-strict) between some alternatives, and a\nset of evaluation functions by which all alternatives can be rated. An instance\nis consistent based on hierarchical preference models, if there exists an\nhierarchical model on the evaluation functions that induces an order relation\non the alternatives by which all relations given by the preference statements\nare satisfied. Deciding if an instance is consistent is known to be NP-complete\nfor hierarchical models. We develop three approaches to solve this decision\nproblem. The first involves a Mixed Integer Linear Programming (MILP)\nformulation, the other two are recursive algorithms that are based on\nproperties of the problem by which the search space can be pruned. Our\nexperiments on synthetic data show that the recursive algorithms are faster\nthan solving the MILP formulation and that the ratio between the running times\nincreases extremely quickly.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Longer Version of IJCAI'16 publication\n  https://www.ijcai.org/Proceedings/16/Papers/157.pdf",
    "pdf_url": "http://arxiv.org/pdf/2410.23934v1",
    "published_date": "2024-10-31 13:48:46 UTC",
    "updated_date": "2024-10-31 13:48:46 UTC"
  },
  {
    "arxiv_id": "2410.23918v3",
    "title": "BitStack: Any-Size Compression of Large Language Models in Variable Memory Environments",
    "authors": [
      "Xinghao Wang",
      "Pengyu Wang",
      "Bo Wang",
      "Dong Zhang",
      "Yunhua Zhou",
      "Xipeng Qiu"
    ],
    "abstract": "Large language models (LLMs) have revolutionized numerous applications, yet\ntheir deployment remains challenged by memory constraints on local devices.\nWhile scaling laws have enhanced LLM capabilities, the primary bottleneck has\nshifted from \\textit{capability} to \\textit{availability}, emphasizing the need\nfor efficient memory management. Traditional compression methods, such as\nquantization, often require predefined compression ratios and separate\ncompression processes for each setting, complicating deployment in variable\nmemory environments. In this paper, we introduce \\textbf{BitStack}, a novel,\ntraining-free weight compression approach that enables megabyte-level\ntrade-offs between memory usage and model performance. By leveraging weight\ndecomposition, BitStack can dynamically adjust the model size with minimal\ntransmission between running memory and storage devices. Our approach\niteratively decomposes weight matrices while considering the significance of\neach parameter, resulting in an approximately 1-bit per parameter residual\nblock in each decomposition iteration. These blocks are sorted and stacked in\nstorage as basic transmission units, with different quantities loaded based on\ncurrent memory availability. Extensive experiments across a wide range of tasks\ndemonstrate that, despite offering fine-grained size control, BitStack\nconsistently matches or surpasses strong quantization baselines, particularly\nat extreme compression ratios. To the best of our knowledge, this is the first\ndecomposition-based method that effectively bridges the gap to practical\ncompression techniques like quantization. Code is available at\nhttps://github.com/xinghaow99/BitStack.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.23918v3",
    "published_date": "2024-10-31 13:26:11 UTC",
    "updated_date": "2025-02-17 13:50:17 UTC"
  },
  {
    "arxiv_id": "2410.23916v1",
    "title": "Transformer-based Model Predictive Control: Trajectory Optimization via Sequence Modeling",
    "authors": [
      "Davide Celestini",
      "Daniele Gammelli",
      "Tommaso Guffanti",
      "Simone D'Amico",
      "Elisa Capello",
      "Marco Pavone"
    ],
    "abstract": "Model predictive control (MPC) has established itself as the primary\nmethodology for constrained control, enabling general-purpose robot autonomy in\ndiverse real-world scenarios. However, for most problems of interest, MPC\nrelies on the recursive solution of highly non-convex trajectory optimization\nproblems, leading to high computational complexity and strong dependency on\ninitialization. In this work, we present a unified framework to combine the\nmain strengths of optimization-based and learning-based methods for MPC. Our\napproach entails embedding high-capacity, transformer-based neural network\nmodels within the optimization process for trajectory generation, whereby the\ntransformer provides a near-optimal initial guess, or target plan, to a\nnon-convex optimization problem. Our experiments, performed in simulation and\nthe real world onboard a free flyer platform, demonstrate the capabilities of\nour framework to improve MPC convergence and runtime. Compared to purely\noptimization-based approaches, results show that our approach can improve\ntrajectory generation performance by up to 75%, reduce the number of solver\niterations by up to 45%, and improve overall MPC runtime by 7x without loss in\nperformance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 7 figures. Datasets, videos and code available at:\n  https://transformermpc.github.io",
    "pdf_url": "http://arxiv.org/pdf/2410.23916v1",
    "published_date": "2024-10-31 13:23:10 UTC",
    "updated_date": "2024-10-31 13:23:10 UTC"
  },
  {
    "arxiv_id": "2410.23913v1",
    "title": "Efficient Inference and Computation of Optimal Alternatives for Preference Languages Based On Lexicographic Models",
    "authors": [
      "Nic Wilson",
      "Anne-Marie George"
    ],
    "abstract": "We analyse preference inference, through consistency, for general preference\nlanguages based on lexicographic models. We identify a property, which we call\nstrong compositionality, that applies for many natural kinds of preference\nstatement, and that allows a greedy algorithm for determining consistency of a\nset of preference statements. We also consider different natural definitions of\noptimality, and their relations to each other, for general preference languages\nbased on lexicographic models. Based on our framework, we show that testing\nconsistency, and thus inference, is polynomial for a specific preference\nlanguage LpqT, which allows strict and non-strict statements, comparisons\nbetween outcomes and between partial tuples, both ceteris paribus and strong\nstatements, and their combination. Computing different kinds of optimal sets is\nalso shown to be polynomial; this is backed up by our experimental results.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LO",
    "comment": "Longer Version of IJCAI'17 publication\n  https://www.ijcai.org/proceedings/2017/0182.pdf",
    "pdf_url": "http://arxiv.org/pdf/2410.23913v1",
    "published_date": "2024-10-31 13:19:31 UTC",
    "updated_date": "2024-10-31 13:19:31 UTC"
  },
  {
    "arxiv_id": "2410.23912v2",
    "title": "RL-STaR: Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner",
    "authors": [
      "Fu-Chieh Chang",
      "Yu-Ting Lee",
      "Hui-Ying Shih",
      "Yi Hsuan Tseng",
      "Pei-Yuan Wu"
    ],
    "abstract": "The reasoning abilities of large language models (LLMs) have improved with\nchain-of-thought (CoT) prompting, allowing models to solve complex tasks\nstepwise. However, training CoT capabilities requires detailed reasoning data,\nwhich is often scarce. The self-taught reasoner (STaR) framework addresses this\nby using reinforcement learning to automatically generate reasoning steps,\nreducing reliance on human-labeled data. Although STaR and its variants have\ndemonstrated empirical success, a theoretical foundation explaining these\nimprovements is lacking. This work provides a theoretical framework for\nunderstanding the effectiveness of reinforcement learning on CoT reasoning and\nSTaR. Our contributions are: (1) criteria for the quality of pre-trained models\nnecessary to initiate effective reasoning improvement; (2) an analysis of\npolicy improvement, showing why LLM reasoning improves iteratively with STaR;\n(3) conditions for convergence to an optimal reasoning policy; and (4) an\nexamination of STaR's robustness, explaining how it can improve reasoning even\nwhen incorporating occasional incorrect steps; This framework aims to bridge\nempirical findings with theoretical insights, advancing reinforcement learning\napproaches for reasoning in LLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23912v2",
    "published_date": "2024-10-31 13:17:53 UTC",
    "updated_date": "2025-04-10 00:52:09 UTC"
  },
  {
    "arxiv_id": "2411.11798v1",
    "title": "COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel Modeling",
    "authors": [
      "Ruisi He",
      "Nicola D. Cicco",
      "Bo Ai",
      "Mi Yang",
      "Yang Miao",
      "Mate Boban"
    ],
    "abstract": "Accurate channel models are the prerequisite for communication-theoretic\ninvestigations as well as system design. Channel modeling generally relies on\nstatistical and deterministic approaches. However, there are still significant\nlimits for the traditional modeling methods in terms of accuracy,\ngeneralization ability, and computational complexity. The fundamental reason is\nthat establishing a quantified and accurate mapping between physical\nenvironment and channel characteristics becomes increasing challenging for\nmodern communication systems. Here, in the context of COST CA20120 Action, we\nevaluate and discuss the feasibility and implementation of using artificial\nintelligence (AI) for channel modeling, and explore where the future of this\nfield lies. Firstly, we present a framework of AI-based channel modeling to\ncharacterize complex wireless channels. Then, we highlight in detail some major\nchallenges and present the possible solutions: i) estimating the uncertainty of\nAI-based channel predictions, ii) integrating prior knowledge of propagation to\nimprove generalization capabilities, and iii) interpretable AI for channel\nmodeling. We present and discuss illustrative numerical results to showcase the\ncapabilities of AI-based channel modeling.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "to appear in IEEE Wireless Communications Magazine",
    "pdf_url": "http://arxiv.org/pdf/2411.11798v1",
    "published_date": "2024-10-31 13:16:05 UTC",
    "updated_date": "2024-10-31 13:16:05 UTC"
  },
  {
    "arxiv_id": "2410.23903v1",
    "title": "Neural Network Verification with PyRAT",
    "authors": [
      "Augustin Lemesle",
      "Julien Lehmann",
      "Tristan Le Gall"
    ],
    "abstract": "As AI systems are becoming more and more popular and used in various critical\ndomains (health, transport, energy, ...), the need to provide guarantees and\ntrust of their safety is undeniable. To this end, we present PyRAT, a tool\nbased on abstract interpretation to verify the safety and the robustness of\nneural networks. In this paper, we describe the different abstractions used by\nPyRAT to find the reachable states of a neural network starting from its input\nas well as the main features of the tool to provide fast and accurate analysis\nof neural networks. PyRAT has already been used in several collaborations to\nensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing\nits performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23903v1",
    "published_date": "2024-10-31 13:05:46 UTC",
    "updated_date": "2024-10-31 13:05:46 UTC"
  },
  {
    "arxiv_id": "2411.00878v1",
    "title": "Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models",
    "authors": [
      "Phil Wee",
      "Riyadh Baghdadi"
    ],
    "abstract": "Recently, there has been an explosion of large language models created\nthrough fine-tuning with data from larger models. These small models able to\nproduce outputs that appear qualitatively similar to significantly larger\nmodels. However, one of the key limitations that have been observed with these\nmodels is their propensity to hallucinate significantly more often than larger\nmodels. In particular, they have been observed to generate coherent outputs\nthat involve factually incorrect information and spread misinformation,\ntoxicity, and stereotypes. There are many potential causes of hallucination, of\nwhich, one hypothesis is that fine-tuning a model on data produced by a larger\nmodel leads to a knowledge mismatch which contributes to hallucination. In\nparticular, it is hypothesized that there is a mismatch between the knowledge\nthat is fed to the model to fine-tune it and the knowledge that is already\npresent in the graph. Fine-tuning the model on data that has such mismatch\ncould contribute to an increased propensity to hallucinate. We show that on an\nunseen test set, a smaller model fine-tuned on data generated from a larger\nmodel produced more wrong answers when compared to models fine-tuned on data\ncreated by the small model, which confirms the hypothesis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00878v1",
    "published_date": "2024-10-31 13:01:46 UTC",
    "updated_date": "2024-10-31 13:01:46 UTC"
  },
  {
    "arxiv_id": "2410.23891v1",
    "title": "AllClear: A Comprehensive Dataset and Benchmark for Cloud Removal in Satellite Imagery",
    "authors": [
      "Hangyu Zhou",
      "Chia-Hsiang Kao",
      "Cheng Perng Phoo",
      "Utkarsh Mall",
      "Bharath Hariharan",
      "Kavita Bala"
    ],
    "abstract": "Clouds in satellite imagery pose a significant challenge for downstream\napplications. A major challenge in current cloud removal research is the\nabsence of a comprehensive benchmark and a sufficiently large and diverse\ntraining dataset. To address this problem, we introduce the largest public\ndataset -- $\\textit{AllClear}$ for cloud removal, featuring 23,742 globally\ndistributed regions of interest (ROIs) with diverse land-use patterns,\ncomprising 4 million images in total. Each ROI includes complete temporal\ncaptures from the year 2022, with (1) multi-spectral optical imagery from\nSentinel-2 and Landsat 8/9, (2) synthetic aperture radar (SAR) imagery from\nSentinel-1, and (3) auxiliary remote sensing products such as cloud masks and\nland cover maps. We validate the effectiveness of our dataset by benchmarking\nperformance, demonstrating the scaling law -- the PSNR rises from $28.47$ to\n$33.87$ with $30\\times$ more data, and conducting ablation studies on the\ntemporal length and the importance of individual modalities. This dataset aims\nto provide comprehensive coverage of the Earth's surface and promote better\ncloud removal results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at NeurIPS 2024 Datasets and Benchmarks Track. Code and data\n  available at https://allclear.cs.cornell.edu/",
    "pdf_url": "http://arxiv.org/pdf/2410.23891v1",
    "published_date": "2024-10-31 12:52:52 UTC",
    "updated_date": "2024-10-31 12:52:52 UTC"
  },
  {
    "arxiv_id": "2410.23890v1",
    "title": "Leveraging LLMs for MT in Crisis Scenarios: a blueprint for low-resource languages",
    "authors": [
      "SÃ©amus Lankford",
      "Andy Way"
    ],
    "abstract": "In an evolving landscape of crisis communication, the need for robust and\nadaptable Machine Translation (MT) systems is more pressing than ever,\nparticularly for low-resource languages. This study presents a comprehensive\nexploration of leveraging Large Language Models (LLMs) and Multilingual LLMs\n(MLLMs) to enhance MT capabilities in such scenarios. By focusing on the unique\nchallenges posed by crisis situations where speed, accuracy, and the ability to\nhandle a wide range of languages are paramount, this research outlines a novel\napproach that combines the cutting-edge capabilities of LLMs with fine-tuning\ntechniques and community-driven corpus development strategies. At the core of\nthis study is the development and empirical evaluation of MT systems tailored\nfor two low-resource language pairs, illustrating the process from initial\nmodel selection and fine-tuning through to deployment. Bespoke systems are\ndeveloped and modelled on the recent Covid-19 pandemic. The research highlights\nthe importance of community involvement in creating highly specialised,\ncrisis-specific datasets and compares custom GPTs with NLLB-adapted MLLM\nmodels. It identifies fine-tuned MLLM models as offering superior performance\ncompared with their LLM counterparts. A scalable and replicable model for rapid\nMT system development in crisis scenarios is outlined. Our approach enhances\nthe field of humanitarian technology by offering a blueprint for developing\nmultilingual communication systems during emergencies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2403.02370,\n  arXiv:2403.01580",
    "pdf_url": "http://arxiv.org/pdf/2410.23890v1",
    "published_date": "2024-10-31 12:52:26 UTC",
    "updated_date": "2024-10-31 12:52:26 UTC"
  },
  {
    "arxiv_id": "2410.23889v2",
    "title": "GEPS: Boosting Generalization in Parametric PDE Neural Solvers through Adaptive Conditioning",
    "authors": [
      "Armand KassaÃ¯ KoupaÃ¯",
      "Jorge Mifsut Benet",
      "Yuan Yin",
      "Jean-NoÃ«l Vittaut",
      "Patrick Gallinari"
    ],
    "abstract": "Solving parametric partial differential equations (PDEs) presents significant\nchallenges for data-driven methods due to the sensitivity of spatio-temporal\ndynamics to variations in PDE parameters. Machine learning approaches often\nstruggle to capture this variability. To address this, data-driven approaches\nlearn parametric PDEs by sampling a very large variety of trajectories with\nvarying PDE parameters. We first show that incorporating conditioning\nmechanisms for learning parametric PDEs is essential and that among them,\n$\\textit{adaptive conditioning}$, allows stronger generalization. As existing\nadaptive conditioning methods do not scale well with respect to the number of\nparameters to adapt in the neural solver, we propose GEPS, a simple adaptation\nmechanism to boost GEneralization in Pde Solvers via a first-order optimization\nand low-rank rapid adaptation of a small set of context parameters. We\ndemonstrate the versatility of our approach for both fully data-driven and for\nphysics-aware neural solvers. Validation performed on a whole range of\nspatio-temporal forecasting problems demonstrates excellent performance for\ngeneralizing to unseen conditions including initial conditions, PDE\ncoefficients, forcing terms and solution domain. $\\textit{Project page}$:\nhttps://geps-project.github.io",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23889v2",
    "published_date": "2024-10-31 12:51:40 UTC",
    "updated_date": "2024-11-08 14:45:55 UTC"
  },
  {
    "arxiv_id": "2410.23883v1",
    "title": "'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue",
    "authors": [
      "Rena Gao",
      "Xuetong Wu",
      "Siwen Luo",
      "Caren Han",
      "Feng Liu"
    ],
    "abstract": "Out-of-distribution (OOD) detection in multimodal contexts is essential for\nidentifying deviations in combined inputs from different modalities,\nparticularly in applications like open-domain dialogue systems or real-life\ndialogue interactions. This paper aims to improve the user experience that\ninvolves multi-round long dialogues by efficiently detecting OOD dialogues and\nimages. We introduce a novel scoring framework named Dialogue Image Aligning\nand Enhancing Framework (DIAEF) that integrates the visual language models with\nthe novel proposed scores that detect OOD in two key scenarios (1) mismatches\nbetween the dialogue and image input pair and (2) input pairs with previously\nunseen labels. Our experimental results, derived from various benchmarks,\ndemonstrate that integrating image and multi-round dialogue OOD detection is\nmore effective with previously unseen labels than using either modality\nindependently. In the presence of mismatched pairs, our proposed score\neffectively identifies these mismatches and demonstrates strong robustness in\nlong dialogues. This approach enhances domain-aware, adaptive conversational\nagents and establishes baselines for future studies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.23883v1",
    "published_date": "2024-10-31 12:45:54 UTC",
    "updated_date": "2024-10-31 12:45:54 UTC"
  },
  {
    "arxiv_id": "2410.23875v1",
    "title": "Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs",
    "authors": [
      "Liyi Chen",
      "Panrong Tong",
      "Zhongming Jin",
      "Ying Sun",
      "Jieping Ye",
      "Hui Xiong"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable reasoning capabilities on\ncomplex tasks, but they still suffer from out-of-date knowledge,\nhallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)\ncan provide explicit and editable knowledge for LLMs to alleviate these issues.\nExisting paradigm of KG-augmented LLM manually predefines the breadth of\nexploration space and requires flawless navigation in KGs. However, this\nparadigm cannot adaptively explore reasoning paths in KGs based on the question\nsemantics and self-correct erroneous reasoning paths, resulting in a bottleneck\nin efficiency and effect. To address these limitations, we propose a novel\nself-correcting adaptive planning paradigm for KG-augmented LLM named\nPlan-on-Graph (PoG), which first decomposes the question into several\nsub-objectives and then repeats the process of adaptively exploring reasoning\npaths, updating memory, and reflecting on the need to self-correct erroneous\nreasoning paths until arriving at the answer. Specifically, three important\nmechanisms of Guidance, Memory, and Reflection are designed to work together,\nto guarantee the adaptive breadth of self-correcting planning for graph\nreasoning. Finally, extensive experiments on three real-world datasets\ndemonstrate the effectiveness and efficiency of PoG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23875v1",
    "published_date": "2024-10-31 12:37:24 UTC",
    "updated_date": "2024-10-31 12:37:24 UTC"
  },
  {
    "arxiv_id": "2411.00066v1",
    "title": "Interpretable Language Modeling via Induction-head Ngram Models",
    "authors": [
      "Eunji Kim",
      "Sriya Mantena",
      "Weiwei Yang",
      "Chandan Singh",
      "Sungroh Yoon",
      "Jianfeng Gao"
    ],
    "abstract": "Recent large language models (LLMs) have excelled across a wide range of\ntasks, but their use in high-stakes and compute-limited settings has\nintensified the demand for interpretability and efficiency. We address this\nneed by proposing Induction-head ngram models (Induction-Gram), a method that\nbuilds an efficient, interpretable LM by bolstering modern ngram models with a\nhand-engineered \"induction head\". This induction head uses a custom neural\nsimilarity metric to efficiently search the model's input context for potential\nnext-word completions. This process enables Induction-Gram to provide\nngram-level grounding for each generated token. Moreover, experiments show that\nthis simple method significantly improves next-word prediction over baseline\ninterpretable models (up to 26%p) and can be used to speed up LLM inference for\nlarge models through speculative decoding. We further study Induction-Gram in a\nnatural-language neuroscience setting, where the goal is to predict the next\nfMRI response in a sequence. It again provides a significant improvement over\ninterpretable models (20% relative increase in the correlation of predicted\nfMRI responses), potentially enabling deeper scientific investigation of\nlanguage selectivity in the brain. The code is available at\nhttps://github.com/ejkim47/induction-gram.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00066v1",
    "published_date": "2024-10-31 12:33:26 UTC",
    "updated_date": "2024-10-31 12:33:26 UTC"
  },
  {
    "arxiv_id": "2410.23855v2",
    "title": "RAGraph: A General Retrieval-Augmented Graph Learning Framework",
    "authors": [
      "Xinke Jiang",
      "Rihong Qiu",
      "Yongxin Xu",
      "Wentao Zhang",
      "Yichen Zhu",
      "Ruizhe Zhang",
      "Yuchen Fang",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become essential in interpreting relational\ndata across various domains, yet, they often struggle to generalize to unseen\ngraph data that differs markedly from training instances. In this paper, we\nintroduce a novel framework called General Retrieval-Augmented Graph Learning\n(RAGraph), which brings external graph data into the general graph foundation\nmodel to improve model generalization on unseen scenarios. On the top of our\nframework is a toy graph vector library that we established, which captures key\nattributes, such as features and task-specific label information. During\ninference, the RAGraph adeptly retrieves similar toy graphs based on key\nsimilarities in downstream tasks, integrating the retrieved data to enrich the\nlearning context via the message-passing prompting mechanism. Our extensive\nexperimental evaluations demonstrate that RAGraph significantly outperforms\nstate-of-the-art graph learning methods in multiple tasks such as node\nclassification, link prediction, and graph classification across both dynamic\nand static datasets. Furthermore, extensive testing confirms that RAGraph\nconsistently maintains high performance without the need for task-specific\nfine-tuning, highlighting its adaptability, robustness, and broad\napplicability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23855v2",
    "published_date": "2024-10-31 12:05:21 UTC",
    "updated_date": "2024-12-07 10:34:41 UTC"
  },
  {
    "arxiv_id": "2410.23844v1",
    "title": "Commonsense Knowledge Editing Based on Free-Text in LLMs",
    "authors": [
      "Xiusheng Huang",
      "Yequan Wang",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Knowledge editing technology is crucial for maintaining the accuracy and\ntimeliness of large language models (LLMs) . However, the setting of this task\noverlooks a significant portion of commonsense knowledge based on free-text in\nthe real world, characterized by broad knowledge scope, long content and non\ninstantiation. The editing objects of previous methods (e.g., MEMIT) were\nsingle token or entity, which were not suitable for commonsense knowledge in\nfree-text form. To address the aforementioned challenges, we conducted\nexperiments from two perspectives: knowledge localization and knowledge\nediting. Firstly, we introduced Knowledge Localization for Free-Text(KLFT)\nmethod, revealing the challenges associated with the distribution of\ncommonsense knowledge in MLP and Attention layers, as well as in decentralized\ndistribution. Next, we propose a Dynamics-aware Editing Method(DEM), which\nutilizes a Dynamics-aware Module to locate the parameter positions\ncorresponding to commonsense knowledge, and uses Knowledge Editing Module to\nupdate knowledge. The DEM method fully explores the potential of the MLP and\nAttention layers, and successfully edits commonsense knowledge based on\nfree-text. The experimental results indicate that the DEM can achieve excellent\nediting performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.23844v1",
    "published_date": "2024-10-31 11:50:24 UTC",
    "updated_date": "2024-10-31 11:50:24 UTC"
  },
  {
    "arxiv_id": "2410.23843v1",
    "title": "Reasons and Solutions for the Decline in Model Performance after Editing",
    "authors": [
      "Xiusheng Huang",
      "Jiaxiang Liu",
      "Yequan Wang",
      "Kang Liu"
    ],
    "abstract": "Knowledge editing technology has received widespread attention for low-cost\nupdates of incorrect or outdated knowledge in large-scale language models.\nHowever, recent research has found that edited models often exhibit varying\ndegrees of performance degradation. The reasons behind this phenomenon and\npotential solutions have not yet been provided. In order to investigate the\nreasons for the performance decline of the edited model and optimize the\nediting method, this work explores the underlying reasons from both data and\nmodel perspectives. Specifically, 1) from a data perspective, to clarify the\nimpact of data on the performance of editing models, this paper first\nconstructs a Multi-Question Dataset (MQD) to evaluate the impact of different\ntypes of editing data on model performance. The performance of the editing\nmodel is mainly affected by the diversity of editing targets and sequence\nlength, as determined through experiments. 2) From a model perspective, this\narticle explores the factors that affect the performance of editing models. The\nresults indicate a strong correlation between the L1-norm of the editing model\nlayer and the editing accuracy, and clarify that this is an important factor\nleading to the bottleneck of editing performance. Finally, in order to improve\nthe performance of the editing model, this paper further proposes a Dump for\nSequence (D4S) method, which successfully overcomes the previous editing\nbottleneck by reducing the L1-norm of the editing layer, allowing users to\nperform multiple effective edits and minimizing model damage. Our code is\navailable at https://github.com/nlpkeg/D4S.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.23843v1",
    "published_date": "2024-10-31 11:49:44 UTC",
    "updated_date": "2024-10-31 11:49:44 UTC"
  },
  {
    "arxiv_id": "2410.23842v1",
    "title": "Auditing Google's Search Algorithm: Measuring News Diversity Across Brazil, the UK, and the US",
    "authors": [
      "Raphael Hernandes",
      "Giulio Corsi"
    ],
    "abstract": "This study examines the influence of Google's search algorithm on news\ndiversity by analyzing search results in Brazil, the UK, and the US. It\nexplores how Google's system preferentially favors a limited number of news\noutlets. Utilizing algorithm auditing techniques, the research measures source\nconcentration with the Herfindahl-Hirschman Index (HHI) and Gini coefficient,\nrevealing significant concentration trends. The study underscores the\nimportance of conducting horizontal analyses across multiple search queries, as\nfocusing solely on individual results pages may obscure these patterns. Factors\nsuch as popularity, political bias, and recency were evaluated for their impact\non news rankings. Findings indicate a slight leftward bias in search outcomes\nand a preference for popular, often national outlets. This bias, combined with\na tendency to prioritize recent content, suggests that Google's algorithm may\nreinforce existing media inequalities. By analyzing the largest dataset to date\n-- 221,863 search results -- this research provides comprehensive, longitudinal\ninsights into how algorithms shape public access to diverse news sources.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages, 3 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.23842v1",
    "published_date": "2024-10-31 11:49:16 UTC",
    "updated_date": "2024-10-31 11:49:16 UTC"
  },
  {
    "arxiv_id": "2410.23835v1",
    "title": "Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models",
    "authors": [
      "Pedro MorÃ£o",
      "Joao Santinha",
      "Yasna Forghani",
      "Nuno LouÃ§Ã£o",
      "Pedro Gouveia",
      "Mario A. T. Figueiredo"
    ],
    "abstract": "Deep learning (DL) models in medical imaging face challenges in\ngeneralizability and robustness due to variations in image acquisition\nparameters (IAP). In this work, we introduce a novel method using conditional\ndenoising diffusion generative models (cDDGMs) to generate counterfactual\nmagnetic resonance (MR) images that simulate different IAP without altering\npatient anatomy. We demonstrate that using these counterfactual images for data\naugmentation can improve segmentation accuracy, particularly in\nout-of-distribution settings, enhancing the overall generalizability and\nrobustness of DL models across diverse imaging conditions. Our approach shows\npromise in addressing domain and covariate shifts in medical imaging. The code\nis publicly available at https:\n//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23835v1",
    "published_date": "2024-10-31 11:29:41 UTC",
    "updated_date": "2024-10-31 11:29:41 UTC"
  },
  {
    "arxiv_id": "2410.23825v2",
    "title": "GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages",
    "authors": [
      "Amir Hossein Kargaran",
      "FranÃ§ois Yvon",
      "Hinrich SchÃ¼tze"
    ],
    "abstract": "The need for large text corpora has increased with the advent of pretrained\nlanguage models and, in particular, the discovery of scaling laws for these\nmodels. Most available corpora have sufficient data only for languages with\nlarge dominant communities. However, there is no corpus available that (i)\ncovers a wide range of minority languages; (ii) is generated by an open-source\nreproducible pipeline; and (iii) is rigorously cleaned from noise, making it\ntrustworthy to use. We present GlotCC, a clean, document-level, 2TB general\ndomain corpus derived from CommonCrawl, covering more than 1000 languages. We\nmake GlotCC and the system used to generate it - including the pipeline,\nlanguage identification model, and filters - available to the research\ncommunity. Corpus v. 1.0 https://huggingface.co/datasets/cis-lmu/GlotCC-v1,\nPipeline v. 3.0 https://github.com/cisnlp/GlotCC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23825v2",
    "published_date": "2024-10-31 11:14:12 UTC",
    "updated_date": "2025-03-03 21:51:52 UTC"
  },
  {
    "arxiv_id": "2410.23822v1",
    "title": "Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding",
    "authors": [
      "Jinlong He",
      "Pengfei Li",
      "Gang Liu",
      "Shenjun Zhong"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) inherit the superior text\nunderstanding capabilities of LLMs and extend these capabilities to multimodal\nscenarios. These models achieve excellent results in the general domain of\nmultimodal tasks. However, in the medical domain, the substantial training\ncosts and the requirement for extensive medical data pose challenges to the\ndevelopment of medical MLLMs. Furthermore, due to the free-text form of\nanswers, tasks such as visual grounding that need to produce output in a\nprescribed form become difficult for MLLMs. So far, there have been no medical\nMLLMs works in medical visual grounding area. For the medical vision grounding\ntask, which involves identifying locations in medical images based on short\ntext descriptions, we propose Parameter-efficient Fine-tuning medical\nmultimodal large language models for Medcial Visual Grounding (PFMVG). To\nvalidate the performance of the model, we evaluate it on a public benchmark\ndataset for medical visual grounding, where it achieves competitive results,\nand significantly outperforming GPT-4v. Our code will be open sourced after\npeer review.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23822v1",
    "published_date": "2024-10-31 11:07:26 UTC",
    "updated_date": "2024-10-31 11:07:26 UTC"
  },
  {
    "arxiv_id": "2411.00876v1",
    "title": "Resilience to the Flowing Unknown: an Open Set Recognition Framework for Data Streams",
    "authors": [
      "Marcos Barcina-Blanco",
      "Jesus L. Lobo",
      "Pablo Garcia-Bringas",
      "Javier Del Ser"
    ],
    "abstract": "Modern digital applications extensively integrate Artificial Intelligence\nmodels into their core systems, offering significant advantages for automated\ndecision-making. However, these AI-based systems encounter reliability and\nsafety challenges when handling continuously generated data streams in complex\nand dynamic scenarios. This work explores the concept of resilient AI systems,\nwhich must operate in the face of unexpected events, including instances that\nbelong to patterns that have not been seen during the training process. This is\nan issue that regular closed-set classifiers commonly encounter in streaming\nscenarios, as they are designed to compulsory classify any new observation into\none of the training patterns (i.e., the so-called \\textit{over-occupied space}\nproblem). In batch learning, the Open Set Recognition research area has\nconsistently confronted this issue by requiring models to robustly uphold their\nclassification performance when processing query instances from unknown\npatterns. In this context, this work investigates the application of an Open\nSet Recognition framework that combines classification and clustering to\naddress the \\textit{over-occupied space} problem in streaming scenarios.\nSpecifically, we systematically devise a benchmark comprising different\nclassification datasets with varying ratios of known to unknown classes.\nExperiments are presented on this benchmark to compare the performance of the\nproposed hybrid framework with that of individual incremental classifiers.\nDiscussions held over the obtained results highlight situations where the\nproposed framework performs best, and delineate the limitations and hurdles\nencountered by incremental classifiers in effectively resolving the challenges\nposed by open-world streaming environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 3 figures, an updated version of this article is published\n  in LNAI,volume 14857 as part of the conference proceedings HAIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00876v1",
    "published_date": "2024-10-31 11:06:54 UTC",
    "updated_date": "2024-10-31 11:06:54 UTC"
  },
  {
    "arxiv_id": "2410.23820v1",
    "title": "Disentangling Disentangled Representations: Towards Improved Latent Units via Diffusion Models",
    "authors": [
      "Youngjun Jun",
      "Jiwoo Park",
      "Kyobin Choo",
      "Tae Eun Choi",
      "Seong Jae Hwang"
    ],
    "abstract": "Disentangled representation learning (DRL) aims to break down observed data\ninto core intrinsic factors for a profound understanding of the data. In\nreal-world scenarios, manually defining and labeling these factors are\nnon-trivial, making unsupervised methods attractive. Recently, there have been\nlimited explorations of utilizing diffusion models (DMs), which are already\nmainstream in generative modeling, for unsupervised DRL. They implement their\nown inductive bias to ensure that each latent unit input to the DM expresses\nonly one distinct factor. In this context, we design Dynamic Gaussian Anchoring\nto enforce attribute-separated latent units for more interpretable DRL. This\nunconventional inductive bias explicitly delineates the decision boundaries\nbetween attributes while also promoting the independence among latent units.\nAdditionally, we also propose Skip Dropout technique, which easily modifies the\ndenoising U-Net to be more DRL-friendly, addressing its uncooperative nature\nwith the disentangling feature extractor. Our methods, which carefully consider\nthe latent unit semantics and the distinct DM structure, enhance the\npracticality of DM-based disentangled representations, demonstrating\nstate-of-the-art disentanglement performance on both synthetic and real data,\nas well as advantages in downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23820v1",
    "published_date": "2024-10-31 11:05:09 UTC",
    "updated_date": "2024-10-31 11:05:09 UTC"
  },
  {
    "arxiv_id": "2410.23815v1",
    "title": "The NPU-HWC System for the ISCSLP 2024 Inspirational and Convincing Audio Generation Challenge",
    "authors": [
      "Dake Guo",
      "Jixun Yao",
      "Xinfa Zhu",
      "Kangxiang Xia",
      "Zhao Guo",
      "Ziyu Zhang",
      "Yao Wang",
      "Jie Liu",
      "Lei Xie"
    ],
    "abstract": "This paper presents the NPU-HWC system submitted to the ISCSLP 2024\nInspirational and Convincing Audio Generation Challenge 2024 (ICAGC). Our\nsystem consists of two modules: a speech generator for Track 1 and a background\naudio generator for Track 2. In Track 1, we employ Single-Codec to tokenize the\nspeech into discrete tokens and use a language-model-based approach to achieve\nzero-shot speaking style cloning. The Single-Codec effectively decouples timbre\nand speaking style at the token level, reducing the acoustic modeling burden on\nthe autoregressive language model. Additionally, we use DSPGAN to upsample 16\nkHz mel-spectrograms to high-fidelity 48 kHz waveforms. In Track 2, we propose\na background audio generator based on large language models (LLMs). This system\nproduces scene-appropriate accompaniment descriptions, synthesizes background\naudio with Tango 2, and integrates it with the speech generated by our Track 1\nsystem. Our submission achieves the second place and the first place in Track 1\nand Track 2 respectively.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted by ISCSLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23815v1",
    "published_date": "2024-10-31 10:58:59 UTC",
    "updated_date": "2024-10-31 10:58:59 UTC"
  },
  {
    "arxiv_id": "2410.23810v1",
    "title": "CALE: Continuous Arcade Learning Environment",
    "authors": [
      "Jesse Farebrother",
      "Pablo Samuel Castro"
    ],
    "abstract": "We introduce the Continuous Arcade Learning Environment (CALE), an extension\nof the well-known Arcade Learning Environment (ALE) [Bellemare et al., 2013].\nThe CALE uses the same underlying emulator of the Atari 2600 gaming system\n(Stella), but adds support for continuous actions. This enables the\nbenchmarking and evaluation of continuous-control agents (such as PPO [Schulman\net al., 2017] and SAC [Haarnoja et al., 2018]) and value-based agents (such as\nDQN [Mnih et al., 2015] and Rainbow [Hessel et al., 2018]) on the same\nenvironment suite. We provide a series of open questions and research\ndirections that CALE enables, as well as initial baseline results using Soft\nActor-Critic. CALE is available as part of the ALE\nathttps://github.com/Farama-Foundation/Arcade-Learning-Environment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23810v1",
    "published_date": "2024-10-31 10:52:42 UTC",
    "updated_date": "2024-10-31 10:52:42 UTC"
  },
  {
    "arxiv_id": "2410.23803v1",
    "title": "Generative AI for Accessible and Inclusive Extended Reality",
    "authors": [
      "Jens Grubert",
      "Junlong Chen",
      "Per Ola Kristensson"
    ],
    "abstract": "Artificial Intelligence-Generated Content (AIGC) has the potential to\ntransform how people build and interact with virtual environments. Within this\npaper, we discuss potential benefits but also challenges that AIGC has for the\ncreation of inclusive and accessible virtual environments. Specifically, we\ntouch upon the decreased need for 3D modeling expertise, benefits of\nsymbolic-only as well as multimodal input, 3D content editing, and 3D model\naccessibility as well as foundation model-specific challenges.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Presented at the CHI 2024 Workshop \"Building a Metaverse for All:\n  Opportunities and Challenges for Future Inclusive and Accessible Virtual\n  Environments\", May 11, 2024, Honolulu, Hawaii",
    "pdf_url": "http://arxiv.org/pdf/2410.23803v1",
    "published_date": "2024-10-31 10:43:43 UTC",
    "updated_date": "2024-10-31 10:43:43 UTC"
  },
  {
    "arxiv_id": "2410.23796v1",
    "title": "Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks",
    "authors": [
      "F. D. Gonzalez-Martinez",
      "J. J. Carabias-Orti",
      "F. J. Canadas-Quesada",
      "N. Ruiz-Reyes",
      "D. Martinez-Munoz",
      "S. Garcia-Galan"
    ],
    "abstract": "Snoring, an acoustic biomarker commonly observed in individuals with\nObstructive Sleep Apnoea Syndrome (OSAS), holds significant potential for\ndiagnosing and monitoring this recognized clinical disorder. Irrespective of\nsnoring types, most snoring instances exhibit identifiable harmonic patterns\nmanifested through distinctive energy distributions over time. In this work, we\npropose a novel method to differentiate monaural snoring from non-snoring\nsounds by analyzing the harmonic content of the input sound using\nharmonic/percussive sound source separation (HPSS). The resulting feature,\nbased on the harmonic spectrogram from HPSS, is employed as input data for\nconventional neural network architectures, aiming to enhance snoring detection\nperformance even under a limited data learning framework. To evaluate the\nperformance of our proposal, we studied two different scenarios: 1) using a\nlarge dataset of snoring and interfering sounds, and 2) using a reduced\ntraining set composed of around 1% of the data material. In the former\nscenario, the proposed HPSS-based feature provides competitive results compared\nto other input features from the literature. However, the key advantage of the\nproposed method lies in the superior performance of the harmonic spectrogram\nderived from HPSS in a limited data learning context. In this particular\nscenario, using the proposed harmonic feature significantly enhances the\nperformance of all the studied architectures in comparison to the classical\ninput features documented in the existing literature. This finding clearly\ndemonstrates that incorporating harmonic content enables more reliable learning\nof the essential time-frequency characteristics that are prevalent in most\nsnoring sounds, even in scenarios where the amount of training data is limited.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.ET",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23796v1",
    "published_date": "2024-10-31 10:27:48 UTC",
    "updated_date": "2024-10-31 10:27:48 UTC"
  },
  {
    "arxiv_id": "2410.23788v1",
    "title": "EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching",
    "authors": [
      "Xinwang Chen",
      "Ning Liu",
      "Yichen Zhu",
      "Feifei Feng",
      "Jian Tang"
    ],
    "abstract": "Transformer-based Diffusion Probabilistic Models (DPMs) have shown more\npotential than CNN-based DPMs, yet their extensive computational requirements\nhinder widespread practical applications. To reduce the computation budget of\ntransformer-based DPMs, this work proposes the Efficient Diffusion Transformer\n(EDT) framework. The framework includes a lightweight-design diffusion model\narchitecture, and a training-free Attention Modulation Matrix and its\nalternation arrangement in EDT inspired by human-like sketching. Additionally,\nwe propose a token relation-enhanced masking training strategy tailored\nexplicitly for EDT to augment its token relation learning capability. Our\nextensive experiments demonstrate the efficacy of EDT. The EDT framework\nreduces training and inference costs and surpasses existing transformer-based\ndiffusion models in image synthesis performance, thereby achieving a\nsignificant overall enhancement. With lower FID, EDT-S, EDT-B, and EDT-XL\nattained speed-ups of 3.93x, 2.84x, and 1.92x respectively in the training\nphase, and 2.29x, 2.29x, and 2.22x respectively in inference, compared to the\ncorresponding sizes of MDTv2. The source code is released at\nhttps://github.com/xinwangChen/EDT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Xinwang Chen and Ning Liu are with equal contributions. This paper\n  has been accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23788v1",
    "published_date": "2024-10-31 10:13:05 UTC",
    "updated_date": "2024-10-31 10:13:05 UTC"
  },
  {
    "arxiv_id": "2410.23780v3",
    "title": "Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map",
    "authors": [
      "Xinyuan Chang",
      "Maixuan Xue",
      "Xinran Liu",
      "Zheng Pan",
      "Xing Wei"
    ],
    "abstract": "Ensuring adherence to traffic sign regulations is essential for both human\nand autonomous vehicle navigation. While current online mapping solutions often\nprioritize the construction of the geometric and connectivity layers of HD\nmaps, overlooking the construction of the traffic regulation layer within HD\nmaps. Addressing this gap, we introduce MapDR, a novel dataset designed for the\nextraction of Driving Rules from traffic signs and their association with\nvectorized, locally perceived HD Maps. MapDR features over $10,000$ annotated\nvideo clips that capture the intricate correlation between traffic sign\nregulations and lanes. Built upon this benchmark and the newly defined task of\nintegrating traffic regulations into online HD maps, we provide modular and\nend-to-end solutions: VLE-MEE and RuleVLM, offering a strong baseline for\nadvancing autonomous driving technology. It fills a critical gap in the\nintegration of traffic sign rules, contributing to the development of reliable\nautonomous driving systems. Code is available at\nhttps://github.com/MIV-XJTU/MapDR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages, 16 figures. Accepted as a Highlight at CVPR 2025. Project\n  page: https://miv-xjtu.github.io/MapDR/",
    "pdf_url": "http://arxiv.org/pdf/2410.23780v3",
    "published_date": "2024-10-31 09:53:21 UTC",
    "updated_date": "2025-04-10 11:13:00 UTC"
  },
  {
    "arxiv_id": "2411.00064v1",
    "title": "The ISCSLP 2024 Conversational Voice Clone (CoVoC) Challenge: Tasks, Results and Findings",
    "authors": [
      "Kangxiang Xia",
      "Dake Guo",
      "Jixun Yao",
      "Liumeng Xue",
      "Hanzhao Li",
      "Shuai Wang",
      "Zhao Guo",
      "Lei Xie",
      "Qingqing Zhang",
      "Lei Luo",
      "Minghui Dong",
      "Peng Sun"
    ],
    "abstract": "The ISCSLP 2024 Conversational Voice Clone (CoVoC) Challenge aims to\nbenchmark and advance zero-shot spontaneous style voice cloning, particularly\nfocusing on generating spontaneous behaviors in conversational speech. The\nchallenge comprises two tracks: an unconstrained track without limitation on\ndata and model usage, and a constrained track only allowing the use of\nconstrained open-source datasets. A 100-hour high-quality conversational speech\ndataset is also made available with the challenge. This paper details the data,\ntracks, submitted systems, evaluation results, and findings.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted by ISCSLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00064v1",
    "published_date": "2024-10-31 09:39:49 UTC",
    "updated_date": "2024-10-31 09:39:49 UTC"
  },
  {
    "arxiv_id": "2410.23769v2",
    "title": "The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams",
    "authors": [
      "Yunqi Zhu",
      "Wen Tang",
      "Huayu Yang",
      "Jinghao Niu",
      "Liyang Dou",
      "Yifan Gu",
      "Yuanyuan Wu",
      "Wensheng Zhang",
      "Ying Sun",
      "Xuebing Yang"
    ],
    "abstract": "In this work, we leverage LLMs to produce medical qualification exam\nquestions and the corresponding answers through few-shot prompts, investigating\nin-depth how LLMs meet the requirements in terms of coherence, evidence of\nstatement, factual consistency, and professionalism etc. Utilizing a\nmulticenter bidirectional anonymized database with respect to comorbid chronic\ndiseases, named Elderly Comorbidity Medical Database (CECMed), we tasked LLMs\nwith generating open-ended questions and answers based on a subset of sampled\nadmission reports. For CECMed, the retrospective cohort includes patients\nenrolled from January 2010 to January 2022 while the prospective cohort from\nJanuary 2023 to November 2023, with participants sourced from selected tertiary\nand community hospitals across the southern, northern, and central regions of\nChina. A total of 8 widely used LLMs were used, including ERNIE 4, ChatGLM 4,\nDoubao, Hunyuan, Spark 4, Qwen,\n  Conventional medical education requires sophisticated clinicians to formulate\nquestions and answers based on prototypes from EHRs, which is heuristic and\ntime-consuming. We found that mainstream LLMs could generate questions and\nanswers with real-world EHRs at levels close to clinicians. Although current\nLLMs performed dissatisfactory in some aspects, medical students, interns and\nresidents could reasonably make use of LLMs to facilitate understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23769v2",
    "published_date": "2024-10-31 09:33:37 UTC",
    "updated_date": "2025-02-27 07:47:40 UTC"
  },
  {
    "arxiv_id": "2411.10453v1",
    "title": "Towards Geometry-Preserving Reductions Between Constraint Satisfaction Problems (and other problems in NP)",
    "authors": [
      "Gabriel Istrate"
    ],
    "abstract": "Motivated by phase transitions in combinatorial optimization problems, we\ndefine two kinds of geometry-preserving reductions between constraint\nsatisfaction problems and other NP-search problems. We give a couple of\nexamples and counterexamples for these reductions.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.DM",
      "F.2.2"
    ],
    "primary_category": "cs.CC",
    "comment": "In Proceedings FROM 2024, arXiv:2410.23020. An extended version is\n  under preparation and will also be posted on arXiv",
    "pdf_url": "http://arxiv.org/pdf/2411.10453v1",
    "published_date": "2024-10-31 09:26:53 UTC",
    "updated_date": "2024-10-31 09:26:53 UTC"
  },
  {
    "arxiv_id": "2410.23753v1",
    "title": "Enhancing Chess Reinforcement Learning with Graph Representation",
    "authors": [
      "Tomas Rigaux",
      "Hisashi Kashima"
    ],
    "abstract": "Mastering games is a hard task, as games can be extremely complex, and still\nfundamentally different in structure from one another. While the AlphaZero\nalgorithm has demonstrated an impressive ability to learn the rules and\nstrategy of a large variety of games, ranging from Go and Chess, to Atari\ngames, its reliance on extensive computational resources and rigid\nConvolutional Neural Network (CNN) architecture limits its adaptability and\nscalability. A model trained to play on a $19\\times 19$ Go board cannot be used\nto play on a smaller $13\\times 13$ board, despite the similarity between the\ntwo Go variants. In this paper, we focus on Chess, and explore using a more\ngeneric Graph-based Representation of a game state, rather than a grid-based\none, to introduce a more general architecture based on Graph Neural Networks\n(GNN). We also expand the classical Graph Attention Network (GAT) layer to\nincorporate edge-features, to naturally provide a generic policy output format.\nOur experiments, performed on smaller networks than the initial AlphaZero\npaper, show that this new architecture outperforms previous architectures with\na similar number of parameters, being able to increase playing strength an\norder of magnitude faster. We also show that the model, when trained on a\nsmaller $5\\times 5$ variant of chess, is able to be quickly fine-tuned to play\non regular $8\\times 8$ chess, suggesting that this approach yields promising\ngeneralization abilities. Our code is available at\nhttps://github.com/akulen/AlphaGateau.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23753v1",
    "published_date": "2024-10-31 09:18:47 UTC",
    "updated_date": "2024-10-31 09:18:47 UTC"
  },
  {
    "arxiv_id": "2410.23749v8",
    "title": "LSEAttention is All You Need for Time Series Forecasting",
    "authors": [
      "Dizhen Liang"
    ],
    "abstract": "Transformer-based architectures have achieved remarkable success in natural\nlanguage processing and computer vision. However, their performance in\nmultivariate long-term forecasting often falls short compared to simpler linear\nbaselines. Previous research has identified the traditional attention mechanism\nas a key factor limiting their effectiveness in this domain. To bridge this\ngap, we introduce LATST, a novel approach designed to mitigate entropy collapse\nand training instability common challenges in Transformer-based time series\nforecasting. We rigorously evaluate LATST across multiple real-world\nmultivariate time series datasets, demonstrating its ability to outperform\nexisting state-of-the-art Transformer models. Notably, LATST manages to achieve\ncompetitive performance with fewer parameters than some linear models on\ncertain datasets, highlighting its efficiency and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages with referencing, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.23749v8",
    "published_date": "2024-10-31 09:09:39 UTC",
    "updated_date": "2025-04-30 01:52:08 UTC"
  },
  {
    "arxiv_id": "2410.23748v2",
    "title": "Exploring Consistency in Graph Representations:from Graph Kernels to Graph Neural Networks",
    "authors": [
      "Xuyuan Liu",
      "Yinghao Cai",
      "Qihui Yang",
      "Yujun Yan"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as a dominant approach in graph\nrepresentation learning, yet they often struggle to capture consistent\nsimilarity relationships among graphs. While graph kernel methods such as the\nWeisfeiler-Lehman subtree (WL-subtree) and Weisfeiler-Lehman optimal assignment\n(WLOA) kernels are effective in capturing similarity relationships, they rely\nheavily on predefined kernels and lack sufficient non-linearity for more\ncomplex data patterns. Our work aims to bridge the gap between neural network\nmethods and kernel approaches by enabling GNNs to consistently capture\nrelational structures in their learned representations. Given the analogy\nbetween the message-passing process of GNNs and WL algorithms, we thoroughly\ncompare and analyze the properties of WL-subtree and WLOA kernels. We find that\nthe similarities captured by WLOA at different iterations are asymptotically\nconsistent, ensuring that similar graphs remain similar in subsequent\niterations, thereby leading to superior performance over the WL-subtree kernel.\nInspired by these findings, we conjecture that the consistency in the\nsimilarities of graph representations across GNN layers is crucial in capturing\nrelational structures and enhancing graph classification performance. Thus, we\npropose a loss to enforce the similarity of graph representations to be\nconsistent across different layers. Our empirical analysis verifies our\nconjecture and shows that our proposed consistency loss can significantly\nenhance graph classification performance across several GNN backbones on\nvarious datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23748v2",
    "published_date": "2024-10-31 09:07:08 UTC",
    "updated_date": "2024-12-11 06:06:31 UTC"
  },
  {
    "arxiv_id": "2410.23746v3",
    "title": "DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios",
    "authors": [
      "Junchao Wu",
      "Runzhe Zhan",
      "Derek F. Wong",
      "Shu Yang",
      "Xinyi Yang",
      "Yulin Yuan",
      "Lidia S. Chao"
    ],
    "abstract": "Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)",
    "pdf_url": "http://arxiv.org/pdf/2410.23746v3",
    "published_date": "2024-10-31 09:01:25 UTC",
    "updated_date": "2025-03-12 10:08:22 UTC"
  },
  {
    "arxiv_id": "2410.23745v1",
    "title": "Syno: Structured Synthesis for Neural Operators",
    "authors": [
      "Yongqi Zhuo",
      "Zhengyuan Su",
      "Chenggang Zhao",
      "Mingyu Gao"
    ],
    "abstract": "The desires for better prediction accuracy and higher execution performance\nin neural networks never end. Neural architecture search (NAS) and tensor\ncompilers are two popular techniques to optimize these two goals, but they are\nboth limited to composing or optimizing existing manually designed operators\nrather than coming up with completely new designs. In this work, we explore the\nless studied direction of neural operator synthesis, which aims to\nautomatically and efficiently discover novel neural operators with better\naccuracy and/or speed. We develop an end-to-end framework Syno, to realize\npractical neural operator synthesis. Syno makes use of a novel set of\nfine-grained primitives defined on tensor dimensions, which ensure various\ndesired properties to ease model training, and also enable expression\ncanonicalization techniques to avoid redundant candidates during search. Syno\nfurther adopts a novel guided synthesis flow to obtain valid operators matched\nwith the specified input/output dimension sizes, and leverages efficient\nstochastic tree search algorithms to quickly explore the design space. We\ndemonstrate that Syno discovers better operators with an average of\n$2.06\\times$ speedup and less than $1\\%$ accuracy loss, even on NAS-optimized\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23745v1",
    "published_date": "2024-10-31 09:00:24 UTC",
    "updated_date": "2024-10-31 09:00:24 UTC"
  },
  {
    "arxiv_id": "2410.23743v1",
    "title": "What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective",
    "authors": [
      "Ming Li",
      "Yanhong Li",
      "Tianyi Zhou"
    ],
    "abstract": "What makes a difference in the post-training of LLMs? We investigate the\ntraining patterns of different layers in large language models (LLMs), through\nthe lens of gradient, when training with different responses and initial\nmodels. We are specifically interested in how fast vs. slow thinking affects\nthe layer-wise gradients, given the recent popularity of training LLMs on\nreasoning paths such as chain-of-thoughts (CoT) and process rewards. In our\nstudy, fast thinking without CoT leads to larger gradients and larger\ndifferences of gradients across layers than slow thinking (Detailed CoT),\nindicating the learning stability brought by the latter. Moreover, pre-trained\nLLMs are less affected by the instability of fast thinking than\ninstruction-tuned LLMs. Additionally, we study whether the gradient patterns\ncan reflect the correctness of responses when training different LLMs using\nslow vs. fast thinking paths. The results show that the gradients of slow\nthinking can distinguish correct and irrelevant reasoning paths. As a\ncomparison, we conduct similar gradient analyses on non-reasoning knowledge\nlearning tasks, on which, however, trivially increasing the response length\ndoes not lead to similar behaviors of slow thinking. Our study strengthens\nfundamental understandings of LLM training and sheds novel insights on its\nefficiency and stability, which pave the way towards building a generalizable\nSystem-2 agent. Our code, data, and gradient statistics can be found in:\nhttps://github.com/MingLiiii/Layer_Gradient.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23743v1",
    "published_date": "2024-10-31 08:58:06 UTC",
    "updated_date": "2024-10-31 08:58:06 UTC"
  },
  {
    "arxiv_id": "2410.23726v1",
    "title": "Towards Reliable Alignment: Uncertainty-aware RLHF",
    "authors": [
      "Debangshu Banerjee",
      "Aditya Gopalan"
    ],
    "abstract": "Recent advances in aligning Large Language Models with human preferences have\nbenefited from larger reward models and better preference data. However, most\nof these methodologies rely on the accuracy of the reward model. The reward\nmodels used in Reinforcement Learning with Human Feedback (RLHF) are typically\nlearned from small datasets using stochastic optimization algorithms, making\nthem prone to high variability. We illustrate the inconsistencies between\nreward models empirically on numerous open-source datasets.\n  We theoretically show that the fluctuation of the reward models can be\ndetrimental to the alignment problem because the derived policies are more\noverfitted to the reward model and, hence, are riskier if the reward model\nitself is uncertain. We use concentration of measure to motivate an\nuncertainty-aware, conservative algorithm for policy optimization. We show that\nsuch policies are more risk-averse in the sense that they are more cautious of\nuncertain rewards. We theoretically prove that our proposed methodology has\nless risk than the vanilla method.\n  We corroborate our theoretical results with experiments based on designing an\nensemble of reward models. We use this ensemble of reward models to align a\nlanguage model using our methodology and observe that our empirical findings\nmatch our theoretical predictions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23726v1",
    "published_date": "2024-10-31 08:26:51 UTC",
    "updated_date": "2024-10-31 08:26:51 UTC"
  },
  {
    "arxiv_id": "2410.23725v1",
    "title": "Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial",
    "authors": [
      "Taridzo Chomutare",
      "Therese Olsen Svenning",
      "Miguel Ãngel Tejedor HernÃ¡ndez",
      "Phuong Dinh Ngo",
      "Andrius Budrionis",
      "Kaisa Markljung",
      "Lill Irene Hind",
      "TorbjÃ¸rn Torsvik",
      "Karl Ãyvind Mikalsen",
      "Aleksandar Babic",
      "Hercules Dalianis"
    ],
    "abstract": "\\textbf{Trial design} Crossover randomized controlled trial. \\textbf{Methods}\nAn AI tool, Easy-ICD, was developed to assist clinical coders and was tested\nfor improving both accuracy and time in a user study in Norway and Sweden.\nParticipants were randomly assigned to two groups, and crossed over between\ncoding complex (longer) texts versus simple (shorter) texts, while using our\ntool versus not using our tool. \\textbf{Results} Based on Mann-Whitney U test,\nthe median coding time difference for complex clinical text sequences was 123\nseconds (\\emph{P}\\textless.001, 95\\% CI: 81 to 164), representing a 46\\%\nreduction in median coding time when our tool is used. There was no significant\ntime difference for simpler text sequences. For coding accuracy, the\nimprovement we noted for both complex and simple texts was not significant.\n\\textbf{Conclusions} This study demonstrates the potential of AI to transform\ncommon tasks in clinical workflows, with ostensible positive impacts on work\nefficiencies for complex clinical coding tasks. Further studies within hospital\nworkflows are required before these presumed impacts can be more clearly\nunderstood.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages, 4 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.23725v1",
    "published_date": "2024-10-31 08:24:37 UTC",
    "updated_date": "2024-10-31 08:24:37 UTC"
  },
  {
    "arxiv_id": "2410.23724v1",
    "title": "Argumentation and Machine Learning",
    "authors": [
      "Antonio Rago",
      "Kristijonas Äyras",
      "Jack Mumford",
      "Oana Cocarascu"
    ],
    "abstract": "This chapter provides an overview of research works that present approaches\nwith some degree of cross-fertilisation between Computational Argumentation and\nMachine Learning. Our review of the literature identified two broad themes\nrepresenting the purpose of the interaction between these two areas:\nargumentation for machine learning and machine learning for argumentation.\nAcross these two themes, we systematically evaluate the spectrum of works\nacross various dimensions, including the type of learning and the form of\nargumentation framework used. Further, we identify three types of interaction\nbetween these two areas: synergistic approaches, where the Argumentation and\nMachine Learning components are tightly integrated; segmented approaches, where\nthe two are interleaved such that the outputs of one are the inputs of the\nother; and approximated approaches, where one component shadows the other at a\nchosen level of detail. We draw conclusions about the suitability of certain\nforms of Argumentation for supporting certain types of Machine Learning, and\nvice versa, with clear patterns emerging from the review. Whilst the reviewed\nworks provide inspiration for successfully combining the two fields of\nresearch, we also identify and discuss limitations and challenges that ought to\nbe addressed in order to ensure that they remain a fruitful pairing as AI\nadvances.",
    "categories": [
      "cs.AI",
      "F.4.1; I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "44 pages, to appear in the Handbook of Formal Argumentation and the\n  Journal of Applied Logics",
    "pdf_url": "http://arxiv.org/pdf/2410.23724v1",
    "published_date": "2024-10-31 08:19:58 UTC",
    "updated_date": "2024-10-31 08:19:58 UTC"
  },
  {
    "arxiv_id": "2411.00062v3",
    "title": "Scalable Reinforcement Post-Training Beyond Static Human Prompts: Evolving Alignment via Asymmetric Self-Play",
    "authors": [
      "Ziyu Ye",
      "Rishabh Agarwal",
      "Tianqi Liu",
      "Rishabh Joshi",
      "Sarmishta Velury",
      "Quoc V. Le",
      "Qijun Tan",
      "Yuan Liu"
    ],
    "abstract": "Current reinforcement learning (RL) frameworks for large language models\n(LLM) post-training typically assume a fixed prompt distribution, which is\nsub-optimal and bottlenecks scalability. Prior works have explored prompt\nevolving, but are often limited to the supervised fine-tuning stage, and\nprompts are sampled and evolved uniformly without signals. This empirical work\npresents a paradigm shift: Evolving Alignment via Asymmetric Self-Play (eva),\nthat casts post-training as an infinite game with regret-based signals for 2\nplayers: (i) a creator, who strategically samples and creates new informative\nprompts and (ii) a solver, who learns to produce preferred responses. eva is\nthe first method that allows language models to adaptively create training\nprompts in both offline and online RL post-training. The design is simple,\neasy-to-use yet remarkably effective: eva sets a new SOTA on challenging\nbenchmarks, without any extra human prompts, e.g. it boosts the win-rate of\ngemma-2-9b-it on Arena-Hard by 51.6% -> 60.1% for DPO and 52.6% -> 62.4% for\nRLOO, surpassing claude-3-opus and catching up to gemini-1.5-pro, both of which\nare orders of magnitude larger. Extensive experiments show eva can create\neffective RL curricula and is robust across ablations. We believe adaptively\nevolving prompts are key to designing the next-generation RL post-training\nscheme.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "spotlight @ neurips language gamification workshop. updated the\n  problem description and added new online RL experiments in this version",
    "pdf_url": "http://arxiv.org/pdf/2411.00062v3",
    "published_date": "2024-10-31 08:15:32 UTC",
    "updated_date": "2025-04-09 19:53:54 UTC"
  },
  {
    "arxiv_id": "2411.00875v1",
    "title": "Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches",
    "authors": [
      "Mahin Mohammadi",
      "Saman Jamshidi"
    ],
    "abstract": "Brain tumors pose a serious health threat due to their rapid growth and\npotential for metastasis. While medical imaging has advanced significantly,\naccurately identifying and characterizing these tumors remains a challenge.\nThis study addresses this challenge by leveraging the innovative TrAdaBoost\nmethodology to enhance the Brain Tumor Segmentation (BraTS2020) dataset, aiming\nto improve the efficiency and accuracy of brain tumor classification. Our\napproach combines state-of-the-art deep learning algorithms, including the\nVision Transformer (ViT), Capsule Neural Network (CapsNet), and convolutional\nneural networks (CNNs) such as ResNet-152 and VGG16. By integrating these\nmodels within a multi-classifier framework, we harness the strengths of each\napproach to achieve more robust and reliable tumor classification. A novel\ndecision template is employed to synergistically combine outputs from different\nalgorithms, further enhancing classification accuracy. To augment the training\nprocess, we incorporate a secondary dataset, \"Brain Tumor MRI Dataset,\" as a\nsource domain, providing additional data for model training and improving\ngeneralization capabilities. Our findings demonstrate a high accuracy rate in\nclassifying tumor versus non-tumor images, signifying the effectiveness of our\napproach in the medical imaging domain. This study highlights the potential of\nadvanced machine learning techniques to contribute significantly to the early\nand accurate diagnosis of brain tumors, ultimately improving patient outcomes.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00875v1",
    "published_date": "2024-10-31 07:28:06 UTC",
    "updated_date": "2024-10-31 07:28:06 UTC"
  },
  {
    "arxiv_id": "2410.23680v1",
    "title": "Rethinking Inverse Reinforcement Learning: from Data Alignment to Task Alignment",
    "authors": [
      "Weichao Zhou",
      "Wenchao Li"
    ],
    "abstract": "Many imitation learning (IL) algorithms use inverse reinforcement learning\n(IRL) to infer a reward function that aligns with the demonstration. However,\nthe inferred reward functions often fail to capture the underlying task\nobjectives. In this paper, we propose a novel framework for IRL-based IL that\nprioritizes task alignment over conventional data alignment. Our framework is a\nsemi-supervised approach that leverages expert demonstrations as weak\nsupervision to derive a set of candidate reward functions that align with the\ntask rather than only with the data. It then adopts an adversarial mechanism to\ntrain a policy with this set of reward functions to gain a collective\nvalidation of the policy's ability to accomplish the task. We provide\ntheoretical insights into this framework's ability to mitigate task-reward\nmisalignment and present a practical implementation. Our experimental results\nshow that our framework outperforms conventional IL baselines in complex and\ntransfer learning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2306.01731",
    "pdf_url": "http://arxiv.org/pdf/2410.23680v1",
    "published_date": "2024-10-31 07:08:14 UTC",
    "updated_date": "2024-10-31 07:08:14 UTC"
  },
  {
    "arxiv_id": "2411.00874v2",
    "title": "VecCity: A Taxonomy-guided Library for Map Entity Representation Learning",
    "authors": [
      "Wentao Zhang",
      "Jingyuan Wang",
      "Yifan Yang",
      "Leong Hou U"
    ],
    "abstract": "Electronic maps consist of diverse entities, such as points of interest\n(POIs), road networks, and land parcels, playing a vital role in applications\nlike ITS and LBS. Map entity representation learning (MapRL) generates\nversatile and reusable data representations, providing essential tools for\nefficiently managing and utilizing map entity data. Despite the progress in\nMapRL, two key challenges constrain further development. First, existing\nresearch is fragmented, with models classified by the type of map entity,\nlimiting the reusability of techniques across different tasks. Second, the lack\nof unified benchmarks makes systematic evaluation and comparison of models\ndifficult. To address these challenges, we propose a novel taxonomy for MapRL\nthat organizes models based on functional module-such as encoders, pre-training\ntasks, and downstream tasks-rather than by entity type. Building on this\ntaxonomy, we present a taxonomy-driven library, VecCity, which offers\neasy-to-use interfaces for encoding, pre-training, fine-tuning, and evaluation.\nThe library integrates datasets from nine cities and reproduces 21 mainstream\nMapRL models, establishing the first standardized benchmarks for the field.\nVecCity also allows users to modify and extend models through modular\ncomponents, facilitating seamless experimentation. Our comprehensive\nexperiments cover multiple types of map entities and evaluate 21 VecCity\npre-built models across various downstream tasks. Experimental results\ndemonstrate the effectiveness of VecCity in streamlining model development and\nprovide insights into the impact of various components on performance. By\npromoting modular design and reusability, VecCity offers a unified framework to\nadvance research and innovation in MapRL. The code is available at\nhttps://github.com/Bigscity-VecCity/VecCity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00874v2",
    "published_date": "2024-10-31 07:03:46 UTC",
    "updated_date": "2025-05-07 12:26:10 UTC"
  },
  {
    "arxiv_id": "2410.23672v1",
    "title": "Provable Benefit of Cutout and CutMix for Feature Learning",
    "authors": [
      "Junsoo Oh",
      "Chulhee Yun"
    ],
    "abstract": "Patch-level data augmentation techniques such as Cutout and CutMix have\ndemonstrated significant efficacy in enhancing the performance of vision tasks.\nHowever, a comprehensive theoretical understanding of these methods remains\nelusive. In this paper, we study two-layer neural networks trained using three\ndistinct methods: vanilla training without augmentation, Cutout training, and\nCutMix training. Our analysis focuses on a feature-noise data model, which\nconsists of several label-dependent features of varying rarity and\nlabel-independent noises of differing strengths. Our theorems demonstrate that\nCutout training can learn low-frequency features that vanilla training cannot,\nwhile CutMix training can learn even rarer features that Cutout cannot capture.\nFrom this, we establish that CutMix yields the highest test accuracy among the\nthree. Our novel analysis reveals that CutMix training makes the network learn\nall features and noise vectors \"evenly\" regardless of the rarity and strength,\nwhich provides an interesting insight into understanding patch-level\naugmentation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 camera-ready version, 81 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.23672v1",
    "published_date": "2024-10-31 06:41:10 UTC",
    "updated_date": "2024-10-31 06:41:10 UTC"
  },
  {
    "arxiv_id": "2410.23668v1",
    "title": "Kernel Looping: Eliminating Synchronization Boundaries for Peak Inference Performance",
    "authors": [
      "David Koeplinger",
      "Darshan Gandhi",
      "Pushkar Nandkar",
      "Nathan Sheeley",
      "Matheen Musaddiq",
      "Leon Zhang",
      "Reid Goodbar",
      "Matthew Shaffer",
      "Han Wang",
      "Angela Wang",
      "Mingran Wang",
      "Raghu Prabhakar"
    ],
    "abstract": "Token generation speed is critical to power the next wave of AI inference\napplications. GPUs significantly underperform during token generation due to\nsynchronization overheads at kernel boundaries, utilizing only 21% of their\npeak memory bandwidth. While recent dataflow architectures mitigate these\noverheads by enabling aggressive fusion of decoder layers into a single kernel,\nthey too leave performance on the table due to synchronization penalties at\nlayer boundaries.\n  This paper presents kernel looping, a specialized global optimization\ntechnique which exploits an optimization opportunity brought by combining the\nunique layer-level fusion possible in modern dataflow architectures with the\nrepeated layer structure found in language models. Kernel looping eliminates\nsynchronization costs between consecutive calls to the same kernel by\ntransforming these calls into a single call to a modified kernel containing a\npipelined outer loop. We evaluate kernel looping on the SambaNova SN40L\nReconfigurable Dataflow Unit (RDU), a commercial dataflow accelerator for AI.\nExperiments demonstrate that kernel looping speeds up the decode phase of a\nwide array of powerful open-source models by up to 2.2$\\times$ on SN40L. Kernel\nlooping allows scaling of decode performance over multiple SN40L sockets,\nachieving speedups of up to 2.5$\\times$. Finally, kernel looping enables SN40L\nto achieve over 90% of peak performance on 8 and 16 sockets and achieve a\nspeedup of up to 3.7$\\times$ over DGX H100. Kernel looping, as well as the\nmodels evaluated in this paper, are deployed in production in a commercial AI\ninference cloud.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR",
      "D.3.4; C.1.3"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23668v1",
    "published_date": "2024-10-31 06:32:47 UTC",
    "updated_date": "2024-10-31 06:32:47 UTC"
  },
  {
    "arxiv_id": "2410.23649v2",
    "title": "Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction",
    "authors": [
      "Guan-Hua Huang",
      "Wan-Chen Lai",
      "Tai-Been Chen",
      "Chien-Chin Hsu",
      "Huei-Yung Chen",
      "Yi-Chen Wu",
      "Li-Ren Yeh"
    ],
    "abstract": "Parkinson's disease (PD), a degenerative disorder of the central nervous\nsystem, is commonly diagnosed using functional medical imaging techniques such\nas single-photon emission computed tomography (SPECT). In this study, we\nutilized two SPECT data sets (n = 634 and n = 202) from different hospitals to\ndevelop a model capable of accurately predicting PD stages, a multiclass\nclassification task. We used the entire three-dimensional (3D) brain images as\ninput and experimented with various model architectures. Initially, we treated\nthe 3D images as sequences of two-dimensional (2D) slices and fed them\nsequentially into 2D convolutional neural network (CNN) models pretrained on\nImageNet, averaging the outputs to obtain the final predicted stage. We also\napplied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated\nan attention mechanism to account for the varying importance of different\nslices in the prediction process. To further enhance model efficacy and\nrobustness, we simultaneously trained the two data sets using weight sharing, a\ntechnique known as cotraining. Our results demonstrated that 2D models\npretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and\nmodels utilizing the attention mechanism outperformed both 2D and 3D models.\nThe cotraining technique proved effective in improving model performance when\nthe cotraining data sets were sufficiently large.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "38 pages, 7 figures, and 4 tables. This paper has been accepted for\n  publication in Journal of Imaging Informatics in Medicine",
    "pdf_url": "http://arxiv.org/pdf/2410.23649v2",
    "published_date": "2024-10-31 05:40:08 UTC",
    "updated_date": "2025-01-21 04:42:10 UTC"
  },
  {
    "arxiv_id": "2411.00873v1",
    "title": "CleaR: Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning",
    "authors": [
      "Yeachan Kim",
      "Junho Kim",
      "SangKeun Lee"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization\nof cumbersome language models in real-world settings. However, as datasets in\nsuch environments often contain noisy labels that adversely affect performance,\nPEFT methods are inevitably exposed to noisy labels. Despite this challenge,\nthe adaptability of PEFT to noisy environments remains underexplored. To bridge\nthis gap, we investigate various PEFT methods under noisy labels.\nInterestingly, our findings reveal that PEFT has difficulty in memorizing noisy\nlabels due to its inherently limited capacity, resulting in robustness.\nHowever, we also find that such limited capacity simultaneously makes PEFT more\nvulnerable to interference of noisy labels, impeding the learning of clean\nsamples. To address this issue, we propose Clean Routing (CleaR), a novel\nrouting-based PEFT approach that adaptively activates PEFT modules. In CleaR,\nPEFT modules are preferentially exposed to clean data while bypassing the noisy\nones, thereby minimizing the noisy influence. To verify the efficacy of CleaR,\nwe perform extensive experiments on diverse configurations of noisy labels. The\nresults convincingly demonstrate that CleaR leads to substantially improved\nperformance in noisy environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2411.00873v1",
    "published_date": "2024-10-31 05:11:58 UTC",
    "updated_date": "2024-10-31 05:11:58 UTC"
  },
  {
    "arxiv_id": "2411.10450v1",
    "title": "Dataset Refinement for Improving the Generalization Ability of the EEG Decoding Model",
    "authors": [
      "Sung-Jin Kim",
      "Dae-Hyeok Lee",
      "Hyeon-Taek Han"
    ],
    "abstract": "Electroencephalography (EEG) is a generally used neuroimaging approach in\nbrain-computer interfaces due to its non-invasive characteristics and\nconvenience, making it an effective tool for understanding human intentions.\nTherefore, recent research has focused on decoding human intentions from EEG\nsignals utilizing deep learning methods. However, since EEG signals are highly\nsusceptible to noise during acquisition, there is a high possibility of the\nexistence of noisy data in the dataset. Although pioneer studies have generally\nassumed that the dataset is well-curated, this assumption is not always met in\nthe EEG dataset. In this paper, we addressed this issue by designing a dataset\nrefinement algorithm that can eliminate noisy data based on metrics evaluating\ndata influence during the training process. We applied the proposed algorithm\nto two motor imagery EEG public datasets and three different models to perform\ndataset refinement. The results indicated that retraining the model with the\nrefined dataset consistently led to better generalization performance compared\nto using the original dataset. Hence, we demonstrated that removing noisy data\nfrom the training dataset alone can effectively improve the generalization\nperformance of deep learning models in the EEG domain.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "4 pages, 1 figure, conference",
    "pdf_url": "http://arxiv.org/pdf/2411.10450v1",
    "published_date": "2024-10-31 05:08:24 UTC",
    "updated_date": "2024-10-31 05:08:24 UTC"
  },
  {
    "arxiv_id": "2410.23637v2",
    "title": "Anytime-Constrained Equilibria in Polynomial Time",
    "authors": [
      "Jeremy McMahan"
    ],
    "abstract": "We extend anytime constraints to the Markov game setting and the\ncorresponding solution concept of an anytime-constrained equilibrium (ACE).\nThen, we present a comprehensive theory of anytime-constrained equilibria that\nincludes (1) a computational characterization of feasible policies, (2) a\nfixed-parameter tractable algorithm for computing ACE, and (3) a\npolynomial-time algorithm for approximately computing ACE. Since computing a\nfeasible policy is NP-hard even for two-player zero-sum games, our\napproximation guarantees are optimal so long as $P \\neq NP$. We also develop\nthe first theory of efficient computation for action-constrained Markov games,\nwhich may be of independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23637v2",
    "published_date": "2024-10-31 05:07:01 UTC",
    "updated_date": "2025-03-04 18:40:33 UTC"
  },
  {
    "arxiv_id": "2410.23630v1",
    "title": "Adaptive Alignment: Dynamic Preference Adjustments via Multi-Objective Reinforcement Learning for Pluralistic AI",
    "authors": [
      "Hadassah Harland",
      "Richard Dazeley",
      "Peter Vamplew",
      "Hashini Senaratne",
      "Bahareh Nakisa",
      "Francisco Cruz"
    ],
    "abstract": "Emerging research in Pluralistic Artificial Intelligence (AI) alignment seeks\nto address how intelligent systems can be designed and deployed in accordance\nwith diverse human needs and values. We contribute to this pursuit with a\ndynamic approach for aligning AI with diverse and shifting user preferences\nthrough Multi Objective Reinforcement Learning (MORL), via post-learning policy\nselection adjustment. In this paper, we introduce the proposed framework for\nthis approach, outline its anticipated advantages and assumptions, and discuss\ntechnical details about the implementation. We also examine the broader\nimplications of adopting a retroactive alignment approach through the\nsociotechnical systems perspective.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for the Pluralistic Alignment workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23630v1",
    "published_date": "2024-10-31 04:46:52 UTC",
    "updated_date": "2024-10-31 04:46:52 UTC"
  },
  {
    "arxiv_id": "2410.23629v2",
    "title": "Posture-Informed Muscular Force Learning for Robust Hand Pressure Estimation",
    "authors": [
      "Kyungjin Seo",
      "Junghoon Seo",
      "Hanseok Jeong",
      "Sangpil Kim",
      "Sang Ho Yoon"
    ],
    "abstract": "We present PiMForce, a novel framework that enhances hand pressure estimation\nby leveraging 3D hand posture information to augment forearm surface\nelectromyography (sEMG) signals. Our approach utilizes detailed spatial\ninformation from 3D hand poses in conjunction with dynamic muscle activity from\nsEMG to enable accurate and robust whole-hand pressure measurements under\ndiverse hand-object interactions. We also developed a multimodal data\ncollection system that combines a pressure glove, an sEMG armband, and a\nmarkerless finger-tracking module. We created a comprehensive dataset from 21\nparticipants, capturing synchronized data of hand posture, sEMG signals, and\nexerted hand pressure across various hand postures and hand-object interaction\nscenarios using our collection system. Our framework enables precise hand\npressure estimation in complex and natural interaction scenarios. Our approach\nsubstantially mitigates the limitations of traditional sEMG-based or\nvision-based methods by integrating 3D hand posture information with sEMG\nsignals. Video demos, data, and code are available online.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024. Project Page Link:\n  https://pimforce.hcitech.org/",
    "pdf_url": "http://arxiv.org/pdf/2410.23629v2",
    "published_date": "2024-10-31 04:42:43 UTC",
    "updated_date": "2024-11-01 08:38:21 UTC"
  },
  {
    "arxiv_id": "2411.00871v1",
    "title": "LLaMo: Large Language Model-based Molecular Graph Assistant",
    "authors": [
      "Jinyoung Park",
      "Minseong Bae",
      "Dohwan Ko",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization and\ninstruction-following capabilities with instruction tuning. The advancements in\nLLMs and instruction tuning have led to the development of Large\nVision-Language Models (LVLMs). However, the competency of the LLMs and\ninstruction tuning have been less explored in the molecular domain. Thus, we\npropose LLaMo: Large Language Model-based Molecular graph assistant, which is\nan end-to-end trained large molecular graph-language model. To bridge the\ndiscrepancy between the language and graph modalities, we present the\nmulti-level graph projector that transforms graph representations into graph\ntokens by abstracting the output representations of each GNN layer and motif\nrepresentations with the cross-attention mechanism. We also introduce\nmachine-generated molecular graph instruction data to instruction-tune the\nlarge molecular graph-language model for general-purpose molecule and language\nunderstanding. Our extensive experiments demonstrate that LLaMo shows the best\nperformance on diverse tasks, such as molecular description generation,\nproperty prediction, and IUPAC name prediction. The code of LLaMo is available\nat https://github.com/mlvlab/LLaMo.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.00871v1",
    "published_date": "2024-10-31 03:56:05 UTC",
    "updated_date": "2024-10-31 03:56:05 UTC"
  },
  {
    "arxiv_id": "2410.23598v2",
    "title": "Using Structural Similarity and Kolmogorov-Arnold Networks for Anatomical Embedding of Cortical Folding Patterns",
    "authors": [
      "Minheng Chen",
      "Chao Cao",
      "Tong Chen",
      "Yan Zhuang",
      "Jing Zhang",
      "Yanjun Lyu",
      "Xiaowei Yu",
      "Lu Zhang",
      "Tianming Liu",
      "Dajiang Zhu"
    ],
    "abstract": "The 3-hinge gyrus (3HG) is a newly defined folding pattern, which is the\nconjunction of gyri coming from three directions in cortical folding. Many\nstudies demonstrated that 3HGs can be reliable nodes when constructing brain\nnetworks or connectome since they simultaneously possess commonality and\nindividuality across different individual brains and populations. However, 3HGs\nare identified and validated within individual spaces, making it difficult to\ndirectly serve as the brain network nodes due to the absence of cross-subject\ncorrespondence. The 3HG correspondences represent the intrinsic regulation of\nbrain organizational architecture, traditional image-based registration methods\ntend to fail because individual anatomical properties need to be fully\nrespected. To address this challenge, we propose a novel self-supervised\nframework for anatomical feature embedding of the 3HGs to build the\ncorrespondences among different brains. The core component of this framework is\nto construct a structural similarity-enhanced multi-hop feature encoding\nstrategy based on the recently developed Kolmogorov-Arnold network (KAN) for\nanatomical feature embedding. Extensive experiments suggest that our approach\ncan effectively establish robust cross-subject correspondences when no\none-to-one mapping exists.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23598v2",
    "published_date": "2024-10-31 03:28:23 UTC",
    "updated_date": "2025-02-23 04:30:14 UTC"
  },
  {
    "arxiv_id": "2410.23594v1",
    "title": "How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?",
    "authors": [
      "Weiguo Gao",
      "Ming Li"
    ],
    "abstract": "Real-world data is often assumed to lie within a low-dimensional structure\nembedded in high-dimensional space. In practical settings, we observe only a\nfinite set of samples, forming what we refer to as the sample data subspace. It\nserves an essential approximation supporting tasks such as dimensionality\nreduction and generation. A major challenge lies in whether generative models\ncan reliably synthesize samples that stay within this subspace rather than\ndrifting away from the underlying structure. In this work, we provide\ntheoretical insights into this challenge by leveraging Flow Matching models,\nwhich transform a simple prior into a complex target distribution via a learned\nvelocity field. By treating the real data distribution as discrete, we derive\nanalytical expressions for the optimal velocity field under a Gaussian prior,\nshowing that generated samples memorize real data points and represent the\nsample data subspace exactly. To generalize to suboptimal scenarios, we\nintroduce the Orthogonal Subspace Decomposition Network (OSDNet), which\nsystematically decomposes the velocity field into subspace and off-subspace\ncomponents. Our analysis shows that the off-subspace component decays, while\nthe subspace component generalizes within the sample data subspace, ensuring\ngenerated samples preserve both proximity and diversity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.23594v1",
    "published_date": "2024-10-31 03:08:07 UTC",
    "updated_date": "2024-10-31 03:08:07 UTC"
  },
  {
    "arxiv_id": "2410.23578v1",
    "title": "Automating Quantum Software Maintenance: Flakiness Detection and Root Cause Analysis",
    "authors": [
      "Janakan Sivaloganathan",
      "Ainaz Jamshidi",
      "Andriy Miranskyy",
      "Lei Zhang"
    ],
    "abstract": "Flaky tests, which pass or fail inconsistently without code changes, are a\nmajor challenge in software engineering in general and in quantum software\nengineering in particular due to their complexity and probabilistic nature,\nleading to hidden issues and wasted developer effort.\n  We aim to create an automated framework to detect flaky tests in quantum\nsoftware and an extended dataset of quantum flaky tests, overcoming the\nlimitations of manual methods.\n  Building on prior manual analysis of 14 quantum software repositories, we\nexpanded the dataset and automated flaky test detection using transformers and\ncosine similarity. We conducted experiments with Large Language Models (LLMs)\nfrom the OpenAI GPT and Meta LLaMA families to assess their ability to detect\nand classify flaky tests from code and issue descriptions.\n  Embedding transformers proved effective: we identified 25 new flaky tests,\nexpanding the dataset by 54%. Top LLMs achieved an F1-score of 0.8871 for\nflakiness detection but only 0.5839 for root cause identification.\n  We introduced an automated flaky test detection framework using machine\nlearning, showing promising results but highlighting the need for improved root\ncause detection and classification in large quantum codebases. Future work will\nfocus on improving detection techniques and developing automatic flaky test\nfixes.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.23578v1",
    "published_date": "2024-10-31 02:43:04 UTC",
    "updated_date": "2024-10-31 02:43:04 UTC"
  },
  {
    "arxiv_id": "2410.23577v2",
    "title": "MS-Glance: Bio-Insipred Non-semantic Context Vectors and their Applications in Supervising Image Reconstruction",
    "authors": [
      "Ziqi Gao",
      "Wendi Yang",
      "Yujia Li",
      "Lei Xing",
      "S. Kevin Zhou"
    ],
    "abstract": "Non-semantic context information is crucial for visual recognition, as the\nhuman visual perception system first uses global statistics to process scenes\nrapidly before identifying specific objects. However, while semantic\ninformation is increasingly incorporated into computer vision tasks such as\nimage reconstruction, non-semantic information, such as global spatial\nstructures, is often overlooked. To bridge the gap, we propose a biologically\ninformed non-semantic context descriptor, \\textbf{MS-Glance}, along with the\nGlance Index Measure for comparing two images. A Global Glance vector is\nformulated by randomly retrieving pixels based on a perception-driven rule from\nan image to form a vector representing non-semantic global context, while a\nlocal Glance vector is a flattened local image window, mimicking a zoom-in\nobservation. The Glance Index is defined as the inner product of two\nstandardized sets of Glance vectors. We evaluate the effectiveness of\nincorporating Glance supervision in two reconstruction tasks: image fitting\nwith implicit neural representation (INR) and undersampled MRI reconstruction.\nExtensive experimental results show that MS-Glance outperforms existing image\nrestoration losses across both natural and medical images. The code is\navailable at \\url{https://github.com/Z7Gao/MSGlance}.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.23577v2",
    "published_date": "2024-10-31 02:42:25 UTC",
    "updated_date": "2024-11-23 10:04:56 UTC"
  },
  {
    "arxiv_id": "2411.10449v1",
    "title": "Love in Action: Gamifying Public Video Cameras for Fostering Social Relationships in Real World",
    "authors": [
      "Zhang Zhang",
      "Da Li",
      "Geng Wu",
      "Yaoning Li",
      "Xiaobing Sun",
      "Liang Wang"
    ],
    "abstract": "In this paper, we create \"Love in Action\" (LIA), a body language-based social\ngame utilizing video cameras installed in public spaces to enhance social\nrelationships in real-world. In the game, participants assume dual roles, i.e.,\nrequesters, who issue social requests, and performers, who respond social\nrequests through performing specified body languages. To mediate the\ncommunication between participants, we build an AI-enhanced video analysis\nsystem incorporating multiple visual analysis modules like person detection,\nattribute recognition, and action recognition, to assess the performer's body\nlanguage quality. A two-week field study involving 27 participants shows\nsignificant improvements in their social friendships, as indicated by\nself-reported questionnaires. Moreover, user experiences are investigated to\nhighlight the potential of public video cameras as a novel communication medium\nfor socializing in public spaces.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "14J60 (Primary) 14F05, 14J26 (Secondary)"
    ],
    "primary_category": "cs.HC",
    "comment": "accepted as a main track paper by EAI-ArtsIT 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.10449v1",
    "published_date": "2024-10-31 02:38:40 UTC",
    "updated_date": "2024-10-31 02:38:40 UTC"
  },
  {
    "arxiv_id": "2410.23558v2",
    "title": "Transferable Ensemble Black-box Jailbreak Attacks on Large Language Models",
    "authors": [
      "Yiqi Yang",
      "Hongye Fu"
    ],
    "abstract": "In this report, we propose a novel black-box jailbreak attacking framework\nthat incorporates various LLM-as-Attacker methods to deliver transferable and\npowerful jailbreak attacks. Our method is designed based on three key\nobservations from existing jailbreaking studies and practices. First, we\nconsider an ensemble approach should be more effective in exposing the\nvulnerabilities of an aligned LLM compared to individual attacks. Second,\ndifferent malicious instructions inherently vary in their jailbreaking\ndifficulty, necessitating differentiated treatment to ensure more efficient\nattacks. Finally, the semantic coherence of a malicious instruction is crucial\nfor triggering the defenses of an aligned LLM; therefore, it must be carefully\ndisrupted to manipulate its embedding representation, thereby increasing the\njailbreak success rate. We validated our approach by participating in the\nCompetition for LLM and Agent Safety 2024, where our team achieved top\nperformance in the Jailbreaking Attack Track.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23558v2",
    "published_date": "2024-10-31 01:55:33 UTC",
    "updated_date": "2024-11-27 11:28:00 UTC"
  },
  {
    "arxiv_id": "2410.23555v1",
    "title": "From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents",
    "authors": [
      "Nalin Tiwary",
      "Vardhan Dongre",
      "Sanil Arun Chawla",
      "Ashwin Lamani",
      "Dilek Hakkani-TÃ¼r"
    ],
    "abstract": "Recent advancements in Large Language Model (LLM)-based frameworks have\nextended their capabilities to complex real-world applications, such as\ninteractive web navigation. These systems, driven by user commands, navigate\nweb browsers to complete tasks through multi-turn dialogues, offering both\ninnovative opportunities and significant challenges. Despite the introduction\nof benchmarks for conversational web navigation, a detailed understanding of\nthe key contextual components that influence the performance of these agents\nremains elusive. This study aims to fill this gap by analyzing the various\ncontextual elements crucial to the functioning of web navigation agents. We\ninvestigate the optimization of context management, focusing on the influence\nof interaction history and web page representation. Our work highlights\nimproved agent performance across out-of-distribution scenarios, including\nunseen websites, categories, and geographic locations through effective context\nmanagement. These findings provide insights into the design and optimization of\nLLM-based agents, enabling more accurate and effective web navigation in\nreal-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.23555v1",
    "published_date": "2024-10-31 01:51:41 UTC",
    "updated_date": "2024-10-31 01:51:41 UTC"
  },
  {
    "arxiv_id": "2410.23537v1",
    "title": "ALISE: Accelerating Large Language Model Serving with Speculative Scheduling",
    "authors": [
      "Youpeng Zhao",
      "Jun Wang"
    ],
    "abstract": "Large Language Models (LLMs) represent a revolutionary advancement in the\ncontemporary landscape of artificial general intelligence (AGI). As exemplified\nby ChatGPT, LLM-based applications necessitate minimal response latency and\nmaximal throughput for inference serving. However, due to the unpredictability\nof LLM execution, the first-come-first-serve (FCFS) scheduling policy employed\nby current LLM serving systems suffers from head-of-line (HoL) blocking issues\nand long job response times.\n  In this paper, we propose a new efficient LLM inference serving framework,\nnamed ALISE. The key design paradigm of ALISE is to leverage a novel\nspeculative scheduler by estimating the execution time for each job and\nexploiting such prior knowledge to assign appropriate job priority orders, thus\nminimizing potential queuing delays for heterogeneous workloads. Furthermore,\nto mitigate the memory overhead of the intermediate key-value (KV) cache, we\nemploy a priority-based adaptive memory management protocol and\nquantization-based compression techniques. Evaluations demonstrate that in\ncomparison to the state-of-the-art solution vLLM, ALISE improves the throughput\nof inference serving by up to 1.8x and 2.1x under the same latency constraint\non the Alpaca and ShareGPT datasets, respectively.",
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "primary_category": "cs.PF",
    "comment": "ICCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.23537v1",
    "published_date": "2024-10-31 00:58:11 UTC",
    "updated_date": "2024-10-31 00:58:11 UTC"
  },
  {
    "arxiv_id": "2410.23535v1",
    "title": "Simulating User Agents for Embodied Conversational-AI",
    "authors": [
      "Daniel Philipov",
      "Vardhan Dongre",
      "Gokhan Tur",
      "Dilek Hakkani-TÃ¼r"
    ],
    "abstract": "Embodied agents designed to assist users with tasks must engage in natural\nlanguage interactions, interpret instructions, execute actions, and communicate\neffectively to resolve issues. However, collecting large-scale, diverse\ndatasets of situated human-robot dialogues to train and evaluate such agents is\nexpensive, labor-intensive, and time-consuming. To address this challenge, we\npropose building a large language model (LLM)-based user agent that can\nsimulate user behavior during interactions with an embodied agent in a virtual\nenvironment. Given a user goal (e.g., make breakfast), at each time step, the\nuser agent may observe\" the robot actions or speak\" to either intervene with\nthe robot or answer questions. Such a user agent assists in improving the\nscalability and efficiency of embodied dialogues dataset generation and is\ncritical for enhancing and evaluating the robot's interaction and task\ncompletion ability, as well as for research in reinforcement learning using AI\nfeedback. We evaluate our user agent's ability to generate human-like behaviors\nby comparing its simulated dialogues with the TEACh dataset. We perform three\nexperiments: zero-shot prompting to predict dialogue acts, few-shot prompting,\nand fine-tuning on the TEACh training subset. Results show the LLM-based user\nagent achieves an F-measure of 42% with zero-shot prompting and 43.4% with\nfew-shot prompting in mimicking human speaking behavior. Through fine-tuning,\nperformance in deciding when to speak remained stable, while deciding what to\nsay improved from 51.1% to 62.5%. These findings showcase the feasibility of\nthe proposed approach for assessing and enhancing the effectiveness of robot\ntask completion through natural language communication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.23535v1",
    "published_date": "2024-10-31 00:56:08 UTC",
    "updated_date": "2024-10-31 00:56:08 UTC"
  },
  {
    "arxiv_id": "2411.09709v1",
    "title": "Feature Selection via Dynamic Graph-based Attention Block in MI-based EEG Signals",
    "authors": [
      "Hyeon-Taek Han",
      "Dae-Hyeok Lee",
      "Heon-Gyu Kwak"
    ],
    "abstract": "Brain-computer interface (BCI) technology enables direct interaction between\nhumans and computers by analyzing brain signals. Electroencephalogram (EEG) is\none of the non-invasive tools used in BCI systems, providing high temporal\nresolution for real-time applications. However, EEG signals are often affected\nby a low signal-to-noise ratio, physiological artifacts, and individual\nvariability, representing challenges in extracting distinct features. Also,\nmotor imagery (MI)-based EEG signals could contain features with low\ncorrelation to MI characteristics, which might cause the weights of the deep\nmodel to become biased towards those features. To address these problems, we\nproposed the end-to-end deep preprocessing method that effectively enhances MI\ncharacteristics while attenuating features with low correlation to MI\ncharacteristics. The proposed method consisted of the temporal, spatial, graph,\nand similarity blocks to preprocess MI-based EEG signals, aiming to extract\nmore discriminative features and improve the robustness. We evaluated the\nproposed method using the public dataset 2a of BCI Competition IV to compare\nthe performances when integrating the proposed method into the conventional\nmodels, including the DeepConvNet, the M-ShallowConvNet, and the EEGNet. The\nexperimental results showed that the proposed method could achieve the improved\nperformances and lead to more clustered feature distributions of MI tasks.\nHence, we demonstrated that our proposed method could enhance discriminative\nfeatures related to MI characteristics.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "4 pages, 2 figures, 1 table, Name of Conference: International\n  Conference on Brain-Computer Interface",
    "pdf_url": "http://arxiv.org/pdf/2411.09709v1",
    "published_date": "2024-10-31 00:53:29 UTC",
    "updated_date": "2024-10-31 00:53:29 UTC"
  },
  {
    "arxiv_id": "2410.23530v2",
    "title": "There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models",
    "authors": [
      "Åukasz Staniszewski",
      "Åukasz KuciÅski",
      "Kamil Deja"
    ],
    "abstract": "Diffusion Models achieve state-of-the-art performance in generating new\nsamples but lack low-dimensional latent space that encodes the data into\nmeaningful features. Inversion-based techniques try to solve this issue by\nreversing the denoising process and mapping images back to their approximated\nstarting noise. In this work, we thoroughly analyze this procedure and focus on\nthe relation between the initial Gaussian noise, the generated samples, and\ntheir corresponding latent encodings obtained through the DDIM inversion.\nFirst, we show that latents exhibit structural patterns in the form of less\ndiverse noise predicted for smooth image regions. Next, we explain the origin\nof this phenomenon, demonstrating that, during the first inversion steps, the\nnoise prediction error is much more significant for the plain areas than for\nthe rest of the image. Finally, we present the consequences of the divergence\nbetween latents and noises by showing that the space of image inversions is\nnotably less manipulative than the original Gaussian noise. This leads to a low\ndiversity of generated interpolations or editions based on the DDIM inversion\nprocedure and ill-defined latent-to-image mapping. Code is available at\nhttps://github.com/luk-st/taba.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23530v2",
    "published_date": "2024-10-31 00:30:35 UTC",
    "updated_date": "2025-03-13 01:33:51 UTC"
  },
  {
    "arxiv_id": "2411.05811v1",
    "title": "Neurophysiological Analysis in Motor and Sensory Cortices for Improving Motor Imagination",
    "authors": [
      "Si-Hyun Kim",
      "Sung-Jin Kim",
      "Dae-Hyeok Lee"
    ],
    "abstract": "Brain-computer interface (BCI) enables direct communication between the brain\nand external devices by decoding neural signals, offering potential solutions\nfor individuals with motor impairments. This study explores the neural\nsignatures of motor execution (ME) and motor imagery (MI) tasks using EEG\nsignals, focusing on four conditions categorized as sense-related (hot and\ncold) and motor-related (pull and push) conditions. We conducted scalp\ntopography analysis to examine activation patterns in the sensorimotor cortex,\nrevealing distinct regional differences: sense--related conditions primarily\nactivated the posterior region of the sensorimotor cortex, while motor--related\nconditions activated the anterior region of the sensorimotor cortex. These\nspatial distinctions align with neurophysiological principles, suggesting\ncondition-specific functional subdivisions within the sensorimotor cortex. We\nfurther evaluated the performances of three neural network models-EEGNet,\nShallowConvNet, and DeepConvNet-demonstrating that ME tasks achieved higher\nclassification accuracies compared to MI tasks. Specifically, in sense-related\nconditions, the highest accuracy was observed in the cold condition. In\nmotor-related conditions, the pull condition showed the highest performance,\nwith DeepConvNet yielding the highest results. These findings provide insights\ninto optimizing BCI applications by leveraging specific condition-induced\nneural activations.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "4 pages, 3 figures, 1 table, Name of Conference: International Winter\n  Conference on Brain-Computer Interface",
    "pdf_url": "http://arxiv.org/pdf/2411.05811v1",
    "published_date": "2024-10-31 00:18:41 UTC",
    "updated_date": "2024-10-31 00:18:41 UTC"
  },
  {
    "arxiv_id": "2410.23526v1",
    "title": "LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models",
    "authors": [
      "Hieu Tran",
      "Junda Wang",
      "Yujan Ting",
      "Weijing Huang",
      "Terrence Chen"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks, yet they often struggle with maintaining\nfactual accuracy, particularly in knowledge-intensive domains like healthcare.\nThis study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,\na novel approach designed to enhance the factual reliability of LLMs, with a\nfocus on medical question answering (QA). LEAF utilizes a dual strategy to\nenhance the factual accuracy of responses from models such as Llama 3 70B\nInstruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,\nimproves Retrieval-Augmented Generation (RAG) by incorporating fact-checking\nresults to guide the retrieval process without updating model parameters. The\nsecond strategy, Learning from Fact-Checks via Self-Training, involves\nsupervised fine-tuning (SFT) on fact-checked responses or applying Simple\nPreference Optimization (SimPO) with fact-checking as a ranking mechanism, both\nupdating LLM parameters from supervision. These findings suggest that\nintegrating fact-checked responses whether through RAG enhancement or\nself-training enhances the reliability and factual correctness of LLM outputs,\noffering a promising solution for applications where information accuracy is\ncrucial.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.23526v1",
    "published_date": "2024-10-31 00:18:05 UTC",
    "updated_date": "2024-10-31 00:18:05 UTC"
  }
]