{
  "date": "2024-10-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-31 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、强化学习、LLM 的鲁棒性和应用、计算机视觉以及医疗 AI 等领域，重点包括 LLM 的越狱攻击和事实性增强、扩散模型的改进，以及 NeurIPS 等会议的相关工作；令人印象深刻的文章有 NeurIPS 接受的论文，如关于深度学习的经验洞见和量子问题优化，以及知名学者如 Jonathan D. Cohen 和 Mihaela van der Schaar 的贡献。\n\n下面，我将按主题分组简要概述今天的论文，先优先讨论重要、话题度高的文章（如 LLM 应用、AI 安全和医疗创新），然后快速掠过其他较次要的。每个论文标题以“中文标题（英文标题）”形式列出，保留核心学术术语，并突出主要贡献和发现。\n\n### LLM 和 AI 安全\n- **神经网络校准错误量化（Quantifying calibration error in modern neural networks through evidence based theory）**：这篇论文引入主观逻辑框架来量化神经网络的期望校准错误（Expected Calibration Error），通过实验证明了其在 MNIST 和 CIFAR-10 数据集上的有效性，提升了 AI 模型在医疗等关键领域的可信度。\n- **LLM 越狱攻击基准（Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models）**：论文提出了一种针对 LLM 的成员推理攻击（Membership Inference Attacks），通过聚合段落级特征实现了对预训练和微调模型的成功攻击，揭示了 LLM 在大规模数据下的隐私风险，并提供了代码基准。\n- **LLM 事实性增强框架（Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning）**：作者使用字典学习（Dictionary Learning）提升医疗编码任务的 LLM 透明度，成功解释了无关标记的影响，并展示了在医学领域的实际应用潜力。\n- **LLM 越狱攻击转移性（Transferable Ensemble Black-box Jailbreak Attacks on Large Language Models）**：这篇短文提出了一种集成黑盒攻击框架，利用多种 LLM 方法实现可转移的越狱攻击，强调了 LLM 安全性的挑战，并在竞赛中取得顶尖成绩。\n- **LLM 推理优化（JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking）**：论文设计了 LLM 代理进行查询分析和相关性判断，提升了检索任务的性能，尤其在推理密集型场景中表现出色。\n- **LLM 文本检测基准（DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios）**：作者构建了 DetectRL 基准，评估 LLM 生成文本的检测性能，突出了真实场景中写作风格和攻击方法的影响。\n- 其他如 **LLM 指令微调（Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking）** 和 **LLM 医疗问答（Rethinking Inverse Reinforcement Learning: from Data Alignment to Task Alignment）** 等，贡献在于改进 LLM 的领域适应性和任务对齐，但整体影响较小。\n\n### 计算机视觉和图像生成\n- **扩散模型改进（Deep Learning Through A Telescoping Lens: A Simple Model Provides Empirical Insights On Grokking, Gradient Boosting & Beyond）**：NeurIPS 接受的论文，使用序列近似模型分析深度学习的现象，如双重下降和 Grokking，提供新指标预测神经网络性能。\n- **视觉几何基准（TurtleBench: A Visual Programming Benchmark in Turtle Geometry）**：论文引入 TurtleBench 基准，评估大语言模型在几何图案理解和代码生成的性能，发现现有模型在简单任务上准确率仅 19%，突显 AI 与人类感知的差距。\n- **图形感知分析（Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models）**：作者通过零样本提示评估视觉语言模型在图表理解中的人类相似行为，揭示模型对样式变化的敏感性。\n- **图像生成框架（DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion）**：论文提出 DiffPano 框架，使用球面感知扩散模型生成一致的全景图像，显著提升文本到图像的生成质量。\n- 其他如 **扩散模型记忆分析（There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models）** 等，探讨扩散模型的噪声和逆转关系，但较基础。\n\n### 强化学习和机器人\n- **量子强化学习（Reinforcement learning with learned gadgets to tackle hard quantum problems on real hardware）**：作者开发了 Gadget Reinforcement Learning (GRL) 框架，结合程序合成优化量子电路，实现了对复杂量子 Hamiltonian 问题的鲁棒性能。\n- **强化学习框架（Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning）**：论文使用确定性有限自动机 (cDFAs) 表示时间目标，并通过图神经网络预训练提升强化学习的零样本泛化能力。\n- **机器人控制优化（Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments）**：NeurIPS 论文提出自愈机器学习框架，使用 LLM 诊断和适应分布偏移，提升模型在动态环境中的鲁棒性。\n- 其他如 **强化学习基准（PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks）** 等，提供多代理任务基准，但实验细节较冗长。\n\n### 医疗和生物 AI\n- **医疗图像预测（Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images）**：作者使用深度学习模型从超声图像预测乳腺密度，AUC 达 0.854，证明其在乳腺癌风险评估中的有效性。\n- **医疗合成图像（Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy）**：论文提出 CEMIS 协议和 TIDE-II 模型，生成高质量内镜图像，提升炎症性肠病诊断的准确性。\n- **癌症疫苗优化（Revolutionizing Personalized Cancer Vaccines with NEO: Novel Epitope Optimization Using an Aggregated Feed Forward and Recurrent Neural Network with LSTM Architecture）**：作者开发 NEO 模型优化新表位预测，提升个性化癌症疫苗的准确性。\n- 其他如 **医疗公平监控（Monitoring fairness in machine learning models that predict patient mortality in the ICU）** 等，关注模型公平性，但规模较小。\n\n### 其他杂项（快速掠过）\n- 如 **元宇宙和 AI 框架（Project Sid: Many-agent simulations toward AI civilization）** 和 **哲学视角 AI（AI-driven Automation as a Pre-condition for Eudaimonia）** 等，探讨 AI 模拟和自动化哲学，但影响力有限，仅提及其概念创新。\n- 量子计算论文如 **Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding**，贡献在于防御攻击，但实验局限于 MNIST 和 CIFAR-10。\n- 一些基准和工具如 **AndroidLab** 和 **VecCity**，提供新数据集和框架，但更多是工具性而非突破性。\n\n总之，今天的论文突显了 AI 领域的快速迭代，LLM 安全和医疗应用是最值得关注的亮点。未来几天，arXiv 可能继续深化这些主题，读者可关注 NeurIPS 相关工作。保持好奇，继续探索！",
  "papers": [
    {
      "arxiv_id": "2411.00265v1",
      "title": "Quantifying calibration error in modern neural networks through evidence based theory",
      "title_zh": "翻译失败",
      "authors": [
        "Koffi Ismael Ouattara"
      ],
      "abstract": "Trustworthiness in neural networks is crucial for their deployment in\ncritical applications, where reliability, confidence, and uncertainty play\npivotal roles in decision-making. Traditional performance metrics such as\naccuracy and precision fail to capture these aspects, particularly in cases\nwhere models exhibit overconfidence. To address these limitations, this paper\nintroduces a novel framework for quantifying the trustworthiness of neural\nnetworks by incorporating subjective logic into the evaluation of Expected\nCalibration Error (ECE). This method provides a comprehensive measure of trust,\ndisbelief, and uncertainty by clustering predicted probabilities and fusing\nopinions using appropriate fusion operators. We demonstrate the effectiveness\nof this approach through experiments on MNIST and CIFAR-10 datasets, where\npost-calibration results indicate improved trustworthiness. The proposed\nframework offers a more interpretable and nuanced assessment of AI models, with\npotential applications in sensitive domains such as healthcare and autonomous\nsystems.",
      "tldr_zh": "这篇论文提出了一种新框架，通过证据理论和主观逻辑（subjective logic）量化现代神经网络的校准错误（Expected Calibration Error, ECE），以评估模型的信任、不信任和不确定性，解决传统指标如准确率在处理过度自信问题上的不足。该框架通过聚类预测概率并使用融合算子融合意见，提供更全面和可解释的可靠性评估。在 MNIST 和 CIFAR-10 数据集上的实验表明，校准后模型的 trustworthiness 得到显著改善，具有潜在应用于医疗和自动系统等敏感领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00265v1",
      "published_date": "2024-10-31 23:54:21 UTC",
      "updated_date": "2024-10-31 23:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:22:34.827146"
    },
    {
      "arxiv_id": "2411.00264v2",
      "title": "TurtleBench: A Visual Programming Benchmark in Turtle Geometry",
      "title_zh": "TurtleBench：龟几何中的可视化编程基准",
      "authors": [
        "Sina Rismanchian",
        "Yasaman Razeghi",
        "Sameer Singh",
        "Shayan Doroudi"
      ],
      "abstract": "Humans have the ability to reason about geometric patterns in images and\nscenes from a young age. However, developing large multimodal models (LMMs)\ncapable of similar reasoning remains a challenge, highlighting the need for\nrobust evaluation methods to assess these capabilities. We introduce \\Turtle, a\nbenchmark designed to evaluate LMMs' capacity to interpret geometric patterns\n-- given visual examples, textual instructions, or both -- and generate precise\ncode outputs. Inspired by turtle geometry, a notion used to teach children\nfoundational coding and geometric concepts, TurtleBench features tasks with\npatterned shapes that have underlying algorithmic logic. Our evaluation reveals\nthat leading LMMs struggle significantly with these tasks, with GPT-4o\nachieving only 19\\% accuracy on the simplest tasks and few-shot prompting only\nmarginally improves their performance ($<2\\%$). \\Turtle highlights the gap\nbetween human and AI performance in intuitive and visual geometrical\nunderstanding, setting the stage for future research in this area. \\Turtle\nstands as one of the few benchmarks to evaluate the integration of visual\nunderstanding and code generation capabilities in LMMs, setting the stage for\nfuture research. Code and Dataset for this paper is provided here:\n\\href{https://github.com/sinaris76/TurtleBench}{https://github.com/sinaris76/TurtleBench}",
      "tldr_zh": "本研究引入了TurtleBench，一种基于turtle geometry的视觉编程基准测试，用于评估大型多模态模型(LMMs)解释几何图案并生成代码的能力。TurtleBench的任务涉及从视觉示例、文本指令或两者中推断算法逻辑，灵感来源于教导儿童基础编码和几何概念的龟几何方法。实验结果显示，领先LMMs如GPT-4o在简单任务上仅达到19%的准确率，而few-shot prompting仅带来微小改善（<2%），突显了AI在直观视觉几何理解上与人类的显著差距。该基准测试为未来LMMs的视觉理解和代码生成整合研究提供了重要基础，并附带开源代码和数据集。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00264v2",
      "published_date": "2024-10-31 23:52:06 UTC",
      "updated_date": "2025-04-11 21:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:20:47.302909"
    },
    {
      "arxiv_id": "2411.00257v1",
      "title": "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models",
      "title_zh": "通过视觉语言模型的零样本提示理解数据可视化中的图形感知",
      "authors": [
        "Grace Guo",
        "Jenna Jiayi Kang",
        "Raj Sanjay Shah",
        "Hanspeter Pfister",
        "Sashank Varma"
      ],
      "abstract": "Vision Language Models (VLMs) have been successful at many chart\ncomprehension tasks that require attending to both the images of charts and\ntheir accompanying textual descriptions. However, it is not well established\nhow VLM performance profiles map to human-like behaviors. If VLMs can be shown\nto have human-like chart comprehension abilities, they can then be applied to a\nbroader range of tasks, such as designing and evaluating visualizations for\nhuman readers. This paper lays the foundations for such applications by\nevaluating the accuracy of zero-shot prompting of VLMs on graphical perception\ntasks with established human performance profiles. Our findings reveal that\nVLMs perform similarly to humans under specific task and style combinations,\nsuggesting that they have the potential to be used for modeling human\nperformance. Additionally, variations to the input stimuli show that VLM\naccuracy is sensitive to stylistic changes such as fill color and chart\ncontiguity, even when the underlying data and data mappings are the same.",
      "tldr_zh": "这篇论文通过零-shot prompting 测试 Vision-Language Models (VLMs) 在图形感知任务上的表现，以探讨其是否类似于人类的行为模式。研究发现，VLMs 在特定任务和风格组合下与人类准确性相似，这表明它们具有潜在用于模拟人类图表理解性能的价值。此外，VLMs 对输入风格变化（如填充颜色和图表连续性）非常敏感，即使底层数据和映射保持不变，这为可视化设计和评估提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00257v1",
      "published_date": "2024-10-31 23:24:46 UTC",
      "updated_date": "2024-10-31 23:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:20:58.595770"
    },
    {
      "arxiv_id": "2411.00247v1",
      "title": "Deep Learning Through A Telescoping Lens: A Simple Model Provides Empirical Insights On Grokking, Gradient Boosting & Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Jeffares",
        "Alicia Curth",
        "Mihaela van der Schaar"
      ],
      "abstract": "Deep learning sometimes appears to work in unexpected ways. In pursuit of a\ndeeper understanding of its surprising behaviors, we investigate the utility of\na simple yet accurate model of a trained neural network consisting of a\nsequence of first-order approximations telescoping out into a single\nempirically operational tool for practical analysis. Across three case studies,\nwe illustrate how it can be applied to derive new empirical insights on a\ndiverse range of prominent phenomena in the literature -- including double\ndescent, grokking, linear mode connectivity, and the challenges of applying\ndeep learning on tabular data -- highlighting that this model allows us to\nconstruct and extract metrics that help predict and understand the a priori\nunexpected performance of neural networks. We also demonstrate that this model\npresents a pedagogical formalism allowing us to isolate components of the\ntraining process even in complex contemporary settings, providing a lens to\nreason about the effects of design choices such as architecture & optimization\nstrategy, and reveals surprising parallels between neural network learning and\ngradient boosting.",
      "tldr_zh": "这篇论文提出了一种简单模型，通过一序列第一阶近似的“望远镜透镜”方法，来分析深度学习的意外行为，并提供实证见解。模型应用于三个案例研究，揭示了double descent、grokking、线性模式连接性以及在表格数据上应用深度学习面临的挑战，帮助预测和理解神经网络的性能。论文还展示了该模型能隔离训练过程的组件，分析架构和优化策略的影响，并揭示神经网络学习与gradient boosting之间的惊人相似性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Conference on Neural Information Processing Systems\n  (NeurIPS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00247v1",
      "published_date": "2024-10-31 22:54:34 UTC",
      "updated_date": "2024-10-31 22:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:21:10.303029"
    },
    {
      "arxiv_id": "2411.00238v2",
      "title": "Understanding the Limits of Vision Language Models Through the Lens of the Binding Problem",
      "title_zh": "通过绑定问题的视角审视视觉语言模型的极限",
      "authors": [
        "Declan Campbell",
        "Sunayana Rane",
        "Tyler Giallanza",
        "Nicolò De Sabbata",
        "Kia Ghods",
        "Amogh Joshi",
        "Alexander Ku",
        "Steven M. Frankland",
        "Thomas L. Griffiths",
        "Jonathan D. Cohen",
        "Taylor W. Webb"
      ],
      "abstract": "Recent work has documented striking heterogeneity in the performance of\nstate-of-the-art vision language models (VLMs), including both multimodal\nlanguage models and text-to-image models. These models are able to describe and\ngenerate a diverse array of complex, naturalistic images, yet they exhibit\nsurprising failures on basic multi-object reasoning tasks -- such as counting,\nlocalization, and simple forms of visual analogy -- that humans perform with\nnear perfect accuracy. To better understand this puzzling pattern of successes\nand failures, we turn to theoretical accounts of the binding problem in\ncognitive science and neuroscience, a fundamental problem that arises when a\nshared set of representational resources must be used to represent distinct\nentities (e.g., to represent multiple objects in an image), necessitating the\nuse of serial processing to avoid interference. We find that many of the\npuzzling failures of state-of-the-art VLMs can be explained as arising due to\nthe binding problem, and that these failure modes are strikingly similar to the\nlimitations exhibited by rapid, feedforward processing in the human brain.",
      "tldr_zh": "这篇论文通过 binding problem 的视角，探讨了视觉语言模型（VLMs，包括多模态语言模型和文本到图像模型）的性能限制。VLMs 能够处理和生成多样复杂的图像，但却在基本多对象推理任务（如计数、定位和视觉类比）上表现出显著失败，而人类能轻松完成这些任务。研究发现，这些失败源于 binding problem，即使用共享表征资源表示多个实体时需要串行处理以避免干扰，且VLMs 的问题模式与人类大脑快速前馈处理的限制高度相似。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00238v2",
      "published_date": "2024-10-31 22:24:47 UTC",
      "updated_date": "2025-04-16 21:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:23:15.903884"
    },
    {
      "arxiv_id": "2411.00230v2",
      "title": "Reinforcement learning with learned gadgets to tackle hard quantum problems on real hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Kundu",
        "Leopoldo Sarra"
      ],
      "abstract": "Designing quantum circuits for specific tasks is challenging due to the\nexponential growth of the state space. We introduce gadget reinforcement\nlearning (GRL), which integrates reinforcement learning with program synthesis\nto automatically generate and incorporate composite gates (gadgets) into the\naction space. This enhances the exploration of parameterized quantum circuits\n(PQCs) for complex tasks like approximating ground states of quantum\nHamiltonians, an NP-hard problem. We evaluate GRL using the transverse field\nIsing model under typical computational budgets (e.g., 2- 3 days of GPU\nruntime). Our results show improved accuracy, hardware compatibility and\nscalability. GRL exhibits robust performance as the size and complexity of the\nproblem increases, even with constrained computational resources. By\nintegrating gadget extraction, GRL facilitates the discovery of reusable\ncircuit components tailored for specific hardware, bridging the gap between\nalgorithmic design and practical implementation. This makes GRL a versatile\nframework for optimizing quantum circuits with applications in\nhardware-specific optimizations and variational quantum algorithms. The code is\navailable at: https://github.com/Aqasch/Gadget_RL",
      "tldr_zh": "该论文提出 Gadget Reinforcement Learning (GRL)，一种将强化学习与程序合成相结合的框架，用于自动生成复合门（gadgets）并整合到动作空间中，以优化参数化量子电路 (PQCs) 处理复杂量子问题，如逼近量子哈密顿量的基态（一个 NP-hard 问题）。GRL 通过增强探索能力，在横场 Ising 模型上进行评估，结果显示其在典型计算预算（如 2-3 天 GPU 运行时）下提高了准确性、硬件兼容性和可扩展性。即便在受限资源下，GRL 也能保持稳健性能，并通过提取可重用电路组件，桥接算法设计与实际硬件实现。总之，GRL 作为优化量子电路的通用框架，适用于硬件特定优化和变分量子算法。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "23 pages, 13 figures. Comments are encouraged",
      "pdf_url": "http://arxiv.org/pdf/2411.00230v2",
      "published_date": "2024-10-31 22:02:32 UTC",
      "updated_date": "2025-05-02 06:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:21:36.402103"
    },
    {
      "arxiv_id": "2411.00222v1",
      "title": "Protecting Feed-Forward Networks from Adversarial Attacks Using Predictive Coding",
      "title_zh": "使用预测编码保护前馈网络免受对抗攻击",
      "authors": [
        "Ehsan Ganjidoost",
        "Jeff Orchard"
      ],
      "abstract": "An adversarial example is a modified input image designed to cause a Machine\nLearning (ML) model to make a mistake; these perturbations are often invisible\nor subtle to human observers and highlight vulnerabilities in a model's ability\nto generalize from its training data. Several adversarial attacks can create\nsuch examples, each with a different perspective, effectiveness, and\nperceptibility of changes. Conversely, defending against such adversarial\nattacks improves the robustness of ML models in image processing and other\ndomains of deep learning. Most defence mechanisms require either a level of\nmodel awareness, changes to the model, or access to a comprehensive set of\nadversarial examples during training, which is impractical. Another option is\nto use an auxiliary model in a preprocessing manner without changing the\nprimary model. This study presents a practical and effective solution -- using\npredictive coding networks (PCnets) as an auxiliary step for adversarial\ndefence. By seamlessly integrating PCnets into feed-forward networks as a\npreprocessing step, we substantially bolster resilience to adversarial\nperturbations. Our experiments on MNIST and CIFAR10 demonstrate the remarkable\neffectiveness of PCnets in mitigating adversarial examples with about 82% and\n65% improvements in robustness, respectively. The PCnet, trained on a small\nsubset of the dataset, leverages its generative nature to effectively counter\nadversarial efforts, reverting perturbed images closer to their original forms.\nThis innovative approach holds promise for enhancing the security and\nreliability of neural network classifiers in the face of the escalating threat\nof adversarial attacks.",
      "tldr_zh": "这篇论文提出了一种使用 Predictive Coding Networks (PCnets) 作为预处理步骤来保护 Feed-Forward Networks 免受 adversarial attacks 的方法，避免了修改主要模型或依赖全面训练数据的需求。PCnets 通过其生成特性，将对抗扰动图像恢复至接近原始形式，从而显著提升模型的鲁棒性。在 MNIST 和 CIFAR10 数据集上的实验显示，该方法分别提高了约 82% 和 65% 的鲁棒性。这种创新方法为增强神经网络分类器的安全性和可靠性提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00222v1",
      "published_date": "2024-10-31 21:38:05 UTC",
      "updated_date": "2024-10-31 21:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:21:48.459683"
    },
    {
      "arxiv_id": "2411.00217v1",
      "title": "ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Lei",
        "Yunfei Ge",
        "Quanyan Zhu"
      ],
      "abstract": "The integration of AI into modern critical infrastructure systems, such as\nhealthcare, has introduced new vulnerabilities that can significantly impact\nworkflow, efficiency, and safety. Additionally, the increased connectivity has\nmade traditional human-driven penetration testing insufficient for assessing\nrisks and developing remediation strategies. Consequently, there is a pressing\nneed for a distributed, adaptive, and efficient automated penetration testing\nframework that not only identifies vulnerabilities but also provides\ncountermeasures to enhance security posture. This work presents ADAPT, a\ngame-theoretic and neuro-symbolic framework for automated distributed adaptive\npenetration testing, specifically designed to address the unique cybersecurity\nchallenges of AI-enabled healthcare infrastructure networks. We use a\nhealthcare system case study to illustrate the methodologies within ADAPT. The\nproposed solution enables a learning-based risk assessment. Numerical\nexperiments are used to demonstrate effective countermeasures against various\ntactical techniques employed by adversarial AI.",
      "tldr_zh": "这篇论文提出了 ADAPT 框架，这是一个基于 Game-Theoretic（博弈论）和 Neuro-Symbolic（神经符号）的自动化分布式自适应渗透测试系统，旨在应对 AI 整合到医疗保健等关键基础设施中引发的网络安全漏洞。框架通过学习-based 风险评估和案例研究，专注于识别漏洞并提供有效对策，以提升系统安全。数值实验证明，ADAPT 对抗对手 AI 的战术技术显示出显著效果，为自动化安全策略提供了可靠解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00217v1",
      "published_date": "2024-10-31 21:32:17 UTC",
      "updated_date": "2024-10-31 21:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:21:59.253557"
    },
    {
      "arxiv_id": "2411.00891v2",
      "title": "Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images",
      "title_zh": "翻译失败",
      "authors": [
        "Arianna Bunnell",
        "Dustin Valdez",
        "Thomas K. Wolfgruber",
        "Brandon Quon",
        "Kailee Hung",
        "Brenda Y. Hernandez",
        "Todd B. Seto",
        "Jeffrey Killeen",
        "Marshall Miyoshi",
        "Peter Sadowski",
        "John A. Shepherd"
      ],
      "abstract": "Background: Breast density, as derived from mammographic images and defined\nby the American College of Radiology's Breast Imaging Reporting and Data System\n(BI-RADS), is one of the strongest risk factors for breast cancer. Breast\nultrasound (BUS) is an alternative breast cancer screening modality,\nparticularly useful for early detection in low-resource, rural contexts. The\npurpose of this study was to explore an artificial intelligence (AI) model to\npredict BI-RADS mammographic breast density category from clinical, handheld\nBUS imaging. Methods: All data are sourced from the Hawaii and Pacific Islands\nMammography Registry. We compared deep learning methods from BUS imaging, as\nwell as machine learning models from image statistics alone. The use of\nAI-derived BUS density as a risk factor for breast cancer was then compared to\nclinical BI-RADS breast density while adjusting for age. The BUS data were\nsplit by individual into 70/20/10% groups for training, validation, and\ntesting. Results: 405,120 clinical BUS images from 14.066 women were selected\nfor inclusion in this study, resulting in 9.846 women for training (302,574\nimages), 2,813 for validation (11,223 images), and 1,406 for testing (4,042\nimages). On the held-out testing set, the strongest AI model achieves AUROC\n0.854 predicting BI-RADS mammographic breast density from BUS imaging and\noutperforms all shallow machine learning methods based on image statistics. In\ncancer risk prediction, age-adjusted AI BUS breast density predicted 5-year\nbreast cancer risk with 0.633 AUROC, as compared to 0.637 AUROC from\nage-adjusted clinical breast density. Conclusions: BI-RADS mammographic breast\ndensity can be estimated from BUS imaging with high accuracy using a deep\nlearning model. Furthermore, we demonstrate that AI-derived BUS breast density\nis predictive of 5-year breast cancer risk in our population.",
      "tldr_zh": "本研究使用深度学习模型从临床乳房超声（BUS）图像预测乳房X线照相（mammography）中的BI-RADS乳房密度类别，以评估其作为乳腺癌风险因素的潜力。研究分析了来自夏威夷和太平洋岛屿乳房X线照相登记处的405,120张BUS图像，通过70/20/10%的训练/验证/测试分割，AI模型在测试集上达到AUROC 0.854的准确率，并优于基于图像统计的浅层机器学习方法。在预测5年乳腺癌风险时，年龄调整后的AI导出的BUS乳房密度AUROC为0.633，与临床BI-RADS密度的0.637相当。该方法证明了从BUS图像准确估计乳房密度的可行性，并为低资源环境下的乳腺癌筛查提供了新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00891v2",
      "published_date": "2024-10-31 21:28:20 UTC",
      "updated_date": "2024-11-07 21:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:22:12.892827"
    },
    {
      "arxiv_id": "2411.00208v2",
      "title": "Using Large Language Models for a standard assessment mapping for sustainable communities",
      "title_zh": "使用大语言模型进行可持续社区的标准评估映射",
      "authors": [
        "Luc Jonveaux"
      ],
      "abstract": "This paper presents a new approach to urban sustainability assessment through\nthe use of Large Language Models (LLMs) to streamline the use of the ISO 37101\nframework to automate and standardise the assessment of urban initiatives\nagainst the six \"sustainability purposes\" and twelve \"issues\" outlined in the\nstandard. The methodology includes the development of a custom prompt based on\nthe standard definitions and its application to two different datasets: 527\nprojects from the Paris Participatory Budget and 398 activities from the\nPROBONO Horizon 2020 project. The results show the effectiveness of LLMs in\nquickly and consistently categorising different urban initiatives according to\nsustainability criteria. The approach is particularly promising when it comes\nto breaking down silos in urban planning by providing a holistic view of the\nimpact of projects. The paper discusses the advantages of this method over\ntraditional human-led assessments, including significant time savings and\nimproved consistency. However, it also points out the importance of human\nexpertise in interpreting results and ethical considerations. This study\nhopefully can contribute to the growing body of work on AI applications in\nurban planning and provides a novel method for operationalising standardised\nsustainability frameworks in different urban contexts.",
      "tldr_zh": "本论文提出了一种新方法，使用 Large Language Models (LLMs) 来简化 ISO 37101 框架的应用，从而自动化和标准化城市举措的评估，针对六个“sustainability purposes”和十二个“issues”。方法包括开发自定义提示，并应用于巴黎参与式预算的527个项目和PROBONO Horizon 2020的398个活动，结果显示LLMs能快速、一致地分类城市举措，提供整体影响视图，并打破城市规划中的孤岛。相比传统人工评估，该方法显著节省时间并提高一致性，但强调需要人类专家解读结果并考虑伦理问题。该研究为AI在城市规划中的应用提供了创新途径，推动可持续性框架在不同城市语境中的实际操作。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4.3"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00208v2",
      "published_date": "2024-10-31 21:07:58 UTC",
      "updated_date": "2024-11-25 12:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:22:22.972154"
    },
    {
      "arxiv_id": "2412.19808v1",
      "title": "AI-driven Automation as a Pre-condition for Eudaimonia",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasia Siapka"
      ],
      "abstract": "The debate surrounding the 'future of work' is saturated with alarmist\nwarnings about the loss of work as an intrinsically valuable activity. Instead,\nthe present doctoral research approaches this debate from the perspective of\nhuman flourishing (eudaimonia). It articulates a neo-Aristotelian\ninterpretation according to which the prospect of mass AI-driven automation,\nfar from being a threat, is rather desirable insofar as it facilitates humans'\nflourishing and, subsequently, their engagement in leisure. Drawing on virtue\njurisprudence, this research further explores what this desirability may imply\nfor the current legal order.",
      "tldr_zh": "这篇博士研究从人类繁荣（eudaimonia）的视角重新审视AI驱动自动化（AI-driven automation）的未来工作辩论，认为它并非威胁，而是促进人类繁荣和休闲的可取条件。研究采用新亚里士多德主义（neo-Aristotelian interpretation）的框架，强调自动化能解放人类从事更有意义活动。进一步，通过美德法学（virtue jurisprudence）的 lens，探讨这对当前法律秩序的潜在含义。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19808v1",
      "published_date": "2024-10-31 20:57:38 UTC",
      "updated_date": "2024-10-31 20:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:23:26.997214"
    },
    {
      "arxiv_id": "2411.00205v2",
      "title": "Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning",
      "title_zh": "用于目标条件化强化学习的组合自动机嵌入",
      "authors": [
        "Beyazit Yalcinkaya",
        "Niklas Lauffer",
        "Marcell Vazquez-Chanlatte",
        "Sanjit A. Seshia"
      ],
      "abstract": "Goal-conditioned reinforcement learning is a powerful way to control an AI\nagent's behavior at runtime. That said, popular goal representations, e.g.,\ntarget states or natural language, are either limited to Markovian tasks or\nrely on ambiguous task semantics. We propose representing temporal goals using\ncompositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL\nagents. cDFAs balance the need for formal temporal semantics with ease of\ninterpretation: if one can understand a flow chart, one can understand a cDFA.\nOn the other hand, cDFAs form a countably infinite concept class with Boolean\nsemantics, and subtle changes to the automaton can result in very different\ntasks, making them difficult to condition agent behavior on. To address this,\nwe observe that all paths through a DFA correspond to a series of reach-avoid\ntasks and propose pre-training graph neural network embeddings on \"reach-avoid\nderived\" DFAs. Through empirical evaluation, we demonstrate that the proposed\npre-training method enables zero-shot generalization to various cDFA task\nclasses and accelerated policy specialization without the myopic suboptimality\nof hierarchical methods.",
      "tldr_zh": "该论文针对目标条件强化学习（Goal-conditioned reinforcement learning）的目标表示问题，提出使用组合确定性有限自动机（cDFAs）来表示时间目标，从而提供正式的语义并易于解释。作者观察到 DFA 的路径对应于 reach-avoid 任务，并通过在“reach-avoid derived” DFAs 上预训练图神经网络嵌入（Graph Neural Network embeddings），来解决 cDFAs 的语义复杂性和任务差异问题。实验结果表明，这种方法实现了对各种 cDFA 任务类的零样本泛化（zero-shot generalization），并加速了策略专业化，同时避免了分层方法的短视次优性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00205v2",
      "published_date": "2024-10-31 20:56:07 UTC",
      "updated_date": "2025-01-15 01:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:23:40.205590"
    },
    {
      "arxiv_id": "2411.00196v1",
      "title": "Whole-Herd Elephant Pose Estimation from Drone Data for Collective Behavior Analysis",
      "title_zh": "基于无人机数据的象群整体姿态",
      "authors": [
        "Brody McNutt",
        "Libby Zhang",
        "Angus Carey-Douglas",
        "Fritz Vollrath",
        "Frank Pope",
        "Leandra Brickson"
      ],
      "abstract": "This research represents a pioneering application of automated pose\nestimation from drone data to study elephant behavior in the wild, utilizing\nvideo footage captured from Samburu National Reserve, Kenya. The study\nevaluates two pose estimation workflows: DeepLabCut, known for its application\nin laboratory settings and emerging wildlife fieldwork, and YOLO-NAS-Pose, a\nnewly released pose estimation model not previously applied to wildlife\nbehavioral studies. These models are trained to analyze elephant herd behavior,\nfocusing on low-resolution ($\\sim$50 pixels) subjects to detect key points such\nas the head, spine, and ears of multiple elephants within a frame. Both\nworkflows demonstrated acceptable quality of pose estimation on the test set,\nfacilitating the automated detection of basic behaviors crucial for studying\nelephant herd dynamics. For the metrics selected for pose estimation evaluation\non the test set -- root mean square error (RMSE), percentage of correct\nkeypoints (PCK), and object keypoint similarity (OKS) -- the YOLO-NAS-Pose\nworkflow outperformed DeepLabCut. Additionally, YOLO-NAS-Pose exceeded\nDeepLabCut in object detection evaluation. This approach introduces a novel\nmethod for wildlife behavioral research, including the burgeoning field of\nwildlife drone monitoring, with significant implications for wildlife\nconservation.",
      "tldr_zh": "这篇论文首次利用无人机数据进行整群大象姿势估计，旨在分析野生大象的集体行为，基于肯尼亚Samburu National Reserve的视频素材。研究评估了两种模型：DeepLabCut和YOLO-NAS-Pose，前者适用于实验室和野外，后者是新模型首次应用于野生动物研究，均针对低分辨率（约50像素）图像检测关键点如头部、脊椎和耳朵。结果显示，YOLO-NAS-Pose在评估指标RMSE、PCK和OKS上优于DeepLabCut，并在物体检测方面表现出色。总体而言，此方法为野生动物行为研究和无人机监测领域引入创新途径，具有重要意义，对野生动物保护带来积极影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CV4Animals: Computer Vision for Animal Behavior Tracking\n  and Modeling Workshop in conjunction with Computer Vision and Pattern\n  Recognition 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00196v1",
      "published_date": "2024-10-31 20:26:59 UTC",
      "updated_date": "2024-10-31 20:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:23:52.203868"
    },
    {
      "arxiv_id": "2411.00890v1",
      "title": "Rethinking Scale: The Efficacy of Fine-Tuned Open-Source LLMs in Large-Scale Reproducible Social Science Research",
      "title_zh": "翻译失败",
      "authors": [
        "Marcello Carammia",
        "Stefano Maria Iacus",
        "Giuseppe Porro"
      ],
      "abstract": "Large Language Models (LLMs) are distinguished by their architecture, which\ndictates their parameter size and performance capabilities. Social scientists\nhave increasingly adopted LLMs for text classification tasks, which are\ndifficult to scale with human coders. While very large, closed-source models\noften deliver superior performance, their use presents significant risks. These\ninclude lack of transparency, potential exposure of sensitive data, challenges\nto replicability, and dependence on proprietary systems. Additionally, their\nhigh costs make them impractical for large-scale research projects.\n  In contrast, open-source models, although available in various sizes, may\nunderperform compared to commercial alternatives if used without further\nfine-tuning. However, open-source models offer distinct advantages: they can be\nrun locally (ensuring data privacy), fine-tuned for specific tasks, shared\nwithin the research community, and integrated into reproducible workflows.\n  This study demonstrates that small, fine-tuned open-source LLMs can achieve\nequal or superior performance to models such as ChatGPT-4. We further explore\nthe relationship between training set size and fine-tuning efficacy in\nopen-source models. Finally, we propose a hybrid workflow that leverages the\nstrengths of both open and closed models, offering a balanced approach to\nperformance, transparency, and reproducibility.",
      "tldr_zh": "本研究重新审视了开源 LLMs 在大规模可复制社会科学研究中的效能，强调微调后的小型开源模型能解决封闭源模型如 ChatGPT-4 的透明度、数据隐私和成本问题。研究发现，通过细调，中小型开源 LLMs 的文本分类性能可达到或超过 ChatGPT-4，同时探索了训练集大小对微调效果的影响。最终，论文提出了一种混合工作流，结合开源和封闭模型的优势，以实现性能、透明度和可复制性的平衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00890v1",
      "published_date": "2024-10-31 20:26:30 UTC",
      "updated_date": "2024-10-31 20:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:24:03.852055"
    },
    {
      "arxiv_id": "2411.00190v2",
      "title": "Monitoring fairness in machine learning models that predict patient mortality in the ICU",
      "title_zh": "翻译失败",
      "authors": [
        "Tempest A. van Schaik",
        "Xinggang Liu",
        "Louis Atallah",
        "Omar Badawi"
      ],
      "abstract": "This work proposes a fairness monitoring approach for machine learning models\nthat predict patient mortality in the ICU. We investigate how well models\nperform for patient groups with different race, sex and medical diagnoses. We\ninvestigate Documentation bias in clinical measurement, showing how fairness\nanalysis provides a more detailed and insightful comparison of model\nperformance than traditional accuracy metrics alone.",
      "tldr_zh": "本研究提出了一种公平性监控方法，用于评估预测 ICU 患者死亡率的机器学习模型在不同种族、性别和医疗诊断患者群体中的表现。该方法通过调查模型性能差异，揭示临床测量中的 Documentation bias，并证明公平性分析比传统准确性指标提供更详细和深刻的性能比较。通过这种方式，研究为构建更公正的医疗预测模型提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00190v2",
      "published_date": "2024-10-31 20:17:12 UTC",
      "updated_date": "2024-11-06 20:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:24:14.761754"
    },
    {
      "arxiv_id": "2411.00188v1",
      "title": "Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis",
      "title_zh": "构建多智能体 Copilot 以实现自治农业数据管理和分析",
      "authors": [
        "Yu Pan",
        "Jianxin Sun",
        "Hongfeng Yu",
        "Joe Luck",
        "Geng Bai",
        "Nipuna Chamara",
        "Yufeng Ge",
        "Tala Awada"
      ],
      "abstract": "Current agricultural data management and analysis paradigms are to large\nextent traditional, in which data collecting, curating, integration, loading,\nstoring, sharing and analyzing still involve too much human effort and\nknow-how. The experts, researchers and the farm operators need to understand\nthe data and the whole process of data management pipeline to make fully use of\nthe data. The essential problem of the traditional paradigm is the lack of a\nlayer of orchestrational intelligence which can understand, organize and\ncoordinate the data processing utilities to maximize data management and\nanalysis outcome. The emerging reasoning and tool mastering abilities of large\nlanguage models (LLM) make it a potentially good fit to this position, which\nhelps a shift from the traditional user-driven paradigm to AI-driven paradigm.\nIn this paper, we propose and explore the idea of a LLM based copilot for\nautonomous agricultural data management and analysis. Based on our previously\ndeveloped platform of Agricultural Data Management and Analytics (ADMA), we\nbuild a proof-of-concept multi-agent system called ADMA Copilot, which can\nunderstand user's intent, makes plans for data processing pipeline and\naccomplishes tasks automatically, in which three agents: a LLM based\ncontroller, an input formatter and an output formatter collaborate together.\nDifferent from existing LLM based solutions, by defining a meta-program graph,\nour work decouples control flow and data flow to enhance the predictability of\nthe behaviour of the agents. Experiments demonstrates the intelligence,\nautonomy, efficacy, efficiency, extensibility, flexibility and privacy of our\nsystem. Comparison is also made between ours and existing systems to show the\nsuperiority and potential of our system.",
      "tldr_zh": "本文提出了一种基于大型语言模型（LLM）的多智能体系统ADMA Copilot，以实现农业数据管理的自治化，解决传统方法依赖过多人力和缺乏协调智能的问题。该系统包括LLM-based controller、input formatter和output formatter三个代理，通过定义meta-program graph来解耦控制流和数据流，提高代理行为的预测性和任务执行效率。实验结果显示，该系统在智能性、自治性、效率、扩展性和隐私方面表现出色，并与现有系统比较证明其优势，为AI驱动的农业数据分析范式提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00188v1",
      "published_date": "2024-10-31 20:15:14 UTC",
      "updated_date": "2024-10-31 20:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:24:27.220563"
    },
    {
      "arxiv_id": "2411.00186v1",
      "title": "Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments",
      "title_zh": "自愈机器学习：一种用于真实世界环境中自主适应的框架",
      "authors": [
        "Paulius Rauba",
        "Nabeel Seedat",
        "Krzysztof Kacprzyk",
        "Mihaela van der Schaar"
      ],
      "abstract": "Real-world machine learning systems often encounter model performance\ndegradation due to distributional shifts in the underlying data generating\nprocess (DGP). Existing approaches to addressing shifts, such as concept drift\nadaptation, are limited by their reason-agnostic nature. By choosing from a\npre-defined set of actions, such methods implicitly assume that the causes of\nmodel degradation are irrelevant to what actions should be taken, limiting\ntheir ability to select appropriate adaptations. In this paper, we propose an\nalternative paradigm to overcome these limitations, called self-healing machine\nlearning (SHML). Contrary to previous approaches, SHML autonomously diagnoses\nthe reason for degradation and proposes diagnosis-based corrective actions. We\nformalize SHML as an optimization problem over a space of adaptation actions to\nminimize the expected risk under the shifted DGP. We introduce a theoretical\nframework for self-healing systems and build an agentic self-healing solution\nH-LLM which uses large language models to perform self-diagnosis by reasoning\nabout the structure underlying the DGP, and self-adaptation by proposing and\nevaluating corrective actions. Empirically, we analyze different components of\nH-LLM to understand why and when it works, demonstrating the potential of\nself-healing ML.",
      "tldr_zh": "本论文提出了一种Self-Healing Machine Learning (SHML)框架，旨在解决机器学习系统在真实环境中因数据生成过程(DGP)分布偏移导致的性能下降问题。不同于现有方法如概念漂移适应的无原因策略，SHML自主诊断退化原因，并基于诊断提出针对性的纠正行动，将其形式化为最小化预期风险的优化问题。作者构建了H-LLM系统，利用大型语言模型(LLMs)进行DGP结构推理和自适应评估，实证结果显示H-LLM在不同场景下表现出色，证明了自愈式机器学习的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Advances in Neural Information Processing Systems 38 (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.00186v1",
      "published_date": "2024-10-31 20:05:51 UTC",
      "updated_date": "2024-10-31 20:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:24:40.438435"
    },
    {
      "arxiv_id": "2411.00178v2",
      "title": "Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy",
      "title_zh": "医疗图像合成的临床评估：无线胶囊内窥镜中的一个案例研究",
      "authors": [
        "Panagiota Gatoula",
        "Dimitrios E. Diamantis",
        "Anastasios Koulaouzidis",
        "Cristina Carretero",
        "Stefania Chetcuti-Zammit",
        "Pablo Cortegoso Valdivia",
        "Begoña González-Suárez",
        "Alessandro Mussetto",
        "John Plevris",
        "Alexander Robertson",
        "Bruno Rosa",
        "Ervin Toth",
        "Dimitris K. Iakovidis"
      ],
      "abstract": "Synthetic Data Generation (SDG) based on Artificial Intelligence (AI) can\ntransform the way clinical medicine is delivered by overcoming privacy barriers\nthat currently render clinical data sharing difficult. This is the key to\naccelerating the development of digital tools contributing to enhanced patient\nsafety. Such tools include robust data-driven clinical decision support\nsystems, and example-based digital training tools that will enable healthcare\nprofessionals to improve their diagnostic performance for enhanced patient\nsafety. This study focuses on the clinical evaluation of medical SDG, with a\nproof-of-concept investigation on diagnosing Inflammatory Bowel Disease (IBD)\nusing Wireless Capsule Endoscopy (WCE) images. Its scientific contributions\ninclude a) a novel protocol for the systematic Clinical Evaluation of Medical\nImage Synthesis (CEMIS); b) a novel variational autoencoder-based model for the\ngeneration of high-resolution synthetic WCE images; and c) a comprehensive\nevaluation of the synthetic images using the CEMIS protocol by 10 international\nWCE specialists, in terms of image quality, diversity, and realism, as well as\ntheir utility for clinical decision-making. The results show that TIDE-II\ngenerates clinically plausible, very realistic WCE images, of improved quality\ncompared to relevant state-of-the-art generative models. Concludingly, CEMIS\ncan serve as a reference for future research on medical image-generation\ntechniques, while the adaptation/extension of the architecture of TIDE-II to\nother imaging domains can be promising.",
      "tldr_zh": "这篇论文探讨了使用人工智能（AI）生成合成数据（Synthetic Data Generation, SDG）来克服临床数据共享的隐私障碍，从而加速医疗工具开发并提升患者安全。研究提出了一种新型系统性协议（Clinical Evaluation of Medical Image Synthesis, CEMIS）和基于变分自编码器（variational autoencoder）的模型 TIDE-II，用于生成高分辨率合成无线胶囊内镜（Wireless Capsule Endoscopy, WCE）图像，以辅助诊断炎症性肠病（Inflammatory Bowel Disease, IBD）。通过 10 名国际专家的全面评估，结果显示 TIDE-II 生成的图像在质量、多样性和真实性方面优于现有模型，并证明其在临床决策中的实用性；最终，CEMIS 可作为未来医疗图像生成研究的参考，而 TIDE-II 的架构有望扩展到其他成像领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted for possible journal publication",
      "pdf_url": "http://arxiv.org/pdf/2411.00178v2",
      "published_date": "2024-10-31 19:48:50 UTC",
      "updated_date": "2025-03-09 06:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:24:52.588241"
    },
    {
      "arxiv_id": "2411.00173v2",
      "title": "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning",
      "title_zh": "超越标签注意力：通过字典学习实现语言模型在自动化医疗编码中的透明度",
      "authors": [
        "John Wu",
        "David Wu",
        "Jimeng Sun"
      ],
      "abstract": "Medical coding, the translation of unstructured clinical text into\nstandardized medical codes, is a crucial but time-consuming healthcare\npractice. Though large language models (LLM) could automate the coding process\nand improve the efficiency of such tasks, interpretability remains paramount\nfor maintaining patient trust. Current efforts in interpretability of medical\ncoding applications rely heavily on label attention mechanisms, which often\nleads to the highlighting of extraneous tokens irrelevant to the ICD code. To\nfacilitate accurate interpretability in medical language models, this paper\nleverages dictionary learning that can efficiently extract sparsely activated\nrepresentations from dense language model embeddings in superposition. Compared\nwith common label attention mechanisms, our model goes beyond token-level\nrepresentations by building an interpretable dictionary which enhances the\nmechanistic-based explanations for each ICD code prediction, even when the\nhighlighted tokens are medically irrelevant. We show that dictionary features\ncan steer model behavior, elucidate the hidden meanings of upwards of 90% of\nmedically irrelevant tokens, and are human interpretable.",
      "tldr_zh": "本研究旨在提升医疗编码过程的可解释性，该过程涉及将非结构化临床文本转化为标准化医疗代码（如 ICD code），以提高效率并维护患者信任。现有方法依赖标签注意力（label attention）机制，但常突出无关标记；为此，论文引入字典学习（dictionary learning）从密集语言模型（LLM）嵌入中提取稀疏激活表示（sparsely activated representations），构建可解释字典以提供更准确的机制解释。结果显示，该方法能引导模型行为，阐明超过90%的 medically irrelevant 标记，并确保这些解释易于人类理解，从而超越传统注意力机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "https://aclanthology.org/2024.emnlp-main.500/",
      "pdf_url": "http://arxiv.org/pdf/2411.00173v2",
      "published_date": "2024-10-31 19:39:40 UTC",
      "updated_date": "2025-03-22 20:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:25:02.961072"
    },
    {
      "arxiv_id": "2411.00168v1",
      "title": "Creativity in the Age of AI: Evaluating the Impact of Generative AI on Design Outputs and Designers' Creative Thinking",
      "title_zh": "AI 时代下的创造力：评估生成式 AI 对设计输出和设计师创造性思维的影响",
      "authors": [
        "Yue Fu",
        "Han Bin",
        "Tony Zhou",
        "Marx Wang",
        "Yixin Chen",
        "Zelia Gomes Da Costa Lai",
        "Jacob O. Wobbrock",
        "Alexis Hiniker"
      ],
      "abstract": "As generative AI (GenAI) increasingly permeates design workflows, its impact\non design outcomes and designers' creative capabilities warrants investigation.\nWe conducted a within-subjects experiment where we asked participants to design\nadvertisements both with and without GenAI support. Our results show that\nexpert evaluators rated GenAI-supported designs as more creative and\nunconventional (\"weird\") despite no significant differences in visual appeal,\nbrand alignment, or usefulness, which highlights the decoupling of novelty from\nusefulness-traditional dual components of creativity-in the context of GenAI\nusage. Moreover, while GenAI does not significantly enhance designers' overall\ncreative thinking abilities, users were affected differently based on native\nlanguage and prior AI exposure. Native English speakers experienced reduced\nrelaxation when using AI, whereas designers new to GenAI exhibited gains in\ndivergent thinking, such as idea fluency and flexibility. These findings\nunderscore the variable impact of GenAI on different user groups, suggesting\nthe potential for customized AI tools.",
      "tldr_zh": "这篇论文评估了 Generative AI (GenAI) 对设计输出和设计师创意思考的影响，通过内部受试者实验，让参与者使用和不使用 GenAI 设计广告。结果显示，专家评估认为 GenAI 支持的设计更具创意和非传统性（“weird”），但在视觉吸引力、品牌一致性和有用性上无显著差异，这突显了新颖性与有用性在 GenAI 上下文中的分离。GenAI 并未显著提升设计师的整体创意思考能力，但其影响因用户群体不同而异：英语母语者使用时放松度降低，而 AI 新手在发散性思考（如想法流畅性和灵活性）上表现出改善。研究建议开发定制化 AI 工具，以适应不同用户的需要。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00168v1",
      "published_date": "2024-10-31 19:23:34 UTC",
      "updated_date": "2024-10-31 19:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:25:16.575027"
    },
    {
      "arxiv_id": "2411.00163v1",
      "title": "PSL: Rethinking and Improving Softmax Loss from Pairwise Perspective for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqin Yang",
        "Jiawei Chen",
        "Xin Xin",
        "Sheng Zhou",
        "Binbin Hu",
        "Yan Feng",
        "Chun Chen",
        "Can Wang"
      ],
      "abstract": "Softmax Loss (SL) is widely applied in recommender systems (RS) and has\ndemonstrated effectiveness. This work analyzes SL from a pairwise perspective,\nrevealing two significant limitations: 1) the relationship between SL and\nconventional ranking metrics like DCG is not sufficiently tight; 2) SL is\nhighly sensitive to false negative instances. Our analysis indicates that these\nlimitations are primarily due to the use of the exponential function. To\naddress these issues, this work extends SL to a new family of loss functions,\ntermed Pairwise Softmax Loss (PSL), which replaces the exponential function in\nSL with other appropriate activation functions. While the revision is minimal,\nwe highlight three merits of PSL: 1) it serves as a tighter surrogate for DCG\nwith suitable activation functions; 2) it better balances data contributions;\nand 3) it acts as a specific BPR loss enhanced by Distributionally Robust\nOptimization (DRO). We further validate the effectiveness and robustness of PSL\nthrough empirical experiments. The code is available at\nhttps://github.com/Tiny-Snow/IR-Benchmark.",
      "tldr_zh": "本文从pairwise视角重新审视Softmax Loss (SL)在推荐系统中的应用，揭示其两个主要局限：与DCG等排名指标关联不够紧密，以及对假负样本高度敏感，这些问题源于指数函数的使用。作者提出Pairwise Softmax Loss (PSL)，通过替换指数函数为其他激活函数，构建一个新的损失函数家族。PSL的优势包括作为DCG的更紧密代理、更好地平衡数据贡献，以及相当于通过Distributionally Robust Optimization (DRO)增强的BPR损失。实验结果证实了PSL的有效性和鲁棒性，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00163v1",
      "published_date": "2024-10-31 19:11:26 UTC",
      "updated_date": "2024-10-31 19:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:25:27.860282"
    },
    {
      "arxiv_id": "2411.00156v1",
      "title": "Unlocking the Potential of Global Human Expertise",
      "title_zh": "释放全球人类专业知识的潜力",
      "authors": [
        "Elliot Meyerson",
        "Olivier Francon",
        "Darren Sargent",
        "Babak Hodjat",
        "Risto Miikkulainen"
      ],
      "abstract": "Solving societal problems on a global scale requires the collection and\nprocessing of ideas and methods from diverse sets of international experts. As\nthe number and diversity of human experts increase, so does the likelihood that\nelements in this collective knowledge can be combined and refined to discover\nnovel and better solutions. However, it is difficult to identify, combine, and\nrefine complementary information in an increasingly large and diverse knowledge\nbase. This paper argues that artificial intelligence (AI) can play a crucial\nrole in this process. An evolutionary AI framework, termed RHEA, fills this\nrole by distilling knowledge from diverse models created by human experts into\nequivalent neural networks, which are then recombined and refined in a\npopulation-based search. The framework was implemented in a formal synthetic\ndomain, demonstrating that it is transparent and systematic. It was then\napplied to the results of the XPRIZE Pandemic Response Challenge, in which over\n100 teams of experts across 23 countries submitted models based on diverse\nmethodologies to predict COVID-19 cases and suggest non-pharmaceutical\nintervention policies for 235 nations, states, and regions across the globe.\nBuilding upon this expert knowledge, by recombining and refining the 169\nresulting policy suggestion models, RHEA discovered a broader and more\neffective set of policies than either AI or human experts alone, as evaluated\nbased on real-world data. The results thus suggest that AI can play a crucial\nrole in realizing the potential of human expertise in global problem-solving.",
      "tldr_zh": "这篇论文探讨了如何通过人工智能（AI）整合全球人类专家的多样化知识，以解决大规模社会问题，强调了在庞大知识库中识别、组合和提炼互补信息的挑战。作者提出了一种进化AI框架RHEA，该框架将专家创建的模型提炼成等效神经网络，并在基于种群的搜索中重组和优化，以发现更有效的解决方案。在XPRIZE Pandemic Response Challenge中应用RHEA后，它基于169个COVID-19政策模型生成了比人类或AI单独更广泛和高效的政策建议，证明了AI在释放人类专业知识潜力的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024; Main Paper 15 pages, Appendix 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.00156v1",
      "published_date": "2024-10-31 19:02:00 UTC",
      "updated_date": "2024-10-31 19:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:25:41.076793"
    },
    {
      "arxiv_id": "2411.00154v2",
      "title": "Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haritz Puerto",
        "Martin Gubri",
        "Sangdoo Yun",
        "Seong Joon Oh"
      ],
      "abstract": "Membership inference attacks (MIA) attempt to verify the membership of a\ngiven data sample in the training set for a model. MIA has become relevant in\nrecent years, following the rapid development of large language models (LLM).\nMany are concerned about the usage of copyrighted materials for training them\nand call for methods for detecting such usage. However, recent research has\nlargely concluded that current MIA methods do not work on LLMs. Even when they\nseem to work, it is usually because of the ill-designed experimental setup\nwhere other shortcut features enable \"cheating.\" In this work, we argue that\nMIA still works on LLMs, but only when multiple documents are presented for\ntesting. We construct new benchmarks that measure the MIA performances at a\ncontinuous scale of data samples, from sentences (n-grams) to a collection of\ndocuments (multiple chunks of tokens). To validate the efficacy of current MIA\napproaches at greater scales, we adapt a recent work on Dataset Inference (DI)\nfor the task of binary membership detection that aggregates paragraph-level MIA\nfeatures to enable MIA at document and collection of documents level. This\nbaseline achieves the first successful MIA on pre-trained and fine-tuned LLMs.",
      "tldr_zh": "本文研究了Membership Inference Attacks (MIA)，即检测数据样本是否在Large Language Models (LLM)训练集中的方法，并挑战了现有结论，即MIA在LLM上无效。作者构建了新的基准，从句子（n-grams）到多个文档的连续规模，改编Dataset Inference (DI)方法通过聚合段落级MIA特征，实现文档级和文档集合级的二元成员检测。实验结果显示，这一方法在预训练和细调LLM上首次成功，证明了MIA在更大数据规模下的有效性，为检测版权材料使用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of NAACL 2025. Our code is available at\n  https://github.com/parameterlab/mia-scaling",
      "pdf_url": "http://arxiv.org/pdf/2411.00154v2",
      "published_date": "2024-10-31 18:59:46 UTC",
      "updated_date": "2025-02-03 15:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:25:52.077911"
    },
    {
      "arxiv_id": "2411.00150v2",
      "title": "Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Richardson",
        "Roshan Sharma",
        "Neeraj Gaur",
        "Parisa Haghani",
        "Anirudh Sundar",
        "Bhuvana Ramabhadran"
      ],
      "abstract": "Zero-shot domain adaptation for dialogue state tracking (DST) remains a\nchallenging problem in task-oriented dialogue (TOD) systems, where models must\ngeneralize to target domains unseen at training time. Current large language\nmodel approaches for zero-shot domain adaptation rely on prompting to introduce\nknowledge pertaining to the target domains. However, their efficacy strongly\ndepends on prompt engineering, as well as the zero-shot ability of the\nunderlying language model. In this work, we devise a novel data augmentation\napproach, Schema Augmentation, that improves the zero-shot domain adaptation of\nlanguage models through fine-tuning. Schema Augmentation is a simple but\neffective technique that enhances generalization by introducing variations of\nslot names within the schema provided in the prompt. Experiments on MultiWOZ\nand SpokenWOZ showed that the proposed approach resulted in a substantial\nimprovement over the baseline, in some experiments achieving over a twofold\naccuracy gain over unseen domains while maintaining equal or superior\nperformance over all domains.",
      "tldr_zh": "该论文针对对话状态跟踪 (DST) 在任务导向对话 (TOD) 系统中的零样本域适应挑战，提出了一种名为 Schema Augmentation 的数据增强方法，通过在提示中引入槽位名称变体来微调语言模型，从而提升模型对未见域的泛化能力。不同于依赖提示工程的传统方法，该技术简单有效，能够增强模型的鲁棒性。在 MultiWOZ 和 SpokenWOZ 数据集上的实验表明，Schema Augmentation 使未见域的准确率提高了两倍以上，同时保持或超过了所有域的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "short paper (4 pages) submitted to ARR",
      "pdf_url": "http://arxiv.org/pdf/2411.00150v2",
      "published_date": "2024-10-31 18:57:59 UTC",
      "updated_date": "2025-02-21 18:54:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:26:03.790961"
    },
    {
      "arxiv_id": "2411.00146v2",
      "title": "Responsibility-aware Strategic Reasoning in Probabilistic Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyan Mu",
        "Muhammad Najib",
        "Nir Oren"
      ],
      "abstract": "Responsibility plays a key role in the development and deployment of\ntrustworthy autonomous systems. In this paper, we focus on the problem of\nstrategic reasoning in probabilistic multi-agent systems with\nresponsibility-aware agents. We introduce the logic PATL+R, a variant of\nProbabilistic Alternating-time Temporal Logic. The novelty of PATL+R lies in\nits incorporation of modalities for causal responsibility, providing a\nframework for responsibility-aware multi-agent strategic reasoning. We present\nan approach to synthesise joint strategies that satisfy an outcome specified in\nPATL+R, while optimising the share of expected causal responsibility and\nreward. This provides a notion of balanced distribution of responsibility and\nreward gain among agents. To this end, we utilise the Nash equilibrium as the\nsolution concept for our strategic reasoning problem and demonstrate how to\ncompute responsibility-aware Nash equilibrium strategies via a reduction to\nparametric model checking of concurrent stochastic multi-player games.",
      "tldr_zh": "该论文探讨了责任（responsibility）在概率多智能体系统中的战略推理问题，引入了 PATL+R 逻辑，这是一种扩展的 Probabilistic Alternating-time Temporal Logic，加入了因果责任（causal responsibility）模态以支持责任感知的多智能体决策。研究提出了一种合成联合策略的方法，能够满足 PATL+R 中指定的结果，同时优化代理间的预期因果责任份额和奖励收益，实现责任和回报的平衡分布。最终，通过将问题归约到参数模型检查的并发随机多玩家游戏，并采用 Nash equilibrium 作为解决方案概念，论文展示了如何计算责任感知的 Nash 均衡策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00146v2",
      "published_date": "2024-10-31 18:49:12 UTC",
      "updated_date": "2024-12-20 10:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:26:16.166841"
    },
    {
      "arxiv_id": "2411.00887v1",
      "title": "Measuring Responsibility in Multi-Agent Systems",
      "title_zh": "多智能体系统的责任测量",
      "authors": [
        "Chunyan Mu",
        "Nir Oren"
      ],
      "abstract": "We introduce a family of quantitative measures of responsibility in\nmulti-agent planning, building upon the concepts of causal responsibility\nproposed by Parker et al.~[ParkerGL23]. These concepts are formalised within a\nvariant of probabilistic alternating-time temporal logic. Unlike existing\napproaches, our framework ascribes responsibility to agents for a given outcome\nby linking probabilities between behaviours and responsibility through three\nmetrics, including an entropy-based measurement of responsibility. This latter\nmeasure is the first to capture the causal responsibility properties of\noutcomes over time, offering an asymptotic measurement that reflects the\ndifficulty of achieving these outcomes. Our approach provides a fresh\nunderstanding of responsibility in multi-agent systems, illuminating both the\nqualitative and quantitative aspects of agents' roles in achieving or\npreventing outcomes.",
      "tldr_zh": "本论文基于因果责任（causal responsibility）的概念，引入了一系列量化责任度量，用于多智能体系统（multi-agent systems）的规划，这些度量在概率交替时间时序逻辑（probabilistic alternating-time temporal logic）的变体中形式化。与现有方法不同，该框架通过三个指标（包括基于熵的度量）将行为概率与责任联系起来，首次捕捉了随时间变化的结果的因果责任，并提供渐进测量以反映实现这些结果的难度。该方法为多智能体系统中代理在实现或防止结果中的角色提供了新的定性和定量理解。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00887v1",
      "published_date": "2024-10-31 18:45:34 UTC",
      "updated_date": "2024-10-31 18:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:26:28.461088"
    },
    {
      "arxiv_id": "2411.00142v1",
      "title": "JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking",
      "title_zh": "JudgeRank: 利用大型语言模型进行推理密集型重新排名",
      "authors": [
        "Tong Niu",
        "Shafiq Joty",
        "Ye Liu",
        "Caiming Xiong",
        "Yingbo Zhou",
        "Semih Yavuz"
      ],
      "abstract": "Accurate document retrieval is crucial for the success of retrieval-augmented\ngeneration (RAG) applications, including open-domain question answering and\ncode completion. While large language models (LLMs) have been employed as dense\nencoders or listwise rerankers in RAG systems, they often struggle with\nreasoning-intensive tasks because they lack nuanced analysis when judging\ndocument relevance. To address this limitation, we introduce JudgeRank, a novel\nagentic reranker that emulates human cognitive processes when assessing\ndocument relevance. Our approach consists of three key steps: (1) query\nanalysis to identify the core problem, (2) document analysis to extract a\nquery-aware summary, and (3) relevance judgment to provide a concise assessment\nof document relevance. We evaluate JudgeRank on the reasoning-intensive BRIGHT\nbenchmark, demonstrating substantial performance improvements over first-stage\nretrieval methods and outperforming other popular reranking approaches. In\naddition, JudgeRank performs on par with fine-tuned state-of-the-art rerankers\non the popular BEIR benchmark, validating its zero-shot generalization\ncapability. Through comprehensive ablation studies, we demonstrate that\nJudgeRank's performance generalizes well across LLMs of various sizes while\nensembling them yields even more accurate reranking than individual models.",
      "tldr_zh": "本研究提出 JudgeRank，一种利用 Large Language Models (LLMs) 的新型代理重排器，旨在解决 RAG (Retrieval-Augmented Generation) 系统在推理密集型任务中存在的相关性判断不足问题。JudgeRank 通过三个关键步骤模拟人类认知过程：查询分析以识别核心问题、文档分析以提取查询相关摘要，以及相关性判断以评估文档相关性。在 BRIGHT 基准测试中，JudgeRank 显著优于第一阶段检索方法和其他重排器，并在 BEIR 基准上与微调的 state-of-the-art 重排器相当，展示了其零样本泛化能力。通过消融研究，证明该方法在不同规模的 LLMs 上表现稳定，且模型集成可进一步提升重排准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00142v1",
      "published_date": "2024-10-31 18:43:12 UTC",
      "updated_date": "2024-10-31 18:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:26:40.085593"
    },
    {
      "arxiv_id": "2411.00138v4",
      "title": "Learning Low-Dimensional Strain Models of Soft Robots by Looking at the Evolution of Their Shape with Application to Model-Based Control",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Valadas",
        "Maximilian Stölzle",
        "Jingyue Liu",
        "Cosimo Della Santina"
      ],
      "abstract": "Obtaining dynamic models of continuum soft robots is central to the analysis\nand control of soft robots, and researchers have devoted much attention to the\nchallenge of proposing both data-driven and first-principle solutions. Both\navenues have, however, shown their limitations; the former lacks structure and\nperforms poorly outside training data, while the latter requires significant\nsimplifications and extensive expert knowledge to be used in practice. This\npaper introduces a streamlined method for learning low-dimensional,\nphysics-based models that are both accurate and easy to interpret. We start\nwith an algorithm that uses image data (i.e., shape evolutions) to determine\nthe minimal necessary segments for describing a soft robot's movement.\nFollowing this, we apply a dynamic regression and strain sparsification\nalgorithm to identify relevant strains and define the model's dynamics. We\nvalidate our approach through simulations with various planar soft\nmanipulators, comparing its performance against other learning strategies,\nshowing that our models are both computationally efficient and 25x more\naccurate on out-of-training distribution inputs. Finally, we demonstrate that\nthanks to the capability of the method of generating physically compatible\nmodels, the learned models can be straightforwardly combined with model-based\ncontrol policies.",
      "tldr_zh": "这篇论文提出了一种基于图像数据（形状演化）学习低维应变模型的方法，用于软机器人的动态建模，以克服数据驱动和第一原理方法的局限性。该方法首先通过算法确定描述软机器人运动的最小必要段，然后应用动态回归和应变稀疏化算法来识别相关应变并定义模型动态。在模拟实验中，该模型在各种平面软机械臂上比其他学习策略准确率提高25倍，且计算效率更高。最后，该物理兼容模型可直接与基于模型的控制策略结合，实现可靠的软机器人控制。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, appearing in Proceedings of the 2025 IEEE 8th International\n  Conference on Soft Robotics (RoboSoft)",
      "pdf_url": "http://arxiv.org/pdf/2411.00138v4",
      "published_date": "2024-10-31 18:37:22 UTC",
      "updated_date": "2025-02-20 12:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:26:51.903070"
    },
    {
      "arxiv_id": "2411.00132v2",
      "title": "Beyond Accuracy: Ensuring Correct Predictions With Correct Rationales",
      "title_zh": "超越准确性：确保预测正确并伴以正确推理依据",
      "authors": [
        "Tang Li",
        "Mengmeng Ma",
        "Xi Peng"
      ],
      "abstract": "Large pretrained foundation models demonstrate exceptional performance and,\nin some high-stakes applications, even surpass human experts. However, most of\nthese models are currently evaluated primarily on prediction accuracy,\noverlooking the validity of the rationales behind their accurate predictions.\nFor the safe deployment of foundation models, there is a pressing need to\nensure double-correct predictions, i.e., correct prediction backed by correct\nrationales. To achieve this, we propose a two-phase scheme: First, we curate a\nnew dataset that offers structured rationales for visual recognition tasks.\nSecond, we propose a rationale-informed optimization method to guide the model\nin disentangling and localizing visual evidence for each rationale, without\nrequiring manual annotations. Extensive experiments and ablation studies\ndemonstrate that our model outperforms state-of-the-art models by up to 10.1%\nin prediction accuracy across a wide range of tasks. Furthermore, our method\nsignificantly improves the model's rationale correctness, improving\nlocalization by 7.5% and disentanglement by 36.5%. Our dataset, source code,\nand pretrained weights: https://github.com/deep-real/DCP",
      "tldr_zh": "该研究强调，大型预训练 foundation models 在高风险应用中表现突出，但当前评估主要关注预测准确性，而忽略了理由的正确性，从而提出“双正确”预测概念（correct prediction backed by correct rationales）。作者构建了一个新数据集，提供结构化理由用于 visual recognition tasks，并开发了一种 rationale-informed optimization 方法，帮助模型无需手动标注即可分离和定位视觉证据。实验结果显示，该方法在多种任务上将预测准确性提高了10.1%，并显著提升理由正确性，包括定位精度提高7.5%和分离度提高36.5%。开源资源可从 https://github.com/deep-real/DCP 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.00132v2",
      "published_date": "2024-10-31 18:33:39 UTC",
      "updated_date": "2024-11-07 03:22:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:27:04.988582"
    },
    {
      "arxiv_id": "2411.00126v1",
      "title": "Training and Evaluating Causal Forecasting Models for Time-Series",
      "title_zh": "时间序列因果预测模型的训练与评估",
      "authors": [
        "Thomas Crasson",
        "Yacine Nabet",
        "Mathias Lécuyer"
      ],
      "abstract": "Deep learning time-series models are often used to make forecasts that inform\ndownstream decisions. Since these decisions can differ from those in the\ntraining set, there is an implicit requirement that time-series models will\ngeneralize outside of their training distribution. Despite this core\nrequirement, time-series models are typically trained and evaluated on\nin-distribution predictive tasks. We extend the orthogonal statistical learning\nframework to train causal time-series models that generalize better when\nforecasting the effect of actions outside of their training distribution. To\nevaluate these models, we leverage Regression Discontinuity Designs popular in\neconomics to construct a test set of causal treatment effects.",
      "tldr_zh": "这篇论文针对时间序列预测模型，扩展了正交统计学习框架（orthogonal statistical learning），以训练因果模型，这些模型在预测训练分布外的行动效果时能够实现更好的泛化，从而支持下游决策。论文指出，现有模型通常仅在分布内任务上训练和评估，这导致了泛化能力的不足。作者通过利用经济学中的回归不连续设计（Regression Discontinuity Designs）来构建测试集，评估模型在因果治疗效果上的表现，为时间序列模型的可靠应用提供了新方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00126v1",
      "published_date": "2024-10-31 18:27:54 UTC",
      "updated_date": "2024-10-31 18:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:27:16.124791"
    },
    {
      "arxiv_id": "2411.00121v1",
      "title": "I Can Hear You: Selective Robust Training for Deepfake Audio Detection",
      "title_zh": "我能听到你：Deepfake 音频检测的选择性鲁棒训练",
      "authors": [
        "Zirui Zhang",
        "Wei Hao",
        "Aroon Sankoh",
        "William Lin",
        "Emanuel Mendiola-Ortiz",
        "Junfeng Yang",
        "Chengzhi Mao"
      ],
      "abstract": "Recent advances in AI-generated voices have intensified the challenge of\ndetecting deepfake audio, posing risks for scams and the spread of\ndisinformation. To tackle this issue, we establish the largest public voice\ndataset to date, named DeepFakeVox-HQ, comprising 1.3 million samples,\nincluding 270,000 high-quality deepfake samples from 14 diverse sources.\nDespite previously reported high accuracy, existing deepfake voice detectors\nstruggle with our diversely collected dataset, and their detection success\nrates drop even further under realistic corruptions and adversarial attacks. We\nconduct a holistic investigation into factors that enhance model robustness and\nshow that incorporating a diversified set of voice augmentations is beneficial.\nMoreover, we find that the best detection models often rely on high-frequency\nfeatures, which are imperceptible to humans and can be easily manipulated by an\nattacker. To address this, we propose the F-SAT: Frequency-Selective\nAdversarial Training method focusing on high-frequency components. Empirical\nresults demonstrate that using our training dataset boosts baseline model\nperformance (without robust training) by 33%, and our robust training further\nimproves accuracy by 7.7% on clean samples and by 29.3% on corrupted and\nattacked samples, over the state-of-the-art RawNet3 model.",
      "tldr_zh": "该研究针对AI生成deepfake音频的检测挑战，构建了迄今为止最大的公开数据集DeepFakeVox-HQ，包含130万样本（其中27万高质量deepfake样本来自14个来源），以应对现有检测模型在多样化数据上的表现不足。研究发现，现有机模型依赖易受攻击的高频特征（high-frequency features），并在现实损坏和adversarial attacks下准确率显著下降。作者通过调查显示，引入多样化语音增强（voice augmentations）可提升模型鲁棒性，并提出F-SAT（Frequency-Selective Adversarial Training）方法，专注于高频组件以提高检测可靠性。实验结果表明，该数据集使基线模型性能提升33%，而F-SAT进一步比state-of-the-art RawNet3模型在干净样本上提高7.7%，在损坏和攻击样本上提高29.3%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00121v1",
      "published_date": "2024-10-31 18:21:36 UTC",
      "updated_date": "2024-10-31 18:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:27:28.640160"
    },
    {
      "arxiv_id": "2411.00885v1",
      "title": "Revolutionizing Personalized Cancer Vaccines with NEO: Novel Epitope Optimization Using an Aggregated Feed Forward and Recurrent Neural Network with LSTM Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Nishanth Basava"
      ],
      "abstract": "As cancer cases continue to rise, with a 2023 study from Zhejiang and Harvard\npredicting a 31 percent increase in cases and a 21 percent increase in deaths\nby 2030, the need to find more effective treatments for cancer is greater than\never before. Traditional approaches to treating cancer, such as chemotherapy,\noften kill healthy cells because of their lack of targetability. In contrast,\npersonalized cancer vaccines can utilize neoepitopes - distinctive peptides on\ncancer cells that are often missed by the body's immune system - that have\nstrong binding affinities to a patient's MHC to provide a more targeted\ntreatment approach. The selection of optimal neoepitopes that elicit an immune\nresponse is a time-consuming and costly process due to the required inputs of\nmodern predictive methods. This project aims to facilitate faster, cheaper, and\nmore accurate neoepitope binding predictions using Feed Forward Neural Networks\n(FFNN) and Recurrent Neural Networks (RNN).\n  To address this, NEO was created. NEO requires next-generation sequencing\ndata and uses a stacking ensemble method by calculating scores from\nstate-of-the-art models (MHCFlurry 1.6, NetMHCstabpan 1.0, and IEDB). The\nmodel's architecture includes an FFNN and an RNN with LSTM layers capable of\nanalyzing both sequential and non-sequential data. The results from both models\nare aggregated to produce predictions. Using this model, personalized cancer\nvaccines can be produced with improved results (AUC = 0.9166, recall = 91.67\npercent).",
      "tldr_zh": "该研究针对癌症治疗的迫切需求，提出了一种名为NEO的模型，用于优化新型表位(neoepitopes)，以提升个性化癌症疫苗的针对性和有效性。NEO采用堆叠集成(stacking ensemble)方法，结合Feed Forward Neural Networks (FFNN)和Recurrent Neural Networks (RNN)与LSTM层，处理下一代测序数据并整合MHCFlurry 1.6、NetMHCstabpan 1.0和IEDB的预测分数，从而实现更快速、准确的neoepitope结合预测。实验结果显示，该模型在AUC=0.9166和recall=91.67%的表现下，显著提高了癌症疫苗的开发效率，为更精确的免疫治疗奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00885v1",
      "published_date": "2024-10-31 18:11:57 UTC",
      "updated_date": "2024-10-31 18:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:27:39.768785"
    },
    {
      "arxiv_id": "2411.00114v1",
      "title": "Project Sid: Many-agent simulations toward AI civilization",
      "title_zh": "翻译失败",
      "authors": [
        "Altera. AL",
        "Andrew Ahn",
        "Nic Becker",
        "Stephanie Carroll",
        "Nico Christie",
        "Manuel Cortes",
        "Arda Demirci",
        "Melissa Du",
        "Frankie Li",
        "Shuying Luo",
        "Peter Y Wang",
        "Mathew Willows",
        "Feitong Yang",
        "Guangyu Robert Yang"
      ],
      "abstract": "AI agents have been evaluated in isolation or within small groups, where\ninteractions remain limited in scope and complexity. Large-scale simulations\ninvolving many autonomous agents -- reflecting the full spectrum of\ncivilizational processes -- have yet to be explored. Here, we demonstrate how\n10 - 1000+ AI agents behave and progress within agent societies. We first\nintroduce the PIANO (Parallel Information Aggregation via Neural Orchestration)\narchitecture, which enables agents to interact with humans and other agents in\nreal-time while maintaining coherence across multiple output streams. We then\nevaluate agent performance in agent simulations using civilizational benchmarks\ninspired by human history. These simulations, set within a Minecraft\nenvironment, reveal that agents are capable of meaningful progress --\nautonomously developing specialized roles, adhering to and changing collective\nrules, and engaging in cultural and religious transmission. These preliminary\nresults show that agents can achieve significant milestones towards AI\ncivilizations, opening new avenues for large simulations, agentic\norganizational intelligence, and integrating AI into human civilizations.",
      "tldr_zh": "本研究提出了Project Sid项目，通过大规模模拟10-1000+ AI agents，探索AI代理在文明进程中的行为和进展。引入了PIANO（Parallel Information Aggregation via Neural Orchestration）架构，支持代理与人类和其他代理的实时互动，并确保多输出流的连贯性。在Minecraft环境中进行的模拟显示，代理能够自主发展专业角色、遵守并修改集体规则，以及参与文化和宗教传播。这些初步结果证明AI agents能实现向AI文明迈进的里程石，为大规模模拟、代理组织智能和AI融入人类文明开辟新路径。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00114v1",
      "published_date": "2024-10-31 18:11:22 UTC",
      "updated_date": "2024-10-31 18:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:27:51.593529"
    },
    {
      "arxiv_id": "2411.00109v2",
      "title": "Prospective Learning: Learning for a Dynamic Future",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwin De Silva",
        "Rahul Ramesh",
        "Rubing Yang",
        "Siyu Yu",
        "Joshua T Vogelstein",
        "Pratik Chaudhari"
      ],
      "abstract": "In real-world applications, the distribution of the data, and our goals,\nevolve over time. The prevailing theoretical framework for studying machine\nlearning, namely probably approximately correct (PAC) learning, largely ignores\ntime. As a consequence, existing strategies to address the dynamic nature of\ndata and goals exhibit poor real-world performance. This paper develops a\ntheoretical framework called \"Prospective Learning\" that is tailored for\nsituations when the optimal hypothesis changes over time. In PAC learning,\nempirical risk minimization (ERM) is known to be consistent. We develop a\nlearner called Prospective ERM, which returns a sequence of predictors that\nmake predictions on future data. We prove that the risk of prospective ERM\nconverges to the Bayes risk under certain assumptions on the stochastic process\ngenerating the data. Prospective ERM, roughly speaking, incorporates time as an\ninput in addition to the data. We show that standard ERM as done in PAC\nlearning, without incorporating time, can result in failure to learn when\ndistributions are dynamic. Numerical experiments illustrate that prospective\nERM can learn synthetic and visual recognition problems constructed from MNIST\nand CIFAR-10. Code at https://github.com/neurodata/prolearn.",
      "tldr_zh": "本文提出“Prospective Learning”框架，以解决机器学习中数据分布和目标随时间变化的问题，该框架扩展了PAC learning的理论基础。研究开发了Prospective ERM算法，将时间作为输入生成序列预测器，并证明其风险在特定假设下收敛到Bayes risk。实验结果显示，Prospective ERM在MNIST和CIFAR-10的合成及视觉识别任务上显著优于标准ERM，提供代码实现以验证其有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00109v2",
      "published_date": "2024-10-31 18:03:17 UTC",
      "updated_date": "2025-01-30 14:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:28:04.685725"
    },
    {
      "arxiv_id": "2410.24220v1",
      "title": "Bridging Geometric States via Geometric Diffusion Bridge",
      "title_zh": "通过几何扩散桥桥接几何状态",
      "authors": [
        "Shengjie Luo",
        "Yixian Xu",
        "Di He",
        "Shuxin Zheng",
        "Tie-Yan Liu",
        "Liwei Wang"
      ],
      "abstract": "The accurate prediction of geometric state evolution in complex systems is\ncritical for advancing scientific domains such as quantum chemistry and\nmaterial modeling. Traditional experimental and computational methods face\nchallenges in terms of environmental constraints and computational demands,\nwhile current deep learning approaches still fall short in terms of precision\nand generality. In this work, we introduce the Geometric Diffusion Bridge\n(GDB), a novel generative modeling framework that accurately bridges initial\nand target geometric states. GDB leverages a probabilistic approach to evolve\ngeometric state distributions, employing an equivariant diffusion bridge\nderived by a modified version of Doob's $h$-transform for connecting geometric\nstates. This tailored diffusion process is anchored by initial and target\ngeometric states as fixed endpoints and governed by equivariant transition\nkernels. Moreover, trajectory data can be seamlessly leveraged in our GDB\nframework by using a chain of equivariant diffusion bridges, providing a more\ndetailed and accurate characterization of evolution dynamics. Theoretically, we\nconduct a thorough examination to confirm our framework's ability to preserve\njoint distributions of geometric states and capability to completely model the\nunderlying dynamics inducing trajectory distributions with negligible error.\nExperimental evaluations across various real-world scenarios show that GDB\nsurpasses existing state-of-the-art approaches, opening up a new pathway for\naccurately bridging geometric states and tackling crucial scientific challenges\nwith improved accuracy and applicability.",
      "tldr_zh": "该论文提出 Geometric Diffusion Bridge (GDB)，一种新型生成模型框架，用于准确连接复杂系统中的初始和目标几何状态，以解决量子化学和材料建模等领域中传统方法和深度学习方法的精度与通用性不足问题。GDB 通过概率方法和修改后的 Doob's h-transform 派生的等变扩散桥（equivariant diffusion bridge）来演化几何状态分布，并支持整合轨迹数据以构建链式等变扩散桥，从而精确建模演化动态。实验结果显示，GDB 在各种真实场景中超越现有最先进方法，提高了准确性和适用性，为科学挑战提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 5 tables; NeurIPS 2024 Camera Ready version",
      "pdf_url": "http://arxiv.org/pdf/2410.24220v1",
      "published_date": "2024-10-31 17:59:53 UTC",
      "updated_date": "2024-10-31 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:28:15.893924"
    },
    {
      "arxiv_id": "2410.24218v1",
      "title": "Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Xi",
        "Yinong He",
        "Jianing Yang",
        "Yinpei Dai",
        "Joyce Chai"
      ],
      "abstract": "In real-world scenarios, it is desirable for embodied agents to have the\nability to leverage human language to gain explicit or implicit knowledge for\nlearning tasks. Despite recent progress, most previous approaches adopt simple\nlow-level instructions as language inputs, which may not reflect natural human\ncommunication. It's not clear how to incorporate rich language use to\nfacilitate task learning. To address this question, this paper studies\ndifferent types of language inputs in facilitating reinforcement learning (RL)\nembodied agents. More specifically, we examine how different levels of language\ninformativeness (i.e., feedback on past behaviors and future guidance) and\ndiversity (i.e., variation of language expressions) impact agent learning and\ninference. Our empirical results based on four RL benchmarks demonstrate that\nagents trained with diverse and informative language feedback can achieve\nenhanced generalization and fast adaptation to new tasks. These findings\nhighlight the pivotal role of language use in teaching embodied agents new\ntasks in an open world. Project website:\nhttps://github.com/sled-group/Teachable_RL",
      "tldr_zh": "本论文探讨了如何通过人类语言输入来教导具身强化学习（embodied reinforcement learning）代理，焦点在于语言的 informativeness（信息性，如对过去行为的反馈和未来指导）和 diversity（多样性，如表达变异）对代理学习的影响。研究通过四个 RL 基准的实验，证明使用多样化和信息丰富的语言反馈能显著提升代理的泛化能力和快速适应新任务。这些发现强调了语言在开放世界中教导代理处理新任务的关键作用，并提供了项目网站供进一步参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main. Project website:\n  https://github.com/sled-group/Teachable_RL",
      "pdf_url": "http://arxiv.org/pdf/2410.24218v1",
      "published_date": "2024-10-31 17:59:52 UTC",
      "updated_date": "2024-10-31 17:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:28:28.352211"
    },
    {
      "arxiv_id": "2410.24206v1",
      "title": "Understanding Optimization in Deep Learning with Central Flows",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy M. Cohen",
        "Alex Damian",
        "Ameet Talwalkar",
        "Zico Kolter",
        "Jason D. Lee"
      ],
      "abstract": "Optimization in deep learning remains poorly understood, even in the simple\nsetting of deterministic (i.e. full-batch) training. A key difficulty is that\nmuch of an optimizer's behavior is implicitly determined by complex oscillatory\ndynamics, referred to as the \"edge of stability.\" The main contribution of this\npaper is to show that an optimizer's implicit behavior can be explicitly\ncaptured by a \"central flow:\" a differential equation which models the\ntime-averaged optimization trajectory. We show that these flows can empirically\npredict long-term optimization trajectories of generic neural networks with a\nhigh degree of numerical accuracy. By interpreting these flows, we reveal for\nthe first time 1) the precise sense in which RMSProp adapts to the local loss\nlandscape, and 2) an \"acceleration via regularization\" mechanism, wherein\nadaptive optimizers implicitly navigate towards low-curvature regions in which\nthey can take larger steps. This mechanism is key to the efficacy of these\nadaptive optimizers. Overall, we believe that central flows constitute a\npromising tool for reasoning about optimization in deep learning.",
      "tldr_zh": "这篇论文探讨了深度学习优化（optimization in deep learning）的理解难题，特别是确定性训练中复杂的振荡动态（如 edge of stability）。作者引入了 central flows——一个微分方程模型，用于显式捕获优化器的隐式行为，通过模拟时间平均优化轨迹来预测神经网络的长期训练路径。实验结果显示，central flows 能以高精度预测优化轨迹，并揭示了 RMSProp 如何适应局部损失景观，以及自适应优化器通过“acceleration via regularization”机制隐式导航到低曲率区域，从而实现更大步长和更高效率。总之，central flows 被视为推理深度学习优化的一个有前景工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "first two authors contributed equally; author order determined by\n  coin flip",
      "pdf_url": "http://arxiv.org/pdf/2410.24206v1",
      "published_date": "2024-10-31 17:58:13 UTC",
      "updated_date": "2024-10-31 17:58:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:28:40.738504"
    },
    {
      "arxiv_id": "2410.24205v1",
      "title": "Zonal RL-RRT: Integrated RL-RRT Path Planning with Collision Probability and Zone Connectivity",
      "title_zh": "Zonal RL-RRT：",
      "authors": [
        "AmirMohammad Tahmasbi",
        "MohammadSaleh Faghfoorian",
        "Saeed Khodaygan",
        "Aniket Bera"
      ],
      "abstract": "Path planning in high-dimensional spaces poses significant challenges,\nparticularly in achieving both time efficiency and a fair success rate. To\naddress these issues, we introduce a novel path-planning algorithm, Zonal\nRL-RRT, that leverages kd-tree partitioning to segment the map into zones while\naddressing zone connectivity, ensuring seamless transitions between zones. By\nbreaking down the complex environment into multiple zones and using Q-learning\nas the high-level decision-maker, our algorithm achieves a 3x improvement in\ntime efficiency compared to basic sampling methods such as RRT and RRT* in\nforest-like maps. Our approach outperforms heuristic-guided methods like BIT*\nand Informed RRT* by 1.5x in terms of runtime while maintaining robust and\nreliable success rates across 2D to 6D environments. Compared to learning-based\nmethods like NeuralRRT* and MPNetSMP, as well as the heuristic RRT*J, our\nalgorithm demonstrates, on average, 1.5x better performance in the same\nenvironments. We also evaluate the effectiveness of our approach through\nsimulations of the UR10e arm manipulator in the MuJoCo environment. A key\nobservation of our approach lies in its use of zone partitioning and\nReinforcement Learning (RL) for adaptive high-level planning allowing the\nalgorithm to accommodate flexible policies across diverse environments, making\nit a versatile tool for advanced path planning.",
      "tldr_zh": "该论文提出了一种新型路径规划算法 Zonal RL-RRT，通过 kd-tree 分区将地图分割成多个区域，并利用 Q-learning 作为高层决策器来处理区域连接性和碰撞概率，从而实现高效的路径规划。相比基本采样方法如 RRT 和 RRT*，该算法在森林状地图上将时间效率提高了 3 倍；与启发式方法如 BIT* 和 Informed RRT* 相比，运行时间平均提升 1.5 倍，同时保持了在 2D 到 6D 环境中的高成功率。实验结果显示，Zonal RL-RRT 比基于学习的 NeuralRRT*、MPNetSMP 和启发式 RRT*J 等方法平均性能提高了 1.5 倍，并在 MuJoCo 环境中对 UR10e 机械臂的模拟中证明了其适应性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24205v1",
      "published_date": "2024-10-31 17:57:51 UTC",
      "updated_date": "2024-10-31 17:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:28:55.056738"
    },
    {
      "arxiv_id": "2410.24203v1",
      "title": "DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Weicai Ye",
        "Chenhao Ji",
        "Zheng Chen",
        "Junyao Gao",
        "Xiaoshui Huang",
        "Song-Hai Zhang",
        "Wanli Ouyang",
        "Tong He",
        "Cairong Zhao",
        "Guofeng Zhang"
      ],
      "abstract": "Diffusion-based methods have achieved remarkable achievements in 2D image or\n3D object generation, however, the generation of 3D scenes and even\n$360^{\\circ}$ images remains constrained, due to the limited number of scene\ndatasets, the complexity of 3D scenes themselves, and the difficulty of\ngenerating consistent multi-view images. To address these issues, we first\nestablish a large-scale panoramic video-text dataset containing millions of\nconsecutive panoramic keyframes with corresponding panoramic depths, camera\nposes, and text descriptions. Then, we propose a novel text-driven panoramic\ngeneration framework, termed DiffPano, to achieve scalable, consistent, and\ndiverse panoramic scene generation. Specifically, benefiting from the powerful\ngenerative capabilities of stable diffusion, we fine-tune a single-view\ntext-to-panorama diffusion model with LoRA on the established panoramic\nvideo-text dataset. We further design a spherical epipolar-aware multi-view\ndiffusion model to ensure the multi-view consistency of the generated panoramic\nimages. Extensive experiments demonstrate that DiffPano can generate scalable,\nconsistent, and diverse panoramic images with given unseen text descriptions\nand camera poses.",
      "tldr_zh": "该论文解决了扩散模型在生成3D场景和360°图像时的限制问题，包括数据集规模不足和多视图一致性挑战，首先建立了一个包含数百万全景关键帧的大规模视频-文本数据集。DiffPano框架通过微调Stable Diffusion模型（使用LoRA技术）实现可扩展的文本到全景生成，并引入spherical epipolar-aware多视图扩散模型，确保生成的图像在多视图上保持一致性。实验结果显示，DiffPano能基于未见文本描述和相机姿态生成多样且一致的全景图像。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS2024, Project: https://github.com/zju3dv/DiffPano; Code:\n  https://github.com/zju3dv/DiffPano",
      "pdf_url": "http://arxiv.org/pdf/2410.24203v1",
      "published_date": "2024-10-31 17:57:02 UTC",
      "updated_date": "2024-10-31 17:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:29:04.136425"
    },
    {
      "arxiv_id": "2410.24200v1",
      "title": "Length-Induced Embedding Collapse in Transformer-based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Zhou",
        "Sunhao Dai",
        "Zhanshuo Cao",
        "Xiao Zhang",
        "Jun Xu"
      ],
      "abstract": "Text embeddings enable various applications, but their performance\ndeteriorates on longer texts. In this paper, we find that the performance\ndegradation is due to a phenomenon called Length Collapse, where longer text\nembeddings collapse into a narrow space. This collapse results in a\ndistributional inconsistency between embeddings of different text lengths,\nultimately hurting the performance of downstream tasks. Theoretically, by\nconsidering the self-attention mechanism inherently functions as a low-pass\nfilter, we prove that long sequences increase the attenuation rate of the\nlow-pass filter effect of the self-attention mechanism. With layers going\ndeeper, excessive low-pass filtering causes the token signals to retain only\ntheir Direct-Current (DC) component, which means the input token feature maps\nwill collapse into a narrow space, especially in long texts. Based on the above\nanalysis, we propose to mitigate the undesirable length collapse limitation by\nintroducing a temperature in softmax(), which achieves a higher low-filter\nattenuation rate. The tuning-free method, called TempScale, can be plugged into\nmultiple transformer-based embedding models. Empirically, we demonstrate that\nTempScale can improve existing embedding models, especially on long text\ninputs, bringing up to 0.53% performance gains on 40 datasets from Massive Text\nEmbedding Benchmark (MTEB) and 0.82% performance gains on 4 datasets from\nLongEmbed, which specifically focuses on long context retrieval.",
      "tldr_zh": "本研究发现，Transformer-based Models 在处理长文本时会发生 Length Collapse 现象，导致文本嵌入坍缩到狭窄空间，从而造成不同文本长度间的分布不一致，并损害下游任务性能。通过分析自注意力机制作为低通滤波器的作用，证明长序列会增加衰减率，导致信号只保留 Direct-Current (DC) 成分。作者提出 TempScale 方法，在 softmax() 中引入温度参数，以提高低通滤波器的衰减率，并验证其在多种模型中的兼容性。实验结果显示，该方法在 Massive Text Embedding Benchmark (MTEB) 的 40 个数据集上提升高达 0.53%，以及在 LongEmbed 的 4 个数据集上提升高达 0.82%，尤其适用于长文本输入。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24200v1",
      "published_date": "2024-10-31 17:55:36 UTC",
      "updated_date": "2024-10-31 17:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:29:16.210748"
    },
    {
      "arxiv_id": "2411.00081v1",
      "title": "PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Chang",
        "Gunjan Chhablani",
        "Alexander Clegg",
        "Mikael Dallaire Cote",
        "Ruta Desai",
        "Michal Hlavac",
        "Vladimir Karashchuk",
        "Jacob Krantz",
        "Roozbeh Mottaghi",
        "Priyam Parashar",
        "Siddharth Patki",
        "Ishita Prasad",
        "Xavier Puig",
        "Akshara Rai",
        "Ram Ramrakhya",
        "Daniel Tran",
        "Joanne Truong",
        "John M. Turner",
        "Eric Undersander",
        "Tsung-Yen Yang"
      ],
      "abstract": "We present a benchmark for Planning And Reasoning Tasks in humaN-Robot\ncollaboration (PARTNR) designed to study human-robot coordination in household\nactivities. PARTNR tasks exhibit characteristics of everyday tasks, such as\nspatial, temporal, and heterogeneous agent capability constraints. We employ a\nsemi-automated task generation pipeline using Large Language Models (LLMs),\nincorporating simulation in the loop for grounding and verification. PARTNR\nstands as the largest benchmark of its kind, comprising 100,000 natural\nlanguage tasks, spanning 60 houses and 5,819 unique objects. We analyze\nstate-of-the-art LLMs on PARTNR tasks, across the axes of planning, perception\nand skill execution. The analysis reveals significant limitations in SoTA\nmodels, such as poor coordination and failures in task tracking and recovery\nfrom errors. When LLMs are paired with real humans, they require 1.5x as many\nsteps as two humans collaborating and 1.1x more steps than a single human,\nunderscoring the potential for improvement in these models. We further show\nthat fine-tuning smaller LLMs with planning data can achieve performance on par\nwith models 9 times larger, while being 8.6x faster at inference. Overall,\nPARTNR highlights significant challenges facing collaborative embodied agents\nand aims to drive research in this direction.",
      "tldr_zh": "本研究引入了PARTNR基准，用于评估多代理任务中的规划和推理，特别是人类-机器人协作在家庭活动中的协调。PARTNR任务模拟日常场景，包括空间、时间和代理能力约束，并通过半自动化管道结合LLMs和模拟生成，共包含100,000个自然语言任务，覆盖60个房屋和5,819个独特对象。实验分析显示，当前最先进的LLMs在规划、感知和技能执行方面存在显著缺陷，如协调能力差、任务跟踪失败和错误恢复问题，导致与人类协作时步骤增加（比两人协作多1.5倍，比单人多1.1倍）。此外，微调较小LLMs使用规划数据可实现与更大模型相当的性能，同时推理速度快8.6倍，突显了提升协作嵌入式代理的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Alphabetical author order",
      "pdf_url": "http://arxiv.org/pdf/2411.00081v1",
      "published_date": "2024-10-31 17:53:12 UTC",
      "updated_date": "2024-10-31 17:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:29:29.006771"
    },
    {
      "arxiv_id": "2410.24187v1",
      "title": "Chasing Better Deep Image Priors between Over- and Under-parameterization",
      "title_zh": "在过参数化和欠参数化之间追求更好的深度图像先验",
      "authors": [
        "Qiming Wu",
        "Xiaohan Chen",
        "Yifan Jiang",
        "Zhangyang Wang"
      ],
      "abstract": "Deep Neural Networks (DNNs) are well-known to act as over-parameterized deep\nimage priors (DIP) that regularize various image inverse problems. Meanwhile,\nresearchers also proposed extremely compact, under-parameterized image priors\n(e.g., deep decoder) that are strikingly competent for image restoration too,\ndespite a loss of accuracy. These two extremes push us to think whether there\nexists a better solution in the middle: between over- and under-parameterized\nimage priors, can one identify \"intermediate\" parameterized image priors that\nachieve better trade-offs between performance, efficiency, and even preserving\nstrong transferability? Drawing inspirations from the lottery ticket hypothesis\n(LTH), we conjecture and study a novel \"lottery image prior\" (LIP) by\nexploiting DNN inherent sparsity, stated as: given an over-parameterized\nDNN-based image prior, it will contain a sparse subnetwork that can be trained\nin isolation, to match the original DNN's performance when being applied as a\nprior to various image inverse problems. Our results validate the superiority\nof LIPs: we can successfully locate the LIP subnetworks from over-parameterized\nDIPs at substantial sparsity ranges. Those LIP subnetworks significantly\noutperform deep decoders under comparably compact model sizes (by often fully\npreserving the effectiveness of their over-parameterized counterparts), and\nthey also possess high transferability across different images as well as\nrestoration task types. Besides, we also extend LIP to compressive sensing\nimage reconstruction, where a pre-trained GAN generator is used as the prior\n(in contrast to untrained DIP or deep decoder), and confirm its validity in\nthis setting too. To our best knowledge, this is the first time that LTH is\ndemonstrated to be relevant in the context of inverse problems or image priors.",
      "tldr_zh": "本研究探讨了在过参数化（over-parameterized）和欠参数化（under-parameterized）深度图像先验（DIP）之间寻找更好的中间方案，旨在优化图像逆问题的性能、效率和转移性。受彩票票假设（Lottery Ticket Hypothesis, LTH）启发，论文提出“彩票图像先验”（Lottery Image Prior, LIP）方法，通过利用Deep Neural Networks (DNNs)的固有稀疏性，从过参数化DIP中提取稀疏子网络，使其在隔离训练后匹配原网络的性能。实验结果表明，这些LIP子网络在紧凑模型大小下显著优于deep decoder，同时保持高转移性，适用于不同图像和任务类型。此外，研究扩展LIP到压缩感知图像重建，使用预训练GAN生成器作为先验，进一步验证了其有效性，这是LTH首次应用于逆问题或图像先验领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Codes are available at\n  https://github.com/VITA-Group/Chasing-Better-DIPs",
      "pdf_url": "http://arxiv.org/pdf/2410.24187v1",
      "published_date": "2024-10-31 17:49:44 UTC",
      "updated_date": "2024-10-31 17:49:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:29:41.170176"
    },
    {
      "arxiv_id": "2410.24185v2",
      "title": "DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Jiang",
        "Yuqi Xie",
        "Kevin Lin",
        "Zhenjia Xu",
        "Weikang Wan",
        "Ajay Mandlekar",
        "Linxi Fan",
        "Yuke Zhu"
      ],
      "abstract": "Imitation learning from human demonstrations is an effective means to teach\nrobots manipulation skills. But data acquisition is a major bottleneck in\napplying this paradigm more broadly, due to the amount of cost and human effort\ninvolved. There has been significant interest in imitation learning for\nbimanual dexterous robots, like humanoids. Unfortunately, data collection is\neven more challenging here due to the challenges of simultaneously controlling\nmultiple arms and multi-fingered hands. Automated data generation in simulation\nis a compelling, scalable alternative to fuel this need for data. To this end,\nwe introduce DexMimicGen, a large-scale automated data generation system that\nsynthesizes trajectories from a handful of human demonstrations for humanoid\nrobots with dexterous hands. We present a collection of simulation environments\nin the setting of bimanual dexterous manipulation, spanning a range of\nmanipulation behaviors and different requirements for coordination among the\ntwo arms. We generate 21K demos across these tasks from just 60 source human\ndemos and study the effect of several data generation and policy learning\ndecisions on agent performance. Finally, we present a real-to-sim-to-real\npipeline and deploy it on a real-world humanoid can sorting task. Generated\ndatasets, simulation environments and additional results are at\nhttps://dexmimicgen.github.io/",
      "tldr_zh": "这篇论文介绍了 DexMimicGen，一个自动化数据生成系统，通过 Imitation Learning 从少量人类演示中合成轨迹，用于双臂灵巧机器人（如人形机器人）的操作。该系统构建了多个模拟环境，涵盖各种双臂协调任务，从仅 60 个源演示生成了 21K 演示，并分析了数据生成和策略学习决策对代理性能的影响。最终，论文展示了从模拟到真实世界的部署管道，并在真实人形机器人罐子排序任务上成功应用，证明了其可扩展性和实际价值。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2025. Project website: https://dexmimicgen.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.24185v2",
      "published_date": "2024-10-31 17:48:45 UTC",
      "updated_date": "2025-03-06 05:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:29:52.030152"
    },
    {
      "arxiv_id": "2410.24175v2",
      "title": "Constraint Back-translation Improves Complex Instruction Following of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yunjia Qi",
        "Hao Peng",
        "Xiaozhi Wang",
        "Bin Xu",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Large language models (LLMs) struggle to follow instructions with complex\nconstraints in format, length, etc. Following the conventional\ninstruction-tuning practice, previous works conduct post-training on complex\ninstruction-response pairs generated by feeding complex instructions to\nadvanced LLMs. However, even advanced LLMs cannot follow complex instructions\nwell, thus limiting the quality of generated data. In this work, we find that\nexisting datasets inherently contain implicit complex constraints and propose a\nnovel data generation technique, constraint back-translation. Specifically, we\ntake the high-quality instruction-response pairs in existing datasets and only\nadopt advanced LLMs to add complex constraints already met by the responses to\nthe instructions, which naturally reduces costs and data noise. In the\nexperiments, we adopt Llama3-70B-Instruct to back-translate constraints and\ncreate a high-quality complex instruction-response dataset, named CRAB. We\npresent that post-training on CRAB improves multiple backbone LLMs' complex\ninstruction-following ability, evaluated on extensive instruction-following\nbenchmarks. We further find that constraint back-translation also serves as a\nuseful auxiliary training objective in post-training. Our code, data, and\nmodels will be released to facilitate future research.",
      "tldr_zh": "大语言模型(LLMs)难以遵循带有复杂约束（如格式或长度）的指令，本文提出constraint back-translation技术，通过在现有高质量指令-响应对上添加已满足的约束来生成新数据，从而降低成本和噪声。作者使用Llama3-70B-Instruct创建了高质数据集CRAB，并在后训练中应用该技术，提升了多种骨干LLMs的复杂指令遵循能力。实验结果显示，模型在多个指令遵循基准上准确性显著提高，且constraint back-translation可作为有效的辅助训练目标。作者将发布代码、数据和模型以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.24175v2",
      "published_date": "2024-10-31 17:42:26 UTC",
      "updated_date": "2025-04-29 15:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:30:04.300306"
    },
    {
      "arxiv_id": "2411.02429v1",
      "title": "IdeaBench: Benchmarking Large Language Models for Research Idea Generation",
      "title_zh": "IdeaBench: 大语言模型研究想法生成的基准测试",
      "authors": [
        "Sikun Guo",
        "Amir Hassan Shariatmadari",
        "Guangzhi Xiong",
        "Albert Huang",
        "Eric Xie",
        "Stefan Bekiranov",
        "Aidong Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have transformed how people interact with\nartificial intelligence (AI) systems, achieving state-of-the-art results in\nvarious tasks, including scientific discovery and hypothesis generation.\nHowever, the lack of a comprehensive and systematic evaluation framework for\ngenerating research ideas using LLMs poses a significant obstacle to\nunderstanding and assessing their generative capabilities in scientific\ndiscovery. To address this gap, we propose IdeaBench, a benchmark system that\nincludes a comprehensive dataset and an evaluation framework for standardizing\nthe assessment of research idea generation using LLMs. Our dataset comprises\ntitles and abstracts from a diverse range of influential papers, along with\ntheir referenced works. To emulate the human process of generating research\nideas, we profile LLMs as domain-specific researchers and ground them in the\nsame context considered by human researchers. This maximizes the utilization of\nthe LLMs' parametric knowledge to dynamically generate new research ideas. We\nalso introduce an evaluation framework for assessing the quality of generated\nresearch ideas. Our evaluation framework is a two-stage process: first, using\nGPT-4o to rank ideas based on user-specified quality indicators such as novelty\nand feasibility, enabling scalable personalization; and second, calculating\nrelative ranking based \"Insight Score\" to quantify the chosen quality\nindicator. The proposed benchmark system will be a valuable asset for the\ncommunity to measure and compare different LLMs, ultimately advancing the\nautomation of the scientific discovery process.",
      "tldr_zh": "本研究提出IdeaBench，一种用于评估Large Language Models (LLMs)在研究想法生成方面的基准系统，以填补现有评估框架的空白。IdeaBench包括一个全面数据集，涵盖影响性论文的标题、摘要和参考作品，并通过将LLMs模拟为领域特定研究者，利用上下文和参数知识动态生成新研究想法。其评估框架采用两阶段方法：首先使用GPT-4o根据用户指定的质量指标（如新颖性和可行性）进行排名，其次计算基于“Insight Score”的相对排名，以量化想法质量。该系统将帮助社区比较不同LLMs，推动科学发现过程的自动化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02429v1",
      "published_date": "2024-10-31 17:04:59 UTC",
      "updated_date": "2024-10-31 17:04:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:30:15.451614"
    },
    {
      "arxiv_id": "2411.00078v1",
      "title": "How Good Are We? Evaluating Cell AI Foundation Models in Kidney Pathology with Human-in-the-Loop Enrichment",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Guo",
        "Siqi Lu",
        "Can Cui",
        "Ruining Deng",
        "Tianyuan Yao",
        "Zhewen Tao",
        "Yizhe Lin",
        "Marilyn Lionts",
        "Quan Liu",
        "Juming Xiong",
        "Yu Wang",
        "Shilin Zhao",
        "Catie Chang",
        "Mitchell Wilkes",
        "Mengmeng Yin",
        "Haichun Yang",
        "Yuankai Huo"
      ],
      "abstract": "Training AI foundation models has emerged as a promising large-scale learning\napproach for addressing real-world healthcare challenges, including digital\npathology. While many of these models have been developed for tasks like\ndisease diagnosis and tissue quantification using extensive and diverse\ntraining datasets, their readiness for deployment on some arguably simplest\ntasks, such as nuclei segmentation within a single organ (e.g., the kidney),\nremains uncertain. This paper seeks to answer this key question, \"How good are\nwe?\", by thoroughly evaluating the performance of recent cell foundation models\non a curated multi-center, multi-disease, and multi-species external testing\ndataset. Additionally, we tackle a more challenging question, \"How can we\nimprove?\", by developing and assessing human-in-the-loop data enrichment\nstrategies aimed at enhancing model performance while minimizing the reliance\non pixel-level human annotation. To address the first question, we curated a\nmulticenter, multidisease, and multispecies dataset consisting of 2,542 kidney\nwhole slide images (WSIs). Three state-of-the-art (SOTA) cell foundation\nmodels-Cellpose, StarDist, and CellViT-were selected for evaluation. To tackle\nthe second question, we explored data enrichment algorithms by distilling\npredictions from the different foundation models with a human-in-the-loop\nframework, aiming to further enhance foundation model performance with minimal\nhuman efforts. Our experimental results showed that all three foundation models\nimproved over their baselines with model fine-tuning with enriched data.\nInterestingly, the baseline model with the highest F1 score does not yield the\nbest segmentation outcomes after fine-tuning. This study establishes a\nbenchmark for the development and deployment of cell vision foundation models\ntailored for real-world data applications.",
      "tldr_zh": "这篇论文评估了AI foundation models在肾脏病理学中进行细胞核分割等简单任务的性能，针对Cellpose、StarDist和CellViT等三款state-of-the-art (SOTA)模型，使用了一个多中心、多疾病和多物种的外部测试数据集（包括2,542张肾脏whole slide images (WSIs)）。研究者探讨了human-in-the-loop数据增强策略，通过预测蒸馏和最小化像素级人工标注来提升模型表现。实验结果显示，所有模型在微调后均超过了基线水平，但F1分数最高的基线模型并不一定在微调后表现最佳。该研究为细胞vision foundation models在真实世界应用的开发和部署建立了基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00078v1",
      "published_date": "2024-10-31 17:00:33 UTC",
      "updated_date": "2024-10-31 17:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:30:28.574198"
    },
    {
      "arxiv_id": "2410.24119v2",
      "title": "Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Dhruv",
        "Anshu Dubey"
      ],
      "abstract": "The emergence of foundational models and generative artificial intelligence\n(GenAI) is poised to transform productivity in scientific computing, especially\nin code development, refactoring, and translating from one programming language\nto another. However, because the output of GenAI cannot be guaranteed to be\ncorrect, manual intervention remains necessary. Some of this intervention can\nbe automated through task-specific tools, alongside additional methodologies\nfor correctness verification and effective prompt development. We explored the\napplication of GenAI in assisting with code translation, language\ninteroperability, and codebase inspection within a legacy Fortran codebase used\nto simulate particle interactions at the Large Hadron Collider (LHC). In the\nprocess, we developed a tool, CodeScribe, which combines prompt engineering\nwith user supervision to establish an efficient process for code conversion. In\nthis paper, we demonstrate how CodeScribe assists in converting Fortran code to\nC++, generating Fortran-C APIs for integrating legacy systems with modern C++\nlibraries, and providing developer support for code organization and algorithm\nimplementation. We also address the challenges of AI-driven code translation\nand highlight its benefits for enhancing productivity in scientific computing\nworkflows.",
      "tldr_zh": "这篇论文探讨了如何利用 Large Language Models (LLMs) 和生成式 AI (GenAI) 提升科学计算中的代码翻译、软件开发和重构效率，特别是针对遗留 Fortran 代码库。研究团队开发了 CodeScribe 工具，该工具结合提示工程和用户监督，实现高效的代码转换，如将 Fortran 代码转换为 C++、生成 Fortran-C API 以整合现代库，并提供代码组织和算法实现的开发者支持。论文强调了 AI 驱动代码转换的潜在挑战（如输出准确性问题），但展示了其在提高科学计算工作流生产力的显著益处。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24119v2",
      "published_date": "2024-10-31 16:48:41 UTC",
      "updated_date": "2025-03-17 02:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:30:40.965428"
    },
    {
      "arxiv_id": "2410.24116v1",
      "title": "AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Kazemi",
        "Qurat ul ain Fatima",
        "Volodymyr Kindratenko",
        "Christopher Tessum"
      ],
      "abstract": "Image labeling is a critical bottleneck in the development of computer vision\ntechnologies, often constraining the potential of machine learning models due\nto the time-intensive nature of manual annotations. This work introduces a\nnovel approach that leverages outpainting to address the problem of annotated\ndata scarcity by generating artificial contexts and annotations, significantly\nreducing manual labeling efforts. We apply this technique to a particularly\nacute challenge in autonomous driving, urban planning, and environmental\nmonitoring: the lack of diverse, eye-level vehicle images in desired classes.\nOur dataset comprises AI-generated vehicle images obtained by detecting and\ncropping vehicles from manually selected seed images, which are then outpainted\nonto larger canvases to simulate varied real-world conditions. The outpainted\nimages include detailed annotations, providing high-quality ground truth data.\nAdvanced outpainting techniques and image quality assessments ensure visual\nfidelity and contextual relevance. Augmentation with outpainted vehicles\nimproves overall performance metrics by up to 8\\% and enhances prediction of\nunderrepresented classes by up to 20\\%. This approach, exemplifying outpainting\nas a self-annotating paradigm, presents a solution that enhances dataset\nversatility across multiple domains of machine learning. The code and links to\ndatasets used in this study are available for further research and replication\nat https://github.com/amir-kazemi/aidovecl.",
      "tldr_zh": "本研究引入AIDOVECL，一种AI-generated Dataset，通过outpainting技术从手动选择的种子图像中检测并裁剪车辆，然后扩展到更大画布上，以模拟多样化的真实世界场景，从而解决图像标注的耗时问题和眼平视车辆图像缺乏的挑战。该数据集包含高质量的注释，确保视觉保真度和上下文相关性，并在自动驾驶、城市规划及环境监测等领域提供丰富的训练数据。实验结果显示，添加outpainted车辆后，整体性能指标提升高达8%，并将underrepresented类别的预测准确率提高20%，为减少手动标注努力并增强机器学习数据集的通用性提供了新范式。代码和数据集链接可在https://github.com/amir-kazemi/aidovecl获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T01, 68T45, 68U01, 68U10",
        "I.2.10; I.3.3; I.4.8; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.24116v1",
      "published_date": "2024-10-31 16:46:23 UTC",
      "updated_date": "2024-10-31 16:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:30:51.547986"
    },
    {
      "arxiv_id": "2410.24114v1",
      "title": "Nearest Neighbor Normalization Improves Multimodal Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Neil Chowdhury",
        "Franklin Wang",
        "Sumedh Shenoy",
        "Douwe Kiela",
        "Sarah Schwettmann",
        "Tristan Thrush"
      ],
      "abstract": "Multimodal models leverage large-scale pre-training to achieve strong but\nstill imperfect performance on tasks such as image captioning, visual question\nanswering, and cross-modal retrieval. In this paper, we present a simple and\nefficient method for correcting errors in trained contrastive image-text\nretrieval models with no additional training, called Nearest Neighbor\nNormalization (NNN). We show an improvement on retrieval metrics in both text\nretrieval and image retrieval for all of the contrastive models that we tested\n(CLIP, BLIP, ALBEF, SigLIP, BEiT) and for both of the datasets that we used\n(MS-COCO and Flickr30k). NNN requires a reference database, but does not\nrequire any training on this database, and can even increase the retrieval\naccuracy of a model after finetuning.",
      "tldr_zh": "本文提出Nearest Neighbor Normalization (NNN)，一种简单高效的方法，用于修正训练好的对比学习图像-文本检索模型的错误，而无需额外训练。该方法通过使用参考数据库来校正检索偏差，在多个模型（如CLIP、BLIP、ALBEF、SigLIP和BEiT）以及数据集（如MS-COCO和Flickr30k）上，显著提高了文本检索和图像检索的性能指标。实验结果显示，NNN甚至能在模型微调后进一步提升准确率，为多模态检索任务提供了一个实用改进方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24114v1",
      "published_date": "2024-10-31 16:44:10 UTC",
      "updated_date": "2024-10-31 16:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:31:03.697111"
    },
    {
      "arxiv_id": "2410.24108v1",
      "title": "Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers",
      "title_zh": "强化学习梯度作为维生素，用于在线微调决策变换器",
      "authors": [
        "Kai Yan",
        "Alexander G. Schwing",
        "Yu-Xiong Wang"
      ],
      "abstract": "Decision Transformers have recently emerged as a new and compelling paradigm\nfor offline Reinforcement Learning (RL), completing a trajectory in an\nautoregressive way. While improvements have been made to overcome initial\nshortcomings, online finetuning of decision transformers has been surprisingly\nunder-explored. The widely adopted state-of-the-art Online Decision Transformer\n(ODT) still struggles when pretrained with low-reward offline data. In this\npaper, we theoretically analyze the online-finetuning of the decision\ntransformer, showing that the commonly used Return-To-Go (RTG) that's far from\nthe expected return hampers the online fine-tuning process. This problem,\nhowever, is well-addressed by the value function and advantage of standard RL\nalgorithms. As suggested by our analysis, in our experiments, we hence find\nthat simply adding TD3 gradients to the finetuning process of ODT effectively\nimproves the online finetuning performance of ODT, especially if ODT is\npretrained with low-reward offline data. These findings provide new directions\nto further improve decision transformers.",
      "tldr_zh": "本论文分析了 Decision Transformers 在在线微调中的问题，特别是当使用低奖励离线数据预训练时，Return-To-Go (RTG) 与预期回报的偏差会阻碍微调过程。研究者通过理论证明，引入标准 Reinforcement Learning (RL) 中的价值函数和优势（如 TD3 gradients）可以有效解决这一问题，并在实验中发现，将 TD3 gradients 添加到 Online Decision Transformer (ODT) 的微调过程中显著提升了性能，尤其在低奖励数据上。总体而言，这为进一步改进 Decision Transformers 提供了新方向，增强了其在线 RL 应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as NeurIPS 2024 spotlight. 33 pages, 26 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.24108v1",
      "published_date": "2024-10-31 16:38:51 UTC",
      "updated_date": "2024-10-31 16:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:31:15.982802"
    },
    {
      "arxiv_id": "2411.00074v1",
      "title": "RPS: A Generic Reservoir Patterns Sampler",
      "title_zh": "翻译失败",
      "authors": [
        "Lamine Diop",
        "Marc Plantevit",
        "Arnaud Soulet"
      ],
      "abstract": "Efficient learning from streaming data is important for modern data analysis\ndue to the continuous and rapid evolution of data streams. Despite significant\nadvancements in stream pattern mining, challenges persist, particularly in\nmanaging complex data streams like sequential and weighted itemsets. While\nreservoir sampling serves as a fundamental method for randomly selecting\nfixed-size samples from data streams, its application to such complex patterns\nremains largely unexplored. In this study, we introduce an approach that\nharnesses a weighted reservoir to facilitate direct pattern sampling from\nstreaming batch data, thus ensuring scalability and efficiency. We present a\ngeneric algorithm capable of addressing temporal biases and handling various\npattern types, including sequential, weighted, and unweighted itemsets. Through\ncomprehensive experiments conducted on real-world datasets, we evaluate the\neffectiveness of our method, showcasing its ability to construct accurate\nincremental online classifiers for sequential data. Our approach not only\nenables previously unusable online machine learning models for sequential data\nto achieve accuracy comparable to offline baselines but also represents\nsignificant progress in the development of incremental online sequential\nitemset classifiers.",
      "tldr_zh": "本研究提出RPS（A Generic Reservoir Patterns Sampler），一种通用算法，用于从流数据中高效采样复杂模式，如sequential和weighted itemsets，从而解决传统reservoir sampling在处理此类数据时的局限性。该算法利用加权reservoir采样技术，直接从streaming batch数据中提取模式，并能处理temporal biases，支持多种模式类型，确保可伸缩性和效率。通过在真实数据集上的实验，RPS展示了构建准确的incremental online classifiers的能力，使在线机器学习模型在sequential数据上达到与offline baselines相当的性能，并推动了incremental online sequential itemset classifiers的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO",
        "math.PR",
        "60: Probability theory",
        "G.3; E.1; E.2; F.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2024 IEEE International Conference on Big Data",
      "pdf_url": "http://arxiv.org/pdf/2411.00074v1",
      "published_date": "2024-10-31 16:25:21 UTC",
      "updated_date": "2024-10-31 16:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:31:27.411042"
    },
    {
      "arxiv_id": "2410.24091v2",
      "title": "3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Binghao Huang",
        "Yixuan Wang",
        "Xinyi Yang",
        "Yiyue Luo",
        "Yunzhu Li"
      ],
      "abstract": "Tactile and visual perception are both crucial for humans to perform\nfine-grained interactions with their environment. Developing similar\nmulti-modal sensing capabilities for robots can significantly enhance and\nexpand their manipulation skills. This paper introduces \\textbf{3D-ViTac}, a\nmulti-modal sensing and learning system designed for dexterous bimanual\nmanipulation. Our system features tactile sensors equipped with dense sensing\nunits, each covering an area of 3$mm^2$. These sensors are low-cost and\nflexible, providing detailed and extensive coverage of physical contacts,\neffectively complementing visual information. To integrate tactile and visual\ndata, we fuse them into a unified 3D representation space that preserves their\n3D structures and spatial relationships. The multi-modal representation can\nthen be coupled with diffusion policies for imitation learning. Through\nconcrete hardware experiments, we demonstrate that even low-cost robots can\nperform precise manipulations and significantly outperform vision-only\npolicies, particularly in safe interactions with fragile items and executing\nlong-horizon tasks involving in-hand manipulation. Our project page is\navailable at \\url{https://binghao-huang.github.io/3D-ViTac/}.",
      "tldr_zh": "这篇论文介绍了 3D-ViTac 系统，这是一个多模态感知和学习框架，旨在通过结合视觉和触觉传感提升机器人的精细双臂操作能力。系统使用低成本、灵活的触觉传感器（每个覆盖 3 mm² 面积）来补充视觉信息，并将两种数据融合到一个统一的 3D 表示空间中，以保留其 3D 结构和空间关系，然后结合 diffusion policies 进行模仿学习。实验证明，即使是低成本机器人，该系统也能在安全互动（如处理易碎物品）和长程任务（如手部操作）中显著优于仅视觉策略。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Conference on Robot Learning (CoRL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.24091v2",
      "published_date": "2024-10-31 16:22:53 UTC",
      "updated_date": "2025-01-06 22:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:31:40.780036"
    },
    {
      "arxiv_id": "2411.00073v2",
      "title": "RSL-SQL: Robust Schema Linking in Text-to-SQL Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenbiao Cao",
        "Yuanlei Zheng",
        "Zhihao Fan",
        "Xiaojin Zhang",
        "Wei Chen",
        "Xiang Bai"
      ],
      "abstract": "Text-to-SQL generation aims to translate natural language questions into SQL\nstatements. In Text-to-SQL based on large language models, schema linking is a\nwidely adopted strategy to streamline the input for LLMs by selecting only\nrelevant schema elements, therefore reducing noise and computational overhead.\nHowever, schema linking faces risks that require caution, including the\npotential omission of necessary elements and disruption of database structural\nintegrity. To address these challenges, we propose a novel framework called\nRSL-SQL that combines bidirectional schema linking, contextual information\naugmentation, binary selection strategy, and multi-turn self-correction. We\nimprove the recall of pattern linking using forward and backward pruning\nmethods, achieving a strict recall of 94% while reducing the number of input\ncolumns by 83%. Furthermore, it hedges the risk by voting between a full mode\nand a simplified mode enhanced with contextual information. Experiments on the\nBIRD and Spider benchmarks demonstrate that our approach achieves SOTA\nexecution accuracy among open-source solutions, with 67.2% on BIRD and 87.9% on\nSpider using GPT-4o. Furthermore, our approach outperforms a series of GPT-4\nbased Text-to-SQL systems when adopting DeepSeek (much cheaper) with same\nintact prompts. Extensive analysis and ablation studies confirm the\neffectiveness of each component in our framework. The codes are available at\nhttps://github.com/Laqcce-cao/RSL-SQL.",
      "tldr_zh": "本研究提出 RSL-SQL 框架，以提升 Text-to-SQL 生成中的 schema linking 鲁棒性，通过双向 schema linking、上下文信息增强、二进制选择策略和多轮自校正机制，解决元素遗漏和结构完整性问题，同时将 strict recall 提高到 94% 并减少 83% 输入列。框架采用 full mode 和 simplified mode 投票方式来规避风险，并在 BIRD 和 Spider 基准上实现 SOTA 执行准确率，分别为 67.2% 和 87.9% 使用 GPT-4o。实验结果表明，RSL-SQL 即使采用更廉价的 DeepSeek 模型，也优于基于 GPT-4 的系统，证明了各组件的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00073v2",
      "published_date": "2024-10-31 16:22:26 UTC",
      "updated_date": "2024-11-26 13:55:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:31:52.973863"
    },
    {
      "arxiv_id": "2410.24087v1",
      "title": "In-Context Fine-Tuning for Time-Series Foundation Models",
      "title_zh": "针对时间序列基础模型的上下文",
      "authors": [
        "Abhimanyu Das",
        "Matthew Faw",
        "Rajat Sen",
        "Yichen Zhou"
      ],
      "abstract": "Motivated by the recent success of time-series foundation models for\nzero-shot forecasting, we present a methodology for $\\textit{in-context\nfine-tuning}$ of a time-series foundation model. In particular, we design a\npretrained foundation model that can be prompted (at inference time) with\nmultiple time-series examples, in order to forecast a target time-series into\nthe future. Our foundation model is specifically trained to utilize examples\nfrom multiple related time-series in its context window (in addition to the\nhistory of the target time-series) to help it adapt to the specific\ndistribution of the target domain at inference time. We show that such a\nfoundation model that uses in-context examples at inference time can obtain\nmuch better performance on popular forecasting benchmarks compared to\nsupervised deep learning methods, statistical models, as well as other\ntime-series foundation models. Interestingly, our in-context fine-tuning\napproach even rivals the performance of a foundation model that is explicitly\nfine-tuned on the target domain.",
      "tldr_zh": "本论文提出了一种in-context fine-tuning方法，用于时间序列基础模型，以提升零样本预测性能。该方法训练模型在推理时利用上下文窗口中的多个相关时间序列例子（结合目标序列历史），帮助其适应目标领域的特定分布。实验结果表明，该方法在流行预测基准上优于监督深度学习方法、统计模型以及其他时间序列基础模型，甚至可与显式在目标领域微调的模型匹敌。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24087v1",
      "published_date": "2024-10-31 16:20:04 UTC",
      "updated_date": "2024-10-31 16:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:32:03.543124"
    },
    {
      "arxiv_id": "2410.24080v2",
      "title": "Graph Learning for Numeric Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Z. Chen",
        "Sylvie Thiébaux"
      ],
      "abstract": "Graph learning is naturally well suited for use in symbolic, object-centric\nplanning due to its ability to exploit relational structures exhibited in\nplanning domains and to take as input planning instances with arbitrary numbers\nof objects. Numeric planning is an extension of symbolic planning in which\nstates may now also exhibit numeric variables. In this work, we propose\ndata-efficient and interpretable machine learning models for learning to solve\nnumeric planning tasks. This involves constructing a new graph kernel for\ngraphs with both continuous and categorical attributes, as well as new\noptimisation methods for learning heuristic functions for numeric planning.\nExperiments show that our graph kernels are vastly more efficient and\ngeneralise better than graph neural networks for numeric planning, and also\nyield competitive coverage performance compared to domain-independent numeric\nplanners. Code is available at https://github.com/DillonZChen/goose",
      "tldr_zh": "这篇论文探讨了图学习（Graph Learning）在数值规划（Numeric Planning）中的应用，旨在通过利用关系结构处理带有数值变量的规划任务。作者提出了一种数据高效且可解释的机器学习模型，包括构建新的图核（Graph Kernel）来处理图中连续和分类属性，以及开发优化方法来学习启发式函数（Heuristic Functions）。实验结果表明，该图核比图神经网络（Graph Neural Networks）更高效、泛化性能更好，并在任务覆盖率上与领域无关的数值规划器竞争。代码已在 GitHub 上提供。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of NeurIPS 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2410.24080v2",
      "published_date": "2024-10-31 16:16:51 UTC",
      "updated_date": "2025-01-07 03:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:32:16.065186"
    },
    {
      "arxiv_id": "2411.10454v1",
      "title": "Biotic Browser: Applying StreamingLLM as a Persistent Web Browsing Co-Pilot",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin F. Dunnell",
        "Andrew P. Stoddard"
      ],
      "abstract": "This paper presents \"Biotic Browser,\" an innovative AI assistant leveraging\nStreamingLLM to transform web navigation and task execution. Characterized by\nits ability to simulate the experience of a passenger in an autonomous vehicle,\nthe Biotic Browser excels in managing extended interactions and complex,\nmulti-step web-based tasks. It marks a significant advancement in AI\ntechnology, particularly in the realm of long-term context management, and\noffers promising applications for enhancing productivity and efficiency in both\npersonal and professional settings.",
      "tldr_zh": "本论文提出 Biotic Browser，这是一个基于 StreamingLLM 的创新 AI 助手，用于提升网页导航和任务执行效率。Biotic Browser 通过模拟自主车辆乘客的体验，擅长处理长期互动和复杂的多步网页任务，在长期上下文管理方面实现了重大技术进步。实验结果表明，该系统为个人和专业环境带来更高的生产力和效率，具有广泛的应用潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Written December 2023",
      "pdf_url": "http://arxiv.org/pdf/2411.10454v1",
      "published_date": "2024-10-31 16:12:02 UTC",
      "updated_date": "2024-10-31 16:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:32:27.470075"
    },
    {
      "arxiv_id": "2410.24070v4",
      "title": "Dynamical similarity analysis can identify compositional dynamics developing in RNNs",
      "title_zh": "动态相似性分析可以识别在 RNNs 中发展的组合动态",
      "authors": [
        "Quentin Guilhot",
        "Michał Wójcik",
        "Jascha Achterberg",
        "Rui Ponte Costa"
      ],
      "abstract": "Methods for analyzing representations in neural systems have become a popular\ntool in both neuroscience and mechanistic interpretability. Having measures to\ncompare how similar activations of neurons are across conditions,\narchitectures, and species, gives us a scalable way of learning how information\nis transformed within different neural networks. In contrast to this trend,\nrecent investigations have revealed how some metrics can respond to spurious\nsignals and hence give misleading results. To identify the most reliable metric\nand understand how measures could be improved, it is going to be important to\nidentify specific test cases which can serve as benchmarks. Here we propose\nthat the phenomena of compositional learning in recurrent neural networks\n(RNNs) allows us to build a test case for dynamical representation alignment\nmetrics. By implementing this case, we show it enables us to test whether\nmetrics can identify representations which gradually develop throughout\nlearning and probe whether representations identified by metrics are relevant\nto computations executed by networks. By building both an attractor- and\nRNN-based test case, we show that the new Dynamical Similarity Analysis (DSA)\nis more noise robust and identifies behaviorally relevant representations more\nreliably than prior metrics (Procrustes, CKA). We also show how test cases can\nbe used beyond evaluating metrics to study new architectures. Specifically,\nresults from applying DSA to modern (Mamba) state space models, suggest that,\nin contrast to RNNs, these models may not exhibit changes to their recurrent\ndynamics due to their expressiveness. Overall, by developing test cases, we\nshow DSA's exceptional ability to detect compositional dynamical motifs,\nthereby enhancing our understanding of how computations unfold in RNNs.",
      "tldr_zh": "这篇论文提出Dynamical Similarity Analysis (DSA) 作为一种新的方法，用于分析RNNs中逐渐发展的组合动态表示，并通过构建RNN和吸引子模型的测试案例来评估指标的可靠性。相比现有指标如Procrustes和CKA，DSA更具噪声鲁棒性，能更准确地识别与网络计算相关的行为表示。研究还发现，应用DSA到现代状态空间模型如Mamba时，这些模型可能不像RNNs那样改变循环动态，从而提升了对神经网络计算过程的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.24070v4",
      "published_date": "2024-10-31 16:07:21 UTC",
      "updated_date": "2024-12-21 17:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:32:39.672810"
    },
    {
      "arxiv_id": "2410.24059v2",
      "title": "Identifying General Mechanism Shifts in Linear Causal Representations",
      "title_zh": "识别线性因果表示中的一般机制转移",
      "authors": [
        "Tianyu Chen",
        "Kevin Bello",
        "Francesco Locatello",
        "Bryon Aragam",
        "Pradeep Ravikumar"
      ],
      "abstract": "We consider the linear causal representation learning setting where we\nobserve a linear mixing of $d$ unknown latent factors, which follow a linear\nstructural causal model. Recent work has shown that it is possible to recover\nthe latent factors as well as the underlying structural causal model over them,\nup to permutation and scaling, provided that we have at least $d$ environments,\neach of which corresponds to perfect interventions on a single latent node\n(factor). After this powerful result, a key open problem faced by the community\nhas been to relax these conditions: allow for coarser than perfect single-node\ninterventions, and allow for fewer than $d$ of them, since the number of latent\nfactors $d$ could be very large. In this work, we consider precisely such a\nsetting, where we allow a smaller than $d$ number of environments, and also\nallow for very coarse interventions that can very coarsely \\textit{change the\nentire causal graph over the latent factors}. On the flip side, we relax what\nwe wish to extract to simply the \\textit{list of nodes that have shifted\nbetween one or more environments}. We provide a surprising identifiability\nresult that it is indeed possible, under some very mild standard assumptions,\nto identify the set of shifted nodes. Our identifiability proof moreover is a\nconstructive one: we explicitly provide necessary and sufficient conditions for\na node to be a shifted node, and show that we can check these conditions given\nobserved data. Our algorithm lends itself very naturally to the sample setting\nwhere instead of just interventional distributions, we are provided datasets of\nsamples from each of these distributions. We corroborate our results on both\nsynthetic experiments as well as an interesting psychometric dataset. The code\ncan be found at https://github.com/TianyuCodings/iLCS.",
      "tldr_zh": "这篇论文探讨了线性因果表示学习中的一般机制变化识别问题，观察到 d 个潜变量(latent factors)的线性混合，并允许少于 d 个环境以及粗糙的干预，如整个因果图的改变。作者证明，在一些温和的标准假设下，可以识别环境之间变化的节点(shifted nodes)，并提供了构造性的算法来检查这些节点的必要和充分条件。实验结果通过合成数据和心理测量数据集验证了该方法的有效性，并附有代码实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.24059v2",
      "published_date": "2024-10-31 15:56:50 UTC",
      "updated_date": "2024-11-02 02:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:32:52.366753"
    },
    {
      "arxiv_id": "2410.24035v1",
      "title": "State- and context-dependent robotic manipulation and grasping via uncertainty-aware imitation learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tim R. Winter",
        "Ashok M. Sundaram",
        "Werner Friedl",
        "Maximo A. Roa",
        "Freek Stulp",
        "João Silvério"
      ],
      "abstract": "Generating context-adaptive manipulation and grasping actions is a\nchallenging problem in robotics. Classical planning and control algorithms tend\nto be inflexible with regard to parameterization by external variables such as\nobject shapes. In contrast, Learning from Demonstration (LfD) approaches, due\nto their nature as function approximators, allow for introducing external\nvariables to modulate policies in response to the environment. In this paper,\nwe utilize this property by introducing an LfD approach to acquire\ncontext-dependent grasping and manipulation strategies. We treat the problem as\na kernel-based function approximation, where the kernel inputs include generic\ncontext variables describing task-dependent parameters such as the object\nshape. We build on existing work on policy fusion with uncertainty\nquantification to propose a state-dependent approach that automatically returns\nto demonstrations, avoiding unpredictable behavior while smoothly adapting to\ncontext changes. The approach is evaluated against the LASA handwriting dataset\nand on a real 7-DoF robot in two scenarios: adaptation to slippage while\ngrasping and manipulating a deformable food item.",
      "tldr_zh": "这篇论文提出了一种基于不确定性感知的模仿学习（LfD）方法，用于实现机器人抓取和操作动作的适应性，解决传统算法在处理外部变量（如物体形状）时的 inflexible 问题。方法将问题视为核-based 函数逼近，引入任务相关的上下文变量，并通过政策融合（policy fusion）和不确定性量化，确保策略在状态变化时自动返回到演示行为，同时平滑适应环境。实验在 LASA 手写数据集以及真实 7-DoF 机器人上验证了该方法的有效性，包括适应抓取时的滑动和操作可变形食物场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24035v1",
      "published_date": "2024-10-31 15:32:32 UTC",
      "updated_date": "2024-10-31 15:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:33:04.070937"
    },
    {
      "arxiv_id": "2411.00069v1",
      "title": "Meta-Sealing: A Revolutionizing Integrity Assurance Protocol for Transparent, Tamper-Proof, and Trustworthy AI System",
      "title_zh": "翻译失败",
      "authors": [
        "Mahesh Vaijainthymala Krishnamoorthy"
      ],
      "abstract": "The Artificial intelligence in critical sectors-healthcare, finance, and\npublic safety-has made system integrity paramount for maintaining societal\ntrust. Current verification methods for AI systems lack comprehensive lifecycle\nassurance, creating significant vulnerabilities in deployment of both powerful\nand trustworthy AI. This research introduces Meta-Sealing, a cryptographic\nframework that fundamentally changes integrity verification in AI systems\nthroughout their operational lifetime. Meta-Sealing surpasses traditional\nintegrity protocols through its implementation of cryptographic seal chains,\nestablishing verifiable, immutable records for all system decisions and\ntransformations. The framework combines advanced cryptography with distributed\nverification, delivering tamper-evident guarantees that achieve both\nmathematical rigor and computational efficiency. Our implementation addresses\nurgent regulatory requirements for AI system transparency and auditability. The\nframework integrates with current AI governance standards, specifically the\nEU's AI Act and FDA's healthcare AI guidelines, enabling organizations to\nmaintain operational efficiency while meeting compliance requirements. Testing\non financial institution data demonstrated Meta-Sealing's capability to reduce\naudit timeframes by 62% while enhancing stakeholder confidence by 47%. Results\ncan establish a new benchmark for integrity assurance in enterprise AI\ndeployments. This research presents Meta-Sealing not merely as a technical\nsolution, but as a foundational framework ensuring AI system integrity aligns\nwith human values and regulatory requirements. As AI continues to influence\ncritical decisions, provides the necessary bridge between technological\nadvancement and verifiable trust. Meta-Sealing serves as a guardian of trust,\nensuring that the AI systems we depend on are as reliable and transparent as\nthey are powerful.",
      "tldr_zh": "这篇论文引入了 Meta-Sealing，一种革命性的加密框架，用于确保 AI 系统在整个生命周期中的透明、防篡改和可信赖性。Meta-Sealing 通过 cryptographic seal chains 和分布式验证，建立可验证的不可变记录，结合高级加密技术以实现数学严谨性和计算效率。实验结果显示，在金融数据测试中，该框架将审计时间减少 62%，并提升利益相关者信心 47%，同时符合 EU's AI Act 和 FDA's healthcare AI guidelines 的合规要求。该框架不仅作为技术解决方案，还为 AI 系统完整性提供基准，确保其与人类价值观和法规保持一致。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 3 figures and 10 Code blocks, to be presented in the\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2411.00069v1",
      "published_date": "2024-10-31 15:31:22 UTC",
      "updated_date": "2024-10-31 15:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:33:16.600786"
    },
    {
      "arxiv_id": "2410.24032v1",
      "title": "Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks",
      "title_zh": "导航未知：一种基于聊天的协作界面，用于个性化的探索性任务",
      "authors": [
        "Yingzhe Peng",
        "Xiaoting Qin",
        "Zhiyang Zhang",
        "Jue Zhang",
        "Qingwei Lin",
        "Xu Yang",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "The rise of large language models (LLMs) has revolutionized user interactions\nwith knowledge-based systems, enabling chatbots to synthesize vast amounts of\ninformation and assist with complex, exploratory tasks. However, LLM-based\nchatbots often struggle to provide personalized support, particularly when\nusers start with vague queries or lack sufficient contextual information. This\npaper introduces the Collaborative Assistant for Personalized Exploration\n(CARE), a system designed to enhance personalization in exploratory tasks by\ncombining a multi-agent LLM framework with a structured user interface. CARE's\ninterface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling\niterative query refinement and dynamic solution generation. The multi-agent\nframework collaborates to identify both explicit and implicit user needs,\ndelivering tailored, actionable solutions. In a within-subject user study with\n22 participants, CARE was consistently preferred over a baseline LLM chatbot,\nwith users praising its ability to reduce cognitive load, inspire creativity,\nand provide more tailored solutions. Our findings highlight CARE's potential to\ntransform LLM-based systems from passive information retrievers to proactive\npartners in personalized problem-solving and exploration.",
      "tldr_zh": "该论文介绍了 CARE 系统，一种基于多-agent LLM 框架的聊天界面，旨在提升大型语言模型（LLMs）在处理模糊查询和个性化探索任务中的支持能力。CARE 通过结合 Chat Panel、Solution Panel 和 Needs Panel 的结构化界面，实现用户需求的迭代优化和动态生成定制解决方案。用户研究显示，与基线 LLM 聊天机器人相比，22 名参与者更青睐 CARE，因为它能降低认知负担、激发创造力，并提供更个性化的问题解决支持，最终将 LLM 系统从被动信息检索器转变为主动合作伙伴。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24032v1",
      "published_date": "2024-10-31 15:30:55 UTC",
      "updated_date": "2024-10-31 15:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:33:28.068171"
    },
    {
      "arxiv_id": "2410.24031v3",
      "title": "A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Ariel Larey",
        "Eyal Rond",
        "Omer Achrack"
      ],
      "abstract": "Face recognition technologies are increasingly used in various applications,\nyet they are vulnerable to face spoofing attacks. These spoofing attacks often\ninvolve unique 3D structures, such as printed papers or mobile device screens.\nAlthough stereo-depth cameras can detect such attacks effectively, their\nhigh-cost limits their widespread adoption. Conversely, two-sensor systems\nwithout extrinsic calibration offer a cost-effective alternative but are unable\nto calculate depth using stereo techniques. In this work, we propose a method\nto overcome this challenge by leveraging facial attributes to derive disparity\ninformation and estimate relative depth for anti-spoofing purposes, using\nnon-calibrated systems. We introduce a multi-modal anti-spoofing model, coined\nDisparity Model, that incorporates created disparity maps as a third modality\nalongside the two original sensor modalities. We demonstrate the effectiveness\nof the Disparity Model in countering various spoof attacks using a\ncomprehensive dataset collected from the Intel RealSense ID Solution F455. Our\nmethod outperformed existing methods in the literature, achieving an Equal\nError Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False\nPositive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the\nerrors of the best comparison method, respectively. Additionally, we introduce\na model ensemble that addresses 3D spoof attacks as well, achieving an EER of\n2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a\nstate-of-the-art solution for the challenging task of anti-spoofing in\nnon-calibrated systems that lack depth information.",
      "tldr_zh": "这篇论文提出了一种多模态方法，用于非校准系统的面部反欺骗攻击，通过利用面部属性生成Disparity Maps来估计相对深度，从而克服传统两传感器系统无法计算深度的挑战。  \n他们引入了Disparity Model，将创建的差异地图作为第三模态，与原始传感器模态结合，形成一个有效的反欺骗框架。  \n实验结果显示，该模型在Intel RealSense ID Solution F455数据集上表现优越，Equal Error Rate (EER)为1.71%、False Negative Rate (FNR)为2.77%（在False Positive Rate (FPR)为1%时），分别比最佳比较方法低2.45%和7.94%。  \n此外，论文还开发了模型集成来应对3D欺骗攻击，进一步将EER降至2.04%，为缺乏深度信息的系统提供先进的反欺骗解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24031v3",
      "published_date": "2024-10-31 15:29:51 UTC",
      "updated_date": "2025-01-16 13:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:33:41.373166"
    },
    {
      "arxiv_id": "2410.24024v2",
      "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents",
      "title_zh": "AndroidLab：Android 自治代理的训练和系统性基准测试",
      "authors": [
        "Yifan Xu",
        "Xiao Liu",
        "Xueqiao Sun",
        "Siyi Cheng",
        "Hao Yu",
        "Hanyu Lai",
        "Shudan Zhang",
        "Dan Zhang",
        "Jie Tang",
        "Yuxiao Dong"
      ],
      "abstract": "Autonomous agents have become increasingly important for interacting with the\nreal world. Android agents, in particular, have been recently a\nfrequently-mentioned interaction method. However, existing studies for training\nand evaluating Android agents lack systematic research on both open-source and\nclosed-source models. In this work, we propose AndroidLab as a systematic\nAndroid agent framework. It includes an operation environment with different\nmodalities, action space, and a reproducible benchmark. It supports both large\nlanguage models (LLMs) and multimodal models (LMMs) in the same action space.\nAndroidLab benchmark includes predefined Android virtual devices and 138 tasks\nacross nine apps built on these devices. By using the AndroidLab environment,\nwe develop an Android Instruction dataset and train six open-source LLMs and\nLMMs, lifting the average success rates from 4.59% to 21.50% for LLMs and from\n1.93% to 13.28% for LMMs. AndroidLab is open-sourced and publicly available at\nhttps://github.com/THUDM/Android-Lab.",
      "tldr_zh": "本研究提出AndroidLab框架，用于系统训练和基准测试Android自主代理，以填补现有研究对开源和闭源模型的缺失。该框架包括多模态操作环境、统一的行动空间以及可复现基准，涵盖预定义的Android虚拟设备和138个跨九个应用的任务，支持LLMs和LMMs模型。通过AndroidLab，研究者开发了Android指令数据集，并训练了六个开源LLMs和LMMs模型，将LLMs的平均成功率从4.59%提升至21.50%，LMMs从1.93%提升至13.28%。AndroidLab已开源，代码可在https://github.com/THUDM/Android-Lab获取，为Android代理的开发提供可靠工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24024v2",
      "published_date": "2024-10-31 15:25:20 UTC",
      "updated_date": "2024-11-04 05:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:33:51.562378"
    },
    {
      "arxiv_id": "2410.24022v1",
      "title": "SFM-Protein: Integrative Co-evolutionary Pre-training for Advanced Protein Sequence Representation",
      "title_zh": "SFM-Protein：整合共同进化预训练用于高级蛋白质序列表示",
      "authors": [
        "Liang He",
        "Peiran Jin",
        "Yaosen Min",
        "Shufang Xie",
        "Lijun Wu",
        "Tao Qin",
        "Xiaozhuan Liang",
        "Kaiyuan Gao",
        "Yuliang Jiang",
        "Tie-Yan Liu"
      ],
      "abstract": "Proteins, essential to biological systems, perform functions intricately\nlinked to their three-dimensional structures. Understanding the relationship\nbetween protein structures and their amino acid sequences remains a core\nchallenge in protein modeling. While traditional protein foundation models\nbenefit from pre-training on vast unlabeled datasets, they often struggle to\ncapture critical co-evolutionary information, which evolutionary-based methods\nexcel at. In this study, we introduce a novel pre-training strategy for protein\nfoundation models that emphasizes the interactions among amino acid residues to\nenhance the extraction of both short-range and long-range co-evolutionary\nfeatures from sequence data. Trained on a large-scale protein sequence dataset,\nour model demonstrates superior generalization ability, outperforming\nestablished baselines of similar size, including the ESM model, across diverse\ndownstream tasks. Experimental results confirm the model's effectiveness in\nintegrating co-evolutionary information, marking a significant step forward in\nprotein sequence-based modeling.",
      "tldr_zh": "本文提出SFM-Protein，一种整合co-evolutionary预训练策略的蛋白质基础模型，旨在提升蛋白质序列表示并解决传统模型在捕获氨基酸残基相互作用方面的不足。该策略强调氨基酸残基间的互动，以从序列数据中更有效地提取短程和长程co-evolutionary特征，并在大型蛋白质序列数据集上进行训练。实验结果显示，该模型在各种下游任务上超越了类似规模的基线模型，如ESM模型，展现出卓越的泛化能力。该研究标志着蛋白质序列建模领域的重大进步。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24022v1",
      "published_date": "2024-10-31 15:22:03 UTC",
      "updated_date": "2024-10-31 15:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:34:04.452922"
    },
    {
      "arxiv_id": "2410.24017v1",
      "title": "Assessing the Impact of Packing on Machine Learning-Based Malware Detection and Classification Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Gibert",
        "Nikolaos Totosis",
        "Constantinos Patsakis",
        "Giulio Zizzo",
        "Quan Le"
      ],
      "abstract": "The proliferation of malware, particularly through the use of packing,\npresents a significant challenge to static analysis and signature-based malware\ndetection techniques. The application of packing to the original executable\ncode renders extracting meaningful features and signatures challenging. To deal\nwith the increasing amount of malware in the wild, researchers and anti-malware\ncompanies started harnessing machine learning capabilities with very promising\nresults. However, little is known about the effects of packing on static\nmachine learning-based malware detection and classification systems. This work\naddresses this gap by investigating the impact of packing on the performance of\nstatic machine learning-based models used for malware detection and\nclassification, with a particular focus on those using visualisation\ntechniques. To this end, we present a comprehensive analysis of various packing\ntechniques and their effects on the performance of machine learning-based\ndetectors and classifiers. Our findings highlight the limitations of current\nstatic detection and classification systems and underscore the need to be\nproactive to effectively counteract the evolving tactics of malware authors.",
      "tldr_zh": "这篇论文评估了打包（packing）技术对基于机器学习（machine learning-based）的恶意软件检测和分类系统的性能影响，特别是在静态分析和使用可视化技术的模型中。研究者通过全面分析多种打包技术及其对检测器和分类器的效果，揭示了这些技术如何使特征提取和签名识别变得困难，导致系统准确率下降。结果强调了当前静态系统的局限性，并呼吁开发更主动的策略来应对恶意软件作者不断演变的战术。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.24017v1",
      "published_date": "2024-10-31 15:19:33 UTC",
      "updated_date": "2024-10-31 15:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:34:15.652009"
    },
    {
      "arxiv_id": "2410.23996v2",
      "title": "An Information Criterion for Controlled Disentanglement of Multimodal Data",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Wang",
        "Sharut Gupta",
        "Xinyi Zhang",
        "Sana Tonekaboni",
        "Stefanie Jegelka",
        "Tommi Jaakkola",
        "Caroline Uhler"
      ],
      "abstract": "Multimodal representation learning seeks to relate and decompose information\ninherent in multiple modalities. By disentangling modality-specific information\nfrom information that is shared across modalities, we can improve\ninterpretability and robustness and enable downstream tasks such as the\ngeneration of counterfactual outcomes. Separating the two types of information\nis challenging since they are often deeply entangled in many real-world\napplications. We propose Disentangled Self-Supervised Learning\n(DisentangledSSL), a novel self-supervised approach for learning disentangled\nrepresentations. We present a comprehensive analysis of the optimality of each\ndisentangled representation, particularly focusing on the scenario not covered\nin prior work where the so-called Minimum Necessary Information (MNI) point is\nnot attainable. We demonstrate that DisentangledSSL successfully learns shared\nand modality-specific features on multiple synthetic and real-world datasets\nand consistently outperforms baselines on various downstream tasks, including\nprediction tasks for vision-language data, as well as molecule-phenotype\nretrieval tasks for biological data. The code is available at\nhttps://github.com/uhlerlab/DisentangledSSL.",
      "tldr_zh": "该论文探讨多模态表示学习（Multimodal representation learning），旨在通过分离共享信息和模态特定信息来提升可解释性和鲁棒性，支持下游任务如生成反事实结果（counterfactual outcomes）。作者提出了一种新颖的自监督方法Disentangled Self-Supervised Learning (DisentangledSSL)，用于处理真实场景中深度纠缠的信息。论文对每个分离表示的优化性进行了全面分析，特别是当Minimum Necessary Information (MNI)点不可达时。实验结果显示，DisentangledSSL在多个合成和真实数据集上成功学习共享和模态特定特征，并在视觉-语言预测以及分子-表型检索任务中 consistently outperform 基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23996v2",
      "published_date": "2024-10-31 14:57:31 UTC",
      "updated_date": "2025-03-17 16:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:34:28.225639"
    },
    {
      "arxiv_id": "2410.23991v1",
      "title": "Localization, balance and affinity: a stronger multifaceted collaborative salient object detector in remote sensing images",
      "title_zh": "翻译失败",
      "authors": [
        "Yakun Xie",
        "Suning Liu",
        "Hongyu Chen",
        "Shaohan Cao",
        "Huixin Zhang",
        "Dejun Feng",
        "Qian Wan",
        "Jun Zhu",
        "Qing Zhu"
      ],
      "abstract": "Despite significant advancements in salient object detection(SOD) in optical\nremote sensing images(ORSI), challenges persist due to the intricate edge\nstructures of ORSIs and the complexity of their contextual relationships.\nCurrent deep learning approaches encounter difficulties in accurately\nidentifying boundary features and lack efficiency in collaboratively modeling\nthe foreground and background by leveraging contextual features. To address\nthese challenges, we propose a stronger multifaceted collaborative salient\nobject detector in ORSIs, termed LBA-MCNet, which incorporates aspects of\nlocalization, balance, and affinity. The network focuses on accurately locating\ntargets, balancing detailed features, and modeling image-level global context\ninformation. Specifically, we design the Edge Feature Adaptive Balancing and\nAdjusting(EFABA) module for precise edge localization, using edge features to\nguide attention to boundaries and preserve spatial details. Moreover, we design\nthe Global Distributed Affinity Learning(GDAL) module to model global context.\nIt captures global context by generating an affinity map from the encoders\nfinal layer, ensuring effective modeling of global patterns. Additionally, deep\nsupervision during deconvolution further enhances feature representation.\nFinally, we compared with 28 state of the art approaches on three publicly\navailable datasets. The results clearly demonstrate the superiority of our\nmethod.",
      "tldr_zh": "该研究针对光学遥感图像（ORSI）中的显著物体检测（SOD）面临的复杂边缘结构和上下文关系挑战，提出了一种更强的多方面协作检测器LBA-MCNet，强调定位、平衡和亲和力三个方面。该框架设计了Edge Feature Adaptive Balancing and Adjusting (EFABA)模块，用于精确边缘定位，通过边缘特征引导注意力并保留空间细节；以及Global Distributed Affinity Learning (GDAL)模块，用于建模全局上下文信息，从编码器的最后一层生成亲和力映射以捕获全局模式。此外，通过深度监督增强反卷积特征表示。在三个公开数据集上与28种最先进方法比较，LBA-MCNet显示出显著的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23991v1",
      "published_date": "2024-10-31 14:50:48 UTC",
      "updated_date": "2024-10-31 14:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:34:40.063697"
    },
    {
      "arxiv_id": "2410.23975v1",
      "title": "Average Controlled and Average Natural Micro Direct Effects in Summary Causal Graphs",
      "title_zh": "在总结因果图中的平均控制微观直接效应和平均自然微观直接效应",
      "authors": [
        "Simon Ferreira",
        "Charles K. Assaad"
      ],
      "abstract": "In this paper, we investigate the identifiability of average controlled\ndirect effects and average natural direct effects in causal systems represented\nby summary causal graphs, which are abstractions of full causal graphs, often\nused in dynamic systems where cycles and omitted temporal information\ncomplicate causal inference. Unlike in the traditional linear setting, where\ndirect effects are typically easier to identify and estimate, non-parametric\ndirect effects, which are crucial for handling real-world complexities,\nparticularly in epidemiological contexts where relationships between variables\n(e.g, genetic, environmental, and behavioral factors) are often non-linear, are\nmuch harder to define and identify. In particular, we give sufficient\nconditions for identifying average controlled micro direct effect and average\nnatural micro direct effect from summary causal graphs in the presence of\nhidden confounding. Furthermore, we show that the conditions given for the\naverage controlled micro direct effect become also necessary in the setting\nwhere there is no hidden confounding and where we are only interested in\nidentifiability by adjustment.",
      "tldr_zh": "本论文探讨了在总结因果图（summary causal graphs）中识别平均控制直接效应（average controlled direct effects）和平均自然直接效应（average natural direct effects）的可识别性，这些图常用于动态系统以处理循环和遗漏时间信息带来的挑战。论文提供了在存在隐藏混杂（hidden confounding）的情况下，从总结因果图中识别平均控制微直接效应（average controlled micro direct effect）和平均自然微直接效应的充分条件，尤其针对非参数设置中的非线性关系，如流行病学变量。研究进一步证明，在无隐藏混杂且仅通过调整（identifiability by adjustment）来识别时，这些条件对于平均控制微直接效应是必要的，从而提升了真实世界因果推理的准确性。",
      "categories": [
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23975v1",
      "published_date": "2024-10-31 14:30:33 UTC",
      "updated_date": "2024-10-31 14:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:34:53.492299"
    },
    {
      "arxiv_id": "2410.23962v1",
      "title": "Image Synthesis with Class-Aware Semantic Diffusion Models for Surgical Scene Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Zhou",
        "Rebecca Towning",
        "Zaid Awad",
        "Stamatia Giannarou"
      ],
      "abstract": "Surgical scene segmentation is essential for enhancing surgical precision,\nyet it is frequently compromised by the scarcity and imbalance of available\ndata. To address these challenges, semantic image synthesis methods based on\ngenerative adversarial networks and diffusion models have been developed.\nHowever, these models often yield non-diverse images and fail to capture small,\ncritical tissue classes, limiting their effectiveness. In response, we propose\nthe Class-Aware Semantic Diffusion Model (CASDM), a novel approach which\nutilizes segmentation maps as conditions for image synthesis to tackle data\nscarcity and imbalance. Novel class-aware mean squared error and class-aware\nself-perceptual loss functions have been defined to prioritize critical, less\nvisible classes, thereby enhancing image quality and relevance. Furthermore, to\nour knowledge, we are the first to generate multi-class segmentation maps using\ntext prompts in a novel fashion to specify their contents. These maps are then\nused by CASDM to generate surgical scene images, enhancing datasets for\ntraining and validating segmentation models. Our evaluation, which assesses\nboth image quality and downstream segmentation performance, demonstrates the\nstrong effectiveness and generalisability of CASDM in producing realistic\nimage-map pairs, significantly advancing surgical scene segmentation across\ndiverse and challenging datasets.",
      "tldr_zh": "该论文针对手术场景分割中数据稀缺和不平衡的问题，提出了一种新型 Class-Aware Semantic Diffusion Model (CASDM)，它利用分割地图作为条件进行图像合成，并引入 class-aware mean squared error 和 class-aware self-perceptual loss 函数，以优先关注关键但不易捕获的组织类，提升图像质量和多样性。创新性地，论文首次使用文本提示生成多类分割地图，并将其应用于合成手术场景图像，从而增强数据集用于训练和验证分割模型。实验评估证明，CASDM 生成的图像-地图对更真实且泛化性强，能够显著提高下游分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23962v1",
      "published_date": "2024-10-31 14:14:30 UTC",
      "updated_date": "2024-10-31 14:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:35:04.970143"
    },
    {
      "arxiv_id": "2410.23953v3",
      "title": "Representative Social Choice: From Learning Theory to AI Alignment",
      "title_zh": "代表性社会选择：从学习理论到 AI 对齐",
      "authors": [
        "Tianyi Qiu"
      ],
      "abstract": "Social choice theory is the study of preference aggregation across a\npopulation, used both in mechanism design for human agents and in the\ndemocratic alignment of language models. In this study, we propose the\nrepresentative social choice framework for the modeling of democratic\nrepresentation in collective decisions, where the number of issues and\nindividuals are too large for mechanisms to consider all preferences directly.\nThese scenarios are widespread in real-world decision-making processes, such as\njury trials, indirect elections, legislation processes, corporate governance,\nand, more recently, language model alignment. In representative social choice,\nthe population is represented by a finite sample of individual-issue pairs\nbased on which social choice decisions are made. We show that many of the\ndeepest questions in representative social choice can be naturally formulated\nas statistical learning problems, and prove the generalization properties of\nsocial choice mechanisms using the theory of machine learning. We further\nformulate axioms for representative social choice, and prove Arrow-like\nimpossibility theorems with new combinatorial tools of analysis. Our framework\nintroduces the representative approach to social choice, opening up research\ndirections at the intersection of social choice, learning theory, and AI\nalignment.",
      "tldr_zh": "本研究提出“representative social choice”框架，用于建模大规模集体决策中的民主代表问题，例如陪审团审判、间接选举、企业治理和AI alignment等领域，其中决策规模太大无法直接考虑所有偏好。框架将社会选择理论转化为统计学习问题，利用机器学习理论证明了社会选择机制的泛化属性，并制定相关公理，证明了类似Arrow的不可能性定理。总体上，该工作桥接了社会选择理论、学习理论和AI alignment的交叉领域，开辟了新的研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version (20 pages). Under review. Received Best Paper Award at\n  NeurIPS 2024 Pluralistic Alignment Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.23953v3",
      "published_date": "2024-10-31 14:07:26 UTC",
      "updated_date": "2024-12-18 18:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:35:16.934292"
    },
    {
      "arxiv_id": "2410.23934v1",
      "title": "Towards Fast Algorithms for the Preference Consistency Problem Based on Hierarchical Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anne-Marie George",
        "Nic Wilson",
        "Barry O'Sullivan"
      ],
      "abstract": "In this paper, we construct and compare algorithmic approaches to solve the\nPreference Consistency Problem for preference statements based on hierarchical\nmodels. Instances of this problem contain a set of preference statements that\nare direct comparisons (strict and non-strict) between some alternatives, and a\nset of evaluation functions by which all alternatives can be rated. An instance\nis consistent based on hierarchical preference models, if there exists an\nhierarchical model on the evaluation functions that induces an order relation\non the alternatives by which all relations given by the preference statements\nare satisfied. Deciding if an instance is consistent is known to be NP-complete\nfor hierarchical models. We develop three approaches to solve this decision\nproblem. The first involves a Mixed Integer Linear Programming (MILP)\nformulation, the other two are recursive algorithms that are based on\nproperties of the problem by which the search space can be pruned. Our\nexperiments on synthetic data show that the recursive algorithms are faster\nthan solving the MILP formulation and that the ratio between the running times\nincreases extremely quickly.",
      "tldr_zh": "本论文针对基于 hierarchical models 的 Preference Consistency Problem，构建并比较了快速算法，以判断偏好语句是否一致。研究开发了三种方法：一个 Mixed Integer Linear Programming (MILP) 公式化，以及两个基于问题属性的递归算法，用于剪枝搜索空间。实验在合成数据上表明，递归算法比 MILP 公式化更快，且两者运行时间差异迅速扩大，为解决该 NP-complete 问题提供了更高效的途径。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Longer Version of IJCAI'16 publication\n  https://www.ijcai.org/Proceedings/16/Papers/157.pdf",
      "pdf_url": "http://arxiv.org/pdf/2410.23934v1",
      "published_date": "2024-10-31 13:48:46 UTC",
      "updated_date": "2024-10-31 13:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:35:27.948919"
    },
    {
      "arxiv_id": "2410.23918v3",
      "title": "BitStack: Any-Size Compression of Large Language Models in Variable Memory Environments",
      "title_zh": "BitStack：大型语言模型的任意尺寸压缩，在可变内存环境",
      "authors": [
        "Xinghao Wang",
        "Pengyu Wang",
        "Bo Wang",
        "Dong Zhang",
        "Yunhua Zhou",
        "Xipeng Qiu"
      ],
      "abstract": "Large language models (LLMs) have revolutionized numerous applications, yet\ntheir deployment remains challenged by memory constraints on local devices.\nWhile scaling laws have enhanced LLM capabilities, the primary bottleneck has\nshifted from \\textit{capability} to \\textit{availability}, emphasizing the need\nfor efficient memory management. Traditional compression methods, such as\nquantization, often require predefined compression ratios and separate\ncompression processes for each setting, complicating deployment in variable\nmemory environments. In this paper, we introduce \\textbf{BitStack}, a novel,\ntraining-free weight compression approach that enables megabyte-level\ntrade-offs between memory usage and model performance. By leveraging weight\ndecomposition, BitStack can dynamically adjust the model size with minimal\ntransmission between running memory and storage devices. Our approach\niteratively decomposes weight matrices while considering the significance of\neach parameter, resulting in an approximately 1-bit per parameter residual\nblock in each decomposition iteration. These blocks are sorted and stacked in\nstorage as basic transmission units, with different quantities loaded based on\ncurrent memory availability. Extensive experiments across a wide range of tasks\ndemonstrate that, despite offering fine-grained size control, BitStack\nconsistently matches or surpasses strong quantization baselines, particularly\nat extreme compression ratios. To the best of our knowledge, this is the first\ndecomposition-based method that effectively bridges the gap to practical\ncompression techniques like quantization. Code is available at\nhttps://github.com/xinghaow99/BitStack.",
      "tldr_zh": "这篇论文提出了 BitStack，一种无需训练的权重压缩方法，用于在可变内存环境中压缩 Large Language Models (LLMs)，实现任意大小的内存使用与性能权衡。BitStack 通过权重分解 (weight decomposition) 技术，迭代分解权重矩阵并根据参数重要性生成约 1 位每参数的残差块 (residual block)，这些块被排序并堆叠在存储中，以便动态加载以适应不同内存可用性。实验结果显示，BitStack 在多种任务中提供细粒度大小控制，并匹配或超过量化 (quantization) 基线，尤其在极端压缩比率下表现出色，这是首个有效桥接分解和量化技术的创新方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23918v3",
      "published_date": "2024-10-31 13:26:11 UTC",
      "updated_date": "2025-02-17 13:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:35:40.919999"
    },
    {
      "arxiv_id": "2410.23916v1",
      "title": "Transformer-based Model Predictive Control: Trajectory Optimization via Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Celestini",
        "Daniele Gammelli",
        "Tommaso Guffanti",
        "Simone D'Amico",
        "Elisa Capello",
        "Marco Pavone"
      ],
      "abstract": "Model predictive control (MPC) has established itself as the primary\nmethodology for constrained control, enabling general-purpose robot autonomy in\ndiverse real-world scenarios. However, for most problems of interest, MPC\nrelies on the recursive solution of highly non-convex trajectory optimization\nproblems, leading to high computational complexity and strong dependency on\ninitialization. In this work, we present a unified framework to combine the\nmain strengths of optimization-based and learning-based methods for MPC. Our\napproach entails embedding high-capacity, transformer-based neural network\nmodels within the optimization process for trajectory generation, whereby the\ntransformer provides a near-optimal initial guess, or target plan, to a\nnon-convex optimization problem. Our experiments, performed in simulation and\nthe real world onboard a free flyer platform, demonstrate the capabilities of\nour framework to improve MPC convergence and runtime. Compared to purely\noptimization-based approaches, results show that our approach can improve\ntrajectory generation performance by up to 75%, reduce the number of solver\niterations by up to 45%, and improve overall MPC runtime by 7x without loss in\nperformance.",
      "tldr_zh": "本文提出了一种基于 Transformer 的 Model Predictive Control (MPC) 框架，通过序列建模来优化轨迹生成，旨在解决传统 MPC 在非凸优化问题中计算复杂性和初始化依赖的问题。该框架将高容量 Transformer 神经网络模型嵌入优化过程，作为近优初始猜测或目标计划，提升整体效率。在模拟和真实世界实验（如 free flyer 平台）中，与纯优化方法相比，该方法将轨迹生成性能提高高达 75%，减少求解器迭代次数达 45%，并将 MPC 运行时间缩短 7 倍，同时保持性能不变。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures. Datasets, videos and code available at:\n  https://transformermpc.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.23916v1",
      "published_date": "2024-10-31 13:23:10 UTC",
      "updated_date": "2024-10-31 13:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:35:51.793121"
    },
    {
      "arxiv_id": "2410.23913v1",
      "title": "Efficient Inference and Computation of Optimal Alternatives for Preference Languages Based On Lexicographic Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nic Wilson",
        "Anne-Marie George"
      ],
      "abstract": "We analyse preference inference, through consistency, for general preference\nlanguages based on lexicographic models. We identify a property, which we call\nstrong compositionality, that applies for many natural kinds of preference\nstatement, and that allows a greedy algorithm for determining consistency of a\nset of preference statements. We also consider different natural definitions of\noptimality, and their relations to each other, for general preference languages\nbased on lexicographic models. Based on our framework, we show that testing\nconsistency, and thus inference, is polynomial for a specific preference\nlanguage LpqT, which allows strict and non-strict statements, comparisons\nbetween outcomes and between partial tuples, both ceteris paribus and strong\nstatements, and their combination. Computing different kinds of optimal sets is\nalso shown to be polynomial; this is backed up by our experimental results.",
      "tldr_zh": "该论文分析了基于 lexicographic models 的偏好语言的推断和优化计算，通过一致性（consistency）来实现高效推理。研究者引入了 strong compositionality 属性，适用于多种自然偏好语句，并开发了贪婪算法（greedy algorithm）来快速确定偏好语句集的一致性。针对特定偏好语言 LpqT，该框架证明了测试一致性以及计算不同类型的最优集均为多项式时间复杂度，并通过实验结果进行了验证。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LO",
      "comment": "Longer Version of IJCAI'17 publication\n  https://www.ijcai.org/proceedings/2017/0182.pdf",
      "pdf_url": "http://arxiv.org/pdf/2410.23913v1",
      "published_date": "2024-10-31 13:19:31 UTC",
      "updated_date": "2024-10-31 13:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:36:03.728300"
    },
    {
      "arxiv_id": "2410.23912v2",
      "title": "RL-STaR: Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner",
      "title_zh": "RL-STaR：自学推理器的强化学习框架理论分析",
      "authors": [
        "Fu-Chieh Chang",
        "Yu-Ting Lee",
        "Hui-Ying Shih",
        "Yi Hsuan Tseng",
        "Pei-Yuan Wu"
      ],
      "abstract": "The reasoning abilities of large language models (LLMs) have improved with\nchain-of-thought (CoT) prompting, allowing models to solve complex tasks\nstepwise. However, training CoT capabilities requires detailed reasoning data,\nwhich is often scarce. The self-taught reasoner (STaR) framework addresses this\nby using reinforcement learning to automatically generate reasoning steps,\nreducing reliance on human-labeled data. Although STaR and its variants have\ndemonstrated empirical success, a theoretical foundation explaining these\nimprovements is lacking. This work provides a theoretical framework for\nunderstanding the effectiveness of reinforcement learning on CoT reasoning and\nSTaR. Our contributions are: (1) criteria for the quality of pre-trained models\nnecessary to initiate effective reasoning improvement; (2) an analysis of\npolicy improvement, showing why LLM reasoning improves iteratively with STaR;\n(3) conditions for convergence to an optimal reasoning policy; and (4) an\nexamination of STaR's robustness, explaining how it can improve reasoning even\nwhen incorporating occasional incorrect steps; This framework aims to bridge\nempirical findings with theoretical insights, advancing reinforcement learning\napproaches for reasoning in LLMs.",
      "tldr_zh": "这篇论文对Self-Taught Reasoner (STaR)框架进行了理论分析，探讨强化学习(Reinforcement Learning)如何提升大型语言模型(LLMs)的Chain-of-Thought (CoT)推理能力，以减少对人类标注数据的依赖。关键贡献包括：提出预训练模型质量的标准以启动有效推理改进、分析政策改进机制解释STaR的迭代优化、定义收敛到最优推理政策的条件，以及评估STaR的鲁棒性，使其即使包含错误步骤也能提升性能。该框架桥接了经验发现与理论洞见，推进了强化学习在LLMs推理中的应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23912v2",
      "published_date": "2024-10-31 13:17:53 UTC",
      "updated_date": "2025-04-10 00:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:36:16.704882"
    },
    {
      "arxiv_id": "2411.11798v1",
      "title": "COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ruisi He",
        "Nicola D. Cicco",
        "Bo Ai",
        "Mi Yang",
        "Yang Miao",
        "Mate Boban"
      ],
      "abstract": "Accurate channel models are the prerequisite for communication-theoretic\ninvestigations as well as system design. Channel modeling generally relies on\nstatistical and deterministic approaches. However, there are still significant\nlimits for the traditional modeling methods in terms of accuracy,\ngeneralization ability, and computational complexity. The fundamental reason is\nthat establishing a quantified and accurate mapping between physical\nenvironment and channel characteristics becomes increasing challenging for\nmodern communication systems. Here, in the context of COST CA20120 Action, we\nevaluate and discuss the feasibility and implementation of using artificial\nintelligence (AI) for channel modeling, and explore where the future of this\nfield lies. Firstly, we present a framework of AI-based channel modeling to\ncharacterize complex wireless channels. Then, we highlight in detail some major\nchallenges and present the possible solutions: i) estimating the uncertainty of\nAI-based channel predictions, ii) integrating prior knowledge of propagation to\nimprove generalization capabilities, and iii) interpretable AI for channel\nmodeling. We present and discuss illustrative numerical results to showcase the\ncapabilities of AI-based channel modeling.",
      "tldr_zh": "本研究在 COST CA20120 Action 的背景下，提出了一种基于 Artificial Intelligence (AI) 的信道建模框架，以解决传统统计和确定性方法的准确性、一般化能力和计算复杂性问题。该框架旨在建立物理环境与信道特性的量化映射，用于表征复杂无线信道，并通过整合 AI 技术提升建模效果。主要挑战包括估计 AI 预测的不确定性、整合传播先验知识以提高泛化能力，以及实现可解释的 AI 建模，而论文提供了可能的解决方案并展示了数值结果，证明了该框架的有效性。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "to appear in IEEE Wireless Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2411.11798v1",
      "published_date": "2024-10-31 13:16:05 UTC",
      "updated_date": "2024-10-31 13:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:36:27.477502"
    },
    {
      "arxiv_id": "2410.23903v1",
      "title": "Neural Network Verification with PyRAT",
      "title_zh": "翻译失败",
      "authors": [
        "Augustin Lemesle",
        "Julien Lehmann",
        "Tristan Le Gall"
      ],
      "abstract": "As AI systems are becoming more and more popular and used in various critical\ndomains (health, transport, energy, ...), the need to provide guarantees and\ntrust of their safety is undeniable. To this end, we present PyRAT, a tool\nbased on abstract interpretation to verify the safety and the robustness of\nneural networks. In this paper, we describe the different abstractions used by\nPyRAT to find the reachable states of a neural network starting from its input\nas well as the main features of the tool to provide fast and accurate analysis\nof neural networks. PyRAT has already been used in several collaborations to\nensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing\nits performance.",
      "tldr_zh": "本论文介绍了 PyRAT，一种基于 abstract interpretation 的工具，用于验证神经网络的安全性和鲁棒性，以满足 AI 系统在关键领域（如健康、交通和能源）的安全需求。该工具通过多种抽象方法分析神经网络从输入开始的可达状态，提供快速且准确的分析功能。PyRAT 已在实际合作中确保安全保证，并在 VNN-Comp 2024 竞赛中获得第二名，证明了其高效性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23903v1",
      "published_date": "2024-10-31 13:05:46 UTC",
      "updated_date": "2024-10-31 13:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:36:40.024840"
    },
    {
      "arxiv_id": "2411.00878v1",
      "title": "Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models",
      "title_zh": "翻译失败",
      "authors": [
        "Phil Wee",
        "Riyadh Baghdadi"
      ],
      "abstract": "Recently, there has been an explosion of large language models created\nthrough fine-tuning with data from larger models. These small models able to\nproduce outputs that appear qualitatively similar to significantly larger\nmodels. However, one of the key limitations that have been observed with these\nmodels is their propensity to hallucinate significantly more often than larger\nmodels. In particular, they have been observed to generate coherent outputs\nthat involve factually incorrect information and spread misinformation,\ntoxicity, and stereotypes. There are many potential causes of hallucination, of\nwhich, one hypothesis is that fine-tuning a model on data produced by a larger\nmodel leads to a knowledge mismatch which contributes to hallucination. In\nparticular, it is hypothesized that there is a mismatch between the knowledge\nthat is fed to the model to fine-tune it and the knowledge that is already\npresent in the graph. Fine-tuning the model on data that has such mismatch\ncould contribute to an increased propensity to hallucinate. We show that on an\nunseen test set, a smaller model fine-tuned on data generated from a larger\nmodel produced more wrong answers when compared to models fine-tuned on data\ncreated by the small model, which confirms the hypothesis.",
      "tldr_zh": "该研究探讨了小模型使用大模型生成数据进行微调时，幻觉（hallucination）倾向增加的现象，假设这源于知识不匹配（knowledge mismatch），即微调数据中的知识与模型原有知识不一致。研究者通过实验比较了小模型分别用大模型数据和自身数据微调后的表现。结果显示，在未见测试集上，用大模型数据微调的小模型产生了更多错误答案，从而证实了知识不匹配假设，并为理解和减少小模型幻觉提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00878v1",
      "published_date": "2024-10-31 13:01:46 UTC",
      "updated_date": "2024-10-31 13:01:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:36:52.165788"
    },
    {
      "arxiv_id": "2410.23891v1",
      "title": "AllClear: A Comprehensive Dataset and Benchmark for Cloud Removal in Satellite Imagery",
      "title_zh": "AllClear：一个全面的数据集",
      "authors": [
        "Hangyu Zhou",
        "Chia-Hsiang Kao",
        "Cheng Perng Phoo",
        "Utkarsh Mall",
        "Bharath Hariharan",
        "Kavita Bala"
      ],
      "abstract": "Clouds in satellite imagery pose a significant challenge for downstream\napplications. A major challenge in current cloud removal research is the\nabsence of a comprehensive benchmark and a sufficiently large and diverse\ntraining dataset. To address this problem, we introduce the largest public\ndataset -- $\\textit{AllClear}$ for cloud removal, featuring 23,742 globally\ndistributed regions of interest (ROIs) with diverse land-use patterns,\ncomprising 4 million images in total. Each ROI includes complete temporal\ncaptures from the year 2022, with (1) multi-spectral optical imagery from\nSentinel-2 and Landsat 8/9, (2) synthetic aperture radar (SAR) imagery from\nSentinel-1, and (3) auxiliary remote sensing products such as cloud masks and\nland cover maps. We validate the effectiveness of our dataset by benchmarking\nperformance, demonstrating the scaling law -- the PSNR rises from $28.47$ to\n$33.87$ with $30\\times$ more data, and conducting ablation studies on the\ntemporal length and the importance of individual modalities. This dataset aims\nto provide comprehensive coverage of the Earth's surface and promote better\ncloud removal results.",
      "tldr_zh": "本研究针对卫星图像中云层干扰的问题，引入了最大的公共数据集 AllClear 和相应的基准测试框架，该数据集包含23,742个全球分布的感兴趣区域(ROIs)，总计4百万图像，覆盖多样化的土地使用模式。\nAllClear 提供2022年完整时间序列数据，包括Sentinel-2和Landsat 8/9的多光谱光学图像、Sentinel-1的合成孔径雷达(SAR)图像，以及辅助遥感产品如云掩码和土地覆盖图。\n通过基准测试，研究证明数据规模效应显著，PSNR从28.47提升至33.87（使用30倍更多数据），并通过消融研究验证了时间长度和各模态的重要性，从而促进更有效的云移除技术发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeurIPS 2024 Datasets and Benchmarks Track. Code and data\n  available at https://allclear.cs.cornell.edu/",
      "pdf_url": "http://arxiv.org/pdf/2410.23891v1",
      "published_date": "2024-10-31 12:52:52 UTC",
      "updated_date": "2024-10-31 12:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:37:05.152077"
    },
    {
      "arxiv_id": "2410.23890v1",
      "title": "Leveraging LLMs for MT in Crisis Scenarios: a blueprint for low-resource languages",
      "title_zh": "翻译失败",
      "authors": [
        "Séamus Lankford",
        "Andy Way"
      ],
      "abstract": "In an evolving landscape of crisis communication, the need for robust and\nadaptable Machine Translation (MT) systems is more pressing than ever,\nparticularly for low-resource languages. This study presents a comprehensive\nexploration of leveraging Large Language Models (LLMs) and Multilingual LLMs\n(MLLMs) to enhance MT capabilities in such scenarios. By focusing on the unique\nchallenges posed by crisis situations where speed, accuracy, and the ability to\nhandle a wide range of languages are paramount, this research outlines a novel\napproach that combines the cutting-edge capabilities of LLMs with fine-tuning\ntechniques and community-driven corpus development strategies. At the core of\nthis study is the development and empirical evaluation of MT systems tailored\nfor two low-resource language pairs, illustrating the process from initial\nmodel selection and fine-tuning through to deployment. Bespoke systems are\ndeveloped and modelled on the recent Covid-19 pandemic. The research highlights\nthe importance of community involvement in creating highly specialised,\ncrisis-specific datasets and compares custom GPTs with NLLB-adapted MLLM\nmodels. It identifies fine-tuned MLLM models as offering superior performance\ncompared with their LLM counterparts. A scalable and replicable model for rapid\nMT system development in crisis scenarios is outlined. Our approach enhances\nthe field of humanitarian technology by offering a blueprint for developing\nmultilingual communication systems during emergencies.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型 (LLMs) 和多语言大型语言模型 (MLLMs) 来提升低资源语言在危机场景中的机器翻译 (MT) 能力，强调速度、准确性和多语言处理的挑战。研究提出了一种新方法，包括模型微调、社区驱动的语料库开发，并针对两个低资源语言对进行了实证评估，以 COVID-19 大流行为例。结果显示，微调后的 MLLM 模型比自定义 GPT 或 NLLB 适配模型表现更优，并提供了一个可扩展、可复制的蓝图，以增强人道主义技术中的紧急多语言通信系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:2403.02370,\n  arXiv:2403.01580",
      "pdf_url": "http://arxiv.org/pdf/2410.23890v1",
      "published_date": "2024-10-31 12:52:26 UTC",
      "updated_date": "2024-10-31 12:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:37:17.815888"
    },
    {
      "arxiv_id": "2410.23889v2",
      "title": "GEPS: Boosting Generalization in Parametric PDE Neural Solvers through Adaptive Conditioning",
      "title_zh": "GEPS：通过自适应条件化提升参数化偏微分方程神经求解器的泛化能力",
      "authors": [
        "Armand Kassaï Koupaï",
        "Jorge Mifsut Benet",
        "Yuan Yin",
        "Jean-Noël Vittaut",
        "Patrick Gallinari"
      ],
      "abstract": "Solving parametric partial differential equations (PDEs) presents significant\nchallenges for data-driven methods due to the sensitivity of spatio-temporal\ndynamics to variations in PDE parameters. Machine learning approaches often\nstruggle to capture this variability. To address this, data-driven approaches\nlearn parametric PDEs by sampling a very large variety of trajectories with\nvarying PDE parameters. We first show that incorporating conditioning\nmechanisms for learning parametric PDEs is essential and that among them,\n$\\textit{adaptive conditioning}$, allows stronger generalization. As existing\nadaptive conditioning methods do not scale well with respect to the number of\nparameters to adapt in the neural solver, we propose GEPS, a simple adaptation\nmechanism to boost GEneralization in Pde Solvers via a first-order optimization\nand low-rank rapid adaptation of a small set of context parameters. We\ndemonstrate the versatility of our approach for both fully data-driven and for\nphysics-aware neural solvers. Validation performed on a whole range of\nspatio-temporal forecasting problems demonstrates excellent performance for\ngeneralizing to unseen conditions including initial conditions, PDE\ncoefficients, forcing terms and solution domain. $\\textit{Project page}$:\nhttps://geps-project.github.io",
      "tldr_zh": "该论文针对参数偏微分方程 (Parametric PDEs) 的求解问题，指出数据驱动方法因时空动态对参数敏感而泛化能力不足，并强调 adaptive conditioning 的重要性。作者提出 GEPS 方法，通过一阶优化和低秩快速适应机制来调整少量上下文参数，从而提升神经求解器的泛化性能。该方法适用于全数据驱动和物理感知神经求解器，并在多种时空预测任务中表现出色，能够有效处理未见条件，如初始条件、PDE 系数、强制项和解域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23889v2",
      "published_date": "2024-10-31 12:51:40 UTC",
      "updated_date": "2024-11-08 14:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:37:29.476561"
    },
    {
      "arxiv_id": "2410.23883v1",
      "title": "'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Rena Gao",
        "Xuetong Wu",
        "Siwen Luo",
        "Caren Han",
        "Feng Liu"
      ],
      "abstract": "Out-of-distribution (OOD) detection in multimodal contexts is essential for\nidentifying deviations in combined inputs from different modalities,\nparticularly in applications like open-domain dialogue systems or real-life\ndialogue interactions. This paper aims to improve the user experience that\ninvolves multi-round long dialogues by efficiently detecting OOD dialogues and\nimages. We introduce a novel scoring framework named Dialogue Image Aligning\nand Enhancing Framework (DIAEF) that integrates the visual language models with\nthe novel proposed scores that detect OOD in two key scenarios (1) mismatches\nbetween the dialogue and image input pair and (2) input pairs with previously\nunseen labels. Our experimental results, derived from various benchmarks,\ndemonstrate that integrating image and multi-round dialogue OOD detection is\nmore effective with previously unseen labels than using either modality\nindependently. In the presence of mismatched pairs, our proposed score\neffectively identifies these mismatches and demonstrates strong robustness in\nlong dialogues. This approach enhances domain-aware, adaptive conversational\nagents and establishes baselines for future studies.",
      "tldr_zh": "这篇论文聚焦于多模态长对话中的 Out-of-Distribution (OOD) 检测，旨在通过识别对话和图像的异常偏差来提升用户体验，特别是针对多轮对话系统。作者提出了一种新型评分框架 Dialogue Image Aligning and Enhancing Framework (DIAEF)，它整合视觉语言模型和创新评分方法，用于检测两种关键场景：对话与图像输入对的不匹配，以及带有未见标签的输入对。实验结果显示，在多种基准上，将图像和多轮对话的 OOD 检测相结合比独立使用单一模态更有效，并在处理不匹配对时展现出强健性。该框架为构建领域感知的自适应对话代理提供了新基准，并推动了未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23883v1",
      "published_date": "2024-10-31 12:45:54 UTC",
      "updated_date": "2024-10-31 12:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:37:42.390977"
    },
    {
      "arxiv_id": "2410.23875v1",
      "title": "Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Liyi Chen",
        "Panrong Tong",
        "Zhongming Jin",
        "Ying Sun",
        "Jieping Ye",
        "Hui Xiong"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable reasoning capabilities on\ncomplex tasks, but they still suffer from out-of-date knowledge,\nhallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)\ncan provide explicit and editable knowledge for LLMs to alleviate these issues.\nExisting paradigm of KG-augmented LLM manually predefines the breadth of\nexploration space and requires flawless navigation in KGs. However, this\nparadigm cannot adaptively explore reasoning paths in KGs based on the question\nsemantics and self-correct erroneous reasoning paths, resulting in a bottleneck\nin efficiency and effect. To address these limitations, we propose a novel\nself-correcting adaptive planning paradigm for KG-augmented LLM named\nPlan-on-Graph (PoG), which first decomposes the question into several\nsub-objectives and then repeats the process of adaptively exploring reasoning\npaths, updating memory, and reflecting on the need to self-correct erroneous\nreasoning paths until arriving at the answer. Specifically, three important\nmechanisms of Guidance, Memory, and Reflection are designed to work together,\nto guarantee the adaptive breadth of self-correcting planning for graph\nreasoning. Finally, extensive experiments on three real-world datasets\ndemonstrate the effectiveness and efficiency of PoG.",
      "tldr_zh": "该研究提出Plan-on-Graph (PoG)，一种自更正的自适应规划范式，用于Knowledge Graphs (KGs)增强Large Language Models (LLMs)，以解决LLMs的过时知识、幻觉和决策不透明问题。PoG通过将问题分解为子目标，并结合Guidance、Memory和Reflection机制，适应性探索推理路径、更新记忆并自我更正错误路径，直至得出答案。与现有方法相比，该范式能动态调整探索广度，提升效率和效果。在三个真实数据集上的实验验证了PoG的有效性和高效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23875v1",
      "published_date": "2024-10-31 12:37:24 UTC",
      "updated_date": "2024-10-31 12:37:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:37:53.341514"
    },
    {
      "arxiv_id": "2411.00066v1",
      "title": "Interpretable Language Modeling via Induction-head Ngram Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eunji Kim",
        "Sriya Mantena",
        "Weiwei Yang",
        "Chandan Singh",
        "Sungroh Yoon",
        "Jianfeng Gao"
      ],
      "abstract": "Recent large language models (LLMs) have excelled across a wide range of\ntasks, but their use in high-stakes and compute-limited settings has\nintensified the demand for interpretability and efficiency. We address this\nneed by proposing Induction-head ngram models (Induction-Gram), a method that\nbuilds an efficient, interpretable LM by bolstering modern ngram models with a\nhand-engineered \"induction head\". This induction head uses a custom neural\nsimilarity metric to efficiently search the model's input context for potential\nnext-word completions. This process enables Induction-Gram to provide\nngram-level grounding for each generated token. Moreover, experiments show that\nthis simple method significantly improves next-word prediction over baseline\ninterpretable models (up to 26%p) and can be used to speed up LLM inference for\nlarge models through speculative decoding. We further study Induction-Gram in a\nnatural-language neuroscience setting, where the goal is to predict the next\nfMRI response in a sequence. It again provides a significant improvement over\ninterpretable models (20% relative increase in the correlation of predicted\nfMRI responses), potentially enabling deeper scientific investigation of\nlanguage selectivity in the brain. The code is available at\nhttps://github.com/ejkim47/induction-gram.",
      "tldr_zh": "本论文提出Induction-Gram，一种可解释语言建模方法，通过在ngram模型中添加手工设计的induction head，利用自定义的neural similarity metric在输入上下文中高效搜索潜在下一词完成，从而为每个生成的token提供ngram-level grounding。相比基线可解释模型，该方法显著提升下一词预测准确率（最高26%），并通过speculative decoding加速大型LLMs的推理过程。在自然语言神经科学应用中，Induction-Gram在预测fMRI响应序列时实现了20%的相对相关性改善，有助于深入探索大脑的语言选择性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00066v1",
      "published_date": "2024-10-31 12:33:26 UTC",
      "updated_date": "2024-10-31 12:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:38:05.607823"
    },
    {
      "arxiv_id": "2410.23855v2",
      "title": "RAGraph: A General Retrieval-Augmented Graph Learning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xinke Jiang",
        "Rihong Qiu",
        "Yongxin Xu",
        "Wentao Zhang",
        "Yichen Zhu",
        "Ruizhe Zhang",
        "Yuchen Fang",
        "Xu Chu",
        "Junfeng Zhao",
        "Yasha Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become essential in interpreting relational\ndata across various domains, yet, they often struggle to generalize to unseen\ngraph data that differs markedly from training instances. In this paper, we\nintroduce a novel framework called General Retrieval-Augmented Graph Learning\n(RAGraph), which brings external graph data into the general graph foundation\nmodel to improve model generalization on unseen scenarios. On the top of our\nframework is a toy graph vector library that we established, which captures key\nattributes, such as features and task-specific label information. During\ninference, the RAGraph adeptly retrieves similar toy graphs based on key\nsimilarities in downstream tasks, integrating the retrieved data to enrich the\nlearning context via the message-passing prompting mechanism. Our extensive\nexperimental evaluations demonstrate that RAGraph significantly outperforms\nstate-of-the-art graph learning methods in multiple tasks such as node\nclassification, link prediction, and graph classification across both dynamic\nand static datasets. Furthermore, extensive testing confirms that RAGraph\nconsistently maintains high performance without the need for task-specific\nfine-tuning, highlighting its adaptability, robustness, and broad\napplicability.",
      "tldr_zh": "该论文提出 RAGraph，一种通用的检索增强图学习框架，旨在解决 Graph Neural Networks (GNNs) 在处理与训练数据显著不同的未见图数据时泛化能力不足的问题。框架通过建立一个 toy graph vector library 来捕获图的关键属性（如特征和任务特定标签信息），并在推理阶段检索相似 toy graphs，并利用 message-passing prompting 机制整合这些数据以丰富学习上下文。实验结果显示，RAGraph 在节点分类、链接预测和图分类等任务上，在动态和静态数据集上显著优于现有方法，且无需任务特定微调，展示了其适应性、稳健性和广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23855v2",
      "published_date": "2024-10-31 12:05:21 UTC",
      "updated_date": "2024-12-07 10:34:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:38:17.369745"
    },
    {
      "arxiv_id": "2410.23844v1",
      "title": "Commonsense Knowledge Editing Based on Free-Text in LLMs",
      "title_zh": "LLMs 中基于自由文本的常识知识编辑",
      "authors": [
        "Xiusheng Huang",
        "Yequan Wang",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Knowledge editing technology is crucial for maintaining the accuracy and\ntimeliness of large language models (LLMs) . However, the setting of this task\noverlooks a significant portion of commonsense knowledge based on free-text in\nthe real world, characterized by broad knowledge scope, long content and non\ninstantiation. The editing objects of previous methods (e.g., MEMIT) were\nsingle token or entity, which were not suitable for commonsense knowledge in\nfree-text form. To address the aforementioned challenges, we conducted\nexperiments from two perspectives: knowledge localization and knowledge\nediting. Firstly, we introduced Knowledge Localization for Free-Text(KLFT)\nmethod, revealing the challenges associated with the distribution of\ncommonsense knowledge in MLP and Attention layers, as well as in decentralized\ndistribution. Next, we propose a Dynamics-aware Editing Method(DEM), which\nutilizes a Dynamics-aware Module to locate the parameter positions\ncorresponding to commonsense knowledge, and uses Knowledge Editing Module to\nupdate knowledge. The DEM method fully explores the potential of the MLP and\nAttention layers, and successfully edits commonsense knowledge based on\nfree-text. The experimental results indicate that the DEM can achieve excellent\nediting performance.",
      "tldr_zh": "本论文探讨了在大型语言模型(LLMs)中编辑基于自由文本的常识知识的挑战，指出现有方法（如MEMIT）仅适用于单个token或实体，无法处理常识知识的广泛范围和非实例化特性。作者引入了Knowledge Localization for Free-Text (KLFT) 方法来揭示常识知识在MLP和Attention layers中的分布问题，并提出了Dynamics-aware Editing Method (DEM)，该方法通过Dynamics-aware Module定位参数位置和Knowledge Editing Module更新知识，从而充分利用模型层级进行有效编辑。实验结果表明，DEM在编辑性能上表现出色，显著提升了LLMs的准确性和及时性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23844v1",
      "published_date": "2024-10-31 11:50:24 UTC",
      "updated_date": "2024-10-31 11:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:38:29.919851"
    },
    {
      "arxiv_id": "2410.23843v1",
      "title": "Reasons and Solutions for the Decline in Model Performance after Editing",
      "title_zh": "编辑后模型性能下降的原因及解决方案",
      "authors": [
        "Xiusheng Huang",
        "Jiaxiang Liu",
        "Yequan Wang",
        "Kang Liu"
      ],
      "abstract": "Knowledge editing technology has received widespread attention for low-cost\nupdates of incorrect or outdated knowledge in large-scale language models.\nHowever, recent research has found that edited models often exhibit varying\ndegrees of performance degradation. The reasons behind this phenomenon and\npotential solutions have not yet been provided. In order to investigate the\nreasons for the performance decline of the edited model and optimize the\nediting method, this work explores the underlying reasons from both data and\nmodel perspectives. Specifically, 1) from a data perspective, to clarify the\nimpact of data on the performance of editing models, this paper first\nconstructs a Multi-Question Dataset (MQD) to evaluate the impact of different\ntypes of editing data on model performance. The performance of the editing\nmodel is mainly affected by the diversity of editing targets and sequence\nlength, as determined through experiments. 2) From a model perspective, this\narticle explores the factors that affect the performance of editing models. The\nresults indicate a strong correlation between the L1-norm of the editing model\nlayer and the editing accuracy, and clarify that this is an important factor\nleading to the bottleneck of editing performance. Finally, in order to improve\nthe performance of the editing model, this paper further proposes a Dump for\nSequence (D4S) method, which successfully overcomes the previous editing\nbottleneck by reducing the L1-norm of the editing layer, allowing users to\nperform multiple effective edits and minimizing model damage. Our code is\navailable at https://github.com/nlpkeg/D4S.",
      "tldr_zh": "该研究探讨了大型语言模型在进行知识编辑后性能下降的原因，并从数据和模型两个角度提出解决方案。从数据视角，论文构建了Multi-Question Dataset (MQD)，实验发现编辑目标的多样性和序列长度是主要影响因素。从模型视角，分析显示编辑模型层的L1-norm与编辑准确率高度相关，是性能瓶颈的关键原因。为优化编辑性能，论文提出Dump for Sequence (D4S)方法，通过降低L1-norm实现多次有效编辑并最小化模型损害。整体结果为知识编辑技术提供了实用改进路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23843v1",
      "published_date": "2024-10-31 11:49:44 UTC",
      "updated_date": "2024-10-31 11:49:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:38:40.707151"
    },
    {
      "arxiv_id": "2410.23842v1",
      "title": "Auditing Google's Search Algorithm: Measuring News Diversity Across Brazil, the UK, and the US",
      "title_zh": "审计 Google 搜索算法：测量巴西、",
      "authors": [
        "Raphael Hernandes",
        "Giulio Corsi"
      ],
      "abstract": "This study examines the influence of Google's search algorithm on news\ndiversity by analyzing search results in Brazil, the UK, and the US. It\nexplores how Google's system preferentially favors a limited number of news\noutlets. Utilizing algorithm auditing techniques, the research measures source\nconcentration with the Herfindahl-Hirschman Index (HHI) and Gini coefficient,\nrevealing significant concentration trends. The study underscores the\nimportance of conducting horizontal analyses across multiple search queries, as\nfocusing solely on individual results pages may obscure these patterns. Factors\nsuch as popularity, political bias, and recency were evaluated for their impact\non news rankings. Findings indicate a slight leftward bias in search outcomes\nand a preference for popular, often national outlets. This bias, combined with\na tendency to prioritize recent content, suggests that Google's algorithm may\nreinforce existing media inequalities. By analyzing the largest dataset to date\n-- 221,863 search results -- this research provides comprehensive, longitudinal\ninsights into how algorithms shape public access to diverse news sources.",
      "tldr_zh": "本研究审计了谷歌搜索算法对新闻多样性的影响，通过分析巴西、英国和美国的搜索结果，揭示了算法偏好有限新闻来源的现象。研究采用算法审计技术，利用 Herfindahl-Hirschman Index (HHI) 和 Gini 系数等指标测量来源集中度，并评估了流行度、政治偏见和时效性对新闻排名的作用。结果显示，搜索结果存在轻微左倾偏见，并倾向于优先流行和最近的内容，从而可能加剧现有媒体不平等。该研究基于迄今为止最大的数据集（221,863 个搜索结果），强调了横向分析多个查询的必要性，以提供全面的纵向洞见。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages, 3 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.23842v1",
      "published_date": "2024-10-31 11:49:16 UTC",
      "updated_date": "2024-10-31 11:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:38:53.929628"
    },
    {
      "arxiv_id": "2410.23835v1",
      "title": "Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Morão",
        "Joao Santinha",
        "Yasna Forghani",
        "Nuno Loução",
        "Pedro Gouveia",
        "Mario A. T. Figueiredo"
      ],
      "abstract": "Deep learning (DL) models in medical imaging face challenges in\ngeneralizability and robustness due to variations in image acquisition\nparameters (IAP). In this work, we introduce a novel method using conditional\ndenoising diffusion generative models (cDDGMs) to generate counterfactual\nmagnetic resonance (MR) images that simulate different IAP without altering\npatient anatomy. We demonstrate that using these counterfactual images for data\naugmentation can improve segmentation accuracy, particularly in\nout-of-distribution settings, enhancing the overall generalizability and\nrobustness of DL models across diverse imaging conditions. Our approach shows\npromise in addressing domain and covariate shifts in medical imaging. The code\nis publicly available at https:\n//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation",
      "tldr_zh": "本文提出了一种使用条件去噪扩散生成模型（cDDGMs）生成反事实磁共振（MR）图像的方法，该方法模拟不同的图像采集参数（IAP），而不会改变患者解剖结构，从而解决深度学习（DL）模型在医疗成像中的泛化性和鲁棒性挑战。  \n通过这些反事实图像进行数据增强，能够显著提高分割准确性，尤其在分布外（out-of-distribution）设置中。  \n实验结果表明，该方法增强了DL模型在多样化成像条件下的整体性能，并有效应对领域和协变量偏移问题。  \n代码已在GitHub上公开，供进一步研究使用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23835v1",
      "published_date": "2024-10-31 11:29:41 UTC",
      "updated_date": "2024-10-31 11:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:39:05.946786"
    },
    {
      "arxiv_id": "2410.23825v2",
      "title": "GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Hossein Kargaran",
        "François Yvon",
        "Hinrich Schütze"
      ],
      "abstract": "The need for large text corpora has increased with the advent of pretrained\nlanguage models and, in particular, the discovery of scaling laws for these\nmodels. Most available corpora have sufficient data only for languages with\nlarge dominant communities. However, there is no corpus available that (i)\ncovers a wide range of minority languages; (ii) is generated by an open-source\nreproducible pipeline; and (iii) is rigorously cleaned from noise, making it\ntrustworthy to use. We present GlotCC, a clean, document-level, 2TB general\ndomain corpus derived from CommonCrawl, covering more than 1000 languages. We\nmake GlotCC and the system used to generate it - including the pipeline,\nlanguage identification model, and filters - available to the research\ncommunity. Corpus v. 1.0 https://huggingface.co/datasets/cis-lmu/GlotCC-v1,\nPipeline v. 3.0 https://github.com/cisnlp/GlotCC.",
      "tldr_zh": "该研究推出了 GlotCC，这是一个开源、广泛覆盖的2TB通用领域语料库，针对少数语言，填补了现有预训练语言模型语料库的空白。GlotCC 基于 CommonCrawl 数据，通过一个可重现的开源管道、语言识别模型和严格的噪音过滤器进行生成和清洗，确保语料库的可靠性和可用性。该语料库覆盖超过1000种语言，并提供完整资源，包括语料库 v1.0 和管道 v3.0，供研究社区免费使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23825v2",
      "published_date": "2024-10-31 11:14:12 UTC",
      "updated_date": "2025-03-03 21:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:39:17.305790"
    },
    {
      "arxiv_id": "2410.23822v1",
      "title": "Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong He",
        "Pengfei Li",
        "Gang Liu",
        "Shenjun Zhong"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) inherit the superior text\nunderstanding capabilities of LLMs and extend these capabilities to multimodal\nscenarios. These models achieve excellent results in the general domain of\nmultimodal tasks. However, in the medical domain, the substantial training\ncosts and the requirement for extensive medical data pose challenges to the\ndevelopment of medical MLLMs. Furthermore, due to the free-text form of\nanswers, tasks such as visual grounding that need to produce output in a\nprescribed form become difficult for MLLMs. So far, there have been no medical\nMLLMs works in medical visual grounding area. For the medical vision grounding\ntask, which involves identifying locations in medical images based on short\ntext descriptions, we propose Parameter-efficient Fine-tuning medical\nmultimodal large language models for Medcial Visual Grounding (PFMVG). To\nvalidate the performance of the model, we evaluate it on a public benchmark\ndataset for medical visual grounding, where it achieves competitive results,\nand significantly outperforming GPT-4v. Our code will be open sourced after\npeer review.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在医疗领域的挑战，如高训练成本和数据需求，提出了一种参数高效微调(Parameter-Efficient Fine-Tuning)方法，名为PFMVG，用于医疗视觉定位任务。该方法通过微调MLLMs，使其能够基于短文本描述准确识别医疗图像中的位置，解决现有模型在输出形式方面的限制。在公共基准数据集上，PFMVG实现了竞争性性能，并显著优于GPT-4v，证明了其在医疗视觉定位领域的有效性。研究代码将在同行评审后开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23822v1",
      "published_date": "2024-10-31 11:07:26 UTC",
      "updated_date": "2024-10-31 11:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:39:28.772941"
    },
    {
      "arxiv_id": "2411.00876v1",
      "title": "Resilience to the Flowing Unknown: an Open Set Recognition Framework for Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Marcos Barcina-Blanco",
        "Jesus L. Lobo",
        "Pablo Garcia-Bringas",
        "Javier Del Ser"
      ],
      "abstract": "Modern digital applications extensively integrate Artificial Intelligence\nmodels into their core systems, offering significant advantages for automated\ndecision-making. However, these AI-based systems encounter reliability and\nsafety challenges when handling continuously generated data streams in complex\nand dynamic scenarios. This work explores the concept of resilient AI systems,\nwhich must operate in the face of unexpected events, including instances that\nbelong to patterns that have not been seen during the training process. This is\nan issue that regular closed-set classifiers commonly encounter in streaming\nscenarios, as they are designed to compulsory classify any new observation into\none of the training patterns (i.e., the so-called \\textit{over-occupied space}\nproblem). In batch learning, the Open Set Recognition research area has\nconsistently confronted this issue by requiring models to robustly uphold their\nclassification performance when processing query instances from unknown\npatterns. In this context, this work investigates the application of an Open\nSet Recognition framework that combines classification and clustering to\naddress the \\textit{over-occupied space} problem in streaming scenarios.\nSpecifically, we systematically devise a benchmark comprising different\nclassification datasets with varying ratios of known to unknown classes.\nExperiments are presented on this benchmark to compare the performance of the\nproposed hybrid framework with that of individual incremental classifiers.\nDiscussions held over the obtained results highlight situations where the\nproposed framework performs best, and delineate the limitations and hurdles\nencountered by incremental classifiers in effectively resolving the challenges\nposed by open-world streaming environments.",
      "tldr_zh": "本文提出一个针对数据流的 Open Set Recognition 框架，旨在提升 AI 系统在处理未知模式时的弹性，解决传统闭集分类器在流式场景中强制归类新观察导致的 over-occupied space 问题。该框架结合分类和聚类方法，设计了一个基准数据集，包括不同已知与未知类比，并通过实验比较了其性能与单个增量分类器的表现。结果显示，该框架在特定情况下表现出色，但也突出了增量分类器在开放世界流式环境中的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures, an updated version of this article is published\n  in LNAI,volume 14857 as part of the conference proceedings HAIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00876v1",
      "published_date": "2024-10-31 11:06:54 UTC",
      "updated_date": "2024-10-31 11:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:39:41.273989"
    },
    {
      "arxiv_id": "2410.23820v1",
      "title": "Disentangling Disentangled Representations: Towards Improved Latent Units via Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Youngjun Jun",
        "Jiwoo Park",
        "Kyobin Choo",
        "Tae Eun Choi",
        "Seong Jae Hwang"
      ],
      "abstract": "Disentangled representation learning (DRL) aims to break down observed data\ninto core intrinsic factors for a profound understanding of the data. In\nreal-world scenarios, manually defining and labeling these factors are\nnon-trivial, making unsupervised methods attractive. Recently, there have been\nlimited explorations of utilizing diffusion models (DMs), which are already\nmainstream in generative modeling, for unsupervised DRL. They implement their\nown inductive bias to ensure that each latent unit input to the DM expresses\nonly one distinct factor. In this context, we design Dynamic Gaussian Anchoring\nto enforce attribute-separated latent units for more interpretable DRL. This\nunconventional inductive bias explicitly delineates the decision boundaries\nbetween attributes while also promoting the independence among latent units.\nAdditionally, we also propose Skip Dropout technique, which easily modifies the\ndenoising U-Net to be more DRL-friendly, addressing its uncooperative nature\nwith the disentangling feature extractor. Our methods, which carefully consider\nthe latent unit semantics and the distinct DM structure, enhance the\npracticality of DM-based disentangled representations, demonstrating\nstate-of-the-art disentanglement performance on both synthetic and real data,\nas well as advantages in downstream tasks.",
      "tldr_zh": "本论文探讨了Disentangled Representation Learning (DRL)，旨在通过分解数据为核心内在因素来提升数据理解，但由于手动定义因素的难度，强调了无监督方法的必要性。论文提出Dynamic Gaussian Anchoring方法，利用Diffusion Models (DMs)的归纳偏差明确划分属性决策边界并促进latent units的独立性，同时引入Skip Dropout技术来修改denoising U-Net，使其更兼容DRL的特征提取器。这些创新显著提高了DM-based disentangled representations的实用性和可解释性，在合成和真实数据上实现了state-of-the-art的disentanglement性能，并在下游任务中表现出优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23820v1",
      "published_date": "2024-10-31 11:05:09 UTC",
      "updated_date": "2024-10-31 11:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:39:53.096813"
    },
    {
      "arxiv_id": "2410.23815v1",
      "title": "The NPU-HWC System for the ISCSLP 2024 Inspirational and Convincing Audio Generation Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Dake Guo",
        "Jixun Yao",
        "Xinfa Zhu",
        "Kangxiang Xia",
        "Zhao Guo",
        "Ziyu Zhang",
        "Yao Wang",
        "Jie Liu",
        "Lei Xie"
      ],
      "abstract": "This paper presents the NPU-HWC system submitted to the ISCSLP 2024\nInspirational and Convincing Audio Generation Challenge 2024 (ICAGC). Our\nsystem consists of two modules: a speech generator for Track 1 and a background\naudio generator for Track 2. In Track 1, we employ Single-Codec to tokenize the\nspeech into discrete tokens and use a language-model-based approach to achieve\nzero-shot speaking style cloning. The Single-Codec effectively decouples timbre\nand speaking style at the token level, reducing the acoustic modeling burden on\nthe autoregressive language model. Additionally, we use DSPGAN to upsample 16\nkHz mel-spectrograms to high-fidelity 48 kHz waveforms. In Track 2, we propose\na background audio generator based on large language models (LLMs). This system\nproduces scene-appropriate accompaniment descriptions, synthesizes background\naudio with Tango 2, and integrates it with the speech generated by our Track 1\nsystem. Our submission achieves the second place and the first place in Track 1\nand Track 2 respectively.",
      "tldr_zh": "这篇论文介绍了NPU-HWC系统，提交给ISCSLP 2024 Inspirational and Convincing Audio Generation Challenge（ICAGC），该系统包括Track 1的语音生成模块和Track 2的背景音频生成模块。Track 1采用Single-Codec将语音标记为离散标记，并使用基于语言模型的方法实现零样本说话风格克隆，同时通过DSPGAN将16 kHz mel-spectrogram上采样到48 kHz的高保真波形。Track 2基于大型语言模型(LLMs)生成适合场景的伴奏描述，并使用Tango 2合成背景音频，然后与Track 1的语音整合。该系统在挑战中获得Track 1第二名和Track 2第一名的成绩，展示了其在音频生成方面的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted by ISCSLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23815v1",
      "published_date": "2024-10-31 10:58:59 UTC",
      "updated_date": "2024-10-31 10:58:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:40:07.375061"
    },
    {
      "arxiv_id": "2410.23810v1",
      "title": "CALE: Continuous Arcade Learning Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Farebrother",
        "Pablo Samuel Castro"
      ],
      "abstract": "We introduce the Continuous Arcade Learning Environment (CALE), an extension\nof the well-known Arcade Learning Environment (ALE) [Bellemare et al., 2013].\nThe CALE uses the same underlying emulator of the Atari 2600 gaming system\n(Stella), but adds support for continuous actions. This enables the\nbenchmarking and evaluation of continuous-control agents (such as PPO [Schulman\net al., 2017] and SAC [Haarnoja et al., 2018]) and value-based agents (such as\nDQN [Mnih et al., 2015] and Rainbow [Hessel et al., 2018]) on the same\nenvironment suite. We provide a series of open questions and research\ndirections that CALE enables, as well as initial baseline results using Soft\nActor-Critic. CALE is available as part of the ALE\nathttps://github.com/Farama-Foundation/Arcade-Learning-Environment.",
      "tldr_zh": "我们介绍了 Continuous Arcade Learning Environment (CALE)，它是 Arcade Learning Environment (ALE) 的扩展，使用 Atari 2600 模拟器添加了对连续动作的支持。\nCALE 允许在同一环境suite中评估连续控制代理（如 PPO 和 SAC）以及基于价值的代理（如 DQN 和 Rainbow），从而促进强化学习算法的基准测试。\n论文提出了若干开放研究问题和方向，并提供了使用 Soft Actor-Critic 的初步基准结果。\nCALE 已作为 ALE 的一部分开源，可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23810v1",
      "published_date": "2024-10-31 10:52:42 UTC",
      "updated_date": "2024-10-31 10:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:42:17.591970"
    },
    {
      "arxiv_id": "2410.23803v1",
      "title": "Generative AI for Accessible and Inclusive Extended Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Jens Grubert",
        "Junlong Chen",
        "Per Ola Kristensson"
      ],
      "abstract": "Artificial Intelligence-Generated Content (AIGC) has the potential to\ntransform how people build and interact with virtual environments. Within this\npaper, we discuss potential benefits but also challenges that AIGC has for the\ncreation of inclusive and accessible virtual environments. Specifically, we\ntouch upon the decreased need for 3D modeling expertise, benefits of\nsymbolic-only as well as multimodal input, 3D content editing, and 3D model\naccessibility as well as foundation model-specific challenges.",
      "tldr_zh": "本文探讨了生成式AI（AIGC）在创建可访问和包容的扩展现实（Extended Reality）环境中的潜力，强调了其减少对3D建模专业知识需求的好处，以及符号输入、多模态输入、3D内容编辑和3D模型可访问性的优势。论文同时指出了基础模型特定的挑战，如潜在的局限性和可靠性问题，需要进一步优化。这些讨论为构建更具包容性的虚拟环境提供了宝贵见解，并推动了AI在虚拟互动领域的应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Presented at the CHI 2024 Workshop \"Building a Metaverse for All:\n  Opportunities and Challenges for Future Inclusive and Accessible Virtual\n  Environments\", May 11, 2024, Honolulu, Hawaii",
      "pdf_url": "http://arxiv.org/pdf/2410.23803v1",
      "published_date": "2024-10-31 10:43:43 UTC",
      "updated_date": "2024-10-31 10:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:42:29.759221"
    },
    {
      "arxiv_id": "2410.23796v1",
      "title": "Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "F. D. Gonzalez-Martinez",
        "J. J. Carabias-Orti",
        "F. J. Canadas-Quesada",
        "N. Ruiz-Reyes",
        "D. Martinez-Munoz",
        "S. Garcia-Galan"
      ],
      "abstract": "Snoring, an acoustic biomarker commonly observed in individuals with\nObstructive Sleep Apnoea Syndrome (OSAS), holds significant potential for\ndiagnosing and monitoring this recognized clinical disorder. Irrespective of\nsnoring types, most snoring instances exhibit identifiable harmonic patterns\nmanifested through distinctive energy distributions over time. In this work, we\npropose a novel method to differentiate monaural snoring from non-snoring\nsounds by analyzing the harmonic content of the input sound using\nharmonic/percussive sound source separation (HPSS). The resulting feature,\nbased on the harmonic spectrogram from HPSS, is employed as input data for\nconventional neural network architectures, aiming to enhance snoring detection\nperformance even under a limited data learning framework. To evaluate the\nperformance of our proposal, we studied two different scenarios: 1) using a\nlarge dataset of snoring and interfering sounds, and 2) using a reduced\ntraining set composed of around 1% of the data material. In the former\nscenario, the proposed HPSS-based feature provides competitive results compared\nto other input features from the literature. However, the key advantage of the\nproposed method lies in the superior performance of the harmonic spectrogram\nderived from HPSS in a limited data learning context. In this particular\nscenario, using the proposed harmonic feature significantly enhances the\nperformance of all the studied architectures in comparison to the classical\ninput features documented in the existing literature. This finding clearly\ndemonstrates that incorporating harmonic content enables more reliable learning\nof the essential time-frequency characteristics that are prevalent in most\nsnoring sounds, even in scenarios where the amount of training data is limited.",
      "tldr_zh": "这篇论文提出了一种新方法，通过谐波/打击声源分离(HPSS)提取输入声音的谐波谱特征，并将其作为输入喂入卷积神经网络(CNNs)，以改善鼾声检测，尤其在数据有限的场景下。研究评估了两种情况：使用大型数据集时，该方法与现有特征表现相当；而在使用约1%减少数据集时，HPSS 基于的谐波特征显著提升了所有网络架构的性能。总体而言，该方法证明了在 Obstructive Sleep Apnoea Syndrome (OSAS) 诊断中，融入谐波内容能更可靠地学习鼾声的时间-频率特征。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.ET",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23796v1",
      "published_date": "2024-10-31 10:27:48 UTC",
      "updated_date": "2024-10-31 10:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:40:42.218060"
    },
    {
      "arxiv_id": "2410.23788v1",
      "title": "EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching",
      "title_zh": "EDT：一种受人类般素描启发的高效扩散Transformer框架",
      "authors": [
        "Xinwang Chen",
        "Ning Liu",
        "Yichen Zhu",
        "Feifei Feng",
        "Jian Tang"
      ],
      "abstract": "Transformer-based Diffusion Probabilistic Models (DPMs) have shown more\npotential than CNN-based DPMs, yet their extensive computational requirements\nhinder widespread practical applications. To reduce the computation budget of\ntransformer-based DPMs, this work proposes the Efficient Diffusion Transformer\n(EDT) framework. The framework includes a lightweight-design diffusion model\narchitecture, and a training-free Attention Modulation Matrix and its\nalternation arrangement in EDT inspired by human-like sketching. Additionally,\nwe propose a token relation-enhanced masking training strategy tailored\nexplicitly for EDT to augment its token relation learning capability. Our\nextensive experiments demonstrate the efficacy of EDT. The EDT framework\nreduces training and inference costs and surpasses existing transformer-based\ndiffusion models in image synthesis performance, thereby achieving a\nsignificant overall enhancement. With lower FID, EDT-S, EDT-B, and EDT-XL\nattained speed-ups of 3.93x, 2.84x, and 1.92x respectively in the training\nphase, and 2.29x, 2.29x, and 2.22x respectively in inference, compared to the\ncorresponding sizes of MDTv2. The source code is released at\nhttps://github.com/xinwangChen/EDT.",
      "tldr_zh": "本研究提出 Efficient Diffusion Transformer (EDT) 框架，旨在解决 Transformer-based Diffusion Probabilistic Models (DPMs) 的高计算开销问题，通过轻量级扩散模型架构和受人类素描启发的训练-free Attention Modulation Matrix 及其交替安排来提升效率。EDT 还引入 token relation-enhanced masking 训练策略，专门增强 token 关系学习能力。实验结果表明，EDT 在训练和推理阶段分别实现高达 3.93x 和 2.29x 的加速，同时在图像合成性能上超越现有模型，如 MDTv2，FID 值更低。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Xinwang Chen and Ning Liu are with equal contributions. This paper\n  has been accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23788v1",
      "published_date": "2024-10-31 10:13:05 UTC",
      "updated_date": "2024-10-31 10:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:40:53.925871"
    },
    {
      "arxiv_id": "2410.23780v3",
      "title": "Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyuan Chang",
        "Maixuan Xue",
        "Xinran Liu",
        "Zheng Pan",
        "Xing Wei"
      ],
      "abstract": "Ensuring adherence to traffic sign regulations is essential for both human\nand autonomous vehicle navigation. While current online mapping solutions often\nprioritize the construction of the geometric and connectivity layers of HD\nmaps, overlooking the construction of the traffic regulation layer within HD\nmaps. Addressing this gap, we introduce MapDR, a novel dataset designed for the\nextraction of Driving Rules from traffic signs and their association with\nvectorized, locally perceived HD Maps. MapDR features over $10,000$ annotated\nvideo clips that capture the intricate correlation between traffic sign\nregulations and lanes. Built upon this benchmark and the newly defined task of\nintegrating traffic regulations into online HD maps, we provide modular and\nend-to-end solutions: VLE-MEE and RuleVLM, offering a strong baseline for\nadvancing autonomous driving technology. It fills a critical gap in the\nintegration of traffic sign rules, contributing to the development of reliable\nautonomous driving systems. Code is available at\nhttps://github.com/MIV-XJTU/MapDR.",
      "tldr_zh": "该研究强调了遵守交通标志规定对人类和自动驾驶车辆导航的重要性，并指出当前在线 HD Map 解决方案忽略了交通规则层的构建。为解决这一问题，研究团队引入了 MapDR 数据集，该数据集包含超过 10,000 个标注视频剪辑，用于提取交通标志规则并将其与矢量化的本地感知 HD Map 关联。基于 MapDR 和新定义的任务（将交通规则集成到在线 HD Map 中），他们提出了模块化解决方案 VLE-MEE 和端到端解决方案 RuleVLM，作为推进自动驾驶技术的强有力基准。这些创新填补了关键空白，有助于开发更可靠的自动驾驶系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages, 16 figures. Accepted as a Highlight at CVPR 2025. Project\n  page: https://miv-xjtu.github.io/MapDR/",
      "pdf_url": "http://arxiv.org/pdf/2410.23780v3",
      "published_date": "2024-10-31 09:53:21 UTC",
      "updated_date": "2025-04-10 11:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:41:05.404069"
    },
    {
      "arxiv_id": "2411.00064v1",
      "title": "The ISCSLP 2024 Conversational Voice Clone (CoVoC) Challenge: Tasks, Results and Findings",
      "title_zh": "翻译失败",
      "authors": [
        "Kangxiang Xia",
        "Dake Guo",
        "Jixun Yao",
        "Liumeng Xue",
        "Hanzhao Li",
        "Shuai Wang",
        "Zhao Guo",
        "Lei Xie",
        "Qingqing Zhang",
        "Lei Luo",
        "Minghui Dong",
        "Peng Sun"
      ],
      "abstract": "The ISCSLP 2024 Conversational Voice Clone (CoVoC) Challenge aims to\nbenchmark and advance zero-shot spontaneous style voice cloning, particularly\nfocusing on generating spontaneous behaviors in conversational speech. The\nchallenge comprises two tracks: an unconstrained track without limitation on\ndata and model usage, and a constrained track only allowing the use of\nconstrained open-source datasets. A 100-hour high-quality conversational speech\ndataset is also made available with the challenge. This paper details the data,\ntracks, submitted systems, evaluation results, and findings.",
      "tldr_zh": "ISCSLP 2024的Conversational Voice Clone (CoVoC) Challenge旨在基准和推进zero-shot自发风格语音克隆技术，特别聚焦于生成对话中的自发行为。挑战设置了两个赛道：不受限赛道（无数据和模型使用限制）和受限赛道（仅允许使用指定开源数据集），并提供了100小时的高质量对话语音数据集。论文总结了提交系统、评估结果以及关键发现，展示了该领域的技术进展和潜在挑战。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted by ISCSLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00064v1",
      "published_date": "2024-10-31 09:39:49 UTC",
      "updated_date": "2024-10-31 09:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:41:16.919867"
    },
    {
      "arxiv_id": "2410.23769v2",
      "title": "The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams",
      "title_zh": "LLMs 在医疗教育中的潜力：为资格考试生成问题和答案",
      "authors": [
        "Yunqi Zhu",
        "Wen Tang",
        "Huayu Yang",
        "Jinghao Niu",
        "Liyang Dou",
        "Yifan Gu",
        "Yuanyuan Wu",
        "Wensheng Zhang",
        "Ying Sun",
        "Xuebing Yang"
      ],
      "abstract": "In this work, we leverage LLMs to produce medical qualification exam\nquestions and the corresponding answers through few-shot prompts, investigating\nin-depth how LLMs meet the requirements in terms of coherence, evidence of\nstatement, factual consistency, and professionalism etc. Utilizing a\nmulticenter bidirectional anonymized database with respect to comorbid chronic\ndiseases, named Elderly Comorbidity Medical Database (CECMed), we tasked LLMs\nwith generating open-ended questions and answers based on a subset of sampled\nadmission reports. For CECMed, the retrospective cohort includes patients\nenrolled from January 2010 to January 2022 while the prospective cohort from\nJanuary 2023 to November 2023, with participants sourced from selected tertiary\nand community hospitals across the southern, northern, and central regions of\nChina. A total of 8 widely used LLMs were used, including ERNIE 4, ChatGLM 4,\nDoubao, Hunyuan, Spark 4, Qwen,\n  Conventional medical education requires sophisticated clinicians to formulate\nquestions and answers based on prototypes from EHRs, which is heuristic and\ntime-consuming. We found that mainstream LLMs could generate questions and\nanswers with real-world EHRs at levels close to clinicians. Although current\nLLMs performed dissatisfactory in some aspects, medical students, interns and\nresidents could reasonably make use of LLMs to facilitate understanding.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在医学教育中的潜力，通过 few-shot prompts 生成医学资格考试的问题和答案，并评估其在连贯性、事实一致性、专业性等方面的表现。研究利用 Elderly Comorbidity Medical Database (CECMed) 数据库中的电子健康记录 (EHRs) 数据，测试了包括 ERNIE 4、ChatGLM 4 在内的 8 个主流 LLMs 的生成能力。结果表明，LLMs 生成的问题和答案水平接近临床医生，尽管在某些方面表现不佳，但可有效辅助医疗学生、实习生和住院医师提升理解和学习效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23769v2",
      "published_date": "2024-10-31 09:33:37 UTC",
      "updated_date": "2025-02-27 07:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:42:41.945118"
    },
    {
      "arxiv_id": "2411.10453v1",
      "title": "Towards Geometry-Preserving Reductions Between Constraint Satisfaction Problems (and other problems in NP)",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Istrate"
      ],
      "abstract": "Motivated by phase transitions in combinatorial optimization problems, we\ndefine two kinds of geometry-preserving reductions between constraint\nsatisfaction problems and other NP-search problems. We give a couple of\nexamples and counterexamples for these reductions.",
      "tldr_zh": "这篇论文受组合优化问题中的相变（phase transitions）启发，定义了两种几何保留归约（geometry-preserving reductions），用于连接约束满足问题（Constraint Satisfaction Problems, CSPs）和其他 NP-search 问题。作者通过提供几个例子和反例，展示了这些归约的适用性和局限性。这些贡献有助于深化对 NP 类问题之间关系的理解。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.DM",
        "F.2.2"
      ],
      "primary_category": "cs.CC",
      "comment": "In Proceedings FROM 2024, arXiv:2410.23020. An extended version is\n  under preparation and will also be posted on arXiv",
      "pdf_url": "http://arxiv.org/pdf/2411.10453v1",
      "published_date": "2024-10-31 09:26:53 UTC",
      "updated_date": "2024-10-31 09:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:42:52.547839"
    },
    {
      "arxiv_id": "2410.23753v1",
      "title": "Enhancing Chess Reinforcement Learning with Graph Representation",
      "title_zh": "使用图表示增强国际象棋强化学习",
      "authors": [
        "Tomas Rigaux",
        "Hisashi Kashima"
      ],
      "abstract": "Mastering games is a hard task, as games can be extremely complex, and still\nfundamentally different in structure from one another. While the AlphaZero\nalgorithm has demonstrated an impressive ability to learn the rules and\nstrategy of a large variety of games, ranging from Go and Chess, to Atari\ngames, its reliance on extensive computational resources and rigid\nConvolutional Neural Network (CNN) architecture limits its adaptability and\nscalability. A model trained to play on a $19\\times 19$ Go board cannot be used\nto play on a smaller $13\\times 13$ board, despite the similarity between the\ntwo Go variants. In this paper, we focus on Chess, and explore using a more\ngeneric Graph-based Representation of a game state, rather than a grid-based\none, to introduce a more general architecture based on Graph Neural Networks\n(GNN). We also expand the classical Graph Attention Network (GAT) layer to\nincorporate edge-features, to naturally provide a generic policy output format.\nOur experiments, performed on smaller networks than the initial AlphaZero\npaper, show that this new architecture outperforms previous architectures with\na similar number of parameters, being able to increase playing strength an\norder of magnitude faster. We also show that the model, when trained on a\nsmaller $5\\times 5$ variant of chess, is able to be quickly fine-tuned to play\non regular $8\\times 8$ chess, suggesting that this approach yields promising\ngeneralization abilities. Our code is available at\nhttps://github.com/akulen/AlphaGateau.",
      "tldr_zh": "这篇论文针对AlphaZero在游戏学习中的局限性（如依赖大量计算资源和刚性Convolutional Neural Network (CNN)架构），提出使用更通用的Graph-based Representation和Graph Neural Networks (GNN)来增强国际象棋的强化学习。作者扩展了Graph Attention Network (GAT)层以包含edge-features，提供通用的策略输出格式。实验结果显示，该新架构在类似参数数量下显著提升了游戏强度，训练效率提高一个数量级，且模型能在5x5国际象棋上训练后快速微调至标准8x8国际象棋，展示了良好的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23753v1",
      "published_date": "2024-10-31 09:18:47 UTC",
      "updated_date": "2024-10-31 09:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:44.486578"
    },
    {
      "arxiv_id": "2410.23749v8",
      "title": "LSEAttention is All You Need for Time Series Forecasting",
      "title_zh": "LSEAttention 就是你所需要的一切，用于时间序列预测",
      "authors": [
        "Dizhen Liang"
      ],
      "abstract": "Transformer-based architectures have achieved remarkable success in natural\nlanguage processing and computer vision. However, their performance in\nmultivariate long-term forecasting often falls short compared to simpler linear\nbaselines. Previous research has identified the traditional attention mechanism\nas a key factor limiting their effectiveness in this domain. To bridge this\ngap, we introduce LATST, a novel approach designed to mitigate entropy collapse\nand training instability common challenges in Transformer-based time series\nforecasting. We rigorously evaluate LATST across multiple real-world\nmultivariate time series datasets, demonstrating its ability to outperform\nexisting state-of-the-art Transformer models. Notably, LATST manages to achieve\ncompetitive performance with fewer parameters than some linear models on\ncertain datasets, highlighting its efficiency and effectiveness.",
      "tldr_zh": "该研究指出，Transformer 架构在多变量长期时间序列预测中往往不如简单的线性基线，主要由于传统注意力机制导致的熵崩溃和训练不稳定性。为解决这些问题，研究团队引入了 LATST 方法，通过优化注意力机制来提升模型性能。在多个真实世界数据集上的严格评估显示，LATST 超过了现有最先进 Transformer 模型，并在某些数据集上以更少的参数实现与线性模型相当的预测准确率，证明了其高效性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages with referencing, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.23749v8",
      "published_date": "2024-10-31 09:09:39 UTC",
      "updated_date": "2025-04-30 01:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:43:17.182222"
    },
    {
      "arxiv_id": "2410.23748v2",
      "title": "Exploring Consistency in Graph Representations:from Graph Kernels to Graph Neural Networks",
      "title_zh": "探索图表示中的一致性：从图核到图神经网络",
      "authors": [
        "Xuyuan Liu",
        "Yinghao Cai",
        "Qihui Yang",
        "Yujun Yan"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as a dominant approach in graph\nrepresentation learning, yet they often struggle to capture consistent\nsimilarity relationships among graphs. While graph kernel methods such as the\nWeisfeiler-Lehman subtree (WL-subtree) and Weisfeiler-Lehman optimal assignment\n(WLOA) kernels are effective in capturing similarity relationships, they rely\nheavily on predefined kernels and lack sufficient non-linearity for more\ncomplex data patterns. Our work aims to bridge the gap between neural network\nmethods and kernel approaches by enabling GNNs to consistently capture\nrelational structures in their learned representations. Given the analogy\nbetween the message-passing process of GNNs and WL algorithms, we thoroughly\ncompare and analyze the properties of WL-subtree and WLOA kernels. We find that\nthe similarities captured by WLOA at different iterations are asymptotically\nconsistent, ensuring that similar graphs remain similar in subsequent\niterations, thereby leading to superior performance over the WL-subtree kernel.\nInspired by these findings, we conjecture that the consistency in the\nsimilarities of graph representations across GNN layers is crucial in capturing\nrelational structures and enhancing graph classification performance. Thus, we\npropose a loss to enforce the similarity of graph representations to be\nconsistent across different layers. Our empirical analysis verifies our\nconjecture and shows that our proposed consistency loss can significantly\nenhance graph classification performance across several GNN backbones on\nvarious datasets.",
      "tldr_zh": "本研究探讨了图表示学习中Graph Neural Networks (GNNs)与图核方法（如Weisfeiler-Lehman subtree (WL-subtree)和Weisfeiler-Lehman optimal assignment (WLOA) kernels）之间的关系，旨在解决GNNs在捕捉图间一致相似性方面的不足。作者通过比较GNNs的消息传递机制与WL算法，发现WLOA内核在不同迭代中表现出渐进一致性，从而优于WL-subtree内核。基于此，他们提出了一种损失函数，用于强制GNN层间表示的相似性一致性。实验结果显示，该方法显著提升了多种GNN框架在各种数据集上的图分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23748v2",
      "published_date": "2024-10-31 09:07:08 UTC",
      "updated_date": "2024-12-11 06:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:44.374993"
    },
    {
      "arxiv_id": "2410.23746v3",
      "title": "DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios",
      "title_zh": "DetectRL：针对真实世界场景的LLM生成文本检测基准测试",
      "authors": [
        "Junchao Wu",
        "Runzhe Zhan",
        "Derek F. Wong",
        "Shu Yang",
        "Xinyi Yang",
        "Yulin Yuan",
        "Lidia S. Chao"
      ],
      "abstract": "Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.",
      "tldr_zh": "该研究引入DetectRL基准，用于评估LLM-Generated Text检测技术在真实场景中的性能，揭示了现有SOTA检测器如DetectGPT的表现仍不尽如人意。研究者收集了人类编写的文本数据集，并使用流行LLMs生成更贴近实际应用的数据，同时通过启发式规则模拟对抗性文本（如提示使用、人为修改和写作噪声）。实验分析了写作风格、模型类型、攻击方法、文本长度以及人类写作因素对检测器的影响，发现这些因素显著暴露了检测器的局限性。DetectRL作为有效基准，将随着高级攻击方法的演进提供更严格的评估，推动更高效检测器的发展，并已公开数据和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)",
      "pdf_url": "http://arxiv.org/pdf/2410.23746v3",
      "published_date": "2024-10-31 09:01:25 UTC",
      "updated_date": "2025-03-12 10:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:43:41.327858"
    },
    {
      "arxiv_id": "2410.23745v1",
      "title": "Syno: Structured Synthesis for Neural Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqi Zhuo",
        "Zhengyuan Su",
        "Chenggang Zhao",
        "Mingyu Gao"
      ],
      "abstract": "The desires for better prediction accuracy and higher execution performance\nin neural networks never end. Neural architecture search (NAS) and tensor\ncompilers are two popular techniques to optimize these two goals, but they are\nboth limited to composing or optimizing existing manually designed operators\nrather than coming up with completely new designs. In this work, we explore the\nless studied direction of neural operator synthesis, which aims to\nautomatically and efficiently discover novel neural operators with better\naccuracy and/or speed. We develop an end-to-end framework Syno, to realize\npractical neural operator synthesis. Syno makes use of a novel set of\nfine-grained primitives defined on tensor dimensions, which ensure various\ndesired properties to ease model training, and also enable expression\ncanonicalization techniques to avoid redundant candidates during search. Syno\nfurther adopts a novel guided synthesis flow to obtain valid operators matched\nwith the specified input/output dimension sizes, and leverages efficient\nstochastic tree search algorithms to quickly explore the design space. We\ndemonstrate that Syno discovers better operators with an average of\n$2.06\\times$ speedup and less than $1\\%$ accuracy loss, even on NAS-optimized\nmodels.",
      "tldr_zh": "该研究提出 Syno 框架，用于自动合成新型 neural operators，以提升神经网络的预测准确性和执行性能。Syno 基于 tensor 维度定义的细粒度 primitives 和 expression canonicalization 技术，确保模型训练易行并避免冗余候选，同时采用 guided synthesis flow 和 stochastic tree search 算法高效探索设计空间。实验结果表明，Syno 发现的算子在 NAS-optimized 模型上平均实现 2.06× 速度提升，同时准确性损失小于 1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23745v1",
      "published_date": "2024-10-31 09:00:24 UTC",
      "updated_date": "2024-10-31 09:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:43:53.220003"
    },
    {
      "arxiv_id": "2410.23743v1",
      "title": "What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Yanhong Li",
        "Tianyi Zhou"
      ],
      "abstract": "What makes a difference in the post-training of LLMs? We investigate the\ntraining patterns of different layers in large language models (LLMs), through\nthe lens of gradient, when training with different responses and initial\nmodels. We are specifically interested in how fast vs. slow thinking affects\nthe layer-wise gradients, given the recent popularity of training LLMs on\nreasoning paths such as chain-of-thoughts (CoT) and process rewards. In our\nstudy, fast thinking without CoT leads to larger gradients and larger\ndifferences of gradients across layers than slow thinking (Detailed CoT),\nindicating the learning stability brought by the latter. Moreover, pre-trained\nLLMs are less affected by the instability of fast thinking than\ninstruction-tuned LLMs. Additionally, we study whether the gradient patterns\ncan reflect the correctness of responses when training different LLMs using\nslow vs. fast thinking paths. The results show that the gradients of slow\nthinking can distinguish correct and irrelevant reasoning paths. As a\ncomparison, we conduct similar gradient analyses on non-reasoning knowledge\nlearning tasks, on which, however, trivially increasing the response length\ndoes not lead to similar behaviors of slow thinking. Our study strengthens\nfundamental understandings of LLM training and sheds novel insights on its\nefficiency and stability, which pave the way towards building a generalizable\nSystem-2 agent. Our code, data, and gradient statistics can be found in:\nhttps://github.com/MingLiiii/Layer_Gradient.",
      "tldr_zh": "该论文从梯度视角研究了在训练大型语言模型 (LLMs) 时，快思考 (fast thinking) 与慢思考 (slow thinking) 的差异，特别是对模型层级梯度的影响。研究发现，快思考（无 Chain-of-Thought, CoT）导致更大的梯度和层间梯度差异，从而带来学习不稳定性，而慢思考（详细 CoT）则提升了训练的稳定性。预训练的 LLMs 比指令微调的 LLMs 更少受快思考不稳定性的影响，且梯度模式能有效区分慢思考中的正确与无关推理路径。与非推理知识学习任务相比，简单增加响应长度无法复制慢思考的效果。该研究深化了对 LLM 训练效率和稳定性的理解，并为构建可泛化的 System-2 代理铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23743v1",
      "published_date": "2024-10-31 08:58:06 UTC",
      "updated_date": "2024-10-31 08:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:05.913352"
    },
    {
      "arxiv_id": "2410.23726v1",
      "title": "Towards Reliable Alignment: Uncertainty-aware RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Debangshu Banerjee",
        "Aditya Gopalan"
      ],
      "abstract": "Recent advances in aligning Large Language Models with human preferences have\nbenefited from larger reward models and better preference data. However, most\nof these methodologies rely on the accuracy of the reward model. The reward\nmodels used in Reinforcement Learning with Human Feedback (RLHF) are typically\nlearned from small datasets using stochastic optimization algorithms, making\nthem prone to high variability. We illustrate the inconsistencies between\nreward models empirically on numerous open-source datasets.\n  We theoretically show that the fluctuation of the reward models can be\ndetrimental to the alignment problem because the derived policies are more\noverfitted to the reward model and, hence, are riskier if the reward model\nitself is uncertain. We use concentration of measure to motivate an\nuncertainty-aware, conservative algorithm for policy optimization. We show that\nsuch policies are more risk-averse in the sense that they are more cautious of\nuncertain rewards. We theoretically prove that our proposed methodology has\nless risk than the vanilla method.\n  We corroborate our theoretical results with experiments based on designing an\nensemble of reward models. We use this ensemble of reward models to align a\nlanguage model using our methodology and observe that our empirical findings\nmatch our theoretical predictions.",
      "tldr_zh": "这篇论文针对强化学习与人类反馈 (RLHF) 中的奖励模型不确定性问题，指出传统方法依赖于易变异性的奖励模型，可能导致策略过拟合和风险增加。作者提出了一种不确定性感知的保守算法，利用浓度不等式 (concentration of measure) 优化策略，使其更谨慎地处理不确定奖励。理论证明显示，该方法比传统 RLHF 更风险厌恶，实验通过奖励模型集合对语言模型进行对齐，进一步验证了其可靠性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23726v1",
      "published_date": "2024-10-31 08:26:51 UTC",
      "updated_date": "2024-10-31 08:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:16.836015"
    },
    {
      "arxiv_id": "2410.23725v1",
      "title": "Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial",
      "title_zh": "翻译失败",
      "authors": [
        "Taridzo Chomutare",
        "Therese Olsen Svenning",
        "Miguel Ángel Tejedor Hernández",
        "Phuong Dinh Ngo",
        "Andrius Budrionis",
        "Kaisa Markljung",
        "Lill Irene Hind",
        "Torbjørn Torsvik",
        "Karl Øyvind Mikalsen",
        "Aleksandar Babic",
        "Hercules Dalianis"
      ],
      "abstract": "\\textbf{Trial design} Crossover randomized controlled trial. \\textbf{Methods}\nAn AI tool, Easy-ICD, was developed to assist clinical coders and was tested\nfor improving both accuracy and time in a user study in Norway and Sweden.\nParticipants were randomly assigned to two groups, and crossed over between\ncoding complex (longer) texts versus simple (shorter) texts, while using our\ntool versus not using our tool. \\textbf{Results} Based on Mann-Whitney U test,\nthe median coding time difference for complex clinical text sequences was 123\nseconds (\\emph{P}\\textless.001, 95\\% CI: 81 to 164), representing a 46\\%\nreduction in median coding time when our tool is used. There was no significant\ntime difference for simpler text sequences. For coding accuracy, the\nimprovement we noted for both complex and simple texts was not significant.\n\\textbf{Conclusions} This study demonstrates the potential of AI to transform\ncommon tasks in clinical workflows, with ostensible positive impacts on work\nefficiencies for complex clinical coding tasks. Further studies within hospital\nworkflows are required before these presumed impacts can be more clearly\nunderstood.",
      "tldr_zh": "这项研究通过交叉随机对照试验（crossover randomized controlled trial）评估了AI工具Easy-ICD在斯堪的纳维亚（挪威和瑞典）临床编码实践中的效果，旨在提高编码的准确性和效率。参与者随机分组，交叉编码复杂和简单文本，同时使用或不使用该工具。结果显示，使用Easy-ICD后，复杂文本的编码时间减少了46%（基于Mann-Whitney U test，P<0.001），但对准确性的改善不显著，而简单文本则无明显时间差异。研究结论认为，AI有潜力提升复杂临床编码任务的效率，但需在医院工作流程中进行更多研究以确认其实际影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.23725v1",
      "published_date": "2024-10-31 08:24:37 UTC",
      "updated_date": "2024-10-31 08:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:29.417877"
    },
    {
      "arxiv_id": "2410.23724v1",
      "title": "Argumentation and Machine Learning",
      "title_zh": "论证和机器学习",
      "authors": [
        "Antonio Rago",
        "Kristijonas Čyras",
        "Jack Mumford",
        "Oana Cocarascu"
      ],
      "abstract": "This chapter provides an overview of research works that present approaches\nwith some degree of cross-fertilisation between Computational Argumentation and\nMachine Learning. Our review of the literature identified two broad themes\nrepresenting the purpose of the interaction between these two areas:\nargumentation for machine learning and machine learning for argumentation.\nAcross these two themes, we systematically evaluate the spectrum of works\nacross various dimensions, including the type of learning and the form of\nargumentation framework used. Further, we identify three types of interaction\nbetween these two areas: synergistic approaches, where the Argumentation and\nMachine Learning components are tightly integrated; segmented approaches, where\nthe two are interleaved such that the outputs of one are the inputs of the\nother; and approximated approaches, where one component shadows the other at a\nchosen level of detail. We draw conclusions about the suitability of certain\nforms of Argumentation for supporting certain types of Machine Learning, and\nvice versa, with clear patterns emerging from the review. Whilst the reviewed\nworks provide inspiration for successfully combining the two fields of\nresearch, we also identify and discuss limitations and challenges that ought to\nbe addressed in order to ensure that they remain a fruitful pairing as AI\nadvances.",
      "tldr_zh": "本章综述了计算论证（Computational Argumentation）和机器学习（Machine Learning）之间的交叉研究，识别了两个主要主题：论证用于机器学习（如提供推理支持）和机器学习用于论证（如优化框架）。作者系统评估了这些作品在学习类型、论证框架形式等方面的维度，并将交互类型分为协同（synergistic approaches，紧密整合组件）、分段（segmented approaches，输出互为输入）和近似（approximated approaches，模拟细节级别）方法。研究得出了某些论证形式适合特定机器学习类型的结论，同时指出了现有局限性和挑战，以促进这两个领域在AI进步中的持续融合。",
      "categories": [
        "cs.AI",
        "F.4.1; I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "44 pages, to appear in the Handbook of Formal Argumentation and the\n  Journal of Applied Logics",
      "pdf_url": "http://arxiv.org/pdf/2410.23724v1",
      "published_date": "2024-10-31 08:19:58 UTC",
      "updated_date": "2024-10-31 08:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:44:56.241901"
    },
    {
      "arxiv_id": "2411.00062v3",
      "title": "Scalable Reinforcement Post-Training Beyond Static Human Prompts: Evolving Alignment via Asymmetric Self-Play",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Ye",
        "Rishabh Agarwal",
        "Tianqi Liu",
        "Rishabh Joshi",
        "Sarmishta Velury",
        "Quoc V. Le",
        "Qijun Tan",
        "Yuan Liu"
      ],
      "abstract": "Current reinforcement learning (RL) frameworks for large language models\n(LLM) post-training typically assume a fixed prompt distribution, which is\nsub-optimal and bottlenecks scalability. Prior works have explored prompt\nevolving, but are often limited to the supervised fine-tuning stage, and\nprompts are sampled and evolved uniformly without signals. This empirical work\npresents a paradigm shift: Evolving Alignment via Asymmetric Self-Play (eva),\nthat casts post-training as an infinite game with regret-based signals for 2\nplayers: (i) a creator, who strategically samples and creates new informative\nprompts and (ii) a solver, who learns to produce preferred responses. eva is\nthe first method that allows language models to adaptively create training\nprompts in both offline and online RL post-training. The design is simple,\neasy-to-use yet remarkably effective: eva sets a new SOTA on challenging\nbenchmarks, without any extra human prompts, e.g. it boosts the win-rate of\ngemma-2-9b-it on Arena-Hard by 51.6% -> 60.1% for DPO and 52.6% -> 62.4% for\nRLOO, surpassing claude-3-opus and catching up to gemini-1.5-pro, both of which\nare orders of magnitude larger. Extensive experiments show eva can create\neffective RL curricula and is robust across ablations. We believe adaptively\nevolving prompts are key to designing the next-generation RL post-training\nscheme.",
      "tldr_zh": "该研究指出，现有强化学习（RL）框架用于大型语言模型（LLM）的后训练通常依赖固定提示分布，导致可扩展性受限。作者提出了一种新范式Evolving Alignment via Asymmetric Self-Play (eva)，将后训练视为一个无限游戏，由两个玩家（creator负责战略采样和创建新提示，solver负责学习生成优选响应）通过基于遗憾信号的不对称自博弈来演化提示，这是首个支持离线和在线RL后训练的自适应提示创建方法。实验结果显示，eva在挑战性基准如Arena-Hard上显著提升性能，例如将gemma-2-9b-it的胜率从51.6%提高到60.1%（DPO）和从52.6%提高到62.4%（RLOO），超越了claude-3-opus并接近gemini-1.5-pro。作者强调，这种自适应提示演化是设计下一代RL后训练方案的关键。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "spotlight @ neurips language gamification workshop. updated the\n  problem description and added new online RL experiments in this version",
      "pdf_url": "http://arxiv.org/pdf/2411.00062v3",
      "published_date": "2024-10-31 08:15:32 UTC",
      "updated_date": "2025-04-09 19:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:45:09.897805"
    },
    {
      "arxiv_id": "2411.00875v1",
      "title": "Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches",
      "title_zh": "利用 TrAdaBoost 和多分类器深度学习方法增强脑肿瘤分类",
      "authors": [
        "Mahin Mohammadi",
        "Saman Jamshidi"
      ],
      "abstract": "Brain tumors pose a serious health threat due to their rapid growth and\npotential for metastasis. While medical imaging has advanced significantly,\naccurately identifying and characterizing these tumors remains a challenge.\nThis study addresses this challenge by leveraging the innovative TrAdaBoost\nmethodology to enhance the Brain Tumor Segmentation (BraTS2020) dataset, aiming\nto improve the efficiency and accuracy of brain tumor classification. Our\napproach combines state-of-the-art deep learning algorithms, including the\nVision Transformer (ViT), Capsule Neural Network (CapsNet), and convolutional\nneural networks (CNNs) such as ResNet-152 and VGG16. By integrating these\nmodels within a multi-classifier framework, we harness the strengths of each\napproach to achieve more robust and reliable tumor classification. A novel\ndecision template is employed to synergistically combine outputs from different\nalgorithms, further enhancing classification accuracy. To augment the training\nprocess, we incorporate a secondary dataset, \"Brain Tumor MRI Dataset,\" as a\nsource domain, providing additional data for model training and improving\ngeneralization capabilities. Our findings demonstrate a high accuracy rate in\nclassifying tumor versus non-tumor images, signifying the effectiveness of our\napproach in the medical imaging domain. This study highlights the potential of\nadvanced machine learning techniques to contribute significantly to the early\nand accurate diagnosis of brain tumors, ultimately improving patient outcomes.",
      "tldr_zh": "本文研究了使用 TrAdaBoost 方法增强 BraTS2020 数据集，以提高脑肿瘤分类的效率和准确性。方法结合了 Vision Transformer (ViT)、Capsule Neural Network (CapsNet)、ResNet-152 和 VGG16 等深度学习模型，通过多分类器框架和新型决策模板协同整合这些模型的优点。研究还引入了 Brain Tumor MRI Dataset 作为源域数据，以增强训练过程并提升模型的泛化能力。结果显示，该方法在肿瘤与非肿瘤图像分类中实现了高准确率，证明了其在脑肿瘤早期诊断中的潜在价值，并有助于改善患者预后。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00875v1",
      "published_date": "2024-10-31 07:28:06 UTC",
      "updated_date": "2024-10-31 07:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:47:20.325717"
    },
    {
      "arxiv_id": "2410.23680v1",
      "title": "Rethinking Inverse Reinforcement Learning: from Data Alignment to Task Alignment",
      "title_zh": "重新审视逆强化学习：从数据对齐到任务对齐",
      "authors": [
        "Weichao Zhou",
        "Wenchao Li"
      ],
      "abstract": "Many imitation learning (IL) algorithms use inverse reinforcement learning\n(IRL) to infer a reward function that aligns with the demonstration. However,\nthe inferred reward functions often fail to capture the underlying task\nobjectives. In this paper, we propose a novel framework for IRL-based IL that\nprioritizes task alignment over conventional data alignment. Our framework is a\nsemi-supervised approach that leverages expert demonstrations as weak\nsupervision to derive a set of candidate reward functions that align with the\ntask rather than only with the data. It then adopts an adversarial mechanism to\ntrain a policy with this set of reward functions to gain a collective\nvalidation of the policy's ability to accomplish the task. We provide\ntheoretical insights into this framework's ability to mitigate task-reward\nmisalignment and present a practical implementation. Our experimental results\nshow that our framework outperforms conventional IL baselines in complex and\ntransfer learning scenarios.",
      "tldr_zh": "本论文重新审视逆强化学习（IRL），提出一个新框架，将重点从数据对齐转向任务对齐，以解决传统模仿学习（IL）算法中奖励函数无法捕捉底层任务目标的问题。该框架采用半监督方法，利用专家演示作为弱监督，生成一组任务对齐的候选奖励函数，并通过对抗机制训练策略，以验证策略在任务完成方面的整体能力。理论分析表明，该框架能有效缓解任务-奖励失调问题，并在实际实现中表现出色；实验结果显示，在复杂和转移学习场景中，该框架优于传统IL基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2306.01731",
      "pdf_url": "http://arxiv.org/pdf/2410.23680v1",
      "published_date": "2024-10-31 07:08:14 UTC",
      "updated_date": "2024-10-31 07:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:45:32.503184"
    },
    {
      "arxiv_id": "2411.00874v2",
      "title": "VecCity: A Taxonomy-guided Library for Map Entity Representation Learning",
      "title_zh": "VecCity: 一种基于分类学的地图实体表示学习库",
      "authors": [
        "Wentao Zhang",
        "Jingyuan Wang",
        "Yifan Yang",
        "Leong Hou U"
      ],
      "abstract": "Electronic maps consist of diverse entities, such as points of interest\n(POIs), road networks, and land parcels, playing a vital role in applications\nlike ITS and LBS. Map entity representation learning (MapRL) generates\nversatile and reusable data representations, providing essential tools for\nefficiently managing and utilizing map entity data. Despite the progress in\nMapRL, two key challenges constrain further development. First, existing\nresearch is fragmented, with models classified by the type of map entity,\nlimiting the reusability of techniques across different tasks. Second, the lack\nof unified benchmarks makes systematic evaluation and comparison of models\ndifficult. To address these challenges, we propose a novel taxonomy for MapRL\nthat organizes models based on functional module-such as encoders, pre-training\ntasks, and downstream tasks-rather than by entity type. Building on this\ntaxonomy, we present a taxonomy-driven library, VecCity, which offers\neasy-to-use interfaces for encoding, pre-training, fine-tuning, and evaluation.\nThe library integrates datasets from nine cities and reproduces 21 mainstream\nMapRL models, establishing the first standardized benchmarks for the field.\nVecCity also allows users to modify and extend models through modular\ncomponents, facilitating seamless experimentation. Our comprehensive\nexperiments cover multiple types of map entities and evaluate 21 VecCity\npre-built models across various downstream tasks. Experimental results\ndemonstrate the effectiveness of VecCity in streamlining model development and\nprovide insights into the impact of various components on performance. By\npromoting modular design and reusability, VecCity offers a unified framework to\nadvance research and innovation in MapRL. The code is available at\nhttps://github.com/Bigscity-VecCity/VecCity.",
      "tldr_zh": "本文提出一个新的分类法，用于 Map Entity Representation Learning (MapRL)，将模型基于功能模块（如编码器、预训练任务和下游任务）组织，而不是实体类型，从而解决研究碎片化和缺乏统一基准的挑战。研究团队开发了 VecCity 库，提供易用接口，支持编码、预训练、微调和评估，并整合九个城市的数据集，重现了21个主流模型，建立首个标准化基准。实验结果显示，VecCity 在多种地图实体（如 POIs 和路网）及下游任务上显著提升模型开发效率，并揭示了组件对性能的影响，促进 MapRL 领域的创新和可重用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00874v2",
      "published_date": "2024-10-31 07:03:46 UTC",
      "updated_date": "2025-05-07 12:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:45:44.739300"
    },
    {
      "arxiv_id": "2410.23672v1",
      "title": "Provable Benefit of Cutout and CutMix for Feature Learning",
      "title_zh": "Cutout 和 CutMix 在特征学习中的可证明益处",
      "authors": [
        "Junsoo Oh",
        "Chulhee Yun"
      ],
      "abstract": "Patch-level data augmentation techniques such as Cutout and CutMix have\ndemonstrated significant efficacy in enhancing the performance of vision tasks.\nHowever, a comprehensive theoretical understanding of these methods remains\nelusive. In this paper, we study two-layer neural networks trained using three\ndistinct methods: vanilla training without augmentation, Cutout training, and\nCutMix training. Our analysis focuses on a feature-noise data model, which\nconsists of several label-dependent features of varying rarity and\nlabel-independent noises of differing strengths. Our theorems demonstrate that\nCutout training can learn low-frequency features that vanilla training cannot,\nwhile CutMix training can learn even rarer features that Cutout cannot capture.\nFrom this, we establish that CutMix yields the highest test accuracy among the\nthree. Our novel analysis reveals that CutMix training makes the network learn\nall features and noise vectors \"evenly\" regardless of the rarity and strength,\nwhich provides an interesting insight into understanding patch-level\naugmentation.",
      "tldr_zh": "本研究通过理论分析探讨了 Cutout 和 CutMix 等 patch-level 数据增强技术在视觉任务中的优势，聚焦于两层神经网络的三种训练方式：无增强的 vanilla 训练、Cutout 训练和 CutMix 训练。基于 feature-noise 数据模型，该模型包括不同稀有度的标签相关特征和不同强度的标签无关噪声，论文证明 Cutout 能学习 vanilla 训练无法捕捉的低频特征，而 CutMix 则能进一步学习更稀有的特征，从而实现最高的测试准确率。主要发现是 CutMix 训练使网络均匀学习所有特征和噪声向量，无论其稀有度或强度，这为理解 patch-level 增强技术提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 camera-ready version, 81 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.23672v1",
      "published_date": "2024-10-31 06:41:10 UTC",
      "updated_date": "2024-10-31 06:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:45:55.974840"
    },
    {
      "arxiv_id": "2410.23668v1",
      "title": "Kernel Looping: Eliminating Synchronization Boundaries for Peak Inference Performance",
      "title_zh": "内核循环：消除同步边界以实现峰值推理性能",
      "authors": [
        "David Koeplinger",
        "Darshan Gandhi",
        "Pushkar Nandkar",
        "Nathan Sheeley",
        "Matheen Musaddiq",
        "Leon Zhang",
        "Reid Goodbar",
        "Matthew Shaffer",
        "Han Wang",
        "Angela Wang",
        "Mingran Wang",
        "Raghu Prabhakar"
      ],
      "abstract": "Token generation speed is critical to power the next wave of AI inference\napplications. GPUs significantly underperform during token generation due to\nsynchronization overheads at kernel boundaries, utilizing only 21% of their\npeak memory bandwidth. While recent dataflow architectures mitigate these\noverheads by enabling aggressive fusion of decoder layers into a single kernel,\nthey too leave performance on the table due to synchronization penalties at\nlayer boundaries.\n  This paper presents kernel looping, a specialized global optimization\ntechnique which exploits an optimization opportunity brought by combining the\nunique layer-level fusion possible in modern dataflow architectures with the\nrepeated layer structure found in language models. Kernel looping eliminates\nsynchronization costs between consecutive calls to the same kernel by\ntransforming these calls into a single call to a modified kernel containing a\npipelined outer loop. We evaluate kernel looping on the SambaNova SN40L\nReconfigurable Dataflow Unit (RDU), a commercial dataflow accelerator for AI.\nExperiments demonstrate that kernel looping speeds up the decode phase of a\nwide array of powerful open-source models by up to 2.2$\\times$ on SN40L. Kernel\nlooping allows scaling of decode performance over multiple SN40L sockets,\nachieving speedups of up to 2.5$\\times$. Finally, kernel looping enables SN40L\nto achieve over 90% of peak performance on 8 and 16 sockets and achieve a\nspeedup of up to 3.7$\\times$ over DGX H100. Kernel looping, as well as the\nmodels evaluated in this paper, are deployed in production in a commercial AI\ninference cloud.",
      "tldr_zh": "这篇论文提出 kernel looping，一种全局优化技术，旨在消除 AI 推理中内核同步边界带来的性能损失，从而提升 token 生成速度。方法通过利用数据流架构的层级融合和语言模型的重复层结构，将连续内核调用转化为一个带流水线外循环的单一调用，在 SambaNova SN40L 上实现解码阶段加速高达 2.2 倍。实验结果显示，该技术在多插槽配置下可提升性能至 2.5 倍，并使 SN40L 达到峰值性能的 90%以上，比 DGX H100 快 3.7 倍。该技术已在商业 AI 推理云中部署应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.AR",
        "D.3.4; C.1.3"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23668v1",
      "published_date": "2024-10-31 06:32:47 UTC",
      "updated_date": "2024-10-31 06:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:48:09.058857"
    },
    {
      "arxiv_id": "2410.23649v2",
      "title": "Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Guan-Hua Huang",
        "Wan-Chen Lai",
        "Tai-Been Chen",
        "Chien-Chin Hsu",
        "Huei-Yung Chen",
        "Yi-Chen Wu",
        "Li-Ren Yeh"
      ],
      "abstract": "Parkinson's disease (PD), a degenerative disorder of the central nervous\nsystem, is commonly diagnosed using functional medical imaging techniques such\nas single-photon emission computed tomography (SPECT). In this study, we\nutilized two SPECT data sets (n = 634 and n = 202) from different hospitals to\ndevelop a model capable of accurately predicting PD stages, a multiclass\nclassification task. We used the entire three-dimensional (3D) brain images as\ninput and experimented with various model architectures. Initially, we treated\nthe 3D images as sequences of two-dimensional (2D) slices and fed them\nsequentially into 2D convolutional neural network (CNN) models pretrained on\nImageNet, averaging the outputs to obtain the final predicted stage. We also\napplied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated\nan attention mechanism to account for the varying importance of different\nslices in the prediction process. To further enhance model efficacy and\nrobustness, we simultaneously trained the two data sets using weight sharing, a\ntechnique known as cotraining. Our results demonstrated that 2D models\npretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and\nmodels utilizing the attention mechanism outperformed both 2D and 3D models.\nThe cotraining technique proved effective in improving model performance when\nthe cotraining data sets were sufficiently large.",
      "tldr_zh": "本研究利用两个 SPECT 数据集（n=634 和 n=202），开发基于 3D 脑图像的多类分类模型，用于预测帕金森病（PD）的阶段。方法包括将 3D 图像视为 2D 切片的序列输入在 ImageNet 上预训练的 CNN 模型、应用在 Kinetics-400 上预训练的 3D CNN 模型，并加入注意力机制以突出不同切片的重要性，同时采用 cotraining 技术通过权重共享训练多个数据集。结果表明，2D CNN 模型优于 3D CNN 模型，使用注意力机制的模型进一步提升了性能，且 cotraining 在数据集足够大时显著提高了模型的准确性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 7 figures, and 4 tables. This paper has been accepted for\n  publication in Journal of Imaging Informatics in Medicine",
      "pdf_url": "http://arxiv.org/pdf/2410.23649v2",
      "published_date": "2024-10-31 05:40:08 UTC",
      "updated_date": "2025-01-21 04:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:46:21.234049"
    },
    {
      "arxiv_id": "2411.00873v1",
      "title": "CleaR: Towards Robust and Generalized Parameter-Efficient Fine-Tuning for Noisy Label Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yeachan Kim",
        "Junho Kim",
        "SangKeun Lee"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) has enabled the efficient optimization\nof cumbersome language models in real-world settings. However, as datasets in\nsuch environments often contain noisy labels that adversely affect performance,\nPEFT methods are inevitably exposed to noisy labels. Despite this challenge,\nthe adaptability of PEFT to noisy environments remains underexplored. To bridge\nthis gap, we investigate various PEFT methods under noisy labels.\nInterestingly, our findings reveal that PEFT has difficulty in memorizing noisy\nlabels due to its inherently limited capacity, resulting in robustness.\nHowever, we also find that such limited capacity simultaneously makes PEFT more\nvulnerable to interference of noisy labels, impeding the learning of clean\nsamples. To address this issue, we propose Clean Routing (CleaR), a novel\nrouting-based PEFT approach that adaptively activates PEFT modules. In CleaR,\nPEFT modules are preferentially exposed to clean data while bypassing the noisy\nones, thereby minimizing the noisy influence. To verify the efficacy of CleaR,\nwe perform extensive experiments on diverse configurations of noisy labels. The\nresults convincingly demonstrate that CleaR leads to substantially improved\nperformance in noisy environments.",
      "tldr_zh": "该研究探讨了参数高效微调 (PEFT) 在噪声标签环境下的表现，发现 PEFT 由于容量有限，对噪声标签有一定鲁棒性，但也更容易受干扰从而影响干净样本的学习。针对这一问题，作者提出了一种新型方法 CleaR，即基于路由的 PEFT 策略，能够自适应激活模块，优先让 PEFT 模块处理干净数据并绕过噪声数据，从而最小化噪声影响。通过广泛实验验证，CleaR 在多种噪声标签配置下显著提升了模型性能，提供了一种更可靠的细调框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2411.00873v1",
      "published_date": "2024-10-31 05:11:58 UTC",
      "updated_date": "2024-10-31 05:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:46:31.532756"
    },
    {
      "arxiv_id": "2411.10450v1",
      "title": "Dataset Refinement for Improving the Generalization Ability of the EEG Decoding Model",
      "title_zh": "数据集精炼以提升 EEG 解码模型的泛化能力",
      "authors": [
        "Sung-Jin Kim",
        "Dae-Hyeok Lee",
        "Hyeon-Taek Han"
      ],
      "abstract": "Electroencephalography (EEG) is a generally used neuroimaging approach in\nbrain-computer interfaces due to its non-invasive characteristics and\nconvenience, making it an effective tool for understanding human intentions.\nTherefore, recent research has focused on decoding human intentions from EEG\nsignals utilizing deep learning methods. However, since EEG signals are highly\nsusceptible to noise during acquisition, there is a high possibility of the\nexistence of noisy data in the dataset. Although pioneer studies have generally\nassumed that the dataset is well-curated, this assumption is not always met in\nthe EEG dataset. In this paper, we addressed this issue by designing a dataset\nrefinement algorithm that can eliminate noisy data based on metrics evaluating\ndata influence during the training process. We applied the proposed algorithm\nto two motor imagery EEG public datasets and three different models to perform\ndataset refinement. The results indicated that retraining the model with the\nrefined dataset consistently led to better generalization performance compared\nto using the original dataset. Hence, we demonstrated that removing noisy data\nfrom the training dataset alone can effectively improve the generalization\nperformance of deep learning models in the EEG domain.",
      "tldr_zh": "这篇论文针对 EEG 信号易受噪声影响的问题，提出了一种数据集精炼算法，该算法基于数据影响评估指标来识别并移除训练过程中的噪声样本。研究者将该算法应用于两个运动想象 EEG 公共数据集和三种不同模型进行实验，结果显示使用精炼后的数据集重新训练模型，能显著提升模型的泛化性能。相比原数据集，改进后的模型在 EEG 意图解码任务中表现出更稳定的表现。该方法证明了在 EEG 领域，仅通过清理噪声数据即可有效改善深度学习模型的泛化能力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "4 pages, 1 figure, conference",
      "pdf_url": "http://arxiv.org/pdf/2411.10450v1",
      "published_date": "2024-10-31 05:08:24 UTC",
      "updated_date": "2024-10-31 05:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:46:43.473791"
    },
    {
      "arxiv_id": "2410.23637v2",
      "title": "Anytime-Constrained Equilibria in Polynomial Time",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy McMahan"
      ],
      "abstract": "We extend anytime constraints to the Markov game setting and the\ncorresponding solution concept of an anytime-constrained equilibrium (ACE).\nThen, we present a comprehensive theory of anytime-constrained equilibria that\nincludes (1) a computational characterization of feasible policies, (2) a\nfixed-parameter tractable algorithm for computing ACE, and (3) a\npolynomial-time algorithm for approximately computing ACE. Since computing a\nfeasible policy is NP-hard even for two-player zero-sum games, our\napproximation guarantees are optimal so long as $P \\neq NP$. We also develop\nthe first theory of efficient computation for action-constrained Markov games,\nwhich may be of independent interest.",
      "tldr_zh": "该论文将 anytime constraints 扩展到 Markov game 环境中，并引入了 anytime-constrained equilibrium (ACE) 的概念，以处理多代理决策问题。研究提供了可行策略的计算表征、一个固定参数可追踪算法用于精确计算 ACE，以及一个多项式时间算法用于近似计算 ACE。鉴于计算可行策略在两玩家零和游戏中是 NP-hard，该近似算法的性能保证是最佳的，除非 P = NP；此外，论文还发展了 action-constrained Markov games 的高效计算理论，这可能具有独立价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23637v2",
      "published_date": "2024-10-31 05:07:01 UTC",
      "updated_date": "2025-03-04 18:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:48:20.355736"
    },
    {
      "arxiv_id": "2410.23630v1",
      "title": "Adaptive Alignment: Dynamic Preference Adjustments via Multi-Objective Reinforcement Learning for Pluralistic AI",
      "title_zh": "自适应对齐：通过多目标强化学习动态",
      "authors": [
        "Hadassah Harland",
        "Richard Dazeley",
        "Peter Vamplew",
        "Hashini Senaratne",
        "Bahareh Nakisa",
        "Francisco Cruz"
      ],
      "abstract": "Emerging research in Pluralistic Artificial Intelligence (AI) alignment seeks\nto address how intelligent systems can be designed and deployed in accordance\nwith diverse human needs and values. We contribute to this pursuit with a\ndynamic approach for aligning AI with diverse and shifting user preferences\nthrough Multi Objective Reinforcement Learning (MORL), via post-learning policy\nselection adjustment. In this paper, we introduce the proposed framework for\nthis approach, outline its anticipated advantages and assumptions, and discuss\ntechnical details about the implementation. We also examine the broader\nimplications of adopting a retroactive alignment approach through the\nsociotechnical systems perspective.",
      "tldr_zh": "本文提出了一种动态框架Adaptive Alignment，用于通过Multi-Objective Reinforcement Learning (MORL)实现Pluralistic AI与多样化和变化的用户偏好对齐。该方法采用后学习策略选择调整（post-learning policy selection adjustment），允许AI在部署后灵活适应不同人类需求和价值观。论文讨论了该框架的预期优势、假设和技术实现细节，并从社会技术系统视角分析了其更广泛的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for the Pluralistic Alignment workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23630v1",
      "published_date": "2024-10-31 04:46:52 UTC",
      "updated_date": "2024-10-31 04:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:48:32.818739"
    },
    {
      "arxiv_id": "2410.23629v2",
      "title": "Posture-Informed Muscular Force Learning for Robust Hand Pressure Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungjin Seo",
        "Junghoon Seo",
        "Hanseok Jeong",
        "Sangpil Kim",
        "Sang Ho Yoon"
      ],
      "abstract": "We present PiMForce, a novel framework that enhances hand pressure estimation\nby leveraging 3D hand posture information to augment forearm surface\nelectromyography (sEMG) signals. Our approach utilizes detailed spatial\ninformation from 3D hand poses in conjunction with dynamic muscle activity from\nsEMG to enable accurate and robust whole-hand pressure measurements under\ndiverse hand-object interactions. We also developed a multimodal data\ncollection system that combines a pressure glove, an sEMG armband, and a\nmarkerless finger-tracking module. We created a comprehensive dataset from 21\nparticipants, capturing synchronized data of hand posture, sEMG signals, and\nexerted hand pressure across various hand postures and hand-object interaction\nscenarios using our collection system. Our framework enables precise hand\npressure estimation in complex and natural interaction scenarios. Our approach\nsubstantially mitigates the limitations of traditional sEMG-based or\nvision-based methods by integrating 3D hand posture information with sEMG\nsignals. Video demos, data, and code are available online.",
      "tldr_zh": "本研究提出 PiMForce 框架，通过整合 3D hand posture 信息和 forearm surface electromyography (sEMG) 信号，实现准确且稳健的 whole-hand pressure estimation，在多样化的 hand-object interactions 中表现突出。框架利用多模态数据收集系统，包括 pressure glove、sEMG armband 和 markerless finger-tracking 模块，从 21 名参与者收集同步数据集，涵盖各种手部姿势和互动场景。该方法有效缓解了传统 sEMG-based 或 vision-based 方法的局限性，提升了复杂自然互动中的压力估计精度。研究成果包括公开的视频演示、数据和代码，支持进一步应用和发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024. Project Page Link:\n  https://pimforce.hcitech.org/",
      "pdf_url": "http://arxiv.org/pdf/2410.23629v2",
      "published_date": "2024-10-31 04:42:43 UTC",
      "updated_date": "2024-11-01 08:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:48:44.793881"
    },
    {
      "arxiv_id": "2411.00871v1",
      "title": "LLaMo: Large Language Model-based Molecular Graph Assistant",
      "title_zh": "LLaMo：基于大型语言模型的分子图助理",
      "authors": [
        "Jinyoung Park",
        "Minseong Bae",
        "Dohwan Ko",
        "Hyunwoo J. Kim"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization and\ninstruction-following capabilities with instruction tuning. The advancements in\nLLMs and instruction tuning have led to the development of Large\nVision-Language Models (LVLMs). However, the competency of the LLMs and\ninstruction tuning have been less explored in the molecular domain. Thus, we\npropose LLaMo: Large Language Model-based Molecular graph assistant, which is\nan end-to-end trained large molecular graph-language model. To bridge the\ndiscrepancy between the language and graph modalities, we present the\nmulti-level graph projector that transforms graph representations into graph\ntokens by abstracting the output representations of each GNN layer and motif\nrepresentations with the cross-attention mechanism. We also introduce\nmachine-generated molecular graph instruction data to instruction-tune the\nlarge molecular graph-language model for general-purpose molecule and language\nunderstanding. Our extensive experiments demonstrate that LLaMo shows the best\nperformance on diverse tasks, such as molecular description generation,\nproperty prediction, and IUPAC name prediction. The code of LLaMo is available\nat https://github.com/mlvlab/LLaMo.",
      "tldr_zh": "本研究提出LLaMo，一种基于Large Language Models (LLMs)的分子图助手模型，通过端到端训练实现分子图和语言模态的融合。该模型引入multi-level graph projector和cross-attention mechanism，将分子图表示转化为图tokens，以桥接语言和图之间的差距，并利用机器生成的分子图指令数据进行instruction tuning，提升通用分子和语言理解能力。实验结果显示，LLaMo在分子描述生成、属性预测和IUPAC名称预测等任务上表现出最佳性能，证明了其在分子领域的高效性。代码已在GitHub上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.00871v1",
      "published_date": "2024-10-31 03:56:05 UTC",
      "updated_date": "2024-10-31 03:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:48:55.981831"
    },
    {
      "arxiv_id": "2410.23598v2",
      "title": "Using Structural Similarity and Kolmogorov-Arnold Networks for Anatomical Embedding of Cortical Folding Patterns",
      "title_zh": "翻译失败",
      "authors": [
        "Minheng Chen",
        "Chao Cao",
        "Tong Chen",
        "Yan Zhuang",
        "Jing Zhang",
        "Yanjun Lyu",
        "Xiaowei Yu",
        "Lu Zhang",
        "Tianming Liu",
        "Dajiang Zhu"
      ],
      "abstract": "The 3-hinge gyrus (3HG) is a newly defined folding pattern, which is the\nconjunction of gyri coming from three directions in cortical folding. Many\nstudies demonstrated that 3HGs can be reliable nodes when constructing brain\nnetworks or connectome since they simultaneously possess commonality and\nindividuality across different individual brains and populations. However, 3HGs\nare identified and validated within individual spaces, making it difficult to\ndirectly serve as the brain network nodes due to the absence of cross-subject\ncorrespondence. The 3HG correspondences represent the intrinsic regulation of\nbrain organizational architecture, traditional image-based registration methods\ntend to fail because individual anatomical properties need to be fully\nrespected. To address this challenge, we propose a novel self-supervised\nframework for anatomical feature embedding of the 3HGs to build the\ncorrespondences among different brains. The core component of this framework is\nto construct a structural similarity-enhanced multi-hop feature encoding\nstrategy based on the recently developed Kolmogorov-Arnold network (KAN) for\nanatomical feature embedding. Extensive experiments suggest that our approach\ncan effectively establish robust cross-subject correspondences when no\none-to-one mapping exists.",
      "tldr_zh": "该研究针对3-hinge gyrus (3HG) 这种皮层褶皱模式提出了一种自监督框架，以解决其在脑网络构建中缺乏跨主体对应性的问题。框架的核心是基于Kolmogorov-Arnold networks (KAN)构建的结构相似性增强多跳特征编码策略，用于对3HG进行解剖特征嵌入，从而建立不同大脑间的稳健对应关系。实验结果表明，该方法在没有一对一映射的情况下，能有效实现跨主体对应，提升了脑网络节点的可靠性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23598v2",
      "published_date": "2024-10-31 03:28:23 UTC",
      "updated_date": "2025-02-23 04:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:49:07.950819"
    },
    {
      "arxiv_id": "2410.23594v1",
      "title": "How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?",
      "title_zh": "翻译失败",
      "authors": [
        "Weiguo Gao",
        "Ming Li"
      ],
      "abstract": "Real-world data is often assumed to lie within a low-dimensional structure\nembedded in high-dimensional space. In practical settings, we observe only a\nfinite set of samples, forming what we refer to as the sample data subspace. It\nserves an essential approximation supporting tasks such as dimensionality\nreduction and generation. A major challenge lies in whether generative models\ncan reliably synthesize samples that stay within this subspace rather than\ndrifting away from the underlying structure. In this work, we provide\ntheoretical insights into this challenge by leveraging Flow Matching models,\nwhich transform a simple prior into a complex target distribution via a learned\nvelocity field. By treating the real data distribution as discrete, we derive\nanalytical expressions for the optimal velocity field under a Gaussian prior,\nshowing that generated samples memorize real data points and represent the\nsample data subspace exactly. To generalize to suboptimal scenarios, we\nintroduce the Orthogonal Subspace Decomposition Network (OSDNet), which\nsystematically decomposes the velocity field into subspace and off-subspace\ncomponents. Our analysis shows that the off-subspace component decays, while\nthe subspace component generalizes within the sample data subspace, ensuring\ngenerated samples preserve both proximity and diversity.",
      "tldr_zh": "本研究探讨了Flow Matching模型在样本数据子空间中的记忆和泛化能力，针对真实数据通常位于高维空间低维子空间内的特性，分析生成模型是否能生成保持在该子空间的样本。作者推导了在高斯先验下最优速度场（optimal velocity field）的解析表达式，证明生成的样本能精确记忆真实数据点并精确表示样本数据子空间。论文引入Orthogonal Subspace Decomposition Network (OSDNet)来分解速度场，其分析显示子空间组件确保生成样本在子空间内泛化，保持接近性和多样性，同时非子空间组件衰减，从而提升生成模型的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23594v1",
      "published_date": "2024-10-31 03:08:07 UTC",
      "updated_date": "2024-10-31 03:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:49:20.186712"
    },
    {
      "arxiv_id": "2410.23578v1",
      "title": "Automating Quantum Software Maintenance: Flakiness Detection and Root Cause Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Janakan Sivaloganathan",
        "Ainaz Jamshidi",
        "Andriy Miranskyy",
        "Lei Zhang"
      ],
      "abstract": "Flaky tests, which pass or fail inconsistently without code changes, are a\nmajor challenge in software engineering in general and in quantum software\nengineering in particular due to their complexity and probabilistic nature,\nleading to hidden issues and wasted developer effort.\n  We aim to create an automated framework to detect flaky tests in quantum\nsoftware and an extended dataset of quantum flaky tests, overcoming the\nlimitations of manual methods.\n  Building on prior manual analysis of 14 quantum software repositories, we\nexpanded the dataset and automated flaky test detection using transformers and\ncosine similarity. We conducted experiments with Large Language Models (LLMs)\nfrom the OpenAI GPT and Meta LLaMA families to assess their ability to detect\nand classify flaky tests from code and issue descriptions.\n  Embedding transformers proved effective: we identified 25 new flaky tests,\nexpanding the dataset by 54%. Top LLMs achieved an F1-score of 0.8871 for\nflakiness detection but only 0.5839 for root cause identification.\n  We introduced an automated flaky test detection framework using machine\nlearning, showing promising results but highlighting the need for improved root\ncause detection and classification in large quantum codebases. Future work will\nfocus on improving detection techniques and developing automatic flaky test\nfixes.",
      "tldr_zh": "这篇论文针对量子软件中的 Flaky tests（不稳定测试）问题，提出一个自动化框架，用于检测这些测试并分析其根因，以减少手动方法的影响。研究团队扩展了数据集，通过 transformers 和 cosine similarity 技术自动化检测，并利用 OpenAI GPT 和 Meta LLaMA 系列的 LLMs 从代码和问题描述中识别 Flaky tests。实验结果显示，该框架检测准确率达到 F1-score 0.8871，但根因识别仅为 0.5839，并新标识了 25 个 Flaky tests，数据集扩展了 54%。未来工作将聚焦于改进检测技术和开发自动修复机制，为量子软件维护提供更可靠的工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.23578v1",
      "published_date": "2024-10-31 02:43:04 UTC",
      "updated_date": "2024-10-31 02:43:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:49:33.419536"
    },
    {
      "arxiv_id": "2410.23577v2",
      "title": "MS-Glance: Bio-Insipred Non-semantic Context Vectors and their Applications in Supervising Image Reconstruction",
      "title_zh": "MS-Glance：受生物启发的非语义上下文向量及其在监督图像重建中的应用",
      "authors": [
        "Ziqi Gao",
        "Wendi Yang",
        "Yujia Li",
        "Lei Xing",
        "S. Kevin Zhou"
      ],
      "abstract": "Non-semantic context information is crucial for visual recognition, as the\nhuman visual perception system first uses global statistics to process scenes\nrapidly before identifying specific objects. However, while semantic\ninformation is increasingly incorporated into computer vision tasks such as\nimage reconstruction, non-semantic information, such as global spatial\nstructures, is often overlooked. To bridge the gap, we propose a biologically\ninformed non-semantic context descriptor, \\textbf{MS-Glance}, along with the\nGlance Index Measure for comparing two images. A Global Glance vector is\nformulated by randomly retrieving pixels based on a perception-driven rule from\nan image to form a vector representing non-semantic global context, while a\nlocal Glance vector is a flattened local image window, mimicking a zoom-in\nobservation. The Glance Index is defined as the inner product of two\nstandardized sets of Glance vectors. We evaluate the effectiveness of\nincorporating Glance supervision in two reconstruction tasks: image fitting\nwith implicit neural representation (INR) and undersampled MRI reconstruction.\nExtensive experimental results show that MS-Glance outperforms existing image\nrestoration losses across both natural and medical images. The code is\navailable at \\url{https://github.com/Z7Gao/MSGlance}.",
      "tldr_zh": "本研究强调了非语义上下文信息在视觉识别中的重要性，提出了一种生物启发的描述符 MS-Glance 和 Glance Index Measure，用于捕捉图像的全局和局部结构。MS-Glance 包括 Global Glance vector（通过感知驱动规则随机检索像素形成非语义全局上下文）和 Local Glance vector（平坦化的局部图像窗口），而 Glance Index 则定义为两个标准化 Glance 向量的内积。作者将 MS-Glance 应用于图像重建任务，如 INR 图像拟合和 undersampled MRI 重建，实验结果显示其在自然和医疗图像上优于现有图像恢复损失。代码已在 GitHub 上开源，提供进一步验证的可能性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.23577v2",
      "published_date": "2024-10-31 02:42:25 UTC",
      "updated_date": "2024-11-23 10:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:49:45.305118"
    },
    {
      "arxiv_id": "2411.10449v1",
      "title": "Love in Action: Gamifying Public Video Cameras for Fostering Social Relationships in Real World",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Zhang",
        "Da Li",
        "Geng Wu",
        "Yaoning Li",
        "Xiaobing Sun",
        "Liang Wang"
      ],
      "abstract": "In this paper, we create \"Love in Action\" (LIA), a body language-based social\ngame utilizing video cameras installed in public spaces to enhance social\nrelationships in real-world. In the game, participants assume dual roles, i.e.,\nrequesters, who issue social requests, and performers, who respond social\nrequests through performing specified body languages. To mediate the\ncommunication between participants, we build an AI-enhanced video analysis\nsystem incorporating multiple visual analysis modules like person detection,\nattribute recognition, and action recognition, to assess the performer's body\nlanguage quality. A two-week field study involving 27 participants shows\nsignificant improvements in their social friendships, as indicated by\nself-reported questionnaires. Moreover, user experiences are investigated to\nhighlight the potential of public video cameras as a novel communication medium\nfor socializing in public spaces.",
      "tldr_zh": "本文介绍了“Love in Action”(LIA)游戏，该系统利用公共空间的视频摄像头，通过肢体语言-based社交互动来增强现实世界的社交关系。参与者分为requester（发出社交请求）和performer（通过指定肢体语言回应），并采用AI增强视频分析系统，包括person detection、attribute recognition和action recognition模块，来评估表演质量。一项涉及27名参与者的两周现场研究显示，社交友谊显著改善，用户体验也证明了公共视频摄像头作为新型社交媒介的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "14J60 (Primary) 14F05, 14J26 (Secondary)"
      ],
      "primary_category": "cs.HC",
      "comment": "accepted as a main track paper by EAI-ArtsIT 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.10449v1",
      "published_date": "2024-10-31 02:38:40 UTC",
      "updated_date": "2024-10-31 02:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:49:55.924220"
    },
    {
      "arxiv_id": "2410.23558v2",
      "title": "Transferable Ensemble Black-box Jailbreak Attacks on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqi Yang",
        "Hongye Fu"
      ],
      "abstract": "In this report, we propose a novel black-box jailbreak attacking framework\nthat incorporates various LLM-as-Attacker methods to deliver transferable and\npowerful jailbreak attacks. Our method is designed based on three key\nobservations from existing jailbreaking studies and practices. First, we\nconsider an ensemble approach should be more effective in exposing the\nvulnerabilities of an aligned LLM compared to individual attacks. Second,\ndifferent malicious instructions inherently vary in their jailbreaking\ndifficulty, necessitating differentiated treatment to ensure more efficient\nattacks. Finally, the semantic coherence of a malicious instruction is crucial\nfor triggering the defenses of an aligned LLM; therefore, it must be carefully\ndisrupted to manipulate its embedding representation, thereby increasing the\njailbreak success rate. We validated our approach by participating in the\nCompetition for LLM and Agent Safety 2024, where our team achieved top\nperformance in the Jailbreaking Attack Track.",
      "tldr_zh": "这篇论文提出了一种新型的 black-box jailbreak attacks 框架，通过集成多种 LLM-as-Attacker 方法，实现对 Large Language Models 的可转移和高效攻击。框架基于三个关键观察：ensemble 方法比单一攻击更能暴露 LLM 的漏洞、不同恶意指令的难度需差异化处理，以及破坏恶意指令的语义连贯性以操纵嵌入表示并提高成功率。实验验证显示，该方法在 Competition for LLM and Agent Safety 2024 的 Jailbreaking Attack Track 中取得了顶尖表现，证明了其在提升攻击效率方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23558v2",
      "published_date": "2024-10-31 01:55:33 UTC",
      "updated_date": "2024-11-27 11:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:50:08.244805"
    },
    {
      "arxiv_id": "2410.23555v1",
      "title": "From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents",
      "title_zh": "从上下文到行动：状态表示和上下文对多轮网页导航代理泛化的影响分析",
      "authors": [
        "Nalin Tiwary",
        "Vardhan Dongre",
        "Sanil Arun Chawla",
        "Ashwin Lamani",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Recent advancements in Large Language Model (LLM)-based frameworks have\nextended their capabilities to complex real-world applications, such as\ninteractive web navigation. These systems, driven by user commands, navigate\nweb browsers to complete tasks through multi-turn dialogues, offering both\ninnovative opportunities and significant challenges. Despite the introduction\nof benchmarks for conversational web navigation, a detailed understanding of\nthe key contextual components that influence the performance of these agents\nremains elusive. This study aims to fill this gap by analyzing the various\ncontextual elements crucial to the functioning of web navigation agents. We\ninvestigate the optimization of context management, focusing on the influence\nof interaction history and web page representation. Our work highlights\nimproved agent performance across out-of-distribution scenarios, including\nunseen websites, categories, and geographic locations through effective context\nmanagement. These findings provide insights into the design and optimization of\nLLM-based agents, enabling more accurate and effective web navigation in\nreal-world applications.",
      "tldr_zh": "这篇论文分析了状态表示和上下文对多轮网页导航代理泛化能力的影响，聚焦于Large Language Model (LLM)-based框架在交互式网页任务中的性能。研究通过优化交互历史和网页表示等关键上下文元素，探讨了如何提升代理在分布外场景（如未见网站、类别和地理位置）的表现。结果表明，有效的上下文管理显著提高了代理的准确性和有效性，为设计更可靠的LLM-based网页导航系统提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.23555v1",
      "published_date": "2024-10-31 01:51:41 UTC",
      "updated_date": "2024-10-31 01:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:50:20.108294"
    },
    {
      "arxiv_id": "2410.23537v1",
      "title": "ALISE: Accelerating Large Language Model Serving with Speculative Scheduling",
      "title_zh": "ALISE：通过推测性调度加速大型语言模型服务",
      "authors": [
        "Youpeng Zhao",
        "Jun Wang"
      ],
      "abstract": "Large Language Models (LLMs) represent a revolutionary advancement in the\ncontemporary landscape of artificial general intelligence (AGI). As exemplified\nby ChatGPT, LLM-based applications necessitate minimal response latency and\nmaximal throughput for inference serving. However, due to the unpredictability\nof LLM execution, the first-come-first-serve (FCFS) scheduling policy employed\nby current LLM serving systems suffers from head-of-line (HoL) blocking issues\nand long job response times.\n  In this paper, we propose a new efficient LLM inference serving framework,\nnamed ALISE. The key design paradigm of ALISE is to leverage a novel\nspeculative scheduler by estimating the execution time for each job and\nexploiting such prior knowledge to assign appropriate job priority orders, thus\nminimizing potential queuing delays for heterogeneous workloads. Furthermore,\nto mitigate the memory overhead of the intermediate key-value (KV) cache, we\nemploy a priority-based adaptive memory management protocol and\nquantization-based compression techniques. Evaluations demonstrate that in\ncomparison to the state-of-the-art solution vLLM, ALISE improves the throughput\nof inference serving by up to 1.8x and 2.1x under the same latency constraint\non the Alpaca and ShareGPT datasets, respectively.",
      "tldr_zh": "该论文针对Large Language Models (LLMs) 在推理服务中存在的first-come-first-serve (FCFS) 调度问题，导致head-of-line (HoL) blocking 和长响应时间，提出了一种高效框架ALISE。ALISE 通过speculative scheduler 估计每个任务的执行时间并动态分配优先级，以最小化队列延迟，同时采用priority-based adaptive memory management 和quantization-based compression 技术来降低内存开销。实验结果显示，与vLLM 相比，ALISE 在Alpaca 和ShareGPT 数据集上分别将吞吐量提高了高达1.8x 和2.1x，同时满足相同的延迟约束。",
      "categories": [
        "cs.PF",
        "cs.AI"
      ],
      "primary_category": "cs.PF",
      "comment": "ICCAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.23537v1",
      "published_date": "2024-10-31 00:58:11 UTC",
      "updated_date": "2024-10-31 00:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:50:32.366794"
    },
    {
      "arxiv_id": "2410.23535v1",
      "title": "Simulating User Agents for Embodied Conversational-AI",
      "title_zh": "模拟用户代理用于具身对话AI",
      "authors": [
        "Daniel Philipov",
        "Vardhan Dongre",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Embodied agents designed to assist users with tasks must engage in natural\nlanguage interactions, interpret instructions, execute actions, and communicate\neffectively to resolve issues. However, collecting large-scale, diverse\ndatasets of situated human-robot dialogues to train and evaluate such agents is\nexpensive, labor-intensive, and time-consuming. To address this challenge, we\npropose building a large language model (LLM)-based user agent that can\nsimulate user behavior during interactions with an embodied agent in a virtual\nenvironment. Given a user goal (e.g., make breakfast), at each time step, the\nuser agent may observe\" the robot actions or speak\" to either intervene with\nthe robot or answer questions. Such a user agent assists in improving the\nscalability and efficiency of embodied dialogues dataset generation and is\ncritical for enhancing and evaluating the robot's interaction and task\ncompletion ability, as well as for research in reinforcement learning using AI\nfeedback. We evaluate our user agent's ability to generate human-like behaviors\nby comparing its simulated dialogues with the TEACh dataset. We perform three\nexperiments: zero-shot prompting to predict dialogue acts, few-shot prompting,\nand fine-tuning on the TEACh training subset. Results show the LLM-based user\nagent achieves an F-measure of 42% with zero-shot prompting and 43.4% with\nfew-shot prompting in mimicking human speaking behavior. Through fine-tuning,\nperformance in deciding when to speak remained stable, while deciding what to\nsay improved from 51.1% to 62.5%. These findings showcase the feasibility of\nthe proposed approach for assessing and enhancing the effectiveness of robot\ntask completion through natural language communication.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型(LLM)的用户代理，用于模拟用户在虚拟环境中的行为，从而解决收集具身对话数据集的成本和效率问题。用户代理在给定用户目标（如制作早餐）时，能观察机器人动作或通过对话进行干预和回答，从而辅助提升机器人的交互能力、任务完成效率以及强化学习研究。实验通过与TEACh数据集比较，采用零样本提示、少样本提示和微调方法，结果显示F-measure从42%提升至43.4%，微调后“说什么”的性能从51.1%提高到62.5%，证明了这种方法在评估和增强机器人自然语言通信方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.23535v1",
      "published_date": "2024-10-31 00:56:08 UTC",
      "updated_date": "2024-10-31 00:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:50:45.676954"
    },
    {
      "arxiv_id": "2411.09709v1",
      "title": "Feature Selection via Dynamic Graph-based Attention Block in MI-based EEG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeon-Taek Han",
        "Dae-Hyeok Lee",
        "Heon-Gyu Kwak"
      ],
      "abstract": "Brain-computer interface (BCI) technology enables direct interaction between\nhumans and computers by analyzing brain signals. Electroencephalogram (EEG) is\none of the non-invasive tools used in BCI systems, providing high temporal\nresolution for real-time applications. However, EEG signals are often affected\nby a low signal-to-noise ratio, physiological artifacts, and individual\nvariability, representing challenges in extracting distinct features. Also,\nmotor imagery (MI)-based EEG signals could contain features with low\ncorrelation to MI characteristics, which might cause the weights of the deep\nmodel to become biased towards those features. To address these problems, we\nproposed the end-to-end deep preprocessing method that effectively enhances MI\ncharacteristics while attenuating features with low correlation to MI\ncharacteristics. The proposed method consisted of the temporal, spatial, graph,\nand similarity blocks to preprocess MI-based EEG signals, aiming to extract\nmore discriminative features and improve the robustness. We evaluated the\nproposed method using the public dataset 2a of BCI Competition IV to compare\nthe performances when integrating the proposed method into the conventional\nmodels, including the DeepConvNet, the M-ShallowConvNet, and the EEGNet. The\nexperimental results showed that the proposed method could achieve the improved\nperformances and lead to more clustered feature distributions of MI tasks.\nHence, we demonstrated that our proposed method could enhance discriminative\nfeatures related to MI characteristics.",
      "tldr_zh": "这篇论文针对脑机接口(BCI)中运动想象(MI)-based EEG 信号的特征选择问题，提出了一种端到端的深度预处理方法，以解决信号信噪比低、生理伪像和特征相关性弱等问题。该方法整合了 temporal、spatial、graph 和 similarity blocks，并利用 dynamic graph-based attention block 来增强 MI 特性、削弱无关特征，从而提取更具区分性的特征。在 BCI Competition IV 数据集 2a 上实验显示，该方法显著提高了 DeepConvNet、M-ShallowConvNet 和 EEGNet 等模型的性能，并使 MI 任务的特征分布更聚类。总的来说，该研究证明了该预处理方法在提升 EEG 信号鲁棒性和准确性方面的有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "4 pages, 2 figures, 1 table, Name of Conference: International\n  Conference on Brain-Computer Interface",
      "pdf_url": "http://arxiv.org/pdf/2411.09709v1",
      "published_date": "2024-10-31 00:53:29 UTC",
      "updated_date": "2024-10-31 00:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:52:50.178869"
    },
    {
      "arxiv_id": "2410.23530v2",
      "title": "There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Łukasz Staniszewski",
        "Łukasz Kuciński",
        "Kamil Deja"
      ],
      "abstract": "Diffusion Models achieve state-of-the-art performance in generating new\nsamples but lack low-dimensional latent space that encodes the data into\nmeaningful features. Inversion-based techniques try to solve this issue by\nreversing the denoising process and mapping images back to their approximated\nstarting noise. In this work, we thoroughly analyze this procedure and focus on\nthe relation between the initial Gaussian noise, the generated samples, and\ntheir corresponding latent encodings obtained through the DDIM inversion.\nFirst, we show that latents exhibit structural patterns in the form of less\ndiverse noise predicted for smooth image regions. Next, we explain the origin\nof this phenomenon, demonstrating that, during the first inversion steps, the\nnoise prediction error is much more significant for the plain areas than for\nthe rest of the image. Finally, we present the consequences of the divergence\nbetween latents and noises by showing that the space of image inversions is\nnotably less manipulative than the original Gaussian noise. This leads to a low\ndiversity of generated interpolations or editions based on the DDIM inversion\nprocedure and ill-defined latent-to-image mapping. Code is available at\nhttps://github.com/luk-st/taba.",
      "tldr_zh": "Diffusion Models 在生成样本方面表现出色，但缺乏有效的低维潜空间来编码数据特征。本文通过分析 DDIM inversion 过程，探讨了初始 Gaussian noise、生成样本及其潜编码之间的关系，揭示潜编码在图像平滑区域呈现结构性模式，且噪声预测错误在 inversion 前几步中更显著。研究进一步解释了这一现象的起源，并证明 inversion 空间不如原始 Gaussian noise 易于操作，导致基于 DDIM inversion 的图像插值和编辑多样性降低，以及潜编码到图像映射的不明确性。该工作为理解 Diffusion Models 的局限性提供了重要洞见，并提供了相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23530v2",
      "published_date": "2024-10-31 00:30:35 UTC",
      "updated_date": "2025-03-13 01:33:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:51:08.682592"
    },
    {
      "arxiv_id": "2411.05811v1",
      "title": "Neurophysiological Analysis in Motor and Sensory Cortices for Improving Motor Imagination",
      "title_zh": "针对改善运动想象的运动和感觉皮层神经生理分析",
      "authors": [
        "Si-Hyun Kim",
        "Sung-Jin Kim",
        "Dae-Hyeok Lee"
      ],
      "abstract": "Brain-computer interface (BCI) enables direct communication between the brain\nand external devices by decoding neural signals, offering potential solutions\nfor individuals with motor impairments. This study explores the neural\nsignatures of motor execution (ME) and motor imagery (MI) tasks using EEG\nsignals, focusing on four conditions categorized as sense-related (hot and\ncold) and motor-related (pull and push) conditions. We conducted scalp\ntopography analysis to examine activation patterns in the sensorimotor cortex,\nrevealing distinct regional differences: sense--related conditions primarily\nactivated the posterior region of the sensorimotor cortex, while motor--related\nconditions activated the anterior region of the sensorimotor cortex. These\nspatial distinctions align with neurophysiological principles, suggesting\ncondition-specific functional subdivisions within the sensorimotor cortex. We\nfurther evaluated the performances of three neural network models-EEGNet,\nShallowConvNet, and DeepConvNet-demonstrating that ME tasks achieved higher\nclassification accuracies compared to MI tasks. Specifically, in sense-related\nconditions, the highest accuracy was observed in the cold condition. In\nmotor-related conditions, the pull condition showed the highest performance,\nwith DeepConvNet yielding the highest results. These findings provide insights\ninto optimizing BCI applications by leveraging specific condition-induced\nneural activations.",
      "tldr_zh": "本研究使用 EEG 信号分析运动执行 (ME) 和运动想象 (MI) 任务的神经特征，聚焦于感官相关（hot 和 cold）和运动相关（pull 和 push）四种条件，通过头皮地形分析揭示了传感器imotor 皮层的区域差异：感官相关条件主要激活后部区域，而运动相关条件激活前部区域，与神经生理学原则一致。实验评估了 EEGNet、ShallowConvNet 和 DeepConvNet 三种神经网络模型，结果显示 ME 任务的分类准确率高于 MI 任务，其中 cold 条件和 pull 条件分别在感官相关和运动相关条件下表现出最高性能，且 DeepConvNet 整体表现最佳。这些发现为优化 BCI 应用提供了见解，通过利用特定条件的神经激活来提升运动想象效果。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "4 pages, 3 figures, 1 table, Name of Conference: International Winter\n  Conference on Brain-Computer Interface",
      "pdf_url": "http://arxiv.org/pdf/2411.05811v1",
      "published_date": "2024-10-31 00:18:41 UTC",
      "updated_date": "2024-10-31 00:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:51:20.970361"
    },
    {
      "arxiv_id": "2410.23526v1",
      "title": "LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hieu Tran",
        "Junda Wang",
        "Yujan Ting",
        "Weijing Huang",
        "Terrence Chen"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks, yet they often struggle with maintaining\nfactual accuracy, particularly in knowledge-intensive domains like healthcare.\nThis study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,\na novel approach designed to enhance the factual reliability of LLMs, with a\nfocus on medical question answering (QA). LEAF utilizes a dual strategy to\nenhance the factual accuracy of responses from models such as Llama 3 70B\nInstruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,\nimproves Retrieval-Augmented Generation (RAG) by incorporating fact-checking\nresults to guide the retrieval process without updating model parameters. The\nsecond strategy, Learning from Fact-Checks via Self-Training, involves\nsupervised fine-tuning (SFT) on fact-checked responses or applying Simple\nPreference Optimization (SimPO) with fact-checking as a ranking mechanism, both\nupdating LLM parameters from supervision. These findings suggest that\nintegrating fact-checked responses whether through RAG enhancement or\nself-training enhances the reliability and factual correctness of LLM outputs,\noffering a promising solution for applications where information accuracy is\ncrucial.",
      "tldr_zh": "该研究提出LEAF框架，通过事实检查增强学习和评估，以提升大型语言模型(LLMs)在知识密集型任务（如医疗问答QA）中的事实准确性。LEAF采用双重策略：Fact-Check-Then-RAG先进行事实检查来指导检索增强生成(RAG)过程，而不更新模型参数；Learning from Fact-Checks via Self-Training则通过监督微调(SFT)或Simple Preference Optimization (SimPO)利用事实检查结果更新LLMs参数，如Llama 3 70B Instruct和Llama 3 8B Instruct。实验结果显示，这种整合方法显著提高了LLMs输出的可靠性和事实正确性，为需要高准确性的应用领域提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.23526v1",
      "published_date": "2024-10-31 00:18:05 UTC",
      "updated_date": "2024-10-31 00:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T19:51:33.495809"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 137,
  "processed_papers_count": 137,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T19:53:13.813829"
}