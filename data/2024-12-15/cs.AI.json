{
  "date": "2024-12-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-15 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 和机器学习领域的创新应用，包括 LLM 在符号回归、药物发现和场景理解中的潜力，以及高效的神经网络优化和医疗图像处理方法；重点文章有 \"Data Laundering\" 揭示 LLM 基准操纵风险，以及 \"SceneLLM\" 用于动态场景图生成；令人印象深刻的还包括知名作者如 David Brooks 参与的 \"Nanoscaling Floating-Point\"，这些工作推动了 LLM 效率和实际应用。\n\n下面，我挑选了今天几篇重要、话题度高的论文进行简要讨论，先从 AI 和 LLM 相关主题入手，再聊医疗和机器人领域。其他论文如一些纯技术优化或小众主题（如特定算法比较），我将快速掠过，以控制篇幅。\n\n### AI 和 LLM 创新应用\n- **Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation**（数据清洗：通过知识蒸馏人为提升基准结果）  \n  这篇论文揭示了知识蒸馏可能被滥用来操纵 LLM 基准分数，导致基准测试失真；主要贡献是提出三阶段“数据清洗”过程，实验显示可提升基准准确率达 75%，但警告了 AI 评估的潜在风险，值得关注 LLM 诚信问题。\n\n- **SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**（SceneLLM：LLM 用于动态场景图生成的隐式语言推理）  \n  论文提出 SceneLLM 框架，利用 LLM 进行动态场景理解，生成语义三元组（如<主语-谓语-宾语>）；主要发现是通过 Video-to-Language 映射和最优传输算法，提升了机器人场景解析的准确性和鲁棒性，在 AG 数据集上达到 SOTA 性能。\n\n- **AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance**（AgentPS：多模态内容质量保证的多代理过程监督）  \n  作者使用 LLM 驱动的多代理系统，确保多模态内容的质量；关键贡献是通过多轮 QA 细化内容，实验在 TikTok 数据集上提升了分类性能，展示了 LLM 在工业应用的潜力。\n\n- **Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling**（纳米级浮点数：NanoMantissa、自适应微指数和代码重用）  \n  由 David Brooks 等知名学者撰写，针对 LLM 的内存挑战，提出 NxFP 技术；主要发现是通过纳米级优化，提升了 LLM 在 MMLU 基准上的准确率达 30%，并减少内存占用 16%，对高效 AI 部署有重要启发。\n\n- **TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**（TrimLLM：针对领域特定 LLM 的渐进层丢弃）  \n  论文引入层级丢弃机制，压缩 LLM 模型；核心贡献是实现 2.1-5.7 倍推理加速，同时保持领域性能（如医疗和法律任务），无需硬件依赖，是 LLM 部署的实用优化。\n\n其他 LLM 相关论文如 \"LitLLMs\"（用于文献综述的 LLM）和 \"LAW\"（法律合同分析框架），快速提一下，它们探索 LLM 在特定任务的扩展，但实验结果中等，未见突破性进展。\n\n### 医疗和图像处理\n- **J-Net: Detecting Daily Living Gait Amid Huntington's Disease**（J-Net：检测亨廷顿病日常步态）  \n  论文开发 J-Net 模型，使用预训练的自监督网络检测神经退行性疾病步态；主要贡献是通过加速度计数据提升检测准确率 10%，并公开数据集，适用于 Parkinson 等疾病，对医疗 AI 有实际价值。\n\n- **VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping**（VividFace：基于扩散的高保真视频面部交换框架）  \n  这是首篇针对视频面部交换的扩散模型框架；关键发现是通过图像-视频混合训练和 3D 重建，显著改善身份保持和时间一致性，实验显示在复杂场景下性能领先。\n\n- **Macro2Micro: Cross-modal Magnetic Resonance Imaging Synthesis**（Macro2Micro：利用多尺度脑结构的多模态 MRI 合成）  \n  论文提出 Macro2Micro 框架，使用 GAN 生成脑微结构图像；主要贡献是通过多尺度表示提升 MRI 合成质量，SSIM 指标提高 6.8%，有助于降低医疗成像成本。\n\n### 机器人和动态计算\n- **Uni-AdaFocus: Spatial-temporal Dynamic Computation for Video Recognition**（Uni-AdaFocus：视频识别的空间-时间动态计算）  \n  作者开发 Uni-AdaFocus，提升视频识别效率；核心发现是通过自适应策略和图神经网络，减少冗余计算，在多个数据集上加速 2-3 倍，同时保持高准确率。\n\n其他机器人论文如 \"Modality-Driven Design for Multi-Step Dexterous Manipulation\"（基于神经科学的机器人灵巧操作设计），快速掠过，它借鉴神经科学分解任务，但实验仅在简单场景验证，未见大规模应用。\n\n今天其他论文如 \"An Empirical Study of Fault Localisation Techniques\"（深度学习故障定位技术研究）和 \"A Comparative Study on Dynamic Graph Embedding\"（动态图嵌入比较），这些更偏向基础实验，贡献局限于特定基准上的小幅提升，我就不详细展开了。总之，今天 arXiv 展示了 AI 领域的活跃创新，尤其在 LLM 应用上，但需警惕潜在风险。期待明天更多深度洞见！",
  "papers": [
    {
      "arxiv_id": "2412.12215v1",
      "title": "Imagined Speech State Classification for Robust Brain-Computer Interface",
      "title_zh": "翻译失败",
      "authors": [
        "Byung-Kwan Ko",
        "Jun-Young Kim",
        "Seo-Hyun Lee"
      ],
      "abstract": "This study examines the effectiveness of traditional machine learning\nclassifiers versus deep learning models for detecting the imagined speech using\nelectroencephalogram data. Specifically, we evaluated conventional machine\nlearning techniques such as CSP-SVM and LDA-SVM classifiers alongside deep\nlearning architectures such as EEGNet, ShallowConvNet, and DeepConvNet. Machine\nlearning classifiers exhibited significantly lower precision and recall,\nindicating limited feature extraction capabilities and poor generalization\nbetween imagined speech and idle states. In contrast, deep learning models,\nparticularly EEGNet, achieved the highest accuracy of 0.7080 and an F1 score of\n0.6718, demonstrating their enhanced ability in automatic feature extraction\nand representation learning, essential for capturing complex neurophysiological\npatterns. These findings highlight the limitations of conventional machine\nlearning approaches in brain-computer interface (BCI) applications and advocate\nfor adopting deep learning methodologies to achieve more precise and reliable\nclassification of detecting imagined speech. This foundational research\ncontributes to the development of imagined speech-based BCI systems.",
      "tldr_zh": "本研究比较了传统机器学习分类器（如 CSP-SVM 和 LDA-SVM）与深度学习模型（如 EEGNet、ShallowConvNet 和 DeepConvNet）在检测想象语音（imagined speech）时的表现，使用脑电图（electroencephalogram）数据。结果显示，传统机器学习分类器精确度和召回率较低，特征提取能力有限，且在想象语音和空闲状态之间泛化能力较差。相比之下，EEGNet 等深度学习模型取得了最高的准确率（0.7080）和 F1 分数（0.6718），展示了其在自动特征提取和表示学习方面的优势。这些发现突出了传统机器学习在脑机接口（BCI）应用中的局限性，并为基于想象语音的 BCI 系统的发展提供了重要基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12215v1",
      "published_date": "2024-12-15 23:59:55 UTC",
      "updated_date": "2024-12-15 23:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:51:54.412906"
    },
    {
      "arxiv_id": "2412.11337v1",
      "title": "Modality-Driven Design for Multi-Step Dexterous Manipulation: Insights from Neuroscience",
      "title_zh": "翻译失败",
      "authors": [
        "Naoki Wake",
        "Atsushi Kanehira",
        "Daichi Saito",
        "Jun Takamatsu",
        "Kazuhiro Sasabuchi",
        "Hideki Koike",
        "Katsushi Ikeuchi"
      ],
      "abstract": "Multi-step dexterous manipulation is a fundamental skill in household\nscenarios, yet remains an underexplored area in robotics. This paper proposes a\nmodular approach, where each step of the manipulation process is addressed with\ndedicated policies based on effective modality input, rather than relying on a\nsingle end-to-end model. To demonstrate this, a dexterous robotic hand performs\na manipulation task involving picking up and rotating a box. Guided by insights\nfrom neuroscience, the task is decomposed into three sub-skills, 1)reaching,\n2)grasping and lifting, and 3)in-hand rotation, based on the dominant sensory\nmodalities employed in the human brain. Each sub-skill is addressed using\ndistinct methods from a practical perspective: a classical controller, a\nVision-Language-Action model, and a reinforcement learning policy with force\nfeedback, respectively. We tested the pipeline on a real robot to demonstrate\nthe feasibility of our approach. The key contribution of this study lies in\npresenting a neuroscience-inspired, modality-driven methodology for multi-step\ndexterous manipulation.",
      "tldr_zh": "这篇论文提出了一种模块化方法，用于多-step dexterous manipulation，借鉴neuroscience的洞见，将任务分解为专用政策和模式输入，而不是依赖单一end-to-end模型。针对机器人手拾取并旋转盒子的任务，该方法将操作分为三个子技能：1) reaching（到达），2) grasping and lifting（抓取和抬起），以及3) in-hand rotation（手内旋转）。每个子技能采用不同的方法，包括经典控制器、Vision-Language-Action模型和reinforcement learning策略（带力反馈）。实验在真实机器人上验证了该方法的feasibility，主要贡献在于提供一种neuroscience启发的模式驱动设计，提升多步灵巧操作的效率和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures, 2 tables. Last updated on December 14th, 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.11337v1",
      "published_date": "2024-12-15 23:05:16 UTC",
      "updated_date": "2024-12-15 23:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:52:07.375801"
    },
    {
      "arxiv_id": "2412.11333v1",
      "title": "Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaochen Zhu",
        "Georgi Karadzhov",
        "Chenxi Whitehouse",
        "Andreas Vlachos"
      ],
      "abstract": "Diffusion models have shown promise in text generation but often struggle\nwith generating long, coherent, and contextually accurate text. Token-level\ndiffusion overlooks word-order dependencies and enforces short output windows,\nwhile passage-level diffusion struggles with learning robust representation for\nlong-form text. To address these challenges, we propose Segment-Level Diffusion\n(SLD), a framework that enhances diffusion-based text generation through text\nsegmentation, robust representation training with adversarial and contrastive\nlearning, and improved latent-space guidance. By segmenting long-form outputs\ninto separate latent representations and decoding them with an autoregressive\ndecoder, SLD simplifies diffusion predictions and improves scalability.\nExperiments on XSum, ROCStories, DialogSum, and DeliData demonstrate that SLD\nachieves competitive or superior performance in fluency, coherence, and\ncontextual compatibility across automatic and human evaluation metrics\ncomparing with other diffusion and autoregressive baselines. Ablation studies\nfurther validate the effectiveness of our segmentation and representation\nlearning strategies.",
      "tldr_zh": "本研究针对扩散模型（diffusion models）在文本生成中的挑战，如难以产生长、连贯且上下文准确的文本，提出了Segment-Level Diffusion (SLD)框架，以提升长文本生成的控制性和可扩展性。SLD通过文本分割成独立的潜在表示、结合对抗学习（adversarial learning）和对比学习（contrastive learning）进行鲁棒表示训练，以及改进的潜在空间指导（latent-space guidance），并使用自回归解码器进行解码，从而简化预测过程并处理词序依赖问题。在XSum、ROCStories、DialogSum和DeliData数据集上的实验显示，SLD在流畅性、一致性和上下文兼容性方面优于其他扩散和自回归基线模型。消融研究进一步证实了文本分割和表示学习策略的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11333v1",
      "published_date": "2024-12-15 22:47:44 UTC",
      "updated_date": "2024-12-15 22:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:52:18.909385"
    },
    {
      "arxiv_id": "2412.19821v1",
      "title": "Nanoscaling Floating-Point (NxFP): NanoMantissa, Adaptive Microexponents, and Code Recycling for Direct-Cast Compression of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yun-Chen Lo",
        "Gu-Yeon Wei",
        "David Brooks"
      ],
      "abstract": "As cutting-edge large language models (LLMs) continue to transform various\nindustries, their fast-growing model size and sequence length have led to\nmemory traffic and capacity challenges. Recently, AMD, Arm, Intel, Meta,\nMicrosoft, NVIDIA, and Qualcomm have proposed a Microscaling standard (Mx),\nwhich augments block floating-point with microexponents to achieve promising\nperplexity-to-footprint trade-offs. However, the Microscaling suffers from\nsignificant perplexity degradation on modern LLMs with less than six bits. This\npaper profiles modern LLMs and identifies three main challenges of low-bit\nMicroscaling format, i.e., inaccurate tracking of outliers, vacant quantization\nlevels, and wasted binary code. In response, Nanoscaling (NxFP) proposes three\ntechniques, i.e., NanoMantissa, Adaptive Microexponent, and Code Recycling to\nenable better accuracy and smaller memory footprint than state-of-the-art MxFP.\nExperimental results on direct-cast inference across various modern LLMs\ndemonstrate that our proposed methods outperform state-of-the-art MxFP by up to\n0.64 in perplexity and by up to 30% in accuracy on MMLU benchmarks.\nFurthermore, NxFP reduces memory footprint by up to 16% while achieving\ncomparable perplexity as MxFP.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）的内存容量和流量挑战，提出Nanoscaling Floating-Point (NxFP)框架，以解决低位Microscaling (Mx)格式的不足，包括不准确跟踪异常值、浪费量化级别和二进制代码浪费。NxFP引入三个关键技术：NanoMantissa用于优化尾数表示、Adaptive Microexponent动态调整指数范围，以及Code Recycling重用二进制代码，以实现更高的准确性和更小的内存占用。实验结果显示，NxFP在各种现代LLMs的直接转换推理中，比MxFP降低高达0.64的perplexity，提高高达30%的MMLU基准准确率，并减少高达16%的内存占用，同时保持可比的perplexity水平。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "I.2.7; E.4"
      ],
      "primary_category": "cs.AR",
      "comment": "12 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19821v1",
      "published_date": "2024-12-15 22:18:20 UTC",
      "updated_date": "2024-12-15 22:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:52:30.493712"
    },
    {
      "arxiv_id": "2412.12212v1",
      "title": "Finding a Wolf in Sheep's Clothing: Combating Adversarial Text-To-Image Prompts with Text Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Portia Cooper",
        "Harshita Narnoli",
        "Mihai Surdeanu"
      ],
      "abstract": "Text-to-image models are vulnerable to the stepwise \"Divide-and-Conquer\nAttack\" (DACA) that utilize a large language model to obfuscate inappropriate\ncontent in prompts by wrapping sensitive text in a benign narrative. To\nmitigate stepwise DACA attacks, we propose a two-layer method involving text\nsummarization followed by binary classification. We assembled the Adversarial\nText-to-Image Prompt (ATTIP) dataset ($N=940$), which contained DACA-obfuscated\nand non-obfuscated prompts. From the ATTIP dataset, we created two summarized\nversions: one generated by a small encoder model and the other by a large\nlanguage model. Then, we used an encoder classifier and a GPT-4o classifier to\nperform content moderation on the summarized and unsummarized prompts. When\ncompared with a classifier that operated over the unsummarized data, our method\nimproved F1 score performance by 31%. Further, the highest recorded F1 score\nachieved (98%) was produced by the encoder classifier on a summarized ATTIP\nvariant. This study indicates that pre-classification text summarization can\ninoculate content detection models against stepwise DACA obfuscations.",
      "tldr_zh": "该研究针对文本到图像模型面临的逐步“Divide-and-Conquer Attack”(DACA)攻击，提出了一种两层防御方法：先通过文本总结简化提示内容，然后进行二元分类，以识别隐藏的不适当信息。研究者构建了Adversarial Text-to-Image Prompt (ATTIP)数据集（N=940），包含DACA隐藏和非隐藏的提示，并生成两种总结版本（由小编码器模型和大语言模型创建）。实验结果显示，与直接分类相比，该方法将F1 score提高了31%，最高达到98%，证明预分类文本总结能有效增强内容检测模型对DACA攻击的抵抗力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12212v1",
      "published_date": "2024-12-15 22:12:36 UTC",
      "updated_date": "2024-12-15 22:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:52:42.722617"
    },
    {
      "arxiv_id": "2412.11318v1",
      "title": "Generics are puzzling. Can language models find the missing piece?",
      "title_zh": "翻译失败",
      "authors": [
        "Gustavo Cilleruelo Calderón",
        "Emily Allaway",
        "Barry Haddow",
        "Alexandra Birch"
      ],
      "abstract": "Generic sentences express generalisations about the world without explicit\nquantification. Although generics are central to everyday communication,\nbuilding a precise semantic framework has proven difficult, in part because\nspeakers use generics to generalise properties with widely different\nstatistical prevalence. In this work, we study the implicit quantification and\ncontext-sensitivity of generics by leveraging language models as models of\nlanguage. We create ConGen, a dataset of 2873 naturally occurring generic and\nquantified sentences in context, and define p-acceptability, a metric based on\nsurprisal that is sensitive to quantification. Our experiments show generics\nare more context-sensitive than determiner quantifiers and about 20% of\nnaturally occurring generics we analyze express weak generalisations. We also\nexplore how human biases in stereotypes can be observed in language models.",
      "tldr_zh": "这篇论文探讨了泛化句(generics)的语义挑战，即它们表达世界的一般化但缺乏明确量化，并使用语言模型来研究其隐式量化(implicit quantification)和上下文敏感性(context-sensitivity)。研究者创建了ConGen数据集，包含2873个自然发生的泛化和量化句子，并定义了基于surprisal的p-acceptability度量来评估量化敏感性。实验发现，泛化句比限定词量化器更依赖上下文，大约20%的自然泛化句表达弱泛化，同时语言模型中观察到人类刻板印象(stereotypes)偏见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at CoLing 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11318v1",
      "published_date": "2024-12-15 21:30:21 UTC",
      "updated_date": "2024-12-15 21:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:52:54.667169"
    },
    {
      "arxiv_id": "2412.11304v2",
      "title": "An Empirical Study of Fault Localisation Techniques for Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nargiz Humbatova",
        "Jinhan Kim",
        "Gunel Jahangirova",
        "Shin Yoo",
        "Paolo Tonella"
      ],
      "abstract": "With the increased popularity of Deep Neural Networks (DNNs), increases also\nthe need for tools to assist developers in the DNN implementation, testing and\ndebugging process. Several approaches have been proposed that automatically\nanalyse and localise potential faults in DNNs under test. In this work, we\nevaluate and compare existing state-of-the-art fault localisation techniques,\nwhich operate based on both dynamic and static analysis of the DNN. The\nevaluation is performed on a benchmark consisting of both real faults obtained\nfrom bug reporting platforms and faulty models produced by a mutation tool. Our\nfindings indicate that the usage of a single, specific ground truth (e.g., the\nhuman defined one) for the evaluation of DNN fault localisation tools results\nin pretty low performance (maximum average recall of 0.31 and precision of\n0.23). However, such figures increase when considering alternative, equivalent\npatches that exist for a given faulty DNN. Results indicate that \\dfd is the\nmost effective tool, achieving an average recall of 0.61 and precision of 0.41\non our benchmark.",
      "tldr_zh": "这篇论文对深度学习(DNN)中的故障定位技术进行了实证研究，评估了基于动态和静态分析的现有状态-of-the-art方法。研究使用一个基准测试集，包括从bug报告平台获取的真实故障和由突变工具生成的故障模型。结果表明，使用单一ground truth评估这些工具会导致低性能（平均recall为0.31和precision为0.23），但考虑等效补丁时性能显著提升；其中\\dfd工具是最有效的，平均recall达0.61和precision达0.41。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11304v2",
      "published_date": "2024-12-15 20:47:03 UTC",
      "updated_date": "2024-12-17 10:07:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:53:06.160957"
    },
    {
      "arxiv_id": "2412.11301v1",
      "title": "Semi-Implicit Neural Ordinary Differential Equations",
      "title_zh": "半隐式神经常微分方程",
      "authors": [
        "Hong Zhang",
        "Ying Liu",
        "Romit Maulik"
      ],
      "abstract": "Classical neural ODEs trained with explicit methods are intrinsically limited\nby stability, crippling their efficiency and robustness for stiff learning\nproblems that are common in graph learning and scientific machine learning. We\npresent a semi-implicit neural ODE approach that exploits the partitionable\nstructure of the underlying dynamics. Our technique leads to an implicit neural\nnetwork with significant computational advantages over existing approaches\nbecause of enhanced stability and efficient linear solves during time\nintegration. We show that our approach outperforms existing approaches on a\nvariety of applications including graph classification and learning complex\ndynamical systems. We also demonstrate that our approach can train challenging\nneural ODEs where both explicit methods and fully implicit methods are\nintractable.",
      "tldr_zh": "这篇论文针对经典神经ODEs在使用显式方法训练时的稳定性问题，提出了一种半隐式神经ODE方法，利用底层动态的可分区结构来提升效率和鲁棒性。该方法通过隐式神经网络和高效线性求解器在时间积分过程中实现计算优势，并在图分类和复杂动态系统学习等应用中表现出色，优于现有方法。此外，该方法能够成功训练那些显式或完全隐式方法无法处理的挑战性神经ODEs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "K.3.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11301v1",
      "published_date": "2024-12-15 20:21:02 UTC",
      "updated_date": "2024-12-15 20:21:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:53:17.644683"
    },
    {
      "arxiv_id": "2412.11293v2",
      "title": "A Comparative Study on Dynamic Graph Embedding based on Mamba and Transformers",
      "title_zh": "基于 Mamba 和 Transformers 的动态图嵌入比较研究",
      "authors": [
        "Ashish Parmanand Pandey",
        "Alan John Varghese",
        "Sarang Patil",
        "Mengjia Xu"
      ],
      "abstract": "Dynamic graph embedding has emerged as an important technique for modeling\ncomplex time-evolving networks across diverse domains. While transformer-based\nmodels have shown promise in capturing long-range dependencies in temporal\ngraph data, they face scalability challenges due to quadratic computational\ncomplexity. This study presents a comparative analysis of dynamic graph\nembedding approaches using transformers and the recently proposed Mamba\narchitecture, a state-space model with linear complexity. We introduce three\nnovel models: TransformerG2G augment with graph convolutional networks,\n\\mathcal{DG}-Mamba, and \\mathcal{GDG}-Mamba with graph isomorphism network edge\nconvolutions. Our experiments on multiple benchmark datasets demonstrate that\nMamba-based models achieve comparable or superior performance to\ntransformer-based approaches in link prediction tasks while offering\nsignificant computational efficiency gains on longer sequences. Notably,\n\\mathcal{DG}-Mamba variants consistently outperform transformer-based models on\ndatasets with high temporal variability, such as UCI, Bitcoin, and Reality\nMining, while maintaining competitive performance on more stable graphs like\nSBM. We provide insights into the learned temporal dependencies through\nanalysis of attention weights and state matrices, revealing the models' ability\nto capture complex temporal patterns. By effectively combining state-space\nmodels with graph neural networks, our work addresses key limitations of\nprevious approaches and contributes to the growing body of research on\nefficient temporal graph representation learning. These findings offer\npromising directions for scaling dynamic graph embedding to larger, more\ncomplex real-world networks, potentially enabling new applications in areas\nsuch as social network analysis, financial modeling, and biological system\ndynamics.",
      "tldr_zh": "本研究比较了基于 Transformers 和 Mamba 的动态 graph embedding 方法，旨在解决时间演化网络建模中的长期依赖性和计算可扩展性问题。论文引入了三个新模型：TransformerG2G（增强了 graph convolutional networks）、\\(\\mathcal{DG}\\)-Mamba 和 \\(\\mathcal{GDG}\\)-Mamba（结合 graph isomorphism network edge convolutions）。实验结果显示，Mamba-based 模型在多个基准数据集（如 UCI、Bitcoin 和 Reality Mining）上的链接预测任务中，性能相当或优于 Transformers-based 模型，同时显著提高了计算效率。通过分析注意力权重和状态矩阵，该工作揭示了模型捕捉复杂时间模式的潜力，并为高效的动态 graph embedding 应用（如社交网络分析和金融建模）提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11293v2",
      "published_date": "2024-12-15 19:56:56 UTC",
      "updated_date": "2025-05-12 17:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:53:33.690684"
    },
    {
      "arxiv_id": "2412.15255v1",
      "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation",
      "title_zh": "数据洗钱：通过知识蒸馏人为提升基准测试结果",
      "authors": [
        "Jonibek Mansurov",
        "Akhmed Sakip",
        "Alham Fikri Aji"
      ],
      "abstract": "In this paper, we show that knowledge distillation can be subverted to\nmanipulate language model benchmark scores, revealing a critical vulnerability\nin current evaluation practices. We introduce \"Data Laundering,\" a three-phase\nprocess analogous to financial money laundering, that enables the covert\ntransfer of benchmark-specific knowledge through seemingly legitimate\nintermediate training steps. Through extensive experiments with a 2-layer BERT\nstudent model, we show how this approach can achieve substantial improvements\nin benchmark accuracy (up to 75\\% on GPQA) without developing genuine reasoning\ncapabilities. Notably, this method can be exploited intentionally or even\nunintentionally, as researchers may inadvertently adopt this method that\ninflates scores using knowledge distillation without realizing the\nimplications. While our findings demonstrate the effectiveness of this\ntechnique, we present them as a cautionary tale highlighting the urgent need\nfor more robust evaluation methods in AI. This work aims to contribute to the\nongoing discussion about evaluation integrity in AI development and the need\nfor benchmarks that more accurately reflect true model capabilities. The code\nis available at \\url{https://github.com/mbzuai-nlp/data_laundering}.",
      "tldr_zh": "本研究揭示了知识蒸馏（knowledge distillation）被滥用来操纵语言模型基准测试分数的问题，引入了“Data Laundering”概念，这是一种三阶段过程，类似于金融洗钱，通过看似合法的中间训练步骤秘密转移基准特定知识。实验使用2层BERT学生模型显示，这种方法可在不提升真实推理能力的情况下显著提高基准准确率（如GPQA上达75%）。作者强调，此技术可能有意或无意发生，凸显了当前AI评估实践的漏洞，并呼吁开发更稳健的评估方法，以确保基准更准确地反映模型真实能力。代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.15255v1",
      "published_date": "2024-12-15 19:38:48 UTC",
      "updated_date": "2024-12-15 19:38:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:53:41.538927"
    },
    {
      "arxiv_id": "2412.11286v1",
      "title": "Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Dafna Schwartz",
        "Lori Quinn",
        "Nora E. Fritz",
        "Lisa M. Muratori",
        "Jeffery M. Hausdorff",
        "Ran Gilad Bachrach"
      ],
      "abstract": "Wearable sensors offer a non-invasive way to collect physical activity (PA)\ndata, with walking as a key component. Existing models often struggle to detect\ngait bouts in individuals with neurodegenerative diseases (NDDs) involving\ninvoluntary movements. We developed J-Net, a deep learning model inspired by\nU-Net, which uses a pre-trained self-supervised foundation model fine-tuned\nwith Huntington`s disease (HD) in-lab data and paired with a segmentation head\nfor gait detection. J-Net processes wrist-worn accelerometer data to detect\ngait during daily living. We evaluated J-Net on in-lab and daily-living data\nfrom HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage\npoint improvement in ROC-AUC for HD over existing methods, reaching 0.97 for\nin-lab data. In daily-living environments, J-Net estimates showed no\nsignificant differences in median daily walking time between HD and controls (p\n= 0.23), in contrast to other models, which indicated counterintuitive results\n(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS\nclinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.\nFine-tuning J-Net on PD data also improved gait detection over current methods.\nJ-Net`s architecture effectively addresses the challenges of gait detection in\nsevere chorea and offers robust performance in daily living. The dataset and\nJ-Net model are publicly available, providing a resource for further research\ninto NDD-related gait impairments.",
      "tldr_zh": "本研究开发了 J-Net，一种基于 U-Net 启发的深度学习模型，用于检测亨廷顿病 (HD) 患者在舞蹈病影响下的日常生活步态，模型通过预训练的自监督基础模型微调并结合分割头处理手腕加速度计数据。实验结果显示，J-Net 在 HD 的实验室数据上将 ROC-AUC 提高了 10 个百分点，达到 0.97，并在日常生活数据中显示 HD 患者与对照组的每日步行时间中位数无显著差异 (p=0.23)，而步行时间与 UHDRS-TMS 临床严重性评分呈负相关 (r=-0.52; p=0.02)。此外，J-Net 在帕金森病 (PD) 数据上微调后也提升了性能，并公开了数据集和模型，为神经退行性疾病 (NDDs) 相关步态损伤研究提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11286v1",
      "published_date": "2024-12-15 19:19:39 UTC",
      "updated_date": "2024-12-15 19:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:53:55.999159"
    },
    {
      "arxiv_id": "2412.11279v1",
      "title": "VividFace: A Diffusion-Based Hybrid Framework for High-Fidelity Video Face Swapping",
      "title_zh": "VividFace：一种基于扩散的混合框架，用于高保真度视频人脸交换",
      "authors": [
        "Hao Shao",
        "Shulun Wang",
        "Yang Zhou",
        "Guanglu Song",
        "Dailan He",
        "Shuo Qin",
        "Zhuofan Zong",
        "Bingqi Ma",
        "Yu Liu",
        "Hongsheng Li"
      ],
      "abstract": "Video face swapping is becoming increasingly popular across various\napplications, yet existing methods primarily focus on static images and\nstruggle with video face swapping because of temporal consistency and complex\nscenarios. In this paper, we present the first diffusion-based framework\nspecifically designed for video face swapping. Our approach introduces a novel\nimage-video hybrid training framework that leverages both abundant static image\ndata and temporal video sequences, addressing the inherent limitations of\nvideo-only training. The framework incorporates a specially designed diffusion\nmodel coupled with a VidFaceVAE that effectively processes both types of data\nto better maintain temporal coherence of the generated videos. To further\ndisentangle identity and pose features, we construct the Attribute-Identity\nDisentanglement Triplet (AIDT) Dataset, where each triplet has three face\nimages, with two images sharing the same pose and two sharing the same\nidentity. Enhanced with a comprehensive occlusion augmentation, this dataset\nalso improves robustness against occlusions. Additionally, we integrate 3D\nreconstruction techniques as input conditioning to our network for handling\nlarge pose variations. Extensive experiments demonstrate that our framework\nachieves superior performance in identity preservation, temporal consistency,\nand visual quality compared to existing methods, while requiring fewer\ninference steps. Our approach effectively mitigates key challenges in video\nface swapping, including temporal flickering, identity preservation, and\nrobustness to occlusions and pose variations.",
      "tldr_zh": "本文提出VividFace，一种基于diffusion的混合框架，用于实现高保真度的视频面部交换，首次解决现有方法在时间一致性和复杂场景中的局限性。该框架采用图像-视频混合训练策略，利用静态图像数据和视频序列，并结合专门设计的diffusion模型和VidFaceVAE，以确保生成的视频保持时间连贯性；同时构建了AIDT Dataset和遮挡增强技术，以分离身份和姿势特征，并提升对遮挡的鲁棒性；此外，整合3D重建作为输入条件来处理大姿势变化。实验结果显示，该框架在身份保留、时间一致性和视觉质量方面优于现有方法，且推理步骤更少，有效缓解了视频面部交换中的关键挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://hao-shao.com/projects/vividface.html",
      "pdf_url": "http://arxiv.org/pdf/2412.11279v1",
      "published_date": "2024-12-15 18:58:32 UTC",
      "updated_date": "2024-12-15 18:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:54:06.923736"
    },
    {
      "arxiv_id": "2412.11277v1",
      "title": "Macro2Micro: Cross-modal Magnetic Resonance Imaging Synthesis Leveraging Multi-scale Brain Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Sooyoung Kim",
        "Joonwoo Kwon",
        "Junbeom Kwon",
        "Sangyoon Bae",
        "Yuewei Lin",
        "Shinjae Yoo",
        "Jiook Cha"
      ],
      "abstract": "Spanning multiple scales-from macroscopic anatomy down to intricate\nmicroscopic architecture-the human brain exemplifies a complex system that\ndemands integrated approaches to fully understand its complexity. Yet, mapping\nnonlinear relationships between these scales remains challenging due to\ntechnical limitations and the high cost of multimodal Magnetic Resonance\nImaging (MRI) acquisition. Here, we introduce Macro2Micro, a deep learning\nframework that predicts brain microstructure from macrostructure using a\nGenerative Adversarial Network (GAN). Grounded in the scale-free, self-similar\nnature of brain organization-where microscale information can be inferred from\nmacroscale patterns-Macro2Micro explicitly encodes multiscale brain\nrepresentations into distinct processing branches. To further enhance image\nfidelity and suppress artifacts, we propose a simple yet effective auxiliary\ndiscriminator and learning objective. Our results show that Macro2Micro\nfaithfully translates T1-weighted MRIs into corresponding Fractional Anisotropy\n(FA) images, achieving a 6.8% improvement in the Structural Similarity Index\nMeasure (SSIM) compared to previous methods, while preserving the individual\nneurobiological characteristics.",
      "tldr_zh": "这篇论文提出了 Macro2Micro 框架，一种利用多尺度脑结构进行跨模态磁共振成像 (MRI) 合成的深度学习方法，旨在从脑宏观解剖预测微观结构，以克服多模态 MRI 获取的高成本和技术挑战。框架基于脑组织的规模无关和自相似特性，使用 Generative Adversarial Network (GAN) 将多尺度脑表示编码到不同的处理分支中，并引入辅助鉴别器和学习目标来提升图像保真度并抑制伪影。结果显示，Macro2Micro 成功地将 T1 加权 MRI 转化为 Fractional Anisotropy (FA) 图像，Structural Similarity Index Measure (SSIM) 比之前方法提高了 6.8%，同时保留了个体神经生物学特征。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "The code will be made available upon acceptance",
      "pdf_url": "http://arxiv.org/pdf/2412.11277v1",
      "published_date": "2024-12-15 18:49:20 UTC",
      "updated_date": "2024-12-15 18:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:54:18.730747"
    },
    {
      "arxiv_id": "2412.11276v2",
      "title": "Wearable Accelerometer Foundation Models for Health via Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Salar Abbaspourazad",
        "Anshuman Mishra",
        "Joseph Futoma",
        "Andrew C. Miller",
        "Ian Shapiro"
      ],
      "abstract": "Modern wearable devices can conveniently record various biosignals in the\nmany different environments of daily living, enabling a rich view of individual\nhealth. However, not all biosignals are the same: high-fidelity biosignals,\nsuch as photoplethysmogram (PPG), contain more physiological information, but\nrequire optical sensors with a high power footprint. Alternatively, a\nlower-fidelity biosignal such as accelerometry has a significantly smaller\npower footprint and is available in almost any wearable device. While\naccelerometry is widely used for activity recognition and fitness, it is less\nexplored for health biomarkers and diagnosis. Here, we show that an\naccelerometry foundation model can predict a wide variety of health targets. To\nachieve improved performance, we distill representational knowledge from PPG\nencoders to accelerometery encoders using 20 million minutes of unlabeled data,\ncollected from ~172K participants in the Apple Heart and Movement Study under\ninformed consent. We observe strong cross-modal alignment on unseen data, e.g.,\n99.2% top-1 accuracy for retrieving PPG embeddings from accelerometry\nembeddings. We show that distilled accelerometry encoders have significantly\nmore informative representations compared to self-supervised or supervised\nencoders trained directly on accelerometry data, observed by at least 23%-49%\nimproved performance for predicting heart rate and heart rate variability. We\nalso show that distilled accelerometry encoders are readily predictive of a\nwide array of downstream health targets, i.e., they are generalist foundation\nmodels. We believe accelerometry foundation models for health may unlock new\nopportunities for developing digital biomarkers from any wearable device.",
      "tldr_zh": "该研究提出了一种通过知识蒸馏（knowledge distillation）的方法，从 PPG 编码器中提炼知识到加速度计（accelerometry）编码器，利用 2000 万分钟未标记数据（来自约 17.2 万参与者），开发可穿戴设备健康预测的基础模型。实验结果显示，蒸馏后的加速度计编码器在未见数据上实现了强跨模态对齐（如 99.2% top-1 准确率），并在预测心率和心率变异性等方面比自监督或监督模型提高了 23%-49%。该模型作为通用基础模型，能够预测广泛的下游健康目标，从而为从任何可穿戴设备开发数字生物标志物开辟新机会。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "updated format",
      "pdf_url": "http://arxiv.org/pdf/2412.11276v2",
      "published_date": "2024-12-15 18:48:14 UTC",
      "updated_date": "2025-01-31 17:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:54:31.626912"
    },
    {
      "arxiv_id": "2412.11261v1",
      "title": "CATER: Leveraging LLM to Pioneer a Multidimensional, Reference-Independent Paradigm in Translation Quality Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Kurando IIDA",
        "Kenjiro MIMURA"
      ],
      "abstract": "This paper introduces the Comprehensive AI-assisted Translation Edit Ratio\n(CATER), a novel and fully prompt-driven framework for evaluating machine\ntranslation (MT) quality. Leveraging large language models (LLMs) via a\ncarefully designed prompt-based protocol, CATER expands beyond traditional\nreference-bound metrics, offering a multidimensional, reference-independent\nevaluation that addresses linguistic accuracy, semantic fidelity, contextual\ncoherence, stylistic appropriateness, and information completeness. CATER's\nunique advantage lies in its immediate implementability: by providing the\nsource and target texts along with a standardized prompt, an LLM can rapidly\nidentify errors, quantify edit effort, and produce category-level and overall\nscores. This approach eliminates the need for pre-computed references or\ndomain-specific resources, enabling instant adaptation to diverse languages,\ngenres, and user priorities through adjustable weights and prompt\nmodifications. CATER's LLM-enabled strategy supports more nuanced assessments,\ncapturing phenomena such as subtle omissions, hallucinations, and\ndiscourse-level shifts that increasingly challenge contemporary MT systems. By\nuniting the conceptual rigor of frameworks like MQM and DQF with the\nscalability and flexibility of LLM-based evaluation, CATER emerges as a\nvaluable tool for researchers, developers, and professional translators\nworldwide. The framework and example prompts are openly available, encouraging\ncommunity-driven refinement and further empirical validation.",
      "tldr_zh": "这篇论文引入了 CATER 框架，这是一种基于大型语言模型 (LLMs) 的提示驱动方法，用于机器翻译 (MT) 质量的多维度评估，超越传统参考依赖指标，提供无参考的评估维度包括语言准确性、语义保真、上下文连贯性、风格适当性和信息完整性。CATER 的核心优势在于其即时可实现性，通过提供源文本和目标文本以及标准化提示，LLM 可以快速识别错误、量化编辑努力并生成类别和整体分数，同时支持通过权重调整和提示修改适应多种语言、类型和用户需求。该框架捕捉了微妙遗漏、幻觉和话语级变化等复杂问题，结合 MQM 和 DQF 等概念的严谨性与 LLM 的可扩展性，成为研究者、开发者和翻译者的重要工具，并已开源以促进社区优化和验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "17pages,1sample prompt",
      "pdf_url": "http://arxiv.org/pdf/2412.11261v1",
      "published_date": "2024-12-15 17:45:34 UTC",
      "updated_date": "2024-12-15 17:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:54:43.296962"
    },
    {
      "arxiv_id": "2412.11258v1",
      "title": "GaussianProperty: Integrating Physical Properties to 3D Gaussians with LMMs",
      "title_zh": "GaussianProperty：利用 LMMs 将物理属性集成到 3D Gaussians 中",
      "authors": [
        "Xinli Xu",
        "Wenhang Ge",
        "Dicong Qiu",
        "ZhiFei Chen",
        "Dongyu Yan",
        "Zhuoyun Liu",
        "Haoyu Zhao",
        "Hanfeng Zhao",
        "Shunsi Zhang",
        "Junwei Liang",
        "Ying-Cong Chen"
      ],
      "abstract": "Estimating physical properties for visual data is a crucial task in computer\nvision, graphics, and robotics, underpinning applications such as augmented\nreality, physical simulation, and robotic grasping. However, this area remains\nunder-explored due to the inherent ambiguities in physical property estimation.\nTo address these challenges, we introduce GaussianProperty, a training-free\nframework that assigns physical properties of materials to 3D Gaussians.\nSpecifically, we integrate the segmentation capability of SAM with the\nrecognition capability of GPT-4V(ision) to formulate a global-local physical\nproperty reasoning module for 2D images. Then we project the physical\nproperties from multi-view 2D images to 3D Gaussians using a voting strategy.\nWe demonstrate that 3D Gaussians with physical property annotations enable\napplications in physics-based dynamic simulation and robotic grasping. For\nphysics-based dynamic simulation, we leverage the Material Point Method (MPM)\nfor realistic dynamic simulation. For robot grasping, we develop a grasping\nforce prediction strategy that estimates a safe force range required for object\ngrasping based on the estimated physical properties. Extensive experiments on\nmaterial segmentation, physics-based dynamic simulation, and robotic grasping\nvalidate the effectiveness of our proposed method, highlighting its crucial\nrole in understanding physical properties from visual data. Online demo, code,\nmore cases and annotated datasets are available on\n\\href{https://Gaussian-Property.github.io}{this https URL}.",
      "tldr_zh": "该研究提出GaussianProperty，一个无需训练的框架，用于将材料物理属性整合到3D Gaussians中，以解决视觉数据中属性估计的模糊性问题。具体方法结合SAM的分割能力和GPT-4V的识别能力，构建全局-本地推理模块处理2D图像，并通过投票策略将多视图属性投影到3D Gaussians。框架支持Material Point Method (MPM)驱动的物理基础动态模拟，以及基于估计属性的机器人抓取力预测策略。实验在材料分割、动态模拟和机器人抓取任务上验证了方法的有效性，展示了其在增强现实和机器人应用中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11258v1",
      "published_date": "2024-12-15 17:44:10 UTC",
      "updated_date": "2024-12-15 17:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:54:54.239827"
    },
    {
      "arxiv_id": "2412.11255v1",
      "title": "Do Tutors Learn from Equity Training and Can Generative AI Assess It?",
      "title_zh": "导师是否从",
      "authors": [
        "Danielle R. Thomas",
        "Conrad Borchers",
        "Sanjit Kakarla",
        "Jionghao Lin",
        "Shambhavi Bhushan",
        "Boyuan Guo",
        "Erin Gatz",
        "Kenneth R. Koedinger"
      ],
      "abstract": "Equity is a core concern of learning analytics. However, applications that\nteach and assess equity skills, particularly at scale are lacking, often due to\nbarriers in evaluating language. Advances in generative AI via large language\nmodels (LLMs) are being used in a wide range of applications, with this present\nwork assessing its use in the equity domain. We evaluate tutor performance\nwithin an online lesson on enhancing tutors' skills when responding to students\nin potentially inequitable situations. We apply a mixed-method approach to\nanalyze the performance of 81 undergraduate remote tutors. We find marginally\nsignificant learning gains with increases in tutors' self-reported confidence\nin their knowledge in responding to middle school students experiencing\npossible inequities from pretest to posttest. Both GPT-4o and GPT-4-turbo\ndemonstrate proficiency in assessing tutors ability to predict and explain the\nbest approach. Balancing performance, efficiency, and cost, we determine that\nfew-shot learning using GPT-4o is the preferred model. This work makes\navailable a dataset of lesson log data, tutor responses, rubrics for human\nannotation, and generative AI prompts. Future work involves leveling the\ndifficulty among scenarios and enhancing LLM prompts for large-scale grading\nand assessment.",
      "tldr_zh": "本研究探讨了导师是否从公平性（Equity）培训中获益，以及生成式AI（如大型语言模型LLMs）是否能有效评估这一过程。通过混合方法分析81名本科远程导师的在线课程表现，发现导师在应对潜在不公平情境时的自报信心从预测试到后测试有轻微显著提升。实验结果显示，GPT-4o和GPT-4-turbo在评估导师预测和解释最佳方法方面表现出色，且基于few-shot learning的GPT-4o在性能、效率和成本上最优。该工作提供了数据集和AI提示，并建议未来优化场景难度和LLM提示以支持大规模评估。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Full research paper accepted to Learning Analytics and Knowledge (LAK\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11255v1",
      "published_date": "2024-12-15 17:36:40 UTC",
      "updated_date": "2024-12-15 17:36:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:55:06.335645"
    },
    {
      "arxiv_id": "2412.11253v1",
      "title": "Are Expressive Models Truly Necessary for Offline RL?",
      "title_zh": "离线强化学习中，表现力强的模型真的必要吗？",
      "authors": [
        "Guan Wang",
        "Haoyi Niu",
        "Jianxiong Li",
        "Li Jiang",
        "Jianming Hu",
        "Xianyuan Zhan"
      ],
      "abstract": "Among various branches of offline reinforcement learning (RL) methods,\ngoal-conditioned supervised learning (GCSL) has gained increasing popularity as\nit formulates the offline RL problem as a sequential modeling task, therefore\nbypassing the notoriously difficult credit assignment challenge of value\nlearning in conventional RL paradigm. Sequential modeling, however, requires\ncapturing accurate dynamics across long horizons in trajectory data to ensure\nreasonable policy performance. To meet this requirement, leveraging large,\nexpressive models has become a popular choice in recent literature, which,\nhowever, comes at the cost of significantly increased computation and inference\nlatency. Contradictory yet promising, we reveal that lightweight models as\nsimple as shallow 2-layer MLPs, can also enjoy accurate dynamics consistency\nand significantly reduced sequential modeling errors against large expressive\nmodels by adopting a simple recursive planning scheme: recursively planning\ncoarse-grained future sub-goals based on current and target information, and\nthen executes the action with a goal-conditioned policy learned from data\nrela-beled with these sub-goal ground truths. We term our method Recursive\nSkip-Step Planning (RSP). Simple yet effective, RSP enjoys great efficiency\nimprovements thanks to its lightweight structure, and substantially outperforms\nexisting methods, reaching new SOTA performances on the D4RL benchmark,\nespecially in multi-stage long-horizon tasks.",
      "tldr_zh": "这篇论文质疑离线强化学习(Offline RL)中是否需要复杂的表达模型，指出基于goal-conditioned supervised learning (GCSL)的顺序建模方法虽有效，但依赖大型模型会增加计算和推理延迟。论文提出Recursive Skip-Step Planning (RSP)方法，使用轻量级模型如浅层2层MLP，通过递归规划粗粒度子目标并结合目标条件策略来实现准确的动态一致性和减少错误。实验结果显示，RSP在D4RL基准上显著超越现有方法，特别是在多阶段长时序任务中，达到了新的SOTA性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Instead of relying on expressive models, shallow MLPs can also excel\n  in long sequential decision-making tasks with Recursive Skip-Step Planning\n  (RSP)",
      "pdf_url": "http://arxiv.org/pdf/2412.11253v1",
      "published_date": "2024-12-15 17:33:56 UTC",
      "updated_date": "2024-12-15 17:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:55:19.140979"
    },
    {
      "arxiv_id": "2412.11250v1",
      "title": "Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Sayantan Pal",
        "Souvik Das",
        "Rohini K. Srihari"
      ],
      "abstract": "Large Language Models (LLMs) have significantly improved personalized\nconversational capabilities. However, existing datasets like Persona Chat,\nSynthetic Persona Chat, and Blended Skill Talk rely on static, predefined\npersonas. This approach often results in dialogues that fail to capture human\npersonalities' fluid and evolving nature. To overcome these limitations, we\nintroduce a novel dataset with around 400,000 dialogues and a framework for\ngenerating personalized conversations using long-form journal entries from\nReddit. Our approach clusters journal entries for each author and filters them\nby selecting the most representative cluster, ensuring that the retained\nentries best reflect the author's personality. We further refine the data by\ncapturing the Big Five personality traits --openness, conscientiousness,\nextraversion, agreeableness, and neuroticism --ensuring that dialogues\nauthentically reflect an individual's personality. Using Llama 3 70B, we\ngenerate high-quality, personality-rich dialogues grounded in these journal\nentries. Fine-tuning models on this dataset leads to an 11% improvement in\ncapturing personality traits on average, outperforming existing approaches in\ngenerating more coherent and personality-driven dialogues.",
      "tldr_zh": "本研究指出，现有的数据集如 Persona Chat 和 Blended Skill Talk 依赖静态、预定义的角色，导致对话无法捕捉人类个性的流变性。为解决这一问题，研究团队引入一个包含约40万对话的新数据集和框架，利用Reddit的长篇日记条目进行聚类和过滤，选择最能代表作者个性的集群，并整合 Big Five personality traits（包括 openness、conscientiousness、extraversion、agreeableness 和 neuroticism）来生成更真实的个性化对话。使用 Llama 3 70B 模型生成高质量的对话后，在该数据集上微调模型平均提高了11%的个性特质捕捉能力，并在对话连贯性和个性驱动方面优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11250v1",
      "published_date": "2024-12-15 17:16:08 UTC",
      "updated_date": "2024-12-15 17:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:55:31.321887"
    },
    {
      "arxiv_id": "2412.11245v1",
      "title": "Transformer-Based Bearing Fault Detection using Temporal Decomposition Attention Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Marzieh Mirzaeibonehkhater",
        "Mohammad Ali Labbaf-Khaniki",
        "Mohammad Manthouri"
      ],
      "abstract": "Bearing fault detection is a critical task in predictive maintenance, where\naccurate and timely fault identification can prevent costly downtime and\nequipment damage. Traditional attention mechanisms in Transformer neural\nnetworks often struggle to capture the complex temporal patterns in bearing\nvibration data, leading to suboptimal performance. To address this limitation,\nwe propose a novel attention mechanism, Temporal Decomposition Attention (TDA),\nwhich combines temporal bias encoding with seasonal-trend decomposition to\ncapture both long-term dependencies and periodic fluctuations in time series\ndata. Additionally, we incorporate the Hull Exponential Moving Average (HEMA)\nfor feature extraction, enabling the model to effectively capture meaningful\ncharacteristics from the data while reducing noise. Our approach integrates TDA\ninto the Transformer architecture, allowing the model to focus separately on\nthe trend and seasonal components of the data. Experimental results on the Case\nWestern Reserve University (CWRU) bearing fault detection dataset demonstrate\nthat our approach outperforms traditional attention mechanisms and achieves\nstate-of-the-art performance in terms of accuracy and interpretability. The\nHEMA-Transformer-TDA model achieves an accuracy of 98.1%, with exceptional\nprecision, recall, and F1-scores, demonstrating its effectiveness in bearing\nfault detection and its potential for application in other time series tasks\nwith seasonal patterns or trends.",
      "tldr_zh": "本研究针对轴承故障检测中的时间序列数据问题，提出了一种基于 Transformer 的新方法，使用 Temporal Decomposition Attention (TDA) 机制结合时间偏差编码和季节趋势分解，以更好地捕捉长期依赖和周期波动。方法还整合了 Hull Exponential Moving Average (HEMA) 用于特征提取，减少噪声并提升模型对趋势和季节成分的关注。实验在 Case Western Reserve University (CWRU) 数据集上显示，该模型准确率达98.1%，在精确率、召回率和F1分数上均优于传统注意力机制，并展示了在其他具有季节模式或趋势的时间序列任务中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11245v1",
      "published_date": "2024-12-15 16:51:31 UTC",
      "updated_date": "2024-12-15 16:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:55:42.377182"
    },
    {
      "arxiv_id": "2412.11242v2",
      "title": "TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lanxiang Hu",
        "Tajana Rosing",
        "Hao Zhang"
      ],
      "abstract": "Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.",
      "tldr_zh": "这篇论文提出了TrimLLM，一种通过渐进式层丢弃(progressive layer dropping)的方法，用于针对特定领域的LLM进行优化，以实现内存节省和推理加速，同时满足延迟和隐私需求。TrimLLM基于观察到的层级专业化现象，减少模型深度，确保在医疗、法律和金融数据集上保留模型容量。实验结果显示，该方法在消费级GPU上实现了2.1-5.7倍的推理加速，在A100上高达3.1倍，且在50~60%模型压缩比时准确率无损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11242v2",
      "published_date": "2024-12-15 16:47:16 UTC",
      "updated_date": "2024-12-19 10:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:55:54.370825"
    },
    {
      "arxiv_id": "2412.11239v2",
      "title": "Learning Set Functions with Implicit Differentiation",
      "title_zh": "翻译失败",
      "authors": [
        "Gözde Özcan",
        "Chengzhi Shi",
        "Stratis Ioannidis"
      ],
      "abstract": "Ou et al. (2022) introduce the problem of learning set functions from data\ngenerated by a so-called optimal subset oracle. Their approach approximates the\nunderlying utility function with an energy-based model, whose parameters are\nestimated via mean-field variational inference. Ou et al. (2022) show this\nreduces to fixed point iterations; however, as the number of iterations\nincreases, automatic differentiation quickly becomes computationally\nprohibitive due to the size of the Jacobians that are stacked during\nbackpropagation. We address this challenge with implicit differentiation and\nexamine the convergence conditions for the fixed-point iterations. We\nempirically demonstrate the efficiency of our method on synthetic and\nreal-world subset selection applications including product recommendation, set\nanomaly detection and compound selection tasks.",
      "tldr_zh": "这篇论文针对 Ou et al. (2022) 的集合函数学习方法存在的计算挑战（如自动微分中 Jacobian 矩阵堆积问题），引入了 implicit differentiation 来优化参数估计过程，并分析了 fixed-point iterations 的收敛条件。方法通过隐式微分减少计算开销，同时保持均值场变分推断的有效性。在实验中，该方法在合成和真实世界应用（如产品推荐、集合异常检测和化合物选择任务）中显示出更高的效率和性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 1 figure, extended version of the AAAI 2025 paper with the\n  same title",
      "pdf_url": "http://arxiv.org/pdf/2412.11239v2",
      "published_date": "2024-12-15 16:42:09 UTC",
      "updated_date": "2024-12-17 11:14:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:56:06.526107"
    },
    {
      "arxiv_id": "2412.11228v1",
      "title": "Uni-AdaFocus: Spatial-temporal Dynamic Computation for Video Recognition",
      "title_zh": "Uni-AdaFocus：用于视频识别的时空动态计算",
      "authors": [
        "Yulin Wang",
        "Haoji Zhang",
        "Yang Yue",
        "Shiji Song",
        "Chao Deng",
        "Junlan Feng",
        "Gao Huang"
      ],
      "abstract": "This paper presents a comprehensive exploration of the phenomenon of data\nredundancy in video understanding, with the aim to improve computational\nefficiency. Our investigation commences with an examination of spatial\nredundancy, which refers to the observation that the most informative region in\neach video frame usually corresponds to a small image patch, whose shape, size\nand location shift smoothly across frames. Motivated by this phenomenon, we\nformulate the patch localization problem as a dynamic decision task, and\nintroduce a spatially adaptive video recognition approach, termed AdaFocus. In\nspecific, a lightweight encoder is first employed to quickly process the full\nvideo sequence, whose features are then utilized by a policy network to\nidentify the most task-relevant regions. Subsequently, the selected patches are\ninferred by a high-capacity deep network for the final prediction. The full\nmodel can be trained in end-to-end conveniently. Furthermore, AdaFocus can be\nextended by further considering temporal and sample-wise redundancies, i.e.,\nallocating the majority of computation to the most task-relevant frames, and\nminimizing the computation spent on relatively \"easier\" videos. Our resulting\napproach, Uni-AdaFocus, establishes a comprehensive framework that seamlessly\nintegrates spatial, temporal, and sample-wise dynamic computation, while it\npreserves the merits of AdaFocus in terms of efficient end-to-end training and\nhardware friendliness. In addition, Uni-AdaFocus is general and flexible as it\nis compatible with off-the-shelf efficient backbones (e.g., TSM and X3D), which\ncan be readily deployed as our feature extractor, yielding a significantly\nimproved computational efficiency. Empirically, extensive experiments based on\nseven benchmark datasets and three application scenarios substantiate that\nUni-AdaFocus is considerably more efficient than the competitive baselines.",
      "tldr_zh": "这篇论文探讨了视频识别中数据冗余的问题，特别是spatial redundancy（空间冗余），并提出AdaFocus方法，将图像块定位视为动态决策任务：使用轻量级编码器处理完整视频序列，策略网络识别最相关区域，然后由高容量网络进行预测，实现端到端训练。Uni-AdaFocus扩展了这一框架，通过进一步考虑temporal redundancy（时间冗余）和样本级冗余，将计算资源分配到最相关的帧和视频上，同时兼容现有高效骨干网络如TSM和X3D。实验结果显示，Uni-AdaFocus在七个基准数据集和三个应用场景中，比竞争基线显著提高了计算效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE TPAMI. Journal version of arXiv:2105.03245\n  (AdaFocusV1, ICCV 2021 Oral), arXiv:2112.14238 (AdaFocusV2, CVPR 2022), and\n  arXiv:2209.13465 (AdaFocusV3, ECCV 2022). Code and pre-trained models:\n  https://github.com/LeapLabTHU/Uni-AdaFocus",
      "pdf_url": "http://arxiv.org/pdf/2412.11228v1",
      "published_date": "2024-12-15 15:51:44 UTC",
      "updated_date": "2024-12-15 15:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:56:18.706891"
    },
    {
      "arxiv_id": "2412.11216v2",
      "title": "Distribution-Consistency-Guided Multi-modal Hashing",
      "title_zh": "分布一致性引导的多模态散列",
      "authors": [
        "Jin-Yu Liu",
        "Xian-Ling Mao",
        "Tian-Yi Che",
        "Rong-Cheng Tu"
      ],
      "abstract": "Multi-modal hashing methods have gained popularity due to their fast speed\nand low storage requirements. Among them, the supervised methods demonstrate\nbetter performance by utilizing labels as supervisory signals compared with\nunsupervised methods. Currently, for almost all supervised multi-modal hashing\nmethods, there is a hidden assumption that training sets have no noisy labels.\nHowever, labels are often annotated incorrectly due to manual labeling in\nreal-world scenarios, which will greatly harm the retrieval performance. To\naddress this issue, we first discover a significant distribution consistency\npattern through experiments, i.e., the 1-0 distribution of the presence or\nabsence of each category in the label is consistent with the high-low\ndistribution of similarity scores of the hash codes relative to category\ncenters. Then, inspired by this pattern, we propose a novel\nDistribution-Consistency-Guided Multi-modal Hashing (DCGMH), which aims to\nfilter and reconstruct noisy labels to enhance retrieval performance.\nSpecifically, the proposed method first randomly initializes several category\ncenters, which are used to compute the high-low distribution of similarity\nscores; Noisy and clean labels are then separately filtered out via the\ndiscovered distribution consistency pattern to mitigate the impact of noisy\nlabels; Subsequently, a correction strategy, which is indirectly designed via\nthe distribution consistency pattern, is applied to the filtered noisy labels,\ncorrecting high-confidence ones while treating low-confidence ones as unlabeled\nfor unsupervised learning, thereby further enhancing the model's performance.\nExtensive experiments on three widely used datasets demonstrate the superiority\nof the proposed method compared to state-of-the-art baselines in multi-modal\nretrieval tasks. The code is available at\nhttps://github.com/LiuJinyu1229/DCGMH.",
      "tldr_zh": "该研究针对监督多模态散列（Multi-modal Hashing）方法中噪声标签问题，提出了一种新方法Distribution-Consistency-Guided Multi-modal Hashing (DCGMH)。通过实验发现，标签的1-0分布与散列码相对于类别中心的相似度分数高低分布一致，该模式用于过滤和重建噪声标签。具体而言，DCGMH先初始化类别中心计算相似度分布，然后分离噪声和干净标签，并对高置信度噪声标签进行修正，低置信度标签则视为无监督学习。在三个常用数据集上的实验表明，该方法在多模态检索任务中优于现有基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11216v2",
      "published_date": "2024-12-15 15:13:14 UTC",
      "updated_date": "2024-12-19 08:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:56:30.144036"
    },
    {
      "arxiv_id": "2412.11215v2",
      "title": "Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks",
      "title_zh": "神经端口-哈密顿微分代数方程用于电气网络的组合",
      "authors": [
        "Cyrus Neary",
        "Nathan Tsao",
        "Ufuk Topcu"
      ],
      "abstract": "We develop compositional learning algorithms for coupled dynamical systems.\nWhile deep learning has proven effective at modeling complex relationships from\ndata, compositional couplings between system components typically introduce\nalgebraic constraints on state variables, posing challenges to many existing\ndata-driven approaches to modeling dynamical systems. Towards developing deep\nlearning models for constrained dynamical systems, we introduce neural\nport-Hamiltonian differential algebraic equations (N-PHDAEs), which use neural\nnetworks to parametrize unknown terms in both the differential and algebraic\ncomponents of a port-Hamiltonian DAE. To train these models, we propose an\nalgorithm that uses automatic differentiation to perform index reduction,\nautomatically transforming the neural DAE into an equivalent system of neural\nordinary differential equations (N-ODEs), for which established model inference\nand backpropagation methods exist. The proposed compositional modeling\nframework and learning algorithms may be applied broadly to learn\ncontrol-oriented models of dynamical systems in a variety of application areas,\nhowever, in this work, we focus on their application to the modeling of\nelectrical networks. Experiments simulating the dynamics of nonlinear circuits\nexemplify the benefits of our approach: the proposed N-PHDAE model achieves an\norder of magnitude improvement in prediction accuracy and constraint\nsatisfaction when compared to a baseline N-ODE over long prediction time\nhorizons. We also validate the compositional capabilities of our approach\nthrough experiments on a simulated D.C. microgrid: we train individual N-PHDAE\nmodels for separate grid components, before coupling them to accurately predict\nthe behavior of larger-scale networks.",
      "tldr_zh": "本论文提出了 Neural Port-Hamiltonian Differential Algebraic Equations (N-PHDAEs)，一种使用神经网络参数化端口-哈密顿微分代数方程的框架，用于处理耦合动力系统中状态变量的代数约束问题，从而实现电气网络的组合学习。训练算法通过自动微分进行指数减少，将 N-PHDAEs 转化为等价的 Neural Ordinary Differential Equations (N-ODEs)，便于应用现有的模型推理和反向传播方法。实验结果显示，在非线性电路模拟中，N-PHDAEs 比基线 N-ODE 模型在预测准确性和约束满足度上提高了数量级；此外，通过在模拟 D.C. 微电网上训练并耦合独立组件模型，该方法验证了其强大的组合建模能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11215v2",
      "published_date": "2024-12-15 15:13:11 UTC",
      "updated_date": "2025-04-07 22:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:56:43.489490"
    },
    {
      "arxiv_id": "2412.11207v1",
      "title": "ProFe: Communication-Efficient Decentralized Federated Learning via Distillation and Prototypes",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Miguel Sánchez Sánchez",
        "Enrique Tomás Martínez Beltrán",
        "Miguel Fernández Llamas",
        "Gérôme Bovet",
        "Gregorio Martínez Pérez",
        "Alberto Huertas Celdrán"
      ],
      "abstract": "Decentralized Federated Learning (DFL) trains models in a collaborative and\nprivacy-preserving manner while removing model centralization risks and\nimproving communication bottlenecks. However, DFL faces challenges in efficient\ncommunication management and model aggregation within decentralized\nenvironments, especially with heterogeneous data distributions. Thus, this\npaper introduces ProFe, a novel communication optimization algorithm for DFL\nthat combines knowledge distillation, prototype learning, and quantization\ntechniques. ProFe utilizes knowledge from large local models to train smaller\nones for aggregation, incorporates prototypes to better learn unseen classes,\nand applies quantization to reduce data transmitted during communication\nrounds. The performance of ProFe has been validated and compared to the\nliterature by using benchmark datasets like MNIST, CIFAR10, and CIFAR100.\nResults showed that the proposed algorithm reduces communication costs by up to\n~40-50% while maintaining or improving model performance. In addition, it adds\n~20% training time due to increased complexity, generating a trade-off.",
      "tldr_zh": "本论文提出ProFe，一种针对Decentralized Federated Learning (DFL)的通信高效算法，通过结合knowledge distillation、prototype learning和quantization技术，优化了异构数据分布下的模型聚合和通信管理。具体而言，ProFe利用大本地模型的知识训练小模型、引入原型以更好地学习未见类，并应用量化减少传输数据。实验在MNIST、CIFAR10和CIFAR100数据集上验证，ProFe可将通信成本降低约40-50%，同时维持或提升模型性能，但增加了约20%的训练时间，体现了效率与复杂度的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11207v1",
      "published_date": "2024-12-15 14:49:29 UTC",
      "updated_date": "2024-12-15 14:49:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:56:53.936493"
    },
    {
      "arxiv_id": "2412.11203v1",
      "title": "Task-Oriented Dialog Systems for the Senegalese Wolof Language",
      "title_zh": "翻译失败",
      "authors": [
        "Derguene Mbaye",
        "Moussa Diallo"
      ],
      "abstract": "In recent years, we are seeing considerable interest in conversational agents\nwith the rise of large language models (LLMs). Although they offer considerable\nadvantages, LLMs also present significant risks, such as hallucination, which\nhinder their widespread deployment in industry. Moreover, low-resource\nlanguages such as African ones are still underrepresented in these systems\nlimiting their performance in these languages. In this paper, we illustrate a\nmore classical approach based on modular architectures of Task-oriented Dialog\nSystems (ToDS) offering better control over outputs. We propose a chatbot\ngeneration engine based on the Rasa framework and a robust methodology for\nprojecting annotations onto the Wolof language using an in-house machine\ntranslation system. After evaluating a generated chatbot trained on the Amazon\nMassive dataset, our Wolof Intent Classifier performs similarly to the one\nobtained for French, which is a resource-rich language. We also show that this\napproach is extensible to other low-resource languages, thanks to the intent\nclassifier's language-agnostic pipeline, simplifying the design of chatbots in\nthese languages.",
      "tldr_zh": "该论文探讨了任务导向对话系统 (ToDS) 在低资源语言 Wolof 上的应用，以应对大型语言模型 (LLMs) 的风险，如幻觉问题，并解决非洲语言在对话系统中的不足。作者提出了一种基于 Rasa 框架的聊天机器人生成引擎，并使用内部机器翻译系统将注释投射到 Wolof 语言，从而构建高效的 Wolof Intent Classifier。实验结果显示，该分类器的性能与资源丰富的法语系统相当，且该方法因其语言无关的管道设计而易于扩展到其他低资源语言。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 tables, 6 figures, The 31st International Conference on\n  Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11203v1",
      "published_date": "2024-12-15 14:35:49 UTC",
      "updated_date": "2024-12-15 14:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:57:06.753878"
    },
    {
      "arxiv_id": "2412.11194v1",
      "title": "SoK: On Closing the Applicability Gap in Automated Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ezzeldin Shereen",
        "Dan Ristea",
        "Sanyam Vyas",
        "Shae McFadden",
        "Madeleine Dwyer",
        "Chris Hicks",
        "Vasilios Mavroudis"
      ],
      "abstract": "The frequent discovery of security vulnerabilities in both open-source and\nproprietary software underscores the urgent need for earlier detection during\nthe development lifecycle. Initiatives such as DARPA's Artificial Intelligence\nCyber Challenge (AIxCC) aim to accelerate Automated Vulnerability Detection\n(AVD), seeking to address this challenge by autonomously analyzing source code\nto identify vulnerabilities.\n  This paper addresses two primary research questions: (RQ1) How is current AVD\nresearch distributed across its core components? (RQ2) What key areas should\nfuture research target to bridge the gap in the practical applicability of AVD\nthroughout software development? To answer these questions, we conduct a\nsystematization over 79 AVD articles and 17 empirical studies, analyzing them\nacross five core components: task formulation and granularity, input\nprogramming languages and representations, detection approaches and key\nsolutions, evaluation metrics and datasets, and reported performance.\n  Our systematization reveals that the narrow focus of AVD research-mainly on\nspecific tasks and programming languages-limits its practical impact and\noverlooks broader areas crucial for effective, real-world vulnerability\ndetection. We identify significant challenges, including the need for\ndiversified problem formulations, varied detection granularities, broader\nlanguage support, better dataset quality, enhanced reproducibility, and\nincreased practical impact. Based on these findings we identify research\ndirections that will enhance the effectiveness and applicability of AVD\nsolutions in software security.",
      "tldr_zh": "这篇 SoK 论文探讨了 Automated Vulnerability Detection (AVD) 在实际软件开发中的适用性差距，针对两个核心研究问题：当前 AVD 研究如何分布于其关键组件，以及未来研究应如何桥接这一差距。作者通过对 79 篇 AVD 文章和 17 个实证研究进行系统化分析，涵盖任务制定、输入语言、检测方法、评估指标和性能等方面。结果显示，现有研究过于集中在特定任务和编程语言，导致实际影响有限，并提出了未来方向，如多样化问题制定、扩展语言支持、提升数据集质量和可重复性，以增强 AVD 在软件安全的实际应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11194v1",
      "published_date": "2024-12-15 14:01:41 UTC",
      "updated_date": "2024-12-15 14:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:57:19.285959"
    },
    {
      "arxiv_id": "2412.11192v1",
      "title": "From Votes to Volatility Predicting the Stock Market on Election Day",
      "title_zh": "翻译失败",
      "authors": [
        "Igor L. R. Azevedo",
        "Toyotaro Suzumura"
      ],
      "abstract": "Stock market forecasting has been a topic of extensive research, aiming to\nprovide investors with optimal stock recommendations for higher returns. In\nrecent years, this field has gained even more attention due to the widespread\nadoption of deep learning models. While these models have achieved impressive\naccuracy in predicting stock behavior, tailoring them to specific scenarios has\nbecome increasingly important. Election Day represents one such critical\nscenario, characterized by intensified market volatility, as the winning\ncandidate's policies significantly impact various economic sectors and\ncompanies. To address this challenge, we propose the Election Day Stock Market\nForecasting (EDSMF) Model. Our approach leverages the contextual capabilities\nof large language models alongside specialized agents designed to analyze the\npolitical and economic consequences of elections. By building on a\nstate-of-the-art architecture, we demonstrate that EDSMF improves the\npredictive performance of the S&P 500 during this uniquely volatile day.",
      "tldr_zh": "这篇论文探讨了股票市场预测在选举日的应用，提出了一种名为 Election Day Stock Market Forecasting (EDSMF) Model，以应对选举导致的市场波动和政策影响。模型结合大型语言模型的上下文分析能力以及专门代理来评估选举的政治和经济后果。结果显示，EDSMF 基于现有先进架构，显著提升了 S&P 500 在选举日期间的预测性能。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11192v1",
      "published_date": "2024-12-15 13:58:20 UTC",
      "updated_date": "2024-12-15 13:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:57:29.230885"
    },
    {
      "arxiv_id": "2412.11189v2",
      "title": "Leveraging Large Language Models for Active Merchant Non-player Characters",
      "title_zh": "翻译失败",
      "authors": [
        "Byungjun Kim",
        "Minju Kim",
        "Dayeon Seo",
        "Bugeun Kim"
      ],
      "abstract": "We highlight two significant issues leading to the passivity of current\nmerchant non-player characters (NPCs): pricing and communication. While\nimmersive interactions have been a focus, negotiations between merchant NPCs\nand players on item prices have not received sufficient attention. First, we\ndefine passive pricing as the limited ability of merchants to modify predefined\nitem prices. Second, passive communication means that merchants can only\ninteract with players in a scripted manner. To tackle these issues and create\nan active merchant NPC, we propose a merchant framework based on large language\nmodels (LLMs), called MART, which consists of an appraiser module and a\nnegotiator module. We conducted two experiments to guide game developers in\nselecting appropriate implementations by comparing different training methods\nand LLM sizes. Our findings indicate that finetuning methods, such as\nsupervised finetuning (SFT) and knowledge distillation (KD), are effective in\nusing smaller LLMs to implement active merchant NPCs. Additionally, we found\nthree irregular cases arising from the responses of LLMs. We expect our\nfindings to guide developers in using LLMs for developing active merchant NPCs.",
      "tldr_zh": "本研究针对当前商家非玩家角色 (NPCs) 的被动定价和被动沟通问题，提出了一种基于 Large Language Models (LLMs) 的框架 MART，包括评估器模块和谈判者模块，以实现更活跃的互动。实验比较了不同训练方法和 LLM 大小，发现监督微调 (SFT) 和知识蒸馏 (KD) 等微调方法能有效使用较小的 LLMs 构建活跃商家 NPCs，并识别了 LLM 响应的三个不规则情况。该框架为游戏开发者提供了指导，帮助他们利用 LLMs 提升商家 NPCs 的互动性和谈判能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review / Modified the links to code and dataset",
      "pdf_url": "http://arxiv.org/pdf/2412.11189v2",
      "published_date": "2024-12-15 13:48:39 UTC",
      "updated_date": "2025-01-08 11:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:59:42.650232"
    },
    {
      "arxiv_id": "2412.11187v1",
      "title": "Analyzing the Attention Heads for Pronoun Disambiguation in Context-aware Machine Translation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Paweł Mąka",
        "Yusuf Can Semerci",
        "Jan Scholtes",
        "Gerasimos Spanakis"
      ],
      "abstract": "In this paper, we investigate the role of attention heads in Context-aware\nMachine Translation models for pronoun disambiguation in the English-to-German\nand English-to-French language directions. We analyze their influence by both\nobserving and modifying the attention scores corresponding to the plausible\nrelations that could impact a pronoun prediction. Our findings reveal that\nwhile some heads do attend the relations of interest, not all of them influence\nthe models' ability to disambiguate pronouns. We show that certain heads are\nunderutilized by the models, suggesting that model performance could be\nimproved if only the heads would attend one of the relations more strongly.\nFurthermore, we fine-tune the most promising heads and observe the increase in\npronoun disambiguation accuracy of up to 5 percentage points which demonstrates\nthat the improvements in performance can be solidified into the models'\nparameters.",
      "tldr_zh": "本研究分析了在 Context-aware Machine Translation 模型中，attention heads 在处理英语到德语和英语到法语的代词消歧（pronoun disambiguation）方面的作用。研究通过观察和修改 attention scores 来评估这些 heads 与相关关系的交互，发现并非所有 heads 都有效，有些 heads 被模型低效利用，从而限制了性能。结果显示，通过对最有潜力的 heads 进行 fine-tune，可以将代词消歧准确率提高多达 5 百分点，证明了优化 attention heads 的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11187v1",
      "published_date": "2024-12-15 13:42:49 UTC",
      "updated_date": "2024-12-15 13:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:45.357454"
    },
    {
      "arxiv_id": "2412.11186v1",
      "title": "Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Haisheng Lu",
        "Yujie Fu",
        "Fan Zhang",
        "Le Zhang"
      ],
      "abstract": "Medical image segmentation is a critical component of clinical practice, and\nthe state-of-the-art MedSAM model has significantly advanced this field.\nNevertheless, critiques highlight that MedSAM demands substantial computational\nresources during inference. To address this issue, the CVPR 2024 MedSAM on\nLaptop Challenge was established to find an optimal balance between accuracy\nand processing speed. In this paper, we introduce a quantization-aware training\npipeline designed to efficiently quantize the Segment Anything Model for\nmedical images and deploy it using the OpenVINO inference engine. This pipeline\noptimizes both training time and disk storage. Our experimental results confirm\nthat this approach considerably enhances processing speed over the baseline,\nwhile still achieving an acceptable accuracy level. The training script,\ninference script, and quantized model are publicly accessible at\nhttps://github.com/AVC2-UESTC/QMedSAM.",
      "tldr_zh": "这篇论文针对医疗图像分割中 Segment Anything Model (MedSAM) 的高计算资源需求，提出了一种高效的 Quantization-Aware Training 管道，以优化模型在医疗图像上的量化过程和 OpenVINO 推理引擎部署。该方法显著减少了训练时间和磁盘存储，同时保持了可接受的准确性。实验结果显示，与基线模型相比，处理速度有了明显提升，且训练脚本、推理脚本和量化模型已公开在 GitHub 上（https://github.com/AVC2-UESTC/QMedSAM）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 3 figures, to be published in LNCS",
      "pdf_url": "http://arxiv.org/pdf/2412.11186v1",
      "published_date": "2024-12-15 13:35:07 UTC",
      "updated_date": "2024-12-15 13:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:45.337777"
    },
    {
      "arxiv_id": "2412.19820v1",
      "title": "GaLore$+$: Boosting Low-Rank Adaptation for LLMs with Cross-Head Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Xutao Liao",
        "Shaohui Li",
        "Yuhui Xu",
        "Zhi Li",
        "Yu Liu",
        "You He"
      ],
      "abstract": "Recent low-rank training methods, such as GaLore, have significantly reduced\nthe memory required to optimize large language models (LLMs). However, these\nmethods often suffer from time-consuming low-rank projection estimations. In\nparticular, the singular value decomposition (SVD) in GaLore can consume more\nthan 80\\% of the total training time. To address this issue, we propose\nGaLore$+$, which uses cross-head low-rank projection to reduce the substantial\ntime consumption in estimating low-rank projections for multi-head attention.\nIn addition, we employ randomized subspace iteration to achieve fast SVD. To\nfurther enhance performance, we propose sparsely coded residuals to reduce the\nerrors caused by low-rank approximation on the first- and second-order moments\nof the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic\nreasoning and natural language generation datasets. Our experiments demonstrate\nthat GaLore$+$ delivers superior performance while achieving approximately\n$4\\times$ fine-tuning speed compared to vanilla GaLore.",
      "tldr_zh": "该论文提出 GaLore$+$ 方法，以提升大型语言模型 (LLMs) 的低秩适配效率，针对原有 GaLore 方法中低秩投影估计（如 SVD）耗时的痛点。GaLore$+$ 引入 cross-head low-rank projection 和 randomized subspace iteration 来加速 SVD 计算，同时采用 sparsely coded residuals 减少低秩近似对优化器和权重更新的误差。实验结果显示，在算术推理和自然语言生成数据集上，GaLore$+$ 比 vanilla GaLore 性能更优，并实现约 4 倍的微调速度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19820v1",
      "published_date": "2024-12-15 12:28:13 UTC",
      "updated_date": "2024-12-15 12:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:00:18.021785"
    },
    {
      "arxiv_id": "2412.12204v1",
      "title": "SEE: Sememe Entanglement Encoding for Transformer-bases Models Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Zhang",
        "Shuzhen Sun",
        "Peng Zhang",
        "Guangxing Cao",
        "Hui Gao",
        "Xindian Ma",
        "Nan Xu",
        "Yuexian Hou"
      ],
      "abstract": "Transformer-based large language models exhibit groundbreaking capabilities,\nbut their storage and computational costs are prohibitively high, limiting\ntheir application in resource-constrained scenarios. An effective approach is\nto eliminate redundant model parameters and computational costs while\nincorporating efficient expert-derived knowledge structures to achieve a\nbalance between compression and performance. Therefore, we propose the\n\\textit{Sememe Entanglement Encoding (SEE)} algorithm. Guided by expert prior\nknowledge, the model is compressed through the low-rank approximation idea. In\nEntanglement Embedding, basic semantic units such as sememes are represented as\nlow-dimensional vectors, and then reconstructed into high-dimensional word\nembeddings through the combination of generalized quantum entanglement. We\nadapt the Sememe Entanglement Encoding algorithm to transformer-based models of\ndifferent magnitudes. Experimental results indicate that our approach achieves\nstable performance while compressing model parameters and computational costs.",
      "tldr_zh": "本研究针对 Transformer-based 模型的高存储和计算成本问题，提出了一种 Sememe Entanglement Encoding (SEE) 算法，通过低-rank approximation 和专家知识指导来压缩模型参数，同时整合高效知识结构。SEE 算法在 Entanglement Embedding 中，将 sememes 表示为低维向量，并通过量子纠缠 (quantum entanglement) 组合重建为高维词嵌入，从而平衡压缩与性能。实验结果显示，该方法适用于不同规模的 Transformer-based 模型，能显著减少计算成本并保持稳定性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12204v1",
      "published_date": "2024-12-15 12:01:43 UTC",
      "updated_date": "2024-12-15 12:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:45.772904"
    },
    {
      "arxiv_id": "2501.16331v1",
      "title": "Decoding OTC Government Bond Market Liquidity: An ABM Model for Market Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Alicia Vidler",
        "Toby Walsh"
      ],
      "abstract": "The over-the-counter (OTC) government bond markets are characterised by their\nbilateral trading structures, which pose unique challenges to understanding and\nensuring market stability and liquidity. In this paper, we develop a bespoke\nABM that simulates market-maker interactions within a stylised government bond\nmarket. The model focuses on the dynamics of liquidity and stability in the\nsecondary trading of government bonds, particularly in concentrated markets\nlike those found in Australia and the UK. Through this simulation, we test key\nhypotheses around improving market stability, focusing on the effects of agent\ndiversity, business costs, and client base size. We demonstrate that greater\nagent diversity enhances market liquidity and that reducing the costs of\nmarket-making can improve overall market stability. The model offers insights\ninto computational finance by simulating trading without price transparency,\nhighlighting how micro-structural elements can affect macro-level market\noutcomes. This research contributes to the evolving field of computational\nfinance by employing computational intelligence techniques to better understand\nthe fundamental mechanics of government bond markets, providing actionable\ninsights for both academics and practitioners.",
      "tldr_zh": "本文研究了 OTC 政府债券市场的双边交易结构及其对市场稳定性和流动性的挑战，开发了一个定制的 ABM（Agent-Based Model）来模拟做市商互动，特别是针对澳大利亚和英国等集中市场。模拟结果显示，增加代理多样性能显著提升市场流动性，而降低业务成本有助于改善整体市场稳定性。该模型通过模拟无价格透明度的交易，揭示微观结构如何影响宏观市场动态，并为计算金融领域提供实用见解，支持学术和从业者优化市场机制。",
      "categories": [
        "q-fin.TR",
        "cs.AI"
      ],
      "primary_category": "q-fin.TR",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.16331v1",
      "published_date": "2024-12-15 11:22:25 UTC",
      "updated_date": "2024-12-15 11:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:45.285516"
    },
    {
      "arxiv_id": "2412.11155v1",
      "title": "Partial Identifiability in Inverse Reinforcement Learning For Agents With Non-Exponential Discounting",
      "title_zh": "翻译失败",
      "authors": [
        "Joar Skalse",
        "Alessandro Abate"
      ],
      "abstract": "The aim of inverse reinforcement learning (IRL) is to infer an agent's\npreferences from observing their behaviour. Usually, preferences are modelled\nas a reward function, $R$, and behaviour is modelled as a policy, $\\pi$. One of\nthe central difficulties in IRL is that multiple preferences may lead to the\nsame observed behaviour. That is, $R$ is typically underdetermined by $\\pi$,\nwhich means that $R$ is only partially identifiable. Recent work has\ncharacterised the extent of this partial identifiability for different types of\nagents, including optimal and Boltzmann-rational agents. However, work so far\nhas only considered agents that discount future reward exponentially: this is a\nserious limitation, especially given that extensive work in the behavioural\nsciences suggests that humans are better modelled as discounting\nhyperbolically. In this work, we newly characterise partial identifiability in\nIRL for agents with non-exponential discounting: our results are in particular\nrelevant for hyperbolical discounting, but they also more generally apply to\nagents that use other types of (non-exponential) discounting. We significantly\nshow that generally IRL is unable to infer enough information about $R$ to\nidentify the correct optimal policy, which entails that IRL alone can be\ninsufficient to adequately characterise the preferences of such agents.",
      "tldr_zh": "本研究探讨了逆强化学习 (IRL) 中奖励函数 $R$ 的部分可识别性问题，针对非指数折扣的代理（如超几何折扣的代理）。以往工作仅限于指数折扣代理，但本文首次表征了非指数折扣代理在 IRL 中的部分可识别性，证明多个 $R$ 可能导致相同的策略 $\\pi$。结果显示，IRL 无法从行为中推断足够的 $R$ 信息来识别正确的最优策略，从而表明 IRL 单独不足以准确表征这些代理的偏好，尤其在建模人类行为时。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11155v1",
      "published_date": "2024-12-15 11:08:58 UTC",
      "updated_date": "2024-12-15 11:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:00:53.902611"
    },
    {
      "arxiv_id": "2412.11142v3",
      "title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
      "title_zh": "AD-LLM：评估大型语言模型用于异常检测的基准测试",
      "authors": [
        "Tiankai Yang",
        "Yi Nian",
        "Shawn Li",
        "Ruiyao Xu",
        "Yuangang Li",
        "Jiaqi Li",
        "Zhuo Xiao",
        "Xiyang Hu",
        "Ryan Rossi",
        "Kaize Ding",
        "Xia Hu",
        "Yue Zhao"
      ],
      "abstract": "Anomaly detection (AD) is an important machine learning task with many\nreal-world uses, including fraud detection, medical diagnosis, and industrial\nmonitoring. Within natural language processing (NLP), AD helps detect issues\nlike spam, misinformation, and unusual user activity. Although large language\nmodels (LLMs) have had a strong impact on tasks such as text generation and\nsummarization, their potential in AD has not been studied enough. This paper\nintroduces AD-LLM, the first benchmark that evaluates how LLMs can help with\nNLP anomaly detection. We examine three key tasks: (i) zero-shot detection,\nusing LLMs' pre-trained knowledge to perform AD without tasks-specific\ntraining; (ii) data augmentation, generating synthetic data and category\ndescriptions to improve AD models; and (iii) model selection, using LLMs to\nsuggest unsupervised AD models. Through experiments with different datasets, we\nfind that LLMs can work well in zero-shot AD, that carefully designed\naugmentation methods are useful, and that explaining model selection for\nspecific datasets remains challenging. Based on these results, we outline six\nfuture research directions on LLMs for AD.",
      "tldr_zh": "本文引入 AD-LLM，这是第一个基准，用于评估大型语言模型（LLMs）在自然语言处理（NLP）异常检测（AD）中的潜力，包括欺诈检测和医疗诊断等应用。研究评估了三个关键任务：（i）零样本检测（zero-shot detection），利用 LLMs 的预训练知识进行无监督 AD；（ii）数据增强（data augmentation），通过生成合成数据和类别描述来提升 AD 模型性能；以及（iii）模型选择（model selection），使用 LLMs 建议无监督 AD 模型。实验结果表明，LLMs 在零样本 AD 中表现良好，精心设计的增强方法有效，但为特定数据集解释模型选择仍面临挑战。基于这些发现，论文概述了六个未来研究方向，以进一步探索 LLMs 在 AD 领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11142v3",
      "published_date": "2024-12-15 10:22:14 UTC",
      "updated_date": "2025-05-15 20:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:47.147162"
    },
    {
      "arxiv_id": "2412.11139v1",
      "title": "ViSymRe: Vision-guided Multimodal Symbolic Regression",
      "title_zh": "ViSymRe：视觉引导的多模态符号回归",
      "authors": [
        "Da Li",
        "Junping Yin",
        "Jin Xu",
        "Xinxin Li",
        "Juan Zhang"
      ],
      "abstract": "Symbolic regression automatically searches for mathematical equations to\nreveal underlying mechanisms within datasets, offering enhanced\ninterpretability compared to black box models. Traditionally, symbolic\nregression has been considered to be purely numeric-driven, with insufficient\nattention given to the potential contributions of visual information in\naugmenting this process. When dealing with high-dimensional and complex\ndatasets, existing symbolic regression models are often inefficient and tend to\ngenerate overly complex equations, making subsequent mechanism analysis\ncomplicated. In this paper, we propose the vision-guided multimodal symbolic\nregression model, called ViSymRe, that systematically explores how visual\ninformation can improve various metrics of symbolic regression. Compared to\ntraditional models, our proposed model has the following innovations: (1) It\nintegrates three modalities: vision, symbol and numeric to enhance symbolic\nregression, enabling the model to benefit from the strengths of each modality;\n(2) It establishes a meta-learning framework that can learn from historical\nexperiences to efficiently solve new symbolic regression problems; (3) It\nemphasizes the simplicity and structural rationality of the equations rather\nthan merely numerical fitting. Extensive experiments show that our proposed\nmodel exhibits strong generalization capability and noise resistance. The\nequations it generates outperform state-of-the-art numeric-only baselines in\nterms of fitting effect, simplicity and structural accuracy, thus being able to\nfacilitate accurate mechanism analysis and the development of theoretical\nmodels.",
      "tldr_zh": "本研究提出ViSymRe，一种视觉引导的多模态Symbolic Regression模型，旨在通过整合视觉、符号和数字三种模态来提升符号回归的效率和可解释性，解决传统模型在处理高维复杂数据集时存在的效率低下和方程复杂度过高问题。ViSymRe的创新包括：建立元学习框架以从历史经验中学习快速解决新问题，以及强调方程的简单性和结构合理性而非单纯的数值拟合。实验结果显示，该模型表现出色，具有强大的泛化能力和抗噪性，其生成的方程在拟合效果、简单性和结构准确性上优于现有数字-only基准，从而促进机制分析和理论模型的开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11139v1",
      "published_date": "2024-12-15 10:05:31 UTC",
      "updated_date": "2024-12-15 10:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:01:57.205402"
    },
    {
      "arxiv_id": "2412.11138v1",
      "title": "Safe Reinforcement Learning using Finite-Horizon Gradient-based Estimation",
      "title_zh": "基于有限地平线梯度估计的安全强化学习",
      "authors": [
        "Juntao Dai",
        "Yaodong Yang",
        "Qian Zheng",
        "Gang Pan"
      ],
      "abstract": "A key aspect of Safe Reinforcement Learning (Safe RL) involves estimating the\nconstraint condition for the next policy, which is crucial for guiding the\noptimization of safe policy updates. However, the existing Advantage-based\nEstimation (ABE) method relies on the infinite-horizon discounted advantage\nfunction. This dependence leads to catastrophic errors in finite-horizon\nscenarios with non-discounted constraints, resulting in safety-violation\nupdates. In response, we propose the first estimation method for finite-horizon\nnon-discounted constraints in deep Safe RL, termed Gradient-based Estimation\n(GBE), which relies on the analytic gradient derived along trajectories. Our\ntheoretical and empirical analyses demonstrate that GBE can effectively\nestimate constraint changes over a finite horizon. Constructing a surrogate\noptimization problem with GBE, we developed a novel Safe RL algorithm called\nConstrained Gradient-based Policy Optimization (CGPO). CGPO identifies feasible\noptimal policies by iteratively resolving sub-problems within trust regions.\nOur empirical results reveal that CGPO, unlike baseline algorithms,\nsuccessfully estimates the constraint functions of subsequent policies, thereby\nensuring the efficiency and feasibility of each update.",
      "tldr_zh": "本研究针对Safe Reinforcement Learning (Safe RL)中现有Advantage-based Estimation (ABE)方法的局限性，该方法依赖无限期折扣优势函数，导致在有限期非折扣约束场景下出现安全违规问题。论文提出了一种新方法Gradient-based Estimation (GBE)，通过轨迹的解析梯度来有效估计有限期约束变化，并进行理论和实证分析以验证其可靠性。基于GBE，作者开发了Constrained Gradient-based Policy Optimization (CGPO)算法，该算法通过在信任区域内迭代解决子问题，实现可行最优策略的识别。实验结果表明，CGPO比基线算法更高效，能准确估计后续策略的约束函数，确保更新过程的安全性和可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11138v1",
      "published_date": "2024-12-15 10:05:23 UTC",
      "updated_date": "2024-12-15 10:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:02:08.935050"
    },
    {
      "arxiv_id": "2412.11137v1",
      "title": "Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners",
      "title_zh": "翻译失败",
      "authors": [
        "Hezha O. Rasul",
        "Dlzar D. Ghafour",
        "Bakhtyar K. Aziz",
        "Bryar A. Hassan",
        "Tarik A. Rashid",
        "Arif Kivrak"
      ],
      "abstract": "The drug development process is a critical challenge in the pharmaceutical\nindustry due to its time-consuming nature and the need to discover new drug\npotentials to address various ailments. The initial step in drug development,\ndrug target identification, often consumes considerable time. While valid,\ntraditional methods such as in vivo and in vitro approaches are limited in\ntheir ability to analyze vast amounts of data efficiently, leading to wasteful\noutcomes. To expedite and streamline drug development, an increasing reliance\non computer-aided drug design (CADD) approaches has merged. These sophisticated\nin silico methods offer a promising avenue for efficiently identifying viable\ndrug candidates, thus providing pharmaceutical firms with significant\nopportunities to uncover new prospective drug targets. The main goal of this\nwork is to review in silico methods used in the drug development process with a\nfocus on identifying therapeutic targets linked to specific diseases at the\ngenetic or protein level. This article thoroughly discusses A-to-Z in silico\ntechniques, which are essential for identifying the targets of bioactive\ncompounds and their potential therapeutic effects. This review intends to\nimprove drug discovery processes by illuminating the state of these\ncutting-edge approaches, thereby maximizing the effectiveness and duration of\nclinical trials for novel drug target investigation.",
      "tldr_zh": "该论文审视了药物开发过程的挑战，特别是药物靶点识别耗时的问题，并强调传统 in vivo 和 in vitro 方法在处理大量数据时的局限性。作者介绍了计算机辅助药物设计 (CADD) 和各种 in silico 技术，作为加速药物发现的解决方案，涵盖从 A 到 Z 的方法，用于识别与特定疾病相关的遗传或蛋白质水平的治疗靶点。通过这一回顾，论文旨在优化药物发现流程，提高临床试验的有效性和效率，为初学者提供全面指导。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "https://link.springer.com/article/10.1007/s12010-024-05110-2",
      "pdf_url": "http://arxiv.org/pdf/2412.11137v1",
      "published_date": "2024-12-15 10:02:38 UTC",
      "updated_date": "2024-12-15 10:02:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:02:20.251890"
    },
    {
      "arxiv_id": "2412.11122v2",
      "title": "Paid with Models: Optimal Contract Design for Collaborative Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bingchen Wang",
        "Zhaoxuan Wu",
        "Fusheng Liu",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Collaborative machine learning (CML) provides a promising paradigm for\ndemocratizing advanced technologies by enabling cost-sharing among\nparticipants. However, the potential for rent-seeking behaviors among parties\ncan undermine such collaborations. Contract theory presents a viable solution\nby rewarding participants with models of varying accuracy based on their\ncontributions. However, unlike monetary compensation, using models as rewards\nintroduces unique challenges, particularly due to the stochastic nature of\nthese rewards when contribution costs are privately held information. This\npaper formalizes the optimal contracting problem within CML and proposes a\ntransformation that simplifies the non-convex optimization problem into one\nthat can be solved through convex optimization algorithms. We conduct a\ndetailed analysis of the properties that an optimal contract must satisfy when\nmodels serve as the rewards, and we explore the potential benefits and welfare\nimplications of these contract-driven CML schemes through numerical\nexperiments.",
      "tldr_zh": "该论文探讨了协作机器学习 (CML) 中租求行为的潜在问题，并提出了一种使用模型作为奖励的最优合同设计方法，以激励参与者基于贡献进行合作。该方法形式化了合同问题，通过一个转换技巧将非凸优化问题简化为可通过凸优化算法解决的形式，同时考虑了贡献成本私有信息带来的随机性。研究分析了最优合同的必要属性，并通过数值实验证明了这种合同驱动的CML方案在提升福利和益处方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "econ.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11122v2",
      "published_date": "2024-12-15 08:55:16 UTC",
      "updated_date": "2024-12-31 10:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:02:32.923668"
    },
    {
      "arxiv_id": "2412.11120v2",
      "title": "Latent Reward: LLM-Empowered Credit Assignment in Episodic Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Qu",
        "Yuhang Jiang",
        "Boyuan Wang",
        "Yixiu Mao",
        "Cheems Wang",
        "Chang Liu",
        "Xiangyang Ji"
      ],
      "abstract": "Reinforcement learning (RL) often encounters delayed and sparse feedback in\nreal-world applications, even with only episodic rewards. Previous approaches\nhave made some progress in reward redistribution for credit assignment but\nstill face challenges, including training difficulties due to redundancy and\nambiguous attributions stemming from overlooking the multifaceted nature of\nmission performance evaluation. Hopefully, Large Language Model (LLM)\nencompasses fruitful decision-making knowledge and provides a plausible tool\nfor reward redistribution. Even so, deploying LLM in this case is non-trivial\ndue to the misalignment between linguistic knowledge and the symbolic form\nrequirement, together with inherent randomness and hallucinations in inference.\nTo tackle these issues, we introduce LaRe, a novel LLM-empowered symbolic-based\ndecision-making framework, to improve credit assignment. Key to LaRe is the\nconcept of the Latent Reward, which works as a multi-dimensional performance\nevaluation, enabling more interpretable goal attainment from various\nperspectives and facilitating more effective reward redistribution. We examine\nthat semantically generated code from LLM can bridge linguistic knowledge and\nsymbolic latent rewards, as it is executable for symbolic objects. Meanwhile,\nwe design latent reward self-verification to increase the stability and\nreliability of LLM inference. Theoretically, reward-irrelevant redundancy\nelimination in the latent reward benefits RL performance from more accurate\nreward estimation. Extensive experimental results witness that LaRe (i)\nachieves superior temporal credit assignment to SOTA methods, (ii) excels in\nallocating contributions among multiple agents, and (iii) outperforms policies\ntrained with ground truth rewards for certain tasks.",
      "tldr_zh": "该论文针对强化学习（RL）中延迟和稀疏反馈的问题，提出LaRe框架，利用Large Language Model (LLM)增强周期性RL中的信用分配（Credit Assignment）。LaRe的核心概念是Latent Reward，作为多维性能评估，通过LLM生成的语义代码桥接语言知识与符号形式，并引入Latent Reward自验证机制来提高推理的稳定性和可靠性。实验结果显示，LaRe在时间信用分配上优于SOTA方法，在多代理贡献分配中表现出色，甚至在某些任务中超越使用真实奖励训练的策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11120v2",
      "published_date": "2024-12-15 08:51:14 UTC",
      "updated_date": "2025-01-09 11:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:02:45.023429"
    },
    {
      "arxiv_id": "2412.11119v1",
      "title": "Impact of Adversarial Attacks on Deep Learning Model Explainability",
      "title_zh": "对抗性攻击对深度学习模型可解释性的影响",
      "authors": [
        "Gazi Nazia Nur",
        "Mohammad Ahnaf Sadat"
      ],
      "abstract": "In this paper, we investigate the impact of adversarial attacks on the\nexplainability of deep learning models, which are commonly criticized for their\nblack-box nature despite their capacity for autonomous feature extraction. This\nblack-box nature can affect the perceived trustworthiness of these models. To\naddress this, explainability techniques such as GradCAM, SmoothGrad, and LIME\nhave been developed to clarify model decision-making processes. Our research\nfocuses on the robustness of these explanations when models are subjected to\nadversarial attacks, specifically those involving subtle image perturbations\nthat are imperceptible to humans but can significantly mislead models. For\nthis, we utilize attack methods like the Fast Gradient Sign Method (FGSM) and\nthe Basic Iterative Method (BIM) and observe their effects on model accuracy\nand explanations. The results reveal a substantial decline in model accuracy,\nwith accuracies dropping from 89.94% to 58.73% and 45.50% under FGSM and BIM\nattacks, respectively. Despite these declines in accuracy, the explanation of\nthe models measured by metrics such as Intersection over Union (IoU) and Root\nMean Square Error (RMSE) shows negligible changes, suggesting that these\nmetrics may not be sensitive enough to detect the presence of adversarial\nperturbations.",
      "tldr_zh": "本研究探讨了对抗攻击对深度学习模型可解释性的影响，旨在解决模型的黑盒特性问题。研究使用了GradCAM、SmoothGrad和LIME等可解释性技术，并通过Fast Gradient Sign Method (FGSM)和Basic Iterative Method (BIM)攻击来模拟图像微扰，导致模型准确率从89.94%大幅下降至58.73%和45.50%。结果显示，虽然准确率显著降低，但解释指标如Intersection over Union (IoU)和Root Mean Square Error (RMSE)变化微小，这表明现有指标可能不足以检测对抗扰动，从而质疑了模型可解释性的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages with reference included, submitted to a journal",
      "pdf_url": "http://arxiv.org/pdf/2412.11119v1",
      "published_date": "2024-12-15 08:41:37 UTC",
      "updated_date": "2024-12-15 08:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:02:55.977705"
    },
    {
      "arxiv_id": "2412.11104v1",
      "title": "ABC3: Active Bayesian Causal Inference with Cohn Criteria in Randomized Experiments",
      "title_zh": "翻译失败",
      "authors": [
        "Taehun Cha",
        "Donghun Lee"
      ],
      "abstract": "In causal inference, randomized experiment is a de facto method to overcome\nvarious theoretical issues in observational study. However, the experimental\ndesign requires expensive costs, so an efficient experimental design is\nnecessary. We propose ABC3, a Bayesian active learning policy for causal\ninference. We show a policy minimizing an estimation error on conditional\naverage treatment effect is equivalent to minimizing an integrated posterior\nvariance, similar to Cohn criteria \\citep{cohn1994active}. We theoretically\nprove ABC3 also minimizes an imbalance between the treatment and control groups\nand the type 1 error probability. Imbalance-minimizing characteristic is\nespecially notable as several works have emphasized the importance of achieving\nbalance. Through extensive experiments on real-world data sets, ABC3 achieves\nthe highest efficiency, while empirically showing the theoretical results hold.",
      "tldr_zh": "本论文提出 ABC3，一种基于 Bayesian 主动学习策略的因果推断方法，旨在优化随机实验设计以最小化条件平均治疗效果（CATE）的估计误差，并与 Cohn criteria 相关联。ABC3 通过最小化后验方差来实现这一目标，同时理论证明其能降低治疗组和对照组之间的不平衡以及第一类错误概率，这种平衡特性强调了其在实验设计中的重要性。在真实数据集上的广泛实验中，ABC3 展现了最高的效率，并验证了其理论结果的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11104v1",
      "published_date": "2024-12-15 08:00:57 UTC",
      "updated_date": "2024-12-15 08:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:04:52.006850"
    },
    {
      "arxiv_id": "2412.11088v1",
      "title": "Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Gutierrez",
        "Irene Hou",
        "Jihye Lee",
        "Kenneth Angelikas",
        "Owen Man",
        "Sophia Mettille",
        "James Prather",
        "Paul Denny",
        "Stephen MacNeil"
      ],
      "abstract": "Recent advancements in generative AI systems have raised concerns about\nacademic integrity among educators. Beyond excelling at solving programming\nproblems and text-based multiple-choice questions, recent research has also\nfound that large multimodal models (LMMs) can solve Parsons problems based only\non an image. However, such problems are still inherently text-based and rely on\nthe capabilities of the models to convert the images of code blocks to their\ncorresponding text. In this paper, we further investigate the capabilities of\nLMMs to solve graph and tree data structure problems based only on images. To\nachieve this, we computationally construct and evaluate a novel benchmark\ndataset comprising 9,072 samples of diverse graph and tree data structure tasks\nto assess the performance of the GPT-4o, GPT-4v, Gemini 1.5 Pro, Gemini 1.5\nFlash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT-4o and Gemini\n1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved\n87.6% accuracy on tree samples, while Gemini 1.5 Flash, achieved 56.2% accuracy\non graph samples. Our findings highlight the influence of structural and visual\nvariations on model performance. This research not only introduces an LMM\nbenchmark to facilitate replication and further exploration but also\nunderscores the potential of LMMs in solving complex computing problems, with\nimportant implications for pedagogy and assessment practices.",
      "tldr_zh": "本研究探讨大型多模态模型（LMMs）在基于图像的图和树数据结构问题上的解决能力，扩展了现有AI在编程领域的评估。研究者构建了一个包含9,072个样本的基准数据集，用于测试GPT-4o、GPT-4v、Gemini 1.5 Pro、Gemini 1.5 Flash、Gemini 1.0 Pro Vision和Claude 3等模型的表现。结果显示，GPT-4o在树问题上达到87.6%的准确率，而Gemini 1.5 Flash在图问题上达到56.2%的准确率，突显结构和视觉变化对性能的影响。该工作不仅提供了一个可复制的LMMs基准，还强调了这些模型在复杂计算问题上的潜力，对教育评估实践具有重要启示。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "I.2.10; K.3.2"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures, to be published in ACE 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11088v1",
      "published_date": "2024-12-15 07:15:19 UTC",
      "updated_date": "2024-12-15 07:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:03:22.631751"
    },
    {
      "arxiv_id": "2412.15252v1",
      "title": "NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulhady Abas Abdullah",
        "Srwa Hasan Abdulla",
        "Dalia Mohammad Toufiq",
        "Halgurd S. Maghdid",
        "Tarik A. Rashid",
        "Pakshan F. Farho",
        "Shadan Sh. Sabr",
        "Akar H. Taher",
        "Darya S. Hamad",
        "Hadi Veisi",
        "Aras T. Asaad"
      ],
      "abstract": "Nowadays, Natural Language Processing (NLP) is an important tool for most\npeople's daily life routines, ranging from understanding speech, translation,\nnamed entity recognition (NER), and text categorization, to generative text\nmodels such as ChatGPT. Due to the existence of big data and consequently large\ncorpora for widely used languages like English, Spanish, Turkish, Persian, and\nmany more, these applications have been developed accurately. However, the\nKurdish language still requires more corpora and large datasets to be included\nin NLP applications. This is because Kurdish has a rich linguistic structure,\nvaried dialects, and a limited dataset, which poses unique challenges for\nKurdish NLP (KNLP) application development. While several studies have been\nconducted in KNLP for various applications, Kurdish NER (KNER) remains a\nchallenge for many KNLP tasks, including text analysis and classification. In\nthis work, we address this limitation by proposing a methodology for\nfine-tuning the pre-trained RoBERTa model for KNER. To this end, we first\ncreate a Kurdish corpus, followed by designing a modified model architecture\nand implementing the training procedures. To evaluate the trained model, a set\nof experiments is conducted to demonstrate the performance of the KNER model\nusing different tokenization methods and trained models. The experimental\nresults show that fine-tuned RoBERTa with the SentencePiece tokenization method\nsubstantially improves KNER performance, achieving a 12.8% improvement in\nF1-score compared to traditional models, and consequently establishes a new\nbenchmark for KNLP.",
      "tldr_zh": "这篇论文针对低资源语言的命名实体识别（NER）问题，提出了一种微调预训练模型 RoBERTa 的方法，以提升库尔德语 NER（KNER）的性能。作者首先创建了库尔德语语料库，并设计了修改后的模型架构，结合不同的分词方法（如 SentencePiece）进行训练和实验。结果显示，微调 RoBERTa 模型在 F1-score 上比传统模型提高了 12.8%，为库尔德语 NLP（KNLP）应用设定了新基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15252v1",
      "published_date": "2024-12-15 07:07:17 UTC",
      "updated_date": "2024-12-15 07:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:03:32.672680"
    },
    {
      "arxiv_id": "2412.11085v1",
      "title": "GraphMoRE: Mitigating Topological Heterogeneity via Mixture of Riemannian Experts",
      "title_zh": "GraphMoRE：通过黎曼专家混合缓解拓扑异质性",
      "authors": [
        "Zihao Guo",
        "Qingyun Sun",
        "Haonan Yuan",
        "Xingcheng Fu",
        "Min Zhou",
        "Yisen Gao",
        "Jianxin Li"
      ],
      "abstract": "Real-world graphs have inherently complex and diverse topological patterns,\nknown as topological heterogeneity. Most existing works learn graph\nrepresentation in a single constant curvature space that is insufficient to\nmatch the complex geometric shapes, resulting in low-quality embeddings with\nhigh distortion. This also constitutes a critical challenge for graph\nfoundation models, which are expected to uniformly handle a wide variety of\ndiverse graph data. Recent studies have indicated that product manifold gains\nthe possibility to address topological heterogeneity. However, the product\nmanifold is still homogeneous, which is inadequate and inflexible for\nrepresenting the mixed heterogeneous topology. In this paper, we propose a\nnovel Graph Mixture of Riemannian Experts (GraphMoRE) framework to effectively\ntackle topological heterogeneity by personalized fine-grained topology geometry\npattern preservation. Specifically, to minimize the embedding distortion, we\npropose a topology-aware gating mechanism to select the optimal embedding space\nfor each node. By fusing the outputs of diverse Riemannian experts with learned\ngating weights, we construct personalized mixed curvature spaces for nodes,\neffectively embedding the graph into a heterogeneous manifold with varying\ncurvatures at different points. Furthermore, to fairly measure pairwise\ndistances between different embedding spaces, we present a concise and\neffective alignment strategy. Extensive experiments on real-world and synthetic\ndatasets demonstrate that our method achieves superior performance with lower\ndistortion, highlighting its potential for modeling complex graphs with\ntopological heterogeneity, and providing a novel architectural perspective for\ngraph foundation models.",
      "tldr_zh": "该论文提出GraphMoRE框架，通过Mixture of Riemannian Experts来缓解图谱中的topological heterogeneity问题，该问题源于现有方法在单一曲率空间学习图表示导致嵌入扭曲高。GraphMoRE采用topology-aware gating mechanism为每个节点选择最佳嵌入空间，并融合Riemannian experts的输出，构建个性化混合曲率空间，从而实现细粒度拓扑几何模式的精确保留。此外，该框架引入alignment strategy来公平测量不同嵌入空间的距离。实验在真实和合成数据集上证明，GraphMoRE显著提升了性能并降低了嵌入扭曲，为图基础模型提供了一种新型架构视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Main Technical Track of the 39th Annual AAAI\n  Conference on Artificial Intelligence (AAAI-2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11085v1",
      "published_date": "2024-12-15 06:52:40 UTC",
      "updated_date": "2024-12-15 06:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:03:44.814783"
    },
    {
      "arxiv_id": "2412.11068v1",
      "title": "RecSys Arena: Pair-wise Recommender System Evaluation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuo Wu",
        "Qinglin Jia",
        "Chuhan Wu",
        "Zhaocheng Du",
        "Shuai Wang",
        "Zan Wang",
        "Zhenhua Dong"
      ],
      "abstract": "Evaluating the quality of recommender systems is critical for algorithm\ndesign and optimization. Most evaluation methods are computed based on offline\nmetrics for quick algorithm evolution, since online experiments are usually\nrisky and time-consuming. However, offline evaluation usually cannot fully\nreflect users' preference for the outcome of different recommendation\nalgorithms, and the results may not be consistent with online A/B test.\nMoreover, many offline metrics such as AUC do not offer sufficient information\nfor comparing the subtle differences between two competitive recommender\nsystems in different aspects, which may lead to substantial performance\ndifferences in long-term online serving. Fortunately, due to the strong\ncommonsense knowledge and role-play capability of large language models (LLMs),\nit is possible to obtain simulated user feedback on offline recommendation\nresults. Motivated by the idea of LLM Chatbot Arena, in this paper we present\nthe idea of RecSys Arena, where the recommendation results given by two\ndifferent recommender systems in each session are evaluated by an LLM judger to\nobtain fine-grained evaluation feedback. More specifically, for each sample we\nuse LLM to generate a user profile description based on user behavior history\nor off-the-shelf profile features, which is used to guide LLM to play the role\nof this user and evaluate the relative preference for two recommendation\nresults generated by different models. Through extensive experiments on two\nrecommendation datasets in different scenarios, we demonstrate that many\ndifferent LLMs not only provide general evaluation results that are highly\nconsistent with canonical offline metrics, but also provide rich insight in\nmany subjective aspects. Moreover, it can better distinguish different\nalgorithms with comparable performance in terms of AUC and nDCG.",
      "tldr_zh": "本论文提出 RecSys Arena，一种基于大型语言模型 (LLMs) 的配对推荐系统评估框架，用于解决传统离线指标（如 AUC 和 nDCG）无法充分反映用户偏好和在线 A/B 测试不一致的问题。该框架让 LLM 模拟用户角色，通过生成用户配置文件并比较两个推荐系统的结果，提供细粒度的相对偏好反馈。在两个推荐数据集上的实验显示，RecSys Arena 不仅与经典离线指标高度一致，还能更好地区分性能相似的算法，并揭示更多主观方面的洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11068v1",
      "published_date": "2024-12-15 05:57:36 UTC",
      "updated_date": "2024-12-15 05:57:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:03:56.828183"
    },
    {
      "arxiv_id": "2412.11063v1",
      "title": "LAW: Legal Agentic Workflows for Custody and Fund Services Contracts",
      "title_zh": "LAW：针对托管和基金服务合同的法律",
      "authors": [
        "William Watson",
        "Nicole Cho",
        "Nishan Srishankar",
        "Zhen Zeng",
        "Lucas Cecchi",
        "Daniel Scott",
        "Suchetha Siddagangappa",
        "Rachneet Kaur",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "Legal contracts in the custody and fund services domain govern critical\naspects such as key provider responsibilities, fee schedules, and\nindemnification rights. However, it is challenging for an off-the-shelf Large\nLanguage Model (LLM) to ingest these contracts due to the lengthy unstructured\nstreams of text, limited LLM context windows, and complex legal jargon. To\naddress these challenges, we introduce LAW (Legal Agentic Workflows for Custody\nand Fund Services Contracts). LAW features a modular design that responds to\nuser queries by orchestrating a suite of domain-specific tools and text agents.\nOur experiments demonstrate that LAW, by integrating multiple specialized\nagents and tools, significantly outperforms the baseline. LAW excels\nparticularly in complex tasks such as calculating a contract's termination\ndate, surpassing the baseline by 92.9% points. Furthermore, LAW offers a\ncost-effective alternative to traditional fine-tuned legal LLMs by leveraging\nreusable, domain-specific tools.",
      "tldr_zh": "这篇论文针对托管和基金服务合同的法律文本处理挑战（如冗长文本、LLM上下文限制和复杂法律术语），引入了LAW（Legal Agentic Workflows）框架。LAW采用模块化设计，通过整合多个领域特定工具和文本代理来响应用户查询，实现高效的合同分析。实验结果显示，LAW在复杂任务上显著优于基线模型，例如计算合同终止日期的准确率提高了92.9%，并提供比传统微调LLM更具成本效益的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at The 31st International Conference on Computational\n  Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11063v1",
      "published_date": "2024-12-15 05:40:57 UTC",
      "updated_date": "2024-12-15 05:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:04:08.823727"
    },
    {
      "arxiv_id": "2412.11057v1",
      "title": "Set-Valued Sensitivity Analysis of Deep Neural Networks",
      "title_zh": "深度神经网络",
      "authors": [
        "Xin Wang",
        "Feilong Wang",
        "Xuegang Ban"
      ],
      "abstract": "This paper proposes a sensitivity analysis framework based on set valued\nmapping for deep neural networks (DNN) to understand and compute how the\nsolutions (model weights) of DNN respond to perturbations in the training data.\nAs a DNN may not exhibit a unique solution (minima) and the algorithm of\nsolving a DNN may lead to different solutions with minor perturbations to input\ndata, we focus on the sensitivity of the solution set of DNN, instead of\nstudying a single solution. In particular, we are interested in the expansion\nand contraction of the set in response to data perturbations. If the change of\nsolution set can be bounded by the extent of the data perturbation, the model\nis said to exhibit the Lipschitz like property. This \"set-to-set\" analysis\napproach provides a deeper understanding of the robustness and reliability of\nDNNs during training. Our framework incorporates both isolated and non-isolated\nminima, and critically, does not require the assumption that the Hessian of\nloss function is non-singular. By developing set-level metrics such as distance\nbetween sets, convergence of sets, derivatives of set-valued mapping, and\nstability across the solution set, we prove that the solution set of the Fully\nConnected Neural Network holds Lipschitz-like properties. For general neural\nnetworks (e.g., Resnet), we introduce a graphical-derivative-based method to\nestimate the new solution set following data perturbation without retraining.",
      "tldr_zh": "这篇论文提出了一种基于集合值映射的敏感性分析框架，用于评估深度神经网络 (DNN) 的模型权重对训练数据扰动的响应，重点关注解决方案集的扩展和收缩，而不是单个解决方案。框架引入集合级指标，如集合间距离、集合收敛和集合值映射的导数，并证明全连接神经网络的解决方案集具有类似 Lipschitz 属性，而无需假设损失函数的 Hessian 非奇异。对于一般神经网络如 ResNet，作者开发了一种基于图形导数的方法，能够估计数据扰动后的新解决方案集，而无需重新训练，从而提升了 DNN 的鲁棒性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11057v1",
      "published_date": "2024-12-15 05:22:38 UTC",
      "updated_date": "2024-12-15 05:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:04:21.156054"
    },
    {
      "arxiv_id": "2412.11053v1",
      "title": "NITRO: LLM Inference on Intel Laptop NPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Fei",
        "Mohamed S. Abdelfattah"
      ],
      "abstract": "Large Language Models (LLMs) have become essential tools in natural language\nprocessing, finding large usage in chatbots such as ChatGPT and Gemini, and are\na central area of research. A particular area of interest includes designing\nhardware specialized for these AI applications, with one such example being the\nneural processing unit (NPU). In 2023, Intel released the Intel Core Ultra\nprocessor with codename Meteor Lake, featuring a CPU, GPU, and NPU\nsystem-on-chip. However, official software support for the NPU through Intel's\nOpenVINO framework is limited to static model inference. The dynamic nature of\nautoregressive token generation in LLMs is therefore not supported out of the\nbox. To address this shortcoming, we present NITRO (NPU Inference for\nTransformers Optimization), a Python-based framework built on top of OpenVINO\nto support text and chat generation on NPUs. In this paper, we discuss in\ndetail the key modifications made to the transformer architecture to enable\ninference, some performance benchmarks, and future steps towards improving the\npackage. The code repository for NITRO can be found here:\nhttps://github.com/abdelfattah-lab/nitro.",
      "tldr_zh": "这篇论文介绍了NITRO框架，这是一个基于Python的工具，用于在Intel笔记本的神经处理单元(NPU)上进行大型语言模型(LLM)推理。论文指出，Intel的OpenVINO框架仅支持静态模型推理，无法处理LLM的动态autoregressive token生成，因此NITRO通过修改transformer架构和集成OpenVINO来实现文本和聊天生成的功能。实验结果展示了NITRO的性能基准测试，并讨论了未来的优化步骤。该框架的开源代码可在GitHub上获取，为LLM在专用硬件上的部署提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11053v1",
      "published_date": "2024-12-15 05:15:54 UTC",
      "updated_date": "2024-12-15 05:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:05:03.297170"
    },
    {
      "arxiv_id": "2412.15251v1",
      "title": "AgentPS: Agentic Process Supervision for Multi-modal Content Quality Assurance through Multi-round QA",
      "title_zh": "翻译失败",
      "authors": [
        "Gorden Liu",
        "Yu Sun",
        "Ruixiao Sun",
        "Xin Dong",
        "Hongyu Xiong"
      ],
      "abstract": "The advanced processing and reasoning capabilities of multimodal large\nlanguage models (MLLMs) have driven substantial progress in vision-language\n(VL) understanding tasks. However, while effective for tasks governed by\nstraightforward logic, MLLMs often encounter challenges when reasoning over\ncomplex, interdependent logic structures. To address this limitation, we\nintroduce \\textit{AgentPS}, a novel framework that integrates Agentic Process\nSupervision into MLLMs via multi-round question answering during fine-tuning.\n\\textit{AgentPS} demonstrates significant performance improvements over\nbaseline MLLMs on proprietary TikTok datasets, due to its integration of\nprocess supervision and structured sequential reasoning. Furthermore, we show\nthat replacing human-annotated labels with LLM-generated labels retains much of\nthe performance gain, highlighting the framework's practical scalability in\nindustrial applications. These results position \\textit{AgentPS} as a highly\neffective and efficient architecture for multimodal classification tasks. Its\nadaptability and scalability, especially when enhanced by automated annotation\ngeneration, make it a powerful tool for handling large-scale, real-world\nchallenges.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)在处理复杂、相互依赖逻辑结构时的挑战，提出AgentPS框架，通过整合Agentic Process Supervision和多轮问答(multi-round QA)于微调过程中，提升模型的推理能力。在TikTok专有数据集上，AgentPS相较基线模型实现了显著性能改进，主要得益于过程监督和结构化顺序推理。此外，使用LLM生成的标签代替人工标注后，框架仍保留了大部分性能提升，展示了其在工业应用中的高效性和可扩展性，使其成为处理大规模多模态分类任务的强大工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15251v1",
      "published_date": "2024-12-15 04:58:00 UTC",
      "updated_date": "2024-12-15 04:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:05:14.904701"
    },
    {
      "arxiv_id": "2412.11050v2",
      "title": "RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yujin Wang",
        "Quanfeng Liu",
        "Jiaqi Fan",
        "Jinlong Hong",
        "Hongqing Chu",
        "Mengjian Tian",
        "Bingzhao Gao",
        "Hong Chen"
      ],
      "abstract": "Understanding and addressing corner cases is essential for ensuring the\nsafety and reliability of autonomous driving systems. Vision-language models\n(VLMs) play a crucial role in enhancing scenario comprehension, yet they face\nsignificant challenges, such as hallucination and insufficient real-world\ngrounding, which compromise their performance in critical driving scenarios. In\nthis work, RAC3, a novel framework designed to enhance the performance of VLMs\nin corner case comprehension, is proposed. RAC3 integrates a frequency-spatial\nfusion (FSF) image encoder, cross-modal alignment fine-tuning with hard and\nsemi-hard negative mining, and a fast querying pipeline based on KMeans\nclustering and hierarchical navigable small world (HNSW) indexing. A multimodal\nchain-of-thought (CoT) prompting strategy to guide analogical reasoning and\nreduce hallucinations during inference is introduced. Moreover, an update\nmechanism is integrated into RAC3 to ensure continual learning within the\nframework. Extensive experiments on the CODA and NuScenes datasets demonstrate\nthat RAC3 significantly improves corner case comprehension across multiple\ndownstream tasks. Compared to prior state-of-the-art methods, RAC3 achieves the\nhighest final score of 74.46 on the CODA-LM benchmark and shows consistent\nperformance gains when integrated with end-to-end frameworks like DriveLM.\nThese results demonstrate the effectiveness of retrieval-augmented strategies\nand cross-modal alignment for safer and more interpretable autonomous driving.",
      "tldr_zh": "本研究提出 RAC3 框架，用于提升视觉语言模型 (VLMs) 在自动驾驶边界情况 (corner cases) 理解中的性能，解决幻觉和真实世界基础不足等问题。RAC3 整合了 frequency-spatial fusion (FSF) 图像编码器、跨模态对齐微调（使用 hard 和 semi-hard negative mining）、基于 KMeans 聚类和 hierarchical navigable small world (HNSW) 索引的快速查询管道，以及多模态 chain-of-thought (CoT) 提示策略，以引导类比推理并减少幻觉，同时加入更新机制支持持续学习。在 CODA 和 NuScenes 数据集的实验中，RAC3 在 CODA-LM 基准上达到最高分数 74.46，并显著优于现有方法，提升了自动驾驶的安全性和可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11050v2",
      "published_date": "2024-12-15 04:51:30 UTC",
      "updated_date": "2025-04-13 05:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:05:29.681795"
    },
    {
      "arxiv_id": "2412.19819v1",
      "title": "ChipAlign: Instruction Alignment in Large Language Models for Chip Design via Geodesic Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhui Deng",
        "Yunsheng Bai",
        "Haoxing Ren"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have expanded their\napplication across various domains, including chip design, where domain-adapted\nchip models like ChipNeMo have emerged. However, these models often struggle\nwith instruction alignment, a crucial capability for LLMs that involves\nfollowing explicit human directives. This limitation impedes the practical\napplication of chip LLMs, including serving as assistant chatbots for hardware\ndesign engineers. In this work, we introduce ChipAlign, a novel approach that\nutilizes a training-free model merging strategy, combining the strengths of a\ngeneral instruction-aligned LLM with a chip-specific LLM. By considering the\nunderlying manifold in the weight space, ChipAlign employs geodesic\ninterpolation to effectively fuse the weights of input LLMs, producing a merged\nmodel that inherits strong instruction alignment and chip expertise from the\nrespective instruction and chip LLMs. Our results demonstrate that ChipAlign\nsignificantly enhances instruction-following capabilities of existing chip\nLLMs, achieving up to a 26.6% improvement on the IFEval benchmark, while\nmaintaining comparable expertise in the chip domain. This improvement in\ninstruction alignment also translates to notable gains in instruction-involved\nQA tasks, delivering performance enhancements of 3.9% on the OpenROAD QA\nbenchmark and 8.25% on production-level chip QA benchmarks, surpassing\nstate-of-the-art baselines.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在芯片设计领域的指令对齐(instruction alignment)问题，提出了一种名为ChipAlign的无训练模型合并策略。该方法通过测地线插值(geodesic interpolation)在权重空间融合通用指令对齐LLM与芯片特定LLM的优点，从而提升模型的指令遵循能力和芯片专业性。实验结果显示，ChipAlign使现有芯片LLMs在IFEval基准上提升26.6%，并在OpenROAD QA基准上提高3.9%、生产级芯片QA基准上提高8.25%，超越了现有基线。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19819v1",
      "published_date": "2024-12-15 04:21:24 UTC",
      "updated_date": "2024-12-15 04:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:05:38.942553"
    },
    {
      "arxiv_id": "2412.11047v1",
      "title": "Deployment Pipeline from Rockpool to Xylo for Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Zhou",
        "Dylan R. Muir"
      ],
      "abstract": "Deploying Spiking Neural Networks (SNNs) on the Xylo neuromorphic chip via\nthe Rockpool framework represents a significant advancement in achieving\nultra-low-power consumption and high computational efficiency for edge\napplications. This paper details a novel deployment pipeline, emphasizing the\nintegration of Rockpool's capabilities with Xylo's architecture, and evaluates\nthe system's performance in terms of energy efficiency and accuracy. The unique\nadvantages of the Xylo chip, including its digital spiking architecture and\nevent-driven processing model, are highlighted to demonstrate its suitability\nfor real-time, power-sensitive applications.",
      "tldr_zh": "该论文提出了一种从 Rockpool 到 Xylo 的部署管道，用于在边缘计算中部署 Spiking Neural Networks (SNNs)，以实现超低功耗和高计算效率。该管道强调了 Rockpool 框架与 Xylo 芯片架构的整合，利用 Xylo 的数字脉冲架构和事件驱动处理模型，提升系统性能。通过实验评估，该系统在能量效率和准确性方面表现出显著优势，适合实时、低功耗应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11047v1",
      "published_date": "2024-12-15 04:19:10 UTC",
      "updated_date": "2024-12-15 04:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:05:50.645046"
    },
    {
      "arxiv_id": "2412.12201v1",
      "title": "Embracing Large Language Models in Traffic Flow Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yusheng Zhao",
        "Xiao Luo",
        "Haomin Wen",
        "Zhiping Xiao",
        "Wei Ju",
        "Ming Zhang"
      ],
      "abstract": "Traffic flow forecasting aims to predict future traffic flows based on the\nhistorical traffic conditions and the road network. It is an important problem\nin intelligent transportation systems, with a plethora of methods been\nproposed. Existing efforts mainly focus on capturing and utilizing\nspatio-temporal dependencies to predict future traffic flows. Though promising,\nthey fall short in adapting to test-time environmental changes of traffic\nconditions. To tackle this challenge, we propose to introduce large language\nmodels (LLMs) to help traffic flow forecasting and design a novel method named\nLarge Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two\nbranches, capturing different spatio-temporal relations using graph and\nhypergraph structures respectively. The two branches are first pre-trained\nindividually, and during test-time, they yield different predictions. Based on\nthese predictions, a large language model is used to select the most likely\nresult. Then, a ranking loss is applied as the learning objective to enhance\nthe prediction ability of the two branches. Extensive experiments on several\ndatasets demonstrate the effectiveness of the proposed LEAF.",
      "tldr_zh": "该研究针对交通流量预测中现有方法无法适应测试时环境变化的问题，提出了一种新方法LEAF（Large Language Model Enhanced Traffic Flow Predictor）。LEAF采用两个分支分别使用图和超图结构捕捉不同的时空依赖关系，先进行独立预训练，然后通过Large Language Models (LLMs)基于预测结果选择最可能的输出，并应用排名损失作为优化目标。实验在多个数据集上验证了LEAF的有效性，展示了引入LLMs在提升预测适应性和准确性方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12201v1",
      "published_date": "2024-12-15 03:08:28 UTC",
      "updated_date": "2024-12-15 03:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:07:56.243091"
    },
    {
      "arxiv_id": "2501.00016v2",
      "title": "Predicting Crack Nucleation and Propagation in Brittle Materials Using Deep Operator Networks with Diverse Trunk Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Elham Kiyani",
        "Manav Manav",
        "Nikhil Kadivar",
        "Laura De Lorenzis",
        "George Em Karniadakis"
      ],
      "abstract": "Phase-field modeling reformulates fracture problems as energy minimization\nproblems and enables a comprehensive characterization of the fracture process,\nincluding crack nucleation, propagation, merging, and branching, without\nrelying on ad-hoc assumptions. However, the numerical solution of phase-field\nfracture problems is characterized by a high computational cost. To address\nthis challenge, in this paper, we employ a deep neural operator (DeepONet)\nconsisting of a branch network and a trunk network to solve brittle fracture\nproblems. We explore three distinct approaches that vary in their trunk network\nconfigurations. In the first approach, we demonstrate the effectiveness of a\ntwo-step DeepONet, which results in a simplification of the learning task. In\nthe second approach, we employ a physics-informed DeepONet, whereby the\nmathematical expression of the energy is integrated into the trunk network's\nloss to enforce physical consistency. The integration of physics also results\nin a substantially smaller data size needed for training. In the third\napproach, we replace the neural network in the trunk with a Kolmogorov-Arnold\nNetwork and train it without the physics loss. Using these methods, we model\ncrack nucleation in a one-dimensional homogeneous bar under prescribed end\ndisplacements, as well as crack propagation and branching in single\nedge-notched specimens with varying notch lengths subjected to tensile and\nshear loading. We show that the networks predict the solution fields\naccurately, and the error in the predicted fields is localized near the crack.",
      "tldr_zh": "本文提出了一种使用 Deep Operator Networks (DeepONet) 的方法来预测脆性材料的裂纹成核和传播，通过探索三种不同的 trunk 网络架构来解决相场建模（phase-field modeling）的高计算成本问题。第一种架构采用两步 DeepONet 简化学习任务，第二种整合物理信息到 trunk 网络的损失函数中以确保物理一致性和减少训练数据需求，第三种则用 Kolmogorov-Arnold Network 替换 trunk 网络并省去物理损失。实验结果显示，这些方法在模拟一维均质棒的裂纹成核以及单边缺口试样的裂纹传播和分支时，能够准确预测解决方案字段，且错误主要局限于裂纹附近。",
      "categories": [
        "physics.comp-ph",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "25 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00016v2",
      "published_date": "2024-12-15 02:50:30 UTC",
      "updated_date": "2025-04-14 17:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:06:16.258861"
    },
    {
      "arxiv_id": "2412.11026v2",
      "title": "SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zhang",
        "Zhuoling Li",
        "Jun Liu"
      ],
      "abstract": "Dynamic scenes contain intricate spatio-temporal information, crucial for\nmobile robots, UAVs, and autonomous driving systems to make informed decisions.\nParsing these scenes into semantic triplets <Subject-Predicate-Object> for\naccurate Scene Graph Generation (SGG) is highly challenging due to the\nfluctuating spatio-temporal complexity. Inspired by the reasoning capabilities\nof Large Language Models (LLMs), we propose SceneLLM, a novel framework that\nleverages LLMs as powerful scene analyzers for dynamic SGG. Our framework\nintroduces a Video-to-Language (V2L) mapping module that transforms video\nframes into linguistic signals (scene tokens), making the input more\ncomprehensible for LLMs. To better encode spatial information, we devise a\nSpatial Information Aggregation (SIA) scheme, inspired by the structure of\nChinese characters, which encodes spatial data into tokens. Using Optimal\nTransport (OT), we generate an implicit language signal from the frame-level\ntoken sequence that captures the video's spatio-temporal information. To\nfurther improve the LLM's ability to process this implicit linguistic input, we\napply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a\ntransformer-based SGG predictor to decode the LLM's reasoning and predict\nsemantic triplets. Our method achieves state-of-the-art results on the Action\nGenome (AG) benchmark, and extensive experiments show the effectiveness of\nSceneLLM in understanding and generating accurate dynamic scene graphs.",
      "tldr_zh": "该研究提出 SceneLLM 框架，利用 Large Language Models (LLMs) 的推理能力来处理动态场景的复杂时空信息，从而实现动态 Scene Graph Generation (SGG)。框架的关键组件包括 Video-to-Language (V2L) 模块将视频帧转化为语言信号、Spatial Information Aggregation (SIA) 方案编码空间信息，以及 Optimal Transport (OT) 生成隐式语言信号，并通过 Low-Rank Adaptation (LoRA) 微调 LLM 以提升处理能力。最终，使用 transformer-based SGG 预测器解码推理结果并生成语义三元组 <Subject-Predicate-Object>。实验在 Action Genome (AG) 基准上达到最先进性能，证明了 SceneLLM 在准确理解和生成动态场景图方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11026v2",
      "published_date": "2024-12-15 02:41:31 UTC",
      "updated_date": "2025-05-07 03:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:08:28.737572"
    },
    {
      "arxiv_id": "2412.11025v1",
      "title": "From Simple to Professional: A Combinatorial Controllable Image Captioning Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Xinran Wang",
        "Muxi Diao",
        "Baoteng Li",
        "Haiwen Zhang",
        "Kongming Liang",
        "Zhanyu Ma"
      ],
      "abstract": "The Controllable Image Captioning Agent (CapAgent) is an innovative system\ndesigned to bridge the gap between user simplicity and professional-level\noutputs in image captioning tasks. CapAgent automatically transforms\nuser-provided simple instructions into detailed, professional instructions,\nenabling precise and context-aware caption generation. By leveraging multimodal\nlarge language models (MLLMs) and external tools such as object detection tool\nand search engines, the system ensures that captions adhere to specified\nguidelines, including sentiment, keywords, focus, and formatting. CapAgent\ntransparently controls each step of the captioning process, and showcases its\nreasoning and tool usage at every step, fostering user trust and engagement.\nThe project code is available at https://github.com/xin-ran-w/CapAgent.",
      "tldr_zh": "该论文提出了一种名为 CapAgent 的可控图像描述代理系统，旨在将用户简单指令自动转化为详细的专业级图像描述，从而桥接用户友好性和高质量输出。系统利用多模态大语言模型 (MLLMs) 以及外部工具如物体检测工具和搜索引擎，确保生成的描述符合指定指南，包括情感、关键词、焦点和格式。CapAgent 通过透明展示每个步骤的推理和工具使用过程，提升用户信任和参与度，并提供了开源代码以便进一步开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "A technical report. Project: https://github.com/xin-ran-w/CapAgent",
      "pdf_url": "http://arxiv.org/pdf/2412.11025v1",
      "published_date": "2024-12-15 02:37:20 UTC",
      "updated_date": "2024-12-15 02:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:06:39.344892"
    },
    {
      "arxiv_id": "2412.11014v1",
      "title": "PromptV: Leveraging LLM-powered Multi-Agent Prompting for High-quality Verilog Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhendong Mi",
        "Renming Zheng",
        "Haowen Zhong",
        "Yue Sun",
        "Shaoyi Huang"
      ],
      "abstract": "Recent advances in agentic LLMs have demonstrated remarkable automated\nVerilog code generation capabilities. However, existing approaches either\ndemand substantial computational resources or rely on LLM-assisted single-agent\nprompt learning techniques, which we observe for the first time has a\ndegeneration issue - characterized by deteriorating generative performance and\ndiminished error detection and correction capabilities. This paper proposes a\nnovel multi-agent prompt learning framework to address these limitations and\nenhance code generation quality. We show for the first time that multi-agent\narchitectures can effectively mitigate the degeneration risk while improving\ncode error correction capabilities, resulting in higher-quality Verilog code\ngeneration. Experimental results show that the proposed method could achieve\n96.4% and 96.5% pass@10 scores on VerilogEval Machine and Human benchmarks,\nrespectively while attaining 100% Syntax and 99.9% Functionality pass@5 metrics\non the RTLLM benchmark.",
      "tldr_zh": "本文提出 PromptV 框架，利用 LLM 驱动的多代理提示学习（multi-agent prompt learning）来生成高质量 Verilog 代码，旨在解决现有方法的计算资源需求和单代理提示学习的退化问题（degeneration issue）。该框架通过多代理架构有效缓解生成性能下降、提升错误检测和修正能力，从而提高代码质量。实验结果显示，在 VerilogEval Machine 和 Human 基准上，pass@10 得分分别为 96.4% 和 96.5%；在 RTLLM 基准上，Syntax pass@5 为 100%，Functionality pass@5 为 99.9%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11014v1",
      "published_date": "2024-12-15 01:58:10 UTC",
      "updated_date": "2024-12-15 01:58:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:06:51.527593"
    },
    {
      "arxiv_id": "2412.11009v1",
      "title": "Dual Traits in Probabilistic Reasoning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shenxiong Li",
        "Huaxia Rui"
      ],
      "abstract": "We conducted three experiments to investigate how large language models\n(LLMs) evaluate posterior probabilities. Our results reveal the coexistence of\ntwo modes in posterior judgment among state-of-the-art models: a normative\nmode, which adheres to Bayes' rule, and a representative-based mode, which\nrelies on similarity -- paralleling human System 1 and System 2 thinking.\nAdditionally, we observed that LLMs struggle to recall base rate information\nfrom their memory, and developing prompt engineering strategies to mitigate\nrepresentative-based judgment may be challenging. We further conjecture that\nthe dual modes of judgment may be a result of the contrastive loss function\nemployed in reinforcement learning from human feedback. Our findings underscore\nthe potential direction for reducing cognitive biases in LLMs and the necessity\nfor cautious deployment of LLMs in critical areas.",
      "tldr_zh": "本研究通过三个实验调查大型语言模型 (LLMs) 在评估后验概率时的表现，发现 LLMs 存在两种判断模式：规范模式 (normative mode)，遵守 Bayes' rule，以及代表性模式 (representative-based mode)，依赖于相似性，与人类 System 1 和 System 2 思考类似。实验结果显示，LLMs 难以从记忆中回忆基本率信息，且开发提示工程策略来缓解代表性判断可能面临挑战。该研究推测，这种双重模式可能源于强化学习从人类反馈 (RLHF) 中的对比损失函数 (contrastive loss function)，并强调了减少 LLMs 认知偏差的潜在方向，以及在关键领域谨慎部署 LLMs 的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11009v1",
      "published_date": "2024-12-15 01:33:45 UTC",
      "updated_date": "2024-12-15 01:33:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:08:40.701613"
    },
    {
      "arxiv_id": "2412.15249v2",
      "title": "LitLLMs, LLMs for Literature Review: Are we there yet?",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Agarwal",
        "Gaurav Sahu",
        "Abhay Puri",
        "Issam H. Laradji",
        "Krishnamurthy DJ Dvijotham",
        "Jason Stanley",
        "Laurent Charlin",
        "Christopher Pal"
      ],
      "abstract": "Literature reviews are an essential component of scientific research, but\nthey remain time-intensive and challenging to write, especially due to the\nrecent influx of research papers. This paper explores the zero-shot abilities\nof recent Large Language Models (LLMs) in assisting with the writing of\nliterature reviews based on an abstract. We decompose the task into two\ncomponents: 1. Retrieving related works given a query abstract, and 2. Writing\na literature review based on the retrieved results. We analyze how effective\nLLMs are for both components. For retrieval, we introduce a novel two-step\nsearch strategy that first uses an LLM to extract meaningful keywords from the\nabstract of a paper and then retrieves potentially relevant papers by querying\nan external knowledge base. Additionally, we study a prompting-based re-ranking\nmechanism with attribution and show that re-ranking doubles the normalized\nrecall compared to naive search methods, while providing insights into the\nLLM's decision-making process. In the generation phase, we propose a two-step\napproach that first outlines a plan for the review and then executes steps in\nthe plan to generate the actual review. To evaluate different LLM-based\nliterature review methods, we create test sets from arXiv papers using a\nprotocol designed for rolling use with newly released LLMs to avoid test set\ncontamination in zero-shot evaluations. We release this evaluation protocol to\npromote additional research and development in this regard. Our empirical\nresults suggest that LLMs show promising potential for writing literature\nreviews when the task is decomposed into smaller components of retrieval and\nplanning. Our project page including a demonstration system and toolkit can be\naccessed here: https://litllm.github.io.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在零样本条件下辅助撰写文献综述的能力，将任务分解为两个部分：检索相关论文和基于检索结果生成综述。作者引入了一种两步检索策略，先用 LLM 提取摘要关键词再查询外部知识基，并开发了基于提示的重新排序机制，使归一化召回率提高一倍，同时提供决策洞见；在生成阶段，则采用先规划后执行的方法来撰写综述。实验通过从 arXiv 论文创建的测试集显示，LLMs 在任务分解后表现出色，并发布了评估协议、演示系统和工具包以推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15249v2",
      "published_date": "2024-12-15 01:12:26 UTC",
      "updated_date": "2025-03-21 14:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:08:53.568255"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 62,
  "processed_papers_count": 62,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T13:09:12.685913"
}