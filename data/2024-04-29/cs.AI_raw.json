[
  {
    "arxiv_id": "2404.19146v1",
    "title": "Automated Construction of Theme-specific Knowledge Graphs",
    "authors": [
      "Linyi Ding",
      "Sizhe Zhou",
      "Jinfeng Xiao",
      "Jiawei Han"
    ],
    "abstract": "Despite widespread applications of knowledge graphs (KGs) in various tasks\nsuch as question answering and intelligent conversational systems, existing KGs\nface two major challenges: information granularity and deficiency in\ntimeliness. These hinder considerably the retrieval and analysis of in-context,\nfine-grained, and up-to-date knowledge from KGs, particularly in highly\nspecialized themes (e.g., specialized scientific research) and rapidly evolving\ncontexts (e.g., breaking news or disaster tracking). To tackle such challenges,\nwe propose a theme-specific knowledge graph (i.e., ThemeKG), a KG constructed\nfrom a theme-specific corpus, and design an unsupervised framework for ThemeKG\nconstruction (named TKGCon). The framework takes raw theme-specific corpus and\ngenerates a high-quality KG that includes salient entities and relations under\nthe theme. Specifically, we start with an entity ontology of the theme from\nWikipedia, based on which we then generate candidate relations by Large\nLanguage Models (LLMs) to construct a relation ontology. To parse the documents\nfrom the theme corpus, we first map the extracted entity pairs to the ontology\nand retrieve the candidate relations. Finally, we incorporate the context and\nontology to consolidate the relations for entity pairs. We observe that\ndirectly prompting GPT-4 for theme-specific KG leads to inaccurate entities\n(such as \"two main types\" as one entity in the query result) and unclear (such\nas \"is\", \"has\") or wrong relations (such as \"have due to\", \"to start\"). In\ncontrast, by constructing the theme-specific KG step by step, our model\noutperforms GPT-4 and could consistently identify accurate entities and\nrelations. Experimental results also show that our framework excels in\nevaluations compared with various KG construction baselines.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.19146v1",
    "published_date": "2024-04-29 23:14:14 UTC",
    "updated_date": "2024-04-29 23:14:14 UTC"
  },
  {
    "arxiv_id": "2404.19130v1",
    "title": "SpherE: Expressive and Interpretable Knowledge Graph Embedding for Set Retrieval",
    "authors": [
      "Zihao Li",
      "Yuyi Ao",
      "Jingrui He"
    ],
    "abstract": "Knowledge graphs (KGs), which store an extensive number of relational facts\n(head, relation, tail), serve various applications. While many downstream tasks\nhighly rely on the expressive modeling and predictive embedding of KGs, most of\nthe current KG representation learning methods, where each entity is embedded\nas a vector in the Euclidean space and each relation is embedded as a\ntransformation, follow an entity ranking protocol. On one hand, such an\nembedding design cannot capture many-to-many relations. On the other hand, in\nmany retrieval cases, the users wish to get an exact set of answers without any\nranking, especially when the results are expected to be precise, e.g., which\ngenes cause an illness. Such scenarios are commonly referred to as \"set\nretrieval\". This work presents a pioneering study on the KG set retrieval\nproblem. We show that the set retrieval highly depends on expressive modeling\nof many-to-many relations, and propose a new KG embedding model SpherE to\naddress this problem. SpherE is based on rotational embedding methods, but each\nentity is embedded as a sphere instead of a vector. While inheriting the high\ninterpretability of rotational-based models, our SpherE can more expressively\nmodel one-to-many, many-to-one, and many-to-many relations. Through extensive\nexperiments, we show that our SpherE can well address the set retrieval problem\nwhile still having a good predictive ability to infer missing facts. The code\nis available at https://github.com/Violet24K/SpherE.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2024, Camera Ready Version",
    "pdf_url": "http://arxiv.org/pdf/2404.19130v1",
    "published_date": "2024-04-29 22:21:24 UTC",
    "updated_date": "2024-04-29 22:21:24 UTC"
  },
  {
    "arxiv_id": "2405.00070v1",
    "title": "Bayesian-Guided Generation of Synthetic Microbiomes with Minimized Pathogenicity",
    "authors": [
      "Nisha Pillai",
      "Bindu Nanduri",
      "Michael J Rothrock Jr.",
      "Zhiqian Chen",
      "Mahalingam Ramkumar"
    ],
    "abstract": "Synthetic microbiomes offer new possibilities for modulating microbiota, to\naddress the barriers in multidtug resistance (MDR) research. We present a\nBayesian optimization approach to enable efficient searching over the space of\nsynthetic microbiome variants to identify candidates predictive of reduced MDR.\nMicrobiome datasets were encoded into a low-dimensional latent space using\nautoencoders. Sampling from this space allowed generation of synthetic\nmicrobiome signatures. Bayesian optimization was then implemented to select\nvariants for biological screening to maximize identification of designs with\nrestricted MDR pathogens based on minimal samples. Four acquisition functions\nwere evaluated: expected improvement, upper confidence bound, Thompson\nsampling, and probability of improvement. Based on each strategy, synthetic\nsamples were prioritized according to their MDR detection. Expected\nimprovement, upper confidence bound, and probability of improvement\nconsistently produced synthetic microbiome candidates with significantly fewer\nsearches than Thompson sampling. By combining deep latent space mapping and\nBayesian learning for efficient guided screening, this study demonstrated the\nfeasibility of creating bespoke synthetic microbiomes with customized MDR\nprofiles.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00070v1",
    "published_date": "2024-04-29 21:30:30 UTC",
    "updated_date": "2024-04-29 21:30:30 UTC"
  },
  {
    "arxiv_id": "2405.00738v1",
    "title": "HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level Synthesis",
    "authors": [
      "Andy He",
      "Darren Key",
      "Mason Bulling",
      "Andrew Chang",
      "Skyler Shapiro",
      "Everett Lee"
    ],
    "abstract": "Graphics Processing Units (GPUs) have become the leading hardware accelerator\nfor deep learning applications and are used widely in training and inference of\ntransformers; transformers have achieved state-of-the-art performance in many\nareas of machine learning and are especially used in most modern Large Language\nModels (LLMs). However, GPUs require large amounts of energy, which poses\nenvironmental concerns, demands high operational costs, and causes GPUs to be\nunsuitable for edge computing. We develop an accelerator for transformers,\nnamely, Llama 2, an open-source state-of-the-art LLM, using high level\nsynthesis (HLS) on Field Programmable Gate Arrays (FPGAs). HLS allows us to\nrapidly prototype FPGA designs without writing code at the register-transfer\nlevel (RTL). We name our method HLSTransform, and the FPGA designs we\nsynthesize with HLS achieve up to a 12.75x reduction and 8.25x reduction in\nenergy used per token on the Xilinx Virtex UltraScale+ VU9P FPGA compared to an\nIntel Xeon Broadwell E5-2686 v4 CPU and NVIDIA RTX 3090 GPU respectively, while\nincreasing inference speeds by up to 2.46x compared to CPU and maintaining\n0.53x the speed of an RTX 3090 GPU despite the GPU's 4 times higher base clock\nrate. With the lack of existing open-source FPGA accelerators for transformers,\nwe open-source our code and document our steps for synthesis. We hope this work\nwill serve as a step in democratizing the use of FPGAs in transformer inference\nand inspire research into energy-efficient inference methods as a whole. The\ncode can be found on https://github.com/HLSTransform/submission.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.00738v1",
    "published_date": "2024-04-29 21:26:06 UTC",
    "updated_date": "2024-04-29 21:26:06 UTC"
  },
  {
    "arxiv_id": "2405.01592v1",
    "title": "Text and Audio Simplification: Human vs. ChatGPT",
    "authors": [
      "Gondy Leroy",
      "David Kauchak",
      "Philip Harber",
      "Ankit Pal",
      "Akash Shukla"
    ],
    "abstract": "Text and audio simplification to increase information comprehension are\nimportant in healthcare. With the introduction of ChatGPT, an evaluation of its\nsimplification performance is needed. We provide a systematic comparison of\nhuman and ChatGPT simplified texts using fourteen metrics indicative of text\ndifficulty. We briefly introduce our online editor where these simplification\ntools, including ChatGPT, are available. We scored twelve corpora using our\nmetrics: six text, one audio, and five ChatGPT simplified corpora. We then\ncompare these corpora with texts simplified and verified in a prior user study.\nFinally, a medical domain expert evaluated these texts and five, new ChatGPT\nsimplified versions. We found that simple corpora show higher similarity with\nthe human simplified texts. ChatGPT simplification moves metrics in the right\ndirection. The medical domain expert evaluation showed a preference for the\nChatGPT style, but the text itself was rated lower for content retention.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "H.4"
    ],
    "primary_category": "cs.CL",
    "comment": "AMIA Summit, Boston, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.01592v1",
    "published_date": "2024-04-29 21:00:33 UTC",
    "updated_date": "2024-04-29 21:00:33 UTC"
  },
  {
    "arxiv_id": "2404.19100v2",
    "title": "Predicting Fairness of ML Software Configurations",
    "authors": [
      "Salvador Robles Herrera",
      "Verya Monjezi",
      "Vladik Kreinovich",
      "Ashutosh Trivedi",
      "Saeid Tizpaz-Niari"
    ],
    "abstract": "This paper investigates the relationships between hyperparameters of machine\nlearning and fairness. Data-driven solutions are increasingly used in critical\nsocio-technical applications where ensuring fairness is important. Rather than\nexplicitly encoding decision logic via control and data structures, the ML\ndevelopers provide input data, perform some pre-processing, choose ML\nalgorithms, and tune hyperparameters (HPs) to infer a program that encodes the\ndecision logic. Prior works report that the selection of HPs can significantly\ninfluence fairness. However, tuning HPs to find an ideal trade-off between\naccuracy, precision, and fairness has remained an expensive and tedious task.\nCan we predict fairness of HP configuration for a given dataset? Are the\npredictions robust to distribution shifts?\n  We focus on group fairness notions and investigate the HP space of 5 training\nalgorithms. We first find that tree regressors and XGBoots significantly\noutperformed deep neural networks and support vector machines in accurately\npredicting the fairness of HPs. When predicting the fairness of ML\nhyperparameters under temporal distribution shift, the tree regressors\noutperforms the other algorithms with reasonable accuracy. However, the\nprecision depends on the ML training algorithm, dataset, and protected\nattributes. For example, the tree regressor model was robust for training data\nshift from 2014 to 2018 on logistic regression and discriminant analysis HPs\nwith sex as the protected attribute; but not for race and other training\nalgorithms. Our method provides a sound framework to efficiently perform\nfine-tuning of ML training algorithms and understand the relationships between\nHPs and fairness.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "To Appear in the 20th International Conference on Predictive Models\n  and Data Analytics in Software Engineering (PROMISE'24)",
    "pdf_url": "http://arxiv.org/pdf/2404.19100v2",
    "published_date": "2024-04-29 20:43:42 UTC",
    "updated_date": "2024-07-01 16:16:34 UTC"
  },
  {
    "arxiv_id": "2404.19093v1",
    "title": "Large Language Models as Conversational Movie Recommenders: A User Study",
    "authors": [
      "Ruixuan Sun",
      "Xinyi Li",
      "Avinash Akella",
      "Joseph A. Konstan"
    ],
    "abstract": "This paper explores the effectiveness of using large language models (LLMs)\nfor personalized movie recommendations from users' perspectives in an online\nfield experiment. Our study involves a combination of between-subject prompt\nand historic consumption assessments, along with within-subject recommendation\nscenario evaluations. By examining conversation and survey response data from\n160 active users, we find that LLMs offer strong recommendation explainability\nbut lack overall personalization, diversity, and user trust. Our results also\nindicate that different personalized prompting techniques do not significantly\naffect user-perceived recommendation quality, but the number of movies a user\nhas watched plays a more significant role. Furthermore, LLMs show a greater\nability to recommend lesser-known or niche movies. Through qualitative\nanalysis, we identify key conversational patterns linked to positive and\nnegative user interaction experiences and conclude that providing personal\ncontext and examples is crucial for obtaining high-quality recommendations from\nLLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.19093v1",
    "published_date": "2024-04-29 20:17:06 UTC",
    "updated_date": "2024-04-29 20:17:06 UTC"
  },
  {
    "arxiv_id": "2404.19087v2",
    "title": "Deep Reinforcement Learning for Advanced Longitudinal Control and Collision Avoidance in High-Risk Driving Scenarios",
    "authors": [
      "Dianwei Chen",
      "Yaobang Gong",
      "Xianfeng Yang"
    ],
    "abstract": "Existing Advanced Driver Assistance Systems primarily focus on the vehicle\ndirectly ahead, often overlooking potential risks from following vehicles. This\noversight can lead to ineffective handling of high risk situations, such as\nhigh speed, closely spaced, multi vehicle scenarios where emergency braking by\none vehicle might trigger a pile up collision. To overcome these limitations,\nthis study introduces a novel deep reinforcement learning based algorithm for\nlongitudinal control and collision avoidance. This proposed algorithm\neffectively considers the behavior of both leading and following vehicles. Its\nimplementation in simulated high risk scenarios, which involve emergency\nbraking in dense traffic where traditional systems typically fail, has\ndemonstrated the algorithm ability to prevent potential pile up collisions,\nincluding those involving heavy duty vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.19087v2",
    "published_date": "2024-04-29 19:58:34 UTC",
    "updated_date": "2025-02-21 19:43:27 UTC"
  },
  {
    "arxiv_id": "2404.19076v1",
    "title": "Who Followed the Blueprint? Analyzing the Responses of U.S. Federal Agencies to the Blueprint for an AI Bill of Rights",
    "authors": [
      "Darren Lage",
      "Riley Pruitt",
      "Jason Ross Arnold"
    ],
    "abstract": "This study examines the extent to which U.S. federal agencies responded to\nand implemented the principles outlined in the White House's October 2022\n\"Blueprint for an AI Bill of Rights.\" The Blueprint provided a framework for\nthe ethical governance of artificial intelligence systems, organized around\nfive core principles: safety and effectiveness, protection against algorithmic\ndiscrimination, data privacy, notice and explanation about AI systems, and\nhuman alternatives and fallback.\n  Through an analysis of publicly available records across 15 federal\ndepartments, the authors found limited evidence that the Blueprint directly\ninfluenced agency actions after its release. Only five departments explicitly\nmentioned the Blueprint, while 12 took steps aligned with one or more of its\nprinciples. However, much of this work appeared to have precedents predating\nthe Blueprint or motivations disconnected from it, such as compliance with\nprior executive orders on trustworthy AI. Departments' activities often\nemphasized priorities like safety, accountability and transparency that\noverlapped with Blueprint principles, but did not necessarily stem from it.\n  The authors conclude that the non-binding Blueprint seems to have had minimal\nimpact on shaping the U.S. government's approach to ethical AI governance in\nits first year. Factors like public concerns after high-profile AI releases and\nobligations to follow direct executive orders likely carried more influence\nover federal agencies. More rigorous study would be needed to definitively\nassess the Blueprint's effects within the federal bureaucracy and broader\nsociety.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.19076v1",
    "published_date": "2024-04-29 19:43:10 UTC",
    "updated_date": "2024-04-29 19:43:10 UTC"
  },
  {
    "arxiv_id": "2404.19075v2",
    "title": "Distributed Stochastic Optimization of a Neural Representation Network for Time-Space Tomography Reconstruction",
    "authors": [
      "K. Aditya Mohan",
      "Massimiliano Ferrucci",
      "Chuck Divin",
      "Garrett A. Stevenson",
      "Hyojin Kim"
    ],
    "abstract": "4D time-space reconstruction of dynamic events or deforming objects using\nX-ray computed tomography (CT) is an important inverse problem in\nnon-destructive evaluation. Conventional back-projection based reconstruction\nmethods assume that the object remains static for the duration of several tens\nor hundreds of X-ray projection measurement images (reconstruction of\nconsecutive limited-angle CT scans). However, this is an unrealistic assumption\nfor many in-situ experiments that causes spurious artifacts and inaccurate\nmorphological reconstructions of the object. To solve this problem, we propose\nto perform a 4D time-space reconstruction using a distributed implicit neural\nrepresentation (DINR) network that is trained using a novel distributed\nstochastic training algorithm. Our DINR network learns to reconstruct the\nobject at its output by iterative optimization of its network parameters such\nthat the measured projection images best match the output of the CT forward\nmeasurement model. We use a forward measurement model that is a function of the\nDINR outputs at a sparsely sampled set of continuous valued 4D object\ncoordinates. Unlike previous neural representation architectures that forward\nand back propagate through dense voxel grids that sample the object's entire\ntime-space coordinates, we only propagate through the DINR at a small subset of\nobject coordinates in each iteration resulting in an order-of-magnitude\nreduction in memory and compute for training. DINR leverages distributed\ncomputation across several compute nodes and GPUs to produce high-fidelity 4D\ntime-space reconstructions. We use both simulated parallel-beam and\nexperimental cone-beam X-ray CT datasets to demonstrate the superior\nperformance of our approach.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "eess.IV",
    "comment": "accepted for publication at IEEE Transactions in Computational\n  Imaging",
    "pdf_url": "http://arxiv.org/pdf/2404.19075v2",
    "published_date": "2024-04-29 19:41:51 UTC",
    "updated_date": "2025-02-26 00:31:31 UTC"
  },
  {
    "arxiv_id": "2404.19065v1",
    "title": "HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models",
    "authors": [
      "Gabriel Sarch",
      "Sahil Somani",
      "Raghav Kapoor",
      "Michael J. Tarr",
      "Katerina Fragkiadaki"
    ],
    "abstract": "Recent research on instructable agents has used memory-augmented Large\nLanguage Models (LLMs) as task planners, a technique that retrieves\nlanguage-program examples relevant to the input instruction and uses them as\nin-context examples in the LLM prompt to improve the performance of the LLM in\ninferring the correct action and task plans. In this technical report, we\nextend the capabilities of HELPER, by expanding its memory with a wider array\nof examples and prompts, and by integrating additional APIs for asking\nquestions. This simple expansion of HELPER into a shared memory enables the\nagent to work across the domains of executing plans from dialogue, natural\nlanguage instruction following, active question asking, and commonsense room\nreorganization. We evaluate the agent on four diverse interactive\nvisual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the\nTidy Task. HELPER-X achieves few-shot, state-of-the-art performance across\nthese benchmarks using a single agent, without requiring in-domain training,\nand remains competitive with agents that have undergone in-domain training.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Videos and code https://helper-agent-llm.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.19065v1",
    "published_date": "2024-04-29 19:12:42 UTC",
    "updated_date": "2024-04-29 19:12:42 UTC"
  },
  {
    "arxiv_id": "2407.10239v2",
    "title": "What is Reproducibility in Artificial Intelligence and Machine Learning Research?",
    "authors": [
      "Abhyuday Desai",
      "Mohamed Abdelhamid",
      "Nakul R. Padalkar"
    ],
    "abstract": "In the rapidly evolving fields of Artificial Intelligence (AI) and Machine\nLearning (ML), the reproducibility crisis underscores the urgent need for clear\nvalidation methodologies to maintain scientific integrity and encourage\nadvancement. The crisis is compounded by the prevalent confusion over\nvalidation terminology. In response to this challenge, we introduce a framework\nthat clarifies the roles and definitions of key validation efforts:\nrepeatability, dependent and independent reproducibility, and direct and\nconceptual replicability. This structured framework aims to provide AI/ML\nresearchers with the necessary clarity on these essential concepts,\nfacilitating the appropriate design, conduct, and interpretation of validation\nstudies. By articulating the nuances and specific roles of each type of\nvalidation study, we aim to enhance the reliability and trustworthiness of\nresearch findings and support the community's efforts to address\nreproducibility challenges effectively.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "I.2.m"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages, 3 figures, 1 table; submitted to AI Magazine",
    "pdf_url": "http://arxiv.org/pdf/2407.10239v2",
    "published_date": "2024-04-29 18:51:20 UTC",
    "updated_date": "2025-03-30 18:44:17 UTC"
  },
  {
    "arxiv_id": "2404.19048v2",
    "title": "A Framework for Real-time Safeguarding the Text Generation of Large Language Model",
    "authors": [
      "Ximing Dong",
      "Dayi Lin",
      "Shaowei Wang",
      "Ahmed E. Hassan"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing (NLP) tasks but also pose ethical and societal risks due to their\npropensity to generate harmful content. To address this, various approaches\nhave been developed to safeguard LLMs from producing unsafe content. However,\nexisting methods have limitations, including the need for training specific\ncontrol models and proactive intervention during text generation, that lead to\nquality degradation and increased computational overhead. To mitigate those\nlimitations, we propose LLMSafeGuard, a lightweight framework to safeguard LLM\ntext generation in real-time. LLMSafeGuard integrates an external validator\ninto the beam search algorithm during decoding, rejecting candidates that\nviolate safety constraints while allowing valid ones to proceed. We introduce a\nsimilarity based validation approach, simplifying constraint introduction and\neliminating the need for control model training. Additionally, LLMSafeGuard\nemploys a context-wise timing selection strategy, intervening LLMs only when\nnecessary. We evaluate LLMSafeGuard on two tasks, detoxification and copyright\nsafeguarding, and demonstrate its superior performance over SOTA baselines. For\ninstance, LLMSafeGuard reduces the average toxic score of. LLM output by 29.7%\ncompared to the best baseline meanwhile preserving similar linguistic quality\nas natural output in detoxification task. Similarly, in the copyright task,\nLLMSafeGuard decreases the Longest Common Subsequence (LCS) by 56.2% compared\nto baselines. Moreover, our context-wise timing selection strategy reduces\ninference time by at least 24% meanwhile maintaining comparable effectiveness\nas validating each time step. LLMSafeGuard also offers tunable parameters to\nbalance its effectiveness and efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.19048v2",
    "published_date": "2024-04-29 18:40:01 UTC",
    "updated_date": "2024-05-01 19:53:12 UTC"
  },
  {
    "arxiv_id": "2404.19038v1",
    "title": "Embedded Representation Learning Network for Animating Styled Video Portrait",
    "authors": [
      "Tianyong Wang",
      "Xiangyu Liang",
      "Wangguandong Zheng",
      "Dan Niu",
      "Haifeng Xia",
      "Siyu Xia"
    ],
    "abstract": "The talking head generation recently attracted considerable attention due to\nits widespread application prospects, especially for digital avatars and 3D\nanimation design. Inspired by this practical demand, several works explored\nNeural Radiance Fields (NeRF) to synthesize the talking heads. However, these\nmethods based on NeRF face two challenges: (1) Difficulty in generating\nstyle-controllable talking heads. (2) Displacement artifacts around the neck in\nrendered images. To overcome these two challenges, we propose a novel\ngenerative paradigm \\textit{Embedded Representation Learning Network} (ERLNet)\nwith two learning stages. First, the \\textit{ audio-driven FLAME} (ADF) module\nis constructed to produce facial expression and head pose sequences\nsynchronized with content audio and style video. Second, given the sequence\ndeduced by the ADF, one novel \\textit{dual-branch fusion NeRF} (DBF-NeRF)\nexplores these contents to render the final images. Extensive empirical studies\ndemonstrate that the collaboration of these two stages effectively facilitates\nour method to render a more realistic talking head than the existing\nalgorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.19038v1",
    "published_date": "2024-04-29 18:24:55 UTC",
    "updated_date": "2024-04-29 18:24:55 UTC"
  },
  {
    "arxiv_id": "2404.19031v1",
    "title": "Machine Unlearning for Document Classification",
    "authors": [
      "Lei Kang",
      "Mohamed Ali Souibgui",
      "Fei Yang",
      "Lluis Gomez",
      "Ernest Valveny",
      "Dimosthenis Karatzas"
    ],
    "abstract": "Document understanding models have recently demonstrated remarkable\nperformance by leveraging extensive collections of user documents. However,\nsince documents often contain large amounts of personal data, their usage can\npose a threat to user privacy and weaken the bonds of trust between humans and\nAI services. In response to these concerns, legislation advocating ``the right\nto be forgotten\" has recently been proposed, allowing users to request the\nremoval of private information from computer systems and neural network models.\nA novel approach, known as machine unlearning, has emerged to make AI models\nforget about a particular class of data. In our research, we explore machine\nunlearning for document classification problems, representing, to the best of\nour knowledge, the first investigation into this area. Specifically, we\nconsider a realistic scenario where a remote server houses a well-trained model\nand possesses only a small portion of training data. This setup is designed for\nefficient forgetting manipulation. This work represents a pioneering step\ntowards the development of machine unlearning methods aimed at addressing\nprivacy concerns in document analysis applications. Our code is publicly\navailable at\n\\url{https://github.com/leitro/MachineUnlearning-DocClassification}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICDAR2024",
    "pdf_url": "http://arxiv.org/pdf/2404.19031v1",
    "published_date": "2024-04-29 18:16:13 UTC",
    "updated_date": "2024-04-29 18:16:13 UTC"
  },
  {
    "arxiv_id": "2404.19007v1",
    "title": "How Did We Get Here? Summarizing Conversation Dynamics",
    "authors": [
      "Yilun Hua",
      "Nicholas Chernogor",
      "Yuzhe Gu",
      "Seoyeon Julie Jeong",
      "Miranda Luo",
      "Cristian Danescu-Niculescu-Mizil"
    ],
    "abstract": "Throughout a conversation, the way participants interact with each other is\nin constant flux: their tones may change, they may resort to different\nstrategies to convey their points, or they might alter their interaction\npatterns. An understanding of these dynamics can complement that of the actual\nfacts and opinions discussed, offering a more holistic view of the trajectory\nof the conversation: how it arrived at its current state and where it is likely\nheading.\n  In this work, we introduce the task of summarizing the dynamics of\nconversations, by constructing a dataset of human-written summaries, and\nexploring several automated baselines. We evaluate whether such summaries can\ncapture the trajectory of conversations via an established downstream task:\nforecasting whether an ongoing conversation will eventually derail into toxic\nbehavior. We show that they help both humans and automated systems with this\nforecasting task. Humans make predictions three times faster, and with greater\nconfidence, when reading the summaries than when reading the transcripts.\nFurthermore, automated forecasting systems are more accurate when constructing,\nand then predicting based on, summaries of conversation dynamics, compared to\ndirectly predicting on the transcripts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in the Proceedings of NAACL 2024. Data available in\n  ConvoKit https://convokit.cornell.edu/",
    "pdf_url": "http://arxiv.org/pdf/2404.19007v1",
    "published_date": "2024-04-29 18:00:03 UTC",
    "updated_date": "2024-04-29 18:00:03 UTC"
  },
  {
    "arxiv_id": "2404.18928v1",
    "title": "Stylus: Automatic Adapter Selection for Diffusion Models",
    "authors": [
      "Michael Luo",
      "Justin Wong",
      "Brandon Trabucco",
      "Yanping Huang",
      "Joseph E. Gonzalez",
      "Zhifeng Chen",
      "Ruslan Salakhutdinov",
      "Ion Stoica"
    ],
    "abstract": "Beyond scaling base models with more data or parameters, fine-tuned adapters\nprovide an alternative way to generate high fidelity, custom images at reduced\ncosts. As such, adapters have been widely adopted by open-source communities,\naccumulating a database of over 100K adapters-most of which are highly\ncustomized with insufficient descriptions. This paper explores the problem of\nmatching the prompt to a set of relevant adapters, built on recent work that\nhighlight the performance gains of composing adapters. We introduce Stylus,\nwhich efficiently selects and automatically composes task-specific adapters\nbased on a prompt's keywords. Stylus outlines a three-stage approach that first\nsummarizes adapters with improved descriptions and embeddings, retrieves\nrelevant adapters, and then further assembles adapters based on prompts'\nkeywords by checking how well they fit the prompt. To evaluate Stylus, we\ndeveloped StylusDocs, a curated dataset featuring 75K adapters with\npre-computed adapter embeddings. In our evaluation on popular Stable Diffusion\ncheckpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as\npreferred, with humans and multimodal models as evaluators, over the base\nmodel. See stylus-diffusion.github.io for more.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Website: https://stylus-diffusion.github.io",
    "pdf_url": "http://arxiv.org/pdf/2404.18928v1",
    "published_date": "2024-04-29 17:59:16 UTC",
    "updated_date": "2024-04-29 17:59:16 UTC"
  },
  {
    "arxiv_id": "2404.18922v3",
    "title": "DPO Meets PPO: Reinforced Token Optimization for RLHF",
    "authors": [
      "Han Zhong",
      "Zikang Shan",
      "Guhao Feng",
      "Wei Xiong",
      "Xinle Cheng",
      "Li Zhao",
      "Di He",
      "Jiang Bian",
      "Liwei Wang"
    ],
    "abstract": "In the classical Reinforcement Learning from Human Feedback (RLHF) framework,\nProximal Policy Optimization (PPO) is employed to learn from sparse,\nsentence-level rewards -- a challenging scenario in traditional deep\nreinforcement learning. Despite the great successes of PPO in the alignment of\nlarge language models, its open-source implementation is still largely\nsub-optimal. To address these issues, we introduce a framework that models RLHF\nproblems as a Markov decision process (MDP), enabling the capture of\nfine-grained token-wise information. Under this framework, we introduce an\nalgorithm Reinforced Token Optimization (\\texttt{RTO}), which learns the\ntoken-wise reward function from preference data and performs policy\noptimization based on this learned token-wise reward signal. Theoretically,\n\\texttt{RTO} is proven to have the capability of finding the near-optimal\npolicy sample-efficiently. For its practical implementation, \\texttt{RTO}\ninnovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,\noriginally derived from sparse sentence rewards, surprisingly provides us with\na token-wise characterization of response quality, which is seamlessly\nincorporated into our subsequent PPO training stage. Extensive experiments\ndemonstrate that \\texttt{RTO} performs better than PPO and other direct\npreference learning algorithms. In particular, RTO outperforms PPO by 7.5\npoints on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code\nand models are available at\n\\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18922v3",
    "published_date": "2024-04-29 17:58:30 UTC",
    "updated_date": "2025-02-11 17:23:13 UTC"
  },
  {
    "arxiv_id": "2404.18891v1",
    "title": "IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation",
    "authors": [
      "Kebin Wu",
      "Wenbin Li",
      "Xiaofei Xiao"
    ],
    "abstract": "The scarcity of labeled data in real-world scenarios is a critical bottleneck\nof deep learning's effectiveness. Semi-supervised semantic segmentation has\nbeen a typical solution to achieve a desirable tradeoff between annotation cost\nand segmentation performance. However, previous approaches, whether based on\nconsistency regularization or self-training, tend to neglect the contextual\nknowledge embedded within inter-pixel relations. This negligence leads to\nsuboptimal performance and limited generalization. In this paper, we propose a\nnovel approach IPixMatch designed to mine the neglected but valuable\nInter-Pixel information for semi-supervised learning. Specifically, IPixMatch\nis constructed as an extension of the standard teacher-student network,\nincorporating additional loss terms to capture inter-pixel relations. It shines\nin low-data regimes by efficiently leveraging the limited labeled data and\nextracting maximum utility from the available unlabeled data. Furthermore,\nIPixMatch can be integrated seamlessly into most teacher-student frameworks\nwithout the need of model modification or adding additional components. Our\nstraightforward IPixMatch method demonstrates consistent performance\nimprovements across various benchmark datasets under different partitioning\nprotocols.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18891v1",
    "published_date": "2024-04-29 17:27:37 UTC",
    "updated_date": "2024-04-29 17:27:37 UTC"
  },
  {
    "arxiv_id": "2404.18886v3",
    "title": "A Survey on Diffusion Models for Time Series and Spatio-Temporal Data",
    "authors": [
      "Yiyuan Yang",
      "Ming Jin",
      "Haomin Wen",
      "Chaoli Zhang",
      "Yuxuan Liang",
      "Lintao Ma",
      "Yi Wang",
      "Chenghao Liu",
      "Bin Yang",
      "Zenglin Xu",
      "Jiang Bian",
      "Shirui Pan",
      "Qingsong Wen"
    ],
    "abstract": "The study of time series is crucial for understanding trends and anomalies\nover time, enabling predictive insights across various sectors. Spatio-temporal\ndata, on the other hand, is vital for analyzing phenomena in both space and\ntime, providing a dynamic perspective on complex system interactions. Recently,\ndiffusion models have seen widespread application in time series and\nspatio-temporal data mining. Not only do they enhance the generative and\ninferential capabilities for sequential and temporal data, but they also extend\nto other downstream tasks. In this survey, we comprehensively and thoroughly\nreview the use of diffusion models in time series and spatio-temporal data,\ncategorizing them by model category, task type, data modality, and practical\napplication domain. In detail, we categorize diffusion models into\nunconditioned and conditioned types and discuss time series and spatio-temporal\ndata separately. Unconditioned models, which operate unsupervised, are\nsubdivided into probability-based and score-based models, serving predictive\nand generative tasks such as forecasting, anomaly detection, classification,\nand imputation. Conditioned models, on the other hand, utilize extra\ninformation to enhance performance and are similarly divided for both\npredictive and generative tasks. Our survey extensively covers their\napplication in various fields, including healthcare, recommendation, climate,\nenergy, audio, and transportation, providing a foundational understanding of\nhow these models analyze and generate data. Through this structured overview,\nwe aim to provide researchers and practitioners with a comprehensive\nunderstanding of diffusion models for time series and spatio-temporal data\nanalysis, aiming to direct future innovations and applications by addressing\ntraditional challenges and exploring innovative solutions within the diffusion\nmodel framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Ongoing work & Under review; 27 pages, 8 figures, 2 tables; Github\n  Repo:\n  https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model",
    "pdf_url": "http://arxiv.org/pdf/2404.18886v3",
    "published_date": "2024-04-29 17:19:40 UTC",
    "updated_date": "2024-06-11 13:25:53 UTC"
  },
  {
    "arxiv_id": "2404.18873v1",
    "title": "OpenStreetView-5M: The Many Roads to Global Visual Geolocation",
    "authors": [
      "Guillaume Astruc",
      "Nicolas Dufour",
      "Ioannis Siglidis",
      "Constantin Aronssohn",
      "Nacim Bouia",
      "Stephanie Fu",
      "Romain Loiseau",
      "Van Nguyen Nguyen",
      "Charles Raude",
      "Elliot Vincent",
      "Lintao XU",
      "Hongyu Zhou",
      "Loic Landrieu"
    ],
    "abstract": "Determining the location of an image anywhere on Earth is a complex visual\ntask, which makes it particularly relevant for evaluating computer vision\nalgorithms. Yet, the absence of standard, large-scale, open-access datasets\nwith reliably localizable images has limited its potential. To address this\nissue, we introduce OpenStreetView-5M, a large-scale, open-access dataset\ncomprising over 5.1 million geo-referenced street view images, covering 225\ncountries and territories. In contrast to existing benchmarks, we enforce a\nstrict train/test separation, allowing us to evaluate the relevance of learned\ngeographical features beyond mere memorization. To demonstrate the utility of\nour dataset, we conduct an extensive benchmark of various state-of-the-art\nimage encoders, spatial representations, and training strategies. All\nassociated codes and models can be found at https://github.com/gastruc/osv5m.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.18873v1",
    "published_date": "2024-04-29 17:06:44 UTC",
    "updated_date": "2024-04-29 17:06:44 UTC"
  },
  {
    "arxiv_id": "2404.18870v2",
    "title": "More RLHF, More Trust? On The Impact of Preference Alignment On Trustworthiness",
    "authors": [
      "Aaron J. Li",
      "Satyapriya Krishna",
      "Himabindu Lakkaraju"
    ],
    "abstract": "The trustworthiness of Large Language Models (LLMs) refers to the extent to\nwhich their outputs are reliable, safe, and ethically aligned, and it has\nbecome a crucial consideration alongside their cognitive performance. In\npractice, Reinforcement Learning From Human Feedback (RLHF) has been widely\nused to align LLMs with labeled human preferences, but its assumed effect on\nmodel trustworthiness hasn't been rigorously evaluated. To bridge this\nknowledge gap, this study investigates how models aligned with general-purpose\npreference data perform across five trustworthiness verticals: toxicity,\nstereotypical bias, machine ethics, truthfulness, and privacy. Our results\ndemonstrate that RLHF on human preferences doesn't automatically guarantee\ntrustworthiness, and reverse effects are often observed. Furthermore, we\npropose to adapt efficient influence function based data attribution methods to\nthe RLHF setting to better understand the influence of fine-tuning data on\nindividual trustworthiness benchmarks, and show its feasibility by providing\nour estimated attribution scores. Together, our results underscore the need for\nmore nuanced approaches for model alignment from both the data and framework\nperspectives, and we hope this research will guide the community towards\ndeveloping language models that are increasingly capable without sacrificing\ntrustworthiness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18870v2",
    "published_date": "2024-04-29 17:00:53 UTC",
    "updated_date": "2024-12-21 22:56:04 UTC"
  },
  {
    "arxiv_id": "2404.18864v1",
    "title": "Performance-Aligned LLMs for Generating Fast Code",
    "authors": [
      "Daniel Nichols",
      "Pranav Polasam",
      "Harshitha Menon",
      "Aniruddha Marathe",
      "Todd Gamblin",
      "Abhinav Bhatele"
    ],
    "abstract": "Optimizing scientific software is a difficult task because codebases are\noften large and complex, and performance can depend upon several factors\nincluding the algorithm, its implementation, and hardware among others. Causes\nof poor performance can originate from disparate sources and be difficult to\ndiagnose. Recent years have seen a multitude of work that use large language\nmodels (LLMs) to assist in software development tasks. However, these tools are\ntrained to model the distribution of code as text, and are not specifically\ndesigned to understand performance aspects of code. In this work, we introduce\na reinforcement learning based methodology to align the outputs of code LLMs\nwith performance. This allows us to build upon the current code modeling\ncapabilities of LLMs and extend them to generate better performing code. We\ndemonstrate that our fine-tuned model improves the expected speedup of\ngenerated code over base models for a set of benchmark tasks from 0.9 to 1.6\nfor serial code and 1.9 to 4.5 for OpenMP code.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18864v1",
    "published_date": "2024-04-29 16:52:38 UTC",
    "updated_date": "2024-04-29 16:52:38 UTC"
  },
  {
    "arxiv_id": "2404.18848v3",
    "title": "FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition",
    "authors": [
      "Yuxuan Yan",
      "Qianqian Yang",
      "Shunpu Tang",
      "Zhiguo Shi"
    ],
    "abstract": "Despite their exceptional performance on various tasks after fine-tuning,\npre-trained language models (PLMs) face significant challenges due to growing\nprivacy concerns with data in centralized training methods. We consider\nfederated learning (FL) to fine-tune PLMs in this paper. However, the\nsubstantial number of parameters in PLMs poses significant difficulties for\nclient devices with limited communication and computational resources. One\npromising solution is to exploit parameter-efficient fine-tuning (PEFT) into\nFL, which trains a much smaller set of parameters than full parameter\nfine-tuning (FFT). Although remarkably improving training efficiency, PEFT\nmethods may lead to degraded performance especially when data across different\nclients are non i.i.d, as revealed by experimental results. To overcome this,\nwe propose FeDeRA, which extends and improves a widely used PEFT method, i.e.,\nlow-rank adaption (LoRA). FeDeRA follows LoRA by decomposing the weight\nmatrices of the PLMs into low-rank matrices, which allows for more efficient\ncomputation and parameter updates during fine-tuning. Different from LoRA which\nsimply initializes these low-rank matrices by random sampling or zeros, the\nproposed FeDeRA initializes these matrices by the results of performing\nsingular value decomposition (SVD) on the pre-trained weight matrices.\nExtensive experiments across various tasks and datasets show that FeDeRA\noutperforms the considered PEFT baselines and is comparable to or even\nsurpasses FFT method within the FL setting in terms of task performance.\nMoreover, FeDeRA requires only 1% trainable paramentes compared to FFT,\nsignificantly reducing training time costs by more than 90% to achieve the same\ntask performance level. The experimental results also highlight the robustness\nof FeDeRA against data heterogeneity, as it maintains stable task performance\neven as data heterogeneity increases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18848v3",
    "published_date": "2024-04-29 16:42:26 UTC",
    "updated_date": "2024-05-25 06:55:19 UTC"
  },
  {
    "arxiv_id": "2404.18831v1",
    "title": "ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization",
    "authors": [
      "Hong Nguyen",
      "Hoang Nguyen",
      "Melinda Chang",
      "Hieu Pham",
      "Shrikanth Narayanan",
      "Michael Pazzani"
    ],
    "abstract": "Understanding the severity of conditions shown in images in medical diagnosis\nis crucial, serving as a key guide for clinical assessment, treatment, as well\nas evaluating longitudinal progression. This paper proposes Con- PrO: a novel\nrepresentation learning method for severity assessment in medical images using\nContrastive learningintegrated Preference Optimization. Different from\nconventional contrastive learning methods that maximize the distance between\nclasses, ConPrO injects into the latent vector the distance preference\nknowledge between various severity classes and the normal class. We\nsystematically examine the key components of our framework to illuminate how\ncontrastive prediction tasks acquire valuable representations. We show that our\nrepresentation learning framework offers valuable severity ordering in the\nfeature space while outperforming previous state-of-the-art methods on\nclassification tasks. We achieve a 6% and 20% relative improvement compared to\na supervised and a self-supervised baseline, respectively. In addition, we\nderived discussions on severity indicators and related applications of\npreference comparison in the medical domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.18831v1",
    "published_date": "2024-04-29 16:16:42 UTC",
    "updated_date": "2024-04-29 16:16:42 UTC"
  },
  {
    "arxiv_id": "2404.18825v1",
    "title": "Harmonic Machine Learning Models are Robust",
    "authors": [
      "Nicholas S. Kersting",
      "Yi Li",
      "Aman Mohanty",
      "Oyindamola Obisesan",
      "Raphael Okochu"
    ],
    "abstract": "We introduce Harmonic Robustness, a powerful and intuitive method to test the\nrobustness of any machine-learning model either during training or in black-box\nreal-time inference monitoring without ground-truth labels. It is based on\nfunctional deviation from the harmonic mean value property, indicating\ninstability and lack of explainability. We show implementation examples in\nlow-dimensional trees and feedforward NNs, where the method reliably identifies\noverfitting, as well as in more complex high-dimensional models such as\nResNet-50 and Vision Transformer where it efficiently measures adversarial\nvulnerability across image classes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18825v1",
    "published_date": "2024-04-29 16:07:36 UTC",
    "updated_date": "2024-04-29 16:07:36 UTC"
  },
  {
    "arxiv_id": "2404.18824v1",
    "title": "Benchmarking Benchmark Leakage in Large Language Models",
    "authors": [
      "Ruijie Xu",
      "Zengzhi Wang",
      "Run-Ze Fan",
      "Pengfei Liu"
    ],
    "abstract": "Amid the expanding use of pre-training data, the phenomenon of benchmark\ndataset leakage has become increasingly prominent, exacerbated by opaque\ntraining processes and the often undisclosed inclusion of supervised data in\ncontemporary Large Language Models (LLMs). This issue skews benchmark\neffectiveness and fosters potentially unfair comparisons, impeding the field's\nhealthy development. To address this, we introduce a detection pipeline\nutilizing Perplexity and N-gram accuracy, two simple and scalable metrics that\ngauge a model's prediction precision on benchmark, to identify potential data\nleakages. By analyzing 31 LLMs under the context of mathematical reasoning, we\nreveal substantial instances of training even test set misuse, resulting in\npotentially unfair comparisons. These findings prompt us to offer several\nrecommendations regarding model documentation, benchmark setup, and future\nevaluations. Notably, we propose the \"Benchmark Transparency Card\" to encourage\nclear documentation of benchmark utilization, promoting transparency and\nhealthy developments of LLMs. we have made our leaderboard, pipeline\nimplementation, and model predictions publicly available, fostering future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages; Homepage: https://gair-nlp.github.io/benbench",
    "pdf_url": "http://arxiv.org/pdf/2404.18824v1",
    "published_date": "2024-04-29 16:05:36 UTC",
    "updated_date": "2024-04-29 16:05:36 UTC"
  },
  {
    "arxiv_id": "2404.18821v2",
    "title": "Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies",
    "authors": [
      "Seyed Soroush Karimi Madahi",
      "Gargya Gokhale",
      "Marie-Sophie Verwee",
      "Bert Claessens",
      "Chris Develder"
    ],
    "abstract": "A continuous rise in the penetration of renewable energy sources, along with\nthe use of the single imbalance pricing, provides a new opportunity for balance\nresponsible parties to reduce their cost through energy arbitrage in the\nimbalance settlement mechanism. Model-free reinforcement learning (RL) methods\nare an appropriate choice for solving the energy arbitrage problem due to their\noutstanding performance in solving complex stochastic sequential problems.\nHowever, RL is rarely deployed in real-world applications since its learned\npolicy does not necessarily guarantee safety during the execution phase. In\nthis paper, we propose a new RL-based control framework for batteries to obtain\na safe energy arbitrage strategy in the imbalance settlement mechanism. In our\nproposed control framework, the agent initially aims to optimize the arbitrage\nrevenue. Subsequently, in the post-processing step, we correct (constrain) the\nlearned policy following a knowledge distillation process based on properties\nthat follow human intuition. Our post-processing step is a generic method and\nis not restricted to the energy arbitrage domain. We use the Belgian imbalance\nprice of 2023 to evaluate the performance of our proposed framework.\nFurthermore, we deploy our proposed control framework on a real battery to show\nits capability in the real world.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "ACM e-Energy 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.18821v2",
    "published_date": "2024-04-29 16:03:21 UTC",
    "updated_date": "2024-04-30 08:54:28 UTC"
  },
  {
    "arxiv_id": "2404.18796v2",
    "title": "Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models",
    "authors": [
      "Pat Verga",
      "Sebastian Hofstatter",
      "Sophia Althammer",
      "Yixuan Su",
      "Aleksandra Piktus",
      "Arkady Arkhangorodsky",
      "Minjie Xu",
      "Naomi White",
      "Patrick Lewis"
    ],
    "abstract": "As Large Language Models (LLMs) have become more advanced, they have outpaced\nour abilities to accurately evaluate their quality. Not only is finding data to\nadequately probe particular model properties difficult, but evaluating the\ncorrectness of a model's freeform generation alone is a challenge. To address\nthis, many evaluations now rely on using LLMs themselves as judges to score the\nquality of outputs from other LLMs. Evaluations most commonly use a single\nlarge model like GPT4. While this method has grown in popularity, it is costly,\nhas been shown to introduce intramodel bias, and in this work, we find that\nvery large models are often unnecessary. We propose instead to evaluate models\nusing a Panel of LLm evaluators (PoLL). Across three distinct judge settings\nand spanning six different datasets, we find that using a PoLL composed of a\nlarger number of smaller models outperforms a single large judge, exhibits less\nintra-model bias due to its composition of disjoint model families, and does so\nwhile being over seven times less expensive.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18796v2",
    "published_date": "2024-04-29 15:33:23 UTC",
    "updated_date": "2024-05-01 15:37:11 UTC"
  },
  {
    "arxiv_id": "2404.18791v2",
    "title": "Certification of Speaker Recognition Models to Additive Perturbations",
    "authors": [
      "Dmitrii Korzh",
      "Elvir Karimov",
      "Mikhail Pautov",
      "Oleg Y. Rogov",
      "Ivan Oseledets"
    ],
    "abstract": "Speaker recognition technology is applied to various tasks, from personal\nvirtual assistants to secure access systems. However, the robustness of these\nsystems against adversarial attacks, particularly to additive perturbations,\nremains a significant challenge. In this paper, we pioneer applying robustness\ncertification techniques to speaker recognition, initially developed for the\nimage domain. Our work covers this gap by transferring and improving randomized\nsmoothing certification techniques against norm-bounded additive perturbations\nfor classification and few-shot learning tasks to speaker recognition. We\ndemonstrate the effectiveness of these methods on VoxCeleb 1 and 2 datasets for\nseveral models. We expect this work to improve the robustness of voice\nbiometrics and accelerate the research of certification methods in the audio\ndomain.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "13 pages, 10 figures; AAAI-2025 accepted paper",
    "pdf_url": "http://arxiv.org/pdf/2404.18791v2",
    "published_date": "2024-04-29 15:23:26 UTC",
    "updated_date": "2024-12-18 16:52:17 UTC"
  },
  {
    "arxiv_id": "2404.18982v2",
    "title": "Can ChatGPT Make Explanatory Inferences? Benchmarks for Abductive Reasoning",
    "authors": [
      "Paul Thagard"
    ],
    "abstract": "Explanatory inference is the creation and evaluation of hypotheses that\nprovide explanations, and is sometimes known as abduction or abductive\ninference. Generative AI is a new set of artificial intelligence models based\non novel algorithms for generating text, images, and sounds. This paper\nproposes a set of benchmarks for assessing the ability of AI programs to\nperform explanatory inference, and uses them to determine the extent to which\nChatGPT, a leading generative AI model, is capable of making explanatory\ninferences. Tests on the benchmarks reveal that ChatGPT performs creative and\nevaluative inferences in many domains, although it is limited to verbal and\nvisual modalities. Claims that ChatGPT and similar models are incapable of\nexplanation, understanding, causal reasoning, meaning, and creativity are\nrebutted.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18982v2",
    "published_date": "2024-04-29 15:19:05 UTC",
    "updated_date": "2024-09-19 13:20:05 UTC"
  },
  {
    "arxiv_id": "2404.18784v1",
    "title": "Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input",
    "authors": [
      "Tessa Masis",
      "Brendan O'Connor"
    ],
    "abstract": "Geo-entity linking is the task of linking a location mention to the\nreal-world geographic location. In this paper we explore the challenging task\nof geo-entity linking for noisy, multilingual social media data. There are few\nopen-source multilingual geo-entity linking tools available and existing ones\nare often rule-based, which break easily in social media settings, or\nLLM-based, which are too expensive for large-scale datasets. We present a\nmethod which represents real-world locations as averaged embeddings from\nlabeled user-input location names and allows for selective prediction via an\ninterpretable confidence score. We show that our approach improves geo-entity\nlinking on a global and multilingual social media dataset, and discuss progress\nand problems with evaluating at different geographic granularities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NLP+CSS workshop at NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.18784v1",
    "published_date": "2024-04-29 15:18:33 UTC",
    "updated_date": "2024-04-29 15:18:33 UTC"
  },
  {
    "arxiv_id": "2404.18981v1",
    "title": "Decoding Radiologists' Intentions: A Novel System for Accurate Region Identification in Chest X-ray Image Analysis",
    "authors": [
      "Akash Awasthi",
      "Safwan Ahmad",
      "Bryant Le",
      "Hien Van Nguyen"
    ],
    "abstract": "In the realm of chest X-ray (CXR) image analysis, radiologists meticulously\nexamine various regions, documenting their observations in reports. The\nprevalence of errors in CXR diagnoses, particularly among inexperienced\nradiologists and hospital residents, underscores the importance of\nunderstanding radiologists' intentions and the corresponding regions of\ninterest. This understanding is crucial for correcting mistakes by guiding\nradiologists to the accurate regions of interest, especially in the diagnosis\nof chest radiograph abnormalities. In response to this imperative, we propose a\nnovel system designed to identify the primary intentions articulated by\nradiologists in their reports and the corresponding regions of interest in CXR\nimages. This system seeks to elucidate the visual context underlying\nradiologists' textual findings, with the potential to rectify errors made by\nless experienced practitioners and direct them to precise regions of interest.\nImportantly, the proposed system can be instrumental in providing constructive\nfeedback to inexperienced radiologists or junior residents in the hospital,\nbridging the gap in face-to-face communication. The system represents a\nvaluable tool for enhancing diagnostic accuracy and fostering continuous\nlearning within the medical community.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted in ISBI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.18981v1",
    "published_date": "2024-04-29 15:18:26 UTC",
    "updated_date": "2024-04-29 15:18:26 UTC"
  },
  {
    "arxiv_id": "2404.18774v1",
    "title": "Self-training superconducting neuromorphic circuits using reinforcement learning rules",
    "authors": [
      "M. L. Schneider",
      "E. M. Jué",
      "M. R. Pufall",
      "K. Segall",
      "C. W. Anderson"
    ],
    "abstract": "Reinforcement learning algorithms are used in a wide range of applications,\nfrom gaming and robotics to autonomous vehicles. In this paper we describe a\nset of reinforcement learning-based local weight update rules and their\nimplementation in superconducting hardware. Using SPICE circuit simulations, we\nimplement a small-scale neural network with a learning time of order one\nnanosecond. This network can be trained to learn new functions simply by\nchanging the target output for a given set of inputs, without the need for any\nexternal adjustments to the network. In this implementation the weights are\nadjusted based on the current state of the overall network response and locally\nstored information about the previous action. This removes the need to program\nexplicit weight values in these networks, which is one of the primary\nchallenges that analog hardware implementations of neural networks face. The\nadjustment of weights is based on a global reinforcement signal that obviates\nthe need for circuitry to back-propagate errors.",
    "categories": [
      "cond-mat.supr-con",
      "cs.AI"
    ],
    "primary_category": "cond-mat.supr-con",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18774v1",
    "published_date": "2024-04-29 15:09:00 UTC",
    "updated_date": "2024-04-29 15:09:00 UTC"
  },
  {
    "arxiv_id": "2404.18772v1",
    "title": "Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain",
    "authors": [
      "Gustaw Opiełka",
      "Jessica Loke",
      "Steven Scholte"
    ],
    "abstract": "Deep learning algorithms lack human-interpretable accounts of how they\ntransform raw visual input into a robust semantic understanding, which impedes\ncomparisons between different architectures, training objectives, and the human\nbrain. In this work, we take inspiration from neuroscience and employ\nrepresentational approaches to shed light on how neural networks encode\ninformation at low (visual saliency) and high (semantic similarity) levels of\nabstraction. Moreover, we introduce a custom image dataset where we\nsystematically manipulate salient and semantic information. We find that\nResNets are more sensitive to saliency information than ViTs, when trained with\nobject classification objectives. We uncover that networks suppress saliency in\nearly layers, a process enhanced by natural language supervision (CLIP) in\nResNets. CLIP also enhances semantic encoding in both architectures. Finally,\nwe show that semantic encoding is a key factor in aligning AI with human visual\nperception, while saliency suppression is a non-brain-like strategy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18772v1",
    "published_date": "2024-04-29 15:05:42 UTC",
    "updated_date": "2024-04-29 15:05:42 UTC"
  },
  {
    "arxiv_id": "2404.18766v1",
    "title": "PECC: Problem Extraction and Coding Challenges",
    "authors": [
      "Patrick Haller",
      "Jonas Golde",
      "Alan Akbik"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have showcased their\nexceptional abilities across various tasks, such as code generation,\nproblem-solving and reasoning. Existing benchmarks evaluate tasks in isolation,\nyet the extent to which LLMs can understand prose-style tasks, identify the\nunderlying problems, and then generate appropriate code solutions is still\nunexplored. Addressing this gap, we introduce PECC, a novel benchmark derived\nfrom Advent Of Code (AoC) challenges and Project Euler, including 2396\nproblems. Unlike conventional benchmarks, PECC requires LLMs to interpret\nnarrative-embedded problems, extract requirements, and generate executable\ncode. A key feature of our dataset is the complexity added by natural language\nprompting in chat-based evaluations, mirroring real-world instruction\nambiguities. Results show varying model performance between narrative and\nneutral problems, with specific challenges in the Euler math-based subset with\nGPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler\nproblems. By probing the limits of LLMs' capabilities, our benchmark provides a\nframework to monitor and assess the subsequent progress of LLMs as a universal\nproblem solver.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper got accepted at LREC-COLING 2024 (long)",
    "pdf_url": "http://arxiv.org/pdf/2404.18766v1",
    "published_date": "2024-04-29 15:02:14 UTC",
    "updated_date": "2024-04-29 15:02:14 UTC"
  },
  {
    "arxiv_id": "2406.14567v2",
    "title": "DragPoser: Motion Reconstruction from Variable Sparse Tracking Signals via Latent Space Optimization",
    "authors": [
      "Jose Luis Ponton",
      "Eduard Pujol",
      "Andreas Aristidou",
      "Carlos Andujar",
      "Nuria Pelechano"
    ],
    "abstract": "High-quality motion reconstruction that follows the user's movements can be\nachieved by high-end mocap systems with many sensors. However, obtaining such\nanimation quality with fewer input devices is gaining popularity as it brings\nmocap closer to the general public. The main challenges include the loss of\nend-effector accuracy in learning-based approaches, or the lack of naturalness\nand smoothness in IK-based solutions. In addition, such systems are often\nfinely tuned to a specific number of trackers and are highly sensitive to\nmissing data e.g., in scenarios where a sensor is occluded or malfunctions. In\nresponse to these challenges, we introduce DragPoser, a novel\ndeep-learning-based motion reconstruction system that accurately represents\nhard and dynamic on-the-fly constraints, attaining real-time high end-effectors\nposition accuracy. This is achieved through a pose optimization process within\na structured latent space. Our system requires only one-time training on a\nlarge human motion dataset, and then constraints can be dynamically defined as\nlosses, while the pose is iteratively refined by computing the gradients of\nthese losses within the latent space. To further enhance our approach, we\nincorporate a Temporal Predictor network, which employs a Transformer\narchitecture to directly encode temporality within the latent space. This\nnetwork ensures the pose optimization is confined to the manifold of valid\nposes and also leverages past pose data to predict temporally coherent poses.\nResults demonstrate that DragPoser surpasses both IK-based and the latest\ndata-driven methods in achieving precise end-effector positioning, while it\nproduces natural poses and temporally coherent motion. In addition, our system\nshowcases robustness against on-the-fly constraint modifications, and exhibits\nexceptional adaptability to various input configurations and changes.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Published on Eurographics 2025. Project page:\n  https://upc-virvig.github.io/DragPoser/",
    "pdf_url": "http://arxiv.org/pdf/2406.14567v2",
    "published_date": "2024-04-29 15:00:50 UTC",
    "updated_date": "2025-04-10 18:42:57 UTC"
  },
  {
    "arxiv_id": "2404.18978v1",
    "title": "Towards Generalizable Agents in Text-Based Educational Environments: A Study of Integrating RL with LLMs",
    "authors": [
      "Bahar Radmehr",
      "Adish Singla",
      "Tanja Käser"
    ],
    "abstract": "There has been a growing interest in developing learner models to enhance\nlearning and teaching experiences in educational environments. However,\nexisting works have primarily focused on structured environments relying on\nmeticulously crafted representations of tasks, thereby limiting the agent's\nability to generalize skills across tasks. In this paper, we aim to enhance the\ngeneralization capabilities of agents in open-ended text-based learning\nenvironments by integrating Reinforcement Learning (RL) with Large Language\nModels (LLMs). We investigate three types of agents: (i) RL-based agents that\nutilize natural language for state and action representations to find the best\ninteraction strategy, (ii) LLM-based agents that leverage the model's general\nknowledge and reasoning through prompting, and (iii) hybrid LLM-assisted RL\nagents that combine these two strategies to improve agents' performance and\ngeneralization. To support the development and evaluation of these agents, we\nintroduce PharmaSimText, a novel benchmark derived from the PharmaSim virtual\npharmacy environment designed for practicing diagnostic conversations. Our\nresults show that RL-based agents excel in task completion but lack in asking\nquality diagnostic questions. In contrast, LLM-based agents perform better in\nasking diagnostic questions but fall short of completing the task. Finally,\nhybrid LLM-assisted RL agents enable us to overcome these limitations,\nhighlighting the potential of combining RL and LLMs to develop high-performing\nagents for open-ended learning environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a full paper at EDM 2024: The 17th International\n  Conference on Educational Data Mining, 14-17 of July 2024, Atlanta",
    "pdf_url": "http://arxiv.org/pdf/2404.18978v1",
    "published_date": "2024-04-29 14:53:48 UTC",
    "updated_date": "2024-04-29 14:53:48 UTC"
  },
  {
    "arxiv_id": "2404.18747v1",
    "title": "Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment",
    "authors": [
      "Shanle Yao",
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Hamed Tabkhi"
    ],
    "abstract": "Video Anomaly Detection (VAD) identifies unusual activities in video streams,\na key technology with broad applications ranging from surveillance to\nhealthcare. Tackling VAD in real-life settings poses significant challenges due\nto the dynamic nature of human actions, environmental variations, and domain\nshifts. Many research initiatives neglect these complexities, often\nconcentrating on traditional testing methods that fail to account for\nperformance on unseen datasets, creating a gap between theoretical models and\ntheir real-world utility. Online learning is a potential strategy to mitigate\nthis issue by allowing models to adapt to new information continuously. This\npaper assesses how well current VAD algorithms can adjust to real-life\nconditions through an online learning framework, particularly those based on\npose analysis, for their efficiency and privacy advantages. Our proposed\nframework enables continuous model updates with streaming data from novel\nenvironments, thus mirroring actual world challenges and evaluating the models'\nability to adapt in real-time while maintaining accuracy. We investigate three\nstate-of-the-art models in this setting, focusing on their adaptability across\ndifferent domains. Our findings indicate that, even under the most challenging\nconditions, our online learning approach allows a model to preserve 89.39% of\nits original effectiveness compared to its offline-trained counterpart in a\nspecific target domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18747v1",
    "published_date": "2024-04-29 14:47:32 UTC",
    "updated_date": "2024-04-29 14:47:32 UTC"
  },
  {
    "arxiv_id": "2404.18976v1",
    "title": "Foundations of Multisensory Artificial Intelligence",
    "authors": [
      "Paul Pu Liang"
    ],
    "abstract": "Building multisensory AI systems that learn from multiple sensory inputs such\nas text, speech, video, real-world sensors, wearable devices, and medical data\nholds great promise for impact in many scientific areas with practical\nbenefits, such as in supporting human health and well-being, enabling\nmultimedia content processing, and enhancing real-world autonomous agents. By\nsynthesizing a range of theoretical frameworks and application domains, this\nthesis aims to advance the machine learning foundations of multisensory AI. In\nthe first part, we present a theoretical framework formalizing how modalities\ninteract with each other to give rise to new information for a task. These\ninteractions are the basic building blocks in all multimodal problems, and\ntheir quantification enables users to understand their multimodal datasets,\ndesign principled approaches to learn these interactions, and analyze whether\ntheir model has succeeded in learning. In the second part, we study the design\nof practical multimodal foundation models that generalize over many modalities\nand tasks, which presents a step toward grounding large language models to\nreal-world sensory modalities. We introduce MultiBench, a unified large-scale\nbenchmark across a wide range of modalities, tasks, and research areas,\nfollowed by the cross-modal attention and multimodal transformer architectures\nthat now underpin many of today's multimodal foundation models. Scaling these\narchitectures on MultiBench enables the creation of general-purpose\nmultisensory AI systems, and we discuss our collaborative efforts in applying\nthese models for real-world impact in affective computing, mental health,\ncancer prognosis, and robotics. Finally, we conclude this thesis by discussing\nhow future work can leverage these ideas toward more general, interactive, and\nsafe multisensory AI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "CMU Machine Learning Department PhD Thesis",
    "pdf_url": "http://arxiv.org/pdf/2404.18976v1",
    "published_date": "2024-04-29 14:45:28 UTC",
    "updated_date": "2024-04-29 14:45:28 UTC"
  },
  {
    "arxiv_id": "2404.18975v3",
    "title": "M3H: Multimodal Multitask Machine Learning for Healthcare",
    "authors": [
      "Dimitris Bertsimas",
      "Yu Ma"
    ],
    "abstract": "Developing an integrated many-to-many framework leveraging multimodal data\nfor multiple tasks is crucial to unifying healthcare applications ranging from\ndiagnoses to operations. In resource-constrained hospital environments, a\nscalable and unified machine learning framework that improves previous forecast\nperformances could improve hospital operations and save costs. We introduce\nM3H, an explainable Multimodal Multitask Machine Learning for Healthcare\nframework that consolidates learning from tabular, time-series, language, and\nvision data for supervised binary/multiclass classification, regression, and\nunsupervised clustering. It features a novel attention mechanism balancing\nself-exploitation (learning source-task), and cross-exploration (learning\ncross-tasks), and offers explainability through a proposed TIM score, shedding\nlight on the dynamics of task learning interdependencies. M3H encompasses an\nunprecedented range of medical tasks and machine learning problem classes and\nconsistently outperforms traditional single-task models by on average 11.6%\nacross 40 disease diagnoses from 16 medical departments, three hospital\noperation forecasts, and one patient phenotyping task. The modular design of\nthe framework ensures its generalizability in data processing, task definition,\nand rapid model prototyping, making it production ready for both clinical and\noperational healthcare settings, especially those in constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18975v3",
    "published_date": "2024-04-29 14:39:15 UTC",
    "updated_date": "2024-06-08 19:11:57 UTC"
  },
  {
    "arxiv_id": "2404.18736v4",
    "title": "Mapping the Potential of Explainable AI for Fairness Along the AI Lifecycle",
    "authors": [
      "Luca Deck",
      "Astrid Schomäcker",
      "Timo Speith",
      "Jakob Schöffer",
      "Lena Kästner",
      "Niklas Kühl"
    ],
    "abstract": "The widespread use of artificial intelligence (AI) systems across various\ndomains is increasingly surfacing issues related to algorithmic fairness,\nespecially in high-stakes scenarios. Thus, critical considerations of how\nfairness in AI systems might be improved -- and what measures are available to\naid this process -- are overdue. Many researchers and policymakers see\nexplainable AI (XAI) as a promising way to increase fairness in AI systems.\nHowever, there is a wide variety of XAI methods and fairness conceptions\nexpressing different desiderata, and the precise connections between XAI and\nfairness remain largely nebulous. Besides, different measures to increase\nalgorithmic fairness might be applicable at different points throughout an AI\nsystem's lifecycle. Yet, there currently is no coherent mapping of fairness\ndesiderata along the AI lifecycle. In this paper, we we distill eight fairness\ndesiderata, map them along the AI lifecycle, and discuss how XAI could help\naddress each of them. We hope to provide orientation for practical applications\nand to inspire XAI research specifically focused on these fairness desiderata.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18736v4",
    "published_date": "2024-04-29 14:34:43 UTC",
    "updated_date": "2024-06-27 11:43:10 UTC"
  },
  {
    "arxiv_id": "2406.15395v1",
    "title": "An Exploratory Study on Human-Centric Video Anomaly Detection through Variational Autoencoders and Trajectory Prediction",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Hamed Tabkhi"
    ],
    "abstract": "Video Anomaly Detection (VAD) represents a challenging and prominent research\ntask within computer vision. In recent years, Pose-based Video Anomaly\nDetection (PAD) has drawn considerable attention from the research community\ndue to several inherent advantages over pixel-based approaches despite the\noccasional suboptimal performance. Specifically, PAD is characterized by\nreduced computational complexity, intrinsic privacy preservation, and the\nmitigation of concerns related to discrimination and bias against specific\ndemographic groups. This paper introduces TSGAD, a novel human-centric\nTwo-Stream Graph-Improved Anomaly Detection leveraging Variational Autoencoders\n(VAEs) and trajectory prediction. TSGAD aims to explore the possibility of\nutilizing VAEs as a new approach for pose-based human-centric VAD alongside the\nbenefits of trajectory prediction. We demonstrate TSGAD's effectiveness through\ncomprehensive experimentation on benchmark datasets. TSGAD demonstrates\ncomparable results with state-of-the-art methods showcasing the potential of\nadopting variational autoencoders. This suggests a promising direction for\nfuture research endeavors. The code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/TSGAD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15395v1",
    "published_date": "2024-04-29 14:25:06 UTC",
    "updated_date": "2024-04-29 14:25:06 UTC"
  },
  {
    "arxiv_id": "2404.18731v3",
    "title": "Real Time Multi Organ Classification on Computed Tomography Images",
    "authors": [
      "Halid Ziya Yerebakan",
      "Yoshihisa Shinagawa",
      "Gerardo Hermosillo Valadez"
    ],
    "abstract": "Organ segmentation is a fundamental task in medical imaging since it is\nuseful for many clinical automation pipelines. However, some tasks do not\nrequire full segmentation. Instead, a classifier can identify the selected\norgan without segmenting the entire volume. In this study, we demonstrate a\nclassifier based method to obtain organ labels in real time by using a large\ncontext size with a sparse data sampling strategy. Although our method operates\nas an independent classifier at query locations, it can generate full\nsegmentations by querying grid locations at any resolution, offering faster\nperformance than segmentation algorithms. We compared our method with existing\nsegmentation techniques, demonstrating its superior runtime potential for\npractical applications in medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, Organ Classification, Organ Segmentation",
    "pdf_url": "http://arxiv.org/pdf/2404.18731v3",
    "published_date": "2024-04-29 14:17:52 UTC",
    "updated_date": "2025-01-09 22:10:14 UTC"
  },
  {
    "arxiv_id": "2404.18730v1",
    "title": "CVTN: Cross Variable and Temporal Integration for Time Series Forecasting",
    "authors": [
      "Han Zhou",
      "Yuntian Chen"
    ],
    "abstract": "In multivariate time series forecasting, the Transformer architecture\nencounters two significant challenges: effectively mining features from\nhistorical sequences and avoiding overfitting during the learning of temporal\ndependencies. To tackle these challenges, this paper deconstructs time series\nforecasting into the learning of historical sequences and prediction sequences,\nintroducing the Cross-Variable and Time Network (CVTN). This unique method\ndivides multivariate time series forecasting into two phases: cross-variable\nlearning for effectively mining fea tures from historical sequences, and\ncross-time learning to capture the temporal dependencies of prediction\nsequences. Separating these two phases helps avoid the impact of overfitting in\ncross-time learning on cross-variable learning. Exten sive experiments on\nvarious real-world datasets have confirmed its state-of-the-art (SOTA)\nperformance. CVTN emphasizes three key dimensions in time series fore casting:\nthe short-term and long-term nature of time series (locality and longevity),\nfeature mining from both historical and prediction sequences, and the\nintegration of cross-variable and cross-time learning. This approach not only\nadvances the current state of time series forecasting but also provides a more\ncomprehensive framework for future research in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18730v1",
    "published_date": "2024-04-29 14:16:16 UTC",
    "updated_date": "2024-04-29 14:16:16 UTC"
  },
  {
    "arxiv_id": "2404.18713v3",
    "title": "Task and Domain Adaptive Reinforcement Learning for Robot Control",
    "authors": [
      "Yu Tang Liu",
      "Nilaksh Singh",
      "Aamir Ahmad"
    ],
    "abstract": "Deep reinforcement learning (DRL) has shown remarkable success in simulation\ndomains, yet its application in designing robot controllers remains limited,\ndue to its single-task orientation and insufficient adaptability to\nenvironmental changes. To overcome these limitations, we present a novel\nadaptive agent that leverages transfer learning techniques to dynamically adapt\npolicy in response to different tasks and environmental conditions. The\napproach is validated through the blimp control challenge, where multitasking\ncapabilities and environmental adaptability are essential. The agent is trained\nusing a custom, highly parallelized simulator built on IsaacGym. We perform\nzero-shot transfer to fly the blimp in the real world to solve various tasks.\nWe share our code at https://github.com/robot-perception-group/adaptive_agent.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18713v3",
    "published_date": "2024-04-29 14:02:02 UTC",
    "updated_date": "2024-09-19 02:36:53 UTC"
  },
  {
    "arxiv_id": "2405.09637v2",
    "title": "CLASSP: a Biologically-Inspired Approach to Continual Learning through Adjustment Suppression and Sparsity Promotion",
    "authors": [
      "Oswaldo Ludwig"
    ],
    "abstract": "This paper introduces a new biologically-inspired training method named\nContinual Learning through Adjustment Suppression and Sparsity Promotion\n(CLASSP). CLASSP is based on two main principles observed in neuroscience,\nparticularly in the context of synaptic transmission and Long-Term Potentiation\n(LTP). The first principle is a decay rate over the weight adjustment, which is\nimplemented as a generalization of the AdaGrad optimization algorithm. This\nmeans that weights that have received many updates should have lower learning\nrates as they likely encode important information about previously seen data.\nHowever, this principle results in a diffuse distribution of updates throughout\nthe model, as it promotes updates for weights that haven't been previously\nupdated, while a sparse update distribution is preferred to leave weights\nunassigned for future tasks. Therefore, the second principle introduces a\nthreshold on the loss gradient. This promotes sparse learning by updating a\nweight only if the loss gradient with respect to that weight is above a certain\nthreshold, i.e. only updating weights with a significant impact on the current\nloss. Both principles reflect phenomena observed in LTP, where a threshold\neffect and a gradual saturation of potentiation have been observed. CLASSP is\nimplemented in a Python/PyTorch class, making it applicable to any model. When\ncompared with Elastic Weight Consolidation (EWC) using Computer Vision and\nsentiment analysis datasets, CLASSP demonstrates superior performance in terms\nof accuracy and memory footprint.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "In this version I included a new experiment in text classification\n  using transformer architecture",
    "pdf_url": "http://arxiv.org/pdf/2405.09637v2",
    "published_date": "2024-04-29 13:31:00 UTC",
    "updated_date": "2024-06-08 21:02:15 UTC"
  },
  {
    "arxiv_id": "2405.01591v1",
    "title": "Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model",
    "authors": [
      "Seonhee Cho",
      "Choonghan Kim",
      "Jiho Lee",
      "Chetan Chilkunda",
      "Sujin Choi",
      "Joo Heung Yoon"
    ],
    "abstract": "Recent advancements in Large Multimodal Models (LMMs) have attracted interest\nin their generalization capability with only a few samples in the prompt. This\nprogress is particularly relevant to the medical domain, where the quality and\nsensitivity of data pose unique challenges for model training and application.\nHowever, the dependency on high-quality data for effective in-context learning\nraises questions about the feasibility of these models when encountering with\nthe inevitable variations and errors inherent in real-world medical data. In\nthis paper, we introduce MID-M, a novel framework that leverages the in-context\nlearning capabilities of a general-domain Large Language Model (LLM) to process\nmultimodal data via image descriptions. MID-M achieves a comparable or superior\nperformance to task-specific fine-tuned LMMs and other general-domain ones,\nwithout the extensive domain-specific training or pre-training on multimodal\ndata, with significantly fewer parameters. This highlights the potential of\nleveraging general-domain LLMs for domain-specific tasks and offers a\nsustainable and cost-effective alternative to traditional LMM developments.\nMoreover, the robustness of MID-M against data quality issues demonstrates its\npractical utility in real-world medical domain applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.01591v1",
    "published_date": "2024-04-29 13:23:33 UTC",
    "updated_date": "2024-04-29 13:23:33 UTC"
  },
  {
    "arxiv_id": "2404.18672v1",
    "title": "Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report",
    "authors": [
      "Paul Cibier",
      "Jean-Guy Mailly"
    ],
    "abstract": "Various approaches have been proposed for providing efficient computational\napproaches for abstract argumentation. Among them, neural networks have\npermitted to solve various decision problems, notably related to arguments\n(credulous or skeptical) acceptability. In this work, we push further this\nstudy in various ways. First, relying on the state-of-the-art approach AFGCN,\nwe show how we can improve the performances of the Graph Convolutional Networks\n(GCNs) regarding both runtime and accuracy. Then, we show that it is possible\nto improve even more the efficiency of the approach by modifying the\narchitecture of the network, using Graph Attention Networks (GATs) instead.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 2 figures. Submitted to the 10th International Conference\n  on Computational Models of Argument (COMMA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.18672v1",
    "published_date": "2024-04-29 13:12:08 UTC",
    "updated_date": "2024-04-29 13:12:08 UTC"
  },
  {
    "arxiv_id": "2404.18669v3",
    "title": "Bootstrap-GS: Self-Supervised Augmentation for High-Fidelity Gaussian Splatting",
    "authors": [
      "Yifei Gao",
      "Kerui Ren",
      "Jie Ou",
      "Lei Wang",
      "Jiaji Wu",
      "Jun Cheng"
    ],
    "abstract": "Recent advancements in 3D Gaussian Splatting (3D-GS) have established new\nbenchmarks for rendering quality and efficiency in 3D reconstruction. However,\n3D-GS faces critical limitations when generating novel views that significantly\ndeviate from those encountered during training. Moreover, issues such as\ndilation and aliasing arise during zoom operations. These challenges stem from\na fundamental issue: training sampling deficiency. In this paper, we introduce\na bootstrapping framework to address this problem. Our approach synthesizes\npseudo-ground truth from novel views that align with the limited training set\nand reintegrates these synthesized views into the training pipeline.\nExperimental results demonstrate that our bootstrapping technique not only\nreduces artifacts but also improves quantitative metrics. Furthermore, our\ntechnique is highly adaptable, allowing various Gaussian-based method to\nbenefit from its integration.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "I.4.8"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18669v3",
    "published_date": "2024-04-29 12:57:05 UTC",
    "updated_date": "2025-03-04 01:06:32 UTC"
  },
  {
    "arxiv_id": "2404.18655v1",
    "title": "Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods",
    "authors": [
      "Haeun Yu",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "abstract": "Language Models (LMs) acquire parametric knowledge from their training\nprocess, embedding it within their weights. The increasing scalability of LMs,\nhowever, poses significant challenges for understanding a model's inner\nworkings and further for updating or correcting this embedded knowledge without\nthe significant cost of retraining. This underscores the importance of\nunveiling exactly what knowledge is stored and its association with specific\nmodel components. Instance Attribution (IA) and Neuron Attribution (NA) offer\ninsights into this training-acquired knowledge, though they have not been\ncompared systematically. Our study introduces a novel evaluation framework to\nquantify and compare the knowledge revealed by IA and NA. To align the results\nof the methods we introduce the attribution method NA-Instances to apply NA for\nretrieving influential training instances, and IA-Neurons to discover important\nneurons of influential instances discovered by IA. We further propose a\ncomprehensive list of faithfulness tests to evaluate the comprehensiveness and\nsufficiency of the explanations provided by both methods. Through extensive\nexperiments and analysis, we demonstrate that NA generally reveals more diverse\nand comprehensive information regarding the LM's parametric knowledge compared\nto IA. Nevertheless, IA provides unique and valuable insights into the LM's\nparametric knowledge, which are not revealed by NA. Our findings further\nsuggest the potential of a synergistic approach of combining the diverse\nfindings of IA and NA for a more holistic understanding of an LM's parametric\nknowledge.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18655v1",
    "published_date": "2024-04-29 12:38:26 UTC",
    "updated_date": "2024-04-29 12:38:26 UTC"
  },
  {
    "arxiv_id": "2404.18649v1",
    "title": "Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection",
    "authors": [
      "Konstantinos Tsigos",
      "Evlampios Apostolidis",
      "Spyridon Baxevanakis",
      "Symeon Papadopoulos",
      "Vasileios Mezaris"
    ],
    "abstract": "In this paper we propose a new framework for evaluating the performance of\nexplanation methods on the decisions of a deepfake detector. This framework\nassesses the ability of an explanation method to spot the regions of a fake\nimage with the biggest influence on the decision of the deepfake detector, by\nexamining the extent to which these regions can be modified through a set of\nadversarial attacks, in order to flip the detector's prediction or reduce its\ninitial prediction; we anticipate a larger drop in deepfake detection accuracy\nand prediction, for methods that spot these regions more accurately. Based on\nthis framework, we conduct a comparative study using a state-of-the-art model\nfor deepfake detection that has been trained on the FaceForensics++ dataset,\nand five explanation methods from the literature. The findings of our\nquantitative and qualitative evaluations document the advanced performance of\nthe LIME explanation method against the other compared ones, and indicate this\nmethod as the most appropriate for explaining the decisions of the utilized\ndeepfake detector.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication, 3rd ACM Int. Workshop on Multimedia AI\n  against Disinformation (MAD'24) at ACM ICMR'24, June 10, 2024, Phuket,\n  Thailand. This is the \"accepted version\"",
    "pdf_url": "http://arxiv.org/pdf/2404.18649v1",
    "published_date": "2024-04-29 12:32:14 UTC",
    "updated_date": "2024-04-29 12:32:14 UTC"
  },
  {
    "arxiv_id": "2404.18638v1",
    "title": "Reinforcement Learning Problem Solving with Large Language Models",
    "authors": [
      "Sina Gholamian",
      "Domingo Huh"
    ],
    "abstract": "Large Language Models (LLMs) encapsulate an extensive amount of world\nknowledge, and this has enabled their application in various domains to improve\nthe performance of a variety of Natural Language Processing (NLP) tasks. This\nhas also facilitated a more accessible paradigm of conversation-based\ninteractions between humans and AI systems to solve intended problems. However,\none interesting avenue that shows untapped potential is the use of LLMs as\nReinforcement Learning (RL) agents to enable conversational RL problem solving.\nTherefore, in this study, we explore the concept of formulating Markov Decision\nProcess-based RL problems as LLM prompting tasks. We demonstrate how LLMs can\nbe iteratively prompted to learn and optimize policies for specific RL tasks.\nIn addition, we leverage the introduced prompting technique for episode\nsimulation and Q-Learning, facilitated by LLMs. We then show the practicality\nof our approach through two detailed case studies for \"Research Scientist\" and\n\"Legal Matter Intake\" workflows.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18638v1",
    "published_date": "2024-04-29 12:16:08 UTC",
    "updated_date": "2024-04-29 12:16:08 UTC"
  },
  {
    "arxiv_id": "2404.18624v4",
    "title": "Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?",
    "authors": [
      "Letitia Parcalabescu",
      "Anette Frank"
    ],
    "abstract": "Vision and language model (VLM) decoders are currently the best-performing\narchitectures on multimodal tasks. Next to answers, they are able to produce\nnatural language explanations, either in post-hoc or CoT settings. However, it\nis not clear to what extent they are using the input vision and text modalities\nwhen generating answers or explanations. In this work, we investigate if VLMs\nrely on their input modalities differently when they produce explanations as\nopposed to answers. We also evaluate the self-consistency of VLM decoders in\nboth post-hoc and CoT explanation settings, by extending existing unimodal\ntests and measures to VLM decoders. We find that most tested VLMs are less\nself-consistent than LLMs. Text contributions in all tested VL decoders are\nmore important than image contributions in all examined tasks. However, when\ncomparing explanation generation to answer generation, the contributions of\nimages are significantly stronger for generating explanations compared to\nanswers. This difference is even larger in CoT compared to post-hoc\nexplanations. Lastly, we provide an up-to-date benchmarking of state-of-the-art\nVL decoders on the VALSE benchmark, which before was restricted to VL encoders.\nWe find that the tested VL decoders still struggle with most phenomena tested\nby VALSE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "68Txx",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 8 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.18624v4",
    "published_date": "2024-04-29 11:52:20 UTC",
    "updated_date": "2025-05-01 18:40:41 UTC"
  },
  {
    "arxiv_id": "2404.18604v1",
    "title": "CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation",
    "authors": [
      "Xiangyu Liang",
      "Wenlin Zhuang",
      "Tianyong Wang",
      "Guangxing Geng",
      "Guangyue Geng",
      "Haifeng Xia",
      "Siyu Xia"
    ],
    "abstract": "Speech-driven 3D facial animation technology has been developed for years,\nbut its practical application still lacks expectations. The main challenges lie\nin data limitations, lip alignment, and the naturalness of facial expressions.\nAlthough lip alignment has seen many related studies, existing methods struggle\nto synthesize natural and realistic expressions, resulting in a mechanical and\nstiff appearance of facial animations. Even with some research extracting\nemotional features from speech, the randomness of facial movements limits the\neffective expression of emotions. To address this issue, this paper proposes a\nmethod called CSTalk (Correlation Supervised) that models the correlations\namong different regions of facial movements and supervises the training of the\ngenerative model to generate realistic expressions that conform to human facial\nmotion patterns. To generate more intricate animations, we employ a rich set of\ncontrol parameters based on the metahuman character model and capture a dataset\nfor five different emotions. We train a generative network using an autoencoder\nstructure and input an emotion embedding vector to achieve the generation of\nuser-control expressions. Experimental results demonstrate that our method\noutperforms existing state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18604v1",
    "published_date": "2024-04-29 11:19:15 UTC",
    "updated_date": "2024-04-29 11:19:15 UTC"
  },
  {
    "arxiv_id": "2405.04585v1",
    "title": "PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large Language Models",
    "authors": [
      "Arpit Aggarwal"
    ],
    "abstract": "There are several improvements proposed over the baseline Absolute Positional\nEncoding (APE) method used in original transformer. In this study, we aim to\ninvestigate the implications of inadequately representing positional encoding\nin higher dimensions on crucial aspects of the attention mechanism, the model's\ncapacity to learn relative positional information, and the convergence of\nmodels, all stemming from the choice of sinusoidal basis functions. Through a\ncombination of theoretical insights and empirical analyses, we elucidate how\nthese challenges extend beyond APEs and may adversely affect the performance of\nRelative Positional Encoding (RPE) methods, such as Rotatory Positional\nEncoding (RoPE).\n  Subsequently, we introduce an innovative solution termed Orthogonal\nPolynomial Based Positional Encoding (PoPE) to address some of the limitations\nassociated with existing methods. The PoPE method encodes positional\ninformation by leveraging Orthogonal Legendre polynomials. Legendre polynomials\nas basis functions offers several desirable properties for positional encoding,\nincluding improved correlation structure, non-periodicity, orthogonality, and\ndistinct functional forms among polynomials of varying orders. Our experimental\nfindings demonstrate that transformer models incorporating PoPE outperform\nbaseline transformer models on the $Multi30k$ English-to-German translation\ntask, thus establishing a new performance benchmark. Furthermore, PoPE-based\ntransformers exhibit significantly accelerated convergence rates.\n  Additionally, we will present novel theoretical perspectives on position\nencoding based on the superior performance of PoPE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04585v1",
    "published_date": "2024-04-29 10:30:59 UTC",
    "updated_date": "2024-04-29 10:30:59 UTC"
  },
  {
    "arxiv_id": "2404.18564v1",
    "title": "Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning",
    "authors": [
      "Wen-Yu Chang",
      "Yun-Nung Chen"
    ],
    "abstract": "Recent research in dialogue systems and corpora has focused on two main\ncategories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD\nsystems help users accomplish specific tasks, while open-domain systems aim to\ncreate engaging conversations. However, in real-world scenarios, user intents\nare often revealed during interactions. A recent study introduced SalesBot,\nwhich simulates dialogues transitioning from chit-chat to task-oriented\nscenarios to train sales agents. Unfortunately, the initial data lacked smooth\ntransitions and coherent long-turn dialogues, resulting in poor naturalness in\nsales-customer interactions. To address these issues, this paper presents\nSalesBot 2.0, an improved dataset. It leverages commonsense knowledge from\nlarge language models (LLMs) through strategic prompting. Additionally, we\nintroduce a novel model called SalesAgent, trained on salesperson's\ninteractions, using chain-of-thought (CoT) reasoning. This model excels in\ntransitioning topics, understanding user intents, and selecting appropriate\nstrategies. Experiments using diverse user simulations validate the\neffectiveness of our method in controlling dialogue strategies in LLMs.\nFurthermore, SalesBot 2.0 enhances coherence and reduces aggression,\nfacilitating better model learning for sales-customer interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2308.14266",
    "pdf_url": "http://arxiv.org/pdf/2404.18564v1",
    "published_date": "2024-04-29 10:12:04 UTC",
    "updated_date": "2024-04-29 10:12:04 UTC"
  },
  {
    "arxiv_id": "2405.00734v2",
    "title": "EEG-MACS: Manifold Attention and Confidence Stratification for EEG-based Cross-Center Brain Disease Diagnosis under Unreliable Annotations",
    "authors": [
      "Zhenxi Song",
      "Ruihan Qin",
      "Huixia Ren",
      "Zhen Liang",
      "Yi Guo",
      "Min Zhang",
      "Zhiguo Zhang"
    ],
    "abstract": "Cross-center data heterogeneity and annotation unreliability significantly\nchallenge the intelligent diagnosis of diseases using brain signals. A notable\nexample is the EEG-based diagnosis of neurodegenerative diseases, which\nfeatures subtler abnormal neural dynamics typically observed in small-group\nsettings. To advance this area, in this work, we introduce a transferable\nframework employing Manifold Attention and Confidence Stratification (MACS) to\ndiagnose neurodegenerative disorders based on EEG signals sourced from four\ncenters with unreliable annotations. The MACS framework's effectiveness stems\nfrom these features: 1) The Augmentor generates various EEG-represented brain\nvariants to enrich the data space; 2) The Switcher enhances the feature space\nfor trusted samples and reduces overfitting on incorrectly labeled samples; 3)\nThe Encoder uses the Riemannian manifold and Euclidean metrics to capture\nspatiotemporal variations and dynamic synchronization in EEG; 4) The Projector,\nequipped with dual heads, monitors consistency across multiple brain variants\nand ensures diagnostic accuracy; 5) The Stratifier adaptively stratifies\nlearned samples by confidence levels throughout the training process; 6)\nForward and backpropagation in MACS are constrained by confidence\nstratification to stabilize the learning system amid unreliable annotations.\nOur subject-independent experiments, conducted on both neurocognitive and\nmovement disorders using cross-center corpora, have demonstrated superior\nperformance compared to existing related algorithms. This work not only\nimproves EEG-based diagnostics for cross-center and small-setting brain\ndiseases but also offers insights into extending MACS techniques to other data\nanalyses, tackling data heterogeneity and annotation unreliability in\nmultimedia and multimodal content understanding.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00734v2",
    "published_date": "2024-04-29 10:08:43 UTC",
    "updated_date": "2024-08-13 16:03:38 UTC"
  },
  {
    "arxiv_id": "2404.18558v1",
    "title": "LangBiTe: A Platform for Testing Bias in Large Language Models",
    "authors": [
      "Sergio Morales",
      "Robert Clarisó",
      "Jordi Cabot"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into various software\napplications raises concerns about their potential biases. Typically, those\nmodels are trained on a vast amount of data scrapped from forums, websites,\nsocial media and other internet sources, which may instill harmful and\ndiscriminating behavior into the model. To address this issue, we present\nLangBiTe, a testing platform to systematically assess the presence of biases\nwithin an LLM. LangBiTe enables development teams to tailor their test\nscenarios, and automatically generate and execute the test cases according to a\nset of user-defined ethical requirements. Each test consists of a prompt fed\ninto the LLM and a corresponding test oracle that scrutinizes the LLM's\nresponse for the identification of biases. LangBite provides users with the\nbias evaluation of LLMs, and end-to-end traceability between the initial\nethical requirements and the insights obtained.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18558v1",
    "published_date": "2024-04-29 10:02:45 UTC",
    "updated_date": "2024-04-29 10:02:45 UTC"
  },
  {
    "arxiv_id": "2404.18555v1",
    "title": "Machine Learning for Quantum Computing Specialists",
    "authors": [
      "Daniel Goldsmith",
      "M M Hassan Mahmud"
    ],
    "abstract": "Quantum machine learning (QML) is a promising early use case for quantum\ncomputing. There has been progress in the last five years from theoretical\nstudies and numerical simulations to proof of concepts. Use cases demonstrated\non contemporary quantum devices include classifying medical images and items\nfrom the Iris dataset, classifying and generating handwritten images, toxicity\nscreening, and learning a probability distribution. Potential benefits of QML\ninclude faster training and identification of feature maps not found\nclassically. Although, these examples lack the scale for commercial\nexploitation, and it may be several years before QML algorithms replace the\nclassical solutions, QML is an exciting area.\n  This article is written for those who already have a sound knowledge of\nquantum computing and now wish to gain a basic overview of the terminology and\nsome applications of classical machine learning ready to study quantum machine\nlearning. The reader will already understand the relevant relevant linear\nalgebra, including Hilbert spaces, a vector space with an inner product.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "I.2.m"
    ],
    "primary_category": "quant-ph",
    "comment": "32 pages, 21 figures, technical report",
    "pdf_url": "http://arxiv.org/pdf/2404.18555v1",
    "published_date": "2024-04-29 09:54:06 UTC",
    "updated_date": "2024-04-29 09:54:06 UTC"
  },
  {
    "arxiv_id": "2404.18553v1",
    "title": "Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting",
    "authors": [
      "Gareth Davies"
    ],
    "abstract": "Autoregressive Recurrent Neural Networks are widely employed in time-series\nforecasting tasks, demonstrating effectiveness in univariate and certain\nmultivariate scenarios. However, their inherent structure does not readily\naccommodate the integration of future, time-dependent covariates. A proposed\nsolution, outlined by Salinas et al 2019, suggests forecasting both covariates\nand the target variable in a multivariate framework. In this study, we\nconducted comprehensive tests on publicly available time-series datasets,\nartificially introducing highly correlated covariates to future time-step\nvalues. Our evaluation aimed to assess the performance of an LSTM network when\nconsidering these covariates and compare it against a univariate baseline. As\npart of this study we introduce a novel approach using seasonal time segments\nin combination with an RNN architecture, which is both simple and extremely\neffective over long forecast horizons with comparable performance to many state\nof the art architectures. Our findings from the results of more than 120 models\nreveal that under certain conditions jointly training covariates with target\nvariables can improve overall performance of the model, but often there exists\na significant performance disparity between multivariate and univariate\npredictions. Surprisingly, even when provided with covariates informing the\nnetwork about future target values, multivariate predictions exhibited inferior\nperformance. In essence, compelling the network to predict multiple values can\nprove detrimental to model performance, even in the presence of informative\ncovariates. These results suggest that LSTM architectures may not be suitable\nfor forecasting tasks where predicting covariates would typically be expected\nto enhance model accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "9 content pages (22 total pages), 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18553v1",
    "published_date": "2024-04-29 09:51:25 UTC",
    "updated_date": "2024-04-29 09:51:25 UTC"
  },
  {
    "arxiv_id": "2404.18552v1",
    "title": "SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods",
    "authors": [
      "Manos Schinas",
      "Symeon Papadopoulos"
    ],
    "abstract": "The generative AI technology offers an increasing variety of tools for\ngenerating entirely synthetic images that are increasingly indistinguishable\nfrom real ones. Unlike methods that alter portions of an image, the creation of\ncompletely synthetic images presents a unique challenge and several Synthetic\nImage Detection (SID) methods have recently appeared to tackle it. Yet, there\nis often a large gap between experimental results on benchmark datasets and the\nperformance of methods in the wild. To better address the evaluation needs of\nSID and help close this gap, this paper introduces a benchmarking framework\nthat integrates several state-of-the-art SID models. Our selection of\nintegrated models was based on the utilization of varied input features, and\ndifferent network architectures, aiming to encompass a broad spectrum of\ntechniques. The framework leverages recent datasets with a diverse set of\ngenerative models, high level of photo-realism and resolution, reflecting the\nrapid improvements in image synthesis technology. Additionally, the framework\nenables the study of how image transformations, common in assets shared online,\nsuch as JPEG compression, affect detection performance. SIDBench is available\non https://github.com/mever-team/sidbench and is designed in a modular manner\nto enable easy inclusion of new datasets and SID models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18552v1",
    "published_date": "2024-04-29 09:50:16 UTC",
    "updated_date": "2024-04-29 09:50:16 UTC"
  },
  {
    "arxiv_id": "2404.18541v1",
    "title": "Machine Learning for Windows Malware Detection and Classification: Methods, Challenges and Ongoing Research",
    "authors": [
      "Daniel Gibert"
    ],
    "abstract": "In this chapter, readers will explore how machine learning has been applied\nto build malware detection systems designed for the Windows operating system.\nThis chapter starts by introducing the main components of a Machine Learning\npipeline, highlighting the challenges of collecting and maintaining up-to-date\ndatasets. Following this introduction, various state-of-the-art malware\ndetectors are presented, encompassing both feature-based and deep\nlearning-based detectors. Subsequent sections introduce the primary challenges\nencountered by machine learning-based malware detectors, including concept\ndrift and adversarial attacks. Lastly, this chapter concludes by providing a\nbrief overview of the ongoing research on adversarial defenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18541v1",
    "published_date": "2024-04-29 09:28:57 UTC",
    "updated_date": "2024-04-29 09:28:57 UTC"
  },
  {
    "arxiv_id": "2404.18539v2",
    "title": "Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods",
    "authors": [
      "Chuni Liu",
      "Boyuan Ma",
      "Xiaojuan Ban",
      "Yujie Xie",
      "Hao Wang",
      "Weihua Xue",
      "Jingchao Ma",
      "Ke Xu"
    ],
    "abstract": "Topological consistency plays a crucial role in the task of boundary\nsegmentation for reticular images, such as cell membrane segmentation in neuron\nelectron microscopic images, grain boundary segmentation in material\nmicroscopic images and road segmentation in aerial images. In these fields,\ntopological changes in segmentation results have a serious impact on the\ndownstream tasks, which can even exceed the misalignment of the boundary\nitself. To enhance the topology accuracy in segmentation results, we propose\nthe Skea-Topo Aware loss, which is a novel loss function that takes into\naccount the shape of each object and topological significance of the pixels. It\nconsists of two components. First, a skeleton-aware weighted loss improves the\nsegmentation accuracy by better modeling the object geometry with skeletons.\nSecond, a boundary rectified term effectively identifies and emphasizes\ntopological critical pixels in the prediction errors using both foreground and\nbackground skeletons in the ground truth and predictions. Experiments prove\nthat our method improves topological consistency by up to 7 points in VI\ncompared to 13 state-of-art methods, based on objective and subjective\nassessments across three different boundary segmentation datasets. The code is\navailable at https://github.com/clovermini/Skea_topo.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18539v2",
    "published_date": "2024-04-29 09:27:31 UTC",
    "updated_date": "2024-05-07 13:55:57 UTC"
  },
  {
    "arxiv_id": "2404.18534v2",
    "title": "Evaluating and Mitigating Linguistic Discrimination in Large Language Models",
    "authors": [
      "Guoliang Dong",
      "Haoyu Wang",
      "Jun Sun",
      "Xinyu Wang"
    ],
    "abstract": "By training on text in various languages, large language models (LLMs)\ntypically possess multilingual support and demonstrate remarkable capabilities\nin solving tasks described in different languages. However, LLMs can exhibit\nlinguistic discrimination due to the uneven distribution of training data\nacross languages. That is, LLMs are hard to keep the consistency of responses\nwhen faced with the same task but depicted in different languages.\n  In this study, we first explore the consistency in the LLMs' outputs\nresponding to queries in various languages from two aspects: safety and\nquality. We conduct this analysis with two datasets (AdvBench and NQ) based on\nfour LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results\nshow that LLMs exhibit stronger human alignment capabilities with queries in\nEnglish, French, Russian, and Spanish (only 1.04\\% of harmful queries\nsuccessfully jailbreak on average) compared to queries in Bengali, Georgian,\nNepali and Maithili (27.7\\% of harmful queries jailbreak successfully on\naverage). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs\ntend to produce responses with a higher quality (with 0.1494 $F_1$ score on\naverage) compared to the other languages. Upon these findings, we propose\nLDFighter, a similarity-based voting, to mitigate the linguistic discrimination\nin LLMs. LDFighter ensures consistent service for different language speakers.\nWe evaluate LDFighter with both benign queries and harmful queries. The results\nshow that LDFighter not only significantly reduces the jailbreak success rate\nbut also improve the response quality on average, demonstrating its\neffectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18534v2",
    "published_date": "2024-04-29 09:22:54 UTC",
    "updated_date": "2024-05-10 07:09:02 UTC"
  },
  {
    "arxiv_id": "2404.18533v3",
    "title": "Evaluating Readability and Faithfulness of Concept-based Explanations",
    "authors": [
      "Meng Li",
      "Haoran Jin",
      "Ruixuan Huang",
      "Zhihao Xu",
      "Defu Lian",
      "Zijia Lin",
      "Di Zhang",
      "Xiting Wang"
    ],
    "abstract": "With the growing popularity of general-purpose Large Language Models (LLMs),\ncomes a need for more global explanations of model behaviors. Concept-based\nexplanations arise as a promising avenue for explaining high-level patterns\nlearned by LLMs. Yet their evaluation poses unique challenges, especially due\nto their non-local nature and high dimensional representation in a model's\nhidden space. Current methods approach concepts from different perspectives,\nlacking a unified formalization. This makes evaluating the core measures of\nconcepts, namely faithfulness or readability, challenging. To bridge the gap,\nwe introduce a formal definition of concepts generalizing to diverse\nconcept-based explanations' settings. Based on this, we quantify the\nfaithfulness of a concept explanation via perturbation. We ensure adequate\nperturbation in the high-dimensional space for different concepts via an\noptimization problem. Readability is approximated via an automatic and\ndeterministic measure, quantifying the coherence of patterns that maximally\nactivate a concept while aligning with human understanding. Finally, based on\nmeasurement theory, we apply a meta-evaluation method for evaluating these\nmeasures, generalizable to other types of explanations or tasks as well.\nExtensive experimental analysis has been conducted to inform the selection of\nexplanation evaluation measures.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024; code:\n  https://github.com/hr-jin/Concept-Explanation-Evaluation",
    "pdf_url": "http://arxiv.org/pdf/2404.18533v3",
    "published_date": "2024-04-29 09:20:25 UTC",
    "updated_date": "2024-10-04 01:21:28 UTC"
  },
  {
    "arxiv_id": "2404.18532v2",
    "title": "MileBench: Benchmarking MLLMs in Long Context",
    "authors": [
      "Dingjie Song",
      "Shunian Chen",
      "Guiming Hardy Chen",
      "Fei Yu",
      "Xiang Wan",
      "Benyou Wang"
    ],
    "abstract": "Despite the advancements and impressive performance of Multimodal Large\nLanguage Models (MLLMs) on benchmarks, their effectiveness in real-world,\nlong-context, and multi-image tasks is unclear due to the benchmarks' limited\nscope. Existing benchmarks often focus on single-image and short-text samples,\nand when assessing multi-image tasks, they either limit the image count or\nfocus on specific task (e.g time-series captioning), potentially obscuring the\nperformance challenges of MLLMs. To address these limitations, we introduce\nMileBench, a pioneering benchmark designed to test the MultImodal Long-contExt\ncapabilities of MLLMs. This benchmark comprises not only multimodal long\ncontexts, but also multiple tasks requiring both comprehension and generation.\nWe establish two distinct evaluation sets, diagnostic and realistic, to\nsystematically assess MLLMs' long-context adaptation capacity and their ability\nto complete tasks in long-context scenarios. Our experimental results, obtained\nfrom testing 22 models, revealed that while the closed-source GPT-4o\noutperforms others, most open-source MLLMs struggle in long-context situations.\nInterestingly, the performance gap tends to widen with an increase in the\nnumber of images. We strongly encourage an intensification of research efforts\ntowards enhancing MLLMs' long-context capabilities, especially in scenarios\ninvolving multiple images.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 13 figures, 14 tables; We add results of GPT-4o in this\n  version",
    "pdf_url": "http://arxiv.org/pdf/2404.18532v2",
    "published_date": "2024-04-29 09:19:05 UTC",
    "updated_date": "2024-05-15 05:43:30 UTC"
  },
  {
    "arxiv_id": "2404.18531v2",
    "title": "A Framework to Model ML Engineering Processes",
    "authors": [
      "Sergio Morales",
      "Robert Clarisó",
      "Jordi Cabot"
    ],
    "abstract": "The development of Machine Learning (ML) based systems is complex and\nrequires multidisciplinary teams with diverse skill sets. This may lead to\ncommunication issues or misapplication of best practices. Process models can\nalleviate these challenges by standardizing task orchestration, providing a\ncommon language to facilitate communication, and nurturing a collaborative\nenvironment. Unfortunately, current process modeling languages are not suitable\nfor describing the development of such systems. In this paper, we introduce a\nframework for modeling ML-based software development processes, built around a\ndomain-specific language and derived from an analysis of scientific and gray\nliterature. A supporting toolkit is also available.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18531v2",
    "published_date": "2024-04-29 09:17:36 UTC",
    "updated_date": "2024-08-28 14:12:22 UTC"
  },
  {
    "arxiv_id": "2404.18527v1",
    "title": "Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning",
    "authors": [
      "Weike Peng",
      "Jiaxin Gao",
      "Yuntian Chen",
      "Shengwei Wang"
    ],
    "abstract": "Machine learning algorithms emerge as a promising approach in energy fields,\nbut its practical is hindered by data barriers, stemming from high collection\ncosts and privacy concerns. This study introduces a novel federated learning\n(FL) framework based on XGBoost models, enabling safe collaborative modeling\nwith accessible yet concealed data from multiple parties. Hyperparameter tuning\nof the models is achieved through Bayesian Optimization. To ascertain the\nmerits of the proposed FL-XGBoost method, a comparative analysis is conducted\nbetween separate and centralized models to address a classical binary\nclassification problem in geoenergy sector. The results reveal that the\nproposed FL framework strikes an optimal balance between privacy and accuracy.\nFL models demonstrate superior accuracy and generalization capabilities\ncompared to separate models, particularly for participants with limited data or\nlow correlation features and offers significant privacy benefits compared to\ncentralized model. The aggregated optimization approach within the FL agreement\nproves effective in tuning hyperparameters. This study opens new avenues for\nassessing unconventional reservoirs through collaborative and\nprivacy-preserving FL techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18527v1",
    "published_date": "2024-04-29 09:12:31 UTC",
    "updated_date": "2024-04-29 09:12:31 UTC"
  },
  {
    "arxiv_id": "2405.01589v2",
    "title": "GPT-4 passes most of the 297 written Polish Board Certification Examinations",
    "authors": [
      "Jakub Pokrywka",
      "Jeremi Kaczmarek",
      "Edward Gorzelańczyk"
    ],
    "abstract": "Introduction: Recently, the effectiveness of Large Language Models (LLMs) has\nincreased rapidly, allowing them to be used in a great number of applications.\nHowever, the risks posed by the generation of false information through LLMs\nsignificantly limit their applications in sensitive areas such as healthcare,\nhighlighting the necessity for rigorous validations to determine their utility\nand reliability. To date, no study has extensively compared the performance of\nLLMs on Polish medical examinations across a broad spectrum of specialties on a\nvery large dataset. Objectives: This study evaluated the performance of three\nGenerative Pretrained Transformer (GPT) models on the Polish Board\nCertification Exam (Pa\\'nstwowy Egzamin Specjalizacyjny, PES) dataset, which\nconsists of 297 tests. Methods: We developed a software program to download and\nprocess PES exams and tested the performance of GPT models using OpenAI\nApplication Programming Interface. Results: Our findings reveal that GPT-3.5\ndid not pass any of the analyzed exams. In contrast, the GPT-4 models\ndemonstrated the capability to pass the majority of the exams evaluated, with\nthe most recent model, gpt-4-0125, successfully passing 222 (75%) of them. The\nperformance of the GPT models varied significantly, displaying excellence in\nexams related to certain specialties while completely failing others.\nConclusions: The significant progress and impressive performance of LLM models\nhold great promise for the increased application of AI in the field of medicine\nin Poland. For instance, this advancement could lead to the development of\nAI-based medical assistants for healthcare professionals, enhancing the\nefficiency and accuracy of medical services.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.01589v2",
    "published_date": "2024-04-29 09:08:22 UTC",
    "updated_date": "2024-05-09 10:21:57 UTC"
  },
  {
    "arxiv_id": "2404.18519v3",
    "title": "On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks",
    "authors": [
      "Usevalad Milasheuski",
      "Luca Barbieri",
      "Bernardo Camajori Tedeschini",
      "Monica Nicoli",
      "Stefano Savazzi"
    ],
    "abstract": "Federated Learning (FL) allows multiple privacy-sensitive applications to\nleverage their dataset for a global model construction without any disclosure\nof the information. One of those domains is healthcare, where groups of silos\ncollaborate in order to generate a global predictor with improved accuracy and\ngeneralization. However, the inherent challenge lies in the high heterogeneity\nof medical data, necessitating sophisticated techniques for assessment and\ncompensation. This paper presents a comprehensive exploration of the\nmathematical formalization and taxonomy of heterogeneity within FL\nenvironments, focusing on the intricacies of medical data. In particular, we\naddress the evaluation and comparison of the most popular FL algorithms with\nrespect to their ability to cope with quantity-based, feature and label\ndistribution-based heterogeneity. The goal is to provide a quantitative\nevaluation of the impact of data heterogeneity in FL systems for healthcare\nnetworks as well as a guideline on FL algorithm selection. Our research extends\nbeyond existing studies by benchmarking seven of the most common FL algorithms\nagainst the unique challenges posed by medical data use cases. The paper\ntargets the prediction of the risk of stroke recurrence through a set of\ntabular clinical reports collected by different federated hospital silos: data\nheterogeneity frequently encountered in this scenario and its impact on FL\nperformance are discussed.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18519v3",
    "published_date": "2024-04-29 09:05:01 UTC",
    "updated_date": "2024-09-05 12:24:52 UTC"
  },
  {
    "arxiv_id": "2404.18518v1",
    "title": "From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?",
    "authors": [
      "Jiangfeng Liu",
      "Ziyi Wang",
      "Jing Xie",
      "Lei Pei"
    ],
    "abstract": "Generative large-scale language models create the fifth paradigm of\nscientific research, organically combine data science and computational\nintelligence, transform the research paradigm of natural language processing\nand multimodal information processing, promote the new trend of AI-enabled\nsocial science research, and provide new ideas for digital humanities research\nand application. This article profoundly explores the application of\nlarge-scale language models in digital humanities research, revealing their\nsignificant potential in ancient book protection, intelligent processing, and\nacademic innovation. The article first outlines the importance of ancient book\nresources and the necessity of digital preservation, followed by a detailed\nintroduction to developing large-scale language models, such as ChatGPT, and\ntheir applications in document management, content understanding, and\ncross-cultural research. Through specific cases, the article demonstrates how\nAI can assist in the organization, classification, and content generation of\nancient books. Then, it explores the prospects of AI applications in artistic\ninnovation and cultural heritage preservation. Finally, the article explores\nthe challenges and opportunities in the interaction of technology, information,\nand society in the digital humanities triggered by AI technologies.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.DL",
    "comment": "21 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.18518v1",
    "published_date": "2024-04-29 09:03:19 UTC",
    "updated_date": "2024-04-29 09:03:19 UTC"
  },
  {
    "arxiv_id": "2404.18508v3",
    "title": "Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models",
    "authors": [
      "Mark Schöne",
      "Neeraj Mohan Sushma",
      "Jingyue Zhuge",
      "Christian Mayr",
      "Anand Subramoney",
      "David Kappel"
    ],
    "abstract": "Event-based sensors are well suited for real-time processing due to their\nfast response times and encoding of the sensory data as successive temporal\ndifferences. These and other valuable properties, such as a high dynamic range,\nare suppressed when the data is converted to a frame-based format. However,\nmost current methods either collapse events into frames or cannot scale up when\nprocessing the event data directly event-by-event. In this work, we address the\nkey challenges of scaling up event-by-event modeling of the long event streams\nemitted by such sensors, which is a particularly relevant problem for\nneuromorphic computing. While prior methods can process up to a few thousand\ntime steps, our model, based on modern recurrent deep state-space models,\nscales to event streams of millions of events for both training and inference.\nWe leverage their stable parameterization for learning long-range dependencies,\nparallelizability along the sequence dimension, and their ability to integrate\nasynchronous events effectively to scale them up to long event streams. We\nfurther augment these with novel event-centric techniques enabling our model to\nmatch or beat the state-of-the-art performance on several event stream\nbenchmarks. In the Spiking Speech Commands task, we improve state-of-the-art by\na large margin of 7.7% to 88.4%. On the DVS128-Gestures dataset, we achieve\ncompetitive results without using frames or convolutional neural networks. Our\nwork demonstrates, for the first time, that it is possible to use fully\nevent-based processing with purely recurrent networks to achieve\nstate-of-the-art task performance in several event-based benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18508v3",
    "published_date": "2024-04-29 08:50:27 UTC",
    "updated_date": "2024-10-09 06:57:39 UTC"
  },
  {
    "arxiv_id": "2404.18470v2",
    "title": "ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction",
    "authors": [
      "Yupeng Cao",
      "Zhi Chen",
      "Qingyun Pei",
      "Nathan Jinseok Lee",
      "K. P. Subbalakshmi",
      "Papa Momar Ndiaye"
    ],
    "abstract": "In the realm of financial analytics, leveraging unstructured data, such as\nearnings conference calls (ECCs), to forecast stock volatility is a critical\nchallenge that has attracted both academics and investors. While previous\nstudies have used multimodal deep learning-based models to obtain a general\nview of ECCs for volatility predicting, they often fail to capture detailed,\ncomplex information. Our research introduces a novel framework: \\textbf{ECC\nAnalyzer}, which utilizes large language models (LLMs) to extract richer, more\npredictive content from ECCs to aid the model's prediction performance. We use\nthe pre-trained large models to extract textual and audio features from ECCs\nand implement a hierarchical information extraction strategy to extract more\nfine-grained information. This strategy first extracts paragraph-level general\ninformation by summarizing the text and then extracts fine-grained focus\nsentences using Retrieval-Augmented Generation (RAG). These features are then\nfused through multimodal feature fusion to perform volatility prediction.\nExperimental results demonstrate that our model outperforms traditional\nanalytical benchmarks, confirming the effectiveness of advanced LLM techniques\nin financial analysis.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "q-fin.RM",
      "q-fin.TR"
    ],
    "primary_category": "cs.CE",
    "comment": "9 pages, 1 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.18470v2",
    "published_date": "2024-04-29 07:11:39 UTC",
    "updated_date": "2024-08-29 23:13:56 UTC"
  },
  {
    "arxiv_id": "2404.18465v3",
    "title": "M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework",
    "authors": [
      "Zijian Zhang",
      "Shuchang Liu",
      "Jiaao Yu",
      "Qingpeng Cai",
      "Xiangyu Zhao",
      "Chunxu Zhang",
      "Ziru Liu",
      "Qidong Liu",
      "Hongwei Zhao",
      "Lantao Hu",
      "Peng Jiang",
      "Kun Gai"
    ],
    "abstract": "Multi-domain recommendation and multi-task recommendation have demonstrated\ntheir effectiveness in leveraging common information from different domains and\nobjectives for comprehensive user modeling. Nonetheless, the practical\nrecommendation usually faces multiple domains and tasks simultaneously, which\ncannot be well-addressed by current methods. To this end, we introduce M3oE, an\nadaptive Multi-domain Multi-task Mixture-of-Experts recommendation framework.\nM3oE integrates multi-domain information, maps knowledge across domains and\ntasks, and optimizes multiple objectives. We leverage three mixture-of-experts\nmodules to learn common, domain-aspect, and task-aspect user preferences\nrespectively to address the complex dependencies among multiple domains and\ntasks in a disentangled manner. Additionally, we design a two-level fusion\nmechanism for precise control over feature extraction and fusion across diverse\ndomains and tasks. The framework's adaptability is further enhanced by applying\nAutoML technique, which allows dynamic structure optimization. To the best of\nthe authors' knowledge, our M3oE is the first effort to solve multi-domain\nmulti-task recommendation self-adaptively. Extensive experiments on two\nbenchmark datasets against diverse baselines demonstrate M3oE's superior\nperformance. The implementation code is available to ensure reproducibility.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18465v3",
    "published_date": "2024-04-29 06:59:30 UTC",
    "updated_date": "2024-05-12 13:11:29 UTC"
  },
  {
    "arxiv_id": "2404.18460v1",
    "title": "Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in",
    "authors": [
      "Utkarsh Agarwal",
      "Kumar Tanmay",
      "Aditi Khandelwal",
      "Monojit Choudhury"
    ],
    "abstract": "Ethical reasoning is a crucial skill for Large Language Models (LLMs).\nHowever, moral values are not universal, but rather influenced by language and\nculture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and\nLlama2-70B-Chat -- perform ethical reasoning in different languages and if\ntheir moral judgement depend on the language in which they are prompted. We\nextend the study of ethical reasoning of LLMs by Rao et al. (2023) to a\nmultilingual setup following their framework of probing LLMs with ethical\ndilemmas and policies from three branches of normative ethics: deontology,\nvirtue, and consequentialism. We experiment with six languages: English,\nSpanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most\nconsistent and unbiased ethical reasoner across languages, while ChatGPT and\nLlama2-70B-Chat show significant moral value bias when we move to languages\nother than English. Interestingly, the nature of this bias significantly vary\nacross languages for all LLMs, including GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18460v1",
    "published_date": "2024-04-29 06:42:27 UTC",
    "updated_date": "2024-04-29 06:42:27 UTC"
  },
  {
    "arxiv_id": "2404.18445v1",
    "title": "Strategic Behavior and AI Training Data",
    "authors": [
      "Christian Peukert",
      "Florian Abeillon",
      "Jérémie Haese",
      "Franziska Kaiser",
      "Alexander Staub"
    ],
    "abstract": "Human-created works represent critical data inputs to artificial intelligence\n(AI). Strategic behavior can play a major role for AI training datasets, be it\nin limiting access to existing works or in deciding which types of new works to\ncreate or whether to create new works at all. We examine creators' behavioral\nchange when their works become training data for AI. Specifically, we focus on\ncontributors on Unsplash, a popular stock image platform with about 6 million\nhigh-quality photos and illustrations. In the summer of 2020, Unsplash launched\nan AI research program by releasing a dataset of 25,000 images for commercial\nuse. We study contributors' reactions, comparing contributors whose works were\nincluded in this dataset to contributors whose works were not included. Our\nresults suggest that treated contributors left the platform at a\nhigher-than-usual rate and substantially slowed down the rate of new uploads.\nProfessional and more successful photographers react stronger than amateurs and\nless successful photographers. We also show that affected users changed the\nvariety and novelty of contributions to the platform, with long-run\nimplications for the stock of works potentially available for AI training.\nTaken together, our findings highlight the trade-off between interests of\nrightsholders and promoting innovation at the technological frontier. We\ndiscuss implications for copyright and AI policy.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18445v1",
    "published_date": "2024-04-29 06:00:59 UTC",
    "updated_date": "2024-04-29 06:00:59 UTC"
  },
  {
    "arxiv_id": "2404.18444v2",
    "title": "U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models",
    "authors": [
      "Song Mei"
    ],
    "abstract": "U-Nets are among the most widely used architectures in computer vision,\nrenowned for their exceptional performance in applications such as image\nsegmentation, denoising, and diffusion modeling. However, a theoretical\nexplanation of the U-Net architecture design has not yet been fully\nestablished.\n  This paper introduces a novel interpretation of the U-Net architecture by\nstudying certain generative hierarchical models, which are tree-structured\ngraphical models extensively utilized in both language and image domains. With\ntheir encoder-decoder structure, long skip connections, and pooling and\nup-sampling layers, we demonstrate how U-Nets can naturally implement the\nbelief propagation denoising algorithm in such generative hierarchical models,\nthereby efficiently approximating the denoising functions. This leads to an\nefficient sample complexity bound for learning the denoising function using\nU-Nets within these models. Additionally, we discuss the broader implications\nof these findings for diffusion models in generative hierarchical models. We\nalso demonstrate that the conventional architecture of convolutional neural\nnetworks (ConvNets) is ideally suited for classification tasks within these\nmodels. This offers a unified view of the roles of ConvNets and U-Nets,\nhighlighting the versatility of generative hierarchical models in modeling\ncomplex data distributions across language and image domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "v2 updated discussions of related literature",
    "pdf_url": "http://arxiv.org/pdf/2404.18444v2",
    "published_date": "2024-04-29 05:57:03 UTC",
    "updated_date": "2024-05-01 16:49:57 UTC"
  },
  {
    "arxiv_id": "2405.06663v1",
    "title": "Protein Representation Learning by Capturing Protein Sequence-Structure-Function Relationship",
    "authors": [
      "Eunji Ko",
      "Seul Lee",
      "Minseon Kim",
      "Dongki Kim"
    ],
    "abstract": "The goal of protein representation learning is to extract knowledge from\nprotein databases that can be applied to various protein-related downstream\ntasks. Although protein sequence, structure, and function are the three key\nmodalities for a comprehensive understanding of proteins, existing methods for\nprotein representation learning have utilized only one or two of these\nmodalities due to the difficulty of capturing the asymmetric interrelationships\nbetween them. To account for this asymmetry, we introduce our novel asymmetric\nmulti-modal masked autoencoder (AMMA). AMMA adopts (1) a unified multi-modal\nencoder to integrate all three modalities into a unified representation space\nand (2) asymmetric decoders to ensure that sequence latent features reflect\nstructural and functional information. The experiments demonstrate that the\nproposed AMMA is highly effective in learning protein representations that\nexhibit well-aligned inter-modal relationships, which in turn makes it\neffective for various downstream protein-related tasks.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "ICLR 2024 MLGenX Workshop (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.06663v1",
    "published_date": "2024-04-29 05:42:29 UTC",
    "updated_date": "2024-04-29 05:42:29 UTC"
  },
  {
    "arxiv_id": "2404.18443v2",
    "title": "BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers",
    "authors": [
      "Ran Xu",
      "Wenqi Shi",
      "Yue Yu",
      "Yuchen Zhuang",
      "Yanqiao Zhu",
      "May D. Wang",
      "Joyce C. Ho",
      "Chao Zhang",
      "Carl Yang"
    ],
    "abstract": "Developing effective biomedical retrieval models is important for excelling\nat knowledge-intensive biomedical tasks but still challenging due to the\ndeficiency of sufficient publicly annotated biomedical data and computational\nresources. We present BMRetriever, a series of dense retrievers for enhancing\nbiomedical retrieval via unsupervised pre-training on large biomedical corpora,\nfollowed by instruction fine-tuning on a combination of labeled datasets and\nsynthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify\nBMRetriever's efficacy on various biomedical applications. BMRetriever also\nexhibits strong parameter efficiency, with the 410M variant outperforming\nbaselines up to 11.7 times larger, and the 2B variant matching the performance\nof models with over 5B parameters. The training data and model checkpoints are\nreleased at \\url{https://huggingface.co/BMRetriever} to ensure transparency,\nreproducibility, and application to new domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024. The model and data are uploaded to\n  \\url{https://github.com/ritaranx/BMRetriever}",
    "pdf_url": "http://arxiv.org/pdf/2404.18443v2",
    "published_date": "2024-04-29 05:40:08 UTC",
    "updated_date": "2024-10-04 03:25:34 UTC"
  },
  {
    "arxiv_id": "2404.18961v1",
    "title": "Unleashing the Power of Multi-Task Learning: A Comprehensive Survey Spanning Traditional, Deep, and Pretrained Foundation Model Eras",
    "authors": [
      "Jun Yu",
      "Yutong Dai",
      "Xiaokang Liu",
      "Jin Huang",
      "Yishan Shen",
      "Ke Zhang",
      "Rong Zhou",
      "Eashan Adhikarla",
      "Wenxuan Ye",
      "Yixin Liu",
      "Zhaoming Kong",
      "Kai Zhang",
      "Yilong Yin",
      "Vinod Namboodiri",
      "Brian D. Davison",
      "Jason H. Moore",
      "Yong Chen"
    ],
    "abstract": "MTL is a learning paradigm that effectively leverages both task-specific and\nshared information to address multiple related tasks simultaneously. In\ncontrast to STL, MTL offers a suite of benefits that enhance both the training\nprocess and the inference efficiency. MTL's key advantages encompass\nstreamlined model architecture, performance enhancement, and cross-domain\ngeneralizability. Over the past twenty years, MTL has become widely recognized\nas a flexible and effective approach in various fields, including CV, NLP,\nrecommendation systems, disease prognosis and diagnosis, and robotics. This\nsurvey provides a comprehensive overview of the evolution of MTL, encompassing\nthe technical aspects of cutting-edge methods from traditional approaches to\ndeep learning and the latest trend of pretrained foundation models. Our survey\nmethodically categorizes MTL techniques into five key areas: regularization,\nrelationship learning, feature propagation, optimization, and pre-training.\nThis categorization not only chronologically outlines the development of MTL\nbut also dives into various specialized strategies within each category.\nFurthermore, the survey reveals how the MTL evolves from handling a fixed set\nof tasks to embracing a more flexible approach free from task or modality\nconstraints. It explores the concepts of task-promptable and -agnostic\ntraining, along with the capacity for ZSL, which unleashes the untapped\npotential of this historically coveted learning paradigm. Overall, we hope this\nsurvey provides the research community with a comprehensive overview of the\nadvancements in MTL from its inception in 1997 to the present in 2023. We\naddress present challenges and look ahead to future possibilities, shedding\nlight on the opportunities and potential avenues for MTL research in a broad\nmanner. This project is publicly available at\nhttps://github.com/junfish/Awesome-Multitask-Learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "60 figures, 116 pages, 500+ references",
    "pdf_url": "http://arxiv.org/pdf/2404.18961v1",
    "published_date": "2024-04-29 05:23:10 UTC",
    "updated_date": "2024-04-29 05:23:10 UTC"
  },
  {
    "arxiv_id": "2405.02336v1",
    "title": "Artificial General Intelligence (AGI)-Native Wireless Systems: A Journey Beyond 6G",
    "authors": [
      "Walid Saad",
      "Omar Hashash",
      "Christo Kurisummoottil Thomas",
      "Christina Chaccour",
      "Merouane Debbah",
      "Narayan Mandayam",
      "Zhu Han"
    ],
    "abstract": "Building future wireless systems that support services like digital twins\n(DTs) is challenging to achieve through advances to conventional technologies\nlike meta-surfaces. While artificial intelligence (AI)-native networks promise\nto overcome some limitations of wireless technologies, developments still rely\non AI tools like neural networks. Such tools struggle to cope with the\nnon-trivial challenges of the network environment and the growing demands of\nemerging use cases. In this paper, we revisit the concept of AI-native wireless\nsystems, equipping them with the common sense necessary to transform them into\nartificial general intelligence (AGI)-native systems. These systems acquire\ncommon sense by exploiting different cognitive abilities such as perception,\nanalogy, and reasoning, that enable them to generalize and deal with unforeseen\nscenarios. Towards developing the components of such a system, we start by\nshowing how the perception module can be built through abstracting real-world\nelements into generalizable representations. These representations are then\nused to create a world model, founded on principles of causality and\nhyper-dimensional (HD) computing, that aligns with intuitive physics and\nenables analogical reasoning, that define common sense. Then, we explain how\nmethods such as integrated information theory play a role in the proposed\nintent-driven and objective-driven planning methods that maneuver the\nAGI-native network to take actions. Next, we discuss how an AGI-native network\ncan enable use cases related to human and autonomous agents: a) analogical\nreasoning for next-generation DTs, b) synchronized and resilient experiences\nfor cognitive avatars, and c) brain-level metaverse experiences like\nholographic teleportation. Finally, we conclude with a set of recommendations\nto build AGI-native systems. Ultimately, we envision this paper as a roadmap\nfor the beyond 6G era.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.02336v1",
    "published_date": "2024-04-29 04:51:05 UTC",
    "updated_date": "2024-04-29 04:51:05 UTC"
  },
  {
    "arxiv_id": "2404.18423v2",
    "title": "Unsupervised Dynamics Prediction with Object-Centric Kinematics",
    "authors": [
      "Yeon-Ji Song",
      "Suhyung Choi",
      "Jaein Kim",
      "Jin-Hwa Kim",
      "Byoung-Tak Zhang"
    ],
    "abstract": "Human perception involves discerning complex multi-object scenes into\ntime-static object appearance (ie, size, shape, color) and time-varying object\nmotion (ie, location, velocity, acceleration). This innate ability to\nunconsciously understand the environment is the motivation behind the success\nof dynamics modeling. Object-centric representations have emerged as a\npromising tool for dynamics prediction, yet they primarily focus on the\nobjects' appearance, often overlooking other crucial attributes. In this paper,\nwe propose Object-Centric Kinematics (OCK), a framework for dynamics prediction\nleveraging object-centric representations. Our model utilizes a novel component\nnamed object kinematics, which comprises low-level structured states of\nobjects' position, velocity, and acceleration. The object kinematics are\nobtained via either implicit or explicit approaches, enabling comprehensive\nspatiotemporal object reasoning, and integrated through various transformer\nmechanisms, facilitating effective object-centric dynamics modeling. Our model\ndemonstrates superior performance when handling objects and backgrounds in\ncomplex scenes characterized by a wide range of object attributes and dynamic\nmovements. Moreover, our model demonstrates generalization capabilities across\ndiverse synthetic environments, highlighting its potential for broad\napplicability in vision-related tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.18423v2",
    "published_date": "2024-04-29 04:47:23 UTC",
    "updated_date": "2024-05-06 06:10:29 UTC"
  },
  {
    "arxiv_id": "2404.18419v1",
    "title": "Research on Intelligent Aided Diagnosis System of Medical Image Based on Computer Deep Learning",
    "authors": [
      "Jiajie Yuan",
      "Linxiao Wu",
      "Yulu Gong",
      "Zhou Yu",
      "Ziang Liu",
      "Shuyao He"
    ],
    "abstract": "This paper combines Struts and Hibernate two architectures together, using\nDAO (Data Access Object) to store and access data. Then a set of dual-mode\nhumidity medical image library suitable for deep network is established, and a\ndual-mode medical image assisted diagnosis method based on the image is\nproposed. Through the test of various feature extraction methods, the optimal\noperating characteristic under curve product (AUROC) is 0.9985, the recall rate\nis 0.9814, and the accuracy is 0.9833. This method can be applied to clinical\ndiagnosis, and it is a practical method. Any outpatient doctor can register\nquickly through the system, or log in to the platform to upload the image to\nobtain more accurate images. Through the system, each outpatient physician can\nquickly register or log in to the platform for image uploading, thus obtaining\nmore accurate images. The segmentation of images can guide doctors in clinical\ndepartments. Then the image is analyzed to determine the location and nature of\nthe tumor, so as to make targeted treatment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18419v1",
    "published_date": "2024-04-29 04:32:11 UTC",
    "updated_date": "2024-04-29 04:32:11 UTC"
  },
  {
    "arxiv_id": "2404.18416v2",
    "title": "Capabilities of Gemini Models in Medicine",
    "authors": [
      "Khaled Saab",
      "Tao Tu",
      "Wei-Hung Weng",
      "Ryutaro Tanno",
      "David Stutz",
      "Ellery Wulczyn",
      "Fan Zhang",
      "Tim Strother",
      "Chunjong Park",
      "Elahe Vedadi",
      "Juanma Zambrano Chaves",
      "Szu-Yeu Hu",
      "Mike Schaekermann",
      "Aishwarya Kamath",
      "Yong Cheng",
      "David G. T. Barrett",
      "Cathy Cheung",
      "Basil Mustafa",
      "Anil Palepu",
      "Daniel McDuff",
      "Le Hou",
      "Tomer Golany",
      "Luyang Liu",
      "Jean-baptiste Alayrac",
      "Neil Houlsby",
      "Nenad Tomasev",
      "Jan Freyberg",
      "Charles Lau",
      "Jonas Kemp",
      "Jeremy Lai",
      "Shekoofeh Azizi",
      "Kimberly Kanada",
      "SiWai Man",
      "Kavita Kulkarni",
      "Ruoxi Sun",
      "Siamak Shakeri",
      "Luheng He",
      "Ben Caine",
      "Albert Webson",
      "Natasha Latysheva",
      "Melvin Johnson",
      "Philip Mansfield",
      "Jian Lu",
      "Ehud Rivlin",
      "Jesper Anderson",
      "Bradley Green",
      "Renee Wong",
      "Jonathan Krause",
      "Jonathon Shlens",
      "Ewa Dominowska",
      "S. M. Ali Eslami",
      "Katherine Chou",
      "Claire Cui",
      "Oriol Vinyals",
      "Koray Kavukcuoglu",
      "James Manyika",
      "Jeff Dean",
      "Demis Hassabis",
      "Yossi Matias",
      "Dale Webster",
      "Joelle Barral",
      "Greg Corrado",
      "Christopher Semturs",
      "S. Sara Mahdavi",
      "Juraj Gottweis",
      "Alan Karthikesalingam",
      "Vivek Natarajan"
    ],
    "abstract": "Excellence in a wide variety of medical applications poses considerable\nchallenges for AI, requiring advanced reasoning, access to up-to-date medical\nknowledge and understanding of complex multimodal data. Gemini models, with\nstrong general capabilities in multimodal and long-context reasoning, offer\nexciting possibilities in medicine. Building on these core strengths of Gemini,\nwe introduce Med-Gemini, a family of highly capable multimodal models that are\nspecialized in medicine with the ability to seamlessly use web search, and that\ncan be efficiently tailored to novel modalities using custom encoders. We\nevaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art\n(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every\nbenchmark where a direct comparison is viable, often by a wide margin. On the\npopular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves\nSoTA performance of 91.1% accuracy, using a novel uncertainty-guided search\nstrategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU\n(health & medicine), Med-Gemini improves over GPT-4V by an average relative\nmargin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context\ncapabilities through SoTA performance on a needle-in-a-haystack retrieval task\nfrom long de-identified health records and medical video question answering,\nsurpassing prior bespoke methods using only in-context learning. Finally,\nMed-Gemini's performance suggests real-world utility by surpassing human\nexperts on tasks such as medical text summarization, alongside demonstrations\nof promising potential for multimodal medical dialogue, medical research and\neducation. Taken together, our results offer compelling evidence for\nMed-Gemini's potential, although further rigorous evaluation will be crucial\nbefore real-world deployment in this safety-critical domain.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18416v2",
    "published_date": "2024-04-29 04:11:28 UTC",
    "updated_date": "2024-05-01 17:12:10 UTC"
  },
  {
    "arxiv_id": "2405.00732v1",
    "title": "LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report",
    "authors": [
      "Justin Zhao",
      "Timothy Wang",
      "Wael Abid",
      "Geoffrey Angus",
      "Arnav Garg",
      "Jeffery Kinnison",
      "Alex Sherstinsky",
      "Piero Molino",
      "Travis Addair",
      "Devvret Rishi"
    ],
    "abstract": "Low Rank Adaptation (LoRA) has emerged as one of the most widely adopted\nmethods for Parameter Efficient Fine-Tuning (PEFT) of Large Language Models\n(LLMs). LoRA reduces the number of trainable parameters and memory usage while\nachieving comparable performance to full fine-tuning. We aim to assess the\nviability of training and serving LLMs fine-tuned with LoRA in real-world\napplications. First, we measure the quality of LLMs fine-tuned with quantized\nlow rank adapters across 10 base models and 31 tasks for a total of 310 models.\nWe find that 4-bit LoRA fine-tuned models outperform base models by 34 points\nand GPT-4 by 10 points on average. Second, we investigate the most effective\nbase models for fine-tuning and assess the correlative and predictive\ncapacities of task complexity heuristics in forecasting the outcomes of\nfine-tuning. Finally, we evaluate the latency and concurrency capabilities of\nLoRAX, an open-source Multi-LoRA inference server that facilitates the\ndeployment of multiple LoRA fine-tuned models on a single GPU using shared base\nmodel weights and dynamic adapter loading. LoRAX powers LoRA Land, a web\napplication that hosts 25 LoRA fine-tuned Mistral-7B LLMs on a single NVIDIA\nA100 GPU with 80GB memory. LoRA Land highlights the quality and\ncost-effectiveness of employing multiple specialized LLMs over a single,\ngeneral-purpose LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00732v1",
    "published_date": "2024-04-29 04:01:45 UTC",
    "updated_date": "2024-04-29 04:01:45 UTC"
  },
  {
    "arxiv_id": "2404.18413v1",
    "title": "3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset",
    "authors": [
      "Xinyu Ma",
      "Xuebo Liu",
      "Derek F. Wong",
      "Jun Rao",
      "Bei Li",
      "Liang Ding",
      "Lidia S. Chao",
      "Dacheng Tao",
      "Min Zhang"
    ],
    "abstract": "Multimodal machine translation (MMT) is a challenging task that seeks to\nimprove translation quality by incorporating visual information. However,\nrecent studies have indicated that the visual information provided by existing\nMMT datasets is insufficient, causing models to disregard it and overestimate\ntheir capabilities. This issue presents a significant obstacle to the\ndevelopment of MMT research. This paper presents a novel solution to this issue\nby introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel\nsentence pairs in English and Chinese, each with corresponding images. Our\ndataset is specifically designed to include more ambiguity and a greater\nvariety of both captions and images than other MMT datasets. We utilize a word\nsense disambiguation model to select ambiguous data from vision-and-language\ndatasets, resulting in a more challenging dataset. We further benchmark several\nstate-of-the-art MMT models on our proposed dataset. Experimental results show\nthat MMT models trained on our dataset exhibit a greater ability to exploit\nvisual information than those trained on other MMT datasets. Our work provides\na valuable resource for researchers in the field of multimodal learning and\nencourages further exploration in this area. The data, code and scripts are\nfreely available at https://github.com/MaxyLee/3AM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18413v1",
    "published_date": "2024-04-29 04:01:30 UTC",
    "updated_date": "2024-04-29 04:01:30 UTC"
  },
  {
    "arxiv_id": "2404.18400v3",
    "title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
    "authors": [
      "Parshin Shojaee",
      "Kazem Meidani",
      "Shashank Gupta",
      "Amir Barati Farimani",
      "Chandan K Reddy"
    ],
    "abstract": "Mathematical equations have been unreasonably effective in describing complex\nnatural phenomena across various scientific disciplines. However, discovering\nsuch insightful equations from data presents significant challenges due to the\nnecessity of navigating extremely large combinatorial hypothesis spaces.\nCurrent methods of equation discovery, commonly known as symbolic regression\ntechniques, largely focus on extracting equations from data alone, often\nneglecting the domain-specific prior knowledge that scientists typically depend\non. They also employ limited representations such as expression trees,\nconstraining the search space and expressiveness of equations. To bridge this\ngap, we introduce LLM-SR, a novel approach that leverages the extensive\nscientific knowledge and robust code generation capabilities of Large Language\nModels (LLMs) to discover scientific equations from data. Specifically, LLM-SR\ntreats equations as programs with mathematical operators and combines LLMs'\nscientific priors with evolutionary search over equation programs. The LLM\niteratively proposes new equation skeleton hypotheses, drawing from its domain\nknowledge, which are then optimized against data to estimate parameters. We\nevaluate LLM-SR on four benchmark problems across diverse scientific domains\n(e.g., physics, biology), which we carefully designed to simulate the discovery\nprocess and prevent LLM recitation. Our results demonstrate that LLM-SR\ndiscovers physically accurate equations that significantly outperform\nstate-of-the-art symbolic regression baselines, particularly in out-of-domain\ntest settings. We also show that LLM-SR's incorporation of scientific priors\nenables more efficient equation space exploration than the baselines. Code and\ndata are available: https://github.com/deep-symbolic-mathematics/LLM-SR",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2404.18400v3",
    "published_date": "2024-04-29 03:30:06 UTC",
    "updated_date": "2025-03-20 16:37:17 UTC"
  },
  {
    "arxiv_id": "2404.18385v2",
    "title": "Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice",
    "authors": [
      "Yixuan Li",
      "Dan C. Baciu",
      "Marcos Novak",
      "George Legrady"
    ],
    "abstract": "Over the past year, the emergence of advanced text-to-image Generative AI\nmodels has significantly impacted the art world, challenging traditional\nnotions of creativity and the role of artists. This study explores how artists\ninteract with these technologies, using a 5P model (Purpose, People, Process,\nProduct, and Press) based on Rhodes' creativity framework to compare the\nartistic processes behind Conceptual Art and Image Generative AI. To exemplify\nthis framework, a practical case study titled \"Equivalence\", a multi-screen\ninteractive installation that converts users' speech input into continuously\nevolving paintings developed based on Stable Diffusion and NLP algorithms, was\ndeveloped. Through comprehensive analysis and the case study, this work aims to\nbroaden our understanding of artists' roles and foster a deeper appreciation\nfor the creative aspects inherent in artwork created with Image Generative AI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.7; J.0; J.5"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18385v2",
    "published_date": "2024-04-29 02:45:23 UTC",
    "updated_date": "2024-04-30 02:06:54 UTC"
  },
  {
    "arxiv_id": "2405.01588v1",
    "title": "Towards Unbiased Evaluation of Detecting Unanswerable Questions in EHRSQL",
    "authors": [
      "Yongjin Yang",
      "Sihyeon Kim",
      "SangMook Kim",
      "Gyubok Lee",
      "Se-Young Yun",
      "Edward Choi"
    ],
    "abstract": "Incorporating unanswerable questions into EHR QA systems is crucial for\ntesting the trustworthiness of a system, as providing non-existent responses\ncan mislead doctors in their diagnoses. The EHRSQL dataset stands out as a\npromising benchmark because it is the only dataset that incorporates\nunanswerable questions in the EHR QA system alongside practical questions.\nHowever, in this work, we identify a data bias in these unanswerable questions;\nthey can often be discerned simply by filtering with specific N-gram patterns.\nSuch biases jeopardize the authenticity and reliability of QA system\nevaluations. To tackle this problem, we propose a simple debiasing method of\nadjusting the split between the validation and test sets to neutralize the\nundue influence of N-gram filtering. By experimenting on the MIMIC-III dataset,\nwe demonstrate both the existing data bias in EHRSQL and the effectiveness of\nour data split strategy in mitigating this bias.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "DPFM Workshop, ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.01588v1",
    "published_date": "2024-04-29 02:26:15 UTC",
    "updated_date": "2024-04-29 02:26:15 UTC"
  },
  {
    "arxiv_id": "2404.18359v1",
    "title": "FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models",
    "authors": [
      "Wei Li",
      "Ren Ma",
      "Jiang Wu",
      "Chenya Gu",
      "Jiahui Peng",
      "Jinyang Len",
      "Songyang Zhang",
      "Hang Yan",
      "Dahua Lin",
      "Conghui He"
    ],
    "abstract": "In the burgeoning field of large language models (LLMs), the assessment of\nfundamental knowledge remains a critical challenge, particularly for models\ntailored to Chinese language and culture. This paper introduces FoundaBench, a\npioneering benchmark designed to rigorously evaluate the fundamental knowledge\ncapabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354\nmultiple-choice questions across common sense and K-12 educational subjects,\nmeticulously curated to reflect the breadth and depth of everyday and academic\nknowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using\nFoundaBench, employing both traditional assessment methods and our CircularEval\nprotocol to mitigate potential biases in model responses. Our results highlight\nthe superior performance of models pre-trained on Chinese corpora, and reveal a\nsignificant disparity between models' reasoning and memory recall capabilities.\nThe insights gleaned from FoundaBench evaluations set a new standard for\nunderstanding the fundamental knowledge of LLMs, providing a robust framework\nfor future advancements in the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.18359v1",
    "published_date": "2024-04-29 01:49:07 UTC",
    "updated_date": "2024-04-29 01:49:07 UTC"
  },
  {
    "arxiv_id": "2404.18353v2",
    "title": "How secure is AI-generated Code: A Large-Scale Comparison of Large Language Models",
    "authors": [
      "Norbert Tihanyi",
      "Tamas Bisztray",
      "Mohamed Amine Ferrag",
      "Ridhi Jain",
      "Lucas C. Cordeiro"
    ],
    "abstract": "This study compares state-of-the-art Large Language Models (LLMs) on their\ntendency to generate vulnerabilities when writing C programs using a neutral\nzero-shot prompt. Tihanyi et al. introduced the FormAI dataset at PROMISE'23,\nfeaturing 112,000 C programs generated by GPT-3.5-turbo, with over 51.24%\nidentified as vulnerable. We extended that research with a large-scale study\ninvolving 9 state-of-the-art models such as OpenAI's GPT-4o-mini, Google's\nGemini Pro 1.0, TII's 180 billion-parameter Falcon, Meta's 13 billion-parameter\nCode Llama, and several other compact models. Additionally, we introduce the\nFormAI-v2 dataset, which comprises 331 000 compilable C programs generated by\nthese LLMs. Each program in the dataset is labeled based on the vulnerabilities\ndetected in its source code through formal verification, using the Efficient\nSMT-based Context-Bounded Model Checker (ESBMC). This technique minimizes false\npositives by providing a counterexample for the specific vulnerability and\nreduces false negatives by thoroughly completing the verification process. Our\nstudy reveals that at least 62.07% of the generated programs are vulnerable.\nThe differences between the models are minor, as they all show similar coding\nerrors with slight variations. Our research highlights that while LLMs offer\npromising capabilities for code generation, deploying their output in a\nproduction environment requires proper risk assessment and validation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted and will be shortly published at Empirical Software\n  Engineering (EMSE). Journal Impact Factor: 3.5 (2023)",
    "pdf_url": "http://arxiv.org/pdf/2404.18353v2",
    "published_date": "2024-04-29 01:24:14 UTC",
    "updated_date": "2024-12-11 13:02:30 UTC"
  },
  {
    "arxiv_id": "2404.18352v1",
    "title": "Post-hoc and manifold explanations analysis of facial expression data based on deep learning",
    "authors": [
      "Yang Xiao"
    ],
    "abstract": "The complex information processing system of humans generates a lot of\nobjective and subjective evaluations, making the exploration of human cognitive\nproducts of great cutting-edge theoretical value. In recent years, deep\nlearning technologies, which are inspired by biological brain mechanisms, have\nmade significant strides in the application of psychological or cognitive\nscientific research, particularly in the memorization and recognition of facial\ndata. This paper investigates through experimental research how neural networks\nprocess and store facial expression data and associate these data with a range\nof psychological attributes produced by humans. Researchers utilized deep\nlearning model VGG16, demonstrating that neural networks can learn and\nreproduce key features of facial data, thereby storing image memories.\nMoreover, the experimental results reveal the potential of deep learning models\nin understanding human emotions and cognitive processes and establish a\nmanifold visualization interpretation of cognitive products or psychological\nattributes from a non-Euclidean space perspective, offering new insights into\nenhancing the explainability of AI. This study not only advances the\napplication of AI technology in the field of psychology but also provides a new\npsychological theoretical understanding the information processing of the AI.\nThe code is available in here: https://github.com/NKUShaw/Psychoinformatics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19PAGES",
    "pdf_url": "http://arxiv.org/pdf/2404.18352v1",
    "published_date": "2024-04-29 01:19:17 UTC",
    "updated_date": "2024-04-29 01:19:17 UTC"
  }
]