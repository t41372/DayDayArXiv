[
  {
    "arxiv_id": "2409.03944v2",
    "title": "HUMOS: Human Motion Model Conditioned on Body Shape",
    "authors": [
      "Shashank Tripathi",
      "Omid Taheri",
      "Christoph Lassner",
      "Michael J. Black",
      "Daniel Holden",
      "Carsten Stoll"
    ],
    "abstract": "Generating realistic human motion is essential for many computer vision and\ngraphics applications. The wide variety of human body shapes and sizes greatly\nimpacts how people move. However, most existing motion models ignore these\ndifferences, relying on a standardized, average body. This leads to uniform\nmotion across different body types, where movements don't match their physical\ncharacteristics, limiting diversity. To solve this, we introduce a new approach\nto develop a generative motion model based on body shape. We show that it's\npossible to train this model using unpaired data by applying cycle consistency,\nintuitive physics, and stability constraints, which capture the relationship\nbetween identity and movement. The resulting model generates diverse,\nphysically plausible, and dynamically stable human motions that are both\nquantitatively and qualitatively more realistic than current state-of-the-art\nmethods. More details are available on our project page\nhttps://CarstenEpic.github.io/humos/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in ECCV'24. Project page:\n  https://CarstenEpic.github.io/humos/",
    "pdf_url": "http://arxiv.org/pdf/2409.03944v2",
    "published_date": "2024-09-05 23:50:57 UTC",
    "updated_date": "2025-04-03 07:40:12 UTC"
  },
  {
    "arxiv_id": "2409.03937v1",
    "title": "Harnessing LLMs for Cross-City OD Flow Prediction",
    "authors": [
      "Chenyang Yu",
      "Xinpeng Xie",
      "Yan Huang",
      "Chenxi Qiu"
    ],
    "abstract": "Understanding and predicting Origin-Destination (OD) flows is crucial for\nurban planning and transportation management. Traditional OD prediction models,\nwhile effective within single cities, often face limitations when applied\nacross different cities due to varied traffic conditions, urban layouts, and\nsocio-economic factors. In this paper, by employing Large Language Models\n(LLMs), we introduce a new method for cross-city OD flow prediction. Our\napproach leverages the advanced semantic understanding and contextual learning\ncapabilities of LLMs to bridge the gap between cities with different\ncharacteristics, providing a robust and adaptable solution for accurate OD flow\nprediction that can be transferred from one city to another. Our novel\nframework involves four major components: collecting OD training datasets from\na source city, instruction-tuning the LLMs, predicting destination POIs in a\ntarget city, and identifying the locations that best match the predicted\ndestination POIs. We introduce a new loss function that integrates POI\nsemantics and trip distance during training. By extracting high-quality\nsemantic features from human mobility and POI data, the model understands\nspatial and functional relationships within urban spaces and captures\ninteractions between individuals and various POIs. Extensive experimental\nresults demonstrate the superiority of our approach over the state-of-the-art\nlearning-based methods in cross-city OD flow prediction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.03937v1",
    "published_date": "2024-09-05 23:04:28 UTC",
    "updated_date": "2024-09-05 23:04:28 UTC"
  },
  {
    "arxiv_id": "2409.03933v1",
    "title": "A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application",
    "authors": [
      "Esther Lagemann",
      "Julia Roeb",
      "Steven L. Brunton",
      "Christian Lagemann"
    ],
    "abstract": "The accurate quantification of wall-shear stress dynamics is of substantial\nimportance for various applications in fundamental and applied research,\nspanning areas from human health to aircraft design and optimization. Despite\nsignificant progress in experimental measurement techniques and post-processing\nalgorithms, temporally resolved wall-shear stress dynamics with adequate\nspatial resolution and within a suitable spatial domain remain an elusive goal.\nTo address this gap, we introduce a deep learning architecture that ingests\nwall-parallel velocity fields from the logarithmic layer of turbulent\nwall-bounded flows and outputs the corresponding 2D wall-shear stress fields\nwith identical spatial resolution and domain size. From a physical perspective,\nour framework acts as a surrogate model encapsulating the various mechanisms\nthrough which highly energetic outer-layer flow structures influence the\ngoverning wall-shear stress dynamics. The network is trained in a supervised\nfashion on a unified dataset comprising direct numerical simulations of\nstatistically 1D turbulent channel and spatially developing turbulent boundary\nlayer flows at friction Reynolds numbers ranging from 390 to 1,500. We\ndemonstrate a zero-shot applicability to experimental velocity fields obtained\nfrom Particle-Image Velocimetry measurements and verify the physical accuracy\nof the wall-shear stress estimates with synchronized wall-shear stress\nmeasurements using the Micro-Pillar Shear-Stress Sensor for Reynolds numbers up\nto 2,000. In summary, the presented framework lays the groundwork for\nextracting inaccessible experimental wall-shear stress information from readily\navailable velocity measurements and thus, facilitates advancements in a variety\nof experimental applications.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03933v1",
    "published_date": "2024-09-05 22:59:23 UTC",
    "updated_date": "2024-09-05 22:59:23 UTC"
  },
  {
    "arxiv_id": "2409.03911v1",
    "title": "The Role of Generative Systems in Historical Photography Management: A Case Study on Catalan Archives",
    "authors": [
      "Èric Śanchez",
      "Adrià Molina",
      "Oriol Ramos Terrades"
    ],
    "abstract": "The use of image analysis in automated photography management is an\nincreasing trend in heritage institutions. Such tools alleviate the human cost\nassociated with the manual and expensive annotation of new data sources while\nfacilitating fast access to the citizenship through online indexes and search\nengines. However, available tagging and description tools are usually designed\naround modern photographs in English, neglecting historical corpora in\nminoritized languages, each of which exhibits intrinsic particularities. The\nprimary objective of this research is to study the quantitative contribution of\ngenerative systems in the description of historical sources. This is done by\ncontextualizing the task of captioning historical photographs from the Catalan\narchives as a case study. Our findings provide practitioners with tools and\ndirections on transfer learning for captioning models based on visual\nadaptation and linguistic proximity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ECCV workshop AI4DH",
    "pdf_url": "http://arxiv.org/pdf/2409.03911v1",
    "published_date": "2024-09-05 21:08:25 UTC",
    "updated_date": "2024-09-05 21:08:25 UTC"
  },
  {
    "arxiv_id": "2409.03881v1",
    "title": "Multi-agent Path Finding for Mixed Autonomy Traffic Coordination",
    "authors": [
      "Han Zheng",
      "Zhongxia Yan",
      "Cathy Wu"
    ],
    "abstract": "In the evolving landscape of urban mobility, the prospective integration of\nConnected and Automated Vehicles (CAVs) with Human-Driven Vehicles (HDVs)\npresents a complex array of challenges and opportunities for autonomous driving\nsystems. While recent advancements in robotics have yielded Multi-Agent Path\nFinding (MAPF) algorithms tailored for agent coordination task characterized by\nsimplified kinematics and complete control over agent behaviors, these\nsolutions are inapplicable in mixed-traffic environments where uncontrollable\nHDVs must coexist and interact with CAVs. Addressing this gap, we propose the\nBehavior Prediction Kinematic Priority Based Search (BK-PBS), which leverages\nan offline-trained conditional prediction model to forecast HDV responses to\nCAV maneuvers, integrating these insights into a Priority Based Search (PBS)\nwhere the A* search proceeds over motion primitives to accommodate kinematic\nconstraints. We compare BK-PBS with CAV planning algorithms derived by\nrule-based car-following models, and reinforcement learning. Through\ncomprehensive simulation on a highway merging scenario across diverse scenarios\nof CAV penetration rate and traffic density, BK-PBS outperforms these baselines\nin reducing collision rates and enhancing system-level travel delay. Our work\nis directly applicable to many scenarios of multi-human multi-robot\ncoordination.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03881v1",
    "published_date": "2024-09-05 19:37:01 UTC",
    "updated_date": "2024-09-05 19:37:01 UTC"
  },
  {
    "arxiv_id": "2409.03874v1",
    "title": "Cost-Control in Display Advertising: Theory vs Practice",
    "authors": [
      "Anoop R Katti",
      "Rui C. Gonçalves",
      "Rinchin Iakovlev"
    ],
    "abstract": "In display advertising, advertisers want to achieve a marketing objective\nwith constraints on budget and cost-per-outcome. This is usually formulated as\nan optimization problem that maximizes the total utility under constraints. The\noptimization is carried out in an online fashion in the dual space - for an\nincoming Ad auction, a bid is placed using an optimal bidding formula, assuming\noptimal values for the dual variables; based on the outcome of the previous\nauctions, the dual variables are updated in an online fashion. While this\napproach is theoretically sound, in practice, the dual variables are not\noptimal from the beginning, but rather converge over time. Specifically, for\nthe cost-constraint, the convergence is asymptotic. As a result, we find that\ncost-control is ineffective. In this work, we analyse the shortcomings of the\noptimal bidding formula and propose a modification that deviates from the\ntheoretical derivation. We simulate various practical scenarios and study the\ncost-control behaviors of the two algorithms. Through a large-scale evaluation\non the real-word data, we show that the proposed modification reduces the cost\nviolations by 50%, thereby achieving a better cost-control than the theoretical\nbidding formula.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03874v1",
    "published_date": "2024-09-05 19:22:33 UTC",
    "updated_date": "2024-09-05 19:22:33 UTC"
  },
  {
    "arxiv_id": "2409.15318v2",
    "title": "On the Complexity of Neural Computation in Superposition",
    "authors": [
      "Micah Adler",
      "Nir Shavit"
    ],
    "abstract": "Superposition, the ability of neural networks to represent more features than\nneurons, is increasingly seen as key to the efficiency of large models. This\npaper investigates the theoretical foundations of computing in superposition,\nestablishing complexity bounds for explicit, provably correct algorithms.\n  We present the first lower bounds for a neural network computing in\nsuperposition, showing that for a broad class of problems, including\npermutations and pairwise logical operations, computing $m'$ features in\nsuperposition requires at least $\\Omega(\\sqrt{m' \\log m'})$ neurons and\n$\\Omega(m' \\log m')$ parameters. This implies the first subexponential upper\nbound on superposition capacity: a network with $n$ neurons can compute at most\n$O(n^2 / \\log n)$ features. Conversely, we provide a nearly tight constructive\nupper bound: logical operations like pairwise AND can be computed using\n$O(\\sqrt{m'} \\log m')$ neurons and $O(m' \\log^2 m')$ parameters. There is thus\nan exponential gap between the complexity of computing in superposition (the\nsubject of this work) versus merely representing features, which can require as\nlittle as $O(\\log m')$ neurons based on the Johnson-Lindenstrauss Lemma.\n  Our hope is that our results open a path for using complexity theoretic\ntechniques in neural network interpretability research.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.DS",
      "cs.NE",
      "F.1.1; F.2.2; I.2.m; E.3"
    ],
    "primary_category": "cs.CC",
    "comment": "32 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15318v2",
    "published_date": "2024-09-05 18:58:59 UTC",
    "updated_date": "2025-04-18 18:13:39 UTC"
  },
  {
    "arxiv_id": "2409.03844v1",
    "title": "MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene Experiences With Ambient Awareness And Personalization",
    "authors": [
      "Haoxuan Liu",
      "Zihao Wang",
      "Haorong Hong",
      "Youwei Feng",
      "Jiaxin Yu",
      "Han Diao",
      "Yunfei Xu",
      "Kejun Zhang"
    ],
    "abstract": "This paper introduces MetaBGM, a groundbreaking framework for generating\nbackground music that adapts to dynamic scenes and real-time user interactions.\nWe define multi-scene as variations in environmental contexts, such as\ntransitions in game settings or movie scenes. To tackle the challenge of\nconverting backend data into music description texts for audio generation\nmodels, MetaBGM employs a novel two-stage generation approach that transforms\ncontinuous scene and user state data into these texts, which are then fed into\nan audio generation model for real-time soundtrack creation. Experimental\nresults demonstrate that MetaBGM effectively generates contextually relevant\nand dynamic background music for interactive applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03844v1",
    "published_date": "2024-09-05 18:12:11 UTC",
    "updated_date": "2024-09-05 18:12:11 UTC"
  },
  {
    "arxiv_id": "2409.04478v1",
    "title": "Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small",
    "authors": [
      "Maheep Chaudhary",
      "Atticus Geiger"
    ],
    "abstract": "A popular new method in mechanistic interpretability is to train\nhigh-dimensional sparse autoencoders (SAEs) on neuron activations and use SAE\nfeatures as the atomic units of analysis. However, the body of evidence on\nwhether SAE feature spaces are useful for causal analysis is underdeveloped. In\nthis work, we use the RAVEL benchmark to evaluate whether SAEs trained on\nhidden representations of GPT-2 small have sets of features that separately\nmediate knowledge of which country a city is in and which continent it is in.\nWe evaluate four open-source SAEs for GPT-2 small against each other, with\nneurons serving as a baseline, and linear features learned via distributed\nalignment search (DAS) serving as a skyline. For each, we learn a binary mask\nto select features that will be patched to change the country of a city without\nchanging the continent, or vice versa. Our results show that SAEs struggle to\nreach the neuron baseline, and none come close to the DAS skyline. We release\ncode here: https://github.com/MaheepChaudhary/SAE-Ravel",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04478v1",
    "published_date": "2024-09-05 18:00:37 UTC",
    "updated_date": "2024-09-05 18:00:37 UTC"
  },
  {
    "arxiv_id": "2409.03833v1",
    "title": "AI forecasting of higher-order wave modes of spinning binary black hole mergers",
    "authors": [
      "Victoria Tiki",
      "Kiet Pham",
      "Eliu Huerta"
    ],
    "abstract": "We present a physics-inspired transformer model that predicts the non-linear\ndynamics of higher-order wave modes emitted by quasi-circular, spinning,\nnon-precessing binary black hole mergers. The model forecasts the waveform\nevolution from the pre-merger phase through the ringdown, starting with an\ninput time-series spanning $ t \\in [-5000\\textrm{M}, -100\\textrm{M}) $. The\nmerger event, defined as the peak amplitude of waveforms that include the $l =\n|m| = 2$ modes, occurs at $ t = 0\\textrm{M} $. The transformer then generates\npredictions over the time range $ t \\in [-100\\textrm{M}, 130\\textrm{M}] $. We\nproduced training, evaluation and test sets using the NRHybSur3dq8 model,\nconsidering a signal manifold defined by mass ratios $ q \\in [1, 8] $; spin\ncomponents $ s^z_{\\{1,2\\}} \\in [-0.8, 0.8] $; modes up to $l \\leq 4$, including\nthe $(5,5)$ mode but excluding the $(4,0)$ and $(4,1)$ modes; and inclination\nangles $\\theta \\in [0, \\pi]$. We trained the model on 14,440,761 waveforms,\ncompleting the training in 15 hours using 16 NVIDIA A100 GPUs in the Delta\nsupercomputer. We used 4 H100 GPUs in the DeltaAI supercomputer to compute,\nwithin 7 hours, the overlap between ground truth and predicted waveforms using\na test set of 840,000 waveforms, finding that the mean and median overlaps over\nthe test set are 0.996 and 0.997, respectively. Additionally, we conducted\ninterpretability studies to elucidate the waveform features utilized by our\ntransformer model to produce accurate predictions. The scientific software used\nfor this work is released with this manuscript.",
    "categories": [
      "gr-qc",
      "astro-ph.IM",
      "cs.AI",
      "68T10, 85-08, 83C35, 83C57",
      "I.2"
    ],
    "primary_category": "gr-qc",
    "comment": "27 pages, 1 appendix, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.03833v1",
    "published_date": "2024-09-05 18:00:11 UTC",
    "updated_date": "2024-09-05 18:00:11 UTC"
  },
  {
    "arxiv_id": "2409.03757v3",
    "title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding",
    "authors": [
      "Yunze Man",
      "Shuhong Zheng",
      "Zhipeng Bao",
      "Martial Hebert",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ],
    "abstract": "Complex 3D scene understanding has gained increasing attention, with scene\nencoding strategies playing a crucial role in this success. However, the\noptimal scene encoding strategies for various scenarios remain unclear,\nparticularly compared to their image-based counterparts. To address this issue,\nwe present a comprehensive study that probes various visual encoding models for\n3D scene understanding, identifying the strengths and limitations of each model\nacross different scenarios. Our evaluation spans seven vision foundation\nencoders, including image-based, video-based, and 3D foundation models. We\nevaluate these models in four tasks: Vision-Language Scene Reasoning, Visual\nGrounding, Segmentation, and Registration, each focusing on different aspects\nof scene understanding. Our evaluations yield key findings: DINOv2 demonstrates\nsuperior performance, video models excel in object-level tasks, diffusion\nmodels benefit geometric tasks, and language-pretrained models show unexpected\nlimitations in language-related tasks. These insights challenge some\nconventional understandings, provide novel perspectives on leveraging visual\nfoundation models, and highlight the need for more flexible encoder selection\nin future vision-language and scene-understanding tasks. Code:\nhttps://github.com/YunzeMan/Lexicon3D",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. Project page: https://yunzeman.github.io/lexicon3d\n  Github: https://github.com/YunzeMan/Lexicon3D",
    "pdf_url": "http://arxiv.org/pdf/2409.03757v3",
    "published_date": "2024-09-05 17:59:56 UTC",
    "updated_date": "2025-05-08 05:10:27 UTC"
  },
  {
    "arxiv_id": "2409.03753v2",
    "title": "WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild",
    "authors": [
      "Yuntian Deng",
      "Wenting Zhao",
      "Jack Hessel",
      "Xiang Ren",
      "Claire Cardie",
      "Yejin Choi"
    ],
    "abstract": "The increasing availability of real-world conversation data offers exciting\nopportunities for researchers to study user-chatbot interactions. However, the\nsheer volume of this data makes manually examining individual conversations\nimpractical. To overcome this challenge, we introduce WildVis, an interactive\ntool that enables fast, versatile, and large-scale conversation analysis.\nWildVis provides search and visualization capabilities in the text and\nembedding spaces based on a list of criteria. To manage million-scale datasets,\nwe implemented optimizations including search index construction, embedding\nprecomputation and compression, and caching to ensure responsive user\ninteractions within seconds. We demonstrate WildVis' utility through three case\nstudies: facilitating chatbot misuse research, visualizing and comparing topic\ndistributions across datasets, and characterizing user-specific conversation\npatterns. WildVis is open-source and designed to be extendable, supporting\nadditional datasets and customized search and visualization functionalities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03753v2",
    "published_date": "2024-09-05 17:59:15 UTC",
    "updated_date": "2024-09-09 10:04:00 UTC"
  },
  {
    "arxiv_id": "2409.03735v2",
    "title": "Investigating Privacy Bias in Training Data of Language Models",
    "authors": [
      "Yan Shvartzshnaider",
      "Vasisht Duddu"
    ],
    "abstract": "As LLMs are integrated into sociotechnical systems, it is crucial to examine\nthe privacy biases they exhibit. A privacy bias refers to the skew in the\nappropriateness of information flows within a given context that LLMs acquire\nfrom large amounts of non-publicly available training data. This skew may\neither align with existing expectations or signal a symptom of systemic issues\nreflected in the training datasets.\n  We formulate a novel research question: how can we examine privacy biases in\nthe training data of LLMs? We present a novel approach to assess the privacy\nbiases using a contextual integrity-based methodology to evaluate the responses\nfrom different LLMs. Our approach accounts for the sensitivity of responses\nacross prompt variations, which hinders the evaluation of privacy biases. We\ninvestigate how privacy biases are affected by model capacities and\noptimizations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 4 Figures, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2409.03735v2",
    "published_date": "2024-09-05 17:50:31 UTC",
    "updated_date": "2025-02-05 12:31:01 UTC"
  },
  {
    "arxiv_id": "2409.03811v2",
    "title": "Parallel AutoRegressive Models for Multi-Agent Combinatorial Optimization",
    "authors": [
      "Federico Berto",
      "Chuanbo Hua",
      "Laurin Luttmann",
      "Jiwoo Son",
      "Junyoung Park",
      "Kyuree Ahn",
      "Changhyun Kwon",
      "Lin Xie",
      "Jinkyoo Park"
    ],
    "abstract": "Combinatorial optimization problems involving multiple agents are notoriously\nchallenging due to their NP-hard nature and the necessity for effective agent\ncoordination. Despite advancements in learning-based methods, existing\napproaches often face critical limitations, including suboptimal agent\ncoordination, poor generalizability, and high computational latency. To address\nthese issues, we propose Parallel AutoRegressive Combinatorial Optimization\n(PARCO), a reinforcement learning framework designed to construct high-quality\nsolutions for multi-agent combinatorial tasks efficiently. To this end, PARCO\nintegrates three key components: (1) transformer-based communication layers to\nenable effective agent collaboration during parallel solution construction, (2)\na multiple pointer mechanism for low-latency, parallel agent decision-making,\nand (3) priority-based conflict handlers to resolve decision conflicts via\nlearned priorities. We evaluate PARCO in multi-agent vehicle routing and\nscheduling problems where our approach outperforms state-of-the-art learning\nmethods and demonstrates strong generalization ability and remarkable\ncomputational efficiency. Code available at: https://github.com/ai4co/parco.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03811v2",
    "published_date": "2024-09-05 17:49:18 UTC",
    "updated_date": "2025-02-05 09:49:54 UTC"
  },
  {
    "arxiv_id": "2409.03810v1",
    "title": "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data",
    "authors": [
      "Yejie Wang",
      "Keqing He",
      "Dayuan Fu",
      "Zhuoma Gongque",
      "Heyang Xu",
      "Yanxu Chen",
      "Zhexu Wang",
      "Yujia Fu",
      "Guanting Dong",
      "Muxi Diao",
      "Jingang Wang",
      "Mengdi Zhang",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "abstract": "Recently, there has been a growing interest in studying how to construct\nbetter code instruction tuning data. However, we observe Code models trained\nwith these datasets exhibit high performance on HumanEval but perform worse on\nother benchmarks such as LiveCodeBench. Upon further investigation, we find\nthat many datasets suffer from severe data leakage. After cleaning up most of\nthe leaked data, some well-known high-quality datasets perform poorly. This\ndiscovery reveals a new challenge: identifying which dataset genuinely qualify\nas high-quality code instruction data. To address this, we propose an efficient\ncode data pruning strategy for selecting good samples. Our approach is based on\nthree dimensions: instruction complexity, response quality, and instruction\ndiversity. Based on our selected data, we present XCoder, a family of models\nfinetuned from LLaMA3. Our experiments show XCoder achieves new\nstate-of-the-art performance using fewer training data, which verify the\neffectiveness of our data strategy. Moreover, we perform a comprehensive\nanalysis on the data composition and find existing code datasets have different\ncharacteristics according to their construction methods, which provide new\ninsights for future code LLMs. Our models and dataset are released in\nhttps://github.com/banksy23/XCoder",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2409.03810v1",
    "published_date": "2024-09-05 17:46:30 UTC",
    "updated_date": "2024-09-05 17:46:30 UTC"
  },
  {
    "arxiv_id": "2409.03733v2",
    "title": "Planning In Natural Language Improves LLM Search For Code Generation",
    "authors": [
      "Evan Wang",
      "Federico Cassano",
      "Catherine Wu",
      "Yunfeng Bai",
      "Will Song",
      "Vaskar Nath",
      "Ziwen Han",
      "Sean Hendryx",
      "Summer Yue",
      "Hugh Zhang"
    ],
    "abstract": "While scaling training compute has led to remarkable improvements in large\nlanguage models (LLMs), scaling inference compute has not yet yielded analogous\ngains. We hypothesize that a core missing component is a lack of diverse LLM\noutputs, leading to inefficient search due to models repeatedly sampling highly\nsimilar, yet incorrect generations. We empirically demonstrate that this lack\nof diversity can be mitigated by searching over candidate plans for solving a\nproblem in natural language. Based on this insight, we propose PlanSearch, a\nnovel search algorithm which shows strong results across HumanEval+, MBPP+, and\nLiveCodeBench (a contamination-free benchmark for competitive coding).\nPlanSearch generates a diverse set of observations about the problem and then\nuses these observations to construct plans for solving the problem. By\nsearching over plans in natural language rather than directly over code\nsolutions, PlanSearch explores a significantly more diverse range of potential\nsolutions compared to baseline search methods. Using PlanSearch on top of\nClaude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on\nLiveCodeBench, outperforming both the best score achieved without search\n(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).\nFinally, we show that, across all models, search algorithms, and benchmarks\nanalyzed, we can accurately predict performance gains due to search as a direct\nfunction of the diversity over generated ideas. Code can be found at\nhttps://github.com/scaleapi/plansearch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03733v2",
    "published_date": "2024-09-05 17:44:49 UTC",
    "updated_date": "2024-10-18 23:53:07 UTC"
  },
  {
    "arxiv_id": "2409.15317v1",
    "title": "Shared Autonomy with IDA: Interventional Diffusion Assistance",
    "authors": [
      "Brandon J. McMahan",
      "Zhenghao Peng",
      "Bolei Zhou",
      "Jonathan C. Kao"
    ],
    "abstract": "The rapid development of artificial intelligence (AI) has unearthed the\npotential to assist humans in controlling advanced technologies. Shared\nautonomy (SA) facilitates control by combining inputs from a human pilot and an\nAI copilot. In prior SA studies, the copilot is constantly active in\ndetermining the action played at each time step. This limits human autonomy and\nmay have deleterious effects on performance. In general, the amount of helpful\ncopilot assistance can vary greatly depending on the task dynamics. We\ntherefore hypothesize that human autonomy and SA performance improve through\ndynamic and selective copilot intervention. To address this, we develop a\ngoal-agnostic intervention assistance (IA) that dynamically shares control by\nhaving the copilot intervene only when the expected value of the copilot's\naction exceeds that of the human's action across all possible goals. We\nimplement IA with a diffusion copilot (termed IDA) trained on expert\ndemonstrations with goal masking. We prove a lower bound on the performance of\nIA that depends on pilot and copilot performance. Experiments with simulated\nhuman pilots show that IDA achieves higher performance than pilot-only and\ntraditional SA control in variants of the Reacher environment and Lunar Lander.\nWe then demonstrate that IDA achieves better control in Lunar Lander with\nhuman-in-the-loop experiments. Human participants report greater autonomy with\nIDA and prefer IDA over pilot-only and traditional SA control. We attribute the\nsuccess of IDA to preserving human autonomy while simultaneously offering\nassistance to prevent the human pilot from entering universally bad states.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 4 main figures, 2 appendix figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15317v1",
    "published_date": "2024-09-05 17:19:22 UTC",
    "updated_date": "2024-09-05 17:19:22 UTC"
  },
  {
    "arxiv_id": "2409.03707v1",
    "title": "A Different Level Text Protection Mechanism With Differential Privacy",
    "authors": [
      "Qingwen Fu"
    ],
    "abstract": "The article introduces a method for extracting words of different degrees of\nimportance based on the BERT pre-training model and proves the effectiveness of\nthis method. The article also discusses the impact of maintaining the same\nperturbation results for words of different importance on the overall text\nutility. This method can be applied to long text protection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03707v1",
    "published_date": "2024-09-05 17:13:38 UTC",
    "updated_date": "2024-09-05 17:13:38 UTC"
  },
  {
    "arxiv_id": "2409.15315v1",
    "title": "An Efficient Recommendation Model Based on Knowledge Graph Attention-Assisted Network (KGATAX)",
    "authors": [
      "Zhizhong Wu"
    ],
    "abstract": "Recommendation systems play a crucial role in helping users filter through\nvast amounts of information. However, traditional recommendation algorithms\noften overlook the integration and utilization of multi-source information,\nlimiting system performance. Therefore, this study proposes a novel\nrecommendation model, Knowledge Graph Attention-assisted Network (KGAT-AX). We\nfirst incorporate the knowledge graph into the recommendation model,\nintroducing an attention mechanism to explore higher order connectivity more\nexplicitly. By using multilayer interactive information propagation, the model\naggregates information to enhance its generalization ability. Furthermore, we\nintegrate auxiliary information into entities through holographic embeddings,\naggregating the information of adjacent entities for each entity by learning\ntheir inferential relationships. This allows for better utilization of\nauxiliary information associated with entities. We conducted experiments on\nreal datasets to demonstrate the rationality and effectiveness of the KGAT-AX\nmodel. Through experimental analysis, we observed the effectiveness and\npotential of KGAT-AX compared to other baseline models on public datasets.\nKGAT-AX demonstrates better knowledge information capture and relationship\nlearning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15315v1",
    "published_date": "2024-09-05 16:42:50 UTC",
    "updated_date": "2024-09-05 16:42:50 UTC"
  },
  {
    "arxiv_id": "2409.03685v2",
    "title": "View-Invariant Policy Learning via Zero-Shot Novel View Synthesis",
    "authors": [
      "Stephen Tian",
      "Blake Wulfe",
      "Kyle Sargent",
      "Katherine Liu",
      "Sergey Zakharov",
      "Vitor Guizilini",
      "Jiajun Wu"
    ],
    "abstract": "Large-scale visuomotor policy learning is a promising approach toward\ndeveloping generalizable manipulation systems. Yet, policies that can be\ndeployed on diverse embodiments, environments, and observational modalities\nremain elusive. In this work, we investigate how knowledge from large-scale\nvisual data of the world may be used to address one axis of variation for\ngeneralizable manipulation: observational viewpoint. Specifically, we study\nsingle-image novel view synthesis models, which learn 3D-aware scene-level\npriors by rendering images of the same scene from alternate camera viewpoints\ngiven a single input image. For practical application to diverse robotic data,\nthese models must operate zero-shot, performing view synthesis on unseen tasks\nand environments. We empirically analyze view synthesis models within a simple\ndata-augmentation scheme that we call View Synthesis Augmentation (VISTA) to\nunderstand their capabilities for learning viewpoint-invariant policies from\nsingle-viewpoint demonstration data. Upon evaluating the robustness of policies\ntrained with our method to out-of-distribution camera viewpoints, we find that\nthey outperform baselines in both simulated and real-world manipulation tasks.\nVideos and additional visualizations are available at\nhttps://s-tian.github.io/projects/vista.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.03685v2",
    "published_date": "2024-09-05 16:39:21 UTC",
    "updated_date": "2025-02-19 21:10:44 UTC"
  },
  {
    "arxiv_id": "2409.03671v2",
    "title": "TRACE-CS: A Synergistic Approach to Explainable Course Scheduling Using LLMs and Logic",
    "authors": [
      "Stylianos Loukas Vasileiou",
      "William Yeoh"
    ],
    "abstract": "We present TRACE-cs, a novel hybrid system that combines symbolic reasoning\nwith large language models (LLMs) to address contrastive queries in scheduling\nproblems. TRACE-cs leverages SAT solving techniques to encode scheduling\nconstraints and generate explanations for user queries, while utilizing an LLM\nto process the user queries into logical clauses as well as refine the\nexplanations generated by the symbolic solver to natural language sentences. By\nintegrating these components, our approach demonstrates the potential of\ncombining symbolic methods with LLMs to create explainable AI agents with\ncorrectness guarantees.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03671v2",
    "published_date": "2024-09-05 16:24:42 UTC",
    "updated_date": "2024-10-08 14:12:00 UTC"
  },
  {
    "arxiv_id": "2409.03669v2",
    "title": "A method to benchmark high-dimensional process drift detection",
    "authors": [
      "Edgar Wolf",
      "Tobias Windisch"
    ],
    "abstract": "Process curves are multivariate finite time series data coming from\nmanufacturing processes. This paper studies machine learning that detect drifts\nin process curve datasets. A theoretic framework to synthetically generate\nprocess curves in a controlled way is introduced in order to benchmark machine\nlearning algorithms for process drift detection. An evaluation score, called\nthe temporal area under the curve, is introduced, which allows to quantify how\nwell machine learning models unveil curves belonging to drift segments.\nFinally, a benchmark study comparing popular machine learning approaches on\nsynthetic data generated with the introduced framework is presented that shows\nthat existing algorithms often struggle with datasets containing multiple drift\nsegments.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03669v2",
    "published_date": "2024-09-05 16:23:07 UTC",
    "updated_date": "2024-12-05 18:56:04 UTC"
  },
  {
    "arxiv_id": "2409.03646v2",
    "title": "Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG",
    "authors": [
      "Manshan Guo",
      "Bhavin Choksi",
      "Sari Sadiya",
      "Alessandro T. Gifford",
      "Martina G. Vilas",
      "Radoslaw M. Cichy",
      "Gemma Roig"
    ],
    "abstract": "In contrast to human vision, artificial neural networks (ANNs) remain\nrelatively susceptible to adversarial attacks. To address this vulnerability,\nefforts have been made to transfer inductive bias from human brains to ANNs,\noften by training the ANN representations to match their biological\ncounterparts. Previous works relied on brain data acquired in rodents or\nprimates using invasive techniques, from specific regions of the brain, under\nnon-natural conditions (anesthetized animals), and with stimulus datasets\nlacking diversity and naturalness. In this work, we explored whether aligning\nmodel representations to human EEG responses to a rich set of real-world images\nincreases robustness to ANNs. Specifically, we trained ResNet50-backbone models\non a dual task of classification and EEG prediction; and evaluated their EEG\nprediction accuracy and robustness to adversarial attacks. We observed\nsignificant correlation between the networks' EEG prediction accuracy, often\nhighest around 100 ms post stimulus onset, and their gains in adversarial\nrobustness. Although effect size was limited, effects were consistent across\ndifferent random initializations and robust for architectural variants. We\nfurther teased apart the data from individual EEG channels and observed\nstrongest contribution from electrodes in the parieto-occipital regions. The\ndemonstrated utility of human EEG for such tasks opens up avenues for future\nefforts that scale to larger datasets under diverse stimuli conditions with the\npromise of stronger effects.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted as ECCV HCV workshop 2024 oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2409.03646v2",
    "published_date": "2024-09-05 16:04:57 UTC",
    "updated_date": "2024-12-12 21:15:25 UTC"
  },
  {
    "arxiv_id": "2409.05898v2",
    "title": "Simplex-enabled Safe Continual Learning Machine",
    "authors": [
      "Hongpeng Cao",
      "Yanbing Mao",
      "Yihao Cai",
      "Lui Sha",
      "Marco Caccamo"
    ],
    "abstract": "This paper proposes the SeC-Learning Machine: Simplex-enabled safe continual\nlearning for safety-critical autonomous systems. The SeC-learning machine is\nbuilt on Simplex logic (that is, ``using simplicity to control complexity'')\nand physics-regulated deep reinforcement learning (Phy-DRL). The SeC-learning\nmachine thus constitutes HP (high performance)-Student, HA (high\nassurance)-Teacher, and Coordinator. Specifically, the HP-Student is a\npre-trained high-performance but not fully verified Phy-DRL, continuing to\nlearn in a real plant to tune the action policy to be safe. In contrast, the\nHA-Teacher is a mission-reduced, physics-model-based, and verified design. As a\ncomplementary, HA-Teacher has two missions: backing up safety and correcting\nunsafe learning. The Coordinator triggers the interaction and the switch\nbetween HP-Student and HA-Teacher. Powered by the three interactive components,\nthe SeC-learning machine can i) assure lifetime safety (i.e., safety guarantee\nin any continual-learning stage, regardless of HP-Student's success or\nconvergence), ii) address the Sim2Real gap, and iii) learn to tolerate unknown\nunknowns in real plants. The experiments on a cart-pole system and a real\nquadruped robot demonstrate the distinguished features of the SeC-learning\nmachine, compared with continual learning built on state-of-the-art safe DRL\nframeworks with approaches to addressing the Sim2Real gap.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05898v2",
    "published_date": "2024-09-05 16:03:00 UTC",
    "updated_date": "2024-10-06 03:05:52 UTC"
  },
  {
    "arxiv_id": "2409.03597v3",
    "title": "Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Fold Paralysis",
    "authors": [
      "Yucong Zhang",
      "Xin Zou",
      "Jinshan Yang",
      "Wenjun Chen",
      "Juan Liu",
      "Faya Liang",
      "Ming Li"
    ],
    "abstract": "This paper presents the Multimodal Laryngoscopic Video Analyzing System\n(MLVAS), a novel system that leverages both audio and video data to\nautomatically extract key video segments and metrics from raw laryngeal\nvideostroboscopic videos for assisted clinical assessment. The system\nintegrates video-based glottis detection with an audio keyword spotting method\nto analyze both video and audio data, identifying patient vocalizations and\nrefining video highlights to ensure optimal inspection of vocal fold movements.\nBeyond key video segment extraction from the raw laryngeal videos, MLVAS is\nable to generate effective audio and visual features for Vocal Fold Paralysis\n(VFP) detection. Pre-trained audio encoders are utilized to encode the patient\nvoice to get the audio features. Visual features are generated by measuring the\nangle deviation of both the left and right vocal folds to the estimated glottal\nmidline on the segmented glottis masks. To get better masks, we introduce a\ndiffusion-based refinement that follows traditional U-Net segmentation to\nreduce false positives. We conducted several ablation studies to demonstrate\nthe effectiveness of each module and modalities in the proposed MLVAS. The\nexperimental results on a public segmentation dataset show the effectiveness of\nour proposed segmentation module. In addition, unilateral VFP classification\nresults on a real-world clinic dataset demonstrate MLVAS's ability of providing\nreliable and objective metrics as well as visualization for assisted clinical\ndiagnosis.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to CSL",
    "pdf_url": "http://arxiv.org/pdf/2409.03597v3",
    "published_date": "2024-09-05 14:56:38 UTC",
    "updated_date": "2025-04-22 15:32:41 UTC"
  },
  {
    "arxiv_id": "2409.13705v2",
    "title": "Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble",
    "authors": [
      "Olivia Sturman",
      "Aparna Joshi",
      "Bhaktipriya Radharapu",
      "Piyush Kumar",
      "Renee Shelby"
    ],
    "abstract": "Increasing use of large language models (LLMs) demand performant guardrails\nto ensure the safety of inputs and outputs of LLMs. When these safeguards are\ntrained on imbalanced data, they can learn the societal biases. We present a\nlight-weight, post-processing method for mitigating counterfactual fairness in\nclosed-source text safety classifiers. Our approach involves building an\nensemble that not only outperforms the input classifiers and policy-aligns\nthem, but also acts as a debiasing regularizer. We introduce two\nthreshold-agnostic metrics to assess the counterfactual fairness of a model,\nand demonstrate how combining these metrics with Fair Data Reweighting (FDW)\nhelps mitigate biases. We create an expanded Open AI dataset, and a new\ntemplated LLM-generated dataset based on user-prompts, both of which are\ncounterfactually balanced across identity groups and cover four key areas of\nsafety; we will work towards publicly releasing these datasets. Our results\nshow that our approach improves counterfactual fairness with minimal impact on\nmodel performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13705v2",
    "published_date": "2024-09-05 14:35:35 UTC",
    "updated_date": "2024-10-22 01:01:56 UTC"
  },
  {
    "arxiv_id": "2409.03563v1",
    "title": "100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances",
    "authors": [
      "Lorenzo Pacchiardi",
      "Lucy G. Cheke",
      "José Hernández-Orallo"
    ],
    "abstract": "Predicting the performance of LLMs on individual task instances is essential\nto ensure their reliability in high-stakes applications. To do so, a\npossibility is to evaluate the considered LLM on a set of task instances and\ntrain an assessor to predict its performance based on features of the\ninstances. However, this approach requires evaluating each new LLM on a\nsufficiently large set of task instances to train an assessor specific to it.\nIn this work, we leverage the evaluation results of previously tested LLMs to\nreduce the number of evaluations required to predict the performance of a new\nLLM. In practice, we propose to test the new LLM on a small set of reference\ninstances and train a generic assessor which predicts the performance of the\nLLM on an instance based on the performance of the former on the reference set\nand features of the instance of interest. We conduct empirical studies on\nHELM-Lite and KindsOfReasoning, a collection of existing reasoning datasets\nthat we introduce, where we evaluate all instruction-fine-tuned OpenAI models\nuntil the January 2024 version of GPT4. When predicting performance on\ninstances with the same distribution as those used to train the generic\nassessor, we find this achieves performance comparable to the LLM-specific\nassessors trained on the full set of instances. Additionally, we find that\nrandomly selecting the reference instances performs as well as some advanced\nselection methods we tested. For out of distribution, however, no clear winner\nemerges and the overall performance is worse, suggesting that the inherent\npredictability of LLMs is low.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at the 2024 KDD workshop on Evaluation and Trustworthiness\n  of Generative AI Models",
    "pdf_url": "http://arxiv.org/pdf/2409.03563v1",
    "published_date": "2024-09-05 14:19:45 UTC",
    "updated_date": "2024-09-05 14:19:45 UTC"
  },
  {
    "arxiv_id": "2409.03550v2",
    "title": "DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture",
    "authors": [
      "Qianlong Xiang",
      "Miao Zhang",
      "Yuzhang Shang",
      "Jianlong Wu",
      "Yan Yan",
      "Liqiang Nie"
    ],
    "abstract": "Diffusion models (DMs) have demonstrated exceptional generative capabilities\nacross various domains, including image, video, and so on. A key factor\ncontributing to their effectiveness is the high quantity and quality of data\nused during training. However, mainstream DMs now consume increasingly large\namounts of data. For example, training a Stable Diffusion model requires\nbillions of image-text pairs. This enormous data requirement poses significant\nchallenges for training large DMs due to high data acquisition costs and\nstorage expenses. To alleviate this data burden, we propose a novel scenario:\nusing existing DMs as data sources to train new DMs with any architecture. We\nrefer to this scenario as Data-Free Knowledge Distillation for Diffusion Models\n(DKDM), where the generative ability of DMs is transferred to new ones in a\ndata-free manner. To tackle this challenge, we make two main contributions.\nFirst, we introduce a DKDM objective that enables the training of new DMs via\ndistillation, without requiring access to the data. Second, we develop a\ndynamic iterative distillation method that efficiently extracts time-domain\nknowledge from existing DMs, enabling direct retrieval of training data without\nthe need for a prolonged generative process. To the best of our knowledge, we\nare the first to explore this scenario. Experimental results demonstrate that\nour data-free approach not only achieves competitive generative performance but\nalso, in some instances, outperforms models trained with the entire dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03550v2",
    "published_date": "2024-09-05 14:12:22 UTC",
    "updated_date": "2025-02-28 15:26:03 UTC"
  },
  {
    "arxiv_id": "2409.03543v1",
    "title": "Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift",
    "authors": [
      "Fabian Diet",
      "Moussa Kassem Sbeyti",
      "Michelle Karg"
    ],
    "abstract": "Natural distribution shift causes a deterioration in the perception\nperformance of convolutional neural networks (CNNs). This comprehensive\nanalysis for real-world traffic data addresses: 1) investigating the effect of\nnatural distribution shift and weather augmentations on both detection quality\nand confidence estimation, 2) evaluating model performance for both\nclassification and object localization, and 3) benchmarking two common\nuncertainty quantification methods - Ensembles and different variants of\nMonte-Carlo (MC) Dropout - under natural and close-to-natural distribution\nshift. For this purpose, a novel dataset has been curated from publicly\navailable autonomous driving datasets. The in-distribution (ID) data is based\non cutouts of a single object, for which both class and bounding box\nannotations are available. The six distribution-shift datasets cover adverse\nweather scenarios, simulated rain and fog, corner cases, and\nout-of-distribution data. A granular analysis of CNNs under distribution shift\nallows to quantize the impact of different types of shifts on both, task\nperformance and confidence estimation: ConvNeXt-Tiny is more robust than\nEfficientNet-B0; heavy rain degrades classification stronger than localization,\ncontrary to heavy fog; integrating MC-Dropout into selected layers only has the\npotential to enhance task performance and confidence estimation, whereby the\nidentification of these layers depends on the type of distribution shift and\nthe considered task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This preprint has not undergone any post-submission improvements or\n  corrections",
    "pdf_url": "http://arxiv.org/pdf/2409.03543v1",
    "published_date": "2024-09-05 14:06:56 UTC",
    "updated_date": "2024-09-05 14:06:56 UTC"
  },
  {
    "arxiv_id": "2409.04475v2",
    "title": "Revolutionizing Database Q&A with Large Language Models: Comprehensive Benchmark and Evaluation",
    "authors": [
      "Yihang Zheng",
      "Bo Li",
      "Zhenghao Lin",
      "Yi Luo",
      "Xuanhe Zhou",
      "Chen Lin",
      "Jinsong Su",
      "Guoliang Li",
      "Shifu Li"
    ],
    "abstract": "The development of Large Language Models (LLMs) has revolutionized QA across\nvarious industries, including the database domain. However, there is still a\nlack of a comprehensive benchmark to evaluate the capabilities of different\nLLMs and their modular components in database QA. To this end, we introduce\nDQABench, the first comprehensive database QA benchmark for LLMs. DQABench\nfeatures an innovative LLM-based method to automate the generation, cleaning,\nand rewriting of evaluation dataset, resulting in over 200,000 QA pairs in\nEnglish and Chinese, separately. These QA pairs cover a wide range of\ndatabase-related knowledge extracted from manuals, online communities, and\ndatabase instances. This inclusion allows for an additional assessment of LLMs'\nRetrieval-Augmented Generation (RAG) and Tool Invocation Generation (TIG)\ncapabilities in the database QA task. Furthermore, we propose a comprehensive\nLLM-based database QA testbed DQATestbed. This testbed is highly modular and\nscalable, with basic and advanced components such as Question Classification\nRouting (QCR), RAG, TIG, and Prompt Template Engineering (PTE). Moreover,\nDQABench provides a comprehensive evaluation pipeline that computes various\nmetrics throughout a standardized evaluation process to ensure the accuracy and\nfairness of the evaluation. We use DQABench to evaluate the database QA\ncapabilities under the proposed testbed comprehensively. The evaluation reveals\nfindings like (i) the strengths and limitations of nine LLM-based QA bots and\n(ii) the performance impact and potential improvements of various service\ncomponents (e.g., QCR, RAG, TIG). Our benchmark and findings will guide the\nfuture development of LLM-based database QA research.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.04475v2",
    "published_date": "2024-09-05 13:45:42 UTC",
    "updated_date": "2024-12-06 05:51:06 UTC"
  },
  {
    "arxiv_id": "2409.03516v1",
    "title": "LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution",
    "authors": [
      "Jeongsoo Kim",
      "Jongho Nang",
      "Junsuk Choe"
    ],
    "abstract": "Recent Vision Transformer (ViT)-based methods for Image Super-Resolution have\ndemonstrated impressive performance. However, they suffer from significant\ncomplexity, resulting in high inference times and memory usage. Additionally,\nViT models using Window Self-Attention (WSA) face challenges in processing\nregions outside their windows. To address these issues, we propose the\nLow-to-high Multi-Level Transformer (LMLT), which employs attention with\nvarying feature sizes for each head. LMLT divides image features along the\nchannel dimension, gradually reduces spatial size for lower heads, and applies\nself-attention to each head. This approach effectively captures both local and\nglobal information. By integrating the results from lower heads into higher\nheads, LMLT overcomes the window boundary issues in self-attention. Extensive\nexperiments show that our model significantly reduces inference time and GPU\nmemory usage while maintaining or even surpassing the performance of\nstate-of-the-art ViT-based Image Super-Resolution methods. Our codes are\navailiable at https://github.com/jwgdmkj/LMLT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03516v1",
    "published_date": "2024-09-05 13:29:50 UTC",
    "updated_date": "2024-09-05 13:29:50 UTC"
  },
  {
    "arxiv_id": "2409.03500v3",
    "title": "Willingness to Read AI-Generated News Is Not Driven by Their Perceived Quality",
    "authors": [
      "Fabrizio Gilardi",
      "Sabrina Di Lorenzo",
      "Juri Ezzaini",
      "Beryl Santa",
      "Benjamin Streiff",
      "Eric Zurfluh",
      "Emma Hoes"
    ],
    "abstract": "The advancement of artificial intelligence has led to its application in many\nareas, including news media, which makes it crucial to understand public\nreception of AI-generated news. This preregistered study investigates (i) the\nperceived quality of AI-assisted and AI-generated versus human-generated news\narticles, (ii) whether disclosure of AI's involvement in generating these news\narticles influences engagement with them, and (iii) whether such awareness\naffects the willingness to read AI-generated articles in the future. We\nconducted a survey experiment with 599 Swiss participants, who evaluated the\ncredibility, readability, and expertise of news articles either written by\njournalists (control group), rewritten by AI (AI-assisted group), or entirely\nwritten by AI (AI-generated group). Our results indicate that all articles were\nperceived to be of equal quality. When participants in the treatment groups\nwere subsequently made aware of AI's role, they expressed a higher willingness\nto continue reading the articles than participants in the control group.\nHowever, they were not more willing to read AI-generated news in the future.\nThese results suggest that aversion to AI usage in news media is not primarily\nrooted in a perceived lack of quality, and that by disclosing using AI,\njournalists could induce more short-term engagement.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03500v3",
    "published_date": "2024-09-05 13:12:16 UTC",
    "updated_date": "2025-02-14 10:39:01 UTC"
  },
  {
    "arxiv_id": "2409.03470v1",
    "title": "Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation",
    "authors": [
      "Prerak Mody",
      "Nicolas F. Chaves-de-Plaza",
      "Chinmay Rao",
      "Eleftheria Astrenidou",
      "Mischa de Ridder",
      "Nienke Hoekstra",
      "Klaus Hildebrandt",
      "Marius Staring"
    ],
    "abstract": "Increased usage of automated tools like deep learning in medical image\nsegmentation has alleviated the bottleneck of manual contouring. This has\nshifted manual labour to quality assessment (QA) of automated contours which\ninvolves detecting errors and correcting them. A potential solution to\nsemi-automated QA is to use deep Bayesian uncertainty to recommend potentially\nerroneous regions, thus reducing time spent on error detection. Previous work\nhas investigated the correspondence between uncertainty and error, however, no\nwork has been done on improving the \"utility\" of Bayesian uncertainty maps such\nthat it is only present in inaccurate regions and not in the accurate ones. Our\nwork trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which\npromotes uncertainty to be present only in inaccurate regions. We apply this\nmethod on datasets of two radiotherapy body sites, c.f. head-and-neck CT and\nprostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated\nagainst voxel inaccuracies using Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves. Numerical results show that when compared to the\nBayesian baseline the proposed method successfully suppresses uncertainty for\naccurate voxels, with similar presence of uncertainty for inaccurate voxels.\nCode to reproduce experiments is available at\nhttps://github.com/prerakmody/bayesuncertainty-error-correspondence",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:018",
    "pdf_url": "http://arxiv.org/pdf/2409.03470v1",
    "published_date": "2024-09-05 12:31:51 UTC",
    "updated_date": "2024-09-05 12:31:51 UTC"
  },
  {
    "arxiv_id": "2409.03463v3",
    "title": "Massive Activations in Graph Neural Networks: Decoding Attention for Domain-Dependent Interpretability",
    "authors": [
      "Lorenzo Bini",
      "Marco Sorbi",
      "Stephane Marchand-Maillet"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become increasingly popular for effectively\nmodeling graph-structured data, and attention mechanisms have been pivotal in\nenabling these models to capture complex patterns. In our study, we reveal a\ncritical yet underexplored consequence of integrating attention into\nedge-featured GNNs: the emergence of Massive Activations (MAs) within attention\nlayers. By developing a novel method for detecting MAs on edge features, we\nshow that these extreme activations are not only activation anomalies but\nencode domain-relevant signals. Our post-hoc interpretability analysis\ndemonstrates that, in molecular graphs, MAs aggregate predominantly on common\nbond types (e.g., single and double bonds) while sparing more informative ones\n(e.g., triple bonds). Furthermore, our ablation studies confirm that MAs can\nserve as natural attribution indicators, reallocating to less informative\nedges. Our study assesses various edge-featured attention-based GNN models\nusing benchmark datasets, including ZINC, TOX21, and PROTEINS. Key\ncontributions include (1) establishing the direct link between attention\nmechanisms and MAs generation in edge-featured GNNs, (2) developing a robust\ndefinition and detection method for MAs enabling reliable post-hoc\ninterpretability. Overall, our study reveals the complex interplay between\nattention mechanisms, edge-featured GNNs model, and MAs emergence, providing\ncrucial insights for relating GNNs internals to domain knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03463v3",
    "published_date": "2024-09-05 12:19:07 UTC",
    "updated_date": "2025-03-07 15:17:02 UTC"
  },
  {
    "arxiv_id": "2409.03454v2",
    "title": "How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes",
    "authors": [
      "Inacio Vieira",
      "Will Allred",
      "Séamus Lankford",
      "Sheila Castilho",
      "Andy Way"
    ],
    "abstract": "Decoder-only LLMs have shown impressive performance in MT due to their\nability to learn from extensive datasets and generate high-quality\ntranslations. However, LLMs often struggle with the nuances and style required\nfor organisation-specific translation. In this study, we explore the\neffectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3\n8B Instruct, leveraging translation memories (TMs), as a valuable resource to\nenhance accuracy and efficiency. We investigate the impact of fine-tuning the\nLlama 3 model using TMs from a specific organisation in the software sector.\nOur experiments cover five translation directions across languages of varying\nresource levels (English to Brazilian Portuguese, Czech, German, Finnish, and\nKorean). We analyse diverse sizes of training datasets (1k to 207k segments) to\nevaluate their influence on translation quality. We fine-tune separate models\nfor each training set and evaluate their performance based on automatic\nmetrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in\ntranslation performance with larger datasets across all metrics. On average,\nBLEU and COMET scores increase by 13 and 25 points, respectively, on the\nlargest training set against the baseline model. Notably, there is a\nperformance deterioration in comparison with the baseline model when\nfine-tuning on only 1k and 2k examples; however, we observe a substantial\nimprovement as the training dataset size increases. The study highlights the\npotential of integrating TMs with LLMs to create bespoke translation models\ntailored to the specific needs of businesses, thus enhancing translation\nquality and reducing turn-around times. This approach offers a valuable insight\nfor organisations seeking to leverage TMs and LLMs for optimal translation\noutcomes, especially in narrower domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03454v2",
    "published_date": "2024-09-05 12:06:38 UTC",
    "updated_date": "2024-09-10 09:22:26 UTC"
  },
  {
    "arxiv_id": "2409.04473v1",
    "title": "Learning in Order! A Sequential Strategy to Learn Invariant Features for Multimodal Sentiment Analysis",
    "authors": [
      "Xianbing Zhao",
      "Lizhen Qu",
      "Tao Feng",
      "Jianfei Cai",
      "Buzhou Tang"
    ],
    "abstract": "This work proposes a novel and simple sequential learning strategy to train\nmodels on videos and texts for multimodal sentiment analysis. To estimate\nsentiment polarities on unseen out-of-distribution data, we introduce a\nmultimodal model that is trained either in a single source domain or multiple\nsource domains using our learning strategy. This strategy starts with learning\ndomain invariant features from text, followed by learning sparse\ndomain-agnostic features from videos, assisted by the selected features learned\nin text. Our experimental results demonstrate that our model achieves\nsignificantly better performance than the state-of-the-art approaches on\naverage in both single-source and multi-source settings. Our feature selection\nprocedure favors the features that are independent to each other and are\nstrongly correlated with their polarity labels. To facilitate research on this\ntopic, the source code of this work will be publicly available upon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04473v1",
    "published_date": "2024-09-05 11:55:05 UTC",
    "updated_date": "2024-09-05 11:55:05 UTC"
  },
  {
    "arxiv_id": "2409.03444v1",
    "title": "Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities",
    "authors": [
      "Wei Lu",
      "Rachel K. Luu",
      "Markus J. Buehler"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) for domain applications in\nfields such as materials science and engineering depends on the development of\nfine-tuning strategies that adapt models for specialized, technical\ncapabilities. In this work, we explore the effects of Continued Pretraining\n(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization\napproaches, including Direct Preference Optimization (DPO) and Odds Ratio\nPreference Optimization (ORPO), on fine-tuned LLM performance. Our analysis\nshows how these strategies influence model outcomes and reveals that the\nmerging of multiple fine-tuned models can lead to the emergence of capabilities\nthat surpass the individual contributions of the parent models. We find that\nmodel merging leads to new functionalities that neither parent model could\nachieve alone, leading to improved performance in domain-specific assessments.\nExperiments with different model architectures are presented, including Llama\n3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring\nwhether the results hold also for much smaller models, we use a tiny LLM with\n1.7 billion parameters and show that very small LLMs do not necessarily feature\nemergent capabilities under model merging, suggesting that model scaling may be\na key component. In open-ended yet consistent chat conversations between a\nhuman and AI models, our assessment reveals detailed insights into how\ndifferent model variants perform and show that the smallest model achieves a\nhigh intelligence score across key criteria including reasoning depth,\ncreativity, clarity, and quantitative precision. Other experiments include the\ndevelopment of image generation prompts based on disparate biological material\ndesign concepts, to create new microstructures, architectural concepts, and\nurban design based on biological materials-inspired construction principles.",
    "categories": [
      "cs.CL",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03444v1",
    "published_date": "2024-09-05 11:49:53 UTC",
    "updated_date": "2024-09-05 11:49:53 UTC"
  },
  {
    "arxiv_id": "2409.03439v1",
    "title": "KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale",
    "authors": [
      "Wei Gao",
      "Jingqiang Wang",
      "Xinv Zhu",
      "Jun Zhong",
      "Yue Shen",
      "Youshuang Ding"
    ],
    "abstract": "We would like industrial robots to handle unstructured environments with\ncameras and perception pipelines. In contrast to traditional industrial robots\nthat replay offline-crafted trajectories, online behavior planning is required\nfor these perception-guided industrial applications. Aside from perception and\nplanning algorithms, deploying perception-guided manipulators also requires\nsubstantial effort in integration. One approach is writing scripts in a\ntraditional language (such as Python) to construct the planning problem and\nperform integration with other algorithmic modules & external devices. While\nscripting in Python is feasible for a handful of robots and applications,\ndeploying perception-guided manipulation at scale (e.g., more than 10000 robot\nworkstations in over 2000 customer sites) becomes intractable. To resolve this\nchallenge, we propose a Domain-Specific Language (DSL) for perception-guided\nmanipulation applications. To scale up the deployment,our DSL provides: 1) an\neasily accessible interface to construct & solve a sub-class of Task and Motion\nPlanning (TAMP) problems that are important in practical applications; and 2) a\nmechanism to implement flexible control flow to perform integration and address\ncustomized requirements of distinct industrial application. Combined with an\nintuitive graphical programming frontend, our DSL is mainly used by machine\noperators without coding experience in traditional programming languages.\nWithin hours of training, operators are capable of orchestrating interesting\nsophisticated manipulation behaviors with our DSL. Extensive practical\ndeployments demonstrate the efficacy of our method.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03439v1",
    "published_date": "2024-09-05 11:42:08 UTC",
    "updated_date": "2024-09-05 11:42:08 UTC"
  },
  {
    "arxiv_id": "2409.03429v1",
    "title": "Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection",
    "authors": [
      "Sara Roos-Hoefgeest",
      "Mario Roos-Hoefgeest",
      "Ignacio Alvarez",
      "Rafael C. González"
    ],
    "abstract": "High-precision surface defect detection in manufacturing is essential for\nensuring quality control. Laser triangulation profilometric sensors are key to\nthis process, providing detailed and accurate surface measurements over a line.\nTo achieve a complete and precise surface scan, accurate relative motion\nbetween the sensor and the workpiece is required. It is crucial to control the\nsensor pose to maintain optimal distance and relative orientation to the\nsurface. It is also important to ensure uniform profile distribution throughout\nthe scanning process. This paper presents a novel Reinforcement Learning (RL)\nbased approach to optimize robot inspection trajectories for profilometric\nsensors. Building upon the Boustrophedon scanning method, our technique\ndynamically adjusts the sensor position and tilt to maintain optimal\norientation and distance from the surface, while also ensuring a consistent\nprofile distance for uniform and high-quality scanning. Utilizing a simulated\nenvironment based on the CAD model of the part, we replicate real-world\nscanning conditions, including sensor noise and surface irregularities. This\nsimulation-based approach enables offline trajectory planning based on CAD\nmodels. Key contributions include the modeling of the state space, action\nspace, and reward function, specifically designed for inspection applications\nusing profilometric sensors. We use Proximal Policy Optimization (PPO)\nalgorithm to efficiently train the RL agent, demonstrating its capability to\noptimize inspection trajectories with profilometric sensors. To validate our\napproach, we conducted several experiments where a model trained on a specific\ntraining piece was tested on various parts in simulation. Also, we conducted a\nreal-world experiment by executing the optimized trajectory, generated offline\nfrom a CAD model, to inspect a part using a UR3e robotic arm model.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03429v1",
    "published_date": "2024-09-05 11:20:12 UTC",
    "updated_date": "2024-09-05 11:20:12 UTC"
  },
  {
    "arxiv_id": "2409.03806v1",
    "title": "Mpox Screen Lite: AI-Driven On-Device Offline Mpox Screening for Low-Resource African Mpox Emergency Response",
    "authors": [
      "Yudara Kularathne",
      "Prathapa Janitha",
      "Sithira Ambepitiya"
    ],
    "abstract": "Background: The 2024 Mpox outbreak, particularly severe in Africa with clade\n1b emergence, has highlighted critical gaps in diagnostic capabilities in\nresource-limited settings. This study aimed to develop and validate an\nartificial intelligence (AI)-driven, on-device screening tool for Mpox,\ndesigned to function offline in low-resource environments.\n  Methods: We developed a YOLOv8n-based deep learning model trained on 2,700\nimages (900 each of Mpox, other skin conditions, and normal skin), including\nsynthetic data. The model was validated on 360 images and tested on 540 images.\nA larger external validation was conducted using 1,500 independent images.\nPerformance metrics included accuracy, precision, recall, F1-score,\nsensitivity, and specificity.\n  Findings: The model demonstrated high accuracy (96%) in the final test set.\nFor Mpox detection, it achieved 93% precision, 97% recall, and an F1-score of\n95%. Sensitivity and specificity for Mpox detection were 97% and 96%,\nrespectively. Performance remained consistent in the larger external\nvalidation, confirming the model's robustness and generalizability.\n  Interpretation: This AI-driven screening tool offers a rapid, accurate, and\nscalable solution for Mpox detection in resource-constrained settings. Its\noffline functionality and high performance across diverse datasets suggest\nsignificant potential for improving Mpox surveillance and management,\nparticularly in areas lacking traditional diagnostic infrastructure.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "11 Pages, 2 Figures, 3 Tables",
    "pdf_url": "http://arxiv.org/pdf/2409.03806v1",
    "published_date": "2024-09-05 11:18:34 UTC",
    "updated_date": "2024-09-05 11:18:34 UTC"
  },
  {
    "arxiv_id": "2409.03404v2",
    "title": "KAN See In the Dark",
    "authors": [
      "Aoxiang Ning",
      "Minglong Xue",
      "Jinhong He",
      "Chengyun Song"
    ],
    "abstract": "Existing low-light image enhancement methods are difficult to fit the complex\nnonlinear relationship between normal and low-light images due to uneven\nillumination and noise effects. The recently proposed Kolmogorov-Arnold\nnetworks (KANs) feature spline-based convolutional layers and learnable\nactivation functions, which can effectively capture nonlinear dependencies. In\nthis paper, we design a KAN-Block based on KANs and innovatively apply it to\nlow-light image enhancement. This method effectively alleviates the limitations\nof current methods constrained by linear network structures and lack of\ninterpretability, further demonstrating the potential of KANs in low-level\nvision tasks. Given the poor perception of current low-light image enhancement\nmethods and the stochastic nature of the inverse diffusion process, we further\nintroduce frequency-domain perception for visually oriented enhancement.\nExtensive experiments demonstrate the competitive performance of our method on\nbenchmark datasets. The code will be available at:\nhttps://github.com/AXNing/KSID}{https://github.com/AXNing/KSID.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03404v2",
    "published_date": "2024-09-05 10:41:17 UTC",
    "updated_date": "2025-02-06 14:34:07 UTC"
  },
  {
    "arxiv_id": "2409.03402v1",
    "title": "Game On: Towards Language Models as RL Experimenters",
    "authors": [
      "Jingwei Zhang",
      "Thomas Lampe",
      "Abbas Abdolmaleki",
      "Jost Tobias Springenberg",
      "Martin Riedmiller"
    ],
    "abstract": "We propose an agent architecture that automates parts of the common\nreinforcement learning experiment workflow, to enable automated mastery of\ncontrol domains for embodied agents. To do so, it leverages a VLM to perform\nsome of the capabilities normally required of a human experimenter, including\nthe monitoring and analysis of experiment progress, the proposition of new\ntasks based on past successes and failures of the agent, decomposing tasks into\na sequence of subtasks (skills), and retrieval of the skill to execute -\nenabling our system to build automated curricula for learning. We believe this\nis one of the first proposals for a system that leverages a VLM throughout the\nfull experiment cycle of reinforcement learning. We provide a first prototype\nof this system, and examine the feasibility of current models and techniques\nfor the desired level of automation. For this, we use a standard Gemini model,\nwithout additional fine-tuning, to provide a curriculum of skills to a\nlanguage-conditioned Actor-Critic algorithm, in order to steer data collection\nso as to aid learning new skills. Data collected in this way is shown to be\nuseful for learning and iteratively improving control policies in a robotics\ndomain. Additional examination of the ability of the system to build a growing\nlibrary of skills, and to judge the progress of the training of those skills,\nalso shows promising results, suggesting that the proposed architecture\nprovides a potential recipe for fully automated mastery of tasks and domains\nfor embodied agents.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03402v1",
    "published_date": "2024-09-05 10:38:16 UTC",
    "updated_date": "2024-09-05 10:38:16 UTC"
  },
  {
    "arxiv_id": "2409.03805v1",
    "title": "Exploratory Visual Analysis for Increasing Data Readiness in Artificial Intelligence Projects",
    "authors": [
      "Mattias Tiger",
      "Daniel Jakobsson",
      "Anders Ynnerman",
      "Fredrik Heintz",
      "Daniel Jönsson"
    ],
    "abstract": "We present experiences and lessons learned from increasing data readiness of\nheterogeneous data for artificial intelligence projects using visual analysis\nmethods. Increasing the data readiness level involves understanding both the\ndata as well as the context in which it is used, which are challenges well\nsuitable to visual analysis. For this purpose, we contribute a mapping between\ndata readiness aspects and visual analysis techniques suitable for different\ndata types. We use the defined mapping to increase data readiness levels in use\ncases involving time-varying data, including numerical, categorical, and text.\nIn addition to the mapping, we extend the data readiness concept to better take\naspects of the task and solution into account and explicitly address\ndistribution shifts during data collection time. We report on our experiences\nin using the presented visual analysis techniques to aid future artificial\nintelligence projects in raising the data readiness level.",
    "categories": [
      "stat.ME",
      "cs.AI"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03805v1",
    "published_date": "2024-09-05 09:57:14 UTC",
    "updated_date": "2024-09-05 09:57:14 UTC"
  },
  {
    "arxiv_id": "2409.03384v1",
    "title": "Hardware Acceleration of LLMs: A comprehensive survey and comparison",
    "authors": [
      "Nikoletta Koilia",
      "Christoforos Kachris"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. In this paper, we present a\ncomprehensive survey of the several research efforts that have been presented\nfor the acceleration of transformer networks for Large Language Models using\nhardware accelerators.\n  The survey presents the frameworks that have been proposed and then performs\na qualitative and quantitative comparison regarding the technology, the\nprocessing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy\nefficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each\nframework. The main challenge in comparison is that every proposed scheme is\nimplemented on a different process technology making hard a fair comparison.\nThe main contribution of this paper is that we extrapolate the results of the\nperformance and the energy efficiency on the same technology to make a fair\ncomparison; one theoretical and one more practical. We implement part of the\nLLMs on several FPGA chips to extrapolate the results to the same process\ntechnology and then we make a fair comparison of the performance.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "https://airtable.com/appC2VwR6X4EeZ50s/shrKwchys0iktvDwk",
    "pdf_url": "http://arxiv.org/pdf/2409.03384v1",
    "published_date": "2024-09-05 09:43:25 UTC",
    "updated_date": "2024-09-05 09:43:25 UTC"
  },
  {
    "arxiv_id": "2409.03381v2",
    "title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
    "authors": [
      "Yongxin Deng",
      "Xihe Qiu",
      "Xiaoyu Tan",
      "Chao Qu",
      "Jing Pan",
      "Yuan Cheng",
      "Yinghui Xu",
      "Wei Chu"
    ],
    "abstract": "Cognitive psychology investigates perception, attention, memory, language,\nproblem-solving, decision-making, and reasoning. Kahneman's dual-system theory\nelucidates the human decision-making process, distinguishing between the rapid,\nintuitive System 1 and the deliberative, rational System 2. Recent advancements\nhave positioned large language Models (LLMs) as formidable tools nearing\nhuman-level proficiency in various cognitive tasks. Nonetheless, the presence\nof a dual-system framework analogous to human cognition in LLMs remains\nunexplored. This study introduces the \\textbf{CogniDual Framework for LLMs}\n(CFLLMs), designed to assess whether LLMs can, through self-training, evolve\nfrom deliberate deduction to intuitive responses, thereby emulating the human\nprocess of acquiring and mastering new information. Our findings reveal the\ncognitive mechanisms behind LLMs' response generation, enhancing our\nunderstanding of their capabilities in cognitive psychology. Practically,\nself-trained models can provide faster responses to certain queries, reducing\ncomputational demands during inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03381v2",
    "published_date": "2024-09-05 09:33:24 UTC",
    "updated_date": "2024-09-06 09:37:36 UTC"
  },
  {
    "arxiv_id": "2409.03377v3",
    "title": "Real-time Speech Enhancement on Raw Signals with Deep State-space Modeling",
    "authors": [
      "Yan Ru Pei",
      "Ritik Shrivastava",
      "FNU Sidharth"
    ],
    "abstract": "We present aTENNuate, a simple deep state-space autoencoder configured for\nefficient online raw speech enhancement in an end-to-end fashion. The network's\nperformance is primarily evaluated on raw speech denoising, with additional\nassessments on tasks such as super-resolution and de-quantization. We benchmark\naTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.\nThe network outperforms previous real-time denoising models in terms of PESQ\nscore, parameter count, MACs, and latency. Even as a raw waveform processing\nmodel, the model maintains high fidelity to the clean signal with minimal\naudible artifacts. In addition, the model remains performant even when the\nnoisy input is compressed down to 4000Hz and 4 bits, suggesting general speech\nenhancement capabilities in low-resource environments. Code is available at\ngithub.com/Brainchip-Inc/aTENNuate",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03377v3",
    "published_date": "2024-09-05 09:28:56 UTC",
    "updated_date": "2024-12-29 22:03:13 UTC"
  },
  {
    "arxiv_id": "2409.03375v1",
    "title": "Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time",
    "authors": [
      "Francisco de Arriba-Pérez",
      "Silvia García-Méndez"
    ],
    "abstract": "Based on official estimates, 50 million people worldwide are affected by\ndementia, and this number increases by 10 million new patients every year.\nWithout a cure, clinical prognostication and early intervention represent the\nmost effective ways to delay its progression. To this end, Artificial\nIntelligence and computational linguistics can be exploited for natural\nlanguage analysis, personalized assessment, monitoring, and treatment. However,\ntraditional approaches need more semantic knowledge management and\nexplicability capabilities. Moreover, using Large Language Models (LLMs) for\ncognitive decline diagnosis is still scarce, even though these models represent\nthe most advanced way for clinical-patient communication using intelligent\nsystems. Consequently, we leverage an LLM using the latest Natural Language\nProcessing (NLP) techniques in a chatbot solution to provide interpretable\nMachine Learning prediction of cognitive decline in real-time.\nLinguistic-conceptual features are exploited for appropriate natural language\nanalysis. Through explainability, we aim to fight potential biases of the\nmodels and improve their potential to help clinical workers in their diagnosis\ndecisions. More in detail, the proposed pipeline is composed of (i) data\nextraction employing NLP-based prompt engineering; (ii) stream-based data\nprocessing including feature engineering, analysis, and selection; (iii)\nreal-time classification; and (iv) the explainability dashboard to provide\nvisual and natural language descriptions of the prediction outcome.\nClassification results exceed 80 % in all evaluation metrics, with a recall\nvalue for the mental deterioration class about 85 %. To sum up, we contribute\nwith an affordable, flexible, non-invasive, personalized diagnostic system to\nthis work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03375v1",
    "published_date": "2024-09-05 09:27:05 UTC",
    "updated_date": "2024-09-05 09:27:05 UTC"
  },
  {
    "arxiv_id": "2409.03346v1",
    "title": "Sketch: A Toolkit for Streamlining LLM Operations",
    "authors": [
      "Xin Jiang",
      "Xiang Li",
      "Wenjia Ma",
      "Xuezhi Fang",
      "Yiqun Yao",
      "Naitong Yu",
      "Xuying Meng",
      "Peng Han",
      "Jing Li",
      "Aixin Sun",
      "Yequan Wang"
    ],
    "abstract": "Large language models (LLMs) represented by GPT family have achieved\nremarkable success. The characteristics of LLMs lie in their ability to\naccommodate a wide range of tasks through a generative approach. However, the\nflexibility of their output format poses challenges in controlling and\nharnessing the model's outputs, thereby constraining the application of LLMs in\nvarious domains. In this work, we present Sketch, an innovative toolkit\ndesigned to streamline LLM operations across diverse fields. Sketch comprises\nthe following components: (1) a suite of task description schemas and prompt\ntemplates encompassing various NLP tasks; (2) a user-friendly, interactive\nprocess for building structured output LLM services tailored to various NLP\ntasks; (3) an open-source dataset for output format control, along with tools\nfor dataset construction; and (4) an open-source model based on\nLLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting\ninstructions. We anticipate this initiative to bring considerable convenience\nto LLM users, achieving the goal of ''plug-and-play'' for various applications.\nThe components of Sketch will be progressively open-sourced at\nhttps://github.com/cofe-ai/Sketch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03346v1",
    "published_date": "2024-09-05 08:45:44 UTC",
    "updated_date": "2024-09-05 08:45:44 UTC"
  },
  {
    "arxiv_id": "2409.03320v1",
    "title": "YOLO-PPA based Efficient Traffic Sign Detection for Cruise Control in Autonomous Driving",
    "authors": [
      "Jingyu Zhang",
      "Wenqing Zhang",
      "Chaoyi Tan",
      "Xiangtian Li",
      "Qianyi Sun"
    ],
    "abstract": "It is very important to detect traffic signs efficiently and accurately in\nautonomous driving systems. However, the farther the distance, the smaller the\ntraffic signs. Existing object detection algorithms can hardly detect these\nsmall scaled signs.In addition, the performance of embedded devices on vehicles\nlimits the scale of detection models.To address these challenges, a YOLO PPA\nbased traffic sign detection algorithm is proposed in this paper.The\nexperimental results on the GTSDB dataset show that compared to the original\nYOLO, the proposed method improves inference efficiency by 11.2%. The mAP 50 is\nalso improved by 93.2%, which demonstrates the effectiveness of the proposed\nYOLO PPA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03320v1",
    "published_date": "2024-09-05 07:49:21 UTC",
    "updated_date": "2024-09-05 07:49:21 UTC"
  },
  {
    "arxiv_id": "2409.03295v1",
    "title": "N-gram Prediction and Word Difference Representations for Language Modeling",
    "authors": [
      "DongNyeong Heo",
      "Daniela Noemi Rim",
      "Heeyoul Choi"
    ],
    "abstract": "Causal language modeling (CLM) serves as the foundational framework\nunderpinning remarkable successes of recent large language models (LLMs).\nDespite its success, the training approach for next word prediction poses a\npotential risk of causing the model to overly focus on local dependencies\nwithin a sentence. While prior studies have been introduced to predict future N\nwords simultaneously, they were primarily applied to tasks such as masked\nlanguage modeling (MLM) and neural machine translation (NMT). In this study, we\nintroduce a simple N-gram prediction framework for the CLM task. Moreover, we\nintroduce word difference representation (WDR) as a surrogate and\ncontextualized target representation during model training on the basis of\nN-gram prediction framework. To further enhance the quality of next word\nprediction, we propose an ensemble method that incorporates the future N words'\nprediction results. Empirical evaluations across multiple benchmark datasets\nencompassing CLM and NMT tasks demonstrate the significant advantages of our\nproposed methods over the conventional CLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03295v1",
    "published_date": "2024-09-05 07:03:23 UTC",
    "updated_date": "2024-09-05 07:03:23 UTC"
  },
  {
    "arxiv_id": "2409.03291v2",
    "title": "LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts",
    "authors": [
      "Henrique Da Silva Gameiro",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "abstract": "With the emergence of widely available powerful LLMs, disinformation\ngenerated by large Language Models (LLMs) has become a major concern.\nHistorically, LLM detectors have been touted as a solution, but their\neffectiveness in the real world is still to be proven. In this paper, we focus\non an important setting in information operations -- short news-like posts\ngenerated by moderately sophisticated attackers.\n  We demonstrate that existing LLM detectors, whether zero-shot or\npurpose-trained, are not ready for real-world use in that setting. All tested\nzero-shot detectors perform inconsistently with prior benchmarks and are highly\nvulnerable to sampling temperature increase, a trivial attack absent from\nrecent benchmarks. A purpose-trained detector generalizing across LLMs and\nunseen attacks can be developed, but it fails to generalize to new\nhuman-written texts.\n  We argue that the former indicates domain-specific benchmarking is needed,\nwhile the latter suggests a trade-off between the adversarial evasion\nresilience and overfitting to the reference human text, with both needing\nevaluation in benchmarks and currently absent. We believe this suggests a\nre-consideration of current LLM detector benchmarking approaches and provides a\ndynamically extensible benchmark to allow it\n(https://github.com/Reliable-Information-Lab-HEVS/benchmark_llm_texts_detection).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "I.2.7; K.6.5"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 7 tables, 13 figures, under consideration for EMNLP",
    "pdf_url": "http://arxiv.org/pdf/2409.03291v2",
    "published_date": "2024-09-05 06:55:13 UTC",
    "updated_date": "2024-09-27 16:04:40 UTC"
  },
  {
    "arxiv_id": "2409.03284v1",
    "title": "iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models",
    "authors": [
      "Yassir Lairgi",
      "Ludovic Moncla",
      "Rémy Cazabet",
      "Khalid Benabdeslem",
      "Pierre Cléau"
    ],
    "abstract": "Most available data is unstructured, making it challenging to access valuable\ninformation. Automatically building Knowledge Graphs (KGs) is crucial for\nstructuring data and making it accessible, allowing users to search for\ninformation effectively. KGs also facilitate insights, inference, and\nreasoning. Traditional NLP methods, such as named entity recognition and\nrelation extraction, are key in information retrieval but face limitations,\nincluding the use of predefined entity types and the need for supervised\nlearning. Current research leverages large language models' capabilities, such\nas zero- or few-shot learning. However, unresolved and semantically duplicated\nentities and relations still pose challenges, leading to inconsistent graphs\nand requiring extensive post-processing. Additionally, most approaches are\ntopic-dependent. In this paper, we propose iText2KG, a method for incremental,\ntopic-independent KG construction without post-processing. This plug-and-play,\nzero-shot method is applicable across a wide range of KG construction scenarios\nand comprises four modules: Document Distiller, Incremental Entity Extractor,\nIncremental Relation Extractor, and Graph Integrator and Visualization. Our\nmethod demonstrates superior performance compared to baseline methods across\nthree scenarios: converting scientific papers to graphs, websites to graphs,\nand CVs to graphs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at The International Web Information Systems Engineering\n  conference (the WISE conference) 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.03284v1",
    "published_date": "2024-09-05 06:49:14 UTC",
    "updated_date": "2024-09-05 06:49:14 UTC"
  },
  {
    "arxiv_id": "2409.03277v3",
    "title": "ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding",
    "authors": [
      "Zhengzhuo Xu",
      "Bowen Qu",
      "Yiyan Qi",
      "Sinan Du",
      "Chengjin Xu",
      "Chun Yuan",
      "Jian Guo"
    ],
    "abstract": "Automatic chart understanding is crucial for content comprehension and\ndocument parsing. Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities in chart understanding through domain-specific\nalignment and fine-tuning. However, current MLLMs still struggle to provide\nfaithful data and reliable analysis only based on charts. To address it, we\npropose ChartMoE, which employs the Mixture of Expert (MoE) architecture to\nreplace the traditional linear projector to bridge the modality gap.\nSpecifically, we train several linear connectors through distinct alignment\ntasks, which are utilized as the foundational initialization parameters for\ndifferent experts. Additionally, we introduce ChartMoE-Align, a dataset with\nnearly 1 million chart-table-JSON-code quadruples to conduct three alignment\ntasks (chart-table/JSON/code). Combined with the vanilla connector, we\ninitialize different experts diversely and adopt high-quality knowledge\nlearning to further refine the MoE connector and LLM parameters. Extensive\nexperiments demonstrate the effectiveness of the MoE connector and our\ninitialization strategy, e.g., ChartMoE improves the accuracy of the previous\nstate-of-the-art from 80.48\\% to 84.64\\% on the ChartQA benchmark.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03277v3",
    "published_date": "2024-09-05 06:41:02 UTC",
    "updated_date": "2025-03-14 03:19:00 UTC"
  },
  {
    "arxiv_id": "2409.03274v3",
    "title": "Recent Advances in Attack and Defense Approaches of Large Language Models",
    "authors": [
      "Jing Cui",
      "Yishi Xu",
      "Zhewei Huang",
      "Shuchang Zhou",
      "Jianbin Jiao",
      "Junge Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence and\nmachine learning through their advanced text processing and generating\ncapabilities. However, their widespread deployment has raised significant\nsafety and reliability concerns. Established vulnerabilities in deep neural\nnetworks, coupled with emerging threat models, may compromise security\nevaluations and create a false sense of security. Given the extensive research\nin the field of LLM security, we believe that summarizing the current state of\naffairs will help the research community better understand the present\nlandscape and inform future developments. This paper reviews current research\non LLM vulnerabilities and threats, and evaluates the effectiveness of\ncontemporary defense mechanisms. We analyze recent studies on attack vectors\nand model weaknesses, providing insights into attack mechanisms and the\nevolving threat landscape. We also examine current defense strategies,\nhighlighting their strengths and limitations. By contrasting advancements in\nattack and defense methodologies, we identify research gaps and propose future\ndirections to enhance LLM security. Our goal is to advance the understanding of\nLLM safety challenges and guide the development of more robust security\nmeasures.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03274v3",
    "published_date": "2024-09-05 06:31:37 UTC",
    "updated_date": "2024-12-02 08:53:40 UTC"
  },
  {
    "arxiv_id": "2409.03271v1",
    "title": "Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation",
    "authors": [
      "Yu Wang",
      "Shiwan Zhao",
      "Zhihu Wang",
      "Heyuan Huang",
      "Ming Fan",
      "Yubo Zhang",
      "Zhixing Wang",
      "Haijun Wang",
      "Ting Liu"
    ],
    "abstract": "The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for\nenhancing the reasoning capabilities of large language models (LLMs). However,\ndespite their widespread adoption and success, CoT methods often exhibit\ninstability due to their inability to consistently ensure the quality of\ngenerated reasoning paths, leading to sub-optimal reasoning performance. To\naddress this challenge, we propose the \\textbf{Strategic Chain-of-Thought}\n(SCoT), a novel methodology designed to refine LLM performance by integrating\nstrategic knowledge prior to generating intermediate reasoning steps. SCoT\nemploys a two-stage approach within a single prompt: first eliciting an\neffective problem-solving strategy, which is then used to guide the generation\nof high-quality CoT paths and final answers. Our experiments across eight\nchallenging reasoning datasets demonstrate significant improvements, including\na 21.05\\% increase on the GSM8K dataset and 24.13\\% on the Tracking\\_Objects\ndataset, respectively, using the Llama3-8b model. Additionally, we extend the\nSCoT framework to develop a few-shot method with automatically matched\ndemonstrations, yielding even stronger results. These findings underscore the\nefficacy of SCoT, highlighting its potential to substantially enhance LLM\nperformance in complex reasoning tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03271v1",
    "published_date": "2024-09-05 06:28:05 UTC",
    "updated_date": "2024-09-05 06:28:05 UTC"
  },
  {
    "arxiv_id": "2409.13701v2",
    "title": "CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat Interaction",
    "authors": [
      "Minghao Liu",
      "Mingxiu Sui",
      "Yi Nan",
      "Cangqing Wang",
      "Zhijie Zhou"
    ],
    "abstract": "Effective communication in automated chat systems hinges on the ability to\nunderstand and respond to context. Traditional models often struggle with\ndetermining when additional context is necessary for generating appropriate\nresponses. This paper introduces Context-Aware BERT (CA-BERT), a\ntransformer-based model specifically fine-tuned to address this challenge.\nCA-BERT innovatively applies deep learning techniques to discern context\nnecessity in multi-turn chat interactions, enhancing both the relevance and\naccuracy of responses.\n  We describe the development of CA-BERT, which adapts the robust architecture\nof BERT with a novel training regimen focused on a specialized dataset of chat\ndialogues. The model is evaluated on its ability to classify context necessity,\ndemonstrating superior performance over baseline BERT models in terms of\naccuracy and efficiency. Furthermore, CA-BERT's implementation showcases\nsignificant reductions in training time and resource usage, making it feasible\nfor real-time applications.\n  The results indicate that CA-BERT can effectively enhance the functionality\nof chatbots by providing a nuanced understanding of context, thereby improving\nuser experience and interaction quality in automated systems. This study not\nonly advances the field of NLP in chat applications but also provides a\nframework for future research into context-sensitive AI developments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by ICBASE 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.13701v2",
    "published_date": "2024-09-05 06:27:59 UTC",
    "updated_date": "2024-10-01 20:45:26 UTC"
  },
  {
    "arxiv_id": "2409.03261v1",
    "title": "Bones Can't Be Triangles: Accurate and Efficient Vertebrae Keypoint Estimation through Collaborative Error Revision",
    "authors": [
      "Jinhee Kim",
      "Taesung Kim",
      "Jaegul Choo"
    ],
    "abstract": "Recent advances in interactive keypoint estimation methods have enhanced\naccuracy while minimizing user intervention. However, these methods require\nuser input for error correction, which can be costly in vertebrae keypoint\nestimation where inaccurate keypoints are densely clustered or overlap. We\nintroduce a novel approach, KeyBot, specifically designed to identify and\ncorrect significant and typical errors in existing models, akin to user\nrevision. By characterizing typical error types and using simulated errors for\ntraining, KeyBot effectively corrects these errors and significantly reduces\nuser workload. Comprehensive quantitative and qualitative evaluations on three\npublic datasets confirm that KeyBot significantly outperforms existing methods,\nachieving state-of-the-art performance in interactive vertebrae keypoint\nestimation. The source code and demo video are available at:\nhttps://ts-kim.github.io/KeyBot/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, ECCV 2024, Project Page: https://ts-kim.github.io/KeyBot/",
    "pdf_url": "http://arxiv.org/pdf/2409.03261v1",
    "published_date": "2024-09-05 06:03:52 UTC",
    "updated_date": "2024-09-05 06:03:52 UTC"
  },
  {
    "arxiv_id": "2409.03260v2",
    "title": "In Search of Trees: Decision-Tree Policy Synthesis for Black-Box Systems via Search",
    "authors": [
      "Emir Demirović",
      "Christian Schilling",
      "Anna Lukina"
    ],
    "abstract": "Decision trees, owing to their interpretability, are attractive as control\npolicies for (dynamical) systems. Unfortunately, constructing, or synthesising,\nsuch policies is a challenging task. Previous approaches do so by imitating a\nneural-network policy, approximating a tabular policy obtained via formal\nsynthesis, employing reinforcement learning, or modelling the problem as a\nmixed-integer linear program. However, these works may require access to a\nhard-to-obtain accurate policy or a formal model of the environment (within\nreach of formal synthesis), and may not provide guarantees on the quality or\nsize of the final tree policy. In contrast, we present an approach to\nsynthesise optimal decision-tree policies given a deterministic black-box\nenvironment and specification, a discretisation of the tree predicates, and an\ninitial set of states, where optimality is defined with respect to the number\nof steps to achieve the goal. Our approach is a specialised search algorithm\nwhich systematically explores the (exponentially large) space of decision trees\nunder the given discretisation. The key component is a novel trace-based\npruning mechanism that significantly reduces the search space. Our approach\nrepresents a conceptually novel way of synthesising small decision-tree\npolicies with optimality guarantees even for black-box environments with\nblack-box specifications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages main text incl. references, 2 pages appendix",
    "pdf_url": "http://arxiv.org/pdf/2409.03260v2",
    "published_date": "2024-09-05 05:51:42 UTC",
    "updated_date": "2025-01-07 11:54:58 UTC"
  },
  {
    "arxiv_id": "2409.03257v3",
    "title": "Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard",
    "authors": [
      "Chanjun Park",
      "Hyeonwoo Kim"
    ],
    "abstract": "This paper conducts a longitudinal study over eleven months to address the\nlimitations of prior research on the Open Ko-LLM Leaderboard, which have relied\non empirical studies with restricted observation periods of only five months.\nBy extending the analysis duration, we aim to provide a more comprehensive\nunderstanding of the progression in developing Korean large language models\n(LLMs). Our study is guided by three primary research questions: (1) What are\nthe specific challenges in improving LLM performance across diverse tasks on\nthe Open Ko-LLM Leaderboard over time? (2) How does model size impact task\nperformance correlations across various benchmarks? (3) How have the patterns\nin leaderboard rankings shifted over time on the Open Ko-LLM Leaderboard?. By\nanalyzing 1,769 models over this period, our research offers a comprehensive\nexamination of the ongoing advancements in LLMs and the evolving nature of\nevaluation frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Industry",
    "pdf_url": "http://arxiv.org/pdf/2409.03257v3",
    "published_date": "2024-09-05 05:31:29 UTC",
    "updated_date": "2025-03-04 01:21:18 UTC"
  },
  {
    "arxiv_id": "2409.03256v2",
    "title": "E2CL: Exploration-based Error Correction Learning for Embodied Agents",
    "authors": [
      "Hanlin Wang",
      "Chak Tou Leong",
      "Jian Wang",
      "Wenjie Li"
    ],
    "abstract": "Language models are exhibiting increasing capability in knowledge utilization\nand reasoning. However, when applied as agents in embodied environments, they\noften suffer from misalignment between their intrinsic knowledge and\nenvironmental knowledge, leading to infeasible actions. Traditional environment\nalignment methods, such as supervised learning on expert trajectories and\nreinforcement learning, encounter limitations in covering environmental\nknowledge and achieving efficient convergence, respectively. Inspired by human\nlearning, we propose Exploration-based Error Correction Learning (E2CL), a\nnovel framework that leverages exploration-induced errors and environmental\nfeedback to enhance environment alignment for embodied agents. E2CL\nincorporates teacher-guided and teacher-free explorations to gather\nenvironmental feedback and correct erroneous actions. The agent learns to\nprovide feedback and self-correct, thereby enhancing its adaptability to target\nenvironments. Extensive experiments in the VirtualHome environment demonstrate\nthat E2CL-trained agents outperform those trained by baseline methods and\nexhibit superior self-correction capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.03256v2",
    "published_date": "2024-09-05 05:22:27 UTC",
    "updated_date": "2024-09-29 06:00:09 UTC"
  },
  {
    "arxiv_id": "2409.03254v1",
    "title": "Granular-ball Representation Learning for Deep CNN on Learning with Label Noise",
    "authors": [
      "Dawei Dai",
      "Hao Zhu",
      "Shuyin Xia",
      "Guoyin Wang"
    ],
    "abstract": "In actual scenarios, whether manually or automatically annotated, label noise\nis inevitably generated in the training data, which can affect the\neffectiveness of deep CNN models. The popular solutions require data cleaning\nor designing additional optimizations to punish the data with mislabeled data,\nthereby enhancing the robustness of models. However, these methods come at the\ncost of weakening or even losing some data during the training process. As we\nknow, content is the inherent attribute of an image that does not change with\nchanges in annotations. In this study, we propose a general granular-ball\ncomputing (GBC) module that can be embedded into a CNN model, where the\nclassifier finally predicts the label of granular-ball ($gb$) samples instead\nof each individual samples. Specifically, considering the classification task:\n(1) in forward process, we split the input samples as $gb$ samples at\nfeature-level, each of which can correspond to multiple samples with varying\nnumbers and share one single label; (2) during the backpropagation process, we\nmodify the gradient allocation strategy of the GBC module to enable it to\npropagate normally; and (3) we develop an experience replay policy to ensure\nthe stability of the training process. Experiments demonstrate that the\nproposed method can improve the robustness of CNN models with no additional\ndata or optimization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03254v1",
    "published_date": "2024-09-05 05:18:31 UTC",
    "updated_date": "2024-09-05 05:18:31 UTC"
  },
  {
    "arxiv_id": "2409.03239v1",
    "title": "DiffGrad for Physics-Informed Neural Networks",
    "authors": [
      "Jamshaid Ul Rahman",
      "Nimra"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) are regarded as state-of-the-art\ntools for addressing highly nonlinear problems based on partial differential\nequations. Despite their broad range of applications, PINNs encounter several\nperformance challenges, including issues related to efficiency, minimization of\ncomputational cost, and enhancement of accuracy. Burgers' equation, a\nfundamental equation in fluid dynamics that is extensively used in PINNs,\nprovides flexible results with the Adam optimizer that does not account for\npast gradients. This paper introduces a novel strategy for solving Burgers'\nequation by incorporating DiffGrad with PINNs, a method that leverages the\ndifference between current and immediately preceding gradients to enhance\nperformance. A comprehensive computational analysis is conducted using\noptimizers such as Adam, Adamax, RMSprop, and DiffGrad to evaluate and compare\ntheir effectiveness. Our approach includes visualizing the solutions over space\nat various time intervals to demonstrate the accuracy of the network. The\nresults show that DiffGrad not only improves the accuracy of the solution but\nalso reduces training time compared to the other optimizers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.03239v1",
    "published_date": "2024-09-05 04:39:35 UTC",
    "updated_date": "2024-09-05 04:39:35 UTC"
  },
  {
    "arxiv_id": "2409.03219v1",
    "title": "Content Moderation by LLM: From Accuracy to Legitimacy",
    "authors": [
      "Tao Huang"
    ],
    "abstract": "One trending application of LLM (large language model) is to use it for\ncontent moderation in online platforms. Most current studies on this\napplication have focused on the metric of accuracy - the extent to which LLM\nmakes correct decisions about content. This article argues that accuracy is\ninsufficient and misleading, because it fails to grasp the distinction between\neasy cases and hard cases as well as the inevitable trade-offs in achieving\nhigher accuracy. Closer examination reveals that content moderation is a\nconstitutive part of platform governance, the key of which is to gain and\nenhance legitimacy. Instead of making moderation decisions correct, the chief\ngoal of LLM is to make them legitimate. In this regard, this article proposes a\nparadigm shift from the single benchmark of accuracy towards a legitimacy-based\nframework of evaluating the performance of LLM moderators. The framework\nsuggests that for easy cases, the key is to ensure accuracy, speed and\ntransparency, while for hard cases, what matters is reasoned justification and\nuser participation. Examined under this framework, LLM's real potential in\nmoderation is not accuracy improvement. Rather, LLM can better contribute in\nfour other aspects: to conduct screening of hard cases from easy cases, to\nprovide quality explanations for moderation decisions, to assist human\nreviewers in getting more contextual information, and to facilitate user\nparticipation in a more interactive way. Using normative theories from law and\nsocial sciences to critically assess the new technological application, this\narticle seeks to redefine LLM's role in content moderation and redirect\nrelevant research in this field.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03219v1",
    "published_date": "2024-09-05 03:33:54 UTC",
    "updated_date": "2024-09-05 03:33:54 UTC"
  },
  {
    "arxiv_id": "2409.03215v1",
    "title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems",
    "authors": [
      "Jianguo Zhang",
      "Tian Lan",
      "Ming Zhu",
      "Zuxin Liu",
      "Thai Hoang",
      "Shirley Kokane",
      "Weiran Yao",
      "Juntao Tan",
      "Akshara Prabhakar",
      "Haolin Chen",
      "Zhiwei Liu",
      "Yihao Feng",
      "Tulika Awalgaonkar",
      "Rithesh Murthy",
      "Eric Hu",
      "Zeyuan Chen",
      "Ran Xu",
      "Juan Carlos Niebles",
      "Shelby Heinecke",
      "Huan Wang",
      "Silvio Savarese",
      "Caiming Xiong"
    ],
    "abstract": "Autonomous agents powered by large language models (LLMs) have attracted\nsignificant research interest. However, the open-source community faces many\nchallenges in developing specialized models for agent tasks, driven by the\nscarcity of high-quality agent datasets and the absence of standard protocols\nin this area. We introduce and publicly release xLAM, a series of large action\nmodels designed for AI agent tasks. The xLAM series includes five models with\nboth dense and mixture-of-expert architectures, ranging from 1B to 8x22B\nparameters, trained using a scalable, flexible pipeline that unifies, augments,\nand synthesizes diverse datasets to enhance AI agents' generalizability and\nperformance across varied environments. Our experimental results demonstrate\nthat xLAM consistently delivers exceptional performance across multiple agent\nability benchmarks, notably securing the 1st position on the Berkeley\nFunction-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other\nmodels in terms of tool use. By releasing the xLAM series, we aim to advance\nthe performance of open-source LLMs for autonomous AI agents, potentially\naccelerating progress and democratizing access to high-performance models for\nagent tasks. Models are available at\nhttps://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical report for the Salesforce xLAM model series",
    "pdf_url": "http://arxiv.org/pdf/2409.03215v1",
    "published_date": "2024-09-05 03:22:22 UTC",
    "updated_date": "2024-09-05 03:22:22 UTC"
  },
  {
    "arxiv_id": "2409.03206v1",
    "title": "TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations",
    "authors": [
      "Mingze Gao",
      "Jingyu Liu",
      "Mingda Li",
      "Jiangtao Xie",
      "Qingbin Liu",
      "Bo Zhao",
      "Xi Chen",
      "Hui Xiong"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have significantly improved\nperformance across various image-language applications. Recently, there has\nbeen a growing interest in adapting image pre-trained MLLMs for video-related\ntasks. However, most efforts concentrate on enhancing the vision encoder and\nprojector components, while the core part, Large Language Models (LLMs),\nremains comparatively under-explored. In this paper, we propose two strategies\nto enhance the model's capability in video understanding tasks by improving\ninter-layer attention computation in LLMs. Specifically, the first approach\nfocuses on the enhancement of Rotary Position Embedding (RoPE) with\nTemporal-Aware Dual RoPE, which introduces temporal position information to\nstrengthen the MLLM's temporal modeling capabilities while preserving the\nrelative position relationships of both visual and text tokens. The second\napproach involves enhancing the Attention Mask with the Frame-wise Block Causal\nAttention Mask, a simple yet effective method that broadens visual token\ninteractions within and across video frames while maintaining the causal\ninference mechanism. Based on these proposed methods, we adapt LLaVA for video\nunderstanding tasks, naming it Temporal-Considered LLaVA (TC-LLaVA). Our\nTC-LLaVA achieves new state-of-the-art performance across various video\nunderstanding benchmarks with only supervised fine-tuning (SFT) on\nvideo-related datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03206v1",
    "published_date": "2024-09-05 02:54:17 UTC",
    "updated_date": "2024-09-05 02:54:17 UTC"
  },
  {
    "arxiv_id": "2409.03203v2",
    "title": "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification",
    "authors": [
      "Zhuowei Chen",
      "Lianxi Wang",
      "Yuben Wu",
      "Xinfeng Liao",
      "Yujia Tian",
      "Junyang Zhong"
    ],
    "abstract": "Sentiment classification (SC) often suffers from low-resource challenges such\nas domain-specific contexts, imbalanced label distributions, and few-shot\nscenarios. The potential of the diffusion language model (LM) for textual data\naugmentation (DA) remains unexplored, moreover, textual DA methods struggle to\nbalance the diversity and consistency of new samples. Most DA methods either\nperform logical modifications or rephrase less important tokens in the original\nsequence with the language model. In the context of SC, strong emotional tokens\ncould act critically on the sentiment of the whole sequence. Therefore,\ncontrary to rephrasing less important context, we propose DiffusionCLS to\nleverage a diffusion LM to capture in-domain knowledge and generate pseudo\nsamples by reconstructing strong label-related tokens. This approach ensures a\nbalance between consistency and diversity, avoiding the introduction of noise\nand augmenting crucial features of datasets. DiffusionCLS also comprises a\nNoise-Resistant Training objective to help the model generalize. Experiments\ndemonstrate the effectiveness of our method in various low-resource scenarios\nincluding domain-specific and domain-general problems. Ablation studies confirm\nthe effectiveness of our framework's modules, and visualization studies\nhighlight optimal deployment conditions, reinforcing our conclusions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03203v2",
    "published_date": "2024-09-05 02:51:28 UTC",
    "updated_date": "2024-09-23 12:39:34 UTC"
  },
  {
    "arxiv_id": "2409.13700v1",
    "title": "MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation",
    "authors": [
      "Yuqian Wu",
      "Yuhong Peng",
      "Jiapeng Yu",
      "Raymond S. T. Lee"
    ],
    "abstract": "LLM-based Multi-Agent Systems have potential benefits of complex\ndecision-making tasks management across various domains but their applications\nin the next Point-of-Interest (POI) recommendation remain underexplored. This\npaper proposes a novel MAS4POI system designed to enhance next POI\nrecommendations through multi-agent interactions. MAS4POI supports Large\nLanguage Models (LLMs) specializing in distinct agents such as DataAgent,\nManager, Analyst, and Navigator with each contributes to a collaborative\nprocess of generating the next POI recommendations.The system is examined by\nintegrating six distinct LLMs and evaluated by two real-world datasets for\nrecommendation accuracy improvement in real-world scenarios. Our code is\navailable at https://github.com/yuqian2003/MAS4POI.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.13700v1",
    "published_date": "2024-09-05 02:47:49 UTC",
    "updated_date": "2024-09-05 02:47:49 UTC"
  },
  {
    "arxiv_id": "2409.03183v1",
    "title": "Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers",
    "authors": [
      "Zuquan Peng",
      "Yuanyuan He",
      "Jianbing Ni",
      "Ben Niu"
    ],
    "abstract": "Neural networks (NN) classification models for Natural Language Processing\n(NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that\ntriggers a model to produce a specific prediction for any input. DARCY borrows\nthe \"honeypot\" concept to bait multiple trapdoors, effectively detecting the\nadversarial examples generated by UAT. Unfortunately, we find a new UAT\ngeneration method, called IndisUAT, which produces triggers (i.e., tokens) and\nuses them to craft adversarial examples whose feature distribution is\nindistinguishable from that of the benign examples in a randomly-chosen\ncategory at the detection layer of DARCY. The produced adversarial examples\nincur the maximal loss of predicting results in the DARCY-protected models.\nMeanwhile, the produced triggers are effective in black-box models for text\ngeneration, text inference, and reading comprehension. Finally, the evaluation\nresults under NN models for NLP tasks indicate that the IndisUAT method can\neffectively circumvent DARCY and penetrate other defenses. For example,\nIndisUAT can reduce the true positive rate of DARCY's detection by at least\n40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN\nand CNN models, respectively. IndisUAT reduces the accuracy of the BERT's\nadversarial defense model by at least 34.0%, and makes the GPT-2 language model\nspew racist outputs even when conditioned on non-racial context.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.03183v1",
    "published_date": "2024-09-05 02:19:34 UTC",
    "updated_date": "2024-09-05 02:19:34 UTC"
  },
  {
    "arxiv_id": "2409.03167v2",
    "title": "InfraLib: Enabling Reinforcement Learning and Decision-Making for Large-Scale Infrastructure Management",
    "authors": [
      "Pranay Thangeda",
      "Trevor S. Betz",
      "Michael N. Grussing",
      "Melkior Ornik"
    ],
    "abstract": "Efficient management of infrastructure systems is crucial for economic\nstability, sustainability, and public safety. However, infrastructure\nsustainment is challenging due to the vast scale of systems, stochastic\ndeterioration of components, partial observability, and resource constraints.\nDecision-making strategies that rely solely on human judgment often result in\nsuboptimal decisions over large scales and long horizons. While data-driven\napproaches like reinforcement learning offer promising solutions, their\napplication has been limited by the lack of suitable simulation environments.\nWe present InfraLib, an open-source modular and extensible framework that\nenables modeling and analyzing infrastructure management problems with resource\nconstraints as sequential decision-making problems. The framework implements\nhierarchical, stochastic deterioration models, supports realistic partial\nobservability, and handles practical constraints including cyclical budgets and\ncomponent unavailability. InfraLib provides standardized environments for\nbenchmarking decision-making approaches, along with tools for expert data\ncollection and policy evaluation. Through case studies on both synthetic\nbenchmarks and real-world road networks, we demonstrate InfraLib's ability to\nmodel diverse infrastructure management scenarios while maintaining\ncomputational efficiency at scale.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated preprint under active review",
    "pdf_url": "http://arxiv.org/pdf/2409.03167v2",
    "published_date": "2024-09-05 01:54:29 UTC",
    "updated_date": "2024-12-16 20:32:49 UTC"
  },
  {
    "arxiv_id": "2409.03166v2",
    "title": "Continual Skill and Task Learning via Dialogue",
    "authors": [
      "Weiwei Gu",
      "Suresh Kondepudi",
      "Lixiao Huang",
      "Nakul Gopalan"
    ],
    "abstract": "Continual and interactive robot learning is a challenging problem as the\nrobot is present with human users who expect the robot to learn novel skills to\nsolve novel tasks perpetually with sample efficiency. In this work we present a\nframework for robots to query and learn visuo-motor robot skills and task\nrelevant information via natural language dialog interactions with human users.\nPrevious approaches either focus on improving the performance of instruction\nfollowing agents, or passively learn novel skills or concepts. Instead, we used\ndialog combined with a language-skill grounding embedding to query or confirm\nskills and/or tasks requested by a user. To achieve this goal, we developed and\nintegrated three different components for our agent. Firstly, we propose a\nnovel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA),\nwhich enables the existing SoTA ACT model to perform few-shot continual\nlearning. Secondly, we develop an alignment model that projects demonstrations\nacross skill embodiments into a shared embedding allowing us to know when to\nask questions and/or demonstrations from users. Finally, we integrated an\nexisting LLM to interact with a human user to perform grounded interactive\ncontinual skill learning to solve a task. Our ACT-LoRA model learns novel\nfine-tuned skills with a 100% accuracy when trained with only five\ndemonstrations for a novel skill while still maintaining a 74.75% accuracy on\npre-trained skills in the RLBench dataset where other models fall significantly\nshort. We also performed a human-subjects study with 8 subjects to demonstrate\nthe continual learning capabilities of our combined framework. We achieve a\nsuccess rate of 75% in the task of sandwich making with the real robot learning\nfrom participant data demonstrating that robots can learn novel skills or task\nknowledge from dialogue with non-expert users using our approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03166v2",
    "published_date": "2024-09-05 01:51:54 UTC",
    "updated_date": "2024-09-11 21:52:22 UTC"
  },
  {
    "arxiv_id": "2409.03155v1",
    "title": "Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models",
    "authors": [
      "Jie Ma",
      "Zhitao Gao",
      "Qi Chai",
      "Wangchun Sun",
      "Pinghui Wang",
      "Hongbin Pei",
      "Jing Tao",
      "Lingyun Song",
      "Jun Liu",
      "Chen Zhang",
      "Lizhen Cui"
    ],
    "abstract": "Large Language Models (LLMs) may suffer from hallucinations in real-world\napplications due to the lack of relevant knowledge. In contrast, knowledge\ngraphs encompass extensive, multi-relational structures that store a vast array\nof symbolic facts. Consequently, integrating LLMs with knowledge graphs has\nbeen extensively explored, with Knowledge Graph Question Answering (KGQA)\nserving as a critical touchstone for the integration. This task requires LLMs\nto answer natural language questions by retrieving relevant triples from\nknowledge graphs. However, existing methods face two significant challenges:\n\\textit{excessively long reasoning paths distracting from the answer\ngeneration}, and \\textit{false-positive relations hindering the path\nrefinement}. In this paper, we propose an iterative interactive KGQA framework\nthat leverages the interactive learning capabilities of LLMs to perform\nreasoning and Debating over Graphs (DoG). Specifically, DoG employs a\nsubgraph-focusing mechanism, allowing LLMs to perform answer trying after each\nreasoning step, thereby mitigating the impact of lengthy reasoning paths. On\nthe other hand, DoG utilizes a multi-role debate team to gradually simplify\ncomplex questions, reducing the influence of false-positive relations. This\ndebate mechanism ensures the reliability of the reasoning process. Experimental\nresults on five public datasets demonstrate the effectiveness and superiority\nof our architecture. Notably, DoG outperforms the state-of-the-art method ToG\nby 23.7\\% and 9.1\\% in accuracy on WebQuestions and GrailQA, respectively.\nFurthermore, the integration experiments with various LLMs on the mentioned\ndatasets highlight the flexibility of DoG. Code is available at\n\\url{https://github.com/reml-group/DoG}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.03155v1",
    "published_date": "2024-09-05 01:11:58 UTC",
    "updated_date": "2024-09-05 01:11:58 UTC"
  },
  {
    "arxiv_id": "2409.03147v1",
    "title": "Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning",
    "authors": [
      "Juan A. Berrios Moya"
    ],
    "abstract": "The rapid global aging trend has led to an increase in dementia cases,\nincluding Alzheimer's disease, underscoring the urgent need for early and\naccurate diagnostic methods. Traditional diagnostic techniques, such as\ncognitive tests, neuroimaging, and biomarker analysis, face significant\nlimitations in sensitivity, accessibility, and cost, particularly in the early\nstages. This study explores the potential of machine learning (ML) as a\ntransformative approach to enhance early dementia detection by leveraging ML\nmodels to analyze and integrate complex multimodal datasets, including\ncognitive assessments, neuroimaging, and genetic information. A comprehensive\nreview of existing literature was conducted to evaluate various ML models,\nincluding supervised learning, deep learning, and advanced techniques such as\nensemble learning and transformer models, assessing their accuracy,\ninterpretability, and potential for clinical integration. The findings indicate\nthat while ML models show significant promise in improving diagnostic precision\nand enabling earlier interventions, challenges remain in their\ngeneralizability, interpretability, and ethical deployment. This research\nconcludes by outlining future directions aimed at enhancing the clinical\nutility of ML models in dementia detection, emphasizing interdisciplinary\ncollaboration and ethically sound frameworks to improve early detection and\nintervention strategies for Alzheimer's disease and other forms of dementia.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.03147v1",
    "published_date": "2024-09-05 00:52:59 UTC",
    "updated_date": "2024-09-05 00:52:59 UTC"
  }
]