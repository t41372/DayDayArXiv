{
  "date": "2024-09-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-05 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和 LLM 在任务优化、机器人控制、医疗诊断以及高效计算方面的创新应用，强调模型鲁棒性、可解释性和跨领域扩展；令人印象深刻的包括 Michael J. Black 参与的 HUMOS 项目，以及 LLM 在交通预测和 AI 代理中的突破性工作。\n\n### 重点论文讨论\n我挑选了今天最具话题度和影响力的论文先聊，这些涉及热门领域如 LLM 应用、机器人和医疗 AI，并将相关主题归类。其他论文会快速掠过。\n\n**1. HUMOS: Human Motion Model Conditioned on Body Shape（人体运动模型基于身体形状的条件化）**  \n   作者包括 Michael J. Black，这篇 ECCV'24 接受的论文提出了一种基于身体形状的生成运动模型，使用循环一致性、物理和稳定性约束训练模型，生成更真实、多样化的动作。该方法显著提升了现有模型的真实性和多样性，适用于计算机视觉和图形学应用。\n\n**2. Harnessing LLMs for Cross-City OD Flow Prediction（利用大语言模型进行跨城市 OD 流量预测）**  \n   这篇论文创新地将 LLM 用于交通领域，引入一个框架通过指令微调和语义特征提取，实现城市间 OD 流量的准确预测。实验证明，该方法优于传统模型，在城市规划中具有实际意义。\n\n**3. A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application（深度学习方法量化壁面剪应力：从数值训练到零样本实验应用）**  \n   作者 Steven L. Brunton 参与，这篇工作开发了一个深度学习架构，从湍流速度场预测壁面剪应力，支持零样本实验应用。该方法在工程和航空领域有潜力，提升了流体力学模拟的精度。\n\n**4. Multi-agent Path Finding for Mixed Autonomy Traffic Coordination（多代理路径寻找用于混合自治交通协调）**  \n   这篇论文提出 BK-PBS 算法，利用行为预测模型协调自动和手动车辆路径，减少碰撞并优化延误。在交通和机器人领域，该方法超越基线模型，适用于现实场景。\n\n**5. On the Complexity of Neural Computation in Superposition（神经计算在叠加中的复杂性）**  \n   作者 Micah Adler 和 Nir Shavit 探讨神经网络在叠加中的计算边界，提供首个下界证明和上界构造。该研究揭示神经网络效率的关键，影响 LLM 和 AI 可解释性研究。\n\n**6. Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small（评估开源稀疏自编码器在 GPT-2 Small 事实知识解耦中的性能）**  \n   这篇论文使用 RAVEL 基准测试稀疏自编码器在 LLM 中的知识解耦能力，发现其不如神经元基线。该工作推动了 LLM 机制可解释性的进展。\n\n**7. AI forecasting of higher-order wave modes of spinning binary black hole mergers（AI 预测旋转双黑洞合并的高阶波模态）**  \n   作者 Eliu Huerta 参与，提出一个物理驱动的 Transformer 模型预测黑洞波形，训练效率高，准确性达 99%。这在天体物理学中具有突破性。\n\n**8. Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding（Lexicon3D：探测视觉基础模型在复杂 3D 场景理解中的性能）**  \n   这篇论文评估多种视觉模型在 3D 任务中的表现，强调 DINOv2 的优势。该方法提供新视角，提升了视觉语言模型在 3D 应用中的鲁棒性。\n\n**9. Shared Autonomy with IDA: Interventional Diffusion Assistance（共享自治与 IDA：干预扩散辅助）**  \n   论文引入 IDA 框架，使用扩散模型动态干预机器人控制，实验显示其在模拟和真实环境中提升性能。该创新适用于安全机器人决策。\n\n**10. Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Fold Paralysis（多模态喉镜视频分析辅助声带麻痹诊断）**  \n   这篇医疗 AI 论文开发 MLVAS 系统，通过视频和音频分析检测声带麻痹，精度高达 97%。它在临床诊断中提供可靠工具，提升了自动化水平。\n\n**11. Mpox Screen Lite: AI-Driven On-Device Offline Mpox Screening for Low-Resource African Mpox Emergency Response（Mpox Screen Lite：AI 驱动的离线设备筛查，用于非洲低资源环境下的 Mpox 响应）**  \n   针对公共卫生，该方法使用 YOLOv8 模型实现高精度 Mpox 检测，适用于资源有限地区。该应用在疫情响应中具有实际价值。\n\n其他论文快速掠过，以免占用过多篇幅：\n- **The Role of Generative Systems in Historical Photography Management（生成系统在历史摄影管理中的作用）**：探讨生成模型在文化遗产中的应用，提供转移学习工具。\n- **Parallel AutoRegressive Models for Multi-Agent Combinatorial Optimization（并行自回归模型用于多代理组合优化）**：提出 PARCO 框架，提升多代理任务效率。\n- **How Do Your Code LLMs Perform?（代码 LLM 的性能如何？）**：使用 PlanSearch 算法改善代码生成搜索。\n- **Debiasing Text Safety Classifiers（消除文本安全分类器的偏置）**：通过公平集成减少 LLM 偏置。\n- **DKDM: Data-Free Knowledge Distillation for Diffusion Models（无数据知识蒸馏用于扩散模型）**：实现模型架构无关的知识转移。\n- **Hardware Acceleration of LLMs（LLM 的硬件加速）**：综述 LLM 加速框架，强调性能和能效。\n- **Revolutionizing Database Q&A with Large Language Models（用大语言模型革新数据库问答）**：提出 DQABench 基准，提升 LLM 在数据库中的查询能力。\n- 剩余论文如 LMLT（图像超分辨率）、KAN See In the Dark（低光增强）和 Willingness to Read AI-Generated News（AI 生成新闻接受度）等，贡献在于特定领域优化，但非核心热点，故从简。\n\n今天的 arXiv 展示了 AI 领域的多样创新，LLM 在实际应用中的潜力值得关注。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2409.03944v2",
      "title": "HUMOS: Human Motion Model Conditioned on Body Shape",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Tripathi",
        "Omid Taheri",
        "Christoph Lassner",
        "Michael J. Black",
        "Daniel Holden",
        "Carsten Stoll"
      ],
      "abstract": "Generating realistic human motion is essential for many computer vision and\ngraphics applications. The wide variety of human body shapes and sizes greatly\nimpacts how people move. However, most existing motion models ignore these\ndifferences, relying on a standardized, average body. This leads to uniform\nmotion across different body types, where movements don't match their physical\ncharacteristics, limiting diversity. To solve this, we introduce a new approach\nto develop a generative motion model based on body shape. We show that it's\npossible to train this model using unpaired data by applying cycle consistency,\nintuitive physics, and stability constraints, which capture the relationship\nbetween identity and movement. The resulting model generates diverse,\nphysically plausible, and dynamically stable human motions that are both\nquantitatively and qualitatively more realistic than current state-of-the-art\nmethods. More details are available on our project page\nhttps://CarstenEpic.github.io/humos/.",
      "tldr_zh": "该研究指出，现有的Human Motion Model忽略了人体形状多样性，导致生成动作不真实且缺乏多样性。为解决这一问题，作者提出HUMOS模型，这是一种基于身体形状的生成性动作模型，通过使用未配对数据并应用cycle consistency、intuitive physics和stability constraints来捕捉身份与动作的关系。实验结果显示，HUMOS生成的动作在多样性、物理合理性和动态稳定性上均优于现有最先进方法，且在定量和定性评估中更逼真。更多细节可查阅项目页面https://CarstenEpic.github.io/humos/。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ECCV'24. Project page:\n  https://CarstenEpic.github.io/humos/",
      "pdf_url": "http://arxiv.org/pdf/2409.03944v2",
      "published_date": "2024-09-05 23:50:57 UTC",
      "updated_date": "2025-04-03 07:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:31:53.177805"
    },
    {
      "arxiv_id": "2409.03937v1",
      "title": "Harnessing LLMs for Cross-City OD Flow Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyang Yu",
        "Xinpeng Xie",
        "Yan Huang",
        "Chenxi Qiu"
      ],
      "abstract": "Understanding and predicting Origin-Destination (OD) flows is crucial for\nurban planning and transportation management. Traditional OD prediction models,\nwhile effective within single cities, often face limitations when applied\nacross different cities due to varied traffic conditions, urban layouts, and\nsocio-economic factors. In this paper, by employing Large Language Models\n(LLMs), we introduce a new method for cross-city OD flow prediction. Our\napproach leverages the advanced semantic understanding and contextual learning\ncapabilities of LLMs to bridge the gap between cities with different\ncharacteristics, providing a robust and adaptable solution for accurate OD flow\nprediction that can be transferred from one city to another. Our novel\nframework involves four major components: collecting OD training datasets from\na source city, instruction-tuning the LLMs, predicting destination POIs in a\ntarget city, and identifying the locations that best match the predicted\ndestination POIs. We introduce a new loss function that integrates POI\nsemantics and trip distance during training. By extracting high-quality\nsemantic features from human mobility and POI data, the model understands\nspatial and functional relationships within urban spaces and captures\ninteractions between individuals and various POIs. Extensive experimental\nresults demonstrate the superiority of our approach over the state-of-the-art\nlearning-based methods in cross-city OD flow prediction.",
      "tldr_zh": "该论文提出了一种利用大语言模型（LLMs）进行跨城市原点-目的地（OD）流量预测的方法，以克服传统模型在不同城市间应用时的局限性，如交通条件和城市布局差异。框架包括四个主要组件：从源城市收集OD训练数据集、对LLMs进行指令微调、在目标城市预测目的地兴趣点（POI）、并通过新损失函数整合POI语义和行程距离来识别最佳位置，从而捕捉城市空间关系和个体与POI的互动。实验结果表明，该方法在跨城市OD流量预测中优于现有最先进的学习方法，提供了一个鲁棒且可转移的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.03937v1",
      "published_date": "2024-09-05 23:04:28 UTC",
      "updated_date": "2024-09-05 23:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:32:15.316561"
    },
    {
      "arxiv_id": "2409.03933v1",
      "title": "A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application",
      "title_zh": "一种深度学习方法用于壁面剪应",
      "authors": [
        "Esther Lagemann",
        "Julia Roeb",
        "Steven L. Brunton",
        "Christian Lagemann"
      ],
      "abstract": "The accurate quantification of wall-shear stress dynamics is of substantial\nimportance for various applications in fundamental and applied research,\nspanning areas from human health to aircraft design and optimization. Despite\nsignificant progress in experimental measurement techniques and post-processing\nalgorithms, temporally resolved wall-shear stress dynamics with adequate\nspatial resolution and within a suitable spatial domain remain an elusive goal.\nTo address this gap, we introduce a deep learning architecture that ingests\nwall-parallel velocity fields from the logarithmic layer of turbulent\nwall-bounded flows and outputs the corresponding 2D wall-shear stress fields\nwith identical spatial resolution and domain size. From a physical perspective,\nour framework acts as a surrogate model encapsulating the various mechanisms\nthrough which highly energetic outer-layer flow structures influence the\ngoverning wall-shear stress dynamics. The network is trained in a supervised\nfashion on a unified dataset comprising direct numerical simulations of\nstatistically 1D turbulent channel and spatially developing turbulent boundary\nlayer flows at friction Reynolds numbers ranging from 390 to 1,500. We\ndemonstrate a zero-shot applicability to experimental velocity fields obtained\nfrom Particle-Image Velocimetry measurements and verify the physical accuracy\nof the wall-shear stress estimates with synchronized wall-shear stress\nmeasurements using the Micro-Pillar Shear-Stress Sensor for Reynolds numbers up\nto 2,000. In summary, the presented framework lays the groundwork for\nextracting inaccessible experimental wall-shear stress information from readily\navailable velocity measurements and thus, facilitates advancements in a variety\nof experimental applications.",
      "tldr_zh": "本文提出了一种深度学习方法，用于精确量化壁面剪应力（wall-shear stress），旨在解决传统测量技术在空间分辨率和领域覆盖上的局限性。该框架通过摄取湍流壁边界流的壁面平行速度场，输出对应的2D壁面剪应力场，并采用监督学习在直接数值模拟（direct numerical simulations）数据集上训练，涵盖雷诺数（Reynolds numbers）从390到1,500的通道流和边界层流。实验结果显示，该方法实现了零样本（zero-shot）应用到粒子图像测速（Particle-Image Velocimetry）测量数据中，并通过Micro-Pillar Shear-Stress Sensor验证其物理准确性，直至雷诺数达2,000。该框架为从现有速度测量中提取壁面剪应力信息奠定了基础，促进了健康、航空等领域的研究应用。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03933v1",
      "published_date": "2024-09-05 22:59:23 UTC",
      "updated_date": "2024-09-05 22:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:32:20.218697"
    },
    {
      "arxiv_id": "2409.03911v1",
      "title": "The Role of Generative Systems in Historical Photography Management: A Case Study on Catalan Archives",
      "title_zh": "翻译失败",
      "authors": [
        "Èric Śanchez",
        "Adrià Molina",
        "Oriol Ramos Terrades"
      ],
      "abstract": "The use of image analysis in automated photography management is an\nincreasing trend in heritage institutions. Such tools alleviate the human cost\nassociated with the manual and expensive annotation of new data sources while\nfacilitating fast access to the citizenship through online indexes and search\nengines. However, available tagging and description tools are usually designed\naround modern photographs in English, neglecting historical corpora in\nminoritized languages, each of which exhibits intrinsic particularities. The\nprimary objective of this research is to study the quantitative contribution of\ngenerative systems in the description of historical sources. This is done by\ncontextualizing the task of captioning historical photographs from the Catalan\narchives as a case study. Our findings provide practitioners with tools and\ndirections on transfer learning for captioning models based on visual\nadaptation and linguistic proximity.",
      "tldr_zh": "本研究探讨了生成系统(Generative Systems)在历史摄影管理中的作用，特别针对遗产机构的图像分析工具如何减少手动标注的人力成本并提升在线访问效率。以加泰罗尼亚档案(Catalan Archives)历史照片为案例，研究了生成系统在描述历史语料中的定量贡献。结果显示，现有的标注工具常忽略少数民族语言的特殊性，该研究提供了基于转移学习(Transfer Learning)、视觉适应(Visual Adaptation)和语言接近度(Linguistic Proximity)的模型工具和指导方向，以优化历史照片的描述任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV workshop AI4DH",
      "pdf_url": "http://arxiv.org/pdf/2409.03911v1",
      "published_date": "2024-09-05 21:08:25 UTC",
      "updated_date": "2024-09-05 21:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:32:28.232875"
    },
    {
      "arxiv_id": "2409.03881v1",
      "title": "Multi-agent Path Finding for Mixed Autonomy Traffic Coordination",
      "title_zh": "多智能体路径寻优用于混合自治交通协调",
      "authors": [
        "Han Zheng",
        "Zhongxia Yan",
        "Cathy Wu"
      ],
      "abstract": "In the evolving landscape of urban mobility, the prospective integration of\nConnected and Automated Vehicles (CAVs) with Human-Driven Vehicles (HDVs)\npresents a complex array of challenges and opportunities for autonomous driving\nsystems. While recent advancements in robotics have yielded Multi-Agent Path\nFinding (MAPF) algorithms tailored for agent coordination task characterized by\nsimplified kinematics and complete control over agent behaviors, these\nsolutions are inapplicable in mixed-traffic environments where uncontrollable\nHDVs must coexist and interact with CAVs. Addressing this gap, we propose the\nBehavior Prediction Kinematic Priority Based Search (BK-PBS), which leverages\nan offline-trained conditional prediction model to forecast HDV responses to\nCAV maneuvers, integrating these insights into a Priority Based Search (PBS)\nwhere the A* search proceeds over motion primitives to accommodate kinematic\nconstraints. We compare BK-PBS with CAV planning algorithms derived by\nrule-based car-following models, and reinforcement learning. Through\ncomprehensive simulation on a highway merging scenario across diverse scenarios\nof CAV penetration rate and traffic density, BK-PBS outperforms these baselines\nin reducing collision rates and enhancing system-level travel delay. Our work\nis directly applicable to many scenarios of multi-human multi-robot\ncoordination.",
      "tldr_zh": "本研究针对混合自治交通中 Connected and Automated Vehicles (CAVs) 与 Human-Driven Vehicles (HDVs) 的协调挑战，提出了一种 Multi-Agent Path Finding (MAPF) 改进算法——Behavior Prediction Kinematic Priority Based Search (BK-PBS)。该方法利用离线训练的条件预测模型来预测 HDV 对 CAV 操作的响应，并将其整合到 Priority Based Search (PBS) 中，通过 A* 搜索处理运动学约束，从而实现更有效的路径规划。实验结果显示，在高速公路合并场景的模拟中，BK-PBS 相较于基于规则的车跟随模型和 reinforcement learning 算法，显著降低了碰撞率并优化了系统级旅行延迟，具有广泛的应用潜力于多人类多机器人协调场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03881v1",
      "published_date": "2024-09-05 19:37:01 UTC",
      "updated_date": "2024-09-05 19:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:32:41.225928"
    },
    {
      "arxiv_id": "2409.03874v1",
      "title": "Cost-Control in Display Advertising: Theory vs Practice",
      "title_zh": "展示广告中的成本控制：理论 vs 实践",
      "authors": [
        "Anoop R Katti",
        "Rui C. Gonçalves",
        "Rinchin Iakovlev"
      ],
      "abstract": "In display advertising, advertisers want to achieve a marketing objective\nwith constraints on budget and cost-per-outcome. This is usually formulated as\nan optimization problem that maximizes the total utility under constraints. The\noptimization is carried out in an online fashion in the dual space - for an\nincoming Ad auction, a bid is placed using an optimal bidding formula, assuming\noptimal values for the dual variables; based on the outcome of the previous\nauctions, the dual variables are updated in an online fashion. While this\napproach is theoretically sound, in practice, the dual variables are not\noptimal from the beginning, but rather converge over time. Specifically, for\nthe cost-constraint, the convergence is asymptotic. As a result, we find that\ncost-control is ineffective. In this work, we analyse the shortcomings of the\noptimal bidding formula and propose a modification that deviates from the\ntheoretical derivation. We simulate various practical scenarios and study the\ncost-control behaviors of the two algorithms. Through a large-scale evaluation\non the real-word data, we show that the proposed modification reduces the cost\nviolations by 50%, thereby achieving a better cost-control than the theoretical\nbidding formula.",
      "tldr_zh": "该论文探讨了显示广告中成本控制的理论与实践差异，指出传统优化方法通过双重变量（dual variables）在线更新出价，但由于这些变量的渐进收敛，导致成本约束无法有效执行。作者分析了最优出价公式（optimal bidding formula）的缺点，并提出一种修改算法，以改善实际应用中的成本控制表现。通过模拟场景和真实数据评估，结果显示修改后的算法将成本违规减少了50%，从而提供更可靠的成本管理解决方案。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03874v1",
      "published_date": "2024-09-05 19:22:33 UTC",
      "updated_date": "2024-09-05 19:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:32:52.029825"
    },
    {
      "arxiv_id": "2409.15318v2",
      "title": "On the Complexity of Neural Computation in Superposition",
      "title_zh": "神经计算在叠加中的复杂性",
      "authors": [
        "Micah Adler",
        "Nir Shavit"
      ],
      "abstract": "Superposition, the ability of neural networks to represent more features than\nneurons, is increasingly seen as key to the efficiency of large models. This\npaper investigates the theoretical foundations of computing in superposition,\nestablishing complexity bounds for explicit, provably correct algorithms.\n  We present the first lower bounds for a neural network computing in\nsuperposition, showing that for a broad class of problems, including\npermutations and pairwise logical operations, computing $m'$ features in\nsuperposition requires at least $\\Omega(\\sqrt{m' \\log m'})$ neurons and\n$\\Omega(m' \\log m')$ parameters. This implies the first subexponential upper\nbound on superposition capacity: a network with $n$ neurons can compute at most\n$O(n^2 / \\log n)$ features. Conversely, we provide a nearly tight constructive\nupper bound: logical operations like pairwise AND can be computed using\n$O(\\sqrt{m'} \\log m')$ neurons and $O(m' \\log^2 m')$ parameters. There is thus\nan exponential gap between the complexity of computing in superposition (the\nsubject of this work) versus merely representing features, which can require as\nlittle as $O(\\log m')$ neurons based on the Johnson-Lindenstrauss Lemma.\n  Our hope is that our results open a path for using complexity theoretic\ntechniques in neural network interpretability research.",
      "tldr_zh": "这篇论文探讨了神经网络在 superposition 中的计算复杂性，强调了这种机制对模型效率的关键作用。研究者首次建立了计算在 superposition 的下界（lower bounds），证明对于如排列和成对逻辑操作等问题，计算 m' 个特征至少需要 Ω(√(m' log m')) 个神经元和 Ω(m' log m') 个参数。论文同时给出了上界（upper bound），即一个有 n 个神经元的网络最多能计算 O(n^2 / log n) 个特征，并通过构造性方法展示了成对逻辑操作可使用 O(√(m') log m') 个神经元实现。总体结果揭示了计算在 superposition 与单纯特征表示（如基于 Johnson-Lindenstrauss Lemma 的 O(log m') 个神经元）之间的指数级差距，为神经网络可解释性研究引入了复杂度理论工具。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.DS",
        "cs.NE",
        "F.1.1; F.2.2; I.2.m; E.3"
      ],
      "primary_category": "cs.CC",
      "comment": "32 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15318v2",
      "published_date": "2024-09-05 18:58:59 UTC",
      "updated_date": "2025-04-18 18:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:33:06.879947"
    },
    {
      "arxiv_id": "2409.03844v1",
      "title": "MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene Experiences With Ambient Awareness And Personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxuan Liu",
        "Zihao Wang",
        "Haorong Hong",
        "Youwei Feng",
        "Jiaxin Yu",
        "Han Diao",
        "Yunfei Xu",
        "Kejun Zhang"
      ],
      "abstract": "This paper introduces MetaBGM, a groundbreaking framework for generating\nbackground music that adapts to dynamic scenes and real-time user interactions.\nWe define multi-scene as variations in environmental contexts, such as\ntransitions in game settings or movie scenes. To tackle the challenge of\nconverting backend data into music description texts for audio generation\nmodels, MetaBGM employs a novel two-stage generation approach that transforms\ncontinuous scene and user state data into these texts, which are then fed into\nan audio generation model for real-time soundtrack creation. Experimental\nresults demonstrate that MetaBGM effectively generates contextually relevant\nand dynamic background music for interactive applications.",
      "tldr_zh": "本论文引入了MetaBGM框架，这是一个创新系统，用于生成适应动态场景和实时用户互动的背景音乐，支持多场景环境（如游戏或电影场景转换）并实现环境感知和个性化。MetaBGM采用两阶段生成方法，先将连续的场景和用户状态数据转换为音乐描述文本，然后输入音频生成模型以实现实时音轨创建。实验结果显示，该框架能有效产生与上下文相关的动态背景音乐，提升交互式应用的沉浸感。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03844v1",
      "published_date": "2024-09-05 18:12:11 UTC",
      "updated_date": "2024-09-05 18:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:33:16.972297"
    },
    {
      "arxiv_id": "2409.04478v1",
      "title": "Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small",
      "title_zh": "翻译失败",
      "authors": [
        "Maheep Chaudhary",
        "Atticus Geiger"
      ],
      "abstract": "A popular new method in mechanistic interpretability is to train\nhigh-dimensional sparse autoencoders (SAEs) on neuron activations and use SAE\nfeatures as the atomic units of analysis. However, the body of evidence on\nwhether SAE feature spaces are useful for causal analysis is underdeveloped. In\nthis work, we use the RAVEL benchmark to evaluate whether SAEs trained on\nhidden representations of GPT-2 small have sets of features that separately\nmediate knowledge of which country a city is in and which continent it is in.\nWe evaluate four open-source SAEs for GPT-2 small against each other, with\nneurons serving as a baseline, and linear features learned via distributed\nalignment search (DAS) serving as a skyline. For each, we learn a binary mask\nto select features that will be patched to change the country of a city without\nchanging the continent, or vice versa. Our results show that SAEs struggle to\nreach the neuron baseline, and none come close to the DAS skyline. We release\ncode here: https://github.com/MaheepChaudhary/SAE-Ravel",
      "tldr_zh": "本研究评估了开源稀疏自编码器(SAEs)在GPT-2 Small模型中分离事实知识的能力，焦点是测试SAE特征是否能独立调解城市所属国家(country)和洲(continent)的知识。研究使用RAVEL基准训练SAEs，并通过学习二进制掩码来修改特征，从而比较四个开源SAE、神经元基线和分布式对齐搜索(DAS)的性能。结果显示，SAEs的表现低于神经元基线，且远未达到DAS的水平，表明SAEs在因果分析中的局限性。该工作提供了代码仓库（https://github.com/MaheepChaudhary/SAE-Ravel），以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04478v1",
      "published_date": "2024-09-05 18:00:37 UTC",
      "updated_date": "2024-09-05 18:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:33:30.083997"
    },
    {
      "arxiv_id": "2409.03833v1",
      "title": "AI forecasting of higher-order wave modes of spinning binary black hole mergers",
      "title_zh": "翻译失败",
      "authors": [
        "Victoria Tiki",
        "Kiet Pham",
        "Eliu Huerta"
      ],
      "abstract": "We present a physics-inspired transformer model that predicts the non-linear\ndynamics of higher-order wave modes emitted by quasi-circular, spinning,\nnon-precessing binary black hole mergers. The model forecasts the waveform\nevolution from the pre-merger phase through the ringdown, starting with an\ninput time-series spanning $ t \\in [-5000\\textrm{M}, -100\\textrm{M}) $. The\nmerger event, defined as the peak amplitude of waveforms that include the $l =\n|m| = 2$ modes, occurs at $ t = 0\\textrm{M} $. The transformer then generates\npredictions over the time range $ t \\in [-100\\textrm{M}, 130\\textrm{M}] $. We\nproduced training, evaluation and test sets using the NRHybSur3dq8 model,\nconsidering a signal manifold defined by mass ratios $ q \\in [1, 8] $; spin\ncomponents $ s^z_{\\{1,2\\}} \\in [-0.8, 0.8] $; modes up to $l \\leq 4$, including\nthe $(5,5)$ mode but excluding the $(4,0)$ and $(4,1)$ modes; and inclination\nangles $\\theta \\in [0, \\pi]$. We trained the model on 14,440,761 waveforms,\ncompleting the training in 15 hours using 16 NVIDIA A100 GPUs in the Delta\nsupercomputer. We used 4 H100 GPUs in the DeltaAI supercomputer to compute,\nwithin 7 hours, the overlap between ground truth and predicted waveforms using\na test set of 840,000 waveforms, finding that the mean and median overlaps over\nthe test set are 0.996 and 0.997, respectively. Additionally, we conducted\ninterpretability studies to elucidate the waveform features utilized by our\ntransformer model to produce accurate predictions. The scientific software used\nfor this work is released with this manuscript.",
      "tldr_zh": "本研究提出了一种基于物理启发的Transformer模型，用于预测准圆轨道、旋转、非进动双黑洞合并的高阶波模态非线性动态。该模型以时间序列输入（t ∈ [-5000M, -100M)）为基础，生成从预合并到环绕阶段的波形预测（t ∈ [-100M, 130M]），并使用NRHybSur3dq8模型生成的大规模数据集进行训练，涵盖质量比q ∈ [1, 8]和自旋组件s^z_{1,2} ∈ [-0.8, 0.8]等参数。实验结果显示，模型在测试集的840,000个波形上平均重叠率为0.996，中位数为0.997，同时通过可解释性研究揭示了模型的关键特征，并发布了相关科学软件。",
      "categories": [
        "gr-qc",
        "astro-ph.IM",
        "cs.AI",
        "68T10, 85-08, 83C35, 83C57",
        "I.2"
      ],
      "primary_category": "gr-qc",
      "comment": "27 pages, 1 appendix, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.03833v1",
      "published_date": "2024-09-05 18:00:11 UTC",
      "updated_date": "2024-09-05 18:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:33:43.027227"
    },
    {
      "arxiv_id": "2409.03757v3",
      "title": "Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yunze Man",
        "Shuhong Zheng",
        "Zhipeng Bao",
        "Martial Hebert",
        "Liang-Yan Gui",
        "Yu-Xiong Wang"
      ],
      "abstract": "Complex 3D scene understanding has gained increasing attention, with scene\nencoding strategies playing a crucial role in this success. However, the\noptimal scene encoding strategies for various scenarios remain unclear,\nparticularly compared to their image-based counterparts. To address this issue,\nwe present a comprehensive study that probes various visual encoding models for\n3D scene understanding, identifying the strengths and limitations of each model\nacross different scenarios. Our evaluation spans seven vision foundation\nencoders, including image-based, video-based, and 3D foundation models. We\nevaluate these models in four tasks: Vision-Language Scene Reasoning, Visual\nGrounding, Segmentation, and Registration, each focusing on different aspects\nof scene understanding. Our evaluations yield key findings: DINOv2 demonstrates\nsuperior performance, video models excel in object-level tasks, diffusion\nmodels benefit geometric tasks, and language-pretrained models show unexpected\nlimitations in language-related tasks. These insights challenge some\nconventional understandings, provide novel perspectives on leveraging visual\nfoundation models, and highlight the need for more flexible encoder selection\nin future vision-language and scene-understanding tasks. Code:\nhttps://github.com/YunzeMan/Lexicon3D",
      "tldr_zh": "本研究探讨了视觉基础模型在复杂 3D 场景理解中的表现，通过评估七种编码器（包括基于图像、视频和 3D 的模型）来识别其优缺点。评估涉及四个任务：Vision-Language Scene Reasoning、Visual Grounding、Segmentation 和 Registration。关键发现包括：DINOv2 在整体表现上领先，视频模型在对象级任务中表现出色，扩散模型有益于几何任务，而语言预训练模型在语言相关任务中显示出意外局限性。这些见解挑战了传统观点，并强调未来视觉语言和场景理解任务中需要更灵活的编码器选择。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. Project page: https://yunzeman.github.io/lexicon3d\n  Github: https://github.com/YunzeMan/Lexicon3D",
      "pdf_url": "http://arxiv.org/pdf/2409.03757v3",
      "published_date": "2024-09-05 17:59:56 UTC",
      "updated_date": "2025-05-08 05:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:33:56.877907"
    },
    {
      "arxiv_id": "2409.03753v2",
      "title": "WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Yuntian Deng",
        "Wenting Zhao",
        "Jack Hessel",
        "Xiang Ren",
        "Claire Cardie",
        "Yejin Choi"
      ],
      "abstract": "The increasing availability of real-world conversation data offers exciting\nopportunities for researchers to study user-chatbot interactions. However, the\nsheer volume of this data makes manually examining individual conversations\nimpractical. To overcome this challenge, we introduce WildVis, an interactive\ntool that enables fast, versatile, and large-scale conversation analysis.\nWildVis provides search and visualization capabilities in the text and\nembedding spaces based on a list of criteria. To manage million-scale datasets,\nwe implemented optimizations including search index construction, embedding\nprecomputation and compression, and caching to ensure responsive user\ninteractions within seconds. We demonstrate WildVis' utility through three case\nstudies: facilitating chatbot misuse research, visualizing and comparing topic\ndistributions across datasets, and characterizing user-specific conversation\npatterns. WildVis is open-source and designed to be extendable, supporting\nadditional datasets and customized search and visualization functionalities.",
      "tldr_zh": "本论文引入了WildVis，这是一个开源交互式工具，旨在快速分析百万级真实世界对话数据（chat logs），通过文本和嵌入空间（embedding spaces）的搜索及可视化功能，帮助研究者高效处理用户-聊天机器人互动。WildVis采用优化技术，包括搜索索引构建、嵌入预计算和压缩以及缓存，确保用户交互响应在数秒内完成。研究通过三个案例研究展示了其实用性：促进聊天机器人误用研究、可视化和比较主题分布，以及表征用户特定对话模式。作为开源工具，WildVis支持扩展以添加更多数据集和自定义功能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03753v2",
      "published_date": "2024-09-05 17:59:15 UTC",
      "updated_date": "2024-09-09 10:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:34:08.960910"
    },
    {
      "arxiv_id": "2409.03735v2",
      "title": "Investigating Privacy Bias in Training Data of Language Models",
      "title_zh": "调查语言模型训练数据中的隐私偏差",
      "authors": [
        "Yan Shvartzshnaider",
        "Vasisht Duddu"
      ],
      "abstract": "As LLMs are integrated into sociotechnical systems, it is crucial to examine\nthe privacy biases they exhibit. A privacy bias refers to the skew in the\nappropriateness of information flows within a given context that LLMs acquire\nfrom large amounts of non-publicly available training data. This skew may\neither align with existing expectations or signal a symptom of systemic issues\nreflected in the training datasets.\n  We formulate a novel research question: how can we examine privacy biases in\nthe training data of LLMs? We present a novel approach to assess the privacy\nbiases using a contextual integrity-based methodology to evaluate the responses\nfrom different LLMs. Our approach accounts for the sensitivity of responses\nacross prompt variations, which hinders the evaluation of privacy biases. We\ninvestigate how privacy biases are affected by model capacities and\noptimizations.",
      "tldr_zh": "本研究调查了语言模型（LLMs）的训练数据中存在的隐私偏差（privacy biases），即模型从非公开数据中获取的信息流动不适当性，可能反映系统性问题。研究者提出一个新方法，使用基于上下文完整性（contextual integrity）的评估框架来分析不同 LLMs 的响应，并考虑提示变化对响应敏感性的影响。该方法探讨了模型容量和优化如何影响隐私偏差，为识别和缓解 LLMs 在社会技术系统中的隐私风险提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2409.03735v2",
      "published_date": "2024-09-05 17:50:31 UTC",
      "updated_date": "2025-02-05 12:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:34:22.790151"
    },
    {
      "arxiv_id": "2409.03811v2",
      "title": "Parallel AutoRegressive Models for Multi-Agent Combinatorial Optimization",
      "title_zh": "针对多智能体组合优化的平行自回归模型",
      "authors": [
        "Federico Berto",
        "Chuanbo Hua",
        "Laurin Luttmann",
        "Jiwoo Son",
        "Junyoung Park",
        "Kyuree Ahn",
        "Changhyun Kwon",
        "Lin Xie",
        "Jinkyoo Park"
      ],
      "abstract": "Combinatorial optimization problems involving multiple agents are notoriously\nchallenging due to their NP-hard nature and the necessity for effective agent\ncoordination. Despite advancements in learning-based methods, existing\napproaches often face critical limitations, including suboptimal agent\ncoordination, poor generalizability, and high computational latency. To address\nthese issues, we propose Parallel AutoRegressive Combinatorial Optimization\n(PARCO), a reinforcement learning framework designed to construct high-quality\nsolutions for multi-agent combinatorial tasks efficiently. To this end, PARCO\nintegrates three key components: (1) transformer-based communication layers to\nenable effective agent collaboration during parallel solution construction, (2)\na multiple pointer mechanism for low-latency, parallel agent decision-making,\nand (3) priority-based conflict handlers to resolve decision conflicts via\nlearned priorities. We evaluate PARCO in multi-agent vehicle routing and\nscheduling problems where our approach outperforms state-of-the-art learning\nmethods and demonstrates strong generalization ability and remarkable\ncomputational efficiency. Code available at: https://github.com/ai4co/parco.",
      "tldr_zh": "本研究针对多智能体组合优化问题（如NP-hard任务）提出的挑战，包括代理协调不足、泛化能力差和高计算延迟，引入了Parallel AutoRegressive Combinatorial Optimization (PARCO)框架，这是一种基于强化学习的解决方案。PARCO整合了三个关键组件：transformer-based communication layers以实现代理在并行解决方案构建中的有效协作、multiple pointer mechanism以支持低延迟的并行决策，以及priority-based conflict handlers通过学习优先级解决冲突。实验结果显示，PARCO在多智能体车辆路由和调度问题上优于现有最先进方法，展现出强劲的泛化能力和计算效率。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03811v2",
      "published_date": "2024-09-05 17:49:18 UTC",
      "updated_date": "2025-02-05 09:49:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:34:32.794666"
    },
    {
      "arxiv_id": "2409.03810v1",
      "title": "How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yejie Wang",
        "Keqing He",
        "Dayuan Fu",
        "Zhuoma Gongque",
        "Heyang Xu",
        "Yanxu Chen",
        "Zhexu Wang",
        "Yujia Fu",
        "Guanting Dong",
        "Muxi Diao",
        "Jingang Wang",
        "Mengdi Zhang",
        "Xunliang Cai",
        "Weiran Xu"
      ],
      "abstract": "Recently, there has been a growing interest in studying how to construct\nbetter code instruction tuning data. However, we observe Code models trained\nwith these datasets exhibit high performance on HumanEval but perform worse on\nother benchmarks such as LiveCodeBench. Upon further investigation, we find\nthat many datasets suffer from severe data leakage. After cleaning up most of\nthe leaked data, some well-known high-quality datasets perform poorly. This\ndiscovery reveals a new challenge: identifying which dataset genuinely qualify\nas high-quality code instruction data. To address this, we propose an efficient\ncode data pruning strategy for selecting good samples. Our approach is based on\nthree dimensions: instruction complexity, response quality, and instruction\ndiversity. Based on our selected data, we present XCoder, a family of models\nfinetuned from LLaMA3. Our experiments show XCoder achieves new\nstate-of-the-art performance using fewer training data, which verify the\neffectiveness of our data strategy. Moreover, we perform a comprehensive\nanalysis on the data composition and find existing code datasets have different\ncharacteristics according to their construction methods, which provide new\ninsights for future code LLMs. Our models and dataset are released in\nhttps://github.com/banksy23/XCoder",
      "tldr_zh": "该研究发现，现有的代码指令微调数据集存在严重数据泄露问题，导致模型在 HumanEval 基准上表现良好，但在 LiveCodeBench 等其他基准上表现较差。作者提出了一种高效的数据修剪策略，基于指令复杂性、响应质量和指令多样性三个维度来筛选高质量数据，并据此微调 LLaMA3 模型，开发出 XCoder 系列模型。实验结果表明，XCoder 使用更少的数据就实现了新的最先进性能，同时通过对数据组成的全面分析，提供了未来代码 LLMs 建设的宝贵见解。模型和数据集已开源于 https://github.com/banksy23/XCoder。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2409.03810v1",
      "published_date": "2024-09-05 17:46:30 UTC",
      "updated_date": "2024-09-05 17:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:34:45.207382"
    },
    {
      "arxiv_id": "2409.03733v2",
      "title": "Planning In Natural Language Improves LLM Search For Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Wang",
        "Federico Cassano",
        "Catherine Wu",
        "Yunfeng Bai",
        "Will Song",
        "Vaskar Nath",
        "Ziwen Han",
        "Sean Hendryx",
        "Summer Yue",
        "Hugh Zhang"
      ],
      "abstract": "While scaling training compute has led to remarkable improvements in large\nlanguage models (LLMs), scaling inference compute has not yet yielded analogous\ngains. We hypothesize that a core missing component is a lack of diverse LLM\noutputs, leading to inefficient search due to models repeatedly sampling highly\nsimilar, yet incorrect generations. We empirically demonstrate that this lack\nof diversity can be mitigated by searching over candidate plans for solving a\nproblem in natural language. Based on this insight, we propose PlanSearch, a\nnovel search algorithm which shows strong results across HumanEval+, MBPP+, and\nLiveCodeBench (a contamination-free benchmark for competitive coding).\nPlanSearch generates a diverse set of observations about the problem and then\nuses these observations to construct plans for solving the problem. By\nsearching over plans in natural language rather than directly over code\nsolutions, PlanSearch explores a significantly more diverse range of potential\nsolutions compared to baseline search methods. Using PlanSearch on top of\nClaude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on\nLiveCodeBench, outperforming both the best score achieved without search\n(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).\nFinally, we show that, across all models, search algorithms, and benchmarks\nanalyzed, we can accurately predict performance gains due to search as a direct\nfunction of the diversity over generated ideas. Code can be found at\nhttps://github.com/scaleapi/plansearch.",
      "tldr_zh": "本文研究发现，虽然扩展训练计算提升了大型语言模型（LLMs）的性能，但扩展推理计算尚未带来类似收益，主要由于LLMs输出缺乏多样性导致搜索效率低下。作者提出PlanSearch算法，通过在自然语言中搜索候选计划（如生成问题观察并构建解决方案计划），显著增加潜在解决方案的多样性。实验在HumanEval+、MBPP+和LiveCodeBench基准上验证了其有效性，使用Claude 3.5 Sonnet时在LiveCodeBench上实现state-of-the-art的pass@200为77.0%，优于无搜索（pass@1=41.4%）和标准采样方法（pass@200=60.6%）。此外，研究表明，搜索性能提升可作为生成想法多样性的直接函数进行准确预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03733v2",
      "published_date": "2024-09-05 17:44:49 UTC",
      "updated_date": "2024-10-18 23:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:34:58.832783"
    },
    {
      "arxiv_id": "2409.15317v1",
      "title": "Shared Autonomy with IDA: Interventional Diffusion Assistance",
      "title_zh": "共享自治与 IDA：介入扩散辅助",
      "authors": [
        "Brandon J. McMahan",
        "Zhenghao Peng",
        "Bolei Zhou",
        "Jonathan C. Kao"
      ],
      "abstract": "The rapid development of artificial intelligence (AI) has unearthed the\npotential to assist humans in controlling advanced technologies. Shared\nautonomy (SA) facilitates control by combining inputs from a human pilot and an\nAI copilot. In prior SA studies, the copilot is constantly active in\ndetermining the action played at each time step. This limits human autonomy and\nmay have deleterious effects on performance. In general, the amount of helpful\ncopilot assistance can vary greatly depending on the task dynamics. We\ntherefore hypothesize that human autonomy and SA performance improve through\ndynamic and selective copilot intervention. To address this, we develop a\ngoal-agnostic intervention assistance (IA) that dynamically shares control by\nhaving the copilot intervene only when the expected value of the copilot's\naction exceeds that of the human's action across all possible goals. We\nimplement IA with a diffusion copilot (termed IDA) trained on expert\ndemonstrations with goal masking. We prove a lower bound on the performance of\nIA that depends on pilot and copilot performance. Experiments with simulated\nhuman pilots show that IDA achieves higher performance than pilot-only and\ntraditional SA control in variants of the Reacher environment and Lunar Lander.\nWe then demonstrate that IDA achieves better control in Lunar Lander with\nhuman-in-the-loop experiments. Human participants report greater autonomy with\nIDA and prefer IDA over pilot-only and traditional SA control. We attribute the\nsuccess of IDA to preserving human autonomy while simultaneously offering\nassistance to prevent the human pilot from entering universally bad states.",
      "tldr_zh": "本研究提出了一种干预扩散辅助（Interventional Diffusion Assistance, IDA）框架，用于提升共享自治（Shared Autonomy, SA）系统中的人类控制性能。IDA 通过动态选择性干预，仅在 AI 辅助（Diffusion Copilot）的预期行动价值超过人类操作时介入，从而避免了传统 SA 中 AI 常驻干预的局限。实验在 Reacher 和 Lunar Lander 环境中显示，IDA 比仅人类操作或传统 SA 控制表现出更高的性能，并通过模拟和真实人类参与测试证实了其优势。人类参与者反馈 IDA 提供了更大的自治感，并更倾向于该方法，因为它能保持人类主导同时防止进入不良状态。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 4 main figures, 2 appendix figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15317v1",
      "published_date": "2024-09-05 17:19:22 UTC",
      "updated_date": "2024-09-05 17:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:35:09.756721"
    },
    {
      "arxiv_id": "2409.03707v1",
      "title": "A Different Level Text Protection Mechanism With Differential Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Qingwen Fu"
      ],
      "abstract": "The article introduces a method for extracting words of different degrees of\nimportance based on the BERT pre-training model and proves the effectiveness of\nthis method. The article also discusses the impact of maintaining the same\nperturbation results for words of different importance on the overall text\nutility. This method can be applied to long text protection.",
      "tldr_zh": "该论文提出了一种基于BERT预训练模型的文本保护机制，能够提取不同重要度单词，并证明了该方法的有效性。该机制探讨了为不同重要度单词保持相同扰动结果对整体文本效用的影响，从而在Differential Privacy框架下平衡隐私保护与数据可用性。该方法适用于长文本保护，提供了一种更精细的文本安全策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03707v1",
      "published_date": "2024-09-05 17:13:38 UTC",
      "updated_date": "2024-09-05 17:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:35:18.948375"
    },
    {
      "arxiv_id": "2409.15315v1",
      "title": "An Efficient Recommendation Model Based on Knowledge Graph Attention-Assisted Network (KGATAX)",
      "title_zh": "基于知识图谱注意力辅助网络的推荐模型 (KGATAX)",
      "authors": [
        "Zhizhong Wu"
      ],
      "abstract": "Recommendation systems play a crucial role in helping users filter through\nvast amounts of information. However, traditional recommendation algorithms\noften overlook the integration and utilization of multi-source information,\nlimiting system performance. Therefore, this study proposes a novel\nrecommendation model, Knowledge Graph Attention-assisted Network (KGAT-AX). We\nfirst incorporate the knowledge graph into the recommendation model,\nintroducing an attention mechanism to explore higher order connectivity more\nexplicitly. By using multilayer interactive information propagation, the model\naggregates information to enhance its generalization ability. Furthermore, we\nintegrate auxiliary information into entities through holographic embeddings,\naggregating the information of adjacent entities for each entity by learning\ntheir inferential relationships. This allows for better utilization of\nauxiliary information associated with entities. We conducted experiments on\nreal datasets to demonstrate the rationality and effectiveness of the KGAT-AX\nmodel. Through experimental analysis, we observed the effectiveness and\npotential of KGAT-AX compared to other baseline models on public datasets.\nKGAT-AX demonstrates better knowledge information capture and relationship\nlearning capabilities.",
      "tldr_zh": "本研究针对传统推荐算法忽略多源信息整合的问题，提出了一种高效推荐模型Knowledge Graph Attention-assisted Network (KGAT-AX)，通过将知识图谱融入模型并引入注意力机制，探索更高阶的连接并进行多层交互信息传播，以提升泛化能力和信息利用。\n此外，KGAT-AX利用全息嵌入(holographic embeddings)将辅助信息聚合到实体中，学习相邻实体的推理关系，从而更好地捕捉实体关联。\n实验结果显示，在真实数据集上，KGAT-AX相比基线模型表现出更强的知识信息捕捉和关系学习能力，证明了其有效性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15315v1",
      "published_date": "2024-09-05 16:42:50 UTC",
      "updated_date": "2024-09-05 16:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:35:32.215747"
    },
    {
      "arxiv_id": "2409.03685v2",
      "title": "View-Invariant Policy Learning via Zero-Shot Novel View Synthesis",
      "title_zh": "通过零样本新颖视点合成实现视点不变策略学习",
      "authors": [
        "Stephen Tian",
        "Blake Wulfe",
        "Kyle Sargent",
        "Katherine Liu",
        "Sergey Zakharov",
        "Vitor Guizilini",
        "Jiajun Wu"
      ],
      "abstract": "Large-scale visuomotor policy learning is a promising approach toward\ndeveloping generalizable manipulation systems. Yet, policies that can be\ndeployed on diverse embodiments, environments, and observational modalities\nremain elusive. In this work, we investigate how knowledge from large-scale\nvisual data of the world may be used to address one axis of variation for\ngeneralizable manipulation: observational viewpoint. Specifically, we study\nsingle-image novel view synthesis models, which learn 3D-aware scene-level\npriors by rendering images of the same scene from alternate camera viewpoints\ngiven a single input image. For practical application to diverse robotic data,\nthese models must operate zero-shot, performing view synthesis on unseen tasks\nand environments. We empirically analyze view synthesis models within a simple\ndata-augmentation scheme that we call View Synthesis Augmentation (VISTA) to\nunderstand their capabilities for learning viewpoint-invariant policies from\nsingle-viewpoint demonstration data. Upon evaluating the robustness of policies\ntrained with our method to out-of-distribution camera viewpoints, we find that\nthey outperform baselines in both simulated and real-world manipulation tasks.\nVideos and additional visualizations are available at\nhttps://s-tian.github.io/projects/vista.",
      "tldr_zh": "该研究探讨了如何利用大规模视觉数据来提升机器人操作策略的视角不变性，特别针对不同观测视角的变异性。作者提出了一种名为 View Synthesis Augmentation (VISTA) 的数据增强方案，利用零样本新视图合成模型（Zero-Shot Novel View Synthesis）从单视角演示数据中生成多视角图像，从而学习 3D 感知的场景先验。实验结果显示，使用 VISTA 训练的策略在模拟和真实世界操作任务中，对分布外相机视角的鲁棒性明显优于基线模型，证明了该方法的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.03685v2",
      "published_date": "2024-09-05 16:39:21 UTC",
      "updated_date": "2025-02-19 21:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:35:43.681961"
    },
    {
      "arxiv_id": "2409.03671v2",
      "title": "TRACE-CS: A Synergistic Approach to Explainable Course Scheduling Using LLMs and Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Stylianos Loukas Vasileiou",
        "William Yeoh"
      ],
      "abstract": "We present TRACE-cs, a novel hybrid system that combines symbolic reasoning\nwith large language models (LLMs) to address contrastive queries in scheduling\nproblems. TRACE-cs leverages SAT solving techniques to encode scheduling\nconstraints and generate explanations for user queries, while utilizing an LLM\nto process the user queries into logical clauses as well as refine the\nexplanations generated by the symbolic solver to natural language sentences. By\nintegrating these components, our approach demonstrates the potential of\ncombining symbolic methods with LLMs to create explainable AI agents with\ncorrectness guarantees.",
      "tldr_zh": "该论文提出了一种名为 TRACE-CS 的混合系统，将符号推理与大型语言模型 (LLMs) 相结合，用于处理调度问题中的对比查询。系统利用 SAT solving 技术来编码调度约束并生成解释，同时依赖 LLMs 将用户查询转化为逻辑子句，并将符号求解器的输出精炼为自然语言解释。通过这种协同方法，论文展示了如何创建可解释的 AI 代理，并提供正确性保证，从而提升了调度问题的可解释性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03671v2",
      "published_date": "2024-09-05 16:24:42 UTC",
      "updated_date": "2024-10-08 14:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:35:55.421002"
    },
    {
      "arxiv_id": "2409.03669v2",
      "title": "A method to benchmark high-dimensional process drift detection",
      "title_zh": "一种用于基准测试高维过程漂移检测的方法",
      "authors": [
        "Edgar Wolf",
        "Tobias Windisch"
      ],
      "abstract": "Process curves are multivariate finite time series data coming from\nmanufacturing processes. This paper studies machine learning that detect drifts\nin process curve datasets. A theoretic framework to synthetically generate\nprocess curves in a controlled way is introduced in order to benchmark machine\nlearning algorithms for process drift detection. An evaluation score, called\nthe temporal area under the curve, is introduced, which allows to quantify how\nwell machine learning models unveil curves belonging to drift segments.\nFinally, a benchmark study comparing popular machine learning approaches on\nsynthetic data generated with the introduced framework is presented that shows\nthat existing algorithms often struggle with datasets containing multiple drift\nsegments.",
      "tldr_zh": "本论文提出了一种基准测试高维过程漂移检测（process drift detection）的方法，通过引入一个理论框架来合成生成可控的多变量过程曲线（process curves）数据集，以评估机器学习算法的性能。论文定义了一个新评价指标temporal area under the curve，用于量化模型在检测漂移段（drift segments）时的准确性。基准研究结果显示，现有的机器学习方法在处理包含多个漂移段的数据集时往往表现不佳，为未来算法改进提供了重要见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03669v2",
      "published_date": "2024-09-05 16:23:07 UTC",
      "updated_date": "2024-12-05 18:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:36:08.312860"
    },
    {
      "arxiv_id": "2409.03646v2",
      "title": "Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG",
      "title_zh": "通过与人类 EEG 联合训练物体识别模型，在对抗鲁棒性方面获得",
      "authors": [
        "Manshan Guo",
        "Bhavin Choksi",
        "Sari Sadiya",
        "Alessandro T. Gifford",
        "Martina G. Vilas",
        "Radoslaw M. Cichy",
        "Gemma Roig"
      ],
      "abstract": "In contrast to human vision, artificial neural networks (ANNs) remain\nrelatively susceptible to adversarial attacks. To address this vulnerability,\nefforts have been made to transfer inductive bias from human brains to ANNs,\noften by training the ANN representations to match their biological\ncounterparts. Previous works relied on brain data acquired in rodents or\nprimates using invasive techniques, from specific regions of the brain, under\nnon-natural conditions (anesthetized animals), and with stimulus datasets\nlacking diversity and naturalness. In this work, we explored whether aligning\nmodel representations to human EEG responses to a rich set of real-world images\nincreases robustness to ANNs. Specifically, we trained ResNet50-backbone models\non a dual task of classification and EEG prediction; and evaluated their EEG\nprediction accuracy and robustness to adversarial attacks. We observed\nsignificant correlation between the networks' EEG prediction accuracy, often\nhighest around 100 ms post stimulus onset, and their gains in adversarial\nrobustness. Although effect size was limited, effects were consistent across\ndifferent random initializations and robust for architectural variants. We\nfurther teased apart the data from individual EEG channels and observed\nstrongest contribution from electrodes in the parieto-occipital regions. The\ndemonstrated utility of human EEG for such tasks opens up avenues for future\nefforts that scale to larger datasets under diverse stimuli conditions with the\npromise of stronger effects.",
      "tldr_zh": "本研究探讨了通过共训练物体识别模型（ANNs）与人类 EEG 响应，来提升模型对抗性鲁棒性的方法。具体地，研究者训练 ResNet50 骨干网络同时执行图像分类和 EEG 预测任务，使用丰富的真实世界图像数据集。结果显示，模型的 EEG 预测准确性（尤其在刺激开始后约 100 ms）与对抗性鲁棒性提升之间存在显著相关性，尽管效果有限但在不同随机初始化和架构变体中保持一致。进一步分析发现，顶枕区电极的 EEG 数据贡献最大，为未来利用更大数据集和多样刺激条件来增强 ANN 鲁棒性开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted as ECCV HCV workshop 2024 oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2409.03646v2",
      "published_date": "2024-09-05 16:04:57 UTC",
      "updated_date": "2024-12-12 21:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:36:23.772919"
    },
    {
      "arxiv_id": "2409.05898v2",
      "title": "Simplex-enabled Safe Continual Learning Machine",
      "title_zh": "翻译失败",
      "authors": [
        "Hongpeng Cao",
        "Yanbing Mao",
        "Yihao Cai",
        "Lui Sha",
        "Marco Caccamo"
      ],
      "abstract": "This paper proposes the SeC-Learning Machine: Simplex-enabled safe continual\nlearning for safety-critical autonomous systems. The SeC-learning machine is\nbuilt on Simplex logic (that is, ``using simplicity to control complexity'')\nand physics-regulated deep reinforcement learning (Phy-DRL). The SeC-learning\nmachine thus constitutes HP (high performance)-Student, HA (high\nassurance)-Teacher, and Coordinator. Specifically, the HP-Student is a\npre-trained high-performance but not fully verified Phy-DRL, continuing to\nlearn in a real plant to tune the action policy to be safe. In contrast, the\nHA-Teacher is a mission-reduced, physics-model-based, and verified design. As a\ncomplementary, HA-Teacher has two missions: backing up safety and correcting\nunsafe learning. The Coordinator triggers the interaction and the switch\nbetween HP-Student and HA-Teacher. Powered by the three interactive components,\nthe SeC-learning machine can i) assure lifetime safety (i.e., safety guarantee\nin any continual-learning stage, regardless of HP-Student's success or\nconvergence), ii) address the Sim2Real gap, and iii) learn to tolerate unknown\nunknowns in real plants. The experiments on a cart-pole system and a real\nquadruped robot demonstrate the distinguished features of the SeC-learning\nmachine, compared with continual learning built on state-of-the-art safe DRL\nframeworks with approaches to addressing the Sim2Real gap.",
      "tldr_zh": "本文提出 SeC-Learning Machine，一种基于 Simplex 逻辑和 physics-regulated deep reinforcement learning (Phy-DRL) 的安全持续学习框架，旨在为安全关键的自适应系统提供终身安全保障。框架由 HP-Student（高性能但未完全验证的 Phy-DRL 学习器）、HA-Teacher（基于物理模型的验证设计，用于安全备份和纠正不安全学习）和 Coordinator（负责交互与切换）三部分组成，能够解决 Sim2Real 差距并学习容忍未知未知。实验在 cart-pole 系统和真实四足机器人上验证了其优势，与现有安全 DRL 框架相比表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05898v2",
      "published_date": "2024-09-05 16:03:00 UTC",
      "updated_date": "2024-10-06 03:05:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:36:33.015925"
    },
    {
      "arxiv_id": "2409.03597v3",
      "title": "Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Fold Paralysis",
      "title_zh": "多模态喉镜视频分析用于声带麻痹的辅助诊断",
      "authors": [
        "Yucong Zhang",
        "Xin Zou",
        "Jinshan Yang",
        "Wenjun Chen",
        "Juan Liu",
        "Faya Liang",
        "Ming Li"
      ],
      "abstract": "This paper presents the Multimodal Laryngoscopic Video Analyzing System\n(MLVAS), a novel system that leverages both audio and video data to\nautomatically extract key video segments and metrics from raw laryngeal\nvideostroboscopic videos for assisted clinical assessment. The system\nintegrates video-based glottis detection with an audio keyword spotting method\nto analyze both video and audio data, identifying patient vocalizations and\nrefining video highlights to ensure optimal inspection of vocal fold movements.\nBeyond key video segment extraction from the raw laryngeal videos, MLVAS is\nable to generate effective audio and visual features for Vocal Fold Paralysis\n(VFP) detection. Pre-trained audio encoders are utilized to encode the patient\nvoice to get the audio features. Visual features are generated by measuring the\nangle deviation of both the left and right vocal folds to the estimated glottal\nmidline on the segmented glottis masks. To get better masks, we introduce a\ndiffusion-based refinement that follows traditional U-Net segmentation to\nreduce false positives. We conducted several ablation studies to demonstrate\nthe effectiveness of each module and modalities in the proposed MLVAS. The\nexperimental results on a public segmentation dataset show the effectiveness of\nour proposed segmentation module. In addition, unilateral VFP classification\nresults on a real-world clinic dataset demonstrate MLVAS's ability of providing\nreliable and objective metrics as well as visualization for assisted clinical\ndiagnosis.",
      "tldr_zh": "本研究提出 Multimodal Laryngoscopic Video Analyzing System (MLVAS)，一个整合音频和视频数据的系统，用于从原始喉镜视频中自动提取关键段落和指标，以辅助 Vocal Fold Paralysis (VFP) 诊断。MLVAS 结合视频-based 声门检测和音频关键词检测方法，识别患者发声并优化视频亮点，同时通过预训练音频编码器提取音频特征，以及测量声带角偏差于声门中线来生成视觉特征，并采用扩散-based 精炼提升 U-Net 分割的准确性以减少假阳性。实验结果显示，该系统在公共分割数据集上表现突出，并在真实临床数据集的单侧 VFP 分类中提供可靠的客观指标和可视化，支持临床评估的精确性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to CSL",
      "pdf_url": "http://arxiv.org/pdf/2409.03597v3",
      "published_date": "2024-09-05 14:56:38 UTC",
      "updated_date": "2025-04-22 15:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:36:46.040669"
    },
    {
      "arxiv_id": "2409.13705v2",
      "title": "Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Olivia Sturman",
        "Aparna Joshi",
        "Bhaktipriya Radharapu",
        "Piyush Kumar",
        "Renee Shelby"
      ],
      "abstract": "Increasing use of large language models (LLMs) demand performant guardrails\nto ensure the safety of inputs and outputs of LLMs. When these safeguards are\ntrained on imbalanced data, they can learn the societal biases. We present a\nlight-weight, post-processing method for mitigating counterfactual fairness in\nclosed-source text safety classifiers. Our approach involves building an\nensemble that not only outperforms the input classifiers and policy-aligns\nthem, but also acts as a debiasing regularizer. We introduce two\nthreshold-agnostic metrics to assess the counterfactual fairness of a model,\nand demonstrate how combining these metrics with Fair Data Reweighting (FDW)\nhelps mitigate biases. We create an expanded Open AI dataset, and a new\ntemplated LLM-generated dataset based on user-prompts, both of which are\ncounterfactually balanced across identity groups and cover four key areas of\nsafety; we will work towards publicly releasing these datasets. Our results\nshow that our approach improves counterfactual fairness with minimal impact on\nmodel performance.",
      "tldr_zh": "这篇论文提出了一种轻量级的后处理方法，通过公平感知集成 (fairness-aware ensemble) 来缓解大型语言模型 (LLMs) 安全分类器在不平衡数据上学到的社会偏见。方法构建了一个集成模型，不仅优于输入分类器并实现政策对齐，还作为去偏置正则化器，并结合 Fair Data Reweighting (FDW) 和两个阈值无关的逆事实公平性 (counterfactual fairness) 指标来评估并缓解偏见。研究者创建了扩展的 OpenAI 数据集和一个新的基于用户提示的模板化 LLM 生成数据集，这些数据集在身份群体上实现了逆事实平衡，并覆盖四个关键安全领域。结果表明，该方法在最小影响模型性能的情况下显著提高了逆事实公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13705v2",
      "published_date": "2024-09-05 14:35:35 UTC",
      "updated_date": "2024-10-22 01:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:36:58.641875"
    },
    {
      "arxiv_id": "2409.03563v1",
      "title": "100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Pacchiardi",
        "Lucy G. Cheke",
        "José Hernández-Orallo"
      ],
      "abstract": "Predicting the performance of LLMs on individual task instances is essential\nto ensure their reliability in high-stakes applications. To do so, a\npossibility is to evaluate the considered LLM on a set of task instances and\ntrain an assessor to predict its performance based on features of the\ninstances. However, this approach requires evaluating each new LLM on a\nsufficiently large set of task instances to train an assessor specific to it.\nIn this work, we leverage the evaluation results of previously tested LLMs to\nreduce the number of evaluations required to predict the performance of a new\nLLM. In practice, we propose to test the new LLM on a small set of reference\ninstances and train a generic assessor which predicts the performance of the\nLLM on an instance based on the performance of the former on the reference set\nand features of the instance of interest. We conduct empirical studies on\nHELM-Lite and KindsOfReasoning, a collection of existing reasoning datasets\nthat we introduce, where we evaluate all instruction-fine-tuned OpenAI models\nuntil the January 2024 version of GPT4. When predicting performance on\ninstances with the same distribution as those used to train the generic\nassessor, we find this achieves performance comparable to the LLM-specific\nassessors trained on the full set of instances. Additionally, we find that\nrandomly selecting the reference instances performs as well as some advanced\nselection methods we tested. For out of distribution, however, no clear winner\nemerges and the overall performance is worse, suggesting that the inherent\npredictability of LLMs is low.",
      "tldr_zh": "本文提出一种高效方法，仅需测试 100 个 reference instances，即可预测新 LLM 在未见数据上的性能，从而减少评估需求。该方法利用之前测试 LLM 的结果，训练一个 generic assessor，通过参考实例的表现和目标实例特征来预测性能。在 HELM-Lite 和 KindsOfReasoning 数据集上的实验显示，该评估器在同分布实例上表现与特定 LLM 评估器相当，且随机选择参考实例的效果与高级方法类似；然而，在 out of distribution 情况下，整体性能较差，表明 LLM 的可预测性较低。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at the 2024 KDD workshop on Evaluation and Trustworthiness\n  of Generative AI Models",
      "pdf_url": "http://arxiv.org/pdf/2409.03563v1",
      "published_date": "2024-09-05 14:19:45 UTC",
      "updated_date": "2024-09-05 14:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:37:09.066011"
    },
    {
      "arxiv_id": "2409.03550v2",
      "title": "DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Qianlong Xiang",
        "Miao Zhang",
        "Yuzhang Shang",
        "Jianlong Wu",
        "Yan Yan",
        "Liqiang Nie"
      ],
      "abstract": "Diffusion models (DMs) have demonstrated exceptional generative capabilities\nacross various domains, including image, video, and so on. A key factor\ncontributing to their effectiveness is the high quantity and quality of data\nused during training. However, mainstream DMs now consume increasingly large\namounts of data. For example, training a Stable Diffusion model requires\nbillions of image-text pairs. This enormous data requirement poses significant\nchallenges for training large DMs due to high data acquisition costs and\nstorage expenses. To alleviate this data burden, we propose a novel scenario:\nusing existing DMs as data sources to train new DMs with any architecture. We\nrefer to this scenario as Data-Free Knowledge Distillation for Diffusion Models\n(DKDM), where the generative ability of DMs is transferred to new ones in a\ndata-free manner. To tackle this challenge, we make two main contributions.\nFirst, we introduce a DKDM objective that enables the training of new DMs via\ndistillation, without requiring access to the data. Second, we develop a\ndynamic iterative distillation method that efficiently extracts time-domain\nknowledge from existing DMs, enabling direct retrieval of training data without\nthe need for a prolonged generative process. To the best of our knowledge, we\nare the first to explore this scenario. Experimental results demonstrate that\nour data-free approach not only achieves competitive generative performance but\nalso, in some instances, outperforms models trained with the entire dataset.",
      "tldr_zh": "该研究针对扩散模型(DMs)训练所需的大量数据问题，提出了一种新型场景：Data-Free Knowledge Distillation for Diffusion Models (DKDM)，利用现有DMs作为数据来源训练任意架构的新模型，从而避免直接获取原始数据。DKDM的主要贡献包括引入一个无需数据访问的蒸馏目标函数，以及开发动态迭代蒸馏方法，以高效提取现有DMs的时间域知识，实现快速训练数据检索。实验结果显示，该方法在生成性能上不仅与使用完整数据集训练的模型相当，在某些情况下甚至表现出色，为减轻DMs训练负担提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03550v2",
      "published_date": "2024-09-05 14:12:22 UTC",
      "updated_date": "2025-02-28 15:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:37:20.415723"
    },
    {
      "arxiv_id": "2409.03543v1",
      "title": "Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift",
      "title_zh": "预测准确性与可靠性：在分布偏移下的分类和对象定位",
      "authors": [
        "Fabian Diet",
        "Moussa Kassem Sbeyti",
        "Michelle Karg"
      ],
      "abstract": "Natural distribution shift causes a deterioration in the perception\nperformance of convolutional neural networks (CNNs). This comprehensive\nanalysis for real-world traffic data addresses: 1) investigating the effect of\nnatural distribution shift and weather augmentations on both detection quality\nand confidence estimation, 2) evaluating model performance for both\nclassification and object localization, and 3) benchmarking two common\nuncertainty quantification methods - Ensembles and different variants of\nMonte-Carlo (MC) Dropout - under natural and close-to-natural distribution\nshift. For this purpose, a novel dataset has been curated from publicly\navailable autonomous driving datasets. The in-distribution (ID) data is based\non cutouts of a single object, for which both class and bounding box\nannotations are available. The six distribution-shift datasets cover adverse\nweather scenarios, simulated rain and fog, corner cases, and\nout-of-distribution data. A granular analysis of CNNs under distribution shift\nallows to quantize the impact of different types of shifts on both, task\nperformance and confidence estimation: ConvNeXt-Tiny is more robust than\nEfficientNet-B0; heavy rain degrades classification stronger than localization,\ncontrary to heavy fog; integrating MC-Dropout into selected layers only has the\npotential to enhance task performance and confidence estimation, whereby the\nidentification of these layers depends on the type of distribution shift and\nthe considered task.",
      "tldr_zh": "该研究调查了自然分布偏移对卷积神经网络 (CNNs) 在分类和对象定位任务中的性能影响，特别关注检测质量和置信度估计。研究者创建了一个新数据集，从公开的自动驾驶数据中提取，包括正常分布 (ID) 数据和各种偏移场景（如恶劣天气、雨、雾等），并基准测试了不确定性量化方法，包括 Ensembles 和 Monte-Carlo (MC) Dropout 的变体。结果显示，ConvNeXt-Tiny 比 EfficientNet-B0 更鲁棒；重雨对分类的影响大于对象定位，而重雾则相反；将 MC-Dropout 集成到特定层可提升任务性能和置信度估计，但效果取决于分布偏移类型和任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This preprint has not undergone any post-submission improvements or\n  corrections",
      "pdf_url": "http://arxiv.org/pdf/2409.03543v1",
      "published_date": "2024-09-05 14:06:56 UTC",
      "updated_date": "2024-09-05 14:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:37:32.774838"
    },
    {
      "arxiv_id": "2409.04475v2",
      "title": "Revolutionizing Database Q&A with Large Language Models: Comprehensive Benchmark and Evaluation",
      "title_zh": "使用大语言模型革新数据库问答：全面基准测试和评估",
      "authors": [
        "Yihang Zheng",
        "Bo Li",
        "Zhenghao Lin",
        "Yi Luo",
        "Xuanhe Zhou",
        "Chen Lin",
        "Jinsong Su",
        "Guoliang Li",
        "Shifu Li"
      ],
      "abstract": "The development of Large Language Models (LLMs) has revolutionized QA across\nvarious industries, including the database domain. However, there is still a\nlack of a comprehensive benchmark to evaluate the capabilities of different\nLLMs and their modular components in database QA. To this end, we introduce\nDQABench, the first comprehensive database QA benchmark for LLMs. DQABench\nfeatures an innovative LLM-based method to automate the generation, cleaning,\nand rewriting of evaluation dataset, resulting in over 200,000 QA pairs in\nEnglish and Chinese, separately. These QA pairs cover a wide range of\ndatabase-related knowledge extracted from manuals, online communities, and\ndatabase instances. This inclusion allows for an additional assessment of LLMs'\nRetrieval-Augmented Generation (RAG) and Tool Invocation Generation (TIG)\ncapabilities in the database QA task. Furthermore, we propose a comprehensive\nLLM-based database QA testbed DQATestbed. This testbed is highly modular and\nscalable, with basic and advanced components such as Question Classification\nRouting (QCR), RAG, TIG, and Prompt Template Engineering (PTE). Moreover,\nDQABench provides a comprehensive evaluation pipeline that computes various\nmetrics throughout a standardized evaluation process to ensure the accuracy and\nfairness of the evaluation. We use DQABench to evaluate the database QA\ncapabilities under the proposed testbed comprehensively. The evaluation reveals\nfindings like (i) the strengths and limitations of nine LLM-based QA bots and\n(ii) the performance impact and potential improvements of various service\ncomponents (e.g., QCR, RAG, TIG). Our benchmark and findings will guide the\nfuture development of LLM-based database QA research.",
      "tldr_zh": "本研究引入了 DQABench，这是首个全面的数据库问答（QA）基准，使用 Large Language Models (LLMs) 自动生成、清理和重写超过 20 万对英文和中文 QA 问题，这些问题涵盖数据库手册、在线社区和实例，以评估 LLMs 的 Retrieval-Augmented Generation (RAG) 和 Tool Invocation Generation (TIG) 能力。论文还提出了 DQATestbed，一个模块化且可扩展的测试平台，包括 Question Classification Routing (QCR)、RAG、TIG 和 Prompt Template Engineering (PTE) 等组件，并提供标准化的评估管道。实验评估了九个 LLM-based QA 机器人，揭示了它们的优势、局限性以及组件（如 QCR 和 RAG）的性能影响，从而为未来 LLM-based 数据库 QA 研究提供重要指导。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.04475v2",
      "published_date": "2024-09-05 13:45:42 UTC",
      "updated_date": "2024-12-06 05:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:37:46.896866"
    },
    {
      "arxiv_id": "2409.03516v1",
      "title": "LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongsoo Kim",
        "Jongho Nang",
        "Junsuk Choe"
      ],
      "abstract": "Recent Vision Transformer (ViT)-based methods for Image Super-Resolution have\ndemonstrated impressive performance. However, they suffer from significant\ncomplexity, resulting in high inference times and memory usage. Additionally,\nViT models using Window Self-Attention (WSA) face challenges in processing\nregions outside their windows. To address these issues, we propose the\nLow-to-high Multi-Level Transformer (LMLT), which employs attention with\nvarying feature sizes for each head. LMLT divides image features along the\nchannel dimension, gradually reduces spatial size for lower heads, and applies\nself-attention to each head. This approach effectively captures both local and\nglobal information. By integrating the results from lower heads into higher\nheads, LMLT overcomes the window boundary issues in self-attention. Extensive\nexperiments show that our model significantly reduces inference time and GPU\nmemory usage while maintaining or even surpassing the performance of\nstate-of-the-art ViT-based Image Super-Resolution methods. Our codes are\navailiable at https://github.com/jwgdmkj/LMLT.",
      "tldr_zh": "本研究针对基于 Vision Transformer (ViT) 的图像超分辨率方法存在的复杂性高、推理时间长和内存占用大等问题，以及 Window Self-Attention (WSA) 在处理窗口外区域的挑战，提出了一种 Low-to-high Multi-Level Transformer (LMLT)。LMLT 通过沿通道维度划分图像特征，为每个注意力头使用不同特征大小，并逐步减少较低头的空间大小，从而有效捕获局部和全局信息，同时通过将较低头的结果整合到较高头中解决窗口边界问题。实验结果表明，LMLT 在保持或超越最先进 ViT-based 方法性能的同时，显著降低了推理时间和 GPU 内存使用，为高效图像超分辨率提供了新方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03516v1",
      "published_date": "2024-09-05 13:29:50 UTC",
      "updated_date": "2024-09-05 13:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:00.073747"
    },
    {
      "arxiv_id": "2409.03500v3",
      "title": "Willingness to Read AI-Generated News Is Not Driven by Their Perceived Quality",
      "title_zh": "阅读 AI 生成新闻的意愿并非由其感知质量驱动",
      "authors": [
        "Fabrizio Gilardi",
        "Sabrina Di Lorenzo",
        "Juri Ezzaini",
        "Beryl Santa",
        "Benjamin Streiff",
        "Eric Zurfluh",
        "Emma Hoes"
      ],
      "abstract": "The advancement of artificial intelligence has led to its application in many\nareas, including news media, which makes it crucial to understand public\nreception of AI-generated news. This preregistered study investigates (i) the\nperceived quality of AI-assisted and AI-generated versus human-generated news\narticles, (ii) whether disclosure of AI's involvement in generating these news\narticles influences engagement with them, and (iii) whether such awareness\naffects the willingness to read AI-generated articles in the future. We\nconducted a survey experiment with 599 Swiss participants, who evaluated the\ncredibility, readability, and expertise of news articles either written by\njournalists (control group), rewritten by AI (AI-assisted group), or entirely\nwritten by AI (AI-generated group). Our results indicate that all articles were\nperceived to be of equal quality. When participants in the treatment groups\nwere subsequently made aware of AI's role, they expressed a higher willingness\nto continue reading the articles than participants in the control group.\nHowever, they were not more willing to read AI-generated news in the future.\nThese results suggest that aversion to AI usage in news media is not primarily\nrooted in a perceived lack of quality, and that by disclosing using AI,\njournalists could induce more short-term engagement.",
      "tldr_zh": "这篇论文通过一项预注册调查实验，探讨了人们对 AI 生成新闻的感知质量（perceived quality）及其阅读意愿的影响，涉及 599 名瑞士参与者，他们评估了由人类、AI 辅助或 AI 生成的新闻文章在可信度（credibility）、易读性（readability）和专业性（expertise）上的差异。结果显示，所有文章的感知质量相似，但当告知参与者 AI 的参与后，AI 相关组比控制组更愿意短期继续阅读。研究发现，这种短期参与增加并未转化为未来阅读 AI-generated 新闻的更高意愿，表明公众对 AI 在新闻媒体中的厌恶并非主要源于质量问题，而是其他因素，通过披露 AI 使用可能提升短期 engagement。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03500v3",
      "published_date": "2024-09-05 13:12:16 UTC",
      "updated_date": "2025-02-14 10:39:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:12.423887"
    },
    {
      "arxiv_id": "2409.03470v1",
      "title": "Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Prerak Mody",
        "Nicolas F. Chaves-de-Plaza",
        "Chinmay Rao",
        "Eleftheria Astrenidou",
        "Mischa de Ridder",
        "Nienke Hoekstra",
        "Klaus Hildebrandt",
        "Marius Staring"
      ],
      "abstract": "Increased usage of automated tools like deep learning in medical image\nsegmentation has alleviated the bottleneck of manual contouring. This has\nshifted manual labour to quality assessment (QA) of automated contours which\ninvolves detecting errors and correcting them. A potential solution to\nsemi-automated QA is to use deep Bayesian uncertainty to recommend potentially\nerroneous regions, thus reducing time spent on error detection. Previous work\nhas investigated the correspondence between uncertainty and error, however, no\nwork has been done on improving the \"utility\" of Bayesian uncertainty maps such\nthat it is only present in inaccurate regions and not in the accurate ones. Our\nwork trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which\npromotes uncertainty to be present only in inaccurate regions. We apply this\nmethod on datasets of two radiotherapy body sites, c.f. head-and-neck CT and\nprostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated\nagainst voxel inaccuracies using Receiver Operating Characteristic (ROC) and\nPrecision-Recall (PR) curves. Numerical results show that when compared to the\nBayesian baseline the proposed method successfully suppresses uncertainty for\naccurate voxels, with similar presence of uncertainty for inaccurate voxels.\nCode to reproduce experiments is available at\nhttps://github.com/prerakmody/bayesuncertainty-error-correspondence",
      "tldr_zh": "本研究针对深度学习在医疗图像分割中的不确定性与错误对应问题，提出了一种改进方法，以减少质量评估（QA）中的手动工作。作者使用 Accuracy-vs-Uncertainty (AvU) 损失函数训练 FlipOut 模型，使不确定性仅出现在不准确区域，而非准确区域，从而提升不确定性热图的效用。在头颈部 CT 和前列腺 MR 扫描数据集上进行实验，结果显示该方法相对于基线模型成功抑制了准确体素的不确定性，同时保持了对不准确体素的不确定性，通过 Receiver Operating Characteristic (ROC) 和 Precision-Recall (PR) 曲线验证了性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:018",
      "pdf_url": "http://arxiv.org/pdf/2409.03470v1",
      "published_date": "2024-09-05 12:31:51 UTC",
      "updated_date": "2024-09-05 12:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:23.899738"
    },
    {
      "arxiv_id": "2409.03463v3",
      "title": "Massive Activations in Graph Neural Networks: Decoding Attention for Domain-Dependent Interpretability",
      "title_zh": "图神经网络中的大规模激活：解码注意力以实现领域相关的可",
      "authors": [
        "Lorenzo Bini",
        "Marco Sorbi",
        "Stephane Marchand-Maillet"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become increasingly popular for effectively\nmodeling graph-structured data, and attention mechanisms have been pivotal in\nenabling these models to capture complex patterns. In our study, we reveal a\ncritical yet underexplored consequence of integrating attention into\nedge-featured GNNs: the emergence of Massive Activations (MAs) within attention\nlayers. By developing a novel method for detecting MAs on edge features, we\nshow that these extreme activations are not only activation anomalies but\nencode domain-relevant signals. Our post-hoc interpretability analysis\ndemonstrates that, in molecular graphs, MAs aggregate predominantly on common\nbond types (e.g., single and double bonds) while sparing more informative ones\n(e.g., triple bonds). Furthermore, our ablation studies confirm that MAs can\nserve as natural attribution indicators, reallocating to less informative\nedges. Our study assesses various edge-featured attention-based GNN models\nusing benchmark datasets, including ZINC, TOX21, and PROTEINS. Key\ncontributions include (1) establishing the direct link between attention\nmechanisms and MAs generation in edge-featured GNNs, (2) developing a robust\ndefinition and detection method for MAs enabling reliable post-hoc\ninterpretability. Overall, our study reveals the complex interplay between\nattention mechanisms, edge-featured GNNs model, and MAs emergence, providing\ncrucial insights for relating GNNs internals to domain knowledge.",
      "tldr_zh": "该研究揭示了在 Graph Neural Networks (GNNs) 中整合注意力机制后，边特征层中会出现 Massive Activations (MAs)，这些激活并非简单异常，而是编码了领域相关信号。研究开发了一种新颖的检测方法，并通过后验解释性分析发现，在分子图中，MAs 主要聚集在常见键类型（如单键和双键）上，而忽略更信息丰富的键（如三键），并通过消融研究证实 MAs 可作为自然归因指标。实验在 ZINC、TOX21 和 PROTEINS 数据集上评估了多种边特征注意力-based GNN 模型，关键贡献包括建立了注意力机制与 MAs 生成的直接联系，并提供了将 GNN 内部机制与领域知识关联的可靠洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03463v3",
      "published_date": "2024-09-05 12:19:07 UTC",
      "updated_date": "2025-03-07 15:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:36.721883"
    },
    {
      "arxiv_id": "2409.03454v2",
      "title": "How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes",
      "title_zh": "翻译失败",
      "authors": [
        "Inacio Vieira",
        "Will Allred",
        "Séamus Lankford",
        "Sheila Castilho",
        "Andy Way"
      ],
      "abstract": "Decoder-only LLMs have shown impressive performance in MT due to their\nability to learn from extensive datasets and generate high-quality\ntranslations. However, LLMs often struggle with the nuances and style required\nfor organisation-specific translation. In this study, we explore the\neffectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3\n8B Instruct, leveraging translation memories (TMs), as a valuable resource to\nenhance accuracy and efficiency. We investigate the impact of fine-tuning the\nLlama 3 model using TMs from a specific organisation in the software sector.\nOur experiments cover five translation directions across languages of varying\nresource levels (English to Brazilian Portuguese, Czech, German, Finnish, and\nKorean). We analyse diverse sizes of training datasets (1k to 207k segments) to\nevaluate their influence on translation quality. We fine-tune separate models\nfor each training set and evaluate their performance based on automatic\nmetrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in\ntranslation performance with larger datasets across all metrics. On average,\nBLEU and COMET scores increase by 13 and 25 points, respectively, on the\nlargest training set against the baseline model. Notably, there is a\nperformance deterioration in comparison with the baseline model when\nfine-tuning on only 1k and 2k examples; however, we observe a substantial\nimprovement as the training dataset size increases. The study highlights the\npotential of integrating TMs with LLMs to create bespoke translation models\ntailored to the specific needs of businesses, thus enhancing translation\nquality and reducing turn-around times. This approach offers a valuable insight\nfor organisations seeking to leverage TMs and LLMs for optimal translation\noutcomes, especially in narrower domains.",
      "tldr_zh": "本文研究探讨了微调大型语言模型（LLMs），如 Llama 3 8B Instruct，使用翻译记忆（TMs）来提升组织内部翻译的准确性和效率，焦点在于评估不同数据集大小对性能的影响。实验涵盖五个翻译方向（英语到巴西葡萄牙语、捷克语、德语、芬兰语和韩语），并测试了从 1k 到 207k 段的训练数据集。结果显示，随着数据集规模增大，翻译质量显著提升，平均 BLEU 和 COMET 分数分别提高了 13 和 25 分；然而，使用 1k 或 2k 示例时，性能较基线模型有所下降。该研究强调了整合 TMs 与 LLMs 的潜力，有助于企业创建定制翻译模型，提高质量并缩短处理时间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03454v2",
      "published_date": "2024-09-05 12:06:38 UTC",
      "updated_date": "2024-09-10 09:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:50.852189"
    },
    {
      "arxiv_id": "2409.04473v1",
      "title": "Learning in Order! A Sequential Strategy to Learn Invariant Features for Multimodal Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xianbing Zhao",
        "Lizhen Qu",
        "Tao Feng",
        "Jianfei Cai",
        "Buzhou Tang"
      ],
      "abstract": "This work proposes a novel and simple sequential learning strategy to train\nmodels on videos and texts for multimodal sentiment analysis. To estimate\nsentiment polarities on unseen out-of-distribution data, we introduce a\nmultimodal model that is trained either in a single source domain or multiple\nsource domains using our learning strategy. This strategy starts with learning\ndomain invariant features from text, followed by learning sparse\ndomain-agnostic features from videos, assisted by the selected features learned\nin text. Our experimental results demonstrate that our model achieves\nsignificantly better performance than the state-of-the-art approaches on\naverage in both single-source and multi-source settings. Our feature selection\nprocedure favors the features that are independent to each other and are\nstrongly correlated with their polarity labels. To facilitate research on this\ntopic, the source code of this work will be publicly available upon acceptance.",
      "tldr_zh": "这篇论文提出了一种新颖的顺序学习策略，用于多模态情感分析（multimodal sentiment analysis），旨在从文本和视频中训练模型以估计未见过的数据（out-of-distribution data）的 sentiment polarities。策略首先从文本学习 domain invariant features，然后辅助从视频学习 sparse domain-agnostic features，这些特征被设计为相互独立且与极性标签高度相关。实验结果显示，该模型在单源和多源设置中比最先进方法平均表现显著更好。最后，作者计划公开源代码以推动相关研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04473v1",
      "published_date": "2024-09-05 11:55:05 UTC",
      "updated_date": "2024-09-05 11:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:38:59.862955"
    },
    {
      "arxiv_id": "2409.03444v1",
      "title": "Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Lu",
        "Rachel K. Luu",
        "Markus J. Buehler"
      ],
      "abstract": "The advancement of Large Language Models (LLMs) for domain applications in\nfields such as materials science and engineering depends on the development of\nfine-tuning strategies that adapt models for specialized, technical\ncapabilities. In this work, we explore the effects of Continued Pretraining\n(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization\napproaches, including Direct Preference Optimization (DPO) and Odds Ratio\nPreference Optimization (ORPO), on fine-tuned LLM performance. Our analysis\nshows how these strategies influence model outcomes and reveals that the\nmerging of multiple fine-tuned models can lead to the emergence of capabilities\nthat surpass the individual contributions of the parent models. We find that\nmodel merging leads to new functionalities that neither parent model could\nachieve alone, leading to improved performance in domain-specific assessments.\nExperiments with different model architectures are presented, including Llama\n3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring\nwhether the results hold also for much smaller models, we use a tiny LLM with\n1.7 billion parameters and show that very small LLMs do not necessarily feature\nemergent capabilities under model merging, suggesting that model scaling may be\na key component. In open-ended yet consistent chat conversations between a\nhuman and AI models, our assessment reveals detailed insights into how\ndifferent model variants perform and show that the smallest model achieves a\nhigh intelligence score across key criteria including reasoning depth,\ncreativity, clarity, and quantitative precision. Other experiments include the\ndevelopment of image generation prompts based on disparate biological material\ndesign concepts, to create new microstructures, architectural concepts, and\nurban design based on biological materials-inspired construction principles.",
      "tldr_zh": "本研究探讨了微调大型语言模型（LLMs）以适应特定领域（如材料科学和工程）的策略，包括持续预训练（CPT）、监督微调（SFT）、直接偏好优化（DPO）和赔率比偏好优化（ORPO）。通过实验分析，这些方法如何影响模型性能，并发现模型合并可以产生超越单个模型的新能力，尤其在Llama 3.1 8B和Mistral 7B等架构上。结果显示，模型缩放是关键因素，小型LLMs（如1.7亿参数模型）可能不具备紧急能力，但在聊天评估和图像生成任务中，某些小模型仍表现出色，如在推理深度和创意方面取得高分。",
      "categories": [
        "cs.CL",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03444v1",
      "published_date": "2024-09-05 11:49:53 UTC",
      "updated_date": "2024-09-05 11:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:39:15.065817"
    },
    {
      "arxiv_id": "2409.03439v1",
      "title": "KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale",
      "title_zh": "KiloBot：一种用于大规模部署感知引导工业机械臂的编程语言",
      "authors": [
        "Wei Gao",
        "Jingqiang Wang",
        "Xinv Zhu",
        "Jun Zhong",
        "Yue Shen",
        "Youshuang Ding"
      ],
      "abstract": "We would like industrial robots to handle unstructured environments with\ncameras and perception pipelines. In contrast to traditional industrial robots\nthat replay offline-crafted trajectories, online behavior planning is required\nfor these perception-guided industrial applications. Aside from perception and\nplanning algorithms, deploying perception-guided manipulators also requires\nsubstantial effort in integration. One approach is writing scripts in a\ntraditional language (such as Python) to construct the planning problem and\nperform integration with other algorithmic modules & external devices. While\nscripting in Python is feasible for a handful of robots and applications,\ndeploying perception-guided manipulation at scale (e.g., more than 10000 robot\nworkstations in over 2000 customer sites) becomes intractable. To resolve this\nchallenge, we propose a Domain-Specific Language (DSL) for perception-guided\nmanipulation applications. To scale up the deployment,our DSL provides: 1) an\neasily accessible interface to construct & solve a sub-class of Task and Motion\nPlanning (TAMP) problems that are important in practical applications; and 2) a\nmechanism to implement flexible control flow to perform integration and address\ncustomized requirements of distinct industrial application. Combined with an\nintuitive graphical programming frontend, our DSL is mainly used by machine\noperators without coding experience in traditional programming languages.\nWithin hours of training, operators are capable of orchestrating interesting\nsophisticated manipulation behaviors with our DSL. Extensive practical\ndeployments demonstrate the efficacy of our method.",
      "tldr_zh": "本研究提出KiloBot，一种Domain-Specific Language (DSL)，用于大规模部署感知引导的工业机械臂，以应对传统编程（如Python脚本）在处理非结构化环境和在线行为规划时的低效问题。KiloBot DSL提供易访问的接口来构建和解决Task and Motion Planning (TAMP)问题的子类，并支持灵活的控制流机制，以实现算法模块和外部设备的集成，满足不同工业应用的定制需求。结合直观的图形编程前端，该语言针对无编程经验的机器操作员设计，操作员经数小时培训即可创建复杂的行为。实际部署证明，KiloBot显著提升了大规模部署的效率和可行性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03439v1",
      "published_date": "2024-09-05 11:42:08 UTC",
      "updated_date": "2024-09-05 11:42:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:39:23.949870"
    },
    {
      "arxiv_id": "2409.03429v1",
      "title": "Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Roos-Hoefgeest",
        "Mario Roos-Hoefgeest",
        "Ignacio Alvarez",
        "Rafael C. González"
      ],
      "abstract": "High-precision surface defect detection in manufacturing is essential for\nensuring quality control. Laser triangulation profilometric sensors are key to\nthis process, providing detailed and accurate surface measurements over a line.\nTo achieve a complete and precise surface scan, accurate relative motion\nbetween the sensor and the workpiece is required. It is crucial to control the\nsensor pose to maintain optimal distance and relative orientation to the\nsurface. It is also important to ensure uniform profile distribution throughout\nthe scanning process. This paper presents a novel Reinforcement Learning (RL)\nbased approach to optimize robot inspection trajectories for profilometric\nsensors. Building upon the Boustrophedon scanning method, our technique\ndynamically adjusts the sensor position and tilt to maintain optimal\norientation and distance from the surface, while also ensuring a consistent\nprofile distance for uniform and high-quality scanning. Utilizing a simulated\nenvironment based on the CAD model of the part, we replicate real-world\nscanning conditions, including sensor noise and surface irregularities. This\nsimulation-based approach enables offline trajectory planning based on CAD\nmodels. Key contributions include the modeling of the state space, action\nspace, and reward function, specifically designed for inspection applications\nusing profilometric sensors. We use Proximal Policy Optimization (PPO)\nalgorithm to efficiently train the RL agent, demonstrating its capability to\noptimize inspection trajectories with profilometric sensors. To validate our\napproach, we conducted several experiments where a model trained on a specific\ntraining piece was tested on various parts in simulation. Also, we conducted a\nreal-world experiment by executing the optimized trajectory, generated offline\nfrom a CAD model, to inspect a part using a UR3e robotic arm model.",
      "tldr_zh": "本研究提出了一种基于强化学习（Reinforcement Learning, RL）的创新方法，用于优化激光三角测量轮廓仪（profilometric sensors）的轨迹，以提升制造领域的表面缺陷检测精度。该方法在Boustrophedon扫描基础上，动态调整传感器位置和倾斜，确保最佳距离、方向和均匀扫描分布，并通过基于CAD模型的模拟环境训练RL代理，考虑传感器噪声和表面不规则。关键贡献包括设计专为检测应用的状态空间、动作空间和奖励函数，并采用Proximal Policy Optimization (PPO)算法进行高效训练。实验结果显示，该方法在模拟环境中优化轨迹后，在不同零件上表现良好，并在真实世界测试中使用UR3e机器人臂成功执行，显著提高了扫描质量。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03429v1",
      "published_date": "2024-09-05 11:20:12 UTC",
      "updated_date": "2024-09-05 11:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:39:35.880779"
    },
    {
      "arxiv_id": "2409.03806v1",
      "title": "Mpox Screen Lite: AI-Driven On-Device Offline Mpox Screening for Low-Resource African Mpox Emergency Response",
      "title_zh": "翻译失败",
      "authors": [
        "Yudara Kularathne",
        "Prathapa Janitha",
        "Sithira Ambepitiya"
      ],
      "abstract": "Background: The 2024 Mpox outbreak, particularly severe in Africa with clade\n1b emergence, has highlighted critical gaps in diagnostic capabilities in\nresource-limited settings. This study aimed to develop and validate an\nartificial intelligence (AI)-driven, on-device screening tool for Mpox,\ndesigned to function offline in low-resource environments.\n  Methods: We developed a YOLOv8n-based deep learning model trained on 2,700\nimages (900 each of Mpox, other skin conditions, and normal skin), including\nsynthetic data. The model was validated on 360 images and tested on 540 images.\nA larger external validation was conducted using 1,500 independent images.\nPerformance metrics included accuracy, precision, recall, F1-score,\nsensitivity, and specificity.\n  Findings: The model demonstrated high accuracy (96%) in the final test set.\nFor Mpox detection, it achieved 93% precision, 97% recall, and an F1-score of\n95%. Sensitivity and specificity for Mpox detection were 97% and 96%,\nrespectively. Performance remained consistent in the larger external\nvalidation, confirming the model's robustness and generalizability.\n  Interpretation: This AI-driven screening tool offers a rapid, accurate, and\nscalable solution for Mpox detection in resource-constrained settings. Its\noffline functionality and high performance across diverse datasets suggest\nsignificant potential for improving Mpox surveillance and management,\nparticularly in areas lacking traditional diagnostic infrastructure.",
      "tldr_zh": "本研究开发了 Mpox Screen Lite，一种基于 AI 的离线设备筛查工具，旨在应对2024年非洲 Mpox 爆发（尤其是 clade 1b 变种）在资源有限地区诊断能力的不足。研究采用 YOLOv8n 深度学习模型，训练于2,700张图像（包括 Mpox、其他皮肤病和正常皮肤的真实及合成数据），并通过验证集（360张图像）和测试集（540张图像）进行评估，同时在1,500张外部图像上进行独立验证。模型在最终测试集上实现96%的准确率，Mpox 检测的精确率达93%、召回率97%、F1-score 95%、灵敏度97%和特异性96%，并在外部验证中保持一致表现。该工具提供快速、准确且可扩展的解决方案，有助于提升资源匮乏地区的 Mpox 监测和管理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "11 Pages, 2 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2409.03806v1",
      "published_date": "2024-09-05 11:18:34 UTC",
      "updated_date": "2024-09-05 11:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:39:50.814863"
    },
    {
      "arxiv_id": "2409.03404v2",
      "title": "KAN See In the Dark",
      "title_zh": "翻译失败",
      "authors": [
        "Aoxiang Ning",
        "Minglong Xue",
        "Jinhong He",
        "Chengyun Song"
      ],
      "abstract": "Existing low-light image enhancement methods are difficult to fit the complex\nnonlinear relationship between normal and low-light images due to uneven\nillumination and noise effects. The recently proposed Kolmogorov-Arnold\nnetworks (KANs) feature spline-based convolutional layers and learnable\nactivation functions, which can effectively capture nonlinear dependencies. In\nthis paper, we design a KAN-Block based on KANs and innovatively apply it to\nlow-light image enhancement. This method effectively alleviates the limitations\nof current methods constrained by linear network structures and lack of\ninterpretability, further demonstrating the potential of KANs in low-level\nvision tasks. Given the poor perception of current low-light image enhancement\nmethods and the stochastic nature of the inverse diffusion process, we further\nintroduce frequency-domain perception for visually oriented enhancement.\nExtensive experiments demonstrate the competitive performance of our method on\nbenchmark datasets. The code will be available at:\nhttps://github.com/AXNing/KSID}{https://github.com/AXNing/KSID.",
      "tldr_zh": "这篇论文针对低光图像增强中存在的复杂非线性关系问题（如不均匀照明和噪声影响），引入Kolmogorov-Arnold networks (KANs)并设计了KAN-Block，利用其基于样条的卷积层和可学习激活函数来有效捕捉非线性依赖，从而提升图像增强的可解释性和性能。论文进一步整合频域感知机制，以改善当前方法的感知不足和逆扩散过程的随机性。实验在基准数据集上证明了该方法的竞争性表现，代码已计划在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03404v2",
      "published_date": "2024-09-05 10:41:17 UTC",
      "updated_date": "2025-02-06 14:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:40:04.209722"
    },
    {
      "arxiv_id": "2409.03402v1",
      "title": "Game On: Towards Language Models as RL Experimenters",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Zhang",
        "Thomas Lampe",
        "Abbas Abdolmaleki",
        "Jost Tobias Springenberg",
        "Martin Riedmiller"
      ],
      "abstract": "We propose an agent architecture that automates parts of the common\nreinforcement learning experiment workflow, to enable automated mastery of\ncontrol domains for embodied agents. To do so, it leverages a VLM to perform\nsome of the capabilities normally required of a human experimenter, including\nthe monitoring and analysis of experiment progress, the proposition of new\ntasks based on past successes and failures of the agent, decomposing tasks into\na sequence of subtasks (skills), and retrieval of the skill to execute -\nenabling our system to build automated curricula for learning. We believe this\nis one of the first proposals for a system that leverages a VLM throughout the\nfull experiment cycle of reinforcement learning. We provide a first prototype\nof this system, and examine the feasibility of current models and techniques\nfor the desired level of automation. For this, we use a standard Gemini model,\nwithout additional fine-tuning, to provide a curriculum of skills to a\nlanguage-conditioned Actor-Critic algorithm, in order to steer data collection\nso as to aid learning new skills. Data collected in this way is shown to be\nuseful for learning and iteratively improving control policies in a robotics\ndomain. Additional examination of the ability of the system to build a growing\nlibrary of skills, and to judge the progress of the training of those skills,\nalso shows promising results, suggesting that the proposed architecture\nprovides a potential recipe for fully automated mastery of tasks and domains\nfor embodied agents.",
      "tldr_zh": "这篇论文提出了一种代理架构，将视觉语言模型(VLM)用于自动化强化学习(RL)实验流程，允许代理监控实验进度、基于过去经验提出新任务、将任务分解为子任务(skills)并构建自动课程(curricula)。该系统使用标准Gemini模型（无额外微调）与语言条件Actor-Critic算法结合，指导数据收集以提升技能学习。实验结果显示，该方法能有效收集有用数据、迭代优化控制策略，并在机器人领域展现出构建技能库和判断训练进度的潜力，为实现完全自动化的任务掌握提供了一个可行方案。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03402v1",
      "published_date": "2024-09-05 10:38:16 UTC",
      "updated_date": "2024-09-05 10:38:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:40:28.090448"
    },
    {
      "arxiv_id": "2409.03805v1",
      "title": "Exploratory Visual Analysis for Increasing Data Readiness in Artificial Intelligence Projects",
      "title_zh": "翻译失败",
      "authors": [
        "Mattias Tiger",
        "Daniel Jakobsson",
        "Anders Ynnerman",
        "Fredrik Heintz",
        "Daniel Jönsson"
      ],
      "abstract": "We present experiences and lessons learned from increasing data readiness of\nheterogeneous data for artificial intelligence projects using visual analysis\nmethods. Increasing the data readiness level involves understanding both the\ndata as well as the context in which it is used, which are challenges well\nsuitable to visual analysis. For this purpose, we contribute a mapping between\ndata readiness aspects and visual analysis techniques suitable for different\ndata types. We use the defined mapping to increase data readiness levels in use\ncases involving time-varying data, including numerical, categorical, and text.\nIn addition to the mapping, we extend the data readiness concept to better take\naspects of the task and solution into account and explicitly address\ndistribution shifts during data collection time. We report on our experiences\nin using the presented visual analysis techniques to aid future artificial\nintelligence projects in raising the data readiness level.",
      "tldr_zh": "该论文探讨了使用探索性视觉分析方法提升人工智能（AI）项目中异构数据的准备度（data readiness），通过理解数据及其使用上下文来应对相关挑战。作者贡献了一个将数据准备度方面与适合不同数据类型（如数值、分类和文本）的视觉分析技术进行映射的框架，并将其应用于时间变化数据用例。此外，他们扩展了数据准备度概念，以更全面地考虑任务、解决方案和分布偏移（distribution shifts）问题。实验经验表明，这种方法有助于未来AI项目提高数据准备水平。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03805v1",
      "published_date": "2024-09-05 09:57:14 UTC",
      "updated_date": "2024-09-05 09:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:40:27.674707"
    },
    {
      "arxiv_id": "2409.03384v1",
      "title": "Hardware Acceleration of LLMs: A comprehensive survey and comparison",
      "title_zh": "翻译失败",
      "authors": [
        "Nikoletta Koilia",
        "Christoforos Kachris"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. In this paper, we present a\ncomprehensive survey of the several research efforts that have been presented\nfor the acceleration of transformer networks for Large Language Models using\nhardware accelerators.\n  The survey presents the frameworks that have been proposed and then performs\na qualitative and quantitative comparison regarding the technology, the\nprocessing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy\nefficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each\nframework. The main challenge in comparison is that every proposed scheme is\nimplemented on a different process technology making hard a fair comparison.\nThe main contribution of this paper is that we extrapolate the results of the\nperformance and the energy efficiency on the same technology to make a fair\ncomparison; one theoretical and one more practical. We implement part of the\nLLMs on several FPGA chips to extrapolate the results to the same process\ntechnology and then we make a fair comparison of the performance.",
      "tldr_zh": "这篇论文对使用硬件加速器加速大型语言模型(LLMs)的Transformer网络进行了全面调查，涵盖了各种框架在技术、处理平台(例如FPGA、ASIC、In-Memory、GPU)上的表现，包括加速比、能源效率(以GOPs和GOPs/W衡量)。主要挑战在于不同方案采用的工艺技术差异导致公平比较困难，因此作者通过理论外推和实际实现部分LLMs于FPGA芯片上，来统一技术节点进行定性和定量比较。论文的关键贡献是为硬件加速LLMs提供了更可靠的性能评估基准，促进了该领域的优化和创新。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "https://airtable.com/appC2VwR6X4EeZ50s/shrKwchys0iktvDwk",
      "pdf_url": "http://arxiv.org/pdf/2409.03384v1",
      "published_date": "2024-09-05 09:43:25 UTC",
      "updated_date": "2024-09-05 09:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:40:43.042629"
    },
    {
      "arxiv_id": "2409.03381v2",
      "title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Yongxin Deng",
        "Xihe Qiu",
        "Xiaoyu Tan",
        "Chao Qu",
        "Jing Pan",
        "Yuan Cheng",
        "Yinghui Xu",
        "Wei Chu"
      ],
      "abstract": "Cognitive psychology investigates perception, attention, memory, language,\nproblem-solving, decision-making, and reasoning. Kahneman's dual-system theory\nelucidates the human decision-making process, distinguishing between the rapid,\nintuitive System 1 and the deliberative, rational System 2. Recent advancements\nhave positioned large language Models (LLMs) as formidable tools nearing\nhuman-level proficiency in various cognitive tasks. Nonetheless, the presence\nof a dual-system framework analogous to human cognition in LLMs remains\nunexplored. This study introduces the \\textbf{CogniDual Framework for LLMs}\n(CFLLMs), designed to assess whether LLMs can, through self-training, evolve\nfrom deliberate deduction to intuitive responses, thereby emulating the human\nprocess of acquiring and mastering new information. Our findings reveal the\ncognitive mechanisms behind LLMs' response generation, enhancing our\nunderstanding of their capabilities in cognitive psychology. Practically,\nself-trained models can provide faster responses to certain queries, reducing\ncomputational demands during inference.",
      "tldr_zh": "本研究基于 Kahneman 的双系统理论（System 1 和 System 2），提出 CogniDual Framework for LLMs (CFLLMs)，旨在通过自训练机制让 Large Language Models (LLMs) 从 deliberate deduction 演变到 intuitive responses，从而提升其在认知任务（如感知、记忆和决策）中的表现。框架评估 LLMs 是否能模仿人类认知过程，揭示其响应生成的认知机制。实验结果显示，自训练模型能提供更快响应，显著减少推理时的计算需求，为 LLMs 在实际应用中实现更高效的认知处理奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03381v2",
      "published_date": "2024-09-05 09:33:24 UTC",
      "updated_date": "2024-09-06 09:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:40:52.087764"
    },
    {
      "arxiv_id": "2409.03377v3",
      "title": "Real-time Speech Enhancement on Raw Signals with Deep State-space Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Ru Pei",
        "Ritik Shrivastava",
        "FNU Sidharth"
      ],
      "abstract": "We present aTENNuate, a simple deep state-space autoencoder configured for\nefficient online raw speech enhancement in an end-to-end fashion. The network's\nperformance is primarily evaluated on raw speech denoising, with additional\nassessments on tasks such as super-resolution and de-quantization. We benchmark\naTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.\nThe network outperforms previous real-time denoising models in terms of PESQ\nscore, parameter count, MACs, and latency. Even as a raw waveform processing\nmodel, the model maintains high fidelity to the clean signal with minimal\naudible artifacts. In addition, the model remains performant even when the\nnoisy input is compressed down to 4000Hz and 4 bits, suggesting general speech\nenhancement capabilities in low-resource environments. Code is available at\ngithub.com/Brainchip-Inc/aTENNuate",
      "tldr_zh": "本研究提出 aTENNuate，一种基于 deep state-space autoencoder 的简单模型，用于实时端到端原始语音增强，主要针对去噪任务，同时评估超分辨率和去量化。\n在 VoiceBank + DEMAND 和 Microsoft DNS1 测试集上，该模型在 PESQ 分数、参数数量、MACs 和延迟方面优于现有实时去噪模型，并保持对干净信号的高保真度。\n此外，aTENNuate 即使在低资源环境（如压缩到 4000Hz 和 4 位）下，仍能有效提升语音质量。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03377v3",
      "published_date": "2024-09-05 09:28:56 UTC",
      "updated_date": "2024-12-29 22:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:41:05.079935"
    },
    {
      "arxiv_id": "2409.03375v1",
      "title": "Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco de Arriba-Pérez",
        "Silvia García-Méndez"
      ],
      "abstract": "Based on official estimates, 50 million people worldwide are affected by\ndementia, and this number increases by 10 million new patients every year.\nWithout a cure, clinical prognostication and early intervention represent the\nmost effective ways to delay its progression. To this end, Artificial\nIntelligence and computational linguistics can be exploited for natural\nlanguage analysis, personalized assessment, monitoring, and treatment. However,\ntraditional approaches need more semantic knowledge management and\nexplicability capabilities. Moreover, using Large Language Models (LLMs) for\ncognitive decline diagnosis is still scarce, even though these models represent\nthe most advanced way for clinical-patient communication using intelligent\nsystems. Consequently, we leverage an LLM using the latest Natural Language\nProcessing (NLP) techniques in a chatbot solution to provide interpretable\nMachine Learning prediction of cognitive decline in real-time.\nLinguistic-conceptual features are exploited for appropriate natural language\nanalysis. Through explainability, we aim to fight potential biases of the\nmodels and improve their potential to help clinical workers in their diagnosis\ndecisions. More in detail, the proposed pipeline is composed of (i) data\nextraction employing NLP-based prompt engineering; (ii) stream-based data\nprocessing including feature engineering, analysis, and selection; (iii)\nreal-time classification; and (iv) the explainability dashboard to provide\nvisual and natural language descriptions of the prediction outcome.\nClassification results exceed 80 % in all evaluation metrics, with a recall\nvalue for the mental deterioration class about 85 %. To sum up, we contribute\nwith an affordable, flexible, non-invasive, personalized diagnostic system to\nthis work.",
      "tldr_zh": "本研究利用 Large Language Models (LLMs) 和 Natural Language Processing (NLP) 技术，开发了一个实时聊天机器人系统，用于提供可解释的 Machine Learning 预测，以识别认知衰退。该系统通过 NLP-based prompt engineering 进行数据提取，结合流处理中的特征工程、分析和选择，实现实时分类，并配备解释性仪表板，提供视觉和自然语言描述以对抗模型偏差。实验结果显示，分类准确率超过80%，认知衰退类的召回率约85%。总体而言，该方法提供了一个负担得起、灵活、非侵入性的个性化诊断工具，帮助临床工作者进行早期干预和决策。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03375v1",
      "published_date": "2024-09-05 09:27:05 UTC",
      "updated_date": "2024-09-05 09:27:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:41:17.320742"
    },
    {
      "arxiv_id": "2409.03346v1",
      "title": "Sketch: A Toolkit for Streamlining LLM Operations",
      "title_zh": "Sketch：一种用于简化LLM操作的工具包",
      "authors": [
        "Xin Jiang",
        "Xiang Li",
        "Wenjia Ma",
        "Xuezhi Fang",
        "Yiqun Yao",
        "Naitong Yu",
        "Xuying Meng",
        "Peng Han",
        "Jing Li",
        "Aixin Sun",
        "Yequan Wang"
      ],
      "abstract": "Large language models (LLMs) represented by GPT family have achieved\nremarkable success. The characteristics of LLMs lie in their ability to\naccommodate a wide range of tasks through a generative approach. However, the\nflexibility of their output format poses challenges in controlling and\nharnessing the model's outputs, thereby constraining the application of LLMs in\nvarious domains. In this work, we present Sketch, an innovative toolkit\ndesigned to streamline LLM operations across diverse fields. Sketch comprises\nthe following components: (1) a suite of task description schemas and prompt\ntemplates encompassing various NLP tasks; (2) a user-friendly, interactive\nprocess for building structured output LLM services tailored to various NLP\ntasks; (3) an open-source dataset for output format control, along with tools\nfor dataset construction; and (4) an open-source model based on\nLLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting\ninstructions. We anticipate this initiative to bring considerable convenience\nto LLM users, achieving the goal of ''plug-and-play'' for various applications.\nThe components of Sketch will be progressively open-sourced at\nhttps://github.com/cofe-ai/Sketch.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)输出格式灵活但控制困难的问题，提出Sketch工具包，以简化LLMs在各种领域的操作。该工具包包括任务描述模式和提示模板、交互式构建结构化输出服务的流程、开源数据集及工具，以及基于LLaMA3-8B-Instruct的模型，用于提升输出格式的理解和遵守。Sketch旨在实现“plug-and-play”的应用便利性，所有组件将逐步开源于https://github.com/cofe-ai/Sketch。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03346v1",
      "published_date": "2024-09-05 08:45:44 UTC",
      "updated_date": "2024-09-05 08:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:41:26.943777"
    },
    {
      "arxiv_id": "2409.03320v1",
      "title": "YOLO-PPA based Efficient Traffic Sign Detection for Cruise Control in Autonomous Driving",
      "title_zh": "基于 YOLO-PPA 的高效交通标志检测，用于自动驾驶中的巡航控制",
      "authors": [
        "Jingyu Zhang",
        "Wenqing Zhang",
        "Chaoyi Tan",
        "Xiangtian Li",
        "Qianyi Sun"
      ],
      "abstract": "It is very important to detect traffic signs efficiently and accurately in\nautonomous driving systems. However, the farther the distance, the smaller the\ntraffic signs. Existing object detection algorithms can hardly detect these\nsmall scaled signs.In addition, the performance of embedded devices on vehicles\nlimits the scale of detection models.To address these challenges, a YOLO PPA\nbased traffic sign detection algorithm is proposed in this paper.The\nexperimental results on the GTSDB dataset show that compared to the original\nYOLO, the proposed method improves inference efficiency by 11.2%. The mAP 50 is\nalso improved by 93.2%, which demonstrates the effectiveness of the proposed\nYOLO PPA.",
      "tldr_zh": "这篇论文针对自动驾驶巡航控制中的交通标志检测问题，强调了检测远距离小尺寸标志的难度，以及车辆嵌入式设备性能的限制。作者提出了一种基于YOLO-PPA的检测算法，通过优化模型来提升效率和准确率。实验结果在GTSDB数据集上显示，与原始YOLO相比，该方法将推理效率提高了11.2%，并将mAP 50提高了93.2%，证明了其在实际应用中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03320v1",
      "published_date": "2024-09-05 07:49:21 UTC",
      "updated_date": "2024-09-05 07:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:41:40.148857"
    },
    {
      "arxiv_id": "2409.03295v1",
      "title": "N-gram Prediction and Word Difference Representations for Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "DongNyeong Heo",
        "Daniela Noemi Rim",
        "Heeyoul Choi"
      ],
      "abstract": "Causal language modeling (CLM) serves as the foundational framework\nunderpinning remarkable successes of recent large language models (LLMs).\nDespite its success, the training approach for next word prediction poses a\npotential risk of causing the model to overly focus on local dependencies\nwithin a sentence. While prior studies have been introduced to predict future N\nwords simultaneously, they were primarily applied to tasks such as masked\nlanguage modeling (MLM) and neural machine translation (NMT). In this study, we\nintroduce a simple N-gram prediction framework for the CLM task. Moreover, we\nintroduce word difference representation (WDR) as a surrogate and\ncontextualized target representation during model training on the basis of\nN-gram prediction framework. To further enhance the quality of next word\nprediction, we propose an ensemble method that incorporates the future N words'\nprediction results. Empirical evaluations across multiple benchmark datasets\nencompassing CLM and NMT tasks demonstrate the significant advantages of our\nproposed methods over the conventional CLM.",
      "tldr_zh": "本文针对 Causal Language Modeling (CLM) 中过度关注局部依赖的问题，提出了一种简单的 N-gram Prediction 框架，用于同时预测未来 N 个词。研究还引入 Word Difference Representation (WDR) 作为训练中的替代和上下文化目标，并提出一种 ensemble 方法来整合这些预测结果，以提升下一个词的预测质量。在多个基准数据集上的实验显示，该方法在 CLM 和 Neural Machine Translation (NMT) 任务上显著优于传统 CLM。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03295v1",
      "published_date": "2024-09-05 07:03:23 UTC",
      "updated_date": "2024-09-05 07:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:41:52.765281"
    },
    {
      "arxiv_id": "2409.03291v2",
      "title": "LLM Detectors Still Fall Short of Real World: Case of LLM-Generated Short News-Like Posts",
      "title_zh": "LLM",
      "authors": [
        "Henrique Da Silva Gameiro",
        "Andrei Kucharavy",
        "Ljiljana Dolamic"
      ],
      "abstract": "With the emergence of widely available powerful LLMs, disinformation\ngenerated by large Language Models (LLMs) has become a major concern.\nHistorically, LLM detectors have been touted as a solution, but their\neffectiveness in the real world is still to be proven. In this paper, we focus\non an important setting in information operations -- short news-like posts\ngenerated by moderately sophisticated attackers.\n  We demonstrate that existing LLM detectors, whether zero-shot or\npurpose-trained, are not ready for real-world use in that setting. All tested\nzero-shot detectors perform inconsistently with prior benchmarks and are highly\nvulnerable to sampling temperature increase, a trivial attack absent from\nrecent benchmarks. A purpose-trained detector generalizing across LLMs and\nunseen attacks can be developed, but it fails to generalize to new\nhuman-written texts.\n  We argue that the former indicates domain-specific benchmarking is needed,\nwhile the latter suggests a trade-off between the adversarial evasion\nresilience and overfitting to the reference human text, with both needing\nevaluation in benchmarks and currently absent. We believe this suggests a\nre-consideration of current LLM detector benchmarking approaches and provides a\ndynamically extensible benchmark to allow it\n(https://github.com/Reliable-Information-Lab-HEVS/benchmark_llm_texts_detection).",
      "tldr_zh": "这篇论文探讨了现有LLM detectors在检测由LLM生成的短新闻-like帖子时的不足，强调这些检测器在真实世界场景下表现不佳。作者测试了零-shot检测器，发现它们与先前基准不一致，且对采样温度增加这种简单攻击高度脆弱。研究还开发了一个针对特定LLM和攻击的训练检测器，但它无法泛化到新的真人文本。论文建议重新审视当前基准测试方法，并提供了一个动态可扩展的基准工具（https://github.com/Reliable-Information-Lab-HEVS/benchmark_llm_texts_detection），以平衡对抗性规避能力和避免过拟合。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "I.2.7; K.6.5"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 7 tables, 13 figures, under consideration for EMNLP",
      "pdf_url": "http://arxiv.org/pdf/2409.03291v2",
      "published_date": "2024-09-05 06:55:13 UTC",
      "updated_date": "2024-09-27 16:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:42:06.674926"
    },
    {
      "arxiv_id": "2409.03284v1",
      "title": "iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models",
      "title_zh": "iText2KG：使用大语言模型的增量知识图谱构建",
      "authors": [
        "Yassir Lairgi",
        "Ludovic Moncla",
        "Rémy Cazabet",
        "Khalid Benabdeslem",
        "Pierre Cléau"
      ],
      "abstract": "Most available data is unstructured, making it challenging to access valuable\ninformation. Automatically building Knowledge Graphs (KGs) is crucial for\nstructuring data and making it accessible, allowing users to search for\ninformation effectively. KGs also facilitate insights, inference, and\nreasoning. Traditional NLP methods, such as named entity recognition and\nrelation extraction, are key in information retrieval but face limitations,\nincluding the use of predefined entity types and the need for supervised\nlearning. Current research leverages large language models' capabilities, such\nas zero- or few-shot learning. However, unresolved and semantically duplicated\nentities and relations still pose challenges, leading to inconsistent graphs\nand requiring extensive post-processing. Additionally, most approaches are\ntopic-dependent. In this paper, we propose iText2KG, a method for incremental,\ntopic-independent KG construction without post-processing. This plug-and-play,\nzero-shot method is applicable across a wide range of KG construction scenarios\nand comprises four modules: Document Distiller, Incremental Entity Extractor,\nIncremental Relation Extractor, and Graph Integrator and Visualization. Our\nmethod demonstrates superior performance compared to baseline methods across\nthree scenarios: converting scientific papers to graphs, websites to graphs,\nand CVs to graphs.",
      "tldr_zh": "本研究针对非结构化数据构建 Knowledge Graphs (KGs) 的挑战，提出 iText2KG 方法，利用 Large Language Models 实现增量式、主题无关的 KG 构建，无需后处理。iText2KG 采用零样本（zero-shot）策略，包括四个模块：Document Distiller、Incremental Entity Extractor、Incremental Relation Extractor 和 Graph Integrator and Visualization，这些模块确保实体和关系的准确提取及整合。实验结果显示，该方法在科学论文、网站和简历等三种场景中，相比基线方法表现出色，有效解决了传统 NLP 方法如 named entity recognition 的局限性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at The International Web Information Systems Engineering\n  conference (the WISE conference) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.03284v1",
      "published_date": "2024-09-05 06:49:14 UTC",
      "updated_date": "2024-09-05 06:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:42:18.713018"
    },
    {
      "arxiv_id": "2409.03277v3",
      "title": "ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengzhuo Xu",
        "Bowen Qu",
        "Yiyan Qi",
        "Sinan Du",
        "Chengjin Xu",
        "Chun Yuan",
        "Jian Guo"
      ],
      "abstract": "Automatic chart understanding is crucial for content comprehension and\ndocument parsing. Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities in chart understanding through domain-specific\nalignment and fine-tuning. However, current MLLMs still struggle to provide\nfaithful data and reliable analysis only based on charts. To address it, we\npropose ChartMoE, which employs the Mixture of Expert (MoE) architecture to\nreplace the traditional linear projector to bridge the modality gap.\nSpecifically, we train several linear connectors through distinct alignment\ntasks, which are utilized as the foundational initialization parameters for\ndifferent experts. Additionally, we introduce ChartMoE-Align, a dataset with\nnearly 1 million chart-table-JSON-code quadruples to conduct three alignment\ntasks (chart-table/JSON/code). Combined with the vanilla connector, we\ninitialize different experts diversely and adopt high-quality knowledge\nlearning to further refine the MoE connector and LLM parameters. Extensive\nexperiments demonstrate the effectiveness of the MoE connector and our\ninitialization strategy, e.g., ChartMoE improves the accuracy of the previous\nstate-of-the-art from 80.48\\% to 84.64\\% on the ChartQA benchmark.",
      "tldr_zh": "该研究针对 Multimodal Large Language Models (MLLMs) 在图表理解中存在的忠实数据和可靠分析问题，提出 ChartMoE 框架，使用 Mixture of Expert (MoE) 架构替换传统线性投影器，以桥接模态差距。具体而言，ChartMoE 通过不同对齐任务训练多个线性连接器作为专家的初始参数，并引入 ChartMoE-Align 数据集（包含近 1 百万 chart-table-JSON-code 四元组）来执行 chart-table/JSON/code 等对齐任务，同时结合高质量知识学习优化 MoE 连接器和 LLM 参数。实验结果显示，该框架在 ChartQA 基准上将之前最先进模型的准确率从 80.48% 提高到 84.64%，证明了 MoE 连接器和初始化策略的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03277v3",
      "published_date": "2024-09-05 06:41:02 UTC",
      "updated_date": "2025-03-14 03:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:42:33.473963"
    },
    {
      "arxiv_id": "2409.03274v3",
      "title": "Recent Advances in Attack and Defense Approaches of Large Language Models",
      "title_zh": "大语言模型的攻击与防御方法的最新进展",
      "authors": [
        "Jing Cui",
        "Yishi Xu",
        "Zhewei Huang",
        "Shuchang Zhou",
        "Jianbin Jiao",
        "Junge Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence and\nmachine learning through their advanced text processing and generating\ncapabilities. However, their widespread deployment has raised significant\nsafety and reliability concerns. Established vulnerabilities in deep neural\nnetworks, coupled with emerging threat models, may compromise security\nevaluations and create a false sense of security. Given the extensive research\nin the field of LLM security, we believe that summarizing the current state of\naffairs will help the research community better understand the present\nlandscape and inform future developments. This paper reviews current research\non LLM vulnerabilities and threats, and evaluates the effectiveness of\ncontemporary defense mechanisms. We analyze recent studies on attack vectors\nand model weaknesses, providing insights into attack mechanisms and the\nevolving threat landscape. We also examine current defense strategies,\nhighlighting their strengths and limitations. By contrasting advancements in\nattack and defense methodologies, we identify research gaps and propose future\ndirections to enhance LLM security. Our goal is to advance the understanding of\nLLM safety challenges and guide the development of more robust security\nmeasures.",
      "tldr_zh": "这篇论文回顾了大型语言模型 (LLMs) 的安全挑战，包括模型漏洞、威胁模型和攻击向量，分析了这些问题如何影响其可靠性和部署。\n作者评估了当前防御策略的优缺点，并通过对比攻击和防御方法的发展，识别了研究空白。\n论文提出未来方向，以增强LLMs的安全措施，并指导更稳健的安全研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03274v3",
      "published_date": "2024-09-05 06:31:37 UTC",
      "updated_date": "2024-12-02 08:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:42:41.134042"
    },
    {
      "arxiv_id": "2409.03271v1",
      "title": "Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Wang",
        "Shiwan Zhao",
        "Zhihu Wang",
        "Heyuan Huang",
        "Ming Fan",
        "Yubo Zhang",
        "Zhixing Wang",
        "Haijun Wang",
        "Ting Liu"
      ],
      "abstract": "The Chain-of-Thought (CoT) paradigm has emerged as a critical approach for\nenhancing the reasoning capabilities of large language models (LLMs). However,\ndespite their widespread adoption and success, CoT methods often exhibit\ninstability due to their inability to consistently ensure the quality of\ngenerated reasoning paths, leading to sub-optimal reasoning performance. To\naddress this challenge, we propose the \\textbf{Strategic Chain-of-Thought}\n(SCoT), a novel methodology designed to refine LLM performance by integrating\nstrategic knowledge prior to generating intermediate reasoning steps. SCoT\nemploys a two-stage approach within a single prompt: first eliciting an\neffective problem-solving strategy, which is then used to guide the generation\nof high-quality CoT paths and final answers. Our experiments across eight\nchallenging reasoning datasets demonstrate significant improvements, including\na 21.05\\% increase on the GSM8K dataset and 24.13\\% on the Tracking\\_Objects\ndataset, respectively, using the Llama3-8b model. Additionally, we extend the\nSCoT framework to develop a few-shot method with automatically matched\ndemonstrations, yielding even stronger results. These findings underscore the\nefficacy of SCoT, highlighting its potential to substantially enhance LLM\nperformance in complex reasoning tasks.",
      "tldr_zh": "该论文提出 Strategic Chain-of-Thought (SCoT)，一种新方法，通过在生成中间推理步骤前提取有效的解决策略，来提升大型语言模型 (LLMs) 的推理准确性和稳定性，解决传统 Chain-of-Thought (CoT) 方法的质量不一致问题。SCoT 采用单提示的两阶段框架：首先提取问题解决策略，然后用该策略指导高质量 CoT 路径和最终答案的生成。实验在八个挑战性数据集上显示显著改进，使用 Llama3-8b 模型，在 GSM8K 上提升 21.05%、在 Tracking_Objects 上提升 24.13%；此外，扩展的 few-shot 方法通过自动匹配演示进一步增强了性能。这些结果突显了 SCoT 在复杂推理任务中提升 LLM 能力的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03271v1",
      "published_date": "2024-09-05 06:28:05 UTC",
      "updated_date": "2024-09-05 06:28:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:42:57.329878"
    },
    {
      "arxiv_id": "2409.13701v2",
      "title": "CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat Interaction",
      "title_zh": "CA",
      "authors": [
        "Minghao Liu",
        "Mingxiu Sui",
        "Yi Nan",
        "Cangqing Wang",
        "Zhijie Zhou"
      ],
      "abstract": "Effective communication in automated chat systems hinges on the ability to\nunderstand and respond to context. Traditional models often struggle with\ndetermining when additional context is necessary for generating appropriate\nresponses. This paper introduces Context-Aware BERT (CA-BERT), a\ntransformer-based model specifically fine-tuned to address this challenge.\nCA-BERT innovatively applies deep learning techniques to discern context\nnecessity in multi-turn chat interactions, enhancing both the relevance and\naccuracy of responses.\n  We describe the development of CA-BERT, which adapts the robust architecture\nof BERT with a novel training regimen focused on a specialized dataset of chat\ndialogues. The model is evaluated on its ability to classify context necessity,\ndemonstrating superior performance over baseline BERT models in terms of\naccuracy and efficiency. Furthermore, CA-BERT's implementation showcases\nsignificant reductions in training time and resource usage, making it feasible\nfor real-time applications.\n  The results indicate that CA-BERT can effectively enhance the functionality\nof chatbots by providing a nuanced understanding of context, thereby improving\nuser experience and interaction quality in automated systems. This study not\nonly advances the field of NLP in chat applications but also provides a\nframework for future research into context-sensitive AI developments.",
      "tldr_zh": "这篇论文介绍了 CA-BERT，一种基于 Transformer 的模型，旨在提升多轮聊天互动中的上下文感知能力，以解决传统模型在判断上下文必要性时的不足。CA-BERT 通过对 BERT 架构进行细调，并采用新型训练方法和专属聊天对话数据集，实现了对上下文需求的精准分类，并在实验中表现出比基线 BERT 模型更高的准确性和效率，同时减少了训练时间和资源消耗。研究结果显示，CA-BERT 显著改善了聊天机器人的响应相关性，提升了用户体验，并为 NLP 领域的上下文敏感 AI 发展提供了重要框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted by ICBASE 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.13701v2",
      "published_date": "2024-09-05 06:27:59 UTC",
      "updated_date": "2024-10-01 20:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:43:06.568018"
    },
    {
      "arxiv_id": "2409.03261v1",
      "title": "Bones Can't Be Triangles: Accurate and Efficient Vertebrae Keypoint Estimation through Collaborative Error Revision",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhee Kim",
        "Taesung Kim",
        "Jaegul Choo"
      ],
      "abstract": "Recent advances in interactive keypoint estimation methods have enhanced\naccuracy while minimizing user intervention. However, these methods require\nuser input for error correction, which can be costly in vertebrae keypoint\nestimation where inaccurate keypoints are densely clustered or overlap. We\nintroduce a novel approach, KeyBot, specifically designed to identify and\ncorrect significant and typical errors in existing models, akin to user\nrevision. By characterizing typical error types and using simulated errors for\ntraining, KeyBot effectively corrects these errors and significantly reduces\nuser workload. Comprehensive quantitative and qualitative evaluations on three\npublic datasets confirm that KeyBot significantly outperforms existing methods,\nachieving state-of-the-art performance in interactive vertebrae keypoint\nestimation. The source code and demo video are available at:\nhttps://ts-kim.github.io/KeyBot/",
      "tldr_zh": "该研究针对脊椎关键点估计中的错误密集问题，提出了一种名为 KeyBot 的新型方法，通过表征典型错误类型并使用模拟错误进行训练，实现自动错误识别和纠正，从而减少用户干预。KeyBot 类似于用户修订过程，但更高效准确，在三个公共数据集上进行了全面定量和定性评估，显著优于现有方法并达到了最先进的交互式 vertebrae keypoint estimation 性能。该方法为精确高效的关键点估计提供了新途径，并附带了源代码和演示视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, ECCV 2024, Project Page: https://ts-kim.github.io/KeyBot/",
      "pdf_url": "http://arxiv.org/pdf/2409.03261v1",
      "published_date": "2024-09-05 06:03:52 UTC",
      "updated_date": "2024-09-05 06:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:43:17.693163"
    },
    {
      "arxiv_id": "2409.03260v2",
      "title": "In Search of Trees: Decision-Tree Policy Synthesis for Black-Box Systems via Search",
      "title_zh": "翻译失败",
      "authors": [
        "Emir Demirović",
        "Christian Schilling",
        "Anna Lukina"
      ],
      "abstract": "Decision trees, owing to their interpretability, are attractive as control\npolicies for (dynamical) systems. Unfortunately, constructing, or synthesising,\nsuch policies is a challenging task. Previous approaches do so by imitating a\nneural-network policy, approximating a tabular policy obtained via formal\nsynthesis, employing reinforcement learning, or modelling the problem as a\nmixed-integer linear program. However, these works may require access to a\nhard-to-obtain accurate policy or a formal model of the environment (within\nreach of formal synthesis), and may not provide guarantees on the quality or\nsize of the final tree policy. In contrast, we present an approach to\nsynthesise optimal decision-tree policies given a deterministic black-box\nenvironment and specification, a discretisation of the tree predicates, and an\ninitial set of states, where optimality is defined with respect to the number\nof steps to achieve the goal. Our approach is a specialised search algorithm\nwhich systematically explores the (exponentially large) space of decision trees\nunder the given discretisation. The key component is a novel trace-based\npruning mechanism that significantly reduces the search space. Our approach\nrepresents a conceptually novel way of synthesising small decision-tree\npolicies with optimality guarantees even for black-box environments with\nblack-box specifications.",
      "tldr_zh": "本研究针对黑-box systems的控制问题，提出了一种通过搜索算法合成最优decision-tree policies的方法，以决策树的可解释性作为优势。方法基于一个专门的搜索算法，系统探索给定离散化谓词和初始状态集下的决策树空间，并引入novel trace-based pruning mechanism来显著减少搜索空间，从而确保策略的最优性（以达到目标的步数最小为标准）。与现有方法不同，该方法无需精确策略或正式模型，即可为black-box environments和specifications合成小型、高质量的决策树策略，提供可靠的优化保证。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages main text incl. references, 2 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2409.03260v2",
      "published_date": "2024-09-05 05:51:42 UTC",
      "updated_date": "2025-01-07 11:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:43:29.649729"
    },
    {
      "arxiv_id": "2409.03257v3",
      "title": "Understanding LLM Development Through Longitudinal Study: Insights from the Open Ko-LLM Leaderboard",
      "title_zh": "通过纵向研究理解大语言模型的发展：来自 Open Ko-LLM Leaderboard 的见解",
      "authors": [
        "Chanjun Park",
        "Hyeonwoo Kim"
      ],
      "abstract": "This paper conducts a longitudinal study over eleven months to address the\nlimitations of prior research on the Open Ko-LLM Leaderboard, which have relied\non empirical studies with restricted observation periods of only five months.\nBy extending the analysis duration, we aim to provide a more comprehensive\nunderstanding of the progression in developing Korean large language models\n(LLMs). Our study is guided by three primary research questions: (1) What are\nthe specific challenges in improving LLM performance across diverse tasks on\nthe Open Ko-LLM Leaderboard over time? (2) How does model size impact task\nperformance correlations across various benchmarks? (3) How have the patterns\nin leaderboard rankings shifted over time on the Open Ko-LLM Leaderboard?. By\nanalyzing 1,769 models over this period, our research offers a comprehensive\nexamination of the ongoing advancements in LLMs and the evolving nature of\nevaluation frameworks.",
      "tldr_zh": "这篇论文通过为期11个月的纵向研究，分析Open Ko-LLM Leaderboard上的1,769个模型，弥补了先前研究仅观察5个月的局限性，以更全面地理解韩国LLM（Large Language Models）的开发进展。研究聚焦三个关键问题：改善LLM在多样任务中的性能面临的挑战、模型大小对任务性能相关性的影响，以及排行榜排名模式随时间的演变。最终，该研究揭示了LLM持续进步的动态，并强调了评估框架的演化重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Industry",
      "pdf_url": "http://arxiv.org/pdf/2409.03257v3",
      "published_date": "2024-09-05 05:31:29 UTC",
      "updated_date": "2025-03-04 01:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:43:42.056267"
    },
    {
      "arxiv_id": "2409.03256v2",
      "title": "E2CL: Exploration-based Error Correction Learning for Embodied Agents",
      "title_zh": "E2CL：基于探索的错误修正学习用于具身代理",
      "authors": [
        "Hanlin Wang",
        "Chak Tou Leong",
        "Jian Wang",
        "Wenjie Li"
      ],
      "abstract": "Language models are exhibiting increasing capability in knowledge utilization\nand reasoning. However, when applied as agents in embodied environments, they\noften suffer from misalignment between their intrinsic knowledge and\nenvironmental knowledge, leading to infeasible actions. Traditional environment\nalignment methods, such as supervised learning on expert trajectories and\nreinforcement learning, encounter limitations in covering environmental\nknowledge and achieving efficient convergence, respectively. Inspired by human\nlearning, we propose Exploration-based Error Correction Learning (E2CL), a\nnovel framework that leverages exploration-induced errors and environmental\nfeedback to enhance environment alignment for embodied agents. E2CL\nincorporates teacher-guided and teacher-free explorations to gather\nenvironmental feedback and correct erroneous actions. The agent learns to\nprovide feedback and self-correct, thereby enhancing its adaptability to target\nenvironments. Extensive experiments in the VirtualHome environment demonstrate\nthat E2CL-trained agents outperform those trained by baseline methods and\nexhibit superior self-correction capabilities.",
      "tldr_zh": "该研究针对语言模型在具身环境（Embodied Agents）中因内在知识与环境知识不匹配而导致不可行动作的问题，提出了一种新型框架E2CL（Exploration-based Error Correction Learning）。E2CL通过教师引导和无教师探索来收集环境反馈，引导代理从探索诱导的错误中学习提供反馈并自我修正，从而提升其环境适应性。与传统监督学习和强化学习方法相比，这种方法更有效地覆盖环境知识并实现高效收敛。在VirtualHome环境中的广泛实验表明，E2CL训练的代理在性能上优于基线方法，并展示了出色的自我修正能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.03256v2",
      "published_date": "2024-09-05 05:22:27 UTC",
      "updated_date": "2024-09-29 06:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:43:53.714559"
    },
    {
      "arxiv_id": "2409.03254v1",
      "title": "Granular-ball Representation Learning for Deep CNN on Learning with Label Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Dai",
        "Hao Zhu",
        "Shuyin Xia",
        "Guoyin Wang"
      ],
      "abstract": "In actual scenarios, whether manually or automatically annotated, label noise\nis inevitably generated in the training data, which can affect the\neffectiveness of deep CNN models. The popular solutions require data cleaning\nor designing additional optimizations to punish the data with mislabeled data,\nthereby enhancing the robustness of models. However, these methods come at the\ncost of weakening or even losing some data during the training process. As we\nknow, content is the inherent attribute of an image that does not change with\nchanges in annotations. In this study, we propose a general granular-ball\ncomputing (GBC) module that can be embedded into a CNN model, where the\nclassifier finally predicts the label of granular-ball ($gb$) samples instead\nof each individual samples. Specifically, considering the classification task:\n(1) in forward process, we split the input samples as $gb$ samples at\nfeature-level, each of which can correspond to multiple samples with varying\nnumbers and share one single label; (2) during the backpropagation process, we\nmodify the gradient allocation strategy of the GBC module to enable it to\npropagate normally; and (3) we develop an experience replay policy to ensure\nthe stability of the training process. Experiments demonstrate that the\nproposed method can improve the robustness of CNN models with no additional\ndata or optimization.",
      "tldr_zh": "该研究针对深度 CNN 模型在标签噪声下的鲁棒性问题，提出了一种通用的 granular-ball computing (GBC) 模块，可嵌入 CNN 模型中，以 granular-ball (gb) 样本代替单个样本进行分类，从而避免数据损失。方法包括：在前向过程将输入样本在特征级别分割为 gb 样本，每个 gb 样本对应多个样本并共享一个标签；在反向传播过程中修改 GBC 模块的梯度分配策略；并引入 experience replay 政策以确保训练稳定性。实验结果表明，该方法无需额外数据或优化即可显著提升 CNN 模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03254v1",
      "published_date": "2024-09-05 05:18:31 UTC",
      "updated_date": "2024-09-05 05:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:44:10.109860"
    },
    {
      "arxiv_id": "2409.03239v1",
      "title": "DiffGrad for Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jamshaid Ul Rahman",
        "Nimra"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are regarded as state-of-the-art\ntools for addressing highly nonlinear problems based on partial differential\nequations. Despite their broad range of applications, PINNs encounter several\nperformance challenges, including issues related to efficiency, minimization of\ncomputational cost, and enhancement of accuracy. Burgers' equation, a\nfundamental equation in fluid dynamics that is extensively used in PINNs,\nprovides flexible results with the Adam optimizer that does not account for\npast gradients. This paper introduces a novel strategy for solving Burgers'\nequation by incorporating DiffGrad with PINNs, a method that leverages the\ndifference between current and immediately preceding gradients to enhance\nperformance. A comprehensive computational analysis is conducted using\noptimizers such as Adam, Adamax, RMSprop, and DiffGrad to evaluate and compare\ntheir effectiveness. Our approach includes visualizing the solutions over space\nat various time intervals to demonstrate the accuracy of the network. The\nresults show that DiffGrad not only improves the accuracy of the solution but\nalso reduces training time compared to the other optimizers.",
      "tldr_zh": "本论文针对 Physics-Informed Neural Networks (PINNs) 在处理偏微分方程问题时存在的效率、计算成本和准确性挑战，提出了一种新策略：将 DiffGrad 优化器整合到 PINNs 中，利用当前梯度和前一个梯度的差异来提升性能，特别是应用于 Burgers' equation。研究通过比较 Adam、Adamax、RMSprop 和 DiffGrad 等优化器，进行全面计算分析并可视化解决方案在不同时间间隔的空间分布。结果表明，DiffGrad 不仅显著提高了解决方案的准确性，还减少了训练时间，为 PINNs 的优化提供了有效方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.03239v1",
      "published_date": "2024-09-05 04:39:35 UTC",
      "updated_date": "2024-09-05 04:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:44:19.099767"
    },
    {
      "arxiv_id": "2409.03219v1",
      "title": "Content Moderation by LLM: From Accuracy to Legitimacy",
      "title_zh": "LLM的内容审核：从准确性到合法性",
      "authors": [
        "Tao Huang"
      ],
      "abstract": "One trending application of LLM (large language model) is to use it for\ncontent moderation in online platforms. Most current studies on this\napplication have focused on the metric of accuracy - the extent to which LLM\nmakes correct decisions about content. This article argues that accuracy is\ninsufficient and misleading, because it fails to grasp the distinction between\neasy cases and hard cases as well as the inevitable trade-offs in achieving\nhigher accuracy. Closer examination reveals that content moderation is a\nconstitutive part of platform governance, the key of which is to gain and\nenhance legitimacy. Instead of making moderation decisions correct, the chief\ngoal of LLM is to make them legitimate. In this regard, this article proposes a\nparadigm shift from the single benchmark of accuracy towards a legitimacy-based\nframework of evaluating the performance of LLM moderators. The framework\nsuggests that for easy cases, the key is to ensure accuracy, speed and\ntransparency, while for hard cases, what matters is reasoned justification and\nuser participation. Examined under this framework, LLM's real potential in\nmoderation is not accuracy improvement. Rather, LLM can better contribute in\nfour other aspects: to conduct screening of hard cases from easy cases, to\nprovide quality explanations for moderation decisions, to assist human\nreviewers in getting more contextual information, and to facilitate user\nparticipation in a more interactive way. Using normative theories from law and\nsocial sciences to critically assess the new technological application, this\narticle seeks to redefine LLM's role in content moderation and redirect\nrelevant research in this field.",
      "tldr_zh": "这篇论文批评了当前使用大型语言模型 (LLM) 进行内容审核时过度依赖准确率 (accuracy) 的评估方法，认为它忽略了简单案例和复杂案例的区别以及不可避免的权衡问题。作者主张将焦点转向合法性 (legitimacy) 框架，提出一个新评估体系：对于简单案例，强调准确率、速度和透明度；对于复杂案例，则优先考虑推理 justification 和用户参与。最终，论文重新定义了 LLM 的角色，指出其最大潜力在于筛选复杂案例、提供高质量解释、辅助人类审查者和增强用户互动，从而为内容审核研究提供新方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03219v1",
      "published_date": "2024-09-05 03:33:54 UTC",
      "updated_date": "2024-09-05 03:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:44:31.006927"
    },
    {
      "arxiv_id": "2409.03215v1",
      "title": "xLAM: A Family of Large Action Models to Empower AI Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jianguo Zhang",
        "Tian Lan",
        "Ming Zhu",
        "Zuxin Liu",
        "Thai Hoang",
        "Shirley Kokane",
        "Weiran Yao",
        "Juntao Tan",
        "Akshara Prabhakar",
        "Haolin Chen",
        "Zhiwei Liu",
        "Yihao Feng",
        "Tulika Awalgaonkar",
        "Rithesh Murthy",
        "Eric Hu",
        "Zeyuan Chen",
        "Ran Xu",
        "Juan Carlos Niebles",
        "Shelby Heinecke",
        "Huan Wang",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) have attracted\nsignificant research interest. However, the open-source community faces many\nchallenges in developing specialized models for agent tasks, driven by the\nscarcity of high-quality agent datasets and the absence of standard protocols\nin this area. We introduce and publicly release xLAM, a series of large action\nmodels designed for AI agent tasks. The xLAM series includes five models with\nboth dense and mixture-of-expert architectures, ranging from 1B to 8x22B\nparameters, trained using a scalable, flexible pipeline that unifies, augments,\nand synthesizes diverse datasets to enhance AI agents' generalizability and\nperformance across varied environments. Our experimental results demonstrate\nthat xLAM consistently delivers exceptional performance across multiple agent\nability benchmarks, notably securing the 1st position on the Berkeley\nFunction-Calling Leaderboard, outperforming GPT-4, Claude-3, and many other\nmodels in terms of tool use. By releasing the xLAM series, we aim to advance\nthe performance of open-source LLMs for autonomous AI agents, potentially\naccelerating progress and democratizing access to high-performance models for\nagent tasks. Models are available at\nhttps://huggingface.co/collections/Salesforce/xlam-models-65f00e2a0a63bbcd1c2dade4",
      "tldr_zh": "这篇论文介绍了 xLAM，一系列针对 AI 代理任务设计的大型行动模型（Large Action Models），旨在解决开源社区在开发代理专用模型时面临的高质量数据集稀缺和标准协议缺失等问题。xLAM 系列包含五个模型，包括密集和混合专家架构，从 1B 到 8x22B 参数，通过一个可扩展的训练管道统一、增强和合成多样数据集，以提升 AI 代理的泛化性和性能。实验结果显示，xLAM 在多个代理能力基准上表现出色，尤其在 Berkeley Function-Calling Leaderboard 上排名第一，超越 GPT-4 和 Claude-3 等模型的工具使用能力。通过开源发布 xLAM 系列，论文旨在推动开源 LLMs 在自主 AI 代理领域的进步，并促进高性能模型的民主化访问。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical report for the Salesforce xLAM model series",
      "pdf_url": "http://arxiv.org/pdf/2409.03215v1",
      "published_date": "2024-09-05 03:22:22 UTC",
      "updated_date": "2024-09-05 03:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:44:45.142187"
    },
    {
      "arxiv_id": "2409.03206v1",
      "title": "TC-LLaVA: Rethinking the Transfer from Image to Video Understanding with Temporal Considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Mingze Gao",
        "Jingyu Liu",
        "Mingda Li",
        "Jiangtao Xie",
        "Qingbin Liu",
        "Bo Zhao",
        "Xi Chen",
        "Hui Xiong"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have significantly improved\nperformance across various image-language applications. Recently, there has\nbeen a growing interest in adapting image pre-trained MLLMs for video-related\ntasks. However, most efforts concentrate on enhancing the vision encoder and\nprojector components, while the core part, Large Language Models (LLMs),\nremains comparatively under-explored. In this paper, we propose two strategies\nto enhance the model's capability in video understanding tasks by improving\ninter-layer attention computation in LLMs. Specifically, the first approach\nfocuses on the enhancement of Rotary Position Embedding (RoPE) with\nTemporal-Aware Dual RoPE, which introduces temporal position information to\nstrengthen the MLLM's temporal modeling capabilities while preserving the\nrelative position relationships of both visual and text tokens. The second\napproach involves enhancing the Attention Mask with the Frame-wise Block Causal\nAttention Mask, a simple yet effective method that broadens visual token\ninteractions within and across video frames while maintaining the causal\ninference mechanism. Based on these proposed methods, we adapt LLaVA for video\nunderstanding tasks, naming it Temporal-Considered LLaVA (TC-LLaVA). Our\nTC-LLaVA achieves new state-of-the-art performance across various video\nunderstanding benchmarks with only supervised fine-tuning (SFT) on\nvideo-related datasets.",
      "tldr_zh": "该论文重新审视了多模态大语言模型(MLLMs)从图像理解向视频理解的迁移问题，重点探索Large Language Models (LLMs)的改进。作者提出两种策略：Temporal-Aware Dual RoPE增强Rotary Position Embedding (RoPE)，通过引入时间位置信息来强化模型的时序建模能力，同时保持视觉和文本标记的相对位置关系；以及Frame-wise Block Causal Attention Mask，通过扩展视觉标记的交互范围来促进帧内和帧间的信息交换，同时保留因果推理机制。基于这些方法，论文改进了LLaVA模型，开发出Temporal-Considered LLaVA (TC-LLaVA)，该模型仅通过在视频相关数据集上的Supervised Fine-Tuning (SFT)便在多种视频理解基准上达到了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03206v1",
      "published_date": "2024-09-05 02:54:17 UTC",
      "updated_date": "2024-09-05 02:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:44:56.785060"
    },
    {
      "arxiv_id": "2409.03203v2",
      "title": "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuowei Chen",
        "Lianxi Wang",
        "Yuben Wu",
        "Xinfeng Liao",
        "Yujia Tian",
        "Junyang Zhong"
      ],
      "abstract": "Sentiment classification (SC) often suffers from low-resource challenges such\nas domain-specific contexts, imbalanced label distributions, and few-shot\nscenarios. The potential of the diffusion language model (LM) for textual data\naugmentation (DA) remains unexplored, moreover, textual DA methods struggle to\nbalance the diversity and consistency of new samples. Most DA methods either\nperform logical modifications or rephrase less important tokens in the original\nsequence with the language model. In the context of SC, strong emotional tokens\ncould act critically on the sentiment of the whole sequence. Therefore,\ncontrary to rephrasing less important context, we propose DiffusionCLS to\nleverage a diffusion LM to capture in-domain knowledge and generate pseudo\nsamples by reconstructing strong label-related tokens. This approach ensures a\nbalance between consistency and diversity, avoiding the introduction of noise\nand augmenting crucial features of datasets. DiffusionCLS also comprises a\nNoise-Resistant Training objective to help the model generalize. Experiments\ndemonstrate the effectiveness of our method in various low-resource scenarios\nincluding domain-specific and domain-general problems. Ablation studies confirm\nthe effectiveness of our framework's modules, and visualization studies\nhighlight optimal deployment conditions, reinforcing our conclusions.",
      "tldr_zh": "该研究针对低资源情感分类（Sentiment Classification）中的挑战，如特定领域上下文、不平衡标签分布和少样本场景，提出了一种有效的数据增强（Data Augmentation）方法DiffusionCLS。DiffusionCLS利用扩散语言模型（Diffusion LM）重构强标签相关tokens生成伪样本，从而平衡新样本的多样性和一致性，同时引入Noise-Resistant Training目标以提升模型泛化能力。实验结果显示，该方法在各种低资源场景中表现出色，消融实验和可视化分析进一步验证了其框架模块的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03203v2",
      "published_date": "2024-09-05 02:51:28 UTC",
      "updated_date": "2024-09-23 12:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:45:06.182098"
    },
    {
      "arxiv_id": "2409.13700v1",
      "title": "MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqian Wu",
        "Yuhong Peng",
        "Jiapeng Yu",
        "Raymond S. T. Lee"
      ],
      "abstract": "LLM-based Multi-Agent Systems have potential benefits of complex\ndecision-making tasks management across various domains but their applications\nin the next Point-of-Interest (POI) recommendation remain underexplored. This\npaper proposes a novel MAS4POI system designed to enhance next POI\nrecommendations through multi-agent interactions. MAS4POI supports Large\nLanguage Models (LLMs) specializing in distinct agents such as DataAgent,\nManager, Analyst, and Navigator with each contributes to a collaborative\nprocess of generating the next POI recommendations.The system is examined by\nintegrating six distinct LLMs and evaluated by two real-world datasets for\nrecommendation accuracy improvement in real-world scenarios. Our code is\navailable at https://github.com/yuqian2003/MAS4POI.",
      "tldr_zh": "这篇论文提出了 MAS4POI，一种基于 LLM 的多智能体协作系统，旨在提升下一个 Point-of-Interest (POI) 推荐的准确性。系统由多个专门代理组成，包括 DataAgent 处理数据、Manager 协调流程、Analyst 进行分析以及 Navigator 提供导航支持，这些代理通过协作交互生成推荐结果。该系统整合了六种不同 LLM，并在两个真实数据集上进行了评估，展示了显著的推荐性能改进，并提供了开源代码（https://github.com/yuqian2003/MAS4POI）。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.13700v1",
      "published_date": "2024-09-05 02:47:49 UTC",
      "updated_date": "2024-09-05 02:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:45:19.196836"
    },
    {
      "arxiv_id": "2409.03183v1",
      "title": "Bypassing DARCY Defense: Indistinguishable Universal Adversarial Triggers",
      "title_zh": "绕过 DARCY 防御：不可区分的通用对抗触发器",
      "authors": [
        "Zuquan Peng",
        "Yuanyuan He",
        "Jianbing Ni",
        "Ben Niu"
      ],
      "abstract": "Neural networks (NN) classification models for Natural Language Processing\n(NLP) are vulnerable to the Universal Adversarial Triggers (UAT) attack that\ntriggers a model to produce a specific prediction for any input. DARCY borrows\nthe \"honeypot\" concept to bait multiple trapdoors, effectively detecting the\nadversarial examples generated by UAT. Unfortunately, we find a new UAT\ngeneration method, called IndisUAT, which produces triggers (i.e., tokens) and\nuses them to craft adversarial examples whose feature distribution is\nindistinguishable from that of the benign examples in a randomly-chosen\ncategory at the detection layer of DARCY. The produced adversarial examples\nincur the maximal loss of predicting results in the DARCY-protected models.\nMeanwhile, the produced triggers are effective in black-box models for text\ngeneration, text inference, and reading comprehension. Finally, the evaluation\nresults under NN models for NLP tasks indicate that the IndisUAT method can\neffectively circumvent DARCY and penetrate other defenses. For example,\nIndisUAT can reduce the true positive rate of DARCY's detection by at least\n40.8% and 90.6%, and drop the accuracy by at least 33.3% and 51.6% in the RNN\nand CNN models, respectively. IndisUAT reduces the accuracy of the BERT's\nadversarial defense model by at least 34.0%, and makes the GPT-2 language model\nspew racist outputs even when conditioned on non-racial context.",
      "tldr_zh": "这篇论文提出了一种名为IndisUAT的新方法，用于生成Universal Adversarial Triggers (UAT)，这些触发器能使对抗样本在特征分布上与正常样本不可区分，从而绕过DARCY防御机制。IndisUAT通过创建有效的触发器，最大化地破坏NLP模型的预测准确性，并在黑盒模型中适用于文本生成、推理和阅读理解任务。实验结果显示，IndisUAT能将DARCY的真阳性率降低至少40.8%和90.6%，并使RNN、CNN和BERT模型的准确率分别下降至少33.3%、51.6%和34.0%，从而暴露了现有防御的脆弱性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.03183v1",
      "published_date": "2024-09-05 02:19:34 UTC",
      "updated_date": "2024-09-05 02:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:45:32.038724"
    },
    {
      "arxiv_id": "2409.03167v2",
      "title": "InfraLib: Enabling Reinforcement Learning and Decision-Making for Large-Scale Infrastructure Management",
      "title_zh": "翻译失败",
      "authors": [
        "Pranay Thangeda",
        "Trevor S. Betz",
        "Michael N. Grussing",
        "Melkior Ornik"
      ],
      "abstract": "Efficient management of infrastructure systems is crucial for economic\nstability, sustainability, and public safety. However, infrastructure\nsustainment is challenging due to the vast scale of systems, stochastic\ndeterioration of components, partial observability, and resource constraints.\nDecision-making strategies that rely solely on human judgment often result in\nsuboptimal decisions over large scales and long horizons. While data-driven\napproaches like reinforcement learning offer promising solutions, their\napplication has been limited by the lack of suitable simulation environments.\nWe present InfraLib, an open-source modular and extensible framework that\nenables modeling and analyzing infrastructure management problems with resource\nconstraints as sequential decision-making problems. The framework implements\nhierarchical, stochastic deterioration models, supports realistic partial\nobservability, and handles practical constraints including cyclical budgets and\ncomponent unavailability. InfraLib provides standardized environments for\nbenchmarking decision-making approaches, along with tools for expert data\ncollection and policy evaluation. Through case studies on both synthetic\nbenchmarks and real-world road networks, we demonstrate InfraLib's ability to\nmodel diverse infrastructure management scenarios while maintaining\ncomputational efficiency at scale.",
      "tldr_zh": "该研究针对大规模基础设施管理的挑战（如系统规模大、组件随机退化、部分可观察性和资源限制）提出InfraLib，一个开源、模块化和可扩展的框架。InfraLib将基础设施管理问题建模为顺序决策问题，实现了层次化随机退化模型，支持部分可观察性，并处理实际约束如周期性预算和组件不可用。该框架提供标准化环境用于基准测试Reinforcement Learning等决策方法，以及工具支持专家数据收集和策略评估；通过合成基准和真实世界道路网络的案例研究，证明了InfraLib在多样场景中的建模能力和计算效率。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated preprint under active review",
      "pdf_url": "http://arxiv.org/pdf/2409.03167v2",
      "published_date": "2024-09-05 01:54:29 UTC",
      "updated_date": "2024-12-16 20:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:45:43.166101"
    },
    {
      "arxiv_id": "2409.03166v2",
      "title": "Continual Skill and Task Learning via Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Weiwei Gu",
        "Suresh Kondepudi",
        "Lixiao Huang",
        "Nakul Gopalan"
      ],
      "abstract": "Continual and interactive robot learning is a challenging problem as the\nrobot is present with human users who expect the robot to learn novel skills to\nsolve novel tasks perpetually with sample efficiency. In this work we present a\nframework for robots to query and learn visuo-motor robot skills and task\nrelevant information via natural language dialog interactions with human users.\nPrevious approaches either focus on improving the performance of instruction\nfollowing agents, or passively learn novel skills or concepts. Instead, we used\ndialog combined with a language-skill grounding embedding to query or confirm\nskills and/or tasks requested by a user. To achieve this goal, we developed and\nintegrated three different components for our agent. Firstly, we propose a\nnovel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA),\nwhich enables the existing SoTA ACT model to perform few-shot continual\nlearning. Secondly, we develop an alignment model that projects demonstrations\nacross skill embodiments into a shared embedding allowing us to know when to\nask questions and/or demonstrations from users. Finally, we integrated an\nexisting LLM to interact with a human user to perform grounded interactive\ncontinual skill learning to solve a task. Our ACT-LoRA model learns novel\nfine-tuned skills with a 100% accuracy when trained with only five\ndemonstrations for a novel skill while still maintaining a 74.75% accuracy on\npre-trained skills in the RLBench dataset where other models fall significantly\nshort. We also performed a human-subjects study with 8 subjects to demonstrate\nthe continual learning capabilities of our combined framework. We achieve a\nsuccess rate of 75% in the task of sandwich making with the real robot learning\nfrom participant data demonstrating that robots can learn novel skills or task\nknowledge from dialogue with non-expert users using our approach.",
      "tldr_zh": "这篇论文提出了一种通过自然语言对话的框架，让机器人与人类互动，以高效持续学习视觉-运动技能和任务相关信息。框架整合了三个关键组件：ACT with Low Rank Adaptation (ACT-LoRA) 模型，支持少样本持续学习；一个 alignment 模型，将不同技能演示投影到共享嵌入空间以决定何时查询用户；以及现有 LLM 用于进行对话互动。实验结果显示，ACT-LoRA 在 RLBench 数据集上仅需五个演示即可以 100% 准确率学习新技能，同时保持 74.75% 的预训练技能准确率；此外，人类实验中，机器人通过与 8 名非专家用户的对话，在真实三明治制作任务上实现了 75% 的成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03166v2",
      "published_date": "2024-09-05 01:51:54 UTC",
      "updated_date": "2024-09-11 21:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:45:57.485995"
    },
    {
      "arxiv_id": "2409.03155v1",
      "title": "Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Ma",
        "Zhitao Gao",
        "Qi Chai",
        "Wangchun Sun",
        "Pinghui Wang",
        "Hongbin Pei",
        "Jing Tao",
        "Lingyun Song",
        "Jun Liu",
        "Chen Zhang",
        "Lizhen Cui"
      ],
      "abstract": "Large Language Models (LLMs) may suffer from hallucinations in real-world\napplications due to the lack of relevant knowledge. In contrast, knowledge\ngraphs encompass extensive, multi-relational structures that store a vast array\nof symbolic facts. Consequently, integrating LLMs with knowledge graphs has\nbeen extensively explored, with Knowledge Graph Question Answering (KGQA)\nserving as a critical touchstone for the integration. This task requires LLMs\nto answer natural language questions by retrieving relevant triples from\nknowledge graphs. However, existing methods face two significant challenges:\n\\textit{excessively long reasoning paths distracting from the answer\ngeneration}, and \\textit{false-positive relations hindering the path\nrefinement}. In this paper, we propose an iterative interactive KGQA framework\nthat leverages the interactive learning capabilities of LLMs to perform\nreasoning and Debating over Graphs (DoG). Specifically, DoG employs a\nsubgraph-focusing mechanism, allowing LLMs to perform answer trying after each\nreasoning step, thereby mitigating the impact of lengthy reasoning paths. On\nthe other hand, DoG utilizes a multi-role debate team to gradually simplify\ncomplex questions, reducing the influence of false-positive relations. This\ndebate mechanism ensures the reliability of the reasoning process. Experimental\nresults on five public datasets demonstrate the effectiveness and superiority\nof our architecture. Notably, DoG outperforms the state-of-the-art method ToG\nby 23.7\\% and 9.1\\% in accuracy on WebQuestions and GrailQA, respectively.\nFurthermore, the integration experiments with various LLMs on the mentioned\ndatasets highlight the flexibility of DoG. Code is available at\n\\url{https://github.com/reml-group/DoG}.",
      "tldr_zh": "这篇论文提出了 DoG（Debating over Graphs），一个灵活可靠的推理框架，用于解决 Large Language Models (LLMs) 在知识图谱问答 (KGQA) 中因缺乏知识而产生的幻觉问题。DoG 通过子图聚焦机制让 LLMs 在每个推理步骤后尝试生成答案，从而减少过长推理路径的干扰，并利用多角色辩论团队逐步简化复杂问题，降低假阳性关系的影响，确保推理过程的可靠性。在五个公共数据集上的实验表明，DoG 比最先进方法 ToG 在 WebQuestions 和 GrailQA 的准确率分别提高了 23.7% 和 9.1%，并展示了与各种 LLMs 的良好兼容性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.03155v1",
      "published_date": "2024-09-05 01:11:58 UTC",
      "updated_date": "2024-09-05 01:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:46:12.388085"
    },
    {
      "arxiv_id": "2409.03147v1",
      "title": "Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juan A. Berrios Moya"
      ],
      "abstract": "The rapid global aging trend has led to an increase in dementia cases,\nincluding Alzheimer's disease, underscoring the urgent need for early and\naccurate diagnostic methods. Traditional diagnostic techniques, such as\ncognitive tests, neuroimaging, and biomarker analysis, face significant\nlimitations in sensitivity, accessibility, and cost, particularly in the early\nstages. This study explores the potential of machine learning (ML) as a\ntransformative approach to enhance early dementia detection by leveraging ML\nmodels to analyze and integrate complex multimodal datasets, including\ncognitive assessments, neuroimaging, and genetic information. A comprehensive\nreview of existing literature was conducted to evaluate various ML models,\nincluding supervised learning, deep learning, and advanced techniques such as\nensemble learning and transformer models, assessing their accuracy,\ninterpretability, and potential for clinical integration. The findings indicate\nthat while ML models show significant promise in improving diagnostic precision\nand enabling earlier interventions, challenges remain in their\ngeneralizability, interpretability, and ethical deployment. This research\nconcludes by outlining future directions aimed at enhancing the clinical\nutility of ML models in dementia detection, emphasizing interdisciplinary\ncollaboration and ethically sound frameworks to improve early detection and\nintervention strategies for Alzheimer's disease and other forms of dementia.",
      "tldr_zh": "该研究探讨了痴呆症（如Alzheimer's disease）早期检测的空白，强调传统方法（如认知测试、神经影像和生物标志物分析）的敏感性、访问性和成本问题。论文通过文献综述评估了机器学习（ML）模型，包括监督学习、深度学习、集成学习和transformer模型，来整合多模态数据（如认知评估、神经影像和遗传信息），从而提升诊断精度和早期干预。结果表明，ML 方法显示出显著潜力，但仍面临模型泛化性、解释性和伦理部署的挑战。未来方向包括加强跨学科合作和建立伦理框架，以优化痴呆症检测策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03147v1",
      "published_date": "2024-09-05 00:52:59 UTC",
      "updated_date": "2024-09-05 00:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:46:23.415961"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 72,
  "processed_papers_count": 72,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T21:46:59.124564"
}