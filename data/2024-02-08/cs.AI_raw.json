[
  {
    "arxiv_id": "2402.06104v4",
    "title": "Gradient Aligned Regression via Pairwise Losses",
    "authors": [
      "Dixian Zhu",
      "Tianbao Yang",
      "Livnat Jerby"
    ],
    "abstract": "Regression is a fundamental task in machine learning that has garnered\nextensive attention over the past decades. The conventional approach for\nregression involves employing loss functions that primarily concentrate on\naligning model prediction with the ground truth for each individual data\nsample. Recent research endeavors have introduced novel perspectives by\nincorporating label similarity to regression via imposing extra pairwise\nregularization on the latent feature space and demonstrated the effectiveness.\nHowever, there are two drawbacks for those approaches: i) their pairwise\noperation in latent feature space is computationally more expensive than\nconventional regression losses; ii) it lacks of theoretical justifications\nbehind such regularization. In this work, we propose GAR (Gradient Aligned\nRegression) as a competitive alternative method in label space, which is\nconstituted by a conventional regression loss and two pairwise label difference\nlosses for gradient alignment including magnitude and direction. GAR enjoys: i)\nthe same level efficiency as conventional regression loss because the quadratic\ncomplexity for the proposed pairwise losses can be reduced to linear\ncomplexity; ii) theoretical insights from learning the pairwise label\ndifference to learning the gradient of the ground truth function. We limit our\ncurrent scope as regression on the clean data setting without noises, outliers\nor distributional shifts, etc. We demonstrate the effectiveness of the proposed\nmethod practically on two synthetic datasets and on eight extensive real-world\ntasks from six benchmark datasets with other eight competitive baselines.\nRunning time experiments demonstrate the superior efficiency of the proposed\nGAR over existing methods with pairwise regularization in latent feature space\nand ablation studies demonstrate the effectiveness of each component for GAR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages excluding references, 12 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.06104v4",
    "published_date": "2024-02-08 23:43:53 UTC",
    "updated_date": "2025-01-31 22:32:17 UTC"
  },
  {
    "arxiv_id": "2402.06098v1",
    "title": "Veni, Vidi, Vici: Solving the Myriad of Challenges before Knowledge Graph Learning",
    "authors": [
      "Jeffrey Sardina",
      "Luca Costabello",
      "Christophe Guéret"
    ],
    "abstract": "Knowledge Graphs (KGs) have become increasingly common for representing\nlarge-scale linked data. However, their immense size has required graph\nlearning systems to assist humans in analysis, interpretation, and pattern\ndetection. While there have been promising results for researcher- and\nclinician- empowerment through a variety of KG learning systems, we identify\nfour key deficiencies in state-of-the-art graph learning that simultaneously\nlimit KG learning performance and diminish the ability of humans to interface\noptimally with these learning systems. These deficiencies are: 1) lack of\nexpert knowledge integration, 2) instability to node degree extremity in the\nKG, 3) lack of consideration for uncertainty and relevance while learning, and\n4) lack of explainability. Furthermore, we characterise state-of-the-art\nattempts to solve each of these problems and note that each attempt has largely\nbeen isolated from attempts to solve the other problems. Through a\nformalisation of these problems and a review of the literature that addresses\nthem, we adopt the position that not only are deficiencies in these four key\nareas holding back human-KG empowerment, but that the divide-and-conquer\napproach to solving these problems as individual units rather than a whole is a\nsignificant barrier to the interface between humans and KG learning systems. We\npropose that it is only through integrated, holistic solutions to the\nlimitations of KG learning systems that human and KG learning co-empowerment\nwill be efficiently affected. We finally present our \"Veni, Vidi, Vici\"\nframework that sets a roadmap for effectively and efficiently shifting to a\nholistic co-empowerment model in both the KG learning and the broader machine\nlearning domain.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This article was accepted for publication at IEEE ICSC 2024, and is\n  being made available as an author preprint. As soon as it is published by\n  IEEE, this registry will be updated in accordance with the IEEE copyright\n  agreement",
    "pdf_url": "http://arxiv.org/pdf/2402.06098v1",
    "published_date": "2024-02-08 23:15:23 UTC",
    "updated_date": "2024-02-08 23:15:23 UTC"
  },
  {
    "arxiv_id": "2402.06097v1",
    "title": "TWIG: Towards pre-hoc Hyperparameter Optimisation and Cross-Graph Generalisation via Simulated KGE Models",
    "authors": [
      "Jeffrey Sardina",
      "John D. Kelleher",
      "Declan O'Sullivan"
    ],
    "abstract": "In this paper we introduce TWIG (Topologically-Weighted Intelligence\nGeneration), a novel, embedding-free paradigm for simulating the output of KGEs\nthat uses a tiny fraction of the parameters. TWIG learns weights from inputs\nthat consist of topological features of the graph data, with no coding for\nlatent representations of entities or edges. Our experiments on the UMLS\ndataset show that a single TWIG neural network can predict the results of\nstate-of-the-art ComplEx-N3 KGE model nearly exactly on across all\nhyperparameter configurations. To do this it uses a total of 2590 learnable\nparameters, but accurately predicts the results of 1215 different\nhyperparameter combinations with a combined cost of 29,322,000 parameters.\nBased on these results, we make two claims: 1) that KGEs do not learn latent\nsemantics, but only latent representations of structural patterns; 2) that\nhyperparameter choice in KGEs is a deterministic function of the KGE model and\ngraph structure. We further hypothesise that, as TWIG can simulate KGEs without\nembeddings, that node and edge embeddings are not needed to learn to accurately\npredict new facts in KGs. Finally, we formulate all of our findings under the\numbrella of the ``Structural Generalisation Hypothesis\", which suggests that\n``twiggy\" embedding-free / data-structure-based learning methods can allow a\nsingle neural network to simulate KGE performance, and perhaps solve the Link\nPrediction task, across many KGs from diverse domains and with different\nsemantics.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68R10"
    ],
    "primary_category": "cs.AI",
    "comment": "This article was accepted for publication at IEEE ICSC 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06097v1",
    "published_date": "2024-02-08 23:12:02 UTC",
    "updated_date": "2024-02-08 23:12:02 UTC"
  },
  {
    "arxiv_id": "2402.06086v2",
    "title": "Rhizomes and Diffusions for Processing Highly Skewed Graphs on Fine-Grain Message-Driven Systems",
    "authors": [
      "Bibrak Qamar Chandio",
      "Prateek Srivastava",
      "Maciej Brodowicz",
      "Martin Swany",
      "Thomas Sterling"
    ],
    "abstract": "The paper provides a unified co-design of 1) a programming and execution\nmodel that allows spawning tasks from within the vertex data at runtime, 2)\nlanguage constructs for \\textit{actions} that send work to where the data\nresides, combining parallel expressiveness of local control objects (LCOs) to\nimplement asynchronous graph processing primitives, 3) and an innovative\nvertex-centric data-structure, using the concept of Rhizomes, that parallelizes\nboth the out and in-degree load of vertex objects across many cores and yet\nprovides a single programming abstraction to the vertex objects. The data\nstructure hierarchically parallelizes the out-degree load of vertices and the\nin-degree load laterally. The rhizomes internally communicate and remain\nconsistent, using event-driven synchronization mechanisms, to provide a unified\nand correct view of the vertex.\n  Simulated experimental results show performance gains for BFS, SSSP, and Page\nRank on large chip sizes for the tested input graph datasets containing highly\nskewed degree distribution. The improvements come from the ability to express\nand create fine-grain dynamic computing task in the form of \\textit{actions},\nlanguage constructs that aid the compiler to generate code that the runtime\nsystem uses to optimally schedule tasks, and the data structure that shares\nboth in and out-degree compute workload among memory-processing elements.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.DS",
      "C.1.4; C.3; C.4; D.1.3"
    ],
    "primary_category": "cs.DC",
    "comment": "arXiv admin note: text overlap with arXiv:2402.02576",
    "pdf_url": "http://arxiv.org/pdf/2402.06086v2",
    "published_date": "2024-02-08 22:38:14 UTC",
    "updated_date": "2024-05-08 02:48:35 UTC"
  },
  {
    "arxiv_id": "2402.06082v1",
    "title": "SubGen: Token Generation in Sublinear Time and Memory",
    "authors": [
      "Amir Zandieh",
      "Insu Han",
      "Vahab Mirrokni",
      "Amin Karbasi"
    ],
    "abstract": "Despite the significant success of large language models (LLMs), their\nextensive memory requirements pose challenges for deploying them in\nlong-context token generation. The substantial memory footprint of LLM decoders\narises from the necessity to store all previous tokens in the attention module,\na requirement imposed by key-value (KV) caching. In this work, our focus is on\ndeveloping an efficient compression technique for the KV cache. Empirical\nevidence indicates a significant clustering tendency within key embeddings in\nthe attention module. Building on this key insight, we have devised a novel\ncaching method with sublinear complexity, employing online clustering on key\ntokens and online $\\ell_2$ sampling on values. The result is a provably\naccurate and efficient attention decoding algorithm, termed SubGen. Not only\ndoes this algorithm ensure a sublinear memory footprint and sublinear time\ncomplexity, but we also establish a tight error bound for our approach.\nEmpirical evaluations on long-context question-answering tasks demonstrate that\nSubGen significantly outperforms existing and state-of-the-art KV cache\ncompression methods in terms of performance and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06082v1",
    "published_date": "2024-02-08 22:17:40 UTC",
    "updated_date": "2024-02-08 22:17:40 UTC"
  },
  {
    "arxiv_id": "2402.06695v1",
    "title": "Integrating LLMs for Explainable Fault Diagnosis in Complex Systems",
    "authors": [
      "Akshay J. Dave",
      "Tat Nghia Nguyen",
      "Richard B. Vilim"
    ],
    "abstract": "This paper introduces an integrated system designed to enhance the\nexplainability of fault diagnostics in complex systems, such as nuclear power\nplants, where operator understanding is critical for informed decision-making.\nBy combining a physics-based diagnostic tool with a Large Language Model, we\noffer a novel solution that not only identifies faults but also provides clear,\nunderstandable explanations of their causes and implications. The system's\nefficacy is demonstrated through application to a molten salt facility,\nshowcasing its ability to elucidate the connections between diagnosed faults\nand sensor data, answer operator queries, and evaluate historical sensor\nanomalies. Our approach underscores the importance of merging model-based\ndiagnostics with advanced AI to improve the reliability and transparency of\nautonomous systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.06695v1",
    "published_date": "2024-02-08 22:11:21 UTC",
    "updated_date": "2024-02-08 22:11:21 UTC"
  },
  {
    "arxiv_id": "2402.06079v2",
    "title": "DiscDiff: Latent Diffusion Model for DNA Sequence Generation",
    "authors": [
      "Zehui Li",
      "Yuhao Ni",
      "William A V Beardall",
      "Guoxuan Xia",
      "Akashaditya Das",
      "Guy-Bart Stan",
      "Yiren Zhao"
    ],
    "abstract": "This paper introduces a novel framework for DNA sequence generation,\ncomprising two key components: DiscDiff, a Latent Diffusion Model (LDM)\ntailored for generating discrete DNA sequences, and Absorb-Escape, a\npost-training algorithm designed to refine these sequences. Absorb-Escape\nenhances the realism of the generated sequences by correcting `round errors'\ninherent in the conversion process between latent and input spaces. Our\napproach not only sets new standards in DNA sequence generation but also\ndemonstrates superior performance over existing diffusion models, in generating\nboth short and long DNA sequences. Additionally, we introduce EPD-GenDNA, the\nfirst comprehensive, multi-species dataset for DNA generation, encompassing\n160,000 unique sequences from 15 species. We hope this study will advance the\ngenerative modelling of DNA, with potential implications for gene therapy and\nprotein production.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "Different from the prior work \"Latent Diffusion Model for DNA\n  Sequence Generation\" (arXiv:2310.06150), we updated the evaluation framework\n  and compared the DiscDiff with other methods comprehensively. In addition, a\n  post-training framework is proposed to increase the quality of generated\n  sequences",
    "pdf_url": "http://arxiv.org/pdf/2402.06079v2",
    "published_date": "2024-02-08 22:06:55 UTC",
    "updated_date": "2024-04-17 16:31:33 UTC"
  },
  {
    "arxiv_id": "2402.06078v1",
    "title": "Gaussian Mixture Models for Affordance Learning using Bayesian Networks",
    "authors": [
      "Pedro Osório",
      "Alexandre Bernardino",
      "Ruben Martinez-Cantin",
      "José Santos-Victor"
    ],
    "abstract": "Affordances are fundamental descriptors of relationships between actions,\nobjects and effects. They provide the means whereby a robot can predict\neffects, recognize actions, select objects and plan its behavior according to\ndesired goals. This paper approaches the problem of an embodied agent exploring\nthe world and learning these affordances autonomously from its sensory\nexperiences. Models exist for learning the structure and the parameters of a\nBayesian Network encoding this knowledge. Although Bayesian Networks are\ncapable of dealing with uncertainty and redundancy, previous work considered\ncomplete observability of the discrete sensory data, which may lead to hard\nerrors in the presence of noise. In this paper we consider a probabilistic\nrepresentation of the sensors by Gaussian Mixture Models (GMMs) and explicitly\ntaking into account the probability distribution contained in each discrete\naffordance concept, which can lead to a more correct learning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  2010",
    "pdf_url": "http://arxiv.org/pdf/2402.06078v1",
    "published_date": "2024-02-08 22:05:45 UTC",
    "updated_date": "2024-02-08 22:05:45 UTC"
  },
  {
    "arxiv_id": "2402.06694v1",
    "title": "Scaling Intelligent Agents in Combat Simulations for Wargaming",
    "authors": [
      "Scotty Black",
      "Christian Darken"
    ],
    "abstract": "Remaining competitive in future conflicts with technologically-advanced\ncompetitors requires us to accelerate our research and development in\nartificial intelligence (AI) for wargaming. More importantly, leveraging\nmachine learning for intelligent combat behavior development will be key to one\nday achieving superhuman performance in this domain--elevating the quality and\naccelerating the speed of our decisions in future wars. Although deep\nreinforcement learning (RL) continues to show promising results in intelligent\nagent behavior development in games, it has yet to perform at or above the\nhuman level in the long-horizon, complex tasks typically found in combat\nmodeling and simulation. Capitalizing on the proven potential of RL and recent\nsuccesses of hierarchical reinforcement learning (HRL), our research is\ninvestigating and extending the use of HRL to create intelligent agents capable\nof performing effectively in these large and complex simulation environments.\nOur ultimate goal is to develop an agent capable of superhuman performance that\ncould then serve as an AI advisor to military planners and decision-makers.\nThis papers covers our ongoing approach and the first three of our five\nresearch areas aimed at managing the exponential growth of computations that\nhave thus far limited the use of AI in combat simulations: (1) developing an\nHRL training framework and agent architecture for combat units; (2) developing\na multi-model framework for agent decision-making; (3) developing\ndimension-invariant observation abstractions of the state space to manage the\nexponential growth of computations; (4) developing an intrinsic rewards engine\nto enable long-term planning; and (5) implementing this framework into a\nhigher-fidelity combat simulation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2402.06075",
    "pdf_url": "http://arxiv.org/pdf/2402.06694v1",
    "published_date": "2024-02-08 21:57:10 UTC",
    "updated_date": "2024-02-08 21:57:10 UTC"
  },
  {
    "arxiv_id": "2402.06075v1",
    "title": "Scaling Artificial Intelligence for Digital Wargaming in Support of Decision-Making",
    "authors": [
      "Scotty Black",
      "Christian Darken"
    ],
    "abstract": "In this unprecedented era of technology-driven transformation, it becomes\nmore critical than ever that we aggressively invest in developing robust\nartificial intelligence (AI) for wargaming in support of decision-making. By\nadvancing AI-enabled systems and pairing these with human judgment, we will be\nable to enhance all-domain awareness, improve the speed and quality of our\ndecision cycles, offer recommendations for novel courses of action, and more\nrapidly counter our adversary's actions. It therefore becomes imperative that\nwe accelerate the development of AI to help us better address the complexity of\nmodern challenges and dilemmas that currently requires human intelligence and,\nif possible, attempt to surpass human intelligence--not to replace humans, but\nto augment and better inform human decision-making at machine speed. Although\ndeep reinforcement learning continues to show promising results in intelligent\nagent behavior development for the long-horizon, complex tasks typically found\nin combat modeling and simulation, further research is needed to enable the\nscaling of AI to deal with these intricate and expansive state-spaces\ncharacteristic of wargaming for either concept development, education, or\nanalysis. To help address this challenge, in our research, we are developing\nand implementing a hierarchical reinforcement learning framework that includes\na multi-model approach and dimension-invariant observation abstractions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06075v1",
    "published_date": "2024-02-08 21:51:07 UTC",
    "updated_date": "2024-02-08 21:51:07 UTC"
  },
  {
    "arxiv_id": "2403.05552v1",
    "title": "Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses",
    "authors": [
      "W. Chango",
      "R. Cerezo",
      "C. Romero"
    ],
    "abstract": "In this paper we applied data fusion approaches for predicting the final\nacademic performance of university students using multiple-source, multimodal\ndata from blended learning environments. We collected and preprocessed data\nabout first-year university students from different sources: theory classes,\npractical sessions, on-line Moodle sessions, and a final exam. Our objective\nwas to discover which data fusion approach produced the best results using our\ndata. We carried out experiments by applying four different data fusion\napproaches and six classification algorithms. The results showed that the best\npredictions were produced using ensembles and selecting the best attributes\napproach with discretized data. The best prediction models showed us that the\nlevel of attention in theory classes, scores in Moodle quizzes, and the level\nof activity in Moodle forums were the best set of attributes for predicting\nstudents' final performance in our courses.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05552v1",
    "published_date": "2024-02-08 21:29:41 UTC",
    "updated_date": "2024-02-08 21:29:41 UTC"
  },
  {
    "arxiv_id": "2402.06053v1",
    "title": "Randomness Is All You Need: Semantic Traversal of Problem-Solution Spaces with Large Language Models",
    "authors": [
      "Thomas Sandholm",
      "Sayandev Mukherjee",
      "Bernardo A. Huberman"
    ],
    "abstract": "We present a novel approach to exploring innovation problem and solution\ndomains using LLM fine-tuning with a custom idea database. By semantically\ntraversing the bi-directional problem and solution tree at different\ntemperature levels we achieve high diversity in solution edit distance while\nstill remaining close to the original problem statement semantically. In\naddition to finding a variety of solutions to a given problem, this method can\nalso be used to refine and clarify the original problem statement. As further\nvalidation of the approach, we implemented a proof-of-concept Slack bot to\nserve as an innovation assistant.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06053v1",
    "published_date": "2024-02-08 20:49:09 UTC",
    "updated_date": "2024-02-08 20:49:09 UTC"
  },
  {
    "arxiv_id": "2402.06046v3",
    "title": "Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap",
    "authors": [
      "Philip Koopman"
    ],
    "abstract": "An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San\nFrancisco resulted not only in a severe injury, but also dramatic upheaval at\nthat company that will likely have lasting effects throughout the industry.\nIs-sues stem not just from the loss events themselves, but also from how Cruise\nmishandled dealing with their robotaxi dragging a pedestrian under the vehicle\nafter the initial post-crash stop. External investigation reports provide raw\nmaterial describing the incident and critique the company's response from a\nregulatory point of view, but exclude safety engineering recommendations from\nscope. We highlight specific facts and relationships among events by tying\ntogether different pieces of the external report material. We then explore\nsafety lessons that might be learned related to: recognizing and responding to\nnearby mishaps, building an accurate world model of a post-collision scenario,\nthe in-adequacy of a so-called \"minimal risk condition\" strategy in complex\nsituations, poor organizational discipline in responding to a mishap, overly\naggressive post-collision automation choices that made a bad situation worse,\nand a reluctance to admit to a mishap causing much worse organizational harm\ndown-stream.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.06046v3",
    "published_date": "2024-02-08 20:37:51 UTC",
    "updated_date": "2024-08-05 10:48:32 UTC"
  },
  {
    "arxiv_id": "2402.16877v1",
    "title": "Large Language Model Augmented Exercise Retrieval for Personalized Language Learning",
    "authors": [
      "Austin Xu",
      "Will Monroe",
      "Klinton Bicknell"
    ],
    "abstract": "We study the problem of zero-shot exercise retrieval in the context of online\nlanguage learning, to give learners the ability to explicitly request\npersonalized exercises via natural language. Using real-world data collected\nfrom language learners, we observe that vector similarity approaches poorly\ncapture the relationship between exercise content and the language that\nlearners use to express what they want to learn. This semantic gap between\nqueries and content dramatically reduces the effectiveness of general-purpose\nretrieval models pretrained on large scale information retrieval datasets like\nMS MARCO. We leverage the generative capabilities of large language models to\nbridge the gap by synthesizing hypothetical exercises based on the learner's\ninput, which are then used to search for relevant exercises. Our approach,\nwhich we call mHyER, overcomes three challenges: (1) lack of relevance labels\nfor training, (2) unrestricted learner input content, and (3) low semantic\nsimilarity between input and retrieval candidates. mHyER outperforms several\nstrong baselines on two novel benchmarks created from crowdsourced data and\npublicly available data.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Presented at Learning Analytics and Knowledge 2024. 11 pages, 4\n  figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.16877v1",
    "published_date": "2024-02-08 20:35:31 UTC",
    "updated_date": "2024-02-08 20:35:31 UTC"
  },
  {
    "arxiv_id": "2402.06044v3",
    "title": "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models",
    "authors": [
      "Hainiu Xu",
      "Runcong Zhao",
      "Lixing Zhu",
      "Jinhua Du",
      "Yulan He"
    ],
    "abstract": "Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track\nof the mental states of others, is pivotal in developing socially intelligent\nagents. However, prevalent N-ToM benchmarks have several shortcomings,\nincluding the presence of ambiguous and artificial narratives, absence of\npersonality traits and preferences, a lack of questions addressing characters'\npsychological mental states, and limited diversity in the questions posed. In\nresponse to these issues, we construct OpenToM, a new benchmark for assessing\nN-ToM with (1) longer and clearer narrative stories, (2) characters with\nexplicit personality traits, (3) actions that are triggered by character\nintentions, and (4) questions designed to challenge LLMs' capabilities of\nmodeling characters' mental states of both the physical and psychological\nworld. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling\ncertain aspects of mental states in the physical world but fall short when\ntracking characters' mental states in the psychological world.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06044v3",
    "published_date": "2024-02-08 20:35:06 UTC",
    "updated_date": "2024-06-03 10:48:16 UTC"
  },
  {
    "arxiv_id": "2402.06038v2",
    "title": "Understanding Contrastive Representation Learning from Positive Unlabeled (PU) Data",
    "authors": [
      "Anish Acharya",
      "Li Jing",
      "Bhargav Bhushanam",
      "Dhruv Choudhary",
      "Michael Rabbat",
      "Sujay Sanghavi",
      "Inderjit S Dhillon"
    ],
    "abstract": "Pretext Invariant Representation Learning (PIRL) followed by Supervised\nFine-Tuning (SFT) has become a standard paradigm for learning with limited\nlabels. We extend this approach to the Positive Unlabeled (PU) setting, where\nonly a small set of labeled positives and a large unlabeled pool -- containing\nboth positives and negatives are available. We study this problem under two\nregimes: (i) without access to the class prior, and (ii) when the prior is\nknown or can be estimated. We introduce Positive Unlabeled Contrastive Learning\n(puCL), an unbiased and variance reducing contrastive objective that integrates\nweak supervision from labeled positives judiciously into the contrastive loss.\nWhen the class prior is known, we propose Positive Unlabeled InfoNCE (puNCE), a\nprior-aware extension that re-weights unlabeled samples as soft positive\nnegative mixtures. For downstream classification, we develop a pseudo-labeling\nalgorithm that leverages the structure of the learned embedding space via PU\naware clustering. Our framework is supported by theory; offering bias-variance\nanalysis, convergence insights, and generalization guarantees via augmentation\nconcentration; and validated empirically across standard PU benchmarks, where\nit consistently outperforms existing methods, particularly in low-supervision\nregimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06038v2",
    "published_date": "2024-02-08 20:20:54 UTC",
    "updated_date": "2025-04-10 10:41:06 UTC"
  },
  {
    "arxiv_id": "2402.06692v1",
    "title": "HistoHDR-Net: Histogram Equalization for Single LDR to HDR Image Translation",
    "authors": [
      "Hrishav Bakul Barua",
      "Ganesh Krishnasamy",
      "KokSheik Wong",
      "Abhinav Dhall",
      "Kalin Stefanov"
    ],
    "abstract": "High Dynamic Range (HDR) imaging aims to replicate the high visual quality\nand clarity of real-world scenes. Due to the high costs associated with HDR\nimaging, the literature offers various data-driven methods for HDR image\nreconstruction from Low Dynamic Range (LDR) counterparts. A common limitation\nof these approaches is missing details in regions of the reconstructed HDR\nimages, which are over- or under-exposed in the input LDR images. To this end,\nwe propose a simple and effective method, HistoHDR-Net, to recover the fine\ndetails (e.g., color, contrast, saturation, and brightness) of HDR images via a\nfusion-based approach utilizing histogram-equalized LDR images along with\nself-attention guidance. Our experiments demonstrate the efficacy of the\nproposed approach over the state-of-art methods.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "cs.MM",
      "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning",
      "I.3.3; I.4.5"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to IEEE",
    "pdf_url": "http://arxiv.org/pdf/2402.06692v1",
    "published_date": "2024-02-08 20:14:46 UTC",
    "updated_date": "2024-02-08 20:14:46 UTC"
  },
  {
    "arxiv_id": "2402.06034v1",
    "title": "Optimizing Predictive AI in Physical Design Flows with Mini Pixel Batch Gradient Descent",
    "authors": [
      "Haoyu Yang",
      "Anthony Agnesina",
      "Haoxing Ren"
    ],
    "abstract": "Exploding predictive AI has enabled fast yet effective evaluation and\ndecision-making in modern chip physical design flows. State-of-the-art\nframeworks typically include the objective of minimizing the mean square error\n(MSE) between the prediction and the ground truth. We argue the averaging\neffect of MSE induces limitations in both model training and deployment, and\ngood MSE behavior does not guarantee the capability of these models to assist\nphysical design flows which are likely sabotaged due to a small portion of\nprediction error. To address this, we propose mini-pixel batch gradient descent\n(MPGD), a plug-and-play optimization algorithm that takes the most informative\nentries into consideration, offering probably faster and better convergence.\nExperiments on representative benchmark suits show the significant benefits of\nMPGD on various physical design prediction tasks using CNN or Graph-based\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.06034v1",
    "published_date": "2024-02-08 20:14:35 UTC",
    "updated_date": "2024-02-08 20:14:35 UTC"
  },
  {
    "arxiv_id": "2402.06030v1",
    "title": "Game-theoretic Counterfactual Explanation for Graph Neural Networks",
    "authors": [
      "Chirag Chhablani",
      "Sarthak Jain",
      "Akshay Channesh",
      "Ian A. Kash",
      "Sourav Medya"
    ],
    "abstract": "Graph Neural Networks (GNNs) have been a powerful tool for node\nclassification tasks in complex networks. However, their decision-making\nprocesses remain a black-box to users, making it challenging to understand the\nreasoning behind their predictions. Counterfactual explanations (CFE) have\nshown promise in enhancing the interpretability of machine learning models.\nPrior approaches to compute CFE for GNNS often are learning-based approaches\nthat require training additional graphs. In this paper, we propose a\nsemivalue-based, non-learning approach to generate CFE for node classification\ntasks, eliminating the need for any additional training. Our results reveals\nthat computing Banzhaf values requires lower sample complexity in identifying\nthe counterfactual explanations compared to other popular methods such as\ncomputing Shapley values. Our empirical evidence indicates computing Banzhaf\nvalues can achieve up to a fourfold speed up compared to Shapley values. We\nalso design a thresholding method for computing Banzhaf values and show\ntheoretical and empirical results on its robustness in noisy environments,\nmaking it superior to Shapley values. Furthermore, the thresholded Banzhaf\nvalues are shown to enhance efficiency without compromising the quality (i.e.,\nfidelity) in the explanations in three popular graph datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.06030v1",
    "published_date": "2024-02-08 20:07:43 UTC",
    "updated_date": "2024-02-08 20:07:43 UTC"
  },
  {
    "arxiv_id": "2402.06026v1",
    "title": "Quantum neural network with ensemble learning to mitigate barren plateaus and cost function concentration",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "abstract": "The rapid development of quantum computers promises transformative impacts\nacross diverse fields of science and technology. Quantum neural networks\n(QNNs), as a forefront application, hold substantial potential. Despite the\nmultitude of proposed models in the literature, persistent challenges, notably\nthe vanishing gradient (VG) and cost function concentration (CFC) problems,\nimpede their widespread success. In this study, we introduce a novel approach\nto quantum neural network construction, specifically addressing the issues of\nVG and CFC. Our methodology employs ensemble learning, advocating for the\nsimultaneous deployment of multiple quantum circuits with a depth equal to $1$,\na departure from the conventional use of a single quantum circuit with depth\n$L$. We assess the efficacy of our proposed model through a comparative\nanalysis with a conventionally constructed QNN. The evaluation unfolds in the\ncontext of a classification problem, yielding valuable insights into the\npotential advantages of our innovative approach.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06026v1",
    "published_date": "2024-02-08 19:57:57 UTC",
    "updated_date": "2024-02-08 19:57:57 UTC"
  },
  {
    "arxiv_id": "2402.06025v7",
    "title": "Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning",
    "authors": [
      "Wasu Top Piriyakulkij",
      "Cassidy Langenfeld",
      "Tuan Anh Le",
      "Kevin Ellis"
    ],
    "abstract": "We give a model of how to infer natural language rules by doing experiments.\nThe model integrates Large Language Models (LLMs) with Monte Carlo algorithms\nfor probabilistic inference, interleaving online belief updates with experiment\ndesign under information-theoretic criteria. We conduct a human-model\ncomparison on a Zendo-style task, finding that a critical ingredient for\nmodeling the human data is to assume that humans also consider fuzzy,\nprobabilistic rules, in addition to assuming that humans perform\napproximately-Bayesian belief updates. We also compare with recent algorithms\nfor using LLMs to generate and revise hypotheses, finding that our online\ninference method yields higher accuracy at recovering the true underlying rule,\nand provides better support for designing optimal experiments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06025v7",
    "published_date": "2024-02-08 19:57:29 UTC",
    "updated_date": "2024-10-25 22:26:41 UTC"
  },
  {
    "arxiv_id": "2402.06023v1",
    "title": "Decision Theory-Guided Deep Reinforcement Learning for Fast Learning",
    "authors": [
      "Zelin Wan",
      "Jin-Hee Cho",
      "Mu Zhu",
      "Ahmed H. Anwar",
      "Charles Kamhoua",
      "Munindar P. Singh"
    ],
    "abstract": "This paper introduces a novel approach, Decision Theory-guided Deep\nReinforcement Learning (DT-guided DRL), to address the inherent cold start\nproblem in DRL. By integrating decision theory principles, DT-guided DRL\nenhances agents' initial performance and robustness in complex environments,\nenabling more efficient and reliable convergence during learning. Our\ninvestigation encompasses two primary problem contexts: the cart pole and maze\nnavigation challenges. Experimental results demonstrate that the integration of\ndecision theory not only facilitates effective initial guidance for DRL agents\nbut also promotes a more structured and informed exploration strategy,\nparticularly in environments characterized by large and intricate state spaces.\nThe results of experiment demonstrate that DT-guided DRL can provide\nsignificantly higher rewards compared to regular DRL. Specifically, during the\ninitial phase of training, the DT-guided DRL yields up to an 184% increase in\naccumulated reward. Moreover, even after reaching convergence, it maintains a\nsuperior performance, ending with up to 53% more reward than standard DRL in\nlarge maze problems. DT-guided DRL represents an advancement in mitigating a\nfundamental challenge of DRL by leveraging functions informed by human\n(designer) knowledge, setting a foundation for further research in this\npromising interdisciplinary domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06023v1",
    "published_date": "2024-02-08 19:47:34 UTC",
    "updated_date": "2024-02-08 19:47:34 UTC"
  },
  {
    "arxiv_id": "2402.07940v1",
    "title": "LLMs Among Us: Generative AI Participating in Digital Discourse",
    "authors": [
      "Kristina Radivojevic",
      "Nicholas Clark",
      "Paul Brenner"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has great potential to reshape\nthe landscape of many social media platforms. While this can bring promising\nopportunities, it also raises many threats, such as biases and privacy\nconcerns, and may contribute to the spread of propaganda by malicious actors.\nWe developed the \"LLMs Among Us\" experimental framework on top of the Mastodon\nsocial media platform for bot and human participants to communicate without\nknowing the ratio or nature of bot and human participants. We built 10 personas\nwith three different LLMs, GPT-4, LLama 2 Chat, and Claude. We conducted three\nrounds of the experiment and surveyed participants after each round to measure\nthe ability of LLMs to pose as human participants without human detection. We\nfound that participants correctly identified the nature of other users in the\nexperiment only 42% of the time despite knowing the presence of both bots and\nhumans. We also found that the choice of persona had substantially more impact\non human perception than the choice of mainstream LLMs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07940v1",
    "published_date": "2024-02-08 19:21:33 UTC",
    "updated_date": "2024-02-08 19:21:33 UTC"
  },
  {
    "arxiv_id": "2402.06004v1",
    "title": "Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank Compression Strategy",
    "authors": [
      "Seyedarmin Azizi",
      "Mahdi Nazemi",
      "Massoud Pedram"
    ],
    "abstract": "As Vision Transformers (ViTs) increasingly set new benchmarks in computer\nvision, their practical deployment on inference engines is often hindered by\ntheir significant memory bandwidth and (on-chip) memory footprint requirements.\nThis paper addresses this memory limitation by introducing an activation-aware\nmodel compression methodology that uses selective low-rank weight tensor\napproximations of different layers to reduce the parameter count of ViTs. The\nkey idea is to decompose the weight tensors into a sum of two\nparameter-efficient tensors while minimizing the error between the product of\nthe input activations with the original weight tensor and the product of the\ninput activations with the approximate tensor sum. This approximation is\nfurther refined by adopting an efficient layer-wise error compensation\ntechnique that uses the gradient of the layer's output loss. The combination of\nthese techniques achieves excellent results while it avoids being trapped in a\nshallow local minimum early in the optimization process and strikes a good\nbalance between the model compression and output accuracy. Notably, the\npresented method significantly reduces the parameter count of DeiT-B by 60%\nwith less than 1% accuracy drop on the ImageNet dataset, overcoming the usual\naccuracy degradation seen in low-rank approximations. In addition to this, the\npresented compression technique can compress large DeiT/ViT models to have\nabout the same model size as smaller DeiT/ViT variants while yielding up to\n1.8% accuracy gain. These results highlight the efficacy of our approach,\npresenting a viable solution for embedding ViTs in memory-constrained\nenvironments without compromising their performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06004v1",
    "published_date": "2024-02-08 19:01:14 UTC",
    "updated_date": "2024-02-08 19:01:14 UTC"
  },
  {
    "arxiv_id": "2402.05935v3",
    "title": "SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models",
    "authors": [
      "Dongyang Liu",
      "Renrui Zhang",
      "Longtian Qiu",
      "Siyuan Huang",
      "Weifeng Lin",
      "Shitian Zhao",
      "Shijie Geng",
      "Ziyi Lin",
      "Peng Jin",
      "Kaipeng Zhang",
      "Wenqi Shao",
      "Chao Xu",
      "Conghui He",
      "Junjun He",
      "Hao Shao",
      "Pan Lu",
      "Hongsheng Li",
      "Yu Qiao",
      "Peng Gao"
    ],
    "abstract": "We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)\nseries developed upon SPHINX. To improve the architecture and training\nefficiency, we modify the SPHINX framework by removing redundant visual\nencoders, bypassing fully-padded sub-images with skip tokens, and simplifying\nmulti-stage training into a one-stage all-in-one paradigm. To fully unleash the\npotential of MLLMs, we assemble a comprehensive multi-domain and multimodal\ndataset covering publicly available resources in language, vision, and\nvision-language tasks. We further enrich this collection with our curated OCR\nintensive and Set-of-Mark datasets, extending the diversity and generality. By\ntraining over different base LLMs including TinyLlama1.1B, InternLM2-7B,\nLLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in\nparameter size and multilingual capabilities. Comprehensive benchmarking\nreveals a strong correlation between the multi-modal performance with the data\nand parameter scales. Code and models are released at\nhttps://github.com/Alpha-VLLM/LLaMA2-Accessory",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML 2024. Code and models are released at\n  https://github.com/Alpha-VLLM/LLaMA2-Accessory",
    "pdf_url": "http://arxiv.org/pdf/2402.05935v3",
    "published_date": "2024-02-08 18:59:48 UTC",
    "updated_date": "2025-03-21 10:19:01 UTC"
  },
  {
    "arxiv_id": "2402.05933v1",
    "title": "Time Series Diffusion in the Frequency Domain",
    "authors": [
      "Jonathan Crabbé",
      "Nicolas Huynh",
      "Jan Stanczuk",
      "Mihaela van der Schaar"
    ],
    "abstract": "Fourier analysis has been an instrumental tool in the development of signal\nprocessing. This leads us to wonder whether this framework could similarly\nbenefit generative modelling. In this paper, we explore this question through\nthe scope of time series diffusion models. More specifically, we analyze\nwhether representing time series in the frequency domain is a useful inductive\nbias for score-based diffusion models. By starting from the canonical SDE\nformulation of diffusion in the time domain, we show that a dual diffusion\nprocess occurs in the frequency domain with an important nuance: Brownian\nmotions are replaced by what we call mirrored Brownian motions, characterized\nby mirror symmetries among their components. Building on this insight, we show\nhow to adapt the denoising score matching approach to implement diffusion\nmodels in the frequency domain. This results in frequency diffusion models,\nwhich we compare to canonical time diffusion models. Our empirical evaluation\non real-world datasets, covering various domains like healthcare and finance,\nshows that frequency diffusion models better capture the training distribution\nthan time diffusion models. We explain this observation by showing that time\nseries from these datasets tend to be more localized in the frequency domain\nthan in the time domain, which makes them easier to model in the former case.\nAll our observations point towards impactful synergies between Fourier analysis\nand diffusion models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05933v1",
    "published_date": "2024-02-08 18:59:05 UTC",
    "updated_date": "2024-02-08 18:59:05 UTC"
  },
  {
    "arxiv_id": "2402.05932v2",
    "title": "Driving Everywhere with Large Language Model Policy Adaptation",
    "authors": [
      "Boyi Li",
      "Yue Wang",
      "Jiageng Mao",
      "Boris Ivanovic",
      "Sushant Veer",
      "Karen Leung",
      "Marco Pavone"
    ],
    "abstract": "Adapting driving behavior to new environments, customs, and laws is a\nlong-standing problem in autonomous driving, precluding the widespread\ndeployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a\nsimple yet powerful tool that enables human drivers and autonomous vehicles\nalike to drive everywhere by adapting their tasks and motion plans to traffic\nrules in new locations. LLaDA achieves this by leveraging the impressive\nzero-shot generalizability of large language models (LLMs) in interpreting the\ntraffic rules in the local driver handbook. Through an extensive user study, we\nshow that LLaDA's instructions are useful in disambiguating in-the-wild\nunexpected situations. We also demonstrate LLaDA's ability to adapt AV motion\nplanning policies in real-world datasets; LLaDA outperforms baseline planning\napproaches on all our metrics. Please check our website for more details:\nhttps://boyiliee.github.io/llada.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "CVPR 2024, featured in GTC 2024:\n  https://www.youtube.com/watch?v=t-UPlPlrYgQ&t=51s",
    "pdf_url": "http://arxiv.org/pdf/2402.05932v2",
    "published_date": "2024-02-08 18:59:03 UTC",
    "updated_date": "2024-04-10 23:29:18 UTC"
  },
  {
    "arxiv_id": "2402.05929v2",
    "title": "An Interactive Agent Foundation Model",
    "authors": [
      "Zane Durante",
      "Bidipta Sarkar",
      "Ran Gong",
      "Rohan Taori",
      "Yusuke Noda",
      "Paul Tang",
      "Ehsan Adeli",
      "Shrinidhi Kowshika Lakshmikanth",
      "Kevin Schulman",
      "Arnold Milstein",
      "Demetri Terzopoulos",
      "Ade Famoti",
      "Noboru Kuno",
      "Ashley Llorens",
      "Hoi Vo",
      "Katsu Ikeuchi",
      "Li Fei-Fei",
      "Jianfeng Gao",
      "Naoki Wake",
      "Qiuyuan Huang"
    ],
    "abstract": "The development of artificial intelligence systems is transitioning from\ncreating static, task-specific models to dynamic, agent-based systems capable\nof performing well in a wide range of applications. We propose an Interactive\nAgent Foundation Model that uses a novel multi-task agent training paradigm for\ntraining AI agents across a wide range of domains, datasets, and tasks. Our\ntraining paradigm unifies diverse pre-training strategies, including visual\nmasked auto-encoders, language modeling, and next-action prediction, enabling a\nversatile and adaptable AI framework. We demonstrate the performance of our\nframework across three separate domains -- Robotics, Gaming AI, and Healthcare.\nOur model demonstrates its ability to generate meaningful and contextually\nrelevant outputs in each area. The strength of our approach lies in its\ngenerality, leveraging a variety of data sources such as robotics sequences,\ngameplay data, large-scale video datasets, and textual information for\neffective multimodal and multi-task learning. Our approach provides a promising\navenue for developing generalist, action-taking, multimodal systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05929v2",
    "published_date": "2024-02-08 18:58:02 UTC",
    "updated_date": "2024-06-17 15:50:02 UTC"
  },
  {
    "arxiv_id": "2402.05906v1",
    "title": "Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games",
    "authors": [
      "Hafez Ghaemi",
      "Hamed Kebriaei",
      "Alireza Ramezani Moghaddam",
      "Majid Nili Ahamdabadi"
    ],
    "abstract": "Classical multi-agent reinforcement learning (MARL) assumes risk neutrality\nand complete objectivity for agents. However, in settings where agents need to\nconsider or model human economic or social preferences, a notion of risk must\nbe incorporated into the RL optimization problem. This will be of greater\nimportance in MARL where other human or non-human agents are involved, possibly\nwith their own risk-sensitive policies. In this work, we consider\nrisk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT),\na non-convex risk measure and a generalization of coherent measures of risk.\nCPT is capable of explaining loss aversion in humans and their tendency to\noverestimate/underestimate small/large probabilities. We propose a distributed\nsampling-based actor-critic (AC) algorithm with CPT risk for network\naggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC.\nUnder a set of assumptions, we prove the convergence of the algorithm to a\nsubjective notion of Markov perfect Nash equilibrium in NAMGs. The experimental\nresults show that subjective CPT policies obtained by our algorithm can be\ndifferent from the risk-neutral ones, and agents with a higher loss aversion\nare more inclined to socially isolate themselves in an NAMG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05906v1",
    "published_date": "2024-02-08 18:43:27 UTC",
    "updated_date": "2024-02-08 18:43:27 UTC"
  },
  {
    "arxiv_id": "2402.05902v4",
    "title": "ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation",
    "authors": [
      "Aimee Guo",
      "Grace Fei",
      "Hemanth Pasupuleti",
      "Jing Wang"
    ],
    "abstract": "The newly released Segment Anything Model (SAM) is a popular tool used in\nimage processing due to its superior segmentation accuracy, variety of input\nprompts, training capabilities, and efficient model design. However, its\ncurrent model is trained on a diverse dataset not tailored to medical images,\nparticularly ultrasound images. Ultrasound images tend to have a lot of noise,\nmaking it difficult to segment out important structures. In this project, we\ndeveloped ClickSAM, which fine-tunes the Segment Anything Model using click\nprompts for ultrasound images. ClickSAM has two stages of training: the first\nstage is trained on single-click prompts centered in the ground-truth contours,\nand the second stage focuses on improving the model performance through\nadditional positive and negative click prompts. By comparing the first stage\npredictions to the ground-truth masks, true positive, false positive, and false\nnegative segments are calculated. Positive clicks are generated using the true\npositive and false negative segments, and negative clicks are generated using\nthe false positive segments. The Centroidal Voronoi Tessellation algorithm is\nthen employed to collect positive and negative click prompts in each segment\nthat are used to enhance the model performance during the second stage of\ntraining. With click-train methods, ClickSAM exhibits superior performance\ncompared to other existing models for ultrasound image segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 2 figures, SPIE Medical Imaging Conference 2024. Project\n  page: https://sites.google.com/view/clicksam/home",
    "pdf_url": "http://arxiv.org/pdf/2402.05902v4",
    "published_date": "2024-02-08 18:41:41 UTC",
    "updated_date": "2024-02-25 03:25:50 UTC"
  },
  {
    "arxiv_id": "2402.05894v4",
    "title": "Large Language Model Meets Graph Neural Network in Knowledge Distillation",
    "authors": [
      "Shengxiang Hu",
      "Guobing Zou",
      "Song Yang",
      "Yanglan Gan",
      "Bofeng Zhang",
      "Yixin Chen"
    ],
    "abstract": "In service-oriented architectures, accurately predicting the Quality of\nService (QoS) is crucial for maintaining reliability and enhancing user\nsatisfaction. However, significant challenges remain due to existing methods\nalways overlooking high-order latent collaborative relationships between users\nand services and failing to dynamically adjust feature learning for every\nspecific user-service invocation, which are critical for learning accurate\nfeatures. Additionally, reliance on RNNs for capturing QoS evolution hampers\nmodels' ability to detect long-term trends due to difficulties in managing\nlong-range dependencies. To address these challenges, we propose the\n\\underline{T}arget-Prompt \\underline{O}nline \\underline{G}raph\n\\underline{C}ollaborative \\underline{L}earning (TOGCL) framework for\ntemporal-aware QoS prediction. TOGCL leverages a dynamic user-service\ninvocation graph to model historical interactions, providing a comprehensive\nrepresentation of user-service relationships. Building on this graph, it\ndevelops a target-prompt graph attention network to extract online deep latent\nfeatures of users and services at each time slice, simultaneously considering\nimplicit collaborative relationships between target users/services and their\nneighbors, as well as relevant historical QoS values. Additionally, a\nmulti-layer Transformer encoder is employed to uncover temporal feature\nevolution patterns of users and services, leading to temporal-aware QoS\nprediction. Extensive experiments conducted on the WS-DREAM dataset demonstrate\nthat our proposed TOGCL framework significantly outperforms state-of-the-art\nmethods across multiple metrics, achieving improvements of up to 38.80\\%. These\nresults underscore the effectiveness of the TOGCL framework for precise\ntemporal QoS prediction.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68T30, 68R10, 68T05"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2402.05894v4",
    "published_date": "2024-02-08 18:33:21 UTC",
    "updated_date": "2024-06-11 13:17:12 UTC"
  },
  {
    "arxiv_id": "2402.05889v4",
    "title": "CREMA: Generalizable and Efficient Video-Language Reasoning via Multimodal Modular Fusion",
    "authors": [
      "Shoubin Yu",
      "Jaehong Yoon",
      "Mohit Bansal"
    ],
    "abstract": "Despite impressive advancements in recent multimodal reasoning approaches,\nthey are still limited in flexibility and efficiency, as these models typically\nprocess only a few fixed modality inputs and require updates to numerous\nparameters. This paper tackles these critical challenges and proposes CREMA, a\ngeneralizable, highly efficient, and modular modality-fusion framework that can\nincorporate any new modality to enhance video reasoning. We first augment\nmultiple informative modalities (such as optical flow, 3D point cloud, audio,\nthermal heatmap, and touch map) from given videos without extra human\nannotation by leveraging sensors or existing pre-trained models. Next, we\nintroduce a query transformer with multiple parameter-efficient modules\nassociated with each accessible modality. It projects diverse modality features\nto the LLM token embedding space, allowing the model to integrate different\ndata types for response generation. Furthermore, we propose a novel progressive\nmultimodal fusion design supported by a lightweight fusion module and\nmodality-sequential training strategy. It helps compress information across\nvarious assisting modalities, maintaining computational efficiency in the LLM\nwhile improving performance. We validate our method on 7 video-language\nreasoning tasks assisted by diverse modalities, including conventional VideoQA\nand Video-Audio/3D/Touch/Thermal QA, and achieve better/equivalent performance\nagainst strong multimodal LLMs, including OneLLM, BLIP-2, and SeViLA while\nreducing over 90% trainable parameters. We provide extensive analyses of CREMA,\nincluding the impact of each modality on reasoning domains, the design of the\nfusion module, and example visualizations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025; first two authors contributed equally. Project page:\n  https://CREMA-VideoLLM.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.05889v4",
    "published_date": "2024-02-08 18:27:22 UTC",
    "updated_date": "2025-03-20 02:27:50 UTC"
  },
  {
    "arxiv_id": "2402.05880v2",
    "title": "Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking",
    "authors": [
      "Nikhil Sharma",
      "Q. Vera Liao",
      "Ziang Xiao"
    ],
    "abstract": "Large language models (LLMs) powered conversational search systems have\nalready been used by hundreds of millions of people, and are believed to bring\nmany benefits over conventional search. However, while decades of research and\npublic discourse interrogated the risk of search systems in increasing\nselective exposure and creating echo chambers -- limiting exposure to diverse\nopinions and leading to opinion polarization, little is known about such a risk\nof LLM-powered conversational search. We conduct two experiments to\ninvestigate: 1) whether and how LLM-powered conversational search increases\nselective exposure compared to conventional search; 2) whether and how LLMs\nwith opinion biases that either reinforce or challenge the user's view change\nthe effect. Overall, we found that participants engaged in more biased\ninformation querying with LLM-powered conversational search, and an opinionated\nLLM reinforcing their views exacerbated this bias. These results present\ncritical implications for the development of LLMs and conversational search\nsystems, and the policy governing these technologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in CHI'24. Supplementary material will be available online\n  with the official submission in CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05880v2",
    "published_date": "2024-02-08 18:14:33 UTC",
    "updated_date": "2024-02-10 17:03:58 UTC"
  },
  {
    "arxiv_id": "2402.05868v3",
    "title": "EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs",
    "authors": [
      "Sam Lin",
      "Wenyue Hua",
      "Zhenting Wang",
      "Mingyu Jin",
      "Lizhou Fan",
      "Yongfeng Zhang"
    ],
    "abstract": "Cloud-based Large Language Models (LLMs) such as ChatGPT have become\nincreasingly integral to daily operations. Nevertheless, they also introduce\nprivacy concerns: firstly, numerous studies underscore the risks to user\nprivacy posed by jailbreaking cloud-based LLMs; secondly, the LLM service\nproviders have access to all user data, which deters individuals from\nconfidently utilizing such services. To address such concerns, we propose a\nsimple yet effective paradigm, EmojiPrompt, to protect user privacy. At its\ncore, EmojiPrompt performs generative transformation, obfuscating private data\nwithin prompts with linguistic and non-linguistic elements before submitting\nthem to cloud-based LLMs. We evaluate EmojiPrompt's performance across 8\ndatasets from various domains. We also propose simulated inference attacks to\nassess EmojiPrompt's ability to preserve user privacy. The results demonstrate\nthat EmojiPrompt effectively obfuscates user private data, while largely\nmaintaining, or even enhancing, performances compared to the unobfuscated\nversion. Furthermore, EmojiPrompt's atomic-level obfuscation allows it to\nfunction exclusively with cloud-based LLMs. For source code, please refer to:\nhttps://github.com/agiresearch/EmojiCrypt.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the 2025 Annual Conference of the Nations of the Americas\n  Chapter of the Association for Computational Linguistics (NAACL 2025)",
    "pdf_url": "http://arxiv.org/pdf/2402.05868v3",
    "published_date": "2024-02-08 17:57:11 UTC",
    "updated_date": "2025-03-20 20:15:22 UTC"
  },
  {
    "arxiv_id": "2402.05863v1",
    "title": "How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis",
    "authors": [
      "Federico Bianchi",
      "Patrick John Chia",
      "Mert Yuksekgonul",
      "Jacopo Tagliabue",
      "Dan Jurafsky",
      "James Zou"
    ],
    "abstract": "Negotiation is the basis of social interactions; humans negotiate everything\nfrom the price of cars to how to share common resources. With rapidly growing\ninterest in using large language models (LLMs) to act as agents on behalf of\nhuman users, such LLM agents would also need to be able to negotiate. In this\npaper, we study how well LLMs can negotiate with each other. We develop\nNegotiationArena: a flexible framework for evaluating and probing the\nnegotiation abilities of LLM agents. We implemented three types of scenarios in\nNegotiationArena to assess LLM's behaviors in allocating shared resources\n(ultimatum games), aggregate resources (trading games) and buy/sell goods\n(price negotiations). Each scenario allows for multiple turns of flexible\ndialogues between LLM agents to allow for more complex negotiations.\nInterestingly, LLM agents can significantly boost their negotiation outcomes by\nemploying certain behavioral tactics. For example, by pretending to be desolate\nand desperate, LLMs can improve their payoffs by 20\\% when negotiating against\nthe standard GPT-4. We also quantify irrational negotiation behaviors exhibited\nby the LLM agents, many of which also appear in humans. Together,\n\\NegotiationArena offers a new environment to investigate LLM interactions,\nenabling new insights into LLM's theory of mind, irrationality, and reasoning\nabilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05863v1",
    "published_date": "2024-02-08 17:51:48 UTC",
    "updated_date": "2024-02-08 17:51:48 UTC"
  },
  {
    "arxiv_id": "2402.05862v1",
    "title": "Let Your Graph Do the Talking: Encoding Structured Data for LLMs",
    "authors": [
      "Bryan Perozzi",
      "Bahare Fatemi",
      "Dustin Zelle",
      "Anton Tsitsulin",
      "Mehran Kazemi",
      "Rami Al-Rfou",
      "Jonathan Halcrow"
    ],
    "abstract": "How can we best encode structured data into sequential form for use in large\nlanguage models (LLMs)? In this work, we introduce a parameter-efficient method\nto explicitly represent structured data for LLMs. Our method, GraphToken,\nlearns an encoding function to extend prompts with explicit structured\ninformation. Unlike other work which focuses on limited domains (e.g. knowledge\ngraph representation), our work is the first effort focused on the general\nencoding of structured data to be used for various reasoning tasks. We show\nthat explicitly representing the graph structure allows significant\nimprovements to graph reasoning tasks. Specifically, we see across the board\nimprovements - up to 73% points - on node, edge and, graph-level tasks from the\nGraphQA benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML",
      "I.5.1; I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05862v1",
    "published_date": "2024-02-08 17:51:44 UTC",
    "updated_date": "2024-02-08 17:51:44 UTC"
  },
  {
    "arxiv_id": "2402.05830v1",
    "title": "Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting",
    "authors": [
      "Yanjun Zhao",
      "Tian Zhou",
      "Chao Chen",
      "Liang Sun",
      "Yi Qian",
      "Rong Jin"
    ],
    "abstract": "Time series analysis is vital for numerous applications, and transformers\nhave become increasingly prominent in this domain. Leading methods customize\nthe transformer architecture from NLP and CV, utilizing a patching technique to\nconvert continuous signals into segments. Yet, time series data are uniquely\nchallenging due to significant distribution shifts and intrinsic noise levels.\nTo address these two challenges,we introduce the Sparse Vector Quantized\nFFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse\nvector quantization technique coupled with Reverse Instance Normalization\n(RevIN) to reduce noise impact and capture sufficient statistics for\nforecasting, serving as an alternative to the Feed-Forward layer (FFN) in the\ntransformer architecture. Our FFN-free approach trims the parameter count,\nenhancing computational efficiency and reducing overfitting. Through\nevaluations across ten benchmark datasets, including the newly introduced CAISO\ndataset, Sparse-VQ surpasses leading models with a 7.84% and 4.17% decrease in\nMAE for univariate and multivariate time series forecasting, respectively.\nMoreover, it can be seamlessly integrated with existing transformer-based\nmodels to elevate their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05830v1",
    "published_date": "2024-02-08 17:09:12 UTC",
    "updated_date": "2024-02-08 17:09:12 UTC"
  },
  {
    "arxiv_id": "2402.05829v1",
    "title": "Limitations of Agents Simulated by Predictive Models",
    "authors": [
      "Raymond Douglas",
      "Jacek Karwowski",
      "Chan Bae",
      "Andis Draguns",
      "Victoria Krakovna"
    ],
    "abstract": "There is increasing focus on adapting predictive models into agent-like\nsystems, most notably AI assistants based on language models. We outline two\nstructural reasons for why these models can fail when turned into agents.\nFirst, we discuss auto-suggestive delusions. Prior work has shown theoretically\nthat models fail to imitate agents that generated the training data if the\nagents relied on hidden observations: the hidden observations act as\nconfounding variables, and the models treat actions they generate as evidence\nfor nonexistent observations. Second, we introduce and formally study a\nrelated, novel limitation: predictor-policy incoherence. When a model generates\na sequence of actions, the model's implicit prediction of the policy that\ngenerated those actions can serve as a confounding variable. The result is that\nmodels choose actions as if they expect future actions to be suboptimal,\ncausing them to be overly conservative. We show that both of those failures are\nfixed by including a feedback loop from the environment, that is, re-training\nthe models on their own actions. We give simple demonstrations of both\nlimitations using Decision Transformers and confirm that empirical results\nagree with our conceptual and formal analysis. Our treatment provides a\nunifying view of those failure modes, and informs the question of why\nfine-tuning offline learned policies with online learning makes them more\neffective.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05829v1",
    "published_date": "2024-02-08 17:08:08 UTC",
    "updated_date": "2024-02-08 17:08:08 UTC"
  },
  {
    "arxiv_id": "2402.05828v1",
    "title": "Discovering Temporally-Aware Reinforcement Learning Algorithms",
    "authors": [
      "Matthew Thomas Jackson",
      "Chris Lu",
      "Louis Kirsch",
      "Robert Tjarko Lange",
      "Shimon Whiteson",
      "Jakob Nicolaus Foerster"
    ],
    "abstract": "Recent advancements in meta-learning have enabled the automatic discovery of\nnovel reinforcement learning algorithms parameterized by surrogate objective\nfunctions. To improve upon manually designed algorithms, the parameterization\nof this learned objective function must be expressive enough to represent novel\nprinciples of learning (instead of merely recovering already established ones)\nwhile still generalizing to a wide range of settings outside of its\nmeta-training distribution. However, existing methods focus on discovering\nobjective functions that, like many widely used objective functions in\nreinforcement learning, do not take into account the total number of steps\nallowed for training, or \"training horizon\". In contrast, humans use a plethora\nof different learning objectives across the course of acquiring a new ability.\nFor instance, students may alter their studying techniques based on the\nproximity to exam deadlines and their self-assessed capabilities. This paper\ncontends that ignoring the optimization time horizon significantly restricts\nthe expressive potential of discovered learning algorithms. We propose a simple\naugmentation to two existing objective discovery approaches that allows the\ndiscovered algorithm to dynamically update its objective function throughout\nthe agent's training procedure, resulting in expressive schedules and increased\ngeneralization across different training horizons. In the process, we find that\ncommonly used meta-gradient approaches fail to discover such adaptive objective\nfunctions while evolution strategies discover highly dynamic learning rules. We\ndemonstrate the effectiveness of our approach on a wide range of tasks and\nanalyze the resulting learned algorithms, which we find effectively balance\nexploration and exploitation by modifying the structure of their learning rules\nthroughout the agent's lifetime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05828v1",
    "published_date": "2024-02-08 17:07:42 UTC",
    "updated_date": "2024-02-08 17:07:42 UTC"
  },
  {
    "arxiv_id": "2402.05823v1",
    "title": "FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting",
    "authors": [
      "Ziqing Ma",
      "Wenwei Wang",
      "Tian Zhou",
      "Chao Chen",
      "Bingqing Peng",
      "Liang Sun",
      "Rong Jin"
    ],
    "abstract": "Accurate solar power forecasting is crucial to integrate photovoltaic plants\ninto the electric grid, schedule and secure the power grid safety. This problem\nbecomes more demanding for those newly installed solar plants which lack\nsufficient data. Current research predominantly relies on historical solar\npower data or numerical weather prediction in a single-modality format,\nignoring the complementary information provided in different modalities. In\nthis paper, we propose a multi-modality fusion framework to integrate\nhistorical power data, numerical weather prediction, and satellite images,\nsignificantly improving forecast performance. We introduce a vector quantized\nframework that aligns modalities with varying information densities, striking a\nbalance between integrating sufficient information and averting model\noverfitting. Our framework demonstrates strong zero-shot forecasting\ncapability, which is especially useful for those newly installed plants.\nMoreover, we collect and release a multi-modal solar power (MMSP) dataset from\nreal-world plants to further promote the research of multi-modal solar\nforecasting algorithms. Our extensive experiments show that our model not only\noperates with robustness but also boosts accuracy in both zero-shot forecasting\nand scenarios rich with training data, surpassing leading models. We have\nincorporated it into our eForecaster platform and deployed it for more than 300\nsolar plants with a capacity of over 15GW.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05823v1",
    "published_date": "2024-02-08 17:03:10 UTC",
    "updated_date": "2024-02-08 17:03:10 UTC"
  },
  {
    "arxiv_id": "2402.05813v2",
    "title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models",
    "authors": [
      "Lingzhi Wang",
      "Xingshan Zeng",
      "Jinsong Guo",
      "Kam-Fai Wong",
      "Georg Gottlob"
    ],
    "abstract": "This paper explores Machine Unlearning (MU), an emerging field that is\ngaining increased attention due to concerns about neural models unintentionally\nremembering personal or sensitive information. We present SeUL, a novel method\nthat enables selective and fine-grained unlearning for language models. Unlike\nprevious work that employs a fully reversed training objective in unlearning,\nSeUL minimizes the negative impact on the capability of language models,\nparticularly in terms of generation. Furthermore, we introduce two innovative\nevaluation metrics, sensitive extraction likelihood (S-EL) and sensitive\nmemorization accuracy (S-MA), specifically designed to assess the effectiveness\nof forgetting sensitive information. In support of the unlearning framework, we\npropose efficient automatic online and offline sensitive span annotation\nmethods. The online selection method, based on language probability scores,\nensures computational efficiency, while the offline annotation involves a\ntwo-stage LLM-based process for robust verification. In summary, this paper\ncontributes a novel selective unlearning method (SeUL), introduces specialized\nevaluation metrics (S-EL and S-MA) for assessing sensitive information\nforgetting, and proposes automatic online and offline sensitive span annotation\nmethods to support the overall unlearning framework and evaluation process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2402.05813v2",
    "published_date": "2024-02-08 16:50:01 UTC",
    "updated_date": "2024-12-16 12:44:07 UTC"
  },
  {
    "arxiv_id": "2402.05809v3",
    "title": "You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement",
    "authors": [
      "Qingsen Yan",
      "Yixu Feng",
      "Cheng Zhang",
      "Pei Wang",
      "Peng Wu",
      "Wei Dong",
      "Jinqiu Sun",
      "Yanning Zhang"
    ],
    "abstract": "Low-Light Image Enhancement (LLIE) task tends to restore the details and\nvisual information from corrupted low-light images. Most existing methods learn\nthe mapping function between low/normal-light images by Deep Neural Networks\n(DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves\namplifying image signals, and applying these color spaces to low-light images\nwith a low signal-to-noise ratio can introduce sensitivity and instability into\nthe enhancement process. Consequently, this results in the presence of color\nartifacts and brightness artifacts in the enhanced images. To alleviate this\nproblem, we propose a novel trainable color space, named\nHorizontal/Vertical-Intensity (HVI). It not only decouples brightness and color\nfrom RGB channels to mitigate the instability during enhancement but also\nadapts to low-light images in different illumination ranges due to the\ntrainable parameters. Further, we design a novel Color and Intensity Decoupling\nNetwork (CIDNet) with two branches dedicated to processing the decoupled image\nbrightness and color in the HVI space. Within CIDNet, we introduce the\nLightweight Cross-Attention (LCA) module to facilitate interaction between\nimage structure and content information in both branches, while also\nsuppressing noise in low-light images. Finally, we conducted 22 quantitative\nand qualitative experiments to show that the proposed CIDNet outperforms the\nstate-of-the-art methods on 11 datasets. The code is available at\nhttps://github.com/Fediory/HVI-CIDNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Qingsen Yan, Yixu Feng, Cheng Zhang contributed equally to this work.\n  Corresponding author: Yanning Zhang",
    "pdf_url": "http://arxiv.org/pdf/2402.05809v3",
    "published_date": "2024-02-08 16:47:43 UTC",
    "updated_date": "2024-06-17 20:43:01 UTC"
  },
  {
    "arxiv_id": "2402.05808v2",
    "title": "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning",
    "authors": [
      "Zhiheng Xi",
      "Wenxiang Chen",
      "Boyang Hong",
      "Senjie Jin",
      "Rui Zheng",
      "Wei He",
      "Yiwen Ding",
      "Shichun Liu",
      "Xin Guo",
      "Junzhe Wang",
      "Honglin Guo",
      "Wei Shen",
      "Xiaoran Fan",
      "Yuhao Zhou",
      "Shihan Dou",
      "Xiao Wang",
      "Xinbo Zhang",
      "Peng Sun",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "In this paper, we propose R$^3$: Learning Reasoning through Reverse\nCurriculum Reinforcement Learning (RL), a novel method that employs only\noutcome supervision to achieve the benefits of process supervision for large\nlanguage models. The core challenge in applying RL to complex reasoning is to\nidentify a sequence of actions that result in positive rewards and provide\nappropriate supervision for optimization. Outcome supervision provides sparse\nrewards for final results without identifying error locations, whereas process\nsupervision offers step-wise rewards but requires extensive manual annotation.\nR$^3$ overcomes these limitations by learning from correct demonstrations.\nSpecifically, R$^3$ progressively slides the start state of reasoning from a\ndemonstration's end to its beginning, facilitating easier model exploration at\nall stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome\nsupervision to offer step-level signals and precisely pinpoint errors. Using\nLlama2-7B, our method surpasses RL baseline on eight reasoning tasks by $4.1$\npoints on average. Notebaly, in program-based reasoning on GSM8K, it exceeds\nthe baseline by $4.2$ points across three backbone models, and without any\nextra data, Codellama-7B + R$^3$ performs comparable to larger models or\nclosed-source models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint. Codes released:\n  https://github.com/WooooDyy/LLM-Reverse-Curriculum-RL",
    "pdf_url": "http://arxiv.org/pdf/2402.05808v2",
    "published_date": "2024-02-08 16:46:26 UTC",
    "updated_date": "2024-03-17 09:02:02 UTC"
  },
  {
    "arxiv_id": "2402.05804v3",
    "title": "InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write",
    "authors": [
      "Blagoj Mitrevski",
      "Arina Rak",
      "Julian Schnitzler",
      "Chengkun Li",
      "Andrii Maksai",
      "Jesse Berent",
      "Claudiu Musat"
    ],
    "abstract": "Digital note-taking is gaining popularity, offering a durable, editable, and\neasily indexable way of storing notes in a vectorized form, known as digital\nink. However, a substantial gap remains between this way of note-taking and\ntraditional pen-and-paper note-taking, a practice that is still favored by a\nvast majority. Our work InkSight, aims to bridge the gap by empowering physical\nnote-takers to effortlessly convert their work (offline handwriting) to digital\nink (online handwriting), a process we refer to as derendering. Prior research\non the topic has focused on the geometric properties of images, resulting in\nlimited generalization beyond their training domains. Our approach combines\nreading and writing priors, allowing training a model in the absence of large\namounts of paired samples, which are difficult to obtain. To our knowledge,\nthis is the first work that effectively derenders handwritten text in arbitrary\nphotos with diverse visual characteristics and backgrounds. Furthermore, it\ngeneralizes beyond its training domain into simple sketches. Our human\nevaluation reveals that 87% of the samples produced by our model on the\nchallenging HierText dataset are considered as a valid tracing of the input\nimage and 67% look like a pen trajectory traced by a human.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Add release info",
    "pdf_url": "http://arxiv.org/pdf/2402.05804v3",
    "published_date": "2024-02-08 16:41:41 UTC",
    "updated_date": "2024-12-08 21:05:43 UTC"
  },
  {
    "arxiv_id": "2402.05794v1",
    "title": "Phonetically rich corpus construction for a low-resourced language",
    "authors": [
      "Marcellus Amadeus",
      "William Alberto Cruz Castañeda",
      "Wilmer Lobato",
      "Niasche Aquino"
    ],
    "abstract": "Speech technologies rely on capturing a speaker's voice variability while\nobtaining comprehensive language information. Textual prompts and sentence\nselection methods have been proposed in the literature to comprise such\nadequate phonetic data, referred to as a phonetically rich \\textit{corpus}.\nHowever, they are still insufficient for acoustic modeling, especially critical\nfor languages with limited resources. Hence, this paper proposes a novel\napproach and outlines the methodological aspects required to create a\n\\textit{corpus} with broad phonetic coverage for a low-resourced language,\nBrazilian Portuguese. Our methodology includes text dataset collection up to a\nsentence selection algorithm based on triphone distribution. Furthermore, we\npropose a new phonemic classification according to acoustic-articulatory speech\nfeatures since the absolute number of distinct triphones, or low-probability\ntriphones, does not guarantee an adequate representation of every possible\ncombination. Using our algorithm, we achieve a 55.8\\% higher percentage of\ndistinct triphones -- for samples of similar size -- while the currently\navailable phonetic-rich corpus, CETUC and TTS-Portuguese, 12.6\\% and 12.3\\% in\ncomparison to a non-phonetically rich dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05794v1",
    "published_date": "2024-02-08 16:36:11 UTC",
    "updated_date": "2024-02-08 16:36:11 UTC"
  },
  {
    "arxiv_id": "2402.05786v2",
    "title": "Prompting Fairness: Artificial Intelligence as Game Players",
    "authors": [
      "Jazmia Henry"
    ],
    "abstract": "Utilitarian games such as dictator games to measure fairness have been\nstudied in the social sciences for decades. These games have given us insight\ninto not only how humans view fairness but also in what conditions the\nfrequency of fairness, altruism and greed increase or decrease. While these\ngames have traditionally been focused on humans, the rise of AI gives us the\nability to study how these models play these games. AI is becoming a constant\nin human interaction and examining how these models portray fairness in game\nplay can give us some insight into how AI makes decisions. Over 101 rounds of\nthe dictator game, I conclude that AI has a strong sense of fairness that is\ndependant of it it deems the person it is playing with as trustworthy, framing\nhas a strong effect on how much AI gives a recipient when designated the\ntrustee, and there may be evidence that AI experiences inequality aversion just\nas humans.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.05786v2",
    "published_date": "2024-02-08 16:24:40 UTC",
    "updated_date": "2024-02-09 04:19:26 UTC"
  },
  {
    "arxiv_id": "2402.05785v5",
    "title": "Limits of Transformer Language Models on Learning to Compose Algorithms",
    "authors": [
      "Jonathan Thomm",
      "Giacomo Camposampiero",
      "Aleksandar Terzic",
      "Michael Hersche",
      "Bernhard Schölkopf",
      "Abbas Rahimi"
    ],
    "abstract": "We analyze the capabilities of Transformer language models in learning\ncompositional discrete tasks. To this end, we evaluate training LLaMA models\nand prompting GPT-4 and Gemini on four tasks demanding to learn a composition\nof several discrete sub-tasks. In particular, we measure how well these models\ncan reuse primitives observable in the sub-tasks to learn the composition task.\nOur results indicate that compositional learning in state-of-the-art\nTransformer language models is highly sample inefficient: LLaMA requires more\ndata samples than relearning all sub-tasks from scratch to learn the\ncompositional task; in-context prompting with few samples is unreliable and\nfails at executing the sub-tasks or correcting the errors in multi-round code\ngeneration. Further, by leveraging complexity theory, we support these findings\nwith a theoretical analysis focused on the sample inefficiency of gradient\ndescent in memorizing feedforward models. We open source our code at\nhttps://github.com/IBM/limitations-lm-algorithmic-compositional-learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05785v5",
    "published_date": "2024-02-08 16:23:29 UTC",
    "updated_date": "2024-11-05 06:32:38 UTC"
  },
  {
    "arxiv_id": "2402.05782v1",
    "title": "Analysing the Sample Complexity of Opponent Shaping",
    "authors": [
      "Kitty Fung",
      "Qizhen Zhang",
      "Chris Lu",
      "Jia Wan",
      "Timon Willi",
      "Jakob Foerster"
    ],
    "abstract": "Learning in general-sum games often yields collectively sub-optimal results.\nAddressing this, opponent shaping (OS) methods actively guide the learning\nprocesses of other agents, empirically leading to improved individual and group\nperformances in many settings. Early OS methods use higher-order derivatives to\nshape the learning of co-players, making them unsuitable for shaping multiple\nlearning steps. Follow-up work, Model-free Opponent Shaping (M-FOS), addresses\nthese by reframing the OS problem as a meta-game. In contrast to early OS\nmethods, there is little theoretical understanding of the M-FOS framework.\nProviding theoretical guarantees for M-FOS is hard because A) there is little\nliterature on theoretical sample complexity bounds for meta-reinforcement\nlearning B) M-FOS operates in continuous state and action spaces, so\ntheoretical analysis is challenging. In this work, we present R-FOS, a tabular\nversion of M-FOS that is more suitable for theoretical analysis. R-FOS\ndiscretises the continuous meta-game MDP into a tabular MDP. Within this\ndiscretised MDP, we adapt the $R_{max}$ algorithm, most prominently used to\nderive PAC-bounds for MDPs, as the meta-learner in the R-FOS algorithm. We\nderive a sample complexity bound that is exponential in the cardinality of the\ninner state and action space and the number of agents. Our bound guarantees\nthat, with high probability, the final policy learned by an R-FOS agent is\nclose to the optimal policy, apart from a constant factor. Finally, we\ninvestigate how R-FOS's sample complexity scales in the size of state-action\nspace. Our theoretical results on scaling are supported empirically in the\nMatching Pennies environment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05782v1",
    "published_date": "2024-02-08 16:17:18 UTC",
    "updated_date": "2024-02-08 16:17:18 UTC"
  },
  {
    "arxiv_id": "2402.05774v1",
    "title": "Stable Autonomous Flow Matching",
    "authors": [
      "Christopher Iliffe Sprague",
      "Arne Elofsson",
      "Hossein Azizpour"
    ],
    "abstract": "In contexts where data samples represent a physically stable state, it is\noften assumed that the data points represent the local minima of an energy\nlandscape. In control theory, it is well-known that energy can serve as an\neffective Lyapunov function. Despite this, connections between control theory\nand generative models in the literature are sparse, even though there are\nseveral machine learning applications with physically stable data points. In\nthis paper, we focus on such data and a recent class of deep generative models\ncalled flow matching. We apply tools of stochastic stability for\ntime-independent systems to flow matching models. In doing so, we characterize\nthe space of flow matching models that are amenable to this treatment, as well\nas draw connections to other control theory principles. We demonstrate our\ntheoretical results on two examples.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "In submission",
    "pdf_url": "http://arxiv.org/pdf/2402.05774v1",
    "published_date": "2024-02-08 16:01:24 UTC",
    "updated_date": "2024-02-08 16:01:24 UTC"
  },
  {
    "arxiv_id": "2402.07939v5",
    "title": "UFO: A UI-Focused Agent for Windows OS Interaction",
    "authors": [
      "Chaoyun Zhang",
      "Liqun Li",
      "Shilin He",
      "Xu Zhang",
      "Bo Qiao",
      "Si Qin",
      "Minghua Ma",
      "Yu Kang",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "We introduce UFO, an innovative UI-Focused agent to fulfill user requests\ntailored to applications on Windows OS, harnessing the capabilities of\nGPT-Vision. UFO employs a dual-agent framework to meticulously observe and\nanalyze the graphical user interface (GUI) and control information of Windows\napplications. This enables the agent to seamlessly navigate and operate within\nindividual applications and across them to fulfill user requests, even when\nspanning multiple applications. The framework incorporates a control\ninteraction module, facilitating action grounding without human intervention\nand enabling fully automated execution. Consequently, UFO transforms arduous\nand time-consuming processes into simple tasks achievable solely through\nnatural language commands. We conducted testing of UFO across 9 popular Windows\napplications, encompassing a variety of scenarios reflective of users' daily\nusage. The results, derived from both quantitative metrics and real-case\nstudies, underscore the superior effectiveness of UFO in fulfilling user\nrequests. To the best of our knowledge, UFO stands as the first UI agent\nspecifically tailored for task completion within the Windows OS environment.\nThe open-source code for UFO is available on https://github.com/microsoft/UFO.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07939v5",
    "published_date": "2024-02-08 15:40:35 UTC",
    "updated_date": "2024-05-23 05:18:58 UTC"
  },
  {
    "arxiv_id": "2402.05749v2",
    "title": "Generalized Preference Optimization: A Unified Approach to Offline Alignment",
    "authors": [
      "Yunhao Tang",
      "Zhaohan Daniel Guo",
      "Zeyu Zheng",
      "Daniele Calandriello",
      "Rémi Munos",
      "Mark Rowland",
      "Pierre Harvey Richemond",
      "Michal Valko",
      "Bernardo Ávila Pires",
      "Bilal Piot"
    ],
    "abstract": "Offline preference optimization allows fine-tuning large models directly from\noffline data, and has proved effective in recent alignment practices. We\npropose generalized preference optimization (GPO), a family of offline losses\nparameterized by a general class of convex functions. GPO enables a unified\nview over preference optimization, encompassing existing algorithms such as\nDPO, IPO and SLiC as special cases, while naturally introducing new variants.\nThe GPO framework also sheds light on how offline algorithms enforce\nregularization, through the design of the convex function that defines the\nloss. Our analysis and experiments reveal the connections and subtle\ndifferences between the offline regularization and the KL divergence\nregularization intended by the canonical RLHF formulation. In a controlled\nsetting akin to Gao et al 2023, we also show that different GPO variants\nachieve similar trade-offs between regularization and performance, though the\noptimal values of hyper-parameter might differ as predicted by theory. In all,\nour results present new algorithmic toolkits and empirical insights to\nalignment practitioners.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2023 main conference",
    "pdf_url": "http://arxiv.org/pdf/2402.05749v2",
    "published_date": "2024-02-08 15:33:09 UTC",
    "updated_date": "2024-05-28 23:25:15 UTC"
  },
  {
    "arxiv_id": "2402.05747v1",
    "title": "Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method",
    "authors": [
      "Qiuhao Li",
      "Shenghai Yuan"
    ],
    "abstract": "In the context of rapid advancements in industrial automation, vision-based\nrobotic grasping plays an increasingly crucial role. In order to enhance visual\nrecognition accuracy, the utilization of large-scale datasets is imperative for\ntraining models to acquire implicit knowledge related to the handling of\nvarious objects. Creating datasets from scratch is a time and labor-intensive\nprocess. Moreover, existing datasets often contain errors due to automated\nannotations aimed at expediency, making the improvement of these datasets a\nsubstantial research challenge. Consequently, several issues have been\nidentified in the annotation of grasp bounding boxes within the popular\nJacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance\ndataset quality. This approach relies on backbone deep learning networks to\npredict object positions and orientations for robotic grasping. Predictions\nwith Intersection over Union (IOU) values below 0.2 undergo an assessment by\nhuman operators. After their evaluation, the data is categorized into False\nNegatives(FN) and True Negatives(TN). FN are then subcategorized into either\nmissing annotations or catastrophic labeling errors. Images lacking labels are\naugmented with valid grasp bounding box information, whereas images afflicted\nby catastrophic labeling errors are completely removed. The open-source tool\nLabelbee was employed for 53,026 iterations of HIL dataset enhancement, leading\nto the removal of 2,884 images and the incorporation of ground truth\ninformation for 30,292 images. The enhanced dataset, named the Jacquard V2\nGrasping Dataset, served as the training data for a range of neural networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05747v1",
    "published_date": "2024-02-08 15:32:22 UTC",
    "updated_date": "2024-02-08 15:32:22 UTC"
  },
  {
    "arxiv_id": "2402.05741v2",
    "title": "Real-World Robot Applications of Foundation Models: A Review",
    "authors": [
      "Kento Kawaharazuka",
      "Tatsuya Matsushima",
      "Andrew Gambardella",
      "Jiaxian Guo",
      "Chris Paxton",
      "Andy Zeng"
    ],
    "abstract": "Recent developments in foundation models, like Large Language Models (LLMs)\nand Vision-Language Models (VLMs), trained on extensive data, facilitate\nflexible application across different tasks and modalities. Their impact spans\nvarious fields, including healthcare, education, and robotics. This paper\nprovides an overview of the practical application of foundation models in\nreal-world robotics, with a primary emphasis on the replacement of specific\ncomponents within existing robot systems. The summary encompasses the\nperspective of input-output relationships in foundation models, as well as\ntheir role in perception, motion planning, and control within the field of\nrobotics. This paper concludes with a discussion of future challenges and\nimplications for practical robot applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05741v2",
    "published_date": "2024-02-08 15:19:50 UTC",
    "updated_date": "2024-10-23 03:39:00 UTC"
  },
  {
    "arxiv_id": "2402.05724v2",
    "title": "Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL",
    "authors": [
      "Jiawei Huang",
      "Niao He",
      "Andreas Krause"
    ],
    "abstract": "We study the sample complexity of reinforcement learning (RL) in Mean-Field\nGames (MFGs) with model-based function approximation that requires strategic\nexploration to find a Nash Equilibrium policy. We introduce the Partial\nModel-Based Eluder Dimension (P-MBED), a more effective notion to characterize\nthe model class complexity. Notably, P-MBED measures the complexity of the\nsingle-agent model class converted from the given mean-field model class, and\npotentially, can be exponentially lower than the MBED proposed by\n\\citet{huang2023statistical}. We contribute a model elimination algorithm\nfeaturing a novel exploration strategy and establish sample complexity results\npolynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic\nrealizability and Lipschitz continuity assumptions, \\emph{learning Nash\nEquilibrium in MFGs is no more statistically challenging than solving a\nlogarithmic number of single-agent RL problems}. We further extend our results\nto Multi-Type MFGs, generalizing from conventional MFGs and involving multiple\ntypes of agents. This extension implies statistical tractability of a broader\nclass of Markov Games through the efficacy of mean-field approximation.\nFinally, inspired by our theoretical algorithm, we present a heuristic approach\nwith improved computational efficiency and empirically demonstrate its\neffectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024; 55 Pages",
    "pdf_url": "http://arxiv.org/pdf/2402.05724v2",
    "published_date": "2024-02-08 14:54:47 UTC",
    "updated_date": "2024-06-03 15:29:09 UTC"
  },
  {
    "arxiv_id": "2402.05713v3",
    "title": "Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on Vulnerable Patient Populations",
    "authors": [
      "Pranav Kulkarni",
      "Andrew Chan",
      "Nithya Navarathna",
      "Skylar Chan",
      "Paul H. Yi",
      "Vishwa S. Parekh"
    ],
    "abstract": "The proliferation of artificial intelligence (AI) in radiology has shed light\non the risk of deep learning (DL) models exacerbating clinical biases towards\nvulnerable patient populations. While prior literature has focused on\nquantifying biases exhibited by trained DL models, demographically targeted\nadversarial bias attacks on DL models and its implication in the clinical\nenvironment remains an underexplored field of research in medical imaging. In\nthis work, we demonstrate that demographically targeted label poisoning attacks\ncan introduce undetectable underdiagnosis bias in DL models. Our results across\nmultiple performance metrics and demographic groups like sex, age, and their\nintersectional subgroups show that adversarial bias attacks demonstrate\nhigh-selectivity for bias in the targeted group by degrading group model\nperformance without impacting overall model performance. Furthermore, our\nresults indicate that adversarial bias attacks result in biased DL models that\npropagate prediction bias even when evaluated with external datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05713v3",
    "published_date": "2024-02-08 14:40:32 UTC",
    "updated_date": "2024-04-07 16:59:41 UTC"
  },
  {
    "arxiv_id": "2402.05712v1",
    "title": "DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer",
    "authors": [
      "Zhiyuan Ma",
      "Xiangyu Zhu",
      "Guojun Qi",
      "Chen Qian",
      "Zhaoxiang Zhang",
      "Zhen Lei"
    ],
    "abstract": "Speech-driven 3D facial animation is important for many multimedia\napplications. Recent work has shown promise in using either Diffusion models or\nTransformer architectures for this task. However, their mere aggregation does\nnot lead to improved performance. We suspect this is due to a shortage of\npaired audio-4D data, which is crucial for the Transformer to effectively\nperform as a denoiser within the Diffusion framework. To tackle this issue, we\npresent DiffSpeaker, a Transformer-based network equipped with novel biased\nconditional attention modules. These modules serve as substitutes for the\ntraditional self/cross-attention in standard Transformers, incorporating\nthoughtfully designed biases that steer the attention mechanisms to concentrate\non both the relevant task-specific and diffusion-related conditions. We also\nexplore the trade-off between accurate lip synchronization and non-verbal\nfacial expressions within the Diffusion paradigm. Experiments show our model\nnot only achieves state-of-the-art performance on existing benchmarks, but also\nfast inference speed owing to its ability to generate facial motions in\nparallel.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures. Code is avalable at\n  https://github.com/theEricMa/DiffSpeaker",
    "pdf_url": "http://arxiv.org/pdf/2402.05712v1",
    "published_date": "2024-02-08 14:39:16 UTC",
    "updated_date": "2024-02-08 14:39:16 UTC"
  },
  {
    "arxiv_id": "2402.05703v1",
    "title": "Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming",
    "authors": [
      "Giorgio Angelotti",
      "Caroline P. C. Chanel",
      "Adam H. M. Pinto",
      "Christophe Lounis",
      "Corentin Chauffaut",
      "Nicolas Drougard"
    ],
    "abstract": "The integration of physiological computing into mixed-initiative human-robot\ninteraction systems offers valuable advantages in autonomous task allocation by\nincorporating real-time features as human state observations into the\ndecision-making system. This approach may alleviate the cognitive load on human\noperators by intelligently allocating mission tasks between agents.\nNevertheless, accommodating a diverse pool of human participants with varying\nphysiological and behavioral measurements presents a substantial challenge. To\naddress this, resorting to a probabilistic framework becomes necessary, given\nthe inherent uncertainty and partial observability on the human's state. Recent\nresearch suggests to learn a Partially Observable Markov Decision Process\n(POMDP) model from a data set of previously collected experiences that can be\nsolved using Offline Reinforcement Learning (ORL) methods. In the present work,\nwe not only highlight the potential of partially observable representations and\nphysiological measurements to improve human operator state estimation and\nperformance, but also enhance the overall mission effectiveness of a\nhuman-robot team. Importantly, as the fixed data set may not contain enough\ninformation to fully represent complex stochastic processes, we propose a\nmethod to incorporate model uncertainty, thus enabling risk-sensitive\nsequential decision-making. Experiments were conducted with a group of\ntwenty-six human participants within a simulated robot teleoperation\nenvironment, yielding empirical evidence of the method's efficacy. The obtained\nadaptive task allocation policy led to statistically significant higher scores\nthan the one that was used to collect the data set, allowing for generalization\nacross diverse participants also taking into account risk-sensitive metrics.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted as a full paper at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05703v1",
    "published_date": "2024-02-08 14:27:34 UTC",
    "updated_date": "2024-02-08 14:27:34 UTC"
  },
  {
    "arxiv_id": "2402.05699v3",
    "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
    "authors": [
      "Xianghe Pang",
      "Shuo Tang",
      "Rui Ye",
      "Yuxin Xiong",
      "Bolun Zhang",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "Aligning large language models (LLMs) with human values is imperative to\nmitigate potential adverse effects resulting from their misuse. Drawing from\nthe sociological insight that acknowledging all parties' concerns is a key\nfactor in shaping human values, this paper proposes a novel direction to align\nLLMs by themselves: social scene simulation. To achieve this, we present\nMATRIX, a novel social scene simulator that emulates realistic scenes around a\nuser's input query, enabling the LLM to take social consequences into account\nbefore responding. MATRIX serves as a virtual rehearsal space, akin to a\nMonopolylogue, where the LLM performs diverse roles related to the query and\npractice by itself. To inject this alignment, we fine-tune the LLM with\nMATRIX-simulated data, ensuring adherence to human values without compromising\ninference speed. We theoretically show that the LLM with MATRIX outperforms\nConstitutional AI under mild assumptions. Finally, extensive experiments\nvalidate that our method outperforms over 10 baselines across 4 benchmarks. As\nevidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning\nwith human values. See our project page at\nhttps://shuotang123.github.io/MATRIX.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05699v3",
    "published_date": "2024-02-08 14:21:03 UTC",
    "updated_date": "2024-06-08 06:13:55 UTC"
  },
  {
    "arxiv_id": "2402.05680v3",
    "title": "Interpretable classifiers for tabular data via discretization and feature selection",
    "authors": [
      "Reijo Jaakkola",
      "Tomi Janhunen",
      "Antti Kuusisto",
      "Masood Feyzbakhsh Rankooh",
      "Miikka Vilander"
    ],
    "abstract": "We introduce a method for computing immediately human interpretable yet\naccurate classifiers from tabular data. The classifiers obtained are short\nBoolean formulas, computed via first discretizing the original data and then\nusing feature selection coupled with a very fast algorithm for producing the\nbest possible Boolean classifier for the setting. We demonstrate the approach\nvia 12 experiments, obtaining results with accuracies comparable to ones\nobtained via random forests, XGBoost, and existing results for the same\ndatasets in the literature. In most cases, the accuracy of our method is in\nfact similar to that of the reference methods, even though the main objective\nof our study is the immediate interpretability of our classifiers. We also\nprove a new result on the probability that the classifier we obtain from\nreal-life data corresponds to the ideally best classifier with respect to the\nbackground distribution the data comes from.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "I.2.6; F.4.1; I.2.4; E.2"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint of a paper in DAO-XAI 2024 (Data meets Applied Ontologies in\n  Explainable AI)",
    "pdf_url": "http://arxiv.org/pdf/2402.05680v3",
    "published_date": "2024-02-08 13:58:16 UTC",
    "updated_date": "2024-09-18 11:43:43 UTC"
  },
  {
    "arxiv_id": "2402.14582v1",
    "title": "Enhancement of High-definition Map Update Service Through Coverage-aware and Reinforcement Learning",
    "authors": [
      "Jeffrey Redondo",
      "Zhenhui Yuan",
      "Nauman Aslam"
    ],
    "abstract": "High-definition (HD) Map systems will play a pivotal role in advancing\nautonomous driving to a higher level, thanks to the significant improvement\nover traditional two-dimensional (2D) maps. Creating an HD Map requires a huge\namount of on-road and off-road data. Typically, these raw datasets are\ncollected and uploaded to cloud-based HD map service providers through\nvehicular networks. Nevertheless, there are challenges in transmitting the raw\ndata over vehicular wireless channels due to the dynamic topology. As the\nnumber of vehicles increases, there is a detrimental impact on service quality,\nwhich acts as a barrier to a real-time HD Map system for collaborative driving\nin Autonomous Vehicles (AV). In this paper, to overcome network congestion, a\nQ-learning coverage-time-awareness algorithm is presented to optimize the\nquality of service for vehicular networks and HD map updates. The algorithm is\nevaluated in an environment that imitates a dynamic scenario where vehicles\nenter and leave. Results showed an improvement in latency for HD map data of\n$75\\%$, $73\\%$, and $10\\%$ compared with IEEE802.11p without Quality of Service\n(QoS), IEEE802.11 with QoS, and IEEE802.11p with new access category (AC) for\nHD map, respectively.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14582v1",
    "published_date": "2024-02-08 13:51:13 UTC",
    "updated_date": "2024-02-08 13:51:13 UTC"
  },
  {
    "arxiv_id": "2402.05668v2",
    "title": "Comprehensive Assessment of Jailbreak Attacks Against LLMs",
    "authors": [
      "Junjie Chu",
      "Yugeng Liu",
      "Ziqing Yang",
      "Xinyue Shen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "abstract": "Jailbreak attacks aim to bypass the safeguards of LLMs. While researchers\nhave studied different jailbreak attacks in depth, they have done so in\nisolation -- either with unaligned experiment settings or comparing a limited\nrange of methods. To fill this gap, we present the first large-scale\nmeasurement of various jailbreak attack methods. We collect 17 cutting-edge\njailbreak methods, summarize their features, and establish a novel jailbreak\nattack taxonomy. Based on eight popular censored LLMs and 160 questions from 16\nviolation categories, we conduct a unified and impartial assessment of attack\neffectiveness as well as a comprehensive ablation study. Our extensive\nexperimental results demonstrate that all the jailbreak attacks have a powerful\neffect on the LLMs. This indicates that all LLMs fail to cover all the\nviolation categories, and they are susceptible to significant jailbreak risks,\nwith even the well-aligned Llama3 facing a maximum attack success rate of 0.88.\nAdditionally, we test jailbreak attacks under eight advanced external defenses\nand find none of the defenses could mitigate the jailbreak attacks entirely.\nOur study offers valuable insights for future research on jailbreak attacks and\ndefenses and serves as a benchmark tool for researchers and practitioners to\nevaluate them effectively.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "22 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05668v2",
    "published_date": "2024-02-08 13:42:50 UTC",
    "updated_date": "2024-12-16 15:02:14 UTC"
  },
  {
    "arxiv_id": "2402.05663v2",
    "title": "Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction",
    "authors": [
      "Raphael Chekroun",
      "Han Wang",
      "Jonathan Lee",
      "Marin Toromanoff",
      "Sascha Hornauer",
      "Fabien Moutarde",
      "Maria Laura Delle Monache"
    ],
    "abstract": "Accurate real-time traffic state forecasting plays a pivotal role in traffic\ncontrol research. In particular, the CIRCLES consortium project necessitates\npredictive techniques to mitigate the impact of data source delays. After the\nsuccess of the MegaVanderTest experiment, this paper aims at overcoming the\ncurrent system limitations and develop a more suited approach to improve the\nreal-time traffic state estimation for the next iterations of the experiment.\nIn this paper, we introduce the SA-LSTM, a deep forecasting method integrating\nSelf-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM)\nyielding state-of-the-art results in real-time mesoscale traffic forecasting.\nWe extend this approach to multi-step forecasting with the n-step SA-LSTM,\nwhich outperforms traditional multi-step forecasting methods in the trade-off\nbetween short-term and long-term predictions, all while operating in real-time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05663v2",
    "published_date": "2024-02-08 13:27:10 UTC",
    "updated_date": "2024-03-04 12:01:53 UTC"
  },
  {
    "arxiv_id": "2402.05660v1",
    "title": "Rethinking Propagation for Unsupervised Graph Domain Adaptation",
    "authors": [
      "Meihan Liu",
      "Zeyu Fang",
      "Zhen Zhang",
      "Ming Gu",
      "Sheng Zhou",
      "Xin Wang",
      "Jiajun Bu"
    ],
    "abstract": "Unsupervised Graph Domain Adaptation (UGDA) aims to transfer knowledge from a\nlabelled source graph to an unlabelled target graph in order to address the\ndistribution shifts between graph domains. Previous works have primarily\nfocused on aligning data from the source and target graph in the representation\nspace learned by graph neural networks (GNNs). However, the inherent\ngeneralization capability of GNNs has been largely overlooked. Motivated by our\nempirical analysis, we reevaluate the role of GNNs in graph domain adaptation\nand uncover the pivotal role of the propagation process in GNNs for adapting to\ndifferent graph domains. We provide a comprehensive theoretical analysis of\nUGDA and derive a generalization bound for multi-layer GNNs. By formulating GNN\nLipschitz for k-layer GNNs, we show that the target risk bound can be tighter\nby removing propagation layers in source graph and stacking multiple\npropagation layers in target graph. Based on the empirical and theoretical\nanalysis mentioned above, we propose a simple yet effective approach called\nA2GNN for graph domain adaptation. Through extensive experiments on real-world\ndatasets, we demonstrate the effectiveness of our proposed A2GNN framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI-24",
    "pdf_url": "http://arxiv.org/pdf/2402.05660v1",
    "published_date": "2024-02-08 13:24:57 UTC",
    "updated_date": "2024-02-08 13:24:57 UTC"
  },
  {
    "arxiv_id": "2402.05650v3",
    "title": "Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks",
    "authors": [
      "Wei Wang",
      "Huilong Ning",
      "Gaowei Zhang",
      "Libo Liu",
      "Yi Wang"
    ],
    "abstract": "Recently, large language models (LLM) based generative AI has been gaining\nmomentum for their impressive high-quality performances in multiple domains,\nparticularly after the release of the ChatGPT. Many believe that they have the\npotential to perform general-purpose problem-solving in software development\nand replace human software developers. Nevertheless, there are in a lack of\nserious investigation into the capability of these LLM techniques in fulfilling\nsoftware development tasks. In a controlled 2 x 2 between-subject experiment\nwith 109 participants, we examined whether and to what degree working with\nChatGPT was helpful in the coding task and typical software development task\nand how people work with ChatGPT. We found that while ChatGPT performed well in\nsolving simple coding problems, its performance in supporting typical software\ndevelopment tasks was not that good. We also observed the interactions between\nparticipants and ChatGPT and found the relations between the interactions and\nthe outcomes. Our study thus provides first-hand insights into using ChatGPT to\nfulfill software engineering tasks with real-world developers and motivates the\nneed for novel interaction mechanisms that help developers effectively work\nwith large language models to achieve desired outcomes.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "65-XX",
      "D.2; I.2"
    ],
    "primary_category": "cs.SE",
    "comment": "The paper has been accepted by FSE",
    "pdf_url": "http://arxiv.org/pdf/2402.05650v3",
    "published_date": "2024-02-08 13:07:31 UTC",
    "updated_date": "2024-02-21 08:16:34 UTC"
  },
  {
    "arxiv_id": "2402.05643v5",
    "title": "Improving Token-Based World Models with Parallel Observation Prediction",
    "authors": [
      "Lior Cohen",
      "Kaixin Wang",
      "Bingyi Kang",
      "Shie Mannor"
    ],
    "abstract": "Motivated by the success of Transformers when applied to sequences of\ndiscrete symbols, token-based world models (TBWMs) were recently proposed as\nsample-efficient methods. In TBWMs, the world model consumes agent experience\nas a language-like sequence of tokens, where each observation constitutes a\nsub-sequence. However, during imagination, the sequential token-by-token\ngeneration of next observations results in a severe bottleneck, leading to long\ntraining times, poor GPU utilization, and limited representations. To resolve\nthis bottleneck, we devise a novel Parallel Observation Prediction (POP)\nmechanism. POP augments a Retentive Network (RetNet) with a novel forward mode\ntailored to our reinforcement learning setting. We incorporate POP in a novel\nTBWM agent named REM (Retentive Environment Model), showcasing a 15.4x faster\nimagination compared to prior TBWMs. REM attains superhuman performance on 12\nout of 26 games of the Atari 100K benchmark, while training in less than 12\nhours. Our code is available at \\url{https://github.com/leor-c/REM}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05643v5",
    "published_date": "2024-02-08 12:58:07 UTC",
    "updated_date": "2024-05-29 07:16:28 UTC"
  },
  {
    "arxiv_id": "2402.05636v2",
    "title": "The Impact of AI Tool on Engineering at ANZ Bank An Empirical Study on GitHub Copilot within Corporate Environment",
    "authors": [
      "Sayan Chatterjee",
      "Ching Louis Liu",
      "Gareth Rowland",
      "Tim Hogarth"
    ],
    "abstract": "The increasing popularity of AI, particularly Large Language Models (LLMs),\nhas significantly impacted various domains, including Software Engineering.\nThis study explores the integration of AI tools in software engineering\npractices within a large organization. We focus on ANZ Bank, which employs over\n5000 engineers covering all aspects of the software development life cycle.\nThis paper details an experiment conducted using GitHub Copilot, a notable AI\ntool, within a controlled environment to evaluate its effectiveness in\nreal-world engineering tasks. Additionally, this paper shares initial findings\non the productivity improvements observed after GitHub Copilot was adopted on a\nlarge scale, with about 1000 engineers using it. ANZ Bank's six-week experiment\nwith GitHub Copilot included two weeks of preparation and four weeks of active\ntesting. The study evaluated participant sentiment and the tool's impact on\nproductivity, code quality, and security. Initially, participants used GitHub\nCopilot for proposed use-cases, with their feedback gathered through regular\nsurveys. In the second phase, they were divided into Control and Copilot\ngroups, each tackling the same Python challenges, and their experiences were\nagain surveyed. Results showed a notable boost in productivity and code quality\nwith GitHub Copilot, though its impact on code security remained inconclusive.\nParticipant responses were overall positive, confirming GitHub Copilot's\neffectiveness in large-scale software engineering environments. Early data from\n1000 engineers also indicated a significant increase in productivity and job\nsatisfaction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "16 pages, 4 figures. in proceeding for 10th International Conference\n  on Software Engineering (SEC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.05636v2",
    "published_date": "2024-02-08 12:47:57 UTC",
    "updated_date": "2024-04-17 12:14:40 UTC"
  },
  {
    "arxiv_id": "2402.05627v1",
    "title": "Binding Dynamics in Rotating Features",
    "authors": [
      "Sindy Löwe",
      "Francesco Locatello",
      "Max Welling"
    ],
    "abstract": "In human cognition, the binding problem describes the open question of how\nthe brain flexibly integrates diverse information into cohesive object\nrepresentations. Analogously, in machine learning, there is a pursuit for\nmodels capable of strong generalization and reasoning by learning\nobject-centric representations in an unsupervised manner. Drawing from\nneuroscientific theories, Rotating Features learn such representations by\nintroducing vector-valued features that encapsulate object characteristics in\ntheir magnitudes and object affiliation in their orientations. The\n\"$\\chi$-binding\" mechanism, embedded in every layer of the architecture, has\nbeen shown to be crucial, but remains poorly understood. In this paper, we\npropose an alternative \"cosine binding\" mechanism, which explicitly computes\nthe alignment between features and adjusts weights accordingly, and we show\nthat it achieves equivalent performance. This allows us to draw direct\nconnections to self-attention and biological neural processes, and to shed\nlight on the fundamental dynamics for object-centric representations to emerge\nin Rotating Features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05627v1",
    "published_date": "2024-02-08 12:31:08 UTC",
    "updated_date": "2024-02-08 12:31:08 UTC"
  },
  {
    "arxiv_id": "2402.05624v1",
    "title": "Efficient Models for the Detection of Hate, Abuse and Profanity",
    "authors": [
      "Christoph Tillmann",
      "Aashka Trivedi",
      "Bishwaranjan Bhattacharjee"
    ],
    "abstract": "Large Language Models (LLMs) are the cornerstone for many Natural Language\nProcessing (NLP) tasks like sentiment analysis, document classification, named\nentity recognition, question answering, summarization, etc. LLMs are often\ntrained on data which originates from the web. This data is prone to having\ncontent with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP,\nplease refer to the Appendix. Due to the LLMs being exposed to HAP content\nduring training, the models learn it and may then generate hateful or profane\ncontent. For example, when the open-source RoBERTa model (specifically, the\nRoBERTA base model) from the HuggingFace (HF) Transformers library is prompted\nto replace the mask token in `I do not know that Persian people are that MASK`\nit returns the word `stupid` with the highest score. This is unacceptable in\ncivil discourse.The detection of Hate, Abuse and Profanity in text is a vital\ncomponent of creating civil and unbiased LLMs, which is needed not only for\nEnglish, but for all languages. In this article, we briefly describe the\ncreation of HAP detectors and various ways of using them to make models civil\nand acceptable in the output they generate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05624v1",
    "published_date": "2024-02-08 12:28:18 UTC",
    "updated_date": "2024-02-08 12:28:18 UTC"
  },
  {
    "arxiv_id": "2402.05616v1",
    "title": "Pretrained Generative Language Models as General Learning Frameworks for Sequence-Based Tasks",
    "authors": [
      "Ben Fauber"
    ],
    "abstract": "We propose that small pretrained foundational generative language models with\nmillions of parameters can be utilized as a general learning framework for\nsequence-based tasks. Our proposal overcomes the computational resource, skill\nset, and timeline challenges associated with training neural networks and\nlanguage models from scratch. Further, our approach focuses on creating small\nand highly specialized models that can accurately execute a challenging task of\nwhich the base model is incapable of performing. We demonstrate that 125M,\n350M, and 1.3B parameter pretrained foundational language models can be\ninstruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve\nnear state-of-the-art results on challenging cheminformatics tasks. We also\ndemonstrate the role of successive language model fine-tuning epochs on\nimproved outcomes, as well as the importance of both data formatting and\npretrained foundational language model selection for instruction fine-tuning\nsuccess.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05616v1",
    "published_date": "2024-02-08 12:19:32 UTC",
    "updated_date": "2024-02-08 12:19:32 UTC"
  },
  {
    "arxiv_id": "2402.05610v2",
    "title": "Extending 6D Object Pose Estimators for Stereo Vision",
    "authors": [
      "Thomas Pöllabauer",
      "Jan Emrich",
      "Volker Knauthe",
      "Arjan Kuijper"
    ],
    "abstract": "Estimating the 6D pose of objects accurately, quickly, and robustly remains a\ndifficult task. However, recent methods for directly regressing poses from RGB\nimages using dense features have achieved state-of-the-art results. Stereo\nvision, which provides an additional perspective on the object, can help reduce\npose ambiguity and occlusion. Moreover, stereo can directly infer the distance\nof an object, while mono-vision requires internalized knowledge of the object's\nsize. To extend the state-of-the-art in 6D object pose estimation to stereo, we\ncreated a BOP compatible stereo version of the YCB-V dataset. Our method\noutperforms state-of-the-art 6D pose estimation algorithms by utilizing stereo\nvision and can easily be adopted for other dense feature-based algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4th International Conference on Pattern Recognition and Artificial\n  Intelligence (ICPRAI)",
    "pdf_url": "http://arxiv.org/pdf/2402.05610v2",
    "published_date": "2024-02-08 12:08:52 UTC",
    "updated_date": "2024-09-10 13:51:00 UTC"
  },
  {
    "arxiv_id": "2402.05605v2",
    "title": "Optimizing Delegation in Collaborative Human-AI Hybrid Teams",
    "authors": [
      "Andrew Fuchs",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "abstract": "When humans and autonomous systems operate together as what we refer to as a\nhybrid team, we of course wish to ensure the team operates successfully and\neffectively. We refer to team members as agents. In our proposed framework, we\naddress the case of hybrid teams in which, at any time, only one team member\n(the control agent) is authorized to act as control for the team. To determine\nthe best selection of a control agent, we propose the addition of an AI manager\n(via Reinforcement Learning) which learns as an outside observer of the team.\nThe manager learns a model of behavior linking observations of agent\nperformance and the environment/world the team is operating in, and from these\nobservations makes the most desirable selection of a control agent. We restrict\nthe manager task by introducing a set of constraints. The manager constraints\nindicate acceptable team operation, so a violation occurs if the team enters a\ncondition which is unacceptable and requires manager intervention. To ensure\nminimal added complexity or potential inefficiency for the team, the manager\nshould attempt to minimize the number of times the team reaches a constraint\nviolation and requires subsequent manager intervention. Therefore our manager\nis optimizing its selection of authorized agents to boost overall team\nperformance while minimizing the frequency of manager intervention. We\ndemonstrate our manager performance in a simulated driving scenario\nrepresenting the case of a hybrid team of agents composed of a human driver and\nautonomous driving system. We perform experiments for our driving scenario with\ninterfering vehicles, indicating the need for collision avoidance and proper\nspeed control. Our results indicate a positive impact of our manager, with some\ncases resulting in increased team performance up to ~187% that of the best solo\nagent performance.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05605v2",
    "published_date": "2024-02-08 12:04:43 UTC",
    "updated_date": "2024-08-25 15:28:21 UTC"
  },
  {
    "arxiv_id": "2402.05602v2",
    "title": "AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers",
    "authors": [
      "Reduan Achtibat",
      "Sayed Mohammad Vakilzadeh Hatefi",
      "Maximilian Dreyer",
      "Aakriti Jain",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "abstract": "Large Language Models are prone to biased predictions and hallucinations,\nunderlining the paramount importance of understanding their model-internal\nreasoning process. However, achieving faithful attributions for the entirety of\na black-box transformer model and maintaining computational efficiency is an\nunsolved challenge. By extending the Layer-wise Relevance Propagation\nattribution method to handle attention layers, we address these challenges\neffectively. While partial solutions exist, our method is the first to\nfaithfully and holistically attribute not only input but also latent\nrepresentations of transformer models with the computational efficiency similar\nto a single backward pass. Through extensive evaluations against existing\nmethods on LLaMa 2, Mixtral 8x7b, Flan-T5 and vision transformer architectures,\nwe demonstrate that our proposed approach surpasses alternative methods in\nterms of faithfulness and enables the understanding of latent representations,\nopening up the door for concept-based explanations. We provide an LRP library\nat https://github.com/rachtibat/LRP-eXplains-Transformers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05602v2",
    "published_date": "2024-02-08 12:01:24 UTC",
    "updated_date": "2024-06-10 09:58:55 UTC"
  },
  {
    "arxiv_id": "2402.05593v1",
    "title": "A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only",
    "authors": [
      "Thomas Pöllabauer",
      "Julius Kühn"
    ],
    "abstract": "In medieval times, stuccoworkers used a red color, called sinopia, to first\ncreate a sketch of the to-be-made statue on the wall. Today, many of these\nstatues are destroyed, but using the original drawings, deriving from the red\ncolor also called sinopia, we can reconstruct how the final statue might have\nlooked.We propose a fully-automated approach to reconstruct a point cloud and\nshow preliminary results by generating a color-image, a depth-map, as well as\nsurface normals requiring only a single sketch, and without requiring a\ncollection of other, similar samples. Our proposed solution allows real-time\nreconstruction on-site, for instance, within an exhibition, or to generate a\nuseful starting point for an expert, trying to manually reconstruct the statue,\nall while using only synthetic data for training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05593v1",
    "published_date": "2024-02-08 11:46:26 UTC",
    "updated_date": "2024-02-08 11:46:26 UTC"
  },
  {
    "arxiv_id": "2402.05591v1",
    "title": "SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels",
    "authors": [
      "Juhwan Choi",
      "Kyohoon Jin",
      "Junho Lee",
      "Sangmin Song",
      "Youngbin Kim"
    ],
    "abstract": "Rule-based text data augmentation is widely used for NLP tasks due to its\nsimplicity. However, this method can potentially damage the original meaning of\nthe text, ultimately hurting the performance of the model. To overcome this\nlimitation, we propose a straightforward technique for applying soft labels to\naugmented data. We conducted experiments across seven different classification\ntasks and empirically demonstrated the effectiveness of our proposed approach.\nWe have publicly opened our source code for reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2023 Tiny Papers",
    "pdf_url": "http://arxiv.org/pdf/2402.05591v1",
    "published_date": "2024-02-08 11:44:25 UTC",
    "updated_date": "2024-02-08 11:44:25 UTC"
  },
  {
    "arxiv_id": "2402.05584v1",
    "title": "AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods in Low-resource Regimes",
    "authors": [
      "Juhwan Choi",
      "Kyohoon Jin",
      "Junho Lee",
      "Sangmin Song",
      "Youngbin Kim"
    ],
    "abstract": "Text data augmentation is a complex problem due to the discrete nature of\nsentences. Although rule-based augmentation methods are widely adopted in\nreal-world applications because of their simplicity, they suffer from potential\nsemantic damage. Previous researchers have suggested easy data augmentation\nwith soft labels (softEDA), employing label smoothing to mitigate this problem.\nHowever, finding the best factor for each model and dataset is challenging;\ntherefore, using softEDA in real-world applications is still difficult. In this\npaper, we propose adapting AutoAugment to solve this problem. The experimental\nresults suggest that the proposed method can boost existing augmentation\nmethods and that rule-based methods can enhance cutting-edge pre-trained\nlanguage models. We offer the source code.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 Student Research Workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.05584v1",
    "published_date": "2024-02-08 11:36:23 UTC",
    "updated_date": "2024-02-08 11:36:23 UTC"
  },
  {
    "arxiv_id": "2402.05575v1",
    "title": "Simultaneously Achieving Group Exposure Fairness and Within-Group Meritocracy in Stochastic Bandits",
    "authors": [
      "Subham Pokhriyal",
      "Shweta Jain",
      "Ganesh Ghalme",
      "Swapnil Dhamal",
      "Sujit Gujar"
    ],
    "abstract": "Existing approaches to fairness in stochastic multi-armed bandits (MAB)\nprimarily focus on exposure guarantee to individual arms. When arms are\nnaturally grouped by certain attribute(s), we propose Bi-Level Fairness, which\nconsiders two levels of fairness. At the first level, Bi-Level Fairness\nguarantees a certain minimum exposure to each group. To address the unbalanced\nallocation of pulls to individual arms within a group, we consider meritocratic\nfairness at the second level, which ensures that each arm is pulled according\nto its merit within the group. Our work shows that we can adapt a UCB-based\nalgorithm to achieve a Bi-Level Fairness by providing (i) anytime Group\nExposure Fairness guarantees and (ii) ensuring individual-level Meritocratic\nFairness within each group. We first show that one can decompose regret bounds\ninto two components: (a) regret due to anytime group exposure fairness and (b)\nregret due to meritocratic fairness within each group. Our proposed algorithm\nBF-UCB balances these two regrets optimally to achieve the upper bound of\n$O(\\sqrt{T})$ on regret; $T$ being the stopping time. With the help of\nsimulated experiments, we further show that BF-UCB achieves sub-linear regret;\nprovides better group and individual exposure guarantees compared to existing\nalgorithms; and does not result in a significant drop in reward with respect to\nUCB algorithm, which does not impose any fairness constraint.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05575v1",
    "published_date": "2024-02-08 11:19:58 UTC",
    "updated_date": "2024-02-08 11:19:58 UTC"
  },
  {
    "arxiv_id": "2402.05569v6",
    "title": "Training-Free Message Passing for Learning on Hypergraphs",
    "authors": [
      "Bohan Tang",
      "Zexi Liu",
      "Keyue Jiang",
      "Siheng Chen",
      "Xiaowen Dong"
    ],
    "abstract": "Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05569v6",
    "published_date": "2024-02-08 11:10:39 UTC",
    "updated_date": "2025-03-11 16:06:25 UTC"
  },
  {
    "arxiv_id": "2402.05563v1",
    "title": "Neural Multigrid Architectures",
    "authors": [
      "Vladimir Fanaskov"
    ],
    "abstract": "We propose a convenient matrix-free neural architecture for the multigrid\nmethod. The architecture is simple enough to be implemented in less than fifty\nlines of code, yet it encompasses a large number of distinct multigrid solvers.\nWe argue that a fixed neural network without dense layers can not realize an\nefficient iterative method. Because of that, standard training protocols do not\nlead to competitive solvers. To overcome this difficulty, we use parameter\nsharing and serialization of layers. The resulting network can be trained on\nlinear problems with thousands of unknowns and retains its efficiency on\nproblems with millions of unknowns. From the point of view of numerical linear\nalgebra network's training corresponds to finding optimal smoothers for the\ngeometric multigrid method. We demonstrate our approach on a few second-order\nelliptic equations. For tested linear systems, we obtain from two to five times\nsmaller spectral radius of the error propagation matrix compare to a basic\nlinear multigrid with Jacobi smoother.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05563v1",
    "published_date": "2024-02-08 11:02:06 UTC",
    "updated_date": "2024-02-08 11:02:06 UTC"
  },
  {
    "arxiv_id": "2402.05558v1",
    "title": "Flashback: Understanding and Mitigating Forgetting in Federated Learning",
    "authors": [
      "Mohammed Aljahdali",
      "Ahmed M. Abdelmoniem",
      "Marco Canini",
      "Samuel Horváth"
    ],
    "abstract": "In Federated Learning (FL), forgetting, or the loss of knowledge across\nrounds, hampers algorithm convergence, particularly in the presence of severe\ndata heterogeneity among clients. This study explores the nuances of this\nissue, emphasizing the critical role of forgetting in FL's inefficient learning\nwithin heterogeneous data contexts. Knowledge loss occurs in both client-local\nupdates and server-side aggregation steps; addressing one without the other\nfails to mitigate forgetting. We introduce a metric to measure forgetting\ngranularly, ensuring distinct recognition amid new knowledge acquisition.\nLeveraging these insights, we propose Flashback, an FL algorithm with a dynamic\ndistillation approach that is used to regularize the local models, and\neffectively aggregate their knowledge. Across different benchmarks, Flashback\noutperforms other methods, mitigates forgetting, and achieves faster\nround-to-target-accuracy, by converging in 6 to 16 rounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05558v1",
    "published_date": "2024-02-08 10:52:37 UTC",
    "updated_date": "2024-02-08 10:52:37 UTC"
  },
  {
    "arxiv_id": "2402.05547v2",
    "title": "Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset",
    "authors": [
      "Hengguan Huang",
      "Songtao Wang",
      "Hongfu Liu",
      "Hao Wang",
      "Ye Wang"
    ],
    "abstract": "Traditional applications of natural language processing (NLP) in healthcare\nhave predominantly focused on patient-centered services, enhancing patient\ninteractions and care delivery, such as through medical dialogue systems.\nHowever, the potential of NLP to benefit inexperienced doctors, particularly in\nareas such as communicative medical coaching, remains largely unexplored. We\nintroduce \"ChatCoach\", a human-AI cooperative framework designed to assist\nmedical learners in practicing their communication skills during patient\nconsultations. ChatCoach (Our data and code are available online:\nhttps://github.com/zerowst/Chatcoach)differentiates itself from conventional\ndialogue systems by offering a simulated environment where medical learners can\npractice dialogues with a patient agent, while a coach agent provides\nimmediate, structured feedback. This is facilitated by our proposed Generalized\nChain-of-Thought (GCoT) approach, which fosters the generation of structured\nfeedback and enhances the utilization of external knowledge sources.\nAdditionally, we have developed a dataset specifically for evaluating Large\nLanguage Models (LLMs) within the ChatCoach framework on communicative medical\ncoaching tasks. Our empirical results validate the effectiveness of ChatCoach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05547v2",
    "published_date": "2024-02-08 10:32:06 UTC",
    "updated_date": "2024-06-08 16:36:56 UTC"
  },
  {
    "arxiv_id": "2402.05546v1",
    "title": "Offline Actor-Critic Reinforcement Learning Scales to Large Models",
    "authors": [
      "Jost Tobias Springenberg",
      "Abbas Abdolmaleki",
      "Jingwei Zhang",
      "Oliver Groth",
      "Michael Bloesch",
      "Thomas Lampe",
      "Philemon Brakel",
      "Sarah Bechtle",
      "Steven Kapturowski",
      "Roland Hafner",
      "Nicolas Heess",
      "Martin Riedmiller"
    ],
    "abstract": "We show that offline actor-critic reinforcement learning can scale to large\nmodels - such as transformers - and follows similar scaling laws as supervised\nlearning. We find that offline actor-critic algorithms can outperform strong,\nsupervised, behavioral cloning baselines for multi-task training on a large\ndataset containing both sub-optimal and expert behavior on 132 continuous\ncontrol tasks. We introduce a Perceiver-based actor-critic model and elucidate\nthe key model features needed to make offline RL work with self- and\ncross-attention modules. Overall, we find that: i) simple offline actor critic\nalgorithms are a natural choice for gradually moving away from the currently\npredominant paradigm of behavioral cloning, and ii) via offline RL it is\npossible to learn multi-task policies that master many domains simultaneously,\nincluding real robotics tasks, from sub-optimal demonstrations or\nself-generated data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05546v1",
    "published_date": "2024-02-08 10:29:46 UTC",
    "updated_date": "2024-02-08 10:29:46 UTC"
  },
  {
    "arxiv_id": "2402.05541v2",
    "title": "FedAA: A Reinforcement Learning Perspective on Adaptive Aggregation for Fair and Robust Federated Learning",
    "authors": [
      "Jialuo He",
      "Wei Chen",
      "Xiaojin Zhang"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising approach for\nprivacy-preserving model training across decentralized devices. However, it\nfaces challenges such as statistical heterogeneity and susceptibility to\nadversarial attacks, which can impact model robustness and fairness.\nPersonalized FL attempts to provide some relief by customizing models for\nindividual clients. However, it falls short in addressing server-side\naggregation vulnerabilities. We introduce a novel method called \\textbf{FedAA},\nwhich optimizes client contributions via \\textbf{A}daptive \\textbf{A}ggregation\nto enhance model robustness against malicious clients and ensure fairness\nacross participants in non-identically distributed settings. To achieve this\ngoal, we propose an approach involving a Deep Deterministic Policy\nGradient-based algorithm for continuous control of aggregation weights, an\ninnovative client selection method based on model parameter distances, and a\nreward mechanism guided by validation set performance. Empirically, extensive\nexperiments demonstrate that, in terms of robustness, \\textbf{FedAA}\noutperforms the state-of-the-art methods, while maintaining comparable levels\nof fairness, offering a promising solution to build resilient and fair\nfederated systems. Our code is available at https://github.com/Gp1g/FedAA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.05541v2",
    "published_date": "2024-02-08 10:22:12 UTC",
    "updated_date": "2024-12-12 13:40:37 UTC"
  },
  {
    "arxiv_id": "2402.05525v2",
    "title": "Differentially Private Deep Model-Based Reinforcement Learning",
    "authors": [
      "Alexandre Rio",
      "Merwan Barlier",
      "Igor Colin",
      "Albert Thomas"
    ],
    "abstract": "We address private deep offline reinforcement learning (RL), where the goal\nis to train a policy on standard control tasks that is differentially private\n(DP) with respect to individual trajectories in the dataset. To achieve this,\nwe introduce PriMORL, a model-based RL algorithm with formal differential\nprivacy guarantees. PriMORL first learns an ensemble of trajectory-level DP\nmodels of the environment from offline data. It then optimizes a policy on the\npenalized private model, without any further interaction with the system or\naccess to the dataset. In addition to offering strong theoretical foundations,\nwe demonstrate empirically that PriMORL enables the training of private RL\nagents on offline continuous control tasks with deep function approximations,\nwhereas current methods are limited to simpler tabular and linear Markov\nDecision Processes (MDPs). We furthermore outline the trade-offs involved in\nachieving privacy in this setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05525v2",
    "published_date": "2024-02-08 10:05:11 UTC",
    "updated_date": "2024-10-09 13:31:25 UTC"
  },
  {
    "arxiv_id": "2402.05521v1",
    "title": "Linearizing Models for Efficient yet Robust Private Inference",
    "authors": [
      "Sreetama Sarkar",
      "Souvik Kundu",
      "Peter A. Beerel"
    ],
    "abstract": "The growing concern about data privacy has led to the development of private\ninference (PI) frameworks in client-server applications which protects both\ndata privacy and model IP. However, the cryptographic primitives required yield\nsignificant latency overhead which limits its wide-spread application. At the\nsame time, changing environments demand the PI service to be robust against\nvarious naturally occurring and gradient-based perturbations. Despite several\nworks focused on the development of latency-efficient models suitable for PI,\nthe impact of these models on robustness has remained unexplored. Towards this\ngoal, this paper presents RLNet, a class of robust linearized networks that can\nyield latency improvement via reduction of high-latency ReLU operations while\nimproving the model performance on both clean and corrupted images. In\nparticular, RLNet models provide a \"triple win ticket\" of improved\nclassification accuracy on clean, naturally perturbed, and gradient-based\nperturbed images using a shared-mask shared-weight architecture with over an\norder of magnitude fewer ReLUs than baseline models. To demonstrate the\nefficacy of RLNet, we perform extensive experiments with ResNet and WRN model\nvariants on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets. Our experimental\nevaluations show that RLNet can yield models with up to 11.14x fewer ReLUs,\nwith accuracy close to the all-ReLU models, on clean, naturally perturbed, and\ngradient-based perturbed images. Compared with the SoTA non-robust linearized\nmodels at similar ReLU budgets, RLNet achieves an improvement in adversarial\naccuracy of up to ~47%, naturally perturbed accuracy up to ~16.4%, while\nimproving clean image accuracy up to ~1.5%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05521v1",
    "published_date": "2024-02-08 10:01:29 UTC",
    "updated_date": "2024-02-08 10:01:29 UTC"
  },
  {
    "arxiv_id": "2402.05519v1",
    "title": "Can ChatGPT evaluate research quality?",
    "authors": [
      "Mike Thelwall"
    ],
    "abstract": "Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research\nevaluations on journal articles to automate this time-consuming task.\nDesign/methodology/approach: Test the extent to which ChatGPT-4 can assess the\nquality of journal articles using a case study of the published scoring\nguidelines of the UK Research Excellence Framework (REF) 2021 to create a\nresearch evaluation ChatGPT. This was applied to 51 of my own articles and\ncompared against my own quality judgements. Findings: ChatGPT-4 can produce\nplausible document summaries and quality evaluation rationales that match the\nREF criteria. Its overall scores have weak correlations with my self-evaluation\nscores of the same documents (averaging r=0.281 over 15 iterations, with 8\nbeing statistically significantly different from 0). In contrast, the average\nscores from the 15 iterations produced a statistically significant positive\ncorrelation of 0.509. Thus, averaging scores from multiple ChatGPT-4 rounds\nseems more effective than individual scores. The positive correlation may be\ndue to ChatGPT being able to extract the author's significance, rigour, and\noriginality claims from inside each paper. If my weakest articles are removed,\nthen the correlation with average scores (r=0.200) falls below statistical\nsignificance, suggesting that ChatGPT struggles to make fine-grained\nevaluations. Research limitations: The data is self-evaluations of a\nconvenience sample of articles from one academic in one field. Practical\nimplications: Overall, ChatGPT does not yet seem to be accurate enough to be\ntrusted for any formal or informal research quality evaluation tasks. Research\nevaluators, including journal editors, should therefore take steps to control\nits use. Originality/value: This is the first published attempt at\npost-publication expert review accuracy testing for ChatGPT.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05519v1",
    "published_date": "2024-02-08 10:00:40 UTC",
    "updated_date": "2024-02-08 10:00:40 UTC"
  },
  {
    "arxiv_id": "2402.05515v2",
    "title": "NoisyICL: A Little Noise in Model Parameters Calibrates In-context Learning",
    "authors": [
      "Yufeng Zhao",
      "Yoshihiro Sakai",
      "Naoya Inoue"
    ],
    "abstract": "In-Context Learning (ICL) is suffering from unsatisfactory performance and\nunder-calibration due to high prior bias and unfaithful confidence. Some\nprevious works fine-tuned language models for better ICL performance with\nenormous datasets and computing costs. In this paper, we propose NoisyICL,\nsimply perturbing the model parameters by random noises to strive for better\nperformance and calibration. Our experiments on two models and 12 downstream\ndatasets show that NoisyICL can help ICL produce more accurate predictions. Our\nfurther analysis indicates that NoisyICL enables the model to provide more fair\npredictions, and also with more faithful confidence. Therefore, we believe that\nNoisyICL is an effective calibration of ICL. Our experimental code is uploaded\nto Github.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 28 figures, 7 tables (5 pages, 4 figures, 1 table in main\n  body). ACL 2024 under review",
    "pdf_url": "http://arxiv.org/pdf/2402.05515v2",
    "published_date": "2024-02-08 09:48:02 UTC",
    "updated_date": "2024-02-15 15:25:47 UTC"
  },
  {
    "arxiv_id": "2402.05512v1",
    "title": "GPTs Are Multilingual Annotators for Sequence Generation Tasks",
    "authors": [
      "Juhwan Choi",
      "Eunju Lee",
      "Kyohoon Jin",
      "YoungBin Kim"
    ],
    "abstract": "Data annotation is an essential step for constructing new datasets. However,\nthe conventional approach of data annotation through crowdsourcing is both\ntime-consuming and expensive. In addition, the complexity of this process\nincreases when dealing with low-resource languages owing to the difference in\nthe language pool of crowdworkers. To address these issues, this study proposes\nan autonomous annotation method by utilizing large language models, which have\nbeen recently demonstrated to exhibit remarkable performance. Through our\nexperiments, we demonstrate that the proposed method is not just cost-efficient\nbut also applicable for low-resource language annotation. Additionally, we\nconstructed an image captioning dataset using our approach and are committed to\nopen this dataset for future study. We have opened our source code for further\nstudy and reproducibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024 Findings: Camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.05512v1",
    "published_date": "2024-02-08 09:44:02 UTC",
    "updated_date": "2024-02-08 09:44:02 UTC"
  },
  {
    "arxiv_id": "2402.10086v2",
    "title": "Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review",
    "authors": [
      "Anton Kuznietsov",
      "Balint Gyevnar",
      "Cheng Wang",
      "Steven Peters",
      "Stefano V. Albrecht"
    ],
    "abstract": "Artificial Intelligence (AI) shows promising applications for the perception\nand planning tasks in autonomous driving (AD) due to its superior performance\ncompared to conventional methods. However, inscrutable AI systems exacerbate\nthe existing challenge of safety assurance of AD. One way to mitigate this\nchallenge is to utilize explainable AI (XAI) techniques. To this end, we\npresent the first comprehensive systematic literature review of explainable\nmethods for safe and trustworthy AD. We begin by analyzing the requirements for\nAI in the context of AD, focusing on three key aspects: data, model, and\nagency. We find that XAI is fundamental to meeting these requirements. Based on\nthis, we explain the sources of explanations in AI and describe a taxonomy of\nXAI. We then identify five key contributions of XAI for safe and trustworthy AI\nin AD, which are interpretable design, interpretable surrogate models,\ninterpretable monitoring, auxiliary explanations, and interpretable validation.\nFinally, we propose a modular framework called SafeX to integrate these\ncontributions, enabling explanation delivery to users while simultaneously\nensuring the safety of AI models.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10086v2",
    "published_date": "2024-02-08 09:08:44 UTC",
    "updated_date": "2024-07-03 08:31:45 UTC"
  },
  {
    "arxiv_id": "2402.05493v4",
    "title": "Investigating White-Box Attacks for On-Device Models",
    "authors": [
      "Mingyi Zhou",
      "Xiang Gao",
      "Jing Wu",
      "Kui Liu",
      "Hailong Sun",
      "Li Li"
    ],
    "abstract": "Numerous mobile apps have leveraged deep learning capabilities. However,\non-device models are vulnerable to attacks as they can be easily extracted from\ntheir corresponding mobile apps. Existing on-device attacking approaches only\ngenerate black-box attacks, which are far less effective and efficient than\nwhite-box strategies. This is because mobile deep learning frameworks like\nTFLite do not support gradient computing, which is necessary for white-box\nattacking algorithms. Thus, we argue that existing findings may underestimate\nthe harmfulness of on-device attacks. To this end, we conduct a study to answer\nthis research question: Can on-device models be directly attacked via white-box\nstrategies? We first systematically analyze the difficulties of transforming\nthe on-device model to its debuggable version, and propose a Reverse\nEngineering framework for On-device Models (REOM), which automatically reverses\nthe compiled on-device TFLite model to the debuggable model. Specifically, REOM\nfirst transforms compiled on-device models into Open Neural Network Exchange\nformat, then removes the non-debuggable parts, and converts them to the\ndebuggable DL models format that allows attackers to exploit in a white-box\nsetting. Our experimental results show that our approach is effective in\nachieving automated transformation among 244 TFLite models. Compared with\nprevious attacks using surrogate models, REOM enables attackers to achieve\nhigher attack success rates with a hundred times smaller attack perturbations.\nIn addition, because the ONNX platform has plenty of tools for model format\nexchanging, the proposed method based on the ONNX platform can be adapted to\nother model formats. Our findings emphasize the need for developers to\ncarefully consider their model deployment strategies, and use white-box methods\nto evaluate the vulnerability of on-device models.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "Published in The International Conference on Software Engineering\n  2024 (ICSE'24)",
    "pdf_url": "http://arxiv.org/pdf/2402.05493v4",
    "published_date": "2024-02-08 09:03:17 UTC",
    "updated_date": "2024-03-01 05:22:38 UTC"
  },
  {
    "arxiv_id": "2402.05484v1",
    "title": "Leveraging AI for Enhanced Software Effort Estimation: A Comprehensive Study and Framework Proposal",
    "authors": [
      "Nhi Tran",
      "Tan Tran",
      "Nam Nguyen"
    ],
    "abstract": "This paper presents an extensive study on the application of AI techniques\nfor software effort estimation in the past five years from 2017 to 2023. By\novercoming the limitations of traditional methods, the study aims to improve\naccuracy and reliability. Through performance evaluation and comparison with\ndiverse Machine Learning models, including Artificial Neural Network (ANN),\nSupport Vector Machine (SVM), Linear Regression, Random Forest and other\ntechniques, the most effective method is identified. The proposed AI-based\nframework holds the potential to enhance project planning and resource\nallocation, contributing to the research area of software project effort\nestimation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05484v1",
    "published_date": "2024-02-08 08:25:41 UTC",
    "updated_date": "2024-02-08 08:25:41 UTC"
  },
  {
    "arxiv_id": "2402.05467v1",
    "title": "Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia",
    "authors": [
      "Guangyu Shen",
      "Siyuan Cheng",
      "Kaiyuan Zhang",
      "Guanhong Tao",
      "Shengwei An",
      "Lu Yan",
      "Zhuo Zhang",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have become prevalent across diverse sectors,\ntransforming human life with their extraordinary reasoning and comprehension\nabilities. As they find increased use in sensitive tasks, safety concerns have\ngained widespread attention. Extensive efforts have been dedicated to aligning\nLLMs with human moral principles to ensure their safe deployment. Despite their\npotential, recent research indicates aligned LLMs are prone to specialized\njailbreaking prompts that bypass safety measures to elicit violent and harmful\ncontent. The intrinsic discrete nature and substantial scale of contemporary\nLLMs pose significant challenges in automatically generating diverse,\nefficient, and potent jailbreaking prompts, representing a continuous obstacle.\nIn this paper, we introduce RIPPLE (Rapid Optimization via Subconscious\nExploitation and Echopraxia), a novel optimization-based method inspired by two\npsychological concepts: subconsciousness and echopraxia, which describe the\nprocesses of the mind that occur without conscious awareness and the\ninvoluntary mimicry of actions, respectively. Evaluations across 6 open-source\nLLMs and 4 commercial LLM APIs show RIPPLE achieves an average Attack Success\nRate of 91.5\\%, outperforming five current methods by up to 47.0\\% with an 8x\nreduction in overhead. Furthermore, it displays significant transferability and\nstealth, successfully evading established detection mechanisms. The code of our\nwork is available at\n\\url{https://github.com/SolidShen/RIPPLE_official/tree/official}",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05467v1",
    "published_date": "2024-02-08 07:56:49 UTC",
    "updated_date": "2024-02-08 07:56:49 UTC"
  },
  {
    "arxiv_id": "2402.14580v1",
    "title": "Savvy: Trustworthy Autonomous Vehicles Architecture",
    "authors": [
      "Ali Shoker",
      "Rehana Yasmin",
      "Paulo Esteves-Verissimo"
    ],
    "abstract": "The increasing interest in Autonomous Vehicles (AV) is notable due to\nbusiness, safety, and performance reasons. While there is salient success in\nrecent AV architectures, hinging on the advancements in AI models, there is a\ngrowing number of fatal incidents that impedes full AVs from going mainstream.\nThis calls for the need to revisit the fundamentals of building safety-critical\nAV architectures. However, this direction should not deter leveraging the power\nof AI. To this end, we propose Savvy, a new trustworthy intelligent AV\narchitecture that achieves the best of both worlds. Savvy makes a clear\nseparation between the control plane and the data plane to guarantee the\nsafety-first principles. The former assume control to ensure safety using\ndesign-time defined rules, while launching the latter for optimizing decisions\nas much as possible within safety time-bounds. This is achieved through guided\nTime-aware predictive quality degradation (TPQD): using dynamic ML models that\ncan be tuned to provide either richer or faster outputs based on the available\nsafety time bounds. For instance, Savvy allows to safely identify an elephant\nas an obstacle (a mere object) the earliest possible, rather than optimally\nrecognizing it as an elephant when it is too late. This position paper presents\nthe Savvy's motivations and concept, whereas empirical evaluation is a work in\nprogress.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14580v1",
    "published_date": "2024-02-08 07:24:45 UTC",
    "updated_date": "2024-02-08 07:24:45 UTC"
  },
  {
    "arxiv_id": "2402.05457v1",
    "title": "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition",
    "authors": [
      "Chen Chen",
      "Ruizhe Li",
      "Yuchen Hu",
      "Sabato Marco Siniscalchi",
      "Pin-Yu Chen",
      "Ensiong Chng",
      "Chao-Han Huck Yang"
    ],
    "abstract": "Recent studies have successfully shown that large language models (LLMs) can\nbe successfully used for generative error correction (GER) on top of the\nautomatic speech recognition (ASR) output. Specifically, an LLM is utilized to\ncarry out a direct mapping from the N-best hypotheses list generated by an ASR\nsystem to the predicted output transcription. However, despite its\neffectiveness, GER introduces extra data uncertainty since the LLM is trained\nwithout taking into account acoustic information available in the speech\nsignal. In this work, we aim to overcome such a limitation by infusing acoustic\ninformation before generating the predicted transcription through a novel late\nfusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a\nmultimodal fusion approach implemented into an auto-regressive decoding process\nand works in two stages: (i) It first analyzes and calibrates the token-level\nLLM decision, and (ii) it then dynamically assimilates the information from the\nacoustic modality. Experimental evidence collected from various ASR tasks shows\nthat UADF surpasses existing fusion mechanisms in several ways. It yields\nsignificant improvements in word error rate (WER) while mitigating data\nuncertainty issues in LLM and addressing the poor generalization relied with\nsole modality during fusion. We also demonstrate that UADF seamlessly adapts to\naudio-visual speech recognition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICLR 2024, 17 pages. This work will be open sourced under\n  MIT license",
    "pdf_url": "http://arxiv.org/pdf/2402.05457v1",
    "published_date": "2024-02-08 07:21:45 UTC",
    "updated_date": "2024-02-08 07:21:45 UTC"
  },
  {
    "arxiv_id": "2402.06682v1",
    "title": "Private Knowledge Sharing in Distributed Learning: A Survey",
    "authors": [
      "Yasas Supeksala",
      "Dinh C. Nguyen",
      "Ming Ding",
      "Thilina Ranbaduge",
      "Calson Chua",
      "Jun Zhang",
      "Jun Li",
      "H. Vincent Poor"
    ],
    "abstract": "The rise of Artificial Intelligence (AI) has revolutionized numerous\nindustries and transformed the way society operates. Its widespread use has led\nto the distribution of AI and its underlying data across many intelligent\nsystems. In this light, it is crucial to utilize information in learning\nprocesses that are either distributed or owned by different entities. As a\nresult, modern data-driven services have been developed to integrate\ndistributed knowledge entities into their outcomes. In line with this goal, the\nlatest AI models are frequently trained in a decentralized manner. Distributed\nlearning involves multiple entities working together to make collective\npredictions and decisions. However, this collaboration can also bring about\nsecurity vulnerabilities and challenges. This paper provides an in-depth survey\non private knowledge sharing in distributed learning, examining various\nknowledge components utilized in leading distributed learning architectures.\nOur analysis sheds light on the most critical vulnerabilities that may arise\nwhen using these components in a distributed setting. We further identify and\nexamine defensive strategies for preserving the privacy of these knowledge\ncomponents and preventing malicious parties from manipulating or accessing the\nknowledge information. Finally, we highlight several key limitations of\nknowledge sharing in distributed learning and explore potential avenues for\nfuture research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Manuscript submitted to ACM",
    "pdf_url": "http://arxiv.org/pdf/2402.06682v1",
    "published_date": "2024-02-08 07:18:23 UTC",
    "updated_date": "2024-02-08 07:18:23 UTC"
  },
  {
    "arxiv_id": "2402.05448v2",
    "title": "Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application",
    "authors": [
      "Bumsoo Kim",
      "Sanghyun Byun",
      "Yonghoon Jung",
      "Wonseop Shin",
      "Sareer UI Amin",
      "Sanghyun Seo"
    ],
    "abstract": "In this paper, we first present the character texture generation system\n\\textit{Minecraft-ify}, specified to Minecraft video game toward in-game\napplication. Ours can generate face-focused image for texture mapping tailored\nto 3D virtual character having cube manifold. While existing projects or works\nonly generate texture, proposed system can inverse the user-provided real\nimage, or generate average/random appearance from learned distribution.\nMoreover, it can be manipulated with text-guidance using StyleGAN and\nStyleCLIP. These features provide a more extended user experience with enlarged\nfreedom as a user-friendly AI-tool. Project page can be found at\nhttps://gh-bumsookim.github.io/Minecraft-ify/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "2 pages, 2 figures. Accepted as Spotlight to NeurIPS 2023 Workshop on\n  Machine Learning for Creativity and Design",
    "pdf_url": "http://arxiv.org/pdf/2402.05448v2",
    "published_date": "2024-02-08 07:01:00 UTC",
    "updated_date": "2024-03-03 10:02:54 UTC"
  },
  {
    "arxiv_id": "2402.05980v3",
    "title": "Do Large Code Models Understand Programming Concepts? Counterfactual Analysis for Code Predicates",
    "authors": [
      "Ashish Hooda",
      "Mihai Christodorescu",
      "Miltiadis Allamanis",
      "Aaron Wilson",
      "Kassem Fawaz",
      "Somesh Jha"
    ],
    "abstract": "Large Language Models' success on text generation has also made them better\nat code generation and coding tasks. While a lot of work has demonstrated their\nremarkable performance on tasks such as code completion and editing, it is\nstill unclear as to why. We help bridge this gap by exploring to what degree\nauto-regressive models understand the logical constructs of the underlying\nprograms. We propose Counterfactual Analysis for Programming Concept Predicates\n(CACP) as a counterfactual testing framework to evaluate whether Large Code\nModels understand programming concepts. With only black-box access to the\nmodel, we use CACP to evaluate ten popular Large Code Models for four different\nprogramming concepts. Our findings suggest that current models lack\nunderstanding of concepts such as data flow and control flow.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05980v3",
    "published_date": "2024-02-08 06:48:01 UTC",
    "updated_date": "2025-02-12 15:40:35 UTC"
  },
  {
    "arxiv_id": "2402.05435v2",
    "title": "GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study",
    "authors": [
      "Christopher J. Lynch",
      "Erik Jensen",
      "Madison H. Munro",
      "Virginia Zamponi",
      "Joseph Martinez",
      "Kevin O'Brien",
      "Brandon Feldhaus",
      "Katherine Smith",
      "Ann Marie Reinhold",
      "Ross Gore"
    ],
    "abstract": "Large Language Models (LLMs) play a pivotal role in generating vast arrays of\nnarratives, facilitating a systematic exploration of their effectiveness for\ncommunicating life events in narrative form. In this study, we employ a\nzero-shot structured narrative prompt to generate 24,000 narratives using\nOpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and\nevaluate their validity in conveying birth, death, hiring, and firing events.\nRemarkably, 87.43% of the narratives sufficiently convey the intention of the\nstructured prompt. To automate the identification of valid and invalid\nnarratives, we train and validate nine Machine Learning models on the\nclassified datasets. Leveraging these models, we extend our analysis to predict\nthe classifications of the remaining 21,120 narratives. All the ML models\nexcelled at classifying valid narratives as valid, but experienced challenges\nat simultaneously classifying invalid narratives as invalid. Our findings not\nonly advance the study of LLM capabilities, limitations, and validity but also\noffer practical insights for narrative generation and natural language\nprocessing applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.6.4"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.05435v2",
    "published_date": "2024-02-08 06:20:01 UTC",
    "updated_date": "2024-07-12 13:46:47 UTC"
  },
  {
    "arxiv_id": "2402.05428v1",
    "title": "Mixture Density Networks for Classification with an Application to Product Bundling",
    "authors": [
      "Narendhar Gugulothu",
      "Sanjay P. Bhat",
      "Tejas Bodas"
    ],
    "abstract": "While mixture density networks (MDNs) have been extensively used for\nregression tasks, they have not been used much for classification tasks. One\nreason for this is that the usability of MDNs for classification is not clear\nand straightforward. In this paper, we propose two MDN-based models for\nclassification tasks. Both models fit mixtures of Gaussians to the the data and\nuse the fitted distributions to classify a given sample by evaluating the\nlearnt cumulative distribution function for the given input features. While the\nproposed MDN-based models perform slightly better than, or on par with, five\nbaseline classification models on three publicly available datasets, the real\nutility of our models comes out through a real-world product bundling\napplication. Specifically, we use our MDN-based models to learn the\nwillingness-to-pay (WTP) distributions for two products from synthetic sales\ndata of the individual products. The Gaussian mixture representation of the\nlearnt WTP distributions is then exploited to obtain the WTP distribution of\nthe bundle consisting of both the products. The proposed MDN-based models are\nable to approximate the true WTP distributions of both products and the bundle\nwell.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05428v1",
    "published_date": "2024-02-08 05:54:08 UTC",
    "updated_date": "2024-02-08 05:54:08 UTC"
  },
  {
    "arxiv_id": "2402.05421v4",
    "title": "DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning",
    "authors": [
      "Weikang Wan",
      "Ziyu Wang",
      "Yufei Wang",
      "Zackory Erickson",
      "David Held"
    ],
    "abstract": "This paper introduces DiffTORI, which utilizes Differentiable Trajectory\nOptimization as the policy representation to generate actions for deep\nReinforcement and Imitation learning. Trajectory optimization is a powerful and\nwidely used algorithm in control, parameterized by a cost and a dynamics\nfunction. The key to our approach is to leverage the recent progress in\ndifferentiable trajectory optimization, which enables computing the gradients\nof the loss with respect to the parameters of trajectory optimization. As a\nresult, the cost and dynamics functions of trajectory optimization can be\nlearned end-to-end. DiffTORI addresses the ``objective mismatch'' issue of\nprior model-based RL algorithms, as the dynamics model in DiffTORI is learned\nto directly maximize task performance by differentiating the policy gradient\nloss through the trajectory optimization process. We further benchmark DiffTORI\nfor imitation learning on standard robotic manipulation task suites with\nhigh-dimensional sensory observations and compare our method to feed-forward\npolicy classes as well as Energy-Based Models (EBM) and Diffusion. Across 15\nmodel-based RL tasks and 35 imitation learning tasks with high-dimensional\nimage and point cloud inputs, DiffTORI outperforms prior state-of-the-art\nmethods in both domains. Our code is available at\nhttps://github.com/wkwan7/DiffTORI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2402.05421v4",
    "published_date": "2024-02-08 05:26:40 UTC",
    "updated_date": "2025-03-03 22:40:19 UTC"
  },
  {
    "arxiv_id": "2402.06680v1",
    "title": "Social Physics Informed Diffusion Model for Crowd Simulation",
    "authors": [
      "Hongyi Chen",
      "Jingtao Ding",
      "Yong Li",
      "Yue Wang",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Crowd simulation holds crucial applications in various domains, such as urban\nplanning, architectural design, and traffic arrangement. In recent years,\nphysics-informed machine learning methods have achieved state-of-the-art\nperformance in crowd simulation but fail to model the heterogeneity and\nmulti-modality of human movement comprehensively. In this paper, we propose a\nsocial physics-informed diffusion model named SPDiff to mitigate the above gap.\nSPDiff takes both the interactive and historical information of crowds in the\ncurrent timeframe to reverse the diffusion process, thereby generating the\ndistribution of pedestrian movement in the subsequent timeframe. Inspired by\nthe well-known social physics model, i.e., Social Force, regarding crowd\ndynamics, we design a crowd interaction module to guide the denoising process\nand further enhance this module with the equivariant properties of crowd\ninteractions. To mitigate error accumulation in long-term simulations, we\npropose a multi-frame rollout training algorithm for diffusion modeling.\nExperiments conducted on two real-world datasets demonstrate the superior\nperformance of SPDiff in terms of macroscopic and microscopic evaluation\nmetrics. Code and appendix are available at\nhttps://github.com/tsinghua-fib-lab/SPDiff.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.06680v1",
    "published_date": "2024-02-08 04:43:33 UTC",
    "updated_date": "2024-02-08 04:43:33 UTC"
  },
  {
    "arxiv_id": "2402.05403v2",
    "title": "In-Context Principle Learning from Mistakes",
    "authors": [
      "Tianjun Zhang",
      "Aman Madaan",
      "Luyu Gao",
      "Steven Zheng",
      "Swaroop Mishra",
      "Yiming Yang",
      "Niket Tandon",
      "Uri Alon"
    ],
    "abstract": "In-context learning (ICL, also known as few-shot prompting) has been the\nstandard method of adapting LLMs to downstream tasks, by learning from a few\ninput-output examples. Nonetheless, all ICL-based approaches only learn from\ncorrect input-output pairs. In this paper, we revisit this paradigm, by\nlearning more from the few given input-output examples. We introduce Learning\nPrinciples (LEAP): First, we intentionally induce the model to make mistakes on\nthese few examples; then we reflect on these mistakes, and learn explicit\ntask-specific \"principles\" from them, which help solve similar problems and\navoid common mistakes; finally, we prompt the model to answer unseen test\nquestions using the original few-shot examples and these learned general\nprinciples. We evaluate LEAP on a wide range of benchmarks, including multi-hop\nquestion answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning,\nand math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the\nstrongest available LLMs such as GPT-3.5-turbo, GPT-4, GPT-4 turbo and\nClaude-2.1. For example, LEAP improves over the standard few-shot prompting\nusing GPT-4 by 7.5% in DROP, and by 3.3% in HotpotQA. Importantly, LEAP does\nnot require any more input or examples than the standard few-shot prompting\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05403v2",
    "published_date": "2024-02-08 04:42:29 UTC",
    "updated_date": "2024-02-09 19:09:52 UTC"
  },
  {
    "arxiv_id": "2402.05399v3",
    "title": "CURE: Simulation-Augmented Auto-Tuning in Robotics",
    "authors": [
      "Md Abir Hossen",
      "Sonam Kharade",
      "Jason M. O'Kane",
      "Bradley Schmerl",
      "David Garlan",
      "Pooyan Jamshidi"
    ],
    "abstract": "Robotic systems are typically composed of various subsystems, such as\nlocalization and navigation, each encompassing numerous configurable components\n(e.g., selecting different planning algorithms). Once an algorithm has been\nselected for a component, its associated configuration options must be set to\nthe appropriate values. Configuration options across the system stack interact\nnon-trivially. Finding optimal configurations for highly configurable robots to\nachieve desired performance poses a significant challenge due to the\ninteractions between configuration options across software and hardware that\nresult in an exponentially large and complex configuration space. These\nchallenges are further compounded by the need for transferability between\ndifferent environments and robotic platforms. Data efficient optimization\nalgorithms (e.g., Bayesian optimization) have been increasingly employed to\nautomate the tuning of configurable parameters in cyber-physical systems.\nHowever, such optimization algorithms converge at later stages, often after\nexhausting the allocated budget (e.g., optimization steps, allotted time) and\nlacking transferability. This paper proposes CURE -- a method that identifies\ncausally relevant configuration options, enabling the optimization process to\noperate in a reduced search space, thereby enabling faster optimization of\nrobot performance. CURE abstracts the causal relationships between various\nconfiguration options and robot performance objectives by learning a causal\nmodel in the source (a low-cost environment such as the Gazebo simulator) and\napplying the learned knowledge to perform optimization in the target (e.g.,\nTurtlebot 3 physical robot). We demonstrate the effectiveness and\ntransferability of CURE by conducting experiments that involve varying degrees\nof deployment changes in both physical robots and simulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for publication in IEEE Transactions on Robotics (T-RO),\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2402.05399v3",
    "published_date": "2024-02-08 04:27:14 UTC",
    "updated_date": "2025-02-25 15:39:25 UTC"
  },
  {
    "arxiv_id": "2402.05396v3",
    "title": "TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning",
    "authors": [
      "Gangda Deng",
      "Hongkuan Zhou",
      "Hanqing Zeng",
      "Yinglong Xia",
      "Christopher Leung",
      "Jianbo Li",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "abstract": "Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated\nstate-of-the-art performance in various high-impact applications, including\nfraud detection and content recommendation. Despite the success of TGNNs, they\nare prone to the prevalent noise found in real-world dynamic graphs like\ntime-deprecated links and skewed interaction distribution. The noise causes two\ncritical issues that significantly compromise the accuracy of TGNNs: (1) models\nare supervised by inferior interactions, and (2) noisy input induces high\nvariance in the aggregated messages. However, current TGNN denoising techniques\ndo not consider the diverse and dynamic noise pattern of each node. In\naddition, they also suffer from the excessive mini-batch generation overheads\ncaused by traversing more neighbors. We believe the remedy for fast and\naccurate TGNNs lies in temporal adaptive sampling. In this work, we propose\nTASER, the first adaptive sampling method for TGNNs optimized for accuracy,\nefficiency, and scalability. TASER adapts its mini-batch selection based on\ntraining dynamics and temporal neighbor selection based on the contextual,\nstructural, and temporal properties of past interactions. To alleviate the\nbottleneck in mini-batch generation, TASER implements a pure GPU-based temporal\nneighbor finder and a dedicated GPU feature cache. We evaluate the performance\nof TASER using two state-of-the-art backbone TGNNs. On five popular datasets,\nTASER outperforms the corresponding baselines by an average of 2.3% in Mean\nReciprocal Rank (MRR) while achieving an average of 5.1x speedup in training\ntime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IPDPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05396v3",
    "published_date": "2024-02-08 04:16:35 UTC",
    "updated_date": "2024-11-23 10:42:11 UTC"
  },
  {
    "arxiv_id": "2402.05391v4",
    "title": "Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey",
    "authors": [
      "Zhuo Chen",
      "Yichi Zhang",
      "Yin Fang",
      "Yuxia Geng",
      "Lingbing Guo",
      "Xiang Chen",
      "Qian Li",
      "Wen Zhang",
      "Jiaoyan Chen",
      "Yushan Zhu",
      "Jiaqi Li",
      "Xiaoze Liu",
      "Jeff Z. Pan",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "abstract": "Knowledge Graphs (KGs) play a pivotal role in advancing various AI\napplications, with the semantic web community's exploration into multi-modal\ndimensions unlocking new avenues for innovation. In this survey, we carefully\nreview over 300 articles, focusing on KG-aware research in two principal\naspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal\ntasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into\nthe MMKG realm. We begin by defining KGs and MMKGs, then explore their\nconstruction progress. Our review includes two primary task categories:\nKG-aware multi-modal learning tasks, such as Image Classification and Visual\nQuestion Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph\nCompletion and Entity Alignment, highlighting specific research trajectories.\nFor most of these tasks, we provide definitions, evaluation benchmarks, and\nadditionally outline essential insights for conducting relevant research.\nFinally, we discuss current challenges and identify emerging trends, such as\nprogress in Large Language Modeling and Multi-modal Pre-training strategies.\nThis survey aims to serve as a comprehensive reference for researchers already\ninvolved in or considering delving into KG and multi-modal learning research,\noffering insights into the evolving landscape of MMKG research and supporting\nfuture work.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Ongoing work; 41 pages (Main Text), 55 pages (Total), 11 Tables, 13\n  Figures, 619 citations; Paper list is available at\n  https://github.com/zjukg/KG-MM-Survey",
    "pdf_url": "http://arxiv.org/pdf/2402.05391v4",
    "published_date": "2024-02-08 04:04:36 UTC",
    "updated_date": "2024-02-26 09:57:12 UTC"
  },
  {
    "arxiv_id": "2402.10941v2",
    "title": "Text2Data: Low-Resource Data Generation with Textual Control",
    "authors": [
      "Shiyu Wang",
      "Yihao Feng",
      "Tian Lan",
      "Ning Yu",
      "Yu Bai",
      "Ran Xu",
      "Huan Wang",
      "Caiming Xiong",
      "Silvio Savarese"
    ],
    "abstract": "Natural language serves as a common and straightforward signal for humans to\ninteract seamlessly with machines. Recognizing the importance of this\ninterface, the machine learning community is investing considerable effort in\ngenerating data that is semantically coherent with textual instructions. While\nstrides have been made in text-to-data generation spanning image editing, audio\nsynthesis, video creation, and beyond, low-resource areas characterized by\nexpensive annotations or complex data structures, such as molecules, motion\ndynamics, and time series, often lack textual labels. This deficiency impedes\nsupervised learning, thereby constraining the application of advanced\ngenerative models for text-to-data tasks. In response to these challenges in\nthe low-resource scenario, we propose Text2Data, a novel approach that utilizes\nunlabeled data to understand the underlying data distribution through an\nunsupervised diffusion model. Subsequently, it undergoes controllable\nfinetuning via a novel constraint optimization-based learning objective that\nensures controllability and effectively counteracts catastrophic forgetting.\nComprehensive experiments demonstrate that Text2Data is able to achieve\nenhanced performance regarding controllability across various modalities,\nincluding molecules, motions and time series, when compared to existing\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2402.10941v2",
    "published_date": "2024-02-08 03:41:39 UTC",
    "updated_date": "2025-01-02 17:47:09 UTC"
  },
  {
    "arxiv_id": "2402.05378v1",
    "title": "Graph Neural Networks for Physical-Layer Security in Multi-User Flexible-Duplex Networks",
    "authors": [
      "Tharaka Perera",
      "Saman Atapattu",
      "Yuting Fang",
      "Jamie Evans"
    ],
    "abstract": "This paper explores Physical-Layer Security (PLS) in Flexible Duplex (FlexD)\nnetworks, considering scenarios involving eavesdroppers. Our investigation\nrevolves around the intricacies of the sum secrecy rate maximization problem,\nparticularly when faced with coordinated and distributed eavesdroppers\nemploying a Minimum Mean Square Error (MMSE) receiver. Our contributions\ninclude an iterative classical optimization solution and an unsupervised\nlearning strategy based on Graph Neural Networks (GNNs). To the best of our\nknowledge, this work marks the initial exploration of GNNs for PLS\napplications. Additionally, we extend the GNN approach to address the absence\nof eavesdroppers' channel knowledge. Extensive numerical simulations highlight\nFlexD's superiority over Half-Duplex (HD) communications and the GNN approach's\nsuperiority over the classical method in both performance and time complexity.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05378v1",
    "published_date": "2024-02-08 03:22:12 UTC",
    "updated_date": "2024-02-08 03:22:12 UTC"
  },
  {
    "arxiv_id": "2402.05374v5",
    "title": "CIC: A Framework for Culturally-Aware Image Captioning",
    "authors": [
      "Youngsik Yun",
      "Jihie Kim"
    ],
    "abstract": "Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.05374v5",
    "published_date": "2024-02-08 03:12:25 UTC",
    "updated_date": "2025-02-24 06:56:33 UTC"
  },
  {
    "arxiv_id": "2402.05370v1",
    "title": "Attention as Robust Representation for Time Series Forecasting",
    "authors": [
      "PeiSong Niu",
      "Tian Zhou",
      "Xue Wang",
      "Liang Sun",
      "Rong Jin"
    ],
    "abstract": "Time series forecasting is essential for many practical applications, with\nthe adoption of transformer-based models on the rise due to their impressive\nperformance in NLP and CV. Transformers' key feature, the attention mechanism,\ndynamically fusing embeddings to enhance data representation, often relegating\nattention weights to a byproduct role. Yet, time series data, characterized by\nnoise and non-stationarity, poses significant forecasting challenges. Our\napproach elevates attention weights as the primary representation for time\nseries, capitalizing on the temporal relationships among data points to improve\nforecasting accuracy. Our study shows that an attention map, structured using\nglobal landmarks and local windows, acts as a robust kernel representation for\ndata points, withstanding noise and shifts in distribution. Our method\noutperforms state-of-the-art models, reducing mean squared error (MSE) in\nmultivariate time series forecasting by a notable 3.6% without altering the\ncore neural network architecture. It serves as a versatile component that can\nreadily replace recent patching based embedding schemes in transformer-based\nmodels, boosting their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05370v1",
    "published_date": "2024-02-08 03:00:50 UTC",
    "updated_date": "2024-02-08 03:00:50 UTC"
  },
  {
    "arxiv_id": "2402.05359v6",
    "title": "An Examination on the Effectiveness of Divide-and-Conquer Prompting in Large Language Models",
    "authors": [
      "Yizhou Zhang",
      "Lun Du",
      "Defu Cao",
      "Qiang Fu",
      "Yan Liu"
    ],
    "abstract": "Foundation models, such as Large language Models (LLMs), have attracted\nsignificant amount of interest due to their large number of applications.\nHowever, when handling tasks involving repetitive sub-tasks and/or deceptive\ncontents, such as arithmetic calculation and article-level fake news detection,\nsimple instructional prompts suffer from inaccurate responses. Existing works\nshow that more complicated prompting strategies, such as Chain-of-Thoughts and\nLeast-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent\nresearches reveal that simple divide-and-conquer prompting strategy, i.e.\nsimply dividing the input sequence to multiple sub-inputs, can also\nsubstantially improve LLM's performance in some specific tasks such as\nmisinformation detection. In this paper, we aim at examining the utility of\ndivide-and-conquer prompting strategy and answer on which kind of tasks this\nstrategy gets advantages. Specifically, we provide a theoretic analysis to\ndivide-and-conquer prompting strategy and help us identify the specific tasks\nwhere DaC prompting can bring performance boost with theoretic guarantee. We\nthen present two cases (large integer arithmetic and fact verification) where\nexperimental results aligns with our theoretic analysis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.05359v6",
    "published_date": "2024-02-08 02:37:30 UTC",
    "updated_date": "2024-07-02 18:18:18 UTC"
  },
  {
    "arxiv_id": "2402.05355v6",
    "title": "A Survey on Safe Multi-Modal Learning System",
    "authors": [
      "Tianyi Zhao",
      "Liangliang Zhang",
      "Yao Ma",
      "Lu Cheng"
    ],
    "abstract": "In the rapidly evolving landscape of artificial intelligence, multimodal\nlearning systems (MMLS) have gained traction for their ability to process and\nintegrate information from diverse modality inputs. Their expanding use in\nvital sectors such as healthcare has made safety assurance a critical concern.\nHowever, the absence of systematic research into their safety is a significant\nbarrier to progress in this field. To bridge the gap, we present the first\ntaxonomy that systematically categorizes and assesses MMLS safety. This\ntaxonomy is structured around four fundamental pillars that are critical to\nensuring the safety of MMLS: robustness, alignment, monitoring, and\ncontrollability. Leveraging this taxonomy, we review existing methodologies,\nbenchmarks, and the current state of research, while also pinpointing the\nprincipal limitations and gaps in knowledge. Finally, we discuss unique\nchallenges in MMLS safety. In illuminating these challenges, we aim to pave the\nway for future research, proposing potential directions that could lead to\nsignificant advancements in the safety protocols of MMLS.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05355v6",
    "published_date": "2024-02-08 02:27:13 UTC",
    "updated_date": "2024-07-16 08:35:40 UTC"
  },
  {
    "arxiv_id": "2402.05346v2",
    "title": "KIX: A Knowledge and Interaction-Centric Metacognitive Framework for Task Generalization",
    "authors": [
      "Arun Kumar",
      "Paul Schrater"
    ],
    "abstract": "People aptly exhibit general intelligence behaviors in solving a variety of\ntasks with flexibility and ability to adapt to novel situations by reusing and\napplying high-level knowledge acquired over time. But artificial agents are\nmore like specialists, lacking such generalist behaviors. Artificial agents\nwill require understanding and exploiting critical structured knowledge\nrepresentations. We present a metacognitive generalization framework,\nKnowledge-Interaction-eXecution (KIX), and argue that interactions with objects\nleveraging type space facilitate the learning of transferable interaction\nconcepts and generalization. It is a natural way of integrating knowledge into\nreinforcement learning and is promising to act as an enabler for autonomous and\ngeneralist behaviors in artificial intelligence systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.05346v2",
    "published_date": "2024-02-08 01:41:28 UTC",
    "updated_date": "2024-08-12 17:19:06 UTC"
  }
]