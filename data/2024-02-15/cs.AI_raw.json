[
  {
    "arxiv_id": "2402.10373v3",
    "title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Emmanuel Morin",
      "Pierre-Antoine Gourraud",
      "Mickael Rouvier",
      "Richard Dufour"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable versatility in\nrecent years, offering potential applications across specialized domains such\nas healthcare and medicine. Despite the availability of various open-source\nLLMs tailored for health contexts, adapting general-purpose LLMs to the medical\ndomain presents significant challenges. In this paper, we introduce BioMistral,\nan open-source LLM tailored for the biomedical domain, utilizing Mistral as its\nfoundation model and further pre-trained on PubMed Central. We conduct a\ncomprehensive evaluation of BioMistral on a benchmark comprising 10 established\nmedical question-answering (QA) tasks in English. We also explore lightweight\nmodels obtained through quantization and model merging approaches. Our results\ndemonstrate BioMistral's superior performance compared to existing open-source\nmedical models and its competitive edge against proprietary counterparts.\nFinally, to address the limited availability of data beyond English and to\nassess the multilingual generalization of medical LLMs, we automatically\ntranslated and evaluated this benchmark into 7 other languages. This marks the\nfirst large-scale multilingual evaluation of LLMs in the medical domain.\nDatasets, multilingual evaluation benchmarks, scripts, and all the models\nobtained during our experiments are freely released.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024 - Proceedings of the 62st Annual Meeting of the\n  Association for Computational Linguistics (Volume 1: Long Papers)",
    "pdf_url": "http://arxiv.org/pdf/2402.10373v3",
    "published_date": "2024-02-15 23:39:04 UTC",
    "updated_date": "2024-07-17 09:34:00 UTC"
  },
  {
    "arxiv_id": "2402.10350v1",
    "title": "Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review",
    "authors": [
      "Jing Su",
      "Chufeng Jiang",
      "Xin Jin",
      "Yuxin Qiao",
      "Tingsong Xiao",
      "Hongda Ma",
      "Rong Wei",
      "Zhi Jing",
      "Jiajun Xu",
      "Junhong Lin"
    ],
    "abstract": "This systematic literature review comprehensively examines the application of\nLarge Language Models (LLMs) in forecasting and anomaly detection, highlighting\nthe current state of research, inherent challenges, and prospective future\ndirections. LLMs have demonstrated significant potential in parsing and\nanalyzing extensive datasets to identify patterns, predict future events, and\ndetect anomalous behavior across various domains. However, this review\nidentifies several critical challenges that impede their broader adoption and\neffectiveness, including the reliance on vast historical datasets, issues with\ngeneralizability across different contexts, the phenomenon of model\nhallucinations, limitations within the models' knowledge boundaries, and the\nsubstantial computational resources required. Through detailed analysis, this\nreview discusses potential solutions and strategies to overcome these\nobstacles, such as integrating multimodal data, advancements in learning\nmethodologies, and emphasizing model explainability and computational\nefficiency. Moreover, this review outlines critical trends that are likely to\nshape the evolution of LLMs in these fields, including the push toward\nreal-time processing, the importance of sustainable modeling practices, and the\nvalue of interdisciplinary collaboration. Conclusively, this review underscores\nthe transformative impact LLMs could have on forecasting and anomaly detection\nwhile emphasizing the need for continuous innovation, ethical considerations,\nand practical solutions to realize their full potential.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10350v1",
    "published_date": "2024-02-15 22:43:02 UTC",
    "updated_date": "2024-02-15 22:43:02 UTC"
  },
  {
    "arxiv_id": "2403.19669v2",
    "title": "Analyzing the Roles of Language and Vision in Learning from Limited Data",
    "authors": [
      "Allison Chen",
      "Ilia Sucholutsky",
      "Olga Russakovsky",
      "Thomas L. Griffiths"
    ],
    "abstract": "Does language help make sense of the visual world? How important is it to\nactually see the world rather than having it described with words? These basic\nquestions about the nature of intelligence have been difficult to answer\nbecause we only had one example of an intelligent system -- humans -- and\nlimited access to cases that isolated language or vision. However, the\ndevelopment of sophisticated Vision-Language Models (VLMs) by artificial\nintelligence researchers offers us new opportunities to explore the\ncontributions that language and vision make to learning about the world. We\nablate components from the cognitive architecture of these models to identify\ntheir contributions to learning new tasks from limited data. We find that a\nlanguage model leveraging all components recovers a majority of a VLM's\nperformance, despite its lack of visual input, and that language seems to allow\nthis by providing access to prior knowledge and reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.19669v2",
    "published_date": "2024-02-15 22:19:41 UTC",
    "updated_date": "2024-05-10 17:33:24 UTC"
  },
  {
    "arxiv_id": "2402.10342v2",
    "title": "Exploration-Driven Policy Optimization in RLHF: Theoretical Insights on Efficient Data Utilization",
    "authors": [
      "Yihan Du",
      "Anna Winnicki",
      "Gal Dalal",
      "Shie Mannor",
      "R. Srikant"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has achieved impressive\nempirical successes while relying on a small amount of human feedback. However,\nthere is limited theoretical justification for this phenomenon. Additionally,\nmost recent studies focus on value-based algorithms despite the recent\nempirical successes of policy-based algorithms. In this work, we consider an\nRLHF algorithm based on policy optimization (PO-RLHF). The algorithm is based\non the popular Policy Cover-Policy Gradient (PC-PG) algorithm, which assumes\nknowledge of the reward function. In PO-RLHF, knowledge of the reward function\nis not assumed, and the algorithm uses trajectory-based comparison feedback to\ninfer the reward function. We provide performance bounds for PO-RLHF with low\nquery complexity, which provides insight into why a small amount of human\nfeedback may be sufficient to achieve good performance with RLHF. A key novelty\nis a trajectory-level elliptical potential analysis, which bounds the reward\nestimation error when comparison feedback (rather than numerical reward\nobservation) is given. We provide and analyze algorithms PG-RLHF and NN-PG-RLHF\nfor two settings: linear and neural function approximation, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10342v2",
    "published_date": "2024-02-15 22:11:18 UTC",
    "updated_date": "2024-07-15 04:19:50 UTC"
  },
  {
    "arxiv_id": "2402.10340v5",
    "title": "On the Vulnerability of LLM/VLM-Controlled Robotics",
    "authors": [
      "Xiyang Wu",
      "Souradip Chakraborty",
      "Ruiqi Xian",
      "Jing Liang",
      "Tianrui Guan",
      "Fuxiao Liu",
      "Brian M. Sadler",
      "Dinesh Manocha",
      "Amrit Singh Bedi"
    ],
    "abstract": "In this work, we highlight vulnerabilities in robotic systems integrating\nlarge language models (LLMs) and vision-language models (VLMs) due to input\nmodality sensitivities. While LLM/VLM-controlled robots show impressive\nperformance across various tasks, their reliability under slight input\nvariations remains underexplored yet critical. These models are highly\nsensitive to instruction or perceptual input changes, which can trigger\nmisalignment issues, leading to execution failures with severe real-world\nconsequences. To study this issue, we analyze the misalignment-induced\nvulnerabilities within LLM/VLM-controlled robotic systems and present a\nmathematical formulation for failure modes arising from variations in input\nmodalities. We propose empirical perturbation strategies to expose these\nvulnerabilities and validate their effectiveness through experiments on\nmultiple robot manipulation tasks. Our results show that simple input\nperturbations reduce task execution success rates by 22.2% and 14.6% in two\nrepresentative LLM/VLM-controlled robotic systems. These findings underscore\nthe importance of input modality robustness and motivate further research to\nensure the safe and reliable deployment of advanced LLM/VLM-controlled robotic\nsystems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10340v5",
    "published_date": "2024-02-15 22:01:45 UTC",
    "updated_date": "2025-03-07 04:01:59 UTC"
  },
  {
    "arxiv_id": "2402.10334v1",
    "title": "HI-GAN: Hierarchical Inpainting GAN with Auxiliary Inputs for Combined RGB and Depth Inpainting",
    "authors": [
      "Ankan Dash",
      "Jingyi Gu",
      "Guiling Wang"
    ],
    "abstract": "Inpainting involves filling in missing pixels or areas in an image, a crucial\ntechnique employed in Mixed Reality environments for various applications,\nparticularly in Diminished Reality (DR) where content is removed from a user's\nvisual environment. Existing methods rely on digital replacement techniques\nwhich necessitate multiple cameras and incur high costs. AR devices and\nsmartphones use ToF depth sensors to capture scene depth maps aligned with RGB\nimages. Despite speed and affordability, ToF cameras create imperfect depth\nmaps with missing pixels. To address the above challenges, we propose\nHierarchical Inpainting GAN (HI-GAN), a novel approach comprising three GANs in\na hierarchical fashion for RGBD inpainting. EdgeGAN and LabelGAN inpaint masked\nedge and segmentation label images respectively, while CombinedRGBD-GAN\ncombines their latent representation outputs and performs RGB and Depth\ninpainting. Edge images and particularly segmentation label images as auxiliary\ninputs significantly enhance inpainting performance by complementary context\nand hierarchical optimization. We believe we make the first attempt to\nincorporate label images into inpainting process.Unlike previous approaches\nrequiring multiple sequential models and separate outputs, our work operates in\nan end-to-end manner, training all three models simultaneously and\nhierarchically. Specifically, EdgeGAN and LabelGAN are first optimized\nseparately and further optimized inside CombinedRGBD-GAN to enhance inpainting\nquality. Experiments demonstrate that HI-GAN works seamlessly and achieves\noverall superior performance compared with existing approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10334v1",
    "published_date": "2024-02-15 21:43:56 UTC",
    "updated_date": "2024-02-15 21:43:56 UTC"
  },
  {
    "arxiv_id": "2402.10980v5",
    "title": "ChemReasoner: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback",
    "authors": [
      "Henry W. Sprueill",
      "Carl Edwards",
      "Khushbu Agarwal",
      "Mariefel V. Olarte",
      "Udishnu Sanyal",
      "Conrad Johnston",
      "Hongbin Liu",
      "Heng Ji",
      "Sutanay Choudhury"
    ],
    "abstract": "The discovery of new catalysts is essential for the design of new and more\nefficient chemical processes in order to transition to a sustainable future. We\nintroduce an AI-guided computational screening framework unifying linguistic\nreasoning with quantum-chemistry based feedback from 3D atomistic\nrepresentations. Our approach formulates catalyst discovery as an uncertain\nenvironment where an agent actively searches for highly effective catalysts via\nthe iterative combination of large language model (LLM)-derived hypotheses and\natomistic graph neural network (GNN)-derived feedback. Identified catalysts in\nintermediate search steps undergo structural evaluation based on spatial\norientation, reaction pathways, and stability. Scoring functions based on\nadsorption energies and reaction energy barriers steer the exploration in the\nLLM's knowledge space toward energetically favorable, high-efficiency\ncatalysts. We introduce planning methods that automatically guide the\nexploration without human input, providing competitive performance against\nexpert-enumerated chemical descriptor-based implementations. By integrating\nlanguage-guided reasoning with computational chemistry feedback, our work\npioneers AI-accelerated, trustworthy catalyst discovery.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "9 pages, accepted by ICML 2024, final version",
    "pdf_url": "http://arxiv.org/pdf/2402.10980v5",
    "published_date": "2024-02-15 21:33:07 UTC",
    "updated_date": "2024-12-09 03:01:35 UTC"
  },
  {
    "arxiv_id": "2403.18923v2",
    "title": "Evolution-based Feature Selection for Predicting Dissolved Oxygen Concentrations in Lakes",
    "authors": [
      "Runlong Yu",
      "Robert Ladwig",
      "Xiang Xu",
      "Peijun Zhu",
      "Paul C. Hanson",
      "Yiqun Xie",
      "Xiaowei Jia"
    ],
    "abstract": "Accurate prediction of dissolved oxygen (DO) concentrations in lakes requires\na comprehensive study of phenological patterns across ecosystems, highlighting\nthe need for precise selection of interactions amongst external factors and\ninternal physical-chemical-biological variables. This paper presents the\nMulti-population Cognitive Evolutionary Search (MCES), a novel evolutionary\nalgorithm for complex feature interaction selection problems. MCES allows\nmodels within every population to evolve adaptively, selecting relevant feature\ninteractions for different lake types and tasks. Evaluated on diverse lakes in\nthe Midwestern USA, MCES not only consistently produces accurate predictions\nwith few observed labels but also, through gene maps of models, reveals\nsophisticated phenological patterns of different lake types, embodying the\ninnovative concept of \"AI from nature, for nature\".",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.18923v2",
    "published_date": "2024-02-15 20:27:33 UTC",
    "updated_date": "2024-10-29 19:55:38 UTC"
  },
  {
    "arxiv_id": "2402.10979v2",
    "title": "SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs",
    "authors": [
      "Yebowen Hu",
      "Kaiqiang Song",
      "Sangwoo Cho",
      "Xiaoyang Wang",
      "Hassan Foroosh",
      "Dong Yu",
      "Fei Liu"
    ],
    "abstract": "Large language models hold significant potential for integrating various data\ntypes, such as text documents and database records, for advanced analytics.\nHowever, blending text and numerical data presents substantial challenges. LLMs\nneed to process and cross-reference entities and numbers, handle data\ninconsistencies and redundancies, and develop planning capabilities such as\nbuilding a working memory for managing complex data queries. In this paper, we\nintroduce four novel tasks centered around sports data analytics to evaluate\nthe numerical reasoning and information fusion capabilities of LLMs. These\ntasks involve providing LLMs with detailed, play-by-play sports game\ndescriptions, then challenging them with adversarial scenarios such as new game\nrules, longer durations, scrambled narratives, and analyzing key statistics in\ngame summaries. We conduct extensive experiments on NBA and NFL games to assess\nthe performance of LLMs on these tasks. Our benchmark, SportsMetrics,\nintroduces a new mechanism for assessing LLMs' numerical reasoning and fusion\nskills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Long Paper",
    "pdf_url": "http://arxiv.org/pdf/2402.10979v2",
    "published_date": "2024-02-15 20:26:07 UTC",
    "updated_date": "2024-06-16 06:43:50 UTC"
  },
  {
    "arxiv_id": "2402.10294v1",
    "title": "LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing",
    "authors": [
      "Bryan Wang",
      "Yuliang Li",
      "Zhaoyang Lv",
      "Haijun Xia",
      "Yan Xu",
      "Raj Sodhi"
    ],
    "abstract": "Video creation has become increasingly popular, yet the expertise and effort\nrequired for editing often pose barriers to beginners. In this paper, we\nexplore the integration of large language models (LLMs) into the video editing\nworkflow to reduce these barriers. Our design vision is embodied in LAVE, a\nnovel system that provides LLM-powered agent assistance and language-augmented\nediting features. LAVE automatically generates language descriptions for the\nuser's footage, serving as the foundation for enabling the LLM to process\nvideos and assist in editing tasks. When the user provides editing objectives,\nthe agent plans and executes relevant actions to fulfill them. Moreover, LAVE\nallows users to edit videos through either the agent or direct UI manipulation,\nproviding flexibility and enabling manual refinement of agent actions. Our user\nstudy, which included eight participants ranging from novices to proficient\neditors, demonstrated LAVE's effectiveness. The results also shed light on user\nperceptions of the proposed LLM-assisted editing paradigm and its impact on\nusers' creativity and sense of co-creation. Based on these findings, we propose\ndesign implications to inform the future development of agent-assisted content\nediting.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted to the ACM Conference on Intelligent User Interfaces\n  (ACM IUI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10294v1",
    "published_date": "2024-02-15 19:53:11 UTC",
    "updated_date": "2024-02-15 19:53:11 UTC"
  },
  {
    "arxiv_id": "2402.10290v1",
    "title": "Experiments with Encoding Structured Data for Neural Networks",
    "authors": [
      "Sujay Nagesh Koujalgi",
      "Jonathan Dodge"
    ],
    "abstract": "The project's aim is to create an AI agent capable of selecting good actions\nin a game-playing domain called Battlespace. Sequential domains like\nBattlespace are important testbeds for planning problems, as such, the\nDepartment of Defense uses such domains for wargaming exercises. The agents we\ndeveloped combine Monte Carlo Tree Search (MCTS) and Deep Q-Network (DQN)\ntechniques in an effort to navigate the game environment, avoid obstacles,\ninteract with adversaries, and capture the flag. This paper will focus on the\nencoding techniques we explored to present complex structured data stored in a\nPython class, a necessary precursor to an agent.",
    "categories": [
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 8 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.10290v1",
    "published_date": "2024-02-15 19:45:15 UTC",
    "updated_date": "2024-02-15 19:45:15 UTC"
  },
  {
    "arxiv_id": "2402.10283v1",
    "title": "Backdoor Attack against One-Class Sequential Anomaly Detection Models",
    "authors": [
      "He Cheng",
      "Shuhan Yuan"
    ],
    "abstract": "Deep anomaly detection on sequential data has garnered significant attention\ndue to the wide application scenarios. However, deep learning-based models face\na critical security threat - their vulnerability to backdoor attacks. In this\npaper, we explore compromising deep sequential anomaly detection models by\nproposing a novel backdoor attack strategy. The attack approach comprises two\nprimary steps, trigger generation and backdoor injection. Trigger generation is\nto derive imperceptible triggers by crafting perturbed samples from the benign\nnormal data, of which the perturbed samples are still normal. The backdoor\ninjection is to properly inject the backdoor triggers to comprise the model\nonly for the samples with triggers. The experimental results demonstrate the\neffectiveness of our proposed attack strategy by injecting backdoors on two\nwell-established one-class anomaly detection models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "This work is accepted by the PAKDD 2024. 12 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.10283v1",
    "published_date": "2024-02-15 19:19:54 UTC",
    "updated_date": "2024-02-15 19:19:54 UTC"
  },
  {
    "arxiv_id": "2402.10210v1",
    "title": "Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation",
    "authors": [
      "Huizhuo Yuan",
      "Zixiang Chen",
      "Kaixuan Ji",
      "Quanquan Gu"
    ],
    "abstract": "Fine-tuning Diffusion Models remains an underexplored frontier in generative\nartificial intelligence (GenAI), especially when compared with the remarkable\nprogress made in fine-tuning Large Language Models (LLMs). While cutting-edge\ndiffusion models such as Stable Diffusion (SD) and SDXL rely on supervised\nfine-tuning, their performance inevitably plateaus after seeing a certain\nvolume of data. Recently, reinforcement learning (RL) has been employed to\nfine-tune diffusion models with human preference data, but it requires at least\ntwo images (\"winner\" and \"loser\" images) for each text prompt. In this paper,\nwe introduce an innovative technique called self-play fine-tuning for diffusion\nmodels (SPIN-Diffusion), where the diffusion model engages in competition with\nits earlier versions, facilitating an iterative self-improvement process. Our\napproach offers an alternative to conventional supervised fine-tuning and RL\nstrategies, significantly improving both model performance and alignment. Our\nexperiments on the Pick-a-Pic dataset reveal that SPIN-Diffusion outperforms\nthe existing supervised fine-tuning method in aspects of human preference\nalignment and visual appeal right from its first iteration. By the second\niteration, it exceeds the performance of RLHF-based methods across all metrics,\nachieving these results with less data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 8 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.10210v1",
    "published_date": "2024-02-15 18:59:18 UTC",
    "updated_date": "2024-02-15 18:59:18 UTC"
  },
  {
    "arxiv_id": "2404.08471v1",
    "title": "Revisiting Feature Prediction for Learning Visual Representations from Video",
    "authors": [
      "Adrien Bardes",
      "Quentin Garrido",
      "Jean Ponce",
      "Xinlei Chen",
      "Michael Rabbat",
      "Yann LeCun",
      "Mahmoud Assran",
      "Nicolas Ballas"
    ],
    "abstract": "This paper explores feature prediction as a stand-alone objective for\nunsupervised learning from video and introduces V-JEPA, a collection of vision\nmodels trained solely using a feature prediction objective, without the use of\npretrained image encoders, text, negative examples, reconstruction, or other\nsources of supervision. The models are trained on 2 million videos collected\nfrom public datasets and are evaluated on downstream image and video tasks. Our\nresults show that learning by predicting video features leads to versatile\nvisual representations that perform well on both motion and appearance-based\ntasks, without adaption of the model's parameters; e.g., using a frozen\nbackbone. Our largest model, a ViT-H/16 trained only on videos, obtains 81.9%\non Kinetics-400, 72.2% on Something-Something-v2, and 77.9% on ImageNet1K.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08471v1",
    "published_date": "2024-02-15 18:59:11 UTC",
    "updated_date": "2024-02-15 18:59:11 UTC"
  },
  {
    "arxiv_id": "2402.10207v6",
    "title": "Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment",
    "authors": [
      "Rui Yang",
      "Xiaoman Pan",
      "Feng Luo",
      "Shuang Qiu",
      "Han Zhong",
      "Dong Yu",
      "Jianshu Chen"
    ],
    "abstract": "We consider the problem of multi-objective alignment of foundation models\nwith human preferences, which is a critical step towards helpful and harmless\nAI systems. However, it is generally costly and unstable to fine-tune large\nfoundation models using reinforcement learning (RL), and the\nmulti-dimensionality, heterogeneity, and conflicting nature of human\npreferences further complicate the alignment process. In this paper, we\nintroduce Rewards-in-Context (RiC), which conditions the response of a\nfoundation model on multiple rewards in its prompt context and applies\nsupervised fine-tuning for alignment. The salient features of RiC are\nsimplicity and adaptivity, as it only requires supervised fine-tuning of a\nsingle foundation model and supports dynamic adjustment for user preferences\nduring inference time. Inspired by the analytical solution of an abstracted\nconvex optimization problem, our dynamic inference-time adjustment method\napproaches the Pareto-optimal solution for multiple objectives. Empirical\nevidence demonstrates the efficacy of our method in aligning both Large\nLanguage Models (LLMs) and diffusion models to accommodate diverse rewards with\nonly around 10% GPU hours compared with multi-objective RL baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10207v6",
    "published_date": "2024-02-15 18:58:31 UTC",
    "updated_date": "2024-10-16 03:24:02 UTC"
  },
  {
    "arxiv_id": "2402.10206v3",
    "title": "Ising on the Graph: Task-specific Graph Subsampling via the Ising Model",
    "authors": [
      "Maria Bånkestad",
      "Jennifer R. Andersson",
      "Sebastian Mair",
      "Jens Sjölund"
    ],
    "abstract": "Reducing a graph while preserving its overall properties is an important\nproblem with many applications. Typically, reduction approaches either remove\nedges (sparsification) or merge nodes (coarsening) in an unsupervised way with\nno specific downstream task in mind. In this paper, we present an approach for\nsubsampling graph structures using an Ising model defined on either the nodes\nor edges and learning the external magnetic field of the Ising model using a\ngraph neural network. Our approach is task-specific as it can learn how to\nreduce a graph for a specific downstream task in an end-to-end fashion without\nrequiring a differentiable loss function for the task. We showcase the\nversatility of our approach on four distinct applications: image segmentation,\nexplainability for graph classification, 3D shape sparsification, and sparse\napproximate matrix inverse determination.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 22 figures, accepted at the Learning on Graphs conference\n  (LoG 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.10206v3",
    "published_date": "2024-02-15 18:58:18 UTC",
    "updated_date": "2025-04-08 13:40:08 UTC"
  },
  {
    "arxiv_id": "2402.10204v2",
    "title": "Radio-astronomical Image Reconstruction with Conditional Denoising Diffusion Model",
    "authors": [
      "Mariia Drozdova",
      "Vitaliy Kinakh",
      "Omkar Bait",
      "Olga Taran",
      "Erica Lastufka",
      "Miroslava Dessauges-Zavadsky",
      "Taras Holotyak",
      "Daniel Schaerer",
      "Slava Voloshynovskiy"
    ],
    "abstract": "Reconstructing sky models from dirty radio images for accurate source\nlocalization and flux estimation is crucial for studying galaxy evolution at\nhigh redshift, especially in deep fields using instruments like the Atacama\nLarge Millimetre Array (ALMA). With new projects like the Square Kilometre\nArray (SKA), there's a growing need for better source extraction methods.\nCurrent techniques, such as CLEAN and PyBDSF, often fail to detect faint\nsources, highlighting the need for more accurate methods. This study proposes\nusing stochastic neural networks to rebuild sky models directly from dirty\nimages. This method can pinpoint radio sources and measure their fluxes with\nrelated uncertainties, marking a potential improvement in radio source\ncharacterization. We tested this approach on 10164 images simulated with the\nCASA tool simalma, based on ALMA's Cycle 5.3 antenna setup. We applied\nconditional Denoising Diffusion Probabilistic Models (DDPMs) for sky models\nreconstruction, then used Photutils to determine source coordinates and fluxes,\nassessing the model's performance across different water vapor levels. Our\nmethod showed excellence in source localization, achieving more than 90%\ncompleteness at a signal-to-noise ratio (SNR) as low as 2. It also surpassed\nPyBDSF in flux estimation, accurately identifying fluxes for 96% of sources in\nthe test set, a significant improvement over CLEAN+ PyBDSF's 57%. Conditional\nDDPMs is a powerful tool for image-to-image translation, yielding accurate and\nrobust characterisation of radio sources, and outperforming existing\nmethodologies. While this study underscores its significant potential for\napplications in radio astronomy, we also acknowledge certain limitations that\naccompany its usage, suggesting directions for further refinement and research.",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "In production in Astronomy&Astrophyics",
    "pdf_url": "http://arxiv.org/pdf/2402.10204v2",
    "published_date": "2024-02-15 18:57:24 UTC",
    "updated_date": "2024-02-20 18:00:23 UTC"
  },
  {
    "arxiv_id": "2402.10196v1",
    "title": "A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents",
    "authors": [
      "Lingbo Mo",
      "Zeyi Liao",
      "Boyuan Zheng",
      "Yu Su",
      "Chaowei Xiao",
      "Huan Sun"
    ],
    "abstract": "Language agents powered by large language models (LLMs) have seen exploding\ndevelopment. Their capability of using language as a vehicle for thought and\ncommunication lends an incredible level of flexibility and versatility. People\nhave quickly capitalized on this capability to connect LLMs to a wide range of\nexternal components and environments: databases, tools, the Internet, robotic\nembodiment, etc. Many believe an unprecedentedly powerful automation technology\nis emerging. However, new automation technologies come with new safety risks,\nespecially for intricate systems like language agents. There is a surprisingly\nlarge gap between the speed and scale of their development and deployment and\nour understanding of their safety risks. Are we building a house of cards? In\nthis position paper, we present the first systematic effort in mapping\nadversarial attacks against language agents. We first present a unified\nconceptual framework for agents with three major components: Perception, Brain,\nand Action. Under this framework, we present a comprehensive discussion and\npropose 12 potential attack scenarios against different components of an agent,\ncovering different attack strategies (e.g., input manipulation, adversarial\ndemonstrations, jailbreaking, backdoors). We also draw connections to\nsuccessful attack strategies previously applied to LLMs. We emphasize the\nurgency to gain a thorough understanding of language agent risks before their\nwidespread deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10196v1",
    "published_date": "2024-02-15 18:51:32 UTC",
    "updated_date": "2024-02-15 18:51:32 UTC"
  },
  {
    "arxiv_id": "2402.10192v3",
    "title": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias",
    "authors": [
      "Philip A. LeMaitre",
      "Marius Krumm",
      "Hans J. Briegel"
    ],
    "abstract": "With the impressive progress of deep learning, applications relying on\nmachine learning are increasingly being integrated into daily life. However,\nmost deep learning models have an opaque, oracle-like nature making it\ndifficult to interpret and understand their decisions. This problem led to the\ndevelopment of the field known as eXplainable Artificial Intelligence (XAI).\nOne method in this field known as Projective Simulation (PS) models a\nchain-of-thought as a random walk of a particle on a graph with vertices that\nhave concepts attached to them. While this description has various benefits,\nincluding the possibility of quantization, it cannot be naturally used to model\nthoughts that combine several concepts simultaneously. To overcome this\nlimitation, we introduce Multi-Excitation Projective Simulation (mePS), a\ngeneralization that considers a chain-of-thought to be a random walk of several\nparticles on a hypergraph. A definition for a dynamic hypergraph is put forward\nto describe the agent's training history along with applications to AI and\nhypergraph visualization. An inductive bias inspired by the remarkably\nsuccessful few-body interaction models used in quantum many-body physics is\nformalized for our classical mePS framework and employed to tackle the\nexponential complexity associated with naive implementations of hypergraphs. We\nprove that our inductive bias reduces the complexity from exponential to\npolynomial, with the exponent representing the cutoff on how many particles can\ninteract. We numerically apply our method to two toy environments and a more\ncomplex scenario modelling the diagnosis of a broken computer. These\nenvironments demonstrate the resource savings provided by an appropriate choice\nof inductive bias, as well as showcasing aspects of interpretability. A quantum\nmodel for mePS is also briefly outlined and some future directions for it are\ndiscussed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 8 figures; Code repository at\n  https://github.com/MariusKrumm/ManyBodyMEPS. Reorganized main text for better\n  readability",
    "pdf_url": "http://arxiv.org/pdf/2402.10192v3",
    "published_date": "2024-02-15 18:48:32 UTC",
    "updated_date": "2024-10-23 08:39:00 UTC"
  },
  {
    "arxiv_id": "2402.10184v6",
    "title": "Reward Generalization in RLHF: A Topological Perspective",
    "authors": [
      "Tianyi Qiu",
      "Fanzhi Zeng",
      "Jiaming Ji",
      "Dong Yan",
      "Kaile Wang",
      "Jiayi Zhou",
      "Yang Han",
      "Josef Dai",
      "Xuehai Pan",
      "Yaodong Yang"
    ],
    "abstract": "Existing alignment methods share a common topology of information flow, where\nreward information is collected from humans, modeled with preference learning,\nand used to tune language models. However, this shared topology has not been\nsystematically characterized, nor have its alternatives been thoroughly\nexplored, leaving the problems of low data efficiency and unreliable\ngeneralization unaddressed. As a solution, we introduce a theoretical framework\nfor investigating reward generalization in reinforcement learning from human\nfeedback (RLHF), focusing on the topology of information flow at both macro and\nmicro levels. At the macro level, we portray the RLHF information flow as an\nautoencoding process over behavior distributions, formalizing the RLHF\nobjective of distributional consistency between human preference and model\nbehavior. At the micro level, we present induced Bayesian networks as a theory\nof reward generalization in RLHF, introducing fine-grained dataset topologies\ninto generalization bounds. Combining analysis on both levels, we propose\nreward modeling from tree-structured preference information. It is shown to\nreduce reward uncertainty by up to $\\Theta(\\log n/\\log\\log n)$ times compared\nto baselines, where $n$ is the dataset size. Validation on three NLP tasks\nshows that our tree-based reward model achieves an average win rate of 65%\nagainst baseline methods, thus improving reward generalization for free via\ntopology design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10184v6",
    "published_date": "2024-02-15 18:39:24 UTC",
    "updated_date": "2024-09-11 02:20:16 UTC"
  },
  {
    "arxiv_id": "2402.10978v1",
    "title": "Language Models with Conformal Factuality Guarantees",
    "authors": [
      "Christopher Mohri",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Guaranteeing the correctness and factuality of language model (LM) outputs is\na major open problem. In this work, we propose conformal factuality, a\nframework that can ensure high probability correctness guarantees for LMs by\nconnecting language modeling and conformal prediction. We observe that the\ncorrectness of an LM output is equivalent to an uncertainty quantification\nproblem, where the uncertainty sets are defined as the entailment set of an\nLM's output. Using this connection, we show that conformal prediction in\nlanguage models corresponds to a back-off algorithm that provides high\nprobability correctness guarantees by progressively making LM outputs less\nspecific (and expanding the associated uncertainty sets). This approach applies\nto any black-box LM and requires very few human-annotated samples. Evaluations\nof our approach on closed book QA (FActScore, NaturalQuestions) and reasoning\ntasks (MATH) show that our approach can provide 80-90% correctness guarantees\nwhile retaining the majority of the LM's original output.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10978v1",
    "published_date": "2024-02-15 18:31:53 UTC",
    "updated_date": "2024-02-15 18:31:53 UTC"
  },
  {
    "arxiv_id": "2402.10177v1",
    "title": "Large Scale Constrained Clustering With Reinforcement Learning",
    "authors": [
      "Benedikt Schesch",
      "Marco Caserta"
    ],
    "abstract": "Given a network, allocating resources at clusters level, rather than at each\nnode, enhances efficiency in resource allocation and usage. In this paper, we\nstudy the problem of finding fully connected disjoint clusters to minimize the\nintra-cluster distances and maximize the number of nodes assigned to the\nclusters, while also ensuring that no two nodes within a cluster exceed a\nthreshold distance. While the problem can easily be formulated using a binary\nlinear model, traditional combinatorial optimization solvers struggle when\ndealing with large-scale instances. We propose an approach to solve this\nconstrained clustering problem via reinforcement learning. Our method involves\ntraining an agent to generate both feasible and (near) optimal solutions. The\nagent learns problem-specific heuristics, tailored to the instances encountered\nin this task. In the results section, we show that our algorithm finds near\noptimal solutions, even for large scale instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "LEANOPT-24 AAAI",
    "pdf_url": "http://arxiv.org/pdf/2402.10177v1",
    "published_date": "2024-02-15 18:27:18 UTC",
    "updated_date": "2024-02-15 18:27:18 UTC"
  },
  {
    "arxiv_id": "2402.10176v2",
    "title": "OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset",
    "authors": [
      "Shubham Toshniwal",
      "Ivan Moshkov",
      "Sean Narenthiran",
      "Daria Gitman",
      "Fei Jia",
      "Igor Gitman"
    ],
    "abstract": "Recent work has shown the immense potential of synthetically generated\ndatasets for training large language models (LLMs), especially for acquiring\ntargeted skills. Current large-scale math instruction tuning datasets such as\nMetaMathQA (Yu et al., 2024) and MAmmoTH (Yue et al., 2024) are constructed\nusing outputs from closed-source LLMs with commercially restrictive licenses. A\nkey reason limiting the use of open-source LLMs in these data generation\npipelines has been the wide gap between the mathematical skills of the best\nclosed-source LLMs, such as GPT-4, and the best open-source LLMs. Building on\nthe recent progress in open-source LLMs, our proposed prompting novelty, and\nsome brute-force scaling, we construct OpenMathInstruct-1, a math instruction\ntuning dataset with 1.8M problem-solution pairs. The dataset is constructed by\nsynthesizing code-interpreter solutions for GSM8K and MATH, two popular math\nreasoning benchmarks, using the recently released and permissively licensed\nMixtral model. Our best model, OpenMath-CodeLlama-70B, trained on a subset of\nOpenMathInstruct-1, achieves a score of 84.6% on GSM8K and 50.7% on MATH, which\nis competitive with the best gpt-distilled models. We release our code, models,\nand the OpenMathInstruct-1 dataset under a commercially permissive license.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera-ready version for NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10176v2",
    "published_date": "2024-02-15 18:26:11 UTC",
    "updated_date": "2024-11-03 03:48:02 UTC"
  },
  {
    "arxiv_id": "2402.10977v2",
    "title": "Generative AI and Process Systems Engineering: The Next Frontier",
    "authors": [
      "Benjamin Decardi-Nelson",
      "Abdulelah S. Alshehri",
      "Akshay Ajagekar",
      "Fengqi You"
    ],
    "abstract": "This article explores how emerging generative artificial intelligence (GenAI)\nmodels, such as large language models (LLMs), can enhance solution\nmethodologies within process systems engineering (PSE). These cutting-edge\nGenAI models, particularly foundation models (FMs), which are pre-trained on\nextensive, general-purpose datasets, offer versatile adaptability for a broad\nrange of tasks, including responding to queries, image generation, and complex\ndecision-making. Given the close relationship between advancements in PSE and\ndevelopments in computing and systems technologies, exploring the synergy\nbetween GenAI and PSE is essential. We begin our discussion with a compact\noverview of both classic and emerging GenAI models, including FMs, and then\ndive into their applications within key PSE domains: synthesis and design,\noptimization and integration, and process monitoring and control. In each\ndomain, we explore how GenAI models could potentially advance PSE\nmethodologies, providing insights and prospects for each area. Furthermore, the\narticle identifies and discusses potential challenges in fully leveraging GenAI\nwithin PSE, including multiscale modeling, data requirements, evaluation\nmetrics and benchmarks, and trust and safety, thereby deepening the discourse\non effective GenAI integration into systems analysis, design, optimization,\noperations, monitoring, and control. This paper provides a guide for future\nresearch focused on the applications of emerging GenAI in PSE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10977v2",
    "published_date": "2024-02-15 18:20:42 UTC",
    "updated_date": "2024-05-06 21:40:04 UTC"
  },
  {
    "arxiv_id": "2402.10172v1",
    "title": "OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models",
    "authors": [
      "Ali AhmadiTeshnizi",
      "Wenzhi Gao",
      "Madeleine Udell"
    ],
    "abstract": "Optimization problems are pervasive in sectors from manufacturing and\ndistribution to healthcare. However, most such problems are still solved\nheuristically by hand rather than optimally by state-of-the-art solvers because\nthe expertise required to formulate and solve these problems limits the\nwidespread adoption of optimization tools and techniques. This paper introduces\nOptiMUS, a Large Language Model (LLM)-based agent designed to formulate and\nsolve (mixed integer) linear programming problems from their natural language\ndescriptions. OptiMUS can develop mathematical models, write and debug solver\ncode, evaluate the generated solutions, and improve its model and code based on\nthese evaluations. OptiMUS utilizes a modular structure to process problems,\nallowing it to handle problems with long descriptions and complex data without\nlong prompts. Experiments demonstrate that OptiMUS outperforms existing\nstate-of-the-art methods on easy datasets by more than $20\\%$ and on hard\ndatasets (including a new dataset, NLP4LP, released with this paper that\nfeatures long and complex problems) by more than $30\\%$.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10172v1",
    "published_date": "2024-02-15 18:19:18 UTC",
    "updated_date": "2024-02-15 18:19:18 UTC"
  },
  {
    "arxiv_id": "2402.10171v1",
    "title": "Data Engineering for Scaling Language Models to 128K Context",
    "authors": [
      "Yao Fu",
      "Rameswar Panda",
      "Xinyao Niu",
      "Xiang Yue",
      "Hannaneh Hajishirzi",
      "Yoon Kim",
      "Hao Peng"
    ],
    "abstract": "We study the continual pretraining recipe for scaling language models'\ncontext lengths to 128K, with a focus on data engineering. We hypothesize that\nlong context modeling, in particular \\textit{the ability to utilize information\nat arbitrary input locations}, is a capability that is mostly already acquired\nthrough large-scale pretraining, and that this capability can be readily\nextended to contexts substantially longer than seen during training~(e.g., 4K\nto 128K) through lightweight continual pretraining on appropriate data mixture.\nWe investigate the \\textit{quantity} and \\textit{quality} of the data for\ncontinual pretraining: (1) for quantity, we show that 500 million to 5 billion\ntokens are enough to enable the model to retrieve information anywhere within\nthe 128K context; (2) for quality, our results equally emphasize \\textit{domain\nbalance} and \\textit{length upsampling}. Concretely, we find that naively\nupsampling longer data on certain domains like books, a common practice of\nexisting work, gives suboptimal performance, and that a balanced domain mixture\nis important. We demonstrate that continual pretraining of the full model on\n1B-5B tokens of such data is an effective and affordable strategy for scaling\nthe context length of language models to 128K. Our recipe outperforms strong\nopen-source long-context models and closes the gap to frontier models like\nGPT-4 128K.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code at https://github.com/FranxYao/Long-Context-Data-Engineering",
    "pdf_url": "http://arxiv.org/pdf/2402.10171v1",
    "published_date": "2024-02-15 18:19:16 UTC",
    "updated_date": "2024-02-15 18:19:16 UTC"
  },
  {
    "arxiv_id": "2402.15521v1",
    "title": "HKD-SHO: A hybrid smart home system based on knowledge-based and data-driven services",
    "authors": [
      "Mingming Qiu",
      "Elie Najm",
      "Rémi Sharrock",
      "Bruno Traverson"
    ],
    "abstract": "A smart home is realized by setting up various services. Several methods have\nbeen proposed to create smart home services, which can be divided into\nknowledge-based and data-driven approaches. However, knowledge-based approaches\nusually require manual input from the inhabitant, which can be complicated if\nthe physical phenomena of the concerned environment states are complex, and the\ninhabitant does not know how to adjust related actuators to achieve the target\nvalues of the states monitored by services. Moreover, machine learning-based\ndata-driven approaches that we are interested in are like black boxes and\ncannot show the inhabitant in which situations certain services proposed\ncertain actuators' states. To solve these problems, we propose a hybrid system\ncalled HKD-SHO (Hybrid Knowledge-based and Data-driven services based Smart\nHOme system), where knowledge-based and machine learning-based data-driven\nservices are profitably integrated. The principal advantage is that it inherits\nthe explicability of knowledge-based services and the dynamism of data-driven\nservices. We compare HKD-SHO with several systems for creating dynamic smart\nhome services, and the results show the better performance of HKD-SHO.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "keywords: Hybrid System, Knowledge Representation, Reinforcement\n  Learning, Services, Smart Home",
    "pdf_url": "http://arxiv.org/pdf/2402.15521v1",
    "published_date": "2024-02-15 18:13:41 UTC",
    "updated_date": "2024-02-15 18:13:41 UTC"
  },
  {
    "arxiv_id": "2402.10168v1",
    "title": "DeepSRGM -- Sequence Classification and Ranking in Indian Classical Music with Deep Learning",
    "authors": [
      "Sathwik Tejaswi Madhusudhan",
      "Girish Chowdhary"
    ],
    "abstract": "A vital aspect of Indian Classical Music (ICM) is Raga, which serves as a\nmelodic framework for compositions and improvisations alike. Raga Recognition\nis an important music information retrieval task in ICM as it can aid numerous\ndownstream applications ranging from music recommendations to organizing huge\nmusic collections. In this work, we propose a deep learning based approach to\nRaga recognition. Our approach employs efficient pre possessing and learns\ntemporal sequences in music data using Long Short Term Memory based Recurrent\nNeural Networks (LSTM-RNN). We train and test the network on smaller sequences\nsampled from the original audio while the final inference is performed on the\naudio as a whole. Our method achieves an accuracy of 88.1% and 97 % during\ninference on the Comp Music Carnatic dataset and its 10 Raga subset\nrespectively making it the state-of-the-art for the Raga recognition task. Our\napproach also enables sequence ranking which aids us in retrieving melodic\npatterns from a given music data base that are closely related to the presented\nquery sequence.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10168v1",
    "published_date": "2024-02-15 18:11:02 UTC",
    "updated_date": "2024-02-15 18:11:02 UTC"
  },
  {
    "arxiv_id": "2402.10142v3",
    "title": "Tracking Changing Probabilities via Dynamic Learners",
    "authors": [
      "Omid Madani"
    ],
    "abstract": "Consider a predictor, a learner, whose input is a stream of discrete items.\nThe predictor's task, at every time point, is probabilistic multiclass\nprediction, i.e. to predict which item may occur next by outputting zero or\nmore candidate items, each with a probability, after which the actual item is\nrevealed and the predictor updates. To output probabilities, the predictor\nkeeps track of the proportions of the items it has seen. The stream is\nunbounded (lifelong), and the predictor has finite limited space. The task is\nopen-ended: the set of items is unknown to the predictor and their totality can\nalso grow unbounded. Moreover, there is non-stationarity: the underlying\nfrequencies of items may change, substantially, from time to time. For\ninstance, new items may start appearing and a few recently frequent items may\ncease to occur again. The predictor, being space-bounded, need only provide\nprobabilities for those items which, at the time of prediction, have\nsufficiently high frequency, i.e., the salient items. This problem is motivated\nin the setting of Prediction Games, a self-supervised learning regime where\nconcepts serve as both the predictors and the predictands, and the set of\nconcepts grows over time, resulting in non-stationarities as new concepts are\ngenerated and used. We design and study a number of predictors, sparse moving\naverages(SMAs), for the task. One SMA adapts the sparse exponentiated moving\naverage and another is based on queuing a few counts, keeping dynamic per-item\nhistories. Evaluating the predicted probabilities, under noise and\nnon-stationarity, presents challenges, and we discuss and develop evaluation\nmethods, one based on bounding log-loss. We show that a combination of ideas,\nsupporting dynamic predictand-specific learning rates, offers advantages in\nterms of faster adaption to change (plasticity), while also supporting low\nvariance (stability).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "69 pages, 30 figures, 18 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.10142v3",
    "published_date": "2024-02-15 17:48:58 UTC",
    "updated_date": "2024-12-24 04:56:07 UTC"
  },
  {
    "arxiv_id": "2402.10135v1",
    "title": "Benchmarking federated strategies in Peer-to-Peer Federated learning for biomedical data",
    "authors": [
      "Jose L. Salmeron",
      "Irina Arévalo",
      "Antonio Ruiz-Celma"
    ],
    "abstract": "The increasing requirements for data protection and privacy has attracted a\nhuge research interest on distributed artificial intelligence and specifically\non federated learning, an emerging machine learning approach that allows the\nconstruction of a model between several participants who hold their own private\ndata. In the initial proposal of federated learning the architecture was\ncentralised and the aggregation was done with federated averaging, meaning that\na central server will orchestrate the federation using the most straightforward\naveraging strategy. This research is focused on testing different federated\nstrategies in a peer-to-peer environment. The authors propose various\naggregation strategies for federated learning, including weighted averaging\naggregation, using different factors and strategies based on participant\ncontribution. The strategies are tested with varying data sizes to identify the\nmost robust ones. This research tests the strategies with several biomedical\ndatasets and the results of the experiments show that the accuracy-based\nweighted average outperforms the classical federated averaging method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10135v1",
    "published_date": "2024-02-15 17:38:32 UTC",
    "updated_date": "2024-02-15 17:38:32 UTC"
  },
  {
    "arxiv_id": "2402.10133v2",
    "title": "Zero-Shot Reasoning: Personalized Content Generation Without the Cold Start Problem",
    "authors": [
      "Davor Hafnar",
      "Jure Demšar"
    ],
    "abstract": "Procedural content generation uses algorithmic techniques to create large\namounts of new content for games at much lower production costs. In newer\napproaches, procedural content generation utilizes machine learning. However,\nthese methods usually require expensive collection of large amounts of data, as\nwell as the development and training of fairly complex learning models, which\ncan be both extremely time-consuming and expensive. The core of our research is\nto explore whether we can lower the barrier to the use of personalized\nprocedural content generation through a more practical and generalizable\napproach with large language models. Matching game content with player\npreferences benefits both players, who enjoy the game more, and developers, who\nincreasingly depend on players enjoying the game before being able to monetize\nit. Therefore, this paper presents a novel approach to achieving\npersonalization by using large language models to propose levels based on the\ngameplay data continuously collected from individual players. We compared the\nlevels generated using our approach with levels generated with more traditional\nprocedural generation techniques. Our easily reproducible method has proven\nviable in a production setting and outperformed levels generated by traditional\nmethods in the probability that a player will not quit the game mid-level.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures. Paper accepted to IEEE Transactions on Games",
    "pdf_url": "http://arxiv.org/pdf/2402.10133v2",
    "published_date": "2024-02-15 17:37:25 UTC",
    "updated_date": "2024-06-28 10:41:02 UTC"
  },
  {
    "arxiv_id": "2402.10130v1",
    "title": "Is Continual Learning Ready for Real-world Challenges?",
    "authors": [
      "Theodora Kontogianni",
      "Yuanwen Yue",
      "Siyu Tang",
      "Konrad Schindler"
    ],
    "abstract": "Despite continual learning's long and well-established academic history, its\napplication in real-world scenarios remains rather limited. This paper contends\nthat this gap is attributable to a misalignment between the actual challenges\nof continual learning and the evaluation protocols in use, rendering proposed\nsolutions ineffective for addressing the complexities of real-world setups. We\nvalidate our hypothesis and assess progress to date, using a new 3D semantic\nsegmentation benchmark, OCL-3DSS. We investigate various continual learning\nschemes from the literature by utilizing more realistic protocols that\nnecessitate online and continual learning for dynamic, real-world scenarios\n(eg., in robotics and 3D vision applications). The outcomes are sobering: all\nconsidered methods perform poorly, significantly deviating from the upper bound\nof joint offline training. This raises questions about the applicability of\nexisting methods in realistic settings. Our paper aims to initiate a paradigm\nshift, advocating for the adoption of continual learning methods through new\nexperimental protocols that better emulate real-world conditions to facilitate\nbreakthroughs in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10130v1",
    "published_date": "2024-02-15 17:34:56 UTC",
    "updated_date": "2024-02-15 17:34:56 UTC"
  },
  {
    "arxiv_id": "2402.10115v2",
    "title": "Generating Visual Stimuli from EEG Recordings using Transformer-encoder based EEG encoder and GAN",
    "authors": [
      "Rahul Mishra",
      "Arnav Bhavsar"
    ],
    "abstract": "In this study, we tackle a modern research challenge within the field of\nperceptual brain decoding, which revolves around synthesizing images from EEG\nsignals using an adversarial deep learning framework. The specific objective is\nto recreate images belonging to various object categories by leveraging EEG\nrecordings obtained while subjects view those images. To achieve this, we\nemploy a Transformer-encoder based EEG encoder to produce EEG encodings, which\nserve as inputs to the generator component of the GAN network. Alongside the\nadversarial loss, we also incorporate perceptual loss to enhance the quality of\nthe generated images.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10115v2",
    "published_date": "2024-02-15 17:10:27 UTC",
    "updated_date": "2024-11-20 05:35:03 UTC"
  },
  {
    "arxiv_id": "2402.10110v2",
    "title": "Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning",
    "authors": [
      "Ming Li",
      "Lichang Chen",
      "Jiuhai Chen",
      "Shwai He",
      "Jiuxiang Gu",
      "Tianyi Zhou"
    ],
    "abstract": "Instruction tuning is critical to large language models (LLMs) for achieving\nbetter instruction following and task adaptation capabilities but its success\nheavily relies on the training data quality. Many recent methods focus on\nimproving the data quality but often overlook the compatibility of the data\nwith the student model being finetuned. This paper introduces Selective\nReflection-Tuning, a novel paradigm that synergizes a teacher LLM's reflection\nand introspection for improving existing data quality with the data selection\ncapability of the student LLM, to automatically refine existing\ninstruction-tuning data. This teacher-student collaboration produces\nhigh-quality and student-compatible instruction-response pairs, resulting in\nsample-efficient instruction tuning and LLMs of superior performance. Selective\nReflection-Tuning is a data augmentation and synthesis that generally improves\nLLM finetuning and self-improvement without collecting brand-new data. We apply\nour method to Alpaca and WizardLM data and achieve much stronger and top-tier\n7B and 13B LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024 (findings), Camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2402.10110v2",
    "published_date": "2024-02-15 17:06:21 UTC",
    "updated_date": "2024-06-07 20:23:21 UTC"
  },
  {
    "arxiv_id": "2402.10109v2",
    "title": "Towards Reducing Diagnostic Errors with Interpretable Risk Prediction",
    "authors": [
      "Denis Jered McInerney",
      "William Dickinson",
      "Lucy C. Flynn",
      "Andrea C. Young",
      "Geoffrey S. Young",
      "Jan-Willem van de Meent",
      "Byron C. Wallace"
    ],
    "abstract": "Many diagnostic errors occur because clinicians cannot easily access relevant\ninformation in patient Electronic Health Records (EHRs). In this work we\npropose a method to use LLMs to identify pieces of evidence in patient EHR data\nthat indicate increased or decreased risk of specific diagnoses; our ultimate\naim is to increase access to evidence and reduce diagnostic errors. In\nparticular, we propose a Neural Additive Model to make predictions backed by\nevidence with individualized risk estimates at time-points where clinicians are\nstill uncertain, aiming to specifically mitigate delays in diagnosis and errors\nstemming from an incomplete differential. To train such a model, it is\nnecessary to infer temporally fine-grained retrospective labels of eventual\n\"true\" diagnoses. We do so with LLMs, to ensure that the input text is from\nbefore a confident diagnosis can be made. We use an LLM to retrieve an initial\npool of evidence, but then refine this set of evidence according to\ncorrelations learned by the model. We conduct an in-depth evaluation of the\nusefulness of our approach by simulating how it might be used by a clinician to\ndecide between a pre-defined list of differential diagnoses.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10109v2",
    "published_date": "2024-02-15 17:05:48 UTC",
    "updated_date": "2024-03-19 16:43:09 UTC"
  },
  {
    "arxiv_id": "2402.10107v1",
    "title": "Quantized Embedding Vectors for Controllable Diffusion Language Models",
    "authors": [
      "Cheng Kang",
      "Xinye Chen",
      "Yong Hu",
      "Daniel Novak"
    ],
    "abstract": "Improving the controllability, portability, and inference speed of diffusion\nlanguage models (DLMs) is a key challenge in natural language generation. While\nrecent research has shown significant success in complex text generation with\nlanguage models, the memory and computational power are still very demanding\nand fall short of expectations, which naturally results in low portability and\ninstability for the models. To mitigate these issues, numerous well-established\nmethods were proposed for neural network quantization. To further enhance their\nportability of independent deployment as well as improve their stability\nevaluated by language perplexity, we propose a novel approach called the\nQuantized Embedding Controllable Diffusion Language Model (QE-CDLM). QE-CDLM\nbuilds upon the recent successful controllable DLMs by remodeling the\ntask-specific embedding space via quantization. This leads to a gradient-based\ncontroller for the generation tasks, and more stable intermediate latent\nvariables are obtained, which naturally brings in an accelerated convergence as\nwell as better controllability. Additionally, the adaption fine-tuning method\nis employed to reduce tunable weights. Experimental results on five challenging\nfine-grained control tasks demonstrate that QE-CDLM compares favorably to\nexisting methods in terms of quality and feasibility, achieving better\nperplexity and lightweight fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10107v1",
    "published_date": "2024-02-15 17:02:48 UTC",
    "updated_date": "2024-02-15 17:02:48 UTC"
  },
  {
    "arxiv_id": "2402.10104v2",
    "title": "GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving",
    "authors": [
      "Jiaxin Zhang",
      "Zhongzhi Li",
      "Mingliang Zhang",
      "Fei Yin",
      "Chenglin Liu",
      "Yashar Moshfeghi"
    ],
    "abstract": "Recent advancements in large language models (LLMs) and multi-modal models\n(MMs) have demonstrated their remarkable capabilities in problem-solving. Yet,\ntheir proficiency in tackling geometry math problems, which necessitates an\nintegrated understanding of both textual and visual information, has not been\nthoroughly evaluated. To address this gap, we introduce the GeoEval benchmark,\na comprehensive collection that includes a main subset of 2,000 problems, a 750\nproblems subset focusing on backward reasoning, an augmented subset of 2,000\nproblems, and a hard subset of 300 problems. This benchmark facilitates a\ndeeper investigation into the performance of LLMs and MMs in solving geometry\nmath problems. Our evaluation of ten LLMs and MMs across these varied subsets\nreveals that the WizardMath model excels, achieving a 55.67\\% accuracy rate on\nthe main subset but only a 6.00\\% accuracy on the hard subset. This highlights\nthe critical need for testing models against datasets on which they have not\nbeen pre-trained. Additionally, our findings indicate that GPT-series models\nperform more effectively on problems they have rephrased, suggesting a\npromising method for enhancing model capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.10104v2",
    "published_date": "2024-02-15 16:59:41 UTC",
    "updated_date": "2024-05-17 11:42:09 UTC"
  },
  {
    "arxiv_id": "2402.10102v2",
    "title": "A privacy-preserving, distributed and cooperative FCM-based learning approach for cancer research",
    "authors": [
      "Jose L. Salmeron",
      "Irina Arévalo"
    ],
    "abstract": "Distributed Artificial Intelligence is attracting interest day by day. In\nthis paper, the authors introduce an innovative methodology for distributed\nlearning of Particle Swarm Optimization-based Fuzzy Cognitive Maps in a\nprivacy-preserving way. The authors design a training scheme for collaborative\nFCM learning that offers data privacy compliant with the current regulation.\nThis method is applied to a cancer detection problem, proving that the\nperformance of the model is improved by the Federated Learning process, and\nobtaining similar results to the ones that can be found in the literature.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "Rough Sets: International Joint Conference, IJCRS 2020",
    "pdf_url": "http://arxiv.org/pdf/2402.10102v2",
    "published_date": "2024-02-15 16:56:25 UTC",
    "updated_date": "2025-03-05 16:51:06 UTC"
  },
  {
    "arxiv_id": "2402.10093v4",
    "title": "MIM-Refiner: A Contrastive Learning Boost from Intermediate Pre-Trained Representations",
    "authors": [
      "Benedikt Alkin",
      "Lukas Miklautz",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "abstract": "We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learning\nboost for pre-trained MIM models. MIM-Refiner is motivated by the insight that\nstrong representations within MIM models generally reside in intermediate\nlayers. Accordingly, MIM-Refiner leverages multiple contrastive heads that are\nconnected to different intermediate layers. In each head, a modified nearest\nneighbor objective constructs semantic clusters that capture semantic\ninformation which improves performance on downstream tasks, including\noff-the-shelf and fine-tuning settings.\n  The refinement process is short and simple - yet highly effective. Within a\nfew epochs, we refine the features of MIM models from subpar to\nstate-of-the-art, off-the-shelf features. Refining a ViT-H, pre-trained with\ndata2vec 2.0 on ImageNet-1K, sets a new state-of-the-art in linear probing\n(84.7%) and low-shot classification among models that are pre-trained on\nImageNet-1K. MIM-Refiner efficiently combines the advantages of MIM and ID\nobjectives and compares favorably against previous state-of-the-art SSL models\non a variety of benchmarks such as low-shot classification, long-tailed\nclassification, clustering and semantic segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at ICLR 2025. Github:\n  https://github.com/ml-jku/MIM-Refiner",
    "pdf_url": "http://arxiv.org/pdf/2402.10093v4",
    "published_date": "2024-02-15 16:46:16 UTC",
    "updated_date": "2025-02-20 23:59:44 UTC"
  },
  {
    "arxiv_id": "2402.10083v1",
    "title": "Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4",
    "authors": [
      "Ting Fang Tan",
      "Kabilan Elangovan",
      "Liyuan Jin",
      "Yao Jie",
      "Li Yong",
      "Joshua Lim",
      "Stanley Poh",
      "Wei Yan Ng",
      "Daniel Lim",
      "Yuhe Ke",
      "Nan Liu",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Purpose: To assess the alignment of GPT-4-based evaluation to human clinician\nexperts, for the evaluation of responses to ophthalmology-related patient\nqueries generated by fine-tuned LLM chatbots. Methods: 400 ophthalmology\nquestions and paired answers were created by ophthalmologists to represent\ncommonly asked patient questions, divided into fine-tuning (368; 92%), and\ntesting (40; 8%). We find-tuned 5 different LLMs, including LLAMA2-7b,\nLLAMA2-7b-Chat, LLAMA2-13b, and LLAMA2-13b-Chat. For the testing dataset,\nadditional 8 glaucoma QnA pairs were included. 200 responses to the testing\ndataset were generated by 5 fine-tuned LLMs for evaluation. A customized\nclinical evaluation rubric was used to guide GPT-4 evaluation, grounded on\nclinical accuracy, relevance, patient safety, and ease of understanding. GPT-4\nevaluation was then compared against ranking by 5 clinicians for clinical\nalignment. Results: Among all fine-tuned LLMs, GPT-3.5 scored the highest\n(87.1%), followed by LLAMA2-13b (80.9%), LLAMA2-13b-chat (75.5%),\nLLAMA2-7b-Chat (70%) and LLAMA2-7b (68.8%) based on the GPT-4 evaluation. GPT-4\nevaluation demonstrated significant agreement with human clinician rankings,\nwith Spearman and Kendall Tau correlation coefficients of 0.90 and 0.80\nrespectively; while correlation based on Cohen Kappa was more modest at 0.50.\nNotably, qualitative analysis and the glaucoma sub-analysis revealed clinical\ninaccuracies in the LLM-generated responses, which were appropriately\nidentified by the GPT-4 evaluation. Conclusion: The notable clinical alignment\nof GPT-4 evaluation highlighted its potential to streamline the clinical\nevaluation of LLM chatbot responses to healthcare-related queries. By\ncomplementing the existing clinician-dependent manual grading, this efficient\nand automated evaluation could assist the validation of future developments in\nLLM applications for healthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 Pages, 1 Figure, 8 Tables",
    "pdf_url": "http://arxiv.org/pdf/2402.10083v1",
    "published_date": "2024-02-15 16:43:41 UTC",
    "updated_date": "2024-02-15 16:43:41 UTC"
  },
  {
    "arxiv_id": "2402.10076v1",
    "title": "QUICK: Quantization-aware Interleaving and Conflict-free Kernel for efficient LLM inference",
    "authors": [
      "Taesu Kim",
      "Jongho Lee",
      "Daehyun Ahn",
      "Sarang Kim",
      "Jiwoong Choi",
      "Minkyu Kim",
      "Hyungjun Kim"
    ],
    "abstract": "We introduce QUICK, a group of novel optimized CUDA kernels for the efficient\ninference of quantized Large Language Models (LLMs). QUICK addresses the shared\nmemory bank-conflict problem of state-of-the-art mixed precision matrix\nmultiplication kernels. Our method interleaves the quantized weight matrices of\nLLMs offline to skip the shared memory write-back after the dequantization. We\ndemonstrate up to 1.91x speedup over existing kernels of AutoAWQ on larger\nbatches and up to 1.94x throughput gain on representative LLM models on various\nNVIDIA GPU devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.10076v1",
    "published_date": "2024-02-15 16:38:41 UTC",
    "updated_date": "2024-02-15 16:38:41 UTC"
  },
  {
    "arxiv_id": "2402.10055v1",
    "title": "Robust semi-automatic vessel tracing in the human retinal image by an instance segmentation neural network",
    "authors": [
      "Siyi Chen",
      "Amir H. Kashani",
      "Ji Yi"
    ],
    "abstract": "The morphology and hierarchy of the vascular systems are essential for\nperfusion in supporting metabolism. In human retina, one of the most\nenergy-demanding organs, retinal circulation nourishes the entire inner retina\nby an intricate vasculature emerging and remerging at the optic nerve head\n(ONH). Thus, tracing the vascular branching from ONH through the vascular tree\ncan illustrate vascular hierarchy and allow detailed morphological\nquantification, and yet remains a challenging task. Here, we presented a novel\napproach for a robust semi-automatic vessel tracing algorithm on human fundus\nimages by an instance segmentation neural network (InSegNN). Distinct from\nsemantic segmentation, InSegNN separates and labels different vascular trees\nindividually and therefore enable tracing each tree throughout its branching.\nWe have built-in three strategies to improve robustness and accuracy with\ntemporal learning, spatial multi-sampling, and dynamic probability map. We\nachieved 83% specificity, and 50% improvement in Symmetric Best Dice (SBD)\ncompared to literature, and outperformed baseline U-net. We have demonstrated\ntracing individual vessel trees from fundus images, and simultaneously retain\nthe vessel hierarchy information. InSegNN paves a way for any subsequent\nmorphological analysis of vascular morphology in relation to retinal diseases.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10055v1",
    "published_date": "2024-02-15 16:25:28 UTC",
    "updated_date": "2024-02-15 16:25:28 UTC"
  },
  {
    "arxiv_id": "2402.10052v2",
    "title": "UNDIAL: Self-Distillation with Adjusted Logits for Robust Unlearning in Large Language Models",
    "authors": [
      "Yijiang River Dong",
      "Hongzhou Lin",
      "Mikhail Belkin",
      "Ramon Huerta",
      "Ivan Vulić"
    ],
    "abstract": "Mitigating the retention of sensitive or private information in large\nlanguage models is essential for enhancing privacy and safety. Existing\nunlearning methods, like Gradient Ascent and Negative Preference Optimization,\ndirectly tune models to remove unwanted information. However, these methods\noften become unstable because they fine-tune by maximizing cross-entropy loss,\nwhich is the opposite of traditional loss minimization in learning. This\nreversal creates instability, especially on larger datasets, as the model\nstruggles to balance unlearning with maintaining language capacity, leading to\nover-unlearning. In this paper, we introduce UnDIAL (Unlearning via\nSelf-Distillation on Adjusted Logits), a novel and robust unlearning method.\nOur approach leverages self-distillation to adjust logits and selectively\nreduce the influence of targeted tokens. This technique ensures smooth\nconvergence and avoids catastrophic forgetting, even in challenging unlearning\ntasks with large datasets and sequential unlearning requests. Extensive\nexperiments show that UnDIAL can achieve both robustness in unlearning and\nscalability while maintaining stable training dynamics and resilience to\nhyperparameter tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10052v2",
    "published_date": "2024-02-15 16:21:14 UTC",
    "updated_date": "2024-10-16 11:50:27 UTC"
  },
  {
    "arxiv_id": "2402.10051v1",
    "title": "SwissNYF: Tool Grounded LLM Agents for Black Box Setting",
    "authors": [
      "Somnath Sendhil Kumar",
      "Dhruv Jain",
      "Eshaan Agarwal",
      "Raunak Pandey"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated enhanced capabilities in\nfunction-calling, these advancements primarily rely on accessing the functions'\nresponses. This methodology is practical for simpler APIs but faces scalability\nissues with irreversible APIs that significantly impact the system, such as a\ndatabase deletion API. Similarly, processes requiring extensive time for each\nAPI call and those necessitating forward planning, like automated action\npipelines, present complex challenges. Furthermore, scenarios often arise where\na generalized approach is needed because algorithms lack direct access to the\nspecific implementations of these functions or secrets to use them. Traditional\ntool planning methods are inadequate in these cases, compelling the need to\noperate within black-box environments. Unlike their performance in tool\nmanipulation, LLMs excel in black-box tasks, such as program synthesis.\nTherefore, we harness the program synthesis capabilities of LLMs to strategize\ntool usage in black-box settings, ensuring solutions are verified prior to\nimplementation. We introduce TOPGUN, an ingeniously crafted approach leveraging\nprogram synthesis for black box tool planning. Accompanied by SwissNYF, a\ncomprehensive suite that integrates black-box algorithms for planning and\nverification tasks, addressing the aforementioned challenges and enhancing the\nversatility and effectiveness of LLMs in complex API interactions. The public\ncode for SwissNYF is available at https://github.com/iclr-dummy-user/SwissNYF.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10051v1",
    "published_date": "2024-02-15 16:15:38 UTC",
    "updated_date": "2024-02-15 16:15:38 UTC"
  },
  {
    "arxiv_id": "2402.10050v1",
    "title": "On-Demand Myoelectric Control Using Wake Gestures to Eliminate False Activations During Activities of Daily Living",
    "authors": [
      "Ethan Eddy",
      "Evan Campbell",
      "Scott Bateman",
      "Erik Scheme"
    ],
    "abstract": "While myoelectric control has recently become a focus of increased research\nas a possible flexible hands-free input modality, current control approaches\nare prone to inadvertent false activations in real-world conditions. In this\nwork, a novel myoelectric control paradigm -- on-demand myoelectric control --\nis proposed, designed, and evaluated, to reduce the number of unrelated muscle\nmovements that are incorrectly interpreted as input gestures . By leveraging\nthe concept of wake gestures, users were able to switch between a dedicated\ncontrol mode and a sleep mode, effectively eliminating inadvertent activations\nduring activities of daily living (ADLs). The feasibility of wake gestures was\ndemonstrated in this work through two online ubiquitous EMG control tasks with\nvarying difficulty levels; dismissing an alarm and controlling a robot. The\nproposed control scheme was able to appropriately ignore almost all\nnon-targeted muscular inputs during ADLs (>99.9%) while maintaining sufficient\nsensitivity for reliable mode switching during intentional wake gesture\nelicitation. These results highlight the potential of wake gestures as a\ncritical step towards enabling ubiquitous myoelectric control-based on-demand\ninput for a wide range of applications.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10050v1",
    "published_date": "2024-02-15 16:11:47 UTC",
    "updated_date": "2024-02-15 16:11:47 UTC"
  },
  {
    "arxiv_id": "2402.10251v6",
    "title": "BrainWave: A Brain Signal Foundation Model for Clinical Applications",
    "authors": [
      "Zhizhang Yuan",
      "Fanqi Shen",
      "Meng Li",
      "Yuguo Yu",
      "Chenhao Tan",
      "Yang Yang"
    ],
    "abstract": "Neural electrical activity is fundamental to brain function, underlying a\nrange of cognitive and behavioral processes, including movement, perception,\ndecision-making, and consciousness. Abnormal patterns of neural signaling often\nindicate the presence of underlying brain diseases. The variability among\nindividuals, the diverse array of clinical symptoms from various brain\ndisorders, and the limited availability of diagnostic classifications, have\nposed significant barriers to formulating reliable model of neural signals for\ndiverse application contexts. Here, we present BrainWave, the first foundation\nmodel for both invasive and non-invasive neural recordings, pretrained on more\nthan 40,000 hours of electrical brain recordings (13.79 TB of data) from\napproximately 16,000 individuals. Our analysis show that BrainWave outperforms\nall other competing models and consistently achieves state-of-the-art\nperformance in the diagnosis and identification of neurological disorders. We\nalso demonstrate robust capabilities of BrainWave in enabling zero-shot\ntransfer learning across varying recording conditions and brain diseases, as\nwell as few-shot classification without fine-tuning, suggesting that BrainWave\nlearns highly generalizable representations of neural signals. We hence believe\nthat open-sourcing BrainWave will facilitate a wide range of clinical\napplications in medicine, paving the way for AI-driven approaches to\ninvestigate brain disorders and advance neuroscience research.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "39 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.10251v6",
    "published_date": "2024-02-15 16:04:11 UTC",
    "updated_date": "2024-09-20 01:50:26 UTC"
  },
  {
    "arxiv_id": "2402.10038v2",
    "title": "RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models",
    "authors": [
      "Saeed Khaki",
      "JinJin Li",
      "Lan Ma",
      "Liu Yang",
      "Prathap Ramachandra"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has been extensively\nemployed to align large language models with user intent. However, proximal\npolicy optimization (PPO) based RLHF is occasionally unstable requiring\nsignificant hyperparameter finetuning, and computationally expensive to\nmaximize the estimated reward during alignment. Recently, direct preference\noptimization (DPO) is proposed to address those challenges. However, DPO relies\non contrastive responses generated from human annotator and alternative LLM,\ninstead of the policy model, limiting the effectiveness of the RLHF. In this\npaper, we addresses both challenges by systematically combining rejection\nsampling (RS) and DPO. Our proposed method, RS-DPO, initiates with the\ndevelopment of a supervised fine-tuned policy model (SFT). A varied set of k\nresponses per prompt are sampled directly from the SFT model. RS-DPO identifies\npairs of contrastive samples based on their reward distribution. Finally, we\napply DPO with the contrastive samples to align the model to human preference.\nOur experiments indicate that our proposed method effectively fine-tunes LLMs\nwith limited resource environments, leading to improved alignment with user\nintent. Furthermore, it outperforms existing methods, including RS, PPO, and\nDPO.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.10038v2",
    "published_date": "2024-02-15 16:00:58 UTC",
    "updated_date": "2024-03-30 16:10:47 UTC"
  },
  {
    "arxiv_id": "2402.10028v1",
    "title": "Diffusion Models Meet Contextual Bandits with Large Action Spaces",
    "authors": [
      "Imad Aouali"
    ],
    "abstract": "Efficient exploration is a key challenge in contextual bandits due to the\nlarge size of their action space, where uninformed exploration can result in\ncomputational and statistical inefficiencies. Fortunately, the rewards of\nactions are often correlated and this can be leveraged to explore them\nefficiently. In this work, we capture such correlations using pre-trained\ndiffusion models; upon which we design diffusion Thompson sampling (dTS). Both\ntheoretical and algorithmic foundations are developed for dTS, and empirical\nevaluation also shows its favorable performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.10028v1",
    "published_date": "2024-02-15 15:48:55 UTC",
    "updated_date": "2024-02-15 15:48:55 UTC"
  },
  {
    "arxiv_id": "2402.10024v2",
    "title": "Self-Augmented In-Context Learning for Unsupervised Word Translation",
    "authors": [
      "Yaoyiran Li",
      "Anna Korhonen",
      "Ivan Vulić"
    ],
    "abstract": "Recent work has shown that, while large language models (LLMs) demonstrate\nstrong word translation or bilingual lexicon induction (BLI) capabilities in\nfew-shot setups, they still cannot match the performance of 'traditional'\nmapping-based approaches in the unsupervised scenario where no seed translation\npairs are available, especially for lower-resource languages. To address this\nchallenge with LLMs, we propose self-augmented in-context learning (SAIL) for\nunsupervised BLI: starting from a zero-shot prompt, SAIL iteratively induces a\nset of high-confidence word translation pairs for in-context learning (ICL)\nfrom an LLM, which it then reapplies to the same LLM in the ICL fashion. Our\nmethod shows substantial gains over zero-shot prompting of LLMs on two\nestablished BLI benchmarks spanning a wide range of language pairs, also\noutperforming mapping-based baselines across the board. In addition to\nachieving state-of-the-art unsupervised BLI performance, we also conduct\ncomprehensive analyses on SAIL and discuss its limitations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Main Conference; 11 Pages, 3 Figures, 9 Tables",
    "pdf_url": "http://arxiv.org/pdf/2402.10024v2",
    "published_date": "2024-02-15 15:43:05 UTC",
    "updated_date": "2024-06-05 13:38:42 UTC"
  },
  {
    "arxiv_id": "2402.10011v3",
    "title": "Clifford Group Equivariant Simplicial Message Passing Networks",
    "authors": [
      "Cong Liu",
      "David Ruhe",
      "Floor Eijkelboom",
      "Patrick Forré"
    ],
    "abstract": "We introduce Clifford Group Equivariant Simplicial Message Passing Networks,\na method for steerable E(n)-equivariant message passing on simplicial\ncomplexes. Our method integrates the expressivity of Clifford group-equivariant\nlayers with simplicial message passing, which is topologically more intricate\nthan regular graph message passing. Clifford algebras include higher-order\nobjects such as bivectors and trivectors, which express geometric features\n(e.g., areas, volumes) derived from vectors. Using this knowledge, we represent\nsimplex features through geometric products of their vertices. To achieve\nefficient simplicial message passing, we share the parameters of the message\nnetwork across different dimensions. Additionally, we restrict the final\nmessage to an aggregation of the incoming messages from different dimensions,\nleading to what we term shared simplicial message passing. Experimental results\nshow that our method is able to outperform both equivariant and simplicial\ngraph neural networks on a variety of geometric tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10011v3",
    "published_date": "2024-02-15 15:18:53 UTC",
    "updated_date": "2024-03-12 12:38:09 UTC"
  },
  {
    "arxiv_id": "2402.10002v3",
    "title": "MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding",
    "authors": [
      "Hai-Tao Yu",
      "Mofei Song"
    ],
    "abstract": "In perception, multiple sensory information is integrated to map visual\ninformation from 2D views onto 3D objects, which is beneficial for\nunderstanding in 3D environments. But in terms of a single 2D view rendered\nfrom different angles, only limited partial information can be provided.The\nrichness and value of Multi-view 2D information can provide superior\nself-supervised signals for 3D objects. In this paper, we propose a novel\nself-supervised point cloud representation learning method, MM-Point, which is\ndriven by intra-modal and inter-modal similarity objectives. The core of\nMM-Point lies in the Multi-modal interaction and transmission between 3D\nobjects and multiple 2D views at the same time. In order to more effectively\nsimultaneously perform the consistent cross-modal objective of 2D multi-view\ninformation based on contrastive learning, we further propose Multi-MLP and\nMulti-level Augmentation strategies. Through carefully designed transformation\nstrategies, we further learn Multi-level invariance in 2D Multi-views. MM-Point\ndemonstrates state-of-the-art (SOTA) performance in various downstream tasks.\nFor instance, it achieves a peak accuracy of 92.4% on the synthetic dataset\nModelNet40, and a top accuracy of 87.8% on the real-world dataset ScanObjectNN,\ncomparable to fully supervised methods. Additionally, we demonstrate its\neffectiveness in tasks such as few-shot classification, 3D part segmentation\nand 3D semantic segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.10002v3",
    "published_date": "2024-02-15 15:10:17 UTC",
    "updated_date": "2024-02-25 07:58:07 UTC"
  },
  {
    "arxiv_id": "2402.09997v1",
    "title": "LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild",
    "authors": [
      "Ziyu Zhao",
      "Leilei Gan",
      "Guoyin Wang",
      "Wangchunshu Zhou",
      "Hongxia Yang",
      "Kun Kuang",
      "Fei Wu"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) provides an effective yet efficient solution for\nfine-tuning large language models (LLM). The modular and plug-and-play nature\nof LoRA enables the integration of diverse domain-specific LoRAs to enhance the\ncapabilities of LLMs. Previous research on exploiting multiple LoRAs either\nfocuses on specific isolated downstream tasks or fixes the selection of LoRAs\nduring training. However, in real-world scenarios, LLMs receive diverse prompts\ncovering different tasks, and the pool of candidate LoRAs is often dynamically\nupdated. To bridge this gap, we propose LoraRetriever, a retrieve-then-compose\nframework that adaptively retrieves and composes multiple LoRAs according to\nthe input prompts. LoraRetriever contains three main components: firstly,\nidentifying and retrieving LoRAs relevant to the given input; secondly,\nformulating strategies for effectively integrating the retrieved LoRAs; and\nthirdly, developing efficient batch inference to accommodate heterogeneous\nrequests. Experimental results indicate that LoraRetriever consistently\noutperforms the baselines, highlighting its practical effectiveness and\nversatility.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09997v1",
    "published_date": "2024-02-15 15:02:46 UTC",
    "updated_date": "2024-02-15 15:02:46 UTC"
  },
  {
    "arxiv_id": "2402.09984v2",
    "title": "Symmetry-Breaking Augmentations for Ad Hoc Teamwork",
    "authors": [
      "Ravi Hammond",
      "Dustin Craggs",
      "Mingyu Guo",
      "Jakob Foerster",
      "Ian Reid"
    ],
    "abstract": "In dynamic collaborative settings, for artificial intelligence (AI) agents to\nbetter align with humans, they must adapt to novel teammates who utilise\nunforeseen strategies. While adaptation is often simple for humans, it can be\nchallenging for AI agents. Our work introduces symmetry-breaking augmentations\n(SBA) as a novel approach to this challenge. By applying a symmetry-flipping\noperation to increase behavioural diversity among training teammates, SBA\nencourages agents to learn robust responses to unknown strategies, highlighting\nhow social conventions impact human-AI alignment. We demonstrate this\nexperimentally in two settings, showing that our approach outperforms previous\nad hoc teamwork results in the challenging card game Hanabi. In addition, we\npropose a general metric for estimating symmetry dependency amongst a given set\nof policies. Our findings provide insights into how AI systems can better adapt\nto diverse human conventions and the core mechanics of alignment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 12 figures, Bidirectional Human-AI Alignment workshop, ICLR\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2402.09984v2",
    "published_date": "2024-02-15 14:49:28 UTC",
    "updated_date": "2025-04-19 14:12:05 UTC"
  },
  {
    "arxiv_id": "2402.09982v1",
    "title": "Data Augmentation and Transfer Learning Approaches Applied to Facial Expressions Recognition",
    "authors": [
      "Enrico Randellini",
      "Leonardo Rigutini",
      "Claudio Sacca'"
    ],
    "abstract": "The face expression is the first thing we pay attention to when we want to\nunderstand a person's state of mind. Thus, the ability to recognize facial\nexpressions in an automatic way is a very interesting research field. In this\npaper, because the small size of available training datasets, we propose a\nnovel data augmentation technique that improves the performances in the\nrecognition task. We apply geometrical transformations and build from scratch\nGAN models able to generate new synthetic images for each emotion type. Thus,\non the augmented datasets we fine tune pretrained convolutional neural networks\nwith different architectures. To measure the generalization ability of the\nmodels, we apply extra-database protocol approach, namely we train models on\nthe augmented versions of training dataset and test them on two different\ndatabases. The combination of these techniques allows to reach average accuracy\nvalues of the order of 85\\% for the InceptionResNetV2 model.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The 11th International Conference on Artificial Intelligence, Soft\n  Computing and Applications (AIAA 2021)",
    "pdf_url": "http://arxiv.org/pdf/2402.09982v1",
    "published_date": "2024-02-15 14:46:03 UTC",
    "updated_date": "2024-02-15 14:46:03 UTC"
  },
  {
    "arxiv_id": "2402.09977v1",
    "title": "Fast Vocabulary Transfer for Language Model Compression",
    "authors": [
      "Leonidas Gee",
      "Andrea Zugarini",
      "Leonardo Rigutini",
      "Paolo Torroni"
    ],
    "abstract": "Real-world business applications require a trade-off between language model\nperformance and size. We propose a new method for model compression that relies\non vocabulary transfer. We evaluate the method on various vertical domains and\ndownstream tasks. Our results indicate that vocabulary transfer can be\neffectively used in combination with other compression techniques, yielding a\nsignificant reduction in model size and inference time while marginally\ncompromising on performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The 2022 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2022)",
    "pdf_url": "http://arxiv.org/pdf/2402.09977v1",
    "published_date": "2024-02-15 14:37:07 UTC",
    "updated_date": "2024-02-15 14:37:07 UTC"
  },
  {
    "arxiv_id": "2402.09941v1",
    "title": "FedLion: Faster Adaptive Federated Optimization with Fewer Communication",
    "authors": [
      "Zhiwei Tang",
      "Tsung-Hui Chang"
    ],
    "abstract": "In Federated Learning (FL), a framework to train machine learning models\nacross distributed data, well-known algorithms like FedAvg tend to have slow\nconvergence rates, resulting in high communication costs during training. To\naddress this challenge, we introduce FedLion, an adaptive federated\noptimization algorithm that seamlessly incorporates key elements from the\nrecently proposed centralized adaptive algorithm, Lion (Chen et al. 2o23), into\nthe FL framework. Through comprehensive evaluations on two widely adopted FL\nbenchmarks, we demonstrate that FedLion outperforms previous state-of-the-art\nadaptive algorithms, including FAFED (Wu et al. 2023) and FedDA. Moreover,\nthanks to the use of signed gradients in local training, FedLion substantially\nreduces data transmission requirements during uplink communication when\ncompared to existing adaptive algorithms, further reducing communication costs.\nLast but not least, this work also includes a novel theoretical analysis,\nshowcasing that FedLion attains faster convergence rate than established FL\nalgorithms like FedAvg.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09941v1",
    "published_date": "2024-02-15 13:41:23 UTC",
    "updated_date": "2024-02-15 13:41:23 UTC"
  },
  {
    "arxiv_id": "2402.09939v1",
    "title": "Generative AI in the Construction Industry: A State-of-the-art Analysis",
    "authors": [
      "Ridwan Taiwo",
      "Idris Temitope Bello",
      "Sulemana Fatoama Abdulai",
      "Abdul-Mugis Yussif",
      "Babatunde Abiodun Salami",
      "Abdullahi Saka",
      "Tarek Zayed"
    ],
    "abstract": "The construction industry is a vital sector of the global economy, but it\nfaces many productivity challenges in various processes, such as design,\nplanning, procurement, inspection, and maintenance. Generative artificial\nintelligence (AI), which can create novel and realistic data or content, such\nas text, image, video, or code, based on some input or prior knowledge, offers\ninnovative and disruptive solutions to address these challenges. However, there\nis a gap in the literature on the current state, opportunities, and challenges\nof generative AI in the construction industry. This study aims to fill this gap\nby providing a state-of-the-art analysis of generative AI in construction, with\nthree objectives: (1) to review and categorize the existing and emerging\ngenerative AI opportunities and challenges in the construction industry; (2) to\npropose a framework for construction firms to build customized generative AI\nsolutions using their own data, comprising steps such as data collection,\ndataset curation, training custom large language model (LLM), model evaluation,\nand deployment; and (3) to demonstrate the framework via a case study of\ndeveloping a generative model for querying contract documents. The results show\nthat retrieval augmented generation (RAG) improves the baseline LLM by 5.2,\n9.4, and 4.8% in terms of quality, relevance, and reproducibility. This study\nprovides academics and construction professionals with a comprehensive analysis\nand practical framework to guide the adoption of generative AI techniques to\nenhance productivity, quality, safety, and sustainability across the\nconstruction industry.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "74 pages, 11 figures, 20 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.09939v1",
    "published_date": "2024-02-15 13:39:55 UTC",
    "updated_date": "2024-02-15 13:39:55 UTC"
  },
  {
    "arxiv_id": "2402.09934v2",
    "title": "Paying Attention to Deflections: Mining Pragmatic Nuances for Whataboutism Detection in Online Discourse",
    "authors": [
      "Khiem Phi",
      "Noushin Salek Faramarzi",
      "Chenlu Wang",
      "Ritwik Banerjee"
    ],
    "abstract": "Whataboutism, a potent tool for disrupting narratives and sowing distrust,\nremains under-explored in quantitative NLP research. Moreover, past work has\nnot distinguished its use as a strategy for misinformation and propaganda from\nits use as a tool for pragmatic and semantic framing. We introduce new datasets\nfrom Twitter and YouTube, revealing overlaps as well as distinctions between\nwhataboutism, propaganda, and the tu quoque fallacy. Furthermore, drawing on\nrecent work in linguistic semantics, we differentiate the `what about' lexical\nconstruct from whataboutism. Our experiments bring to light unique challenges\nin its accurate detection, prompting the introduction of a novel method using\nattention weights for negative sample mining. We report significant\nimprovements of 4% and 10% over previous state-of-the-art methods in our\nTwitter and YouTube collections, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09934v2",
    "published_date": "2024-02-15 13:34:19 UTC",
    "updated_date": "2024-09-22 22:22:27 UTC"
  },
  {
    "arxiv_id": "2402.09923v1",
    "title": "A Dataset of Open-Domain Question Answering with Multiple-Span Answers",
    "authors": [
      "Zhiyi Luo",
      "Yingying Zhang",
      "Shuyun Luo",
      "Ying Zhao",
      "Wentao Lyu"
    ],
    "abstract": "Multi-span answer extraction, also known as the task of multi-span question\nanswering (MSQA), is critical for real-world applications, as it requires\nextracting multiple pieces of information from a text to answer complex\nquestions. Despite the active studies and rapid progress in English MSQA\nresearch, there is a notable lack of publicly available MSQA benchmark in\nChinese. Previous efforts for constructing MSQA datasets predominantly\nemphasized entity-centric contextualization, resulting in a bias towards\ncollecting factoid questions and potentially overlooking questions requiring\nmore detailed descriptive responses. To overcome these limitations, we present\nCLEAN, a comprehensive Chinese multi-span question answering dataset that\ninvolves a wide range of open-domain subjects with a substantial number of\ninstances requiring descriptive answers. Additionally, we provide established\nmodels from relevant literature as baselines for CLEAN. Experimental results\nand analysis show the characteristics and challenge of the newly proposed CLEAN\ndataset for the community. Our dataset, CLEAN, will be publicly released at\nzhiyiluo.site/misc/clean_v1.0_ sample.json.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09923v1",
    "published_date": "2024-02-15 13:03:57 UTC",
    "updated_date": "2024-02-15 13:03:57 UTC"
  },
  {
    "arxiv_id": "2402.09921v1",
    "title": "Identifying and modelling cognitive biases in mobility choices",
    "authors": [
      "Chloe Conrad",
      "Carole Adam"
    ],
    "abstract": "This report presents results from an M1 internship dedicated to agent-based\nmodelling and simulation of daily mobility choices. This simulation is intended\nto be realistic enough to serve as a basis for a serious game about the\nmobility transition. In order to ensure this level of realism, we conducted a\nsurvey to measure if real mobility choices are made rationally, or how biased\nthey are. Results analysed here show that various biases could play a role in\ndecisions. We then propose an implementation in a GAMA agent-based simulation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MA",
      "K.4.2"
    ],
    "primary_category": "cs.CY",
    "comment": "M1 internship report from Univ. Lyon 1 Claude Bernard. Internship was\n  from October 2022 to June 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.09921v1",
    "published_date": "2024-02-15 12:58:27 UTC",
    "updated_date": "2024-02-15 12:58:27 UTC"
  },
  {
    "arxiv_id": "2402.09919v3",
    "title": "Road Graph Generator: Mapping roads at construction sites from GPS data",
    "authors": [
      "Katarzyna Michałowska",
      "Helga Margrete Bodahl Holmestad",
      "Signe Riemer-Sørensen"
    ],
    "abstract": "We propose a new method for inferring roads from GPS trajectories to map\nconstruction sites. This task presents a unique challenge due to the erratic\nand non-standard movement patterns of construction machinery, which\nsignificantly diverge from typical vehicular traffic on established roads. Our\nproposed method first identifies intersections in the road network that serve\nas critical decision points, and then connects them with edges to produce a\ngraph, which can subsequently be used for planning and task-allocation. We\ndemonstrate the approach by mapping roads at a real-life construction site in\nNorway. The method is validated on four increasingly complex segments of the\nmap. In our tests, the method achieved perfect accuracy in detecting\nintersections and inferring roads in data with no or low noise, while its\nperformance was reduced in areas with significant noise and consistently\nmissing GPS updates.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 4 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.09919v3",
    "published_date": "2024-02-15 12:53:25 UTC",
    "updated_date": "2024-10-08 18:36:43 UTC"
  },
  {
    "arxiv_id": "2402.09911v2",
    "title": "Enhancing Large Language Models with Pseudo- and Multisource- Knowledge Graphs for Open-ended Question Answering",
    "authors": [
      "Jiaxiang Liu",
      "Tong Zhou",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Mitigating the hallucinations of Large Language Models is a crucial task.\nAlthough some existing methods employ self-enhancement techniques, they fall\nshort of effectively addressing unknown factual hallucinations. Meanwhile,\nKnowledge Graph (KG) enhancement approaches fail to address the generalization\nacross different KG sources and the enhancement of open-ended answer questions\nsimultaneously. To tackle these limitations, we propose a framework that\ncombines Pseudo-Graph Generation and Atomic Knowledge Verification (PG\\&AKV).\nEnhancement of open-ended question-answering begins with leveraging the\nPseudo-Graph Generation to provide the related knowledge framework.\nSubsequently, Atomic Knowledge Verification utilizes atomic-level knowledge\nquerying and verification to achieve generalizability under different KG\nsources. Compared to the baseline, this approach yields a minimum improvement\nof 11.5 in the ROUGE-L score for open-ended questions. For precise-answered\nquestions, we observe a minimum accuracy improvement of 7.5%. Moreover, PG\\&AKV\nalso exhibits generalizability across different KG sources. Utilizing KG\ndifferent from the question sources, PG\\&AKV can even achieve at least a 3.5 %\nperformance improvement. In summary, our results pave the way for enhancing\nLLMs by incorporating Pseudo- and Multisource-KGs, particularly in the filed of\nopen-ended questions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09911v2",
    "published_date": "2024-02-15 12:20:02 UTC",
    "updated_date": "2025-03-03 09:21:11 UTC"
  },
  {
    "arxiv_id": "2402.09906v3",
    "title": "Generative Representational Instruction Tuning",
    "authors": [
      "Niklas Muennighoff",
      "Hongjin Su",
      "Liang Wang",
      "Nan Yang",
      "Furu Wei",
      "Tao Yu",
      "Amanpreet Singh",
      "Douwe Kiela"
    ],
    "abstract": "All text-based language problems can be reduced to either generation or\nembedding. Current models only perform well at one or the other. We introduce\ngenerative representational instruction tuning (GRIT) whereby a large language\nmodel is trained to handle both generative and embedding tasks by\ndistinguishing between them through instructions. Compared to other open\nmodels, our resulting GritLM 7B sets a new state of the art on the Massive Text\nEmbedding Benchmark (MTEB) and outperforms all models up to its size on a range\nof generative tasks. By scaling up further, GritLM 8x7B outperforms all open\ngenerative language models that we tried while still being among the best\nembedding models. Notably, we find that GRIT matches training on only\ngenerative or embedding data, thus we can unify both at no performance loss.\nAmong other benefits, the unification via GRIT speeds up Retrieval-Augmented\nGeneration (RAG) by > 60% for long documents, by no longer requiring separate\nretrieval and generation models. Models, code, etc. are freely available at\nhttps://github.com/ContextualAI/gritlm.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "67 pages (16 main), 25 figures, 34 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.09906v3",
    "published_date": "2024-02-15 12:12:19 UTC",
    "updated_date": "2025-03-03 04:28:49 UTC"
  },
  {
    "arxiv_id": "2402.09900v3",
    "title": "Recurrent Reinforcement Learning with Memoroids",
    "authors": [
      "Steven Morad",
      "Chris Lu",
      "Ryan Kortvelesy",
      "Stephan Liwicki",
      "Jakob Foerster",
      "Amanda Prorok"
    ],
    "abstract": "Memory models such as Recurrent Neural Networks (RNNs) and Transformers\naddress Partially Observable Markov Decision Processes (POMDPs) by mapping\ntrajectories to latent Markov states. Neither model scales particularly well to\nlong sequences, especially compared to an emerging class of memory models\ncalled Linear Recurrent Models. We discover that the recurrent update of these\nmodels resembles a monoid, leading us to reformulate existing models using a\nnovel monoid-based framework that we call memoroids. We revisit the traditional\napproach to batching in recurrent reinforcement learning, highlighting\ntheoretical and empirical deficiencies. We leverage memoroids to propose a\nbatching method that improves sample efficiency, increases the return, and\nsimplifies the implementation of recurrent loss functions in reinforcement\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09900v3",
    "published_date": "2024-02-15 11:56:53 UTC",
    "updated_date": "2024-10-28 05:15:15 UTC"
  },
  {
    "arxiv_id": "2402.09894v2",
    "title": "Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow",
    "authors": [
      "Tao Long",
      "Katy Ilonka Gero",
      "Lydia B. Chilton"
    ],
    "abstract": "Generative AI brings novel and impressive abilities to help people in\neveryday tasks. There are many AI workflows that solve real and complex\nproblems by chaining AI outputs together with human interaction. Although there\nis an undeniable lure of AI, it is uncertain how useful generative AI workflows\nare after the novelty wears off. Additionally, workflows built with generative\nAI have the potential to be easily customized to fit users' individual needs,\nbut do users take advantage of this? We conducted a three-week longitudinal\nstudy with 12 users to understand the familiarization and customization of\ngenerative AI tools for science communication. Our study revealed that there\nexists a familiarization phase, during which users were exploring the novel\ncapabilities of the workflow and discovering which aspects they found useful.\nAfter this phase, users understood the workflow and were able to anticipate the\noutputs. Surprisingly, after familiarization the perceived utility of the\nsystem was rated higher than before, indicating that the perceived utility of\nAI is not just a novelty effect. The increase in benefits mainly comes from\nend-users' ability to customize prompts, and thus potentially appropriate the\nsystem to their own needs. This points to a future where generative AI systems\ncan allow us to design for appropriation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "22 pages, 16 figures. ACM Conference on Designing Interactive Systems\n  (DIS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.09894v2",
    "published_date": "2024-02-15 11:39:11 UTC",
    "updated_date": "2024-05-31 16:00:05 UTC"
  },
  {
    "arxiv_id": "2402.09883v1",
    "title": "Lester: rotoscope animation through video object segmentation and tracking",
    "authors": [
      "Ruben Tous"
    ],
    "abstract": "This article introduces Lester, a novel method to automatically synthetise\nretro-style 2D animations from videos. The method approaches the challenge\nmainly as an object segmentation and tracking problem. Video frames are\nprocessed with the Segment Anything Model (SAM) and the resulting masks are\ntracked through subsequent frames with DeAOT, a method of hierarchical\npropagation for semi-supervised video object segmentation. The geometry of the\nmasks' contours is simplified with the Douglas-Peucker algorithm. Finally,\nfacial traits, pixelation and a basic shadow effect can be optionally added.\nThe results show that the method exhibits an excellent temporal consistency and\ncan correctly process videos with different poses and appearances, dynamic\nshots, partial shots and diverse backgrounds. The proposed method provides a\nmore simple and deterministic approach than diffusion models based\nvideo-to-video translation pipelines, which suffer from temporal consistency\nproblems and do not cope well with pixelated and schematic outputs. The method\nis also much most practical than techniques based on 3D human pose estimation,\nwhich require custom handcrafted 3D models and are very limited with respect to\nthe type of scenes they can process.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09883v1",
    "published_date": "2024-02-15 11:15:54 UTC",
    "updated_date": "2024-02-15 11:15:54 UTC"
  },
  {
    "arxiv_id": "2402.10248v1",
    "title": "A Data-Driven Supervised Machine Learning Approach to Estimating Global Ambient Air Pollution Concentrations With Associated Prediction Intervals",
    "authors": [
      "Liam J Berrisford",
      "Hugo Barbosa",
      "Ronaldo Menezes"
    ],
    "abstract": "Global ambient air pollution, a transboundary challenge, is typically\naddressed through interventions relying on data from spatially sparse and\nheterogeneously placed monitoring stations. These stations often encounter\ntemporal data gaps due to issues such as power outages. In response, we have\ndeveloped a scalable, data-driven, supervised machine learning framework. This\nmodel is designed to impute missing temporal and spatial measurements, thereby\ngenerating a comprehensive dataset for pollutants including NO$_2$, O$_3$,\nPM$_{10}$, PM$_{2.5}$, and SO$_2$. The dataset, with a fine granularity of\n0.25$^{\\circ}$ at hourly intervals and accompanied by prediction intervals for\neach estimate, caters to a wide range of stakeholders relying on outdoor air\npollution data for downstream assessments. This enables more detailed studies.\nAdditionally, the model's performance across various geographical locations is\nexamined, providing insights and recommendations for strategic placement of\nfuture monitoring stations to further enhance the model's accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Main Paper: 25 pages, 15 figures, 5 tables. Supplementary: 4 pages, 3\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2402.10248v1",
    "published_date": "2024-02-15 11:09:22 UTC",
    "updated_date": "2024-02-15 11:09:22 UTC"
  },
  {
    "arxiv_id": "2402.09880v2",
    "title": "Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence",
    "authors": [
      "Timothy R. McIntosh",
      "Teo Susnjak",
      "Nalin Arachchilage",
      "Tong Liu",
      "Paul Watters",
      "Malka N. Halgamuge"
    ],
    "abstract": "The rapid rise in popularity of Large Language Models (LLMs) with emerging\ncapabilities has spurred public curiosity to evaluate and compare different\nLLMs, leading many researchers to propose their own LLM benchmarks. Noticing\npreliminary inadequacies in those benchmarks, we embarked on a study to\ncritically assess 23 state-of-the-art LLM benchmarks, using our novel unified\nevaluation framework through the lenses of people, process, and technology,\nunder the pillars of benchmark functionality and integrity. Our research\nuncovered significant limitations, including biases, difficulties in measuring\ngenuine reasoning, adaptability, implementation inconsistencies, prompt\nengineering complexity, evaluator diversity, and the overlooking of cultural\nand ideological norms in one comprehensive assessment. Our discussions\nemphasized the urgent need for standardized methodologies, regulatory\ncertainties, and ethical guidelines in light of Artificial Intelligence (AI)\nadvancements, including advocating for an evolution from static benchmarks to\ndynamic behavioral profiling to accurately capture LLMs' complex behaviors and\npotential risks. Our study highlighted the necessity for a paradigm shift in\nLLM evaluation methodologies, underlining the importance of collaborative\nefforts for the development of universally accepted benchmarks and the\nenhancement of AI systems' integration into society.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09880v2",
    "published_date": "2024-02-15 11:08:10 UTC",
    "updated_date": "2024-10-14 02:11:29 UTC"
  },
  {
    "arxiv_id": "2402.09877v3",
    "title": "On Computing Plans with Uniform Action Costs",
    "authors": [
      "Alberto Pozanco",
      "Daniel Borrajo",
      "Manuela Veloso"
    ],
    "abstract": "In many real-world planning applications, agents might be interested in\nfinding plans whose actions have costs that are as uniform as possible. Such\nplans provide agents with a sense of stability and predictability, which are\nkey features when humans are the agents executing plans suggested by planning\ntools. This paper adapts three uniformity metrics to automated planning, and\nintroduce planning-based compilations that allow to lexicographically optimize\nsum of action costs and action costs uniformity. Experimental results both in\nwell-known and novel planning benchmarks show that the reformulated tasks can\nbe effectively solved in practice to generate uniform plans.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09877v3",
    "published_date": "2024-02-15 11:00:28 UTC",
    "updated_date": "2024-05-24 09:19:23 UTC"
  },
  {
    "arxiv_id": "2402.09871v4",
    "title": "MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music",
    "authors": [
      "Zihao Wang",
      "Shuyu Li",
      "Tao Zhang",
      "Qi Wang",
      "Pengfei Yu",
      "Jinyang Luo",
      "Yan Liu",
      "Ming Xi",
      "Kejun Zhang"
    ],
    "abstract": "The rapidly evolving multimodal Large Language Models (LLMs) urgently require\nnew benchmarks to uniformly evaluate their performance on understanding and\ntextually describing music. However, due to semantic gaps between Music\nInformation Retrieval (MIR) algorithms and human understanding, discrepancies\nbetween professionals and the public, and low precision of annotations,\nexisting music description datasets cannot serve as benchmarks. To this end, we\npresent MuChin, the first open-source music description benchmark in Chinese\ncolloquial language, designed to evaluate the performance of multimodal LLMs in\nunderstanding and describing music. We established the Caichong Music\nAnnotation Platform (CaiMAP) that employs an innovative multi-person,\nmulti-stage assurance method, and recruited both amateurs and professionals to\nensure the precision of annotations and alignment with popular semantics.\nUtilizing this method, we built a dataset with multi-dimensional,\nhigh-precision music annotations, the Caichong Music Dataset (CaiMD), and\ncarefully selected 1,000 high-quality entries to serve as the test set for\nMuChin. Based on MuChin, we analyzed the discrepancies between professionals\nand amateurs in terms of music description, and empirically demonstrated the\neffectiveness of annotated data for fine-tuning LLMs. Ultimately, we employed\nMuChin to evaluate existing music understanding models on their ability to\nprovide colloquial descriptions of music. All data related to the benchmark,\nalong with the scoring code and detailed appendices, have been open-sourced\n(https://github.com/CarlWangChina/MuChin/).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS",
      "68Txx(Primary)14F05, 91Fxx(Secondary)",
      "I.2.7; J.5"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by International Joint Conference on Artificial Intelligence\n  2024 (IJCAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.09871v4",
    "published_date": "2024-02-15 10:55:01 UTC",
    "updated_date": "2024-06-13 13:36:28 UTC"
  },
  {
    "arxiv_id": "2402.09867v1",
    "title": "Characterizing Accuracy Trade-offs of EEG Applications on Embedded HMPs",
    "authors": [
      "Zain Taufique",
      "Muhammad Awais Bin Altaf",
      "Antonio Miele",
      "Pasi Liljeberg",
      "Anil Kanduri"
    ],
    "abstract": "Electroencephalography (EEG) recordings are analyzed using battery-powered\nwearable devices to monitor brain activities and neurological disorders. These\napplications require long and continuous processing to generate feasible\nresults. However, wearable devices are constrained with limited energy and\ncomputation resources, owing to their small sizes for practical use cases.\nEmbedded heterogeneous multi-core platforms (HMPs) can provide better\nperformance within limited energy budgets for EEG applications. Error\nresilience of the EEG application pipeline can be exploited further to maximize\nthe performance and energy gains with HMPs. However, disciplined tuning of\napproximation on embedded HMPs requires a thorough exploration of the\naccuracy-performance-power trade-off space. In this work, we characterize the\nerror resilience of three EEG applications, including Epileptic Seizure\nDetection, Sleep Stage Classification, and Stress Detection on the real-world\nembedded HMP test-bed of the Odroid XU3 platform. We present a combinatorial\nevaluation of power-performance-accuracy trade-offs of EEG applications at\ndifferent approximation, power, and performance levels to provide insights into\nthe disciplined tuning of approximation in EEG applications on embedded\nplatforms.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "eess.SP",
    "comment": "7 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09867v1",
    "published_date": "2024-02-15 10:50:42 UTC",
    "updated_date": "2024-02-15 10:50:42 UTC"
  },
  {
    "arxiv_id": "2402.09844v3",
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "authors": [
      "Quentin Gallouédec",
      "Edward Beeching",
      "Clément Romac",
      "Emmanuel Dellandréa"
    ],
    "abstract": "The search for a general model that can operate seamlessly across multiple\ndomains remains a key goal in machine learning research. The prevailing\nmethodology in Reinforcement Learning (RL) typically limits models to a single\ntask within a unimodal framework, a limitation that contrasts with the broader\nvision of a versatile, multi-domain model. In this paper, we present Jack of\nAll Trades (JAT), a transformer-based model with a unique design optimized for\nhandling sequential decision-making tasks and multi-modal data types. The JAT\nmodel demonstrates its robust capabilities and versatility by achieving strong\nperformance on very different RL benchmarks, along with promising results on\nComputer Vision (CV) and Natural Language Processing (NLP) tasks, all using a\nsingle set of weights. The JAT model marks a significant step towards more\ngeneral, cross-domain AI model design, and notably, it is the first model of\nits kind to be fully open-sourced at https://huggingface.co/jat-project/jat,\nincluding a pioneering general-purpose dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09844v3",
    "published_date": "2024-02-15 10:01:55 UTC",
    "updated_date": "2024-07-10 15:56:14 UTC"
  },
  {
    "arxiv_id": "2402.09836v2",
    "title": "Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation in LLMs",
    "authors": [
      "Chenyang Shao",
      "Fengli Xu",
      "Bingbing Fan",
      "Jingtao Ding",
      "Yuan Yuan",
      "Meng Wang",
      "Yong Li"
    ],
    "abstract": "The powerful reasoning capabilities of large language models (LLMs) have\nbrought revolutionary changes to many fields, but their performance in human\nbehaviour generation has not yet been extensively explored. This gap likely\nemerges because the internal processes governing behavioral intentions cannot\nbe solely explained by abstract reasoning. Instead, they are also influenced by\na multitude of factors, including social norms and personal preference.\nInspired by the Theory of Planned Behaviour (TPB), we develop a LLM workflow\nnamed Chain-of-Planned Behaviour (CoPB) for mobility behaviour generation,\nwhich reflects the important spatio-temporal dynamics of human activities.\nThrough exploiting the cognitive structures of attitude, subjective norms, and\nperceived behaviour control in TPB, CoPB significantly enhance the ability of\nLLMs to reason the intention of next movement. Specifically, CoPB substantially\nreduces the error rate of mobility intention generation from 57.8% to 19.4%. To\nimprove the scalability of the proposed CoPB workflow, we further explore the\nsynergy between LLMs and mechanistic models. We find mechanistic mobility\nmodels, such as gravity model, can effectively map mobility intentions to\nphysical mobility behaviours. The strategy of integrating CoPB with gravity\nmodel can reduce the token cost by 97.7% and achieve better performance\nsimultaneously. Besides, the proposed CoPB workflow can facilitate GPT-4-turbo\nto automatically generate high quality labels for mobility behavior reasoning.\nWe show such labels can be leveraged to fine-tune the smaller-scale, open\nsource LLaMA 3-8B, which significantly reduces usage costs without sacrificing\nthe quality of the generated behaviours.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09836v2",
    "published_date": "2024-02-15 09:58:23 UTC",
    "updated_date": "2024-06-05 09:27:42 UTC"
  },
  {
    "arxiv_id": "2402.09830v1",
    "title": "Utilizing GANs for Fraud Detection: Model Training with Synthetic Transaction Data",
    "authors": [
      "Mengran Zhu",
      "Yulu Gong",
      "Yafei Xiang",
      "Hanyi Yu",
      "Shuning Huo"
    ],
    "abstract": "Anomaly detection is a critical challenge across various research domains,\naiming to identify instances that deviate from normal data distributions. This\npaper explores the application of Generative Adversarial Networks (GANs) in\nfraud detection, comparing their advantages with traditional methods. GANs, a\ntype of Artificial Neural Network (ANN), have shown promise in modeling complex\ndata distributions, making them effective tools for anomaly detection. The\npaper systematically describes the principles of GANs and their derivative\nmodels, emphasizing their application in fraud detection across different\ndatasets. And by building a collection of adversarial verification graphs, we\nwill effectively prevent fraud caused by bots or automated systems and ensure\nthat the users in the transaction are real. The objective of the experiment is\nto design and implement a fake face verification code and fraud detection\nsystem based on Generative Adversarial network (GANs) algorithm to enhance the\nsecurity of the transaction process.The study demonstrates the potential of\nGANs in enhancing transaction security through deep learning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09830v1",
    "published_date": "2024-02-15 09:48:20 UTC",
    "updated_date": "2024-02-15 09:48:20 UTC"
  },
  {
    "arxiv_id": "2402.09820v2",
    "title": "Utilizing Deep Learning for Enhancing Network Resilience in Finance",
    "authors": [
      "Yulu Gong",
      "Mengran Zhu",
      "Shuning Huo",
      "Yafei Xiang",
      "Hanyi Yu"
    ],
    "abstract": "In the age of the Internet, people's lives are increasingly dependent on\ntoday's network technology. Maintaining network integrity and protecting the\nlegitimate interests of users is at the heart of network construction. Threat\ndetection is an important part of a complete and effective defense system. How\nto effectively detect unknown threats is one of the concerns of network\nprotection. Currently, network threat detection is usually based on rules and\ntraditional machine learning methods, which create artificial rules or extract\ncommon spatiotemporal features, which cannot be applied to large-scale data\napplications, and the emergence of unknown risks causes the detection accuracy\nof the original model to decline. With this in mind, this paper uses deep\nlearning for advanced threat detection to improve protective measures in the\nfinancial industry. Many network researchers have shifted their focus to\nexception-based intrusion detection techniques. The detection technology mainly\nuses statistical machine learning methods - collecting normal program and\nnetwork behavior data, extracting multidimensional features, and training\ndecision machine learning models on this basis (commonly used include naive\nBayes, decision trees, support vector machines, random forests, etc.).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "q-fin.GN"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09820v2",
    "published_date": "2024-02-15 09:35:57 UTC",
    "updated_date": "2024-02-18 11:29:45 UTC"
  },
  {
    "arxiv_id": "2402.09795v1",
    "title": "An advanced data fabric architecture leveraging homomorphic encryption and federated learning",
    "authors": [
      "Sakib Anwar Rieyan",
      "Md. Raisul Kabir News",
      "A. B. M. Muntasir Rahman",
      "Sadia Afrin Khan",
      "Sultan Tasneem Jawad Zaarif",
      "Md. Golam Rabiul Alam",
      "Mohammad Mehedi Hassan",
      "Michele Ianni",
      "Giancarlo Fortino"
    ],
    "abstract": "Data fabric is an automated and AI-driven data fusion approach to accomplish\ndata management unification without moving data to a centralized location for\nsolving complex data problems. In a Federated learning architecture, the global\nmodel is trained based on the learned parameters of several local models that\neliminate the necessity of moving data to a centralized repository for machine\nlearning. This paper introduces a secure approach for medical image analysis\nusing federated learning and partially homomorphic encryption within a\ndistributed data fabric architecture. With this method, multiple parties can\ncollaborate in training a machine-learning model without exchanging raw data\nbut using the learned or fused features. The approach complies with laws and\nregulations such as HIPAA and GDPR, ensuring the privacy and security of the\ndata. The study demonstrates the method's effectiveness through a case study on\npituitary tumor classification, achieving a significant level of accuracy.\nHowever, the primary focus of the study is on the development and evaluation of\nfederated learning and partially homomorphic encryption as tools for secure\nmedical image analysis. The results highlight the potential of these techniques\nto be applied to other privacy-sensitive domains and contribute to the growing\nbody of research on secure and privacy-preserving machine learning.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09795v1",
    "published_date": "2024-02-15 08:50:36 UTC",
    "updated_date": "2024-02-15 08:50:36 UTC"
  },
  {
    "arxiv_id": "2402.09792v1",
    "title": "System-level Impact of Non-Ideal Program-Time of Charge Trap Flash (CTF) on Deep Neural Network",
    "authors": [
      "S. Shrivastava",
      "A. Biswas",
      "S. Chakrabarty",
      "G. Dash",
      "V. Saraswat",
      "U. Ganguly"
    ],
    "abstract": "Learning of deep neural networks (DNN) using Resistive Processing Unit (RPU)\narchitecture is energy-efficient as it utilizes dedicated neuromorphic hardware\nand stochastic computation of weight updates for in-memory computing. Charge\nTrap Flash (CTF) devices can implement RPU-based weight updates in DNNs.\nHowever, prior work has shown that the weight updates (V_T) in CTF-based RPU\nare impacted by the non-ideal program time of CTF. The non-ideal program time\nis affected by two factors of CTF. Firstly, the effects of the number of input\npulses (N) or pulse width (pw), and secondly, the gap between successive update\npulses (t_gap) used for the stochastic computation of weight updates.\nTherefore, the impact of this non-ideal program time must be studied for neural\nnetwork training simulations. In this study, Firstly, we propose a pulse-train\ndesign compensation technique to reduce the total error caused by non-ideal\nprogram time of CTF and stochastic variance of a network. Secondly, we simulate\nRPU-based DNN with non-ideal program time of CTF on MNIST and Fashion-MNIST\ndatasets. We find that for larger N (~1000), learning performance approaches\nthe ideal (software-level) training level and, therefore, is not much impacted\nby the choice of t_gap used to implement RPU-based weight updates. However, for\nlower N (<500), learning performance depends on T_gap of the pulses. Finally,\nwe also performed an ablation study to isolate the causal factor of the\nimproved learning performance. We conclude that the lower noise level in the\nweight updates is the most likely significant factor to improve the learning\nperformance of DNN. Thus, our study attempts to compensate for the error caused\nby non-ideal program time and standardize the pulse length (N) and pulse gap\n(t_gap) specifications for CTF-based RPUs for accurate system-level on-chip\ntraining.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET",
      "eess.IV"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09792v1",
    "published_date": "2024-02-15 08:47:35 UTC",
    "updated_date": "2024-02-15 08:47:35 UTC"
  },
  {
    "arxiv_id": "2402.09786v4",
    "title": "Examining Pathological Bias in a Generative Adversarial Network Discriminator: A Case Study on a StyleGAN3 Model",
    "authors": [
      "Alvin Grissom II",
      "Ryan F. Lei",
      "Matt Gusdorff",
      "Jeova Farias Sales Rocha Neto",
      "Bailey Lin",
      "Ryan Trotter"
    ],
    "abstract": "Generative adversarial networks (GANs) generate photorealistic faces that are\noften indistinguishable by humans from real faces. While biases in machine\nlearning models are often assumed to be due to biases in training data, we find\npathological internal color and luminance biases in the discriminator of a\npre-trained StyleGAN3-r model that are not explicable by the training data. We\nalso find that the discriminator systematically stratifies scores by both\nimage- and face-level qualities and that this disproportionately affects images\nacross gender, race, and other categories. We examine axes common in research\non stereotyping in social psychology.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09786v4",
    "published_date": "2024-02-15 08:34:21 UTC",
    "updated_date": "2024-08-28 16:48:06 UTC"
  },
  {
    "arxiv_id": "2402.09784v2",
    "title": "Sequential Recommendation on Temporal Proximities with Contrastive Learning and Self-Attention",
    "authors": [
      "Hansol Jung",
      "Hyunwoo Seo",
      "Chiehyeon Lim"
    ],
    "abstract": "Sequential recommender systems identify user preferences from their past\ninteractions to predict subsequent items optimally. Although traditional\ndeep-learning-based models and modern transformer-based models in previous\nstudies capture unidirectional and bidirectional patterns within user-item\ninteractions, the importance of temporal contexts, such as individual\nbehavioral and societal trend patterns, remains underexplored. Notably, recent\nmodels often neglect similarities in users' actions that occur implicitly among\nusers during analogous timeframes-a concept we term vertical temporal\nproximity. These models primarily adapt the self-attention mechanisms of the\ntransformer to consider the temporal context in individual user actions.\nMeanwhile, this adaptation still remains limited in considering the horizontal\ntemporal proximity within item interactions, like distinguishing between\nsubsequent item purchases within a week versus a month. To address these gaps,\nwe propose a sequential recommendation model called TemProxRec, which includes\ncontrastive learning and self-attention methods to consider temporal\nproximities both across and within user-item interactions. The proposed\ncontrastive learning method learns representations of items selected in close\ntemporal periods across different users to be close. Simultaneously, the\nproposed self-attention mechanism encodes temporal and positional contexts in a\nuser sequence using both absolute and relative embeddings. This way, our\nTemProxRec accurately predicts the relevant items based on the user-item\ninteractions within a specific timeframe. We validate this work through\ncomprehensive experiments on TemProxRec, consistently outperforming existing\nmodels on benchmark datasets as well as showing the significance of considering\nthe vertical and horizontal temporal proximities into sequential\nrecommendation.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09784v2",
    "published_date": "2024-02-15 08:33:16 UTC",
    "updated_date": "2024-02-18 02:38:02 UTC"
  },
  {
    "arxiv_id": "2402.09782v3",
    "title": "MC-DBN: A Deep Belief Network-Based Model for Modality Completion",
    "authors": [
      "Zihong Luo",
      "Zheng Tao",
      "Yuxuan Huang",
      "Kexin He",
      "Chengzhi Liu"
    ],
    "abstract": "Recent advancements in multi-modal artificial intelligence (AI) have\nrevolutionized the fields of stock market forecasting and heart rate\nmonitoring. Utilizing diverse data sources can substantially improve prediction\naccuracy. Nonetheless, additional data may not always align with the original\ndataset. Interpolation methods are commonly utilized for handling missing\nvalues in modal data, though they may exhibit limitations in the context of\nsparse information. Addressing this challenge, we propose a Modality Completion\nDeep Belief Network-Based Model (MC-DBN). This approach utilizes implicit\nfeatures of complete data to compensate for gaps between itself and additional\nincomplete data. It ensures that the enhanced multi-modal data closely aligns\nwith the dynamic nature of the real world to enhance the effectiveness of the\nmodel. We conduct evaluations of the MC-DBN model in two datasets from the\nstock market forecasting and heart rate monitoring domains. Comprehensive\nexperiments showcase the model's capacity to bridge the semantic divide present\nin multi-modal data, subsequently enhancing its performance. The source code is\navailable at: https://github.com/logan-0623/DBN-generate",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09782v3",
    "published_date": "2024-02-15 08:21:50 UTC",
    "updated_date": "2024-03-20 08:50:46 UTC"
  },
  {
    "arxiv_id": "2402.09769v2",
    "title": "Learning Using a Single Forward Pass",
    "authors": [
      "Aditya Somasundaram",
      "Pushkal Mishra",
      "Ayon Borthakur"
    ],
    "abstract": "We propose a learning algorithm to overcome the limitations of a traditional\nbackpropagation in resource-constrained environments: Solo Pass Embedded\nLearning Algorithm (SPELA). SPELA is equipped with rapid learning capabilities\nand operates with local loss functions to update weights, significantly saving\non resources allocated to the propagation of gradients and storing\ncomputational graphs while being sufficiently accurate. Consequently, SPELA can\nclosely match backpropagation with less data, computing, storage, and power.\nMoreover, SPELA can effectively fine-tune pre-trained image recognition models\nfor new tasks. Our results indicate that SPELA can be an ideal candidate for\nlearning in resource-constrained edge AI applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09769v2",
    "published_date": "2024-02-15 07:47:10 UTC",
    "updated_date": "2025-03-10 06:32:41 UTC"
  },
  {
    "arxiv_id": "2402.09766v2",
    "title": "From Variability to Stability: Advancing RecSys Benchmarking Practices",
    "authors": [
      "Valeriy Shevchenko",
      "Nikita Belousov",
      "Alexey Vasilev",
      "Vladimir Zholobov",
      "Artyom Sosedka",
      "Natalia Semenova",
      "Anna Volodkevich",
      "Andrey Savchenko",
      "Alexey Zaytsev"
    ],
    "abstract": "In the rapidly evolving domain of Recommender Systems (RecSys), new\nalgorithms frequently claim state-of-the-art performance based on evaluations\nover a limited set of arbitrarily selected datasets. However, this approach may\nfail to holistically reflect their effectiveness due to the significant impact\nof dataset characteristics on algorithm performance. Addressing this\ndeficiency, this paper introduces a novel benchmarking methodology to\nfacilitate a fair and robust comparison of RecSys algorithms, thereby advancing\nevaluation practices. By utilizing a diverse set of $30$ open datasets,\nincluding two introduced in this work, and evaluating $11$ collaborative\nfiltering algorithms across $9$ metrics, we critically examine the influence of\ndataset characteristics on algorithm performance. We further investigate the\nfeasibility of aggregating outcomes from multiple datasets into a unified\nranking. Through rigorous experimental analysis, we validate the reliability of\nour methodology under the variability of datasets, offering a benchmarking\nstrategy that balances quality and computational demands. This methodology\nenables a fair yet effective means of evaluating RecSys algorithms, providing\nvaluable guidance for future research endeavors.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages with 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09766v2",
    "published_date": "2024-02-15 07:35:52 UTC",
    "updated_date": "2024-08-27 13:01:56 UTC"
  },
  {
    "arxiv_id": "2402.09765v1",
    "title": "Reinforcement Learning for Solving Stochastic Vehicle Routing Problem with Time Windows",
    "authors": [
      "Zangir Iklassov",
      "Ikboljon Sobirov",
      "Ruben Solozabal",
      "Martin Takac"
    ],
    "abstract": "This paper introduces a reinforcement learning approach to optimize the\nStochastic Vehicle Routing Problem with Time Windows (SVRP), focusing on\nreducing travel costs in goods delivery. We develop a novel SVRP formulation\nthat accounts for uncertain travel costs and demands, alongside specific\ncustomer time windows. An attention-based neural network trained through\nreinforcement learning is employed to minimize routing costs. Our approach\naddresses a gap in SVRP research, which traditionally relies on heuristic\nmethods, by leveraging machine learning. The model outperforms the Ant-Colony\nOptimization algorithm, achieving a 1.73% reduction in travel costs. It\nuniquely integrates external information, demonstrating robustness in diverse\nenvironments, making it a valuable benchmark for future SVRP studies and\nindustry application.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09765v1",
    "published_date": "2024-02-15 07:35:29 UTC",
    "updated_date": "2024-02-15 07:35:29 UTC"
  },
  {
    "arxiv_id": "2402.09764v3",
    "title": "Aligning Crowd Feedback via Distributional Preference Reward Modeling",
    "authors": [
      "Dexun Li",
      "Cong Zhang",
      "Kuicai Dong",
      "Derrick Goh Xin Deik",
      "Ruiming Tang",
      "Yong Liu"
    ],
    "abstract": "Deep Reinforcement Learning is widely used for aligning Large Language Models\n(LLM) with human preference. However, the conventional reward modelling is\npredominantly dependent on human annotations provided by a select cohort of\nindividuals. Such dependence may unintentionally result in skewed models that\nreflect the inclinations of these annotators, thereby failing to adequately\nrepresent the wider population's expectations. We propose the Distributional\nPreference Reward Model (DPRM), a simple yet effective framework to align large\nlanguage models with diverse human preferences. To this end, we characterize\nmultiple preferences by a categorical distribution and introduce a Bayesian\nupdater to accommodate shifted or new preferences. On top of that, we design an\noptimal-transportation-based loss to calibrate DPRM to align with the\npreference distribution. Finally, the expected reward is utilized to fine-tune\nan LLM policy to generate responses favoured by the population. Our experiments\nshow that DPRM significantly enhances the alignment of LLMs with population\npreference, yielding more accurate, unbiased, and contextually appropriate\nresponses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09764v3",
    "published_date": "2024-02-15 07:29:43 UTC",
    "updated_date": "2024-05-30 15:39:17 UTC"
  },
  {
    "arxiv_id": "2402.09760v1",
    "title": "Grounding Language Model with Chunking-Free In-Context Retrieval",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu",
      "Kelong Mao",
      "Yujia Zhou",
      "Zhicheng Dou"
    ],
    "abstract": "This paper presents a novel Chunking-Free In-Context (CFIC) retrieval\napproach, specifically tailored for Retrieval-Augmented Generation (RAG)\nsystems. Traditional RAG systems often struggle with grounding responses using\nprecise evidence text due to the challenges of processing lengthy documents and\nfiltering out irrelevant content. Commonly employed solutions, such as document\nchunking and adapting language models to handle longer contexts, have their\nlimitations. These methods either disrupt the semantic coherence of the text or\nfail to effectively address the issues of noise and inaccuracy in evidence\nretrieval.\n  CFIC addresses these challenges by circumventing the conventional chunking\nprocess. It utilizes the encoded hidden states of documents for in-context\nretrieval, employing auto-aggressive decoding to accurately identify the\nspecific evidence text required for user queries, eliminating the need for\nchunking. CFIC is further enhanced by incorporating two decoding strategies,\nnamely Constrained Sentence Prefix Decoding and Skip Decoding. These strategies\nnot only improve the efficiency of the retrieval process but also ensure that\nthe fidelity of the generated grounding text evidence is maintained. Our\nevaluations of CFIC on a range of open QA datasets demonstrate its superiority\nin retrieving relevant and accurate evidence, offering a significant\nimprovement over traditional methods. By doing away with the need for document\nchunking, CFIC presents a more streamlined, effective, and efficient retrieval\nsolution, making it a valuable advancement in the field of RAG systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09760v1",
    "published_date": "2024-02-15 07:22:04 UTC",
    "updated_date": "2024-02-15 07:22:04 UTC"
  },
  {
    "arxiv_id": "2402.09759v1",
    "title": "Efficient Language Adaptive Pre-training: Extending State-of-the-Art Large Language Models for Polish",
    "authors": [
      "Szymon Ruciński"
    ],
    "abstract": "This study explores the potential of fine-tuning foundational English Large\nLanguage Models (LLMs) for generating Polish text. The first step involves\nLanguage Adaptive Pre-training (LAPT) on a high-quality dataset of 3.11 GB,\nconsisting of 276 million Polish tokens. The LAPT is followed by additional\nfine-tuning aimed at solving nine KLEJ challenges. Our trained model\nCurie-7B-v1 not only generates Polish text with the lowest perplexity of 3.02\namong decoder-based Polish models but also closely rivals the performance of\nthe best Polish encoder-decoder models with a less than 2% gap on 8 out of 9\ntasks. Curie-7B-v1 used approximately 2-3% of a typical dataset size to learn\nPolish. The LAPT was completed in less than five days using a consumer GPU,\nhighlighting the method's efficiency. The proficiency of the model in Polish\nwas significantly enhanced, demonstrating the viability of this approach for\nadding new languages to existing LLMs by training just 1.2% of its parameters.\nTo contribute to the community's collaborative progress, the model has been\nreleased as open-source.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.09759v1",
    "published_date": "2024-02-15 07:17:10 UTC",
    "updated_date": "2024-02-15 07:17:10 UTC"
  },
  {
    "arxiv_id": "2402.09750v1",
    "title": "Exploring the Potential of Large Language Models in Artistic Creation: Collaboration and Reflection on Creative Programming",
    "authors": [
      "Anqi Wang",
      "Zhizhuo Yin",
      "Yulu Hu",
      "Yuanyuan Mao",
      "Pan Hui"
    ],
    "abstract": "Recently, the potential of large language models (LLMs) has been widely used\nin assisting programming. However, current research does not explore the artist\npotential of LLMs in creative coding within artist and AI collaboration. Our\nwork probes the reflection type of artists in the creation process with such\ncollaboration. We compare two common collaboration approaches: invoking the\nentire program and multiple subtasks. Our findings exhibit artists' different\nstimulated reflections in two different methods. Our finding also shows the\ncorrelation of reflection type with user performance, user satisfaction, and\nsubjective experience in two collaborations through conducting two methods,\nincluding experimental data and qualitative interviews. In this sense, our work\nreveals the artistic potential of LLM in creative coding. Meanwhile, we provide\na critical lens of human-AI collaboration from the artists' perspective and\nexpound design suggestions for future work of AI-assisted creative tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.5"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09750v1",
    "published_date": "2024-02-15 07:00:06 UTC",
    "updated_date": "2024-02-15 07:00:06 UTC"
  },
  {
    "arxiv_id": "2402.09748v1",
    "title": "Model Compression and Efficient Inference for Large Language Models: A Survey",
    "authors": [
      "Wenxiao Wang",
      "Wei Chen",
      "Yicong Luo",
      "Yongliu Long",
      "Zhengkai Lin",
      "Liye Zhang",
      "Binbin Lin",
      "Deng Cai",
      "Xiaofei He"
    ],
    "abstract": "Transformer based large language models have achieved tremendous success.\nHowever, the significant memory and computational costs incurred during the\ninference process make it challenging to deploy large models on\nresource-constrained devices. In this paper, we investigate compression and\nefficient inference methods for large language models from an algorithmic\nperspective. Regarding taxonomy, similar to smaller models, compression and\nacceleration algorithms for large language models can still be categorized into\nquantization, pruning, distillation, compact architecture design, dynamic\nnetworks. However, Large language models have two prominent characteristics\ncompared to smaller models: (1) Most of compression algorithms require\nfinetuning or even retraining the model after compression. The most notable\naspect of large models is the very high cost associated with model finetuning\nor training. Therefore, many algorithms for large models, such as quantization\nand pruning, start to explore tuning-free algorithms. (2) Large models\nemphasize versatility and generalization rather than performance on a single\ntask. Hence, many algorithms, such as knowledge distillation, focus on how to\npreserving their versatility and generalization after compression. Since these\ntwo characteristics were not very pronounced in early large models, we further\ndistinguish large language models into medium models and ``real'' large models.\nAdditionally, we also provide an introduction to some mature frameworks for\nefficient inference of large models, which can support basic compression or\nacceleration algorithms, greatly facilitating model deployment for users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CL",
    "comment": "47 pages, review 380 papers. The work is ongoing",
    "pdf_url": "http://arxiv.org/pdf/2402.09748v1",
    "published_date": "2024-02-15 06:58:30 UTC",
    "updated_date": "2024-02-15 06:58:30 UTC"
  },
  {
    "arxiv_id": "2402.09746v1",
    "title": "Alpha-GPT 2.0: Human-in-the-Loop AI for Quantitative Investment",
    "authors": [
      "Hang Yuan",
      "Saizhuo Wang",
      "Jian Guo"
    ],
    "abstract": "Recently, we introduced a new paradigm for alpha mining in the realm of\nquantitative investment, developing a new interactive alpha mining system\nframework, Alpha-GPT. This system is centered on iterative Human-AI interaction\nbased on large language models, introducing a Human-in-the-Loop approach to\nalpha discovery. In this paper, we present the next-generation Alpha-GPT 2.0\n\\footnote{Draft. Work in progress}, a quantitative investment framework that\nfurther encompasses crucial modeling and analysis phases in quantitative\ninvestment. This framework emphasizes the iterative, interactive research\nbetween humans and AI, embodying a Human-in-the-Loop strategy throughout the\nentire quantitative investment pipeline. By assimilating the insights of human\nresearchers into the systematic alpha research process, we effectively leverage\nthe Human-in-the-Loop approach, enhancing the efficiency and precision of\nquantitative investment research.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09746v1",
    "published_date": "2024-02-15 06:52:42 UTC",
    "updated_date": "2024-02-15 06:52:42 UTC"
  },
  {
    "arxiv_id": "2402.12391v2",
    "title": "Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data",
    "authors": [
      "Haoyang Liu",
      "Yijiang Li",
      "Jinglin Jian",
      "Yuxuan Cheng",
      "Jianrong Lu",
      "Shuyi Guo",
      "Jinglei Zhu",
      "Mianchen Zhang",
      "Miantong Zhang",
      "Haohan Wang"
    ],
    "abstract": "Machine learning has emerged as a powerful tool for scientific discovery,\nenabling researchers to extract meaningful insights from complex datasets. For\ninstance, it has facilitated the identification of disease-predictive genes\nfrom gene expression data, significantly advancing healthcare. However, the\ntraditional process for analyzing such datasets demands substantial human\neffort and expertise for the data selection, processing, and analysis. To\naddress this challenge, we introduce a novel framework, a Team of AI-made\nScientists (TAIS), designed to streamline the scientific discovery pipeline.\nTAIS comprises simulated roles, including a project manager, data engineer, and\ndomain expert, each represented by a Large Language Model (LLM). These roles\ncollaborate to replicate the tasks typically performed by data scientists, with\na specific focus on identifying disease-predictive genes. Furthermore, we have\ncurated a benchmark dataset to assess TAIS's effectiveness in gene\nidentification, demonstrating our system's potential to significantly enhance\nthe efficiency and scope of scientific exploration. Our findings represent a\nsolid step towards automating scientific discovery through large language\nmodels.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "18 pages, 2 figures; added contact",
    "pdf_url": "http://arxiv.org/pdf/2402.12391v2",
    "published_date": "2024-02-15 06:30:12 UTC",
    "updated_date": "2024-02-21 03:42:32 UTC"
  },
  {
    "arxiv_id": "2404.03662v1",
    "title": "X-lifecycle Learning for Cloud Incident Management using LLMs",
    "authors": [
      "Drishti Goel",
      "Fiza Husain",
      "Aditya Singh",
      "Supriyo Ghosh",
      "Anjaly Parayil",
      "Chetan Bansal",
      "Xuchao Zhang",
      "Saravan Rajmohan"
    ],
    "abstract": "Incident management for large cloud services is a complex and tedious process\nand requires significant amount of manual efforts from on-call engineers\n(OCEs). OCEs typically leverage data from different stages of the software\ndevelopment lifecycle [SDLC] (e.g., codes, configuration, monitor data, service\nproperties, service dependencies, trouble-shooting documents, etc.) to generate\ninsights for detection, root causing and mitigating of incidents. Recent\nadvancements in large language models [LLMs] (e.g., ChatGPT, GPT-4, Gemini)\ncreated opportunities to automatically generate contextual recommendations to\nthe OCEs assisting them to quickly identify and mitigate critical issues.\nHowever, existing research typically takes a silo-ed view for solving a certain\ntask in incident management by leveraging data from a single stage of SDLC. In\nthis paper, we demonstrate that augmenting additional contextual data from\ndifferent stages of SDLC improves the performance of two critically important\nand practically challenging tasks: (1) automatically generating root cause\nrecommendations for dependency failure related incidents, and (2) identifying\nontology of service monitors used for automatically detecting incidents. By\nleveraging 353 incident and 260 monitor dataset from Microsoft, we demonstrate\nthat augmenting contextual information from different stages of the SDLC\nimproves the performance over State-of-The-Art methods.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.03662v1",
    "published_date": "2024-02-15 06:19:02 UTC",
    "updated_date": "2024-02-15 06:19:02 UTC"
  },
  {
    "arxiv_id": "2402.09734v1",
    "title": "Agents Need Not Know Their Purpose",
    "authors": [
      "Paulo Garcia"
    ],
    "abstract": "Ensuring artificial intelligence behaves in such a way that is aligned with\nhuman values is commonly referred to as the alignment challenge. Prior work has\nshown that rational agents, behaving in such a way that maximizes a utility\nfunction, will inevitably behave in such a way that is not aligned with human\nvalues, especially as their level of intelligence goes up. Prior work has also\nshown that there is no \"one true utility function\"; solutions must include a\nmore holistic approach to alignment. This paper describes oblivious agents:\nagents that are architected in such a way that their effective utility function\nis an aggregation of a known and hidden sub-functions. The hidden component, to\nbe maximized, is internally implemented as a black box, preventing the agent\nfrom examining it. The known component, to be minimized, is knowledge of the\nhidden sub-function. Architectural constraints further influence how agent\nactions can evolve its internal environment model. We show that an oblivious\nagent, behaving rationally, constructs an internal approximation of designers'\nintentions (i.e., infers alignment), and, as a consequence of its architecture\nand effective utility function, behaves in such a way that maximizes alignment;\ni.e., maximizing the approximated intention function. We show that,\nparadoxically, it does this for whatever utility function is used as the hidden\ncomponent and, in contrast with extant techniques, chances of alignment\nactually improve as agent intelligence grows.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09734v1",
    "published_date": "2024-02-15 06:15:46 UTC",
    "updated_date": "2024-02-15 06:15:46 UTC"
  },
  {
    "arxiv_id": "2402.09729v1",
    "title": "Federated Prompt-based Decision Transformer for Customized VR Services in Mobile Edge Computing System",
    "authors": [
      "Tailin Zhou",
      "Jiadong Yu",
      "Jun Zhang",
      "Danny H. K. Tsang"
    ],
    "abstract": "This paper investigates resource allocation to provide heterogeneous users\nwith customized virtual reality (VR) services in a mobile edge computing (MEC)\nsystem. We first introduce a quality of experience (QoE) metric to measure user\nexperience, which considers the MEC system's latency, user attention levels,\nand preferred resolutions. Then, a QoE maximization problem is formulated for\nresource allocation to ensure the highest possible user experience,which is\ncast as a reinforcement learning problem, aiming to learn a generalized policy\napplicable across diverse user environments for all MEC servers. To learn the\ngeneralized policy, we propose a framework that employs federated learning (FL)\nand prompt-based sequence modeling to pre-train a common decision model across\nMEC servers, which is named FedPromptDT. Using FL solves the problem of\ninsufficient local MEC data while protecting user privacy during offline\ntraining. The design of prompts integrating user-environment cues and\nuser-preferred allocation improves the model's adaptability to various user\nenvironments during online execution.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09729v1",
    "published_date": "2024-02-15 05:56:35 UTC",
    "updated_date": "2024-02-15 05:56:35 UTC"
  },
  {
    "arxiv_id": "2402.09728v1",
    "title": "AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns",
    "authors": [
      "Ashfak Md Shibli",
      "Mir Mehedi A. Pritom",
      "Maanak Gupta"
    ],
    "abstract": "SMS phishing, also known as \"smishing\", is a growing threat that tricks users\ninto disclosing private information or clicking into URLs with malicious\ncontent through fraudulent mobile text messages. In recent past, we have also\nobserved a rapid advancement of conversational generative AI chatbot services\n(e.g., OpenAI's ChatGPT, Google's BARD), which are powered by pre-trained large\nlanguage models (LLMs). These AI chatbots certainly have a lot of utilities but\nit is not systematically understood how they can play a role in creating\nthreats and attacks. In this paper, we propose AbuseGPT method to show how the\nexisting generative AI-based chatbot services can be exploited by attackers in\nreal world to create smishing texts and eventually lead to craftier smishing\ncampaigns. To the best of our knowledge, there is no pre-existing work that\nevidently shows the impacts of these generative text-based models on creating\nSMS phishing. Thus, we believe this study is the first of its kind to shed\nlight on this emerging cybersecurity threat. We have found strong empirical\nevidences to show that attackers can exploit ethical standards in the existing\ngenerative AI-based chatbot services by crafting prompt injection attacks to\ncreate newer smishing campaigns. We also discuss some future research\ndirections and guidelines to protect the abuse of generative AI-based services\nand safeguard users from smishing attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, 12 figures, published in ISDFS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09728v1",
    "published_date": "2024-02-15 05:49:22 UTC",
    "updated_date": "2024-02-15 05:49:22 UTC"
  },
  {
    "arxiv_id": "2402.09727v3",
    "title": "A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts",
    "authors": [
      "Kuang-Huei Lee",
      "Xinyun Chen",
      "Hiroki Furuta",
      "John Canny",
      "Ian Fischer"
    ],
    "abstract": "Current Large Language Models (LLMs) are not only limited to some maximum\ncontext length, but also are not able to robustly consume long inputs. To\naddress these limitations, we propose ReadAgent, an LLM agent system that\nincreases effective context length up to 20x in our experiments. Inspired by\nhow humans interactively read long documents, we implement ReadAgent as a\nsimple prompting system that uses the advanced language capabilities of LLMs to\n(1) decide what content to store together in a memory episode, (2) compress\nthose memory episodes into short episodic memories called gist memories, and\n(3) take actions to look up passages in the original text if ReadAgent needs to\nremind itself of relevant details to complete a task. We evaluate ReadAgent\nagainst baselines using retrieval methods, using the original long contexts,\nand using the gist memories. These evaluations are performed on three\nlong-document reading comprehension tasks: QuALITY, NarrativeQA, and QMSum.\nReadAgent outperforms the baselines on all three tasks while extending the\neffective context window by 3.5-20x.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Website: https://read-agent.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.09727v3",
    "published_date": "2024-02-15 05:40:21 UTC",
    "updated_date": "2024-07-22 05:33:51 UTC"
  },
  {
    "arxiv_id": "2402.09725v1",
    "title": "Improving Non-autoregressive Machine Translation with Error Exposure and Consistency Regularization",
    "authors": [
      "Xinran Chen",
      "Sufeng Duan",
      "Gongshen Liu"
    ],
    "abstract": "Being one of the IR-NAT (Iterative-refinemennt-based NAT) frameworks, the\nConditional Masked Language Model (CMLM) adopts the mask-predict paradigm to\nre-predict the masked low-confidence tokens. However, CMLM suffers from the\ndata distribution discrepancy between training and inference, where the\nobserved tokens are generated differently in the two cases. In this paper, we\naddress this problem with the training approaches of error exposure and\nconsistency regularization (EECR). We construct the mixed sequences based on\nmodel prediction during training, and propose to optimize over the masked\ntokens under imperfect observation conditions. We also design a consistency\nlearning method to constrain the data distribution for the masked tokens under\ndifferent observing situations to narrow down the gap between training and\ninference. The experiments on five translation benchmarks obtains an average\nimprovement of 0.68 and 0.40 BLEU scores compared to the base models,\nrespectively, and our CMLMC-EECR achieves the best performance with a\ncomparable translation quality with the Transformer. The experiments results\ndemonstrate the effectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09725v1",
    "published_date": "2024-02-15 05:35:04 UTC",
    "updated_date": "2024-02-15 05:35:04 UTC"
  },
  {
    "arxiv_id": "2402.09723v3",
    "title": "Efficient Prompt Optimization Through the Lens of Best Arm Identification",
    "authors": [
      "Chengshuai Shi",
      "Kun Yang",
      "Zihan Chen",
      "Jundong Li",
      "Jing Yang",
      "Cong Shen"
    ],
    "abstract": "The remarkable instruction-following capability of large language models\n(LLMs) has sparked a growing interest in automatically finding good prompts,\ni.e., prompt optimization. Most existing works follow the scheme of selecting\nfrom a pre-generated pool of candidate prompts. However, these designs mainly\nfocus on the generation strategy, while limited attention has been paid to the\nselection method. Especially, the cost incurred during the selection (e.g.,\naccessing LLM and evaluating the responses) is rarely explicitly considered. To\novercome this limitation, this work provides a principled framework, TRIPLE, to\nefficiently perform prompt selection under an explicit budget constraint.\nTRIPLE is built on a novel connection established between prompt optimization\nand fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB);\nthus, it is capable of leveraging the rich toolbox from BAI-FB systematically\nand also incorporating unique characteristics of prompt optimization. Extensive\nexperiments on multiple well-adopted tasks using various LLMs demonstrate the\nremarkable performance improvement of TRIPLE over baselines while satisfying\nthe limited budget constraints. As an extension, variants of TRIPLE are\nproposed to efficiently select examples for few-shot prompts, also achieving\nsuperior empirical performance.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09723v3",
    "published_date": "2024-02-15 05:31:13 UTC",
    "updated_date": "2024-05-30 19:40:21 UTC"
  },
  {
    "arxiv_id": "2402.09722v1",
    "title": "Reg-NF: Efficient Registration of Implicit Surfaces within Neural Fields",
    "authors": [
      "Stephen Hausler",
      "David Hall",
      "Sutharsan Mahendren",
      "Peyman Moghadam"
    ],
    "abstract": "Neural fields, coordinate-based neural networks, have recently gained\npopularity for implicitly representing a scene. In contrast to classical\nmethods that are based on explicit representations such as point clouds, neural\nfields provide a continuous scene representation able to represent 3D geometry\nand appearance in a way which is compact and ideal for robotics applications.\nHowever, limited prior methods have investigated registering multiple neural\nfields by directly utilising these continuous implicit representations. In this\npaper, we present Reg-NF, a neural fields-based registration that optimises for\nthe relative 6-DoF transformation between two arbitrary neural fields, even if\nthose two fields have different scale factors. Key components of Reg-NF include\na bidirectional registration loss, multi-view surface sampling, and utilisation\nof volumetric signed distance functions (SDFs). We showcase our approach on a\nnew neural field dataset for evaluating registration problems. We provide an\nexhaustive set of experiments and ablation studies to identify the performance\nof our approach, while also discussing limitations to provide future direction\nto the research community on open challenges in utilizing neural fields in\nunconstrained environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICRA 2024. The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2402.09722v1",
    "published_date": "2024-02-15 05:31:03 UTC",
    "updated_date": "2024-02-15 05:31:03 UTC"
  },
  {
    "arxiv_id": "2402.09721v6",
    "title": "Generalized Principal-Agent Problem with a Learning Agent",
    "authors": [
      "Tao Lin",
      "Yiling Chen"
    ],
    "abstract": "Classic principal-agent problems such as Stackelberg games, contract design,\nand Bayesian persuasion, often assume that the agent is able to best respond to\nthe principal's committed strategy. We study repeated generalized\nprincipal-agent problems under the assumption that the principal does not have\ncommitment power and the agent uses algorithms to learn to respond to the\nprincipal. We reduce this problem to a one-shot generalized principal-agent\nproblem where the agent approximately best responds. Using this reduction, we\nshow that: (1) If the agent uses contextual no-regret learning algorithms with\nregret $\\mathrm{Reg}(T)$, then the principal can guarantee utility at least\n$U^* - \\Theta\\big(\\sqrt{\\tfrac{\\mathrm{Reg}(T)}{T}}\\big)$, where $U^*$ is the\nprincipal's optimal utility in the classic model with a best-responding agent.\n(2) If the agent uses contextual no-swap-regret learning algorithms with\nswap-regret $\\mathrm{SReg}(T)$, then the principal cannot obtain utility more\nthan $U^* + O(\\frac{\\mathrm{SReg(T)}}{T})$. But (3) if the agent uses\nmean-based learning algorithms (which can be no-regret but not no-swap-regret),\nthen the principal can sometimes do significantly better than $U^*$. These\nresults not only refine previous results in Stackelberg games and contract\ndesign, but also lead to new results for Bayesian persuasion with a learning\nagent and all generalized principal-agent problems where the agent does not\nhave private information.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "Accepted by ICLR 2025 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2402.09721v6",
    "published_date": "2024-02-15 05:30:47 UTC",
    "updated_date": "2025-02-22 06:58:43 UTC"
  },
  {
    "arxiv_id": "2402.09712v2",
    "title": "Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement",
    "authors": [
      "Tao Yang",
      "Cuiling Lan",
      "Yan Lu",
      "Nanning zheng"
    ],
    "abstract": "Disentangled representation learning strives to extract the intrinsic factors\nwithin observed data. Factorizing these representations in an unsupervised\nmanner is notably challenging and usually requires tailored loss functions or\nspecific structural designs. In this paper, we introduce a new perspective and\nframework, demonstrating that diffusion models with cross-attention can serve\nas a powerful inductive bias to facilitate the learning of disentangled\nrepresentations. We propose to encode an image to a set of concept tokens and\ntreat them as the condition of the latent diffusion for image reconstruction,\nwhere cross-attention over the concept tokens is used to bridge the interaction\nbetween the encoder and diffusion. Without any additional regularization, this\nframework achieves superior disentanglement performance on the benchmark\ndatasets, surpassing all previous methods with intricate designs. We have\nconducted comprehensive ablation studies and visualization analysis, shedding\nlight on the functioning of this model. This is the first work to reveal the\npotent disentanglement capability of diffusion models with cross-attention,\nrequiring no complex designs. We anticipate that our findings will inspire more\ninvestigation on exploring diffusion for disentangled representation learning\ntowards more sophisticated data analysis and understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09712v2",
    "published_date": "2024-02-15 05:07:54 UTC",
    "updated_date": "2024-06-12 15:20:36 UTC"
  },
  {
    "arxiv_id": "2402.09695v2",
    "title": "Universal Black-Box Reward Poisoning Attack against Offline Reinforcement Learning",
    "authors": [
      "Yinglun Xu",
      "Rohan Gumaste",
      "Gagandeep Singh"
    ],
    "abstract": "We study the problem of universal black-boxed reward poisoning attacks\nagainst general offline reinforcement learning with deep neural networks. We\nconsider a black-box threat model where the attacker is entirely oblivious to\nthe learning algorithm, and its budget is limited by constraining the amount of\ncorruption at each data point and the total perturbation. We require the attack\nto be universally efficient against any efficient algorithms that might be used\nby the agent. We propose an attack strategy called the `policy contrast\nattack.' The idea is to find low- and high-performing policies covered by the\ndataset and make them appear to be high- and low-performing to the agent,\nrespectively. To the best of our knowledge, we propose the first universal\nblack-box reward poisoning attack in the general offline RL setting. We provide\ntheoretical insights on the attack design and empirically show that our attack\nis efficient against current state-of-the-art offline RL algorithms in\ndifferent learning datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09695v2",
    "published_date": "2024-02-15 04:08:49 UTC",
    "updated_date": "2024-10-23 19:31:22 UTC"
  },
  {
    "arxiv_id": "2402.09683v1",
    "title": "Exploring a Behavioral Model of \"Positive Friction\" in Human-AI Interaction",
    "authors": [
      "Zeya Chen",
      "Ruth Schmidt"
    ],
    "abstract": "Designing seamless, frictionless user experiences has long been a dominant\ntrend in both applied behavioral science and artificial intelligence (AI), in\nwhich the goal of making desirable actions easy and efficient informs efforts\nto minimize friction in user experiences. However, in some settings, friction\ncan be genuinely beneficial, such as the insertion of deliberate delays to\nincrease reflection, preventing individuals from resorting to automatic or\nbiased behaviors, and enhancing opportunities for unexpected discoveries. More\nrecently, the popularization and availability of AI on a widespread scale has\nonly increased the need to examine how friction can help or hinder users of AI;\nit also suggests a need to consider how positive friction can benefit AI\npractitioners, both during development processes (e.g., working with diverse\nteams) and to inform how AI is designed into offerings. This paper first\nproposes a \"positive friction\" model that can help characterize how friction is\ncurrently beneficial in user and developer experiences with AI, diagnose the\npotential need for friction where it may not yet exist in these contexts, and\ninform how positive friction can be used to generate solutions, especially as\nadvances in AI continue to be progress and new opportunities emerge. It then\nexplores this model in the context of AI users and developers by proposing the\nvalue of taking a hybrid \"AI+human\" lens, and concludes by suggesting questions\nfor further exploration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "This preprint has not undergone peer review or any post-submission\n  corrections. The Version of Record of this contribution will be published in\n  Springer Nature Computer Science book series in Volume HCI International 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09683v1",
    "published_date": "2024-02-15 03:39:55 UTC",
    "updated_date": "2024-02-15 03:39:55 UTC"
  },
  {
    "arxiv_id": "2402.09674v1",
    "title": "PAL: Proxy-Guided Black-Box Attack on Large Language Models",
    "authors": [
      "Chawin Sitawarin",
      "Norman Mu",
      "David Wagner",
      "Alexandre Araujo"
    ],
    "abstract": "Large Language Models (LLMs) have surged in popularity in recent months, but\nthey have demonstrated concerning capabilities to generate harmful content when\nmanipulated. While techniques like safety fine-tuning aim to minimize harmful\nuse, recent works have shown that LLMs remain vulnerable to attacks that elicit\ntoxic responses. In this work, we introduce the Proxy-Guided Attack on LLMs\n(PAL), the first optimization-based attack on LLMs in a black-box query-only\nsetting. In particular, it relies on a surrogate model to guide the\noptimization and a sophisticated loss designed for real-world LLM APIs. Our\nattack achieves 84% attack success rate (ASR) on GPT-3.5-Turbo and 48% on\nLlama-2-7B, compared to 4% for the current state of the art. We also propose\nGCG++, an improvement to the GCG attack that reaches 94% ASR on white-box\nLlama-2-7B, and the Random-Search Attack on LLMs (RAL), a strong but simple\nbaseline for query-based attacks. We believe the techniques proposed in this\nwork will enable more comprehensive safety testing of LLMs and, in the long\nterm, the development of better security guardrails. The code can be found at\nhttps://github.com/chawins/pal.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09674v1",
    "published_date": "2024-02-15 02:54:49 UTC",
    "updated_date": "2024-02-15 02:54:49 UTC"
  },
  {
    "arxiv_id": "2402.09668v1",
    "title": "How to Train Data-Efficient LLMs",
    "authors": [
      "Noveen Sachdeva",
      "Benjamin Coleman",
      "Wang-Cheng Kang",
      "Jianmo Ni",
      "Lichan Hong",
      "Ed H. Chi",
      "James Caverlee",
      "Julian McAuley",
      "Derek Zhiyuan Cheng"
    ],
    "abstract": "The training of large language models (LLMs) is expensive. In this paper, we\nstudy data-efficient approaches for pre-training LLMs, i.e., techniques that\naim to optimize the Pareto frontier of model quality and training resource/data\nconsumption. We seek to understand the tradeoffs associated with data selection\nroutines based on (i) expensive-to-compute data-quality estimates, and (ii)\nmaximization of coverage and diversity-based measures in the feature space. Our\nfirst technique, Ask-LLM, leverages the zero-shot reasoning capabilities of\ninstruction-tuned LLMs to directly assess the quality of a training example. To\ntarget coverage, we propose Density sampling, which models the data\ndistribution to select a diverse sample. In our comparison of 19 samplers,\ninvolving hundreds of evaluation tasks and pre-training runs, we find that\nAsk-LLM and Density are the best methods in their respective categories.\nCoverage sampling can recover the performance of the full data, while models\ntrained on Ask-LLM data consistently outperform full-data training -- even when\nwe reject 90% of the original dataset, while converging up to 70% faster.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review. 44 pages, 30 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.09668v1",
    "published_date": "2024-02-15 02:27:57 UTC",
    "updated_date": "2024-02-15 02:27:57 UTC"
  },
  {
    "arxiv_id": "2402.09664v4",
    "title": "CodeMind: A Framework to Challenge Large Language Models for Code Reasoning",
    "authors": [
      "Changshu Liu",
      "Shizhuo Dylan Zhang",
      "Ali Reza Ibrahimzada",
      "Reyhaneh Jabbarvand"
    ],
    "abstract": "Solely relying on test passing to evaluate Large Language Models (LLMs) for\ncode synthesis may result in unfair assessment or promoting models with data\nleakage. As an alternative, we introduce CodeMind, a framework designed to\ngauge the code reasoning abilities of LLMs. CodeMind currently supports three\ncode reasoning tasks: Independent Execution Reasoning (IER), Dependent\nExecution Reasoning (DER), and Specification Reasoning (SR). The first two\nevaluate models to predict the execution output of an arbitrary code or code\nthe model could correctly synthesize. The third one evaluates the extent to\nwhich LLMs implement the specified expected behavior.\n  Our extensive evaluation of nine LLMs across five benchmarks in two different\nprogramming languages using CodeMind shows that LLMs fairly follow control flow\nconstructs and, in general, explain how inputs evolve to output, specifically\nfor simple programs and the ones they can correctly synthesize. However, their\nperformance drops for code with higher complexity, non-trivial logical and\narithmetic operators, non-primitive types, and API calls. Furthermore, we\nobserve that, while correlated, specification reasoning (essential for code\nsynthesis) does not imply execution reasoning (essential for broader\nprogramming tasks such as testing and debugging): ranking LLMs based on test\npassing can be different compared to code reasoning.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09664v4",
    "published_date": "2024-02-15 02:24:46 UTC",
    "updated_date": "2024-04-03 06:23:48 UTC"
  },
  {
    "arxiv_id": "2402.09660v2",
    "title": "User Modeling and User Profiling: A Comprehensive Survey",
    "authors": [
      "Erasmo Purificato",
      "Ludovico Boratto",
      "Ernesto William De Luca"
    ],
    "abstract": "The integration of artificial intelligence (AI) into daily life, particularly\nthrough information retrieval and recommender systems, has necessitated\nadvanced user modeling and profiling techniques to deliver personalized\nexperiences. These techniques aim to construct accurate user representations\nbased on the rich amounts of data generated through interactions with these\nsystems. This paper presents a comprehensive survey of the current state,\nevolution, and future directions of user modeling and profiling research. We\nprovide a historical overview, tracing the development from early stereotype\nmodels to the latest deep learning techniques, and propose a novel taxonomy\nthat encompasses all active topics in this research area, including recent\ntrends. Our survey highlights the paradigm shifts towards more sophisticated\nuser profiling methods, emphasizing implicit data collection, multi-behavior\nmodeling, and the integration of graph data structures. We also address the\ncritical need for privacy-preserving techniques and the push towards\nexplainability and fairness in user modeling approaches. By examining the\ndefinitions of core terminology, we aim to clarify ambiguities and foster a\nclearer understanding of the field by proposing two novel encyclopedic\ndefinitions of the main terms. Furthermore, we explore the application of user\nmodeling in various domains, such as fake news detection, cybersecurity, and\npersonalized education. This survey serves as a comprehensive resource for\nresearchers and practitioners, offering insights into the evolution of user\nmodeling and profiling and guiding the development of more personalized,\nethical, and effective AI systems.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG",
      "cs.SI",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "71 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.09660v2",
    "published_date": "2024-02-15 02:06:06 UTC",
    "updated_date": "2024-02-20 23:43:20 UTC"
  },
  {
    "arxiv_id": "2403.03222v1",
    "title": "Knowledge-guided EEG Representation Learning",
    "authors": [
      "Aditya Kommineni",
      "Kleanthis Avramidis",
      "Richard Leahy",
      "Shrikanth Narayanan"
    ],
    "abstract": "Self-supervised learning has produced impressive results in multimedia\ndomains of audio, vision and speech. This paradigm is equally, if not more,\nrelevant for the domain of biosignals, owing to the scarcity of labelled data\nin such scenarios. The ability to leverage large-scale unlabelled data to learn\nrobust representations could help improve the performance of numerous inference\ntasks on biosignals. Given the inherent domain differences between multimedia\nmodalities and biosignals, the established objectives for self-supervised\nlearning may not translate well to this domain. Hence, there is an unmet need\nto adapt these methods to biosignal analysis. In this work we propose a\nself-supervised model for EEG, which provides robust performance and remarkable\nparameter efficiency by using state space-based deep learning architecture. We\nalso propose a novel knowledge-guided pre-training objective that accounts for\nthe idiosyncrasies of the EEG signal. The results indicate improved embedding\nrepresentation learning and downstream performance compared to prior works on\nexemplary tasks. Also, the proposed objective significantly reduces the amount\nof pre-training data required to obtain performance equivalent to prior works.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "6 Pages, 5 figures, Submitted to EMBC 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.03222v1",
    "published_date": "2024-02-15 01:52:44 UTC",
    "updated_date": "2024-02-15 01:52:44 UTC"
  },
  {
    "arxiv_id": "2402.09656v4",
    "title": "The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse",
    "authors": [
      "Wanli Yang",
      "Fei Sun",
      "Xinyu Ma",
      "Xun Liu",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "abstract": "Although model editing has shown promise in revising knowledge in Large\nLanguage Models (LLMs), its impact on the inherent capabilities of LLMs is\noften overlooked. In this work, we reveal a critical phenomenon: even a single\nedit can trigger model collapse, manifesting as significant performance\ndegradation in various benchmark tasks. However, benchmarking LLMs after each\nedit, while necessary to prevent such collapses, is impractically\ntime-consuming and resource-intensive. To mitigate this, we propose using\nperplexity as a surrogate metric, validated by extensive experiments\ndemonstrating changes in an edited model's perplexity are strongly correlated\nwith its downstream task performances. We further conduct an in-depth study on\nsequential editing, a practical setting for real-world scenarios, across\nvarious editing methods and LLMs, focusing on hard cases from our previous\nsingle edit studies. The results indicate that nearly all examined editing\nmethods result in model collapse after only few edits. To facilitate further\nresearch, we have utilized GPT-3.5 to develop a new dataset, HardEdit, based on\nthose hard cases. This dataset aims to establish the foundation for pioneering\nresearch in reliable model editing and the mechanisms underlying\nediting-induced model collapse. We hope this work can draw the community's\nattention to the potential risks inherent in model editing practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09656v4",
    "published_date": "2024-02-15 01:50:38 UTC",
    "updated_date": "2024-06-05 09:43:00 UTC"
  },
  {
    "arxiv_id": "2402.09654v2",
    "title": "GPT-4's assessment of its performance in a USMLE-based case study",
    "authors": [
      "Uttam Dhakal",
      "Aniket Kumar Singh",
      "Suman Devkota",
      "Yogesh Sapkota",
      "Bishal Lamichhane",
      "Suprinsa Paudyal",
      "Chandra Dhakal"
    ],
    "abstract": "This study investigates GPT-4's assessment of its performance in healthcare\napplications. A simple prompting technique was used to prompt the LLM with\nquestions taken from the United States Medical Licensing Examination (USMLE)\nquestionnaire and it was tasked to evaluate its confidence score before posing\nthe question and after asking the question. The questionnaire was categorized\ninto two groups-questions with feedback (WF) and questions with no feedback(NF)\npost-question. The model was asked to provide absolute and relative confidence\nscores before and after each question. The experimental findings were analyzed\nusing statistical tools to study the variability of confidence in WF and NF\ngroups. Additionally, a sequential analysis was conducted to observe the\nperformance variation for the WF and NF groups. Results indicate that feedback\ninfluences relative confidence but doesn't consistently increase or decrease\nit. Understanding the performance of LLM is paramount in exploring its utility\nin sensitive areas like healthcare. This study contributes to the ongoing\ndiscourse on the reliability of AI, particularly of LLMs like GPT-4, within\nhealthcare, offering insights into how feedback mechanisms might be optimized\nto enhance AI-assisted medical education and decision support.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.MA",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09654v2",
    "published_date": "2024-02-15 01:38:50 UTC",
    "updated_date": "2024-03-26 20:12:18 UTC"
  },
  {
    "arxiv_id": "2402.09649v2",
    "title": "ProtChatGPT: Towards Understanding Proteins with Large Language Models",
    "authors": [
      "Chao Wang",
      "Hehe Fan",
      "Ruijie Quan",
      "Yi Yang"
    ],
    "abstract": "Protein research is crucial in various fundamental disciplines, but\nunderstanding their intricate structure-function relationships remains\nchallenging. Recent Large Language Models (LLMs) have made significant strides\nin comprehending task-specific knowledge, suggesting the potential for\nChatGPT-like systems specialized in protein to facilitate basic research. In\nthis work, we introduce ProtChatGPT, which aims at learning and understanding\nprotein structures via natural languages. ProtChatGPT enables users to upload\nproteins, ask questions, and engage in interactive conversations to produce\ncomprehensive answers. The system comprises protein encoders, a\nProtein-Language Pertaining Transformer (PLP-former), a projection adapter, and\nan LLM. The protein first undergoes protein encoders and PLP-former to produce\nprotein embeddings, which are then projected by the adapter to conform with the\nLLM. The LLM finally combines user questions with projected embeddings to\ngenerate informative answers. Experiments show that ProtChatGPT can produce\npromising responses to proteins and their corresponding questions. We hope that\nProtChatGPT could form the basis for further exploration and application in\nprotein research. Code and our pre-trained model will be publicly available.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09649v2",
    "published_date": "2024-02-15 01:22:30 UTC",
    "updated_date": "2025-01-23 06:30:10 UTC"
  }
]