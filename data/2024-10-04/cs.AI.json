{
  "date": "2024-10-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-04 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型优化（如 Mamba 和扩散模型）、LLM 的安全与编辑、多模态学习、机器人应用以及图神经网络等领域。其中，Mamba 模型的扩展和 LLM 知识编辑（如 Chain-of-Jailbreak）最为令人印象深刻，而著名学者如 Jitendra Malik 的机器人相关工作也值得关注。以下是关键论文的简要概述，我会优先讨论重要或创新性强的文章，并快速掠过较常规或次要的。\n\n### 重点论文讨论\n\n**Exploring the Benefit of Activation Sparsity in Pre-training（探索激活稀疏性的益处于预训练）**  \n这篇论文探讨了在预训练中利用激活稀疏性来提升模型效率，主要贡献是通过稀疏激活机制优化 Transformer 模型，显著减少计算开销，同时保持性能。该方法在序列建模任务中表现出色，适用于资源受限的场景。\n\n**Diffusion State-Guided Projected Gradient for Inverse Problems（扩散状态引导的投影梯度用于逆问题）**  \n作者提出了一种新方法，将扩散模型用于逆问题（如图像恢复），核心发现是通过状态引导的投影梯度提升鲁棒性。该工作在图像处理领域有实际应用潜力，显著提高了生成模型的鲁棒性和效率。\n\n**Chain-of-Jailbreak Attack for Image Generation Models（基于逐步编辑的图像生成模型越狱攻击链）**  \n这篇论文揭示了图像生成模型（如 Stable Diffusion）的安全漏洞，主要贡献是提出 Chain-of-Jailbreak 攻击框架，通过逐步编辑绕过安全机制。作者还设计了防御方法 Think Twice Prompting，能有效缓解攻击，强调了 AI 安全的重要性。\n\n**Learning Object Properties Using Robot Proprioception via Differentiable Robot-Object Interaction（通过可微机器人-物体交互学习物体属性）**  \n著名学者 Jitendra Malik 参与的工作，聚焦机器人感知。主要发现是通过可微模拟从机器人本体数据推断物体属性（如质量和柔软度），无需外部传感器。该方法提升了机器人在未知环境中的适应性。\n\n**Geometric Representation Condition Improves Equivariant Molecule Generation（几何表示条件提升等变分子生成）**  \n论文引入几何表示条件来优化分子生成模型，核心贡献是分解生成过程为两阶段，提高了生成质量和效率。该方法在药物设计领域有潜力，显著改善了分子结构的准确性。\n\n**SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation（SwiftKV: 通过知识保留模型转换实现快速预填充优化推理）**  \n作者提出 SwiftKV 框架，用于加速 LLM 推理，主要发现是通过模型转换减少计算和内存需求，同时保持生成质量。该工作在实际部署中表现出色，支持更大批量处理。\n\n**Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery（朝向实时肝内血管识别在术中超声引导肝手术中）**  \n这篇论文开发了基于深度学习的实时血管识别系统，主要贡献是使用患者特定模型提升手术精度。该方法在医疗应用中潜力巨大，能辅助外科医生。\n\n**GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs（GenSim2: 使用多模态和推理LLM扩展机器人数据生成）**  \n论文扩展了机器人数据生成框架，主要发现是通过 LLM 生成高质量模拟数据，提升零样本转移性能。该工作在机器人训练中实用性强。\n\n其他论文如那些涉及图神经网络（如 GraphCroc）、强化学习或常规分类任务（如 Stock Trend Prediction），虽有贡献但相对常规，我这里快速掠过：它们主要优化了特定领域模型的性能，但未带来突破性创新。例如，\"GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction\"（GraphCroc: 用于图结构重建的交叉相关自编码器）改进了图重建，但限于学术方法。\n\n总之，今天的论文突显了 AI 模型效率、安全和应用的进展，建议关注 LLM 和机器人领域的创新，以推动实际部署。如果您对特定主题感兴趣，欢迎进一步探讨！",
  "papers": [
    {
      "arxiv_id": "2410.03977v2",
      "title": "Learning to Balance: Diverse Normalization for Cloth-Changing Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Zhengwei Yin",
        "Xuan Song",
        "Yinqiang Zheng"
      ],
      "abstract": "Cloth-Changing Person Re-Identification (CC-ReID) involves recognizing\nindividuals in images regardless of clothing status. In this paper, we\nempirically and experimentally demonstrate that completely eliminating or fully\nretaining clothing features is detrimental to the task. Existing work, either\nrelying on clothing labels, silhouettes, or other auxiliary data, fundamentally\naim to balance the learning of clothing and identity features. However, we\npractically find that achieving this balance is challenging and nuanced. In\nthis study, we introduce a novel module called Diverse Norm, which expands\npersonal features into orthogonal spaces and employs channel attention to\nseparate clothing and identity features. A sample re-weighting optimization\nstrategy is also introduced to guarantee the opposite optimization direction.\nDiverse Norm presents a simple yet effective approach that does not require\nadditional data. Furthermore, Diverse Norm can be seamlessly integrated\nResNet50 and significantly outperforms the state-of-the-art methods.",
      "tldr_zh": "本研究针对 Cloth-Changing Person Re-Identification (CC-ReID) 任务，即识别穿着变化的个体，证明完全消除或保留衣物特征均会损害性能。论文提出 Diverse Norm 模块，将个人特征扩展到正交空间，并利用通道注意力分离衣物和身份特征，同时引入样本再加权优化策略来确保优化方向相反。该方法无需额外数据，可无缝整合到 ResNet50 中，并显著优于现有技术，在实验中实现了更好的平衡和识别准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03977v2",
      "published_date": "2024-10-04 23:33:08 UTC",
      "updated_date": "2024-10-14 09:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:59:52.435916"
    },
    {
      "arxiv_id": "2410.03974v2",
      "title": "Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport",
      "title_zh": "利用半不平衡神经最优传输的稳健重心估计",
      "authors": [
        "Milena Gazdieva",
        "Jaemoo Choi",
        "Alexander Kolesov",
        "Jaewoong Choi",
        "Petr Mokrov",
        "Alexander Korotin"
      ],
      "abstract": "Aggregating data from multiple sources can be formalized as an Optimal\nTransport (OT) barycenter problem, which seeks to compute the average of\nprobability distributions with respect to OT discrepancies. However, in\nreal-world scenarios, the presence of outliers and noise in the data measures\ncan significantly hinder the performance of traditional statistical methods for\nestimating OT barycenters. To address this issue, we propose a novel scalable\napproach for estimating the robust continuous barycenter, leveraging the dual\nformulation of the (semi-)unbalanced OT problem. To the best of our knowledge,\nthis paper is the first attempt to develop an algorithm for robust barycenters\nunder the continuous distribution setup. Our method is framed as a min-max\noptimization problem and is adaptable to general cost functions. We rigorously\nestablish the theoretical underpinnings of the proposed method and demonstrate\nits robustness to outliers and class imbalance through a number of illustrative\nexperiments. Our source code is publicly available at\nhttps://github.com/milenagazdieva/U-NOTBarycenters.",
      "tldr_zh": "本研究针对 Optimal Transport (OT) barycenter 问题中异常值和噪声的干扰，提出了一种可扩展的鲁棒估计方法，利用 semi-unbalanced Neural Optimal Transport 的双重公式来计算连续分布的重心。该方法被表述为一个 min-max 优化问题，适用于一般成本函数，并首次在连续分布设置下开发了鲁棒 barycenter 算法。实验结果证明，该方法对异常值和类别不平衡表现出色，显著提升了性能，并提供了开源代码以供进一步验证。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "30 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03974v2",
      "published_date": "2024-10-04 23:27:33 UTC",
      "updated_date": "2025-04-14 04:16:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T06:59:54.435016"
    },
    {
      "arxiv_id": "2410.03968v3",
      "title": "Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Sijin Chen",
        "Omar Hagrass",
        "Jason M. Klusowski"
      ],
      "abstract": "Decoding strategies play a pivotal role in text generation for modern\nlanguage models, yet a puzzling gap divides theory and practice. Surprisingly,\nstrategies that should intuitively be optimal, such as Maximum a Posteriori\n(MAP), often perform poorly in practice. Meanwhile, popular heuristic\napproaches like Top-$k$ and Nucleus sampling, which employ truncation and\nnormalization of the conditional next-token probabilities, have achieved great\nempirical success but lack theoretical justifications. In this paper, we\npropose Decoding Game, a comprehensive theoretical framework which reimagines\ntext generation as a two-player zero-sum game between Strategist, who seeks to\nproduce text credible in the true distribution, and Nature, who distorts the\ntrue distribution adversarially. After discussing the decomposibility of\nmulti-step generation, we derive the optimal strategy in closed form for\none-step Decoding Game. It is shown that the adversarial Nature imposes an\nimplicit regularization on likelihood maximization, and\ntruncation-normalization methods are first-order approximations to the optimal\nstrategy under this regularization. Additionally, by generalizing the objective\nand parameters of Decoding Game, near-optimal strategies encompass diverse\nmethods such as greedy search, temperature scaling, and hybrids thereof.\nNumerical experiments are conducted to complement our theoretical analysis.",
      "tldr_zh": "这篇论文探讨了文本生成中解码策略的理论与实践脱节问题，指出传统最优策略如Maximum a Posteriori (MAP)实际表现较差，而启发式方法如Top-$k$和Nucleus sampling虽有效却缺乏理论支撑。论文提出Decoding Game框架，将文本生成视为Strategist与Nature的两玩家零和游戏，导出了单步生成的最优策略，并证明Nature的对抗性引入了对似然最大化的隐式正则化，使截断-归一化方法成为其一阶近似。通过扩展框架，论文涵盖了贪婪搜索、温度缩放等策略，并通过数值实验验证了这些分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03968v3",
      "published_date": "2024-10-04 23:18:27 UTC",
      "updated_date": "2025-05-17 00:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:00:08.198909"
    },
    {
      "arxiv_id": "2410.03964v2",
      "title": "Variational Language Concepts for Interpreting Foundation Language Models",
      "title_zh": "变分语言概念用于解释基础语言模型",
      "authors": [
        "Hengyi Wang",
        "Shiwei Tan",
        "Zhiqing Hong",
        "Desheng Zhang",
        "Hao Wang"
      ],
      "abstract": "Foundation Language Models (FLMs) such as BERT and its variants have achieved\nremarkable success in natural language processing. To date, the\ninterpretability of FLMs has primarily relied on the attention weights in their\nself-attention layers. However, these attention weights only provide word-level\ninterpretations, failing to capture higher-level structures, and are therefore\nlacking in readability and intuitiveness. To address this challenge, we first\nprovide a formal definition of conceptual interpretation and then propose a\nvariational Bayesian framework, dubbed VAriational Language Concept (VALC), to\ngo beyond word-level interpretations and provide concept-level interpretations.\nOur theoretical analysis shows that our VALC finds the optimal language\nconcepts to interpret FLM predictions. Empirical results on several real-world\ndatasets show that our method can successfully provide conceptual\ninterpretation for FLMs.",
      "tldr_zh": "本研究针对 Foundation Language Models (FLMs) 如 BERT 的解释性问题，指出现有依赖注意力 weights 的方法仅限于词级别，缺乏可读性和直观性。作者首先正式定义了概念解释，然后提出一个变分贝叶斯框架 VAriational Language Concept (VALC)，用于提供概念级别的解释，并通过理论分析证明其能找到最优语言概念来解读 FLM 的预测。在多个真实数据集上的实证结果显示，VALC 成功实现了概念解释，提升了模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.03964v2",
      "published_date": "2024-10-04 23:05:19 UTC",
      "updated_date": "2024-10-28 19:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:00:18.843054"
    },
    {
      "arxiv_id": "2410.16282v2",
      "title": "Optimal Ground Station Selection for Low-Earth Orbiting Satellites",
      "title_zh": "低地球轨道卫星的最优地面站选择",
      "authors": [
        "Duncan Eddy",
        "Michelle Ho",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "This paper presents a solution to the problem of optimal ground station\nselection for low-Earth orbiting (LEO) space missions that enables mission\noperators to precisely design their ground segment performance and costs. Space\nmission operators are increasingly turning to Ground-Station-as-a-Service\n(GSaaS) providers to supply the terrestrial communications segment to reduce\ncosts and increase network size. However, this approach leads to a new\nchallenge of selecting the optimal service providers and station locations for\na given mission. We consider the problem of ground station selection as an\noptimization problem and present a general solution framework that allows\nmission designers to set their overall optimization objective and constrain key\nmission performance variables such as total data downlink, total mission cost,\nrecurring operational cost, and maximum communications time-gap. We solve the\nproblem using integer programming (IP). To address computational scaling\nchallenges, we introduce a surrogate optimization approach where the optimal\nstation selection is determined based on solving the problem over a reduced\ntime domain. Two different IP formulations are evaluated using randomized\nselections of LEO satellites of varying constellation sizes. We consider the\nnetworks of the commercial GSaaS providers Atlas Space Operations, Amazon Web\nServices (AWS) Ground Station, Azure Orbital Ground Station, Kongsberg\nSatellite Services (KSAT), Leaf Space, and Viasat Real-Time Earth. We compare\nour results against standard operational practices of integrating with one or\ntwo primary ground station providers.",
      "tldr_zh": "这篇论文针对低地球轨道(LEO)卫星任务，提出了一种优化地面站选择的解决方案框架，允许任务设计者设定总体优化目标并约束关键变量，如总数据下行量、任务成本、运营成本和最大通信间隙。\n他们将问题建模为整数规划(IP)优化问题，并引入代理优化方法，通过在减少的时间域上求解来应对计算规模挑战。\n实验评估了两种IP公式，使用随机选择的LEO卫星星座，并与商业GSaaS提供者（如Atlas Space Operations和AWS Ground Station）的网络进行比较，结果显示该方法比标准实践（如单一或双提供者）提高了性能。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "13 pages, 3 tables, 4 figures, presented at IEEE Aeroconf 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.16282v2",
      "published_date": "2024-10-04 22:48:50 UTC",
      "updated_date": "2025-03-02 01:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:00:31.303000"
    },
    {
      "arxiv_id": "2410.03960v2",
      "title": "SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Aurick Qiao",
        "Zhewei Yao",
        "Samyam Rajbhandari",
        "Yuxiong He"
      ],
      "abstract": "LLM inference for popular enterprise use cases, such as summarization, RAG,\nand code-generation, typically observes orders of magnitude longer prompt\nlengths than generation lengths. This characteristic leads to high cost of\nprefill and increased response latency. In this paper, we present SwiftKV, a\nnovel model transformation and distillation procedure specifically designed to\nreduce the time and cost of processing prompt tokens while preserving high\nquality of generated tokens. SwiftKV combines three key mechanisms: i)\nSingleInputKV, which prefills later layers' KV cache using a much earlier\nlayer's output, allowing prompt tokens to skip much of the model computation,\nii) AcrossKV, which merges the KV caches of neighboring layers to reduce the\nmemory footprint and support larger batch size for higher throughput, and iii)\na knowledge-preserving distillation procedure that can adapt existing LLMs for\nSwiftKV with minimal accuracy impact and low compute and data requirement. For\nLlama-3.1-8B and 70B, SwiftKV reduces the compute requirement of prefill by 50%\nand the memory requirement of the KV cache by 62.5% while incurring minimum\nquality degradation across a wide range of tasks. In the end-to-end inference\nserving using an optimized vLLM implementation, SwiftKV realizes up to 2x\nhigher aggregate throughput and 60% lower time per output token. It can achieve\na staggering 560 TFlops/GPU of normalized inference throughput, which\ntranslates to 16K tokens/s for Llama-3.1-70B in 16-bit precision on 4x H100\nGPUs. Our training, inference, and model implementations are open-sourced and\ncan be found through\nhttps://huggingface.co/collections/Snowflake/swiftkv-models-674f7d7474eb789e185d31cb.",
      "tldr_zh": "这篇论文介绍了 SwiftKV，一种专为大型语言模型(LLM)推理优化的模型转换和蒸馏方法，针对企业应用如总结、RAG和代码生成中提示长度远超生成长度的场景，显著减少预填充计算成本和响应延迟，同时保持生成质量。SwiftKV 整合了三个关键机制：SingleInputKV（使用早期层输出预填充后期层以跳过大部分计算）、AcrossKV（合并相邻层 KV cache 减少内存占用并提升批量处理吞吐量），以及知识保留蒸馏过程，以低计算和数据需求适应现有 LLM。实验结果显示，对于 Llama-3.1-8B 和 70B 模型，SwiftKV 将预填充计算需求降低 50%、KV cache 内存需求降低 62.5%，并在端到端推理中实现高达 2x 聚合吞吐量和 60% 更低输出标记时间，达到 560 TFlops/GPU 的标准化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03960v2",
      "published_date": "2024-10-04 22:45:26 UTC",
      "updated_date": "2024-12-05 14:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:00:44.654057"
    },
    {
      "arxiv_id": "2410.03959v1",
      "title": "Grounding Language in Multi-Perspective Referential Communication",
      "title_zh": "在多视角指代通信中的语言接地",
      "authors": [
        "Zineng Tang",
        "Lingjun Mao",
        "Alane Suhr"
      ],
      "abstract": "We introduce a task and dataset for referring expression generation and\ncomprehension in multi-agent embodied environments. In this task, two agents in\na shared scene must take into account one another's visual perspective, which\nmay be different from their own, to both produce and understand references to\nobjects in a scene and the spatial relations between them. We collect a dataset\nof 2,970 human-written referring expressions, each paired with human\ncomprehension judgments, and evaluate the performance of automated models as\nspeakers and listeners paired with human partners, finding that model\nperformance in both reference generation and comprehension lags behind that of\npairs of human agents. Finally, we experiment training an open-weight speaker\nmodel with evidence of communicative success when paired with a listener,\nresulting in an improvement from 58.9 to 69.3% in communicative success and\neven outperforming the strongest proprietary model.",
      "tldr_zh": "本研究引入了一个多代理体环境中参照表达生成和理解的任务及数据集，要求两个代理体在共享场景中考虑彼此的视觉视角（可能不同），以生成和理解对场景对象及其空间关系的引用。数据集包含2,970个由人类编写的参照表达，并配有人类的理解判断。实验评估显示，自动化模型在与人类伙伴配对时，其生成和理解性能落后于人类代理体。最终，通过训练一个开源说话者模型并使用沟通成功证据，模型的沟通成功率从58.9%提升至69.3%，甚至超过了最强的专有模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.03959v1",
      "published_date": "2024-10-04 22:42:30 UTC",
      "updated_date": "2024-10-04 22:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:00:54.619876"
    },
    {
      "arxiv_id": "2410.03955v4",
      "title": "A Retention-Centric Framework for Continual Learning with Guaranteed Model Developmental Safety",
      "title_zh": "一个以保留为核心的持续学习框架，带有保证的模型开发安全",
      "authors": [
        "Gang Li",
        "Wendi Yu",
        "Yao Yao",
        "Wei Tong",
        "Yingbin Liang",
        "Qihang Lin",
        "Tianbao Yang"
      ],
      "abstract": "In real-world applications, learning-enabled systems often undergo iterative\nmodel development to address challenging or emerging tasks, which involve\ncollecting new data, training a new model and validating the model. This\ncontinual model development process raises a significant issue that acquiring\nnew or improving existing capabilities may inadvertently lose good capabilities\nof the old model, also known as catastrophic forgetting. While existing\ncontinual learning aims to mitigate catastrophic forgetting by trading off\nperformance on previous tasks and new tasks to ensure good average performance,\nit often falls short in cost-sensitive applications, where failing to preserve\nessential established capabilities introduces unforeseen costs and risks and\nsubstantial expenses for re-improving these capabilities. To address this\nissue, we impose a requirement on learning systems to ensure that a new model\nstrictly retains important capabilities of the old model while improving\ntarget-task performance, which we term model developmental safety. To ensure\nmodel developmental safety, we propose a retention-centric framework with\ndata-dependent constraints, and study how to continually develop a pretrained\nCLIP model for acquiring new or improving existing capabilities of image\nclassification. We propose an efficient constrained optimization algorithm with\ntheoretical guarantees and use its insights to finetune the CLIP model with\ntask-dependent heads for promoting the model developmental safety. Experiments\non autonomous driving and scene recognition datasets validate the efficacy of\nour method.",
      "tldr_zh": "本研究针对持续学习（continual learning）中的灾难性遗忘（catastrophic forgetting）问题，提出了一种以保留为中心的框架（retention-centric framework），强调模型开发安全（model developmental safety），即新模型必须严格保留旧模型的重要能力，同时提升目标任务性能，以避免成本敏感应用中的风险。框架通过数据依赖约束（data-dependent constraints）来持续开发预训练的 CLIP 模型，用于图像分类的新能力或现有能力的改进。作者设计了一种高效的约束优化算法（constrained optimization algorithm），并结合任务依赖头（task-dependent heads）进行模型微调，以确保开发过程的安全性。实验在自动驾驶和场景识别数据集上验证了该方法的有效性，展示了其在平衡保留与提升方面的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03955v4",
      "published_date": "2024-10-04 22:34:58 UTC",
      "updated_date": "2025-04-19 02:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:01:07.126795"
    },
    {
      "arxiv_id": "2410.03954v2",
      "title": "SDA-GRIN for Adaptive Spatial-Temporal Multivariate Time Series Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Eskandari",
        "Aman Anand",
        "Drishti Sharma",
        "Farhana Zulkernine"
      ],
      "abstract": "In various applications, the multivariate time series often suffers from\nmissing data. This issue can significantly disrupt systems that rely on the\ndata. Spatial and temporal dependencies can be leveraged to impute the missing\nsamples. Existing imputation methods often ignore dynamic changes in spatial\ndependencies. We propose a Spatial Dynamic Aware Graph Recurrent Imputation\nNetwork (SDA-GRIN) which is capable of capturing dynamic changes in spatial\ndependencies.SDA-GRIN leverages a multi-head attention mechanism to adapt graph\nstructures with time. SDA-GRIN models multivariate time series as a sequence of\ntemporal graphs and uses a recurrent message-passing architecture for\nimputation. We evaluate SDA-GRIN on four real-world datasets: SDA-GRIN improves\nMSE by 9.51% for the AQI and 9.40% for AQI-36. On the PEMS-BAY dataset, it\nachieves a 1.94% improvement in MSE. Detailed ablation study demonstrates the\neffect of window sizes and missing data on the performance of the method.\nProject page:https://ameskandari.github.io/sda-grin/",
      "tldr_zh": "这篇论文针对多变量时间序列数据的缺失问题，提出了一种自适应空间-时间插值方法SDA-GRIN。SDA-GRIN利用多头注意力机制动态捕捉空间依赖性的变化，并将时间序列建模为一系列时间图，通过循环消息传递架构进行插值。实验在四个真实数据集上显示，该方法将MSE改善了9.51%（AQI数据集）和9.40%（AQI-36数据集），在PEMS-BAY数据集上实现了1.94%的提升。消融研究进一步验证了窗口大小和缺失数据对性能的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03954v2",
      "published_date": "2024-10-04 22:32:08 UTC",
      "updated_date": "2025-05-05 15:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:01:19.931433"
    },
    {
      "arxiv_id": "2410.03952v2",
      "title": "A Brain-Inspired Regularizer for Adversarial Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Elie Attias",
        "Cengiz Pehlevan",
        "Dina Obeid"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) excel in many visual tasks, but they\ntend to be sensitive to slight input perturbations that are imperceptible to\nthe human eye, often resulting in task failures. Recent studies indicate that\ntraining CNNs with regularizers that promote brain-like representations, using\nneural recordings, can improve model robustness. However, the requirement to\nuse neural data severely restricts the utility of these methods. Is it possible\nto develop regularizers that mimic the computational function of neural\nregularizers without the need for neural recordings, thereby expanding the\nusability and effectiveness of these techniques? In this work, we inspect a\nneural regularizer introduced in Li et al. (2019) to extract its underlying\nstrength. The regularizer uses neural representational similarities, which we\nfind also correlate with pixel similarities. Motivated by this finding, we\nintroduce a new regularizer that retains the essence of the original but is\ncomputed using image pixel similarities, eliminating the need for neural\nrecordings. We show that our regularization method 1) significantly increases\nmodel robustness to a range of black box attacks on various datasets and 2) is\ncomputationally inexpensive and relies only on original datasets. Our work\nexplores how biologically motivated loss functions can be used to drive the\nperformance of artificial neural networks.",
      "tldr_zh": "这篇论文探讨了卷积神经网络 (CNNs) 在对抗性鲁棒性方面的不足，即对人类难以察觉的输入扰动高度敏感。作者分析了 Li et al. (2019) 的神经正则化器，发现其表示相似度与像素相似度相关，因此提出了一种新的基于像素相似度的正则化器，摒弃了对神经记录的依赖，仅使用原始图像数据。实验结果显示，该方法显著提升了模型对各种黑盒攻击的鲁棒性，同时计算成本低廉。该研究展示了生物启发的损失函数如何驱动人工神经网络 (ANNs) 的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages plus appendix, 10 figures (main text), 15 figures\n  (appendix), 3 tables (appendix)",
      "pdf_url": "http://arxiv.org/pdf/2410.03952v2",
      "published_date": "2024-10-04 22:30:47 UTC",
      "updated_date": "2024-10-11 01:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:01:31.961722"
    },
    {
      "arxiv_id": "2410.14700v1",
      "title": "Self-Supervised Keypoint Detection with Distilled Depth Keypoint Representation",
      "title_zh": "自监督关键",
      "authors": [
        "Aman Anand",
        "Elyas Rashno",
        "Amir Eskandari",
        "Farhana Zulkernine"
      ],
      "abstract": "Existing unsupervised keypoint detection methods apply artificial\ndeformations to images such as masking a significant portion of images and\nusing reconstruction of original image as a learning objective to detect\nkeypoints. However, this approach lacks depth information in the image and\noften detects keypoints on the background. To address this, we propose\nDistill-DKP, a novel cross-modal knowledge distillation framework that\nleverages depth maps and RGB images for keypoint detection in a self-supervised\nsetting. During training, Distill-DKP extracts embedding-level knowledge from a\ndepth-based teacher model to guide an image-based student model with inference\nrestricted to the student. Experiments show that Distill-DKP significantly\noutperforms previous unsupervised methods by reducing mean L2 error by 47.15%\non Human3.6M, mean average error by 5.67% on Taichi, and improving keypoints\naccuracy by 1.3% on DeepFashion dataset. Detailed ablation studies demonstrate\nthe sensitivity of knowledge distillation across different layers of the\nnetwork. Project Page: https://23wm13.github.io/distill-dkp/",
      "tldr_zh": "本研究针对现有无监督关键点检测方法的问题（如缺少深度信息导致关键点检测到背景），提出了一种名为 Distill-DKP 的新型跨模态知识 distillation 框架。该框架在 self-supervised 设置中，利用深度图的教师模型提取嵌入级知识，来指导 RGB 图像的学生模型，从而提升关键点检测的准确性。实验结果显示，Distill-DKP 在 Human3.6M 数据集上将平均 L2 错误减少 47.15%，在 Taichi 数据集上减少平均错误 5.67%，并在 DeepFashion 数据集上提高关键点准确率 1.3%。此外，详细的消融研究揭示了知识 distillation 在网络不同层面的敏感性，为未来关键点检测优化提供了洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14700v1",
      "published_date": "2024-10-04 22:14:08 UTC",
      "updated_date": "2024-10-04 22:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:01:44.187939"
    },
    {
      "arxiv_id": "2410.09080v2",
      "title": "Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Shang",
        "Shu Yang",
        "Weiqing He",
        "Tianhua Zhai",
        "Dawei Li",
        "Bojian Hou",
        "Tianlong Chen",
        "Jason H. Moore",
        "Marylyn D. Ritchie",
        "Li Shen"
      ],
      "abstract": "Growing evidence suggests that social determinants of health (SDoH), a set of\nnonmedical factors, affect individuals' risks of developing Alzheimer's disease\n(AD) and related dementias. Nevertheless, the etiological mechanisms underlying\nsuch relationships remain largely unclear, mainly due to difficulties in\ncollecting relevant information. This study presents a novel, automated\nframework that leverages recent advancements of large language model (LLM) and\nnatural language processing techniques to mine SDoH knowledge from extensive\nliterature and integrate it with AD-related biological entities extracted from\nthe general-purpose knowledge graph PrimeKG. Utilizing graph neural networks,\nwe performed link prediction tasks to evaluate the resultant SDoH-augmented\nknowledge graph. Our framework shows promise for enhancing knowledge discovery\nin AD and can be generalized to other SDoH-related research areas, offering a\nnew tool for exploring the impact of social determinants on health outcomes.\nOur code is available at: https://github.com/hwq0726/SDoHenPKG",
      "tldr_zh": "该研究探讨社会决定因素（SDoH）对阿尔茨海默病（AD）和相关痴呆风险的影响，提出一个自动化框架利用大型语言模型（LLM）和自然语言处理技术，从大量文献中挖掘SDoH知识，并将其整合到PrimeKG知识图谱中。框架通过图神经网络进行链接预测任务，评估增强后的知识图谱，以揭示SDoH与AD的潜在机制。结果显示，该方法有助于提升AD知识发现，并可推广至其他SDoH相关领域，相关代码已在GitHub开源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AMIA-IS'25: AMIA Informatics Summit",
      "pdf_url": "http://arxiv.org/pdf/2410.09080v2",
      "published_date": "2024-10-04 21:39:30 UTC",
      "updated_date": "2025-04-16 05:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:01:56.659958"
    },
    {
      "arxiv_id": "2410.03936v2",
      "title": "Learning Truncated Causal History Model for Video Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Amirhosein Ghasemabadi",
        "Muhammad Kamran Janjua",
        "Mohammad Salameh",
        "Di Niu"
      ],
      "abstract": "One key challenge to video restoration is to model the transition dynamics of\nvideo frames governed by motion. In this work, we propose TURTLE to learn the\ntruncated causal history model for efficient and high-performing video\nrestoration. Unlike traditional methods that process a range of contextual\nframes in parallel, TURTLE enhances efficiency by storing and summarizing a\ntruncated history of the input frame latent representation into an evolving\nhistorical state. This is achieved through a sophisticated similarity-based\nretrieval mechanism that implicitly accounts for inter-frame motion and\nalignment. The causal design in TURTLE enables recurrence in inference through\nstate-memorized historical features while allowing parallel training by\nsampling truncated video clips. We report new state-of-the-art results on a\nmultitude of video restoration benchmark tasks, including video desnowing,\nnighttime video deraining, video raindrops and rain streak removal, video\nsuper-resolution, real-world and synthetic video deblurring, and blind video\ndenoising while reducing the computational cost compared to existing best\ncontextual methods on all these tasks.",
      "tldr_zh": "这篇论文针对视频恢复中帧过渡动态（由运动控制）的关键挑战，提出了一种名为TURTLE的截断因果历史模型。该模型通过存储和总结输入帧的潜在表示到一个演化的历史状态，并采用基于相似性的检索机制来隐式处理帧间运动和对齐，从而实现高效的递归推理和并行训练。实验结果显示，TURTLE在多个基准任务上（如视频去雪、夜间视频去雨、视频超分辨率、视频去模糊和盲视频去噪）取得了新的最先进性能，同时比现有最佳上下文方法显著降低了计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024. 24 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03936v2",
      "published_date": "2024-10-04 21:31:02 UTC",
      "updated_date": "2024-10-15 15:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:02:09.340776"
    },
    {
      "arxiv_id": "2410.05312v1",
      "title": "An Intelligent Native Network Slicing Security Architecture Empowered by Federated Learning",
      "title_zh": "由联邦学习赋能的智能原生网络切片安全架构",
      "authors": [
        "Rodrigo Moreira",
        "Rodolfo S. Villaca",
        "Moises R. N. Ribeiro",
        "Joberto S. B. Martins",
        "Joao Henrique Correa",
        "Tereza C. Carvalho",
        "Flavio de Oliveira Silva"
      ],
      "abstract": "Network Slicing (NS) has transformed the landscape of resource sharing in\nnetworks, offering flexibility to support services and applications with highly\nvariable requirements in areas such as the next-generation 5G/6G mobile\nnetworks (NGMN), vehicular networks, industrial Internet of Things (IoT), and\nverticals. Although significant research and experimentation have driven the\ndevelopment of network slicing, existing architectures often fall short in\nintrinsic architectural intelligent security capabilities. This paper proposes\nan architecture-intelligent security mechanism to improve the NS solutions. We\nidealized a security-native architecture that deploys intelligent microservices\nas federated agents based on machine learning, providing intra-slice and\narchitectural operation security for the Slicing Future Internet\nInfrastructures (SFI2) reference architecture. It is noteworthy that federated\nlearning approaches match the highly distributed modern microservice-based\narchitectures, thus providing a unifying and scalable design choice for NS\nplatforms addressing both service and security. Using ML-Agents and Security\nAgents, our approach identified Distributed Denial-of-Service (DDoS) and\nintrusion attacks within the slice using generic and non-intrusive telemetry\nrecords, achieving an average accuracy of approximately $95.60\\%$ in the\nnetwork slicing architecture and $99.99\\%$ for the deployed slice --\nintra-slice. This result demonstrates the potential for leveraging\narchitectural operational security and introduces a promising new research\ndirection for network slicing architectures.",
      "tldr_zh": "本研究提出了一种基于Federated Learning的智能原生网络切片（Network Slicing）安全架构，旨在提升网络切片在5G/6G、车联网和工业IoT等领域的安全性，解决现有架构缺乏内在智能安全能力的不足。该架构采用分布式智能微服务，包括ML-Agents和Security Agents作为联邦代理，提供intra-slice和架构操作安全，通过非侵入式遥测记录检测DDoS和入侵攻击。实验结果显示，该方法在网络切片架构中平均准确率达95.60%，而在部署的切片内达到99.99%，为网络切片平台的安全性和可扩展性开辟了新研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NI",
        "I.2; I.6; F.2.2"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 12 figures, Future Generation Computer Systems (FGCS)",
      "pdf_url": "http://arxiv.org/pdf/2410.05312v1",
      "published_date": "2024-10-04 21:12:23 UTC",
      "updated_date": "2024-10-04 21:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:02:18.882839"
    },
    {
      "arxiv_id": "2410.05311v1",
      "title": "ConceptLens: from Pixels to Understanding",
      "title_zh": "ConceptLens：从像素到理解",
      "authors": [
        "Abhilekha Dalal",
        "Pascal Hitzler"
      ],
      "abstract": "ConceptLens is an innovative tool designed to illuminate the intricate\nworkings of deep neural networks (DNNs) by visualizing hidden neuron\nactivations. By integrating deep learning with symbolic methods, ConceptLens\noffers users a unique way to understand what triggers neuron activations and\nhow they respond to various stimuli. The tool uses error-margin analysis to\nprovide insights into the confidence levels of neuron activations, thereby\nenhancing the interpretability of DNNs. This paper presents an overview of\nConceptLens, its implementation, and its application in real-time visualization\nof neuron activations and error margins through bar charts.",
      "tldr_zh": "本研究引入了ConceptLens，一种创新工具，用于可视化深度神经网络(DNNs)的隐藏神经元激活，从而帮助用户理解触发这些激活的因素及其对各种刺激的响应。ConceptLens 通过整合深度学习和符号方法，并应用error-margin analysis 来评估神经元激活的置信度水平，从而提升DNNs 的可解释性。该工具实现了神经元激活和错误边界的实时可视化，例如通过条形图展示，提供了一个直观的框架来分析复杂模型的行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05311v1",
      "published_date": "2024-10-04 20:49:12 UTC",
      "updated_date": "2024-10-04 20:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:02:30.080211"
    },
    {
      "arxiv_id": "2410.03920v2",
      "title": "Learning Object Properties Using Robot Proprioception via Differentiable Robot-Object Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Yichen Chen",
        "Chao Liu",
        "Pingchuan Ma",
        "John Eastman",
        "Daniela Rus",
        "Dylan Randle",
        "Yuri Ivanov",
        "Wojciech Matusik"
      ],
      "abstract": "Differentiable simulation has become a powerful tool for system\nidentification. While prior work has focused on identifying robot properties\nusing robot-specific data or object properties using object-specific data, our\napproach calibrates object properties by using information from the robot,\nwithout relying on data from the object itself. Specifically, we utilize robot\njoint encoder information, which is commonly available in standard robotic\nsystems. Our key observation is that by analyzing the robot's reactions to\nmanipulated objects, we can infer properties of those objects, such as inertia\nand softness. Leveraging this insight, we develop differentiable simulations of\nrobot-object interactions to inversely identify the properties of the\nmanipulated objects. Our approach relies solely on proprioception -- the\nrobot's internal sensing capabilities -- and does not require external\nmeasurement tools or vision-based tracking systems. This general method is\napplicable to any articulated robot and requires only joint position\ninformation. We demonstrate the effectiveness of our method on a low-cost\nrobotic platform, achieving accurate mass and elastic modulus estimations of\nmanipulated objects with just a few seconds of computation on a laptop.",
      "tldr_zh": "本研究提出了一种利用机器人本体感知（proprioception）通过可微分机器人-物体交互（Differentiable Robot-Object Interaction）来学习物体属性的方法，无需依赖物体自身数据，仅使用机器人关节编码器信息。方法的核心在于分析机器人对物体操作的反应（如惯性（inertia）和柔软度（softness）），并通过可微分模拟逆向推断物体的属性，例如质量（mass）和弹性模量（elastic modulus）。该方法适用于任何关节机器人，仅需关节位置数据，且不依赖外部测量工具或视觉系统。在低成本机器人平台上实验证明，该方法能在几秒钟内实现物体属性的高精度估计，为机器人系统识别提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CE",
        "cs.CV",
        "physics.comp-ph"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
      "pdf_url": "http://arxiv.org/pdf/2410.03920v2",
      "published_date": "2024-10-04 20:48:38 UTC",
      "updated_date": "2025-03-08 04:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:02:43.117737"
    },
    {
      "arxiv_id": "2410.03913v1",
      "title": "Leveraging Fundamental Analysis for Stock Trend Prediction for Profit",
      "title_zh": "翻译失败",
      "authors": [
        "John Phan",
        "Hung-Fu Chang"
      ],
      "abstract": "This paper investigates the application of machine learning models, Long\nShort-Term Memory (LSTM), one-dimensional Convolutional Neural Networks (1D\nCNN), and Logistic Regression (LR), for predicting stock trends based on\nfundamental analysis. Unlike most existing studies that predominantly utilize\ntechnical or sentiment analysis, we emphasize the use of a company's financial\nstatements and intrinsic value for trend forecasting. Using a dataset of 269\ndata points from publicly traded companies across various sectors from 2019 to\n2023, we employ key financial ratios and the Discounted Cash Flow (DCF) model\nto formulate two prediction tasks: Annual Stock Price Difference (ASPD) and\nDifference between Current Stock Price and Intrinsic Value (DCSPIV). These\ntasks assess the likelihood of annual profit and current profitability,\nrespectively. Our results demonstrate that LR models outperform CNN and LSTM\nmodels, achieving an average test accuracy of 74.66% for ASPD and 72.85% for\nDCSPIV. This study contributes to the limited literature on integrating\nfundamental analysis into machine learning for stock prediction, offering\nvaluable insights for both academic research and practical investment\nstrategies. By leveraging fundamental data, our approach highlights the\npotential for long-term stock trend prediction, supporting portfolio managers\nin their decision-making processes.",
      "tldr_zh": "本研究探讨了利用基本面分析结合机器学习模型（LSTM、1D CNN 和 LR）预测股票趋势，重点使用公司财务报表和内在价值，而非技术或情绪分析。研究基于2019-2023年间269个数据点的财务比率和Discounted Cash Flow (DCF)模型，定义了两个预测任务：Annual Stock Price Difference (ASPD)用于评估年度利润可能性，以及Difference between Current Stock Price and Intrinsic Value (DCSPIV)用于判断当前盈利性。结果表明，LR模型在ASPD和DCSPIV任务上分别取得74.66%和72.85%的平均测试准确率，优于LSTM和1D CNN模型。该方法为整合基本面分析的股票预测提供了宝贵见解，支持学术研究和实际投资策略。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03913v1",
      "published_date": "2024-10-04 20:36:19 UTC",
      "updated_date": "2024-10-04 20:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:02:56.307779"
    },
    {
      "arxiv_id": "2410.03908v1",
      "title": "Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis",
      "title_zh": "尚未完全到位！评估大型语言模型用于共病",
      "authors": [
        "Amey Hengle",
        "Atharva Kulkarni",
        "Shantanu Patankar",
        "Madhumitha Chandrasekaran",
        "Sneha D'Silva",
        "Jemima Jacob",
        "Rashmi Gupta"
      ],
      "abstract": "In this study, we introduce ANGST, a novel, first-of-its kind benchmark for\ndepression-anxiety comorbidity classification from social media posts. Unlike\ncontemporary datasets that often oversimplify the intricate interplay between\ndifferent mental health disorders by treating them as isolated conditions,\nANGST enables multi-label classification, allowing each post to be\nsimultaneously identified as indicating depression and/or anxiety. Comprising\n2876 meticulously annotated posts by expert psychologists and an additional\n7667 silver-labeled posts, ANGST posits a more representative sample of online\nmental health discourse. Moreover, we benchmark ANGST using various\nstate-of-the-art language models, ranging from Mental-BERT to GPT-4. Our\nresults provide significant insights into the capabilities and limitations of\nthese models in complex diagnostic scenarios. While GPT-4 generally outperforms\nother models, none achieve an F1 score exceeding 72% in multi-class comorbid\nclassification, underscoring the ongoing challenges in applying language models\nto mental health diagnostics.",
      "tldr_zh": "本研究引入了ANGST，这是一个首创的基准数据集，用于从社交媒体帖子中进行抑郁-焦虑共病的多标签分类，与传统数据集不同，它允许帖子同时标识多种心理健康问题，并包含2876个专家标注帖子和7667个银标准帖子。研究者使用多种最先进语言模型（如Mental-BERT和GPT-4）对ANGST进行基准测试，以评估这些模型在复杂心理诊断场景中的性能。结果显示，GPT-4表现最佳，但所有模型在多类共病分类中的F1 score均未超过72%，突显了语言模型在心理健康诊断应用上的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03908v1",
      "published_date": "2024-10-04 20:24:11 UTC",
      "updated_date": "2024-10-04 20:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:03:06.785026"
    },
    {
      "arxiv_id": "2410.05310v2",
      "title": "An Approach To Enhance IoT Security In 6G Networks Through Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Navneet Kaur",
        "Lav Gupta"
      ],
      "abstract": "Wireless communication has evolved significantly, with 6G offering\ngroundbreaking capabilities, particularly for IoT. However, the integration of\nIoT into 6G presents new security challenges, expanding the attack surface due\nto vulnerabilities introduced by advanced technologies such as open RAN,\nterahertz (THz) communication, IRS, massive MIMO, and AI. Emerging threats like\nAI exploitation, virtualization risks, and evolving attacks, including data\nmanipulation and signal interference, further complicate security efforts. As\n6G standards are set to be finalized by 2030, work continues to align security\nmeasures with technological advances. However, substantial gaps remain in\nframeworks designed to secure integrated IoT and 6G systems. Our research\naddresses these challenges by utilizing tree-based machine learning algorithms\nto manage complex datasets and evaluate feature importance. We apply data\nbalancing techniques to ensure fair attack representation and use SHAP and LIME\nto improve model transparency. By aligning feature importance with XAI methods\nand cross-validating for consistency, we boost model accuracy and enhance IoT\nsecurity within the 6G ecosystem.",
      "tldr_zh": "本研究针对 6G 网络中 IoT 安全挑战（如攻击面扩大、AI 利用和信号干扰等风险）提出了一种基于 Explainable AI (XAI) 的增强方法，以填补现有安全框架的空白。研究采用 tree-based machine learning algorithms 处理复杂数据集，并通过数据平衡技术确保攻击表示的公平性，同时利用 SHAP 和 LIME 提升模型透明度和特征重要性评估。最终，通过特征对齐和交叉验证，该方法显著提高了模型准确性，并在 6G 生态中增强了 IoT 系统的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05310v2",
      "published_date": "2024-10-04 20:14:25 UTC",
      "updated_date": "2024-12-24 01:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:03:18.740206"
    },
    {
      "arxiv_id": "2410.03904v1",
      "title": "Did You Hear That? Introducing AADG: A Framework for Generating Benchmark Data in Audio Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ksheeraja Raghavan",
        "Samiran Gode",
        "Ankit Shah",
        "Surabhi Raghavan",
        "Wolfram Burgard",
        "Bhiksha Raj",
        "Rita Singh"
      ],
      "abstract": "We introduce a novel, general-purpose audio generation framework specifically\ndesigned for anomaly detection and localization. Unlike existing datasets that\npredominantly focus on industrial and machine-related sounds, our framework\nfocuses a broader range of environments, particularly useful in real-world\nscenarios where only audio data are available, such as in video-derived or\ntelephonic audio. To generate such data, we propose a new method inspired by\nthe LLM-Modulo framework, which leverages large language models(LLMs) as world\nmodels to simulate such real-world scenarios. This tool is modular allowing a\nplug-and-play approach. It operates by first using LLMs to predict plausible\nreal-world scenarios. An LLM further extracts the constituent sounds, the order\nand the way in which these should be merged to create coherent wholes. Much\nlike the LLM-Modulo framework, we include rigorous verification of each output\nstage, ensuring the reliability of the generated data. The data produced using\nthe framework serves as a benchmark for anomaly detection applications,\npotentially enhancing the performance of models trained on audio data,\nparticularly in handling out-of-distribution cases. Our contributions thus fill\na critical void in audio anomaly detection resources and provide a scalable\ntool for generating diverse, realistic audio data.",
      "tldr_zh": "本文引入 AADG 框架，这是一个通用音频生成工具，专门用于音频异常检测和定位的基准数据生成，覆盖更广泛的真实环境，如视频衍生或电话音频。框架受 LLM-Modulo 启发，利用 LLMs 作为世界模型来模拟真实场景，先预测场景细节，然后提取组成声音、顺序和合并方式，并通过严格验证确保数据可靠性。生成的基准数据可提升异常检测模型的性能，特别是处理 out-of-distribution 情况，并为音频异常检测资源提供可扩展的多样化工具。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.03904v1",
      "published_date": "2024-10-04 20:12:35 UTC",
      "updated_date": "2024-10-04 20:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:03:31.094786"
    },
    {
      "arxiv_id": "2410.03901v2",
      "title": "Improving Node Representation by Boosting Target-Aware Contrastive Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Ying-Chun Lin",
        "Jennifer Neville"
      ],
      "abstract": "Graphs model complex relationships between entities, with nodes and edges\ncapturing intricate connections. Node representation learning involves\ntransforming nodes into low-dimensional embeddings. These embeddings are\ntypically used as features for downstream tasks. Therefore, their quality has a\nsignificant impact on task performance. Existing approaches for node\nrepresentation learning span (semi-)supervised, unsupervised, and\nself-supervised paradigms. In graph domains, (semi-)supervised learning often\nonly optimizes models based on class labels, neglecting other abundant graph\nsignals, which limits generalization. While self-supervised or unsupervised\nlearning produces representations that better capture underlying graph signals,\nthe usefulness of these captured signals for downstream target tasks can vary.\nTo bridge this gap, we introduce Target-Aware Contrastive Learning\n(Target-aware CL) which aims to enhance target task performance by maximizing\nthe mutual information between the target task and node representations with a\nself-supervised learning process. This is achieved through a sampling function,\nXGBoost Sampler (XGSampler), to sample proper positive examples for the\nproposed Target-Aware Contrastive Loss (XTCL). By minimizing XTCL, Target-aware\nCL increases the mutual information between the target task and node\nrepresentations, such that model generalization is improved. Additionally,\nXGSampler enhances the interpretability of each signal by showing the weights\nfor sampling the proper positive examples. We show experimentally that XTCL\nsignificantly improves the performance on two target tasks: node classification\nand link prediction tasks, compared to state-of-the-art models.",
      "tldr_zh": "本研究针对图节点表示学习中的局限性，提出Target-Aware Contrastive Learning（Target-aware CL），旨在通过最大化目标任务与节点表示之间的互信息，提升下游任务性能。方法引入XGBoost Sampler（XGSampler）来采样合适的正例，并最小化Target-Aware Contrastive Loss（XTCL），从而优化模型泛化并增强信号的可解释性。实验结果显示，XTCL在节点分类和链接预测任务上显著优于现有模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03901v2",
      "published_date": "2024-10-04 20:08:24 UTC",
      "updated_date": "2024-11-01 15:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:03:52.958068"
    },
    {
      "arxiv_id": "2410.03893v1",
      "title": "Human-aligned Chess with a Bit of Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhang",
        "Athul Paul Jacob",
        "Vivian Lai",
        "Daniel Fried",
        "Daphne Ippolito"
      ],
      "abstract": "Chess has long been a testbed for AI's quest to match human intelligence, and\nin recent years, chess AI systems have surpassed the strongest humans at the\ngame. However, these systems are not human-aligned; they are unable to match\nthe skill levels of all human partners or model human-like behaviors beyond\npiece movement. In this paper, we introduce Allie, a chess-playing AI designed\nto bridge the gap between artificial and human intelligence in this classic\ngame. Allie is trained on log sequences of real chess games to model the\nbehaviors of human chess players across the skill spectrum, including non-move\nbehaviors such as pondering times and resignations In offline evaluations, we\nfind that Allie exhibits humanlike behavior: it outperforms the existing\nstate-of-the-art in human chess move prediction and \"ponders\" at critical\npositions. The model learns to reliably assign reward at each game state, which\ncan be used at inference as a reward function in a novel time-adaptive\nMonte-Carlo tree search (MCTS) procedure, where the amount of search depends on\nhow long humans would think in the same positions. Adaptive search enables\nremarkable skill calibration; in a large-scale online evaluation against\nplayers with ratings from 1000 to 2600 Elo, our adaptive search method leads to\na skill gap of only 49 Elo on average, substantially outperforming search-free\nand standard MCTS baselines. Against grandmaster-level (2500 Elo) opponents,\nAllie with adaptive search exhibits the strength of a fellow grandmaster, all\nwhile learning exclusively from humans.",
      "tldr_zh": "这篇论文引入了 Allie，一种国际象棋 AI，旨在通过训练真实棋局日志来模拟人类玩家的行为，包括走子、非走子行为（如思考时间和认输），从而实现更人性化的对弈。Allie 采用基于游戏状态奖励的自适应 Monte-Carlo tree search (MCTS) 方法，根据人类在相同位置的思考时间动态调整搜索深度。实验结果显示，Allie 在人类走子预测上优于现有技术，并在在线评估中对抗 1000 到 2600 Elo 玩家的对弈中，平均技能差距仅 49 Elo，甚至能与大师级对手（2500 Elo）匹敌。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03893v1",
      "published_date": "2024-10-04 19:51:03 UTC",
      "updated_date": "2024-10-04 19:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:03:56.163578"
    },
    {
      "arxiv_id": "2410.03892v1",
      "title": "Towards Cost Sensitive Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Junier Oliva"
      ],
      "abstract": "Many real-world situations allow for the acquisition of additional relevant\ninformation when making decisions with limited or uncertain data. However,\ntraditional RL approaches either require all features to be acquired beforehand\n(e.g. in a MDP) or regard part of them as missing data that cannot be acquired\n(e.g. in a POMDP). In this work, we consider RL models that may actively\nacquire features from the environment to improve the decision quality and\ncertainty, while automatically balancing the cost of feature acquisition\nprocess and the reward of task decision process. We propose the\nActive-Acquisition POMDP and identify two types of the acquisition process for\ndifferent application domains. In order to assist the agent in the\nactively-acquired partially-observed environment and alleviate the\nexploration-exploitation dilemma, we develop a model-based approach, where a\ndeep generative model is utilized to capture the dependencies of the features\nand impute the unobserved features. The imputations essentially represent the\nbeliefs of the agent. Equipped with the dynamics model, we develop hierarchical\nRL algorithms to resolve both types of the AA-POMDPs. Empirical results\ndemonstrate that our approach achieves considerably better performance than\nexisting POMDP-RL solutions.",
      "tldr_zh": "这篇论文针对决策中的不确定数据问题，提出 Active-Acquisition POMDP (AA-POMDP) 模型，允许 RL 代理主动获取环境特征以改善决策质量，同时自动平衡特征获取成本和任务奖励。方法包括使用深度生成模型捕获特征依赖关系并填充未观察特征，作为代理信念的表示，并开发分层 RL 算法来处理 AA-POMDP 的两种获取过程类型。实验结果表明，该方法在性能上显著优于现有 POMDP-RL 解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03892v1",
      "published_date": "2024-10-04 19:48:23 UTC",
      "updated_date": "2024-10-04 19:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:04:07.091913"
    },
    {
      "arxiv_id": "2410.03887v2",
      "title": "Solving Dual Sourcing Problems with Supply Mode Dependent Failure Rates",
      "title_zh": "解决具有供应模式相关故障",
      "authors": [
        "Fabian Akkerman",
        "Nils Knofius",
        "Matthieu van der Heijden",
        "Martijn Mes"
      ],
      "abstract": "This paper investigates dual sourcing problems with supply mode dependent\nfailure rates, particularly relevant in managing spare parts for\ndowntime-critical assets. To enhance resilience, businesses increasingly adopt\ndual sourcing strategies using both conventional and additive manufacturing\ntechniques. This paper explores how these strategies can optimise sourcing by\naddressing variations in part properties and failure rates. A significant\nchallenge is the distinct failure characteristics of parts produced by these\nmethods, which influence future demand. To tackle this, we propose a new\niterative heuristic and several reinforcement learning techniques combined with\nan endogenous parameterised learning (EPL) approach. This EPL approach -\ncompatible with any learning method - allows a single policy to handle various\ninput parameters for multiple items. In a stylised setting, our best policy\nachieves an average optimality gap of 0.4%. In a case study within the energy\nsector, our policies outperform the baseline in 91.1% of instances, yielding\naverage cost savings up to 22.6%.",
      "tldr_zh": "本文研究了双重采购（dual sourcing）问题，重点关注采购模式相关的故障率差异，尤其在管理关键资产备件时。该文提出了一种新的迭代启发式算法（iterative heuristic）和强化学习（reinforcement learning）技术，结合内生参数化学习（EPL）方法，使单一策略能处理多种输入参数，从而优化采购策略。实验结果显示，在模拟环境中该策略的优化差距平均为0.4%，而在能源行业案例中，它在91.1%的实例中优于基准方案，平均成本节省达22.6%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03887v2",
      "published_date": "2024-10-04 19:42:14 UTC",
      "updated_date": "2025-04-11 11:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:04:19.455245"
    },
    {
      "arxiv_id": "2410.03884v1",
      "title": "KidLM: Advancing Language Models for Children -- Early Insights and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Mir Tafseer Nayeem",
        "Davood Rafiei"
      ],
      "abstract": "Recent studies highlight the potential of large language models in creating\neducational tools for children, yet significant challenges remain in\nmaintaining key child-specific properties such as linguistic nuances, cognitive\nneeds, and safety standards. In this paper, we explore foundational steps\ntoward the development of child-specific language models, emphasizing the\nnecessity of high-quality pre-training data. We introduce a novel user-centric\ndata collection pipeline that involves gathering and validating a corpus\nspecifically written for and sometimes by children. Additionally, we propose a\nnew training objective, Stratified Masking, which dynamically adjusts masking\nprobabilities based on our domain-specific child language data, enabling models\nto prioritize vocabulary and concepts more suitable for children. Experimental\nevaluations demonstrate that our model excels in understanding lower\ngrade-level text, maintains safety by avoiding stereotypes, and captures\nchildren's unique preferences. Furthermore, we provide actionable insights for\nfuture research and development in child-specific language modeling.",
      "tldr_zh": "本论文探讨了大型语言模型（large language models）在儿童教育工具中的潜力，同时强调了维护儿童特定属性（如语言细微差别、认知需求和安全标准）的挑战。研究引入了一个用户导向数据收集管道，用于收集和验证专为儿童编写的语料，并提出Stratified Masking新训练目标，该方法根据儿童语言数据动态调整掩码概率，以优先处理适合儿童的词汇和概念。实验结果显示，KidLM模型在理解低年级文本、避免刻板印象和捕捉儿童偏好方面表现出色，并为未来儿童专用语言模型的研究提供了行动性见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (long, main)",
      "pdf_url": "http://arxiv.org/pdf/2410.03884v1",
      "published_date": "2024-10-04 19:35:44 UTC",
      "updated_date": "2024-10-04 19:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:04:31.368838"
    },
    {
      "arxiv_id": "2410.03869v1",
      "title": "Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Wang",
        "Kuiyi Gao",
        "Zihan Jia",
        "Youliang Yuan",
        "Jen-tse Huang",
        "Qiuzhi Liu",
        "Shuai Wang",
        "Wenxiang Jiao",
        "Zhaopeng Tu"
      ],
      "abstract": "Text-based image generation models, such as Stable Diffusion and DALL-E 3,\nhold significant potential in content creation and publishing workflows, making\nthem the focus in recent years. Despite their remarkable capability to generate\ndiverse and vivid images, considerable efforts are being made to prevent the\ngeneration of harmful content, such as abusive, violent, or pornographic\nmaterial. To assess the safety of existing models, we introduce a novel\njailbreaking method called Chain-of-Jailbreak (CoJ) attack, which compromises\nimage generation models through a step-by-step editing process. Specifically,\nfor malicious queries that cannot bypass the safeguards with a single prompt,\nwe intentionally decompose the query into multiple sub-queries. The image\ngeneration models are then prompted to generate and iteratively edit images\nbased on these sub-queries. To evaluate the effectiveness of our CoJ attack\nmethod, we constructed a comprehensive dataset, CoJ-Bench, encompassing nine\nsafety scenarios, three types of editing operations, and three editing\nelements. Experiments on four widely-used image generation services provided by\nGPT-4V, GPT-4o, Gemini 1.5 and Gemini 1.5 Pro, demonstrate that our CoJ attack\nmethod can successfully bypass the safeguards of models for over 60% cases,\nwhich significantly outperforms other jailbreaking methods (i.e., 14%).\nFurther, to enhance these models' safety against our CoJ attack method, we also\npropose an effective prompting-based method, Think Twice Prompting, that can\nsuccessfully defend over 95% of CoJ attack. We release our dataset and code to\nfacilitate the AI safety research.",
      "tldr_zh": "本文提出 Chain-of-Jailbreak (CoJ) 攻击方法，通过将恶意查询分解为多个子查询并逐步迭代编辑图像，来绕过文本-based 图像生成模型（如 Stable Diffusion 和 DALL-E 3）的安全防护。研究者构建了 CoJ-Bench 数据集，涵盖九种安全场景、三种编辑操作和三种编辑元素，并在 GPT-4V、GPT-4o、Gemini 1.5 和 Gemini 1.5 Pro 等模型上实验，证明 CoJ 攻击成功率超过 60%，远高于其他方法（14%）。此外，他们开发了 Think Twice Prompting 防御机制，能有效抵御超过 95% 的攻击，并公开数据集和代码以促进 AI 安全研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03869v1",
      "published_date": "2024-10-04 19:04:43 UTC",
      "updated_date": "2024-10-04 19:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:04:44.393723"
    },
    {
      "arxiv_id": "2410.03867v1",
      "title": "Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Di Pasquale",
        "Soledad Represa"
      ],
      "abstract": "In an era dominated by data, the management and utilization of\ndomain-specific language have emerged as critical challenges in various\napplication domains, particularly those with industry-specific requirements.\nOur work is driven by the need to effectively manage and process large volumes\nof short text documents inherent in specific application domains. By leveraging\ndomain-specific knowledge and expertise, our approach aims to shape factual\ndata within these domains, thereby facilitating enhanced utilization and\nunderstanding by end-users. Central to our methodology is the integration of\ndomain-specific language models with graph-oriented databases, facilitating\nseamless processing, analysis, and utilization of textual data within targeted\ndomains. Our work underscores the transformative potential of the partnership\nof domain-specific language models and graph-oriented databases. This\ncooperation aims to assist researchers and engineers in metric usage,\nmitigation of latency issues, boosting explainability, enhancing debug and\nimproving overall model performance. Moving forward, we envision our work as a\nguide AI engineers, providing valuable insights for the implementation of\ndomain-specific language models in conjunction with graph-oriented databases,\nand additionally provide valuable experience in full-life cycle maintenance of\nthis kind of products.",
      "tldr_zh": "本研究探讨了在数据主导时代如何管理领域特定语言模型（domain-specific language models），通过将其与图导向数据库（graph-oriented databases）整合，处理特定领域的海量短文本文档，从而提升数据处理、分析和利用效率。这种方法利用领域知识来优化模型性能，解决延迟问题、提升解释性、改进调试过程，并实现整体模型维护的范式转变（paradigm shift）。最终，该框架为AI工程师提供指导和全生命周期维护经验，促进更可靠的领域应用。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03867v1",
      "published_date": "2024-10-04 19:02:09 UTC",
      "updated_date": "2024-10-04 19:02:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:04:54.525222"
    },
    {
      "arxiv_id": "2410.03864v1",
      "title": "DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search",
      "title_zh": "DOTS：通过最优推理轨迹搜索在LLMs中动态学习推理",
      "authors": [
        "Murong Yue",
        "Wenlin Yao",
        "Haitao Mi",
        "Dian Yu",
        "Ziyu Yao",
        "Dong Yu"
      ],
      "abstract": "Enhancing the capability of large language models (LLMs) in reasoning has\ngained significant attention in recent years. Previous studies have\ndemonstrated the effectiveness of various prompting strategies in aiding LLMs\nin reasoning (called \"reasoning actions\"), such as step-by-step thinking,\nreflecting before answering, solving with programs, and their combinations.\nHowever, these approaches often applied static, predefined reasoning actions\nuniformly to all questions, without considering the specific characteristics of\neach question or the capability of the task-solving LLM. In this paper, we\npropose DOTS, an approach enabling LLMs to reason dynamically via optimal\nreasoning trajectory search, tailored to the specific characteristics of each\nquestion and the inherent capability of the task-solving LLM. Our approach\ninvolves three key steps: i) defining atomic reasoning action modules that can\nbe composed into various reasoning action trajectories; ii) searching for the\noptimal action trajectory for each training question through iterative\nexploration and evaluation for the specific task-solving LLM; and iii) using\nthe collected optimal trajectories to train an LLM to plan for the reasoning\ntrajectories of unseen questions. In particular, we propose two learning\nparadigms, i.e., fine-tuning an external LLM as a planner to guide the\ntask-solving LLM, or directly fine-tuning the task-solving LLM with an\ninternalized capability for reasoning actions planning. Our experiments across\neight reasoning tasks show that our method consistently outperforms static\nreasoning techniques and the vanilla instruction tuning approach. Further\nanalysis reveals that our method enables LLMs to adjust their computation based\non problem complexity, allocating deeper thinking and reasoning to harder\nproblems.",
      "tldr_zh": "本文提出 DOTS 方法，通过最优推理轨迹搜索（Optimal Reasoning Trajectories Search），让大型语言模型（LLMs）实现动态推理，针对每个问题的特性及模型能力进行个性化调整。方法包括定义原子推理动作模块、为训练问题迭代探索和评估最优轨迹，以及使用这些轨迹训练 LLM 来规划未见问题的推理路径。实验结果显示，DOTS 在八个推理任务上 consistently outperforms 静态推理技术和 vanilla 指令微调方法，并使 LLMs 根据问题复杂度分配更深入的计算资源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03864v1",
      "published_date": "2024-10-04 18:58:09 UTC",
      "updated_date": "2024-10-04 18:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:05:07.506229"
    },
    {
      "arxiv_id": "2410.10848v1",
      "title": "Crafting Narrative Closures: Zero-Shot Learning with SSM Mamba for Short Story Ending Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Divyam Sharma",
        "Divya Santhanam"
      ],
      "abstract": "Writing stories is an engaging yet challenging endeavor. Often, authors\nencounter moments of creative block, where the path forward in their narrative\nbecomes obscured. This paper is designed to address such moments by providing\nan innovative solution: A tool that completes stories based on given prompts.\nBy inputting a short story prompt, users can receive a conclusion to their\nstory, articulated in one sentence or more, thereby enhancing the storytelling\nprocess with AI-driven creativity. This tool aims not only to assist authors in\nnavigating writer's block but also to offer a fun and interactive way for\nanyone to expand on story ideas spontaneously. Through this paper, we explore\nthe intersection of artificial intelligence and creative writing, pushing the\nboundaries of how stories can be crafted and concluded. To create our final\ntext-generation models, we used a pre-trained GPT-3.5 model and a newly created\nfinetuned SSM-Mamba model, both of which perform well on a comprehensive list\nof metrics including BERT score, METEOR, BLEU, ROUGE, and Perplexity. The SSM\nmodel has also been made public for the NLP community on HuggingFace models as\nan open source contribution, which for the timebeing is a first of its kind\nstate-space model for story-generation task on HuggingFace.",
      "tldr_zh": "本论文提出了一种工具，用于解决故事写作中的创意阻塞问题，通过基于给定提示生成故事结尾，支持零样本学习（Zero-Shot Learning）。该工具利用预训练的 GPT-3.5 模型和一个新微调的 SSM Mamba 模型进行文本生成，在 BERT score、METEOR、BLEU、ROUGE 和 Perplexity 等指标上表现出色。论文还开源了 SSM Mamba 模型在 HuggingFace 上，作为首个用于故事生成任务的状态空间模型，推进了 AI 在创意写作领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.10848v1",
      "published_date": "2024-10-04 18:56:32 UTC",
      "updated_date": "2024-10-04 18:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:05:18.963701"
    },
    {
      "arxiv_id": "2410.09079v1",
      "title": "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models",
      "title_zh": "BIPEFT：预算引导的迭代搜索用于大型预训练语言",
      "authors": [
        "Aofei Chang",
        "Jiaqi Wang",
        "Han Liu",
        "Parminder Bhatia",
        "Cao Xiao",
        "Ting Wang",
        "Fenglong Ma"
      ],
      "abstract": "Parameter Efficient Fine-Tuning (PEFT) offers an efficient solution for\nfine-tuning large pretrained language models for downstream tasks. However,\nmost PEFT strategies are manually designed, often resulting in suboptimal\nperformance. Recent automatic PEFT approaches aim to address this but face\nchallenges such as search space entanglement, inefficiency, and lack of\nintegration between parameter budgets and search processes. To overcome these\nissues, we introduce a novel Budget-guided Iterative search strategy for\nautomatic PEFT (BIPEFT), significantly enhancing search efficiency. BIPEFT\nemploys a new iterative search strategy to disentangle the binary module and\nrank dimension search spaces. Additionally, we design early selection\nstrategies based on parameter budgets, accelerating the learning process by\ngradually removing unimportant modules and fixing rank dimensions. Extensive\nexperiments on public benchmarks demonstrate the superior performance of BIPEFT\nin achieving efficient and effective PEFT for downstream tasks with a low\nparameter budget.",
      "tldr_zh": "该研究针对 Parameter Efficient Fine-Tuning (PEFT) 的手动设计问题及其自动方法的效率不足（如搜索空间纠缠和缺乏参数预算整合），提出了一种新型 BIPEFT 框架。BIPEFT 通过预算引导的迭代搜索策略，将二进制模块和秩维度搜索空间分离，并采用早期选择机制逐步移除不重要模块并固定秩维度，从而显著提升搜索效率。在公共基准实验中，BIPEFT 在低参数预算下实现了高效且有效的 PEFT 性能，展现出优越的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2410.09079v1",
      "published_date": "2024-10-04 18:50:46 UTC",
      "updated_date": "2024-10-04 18:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:05:30.930829"
    },
    {
      "arxiv_id": "2410.03859v1",
      "title": "SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?",
      "title_zh": "SWE-bench Multimodal：AI 系统是否能泛化到视觉软件领域？",
      "authors": [
        "John Yang",
        "Carlos E. Jimenez",
        "Alex L. Zhang",
        "Kilian Lieret",
        "Joyce Yang",
        "Xindi Wu",
        "Ori Press",
        "Niklas Muennighoff",
        "Gabriel Synnaeve",
        "Karthik R. Narasimhan",
        "Diyi Yang",
        "Sida I. Wang",
        "Ofir Press"
      ],
      "abstract": "Autonomous systems for software engineering are now capable of fixing bugs\nand developing features. These systems are commonly evaluated on SWE-bench\n(Jimenez et al., 2024a), which assesses their ability to solve software issues\nfrom GitHub repositories. However, SWE-bench uses only Python repositories,\nwith problem statements presented predominantly as text and lacking visual\nelements such as images. This limited coverage motivates our inquiry into how\nexisting systems might perform on unrepresented software engineering domains\n(e.g., front-end, game development, DevOps), which use different programming\nlanguages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench\nM), to evaluate systems on their ability to fix bugs in visual, user-facing\nJavaScript software. SWE-bench M features 617 task instances collected from 17\nJavaScript libraries used for web interface design, diagramming, data\nvisualization, syntax highlighting, and interactive mapping. Each SWE-bench M\ntask instance contains at least one image in its problem statement or unit\ntests. Our analysis finds that top-performing SWE-bench systems struggle with\nSWE-bench M, revealing limitations in visual problem-solving and cross-language\ngeneralization. Lastly, we show that SWE-agent's flexible language-agnostic\nfeatures enable it to substantially outperform alternatives on SWE-bench M,\nresolving 12% of task instances compared to 6% for the next best system.",
      "tldr_zh": "该论文提出 SWE-bench Multimodal（SWE-bench M），一个新基准，用于评估 AI 系统在视觉软件领域（如前端开发和游戏制作）的泛化能力，解决现有 SWE-bench 只限于 Python 文本任务的局限性。SWE-bench M 包含 617 个任务实例，来自 17 个 JavaScript 库，涉及 web 接口设计、绘图、数据可视化等领域，每个任务均包括至少一个图像。实验结果显示，在 SWE-bench M 上表现最佳的系统难以处理视觉问题和跨语言挑战，导致性能下降。最终，SWE-agent 通过其语言无关特性表现出色，成功解决 12% 的任务实例，比次优系统高出一倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03859v1",
      "published_date": "2024-10-04 18:48:58 UTC",
      "updated_date": "2024-10-04 18:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:05:46.594965"
    },
    {
      "arxiv_id": "2410.03855v1",
      "title": "A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research",
      "title_zh": "翻译失败",
      "authors": [
        "Teresa Salazar",
        "Helder Araújo",
        "Alberto Cano",
        "Pedro Henriques Abreu"
      ],
      "abstract": "Group fairness in machine learning is a critical area of research focused on\nachieving equitable outcomes across different groups defined by sensitive\nattributes such as race or gender. Federated learning, a decentralized approach\nto training machine learning models across multiple devices or organizations\nwithout sharing raw data, amplifies the need for fairness due to the\nheterogeneous data distributions across clients, which can exacerbate biases.\nThe intersection of federated learning and group fairness has attracted\nsignificant interest, with 47 research works specifically dedicated to\naddressing this issue. However, no dedicated survey has focused comprehensively\non group fairness in federated learning. In this work, we present an in-depth\nsurvey on this topic, addressing the critical challenges and reviewing related\nworks in the field. We create a novel taxonomy of these approaches based on key\ncriteria such as data partitioning, location, and applied strategies.\nAdditionally, we explore broader concerns related to this problem and\ninvestigate how different approaches handle the complexities of various\nsensitive groups and their intersections. Finally, we review the datasets and\napplications commonly used in current research. We conclude by highlighting key\nareas for future research, emphasizing the need for more methods to address the\ncomplexities of achieving group fairness in federated systems.",
      "tldr_zh": "这篇调查论文探讨了Federated Learning中Group Fairness的挑战，强调了数据分布异质性可能加剧种族或性别等敏感属性偏见的问题。作者对47篇相关研究进行全面综述，创建了一个新taxonomy，基于数据分区、位置和应用策略对解决方案进行分类，并分析了处理敏感群体交集的复杂性。论文还审查了常用数据集和应用，并指出未来研究方向，如开发更多方法来提升Federated Systems中的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "68T01",
        "I.2.6; I.5.1; K.4.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03855v1",
      "published_date": "2024-10-04 18:39:28 UTC",
      "updated_date": "2024-10-04 18:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:05:56.113913"
    },
    {
      "arxiv_id": "2410.05306v1",
      "title": "Towards Assuring EU AI Act Compliance and Adversarial Robustness of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tomas Bueno Momcilovic",
        "Beat Buesser",
        "Giulio Zizzo",
        "Mark Purcell",
        "Dian Balta"
      ],
      "abstract": "Large language models are prone to misuse and vulnerable to security threats,\nraising significant safety and security concerns. The European Union's\nArtificial Intelligence Act seeks to enforce AI robustness in certain contexts,\nbut faces implementation challenges due to the lack of standards, complexity of\nLLMs and emerging security vulnerabilities. Our research introduces a framework\nusing ontologies, assurance cases, and factsheets to support engineers and\nstakeholders in understanding and documenting AI system compliance and security\nregarding adversarial robustness. This approach aims to ensure that LLMs adhere\nto regulatory standards and are equipped to counter potential threats.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 易被滥用且面临安全威胁的问题，以及欧盟人工智能法案 (EU AI Act) 在实施中遇到的标准缺失和复杂性挑战，提出一个创新框架。框架利用本体 (ontologies)、保证案例 (assurance cases) 和事实表 (factsheets)，帮助工程师和利益相关者理解、记录和评估 LLMs 的合规性与对抗鲁棒性 (adversarial robustness)。通过此方法，LLMs 可以更好地遵守监管要求，并提升对潜在威胁的抵抗能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in the AI Act Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.05306v1",
      "published_date": "2024-10-04 18:38:49 UTC",
      "updated_date": "2024-10-04 18:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:06:07.931562"
    },
    {
      "arxiv_id": "2410.03847v1",
      "title": "Model-Based Reward Shaping for Adversarial Inverse Reinforcement Learning in Stochastic Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Sinong Zhan",
        "Qingyuan Wu",
        "Philip Wang",
        "Yixuan Wang",
        "Ruochen Jiao",
        "Chao Huang",
        "Qi Zhu"
      ],
      "abstract": "In this paper, we aim to tackle the limitation of the Adversarial Inverse\nReinforcement Learning (AIRL) method in stochastic environments where\ntheoretical results cannot hold and performance is degraded. To address this\nissue, we propose a novel method which infuses the dynamics information into\nthe reward shaping with the theoretical guarantee for the induced optimal\npolicy in the stochastic environments. Incorporating our novel model-enhanced\nrewards, we present a novel Model-Enhanced AIRL framework, which integrates\ntransition model estimation directly into reward shaping. Furthermore, we\nprovide a comprehensive theoretical analysis of the reward error bound and\nperformance difference bound for our method. The experimental results in MuJoCo\nbenchmarks show that our method can achieve superior performance in stochastic\nenvironments and competitive performance in deterministic environments, with\nsignificant improvement in sample efficiency, compared to existing baselines.",
      "tldr_zh": "这篇论文针对 Adversarial Inverse Reinforcement Learning (AIRL) 在随机环境中性能下降的问题，提出了一种新型方法，通过将动态信息注入奖励塑造（reward shaping）来确保诱导最优策略。该方法构建了 Model-Enhanced AIRL 框架，直接整合过渡模型估计到奖励塑造中，并提供了奖励错误边界和性能差异边界的全面理论分析。在 MuJoCo 基准测试中，该方法在随机环境中表现出色，在确定性环境中与现有基线竞争，并显著提升了样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03847v1",
      "published_date": "2024-10-04 18:27:37 UTC",
      "updated_date": "2024-10-04 18:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:06:21.127567"
    },
    {
      "arxiv_id": "2410.09078v1",
      "title": "Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tomas Bueno Momcilovic",
        "Dian Balta",
        "Beat Buesser",
        "Giulio Zizzo",
        "Mark Purcell"
      ],
      "abstract": "The EU AI Act (EUAIA) introduces requirements for AI systems which intersect\nwith the processes required to establish adversarial robustness. However, given\nthe ambiguous language of regulation and the dynamicity of adversarial attacks,\ndevelopers of systems with highly complex models such as LLMs may find their\neffort to be duplicated without the assurance of having achieved either\ncompliance or robustness. This paper presents a functional architecture that\nfocuses on bridging the two properties, by introducing components with clear\nreference to their source. Taking the detection layer recommended by the\nliterature, and the reporting layer required by the law, we aim to support\ndevelopers and auditors with a reasoning layer based on knowledge augmentation\n(rules, assurance cases, contextual mappings). Our findings demonstrate a novel\ndirection for ensuring LLMs deployed in the EU are both compliant and\nadversarially robust, which underpin trustworthiness.",
      "tldr_zh": "这篇论文针对欧盟AI法案(EUAIA)合规性和大型语言模型(LLMs)的对抗鲁棒性问题，提出一个功能架构来桥接两者，避免开发过程中的重复努力。架构通过引入基于知识增强的推理层（包括规则、保证案例和上下文映射），结合文献推荐的检测层和法律要求的报告层，支持开发者和审计者实现高效的合规与鲁棒性评估。研究发现，这种方法为在欧盟部署LLMs提供了一个新方向，确保模型在动态对抗攻击下保持可信赖性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in the VECOMP 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.09078v1",
      "published_date": "2024-10-04 18:23:14 UTC",
      "updated_date": "2024-10-04 18:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:06:31.633919"
    },
    {
      "arxiv_id": "2410.05305v2",
      "title": "Output Scouting: Auditing Large Language Models for Catastrophic Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Bell",
        "Joao Fonseca"
      ],
      "abstract": "Recent high profile incidents in which the use of Large Language Models\n(LLMs) resulted in significant harm to individuals have brought about a growing\ninterest in AI safety. One reason LLM safety issues occur is that models often\nhave at least some non-zero probability of producing harmful outputs. In this\nwork, we explore the following scenario: imagine an AI safety auditor is\nsearching for catastrophic responses from an LLM (e.g. a \"yes\" responses to\n\"can I fire an employee for being pregnant?\"), and is able to query the model a\nlimited number times (e.g. 1000 times). What is a strategy for querying the\nmodel that would efficiently find those failure responses? To this end, we\npropose output scouting: an approach that aims to generate semantically fluent\noutputs to a given prompt matching any target probability distribution. We then\nrun experiments using two LLMs and find numerous examples of catastrophic\nresponses. We conclude with a discussion that includes advice for practitioners\nwho are looking to implement LLM auditing for catastrophic responses. We also\nrelease an open-source toolkit (https://github.com/joaopfonseca/outputscouting)\nthat implements our auditing framework using the Hugging Face transformers\nlibrary.",
      "tldr_zh": "这篇论文探讨了如何审计Large Language Models (LLMs) 以识别灾难性响应，例如模型对有害查询（如“可以解雇怀孕员工吗？”）给出肯定回答的问题。作者提出Output Scouting 方法，该方法通过生成与给定提示匹配目标概率分布的语义流畅输出，实现高效查询，并在有限次数（如1000次）内发现失败响应。实验在两个LLMs上发现了众多灾难性响应，并提供了开源工具包（https://github.com/joaopfonseca/outputscouting），以帮助从业者实施类似审计。总的来说，该工作为提升LLM的安全性提供了实用策略和实证证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work not ready, further experiments needed to validate the method",
      "pdf_url": "http://arxiv.org/pdf/2410.05305v2",
      "published_date": "2024-10-04 18:18:53 UTC",
      "updated_date": "2025-03-28 15:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:06:43.470690"
    },
    {
      "arxiv_id": "2410.03841v1",
      "title": "Explaining the (Not So) Obvious: Simple and Fast Explanation of STAN, a Next Point of Interest Recommendation System",
      "title_zh": "翻译失败",
      "authors": [
        "Fajrian Yunus",
        "Talel Abdessalem"
      ],
      "abstract": "A lot of effort in recent years have been expended to explain machine\nlearning systems. However, some machine learning methods are inherently\nexplainable, and thus are not completely black box. This enables the developers\nto make sense of the output without a developing a complex and expensive\nexplainability technique. Besides that, explainability should be tailored to\nsuit the context of the problem. In a recommendation system which relies on\ncollaborative filtering, the recommendation is based on the behaviors of\nsimilar users, therefore the explanation should tell which other users are\nsimilar to the current user. Similarly, if the recommendation system is based\non sequence prediction, the explanation should also tell which input timesteps\nare the most influential. We demonstrate this philosophy/paradigm in STAN\n(Spatio-Temporal Attention Network for Next Location Recommendation), a next\nPoint of Interest recommendation system based on collaborative filtering and\nsequence prediction. We also show that the explanation helps to \"debug\" the\noutput.",
      "tldr_zh": "本论文探讨了机器学习系统的可解释性，强调某些方法如 STAN（Spatio-Temporal Attention Network for Next Location Recommendation）本身就具有内在解释性，无需复杂的解释技术。作者提出了一种简单快速的解释方法，针对基于 collaborative filtering 的推荐系统，揭示类似用户的行为模式；对于基于 sequence prediction 的部分，则强调关键时间步的影响。该方法不仅提升了系统输出的可理解性，还有助于调试和优化推荐结果。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03841v1",
      "published_date": "2024-10-04 18:14:58 UTC",
      "updated_date": "2024-10-04 18:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:06:59.759002"
    },
    {
      "arxiv_id": "2410.05304v1",
      "title": "Developing Assurance Cases for Adversarial Robustness and Regulatory Compliance in LLMs",
      "title_zh": "针对大型语言模型（LLMs）开发对抗鲁棒性和监管合规的",
      "authors": [
        "Tomas Bueno Momcilovic",
        "Dian Balta",
        "Beat Buesser",
        "Giulio Zizzo",
        "Mark Purcell"
      ],
      "abstract": "This paper presents an approach to developing assurance cases for adversarial\nrobustness and regulatory compliance in large language models (LLMs). Focusing\non both natural and code language tasks, we explore the vulnerabilities these\nmodels face, including adversarial attacks based on jailbreaking, heuristics,\nand randomization. We propose a layered framework incorporating guardrails at\nvarious stages of LLM deployment, aimed at mitigating these attacks and\nensuring compliance with the EU AI Act. Our approach includes a meta-layer for\ndynamic risk management and reasoning, crucial for addressing the evolving\nnature of LLM vulnerabilities. We illustrate our method with two exemplary\nassurance cases, highlighting how different contexts demand tailored strategies\nto ensure robust and compliant AI systems.",
      "tldr_zh": "本论文提出了一种开发 assurance cases 的方法，以提升大型语言模型 (LLMs) 的对抗鲁棒性和监管合规性，针对自然语言和代码任务中存在的漏洞，如基于 jailbreaking、heuristics 和 randomization 的对抗攻击。研究引入一个分层框架，在 LLM 部署的各个阶段部署 guardrails 来缓解这些风险，并通过 meta-layer 实现动态风险管理和推理，以适应漏洞的演变，同时确保符合 EU AI Act 的要求。通过两个示例 assurance cases 展示，该方法能根据不同上下文定制策略，从而构建更可靠和合规的 AI 系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to the ASSURE 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.05304v1",
      "published_date": "2024-10-04 18:14:29 UTC",
      "updated_date": "2024-10-04 18:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:07:07.388588"
    },
    {
      "arxiv_id": "2410.03834v2",
      "title": "GraphRouter: A Graph-based Router for LLM Selections",
      "title_zh": "GraphRouter：基于图的LLM选择路由器",
      "authors": [
        "Tao Feng",
        "Yanzhen Shen",
        "Jiaxuan You"
      ],
      "abstract": "The rapidly growing number and variety of Large Language Models (LLMs)\npresent significant challenges in efficiently selecting the appropriate LLM for\na given query, especially considering the trade-offs between performance and\ncomputational cost. Current LLM selection methods often struggle to generalize\nacross new LLMs and different tasks because of their limited ability to\nleverage contextual interactions among tasks, queries, and LLMs, as well as\ntheir dependence on a transductive learning framework. To address these\nshortcomings, we introduce a novel inductive graph framework, named as\nGraphRouter, which fully utilizes the contextual information among tasks,\nqueries, and LLMs to enhance the LLM selection process. GraphRouter constructs\na heterogeneous graph comprising task, query, and LLM nodes, with interactions\nrepresented as edges, which efficiently captures the contextual information\nbetween the query's requirements and the LLM's capabilities. Through an\ninnovative edge prediction mechanism, GraphRouter is able to predict attributes\n(the effect and cost of LLM response) of potential edges, allowing for\noptimized recommendations that adapt to both existing and newly introduced LLMs\nwithout requiring retraining. Comprehensive experiments across three distinct\neffect-cost weight scenarios have shown that GraphRouter substantially\nsurpasses existing routers, delivering a minimum performance improvement of\n12.3%. In addition, it achieves enhanced generalization across new LLMs\nsettings and supports diverse tasks with at least a 9.5% boost in effect and a\nsignificant reduction in computational demands. This work endeavors to apply a\ngraph-based approach for the contextual and adaptive selection of LLMs,\noffering insights for real-world applications. Our codes for GraphRouter is\nreleased at https://github.com/ulab-uiuc/GraphRouter.",
      "tldr_zh": "该研究提出GraphRouter，一种基于inductive graph framework的路由器，用于高效选择Large Language Models (LLMs)，以解决现有方法在泛化能力和上下文交互方面的局限性。GraphRouter构建一个heterogeneous graph，包括任务、查询和LLM节点，通过edge prediction机制预测潜在edges的属性（如效果和成本），从而优化LLM推荐并适应新引入的LLMs，而无需重新训练。实验结果显示，在三种effect-cost weight场景中，GraphRouter比现有路由器至少提升12.3%的性能，并在新LLM设置和多样任务上实现至少9.5%的效果提升，同时显著减少计算需求。该框架为LLM选择的上下文适应性提供了新见解，并开源了代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03834v2",
      "published_date": "2024-10-04 18:02:48 UTC",
      "updated_date": "2025-03-17 15:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:07:20.959090"
    },
    {
      "arxiv_id": "2410.03665v3",
      "title": "Estimating Body and Hand Motion in an Ego-sensed World",
      "title_zh": "翻译失败",
      "authors": [
        "Brent Yi",
        "Vickie Ye",
        "Maya Zheng",
        "Yunqi Li",
        "Lea Müller",
        "Georgios Pavlakos",
        "Yi Ma",
        "Jitendra Malik",
        "Angjoo Kanazawa"
      ],
      "abstract": "We present EgoAllo, a system for human motion estimation from a head-mounted\ndevice. Using only egocentric SLAM poses and images, EgoAllo guides sampling\nfrom a conditional diffusion model to estimate 3D body pose, height, and hand\nparameters that capture a device wearer's actions in the allocentric coordinate\nframe of the scene. To achieve this, our key insight is in representation: we\npropose spatial and temporal invariance criteria for improving model\nperformance, from which we derive a head motion conditioning parameterization\nthat improves estimation by up to 18%. We also show how the bodies estimated by\nour system can improve hand estimation: the resulting kinematic and temporal\nconstraints can reduce world-frame errors in single-frame estimates by 40%.\nProject page: https://egoallo.github.io/",
      "tldr_zh": "本文提出 EgoAllo 系统，利用头戴设备的 egocentric SLAM 位姿和图像，通过引导条件扩散模型，估计佩戴者在场景绝对坐标系中的 3D 身体姿势、身高和手部参数。关键创新在于引入空间和时间不变性标准，衍生出头部运动条件参数化方法，提高估计准确性高达 18%。此外，该系统利用估计的身体姿势施加运动学和时间约束，能将手部估计的单帧世界坐标错误减少 40%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://egoallo.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.03665v3",
      "published_date": "2024-10-04 17:59:57 UTC",
      "updated_date": "2024-12-17 18:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:07:41.465815"
    },
    {
      "arxiv_id": "2410.03663v3",
      "title": "Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuochun Li",
        "Yuelyu Ji",
        "Rui Meng",
        "Daqing He"
      ],
      "abstract": "While reasoning capabilities typically emerge in large language models (LLMs)\nwith tens of billions of parameters, recent research focuses on improving\nsmaller open-source models through knowledge distillation (KD) from commercial\nLLMs. However, many of these studies rely solely on responses from a single LLM\nas the gold rationale, unlike the natural human learning process, which\ninvolves understanding both the correct answers and the reasons behind\nmistakes. In this paper, we introduce a novel Fault-Aware DistIllation via\nPeer-Review (FAIR) approach: 1) Instead of merely obtaining rationales from\nteachers, our method asks teachers to identify and explain the student's\nmistakes, providing customized instruction learning data. 2) We design a\nsimulated peer-review process between teacher LLMs, which selects only the\ngenerated rationales above the acceptance threshold. This reduces the chance of\nteachers guessing correctly with flawed rationale, improving instructional data\nquality. Comprehensive experiments and analysis on mathematical, commonsense,\nand logical reasoning tasks demonstrate the effectiveness of our method.",
      "tldr_zh": "本论文提出了一种名为 Fault-Aware DistIllation via Peer-Review (FAIR) 的新方法，用于通过知识 distillation (KD) 提升小型语言模型 (LLMs) 的推理能力，解决传统方法仅依赖单一教师模型响应的局限性。FAIR 包括让教师 LLMs 识别并解释学生的错误，提供定制化的指令学习数据，以及设计一个模拟的同行评审过程，仅选择质量达到阈值的推理理由，以提高数据可靠性。实验在数学、常识和逻辑推理任务上证明，该方法显著提升了模型性能，展示了其在模拟人类学习过程方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03663v3",
      "published_date": "2024-10-04 17:59:41 UTC",
      "updated_date": "2025-02-19 18:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:07:51.727267"
    },
    {
      "arxiv_id": "2410.03662v2",
      "title": "System 2 Reasoning Capabilities Are Nigh",
      "title_zh": "System 2 推理能力近在眼前",
      "authors": [
        "Scott C. Lowe"
      ],
      "abstract": "In recent years, machine learning models have made strides towards human-like\nreasoning capabilities from several directions. In this work, we review the\ncurrent state of the literature and describe the remaining steps to achieve a\nneural model which can perform System~2 reasoning analogous to a human. We\nargue that if current models are insufficient to be classed as performing\nreasoning, there remains very little additional progress needed to attain that\ngoal.",
      "tldr_zh": "这篇论文回顾了机器学习模型在实现类似人类推理能力方面的最新进展，特别是System 2 Reasoning（即深思熟虑的慢速推理）。作者分析了现有文献，并指出当前模型虽尚未完全达到这一水平，但只需少量额外进步即可实现神经模型的System 2推理。论文强调，剩余步骤主要涉及优化模型架构和训练策略，以接近人类水平的推理性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03662v2",
      "published_date": "2024-10-04 17:59:36 UTC",
      "updated_date": "2024-10-29 23:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:08:03.021601"
    },
    {
      "arxiv_id": "2410.03655v2",
      "title": "Geometric Representation Condition Improves Equivariant Molecule Generation",
      "title_zh": "几何表示条件改善等变分子生成",
      "authors": [
        "Zian Li",
        "Cai Zhou",
        "Xiyuan Wang",
        "Xingang Peng",
        "Muhan Zhang"
      ],
      "abstract": "Recent advancements in molecular generative models have demonstrated\nsubstantial potential in accelerating scientific discovery, particularly in\ndrug design. However, these models often face challenges in generating\nhigh-quality molecules, especially in conditional scenarios where specific\nmolecular properties must be satisfied. In this work, we introduce GeoRCG, a\ngeneral framework to enhance the performance of molecular generative models by\nintegrating geometric representation conditions with provable theoretical\nguarantees. We decompose the molecule generation process into two stages:\nfirst, generating an informative geometric representation; second, generating a\nmolecule conditioned on the representation. Compared to directly generating a\nmolecule, the relatively easy-to-generate representation in the first stage\nguides the second-stage generation to reach a high-quality molecule in a more\ngoal-oriented and much faster way. Leveraging EDM and SemlaFlow as the base\ngenerators, we observe significant quality improvements in unconditional\nmolecule generation tasks on the widely-used QM9 and GEOM-DRUG datasets. More\nnotably, in the challenging conditional molecular generation task, our\nframework achieves an average 31\\% performance improvement over\nstate-of-the-art approaches, highlighting the superiority of conditioning on\nsemantically rich geometric representations over conditioning on individual\nproperty values as in previous approaches. Furthermore, we show that, with such\nrepresentation guidance, the number of diffusion steps can be reduced to as\nsmall as 100 while largely preserving the generation quality achieved with\n1,000 steps, thereby significantly accelerating the generation process.",
      "tldr_zh": "该研究提出GeoRCG框架，通过整合geometric representation conditions来提升等变分子生成模型的性能，并提供可证明的理论保证。该框架将分子生成过程分解为两个阶段：首先生成信息丰富的geometric representation，然后基于此表示进行条件分子生成，从而更高效地实现高质量输出。在QM9和GEOM-DRUG数据集上的实验显示，GeoRCG在无条件任务中显著改善生成质量，在条件分子生成任务中平均比现有方法提高31%的性能。更重要的是，该方法允许将diffusion步骤减少到100步，同时基本保持生成质量，从而大幅加速分子设计过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03655v2",
      "published_date": "2024-10-04 17:57:35 UTC",
      "updated_date": "2025-02-10 06:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:08:15.983877"
    },
    {
      "arxiv_id": "2410.03645v1",
      "title": "GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Pu Hua",
        "Minghuan Liu",
        "Annabella Macaluso",
        "Yunfeng Lin",
        "Weinan Zhang",
        "Huazhe Xu",
        "Lirui Wang"
      ],
      "abstract": "Robotic simulation today remains challenging to scale up due to the human\nefforts required to create diverse simulation tasks and scenes.\nSimulation-trained policies also face scalability issues as many sim-to-real\nmethods focus on a single task. To address these challenges, this work proposes\nGenSim2, a scalable framework that leverages coding LLMs with multi-modal and\nreasoning capabilities for complex and realistic simulation task creation,\nincluding long-horizon tasks with articulated objects. To automatically\ngenerate demonstration data for these tasks at scale, we propose planning and\nRL solvers that generalize within object categories. The pipeline can generate\ndata for up to 100 articulated tasks with 200 objects and reduce the required\nhuman efforts. To utilize such data, we propose an effective multi-task\nlanguage-conditioned policy architecture, dubbed proprioceptive point-cloud\ntransformer (PPT), that learns from the generated demonstrations and exhibits\nstrong sim-to-real zero-shot transfer. Combining the proposed pipeline and the\npolicy architecture, we show a promising usage of GenSim2 that the generated\ndata can be used for zero-shot transfer or co-train with real-world collected\ndata, which enhances the policy performance by 20% compared with training\nexclusively on limited real data.",
      "tldr_zh": "该论文提出GenSim2框架，利用多模态和推理LLMs来扩展机器人模拟数据生成，解决传统方法中创建多样任务和场景所需的人力问题，以及sim-to-real策略的单一任务局限。框架通过编码LLMs自动生成复杂任务（如长horizon任务和铰接物体），并使用规划和RL求解器在物体类别内泛化，生成高达100个任务和200个物体的演示数据，从而显著减少人力需求。实验结果显示，结合新颖的proprioceptive point-cloud transformer (PPT)多任务语言条件策略架构，GenSim2生成的模拟数据可实现zero-shot sim-to-real转移，或与真实数据联合训练，提升策略性能20%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2024. Project website: https://gensim2.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.03645v1",
      "published_date": "2024-10-04 17:51:33 UTC",
      "updated_date": "2024-10-04 17:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:08:29.467178"
    },
    {
      "arxiv_id": "2410.03642v2",
      "title": "Aligning LLMs with Individual Preferences via Interaction",
      "title_zh": "通过交互对齐大语言模型的个人偏好",
      "authors": [
        "Shujin Wu",
        "May Fung",
        "Cheng Qian",
        "Jeonghwan Kim",
        "Dilek Hakkani-Tur",
        "Heng Ji"
      ],
      "abstract": "As large language models (LLMs) demonstrate increasingly advanced\ncapabilities, aligning their behaviors with human values and preferences\nbecomes crucial for their wide adoption. While previous research focuses on\ngeneral alignment to principles such as helpfulness, harmlessness, and honesty,\nthe need to account for individual and diverse preferences has been largely\noverlooked, potentially undermining customized human experiences. To address\nthis gap, we train LLMs that can ''interact to align'', essentially cultivating\nthe meta-skill of LLMs to implicitly infer the unspoken personalized\npreferences of the current user through multi-turn conversations, and then\ndynamically align their following behaviors and responses to these inferred\npreferences. Our approach involves establishing a diverse pool of 3,310\ndistinct user personas by initially creating seed examples, which are then\nexpanded through iterative self-generation and filtering. Guided by distinct\nuser personas, we leverage multi-LLM collaboration to develop a multi-turn\npreference dataset containing 3K+ multi-turn conversations in tree structures.\nFinally, we apply supervised fine-tuning and reinforcement learning to enhance\nLLMs using this dataset. For evaluation, we establish the ALOE (ALign With\nCustOmized PrEferences) benchmark, consisting of 100 carefully selected\nexamples and well-designed metrics to measure the customized alignment\nperformance during conversations. Experimental results demonstrate the\neffectiveness of our method in enabling dynamic, personalized alignment via\ninteraction.",
      "tldr_zh": "本论文提出了一种通过互动对齐大型语言模型 (LLMs) 与个人偏好的方法，以解决现有研究忽略用户多样化偏好的问题。研究团队创建了3,310个多样用户 personas，并利用多-LLM协作生成3K+多轮对话数据集，然后通过监督微调和强化学习训练LLMs，使其能够在多轮对话中隐式推断用户偏好并动态调整响应。最终，论文建立了ALOE基准（包括100个示例和专用指标）来评估个性化对齐性能，实验结果证明了该方法的有效性，在实现动态、个性化的用户体验方面取得了显著进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLING 2025. The code and dataset are made public at\n  https://github.com/ShujinWu-0814/ALOE",
      "pdf_url": "http://arxiv.org/pdf/2410.03642v2",
      "published_date": "2024-10-04 17:48:29 UTC",
      "updated_date": "2024-12-15 21:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:08:40.506730"
    },
    {
      "arxiv_id": "2410.03818v1",
      "title": "Large Language Models can be Strong Self-Detoxifiers",
      "title_zh": "大语言模型可以是强大的自我解毒器",
      "authors": [
        "Ching-Yun Ko",
        "Pin-Yu Chen",
        "Payel Das",
        "Youssef Mroueh",
        "Soham Dan",
        "Georgios Kollias",
        "Subhajit Chaudhury",
        "Tejaswini Pedapati",
        "Luca Daniel"
      ],
      "abstract": "Reducing the likelihood of generating harmful and toxic output is an\nessential task when aligning large language models (LLMs). Existing methods\nmainly rely on training an external reward model (i.e., another language model)\nor fine-tuning the LLM using self-generated data to influence the outcome. In\nthis paper, we show that LLMs have the capability of self-detoxification\nwithout the use of an additional reward model or re-training. We propose\n\\textit{Self-disciplined Autoregressive Sampling (SASA)}, a lightweight\ncontrolled decoding algorithm for toxicity reduction of LLMs. SASA leverages\nthe contextual representations from an LLM to learn linear subspaces\ncharacterizing toxic v.s. non-toxic output in analytical forms. When\nauto-completing a response token-by-token, SASA dynamically tracks the margin\nof the current output to steer the generation away from the toxic subspace, by\nadjusting the autoregressive sampling strategy. Evaluated on LLMs of different\nscale and nature, namely Llama-3.1-Instruct (8B), Llama-2 (7B), and GPT2-L\nmodels with the RealToxicityPrompts, BOLD, and AttaQ benchmarks, SASA markedly\nenhances the quality of the generated sentences relative to the original models\nand attains comparable performance to state-of-the-art detoxification\ntechniques, significantly reducing the toxicity level by only using the LLM's\ninternal representations.",
      "tldr_zh": "该研究证明Large Language Models (LLMs) 能够通过自我净化（self-detoxification）机制减少有害输出，而无需外部奖励模型或重新训练。论文提出SASA（Self-disciplined Autoregressive Sampling），一种轻量级控制解码算法，利用LLMs的内部上下文表示学习toxic vs. non-toxic输出的线性子空间，并在生成过程中动态调整自回归采样策略以避开toxic子空间。在RealToxicityPrompts、BOLD和AttaQ基准上的实验显示，SASA显著降低了Llama-3.1-Instruct (8B)、Llama-2 (7B)和GPT2-L模型的毒性水平，与最先进技术相当，从而提升了生成句子的整体质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03818v1",
      "published_date": "2024-10-04 17:45:15 UTC",
      "updated_date": "2024-10-04 17:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:03.474633"
    },
    {
      "arxiv_id": "2410.03617v1",
      "title": "What Matters for Model Merging at Scale?",
      "title_zh": "大规模模型合并中哪些因素至关重要？",
      "authors": [
        "Prateek Yadav",
        "Tu Vu",
        "Jonathan Lai",
        "Alexandra Chronopoulou",
        "Manaal Faruqui",
        "Mohit Bansal",
        "Tsendsuren Munkhdalai"
      ],
      "abstract": "Model merging aims to combine multiple expert models into a more capable\nsingle model, offering benefits such as reduced storage and serving costs,\nimproved generalization, and support for decentralized model development.\nDespite its promise, previous studies have primarily focused on merging a few\nsmall models. This leaves many unanswered questions about the effect of scaling\nmodel size and how it interplays with other key factors -- like the base model\nquality and number of expert models -- , to affect the merged model's\nperformance. This work systematically evaluates the utility of model merging at\nscale, examining the impact of these different factors. We experiment with\nmerging fully fine-tuned models using 4 popular merging methods -- Averaging,\nTask~Arithmetic, Dare, and TIES -- across model sizes ranging from 1B-64B\nparameters and merging up to 8 different expert models. We evaluate the merged\nmodels on both held-in tasks, i.e., the expert's training tasks, and zero-shot\ngeneralization to unseen held-out tasks. Our experiments provide several new\ninsights about model merging at scale and the interplay between different\nfactors. First, we find that merging is more effective when experts are created\nfrom strong base models, i.e., models with good zero-shot performance. Second,\nlarger models facilitate easier merging. Third merging consistently improves\ngeneralization capabilities. Notably, when merging 8 large expert models, the\nmerged models often generalize better compared to the multitask trained models.\nFourth, we can better merge more expert models when working with larger models.\nFifth, different merging methods behave very similarly at larger scales.\nOverall, our findings shed light on some interesting properties of model\nmerging while also highlighting some limitations. We hope that this study will\nserve as a reference point on large-scale merging for upcoming research.",
      "tldr_zh": "本文研究了大规模模型合并（Model Merging）的关键因素，包括基础模型质量、专家模型数量及其相互影响。作者通过实验评估了4种流行方法（Averaging, Task Arithmetic, Dare, and TIES），在1B至64B参数模型上合并多达8个专家模型，并测试了合并模型在已知任务和零样本泛化任务上的性能。关键发现包括：使用强基础模型（如零样本性能良好者）能显著提升合并效果；更大模型更易合并且改善泛化能力，尤其合并8个大模型时优于多任务训练模型；不同合并方法在大规模下表现相似。该研究为模型合并提供了新洞见，并指出了其潜在局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 Pages, 7 Figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.03617v1",
      "published_date": "2024-10-04 17:17:19 UTC",
      "updated_date": "2024-10-04 17:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:08.462913"
    },
    {
      "arxiv_id": "2410.03608v1",
      "title": "TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Cook",
        "Tim Rocktäschel",
        "Jakob Foerster",
        "Dennis Aumiller",
        "Alex Wang"
      ],
      "abstract": "Given the widespread adoption and usage of Large Language Models (LLMs), it\nis crucial to have flexible and interpretable evaluations of their\ninstruction-following ability. Preference judgments between model outputs have\nbecome the de facto evaluation standard, despite distilling complex,\nmulti-faceted preferences into a single ranking. Furthermore, as human\nannotation is slow and costly, LLMs are increasingly used to make these\njudgments, at the expense of reliability and interpretability. In this work, we\npropose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated,\ninterpretable evaluation protocol that structures evaluations with\nLLM-generated, instruction-specific checklists. We first show that, given an\ninstruction, LLMs can reliably produce high-quality, tailored evaluation\nchecklists that decompose the instruction into a series of YES/NO questions.\nEach question asks whether a candidate response meets a specific requirement of\nthe instruction. We demonstrate that using TICK leads to a significant increase\n(46.4% $\\to$ 52.2%) in the frequency of exact agreements between LLM judgements\nand human preferences, as compared to having an LLM directly score an output.\nWe then show that STICK (Self-TICK) can be used to improve generation quality\nacross multiple benchmarks via self-refinement and Best-of-N selection. STICK\nself-refinement on LiveBench reasoning tasks leads to an absolute gain of\n$+$7.8%, whilst Best-of-N selection with STICK attains $+$6.3% absolute\nimprovement on the real-world instruction dataset, WildBench. In light of this,\nstructured, multi-faceted self-improvement is shown to be a promising way to\nfurther advance LLM capabilities. Finally, by providing LLM-generated\nchecklists to human evaluators tasked with directly scoring LLM responses to\nWildBench instructions, we notably increase inter-annotator agreement (0.194\n$\\to$ 0.256).",
      "tldr_zh": "本文提出 TICK（Targeted Instruct-evaluation with ChecKlists），一种基于 LLM 生成的指令特定检查列表的自动评估协议，将指令分解为一系列 YES/NO 问题，以提高 LLM 指令遵循能力的评估准确性和可解释性。实验显示，TICK 使 LLM 判断与人类偏好的精确一致性从 46.4% 提升至 52.2%。此外，扩展方法 STICK 通过自精炼和 Best-of-N 选择，显著改善生成质量，在 LiveBench 推理任务上获得 7.8% 的绝对提升，在 WildBench 上实现 6.3% 的改进，并提高了人类评估者间的共识（从 0.194 至 0.256）。这项工作展示了结构化、多维度的自提升方法在推进 LLM 能力方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03608v1",
      "published_date": "2024-10-04 17:09:08 UTC",
      "updated_date": "2024-10-04 17:09:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:16.911533"
    },
    {
      "arxiv_id": "2410.03596v1",
      "title": "SiMilarity-Enhanced Homophily for Multi-View Heterophilous Graph Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Jianpeng Chen",
        "Yawen Ling",
        "Yazhou Ren",
        "Zichen Wen",
        "Tianyi Wu",
        "Shufei Zhang",
        "Lifang He"
      ],
      "abstract": "With the increasing prevalence of graph-structured data, multi-view graph\nclustering has been widely used in various downstream applications. Existing\napproaches primarily rely on a unified message passing mechanism, which\nsignificantly enhances clustering performance. Nevertheless, this mechanism\nlimits its applicability to heterophilous situations, as it is fundamentally\npredicated on the assumption of homophily, i.e., the connected nodes often\nbelong to the same class. In reality, this assumption does not always hold; a\nmoderately or even mildly homophilous graph is more common than a fully\nhomophilous one due to inevitable heterophilous information in the graph. To\naddress this issue, in this paper, we propose a novel SiMilarity-enhanced\nHomophily for Multi-view Heterophilous Graph Clustering (SMHGC) approach. By\nanalyzing the relationship between similarity and graph homophily, we propose\nto enhance the homophily by introducing three similarity terms, i.e., neighbor\npattern similarity, node feature similarity, and multi-view global similarity,\nin a label-free manner. Then, a consensus-based inter- and intra-view fusion\nparadigm is proposed to fuse the improved homophilous graph from different\nviews and utilize them for clustering. The state-of-the-art experimental\nresults on both multi-view heterophilous and homophilous datasets collectively\ndemonstrate the strong capacity of similarity for unsupervised multi-view\nheterophilous graph learning. Additionally, the consistent performance across\nsemi-synthetic datasets with varying levels of homophily serves as further\nevidence of SMHGC's resilience to heterophily.",
      "tldr_zh": "该论文针对多视图异质图（heterophilous graph）聚类问题，提出了一种名为SMHGC的方法，通过引入邻居模式相似性（neighbor pattern similarity）、节点特征相似性（node feature similarity）和多视图全局相似性（multi-view global similarity）来增强同质性（homophily），从而克服现有基于统一message passing机制的局限性。SMHGC采用无标签的共识-based融合范式，在不同视图间融合改进后的图结构，并应用于聚类任务。实验结果显示，该方法在多视图异质和同质数据集上显著优于现有方法，并在半合成数据集上展现出对异质性的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03596v1",
      "published_date": "2024-10-04 16:55:35 UTC",
      "updated_date": "2024-10-04 16:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:29.092979"
    },
    {
      "arxiv_id": "2410.03595v1",
      "title": "Understanding Reasoning in Chain-of-Thought from the Hopfieldian View",
      "title_zh": "翻译失败",
      "authors": [
        "Lijie Hu",
        "Liang Liu",
        "Shu Yang",
        "Xin Chen",
        "Zhen Tan",
        "Muhammad Asif Ali",
        "Mengdi Li",
        "Di Wang"
      ],
      "abstract": "Large Language Models have demonstrated remarkable abilities across various\ntasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to\nenhance reasoning capabilities. However, existing research primarily focuses on\nimproving performance, lacking a comprehensive framework to explain and\nunderstand the fundamental factors behind CoT's success. To bridge this gap, we\nintroduce a novel perspective grounded in the Hopfieldian view of cognition in\ncognitive neuroscience. We establish a connection between CoT reasoning and key\ncognitive elements such as stimuli, actions, neural populations, and\nrepresentation spaces. From our view, we can understand the reasoning process\nas the movement between these representation spaces. Building on this insight,\nwe develop a method for localizing reasoning errors in the response of CoTs.\nMoreover, we propose the Representation-of-Thought (RoT) framework, which\nleverages the robustness of low-dimensional representation spaces to enhance\nthe robustness of the reasoning process in CoTs. Experimental results\ndemonstrate that RoT improves the robustness and interpretability of CoT\nreasoning while offering fine-grained control over the reasoning process.",
      "tldr_zh": "本论文从 Hopfieldian 视角探讨 Chain-of-Thought (CoT) 推理的机制，建立了 CoT 与认知神经科学元素（如 stimuli、actions、neural populations 和 representation spaces）的联系，将推理过程视为在这些表示空间间的移动。作者开发了一种方法来定位 CoT 响应中的推理错误，并提出 Representation-of-Thought (RoT) 框架，利用低维表示空间的鲁棒性来提升 CoT 推理的鲁棒性。实验结果显示，RoT 框架显著提高了 CoT 推理的鲁棒性和可解释性，同时提供了对推理过程的细粒度控制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, a new version of \"A Hopfieldian View-based Interpretation\n  for Chain-of-Thought Reasoning\"",
      "pdf_url": "http://arxiv.org/pdf/2410.03595v1",
      "published_date": "2024-10-04 16:55:30 UTC",
      "updated_date": "2024-10-04 16:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:40.539247"
    },
    {
      "arxiv_id": "2410.03592v1",
      "title": "Variational Bayes Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Toon Van de Maele",
        "Ozan Catal",
        "Alexander Tschantz",
        "Christopher L. Buckley",
        "Tim Verbelen"
      ],
      "abstract": "Recently, 3D Gaussian Splatting has emerged as a promising approach for\nmodeling 3D scenes using mixtures of Gaussians. The predominant optimization\nmethod for these models relies on backpropagating gradients through a\ndifferentiable rendering pipeline, which struggles with catastrophic forgetting\nwhen dealing with continuous streams of data. To address this limitation, we\npropose Variational Bayes Gaussian Splatting (VBGS), a novel approach that\nframes training a Gaussian splat as variational inference over model\nparameters. By leveraging the conjugacy properties of multivariate Gaussians,\nwe derive a closed-form variational update rule, allowing efficient updates\nfrom partial, sequential observations without the need for replay buffers. Our\nexperiments show that VBGS not only matches state-of-the-art performance on\nstatic datasets, but also enables continual learning from sequentially streamed\n2D and 3D data, drastically improving performance in this setting.",
      "tldr_zh": "该研究提出Variational Bayes Gaussian Splatting (VBGS)，一种将3D Gaussian Splatting的训练框架化为模型参数的变分推断方法，以解决现有优化方法在处理连续数据流时易出现灾难性遗忘的问题。VBGS利用多元高斯的共轭性质，推导了闭式变分更新规则，实现从部分顺序观察中高效更新，而无需重放缓冲区。实验结果显示，VBGS在静态数据集上与最先进方法性能相当，并在从顺序流式2D和3D数据中持续学习时显著提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03592v1",
      "published_date": "2024-10-04 16:52:03 UTC",
      "updated_date": "2024-10-04 16:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:09:51.823948"
    },
    {
      "arxiv_id": "2410.03580v1",
      "title": "A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle Development",
      "title_zh": "翻译失败",
      "authors": [
        "Jesper Knapp",
        "Klas Moberg",
        "Yuchuan Jin",
        "Simin Sun",
        "Miroslaw Staron"
      ],
      "abstract": "Autonomous driving software generates enormous amounts of data every second,\nwhich software development organizations save for future analysis and testing\nin the form of logs. However, given the vast size of this data, locating\nspecific scenarios within a collection of vehicle logs can be challenging.\nWriting the correct SQL queries to find these scenarios requires engineers to\nhave a strong background in SQL and the specific databases in question, further\ncomplicating the search process. This paper presents and evaluates a pipeline\nthat allows searching for specific scenarios in log collections using natural\nlanguage descriptions instead of SQL. The generated descriptions were evaluated\nby engineers working with vehicle logs at the Zenseact on a scale from 1 to 5.\nOur approach achieved a mean score of 3.3, demonstrating the potential of using\na multi-model architecture to improve the software development workflow. We\nalso present an interface that can visualize the query process and visualize\nthe results.",
      "tldr_zh": "本论文提出了一种多模型方法，用于自动驾驶车辆开发中的视频数据检索，旨在解决从海量日志中查找特定场景的难题，避免工程师编写复杂 SQL 查询的需求。该方法通过一个管道，使用自然语言描述来搜索日志数据，并提供一个可视化接口来展示查询过程和结果。在工程师评估中，该方法生成的描述平均得分 3.3 分，证明了其在提升软件开发工作流效率方面的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03580v1",
      "published_date": "2024-10-04 16:38:27 UTC",
      "updated_date": "2024-10-04 16:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:10:04.311036"
    },
    {
      "arxiv_id": "2410.03565v2",
      "title": "Exploration Implies Data Augmentation: Reachability and Generalisation in Contextual MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Max Weltevrede",
        "Caroline Horsch",
        "Matthijs T. J. Spaan",
        "Wendelin Böhmer"
      ],
      "abstract": "In the zero-shot policy transfer (ZSPT) setting for contextual Markov\ndecision processes (MDP), agents train on a fixed set of contexts and must\ngeneralise to new ones. Recent work has argued and demonstrated that increased\nexploration can improve this generalisation, by training on more states in the\ntraining contexts. In this paper, we demonstrate that training on more states\ncan indeed improve generalisation, but can come at a cost of reducing the\naccuracy of the learned value function which should not benefit generalisation.\nWe introduce reachability in the ZSPT setting to define which states/contexts\nrequire generalisation and explain why exploration can improve it. We\nhypothesise and demonstrate that using exploration to increase the agent's\ncoverage while also increasing the accuracy improves generalisation even more.\nInspired by this, we propose a method Explore-Go that implements an exploration\nphase at the beginning of each episode, which can be combined with existing on-\nand off-policy RL algorithms and significantly improves generalisation even in\npartially observable MDPs. We demonstrate the effectiveness of Explore-Go when\ncombined with several popular algorithms and show an increase in generalisation\nperformance across several environments. With this, we hope to provide\npractitioners with a simple modification that can improve the generalisation of\ntheir agents.",
      "tldr_zh": "在 contextual MDPs 的 zero-shot policy transfer (ZSPT) 设置中，本文探讨了探索如何通过增强数据来改善代理从训练上下文向新上下文的 generalisation，但这可能以降低学习的价值函数准确性为代价。作者引入 reachability 概念来定义需要泛化的状态/上下文，并假设增加探索覆盖范围的同时维持准确性能进一步提升性能。基于此，他们提出 Explore-Go 方法，在每个 episode 的开始添加探索阶段，可与现有 on- 和 off-policy RL 算法结合，并在多个环境中显著提高了 generalisation 性能，甚至适用于 partially observable MDPs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2406.08069",
      "pdf_url": "http://arxiv.org/pdf/2410.03565v2",
      "published_date": "2024-10-04 16:15:31 UTC",
      "updated_date": "2025-03-05 10:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:10:16.550135"
    },
    {
      "arxiv_id": "2410.03560v1",
      "title": "færdXel: An Expert System for Danish Traffic Law",
      "title_zh": "翻译失败",
      "authors": [
        "Luís Cruz-Filipe",
        "Jonas Vistrup"
      ],
      "abstract": "We present f{\\ae}rdXel, a tool for symbolic reasoning in the domain of Danish\ntraffic law. f{\\ae}rdXel combines techniques from logic programming with a\nnovel interface that allows users to navigate through its reasoning process,\nthereby ensuring the system's trustworthiness. A preliminary empirical\nevaluation indicates that this work is seen as very promising, and has the\npotential to become a foundation for real-world AI tools supporting\nprofessionals in the Danish legal sector.",
      "tldr_zh": "我们介绍了 færdXel，这是一个针对丹麦交通法的专家系统，用于进行符号推理。færdXel 结合了 logic programming 技术与一个创新的接口，允许用户导航其推理过程，从而提升系统的可信度（trustworthiness）。初步实证评估显示，该系统非常有前景，可能成为支持丹麦法律专业人士的真实AI工具的基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03560v1",
      "published_date": "2024-10-04 16:07:36 UTC",
      "updated_date": "2024-10-04 16:07:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:10:38.141010"
    },
    {
      "arxiv_id": "2410.03558v3",
      "title": "Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features",
      "title_zh": "并非所有扩散模型激活都已被评估为鉴别特征",
      "authors": [
        "Benyuan Meng",
        "Qianqian Xu",
        "Zitai Wang",
        "Xiaochun Cao",
        "Qingming Huang"
      ],
      "abstract": "Diffusion models are initially designed for image generation. Recent research\nshows that the internal signals within their backbones, named activations, can\nalso serve as dense features for various discriminative tasks such as semantic\nsegmentation. Given numerous activations, selecting a small yet effective\nsubset poses a fundamental problem. To this end, the early study of this field\nperforms a large-scale quantitative comparison of the discriminative ability of\nthe activations. However, we find that many potential activations have not been\nevaluated, such as the queries and keys used to compute attention scores.\nMoreover, recent advancements in diffusion architectures bring many new\nactivations, such as those within embedded ViT modules. Both combined,\nactivation selection remains unresolved but overlooked. To tackle this issue,\nthis paper takes a further step with a much broader range of activations\nevaluated. Considering the significant increase in activations, a full-scale\nquantitative comparison is no longer operational. Instead, we seek to\nunderstand the properties of these activations, such that the activations that\nare clearly inferior can be filtered out in advance via simple qualitative\nevaluation. After careful analysis, we discover three properties universal\namong diffusion models, enabling this study to go beyond specific models. On\ntop of this, we present effective feature selection solutions for several\npopular diffusion models. Finally, the experiments across multiple\ndiscriminative tasks validate the superiority of our method over the SOTA\ncompetitors. Our code is available at\nhttps://github.com/Darkbblue/generic-diffusion-feature.",
      "tldr_zh": "该研究发现，扩散模型（Diffusion models）的内部激活（activations）可作为判别特征用于任务如语义分割，但许多潜在激活（如用于计算注意力分数的 queries 和 keys）尚未被评估。论文扩展了激活评估范围，通过定性分析识别了扩散模型中通用的三个属性，用于提前过滤劣质激活，并提出了针对流行扩散模型的有效特征选择解决方案。实验结果表明，该方法在多个判别任务上优于现有最先进方法（SOTA），并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03558v3",
      "published_date": "2024-10-04 16:05:14 UTC",
      "updated_date": "2024-10-18 06:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:10:40.169102"
    },
    {
      "arxiv_id": "2410.14697v2",
      "title": "Learning Cortico-Muscular Dependence through Orthonormal Decomposition of Density Ratios",
      "title_zh": "通过密度比的正交归一分解学习皮层-肌肉依赖性",
      "authors": [
        "Shihan Ma",
        "Bo Hu",
        "Tianyu Jia",
        "Alexander Kenneth Clarke",
        "Blanka Zicher",
        "Arnault H. Caillet",
        "Dario Farina",
        "Jose C. Principe"
      ],
      "abstract": "The cortico-spinal neural pathway is fundamental for motor control and\nmovement execution, and in humans it is typically studied using concurrent\nelectroencephalography (EEG) and electromyography (EMG) recordings. However,\ncurrent approaches for capturing high-level and contextual connectivity between\nthese recordings have important limitations. Here, we present a novel\napplication of statistical dependence estimators based on orthonormal\ndecomposition of density ratios to model the relationship between cortical and\nmuscle oscillations. Our method extends from traditional scalar-valued measures\nby learning eigenvalues, eigenfunctions, and projection spaces of density\nratios from realizations of the signal, addressing the interpretability,\nscalability, and local temporal dependence of cortico-muscular connectivity. We\nexperimentally demonstrate that eigenfunctions learned from cortico-muscular\nconnectivity can accurately classify movements and subjects. Moreover, they\nreveal channel and temporal dependencies that confirm the activation of\nspecific EEG channels during movement. Our code is available at\nhttps://github.com/bohu615/corticomuscular-eigen-encoder.",
      "tldr_zh": "本研究提出了一种基于正交分解密度比(orthonormal decomposition of density ratios)的统计依赖估计器，用于建模皮层-肌肉振荡的依赖关系，针对传统标量值方法在EEG和EMG记录间的连接性分析中存在的可解释性、可扩展性和局部时间依赖问题。方法通过从信号实现中学习特征值(eigenvalues)、特征函数(eigenfunctions)和投影空间，扩展了高水平和上下文连接的捕捉能力。实验结果显示，该方法能准确分类动作和受试者，并揭示特定EEG通道在运动中的激活，提供了一个更可靠的皮层-肌肉通路分析框架。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14697v2",
      "published_date": "2024-10-04 16:05:08 UTC",
      "updated_date": "2024-12-19 22:44:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:10:52.713031"
    },
    {
      "arxiv_id": "2410.14696v1",
      "title": "REBIND: Enhancing ground-state molecular conformation via force-based graph rewiring",
      "title_zh": "翻译失败",
      "authors": [
        "Taewon Kim",
        "Hyunjin Seo",
        "Sungsoo Ahn",
        "Eunho Yang"
      ],
      "abstract": "Predicting the ground-state 3D molecular conformations from 2D molecular\ngraphs is critical in computational chemistry due to its profound impact on\nmolecular properties. Deep learning (DL) approaches have recently emerged as\npromising alternatives to computationally-heavy classical methods such as\ndensity functional theory (DFT). However, we discover that existing DL methods\ninadequately model inter-atomic forces, particularly for non-bonded atomic\npairs, due to their naive usage of bonds and pairwise distances. Consequently,\nsignificant prediction errors occur for atoms with low degree (i.e., low\ncoordination numbers) whose conformations are primarily influenced by\nnon-bonded interactions. To address this, we propose REBIND, a novel framework\nthat rewires molecular graphs by adding edges based on the Lennard-Jones\npotential to capture non-bonded interactions for low-degree atoms. Experimental\nresults demonstrate that REBIND significantly outperforms state-of-the-art\nmethods across various molecular sizes, achieving up to a 20\\% reduction in\nprediction error.",
      "tldr_zh": "该论文针对从2D分子图预测3D分子构象的关键问题，指出现有Deep Learning (DL)方法未能有效建模原子间力，尤其是非键合原子对，导致低度原子预测错误。作者提出REBIND框架，通过基于Lennard-Jones potential的force-based graph rewiring技术，重连分子图以添加边捕捉非键合交互，从而提升预测准确性。实验结果显示，REBIND在不同分子大小上比最先进方法减少了高达20%的预测错误，为计算化学中的分子构象预测提供了显著改进。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "17 pages, 4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14696v1",
      "published_date": "2024-10-04 16:02:33 UTC",
      "updated_date": "2024-10-04 16:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:11:04.635408"
    },
    {
      "arxiv_id": "2410.03537v2",
      "title": "Ward: Provable RAG Dataset Inference via LLM Watermarks",
      "title_zh": "Ward：通过 LLM 水印的可证明 RAG 数据集推断",
      "authors": [
        "Nikola Jovanović",
        "Robin Staab",
        "Maximilian Baader",
        "Martin Vechev"
      ],
      "abstract": "RAG enables LLMs to easily incorporate external data, raising concerns for\ndata owners regarding unauthorized usage of their content. The challenge of\ndetecting such unauthorized usage remains underexplored, with datasets and\nmethods from adjacent fields being ill-suited for its study. We take several\nsteps to bridge this gap. First, we formalize this problem as (black-box) RAG\nDataset Inference (RAG-DI). We then introduce a novel dataset designed for\nrealistic benchmarking of RAG-DI methods, alongside a set of baselines.\nFinally, we propose Ward, a method for RAG-DI based on LLM watermarks that\nequips data owners with rigorous statistical guarantees regarding their\ndataset's misuse in RAG corpora. Ward consistently outperforms all baselines,\nachieving higher accuracy, superior query efficiency and robustness. Our work\nprovides a foundation for future studies of RAG-DI and highlights LLM\nwatermarks as a promising approach to this problem.",
      "tldr_zh": "该研究针对 RAG（Retrieval-Augmented Generation）技术导致的大型语言模型（LLMs）对外部数据未授权使用的担忧，形式化了 RAG Dataset Inference (RAG-DI) 问题。论文引入了一个新的数据集和一组基线方法，用于实际基准测试 RAG-DI。作者提出 Ward 方法，该方法基于 LLM watermarks，提供对数据集误用的严格统计保证，并在准确性、查询效率和鲁棒性方面显著优于所有基线。该工作为未来的 RAG-DI 研究奠定了基础，并突出了 LLM watermarks 作为有效解决方案的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03537v2",
      "published_date": "2024-10-04 15:54:49 UTC",
      "updated_date": "2025-02-25 16:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:11:16.369811"
    },
    {
      "arxiv_id": "2410.03531v1",
      "title": "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Han Jiang",
        "Junwen Duan",
        "Zhe Qu",
        "Jianxin Wang"
      ],
      "abstract": "Unsupervised rationale extraction aims to extract text snippets to support\nmodel predictions without explicit rationale annotation. Researchers have made\nmany efforts to solve this task. Previous works often encode each aspect\nindependently, which may limit their ability to capture meaningful internal\ncorrelations between aspects. While there has been significant work on\nmitigating spurious correlations, our approach focuses on leveraging the\nbeneficial internal correlations to improve multi-aspect rationale extraction.\nIn this paper, we propose a Multi-Aspect Rationale Extractor (MARE) to explain\nand predict multiple aspects simultaneously. Concretely, we propose a\nMulti-Aspect Multi-Head Attention (MAMHA) mechanism based on hard deletion to\nencode multiple text chunks simultaneously. Furthermore, multiple special\ntokens are prepended in front of the text with each corresponding to one\ncertain aspect. Finally, multi-task training is deployed to reduce the training\noverhead. Experimental results on two unsupervised rationale extraction\nbenchmarks show that MARE achieves state-of-the-art performance. Ablation\nstudies further demonstrate the effectiveness of our method. Our codes have\nbeen available at https://github.com/CSU-NLP-Group/MARE.",
      "tldr_zh": "这篇论文提出了 MARE（Multi-Aspect Rationale Extractor），一种用于无监督 rationale extraction 的方法，通过利用方面之间的内部相关性来同时解释和预测多个方面，从而改善了传统方法的局限性。MARE 引入了 Multi-Aspect Multi-Head Attention (MAMHA) 机制、基于硬删除的文本块编码，以及在文本前添加对应方面的特殊 tokens，并采用多任务训练来减少训练开销。实验结果显示，MARE 在两个无监督 rationale extraction 基准上达到了最先进性能，消融研究进一步证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP2024(Main) conference",
      "pdf_url": "http://arxiv.org/pdf/2410.03531v1",
      "published_date": "2024-10-04 15:52:29 UTC",
      "updated_date": "2024-10-04 15:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:11:28.704774"
    },
    {
      "arxiv_id": "2410.03523v6",
      "title": "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Scholten",
        "Stephan Günnemann",
        "Leo Schwinn"
      ],
      "abstract": "Comprehensive evaluation of Large Language Models (LLMs) is an open research\nproblem. Existing evaluations rely on deterministic point estimates generated\nvia greedy decoding. However, we find that deterministic evaluations fail to\ncapture the whole output distribution of a model, yielding inaccurate\nestimations of model capabilities. This is particularly problematic in critical\ncontexts such as unlearning and alignment, where precise model evaluations are\ncrucial. To remedy this, we introduce the first formal probabilistic evaluation\nframework for LLMs. Namely, we propose novel metrics with high probability\nguarantees concerning the output distribution of a model. Our metrics are\napplication-independent and allow practitioners to make more reliable estimates\nabout model capabilities before deployment. Our experimental analysis reveals\nthat deterministic evaluations falsely indicate successful unlearning and\nalignment, whereas our probabilistic evaluations better capture model\ncapabilities. We show how to overcome challenges associated with probabilistic\noutputs in a case study on unlearning by introducing (1) a novel loss based on\nentropy optimization, and (2) adaptive temperature scaling. We demonstrate that\nour approach significantly enhances unlearning in probabilistic settings on\nrecent benchmarks. Overall, our proposed shift from point estimates to\nprobabilistic evaluations of output distributions represents an important step\ntoward comprehensive evaluations of LLMs. Code available at\nhttps://www.cs.cit.tum.de/daml/probabilistic-unlearning/.",
      "tldr_zh": "该论文从概率视角审视 Large Language Models (LLMs) 的 unlearning 和 alignment，指出现有依赖贪婪解码的确定性评估无法捕捉模型输出分布，导致评估不准确，尤其在关键应用中。作者提出首个正式的概率评估框架，包括新指标，这些指标针对输出分布提供高概率保证，并适用于独立应用，帮助更可靠地估计模型能力。实验结果显示，概率评估比确定性评估更准确，能揭示 unlearning 和 alignment 的真实效果；同时，通过引入基于熵优化的新损失函数和自适应温度缩放，论文显著提升了 unlearning 的性能。整体上，这标志着 LLM 评估从点估计向概率评估的重要转变。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2410.03523v6",
      "published_date": "2024-10-04 15:44:23 UTC",
      "updated_date": "2025-03-01 11:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:11:40.814769"
    },
    {
      "arxiv_id": "2410.03499v1",
      "title": "FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator",
      "title_zh": "翻译失败",
      "authors": [
        "Sunny Gupta",
        "Nikita Jangid",
        "Amit Sethi"
      ],
      "abstract": "Federated Learning (FL) facilitates data privacy by enabling collaborative\nin-situ training across decentralized clients. Despite its inherent advantages,\nFL faces significant challenges of performance and convergence when dealing\nwith data that is not independently and identically distributed (non-i.i.d.).\nWhile previous research has primarily addressed the issue of skewed label\ndistribution across clients, this study focuses on the less explored challenge\nof multi-domain FL, where client data originates from distinct domains with\nvarying feature distributions. We introduce a novel method designed to address\nthese challenges FedStein: Enhancing Multi-Domain Federated Learning Through\nthe James-Stein Estimator. FedStein uniquely shares only the James-Stein (JS)\nestimates of batch normalization (BN) statistics across clients, while\nmaintaining local BN parameters. The non-BN layer parameters are exchanged via\nstandard FL techniques. Extensive experiments conducted across three datasets\nand multiple models demonstrate that FedStein surpasses existing methods such\nas FedAvg and FedBN, with accuracy improvements exceeding 14% in certain\ndomains leading to enhanced domain generalization. The code is available at\nhttps://github.com/sunnyinAI/FedStein",
      "tldr_zh": "本研究针对联邦学习（Federated Learning, FL）在处理非独立同分布（non-i.i.d.）数据时的多域挑战，提出了一种新方法FedStein，通过James-Stein Estimator优化批量归一化（BN）统计量的共享。FedStein仅共享JS估计的BN统计量，同时保持本地BN参数，而非BN层参数则采用标准FL技术进行交换，从而提升模型的性能和收敛性。在三个数据集和多个模型的实验中，FedStein相较于FedAvg和FedBN等方法，准确率在某些域提升超过14%，显著提高了域泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC",
        "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 2 figures. Accepted at International Workshop on Federated\n  Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)",
      "pdf_url": "http://arxiv.org/pdf/2410.03499v1",
      "published_date": "2024-10-04 15:13:31 UTC",
      "updated_date": "2024-10-04 15:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:11:51.894669"
    },
    {
      "arxiv_id": "2410.03494v1",
      "title": "Generative Artificial Intelligence for Navigating Synthesizable Chemical Space",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Gao",
        "Shitong Luo",
        "Connor W. Coley"
      ],
      "abstract": "We introduce SynFormer, a generative modeling framework designed to\nefficiently explore and navigate synthesizable chemical space. Unlike\ntraditional molecular generation approaches, we generate synthetic pathways for\nmolecules to ensure that designs are synthetically tractable. By incorporating\na scalable transformer architecture and a diffusion module for building block\nselection, SynFormer surpasses existing models in synthesizable molecular\ndesign. We demonstrate SynFormer's effectiveness in two key applications: (1)\nlocal chemical space exploration, where the model generates synthesizable\nanalogs of a reference molecule, and (2) global chemical space exploration,\nwhere the model aims to identify optimal molecules according to a black-box\nproperty prediction oracle. Additionally, we demonstrate the scalability of our\napproach via the improvement in performance as more computational resources\nbecome available. With our code and trained models openly available, we hope\nthat SynFormer will find use across applications in drug discovery and\nmaterials science.",
      "tldr_zh": "本研究提出了一种生成式人工智能框架 SynFormer，用于高效探索和导航可合成化学空间。该框架通过生成分子的合成路径，确保设计的合成可行性，并结合可扩展的 Transformer 架构和扩散模块进行构建块选择，从而超越现有模型在可合成分子设计中的性能。SynFormer 在局部化学空间探索中生成参考分子的可合成类似物，在全局探索中识别黑箱属性预测的最佳分子，并展示性能随计算资源增加而提升。该框架的代码和训练模型已公开，可应用于药物发现和材料科学等领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03494v1",
      "published_date": "2024-10-04 15:09:05 UTC",
      "updated_date": "2024-10-04 15:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:12:04.078027"
    },
    {
      "arxiv_id": "2410.03489v2",
      "title": "Gradient-based Jailbreak Images for Multimodal Fusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Rando",
        "Hannah Korevaar",
        "Erik Brinkman",
        "Ivan Evtimov",
        "Florian Tramèr"
      ],
      "abstract": "Augmenting language models with image inputs may enable more effective\njailbreak attacks through continuous optimization, unlike text inputs that\nrequire discrete optimization. However, new multimodal fusion models tokenize\nall input modalities using non-differentiable functions, which hinders\nstraightforward attacks. In this work, we introduce the notion of a tokenizer\nshortcut that approximates tokenization with a continuous function and enables\ncontinuous optimization. We use tokenizer shortcuts to create the first\nend-to-end gradient image attacks against multimodal fusion models. We evaluate\nour attacks on Chameleon models and obtain jailbreak images that elicit harmful\ninformation for 72.5% of prompts. Jailbreak images outperform text jailbreaks\noptimized with the same objective and require 3x lower compute budget to\noptimize 50x more input tokens. Finally, we find that representation\nengineering defenses, like Circuit Breakers, trained only on text attacks can\neffectively transfer to adversarial image inputs.",
      "tldr_zh": "本研究提出了一种针对多模态融合模型的梯度图像jailbreak攻击方法，通过引入tokenizer shortcut来用连续函数近似标记化，从而实现端到端的梯度优化，避免了传统文本输入的离散优化限制。在Chameleon模型上评估，该攻击使72.5%的提示成功诱导有害信息输出，且比文本jailbreak攻击更高效，需要3倍更低的计算预算来优化50倍更多的输入标记。实验还发现，基于表示工程的防御如Circuit Breakers，仅在文本攻击上训练即可有效转移到对抗图像输入上。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03489v2",
      "published_date": "2024-10-04 14:59:39 UTC",
      "updated_date": "2024-10-23 13:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:12:16.404993"
    },
    {
      "arxiv_id": "2410.03487v1",
      "title": "A Multimodal Framework for Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Kashish Gandhi",
        "Prutha Kulkarni",
        "Taran Shah",
        "Piyush Chaudhari",
        "Meera Narvekar",
        "Kranti Ghag"
      ],
      "abstract": "The rapid advancement of deepfake technology poses a significant threat to\ndigital media integrity. Deepfakes, synthetic media created using AI, can\nconvincingly alter videos and audio to misrepresent reality. This creates risks\nof misinformation, fraud, and severe implications for personal privacy and\nsecurity. Our research addresses the critical issue of deepfakes through an\ninnovative multimodal approach, targeting both visual and auditory elements.\nThis comprehensive strategy recognizes that human perception integrates\nmultiple sensory inputs, particularly visual and auditory information, to form\na complete understanding of media content. For visual analysis, a model that\nemploys advanced feature extraction techniques was developed, extracting nine\ndistinct facial characteristics and then applying various machine learning and\ndeep learning models. For auditory analysis, our model leverages\nmel-spectrogram analysis for feature extraction and then applies various\nmachine learning and deep learningmodels. To achieve a combined analysis, real\nand deepfake audio in the original dataset were swapped for testing purposes\nand ensured balanced samples. Using our proposed models for video and audio\nclassification i.e. Artificial Neural Network and VGG19, the overall sample is\nclassified as deepfake if either component is identified as such. Our\nmultimodal framework combines visual and auditory analyses, yielding an\naccuracy of 94%.",
      "tldr_zh": "这篇论文提出了一种多模态框架，用于检测 deepfake 技术对数字媒体完整性的威胁，通过整合视觉和听觉分析来识别合成媒体。视觉分析采用高级特征提取技术，提取九种面部特征并应用机器学习和深度学习模型如 Artificial Neural Network 和 VGG19；听觉分析则基于 mel-spectrogram 进行特征提取，并使用类似模型进行分类。最终，该框架通过结合两种模态的检测结果（如果任一模态识别为 deepfake，则整体样本被判定为 deepfake），实现了94%的准确率，为防范 misinformation 和 fraud 提供了有效工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 14 figures, Accepted in Journal of Electrical Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.03487v1",
      "published_date": "2024-10-04 14:59:10 UTC",
      "updated_date": "2024-10-04 14:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:12:29.018257"
    },
    {
      "arxiv_id": "2410.03474v1",
      "title": "Group Fairness in Peer Review",
      "title_zh": "同行评审中的群体公平",
      "authors": [
        "Haris Aziz",
        "Evi Micha",
        "Nisarg Shah"
      ],
      "abstract": "Large conferences such as NeurIPS and AAAI serve as crossroads of various AI\nfields, since they attract submissions from a vast number of communities.\nHowever, in some cases, this has resulted in a poor reviewing experience for\nsome communities, whose submissions get assigned to less qualified reviewers\noutside of their communities. An often-advocated solution is to break up any\nsuch large conference into smaller conferences, but this can lead to isolation\nof communities and harm interdisciplinary research. We tackle this challenge by\nintroducing a notion of group fairness, called the core, which requires that\nevery possible community (subset of researchers) to be treated in a way that\nprevents them from unilaterally benefiting by withdrawing from a large\nconference.\n  We study a simple peer review model, prove that it always admits a reviewing\nassignment in the core, and design an efficient algorithm to find one such\nassignment. We use real data from CVPR and ICLR conferences to compare our\nalgorithm to existing reviewing assignment algorithms on a number of metrics.",
      "tldr_zh": "该论文探讨了大型学术会议（如NeurIPS和AAAI）中群体公平（group fairness）问题，旨在解决不同社区的提交可能被分配给不合格审稿人，导致不公平现象。作者引入了“core”公平概念，确保每个社区（研究者子集）无法通过退出会议而获益，从而平衡社区互动和跨学科合作。研究基于一个简单同行评审（peer review）模型，证明了总是存在符合core的评审分配，并设计了一个高效算法来实现这种分配。实验使用CVPR和ICLR真实数据，将该算法与其他现有算法比较，展示了其在公平性和效率上的优势。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.GT",
      "comment": "A preliminary version appeared at NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2410.03474v1",
      "published_date": "2024-10-04 14:48:10 UTC",
      "updated_date": "2024-10-04 14:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:12:39.596482"
    },
    {
      "arxiv_id": "2410.03470v1",
      "title": "Vulnerability Detection via Topological Analysis of Attention Maps",
      "title_zh": "通过注意力图的拓扑分析进行漏洞检测",
      "authors": [
        "Pavel Snopov",
        "Andrey Nikolaevich Golubinskiy"
      ],
      "abstract": "Recently, deep learning (DL) approaches to vulnerability detection have\ngained significant traction. These methods demonstrate promising results, often\nsurpassing traditional static code analysis tools in effectiveness.\n  In this study, we explore a novel approach to vulnerability detection\nutilizing the tools from topological data analysis (TDA) on the attention\nmatrices of the BERT model. Our findings reveal that traditional machine\nlearning (ML) techniques, when trained on the topological features extracted\nfrom these attention matrices, can perform competitively with pre-trained\nlanguage models (LLMs) such as CodeBERTa. This suggests that TDA tools,\nincluding persistent homology, are capable of effectively capturing semantic\ninformation critical for identifying vulnerabilities.",
      "tldr_zh": "本文提出了一种新方法，利用拓扑数据分析(TDA)对BERT模型的注意力矩阵进行分析，以提升漏洞检测的准确性。研究发现，通过提取这些矩阵的拓扑特征并应用传统机器学习(ML)技术进行训练，该方法能与预训练语言模型(LLMs)如CodeBERTa的性能相媲美。结果表明，TDA工具包括persistent homology，能够有效捕获识别漏洞的关键语义信息，从而为深度学习(DL)漏洞检测提供一种高效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ITaS2024. Contains 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03470v1",
      "published_date": "2024-10-04 14:40:11 UTC",
      "updated_date": "2024-10-04 14:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:12:52.480897"
    },
    {
      "arxiv_id": "2410.03463v5",
      "title": "Diffusion State-Guided Projected Gradient for Inverse Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Rayhan Zirvi",
        "Bahareh Tolooshams",
        "Anima Anandkumar"
      ],
      "abstract": "Recent advancements in diffusion models have been effective in learning data\npriors for solving inverse problems. They leverage diffusion sampling steps for\ninducing a data prior while using a measurement guidance gradient at each step\nto impose data consistency. For general inverse problems, approximations are\nneeded when an unconditionally trained diffusion model is used since the\nmeasurement likelihood is intractable, leading to inaccurate posterior\nsampling. In other words, due to their approximations, these methods fail to\npreserve the generation process on the data manifold defined by the diffusion\nprior, leading to artifacts in applications such as image restoration. To\nenhance the performance and robustness of diffusion models in solving inverse\nproblems, we propose Diffusion State-Guided Projected Gradient (DiffStateGrad),\nwhich projects the measurement gradient onto a subspace that is a low-rank\napproximation of an intermediate state of the diffusion process. DiffStateGrad,\nas a module, can be added to a wide range of diffusion-based inverse solvers to\nimprove the preservation of the diffusion process on the prior manifold and\nfilter out artifact-inducing components. We highlight that DiffStateGrad\nimproves the robustness of diffusion models in terms of the choice of\nmeasurement guidance step size and noise while improving the worst-case\nperformance. Finally, we demonstrate that DiffStateGrad improves upon the\nstate-of-the-art on linear and nonlinear image restoration inverse problems.\nOur code is available at https://github.com/Anima-Lab/DiffStateGrad.",
      "tldr_zh": "本论文针对扩散模型（diffusion models）在解决逆问题（inverse problems）时存在的近似误差和伪影（artifacts）问题，提出了一种新方法Diffusion State-Guided Projected Gradient (DiffStateGrad)。该方法将测量指导梯度（measurement guidance gradient）投影到扩散过程中间状态的低秩子空间，从而更好地保留数据流形上的生成过程，并提升模型在噪声和步长方面的鲁棒性。实验结果表明，DiffStateGrad 在线性、非线性图像恢复任务上超过了最先进的方法，提高了整体性能和最坏情况下的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025. RZ and BT have equal\n  contributions",
      "pdf_url": "http://arxiv.org/pdf/2410.03463v5",
      "published_date": "2024-10-04 14:26:54 UTC",
      "updated_date": "2025-04-01 04:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:13:05.618838"
    },
    {
      "arxiv_id": "2410.03448v2",
      "title": "\"Cold, Calculated, and Condescending\": How AI Identifies and Explains Ableism Compared to Disabled People",
      "title_zh": "翻译失败",
      "authors": [
        "Mahika Phutane",
        "Ananya Seelam",
        "Aditya Vashistha"
      ],
      "abstract": "People with disabilities (PwD) regularly encounter ableist hate and\nmicroaggressions online. These spaces are generally moderated by machine\nlearning models, but little is known about how effectively AI models identify\nableist speech and how well their judgments align with PwD. To investigate\nthis, we curated a first-of-its-kind dataset of 200 social media comments\ntargeted towards PwD, and prompted state-of-the art AI models (i.e., Toxicity\nClassifiers, LLMs) to score toxicity and ableism for each comment, and explain\ntheir reasoning. Then, we recruited 190 participants to similarly rate and\nexplain the harm, and evaluate LLM explanations. Our mixed-methods analysis\nhighlighted a major disconnect: AI underestimated toxicity compared to PwD\nratings, while its ableism assessments were sporadic and varied. Although LLMs\nidentified some biases, its explanations were flawed--they lacked nuance, made\nincorrect assumptions, and appeared judgmental instead of educational. Going\nforward, we discuss challenges and opportunities in designing moderation\nsystems for ableism, and advocate for the involvement of intersectional\ndisabled perspectives in AI.",
      "tldr_zh": "这篇论文探讨了AI模型（如Toxicity Classifiers和LLMs）在识别和解释针对残疾人士(PwD)的歧视性言论时的表现，并与PwD的看法进行比较。研究者创建了一个首创的200条社交媒体评论数据集，使用AI模型评分毒性和歧视性并提供解释，同时招募190名参与者进行类似评估和反馈。分析结果显示，AI低估了评论的毒性，其对歧视性的评估不一致，且解释缺乏细微性、包含错误假设，并显得判断性而非教育性。论文强调了在设计moderation systems时面临的挑战，并主张纳入交叉残疾视角，以提升AI的公平性和有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03448v2",
      "published_date": "2024-10-04 14:09:12 UTC",
      "updated_date": "2025-01-31 04:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:13:17.475529"
    },
    {
      "arxiv_id": "2410.03446v1",
      "title": "On Uncertainty In Natural Language Processing",
      "title_zh": "关于自然语言处理中的不确定性",
      "authors": [
        "Dennis Ulmer"
      ],
      "abstract": "The last decade in deep learning has brought on increasingly capable systems\nthat are deployed on a wide variety of applications. In natural language\nprocessing, the field has been transformed by a number of breakthroughs\nincluding large language models, which are used in increasingly many\nuser-facing applications. In order to reap the benefits of this technology and\nreduce potential harms, it is important to quantify the reliability of model\npredictions and the uncertainties that shroud their development.\n  This thesis studies how uncertainty in natural language processing can be\ncharacterized from a linguistic, statistical and neural perspective, and how it\ncan be reduced and quantified through the design of the experimental pipeline.\nWe further explore uncertainty quantification in modeling by theoretically and\nempirically investigating the effect of inductive model biases in text\nclassification tasks. The corresponding experiments include data for three\ndifferent languages (Danish, English and Finnish) and tasks as well as a large\nset of different uncertainty quantification approaches. Additionally, we\npropose a method for calibrated sampling in natural language generation based\non non-exchangeable conformal prediction, which provides tighter token sets\nwith better coverage of the actual continuation. Lastly, we develop an approach\nto quantify confidence in large black-box language models using auxiliary\npredictors, where the confidence is predicted from the input to and generated\noutput text of the target model alone.",
      "tldr_zh": "这篇论文探讨了Natural Language Processing中的不确定性，强调量化模型预测可靠性的重要性，以最大化大型语言模型(Large Language Models)的益处并减少潜在风险。从语言学、统计和神经角度分析不确定性，并通过实验设计减少和量化它。论文理论和实证调查了Inductive Model Biases在文本分类任务中的影响，涵盖Danish、English和Finnish三种语言及多种任务。还提出了一种基于Non-Exchangeable Conformal Prediction的校准采样方法，用于自然语言生成，提供更紧凑的标记集和更好的覆盖。最后，开发了一种使用Auxiliary Predictors量化大型黑箱语言模型置信度的方法，仅基于输入和输出文本。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.03446v1",
      "published_date": "2024-10-04 14:08:02 UTC",
      "updated_date": "2024-10-04 14:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:13:29.496566"
    },
    {
      "arxiv_id": "2410.03440v1",
      "title": "Exploring the Benefit of Activation Sparsity in Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyan Zhang",
        "Chaojun Xiao",
        "Qiujieli Qin",
        "Yankai Lin",
        "Zhiyuan Zeng",
        "Xu Han",
        "Zhiyuan Liu",
        "Ruobing Xie",
        "Maosong Sun",
        "Jie Zhou"
      ],
      "abstract": "Pre-trained Transformers inherently possess the characteristic of sparse\nactivation, where only a small fraction of the neurons are activated for each\ntoken. While sparse activation has been explored through post-training methods,\nits potential in pre-training remains untapped. In this work, we first study\nhow activation properties change during pre-training. Our examination reveals\nthat Transformers exhibit sparse activation throughout the majority of the\npre-training process while the activation correlation keeps evolving as\ntraining progresses. Leveraging this observation, we propose Switchable\nSparse-Dense Learning (SSD). SSD adaptively switches between the\nMixtures-of-Experts (MoE) based sparse training and the conventional dense\ntraining during the pre-training process, leveraging the efficiency of sparse\ntraining and avoiding the static activation correlation of sparse training.\nCompared to dense training, SSD achieves comparable performance with identical\nmodel size and reduces pre-training costs. Moreover, the models trained with\nSSD can be directly used as MoE models for sparse inference and achieve the\nsame performance as dense models with up to $2\\times$ faster inference speed.\nCodes are available at https://github.com/thunlp/moefication.",
      "tldr_zh": "本文研究了预训练 Transformer 的激活稀疏性（activation sparsity），发现这种特性在预训练过程中持续存在，但激活相关性（activation correlation）会随着训练进展而演变。作者提出 Switchable Sparse-Dense Learning (SSD) 方法，该方法在预训练中自适应切换 Mixtures-of-Experts (MoE) 基于的稀疏训练和传统的稠密训练（dense training），从而利用稀疏训练的效率并避免静态激活相关性问题。与稠密训练相比，SSD 实现了相似的性能，同时降低了预训练成本，并使模型支持稀疏推理，推理速度可提高至 2 倍。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03440v1",
      "published_date": "2024-10-04 13:53:33 UTC",
      "updated_date": "2024-10-04 13:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:13:40.266848"
    },
    {
      "arxiv_id": "2410.03435v1",
      "title": "A General Framework for Producing Interpretable Semantic Text Embeddings",
      "title_zh": "用于生成可解释语义文本嵌入的通用框架",
      "authors": [
        "Yiqun Sun",
        "Qiang Huang",
        "Yixuan Tang",
        "Anthony K. H. Tung",
        "Jun Yu"
      ],
      "abstract": "Semantic text embedding is essential to many tasks in Natural Language\nProcessing (NLP). While black-box models are capable of generating high-quality\nembeddings, their lack of interpretability limits their use in tasks that\ndemand transparency. Recent approaches have improved interpretability by\nleveraging domain-expert-crafted or LLM-generated questions, but these methods\nrely heavily on expert input or well-prompt design, which restricts their\ngeneralizability and ability to generate discriminative questions across a wide\nrange of tasks. To address these challenges, we introduce \\algo{CQG-MBQA}\n(Contrastive Question Generation - Multi-task Binary Question Answering), a\ngeneral framework for producing interpretable semantic text embeddings across\ndiverse tasks. Our framework systematically generates highly discriminative,\nlow cognitive load yes/no questions through the \\algo{CQG} method and answers\nthem efficiently with the \\algo{MBQA} model, resulting in interpretable\nembeddings in a cost-effective manner. We validate the effectiveness and\ninterpretability of \\algo{CQG-MBQA} through extensive experiments and ablation\nstudies, demonstrating that it delivers embedding quality comparable to many\nadvanced black-box models while maintaining inherently interpretability.\nAdditionally, \\algo{CQG-MBQA} outperforms other interpretable text embedding\nmethods across various downstream tasks.",
      "tldr_zh": "该研究提出了一种通用框架CQG-MBQA（Contrastive Question Generation - Multi-task Binary Question Answering），旨在生成可解释的语义文本嵌入，以解决现有黑盒模型缺乏透明性的问题。该框架通过CQG方法系统生成高区分度的低认知负荷是非问题，并利用MBQA模型高效回答这些问题，从而以成本有效的方式产生可解释嵌入。实验结果显示，CQG-MBQA在嵌入质量上可与先进黑盒模型媲美，并在各种下游任务中优于其他可解释文本嵌入方法，证明了其有效性和通用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 5 figures, and 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.03435v1",
      "published_date": "2024-10-04 13:51:19 UTC",
      "updated_date": "2024-10-04 13:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:13:51.769689"
    },
    {
      "arxiv_id": "2410.03434v1",
      "title": "Self-supervised Spatio-Temporal Graph Mask-Passing Attention Network for Perceptual Importance Prediction of Multi-point Tactility",
      "title_zh": "翻译失败",
      "authors": [
        "Dazhong He",
        "Qian Liu"
      ],
      "abstract": "While visual and auditory information are prevalent in modern multimedia\nsystems, haptic interaction, e.g., tactile and kinesthetic interaction,\nprovides a unique form of human perception. However, multimedia technology for\ncontact interaction is less mature than non-contact multimedia technologies and\nrequires further development. Specialized haptic media technologies, requiring\nlow latency and bitrates, are essential to enable haptic interaction,\nnecessitating haptic information compression. Existing vibrotactile signal\ncompression methods, based on the perceptual model, do not consider the\ncharacteristics of fused tactile perception at multiple spatially distributed\ninteraction points. In fact, differences in tactile perceptual importance are\nnot limited to conventional frequency and time domains, but also encompass\ndifferences in the spatial locations on the skin unique to tactile perception.\nFor the most frequently used tactile information, vibrotactile texture\nperception, we have developed a model to predict its perceptual importance at\nmultiple points, based on self-supervised learning and Spatio-Temporal Graph\nNeural Network. Current experimental results indicate that this model can\neffectively predict the perceptual importance of various points in multi-point\ntactile perception scenarios.",
      "tldr_zh": "该论文针对多点触觉感知的感知重要性预测问题，指出现有触觉信号压缩方法忽略了空间分布点之间的融合特性，如皮肤位置差异。研究提出了一种基于自监督学习(Self-supervised)的时空图掩码传递注意力网络(Spatio-Temporal Graph Mask-Passing Attention Network)，用于预测多点触觉交互中的感知重要性。实验结果表明，该模型在多点触觉感知场景中能有效预测各点的感知重要性，从而为触觉信息压缩技术提供新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "Published as a conference paper at Eurohaptics 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03434v1",
      "published_date": "2024-10-04 13:45:50 UTC",
      "updated_date": "2024-10-04 13:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:14:03.845076"
    },
    {
      "arxiv_id": "2410.03432v1",
      "title": "EB-NeRD: A Large-Scale Dataset for News Recommendation",
      "title_zh": "EB-NeRD：大规模新闻推荐数据集",
      "authors": [
        "Johannes Kruse",
        "Kasper Lindskow",
        "Saikishore Kalloori",
        "Marco Polignano",
        "Claudio Pomo",
        "Abhishek Srivastava",
        "Anshuk Uppal",
        "Michael Riis Andersen",
        "Jes Frellsen"
      ],
      "abstract": "Personalized content recommendations have been pivotal to the content\nexperience in digital media from video streaming to social networks. However,\nseveral domain specific challenges have held back adoption of recommender\nsystems in news publishing. To address these challenges, we introduce the\nEkstra Bladet News Recommendation Dataset (EB-NeRD). The dataset encompasses\ndata from over a million unique users and more than 37 million impression logs\nfrom Ekstra Bladet. It also includes a collection of over 125,000 Danish news\narticles, complete with titles, abstracts, bodies, and metadata, such as\ncategories. EB-NeRD served as the benchmark dataset for the RecSys '24\nChallenge, where it was demonstrated how the dataset can be used to address\nboth technical and normative challenges in designing effective and responsible\nrecommender systems for news publishing. The dataset is available at:\nhttps://recsys.eb.dk.",
      "tldr_zh": "这篇论文介绍了 EB-NeRD，一种大规模数据集，旨在解决新闻推荐系统在出版领域的采用挑战。数据集包含超过一百万独特用户的数据、超过3700万印象日志，以及12.5万篇丹麦新闻文章，包括标题、摘要、正文和元数据（如类别）。EB-NeRD 作为 RecSys '24 Challenge 的基准数据集，展示了如何处理新闻推荐的技术和规范问题，如有效性和责任性。数据集可从 https://recsys.eb.dk 获取，为开发可信赖的新闻推荐系统提供了宝贵资源。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 8 tables, 2 figures, RecSys '24",
      "pdf_url": "http://arxiv.org/pdf/2410.03432v1",
      "published_date": "2024-10-04 13:43:29 UTC",
      "updated_date": "2024-10-04 13:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:14:16.367148"
    },
    {
      "arxiv_id": "2410.03424v2",
      "title": "Cayley Graph Propagation",
      "title_zh": "Cayley 图传播",
      "authors": [
        "JJ Wilson",
        "Maya Bechler-Speicher",
        "Petar Veličković"
      ],
      "abstract": "In spite of the plethora of success stories with graph neural networks (GNNs)\non modelling graph-structured data, they are notoriously vulnerable to\nover-squashing, whereby tasks necessitate the mixing of information between\ndistance pairs of nodes. To address this problem, prior work suggests rewiring\nthe graph structure to improve information flow. Alternatively, a significant\nbody of research has dedicated itself to discovering and precomputing\nbottleneck-free graph structures to ameliorate over-squashing. One well\nregarded family of bottleneck-free graphs within the mathematical community are\nexpander graphs, with prior work -- Expander Graph Propagation (EGP) --\nproposing the use of a well-known expander graph family -- the Cayley graphs of\nthe $\\mathrm{SL}(2,\\mathbb{Z}_n)$ special linear group -- as a computational\ntemplate for GNNs. However, in EGP the computational graphs used are truncated\nto align with a given input graph. In this work, we show that truncation is\ndetrimental to the coveted expansion properties. Instead, we propose CGP, a\nmethod to propagate information over a complete Cayley graph structure, thereby\nensuring it is bottleneck-free to better alleviate over-squashing. Our\nempirical evidence across several real-world datasets not only shows that CGP\nrecovers significant improvements as compared to EGP, but it is also akin to or\noutperforms computationally complex graph rewiring techniques.",
      "tldr_zh": "这篇论文针对图神经网络(GNNs)的over-squashing问题，提出了一种新方法Cayley Graph Propagation (CGP)，通过在完整的Cayley graph结构上传播信息，确保无瓶颈并改善节点间信息流动。相比先前的工作Expander Graph Propagation (EGP)，CGP避免了图结构的截断，从而保留了expander graphs的扩展属性。实验结果显示，CGP在多个真实数据集上显著优于EGP，并在性能上与复杂的图重构技术相当或更胜一筹。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the Third Learning on Graphs Conference (LoG 2024),\n  PMLR 269. 20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03424v2",
      "published_date": "2024-10-04 13:32:34 UTC",
      "updated_date": "2025-05-19 17:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:14:29.299007"
    },
    {
      "arxiv_id": "2410.03810v1",
      "title": "Can Mamba Always Enjoy the \"Free Lunch\"?",
      "title_zh": "Mamba 能否始终享受“免费午餐”？",
      "authors": [
        "Ruifeng Ren",
        "Zhicong Li",
        "Yong Liu"
      ],
      "abstract": "Transformers have been the cornerstone of current Large Language Models\n(LLMs); however, its linear growth in overhead during inference with respect to\nsequence length poses challenges for modeling long sequences. In this context,\nMamba has gradually attracted attention due to its constant-level size during\ninference and existing empirical results have shown that it can perform\ncomparably to Transformers in sequence modeling while offering significant\nsavings. However, one may ask that, can Mamba always enjoy the ``free lunch\"?\nIn this paper, we focus on analyzing the expressive ability of Mamba from a\ntheoretical standpoint. First, inspired by the connection between Mamba and\nlinear attention, we investigate potential shortcomings of the Mamba when\nperforming the COPY operation. Our results indicate that Mamba with constant\nsize may encounter bottlenecks when handling COPY, while it can achieve perfect\nperformance when the size scales linearly with sequence length. Based on this\nobservation, we analyze Mamba's ability to tackle DP problems when equipped\nwith Chain of Thought (CoT). Our findings suggest that to solve arbitrary DP\nproblems, the total cost of Mamba is comparable to standard and efficient\nTransformers. However, similar to efficient Transformers, when facing DP\nproblems with favorable properties such as locality, Mamba can provide savings\nin overhead. Our results contribute to a deeper understanding of Mamba.",
      "tldr_zh": "该论文从理论角度分析了Mamba模型在序列建模中的表达能力，探讨其是否能始终如“免费午餐”般优于Transformers。研究发现，Mamba在处理COPY操作时可能存在瓶颈，需要大小线性增长以实现完美性能，而其固定大小的优势在某些场景下受限。基于Chain of Thought (CoT)，论文进一步评估了Mamba解决动态规划(DP)问题的能力，结果表明Mamba的总体成本与标准和高效Transformers相当，但在局部性强的DP问题上能节省开销。该工作加深了对Mamba局限性的理解，为序列模型设计提供参考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03810v1",
      "published_date": "2024-10-04 13:31:24 UTC",
      "updated_date": "2024-10-04 13:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:14:39.754295"
    },
    {
      "arxiv_id": "2410.03421v2",
      "title": "One2set + Large Language Model: Best Partners for Keyphrase Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Liangying Shao",
        "Liang Zhang",
        "Minlong Peng",
        "Guoqi Ma",
        "Hao Yue",
        "Mingming Sun",
        "Jinsong Su"
      ],
      "abstract": "Keyphrase generation (KPG) aims to automatically generate a collection of\nphrases representing the core concepts of a given document. The dominant\nparadigms in KPG include one2seq and one2set. Recently, there has been\nincreasing interest in applying large language models (LLMs) to KPG. Our\npreliminary experiments reveal that it is challenging for a single model to\nexcel in both recall and precision. Further analysis shows that: 1) the one2set\nparadigm owns the advantage of high recall, but suffers from improper\nassignments of supervision signals during training; 2) LLMs are powerful in\nkeyphrase selection, but existing selection methods often make redundant\nselections. Given these observations, we introduce a generate-then-select\nframework decomposing KPG into two steps, where we adopt a one2set-based model\nas generator to produce candidates and then use an LLM as selector to select\nkeyphrases from these candidates. Particularly, we make two important\nimprovements on our generator and selector: 1) we design an Optimal\nTransport-based assignment strategy to address the above improper assignments;\n2) we model the keyphrase selection as a sequence labeling task to alleviate\nredundant selections. Experimental results on multiple benchmark datasets show\nthat our framework significantly surpasses state-of-the-art models, especially\nin absent keyphrase prediction.",
      "tldr_zh": "这篇论文探讨了关键短语生成 (Keyphrase Generation, KPG) 的挑战，指出单一模型难以同时优化召回率 (recall) 和精确率 (precision)，并分析了 one2set 范式的高召回优势与监督信号分配问题，以及 Large Language Models (LLMs) 在选择中的冗余问题。论文提出一个 generate-then-select 框架：先使用 one2set-based 模型生成候选短语，并引入 Optimal Transport-based 分配策略来改进训练信号；然后利用 LLMs 将选择建模为序列标注任务，以减少冗余。实验结果显示，该框架在多个基准数据集上显著超越现有模型，尤其在 absent keyphrase prediction 方面的性能提升明显。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.03421v2",
      "published_date": "2024-10-04 13:31:09 UTC",
      "updated_date": "2024-10-21 02:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:14:53.343046"
    },
    {
      "arxiv_id": "2410.03420v2",
      "title": "Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Karl-Philippe Beaudet",
        "Alexandros Karargyris",
        "Sidaty El Hadramy",
        "Stéphane Cotin",
        "Jean-Paul Mazellier",
        "Nicolas Padoy",
        "Juan Verde"
      ],
      "abstract": "While laparoscopic liver resection is less prone to complications and\nmaintains patient outcomes compared to traditional open surgery, its complexity\nhinders widespread adoption due to challenges in representing the liver's\ninternal structure. Laparoscopic intraoperative ultrasound offers efficient,\ncost-effective and radiation-free guidance. Our objective is to aid physicians\nin identifying internal liver structures using laparoscopic intraoperative\nultrasound. We propose a patient-specific approach using preoperative 3D\nultrasound liver volume to train a deep learning model for real-time\nidentification of portal tree and branch structures. Our personalized AI model,\nvalidated on ex vivo swine livers, achieved superior precision (0.95) and\nrecall (0.93) compared to surgeons, laying groundwork for precise vessel\nidentification in ultrasound-based liver resection. Its adaptability and\npotential clinical impact promise to advance surgical interventions and improve\npatient care.",
      "tldr_zh": "该研究针对腹腔镜肝切除手术中肝脏内部结构表示的挑战，提出了一种患者特异性方法，使用术前3D超声肝脏体积训练深度学习模型，实现实时识别门静脉树和分支结构。模型在体外猪肝上验证，取得了优于外科医生的精确度（0.95）和召回率（0.93）。这一创新有望提升基于超声的肝切除手术的精确性，并改善手术干预和患者护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03420v2",
      "published_date": "2024-10-04 13:30:18 UTC",
      "updated_date": "2024-10-08 09:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:15:04.906831"
    },
    {
      "arxiv_id": "2410.03409v1",
      "title": "Comparative study of regression vs pairwise models for surrogate-based heuristic optimisation",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo S. Naharro",
        "Pablo Toharia",
        "Antonio LaTorre",
        "José-María Peña"
      ],
      "abstract": "Heuristic optimisation algorithms explore the search space by sampling\nsolutions, evaluating their fitness, and biasing the search in the direction of\npromising solutions. However, in many cases, this fitness function involves\nexecuting expensive computational calculations, drastically reducing the\nreasonable number of evaluations. In this context, surrogate models have\nemerged as an excellent alternative to alleviate these computational problems.\nThis paper addresses the formulation of surrogate problems as both regression\nmodels that approximate fitness (surface surrogate models) and a novel way to\nconnect classification models (pairwise surrogate models). The pairwise\napproach can be directly exploited by some algorithms, such as Differential\nEvolution, in which the fitness value is not actually needed to drive the\nsearch, and it is sufficient to know whether a solution is better than another\none or not. Based on these modelling approaches, we have conducted a\nmultidimensional analysis of surrogate models under different configurations:\ndifferent machine learning algorithms (regularised regression, neural networks,\ndecision trees, boosting methods, and random forests), different surrogate\nstrategies (encouraging diversity or relaxing prediction thresholds), and\ncompare them for both surface and pairwise surrogate models. The experimental\npart of the article includes the benchmark problems already proposed for the\nSOCO2011 competition in continuous optimisation and a simulation problem\nincluded in the recent GECCO2021 Industrial Challenge. This paper shows that\nthe performance of the overall search, when using online machine learning-based\nsurrogate models, depends not only on the accuracy of the predictive model but\nalso on both the kind of bias towards positive or negative cases and how the\noptimisation uses those predictions to decide whether to execute the actual\nfitness function.",
      "tldr_zh": "本研究比较了回归模型（regression models）和配对模型（pairwise models）作为代理模型（surrogate models）在启发式优化（heuristic optimisation）中的应用，以缓解昂贵适应度评估计算的问题。论文探讨了不同机器学习算法（如正则化回归、神经网络、决策树、提升方法和随机森林）以及代理策略（如鼓励多样性或放宽预测阈值），并评估了surface和pairwise模型的表现。实验基于SOCO2011和GECCO2021的基准优化问题，结果表明，整体搜索性能不仅取决于预测模型的准确性，还受正负案例偏置以及优化算法如何利用这些预测的影响。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03409v1",
      "published_date": "2024-10-04 13:19:06 UTC",
      "updated_date": "2024-10-04 13:19:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:15:16.712951"
    },
    {
      "arxiv_id": "2410.03399v2",
      "title": "EBES: Easy Benchmarking for Event Sequences",
      "title_zh": "EBES：事件序列的易用基准测试",
      "authors": [
        "Dmitry Osin",
        "Igor Udovichenko",
        "Viktor Moskvoretskii",
        "Egor Shvetsov",
        "Evgeny Burnaev"
      ],
      "abstract": "Event Sequences (EvS) refer to sequential data characterized by irregular\nsampling intervals and a mix of categorical and numerical features. Accurate\nclassification of these sequences is crucial for various real-life\napplications, including healthcare, finance, and user interaction. Despite the\npopularity of the EvS classification task, there is currently no standardized\nbenchmark or rigorous evaluation protocol. This lack of standardization makes\nit difficult to compare results across studies, which can result in unreliable\nconclusions and hinder progress in the field. To address this gap, we present\nEBES, a comprehensive benchmark for EvS classification with sequence-level\ntargets. EBES features standardized evaluation scenarios and protocols, along\nwith an open-source PyTorch library that implements 9 modern models.\nAdditionally, it includes the largest collection of EvS datasets, featuring 10\ncurated datasets, including a novel synthetic dataset and real-world data with\nthe largest publicly available banking dataset. The library offers\nuser-friendly interfaces for integrating new methods and datasets. Our\nbenchmarking results highlight the unique properties of EvS compared to other\nsequential data types, provide a performance ranking of modern models with\nGRU-based models achieving the best results and reveal the challenges\nassociated with robust EvS learning. The goal of EBES is to facilitate\nreproducible research, expedite progress in the field, and increase the\nreal-world impact of EvS classification techniques.",
      "tldr_zh": "本文提出 EBES，这是一个针对 Event Sequences (EvS) 分类任务的标准化基准，旨在解决 EvS 数据（不规则采样间隔、混合类别和数值特征）在医疗、金融和用户互动等领域缺乏统一评估协议的问题。EBES 包括标准化评估场景、一个开源 PyTorch 库（实现 9 个现代模型）和 10 个数据集（如一个新合成数据集和最大的公开银行数据集），并提供用户友好的接口以便集成新方法。基准结果显示，GRU-based 模型在 EvS 任务中表现出色，同时揭示了 EvS 与其他序列数据的独特挑战，从而促进可重复研究和领域进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03399v2",
      "published_date": "2024-10-04 13:03:43 UTC",
      "updated_date": "2025-02-25 20:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:15:28.836872"
    },
    {
      "arxiv_id": "2410.03396v1",
      "title": "GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Shijin Duan",
        "Ruyi Ding",
        "Jiaxing He",
        "Aidong Adam Ding",
        "Yunsi Fei",
        "Xiaolin Xu"
      ],
      "abstract": "Graph-structured data is integral to many applications, prompting the\ndevelopment of various graph representation methods. Graph autoencoders (GAEs),\nin particular, reconstruct graph structures from node embeddings. Current GAE\nmodels primarily utilize self-correlation to represent graph structures and\nfocus on node-level tasks, often overlooking multi-graph scenarios. Our\ntheoretical analysis indicates that self-correlation generally falls short in\naccurately representing specific graph features such as islands, symmetrical\nstructures, and directional edges, particularly in smaller or multiple graph\ncontexts. To address these limitations, we introduce a cross-correlation\nmechanism that significantly enhances the GAE representational capabilities.\nAdditionally, we propose GraphCroc, a new GAE that supports flexible encoder\narchitectures tailored for various downstream tasks and ensures robust\nstructural reconstruction, through a mirrored encoding-decoding process. This\nmodel also tackles the challenge of representation bias during optimization by\nimplementing a loss-balancing strategy. Both theoretical analysis and numerical\nevaluations demonstrate that our methodology significantly outperforms existing\nself-correlation-based GAEs in graph structure reconstruction.",
      "tldr_zh": "该论文分析了现有图自编码器(GAEs)依赖自相关(self-correlation)的局限性，导致在表示岛屿、对称结构和定向边等图特征时表现不足，尤其在多图场景中。  \n为了解决这些问题，作者引入交叉相关(cross-correlation)机制，并提出GraphCroc模型，该模型支持灵活的编码器架构，通过镜像编码-解码过程实现鲁棒的图结构重建，并采用损失平衡策略减少优化过程中的表示偏差。  \n实验结果显示，GraphCroc在图结构重建任务上显著优于基于自相关的GAEs方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 16 figures. Accepted in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03396v1",
      "published_date": "2024-10-04 12:59:45 UTC",
      "updated_date": "2024-10-04 12:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:15:41.364139"
    },
    {
      "arxiv_id": "2410.03380v2",
      "title": "Identifying perturbation targets through causal differential networks",
      "title_zh": "通过因果差异网络识别扰动目标",
      "authors": [
        "Menghua Wu",
        "Umesh Padia",
        "Sean H. Murphy",
        "Regina Barzilay",
        "Tommi Jaakkola"
      ],
      "abstract": "Identifying variables responsible for changes to a biological system enables\napplications in drug target discovery and cell engineering. Given a pair of\nobservational and interventional datasets, the goal is to isolate the subset of\nobserved variables that were the targets of the intervention. Directly applying\ncausal discovery algorithms is challenging: the data may contain thousands of\nvariables with as few as tens of samples per intervention, and biological\nsystems do not adhere to classical causality assumptions. We propose a\ncausality-inspired approach to address this practical setting. First, we infer\nnoisy causal graphs from the observational and interventional data. Then, we\nlearn to map the differences between these graphs, along with additional\nstatistical features, to sets of variables that were intervened upon. Both\nmodules are jointly trained in a supervised framework, on simulated and real\ndata that reflect the nature of biological interventions. This approach\nconsistently outperforms baselines for perturbation modeling on seven\nsingle-cell transcriptomics datasets. We also demonstrate significant\nimprovements over current causal discovery methods for predicting soft and hard\nintervention targets across a variety of synthetic data.",
      "tldr_zh": "本研究旨在通过因果差分网络（causal differential networks）识别生物系统中干预目标变量，以支持药物靶点发现和细胞工程。方法包括从观察数据和干预数据中推断嘈杂的因果图（causal graphs），然后利用这些图的差异以及额外统计特征，通过监督学习训练模块来映射被干预变量集。实验结果显示，该方法在七个单细胞转录组学（single-cell transcriptomics）数据集上优于基线模型，并在合成数据中显著提升了预测软干预和硬干预目标的因果发现（causal discovery）性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03380v2",
      "published_date": "2024-10-04 12:48:21 UTC",
      "updated_date": "2025-02-10 16:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:15:51.845261"
    },
    {
      "arxiv_id": "2410.03376v1",
      "title": "Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization",
      "title_zh": "通过向量量化缓解深度强化学习的敌对",
      "authors": [
        "Tung M. Luu",
        "Thanh Nguyen",
        "Tee Joshua Tian Jin",
        "Sungwoon Kim",
        "Chang D. Yoo"
      ],
      "abstract": "Recent studies reveal that well-performing reinforcement learning (RL) agents\nin training often lack resilience against adversarial perturbations during\ndeployment. This highlights the importance of building a robust agent before\ndeploying it in the real world. Most prior works focus on developing robust\ntraining-based procedures to tackle this problem, including enhancing the\nrobustness of the deep neural network component itself or adversarially\ntraining the agent on strong attacks. In this work, we instead study an input\ntransformation-based defense for RL. Specifically, we propose using a variant\nof vector quantization (VQ) as a transformation for input observations, which\nis then used to reduce the space of adversarial attacks during testing,\nresulting in the transformed observations being less affected by attacks. Our\nmethod is computationally efficient and seamlessly integrates with adversarial\ntraining, further enhancing the robustness of RL agents against adversarial\nattacks. Through extensive experiments in multiple environments, we demonstrate\nthat using VQ as the input transformation effectively defends against\nadversarial attacks on the agent's observations.",
      "tldr_zh": "该研究针对强化学习（RL）代理在部署时易受对抗性扰动（adversarial perturbations）的影响，提出了一种基于输入变换的防御方法。作者使用 Vector Quantization (VQ) 的变体对输入观察进行变换，以缩小攻击空间并降低对代理的干扰，同时该方法计算高效且能与对抗训练（adversarial training）无缝整合。通过在多个环境中的广泛实验，证明了 VQ 输入变换能显著提升 RL 代理的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, IROS 2024 (Code: https://github.com/tunglm2203/vq_robust_rl)",
      "pdf_url": "http://arxiv.org/pdf/2410.03376v1",
      "published_date": "2024-10-04 12:41:54 UTC",
      "updated_date": "2024-10-04 12:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:16:04.700886"
    },
    {
      "arxiv_id": "2410.03375v1",
      "title": "SoundSignature: What Type of Music Do You Like?",
      "title_zh": "SoundSignature：你喜欢什么类型的音乐？",
      "authors": [
        "Brandon James Carone",
        "Pablo Ripollés"
      ],
      "abstract": "SoundSignature is a music application that integrates a custom OpenAI\nAssistant to analyze users' favorite songs. The system incorporates\nstate-of-the-art Music Information Retrieval (MIR) Python packages to combine\nextracted acoustic/musical features with the assistant's extensive knowledge of\nthe artists and bands. Capitalizing on this combined knowledge, SoundSignature\nleverages semantic audio and principles from the emerging Internet of Sounds\n(IoS) ecosystem, integrating MIR with AI to provide users with personalized\ninsights into the acoustic properties of their music, akin to a musical\npreference personality report. Users can then interact with the chatbot to\nexplore deeper inquiries about the acoustic analyses performed and how they\nrelate to their musical taste. This interactivity transforms the application,\nacting not only as an informative resource about familiar and/or favorite\nsongs, but also as an educational platform that enables users to deepen their\nunderstanding of musical features, music theory, acoustic properties commonly\nused in signal processing, and the artists behind the music. Beyond general\nusability, the application also incorporates several well-established\nopen-source musician-specific tools, such as a chord recognition algorithm\n(CREMA), a source separation algorithm (DEMUCS), and an audio-to-MIDI converter\n(basic-pitch). These features allow users without coding skills to access\nadvanced, open-source music processing algorithms simply by interacting with\nthe chatbot (e.g., can you give me the stems of this song?). In this paper, we\nhighlight the application's innovative features and educational potential, and\npresent findings from a pilot user study that evaluates its efficacy and\nusability.",
      "tldr_zh": "本研究介绍了SoundSignature，一款整合自定义OpenAI Assistant的音乐应用，利用Music Information Retrieval (MIR) 包提取声学/音乐特征，并结合语义音频和Internet of Sounds (IoS) 原则，为用户提供个性化的音乐偏好报告。用户可通过聊天机器人互动，深入探索歌曲分析、音乐理论和声学属性，同时访问开源工具如CREMA（chord recognition）、DEMUCS（source separation）和basic-pitch（audio-to-MIDI converter），无需编程技能即可处理音乐。试点用户研究表明，该应用在教育价值和可用性方面表现出色，有助于用户加深对音乐和艺术家的理解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 1 figure, to be published in the 2024 International\n  Symposium on the IEEE Internet of Sounds Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2410.03375v1",
      "published_date": "2024-10-04 12:40:45 UTC",
      "updated_date": "2024-10-04 12:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:16:17.210278"
    },
    {
      "arxiv_id": "2410.03373v1",
      "title": "Make Interval Bound Propagation great again",
      "title_zh": "让 Interval Bound Propagation 再次伟大",
      "authors": [
        "Patryk Krukowski",
        "Daniel Wilczak",
        "Jacek Tabor",
        "Anna Bielawska",
        "Przemysław Spurek"
      ],
      "abstract": "In various scenarios motivated by real life, such as medical data analysis,\nautonomous driving, and adversarial training, we are interested in robust deep\nnetworks. A network is robust when a relatively small perturbation of the input\ncannot lead to drastic changes in output (like change of class, etc.). This\nfalls under the broader scope field of Neural Network Certification (NNC). Two\ncrucial problems in NNC are of profound interest to the scientific community:\nhow to calculate the robustness of a given pre-trained network and how to\nconstruct robust networks. The common approach to constructing robust networks\nis Interval Bound Propagation (IBP). This paper demonstrates that IBP is\nsub-optimal in the first case due to its susceptibility to the wrapping effect.\nEven for linear activation, IBP gives strongly sub-optimal bounds.\nConsequently, one should use strategies immune to the wrapping effect to obtain\nbounds close to optimal ones. We adapt two classical approaches dedicated to\nstrict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate\nthe wrapping effect in neural networks. These techniques yield precise results\nfor networks with linear activation functions, thus resisting the wrapping\neffect. As a result, we achieve bounds significantly closer to the optimal\nlevel than IBPs.",
      "tldr_zh": "这篇论文针对神经网络认证（NNC）中的鲁棒性计算问题，指出 Interval Bound Propagation (IBP) 由于 wrapping effect 的影响而在计算预训练网络的鲁棒边界时表现次优，甚至在线性激活函数下也给出次优结果。作者适应了 Dubleton Arithmetic 和 Affine Arithmetic 等经典方法来缓解 wrapping effect，这些技术为线性激活网络提供更精确的边界。结果显示，这些方法使鲁棒边界显著接近最优水平，比 IBP 更有效，从而有助于构建更可靠的深度网络应用于医疗数据分析、自动驾驶等领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03373v1",
      "published_date": "2024-10-04 12:39:46 UTC",
      "updated_date": "2024-10-04 12:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:16:29.890062"
    },
    {
      "arxiv_id": "2410.03359v1",
      "title": "An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Bill Cassidy",
        "Christian Mcbride",
        "Connah Kendrick",
        "Neil D. Reeves",
        "Joseph M. Pappachan",
        "Cornelius J. Fernandez",
        "Elias Chacko",
        "Raphael Brüngel",
        "Christoph M. Friedrich",
        "Metib Alotaibi",
        "Abdullah Abdulaziz AlWabel",
        "Mohammad Alderwish",
        "Kuan-Ying Lai",
        "Moi Hoon Yap"
      ],
      "abstract": "Chronic wounds and associated complications present ever growing burdens for\nclinics and hospitals world wide. Venous, arterial, diabetic, and pressure\nwounds are becoming increasingly common globally. These conditions can result\nin highly debilitating repercussions for those affected, with limb amputations\nand increased mortality risk resulting from infection becoming more common. New\nmethods to assist clinicians in chronic wound care are therefore vital to\nmaintain high quality care standards. This paper presents an improved HarDNet\nsegmentation architecture which integrates a contrast-eliminating component in\nthe initial layers of the network to enhance feature learning. We also utilise\na multi-colour space tensor merging process and adjust the harmonic shape of\nthe convolution blocks to facilitate these additional features. We train our\nproposed model using wound images from light-skinned patients and test the\nmodel on two test sets (one set with ground truth, and one without) comprising\nonly darker-skinned cases. Subjective ratings are obtained from clinical wound\nexperts with intraclass correlation coefficient used to determine inter-rater\nreliability. For the dark-skin tone test set with ground truth, we demonstrate\nimprovements in terms of Dice similarity coefficient (+0.1221) and intersection\nover union (+0.1274). Qualitative analysis showed high expert ratings, with\nimprovements of >3% demonstrated when comparing the baseline model with the\nproposed model. This paper presents the first study to focus on darker-skin\ntones for chronic wound segmentation using models trained only on wound images\nexhibiting lighter skin. Diabetes is highly prevalent in countries where\npatients have darker skin tones, highlighting the need for a greater focus on\nsuch cases. Additionally, we conduct the largest qualitative study to date for\nchronic wound segmentation.",
      "tldr_zh": "这篇论文提出了一种增强的 HarDNet 架构，用于慢性伤口分割，整合了对比消除组件、多颜色空间张量合并（multi-colour space tensor merging）和调整的卷积块（harmonic shape of the convolution blocks），以提升特征学习和模型性能。模型使用浅肤色患者图像训练，并在深肤色患者图像上测试，结果显示 Dice similarity coefficient 提高了 0.1221，intersection over union 提高了 0.1274，主观专家评分也提升了超过 3%。该研究首次专注于深肤色伤口分割，并进行了迄今为止最大的定性评估，强调了在糖尿病高发地区的需求，以改善临床护理标准。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03359v1",
      "published_date": "2024-10-04 12:26:51 UTC",
      "updated_date": "2024-10-04 12:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:16:41.429509"
    },
    {
      "arxiv_id": "2410.05301v2",
      "title": "Diffusion-based Unsupervised Audio-visual Speech Enhancement",
      "title_zh": "基于扩散的无监督音频-视觉语音增强",
      "authors": [
        "Jean-Eudes Ayilo",
        "Mostafa Sadeghi",
        "Romain Serizel",
        "Xavier Alameda-Pineda"
      ],
      "abstract": "This paper proposes a new unsupervised audio-visual speech enhancement (AVSE)\napproach that combines a diffusion-based audio-visual speech generative model\nwith a non-negative matrix factorization (NMF) noise model. First, the\ndiffusion model is pre-trained on clean speech conditioned on corresponding\nvideo data to simulate the speech generative distribution. This pre-trained\nmodel is then paired with the NMF-based noise model to estimate clean speech\niteratively. Specifically, a diffusion-based posterior sampling approach is\nimplemented within the reverse diffusion process, where after each iteration, a\nspeech estimate is obtained and used to update the noise parameters.\nExperimental results confirm that the proposed AVSE approach not only\noutperforms its audio-only counterpart but also generalizes better than a\nrecent supervised-generative AVSE method. Additionally, the new inference\nalgorithm offers a better balance between inference speed and performance\ncompared to the previous diffusion-based method. Code and demo available at:\nhttps://jeaneudesayilo.github.io/fast_UdiffSE",
      "tldr_zh": "这篇论文提出了一种基于扩散的无监督音频-视觉语音增强 (AVSE) 方法，将 diffusion-based 音频-视觉语音生成模型与非负矩阵分解 (NMF) 噪声模型相结合，先预训练扩散模型来模拟干净语音的生成分布，然后通过迭代的后验采样过程估计干净语音并更新噪声参数。实验结果显示，该方法不仅在性能上优于仅音频的对应方法，还比最近的监督生成 AVSE 方法具有更好的泛化能力。此外，该方法的推理算法在推理速度和性能之间实现了更好的平衡。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05301v2",
      "published_date": "2024-10-04 12:22:54 UTC",
      "updated_date": "2025-01-15 09:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:16:53.519992"
    },
    {
      "arxiv_id": "2410.03355v3",
      "title": "LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding",
      "title_zh": "LANTERN：通过",
      "authors": [
        "Doohyuk Jang",
        "Sihwan Park",
        "June Yong Yang",
        "Yeonsung Jung",
        "Jihun Yun",
        "Souvik Kundu",
        "Sung-Yub Kim",
        "Eunho Yang"
      ],
      "abstract": "Auto-Regressive (AR) models have recently gained prominence in image\ngeneration, often matching or even surpassing the performance of diffusion\nmodels. However, one major limitation of AR models is their sequential nature,\nwhich processes tokens one at a time, slowing down generation compared to\nmodels like GANs or diffusion-based methods that operate more efficiently.\nWhile speculative decoding has proven effective for accelerating LLMs by\ngenerating multiple tokens in a single forward, its application in visual AR\nmodels remains largely unexplored. In this work, we identify a challenge in\nthis setting, which we term \\textit{token selection ambiguity}, wherein visual\nAR models frequently assign uniformly low probabilities to tokens, hampering\nthe performance of speculative decoding. To overcome this challenge, we propose\na relaxed acceptance condition referred to as LANTERN that leverages the\ninterchangeability of tokens in latent space. This relaxation restores the\neffectiveness of speculative decoding in visual AR models by enabling more\nflexible use of candidate tokens that would otherwise be prematurely rejected.\nFurthermore, by incorporating a total variation distance bound, we ensure that\nthese speed gains are achieved without significantly compromising image quality\nor semantic coherence. Experimental results demonstrate the efficacy of our\nmethod in providing a substantial speed-up over speculative decoding. In\nspecific, compared to a na\\\"ive application of the state-of-the-art speculative\ndecoding, LANTERN increases speed-ups by $\\mathbf{1.75}\\times$ and\n$\\mathbf{1.82}\\times$, as compared to greedy decoding and random sampling,\nrespectively, when applied to LlamaGen, a contemporary visual AR model. The\ncode is publicly available at https://github.com/jadohu/LANTERN.",
      "tldr_zh": "本研究针对视觉Auto-Regressive (AR) 模型在图像生成中的速度瓶颈，提出LANTERN方法，通过relaxed speculative decoding来加速生成过程。LANTERN解决了token selection ambiguity问题，利用latent space中tokens的可互换性，引入relaxed acceptance condition和total variation distance bound，确保生成速度提升的同时不显著影响图像质量或语义一致性。实验结果显示，在LlamaGen模型上，LANTERN相比naive speculative decoding提高了1.75倍速度，并分别比greedy decoding和random sampling提高了1.75倍和1.82倍，证明了其在提升视觉AR模型效率方面的显著贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "30 pages, 13 figures, Accepted to ICLR 2025 (poster)",
      "pdf_url": "http://arxiv.org/pdf/2410.03355v3",
      "published_date": "2024-10-04 12:21:03 UTC",
      "updated_date": "2025-03-02 07:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:17:45.780712"
    },
    {
      "arxiv_id": "2410.03334v1",
      "title": "An X-Ray Is Worth 15 Features: Sparse Autoencoders for Interpretable Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abdulaal",
        "Hugo Fry",
        "Nina Montaña-Brown",
        "Ayodeji Ijishakin",
        "Jack Gao",
        "Stephanie Hyland",
        "Daniel C. Alexander",
        "Daniel C. Castro"
      ],
      "abstract": "Radiological services are experiencing unprecedented demand, leading to\nincreased interest in automating radiology report generation. Existing\nVision-Language Models (VLMs) suffer from hallucinations, lack\ninterpretability, and require expensive fine-tuning. We introduce SAE-Rad,\nwhich uses sparse autoencoders (SAEs) to decompose latent representations from\na pre-trained vision transformer into human-interpretable features. Our hybrid\narchitecture combines state-of-the-art SAE advancements, achieving accurate\nlatent reconstructions while maintaining sparsity. Using an off-the-shelf\nlanguage model, we distil ground-truth reports into radiological descriptions\nfor each SAE feature, which we then compile into a full report for each image,\neliminating the need for fine-tuning large models for this task. To the best of\nour knowledge, SAE-Rad represents the first instance of using mechanistic\ninterpretability techniques explicitly for a downstream multi-modal reasoning\ntask. On the MIMIC-CXR dataset, SAE-Rad achieves competitive radiology-specific\nmetrics compared to state-of-the-art models while using significantly fewer\ncomputational resources for training. Qualitative analysis reveals that SAE-Rad\nlearns meaningful visual concepts and generates reports aligning closely with\nexpert interpretations. Our results suggest that SAEs can enhance multimodal\nreasoning in healthcare, providing a more interpretable alternative to existing\nVLMs.",
      "tldr_zh": "本研究提出 SAE-Rad 框架，使用 sparse autoencoders (SAEs) 将预训练 Vision Transformer 的潜在表示分解成人类可解释的特征，以解决现有 Vision-Language Models (VLMs) 在放射报告生成中的幻觉问题、可解释性不足和微调成本高的问题。SAE-Rad 采用混合架构，结合先进的 SAE 技术实现准确的潜在重建和稀疏性维护，并通过现成语言模型将 ground-truth 报告提炼成每个特征的放射描述，最终编译成完整报告，而无需微调大型模型。在 MIMIC-CXR 数据集上，SAE-Rad 达到与最先进模型相当的放射学特定指标，但使用更少的计算资源；定性分析显示，它学习了有意义的视觉概念，并生成与专家解释紧密对齐的报告，从而为医疗多模态推理提供更可解释的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03334v1",
      "published_date": "2024-10-04 11:40:21 UTC",
      "updated_date": "2024-10-04 11:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:17:17.361441"
    },
    {
      "arxiv_id": "2410.03333v1",
      "title": "Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification",
      "title_zh": "领先的 CNN 架构的比较分析和集成增强用于乳腺癌分类",
      "authors": [
        "Gary Murphy",
        "Raghubir Singh"
      ],
      "abstract": "This study introduces a novel and accurate approach to breast cancer\nclassification using histopathology images. It systematically compares leading\nConvolutional Neural Network (CNN) models across varying image datasets,\nidentifies their optimal hyperparameters, and ranks them based on\nclassification efficacy. To maximize classification accuracy for each model we\nexplore, the effects of data augmentation, alternative fully-connected layers,\nmodel training hyperparameter settings, and, the advantages of retraining\nmodels versus using pre-trained weights. Our methodology includes several\noriginal concepts, including serializing generated datasets to ensure\nconsistent data conditions across training runs and significantly reducing\ntraining duration. Combined with automated curation of results, this enabled\nthe exploration of over 2,000 training permutations -- such a comprehensive\ncomparison is as yet unprecedented. Our findings establish the settings\nrequired to achieve exceptional classification accuracy for standalone CNN\nmodels and rank them by model efficacy. Based on these results, we propose\nensemble architectures that stack three high-performing standalone CNN models\ntogether with diverse classifiers, resulting in improved classification\naccuracy. The ability to systematically run so many model permutations to get\nthe best outcomes gives rise to very high quality results, including 99.75% for\nBreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into\ntrain, validation and test datasets. The Bach Online blind challenge, yielded\n89% using this approach. Whilst this study is based on breast cancer\nhistopathology image datasets, the methodology is equally applicable to other\nmedical image datasets.",
      "tldr_zh": "本研究系统比较了领先的 CNN 模型在乳腺癌组织病理图像分类中的性能，通过优化数据增强、超参数设置和训练策略（如使用预训练权重），探索了超过 2000 个训练组合，以实现模型的最高准确率。研究引入原创方法，如序列化数据集以确保一致性和减少训练时间，并基于比较结果对模型进行排名。最终，提出 ensemble architectures，将多个高性能 CNN 模型与多样化分类器结合，显著提升分类准确率，在 BreakHis x40 和 x200 数据集上达到 99.75%，Bach 数据集上达 95.18%，Bach Online 盲挑战上达 89%。该方法不仅适用于乳腺癌分类，还可扩展到其他医疗图像数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03333v1",
      "published_date": "2024-10-04 11:31:43 UTC",
      "updated_date": "2024-10-04 11:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:17:28.888952"
    },
    {
      "arxiv_id": "2410.03315v1",
      "title": "Influence-oriented Personalized Federated Learning",
      "title_zh": "影响导向的个性化联邦学习",
      "authors": [
        "Yue Tan",
        "Guodong Long",
        "Jing Jiang",
        "Chengqi Zhang"
      ],
      "abstract": "Traditional federated learning (FL) methods often rely on fixed weighting for\nparameter aggregation, neglecting the mutual influence by others. Hence, their\neffectiveness in heterogeneous data contexts is limited. To address this\nproblem, we propose an influence-oriented federated learning framework, namely\nFedC^2I, which quantitatively measures Client-level and Class-level Influence\nto realize adaptive parameter aggregation for each client. Our core idea is to\nexplicitly model the inter-client influence within an FL system via the\nwell-crafted influence vector and influence matrix. The influence vector\nquantifies client-level influence, enables clients to selectively acquire\nknowledge from others, and guides the aggregation of feature representation\nlayers. Meanwhile, the influence matrix captures class-level influence in a\nmore fine-grained manner to achieve personalized classifier aggregation. We\nevaluate the performance of FedC^2I against existing federated learning methods\nunder non-IID settings and the results demonstrate the superiority of our\nmethod.",
      "tldr_zh": "本研究针对传统联邦学习（FL）方法的固定权重聚合问题，提出了一种影响导向的个性化联邦学习框架FedC^2I，以解决异构数据环境下的局限性。FedC^2I通过量化客户端级影响（Client-level Influence）和类别级影响（Class-level Influence），利用影响向量和影响矩阵来显式建模客户端间的相互影响，实现自适应参数聚合，其中影响向量指导特征表示层的聚合，而影响矩阵实现细粒度的分类器个性化。实验结果显示，在非独立同分布（non-IID）设置下，FedC^2I比现有方法表现出色，证明了其在个性化FL中的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03315v1",
      "published_date": "2024-10-04 11:00:17 UTC",
      "updated_date": "2024-10-04 11:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:17:40.322671"
    },
    {
      "arxiv_id": "2410.03804v2",
      "title": "Mixture of Attentions For Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Matthieu Zimmer",
        "Milan Gritta",
        "Gerasimos Lampouras",
        "Haitham Bou Ammar",
        "Jun Wang"
      ],
      "abstract": "The growth in the number of parameters of Large Language Models (LLMs) has\nled to a significant surge in computational requirements, making them\nchallenging and costly to deploy. Speculative decoding (SD) leverages smaller\nmodels to efficiently propose future tokens, which are then verified by the LLM\nin parallel. Small models that utilise activations from the LLM currently\nachieve the fastest decoding speeds. However, we identify several limitations\nof SD models including the lack of on-policyness during training and partial\nobservability. To address these shortcomings, we propose a more grounded\narchitecture for small models by introducing a Mixture of Attentions for SD.\nOur novel architecture can be applied in two scenarios: a conventional single\ndevice deployment and a novel client-server deployment where the small model is\nhosted on a consumer device and the LLM on a server. In a single-device\nscenario, we demonstrate state-of-the-art speedups improving EAGLE-2 by 9.5%\nand its acceptance length by 25%. In a client-server setting, our experiments\ndemonstrate: 1) state-of-the-art latencies with minimal calls to the server for\ndifferent network conditions, and 2) in the event of a complete disconnection,\nour approach can maintain higher accuracy compared to other SD methods and\ndemonstrates advantages over API calls to LLMs, which would otherwise be unable\nto continue the generation process.",
      "tldr_zh": "本研究针对大语言模型（LLMs）的计算需求激增问题，提出了一种名为Mixture of Attentions for Speculative Decoding (SD) 的新架构，以解决现有SD模型在训练时缺乏on-policyness和部分可观察性的局限性。该架构通过混合注意力机制优化小模型的表现，可应用于单设备部署和客户端-服务器部署场景；在单设备中，它比EAGLE-2模型提升9.5%的解码速度并提高25%的接受长度，而在客户端-服务器设置中，实现最低延迟、最少服务器调用，并在网络断开时保持更高准确性，比其他SD方法和LLM API更具鲁棒性。总体而言，这一创新为高效部署LLMs提供了可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.03804v2",
      "published_date": "2024-10-04 10:25:52 UTC",
      "updated_date": "2025-04-03 14:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:17:59.092679"
    },
    {
      "arxiv_id": "2410.03803v1",
      "title": "Text-guided Diffusion Model for 3D Molecule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yanchen Luo",
        "Junfeng Fang",
        "Sihang Li",
        "Zhiyuan Liu",
        "Jiancan Wu",
        "An Zhang",
        "Wenjie Du",
        "Xiang Wang"
      ],
      "abstract": "The de novo generation of molecules with targeted properties is crucial in\nbiology, chemistry, and drug discovery. Current generative models are limited\nto using single property values as conditions, struggling with complex\ncustomizations described in detailed human language. To address this, we\npropose the text guidance instead, and introduce TextSMOG, a new Text-guided\nSmall Molecule Generation Approach via 3D Diffusion Model which integrates\nlanguage and diffusion models for text-guided small molecule generation. This\nmethod uses textual conditions to guide molecule generation, enhancing both\nstability and diversity. Experimental results show TextSMOG's proficiency in\ncapturing and utilizing information from textual descriptions, making it a\npowerful tool for generating 3D molecular structures in response to complex\ntextual customizations.",
      "tldr_zh": "该研究针对分子生成领域的局限性，提出了一种文本指导的3D扩散模型TextSMOG，用于生成具有目标属性的小分子。该方法整合语言模型和扩散模型，通过文本条件（如详细的人类语言描述）来指导生成过程，从而提升分子的稳定性和多样性。实验结果表明，TextSMOG 能够有效捕捉文本信息，并成功响应复杂的自定义需求，为生物、化学和药物发现领域提供强大的3D分子结构生成工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03803v1",
      "published_date": "2024-10-04 10:23:20 UTC",
      "updated_date": "2024-10-04 10:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:18:10.706941"
    },
    {
      "arxiv_id": "2410.03296v2",
      "title": "Comparing zero-shot self-explanations with human rationales in text classification",
      "title_zh": "在文本分类中比较零样本自解释与人类推理",
      "authors": [
        "Stephanie Brandl",
        "Oliver Eberle"
      ],
      "abstract": "Instruction-tuned LLMs are able to provide an explanation about their output\nto users by generating self-explanations. These do not require gradient\ncomputations or the application of possibly complex XAI methods. In this paper,\nwe analyse whether this ability results in a good explanation. We evaluate\nself-explanations in the form of input rationales with respect to their\nplausibility to humans as well as their faithfulness to models. We study two\ntext classification tasks: sentiment classification and forced labour\ndetection, i.e., identifying pre-defined risk indicators of forced labour. In\naddition to English, we include Danish and Italian translations of the\nsentiment classification task and compare self-explanations to human\nannotations for all samples. To allow for direct comparisons, we also compute\npost-hoc feature attribution, i.e., layer-wise relevance propagation (LRP) and\nanalyse 4 LLMs. We show that self-explanations align more closely with human\nannotations compared to LRP, while maintaining a comparable level of\nfaithfulness. This finding suggests that self-explanations indeed provide good\nexplanations for text classification.",
      "tldr_zh": "该论文比较了 zero-shot self-explanations 与 human rationales 在文本分类任务中的表现，评估了大型语言模型（LLMs）生成的自解释在人类合理性（plausibility）和模型忠实度（faithfulness）方面的效果。研究涉及情感分类和强制劳动检测任务，并扩展到英语、丹麦语和意大利语数据集，同时将自解释与人类注解以及后验特征归因方法如 layer-wise relevance propagation (LRP) 进行对比。结果显示，自解释与人类注解更紧密一致，同时保持了与 LRP 相当的忠实度，这表明自解释在提供高质量解释方面具有显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.03296v2",
      "published_date": "2024-10-04 10:14:12 UTC",
      "updated_date": "2025-02-21 13:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:18:22.452738"
    },
    {
      "arxiv_id": "2410.03293v3",
      "title": "Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram Dataset of Over Half a Million Posts for Multilingual Sentiment Analysis",
      "title_zh": "Instagram 上的 COVID-19 话语",
      "authors": [
        "Nirmalya Thakur"
      ],
      "abstract": "The work presented in this paper makes three scientific contributions with a\nspecific focus on mining and analysis of COVID-19-related posts on Instagram.\nFirst, it presents a multilingual dataset of 500,153 Instagram posts about\nCOVID-19 published between January 2020 and September 2024. This dataset,\navailable at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in\n161 different languages as well as 535,021 distinct hashtags. After the\ndevelopment of this dataset, multilingual sentiment analysis was performed,\nwhich involved classifying each post as positive, negative, or neutral. The\nresults of sentiment analysis are presented as a separate attribute in this\ndataset. Second, it presents the results of performing sentiment analysis per\nyear from 2020 to 2024. The findings revealed the trends in sentiment related\nto COVID-19 on Instagram since the beginning of the pandemic. For instance,\nbetween 2020 and 2024, the sentiment trends show a notable shift, with positive\nsentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from\n44.19% to 58.34%. Finally, the paper also presents findings of\nlanguage-specific sentiment analysis. This analysis highlighted similar and\ncontrasting trends of sentiment across posts published in different languages\non Instagram. For instance, out of all English posts, 49.68% were positive,\n14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts,\n4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting\ndistinct differences in the sentiment distribution between these two languages.",
      "tldr_zh": "本研究构建了一个多语言数据集，包含从2020年1月到2024年9月的超过50万条Instagram帖子，涉及161种语言和53.5万个hashtags，用于COVID-19相关讨论的分析，该数据集可通过https://dx.doi.org/10.21227/d46p-v480获取。研究通过sentiment analysis对这些帖子进行分类（正面、负面或中性），并分析了年度情感趋势，例如正面情感从2020年的38.35%降至2024年的28.69%，而中性情感从44.19%上升至58.34%。此外，语言特定的sentiment analysis揭示了显著差异，如英语帖子中49.68%为正面，而印地语帖子中57.04%为负面，这突显了跨语言情感分布的多样性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI",
        "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03293v3",
      "published_date": "2024-10-04 10:06:55 UTC",
      "updated_date": "2024-10-16 14:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:18:34.881576"
    },
    {
      "arxiv_id": "2410.03291v1",
      "title": "Enhanced Transformer architecture for in-context learning of dynamical systems",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Rufolo",
        "Dario Piga",
        "Gabriele Maroni",
        "Marco Forgione"
      ],
      "abstract": "Recently introduced by some of the authors, the in-context identification\nparadigm aims at estimating, offline and based on synthetic data, a meta-model\nthat describes the behavior of a whole class of systems. Once trained, this\nmeta-model is fed with an observed input/output sequence (context) generated by\na real system to predict its behavior in a zero-shot learning fashion. In this\npaper, we enhance the original meta-modeling framework through three key\ninnovations: by formulating the learning task within a probabilistic framework;\nby managing non-contiguous context and query windows; and by adopting recurrent\npatching to effectively handle long context sequences. The efficacy of these\nmodifications is demonstrated through a numerical example focusing on the\nWiener-Hammerstein system class, highlighting the model's enhanced performance\nand scalability.",
      "tldr_zh": "这篇论文增强了 Transformer 架构，用于动态系统的 in-context learning 范式，旨在基于合成数据训练一个元模型(meta-model)，以零样本方式预测真实系统的行为。关键创新包括：将学习任务置于概率框架内、管理非连续的上下文和查询窗口，以及采用 recurrent patching 来有效处理长上下文序列。这些改进通过 Wiener-Hammerstein 系统类的数值例子得到验证，展示了模型的性能提升和更好的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03291v1",
      "published_date": "2024-10-04 10:05:15 UTC",
      "updated_date": "2024-10-04 10:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:18:45.809790"
    },
    {
      "arxiv_id": "2410.03290v1",
      "title": "Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haibo Wang",
        "Zhiyang Xu",
        "Yu Cheng",
        "Shizhe Diao",
        "Yufan Zhou",
        "Yixin Cao",
        "Qifan Wang",
        "Weifeng Ge",
        "Lifu Huang"
      ],
      "abstract": "Video Large Language Models (Video-LLMs) have demonstrated remarkable\ncapabilities in coarse-grained video understanding, however, they struggle with\nfine-grained temporal grounding. In this paper, we introduce Grounded-VideoLLM,\na novel Video-LLM adept at perceiving and reasoning over specific video moments\nin a fine-grained manner. We identify that current Video-LLMs have limitations\nfor fine-grained video understanding since they lack effective temporal\nmodeling and timestamp representation. In light of this, we sharpen our model\nby incorporating (1) an additional temporal stream to encode the relationships\nbetween frames and (2) discrete temporal tokens enriched with specific time\nknowledge to represent timestamps. To optimize the training of\nGrounded-VideoLLM, we employ a multi-stage training scheme, beginning with\nsimple video-captioning tasks and progressively introducing video temporal\ngrounding tasks of increasing complexity. To further enhance\nGrounded-VideoLLM's temporal reasoning capability, we also curate a grounded\nVideoQA dataset by an automatic annotation pipeline. Extensive experiments\ndemonstrate that Grounded-VideoLLM not only excels in fine-grained grounding\ntasks such as temporal sentence grounding, dense video captioning, and grounded\nVideoQA, but also shows great potential as a versatile video assistant for\ngeneral video understanding.",
      "tldr_zh": "该研究针对Video-LLMs在粗粒度视频理解上表现良好但细粒度时间定位不足的问题，提出了Grounded-VideoLLM模型。该模型通过添加temporal stream来编码帧间关系，并使用富含时间知识的离散temporal tokens来表示时间戳，从而提升细粒度视频感知和推理能力。为优化训练，该框架采用多阶段方案，从视频字幕任务逐步过渡到复杂的时间定位任务，并通过自动标注管道构建了一个grounded VideoQA数据集。实验结果显示，Grounded-VideoLLM在temporal sentence grounding、dense video captioning和grounded VideoQA等任务上表现出色，并展现出作为通用视频助手的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03290v1",
      "published_date": "2024-10-04 10:04:37 UTC",
      "updated_date": "2024-10-04 10:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:18:58.290038"
    },
    {
      "arxiv_id": "2410.03280v1",
      "title": "Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope",
      "title_zh": "翻译失败",
      "authors": [
        "Yasaman Torabi",
        "Shahram Shirani",
        "James P. Reilly"
      ],
      "abstract": "Heart and lung sounds are crucial for healthcare monitoring. Recent\nimprovements in stethoscope technology have made it possible to capture patient\nsounds with enhanced precision. In this dataset, we used a digital stethoscope\nto capture both heart and lung sounds, including individual and mixed\nrecordings. To our knowledge, this is the first dataset to offer both separate\nand mixed cardiorespiratory sounds. The recordings were collected from a\nclinical manikin, a patient simulator designed to replicate human physiological\nconditions, generating clean heart and lung sounds at different body locations.\nThis dataset includes both normal sounds and various abnormalities (i.e.,\nmurmur, atrial fibrillation, tachycardia, atrioventricular block, third and\nfourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling\nsounds). The dataset includes audio recordings of chest examinations performed\nat different anatomical locations, as determined by specialist nurses. Each\nrecording has been enhanced using frequency filters to highlight specific sound\ntypes. This dataset is useful for applications in artificial intelligence, such\nas automated cardiopulmonary disease detection, sound classification,\nunsupervised separation techniques, and deep learning algorithms related to\naudio signal processing.",
      "tldr_zh": "这篇论文介绍了使用数字听诊器采集的心肺声音数据集，这是首个同时提供单独和混合心肺录音的资源。数据集从临床人体模型（manikin）上采集，包括正常声音以及各种异常声音，如murmur、atrial fibrillation、tachycardia、wheezing 和 crackles 等，并通过频率过滤器增强录音以突出特定声音类型。该数据集适用于人工智能应用，例如自动化心肺疾病检测、声音分类和深度学习音频信号处理算法。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03280v1",
      "published_date": "2024-10-04 09:53:16 UTC",
      "updated_date": "2024-10-04 09:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:19:10.109960"
    },
    {
      "arxiv_id": "2410.03263v2",
      "title": "Test-time Adaptation for Regression by Subspace Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuki Adachi",
        "Shin'ya Yamaguchi",
        "Atsutoshi Kumagai",
        "Tomoki Hamagami"
      ],
      "abstract": "This paper investigates test-time adaptation (TTA) for regression, where a\nregression model pre-trained in a source domain is adapted to an unknown target\ndistribution with unlabeled target data. Although regression is one of the\nfundamental tasks in machine learning, most of the existing TTA methods have\nclassification-specific designs, which assume that models output\nclass-categorical predictions, whereas regression models typically output only\nsingle scalar values. To enable TTA for regression, we adopt a feature\nalignment approach, which aligns the feature distributions between the source\nand target domains to mitigate the domain gap. However, we found that naive\nfeature alignment employed in existing TTA methods for classification is\nineffective or even worse for regression because the features are distributed\nin a small subspace and many of the raw feature dimensions have little\nsignificance to the output. For an effective feature alignment in TTA for\nregression, we propose Significant-subspace Alignment (SSA). SSA consists of\ntwo components: subspace detection and dimension weighting. Subspace detection\nfinds the feature subspace that is representative and significant to the\noutput. Then, the feature alignment is performed in the subspace during TTA.\nMeanwhile, dimension weighting raises the importance of the dimensions of the\nfeature subspace that have greater significance to the output. We\nexperimentally show that SSA outperforms various baselines on real-world\ndatasets.",
      "tldr_zh": "这篇论文探讨了回归任务中的Test-time Adaptation (TTA)，提出了一种Subspace Alignment (SSA)方法来将源域预训练的回归模型适应到未知的目标域，使用无标签数据进行特征对齐。SSA包括两个关键组件：subspace detection，用于识别对输出有代表性和重要性的特征子空间，以及dimension weighting，用于提升子空间中关键维度的权重，以解决传统特征对齐在回归任务中的无效性。实验结果表明，SSA在真实数据集上优于各种基线方法，显著提高了模型的适应性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03263v2",
      "published_date": "2024-10-04 09:31:10 UTC",
      "updated_date": "2025-01-23 04:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:19:22.517913"
    },
    {
      "arxiv_id": "2410.03255v2",
      "title": "Towards a Benchmark for Large Language Models for Business Process Management Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Kiran Busch",
        "Henrik Leopold"
      ],
      "abstract": "An increasing number of organizations are deploying Large Language Models\n(LLMs) for a wide range of tasks. Despite their general utility, LLMs are prone\nto errors, ranging from inaccuracies to hallucinations. To objectively assess\nthe capabilities of existing LLMs, performance benchmarks are conducted.\nHowever, these benchmarks often do not translate to more specific real-world\ntasks. This paper addresses the gap in benchmarking LLM performance in the\nBusiness Process Management (BPM) domain. Currently, no BPM-specific benchmarks\nexist, creating uncertainty about the suitability of different LLMs for BPM\ntasks. This paper systematically compares LLM performance on four BPM tasks\nfocusing on small open-source models. The analysis aims to identify\ntask-specific performance variations, compare the effectiveness of open-source\nversus commercial models, and assess the impact of model size on BPM task\nperformance. This paper provides insights into the practical applications of\nLLMs in BPM, guiding organizations in selecting appropriate models for their\nspecific needs.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在业务流程管理(BPM)任务中的性能评估问题，提出了首个BPM特定基准，以填补现有基准的适用性缺口。该研究系统比较了不同LLMs在四个BPM任务上的表现，重点关注小型开源模型，并分析了任务特定性能差异、开源模型与商业模型的有效性对比，以及模型大小对性能的影响。结果显示，LLMs在BPM领域的适用性因任务而异，为组织选择合适的模型提供了实用指导。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to HICSS (June 15, 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.03255v2",
      "published_date": "2024-10-04 09:18:54 UTC",
      "updated_date": "2024-10-13 11:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:19:34.835231"
    },
    {
      "arxiv_id": "2410.03249v3",
      "title": "How Much Can We Forget about Data Contamination?",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Bordt",
        "Suraj Srinivas",
        "Valentyn Boreiko",
        "Ulrike von Luxburg"
      ],
      "abstract": "The leakage of benchmark data into the training data has emerged as a\nsignificant challenge for evaluating the capabilities of large language models\n(LLMs). In this work, we challenge the common assumption that small-scale\ncontamination renders benchmark evaluations invalid. First, we experimentally\nquantify the magnitude of benchmark overfitting based on scaling along three\ndimensions: The number of model parameters (up to 1.6B), the number of times an\nexample is seen (up to 144), and the number of training tokens (up to 40B). If\nmodel and data follow the Chinchilla scaling laws, minor contamination indeed\nleads to overfitting. At the same time, even 144 times of contamination can be\nforgotten if the training data is scaled beyond five times Chinchilla, a regime\ncharacteristic of many modern LLMs. Continual pre-training of OLMo-7B\ncorroborates these results. Next, we study the impact of the weight decay\nparameter on example forgetting, showing that empirical forgetting occurs\nfaster than the cumulative weight decay. This allows us to gauge the degree of\nexample forgetting in large-scale training runs, indicating that many LLMs,\nincluding Lllama 3 405B, have forgotten the data seen at the beginning of\ntraining.",
      "tldr_zh": "该论文探讨了基准数据污染对大型语言模型(LLMs)评估的影响，挑战了小规模污染会使评估无效的假设。通过实验量化过拟合的程度，包括模型参数规模（最高1.6B）、示例重复次数（最高144次）和训练标记数量（最高40B），研究发现，如果模型和数据遵循Chinchilla缩放定律，轻微污染可通过增加训练数据（如超过五倍Chinchilla水平）实现遗忘。进一步分析权重衰减参数显示，经验遗忘速度更快，许多LLMs（如Llama 3 405B）已在训练过程中遗忘了早期数据，这为更可靠的模型评估提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03249v3",
      "published_date": "2024-10-04 09:14:11 UTC",
      "updated_date": "2025-01-30 16:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:19:47.366499"
    },
    {
      "arxiv_id": "2410.03246v2",
      "title": "Latent Action Priors for Locomotion with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Hausdörfer",
        "Alexander von Rohr",
        "Éric Lefort",
        "Angela Schoellig"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) enables robots to learn complex behaviors\nthrough interaction with the environment. However, due to the unrestricted\nnature of the learning algorithms, the resulting solutions are often brittle\nand appear unnatural. This is especially true for learning direct joint-level\ntorque control, as inductive biases are difficult to integrate into the\nlearning process. We propose an inductive bias for learning locomotion that is\nespecially useful for torque control: latent actions learned from a small\ndataset of expert demonstrations. This prior allows the policy to directly\nleverage knowledge contained in the expert's actions and facilitates more\nefficient exploration. We observe that the agent is not restricted to the\nreward levels of the demonstration, and performance in transfer tasks is\nimproved significantly. Latent action priors combined with style rewards for\nimitation lead to a closer replication of the expert's behavior. Videos and\ncode are available at https://sites.google.com/view/latent-action-priors.",
      "tldr_zh": "本文提出了一种针对 Deep Reinforcement Learning (DRL) 机器人运动学习的归纳偏差，即从少量专家演示数据中学习潜在动作（latent actions），以解决直接关节级扭矩控制中解决方案脆弱和不自然的问题。 该方法允许策略直接利用专家动作知识，提高探索效率，并在转移任务中显著提升性能，即使代理超出演示的奖励水平。 此外，将潜在动作先验与风格奖励结合，能更精确地模仿专家行为，为 DRL 在运动控制领域提供更高效可靠的框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03246v2",
      "published_date": "2024-10-04 09:10:56 UTC",
      "updated_date": "2025-03-01 09:12:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:19:58.651582"
    },
    {
      "arxiv_id": "2410.03235v2",
      "title": "Enriching Ontologies with Disjointness Axioms using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Crum",
        "Antonio De Santis",
        "Manon Ovide",
        "Jiaxin Pan",
        "Alessia Pisu",
        "Nicolas Lazzari",
        "Sebastian Rudolph"
      ],
      "abstract": "Ontologies often lack explicit disjointness declarations between classes,\ndespite their usefulness for sophisticated reasoning and consistency checking\nin Knowledge Graphs. In this study, we explore the potential of Large Language\nModels (LLMs) to enrich ontologies by identifying and asserting class\ndisjointness axioms. Our approach aims at leveraging the implicit knowledge\nembedded in LLMs, using prompt engineering to elicit this knowledge for\nclassifying ontological disjointness. We validate our methodology on the\nDBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs,\nwhen guided by effective prompt strategies, can reliably identify disjoint\nclass relationships, thus streamlining the process of ontology completion\nwithout extensive manual input. For comprehensive disjointness enrichment, we\npropose a process that takes logical relationships between disjointness and\nsubclass statements into account in order to maintain satisfiability and reduce\nthe number of calls to the LLM. This work provides a foundation for future\napplications of LLMs in automated ontology enhancement and offers insights into\noptimizing LLM performance through strategic prompt design. Our code is\npublicly available on GitHub at https://github.com/n28div/llm-disjointness.",
      "tldr_zh": "该研究探讨了利用大型语言模型（Large Language Models, LLMs）来为本体（Ontologies）添加类间不相交声明（Disjointness Axioms），以提升知识图谱（Knowledge Graphs）的推理和一致性检查。通过提示工程（Prompt Engineering），LLMs 可以从其隐性知识中提取信息，在 DBpedia 本体上可靠地识别不相交关系，从而简化本体完善过程并减少手动干预。研究还提出一个优化流程，考虑不相交和子类语句（Subclass Statements）的逻辑关系，以维护本体满足性和最小化 LLM 调用次数。该工作为 LLMs 在自动本体增强中的应用奠定基础，并通过开源代码（GitHub）提供实际见解。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at KBC-LM'24 workshop at ISWC 2024,\n  https://ceur-ws.org/Vol-3853/paper1.pdf",
      "pdf_url": "http://arxiv.org/pdf/2410.03235v2",
      "published_date": "2024-10-04 09:00:06 UTC",
      "updated_date": "2024-12-02 13:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:20:10.183072"
    },
    {
      "arxiv_id": "2410.03225v2",
      "title": "AutoPenBench: Benchmarking Generative Agents for Penetration Testing",
      "title_zh": "AutoPenBench：用于渗透测试的生成式代理基准测试",
      "authors": [
        "Luca Gioacchini",
        "Marco Mellia",
        "Idilio Drago",
        "Alexander Delsanto",
        "Giuseppe Siracusano",
        "Roberto Bifulco"
      ],
      "abstract": "Generative AI agents, software systems powered by Large Language Models\n(LLMs), are emerging as a promising approach to automate cybersecurity tasks.\nAmong the others, penetration testing is a challenging field due to the task\ncomplexity and the diverse strategies to simulate cyber-attacks. Despite\ngrowing interest and initial studies in automating penetration testing with\ngenerative agents, there remains a significant gap in the form of a\ncomprehensive and standard framework for their evaluation and development. This\npaper introduces AutoPenBench, an open benchmark for evaluating generative\nagents in automated penetration testing. We present a comprehensive framework\nthat includes 33 tasks, each representing a vulnerable system that the agent\nhas to attack. Tasks are of increasing difficulty levels, including in-vitro\nand real-world scenarios. We assess the agent performance with generic and\nspecific milestones that allow us to compare results in a standardised manner\nand understand the limits of the agent under test. We show the benefits of\nAutoPenBench by testing two agent architectures: a fully autonomous and a\nsemi-autonomous supporting human interaction. We compare their performance and\nlimitations. For example, the fully autonomous agent performs unsatisfactorily\nachieving a 21% Success Rate (SR) across the benchmark, solving 27% of the\nsimple tasks and only one real-world task. In contrast, the assisted agent\ndemonstrates substantial improvements, with 64% of SR. AutoPenBench allows us\nalso to observe how different LLMs like GPT-4o or OpenAI o1 impact the ability\nof the agents to complete the tasks. We believe that our benchmark fills the\ngap with a standard and flexible framework to compare penetration testing\nagents on a common ground. We hope to extend AutoPenBench along with the\nresearch community by making it available under\nhttps://github.com/lucagioacchini/auto-pen-bench.",
      "tldr_zh": "这篇论文引入了 AutoPenBench，一个开放基准，用于评估生成式 AI 代理在渗透测试中的性能，旨在填补自动化网络安全任务评估的框架空白。该基准包括 33 个任务，涵盖从简单到真实场景的难度级别，并采用通用和特定里程碑进行标准化比较。实验结果显示，完全自治代理的成功率仅为 21%，而支持人类交互的半自治代理提升至 64%；此外，不同 LLMs 如 GPT-4o 和 OpenAI o1 对代理任务完成能力有显著影响。AutoPenBench 作为开源工具，将促进渗透测试代理的开发和比较。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Codes for the benchmark:\n  https://github.com/lucagioacchini/auto-pen-bench Codes for the paper\n  experiments: https://github.com/lucagioacchini/genai-pentest-paper",
      "pdf_url": "http://arxiv.org/pdf/2410.03225v2",
      "published_date": "2024-10-04 08:24:15 UTC",
      "updated_date": "2024-10-28 17:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:20:23.612054"
    },
    {
      "arxiv_id": "2410.03224v1",
      "title": "ScriptViz: A Visualization Tool to Aid Scriptwriting based on a Large Movie Database",
      "title_zh": "翻译失败",
      "authors": [
        "Anyi Rao",
        "Jean-Peïc Chou",
        "Maneesh Agrawala"
      ],
      "abstract": "Scriptwriters usually rely on their mental visualization to create a vivid\nstory by using their imagination to see, feel, and experience the scenes they\nare writing. Besides mental visualization, they often refer to existing images\nor scenes in movies and analyze the visual elements to create a certain mood or\natmosphere. In this paper, we develop ScriptViz to provide external\nvisualization based on a large movie database for the screenwriting process. It\nretrieves reference visuals on the fly based on scripts' text and dialogue from\na large movie database. The tool provides two types of control on visual\nelements that enable writers to 1) see exactly what they want with fixed visual\nelements and 2) see variances in uncertain elements. User evaluation among 15\nscriptwriters shows that ScriptViz is able to present scriptwriters with\nconsistent yet diverse visual possibilities, aligning closely with their\nscripts and helping their creation.",
      "tldr_zh": "本研究开发了ScriptViz，一款基于Large Movie Database的视觉化工具，旨在辅助脚本写作过程，通过实时检索脚本文本和对话中的参考视觉元素，提供外部可视化支持。该工具支持两种控制类型：固定视觉元素以精确匹配作家意图，以及显示不确定元素的变异形式，帮助探索多样可能性。在15名脚本作家的用户评估中，ScriptViz证明能够提供与脚本高度一致且多样的视觉选项，从而提升创作效率和质量。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted in the 37th Annual ACM Symposium on User Interface Software\n  and Technology (UIST'24). Webpage:\n  https://virtualfilmstudio.github.io/projects/scriptviz",
      "pdf_url": "http://arxiv.org/pdf/2410.03224v1",
      "published_date": "2024-10-04 08:23:56 UTC",
      "updated_date": "2024-10-04 08:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:20:33.469790"
    },
    {
      "arxiv_id": "2410.14691v1",
      "title": "Green vehicle routing problem that jointly optimizes delivery speed and routing based on the characteristics of electric vehicles",
      "title_zh": "基于电动车辆特性的绿色车辆路径问题：联合优化交付速度和路径",
      "authors": [
        "YY. Feng"
      ],
      "abstract": "The abundance of materials and the development of the economy have led to the\nflourishing of the logistics industry, but have also caused certain pollution.\nThe research on GVRP (Green vehicle routing problem) for planning vehicle\nroutes during transportation to reduce pollution is also increasingly\ndeveloping. Further exploration is needed on how to integrate these research\nfindings with real vehicles. This paper establishes an energy consumption model\nusing real electric vehicles, fully considering the physical characteristics of\neach component of the vehicle. To avoid the distortion of energy consumption\nmodels affecting the results of route planning. The energy consumption model\nalso incorporates the effects of vehicle start/stop, speed, distance, and load\non energy consumption. In addition, a load first speed optimization algorithm\nwas proposed, which selects the most suitable speed between every two delivery\npoints while planning the route. In order to further reduce energy consumption\nwhile meeting the time window. Finally, an improved Adaptive Genetic Algorithm\nis used to solve for the most energy-efficient route. The experiment shows that\nthe results of using this speed optimization algorithm are generally more\nenergy-efficient than those without using this algorithm. The average energy\nconsumption of constant speed delivery at different speeds is 17.16% higher\nthan that after speed optimization. Provided a method that is closer to reality\nand easier for logistics companies to use. It also enriches the GVRP model.",
      "tldr_zh": "本研究针对绿色车辆路径问题（GVRP），提出了一种基于电动车辆特性的联合优化方法，旨在通过优化送货速度和路线来减少运输污染。论文建立了真实电动车的能源消耗模型，全面考虑车辆启动/停止、速度、距离和负载等因素，并设计了负载优先速度优化算法来在路线规划中选择最适合的速度，同时结合改进的自适应遗传算法求解最节能路径。实验结果显示，该算法比固定速度方案平均降低能源消耗17.16%，为物流公司提供更贴近实际的优化方法，并丰富了GVRP模型。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14691v1",
      "published_date": "2024-10-04 08:08:15 UTC",
      "updated_date": "2024-10-04 08:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:20:46.302051"
    },
    {
      "arxiv_id": "2410.03215v1",
      "title": "NLIP_Lab-IITH Low-Resource MT System for WMT24 Indic MT Shared Task",
      "title_zh": "翻译失败",
      "authors": [
        "Pramit Sahoo",
        "Maharaj Brahma",
        "Maunendra Sankar Desarkar"
      ],
      "abstract": "In this paper, we describe our system for the WMT 24 shared task of\nLow-Resource Indic Language Translation. We consider eng $\\leftrightarrow$ {as,\nkha, lus, mni} as participating language pairs. In this shared task, we explore\nthe finetuning of a pre-trained model motivated by the pre-trained objective of\naligning embeddings closer by alignment augmentation \\cite{lin-etal-2020-pre}\nfor 22 scheduled Indian languages. Our primary system is based on\nlanguage-specific finetuning on a pre-trained model. We achieve chrF2 scores of\n50.6, 42.3, 54.9, and 66.3 on the official public test set for\neng$\\rightarrow$as, eng$\\rightarrow$kha, eng$\\rightarrow$lus,\neng$\\rightarrow$mni respectively. We also explore multilingual training\nwith/without language grouping and layer-freezing. Our code, models, and\ngenerated translations are available here:\nhttps://github.com/pramitsahoo/WMT2024-LRILT.",
      "tldr_zh": "这篇论文介绍了 NLIP_Lab-IITH 团队为 WMT24 Indic MT 共享任务开发的低资源机器翻译系统，针对 eng ↔ {as, kha, lus, mni} 等语言对进行优化。系统主要通过对预训练模型进行语言特定微调，并结合 alignment augmentation 方法来提升嵌入对齐。实验结果显示，在官方公共测试集上，eng→as、eng→kha、eng→lus 和 eng→mni 的 chrF2 分数分别为 50.6、42.3、54.9 和 66.3；此外，还探索了 multilingual training 和 layer-freezing 技术，以进一步提高性能。代码、模型和生成的翻译已开源于 GitHub。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WMT2024 INDICMT Shared Task",
      "pdf_url": "http://arxiv.org/pdf/2410.03215v1",
      "published_date": "2024-10-04 08:02:43 UTC",
      "updated_date": "2024-10-04 08:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:21:53.425027"
    },
    {
      "arxiv_id": "2410.03205v1",
      "title": "A Tutorial on the Design, Experimentation and Application of Metaheuristic Algorithms to Real-World Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Esther Villar-Rodriguez",
        "Javier Del Ser",
        "Antonio J. Nebro",
        "Daniel Molina",
        "Antonio LaTorre",
        "Ponnuthurai N. Suganthan",
        "Carlos A. Coello Coello",
        "Francisco Herrera"
      ],
      "abstract": "In the last few years, the formulation of real-world optimization problems\nand their efficient solution via metaheuristic algorithms has been a catalyst\nfor a myriad of research studies. In spite of decades of historical\nadvancements on the design and use of metaheuristics, large difficulties still\nremain in regards to the understandability, algorithmic design uprightness, and\nperformance verifiability of new technical achievements. A clear example stems\nfrom the scarce replicability of works dealing with metaheuristics used for\noptimization, which is often infeasible due to ambiguity and lack of detail in\nthe presentation of the methods to be reproduced. Additionally, in many cases,\nthere is a questionable statistical significance of their reported results.\nThis work aims at providing the audience with a proposal of good practices\nwhich should be embraced when conducting studies about metaheuristics methods\nused for optimization in order to provide scientific rigor, value and\ntransparency. To this end, we introduce a step by step methodology covering\nevery research phase that should be followed when addressing this scientific\nfield. Specifically, frequently overlooked yet crucial aspects and useful\nrecommendations will be discussed in regards to the formulation of the problem,\nsolution encoding, implementation of search operators, evaluation metrics,\ndesign of experiments, and considerations for real-world performance, among\nothers. Finally, we will outline important considerations, challenges, and\nresearch directions for the success of newly developed optimization\nmetaheuristics in their deployment and operation over real-world application\nenvironments.",
      "tldr_zh": "这篇教程论文讨论了元启发式算法（metaheuristic algorithms）在真实世界优化问题中的设计、实验和应用面临的挑战，如算法可理解性、设计完整性和性能验证的不足，以及实验重复性和统计显著性的问题。论文提出一套良好实践建议和逐步方法论，涵盖问题制定、解决方案编码、搜索操作实现、评估指标、实验设计以及真实世界性能考虑，以提升研究的科学严谨性和透明度。最后，它概述了部署这些算法的关键挑战和未来研究方向，以促进其在实际环境中的成功应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03205v1",
      "published_date": "2024-10-04 07:41:23 UTC",
      "updated_date": "2024-10-04 07:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:21:11.066306"
    },
    {
      "arxiv_id": "2410.03192v1",
      "title": "MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Taejun Bak",
        "Youngsik Eom",
        "SeungJae Choi",
        "Young-Sun Joo"
      ],
      "abstract": "Text-to-speech (TTS) systems that scale up the amount of training data have\nachieved significant improvements in zero-shot speech synthesis. However, these\nsystems have certain limitations: they require a large amount of training data,\nwhich increases costs, and often overlook prosody similarity. To address these\nissues, we propose MultiVerse, a zero-shot multi-task TTS system that is able\nto perform TTS or speech style transfer in zero-shot and cross-lingual\nconditions. MultiVerse requires much less training data than traditional\ndata-driven approaches. To ensure zero-shot performance even with limited data,\nwe leverage source-filter theory-based disentanglement, utilizing the prompt\nfor modeling filter-related and source-related representations. Additionally,\nto further enhance prosody similarity, we adopt a prosody modeling approach\ncombining prompt-based autoregressive and non-autoregressive methods.\nEvaluations demonstrate the remarkable zero-shot multi-task TTS performance of\nMultiVerse and show that MultiVerse not only achieves zero-shot TTS performance\ncomparable to data-driven TTS systems with much less data, but also\nsignificantly outperforms other zero-shot TTS systems trained with the same\nsmall amount of data. In particular, our novel prosody modeling technique\nsignificantly contributes to MultiVerse's ability to generate speech with high\nprosody similarity to the given prompts. Our samples are available at\nhttps://nc-ai.github.io/speech/publications/multiverse/index.html",
      "tldr_zh": "该论文提出 MultiVerse，一种高效且富有表现力的零-shot 多任务 Text-to-Speech (TTS) 系统，能够在零-shot 和跨语言条件下实现 TTS 或语音风格转移，同时显著减少训练数据需求。MultiVerse 利用 source-filter theory 进行基于提示的表征解耦，并结合自回归和非自回归方法来增强韵律建模，从而提高生成语音的 prosody similarity。实验结果显示，MultiVerse 在少量数据下达到与数据驱动 TTS 系统相当的性能，并显著优于其他使用相同数据量的零-shot 系统，尤其在韵律相似性方面表现出色。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.03192v1",
      "published_date": "2024-10-04 07:10:25 UTC",
      "updated_date": "2024-10-04 07:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:21:22.177905"
    },
    {
      "arxiv_id": "2410.03188v1",
      "title": "Looking into Concept Explanation Methods for Diabetic Retinopathy Classification",
      "title_zh": "探究糖尿病视网膜病变分类的概念解释方法",
      "authors": [
        "Andrea M. Storås",
        "Josefine V. Sundgaard"
      ],
      "abstract": "Diabetic retinopathy is a common complication of diabetes, and monitoring the\nprogression of retinal abnormalities using fundus imaging is crucial. Because\nthe images must be interpreted by a medical expert, it is infeasible to screen\nall individuals with diabetes for diabetic retinopathy. Deep learning has shown\nimpressive results for automatic analysis and grading of fundus images. One\ndrawback is, however, the lack of interpretability, which hampers the\nimplementation of such systems in the clinic. Explainable artificial\nintelligence methods can be applied to explain the deep neural networks.\nExplanations based on concepts have shown to be intuitive for humans to\nunderstand, but have not yet been explored in detail for diabetic retinopathy\ngrading. This work investigates and compares two concept-based explanation\ntechniques for explaining deep neural networks developed for automatic\ndiagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation\nVectors and Concept Bottleneck Models. We found that both methods have\nstrengths and weaknesses, and choice of method should take the available data\nand the end user's preferences into account.",
      "tldr_zh": "本研究探讨了基于概念的解释方法在糖尿病视网膜病变分类中的应用，以解决深度学习模型在临床中的可解释性问题。\n他们比较了两种技术：Quantitative Testing with Concept Activation Vectors 和 Concept Bottleneck Models，用于解释自动诊断模型。\n结果表明，每种方法都有优缺点，选择应根据可用数据和用户偏好来决定，从而提高AI系统的可信度和临床实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:021",
      "pdf_url": "http://arxiv.org/pdf/2410.03188v1",
      "published_date": "2024-10-04 07:01:37 UTC",
      "updated_date": "2024-10-04 07:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:21:34.370009"
    },
    {
      "arxiv_id": "2410.03185v1",
      "title": "EXAQ: Exponent Aware Quantization For LLMs Acceleration",
      "title_zh": "翻译失败",
      "authors": [
        "Moran Shkolnik",
        "Maxim Fishman",
        "Brian Chmiel",
        "Hilla Ben-Yaacov",
        "Ron Banner",
        "Kfir Yehuda Levy"
      ],
      "abstract": "Quantization has established itself as the primary approach for decreasing\nthe computational and storage expenses associated with Large Language Models\n(LLMs) inference. The majority of current research emphasizes quantizing\nweights and activations to enable low-bit general-matrix-multiply (GEMM)\noperations, with the remaining non-linear operations executed at higher\nprecision. In our study, we discovered that following the application of these\ntechniques, the primary bottleneck in LLMs inference lies in the softmax layer.\nThe softmax operation comprises three phases: exponent calculation,\naccumulation, and normalization, Our work focuses on optimizing the first two\nphases. We propose an analytical approach to determine the optimal clipping\nvalue for the input to the softmax function, enabling sub-4-bit quantization\nfor LLMs inference. This method accelerates the calculations of both $e^x$ and\n$\\sum(e^x)$ with minimal to no accuracy degradation. For example, in\nLLaMA1-30B, we achieve baseline performance with 2-bit quantization on the\nwell-known \"Physical Interaction: Question Answering\" (PIQA) dataset\nevaluation. This ultra-low bit quantization allows, for the first time, an\nacceleration of approximately 4x in the accumulation phase. The combination of\naccelerating both $e^x$ and $\\sum(e^x)$ results in a 36.9% acceleration in the\nsoftmax operation.",
      "tldr_zh": "这篇论文提出了EXAQ框架，一种指数感知量化方法，用于加速大型语言模型(LLMs)的推理过程，主要针对softmax层作为推理瓶颈的问题进行优化。该方法通过分析确定softmax输入的最佳裁剪值，实现子4位量化，从而加速e^x计算和∑(e^x)累加阶段，同时几乎不损失准确性。在LLaMA1-30B模型上，EXAQ实现了2位量化在PIQA数据集上的基线性能，并使softmax操作整体加速36.9%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03185v1",
      "published_date": "2024-10-04 06:54:30 UTC",
      "updated_date": "2024-10-04 06:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:21:46.787226"
    },
    {
      "arxiv_id": "2410.03182v2",
      "title": "Generating bilingual example sentences with large language models as lexicography assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Merx",
        "Ekaterina Vylomova",
        "Kemal Kurniawan"
      ],
      "abstract": "We present a study of LLMs' performance in generating and rating example\nsentences for bilingual dictionaries across languages with varying resource\nlevels: French (high-resource), Indonesian (mid-resource), and Tetun\n(low-resource), with English as the target language. We evaluate the quality of\nLLM-generated examples against the GDEX (Good Dictionary EXample) criteria:\ntypicality, informativeness, and intelligibility. Our findings reveal that\nwhile LLMs can generate reasonably good dictionary examples, their performance\ndegrades significantly for lower-resourced languages. We also observe high\nvariability in human preferences for example quality, reflected in low\ninter-annotator agreement rates. To address this, we demonstrate that\nin-context learning can successfully align LLMs with individual annotator\npreferences. Additionally, we explore the use of pre-trained language models\nfor automated rating of examples, finding that sentence perplexity serves as a\ngood proxy for typicality and intelligibility in higher-resourced languages.\nOur study also contributes a novel dataset of 600 ratings for LLM-generated\nsentence pairs, and provides insights into the potential of LLMs in reducing\nthe cost of lexicographic work, particularly for low-resource languages.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在为双语词典生成例句方面的表现，涵盖不同资源水平的语言（法语高资源、印尼语中资源、Tetun低资源），并以英语为目标语言，使用GDEX标准（典型性、信息性和可理解性）进行评估。结果显示，LLMs能生成高质量例句，但对低资源语言的性能显著下降，且人类评估者间的偏好差异大，导致评注一致性低；为此，研究采用in-context learning方法来调整LLMs以匹配个体偏好，并发现句子perplexity可作为高资源语言中典型性和可理解性的有效代理。最终，该研究贡献了一个包含600个评级的全新数据集，并探讨了LLMs在降低词汇学工作成本方面的潜力，特别是针对低资源语言。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03182v2",
      "published_date": "2024-10-04 06:45:48 UTC",
      "updated_date": "2024-11-19 05:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:22:04.858859"
    },
    {
      "arxiv_id": "2410.03176v1",
      "title": "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models",
      "title_zh": "调查与缓解预训练视觉-语言（",
      "authors": [
        "Yufang Liu",
        "Tao Ji",
        "Changzhi Sun",
        "Yuanbin Wu",
        "Aimin Zhou"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have achieved impressive performance,\nyet research has pointed out a serious issue with object hallucinations within\nthese models. However, there is no clear conclusion as to which part of the\nmodel these hallucinations originate from. In this paper, we present an\nin-depth investigation into the object hallucination problem specifically\nwithin the CLIP model, which serves as the backbone for many state-of-the-art\nvision-language systems. We unveil that even in isolation, the CLIP model is\nprone to object hallucinations, suggesting that the hallucination problem is\nnot solely due to the interaction between vision and language modalities. To\naddress this, we propose a counterfactual data augmentation method by creating\nnegative samples with a variety of hallucination issues. We demonstrate that\nour method can effectively mitigate object hallucinations for CLIP model, and\nwe show the the enhanced model can be employed as a visual encoder, effectively\nalleviating the object hallucination issue in LVLMs.",
      "tldr_zh": "本研究调查了预训练视觉语言模型（CLIP）中的物体幻觉问题，发现这种幻觉并非仅源于视觉和语言模态的交互，而是CLIP模型本身就容易出现。作者提出了一种反事实数据增强（counterfactual data augmentation）方法，通过创建带有各种幻觉问题的负样本来训练模型，从而有效缓解物体幻觉。实验结果表明，该增强方法不仅提高了CLIP的性能，还能作为视觉编码器用于大型视觉语言模型（LVLMs），整体减少了幻觉问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03176v1",
      "published_date": "2024-10-04 06:24:49 UTC",
      "updated_date": "2024-10-04 06:24:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:22:16.736498"
    },
    {
      "arxiv_id": "2410.03161v1",
      "title": "Adaptive Masking Enhances Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Sen Jia",
        "Lei Li"
      ],
      "abstract": "In recent years, zero-shot and few-shot learning in visual grounding have\ngarnered considerable attention, largely due to the success of large-scale\nvision-language pre-training on expansive datasets such as LAION-5B and\nDataComp-1B. However, the continuous expansion of these datasets presents\nsignificant challenges, particularly with respect to data availability and\ncomputational overhead, thus creating a bottleneck in the advancement of\nlow-shot learning capabilities. In this paper, we propose IMAGE, Interpretative\nMAsking with Gaussian radiation modEling, aimed at enhancing vocabulary\ngrounding in low-shot learning scenarios without necessitating an increase in\ndataset size. Drawing inspiration from cognitive science and the recent success\nof masked autoencoders (MAE), our method leverages adaptive masking on salient\nregions of the feature maps generated by the vision backbone. This enables the\nmodel to learn robust, generalized representations through the reconstruction\nof occluded information, thereby facilitating effective attention to both local\nand global features. We evaluate the efficacy of our approach on benchmark\ndatasets, including COCO and ODinW, demonstrating its superior performance in\nzero-shot and few-shot tasks. Experimental results consistently show that IMAGE\noutperforms baseline models, achieving enhanced generalization and improved\nperformance in low-shot scenarios. These findings highlight the potential of\nadaptive feature manipulation through attention mechanisms and Gaussian\nmodeling as a promising alternative to approaches that rely on the continual\nscaling of dataset sizes for the advancement of zero-shot and few-shot\nlearning. Our code is publicly available at https://github.com/git-lenny/IMAGE.",
      "tldr_zh": "该论文提出 IMAGE（Interpretative Masking with Gaussian radiation modEling）方法，以提升 zero-shot 和 few-shot 学习在 visual grounding 中的性能，而无需增加数据集规模。IMAGE 借鉴 masked autoencoders (MAE) 和认知科学，通过在视觉骨干生成的特征图上进行自适应 masking 和 Gaussian modeling，对显著区域进行遮挡重建，帮助模型学习鲁棒的局部和全局特征表示。实验在 COCO 和 ODinW 数据集上显示，IMAGE 在 zero-shot 和 few-shot 任务中超越基线模型，实现了更好的泛化和性能。这些结果证明了通过注意力机制和自适应特征操作的潜力，作为扩充数据集的替代方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code will be available at https://github.com/git-lenny/IMAGE",
      "pdf_url": "http://arxiv.org/pdf/2410.03161v1",
      "published_date": "2024-10-04 05:48:02 UTC",
      "updated_date": "2024-10-04 05:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:22:32.058693"
    },
    {
      "arxiv_id": "2410.03159v3",
      "title": "WAVE: Weighted Autoregressive Varying Gate for Time Series Forecasting",
      "title_zh": "WAVE：加权自回归可变门控用于时间序列预测",
      "authors": [
        "Jiecheng Lu",
        "Xu Han",
        "Yan Sun",
        "Shihao Yang"
      ],
      "abstract": "We propose a Weighted Autoregressive Varying gatE (WAVE) attention mechanism\nequipped with both Autoregressive (AR) and Moving-average (MA) components. It\ncan adapt to various attention mechanisms, enhancing and decoupling their\nability to capture long-range and local temporal patterns in time series data.\nIn this paper, we first demonstrate that, for the time series forecasting (TSF)\ntask, the previously overlooked decoder-only autoregressive Transformer model\ncan achieve results comparable to the best baselines when appropriate\ntokenization and training methods are applied. Moreover, inspired by the ARMA\nmodel from statistics and recent advances in linear attention, we introduce the\nfull ARMA structure into existing autoregressive attention mechanisms. By using\nan indirect MA weight generation method, we incorporate the MA term while\nmaintaining the time complexity and parameter size of the underlying efficient\nattention models. We further explore how indirect parameter generation can\nproduce implicit MA weights that align with the modeling requirements for local\ntemporal impacts. Experimental results show that WAVE attention that\nincorporates the ARMA structure consistently improves the performance of\nvarious AR attentions on TSF tasks, achieving state-of-the-art results.",
      "tldr_zh": "本研究提出了一种WAVE（Weighted Autoregressive Varying Gate）注意力机制，将Autoregressive (AR) 和 Moving-average (MA) 组件结合，以适应各种注意力机制，并增强时间序列数据中长程和局部模式捕捉能力。受ARMA模型启发，作者将完整ARMA结构融入现有的autoregressive注意力机制，通过间接MA权重生成方法，保持了底层高效注意力模型的时间复杂度和参数规模，同时优化了局部时间影响的建模。实验结果显示，WAVE注意力机制显著提升了各种AR注意力的性能，在时间序列预测(TSF)任务上达到了state-of-the-art水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03159v3",
      "published_date": "2024-10-04 05:45:50 UTC",
      "updated_date": "2025-02-12 03:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:22:40.808211"
    },
    {
      "arxiv_id": "2410.03158v1",
      "title": "Mathematical Formalism for Memory Compression in Selective State Space Models",
      "title_zh": "选择性状态空间模型中的记忆压缩数学形式化",
      "authors": [
        "Siddhanth Bhat"
      ],
      "abstract": "State space models (SSMs) have emerged as a powerful framework for modelling\nlong-range dependencies in sequence data. Unlike traditional recurrent neural\nnetworks (RNNs) and convolutional neural networks (CNNs), SSMs offer a\nstructured and stable approach to sequence modelling, leveraging principles\nfrom control theory and dynamical systems. However, a key challenge in sequence\nmodelling is compressing long-term dependencies into a compact hidden state\nrepresentation without losing critical information.\n  In this paper, we develop a rigorous mathematical framework for understanding\nmemory compression in selective state space models. We introduce a selective\ngating mechanism that dynamically filters and updates the hidden state based on\ninput relevance, allowing for efficient memory compression. We formalize the\ntrade-off between memory efficiency and information retention using\ninformation-theoretic tools, such as mutual information and rate-distortion\ntheory. Our analysis provides theoretical bounds on the amount of information\nthat can be compressed without sacrificing model performance.\n  We also derive theorems that prove the stability and convergence of the\nhidden state in selective SSMs, ensuring reliable long-term memory retention.\nComputational complexity analysis reveals that selective SSMs offer significant\nimprovements in memory efficiency and processing speed compared to traditional\nRNN-based models. Through empirical validation on sequence modelling tasks such\nas time-series forecasting and natural language processing, we demonstrate that\nselective SSMs achieve state-of-the-art performance while using less memory and\ncomputational resources.",
      "tldr_zh": "本论文提出了一种针对选择性状态空间模型 (Selective State Space Models) 的数学框架，用于理解和优化序列数据建模中的内存压缩问题。论文引入了选择性门控机制 (Selective Gating Mechanism)，该机制动态过滤和更新隐藏状态基于输入的相关性，并使用 mutual information 和 rate-distortion theory 等信息论工具形式化内存效率与信息保留的权衡，提供理论边界以确保不牺牲模型性能。研究还证明了选择性 SSMs 的隐藏状态稳定性和收敛性，并在计算复杂性分析中显示其相较传统 RNNs 显著提高了内存效率和处理速度；实证结果表明，在时间序列预测和自然语言处理任务上，该模型实现了最先进性能的同时减少了资源消耗。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "comment": "27 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03158v1",
      "published_date": "2024-10-04 05:45:48 UTC",
      "updated_date": "2024-10-04 05:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:22:53.211002"
    },
    {
      "arxiv_id": "2410.03156v1",
      "title": "MELODI: Exploring Memory Compression for Long Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Yinpeng Chen",
        "DeLesley Hutchins",
        "Aren Jansen",
        "Andrey Zhmoginov",
        "David Racz",
        "Jesper Andersen"
      ],
      "abstract": "We present MELODI, a novel memory architecture designed to efficiently\nprocess long documents using short context windows. The key principle behind\nMELODI is to represent short-term and long-term memory as a hierarchical\ncompression scheme across both network layers and context windows.\nSpecifically, the short-term memory is achieved through recurrent compression\nof context windows across multiple layers, ensuring smooth transitions between\nwindows. In contrast, the long-term memory performs further compression within\na single middle layer and aggregates information across context windows,\neffectively consolidating crucial information from the entire history. Compared\nto a strong baseline - the Memorizing Transformer employing dense attention\nover a large long-term memory (64K key-value pairs) - our method demonstrates\nsuperior performance on various long-context datasets while remarkably reducing\nthe memory footprint by a factor of 8.",
      "tldr_zh": "该论文提出了 MELODI，一种新型内存架构，旨在通过分层压缩方案高效处理长文档，同时使用短上下文窗口。MELODI 将 short-term memory 通过在多个网络层上进行 recurrent compression 来确保上下文窗口之间平滑过渡，而 long-term memory 则在单个中间层上进一步压缩并聚合跨窗口的关键信息。相比于 Memorizing Transformer 基线，MELODI 在各种长-context 数据集上表现出优越性能，同时将内存占用减少 8 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03156v1",
      "published_date": "2024-10-04 05:34:15 UTC",
      "updated_date": "2024-10-04 05:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:23:04.643167"
    },
    {
      "arxiv_id": "2410.05298v2",
      "title": "How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Xinnan Dai",
        "Haohao Qu",
        "Yifen Shen",
        "Bohang Zhang",
        "Qihao Wen",
        "Wenqi Fan",
        "Dongsheng Li",
        "Jiliang Tang",
        "Caihua Shan"
      ],
      "abstract": "Benchmarking the capabilities and limitations of large language models (LLMs)\nin graph-related tasks is becoming an increasingly popular and crucial area of\nresearch. Recent studies have shown that LLMs exhibit a preliminary ability to\nunderstand graph structures and node features. However, the potential of LLMs\nin graph pattern mining remains largely unexplored. This is a key component in\nfields such as computational chemistry, biology, and social network analysis.\nTo bridge this gap, this work introduces a comprehensive benchmark to assess\nLLMs' capabilities in graph pattern tasks. We have developed a benchmark that\nevaluates whether LLMs can understand graph patterns based on either\nterminological or topological descriptions. Additionally, our benchmark tests\nthe LLMs' capacity to autonomously discover graph patterns from data. The\nbenchmark encompasses both synthetic and real datasets, and a variety of\nmodels, with a total of 11 tasks and 7 models. Our experimental framework is\ndesigned for easy expansion to accommodate new models and datasets. Our\nfindings reveal that: (1) LLMs have preliminary abilities to understand graph\npatterns, with O1-mini outperforming in the majority of tasks; (2) Formatting\ninput data to align with the knowledge acquired during pretraining can enhance\nperformance; (3) The strategies employed by LLMs may differ from those used in\nconventional algorithms.",
      "tldr_zh": "这篇论文引入了一个全面基准测试，评估大型语言模型（LLMs）在理解图模式方面的能力和局限性，特别是针对图模式挖掘任务，如计算化学、生物学和社会网络分析。基准包括基于术语或拓扑描述的图模式理解，以及LLMs自主从数据中发现模式的测试，共涵盖11个任务、7个模型，以及合成和真实数据集，并设计为易于扩展。实验发现，LLMs显示出初步的图模式理解能力，其中O1-mini在大多数任务中表现最佳；通过将输入数据格式化为与预训练知识一致的形式，可以显著提升性能；此外，LLMs采用的策略可能与传统算法不同。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper is published in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05298v2",
      "published_date": "2024-10-04 04:48:33 UTC",
      "updated_date": "2025-04-20 21:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:23:17.650967"
    },
    {
      "arxiv_id": "2410.03134v1",
      "title": "Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models",
      "title_zh": "剩余有用寿命预测：基于大型语言模型的多维工业信号处理和高效迁移学习研究",
      "authors": [
        "Yan Chen",
        "Cheng Liu"
      ],
      "abstract": "Remaining useful life (RUL) prediction is crucial for maintaining modern\nindustrial systems, where equipment reliability and operational safety are\nparamount. Traditional methods, based on small-scale deep learning or\nphysical/statistical models, often struggle with complex, multidimensional\nsensor data and varying operating conditions, limiting their generalization\ncapabilities. To address these challenges, this paper introduces an innovative\nregression framework utilizing large language models (LLMs) for RUL prediction.\nBy leveraging the modeling power of LLMs pre-trained on corpus data, the\nproposed model can effectively capture complex temporal dependencies and\nimprove prediction accuracy. Extensive experiments on the Turbofan engine's RUL\nprediction task show that the proposed model surpasses state-of-the-art (SOTA)\nmethods on the challenging FD002 and FD004 subsets and achieves near-SOTA\nresults on the other subsets. Notably, different from previous research, our\nframework uses the same sliding window length and all sensor signals for all\nsubsets, demonstrating strong consistency and generalization. Moreover,\ntransfer learning experiments reveal that with minimal target domain data for\nfine-tuning, the model outperforms SOTA methods trained on full target domain\ndata. This research highlights the significant potential of LLMs in industrial\nsignal processing and RUL prediction, offering a forward-looking solution for\nhealth management in future intelligent industrial systems.",
      "tldr_zh": "该论文提出了一种基于大型语言模型(LLMs)的创新回归框架，用于剩余可用寿命(RUL)预测，旨在解决传统方法在处理多维工业传感器数据和变化操作条件时的泛化能力不足问题。该框架利用LLMs的预训练能力有效捕捉复杂时序依赖，并在Turbofan引擎RUL任务上超越SOTA方法，尤其在FD002和FD004子集上实现显著性能提升，同时保持统一的滑动窗口长度和所有传感器信号使用。通过transfer learning实验，模型仅需少量目标域数据微调，即可优于用完整数据训练的SOTA方法，展示了LLMs在工业信号处理和智能系统健康管理中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03134v1",
      "published_date": "2024-10-04 04:21:53 UTC",
      "updated_date": "2024-10-04 04:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:23:29.860802"
    },
    {
      "arxiv_id": "2410.03132v5",
      "title": "Autoregressive Action Sequence Learning for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhang",
        "Yuhan Liu",
        "Haonan Chang",
        "Liam Schramm",
        "Abdeslam Boularias"
      ],
      "abstract": "Designing a universal policy architecture that performs well across diverse\nrobots and task configurations remains a key challenge. In this work, we\naddress this by representing robot actions as sequential data and generating\nactions through autoregressive sequence modeling. Existing autoregressive\narchitectures generate end-effector waypoints sequentially as word tokens in\nlanguage modeling, which are limited to low-frequency control tasks. Unlike\nlanguage, robot actions are heterogeneous and often include continuous values\n-- such as joint positions, 2D pixel coordinates, and end-effector poses --\nwhich are not easily suited for language-based modeling. Based on this insight,\nwe introduce a straightforward enhancement: we extend causal transformers'\nsingle-token prediction to support predicting a variable number of tokens in a\nsingle step through our Chunking Causal Transformer (CCT). This enhancement\nenables robust performance across diverse tasks of various control frequencies,\ngreater efficiency by having fewer autoregression steps, and lead to a hybrid\naction sequence design by mixing different types of actions and using a\ndifferent chunk size for each action type. Based on CCT, we propose the\nAutoregressive Policy (ARP) architecture, which solves manipulation tasks by\ngenerating hybrid action sequences. We evaluate ARP across diverse robotic\nmanipulation environments, including Push-T, ALOHA, and RLBench, and show that\nARP, as a universal architecture, matches or outperforms the\nenvironment-specific state-of-the-art in all tested benchmarks, while being\nmore efficient in computation and parameter sizes. Videos of our real robot\ndemonstrations, all source code and the pretrained models of ARP can be found\nat http://github.com/mlzxy/arp.",
      "tldr_zh": "这篇论文针对机器人操作任务的通用策略架构挑战，提出将动作表示为序列数据，通过自回归序列建模生成动作，以适应不同机器人和任务配置。作者引入了 Chunking Causal Transformer (CCT)，扩展因果变压器以一步预测可变数量的标记，支持异构动作（如关节位置和端效应器姿势），从而提高控制频率多样性和计算效率。实验结果显示，基于 CCT 的 Autoregressive Policy (ARP) 架构在 Push-T、ALOHA 和 RLBench 等环境中匹配或超过特定基准的最先进性能，同时在参数大小和计算资源上更高效。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "(RA-L 2025) Add a new figure to explain why chunking autoregression\n  works. Put back the previous in-depth discussion for arxiv release",
      "pdf_url": "http://arxiv.org/pdf/2410.03132v5",
      "published_date": "2024-10-04 04:07:15 UTC",
      "updated_date": "2025-03-25 19:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:23:42.146458"
    },
    {
      "arxiv_id": "2410.03131v3",
      "title": "AIME: AI System Optimization via Multiple LLM Evaluators",
      "title_zh": "翻译失败",
      "authors": [
        "Bhrij Patel",
        "Souradip Chakraborty",
        "Wesley A. Suttle",
        "Mengdi Wang",
        "Amrit Singh Bedi",
        "Dinesh Manocha"
      ],
      "abstract": "Text-based AI system optimization typically involves a feedback loop scheme\nwhere a single LLM generates an evaluation in natural language of the current\noutput to improve the next iteration's output. However, in this work, we\nempirically demonstrate that for a practical and complex task (code generation)\nwith multiple criteria to evaluate, utilizing only one LLM evaluator tends to\nlet errors in generated code go undetected, thus leading to incorrect\nevaluations and ultimately suboptimal test case performance. Motivated by this\nfailure case, we assume there exists an optimal evaluation policy that samples\nan evaluation between response and ground truth. We then theoretically prove\nthat a linear combination of multiple evaluators can approximate this optimal\npolicy. From this insight, we propose AI system optimization via Multiple LLM\nEvaluators (AIME). AIME is an evaluation protocol that utilizes multiple LLMs\nthat each independently generate an evaluation on separate criteria and then\ncombine them via concatenation. We provide an extensive empirical study showing\nAIME outperforming baseline methods in code generation tasks, with up to $62\\%$\nhigher error detection rate and up to $16\\%$ higher success rate than a single\nLLM evaluation protocol on LeetCodeHard and HumanEval datasets. We also show\nthat the selection of the number of evaluators and which criteria to utilize is\nnon-trivial as it can impact pact success rate by up to $12\\%$.",
      "tldr_zh": "本研究发现，传统AI系统优化方法依赖单一LLM评估器在复杂任务（如代码生成）中容易忽略错误，导致评估不准确和性能次优。为解决这一问题，论文提出AIME框架，该框架利用多个LLM评估器分别评估不同标准，然后通过连接组合它们的评估，以近似最优评估策略。实验结果显示，AIME在LeetCodeHard和HumanEval数据集上，比单一LLM协议提高了错误检测率高达62%和成功率高达16%，同时强调了评估器数量和标准的选择对成功率的影响可达12%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 10 Figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.03131v3",
      "published_date": "2024-10-04 04:03:24 UTC",
      "updated_date": "2024-10-29 02:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:23:52.441708"
    },
    {
      "arxiv_id": "2410.03129v2",
      "title": "ARB-LLM: Alternating Refined Binarizations for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiteng Li",
        "Xianglong Yan",
        "Tianao Zhang",
        "Haotong Qin",
        "Dong Xie",
        "Jiang Tian",
        "zhongchao shi",
        "Linghe Kong",
        "Yulun Zhang",
        "Xiaokang Yang"
      ],
      "abstract": "Large Language Models (LLMs) have greatly pushed forward advancements in\nnatural language processing, yet their high memory and computational demands\nhinder practical deployment. Binarization, as an effective compression\ntechnique, can shrink model weights to just 1 bit, significantly reducing the\nhigh demands on computation and memory. However, current binarization methods\nstruggle to narrow the distribution gap between binarized and full-precision\nweights, while also overlooking the column deviation in LLM weight\ndistribution. To tackle these issues, we propose ARB-LLM, a novel 1-bit\npost-training quantization (PTQ) technique tailored for LLMs. To narrow the\ndistribution shift between binarized and full-precision weights, we first\ndesign an alternating refined binarization (ARB) algorithm to progressively\nupdate the binarization parameters, which significantly reduces the\nquantization error. Moreover, considering the pivot role of calibration data\nand the column deviation in LLM weights, we further extend ARB to ARB-X and\nARB-RC. In addition, we refine the weight partition strategy with column-group\nbitmap (CGB), which further enhance performance. Equipping ARB-X and ARB-RC\nwith CGB, we obtain ARB-LLM$_\\text{X}$ and ARB-LLM$_\\text{RC}$ respectively,\nwhich significantly outperform state-of-the-art (SOTA) binarization methods for\nLLMs. As a binary PTQ method, our ARB-LLM$_\\text{RC}$ is the first to surpass\nFP16 models of the same size. The code and models will be available at\nhttps://github.com/ZHITENGLI/ARB-LLM.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的内存和计算需求问题，提出了一种新型1-bit后训练量化(PTQ)技术ARB-LLM，以有效压缩模型权重。ARB-LLM的核心是Alternating Refined Binarization (ARB)算法，通过逐步更新二值化参数减少量化误差，并扩展到ARB-X和ARB-RC以处理校准数据和LLM权重中的列偏差，同时引入Column-Group Bitmap (CGB)策略优化权重分区。实验结果显示，ARB-LLM$_\\text{X}$和ARB-LLM$_\\text{RC}$显著优于现有最先进方法，其中ARB-LLM$_\\text{RC}$首次在性能上超越相同大小的FP16模型，为LLMs的实际部署提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The code and models will be available at\n  https://github.com/ZHITENGLI/ARB-LLM",
      "pdf_url": "http://arxiv.org/pdf/2410.03129v2",
      "published_date": "2024-10-04 03:50:10 UTC",
      "updated_date": "2024-10-10 05:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:24:06.136229"
    },
    {
      "arxiv_id": "2410.03126v1",
      "title": "Understanding Decision Subjects' Engagement with and Perceived Fairness of AI Models When Opportunities of Qualification Improvement Exist",
      "title_zh": "翻译失败",
      "authors": [
        "Meric Altug Gemalmaz",
        "Ming Yin"
      ],
      "abstract": "We explore how an AI model's decision fairness affects people's engagement\nwith and perceived fairness of the model if they are subject to its decisions,\nbut could repeatedly and strategically respond to these decisions. Two types of\nstrategic responses are considered -- people could determine whether to\ncontinue interacting with the model, and whether to invest in themselves to\nimprove their chance of future favorable decisions from the model. Via three\nhuman-subject experiments, we found that in decision subjects' strategic,\nrepeated interactions with an AI model, the model's decision fairness does not\nchange their willingness to interact with the model or to improve themselves,\neven when the model exhibits unfairness on salient protected attributes.\nHowever, decision subjects still perceive the AI model to be less fair when it\nsystematically biases against their group, especially if the difficulty of\nimproving one's qualification for the favorable decision is larger for the\nlowly-qualified people.",
      "tldr_zh": "本文研究了AI模型的决策公平性如何影响决策主体的互动意愿和对模型的感知公平性，特别是当他们可以通过策略性回应（如继续互动或投资自我提升）来应对决策时。通过三个人类实验，研究发现，即使AI模型在保护属性上表现出不公平，决策主体的互动意愿和自我提升意愿并不会改变。然而，决策主体会认为AI模型不公平，尤其是当模型系统性地歧视其群体，且低资格者提升机会的难度较大时。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03126v1",
      "published_date": "2024-10-04 03:43:26 UTC",
      "updated_date": "2024-10-04 03:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:24:26.494202"
    },
    {
      "arxiv_id": "2410.03122v1",
      "title": "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Zhao",
        "Yuchen Yang",
        "Yijiang Li",
        "Yinzhi Cao"
      ],
      "abstract": "The ripple effect poses a significant challenge in knowledge editing for\nlarge language models. Namely, when a single fact is edited, the model\nstruggles to accurately update the related facts in a sequence, which is\nevaluated by multi-hop questions linked to a chain of related facts. Recent\nstrategies have moved away from traditional parameter updates to more flexible,\nless computation-intensive methods, proven to be more effective in addressing\nthe ripple effect. In-context learning (ICL) editing uses a simple\ndemonstration `Imagine that + new fact` to guide LLMs, but struggles with\ncomplex multi-hop questions as the new fact alone fails to specify the chain of\nfacts involved in such scenarios. Besides, memory-based editing maintains\nadditional storage for all edits and related facts, requiring continuous\nupdates to stay effective. As a result of these design limitations, the\nchallenge remains, with the highest accuracy being only 33.8% on the MQuAKE-cf\nbenchmarks for Vicuna-7B. To address this, we propose RippleCOT, a novel ICL\nediting approach integrating Chain-of-Thought (COT) reasoning. RippleCOT\nstructures demonstrations as `newfact, question, thought, answer`,\nincorporating a thought component to identify and decompose the multi-hop logic\nwithin questions. This approach effectively guides the model through complex\nmulti-hop questions with chains of related facts. Comprehensive experiments\ndemonstrate that RippleCOT significantly outperforms the state-of-the-art on\nthe ripple effect, achieving accuracy gains ranging from 7.8% to 87.1%.",
      "tldr_zh": "这篇论文针对大型语言模型中知识编辑的ripple effect问题，提出了一种新型ICL编辑方法RIPPLECOT，以Chain-of-Thought (COT)推理增强模型对多跳事实链的更新能力。RIPPLECOT通过结构化的演示格式（new fact, question, thought, answer）来识别和分解复杂多跳问题，从而更有效地指导模型处理相关事实。实验结果显示，该方法在MQuAKE-cf基准上比现有技术准确率提高了7.8%至87.1%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP findings",
      "pdf_url": "http://arxiv.org/pdf/2410.03122v1",
      "published_date": "2024-10-04 03:37:36 UTC",
      "updated_date": "2024-10-04 03:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:24:29.928772"
    },
    {
      "arxiv_id": "2410.03796v1",
      "title": "Dynamic Evidence Decoupling for Trusted Multi-view Learning",
      "title_zh": "动态证据解耦用于可信多视图学习",
      "authors": [
        "Ying Liu",
        "Lihong Liu",
        "Cai Xu",
        "Xiangyu Song",
        "Ziyu Guan",
        "Wei Zhao"
      ],
      "abstract": "Multi-view learning methods often focus on improving decision accuracy, while\nneglecting the decision uncertainty, limiting their suitability for\nsafety-critical applications. To mitigate this, researchers propose trusted\nmulti-view learning methods that estimate classification probabilities and\nuncertainty by learning the class distributions for each instance. However,\nthese methods assume that the data from each view can effectively differentiate\nall categories, ignoring the semantic vagueness phenomenon in real-world\nmulti-view data. Our findings demonstrate that this phenomenon significantly\nsuppresses the learning of view-specific evidence in existing methods. We\npropose a Consistent and Complementary-aware trusted Multi-view Learning (CCML)\nmethod to solve this problem. We first construct view opinions using evidential\ndeep neural networks, which consist of belief mass vectors and uncertainty\nestimates. Next, we dynamically decouple the consistent and complementary\nevidence. The consistent evidence is derived from the shared portions across\nall views, while the complementary evidence is obtained by averaging the\ndiffering portions across all views. We ensure that the opinion constructed\nfrom the consistent evidence strictly aligns with the ground-truth category.\nFor the opinion constructed from the complementary evidence, we allow it for\npotential vagueness in the evidence. We compare CCML with state-of-the-art\nbaselines on one synthetic and six real-world datasets. The results validate\nthe effectiveness of the dynamic evidence decoupling strategy and show that\nCCML significantly outperforms baselines on accuracy and reliability. The code\nis released at https://github.com/Lihong-Liu/CCML.",
      "tldr_zh": "该论文针对多视图学习（Multi-view Learning）方法忽略决策不确定性的问题，提出了一种可信的多视图学习方法，以提升其在安全关键应用中的适用性。研究发现，真实世界数据中的语义模糊现象会抑制视图特定证据的学习，因此引入 CCML（Consistent and Complementary-aware Trusted Multi-view Learning）框架，使用 Evidential Deep Neural Networks 构建视图意见，并动态解耦一致性和互补性证据：一致性证据来自视图共享部分，确保与真实类别对齐，而互补性证据则处理视图差异部分，允许潜在模糊。在一个合成数据集和六个真实世界数据集上的实验表明，CCML 在准确性和可靠性上显著优于现有基线方法。代码已开源于 https://github.com/Lihong-Liu/CCML。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03796v1",
      "published_date": "2024-10-04 03:27:51 UTC",
      "updated_date": "2024-10-04 03:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:24:40.625035"
    },
    {
      "arxiv_id": "2410.03117v1",
      "title": "ProcBench: Benchmark for Multi-Step Reasoning and Following Procedure",
      "title_zh": "ProcBench：多步推理和遵循程序的基准测试",
      "authors": [
        "Ippei Fujisawa",
        "Sensho Nobe",
        "Hiroki Seto",
        "Rina Onda",
        "Yoshiaki Uchida",
        "Hiroki Ikoma",
        "Pei-Chun Chien",
        "Ryota Kanai"
      ],
      "abstract": "Reasoning is central to a wide range of intellectual activities, and while\nthe capabilities of large language models (LLMs) continue to advance, their\nperformance in reasoning tasks remains limited. The processes and mechanisms\nunderlying reasoning are not yet fully understood, but key elements include\npath exploration, selection of relevant knowledge, and multi-step inference.\nProblems are solved through the synthesis of these components. In this paper,\nwe propose a benchmark that focuses on a specific aspect of reasoning ability:\nthe direct evaluation of multi-step inference. To this end, we design a special\nreasoning task where multi-step inference is specifically focused by largely\neliminating path exploration and implicit knowledge utilization. Our dataset\ncomprises pairs of explicit instructions and corresponding questions, where the\nprocedures necessary for solving the questions are entirely detailed within the\ninstructions. This setup allows models to solve problems solely by following\nthe provided directives. By constructing problems that require varying numbers\nof steps to solve and evaluating responses at each step, we enable a thorough\nassessment of state-of-the-art LLMs' ability to follow instructions. To ensure\nthe robustness of our evaluation, we include multiple distinct tasks.\nFurthermore, by comparing accuracy across tasks, utilizing step-aware metrics,\nand applying separately defined measures of complexity, we conduct experiments\nthat offer insights into the capabilities and limitations of LLMs in reasoning\ntasks. Our findings have significant implications for the development of LLMs\nand highlight areas for future research in advancing their reasoning abilities.\nOur dataset is available at\n\\url{https://huggingface.co/datasets/ifujisawa/procbench} and code at\n\\url{https://github.com/ifujisawa/proc-bench}.",
      "tldr_zh": "本研究提出ProcBench基准，用于评估大型语言模型(LLMs)在多步推理和遵循程序方面的能力，专注于直接测试多步推理而非路径探索或隐性知识利用。数据集包括成对的明确指令和问题，所有解决问题所需的程序均在指令中详细说明，从而允许模型仅通过遵循指令来完成任务。实验通过设计不同步骤数量的问题、多任务评估以及步骤感知指标和复杂性度量，揭示了当前LLMs的推理优势和局限性，为未来模型开发和研究提供了重要启示。数据集可从https://huggingface.co/datasets/ifujisawa/procbench获取，代码在https://github.com/ifujisawa/proc-bench。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03117v1",
      "published_date": "2024-10-04 03:21:24 UTC",
      "updated_date": "2024-10-04 03:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:24:53.181532"
    },
    {
      "arxiv_id": "2410.03111v1",
      "title": "LoRC: Low-Rank Compression for LLMs KV Cache with a Progressive Compression Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Rongzhi Zhang",
        "Kuang Wang",
        "Liyuan Liu",
        "Shuohang Wang",
        "Hao Cheng",
        "Chao Zhang",
        "Yelong Shen"
      ],
      "abstract": "The Key-Value (KV) cache is a crucial component in serving transformer-based\nautoregressive large language models (LLMs), enabling faster inference by\nstoring previously computed KV vectors. However, its memory consumption scales\nlinearly with sequence length and batch size, posing a significant bottleneck\nin LLM deployment. Existing approaches to mitigate this issue include: (1)\nefficient attention variants integrated in upcycling stages, which requires\nextensive parameter tuning thus unsuitable for pre-trained LLMs; (2) KV cache\ncompression at test time, primarily through token eviction policies, which\noften overlook inter-layer dependencies and can be task-specific.\n  This paper introduces an orthogonal approach to KV cache compression. We\npropose a low-rank approximation of KV weight matrices, allowing for plug-in\nintegration with existing transformer-based LLMs without model retraining. To\neffectively compress KV cache at the weight level, we adjust for layerwise\nsensitivity and introduce a progressive compression strategy, which is\nsupported by our theoretical analysis on how compression errors accumulate in\ndeep networks. Our method is designed to function without model tuning in\nupcycling stages or task-specific profiling in test stages. Extensive\nexperiments with LLaMA models ranging from 8B to 70B parameters across various\ntasks show that our approach significantly reduces the GPU memory footprint\nwhile maintaining performance.",
      "tldr_zh": "这篇论文提出了 LoRC，一种针对大型语言模型 (LLMs) KV Cache 的低秩压缩方法，通过低秩近似 KV 权重矩阵实现高效压缩，同时引入渐进压缩策略来处理层级敏感性和深度网络中的错误积累。不同于现有方法，该框架无需模型重新训练或任务特定调整，可直接集成到 transformer-based LLMs 中。实验结果显示，在 LLaMA 模型（从 8B 到 70B 参数）上，LoRC 显著减少了 GPU 内存占用，同时在各种任务中保持了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03111v1",
      "published_date": "2024-10-04 03:10:53 UTC",
      "updated_date": "2024-10-04 03:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:25:04.797886"
    },
    {
      "arxiv_id": "2410.03107v1",
      "title": "MBDS: A Multi-Body Dynamics Simulation Dataset for Graph Networks Simulators",
      "title_zh": "MBDS：用于图网络模拟器的多体动力学模拟数据集",
      "authors": [
        "Sheng Yang",
        "Fengge Wu",
        "Junsuo Zhao"
      ],
      "abstract": "Modeling the structure and events of the physical world constitutes a\nfundamental objective of neural networks. Among the diverse approaches, Graph\nNetwork Simulators (GNS) have emerged as the leading method for modeling\nphysical phenomena, owing to their low computational cost and high accuracy.\nThe datasets employed for training and evaluating physical simulation\ntechniques are typically generated by researchers themselves, often resulting\nin limited data volume and quality. Consequently, this poses challenges in\naccurately assessing the performance of these methods. In response to this, we\nhave constructed a high-quality physical simulation dataset encompassing 1D,\n2D, and 3D scenes, along with more trajectories and time-steps compared to\nexisting datasets. Furthermore, our work distinguishes itself by developing\neight complete scenes, significantly enhancing the dataset's comprehensiveness.\nA key feature of our dataset is the inclusion of precise multi-body dynamics,\nfacilitating a more realistic simulation of the physical world. Utilizing our\nhigh-quality dataset, we conducted a systematic evaluation of various existing\nGNS methods. Our dataset is accessible for download at\nhttps://github.com/Sherlocktein/MBDS, offering a valuable resource for\nresearchers to enhance the training and evaluation of their methodologies.",
      "tldr_zh": "该论文构建了MBDS数据集，用于Graph Network Simulators (GNS) 的训练和评估，以解决现有物理模拟数据集数据量和质量不足的问题。该数据集涵盖1D、2D和3D场景，包含更多轨迹和时间步，并开发了八个完整场景，融入精确的multi-body dynamics以实现更真实的模拟。通过系统评估现有GNS方法，该数据集证明了其在提升模型性能评估方面的价值，并可从https://github.com/Sherlocktein/MBDS下载。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03107v1",
      "published_date": "2024-10-04 03:03:06 UTC",
      "updated_date": "2024-10-04 03:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:25:16.961868"
    },
    {
      "arxiv_id": "2410.03105v1",
      "title": "Mamba in Vision: A Comprehensive Survey of Techniques and Applications",
      "title_zh": "Mamba in Vision：技术与应用的全面综述",
      "authors": [
        "Md Maklachur Rahman",
        "Abdullah Aman Tutul",
        "Ankur Nath",
        "Lamyanba Laishram",
        "Soon Ki Jung",
        "Tracy Hammond"
      ],
      "abstract": "Mamba is emerging as a novel approach to overcome the challenges faced by\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs) in computer\nvision. While CNNs excel at extracting local features, they often struggle to\ncapture long-range dependencies without complex architectural modifications. In\ncontrast, ViTs effectively model global relationships but suffer from high\ncomputational costs due to the quadratic complexity of their self-attention\nmechanisms. Mamba addresses these limitations by leveraging Selective\nStructured State Space Models to effectively capture long-range dependencies\nwith linear computational complexity. This survey analyzes the unique\ncontributions, computational benefits, and applications of Mamba models while\nalso identifying challenges and potential future research directions. We\nprovide a foundational resource for advancing the understanding and growth of\nMamba models in computer vision. An overview of this work is available at\nhttps://github.com/maklachur/Mamba-in-Computer-Vision.",
      "tldr_zh": "这篇调查综述探讨了Mamba模型在计算机视觉中的技术与应用，旨在克服Convolutional Neural Networks (CNNs)捕捉局部特征的局限和Vision Transformers (ViTs)的高计算复杂度问题。Mamba利用Selective Structured State Space Models实现线性计算复杂度的长程依赖性捕获，提供更高的计算效率和性能优势。该调查分析了Mamba的独特贡献、实际应用、潜在挑战，并指出了未来研究方向，作为推进该领域理解的重要资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.03105v1",
      "published_date": "2024-10-04 02:58:49 UTC",
      "updated_date": "2024-10-04 02:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:25:28.288302"
    },
    {
      "arxiv_id": "2410.03097v2",
      "title": "CLIPDrag: Combining Text-based and Drag-based Instructions for Image Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Jiang",
        "Zhen Wang",
        "Long Chen"
      ],
      "abstract": "Precise and flexible image editing remains a fundamental challenge in\ncomputer vision. Based on the modified areas, most editing methods can be\ndivided into two main types: global editing and local editing. In this paper,\nwe choose the two most common editing approaches (ie text-based editing and\ndrag-based editing) and analyze their drawbacks. Specifically, text-based\nmethods often fail to describe the desired modifications precisely, while\ndrag-based methods suffer from ambiguity. To address these issues, we proposed\n\\textbf{CLIPDrag}, a novel image editing method that is the first to combine\ntext and drag signals for precise and ambiguity-free manipulations on diffusion\nmodels. To fully leverage these two signals, we treat text signals as global\nguidance and drag points as local information. Then we introduce a novel\nglobal-local motion supervision method to integrate text signals into existing\ndrag-based methods by adapting a pre-trained language-vision model like CLIP.\nFurthermore, we also address the problem of slow convergence in CLIPDrag by\npresenting a fast point-tracking method that enforces drag points moving toward\ncorrect directions. Extensive experiments demonstrate that CLIPDrag outperforms\nexisting single drag-based methods or text-based methods.",
      "tldr_zh": "本论文提出CLIPDrag，一种创新的图像编辑方法，首次结合text-based和drag-based指令，解决传统方法的精确性不足和歧义问题。该方法将text signals作为全局指导，drag points作为局部信息，并引入global-local motion supervision技术，通过预训练的语言-视觉模型如CLIP，将文本信号整合到现有的drag-based方法中。同时，论文提出一个快速点跟踪方法，以加速CLIPDrag的收敛过程。实验结果表明，CLIPDrag在扩散模型上优于现有的单一text-based或drag-based方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03097v2",
      "published_date": "2024-10-04 02:46:09 UTC",
      "updated_date": "2025-02-26 02:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:25:41.131925"
    },
    {
      "arxiv_id": "2410.03092v1",
      "title": "Strategic Insights from Simulation Gaming of AI Race Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Gruetzemacher",
        "Shahar Avin",
        "James Fox",
        "Alexander K Saeri"
      ],
      "abstract": "We present insights from \"Intelligence Rising\", a scenario exploration\nexercise about possible AI futures. Drawing on the experiences of facilitators\nwho have overseen 43 games over a four-year period, we illuminate recurring\npatterns, strategies, and decision-making processes observed during gameplay.\nOur analysis reveals key strategic considerations about AI development\ntrajectories in this simulated environment, including: the destabilising\neffects of AI races, the crucial role of international cooperation in\nmitigating catastrophic risks, the challenges of aligning corporate and\nnational interests, and the potential for rapid, transformative change in AI\ncapabilities. We highlight places where we believe the game has been effective\nin exposing participants to the complexities and uncertainties inherent in AI\ngovernance. Key recurring gameplay themes include the emergence of\ninternational agreements, challenges to the robustness of such agreements, the\ncritical role of cybersecurity in AI development, and the potential for\nunexpected crises to dramatically alter AI trajectories. By documenting these\ninsights, we aim to provide valuable foresight for policymakers, industry\nleaders, and researchers navigating the complex landscape of AI development and\ngovernance.",
      "tldr_zh": "本研究基于“Intelligence Rising”模拟游戏，分析了43次游戏中的决策模式和策略，揭示了AI发展竞赛（AI Race Dynamics）的关键动态，包括AI竞赛的破坏性影响、国际合作在缓解灾难性风险中的重要性，以及企业与国家利益冲突的挑战。研究发现，游戏有效暴露了AI治理的复杂性和不确定性，突出主题如国际协议的形成与脆弱性、网络安全在AI开发中的关键作用，以及意外危机对AI轨迹的潜在影响。通过这些见解，论文为政策制定者、行业领袖和研究人员提供宝贵的前瞻性指导，以应对AI发展的复杂景观。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "41 pages, includes executive summary. Under review for academic\n  journal",
      "pdf_url": "http://arxiv.org/pdf/2410.03092v1",
      "published_date": "2024-10-04 02:34:21 UTC",
      "updated_date": "2024-10-04 02:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:25:52.051626"
    },
    {
      "arxiv_id": "2410.03083v1",
      "title": "Scaling Parameter-Constrained Language Models with Quality Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ernie Chang",
        "Matteo Paltenghi",
        "Yang Li",
        "Pin-Jie Lin",
        "Changsheng Zhao",
        "Patrick Huber",
        "Zechun Liu",
        "Rastislav Rabatin",
        "Yangyang Shi",
        "Vikas Chandra"
      ],
      "abstract": "Scaling laws in language modeling traditionally quantify training loss as a\nfunction of dataset size and model parameters, providing compute-optimal\nestimates but often neglecting the impact of data quality on model\ngeneralization. In this paper, we extend the conventional understanding of\nscaling law by offering a microscopic view of data quality within the original\nformulation -- effective training tokens -- which we posit to be a critical\ndeterminant of performance for parameter-constrained language models.\nSpecifically, we formulate the proposed term of effective training tokens to be\na combination of two readily-computed indicators of text: (i) text diversity\nand (ii) syntheticity as measured by a teacher model. We pretrained over $200$\nmodels of 25M to 1.5B parameters on a diverse set of sampled, synthetic data,\nand estimated the constants that relate text quality, model size, training\ntokens, and eight reasoning task accuracy scores. We demonstrated the estimated\nconstants yield +0.83 Pearson correlation with true accuracies, and analyzed it\nin scenarios involving widely-used data techniques such as data sampling and\nsynthesis which aim to improve data quality.",
      "tldr_zh": "本文扩展了语言模型的缩放定律（scaling laws），通过引入“有效训练标记”（effective training tokens）来量化数据质量（包括文本多样性（text diversity）和合成性（syntheticity））对参数受限模型性能的影响。作者训练了超过200个模型（从25M到1.5B参数），使用采样和合成数据，估计了文本质量、模型大小、训练标记与八个推理任务准确率的相关常量。结果显示，这些常量与实际准确率的相关性达到+0.83 Pearson correlation，并证明了在数据采样和合成等技术中的实际应用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Industry Track, 18 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.03083v1",
      "published_date": "2024-10-04 02:07:17 UTC",
      "updated_date": "2024-10-04 02:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:26:05.130763"
    },
    {
      "arxiv_id": "2410.03077v1",
      "title": "CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Rao",
        "Xuebo Liu",
        "Lian Lian",
        "Shengjun Cheng",
        "Yunjie Liao",
        "Min Zhang"
      ],
      "abstract": "With instruction tuning, Large Language Models (LLMs) can enhance their\nability to adhere to commands. Diverging from most works focusing on data\nmixing, our study concentrates on enhancing the model's capabilities from the\nperspective of data sampling during training. Drawing inspiration from the\nhuman learning process, where it is generally easier to master solutions to\nsimilar topics through focused practice on a single type of topic, we introduce\na novel instruction tuning strategy termed CommonIT: Commonality-aware\nInstruction Tuning. Specifically, we cluster instruction datasets into distinct\ngroups with three proposed metrics (Task, Embedding and Length). We ensure each\ntraining mini-batch, or \"partition\", consists solely of data from a single\ngroup, which brings about both data randomness across mini-batches and\nintra-batch data similarity. Rigorous testing on LLaMa models demonstrates\nCommonIT's effectiveness in enhancing the instruction-following capabilities of\nLLMs through IT datasets (FLAN, CoT, and Alpaca) and models (LLaMa2-7B,\nQwen2-7B, LLaMa 13B, and BLOOM 7B). CommonIT consistently boosts an average\nimprovement of 2.1\\% on the general domain (i.e., the average score of\nKnowledge, Reasoning, Multilinguality and Coding) with the Length metric, and\n5.2\\% on the special domain (i.e., GSM, Openfunctions and Code) with the Task\nmetric, and 3.8\\% on the specific tasks (i.e., MMLU) with the Embedding metric.\nCode is available at \\url{https://github.com/raojay7/CommonIT}.",
      "tldr_zh": "该论文提出CommonIT，一种基于数据聚类的指令微调策略，旨在通过模拟人类学习过程提升Large Language Models (LLMs)的指令遵循能力。具体方法包括使用Task、Embedding和Length三种指标对指令数据集进行聚类，确保每个训练mini-batch仅包含单一组数据，从而实现数据随机性和内部相似性。在LLaMa系列模型上实验表明，CommonIT分别在一般领域（如Knowledge和Reasoning）平均提升2.1%、特殊领域（如GSM和Code）提升5.2%、以及特定任务（如MMLU）提升3.8%，证明其有效性。代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03077v1",
      "published_date": "2024-10-04 01:42:35 UTC",
      "updated_date": "2024-10-04 01:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:26:17.423931"
    },
    {
      "arxiv_id": "2410.03072v2",
      "title": "Multi-Robot Motion Planning with Diffusion Models",
      "title_zh": "基于扩散模型的多机器人运动规划",
      "authors": [
        "Yorai Shaoul",
        "Itamar Mishani",
        "Shivam Vats",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "Diffusion models have recently been successfully applied to a wide range of\nrobotics applications for learning complex multi-modal behaviors from data.\nHowever, prior works have mostly been confined to single-robot and small-scale\nenvironments due to the high sample complexity of learning multi-robot\ndiffusion models. In this paper, we propose a method for generating\ncollision-free multi-robot trajectories that conform to underlying data\ndistributions while using only single-robot data. Our algorithm, Multi-robot\nMulti-model planning Diffusion (MMD), does so by combining learned diffusion\nmodels with classical search-based techniques -- generating data-driven motions\nunder collision constraints. Scaling further, we show how to compose multiple\ndiffusion models to plan in large environments where a single diffusion model\nfails to generalize well. We demonstrate the effectiveness of our approach in\nplanning for dozens of robots in a variety of simulated scenarios motivated by\nlogistics environments. View video demonstrations and code at:\nhttps://multi-robot-diffusion.github.io/.",
      "tldr_zh": "本研究提出了一种名为 Multi-robot Multi-model planning Diffusion (MMD) 的算法，利用 Diffusion Models 生成符合数据分布的无碰撞多机器人轨迹，仅需单机器人数据作为输入。该方法将学习到的扩散模型与经典搜索技术相结合，在碰撞约束下实现数据驱动的运动规划，并通过组合多个扩散模型来处理大型环境中的泛化问题。实验结果显示，MMD 在模拟物流场景中有效支持数十个机器人的规划，显著提升了多机器人系统的可扩展性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "The first three authors contributed equally to this work. Published\n  at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.03072v2",
      "published_date": "2024-10-04 01:31:13 UTC",
      "updated_date": "2025-05-07 13:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:26:28.258692"
    },
    {
      "arxiv_id": "2410.03063v1",
      "title": "Integrating Natural Language Prompting Tasks in Introductory Programming Courses",
      "title_zh": "将自然语言提示任务整合到入门编程课程中",
      "authors": [
        "Chris Kerslake",
        "Paul Denny",
        "David H Smith IV",
        "James Prather",
        "Juho Leinonen",
        "Andrew Luxton-Reilly",
        "Stephen MacNeil"
      ],
      "abstract": "Introductory programming courses often emphasize mastering syntax and basic\nconstructs before progressing to more complex and interesting programs. This\nbottom-up approach can be frustrating for novices, shifting the focus away from\nproblem solving and potentially making computing less appealing to a broad\nrange of students. The rise of generative AI for code production could\npartially address these issues by fostering new skills via interaction with AI\nmodels, including constructing high-level prompts and evaluating code that is\nautomatically generated. In this experience report, we explore the inclusion of\ntwo prompt-focused activities in an introductory course, implemented across\nfour labs in a six-week module. The first requires students to solve\ncomputational problems by writing natural language prompts, emphasizing\nproblem-solving over syntax. The second involves students crafting prompts to\ngenerate code equivalent to provided fragments, to foster an understanding of\nthe relationship between prompts and code. Most of the students in the course\nhad reported finding programming difficult to learn, often citing frustrations\nwith syntax and debugging. We found that self-reported difficulty with learning\nprogramming had a strong inverse relationship with performance on traditional\nprogramming assessments such as tests and projects, as expected. However,\nperformance on the natural language tasks was less strongly related to\nself-reported difficulty, suggesting they may target different skills. Learning\nhow to communicate with AI coding models is becoming an important skill, and\nnatural language prompting tasks may appeal to a broad range of students.",
      "tldr_zh": "本文探讨了在入门编程课程中整合自然语言提示任务，以缓解传统方法（如强调语法和基本结构）对新手的挫败感，并利用生成式AI（generative AI）培养问题解决技能。研究在四次实验中实施了两个活动：第一，让学生通过编写自然语言提示解决计算问题，焦点从语法转向问题解决；第二，要求学生创建提示生成与给定代码片段等价的代码，以理解提示与代码的关系。结果显示，这些任务的性能与学生自报的学习难度相关性较弱，表明它们可能针对不同的技能，并有助于吸引更广泛的学生学习编程。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 6 figures. Accepted for publication at SIGCSE Virtual 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.03063v1",
      "published_date": "2024-10-04 01:03:25 UTC",
      "updated_date": "2024-10-04 01:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:26:41.014523"
    },
    {
      "arxiv_id": "2410.03062v1",
      "title": "Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Grant Wardle",
        "Teo Susnjak"
      ],
      "abstract": "This paper examines how the sequencing of images and text within multi-modal\nprompts influences the reasoning performance of large language models (LLMs).\nWe performed empirical evaluations using three commercial LLMs. Our results\ndemonstrate that the order in which modalities are presented can significantly\naffect performance, particularly in tasks of varying complexity. For simpler\ntasks involving a single image, modality sequencing had a clear impact on\naccuracy. However, in more complex tasks involving multiple images and\nintricate reasoning steps, the effect of sequencing diminished, likely due to\nthe increased cognitive demands of the task. Our findings also highlight the\nimportance of question/prompt structure. In nested and multi-step reasoning\ntasks, modality sequencing played a key role in shaping model performance.\nWhile LLMs excelled in the initial stages of reasoning, they struggled to\nre-incorporate earlier information, underscoring the challenges of multi-hop\nreasoning within transformer architectures. This suggests that aligning the\nsequence of modalities with the logical flow of reasoning steps is more\ncritical than modality order alone. These insights offer valuable implications\nfor improving multi-modal prompt design, with broader applications across\nfields such as education, medical imaging, and cross-modal learning.",
      "tldr_zh": "这篇论文探讨了在多模态提示中，图像和文本顺序（modality sequencing）如何影响大型语言模型（LLMs）的推理性能。研究者通过对三个商业 LLMs 进行实证评估，发现模态顺序在简单任务（如单个图像）中显著提升准确率，但在复杂任务（如多个图像和多步推理）中影响减弱，可能由于认知需求的增加。论文强调提示结构的重要性，并建议将模态顺序与推理逻辑流程对齐，以优化多模态提示设计，并应用于教育、医疗成像和跨模态学习等领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03062v1",
      "published_date": "2024-10-04 00:55:15 UTC",
      "updated_date": "2024-10-04 00:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:26:56.250188"
    },
    {
      "arxiv_id": "2410.03056v1",
      "title": "Towards an Improved Metric for Evaluating Disentangled Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Sahib Julka",
        "Yashu Wang",
        "Michael Granitzer"
      ],
      "abstract": "Disentangled representation learning plays a pivotal role in making\nrepresentations controllable, interpretable and transferable. Despite its\nsignificance in the domain, the quest for reliable and consistent quantitative\ndisentanglement metric remains a major challenge. This stems from the\nutilisation of diverse metrics measuring different properties and the potential\nbias introduced by their design. Our work undertakes a comprehensive\nexamination of existing popular disentanglement evaluation metrics, comparing\nthem in terms of measuring aspects of disentanglement (viz. Modularity,\nCompactness, and Explicitness), detecting the factor-code relationship, and\ndescribing the degree of disentanglement. We propose a new framework for\nquantifying disentanglement, introducing a metric entitled \\emph{EDI}, that\nleverages the intuitive concept of \\emph{exclusivity} and improved factor-code\nrelationship to minimize ad-hoc decisions. An in-depth analysis reveals that\nEDI measures essential properties while offering more stability than existing\nmetrics, advocating for its adoption as a standardised approach.",
      "tldr_zh": "该论文探讨了解耦表示学习（Disentangled representation learning）中评估指标的改进问题，指出现有指标在测量模块性（Modularity）、紧凑性（Compactness）和显性性（Explicitness）等方面存在偏差和不一致性。作者通过全面比较现有指标，提出一个新的框架和指标 EDI，该指标利用独占性（exclusivity）和改进的因子-代码关系，减少人为决策偏差。实验结果显示，EDI 提供更稳定的度量性能，并被推荐作为标准化评估方法，以提升表示的可控性、解释性和可转移性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.03056v1",
      "published_date": "2024-10-04 00:32:59 UTC",
      "updated_date": "2024-10-04 00:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:27:05.451912"
    },
    {
      "arxiv_id": "2410.03055v1",
      "title": "Permissive Information-Flow Analysis for Large Language Models",
      "title_zh": "针对大语言模型的宽容信息流分析",
      "authors": [
        "Shoaib Ahmed Siddiqui",
        "Radhika Gaonkar",
        "Boris Köpf",
        "David Krueger",
        "Andrew Paverd",
        "Ahmed Salem",
        "Shruti Tople",
        "Lukas Wutschitz",
        "Menglin Xia",
        "Santiago Zanella-Béguelin"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly becoming commodity components of\nlarger software systems. This poses natural security and privacy problems:\npoisoned data retrieved from one component can change the model's behavior and\ncompromise the entire system, including coercing the model to spread\nconfidential data to untrusted components. One promising approach is to tackle\nthis problem at the system level via dynamic information flow (aka taint)\ntracking. Unfortunately, the traditional approach of propagating the most\nrestrictive input label to the output is too conservative for applications\nwhere LLMs operate on inputs retrieved from diverse sources. In this paper, we\npropose a novel, more permissive approach to propagate information flow labels\nthrough LLM queries. The key idea behind our approach is to propagate only the\nlabels of the samples that were influential in generating the model output and\nto eliminate the labels of unnecessary input. We implement and investigate the\neffectiveness of two variations of this approach, based on (i) prompt-based\nretrieval augmentation, and (ii) a $k$-nearest-neighbors language model. We\ncompare these with the baseline of an introspection-based influence estimator\nthat directly asks the language model to predict the output label. The results\nobtained highlight the superiority of our prompt-based label propagator, which\nimproves the label in more than 85% of the cases in an LLM agent setting. These\nfindings underscore the practicality of permissive label propagation for\nretrieval augmentation.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 在软件系统中可能导致的安全和隐私问题（如数据泄露或毒害输入影响输出），提出了一种更宽容的信息流 (information flow) 标签传播方法。该方法的核心在于仅传播对输出生成有影响的输入标签，消除了不必要的标签，并实现了两种变体：基于提示的检索增强 (retrieval augmentation) 和 k-nearest-neighbors 语言模型。实验结果显示，与基线内省-based 影响估计器相比，该提示-based 方法在 85% 的 LLM 代理场景中改善了标签精度，突显了其在检索增强中的实用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03055v1",
      "published_date": "2024-10-04 00:25:43 UTC",
      "updated_date": "2024-10-04 00:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:27:17.093302"
    },
    {
      "arxiv_id": "2410.03049v1",
      "title": "Scalable Frame-based Construction of Sociocultural NormBases for Socially-Aware Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Shilin Qu",
        "Weiqing Wang",
        "Xin Zhou",
        "Haolan Zhan",
        "Zhuang Li",
        "Lizhen Qu",
        "Linhao Luo",
        "Yuan-Fang Li",
        "Gholamreza Haffari"
      ],
      "abstract": "Sociocultural norms serve as guiding principles for personal conduct in\nsocial interactions, emphasizing respect, cooperation, and appropriate\nbehavior, which is able to benefit tasks including conversational information\nretrieval, contextual information retrieval and retrieval-enhanced machine\nlearning. We propose a scalable approach for constructing a Sociocultural Norm\n(SCN) Base using Large Language Models (LLMs) for socially aware dialogues. We\nconstruct a comprehensive and publicly accessible Chinese Sociocultural\nNormBase. Our approach utilizes socially aware dialogues, enriched with\ncontextual frames, as the primary data source to constrain the generating\nprocess and reduce the hallucinations. This enables extracting of high-quality\nand nuanced natural-language norm statements, leveraging the pragmatic\nimplications of utterances with respect to the situation. As real dialogue\nannotated with gold frames are not readily available, we propose using\nsynthetic data. Our empirical results show: (i) the quality of the SCNs derived\nfrom synthetic data is comparable to that from real dialogues annotated with\ngold frames, and (ii) the quality of the SCNs extracted from real data,\nannotated with either silver (predicted) or gold frames, surpasses that without\nthe frame annotations. We further show the effectiveness of the extracted SCNs\nin a RAG-based (Retrieval-Augmented Generation) model to reason about multiple\ndownstream dialogue tasks.",
      "tldr_zh": "本论文提出了一种可扩展的框架-based 方法，使用 Large Language Models (LLMs) 构建 Sociocultural Norm (SCN) Base，以支持社会感知对话，并公开了一个全面的中文 SCN Base。该方法利用社会感知对话作为主要数据源，通过上下文框架约束生成过程并减少幻觉，同时采用合成数据来替代不易获取的真实标注数据。实验结果表明，从合成数据提取的 SCN 质量与真实标注数据相当，而使用银级或金级框架标注的数据能进一步提升 SCN 质量；此外，这些 SCN 在 RAG-based 模型中有效提升了多个下游对话任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.03049v1",
      "published_date": "2024-10-04 00:08:46 UTC",
      "updated_date": "2024-10-04 00:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:27:29.931839"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 138,
  "processed_papers_count": 138,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T07:27:45.238641"
}