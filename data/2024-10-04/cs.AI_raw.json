[
  {
    "arxiv_id": "2410.03977v2",
    "title": "Learning to Balance: Diverse Normalization for Cloth-Changing Person Re-Identification",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Zhengwei Yin",
      "Xuan Song",
      "Yinqiang Zheng"
    ],
    "abstract": "Cloth-Changing Person Re-Identification (CC-ReID) involves recognizing\nindividuals in images regardless of clothing status. In this paper, we\nempirically and experimentally demonstrate that completely eliminating or fully\nretaining clothing features is detrimental to the task. Existing work, either\nrelying on clothing labels, silhouettes, or other auxiliary data, fundamentally\naim to balance the learning of clothing and identity features. However, we\npractically find that achieving this balance is challenging and nuanced. In\nthis study, we introduce a novel module called Diverse Norm, which expands\npersonal features into orthogonal spaces and employs channel attention to\nseparate clothing and identity features. A sample re-weighting optimization\nstrategy is also introduced to guarantee the opposite optimization direction.\nDiverse Norm presents a simple yet effective approach that does not require\nadditional data. Furthermore, Diverse Norm can be seamlessly integrated\nResNet50 and significantly outperforms the state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03977v2",
    "published_date": "2024-10-04 23:33:08 UTC",
    "updated_date": "2024-10-14 09:14:14 UTC"
  },
  {
    "arxiv_id": "2410.03974v2",
    "title": "Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport",
    "authors": [
      "Milena Gazdieva",
      "Jaemoo Choi",
      "Alexander Kolesov",
      "Jaewoong Choi",
      "Petr Mokrov",
      "Alexander Korotin"
    ],
    "abstract": "Aggregating data from multiple sources can be formalized as an Optimal\nTransport (OT) barycenter problem, which seeks to compute the average of\nprobability distributions with respect to OT discrepancies. However, in\nreal-world scenarios, the presence of outliers and noise in the data measures\ncan significantly hinder the performance of traditional statistical methods for\nestimating OT barycenters. To address this issue, we propose a novel scalable\napproach for estimating the robust continuous barycenter, leveraging the dual\nformulation of the (semi-)unbalanced OT problem. To the best of our knowledge,\nthis paper is the first attempt to develop an algorithm for robust barycenters\nunder the continuous distribution setup. Our method is framed as a min-max\noptimization problem and is adaptable to general cost functions. We rigorously\nestablish the theoretical underpinnings of the proposed method and demonstrate\nits robustness to outliers and class imbalance through a number of illustrative\nexperiments. Our source code is publicly available at\nhttps://github.com/milenagazdieva/U-NOTBarycenters.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03974v2",
    "published_date": "2024-10-04 23:27:33 UTC",
    "updated_date": "2025-04-14 04:16:25 UTC"
  },
  {
    "arxiv_id": "2410.03968v3",
    "title": "Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies",
    "authors": [
      "Sijin Chen",
      "Omar Hagrass",
      "Jason M. Klusowski"
    ],
    "abstract": "Decoding strategies play a pivotal role in text generation for modern\nlanguage models, yet a puzzling gap divides theory and practice. Surprisingly,\nstrategies that should intuitively be optimal, such as Maximum a Posteriori\n(MAP), often perform poorly in practice. Meanwhile, popular heuristic\napproaches like Top-$k$ and Nucleus sampling, which employ truncation and\nnormalization of the conditional next-token probabilities, have achieved great\nempirical success but lack theoretical justifications. In this paper, we\npropose Decoding Game, a comprehensive theoretical framework which reimagines\ntext generation as a two-player zero-sum game between Strategist, who seeks to\nproduce text credible in the true distribution, and Nature, who distorts the\ntrue distribution adversarially. After discussing the decomposibility of\nmulti-step generation, we derive the optimal strategy in closed form for\none-step Decoding Game. It is shown that the adversarial Nature imposes an\nimplicit regularization on likelihood maximization, and\ntruncation-normalization methods are first-order approximations to the optimal\nstrategy under this regularization. Additionally, by generalizing the objective\nand parameters of Decoding Game, near-optimal strategies encompass diverse\nmethods such as greedy search, temperature scaling, and hybrids thereof.\nNumerical experiments are conducted to complement our theoretical analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03968v3",
    "published_date": "2024-10-04 23:18:27 UTC",
    "updated_date": "2025-05-17 00:23:08 UTC"
  },
  {
    "arxiv_id": "2410.03964v2",
    "title": "Variational Language Concepts for Interpreting Foundation Language Models",
    "authors": [
      "Hengyi Wang",
      "Shiwei Tan",
      "Zhiqing Hong",
      "Desheng Zhang",
      "Hao Wang"
    ],
    "abstract": "Foundation Language Models (FLMs) such as BERT and its variants have achieved\nremarkable success in natural language processing. To date, the\ninterpretability of FLMs has primarily relied on the attention weights in their\nself-attention layers. However, these attention weights only provide word-level\ninterpretations, failing to capture higher-level structures, and are therefore\nlacking in readability and intuitiveness. To address this challenge, we first\nprovide a formal definition of conceptual interpretation and then propose a\nvariational Bayesian framework, dubbed VAriational Language Concept (VALC), to\ngo beyond word-level interpretations and provide concept-level interpretations.\nOur theoretical analysis shows that our VALC finds the optimal language\nconcepts to interpret FLM predictions. Empirical results on several real-world\ndatasets show that our method can successfully provide conceptual\ninterpretation for FLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.03964v2",
    "published_date": "2024-10-04 23:05:19 UTC",
    "updated_date": "2024-10-28 19:43:26 UTC"
  },
  {
    "arxiv_id": "2410.16282v2",
    "title": "Optimal Ground Station Selection for Low-Earth Orbiting Satellites",
    "authors": [
      "Duncan Eddy",
      "Michelle Ho",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "This paper presents a solution to the problem of optimal ground station\nselection for low-Earth orbiting (LEO) space missions that enables mission\noperators to precisely design their ground segment performance and costs. Space\nmission operators are increasingly turning to Ground-Station-as-a-Service\n(GSaaS) providers to supply the terrestrial communications segment to reduce\ncosts and increase network size. However, this approach leads to a new\nchallenge of selecting the optimal service providers and station locations for\na given mission. We consider the problem of ground station selection as an\noptimization problem and present a general solution framework that allows\nmission designers to set their overall optimization objective and constrain key\nmission performance variables such as total data downlink, total mission cost,\nrecurring operational cost, and maximum communications time-gap. We solve the\nproblem using integer programming (IP). To address computational scaling\nchallenges, we introduce a surrogate optimization approach where the optimal\nstation selection is determined based on solving the problem over a reduced\ntime domain. Two different IP formulations are evaluated using randomized\nselections of LEO satellites of varying constellation sizes. We consider the\nnetworks of the commercial GSaaS providers Atlas Space Operations, Amazon Web\nServices (AWS) Ground Station, Azure Orbital Ground Station, Kongsberg\nSatellite Services (KSAT), Leaf Space, and Viasat Real-Time Earth. We compare\nour results against standard operational practices of integrating with one or\ntwo primary ground station providers.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "13 pages, 3 tables, 4 figures, presented at IEEE Aeroconf 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.16282v2",
    "published_date": "2024-10-04 22:48:50 UTC",
    "updated_date": "2025-03-02 01:10:07 UTC"
  },
  {
    "arxiv_id": "2410.03960v2",
    "title": "SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation",
    "authors": [
      "Aurick Qiao",
      "Zhewei Yao",
      "Samyam Rajbhandari",
      "Yuxiong He"
    ],
    "abstract": "LLM inference for popular enterprise use cases, such as summarization, RAG,\nand code-generation, typically observes orders of magnitude longer prompt\nlengths than generation lengths. This characteristic leads to high cost of\nprefill and increased response latency. In this paper, we present SwiftKV, a\nnovel model transformation and distillation procedure specifically designed to\nreduce the time and cost of processing prompt tokens while preserving high\nquality of generated tokens. SwiftKV combines three key mechanisms: i)\nSingleInputKV, which prefills later layers' KV cache using a much earlier\nlayer's output, allowing prompt tokens to skip much of the model computation,\nii) AcrossKV, which merges the KV caches of neighboring layers to reduce the\nmemory footprint and support larger batch size for higher throughput, and iii)\na knowledge-preserving distillation procedure that can adapt existing LLMs for\nSwiftKV with minimal accuracy impact and low compute and data requirement. For\nLlama-3.1-8B and 70B, SwiftKV reduces the compute requirement of prefill by 50%\nand the memory requirement of the KV cache by 62.5% while incurring minimum\nquality degradation across a wide range of tasks. In the end-to-end inference\nserving using an optimized vLLM implementation, SwiftKV realizes up to 2x\nhigher aggregate throughput and 60% lower time per output token. It can achieve\na staggering 560 TFlops/GPU of normalized inference throughput, which\ntranslates to 16K tokens/s for Llama-3.1-70B in 16-bit precision on 4x H100\nGPUs. Our training, inference, and model implementations are open-sourced and\ncan be found through\nhttps://huggingface.co/collections/Snowflake/swiftkv-models-674f7d7474eb789e185d31cb.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03960v2",
    "published_date": "2024-10-04 22:45:26 UTC",
    "updated_date": "2024-12-05 14:56:56 UTC"
  },
  {
    "arxiv_id": "2410.03959v1",
    "title": "Grounding Language in Multi-Perspective Referential Communication",
    "authors": [
      "Zineng Tang",
      "Lingjun Mao",
      "Alane Suhr"
    ],
    "abstract": "We introduce a task and dataset for referring expression generation and\ncomprehension in multi-agent embodied environments. In this task, two agents in\na shared scene must take into account one another's visual perspective, which\nmay be different from their own, to both produce and understand references to\nobjects in a scene and the spatial relations between them. We collect a dataset\nof 2,970 human-written referring expressions, each paired with human\ncomprehension judgments, and evaluate the performance of automated models as\nspeakers and listeners paired with human partners, finding that model\nperformance in both reference generation and comprehension lags behind that of\npairs of human agents. Finally, we experiment training an open-weight speaker\nmodel with evidence of communicative success when paired with a listener,\nresulting in an improvement from 58.9 to 69.3% in communicative success and\neven outperforming the strongest proprietary model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2410.03959v1",
    "published_date": "2024-10-04 22:42:30 UTC",
    "updated_date": "2024-10-04 22:42:30 UTC"
  },
  {
    "arxiv_id": "2410.03955v4",
    "title": "A Retention-Centric Framework for Continual Learning with Guaranteed Model Developmental Safety",
    "authors": [
      "Gang Li",
      "Wendi Yu",
      "Yao Yao",
      "Wei Tong",
      "Yingbin Liang",
      "Qihang Lin",
      "Tianbao Yang"
    ],
    "abstract": "In real-world applications, learning-enabled systems often undergo iterative\nmodel development to address challenging or emerging tasks, which involve\ncollecting new data, training a new model and validating the model. This\ncontinual model development process raises a significant issue that acquiring\nnew or improving existing capabilities may inadvertently lose good capabilities\nof the old model, also known as catastrophic forgetting. While existing\ncontinual learning aims to mitigate catastrophic forgetting by trading off\nperformance on previous tasks and new tasks to ensure good average performance,\nit often falls short in cost-sensitive applications, where failing to preserve\nessential established capabilities introduces unforeseen costs and risks and\nsubstantial expenses for re-improving these capabilities. To address this\nissue, we impose a requirement on learning systems to ensure that a new model\nstrictly retains important capabilities of the old model while improving\ntarget-task performance, which we term model developmental safety. To ensure\nmodel developmental safety, we propose a retention-centric framework with\ndata-dependent constraints, and study how to continually develop a pretrained\nCLIP model for acquiring new or improving existing capabilities of image\nclassification. We propose an efficient constrained optimization algorithm with\ntheoretical guarantees and use its insights to finetune the CLIP model with\ntask-dependent heads for promoting the model developmental safety. Experiments\non autonomous driving and scene recognition datasets validate the efficacy of\nour method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03955v4",
    "published_date": "2024-10-04 22:34:58 UTC",
    "updated_date": "2025-04-19 02:00:47 UTC"
  },
  {
    "arxiv_id": "2410.03954v2",
    "title": "SDA-GRIN for Adaptive Spatial-Temporal Multivariate Time Series Imputation",
    "authors": [
      "Amir Eskandari",
      "Aman Anand",
      "Drishti Sharma",
      "Farhana Zulkernine"
    ],
    "abstract": "In various applications, the multivariate time series often suffers from\nmissing data. This issue can significantly disrupt systems that rely on the\ndata. Spatial and temporal dependencies can be leveraged to impute the missing\nsamples. Existing imputation methods often ignore dynamic changes in spatial\ndependencies. We propose a Spatial Dynamic Aware Graph Recurrent Imputation\nNetwork (SDA-GRIN) which is capable of capturing dynamic changes in spatial\ndependencies.SDA-GRIN leverages a multi-head attention mechanism to adapt graph\nstructures with time. SDA-GRIN models multivariate time series as a sequence of\ntemporal graphs and uses a recurrent message-passing architecture for\nimputation. We evaluate SDA-GRIN on four real-world datasets: SDA-GRIN improves\nMSE by 9.51% for the AQI and 9.40% for AQI-36. On the PEMS-BAY dataset, it\nachieves a 1.94% improvement in MSE. Detailed ablation study demonstrates the\neffect of window sizes and missing data on the performance of the method.\nProject page:https://ameskandari.github.io/sda-grin/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03954v2",
    "published_date": "2024-10-04 22:32:08 UTC",
    "updated_date": "2025-05-05 15:55:16 UTC"
  },
  {
    "arxiv_id": "2410.03952v2",
    "title": "A Brain-Inspired Regularizer for Adversarial Robustness",
    "authors": [
      "Elie Attias",
      "Cengiz Pehlevan",
      "Dina Obeid"
    ],
    "abstract": "Convolutional Neural Networks (CNNs) excel in many visual tasks, but they\ntend to be sensitive to slight input perturbations that are imperceptible to\nthe human eye, often resulting in task failures. Recent studies indicate that\ntraining CNNs with regularizers that promote brain-like representations, using\nneural recordings, can improve model robustness. However, the requirement to\nuse neural data severely restricts the utility of these methods. Is it possible\nto develop regularizers that mimic the computational function of neural\nregularizers without the need for neural recordings, thereby expanding the\nusability and effectiveness of these techniques? In this work, we inspect a\nneural regularizer introduced in Li et al. (2019) to extract its underlying\nstrength. The regularizer uses neural representational similarities, which we\nfind also correlate with pixel similarities. Motivated by this finding, we\nintroduce a new regularizer that retains the essence of the original but is\ncomputed using image pixel similarities, eliminating the need for neural\nrecordings. We show that our regularization method 1) significantly increases\nmodel robustness to a range of black box attacks on various datasets and 2) is\ncomputationally inexpensive and relies only on original datasets. Our work\nexplores how biologically motivated loss functions can be used to drive the\nperformance of artificial neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages plus appendix, 10 figures (main text), 15 figures\n  (appendix), 3 tables (appendix)",
    "pdf_url": "http://arxiv.org/pdf/2410.03952v2",
    "published_date": "2024-10-04 22:30:47 UTC",
    "updated_date": "2024-10-11 01:24:29 UTC"
  },
  {
    "arxiv_id": "2410.14700v1",
    "title": "Self-Supervised Keypoint Detection with Distilled Depth Keypoint Representation",
    "authors": [
      "Aman Anand",
      "Elyas Rashno",
      "Amir Eskandari",
      "Farhana Zulkernine"
    ],
    "abstract": "Existing unsupervised keypoint detection methods apply artificial\ndeformations to images such as masking a significant portion of images and\nusing reconstruction of original image as a learning objective to detect\nkeypoints. However, this approach lacks depth information in the image and\noften detects keypoints on the background. To address this, we propose\nDistill-DKP, a novel cross-modal knowledge distillation framework that\nleverages depth maps and RGB images for keypoint detection in a self-supervised\nsetting. During training, Distill-DKP extracts embedding-level knowledge from a\ndepth-based teacher model to guide an image-based student model with inference\nrestricted to the student. Experiments show that Distill-DKP significantly\noutperforms previous unsupervised methods by reducing mean L2 error by 47.15%\non Human3.6M, mean average error by 5.67% on Taichi, and improving keypoints\naccuracy by 1.3% on DeepFashion dataset. Detailed ablation studies demonstrate\nthe sensitivity of knowledge distillation across different layers of the\nnetwork. Project Page: https://23wm13.github.io/distill-dkp/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14700v1",
    "published_date": "2024-10-04 22:14:08 UTC",
    "updated_date": "2024-10-04 22:14:08 UTC"
  },
  {
    "arxiv_id": "2410.09080v2",
    "title": "Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs",
    "authors": [
      "Tianqi Shang",
      "Shu Yang",
      "Weiqing He",
      "Tianhua Zhai",
      "Dawei Li",
      "Bojian Hou",
      "Tianlong Chen",
      "Jason H. Moore",
      "Marylyn D. Ritchie",
      "Li Shen"
    ],
    "abstract": "Growing evidence suggests that social determinants of health (SDoH), a set of\nnonmedical factors, affect individuals' risks of developing Alzheimer's disease\n(AD) and related dementias. Nevertheless, the etiological mechanisms underlying\nsuch relationships remain largely unclear, mainly due to difficulties in\ncollecting relevant information. This study presents a novel, automated\nframework that leverages recent advancements of large language model (LLM) and\nnatural language processing techniques to mine SDoH knowledge from extensive\nliterature and integrate it with AD-related biological entities extracted from\nthe general-purpose knowledge graph PrimeKG. Utilizing graph neural networks,\nwe performed link prediction tasks to evaluate the resultant SDoH-augmented\nknowledge graph. Our framework shows promise for enhancing knowledge discovery\nin AD and can be generalized to other SDoH-related research areas, offering a\nnew tool for exploring the impact of social determinants on health outcomes.\nOur code is available at: https://github.com/hwq0726/SDoHenPKG",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AMIA-IS'25: AMIA Informatics Summit",
    "pdf_url": "http://arxiv.org/pdf/2410.09080v2",
    "published_date": "2024-10-04 21:39:30 UTC",
    "updated_date": "2025-04-16 05:45:31 UTC"
  },
  {
    "arxiv_id": "2410.03936v2",
    "title": "Learning Truncated Causal History Model for Video Restoration",
    "authors": [
      "Amirhosein Ghasemabadi",
      "Muhammad Kamran Janjua",
      "Mohammad Salameh",
      "Di Niu"
    ],
    "abstract": "One key challenge to video restoration is to model the transition dynamics of\nvideo frames governed by motion. In this work, we propose TURTLE to learn the\ntruncated causal history model for efficient and high-performing video\nrestoration. Unlike traditional methods that process a range of contextual\nframes in parallel, TURTLE enhances efficiency by storing and summarizing a\ntruncated history of the input frame latent representation into an evolving\nhistorical state. This is achieved through a sophisticated similarity-based\nretrieval mechanism that implicitly accounts for inter-frame motion and\nalignment. The causal design in TURTLE enables recurrence in inference through\nstate-memorized historical features while allowing parallel training by\nsampling truncated video clips. We report new state-of-the-art results on a\nmultitude of video restoration benchmark tasks, including video desnowing,\nnighttime video deraining, video raindrops and rain streak removal, video\nsuper-resolution, real-world and synthetic video deblurring, and blind video\ndenoising while reducing the computational cost compared to existing best\ncontextual methods on all these tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024. 24 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03936v2",
    "published_date": "2024-10-04 21:31:02 UTC",
    "updated_date": "2024-10-15 15:57:10 UTC"
  },
  {
    "arxiv_id": "2410.05312v1",
    "title": "An Intelligent Native Network Slicing Security Architecture Empowered by Federated Learning",
    "authors": [
      "Rodrigo Moreira",
      "Rodolfo S. Villaca",
      "Moises R. N. Ribeiro",
      "Joberto S. B. Martins",
      "Joao Henrique Correa",
      "Tereza C. Carvalho",
      "Flavio de Oliveira Silva"
    ],
    "abstract": "Network Slicing (NS) has transformed the landscape of resource sharing in\nnetworks, offering flexibility to support services and applications with highly\nvariable requirements in areas such as the next-generation 5G/6G mobile\nnetworks (NGMN), vehicular networks, industrial Internet of Things (IoT), and\nverticals. Although significant research and experimentation have driven the\ndevelopment of network slicing, existing architectures often fall short in\nintrinsic architectural intelligent security capabilities. This paper proposes\nan architecture-intelligent security mechanism to improve the NS solutions. We\nidealized a security-native architecture that deploys intelligent microservices\nas federated agents based on machine learning, providing intra-slice and\narchitectural operation security for the Slicing Future Internet\nInfrastructures (SFI2) reference architecture. It is noteworthy that federated\nlearning approaches match the highly distributed modern microservice-based\narchitectures, thus providing a unifying and scalable design choice for NS\nplatforms addressing both service and security. Using ML-Agents and Security\nAgents, our approach identified Distributed Denial-of-Service (DDoS) and\nintrusion attacks within the slice using generic and non-intrusive telemetry\nrecords, achieving an average accuracy of approximately $95.60\\%$ in the\nnetwork slicing architecture and $99.99\\%$ for the deployed slice --\nintra-slice. This result demonstrates the potential for leveraging\narchitectural operational security and introduces a promising new research\ndirection for network slicing architectures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NI",
      "I.2; I.6; F.2.2"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages, 12 figures, Future Generation Computer Systems (FGCS)",
    "pdf_url": "http://arxiv.org/pdf/2410.05312v1",
    "published_date": "2024-10-04 21:12:23 UTC",
    "updated_date": "2024-10-04 21:12:23 UTC"
  },
  {
    "arxiv_id": "2410.05311v1",
    "title": "ConceptLens: from Pixels to Understanding",
    "authors": [
      "Abhilekha Dalal",
      "Pascal Hitzler"
    ],
    "abstract": "ConceptLens is an innovative tool designed to illuminate the intricate\nworkings of deep neural networks (DNNs) by visualizing hidden neuron\nactivations. By integrating deep learning with symbolic methods, ConceptLens\noffers users a unique way to understand what triggers neuron activations and\nhow they respond to various stimuli. The tool uses error-margin analysis to\nprovide insights into the confidence levels of neuron activations, thereby\nenhancing the interpretability of DNNs. This paper presents an overview of\nConceptLens, its implementation, and its application in real-time visualization\nof neuron activations and error margins through bar charts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05311v1",
    "published_date": "2024-10-04 20:49:12 UTC",
    "updated_date": "2024-10-04 20:49:12 UTC"
  },
  {
    "arxiv_id": "2410.03920v2",
    "title": "Learning Object Properties Using Robot Proprioception via Differentiable Robot-Object Interaction",
    "authors": [
      "Peter Yichen Chen",
      "Chao Liu",
      "Pingchuan Ma",
      "John Eastman",
      "Daniela Rus",
      "Dylan Randle",
      "Yuri Ivanov",
      "Wojciech Matusik"
    ],
    "abstract": "Differentiable simulation has become a powerful tool for system\nidentification. While prior work has focused on identifying robot properties\nusing robot-specific data or object properties using object-specific data, our\napproach calibrates object properties by using information from the robot,\nwithout relying on data from the object itself. Specifically, we utilize robot\njoint encoder information, which is commonly available in standard robotic\nsystems. Our key observation is that by analyzing the robot's reactions to\nmanipulated objects, we can infer properties of those objects, such as inertia\nand softness. Leveraging this insight, we develop differentiable simulations of\nrobot-object interactions to inversely identify the properties of the\nmanipulated objects. Our approach relies solely on proprioception -- the\nrobot's internal sensing capabilities -- and does not require external\nmeasurement tools or vision-based tracking systems. This general method is\napplicable to any articulated robot and requires only joint position\ninformation. We demonstrate the effectiveness of our method on a low-cost\nrobotic platform, achieving accurate mass and elastic modulus estimations of\nmanipulated objects with just a few seconds of computation on a laptop.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CE",
      "cs.CV",
      "physics.comp-ph"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
    "pdf_url": "http://arxiv.org/pdf/2410.03920v2",
    "published_date": "2024-10-04 20:48:38 UTC",
    "updated_date": "2025-03-08 04:53:40 UTC"
  },
  {
    "arxiv_id": "2410.03913v1",
    "title": "Leveraging Fundamental Analysis for Stock Trend Prediction for Profit",
    "authors": [
      "John Phan",
      "Hung-Fu Chang"
    ],
    "abstract": "This paper investigates the application of machine learning models, Long\nShort-Term Memory (LSTM), one-dimensional Convolutional Neural Networks (1D\nCNN), and Logistic Regression (LR), for predicting stock trends based on\nfundamental analysis. Unlike most existing studies that predominantly utilize\ntechnical or sentiment analysis, we emphasize the use of a company's financial\nstatements and intrinsic value for trend forecasting. Using a dataset of 269\ndata points from publicly traded companies across various sectors from 2019 to\n2023, we employ key financial ratios and the Discounted Cash Flow (DCF) model\nto formulate two prediction tasks: Annual Stock Price Difference (ASPD) and\nDifference between Current Stock Price and Intrinsic Value (DCSPIV). These\ntasks assess the likelihood of annual profit and current profitability,\nrespectively. Our results demonstrate that LR models outperform CNN and LSTM\nmodels, achieving an average test accuracy of 74.66% for ASPD and 72.85% for\nDCSPIV. This study contributes to the limited literature on integrating\nfundamental analysis into machine learning for stock prediction, offering\nvaluable insights for both academic research and practical investment\nstrategies. By leveraging fundamental data, our approach highlights the\npotential for long-term stock trend prediction, supporting portfolio managers\nin their decision-making processes.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03913v1",
    "published_date": "2024-10-04 20:36:19 UTC",
    "updated_date": "2024-10-04 20:36:19 UTC"
  },
  {
    "arxiv_id": "2410.03908v1",
    "title": "Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis",
    "authors": [
      "Amey Hengle",
      "Atharva Kulkarni",
      "Shantanu Patankar",
      "Madhumitha Chandrasekaran",
      "Sneha D'Silva",
      "Jemima Jacob",
      "Rashmi Gupta"
    ],
    "abstract": "In this study, we introduce ANGST, a novel, first-of-its kind benchmark for\ndepression-anxiety comorbidity classification from social media posts. Unlike\ncontemporary datasets that often oversimplify the intricate interplay between\ndifferent mental health disorders by treating them as isolated conditions,\nANGST enables multi-label classification, allowing each post to be\nsimultaneously identified as indicating depression and/or anxiety. Comprising\n2876 meticulously annotated posts by expert psychologists and an additional\n7667 silver-labeled posts, ANGST posits a more representative sample of online\nmental health discourse. Moreover, we benchmark ANGST using various\nstate-of-the-art language models, ranging from Mental-BERT to GPT-4. Our\nresults provide significant insights into the capabilities and limitations of\nthese models in complex diagnostic scenarios. While GPT-4 generally outperforms\nother models, none achieve an F1 score exceeding 72% in multi-class comorbid\nclassification, underscoring the ongoing challenges in applying language models\nto mental health diagnostics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 Pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03908v1",
    "published_date": "2024-10-04 20:24:11 UTC",
    "updated_date": "2024-10-04 20:24:11 UTC"
  },
  {
    "arxiv_id": "2410.05310v2",
    "title": "An Approach To Enhance IoT Security In 6G Networks Through Explainable AI",
    "authors": [
      "Navneet Kaur",
      "Lav Gupta"
    ],
    "abstract": "Wireless communication has evolved significantly, with 6G offering\ngroundbreaking capabilities, particularly for IoT. However, the integration of\nIoT into 6G presents new security challenges, expanding the attack surface due\nto vulnerabilities introduced by advanced technologies such as open RAN,\nterahertz (THz) communication, IRS, massive MIMO, and AI. Emerging threats like\nAI exploitation, virtualization risks, and evolving attacks, including data\nmanipulation and signal interference, further complicate security efforts. As\n6G standards are set to be finalized by 2030, work continues to align security\nmeasures with technological advances. However, substantial gaps remain in\nframeworks designed to secure integrated IoT and 6G systems. Our research\naddresses these challenges by utilizing tree-based machine learning algorithms\nto manage complex datasets and evaluate feature importance. We apply data\nbalancing techniques to ensure fair attack representation and use SHAP and LIME\nto improve model transparency. By aligning feature importance with XAI methods\nand cross-validating for consistency, we boost model accuracy and enhance IoT\nsecurity within the 6G ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05310v2",
    "published_date": "2024-10-04 20:14:25 UTC",
    "updated_date": "2024-12-24 01:54:28 UTC"
  },
  {
    "arxiv_id": "2410.03904v1",
    "title": "Did You Hear That? Introducing AADG: A Framework for Generating Benchmark Data in Audio Anomaly Detection",
    "authors": [
      "Ksheeraja Raghavan",
      "Samiran Gode",
      "Ankit Shah",
      "Surabhi Raghavan",
      "Wolfram Burgard",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "abstract": "We introduce a novel, general-purpose audio generation framework specifically\ndesigned for anomaly detection and localization. Unlike existing datasets that\npredominantly focus on industrial and machine-related sounds, our framework\nfocuses a broader range of environments, particularly useful in real-world\nscenarios where only audio data are available, such as in video-derived or\ntelephonic audio. To generate such data, we propose a new method inspired by\nthe LLM-Modulo framework, which leverages large language models(LLMs) as world\nmodels to simulate such real-world scenarios. This tool is modular allowing a\nplug-and-play approach. It operates by first using LLMs to predict plausible\nreal-world scenarios. An LLM further extracts the constituent sounds, the order\nand the way in which these should be merged to create coherent wholes. Much\nlike the LLM-Modulo framework, we include rigorous verification of each output\nstage, ensuring the reliability of the generated data. The data produced using\nthe framework serves as a benchmark for anomaly detection applications,\npotentially enhancing the performance of models trained on audio data,\nparticularly in handling out-of-distribution cases. Our contributions thus fill\na critical void in audio anomaly detection resources and provide a scalable\ntool for generating diverse, realistic audio data.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, under review",
    "pdf_url": "http://arxiv.org/pdf/2410.03904v1",
    "published_date": "2024-10-04 20:12:35 UTC",
    "updated_date": "2024-10-04 20:12:35 UTC"
  },
  {
    "arxiv_id": "2410.03901v2",
    "title": "Improving Node Representation by Boosting Target-Aware Contrastive Loss",
    "authors": [
      "Ying-Chun Lin",
      "Jennifer Neville"
    ],
    "abstract": "Graphs model complex relationships between entities, with nodes and edges\ncapturing intricate connections. Node representation learning involves\ntransforming nodes into low-dimensional embeddings. These embeddings are\ntypically used as features for downstream tasks. Therefore, their quality has a\nsignificant impact on task performance. Existing approaches for node\nrepresentation learning span (semi-)supervised, unsupervised, and\nself-supervised paradigms. In graph domains, (semi-)supervised learning often\nonly optimizes models based on class labels, neglecting other abundant graph\nsignals, which limits generalization. While self-supervised or unsupervised\nlearning produces representations that better capture underlying graph signals,\nthe usefulness of these captured signals for downstream target tasks can vary.\nTo bridge this gap, we introduce Target-Aware Contrastive Learning\n(Target-aware CL) which aims to enhance target task performance by maximizing\nthe mutual information between the target task and node representations with a\nself-supervised learning process. This is achieved through a sampling function,\nXGBoost Sampler (XGSampler), to sample proper positive examples for the\nproposed Target-Aware Contrastive Loss (XTCL). By minimizing XTCL, Target-aware\nCL increases the mutual information between the target task and node\nrepresentations, such that model generalization is improved. Additionally,\nXGSampler enhances the interpretability of each signal by showing the weights\nfor sampling the proper positive examples. We show experimentally that XTCL\nsignificantly improves the performance on two target tasks: node classification\nand link prediction tasks, compared to state-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03901v2",
    "published_date": "2024-10-04 20:08:24 UTC",
    "updated_date": "2024-11-01 15:19:18 UTC"
  },
  {
    "arxiv_id": "2410.03893v1",
    "title": "Human-aligned Chess with a Bit of Search",
    "authors": [
      "Yiming Zhang",
      "Athul Paul Jacob",
      "Vivian Lai",
      "Daniel Fried",
      "Daphne Ippolito"
    ],
    "abstract": "Chess has long been a testbed for AI's quest to match human intelligence, and\nin recent years, chess AI systems have surpassed the strongest humans at the\ngame. However, these systems are not human-aligned; they are unable to match\nthe skill levels of all human partners or model human-like behaviors beyond\npiece movement. In this paper, we introduce Allie, a chess-playing AI designed\nto bridge the gap between artificial and human intelligence in this classic\ngame. Allie is trained on log sequences of real chess games to model the\nbehaviors of human chess players across the skill spectrum, including non-move\nbehaviors such as pondering times and resignations In offline evaluations, we\nfind that Allie exhibits humanlike behavior: it outperforms the existing\nstate-of-the-art in human chess move prediction and \"ponders\" at critical\npositions. The model learns to reliably assign reward at each game state, which\ncan be used at inference as a reward function in a novel time-adaptive\nMonte-Carlo tree search (MCTS) procedure, where the amount of search depends on\nhow long humans would think in the same positions. Adaptive search enables\nremarkable skill calibration; in a large-scale online evaluation against\nplayers with ratings from 1000 to 2600 Elo, our adaptive search method leads to\na skill gap of only 49 Elo on average, substantially outperforming search-free\nand standard MCTS baselines. Against grandmaster-level (2500 Elo) opponents,\nAllie with adaptive search exhibits the strength of a fellow grandmaster, all\nwhile learning exclusively from humans.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03893v1",
    "published_date": "2024-10-04 19:51:03 UTC",
    "updated_date": "2024-10-04 19:51:03 UTC"
  },
  {
    "arxiv_id": "2410.03892v1",
    "title": "Towards Cost Sensitive Decision Making",
    "authors": [
      "Yang Li",
      "Junier Oliva"
    ],
    "abstract": "Many real-world situations allow for the acquisition of additional relevant\ninformation when making decisions with limited or uncertain data. However,\ntraditional RL approaches either require all features to be acquired beforehand\n(e.g. in a MDP) or regard part of them as missing data that cannot be acquired\n(e.g. in a POMDP). In this work, we consider RL models that may actively\nacquire features from the environment to improve the decision quality and\ncertainty, while automatically balancing the cost of feature acquisition\nprocess and the reward of task decision process. We propose the\nActive-Acquisition POMDP and identify two types of the acquisition process for\ndifferent application domains. In order to assist the agent in the\nactively-acquired partially-observed environment and alleviate the\nexploration-exploitation dilemma, we develop a model-based approach, where a\ndeep generative model is utilized to capture the dependencies of the features\nand impute the unobserved features. The imputations essentially represent the\nbeliefs of the agent. Equipped with the dynamics model, we develop hierarchical\nRL algorithms to resolve both types of the AA-POMDPs. Empirical results\ndemonstrate that our approach achieves considerably better performance than\nexisting POMDP-RL solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03892v1",
    "published_date": "2024-10-04 19:48:23 UTC",
    "updated_date": "2024-10-04 19:48:23 UTC"
  },
  {
    "arxiv_id": "2410.03887v2",
    "title": "Solving Dual Sourcing Problems with Supply Mode Dependent Failure Rates",
    "authors": [
      "Fabian Akkerman",
      "Nils Knofius",
      "Matthieu van der Heijden",
      "Martijn Mes"
    ],
    "abstract": "This paper investigates dual sourcing problems with supply mode dependent\nfailure rates, particularly relevant in managing spare parts for\ndowntime-critical assets. To enhance resilience, businesses increasingly adopt\ndual sourcing strategies using both conventional and additive manufacturing\ntechniques. This paper explores how these strategies can optimise sourcing by\naddressing variations in part properties and failure rates. A significant\nchallenge is the distinct failure characteristics of parts produced by these\nmethods, which influence future demand. To tackle this, we propose a new\niterative heuristic and several reinforcement learning techniques combined with\nan endogenous parameterised learning (EPL) approach. This EPL approach -\ncompatible with any learning method - allows a single policy to handle various\ninput parameters for multiple items. In a stylised setting, our best policy\nachieves an average optimality gap of 0.4%. In a case study within the energy\nsector, our policies outperform the baseline in 91.1% of instances, yielding\naverage cost savings up to 22.6%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03887v2",
    "published_date": "2024-10-04 19:42:14 UTC",
    "updated_date": "2025-04-11 11:51:19 UTC"
  },
  {
    "arxiv_id": "2410.03884v1",
    "title": "KidLM: Advancing Language Models for Children -- Early Insights and Future Directions",
    "authors": [
      "Mir Tafseer Nayeem",
      "Davood Rafiei"
    ],
    "abstract": "Recent studies highlight the potential of large language models in creating\neducational tools for children, yet significant challenges remain in\nmaintaining key child-specific properties such as linguistic nuances, cognitive\nneeds, and safety standards. In this paper, we explore foundational steps\ntoward the development of child-specific language models, emphasizing the\nnecessity of high-quality pre-training data. We introduce a novel user-centric\ndata collection pipeline that involves gathering and validating a corpus\nspecifically written for and sometimes by children. Additionally, we propose a\nnew training objective, Stratified Masking, which dynamically adjusts masking\nprobabilities based on our domain-specific child language data, enabling models\nto prioritize vocabulary and concepts more suitable for children. Experimental\nevaluations demonstrate that our model excels in understanding lower\ngrade-level text, maintains safety by avoiding stereotypes, and captures\nchildren's unique preferences. Furthermore, we provide actionable insights for\nfuture research and development in child-specific language modeling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 (long, main)",
    "pdf_url": "http://arxiv.org/pdf/2410.03884v1",
    "published_date": "2024-10-04 19:35:44 UTC",
    "updated_date": "2024-10-04 19:35:44 UTC"
  },
  {
    "arxiv_id": "2410.03869v1",
    "title": "Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step",
    "authors": [
      "Wenxuan Wang",
      "Kuiyi Gao",
      "Zihan Jia",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Qiuzhi Liu",
      "Shuai Wang",
      "Wenxiang Jiao",
      "Zhaopeng Tu"
    ],
    "abstract": "Text-based image generation models, such as Stable Diffusion and DALL-E 3,\nhold significant potential in content creation and publishing workflows, making\nthem the focus in recent years. Despite their remarkable capability to generate\ndiverse and vivid images, considerable efforts are being made to prevent the\ngeneration of harmful content, such as abusive, violent, or pornographic\nmaterial. To assess the safety of existing models, we introduce a novel\njailbreaking method called Chain-of-Jailbreak (CoJ) attack, which compromises\nimage generation models through a step-by-step editing process. Specifically,\nfor malicious queries that cannot bypass the safeguards with a single prompt,\nwe intentionally decompose the query into multiple sub-queries. The image\ngeneration models are then prompted to generate and iteratively edit images\nbased on these sub-queries. To evaluate the effectiveness of our CoJ attack\nmethod, we constructed a comprehensive dataset, CoJ-Bench, encompassing nine\nsafety scenarios, three types of editing operations, and three editing\nelements. Experiments on four widely-used image generation services provided by\nGPT-4V, GPT-4o, Gemini 1.5 and Gemini 1.5 Pro, demonstrate that our CoJ attack\nmethod can successfully bypass the safeguards of models for over 60% cases,\nwhich significantly outperforms other jailbreaking methods (i.e., 14%).\nFurther, to enhance these models' safety against our CoJ attack method, we also\npropose an effective prompting-based method, Think Twice Prompting, that can\nsuccessfully defend over 95% of CoJ attack. We release our dataset and code to\nfacilitate the AI safety research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03869v1",
    "published_date": "2024-10-04 19:04:43 UTC",
    "updated_date": "2024-10-04 19:04:43 UTC"
  },
  {
    "arxiv_id": "2410.03867v1",
    "title": "Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance",
    "authors": [
      "Ricardo Di Pasquale",
      "Soledad Represa"
    ],
    "abstract": "In an era dominated by data, the management and utilization of\ndomain-specific language have emerged as critical challenges in various\napplication domains, particularly those with industry-specific requirements.\nOur work is driven by the need to effectively manage and process large volumes\nof short text documents inherent in specific application domains. By leveraging\ndomain-specific knowledge and expertise, our approach aims to shape factual\ndata within these domains, thereby facilitating enhanced utilization and\nunderstanding by end-users. Central to our methodology is the integration of\ndomain-specific language models with graph-oriented databases, facilitating\nseamless processing, analysis, and utilization of textual data within targeted\ndomains. Our work underscores the transformative potential of the partnership\nof domain-specific language models and graph-oriented databases. This\ncooperation aims to assist researchers and engineers in metric usage,\nmitigation of latency issues, boosting explainability, enhancing debug and\nimproving overall model performance. Moving forward, we envision our work as a\nguide AI engineers, providing valuable insights for the implementation of\ndomain-specific language models in conjunction with graph-oriented databases,\nand additionally provide valuable experience in full-life cycle maintenance of\nthis kind of products.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03867v1",
    "published_date": "2024-10-04 19:02:09 UTC",
    "updated_date": "2024-10-04 19:02:09 UTC"
  },
  {
    "arxiv_id": "2410.03864v1",
    "title": "DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search",
    "authors": [
      "Murong Yue",
      "Wenlin Yao",
      "Haitao Mi",
      "Dian Yu",
      "Ziyu Yao",
      "Dong Yu"
    ],
    "abstract": "Enhancing the capability of large language models (LLMs) in reasoning has\ngained significant attention in recent years. Previous studies have\ndemonstrated the effectiveness of various prompting strategies in aiding LLMs\nin reasoning (called \"reasoning actions\"), such as step-by-step thinking,\nreflecting before answering, solving with programs, and their combinations.\nHowever, these approaches often applied static, predefined reasoning actions\nuniformly to all questions, without considering the specific characteristics of\neach question or the capability of the task-solving LLM. In this paper, we\npropose DOTS, an approach enabling LLMs to reason dynamically via optimal\nreasoning trajectory search, tailored to the specific characteristics of each\nquestion and the inherent capability of the task-solving LLM. Our approach\ninvolves three key steps: i) defining atomic reasoning action modules that can\nbe composed into various reasoning action trajectories; ii) searching for the\noptimal action trajectory for each training question through iterative\nexploration and evaluation for the specific task-solving LLM; and iii) using\nthe collected optimal trajectories to train an LLM to plan for the reasoning\ntrajectories of unseen questions. In particular, we propose two learning\nparadigms, i.e., fine-tuning an external LLM as a planner to guide the\ntask-solving LLM, or directly fine-tuning the task-solving LLM with an\ninternalized capability for reasoning actions planning. Our experiments across\neight reasoning tasks show that our method consistently outperforms static\nreasoning techniques and the vanilla instruction tuning approach. Further\nanalysis reveals that our method enables LLMs to adjust their computation based\non problem complexity, allocating deeper thinking and reasoning to harder\nproblems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03864v1",
    "published_date": "2024-10-04 18:58:09 UTC",
    "updated_date": "2024-10-04 18:58:09 UTC"
  },
  {
    "arxiv_id": "2410.10848v1",
    "title": "Crafting Narrative Closures: Zero-Shot Learning with SSM Mamba for Short Story Ending Generation",
    "authors": [
      "Divyam Sharma",
      "Divya Santhanam"
    ],
    "abstract": "Writing stories is an engaging yet challenging endeavor. Often, authors\nencounter moments of creative block, where the path forward in their narrative\nbecomes obscured. This paper is designed to address such moments by providing\nan innovative solution: A tool that completes stories based on given prompts.\nBy inputting a short story prompt, users can receive a conclusion to their\nstory, articulated in one sentence or more, thereby enhancing the storytelling\nprocess with AI-driven creativity. This tool aims not only to assist authors in\nnavigating writer's block but also to offer a fun and interactive way for\nanyone to expand on story ideas spontaneously. Through this paper, we explore\nthe intersection of artificial intelligence and creative writing, pushing the\nboundaries of how stories can be crafted and concluded. To create our final\ntext-generation models, we used a pre-trained GPT-3.5 model and a newly created\nfinetuned SSM-Mamba model, both of which perform well on a comprehensive list\nof metrics including BERT score, METEOR, BLEU, ROUGE, and Perplexity. The SSM\nmodel has also been made public for the NLP community on HuggingFace models as\nan open source contribution, which for the timebeing is a first of its kind\nstate-space model for story-generation task on HuggingFace.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.10848v1",
    "published_date": "2024-10-04 18:56:32 UTC",
    "updated_date": "2024-10-04 18:56:32 UTC"
  },
  {
    "arxiv_id": "2410.09079v1",
    "title": "BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models",
    "authors": [
      "Aofei Chang",
      "Jiaqi Wang",
      "Han Liu",
      "Parminder Bhatia",
      "Cao Xiao",
      "Ting Wang",
      "Fenglong Ma"
    ],
    "abstract": "Parameter Efficient Fine-Tuning (PEFT) offers an efficient solution for\nfine-tuning large pretrained language models for downstream tasks. However,\nmost PEFT strategies are manually designed, often resulting in suboptimal\nperformance. Recent automatic PEFT approaches aim to address this but face\nchallenges such as search space entanglement, inefficiency, and lack of\nintegration between parameter budgets and search processes. To overcome these\nissues, we introduce a novel Budget-guided Iterative search strategy for\nautomatic PEFT (BIPEFT), significantly enhancing search efficiency. BIPEFT\nemploys a new iterative search strategy to disentangle the binary module and\nrank dimension search spaces. Additionally, we design early selection\nstrategies based on parameter budgets, accelerating the learning process by\ngradually removing unimportant modules and fixing rank dimensions. Extensive\nexperiments on public benchmarks demonstrate the superior performance of BIPEFT\nin achieving efficient and effective PEFT for downstream tasks with a low\nparameter budget.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2410.09079v1",
    "published_date": "2024-10-04 18:50:46 UTC",
    "updated_date": "2024-10-04 18:50:46 UTC"
  },
  {
    "arxiv_id": "2410.03859v1",
    "title": "SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?",
    "authors": [
      "John Yang",
      "Carlos E. Jimenez",
      "Alex L. Zhang",
      "Kilian Lieret",
      "Joyce Yang",
      "Xindi Wu",
      "Ori Press",
      "Niklas Muennighoff",
      "Gabriel Synnaeve",
      "Karthik R. Narasimhan",
      "Diyi Yang",
      "Sida I. Wang",
      "Ofir Press"
    ],
    "abstract": "Autonomous systems for software engineering are now capable of fixing bugs\nand developing features. These systems are commonly evaluated on SWE-bench\n(Jimenez et al., 2024a), which assesses their ability to solve software issues\nfrom GitHub repositories. However, SWE-bench uses only Python repositories,\nwith problem statements presented predominantly as text and lacking visual\nelements such as images. This limited coverage motivates our inquiry into how\nexisting systems might perform on unrepresented software engineering domains\n(e.g., front-end, game development, DevOps), which use different programming\nlanguages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench\nM), to evaluate systems on their ability to fix bugs in visual, user-facing\nJavaScript software. SWE-bench M features 617 task instances collected from 17\nJavaScript libraries used for web interface design, diagramming, data\nvisualization, syntax highlighting, and interactive mapping. Each SWE-bench M\ntask instance contains at least one image in its problem statement or unit\ntests. Our analysis finds that top-performing SWE-bench systems struggle with\nSWE-bench M, revealing limitations in visual problem-solving and cross-language\ngeneralization. Lastly, we show that SWE-agent's flexible language-agnostic\nfeatures enable it to substantially outperform alternatives on SWE-bench M,\nresolving 12% of task instances compared to 6% for the next best system.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03859v1",
    "published_date": "2024-10-04 18:48:58 UTC",
    "updated_date": "2024-10-04 18:48:58 UTC"
  },
  {
    "arxiv_id": "2410.03855v1",
    "title": "A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research",
    "authors": [
      "Teresa Salazar",
      "Helder Araújo",
      "Alberto Cano",
      "Pedro Henriques Abreu"
    ],
    "abstract": "Group fairness in machine learning is a critical area of research focused on\nachieving equitable outcomes across different groups defined by sensitive\nattributes such as race or gender. Federated learning, a decentralized approach\nto training machine learning models across multiple devices or organizations\nwithout sharing raw data, amplifies the need for fairness due to the\nheterogeneous data distributions across clients, which can exacerbate biases.\nThe intersection of federated learning and group fairness has attracted\nsignificant interest, with 47 research works specifically dedicated to\naddressing this issue. However, no dedicated survey has focused comprehensively\non group fairness in federated learning. In this work, we present an in-depth\nsurvey on this topic, addressing the critical challenges and reviewing related\nworks in the field. We create a novel taxonomy of these approaches based on key\ncriteria such as data partitioning, location, and applied strategies.\nAdditionally, we explore broader concerns related to this problem and\ninvestigate how different approaches handle the complexities of various\nsensitive groups and their intersections. Finally, we review the datasets and\napplications commonly used in current research. We conclude by highlighting key\nareas for future research, emphasizing the need for more methods to address the\ncomplexities of achieving group fairness in federated systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "68T01",
      "I.2.6; I.5.1; K.4.1"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03855v1",
    "published_date": "2024-10-04 18:39:28 UTC",
    "updated_date": "2024-10-04 18:39:28 UTC"
  },
  {
    "arxiv_id": "2410.05306v1",
    "title": "Towards Assuring EU AI Act Compliance and Adversarial Robustness of LLMs",
    "authors": [
      "Tomas Bueno Momcilovic",
      "Beat Buesser",
      "Giulio Zizzo",
      "Mark Purcell",
      "Dian Balta"
    ],
    "abstract": "Large language models are prone to misuse and vulnerable to security threats,\nraising significant safety and security concerns. The European Union's\nArtificial Intelligence Act seeks to enforce AI robustness in certain contexts,\nbut faces implementation challenges due to the lack of standards, complexity of\nLLMs and emerging security vulnerabilities. Our research introduces a framework\nusing ontologies, assurance cases, and factsheets to support engineers and\nstakeholders in understanding and documenting AI system compliance and security\nregarding adversarial robustness. This approach aims to ensure that LLMs adhere\nto regulatory standards and are equipped to counter potential threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted in the AI Act Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.05306v1",
    "published_date": "2024-10-04 18:38:49 UTC",
    "updated_date": "2024-10-04 18:38:49 UTC"
  },
  {
    "arxiv_id": "2410.03847v1",
    "title": "Model-Based Reward Shaping for Adversarial Inverse Reinforcement Learning in Stochastic Environments",
    "authors": [
      "Simon Sinong Zhan",
      "Qingyuan Wu",
      "Philip Wang",
      "Yixuan Wang",
      "Ruochen Jiao",
      "Chao Huang",
      "Qi Zhu"
    ],
    "abstract": "In this paper, we aim to tackle the limitation of the Adversarial Inverse\nReinforcement Learning (AIRL) method in stochastic environments where\ntheoretical results cannot hold and performance is degraded. To address this\nissue, we propose a novel method which infuses the dynamics information into\nthe reward shaping with the theoretical guarantee for the induced optimal\npolicy in the stochastic environments. Incorporating our novel model-enhanced\nrewards, we present a novel Model-Enhanced AIRL framework, which integrates\ntransition model estimation directly into reward shaping. Furthermore, we\nprovide a comprehensive theoretical analysis of the reward error bound and\nperformance difference bound for our method. The experimental results in MuJoCo\nbenchmarks show that our method can achieve superior performance in stochastic\nenvironments and competitive performance in deterministic environments, with\nsignificant improvement in sample efficiency, compared to existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03847v1",
    "published_date": "2024-10-04 18:27:37 UTC",
    "updated_date": "2024-10-04 18:27:37 UTC"
  },
  {
    "arxiv_id": "2410.09078v1",
    "title": "Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs",
    "authors": [
      "Tomas Bueno Momcilovic",
      "Dian Balta",
      "Beat Buesser",
      "Giulio Zizzo",
      "Mark Purcell"
    ],
    "abstract": "The EU AI Act (EUAIA) introduces requirements for AI systems which intersect\nwith the processes required to establish adversarial robustness. However, given\nthe ambiguous language of regulation and the dynamicity of adversarial attacks,\ndevelopers of systems with highly complex models such as LLMs may find their\neffort to be duplicated without the assurance of having achieved either\ncompliance or robustness. This paper presents a functional architecture that\nfocuses on bridging the two properties, by introducing components with clear\nreference to their source. Taking the detection layer recommended by the\nliterature, and the reporting layer required by the law, we aim to support\ndevelopers and auditors with a reasoning layer based on knowledge augmentation\n(rules, assurance cases, contextual mappings). Our findings demonstrate a novel\ndirection for ensuring LLMs deployed in the EU are both compliant and\nadversarially robust, which underpin trustworthiness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in the VECOMP 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.09078v1",
    "published_date": "2024-10-04 18:23:14 UTC",
    "updated_date": "2024-10-04 18:23:14 UTC"
  },
  {
    "arxiv_id": "2410.05305v2",
    "title": "Output Scouting: Auditing Large Language Models for Catastrophic Responses",
    "authors": [
      "Andrew Bell",
      "Joao Fonseca"
    ],
    "abstract": "Recent high profile incidents in which the use of Large Language Models\n(LLMs) resulted in significant harm to individuals have brought about a growing\ninterest in AI safety. One reason LLM safety issues occur is that models often\nhave at least some non-zero probability of producing harmful outputs. In this\nwork, we explore the following scenario: imagine an AI safety auditor is\nsearching for catastrophic responses from an LLM (e.g. a \"yes\" responses to\n\"can I fire an employee for being pregnant?\"), and is able to query the model a\nlimited number times (e.g. 1000 times). What is a strategy for querying the\nmodel that would efficiently find those failure responses? To this end, we\npropose output scouting: an approach that aims to generate semantically fluent\noutputs to a given prompt matching any target probability distribution. We then\nrun experiments using two LLMs and find numerous examples of catastrophic\nresponses. We conclude with a discussion that includes advice for practitioners\nwho are looking to implement LLM auditing for catastrophic responses. We also\nrelease an open-source toolkit (https://github.com/joaopfonseca/outputscouting)\nthat implements our auditing framework using the Hugging Face transformers\nlibrary.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work not ready, further experiments needed to validate the method",
    "pdf_url": "http://arxiv.org/pdf/2410.05305v2",
    "published_date": "2024-10-04 18:18:53 UTC",
    "updated_date": "2025-03-28 15:45:58 UTC"
  },
  {
    "arxiv_id": "2410.03841v1",
    "title": "Explaining the (Not So) Obvious: Simple and Fast Explanation of STAN, a Next Point of Interest Recommendation System",
    "authors": [
      "Fajrian Yunus",
      "Talel Abdessalem"
    ],
    "abstract": "A lot of effort in recent years have been expended to explain machine\nlearning systems. However, some machine learning methods are inherently\nexplainable, and thus are not completely black box. This enables the developers\nto make sense of the output without a developing a complex and expensive\nexplainability technique. Besides that, explainability should be tailored to\nsuit the context of the problem. In a recommendation system which relies on\ncollaborative filtering, the recommendation is based on the behaviors of\nsimilar users, therefore the explanation should tell which other users are\nsimilar to the current user. Similarly, if the recommendation system is based\non sequence prediction, the explanation should also tell which input timesteps\nare the most influential. We demonstrate this philosophy/paradigm in STAN\n(Spatio-Temporal Attention Network for Next Location Recommendation), a next\nPoint of Interest recommendation system based on collaborative filtering and\nsequence prediction. We also show that the explanation helps to \"debug\" the\noutput.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03841v1",
    "published_date": "2024-10-04 18:14:58 UTC",
    "updated_date": "2024-10-04 18:14:58 UTC"
  },
  {
    "arxiv_id": "2410.05304v1",
    "title": "Developing Assurance Cases for Adversarial Robustness and Regulatory Compliance in LLMs",
    "authors": [
      "Tomas Bueno Momcilovic",
      "Dian Balta",
      "Beat Buesser",
      "Giulio Zizzo",
      "Mark Purcell"
    ],
    "abstract": "This paper presents an approach to developing assurance cases for adversarial\nrobustness and regulatory compliance in large language models (LLMs). Focusing\non both natural and code language tasks, we explore the vulnerabilities these\nmodels face, including adversarial attacks based on jailbreaking, heuristics,\nand randomization. We propose a layered framework incorporating guardrails at\nvarious stages of LLM deployment, aimed at mitigating these attacks and\nensuring compliance with the EU AI Act. Our approach includes a meta-layer for\ndynamic risk management and reasoning, crucial for addressing the evolving\nnature of LLM vulnerabilities. We illustrate our method with two exemplary\nassurance cases, highlighting how different contexts demand tailored strategies\nto ensure robust and compliant AI systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to the ASSURE 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.05304v1",
    "published_date": "2024-10-04 18:14:29 UTC",
    "updated_date": "2024-10-04 18:14:29 UTC"
  },
  {
    "arxiv_id": "2410.03834v2",
    "title": "GraphRouter: A Graph-based Router for LLM Selections",
    "authors": [
      "Tao Feng",
      "Yanzhen Shen",
      "Jiaxuan You"
    ],
    "abstract": "The rapidly growing number and variety of Large Language Models (LLMs)\npresent significant challenges in efficiently selecting the appropriate LLM for\na given query, especially considering the trade-offs between performance and\ncomputational cost. Current LLM selection methods often struggle to generalize\nacross new LLMs and different tasks because of their limited ability to\nleverage contextual interactions among tasks, queries, and LLMs, as well as\ntheir dependence on a transductive learning framework. To address these\nshortcomings, we introduce a novel inductive graph framework, named as\nGraphRouter, which fully utilizes the contextual information among tasks,\nqueries, and LLMs to enhance the LLM selection process. GraphRouter constructs\na heterogeneous graph comprising task, query, and LLM nodes, with interactions\nrepresented as edges, which efficiently captures the contextual information\nbetween the query's requirements and the LLM's capabilities. Through an\ninnovative edge prediction mechanism, GraphRouter is able to predict attributes\n(the effect and cost of LLM response) of potential edges, allowing for\noptimized recommendations that adapt to both existing and newly introduced LLMs\nwithout requiring retraining. Comprehensive experiments across three distinct\neffect-cost weight scenarios have shown that GraphRouter substantially\nsurpasses existing routers, delivering a minimum performance improvement of\n12.3%. In addition, it achieves enhanced generalization across new LLMs\nsettings and supports diverse tasks with at least a 9.5% boost in effect and a\nsignificant reduction in computational demands. This work endeavors to apply a\ngraph-based approach for the contextual and adaptive selection of LLMs,\noffering insights for real-world applications. Our codes for GraphRouter is\nreleased at https://github.com/ulab-uiuc/GraphRouter.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03834v2",
    "published_date": "2024-10-04 18:02:48 UTC",
    "updated_date": "2025-03-17 15:08:47 UTC"
  },
  {
    "arxiv_id": "2410.03665v3",
    "title": "Estimating Body and Hand Motion in an Ego-sensed World",
    "authors": [
      "Brent Yi",
      "Vickie Ye",
      "Maya Zheng",
      "Yunqi Li",
      "Lea Müller",
      "Georgios Pavlakos",
      "Yi Ma",
      "Jitendra Malik",
      "Angjoo Kanazawa"
    ],
    "abstract": "We present EgoAllo, a system for human motion estimation from a head-mounted\ndevice. Using only egocentric SLAM poses and images, EgoAllo guides sampling\nfrom a conditional diffusion model to estimate 3D body pose, height, and hand\nparameters that capture a device wearer's actions in the allocentric coordinate\nframe of the scene. To achieve this, our key insight is in representation: we\npropose spatial and temporal invariance criteria for improving model\nperformance, from which we derive a head motion conditioning parameterization\nthat improves estimation by up to 18%. We also show how the bodies estimated by\nour system can improve hand estimation: the resulting kinematic and temporal\nconstraints can reduce world-frame errors in single-frame estimates by 40%.\nProject page: https://egoallo.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://egoallo.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.03665v3",
    "published_date": "2024-10-04 17:59:57 UTC",
    "updated_date": "2024-12-17 18:39:00 UTC"
  },
  {
    "arxiv_id": "2410.03663v3",
    "title": "Learning from Committee: Reasoning Distillation from a Mixture of Teachers with Peer-Review",
    "authors": [
      "Zhuochun Li",
      "Yuelyu Ji",
      "Rui Meng",
      "Daqing He"
    ],
    "abstract": "While reasoning capabilities typically emerge in large language models (LLMs)\nwith tens of billions of parameters, recent research focuses on improving\nsmaller open-source models through knowledge distillation (KD) from commercial\nLLMs. However, many of these studies rely solely on responses from a single LLM\nas the gold rationale, unlike the natural human learning process, which\ninvolves understanding both the correct answers and the reasons behind\nmistakes. In this paper, we introduce a novel Fault-Aware DistIllation via\nPeer-Review (FAIR) approach: 1) Instead of merely obtaining rationales from\nteachers, our method asks teachers to identify and explain the student's\nmistakes, providing customized instruction learning data. 2) We design a\nsimulated peer-review process between teacher LLMs, which selects only the\ngenerated rationales above the acceptance threshold. This reduces the chance of\nteachers guessing correctly with flawed rationale, improving instructional data\nquality. Comprehensive experiments and analysis on mathematical, commonsense,\nand logical reasoning tasks demonstrate the effectiveness of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03663v3",
    "published_date": "2024-10-04 17:59:41 UTC",
    "updated_date": "2025-02-19 18:34:19 UTC"
  },
  {
    "arxiv_id": "2410.03662v2",
    "title": "System 2 Reasoning Capabilities Are Nigh",
    "authors": [
      "Scott C. Lowe"
    ],
    "abstract": "In recent years, machine learning models have made strides towards human-like\nreasoning capabilities from several directions. In this work, we review the\ncurrent state of the literature and describe the remaining steps to achieve a\nneural model which can perform System~2 reasoning analogous to a human. We\nargue that if current models are insufficient to be classed as performing\nreasoning, there remains very little additional progress needed to attain that\ngoal.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03662v2",
    "published_date": "2024-10-04 17:59:36 UTC",
    "updated_date": "2024-10-29 23:40:27 UTC"
  },
  {
    "arxiv_id": "2410.03655v2",
    "title": "Geometric Representation Condition Improves Equivariant Molecule Generation",
    "authors": [
      "Zian Li",
      "Cai Zhou",
      "Xiyuan Wang",
      "Xingang Peng",
      "Muhan Zhang"
    ],
    "abstract": "Recent advancements in molecular generative models have demonstrated\nsubstantial potential in accelerating scientific discovery, particularly in\ndrug design. However, these models often face challenges in generating\nhigh-quality molecules, especially in conditional scenarios where specific\nmolecular properties must be satisfied. In this work, we introduce GeoRCG, a\ngeneral framework to enhance the performance of molecular generative models by\nintegrating geometric representation conditions with provable theoretical\nguarantees. We decompose the molecule generation process into two stages:\nfirst, generating an informative geometric representation; second, generating a\nmolecule conditioned on the representation. Compared to directly generating a\nmolecule, the relatively easy-to-generate representation in the first stage\nguides the second-stage generation to reach a high-quality molecule in a more\ngoal-oriented and much faster way. Leveraging EDM and SemlaFlow as the base\ngenerators, we observe significant quality improvements in unconditional\nmolecule generation tasks on the widely-used QM9 and GEOM-DRUG datasets. More\nnotably, in the challenging conditional molecular generation task, our\nframework achieves an average 31\\% performance improvement over\nstate-of-the-art approaches, highlighting the superiority of conditioning on\nsemantically rich geometric representations over conditioning on individual\nproperty values as in previous approaches. Furthermore, we show that, with such\nrepresentation guidance, the number of diffusion steps can be reduced to as\nsmall as 100 while largely preserving the generation quality achieved with\n1,000 steps, thereby significantly accelerating the generation process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03655v2",
    "published_date": "2024-10-04 17:57:35 UTC",
    "updated_date": "2025-02-10 06:34:22 UTC"
  },
  {
    "arxiv_id": "2410.03645v1",
    "title": "GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs",
    "authors": [
      "Pu Hua",
      "Minghuan Liu",
      "Annabella Macaluso",
      "Yunfeng Lin",
      "Weinan Zhang",
      "Huazhe Xu",
      "Lirui Wang"
    ],
    "abstract": "Robotic simulation today remains challenging to scale up due to the human\nefforts required to create diverse simulation tasks and scenes.\nSimulation-trained policies also face scalability issues as many sim-to-real\nmethods focus on a single task. To address these challenges, this work proposes\nGenSim2, a scalable framework that leverages coding LLMs with multi-modal and\nreasoning capabilities for complex and realistic simulation task creation,\nincluding long-horizon tasks with articulated objects. To automatically\ngenerate demonstration data for these tasks at scale, we propose planning and\nRL solvers that generalize within object categories. The pipeline can generate\ndata for up to 100 articulated tasks with 200 objects and reduce the required\nhuman efforts. To utilize such data, we propose an effective multi-task\nlanguage-conditioned policy architecture, dubbed proprioceptive point-cloud\ntransformer (PPT), that learns from the generated demonstrations and exhibits\nstrong sim-to-real zero-shot transfer. Combining the proposed pipeline and the\npolicy architecture, we show a promising usage of GenSim2 that the generated\ndata can be used for zero-shot transfer or co-train with real-world collected\ndata, which enhances the policy performance by 20% compared with training\nexclusively on limited real data.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2024. Project website: https://gensim2.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.03645v1",
    "published_date": "2024-10-04 17:51:33 UTC",
    "updated_date": "2024-10-04 17:51:33 UTC"
  },
  {
    "arxiv_id": "2410.03642v2",
    "title": "Aligning LLMs with Individual Preferences via Interaction",
    "authors": [
      "Shujin Wu",
      "May Fung",
      "Cheng Qian",
      "Jeonghwan Kim",
      "Dilek Hakkani-Tur",
      "Heng Ji"
    ],
    "abstract": "As large language models (LLMs) demonstrate increasingly advanced\ncapabilities, aligning their behaviors with human values and preferences\nbecomes crucial for their wide adoption. While previous research focuses on\ngeneral alignment to principles such as helpfulness, harmlessness, and honesty,\nthe need to account for individual and diverse preferences has been largely\noverlooked, potentially undermining customized human experiences. To address\nthis gap, we train LLMs that can ''interact to align'', essentially cultivating\nthe meta-skill of LLMs to implicitly infer the unspoken personalized\npreferences of the current user through multi-turn conversations, and then\ndynamically align their following behaviors and responses to these inferred\npreferences. Our approach involves establishing a diverse pool of 3,310\ndistinct user personas by initially creating seed examples, which are then\nexpanded through iterative self-generation and filtering. Guided by distinct\nuser personas, we leverage multi-LLM collaboration to develop a multi-turn\npreference dataset containing 3K+ multi-turn conversations in tree structures.\nFinally, we apply supervised fine-tuning and reinforcement learning to enhance\nLLMs using this dataset. For evaluation, we establish the ALOE (ALign With\nCustOmized PrEferences) benchmark, consisting of 100 carefully selected\nexamples and well-designed metrics to measure the customized alignment\nperformance during conversations. Experimental results demonstrate the\neffectiveness of our method in enabling dynamic, personalized alignment via\ninteraction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to COLING 2025. The code and dataset are made public at\n  https://github.com/ShujinWu-0814/ALOE",
    "pdf_url": "http://arxiv.org/pdf/2410.03642v2",
    "published_date": "2024-10-04 17:48:29 UTC",
    "updated_date": "2024-12-15 21:40:35 UTC"
  },
  {
    "arxiv_id": "2410.03818v1",
    "title": "Large Language Models can be Strong Self-Detoxifiers",
    "authors": [
      "Ching-Yun Ko",
      "Pin-Yu Chen",
      "Payel Das",
      "Youssef Mroueh",
      "Soham Dan",
      "Georgios Kollias",
      "Subhajit Chaudhury",
      "Tejaswini Pedapati",
      "Luca Daniel"
    ],
    "abstract": "Reducing the likelihood of generating harmful and toxic output is an\nessential task when aligning large language models (LLMs). Existing methods\nmainly rely on training an external reward model (i.e., another language model)\nor fine-tuning the LLM using self-generated data to influence the outcome. In\nthis paper, we show that LLMs have the capability of self-detoxification\nwithout the use of an additional reward model or re-training. We propose\n\\textit{Self-disciplined Autoregressive Sampling (SASA)}, a lightweight\ncontrolled decoding algorithm for toxicity reduction of LLMs. SASA leverages\nthe contextual representations from an LLM to learn linear subspaces\ncharacterizing toxic v.s. non-toxic output in analytical forms. When\nauto-completing a response token-by-token, SASA dynamically tracks the margin\nof the current output to steer the generation away from the toxic subspace, by\nadjusting the autoregressive sampling strategy. Evaluated on LLMs of different\nscale and nature, namely Llama-3.1-Instruct (8B), Llama-2 (7B), and GPT2-L\nmodels with the RealToxicityPrompts, BOLD, and AttaQ benchmarks, SASA markedly\nenhances the quality of the generated sentences relative to the original models\nand attains comparable performance to state-of-the-art detoxification\ntechniques, significantly reducing the toxicity level by only using the LLM's\ninternal representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03818v1",
    "published_date": "2024-10-04 17:45:15 UTC",
    "updated_date": "2024-10-04 17:45:15 UTC"
  },
  {
    "arxiv_id": "2410.03617v1",
    "title": "What Matters for Model Merging at Scale?",
    "authors": [
      "Prateek Yadav",
      "Tu Vu",
      "Jonathan Lai",
      "Alexandra Chronopoulou",
      "Manaal Faruqui",
      "Mohit Bansal",
      "Tsendsuren Munkhdalai"
    ],
    "abstract": "Model merging aims to combine multiple expert models into a more capable\nsingle model, offering benefits such as reduced storage and serving costs,\nimproved generalization, and support for decentralized model development.\nDespite its promise, previous studies have primarily focused on merging a few\nsmall models. This leaves many unanswered questions about the effect of scaling\nmodel size and how it interplays with other key factors -- like the base model\nquality and number of expert models -- , to affect the merged model's\nperformance. This work systematically evaluates the utility of model merging at\nscale, examining the impact of these different factors. We experiment with\nmerging fully fine-tuned models using 4 popular merging methods -- Averaging,\nTask~Arithmetic, Dare, and TIES -- across model sizes ranging from 1B-64B\nparameters and merging up to 8 different expert models. We evaluate the merged\nmodels on both held-in tasks, i.e., the expert's training tasks, and zero-shot\ngeneralization to unseen held-out tasks. Our experiments provide several new\ninsights about model merging at scale and the interplay between different\nfactors. First, we find that merging is more effective when experts are created\nfrom strong base models, i.e., models with good zero-shot performance. Second,\nlarger models facilitate easier merging. Third merging consistently improves\ngeneralization capabilities. Notably, when merging 8 large expert models, the\nmerged models often generalize better compared to the multitask trained models.\nFourth, we can better merge more expert models when working with larger models.\nFifth, different merging methods behave very similarly at larger scales.\nOverall, our findings shed light on some interesting properties of model\nmerging while also highlighting some limitations. We hope that this study will\nserve as a reference point on large-scale merging for upcoming research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 Pages, 7 Figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.03617v1",
    "published_date": "2024-10-04 17:17:19 UTC",
    "updated_date": "2024-10-04 17:17:19 UTC"
  },
  {
    "arxiv_id": "2410.03608v1",
    "title": "TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and Generation",
    "authors": [
      "Jonathan Cook",
      "Tim Rocktäschel",
      "Jakob Foerster",
      "Dennis Aumiller",
      "Alex Wang"
    ],
    "abstract": "Given the widespread adoption and usage of Large Language Models (LLMs), it\nis crucial to have flexible and interpretable evaluations of their\ninstruction-following ability. Preference judgments between model outputs have\nbecome the de facto evaluation standard, despite distilling complex,\nmulti-faceted preferences into a single ranking. Furthermore, as human\nannotation is slow and costly, LLMs are increasingly used to make these\njudgments, at the expense of reliability and interpretability. In this work, we\npropose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated,\ninterpretable evaluation protocol that structures evaluations with\nLLM-generated, instruction-specific checklists. We first show that, given an\ninstruction, LLMs can reliably produce high-quality, tailored evaluation\nchecklists that decompose the instruction into a series of YES/NO questions.\nEach question asks whether a candidate response meets a specific requirement of\nthe instruction. We demonstrate that using TICK leads to a significant increase\n(46.4% $\\to$ 52.2%) in the frequency of exact agreements between LLM judgements\nand human preferences, as compared to having an LLM directly score an output.\nWe then show that STICK (Self-TICK) can be used to improve generation quality\nacross multiple benchmarks via self-refinement and Best-of-N selection. STICK\nself-refinement on LiveBench reasoning tasks leads to an absolute gain of\n$+$7.8%, whilst Best-of-N selection with STICK attains $+$6.3% absolute\nimprovement on the real-world instruction dataset, WildBench. In light of this,\nstructured, multi-faceted self-improvement is shown to be a promising way to\nfurther advance LLM capabilities. Finally, by providing LLM-generated\nchecklists to human evaluators tasked with directly scoring LLM responses to\nWildBench instructions, we notably increase inter-annotator agreement (0.194\n$\\to$ 0.256).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03608v1",
    "published_date": "2024-10-04 17:09:08 UTC",
    "updated_date": "2024-10-04 17:09:08 UTC"
  },
  {
    "arxiv_id": "2410.03596v1",
    "title": "SiMilarity-Enhanced Homophily for Multi-View Heterophilous Graph Clustering",
    "authors": [
      "Jianpeng Chen",
      "Yawen Ling",
      "Yazhou Ren",
      "Zichen Wen",
      "Tianyi Wu",
      "Shufei Zhang",
      "Lifang He"
    ],
    "abstract": "With the increasing prevalence of graph-structured data, multi-view graph\nclustering has been widely used in various downstream applications. Existing\napproaches primarily rely on a unified message passing mechanism, which\nsignificantly enhances clustering performance. Nevertheless, this mechanism\nlimits its applicability to heterophilous situations, as it is fundamentally\npredicated on the assumption of homophily, i.e., the connected nodes often\nbelong to the same class. In reality, this assumption does not always hold; a\nmoderately or even mildly homophilous graph is more common than a fully\nhomophilous one due to inevitable heterophilous information in the graph. To\naddress this issue, in this paper, we propose a novel SiMilarity-enhanced\nHomophily for Multi-view Heterophilous Graph Clustering (SMHGC) approach. By\nanalyzing the relationship between similarity and graph homophily, we propose\nto enhance the homophily by introducing three similarity terms, i.e., neighbor\npattern similarity, node feature similarity, and multi-view global similarity,\nin a label-free manner. Then, a consensus-based inter- and intra-view fusion\nparadigm is proposed to fuse the improved homophilous graph from different\nviews and utilize them for clustering. The state-of-the-art experimental\nresults on both multi-view heterophilous and homophilous datasets collectively\ndemonstrate the strong capacity of similarity for unsupervised multi-view\nheterophilous graph learning. Additionally, the consistent performance across\nsemi-synthetic datasets with varying levels of homophily serves as further\nevidence of SMHGC's resilience to heterophily.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03596v1",
    "published_date": "2024-10-04 16:55:35 UTC",
    "updated_date": "2024-10-04 16:55:35 UTC"
  },
  {
    "arxiv_id": "2410.03595v1",
    "title": "Understanding Reasoning in Chain-of-Thought from the Hopfieldian View",
    "authors": [
      "Lijie Hu",
      "Liang Liu",
      "Shu Yang",
      "Xin Chen",
      "Zhen Tan",
      "Muhammad Asif Ali",
      "Mengdi Li",
      "Di Wang"
    ],
    "abstract": "Large Language Models have demonstrated remarkable abilities across various\ntasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to\nenhance reasoning capabilities. However, existing research primarily focuses on\nimproving performance, lacking a comprehensive framework to explain and\nunderstand the fundamental factors behind CoT's success. To bridge this gap, we\nintroduce a novel perspective grounded in the Hopfieldian view of cognition in\ncognitive neuroscience. We establish a connection between CoT reasoning and key\ncognitive elements such as stimuli, actions, neural populations, and\nrepresentation spaces. From our view, we can understand the reasoning process\nas the movement between these representation spaces. Building on this insight,\nwe develop a method for localizing reasoning errors in the response of CoTs.\nMoreover, we propose the Representation-of-Thought (RoT) framework, which\nleverages the robustness of low-dimensional representation spaces to enhance\nthe robustness of the reasoning process in CoTs. Experimental results\ndemonstrate that RoT improves the robustness and interpretability of CoT\nreasoning while offering fine-grained control over the reasoning process.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, a new version of \"A Hopfieldian View-based Interpretation\n  for Chain-of-Thought Reasoning\"",
    "pdf_url": "http://arxiv.org/pdf/2410.03595v1",
    "published_date": "2024-10-04 16:55:30 UTC",
    "updated_date": "2024-10-04 16:55:30 UTC"
  },
  {
    "arxiv_id": "2410.03592v1",
    "title": "Variational Bayes Gaussian Splatting",
    "authors": [
      "Toon Van de Maele",
      "Ozan Catal",
      "Alexander Tschantz",
      "Christopher L. Buckley",
      "Tim Verbelen"
    ],
    "abstract": "Recently, 3D Gaussian Splatting has emerged as a promising approach for\nmodeling 3D scenes using mixtures of Gaussians. The predominant optimization\nmethod for these models relies on backpropagating gradients through a\ndifferentiable rendering pipeline, which struggles with catastrophic forgetting\nwhen dealing with continuous streams of data. To address this limitation, we\npropose Variational Bayes Gaussian Splatting (VBGS), a novel approach that\nframes training a Gaussian splat as variational inference over model\nparameters. By leveraging the conjugacy properties of multivariate Gaussians,\nwe derive a closed-form variational update rule, allowing efficient updates\nfrom partial, sequential observations without the need for replay buffers. Our\nexperiments show that VBGS not only matches state-of-the-art performance on\nstatic datasets, but also enables continual learning from sequentially streamed\n2D and 3D data, drastically improving performance in this setting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03592v1",
    "published_date": "2024-10-04 16:52:03 UTC",
    "updated_date": "2024-10-04 16:52:03 UTC"
  },
  {
    "arxiv_id": "2410.03580v1",
    "title": "A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle Development",
    "authors": [
      "Jesper Knapp",
      "Klas Moberg",
      "Yuchuan Jin",
      "Simin Sun",
      "Miroslaw Staron"
    ],
    "abstract": "Autonomous driving software generates enormous amounts of data every second,\nwhich software development organizations save for future analysis and testing\nin the form of logs. However, given the vast size of this data, locating\nspecific scenarios within a collection of vehicle logs can be challenging.\nWriting the correct SQL queries to find these scenarios requires engineers to\nhave a strong background in SQL and the specific databases in question, further\ncomplicating the search process. This paper presents and evaluates a pipeline\nthat allows searching for specific scenarios in log collections using natural\nlanguage descriptions instead of SQL. The generated descriptions were evaluated\nby engineers working with vehicle logs at the Zenseact on a scale from 1 to 5.\nOur approach achieved a mean score of 3.3, demonstrating the potential of using\na multi-model architecture to improve the software development workflow. We\nalso present an interface that can visualize the query process and visualize\nthe results.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03580v1",
    "published_date": "2024-10-04 16:38:27 UTC",
    "updated_date": "2024-10-04 16:38:27 UTC"
  },
  {
    "arxiv_id": "2410.03565v2",
    "title": "Exploration Implies Data Augmentation: Reachability and Generalisation in Contextual MDPs",
    "authors": [
      "Max Weltevrede",
      "Caroline Horsch",
      "Matthijs T. J. Spaan",
      "Wendelin Böhmer"
    ],
    "abstract": "In the zero-shot policy transfer (ZSPT) setting for contextual Markov\ndecision processes (MDP), agents train on a fixed set of contexts and must\ngeneralise to new ones. Recent work has argued and demonstrated that increased\nexploration can improve this generalisation, by training on more states in the\ntraining contexts. In this paper, we demonstrate that training on more states\ncan indeed improve generalisation, but can come at a cost of reducing the\naccuracy of the learned value function which should not benefit generalisation.\nWe introduce reachability in the ZSPT setting to define which states/contexts\nrequire generalisation and explain why exploration can improve it. We\nhypothesise and demonstrate that using exploration to increase the agent's\ncoverage while also increasing the accuracy improves generalisation even more.\nInspired by this, we propose a method Explore-Go that implements an exploration\nphase at the beginning of each episode, which can be combined with existing on-\nand off-policy RL algorithms and significantly improves generalisation even in\npartially observable MDPs. We demonstrate the effectiveness of Explore-Go when\ncombined with several popular algorithms and show an increase in generalisation\nperformance across several environments. With this, we hope to provide\npractitioners with a simple modification that can improve the generalisation of\ntheir agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2406.08069",
    "pdf_url": "http://arxiv.org/pdf/2410.03565v2",
    "published_date": "2024-10-04 16:15:31 UTC",
    "updated_date": "2025-03-05 10:47:17 UTC"
  },
  {
    "arxiv_id": "2410.03560v1",
    "title": "færdXel: An Expert System for Danish Traffic Law",
    "authors": [
      "Luís Cruz-Filipe",
      "Jonas Vistrup"
    ],
    "abstract": "We present f{\\ae}rdXel, a tool for symbolic reasoning in the domain of Danish\ntraffic law. f{\\ae}rdXel combines techniques from logic programming with a\nnovel interface that allows users to navigate through its reasoning process,\nthereby ensuring the system's trustworthiness. A preliminary empirical\nevaluation indicates that this work is seen as very promising, and has the\npotential to become a foundation for real-world AI tools supporting\nprofessionals in the Danish legal sector.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03560v1",
    "published_date": "2024-10-04 16:07:36 UTC",
    "updated_date": "2024-10-04 16:07:36 UTC"
  },
  {
    "arxiv_id": "2410.03558v3",
    "title": "Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features",
    "authors": [
      "Benyuan Meng",
      "Qianqian Xu",
      "Zitai Wang",
      "Xiaochun Cao",
      "Qingming Huang"
    ],
    "abstract": "Diffusion models are initially designed for image generation. Recent research\nshows that the internal signals within their backbones, named activations, can\nalso serve as dense features for various discriminative tasks such as semantic\nsegmentation. Given numerous activations, selecting a small yet effective\nsubset poses a fundamental problem. To this end, the early study of this field\nperforms a large-scale quantitative comparison of the discriminative ability of\nthe activations. However, we find that many potential activations have not been\nevaluated, such as the queries and keys used to compute attention scores.\nMoreover, recent advancements in diffusion architectures bring many new\nactivations, such as those within embedded ViT modules. Both combined,\nactivation selection remains unresolved but overlooked. To tackle this issue,\nthis paper takes a further step with a much broader range of activations\nevaluated. Considering the significant increase in activations, a full-scale\nquantitative comparison is no longer operational. Instead, we seek to\nunderstand the properties of these activations, such that the activations that\nare clearly inferior can be filtered out in advance via simple qualitative\nevaluation. After careful analysis, we discover three properties universal\namong diffusion models, enabling this study to go beyond specific models. On\ntop of this, we present effective feature selection solutions for several\npopular diffusion models. Finally, the experiments across multiple\ndiscriminative tasks validate the superiority of our method over the SOTA\ncompetitors. Our code is available at\nhttps://github.com/Darkbblue/generic-diffusion-feature.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03558v3",
    "published_date": "2024-10-04 16:05:14 UTC",
    "updated_date": "2024-10-18 06:19:45 UTC"
  },
  {
    "arxiv_id": "2410.14697v2",
    "title": "Learning Cortico-Muscular Dependence through Orthonormal Decomposition of Density Ratios",
    "authors": [
      "Shihan Ma",
      "Bo Hu",
      "Tianyu Jia",
      "Alexander Kenneth Clarke",
      "Blanka Zicher",
      "Arnault H. Caillet",
      "Dario Farina",
      "Jose C. Principe"
    ],
    "abstract": "The cortico-spinal neural pathway is fundamental for motor control and\nmovement execution, and in humans it is typically studied using concurrent\nelectroencephalography (EEG) and electromyography (EMG) recordings. However,\ncurrent approaches for capturing high-level and contextual connectivity between\nthese recordings have important limitations. Here, we present a novel\napplication of statistical dependence estimators based on orthonormal\ndecomposition of density ratios to model the relationship between cortical and\nmuscle oscillations. Our method extends from traditional scalar-valued measures\nby learning eigenvalues, eigenfunctions, and projection spaces of density\nratios from realizations of the signal, addressing the interpretability,\nscalability, and local temporal dependence of cortico-muscular connectivity. We\nexperimentally demonstrate that eigenfunctions learned from cortico-muscular\nconnectivity can accurately classify movements and subjects. Moreover, they\nreveal channel and temporal dependencies that confirm the activation of\nspecific EEG channels during movement. Our code is available at\nhttps://github.com/bohu615/corticomuscular-eigen-encoder.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14697v2",
    "published_date": "2024-10-04 16:05:08 UTC",
    "updated_date": "2024-12-19 22:44:23 UTC"
  },
  {
    "arxiv_id": "2410.14696v1",
    "title": "REBIND: Enhancing ground-state molecular conformation via force-based graph rewiring",
    "authors": [
      "Taewon Kim",
      "Hyunjin Seo",
      "Sungsoo Ahn",
      "Eunho Yang"
    ],
    "abstract": "Predicting the ground-state 3D molecular conformations from 2D molecular\ngraphs is critical in computational chemistry due to its profound impact on\nmolecular properties. Deep learning (DL) approaches have recently emerged as\npromising alternatives to computationally-heavy classical methods such as\ndensity functional theory (DFT). However, we discover that existing DL methods\ninadequately model inter-atomic forces, particularly for non-bonded atomic\npairs, due to their naive usage of bonds and pairwise distances. Consequently,\nsignificant prediction errors occur for atoms with low degree (i.e., low\ncoordination numbers) whose conformations are primarily influenced by\nnon-bonded interactions. To address this, we propose REBIND, a novel framework\nthat rewires molecular graphs by adding edges based on the Lennard-Jones\npotential to capture non-bonded interactions for low-degree atoms. Experimental\nresults demonstrate that REBIND significantly outperforms state-of-the-art\nmethods across various molecular sizes, achieving up to a 20\\% reduction in\nprediction error.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "17 pages, 4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.14696v1",
    "published_date": "2024-10-04 16:02:33 UTC",
    "updated_date": "2024-10-04 16:02:33 UTC"
  },
  {
    "arxiv_id": "2410.03537v2",
    "title": "Ward: Provable RAG Dataset Inference via LLM Watermarks",
    "authors": [
      "Nikola Jovanović",
      "Robin Staab",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "abstract": "RAG enables LLMs to easily incorporate external data, raising concerns for\ndata owners regarding unauthorized usage of their content. The challenge of\ndetecting such unauthorized usage remains underexplored, with datasets and\nmethods from adjacent fields being ill-suited for its study. We take several\nsteps to bridge this gap. First, we formalize this problem as (black-box) RAG\nDataset Inference (RAG-DI). We then introduce a novel dataset designed for\nrealistic benchmarking of RAG-DI methods, alongside a set of baselines.\nFinally, we propose Ward, a method for RAG-DI based on LLM watermarks that\nequips data owners with rigorous statistical guarantees regarding their\ndataset's misuse in RAG corpora. Ward consistently outperforms all baselines,\nachieving higher accuracy, superior query efficiency and robustness. Our work\nprovides a foundation for future studies of RAG-DI and highlights LLM\nwatermarks as a promising approach to this problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03537v2",
    "published_date": "2024-10-04 15:54:49 UTC",
    "updated_date": "2025-02-25 16:22:44 UTC"
  },
  {
    "arxiv_id": "2410.03531v1",
    "title": "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction",
    "authors": [
      "Han Jiang",
      "Junwen Duan",
      "Zhe Qu",
      "Jianxin Wang"
    ],
    "abstract": "Unsupervised rationale extraction aims to extract text snippets to support\nmodel predictions without explicit rationale annotation. Researchers have made\nmany efforts to solve this task. Previous works often encode each aspect\nindependently, which may limit their ability to capture meaningful internal\ncorrelations between aspects. While there has been significant work on\nmitigating spurious correlations, our approach focuses on leveraging the\nbeneficial internal correlations to improve multi-aspect rationale extraction.\nIn this paper, we propose a Multi-Aspect Rationale Extractor (MARE) to explain\nand predict multiple aspects simultaneously. Concretely, we propose a\nMulti-Aspect Multi-Head Attention (MAMHA) mechanism based on hard deletion to\nencode multiple text chunks simultaneously. Furthermore, multiple special\ntokens are prepended in front of the text with each corresponding to one\ncertain aspect. Finally, multi-task training is deployed to reduce the training\noverhead. Experimental results on two unsupervised rationale extraction\nbenchmarks show that MARE achieves state-of-the-art performance. Ablation\nstudies further demonstrate the effectiveness of our method. Our codes have\nbeen available at https://github.com/CSU-NLP-Group/MARE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in EMNLP2024(Main) conference",
    "pdf_url": "http://arxiv.org/pdf/2410.03531v1",
    "published_date": "2024-10-04 15:52:29 UTC",
    "updated_date": "2024-10-04 15:52:29 UTC"
  },
  {
    "arxiv_id": "2410.03523v6",
    "title": "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models",
    "authors": [
      "Yan Scholten",
      "Stephan Günnemann",
      "Leo Schwinn"
    ],
    "abstract": "Comprehensive evaluation of Large Language Models (LLMs) is an open research\nproblem. Existing evaluations rely on deterministic point estimates generated\nvia greedy decoding. However, we find that deterministic evaluations fail to\ncapture the whole output distribution of a model, yielding inaccurate\nestimations of model capabilities. This is particularly problematic in critical\ncontexts such as unlearning and alignment, where precise model evaluations are\ncrucial. To remedy this, we introduce the first formal probabilistic evaluation\nframework for LLMs. Namely, we propose novel metrics with high probability\nguarantees concerning the output distribution of a model. Our metrics are\napplication-independent and allow practitioners to make more reliable estimates\nabout model capabilities before deployment. Our experimental analysis reveals\nthat deterministic evaluations falsely indicate successful unlearning and\nalignment, whereas our probabilistic evaluations better capture model\ncapabilities. We show how to overcome challenges associated with probabilistic\noutputs in a case study on unlearning by introducing (1) a novel loss based on\nentropy optimization, and (2) adaptive temperature scaling. We demonstrate that\nour approach significantly enhances unlearning in probabilistic settings on\nrecent benchmarks. Overall, our proposed shift from point estimates to\nprobabilistic evaluations of output distributions represents an important step\ntoward comprehensive evaluations of LLMs. Code available at\nhttps://www.cs.cit.tum.de/daml/probabilistic-unlearning/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2410.03523v6",
    "published_date": "2024-10-04 15:44:23 UTC",
    "updated_date": "2025-03-01 11:51:16 UTC"
  },
  {
    "arxiv_id": "2410.03499v1",
    "title": "FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator",
    "authors": [
      "Sunny Gupta",
      "Nikita Jangid",
      "Amit Sethi"
    ],
    "abstract": "Federated Learning (FL) facilitates data privacy by enabling collaborative\nin-situ training across decentralized clients. Despite its inherent advantages,\nFL faces significant challenges of performance and convergence when dealing\nwith data that is not independently and identically distributed (non-i.i.d.).\nWhile previous research has primarily addressed the issue of skewed label\ndistribution across clients, this study focuses on the less explored challenge\nof multi-domain FL, where client data originates from distinct domains with\nvarying feature distributions. We introduce a novel method designed to address\nthese challenges FedStein: Enhancing Multi-Domain Federated Learning Through\nthe James-Stein Estimator. FedStein uniquely shares only the James-Stein (JS)\nestimates of batch normalization (BN) statistics across clients, while\nmaintaining local BN parameters. The non-BN layer parameters are exchanged via\nstandard FL techniques. Extensive experiments conducted across three datasets\nand multiple models demonstrate that FedStein surpasses existing methods such\nas FedAvg and FedBN, with accuracy improvements exceeding 14% in certain\ndomains leading to enhanced domain generalization. The code is available at\nhttps://github.com/sunnyinAI/FedStein",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 2 figures. Accepted at International Workshop on Federated\n  Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)",
    "pdf_url": "http://arxiv.org/pdf/2410.03499v1",
    "published_date": "2024-10-04 15:13:31 UTC",
    "updated_date": "2024-10-04 15:13:31 UTC"
  },
  {
    "arxiv_id": "2410.03494v1",
    "title": "Generative Artificial Intelligence for Navigating Synthesizable Chemical Space",
    "authors": [
      "Wenhao Gao",
      "Shitong Luo",
      "Connor W. Coley"
    ],
    "abstract": "We introduce SynFormer, a generative modeling framework designed to\nefficiently explore and navigate synthesizable chemical space. Unlike\ntraditional molecular generation approaches, we generate synthetic pathways for\nmolecules to ensure that designs are synthetically tractable. By incorporating\na scalable transformer architecture and a diffusion module for building block\nselection, SynFormer surpasses existing models in synthesizable molecular\ndesign. We demonstrate SynFormer's effectiveness in two key applications: (1)\nlocal chemical space exploration, where the model generates synthesizable\nanalogs of a reference molecule, and (2) global chemical space exploration,\nwhere the model aims to identify optimal molecules according to a black-box\nproperty prediction oracle. Additionally, we demonstrate the scalability of our\napproach via the improvement in performance as more computational resources\nbecome available. With our code and trained models openly available, we hope\nthat SynFormer will find use across applications in drug discovery and\nmaterials science.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03494v1",
    "published_date": "2024-10-04 15:09:05 UTC",
    "updated_date": "2024-10-04 15:09:05 UTC"
  },
  {
    "arxiv_id": "2410.03489v2",
    "title": "Gradient-based Jailbreak Images for Multimodal Fusion Models",
    "authors": [
      "Javier Rando",
      "Hannah Korevaar",
      "Erik Brinkman",
      "Ivan Evtimov",
      "Florian Tramèr"
    ],
    "abstract": "Augmenting language models with image inputs may enable more effective\njailbreak attacks through continuous optimization, unlike text inputs that\nrequire discrete optimization. However, new multimodal fusion models tokenize\nall input modalities using non-differentiable functions, which hinders\nstraightforward attacks. In this work, we introduce the notion of a tokenizer\nshortcut that approximates tokenization with a continuous function and enables\ncontinuous optimization. We use tokenizer shortcuts to create the first\nend-to-end gradient image attacks against multimodal fusion models. We evaluate\nour attacks on Chameleon models and obtain jailbreak images that elicit harmful\ninformation for 72.5% of prompts. Jailbreak images outperform text jailbreaks\noptimized with the same objective and require 3x lower compute budget to\noptimize 50x more input tokens. Finally, we find that representation\nengineering defenses, like Circuit Breakers, trained only on text attacks can\neffectively transfer to adversarial image inputs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03489v2",
    "published_date": "2024-10-04 14:59:39 UTC",
    "updated_date": "2024-10-23 13:38:29 UTC"
  },
  {
    "arxiv_id": "2410.03487v1",
    "title": "A Multimodal Framework for Deepfake Detection",
    "authors": [
      "Kashish Gandhi",
      "Prutha Kulkarni",
      "Taran Shah",
      "Piyush Chaudhari",
      "Meera Narvekar",
      "Kranti Ghag"
    ],
    "abstract": "The rapid advancement of deepfake technology poses a significant threat to\ndigital media integrity. Deepfakes, synthetic media created using AI, can\nconvincingly alter videos and audio to misrepresent reality. This creates risks\nof misinformation, fraud, and severe implications for personal privacy and\nsecurity. Our research addresses the critical issue of deepfakes through an\ninnovative multimodal approach, targeting both visual and auditory elements.\nThis comprehensive strategy recognizes that human perception integrates\nmultiple sensory inputs, particularly visual and auditory information, to form\na complete understanding of media content. For visual analysis, a model that\nemploys advanced feature extraction techniques was developed, extracting nine\ndistinct facial characteristics and then applying various machine learning and\ndeep learning models. For auditory analysis, our model leverages\nmel-spectrogram analysis for feature extraction and then applies various\nmachine learning and deep learningmodels. To achieve a combined analysis, real\nand deepfake audio in the original dataset were swapped for testing purposes\nand ensured balanced samples. Using our proposed models for video and audio\nclassification i.e. Artificial Neural Network and VGG19, the overall sample is\nclassified as deepfake if either component is identified as such. Our\nmultimodal framework combines visual and auditory analyses, yielding an\naccuracy of 94%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 14 figures, Accepted in Journal of Electrical Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.03487v1",
    "published_date": "2024-10-04 14:59:10 UTC",
    "updated_date": "2024-10-04 14:59:10 UTC"
  },
  {
    "arxiv_id": "2410.03474v1",
    "title": "Group Fairness in Peer Review",
    "authors": [
      "Haris Aziz",
      "Evi Micha",
      "Nisarg Shah"
    ],
    "abstract": "Large conferences such as NeurIPS and AAAI serve as crossroads of various AI\nfields, since they attract submissions from a vast number of communities.\nHowever, in some cases, this has resulted in a poor reviewing experience for\nsome communities, whose submissions get assigned to less qualified reviewers\noutside of their communities. An often-advocated solution is to break up any\nsuch large conference into smaller conferences, but this can lead to isolation\nof communities and harm interdisciplinary research. We tackle this challenge by\nintroducing a notion of group fairness, called the core, which requires that\nevery possible community (subset of researchers) to be treated in a way that\nprevents them from unilaterally benefiting by withdrawing from a large\nconference.\n  We study a simple peer review model, prove that it always admits a reviewing\nassignment in the core, and design an efficient algorithm to find one such\nassignment. We use real data from CVPR and ICLR conferences to compare our\nalgorithm to existing reviewing assignment algorithms on a number of metrics.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.GT",
    "comment": "A preliminary version appeared at NeurIPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2410.03474v1",
    "published_date": "2024-10-04 14:48:10 UTC",
    "updated_date": "2024-10-04 14:48:10 UTC"
  },
  {
    "arxiv_id": "2410.03470v1",
    "title": "Vulnerability Detection via Topological Analysis of Attention Maps",
    "authors": [
      "Pavel Snopov",
      "Andrey Nikolaevich Golubinskiy"
    ],
    "abstract": "Recently, deep learning (DL) approaches to vulnerability detection have\ngained significant traction. These methods demonstrate promising results, often\nsurpassing traditional static code analysis tools in effectiveness.\n  In this study, we explore a novel approach to vulnerability detection\nutilizing the tools from topological data analysis (TDA) on the attention\nmatrices of the BERT model. Our findings reveal that traditional machine\nlearning (ML) techniques, when trained on the topological features extracted\nfrom these attention matrices, can perform competitively with pre-trained\nlanguage models (LLMs) such as CodeBERTa. This suggests that TDA tools,\nincluding persistent homology, are capable of effectively capturing semantic\ninformation critical for identifying vulnerabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ITaS2024. Contains 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03470v1",
    "published_date": "2024-10-04 14:40:11 UTC",
    "updated_date": "2024-10-04 14:40:11 UTC"
  },
  {
    "arxiv_id": "2410.03463v5",
    "title": "Diffusion State-Guided Projected Gradient for Inverse Problems",
    "authors": [
      "Rayhan Zirvi",
      "Bahareh Tolooshams",
      "Anima Anandkumar"
    ],
    "abstract": "Recent advancements in diffusion models have been effective in learning data\npriors for solving inverse problems. They leverage diffusion sampling steps for\ninducing a data prior while using a measurement guidance gradient at each step\nto impose data consistency. For general inverse problems, approximations are\nneeded when an unconditionally trained diffusion model is used since the\nmeasurement likelihood is intractable, leading to inaccurate posterior\nsampling. In other words, due to their approximations, these methods fail to\npreserve the generation process on the data manifold defined by the diffusion\nprior, leading to artifacts in applications such as image restoration. To\nenhance the performance and robustness of diffusion models in solving inverse\nproblems, we propose Diffusion State-Guided Projected Gradient (DiffStateGrad),\nwhich projects the measurement gradient onto a subspace that is a low-rank\napproximation of an intermediate state of the diffusion process. DiffStateGrad,\nas a module, can be added to a wide range of diffusion-based inverse solvers to\nimprove the preservation of the diffusion process on the prior manifold and\nfilter out artifact-inducing components. We highlight that DiffStateGrad\nimproves the robustness of diffusion models in terms of the choice of\nmeasurement guidance step size and noise while improving the worst-case\nperformance. Finally, we demonstrate that DiffStateGrad improves upon the\nstate-of-the-art on linear and nonlinear image restoration inverse problems.\nOur code is available at https://github.com/Anima-Lab/DiffStateGrad.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025. RZ and BT have equal\n  contributions",
    "pdf_url": "http://arxiv.org/pdf/2410.03463v5",
    "published_date": "2024-10-04 14:26:54 UTC",
    "updated_date": "2025-04-01 04:08:13 UTC"
  },
  {
    "arxiv_id": "2410.03448v2",
    "title": "\"Cold, Calculated, and Condescending\": How AI Identifies and Explains Ableism Compared to Disabled People",
    "authors": [
      "Mahika Phutane",
      "Ananya Seelam",
      "Aditya Vashistha"
    ],
    "abstract": "People with disabilities (PwD) regularly encounter ableist hate and\nmicroaggressions online. These spaces are generally moderated by machine\nlearning models, but little is known about how effectively AI models identify\nableist speech and how well their judgments align with PwD. To investigate\nthis, we curated a first-of-its-kind dataset of 200 social media comments\ntargeted towards PwD, and prompted state-of-the art AI models (i.e., Toxicity\nClassifiers, LLMs) to score toxicity and ableism for each comment, and explain\ntheir reasoning. Then, we recruited 190 participants to similarly rate and\nexplain the harm, and evaluate LLM explanations. Our mixed-methods analysis\nhighlighted a major disconnect: AI underestimated toxicity compared to PwD\nratings, while its ableism assessments were sporadic and varied. Although LLMs\nidentified some biases, its explanations were flawed--they lacked nuance, made\nincorrect assumptions, and appeared judgmental instead of educational. Going\nforward, we discuss challenges and opportunities in designing moderation\nsystems for ableism, and advocate for the involvement of intersectional\ndisabled perspectives in AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03448v2",
    "published_date": "2024-10-04 14:09:12 UTC",
    "updated_date": "2025-01-31 04:48:29 UTC"
  },
  {
    "arxiv_id": "2410.03446v1",
    "title": "On Uncertainty In Natural Language Processing",
    "authors": [
      "Dennis Ulmer"
    ],
    "abstract": "The last decade in deep learning has brought on increasingly capable systems\nthat are deployed on a wide variety of applications. In natural language\nprocessing, the field has been transformed by a number of breakthroughs\nincluding large language models, which are used in increasingly many\nuser-facing applications. In order to reap the benefits of this technology and\nreduce potential harms, it is important to quantify the reliability of model\npredictions and the uncertainties that shroud their development.\n  This thesis studies how uncertainty in natural language processing can be\ncharacterized from a linguistic, statistical and neural perspective, and how it\ncan be reduced and quantified through the design of the experimental pipeline.\nWe further explore uncertainty quantification in modeling by theoretically and\nempirically investigating the effect of inductive model biases in text\nclassification tasks. The corresponding experiments include data for three\ndifferent languages (Danish, English and Finnish) and tasks as well as a large\nset of different uncertainty quantification approaches. Additionally, we\npropose a method for calibrated sampling in natural language generation based\non non-exchangeable conformal prediction, which provides tighter token sets\nwith better coverage of the actual continuation. Lastly, we develop an approach\nto quantify confidence in large black-box language models using auxiliary\npredictors, where the confidence is predicted from the input to and generated\noutput text of the target model alone.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.03446v1",
    "published_date": "2024-10-04 14:08:02 UTC",
    "updated_date": "2024-10-04 14:08:02 UTC"
  },
  {
    "arxiv_id": "2410.03440v1",
    "title": "Exploring the Benefit of Activation Sparsity in Pre-training",
    "authors": [
      "Zhengyan Zhang",
      "Chaojun Xiao",
      "Qiujieli Qin",
      "Yankai Lin",
      "Zhiyuan Zeng",
      "Xu Han",
      "Zhiyuan Liu",
      "Ruobing Xie",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "abstract": "Pre-trained Transformers inherently possess the characteristic of sparse\nactivation, where only a small fraction of the neurons are activated for each\ntoken. While sparse activation has been explored through post-training methods,\nits potential in pre-training remains untapped. In this work, we first study\nhow activation properties change during pre-training. Our examination reveals\nthat Transformers exhibit sparse activation throughout the majority of the\npre-training process while the activation correlation keeps evolving as\ntraining progresses. Leveraging this observation, we propose Switchable\nSparse-Dense Learning (SSD). SSD adaptively switches between the\nMixtures-of-Experts (MoE) based sparse training and the conventional dense\ntraining during the pre-training process, leveraging the efficiency of sparse\ntraining and avoiding the static activation correlation of sparse training.\nCompared to dense training, SSD achieves comparable performance with identical\nmodel size and reduces pre-training costs. Moreover, the models trained with\nSSD can be directly used as MoE models for sparse inference and achieve the\nsame performance as dense models with up to $2\\times$ faster inference speed.\nCodes are available at https://github.com/thunlp/moefication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03440v1",
    "published_date": "2024-10-04 13:53:33 UTC",
    "updated_date": "2024-10-04 13:53:33 UTC"
  },
  {
    "arxiv_id": "2410.03435v1",
    "title": "A General Framework for Producing Interpretable Semantic Text Embeddings",
    "authors": [
      "Yiqun Sun",
      "Qiang Huang",
      "Yixuan Tang",
      "Anthony K. H. Tung",
      "Jun Yu"
    ],
    "abstract": "Semantic text embedding is essential to many tasks in Natural Language\nProcessing (NLP). While black-box models are capable of generating high-quality\nembeddings, their lack of interpretability limits their use in tasks that\ndemand transparency. Recent approaches have improved interpretability by\nleveraging domain-expert-crafted or LLM-generated questions, but these methods\nrely heavily on expert input or well-prompt design, which restricts their\ngeneralizability and ability to generate discriminative questions across a wide\nrange of tasks. To address these challenges, we introduce \\algo{CQG-MBQA}\n(Contrastive Question Generation - Multi-task Binary Question Answering), a\ngeneral framework for producing interpretable semantic text embeddings across\ndiverse tasks. Our framework systematically generates highly discriminative,\nlow cognitive load yes/no questions through the \\algo{CQG} method and answers\nthem efficiently with the \\algo{MBQA} model, resulting in interpretable\nembeddings in a cost-effective manner. We validate the effectiveness and\ninterpretability of \\algo{CQG-MBQA} through extensive experiments and ablation\nstudies, demonstrating that it delivers embedding quality comparable to many\nadvanced black-box models while maintaining inherently interpretability.\nAdditionally, \\algo{CQG-MBQA} outperforms other interpretable text embedding\nmethods across various downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 5 figures, and 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.03435v1",
    "published_date": "2024-10-04 13:51:19 UTC",
    "updated_date": "2024-10-04 13:51:19 UTC"
  },
  {
    "arxiv_id": "2410.03434v1",
    "title": "Self-supervised Spatio-Temporal Graph Mask-Passing Attention Network for Perceptual Importance Prediction of Multi-point Tactility",
    "authors": [
      "Dazhong He",
      "Qian Liu"
    ],
    "abstract": "While visual and auditory information are prevalent in modern multimedia\nsystems, haptic interaction, e.g., tactile and kinesthetic interaction,\nprovides a unique form of human perception. However, multimedia technology for\ncontact interaction is less mature than non-contact multimedia technologies and\nrequires further development. Specialized haptic media technologies, requiring\nlow latency and bitrates, are essential to enable haptic interaction,\nnecessitating haptic information compression. Existing vibrotactile signal\ncompression methods, based on the perceptual model, do not consider the\ncharacteristics of fused tactile perception at multiple spatially distributed\ninteraction points. In fact, differences in tactile perceptual importance are\nnot limited to conventional frequency and time domains, but also encompass\ndifferences in the spatial locations on the skin unique to tactile perception.\nFor the most frequently used tactile information, vibrotactile texture\nperception, we have developed a model to predict its perceptual importance at\nmultiple points, based on self-supervised learning and Spatio-Temporal Graph\nNeural Network. Current experimental results indicate that this model can\neffectively predict the perceptual importance of various points in multi-point\ntactile perception scenarios.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "Published as a conference paper at Eurohaptics 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03434v1",
    "published_date": "2024-10-04 13:45:50 UTC",
    "updated_date": "2024-10-04 13:45:50 UTC"
  },
  {
    "arxiv_id": "2410.03432v1",
    "title": "EB-NeRD: A Large-Scale Dataset for News Recommendation",
    "authors": [
      "Johannes Kruse",
      "Kasper Lindskow",
      "Saikishore Kalloori",
      "Marco Polignano",
      "Claudio Pomo",
      "Abhishek Srivastava",
      "Anshuk Uppal",
      "Michael Riis Andersen",
      "Jes Frellsen"
    ],
    "abstract": "Personalized content recommendations have been pivotal to the content\nexperience in digital media from video streaming to social networks. However,\nseveral domain specific challenges have held back adoption of recommender\nsystems in news publishing. To address these challenges, we introduce the\nEkstra Bladet News Recommendation Dataset (EB-NeRD). The dataset encompasses\ndata from over a million unique users and more than 37 million impression logs\nfrom Ekstra Bladet. It also includes a collection of over 125,000 Danish news\narticles, complete with titles, abstracts, bodies, and metadata, such as\ncategories. EB-NeRD served as the benchmark dataset for the RecSys '24\nChallenge, where it was demonstrated how the dataset can be used to address\nboth technical and normative challenges in designing effective and responsible\nrecommender systems for news publishing. The dataset is available at:\nhttps://recsys.eb.dk.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 8 tables, 2 figures, RecSys '24",
    "pdf_url": "http://arxiv.org/pdf/2410.03432v1",
    "published_date": "2024-10-04 13:43:29 UTC",
    "updated_date": "2024-10-04 13:43:29 UTC"
  },
  {
    "arxiv_id": "2410.03424v2",
    "title": "Cayley Graph Propagation",
    "authors": [
      "JJ Wilson",
      "Maya Bechler-Speicher",
      "Petar Veličković"
    ],
    "abstract": "In spite of the plethora of success stories with graph neural networks (GNNs)\non modelling graph-structured data, they are notoriously vulnerable to\nover-squashing, whereby tasks necessitate the mixing of information between\ndistance pairs of nodes. To address this problem, prior work suggests rewiring\nthe graph structure to improve information flow. Alternatively, a significant\nbody of research has dedicated itself to discovering and precomputing\nbottleneck-free graph structures to ameliorate over-squashing. One well\nregarded family of bottleneck-free graphs within the mathematical community are\nexpander graphs, with prior work -- Expander Graph Propagation (EGP) --\nproposing the use of a well-known expander graph family -- the Cayley graphs of\nthe $\\mathrm{SL}(2,\\mathbb{Z}_n)$ special linear group -- as a computational\ntemplate for GNNs. However, in EGP the computational graphs used are truncated\nto align with a given input graph. In this work, we show that truncation is\ndetrimental to the coveted expansion properties. Instead, we propose CGP, a\nmethod to propagate information over a complete Cayley graph structure, thereby\nensuring it is bottleneck-free to better alleviate over-squashing. Our\nempirical evidence across several real-world datasets not only shows that CGP\nrecovers significant improvements as compared to EGP, but it is also akin to or\noutperforms computationally complex graph rewiring techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the Third Learning on Graphs Conference (LoG 2024),\n  PMLR 269. 20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03424v2",
    "published_date": "2024-10-04 13:32:34 UTC",
    "updated_date": "2025-05-19 17:39:17 UTC"
  },
  {
    "arxiv_id": "2410.03810v1",
    "title": "Can Mamba Always Enjoy the \"Free Lunch\"?",
    "authors": [
      "Ruifeng Ren",
      "Zhicong Li",
      "Yong Liu"
    ],
    "abstract": "Transformers have been the cornerstone of current Large Language Models\n(LLMs); however, its linear growth in overhead during inference with respect to\nsequence length poses challenges for modeling long sequences. In this context,\nMamba has gradually attracted attention due to its constant-level size during\ninference and existing empirical results have shown that it can perform\ncomparably to Transformers in sequence modeling while offering significant\nsavings. However, one may ask that, can Mamba always enjoy the ``free lunch\"?\nIn this paper, we focus on analyzing the expressive ability of Mamba from a\ntheoretical standpoint. First, inspired by the connection between Mamba and\nlinear attention, we investigate potential shortcomings of the Mamba when\nperforming the COPY operation. Our results indicate that Mamba with constant\nsize may encounter bottlenecks when handling COPY, while it can achieve perfect\nperformance when the size scales linearly with sequence length. Based on this\nobservation, we analyze Mamba's ability to tackle DP problems when equipped\nwith Chain of Thought (CoT). Our findings suggest that to solve arbitrary DP\nproblems, the total cost of Mamba is comparable to standard and efficient\nTransformers. However, similar to efficient Transformers, when facing DP\nproblems with favorable properties such as locality, Mamba can provide savings\nin overhead. Our results contribute to a deeper understanding of Mamba.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03810v1",
    "published_date": "2024-10-04 13:31:24 UTC",
    "updated_date": "2024-10-04 13:31:24 UTC"
  },
  {
    "arxiv_id": "2410.03421v2",
    "title": "One2set + Large Language Model: Best Partners for Keyphrase Generation",
    "authors": [
      "Liangying Shao",
      "Liang Zhang",
      "Minlong Peng",
      "Guoqi Ma",
      "Hao Yue",
      "Mingming Sun",
      "Jinsong Su"
    ],
    "abstract": "Keyphrase generation (KPG) aims to automatically generate a collection of\nphrases representing the core concepts of a given document. The dominant\nparadigms in KPG include one2seq and one2set. Recently, there has been\nincreasing interest in applying large language models (LLMs) to KPG. Our\npreliminary experiments reveal that it is challenging for a single model to\nexcel in both recall and precision. Further analysis shows that: 1) the one2set\nparadigm owns the advantage of high recall, but suffers from improper\nassignments of supervision signals during training; 2) LLMs are powerful in\nkeyphrase selection, but existing selection methods often make redundant\nselections. Given these observations, we introduce a generate-then-select\nframework decomposing KPG into two steps, where we adopt a one2set-based model\nas generator to produce candidates and then use an LLM as selector to select\nkeyphrases from these candidates. Particularly, we make two important\nimprovements on our generator and selector: 1) we design an Optimal\nTransport-based assignment strategy to address the above improper assignments;\n2) we model the keyphrase selection as a sequence labeling task to alleviate\nredundant selections. Experimental results on multiple benchmark datasets show\nthat our framework significantly surpasses state-of-the-art models, especially\nin absent keyphrase prediction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.03421v2",
    "published_date": "2024-10-04 13:31:09 UTC",
    "updated_date": "2024-10-21 02:43:50 UTC"
  },
  {
    "arxiv_id": "2410.03420v2",
    "title": "Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery",
    "authors": [
      "Karl-Philippe Beaudet",
      "Alexandros Karargyris",
      "Sidaty El Hadramy",
      "Stéphane Cotin",
      "Jean-Paul Mazellier",
      "Nicolas Padoy",
      "Juan Verde"
    ],
    "abstract": "While laparoscopic liver resection is less prone to complications and\nmaintains patient outcomes compared to traditional open surgery, its complexity\nhinders widespread adoption due to challenges in representing the liver's\ninternal structure. Laparoscopic intraoperative ultrasound offers efficient,\ncost-effective and radiation-free guidance. Our objective is to aid physicians\nin identifying internal liver structures using laparoscopic intraoperative\nultrasound. We propose a patient-specific approach using preoperative 3D\nultrasound liver volume to train a deep learning model for real-time\nidentification of portal tree and branch structures. Our personalized AI model,\nvalidated on ex vivo swine livers, achieved superior precision (0.95) and\nrecall (0.93) compared to surgeons, laying groundwork for precise vessel\nidentification in ultrasound-based liver resection. Its adaptability and\npotential clinical impact promise to advance surgical interventions and improve\npatient care.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03420v2",
    "published_date": "2024-10-04 13:30:18 UTC",
    "updated_date": "2024-10-08 09:44:34 UTC"
  },
  {
    "arxiv_id": "2410.03409v1",
    "title": "Comparative study of regression vs pairwise models for surrogate-based heuristic optimisation",
    "authors": [
      "Pablo S. Naharro",
      "Pablo Toharia",
      "Antonio LaTorre",
      "José-María Peña"
    ],
    "abstract": "Heuristic optimisation algorithms explore the search space by sampling\nsolutions, evaluating their fitness, and biasing the search in the direction of\npromising solutions. However, in many cases, this fitness function involves\nexecuting expensive computational calculations, drastically reducing the\nreasonable number of evaluations. In this context, surrogate models have\nemerged as an excellent alternative to alleviate these computational problems.\nThis paper addresses the formulation of surrogate problems as both regression\nmodels that approximate fitness (surface surrogate models) and a novel way to\nconnect classification models (pairwise surrogate models). The pairwise\napproach can be directly exploited by some algorithms, such as Differential\nEvolution, in which the fitness value is not actually needed to drive the\nsearch, and it is sufficient to know whether a solution is better than another\none or not. Based on these modelling approaches, we have conducted a\nmultidimensional analysis of surrogate models under different configurations:\ndifferent machine learning algorithms (regularised regression, neural networks,\ndecision trees, boosting methods, and random forests), different surrogate\nstrategies (encouraging diversity or relaxing prediction thresholds), and\ncompare them for both surface and pairwise surrogate models. The experimental\npart of the article includes the benchmark problems already proposed for the\nSOCO2011 competition in continuous optimisation and a simulation problem\nincluded in the recent GECCO2021 Industrial Challenge. This paper shows that\nthe performance of the overall search, when using online machine learning-based\nsurrogate models, depends not only on the accuracy of the predictive model but\nalso on both the kind of bias towards positive or negative cases and how the\noptimisation uses those predictions to decide whether to execute the actual\nfitness function.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03409v1",
    "published_date": "2024-10-04 13:19:06 UTC",
    "updated_date": "2024-10-04 13:19:06 UTC"
  },
  {
    "arxiv_id": "2410.03399v2",
    "title": "EBES: Easy Benchmarking for Event Sequences",
    "authors": [
      "Dmitry Osin",
      "Igor Udovichenko",
      "Viktor Moskvoretskii",
      "Egor Shvetsov",
      "Evgeny Burnaev"
    ],
    "abstract": "Event Sequences (EvS) refer to sequential data characterized by irregular\nsampling intervals and a mix of categorical and numerical features. Accurate\nclassification of these sequences is crucial for various real-life\napplications, including healthcare, finance, and user interaction. Despite the\npopularity of the EvS classification task, there is currently no standardized\nbenchmark or rigorous evaluation protocol. This lack of standardization makes\nit difficult to compare results across studies, which can result in unreliable\nconclusions and hinder progress in the field. To address this gap, we present\nEBES, a comprehensive benchmark for EvS classification with sequence-level\ntargets. EBES features standardized evaluation scenarios and protocols, along\nwith an open-source PyTorch library that implements 9 modern models.\nAdditionally, it includes the largest collection of EvS datasets, featuring 10\ncurated datasets, including a novel synthetic dataset and real-world data with\nthe largest publicly available banking dataset. The library offers\nuser-friendly interfaces for integrating new methods and datasets. Our\nbenchmarking results highlight the unique properties of EvS compared to other\nsequential data types, provide a performance ranking of modern models with\nGRU-based models achieving the best results and reveal the challenges\nassociated with robust EvS learning. The goal of EBES is to facilitate\nreproducible research, expedite progress in the field, and increase the\nreal-world impact of EvS classification techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03399v2",
    "published_date": "2024-10-04 13:03:43 UTC",
    "updated_date": "2025-02-25 20:02:47 UTC"
  },
  {
    "arxiv_id": "2410.03396v1",
    "title": "GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction",
    "authors": [
      "Shijin Duan",
      "Ruyi Ding",
      "Jiaxing He",
      "Aidong Adam Ding",
      "Yunsi Fei",
      "Xiaolin Xu"
    ],
    "abstract": "Graph-structured data is integral to many applications, prompting the\ndevelopment of various graph representation methods. Graph autoencoders (GAEs),\nin particular, reconstruct graph structures from node embeddings. Current GAE\nmodels primarily utilize self-correlation to represent graph structures and\nfocus on node-level tasks, often overlooking multi-graph scenarios. Our\ntheoretical analysis indicates that self-correlation generally falls short in\naccurately representing specific graph features such as islands, symmetrical\nstructures, and directional edges, particularly in smaller or multiple graph\ncontexts. To address these limitations, we introduce a cross-correlation\nmechanism that significantly enhances the GAE representational capabilities.\nAdditionally, we propose GraphCroc, a new GAE that supports flexible encoder\narchitectures tailored for various downstream tasks and ensures robust\nstructural reconstruction, through a mirrored encoding-decoding process. This\nmodel also tackles the challenge of representation bias during optimization by\nimplementing a loss-balancing strategy. Both theoretical analysis and numerical\nevaluations demonstrate that our methodology significantly outperforms existing\nself-correlation-based GAEs in graph structure reconstruction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 16 figures. Accepted in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03396v1",
    "published_date": "2024-10-04 12:59:45 UTC",
    "updated_date": "2024-10-04 12:59:45 UTC"
  },
  {
    "arxiv_id": "2410.03380v2",
    "title": "Identifying perturbation targets through causal differential networks",
    "authors": [
      "Menghua Wu",
      "Umesh Padia",
      "Sean H. Murphy",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "abstract": "Identifying variables responsible for changes to a biological system enables\napplications in drug target discovery and cell engineering. Given a pair of\nobservational and interventional datasets, the goal is to isolate the subset of\nobserved variables that were the targets of the intervention. Directly applying\ncausal discovery algorithms is challenging: the data may contain thousands of\nvariables with as few as tens of samples per intervention, and biological\nsystems do not adhere to classical causality assumptions. We propose a\ncausality-inspired approach to address this practical setting. First, we infer\nnoisy causal graphs from the observational and interventional data. Then, we\nlearn to map the differences between these graphs, along with additional\nstatistical features, to sets of variables that were intervened upon. Both\nmodules are jointly trained in a supervised framework, on simulated and real\ndata that reflect the nature of biological interventions. This approach\nconsistently outperforms baselines for perturbation modeling on seven\nsingle-cell transcriptomics datasets. We also demonstrate significant\nimprovements over current causal discovery methods for predicting soft and hard\nintervention targets across a variety of synthetic data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03380v2",
    "published_date": "2024-10-04 12:48:21 UTC",
    "updated_date": "2025-02-10 16:21:03 UTC"
  },
  {
    "arxiv_id": "2410.03376v1",
    "title": "Mitigating Adversarial Perturbations for Deep Reinforcement Learning via Vector Quantization",
    "authors": [
      "Tung M. Luu",
      "Thanh Nguyen",
      "Tee Joshua Tian Jin",
      "Sungwoon Kim",
      "Chang D. Yoo"
    ],
    "abstract": "Recent studies reveal that well-performing reinforcement learning (RL) agents\nin training often lack resilience against adversarial perturbations during\ndeployment. This highlights the importance of building a robust agent before\ndeploying it in the real world. Most prior works focus on developing robust\ntraining-based procedures to tackle this problem, including enhancing the\nrobustness of the deep neural network component itself or adversarially\ntraining the agent on strong attacks. In this work, we instead study an input\ntransformation-based defense for RL. Specifically, we propose using a variant\nof vector quantization (VQ) as a transformation for input observations, which\nis then used to reduce the space of adversarial attacks during testing,\nresulting in the transformed observations being less affected by attacks. Our\nmethod is computationally efficient and seamlessly integrates with adversarial\ntraining, further enhancing the robustness of RL agents against adversarial\nattacks. Through extensive experiments in multiple environments, we demonstrate\nthat using VQ as the input transformation effectively defends against\nadversarial attacks on the agent's observations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, IROS 2024 (Code: https://github.com/tunglm2203/vq_robust_rl)",
    "pdf_url": "http://arxiv.org/pdf/2410.03376v1",
    "published_date": "2024-10-04 12:41:54 UTC",
    "updated_date": "2024-10-04 12:41:54 UTC"
  },
  {
    "arxiv_id": "2410.03375v1",
    "title": "SoundSignature: What Type of Music Do You Like?",
    "authors": [
      "Brandon James Carone",
      "Pablo Ripollés"
    ],
    "abstract": "SoundSignature is a music application that integrates a custom OpenAI\nAssistant to analyze users' favorite songs. The system incorporates\nstate-of-the-art Music Information Retrieval (MIR) Python packages to combine\nextracted acoustic/musical features with the assistant's extensive knowledge of\nthe artists and bands. Capitalizing on this combined knowledge, SoundSignature\nleverages semantic audio and principles from the emerging Internet of Sounds\n(IoS) ecosystem, integrating MIR with AI to provide users with personalized\ninsights into the acoustic properties of their music, akin to a musical\npreference personality report. Users can then interact with the chatbot to\nexplore deeper inquiries about the acoustic analyses performed and how they\nrelate to their musical taste. This interactivity transforms the application,\nacting not only as an informative resource about familiar and/or favorite\nsongs, but also as an educational platform that enables users to deepen their\nunderstanding of musical features, music theory, acoustic properties commonly\nused in signal processing, and the artists behind the music. Beyond general\nusability, the application also incorporates several well-established\nopen-source musician-specific tools, such as a chord recognition algorithm\n(CREMA), a source separation algorithm (DEMUCS), and an audio-to-MIDI converter\n(basic-pitch). These features allow users without coding skills to access\nadvanced, open-source music processing algorithms simply by interacting with\nthe chatbot (e.g., can you give me the stems of this song?). In this paper, we\nhighlight the application's innovative features and educational potential, and\npresent findings from a pilot user study that evaluates its efficacy and\nusability.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "10 pages, 1 figure, to be published in the 2024 International\n  Symposium on the IEEE Internet of Sounds Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2410.03375v1",
    "published_date": "2024-10-04 12:40:45 UTC",
    "updated_date": "2024-10-04 12:40:45 UTC"
  },
  {
    "arxiv_id": "2410.03373v1",
    "title": "Make Interval Bound Propagation great again",
    "authors": [
      "Patryk Krukowski",
      "Daniel Wilczak",
      "Jacek Tabor",
      "Anna Bielawska",
      "Przemysław Spurek"
    ],
    "abstract": "In various scenarios motivated by real life, such as medical data analysis,\nautonomous driving, and adversarial training, we are interested in robust deep\nnetworks. A network is robust when a relatively small perturbation of the input\ncannot lead to drastic changes in output (like change of class, etc.). This\nfalls under the broader scope field of Neural Network Certification (NNC). Two\ncrucial problems in NNC are of profound interest to the scientific community:\nhow to calculate the robustness of a given pre-trained network and how to\nconstruct robust networks. The common approach to constructing robust networks\nis Interval Bound Propagation (IBP). This paper demonstrates that IBP is\nsub-optimal in the first case due to its susceptibility to the wrapping effect.\nEven for linear activation, IBP gives strongly sub-optimal bounds.\nConsequently, one should use strategies immune to the wrapping effect to obtain\nbounds close to optimal ones. We adapt two classical approaches dedicated to\nstrict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate\nthe wrapping effect in neural networks. These techniques yield precise results\nfor networks with linear activation functions, thus resisting the wrapping\neffect. As a result, we achieve bounds significantly closer to the optimal\nlevel than IBPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03373v1",
    "published_date": "2024-10-04 12:39:46 UTC",
    "updated_date": "2024-10-04 12:39:46 UTC"
  },
  {
    "arxiv_id": "2410.03359v1",
    "title": "An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging",
    "authors": [
      "Bill Cassidy",
      "Christian Mcbride",
      "Connah Kendrick",
      "Neil D. Reeves",
      "Joseph M. Pappachan",
      "Cornelius J. Fernandez",
      "Elias Chacko",
      "Raphael Brüngel",
      "Christoph M. Friedrich",
      "Metib Alotaibi",
      "Abdullah Abdulaziz AlWabel",
      "Mohammad Alderwish",
      "Kuan-Ying Lai",
      "Moi Hoon Yap"
    ],
    "abstract": "Chronic wounds and associated complications present ever growing burdens for\nclinics and hospitals world wide. Venous, arterial, diabetic, and pressure\nwounds are becoming increasingly common globally. These conditions can result\nin highly debilitating repercussions for those affected, with limb amputations\nand increased mortality risk resulting from infection becoming more common. New\nmethods to assist clinicians in chronic wound care are therefore vital to\nmaintain high quality care standards. This paper presents an improved HarDNet\nsegmentation architecture which integrates a contrast-eliminating component in\nthe initial layers of the network to enhance feature learning. We also utilise\na multi-colour space tensor merging process and adjust the harmonic shape of\nthe convolution blocks to facilitate these additional features. We train our\nproposed model using wound images from light-skinned patients and test the\nmodel on two test sets (one set with ground truth, and one without) comprising\nonly darker-skinned cases. Subjective ratings are obtained from clinical wound\nexperts with intraclass correlation coefficient used to determine inter-rater\nreliability. For the dark-skin tone test set with ground truth, we demonstrate\nimprovements in terms of Dice similarity coefficient (+0.1221) and intersection\nover union (+0.1274). Qualitative analysis showed high expert ratings, with\nimprovements of >3% demonstrated when comparing the baseline model with the\nproposed model. This paper presents the first study to focus on darker-skin\ntones for chronic wound segmentation using models trained only on wound images\nexhibiting lighter skin. Diabetes is highly prevalent in countries where\npatients have darker skin tones, highlighting the need for a greater focus on\nsuch cases. Additionally, we conduct the largest qualitative study to date for\nchronic wound segmentation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03359v1",
    "published_date": "2024-10-04 12:26:51 UTC",
    "updated_date": "2024-10-04 12:26:51 UTC"
  },
  {
    "arxiv_id": "2410.05301v2",
    "title": "Diffusion-based Unsupervised Audio-visual Speech Enhancement",
    "authors": [
      "Jean-Eudes Ayilo",
      "Mostafa Sadeghi",
      "Romain Serizel",
      "Xavier Alameda-Pineda"
    ],
    "abstract": "This paper proposes a new unsupervised audio-visual speech enhancement (AVSE)\napproach that combines a diffusion-based audio-visual speech generative model\nwith a non-negative matrix factorization (NMF) noise model. First, the\ndiffusion model is pre-trained on clean speech conditioned on corresponding\nvideo data to simulate the speech generative distribution. This pre-trained\nmodel is then paired with the NMF-based noise model to estimate clean speech\niteratively. Specifically, a diffusion-based posterior sampling approach is\nimplemented within the reverse diffusion process, where after each iteration, a\nspeech estimate is obtained and used to update the noise parameters.\nExperimental results confirm that the proposed AVSE approach not only\noutperforms its audio-only counterpart but also generalizes better than a\nrecent supervised-generative AVSE method. Additionally, the new inference\nalgorithm offers a better balance between inference speed and performance\ncompared to the previous diffusion-based method. Code and demo available at:\nhttps://jeaneudesayilo.github.io/fast_UdiffSE",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05301v2",
    "published_date": "2024-10-04 12:22:54 UTC",
    "updated_date": "2025-01-15 09:42:42 UTC"
  },
  {
    "arxiv_id": "2410.03355v3",
    "title": "LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding",
    "authors": [
      "Doohyuk Jang",
      "Sihwan Park",
      "June Yong Yang",
      "Yeonsung Jung",
      "Jihun Yun",
      "Souvik Kundu",
      "Sung-Yub Kim",
      "Eunho Yang"
    ],
    "abstract": "Auto-Regressive (AR) models have recently gained prominence in image\ngeneration, often matching or even surpassing the performance of diffusion\nmodels. However, one major limitation of AR models is their sequential nature,\nwhich processes tokens one at a time, slowing down generation compared to\nmodels like GANs or diffusion-based methods that operate more efficiently.\nWhile speculative decoding has proven effective for accelerating LLMs by\ngenerating multiple tokens in a single forward, its application in visual AR\nmodels remains largely unexplored. In this work, we identify a challenge in\nthis setting, which we term \\textit{token selection ambiguity}, wherein visual\nAR models frequently assign uniformly low probabilities to tokens, hampering\nthe performance of speculative decoding. To overcome this challenge, we propose\na relaxed acceptance condition referred to as LANTERN that leverages the\ninterchangeability of tokens in latent space. This relaxation restores the\neffectiveness of speculative decoding in visual AR models by enabling more\nflexible use of candidate tokens that would otherwise be prematurely rejected.\nFurthermore, by incorporating a total variation distance bound, we ensure that\nthese speed gains are achieved without significantly compromising image quality\nor semantic coherence. Experimental results demonstrate the efficacy of our\nmethod in providing a substantial speed-up over speculative decoding. In\nspecific, compared to a na\\\"ive application of the state-of-the-art speculative\ndecoding, LANTERN increases speed-ups by $\\mathbf{1.75}\\times$ and\n$\\mathbf{1.82}\\times$, as compared to greedy decoding and random sampling,\nrespectively, when applied to LlamaGen, a contemporary visual AR model. The\ncode is publicly available at https://github.com/jadohu/LANTERN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 13 figures, Accepted to ICLR 2025 (poster)",
    "pdf_url": "http://arxiv.org/pdf/2410.03355v3",
    "published_date": "2024-10-04 12:21:03 UTC",
    "updated_date": "2025-03-02 07:45:09 UTC"
  },
  {
    "arxiv_id": "2410.03334v1",
    "title": "An X-Ray Is Worth 15 Features: Sparse Autoencoders for Interpretable Radiology Report Generation",
    "authors": [
      "Ahmed Abdulaal",
      "Hugo Fry",
      "Nina Montaña-Brown",
      "Ayodeji Ijishakin",
      "Jack Gao",
      "Stephanie Hyland",
      "Daniel C. Alexander",
      "Daniel C. Castro"
    ],
    "abstract": "Radiological services are experiencing unprecedented demand, leading to\nincreased interest in automating radiology report generation. Existing\nVision-Language Models (VLMs) suffer from hallucinations, lack\ninterpretability, and require expensive fine-tuning. We introduce SAE-Rad,\nwhich uses sparse autoencoders (SAEs) to decompose latent representations from\na pre-trained vision transformer into human-interpretable features. Our hybrid\narchitecture combines state-of-the-art SAE advancements, achieving accurate\nlatent reconstructions while maintaining sparsity. Using an off-the-shelf\nlanguage model, we distil ground-truth reports into radiological descriptions\nfor each SAE feature, which we then compile into a full report for each image,\neliminating the need for fine-tuning large models for this task. To the best of\nour knowledge, SAE-Rad represents the first instance of using mechanistic\ninterpretability techniques explicitly for a downstream multi-modal reasoning\ntask. On the MIMIC-CXR dataset, SAE-Rad achieves competitive radiology-specific\nmetrics compared to state-of-the-art models while using significantly fewer\ncomputational resources for training. Qualitative analysis reveals that SAE-Rad\nlearns meaningful visual concepts and generates reports aligning closely with\nexpert interpretations. Our results suggest that SAEs can enhance multimodal\nreasoning in healthcare, providing a more interpretable alternative to existing\nVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03334v1",
    "published_date": "2024-10-04 11:40:21 UTC",
    "updated_date": "2024-10-04 11:40:21 UTC"
  },
  {
    "arxiv_id": "2410.03333v1",
    "title": "Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification",
    "authors": [
      "Gary Murphy",
      "Raghubir Singh"
    ],
    "abstract": "This study introduces a novel and accurate approach to breast cancer\nclassification using histopathology images. It systematically compares leading\nConvolutional Neural Network (CNN) models across varying image datasets,\nidentifies their optimal hyperparameters, and ranks them based on\nclassification efficacy. To maximize classification accuracy for each model we\nexplore, the effects of data augmentation, alternative fully-connected layers,\nmodel training hyperparameter settings, and, the advantages of retraining\nmodels versus using pre-trained weights. Our methodology includes several\noriginal concepts, including serializing generated datasets to ensure\nconsistent data conditions across training runs and significantly reducing\ntraining duration. Combined with automated curation of results, this enabled\nthe exploration of over 2,000 training permutations -- such a comprehensive\ncomparison is as yet unprecedented. Our findings establish the settings\nrequired to achieve exceptional classification accuracy for standalone CNN\nmodels and rank them by model efficacy. Based on these results, we propose\nensemble architectures that stack three high-performing standalone CNN models\ntogether with diverse classifiers, resulting in improved classification\naccuracy. The ability to systematically run so many model permutations to get\nthe best outcomes gives rise to very high quality results, including 99.75% for\nBreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into\ntrain, validation and test datasets. The Bach Online blind challenge, yielded\n89% using this approach. Whilst this study is based on breast cancer\nhistopathology image datasets, the methodology is equally applicable to other\nmedical image datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03333v1",
    "published_date": "2024-10-04 11:31:43 UTC",
    "updated_date": "2024-10-04 11:31:43 UTC"
  },
  {
    "arxiv_id": "2410.03315v1",
    "title": "Influence-oriented Personalized Federated Learning",
    "authors": [
      "Yue Tan",
      "Guodong Long",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Traditional federated learning (FL) methods often rely on fixed weighting for\nparameter aggregation, neglecting the mutual influence by others. Hence, their\neffectiveness in heterogeneous data contexts is limited. To address this\nproblem, we propose an influence-oriented federated learning framework, namely\nFedC^2I, which quantitatively measures Client-level and Class-level Influence\nto realize adaptive parameter aggregation for each client. Our core idea is to\nexplicitly model the inter-client influence within an FL system via the\nwell-crafted influence vector and influence matrix. The influence vector\nquantifies client-level influence, enables clients to selectively acquire\nknowledge from others, and guides the aggregation of feature representation\nlayers. Meanwhile, the influence matrix captures class-level influence in a\nmore fine-grained manner to achieve personalized classifier aggregation. We\nevaluate the performance of FedC^2I against existing federated learning methods\nunder non-IID settings and the results demonstrate the superiority of our\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03315v1",
    "published_date": "2024-10-04 11:00:17 UTC",
    "updated_date": "2024-10-04 11:00:17 UTC"
  },
  {
    "arxiv_id": "2410.03804v2",
    "title": "Mixture of Attentions For Speculative Decoding",
    "authors": [
      "Matthieu Zimmer",
      "Milan Gritta",
      "Gerasimos Lampouras",
      "Haitham Bou Ammar",
      "Jun Wang"
    ],
    "abstract": "The growth in the number of parameters of Large Language Models (LLMs) has\nled to a significant surge in computational requirements, making them\nchallenging and costly to deploy. Speculative decoding (SD) leverages smaller\nmodels to efficiently propose future tokens, which are then verified by the LLM\nin parallel. Small models that utilise activations from the LLM currently\nachieve the fastest decoding speeds. However, we identify several limitations\nof SD models including the lack of on-policyness during training and partial\nobservability. To address these shortcomings, we propose a more grounded\narchitecture for small models by introducing a Mixture of Attentions for SD.\nOur novel architecture can be applied in two scenarios: a conventional single\ndevice deployment and a novel client-server deployment where the small model is\nhosted on a consumer device and the LLM on a server. In a single-device\nscenario, we demonstrate state-of-the-art speedups improving EAGLE-2 by 9.5%\nand its acceptance length by 25%. In a client-server setting, our experiments\ndemonstrate: 1) state-of-the-art latencies with minimal calls to the server for\ndifferent network conditions, and 2) in the event of a complete disconnection,\nour approach can maintain higher accuracy compared to other SD methods and\ndemonstrates advantages over API calls to LLMs, which would otherwise be unable\nto continue the generation process.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.03804v2",
    "published_date": "2024-10-04 10:25:52 UTC",
    "updated_date": "2025-04-03 14:35:01 UTC"
  },
  {
    "arxiv_id": "2410.03803v1",
    "title": "Text-guided Diffusion Model for 3D Molecule Generation",
    "authors": [
      "Yanchen Luo",
      "Junfeng Fang",
      "Sihang Li",
      "Zhiyuan Liu",
      "Jiancan Wu",
      "An Zhang",
      "Wenjie Du",
      "Xiang Wang"
    ],
    "abstract": "The de novo generation of molecules with targeted properties is crucial in\nbiology, chemistry, and drug discovery. Current generative models are limited\nto using single property values as conditions, struggling with complex\ncustomizations described in detailed human language. To address this, we\npropose the text guidance instead, and introduce TextSMOG, a new Text-guided\nSmall Molecule Generation Approach via 3D Diffusion Model which integrates\nlanguage and diffusion models for text-guided small molecule generation. This\nmethod uses textual conditions to guide molecule generation, enhancing both\nstability and diversity. Experimental results show TextSMOG's proficiency in\ncapturing and utilizing information from textual descriptions, making it a\npowerful tool for generating 3D molecular structures in response to complex\ntextual customizations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03803v1",
    "published_date": "2024-10-04 10:23:20 UTC",
    "updated_date": "2024-10-04 10:23:20 UTC"
  },
  {
    "arxiv_id": "2410.03296v2",
    "title": "Comparing zero-shot self-explanations with human rationales in text classification",
    "authors": [
      "Stephanie Brandl",
      "Oliver Eberle"
    ],
    "abstract": "Instruction-tuned LLMs are able to provide an explanation about their output\nto users by generating self-explanations. These do not require gradient\ncomputations or the application of possibly complex XAI methods. In this paper,\nwe analyse whether this ability results in a good explanation. We evaluate\nself-explanations in the form of input rationales with respect to their\nplausibility to humans as well as their faithfulness to models. We study two\ntext classification tasks: sentiment classification and forced labour\ndetection, i.e., identifying pre-defined risk indicators of forced labour. In\naddition to English, we include Danish and Italian translations of the\nsentiment classification task and compare self-explanations to human\nannotations for all samples. To allow for direct comparisons, we also compute\npost-hoc feature attribution, i.e., layer-wise relevance propagation (LRP) and\nanalyse 4 LLMs. We show that self-explanations align more closely with human\nannotations compared to LRP, while maintaining a comparable level of\nfaithfulness. This finding suggests that self-explanations indeed provide good\nexplanations for text classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.03296v2",
    "published_date": "2024-10-04 10:14:12 UTC",
    "updated_date": "2025-02-21 13:45:51 UTC"
  },
  {
    "arxiv_id": "2410.03293v3",
    "title": "Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram Dataset of Over Half a Million Posts for Multilingual Sentiment Analysis",
    "authors": [
      "Nirmalya Thakur"
    ],
    "abstract": "The work presented in this paper makes three scientific contributions with a\nspecific focus on mining and analysis of COVID-19-related posts on Instagram.\nFirst, it presents a multilingual dataset of 500,153 Instagram posts about\nCOVID-19 published between January 2020 and September 2024. This dataset,\navailable at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in\n161 different languages as well as 535,021 distinct hashtags. After the\ndevelopment of this dataset, multilingual sentiment analysis was performed,\nwhich involved classifying each post as positive, negative, or neutral. The\nresults of sentiment analysis are presented as a separate attribute in this\ndataset. Second, it presents the results of performing sentiment analysis per\nyear from 2020 to 2024. The findings revealed the trends in sentiment related\nto COVID-19 on Instagram since the beginning of the pandemic. For instance,\nbetween 2020 and 2024, the sentiment trends show a notable shift, with positive\nsentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from\n44.19% to 58.34%. Finally, the paper also presents findings of\nlanguage-specific sentiment analysis. This analysis highlighted similar and\ncontrasting trends of sentiment across posts published in different languages\non Instagram. For instance, out of all English posts, 49.68% were positive,\n14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts,\n4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting\ndistinct differences in the sentiment distribution between these two languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03293v3",
    "published_date": "2024-10-04 10:06:55 UTC",
    "updated_date": "2024-10-16 14:11:21 UTC"
  },
  {
    "arxiv_id": "2410.03291v1",
    "title": "Enhanced Transformer architecture for in-context learning of dynamical systems",
    "authors": [
      "Matteo Rufolo",
      "Dario Piga",
      "Gabriele Maroni",
      "Marco Forgione"
    ],
    "abstract": "Recently introduced by some of the authors, the in-context identification\nparadigm aims at estimating, offline and based on synthetic data, a meta-model\nthat describes the behavior of a whole class of systems. Once trained, this\nmeta-model is fed with an observed input/output sequence (context) generated by\na real system to predict its behavior in a zero-shot learning fashion. In this\npaper, we enhance the original meta-modeling framework through three key\ninnovations: by formulating the learning task within a probabilistic framework;\nby managing non-contiguous context and query windows; and by adopting recurrent\npatching to effectively handle long context sequences. The efficacy of these\nmodifications is demonstrated through a numerical example focusing on the\nWiener-Hammerstein system class, highlighting the model's enhanced performance\nand scalability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03291v1",
    "published_date": "2024-10-04 10:05:15 UTC",
    "updated_date": "2024-10-04 10:05:15 UTC"
  },
  {
    "arxiv_id": "2410.03290v1",
    "title": "Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models",
    "authors": [
      "Haibo Wang",
      "Zhiyang Xu",
      "Yu Cheng",
      "Shizhe Diao",
      "Yufan Zhou",
      "Yixin Cao",
      "Qifan Wang",
      "Weifeng Ge",
      "Lifu Huang"
    ],
    "abstract": "Video Large Language Models (Video-LLMs) have demonstrated remarkable\ncapabilities in coarse-grained video understanding, however, they struggle with\nfine-grained temporal grounding. In this paper, we introduce Grounded-VideoLLM,\na novel Video-LLM adept at perceiving and reasoning over specific video moments\nin a fine-grained manner. We identify that current Video-LLMs have limitations\nfor fine-grained video understanding since they lack effective temporal\nmodeling and timestamp representation. In light of this, we sharpen our model\nby incorporating (1) an additional temporal stream to encode the relationships\nbetween frames and (2) discrete temporal tokens enriched with specific time\nknowledge to represent timestamps. To optimize the training of\nGrounded-VideoLLM, we employ a multi-stage training scheme, beginning with\nsimple video-captioning tasks and progressively introducing video temporal\ngrounding tasks of increasing complexity. To further enhance\nGrounded-VideoLLM's temporal reasoning capability, we also curate a grounded\nVideoQA dataset by an automatic annotation pipeline. Extensive experiments\ndemonstrate that Grounded-VideoLLM not only excels in fine-grained grounding\ntasks such as temporal sentence grounding, dense video captioning, and grounded\nVideoQA, but also shows great potential as a versatile video assistant for\ngeneral video understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03290v1",
    "published_date": "2024-10-04 10:04:37 UTC",
    "updated_date": "2024-10-04 10:04:37 UTC"
  },
  {
    "arxiv_id": "2410.03280v1",
    "title": "Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope",
    "authors": [
      "Yasaman Torabi",
      "Shahram Shirani",
      "James P. Reilly"
    ],
    "abstract": "Heart and lung sounds are crucial for healthcare monitoring. Recent\nimprovements in stethoscope technology have made it possible to capture patient\nsounds with enhanced precision. In this dataset, we used a digital stethoscope\nto capture both heart and lung sounds, including individual and mixed\nrecordings. To our knowledge, this is the first dataset to offer both separate\nand mixed cardiorespiratory sounds. The recordings were collected from a\nclinical manikin, a patient simulator designed to replicate human physiological\nconditions, generating clean heart and lung sounds at different body locations.\nThis dataset includes both normal sounds and various abnormalities (i.e.,\nmurmur, atrial fibrillation, tachycardia, atrioventricular block, third and\nfourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling\nsounds). The dataset includes audio recordings of chest examinations performed\nat different anatomical locations, as determined by specialist nurses. Each\nrecording has been enhanced using frequency filters to highlight specific sound\ntypes. This dataset is useful for applications in artificial intelligence, such\nas automated cardiopulmonary disease detection, sound classification,\nunsupervised separation techniques, and deep learning algorithms related to\naudio signal processing.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03280v1",
    "published_date": "2024-10-04 09:53:16 UTC",
    "updated_date": "2024-10-04 09:53:16 UTC"
  },
  {
    "arxiv_id": "2410.03263v2",
    "title": "Test-time Adaptation for Regression by Subspace Alignment",
    "authors": [
      "Kazuki Adachi",
      "Shin'ya Yamaguchi",
      "Atsutoshi Kumagai",
      "Tomoki Hamagami"
    ],
    "abstract": "This paper investigates test-time adaptation (TTA) for regression, where a\nregression model pre-trained in a source domain is adapted to an unknown target\ndistribution with unlabeled target data. Although regression is one of the\nfundamental tasks in machine learning, most of the existing TTA methods have\nclassification-specific designs, which assume that models output\nclass-categorical predictions, whereas regression models typically output only\nsingle scalar values. To enable TTA for regression, we adopt a feature\nalignment approach, which aligns the feature distributions between the source\nand target domains to mitigate the domain gap. However, we found that naive\nfeature alignment employed in existing TTA methods for classification is\nineffective or even worse for regression because the features are distributed\nin a small subspace and many of the raw feature dimensions have little\nsignificance to the output. For an effective feature alignment in TTA for\nregression, we propose Significant-subspace Alignment (SSA). SSA consists of\ntwo components: subspace detection and dimension weighting. Subspace detection\nfinds the feature subspace that is representative and significant to the\noutput. Then, the feature alignment is performed in the subspace during TTA.\nMeanwhile, dimension weighting raises the importance of the dimensions of the\nfeature subspace that have greater significance to the output. We\nexperimentally show that SSA outperforms various baselines on real-world\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03263v2",
    "published_date": "2024-10-04 09:31:10 UTC",
    "updated_date": "2025-01-23 04:57:09 UTC"
  },
  {
    "arxiv_id": "2410.03255v2",
    "title": "Towards a Benchmark for Large Language Models for Business Process Management Tasks",
    "authors": [
      "Kiran Busch",
      "Henrik Leopold"
    ],
    "abstract": "An increasing number of organizations are deploying Large Language Models\n(LLMs) for a wide range of tasks. Despite their general utility, LLMs are prone\nto errors, ranging from inaccuracies to hallucinations. To objectively assess\nthe capabilities of existing LLMs, performance benchmarks are conducted.\nHowever, these benchmarks often do not translate to more specific real-world\ntasks. This paper addresses the gap in benchmarking LLM performance in the\nBusiness Process Management (BPM) domain. Currently, no BPM-specific benchmarks\nexist, creating uncertainty about the suitability of different LLMs for BPM\ntasks. This paper systematically compares LLM performance on four BPM tasks\nfocusing on small open-source models. The analysis aims to identify\ntask-specific performance variations, compare the effectiveness of open-source\nversus commercial models, and assess the impact of model size on BPM task\nperformance. This paper provides insights into the practical applications of\nLLMs in BPM, guiding organizations in selecting appropriate models for their\nspecific needs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to HICSS (June 15, 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.03255v2",
    "published_date": "2024-10-04 09:18:54 UTC",
    "updated_date": "2024-10-13 11:32:49 UTC"
  },
  {
    "arxiv_id": "2410.03249v3",
    "title": "How Much Can We Forget about Data Contamination?",
    "authors": [
      "Sebastian Bordt",
      "Suraj Srinivas",
      "Valentyn Boreiko",
      "Ulrike von Luxburg"
    ],
    "abstract": "The leakage of benchmark data into the training data has emerged as a\nsignificant challenge for evaluating the capabilities of large language models\n(LLMs). In this work, we challenge the common assumption that small-scale\ncontamination renders benchmark evaluations invalid. First, we experimentally\nquantify the magnitude of benchmark overfitting based on scaling along three\ndimensions: The number of model parameters (up to 1.6B), the number of times an\nexample is seen (up to 144), and the number of training tokens (up to 40B). If\nmodel and data follow the Chinchilla scaling laws, minor contamination indeed\nleads to overfitting. At the same time, even 144 times of contamination can be\nforgotten if the training data is scaled beyond five times Chinchilla, a regime\ncharacteristic of many modern LLMs. Continual pre-training of OLMo-7B\ncorroborates these results. Next, we study the impact of the weight decay\nparameter on example forgetting, showing that empirical forgetting occurs\nfaster than the cumulative weight decay. This allows us to gauge the degree of\nexample forgetting in large-scale training runs, indicating that many LLMs,\nincluding Lllama 3 405B, have forgotten the data seen at the beginning of\ntraining.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03249v3",
    "published_date": "2024-10-04 09:14:11 UTC",
    "updated_date": "2025-01-30 16:31:31 UTC"
  },
  {
    "arxiv_id": "2410.03246v2",
    "title": "Latent Action Priors for Locomotion with Deep Reinforcement Learning",
    "authors": [
      "Oliver Hausdörfer",
      "Alexander von Rohr",
      "Éric Lefort",
      "Angela Schoellig"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) enables robots to learn complex behaviors\nthrough interaction with the environment. However, due to the unrestricted\nnature of the learning algorithms, the resulting solutions are often brittle\nand appear unnatural. This is especially true for learning direct joint-level\ntorque control, as inductive biases are difficult to integrate into the\nlearning process. We propose an inductive bias for learning locomotion that is\nespecially useful for torque control: latent actions learned from a small\ndataset of expert demonstrations. This prior allows the policy to directly\nleverage knowledge contained in the expert's actions and facilitates more\nefficient exploration. We observe that the agent is not restricted to the\nreward levels of the demonstration, and performance in transfer tasks is\nimproved significantly. Latent action priors combined with style rewards for\nimitation lead to a closer replication of the expert's behavior. Videos and\ncode are available at https://sites.google.com/view/latent-action-priors.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03246v2",
    "published_date": "2024-10-04 09:10:56 UTC",
    "updated_date": "2025-03-01 09:12:55 UTC"
  },
  {
    "arxiv_id": "2410.03235v2",
    "title": "Enriching Ontologies with Disjointness Axioms using Large Language Models",
    "authors": [
      "Elias Crum",
      "Antonio De Santis",
      "Manon Ovide",
      "Jiaxin Pan",
      "Alessia Pisu",
      "Nicolas Lazzari",
      "Sebastian Rudolph"
    ],
    "abstract": "Ontologies often lack explicit disjointness declarations between classes,\ndespite their usefulness for sophisticated reasoning and consistency checking\nin Knowledge Graphs. In this study, we explore the potential of Large Language\nModels (LLMs) to enrich ontologies by identifying and asserting class\ndisjointness axioms. Our approach aims at leveraging the implicit knowledge\nembedded in LLMs, using prompt engineering to elicit this knowledge for\nclassifying ontological disjointness. We validate our methodology on the\nDBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs,\nwhen guided by effective prompt strategies, can reliably identify disjoint\nclass relationships, thus streamlining the process of ontology completion\nwithout extensive manual input. For comprehensive disjointness enrichment, we\npropose a process that takes logical relationships between disjointness and\nsubclass statements into account in order to maintain satisfiability and reduce\nthe number of calls to the LLM. This work provides a foundation for future\napplications of LLMs in automated ontology enhancement and offers insights into\noptimizing LLM performance through strategic prompt design. Our code is\npublicly available on GitHub at https://github.com/n28div/llm-disjointness.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at KBC-LM'24 workshop at ISWC 2024,\n  https://ceur-ws.org/Vol-3853/paper1.pdf",
    "pdf_url": "http://arxiv.org/pdf/2410.03235v2",
    "published_date": "2024-10-04 09:00:06 UTC",
    "updated_date": "2024-12-02 13:21:36 UTC"
  },
  {
    "arxiv_id": "2410.03225v2",
    "title": "AutoPenBench: Benchmarking Generative Agents for Penetration Testing",
    "authors": [
      "Luca Gioacchini",
      "Marco Mellia",
      "Idilio Drago",
      "Alexander Delsanto",
      "Giuseppe Siracusano",
      "Roberto Bifulco"
    ],
    "abstract": "Generative AI agents, software systems powered by Large Language Models\n(LLMs), are emerging as a promising approach to automate cybersecurity tasks.\nAmong the others, penetration testing is a challenging field due to the task\ncomplexity and the diverse strategies to simulate cyber-attacks. Despite\ngrowing interest and initial studies in automating penetration testing with\ngenerative agents, there remains a significant gap in the form of a\ncomprehensive and standard framework for their evaluation and development. This\npaper introduces AutoPenBench, an open benchmark for evaluating generative\nagents in automated penetration testing. We present a comprehensive framework\nthat includes 33 tasks, each representing a vulnerable system that the agent\nhas to attack. Tasks are of increasing difficulty levels, including in-vitro\nand real-world scenarios. We assess the agent performance with generic and\nspecific milestones that allow us to compare results in a standardised manner\nand understand the limits of the agent under test. We show the benefits of\nAutoPenBench by testing two agent architectures: a fully autonomous and a\nsemi-autonomous supporting human interaction. We compare their performance and\nlimitations. For example, the fully autonomous agent performs unsatisfactorily\nachieving a 21% Success Rate (SR) across the benchmark, solving 27% of the\nsimple tasks and only one real-world task. In contrast, the assisted agent\ndemonstrates substantial improvements, with 64% of SR. AutoPenBench allows us\nalso to observe how different LLMs like GPT-4o or OpenAI o1 impact the ability\nof the agents to complete the tasks. We believe that our benchmark fills the\ngap with a standard and flexible framework to compare penetration testing\nagents on a common ground. We hope to extend AutoPenBench along with the\nresearch community by making it available under\nhttps://github.com/lucagioacchini/auto-pen-bench.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Codes for the benchmark:\n  https://github.com/lucagioacchini/auto-pen-bench Codes for the paper\n  experiments: https://github.com/lucagioacchini/genai-pentest-paper",
    "pdf_url": "http://arxiv.org/pdf/2410.03225v2",
    "published_date": "2024-10-04 08:24:15 UTC",
    "updated_date": "2024-10-28 17:05:27 UTC"
  },
  {
    "arxiv_id": "2410.03224v1",
    "title": "ScriptViz: A Visualization Tool to Aid Scriptwriting based on a Large Movie Database",
    "authors": [
      "Anyi Rao",
      "Jean-Peïc Chou",
      "Maneesh Agrawala"
    ],
    "abstract": "Scriptwriters usually rely on their mental visualization to create a vivid\nstory by using their imagination to see, feel, and experience the scenes they\nare writing. Besides mental visualization, they often refer to existing images\nor scenes in movies and analyze the visual elements to create a certain mood or\natmosphere. In this paper, we develop ScriptViz to provide external\nvisualization based on a large movie database for the screenwriting process. It\nretrieves reference visuals on the fly based on scripts' text and dialogue from\na large movie database. The tool provides two types of control on visual\nelements that enable writers to 1) see exactly what they want with fixed visual\nelements and 2) see variances in uncertain elements. User evaluation among 15\nscriptwriters shows that ScriptViz is able to present scriptwriters with\nconsistent yet diverse visual possibilities, aligning closely with their\nscripts and helping their creation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted in the 37th Annual ACM Symposium on User Interface Software\n  and Technology (UIST'24). Webpage:\n  https://virtualfilmstudio.github.io/projects/scriptviz",
    "pdf_url": "http://arxiv.org/pdf/2410.03224v1",
    "published_date": "2024-10-04 08:23:56 UTC",
    "updated_date": "2024-10-04 08:23:56 UTC"
  },
  {
    "arxiv_id": "2410.14691v1",
    "title": "Green vehicle routing problem that jointly optimizes delivery speed and routing based on the characteristics of electric vehicles",
    "authors": [
      "YY. Feng"
    ],
    "abstract": "The abundance of materials and the development of the economy have led to the\nflourishing of the logistics industry, but have also caused certain pollution.\nThe research on GVRP (Green vehicle routing problem) for planning vehicle\nroutes during transportation to reduce pollution is also increasingly\ndeveloping. Further exploration is needed on how to integrate these research\nfindings with real vehicles. This paper establishes an energy consumption model\nusing real electric vehicles, fully considering the physical characteristics of\neach component of the vehicle. To avoid the distortion of energy consumption\nmodels affecting the results of route planning. The energy consumption model\nalso incorporates the effects of vehicle start/stop, speed, distance, and load\non energy consumption. In addition, a load first speed optimization algorithm\nwas proposed, which selects the most suitable speed between every two delivery\npoints while planning the route. In order to further reduce energy consumption\nwhile meeting the time window. Finally, an improved Adaptive Genetic Algorithm\nis used to solve for the most energy-efficient route. The experiment shows that\nthe results of using this speed optimization algorithm are generally more\nenergy-efficient than those without using this algorithm. The average energy\nconsumption of constant speed delivery at different speeds is 17.16% higher\nthan that after speed optimization. Provided a method that is closer to reality\nand easier for logistics companies to use. It also enriches the GVRP model.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14691v1",
    "published_date": "2024-10-04 08:08:15 UTC",
    "updated_date": "2024-10-04 08:08:15 UTC"
  },
  {
    "arxiv_id": "2410.03215v1",
    "title": "NLIP_Lab-IITH Low-Resource MT System for WMT24 Indic MT Shared Task",
    "authors": [
      "Pramit Sahoo",
      "Maharaj Brahma",
      "Maunendra Sankar Desarkar"
    ],
    "abstract": "In this paper, we describe our system for the WMT 24 shared task of\nLow-Resource Indic Language Translation. We consider eng $\\leftrightarrow$ {as,\nkha, lus, mni} as participating language pairs. In this shared task, we explore\nthe finetuning of a pre-trained model motivated by the pre-trained objective of\naligning embeddings closer by alignment augmentation \\cite{lin-etal-2020-pre}\nfor 22 scheduled Indian languages. Our primary system is based on\nlanguage-specific finetuning on a pre-trained model. We achieve chrF2 scores of\n50.6, 42.3, 54.9, and 66.3 on the official public test set for\neng$\\rightarrow$as, eng$\\rightarrow$kha, eng$\\rightarrow$lus,\neng$\\rightarrow$mni respectively. We also explore multilingual training\nwith/without language grouping and layer-freezing. Our code, models, and\ngenerated translations are available here:\nhttps://github.com/pramitsahoo/WMT2024-LRILT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "WMT2024 INDICMT Shared Task",
    "pdf_url": "http://arxiv.org/pdf/2410.03215v1",
    "published_date": "2024-10-04 08:02:43 UTC",
    "updated_date": "2024-10-04 08:02:43 UTC"
  },
  {
    "arxiv_id": "2410.03205v1",
    "title": "A Tutorial on the Design, Experimentation and Application of Metaheuristic Algorithms to Real-World Optimization Problems",
    "authors": [
      "Eneko Osaba",
      "Esther Villar-Rodriguez",
      "Javier Del Ser",
      "Antonio J. Nebro",
      "Daniel Molina",
      "Antonio LaTorre",
      "Ponnuthurai N. Suganthan",
      "Carlos A. Coello Coello",
      "Francisco Herrera"
    ],
    "abstract": "In the last few years, the formulation of real-world optimization problems\nand their efficient solution via metaheuristic algorithms has been a catalyst\nfor a myriad of research studies. In spite of decades of historical\nadvancements on the design and use of metaheuristics, large difficulties still\nremain in regards to the understandability, algorithmic design uprightness, and\nperformance verifiability of new technical achievements. A clear example stems\nfrom the scarce replicability of works dealing with metaheuristics used for\noptimization, which is often infeasible due to ambiguity and lack of detail in\nthe presentation of the methods to be reproduced. Additionally, in many cases,\nthere is a questionable statistical significance of their reported results.\nThis work aims at providing the audience with a proposal of good practices\nwhich should be embraced when conducting studies about metaheuristics methods\nused for optimization in order to provide scientific rigor, value and\ntransparency. To this end, we introduce a step by step methodology covering\nevery research phase that should be followed when addressing this scientific\nfield. Specifically, frequently overlooked yet crucial aspects and useful\nrecommendations will be discussed in regards to the formulation of the problem,\nsolution encoding, implementation of search operators, evaluation metrics,\ndesign of experiments, and considerations for real-world performance, among\nothers. Finally, we will outline important considerations, challenges, and\nresearch directions for the success of newly developed optimization\nmetaheuristics in their deployment and operation over real-world application\nenvironments.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03205v1",
    "published_date": "2024-10-04 07:41:23 UTC",
    "updated_date": "2024-10-04 07:41:23 UTC"
  },
  {
    "arxiv_id": "2410.03192v1",
    "title": "MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech",
    "authors": [
      "Taejun Bak",
      "Youngsik Eom",
      "SeungJae Choi",
      "Young-Sun Joo"
    ],
    "abstract": "Text-to-speech (TTS) systems that scale up the amount of training data have\nachieved significant improvements in zero-shot speech synthesis. However, these\nsystems have certain limitations: they require a large amount of training data,\nwhich increases costs, and often overlook prosody similarity. To address these\nissues, we propose MultiVerse, a zero-shot multi-task TTS system that is able\nto perform TTS or speech style transfer in zero-shot and cross-lingual\nconditions. MultiVerse requires much less training data than traditional\ndata-driven approaches. To ensure zero-shot performance even with limited data,\nwe leverage source-filter theory-based disentanglement, utilizing the prompt\nfor modeling filter-related and source-related representations. Additionally,\nto further enhance prosody similarity, we adopt a prosody modeling approach\ncombining prompt-based autoregressive and non-autoregressive methods.\nEvaluations demonstrate the remarkable zero-shot multi-task TTS performance of\nMultiVerse and show that MultiVerse not only achieves zero-shot TTS performance\ncomparable to data-driven TTS systems with much less data, but also\nsignificantly outperforms other zero-shot TTS systems trained with the same\nsmall amount of data. In particular, our novel prosody modeling technique\nsignificantly contributes to MultiVerse's ability to generate speech with high\nprosody similarity to the given prompts. Our samples are available at\nhttps://nc-ai.github.io/speech/publications/multiverse/index.html",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.03192v1",
    "published_date": "2024-10-04 07:10:25 UTC",
    "updated_date": "2024-10-04 07:10:25 UTC"
  },
  {
    "arxiv_id": "2410.03188v1",
    "title": "Looking into Concept Explanation Methods for Diabetic Retinopathy Classification",
    "authors": [
      "Andrea M. Storås",
      "Josefine V. Sundgaard"
    ],
    "abstract": "Diabetic retinopathy is a common complication of diabetes, and monitoring the\nprogression of retinal abnormalities using fundus imaging is crucial. Because\nthe images must be interpreted by a medical expert, it is infeasible to screen\nall individuals with diabetes for diabetic retinopathy. Deep learning has shown\nimpressive results for automatic analysis and grading of fundus images. One\ndrawback is, however, the lack of interpretability, which hampers the\nimplementation of such systems in the clinic. Explainable artificial\nintelligence methods can be applied to explain the deep neural networks.\nExplanations based on concepts have shown to be intuitive for humans to\nunderstand, but have not yet been explored in detail for diabetic retinopathy\ngrading. This work investigates and compares two concept-based explanation\ntechniques for explaining deep neural networks developed for automatic\ndiagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation\nVectors and Concept Bottleneck Models. We found that both methods have\nstrengths and weaknesses, and choice of method should take the available data\nand the end user's preferences into account.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2024:021",
    "pdf_url": "http://arxiv.org/pdf/2410.03188v1",
    "published_date": "2024-10-04 07:01:37 UTC",
    "updated_date": "2024-10-04 07:01:37 UTC"
  },
  {
    "arxiv_id": "2410.03185v1",
    "title": "EXAQ: Exponent Aware Quantization For LLMs Acceleration",
    "authors": [
      "Moran Shkolnik",
      "Maxim Fishman",
      "Brian Chmiel",
      "Hilla Ben-Yaacov",
      "Ron Banner",
      "Kfir Yehuda Levy"
    ],
    "abstract": "Quantization has established itself as the primary approach for decreasing\nthe computational and storage expenses associated with Large Language Models\n(LLMs) inference. The majority of current research emphasizes quantizing\nweights and activations to enable low-bit general-matrix-multiply (GEMM)\noperations, with the remaining non-linear operations executed at higher\nprecision. In our study, we discovered that following the application of these\ntechniques, the primary bottleneck in LLMs inference lies in the softmax layer.\nThe softmax operation comprises three phases: exponent calculation,\naccumulation, and normalization, Our work focuses on optimizing the first two\nphases. We propose an analytical approach to determine the optimal clipping\nvalue for the input to the softmax function, enabling sub-4-bit quantization\nfor LLMs inference. This method accelerates the calculations of both $e^x$ and\n$\\sum(e^x)$ with minimal to no accuracy degradation. For example, in\nLLaMA1-30B, we achieve baseline performance with 2-bit quantization on the\nwell-known \"Physical Interaction: Question Answering\" (PIQA) dataset\nevaluation. This ultra-low bit quantization allows, for the first time, an\nacceleration of approximately 4x in the accumulation phase. The combination of\naccelerating both $e^x$ and $\\sum(e^x)$ results in a 36.9% acceleration in the\nsoftmax operation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03185v1",
    "published_date": "2024-10-04 06:54:30 UTC",
    "updated_date": "2024-10-04 06:54:30 UTC"
  },
  {
    "arxiv_id": "2410.03182v2",
    "title": "Generating bilingual example sentences with large language models as lexicography assistants",
    "authors": [
      "Raphael Merx",
      "Ekaterina Vylomova",
      "Kemal Kurniawan"
    ],
    "abstract": "We present a study of LLMs' performance in generating and rating example\nsentences for bilingual dictionaries across languages with varying resource\nlevels: French (high-resource), Indonesian (mid-resource), and Tetun\n(low-resource), with English as the target language. We evaluate the quality of\nLLM-generated examples against the GDEX (Good Dictionary EXample) criteria:\ntypicality, informativeness, and intelligibility. Our findings reveal that\nwhile LLMs can generate reasonably good dictionary examples, their performance\ndegrades significantly for lower-resourced languages. We also observe high\nvariability in human preferences for example quality, reflected in low\ninter-annotator agreement rates. To address this, we demonstrate that\nin-context learning can successfully align LLMs with individual annotator\npreferences. Additionally, we explore the use of pre-trained language models\nfor automated rating of examples, finding that sentence perplexity serves as a\ngood proxy for typicality and intelligibility in higher-resourced languages.\nOur study also contributes a novel dataset of 600 ratings for LLM-generated\nsentence pairs, and provides insights into the potential of LLMs in reducing\nthe cost of lexicographic work, particularly for low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03182v2",
    "published_date": "2024-10-04 06:45:48 UTC",
    "updated_date": "2024-11-19 05:57:28 UTC"
  },
  {
    "arxiv_id": "2410.03176v1",
    "title": "Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models",
    "authors": [
      "Yufang Liu",
      "Tao Ji",
      "Changzhi Sun",
      "Yuanbin Wu",
      "Aimin Zhou"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have achieved impressive performance,\nyet research has pointed out a serious issue with object hallucinations within\nthese models. However, there is no clear conclusion as to which part of the\nmodel these hallucinations originate from. In this paper, we present an\nin-depth investigation into the object hallucination problem specifically\nwithin the CLIP model, which serves as the backbone for many state-of-the-art\nvision-language systems. We unveil that even in isolation, the CLIP model is\nprone to object hallucinations, suggesting that the hallucination problem is\nnot solely due to the interaction between vision and language modalities. To\naddress this, we propose a counterfactual data augmentation method by creating\nnegative samples with a variety of hallucination issues. We demonstrate that\nour method can effectively mitigate object hallucinations for CLIP model, and\nwe show the the enhanced model can be employed as a visual encoder, effectively\nalleviating the object hallucination issue in LVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03176v1",
    "published_date": "2024-10-04 06:24:49 UTC",
    "updated_date": "2024-10-04 06:24:49 UTC"
  },
  {
    "arxiv_id": "2410.03161v1",
    "title": "Adaptive Masking Enhances Visual Grounding",
    "authors": [
      "Sen Jia",
      "Lei Li"
    ],
    "abstract": "In recent years, zero-shot and few-shot learning in visual grounding have\ngarnered considerable attention, largely due to the success of large-scale\nvision-language pre-training on expansive datasets such as LAION-5B and\nDataComp-1B. However, the continuous expansion of these datasets presents\nsignificant challenges, particularly with respect to data availability and\ncomputational overhead, thus creating a bottleneck in the advancement of\nlow-shot learning capabilities. In this paper, we propose IMAGE, Interpretative\nMAsking with Gaussian radiation modEling, aimed at enhancing vocabulary\ngrounding in low-shot learning scenarios without necessitating an increase in\ndataset size. Drawing inspiration from cognitive science and the recent success\nof masked autoencoders (MAE), our method leverages adaptive masking on salient\nregions of the feature maps generated by the vision backbone. This enables the\nmodel to learn robust, generalized representations through the reconstruction\nof occluded information, thereby facilitating effective attention to both local\nand global features. We evaluate the efficacy of our approach on benchmark\ndatasets, including COCO and ODinW, demonstrating its superior performance in\nzero-shot and few-shot tasks. Experimental results consistently show that IMAGE\noutperforms baseline models, achieving enhanced generalization and improved\nperformance in low-shot scenarios. These findings highlight the potential of\nadaptive feature manipulation through attention mechanisms and Gaussian\nmodeling as a promising alternative to approaches that rely on the continual\nscaling of dataset sizes for the advancement of zero-shot and few-shot\nlearning. Our code is publicly available at https://github.com/git-lenny/IMAGE.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code will be available at https://github.com/git-lenny/IMAGE",
    "pdf_url": "http://arxiv.org/pdf/2410.03161v1",
    "published_date": "2024-10-04 05:48:02 UTC",
    "updated_date": "2024-10-04 05:48:02 UTC"
  },
  {
    "arxiv_id": "2410.03159v3",
    "title": "WAVE: Weighted Autoregressive Varying Gate for Time Series Forecasting",
    "authors": [
      "Jiecheng Lu",
      "Xu Han",
      "Yan Sun",
      "Shihao Yang"
    ],
    "abstract": "We propose a Weighted Autoregressive Varying gatE (WAVE) attention mechanism\nequipped with both Autoregressive (AR) and Moving-average (MA) components. It\ncan adapt to various attention mechanisms, enhancing and decoupling their\nability to capture long-range and local temporal patterns in time series data.\nIn this paper, we first demonstrate that, for the time series forecasting (TSF)\ntask, the previously overlooked decoder-only autoregressive Transformer model\ncan achieve results comparable to the best baselines when appropriate\ntokenization and training methods are applied. Moreover, inspired by the ARMA\nmodel from statistics and recent advances in linear attention, we introduce the\nfull ARMA structure into existing autoregressive attention mechanisms. By using\nan indirect MA weight generation method, we incorporate the MA term while\nmaintaining the time complexity and parameter size of the underlying efficient\nattention models. We further explore how indirect parameter generation can\nproduce implicit MA weights that align with the modeling requirements for local\ntemporal impacts. Experimental results show that WAVE attention that\nincorporates the ARMA structure consistently improves the performance of\nvarious AR attentions on TSF tasks, achieving state-of-the-art results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03159v3",
    "published_date": "2024-10-04 05:45:50 UTC",
    "updated_date": "2025-02-12 03:55:17 UTC"
  },
  {
    "arxiv_id": "2410.03158v1",
    "title": "Mathematical Formalism for Memory Compression in Selective State Space Models",
    "authors": [
      "Siddhanth Bhat"
    ],
    "abstract": "State space models (SSMs) have emerged as a powerful framework for modelling\nlong-range dependencies in sequence data. Unlike traditional recurrent neural\nnetworks (RNNs) and convolutional neural networks (CNNs), SSMs offer a\nstructured and stable approach to sequence modelling, leveraging principles\nfrom control theory and dynamical systems. However, a key challenge in sequence\nmodelling is compressing long-term dependencies into a compact hidden state\nrepresentation without losing critical information.\n  In this paper, we develop a rigorous mathematical framework for understanding\nmemory compression in selective state space models. We introduce a selective\ngating mechanism that dynamically filters and updates the hidden state based on\ninput relevance, allowing for efficient memory compression. We formalize the\ntrade-off between memory efficiency and information retention using\ninformation-theoretic tools, such as mutual information and rate-distortion\ntheory. Our analysis provides theoretical bounds on the amount of information\nthat can be compressed without sacrificing model performance.\n  We also derive theorems that prove the stability and convergence of the\nhidden state in selective SSMs, ensuring reliable long-term memory retention.\nComputational complexity analysis reveals that selective SSMs offer significant\nimprovements in memory efficiency and processing speed compared to traditional\nRNN-based models. Through empirical validation on sequence modelling tasks such\nas time-series forecasting and natural language processing, we demonstrate that\nselective SSMs achieve state-of-the-art performance while using less memory and\ncomputational resources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "comment": "27 Pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03158v1",
    "published_date": "2024-10-04 05:45:48 UTC",
    "updated_date": "2024-10-04 05:45:48 UTC"
  },
  {
    "arxiv_id": "2410.03156v1",
    "title": "MELODI: Exploring Memory Compression for Long Contexts",
    "authors": [
      "Yinpeng Chen",
      "DeLesley Hutchins",
      "Aren Jansen",
      "Andrey Zhmoginov",
      "David Racz",
      "Jesper Andersen"
    ],
    "abstract": "We present MELODI, a novel memory architecture designed to efficiently\nprocess long documents using short context windows. The key principle behind\nMELODI is to represent short-term and long-term memory as a hierarchical\ncompression scheme across both network layers and context windows.\nSpecifically, the short-term memory is achieved through recurrent compression\nof context windows across multiple layers, ensuring smooth transitions between\nwindows. In contrast, the long-term memory performs further compression within\na single middle layer and aggregates information across context windows,\neffectively consolidating crucial information from the entire history. Compared\nto a strong baseline - the Memorizing Transformer employing dense attention\nover a large long-term memory (64K key-value pairs) - our method demonstrates\nsuperior performance on various long-context datasets while remarkably reducing\nthe memory footprint by a factor of 8.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03156v1",
    "published_date": "2024-10-04 05:34:15 UTC",
    "updated_date": "2024-10-04 05:34:15 UTC"
  },
  {
    "arxiv_id": "2410.05298v2",
    "title": "How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension",
    "authors": [
      "Xinnan Dai",
      "Haohao Qu",
      "Yifen Shen",
      "Bohang Zhang",
      "Qihao Wen",
      "Wenqi Fan",
      "Dongsheng Li",
      "Jiliang Tang",
      "Caihua Shan"
    ],
    "abstract": "Benchmarking the capabilities and limitations of large language models (LLMs)\nin graph-related tasks is becoming an increasingly popular and crucial area of\nresearch. Recent studies have shown that LLMs exhibit a preliminary ability to\nunderstand graph structures and node features. However, the potential of LLMs\nin graph pattern mining remains largely unexplored. This is a key component in\nfields such as computational chemistry, biology, and social network analysis.\nTo bridge this gap, this work introduces a comprehensive benchmark to assess\nLLMs' capabilities in graph pattern tasks. We have developed a benchmark that\nevaluates whether LLMs can understand graph patterns based on either\nterminological or topological descriptions. Additionally, our benchmark tests\nthe LLMs' capacity to autonomously discover graph patterns from data. The\nbenchmark encompasses both synthetic and real datasets, and a variety of\nmodels, with a total of 11 tasks and 7 models. Our experimental framework is\ndesigned for easy expansion to accommodate new models and datasets. Our\nfindings reveal that: (1) LLMs have preliminary abilities to understand graph\npatterns, with O1-mini outperforming in the majority of tasks; (2) Formatting\ninput data to align with the knowledge acquired during pretraining can enhance\nperformance; (3) The strategies employed by LLMs may differ from those used in\nconventional algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper is published in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05298v2",
    "published_date": "2024-10-04 04:48:33 UTC",
    "updated_date": "2025-04-20 21:31:45 UTC"
  },
  {
    "arxiv_id": "2410.03134v1",
    "title": "Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models",
    "authors": [
      "Yan Chen",
      "Cheng Liu"
    ],
    "abstract": "Remaining useful life (RUL) prediction is crucial for maintaining modern\nindustrial systems, where equipment reliability and operational safety are\nparamount. Traditional methods, based on small-scale deep learning or\nphysical/statistical models, often struggle with complex, multidimensional\nsensor data and varying operating conditions, limiting their generalization\ncapabilities. To address these challenges, this paper introduces an innovative\nregression framework utilizing large language models (LLMs) for RUL prediction.\nBy leveraging the modeling power of LLMs pre-trained on corpus data, the\nproposed model can effectively capture complex temporal dependencies and\nimprove prediction accuracy. Extensive experiments on the Turbofan engine's RUL\nprediction task show that the proposed model surpasses state-of-the-art (SOTA)\nmethods on the challenging FD002 and FD004 subsets and achieves near-SOTA\nresults on the other subsets. Notably, different from previous research, our\nframework uses the same sliding window length and all sensor signals for all\nsubsets, demonstrating strong consistency and generalization. Moreover,\ntransfer learning experiments reveal that with minimal target domain data for\nfine-tuning, the model outperforms SOTA methods trained on full target domain\ndata. This research highlights the significant potential of LLMs in industrial\nsignal processing and RUL prediction, offering a forward-looking solution for\nhealth management in future intelligent industrial systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03134v1",
    "published_date": "2024-10-04 04:21:53 UTC",
    "updated_date": "2024-10-04 04:21:53 UTC"
  },
  {
    "arxiv_id": "2410.03132v5",
    "title": "Autoregressive Action Sequence Learning for Robotic Manipulation",
    "authors": [
      "Xinyu Zhang",
      "Yuhan Liu",
      "Haonan Chang",
      "Liam Schramm",
      "Abdeslam Boularias"
    ],
    "abstract": "Designing a universal policy architecture that performs well across diverse\nrobots and task configurations remains a key challenge. In this work, we\naddress this by representing robot actions as sequential data and generating\nactions through autoregressive sequence modeling. Existing autoregressive\narchitectures generate end-effector waypoints sequentially as word tokens in\nlanguage modeling, which are limited to low-frequency control tasks. Unlike\nlanguage, robot actions are heterogeneous and often include continuous values\n-- such as joint positions, 2D pixel coordinates, and end-effector poses --\nwhich are not easily suited for language-based modeling. Based on this insight,\nwe introduce a straightforward enhancement: we extend causal transformers'\nsingle-token prediction to support predicting a variable number of tokens in a\nsingle step through our Chunking Causal Transformer (CCT). This enhancement\nenables robust performance across diverse tasks of various control frequencies,\ngreater efficiency by having fewer autoregression steps, and lead to a hybrid\naction sequence design by mixing different types of actions and using a\ndifferent chunk size for each action type. Based on CCT, we propose the\nAutoregressive Policy (ARP) architecture, which solves manipulation tasks by\ngenerating hybrid action sequences. We evaluate ARP across diverse robotic\nmanipulation environments, including Push-T, ALOHA, and RLBench, and show that\nARP, as a universal architecture, matches or outperforms the\nenvironment-specific state-of-the-art in all tested benchmarks, while being\nmore efficient in computation and parameter sizes. Videos of our real robot\ndemonstrations, all source code and the pretrained models of ARP can be found\nat http://github.com/mlzxy/arp.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "(RA-L 2025) Add a new figure to explain why chunking autoregression\n  works. Put back the previous in-depth discussion for arxiv release",
    "pdf_url": "http://arxiv.org/pdf/2410.03132v5",
    "published_date": "2024-10-04 04:07:15 UTC",
    "updated_date": "2025-03-25 19:16:05 UTC"
  },
  {
    "arxiv_id": "2410.03131v3",
    "title": "AIME: AI System Optimization via Multiple LLM Evaluators",
    "authors": [
      "Bhrij Patel",
      "Souradip Chakraborty",
      "Wesley A. Suttle",
      "Mengdi Wang",
      "Amrit Singh Bedi",
      "Dinesh Manocha"
    ],
    "abstract": "Text-based AI system optimization typically involves a feedback loop scheme\nwhere a single LLM generates an evaluation in natural language of the current\noutput to improve the next iteration's output. However, in this work, we\nempirically demonstrate that for a practical and complex task (code generation)\nwith multiple criteria to evaluate, utilizing only one LLM evaluator tends to\nlet errors in generated code go undetected, thus leading to incorrect\nevaluations and ultimately suboptimal test case performance. Motivated by this\nfailure case, we assume there exists an optimal evaluation policy that samples\nan evaluation between response and ground truth. We then theoretically prove\nthat a linear combination of multiple evaluators can approximate this optimal\npolicy. From this insight, we propose AI system optimization via Multiple LLM\nEvaluators (AIME). AIME is an evaluation protocol that utilizes multiple LLMs\nthat each independently generate an evaluation on separate criteria and then\ncombine them via concatenation. We provide an extensive empirical study showing\nAIME outperforming baseline methods in code generation tasks, with up to $62\\%$\nhigher error detection rate and up to $16\\%$ higher success rate than a single\nLLM evaluation protocol on LeetCodeHard and HumanEval datasets. We also show\nthat the selection of the number of evaluators and which criteria to utilize is\nnon-trivial as it can impact pact success rate by up to $12\\%$.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 10 Figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.03131v3",
    "published_date": "2024-10-04 04:03:24 UTC",
    "updated_date": "2024-10-29 02:35:14 UTC"
  },
  {
    "arxiv_id": "2410.03129v2",
    "title": "ARB-LLM: Alternating Refined Binarizations for Large Language Models",
    "authors": [
      "Zhiteng Li",
      "Xianglong Yan",
      "Tianao Zhang",
      "Haotong Qin",
      "Dong Xie",
      "Jiang Tian",
      "zhongchao shi",
      "Linghe Kong",
      "Yulun Zhang",
      "Xiaokang Yang"
    ],
    "abstract": "Large Language Models (LLMs) have greatly pushed forward advancements in\nnatural language processing, yet their high memory and computational demands\nhinder practical deployment. Binarization, as an effective compression\ntechnique, can shrink model weights to just 1 bit, significantly reducing the\nhigh demands on computation and memory. However, current binarization methods\nstruggle to narrow the distribution gap between binarized and full-precision\nweights, while also overlooking the column deviation in LLM weight\ndistribution. To tackle these issues, we propose ARB-LLM, a novel 1-bit\npost-training quantization (PTQ) technique tailored for LLMs. To narrow the\ndistribution shift between binarized and full-precision weights, we first\ndesign an alternating refined binarization (ARB) algorithm to progressively\nupdate the binarization parameters, which significantly reduces the\nquantization error. Moreover, considering the pivot role of calibration data\nand the column deviation in LLM weights, we further extend ARB to ARB-X and\nARB-RC. In addition, we refine the weight partition strategy with column-group\nbitmap (CGB), which further enhance performance. Equipping ARB-X and ARB-RC\nwith CGB, we obtain ARB-LLM$_\\text{X}$ and ARB-LLM$_\\text{RC}$ respectively,\nwhich significantly outperform state-of-the-art (SOTA) binarization methods for\nLLMs. As a binary PTQ method, our ARB-LLM$_\\text{RC}$ is the first to surpass\nFP16 models of the same size. The code and models will be available at\nhttps://github.com/ZHITENGLI/ARB-LLM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The code and models will be available at\n  https://github.com/ZHITENGLI/ARB-LLM",
    "pdf_url": "http://arxiv.org/pdf/2410.03129v2",
    "published_date": "2024-10-04 03:50:10 UTC",
    "updated_date": "2024-10-10 05:38:46 UTC"
  },
  {
    "arxiv_id": "2410.03126v1",
    "title": "Understanding Decision Subjects' Engagement with and Perceived Fairness of AI Models When Opportunities of Qualification Improvement Exist",
    "authors": [
      "Meric Altug Gemalmaz",
      "Ming Yin"
    ],
    "abstract": "We explore how an AI model's decision fairness affects people's engagement\nwith and perceived fairness of the model if they are subject to its decisions,\nbut could repeatedly and strategically respond to these decisions. Two types of\nstrategic responses are considered -- people could determine whether to\ncontinue interacting with the model, and whether to invest in themselves to\nimprove their chance of future favorable decisions from the model. Via three\nhuman-subject experiments, we found that in decision subjects' strategic,\nrepeated interactions with an AI model, the model's decision fairness does not\nchange their willingness to interact with the model or to improve themselves,\neven when the model exhibits unfairness on salient protected attributes.\nHowever, decision subjects still perceive the AI model to be less fair when it\nsystematically biases against their group, especially if the difficulty of\nimproving one's qualification for the favorable decision is larger for the\nlowly-qualified people.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03126v1",
    "published_date": "2024-10-04 03:43:26 UTC",
    "updated_date": "2024-10-04 03:43:26 UTC"
  },
  {
    "arxiv_id": "2410.03122v1",
    "title": "RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models via Chain-of-Thought In-Context Learning",
    "authors": [
      "Zihao Zhao",
      "Yuchen Yang",
      "Yijiang Li",
      "Yinzhi Cao"
    ],
    "abstract": "The ripple effect poses a significant challenge in knowledge editing for\nlarge language models. Namely, when a single fact is edited, the model\nstruggles to accurately update the related facts in a sequence, which is\nevaluated by multi-hop questions linked to a chain of related facts. Recent\nstrategies have moved away from traditional parameter updates to more flexible,\nless computation-intensive methods, proven to be more effective in addressing\nthe ripple effect. In-context learning (ICL) editing uses a simple\ndemonstration `Imagine that + new fact` to guide LLMs, but struggles with\ncomplex multi-hop questions as the new fact alone fails to specify the chain of\nfacts involved in such scenarios. Besides, memory-based editing maintains\nadditional storage for all edits and related facts, requiring continuous\nupdates to stay effective. As a result of these design limitations, the\nchallenge remains, with the highest accuracy being only 33.8% on the MQuAKE-cf\nbenchmarks for Vicuna-7B. To address this, we propose RippleCOT, a novel ICL\nediting approach integrating Chain-of-Thought (COT) reasoning. RippleCOT\nstructures demonstrations as `newfact, question, thought, answer`,\nincorporating a thought component to identify and decompose the multi-hop logic\nwithin questions. This approach effectively guides the model through complex\nmulti-hop questions with chains of related facts. Comprehensive experiments\ndemonstrate that RippleCOT significantly outperforms the state-of-the-art on\nthe ripple effect, achieving accuracy gains ranging from 7.8% to 87.1%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP findings",
    "pdf_url": "http://arxiv.org/pdf/2410.03122v1",
    "published_date": "2024-10-04 03:37:36 UTC",
    "updated_date": "2024-10-04 03:37:36 UTC"
  },
  {
    "arxiv_id": "2410.03796v1",
    "title": "Dynamic Evidence Decoupling for Trusted Multi-view Learning",
    "authors": [
      "Ying Liu",
      "Lihong Liu",
      "Cai Xu",
      "Xiangyu Song",
      "Ziyu Guan",
      "Wei Zhao"
    ],
    "abstract": "Multi-view learning methods often focus on improving decision accuracy, while\nneglecting the decision uncertainty, limiting their suitability for\nsafety-critical applications. To mitigate this, researchers propose trusted\nmulti-view learning methods that estimate classification probabilities and\nuncertainty by learning the class distributions for each instance. However,\nthese methods assume that the data from each view can effectively differentiate\nall categories, ignoring the semantic vagueness phenomenon in real-world\nmulti-view data. Our findings demonstrate that this phenomenon significantly\nsuppresses the learning of view-specific evidence in existing methods. We\npropose a Consistent and Complementary-aware trusted Multi-view Learning (CCML)\nmethod to solve this problem. We first construct view opinions using evidential\ndeep neural networks, which consist of belief mass vectors and uncertainty\nestimates. Next, we dynamically decouple the consistent and complementary\nevidence. The consistent evidence is derived from the shared portions across\nall views, while the complementary evidence is obtained by averaging the\ndiffering portions across all views. We ensure that the opinion constructed\nfrom the consistent evidence strictly aligns with the ground-truth category.\nFor the opinion constructed from the complementary evidence, we allow it for\npotential vagueness in the evidence. We compare CCML with state-of-the-art\nbaselines on one synthetic and six real-world datasets. The results validate\nthe effectiveness of the dynamic evidence decoupling strategy and show that\nCCML significantly outperforms baselines on accuracy and reliability. The code\nis released at https://github.com/Lihong-Liu/CCML.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03796v1",
    "published_date": "2024-10-04 03:27:51 UTC",
    "updated_date": "2024-10-04 03:27:51 UTC"
  },
  {
    "arxiv_id": "2410.03117v1",
    "title": "ProcBench: Benchmark for Multi-Step Reasoning and Following Procedure",
    "authors": [
      "Ippei Fujisawa",
      "Sensho Nobe",
      "Hiroki Seto",
      "Rina Onda",
      "Yoshiaki Uchida",
      "Hiroki Ikoma",
      "Pei-Chun Chien",
      "Ryota Kanai"
    ],
    "abstract": "Reasoning is central to a wide range of intellectual activities, and while\nthe capabilities of large language models (LLMs) continue to advance, their\nperformance in reasoning tasks remains limited. The processes and mechanisms\nunderlying reasoning are not yet fully understood, but key elements include\npath exploration, selection of relevant knowledge, and multi-step inference.\nProblems are solved through the synthesis of these components. In this paper,\nwe propose a benchmark that focuses on a specific aspect of reasoning ability:\nthe direct evaluation of multi-step inference. To this end, we design a special\nreasoning task where multi-step inference is specifically focused by largely\neliminating path exploration and implicit knowledge utilization. Our dataset\ncomprises pairs of explicit instructions and corresponding questions, where the\nprocedures necessary for solving the questions are entirely detailed within the\ninstructions. This setup allows models to solve problems solely by following\nthe provided directives. By constructing problems that require varying numbers\nof steps to solve and evaluating responses at each step, we enable a thorough\nassessment of state-of-the-art LLMs' ability to follow instructions. To ensure\nthe robustness of our evaluation, we include multiple distinct tasks.\nFurthermore, by comparing accuracy across tasks, utilizing step-aware metrics,\nand applying separately defined measures of complexity, we conduct experiments\nthat offer insights into the capabilities and limitations of LLMs in reasoning\ntasks. Our findings have significant implications for the development of LLMs\nand highlight areas for future research in advancing their reasoning abilities.\nOur dataset is available at\n\\url{https://huggingface.co/datasets/ifujisawa/procbench} and code at\n\\url{https://github.com/ifujisawa/proc-bench}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03117v1",
    "published_date": "2024-10-04 03:21:24 UTC",
    "updated_date": "2024-10-04 03:21:24 UTC"
  },
  {
    "arxiv_id": "2410.03111v1",
    "title": "LoRC: Low-Rank Compression for LLMs KV Cache with a Progressive Compression Strategy",
    "authors": [
      "Rongzhi Zhang",
      "Kuang Wang",
      "Liyuan Liu",
      "Shuohang Wang",
      "Hao Cheng",
      "Chao Zhang",
      "Yelong Shen"
    ],
    "abstract": "The Key-Value (KV) cache is a crucial component in serving transformer-based\nautoregressive large language models (LLMs), enabling faster inference by\nstoring previously computed KV vectors. However, its memory consumption scales\nlinearly with sequence length and batch size, posing a significant bottleneck\nin LLM deployment. Existing approaches to mitigate this issue include: (1)\nefficient attention variants integrated in upcycling stages, which requires\nextensive parameter tuning thus unsuitable for pre-trained LLMs; (2) KV cache\ncompression at test time, primarily through token eviction policies, which\noften overlook inter-layer dependencies and can be task-specific.\n  This paper introduces an orthogonal approach to KV cache compression. We\npropose a low-rank approximation of KV weight matrices, allowing for plug-in\nintegration with existing transformer-based LLMs without model retraining. To\neffectively compress KV cache at the weight level, we adjust for layerwise\nsensitivity and introduce a progressive compression strategy, which is\nsupported by our theoretical analysis on how compression errors accumulate in\ndeep networks. Our method is designed to function without model tuning in\nupcycling stages or task-specific profiling in test stages. Extensive\nexperiments with LLaMA models ranging from 8B to 70B parameters across various\ntasks show that our approach significantly reduces the GPU memory footprint\nwhile maintaining performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03111v1",
    "published_date": "2024-10-04 03:10:53 UTC",
    "updated_date": "2024-10-04 03:10:53 UTC"
  },
  {
    "arxiv_id": "2410.03107v1",
    "title": "MBDS: A Multi-Body Dynamics Simulation Dataset for Graph Networks Simulators",
    "authors": [
      "Sheng Yang",
      "Fengge Wu",
      "Junsuo Zhao"
    ],
    "abstract": "Modeling the structure and events of the physical world constitutes a\nfundamental objective of neural networks. Among the diverse approaches, Graph\nNetwork Simulators (GNS) have emerged as the leading method for modeling\nphysical phenomena, owing to their low computational cost and high accuracy.\nThe datasets employed for training and evaluating physical simulation\ntechniques are typically generated by researchers themselves, often resulting\nin limited data volume and quality. Consequently, this poses challenges in\naccurately assessing the performance of these methods. In response to this, we\nhave constructed a high-quality physical simulation dataset encompassing 1D,\n2D, and 3D scenes, along with more trajectories and time-steps compared to\nexisting datasets. Furthermore, our work distinguishes itself by developing\neight complete scenes, significantly enhancing the dataset's comprehensiveness.\nA key feature of our dataset is the inclusion of precise multi-body dynamics,\nfacilitating a more realistic simulation of the physical world. Utilizing our\nhigh-quality dataset, we conducted a systematic evaluation of various existing\nGNS methods. Our dataset is accessible for download at\nhttps://github.com/Sherlocktein/MBDS, offering a valuable resource for\nresearchers to enhance the training and evaluation of their methodologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03107v1",
    "published_date": "2024-10-04 03:03:06 UTC",
    "updated_date": "2024-10-04 03:03:06 UTC"
  },
  {
    "arxiv_id": "2410.03105v1",
    "title": "Mamba in Vision: A Comprehensive Survey of Techniques and Applications",
    "authors": [
      "Md Maklachur Rahman",
      "Abdullah Aman Tutul",
      "Ankur Nath",
      "Lamyanba Laishram",
      "Soon Ki Jung",
      "Tracy Hammond"
    ],
    "abstract": "Mamba is emerging as a novel approach to overcome the challenges faced by\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs) in computer\nvision. While CNNs excel at extracting local features, they often struggle to\ncapture long-range dependencies without complex architectural modifications. In\ncontrast, ViTs effectively model global relationships but suffer from high\ncomputational costs due to the quadratic complexity of their self-attention\nmechanisms. Mamba addresses these limitations by leveraging Selective\nStructured State Space Models to effectively capture long-range dependencies\nwith linear computational complexity. This survey analyzes the unique\ncontributions, computational benefits, and applications of Mamba models while\nalso identifying challenges and potential future research directions. We\nprovide a foundational resource for advancing the understanding and growth of\nMamba models in computer vision. An overview of this work is available at\nhttps://github.com/maklachur/Mamba-in-Computer-Vision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.03105v1",
    "published_date": "2024-10-04 02:58:49 UTC",
    "updated_date": "2024-10-04 02:58:49 UTC"
  },
  {
    "arxiv_id": "2410.03097v2",
    "title": "CLIPDrag: Combining Text-based and Drag-based Instructions for Image Editing",
    "authors": [
      "Ziqi Jiang",
      "Zhen Wang",
      "Long Chen"
    ],
    "abstract": "Precise and flexible image editing remains a fundamental challenge in\ncomputer vision. Based on the modified areas, most editing methods can be\ndivided into two main types: global editing and local editing. In this paper,\nwe choose the two most common editing approaches (ie text-based editing and\ndrag-based editing) and analyze their drawbacks. Specifically, text-based\nmethods often fail to describe the desired modifications precisely, while\ndrag-based methods suffer from ambiguity. To address these issues, we proposed\n\\textbf{CLIPDrag}, a novel image editing method that is the first to combine\ntext and drag signals for precise and ambiguity-free manipulations on diffusion\nmodels. To fully leverage these two signals, we treat text signals as global\nguidance and drag points as local information. Then we introduce a novel\nglobal-local motion supervision method to integrate text signals into existing\ndrag-based methods by adapting a pre-trained language-vision model like CLIP.\nFurthermore, we also address the problem of slow convergence in CLIPDrag by\npresenting a fast point-tracking method that enforces drag points moving toward\ncorrect directions. Extensive experiments demonstrate that CLIPDrag outperforms\nexisting single drag-based methods or text-based methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03097v2",
    "published_date": "2024-10-04 02:46:09 UTC",
    "updated_date": "2025-02-26 02:51:12 UTC"
  },
  {
    "arxiv_id": "2410.03092v1",
    "title": "Strategic Insights from Simulation Gaming of AI Race Dynamics",
    "authors": [
      "Ross Gruetzemacher",
      "Shahar Avin",
      "James Fox",
      "Alexander K Saeri"
    ],
    "abstract": "We present insights from \"Intelligence Rising\", a scenario exploration\nexercise about possible AI futures. Drawing on the experiences of facilitators\nwho have overseen 43 games over a four-year period, we illuminate recurring\npatterns, strategies, and decision-making processes observed during gameplay.\nOur analysis reveals key strategic considerations about AI development\ntrajectories in this simulated environment, including: the destabilising\neffects of AI races, the crucial role of international cooperation in\nmitigating catastrophic risks, the challenges of aligning corporate and\nnational interests, and the potential for rapid, transformative change in AI\ncapabilities. We highlight places where we believe the game has been effective\nin exposing participants to the complexities and uncertainties inherent in AI\ngovernance. Key recurring gameplay themes include the emergence of\ninternational agreements, challenges to the robustness of such agreements, the\ncritical role of cybersecurity in AI development, and the potential for\nunexpected crises to dramatically alter AI trajectories. By documenting these\ninsights, we aim to provide valuable foresight for policymakers, industry\nleaders, and researchers navigating the complex landscape of AI development and\ngovernance.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "41 pages, includes executive summary. Under review for academic\n  journal",
    "pdf_url": "http://arxiv.org/pdf/2410.03092v1",
    "published_date": "2024-10-04 02:34:21 UTC",
    "updated_date": "2024-10-04 02:34:21 UTC"
  },
  {
    "arxiv_id": "2410.03083v1",
    "title": "Scaling Parameter-Constrained Language Models with Quality Data",
    "authors": [
      "Ernie Chang",
      "Matteo Paltenghi",
      "Yang Li",
      "Pin-Jie Lin",
      "Changsheng Zhao",
      "Patrick Huber",
      "Zechun Liu",
      "Rastislav Rabatin",
      "Yangyang Shi",
      "Vikas Chandra"
    ],
    "abstract": "Scaling laws in language modeling traditionally quantify training loss as a\nfunction of dataset size and model parameters, providing compute-optimal\nestimates but often neglecting the impact of data quality on model\ngeneralization. In this paper, we extend the conventional understanding of\nscaling law by offering a microscopic view of data quality within the original\nformulation -- effective training tokens -- which we posit to be a critical\ndeterminant of performance for parameter-constrained language models.\nSpecifically, we formulate the proposed term of effective training tokens to be\na combination of two readily-computed indicators of text: (i) text diversity\nand (ii) syntheticity as measured by a teacher model. We pretrained over $200$\nmodels of 25M to 1.5B parameters on a diverse set of sampled, synthetic data,\nand estimated the constants that relate text quality, model size, training\ntokens, and eight reasoning task accuracy scores. We demonstrated the estimated\nconstants yield +0.83 Pearson correlation with true accuracies, and analyzed it\nin scenarios involving widely-used data techniques such as data sampling and\nsynthesis which aim to improve data quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Industry Track, 18 pages, 9 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.03083v1",
    "published_date": "2024-10-04 02:07:17 UTC",
    "updated_date": "2024-10-04 02:07:17 UTC"
  },
  {
    "arxiv_id": "2410.03077v1",
    "title": "CommonIT: Commonality-Aware Instruction Tuning for Large Language Models via Data Partitions",
    "authors": [
      "Jun Rao",
      "Xuebo Liu",
      "Lian Lian",
      "Shengjun Cheng",
      "Yunjie Liao",
      "Min Zhang"
    ],
    "abstract": "With instruction tuning, Large Language Models (LLMs) can enhance their\nability to adhere to commands. Diverging from most works focusing on data\nmixing, our study concentrates on enhancing the model's capabilities from the\nperspective of data sampling during training. Drawing inspiration from the\nhuman learning process, where it is generally easier to master solutions to\nsimilar topics through focused practice on a single type of topic, we introduce\na novel instruction tuning strategy termed CommonIT: Commonality-aware\nInstruction Tuning. Specifically, we cluster instruction datasets into distinct\ngroups with three proposed metrics (Task, Embedding and Length). We ensure each\ntraining mini-batch, or \"partition\", consists solely of data from a single\ngroup, which brings about both data randomness across mini-batches and\nintra-batch data similarity. Rigorous testing on LLaMa models demonstrates\nCommonIT's effectiveness in enhancing the instruction-following capabilities of\nLLMs through IT datasets (FLAN, CoT, and Alpaca) and models (LLaMa2-7B,\nQwen2-7B, LLaMa 13B, and BLOOM 7B). CommonIT consistently boosts an average\nimprovement of 2.1\\% on the general domain (i.e., the average score of\nKnowledge, Reasoning, Multilinguality and Coding) with the Length metric, and\n5.2\\% on the special domain (i.e., GSM, Openfunctions and Code) with the Task\nmetric, and 3.8\\% on the specific tasks (i.e., MMLU) with the Embedding metric.\nCode is available at \\url{https://github.com/raojay7/CommonIT}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03077v1",
    "published_date": "2024-10-04 01:42:35 UTC",
    "updated_date": "2024-10-04 01:42:35 UTC"
  },
  {
    "arxiv_id": "2410.03072v2",
    "title": "Multi-Robot Motion Planning with Diffusion Models",
    "authors": [
      "Yorai Shaoul",
      "Itamar Mishani",
      "Shivam Vats",
      "Jiaoyang Li",
      "Maxim Likhachev"
    ],
    "abstract": "Diffusion models have recently been successfully applied to a wide range of\nrobotics applications for learning complex multi-modal behaviors from data.\nHowever, prior works have mostly been confined to single-robot and small-scale\nenvironments due to the high sample complexity of learning multi-robot\ndiffusion models. In this paper, we propose a method for generating\ncollision-free multi-robot trajectories that conform to underlying data\ndistributions while using only single-robot data. Our algorithm, Multi-robot\nMulti-model planning Diffusion (MMD), does so by combining learned diffusion\nmodels with classical search-based techniques -- generating data-driven motions\nunder collision constraints. Scaling further, we show how to compose multiple\ndiffusion models to plan in large environments where a single diffusion model\nfails to generalize well. We demonstrate the effectiveness of our approach in\nplanning for dozens of robots in a variety of simulated scenarios motivated by\nlogistics environments. View video demonstrations and code at:\nhttps://multi-robot-diffusion.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "The first three authors contributed equally to this work. Published\n  at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.03072v2",
    "published_date": "2024-10-04 01:31:13 UTC",
    "updated_date": "2025-05-07 13:04:49 UTC"
  },
  {
    "arxiv_id": "2410.03063v1",
    "title": "Integrating Natural Language Prompting Tasks in Introductory Programming Courses",
    "authors": [
      "Chris Kerslake",
      "Paul Denny",
      "David H Smith IV",
      "James Prather",
      "Juho Leinonen",
      "Andrew Luxton-Reilly",
      "Stephen MacNeil"
    ],
    "abstract": "Introductory programming courses often emphasize mastering syntax and basic\nconstructs before progressing to more complex and interesting programs. This\nbottom-up approach can be frustrating for novices, shifting the focus away from\nproblem solving and potentially making computing less appealing to a broad\nrange of students. The rise of generative AI for code production could\npartially address these issues by fostering new skills via interaction with AI\nmodels, including constructing high-level prompts and evaluating code that is\nautomatically generated. In this experience report, we explore the inclusion of\ntwo prompt-focused activities in an introductory course, implemented across\nfour labs in a six-week module. The first requires students to solve\ncomputational problems by writing natural language prompts, emphasizing\nproblem-solving over syntax. The second involves students crafting prompts to\ngenerate code equivalent to provided fragments, to foster an understanding of\nthe relationship between prompts and code. Most of the students in the course\nhad reported finding programming difficult to learn, often citing frustrations\nwith syntax and debugging. We found that self-reported difficulty with learning\nprogramming had a strong inverse relationship with performance on traditional\nprogramming assessments such as tests and projects, as expected. However,\nperformance on the natural language tasks was less strongly related to\nself-reported difficulty, suggesting they may target different skills. Learning\nhow to communicate with AI coding models is becoming an important skill, and\nnatural language prompting tasks may appeal to a broad range of students.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 6 figures. Accepted for publication at SIGCSE Virtual 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.03063v1",
    "published_date": "2024-10-04 01:03:25 UTC",
    "updated_date": "2024-10-04 01:03:25 UTC"
  },
  {
    "arxiv_id": "2410.03062v1",
    "title": "Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks",
    "authors": [
      "Grant Wardle",
      "Teo Susnjak"
    ],
    "abstract": "This paper examines how the sequencing of images and text within multi-modal\nprompts influences the reasoning performance of large language models (LLMs).\nWe performed empirical evaluations using three commercial LLMs. Our results\ndemonstrate that the order in which modalities are presented can significantly\naffect performance, particularly in tasks of varying complexity. For simpler\ntasks involving a single image, modality sequencing had a clear impact on\naccuracy. However, in more complex tasks involving multiple images and\nintricate reasoning steps, the effect of sequencing diminished, likely due to\nthe increased cognitive demands of the task. Our findings also highlight the\nimportance of question/prompt structure. In nested and multi-step reasoning\ntasks, modality sequencing played a key role in shaping model performance.\nWhile LLMs excelled in the initial stages of reasoning, they struggled to\nre-incorporate earlier information, underscoring the challenges of multi-hop\nreasoning within transformer architectures. This suggests that aligning the\nsequence of modalities with the logical flow of reasoning steps is more\ncritical than modality order alone. These insights offer valuable implications\nfor improving multi-modal prompt design, with broader applications across\nfields such as education, medical imaging, and cross-modal learning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03062v1",
    "published_date": "2024-10-04 00:55:15 UTC",
    "updated_date": "2024-10-04 00:55:15 UTC"
  },
  {
    "arxiv_id": "2410.03056v1",
    "title": "Towards an Improved Metric for Evaluating Disentangled Representations",
    "authors": [
      "Sahib Julka",
      "Yashu Wang",
      "Michael Granitzer"
    ],
    "abstract": "Disentangled representation learning plays a pivotal role in making\nrepresentations controllable, interpretable and transferable. Despite its\nsignificance in the domain, the quest for reliable and consistent quantitative\ndisentanglement metric remains a major challenge. This stems from the\nutilisation of diverse metrics measuring different properties and the potential\nbias introduced by their design. Our work undertakes a comprehensive\nexamination of existing popular disentanglement evaluation metrics, comparing\nthem in terms of measuring aspects of disentanglement (viz. Modularity,\nCompactness, and Explicitness), detecting the factor-code relationship, and\ndescribing the degree of disentanglement. We propose a new framework for\nquantifying disentanglement, introducing a metric entitled \\emph{EDI}, that\nleverages the intuitive concept of \\emph{exclusivity} and improved factor-code\nrelationship to minimize ad-hoc decisions. An in-depth analysis reveals that\nEDI measures essential properties while offering more stability than existing\nmetrics, advocating for its adoption as a standardised approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.03056v1",
    "published_date": "2024-10-04 00:32:59 UTC",
    "updated_date": "2024-10-04 00:32:59 UTC"
  },
  {
    "arxiv_id": "2410.03055v1",
    "title": "Permissive Information-Flow Analysis for Large Language Models",
    "authors": [
      "Shoaib Ahmed Siddiqui",
      "Radhika Gaonkar",
      "Boris Köpf",
      "David Krueger",
      "Andrew Paverd",
      "Ahmed Salem",
      "Shruti Tople",
      "Lukas Wutschitz",
      "Menglin Xia",
      "Santiago Zanella-Béguelin"
    ],
    "abstract": "Large Language Models (LLMs) are rapidly becoming commodity components of\nlarger software systems. This poses natural security and privacy problems:\npoisoned data retrieved from one component can change the model's behavior and\ncompromise the entire system, including coercing the model to spread\nconfidential data to untrusted components. One promising approach is to tackle\nthis problem at the system level via dynamic information flow (aka taint)\ntracking. Unfortunately, the traditional approach of propagating the most\nrestrictive input label to the output is too conservative for applications\nwhere LLMs operate on inputs retrieved from diverse sources. In this paper, we\npropose a novel, more permissive approach to propagate information flow labels\nthrough LLM queries. The key idea behind our approach is to propagate only the\nlabels of the samples that were influential in generating the model output and\nto eliminate the labels of unnecessary input. We implement and investigate the\neffectiveness of two variations of this approach, based on (i) prompt-based\nretrieval augmentation, and (ii) a $k$-nearest-neighbors language model. We\ncompare these with the baseline of an introspection-based influence estimator\nthat directly asks the language model to predict the output label. The results\nobtained highlight the superiority of our prompt-based label propagator, which\nimproves the label in more than 85% of the cases in an LLM agent setting. These\nfindings underscore the practicality of permissive label propagation for\nretrieval augmentation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03055v1",
    "published_date": "2024-10-04 00:25:43 UTC",
    "updated_date": "2024-10-04 00:25:43 UTC"
  },
  {
    "arxiv_id": "2410.03049v1",
    "title": "Scalable Frame-based Construction of Sociocultural NormBases for Socially-Aware Dialogues",
    "authors": [
      "Shilin Qu",
      "Weiqing Wang",
      "Xin Zhou",
      "Haolan Zhan",
      "Zhuang Li",
      "Lizhen Qu",
      "Linhao Luo",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ],
    "abstract": "Sociocultural norms serve as guiding principles for personal conduct in\nsocial interactions, emphasizing respect, cooperation, and appropriate\nbehavior, which is able to benefit tasks including conversational information\nretrieval, contextual information retrieval and retrieval-enhanced machine\nlearning. We propose a scalable approach for constructing a Sociocultural Norm\n(SCN) Base using Large Language Models (LLMs) for socially aware dialogues. We\nconstruct a comprehensive and publicly accessible Chinese Sociocultural\nNormBase. Our approach utilizes socially aware dialogues, enriched with\ncontextual frames, as the primary data source to constrain the generating\nprocess and reduce the hallucinations. This enables extracting of high-quality\nand nuanced natural-language norm statements, leveraging the pragmatic\nimplications of utterances with respect to the situation. As real dialogue\nannotated with gold frames are not readily available, we propose using\nsynthetic data. Our empirical results show: (i) the quality of the SCNs derived\nfrom synthetic data is comparable to that from real dialogues annotated with\ngold frames, and (ii) the quality of the SCNs extracted from real data,\nannotated with either silver (predicted) or gold frames, surpasses that without\nthe frame annotations. We further show the effectiveness of the extracted SCNs\nin a RAG-based (Retrieval-Augmented Generation) model to reason about multiple\ndownstream dialogue tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.03049v1",
    "published_date": "2024-10-04 00:08:46 UTC",
    "updated_date": "2024-10-04 00:08:46 UTC"
  }
]