[
  {
    "arxiv_id": "2412.03773v1",
    "title": "Modular addition without black-boxes: Compressing explanations of MLPs that compute numerical integration",
    "authors": [
      "Chun Hei Yip",
      "Rajashree Agrawal",
      "Lawrence Chan",
      "Jason Gross"
    ],
    "abstract": "The goal of mechanistic interpretability is discovering simpler, low-rank\nalgorithms implemented by models. While we can compress activations into\nfeatures, compressing nonlinear feature-maps -- like MLP layers -- is an open\nproblem. In this work, we present the first case study in rigorously\ncompressing nonlinear feature-maps, which are the leading asymptotic bottleneck\nto compressing small transformer models. We work in the classic setting of the\nmodular addition models, and target a non-vacuous bound on the behaviour of the\nReLU MLP in time linear in the parameter-count of the circuit. To study the\nReLU MLP analytically, we use the infinite-width lens, which turns\npost-activation matrix multiplications into approximate integrals. We discover\na novel interpretation of} the MLP layer in one-layer transformers implementing\nthe ``pizza'' algorithm: the MLP can be understood as evaluating a quadrature\nscheme, where each neuron computes the area of a rectangle under the curve of a\ntrigonometric integral identity. Our code is available at\nhttps://tinyurl.com/mod-add-integration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03773v1",
    "published_date": "2024-12-04 23:29:07 UTC",
    "updated_date": "2024-12-04 23:29:07 UTC"
  },
  {
    "arxiv_id": "2412.03772v1",
    "title": "A Contemporary Overview: Trends and Applications of Large Language Models on Mobile Devices",
    "authors": [
      "Lianjun Liu",
      "Hongli An",
      "Pengxuan Chen",
      "Longxiang Ye"
    ],
    "abstract": "With the rapid development of large language models (LLMs), which possess\npowerful natural language processing and generation capabilities, LLMs are\npoised to provide more natural and personalized user experiences. Their\ndeployment on mobile devices is gradually becoming a significant trend in the\nfield of intelligent devices. LLMs have demonstrated tremendous potential in\napplications such as voice assistants, real-time translation, and intelligent\nrecommendations. Advancements in hardware technologies (such as neural network\naccelerators) and network infrastructure (such as 5G) have enabled efficient\nlocal inference and low-latency intelligent responses on mobile devices. This\nreduces reliance on cloud computing while enhancing data privacy and security.\nDevelopers can easily integrate LLM functionalities through open APIs and SDKs,\nenabling the creation of more innovative intelligent applications. The\nwidespread use of LLMs not only enhances the intelligence of mobile devices but\nalso fosters the integrated innovation of fields like augmented reality (AR)\nand the Internet of Things (IoT). This trend is expected to drive the\ndevelopment of the next generation of mobile intelligent applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03772v1",
    "published_date": "2024-12-04 23:25:03 UTC",
    "updated_date": "2024-12-04 23:25:03 UTC"
  },
  {
    "arxiv_id": "2412.03761v1",
    "title": "Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks",
    "authors": [
      "Ximing Wen"
    ],
    "abstract": "Pretrained transformer-based Language Models (LMs) are well-known for their\nability to achieve significant improvement on NLP tasks, but their black-box\nnature, which leads to a lack of interpretability, has been a major concern. My\ndissertation focuses on developing intrinsically interpretable models when\nusing LMs as encoders while maintaining their superior performance via\nprototypical networks. I initiated my research by investigating enhancements in\nperformance for interpretable models of sarcasm detection. My proposed approach\nfocuses on capturing sentiment incongruity to enhance accuracy while offering\ninstance-based explanations for the classification decisions. Later, I\ndeveloped a novel white-box multi-head graph attention-based prototype network\ndesigned to explain the decisions of text classification models without\nsacrificing the accuracy of the original black-box LMs. In addition, I am\nworking on extending the attention-based prototype network with contrastive\nlearning to redesign an interpretable graph neural network, aiming to enhance\nboth the interpretability and performance of the model in document\nclassification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "2 pages, 1 figure, accepted by AAAI25 DC",
    "pdf_url": "http://arxiv.org/pdf/2412.03761v1",
    "published_date": "2024-12-04 22:59:35 UTC",
    "updated_date": "2024-12-04 22:59:35 UTC"
  },
  {
    "arxiv_id": "2412.03756v1",
    "title": "Multi-view Image Diffusion via Coordinate Noise and Fourier Attention",
    "authors": [
      "Justin Theiss",
      "Norman MÃ¼ller",
      "Daeil Kim",
      "Aayush Prakash"
    ],
    "abstract": "Recently, text-to-image generation with diffusion models has made significant\nadvancements in both higher fidelity and generalization capabilities compared\nto previous baselines. However, generating holistic multi-view consistent\nimages from prompts still remains an important and challenging task. To address\nthis challenge, we propose a diffusion process that attends to time-dependent\nspatial frequencies of features with a novel attention mechanism as well as\nnovel noise initialization technique and cross-attention loss. This\nFourier-based attention block focuses on features from non-overlapping regions\nof the generated scene in order to better align the global appearance. Our\nnoise initialization technique incorporates shared noise and low spatial\nfrequency information derived from pixel coordinates and depth maps to induce\nnoise correlations across views. The cross-attention loss further aligns\nfeatures sharing the same prompt across the scene. Our technique improves SOTA\non several quantitative metrics with qualitatively better results when compared\nto other state-of-the-art approaches for multi-view consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03756v1",
    "published_date": "2024-12-04 22:49:40 UTC",
    "updated_date": "2024-12-04 22:49:40 UTC"
  },
  {
    "arxiv_id": "2412.03752v2",
    "title": "Beyond Local Sharpness: Communication-Efficient Global Sharpness-aware Minimization for Federated Learning",
    "authors": [
      "Debora Caldarola",
      "Pietro Cagnasso",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training with privacy\npreservation. Data heterogeneity across edge devices (clients) can cause models\nto converge to sharp minima, negatively impacting generalization and\nrobustness. Recent approaches use client-side sharpness-aware minimization\n(SAM) to encourage flatter minima, but the discrepancy between local and global\nloss landscapes often undermines their effectiveness, as optimizing for local\nsharpness does not ensure global flatness. This work introduces FedGloSS\n(Federated Global Server-side Sharpness), a novel FL approach that prioritizes\nthe optimization of global sharpness on the server, using SAM. To reduce\ncommunication overhead, FedGloSS cleverly approximates sharpness using the\nprevious global gradient, eliminating the need for additional client\ncommunication. Our extensive evaluations demonstrate that FedGloSS consistently\nreaches flatter minima and better performance compared to state-of-the-art FL\nmethods across various federated vision benchmarks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CVPR 2025, 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.03752v2",
    "published_date": "2024-12-04 22:46:06 UTC",
    "updated_date": "2025-03-30 21:09:13 UTC"
  },
  {
    "arxiv_id": "2412.03745v1",
    "title": "Deep Variational Bayesian Modeling of Haze Degradation Process",
    "authors": [
      "Eun Woo Im",
      "Junsung Shin",
      "Sungyong Baik",
      "Tae Hyun Kim"
    ],
    "abstract": "Relying on the representation power of neural networks, most recent works\nhave often neglected several factors involved in haze degradation, such as\ntransmission (the amount of light reaching an observer from a scene over\ndistance) and atmospheric light. These factors are generally unknown, making\ndehazing problems ill-posed and creating inherent uncertainties. To account for\nsuch uncertainties and factors involved in haze degradation, we introduce a\nvariational Bayesian framework for single image dehazing. We propose to take\nnot only a clean image and but also transmission map as latent variables, the\nposterior distributions of which are parameterized by corresponding neural\nnetworks: dehazing and transmission networks, respectively. Based on a physical\nmodel for haze degradation, our variational Bayesian framework leads to a new\nobjective function that encourages the cooperation between them, facilitating\nthe joint training of and thereby boosting the performance of each other. In\nour framework, a dehazing network can estimate a clean image independently of a\ntransmission map estimation during inference, introducing no overhead.\nFurthermore, our model-agnostic framework can be seamlessly incorporated with\nother existing dehazing networks, greatly enhancing the performance\nconsistently across datasets and models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in CIKM 2023, 10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03745v1",
    "published_date": "2024-12-04 22:24:37 UTC",
    "updated_date": "2024-12-04 22:24:37 UTC"
  },
  {
    "arxiv_id": "2412.03740v1",
    "title": "Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety",
    "authors": [
      "Dilan Mian"
    ],
    "abstract": "The world can be a complex and difficult place to navigate. People with\nHigh-Functioning Autistic Spectrum Disorder as well as general social\nineptitude often face navigation challenges that individuals of other\ndemographics simply do not themselves. This can become even more pronounced\nwith people of that specific group when they are in their teenage years and\nearly adulthood (that being the usual age range of college students). When they\nare at such a vulnerable age, they can be far more susceptible to the struggles\nof becoming comfortable and content with social interactions as well as having\nstrong relationships (outside their immediate family). Concerning this, the\nrapid emergence of artificial intelligence chatbots has led to many of them\nbeing used to benefit people of different ages and demographics with easy\naccessibility. With this, if there is anything that people with\nHigh-Functioning ASD and social ineptitude want when it comes to guidance\ntowards self-improvement, surely easy accessibility would be one. What are the\npotential benefits and limitations of using a Mindstudio AI-powered chatbot to\nprovide mental health support for teens and young adults with the\naforementioned conditions? What could be done with a tool like this to help\nthose individuals navigate ethical dilemmas within different social\nenvironments to reduce existing social tensions? This paper addresses these\nqueries and offers insights to inform future discussions on the subject.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, 30 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03740v1",
    "published_date": "2024-12-04 22:10:58 UTC",
    "updated_date": "2024-12-04 22:10:58 UTC"
  },
  {
    "arxiv_id": "2412.03719v1",
    "title": "From Language Models over Tokens to Language Models over Characters",
    "authors": [
      "Tim Vieira",
      "Ben LeBrun",
      "Mario Giulianelli",
      "Juan Luis Gastaldi",
      "Brian DuSell",
      "John Terilla",
      "Timothy J. O'Donnell",
      "Ryan Cotterell"
    ],
    "abstract": "Modern language models are internally -- and mathematically -- distributions\nover token strings rather than \\emph{character} strings, posing numerous\nchallenges for programmers building user applications on top of them. For\nexample, if a prompt is specified as a character string, it must be tokenized\nbefore passing it to the token-level language model. Thus, the tokenizer and\nconsequent analyses are very sensitive to the specification of the prompt\n(e.g., if the prompt ends with a space or not). This paper presents algorithms\nfor converting token-level language models to character-level ones. We present\nboth exact and approximate algorithms. In the empirical portion of the paper,\nwe benchmark the practical runtime and approximation quality. We find that --\neven with a small computation budget -- our method is able to accurately\napproximate the character-level distribution (less than 0.00021 excess bits /\ncharacter) at reasonably fast speeds (46.3 characters / second) on the Llama\n3.1 8B language model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03719v1",
    "published_date": "2024-12-04 21:19:20 UTC",
    "updated_date": "2024-12-04 21:19:20 UTC"
  },
  {
    "arxiv_id": "2412.03718v2",
    "title": "ParetoFlow: Guided Flows in Multi-Objective Optimization",
    "authors": [
      "Ye Yuan",
      "Can Chen",
      "Christopher Pal",
      "Xue Liu"
    ],
    "abstract": "In offline multi-objective optimization (MOO), we leverage an offline dataset\nof designs and their associated labels to simultaneously minimize multiple\nobjectives. This setting more closely mirrors complex real-world problems\ncompared to single-objective optimization. Recent works mainly employ\nevolutionary algorithms and Bayesian optimization, with limited attention given\nto the generative modeling capabilities inherent in such data. In this study,\nwe explore generative modeling in offline MOO through flow matching, noted for\nits effectiveness and efficiency. We introduce ParetoFlow, specifically\ndesigned to guide flow sampling to approximate the Pareto front. Traditional\npredictor (classifier) guidance is inadequate for this purpose because it\nmodels only a single objective. In response, we propose a multi-objective\npredictor guidance module that assigns each sample a weight vector,\nrepresenting a weighted distribution across multiple objective predictions. A\nlocal filtering scheme is introduced to address non-convex Pareto fronts. These\nweights uniformly cover the entire objective space, effectively directing\nsample generation towards the Pareto front. Since distributions with similar\nweights tend to generate similar samples, we introduce a neighboring evolution\nmodule to foster knowledge sharing among neighboring distributions. This module\ngenerates offspring from these distributions, and selects the most promising\none for the next iteration. Our method achieves state-of-the-art performance\nacross various tasks.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03718v2",
    "published_date": "2024-12-04 21:14:18 UTC",
    "updated_date": "2025-02-20 13:31:09 UTC"
  },
  {
    "arxiv_id": "2412.03715v1",
    "title": "PathletRL++: Optimizing Trajectory Pathlet Extraction and Dictionary Formation via Reinforcement Learning",
    "authors": [
      "Gian Alix",
      "Arian Haghparast",
      "Manos Papagelis"
    ],
    "abstract": "Advances in tracking technologies have spurred the rapid growth of\nlarge-scale trajectory data. Building a compact collection of pathlets,\nreferred to as a trajectory pathlet dictionary, is essential for supporting\nmobility-related applications. Existing methods typically adopt a top-down\napproach, generating numerous candidate pathlets and selecting a subset,\nleading to high memory usage and redundant storage from overlapping pathlets.\nTo overcome these limitations, we propose a bottom-up strategy that\nincrementally merges basic pathlets to build the dictionary, reducing memory\nrequirements by up to 24,000 times compared to baseline methods. The approach\nbegins with unit-length pathlets and iteratively merges them while optimizing\nutility, which is defined using newly introduced metrics of trajectory loss and\nrepresentability. We develop a deep reinforcement learning framework,\nPathletRL, which utilizes Deep Q-Networks (DQN) to approximate the utility\nfunction, resulting in a compact and efficient pathlet dictionary. Experiments\non both synthetic and real-world datasets demonstrate that our method\noutperforms state-of-the-art techniques, reducing the size of the constructed\ndictionary by up to 65.8%. Additionally, our results show that only half of the\ndictionary pathlets are needed to reconstruct 85% of the original trajectory\ndata. Building on PathletRL, we introduce PathletRL++, which extends the\noriginal model by incorporating a richer state representation and an improved\nreward function to optimize decision-making during pathlet merging. These\nenhancements enable the agent to gain a more nuanced understanding of the\nenvironment, leading to higher-quality pathlet dictionaries. PathletRL++\nachieves even greater dictionary size reduction, surpassing the performance of\nPathletRL, while maintaining high trajectory representability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03715v1",
    "published_date": "2024-12-04 21:09:43 UTC",
    "updated_date": "2024-12-04 21:09:43 UTC"
  },
  {
    "arxiv_id": "2412.03710v2",
    "title": "CIKAN: Constraint Informed Kolmogorov-Arnold Networks for Autonomous Spacecraft Rendezvous using Time Shift Governor",
    "authors": [
      "Taehyeun Kim",
      "Anouck Girard",
      "Ilya Kolmanovsky"
    ],
    "abstract": "The paper considers a Constrained-Informed Neural Network (CINN)\napproximation for the Time Shift Governor (TSG), which is an add-on scheme to\nthe nominal closed-loop system used to enforce constraints by time-shifting the\nreference trajectory in spacecraft rendezvous applications. We incorporate\nKolmogorov-Arnold Networks (KANs), an emerging architecture in the AI\ncommunity, as a fundamental component of CINN and propose a\nConstrained-Informed Kolmogorov-Arnold Network (CIKAN)-based approximation for\nTSG. We demonstrate the effectiveness of the CIKAN-based TSG through\nsimulations of constrained spacecraft rendezvous missions on highly elliptic\norbits and present comparisons between CIKANs, MLP-based CINNs, and the\nconventional TSG.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03710v2",
    "published_date": "2024-12-04 20:58:06 UTC",
    "updated_date": "2024-12-06 19:09:56 UTC"
  },
  {
    "arxiv_id": "2412.03693v1",
    "title": "System Test Case Design from Requirements Specifications: Insights and Challenges of Using ChatGPT",
    "authors": [
      "Shreya Bhatia",
      "Tarushi Gandhi",
      "Dhruv Kumar",
      "Pankaj Jalote"
    ],
    "abstract": "System testing is essential in any software development project to ensure\nthat the final products meet the requirements. Creating comprehensive test\ncases for system testing from requirements is often challenging and\ntime-consuming. This paper explores the effectiveness of using Large Language\nModels (LLMs) to generate test case designs from Software Requirements\nSpecification (SRS) documents. In this study, we collected the SRS documents of\nfive software engineering projects containing functional and non-functional\nrequirements, which were implemented, tested, and delivered by respective\ndeveloper teams. For generating test case designs, we used ChatGPT-4o Turbo\nmodel. We employed prompt-chaining, starting with an initial context-setting\nprompt, followed by prompts to generate test cases for each use case. We\nassessed the quality of the generated test case designs through feedback from\nthe same developer teams as mentioned above. Our experiments show that about 87\npercent of the generated test cases were valid, with the remaining 13 percent\neither not applicable or redundant. Notably, 15 percent of the valid test cases\nwere previously not considered by developers in their testing. We also tasked\nChatGPT with identifying redundant test cases, which were subsequently\nvalidated by the respective developers to identify false positives and to\nuncover any redundant test cases that may have been missed by the developers\nthemselves. This study highlights the potential of leveraging LLMs for test\ngeneration from the Requirements Specification document and also for assisting\ndevelopers in quickly identifying and addressing redundancies, ultimately\nimproving test suite quality and efficiency of the testing procedure.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03693v1",
    "published_date": "2024-12-04 20:12:27 UTC",
    "updated_date": "2024-12-04 20:12:27 UTC"
  },
  {
    "arxiv_id": "2412.03689v1",
    "title": "Predicting Pedestrian Crossing Behavior in Germany and Japan: Insights into Model Transferability",
    "authors": [
      "Chi Zhang",
      "Janis Sprenger",
      "Zhongjun Ni",
      "Christian Berger"
    ],
    "abstract": "Predicting pedestrian crossing behavior is important for intelligent traffic\nsystems to avoid pedestrian-vehicle collisions. Most existing pedestrian\ncrossing behavior models are trained and evaluated on datasets collected from a\nsingle country, overlooking differences between countries. To address this gap,\nwe compared pedestrian road-crossing behavior at unsignalized crossings in\nGermany and Japan. We presented four types of machine learning models to\npredict gap selection behavior, zebra crossing usage, and their trajectories\nusing simulator data collected from both countries. When comparing the\ndifferences between countries, pedestrians from the study conducted in Japan\nare more cautious, selecting larger gaps compared to those in Germany. We\nevaluate and analyze model transferability. Our results show that neural\nnetworks outperform other machine learning models in predicting gap selection\nand zebra crossing usage, while random forest models perform best on trajectory\nprediction tasks, demonstrating strong performance and transferability. We\ndevelop a transferable model using an unsupervised clustering method, which\nimproves prediction accuracy for gap selection and trajectory prediction. These\nfindings provide a deeper understanding of pedestrian crossing behaviors in\ndifferent countries and offer valuable insights into model transferability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T40, 68T45",
      "I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 12 figures, 11 tables. Accepted in IEEE Transactions on\n  Intelligent Vehicles",
    "pdf_url": "http://arxiv.org/pdf/2412.03689v1",
    "published_date": "2024-12-04 19:55:40 UTC",
    "updated_date": "2024-12-04 19:55:40 UTC"
  },
  {
    "arxiv_id": "2412.03682v1",
    "title": "Designing DNNs for a trade-off between robustness and processing performance in embedded devices",
    "authors": [
      "Jon GutiÃ©rrez-Zaballa",
      "Koldo Basterretxea",
      "Javier Echanobe"
    ],
    "abstract": "Machine learning-based embedded systems employed in safety-critical\napplications such as aerospace and autonomous driving need to be robust against\nperturbations produced by soft errors. Soft errors are an increasing concern in\nmodern digital processors since smaller transistor geometries and lower\nvoltages give electronic devices a higher sensitivity to background radiation.\nThe resilience of deep neural network (DNN) models to perturbations in their\nparameters is determined, to a large extent, by the structure of the model\nitself, and also by the selected numerical representation and used arithmetic\nprecision. When compression techniques such as model pruning and model\nquantization are applied to reduce memory footprint and computational\ncomplexity for deployment, both model structure and numerical representation\nare modified and thus, soft error robustness also changes. In this sense,\nalthough the choice of activation functions (AFs) in DNN models is frequently\nignored, it conditions not only their accuracy and trainability, but also\ncompressibility rates and numerical robustness. This paper investigates the\nsuitability of using bounded AFs to improve model robustness against DNN\nparameter perturbations, assessing at the same time the impact of this choice\non deployment in terms of model accuracy, compressibility, and computational\nburden. In particular, we analyze encoder-decoder fully convolutional models\naimed at performing semantic segmentation tasks on hyperspectral images for\nscene understanding in autonomous driving. Deployment characterization is\nperformed experimentally on an AMD-Xilinx's KV260 SoM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03682v1",
    "published_date": "2024-12-04 19:34:33 UTC",
    "updated_date": "2024-12-04 19:34:33 UTC"
  },
  {
    "arxiv_id": "2412.03676v1",
    "title": "JPC: Flexible Inference for Predictive Coding Networks in JAX",
    "authors": [
      "Francesco Innocenti",
      "Paul Kinghorn",
      "Will Yun-Farmbrough",
      "Miguel De Llanza Varona",
      "Ryan Singh",
      "Christopher L. Buckley"
    ],
    "abstract": "We introduce JPC, a JAX library for training neural networks with Predictive\nCoding. JPC provides a simple, fast and flexible interface to train a variety\nof PC networks (PCNs) including discriminative, generative and hybrid models.\nUnlike existing libraries, JPC leverages ordinary differential equation solvers\nto integrate the gradient flow inference dynamics of PCNs. We find that a\nsecond-order solver achieves significantly faster runtimes compared to standard\nEuler integration, with comparable performance on a range of tasks and network\ndepths. JPC also provides some theoretical tools that can be used to study\nPCNs. We hope that JPC will facilitate future research of PC. The code is\navailable at https://github.com/thebuckleylab/jpc.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03676v1",
    "published_date": "2024-12-04 19:15:34 UTC",
    "updated_date": "2024-12-04 19:15:34 UTC"
  },
  {
    "arxiv_id": "2412.03671v1",
    "title": "Tight Lower Bounds and Improved Convergence in Performative Prediction",
    "authors": [
      "Pedram Khorsandi",
      "Rushil Gupta",
      "Mehrnaz Mofakhami",
      "Simon Lacoste-Julien",
      "Gauthier Gidel"
    ],
    "abstract": "Performative prediction is a framework accounting for the shift in the data\ndistribution induced by the prediction of a model deployed in the real world.\nEnsuring rapid convergence to a stable solution where the data distribution\nremains the same after the model deployment is crucial, especially in evolving\nenvironments. This paper extends the Repeated Risk Minimization (RRM) framework\nby utilizing historical datasets from previous retraining snapshots, yielding a\nclass of algorithms that we call Affine Risk Minimizers and enabling\nconvergence to a performatively stable point for a broader class of problems.\nWe introduce a new upper bound for methods that use only the final iteration of\nthe dataset and prove for the first time the tightness of both this new bound\nand the previous existing bounds within the same regime. We also prove that\nutilizing historical datasets can surpass the lower bound for last iterate RRM,\nand empirically observe faster convergence to the stable point on various\nperformative prediction benchmarks. We offer at the same time the first lower\nbound analysis for RRM within the class of Affine Risk Minimizers, quantifying\nthe potential improvements in convergence speed that could be achieved with\nother variants in our framework.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03671v1",
    "published_date": "2024-12-04 19:06:19 UTC",
    "updated_date": "2024-12-04 19:06:19 UTC"
  },
  {
    "arxiv_id": "2412.03665v1",
    "title": "Personalizing Multimodal Large Language Models for Image Captioning: An Experimental Analysis",
    "authors": [
      "Davide Bucciarelli",
      "Nicholas Moratelli",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "The task of image captioning demands an algorithm to generate natural\nlanguage descriptions of visual inputs. Recent advancements have seen a\nconvergence between image captioning research and the development of Large\nLanguage Models (LLMs) and Multimodal LLMs -- like GPT-4V and Gemini -- which\nextend the capabilities of text-only LLMs to multiple modalities. This paper\ninvestigates whether Multimodal LLMs can supplant traditional image captioning\nnetworks by evaluating their performance on various image description\nbenchmarks. We explore both the zero-shot capabilities of these models and\ntheir adaptability to different semantic domains through fine-tuning methods,\nincluding prompt learning, prefix tuning, and low-rank adaptation. Our results\ndemonstrate that while Multimodal LLMs achieve impressive zero-shot\nperformance, fine-tuning for specific domains while maintaining their\ngeneralization capabilities intact remains challenging. We discuss the\nimplications of these findings for future research in image captioning and the\ndevelopment of more adaptable Multimodal LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024 Workshop on Green Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2412.03665v1",
    "published_date": "2024-12-04 19:01:06 UTC",
    "updated_date": "2024-12-04 19:01:06 UTC"
  },
  {
    "arxiv_id": "2412.03572v2",
    "title": "Navigation World Models",
    "authors": [
      "Amir Bar",
      "Gaoyue Zhou",
      "Danny Tran",
      "Trevor Darrell",
      "Yann LeCun"
    ],
    "abstract": "Navigation is a fundamental skill of agents with visual-motor capabilities.\nWe introduce a Navigation World Model (NWM), a controllable video generation\nmodel that predicts future visual observations based on past observations and\nnavigation actions. To capture complex environment dynamics, NWM employs a\nConditional Diffusion Transformer (CDiT), trained on a diverse collection of\negocentric videos of both human and robotic agents, and scaled up to 1 billion\nparameters. In familiar environments, NWM can plan navigation trajectories by\nsimulating them and evaluating whether they achieve the desired goal. Unlike\nsupervised navigation policies with fixed behavior, NWM can dynamically\nincorporate constraints during planning. Experiments demonstrate its\neffectiveness in planning trajectories from scratch or by ranking trajectories\nsampled from an external policy. Furthermore, NWM leverages its learned visual\npriors to imagine trajectories in unfamiliar environments from a single input\nimage, making it a flexible and powerful tool for next-generation navigation\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Project page: https://www.amirbar.net/nwm/",
    "pdf_url": "http://arxiv.org/pdf/2412.03572v2",
    "published_date": "2024-12-04 18:59:45 UTC",
    "updated_date": "2025-04-11 19:20:22 UTC"
  },
  {
    "arxiv_id": "2412.03568v1",
    "title": "The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control",
    "authors": [
      "Ruili Feng",
      "Han Zhang",
      "Zhantao Yang",
      "Jie Xiao",
      "Zhilei Shu",
      "Zhiheng Liu",
      "Andy Zheng",
      "Yukun Huang",
      "Yu Liu",
      "Hongyang Zhang"
    ],
    "abstract": "We present The Matrix, the first foundational realistic world simulator\ncapable of generating continuous 720p high-fidelity real-scene video streams\nwith real-time, responsive control in both first- and third-person\nperspectives, enabling immersive exploration of richly dynamic environments.\nTrained on limited supervised data from AAA games like Forza Horizon 5 and\nCyberpunk 2077, complemented by large-scale unsupervised footage from\nreal-world settings like Tokyo streets, The Matrix allows users to traverse\ndiverse terrains -- deserts, grasslands, water bodies, and urban landscapes --\nin continuous, uncut hour-long sequences. Operating at 16 FPS, the system\nsupports real-time interactivity and demonstrates zero-shot generalization,\ntranslating virtual game environments to real-world contexts where collecting\ncontinuous movement data is often infeasible. For example, The Matrix can\nsimulate a BMW X3 driving through an office setting--an environment present in\nneither gaming data nor real-world sources. This approach showcases the\npotential of AAA game data to advance robust world models, bridging the gap\nbetween simulations and real-world applications in scenarios with limited data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03568v1",
    "published_date": "2024-12-04 18:59:05 UTC",
    "updated_date": "2024-12-04 18:59:05 UTC"
  },
  {
    "arxiv_id": "2412.03561v1",
    "title": "FLAIR: VLM with Fine-grained Language-informed Image Representations",
    "authors": [
      "Rui Xiao",
      "Sanghwan Kim",
      "Mariana-Iuliana Georgescu",
      "Zeynep Akata",
      "Stephan Alaniz"
    ],
    "abstract": "CLIP has shown impressive results in aligning images and texts at scale.\nHowever, its ability to capture detailed visual features remains limited\nbecause CLIP matches images and texts at a global level. To address this issue,\nwe propose FLAIR, Fine-grained Language-informed Image Representations, an\napproach that utilizes long and detailed image descriptions to learn localized\nimage embeddings. By sampling diverse sub-captions that describe fine-grained\ndetails about an image, we train our vision-language model to produce not only\nglobal embeddings but also text-specific image representations. Our model\nintroduces text-conditioned attention pooling on top of local image tokens to\nproduce fine-grained image representations that excel at retrieving detailed\nimage content. We achieve state-of-the-art performance on both, existing\nmultimodal retrieval benchmarks, as well as, our newly introduced fine-grained\nretrieval task which evaluates vision-language models' ability to retrieve\npartial image content. Furthermore, our experiments demonstrate the\neffectiveness of FLAIR trained on 30M image-text pairs in capturing\nfine-grained visual information, including zero-shot semantic segmentation,\noutperforming models trained on billions of pairs. Code is available at\nhttps://github.com/ExplainableML/flair .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03561v1",
    "published_date": "2024-12-04 18:56:04 UTC",
    "updated_date": "2024-12-04 18:56:04 UTC"
  },
  {
    "arxiv_id": "2412.03556v2",
    "title": "Best-of-N Jailbreaking",
    "authors": [
      "John Hughes",
      "Sara Price",
      "Aengus Lynch",
      "Rylan Schaeffer",
      "Fazl Barez",
      "Sanmi Koyejo",
      "Henry Sleight",
      "Erik Jones",
      "Ethan Perez",
      "Mrinank Sharma"
    ],
    "abstract": "We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that\njailbreaks frontier AI systems across modalities. BoN Jailbreaking works by\nrepeatedly sampling variations of a prompt with a combination of augmentations\n- such as random shuffling or capitalization for textual prompts - until a\nharmful response is elicited. We find that BoN Jailbreaking achieves high\nattack success rates (ASRs) on closed-source language models, such as 89% on\nGPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.\nFurther, it is similarly effective at circumventing state-of-the-art\nopen-source defenses like circuit breakers. BoN also seamlessly extends to\nother modalities: it jailbreaks vision language models (VLMs) such as GPT-4o\nand audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific\naugmentations. BoN reliably improves when we sample more augmented prompts.\nAcross all modalities, ASR, as a function of the number of samples (N),\nempirically follows power-law-like behavior for many orders of magnitude. BoN\nJailbreaking can also be composed with other black-box algorithms for even more\neffective attacks - combining BoN with an optimized prefix attack achieves up\nto a 35% increase in ASR. Overall, our work indicates that, despite their\ncapability, language models are sensitive to seemingly innocuous changes to\ninputs, which attackers can exploit across modalities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03556v2",
    "published_date": "2024-12-04 18:51:32 UTC",
    "updated_date": "2024-12-19 22:37:45 UTC"
  },
  {
    "arxiv_id": "2412.03548v2",
    "title": "Perception Tokens Enhance Visual Reasoning in Multimodal Language Models",
    "authors": [
      "Mahtab Bigverdi",
      "Zelun Luo",
      "Cheng-Yu Hsieh",
      "Ethan Shen",
      "Dongping Chen",
      "Linda G. Shapiro",
      "Ranjay Krishna"
    ],
    "abstract": "Multimodal language models (MLMs) still face challenges in fundamental visual\nperception tasks where specialized models excel. Tasks requiring reasoning\nabout 3D structures benefit from depth estimation, and reasoning about 2D\nobject instances benefits from object detection. Yet, MLMs can not produce\nintermediate depth or boxes to reason over. Finetuning MLMs on relevant data\ndoesn't generalize well and outsourcing computation to specialized vision tools\nis too compute-intensive and memory-inefficient. To address this, we introduce\nPerception Tokens, intrinsic image representations designed to assist reasoning\ntasks where language is insufficient. Perception tokens act as auxiliary\nreasoning tokens, akin to chain-of-thought prompts in language models. For\nexample, in a depth-related task, an MLM augmented with perception tokens can\nreason by generating a depth map as tokens, enabling it to solve the problem\neffectively. We propose AURORA, a training method that augments MLMs with\nperception tokens for improved reasoning over visual inputs. AURORA leverages a\nVQVAE to transform intermediate image representations, such as depth maps into\na tokenized format and bounding box tokens, which is then used in a multi-task\ntraining framework. AURORA achieves notable improvements across counting\nbenchmarks: +10.8% on BLINK, +11.3% on CVBench, and +8.3% on SEED-Bench,\noutperforming finetuning approaches in generalization across datasets. It also\nimproves on relative depth: over +6% on BLINK. With perception tokens, AURORA\nexpands the scope of MLMs beyond language-based reasoning, paving the way for\nmore effective visual reasoning capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03548v2",
    "published_date": "2024-12-04 18:45:35 UTC",
    "updated_date": "2024-12-08 05:18:30 UTC"
  },
  {
    "arxiv_id": "2412.03539v2",
    "title": "NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model",
    "authors": [
      "Xinheng Xie",
      "Yue Wu",
      "Cuiyu He"
    ],
    "abstract": "Understanding adversarial examples is crucial for improving model robustness,\nas they introduce imperceptible perturbations to deceive models. Effective\nadversarial examples, therefore, offer the potential to train more robust\nmodels by eliminating model singularities. We propose NODE-AdvGAN, a novel\napproach that treats adversarial generation as a continuous process and employs\na Neural Ordinary Differential Equation (NODE) to simulate generator dynamics.\nBy mimicking the iterative nature of traditional gradient-based methods,\nNODE-AdvGAN generates smoother and more precise perturbations that preserve\nhigh perceptual similarity when added to benign images. We also propose a new\ntraining strategy, NODE-AdvGAN-T, which enhances transferability in black-box\nattacks by tuning the noise parameters during training. Experiments demonstrate\nthat NODE-AdvGAN and NODE-AdvGAN-T generate more effective adversarial examples\nthat achieve higher attack success rates while preserving better perceptual\nquality than baseline models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03539v2",
    "published_date": "2024-12-04 18:36:09 UTC",
    "updated_date": "2025-04-13 22:02:59 UTC"
  },
  {
    "arxiv_id": "2412.03537v1",
    "title": "Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models",
    "authors": [
      "Natalie Mackraz",
      "Nivedha Sivakumar",
      "Samira Khorshidi",
      "Krishna Patel",
      "Barry-John Theobald",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "abstract": "Large language models (LLMs) are increasingly being adapted to achieve\ntask-specificity for deployment in real-world decision systems. Several\nprevious works have investigated the bias transfer hypothesis (BTH) by studying\nthe effect of the fine-tuning adaptation strategy on model fairness to find\nthat fairness in pre-trained masked language models have limited effect on the\nfairness of models when adapted using fine-tuning. In this work, we expand the\nstudy of BTH to causal models under prompt adaptations, as prompting is an\naccessible, and compute-efficient way to deploy models in real-world systems.\nIn contrast to previous works, we establish that intrinsic biases in\npre-trained Mistral, Falcon and Llama models are strongly correlated (rho >=\n0.94) with biases when the same models are zero- and few-shot prompted, using a\npronoun co-reference resolution task. Further, we find that bias transfer\nremains strongly correlated even when LLMs are specifically prompted to exhibit\nfair or biased behavior (rho >= 0.92), and few-shot length and stereotypical\ncomposition are varied (rho >= 0.97). Our findings highlight the importance of\nensuring fairness in pre-trained LLMs, especially when they are later used to\nperform downstream tasks via prompt adaptation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03537v1",
    "published_date": "2024-12-04 18:32:42 UTC",
    "updated_date": "2024-12-04 18:32:42 UTC"
  },
  {
    "arxiv_id": "2412.03630v1",
    "title": "Evaluating Single Event Upsets in Deep Neural Networks for Semantic Segmentation: an embedded system perspective",
    "authors": [
      "Jon GutiÃ©rrez-Zaballa",
      "Koldo Basterretxea",
      "Javier Echanobe"
    ],
    "abstract": "As the deployment of artifical intelligence (AI) algorithms at edge devices\nbecomes increasingly prevalent, enhancing the robustness and reliability of\nautonomous AI-based perception and decision systems is becoming as relevant as\nprecision and performance, especially in applications areas considered\nsafety-critical such as autonomous driving and aerospace. This paper delves\ninto the robustness assessment in embedded Deep Neural Networks (DNNs),\nparticularly focusing on the impact of parameter perturbations produced by\nsingle event upsets (SEUs) on convolutional neural networks (CNN) for image\nsemantic segmentation. By scrutinizing the layer-by-layer and bit-by-bit\nsensitivity of various encoder-decoder models to soft errors, this study\nthoroughly investigates the vulnerability of segmentation DNNs to SEUs and\nevaluates the consequences of techniques like model pruning and parameter\nquantization on the robustness of compressed models aimed at embedded\nimplementations. The findings offer valuable insights into the mechanisms\nunderlying SEU-induced failures that allow for evaluating the robustness of\nDNNs once trained in advance. Moreover, based on the collected data, we propose\na set of practical lightweight error mitigation techniques with no memory or\ncomputational cost suitable for resource-constrained deployments. The code used\nto perform the fault injection (FI) campaign is available at\nhttps://github.com/jonGuti13/TensorFI2 , while the code to implement proposed\ntechniques is available at https://github.com/jonGuti13/parameterProtection .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.AR",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03630v1",
    "published_date": "2024-12-04 18:28:38 UTC",
    "updated_date": "2024-12-04 18:28:38 UTC"
  },
  {
    "arxiv_id": "2412.03526v2",
    "title": "Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos",
    "authors": [
      "Hanxue Liang",
      "Jiawei Ren",
      "Ashkan Mirzaei",
      "Antonio Torralba",
      "Ziwei Liu",
      "Igor Gilitschenski",
      "Sanja Fidler",
      "Cengiz Oztireli",
      "Huan Ling",
      "Zan Gojcic",
      "Jiahui Huang"
    ],
    "abstract": "Recent advancements in static feed-forward scene reconstruction have\ndemonstrated significant progress in high-quality novel view synthesis.\nHowever, these models often struggle with generalizability across diverse\nenvironments and fail to effectively handle dynamic content. We present BTimer\n(short for BulletTimer), the first motion-aware feed-forward model for\nreal-time reconstruction and novel view synthesis of dynamic scenes. Our\napproach reconstructs the full scene in a 3D Gaussian Splatting representation\nat a given target ('bullet') timestamp by aggregating information from all the\ncontext frames. Such a formulation allows BTimer to gain scalability and\ngeneralization by leveraging both static and dynamic scene datasets. Given a\ncasual monocular dynamic video, BTimer reconstructs a bullet-time scene within\n150ms while reaching state-of-the-art performance on both static and dynamic\nscene datasets, even compared with optimization-based approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website:\n  https://research.nvidia.com/labs/toronto-ai/bullet-timer/",
    "pdf_url": "http://arxiv.org/pdf/2412.03526v2",
    "published_date": "2024-12-04 18:15:06 UTC",
    "updated_date": "2025-04-01 06:04:34 UTC"
  },
  {
    "arxiv_id": "2412.03516v1",
    "title": "You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?",
    "authors": [
      "Dominic Lohr",
      "Hieke Keuning",
      "Natalie Kiesler"
    ],
    "abstract": "Background: Feedback as one of the most influential factors for learning has\nbeen subject to a great body of research. It plays a key role in the\ndevelopment of educational technology systems and is traditionally rooted in\ndeterministic feedback defined by experts and their experience. However, with\nthe rise of generative AI and especially Large Language Models (LLMs), we\nexpect feedback as part of learning systems to transform, especially for the\ncontext of programming. In the past, it was challenging to automate feedback\nfor learners of programming. LLMs may create new possibilities to provide\nricher, and more individual feedback than ever before.\n  Objectives: This paper aims to generate specific types of feedback for\nintroductory programming tasks using LLMs. We revisit existing feedback\ntaxonomies to capture the specifics of the generated feedback, such as\nrandomness, uncertainty, and degrees of variation.\n  Methods: We iteratively designed prompts for the generation of specific\nfeedback types (as part of existing feedback taxonomies) in response to\nauthentic student programs. We then evaluated the generated output and\ndetermined to what extent it reflected certain feedback types.\n  Results and Conclusion: The present work provides a better understanding of\ndifferent feedback dimensions and characteristics. The results have\nimplications for future feedback research with regard to, for example, feedback\neffects and learners' informational needs. It further provides a basis for the\ndevelopment of new tools and learning systems for novice programmers including\nfeedback generated by AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at Journal of Computer Assisted Learning (2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.03516v1",
    "published_date": "2024-12-04 17:57:39 UTC",
    "updated_date": "2024-12-04 17:57:39 UTC"
  },
  {
    "arxiv_id": "2412.03513v2",
    "title": "Enhancing CLIP Conceptual Embedding through Knowledge Distillation",
    "authors": [
      "Kuei-Chun Kao"
    ],
    "abstract": "Recently, CLIP has become an important model for aligning images and text in\nmulti-modal contexts. However, researchers have identified limitations in the\nability of CLIP's text and image encoders to extract detailed knowledge from\npairs of captions and images. In response, this paper presents Knowledge-CLIP,\nan innovative approach designed to improve CLIP's performance by integrating a\nnew knowledge distillation (KD) method based on Llama 2. Our approach focuses\non three key objectives: Text Embedding Distillation, Concept Learning, and\nContrastive Learning. First, Text Embedding Distillation involves training the\nKnowledge-CLIP text encoder to mirror the teacher model, Llama 2. Next, Concept\nLearning assigns a soft concept label to each caption-image pair by employing\noffline K-means clustering on text data from Llama 2, enabling Knowledge-CLIP\nto learn from these soft concept labels. Lastly, Contrastive Learning aligns\nthe text and image embeddings. Our experimental findings show that the proposed\nmodel improves the performance of both text and image encoders.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03513v2",
    "published_date": "2024-12-04 17:56:49 UTC",
    "updated_date": "2024-12-07 13:01:13 UTC"
  },
  {
    "arxiv_id": "2412.03498v2",
    "title": "A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks",
    "authors": [
      "Proma Hossain Progga",
      "Md. Jobayer Rahman",
      "Swapnil Biswas",
      "Md. Shakil Ahmed",
      "Arif Reza Anwary",
      "Swakkhar Shatabda"
    ],
    "abstract": "Gait recognition is a significant biometric technique for person\nidentification, particularly in scenarios where other physiological biometrics\nare impractical or ineffective. In this paper, we address the challenges\nassociated with gait recognition and present a novel approach to improve its\naccuracy and reliability. The proposed method leverages advanced techniques,\nincluding sequential gait landmarks obtained through the Mediapipe pose\nestimation model, Procrustes analysis for alignment, and a Siamese\nbiGRU-dualStack Neural Network architecture for capturing temporal\ndependencies. Extensive experiments were conducted on large-scale cross-view\ndatasets to demonstrate the effectiveness of the approach, achieving high\nrecognition accuracy compared to other models. The model demonstrated\naccuracies of 95.7%, 94.44%, 87.71%, and 86.6% on CASIA-B, SZU RGB-D, OU-MVLP,\nand Gait3D datasets respectively. The results highlight the potential\napplications of the proposed method in various practical domains, indicating\nits significant contribution to the field of gait recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03498v2",
    "published_date": "2024-12-04 17:39:55 UTC",
    "updated_date": "2024-12-05 03:47:49 UTC"
  },
  {
    "arxiv_id": "2412.03487v1",
    "title": "Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective",
    "authors": [
      "Neta Shaul",
      "Itai Gat",
      "Marton Havasi",
      "Daniel Severo",
      "Anuroop Sriram",
      "Peter Holderrieth",
      "Brian Karrer",
      "Yaron Lipman",
      "Ricky T. Q. Chen"
    ],
    "abstract": "The design space of discrete-space diffusion or flow generative models are\nsignificantly less well-understood than their continuous-space counterparts,\nwith many works focusing only on a simple masked construction. In this work, we\naim to take a holistic approach to the construction of discrete generative\nmodels based on continuous-time Markov chains, and for the first time, allow\nthe use of arbitrary discrete probability paths, or colloquially, corruption\nprocesses. Through the lens of optimizing the symmetric kinetic energy, we\npropose velocity formulas that can be applied to any given probability path,\ncompletely decoupling the probability and velocity, and giving the user the\nfreedom to specify any desirable probability path based on expert knowledge\nspecific to the data domain. Furthermore, we find that a special construction\nof mixture probability paths optimizes the symmetric kinetic energy for the\ndiscrete case. We empirically validate the usefulness of this new design space\nacross multiple modalities: text generation, inorganic material generation, and\nimage generation. We find that we can outperform the mask construction even in\ntext with kinetic-optimal mixture paths, while we can make use of\ndomain-specific constructions of the probability path over the visual domain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03487v1",
    "published_date": "2024-12-04 17:24:35 UTC",
    "updated_date": "2024-12-04 17:24:35 UTC"
  },
  {
    "arxiv_id": "2412.16166v1",
    "title": "Unveiling the Role of Artificial Intelligence and Stock Market Growth in Achieving Carbon Neutrality in the United States: An ARDL Model Analysis",
    "authors": [
      "Azizul Hakim Rafi",
      "Abdullah Al Abrar Chowdhury",
      "Adita Sultana",
      "Abdulla All Noman"
    ],
    "abstract": "Given the fact that climate change has become one of the most pressing\nproblems in many countries in recent years, specialized research on how to\nmitigate climate change has been adopted by many countries. Within this\ndiscussion, the influence of advanced technologies in achieving carbon\nneutrality has been discussed. While several studies investigated how AI and\nDigital innovations could be used to reduce the environmental footprint, the\nactual influence of AI in reducing CO2 emissions (a proxy measuring carbon\nfootprint) has yet to be investigated. This paper studies the role of advanced\ntechnologies in general, and Artificial Intelligence (AI) and ICT use in\nparticular, in advancing carbon neutrality in the United States, between 2021.\nSecondly, this paper examines how Stock Market Growth, ICT use, Gross Domestic\nProduct (GDP), and Population affect CO2 emissions using the STIRPAT model.\nAfter examining stationarity among the variables using a variety of unit root\ntests, this study concluded that there are no unit root problems across all the\nvariables, with a mixed order of integration. The ARDL bounds test for\ncointegration revealed that variables in this study have a long-run\nrelationship. Moreover, the estimates revealed from the ARDL model in the\nshort- and long-run indicated that economic growth, stock market\ncapitalization, and population significantly contributed to the carbon\nemissions in both the short-run and long-run. Conversely, AI and ICT use\nsignificantly reduced carbon emissions over both periods. Furthermore, findings\nwere confirmed to be robust using FMOLS, DOLS, and CCR estimations.\nFurthermore, diagnostic tests indicated the absence of serial correlation,\nheteroscedasticity, and specification errors and, thus, the model was robust.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "26 pages, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.16166v1",
    "published_date": "2024-12-04 17:07:04 UTC",
    "updated_date": "2024-12-04 17:07:04 UTC"
  },
  {
    "arxiv_id": "2412.03467v1",
    "title": "Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning",
    "authors": [
      "Neale Ratzlaff",
      "Man Luo",
      "Xin Su",
      "Vasudev Lal",
      "Phillip Howard"
    ],
    "abstract": "Multimodal models typically combine a powerful large language model (LLM)\nwith a vision encoder and are then trained on multimodal data via instruction\ntuning. While this process adapts LLMs to multimodal settings, it remains\nunclear whether this adaptation compromises their original language reasoning\ncapabilities. In this work, we explore the effects of multimodal instruction\ntuning on language reasoning performance. We focus on LLaVA, a leading\nmultimodal framework that integrates LLMs such as Vicuna or Mistral with the\nCLIP vision encoder. We compare the performance of the original LLMs with their\nmultimodal-adapted counterparts across eight language reasoning tasks. Our\nexperiments yield several key insights. First, the impact of multimodal\nlearning varies between Vicuna and Mistral: we observe a degradation in\nlanguage reasoning for Mistral but improvements for Vicuna across most tasks.\nSecond, while multimodal instruction learning consistently degrades performance\non mathematical reasoning tasks (e.g., GSM8K), it enhances performance on\ncommonsense reasoning tasks (e.g., CommonsenseQA). Finally, we demonstrate that\na training-free model merging technique can effectively mitigate the language\nreasoning degradation observed in multimodal-adapted Mistral and even improve\nperformance on visual tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03467v1",
    "published_date": "2024-12-04 16:56:20 UTC",
    "updated_date": "2024-12-04 16:56:20 UTC"
  },
  {
    "arxiv_id": "2412.03465v1",
    "title": "YT-30M: A multi-lingual multi-category dataset of YouTube comments",
    "authors": [
      "Hridoy Sankar Dutta"
    ],
    "abstract": "This paper introduces two large-scale multilingual comment datasets, YT-30M\n(and YT-100K) from YouTube. The analysis in this paper is performed on a\nsmaller sample (YT-100K) of YT-30M. Both the datasets: YT-30M (full) and\nYT-100K (randomly selected 100K sample from YT-30M) are publicly released for\nfurther research. YT-30M (YT-100K) contains 32236173 (108694) comments posted\nby YouTube channel that belong to YouTube categories. Each comment is\nassociated with a video ID, comment ID, commentor name, commentor channel ID,\ncomment text, upvotes, original channel ID and category of the YouTube channel\n(e.g., 'News & Politics', 'Science & Technology', etc.).",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03465v1",
    "published_date": "2024-12-04 16:54:58 UTC",
    "updated_date": "2024-12-04 16:54:58 UTC"
  },
  {
    "arxiv_id": "2412.03446v1",
    "title": "From Words to Workflows: Automating Business Processes",
    "authors": [
      "Laura Minkova",
      "Jessica LÃ³pez Espejel",
      "Taki Eddine Toufik Djaidja",
      "Walid Dahhane",
      "El Hassane Ettifouri"
    ],
    "abstract": "As businesses increasingly rely on automation to streamline operations, the\nlimitations of Robotic Process Automation (RPA) have become apparent,\nparticularly its dependence on expert knowledge and inability to handle complex\ndecision-making tasks. Recent advancements in Artificial Intelligence (AI),\nparticularly Generative AI (GenAI) and Large Language Models (LLMs), have paved\nthe way for Intelligent Automation (IA), which integrates cognitive\ncapabilities to overcome the shortcomings of RPA. This paper introduces\nText2Workflow, a novel method that automatically generates workflows from\nnatural language user requests. Unlike traditional automation approaches,\nText2Workflow offers a generalized solution for automating any business\nprocess, translating user inputs into a sequence of executable steps\nrepresented in JavaScript Object Notation (JSON) format. Leveraging the\ndecision-making and instruction-following capabilities of LLMs, this method\nprovides a scalable, adaptable framework that enables users to visualize and\nexecute workflows with minimal manual intervention. This research outlines the\nText2Workflow methodology and its broader implications for automating complex\nbusiness processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review at Elsevier's Engineering Applications of Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2412.03446v1",
    "published_date": "2024-12-04 16:34:35 UTC",
    "updated_date": "2024-12-04 16:34:35 UTC"
  },
  {
    "arxiv_id": "2412.04106v2",
    "title": "MRGen: Segmentation Data Engine For Underrepresented MRI Modalities",
    "authors": [
      "Haoning Wu",
      "Ziheng Zhao",
      "Ya Zhang",
      "Yanfeng Wang",
      "Weidi Xie"
    ],
    "abstract": "Training medical image segmentation models for rare yet clinically\nsignificant imaging modalities is challenging due to the scarcity of annotated\ndata, and manual mask annotations can be costly and labor-intensive to acquire.\nThis paper investigates leveraging generative models to synthesize training\ndata, to train segmentation models for underrepresented modalities,\nparticularly on annotation-scarce MRI. Concretely, our contributions are\nthreefold: (i) we introduce MRGen-DB, a large-scale radiology image-text\ndataset comprising extensive samples with rich metadata, including modality\nlabels, attributes, regions, and organs information, with a subset having\npixelwise mask annotations; (ii) we present MRGen, a diffusion-based data\nengine for controllable medical image synthesis, conditioned on text prompts\nand segmentation masks. MRGen can generate realistic images for diverse MRI\nmodalities lacking mask annotations, facilitating segmentation training in\nlow-source domains; (iii) extensive experiments across multiple modalities\ndemonstrate that MRGen significantly improves segmentation performance on\nunannotated modalities by providing high-quality synthetic data. We believe\nthat our method bridges a critical gap in medical image analysis, extending\nsegmentation capabilities to scenarios that are challenging to acquire manual\nannotations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report; Project Page:\n  https://haoningwu3639.github.io/MRGen/",
    "pdf_url": "http://arxiv.org/pdf/2412.04106v2",
    "published_date": "2024-12-04 16:34:22 UTC",
    "updated_date": "2025-03-12 11:59:46 UTC"
  },
  {
    "arxiv_id": "2412.03441v3",
    "title": "PBP: Post-training Backdoor Purification for Malware Classifiers",
    "authors": [
      "Dung Thuy Nguyen",
      "Ngoc N. Tran",
      "Taylor T. Johnson",
      "Kevin Leach"
    ],
    "abstract": "In recent years, the rise of machine learning (ML) in cybersecurity has\nbrought new challenges, including the increasing threat of backdoor poisoning\nattacks on ML malware classifiers. For instance, adversaries could inject\nmalicious samples into public malware repositories, contaminating the training\ndata and potentially misclassifying malware by the ML model. Current\ncountermeasures predominantly focus on detecting poisoned samples by leveraging\ndisagreements within the outputs of a diverse set of ensemble models on\ntraining data points. However, these methods are not suitable for scenarios\nwhere Machine Learning-as-a-Service (MLaaS) is used or when users aim to remove\nbackdoors from a model after it has been trained. Addressing this scenario, we\nintroduce PBP, a post-training defense for malware classifiers that mitigates\nvarious types of backdoor embeddings without assuming any specific backdoor\nembedding mechanism. Our method exploits the influence of backdoor attacks on\nthe activation distribution of neural networks, independent of the\ntrigger-embedding method. In the presence of a backdoor attack, the activation\ndistribution of each layer is distorted into a mixture of distributions. By\nregulating the statistics of the batch normalization layers, we can guide a\nbackdoored model to perform similarly to a clean one. Our method demonstrates\nsubstantial advantages over several state-of-the-art methods, as evidenced by\nexperiments on two datasets, two types of backdoor methods, and various attack\nconfigurations. Notably, our approach requires only a small portion of the\ntraining data -- only 1\\% -- to purify the backdoor and reduce the attack\nsuccess rate from 100\\% to almost 0\\%, a 100-fold improvement over the baseline\nmethods. Our code is available at\n\\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NDSS 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03441v3",
    "published_date": "2024-12-04 16:30:03 UTC",
    "updated_date": "2024-12-10 20:17:49 UTC"
  },
  {
    "arxiv_id": "2412.14179v1",
    "title": "Benchmarking Harmonized Tariff Schedule Classification Models",
    "authors": [
      "Bryce Judy"
    ],
    "abstract": "The Harmonized Tariff System (HTS) classification industry, essential to\ne-commerce and international trade, currently lacks standardized benchmarks for\nevaluating the effectiveness of classification solutions. This study\nestablishes and tests a benchmark framework for imports to the United States,\ninspired by the benchmarking approaches used in language model evaluation, to\nsystematically compare prominent HTS classification tools. The framework\nassesses key metrics--such as speed, accuracy, rationality, and HTS code\nalignment--to provide a comprehensive performance comparison. The study\nevaluates several industry-leading solutions, including those provided by\nZonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and\nlimitations. Results highlight areas for industry-wide improvement and\ninnovation, paving the way for more effective and standardized HTS\nclassification solutions across the international trade and e-commerce sectors.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14179v1",
    "published_date": "2024-12-04 16:29:05 UTC",
    "updated_date": "2024-12-04 16:29:05 UTC"
  },
  {
    "arxiv_id": "2412.03434v1",
    "title": "BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement",
    "authors": [
      "Miguel Arturo Vega Torres",
      "Anna Ribic",
      "Borja GarcÃ­a de Soto",
      "AndrÃ© Borrmann"
    ],
    "abstract": "This paper introduces BIMCaP, a novel method to integrate mobile 3D sparse\nLiDAR data and camera measurements with pre-existing building information\nmodels (BIMs), enhancing fast and accurate indoor mapping with affordable\nsensors. BIMCaP refines sensor poses by leveraging a 3D BIM and employing a\nbundle adjustment technique to align real-world measurements with the model.\nExperiments using real-world open-access data show that BIMCaP achieves\nsuperior accuracy, reducing translational error by over 4 cm compared to\ncurrent state-of-the-art methods. This advancement enhances the accuracy and\ncost-effectiveness of 3D mapping methodologies like SLAM. BIMCaP's improvements\nbenefit various fields, including construction site management and emergency\nresponse, by providing up-to-date, aligned digital maps for better\ndecision-making and productivity. Link to the repository:\nhttps://github.com/MigVega/BIMCaP",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 24 figures, Conference: EG-ICE: 31st International Workshop\n  on Intelligent Computing in Engineering",
    "pdf_url": "http://arxiv.org/pdf/2412.03434v1",
    "published_date": "2024-12-04 16:26:17 UTC",
    "updated_date": "2024-12-04 16:26:17 UTC"
  },
  {
    "arxiv_id": "2412.03433v1",
    "title": "Genetic Algorithm Based System for Path Planning with Unmanned Aerial Vehicles Swarms in Cell-Grid Environments",
    "authors": [
      "Alejandro Puente-Castro",
      "Enrique Fernandez-Blanco",
      "Daniel Rivero"
    ],
    "abstract": "Path Planning methods for autonomously controlling swarms of unmanned aerial\nvehicles (UAVs) are gaining momentum due to their operational advantages. An\nincreasing number of scenarios now require autonomous control of multiple UAVs,\nas autonomous operation can significantly reduce labor costs. Additionally,\nobtaining optimal flight paths can lower energy consumption, thereby extending\nbattery life for other critical operations. Many of these scenarios, however,\ninvolve obstacles such as power lines and trees, which complicate Path\nPlanning. This paper presents an evolutionary computation-based system\nemploying genetic algorithms to address this problem in environments with\nobstacles. The proposed approach aims to ensure complete coverage of areas with\nfixed obstacles, such as in field exploration tasks, while minimizing flight\ntime regardless of map size or the number of UAVs in the swarm. No specific\ngoal points or prior information beyond the provided map is required. The\nexperiments conducted in this study used five maps of varying sizes and\nobstacle densities, as well as a control map without obstacles, with different\nnumbers of UAVs. The results demonstrate that this method can determine optimal\npaths for all UAVs during full map traversal, thus minimizing resource\nconsumption. A comparative analysis with other state-of-the-art approach is\npresented to highlight the advantages and potential limitations of the proposed\nmethod.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03433v1",
    "published_date": "2024-12-04 16:24:41 UTC",
    "updated_date": "2024-12-04 16:24:41 UTC"
  },
  {
    "arxiv_id": "2412.03424v1",
    "title": "Tango*: Constrained synthesis planning using chemically informed value functions",
    "authors": [
      "Daniel Armstrong",
      "Zlatko Joncev",
      "Jeff Guo",
      "Philippe Schwaller"
    ],
    "abstract": "Computer-aided synthesis planning (CASP) has made significant strides in\ngenerating retrosynthetic pathways for simple molecules in a non-constrained\nfashion. Recent work introduces a specialised bidirectional search algorithm\nwith forward and retro expansion to address the starting material-constrained\nsynthesis problem, allowing CASP systems to provide synthesis pathways from\nspecified starting materials, such as waste products or renewable feed-stocks.\nIn this work, we introduce a simple guided search which allows solving the\nstarting material-constrained synthesis planning problem using an existing,\nuni-directional search algorithm, Retro*. We show that by optimising a single\nhyperparameter, Tango* outperforms existing methods in terms of efficiency and\nsolve rate. We find the Tango* cost function catalyses strong improvements for\nthe bidirectional DESP methods. Our method also achieves lower wall clock times\nwhile proposing synthetic routes of similar length, a common metric for route\nquality. Finally, we highlight potential reasons for the strong performance of\nTango over neural guided search methods",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03424v1",
    "published_date": "2024-12-04 16:14:02 UTC",
    "updated_date": "2024-12-04 16:14:02 UTC"
  },
  {
    "arxiv_id": "2412.03420v2",
    "title": "Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic",
    "authors": [
      "Clinton Cao",
      "Annibale Panichella",
      "Sicco Verwer"
    ],
    "abstract": "The rising popularity of the microservice architectural style has led to a\ngrowing demand for automated testing approaches tailored to these systems.\nEvoMaster is a state-of-the-art tool that uses Evolutionary Algorithms (EAs) to\nautomatically generate test cases for microservices' REST APIs. One limitation\nof these EAs is the use of unit-level search heuristics, such as branch\ndistances, which focus on fine-grained code coverage and may not effectively\ncapture the complex, interconnected behaviors characteristic of system-level\ntesting. To address this limitation, we propose a new search heuristic (MISH)\nthat uses real-time automaton learning to guide the test case generation\nprocess. We capture the sequential call patterns exhibited by a test case by\nlearning an automaton from the stream of log events outputted by different\nmicroservices within the same system. Therefore, MISH learns a representation\nof the systemwide behavior, allowing us to define the fitness of a test case\nbased on the path it traverses within the inferred automaton. We empirically\nevaluate MISH's effectiveness on six real-world benchmark microservice\napplications and compare it against a state-of-the-art technique, MOSA, for\ntesting REST APIs. Our evaluation shows promising results for using MISH to\nguide the automated test case generation within EvoMaster.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.03420v2",
    "published_date": "2024-12-04 16:00:14 UTC",
    "updated_date": "2025-01-30 12:35:06 UTC"
  },
  {
    "arxiv_id": "2412.03417v2",
    "title": "Learning Semantic Association Rules from Internet of Things Data",
    "authors": [
      "Erkan Karabulut",
      "Paul Groth",
      "Victoria Degeler"
    ],
    "abstract": "Association Rule Mining (ARM) is the task of discovering commonalities in\ndata in the form of logical implications. ARM is used in the Internet of Things\n(IoT) for different tasks including monitoring and decision-making. However,\nexisting methods give limited consideration to IoT-specific requirements such\nas heterogeneity and volume. Furthermore, they do not utilize important static\ndomain-specific description data about IoT systems, which is increasingly\nrepresented as knowledge graphs. In this paper, we propose a novel ARM pipeline\nfor IoT data that utilizes both dynamic sensor data and static IoT system\nmetadata. Furthermore, we propose an Autoencoder-based Neurosymbolic ARM method\n(Aerial) as part of the pipeline to address the high volume of IoT data and\nreduce the total number of rules that are resource-intensive to process. Aerial\nlearns a neural representation of a given data and extracts association rules\nfrom this representation by exploiting the reconstruction (decoding) mechanism\nof an autoencoder. Extensive evaluations on 3 IoT datasets from 2 domains show\nthat ARM on both static and dynamic IoT data results in more generically\napplicable rules while Aerial can learn a more concise set of high-quality\nassociation rules than the state-of-the-art with full coverage over the\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03417v2",
    "published_date": "2024-12-04 15:53:45 UTC",
    "updated_date": "2024-12-05 13:22:28 UTC"
  },
  {
    "arxiv_id": "2412.03624v1",
    "title": "How to Correctly do Semantic Backpropagation on Language-based Agentic Systems",
    "authors": [
      "Wenyi Wang",
      "Hisham A. Alyahya",
      "Dylan R. Ashley",
      "Oleg Serikov",
      "Dmitrii Khizbullin",
      "Francesco Faccio",
      "JÃ¼rgen Schmidhuber"
    ],
    "abstract": "Language-based agentic systems have shown great promise in recent years,\ntransitioning from solving small-scale research problems to being deployed in\nchallenging real-world tasks. However, optimizing these systems often requires\nsubstantial manual labor. Recent studies have demonstrated that these systems\ncan be represented as computational graphs, enabling automatic optimization.\nDespite these advancements, most current efforts in Graph-based Agentic System\nOptimization (GASO) fail to properly assign feedback to the system's components\ngiven feedback on the system's output. To address this challenge, we formalize\nthe concept of semantic backpropagation with semantic gradients -- a\ngeneralization that aligns several key optimization techniques, including\nreverse-mode automatic differentiation and the more recent TextGrad by\nexploiting the relationship among nodes with a common successor. This serves as\na method for computing directional information about how changes to each\ncomponent of an agentic system might improve the system's output. To use these\ngradients, we propose a method called semantic gradient descent which enables\nus to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show\nthat our approach outperforms existing state-of-the-art methods for solving\nGASO problems. A detailed ablation study on the LIAR dataset demonstrates the\nparsimonious nature of our method. A full copy of our implementation is\npublicly available at https://github.com/HishamAlyahya/semantic_backprop",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "stat.ML",
      "68T07",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages in main text + 2 pages of references + 15 pages of\n  appendices, 2 figures in main text + 17 figures in appendices, 2 tables in\n  main text + 1 table in appendices, 2 algorithms in main text; source code\n  available at https://github.com/HishamAlyahya/semantic_backprop",
    "pdf_url": "http://arxiv.org/pdf/2412.03624v1",
    "published_date": "2024-12-04 15:52:03 UTC",
    "updated_date": "2024-12-04 15:52:03 UTC"
  },
  {
    "arxiv_id": "2412.03401v2",
    "title": "Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy",
    "authors": [
      "Ronald L. P. D. de Jong",
      "Yasmina al Khalil",
      "Tim J. M. Jaspers",
      "Romy C. van Jaarsveld",
      "Gino M. Kuiper",
      "Yiping Li",
      "Richard van Hillegersberg",
      "Jelle P. Ruurda",
      "Marcel Breeuwer",
      "Fons van der Sommen"
    ],
    "abstract": "Esophageal cancer is among the most common types of cancer worldwide. It is\ntraditionally treated using open esophagectomy, but in recent years,\nrobot-assisted minimally invasive esophagectomy (RAMIE) has emerged as a\npromising alternative. However, robot-assisted surgery can be challenging for\nnovice surgeons, as they often suffer from a loss of spatial orientation.\nComputer-aided anatomy recognition holds promise for improving surgical\nnavigation, but research in this area remains limited. In this study, we\ndeveloped a comprehensive dataset for semantic segmentation in RAMIE, featuring\nthe largest collection of vital anatomical structures and surgical instruments\nto date. Handling this diverse set of classes presents challenges, including\nclass imbalance and the recognition of complex structures such as nerves. This\nstudy aims to understand the challenges and limitations of current\nstate-of-the-art algorithms on this novel dataset and problem. Therefore, we\nbenchmarked eight real-time deep learning models using two pretraining\ndatasets. We assessed both traditional and attention-based networks,\nhypothesizing that attention-based networks better capture global patterns and\naddress challenges such as occlusion caused by blood or other tissues. The\nbenchmark includes our RAMIE dataset and the publicly available CholecSeg8k\ndataset, enabling a thorough assessment of surgical segmentation tasks. Our\nfindings indicate that pretraining on ADE20k, a dataset for semantic\nsegmentation, is more effective than pretraining on ImageNet. Furthermore,\nattention-based models outperform traditional convolutional neural networks,\nwith SegNeXt and Mask2Former achieving higher Dice scores, and Mask2Former\nadditionally excelling in average symmetric surface distance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for presentation at the SPIE Medical Imaging Conference,\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03401v2",
    "published_date": "2024-12-04 15:32:37 UTC",
    "updated_date": "2024-12-18 15:47:57 UTC"
  },
  {
    "arxiv_id": "2412.05329v1",
    "title": "Mapping The Layers of The Ocean Floor With a Convolutional Neural Network",
    "authors": [
      "Guilherme G. D. Fernandes",
      "Vitor S. P. P. Oliveira",
      "JoÃ£o P. I. Astolfo"
    ],
    "abstract": "The mapping of ocean floor layers is a current challenge for the oil\nindustry. Existing solution methods involve mapping through seismic methods and\nwave inversion, which are complex and computationally expensive. The\nintroduction of artificial neural networks, specifically UNet, to predict\nvelocity models based on seismic shots reflected from the ocean floor shows\npromise for optimising this process. In this study, two neural network\narchitectures are validated for velocity model inversion and compared in terms\nof stability metrics such as loss function and similarity coefficient, as well\nas the differences between predicted and actual models. Indeed, neural networks\nprove promising as a solution to this challenge, achieving S{\\o}rensen-Dice\ncoefficient values above 70%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.comp-ph",
      "physics.geo-ph",
      "86A15",
      "I.4.7; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures. Developed during the 6th Edition of the Advanced\n  School of Experimental Physics (EAFExp), Brazilian Centre for Physics\n  Research",
    "pdf_url": "http://arxiv.org/pdf/2412.05329v1",
    "published_date": "2024-12-04 15:26:48 UTC",
    "updated_date": "2024-12-04 15:26:48 UTC"
  },
  {
    "arxiv_id": "2412.03390v1",
    "title": "Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs",
    "authors": [
      "Ge Zheng",
      "Alexandra Brintrup"
    ],
    "abstract": "A key stumbling block in effective supply chain risk management for companies\nand policymakers is a lack of visibility on interdependent supply network\nrelationships. Relationship prediction, also called link prediction is an\nemergent area of supply chain surveillance research that aims to increase the\nvisibility of supply chains using data-driven techniques. Existing methods have\nbeen successful for predicting relationships but struggle to extract the\ncontext in which these relationships are embedded - such as the products being\nsupplied or locations they are supplied from. Lack of context prevents\npractitioners from distinguishing transactional relations from established\nsupply chain relations, hindering accurate estimations of risk. In this work,\nwe develop a new Generative Artificial Intelligence (Gen AI) enhanced machine\nlearning framework that leverages pre-trained language models as embedding\nmodels combined with machine learning models to predict supply chain\nrelationships within knowledge graphs. By integrating Generative AI techniques,\nour approach captures the nuanced semantic relationships between entities,\nthereby improving supply chain visibility and facilitating more precise risk\nmanagement. Using data from a real case study, we show that GenAI-enhanced link\nprediction surpasses all benchmarks, and demonstrate how GenAI models can be\nexplored and effectively used in supply chain risk management.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03390v1",
    "published_date": "2024-12-04 15:19:01 UTC",
    "updated_date": "2024-12-04 15:19:01 UTC"
  },
  {
    "arxiv_id": "2412.03388v1",
    "title": "DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles",
    "authors": [
      "Jiaxuan Liu",
      "Zhaoci Liu",
      "Yajun Hu",
      "Yingying Gao",
      "Shilei Zhang",
      "Zhenhua Ling"
    ],
    "abstract": "Human speech exhibits rich and flexible prosodic variations. To address the\none-to-many mapping problem from text to prosody in a reasonable and flexible\nmanner, we propose DiffStyleTTS, a multi-speaker acoustic model based on a\nconditional diffusion module and an improved classifier-free guidance, which\nhierarchically models speech prosodic features, and controls different prosodic\nstyles to guide prosody prediction. Experiments show that our method\noutperforms all baselines in naturalness and achieves superior synthesis speed\ncompared to three diffusion-based baselines. Additionally, by adjusting the\nguiding scale, DiffStyleTTS effectively controls the guidance intensity of the\nsynthetic prosody.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03388v1",
    "published_date": "2024-12-04 15:17:25 UTC",
    "updated_date": "2024-12-04 15:17:25 UTC"
  },
  {
    "arxiv_id": "2412.03620v1",
    "title": "Recommender Systems for Sustainability: Overview and Research Issues",
    "authors": [
      "Alexander Felfernig",
      "Manfred Wundara",
      "Thi Ngoc Trang Tran",
      "Seda Polat-Erdeniz",
      "Sebastian Lubos",
      "Merfat El-Mansi",
      "Damian Garber",
      "Viet-Man Le"
    ],
    "abstract": "Sustainability development goals (SDGs) are regarded as a universal call to\naction with the overall objectives of planet protection, ending of poverty, and\nensuring peace and prosperity for all people. In order to achieve these\nobjectives, different AI technologies play a major role. Specifically,\nrecommender systems can provide support for organizations and individuals to\nachieve the defined goals. Recommender systems integrate AI technologies such\nas machine learning, explainable AI (XAI), case-based reasoning, and constraint\nsolving in order to find and explain user-relevant alternatives from a\npotentially large set of options. In this article, we summarize the state of\nthe art in applying recommender systems to support the achievement of\nsustainability development goals. In this context, we discuss open issues for\nfuture research.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03620v1",
    "published_date": "2024-12-04 15:03:47 UTC",
    "updated_date": "2024-12-04 15:03:47 UTC"
  },
  {
    "arxiv_id": "2412.03359v1",
    "title": "WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis",
    "authors": [
      "Chengwei Hu",
      "Jianhui Zheng",
      "Yancheng He",
      "Hangyu Guo",
      "Junguang Jiang",
      "Han Zhu",
      "Kai Sun",
      "Yuning Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Recent advancements in autonomous multi-agent systems (MAS) based on large\nlanguage models (LLMs) have enhanced the application scenarios and improved the\ncapability of LLMs to handle complex tasks. Despite demonstrating\neffectiveness, existing studies still evidently struggle to evaluate, analysis,\nand reproducibility of LLM-based MAS. In this paper, to facilitate the research\non LLM-based MAS, we introduce an open, scalable, and real-time updated\nplatform for accessing and analyzing the LLM-based MAS based on the games Who\nis Spy?\" (WiS). Our platform is featured with three main worths: (1) a unified\nmodel evaluate interface that supports models available on Hugging Face; (2)\nreal-time updated leaderboard for model evaluation; (3) a comprehensive\nevaluation covering game-winning rates, attacking, defense strategies, and\nreasoning of LLMs. To rigorously test WiS, we conduct extensive experiments\ncoverage of various open- and closed-source LLMs, we find that different agents\nexhibit distinct and intriguing behaviors in the game. The experimental results\ndemonstrate the effectiveness and efficiency of our platform in evaluating\nLLM-based MAS. Our platform and its documentation are publicly available at\n\\url{https://whoisspy.ai/}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03359v1",
    "published_date": "2024-12-04 14:45:09 UTC",
    "updated_date": "2024-12-04 14:45:09 UTC"
  },
  {
    "arxiv_id": "2412.03352v2",
    "title": "Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation",
    "authors": [
      "Yiqin Zhang",
      "Qingkui Chen",
      "Chen Huang",
      "Zhengjie Zhang",
      "Meiling Chen",
      "Zhibing Fu"
    ],
    "abstract": "Most data-driven models for medical image analysis rely on universal\naugmentations to improve accuracy. Experimental evidence has confirmed their\neffectiveness, but the unclear mechanism underlying them poses a barrier to the\nwidespread acceptance and trust in such methods within the medical community.\nWe revisit and acknowledge the unique characteristics of medical images apart\nfrom traditional digital images, and consequently, proposed a medical-specific\naugmentation algorithm that is more elastic and aligns well with radiology scan\nprocedure. The method performs piecewise affine with sinusoidal distorted ray\naccording to radius on polar coordinates, thus simulating uncertain postures of\nhuman lying flat on the scanning table. Our method could generate human\nvisceral distribution without affecting the fundamental relative position on\naxial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal\nand Similarity-Guided Parameter Search, are introduced to bolster robustness of\nour augmentation method. In contrast to other methodologies, our method is\nhighlighted for its intuitive design and ease of understanding for medical\nprofessionals, thereby enhancing its applicability in clinical scenarios.\nExperiments show our method improves accuracy with two modality across multiple\nfamous segmentation frameworks without requiring more data samples. Our preview\ncode is available in: https://github.com/MGAMZ/PSBPD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at Smart Health",
    "pdf_url": "http://arxiv.org/pdf/2412.03352v2",
    "published_date": "2024-12-04 14:35:06 UTC",
    "updated_date": "2025-03-26 15:19:56 UTC"
  },
  {
    "arxiv_id": "2412.03347v1",
    "title": "DIVE: Taming DINO for Subject-Driven Video Editing",
    "authors": [
      "Yi Huang",
      "Wei Xiong",
      "He Zhang",
      "Chaoqi Chen",
      "Jianzhuang Liu",
      "Mingfu Yan",
      "Shifeng Chen"
    ],
    "abstract": "Building on the success of diffusion models in image generation and editing,\nvideo editing has recently gained substantial attention. However, maintaining\ntemporal consistency and motion alignment still remains challenging. To address\nthese issues, this paper proposes DINO-guided Video Editing (DIVE), a framework\ndesigned to facilitate subject-driven editing in source videos conditioned on\neither target text prompts or reference images with specific identities. The\ncore of DIVE lies in leveraging the powerful semantic features extracted from a\npretrained DINOv2 model as implicit correspondences to guide the editing\nprocess. Specifically, to ensure temporal motion consistency, DIVE employs DINO\nfeatures to align with the motion trajectory of the source video. Extensive\nexperiments on diverse real-world videos demonstrate that our framework can\nachieve high-quality editing results with robust motion consistency,\nhighlighting the potential of DINO to contribute to video editing. For precise\nsubject editing, DIVE incorporates the DINO features of reference images into a\npretrained text-to-image model to learn Low-Rank Adaptations (LoRAs),\neffectively registering the target subject's identity. Project page:\nhttps://dino-video-editing.github.io",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03347v1",
    "published_date": "2024-12-04 14:28:43 UTC",
    "updated_date": "2024-12-04 14:28:43 UTC"
  },
  {
    "arxiv_id": "2412.03343v1",
    "title": "Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning",
    "authors": [
      "Long Mai",
      "Julie Carson-Berndsen"
    ],
    "abstract": "While Large Language Models (LLMs) have made significant strides in\nreplicating human-like abilities, there are concerns about a reduction in the\nlinguistic diversity of their outputs. This results in the homogenization of\nviewpoints and perspectives, as well as the underrepresentation of specific\ndemographic groups. Although several fine-tuning and prompting techniques have\nbeen suggested to tackle the issue, they are often tailored to specific tasks\nor come with a substantial increase in computational cost and latency. This\nmakes them challenging to apply to applications that demand very low latency,\nsuch as chatbots and virtual assistants. We propose Possibility Exploration\nFine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity\nof LLMs without increasing latency or computational cost. Given the same\nprompt, models fine-tuned with PEFT can simultaneously generate multiple\ndiverse responses, each corresponding with a controllable possibility number.\nExperiments on dialogue and story generation tasks demonstrate that PEFT\nsignificantly enhances the diversity of LLM outputs, as evidenced by lower\nsimilarity between candidate responses. Since PEFT emphasizes semantic\ndiversity over lexical diversity, it can also notably reduce demographic bias\nin dialogue systems. The implementations and datasets are available in our\nrepository: https://github.com/mailong25/peft_diversity",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03343v1",
    "published_date": "2024-12-04 14:23:16 UTC",
    "updated_date": "2024-12-04 14:23:16 UTC"
  },
  {
    "arxiv_id": "2412.03338v2",
    "title": "AI-Driven Day-to-Day Route Choice",
    "authors": [
      "Leizhen Wang",
      "Peibo Duan",
      "Zhengbing He",
      "Cheng Lyu",
      "Xin Chen",
      "Nan Zheng",
      "Li Yao",
      "Zhenliang Ma"
    ],
    "abstract": "Understanding travelers' route choices can help policymakers devise optimal\noperational and planning strategies for both normal and abnormal circumstances.\nHowever, existing choice modeling methods often rely on predefined assumptions\nand struggle to capture the dynamic and adaptive nature of travel behavior.\nRecently, Large Language Models (LLMs) have emerged as a promising alternative,\ndemonstrating remarkable ability to replicate human-like behaviors across\nvarious fields. Despite this potential, their capacity to accurately simulate\nhuman route choice behavior in transportation contexts remains doubtful. To\nsatisfy this curiosity, this paper investigates the potential of LLMs for route\nchoice modeling by introducing an LLM-empowered agent, \"LLMTraveler.\" This\nagent integrates an LLM as its core, equipped with a memory system that learns\nfrom past experiences and makes decisions by balancing retrieved data and\npersonality traits. The study systematically evaluates the LLMTraveler's\nability to replicate human-like decision-making through two stages of\nday-to-day (DTD) congestion games: (1) analyzing its route-switching behavior\nin single origin-destination (OD) pair scenarios, where it demonstrates\npatterns that align with laboratory data but cannot be fully explained by\ntraditional models, and (2) testing its capacity to model adaptive learning\nbehaviors in multi-OD scenarios on the Ortuzar and Willumsen (OW) network,\nproducing results comparable to Multinomial Logit (MNL) and Reinforcement\nLearning (RL) models. These experiments demonstrate that the framework can\npartially replicate human-like decision-making in route choice while providing\nnatural language explanations for its decisions. This capability offers\nvaluable insights for transportation policymaking, such as simulating traveler\nresponses to new policies or changes in the network.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03338v2",
    "published_date": "2024-12-04 14:13:38 UTC",
    "updated_date": "2024-12-31 14:57:11 UTC"
  },
  {
    "arxiv_id": "2412.03612v1",
    "title": "Chatting with Logs: An exploratory study on Finetuning LLMs for LogQL",
    "authors": [
      "Vishwanath Seshagiri",
      "Siddharth Balyan",
      "Vaastav Anand",
      "Kaustubh Dhole",
      "Ishan Sharma",
      "Avani Wildani",
      "JosÃ© Cambronero",
      "Andreas ZÃ¼fle"
    ],
    "abstract": "Logging is a critical function in modern distributed applications, but the\nlack of standardization in log query languages and formats creates significant\nchallenges. Developers currently must write ad hoc queries in platform-specific\nlanguages, requiring expertise in both the query language and\napplication-specific log details -- an impractical expectation given the\nvariety of platforms and volume of logs and applications. While generating\nthese queries with large language models (LLMs) seems intuitive, we show that\ncurrent LLMs struggle with log-specific query generation due to the lack of\nexposure to domain-specific knowledge. We propose a novel natural language (NL)\ninterface to address these inconsistencies and aide log query generation,\nenabling developers to create queries in a target log query language by\nproviding NL inputs. We further introduce ~\\textbf{NL2QL}, a manually\nannotated, real-world dataset of natural language questions paired with\ncorresponding LogQL queries spread across three log formats, to promote the\ntraining and evaluation of NL-to-loq query systems. Using NL2QL, we\nsubsequently fine-tune and evaluate several state of the art LLMs, and\ndemonstrate their improved capability to generate accurate LogQL queries. We\nperform further ablation studies to demonstrate the effect of additional\ntraining data, and the transferability across different log formats. In our\nexperiments, we find up to 75\\% improvement of finetuned models to generate\nLogQL queries compared to non finetuned models.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.DB",
    "comment": "draft under submission at another venue",
    "pdf_url": "http://arxiv.org/pdf/2412.03612v1",
    "published_date": "2024-12-04 14:06:24 UTC",
    "updated_date": "2024-12-04 14:06:24 UTC"
  },
  {
    "arxiv_id": "2412.03331v2",
    "title": "LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings",
    "authors": [
      "Fred Philippy",
      "Siwen Guo",
      "Jacques Klein",
      "TegawendÃ© F. BissyandÃ©"
    ],
    "abstract": "Sentence embedding models play a key role in various Natural Language\nProcessing tasks, such as in Topic Modeling, Document Clustering and\nRecommendation Systems. However, these models rely heavily on parallel data,\nwhich can be scarce for many low-resource languages, including Luxembourgish.\nThis scarcity results in suboptimal performance of monolingual and\ncross-lingual sentence embedding models for these languages. To address this\nissue, we compile a relatively small but high-quality human-generated\ncross-lingual parallel dataset to train LuxEmbedder, an enhanced sentence\nembedding model for Luxembourgish with strong cross-lingual capabilities.\nAdditionally, we present evidence suggesting that including low-resource\nlanguages in parallel training datasets can be more advantageous for other\nlow-resource languages than relying solely on high-resource language pairs.\nFurthermore, recognizing the lack of sentence embedding benchmarks for\nlow-resource languages, we create a paraphrase detection benchmark specifically\nfor Luxembourgish, aiming to partially fill this gap and promote further\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03331v2",
    "published_date": "2024-12-04 14:02:12 UTC",
    "updated_date": "2024-12-05 07:05:57 UTC"
  },
  {
    "arxiv_id": "2412.03610v1",
    "title": "The Use of Artificial Intelligence in Military Intelligence: An Experimental Investigation of Added Value in the Analysis Process",
    "authors": [
      "Christian Nitzl",
      "Achim Cyran",
      "Sascha Krstanovic",
      "Uwe M. Borghoff"
    ],
    "abstract": "It is beyond dispute that the potential benefits of artificial intelligence\n(AI) in military intelligence are considerable. Nevertheless, it remains\nuncertain precisely how AI can enhance the analysis of military data. The aim\nof this study is to address this issue. To this end, the AI demonstrator\ndeepCOM was developed in collaboration with the start-up Aleph Alpha.\n  The AI functions include text search, automatic text summarization and Named\nEntity Recognition (NER). These are evaluated for their added value in military\nanalysis. It is demonstrated that under time pressure, the utilization of AI\nfunctions results in assessments clearly superior to that of the control group.\nNevertheless, despite the demonstrably superior analysis outcome in the\nexperimental group, no increase in confidence in the accuracy of their own\nanalyses was observed. Finally, the paper identifies the limitations of\nemploying AI in military intelligence, particularly in the context of analyzing\nambiguous and contradictory information.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 8 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.03610v1",
    "published_date": "2024-12-04 13:56:10 UTC",
    "updated_date": "2024-12-04 13:56:10 UTC"
  },
  {
    "arxiv_id": "2412.03312v1",
    "title": "Path-Guided Particle-based Sampling",
    "authors": [
      "Mingzhou Fan",
      "Ruida Zhou",
      "Chao Tian",
      "Xiaoning Qian"
    ],
    "abstract": "Particle-based Bayesian inference methods by sampling from a partition-free\ntarget (posterior) distribution, e.g., Stein variational gradient descent\n(SVGD), have attracted significant attention. We propose a path-guided\nparticle-based sampling~(PGPS) method based on a novel Log-weighted Shrinkage\n(LwS) density path linking an initial distribution to the target distribution.\nWe propose to utilize a Neural network to learn a vector field motivated by the\nFokker-Planck equation of the designed density path. Particles, initiated from\nthe initial distribution, evolve according to the ordinary differential\nequation defined by the vector field. The distribution of these particles is\nguided along a density path from the initial distribution to the target\ndistribution. The proposed LwS density path allows for an efficient search of\nmodes of the target distribution while canonical methods fail. We theoretically\nanalyze the Wasserstein distance of the distribution of the PGPS-generated\nsamples and the target distribution due to approximation and discretization\nerrors. Practically, the proposed PGPS-LwS method demonstrates higher Bayesian\ninference accuracy and better calibration ability in experiments conducted on\nboth synthetic and real-world Bayesian learning tasks, compared to baselines,\nsuch as SVGD and Langevin dynamics, etc.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03312v1",
    "published_date": "2024-12-04 13:44:56 UTC",
    "updated_date": "2024-12-04 13:44:56 UTC"
  },
  {
    "arxiv_id": "2412.03307v1",
    "title": "Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions",
    "authors": [
      "Romain Rochas",
      "Angelo Furno",
      "Nour-Eddin El Faouzi"
    ],
    "abstract": "Demand for bike sharing is impacted by various factors, such as weather\nconditions, events, and the availability of other transportation modes. This\nimpact remains elusive due to the complex interdependence of these factors or\nlocationrelated user behavior variations. It is also not clear which factor is\nadditional information which are not already contained in the historical\ndemand. Intermodal dependencies between bike-sharing and other modes are also\nunderexplored, and the value of this information has not been studied in\ndegraded situations. The proposed study analyzes the impact of adding\ncontextual data, such as weather, time embedding, and road traffic flow, to\npredict bike-sharing Origin-Destination (OD) flows in atypical weather\nsituations Our study highlights a mild relationship between prediction quality\nof bike-sharing demand and road traffic flow, while the introduced time\nembedding allows outperforming state-of-the-art results, particularly in the\ncase of degraded weather conditions. Including weather data as an additional\ninput further improves our model with respect to the basic ST-ED-RMGC\nprediction model by reducing of more than 20% the prediction error in degraded\nweather condition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03307v1",
    "published_date": "2024-12-04 13:29:52 UTC",
    "updated_date": "2024-12-04 13:29:52 UTC"
  },
  {
    "arxiv_id": "2412.06820v1",
    "title": "Artificial Intelligence without Restriction Surpassing Human Intelligence with Probability One: Theoretical Insight into Secrets of the Brain with AI Twins of the Brain",
    "authors": [
      "Guang-Bin Huang",
      "M. Brandon Westover",
      "Eng-King Tan",
      "Haibo Wang",
      "Dongshun Cui",
      "Wei-Ying Ma",
      "Tiantong Wang",
      "Qi He",
      "Haikun Wei",
      "Ning Wang",
      "Qiyuan Tian",
      "Kwok-Yan Lam",
      "Xin Yao",
      "Tien Yin Wong"
    ],
    "abstract": "Artificial Intelligence (AI) has apparently become one of the most important\ntechniques discovered by humans in history while the human brain is widely\nrecognized as one of the most complex systems in the universe. One fundamental\ncritical question which would affect human sustainability remains open: Will\nartificial intelligence (AI) evolve to surpass human intelligence in the\nfuture? This paper shows that in theory new AI twins with fresh cellular level\nof AI techniques for neuroscience could approximate the brain and its\nfunctioning systems (e.g. perception and cognition functions) with any expected\nsmall error and AI without restrictions could surpass human intelligence with\nprobability one in the end. This paper indirectly proves the validity of the\nconjecture made by Frank Rosenblatt 70 years ago about the potential\ncapabilities of AI, especially in the realm of artificial neural networks.\nIntelligence is just one of fortuitous but sophisticated creations of the\nnature which has not been fully discovered. Like mathematics and physics, with\nno restrictions artificial intelligence would lead to a new subject with its\nself-contained systems and principles. We anticipate that this paper opens new\ndoors for 1) AI twins and other AI techniques to be used in cellular level of\nefficient neuroscience dynamic analysis, functioning analysis of the brain and\nbrain illness solutions; 2) new worldwide collaborative scheme for\ninterdisciplinary teams concurrently working on and modelling different types\nof neurons and synapses and different level of functioning subsystems of the\nbrain with AI techniques; 3) development of low energy of AI techniques with\nthe aid of fundamental neuroscience properties; and 4) new controllable,\nexplainable and safe AI techniques with reasoning capabilities of discovering\nprinciples in nature.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by journal Neurocomputing",
    "pdf_url": "http://arxiv.org/pdf/2412.06820v1",
    "published_date": "2024-12-04 13:17:44 UTC",
    "updated_date": "2024-12-04 13:17:44 UTC"
  },
  {
    "arxiv_id": "2412.03287v1",
    "title": "Integrating Generative AI into Art Therapy: A Technical Showcase",
    "authors": [
      "Yannis Valentin Schmutz",
      "Tetiana Kravchenko",
      "Souhir Ben Souissi",
      "Mascha Kurpicz-Briki"
    ],
    "abstract": "This paper explores the integration of generative AI into the field of art\ntherapy. Leveraging proven text-to-image models, we introduce a novel technical\ndesign to complement art therapy. The resulting AI-based tools shall enable\npatients to refine and customize their creative work, opening up new avenues of\nexpression and accessibility. Using three illustrative examples, we demonstrate\npotential outputs of our solution and evaluate them qualitatively. Furthermore,\nwe discuss the current limitations and ethical considerations associated with\nthis integration and provide an outlook into future research efforts. Our\nimplementations are publicly available at https://github.com/BFH-AMI/sds24.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03287v1",
    "published_date": "2024-12-04 12:58:55 UTC",
    "updated_date": "2024-12-04 12:58:55 UTC"
  },
  {
    "arxiv_id": "2412.03283v2",
    "title": "Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models",
    "authors": [
      "Andreas MÃ¼ller",
      "Denis Lukovnikov",
      "Jonas Thietke",
      "Asja Fischer",
      "Erwin Quiring"
    ],
    "abstract": "Integrating watermarking into the generation process of latent diffusion\nmodels (LDMs) simplifies detection and attribution of generated content.\nSemantic watermarks, such as Tree-Rings and Gaussian Shading, represent a novel\nclass of watermarking techniques that are easy to implement and highly robust\nagainst various perturbations. However, our work demonstrates a fundamental\nsecurity vulnerability of semantic watermarks. We show that attackers can\nleverage unrelated models, even with different latent spaces and architectures\n(UNet vs DiT), to perform powerful and realistic forgery attacks. Specifically,\nwe design two watermark forgery attacks. The first imprints a targeted\nwatermark into real images by manipulating the latent representation of an\narbitrary image in an unrelated LDM to get closer to the latent representation\nof a watermarked image. We also show that this technique can be used for\nwatermark removal. The second attack generates new images with the target\nwatermark by inverting a watermarked image and re-generating it with an\narbitrary prompt. Both attacks just need a single reference image with the\ntarget watermark. Overall, our findings question the applicability of semantic\nwatermarks by revealing that attackers can easily forge or remove these\nwatermarks under realistic conditions.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "28 pages, 22 figures, 8 tables, to be published in The IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition 2025 (CVPR)",
    "pdf_url": "http://arxiv.org/pdf/2412.03283v2",
    "published_date": "2024-12-04 12:57:17 UTC",
    "updated_date": "2025-03-26 15:10:26 UTC"
  },
  {
    "arxiv_id": "2412.03270v1",
    "title": "Intent-driven In-context Learning for Few-shot Dialogue State Tracking",
    "authors": [
      "Zihao Yi",
      "Zhe Xu",
      "Ying Shen"
    ],
    "abstract": "Dialogue state tracking (DST) plays an essential role in task-oriented\ndialogue systems. However, user's input may contain implicit information,\nposing significant challenges for DST tasks. Additionally, DST data includes\ncomplex information, which not only contains a large amount of noise unrelated\nto the current turn, but also makes constructing DST datasets expensive. To\naddress these challenges, we introduce Intent-driven In-context Learning for\nFew-shot DST (IDIC-DST). By extracting user's intent, we propose an\nIntent-driven Dialogue Information Augmentation module to augment the dialogue\ninformation, which can track dialogue states more effectively. Moreover, we\nmask noisy information from DST data and rewrite user's input in the\nIntent-driven Examples Retrieval module, where we retrieve similar examples. We\nthen utilize a pre-trained large language model to update the dialogue state\nusing the augmented dialogue information and examples. Experimental results\ndemonstrate that IDIC-DST achieves state-of-the-art performance in few-shot\nsettings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03270v1",
    "published_date": "2024-12-04 12:25:41 UTC",
    "updated_date": "2024-12-04 12:25:41 UTC"
  },
  {
    "arxiv_id": "2412.05327v1",
    "title": "IMPACT:InMemory ComPuting Architecture Based on Y-FlAsh Technology for Coalesced Tsetlin Machine Inference",
    "authors": [
      "Omar Ghazal",
      "Wei Wang",
      "Shahar Kvatinsky",
      "Farhad Merchant",
      "Alex Yakovlev",
      "Rishad Shafik"
    ],
    "abstract": "The increasing demand for processing large volumes of data for machine\nlearning models has pushed data bandwidth requirements beyond the capability of\ntraditional von Neumann architecture. In-memory computing (IMC) has recently\nemerged as a promising solution to address this gap by enabling distributed\ndata storage and processing at the micro-architectural level, significantly\nreducing both latency and energy. In this paper, we present the IMPACT:\nInMemory ComPuting Architecture Based on Y-FlAsh Technology for Coalesced\nTsetlin Machine Inference, underpinned on a cutting-edge memory device,\nY-Flash, fabricated on a 180 nm CMOS process. Y-Flash devices have recently\nbeen demonstrated for digital and analog memory applications, offering high\nyield, non-volatility, and low power consumption. The IMPACT leverages the\nY-Flash array to implement the inference of a novel machine learning algorithm:\ncoalesced Tsetlin machine (CoTM) based on propositional logic. CoTM utilizes\nTsetlin automata (TA) to create Boolean feature selections stochastically\nacross parallel clauses. The IMPACT is organized into two computational\ncrossbars for storing the TA and weights. Through validation on the MNIST\ndataset, IMPACT achieved 96.3% accuracy. The IMPACT demonstrated improvements\nin energy efficiency, e.g., 2.23X over CNN-based ReRAM, 2.46X over Neuromorphic\nusing NOR-Flash, and 2.06X over DNN-based PCM, suited for modern ML inference\napplications.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "27 Pages, 14 Figures, 6 Tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05327v1",
    "published_date": "2024-12-04 12:22:52 UTC",
    "updated_date": "2024-12-04 12:22:52 UTC"
  },
  {
    "arxiv_id": "2412.03267v1",
    "title": "Detecting abnormal heart sound using mobile phones and on-device IConNet",
    "authors": [
      "Linh Vu",
      "Thu Tran"
    ],
    "abstract": "Given the global prevalence of cardiovascular diseases, there is a pressing\nneed for easily accessible early screening methods. Typically, this requires\nmedical practitioners to investigate heart auscultations for irregular sounds,\nfollowed by echocardiography and electrocardiography tests. To democratize\nearly diagnosis, we present a user-friendly solution for abnormal heart sound\ndetection, utilizing mobile phones and a lightweight neural network optimized\nfor on-device inference. Unlike previous approaches reliant on specialized\nstethoscopes, our method directly analyzes audio recordings, facilitated by a\nnovel architecture known as IConNet. IConNet, an Interpretable Convolutional\nNeural Network, harnesses insights from audio signal processing, enhancing\nefficiency and providing transparency in neural pattern extraction from raw\nwaveform signals. This is a significant step towards trustworthy AI in\nhealthcare, aiding in remote health monitoring efforts.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "N2Women'24 Workshop, MobiSys 2024, Tokyo, Japan",
    "pdf_url": "http://arxiv.org/pdf/2412.03267v1",
    "published_date": "2024-12-04 12:18:21 UTC",
    "updated_date": "2024-12-04 12:18:21 UTC"
  },
  {
    "arxiv_id": "2412.03248v1",
    "title": "AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning",
    "authors": [
      "Yiwu Zhong",
      "Zhuoming Liu",
      "Yin Li",
      "Liwei Wang"
    ],
    "abstract": "Large language models (LLMs) have enabled the creation of multi-modal LLMs\nthat exhibit strong comprehension of visual data such as images and videos.\nHowever, these models usually rely on extensive visual tokens from visual\nencoders, leading to high computational demands, which limits their\napplicability in resource-constrained environments and for long-context tasks.\nIn this work, we propose a training-free adaptive inference method for\nmulti-modal LLMs that can accommodate a broad range of efficiency requirements\nwith a minimum performance drop. Our method consists of a) iterative token\nmerging based on embedding similarity before LLMs, and b) progressive token\npruning within LLM layers based on multi-modal importance. With a minimalist\ndesign, our method can be applied to both video and image LLMs. Extensive\nexperiments on diverse video and image benchmarks demonstrate that, our method\nsubstantially reduces computation load (e.g., a $\\textbf{7-fold}$ reduction in\nFLOPs) while preserving the performance of video and image LLMs. Further, under\na similar computational cost, our method outperforms the state-of-the-art\nmethods in long video understanding (e.g., $\\textbf{+4.6}$ on MLVU).\nAdditionally, our in-depth analysis provides insights into token redundancy and\nLLM layer behaviors, offering guidance for future research in designing\nefficient multi-modal LLMs. Our code will be available at\nhttps://github.com/LaVi-Lab/AIM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03248v1",
    "published_date": "2024-12-04 11:47:57 UTC",
    "updated_date": "2024-12-04 11:47:57 UTC"
  },
  {
    "arxiv_id": "2412.03235v2",
    "title": "Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?",
    "authors": [
      "Sravanti Addepalli",
      "Yerram Varun",
      "Arun Suggala",
      "Karthikeyan Shanmugam",
      "Prateek Jain"
    ],
    "abstract": "Large Language Models (LLMs) are known to be susceptible to crafted\nadversarial attacks or jailbreaks that lead to the generation of objectionable\ncontent despite being aligned to human preferences using safety fine-tuning\nmethods. While the large dimensionality of input token space makes it\ninevitable to find adversarial prompts that can jailbreak these models, we aim\nto evaluate whether safety fine-tuned LLMs are safe against natural prompts\nwhich are semantically related to toxic seed prompts that elicit safe responses\nafter alignment. We surprisingly find that popular aligned LLMs such as GPT-4\ncan be compromised using naive prompts that are NOT even crafted with an\nobjective of jailbreaking the model. Furthermore, we empirically show that\ngiven a seed prompt that elicits a toxic response from an unaligned model, one\ncan systematically generate several semantically related natural prompts that\ncan jailbreak aligned LLMs. Towards this, we propose a method of Response\nGuided Question Augmentation (ReG-QA) to evaluate the generalization of safety\naligned LLMs to natural prompts, that first generates several toxic answers\ngiven a seed question using an unaligned LLM (Q to A), and further leverages an\nLLM to generate questions that are likely to produce these answers (A to Q). We\ninterestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to\nproducing natural jailbreak questions from unsafe content (without denial) and\ncan thus be used for the latter (A to Q) step. We obtain attack success rates\nthat are comparable to/ better than leading adversarial attack methods on the\nJailbreakBench leaderboard, while being significantly more stable against\ndefenses such as Smooth-LLM and Synonym Substitution, which are effective\nagainst existing all attacks on the leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03235v2",
    "published_date": "2024-12-04 11:36:37 UTC",
    "updated_date": "2025-03-25 12:49:43 UTC"
  },
  {
    "arxiv_id": "2412.03213v1",
    "title": "ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression",
    "authors": [
      "Guangda Liu",
      "Chengwei Li",
      "Jieru Zhao",
      "Chenqi Zhang",
      "Minyi Guo"
    ],
    "abstract": "Large Language Models (LLMs) have been widely deployed in a variety of\napplications, and the context length is rapidly increasing to handle tasks such\nas long-document QA and complex logical reasoning. However, long context poses\nsignificant challenges for inference efficiency, including high memory costs of\nkey-value (KV) cache and increased latency due to extensive memory accesses.\nRecent works have proposed compressing KV cache to approximate computation, but\nthese methods either evict tokens permanently, never recalling them for later\ninference, or recall previous tokens at the granularity of pages divided by\ntextual positions. Both approaches degrade the model accuracy and output\nquality. To achieve efficient and accurate recallable KV cache compression, we\nintroduce ClusterKV, which recalls tokens at the granularity of semantic\nclusters. We design and implement efficient algorithms and systems for\nclustering, selection, indexing and caching. Experiment results show that\nClusterKV attains negligible accuracy loss across various tasks with 32k\ncontext lengths, using only a 1k to 2k KV cache budget, and achieves up to a\n2$\\times$ speedup in latency and a 2.5$\\times$ improvement in decoding\nthroughput. Compared to SoTA recallable KV compression methods, ClusterKV\ndemonstrates higher model accuracy and output quality, while maintaining or\nexceeding inference efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03213v1",
    "published_date": "2024-12-04 10:58:27 UTC",
    "updated_date": "2024-12-04 10:58:27 UTC"
  },
  {
    "arxiv_id": "2412.03205v3",
    "title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs",
    "authors": [
      "Konstantin Chernyshev",
      "Vitaliy Polshkov",
      "Ekaterina Artemova",
      "Alex Myasnikov",
      "Vlad Stepanov",
      "Alexei Miasnikov",
      "Sergei Tilga"
    ],
    "abstract": "The current evaluation of mathematical skills in LLMs is limited, as existing\nbenchmarks are either relatively small, primarily focus on elementary and\nhigh-school problems, or lack diversity in topics. Additionally, the inclusion\nof visual elements in tasks remains largely under-explored.\n  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100\nunpublished open-ended university-level problems sourced from teaching\nmaterials. It is balanced across six core subjects, with 20% of multimodal\nproblems. Given the open-ended nature of U-MATH problems, we employ an LLM to\njudge the correctness of generated solutions. To this end, we release\n$\\mu$-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.\n  The evaluation of general domain, math-specific, and multimodal LLMs\nhighlights the challenges presented by U-MATH. Our findings reveal that LLMs\nachieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%\non visual problems. The solution assessment proves challenging for LLMs, with\nthe best LLM judge having an F1-score of 80% on $\\mu$-MATH.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03205v3",
    "published_date": "2024-12-04 10:44:50 UTC",
    "updated_date": "2025-01-14 21:58:47 UTC"
  },
  {
    "arxiv_id": "2412.03188v1",
    "title": "Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction",
    "authors": [
      "Ivan Kralj",
      "Lodovico Giaretta",
      "Gordan JeÅ¾iÄ",
      "Ivana Podnar Å½arko",
      "Å arÅ«nas Girdzijauskas"
    ],
    "abstract": "In smart mobility, large networks of geographically distributed sensors\nproduce vast amounts of high-frequency spatio-temporal data that must be\nprocessed in real time to avoid major disruptions. Traditional centralized\napproaches are increasingly unsuitable to this task, as they struggle to scale\nwith expanding sensor networks, and reliability issues in central components\ncan easily affect the whole deployment. To address these challenges, we explore\nand adapt semi-decentralized training techniques for Spatio-Temporal Graph\nNeural Networks (ST-GNNs) in smart mobility domain. We implement a simulation\nframework where sensors are grouped by proximity into multiple cloudlets, each\nhandling a subgraph of the traffic graph, fetching node features from other\ncloudlets to train its own local ST-GNN model, and exchanging model updates\nwith other cloudlets to ensure consistency, enhancing scalability and removing\nreliance on a centralized aggregator. We perform extensive comparative\nevaluation of four different ST-GNN training setups -- centralized, traditional\nFL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the\nMETR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed\npredictions. Experimental results show that semi-decentralized setups are\ncomparable to centralized approaches in performance metrics, while offering\nadvantages in terms of scalability and fault tolerance. In addition, we\nhighlight often overlooked issues in existing literature for distributed\nST-GNNs, such as the variation in model performance across different\ngeographical areas due to region-specific traffic patterns, and the significant\ncommunication overhead and computational costs that arise from the large\nreceptive field of GNNs, leading to substantial data transfers and increased\ncomputation of partial embeddings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures, 3 tables, conference",
    "pdf_url": "http://arxiv.org/pdf/2412.03188v1",
    "published_date": "2024-12-04 10:20:21 UTC",
    "updated_date": "2024-12-04 10:20:21 UTC"
  },
  {
    "arxiv_id": "2412.03179v1",
    "title": "Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization",
    "authors": [
      "Maxime Fontana",
      "Michael Spratling",
      "Miaojing Shi"
    ],
    "abstract": "Multi-Task Learning (MTL) involves the concurrent training of multiple tasks,\noffering notable advantages for dense prediction tasks in computer vision. MTL\nnot only reduces training and inference time as opposed to having multiple\nsingle-task models, but also enhances task accuracy through the interaction of\nmultiple tasks. However, existing methods face limitations. They often rely on\nsuboptimal cross-task interactions, resulting in task-specific predictions with\npoor geometric and predictive coherence. In addition, many approaches use\ninadequate loss weighting strategies, which do not address the inherent\nvariability in task evolution during training. To overcome these challenges, we\npropose an advanced MTL model specifically designed for dense vision tasks. Our\nmodel leverages state-of-the-art vision transformers with task-specific\ndecoders. To enhance cross-task coherence, we introduce a trace-back method\nthat improves both cross-task geometric and predictive features. Furthermore,\nwe present a novel dynamic task balancing approach that projects task losses\nonto a common scale and prioritizes more challenging tasks during training.\nExtensive experiments demonstrate the superiority of our method, establishing\nnew state-of-the-art performance across two benchmark datasets. The code is\navailable at:https://github.com/Klodivio355/MT-CP",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03179v1",
    "published_date": "2024-12-04 10:05:47 UTC",
    "updated_date": "2024-12-04 10:05:47 UTC"
  },
  {
    "arxiv_id": "2412.03178v1",
    "title": "Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation",
    "authors": [
      "Gianni Franchi",
      "Dat Nguyen Trong",
      "Nacim Belkhir",
      "Guoxuan Xia",
      "Andrea Pilzer"
    ],
    "abstract": "Uncertainty quantification in text-to-image (T2I) generative models is\ncrucial for understanding model behavior and improving output reliability. In\nthis paper, we are the first to quantify and evaluate the uncertainty of T2I\nmodels with respect to the prompt. Alongside adapting existing approaches\ndesigned to measure uncertainty in the image space, we also introduce\nPrompt-based UNCertainty Estimation for T2I models (PUNC), a novel method\nleveraging Large Vision-Language Models (LVLMs) to better address uncertainties\narising from the semantics of the prompt and generated images. PUNC utilizes a\nLVLM to caption a generated image, and then compares the caption with the\noriginal prompt in the more semantically meaningful text space. PUNC also\nenables the disentanglement of both aleatoric and epistemic uncertainties via\nprecision and recall, which image-space approaches are unable to do. Extensive\nexperiments demonstrate that PUNC outperforms state-of-the-art uncertainty\nestimation techniques across various settings. Uncertainty quantification in\ntext-to-image generation models can be used on various applications including\nbias detection, copyright protection, and OOD detection. We also introduce a\ncomprehensive dataset of text prompts and generation pairs to foster further\nresearch in uncertainty quantification for generative models. Our findings\nillustrate that PUNC not only achieves competitive performance but also enables\nnovel applications in evaluating and improving the trustworthiness of\ntext-to-image models.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages and 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03178v1",
    "published_date": "2024-12-04 10:03:52 UTC",
    "updated_date": "2024-12-04 10:03:52 UTC"
  },
  {
    "arxiv_id": "2412.03161v2",
    "title": "Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems",
    "authors": [
      "Sung Woong Cho",
      "Hwijae Son"
    ],
    "abstract": "Inverse problems involving partial differential equations (PDEs) can be seen\nas discovering a mapping from measurement data to unknown quantities, often\nframed within an operator learning approach. However, existing methods\ntypically rely on large amounts of labeled training data, which is impractical\nfor most real-world applications. Moreover, these supervised models may fail to\ncapture the underlying physical principles accurately. To address these\nlimitations, we propose a novel architecture called Physics-Informed Deep\nInverse Operator Networks (PI-DIONs), which can learn the solution operator of\nPDE-based inverse problems without labeled training data. We extend the\nstability estimates established in the inverse problem literature to the\noperator learning framework, thereby providing a robust theoretical foundation\nfor our method. These estimates guarantee that the proposed model, trained on a\nfinite sample and grid, generalizes effectively across the entire domain and\nfunction space. Extensive experiments are conducted to demonstrate that\nPI-DIONs can effectively and accurately learn the solution operators of the\ninverse problems without the need for labeled data.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.NA",
      "65M32, 68T99",
      "G.1.8; G.1.10"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03161v2",
    "published_date": "2024-12-04 09:38:58 UTC",
    "updated_date": "2025-02-07 09:56:51 UTC"
  },
  {
    "arxiv_id": "2412.03154v1",
    "title": "Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples",
    "authors": [
      "Xingjian Zhou",
      "Hongji Xu",
      "Andy Xu",
      "Zhouxing Shi",
      "Cho-Jui Hsieh",
      "Huan Zhang"
    ],
    "abstract": "In recent years, many neural network (NN) verifiers have been developed to\nformally verify certain properties of neural networks such as robustness.\nAlthough many benchmarks have been constructed to evaluate the performance of\nNN verifiers, they typically lack a ground-truth for hard instances where no\ncurrent verifier can verify and no counterexample can be found, which makes it\ndifficult to check the soundness of a new verifier if it claims to verify hard\ninstances which no other verifier can do. We propose to develop a soundness\nbenchmark for NN verification. Our benchmark contains instances with\ndeliberately inserted counterexamples while we also try to hide the\ncounterexamples from regular adversarial attacks which can be used for finding\ncounterexamples. We design a training method to produce neural networks with\nsuch hidden counterexamples. Our benchmark aims to be used for testing the\nsoundness of NN verifiers and identifying falsely claimed verifiability when it\nis known that hidden counterexamples exist. We systematically construct our\nbenchmark and generate instances across diverse model architectures, activation\nfunctions, input sizes, and perturbation radii. We demonstrate that our\nbenchmark successfully identifies bugs in state-of-the-art NN verifiers, as\nwell as synthetic bugs, providing a crucial step toward enhancing the\nreliability of testing NN verifiers. Our code is available at\nhttps://github.com/MVP-Harry/SoundnessBench and our benchmark is available at\nhttps://huggingface.co/datasets/SoundnessBench/SoundnessBench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2412.03154v1",
    "published_date": "2024-12-04 09:24:33 UTC",
    "updated_date": "2024-12-04 09:24:33 UTC"
  },
  {
    "arxiv_id": "2412.03152v2",
    "title": "A Measure of the System Dependence of Automated Metrics",
    "authors": [
      "Pius von DÃ¤niken",
      "Jan Deriu",
      "Mark Cieliebak"
    ],
    "abstract": "Automated metrics for Machine Translation have made significant progress,\nwith the goal of replacing expensive and time-consuming human evaluations.\nThese metrics are typically assessed by their correlation with human judgments,\nwhich captures the monotonic relationship between human and metric scores.\nHowever, we argue that it is equally important to ensure that metrics treat all\nsystems fairly and consistently. In this paper, we introduce a method to\nevaluate this aspect.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03152v2",
    "published_date": "2024-12-04 09:21:46 UTC",
    "updated_date": "2024-12-28 17:21:27 UTC"
  },
  {
    "arxiv_id": "2412.03151v1",
    "title": "Large Language Models show both individual and collective creativity comparable to humans",
    "authors": [
      "Luning Sun",
      "Yuzhuo Yuan",
      "Yuan Yao",
      "Yanyan Li",
      "Hao Zhang",
      "Xing Xie",
      "Xiting Wang",
      "Fang Luo",
      "David Stillwell"
    ],
    "abstract": "Artificial intelligence has, so far, largely automated routine tasks, but\nwhat does it mean for the future of work if Large Language Models (LLMs) show\ncreativity comparable to humans? To measure the creativity of LLMs\nholistically, the current study uses 13 creative tasks spanning three domains.\nWe benchmark the LLMs against individual humans, and also take a novel approach\nby comparing them to the collective creativity of groups of humans. We find\nthat the best LLMs (Claude and GPT-4) rank in the 52nd percentile against\nhumans, and overall LLMs excel in divergent thinking and problem solving but\nlag in creative writing. When questioned 10 times, an LLM's collective\ncreativity is equivalent to 8-10 humans. When more responses are requested, two\nadditional responses of LLMs equal one extra human. Ultimately, LLMs, when\noptimally applied, may compete with a small group of humans in the future of\nwork.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03151v1",
    "published_date": "2024-12-04 09:18:54 UTC",
    "updated_date": "2024-12-04 09:18:54 UTC"
  },
  {
    "arxiv_id": "2412.03148v1",
    "title": "Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media",
    "authors": [
      "Kun Li",
      "Chenwei Dai",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nrole-playing tasks. However, there is limited research on whether LLMs can\naccurately simulate user behavior in real-world scenarios, such as social\nmedia. This requires models to effectively analyze a user's history and\nsimulate their role. In this paper, we introduce \\textbf{FineRob}, a novel\nfine-grained behavior simulation dataset. We collect the complete behavioral\nhistory of 1,866 distinct users across three social media platforms. Each\nbehavior is decomposed into three fine-grained elements: object, type, and\ncontent, resulting in 78.6k QA records. Based on FineRob, we identify two\ndominant reasoning patterns in LLMs' behavior simulation processes and propose\nthe \\textbf{OM-CoT} fine-tuning method to enhance the capability. Through\ncomprehensive experiments, we conduct an in-depth analysis of key factors of\nbehavior simulation and also demonstrate the effectiveness of OM-CoT\napproach\\footnote{Code and dataset are available at\n\\url{https://github.com/linkseed18612254945/FineRob}}",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03148v1",
    "published_date": "2024-12-04 09:14:56 UTC",
    "updated_date": "2024-12-04 09:14:56 UTC"
  },
  {
    "arxiv_id": "2412.03123v1",
    "title": "Robust Multi-bit Text Watermark with LLM-based Paraphrasers",
    "authors": [
      "Xiaojun Xu",
      "Jinghan Jia",
      "Yuanshun Yao",
      "Yang Liu",
      "Hang Li"
    ],
    "abstract": "We propose an imperceptible multi-bit text watermark embedded by paraphrasing\nwith LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave\ndifferently so that their paraphrasing difference reflected in the text\nsemantics can be identified by a trained decoder. To embed our multi-bit\nwatermark, we use two paraphrasers alternatively to encode the pre-defined\nbinary code at the sentence level. Then we use a text classifier as the decoder\nto decode each bit of the watermark. Through extensive experiments, we show\nthat our watermarks can achieve over 99.99\\% detection AUC with small (1.1B)\ntext paraphrasers while keeping the semantic information of the original\nsentence. More importantly, our pipeline is robust under word substitution and\nsentence paraphrasing perturbations and generalizes well to\nout-of-distributional data. We also show the stealthiness of our watermark with\nLLM-based evaluation. We open-source the code:\nhttps://github.com/xiaojunxu/multi-bit-text-watermark.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03123v1",
    "published_date": "2024-12-04 08:43:12 UTC",
    "updated_date": "2024-12-04 08:43:12 UTC"
  },
  {
    "arxiv_id": "2412.03111v1",
    "title": "Experience-driven discovery of planning strategies",
    "authors": [
      "Ruiqi He",
      "Falk Lieder"
    ],
    "abstract": "One explanation for how people can plan efficiently despite limited cognitive\nresources is that we possess a set of adaptive planning strategies and know\nwhen and how to use them. But how are these strategies acquired? While previous\nresearch has studied how individuals learn to choose among existing strategies,\nlittle is known about the process of forming new planning strategies. In this\nwork, we propose that new planning strategies are discovered through\nmetacognitive reinforcement learning. To test this, we designed a novel\nexperiment to investigate the discovery of new planning strategies. We then\npresent metacognitive reinforcement learning models and demonstrate their\ncapability for strategy discovery as well as show that they provide a better\nexplanation of human strategy discovery than alternative learning mechanisms.\nHowever, when fitted to human data, these models exhibit a slower discovery\nrate than humans, leaving room for improvement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03111v1",
    "published_date": "2024-12-04 08:20:03 UTC",
    "updated_date": "2024-12-04 08:20:03 UTC"
  },
  {
    "arxiv_id": "2412.03107v1",
    "title": "CredID: Credible Multi-Bit Watermark for Large Language Models Identification",
    "authors": [
      "Haoyu Jiang",
      "Xuhong Wang",
      "Ping Yi",
      "Shanzhe Lei",
      "Yilun Lin"
    ],
    "abstract": "Large Language Models (LLMs) are widely used in complex natural language\nprocessing tasks but raise privacy and security concerns due to the lack of\nidentity recognition. This paper proposes a multi-party credible watermarking\nframework (CredID) involving a trusted third party (TTP) and multiple LLM\nvendors to address these issues. In the watermark embedding stage, vendors\nrequest a seed from the TTP to generate watermarked text without sending the\nuser's prompt. In the extraction stage, the TTP coordinates each vendor to\nextract and verify the watermark from the text. This provides a credible\nwatermarking scheme while preserving vendor privacy. Furthermore, current\nwatermarking algorithms struggle with text quality, information capacity, and\nrobustness, making it challenging to meet the diverse identification needs of\nLLMs. Thus, we propose a novel multi-bit watermarking algorithm and an\nopen-source toolkit to facilitate research. Experiments show our CredID\nenhances watermark credibility and efficiency without compromising text\nquality. Additionally, we successfully utilized this framework to achieve\nhighly accurate identification among multiple LLM vendors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "v1",
    "pdf_url": "http://arxiv.org/pdf/2412.03107v1",
    "published_date": "2024-12-04 08:13:29 UTC",
    "updated_date": "2024-12-04 08:13:29 UTC"
  },
  {
    "arxiv_id": "2412.03104v3",
    "title": "ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning",
    "authors": [
      "Zhe Xie",
      "Zeyan Li",
      "Xiao He",
      "Longlong Xu",
      "Xidao Wen",
      "Tieying Zhang",
      "Jianjun Chen",
      "Rui Shi",
      "Dan Pei"
    ],
    "abstract": "Understanding time series is crucial for its application in real-world\nscenarios. Recently, large language models (LLMs) have been increasingly\napplied to time series tasks, leveraging their strong language capabilities to\nenhance various applications. However, research on multimodal LLMs (MLLMs) for\ntime series understanding and reasoning remains limited, primarily due to the\nscarcity of high-quality datasets that align time series with textual\ninformation. This paper introduces ChatTS, a novel MLLM designed for time\nseries analysis. ChatTS treats time series as a modality, similar to how vision\nMLLMs process images, enabling it to perform both understanding and reasoning\nwith time series. To address the scarcity of training data, we propose an\nattribute-based method for generating synthetic time series with detailed\nattribute descriptions. We further introduce Time Series Evol-Instruct, a novel\napproach that generates diverse time series Q&As, enhancing the model's\nreasoning capabilities. To the best of our knowledge, ChatTS is the first\nTS-MLLM that takes multivariate time series as input for understanding and\nreasoning, which is fine-tuned exclusively on synthetic datasets. We evaluate\nits performance using benchmark datasets with real-world data, including six\nalignment tasks and four reasoning tasks. Our results show that ChatTS\nsignificantly outperforms existing vision-based MLLMs (e.g., GPT-4o) and\ntext/agent-based LLMs, achieving a 46.0% improvement in alignment tasks and a\n25.8% improvement in reasoning tasks. We have open-sourced the source code,\nmodel checkpoint and datasets at https://github.com/NetManAIOps/ChatTS.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted by VLDB' 25",
    "pdf_url": "http://arxiv.org/pdf/2412.03104v3",
    "published_date": "2024-12-04 08:06:15 UTC",
    "updated_date": "2025-04-16 10:18:01 UTC"
  },
  {
    "arxiv_id": "2412.03092v1",
    "title": "Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization",
    "authors": [
      "Peiyan Zhang",
      "Haibo Jin",
      "Leyang Hu",
      "Xinnuo Li",
      "Liying Kang",
      "Man Luo",
      "Yangqiu Song",
      "Haohan Wang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced the ability of LLM-based systems to perform complex tasks through\nnatural language processing and tool interaction. However, optimizing these\nLLM-based systems for specific tasks remains challenging, often requiring\nmanual interventions like prompt engineering and hyperparameter tuning.\nExisting automatic optimization methods, such as textual feedback-based\ntechniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to\nusing immediate derivatives in traditional numerical gradient descent. However,\nrelying solely on such feedback can be limited when the adjustments made in\nresponse to this feedback are either too small or fluctuate irregularly,\npotentially slowing down or even stalling the optimization process. To overcome\nthese challenges, more adaptive methods are needed, especially in situations\nwhere the system's response is evolving slowly or unpredictably. In this paper,\nwe introduce REVOLVE, an optimization method that tracks how \"R\"esponses\n\"EVOLVE\" across iterations in LLM systems. By focusing on the evolution of\nresponses over time, REVOLVE enables more stable and effective optimization by\nmaking thoughtful, progressive adjustments at each step. Experimental results\ndemonstrate that REVOLVE outperforms competitive baselines, achieving a 7.8%\nimprovement in prompt optimization, a 20.72% gain in solution refinement, and a\n29.17% increase in code optimization. Additionally, REVOLVE converges in fewer\niterations, resulting in significant computational savings. These advantages\nhighlight its adaptability and efficiency, positioning REVOLVE as a valuable\ntool for optimizing LLM-based systems and accelerating the development of\nnext-generation AI technologies. Code is available at:\nhttps://github.com/Peiyance/REVOLVE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.8"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.03092v1",
    "published_date": "2024-12-04 07:44:35 UTC",
    "updated_date": "2024-12-04 07:44:35 UTC"
  },
  {
    "arxiv_id": "2412.03076v2",
    "title": "Coordinated Multi-Armed Bandits for Improved Spatial Reuse in Wi-Fi",
    "authors": [
      "Francesc Wilhelmi",
      "Boris Bellalta",
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Sergio Barrachina-MuÃ±oz"
    ],
    "abstract": "Multi-Access Point Coordination (MAPC) and Artificial Intelligence and\nMachine Learning (AI/ML) are expected to be key features in future Wi-Fi, such\nas the forthcoming IEEE 802.11bn (Wi-Fi~8) and beyond. In this paper, we\nexplore a coordinated solution based on online learning to drive the\noptimization of Spatial Reuse (SR), a method that allows multiple devices to\nperform simultaneous transmissions by controlling interference through Packet\nDetect (PD) adjustment and transmit power control. In particular, we focus on a\nMulti-Agent Multi-Armed Bandit (MA-MAB) setting, where multiple decision-making\nagents concurrently configure SR parameters from coexisting networks by\nleveraging the MAPC framework, and study various algorithms and reward-sharing\nmechanisms. We evaluate different MA-MAB implementations using Komondor, a\nwell-adopted Wi-Fi simulator, and demonstrate that AI-native SR enabled by\ncoordinated MABs can improve the network performance over current Wi-Fi\noperation: mean throughput increases by 15%, fairness is improved by increasing\nthe minimum throughput across the network by 210%, while the maximum access\ndelay is kept below 3 ms.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03076v2",
    "published_date": "2024-12-04 06:53:59 UTC",
    "updated_date": "2025-03-05 10:19:05 UTC"
  },
  {
    "arxiv_id": "2412.03072v1",
    "title": "Preference-based opponent shaping in differentiable games",
    "authors": [
      "Xinyu Qiao",
      "Yudong Hu",
      "Congying Han",
      "Weiyan Wu",
      "Tiande Guo"
    ],
    "abstract": "Strategy learning in game environments with multi-agent is a challenging\nproblem. Since each agent's reward is determined by the joint strategy, a\ngreedy learning strategy that aims to maximize its own reward may fall into a\nlocal optimum. Recent studies have proposed the opponent modeling and shaping\nmethods for game environments. These methods enhance the efficiency of strategy\nlearning by modeling the strategies and updating processes of other agents.\nHowever, these methods often rely on simple predictions of opponent strategy\nchanges. Due to the lack of modeling behavioral preferences such as cooperation\nand competition, they are usually applicable only to predefined scenarios and\nlack generalization capabilities. In this paper, we propose a novel\nPreference-based Opponent Shaping (PBOS) method to enhance the strategy\nlearning process by shaping agents' preferences towards cooperation. We\nintroduce the preference parameter, which is incorporated into the agent's loss\nfunction, thus allowing the agent to directly consider the opponent's loss\nfunction when updating the strategy. We update the preference parameters\nconcurrently with strategy learning to ensure that agents can adapt to any\ncooperative or competitive game environment. Through a series of experiments,\nwe verify the performance of PBOS algorithm in a variety of differentiable\ngames. The experimental results show that the PBOS algorithm can guide the\nagent to learn the appropriate preference parameters, so as to achieve better\nreward distribution in multiple game environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03072v1",
    "published_date": "2024-12-04 06:49:21 UTC",
    "updated_date": "2024-12-04 06:49:21 UTC"
  },
  {
    "arxiv_id": "2412.03069v1",
    "title": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation",
    "authors": [
      "Liao Qu",
      "Huichao Zhang",
      "Yiheng Liu",
      "Xu Wang",
      "Yi Jiang",
      "Yiming Gao",
      "Hu Ye",
      "Daniel K. Du",
      "Zehuan Yuan",
      "Xinglong Wu"
    ],
    "abstract": "We present TokenFlow, a novel unified image tokenizer that bridges the\nlong-standing gap between multimodal understanding and generation. Prior\nresearch attempt to employ a single reconstruction-targeted Vector Quantization\n(VQ) encoder for unifying these two tasks. We observe that understanding and\ngeneration require fundamentally different granularities of visual information.\nThis leads to a critical trade-off, particularly compromising performance in\nmultimodal understanding tasks. TokenFlow addresses this challenge through an\ninnovative dual-codebook architecture that decouples semantic and pixel-level\nfeature learning while maintaining their alignment via a shared mapping\nmechanism. This design enables direct access to both high-level semantic\nrepresentations crucial for understanding tasks and fine-grained visual\nfeatures essential for generation through shared indices. Our extensive\nexperiments demonstrate TokenFlow's superiority across multiple dimensions.\nLeveraging TokenFlow, we demonstrate for the first time that discrete visual\ninput can surpass LLaVA-1.5 13B in understanding performance, achieving a 7.2\\%\naverage improvement. For image reconstruction, we achieve a strong FID score of\n0.63 at 384*384 resolution. Moreover, TokenFlow establishes state-of-the-art\nperformance in autoregressive image generation with a GenEval score of 0.55 at\n256*256 resolution, achieving comparable results to SDXL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "https://byteflow-ai.github.io/TokenFlow/",
    "pdf_url": "http://arxiv.org/pdf/2412.03069v1",
    "published_date": "2024-12-04 06:46:55 UTC",
    "updated_date": "2024-12-04 06:46:55 UTC"
  },
  {
    "arxiv_id": "2412.03068v1",
    "title": "UTSD: Unified Time Series Diffusion Model",
    "authors": [
      "Xiangkai Ma",
      "Xiaobin Hong",
      "Wenzhong Li",
      "Sanglu Lu"
    ],
    "abstract": "Transformer-based architectures have achieved unprecedented success in time\nseries analysis. However, facing the challenge of across-domain modeling,\nexisting studies utilize statistical prior as prompt engineering fails under\nthe huge distribution shift among various domains. In this paper, a Unified\nTime Series Diffusion (UTSD) model is established for the first time to model\nthe multi-domain probability distribution, utilizing the powerful probability\ndistribution modeling ability of Diffusion. Unlike the autoregressive models\nthat capture the conditional probabilities of the prediction horizon to the\nhistorical sequence, we use a diffusion denoising process to model the mixture\ndistribution of the cross-domain data and generate the prediction sequence for\nthe target domain directly utilizing conditional sampling. The proposed UTSD\ncontains three pivotal designs: (1) The condition network captures the\nmulti-scale fluctuation patterns from the observation sequence, which are\nutilized as context representations to guide the denoising network to generate\nthe prediction sequence; (2) Adapter-based fine-tuning strategy, the\nmulti-domain universal representation learned in the pretraining stage is\nutilized for downstream tasks in target domains; (3) The diffusion and\ndenoising process on the actual sequence space, combined with the improved\nclassifier free guidance as the conditional generation strategy, greatly\nimproves the stability and accuracy of the downstream task. We conduct\nextensive experiments on mainstream benchmarks, and the pre-trained UTSD\noutperforms existing foundation models on all data domains, exhibiting superior\nzero-shot generalization ability. After training from scratch, UTSD achieves\ncomparable performance against domain-specific proprietary models. The\nempirical results validate the potential of UTSD as a time series foundational\nmodel.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03068v1",
    "published_date": "2024-12-04 06:42:55 UTC",
    "updated_date": "2024-12-04 06:42:55 UTC"
  },
  {
    "arxiv_id": "2412.03056v2",
    "title": "Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification",
    "authors": [
      "Marzieh Mohammadi",
      "Amir Salarpour"
    ],
    "abstract": "This paper introduces Point-GN, a novel non-parametric network for efficient\nand accurate 3D point cloud classification. Unlike conventional deep learning\nmodels that rely on a large number of trainable parameters, Point-GN leverages\nnon-learnable components-specifically, Farthest Point Sampling (FPS), k-Nearest\nNeighbors (k-NN), and Gaussian Positional Encoding (GPE)-to extract both local\nand global geometric features. This design eliminates the need for additional\ntraining while maintaining high performance, making Point-GN particularly\nsuited for real-time, resource-constrained applications. We evaluate Point-GN\non two benchmark datasets, ModelNet40 and ScanObjectNN, achieving\nclassification accuracies of 85.29% and 85.89%, respectively, while\nsignificantly reducing computational complexity. Point-GN outperforms existing\nnon-parametric methods and matches the performance of fully trained models, all\nwith zero learnable parameters. Our results demonstrate that Point-GN is a\npromising solution for 3D point cloud classification in practical, real-time\nenvironments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted for presentation at the IEEE Winter\n  Conference on Applications of Computer Vision (WACV) 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03056v2",
    "published_date": "2024-12-04 06:20:51 UTC",
    "updated_date": "2024-12-07 05:07:59 UTC"
  },
  {
    "arxiv_id": "2412.03051v1",
    "title": "Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies",
    "authors": [
      "Junchao Fan",
      "Xuyang Lei",
      "Xiaolin Chang",
      "Jelena MiÅ¡iÄ",
      "Vojislav B. MiÅ¡iÄ"
    ],
    "abstract": "Despite significant advancements in deep reinforcement learning (DRL)-based\nautonomous driving policies, these policies still exhibit vulnerability to\nadversarial attacks. This vulnerability poses a formidable challenge to the\npractical deployment of these policies in autonomous driving. Designing\neffective adversarial attacks is an indispensable prerequisite for enhancing\nthe robustness of these policies. In view of this, we present a novel stealthy\nand efficient adversarial attack method for DRL-based autonomous driving\npolicies. Specifically, we introduce a DRL-based adversary designed to trigger\nsafety violations (e.g., collisions) by injecting adversarial samples at\ncritical moments. We model the attack as a mixed-integer optimization problem\nand formulate it as a Markov decision process. Then, we train the adversary to\nlearn the optimal policy for attacking at critical moments without domain\nknowledge. Furthermore, we introduce attack-related information and a\ntrajectory clipping method to enhance the learning capability of the adversary.\nFinally, we validate our method in an unprotected left-turn scenario across\ndifferent traffic densities. The experimental results show that our method\nachieves more than 90% collision rate within three attacks in most cases.\nFurthermore, our method achieves more than 130% improvement in attack\nefficiency compared to the unlimited attack method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03051v1",
    "published_date": "2024-12-04 06:11:09 UTC",
    "updated_date": "2024-12-04 06:11:09 UTC"
  },
  {
    "arxiv_id": "2412.03605v1",
    "title": "CBEval: A framework for evaluating and interpreting cognitive biases in LLMs",
    "authors": [
      "Ammar Shaikh",
      "Raj Abhijit Dandekar",
      "Sreedath Panat",
      "Rajat Dandekar"
    ],
    "abstract": "Rapid advancements in Large Language models (LLMs) has significantly enhanced\ntheir reasoning capabilities. Despite improved performance on benchmarks, LLMs\nexhibit notable gaps in their cognitive processes. Additionally, as reflections\nof human-generated data, these models have the potential to inherit cognitive\nbiases, raising concerns about their reasoning and decision making\ncapabilities. In this paper we present a framework to interpret, understand and\nprovide insights into a host of cognitive biases in LLMs. Conducting our\nresearch on frontier language models we're able to elucidate reasoning\nlimitations and biases, and provide reasoning behind these biases by\nconstructing influence graphs that identify phrases and words most responsible\nfor biases manifested in LLMs. We further investigate biases such as round\nnumber bias and cognitive bias barrier revealed when noting framing effect in\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03605v1",
    "published_date": "2024-12-04 05:53:28 UTC",
    "updated_date": "2024-12-04 05:53:28 UTC"
  },
  {
    "arxiv_id": "2412.03039v1",
    "title": "MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation",
    "authors": [
      "Hyojeong Lee",
      "Youngwan Jo",
      "Inpyo Hong",
      "Sanghyun Park"
    ],
    "abstract": "We propose a Multifaceted Resilient Network(MRNet), a novel architecture\ndeveloped for medical image-to-image translation that outperforms\nstate-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet\nleverages the Segment Anything Model (SAM) to exploit frequency-based features\nto build a powerful method for advanced medical image transformation. The\narchitecture extracts comprehensive multiscale features from diverse datasets\nusing a powerful SAM image encoder and performs resolution-aware feature fusion\nthat consistently integrates U-Net encoder outputs with SAM-derived features.\nThis fusion optimizes the traditional U-Net skip connection while leveraging\ntransformer-based contextual analysis. The translation is complemented by an\ninnovative dual-mask configuration incorporating dynamic attention patterns and\na specialized loss function designed to address regional mapping mismatches,\npreserving both the gross anatomy and tissue details. Extensive validation\nstudies have shown that MRNet outperforms state-of-the-art architectures,\nparticularly in maintaining anatomical fidelity and minimizing translation\nartifacts.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2412.03039v1",
    "published_date": "2024-12-04 05:23:46 UTC",
    "updated_date": "2024-12-04 05:23:46 UTC"
  },
  {
    "arxiv_id": "2412.03038v1",
    "title": "MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management",
    "authors": [
      "Liwei Deng",
      "Tianfu Wang",
      "Yan Zhao",
      "Kai Zheng"
    ],
    "abstract": "Portfolio management is an important yet challenging task in AI for FinTech,\nwhich aims to allocate investors' budgets among different assets to balance the\nrisk and return of an investment. In this study, we propose a general\nMulti-objectIve framework with controLLable rIsk for pOrtfolio maNagement\n(MILLION), which consists of two main phases, i.e., return-related maximization\nand risk control. Specifically, in the return-related maximization phase, we\nintroduce two auxiliary objectives, i.e., return rate prediction, and return\nrate ranking, combined with portfolio optimization to remit the overfitting\nproblem and improve the generalization of the trained model to future markets.\nSubsequently, in the risk control phase, we propose two methods, i.e.,\nportfolio interpolation and portfolio improvement, to achieve fine-grained risk\ncontrol and fast risk adaption to a user-specified risk level. For the\nportfolio interpolation method, we theoretically prove that the risk can be\nperfectly controlled if the to-be-set risk level is in a proper interval. In\naddition, we also show that the return rate of the adjusted portfolio after\nportfolio interpolation is no less than that of the min-variance optimization,\nas long as the model in the reward maximization phase is effective.\nFurthermore, the portfolio improvement method can achieve greater return rates\nwhile keeping the same risk level compared to portfolio interpolation.\nExtensive experiments are conducted on three real-world datasets. The results\ndemonstrate the effectiveness and efficiency of the proposed framework.",
    "categories": [
      "q-fin.PM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.PM",
    "comment": "accepted by VLDB 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.03038v1",
    "published_date": "2024-12-04 05:19:34 UTC",
    "updated_date": "2024-12-04 05:19:34 UTC"
  },
  {
    "arxiv_id": "2412.03028v1",
    "title": "Specification Generation for Neural Networks in Systems",
    "authors": [
      "Isha Chaudhary",
      "Shuyi Lin",
      "Cheng Tan",
      "Gagandeep Singh"
    ],
    "abstract": "Specifications - precise mathematical representations of correct\ndomain-specific behaviors - are crucial to guarantee the trustworthiness of\ncomputer systems. With the increasing development of neural networks as\ncomputer system components, specifications gain more importance as they can be\nused to regulate the behaviors of these black-box models. Traditionally,\nspecifications are designed by domain experts based on their intuition of\ncorrect behavior. However, this is labor-intensive and hence not a scalable\napproach as computer system applications diversify. We hypothesize that the\ntraditional (aka reference) algorithms that neural networks replace for higher\nperformance can act as effective proxies for correct behaviors of the models,\nwhen available. This is because they have been used and tested for long enough\nto encode several aspects of the trustworthy/correct behaviors in the\nunderlying domain. Driven by our hypothesis, we develop a novel automated\nframework, SpecTRA to generate specifications for neural networks using\nreferences. We formulate specification generation as an optimization problem\nand solve it with observations of reference behaviors. SpecTRA clusters similar\nobservations into compact specifications. We present specifications generated\nby SpecTRA for neural networks in adaptive bit rate and congestion control\nalgorithms. Our specifications show evidence of being correct and matching\nintuition. Moreover, we use our specifications to show several unknown\nvulnerabilities of the SOTA models for computer systems.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03028v1",
    "published_date": "2024-12-04 04:45:36 UTC",
    "updated_date": "2024-12-04 04:45:36 UTC"
  },
  {
    "arxiv_id": "2412.03021v4",
    "title": "PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm",
    "authors": [
      "Tianyu Chang",
      "Xiaohao Chen",
      "Zhichao Wei",
      "Xuanpu Zhang",
      "Qing-Guo Chen",
      "Weihua Luo",
      "Peipei Song",
      "Xun Yang"
    ],
    "abstract": "Video Virtual Try-on aims to seamlessly transfer a reference garment onto a\ntarget person in a video while preserving both visual fidelity and temporal\ncoherence. Existing methods typically rely on inpainting masks to define the\ntry-on area, enabling accurate garment transfer for simple scenes (e.g.,\nin-shop videos). However, these mask-based approaches struggle with complex\nreal-world scenarios, as overly large and inconsistent masks often destroy\nspatial-temporal information, leading to distorted results. Mask-free methods\nalleviate this issue but face challenges in accurately determining the try-on\narea, especially for videos with dynamic body movements. To address these\nlimitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video\nVirtual Try-On framework that leverages sparse point alignments to explicitly\nguide garment transfer. Our key innovation is the introduction of\npoint-enhanced guidance, which provides flexible and reliable control over both\nspatial-level garment transfer and temporal-level video coherence.\nSpecifically, we design a Point-Enhanced Transformer (PET) with two core\ncomponents: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth\npoint alignments to precisely guide garment transfer, and Point-Enhanced\nTemporal Attention (PTA), which leverages frame-frame point correspondences to\nenhance temporal coherence and ensure smooth transitions across frames.\nExtensive experiments demonstrate that our PEMF-VTO outperforms\nstate-of-the-art methods, generating more natural, coherent, and visually\nappealing try-on videos, particularly for challenging in-the-wild scenarios.\nThe link to our paper's homepage is https://pemf-vto.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03021v4",
    "published_date": "2024-12-04 04:24:15 UTC",
    "updated_date": "2025-03-14 10:07:40 UTC"
  },
  {
    "arxiv_id": "2412.03011v1",
    "title": "Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations",
    "authors": [
      "Yu Feng",
      "Shunsi Zhang",
      "Jian Shu",
      "Hanfeng Zhao",
      "Guoliang Pang",
      "Chi Zhang",
      "Hao Wang"
    ],
    "abstract": "Generating multi-view human images from a single view is a complex and\nsignificant challenge. Although recent advancements in multi-view object\ngeneration have shown impressive results with diffusion models, novel view\nsynthesis for humans remains constrained by the limited availability of 3D\nhuman datasets. Consequently, many existing models struggle to produce\nrealistic human body shapes or capture fine-grained facial details accurately.\nTo address these issues, we propose an innovative framework that leverages\ntransferred body and facial representations for multi-view human synthesis.\nSpecifically, we use a single-view model pretrained on a large-scale human\ndataset to develop a multi-view body representation, aiming to extend the 2D\nknowledge of the single-view model to a multi-view diffusion model.\nAdditionally, to enhance the model's detail restoration capability, we\nintegrate transferred multimodal facial features into our trained human\ndiffusion model. Experimental evaluations on benchmark datasets demonstrate\nthat our approach outperforms the current state-of-the-art methods, achieving\nsuperior performance in multi-view human synthesis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03011v1",
    "published_date": "2024-12-04 04:02:17 UTC",
    "updated_date": "2024-12-04 04:02:17 UTC"
  },
  {
    "arxiv_id": "2412.02980v2",
    "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
    "authors": [
      "Alex Havrilla",
      "Andrew Dai",
      "Laura O'Mahony",
      "Koen Oostermeijer",
      "Vera Zisler",
      "Alon Albalak",
      "Fabrizio Milo",
      "Sharath Chandra Raparthy",
      "Kanishk Gandhi",
      "Baber Abbasi",
      "Duy Phung",
      "Maia Iyer",
      "Dakota Mahan",
      "Chase Blagden",
      "Srishti Gureja",
      "Mohammed Hamdy",
      "Wen-Ding Li",
      "Giovanni Paolini",
      "Pawan Sasanka Ammanamanchi",
      "Elliot Meyerson"
    ],
    "abstract": "Synthetic data generation with Large Language Models is a promising paradigm\nfor augmenting natural data over a nearly infinite range of tasks. Given this\nvariety, direct comparisons among synthetic data generation algorithms are\nscarce, making it difficult to understand where improvement comes from and what\nbottlenecks exist. We propose to evaluate algorithms via the makeup of\nsynthetic data generated by each algorithm in terms of data quality, diversity,\nand complexity. We choose these three characteristics for their significance in\nopen-ended processes and the impact each has on the capabilities of downstream\nmodels. We find quality to be essential for in-distribution model\ngeneralization, diversity to be essential for out-of-distribution\ngeneralization, and complexity to be beneficial for both. Further, we emphasize\nthe existence of Quality-Diversity trade-offs in training data and the\ndownstream effects on model performance. We then examine the effect of various\ncomponents in the synthetic data pipeline on each data characteristic. This\nexamination allows us to taxonomize and compare synthetic data generation\nalgorithms through the components they utilize and the resulting effects on\ndata QDC composition. This analysis extends into a discussion on the importance\nof balancing QDC in synthetic data for efficient reinforcement learning and\nself-improvement algorithms. Analogous to the QD trade-offs in training data,\noften there exist trade-offs between model output quality and output diversity\nwhich impact the composition of synthetic data. We observe that many models are\ncurrently evaluated and optimized only for output quality, thereby limiting\noutput diversity and the potential for self-improvement. We argue that\nbalancing these trade-offs is essential to the development of future\nself-improvement algorithms and highlight a number of works making progress in\nthis direction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02980v2",
    "published_date": "2024-12-04 02:47:45 UTC",
    "updated_date": "2024-12-09 22:23:41 UTC"
  },
  {
    "arxiv_id": "2412.02975v1",
    "title": "Theoretical limitations of multi-layer Transformer",
    "authors": [
      "Lijie Chen",
      "Binghui Peng",
      "Hongxun Wu"
    ],
    "abstract": "Transformers, especially the decoder-only variants, are the backbone of most\nmodern large language models; yet we do not have much understanding of their\nexpressive power except for the simple $1$-layer case.\n  Due to the difficulty of analyzing multi-layer models, all previous work\nrelies on unproven complexity conjectures to show limitations for multi-layer\nTransformers. In this work, we prove the first $\\textit{unconditional}$ lower\nbound against multi-layer decoder-only transformers. For any constant $L$, we\nprove that any $L$-layer decoder-only transformer needs a polynomial model\ndimension ($n^{\\Omega(1)}$) to perform sequential composition of $L$ functions\nover an input of $n$ tokens.\n  As a consequence, our results give: (1) the first depth-width trade-off for\nmulti-layer transformers, exhibiting that the $L$-step composition task is\nexponentially harder for $L$-layer models compared to $(L+1)$-layer ones; (2)\nan unconditional separation between encoder and decoder, exhibiting a hard task\nfor decoders that can be solved by an exponentially shallower and smaller\nencoder; (3) a provable advantage of chain-of-thought, exhibiting a task that\nbecomes exponentially easier with chain-of-thought.\n  On the technical side, we propose the multi-party $\\textit{autoregressive}$\n$\\textit{communication}$ $\\textit{model}$ that captures the computation of a\ndecoder-only Transformer. We also introduce a new proof technique that finds a\ncertain $\\textit{indistinguishable}$ $\\textit{decomposition}$ of all possible\ninputs iteratively for proving lower bounds in this model. We believe our new\ncommunication model and proof technique will be helpful to further understand\nthe computational power of transformers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02975v1",
    "published_date": "2024-12-04 02:37:31 UTC",
    "updated_date": "2024-12-04 02:37:31 UTC"
  },
  {
    "arxiv_id": "2412.02957v1",
    "title": "3D Interaction Geometric Pre-training for Molecular Relational Learning",
    "authors": [
      "Namkyeong Lee",
      "Yunhak Oh",
      "Heewoong Noh",
      "Gyoung S. Na",
      "Minkai Xu",
      "Hanchen Wang",
      "Tianfan Fu",
      "Chanyoung Park"
    ],
    "abstract": "Molecular Relational Learning (MRL) is a rapidly growing field that focuses\non understanding the interaction dynamics between molecules, which is crucial\nfor applications ranging from catalyst engineering to drug discovery. Despite\nrecent progress, earlier MRL approaches are limited to using only the 2D\ntopological structure of molecules, as obtaining the 3D interaction geometry\nremains prohibitively expensive. This paper introduces a novel 3D geometric\npre-training strategy for MRL (3DMRL) that incorporates a 3D virtual\ninteraction environment, overcoming the limitations of costly traditional\nquantum mechanical calculation methods. With the constructed 3D virtual\ninteraction environment, 3DMRL trains 2D MRL model to learn the overall 3D\ngeometric information of molecular interaction through contrastive learning.\nMoreover, fine-grained interaction between molecules is learned through force\nprediction loss, which is crucial in understanding the wide range of molecular\ninteraction processes. Extensive experiments on various tasks using real-world\ndatasets, including out-of-distribution and extrapolation scenarios,\ndemonstrate the effectiveness of 3DMRL, showing up to a 24.93\\% improvement in\nperformance across 40 tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02957v1",
    "published_date": "2024-12-04 02:05:55 UTC",
    "updated_date": "2024-12-04 02:05:55 UTC"
  },
  {
    "arxiv_id": "2412.02946v1",
    "title": "Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis",
    "authors": [
      "Po-Hsuan Huang",
      "Jeng-Lin Li",
      "Chin-Po Chen",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "abstract": "Recent advancements in large vision-language models (LVLM) have significantly\nenhanced their ability to comprehend visual inputs alongside natural language.\nHowever, a major challenge in their real-world application is hallucination,\nwhere LVLMs generate non-existent visual elements, eroding user trust. The\nunderlying mechanism driving this multimodal hallucination is poorly\nunderstood. Minimal research has illuminated whether contexts such as sky,\ntree, or grass field involve the LVLM in hallucinating a frisbee. We\nhypothesize that hidden factors, such as objects, contexts, and semantic\nforeground-background structures, induce hallucination. This study proposes a\nnovel causal approach: a hallucination probing system to identify these hidden\nfactors. By analyzing the causality between images, text prompts, and network\nsaliency, we systematically explore interventions to block these factors. Our\nexperimental findings show that a straightforward technique based on our\nanalysis can significantly reduce hallucinations. Additionally, our analyses\nindicate the potential to edit network internals to minimize hallucinated\noutputs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WACV2025",
    "pdf_url": "http://arxiv.org/pdf/2412.02946v1",
    "published_date": "2024-12-04 01:23:57 UTC",
    "updated_date": "2024-12-04 01:23:57 UTC"
  },
  {
    "arxiv_id": "2412.02942v1",
    "title": "STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction",
    "authors": [
      "Silu He",
      "Peng Shen",
      "Pingzhen Xu",
      "Qinyao Luo",
      "Haifeng Li"
    ],
    "abstract": "Existing works typically treat spatial-temporal prediction as the task of\nlearning a function $F$ to transform historical observations to future\nobservations. We further decompose this cross-time transformation into three\nprocesses: (1) Encoding ($E$): learning the intrinsic representation of\nobservations, (2) Cross-Time Mapping ($M$): transforming past representations\ninto future representations, and (3) Decoding ($D$): reconstructing future\nobservations from the future representations. From this perspective,\nspatial-temporal prediction can be viewed as learning $F = E \\cdot M \\cdot D$,\nwhich includes learning the space transformations $\\left\\{{E},{D}\\right\\}$\nbetween the observation space and the hidden representation space, as well as\nthe spatial-temporal mapping $M$ from future states to past states within the\nrepresentation space. This leads to two key questions: \\textbf{Q1: What kind of\nrepresentation space allows for mapping the past to the future? Q2: How to\nachieve map the past to the future within the representation space?} To address\nQ1, we propose a Spatial-Temporal Backdoor Adjustment strategy, which learns a\nSpatial-Temporal De-Confounded (STDC) representation space and estimates the\nde-confounding causal effect of historical data on future data. This causal\nrelationship we captured serves as the foundation for subsequent\nspatial-temporal mapping. To address Q2, we design a Spatial-Temporal Embedding\n(STE) that fuses the information of temporal and spatial confounders, capturing\nthe intrinsic spatial-temporal characteristics of the representations.\nAdditionally, we introduce a Cross-Time Attention mechanism, which queries the\nattention between the future and the past to guide spatial-temporal mapping.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02942v1",
    "published_date": "2024-12-04 01:20:43 UTC",
    "updated_date": "2024-12-04 01:20:43 UTC"
  },
  {
    "arxiv_id": "2412.02940v1",
    "title": "SAVER: A Toolbox for Sampling-Based, Probabilistic Verification of Neural Networks",
    "authors": [
      "Vignesh Sivaramakrishnan",
      "Krishna C. Kalagarla",
      "Rosalyn Devonport",
      "Joshua Pilipovsky",
      "Panagiotis Tsiotras",
      "Meeko Oishi"
    ],
    "abstract": "We present a neural network verification toolbox to 1) assess the probability\nof satisfaction of a constraint, and 2) synthesize a set expansion factor to\nachieve the probability of satisfaction. Specifically, the tool box establishes\nwith a user-specified level of confidence whether the output of the neural\nnetwork for a given input distribution is likely to be contained within a given\nset. Should the tool determine that the given set cannot satisfy the likelihood\nconstraint, the tool also implements an approach outlined in this paper to\nalter the constraint set to ensure that the user-defined satisfaction\nprobability is achieved. The toolbox is comprised of sampling-based approaches\nwhich exploit the properties of signed distance function to define set\ncontainment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 8 figures, submitted to the 28th ACM International\n  Conference on Hybrid Systems: Computation and Control",
    "pdf_url": "http://arxiv.org/pdf/2412.02940v1",
    "published_date": "2024-12-04 01:13:44 UTC",
    "updated_date": "2024-12-04 01:13:44 UTC"
  },
  {
    "arxiv_id": "2412.02931v1",
    "title": "Inverse Delayed Reinforcement Learning",
    "authors": [
      "Simon Sinong Zhan",
      "Qingyuan Wu",
      "Zhian Ruan",
      "Frank Yang",
      "Philip Wang",
      "Yixuan Wang",
      "Ruochen Jiao",
      "Chao Huang",
      "Qi Zhu"
    ],
    "abstract": "Inverse Reinforcement Learning (IRL) has demonstrated effectiveness in a\nvariety of imitation tasks. In this paper, we introduce an IRL framework\ndesigned to extract rewarding features from expert trajectories affected by\ndelayed disturbances. Instead of relying on direct observations, our approach\nemploys an efficient off-policy adversarial training framework to derive expert\nfeatures and recover optimal policies from augmented delayed observations.\nEmpirical evaluations in the MuJoCo environment under diverse delay settings\nvalidate the effectiveness of our method. Furthermore, we provide a theoretical\nanalysis showing that recovering expert policies from augmented delayed\nobservations outperforms using direct delayed observations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02931v1",
    "published_date": "2024-12-04 00:53:55 UTC",
    "updated_date": "2024-12-04 00:53:55 UTC"
  },
  {
    "arxiv_id": "2412.02929v2",
    "title": "Panoptic Diffusion Models: co-generation of images and segmentation maps",
    "authors": [
      "Yinghan Long",
      "Kaushik Roy"
    ],
    "abstract": "Recently, diffusion models have demonstrated impressive capabilities in\ntext-guided and image-conditioned image generation. However, existing diffusion\nmodels cannot simultaneously generate an image and a panoptic segmentation of\nobjects and stuff from the prompt. Incorporating an inherent understanding of\nshapes and scene layouts can improve the creativity and realism of diffusion\nmodels. To address this limitation, we present Panoptic Diffusion Model (PDM),\nthe first model designed to generate both images and panoptic segmentation maps\nconcurrently. PDM bridges the gap between image and text by constructing\nsegmentation layouts that provide detailed, built-in guidance throughout the\ngeneration process. This ensures the inclusion of categories mentioned in text\nprompts and enriches the diversity of segments within the background. We\ndemonstrate the effectiveness of PDM across two architectures: a unified\ndiffusion transformer and a two-stream transformer with a pretrained backbone.\nWe propose a Multi-Scale Patching mechanism to generate high-resolution\nsegmentation maps. Additionally, when ground-truth maps are available, PDM can\nfunction as a text-guided image-to-image generation model. Finally, we propose\na novel metric for evaluating the quality of generated maps and show that PDM\nachieves state-of-the-art results in image generation with implicit scene\ncontrol.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02929v2",
    "published_date": "2024-12-04 00:42:15 UTC",
    "updated_date": "2025-02-22 05:58:21 UTC"
  },
  {
    "arxiv_id": "2412.02919v1",
    "title": "Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data",
    "authors": [
      "Soroush Omranpour",
      "Guillaume Rabusseau",
      "Reihaneh Rabbany"
    ],
    "abstract": "Transformers are now ubiquitous for sequence modeling tasks, but their\nextension to multi-dimensional data remains a challenge due to the quadratic\ncost of the attention mechanism. In this paper, we propose Higher-Order\nTransformers (HOT), a novel architecture designed to efficiently process data\nwith more than two axes, i.e. higher-order tensors. To address the\ncomputational challenges associated with high-order tensor attention, we\nintroduce a novel Kronecker factorized attention mechanism that reduces the\nattention cost to quadratic in each axis' dimension, rather than quadratic in\nthe total size of the input tensor. To further enhance efficiency, HOT\nleverages kernelized attention, reducing the complexity to linear. This\nstrategy maintains the model's expressiveness while enabling scalable attention\ncomputation. We validate the effectiveness of HOT on two high-dimensional\ntasks, including multivariate time series forecasting, and 3D medical image\nclassification. Experimental results demonstrate that HOT achieves competitive\nperformance while significantly improving computational efficiency, showcasing\nits potential for tackling a wide range of complex, multi-dimensional data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02919v1",
    "published_date": "2024-12-04 00:10:47 UTC",
    "updated_date": "2024-12-04 00:10:47 UTC"
  }
]