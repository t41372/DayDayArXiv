{
  "date": "2024-12-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-04 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 102 篇论文，主要聚焦于 AI 生成模型、多模态理解、LLM 优化和安全等领域，其中令人印象深刻的包括 Yann LeCun 参与的导航世界模型生成，以及多篇关于 LLM 鲁棒性和高效训练的创新工作；有名学者如 Yann LeCun 和 Jürgen Schmidhuber 的论文脱颖而出，展示了 AI 在视觉导航和认知偏差方面的前沿进展。\n\n下面，我挑选并简要讨论几篇重要的、话题度高的论文，先从 LLM 和多模态模型相关的内容入手，再聊聊 AI 在医疗和科学领域的应用，其他论文则快速掠过，以控制篇幅。重点保留核心学术术语，如 Transformer、Diffusion Models 和 Causal Inference。\n\n### LLM 和多模态模型优化（重点讨论）\n- **TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation（TokenFlow: 多模态理解和生成的统一图像标记器）**  \n  这篇论文提出 TokenFlow，一种统一图像标记器，桥接多模态理解和生成任务。主要贡献是通过双代码本架构分离语义和像素级特征，同时保持对齐，实现高效的多模态处理。发现它在图像生成和理解任务上超越了现有模型，如在 CLIP 基础上提升了细粒度检索性能。\n\n- **Perception Tokens Enhance Visual Reasoning in Multimodal Language Models（感知标记增强多模态语言模型的视觉推理）**  \n  作者引入感知标记作为辅助推理元素，用于处理视觉任务。主要贡献是开发 AURORA 框架，通过 VQVAE 转换深度图和边界框为标记，提升多模态模型在计数和深度任务上的性能。发现它在 BLINK 和 SEED-Bench 等基准上提升了 8-11% 的准确率，显著改善了视觉推理。\n\n- **Best-of-N Jailbreaking（Best-of-N 越狱攻击）**  \n  这篇论文提出一种简单黑盒算法，用于测试 LLM 的安全漏洞。主要贡献是通过采样提示变体（如随机重排）来实现高效攻击，扩展到视觉和音频模型。发现它在 GPT-4o 和 Claude 3.5 上达到 78-89% 的攻击成功率，并揭示 LLM 对细微输入变化的敏感性，强调了安全防护的必要性。\n\n- **ChatTS: Aligning Time Series with LLMs via Synthetic Data（ChatTS: 通过合成数据将时间序列与 LLM 对齐）**  \n  作者构建 ChatTS，一种处理时间序列的多模态 LLM。主要贡献是通过属性-based 合成数据和 Time Series Evol-Instruct 生成方法，提升模型在序列理解和推理上的性能。发现它在时间序列任务中比 GPT-4o 提升 25.8% 的推理准确率，展示了合成数据的潜力。\n\n这些论文突出了 LLM 在多模态和生成任务中的进展，Yann LeCun 的参与（如在 Navigation World Models 中）进一步提升了话题度，它们强调了高效训练和鲁棒性的重要性。\n\n### AI 在医疗和科学应用（相关讨论）\n- **Navigation World Models（导航世界模型）**  \n  Yann LeCun 等作者提出一种基于扩散模型的导航生成框架。主要贡献是使用 Conditional Diffusion Transformer 生成视觉导航轨迹，支持实时交互。发现它在熟悉和陌生环境中均表现出色，能从单张图像想象轨迹，适用于下一代导航系统。\n\n- **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety（探索 AI 驱动聊天机器人对 ASD 或社交焦虑青少年的作用）**  \n  这篇论文调查 AI 聊天机器人（如 Mindstudio）在精神健康支持中的潜力。主要贡献是通过伦理分析讨论其益处（如易访问性和社交指导）和局限（如隐私风险）。发现它能帮助缓解社交紧张，但需进一步优化以减少误导风险。\n\n其他如 \"Deep Variational Bayesian Modeling of Haze Degradation Process\"（在图像去雾中引入变分贝叶斯框架，提升模型鲁棒性）和 \"MRGen: Segmentation Data Engine For Underrepresented MRI Modalities\"（使用扩散模型生成 MRI 合成数据，改善分割任务），这些在医疗图像处理中表现出色，但细节较技术性，这里快速掠过。\n\n### 其他论文（快速掠过）\n对于剩余论文，如 \"Modular addition without black-boxes\"（提出压缩 MLP 层的机制，提升模型解释性）、\"ParetoFlow\"（优化多目标问题的流匹配方法）和 \"JPC: Flexible Inference for Predictive Coding Networks\"（JAX 库用于预测编码网络训练），它们在 ML 优化和特定应用中有所贡献，但非核心话题，故仅列出标题和关键发现：这些工作分别提升了数值积分计算、生成模型泛化和预测任务的效率。\n\n今天的 arXiv 快报到此结束，聚焦于 AI 的创新应用和挑战，欢迎读者关注这些前沿论文！",
  "papers": [
    {
      "arxiv_id": "2412.03773v1",
      "title": "Modular addition without black-boxes: Compressing explanations of MLPs that compute numerical integration",
      "title_zh": "翻译失败",
      "authors": [
        "Chun Hei Yip",
        "Rajashree Agrawal",
        "Lawrence Chan",
        "Jason Gross"
      ],
      "abstract": "The goal of mechanistic interpretability is discovering simpler, low-rank\nalgorithms implemented by models. While we can compress activations into\nfeatures, compressing nonlinear feature-maps -- like MLP layers -- is an open\nproblem. In this work, we present the first case study in rigorously\ncompressing nonlinear feature-maps, which are the leading asymptotic bottleneck\nto compressing small transformer models. We work in the classic setting of the\nmodular addition models, and target a non-vacuous bound on the behaviour of the\nReLU MLP in time linear in the parameter-count of the circuit. To study the\nReLU MLP analytically, we use the infinite-width lens, which turns\npost-activation matrix multiplications into approximate integrals. We discover\na novel interpretation of} the MLP layer in one-layer transformers implementing\nthe ``pizza'' algorithm: the MLP can be understood as evaluating a quadrature\nscheme, where each neuron computes the area of a rectangle under the curve of a\ntrigonometric integral identity. Our code is available at\nhttps://tinyurl.com/mod-add-integration.",
      "tldr_zh": "该研究探讨了机械解释(mechanistic interpretability)，专注于压缩非线性特征映射，如MLP层，这是小型Transformer模型压缩的主要瓶颈。作者针对模加法模型(modular addition models)进行了首个严格案例研究，使用无限宽度透镜(infinite-width lens)将ReLU MLP的激活后矩阵乘法转化为近似积分，从而分析MLP的行为并提供一个线性于电路参数计数的非空洞边界(non-vacuous bound)。关键发现是，MLP层在实现“pizza”算法的一层Transformer中可视为评估一个求积方案(quadrature scheme)，其中每个神经元计算三角积分恒等式下的矩形面积，这为更高效的模型解释和压缩提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03773v1",
      "published_date": "2024-12-04 23:29:07 UTC",
      "updated_date": "2024-12-04 23:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:32:04.844031"
    },
    {
      "arxiv_id": "2412.03772v1",
      "title": "A Contemporary Overview: Trends and Applications of Large Language Models on Mobile Devices",
      "title_zh": "当代概述：大语言模型在移动设备上的趋势和应用",
      "authors": [
        "Lianjun Liu",
        "Hongli An",
        "Pengxuan Chen",
        "Longxiang Ye"
      ],
      "abstract": "With the rapid development of large language models (LLMs), which possess\npowerful natural language processing and generation capabilities, LLMs are\npoised to provide more natural and personalized user experiences. Their\ndeployment on mobile devices is gradually becoming a significant trend in the\nfield of intelligent devices. LLMs have demonstrated tremendous potential in\napplications such as voice assistants, real-time translation, and intelligent\nrecommendations. Advancements in hardware technologies (such as neural network\naccelerators) and network infrastructure (such as 5G) have enabled efficient\nlocal inference and low-latency intelligent responses on mobile devices. This\nreduces reliance on cloud computing while enhancing data privacy and security.\nDevelopers can easily integrate LLM functionalities through open APIs and SDKs,\nenabling the creation of more innovative intelligent applications. The\nwidespread use of LLMs not only enhances the intelligence of mobile devices but\nalso fosters the integrated innovation of fields like augmented reality (AR)\nand the Internet of Things (IoT). This trend is expected to drive the\ndevelopment of the next generation of mobile intelligent applications.",
      "tldr_zh": "本文概述了大语言模型 (LLMs) 在移动设备上的发展趋势和应用潜力，强调其在语音助手、实时翻译和智能推荐等领域提供更自然、个性化的用户体验。\n\n得益于神经网络加速器和 5G 等硬件及网络进步，LLMs 实现了高效本地推理和低延迟响应，减少了对云计算的依赖，同时提升了数据隐私和安全。\n\n开发人员可通过开放 API 和 SDK 轻松集成 LLMs，推动 AR 和 IoT 等领域的创新，并有望驱动下一代移动智能应用的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03772v1",
      "published_date": "2024-12-04 23:25:03 UTC",
      "updated_date": "2024-12-04 23:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:34:17.591308"
    },
    {
      "arxiv_id": "2412.03761v1",
      "title": "Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ximing Wen"
      ],
      "abstract": "Pretrained transformer-based Language Models (LMs) are well-known for their\nability to achieve significant improvement on NLP tasks, but their black-box\nnature, which leads to a lack of interpretability, has been a major concern. My\ndissertation focuses on developing intrinsically interpretable models when\nusing LMs as encoders while maintaining their superior performance via\nprototypical networks. I initiated my research by investigating enhancements in\nperformance for interpretable models of sarcasm detection. My proposed approach\nfocuses on capturing sentiment incongruity to enhance accuracy while offering\ninstance-based explanations for the classification decisions. Later, I\ndeveloped a novel white-box multi-head graph attention-based prototype network\ndesigned to explain the decisions of text classification models without\nsacrificing the accuracy of the original black-box LMs. In addition, I am\nworking on extending the attention-based prototype network with contrastive\nlearning to redesign an interpretable graph neural network, aiming to enhance\nboth the interpretability and performance of the model in document\nclassification.",
      "tldr_zh": "本论文探讨了预训练Transformer-based Language Models (LMs) 在NLP任务中的高性能，但强调了其黑盒性质导致的解释性不足问题。作者通过prototypical networks 开发了内在可解释的文本分类模型，旨在保持LMs的性能优势。关键贡献包括：提出一种捕捉sentiment incongruity的方法来提升sarcasm detection的准确性，并提供instance-based explanations；开发了一个white-box multi-head graph attention-based prototype network，用于解释文本分类决策而不牺牲原模型性能；以及扩展该网络结合contrastive learning，重设计可解释的graph neural network，以提升文档分类的解释性和整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2 pages, 1 figure, accepted by AAAI25 DC",
      "pdf_url": "http://arxiv.org/pdf/2412.03761v1",
      "published_date": "2024-12-04 22:59:35 UTC",
      "updated_date": "2024-12-04 22:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:32:28.955841"
    },
    {
      "arxiv_id": "2412.03756v1",
      "title": "Multi-view Image Diffusion via Coordinate Noise and Fourier Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Theiss",
        "Norman Müller",
        "Daeil Kim",
        "Aayush Prakash"
      ],
      "abstract": "Recently, text-to-image generation with diffusion models has made significant\nadvancements in both higher fidelity and generalization capabilities compared\nto previous baselines. However, generating holistic multi-view consistent\nimages from prompts still remains an important and challenging task. To address\nthis challenge, we propose a diffusion process that attends to time-dependent\nspatial frequencies of features with a novel attention mechanism as well as\nnovel noise initialization technique and cross-attention loss. This\nFourier-based attention block focuses on features from non-overlapping regions\nof the generated scene in order to better align the global appearance. Our\nnoise initialization technique incorporates shared noise and low spatial\nfrequency information derived from pixel coordinates and depth maps to induce\nnoise correlations across views. The cross-attention loss further aligns\nfeatures sharing the same prompt across the scene. Our technique improves SOTA\non several quantitative metrics with qualitatively better results when compared\nto other state-of-the-art approaches for multi-view consistency.",
      "tldr_zh": "本文提出了一种新的多视图图像扩散方法，通过Coordinate Noise和Fourier Attention机制来解决文本到图像生成中多视图一致性的挑战。该方法引入Fourier-based attention block来关注时间相关的空间频率特征，从而更好地对齐生成场景中非重叠区域的全局外观；同时，Coordinate Noise初始化技术利用共享噪声和从像素坐标及深度图派生的低空间频率信息，在视图间诱导噪声相关性，并辅以cross-attention loss进一步对齐共享提示的特征。实验结果显示，该技术在多个定量指标上超越了现有最先进方法，并在多视图一致性方面取得了定性更优的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03756v1",
      "published_date": "2024-12-04 22:49:40 UTC",
      "updated_date": "2024-12-04 22:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:32:42.443660"
    },
    {
      "arxiv_id": "2412.03752v2",
      "title": "Beyond Local Sharpness: Communication-Efficient Global Sharpness-aware Minimization for Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Debora Caldarola",
        "Pietro Cagnasso",
        "Barbara Caputo",
        "Marco Ciccone"
      ],
      "abstract": "Federated learning (FL) enables collaborative model training with privacy\npreservation. Data heterogeneity across edge devices (clients) can cause models\nto converge to sharp minima, negatively impacting generalization and\nrobustness. Recent approaches use client-side sharpness-aware minimization\n(SAM) to encourage flatter minima, but the discrepancy between local and global\nloss landscapes often undermines their effectiveness, as optimizing for local\nsharpness does not ensure global flatness. This work introduces FedGloSS\n(Federated Global Server-side Sharpness), a novel FL approach that prioritizes\nthe optimization of global sharpness on the server, using SAM. To reduce\ncommunication overhead, FedGloSS cleverly approximates sharpness using the\nprevious global gradient, eliminating the need for additional client\ncommunication. Our extensive evaluations demonstrate that FedGloSS consistently\nreaches flatter minima and better performance compared to state-of-the-art FL\nmethods across various federated vision benchmarks.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）中数据异质性导致模型收敛到 sharp minima 的问题，指出现有 client-side Sharpness-aware Minimization (SAM) 方法虽能促进平坦极小点，但无法确保全局损失景观的 flatness，从而影响模型泛化和鲁棒性。论文提出 FedGloSS，一种通信高效的服务器端全局 sharpness 优化方法，通过利用之前的全局梯度来近似 sharpness，避免额外客户端通信开销。实验结果显示，FedGloSS 在多种 FL 视觉基准上比现有方法实现更平坦的极小点和显著更好的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CVPR 2025, 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.03752v2",
      "published_date": "2024-12-04 22:46:06 UTC",
      "updated_date": "2025-03-30 21:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:32:52.460724"
    },
    {
      "arxiv_id": "2412.03745v1",
      "title": "Deep Variational Bayesian Modeling of Haze Degradation Process",
      "title_zh": "深度变分贝叶斯雾霾退化过程建模",
      "authors": [
        "Eun Woo Im",
        "Junsung Shin",
        "Sungyong Baik",
        "Tae Hyun Kim"
      ],
      "abstract": "Relying on the representation power of neural networks, most recent works\nhave often neglected several factors involved in haze degradation, such as\ntransmission (the amount of light reaching an observer from a scene over\ndistance) and atmospheric light. These factors are generally unknown, making\ndehazing problems ill-posed and creating inherent uncertainties. To account for\nsuch uncertainties and factors involved in haze degradation, we introduce a\nvariational Bayesian framework for single image dehazing. We propose to take\nnot only a clean image and but also transmission map as latent variables, the\nposterior distributions of which are parameterized by corresponding neural\nnetworks: dehazing and transmission networks, respectively. Based on a physical\nmodel for haze degradation, our variational Bayesian framework leads to a new\nobjective function that encourages the cooperation between them, facilitating\nthe joint training of and thereby boosting the performance of each other. In\nour framework, a dehazing network can estimate a clean image independently of a\ntransmission map estimation during inference, introducing no overhead.\nFurthermore, our model-agnostic framework can be seamlessly incorporated with\nother existing dehazing networks, greatly enhancing the performance\nconsistently across datasets and models.",
      "tldr_zh": "这篇论文提出了一种基于变分贝叶斯框架（variational Bayesian framework）的深度模型，用于处理单图像去雾问题，通过考虑传输（transmission）和大气光的 uncertainties，解决现有方法的局限性。框架将干净图像和传输图作为潜在变量，由去雾网络和传输网络参数化，并基于雾霾退化的物理模型设计了一个新目标函数，促进两网络的联合训练和性能提升。在推理阶段，去雾网络能独立估计干净图像，且该模型无关框架可无缝整合到其他去雾网络中，一致地在多个数据集和模型上提升去雾效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in CIKM 2023, 10 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03745v1",
      "published_date": "2024-12-04 22:24:37 UTC",
      "updated_date": "2024-12-04 22:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:33:05.112754"
    },
    {
      "arxiv_id": "2412.03740v1",
      "title": "Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety",
      "title_zh": "探讨 AI 驱动聊天机器人对患有 ASD 或社交焦虑的青少年和年轻成人的作用",
      "authors": [
        "Dilan Mian"
      ],
      "abstract": "The world can be a complex and difficult place to navigate. People with\nHigh-Functioning Autistic Spectrum Disorder as well as general social\nineptitude often face navigation challenges that individuals of other\ndemographics simply do not themselves. This can become even more pronounced\nwith people of that specific group when they are in their teenage years and\nearly adulthood (that being the usual age range of college students). When they\nare at such a vulnerable age, they can be far more susceptible to the struggles\nof becoming comfortable and content with social interactions as well as having\nstrong relationships (outside their immediate family). Concerning this, the\nrapid emergence of artificial intelligence chatbots has led to many of them\nbeing used to benefit people of different ages and demographics with easy\naccessibility. With this, if there is anything that people with\nHigh-Functioning ASD and social ineptitude want when it comes to guidance\ntowards self-improvement, surely easy accessibility would be one. What are the\npotential benefits and limitations of using a Mindstudio AI-powered chatbot to\nprovide mental health support for teens and young adults with the\naforementioned conditions? What could be done with a tool like this to help\nthose individuals navigate ethical dilemmas within different social\nenvironments to reduce existing social tensions? This paper addresses these\nqueries and offers insights to inform future discussions on the subject.",
      "tldr_zh": "这篇论文探讨了AI-powered chatbots（如Mindstudio）在帮助患有ASD（高功能自闭谱障碍）或社交焦虑的青少年和年轻成年人的作用，重点分析了这些工具在提供心理支持方面的潜在益处和局限性。研究强调了聊天机器人的易访问性如何缓解个体在社交互动和关系构建中的挑战，同时讨论了其在处理社交环境伦理困境的应用潜力。最终，论文提供了见解，以指导未来关于此主题的讨论和改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 30 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03740v1",
      "published_date": "2024-12-04 22:10:58 UTC",
      "updated_date": "2024-12-04 22:10:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:33:17.829638"
    },
    {
      "arxiv_id": "2412.03719v1",
      "title": "From Language Models over Tokens to Language Models over Characters",
      "title_zh": "从基于标记的语言模型到基于字符的语言模型",
      "authors": [
        "Tim Vieira",
        "Ben LeBrun",
        "Mario Giulianelli",
        "Juan Luis Gastaldi",
        "Brian DuSell",
        "John Terilla",
        "Timothy J. O'Donnell",
        "Ryan Cotterell"
      ],
      "abstract": "Modern language models are internally -- and mathematically -- distributions\nover token strings rather than \\emph{character} strings, posing numerous\nchallenges for programmers building user applications on top of them. For\nexample, if a prompt is specified as a character string, it must be tokenized\nbefore passing it to the token-level language model. Thus, the tokenizer and\nconsequent analyses are very sensitive to the specification of the prompt\n(e.g., if the prompt ends with a space or not). This paper presents algorithms\nfor converting token-level language models to character-level ones. We present\nboth exact and approximate algorithms. In the empirical portion of the paper,\nwe benchmark the practical runtime and approximation quality. We find that --\neven with a small computation budget -- our method is able to accurately\napproximate the character-level distribution (less than 0.00021 excess bits /\ncharacter) at reasonably fast speeds (46.3 characters / second) on the Llama\n3.1 8B language model.",
      "tldr_zh": "本研究探讨了现代语言模型基于 token 而非字符分布的问题，这导致提示处理（如 tokenization）对输入细节高度敏感，增加了开发者应用的挑战。论文提出算法将 token-level language models 转换为 character-level 模型，包括精确和近似方法，以更灵活地处理字符级输入。实验结果显示，在 Llama 3.1 8B 模型上，即使计算预算有限，该方法也能准确近似字符级分布（小于 0.00021 excess bits / character），并实现较快速度（46.3 characters / second）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03719v1",
      "published_date": "2024-12-04 21:19:20 UTC",
      "updated_date": "2024-12-04 21:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:33:28.234625"
    },
    {
      "arxiv_id": "2412.03718v2",
      "title": "ParetoFlow: Guided Flows in Multi-Objective Optimization",
      "title_zh": "ParetoFlow：多目标优化中的引导流",
      "authors": [
        "Ye Yuan",
        "Can Chen",
        "Christopher Pal",
        "Xue Liu"
      ],
      "abstract": "In offline multi-objective optimization (MOO), we leverage an offline dataset\nof designs and their associated labels to simultaneously minimize multiple\nobjectives. This setting more closely mirrors complex real-world problems\ncompared to single-objective optimization. Recent works mainly employ\nevolutionary algorithms and Bayesian optimization, with limited attention given\nto the generative modeling capabilities inherent in such data. In this study,\nwe explore generative modeling in offline MOO through flow matching, noted for\nits effectiveness and efficiency. We introduce ParetoFlow, specifically\ndesigned to guide flow sampling to approximate the Pareto front. Traditional\npredictor (classifier) guidance is inadequate for this purpose because it\nmodels only a single objective. In response, we propose a multi-objective\npredictor guidance module that assigns each sample a weight vector,\nrepresenting a weighted distribution across multiple objective predictions. A\nlocal filtering scheme is introduced to address non-convex Pareto fronts. These\nweights uniformly cover the entire objective space, effectively directing\nsample generation towards the Pareto front. Since distributions with similar\nweights tend to generate similar samples, we introduce a neighboring evolution\nmodule to foster knowledge sharing among neighboring distributions. This module\ngenerates offspring from these distributions, and selects the most promising\none for the next iteration. Our method achieves state-of-the-art performance\nacross various tasks.",
      "tldr_zh": "本研究提出ParetoFlow，一种用于离线多目标优化（MOO）的生成建模框架，通过flow matching引导采样以逼近Pareto前沿，相比传统进化算法和贝叶斯优化，更注重数据集的生成能力。ParetoFlow引入多目标预测器指导模块，为每个样本分配权重向量以覆盖多个目标预测，并采用局部过滤方案处理非凸Pareto前沿，同时通过相邻进化模块促进相邻分布间知识共享，生成并选择最优后代。实验结果显示，该方法在各种任务上实现最先进性能，提升了多目标优化的效率和有效性。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03718v2",
      "published_date": "2024-12-04 21:14:18 UTC",
      "updated_date": "2025-02-20 13:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:33:40.178934"
    },
    {
      "arxiv_id": "2412.03715v1",
      "title": "PathletRL++: Optimizing Trajectory Pathlet Extraction and Dictionary Formation via Reinforcement Learning",
      "title_zh": "Pathlet",
      "authors": [
        "Gian Alix",
        "Arian Haghparast",
        "Manos Papagelis"
      ],
      "abstract": "Advances in tracking technologies have spurred the rapid growth of\nlarge-scale trajectory data. Building a compact collection of pathlets,\nreferred to as a trajectory pathlet dictionary, is essential for supporting\nmobility-related applications. Existing methods typically adopt a top-down\napproach, generating numerous candidate pathlets and selecting a subset,\nleading to high memory usage and redundant storage from overlapping pathlets.\nTo overcome these limitations, we propose a bottom-up strategy that\nincrementally merges basic pathlets to build the dictionary, reducing memory\nrequirements by up to 24,000 times compared to baseline methods. The approach\nbegins with unit-length pathlets and iteratively merges them while optimizing\nutility, which is defined using newly introduced metrics of trajectory loss and\nrepresentability. We develop a deep reinforcement learning framework,\nPathletRL, which utilizes Deep Q-Networks (DQN) to approximate the utility\nfunction, resulting in a compact and efficient pathlet dictionary. Experiments\non both synthetic and real-world datasets demonstrate that our method\noutperforms state-of-the-art techniques, reducing the size of the constructed\ndictionary by up to 65.8%. Additionally, our results show that only half of the\ndictionary pathlets are needed to reconstruct 85% of the original trajectory\ndata. Building on PathletRL, we introduce PathletRL++, which extends the\noriginal model by incorporating a richer state representation and an improved\nreward function to optimize decision-making during pathlet merging. These\nenhancements enable the agent to gain a more nuanced understanding of the\nenvironment, leading to higher-quality pathlet dictionaries. PathletRL++\nachieves even greater dictionary size reduction, surpassing the performance of\nPathletRL, while maintaining high trajectory representability.",
      "tldr_zh": "该论文提出了一种自下而上的策略，用于优化轨迹路径片段（pathlet）提取和字典构建，旨在解决现有自上而下方法的高内存占用和冗余问题。该方法从单位长度pathlets开始，通过迭代合并来优化效用，利用Deep Q-Networks (DQN)的PathletRL框架来近似效用函数，并引入轨迹损失和可表示性指标。实验结果显示，该方法在合成和真实数据集上比现有技术减少字典大小高达65.8%，并只需字典pathlets的一半即可重构85%的原始轨迹数据。进一步，PathletRL++通过更丰富的状态表示和改进的奖励函数提升决策优化，实现更大字典大小减小，同时保持高轨迹可表示性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03715v1",
      "published_date": "2024-12-04 21:09:43 UTC",
      "updated_date": "2024-12-04 21:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:33:52.656821"
    },
    {
      "arxiv_id": "2412.03710v2",
      "title": "CIKAN: Constraint Informed Kolmogorov-Arnold Networks for Autonomous Spacecraft Rendezvous using Time Shift Governor",
      "title_zh": "翻译失败",
      "authors": [
        "Taehyeun Kim",
        "Anouck Girard",
        "Ilya Kolmanovsky"
      ],
      "abstract": "The paper considers a Constrained-Informed Neural Network (CINN)\napproximation for the Time Shift Governor (TSG), which is an add-on scheme to\nthe nominal closed-loop system used to enforce constraints by time-shifting the\nreference trajectory in spacecraft rendezvous applications. We incorporate\nKolmogorov-Arnold Networks (KANs), an emerging architecture in the AI\ncommunity, as a fundamental component of CINN and propose a\nConstrained-Informed Kolmogorov-Arnold Network (CIKAN)-based approximation for\nTSG. We demonstrate the effectiveness of the CIKAN-based TSG through\nsimulations of constrained spacecraft rendezvous missions on highly elliptic\norbits and present comparisons between CIKANs, MLP-based CINNs, and the\nconventional TSG.",
      "tldr_zh": "该论文提出了一种 Constraint Informed Kolmogorov-Arnold Network (CIKAN)，将 Kolmogorov-Arnold Networks (KANs) 整合到 Constraint Informed Neural Network (CINN) 中，用于近似 Time Shift Governor (TSG)，以在自主航天器交会任务中通过时间偏移参考轨迹强制执行约束。CIKAN 旨在解决传统 TSG 的局限性，通过其新兴架构提升约束处理效率。模拟实验在高度椭圆轨道航天器交会任务中验证了 CIKAN 的有效性，并显示其性能优于 MLP-based CINNs 和传统 TSG。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03710v2",
      "published_date": "2024-12-04 20:58:06 UTC",
      "updated_date": "2024-12-06 19:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:34:29.235987"
    },
    {
      "arxiv_id": "2412.03693v1",
      "title": "System Test Case Design from Requirements Specifications: Insights and Challenges of Using ChatGPT",
      "title_zh": "从需求规范中设计系统测试用例：使用 ChatGPT 的见解与挑战",
      "authors": [
        "Shreya Bhatia",
        "Tarushi Gandhi",
        "Dhruv Kumar",
        "Pankaj Jalote"
      ],
      "abstract": "System testing is essential in any software development project to ensure\nthat the final products meet the requirements. Creating comprehensive test\ncases for system testing from requirements is often challenging and\ntime-consuming. This paper explores the effectiveness of using Large Language\nModels (LLMs) to generate test case designs from Software Requirements\nSpecification (SRS) documents. In this study, we collected the SRS documents of\nfive software engineering projects containing functional and non-functional\nrequirements, which were implemented, tested, and delivered by respective\ndeveloper teams. For generating test case designs, we used ChatGPT-4o Turbo\nmodel. We employed prompt-chaining, starting with an initial context-setting\nprompt, followed by prompts to generate test cases for each use case. We\nassessed the quality of the generated test case designs through feedback from\nthe same developer teams as mentioned above. Our experiments show that about 87\npercent of the generated test cases were valid, with the remaining 13 percent\neither not applicable or redundant. Notably, 15 percent of the valid test cases\nwere previously not considered by developers in their testing. We also tasked\nChatGPT with identifying redundant test cases, which were subsequently\nvalidated by the respective developers to identify false positives and to\nuncover any redundant test cases that may have been missed by the developers\nthemselves. This study highlights the potential of leveraging LLMs for test\ngeneration from the Requirements Specification document and also for assisting\ndevelopers in quickly identifying and addressing redundancies, ultimately\nimproving test suite quality and efficiency of the testing procedure.",
      "tldr_zh": "本文研究了使用 Large Language Models (LLMs)，特别是 ChatGPT-4o Turbo，从 Software Requirements Specification (SRS) 文档中生成系统测试用例的设计，以提高软件开发中的测试效率。研究方法包括收集五个真实软件工程项目的 SRS 文档，并采用 prompt-chaining 技术生成测试用例，然后由开发团队评估。结果显示，87% 的生成测试用例有效，其中15% 为开发人员之前未考虑的新用例，且 LLMs 成功协助识别冗余测试用例，从而提升了测试套件的质量和整体效率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03693v1",
      "published_date": "2024-12-04 20:12:27 UTC",
      "updated_date": "2024-12-04 20:12:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:34:40.780876"
    },
    {
      "arxiv_id": "2412.03689v1",
      "title": "Predicting Pedestrian Crossing Behavior in Germany and Japan: Insights into Model Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Zhang",
        "Janis Sprenger",
        "Zhongjun Ni",
        "Christian Berger"
      ],
      "abstract": "Predicting pedestrian crossing behavior is important for intelligent traffic\nsystems to avoid pedestrian-vehicle collisions. Most existing pedestrian\ncrossing behavior models are trained and evaluated on datasets collected from a\nsingle country, overlooking differences between countries. To address this gap,\nwe compared pedestrian road-crossing behavior at unsignalized crossings in\nGermany and Japan. We presented four types of machine learning models to\npredict gap selection behavior, zebra crossing usage, and their trajectories\nusing simulator data collected from both countries. When comparing the\ndifferences between countries, pedestrians from the study conducted in Japan\nare more cautious, selecting larger gaps compared to those in Germany. We\nevaluate and analyze model transferability. Our results show that neural\nnetworks outperform other machine learning models in predicting gap selection\nand zebra crossing usage, while random forest models perform best on trajectory\nprediction tasks, demonstrating strong performance and transferability. We\ndevelop a transferable model using an unsupervised clustering method, which\nimproves prediction accuracy for gap selection and trajectory prediction. These\nfindings provide a deeper understanding of pedestrian crossing behaviors in\ndifferent countries and offer valuable insights into model transferability.",
      "tldr_zh": "本文研究了预测德国和日本行人过马路行为的差异，以提升智能交通系统的碰撞避免能力。研究使用四种机器学习模型（包括neural networks和random forest）基于模拟数据预测间隙选择行为、斑马线使用和轨迹，结果显示日本行人更谨慎，选择更大的间隙。neural networks在间隙选择和斑马线使用预测上表现最佳，而random forest在轨迹预测任务中更出色；此外，通过unsupervised clustering方法开发的模型显著提高了预测准确性和model transferability。这些发现为理解跨国行人行为和模型可转移性提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T40, 68T45",
        "I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 12 figures, 11 tables. Accepted in IEEE Transactions on\n  Intelligent Vehicles",
      "pdf_url": "http://arxiv.org/pdf/2412.03689v1",
      "published_date": "2024-12-04 19:55:40 UTC",
      "updated_date": "2024-12-04 19:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:34:53.322596"
    },
    {
      "arxiv_id": "2412.03682v1",
      "title": "Designing DNNs for a trade-off between robustness and processing performance in embedded devices",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "Machine learning-based embedded systems employed in safety-critical\napplications such as aerospace and autonomous driving need to be robust against\nperturbations produced by soft errors. Soft errors are an increasing concern in\nmodern digital processors since smaller transistor geometries and lower\nvoltages give electronic devices a higher sensitivity to background radiation.\nThe resilience of deep neural network (DNN) models to perturbations in their\nparameters is determined, to a large extent, by the structure of the model\nitself, and also by the selected numerical representation and used arithmetic\nprecision. When compression techniques such as model pruning and model\nquantization are applied to reduce memory footprint and computational\ncomplexity for deployment, both model structure and numerical representation\nare modified and thus, soft error robustness also changes. In this sense,\nalthough the choice of activation functions (AFs) in DNN models is frequently\nignored, it conditions not only their accuracy and trainability, but also\ncompressibility rates and numerical robustness. This paper investigates the\nsuitability of using bounded AFs to improve model robustness against DNN\nparameter perturbations, assessing at the same time the impact of this choice\non deployment in terms of model accuracy, compressibility, and computational\nburden. In particular, we analyze encoder-decoder fully convolutional models\naimed at performing semantic segmentation tasks on hyperspectral images for\nscene understanding in autonomous driving. Deployment characterization is\nperformed experimentally on an AMD-Xilinx's KV260 SoM.",
      "tldr_zh": "本研究探讨了在嵌入式设备中设计深度神经网络 (DNNs)，以平衡对软错误 (soft errors) 的鲁棒性和处理性能的权衡问题，特别是针对安全关键应用如航空和自动驾驶。论文重点调查使用有界激活函数 (bounded AFs) 来提升模型对参数扰动的鲁棒性，同时评估其对模型准确性、可压缩性（如模型剪枝和量化）和计算负担的影响。实验基于编码器-解码器全卷积模型 (encoder-decoder fully convolutional models)，应用于高光谱图像 (hyperspectral images) 的语义分割任务，并在 AMD-Xilinx's KV260 SoM 上进行部署验证，结果显示 bounded AFs 能显著改善鲁棒性，但需优化以维持整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03682v1",
      "published_date": "2024-12-04 19:34:33 UTC",
      "updated_date": "2024-12-04 19:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:35:04.793833"
    },
    {
      "arxiv_id": "2412.03676v1",
      "title": "JPC: Flexible Inference for Predictive Coding Networks in JAX",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Innocenti",
        "Paul Kinghorn",
        "Will Yun-Farmbrough",
        "Miguel De Llanza Varona",
        "Ryan Singh",
        "Christopher L. Buckley"
      ],
      "abstract": "We introduce JPC, a JAX library for training neural networks with Predictive\nCoding. JPC provides a simple, fast and flexible interface to train a variety\nof PC networks (PCNs) including discriminative, generative and hybrid models.\nUnlike existing libraries, JPC leverages ordinary differential equation solvers\nto integrate the gradient flow inference dynamics of PCNs. We find that a\nsecond-order solver achieves significantly faster runtimes compared to standard\nEuler integration, with comparable performance on a range of tasks and network\ndepths. JPC also provides some theoretical tools that can be used to study\nPCNs. We hope that JPC will facilitate future research of PC. The code is\navailable at https://github.com/thebuckleylab/jpc.",
      "tldr_zh": "本研究引入了 JPC，这是一个基于 JAX 的库，用于训练预测编码神经网络 (PCNs)，支持判别式、生成式和混合模型，提供简单、快速且灵活的接口。JPC 通过利用普通微分方程求解器来整合 PCNs 的梯度流推断动态，其中二阶求解器相较于标准 Euler 积分显著提高了运行效率，同时在各种任务和网络深度上保持了可比性能。研究还提供了理论工具来辅助 PCNs 的研究，并开源代码以促进未来相关工作。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03676v1",
      "published_date": "2024-12-04 19:15:34 UTC",
      "updated_date": "2024-12-04 19:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:35:16.394843"
    },
    {
      "arxiv_id": "2412.03671v1",
      "title": "Tight Lower Bounds and Improved Convergence in Performative Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Pedram Khorsandi",
        "Rushil Gupta",
        "Mehrnaz Mofakhami",
        "Simon Lacoste-Julien",
        "Gauthier Gidel"
      ],
      "abstract": "Performative prediction is a framework accounting for the shift in the data\ndistribution induced by the prediction of a model deployed in the real world.\nEnsuring rapid convergence to a stable solution where the data distribution\nremains the same after the model deployment is crucial, especially in evolving\nenvironments. This paper extends the Repeated Risk Minimization (RRM) framework\nby utilizing historical datasets from previous retraining snapshots, yielding a\nclass of algorithms that we call Affine Risk Minimizers and enabling\nconvergence to a performatively stable point for a broader class of problems.\nWe introduce a new upper bound for methods that use only the final iteration of\nthe dataset and prove for the first time the tightness of both this new bound\nand the previous existing bounds within the same regime. We also prove that\nutilizing historical datasets can surpass the lower bound for last iterate RRM,\nand empirically observe faster convergence to the stable point on various\nperformative prediction benchmarks. We offer at the same time the first lower\nbound analysis for RRM within the class of Affine Risk Minimizers, quantifying\nthe potential improvements in convergence speed that could be achieved with\nother variants in our framework.",
      "tldr_zh": "该论文研究了Performative Prediction框架中模型部署导致数据分布变化的问题，扩展了Repeated Risk Minimization (RRM)框架，通过利用历史数据集引入Affine Risk Minimizers算法，以实现更广泛问题的收敛到performatively stable点。主要贡献包括证明了一个新upper bound的紧致性，并首次证实使用历史数据集能超越RRM的lower bound，导致更快收敛。实验结果显示，该方法在各种基准上表现出更快的稳定点收敛，同时提供了RRM在Affine Risk Minimizers类中的首个lower bound分析，量化了潜在的收敛速度改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03671v1",
      "published_date": "2024-12-04 19:06:19 UTC",
      "updated_date": "2024-12-04 19:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:35:28.907888"
    },
    {
      "arxiv_id": "2412.03665v1",
      "title": "Personalizing Multimodal Large Language Models for Image Captioning: An Experimental Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Bucciarelli",
        "Nicholas Moratelli",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "The task of image captioning demands an algorithm to generate natural\nlanguage descriptions of visual inputs. Recent advancements have seen a\nconvergence between image captioning research and the development of Large\nLanguage Models (LLMs) and Multimodal LLMs -- like GPT-4V and Gemini -- which\nextend the capabilities of text-only LLMs to multiple modalities. This paper\ninvestigates whether Multimodal LLMs can supplant traditional image captioning\nnetworks by evaluating their performance on various image description\nbenchmarks. We explore both the zero-shot capabilities of these models and\ntheir adaptability to different semantic domains through fine-tuning methods,\nincluding prompt learning, prefix tuning, and low-rank adaptation. Our results\ndemonstrate that while Multimodal LLMs achieve impressive zero-shot\nperformance, fine-tuning for specific domains while maintaining their\ngeneralization capabilities intact remains challenging. We discuss the\nimplications of these findings for future research in image captioning and the\ndevelopment of more adaptable Multimodal LLMs.",
      "tldr_zh": "这篇论文通过实验分析探讨了如何个性化Multimodal Large Language Models（Multimodal LLMs）以提升图像字幕任务的性能，评估其是否能取代传统网络。研究方法包括测试模型的zero-shot能力，以及通过prompt learning、prefix tuning和low-rank adaptation等微调技术适应不同语义领域。结果表明，Multimodal LLMs在零-shot场景下表现出色，但微调特定领域时难以同时保持泛化能力。作者讨论了这些发现对未来图像字幕研究和更具适应性的Multimodal LLMs发展的启示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 Workshop on Green Foundation Models",
      "pdf_url": "http://arxiv.org/pdf/2412.03665v1",
      "published_date": "2024-12-04 19:01:06 UTC",
      "updated_date": "2024-12-04 19:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:35:41.416724"
    },
    {
      "arxiv_id": "2412.03572v2",
      "title": "Navigation World Models",
      "title_zh": "导航世界模型",
      "authors": [
        "Amir Bar",
        "Gaoyue Zhou",
        "Danny Tran",
        "Trevor Darrell",
        "Yann LeCun"
      ],
      "abstract": "Navigation is a fundamental skill of agents with visual-motor capabilities.\nWe introduce a Navigation World Model (NWM), a controllable video generation\nmodel that predicts future visual observations based on past observations and\nnavigation actions. To capture complex environment dynamics, NWM employs a\nConditional Diffusion Transformer (CDiT), trained on a diverse collection of\negocentric videos of both human and robotic agents, and scaled up to 1 billion\nparameters. In familiar environments, NWM can plan navigation trajectories by\nsimulating them and evaluating whether they achieve the desired goal. Unlike\nsupervised navigation policies with fixed behavior, NWM can dynamically\nincorporate constraints during planning. Experiments demonstrate its\neffectiveness in planning trajectories from scratch or by ranking trajectories\nsampled from an external policy. Furthermore, NWM leverages its learned visual\npriors to imagine trajectories in unfamiliar environments from a single input\nimage, making it a flexible and powerful tool for next-generation navigation\nsystems.",
      "tldr_zh": "本研究提出了一种Navigation World Model (NWM)，这是一个可控的视频生成模型，用于基于过去的视觉观察和导航动作预测未来的环境动态。NWM 采用Conditional Diffusion Transformer (CDiT)架构，训练于多样化的egocentric视频数据集（包括人类和机器人代理），并扩展到10亿参数规模，从而捕捉复杂的环境变化。在熟悉环境中，NWM 通过模拟轨迹并动态加入约束来规划导航路径，并在实验中证明其在从零开始规划或对外部策略采样轨迹排序方面的有效性；此外，它还能利用学到的视觉先验，从单个输入图像想象不熟悉环境中的轨迹，提升了下一代导航系统的灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project page: https://www.amirbar.net/nwm/",
      "pdf_url": "http://arxiv.org/pdf/2412.03572v2",
      "published_date": "2024-12-04 18:59:45 UTC",
      "updated_date": "2025-04-11 19:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:35:52.714033"
    },
    {
      "arxiv_id": "2412.03568v1",
      "title": "The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control",
      "title_zh": "翻译失败",
      "authors": [
        "Ruili Feng",
        "Han Zhang",
        "Zhantao Yang",
        "Jie Xiao",
        "Zhilei Shu",
        "Zhiheng Liu",
        "Andy Zheng",
        "Yukun Huang",
        "Yu Liu",
        "Hongyang Zhang"
      ],
      "abstract": "We present The Matrix, the first foundational realistic world simulator\ncapable of generating continuous 720p high-fidelity real-scene video streams\nwith real-time, responsive control in both first- and third-person\nperspectives, enabling immersive exploration of richly dynamic environments.\nTrained on limited supervised data from AAA games like Forza Horizon 5 and\nCyberpunk 2077, complemented by large-scale unsupervised footage from\nreal-world settings like Tokyo streets, The Matrix allows users to traverse\ndiverse terrains -- deserts, grasslands, water bodies, and urban landscapes --\nin continuous, uncut hour-long sequences. Operating at 16 FPS, the system\nsupports real-time interactivity and demonstrates zero-shot generalization,\ntranslating virtual game environments to real-world contexts where collecting\ncontinuous movement data is often infeasible. For example, The Matrix can\nsimulate a BMW X3 driving through an office setting--an environment present in\nneither gaming data nor real-world sources. This approach showcases the\npotential of AAA game data to advance robust world models, bridging the gap\nbetween simulations and real-world applications in scenarios with limited data.",
      "tldr_zh": "我们介绍了 The Matrix，这是一个首个基础现实世界模拟器，能够生成连续 720p 高保真视频流，支持实时互动控制和第一/第三人称视角，允许用户探索多样动态环境，如沙漠、草地、水体和城市景观。系统训练于有限的监督数据（如 AAA games Forza Horizon 5 和 Cyberpunk 2077）和大规模无监督真实世界视频（如东京街道），实现了 16 FPS 的运行速度和 zero-shot generalization，能够将虚拟环境扩展到真实场景中，例如模拟 BMW X3 在办公室行驶。The Matrix 展示了利用 AAA 游戏数据构建鲁棒世界模型的潜力，有助于桥接模拟与真实世界应用，尤其在数据有限的情况下。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03568v1",
      "published_date": "2024-12-04 18:59:05 UTC",
      "updated_date": "2024-12-04 18:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:36:06.060015"
    },
    {
      "arxiv_id": "2412.03561v1",
      "title": "FLAIR: VLM with Fine-grained Language-informed Image Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Xiao",
        "Sanghwan Kim",
        "Mariana-Iuliana Georgescu",
        "Zeynep Akata",
        "Stephan Alaniz"
      ],
      "abstract": "CLIP has shown impressive results in aligning images and texts at scale.\nHowever, its ability to capture detailed visual features remains limited\nbecause CLIP matches images and texts at a global level. To address this issue,\nwe propose FLAIR, Fine-grained Language-informed Image Representations, an\napproach that utilizes long and detailed image descriptions to learn localized\nimage embeddings. By sampling diverse sub-captions that describe fine-grained\ndetails about an image, we train our vision-language model to produce not only\nglobal embeddings but also text-specific image representations. Our model\nintroduces text-conditioned attention pooling on top of local image tokens to\nproduce fine-grained image representations that excel at retrieving detailed\nimage content. We achieve state-of-the-art performance on both, existing\nmultimodal retrieval benchmarks, as well as, our newly introduced fine-grained\nretrieval task which evaluates vision-language models' ability to retrieve\npartial image content. Furthermore, our experiments demonstrate the\neffectiveness of FLAIR trained on 30M image-text pairs in capturing\nfine-grained visual information, including zero-shot semantic segmentation,\noutperforming models trained on billions of pairs. Code is available at\nhttps://github.com/ExplainableML/flair .",
      "tldr_zh": "该论文提出 FLAIR，一种视觉语言模型 (VLM)，旨在解决 CLIP 在全局匹配图像和文本时无法捕获细粒度视觉特征的问题。FLAIR 通过使用长详细图像描述和多样化子标题采样，训练模型生成全局嵌入以及文本特定的本地化图像表示，并引入文本条件注意力池化 (text-conditioned attention pooling) 来提升细粒度内容检索能力。在现有多模态检索基准和新细粒度检索任务上，FLAIR 实现了最先进性能，并在零样本语义分割等任务中表现出色，仅使用 30M 图像-文本对就超越了在数十亿对上训练的模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03561v1",
      "published_date": "2024-12-04 18:56:04 UTC",
      "updated_date": "2024-12-04 18:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:36:18.060958"
    },
    {
      "arxiv_id": "2412.03556v2",
      "title": "Best-of-N Jailbreaking",
      "title_zh": "翻译失败",
      "authors": [
        "John Hughes",
        "Sara Price",
        "Aengus Lynch",
        "Rylan Schaeffer",
        "Fazl Barez",
        "Sanmi Koyejo",
        "Henry Sleight",
        "Erik Jones",
        "Ethan Perez",
        "Mrinank Sharma"
      ],
      "abstract": "We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that\njailbreaks frontier AI systems across modalities. BoN Jailbreaking works by\nrepeatedly sampling variations of a prompt with a combination of augmentations\n- such as random shuffling or capitalization for textual prompts - until a\nharmful response is elicited. We find that BoN Jailbreaking achieves high\nattack success rates (ASRs) on closed-source language models, such as 89% on\nGPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.\nFurther, it is similarly effective at circumventing state-of-the-art\nopen-source defenses like circuit breakers. BoN also seamlessly extends to\nother modalities: it jailbreaks vision language models (VLMs) such as GPT-4o\nand audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific\naugmentations. BoN reliably improves when we sample more augmented prompts.\nAcross all modalities, ASR, as a function of the number of samples (N),\nempirically follows power-law-like behavior for many orders of magnitude. BoN\nJailbreaking can also be composed with other black-box algorithms for even more\neffective attacks - combining BoN with an optimized prefix attack achieves up\nto a 35% increase in ASR. Overall, our work indicates that, despite their\ncapability, language models are sensitive to seemingly innocuous changes to\ninputs, which attackers can exploit across modalities.",
      "tldr_zh": "这篇论文提出了 Best-of-N (BoN) Jailbreaking，一种简单的黑盒算法，用于越狱（jailbreaking）前沿 AI 系统，包括语言、视觉和音频模态，通过重复采样提示变体（如随机打乱或大写变换）来诱导有害响应。实验结果显示，该算法在 GPT-4o 上达到 89% 的攻击成功率 (ASR)，在 Claude 3.5 Sonnet 上达到 78%，并能有效绕过开源防御措施，且 ASR 随样本数量呈幂律-like 行为而提升。与其他算法组合后，ASR 可提高多达 35%。总体上，该研究揭示了语言模型对输入微小变化的脆弱性，为 AI 安全提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03556v2",
      "published_date": "2024-12-04 18:51:32 UTC",
      "updated_date": "2024-12-19 22:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:36:30.816061"
    },
    {
      "arxiv_id": "2412.03548v2",
      "title": "Perception Tokens Enhance Visual Reasoning in Multimodal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mahtab Bigverdi",
        "Zelun Luo",
        "Cheng-Yu Hsieh",
        "Ethan Shen",
        "Dongping Chen",
        "Linda G. Shapiro",
        "Ranjay Krishna"
      ],
      "abstract": "Multimodal language models (MLMs) still face challenges in fundamental visual\nperception tasks where specialized models excel. Tasks requiring reasoning\nabout 3D structures benefit from depth estimation, and reasoning about 2D\nobject instances benefits from object detection. Yet, MLMs can not produce\nintermediate depth or boxes to reason over. Finetuning MLMs on relevant data\ndoesn't generalize well and outsourcing computation to specialized vision tools\nis too compute-intensive and memory-inefficient. To address this, we introduce\nPerception Tokens, intrinsic image representations designed to assist reasoning\ntasks where language is insufficient. Perception tokens act as auxiliary\nreasoning tokens, akin to chain-of-thought prompts in language models. For\nexample, in a depth-related task, an MLM augmented with perception tokens can\nreason by generating a depth map as tokens, enabling it to solve the problem\neffectively. We propose AURORA, a training method that augments MLMs with\nperception tokens for improved reasoning over visual inputs. AURORA leverages a\nVQVAE to transform intermediate image representations, such as depth maps into\na tokenized format and bounding box tokens, which is then used in a multi-task\ntraining framework. AURORA achieves notable improvements across counting\nbenchmarks: +10.8% on BLINK, +11.3% on CVBench, and +8.3% on SEED-Bench,\noutperforming finetuning approaches in generalization across datasets. It also\nimproves on relative depth: over +6% on BLINK. With perception tokens, AURORA\nexpands the scope of MLMs beyond language-based reasoning, paving the way for\nmore effective visual reasoning capabilities.",
      "tldr_zh": "该论文指出，多模态语言模型 (MLMs) 在视觉感知任务中存在挑战，例如处理3D结构和2D物体实例时无法生成中间表示如深度图或边界框。研究引入 Perception Tokens 作为辅助推理的内在图像表示，类似于 Chain-of-Thought 提示，帮助 MLMs 更有效地进行视觉推理。作者提出 AURORA 训练方法，使用 VQVAE 将图像中间表示（如深度图）转化为令牌格式，并在多任务训练框架中整合这些令牌。实验结果显示，AURORA 在计数基准上取得显著提升，包括 BLINK 上 +10.8%、CVBench 上 +11.3% 以及 SEED-Bench 上 +8.3%，并在相对深度任务上改善超过 6%，从而扩展了 MLMs 的视觉推理能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03548v2",
      "published_date": "2024-12-04 18:45:35 UTC",
      "updated_date": "2024-12-08 05:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:36:42.864457"
    },
    {
      "arxiv_id": "2412.03539v2",
      "title": "NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model",
      "title_zh": "翻译失败",
      "authors": [
        "Xinheng Xie",
        "Yue Wu",
        "Cuiyu He"
      ],
      "abstract": "Understanding adversarial examples is crucial for improving model robustness,\nas they introduce imperceptible perturbations to deceive models. Effective\nadversarial examples, therefore, offer the potential to train more robust\nmodels by eliminating model singularities. We propose NODE-AdvGAN, a novel\napproach that treats adversarial generation as a continuous process and employs\na Neural Ordinary Differential Equation (NODE) to simulate generator dynamics.\nBy mimicking the iterative nature of traditional gradient-based methods,\nNODE-AdvGAN generates smoother and more precise perturbations that preserve\nhigh perceptual similarity when added to benign images. We also propose a new\ntraining strategy, NODE-AdvGAN-T, which enhances transferability in black-box\nattacks by tuning the noise parameters during training. Experiments demonstrate\nthat NODE-AdvGAN and NODE-AdvGAN-T generate more effective adversarial examples\nthat achieve higher attack success rates while preserving better perceptual\nquality than baseline models.",
      "tldr_zh": "本文提出 NODE-AdvGAN，一种基于 Neural Ordinary Differential Equation (NODE) 的动态系统驱动对抗生成模型，旨在通过模拟生成器的连续过程生成更平滑、精确的对抗样本，从而提升对抗样本的转移性和感知相似性。NODE-AdvGAN 模仿传统的梯度-based 方法，确保扰动在添加到原始图像时保持高感知质量，同时引入 NODE-AdvGAN-T 训练策略，通过调整噪声参数来提高黑盒攻击的转移性。实验结果表明，该方法生成的对抗样本比基线模型实现了更高的攻击成功率，同时保留了更好的感知质量，为提升模型鲁棒性提供了有效途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03539v2",
      "published_date": "2024-12-04 18:36:09 UTC",
      "updated_date": "2025-04-13 22:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:36:54.082957"
    },
    {
      "arxiv_id": "2412.03537v1",
      "title": "Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models",
      "title_zh": "评估预训练和提示适配语言模型之间的性别偏见转移",
      "authors": [
        "Natalie Mackraz",
        "Nivedha Sivakumar",
        "Samira Khorshidi",
        "Krishna Patel",
        "Barry-John Theobald",
        "Luca Zappella",
        "Nicholas Apostoloff"
      ],
      "abstract": "Large language models (LLMs) are increasingly being adapted to achieve\ntask-specificity for deployment in real-world decision systems. Several\nprevious works have investigated the bias transfer hypothesis (BTH) by studying\nthe effect of the fine-tuning adaptation strategy on model fairness to find\nthat fairness in pre-trained masked language models have limited effect on the\nfairness of models when adapted using fine-tuning. In this work, we expand the\nstudy of BTH to causal models under prompt adaptations, as prompting is an\naccessible, and compute-efficient way to deploy models in real-world systems.\nIn contrast to previous works, we establish that intrinsic biases in\npre-trained Mistral, Falcon and Llama models are strongly correlated (rho >=\n0.94) with biases when the same models are zero- and few-shot prompted, using a\npronoun co-reference resolution task. Further, we find that bias transfer\nremains strongly correlated even when LLMs are specifically prompted to exhibit\nfair or biased behavior (rho >= 0.92), and few-shot length and stereotypical\ncomposition are varied (rho >= 0.97). Our findings highlight the importance of\nensuring fairness in pre-trained LLMs, especially when they are later used to\nperform downstream tasks via prompt adaptation.",
      "tldr_zh": "本研究评估了预训练语言模型（LLMs）中的性别偏见在提示适应（prompt adaptations）过程中的转移情况，扩展了偏见转移假设（BTH）的相关研究。研究发现，预训练模型如 Mistral、Falcon 和 Llama 的内在偏见与零样本（zero-shot）和少样本（few-shot）提示后的偏见高度相关（rho >= 0.94），即使在提示模型显示公平或偏见行为时，这种相关性仍保持强劲（rho >= 0.92）。此外，改变少样本长度和刻板印象组成后，偏见转移的相关性依然显著（rho >= 0.97）。这些发现强调了确保预训练 LLMs 公平性的重要性，尤其在通过提示适应应用于下游任务时。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03537v1",
      "published_date": "2024-12-04 18:32:42 UTC",
      "updated_date": "2024-12-04 18:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:37:05.769059"
    },
    {
      "arxiv_id": "2412.03630v1",
      "title": "Evaluating Single Event Upsets in Deep Neural Networks for Semantic Segmentation: an embedded system perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Gutiérrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "As the deployment of artifical intelligence (AI) algorithms at edge devices\nbecomes increasingly prevalent, enhancing the robustness and reliability of\nautonomous AI-based perception and decision systems is becoming as relevant as\nprecision and performance, especially in applications areas considered\nsafety-critical such as autonomous driving and aerospace. This paper delves\ninto the robustness assessment in embedded Deep Neural Networks (DNNs),\nparticularly focusing on the impact of parameter perturbations produced by\nsingle event upsets (SEUs) on convolutional neural networks (CNN) for image\nsemantic segmentation. By scrutinizing the layer-by-layer and bit-by-bit\nsensitivity of various encoder-decoder models to soft errors, this study\nthoroughly investigates the vulnerability of segmentation DNNs to SEUs and\nevaluates the consequences of techniques like model pruning and parameter\nquantization on the robustness of compressed models aimed at embedded\nimplementations. The findings offer valuable insights into the mechanisms\nunderlying SEU-induced failures that allow for evaluating the robustness of\nDNNs once trained in advance. Moreover, based on the collected data, we propose\na set of practical lightweight error mitigation techniques with no memory or\ncomputational cost suitable for resource-constrained deployments. The code used\nto perform the fault injection (FI) campaign is available at\nhttps://github.com/jonGuti13/TensorFI2 , while the code to implement proposed\ntechniques is available at https://github.com/jonGuti13/parameterProtection .",
      "tldr_zh": "这篇论文评估了深度神经网络(DNNs)用于图像语义分割时，对单事件翻转(SEUs)引发的参数扰动的鲁棒性，重点从嵌入式系统角度探讨安全关键应用如自动驾驶和航空航天中的可靠性。研究通过层级和位级分析，检查了各种编码器-解码器模型的敏感性，并评估了模型修剪和参数量化等技术对压缩模型鲁棒性的影响。最终，论文揭示了SEU导致故障的潜在机制，并提出了一套轻量级错误缓解技术，这些方法无需额外内存或计算资源，适用于资源受限的部署，并提供了开源代码支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03630v1",
      "published_date": "2024-12-04 18:28:38 UTC",
      "updated_date": "2024-12-04 18:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:37:17.769951"
    },
    {
      "arxiv_id": "2412.03526v2",
      "title": "Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Hanxue Liang",
        "Jiawei Ren",
        "Ashkan Mirzaei",
        "Antonio Torralba",
        "Ziwei Liu",
        "Igor Gilitschenski",
        "Sanja Fidler",
        "Cengiz Oztireli",
        "Huan Ling",
        "Zan Gojcic",
        "Jiahui Huang"
      ],
      "abstract": "Recent advancements in static feed-forward scene reconstruction have\ndemonstrated significant progress in high-quality novel view synthesis.\nHowever, these models often struggle with generalizability across diverse\nenvironments and fail to effectively handle dynamic content. We present BTimer\n(short for BulletTimer), the first motion-aware feed-forward model for\nreal-time reconstruction and novel view synthesis of dynamic scenes. Our\napproach reconstructs the full scene in a 3D Gaussian Splatting representation\nat a given target ('bullet') timestamp by aggregating information from all the\ncontext frames. Such a formulation allows BTimer to gain scalability and\ngeneralization by leveraging both static and dynamic scene datasets. Given a\ncasual monocular dynamic video, BTimer reconstructs a bullet-time scene within\n150ms while reaching state-of-the-art performance on both static and dynamic\nscene datasets, even compared with optimization-based approaches.",
      "tldr_zh": "本论文提出了一种名为 BTimer 的 motion-aware feed-forward 模型，用于从单目视频实时重建动态场景并实现高品质 novel view synthesis。模型通过 3D Gaussian Splatting 表示，在目标时间戳（bullet timestamp）聚合所有上下文帧的信息，实现场景的重建。相比传统方法，BTimer 展示了出色的可扩展性和泛化能力，能够处理静态和动态数据集，并在重建速度上仅需 150ms，同时达到 state-of-the-art 性能，甚至优于基于优化的方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website:\n  https://research.nvidia.com/labs/toronto-ai/bullet-timer/",
      "pdf_url": "http://arxiv.org/pdf/2412.03526v2",
      "published_date": "2024-12-04 18:15:06 UTC",
      "updated_date": "2025-04-01 06:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:37:28.874190"
    },
    {
      "arxiv_id": "2412.03516v1",
      "title": "You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?",
      "title_zh": "你（不是）我的类型——大型语言模型能否为入门级编程任务生成特定类型的反馈？",
      "authors": [
        "Dominic Lohr",
        "Hieke Keuning",
        "Natalie Kiesler"
      ],
      "abstract": "Background: Feedback as one of the most influential factors for learning has\nbeen subject to a great body of research. It plays a key role in the\ndevelopment of educational technology systems and is traditionally rooted in\ndeterministic feedback defined by experts and their experience. However, with\nthe rise of generative AI and especially Large Language Models (LLMs), we\nexpect feedback as part of learning systems to transform, especially for the\ncontext of programming. In the past, it was challenging to automate feedback\nfor learners of programming. LLMs may create new possibilities to provide\nricher, and more individual feedback than ever before.\n  Objectives: This paper aims to generate specific types of feedback for\nintroductory programming tasks using LLMs. We revisit existing feedback\ntaxonomies to capture the specifics of the generated feedback, such as\nrandomness, uncertainty, and degrees of variation.\n  Methods: We iteratively designed prompts for the generation of specific\nfeedback types (as part of existing feedback taxonomies) in response to\nauthentic student programs. We then evaluated the generated output and\ndetermined to what extent it reflected certain feedback types.\n  Results and Conclusion: The present work provides a better understanding of\ndifferent feedback dimensions and characteristics. The results have\nimplications for future feedback research with regard to, for example, feedback\neffects and learners' informational needs. It further provides a basis for the\ndevelopment of new tools and learning systems for novice programmers including\nfeedback generated by AI.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否能为入门级编程任务生成特定类型的反馈，旨在分析反馈的特性如随机性、不确定性和变化度，并基于现有feedback taxonomies进行重新审视。研究者通过迭代设计提示，针对真实学生程序生成反馈类型，并评估其输出是否符合预设特性。结果显示，此方法提升了对反馈维度的理解，并为未来反馈研究、AI生成反馈工具的开发以及支持新手程序员的学习系统提供重要基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at Journal of Computer Assisted Learning (2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.03516v1",
      "published_date": "2024-12-04 17:57:39 UTC",
      "updated_date": "2024-12-04 17:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:37:40.606784"
    },
    {
      "arxiv_id": "2412.03513v2",
      "title": "Enhancing CLIP Conceptual Embedding through Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Kuei-Chun Kao"
      ],
      "abstract": "Recently, CLIP has become an important model for aligning images and text in\nmulti-modal contexts. However, researchers have identified limitations in the\nability of CLIP's text and image encoders to extract detailed knowledge from\npairs of captions and images. In response, this paper presents Knowledge-CLIP,\nan innovative approach designed to improve CLIP's performance by integrating a\nnew knowledge distillation (KD) method based on Llama 2. Our approach focuses\non three key objectives: Text Embedding Distillation, Concept Learning, and\nContrastive Learning. First, Text Embedding Distillation involves training the\nKnowledge-CLIP text encoder to mirror the teacher model, Llama 2. Next, Concept\nLearning assigns a soft concept label to each caption-image pair by employing\noffline K-means clustering on text data from Llama 2, enabling Knowledge-CLIP\nto learn from these soft concept labels. Lastly, Contrastive Learning aligns\nthe text and image embeddings. Our experimental findings show that the proposed\nmodel improves the performance of both text and image encoders.",
      "tldr_zh": "本文提出 Knowledge-CLIP，一种通过知识蒸馏（KD）方法提升 CLIP 概念嵌入性能的创新框架，使用 Llama 2 作为教师模型。方法包括 Text Embedding Distillation（训练文本编码器模仿教师模型）、Concept Learning（通过 K-means 聚类在 Llama 2 的文本数据上生成软概念标签以辅助学习）和 Contrastive Learning（对齐文本和图像嵌入）。实验结果表明，该模型显著提高了 CLIP 的文本和图像编码器性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03513v2",
      "published_date": "2024-12-04 17:56:49 UTC",
      "updated_date": "2024-12-07 13:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:37:53.008836"
    },
    {
      "arxiv_id": "2412.03498v2",
      "title": "A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Proma Hossain Progga",
        "Md. Jobayer Rahman",
        "Swapnil Biswas",
        "Md. Shakil Ahmed",
        "Arif Reza Anwary",
        "Swakkhar Shatabda"
      ],
      "abstract": "Gait recognition is a significant biometric technique for person\nidentification, particularly in scenarios where other physiological biometrics\nare impractical or ineffective. In this paper, we address the challenges\nassociated with gait recognition and present a novel approach to improve its\naccuracy and reliability. The proposed method leverages advanced techniques,\nincluding sequential gait landmarks obtained through the Mediapipe pose\nestimation model, Procrustes analysis for alignment, and a Siamese\nbiGRU-dualStack Neural Network architecture for capturing temporal\ndependencies. Extensive experiments were conducted on large-scale cross-view\ndatasets to demonstrate the effectiveness of the approach, achieving high\nrecognition accuracy compared to other models. The model demonstrated\naccuracies of 95.7%, 94.44%, 87.71%, and 86.6% on CASIA-B, SZU RGB-D, OU-MVLP,\nand Gait3D datasets respectively. The results highlight the potential\napplications of the proposed method in various practical domains, indicating\nits significant contribution to the field of gait recognition.",
      "tldr_zh": "本论文针对步态识别的准确性和可靠性挑战，提出了一种新型方法，利用Mediapipe姿势估计模型获取顺序步态地标，并结合Procrustes分析进行对齐。\n该方法采用Siamese biGRU-dualStack神经网络架构来捕获时间依赖性，从而提升识别性能。\n在跨视图数据集上的实验显示，该模型在CASIA-B、SZU RGB-D、OU-MVLP和Gait3D数据集上分别达到了95.7%、94.44%、87.71%和86.6%的准确率。\n这项研究为步态识别领域提供了高效的生物识别解决方案，具有广泛的实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03498v2",
      "published_date": "2024-12-04 17:39:55 UTC",
      "updated_date": "2024-12-05 03:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:38:05.762886"
    },
    {
      "arxiv_id": "2412.03487v1",
      "title": "Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Neta Shaul",
        "Itai Gat",
        "Marton Havasi",
        "Daniel Severo",
        "Anuroop Sriram",
        "Peter Holderrieth",
        "Brian Karrer",
        "Yaron Lipman",
        "Ricky T. Q. Chen"
      ],
      "abstract": "The design space of discrete-space diffusion or flow generative models are\nsignificantly less well-understood than their continuous-space counterparts,\nwith many works focusing only on a simple masked construction. In this work, we\naim to take a holistic approach to the construction of discrete generative\nmodels based on continuous-time Markov chains, and for the first time, allow\nthe use of arbitrary discrete probability paths, or colloquially, corruption\nprocesses. Through the lens of optimizing the symmetric kinetic energy, we\npropose velocity formulas that can be applied to any given probability path,\ncompletely decoupling the probability and velocity, and giving the user the\nfreedom to specify any desirable probability path based on expert knowledge\nspecific to the data domain. Furthermore, we find that a special construction\nof mixture probability paths optimizes the symmetric kinetic energy for the\ndiscrete case. We empirically validate the usefulness of this new design space\nacross multiple modalities: text generation, inorganic material generation, and\nimage generation. We find that we can outperform the mask construction even in\ntext with kinetic-optimal mixture paths, while we can make use of\ndomain-specific constructions of the probability path over the visual domain.",
      "tldr_zh": "本文从kinetic-optimal视角探讨离散空间生成模型的设计，提出了一种基于连续时间Markov chains的框架，允许使用任意离散概率路径（corruption processes），并通过优化symmetric kinetic energy来定义velocity公式，从而将概率路径与velocity完全解耦。研究发现，特殊的mixture probability paths构造能进一步优化离散情况下的性能，并在文本生成、无机材料生成和图像生成等多模态任务上验证其有效性。结果显示，该方法在文本生成中优于传统的masked构造，并在视觉领域利用domain-specific概率路径取得了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03487v1",
      "published_date": "2024-12-04 17:24:35 UTC",
      "updated_date": "2024-12-04 17:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:38:17.921542"
    },
    {
      "arxiv_id": "2412.16166v1",
      "title": "Unveiling the Role of Artificial Intelligence and Stock Market Growth in Achieving Carbon Neutrality in the United States: An ARDL Model Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Azizul Hakim Rafi",
        "Abdullah Al Abrar Chowdhury",
        "Adita Sultana",
        "Abdulla All Noman"
      ],
      "abstract": "Given the fact that climate change has become one of the most pressing\nproblems in many countries in recent years, specialized research on how to\nmitigate climate change has been adopted by many countries. Within this\ndiscussion, the influence of advanced technologies in achieving carbon\nneutrality has been discussed. While several studies investigated how AI and\nDigital innovations could be used to reduce the environmental footprint, the\nactual influence of AI in reducing CO2 emissions (a proxy measuring carbon\nfootprint) has yet to be investigated. This paper studies the role of advanced\ntechnologies in general, and Artificial Intelligence (AI) and ICT use in\nparticular, in advancing carbon neutrality in the United States, between 2021.\nSecondly, this paper examines how Stock Market Growth, ICT use, Gross Domestic\nProduct (GDP), and Population affect CO2 emissions using the STIRPAT model.\nAfter examining stationarity among the variables using a variety of unit root\ntests, this study concluded that there are no unit root problems across all the\nvariables, with a mixed order of integration. The ARDL bounds test for\ncointegration revealed that variables in this study have a long-run\nrelationship. Moreover, the estimates revealed from the ARDL model in the\nshort- and long-run indicated that economic growth, stock market\ncapitalization, and population significantly contributed to the carbon\nemissions in both the short-run and long-run. Conversely, AI and ICT use\nsignificantly reduced carbon emissions over both periods. Furthermore, findings\nwere confirmed to be robust using FMOLS, DOLS, and CCR estimations.\nFurthermore, diagnostic tests indicated the absence of serial correlation,\nheteroscedasticity, and specification errors and, thus, the model was robust.",
      "tldr_zh": "本研究探讨了人工智能(AI)和股票市场增长在实现美国碳中和中的作用，特别考察AI和ICT使用如何减少CO2排放。研究采用STIRPAT模型和ARDL模型分析经济成长(GDP)、股票市场增长、ICT使用和人口对CO2排放的影响，并通过单位根测试确认变量间无单位根问题及长期共整合关系。结果显示，经济成长、股票市场资本化和人口在短期和长期显著增加碳排放，而AI和ICT使用则显著降低排放；这些发现经FMOLS、DOLS和CCR估计得到验证，并通过诊断测试证明模型稳健。整体而言，该研究为利用先进技术推动碳中和提供了实证依据。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "26 pages, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.16166v1",
      "published_date": "2024-12-04 17:07:04 UTC",
      "updated_date": "2024-12-04 17:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:38:29.644897"
    },
    {
      "arxiv_id": "2412.03467v1",
      "title": "Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Neale Ratzlaff",
        "Man Luo",
        "Xin Su",
        "Vasudev Lal",
        "Phillip Howard"
      ],
      "abstract": "Multimodal models typically combine a powerful large language model (LLM)\nwith a vision encoder and are then trained on multimodal data via instruction\ntuning. While this process adapts LLMs to multimodal settings, it remains\nunclear whether this adaptation compromises their original language reasoning\ncapabilities. In this work, we explore the effects of multimodal instruction\ntuning on language reasoning performance. We focus on LLaVA, a leading\nmultimodal framework that integrates LLMs such as Vicuna or Mistral with the\nCLIP vision encoder. We compare the performance of the original LLMs with their\nmultimodal-adapted counterparts across eight language reasoning tasks. Our\nexperiments yield several key insights. First, the impact of multimodal\nlearning varies between Vicuna and Mistral: we observe a degradation in\nlanguage reasoning for Mistral but improvements for Vicuna across most tasks.\nSecond, while multimodal instruction learning consistently degrades performance\non mathematical reasoning tasks (e.g., GSM8K), it enhances performance on\ncommonsense reasoning tasks (e.g., CommonsenseQA). Finally, we demonstrate that\na training-free model merging technique can effectively mitigate the language\nreasoning degradation observed in multimodal-adapted Mistral and even improve\nperformance on visual tasks.",
      "tldr_zh": "这篇论文探讨了多模态指令微调对大型语言模型(LLM)语言推理能力的潜在负面影响，使用 LLaVA 框架将 Vicuna 或 Mistral 与 CLIP 视觉编码器结合，并比较其在八个语言推理任务上的表现。研究发现，Mistral 在多模态学习后语言推理能力普遍下降，而 Vicuna 则在大多数任务中有所提升；具体而言，多模态微调会降低数学推理任务（如 GSM8K）的性能，但提升常识推理任务（如 CommonsenseQA）。作者提出了一种无需额外训练的模型合并技术，能够有效缓解 Mistral 的推理退化问题，甚至进一步改善视觉任务的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03467v1",
      "published_date": "2024-12-04 16:56:20 UTC",
      "updated_date": "2024-12-04 16:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:38:42.049207"
    },
    {
      "arxiv_id": "2412.03465v1",
      "title": "YT-30M: A multi-lingual multi-category dataset of YouTube comments",
      "title_zh": "翻译失败",
      "authors": [
        "Hridoy Sankar Dutta"
      ],
      "abstract": "This paper introduces two large-scale multilingual comment datasets, YT-30M\n(and YT-100K) from YouTube. The analysis in this paper is performed on a\nsmaller sample (YT-100K) of YT-30M. Both the datasets: YT-30M (full) and\nYT-100K (randomly selected 100K sample from YT-30M) are publicly released for\nfurther research. YT-30M (YT-100K) contains 32236173 (108694) comments posted\nby YouTube channel that belong to YouTube categories. Each comment is\nassociated with a video ID, comment ID, commentor name, commentor channel ID,\ncomment text, upvotes, original channel ID and category of the YouTube channel\n(e.g., 'News & Politics', 'Science & Technology', etc.).",
      "tldr_zh": "本论文引入了两个大规模的多语言多类别数据集，YT-30M 和 YT-100K，基于 YouTube 评论数据构建。YT-30M 包含约 3.22 千万条评论，而 YT-100K 是其随机抽样的 10.8 万条子集，每条评论关联了视频 ID、评论 ID、评论者信息、评论文本、点赞数、原始频道 ID 和频道类别（如 'News & Politics' 或 'Science & Technology'）。这些数据集已公开发布，旨在支持进一步的自然语言处理和社交媒体分析研究。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03465v1",
      "published_date": "2024-12-04 16:54:58 UTC",
      "updated_date": "2024-12-04 16:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:38:52.868645"
    },
    {
      "arxiv_id": "2412.03446v1",
      "title": "From Words to Workflows: Automating Business Processes",
      "title_zh": "从文字到工作流：自动化业务流程",
      "authors": [
        "Laura Minkova",
        "Jessica López Espejel",
        "Taki Eddine Toufik Djaidja",
        "Walid Dahhane",
        "El Hassane Ettifouri"
      ],
      "abstract": "As businesses increasingly rely on automation to streamline operations, the\nlimitations of Robotic Process Automation (RPA) have become apparent,\nparticularly its dependence on expert knowledge and inability to handle complex\ndecision-making tasks. Recent advancements in Artificial Intelligence (AI),\nparticularly Generative AI (GenAI) and Large Language Models (LLMs), have paved\nthe way for Intelligent Automation (IA), which integrates cognitive\ncapabilities to overcome the shortcomings of RPA. This paper introduces\nText2Workflow, a novel method that automatically generates workflows from\nnatural language user requests. Unlike traditional automation approaches,\nText2Workflow offers a generalized solution for automating any business\nprocess, translating user inputs into a sequence of executable steps\nrepresented in JavaScript Object Notation (JSON) format. Leveraging the\ndecision-making and instruction-following capabilities of LLMs, this method\nprovides a scalable, adaptable framework that enables users to visualize and\nexecute workflows with minimal manual intervention. This research outlines the\nText2Workflow methodology and its broader implications for automating complex\nbusiness processes.",
      "tldr_zh": "这篇论文探讨了 Robotic Process Automation (RPA) 的局限性，包括对专家知识的依赖和处理复杂决策任务的不足，并介绍了 Artificial Intelligence (AI) 尤其是 Generative AI (GenAI) 和 Large Language Models (LLMs) 如何推动 Intelligent Automation (IA) 的发展。论文提出了一种新方法 Text2Workflow，能从自然语言用户请求自动生成业务工作流，将输入转化为 JSON 格式的执行步骤序列。利用 LLMs 的决策和指令遵循能力，该框架提供了一个可扩展、可适应的解决方案，显著减少手动干预。总体而言，Text2Workflow 为自动化复杂业务流程提供了通用框架，并讨论了其更广泛的应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review at Elsevier's Engineering Applications of Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2412.03446v1",
      "published_date": "2024-12-04 16:34:35 UTC",
      "updated_date": "2024-12-04 16:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:39:05.566994"
    },
    {
      "arxiv_id": "2412.04106v2",
      "title": "MRGen: Segmentation Data Engine For Underrepresented MRI Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Haoning Wu",
        "Ziheng Zhao",
        "Ya Zhang",
        "Yanfeng Wang",
        "Weidi Xie"
      ],
      "abstract": "Training medical image segmentation models for rare yet clinically\nsignificant imaging modalities is challenging due to the scarcity of annotated\ndata, and manual mask annotations can be costly and labor-intensive to acquire.\nThis paper investigates leveraging generative models to synthesize training\ndata, to train segmentation models for underrepresented modalities,\nparticularly on annotation-scarce MRI. Concretely, our contributions are\nthreefold: (i) we introduce MRGen-DB, a large-scale radiology image-text\ndataset comprising extensive samples with rich metadata, including modality\nlabels, attributes, regions, and organs information, with a subset having\npixelwise mask annotations; (ii) we present MRGen, a diffusion-based data\nengine for controllable medical image synthesis, conditioned on text prompts\nand segmentation masks. MRGen can generate realistic images for diverse MRI\nmodalities lacking mask annotations, facilitating segmentation training in\nlow-source domains; (iii) extensive experiments across multiple modalities\ndemonstrate that MRGen significantly improves segmentation performance on\nunannotated modalities by providing high-quality synthetic data. We believe\nthat our method bridges a critical gap in medical image analysis, extending\nsegmentation capabilities to scenarios that are challenging to acquire manual\nannotations.",
      "tldr_zh": "该研究针对医疗图像分割模型在稀有 MRI 模式中的训练挑战，提出 MRGen 框架，利用生成模型合成训练数据以缓解标注数据稀缺问题。主要贡献包括：(i) 引入 MRGen-DB，一个大规模放射学图像-文本数据集，包含丰富的元数据（如 modality labels、attributes 和器官信息），部分带有 pixelwise mask annotations；(ii) 开发 MRGen，一种 diffusion-based 数据引擎，通过文本提示和 segmentation masks 进行可控图像合成，生成真实 MRI 图像以支持低资源领域训练；(iii) 实验结果显示，MRGen 通过高质量合成数据显著提升了未标注模式的 segmentation 性能，从而扩展了医疗图像分析在标注困难场景中的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report; Project Page:\n  https://haoningwu3639.github.io/MRGen/",
      "pdf_url": "http://arxiv.org/pdf/2412.04106v2",
      "published_date": "2024-12-04 16:34:22 UTC",
      "updated_date": "2025-03-12 11:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:39:16.727999"
    },
    {
      "arxiv_id": "2412.03441v3",
      "title": "PBP: Post-training Backdoor Purification for Malware Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Dung Thuy Nguyen",
        "Ngoc N. Tran",
        "Taylor T. Johnson",
        "Kevin Leach"
      ],
      "abstract": "In recent years, the rise of machine learning (ML) in cybersecurity has\nbrought new challenges, including the increasing threat of backdoor poisoning\nattacks on ML malware classifiers. For instance, adversaries could inject\nmalicious samples into public malware repositories, contaminating the training\ndata and potentially misclassifying malware by the ML model. Current\ncountermeasures predominantly focus on detecting poisoned samples by leveraging\ndisagreements within the outputs of a diverse set of ensemble models on\ntraining data points. However, these methods are not suitable for scenarios\nwhere Machine Learning-as-a-Service (MLaaS) is used or when users aim to remove\nbackdoors from a model after it has been trained. Addressing this scenario, we\nintroduce PBP, a post-training defense for malware classifiers that mitigates\nvarious types of backdoor embeddings without assuming any specific backdoor\nembedding mechanism. Our method exploits the influence of backdoor attacks on\nthe activation distribution of neural networks, independent of the\ntrigger-embedding method. In the presence of a backdoor attack, the activation\ndistribution of each layer is distorted into a mixture of distributions. By\nregulating the statistics of the batch normalization layers, we can guide a\nbackdoored model to perform similarly to a clean one. Our method demonstrates\nsubstantial advantages over several state-of-the-art methods, as evidenced by\nexperiments on two datasets, two types of backdoor methods, and various attack\nconfigurations. Notably, our approach requires only a small portion of the\ntraining data -- only 1\\% -- to purify the backdoor and reduce the attack\nsuccess rate from 100\\% to almost 0\\%, a 100-fold improvement over the baseline\nmethods. Our code is available at\n\\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}.",
      "tldr_zh": "该论文提出了PBP，一种针对恶意软件分类器的后训练背门净化（Post-training Backdoor Purification）方法，用于缓解背门攻击，而无需假设特定背门嵌入机制。PBP通过利用背门攻击对神经网络激活分布的影响，调节批标准化（batch normalization）层的统计，使受攻击模型的表现类似于干净模型。实验结果显示，在两个数据集和多种攻击配置下，该方法仅需1%的训练数据，即可将攻击成功率从100%降至几乎0%，比现有基线方法改善100倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NDSS 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03441v3",
      "published_date": "2024-12-04 16:30:03 UTC",
      "updated_date": "2024-12-10 20:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:39:29.093065"
    },
    {
      "arxiv_id": "2412.14179v1",
      "title": "Benchmarking Harmonized Tariff Schedule Classification Models",
      "title_zh": "协调关税表分类模型的基准测试",
      "authors": [
        "Bryce Judy"
      ],
      "abstract": "The Harmonized Tariff System (HTS) classification industry, essential to\ne-commerce and international trade, currently lacks standardized benchmarks for\nevaluating the effectiveness of classification solutions. This study\nestablishes and tests a benchmark framework for imports to the United States,\ninspired by the benchmarking approaches used in language model evaluation, to\nsystematically compare prominent HTS classification tools. The framework\nassesses key metrics--such as speed, accuracy, rationality, and HTS code\nalignment--to provide a comprehensive performance comparison. The study\nevaluates several industry-leading solutions, including those provided by\nZonos, Tarifflo, Avalara, and WCO BACUDA, identifying each tool's strengths and\nlimitations. Results highlight areas for industry-wide improvement and\ninnovation, paving the way for more effective and standardized HTS\nclassification solutions across the international trade and e-commerce sectors.",
      "tldr_zh": "这篇论文针对 Harmonized Tariff System (HTS) 分类行业缺乏标准化基准的问题，建立了针对美国进口的基准框架，借鉴语言模型评估方法来系统比较分类工具的性能。该框架评估了关键指标，包括速度、准确性、合理性和 HTS 代码对齐，并测试了 Zonos、Tarifflo、Avalara 和 WCO BACUDA 等领先解决方案，揭示了各工具的优缺点。研究结果强调了行业改进的潜在领域，推动更有效的标准化 HTS 分类工具在国际贸易和电商领域的应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14179v1",
      "published_date": "2024-12-04 16:29:05 UTC",
      "updated_date": "2024-12-04 16:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:39:41.068064"
    },
    {
      "arxiv_id": "2412.03434v1",
      "title": "BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement",
      "title_zh": "BIMCaP：基于 BIM 的 AI 支持 LiDAR-相机位姿精炼",
      "authors": [
        "Miguel Arturo Vega Torres",
        "Anna Ribic",
        "Borja García de Soto",
        "André Borrmann"
      ],
      "abstract": "This paper introduces BIMCaP, a novel method to integrate mobile 3D sparse\nLiDAR data and camera measurements with pre-existing building information\nmodels (BIMs), enhancing fast and accurate indoor mapping with affordable\nsensors. BIMCaP refines sensor poses by leveraging a 3D BIM and employing a\nbundle adjustment technique to align real-world measurements with the model.\nExperiments using real-world open-access data show that BIMCaP achieves\nsuperior accuracy, reducing translational error by over 4 cm compared to\ncurrent state-of-the-art methods. This advancement enhances the accuracy and\ncost-effectiveness of 3D mapping methodologies like SLAM. BIMCaP's improvements\nbenefit various fields, including construction site management and emergency\nresponse, by providing up-to-date, aligned digital maps for better\ndecision-making and productivity. Link to the repository:\nhttps://github.com/MigVega/BIMCaP",
      "tldr_zh": "这篇论文提出了 BIMCaP，一种基于 BIM 的 AI 支持方法，用于整合移动 3D 稀疏 LiDAR 数据和相机测量，以实现快速准确的室内映射。BIMCaP 通过利用 3D BIM 和 bundle adjustment 技术精炼传感器姿态，确保真实世界测量与模型对齐。实验结果显示，该方法在真实世界数据上比现有最先进方法减少了超过 4 cm 的平移误差，提升了 SLAM 等 3D 映射技术的准确性和成本效益。这种改进可应用于建筑工地管理和应急响应等领域，提供更精确的数字地图以优化决策和生产力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 24 figures, Conference: EG-ICE: 31st International Workshop\n  on Intelligent Computing in Engineering",
      "pdf_url": "http://arxiv.org/pdf/2412.03434v1",
      "published_date": "2024-12-04 16:26:17 UTC",
      "updated_date": "2024-12-04 16:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:39:53.234246"
    },
    {
      "arxiv_id": "2412.03433v1",
      "title": "Genetic Algorithm Based System for Path Planning with Unmanned Aerial Vehicles Swarms in Cell-Grid Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Puente-Castro",
        "Enrique Fernandez-Blanco",
        "Daniel Rivero"
      ],
      "abstract": "Path Planning methods for autonomously controlling swarms of unmanned aerial\nvehicles (UAVs) are gaining momentum due to their operational advantages. An\nincreasing number of scenarios now require autonomous control of multiple UAVs,\nas autonomous operation can significantly reduce labor costs. Additionally,\nobtaining optimal flight paths can lower energy consumption, thereby extending\nbattery life for other critical operations. Many of these scenarios, however,\ninvolve obstacles such as power lines and trees, which complicate Path\nPlanning. This paper presents an evolutionary computation-based system\nemploying genetic algorithms to address this problem in environments with\nobstacles. The proposed approach aims to ensure complete coverage of areas with\nfixed obstacles, such as in field exploration tasks, while minimizing flight\ntime regardless of map size or the number of UAVs in the swarm. No specific\ngoal points or prior information beyond the provided map is required. The\nexperiments conducted in this study used five maps of varying sizes and\nobstacle densities, as well as a control map without obstacles, with different\nnumbers of UAVs. The results demonstrate that this method can determine optimal\npaths for all UAVs during full map traversal, thus minimizing resource\nconsumption. A comparative analysis with other state-of-the-art approach is\npresented to highlight the advantages and potential limitations of the proposed\nmethod.",
      "tldr_zh": "该论文提出了一种基于 Genetic Algorithm 的路径规划系统，用于在有障碍物的 Cell-Grid 环境中控制 Unmanned Aerial Vehicles Swarms (UAV Swarms)，以实现完全区域覆盖并最小化飞行时间，而无需特定目标点或额外信息。系统利用进化计算方法处理障碍物挑战，如电线和树木，提高了自主操作的效率和能源利用。实验在五张不同大小和障碍密度的地图上进行，结果显示该方法能为所有UAV确定最佳路径，资源消耗最小，并通过与现有最先进方法的比较突出了其优势和潜在局限性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03433v1",
      "published_date": "2024-12-04 16:24:41 UTC",
      "updated_date": "2024-12-04 16:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:40:05.606559"
    },
    {
      "arxiv_id": "2412.03424v1",
      "title": "Tango*: Constrained synthesis planning using chemically informed value functions",
      "title_zh": "Tango*：利用化学",
      "authors": [
        "Daniel Armstrong",
        "Zlatko Joncev",
        "Jeff Guo",
        "Philippe Schwaller"
      ],
      "abstract": "Computer-aided synthesis planning (CASP) has made significant strides in\ngenerating retrosynthetic pathways for simple molecules in a non-constrained\nfashion. Recent work introduces a specialised bidirectional search algorithm\nwith forward and retro expansion to address the starting material-constrained\nsynthesis problem, allowing CASP systems to provide synthesis pathways from\nspecified starting materials, such as waste products or renewable feed-stocks.\nIn this work, we introduce a simple guided search which allows solving the\nstarting material-constrained synthesis planning problem using an existing,\nuni-directional search algorithm, Retro*. We show that by optimising a single\nhyperparameter, Tango* outperforms existing methods in terms of efficiency and\nsolve rate. We find the Tango* cost function catalyses strong improvements for\nthe bidirectional DESP methods. Our method also achieves lower wall clock times\nwhile proposing synthetic routes of similar length, a common metric for route\nquality. Finally, we highlight potential reasons for the strong performance of\nTango over neural guided search methods",
      "tldr_zh": "本研究提出Tango*，一种基于化学信息价值函数的引导搜索方法，用于解决计算机辅助合成规划(CASP)中的起始材料约束问题。该方法构建于现有的单向搜索算法Retro*之上，通过优化一个超参数，显著提高了合成路径的效率和成功率。实验结果显示，Tango*在保持合成路线长度类似的同时，实现了更低的实际运行时间，并对双向DESP方法产生催化作用，最终优于神经引导搜索方法。总的来说，这为约束式合成规划提供了更高效的解决方案。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03424v1",
      "published_date": "2024-12-04 16:14:02 UTC",
      "updated_date": "2024-12-04 16:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:40:16.462193"
    },
    {
      "arxiv_id": "2412.03420v2",
      "title": "Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic",
      "title_zh": "使用模型推理搜索启发式的 REST APIs 测试用例自动生成",
      "authors": [
        "Clinton Cao",
        "Annibale Panichella",
        "Sicco Verwer"
      ],
      "abstract": "The rising popularity of the microservice architectural style has led to a\ngrowing demand for automated testing approaches tailored to these systems.\nEvoMaster is a state-of-the-art tool that uses Evolutionary Algorithms (EAs) to\nautomatically generate test cases for microservices' REST APIs. One limitation\nof these EAs is the use of unit-level search heuristics, such as branch\ndistances, which focus on fine-grained code coverage and may not effectively\ncapture the complex, interconnected behaviors characteristic of system-level\ntesting. To address this limitation, we propose a new search heuristic (MISH)\nthat uses real-time automaton learning to guide the test case generation\nprocess. We capture the sequential call patterns exhibited by a test case by\nlearning an automaton from the stream of log events outputted by different\nmicroservices within the same system. Therefore, MISH learns a representation\nof the systemwide behavior, allowing us to define the fitness of a test case\nbased on the path it traverses within the inferred automaton. We empirically\nevaluate MISH's effectiveness on six real-world benchmark microservice\napplications and compare it against a state-of-the-art technique, MOSA, for\ntesting REST APIs. Our evaluation shows promising results for using MISH to\nguide the automated test case generation within EvoMaster.",
      "tldr_zh": "微服务架构的流行增加了对自动化测试的需求，而现有工具如 EvoMaster 使用进化算法(EAs)的单位级搜索启发式（如分支距离）无法有效捕捉系统级测试的复杂行为。为解决此问题，本文提出 MISH（Model Inference Search Heuristic），一种基于实时自动机学习的技术，从微服务日志事件中学习自动机以表示系统整体行为，并据此定义测试用例的适应度。实验在六个真实世界基准微服务应用上评估 MISH，与状态-of-the-art 技术 MOSA 相比，结果显示 MISH 显著提升了 REST APIs 测试用例生成的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.03420v2",
      "published_date": "2024-12-04 16:00:14 UTC",
      "updated_date": "2025-01-30 12:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:40:29.698796"
    },
    {
      "arxiv_id": "2412.03417v2",
      "title": "Learning Semantic Association Rules from Internet of Things Data",
      "title_zh": "从物联网数据中学习语义关联规则",
      "authors": [
        "Erkan Karabulut",
        "Paul Groth",
        "Victoria Degeler"
      ],
      "abstract": "Association Rule Mining (ARM) is the task of discovering commonalities in\ndata in the form of logical implications. ARM is used in the Internet of Things\n(IoT) for different tasks including monitoring and decision-making. However,\nexisting methods give limited consideration to IoT-specific requirements such\nas heterogeneity and volume. Furthermore, they do not utilize important static\ndomain-specific description data about IoT systems, which is increasingly\nrepresented as knowledge graphs. In this paper, we propose a novel ARM pipeline\nfor IoT data that utilizes both dynamic sensor data and static IoT system\nmetadata. Furthermore, we propose an Autoencoder-based Neurosymbolic ARM method\n(Aerial) as part of the pipeline to address the high volume of IoT data and\nreduce the total number of rules that are resource-intensive to process. Aerial\nlearns a neural representation of a given data and extracts association rules\nfrom this representation by exploiting the reconstruction (decoding) mechanism\nof an autoencoder. Extensive evaluations on 3 IoT datasets from 2 domains show\nthat ARM on both static and dynamic IoT data results in more generically\napplicable rules while Aerial can learn a more concise set of high-quality\nassociation rules than the state-of-the-art with full coverage over the\ndatasets.",
      "tldr_zh": "这篇论文提出了一种新的 Association Rule Mining (ARM) 管道，用于从 Internet of Things (IoT) 数据中学习语义关联规则，该管道整合了动态传感器数据和静态 IoT 系统元数据，以解决现有方法对 IoT 异构性和数据量的局限性。核心方法是基于 Autoencoder 的 Neurosymbolic ARM 技术（Aerial），它通过学习数据的神经表示并利用自编码器的重建机制来提取规则，从而减少规则数量并提高处理效率。在 3 个 IoT 数据集上的实验显示，这种方法生成更通用的规则，且 Aerial 比现有技术提供更简洁、高质量的规则，同时实现完整数据集覆盖。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03417v2",
      "published_date": "2024-12-04 15:53:45 UTC",
      "updated_date": "2024-12-05 13:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:40:40.928934"
    },
    {
      "arxiv_id": "2412.03624v1",
      "title": "How to Correctly do Semantic Backpropagation on Language-based Agentic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyi Wang",
        "Hisham A. Alyahya",
        "Dylan R. Ashley",
        "Oleg Serikov",
        "Dmitrii Khizbullin",
        "Francesco Faccio",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Language-based agentic systems have shown great promise in recent years,\ntransitioning from solving small-scale research problems to being deployed in\nchallenging real-world tasks. However, optimizing these systems often requires\nsubstantial manual labor. Recent studies have demonstrated that these systems\ncan be represented as computational graphs, enabling automatic optimization.\nDespite these advancements, most current efforts in Graph-based Agentic System\nOptimization (GASO) fail to properly assign feedback to the system's components\ngiven feedback on the system's output. To address this challenge, we formalize\nthe concept of semantic backpropagation with semantic gradients -- a\ngeneralization that aligns several key optimization techniques, including\nreverse-mode automatic differentiation and the more recent TextGrad by\nexploiting the relationship among nodes with a common successor. This serves as\na method for computing directional information about how changes to each\ncomponent of an agentic system might improve the system's output. To use these\ngradients, we propose a method called semantic gradient descent which enables\nus to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show\nthat our approach outperforms existing state-of-the-art methods for solving\nGASO problems. A detailed ablation study on the LIAR dataset demonstrates the\nparsimonious nature of our method. A full copy of our implementation is\npublicly available at https://github.com/HishamAlyahya/semantic_backprop",
      "tldr_zh": "本研究探讨了基于语言的智能代理系统（language-based agentic systems）的优化问题，强调了现有 Graph-based Agentic System Optimization (GASO) 方法在反馈分配上的不足。论文正式化了 semantic backpropagation 和 semantic gradients 概念，这是一种泛化方法，通过利用节点间的关系整合 reverse-mode automatic differentiation 和 TextGrad 等技术，来计算组件变化如何改善系统输出，并提出 semantic gradient descent 方法以有效解决 GASO 问题。实验结果显示，该方法在 BIG-Bench Hard 和 GSM8K 数据集上优于现有最先进方法，且在 LIAR 数据集上的消融研究证明了其简洁性；实现代码已公开在 https://github.com/HishamAlyahya/semantic_backprop。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA",
        "stat.ML",
        "68T07",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages in main text + 2 pages of references + 15 pages of\n  appendices, 2 figures in main text + 17 figures in appendices, 2 tables in\n  main text + 1 table in appendices, 2 algorithms in main text; source code\n  available at https://github.com/HishamAlyahya/semantic_backprop",
      "pdf_url": "http://arxiv.org/pdf/2412.03624v1",
      "published_date": "2024-12-04 15:52:03 UTC",
      "updated_date": "2024-12-04 15:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:40:53.549471"
    },
    {
      "arxiv_id": "2412.03401v2",
      "title": "Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy",
      "title_zh": "机器人辅助食管切除术中预训练注意力模型的",
      "authors": [
        "Ronald L. P. D. de Jong",
        "Yasmina al Khalil",
        "Tim J. M. Jaspers",
        "Romy C. van Jaarsveld",
        "Gino M. Kuiper",
        "Yiping Li",
        "Richard van Hillegersberg",
        "Jelle P. Ruurda",
        "Marcel Breeuwer",
        "Fons van der Sommen"
      ],
      "abstract": "Esophageal cancer is among the most common types of cancer worldwide. It is\ntraditionally treated using open esophagectomy, but in recent years,\nrobot-assisted minimally invasive esophagectomy (RAMIE) has emerged as a\npromising alternative. However, robot-assisted surgery can be challenging for\nnovice surgeons, as they often suffer from a loss of spatial orientation.\nComputer-aided anatomy recognition holds promise for improving surgical\nnavigation, but research in this area remains limited. In this study, we\ndeveloped a comprehensive dataset for semantic segmentation in RAMIE, featuring\nthe largest collection of vital anatomical structures and surgical instruments\nto date. Handling this diverse set of classes presents challenges, including\nclass imbalance and the recognition of complex structures such as nerves. This\nstudy aims to understand the challenges and limitations of current\nstate-of-the-art algorithms on this novel dataset and problem. Therefore, we\nbenchmarked eight real-time deep learning models using two pretraining\ndatasets. We assessed both traditional and attention-based networks,\nhypothesizing that attention-based networks better capture global patterns and\naddress challenges such as occlusion caused by blood or other tissues. The\nbenchmark includes our RAMIE dataset and the publicly available CholecSeg8k\ndataset, enabling a thorough assessment of surgical segmentation tasks. Our\nfindings indicate that pretraining on ADE20k, a dataset for semantic\nsegmentation, is more effective than pretraining on ImageNet. Furthermore,\nattention-based models outperform traditional convolutional neural networks,\nwith SegNeXt and Mask2Former achieving higher Dice scores, and Mask2Former\nadditionally excelling in average symmetric surface distance.",
      "tldr_zh": "本研究开发了一个全面的语义分割数据集，用于机器人辅助食管切除术 (RAMIE)，涵盖了最大的解剖结构和手术器械集合，以解决新手外科医生在空间定向方面的挑战。研究基准测试了八个实时深度学习模型，包括传统和基于注意力的网络（如 SegNeXt 和 Mask2Former），使用 ADE20k 和 ImageNet 预训练数据集，并假设注意力机制能更好地处理类别不平衡和遮挡问题。结果表明，ADE20k 预训练比 ImageNet 更有效，注意力模型在 Dice scores 和平均对称表面距离上显著优于传统 CNN，为手术导航技术提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for presentation at the SPIE Medical Imaging Conference,\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03401v2",
      "published_date": "2024-12-04 15:32:37 UTC",
      "updated_date": "2024-12-18 15:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:43:02.245388"
    },
    {
      "arxiv_id": "2412.05329v1",
      "title": "Mapping The Layers of The Ocean Floor With a Convolutional Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Guilherme G. D. Fernandes",
        "Vitor S. P. P. Oliveira",
        "João P. I. Astolfo"
      ],
      "abstract": "The mapping of ocean floor layers is a current challenge for the oil\nindustry. Existing solution methods involve mapping through seismic methods and\nwave inversion, which are complex and computationally expensive. The\nintroduction of artificial neural networks, specifically UNet, to predict\nvelocity models based on seismic shots reflected from the ocean floor shows\npromise for optimising this process. In this study, two neural network\narchitectures are validated for velocity model inversion and compared in terms\nof stability metrics such as loss function and similarity coefficient, as well\nas the differences between predicted and actual models. Indeed, neural networks\nprove promising as a solution to this challenge, achieving S{\\o}rensen-Dice\ncoefficient values above 70%.",
      "tldr_zh": "本研究针对石油行业中海洋底层映射的挑战，提出使用卷积神经网络（特别是UNet）来基于地震射线反射预测速度模型，从而优化复杂且计算密集的传统地震方法和波形反演。研究者验证了两种神经网络架构，并通过损失函数和相似性系数等稳定性指标比较了预测模型与实际模型的差异。结果显示，神经网络表现出色，S{\\o}rensen-Dice系数超过70%，证明其在速度模型反演中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.comp-ph",
        "physics.geo-ph",
        "86A15",
        "I.4.7; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures. Developed during the 6th Edition of the Advanced\n  School of Experimental Physics (EAFExp), Brazilian Centre for Physics\n  Research",
      "pdf_url": "http://arxiv.org/pdf/2412.05329v1",
      "published_date": "2024-12-04 15:26:48 UTC",
      "updated_date": "2024-12-04 15:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:41:16.296201"
    },
    {
      "arxiv_id": "2412.03390v1",
      "title": "Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs",
      "title_zh": "使用生成式 AI 增强供应链可见性：知识图谱中关系预测的探索性案例研究",
      "authors": [
        "Ge Zheng",
        "Alexandra Brintrup"
      ],
      "abstract": "A key stumbling block in effective supply chain risk management for companies\nand policymakers is a lack of visibility on interdependent supply network\nrelationships. Relationship prediction, also called link prediction is an\nemergent area of supply chain surveillance research that aims to increase the\nvisibility of supply chains using data-driven techniques. Existing methods have\nbeen successful for predicting relationships but struggle to extract the\ncontext in which these relationships are embedded - such as the products being\nsupplied or locations they are supplied from. Lack of context prevents\npractitioners from distinguishing transactional relations from established\nsupply chain relations, hindering accurate estimations of risk. In this work,\nwe develop a new Generative Artificial Intelligence (Gen AI) enhanced machine\nlearning framework that leverages pre-trained language models as embedding\nmodels combined with machine learning models to predict supply chain\nrelationships within knowledge graphs. By integrating Generative AI techniques,\nour approach captures the nuanced semantic relationships between entities,\nthereby improving supply chain visibility and facilitating more precise risk\nmanagement. Using data from a real case study, we show that GenAI-enhanced link\nprediction surpasses all benchmarks, and demonstrate how GenAI models can be\nexplored and effectively used in supply chain risk management.",
      "tldr_zh": "该研究针对供应链风险管理中关系可见性不足的问题，提出了一种基于 Generative AI 的增强机器学习框架，用于在知识图谱（knowledge graphs）中进行关系预测（link prediction）。该框架利用预训练语言模型作为嵌入模型，与机器学习模型结合，捕捉实体之间的细微语义关系，从而提取上下文（如产品和地点），以区分交易关系和供应链关系。实验结果显示，该方法在真实案例研究中超过了所有基准，提升了供应链可见性和风险管理精度，并展示了 Generative AI 在该领域的实际应用潜力。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03390v1",
      "published_date": "2024-12-04 15:19:01 UTC",
      "updated_date": "2024-12-04 15:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:43:25.305685"
    },
    {
      "arxiv_id": "2412.03388v1",
      "title": "DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxuan Liu",
        "Zhaoci Liu",
        "Yajun Hu",
        "Yingying Gao",
        "Shilei Zhang",
        "Zhenhua Ling"
      ],
      "abstract": "Human speech exhibits rich and flexible prosodic variations. To address the\none-to-many mapping problem from text to prosody in a reasonable and flexible\nmanner, we propose DiffStyleTTS, a multi-speaker acoustic model based on a\nconditional diffusion module and an improved classifier-free guidance, which\nhierarchically models speech prosodic features, and controls different prosodic\nstyles to guide prosody prediction. Experiments show that our method\noutperforms all baselines in naturalness and achieves superior synthesis speed\ncompared to three diffusion-based baselines. Additionally, by adjusting the\nguiding scale, DiffStyleTTS effectively controls the guidance intensity of the\nsynthetic prosody.",
      "tldr_zh": "本论文提出DiffStyleTTS，一种基于diffusion的层次化韵律建模方法，用于文本到语音(Text-to-Speech)系统，以解决文本到韵律的一对多映射问题，实现多样化和可控的prosodic styles。模型采用条件扩散模块和改进的无分类器引导，层次化建模语音韵律特征，并通过控制不同风格来指导韵律预测。实验表明，DiffStyleTTS在自然度和合成速度上优于基线模型，且通过调整引导比例，能有效控制合成韵律的强度。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03388v1",
      "published_date": "2024-12-04 15:17:25 UTC",
      "updated_date": "2024-12-04 15:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:41:41.448195"
    },
    {
      "arxiv_id": "2412.03620v1",
      "title": "Recommender Systems for Sustainability: Overview and Research Issues",
      "title_zh": "可持续性推荐系统：概述和研究问题",
      "authors": [
        "Alexander Felfernig",
        "Manfred Wundara",
        "Thi Ngoc Trang Tran",
        "Seda Polat-Erdeniz",
        "Sebastian Lubos",
        "Merfat El-Mansi",
        "Damian Garber",
        "Viet-Man Le"
      ],
      "abstract": "Sustainability development goals (SDGs) are regarded as a universal call to\naction with the overall objectives of planet protection, ending of poverty, and\nensuring peace and prosperity for all people. In order to achieve these\nobjectives, different AI technologies play a major role. Specifically,\nrecommender systems can provide support for organizations and individuals to\nachieve the defined goals. Recommender systems integrate AI technologies such\nas machine learning, explainable AI (XAI), case-based reasoning, and constraint\nsolving in order to find and explain user-relevant alternatives from a\npotentially large set of options. In this article, we summarize the state of\nthe art in applying recommender systems to support the achievement of\nsustainability development goals. In this context, we discuss open issues for\nfuture research.",
      "tldr_zh": "该论文概述了推荐系统在支持可持续发展目标（SDGs）方面的应用，强调其通过整合机器学习、Explainable AI (XAI)、基于案例的推理和约束求解等AI技术，帮助组织和个人从大量选项中筛选出相关方案，以实现环境保护、消除贫困及促进和平繁荣的目标。文章总结了当前推荐系统在SDGs领域的现有研究状态，并指出了未来研究的关键问题，如改进算法的可持续性和扩展应用场景。总之，该研究为利用推荐系统推动可持续发展提供了重要见解和方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03620v1",
      "published_date": "2024-12-04 15:03:47 UTC",
      "updated_date": "2024-12-04 15:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:41:52.724569"
    },
    {
      "arxiv_id": "2412.03359v1",
      "title": "WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis",
      "title_zh": "WiS 平台：通过基于游戏的分析增强基于 LLM 的多智能体系统的评估",
      "authors": [
        "Chengwei Hu",
        "Jianhui Zheng",
        "Yancheng He",
        "Hangyu Guo",
        "Junguang Jiang",
        "Han Zhu",
        "Kai Sun",
        "Yuning Jiang",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in autonomous multi-agent systems (MAS) based on large\nlanguage models (LLMs) have enhanced the application scenarios and improved the\ncapability of LLMs to handle complex tasks. Despite demonstrating\neffectiveness, existing studies still evidently struggle to evaluate, analysis,\nand reproducibility of LLM-based MAS. In this paper, to facilitate the research\non LLM-based MAS, we introduce an open, scalable, and real-time updated\nplatform for accessing and analyzing the LLM-based MAS based on the games Who\nis Spy?\" (WiS). Our platform is featured with three main worths: (1) a unified\nmodel evaluate interface that supports models available on Hugging Face; (2)\nreal-time updated leaderboard for model evaluation; (3) a comprehensive\nevaluation covering game-winning rates, attacking, defense strategies, and\nreasoning of LLMs. To rigorously test WiS, we conduct extensive experiments\ncoverage of various open- and closed-source LLMs, we find that different agents\nexhibit distinct and intriguing behaviors in the game. The experimental results\ndemonstrate the effectiveness and efficiency of our platform in evaluating\nLLM-based MAS. Our platform and its documentation are publicly available at\n\\url{https://whoisspy.ai/}",
      "tldr_zh": "本研究引入了 WiS 平台，这是一个开放、可扩展的系统，用于通过 \"Who is Spy?\" (WiS) 游戏评估基于大型语言模型 (LLMs) 的多智能体系统 (MAS)，以解决现有研究的评估、分析和可重复性问题。平台的关键特点包括统一的模型评估接口（支持 Hugging Face 上的模型）、实时更新的排行榜，以及全面评估如游戏获胜率、攻击防御策略和 LLMs 推理能力。实验结果显示，不同代理在游戏中表现出独特的行为，证明了平台的有效性和高效性；平台及其文档已公开可用于 https://whoisspy.ai/。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03359v1",
      "published_date": "2024-12-04 14:45:09 UTC",
      "updated_date": "2024-12-04 14:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:42:05.380912"
    },
    {
      "arxiv_id": "2412.03352v2",
      "title": "Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqin Zhang",
        "Qingkui Chen",
        "Chen Huang",
        "Zhengjie Zhang",
        "Meiling Chen",
        "Zhibing Fu"
      ],
      "abstract": "Most data-driven models for medical image analysis rely on universal\naugmentations to improve accuracy. Experimental evidence has confirmed their\neffectiveness, but the unclear mechanism underlying them poses a barrier to the\nwidespread acceptance and trust in such methods within the medical community.\nWe revisit and acknowledge the unique characteristics of medical images apart\nfrom traditional digital images, and consequently, proposed a medical-specific\naugmentation algorithm that is more elastic and aligns well with radiology scan\nprocedure. The method performs piecewise affine with sinusoidal distorted ray\naccording to radius on polar coordinates, thus simulating uncertain postures of\nhuman lying flat on the scanning table. Our method could generate human\nvisceral distribution without affecting the fundamental relative position on\naxial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal\nand Similarity-Guided Parameter Search, are introduced to bolster robustness of\nour augmentation method. In contrast to other methodologies, our method is\nhighlighted for its intuitive design and ease of understanding for medical\nprofessionals, thereby enhancing its applicability in clinical scenarios.\nExperiments show our method improves accuracy with two modality across multiple\nfamous segmentation frameworks without requiring more data samples. Our preview\ncode is available in: https://github.com/MGAMZ/PSBPD.",
      "tldr_zh": "该论文针对医疗图像分析中的数据增强（augmentations）问题，提出了一种直观的轴向增强方法，使用基于极坐标的正弦分段扭曲（Polar-Sine-Based Piecewise Distortion），以模拟人类在扫描台上的不确定姿势，同时保持轴向平面的基本相对位置。方法结合了 Meta-based Scan Table Removal 和 Similarity-Guided Parameter Search 等非自适应算法，提升了增强的鲁棒性和易懂性，便于医疗专业人员应用。实验结果显示，该方法在多种模态和知名分割框架中显著提高了准确性，而无需额外数据样本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at Smart Health",
      "pdf_url": "http://arxiv.org/pdf/2412.03352v2",
      "published_date": "2024-12-04 14:35:06 UTC",
      "updated_date": "2025-03-26 15:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:42:24.399783"
    },
    {
      "arxiv_id": "2412.03347v1",
      "title": "DIVE: Taming DINO for Subject-Driven Video Editing",
      "title_zh": "DIVE：驯服 DINO 用于主体驱动",
      "authors": [
        "Yi Huang",
        "Wei Xiong",
        "He Zhang",
        "Chaoqi Chen",
        "Jianzhuang Liu",
        "Mingfu Yan",
        "Shifeng Chen"
      ],
      "abstract": "Building on the success of diffusion models in image generation and editing,\nvideo editing has recently gained substantial attention. However, maintaining\ntemporal consistency and motion alignment still remains challenging. To address\nthese issues, this paper proposes DINO-guided Video Editing (DIVE), a framework\ndesigned to facilitate subject-driven editing in source videos conditioned on\neither target text prompts or reference images with specific identities. The\ncore of DIVE lies in leveraging the powerful semantic features extracted from a\npretrained DINOv2 model as implicit correspondences to guide the editing\nprocess. Specifically, to ensure temporal motion consistency, DIVE employs DINO\nfeatures to align with the motion trajectory of the source video. Extensive\nexperiments on diverse real-world videos demonstrate that our framework can\nachieve high-quality editing results with robust motion consistency,\nhighlighting the potential of DINO to contribute to video editing. For precise\nsubject editing, DIVE incorporates the DINO features of reference images into a\npretrained text-to-image model to learn Low-Rank Adaptations (LoRAs),\neffectively registering the target subject's identity. Project page:\nhttps://dino-video-editing.github.io",
      "tldr_zh": "本研究提出DIVE框架，利用预训练的DINOv2模型语义特征来指导基于主题的视频编辑，旨在解决视频编辑中时间一致性和运动对齐的挑战。DIVE通过将DINO特征与源视频的运动轨迹对齐，确保编辑过程的稳健性，并支持基于目标文本提示或参考图像的编辑；此外，它将参考图像的DINO特征整合到预训练文本到图像模型中，学习Low-Rank Adaptations (LoRAs)以精确注册目标主题身份。实验在多样真实世界视频上证明，DIVE实现了高质量编辑结果，并显著提升了运动一致性，展示了DINO在视频编辑领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03347v1",
      "published_date": "2024-12-04 14:28:43 UTC",
      "updated_date": "2024-12-04 14:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:43:41.837089"
    },
    {
      "arxiv_id": "2412.03343v1",
      "title": "Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning",
      "title_zh": "通过可能性探索微调提升大型语言模型的语言多样性",
      "authors": [
        "Long Mai",
        "Julie Carson-Berndsen"
      ],
      "abstract": "While Large Language Models (LLMs) have made significant strides in\nreplicating human-like abilities, there are concerns about a reduction in the\nlinguistic diversity of their outputs. This results in the homogenization of\nviewpoints and perspectives, as well as the underrepresentation of specific\ndemographic groups. Although several fine-tuning and prompting techniques have\nbeen suggested to tackle the issue, they are often tailored to specific tasks\nor come with a substantial increase in computational cost and latency. This\nmakes them challenging to apply to applications that demand very low latency,\nsuch as chatbots and virtual assistants. We propose Possibility Exploration\nFine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity\nof LLMs without increasing latency or computational cost. Given the same\nprompt, models fine-tuned with PEFT can simultaneously generate multiple\ndiverse responses, each corresponding with a controllable possibility number.\nExperiments on dialogue and story generation tasks demonstrate that PEFT\nsignificantly enhances the diversity of LLM outputs, as evidenced by lower\nsimilarity between candidate responses. Since PEFT emphasizes semantic\ndiversity over lexical diversity, it can also notably reduce demographic bias\nin dialogue systems. The implementations and datasets are available in our\nrepository: https://github.com/mailong25/peft_diversity",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 输出语言多样性不足的问题，提出了一种任务无关的框架——Possibility Exploration Fine-Tuning (PEFT)，旨在提升文本多样性而不增加计算成本或延迟。PEFT 允许模型在同一提示下生成多个可控多样化的响应，每个响应对应不同的可能性数字，从而强调语义多样性而非词汇层面。实验在对话和故事生成任务上显示，PEFT 显著降低了候选响应之间的相似度，并有效减少了对话系统中的人口统计学偏差，为更包容的 LLMs 应用提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03343v1",
      "published_date": "2024-12-04 14:23:16 UTC",
      "updated_date": "2024-12-04 14:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:43:51.794839"
    },
    {
      "arxiv_id": "2412.03338v2",
      "title": "AI-Driven Day-to-Day Route Choice",
      "title_zh": "AI驱动的日常路线选择",
      "authors": [
        "Leizhen Wang",
        "Peibo Duan",
        "Zhengbing He",
        "Cheng Lyu",
        "Xin Chen",
        "Nan Zheng",
        "Li Yao",
        "Zhenliang Ma"
      ],
      "abstract": "Understanding travelers' route choices can help policymakers devise optimal\noperational and planning strategies for both normal and abnormal circumstances.\nHowever, existing choice modeling methods often rely on predefined assumptions\nand struggle to capture the dynamic and adaptive nature of travel behavior.\nRecently, Large Language Models (LLMs) have emerged as a promising alternative,\ndemonstrating remarkable ability to replicate human-like behaviors across\nvarious fields. Despite this potential, their capacity to accurately simulate\nhuman route choice behavior in transportation contexts remains doubtful. To\nsatisfy this curiosity, this paper investigates the potential of LLMs for route\nchoice modeling by introducing an LLM-empowered agent, \"LLMTraveler.\" This\nagent integrates an LLM as its core, equipped with a memory system that learns\nfrom past experiences and makes decisions by balancing retrieved data and\npersonality traits. The study systematically evaluates the LLMTraveler's\nability to replicate human-like decision-making through two stages of\nday-to-day (DTD) congestion games: (1) analyzing its route-switching behavior\nin single origin-destination (OD) pair scenarios, where it demonstrates\npatterns that align with laboratory data but cannot be fully explained by\ntraditional models, and (2) testing its capacity to model adaptive learning\nbehaviors in multi-OD scenarios on the Ortuzar and Willumsen (OW) network,\nproducing results comparable to Multinomial Logit (MNL) and Reinforcement\nLearning (RL) models. These experiments demonstrate that the framework can\npartially replicate human-like decision-making in route choice while providing\nnatural language explanations for its decisions. This capability offers\nvaluable insights for transportation policymaking, such as simulating traveler\nresponses to new policies or changes in the network.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在路线选择建模中的潜力，以解决现有方法依赖预定义假设而无法捕捉动态旅行行为的局限性。作者引入了 LLMTraveler 代理，该代理以 LLM 为核心，结合记忆系统、过去经验和个性特征来模拟人类决策，并在日复一日 (DTD) 拥堵游戏中进行评估。实验结果显示，LLMTraveler 在单源-目的地 (OD) 和多 OD 场景中，能部分复制人类行为，与 Multinomial Logit (MNL) 和 Reinforcement Learning (RL) 模型相当，并提供自然语言解释，从而为交通政策制定提供宝贵模拟工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03338v2",
      "published_date": "2024-12-04 14:13:38 UTC",
      "updated_date": "2024-12-31 14:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:44:05.629943"
    },
    {
      "arxiv_id": "2412.03612v1",
      "title": "Chatting with Logs: An exploratory study on Finetuning LLMs for LogQL",
      "title_zh": "与日志对话：关于为 LogQL 微调大型语言模型的探索性研究",
      "authors": [
        "Vishwanath Seshagiri",
        "Siddharth Balyan",
        "Vaastav Anand",
        "Kaustubh Dhole",
        "Ishan Sharma",
        "Avani Wildani",
        "José Cambronero",
        "Andreas Züfle"
      ],
      "abstract": "Logging is a critical function in modern distributed applications, but the\nlack of standardization in log query languages and formats creates significant\nchallenges. Developers currently must write ad hoc queries in platform-specific\nlanguages, requiring expertise in both the query language and\napplication-specific log details -- an impractical expectation given the\nvariety of platforms and volume of logs and applications. While generating\nthese queries with large language models (LLMs) seems intuitive, we show that\ncurrent LLMs struggle with log-specific query generation due to the lack of\nexposure to domain-specific knowledge. We propose a novel natural language (NL)\ninterface to address these inconsistencies and aide log query generation,\nenabling developers to create queries in a target log query language by\nproviding NL inputs. We further introduce ~\\textbf{NL2QL}, a manually\nannotated, real-world dataset of natural language questions paired with\ncorresponding LogQL queries spread across three log formats, to promote the\ntraining and evaluation of NL-to-loq query systems. Using NL2QL, we\nsubsequently fine-tune and evaluate several state of the art LLMs, and\ndemonstrate their improved capability to generate accurate LogQL queries. We\nperform further ablation studies to demonstrate the effect of additional\ntraining data, and the transferability across different log formats. In our\nexperiments, we find up to 75\\% improvement of finetuned models to generate\nLogQL queries compared to non finetuned models.",
      "tldr_zh": "该研究探讨了日志查询语言(LogQL)的标准化缺失问题，开发人员需编写特定平台的查询并掌握相关专业知识，而现有LLMs在生成日志查询时因缺乏领域知识而表现不佳。为此，研究提出了一种自然语言(NL)接口，允许用户通过NL输入生成LogQL查询，并引入了NL2QL数据集——一个手动标注的真实数据集，包含NL问题和对应LogQL查询，覆盖三种日志格式。使用NL2QL微调了几种最先进LLMs，实验结果显示，微调模型在生成LogQL查询的准确性上比未微调模型提高了多达75%，并通过消融研究验证了额外训练数据和跨日志格式转移性的积极影响。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.DB",
      "comment": "draft under submission at another venue",
      "pdf_url": "http://arxiv.org/pdf/2412.03612v1",
      "published_date": "2024-12-04 14:06:24 UTC",
      "updated_date": "2024-12-04 14:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:44:16.388267"
    },
    {
      "arxiv_id": "2412.03331v2",
      "title": "LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Fred Philippy",
        "Siwen Guo",
        "Jacques Klein",
        "Tegawendé F. Bissyandé"
      ],
      "abstract": "Sentence embedding models play a key role in various Natural Language\nProcessing tasks, such as in Topic Modeling, Document Clustering and\nRecommendation Systems. However, these models rely heavily on parallel data,\nwhich can be scarce for many low-resource languages, including Luxembourgish.\nThis scarcity results in suboptimal performance of monolingual and\ncross-lingual sentence embedding models for these languages. To address this\nissue, we compile a relatively small but high-quality human-generated\ncross-lingual parallel dataset to train LuxEmbedder, an enhanced sentence\nembedding model for Luxembourgish with strong cross-lingual capabilities.\nAdditionally, we present evidence suggesting that including low-resource\nlanguages in parallel training datasets can be more advantageous for other\nlow-resource languages than relying solely on high-resource language pairs.\nFurthermore, recognizing the lack of sentence embedding benchmarks for\nlow-resource languages, we create a paraphrase detection benchmark specifically\nfor Luxembourgish, aiming to partially fill this gap and promote further\nresearch.",
      "tldr_zh": "本研究针对低资源语言Luxembourgish的句嵌入问题，编译了一个小型但高质量的人工生成跨语言平行数据集，用于训练LuxEmbedder模型，以提升其句嵌入性能和跨语言能力。研究发现，在训练数据中包含低资源语言比仅依赖高资源语言对更能改善其他低资源语言的模型表现。此外，作者创建了一个专为Luxembourgish设计的释义检测基准，旨在填补低资源语言的句嵌入基准空白并推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03331v2",
      "published_date": "2024-12-04 14:02:12 UTC",
      "updated_date": "2024-12-05 07:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:44:30.047913"
    },
    {
      "arxiv_id": "2412.03610v1",
      "title": "The Use of Artificial Intelligence in Military Intelligence: An Experimental Investigation of Added Value in the Analysis Process",
      "title_zh": "人工智能在军事情报中的应用：分析过程增加价值的实验调查",
      "authors": [
        "Christian Nitzl",
        "Achim Cyran",
        "Sascha Krstanovic",
        "Uwe M. Borghoff"
      ],
      "abstract": "It is beyond dispute that the potential benefits of artificial intelligence\n(AI) in military intelligence are considerable. Nevertheless, it remains\nuncertain precisely how AI can enhance the analysis of military data. The aim\nof this study is to address this issue. To this end, the AI demonstrator\ndeepCOM was developed in collaboration with the start-up Aleph Alpha.\n  The AI functions include text search, automatic text summarization and Named\nEntity Recognition (NER). These are evaluated for their added value in military\nanalysis. It is demonstrated that under time pressure, the utilization of AI\nfunctions results in assessments clearly superior to that of the control group.\nNevertheless, despite the demonstrably superior analysis outcome in the\nexperimental group, no increase in confidence in the accuracy of their own\nanalyses was observed. Finally, the paper identifies the limitations of\nemploying AI in military intelligence, particularly in the context of analyzing\nambiguous and contradictory information.",
      "tldr_zh": "这篇论文通过实验调查了AI在军事情报分析中的附加价值，开发了deepCOM演示器，该系统整合了文本搜索、自动文本摘要和Named Entity Recognition (NER) 等功能。实验结果显示，在时间压力环境下，使用AI的组别分析结果明显优于对照组，但参与者对自身分析的信心并未提升。论文同时指出了AI在处理模糊和矛盾信息时的局限性，为AI在军事情报领域的应用提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.03610v1",
      "published_date": "2024-12-04 13:56:10 UTC",
      "updated_date": "2024-12-04 13:56:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:46:17.096680"
    },
    {
      "arxiv_id": "2412.03312v1",
      "title": "Path-Guided Particle-based Sampling",
      "title_zh": "路径引导的基于粒子的采样",
      "authors": [
        "Mingzhou Fan",
        "Ruida Zhou",
        "Chao Tian",
        "Xiaoning Qian"
      ],
      "abstract": "Particle-based Bayesian inference methods by sampling from a partition-free\ntarget (posterior) distribution, e.g., Stein variational gradient descent\n(SVGD), have attracted significant attention. We propose a path-guided\nparticle-based sampling~(PGPS) method based on a novel Log-weighted Shrinkage\n(LwS) density path linking an initial distribution to the target distribution.\nWe propose to utilize a Neural network to learn a vector field motivated by the\nFokker-Planck equation of the designed density path. Particles, initiated from\nthe initial distribution, evolve according to the ordinary differential\nequation defined by the vector field. The distribution of these particles is\nguided along a density path from the initial distribution to the target\ndistribution. The proposed LwS density path allows for an efficient search of\nmodes of the target distribution while canonical methods fail. We theoretically\nanalyze the Wasserstein distance of the distribution of the PGPS-generated\nsamples and the target distribution due to approximation and discretization\nerrors. Practically, the proposed PGPS-LwS method demonstrates higher Bayesian\ninference accuracy and better calibration ability in experiments conducted on\nboth synthetic and real-world Bayesian learning tasks, compared to baselines,\nsuch as SVGD and Langevin dynamics, etc.",
      "tldr_zh": "本文提出了一种路径引导的粒子-based采样方法（Path-Guided Particle-based Sampling, PGPS），基于Log-weighted Shrinkage (LwS)密度路径，将初始分布引导至目标分布，以提升Bayesian inference的效率。PGPS利用神经网络学习一个基于Fokker-Planck equation的矢量场，使粒子通过普通微分方程（ODE）演化，从而高效搜索目标分布的模式，并减少传统方法的局限。实验结果显示，PGPS-LwS在合成和真实世界Bayesian学习任务中，比SVGD和Langevin dynamics等基线方法具有更高的推理准确性和校准能力，且通过Wasserstein distance分析验证了其近似和离散化误差。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03312v1",
      "published_date": "2024-12-04 13:44:56 UTC",
      "updated_date": "2024-12-04 13:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:46:15.204976"
    },
    {
      "arxiv_id": "2412.03307v1",
      "title": "Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Rochas",
        "Angelo Furno",
        "Nour-Eddin El Faouzi"
      ],
      "abstract": "Demand for bike sharing is impacted by various factors, such as weather\nconditions, events, and the availability of other transportation modes. This\nimpact remains elusive due to the complex interdependence of these factors or\nlocationrelated user behavior variations. It is also not clear which factor is\nadditional information which are not already contained in the historical\ndemand. Intermodal dependencies between bike-sharing and other modes are also\nunderexplored, and the value of this information has not been studied in\ndegraded situations. The proposed study analyzes the impact of adding\ncontextual data, such as weather, time embedding, and road traffic flow, to\npredict bike-sharing Origin-Destination (OD) flows in atypical weather\nsituations Our study highlights a mild relationship between prediction quality\nof bike-sharing demand and road traffic flow, while the introduced time\nembedding allows outperforming state-of-the-art results, particularly in the\ncase of degraded weather conditions. Including weather data as an additional\ninput further improves our model with respect to the basic ST-ED-RMGC\nprediction model by reducing of more than 20% the prediction error in degraded\nweather condition.",
      "tldr_zh": "本研究探讨了在恶劣天气条件下，使用Graph Neural Networks预测共享单车Origin-Destination (OD)流量的需求问题，通过整合上下文数据如天气、时间嵌入和道路交通流量来分析这些因素的影响。结果显示，道路交通流量与预测质量的相关性较弱，而引入时间嵌入显著提升了模型性能，尤其在恶劣天气中超过了现有最先进方法。进一步添加天气数据后，与基本ST-ED-RMGC模型相比，预测错误减少了20%以上，这为改进共享单车需求预测提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03307v1",
      "published_date": "2024-12-04 13:29:52 UTC",
      "updated_date": "2024-12-04 13:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:45:03.646004"
    },
    {
      "arxiv_id": "2412.06820v1",
      "title": "Artificial Intelligence without Restriction Surpassing Human Intelligence with Probability One: Theoretical Insight into Secrets of the Brain with AI Twins of the Brain",
      "title_zh": "翻译失败",
      "authors": [
        "Guang-Bin Huang",
        "M. Brandon Westover",
        "Eng-King Tan",
        "Haibo Wang",
        "Dongshun Cui",
        "Wei-Ying Ma",
        "Tiantong Wang",
        "Qi He",
        "Haikun Wei",
        "Ning Wang",
        "Qiyuan Tian",
        "Kwok-Yan Lam",
        "Xin Yao",
        "Tien Yin Wong"
      ],
      "abstract": "Artificial Intelligence (AI) has apparently become one of the most important\ntechniques discovered by humans in history while the human brain is widely\nrecognized as one of the most complex systems in the universe. One fundamental\ncritical question which would affect human sustainability remains open: Will\nartificial intelligence (AI) evolve to surpass human intelligence in the\nfuture? This paper shows that in theory new AI twins with fresh cellular level\nof AI techniques for neuroscience could approximate the brain and its\nfunctioning systems (e.g. perception and cognition functions) with any expected\nsmall error and AI without restrictions could surpass human intelligence with\nprobability one in the end. This paper indirectly proves the validity of the\nconjecture made by Frank Rosenblatt 70 years ago about the potential\ncapabilities of AI, especially in the realm of artificial neural networks.\nIntelligence is just one of fortuitous but sophisticated creations of the\nnature which has not been fully discovered. Like mathematics and physics, with\nno restrictions artificial intelligence would lead to a new subject with its\nself-contained systems and principles. We anticipate that this paper opens new\ndoors for 1) AI twins and other AI techniques to be used in cellular level of\nefficient neuroscience dynamic analysis, functioning analysis of the brain and\nbrain illness solutions; 2) new worldwide collaborative scheme for\ninterdisciplinary teams concurrently working on and modelling different types\nof neurons and synapses and different level of functioning subsystems of the\nbrain with AI techniques; 3) development of low energy of AI techniques with\nthe aid of fundamental neuroscience properties; and 4) new controllable,\nexplainable and safe AI techniques with reasoning capabilities of discovering\nprinciples in nature.",
      "tldr_zh": "该论文探讨了无限制的 Artificial Intelligence (AI) 是否能以概率一超越人类智能，并通过理论分析证明了 AI Twins of the Brain（一种模拟大脑细胞水平的AI技术）可以精确近似大脑功能，如感知和认知系统，从而实现这一超越。论文间接验证了Frank Rosenblatt 70年前关于人工智能潜力的猜想，强调AI将发展为一个独立学科。最终，它提出利用AI Twins进行神经科学动态分析、脑功能研究和脑病解决方案，并呼吁全球协作开发低能耗、可控且安全的AI技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by journal Neurocomputing",
      "pdf_url": "http://arxiv.org/pdf/2412.06820v1",
      "published_date": "2024-12-04 13:17:44 UTC",
      "updated_date": "2024-12-04 13:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:45:18.706132"
    },
    {
      "arxiv_id": "2412.03287v1",
      "title": "Integrating Generative AI into Art Therapy: A Technical Showcase",
      "title_zh": "翻译失败",
      "authors": [
        "Yannis Valentin Schmutz",
        "Tetiana Kravchenko",
        "Souhir Ben Souissi",
        "Mascha Kurpicz-Briki"
      ],
      "abstract": "This paper explores the integration of generative AI into the field of art\ntherapy. Leveraging proven text-to-image models, we introduce a novel technical\ndesign to complement art therapy. The resulting AI-based tools shall enable\npatients to refine and customize their creative work, opening up new avenues of\nexpression and accessibility. Using three illustrative examples, we demonstrate\npotential outputs of our solution and evaluate them qualitatively. Furthermore,\nwe discuss the current limitations and ethical considerations associated with\nthis integration and provide an outlook into future research efforts. Our\nimplementations are publicly available at https://github.com/BFH-AMI/sds24.",
      "tldr_zh": "这篇论文探讨了将 Generative AI 整合到艺术治疗领域的可能性，通过使用成熟的 text-to-image 模型，引入了一个新颖的技术设计，帮助患者完善和自定义创意作品，从而提升表达和可访问性。作者通过三个示例演示了解决方案的潜在输出，并进行了定性评估，同时讨论了当前限制、伦理考虑，并展望未来研究方向。该实现已公开在 GitHub 上（https://github.com/BFH-AMI/sds24），为 AI 在治疗领域的应用提供了实际参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03287v1",
      "published_date": "2024-12-04 12:58:55 UTC",
      "updated_date": "2024-12-04 12:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:45:27.323981"
    },
    {
      "arxiv_id": "2412.03283v2",
      "title": "Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Müller",
        "Denis Lukovnikov",
        "Jonas Thietke",
        "Asja Fischer",
        "Erwin Quiring"
      ],
      "abstract": "Integrating watermarking into the generation process of latent diffusion\nmodels (LDMs) simplifies detection and attribution of generated content.\nSemantic watermarks, such as Tree-Rings and Gaussian Shading, represent a novel\nclass of watermarking techniques that are easy to implement and highly robust\nagainst various perturbations. However, our work demonstrates a fundamental\nsecurity vulnerability of semantic watermarks. We show that attackers can\nleverage unrelated models, even with different latent spaces and architectures\n(UNet vs DiT), to perform powerful and realistic forgery attacks. Specifically,\nwe design two watermark forgery attacks. The first imprints a targeted\nwatermark into real images by manipulating the latent representation of an\narbitrary image in an unrelated LDM to get closer to the latent representation\nof a watermarked image. We also show that this technique can be used for\nwatermark removal. The second attack generates new images with the target\nwatermark by inverting a watermarked image and re-generating it with an\narbitrary prompt. Both attacks just need a single reference image with the\ntarget watermark. Overall, our findings question the applicability of semantic\nwatermarks by revealing that attackers can easily forge or remove these\nwatermarks under realistic conditions.",
      "tldr_zh": "本文研究了 semantic watermarks（如 Tree-Rings 和 Gaussian Shading）在潜在扩散模型 (LDMs) 中的安全漏洞，展示了攻击者可利用无关模型（包括不同架构如 UNet vs DiT）进行黑箱伪造攻击。研究设计了两种攻击：第一种通过操纵图像潜在表示，将目标水印印入真实图像或实现水印移除；第二种通过反转水印图像并用任意提示重新生成，创建带有水印的新图像。两者仅需一个参考图像即可执行，结果表明这些攻击在现实条件下高度有效，质疑了 semantic watermarks 的鲁棒性和实际适用性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "28 pages, 22 figures, 8 tables, to be published in The IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition 2025 (CVPR)",
      "pdf_url": "http://arxiv.org/pdf/2412.03283v2",
      "published_date": "2024-12-04 12:57:17 UTC",
      "updated_date": "2025-03-26 15:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:46:33.099675"
    },
    {
      "arxiv_id": "2412.03270v1",
      "title": "Intent-driven In-context Learning for Few-shot Dialogue State Tracking",
      "title_zh": "意图驱动的语境学习用于少样本对话状态跟踪",
      "authors": [
        "Zihao Yi",
        "Zhe Xu",
        "Ying Shen"
      ],
      "abstract": "Dialogue state tracking (DST) plays an essential role in task-oriented\ndialogue systems. However, user's input may contain implicit information,\nposing significant challenges for DST tasks. Additionally, DST data includes\ncomplex information, which not only contains a large amount of noise unrelated\nto the current turn, but also makes constructing DST datasets expensive. To\naddress these challenges, we introduce Intent-driven In-context Learning for\nFew-shot DST (IDIC-DST). By extracting user's intent, we propose an\nIntent-driven Dialogue Information Augmentation module to augment the dialogue\ninformation, which can track dialogue states more effectively. Moreover, we\nmask noisy information from DST data and rewrite user's input in the\nIntent-driven Examples Retrieval module, where we retrieve similar examples. We\nthen utilize a pre-trained large language model to update the dialogue state\nusing the augmented dialogue information and examples. Experimental results\ndemonstrate that IDIC-DST achieves state-of-the-art performance in few-shot\nsettings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.",
      "tldr_zh": "本文提出了一种基于意图驱动的少样本对话状态跟踪（Intent-driven In-context Learning for Few-shot DST，简称 IDIC-DST），旨在解决用户输入中的隐式信息和数据噪声问题。该方法包括意图驱动对话信息增强模块，用于提取用户意图并优化对话数据，以及意图驱动示例检索模块，通过屏蔽噪声并重写输入来检索相似示例。随后，利用预训练的大型语言模型更新对话状态。实验结果显示，IDIC-DST 在 MultiWOZ 2.1 和 MultiWOZ 2.4 数据集的少样本设置中，达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03270v1",
      "published_date": "2024-12-04 12:25:41 UTC",
      "updated_date": "2024-12-04 12:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:46:44.418162"
    },
    {
      "arxiv_id": "2412.05327v1",
      "title": "IMPACT:InMemory ComPuting Architecture Based on Y-FlAsh Technology for Coalesced Tsetlin Machine Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Ghazal",
        "Wei Wang",
        "Shahar Kvatinsky",
        "Farhad Merchant",
        "Alex Yakovlev",
        "Rishad Shafik"
      ],
      "abstract": "The increasing demand for processing large volumes of data for machine\nlearning models has pushed data bandwidth requirements beyond the capability of\ntraditional von Neumann architecture. In-memory computing (IMC) has recently\nemerged as a promising solution to address this gap by enabling distributed\ndata storage and processing at the micro-architectural level, significantly\nreducing both latency and energy. In this paper, we present the IMPACT:\nInMemory ComPuting Architecture Based on Y-FlAsh Technology for Coalesced\nTsetlin Machine Inference, underpinned on a cutting-edge memory device,\nY-Flash, fabricated on a 180 nm CMOS process. Y-Flash devices have recently\nbeen demonstrated for digital and analog memory applications, offering high\nyield, non-volatility, and low power consumption. The IMPACT leverages the\nY-Flash array to implement the inference of a novel machine learning algorithm:\ncoalesced Tsetlin machine (CoTM) based on propositional logic. CoTM utilizes\nTsetlin automata (TA) to create Boolean feature selections stochastically\nacross parallel clauses. The IMPACT is organized into two computational\ncrossbars for storing the TA and weights. Through validation on the MNIST\ndataset, IMPACT achieved 96.3% accuracy. The IMPACT demonstrated improvements\nin energy efficiency, e.g., 2.23X over CNN-based ReRAM, 2.46X over Neuromorphic\nusing NOR-Flash, and 2.06X over DNN-based PCM, suited for modern ML inference\napplications.",
      "tldr_zh": "本研究提出IMPACT架构，利用Y-Flash技术实现In-Memory Computing (IMC)，以解决传统von Neumann architecture在机器学习数据处理中的带宽限制问题。IMPACT基于180 nm CMOS工艺的Y-Flash设备，构建两个计算交叉阵列来存储Tsetlin Automata (TA)和权重，支持Coalesced Tsetlin Machine (CoTM)算法的推理，该算法通过随机布尔特征选择进行并行处理。在MNIST数据集上，IMPACT实现了96.3%的准确率，并在能量效率上比CNN-based ReRAM提升2.23倍、比Neuromorphic using NOR-Flash提升2.46倍、比DNN-based PCM提升2.06倍，适用于现代ML推理应用。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "27 Pages, 14 Figures, 6 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.05327v1",
      "published_date": "2024-12-04 12:22:52 UTC",
      "updated_date": "2024-12-04 12:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:46:55.712788"
    },
    {
      "arxiv_id": "2412.03267v1",
      "title": "Detecting abnormal heart sound using mobile phones and on-device IConNet",
      "title_zh": "翻译失败",
      "authors": [
        "Linh Vu",
        "Thu Tran"
      ],
      "abstract": "Given the global prevalence of cardiovascular diseases, there is a pressing\nneed for easily accessible early screening methods. Typically, this requires\nmedical practitioners to investigate heart auscultations for irregular sounds,\nfollowed by echocardiography and electrocardiography tests. To democratize\nearly diagnosis, we present a user-friendly solution for abnormal heart sound\ndetection, utilizing mobile phones and a lightweight neural network optimized\nfor on-device inference. Unlike previous approaches reliant on specialized\nstethoscopes, our method directly analyzes audio recordings, facilitated by a\nnovel architecture known as IConNet. IConNet, an Interpretable Convolutional\nNeural Network, harnesses insights from audio signal processing, enhancing\nefficiency and providing transparency in neural pattern extraction from raw\nwaveform signals. This is a significant step towards trustworthy AI in\nhealthcare, aiding in remote health monitoring efforts.",
      "tldr_zh": "该研究针对心血管疾病的全球流行，提出了一种用户友好的异常心音检测方法，利用手机直接分析音频记录，并采用轻量级神经网络 IConNet 进行 on-device inference。IConNet 是一种可解释的 Convolutional Neural Network，利用音频信号处理见解，从原始波形信号中高效提取神经模式，提供透明性和可靠性。与传统依赖专业听诊器的方案不同，该方法有助于实现早期筛查的民主化，并支持远程健康监测。实验结果表明，此方法提升了诊断的可访问性和可信赖性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "N2Women'24 Workshop, MobiSys 2024, Tokyo, Japan",
      "pdf_url": "http://arxiv.org/pdf/2412.03267v1",
      "published_date": "2024-12-04 12:18:21 UTC",
      "updated_date": "2024-12-04 12:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:47:06.590071"
    },
    {
      "arxiv_id": "2412.03248v1",
      "title": "AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning",
      "title_zh": "AIM：通过令牌合并和剪枝的多模态 LLMs 自适应推理",
      "authors": [
        "Yiwu Zhong",
        "Zhuoming Liu",
        "Yin Li",
        "Liwei Wang"
      ],
      "abstract": "Large language models (LLMs) have enabled the creation of multi-modal LLMs\nthat exhibit strong comprehension of visual data such as images and videos.\nHowever, these models usually rely on extensive visual tokens from visual\nencoders, leading to high computational demands, which limits their\napplicability in resource-constrained environments and for long-context tasks.\nIn this work, we propose a training-free adaptive inference method for\nmulti-modal LLMs that can accommodate a broad range of efficiency requirements\nwith a minimum performance drop. Our method consists of a) iterative token\nmerging based on embedding similarity before LLMs, and b) progressive token\npruning within LLM layers based on multi-modal importance. With a minimalist\ndesign, our method can be applied to both video and image LLMs. Extensive\nexperiments on diverse video and image benchmarks demonstrate that, our method\nsubstantially reduces computation load (e.g., a $\\textbf{7-fold}$ reduction in\nFLOPs) while preserving the performance of video and image LLMs. Further, under\na similar computational cost, our method outperforms the state-of-the-art\nmethods in long video understanding (e.g., $\\textbf{+4.6}$ on MLVU).\nAdditionally, our in-depth analysis provides insights into token redundancy and\nLLM layer behaviors, offering guidance for future research in designing\nefficient multi-modal LLMs. Our code will be available at\nhttps://github.com/LaVi-Lab/AIM.",
      "tldr_zh": "这篇论文提出了 AIM，一种无需训练的自适应推理方法，用于多模态 LLMs，通过 token merging 和 token pruning 来减少视觉 tokens 的计算开销，适用于资源受限环境。方法包括基于嵌入相似度的迭代 token merging（在 LLMs 前）和基于多模态重要性的渐进 token pruning（在 LLM 层内），可应用于视频和图像任务。实验结果显示，AIM 显著降低计算负载（如 FLOPs 减少 7 倍），同时保持模型性能，并在长视频理解benchmark上（如 MLVU）比现有方法提升 4.6 分，提供对 token 冗余和 LLM 层行为的宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03248v1",
      "published_date": "2024-12-04 11:47:57 UTC",
      "updated_date": "2024-12-04 11:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:47:20.203982"
    },
    {
      "arxiv_id": "2412.03235v2",
      "title": "Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?",
      "title_zh": "翻译失败",
      "authors": [
        "Sravanti Addepalli",
        "Yerram Varun",
        "Arun Suggala",
        "Karthikeyan Shanmugam",
        "Prateek Jain"
      ],
      "abstract": "Large Language Models (LLMs) are known to be susceptible to crafted\nadversarial attacks or jailbreaks that lead to the generation of objectionable\ncontent despite being aligned to human preferences using safety fine-tuning\nmethods. While the large dimensionality of input token space makes it\ninevitable to find adversarial prompts that can jailbreak these models, we aim\nto evaluate whether safety fine-tuned LLMs are safe against natural prompts\nwhich are semantically related to toxic seed prompts that elicit safe responses\nafter alignment. We surprisingly find that popular aligned LLMs such as GPT-4\ncan be compromised using naive prompts that are NOT even crafted with an\nobjective of jailbreaking the model. Furthermore, we empirically show that\ngiven a seed prompt that elicits a toxic response from an unaligned model, one\ncan systematically generate several semantically related natural prompts that\ncan jailbreak aligned LLMs. Towards this, we propose a method of Response\nGuided Question Augmentation (ReG-QA) to evaluate the generalization of safety\naligned LLMs to natural prompts, that first generates several toxic answers\ngiven a seed question using an unaligned LLM (Q to A), and further leverages an\nLLM to generate questions that are likely to produce these answers (A to Q). We\ninterestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to\nproducing natural jailbreak questions from unsafe content (without denial) and\ncan thus be used for the latter (A to Q) step. We obtain attack success rates\nthat are comparable to/ better than leading adversarial attack methods on the\nJailbreakBench leaderboard, while being significantly more stable against\ndefenses such as Smooth-LLM and Synonym Substitution, which are effective\nagainst existing all attacks on the leaderboard.",
      "tldr_zh": "本研究评估了大语言模型 (LLMs) 的安全微调是否能泛化到与毒性种子提示语义相关的自然提示，发现如 GPT-4 这样的模型容易被简单、非针对性的自然提示攻破，导致生成不良内容。研究提出 Response Guided Question Augmentation (ReG-QA) 方法，利用未对齐的 LLM 先生成毒性答案，然后创建可能产生这些答案的语义相关问题，从而系统性地测试安全微调模型的漏洞。在 JailbreakBench 基准测试中，ReG-QA 取得了与领先 adversarial attack 方法相当或更好的攻击成功率，且对防御如 Smooth-LLM 和 Synonym Substitution 的稳定性更强。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03235v2",
      "published_date": "2024-12-04 11:36:37 UTC",
      "updated_date": "2025-03-25 12:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:47:31.797961"
    },
    {
      "arxiv_id": "2412.03213v1",
      "title": "ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Guangda Liu",
        "Chengwei Li",
        "Jieru Zhao",
        "Chenqi Zhang",
        "Minyi Guo"
      ],
      "abstract": "Large Language Models (LLMs) have been widely deployed in a variety of\napplications, and the context length is rapidly increasing to handle tasks such\nas long-document QA and complex logical reasoning. However, long context poses\nsignificant challenges for inference efficiency, including high memory costs of\nkey-value (KV) cache and increased latency due to extensive memory accesses.\nRecent works have proposed compressing KV cache to approximate computation, but\nthese methods either evict tokens permanently, never recalling them for later\ninference, or recall previous tokens at the granularity of pages divided by\ntextual positions. Both approaches degrade the model accuracy and output\nquality. To achieve efficient and accurate recallable KV cache compression, we\nintroduce ClusterKV, which recalls tokens at the granularity of semantic\nclusters. We design and implement efficient algorithms and systems for\nclustering, selection, indexing and caching. Experiment results show that\nClusterKV attains negligible accuracy loss across various tasks with 32k\ncontext lengths, using only a 1k to 2k KV cache budget, and achieves up to a\n2$\\times$ speedup in latency and a 2.5$\\times$ improvement in decoding\nthroughput. Compared to SoTA recallable KV compression methods, ClusterKV\ndemonstrates higher model accuracy and output quality, while maintaining or\nexceeding inference efficiency.",
      "tldr_zh": "这篇论文提出了ClusterKV，一种创新框架，用于在语义空间中操作LLM的KV cache，实现可召回的压缩，以解决长上下文处理中的高内存成本和延迟问题。该方法通过语义聚类、选择、索引和缓存的算法，允许按语义群组召回tokens，而不是永久删除或按文本位置分块，从而显著提升模型准确性和输出质量。实验结果显示，在32k上下文长度下，ClusterKV仅需1k-2k KV缓存预算，即可实现几乎无准确性损失、延迟减少2倍以及解码吞吐量提高2.5倍，并优于现有状态-of-the-art方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03213v1",
      "published_date": "2024-12-04 10:58:27 UTC",
      "updated_date": "2024-12-04 10:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:47:43.912355"
    },
    {
      "arxiv_id": "2412.03205v3",
      "title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantin Chernyshev",
        "Vitaliy Polshkov",
        "Ekaterina Artemova",
        "Alex Myasnikov",
        "Vlad Stepanov",
        "Alexei Miasnikov",
        "Sergei Tilga"
      ],
      "abstract": "The current evaluation of mathematical skills in LLMs is limited, as existing\nbenchmarks are either relatively small, primarily focus on elementary and\nhigh-school problems, or lack diversity in topics. Additionally, the inclusion\nof visual elements in tasks remains largely under-explored.\n  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100\nunpublished open-ended university-level problems sourced from teaching\nmaterials. It is balanced across six core subjects, with 20% of multimodal\nproblems. Given the open-ended nature of U-MATH problems, we employ an LLM to\njudge the correctness of generated solutions. To this end, we release\n$\\mu$-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.\n  The evaluation of general domain, math-specific, and multimodal LLMs\nhighlights the challenges presented by U-MATH. Our findings reveal that LLMs\nachieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%\non visual problems. The solution assessment proves challenging for LLMs, with\nthe best LLM judge having an F1-score of 80% on $\\mu$-MATH.",
      "tldr_zh": "该研究指出，现有的LLMs数学技能评估基准存在规模小、主要针对基础高中水平、主题多样性不足以及视觉元素缺乏等问题。为此，引入U-MATH，一个包含1100个未发表的开放式大学级问题的基准，覆盖六大核心科目，其中20%为多模态问题，并发布μ-MATH数据集用于评估LLMs判断解决方案的能力。实验结果显示，LLMs在U-MATH文本任务上的最高准确率仅为63%，在视觉问题上降至45%，而最佳LLM判断器的F1-score为80%，突显了LLMs在高级数学任务中的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03205v3",
      "published_date": "2024-12-04 10:44:50 UTC",
      "updated_date": "2025-01-14 21:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:47:55.802030"
    },
    {
      "arxiv_id": "2412.03188v1",
      "title": "Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Kralj",
        "Lodovico Giaretta",
        "Gordan Ježić",
        "Ivana Podnar Žarko",
        "Šarūnas Girdzijauskas"
      ],
      "abstract": "In smart mobility, large networks of geographically distributed sensors\nproduce vast amounts of high-frequency spatio-temporal data that must be\nprocessed in real time to avoid major disruptions. Traditional centralized\napproaches are increasingly unsuitable to this task, as they struggle to scale\nwith expanding sensor networks, and reliability issues in central components\ncan easily affect the whole deployment. To address these challenges, we explore\nand adapt semi-decentralized training techniques for Spatio-Temporal Graph\nNeural Networks (ST-GNNs) in smart mobility domain. We implement a simulation\nframework where sensors are grouped by proximity into multiple cloudlets, each\nhandling a subgraph of the traffic graph, fetching node features from other\ncloudlets to train its own local ST-GNN model, and exchanging model updates\nwith other cloudlets to ensure consistency, enhancing scalability and removing\nreliance on a centralized aggregator. We perform extensive comparative\nevaluation of four different ST-GNN training setups -- centralized, traditional\nFL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the\nMETR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed\npredictions. Experimental results show that semi-decentralized setups are\ncomparable to centralized approaches in performance metrics, while offering\nadvantages in terms of scalability and fault tolerance. In addition, we\nhighlight often overlooked issues in existing literature for distributed\nST-GNNs, such as the variation in model performance across different\ngeographical areas due to region-specific traffic patterns, and the significant\ncommunication overhead and computational costs that arise from the large\nreceptive field of GNNs, leading to substantial data transfers and increased\ncomputation of partial embeddings.",
      "tldr_zh": "本论文探讨了在智能交通领域使用半去中心化训练技术来训练Spatio-Temporal Graph Neural Networks (ST-GNNs)，以处理大规模传感器数据的实时交通预测问题。方法通过将传感器按地理 proximity 分组到多个 cloudlets，每个 cloudlets 处理本地交通图子图、获取节点特征并交换模型更新，从而提升系统可扩展性和容错性。在 METR-LA 和 PeMS-BAY 数据集上的实验比较了集中式、传统 Federated Learning (FL)、server-free FL 和 Gossip Learning 等四种设置，结果显示半去中心化方法在短期、中期和长期车辆速度预测的性能指标上与集中式方法相当，同时显著降低了通信开销和计算成本。该研究还强调了分布式 ST-GNNs 中存在的区域性能差异和通信开销问题，为未来优化提供洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, 3 tables, conference",
      "pdf_url": "http://arxiv.org/pdf/2412.03188v1",
      "published_date": "2024-12-04 10:20:21 UTC",
      "updated_date": "2024-12-04 10:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:48:10.275625"
    },
    {
      "arxiv_id": "2412.03179v1",
      "title": "Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization",
      "title_zh": "通过多任务一致性和优先化优化密集视觉预测",
      "authors": [
        "Maxime Fontana",
        "Michael Spratling",
        "Miaojing Shi"
      ],
      "abstract": "Multi-Task Learning (MTL) involves the concurrent training of multiple tasks,\noffering notable advantages for dense prediction tasks in computer vision. MTL\nnot only reduces training and inference time as opposed to having multiple\nsingle-task models, but also enhances task accuracy through the interaction of\nmultiple tasks. However, existing methods face limitations. They often rely on\nsuboptimal cross-task interactions, resulting in task-specific predictions with\npoor geometric and predictive coherence. In addition, many approaches use\ninadequate loss weighting strategies, which do not address the inherent\nvariability in task evolution during training. To overcome these challenges, we\npropose an advanced MTL model specifically designed for dense vision tasks. Our\nmodel leverages state-of-the-art vision transformers with task-specific\ndecoders. To enhance cross-task coherence, we introduce a trace-back method\nthat improves both cross-task geometric and predictive features. Furthermore,\nwe present a novel dynamic task balancing approach that projects task losses\nonto a common scale and prioritizes more challenging tasks during training.\nExtensive experiments demonstrate the superiority of our method, establishing\nnew state-of-the-art performance across two benchmark datasets. The code is\navailable at:https://github.com/Klodivio355/MT-CP",
      "tldr_zh": "本论文针对多任务学习 (MTL) 在密集视觉预测任务中的问题，提出了一种优化框架，以提升跨任务的几何和预测一致性。方法包括使用 state-of-the-art vision transformers 结合任务特定解码器，并引入 trace-back 方法来改善跨任务特征交互，同时采用动态任务平衡策略，将任务损失投影到统一尺度并优先处理更具挑战性的任务。实验结果显示，该方法在两个基准数据集上实现了新的 state-of-the-art 性能，代码可从指定仓库获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03179v1",
      "published_date": "2024-12-04 10:05:47 UTC",
      "updated_date": "2024-12-04 10:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:48:19.722151"
    },
    {
      "arxiv_id": "2412.03178v1",
      "title": "Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Gianni Franchi",
        "Dat Nguyen Trong",
        "Nacim Belkhir",
        "Guoxuan Xia",
        "Andrea Pilzer"
      ],
      "abstract": "Uncertainty quantification in text-to-image (T2I) generative models is\ncrucial for understanding model behavior and improving output reliability. In\nthis paper, we are the first to quantify and evaluate the uncertainty of T2I\nmodels with respect to the prompt. Alongside adapting existing approaches\ndesigned to measure uncertainty in the image space, we also introduce\nPrompt-based UNCertainty Estimation for T2I models (PUNC), a novel method\nleveraging Large Vision-Language Models (LVLMs) to better address uncertainties\narising from the semantics of the prompt and generated images. PUNC utilizes a\nLVLM to caption a generated image, and then compares the caption with the\noriginal prompt in the more semantically meaningful text space. PUNC also\nenables the disentanglement of both aleatoric and epistemic uncertainties via\nprecision and recall, which image-space approaches are unable to do. Extensive\nexperiments demonstrate that PUNC outperforms state-of-the-art uncertainty\nestimation techniques across various settings. Uncertainty quantification in\ntext-to-image generation models can be used on various applications including\nbias detection, copyright protection, and OOD detection. We also introduce a\ncomprehensive dataset of text prompts and generation pairs to foster further\nresearch in uncertainty quantification for generative models. Our findings\nillustrate that PUNC not only achieves competitive performance but also enables\nnovel applications in evaluating and improving the trustworthiness of\ntext-to-image models.",
      "tldr_zh": "本论文探讨了文本到图像 (T2I) 生成模型的不确定性量化问题，以提升模型行为理解和输出可靠性。研究首次引入 PUNC（Prompt-based UNCertainty Estimation for T2I models），一种利用 Large Vision-Language Models (LVLMs) 的新方法，通过为生成图像生成标题并与原提示在文本空间比较，来评估提示语义相关的不确定性。PUNC 能够分离 aleatoric 和 epistemic uncertainties，并通过 precision 和 recall 指标实现图像空间方法无法做到的解耦。实验结果显示，PUNC 在多种设置下优于现有最先进技术，并支持应用如偏差检测、版权保护和 OOD detection；此外，论文还发布了一个全面的文本提示和生成对数据集，以推动该领域的研究。总体而言，此方法提高了 T2I 模型的可信度，并为未来改进提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages and 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03178v1",
      "published_date": "2024-12-04 10:03:52 UTC",
      "updated_date": "2024-12-04 10:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:48:35.754218"
    },
    {
      "arxiv_id": "2412.03161v2",
      "title": "Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems",
      "title_zh": "基于物理信息的深度逆算子网络用于求解",
      "authors": [
        "Sung Woong Cho",
        "Hwijae Son"
      ],
      "abstract": "Inverse problems involving partial differential equations (PDEs) can be seen\nas discovering a mapping from measurement data to unknown quantities, often\nframed within an operator learning approach. However, existing methods\ntypically rely on large amounts of labeled training data, which is impractical\nfor most real-world applications. Moreover, these supervised models may fail to\ncapture the underlying physical principles accurately. To address these\nlimitations, we propose a novel architecture called Physics-Informed Deep\nInverse Operator Networks (PI-DIONs), which can learn the solution operator of\nPDE-based inverse problems without labeled training data. We extend the\nstability estimates established in the inverse problem literature to the\noperator learning framework, thereby providing a robust theoretical foundation\nfor our method. These estimates guarantee that the proposed model, trained on a\nfinite sample and grid, generalizes effectively across the entire domain and\nfunction space. Extensive experiments are conducted to demonstrate that\nPI-DIONs can effectively and accurately learn the solution operators of the\ninverse problems without the need for labeled data.",
      "tldr_zh": "该论文针对偏微分方程（PDE）逆问题的挑战，提出了一种名为 Physics-Informed Deep Inverse Operator Networks (PI-DIONs) 的新架构，该方法无需标注训练数据即可学习逆问题的解算子。PI-DIONs 通过整合物理信息和稳定性估计扩展到算子学习框架，提供理论基础，确保模型在有限样本和网格上训练后能泛化到整个域和函数空间。主要实验结果显示，该方法在多种逆问题上表现出色，准确有效地学习解算子，从而解决了现有方法的局限。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "65M32, 68T99",
        "G.1.8; G.1.10"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03161v2",
      "published_date": "2024-12-04 09:38:58 UTC",
      "updated_date": "2025-02-07 09:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:48:45.921691"
    },
    {
      "arxiv_id": "2412.03154v1",
      "title": "Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples",
      "title_zh": "翻译失败",
      "authors": [
        "Xingjian Zhou",
        "Hongji Xu",
        "Andy Xu",
        "Zhouxing Shi",
        "Cho-Jui Hsieh",
        "Huan Zhang"
      ],
      "abstract": "In recent years, many neural network (NN) verifiers have been developed to\nformally verify certain properties of neural networks such as robustness.\nAlthough many benchmarks have been constructed to evaluate the performance of\nNN verifiers, they typically lack a ground-truth for hard instances where no\ncurrent verifier can verify and no counterexample can be found, which makes it\ndifficult to check the soundness of a new verifier if it claims to verify hard\ninstances which no other verifier can do. We propose to develop a soundness\nbenchmark for NN verification. Our benchmark contains instances with\ndeliberately inserted counterexamples while we also try to hide the\ncounterexamples from regular adversarial attacks which can be used for finding\ncounterexamples. We design a training method to produce neural networks with\nsuch hidden counterexamples. Our benchmark aims to be used for testing the\nsoundness of NN verifiers and identifying falsely claimed verifiability when it\nis known that hidden counterexamples exist. We systematically construct our\nbenchmark and generate instances across diverse model architectures, activation\nfunctions, input sizes, and perturbation radii. We demonstrate that our\nbenchmark successfully identifies bugs in state-of-the-art NN verifiers, as\nwell as synthetic bugs, providing a crucial step toward enhancing the\nreliability of testing NN verifiers. Our code is available at\nhttps://github.com/MVP-Harry/SoundnessBench and our benchmark is available at\nhttps://huggingface.co/datasets/SoundnessBench/SoundnessBench.",
      "tldr_zh": "该论文提出一个名为 Soundness Benchmark 的测试框架，用于评估神经网络 (NN) 验证器的正确性 (soundness)，通过在基准中故意插入隐藏 counterexamples 来解决现有基准缺乏真实性验证的问题。这些 counterexamples 设计得能避开常规对抗攻击，并通过一种专门的训练方法生成 NN 实例，覆盖多种模型架构、激活函数、输入大小和扰动半径。实验结果表明，该基准成功识别了现有 NN 验证器中的 bug，包括合成错误，从而提升了 NN 验证器的可靠性和测试质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2412.03154v1",
      "published_date": "2024-12-04 09:24:33 UTC",
      "updated_date": "2024-12-04 09:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:48:58.009604"
    },
    {
      "arxiv_id": "2412.03152v2",
      "title": "A Measure of the System Dependence of Automated Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Pius von Däniken",
        "Jan Deriu",
        "Mark Cieliebak"
      ],
      "abstract": "Automated metrics for Machine Translation have made significant progress,\nwith the goal of replacing expensive and time-consuming human evaluations.\nThese metrics are typically assessed by their correlation with human judgments,\nwhich captures the monotonic relationship between human and metric scores.\nHowever, we argue that it is equally important to ensure that metrics treat all\nsystems fairly and consistently. In this paper, we introduce a method to\nevaluate this aspect.",
      "tldr_zh": "该论文讨论了机器翻译(Automated Metrics)的自动化指标进展，这些指标旨在取代昂贵的人工评估，但目前主要通过与人工判断的相关性来衡量，从而捕捉分数之间的单调关系。作者指出，确保这些指标公平一致地对待所有系统同样重要，以避免系统依赖性问题。为此，论文引入了一种新方法来评估指标的系统依赖性，从而提升指标的可靠性和通用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03152v2",
      "published_date": "2024-12-04 09:21:46 UTC",
      "updated_date": "2024-12-28 17:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:49:08.769908"
    },
    {
      "arxiv_id": "2412.03151v1",
      "title": "Large Language Models show both individual and collective creativity comparable to humans",
      "title_zh": "大语言模型展现出与人类相当的个体和集体创造力",
      "authors": [
        "Luning Sun",
        "Yuzhuo Yuan",
        "Yuan Yao",
        "Yanyan Li",
        "Hao Zhang",
        "Xing Xie",
        "Xiting Wang",
        "Fang Luo",
        "David Stillwell"
      ],
      "abstract": "Artificial intelligence has, so far, largely automated routine tasks, but\nwhat does it mean for the future of work if Large Language Models (LLMs) show\ncreativity comparable to humans? To measure the creativity of LLMs\nholistically, the current study uses 13 creative tasks spanning three domains.\nWe benchmark the LLMs against individual humans, and also take a novel approach\nby comparing them to the collective creativity of groups of humans. We find\nthat the best LLMs (Claude and GPT-4) rank in the 52nd percentile against\nhumans, and overall LLMs excel in divergent thinking and problem solving but\nlag in creative writing. When questioned 10 times, an LLM's collective\ncreativity is equivalent to 8-10 humans. When more responses are requested, two\nadditional responses of LLMs equal one extra human. Ultimately, LLMs, when\noptimally applied, may compete with a small group of humans in the future of\nwork.",
      "tldr_zh": "这项研究评估了大型语言模型（LLMs）在创意方面的表现，使用13个跨三个领域的创意任务，与个体人类和人类群体进行比较。结果显示，最优秀的LLMs（如Claude和GPT-4）在人类中排名第52百分位，在发散思维和问题解决上表现出色，但创意写作方面落后。当LLMs被多次查询时，其集体创意相当于8-10个人类，而额外响应可进一步提升其等效性。总体而言，该研究表明LLMs在最佳应用下，可能在未来工作中与小型人类群体竞争。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03151v1",
      "published_date": "2024-12-04 09:18:54 UTC",
      "updated_date": "2024-12-04 09:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:49:22.072308"
    },
    {
      "arxiv_id": "2412.03148v1",
      "title": "Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Li",
        "Chenwei Dai",
        "Wei Zhou",
        "Songlin Hu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nrole-playing tasks. However, there is limited research on whether LLMs can\naccurately simulate user behavior in real-world scenarios, such as social\nmedia. This requires models to effectively analyze a user's history and\nsimulate their role. In this paper, we introduce \\textbf{FineRob}, a novel\nfine-grained behavior simulation dataset. We collect the complete behavioral\nhistory of 1,866 distinct users across three social media platforms. Each\nbehavior is decomposed into three fine-grained elements: object, type, and\ncontent, resulting in 78.6k QA records. Based on FineRob, we identify two\ndominant reasoning patterns in LLMs' behavior simulation processes and propose\nthe \\textbf{OM-CoT} fine-tuning method to enhance the capability. Through\ncomprehensive experiments, we conduct an in-depth analysis of key factors of\nbehavior simulation and also demonstrate the effectiveness of OM-CoT\napproach\\footnote{Code and dataset are available at\n\\url{https://github.com/linkseed18612254945/FineRob}}",
      "tldr_zh": "本文探讨大型语言模型(LLMs)在社交媒体上模拟用户行为的准确性，特别关注基于用户历史数据的角色扮演任务。研究引入了FineRob数据集，收集了1,866个用户在三个平台的完整行为历史，总计78.6k QA记录，每个行为细分为object、type和content三个元素。基于FineRob，作者识别了LLMs行为模拟中的两种主要推理模式，并提出OM-CoT细调方法来增强模型的模拟能力。通过全面实验，证明OM-CoT显著提高了模拟性能，并分析了关键影响因素。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03148v1",
      "published_date": "2024-12-04 09:14:56 UTC",
      "updated_date": "2024-12-04 09:14:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:51:26.300928"
    },
    {
      "arxiv_id": "2412.03123v1",
      "title": "Robust Multi-bit Text Watermark with LLM-based Paraphrasers",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojun Xu",
        "Jinghan Jia",
        "Yuanshun Yao",
        "Yang Liu",
        "Hang Li"
      ],
      "abstract": "We propose an imperceptible multi-bit text watermark embedded by paraphrasing\nwith LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave\ndifferently so that their paraphrasing difference reflected in the text\nsemantics can be identified by a trained decoder. To embed our multi-bit\nwatermark, we use two paraphrasers alternatively to encode the pre-defined\nbinary code at the sentence level. Then we use a text classifier as the decoder\nto decode each bit of the watermark. Through extensive experiments, we show\nthat our watermarks can achieve over 99.99\\% detection AUC with small (1.1B)\ntext paraphrasers while keeping the semantic information of the original\nsentence. More importantly, our pipeline is robust under word substitution and\nsentence paraphrasing perturbations and generalizes well to\nout-of-distributional data. We also show the stealthiness of our watermark with\nLLM-based evaluation. We open-source the code:\nhttps://github.com/xiaojunxu/multi-bit-text-watermark.",
      "tldr_zh": "本论文提出了一种基于LLM的鲁棒多位文本水印方法，通过微调一对行为不同的LLM paraphrasers，在句子级别交替嵌入预定义二进制代码，并使用文本分类器作为解码器来识别水印位。实验结果显示，该方法在小型（1.1B）文本改写器上实现了超过99.99%的检测AUC，同时保留了原句语义。更为重要的是，该水印对词替换和句子改写等干扰具有高度鲁棒性，并对分布外数据具有良好的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03123v1",
      "published_date": "2024-12-04 08:43:12 UTC",
      "updated_date": "2024-12-04 08:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:49:46.786644"
    },
    {
      "arxiv_id": "2412.03111v1",
      "title": "Experience-driven discovery of planning strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi He",
        "Falk Lieder"
      ],
      "abstract": "One explanation for how people can plan efficiently despite limited cognitive\nresources is that we possess a set of adaptive planning strategies and know\nwhen and how to use them. But how are these strategies acquired? While previous\nresearch has studied how individuals learn to choose among existing strategies,\nlittle is known about the process of forming new planning strategies. In this\nwork, we propose that new planning strategies are discovered through\nmetacognitive reinforcement learning. To test this, we designed a novel\nexperiment to investigate the discovery of new planning strategies. We then\npresent metacognitive reinforcement learning models and demonstrate their\ncapability for strategy discovery as well as show that they provide a better\nexplanation of human strategy discovery than alternative learning mechanisms.\nHowever, when fitted to human data, these models exhibit a slower discovery\nrate than humans, leaving room for improvement.",
      "tldr_zh": "本研究探讨人们如何在有限认知资源下高效规划，提出新规划策略是通过元认知强化学习(metacognitive reinforcement learning)来发现的。研究者设计了一个新实验，并开发了相关模型，展示了这些模型在策略发现中的能力，并证明它们比其他学习机制更能解释人类行为。然而，当拟合人类数据时，模型的策略发现率比人类更慢，留有进一步改进的空间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03111v1",
      "published_date": "2024-12-04 08:20:03 UTC",
      "updated_date": "2024-12-04 08:20:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:49:57.122805"
    },
    {
      "arxiv_id": "2412.03107v1",
      "title": "CredID: Credible Multi-Bit Watermark for Large Language Models Identification",
      "title_zh": "CredID: 可信的多位水印用于大型语言模型识别",
      "authors": [
        "Haoyu Jiang",
        "Xuhong Wang",
        "Ping Yi",
        "Shanzhe Lei",
        "Yilun Lin"
      ],
      "abstract": "Large Language Models (LLMs) are widely used in complex natural language\nprocessing tasks but raise privacy and security concerns due to the lack of\nidentity recognition. This paper proposes a multi-party credible watermarking\nframework (CredID) involving a trusted third party (TTP) and multiple LLM\nvendors to address these issues. In the watermark embedding stage, vendors\nrequest a seed from the TTP to generate watermarked text without sending the\nuser's prompt. In the extraction stage, the TTP coordinates each vendor to\nextract and verify the watermark from the text. This provides a credible\nwatermarking scheme while preserving vendor privacy. Furthermore, current\nwatermarking algorithms struggle with text quality, information capacity, and\nrobustness, making it challenging to meet the diverse identification needs of\nLLMs. Thus, we propose a novel multi-bit watermarking algorithm and an\nopen-source toolkit to facilitate research. Experiments show our CredID\nenhances watermark credibility and efficiency without compromising text\nquality. Additionally, we successfully utilized this framework to achieve\nhighly accurate identification among multiple LLM vendors.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 的隐私和安全问题，提出了 CredID 框架，该框架涉及可信第三方 (TTP) 和多个 LLM 供应商，实现多方协作的水印嵌入和提取过程。\n在水印嵌入阶段，供应商从 TTP 获取种子生成水印文本，而不需发送用户提示；在提取阶段，TTP 协调验证水印，以确保可信度并保护供应商隐私。\n此外，论文引入了一种新颖的多-bit 水印算法和开源工具，以提升水印的信息容量和鲁棒性。\n实验证明，CredID 显著提高了水印的可信度和效率，同时保持文本质量，并在多个 LLM 供应商间实现了高精度识别。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "v1",
      "pdf_url": "http://arxiv.org/pdf/2412.03107v1",
      "published_date": "2024-12-04 08:13:29 UTC",
      "updated_date": "2024-12-04 08:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:50:11.013887"
    },
    {
      "arxiv_id": "2412.03104v3",
      "title": "ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Xie",
        "Zeyan Li",
        "Xiao He",
        "Longlong Xu",
        "Xidao Wen",
        "Tieying Zhang",
        "Jianjun Chen",
        "Rui Shi",
        "Dan Pei"
      ],
      "abstract": "Understanding time series is crucial for its application in real-world\nscenarios. Recently, large language models (LLMs) have been increasingly\napplied to time series tasks, leveraging their strong language capabilities to\nenhance various applications. However, research on multimodal LLMs (MLLMs) for\ntime series understanding and reasoning remains limited, primarily due to the\nscarcity of high-quality datasets that align time series with textual\ninformation. This paper introduces ChatTS, a novel MLLM designed for time\nseries analysis. ChatTS treats time series as a modality, similar to how vision\nMLLMs process images, enabling it to perform both understanding and reasoning\nwith time series. To address the scarcity of training data, we propose an\nattribute-based method for generating synthetic time series with detailed\nattribute descriptions. We further introduce Time Series Evol-Instruct, a novel\napproach that generates diverse time series Q&As, enhancing the model's\nreasoning capabilities. To the best of our knowledge, ChatTS is the first\nTS-MLLM that takes multivariate time series as input for understanding and\nreasoning, which is fine-tuned exclusively on synthetic datasets. We evaluate\nits performance using benchmark datasets with real-world data, including six\nalignment tasks and four reasoning tasks. Our results show that ChatTS\nsignificantly outperforms existing vision-based MLLMs (e.g., GPT-4o) and\ntext/agent-based LLMs, achieving a 46.0% improvement in alignment tasks and a\n25.8% improvement in reasoning tasks. We have open-sourced the source code,\nmodel checkpoint and datasets at https://github.com/NetManAIOps/ChatTS.",
      "tldr_zh": "该论文提出ChatTS，一种新型多模态LLM（MLLMs），旨在通过合成数据提升时间序列（time series）的理解和推理能力，以解决高质量数据集稀缺的问题。ChatTS将时间序列视为一种模态，并引入基于属性的合成时间序列生成方法以及Time Series Evol-Instruct策略，来创建多样化的时间序列Q&A数据集，从而增强模型的推理功能。作为首个以多变量时间序列为输入的TS-MLLM，ChatTS仅在合成数据集上微调，并在真实基准测试中表现出色，比现有视觉-based MLLMs（如GPT-4o）和文本/代理-based LLMs 在对齐任务提升46.0%、在推理任务提升25.8%。作者已开源代码、模型和数据集。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by VLDB' 25",
      "pdf_url": "http://arxiv.org/pdf/2412.03104v3",
      "published_date": "2024-12-04 08:06:15 UTC",
      "updated_date": "2025-04-16 10:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:50:23.474005"
    },
    {
      "arxiv_id": "2412.03092v1",
      "title": "Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyan Zhang",
        "Haibo Jin",
        "Leyang Hu",
        "Xinnuo Li",
        "Liying Kang",
        "Man Luo",
        "Yangqiu Song",
        "Haohan Wang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced the ability of LLM-based systems to perform complex tasks through\nnatural language processing and tool interaction. However, optimizing these\nLLM-based systems for specific tasks remains challenging, often requiring\nmanual interventions like prompt engineering and hyperparameter tuning.\nExisting automatic optimization methods, such as textual feedback-based\ntechniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to\nusing immediate derivatives in traditional numerical gradient descent. However,\nrelying solely on such feedback can be limited when the adjustments made in\nresponse to this feedback are either too small or fluctuate irregularly,\npotentially slowing down or even stalling the optimization process. To overcome\nthese challenges, more adaptive methods are needed, especially in situations\nwhere the system's response is evolving slowly or unpredictably. In this paper,\nwe introduce REVOLVE, an optimization method that tracks how \"R\"esponses\n\"EVOLVE\" across iterations in LLM systems. By focusing on the evolution of\nresponses over time, REVOLVE enables more stable and effective optimization by\nmaking thoughtful, progressive adjustments at each step. Experimental results\ndemonstrate that REVOLVE outperforms competitive baselines, achieving a 7.8%\nimprovement in prompt optimization, a 20.72% gain in solution refinement, and a\n29.17% increase in code optimization. Additionally, REVOLVE converges in fewer\niterations, resulting in significant computational savings. These advantages\nhighlight its adaptability and efficiency, positioning REVOLVE as a valuable\ntool for optimizing LLM-based systems and accelerating the development of\nnext-generation AI technologies. Code is available at:\nhttps://github.com/Peiyance/REVOLVE.",
      "tldr_zh": "该论文提出 REVOLVE 方法，通过跟踪大型语言模型 (LLMs) 系统响应在迭代中的演变，来优化 AI 系统，解决现有基于即时反馈的技术（如 TextGrad）可能导致的优化缓慢或不稳定问题。REVOLVE 关注响应的渐进调整，实现更稳定的文本优化过程。实验结果显示，该方法在提示优化上提升 7.8%、解决方案精炼上提升 20.72%、代码优化上提升 29.17%，并在更少迭代中收敛，显著节省计算资源。这些优势使 REVOLVE 成为优化 LLM-based 系统的有效工具，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.8"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.03092v1",
      "published_date": "2024-12-04 07:44:35 UTC",
      "updated_date": "2024-12-04 07:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:51:39.930121"
    },
    {
      "arxiv_id": "2412.03076v2",
      "title": "Coordinated Multi-Armed Bandits for Improved Spatial Reuse in Wi-Fi",
      "title_zh": "翻译失败",
      "authors": [
        "Francesc Wilhelmi",
        "Boris Bellalta",
        "Szymon Szott",
        "Katarzyna Kosek-Szott",
        "Sergio Barrachina-Muñoz"
      ],
      "abstract": "Multi-Access Point Coordination (MAPC) and Artificial Intelligence and\nMachine Learning (AI/ML) are expected to be key features in future Wi-Fi, such\nas the forthcoming IEEE 802.11bn (Wi-Fi~8) and beyond. In this paper, we\nexplore a coordinated solution based on online learning to drive the\noptimization of Spatial Reuse (SR), a method that allows multiple devices to\nperform simultaneous transmissions by controlling interference through Packet\nDetect (PD) adjustment and transmit power control. In particular, we focus on a\nMulti-Agent Multi-Armed Bandit (MA-MAB) setting, where multiple decision-making\nagents concurrently configure SR parameters from coexisting networks by\nleveraging the MAPC framework, and study various algorithms and reward-sharing\nmechanisms. We evaluate different MA-MAB implementations using Komondor, a\nwell-adopted Wi-Fi simulator, and demonstrate that AI-native SR enabled by\ncoordinated MABs can improve the network performance over current Wi-Fi\noperation: mean throughput increases by 15%, fairness is improved by increasing\nthe minimum throughput across the network by 210%, while the maximum access\ndelay is kept below 3 ms.",
      "tldr_zh": "该论文提出了一种基于 Multi-Agent Multi-Armed Bandit (MA-MAB) 的协调解决方案，用于优化 Wi-Fi 中的 Spatial Reuse (SR)，以通过调整 Packet Detect (PD) 和发射功率控制干扰，实现多个设备的同时传输。方法利用 Multi-Access Point Coordination (MAPC) 框架和在线学习技术，让多个代理协同配置 SR 参数，并研究各种算法及奖励共享机制。实验在 Komondor 模拟器上显示，该方案相对于当前 Wi-Fi 操作，平均吞吐量提高了 15%，网络公平性显著提升（最小吞吐量增加 210%），同时最大访问延迟保持在 3 ms 以下。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03076v2",
      "published_date": "2024-12-04 06:53:59 UTC",
      "updated_date": "2025-03-05 10:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:51:53.136305"
    },
    {
      "arxiv_id": "2412.03072v1",
      "title": "Preference-based opponent shaping in differentiable games",
      "title_zh": "基于偏好的对手塑造在可微游戏中",
      "authors": [
        "Xinyu Qiao",
        "Yudong Hu",
        "Congying Han",
        "Weiyan Wu",
        "Tiande Guo"
      ],
      "abstract": "Strategy learning in game environments with multi-agent is a challenging\nproblem. Since each agent's reward is determined by the joint strategy, a\ngreedy learning strategy that aims to maximize its own reward may fall into a\nlocal optimum. Recent studies have proposed the opponent modeling and shaping\nmethods for game environments. These methods enhance the efficiency of strategy\nlearning by modeling the strategies and updating processes of other agents.\nHowever, these methods often rely on simple predictions of opponent strategy\nchanges. Due to the lack of modeling behavioral preferences such as cooperation\nand competition, they are usually applicable only to predefined scenarios and\nlack generalization capabilities. In this paper, we propose a novel\nPreference-based Opponent Shaping (PBOS) method to enhance the strategy\nlearning process by shaping agents' preferences towards cooperation. We\nintroduce the preference parameter, which is incorporated into the agent's loss\nfunction, thus allowing the agent to directly consider the opponent's loss\nfunction when updating the strategy. We update the preference parameters\nconcurrently with strategy learning to ensure that agents can adapt to any\ncooperative or competitive game environment. Through a series of experiments,\nwe verify the performance of PBOS algorithm in a variety of differentiable\ngames. The experimental results show that the PBOS algorithm can guide the\nagent to learn the appropriate preference parameters, so as to achieve better\nreward distribution in multiple game environments.",
      "tldr_zh": "本文提出 Preference-based Opponent Shaping (PBOS) 方法，以解决多智能体游戏环境中策略学习面临的挑战，这些挑战源于代理的贪婪学习可能陷入局部最优，且现有对手建模方法缺乏对行为偏好（如合作或竞争）的建模，导致泛化能力不足。PBOS 通过引入偏好参数并将其融入代理的损失函数，使代理在更新策略时直接考虑对手的损失函数，并同时更新偏好参数以适应各种合作或竞争游戏环境。该方法的实验验证显示，在多种可微游戏中，PBOS 能引导代理学习合适的偏好参数，从而实现更优的奖励分布和整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03072v1",
      "published_date": "2024-12-04 06:49:21 UTC",
      "updated_date": "2024-12-04 06:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:53:56.443745"
    },
    {
      "arxiv_id": "2412.03069v1",
      "title": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation",
      "title_zh": "TokenFlow: 统一的图像标记化器用于多模态理解和生成",
      "authors": [
        "Liao Qu",
        "Huichao Zhang",
        "Yiheng Liu",
        "Xu Wang",
        "Yi Jiang",
        "Yiming Gao",
        "Hu Ye",
        "Daniel K. Du",
        "Zehuan Yuan",
        "Xinglong Wu"
      ],
      "abstract": "We present TokenFlow, a novel unified image tokenizer that bridges the\nlong-standing gap between multimodal understanding and generation. Prior\nresearch attempt to employ a single reconstruction-targeted Vector Quantization\n(VQ) encoder for unifying these two tasks. We observe that understanding and\ngeneration require fundamentally different granularities of visual information.\nThis leads to a critical trade-off, particularly compromising performance in\nmultimodal understanding tasks. TokenFlow addresses this challenge through an\ninnovative dual-codebook architecture that decouples semantic and pixel-level\nfeature learning while maintaining their alignment via a shared mapping\nmechanism. This design enables direct access to both high-level semantic\nrepresentations crucial for understanding tasks and fine-grained visual\nfeatures essential for generation through shared indices. Our extensive\nexperiments demonstrate TokenFlow's superiority across multiple dimensions.\nLeveraging TokenFlow, we demonstrate for the first time that discrete visual\ninput can surpass LLaVA-1.5 13B in understanding performance, achieving a 7.2\\%\naverage improvement. For image reconstruction, we achieve a strong FID score of\n0.63 at 384*384 resolution. Moreover, TokenFlow establishes state-of-the-art\nperformance in autoregressive image generation with a GenEval score of 0.55 at\n256*256 resolution, achieving comparable results to SDXL.",
      "tldr_zh": "我们介绍了 TokenFlow，一种新型的统一图像标记器（unified image tokenizer），旨在桥接多模态理解和生成任务的差距，通过创新的双代码本架构（dual-codebook architecture）解耦语义和像素级特征学习，同时利用共享映射机制保持对齐，从而提供高层次语义表示和细粒度视觉特征。相较于以往依赖单一重建导向的 Vector Quantization (VQ) 编码器的方法，TokenFlow 避免了视觉信息粒度的权衡。实验结果显示，TokenFlow 使离散视觉输入首次在理解任务中超越 LLaVA-1.5 13B，平均提升 7.2%；在图像重建中达到 FID score 0.63（384*384 分辨率）；在自回归图像生成中，GenEval score 为 0.55（256*256 分辨率），与 SDXL 相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "https://byteflow-ai.github.io/TokenFlow/",
      "pdf_url": "http://arxiv.org/pdf/2412.03069v1",
      "published_date": "2024-12-04 06:46:55 UTC",
      "updated_date": "2024-12-04 06:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:52:18.478729"
    },
    {
      "arxiv_id": "2412.03068v1",
      "title": "UTSD: Unified Time Series Diffusion Model",
      "title_zh": "UTSD：统一的时序扩散模型",
      "authors": [
        "Xiangkai Ma",
        "Xiaobin Hong",
        "Wenzhong Li",
        "Sanglu Lu"
      ],
      "abstract": "Transformer-based architectures have achieved unprecedented success in time\nseries analysis. However, facing the challenge of across-domain modeling,\nexisting studies utilize statistical prior as prompt engineering fails under\nthe huge distribution shift among various domains. In this paper, a Unified\nTime Series Diffusion (UTSD) model is established for the first time to model\nthe multi-domain probability distribution, utilizing the powerful probability\ndistribution modeling ability of Diffusion. Unlike the autoregressive models\nthat capture the conditional probabilities of the prediction horizon to the\nhistorical sequence, we use a diffusion denoising process to model the mixture\ndistribution of the cross-domain data and generate the prediction sequence for\nthe target domain directly utilizing conditional sampling. The proposed UTSD\ncontains three pivotal designs: (1) The condition network captures the\nmulti-scale fluctuation patterns from the observation sequence, which are\nutilized as context representations to guide the denoising network to generate\nthe prediction sequence; (2) Adapter-based fine-tuning strategy, the\nmulti-domain universal representation learned in the pretraining stage is\nutilized for downstream tasks in target domains; (3) The diffusion and\ndenoising process on the actual sequence space, combined with the improved\nclassifier free guidance as the conditional generation strategy, greatly\nimproves the stability and accuracy of the downstream task. We conduct\nextensive experiments on mainstream benchmarks, and the pre-trained UTSD\noutperforms existing foundation models on all data domains, exhibiting superior\nzero-shot generalization ability. After training from scratch, UTSD achieves\ncomparable performance against domain-specific proprietary models. The\nempirical results validate the potential of UTSD as a time series foundational\nmodel.",
      "tldr_zh": "本文提出 UTSD（Unified Time Series Diffusion Model），这是首个利用扩散模型（Diffusion）来统一建模多领域时间序列概率分布的框架，旨在解决 Transformer 模型在跨领域建模中面临的分布偏移挑战。UTSD 通过条件网络捕获观察序列的多尺度波动模式、Adapter-based fine-tuning 策略实现预训练表示的迁移，以及在实际序列空间上改进的 classifier free guidance 作为条件生成策略，提高了预测的稳定性和准确性。实验结果表明，预训练后的 UTSD 在主流基准上优于现有基础模型，展现出卓越的零样本泛化能力，并在从零开始训练时与领域特定模型性能相当，验证了其作为时间序列基础模型的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03068v1",
      "published_date": "2024-12-04 06:42:55 UTC",
      "updated_date": "2024-12-04 06:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:52:29.642713"
    },
    {
      "arxiv_id": "2412.03056v2",
      "title": "Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Marzieh Mohammadi",
        "Amir Salarpour"
      ],
      "abstract": "This paper introduces Point-GN, a novel non-parametric network for efficient\nand accurate 3D point cloud classification. Unlike conventional deep learning\nmodels that rely on a large number of trainable parameters, Point-GN leverages\nnon-learnable components-specifically, Farthest Point Sampling (FPS), k-Nearest\nNeighbors (k-NN), and Gaussian Positional Encoding (GPE)-to extract both local\nand global geometric features. This design eliminates the need for additional\ntraining while maintaining high performance, making Point-GN particularly\nsuited for real-time, resource-constrained applications. We evaluate Point-GN\non two benchmark datasets, ModelNet40 and ScanObjectNN, achieving\nclassification accuracies of 85.29% and 85.89%, respectively, while\nsignificantly reducing computational complexity. Point-GN outperforms existing\nnon-parametric methods and matches the performance of fully trained models, all\nwith zero learnable parameters. Our results demonstrate that Point-GN is a\npromising solution for 3D point cloud classification in practical, real-time\nenvironments.",
      "tldr_zh": "这篇论文提出了 Point-GN，一种新型非参数网络，用于高效且准确的 3D 点云分类，旨在减少对可训练参数的依赖。Point-GN 通过 Farthest Point Sampling (FPS)、k-Nearest Neighbors (k-NN) 和 Gaussian Positional Encoding (GPE) 等非可学习组件提取局部和全局几何特征，实现无需额外训练的性能。实验结果显示，在 ModelNet40 和 ScanObjectNN 数据集上，分类准确率分别为 85.29% 和 85.89%，并显著降低了计算复杂度，使其优于现有非参数方法并适用于实时资源受限的环境。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted for presentation at the IEEE Winter\n  Conference on Applications of Computer Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03056v2",
      "published_date": "2024-12-04 06:20:51 UTC",
      "updated_date": "2024-12-07 05:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:52:41.673967"
    },
    {
      "arxiv_id": "2412.03051v1",
      "title": "Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies",
      "title_zh": "Less is More: 一种针对基于 DRL 的自动驾驶策略的隐秘高效对抗",
      "authors": [
        "Junchao Fan",
        "Xuyang Lei",
        "Xiaolin Chang",
        "Jelena Mišić",
        "Vojislav B. Mišić"
      ],
      "abstract": "Despite significant advancements in deep reinforcement learning (DRL)-based\nautonomous driving policies, these policies still exhibit vulnerability to\nadversarial attacks. This vulnerability poses a formidable challenge to the\npractical deployment of these policies in autonomous driving. Designing\neffective adversarial attacks is an indispensable prerequisite for enhancing\nthe robustness of these policies. In view of this, we present a novel stealthy\nand efficient adversarial attack method for DRL-based autonomous driving\npolicies. Specifically, we introduce a DRL-based adversary designed to trigger\nsafety violations (e.g., collisions) by injecting adversarial samples at\ncritical moments. We model the attack as a mixed-integer optimization problem\nand formulate it as a Markov decision process. Then, we train the adversary to\nlearn the optimal policy for attacking at critical moments without domain\nknowledge. Furthermore, we introduce attack-related information and a\ntrajectory clipping method to enhance the learning capability of the adversary.\nFinally, we validate our method in an unprotected left-turn scenario across\ndifferent traffic densities. The experimental results show that our method\nachieves more than 90% collision rate within three attacks in most cases.\nFurthermore, our method achieves more than 130% improvement in attack\nefficiency compared to the unlimited attack method.",
      "tldr_zh": "本研究提出了一种隐秘且高效的对抗攻击方法，针对基于DRL（Deep Reinforcement Learning）的自动驾驶政策，旨在通过在关键时刻注入对抗样本来引发安全问题（如碰撞），从而评估和提升这些政策的鲁棒性。该方法将攻击建模为混合整数优化问题和Markov决策过程，使用DRL-based adversary进行训练，并在不依赖领域知识的情况下，通过引入攻击相关信息和轨迹剪裁技术来优化攻击策略。实验结果显示，在无保护的左转场景中，该方法在大多数情况下实现超过90%的碰撞率，并比无限制攻击方法效率提升130%以上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03051v1",
      "published_date": "2024-12-04 06:11:09 UTC",
      "updated_date": "2024-12-04 06:11:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:54:52.479113"
    },
    {
      "arxiv_id": "2412.03605v1",
      "title": "CBEval: A framework for evaluating and interpreting cognitive biases in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ammar Shaikh",
        "Raj Abhijit Dandekar",
        "Sreedath Panat",
        "Rajat Dandekar"
      ],
      "abstract": "Rapid advancements in Large Language models (LLMs) has significantly enhanced\ntheir reasoning capabilities. Despite improved performance on benchmarks, LLMs\nexhibit notable gaps in their cognitive processes. Additionally, as reflections\nof human-generated data, these models have the potential to inherit cognitive\nbiases, raising concerns about their reasoning and decision making\ncapabilities. In this paper we present a framework to interpret, understand and\nprovide insights into a host of cognitive biases in LLMs. Conducting our\nresearch on frontier language models we're able to elucidate reasoning\nlimitations and biases, and provide reasoning behind these biases by\nconstructing influence graphs that identify phrases and words most responsible\nfor biases manifested in LLMs. We further investigate biases such as round\nnumber bias and cognitive bias barrier revealed when noting framing effect in\nlanguage models.",
      "tldr_zh": "这篇论文提出了CBEval框架，用于评估和解释大型语言模型(LLMs)中的认知偏差(cognitive biases)，旨在揭示这些模型在推理和决策过程中存在的局限性。框架通过在前沿语言模型上进行研究，构建影响图(influence graphs)来识别导致偏差的关键短语和单词，从而提供偏差背后的原因分析。研究还调查了具体偏差，如round number bias和cognitive bias barrier，强调了LLMs继承人类数据偏差的风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03605v1",
      "published_date": "2024-12-04 05:53:28 UTC",
      "updated_date": "2024-12-04 05:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:53:03.479955"
    },
    {
      "arxiv_id": "2412.03039v1",
      "title": "MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Hyojeong Lee",
        "Youngwan Jo",
        "Inpyo Hong",
        "Sanghyun Park"
      ],
      "abstract": "We propose a Multifaceted Resilient Network(MRNet), a novel architecture\ndeveloped for medical image-to-image translation that outperforms\nstate-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet\nleverages the Segment Anything Model (SAM) to exploit frequency-based features\nto build a powerful method for advanced medical image transformation. The\narchitecture extracts comprehensive multiscale features from diverse datasets\nusing a powerful SAM image encoder and performs resolution-aware feature fusion\nthat consistently integrates U-Net encoder outputs with SAM-derived features.\nThis fusion optimizes the traditional U-Net skip connection while leveraging\ntransformer-based contextual analysis. The translation is complemented by an\ninnovative dual-mask configuration incorporating dynamic attention patterns and\na specialized loss function designed to address regional mapping mismatches,\npreserving both the gross anatomy and tissue details. Extensive validation\nstudies have shown that MRNet outperforms state-of-the-art architectures,\nparticularly in maintaining anatomical fidelity and minimizing translation\nartifacts.",
      "tldr_zh": "该研究提出了MRNet，一种多面弹性网络架构，用于医疗图像翻译任务，如MRI-to-CT和MRI-to-MRI转换。MRNet利用Segment Anything Model (SAM)提取基于频率的多尺度特征，并与U-Net编码器输出进行分辨率感知的特征融合，同时引入双掩码配置和专门损失函数，以优化跳跃连接、动态注意力模式，并处理区域映射不匹配问题，从而保留解剖结构和组织细节。实验验证显示，MRNet在维持解剖保真度和最小化翻译伪影方面，显著优于现有先进方法。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2412.03039v1",
      "published_date": "2024-12-04 05:23:46 UTC",
      "updated_date": "2024-12-04 05:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:53:16.980832"
    },
    {
      "arxiv_id": "2412.03038v1",
      "title": "MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management",
      "title_zh": "MILLION：一种通用多目标框架，用于投资组合",
      "authors": [
        "Liwei Deng",
        "Tianfu Wang",
        "Yan Zhao",
        "Kai Zheng"
      ],
      "abstract": "Portfolio management is an important yet challenging task in AI for FinTech,\nwhich aims to allocate investors' budgets among different assets to balance the\nrisk and return of an investment. In this study, we propose a general\nMulti-objectIve framework with controLLable rIsk for pOrtfolio maNagement\n(MILLION), which consists of two main phases, i.e., return-related maximization\nand risk control. Specifically, in the return-related maximization phase, we\nintroduce two auxiliary objectives, i.e., return rate prediction, and return\nrate ranking, combined with portfolio optimization to remit the overfitting\nproblem and improve the generalization of the trained model to future markets.\nSubsequently, in the risk control phase, we propose two methods, i.e.,\nportfolio interpolation and portfolio improvement, to achieve fine-grained risk\ncontrol and fast risk adaption to a user-specified risk level. For the\nportfolio interpolation method, we theoretically prove that the risk can be\nperfectly controlled if the to-be-set risk level is in a proper interval. In\naddition, we also show that the return rate of the adjusted portfolio after\nportfolio interpolation is no less than that of the min-variance optimization,\nas long as the model in the reward maximization phase is effective.\nFurthermore, the portfolio improvement method can achieve greater return rates\nwhile keeping the same risk level compared to portfolio interpolation.\nExtensive experiments are conducted on three real-world datasets. The results\ndemonstrate the effectiveness and efficiency of the proposed framework.",
      "tldr_zh": "本研究提出MILLION框架，这是一个通用的多目标框架，用于投资组合管理（portfolio management），旨在平衡投资回报和风险。框架分为两个阶段：回报相关最大化（return-related maximization）阶段，通过引入回报率预测和回报率排名辅助目标来缓解过拟合问题并提升模型泛化能力；风险控制阶段，则采用投资组合插值（portfolio interpolation）和投资组合改进（portfolio improvement）方法，实现精细风险调整和快速适应用户指定风险水平，并理论证明了其有效性。实验在三个真实数据集上验证，证明MILLION框架在效率和效果上优于基线模型。",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.PM",
      "comment": "accepted by VLDB 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.03038v1",
      "published_date": "2024-12-04 05:19:34 UTC",
      "updated_date": "2024-12-04 05:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:53:27.664990"
    },
    {
      "arxiv_id": "2412.03028v1",
      "title": "Specification Generation for Neural Networks in Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Isha Chaudhary",
        "Shuyi Lin",
        "Cheng Tan",
        "Gagandeep Singh"
      ],
      "abstract": "Specifications - precise mathematical representations of correct\ndomain-specific behaviors - are crucial to guarantee the trustworthiness of\ncomputer systems. With the increasing development of neural networks as\ncomputer system components, specifications gain more importance as they can be\nused to regulate the behaviors of these black-box models. Traditionally,\nspecifications are designed by domain experts based on their intuition of\ncorrect behavior. However, this is labor-intensive and hence not a scalable\napproach as computer system applications diversify. We hypothesize that the\ntraditional (aka reference) algorithms that neural networks replace for higher\nperformance can act as effective proxies for correct behaviors of the models,\nwhen available. This is because they have been used and tested for long enough\nto encode several aspects of the trustworthy/correct behaviors in the\nunderlying domain. Driven by our hypothesis, we develop a novel automated\nframework, SpecTRA to generate specifications for neural networks using\nreferences. We formulate specification generation as an optimization problem\nand solve it with observations of reference behaviors. SpecTRA clusters similar\nobservations into compact specifications. We present specifications generated\nby SpecTRA for neural networks in adaptive bit rate and congestion control\nalgorithms. Our specifications show evidence of being correct and matching\nintuition. Moreover, we use our specifications to show several unknown\nvulnerabilities of the SOTA models for computer systems.",
      "tldr_zh": "该论文探讨了为系统中的神经网络生成规格说明（Specifications）的自动化方法，以提升计算机系统的可信度。作者假设传统参考算法（reference algorithms）可作为神经网络行为的有效代理，并基于此开发了新型框架 SpecTRA，将规格生成表述为优化问题，通过聚类参考行为的观察来创建紧凑的规格说明。在自适应比特率和拥塞控制算法的案例中，SpecTRA 生成的规格证明正确且符合直觉，并揭示了现有最先进（SOTA）模型的多个未知漏洞，从而为可扩展的神经网络验证提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03028v1",
      "published_date": "2024-12-04 04:45:36 UTC",
      "updated_date": "2024-12-04 04:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:11.384071"
    },
    {
      "arxiv_id": "2412.03021v4",
      "title": "PEMF-VTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm",
      "title_zh": "PEMF-VTO：基于无掩码范式的点增强视频虚拟试穿",
      "authors": [
        "Tianyu Chang",
        "Xiaohao Chen",
        "Zhichao Wei",
        "Xuanpu Zhang",
        "Qing-Guo Chen",
        "Weihua Luo",
        "Peipei Song",
        "Xun Yang"
      ],
      "abstract": "Video Virtual Try-on aims to seamlessly transfer a reference garment onto a\ntarget person in a video while preserving both visual fidelity and temporal\ncoherence. Existing methods typically rely on inpainting masks to define the\ntry-on area, enabling accurate garment transfer for simple scenes (e.g.,\nin-shop videos). However, these mask-based approaches struggle with complex\nreal-world scenarios, as overly large and inconsistent masks often destroy\nspatial-temporal information, leading to distorted results. Mask-free methods\nalleviate this issue but face challenges in accurately determining the try-on\narea, especially for videos with dynamic body movements. To address these\nlimitations, we propose PEMF-VTO, a novel Point-Enhanced Mask-Free Video\nVirtual Try-On framework that leverages sparse point alignments to explicitly\nguide garment transfer. Our key innovation is the introduction of\npoint-enhanced guidance, which provides flexible and reliable control over both\nspatial-level garment transfer and temporal-level video coherence.\nSpecifically, we design a Point-Enhanced Transformer (PET) with two core\ncomponents: Point-Enhanced Spatial Attention (PSA), which uses frame-cloth\npoint alignments to precisely guide garment transfer, and Point-Enhanced\nTemporal Attention (PTA), which leverages frame-frame point correspondences to\nenhance temporal coherence and ensure smooth transitions across frames.\nExtensive experiments demonstrate that our PEMF-VTO outperforms\nstate-of-the-art methods, generating more natural, coherent, and visually\nappealing try-on videos, particularly for challenging in-the-wild scenarios.\nThe link to our paper's homepage is https://pemf-vto.github.io/.",
      "tldr_zh": "本论文提出PEMF-VTO，一种基于无掩码范式的点增强视频虚拟试穿框架，旨在解决现有方法在复杂场景中（如动态身体运动）难以准确转移服装并保持空间-时间连贯性的问题。该框架通过稀疏点对齐技术引入Point-Enhanced Transformer (PET)，其中Point-Enhanced Spatial Attention (PSA)用于精确指导帧-布料点对齐以实现服装转移，而Point-Enhanced Temporal Attention (PTA)则利用帧-帧点对应增强视频的平滑过渡。实验结果表明，PEMF-VTO在广泛测试中优于最先进方法，尤其在野外场景中，生成更自然、连贯且视觉吸引力的试穿视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03021v4",
      "published_date": "2024-12-04 04:24:15 UTC",
      "updated_date": "2025-03-14 10:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:55:21.407286"
    },
    {
      "arxiv_id": "2412.03011v1",
      "title": "Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Feng",
        "Shunsi Zhang",
        "Jian Shu",
        "Hanfeng Zhao",
        "Guoliang Pang",
        "Chi Zhang",
        "Hao Wang"
      ],
      "abstract": "Generating multi-view human images from a single view is a complex and\nsignificant challenge. Although recent advancements in multi-view object\ngeneration have shown impressive results with diffusion models, novel view\nsynthesis for humans remains constrained by the limited availability of 3D\nhuman datasets. Consequently, many existing models struggle to produce\nrealistic human body shapes or capture fine-grained facial details accurately.\nTo address these issues, we propose an innovative framework that leverages\ntransferred body and facial representations for multi-view human synthesis.\nSpecifically, we use a single-view model pretrained on a large-scale human\ndataset to develop a multi-view body representation, aiming to extend the 2D\nknowledge of the single-view model to a multi-view diffusion model.\nAdditionally, to enhance the model's detail restoration capability, we\nintegrate transferred multimodal facial features into our trained human\ndiffusion model. Experimental evaluations on benchmark datasets demonstrate\nthat our approach outperforms the current state-of-the-art methods, achieving\nsuperior performance in multi-view human synthesis.",
      "tldr_zh": "该论文针对从单视图生成多视图人类图像的挑战，提出了一种创新框架，利用 transferred body and face representations 来解决现有模型在人体形状和面部细节捕捉上的不足。具体方法包括使用在大型人类数据集上预训练的单视图模型扩展到 multi-view diffusion model，以及整合 transferred multimodal facial features 以提升细节恢复能力。实验评估显示，该方法在基准数据集上优于当前最先进技术，在 multi-view human synthesis 方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.03011v1",
      "published_date": "2024-12-04 04:02:17 UTC",
      "updated_date": "2024-12-04 04:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:55:30.573945"
    },
    {
      "arxiv_id": "2412.02980v2",
      "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Havrilla",
        "Andrew Dai",
        "Laura O'Mahony",
        "Koen Oostermeijer",
        "Vera Zisler",
        "Alon Albalak",
        "Fabrizio Milo",
        "Sharath Chandra Raparthy",
        "Kanishk Gandhi",
        "Baber Abbasi",
        "Duy Phung",
        "Maia Iyer",
        "Dakota Mahan",
        "Chase Blagden",
        "Srishti Gureja",
        "Mohammed Hamdy",
        "Wen-Ding Li",
        "Giovanni Paolini",
        "Pawan Sasanka Ammanamanchi",
        "Elliot Meyerson"
      ],
      "abstract": "Synthetic data generation with Large Language Models is a promising paradigm\nfor augmenting natural data over a nearly infinite range of tasks. Given this\nvariety, direct comparisons among synthetic data generation algorithms are\nscarce, making it difficult to understand where improvement comes from and what\nbottlenecks exist. We propose to evaluate algorithms via the makeup of\nsynthetic data generated by each algorithm in terms of data quality, diversity,\nand complexity. We choose these three characteristics for their significance in\nopen-ended processes and the impact each has on the capabilities of downstream\nmodels. We find quality to be essential for in-distribution model\ngeneralization, diversity to be essential for out-of-distribution\ngeneralization, and complexity to be beneficial for both. Further, we emphasize\nthe existence of Quality-Diversity trade-offs in training data and the\ndownstream effects on model performance. We then examine the effect of various\ncomponents in the synthetic data pipeline on each data characteristic. This\nexamination allows us to taxonomize and compare synthetic data generation\nalgorithms through the components they utilize and the resulting effects on\ndata QDC composition. This analysis extends into a discussion on the importance\nof balancing QDC in synthetic data for efficient reinforcement learning and\nself-improvement algorithms. Analogous to the QD trade-offs in training data,\noften there exist trade-offs between model output quality and output diversity\nwhich impact the composition of synthetic data. We observe that many models are\ncurrently evaluated and optimized only for output quality, thereby limiting\noutput diversity and the potential for self-improvement. We argue that\nbalancing these trade-offs is essential to the development of future\nself-improvement algorithms and highlight a number of works making progress in\nthis direction.",
      "tldr_zh": "这篇论文调查了Large Language Models (LLMs) 生成的合成数据中，质量 (quality)、多样性 (diversity) 和复杂性 (complexity) 这些特性的影响，以评估合成数据算法在各种任务中的性能。研究发现，数据质量对模型的分布内泛化至关重要，多样性有助于分布外泛化，而复杂性则对两者均有益，但存在质量与多样性的权衡，可能影响下游模型的表现。论文进一步分析了合成数据管道组件对这些特性的作用，并强调平衡 QDC 是提升强化学习和自提升算法效率的关键，呼吁未来算法优化需兼顾输出质量与多样性以实现更好的自改进潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02980v2",
      "published_date": "2024-12-04 02:47:45 UTC",
      "updated_date": "2024-12-09 22:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:08.459879"
    },
    {
      "arxiv_id": "2412.02975v1",
      "title": "Theoretical limitations of multi-layer Transformer",
      "title_zh": "多层 Transformer 的理论限制",
      "authors": [
        "Lijie Chen",
        "Binghui Peng",
        "Hongxun Wu"
      ],
      "abstract": "Transformers, especially the decoder-only variants, are the backbone of most\nmodern large language models; yet we do not have much understanding of their\nexpressive power except for the simple $1$-layer case.\n  Due to the difficulty of analyzing multi-layer models, all previous work\nrelies on unproven complexity conjectures to show limitations for multi-layer\nTransformers. In this work, we prove the first $\\textit{unconditional}$ lower\nbound against multi-layer decoder-only transformers. For any constant $L$, we\nprove that any $L$-layer decoder-only transformer needs a polynomial model\ndimension ($n^{\\Omega(1)}$) to perform sequential composition of $L$ functions\nover an input of $n$ tokens.\n  As a consequence, our results give: (1) the first depth-width trade-off for\nmulti-layer transformers, exhibiting that the $L$-step composition task is\nexponentially harder for $L$-layer models compared to $(L+1)$-layer ones; (2)\nan unconditional separation between encoder and decoder, exhibiting a hard task\nfor decoders that can be solved by an exponentially shallower and smaller\nencoder; (3) a provable advantage of chain-of-thought, exhibiting a task that\nbecomes exponentially easier with chain-of-thought.\n  On the technical side, we propose the multi-party $\\textit{autoregressive}$\n$\\textit{communication}$ $\\textit{model}$ that captures the computation of a\ndecoder-only Transformer. We also introduce a new proof technique that finds a\ncertain $\\textit{indistinguishable}$ $\\textit{decomposition}$ of all possible\ninputs iteratively for proving lower bounds in this model. We believe our new\ncommunication model and proof technique will be helpful to further understand\nthe computational power of transformers.",
      "tldr_zh": "本文证明了多层 decoder-only Transformer 的理论限制，首次提供了无条件 lower bound：对于任何常量 L，L 层模型需要多项式模型维度 (n^Ω(1)) 来处理 n 个 token 的 L 函数顺序组合。研究揭示了深度-宽度权衡，即 L 步组合任务对 L 层模型比 (L+1) 层模型指数级更难；同时展示了 encoder 与 decoder 的分离，一个对 decoder 困难的任务可以用指数级更浅更小的 encoder 解决。论文还证明了 chain-of-thought 的优势，某些任务通过该方法变得指数级更容易。在技术上，作者提出了多方 autoregressive 通信模型和新的证明技术，用于迭代找到输入的不可区分分解，以进一步理解 Transformer's 计算能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02975v1",
      "published_date": "2024-12-04 02:37:31 UTC",
      "updated_date": "2024-12-04 02:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:55:57.333867"
    },
    {
      "arxiv_id": "2412.02957v1",
      "title": "3D Interaction Geometric Pre-training for Molecular Relational Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Namkyeong Lee",
        "Yunhak Oh",
        "Heewoong Noh",
        "Gyoung S. Na",
        "Minkai Xu",
        "Hanchen Wang",
        "Tianfan Fu",
        "Chanyoung Park"
      ],
      "abstract": "Molecular Relational Learning (MRL) is a rapidly growing field that focuses\non understanding the interaction dynamics between molecules, which is crucial\nfor applications ranging from catalyst engineering to drug discovery. Despite\nrecent progress, earlier MRL approaches are limited to using only the 2D\ntopological structure of molecules, as obtaining the 3D interaction geometry\nremains prohibitively expensive. This paper introduces a novel 3D geometric\npre-training strategy for MRL (3DMRL) that incorporates a 3D virtual\ninteraction environment, overcoming the limitations of costly traditional\nquantum mechanical calculation methods. With the constructed 3D virtual\ninteraction environment, 3DMRL trains 2D MRL model to learn the overall 3D\ngeometric information of molecular interaction through contrastive learning.\nMoreover, fine-grained interaction between molecules is learned through force\nprediction loss, which is crucial in understanding the wide range of molecular\ninteraction processes. Extensive experiments on various tasks using real-world\ndatasets, including out-of-distribution and extrapolation scenarios,\ndemonstrate the effectiveness of 3DMRL, showing up to a 24.93\\% improvement in\nperformance across 40 tasks.",
      "tldr_zh": "该论文提出了一种名为3DMRL的3D几何预训练策略，用于Molecular Relational Learning（MRL），旨在解决现有方法仅依赖2D拓扑结构且获取3D交互几何成本高的局限性。\n通过构建3D虚拟交互环境，3DMRL采用contrastive learning学习分子交互的整体3D几何信息，并利用力预测损失捕捉细粒度的交互动态。\n实验在真实数据集上验证了其有效性，在40个任务中性能提升高达24.93%，尤其在out-of-distribution和外推场景中表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02957v1",
      "published_date": "2024-12-04 02:05:55 UTC",
      "updated_date": "2024-12-04 02:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:06.362819"
    },
    {
      "arxiv_id": "2412.02946v1",
      "title": "Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Po-Hsuan Huang",
        "Jeng-Lin Li",
        "Chin-Po Chen",
        "Ming-Ching Chang",
        "Wei-Chao Chen"
      ],
      "abstract": "Recent advancements in large vision-language models (LVLM) have significantly\nenhanced their ability to comprehend visual inputs alongside natural language.\nHowever, a major challenge in their real-world application is hallucination,\nwhere LVLMs generate non-existent visual elements, eroding user trust. The\nunderlying mechanism driving this multimodal hallucination is poorly\nunderstood. Minimal research has illuminated whether contexts such as sky,\ntree, or grass field involve the LVLM in hallucinating a frisbee. We\nhypothesize that hidden factors, such as objects, contexts, and semantic\nforeground-background structures, induce hallucination. This study proposes a\nnovel causal approach: a hallucination probing system to identify these hidden\nfactors. By analyzing the causality between images, text prompts, and network\nsaliency, we systematically explore interventions to block these factors. Our\nexperimental findings show that a straightforward technique based on our\nanalysis can significantly reduce hallucinations. Additionally, our analyses\nindicate the potential to edit network internals to minimize hallucinated\noutputs.",
      "tldr_zh": "该研究探讨了大型视觉语言模型（LVLM）中的幻觉问题（hallucination），即模型生成不存在的视觉元素，并假设隐藏因素如对象、上下文和语义前后台结构是诱因。研究提出了一种新型因果分析方法，包括一个幻觉探测系统，通过分析图像、文本提示和网络显着性（saliency）来识别并干预这些因素。实验结果显示，这种基于分析的简单技术能显著减少幻觉现象，并表明可以通过编辑网络内部来最小化幻觉输出，从而提升LVLM的可靠性和实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV2025",
      "pdf_url": "http://arxiv.org/pdf/2412.02946v1",
      "published_date": "2024-12-04 01:23:57 UTC",
      "updated_date": "2024-12-04 01:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:19.124206"
    },
    {
      "arxiv_id": "2412.02942v1",
      "title": "STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Silu He",
        "Peng Shen",
        "Pingzhen Xu",
        "Qinyao Luo",
        "Haifeng Li"
      ],
      "abstract": "Existing works typically treat spatial-temporal prediction as the task of\nlearning a function $F$ to transform historical observations to future\nobservations. We further decompose this cross-time transformation into three\nprocesses: (1) Encoding ($E$): learning the intrinsic representation of\nobservations, (2) Cross-Time Mapping ($M$): transforming past representations\ninto future representations, and (3) Decoding ($D$): reconstructing future\nobservations from the future representations. From this perspective,\nspatial-temporal prediction can be viewed as learning $F = E \\cdot M \\cdot D$,\nwhich includes learning the space transformations $\\left\\{{E},{D}\\right\\}$\nbetween the observation space and the hidden representation space, as well as\nthe spatial-temporal mapping $M$ from future states to past states within the\nrepresentation space. This leads to two key questions: \\textbf{Q1: What kind of\nrepresentation space allows for mapping the past to the future? Q2: How to\nachieve map the past to the future within the representation space?} To address\nQ1, we propose a Spatial-Temporal Backdoor Adjustment strategy, which learns a\nSpatial-Temporal De-Confounded (STDC) representation space and estimates the\nde-confounding causal effect of historical data on future data. This causal\nrelationship we captured serves as the foundation for subsequent\nspatial-temporal mapping. To address Q2, we design a Spatial-Temporal Embedding\n(STE) that fuses the information of temporal and spatial confounders, capturing\nthe intrinsic spatial-temporal characteristics of the representations.\nAdditionally, we introduce a Cross-Time Attention mechanism, which queries the\nattention between the future and the past to guide spatial-temporal mapping.",
      "tldr_zh": "本论文提出 STDCformer，一种基于 Transformer 的模型，针对人群流动预测问题，通过 Spatial-Temporal Causal De-Confounding Strategy 将预测任务分解为编码(E)、跨时间映射(M)和解码(D)三个过程，以解决空间-时间关系的混杂因素。论文首先采用 Spatial-Temporal Backdoor Adjustment 策略，学习 Spatial-Temporal De-Confounded (STDC) 代表空间，并估计历史数据对未来数据的因果效应。接着，设计 Spatial-Temporal Embedding (STE) 来融合时间和空间混杂信息，并引入 Cross-Time Attention 机制指导跨时间映射，从而提升预测的准确性和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02942v1",
      "published_date": "2024-12-04 01:20:43 UTC",
      "updated_date": "2024-12-04 01:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:32.074444"
    },
    {
      "arxiv_id": "2412.02940v1",
      "title": "SAVER: A Toolbox for Sampling-Based, Probabilistic Verification of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Vignesh Sivaramakrishnan",
        "Krishna C. Kalagarla",
        "Rosalyn Devonport",
        "Joshua Pilipovsky",
        "Panagiotis Tsiotras",
        "Meeko Oishi"
      ],
      "abstract": "We present a neural network verification toolbox to 1) assess the probability\nof satisfaction of a constraint, and 2) synthesize a set expansion factor to\nachieve the probability of satisfaction. Specifically, the tool box establishes\nwith a user-specified level of confidence whether the output of the neural\nnetwork for a given input distribution is likely to be contained within a given\nset. Should the tool determine that the given set cannot satisfy the likelihood\nconstraint, the tool also implements an approach outlined in this paper to\nalter the constraint set to ensure that the user-defined satisfaction\nprobability is achieved. The toolbox is comprised of sampling-based approaches\nwhich exploit the properties of signed distance function to define set\ncontainment.",
      "tldr_zh": "这篇论文介绍了 SAVER，一个基于采样的神经网络概率验证工具箱，用于评估约束满足的概率并合成集合扩展因子以实现指定概率。该工具箱以用户定义的置信水平检查神经网络输出是否可能包含在给定输入分布的集合内，如果不满足，则通过调整约束集来确保满足概率。SAVER 采用 sampling-based approaches，并利用 signed distance function 的属性来定义集合包含，为神经网络的可靠验证提供实用方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 8 figures, submitted to the 28th ACM International\n  Conference on Hybrid Systems: Computation and Control",
      "pdf_url": "http://arxiv.org/pdf/2412.02940v1",
      "published_date": "2024-12-04 01:13:44 UTC",
      "updated_date": "2024-12-04 01:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:43.006474"
    },
    {
      "arxiv_id": "2412.02931v1",
      "title": "Inverse Delayed Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Sinong Zhan",
        "Qingyuan Wu",
        "Zhian Ruan",
        "Frank Yang",
        "Philip Wang",
        "Yixuan Wang",
        "Ruochen Jiao",
        "Chao Huang",
        "Qi Zhu"
      ],
      "abstract": "Inverse Reinforcement Learning (IRL) has demonstrated effectiveness in a\nvariety of imitation tasks. In this paper, we introduce an IRL framework\ndesigned to extract rewarding features from expert trajectories affected by\ndelayed disturbances. Instead of relying on direct observations, our approach\nemploys an efficient off-policy adversarial training framework to derive expert\nfeatures and recover optimal policies from augmented delayed observations.\nEmpirical evaluations in the MuJoCo environment under diverse delay settings\nvalidate the effectiveness of our method. Furthermore, we provide a theoretical\nanalysis showing that recovering expert policies from augmented delayed\nobservations outperforms using direct delayed observations.",
      "tldr_zh": "本研究提出了一种Inverse Reinforcement Learning (IRL) 框架，用于从受延迟干扰影响的专家轨迹中提取奖励特征。该框架采用高效的off-policy对抗训练方法，通过增强延迟观察来推导专家特征并恢复最优策略。在MuJoCo环境中进行的实证评估显示，该方法在各种延迟设置下表现出色，并通过理论分析证明，从增强延迟观察中恢复专家策略优于直接使用延迟观察。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02931v1",
      "published_date": "2024-12-04 00:53:55 UTC",
      "updated_date": "2024-12-04 00:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:56:52.989036"
    },
    {
      "arxiv_id": "2412.02929v2",
      "title": "Panoptic Diffusion Models: co-generation of images and segmentation maps",
      "title_zh": "全景扩散模型：图像与分割图的共同生成",
      "authors": [
        "Yinghan Long",
        "Kaushik Roy"
      ],
      "abstract": "Recently, diffusion models have demonstrated impressive capabilities in\ntext-guided and image-conditioned image generation. However, existing diffusion\nmodels cannot simultaneously generate an image and a panoptic segmentation of\nobjects and stuff from the prompt. Incorporating an inherent understanding of\nshapes and scene layouts can improve the creativity and realism of diffusion\nmodels. To address this limitation, we present Panoptic Diffusion Model (PDM),\nthe first model designed to generate both images and panoptic segmentation maps\nconcurrently. PDM bridges the gap between image and text by constructing\nsegmentation layouts that provide detailed, built-in guidance throughout the\ngeneration process. This ensures the inclusion of categories mentioned in text\nprompts and enriches the diversity of segments within the background. We\ndemonstrate the effectiveness of PDM across two architectures: a unified\ndiffusion transformer and a two-stream transformer with a pretrained backbone.\nWe propose a Multi-Scale Patching mechanism to generate high-resolution\nsegmentation maps. Additionally, when ground-truth maps are available, PDM can\nfunction as a text-guided image-to-image generation model. Finally, we propose\na novel metric for evaluating the quality of generated maps and show that PDM\nachieves state-of-the-art results in image generation with implicit scene\ncontrol.",
      "tldr_zh": "该论文提出 Panoptic Diffusion Model (PDM)，这是首个能够同时生成图像和全景分割地图（panoptic segmentation maps）的扩散模型，通过构建分割布局（segmentation layouts）来桥接文本提示与图像生成，确保包含指定类别并提升场景多样性。PDM 支持两种架构，包括统一的扩散transformer和两流transformer（two-stream transformer）带预训练骨干，并引入 Multi-Scale Patching 机制以生成高分辨率分割地图。实验结果显示，PDM 在图像生成中实现最先进（state-of-the-art）性能，提供隐式场景控制，并提出新评估指标来衡量生成地图的质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02929v2",
      "published_date": "2024-12-04 00:42:15 UTC",
      "updated_date": "2025-02-22 05:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:57:07.021593"
    },
    {
      "arxiv_id": "2412.02919v1",
      "title": "Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data",
      "title_zh": "高阶 Transformer：用于张量结构数据的高效注意力机制",
      "authors": [
        "Soroush Omranpour",
        "Guillaume Rabusseau",
        "Reihaneh Rabbany"
      ],
      "abstract": "Transformers are now ubiquitous for sequence modeling tasks, but their\nextension to multi-dimensional data remains a challenge due to the quadratic\ncost of the attention mechanism. In this paper, we propose Higher-Order\nTransformers (HOT), a novel architecture designed to efficiently process data\nwith more than two axes, i.e. higher-order tensors. To address the\ncomputational challenges associated with high-order tensor attention, we\nintroduce a novel Kronecker factorized attention mechanism that reduces the\nattention cost to quadratic in each axis' dimension, rather than quadratic in\nthe total size of the input tensor. To further enhance efficiency, HOT\nleverages kernelized attention, reducing the complexity to linear. This\nstrategy maintains the model's expressiveness while enabling scalable attention\ncomputation. We validate the effectiveness of HOT on two high-dimensional\ntasks, including multivariate time series forecasting, and 3D medical image\nclassification. Experimental results demonstrate that HOT achieves competitive\nperformance while significantly improving computational efficiency, showcasing\nits potential for tackling a wide range of complex, multi-dimensional data.",
      "tldr_zh": "这篇论文针对 Transformers 在处理多维张量数据时因 attention mechanism 的二次方计算成本而面临的挑战，提出了 Higher-Order Transformers (HOT) 架构，以高效处理更高阶张量。HOT 引入了 Kronecker factorized attention 机制，将 attention 成本减少到每个轴维度的二次方，并通过 kernelized attention 进一步降低复杂度至线性，同时保持模型的表达能力。在多变量时间序列预测和 3D 医疗图像分类任务上，实验结果表明 HOT 实现了与基线模型相当的性能，同时显著提升了计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.02919v1",
      "published_date": "2024-12-04 00:10:47 UTC",
      "updated_date": "2024-12-04 00:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T07:59:11.368978"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 102,
  "processed_papers_count": 102,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T07:59:37.537240"
}