[
  {
    "arxiv_id": "2406.17813v1",
    "title": "Unsupervised Concept Drift Detection from Deep Learning Representations in Real-time",
    "authors": [
      "Salvatore Greco",
      "Bartolomeo Vacchetti",
      "Daniele Apiletti",
      "Tania Cerquitelli"
    ],
    "abstract": "Concept Drift is a phenomenon in which the underlying data distribution and\nstatistical properties of a target domain change over time, leading to a\ndegradation of the model's performance. Consequently, models deployed in\nproduction require continuous monitoring through drift detection techniques.\nMost drift detection methods to date are supervised, i.e., based on\nground-truth labels. However, true labels are usually not available in many\nreal-world scenarios. Although recent efforts have been made to develop\nunsupervised methods, they often lack the required accuracy, have a complexity\nthat makes real-time implementation in production environments difficult, or\nare unable to effectively characterize drift. To address these challenges, we\npropose DriftLens, an unsupervised real-time concept drift detection framework.\nIt works on unstructured data by exploiting the distribution distances of deep\nlearning representations. DriftLens can also provide drift characterization by\nanalyzing each label separately. A comprehensive experimental evaluation is\npresented with multiple deep learning classifiers for text, image, and speech.\nResults show that (i) DriftLens performs better than previous methods in\ndetecting drift in $11/13$ use cases; (ii) it runs at least 5 times faster;\n(iii) its detected drift value is very coherent with the amount of drift\n(correlation $\\geq 0.85$); (iv) it is robust to parameter changes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17813v1",
    "published_date": "2024-06-24 23:41:46 UTC",
    "updated_date": "2024-06-24 23:41:46 UTC"
  },
  {
    "arxiv_id": "2406.17169v3",
    "title": "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models",
    "authors": [
      "Nisarg Patel",
      "Mohith Kulkarni",
      "Mihir Parmar",
      "Aashna Budhiraja",
      "Mutsumi Nakamura",
      "Neeraj Varshney",
      "Chitta Baral"
    ],
    "abstract": "As Large Language Models (LLMs) continue to exhibit remarkable performance in\nnatural language understanding tasks, there is a crucial need to measure their\nability for human-like multi-step logical reasoning. Existing logical reasoning\nevaluation benchmarks often focus primarily on simplistic single-step or\nmulti-step reasoning with a limited set of inference rules. Furthermore, the\nlack of datasets for evaluating non-monotonic reasoning represents a crucial\ngap since it aligns more closely with human-like reasoning. To address these\nlimitations, we propose Multi-LogiEval, a comprehensive evaluation dataset\nencompassing multi-step logical reasoning with various inference rules and\ndepths. Multi-LogiEval covers three logic types--propositional, first-order,\nand non-monotonic--consisting of more than 30 inference rules and more than 60\nof their combinations with various depths. Leveraging this dataset, we conduct\nevaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,\nand Mistral, employing a zero-shot chain-of-thought. Experimental results show\nthat there is a significant drop in the performance of LLMs as the reasoning\nsteps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).\nWe further conduct a thorough investigation of reasoning chains generated by\nLLMs which reveals several important findings. We believe that Multi-LogiEval\nfacilitates future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data is available at\nhttps://github.com/Mihir3009/Multi-LogiEval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2406.17169v3",
    "published_date": "2024-06-24 23:02:56 UTC",
    "updated_date": "2024-10-07 03:48:18 UTC"
  },
  {
    "arxiv_id": "2406.17168v1",
    "title": "Reinforcement Learning via Auxiliary Task Distillation",
    "authors": [
      "Abhinav Narayan Harish",
      "Larry Heck",
      "Josiah P. Hanna",
      "Zsolt Kira",
      "Andrew Szot"
    ],
    "abstract": "We present Reinforcement Learning via Auxiliary Task Distillation\n(AuxDistill), a new method that enables reinforcement learning (RL) to perform\nlong-horizon robot control problems by distilling behaviors from auxiliary RL\ntasks. AuxDistill achieves this by concurrently carrying out multi-task RL with\nauxiliary tasks, which are easier to learn and relevant to the main task. A\nweighted distillation loss transfers behaviors from these auxiliary tasks to\nsolve the main task. We demonstrate that AuxDistill can learn a\npixels-to-actions policy for a challenging multi-stage embodied object\nrearrangement task from the environment reward without demonstrations, a\nlearning curriculum, or pre-trained skills. AuxDistill achieves $2.3 \\times$\nhigher success than the previous state-of-the-art baseline in the Habitat\nObject Rearrangement benchmark and outperforms methods that use pre-trained\nskills and expert demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17168v1",
    "published_date": "2024-06-24 23:02:18 UTC",
    "updated_date": "2024-06-24 23:02:18 UTC"
  },
  {
    "arxiv_id": "2406.17163v1",
    "title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors",
    "authors": [
      "Vikas Yadav",
      "Zheng Tang",
      "Vijay Srinivasan"
    ],
    "abstract": "Large language models (LLM) have achieved remarkable success in natural\nlanguage generation but lesser focus has been given to their applicability in\ndecision making tasks such as classification. We show that LLMs like LLaMa can\nachieve high performance on large multi-class classification tasks but still\nmake classification errors and worse, generate out-of-vocabulary class labels.\nTo address these critical issues, we introduce Paraphrase and AGgregate\n(PAG)-LLM approach wherein an LLM generates multiple paraphrases of the input\nquery (parallel queries), performs multi-class classification for the original\nquery and each paraphrase, and at the end aggregate all the classification\nlabels based on their confidence scores. We evaluate PAG-LLM on two large\nmulti-class classication datasets: CLINC, and Banking and show 22.7% and 15.1%\nerror reduction. We show that PAG-LLM is especially effective for hard examples\nwhere LLM is uncertain, and reduces the critical misclassification and\nhallucinated label generation errors",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SIGIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.17163v1",
    "published_date": "2024-06-24 22:30:26 UTC",
    "updated_date": "2024-06-24 22:30:26 UTC"
  },
  {
    "arxiv_id": "2406.17162v1",
    "title": "Virtual Mines -- Component-level recycling of printed circuit boards using deep learning",
    "authors": [
      "Muhammad Mohsin",
      "Stefano Rovetta",
      "Francesco Masulli",
      "Alberto Cabri"
    ],
    "abstract": "This contribution gives an overview of an ongoing project using machine\nlearning and computer vision components for improving the electronic waste\nrecycling process. In circular economy, the \"virtual mines\" concept refers to\nproduction cycles where interesting raw materials are reclaimed in an efficient\nand cost-effective manner from end-of-life items. In particular, the growth of\ne-waste, due to the increasingly shorter life cycle of hi-tech goods, is a\nglobal problem. In this paper, we describe a pipeline based on deep learning\nmodel to recycle printed circuit boards at the component level. A pre-trained\nYOLOv5 model is used to analyze the results of the locally developed dataset.\nWith a different distribution of class instances, YOLOv5 managed to achieve\nsatisfactory precision and recall, with the ability to optimize with large\ncomponent instances.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.17162v1",
    "published_date": "2024-06-24 22:29:30 UTC",
    "updated_date": "2024-06-24 22:29:30 UTC"
  },
  {
    "arxiv_id": "2406.17150v1",
    "title": "Peirce in the Machine: How Mixture of Experts Models Perform Hypothesis Construction",
    "authors": [
      "Bruce Rushing"
    ],
    "abstract": "Mixture of experts is a prediction aggregation method in machine learning\nthat aggregates the predictions of specialized experts. This method often\noutperforms Bayesian methods despite the Bayesian having stronger inductive\nguarantees. We argue that this is due to the greater functional capacity of\nmixture of experts. We prove that in a limiting case of mixture of experts will\nhave greater capacity than equivalent Bayesian methods, which we vouchsafe\nthrough experiments on non-limiting cases. Finally, we conclude that mixture of\nexperts is a type of abductive reasoning in the Peircian sense of hypothesis\nconstruction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.17150v1",
    "published_date": "2024-06-24 21:44:37 UTC",
    "updated_date": "2024-06-24 21:44:37 UTC"
  },
  {
    "arxiv_id": "2406.17147v1",
    "title": "Quantifying Heterogeneous Ecosystem Services With Multi-Label Soft Classification",
    "authors": [
      "Zhihui Tian",
      "John Upchurch",
      "G. Austin Simon",
      "José Dubeux",
      "Alina Zare",
      "Chang Zhao",
      "Joel B. Harley"
    ],
    "abstract": "Understanding and quantifying ecosystem services are crucial for sustainable\nenvironmental management, conservation efforts, and policy-making. The\nadvancement of remote sensing technology and machine learning techniques has\ngreatly facilitated this process. Yet, ground truth labels, such as\nbiodiversity, are very difficult and expensive to measure. In addition, more\neasily obtainable proxy labels, such as land use, often fail to capture the\ncomplex heterogeneity of the ecosystem. In this paper, we demonstrate how land\nuse proxy labels can be implemented with a soft, multi-label classifier to\npredict ecosystem services with complex heterogeneity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2406.17147v1",
    "published_date": "2024-06-24 21:38:13 UTC",
    "updated_date": "2024-06-24 21:38:13 UTC"
  },
  {
    "arxiv_id": "2406.17145v2",
    "title": "GraphPipe: Improving Performance and Scalability of DNN Training with Graph Pipeline Parallelism",
    "authors": [
      "Byungsoo Jeon",
      "Mengdi Wu",
      "Shiyi Cao",
      "Sunghyun Kim",
      "Sunghyun Park",
      "Neeraj Aggarwal",
      "Colin Unger",
      "Daiyaan Arfeen",
      "Peiyuan Liao",
      "Xupeng Miao",
      "Mohammad Alizadeh",
      "Gregory R. Ganger",
      "Tianqi Chen",
      "Zhihao Jia"
    ],
    "abstract": "Deep neural networks (DNNs) continue to grow rapidly in size, making them\ninfeasible to train on a single device. Pipeline parallelism is commonly used\nin existing DNN systems to support large-scale DNN training by partitioning a\nDNN into multiple stages, which concurrently perform DNN training for different\nmicro-batches in a pipeline fashion. However, existing pipeline-parallel\napproaches only consider sequential pipeline stages and thus ignore the\ntopology of a DNN, resulting in missed model-parallel opportunities. This paper\npresents graph pipeline parallelism (GPP), a new pipeline-parallel scheme that\npartitions a DNN into pipeline stages whose dependencies are identified by a\ndirected acyclic graph. GPP generalizes existing sequential pipeline\nparallelism and preserves the inherent topology of a DNN to enable concurrent\nexecution of computationally-independent operators, resulting in reduced memory\nrequirement and improved GPU performance. In addition, we develop GraphPipe, a\ndistributed system that exploits GPP strategies to enable performant and\nscalable DNN training. GraphPipe partitions a DNN into a graph of stages,\noptimizes micro-batch schedules for these stages, and parallelizes DNN training\nusing the discovered GPP strategies. Evaluation on a variety of DNNs shows that\nGraphPipe outperforms existing pipeline-parallel systems such as PipeDream and\nPiper by up to 1.6X. GraphPipe also reduces the search time by 9-21X compared\nto PipeDream and Piper.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17145v2",
    "published_date": "2024-06-24 21:32:51 UTC",
    "updated_date": "2024-10-28 13:44:30 UTC"
  },
  {
    "arxiv_id": "2407.09527v1",
    "title": "BitNet b1.58 Reloaded: State-of-the-art Performance Also on Smaller Networks",
    "authors": [
      "Jacob Nielsen",
      "Peter Schneider-Kamp"
    ],
    "abstract": "Recently proposed methods for 1-bit and 1.58-bit quantization aware training\ninvestigate the performance and behavior of these methods in the context of\nlarge language models, finding state-of-the-art performance for models with\nmore than 3B parameters. In this work, we investigate 1.58-bit quantization for\nsmall language and vision models ranging from 100K to 48M parameters. We\nintroduce a variant of BitNet b1.58, which allows to rely on the median rather\nthan the mean in the quantization process.\n  Through extensive experiments we investigate the performance of 1.58-bit\nmodels obtained through quantization aware training. We further investigate the\nrobustness of 1.58-bit quantization-aware training to changes in the learning\nrate and regularization through weight decay, finding different patterns for\nsmall language and vision models than previously reported for large language\nmodels.\n  Our results showcase that 1.58-bit quantization-aware training provides\nstate-of-the-art performance for small language models when doubling hidden\nlayer sizes and reaches or even surpasses state-of-the-art performance for\nsmall vision models of identical size. Ultimately, we demonstrate that 1.58-bit\nquantization-aware training is a viable and promising approach also for\ntraining smaller deep learning networks, facilitating deployment of such models\nin low-resource use-cases and encouraging future research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 4 Tables, 14 grafs. Accepted to DeLTA",
    "pdf_url": "http://arxiv.org/pdf/2407.09527v1",
    "published_date": "2024-06-24 20:55:36 UTC",
    "updated_date": "2024-06-24 20:55:36 UTC"
  },
  {
    "arxiv_id": "2406.17812v1",
    "title": "Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars",
    "authors": [
      "Wesley Brewer",
      "Aditya Kashi",
      "Sajal Dash",
      "Aristeidis Tsaris",
      "Junqi Yin",
      "Mallikarjun Shankar",
      "Feiyi Wang"
    ],
    "abstract": "In a post-ChatGPT world, this paper explores the potential of leveraging\nscalable artificial intelligence for scientific discovery. We propose that\nscaling up artificial intelligence on high-performance computing platforms is\nessential to address such complex problems. This perspective focuses on\nscientific use cases like cognitive simulations, large language models for\nscientific inquiry, medical image analysis, and physics-informed approaches.\nThe study outlines the methodologies needed to address such challenges at scale\non supercomputers or the cloud and provides exemplars of such approaches\napplied to solve a variety of scientific problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.17812v1",
    "published_date": "2024-06-24 20:29:29 UTC",
    "updated_date": "2024-06-24 20:29:29 UTC"
  },
  {
    "arxiv_id": "2406.17811v2",
    "title": "CATBench: A Compiler Autotuning Benchmarking Suite for Black-box Optimization",
    "authors": [
      "Jacob O. Tørring",
      "Carl Hvarfner",
      "Luigi Nardi",
      "Magnus Själander"
    ],
    "abstract": "Bayesian optimization is a powerful method for automating tuning of\ncompilers. The complex landscape of autotuning provides a myriad of rarely\nconsidered structural challenges for black-box optimizers, and the lack of\nstandardized benchmarks has limited the study of Bayesian optimization within\nthe domain. To address this, we present CATBench, a comprehensive benchmarking\nsuite that captures the complexities of compiler autotuning, ranging from\ndiscrete, conditional, and permutation parameter types to known and unknown\nbinary constraints, as well as both multi-fidelity and multi-objective\nevaluations. The benchmarks in CATBench span a range of machine\nlearning-oriented computations, from tensor algebra to image processing and\nclustering, and uses state-of-the-art compilers, such as TACO and RISE/ELEVATE.\nCATBench offers a unified interface for evaluating Bayesian optimization\nalgorithms, promoting reproducibility and innovation through an easy-to-use,\nfully containerized setup of both surrogate and real-world compiler\noptimization tasks. We validate CATBench on several state-of-the-art\nalgorithms, revealing their strengths and weaknesses and demonstrating the\nsuite's potential for advancing both Bayesian optimization and compiler\nautotuning research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17811v2",
    "published_date": "2024-06-24 20:15:04 UTC",
    "updated_date": "2025-04-08 14:37:00 UTC"
  },
  {
    "arxiv_id": "2406.17115v2",
    "title": "Evaluating the Quality of Hallucination Benchmarks for Large Vision-Language Models",
    "authors": [
      "Bei Yan",
      "Jie Zhang",
      "Zheng Yuan",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Despite the rapid progress and outstanding performance of Large\nVision-Language Models (LVLMs) in recent years, LVLMs have been plagued by the\nissue of hallucination, i.e., LVLMs tend to generate responses that are\ninconsistent with the corresponding visual inputs. To evaluate the degree of\nhallucination in LVLMs, previous works have proposed a series of benchmarks\nfeaturing different types of tasks and evaluation metrics. However, we find\nthat the quality of the existing hallucination benchmarks varies, with some\nsuffering from problems, e.g., inconsistent evaluation results under repeated\ntests, and misalignment with human evaluation. To this end, we propose a\nHallucination benchmark Quality Measurement framework (HQM), which leverages\nvarious indicators to assess the reliability and validity of existing\nhallucination benchmarks separately. Specifically, for reliability we explore\ntest-retest reliability and parallel-forms reliability, while for validity we\nexamine criterion validity and coverage of hallucination types. Furthermore,\nbased on the results of our quality measurement, we construct a High-Quality\nHallucination Benchmark (HQH) for LVLMs, which demonstrates superior\nreliability and validity under our HQM framework. We conduct an extensive\nevaluation of over 10 representative LVLMs, including GPT-4o and\nGemini-1.5-Pro, to provide an in-depth analysis of the hallucination issues in\nexisting models. Our benchmark is publicly available at\nhttps://github.com/HQHBench/HQHBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17115v2",
    "published_date": "2024-06-24 20:08:07 UTC",
    "updated_date": "2024-10-09 10:43:47 UTC"
  },
  {
    "arxiv_id": "2406.17098v2",
    "title": "Learning Temporal Distances: Contrastive Successor Features Can Provide a Metric Structure for Decision-Making",
    "authors": [
      "Vivek Myers",
      "Chongyi Zheng",
      "Anca Dragan",
      "Sergey Levine",
      "Benjamin Eysenbach"
    ],
    "abstract": "Temporal distances lie at the heart of many algorithms for planning, control,\nand reinforcement learning that involve reaching goals, allowing one to\nestimate the transit time between two states. However, prior attempts to define\nsuch temporal distances in stochastic settings have been stymied by an\nimportant limitation: these prior approaches do not satisfy the triangle\ninequality. This is not merely a definitional concern, but translates to an\ninability to generalize and find shortest paths. In this paper, we build on\nprior work in contrastive learning and quasimetrics to show how successor\nfeatures learned by contrastive learning (after a change of variables) form a\ntemporal distance that does satisfy the triangle inequality, even in stochastic\nsettings. Importantly, this temporal distance is computationally efficient to\nestimate, even in high-dimensional and stochastic settings. Experiments in\ncontrolled settings and benchmark suites demonstrate that an RL algorithm based\non these new temporal distances exhibits combinatorial generalization (i.e.,\n\"stitching\") and can sometimes learn more quickly than prior methods, including\nthose based on quasimetrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.17098v2",
    "published_date": "2024-06-24 19:36:45 UTC",
    "updated_date": "2025-03-10 07:33:32 UTC"
  },
  {
    "arxiv_id": "2406.17096v1",
    "title": "Model-Free Robust Reinforcement Learning with Sample Complexity Analysis",
    "authors": [
      "Yudan Wang",
      "Shaofeng Zou",
      "Yue Wang"
    ],
    "abstract": "Distributionally Robust Reinforcement Learning (DR-RL) aims to derive a\npolicy optimizing the worst-case performance within a predefined uncertainty\nset. Despite extensive research, previous DR-RL algorithms have predominantly\nfavored model-based approaches, with limited availability of model-free methods\noffering convergence guarantees or sample complexities. This paper proposes a\nmodel-free DR-RL algorithm leveraging the Multi-level Monte Carlo (MLMC)\ntechnique to close such a gap. Our innovative approach integrates a threshold\nmechanism that ensures finite sample requirements for algorithmic\nimplementation, a significant improvement than previous model-free algorithms.\nWe develop algorithms for uncertainty sets defined by total variation,\nChi-square divergence, and KL divergence, and provide finite sample analyses\nunder all three cases. Remarkably, our algorithms represent the first\nmodel-free DR-RL approach featuring finite sample complexity for total\nvariation and Chi-square divergence uncertainty sets, while also offering an\nimproved sample complexity and broader applicability compared to existing\nmodel-free DR-RL algorithms for the KL divergence model. The complexities of\nour method establish the tightest results for all three uncertainty models in\nmodel-free DR-RL, underscoring the effectiveness and efficiency of our\nalgorithm, and highlighting its potential for practical applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "UAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.17096v1",
    "published_date": "2024-06-24 19:35:26 UTC",
    "updated_date": "2024-06-24 19:35:26 UTC"
  },
  {
    "arxiv_id": "2406.17092v1",
    "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
    "authors": [
      "Yi Zeng",
      "Weiyu Sun",
      "Tran Ngoc Huynh",
      "Dawn Song",
      "Bo Li",
      "Ruoxi Jia"
    ],
    "abstract": "Safety backdoor attacks in large language models (LLMs) enable the stealthy\ntriggering of unsafe behaviors while evading detection during normal\ninteractions. The high dimensionality of potential triggers in the token space\nand the diverse range of malicious behaviors make this a critical challenge. We\npresent BEEAR, a mitigation approach leveraging the insight that backdoor\ntriggers induce relatively uniform drifts in the model's embedding space. Our\nbi-level optimization method identifies universal embedding perturbations that\nelicit unwanted behaviors and adjusts the model parameters to reinforce safe\nbehaviors against these perturbations. Experiments show BEEAR reduces the\nsuccess rate of RLHF time backdoor attacks from >95% to <1% and from 47% to 0%\nfor instruction-tuning time backdoors targeting malicious code generation,\nwithout compromising model utility. Requiring only defender-defined safe and\nunwanted behaviors, BEEAR represents a step towards practical defenses against\nsafety backdoors in LLMs, providing a foundation for further advancements in AI\nsafety and security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17092v1",
    "published_date": "2024-06-24 19:29:47 UTC",
    "updated_date": "2024-06-24 19:29:47 UTC"
  },
  {
    "arxiv_id": "2406.17090v1",
    "title": "Exploring Biomarker Relationships in Both Type 1 and Type 2 Diabetes Mellitus Through a Bayesian Network Analysis Approach",
    "authors": [
      "Yuyang Sun",
      "Jingyu Lei",
      "Panagiotis Kosmas"
    ],
    "abstract": "Understanding the complex relationships of biomarkers in diabetes is pivotal\nfor advancing treatment strategies, a pressing need in diabetes research. This\nstudy applies Bayesian network structure learning to analyze the Shanghai Type\n1 and Type 2 diabetes mellitus datasets, revealing complex relationships among\nkey diabetes-related biomarkers. The constructed Bayesian network presented\nnotable predictive accuracy, particularly for Type 2 diabetes mellitus, with\nroot mean squared error (RMSE) of 18.23 mg/dL, as validated through\nleave-one-domain experiments and Clarke error grid analysis. This study not\nonly elucidates the intricate dynamics of diabetes through a deeper\nunderstanding of biomarker interplay but also underscores the significant\npotential of integrating data-driven and knowledge-driven methodologies in the\nrealm of personalized diabetes management. Such an approach paves the way for\nmore custom and effective treatment strategies, marking a notable advancement\nin the field.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Paper is accepted by EMBC 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.17090v1",
    "published_date": "2024-06-24 19:27:34 UTC",
    "updated_date": "2024-06-24 19:27:34 UTC"
  },
  {
    "arxiv_id": "2406.17073v2",
    "title": "Meta-GCN: A Dynamically Weighted Loss Minimization Method for Dealing with the Data Imbalance in Graph Neural Networks",
    "authors": [
      "Mahdi Mohammadizadeh",
      "Arash Mozhdehi",
      "Yani Ioannou",
      "Xin Wang"
    ],
    "abstract": "Although many real-world applications, such as disease prediction, and fault\ndetection suffer from class imbalance, most existing graph-based classification\nmethods ignore the skewness of the distribution of classes; therefore, tend to\nbe biased towards the majority class(es). Conventional methods typically tackle\nthis problem through the assignment of weights to each one of the class samples\nbased on a function of their loss, which can lead to over-fitting on outliers.\nIn this paper, we propose a meta-learning algorithm, named Meta-GCN, for\nadaptively learning the example weights by simultaneously minimizing the\nunbiased meta-data set loss and optimizing the model weights through the use of\na small unbiased meta-data set. Through experiments, we have shown that\nMeta-GCN outperforms state-of-the-art frameworks and other baselines in terms\nof accuracy, the area under the receiver operating characteristic (AUC-ROC)\ncurve, and macro F1-Score for classification tasks on two different datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17073v2",
    "published_date": "2024-06-24 18:59:24 UTC",
    "updated_date": "2024-06-27 18:15:16 UTC"
  },
  {
    "arxiv_id": "2406.17066v1",
    "title": "Tolerance of Reinforcement Learning Controllers against Deviations in Cyber Physical Systems",
    "authors": [
      "Changjian Zhang",
      "Parv Kapoor",
      "Eunsuk Kang",
      "Romulo Meira-Goes",
      "David Garlan",
      "Akila Ganlath",
      "Shatadal Mishra",
      "Nejib Ammar"
    ],
    "abstract": "Cyber-physical systems (CPS) with reinforcement learning (RL)-based\ncontrollers are increasingly being deployed in complex physical environments\nsuch as autonomous vehicles, the Internet-of-Things(IoT), and smart cities. An\nimportant property of a CPS is tolerance; i.e., its ability to function safely\nunder possible disturbances and uncertainties in the actual operation. In this\npaper, we introduce a new, expressive notion of tolerance that describes how\nwell a controller is capable of satisfying a desired system requirement,\nspecified using Signal Temporal Logic (STL), under possible deviations in the\nsystem. Based on this definition, we propose a novel analysis problem, called\nthe tolerance falsification problem, which involves finding small deviations\nthat result in a violation of the given requirement. We present a novel,\ntwo-layer simulation-based analysis framework and a novel search heuristic for\nfinding small tolerance violations. To evaluate our approach, we construct a\nset of benchmark problems where system parameters can be configured to\nrepresent different types of uncertainties and disturbancesin the system. Our\nevaluation shows that our falsification approach and heuristic can effectively\nfind small tolerance violations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LO",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "arXiv admin note: text overlap with arXiv:2311.07462",
    "pdf_url": "http://arxiv.org/pdf/2406.17066v1",
    "published_date": "2024-06-24 18:33:45 UTC",
    "updated_date": "2024-06-24 18:33:45 UTC"
  },
  {
    "arxiv_id": "2406.17057v1",
    "title": "At First Sight: Zero-Shot Classification of Astronomical Images with Large Multimodal Models",
    "authors": [
      "Dimitrios Tanoglidis",
      "Bhuvnesh Jain"
    ],
    "abstract": "Vision-Language multimodal Models (VLMs) offer the possibility for zero-shot\nclassification in astronomy: i.e. classification via natural language prompts,\nwith no training. We investigate two models, GPT-4o and LLaVA-NeXT, for\nzero-shot classification of low-surface brightness galaxies and artifacts, as\nwell as morphological classification of galaxies. We show that with natural\nlanguage prompts these models achieved significant accuracy (above 80 percent\ntypically) without additional training/fine tuning. We discuss areas that\nrequire improvement, especially for LLaVA-NeXT, which is an open source model.\nOur findings aim to motivate the astronomical community to consider VLMs as a\npowerful tool for both research and pedagogy, with the prospect that future\ncustom-built or fine-tuned models could perform better.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.GA",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "5 pages, 3 images. Prepared for submission to RNAAS",
    "pdf_url": "http://arxiv.org/pdf/2406.17057v1",
    "published_date": "2024-06-24 18:17:54 UTC",
    "updated_date": "2024-06-24 18:17:54 UTC"
  },
  {
    "arxiv_id": "2406.17810v1",
    "title": "PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation",
    "authors": [
      "Pingchuan Ma",
      "Haoyu Yang",
      "Zhengqi Gao",
      "Duane S. Boning",
      "Jiaqi Gu"
    ],
    "abstract": "The finite-difference time-domain (FDTD) method, which is important in\nphotonic hardware design flow, is widely adopted to solve time-domain Maxwell\nequations. However, FDTD is known for its prohibitive runtime cost, taking\nminutes to hours to simulate a single device. Recently, AI has been applied to\nrealize orders-of-magnitude speedup in partial differential equation (PDE)\nsolving. However, AI-based FDTD solvers for photonic devices have not been\nclearly formulated. Directly applying off-the-shelf models to predict the\noptical field dynamics shows unsatisfying fidelity and efficiency since the\nmodel primitives are agnostic to the unique physical properties of Maxwell\nequations and lack algorithmic customization. In this work, we thoroughly\ninvestigate the synergy between neural operator designs and the physical\nproperty of Maxwell equations and introduce a physics-inspired AI-based FDTD\nprediction framework PIC2O-Sim which features a causality-aware dynamic\nconvolutional neural operator as its backbone model that honors the space-time\ncausality constraints via careful receptive field configuration and explicitly\ncaptures the permittivity-dependent light propagation behavior via an efficient\ndynamic convolution operator. Meanwhile, we explore the trade-offs among\nprediction scalability, fidelity, and efficiency via a multi-stage partitioned\ntime-bundling technique in autoregressive prediction. Multiple key techniques\nhave been introduced to mitigate iterative error accumulation while maintaining\nefficiency advantages during autoregressive field prediction. Extensive\nevaluations on three challenging photonic device simulation tasks have shown\nthe superiority of our PIC2O-Sim method, showing 51.2% lower roll-out\nprediction error, 23.5 times fewer parameters than state-of-the-art neural\noperators, providing 300-600x higher simulation speed than an open-source FDTD\nnumerical solver.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "physics.optics"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17810v1",
    "published_date": "2024-06-24 18:15:36 UTC",
    "updated_date": "2024-06-24 18:15:36 UTC"
  },
  {
    "arxiv_id": "2406.17055v4",
    "title": "Large Language Models Assume People are More Rational than We Really are",
    "authors": [
      "Ryan Liu",
      "Jiayi Geng",
      "Joshua C. Peterson",
      "Ilia Sucholutsky",
      "Thomas L. Griffiths"
    ],
    "abstract": "In order for AI systems to communicate effectively with people, they must\nunderstand how we make decisions. However, people's decisions are not always\nrational, so the implicit internal models of human decision-making in Large\nLanguage Models (LLMs) must account for this. Previous empirical evidence seems\nto suggest that these implicit models are accurate -- LLMs offer believable\nproxies of human behavior, acting how we expect humans would in everyday\ninteractions. However, by comparing LLM behavior and predictions to a large\ndataset of human decisions, we find that this is actually not the case: when\nboth simulating and predicting people's choices, a suite of cutting-edge LLMs\n(GPT-4o & 4-Turbo, Llama-3-8B & 70B, Claude 3 Opus) assume that people are more\nrational than we really are. Specifically, these models deviate from human\nbehavior and align more closely with a classic model of rational choice --\nexpected value theory. Interestingly, people also tend to assume that other\npeople are rational when interpreting their behavior. As a consequence, when we\ncompare the inferences that LLMs and people draw from the decisions of others\nusing another psychological dataset, we find that these inferences are highly\ncorrelated. Thus, the implicit decision-making models of LLMs appear to be\naligned with the human expectation that other people will act rationally,\nrather than with how people actually act.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17055v4",
    "published_date": "2024-06-24 18:15:27 UTC",
    "updated_date": "2025-03-10 17:42:37 UTC"
  },
  {
    "arxiv_id": "2406.16864v1",
    "title": "StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal",
    "authors": [
      "Chongjie Ye",
      "Lingteng Qiu",
      "Xiaodong Gu",
      "Qi Zuo",
      "Yushuang Wu",
      "Zilong Dong",
      "Liefeng Bo",
      "Yuliang Xiu",
      "Xiaoguang Han"
    ],
    "abstract": "This work addresses the challenge of high-quality surface normal estimation\nfrom monocular colored inputs (i.e., images and videos), a field which has\nrecently been revolutionized by repurposing diffusion priors. However, previous\nattempts still struggle with stochastic inference, conflicting with the\ndeterministic nature of the Image2Normal task, and costly ensembling step,\nwhich slows down the estimation process. Our method, StableNormal, mitigates\nthe stochasticity of the diffusion process by reducing inference variance, thus\nproducing \"Stable-and-Sharp\" normal estimates without any additional ensembling\nprocess. StableNormal works robustly under challenging imaging conditions, such\nas extreme lighting, blurring, and low quality. It is also robust against\ntransparent and reflective surfaces, as well as cluttered scenes with numerous\nobjects. Specifically, StableNormal employs a coarse-to-fine strategy, which\nstarts with a one-step normal estimator (YOSO) to derive an initial normal\nguess, that is relatively coarse but reliable, then followed by a\nsemantic-guided refinement process (SG-DRN) that refines the normals to recover\ngeometric details. The effectiveness of StableNormal is demonstrated through\ncompetitive performance in standard datasets such as DIODE-indoor, iBims,\nScannetV2 and NYUv2, and also in various downstream tasks, such as surface\nreconstruction and normal enhancement. These results evidence that StableNormal\nretains both the \"stability\" and \"sharpness\" for accurate normal estimation.\nStableNormal represents a baby attempt to repurpose diffusion priors for\ndeterministic estimation. To democratize this, code and models have been\npublicly available in hf.co/Stable-X",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "HF Demo: hf.co/Stable-X, Video:\n  https://www.youtube.com/watch?v=sylXTxG_U2U",
    "pdf_url": "http://arxiv.org/pdf/2406.16864v1",
    "published_date": "2024-06-24 17:59:58 UTC",
    "updated_date": "2024-06-24 17:59:58 UTC"
  },
  {
    "arxiv_id": "2406.16853v1",
    "title": "GeoMFormer: A General Architecture for Geometric Molecular Representation Learning",
    "authors": [
      "Tianlang Chen",
      "Shengjie Luo",
      "Di He",
      "Shuxin Zheng",
      "Tie-Yan Liu",
      "Liwei Wang"
    ],
    "abstract": "Molecular modeling, a central topic in quantum mechanics, aims to accurately\ncalculate the properties and simulate the behaviors of molecular systems. The\nmolecular model is governed by physical laws, which impose geometric\nconstraints such as invariance and equivariance to coordinate rotation and\ntranslation. While numerous deep learning approaches have been developed to\nlearn molecular representations under these constraints, most of them are built\nupon heuristic and costly modules. We argue that there is a strong need for a\ngeneral and flexible framework for learning both invariant and equivariant\nfeatures. In this work, we introduce a novel Transformer-based molecular model\ncalled GeoMFormer to achieve this goal. Using the standard Transformer modules,\ntwo separate streams are developed to maintain and learn invariant and\nequivariant representations. Carefully designed cross-attention modules bridge\nthe two streams, allowing information fusion and enhancing geometric modeling\nin each stream. As a general and flexible architecture, we show that many\nprevious architectures can be viewed as special instantiations of GeoMFormer.\nExtensive experiments are conducted to demonstrate the power of GeoMFormer. All\nempirical results show that GeoMFormer achieves strong performance on both\ninvariant and equivariant tasks of different types and scales. Code and models\nwill be made publicly available at https://github.com/c-tl/GeoMFormer.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 13 tables, l figure; ICML 2024 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2406.16853v1",
    "published_date": "2024-06-24 17:58:13 UTC",
    "updated_date": "2024-06-24 17:58:13 UTC"
  },
  {
    "arxiv_id": "2406.16851v3",
    "title": "Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts",
    "authors": [
      "Aditya Sharma",
      "Michael Saxon",
      "William Yang Wang"
    ],
    "abstract": "We present LoCoVQA, a dynamic benchmark generator for evaluating long-context\nextractive reasoning in vision language models (VLMs). LoCoVQA augments test\nexamples for mathematical reasoning, VQA, and character recognition tasks with\nincreasingly long visual contexts composed of both in-distribution and\nout-of-distribution distractor images.\n  Across these tasks, a diverse set of VLMs rapidly lose performance as the\nvisual context length grows, often exhibiting a striking logarithmic decay\ntrend. This test assesses how well VLMs can ignore irrelevant information when\nanswering queries -- a task that is quite easy for language models (LMs) in the\ntext domain -- demonstrating that current state-of-the-art VLMs lack this\nessential capability for many long-context applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16851v3",
    "published_date": "2024-06-24 17:58:03 UTC",
    "updated_date": "2024-10-04 01:58:06 UTC"
  },
  {
    "arxiv_id": "2407.10996v1",
    "title": "Visualization Literacy of Multimodal Large Language Models: A Comparative Study",
    "authors": [
      "Zhimin Li",
      "Haichao Miao",
      "Valerio Pascucci",
      "Shusen Liu"
    ],
    "abstract": "The recent introduction of multimodal large language models (MLLMs) combine\nthe inherent power of large language models (LLMs) with the renewed\ncapabilities to reason about the multimodal context. The potential usage\nscenarios for MLLMs significantly outpace their text-only counterparts. Many\nrecent works in visualization have demonstrated MLLMs' capability to understand\nand interpret visualization results and explain the content of the\nvisualization to users in natural language. In the machine learning community,\nthe general vision capabilities of MLLMs have been evaluated and tested through\nvarious visual understanding benchmarks. However, the ability of MLLMs to\naccomplish specific visualization tasks based on visual perception has not been\nproperly explored and evaluated, particularly, from a visualization-centric\nperspective.\n  In this work, we aim to fill the gap by utilizing the concept of\nvisualization literacy to evaluate MLLMs. We assess MLLMs' performance over two\npopular visualization literacy evaluation datasets (VLAT and mini-VLAT). Under\nthe framework of visualization literacy, we develop a general setup to compare\ndifferent multimodal large language models (e.g., GPT4-o, Claude 3 Opus, Gemini\n1.5 Pro) as well as against existing human baselines. Our study demonstrates\nMLLMs' competitive performance in visualization literacy, where they outperform\nhumans in certain tasks such as identifying correlations, clusters, and\nhierarchical structures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.10996v1",
    "published_date": "2024-06-24 17:52:16 UTC",
    "updated_date": "2024-06-24 17:52:16 UTC"
  },
  {
    "arxiv_id": "2407.02520v1",
    "title": "RaCIL: Ray Tracing based Multi-UAV Obstacle Avoidance through Composite Imitation Learning",
    "authors": [
      "Harsh Bansal",
      "Vyom Goyal",
      "Bhaskar Joshi",
      "Akhil Gupta",
      "Harikumar Kandath"
    ],
    "abstract": "In this study, we address the challenge of obstacle avoidance for Unmanned\nAerial Vehicles (UAVs) through an innovative composite imitation learning\napproach that combines Proximal Policy Optimization (PPO) with Behavior Cloning\n(BC) and Generative Adversarial Imitation Learning (GAIL), enriched by the\nintegration of ray-tracing techniques. Our research underscores the significant\nrole of ray-tracing in enhancing obstacle detection and avoidance capabilities.\nMoreover, we demonstrate the effectiveness of incorporating GAIL in\ncoordinating the flight paths of two UAVs, showcasing improved collision\navoidance capabilities. Extending our methodology, we apply our combined PPO,\nBC, GAIL, and ray-tracing framework to scenarios involving four UAVs,\nillustrating its scalability and adaptability to more complex scenarios. The\nfindings indicate that our approach not only improves the reliability of basic\nPPO based obstacle avoidance but also paves the way for advanced autonomous UAV\noperations in crowded or dynamic environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02520v1",
    "published_date": "2024-06-24 17:43:24 UTC",
    "updated_date": "2024-06-24 17:43:24 UTC"
  },
  {
    "arxiv_id": "2406.16833v1",
    "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
    "authors": [
      "Mounika Marreddy",
      "Subba Reddy Oota",
      "Venkata Charan Chinni",
      "Manish Gupta",
      "Lucie Flek"
    ],
    "abstract": "Identifying user's opinions and stances in long conversation threads on\nvarious topics can be extremely critical for enhanced personalization, market\nresearch, political campaigns, customer service, conflict resolution, targeted\nadvertising, and content moderation. Hence, training language models to\nautomate this task is critical. However, to train such models, gathering manual\nannotations has multiple challenges: 1) It is time-consuming and costly; 2)\nConversation threads could be very long, increasing chances of noisy\nannotations; and 3) Interpreting instances where a user changes their opinion\nwithin a conversation is difficult because often such transitions are subtle\nand not expressed explicitly. Inspired by the recent success of large language\nmodels (LLMs) for complex natural language processing (NLP) tasks, we leverage\nMistral Large and GPT-4 to automate the human annotation process on the\nfollowing two tasks while also providing reasoning: i) User Stance\nclassification, which involves labeling a user's stance of a post in a\nconversation on a five-point scale; ii) User Dogmatism classification, which\ndeals with labeling a user's overall opinion in the conversation on a\nfour-point scale. The majority voting on zero-shot, one-shot, and few-shot\nannotations from these two LLMs on 764 multi-user Reddit conversations helps us\ncurate the USDC dataset. USDC is then used to finetune and instruction-tune\nmultiple deployable small language models for the 5-class stance and 4-class\ndogmatism classification tasks. We make the code and dataset publicly available\n[https://anonymous.4open.science/r/USDC-0F7F].",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16833v1",
    "published_date": "2024-06-24 17:41:53 UTC",
    "updated_date": "2024-06-24 17:41:53 UTC"
  },
  {
    "arxiv_id": "2406.16829v2",
    "title": "Understanding and Mitigating Tokenization Bias in Language Models",
    "authors": [
      "Buu Phan",
      "Marton Havasi",
      "Matthew Muckley",
      "Karen Ullrich"
    ],
    "abstract": "State-of-the-art language models are autoregressive and operate on subword\nunits known as tokens. Specifically, one must encode the conditioning string\ninto a list of tokens before passing to the language models for next-token\nprediction. We show that popular encoding schemes, such as maximum prefix\nencoding (MPE) and byte-pair-encoding (BPE), induce a sampling bias that cannot\nbe mitigated with more training or data. To counter this universal problem, for\neach encoding scheme above, we propose a novel algorithm to obtain unbiased\nestimates from any language model trained on tokenized data. Our methods do not\nrequire finetuning the model, and the complexity, defined as the number of\nmodel runs, scales linearly with the sequence length in the case of MPE. As a\nresult, we show that one can simulate token-free behavior from a tokenized\nlanguage model. We empirically verify the correctness of our method through a\nMarkov-chain setup, where it accurately recovers the transition probabilities,\nas opposed to the conventional method of directly prompting tokens into the\nlanguage model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16829v2",
    "published_date": "2024-06-24 17:38:02 UTC",
    "updated_date": "2024-07-05 21:49:08 UTC"
  },
  {
    "arxiv_id": "2406.16828v1",
    "title": "Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
    "authors": [
      "Ronak Pradeep",
      "Nandan Thakur",
      "Sahel Sharifymoghaddam",
      "Eric Zhang",
      "Ryan Nguyen",
      "Daniel Campos",
      "Nick Craswell",
      "Jimmy Lin"
    ],
    "abstract": "Did you try out the new Bing Search? Or maybe you fiddled around with Google\nAI~Overviews? These might sound familiar because the modern-day search stack\nhas recently evolved to include retrieval-augmented generation (RAG) systems.\nThey allow searching and incorporating real-time data into large language\nmodels (LLMs) to provide a well-informed, attributed, concise summary in\ncontrast to the traditional search paradigm that relies on displaying a ranked\nlist of documents. Therefore, given these recent advancements, it is crucial to\nhave an arena to build, test, visualize, and systematically evaluate RAG-based\nsearch systems. With this in mind, we propose the TREC 2024 RAG Track to foster\ninnovation in evaluating RAG systems. In our work, we lay out the steps we've\nmade towards making this track a reality -- we describe the details of our\nreusable framework, Ragnar\\\"ok, explain the curation of the new MS MARCO V2.1\ncollection choice, release the development topics for the track, and\nstandardize the I/O definitions which assist the end user. Next, using\nRagnar\\\"ok, we identify and provide key industrial baselines such as OpenAI's\nGPT-4o or Cohere's Command R+. Further, we introduce a web-based user interface\nfor an interactive arena allowing benchmarking pairwise RAG systems by\ncrowdsourcing. We open-source our Ragnar\\\"ok framework and baselines to achieve\na unified standard for future RAG systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16828v1",
    "published_date": "2024-06-24 17:37:52 UTC",
    "updated_date": "2024-06-24 17:37:52 UTC"
  },
  {
    "arxiv_id": "2406.16821v1",
    "title": "General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design",
    "authors": [
      "Yue Jian",
      "Curtis Wu",
      "Danny Reidenbach",
      "Aditi S. Krishnapriyan"
    ],
    "abstract": "Structure-Based Drug Design (SBDD) focuses on generating valid ligands that\nstrongly and specifically bind to a designated protein pocket. Several methods\nuse machine learning for SBDD to generate these ligands in 3D space,\nconditioned on the structure of a desired protein pocket. Recently, diffusion\nmodels have shown success here by modeling the underlying distributions of\natomic positions and types. While these methods are effective in considering\nthe structural details of the protein pocket, they often fail to explicitly\nconsider the binding affinity. Binding affinity characterizes how tightly the\nligand binds to the protein pocket, and is measured by the change in free\nenergy associated with the binding process. It is one of the most crucial\nmetrics for benchmarking the effectiveness of the interaction between a ligand\nand protein pocket. To address this, we propose BADGER: Binding Affinity\nDiffusion Guidance with Enhanced Refinement. BADGER is a general guidance\nmethod to steer the diffusion sampling process towards improved protein-ligand\nbinding, allowing us to adjust the distribution of the binding affinity between\nligands and proteins. Our method is enabled by using a neural network (NN) to\nmodel the energy function, which is commonly approximated by AutoDock Vina\n(ADV). ADV's energy function is non-differentiable, and estimates the affinity\nbased on the interactions between a ligand and target protein receptor. By\nusing a NN as a differentiable energy function proxy, we utilize the gradient\nof our learned energy function as a guidance method on top of any trained\ndiffusion model. We show that our method improves the binding affinity of\ngenerated ligands to their protein receptors by up to 60\\%, significantly\nsurpassing previous machine learning methods. We also show that our guidance\nmethod is flexible and can be easily applied to other diffusion-based SBDD\nframeworks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16821v1",
    "published_date": "2024-06-24 17:31:41 UTC",
    "updated_date": "2024-06-24 17:31:41 UTC"
  },
  {
    "arxiv_id": "2406.16810v2",
    "title": "How Data Inter-connectivity Shapes LLMs Unlearning: A Structural Unlearning Perspective",
    "authors": [
      "Xinchi Qiu",
      "William F. Shen",
      "Yihong Chen",
      "Meghdad Kurmanji",
      "Nicola Cancedda",
      "Pontus Stenetorp",
      "Nicholas D. Lane"
    ],
    "abstract": "While unlearning knowledge from large language models (LLMs) is receiving\nincreasing attention, one important aspect remains unexplored. Existing\napproaches and benchmarks assume data points to-be-forgotten are independent,\nignoring their inter-connectivity - a fundamental characteristic of real-world\ndata structures. In this paper, we propose PISTOL, a method for compiling\nstructural datasets. PISTOL leverages the inherently structured nature of\ncontractual relationships, offering several key benefits. First, it enables\ninsights into the impact of structural data on unlearning effectiveness.\nSecond, it provides precise and concise ground truths for clearer evaluation.\nThird, its attribute generation does not require input from pre-trained LLMs,\nmitigating confounding risks. Leveraging datasets synthesized using PISTOL, we\ndemonstrate how data inter-connectivity impacts LLM unlearning. Specifically,\n(a) in both the pre-trained and fine-tuned models, unlearning difficulty\nincreases as data inter-connectivity grows, (b) there is a positive correlation\nbetween the density of the knowledge graph and unlearning difficulty, and (c)\nwhen the to-be-forgotten data is skewed towards one domain, balancing retaining\nperformance across all domains is challenging.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16810v2",
    "published_date": "2024-06-24 17:22:36 UTC",
    "updated_date": "2025-03-10 21:33:53 UTC"
  },
  {
    "arxiv_id": "2406.16797v2",
    "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs",
    "authors": [
      "Ashwinee Panda",
      "Berivan Isik",
      "Xiangyu Qi",
      "Sanmi Koyejo",
      "Tsachy Weissman",
      "Prateek Mittal"
    ],
    "abstract": "Existing methods for adapting large language models (LLMs) to new tasks are\nnot suited to multi-task adaptation because they modify all the model weights\n-- causing destructive interference between tasks. The resulting effects, such\nas catastrophic forgetting of earlier tasks, make it challenging to obtain good\nperformance on multiple tasks at the same time. To mitigate this, we propose\nLottery Ticket Adaptation (LoTA), a sparse adaptation method that identifies\nand optimizes only a sparse subnetwork of the model. We evaluate LoTA on a wide\nrange of challenging tasks such as instruction following, reasoning, math, and\nsummarization. LoTA obtains better performance than full fine-tuning and\nlow-rank adaptation (LoRA), and maintains good performance even after training\non other tasks -- thus, avoiding catastrophic forgetting. By extracting and\nfine-tuning over lottery tickets (or sparse task vectors), LoTA also enables\nmodel merging over highly dissimilar tasks. Our code is made publicly available\nat https://github.com/kiddyboots216/lottery-ticket-adaptation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16797v2",
    "published_date": "2024-06-24 16:58:23 UTC",
    "updated_date": "2024-06-25 13:46:41 UTC"
  },
  {
    "arxiv_id": "2406.16793v7",
    "title": "Adam-mini: Use Fewer Learning Rates To Gain More",
    "authors": [
      "Yushun Zhang",
      "Congliang Chen",
      "Ziniu Li",
      "Tian Ding",
      "Chenwei Wu",
      "Diederik P. Kingma",
      "Yinyu Ye",
      "Zhi-Quan Luo",
      "Ruoyu Sun"
    ],
    "abstract": "We propose Adam-mini, an optimizer that achieves on par or better performance\nthan AdamW with 50% less memory footprint. Adam-mini reduces memory by cutting\ndown the learning rate resources in Adam (i.e., $1/\\sqrt{v}$). By investigating\nthe Hessian structure of neural nets, we find Adam's $v$ might not function at\nits full potential as effectively as we expected. We find that $\\geq$ 99.9% of\nthese learning rates in $v$ could be harmlessly removed if we (1) carefully\npartition the parameters into blocks following our new principle on Hessian\nstructure; (2) assign a single but good learning rate to each parameter block.\nWe then provide one simple way to find good learning rates and propose\nAdam-mini. Empirically, we verify that Adam-mini performs on par or better than\nAdamW on various language models sized from 39M to 13B for pre-training,\nsupervised fine-tuning, and RLHF. The reduced memory footprint of Adam-mini\nalso alleviates communication overheads among GPUs, thereby increasing\nthroughput. For instance, Adam-mini achieves 49.6% higher throughput than AdamW\nwhen pre-training Llama 2-7B on $2\\times$ A800-80GB GPUs, which saves 33%\nwall-clock time for pre-training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16793v7",
    "published_date": "2024-06-24 16:56:41 UTC",
    "updated_date": "2025-02-24 11:29:08 UTC"
  },
  {
    "arxiv_id": "2406.16784v1",
    "title": "The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers",
    "authors": [
      "Abhi Kamboj"
    ],
    "abstract": "The transformer neural network architecture allows for autoregressive\nsequence-to-sequence modeling through the use of attention layers. It was\noriginally created with the application of machine translation but has\nrevolutionized natural language processing. Recently, transformers have also\nbeen applied across a wide variety of pattern recognition tasks, particularly\nin computer vision. In this literature review, we describe major advances in\ncomputer vision utilizing transformers. We then focus specifically on\nMulti-Object Tracking (MOT) and discuss how transformers are increasingly\nbecoming competitive in state-of-the-art MOT works, yet still lag behind\ntraditional deep learning methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This report was written in November 2022, and may not contain more\n  recent works since then",
    "pdf_url": "http://arxiv.org/pdf/2406.16784v1",
    "published_date": "2024-06-24 16:45:28 UTC",
    "updated_date": "2024-06-24 16:45:28 UTC"
  },
  {
    "arxiv_id": "2406.16783v3",
    "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
    "authors": [
      "Rishabh Maheshwary",
      "Vikas Yadav",
      "Hoang Nguyen",
      "Khyati Mahajan",
      "Sathwik Tejaswi Madhusudhan"
    ],
    "abstract": "Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "39 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.16783v3",
    "published_date": "2024-06-24 16:45:13 UTC",
    "updated_date": "2025-03-04 07:56:00 UTC"
  },
  {
    "arxiv_id": "2406.16777v1",
    "title": "Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024",
    "authors": [
      "Sai Koneru",
      "Thai-Binh Nguyen",
      "Ngoc-Quan Pham",
      "Danni Liu",
      "Zhaolin Li",
      "Alexander Waibel",
      "Jan Niehues"
    ],
    "abstract": "Large Language Models (LLMs) are currently under exploration for various\ntasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),\nand even End-to-End Speech Translation (ST). In this paper, we present KIT's\noffline submission in the constrained + LLM track by incorporating recently\nproposed techniques that can be added to any cascaded speech translation.\nSpecifically, we integrate\nMistral-7B\\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system to\nenhance it in two ways. Firstly, we refine the ASR outputs by utilizing the\nN-best lists generated by our system and fine-tuning the LLM to predict the\ntranscript accurately. Secondly, we refine the MT outputs at the document level\nby fine-tuning the LLM, leveraging both ASR and MT predictions to improve\ntranslation quality. We find that integrating the LLM into the ASR and MT\nsystems results in an absolute improvement of $0.3\\%$ in Word Error Rate and\n$0.65\\%$ in COMET for tst2019 test set. In challenging test sets with\noverlapping speakers and background noise, we find that integrating LLM is not\nbeneficial due to poor ASR performance. Here, we use ASR with chunked long-form\ndecoding to improve context usage that may be unavailable when transcribing\nwith Voice Activity Detection segmentation alone.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16777v1",
    "published_date": "2024-06-24 16:38:17 UTC",
    "updated_date": "2024-06-24 16:38:17 UTC"
  },
  {
    "arxiv_id": "2406.16772v2",
    "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
    "authors": [
      "Zhen Huang",
      "Zengzhi Wang",
      "Shijie Xia",
      "Pengfei Liu"
    ],
    "abstract": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.16772v2",
    "published_date": "2024-06-24 16:31:12 UTC",
    "updated_date": "2024-06-26 15:00:04 UTC"
  },
  {
    "arxiv_id": "2407.12804v2",
    "title": "Modulating Language Model Experiences through Frictions",
    "authors": [
      "Katherine M. Collins",
      "Valerie Chen",
      "Ilia Sucholutsky",
      "Hannah Rose Kirk",
      "Malak Sadek",
      "Holli Sargeant",
      "Ameet Talwalkar",
      "Adrian Weller",
      "Umang Bhatt"
    ],
    "abstract": "Language models are transforming the ways that their users engage with the\nworld. Despite impressive capabilities, over-consumption of language model\noutputs risks propagating unchecked errors in the short-term and damaging human\ncapabilities for critical thinking in the long-term. How can we develop\nscaffolding around language models to curate more appropriate use? We propose\nselective frictions for language model experiences, inspired by behavioral\nscience interventions, to dampen misuse. Frictions involve small modifications\nto a user's experience, e.g., the addition of a button impeding model access\nand reminding a user of their expertise relative to the model. Through a user\nstudy with real humans, we observe shifts in user behavior from the imposition\nof a friction over LLMs in the context of a multi-topic question-answering task\nas a representative task that people may use LLMs for, e.g., in education and\ninformation retrieval. We find that frictions modulate over-reliance by driving\ndown users' click rates while minimally affecting accuracy for those topics.\nYet, frictions may have unintended effects. We find marked differences in\nusers' click behaviors even on topics where frictions were not provisioned. Our\ncontributions motivate further study of human-AI behavioral interaction to\ninform more effective and appropriate LLM use.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "NeurIPS Workshop on Behavioral ML; non-archival",
    "pdf_url": "http://arxiv.org/pdf/2407.12804v2",
    "published_date": "2024-06-24 16:31:11 UTC",
    "updated_date": "2024-11-18 15:41:24 UTC"
  },
  {
    "arxiv_id": "2406.16768v1",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "authors": [
      "Alexandre Ramé",
      "Johan Ferret",
      "Nino Vieillard",
      "Robert Dadashi",
      "Léonard Hussenot",
      "Pierre-Louis Cedoz",
      "Pier Giuseppe Sessa",
      "Sertan Girgin",
      "Arthur Douillard",
      "Olivier Bachem"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) aligns large language\nmodels (LLMs) by encouraging their generations to have high rewards, using a\nreward model trained on human preferences. To prevent the forgetting of\npre-trained knowledge, RLHF usually incorporates a KL regularization; this\nforces the policy to remain close to its supervised fine-tuned initialization,\nthough it hinders the reward optimization. To tackle the trade-off between KL\nand reward, in this paper we introduce a novel alignment strategy named Weight\nAveraged Rewarded Policies (WARP). WARP merges policies in the weight space at\nthree distinct stages. First, it uses the exponential moving average of the\npolicy as a dynamic anchor in the KL regularization. Second, it applies\nspherical interpolation to merge independently fine-tuned policies into a new\nenhanced one. Third, it linearly interpolates between this merged model and the\ninitialization, to recover features from pre-training. This procedure is then\napplied iteratively, with each iteration's final model used as an advanced\ninitialization for the next, progressively refining the KL-reward Pareto front,\nachieving superior rewards at fixed KL. Experiments with GEMMA policies\nvalidate that WARP improves their quality and alignment, outperforming other\nopen-source LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 main pages (34 pages with Appendix)",
    "pdf_url": "http://arxiv.org/pdf/2406.16768v1",
    "published_date": "2024-06-24 16:24:34 UTC",
    "updated_date": "2024-06-24 16:24:34 UTC"
  },
  {
    "arxiv_id": "2406.16756v1",
    "title": "Addressing Polarization and Unfairness in Performative Prediction",
    "authors": [
      "Kun Jin",
      "Tian Xie",
      "Yang Liu",
      "Xueru Zhang"
    ],
    "abstract": "When machine learning (ML) models are used in applications that involve\nhumans (e.g., online recommendation, school admission, hiring, lending), the\nmodel itself may trigger changes in the distribution of targeted data it aims\nto predict. Performative prediction (PP) is a framework that explicitly\nconsiders such model-dependent distribution shifts when learning ML models.\nWhile significant efforts have been devoted to finding performative stable (PS)\nsolutions in PP for system robustness, their societal implications are less\nexplored and it is unclear whether PS solutions are aligned with social norms\nsuch as fairness. In this paper, we set out to examine the fairness property of\nPS solutions in performative prediction. We first show that PS solutions can\nincur severe polarization effects and group-wise loss disparity. Although\nexisting fairness mechanisms commonly used in literature can help mitigate\nunfairness, they may fail and disrupt the stability under model-dependent\ndistribution shifts. We thus propose novel fairness intervention mechanisms\nthat can simultaneously achieve both stability and fairness in PP settings.\nBoth theoretical analysis and experiments are provided to validate the proposed\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16756v1",
    "published_date": "2024-06-24 16:03:57 UTC",
    "updated_date": "2024-06-24 16:03:57 UTC"
  },
  {
    "arxiv_id": "2406.16746v4",
    "title": "The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources",
    "authors": [
      "Shayne Longpre",
      "Stella Biderman",
      "Alon Albalak",
      "Hailey Schoelkopf",
      "Daniel McDuff",
      "Sayash Kapoor",
      "Kevin Klyman",
      "Kyle Lo",
      "Gabriel Ilharco",
      "Nay San",
      "Maribeth Rauh",
      "Aviya Skowron",
      "Bertie Vidgen",
      "Laura Weidinger",
      "Arvind Narayanan",
      "Victor Sanh",
      "David Adelani",
      "Percy Liang",
      "Rishi Bommasani",
      "Peter Henderson",
      "Sasha Luccioni",
      "Yacine Jernite",
      "Luca Soldaini"
    ],
    "abstract": "Foundation model development attracts a rapidly expanding body of\ncontributors, scientists, and applications. To help shape responsible\ndevelopment practices, we introduce the Foundation Model Development\nCheatsheet: a growing collection of 250+ tools and resources spanning text,\nvision, and speech modalities. We draw on a large body of prior work to survey\nresources (e.g. software, documentation, frameworks, guides, and practical\ntools) that support informed data selection, processing, and understanding,\nprecise and limitation-aware artifact documentation, efficient model training,\nadvance awareness of the environmental impact from training, careful model\nevaluation of capabilities, risks, and claims, as well as responsible model\nrelease, licensing and deployment practices. We hope this curated collection of\nresources helps guide more responsible development. The process of curating\nthis list, enabled us to review the AI development ecosystem, revealing what\ntools are critically missing, misused, or over-used in existing practices. We\nfind that (i) tools for data sourcing, model evaluation, and monitoring are\ncritically under-serving ethical and real-world needs, (ii) evaluations for\nmodel safety, capabilities, and environmental impact all lack reproducibility\nand transparency, (iii) text and particularly English-centric analyses continue\nto dominate over multilingual and multi-modal analyses, and (iv) evaluation of\nsystems, rather than just models, is needed so that capabilities and impact are\nassessed in context.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16746v4",
    "published_date": "2024-06-24 15:55:49 UTC",
    "updated_date": "2025-02-17 00:31:25 UTC"
  },
  {
    "arxiv_id": "2406.16745v2",
    "title": "Bandits with Preference Feedback: A Stackelberg Game Perspective",
    "authors": [
      "Barna Pásztor",
      "Parnian Kassraie",
      "Andreas Krause"
    ],
    "abstract": "Bandits with preference feedback present a powerful tool for optimizing\nunknown target functions when only pairwise comparisons are allowed instead of\ndirect value queries. This model allows for incorporating human feedback into\nonline inference and optimization and has been employed in systems for\nfine-tuning large language models. The problem is well understood in simplified\nsettings with linear target functions or over finite small domains that limit\npractical interest. Taking the next step, we consider infinite domains and\nnonlinear (kernelized) rewards. In this setting, selecting a pair of actions is\nquite challenging and requires balancing exploration and exploitation at two\nlevels: within the pair, and along the iterations of the algorithm. We propose\nMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and\nchooses action pairs that are informative and yield favorable rewards.\nMAXMINLCB consistently outperforms existing algorithms and satisfies an\nanytime-valid rate-optimal regret guarantee. This is due to our novel\npreference-based confidence sequences for kernelized logistic estimators.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 38th Conference on Neural Information\n  Processing Systems (NeurIPS), 30 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16745v2",
    "published_date": "2024-06-24 15:53:11 UTC",
    "updated_date": "2024-10-30 17:10:52 UTC"
  },
  {
    "arxiv_id": "2406.16741v2",
    "title": "Extracting thin film structures of energy materials using transformers",
    "authors": [
      "Chen Zhang",
      "Valerie A. Niemann",
      "Peter Benedek",
      "Thomas F. Jaramillo",
      "Mathieu Doucet"
    ],
    "abstract": "Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),\na neural network model using transformer architecture, is introduced for\nneutron reflectometry data analysis. It offers fast, accurate initial parameter\nestimations and efficient refinements, improving efficiency and precision for\nreal-time data analysis of lithium-mediated nitrogen reduction for\nelectrochemical ammonia synthesis, with relevance to other chemical\ntransformations and batteries. Despite limitations in generalizing across\nsystems, it shows promises for the use of transformers as the basis for models\nthat could replace trial-and-error approaches to modeling reflectometry data.",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16741v2",
    "published_date": "2024-06-24 15:48:19 UTC",
    "updated_date": "2024-10-30 17:44:53 UTC"
  },
  {
    "arxiv_id": "2406.16738v2",
    "title": "Inducing Group Fairness in Prompt-Based Language Model Decisions",
    "authors": [
      "James Atwood",
      "Nino Scherrer",
      "Preethi Lahoti",
      "Ananth Balashankar",
      "Flavien Prost",
      "Ahmad Beirami"
    ],
    "abstract": "Classifiers are used throughout industry to enforce policies, ranging from\nthe detection of toxic content to age-appropriate content filtering. While\nthese classifiers serve important functions, it is also essential that they are\nbuilt in ways that minimize unfair biases for users.\n  One such fairness consideration is called group fairness, which desires that\ndifferent sub-population of users receive equal treatment. This is a\nwell-studied problem in the context of 'classical' classifiers. However, the\nemergence of prompt-based language model (LM) decision making has created new\nopportunities to solve text-based classification tasks, and the fairness\nproperties of these new classifiers are not yet well understood. Further, the\n`remediation toolkit' is incomplete for LM-based decision makers and little is\nunderstood about how to improve decision maker group fairness while maintaining\nclassifier performance.\n  This work sets out to add more tools to that toolbox. We introduce\nadaptations of existing effective approaches from the classical classifier\nfairness to the prompt-based classifier space. We also devise simple methods\nthat take advantage of the new structure of prompt-based decision makers and\noperate at the prompt level. We compare these approaches empirically on real\ndata. Our results suggest that adaptations of approaches that are effective for\nclassical classifiers remain effective in the LM-based classifier environment.\nHowever, there is room for further exploration of prompt-based remediation\nmethods (and other remediation methods that take advantage of LM structure).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16738v2",
    "published_date": "2024-06-24 15:45:20 UTC",
    "updated_date": "2024-12-02 18:27:02 UTC"
  },
  {
    "arxiv_id": "2406.16730v1",
    "title": "Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument)",
    "authors": [
      "Julien Taran"
    ],
    "abstract": "DESI is a groundbreaking international project to observe more than 40\nmillion quasars and galaxies over a 5-year period to create a 3D map of the\nsky. This map will enable us to probe multiple aspects of cosmology, from dark\nenergy to neutrino mass. We are focusing here on one type of object observed by\nDESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra to\ndetermine whether they are indeed LBGs, and if so, to determine their distance\nfrom the Earth using a phenomenon called redshift. This will enable us to place\nthese galaxies on the DESI 3D map.\n  The aim is therefore to develop a convolutional neural network (CNN) inspired\nby QuasarNET (See arXiv:1808.09955), performing simultaneously a classification\n(LBG type or not) and a regression task (determine the redshift of the LBGs).\nInitially, data augmentation techniques such as shifting the spectra in\nwavelengths, adding noise to the spectra, or adding synthetic spectra were used\nto increase the model training dataset from 3,019 data to over 66,000. In a\nsecond phase, modifications to the QuasarNET architecture, notably through\ntransfer learning and hyperparameter tuning with Bayesian optimization, boosted\nmodel performance.\n  Gains of up to 26% were achieved on the Purity/Efficiency curve, which is\nused to evaluate model performance, particularly in areas with interesting\nredshifts, at low (around 2) and high (around 4) redshifts. The best model\nobtained an average score of 94%, compared with 75% for the initial model.",
    "categories": [
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.CO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16730v1",
    "published_date": "2024-06-24 15:35:51 UTC",
    "updated_date": "2024-06-24 15:35:51 UTC"
  },
  {
    "arxiv_id": "2406.16728v1",
    "title": "CausalMMM: Learning Causal Structure for Marketing Mix Modeling",
    "authors": [
      "Chang Gong",
      "Di Yao",
      "Lei Zhang",
      "Sheng Chen",
      "Wenbin Li",
      "Yueyang Su",
      "Jingping Bi"
    ],
    "abstract": "In online advertising, marketing mix modeling (MMM) is employed to predict\nthe gross merchandise volume (GMV) of brand shops and help decision-makers to\nadjust the budget allocation of various advertising channels. Traditional MMM\nmethods leveraging regression techniques can fail in handling the complexity of\nmarketing. Although some efforts try to encode the causal structures for better\nprediction, they have the strict restriction that causal structures are\nprior-known and unchangeable. In this paper, we define a new causal MMM problem\nthat automatically discovers the interpretable causal structures from data and\nyields better GMV predictions. To achieve causal MMM, two essential challenges\nshould be addressed: (1) Causal Heterogeneity. The causal structures of\ndifferent kinds of shops vary a lot. (2) Marketing Response Patterns. Various\nmarketing response patterns i.e., carryover effect and shape effect, have been\nvalidated in practice. We argue that causal MMM needs dynamically discover\nspecific causal structures for different shops and the predictions should\ncomply with the prior known marketing response patterns. Thus, we propose\nCausalMMM that integrates Granger causality in a variational inference\nframework to measure the causal relationships between different channels and\npredict the GMV with the regularization of both temporal and saturation\nmarketing response patterns. Extensive experiments show that CausalMMM can not\nonly achieve superior performance of causal structure learning on synthetic\ndatasets with improvements of 5.7%\\sim 7.1%, but also enhance the GMV\nprediction results on a representative E-commerce platform.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "WSDM 2024, full version",
    "pdf_url": "http://arxiv.org/pdf/2406.16728v1",
    "published_date": "2024-06-24 15:33:47 UTC",
    "updated_date": "2024-06-24 15:33:47 UTC"
  },
  {
    "arxiv_id": "2407.16905v1",
    "title": "Assessing the role of clinical summarization and patient chart review within communications, medical management, and diagnostics",
    "authors": [
      "Chanseo Lee",
      "Kimon-Aristotelis Vogt",
      "Sonu Kumar"
    ],
    "abstract": "Effective summarization of unstructured patient data in electronic health\nrecords (EHRs) is crucial for accurate diagnosis and efficient patient care,\nyet clinicians often struggle with information overload and time constraints.\nThis review dives into recent literature and case studies on both the\nsignificant impacts and outstanding issues of patient chart review on\ncommunications, diagnostics, and management. It also discusses recent efforts\nto integrate artificial intelligence (AI) into clinical summarization tasks,\nand its transformative impact on the clinician's potential, including but not\nlimited to reductions of administrative burden and improved patient-centered\ncare.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.16905v1",
    "published_date": "2024-06-24 15:31:24 UTC",
    "updated_date": "2024-06-24 15:31:24 UTC"
  },
  {
    "arxiv_id": "2406.16714v2",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "authors": [
      "Jiale Cheng",
      "Yida Lu",
      "Xiaotao Gu",
      "Pei Ke",
      "Xiao Liu",
      "Yuxiao Dong",
      "Hongning Wang",
      "Jie Tang",
      "Minlie Huang"
    ],
    "abstract": "Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 findings",
    "pdf_url": "http://arxiv.org/pdf/2406.16714v2",
    "published_date": "2024-06-24 15:16:45 UTC",
    "updated_date": "2024-12-10 13:57:46 UTC"
  },
  {
    "arxiv_id": "2406.16707v1",
    "title": "Probabilistic Subgoal Representations for Hierarchical Reinforcement learning",
    "authors": [
      "Vivienne Huiling Wang",
      "Tinghuai Wang",
      "Wenyan Yang",
      "Joni-Kristian Kämäräinen",
      "Joni Pajarinen"
    ],
    "abstract": "In goal-conditioned hierarchical reinforcement learning (HRL), a high-level\npolicy specifies a subgoal for the low-level policy to reach. Effective HRL\nhinges on a suitable subgoal represen tation function, abstracting state space\ninto latent subgoal space and inducing varied low-level behaviors. Existing\nmethods adopt a subgoal representation that provides a deterministic mapping\nfrom state space to latent subgoal space. Instead, this paper utilizes Gaussian\nProcesses (GPs) for the first probabilistic subgoal representation. Our method\nemploys a GP prior on the latent subgoal space to learn a posterior\ndistribution over the subgoal representation functions while exploiting the\nlong-range correlation in the state space through learnable kernels. This\nenables an adaptive memory that integrates long-range subgoal information from\nprior planning steps allowing to cope with stochastic uncertainties.\nFurthermore, we propose a novel learning objective to facilitate the\nsimultaneous learning of probabilistic subgoal representations and policies\nwithin a unified framework. In experiments, our approach outperforms\nstate-of-the-art baselines in standard benchmarks but also in environments with\nstochastic elements and under diverse reward conditions. Additionally, our\nmodel shows promising capabilities in transferring low-level policies across\ndifferent tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16707v1",
    "published_date": "2024-06-24 15:09:22 UTC",
    "updated_date": "2024-06-24 15:09:22 UTC"
  },
  {
    "arxiv_id": "2406.16697v1",
    "title": "Expected Runtime Comparisons Between Breadth-First Search and Constant-Depth Restarting Random Walks",
    "authors": [
      "Daniel Platnick",
      "Richard Anthony Valenzano"
    ],
    "abstract": "When greedy search algorithms encounter a local minima or plateau, the search\ntypically devolves into a breadth-first search (BrFS), or a local search\ntechnique is used in an attempt to find a way out. In this work, we formally\nanalyze the performance of BrFS and constant-depth restarting random walks\n(RRW) -- two methods often used for finding exits to a plateau/local minima --\nto better understand when each is best suited. In particular, we formally\nderive the expected runtime for BrFS in the case of a uniformly distributed set\nof goals at a given goal depth. We then prove RRW will be faster than BrFS on\ntrees if there are enough goals at that goal depth. We refer to this threshold\nas the crossover point. Our bound shows that the crossover point grows linearly\nwith the branching factor of the tree, the goal depth, and the error in the\nrandom walk depth, while the size of the tree grows exponentially in branching\nfactor and goal depth. Finally, we discuss the practical implications and\napplicability of this bound.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICAPS 2024 Heuristics and Search for Domain-Independent Planning\n  Workshop, 5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2406.16697v1",
    "published_date": "2024-06-24 15:00:59 UTC",
    "updated_date": "2024-06-24 15:00:59 UTC"
  },
  {
    "arxiv_id": "2406.16696v2",
    "title": "Public Constitutional AI",
    "authors": [
      "Gilad Abiri"
    ],
    "abstract": "We are increasingly subjected to the power of AI authorities. As AI decisions\nbecome inescapable, entering domains such as healthcare, education, and law, we\nmust confront a vital question: how can we ensure AI systems have the\nlegitimacy necessary for effective governance? This essay argues that to secure\nAI legitimacy, we need methods that engage the public in designing and\nconstraining AI systems, ensuring these technologies reflect the community's\nshared values. Constitutional AI, proposed by Anthropic, represents a step\ntowards this goal, offering a model for democratic control of AI. However,\nwhile Constitutional AI's commitment to hardcoding explicit principles into AI\nmodels enhances transparency and accountability, it falls short in two crucial\naspects: addressing the opacity of individual AI decisions and fostering\ngenuine democratic legitimacy. To overcome these limitations, this essay\nproposes \"Public Constitutional AI.\" This approach envisions a participatory\nprocess where diverse stakeholders, including ordinary citizens, deliberate on\nthe principles guiding AI development. The resulting \"AI Constitution\" would\ncarry the legitimacy of popular authorship, grounding AI governance in the\npublic will. Furthermore, the essay proposes \"AI Courts\" to develop \"AI case\nlaw,\" providing concrete examples for operationalizing constitutional\nprinciples in AI training. This evolving combination of constitutional\nprinciples and case law aims to make AI governance more responsive to public\nvalues. By grounding AI governance in deliberative democratic processes, Public\nConstitutional AI offers a path to imbue automated authorities with genuine\ndemocratic legitimacy, addressing the unique challenges posed by increasingly\npowerful AI systems while ensuring their alignment with the public interest.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16696v2",
    "published_date": "2024-06-24 15:00:01 UTC",
    "updated_date": "2025-05-14 17:21:19 UTC"
  },
  {
    "arxiv_id": "2407.09525v1",
    "title": "A Deep Learning Framework for Three Dimensional Shape Reconstruction from Phaseless Acoustic Scattering Far-field Data",
    "authors": [
      "Doga Dikbayir",
      "Abdel Alsnayyan",
      "Vishnu Naresh Boddeti",
      "Balasubramaniam Shanker",
      "Hasan Metin Aktulga"
    ],
    "abstract": "The inverse scattering problem is of critical importance in a number of\nfields, including medical imaging, sonar, sensing, non-destructive evaluation,\nand several others. The problem of interest can vary from detecting the shape\nto the constitutive properties of the obstacle. The challenge in both is that\nthis problem is ill-posed, more so when there is limited information. That\nsaid, significant effort has been expended over the years in developing\nsolutions to this problem. Here, we use a different approach, one that is\nfounded on data. Specifically, we develop a deep learning framework for shape\nreconstruction using limited information with single incident wave, single\nfrequency, and phase-less far-field data. This is done by (a) using a compact\nprobabilistic shape latent space, learned by a 3D variational auto-encoder, and\n(b) a convolutional neural network trained to map the acoustic scattering\ninformation to this shape representation. The proposed framework is evaluated\non a synthetic 3D particle dataset, as well as ShapeNet, a popular 3D shape\nrecognition dataset. As demonstrated via a number of results, the proposed\nmethod is able to produce accurate reconstructions for large batches of complex\nscatterer shapes (such as airplanes and automobiles), despite the significant\nvariation present within the data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.1; J.2"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 14 Figures",
    "pdf_url": "http://arxiv.org/pdf/2407.09525v1",
    "published_date": "2024-06-24 14:58:49 UTC",
    "updated_date": "2024-06-24 14:58:49 UTC"
  },
  {
    "arxiv_id": "2406.16687v1",
    "title": "Link Prediction with Untrained Message Passing Layers",
    "authors": [
      "Lisi Qarkaxhija",
      "Anatol E. Wegner",
      "Ingo Scholtes"
    ],
    "abstract": "Message passing neural networks (MPNNs) operate on graphs by exchanging\ninformation between neigbouring nodes. MPNNs have been successfully applied to\nvarious node-, edge-, and graph-level tasks in areas like molecular science,\ncomputer vision, natural language processing, and combinatorial optimization.\nHowever, most MPNNs require training on large amounts of labeled data, which\ncan be costly and time-consuming. In this work, we explore the use of various\nuntrained message passing layers in graph neural networks, i.e. variants of\npopular message passing architecture where we remove all trainable parameters\nthat are used to transform node features in the message passing step. Focusing\non link prediction, we find that untrained message passing layers can lead to\ncompetitive and even superior performance compared to fully trained MPNNs,\nespecially in the presence of high-dimensional features. We provide a\ntheoretical analysis of untrained message passing by relating the inner\nproducts of features implicitly produced by untrained message passing layers to\npath-based topological node similarity measures. As such, untrained message\npassing architectures can be viewed as a highly efficient and interpretable\napproach to link prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16687v1",
    "published_date": "2024-06-24 14:46:34 UTC",
    "updated_date": "2024-06-24 14:46:34 UTC"
  },
  {
    "arxiv_id": "2407.12803v1",
    "title": "Bosch Street Dataset: A Multi-Modal Dataset with Imaging Radar for Automated Driving",
    "authors": [
      "Karim Armanious",
      "Maurice Quach",
      "Michael Ulrich",
      "Timo Winterling",
      "Johannes Friesen",
      "Sascha Braun",
      "Daniel Jenet",
      "Yuri Feldman",
      "Eitan Kosman",
      "Philipp Rapp",
      "Volker Fischer",
      "Marc Sons",
      "Lukas Kohns",
      "Daniel Eckstein",
      "Daniela Egbert",
      "Simone Letsch",
      "Corinna Voege",
      "Felix Huttner",
      "Alexander Bartler",
      "Robert Maiwald",
      "Yancong Lin",
      "Ulf Rüegg",
      "Claudius Gläser",
      "Bastian Bischoff",
      "Jascha Freess",
      "Karsten Haug",
      "Kathrin Klee",
      "Holger Caesar"
    ],
    "abstract": "This paper introduces the Bosch street dataset (BSD), a novel multi-modal\nlarge-scale dataset aimed at promoting highly automated driving (HAD) and\nadvanced driver-assistance systems (ADAS) research. Unlike existing datasets,\nBSD offers a unique integration of high-resolution imaging radar, lidar, and\ncamera sensors, providing unprecedented 360-degree coverage to bridge the\ncurrent gap in high-resolution radar data availability. Spanning urban, rural,\nand highway environments, BSD enables detailed exploration into radar-based\nobject detection and sensor fusion techniques. The dataset is aimed at\nfacilitating academic and research collaborations between Bosch and current and\nfuture partners. This aims to foster joint efforts in developing cutting-edge\nHAD and ADAS technologies. The paper describes the dataset's key attributes,\nincluding its scalability, radar resolution, and labeling methodology. Key\nofferings also include initial benchmarks for sensor modalities and a\ndevelopment kit tailored for extensive data analysis and performance\nevaluation, underscoring our commitment to contributing valuable resources to\nthe HAD and ADAS research community.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12803v1",
    "published_date": "2024-06-24 14:40:56 UTC",
    "updated_date": "2024-06-24 14:40:56 UTC"
  },
  {
    "arxiv_id": "2407.00082v1",
    "title": "Adapting Job Recommendations to User Preference Drift with Behavioral-Semantic Fusion Learning",
    "authors": [
      "Xiao Han",
      "Chen Zhu",
      "Xiao Hu",
      "Chuan Qin",
      "Xiangyu Zhao",
      "Hengshu Zhu"
    ],
    "abstract": "Job recommender systems are crucial for aligning job opportunities with\njob-seekers in online job-seeking. However, users tend to adjust their job\npreferences to secure employment opportunities continually, which limits the\nperformance of job recommendations. The inherent frequency of preference drift\nposes a challenge to promptly and precisely capture user preferences. To\naddress this issue, we propose a novel session-based framework, BISTRO, to\ntimely model user preference through fusion learning of semantic and behavioral\ninformation. Specifically, BISTRO is composed of three stages: 1)\ncoarse-grained semantic clustering, 2) fine-grained job preference extraction,\nand 3) personalized top-$k$ job recommendation. Initially, BISTRO segments the\nuser interaction sequence into sessions and leverages session-based semantic\nclustering to achieve broad identification of person-job matching.\nSubsequently, we design a hypergraph wavelet learning method to capture the\nnuanced job preference drift. To mitigate the effect of noise in interactions\ncaused by frequent preference drift, we innovatively propose an adaptive\nwavelet filtering technique to remove noisy interaction. Finally, a recurrent\nneural network is utilized to analyze session-based interaction for inferring\npersonalized preferences. Extensive experiments on three real-world offline\nrecruitment datasets demonstrate the significant performances of our framework.\nSignificantly, BISTRO also excels in online experiments, affirming its\neffectiveness in live recruitment settings. This dual success underscores the\nrobustness and adaptability of BISTRO. The source code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/BISTRO.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by KDD 24 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2407.00082v1",
    "published_date": "2024-06-24 14:38:04 UTC",
    "updated_date": "2024-06-24 14:38:04 UTC"
  },
  {
    "arxiv_id": "2406.16678v2",
    "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
    "authors": [
      "Markus Frohmann",
      "Igor Sterner",
      "Ivan Vulić",
      "Benjamin Minixhofer",
      "Markus Schedl"
    ],
    "abstract": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://github.com/segment-any-text/wtpsplit under the MIT license.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2406.16678v2",
    "published_date": "2024-06-24 14:36:11 UTC",
    "updated_date": "2024-10-02 19:04:17 UTC"
  },
  {
    "arxiv_id": "2406.17809v2",
    "title": "Towards a Science Exocortex",
    "authors": [
      "Kevin G. Yager"
    ],
    "abstract": "Artificial intelligence (AI) methods are poised to revolutionize intellectual\nwork, with generative AI enabling automation of text analysis, text generation,\nand simple decision making or reasoning. The impact to science is only just\nbeginning, but the opportunity is significant since scientific research relies\nfundamentally on extended chains of cognitive work. Here, we review the state\nof the art in agentic AI systems, and discuss how these methods could be\nextended to have even greater impact on science. We propose the development of\nan exocortex, a synthetic extension of a person's cognition. A science\nexocortex could be designed as a swarm of AI agents, with each agent\nindividually streamlining specific researcher tasks, and whose\ninter-communication leads to emergent behavior that greatly extend the\nresearcher's cognition and volition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.17809v2",
    "published_date": "2024-06-24 14:32:32 UTC",
    "updated_date": "2024-08-15 14:32:34 UTC"
  },
  {
    "arxiv_id": "2406.16672v3",
    "title": "CAVE: Controllable Authorship Verification Explanations",
    "authors": [
      "Sahana Ramnath",
      "Kartik Pandey",
      "Elizabeth Boschee",
      "Xiang Ren"
    ],
    "abstract": "Authorship Verification (AV) (do two documents have the same author?) is\nessential in many real-life applications. AV is often used in privacy-sensitive\ndomains that require an offline proprietary model that is deployed on premises,\nmaking publicly served online models (APIs) a suboptimal choice. Current\noffline AV models however have lower downstream utility due to limited accuracy\n(eg: traditional stylometry AV systems) and lack of accessible post-hoc\nexplanations. In this work, we address the above challenges by developing a\ntrained, offline model CAVE (Controllable Authorship Verification\nExplanations). CAVE generates free-text AV explanations that are controlled to\nbe (1) accessible (uniform structure that can be decomposed into\nsub-explanations grounded to relevant linguistic features), and (2) easily\nverified for explanation-label consistency. We generate silver-standard\ntraining data grounded to the desirable linguistic features by a prompt-based\nmethod Prompt-CAVE. We then filter the data based on rationale-label\nconsistency using a novel metric Cons-R-L. Finally, we fine-tune a small,\noffline model (Llama-3-8B) with this data to create our model CAVE. Results on\nthree difficult AV datasets show that CAVE generates high quality explanations\n(as measured by automatic and human evaluation) as well as competitive task\naccuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.16672v3",
    "published_date": "2024-06-24 14:27:54 UTC",
    "updated_date": "2025-02-10 03:02:26 UTC"
  },
  {
    "arxiv_id": "2407.10995v2",
    "title": "LionGuard: Building a Contextualized Moderation Classifier to Tackle Localized Unsafe Content",
    "authors": [
      "Jessica Foo",
      "Shaun Khoo"
    ],
    "abstract": "As large language models (LLMs) become increasingly prevalent in a wide\nvariety of applications, concerns about the safety of their outputs have become\nmore significant. Most efforts at safety-tuning or moderation today take on a\npredominantly Western-centric view of safety, especially for toxic, hateful, or\nviolent speech. In this paper, we describe LionGuard, a\nSingapore-contextualized moderation classifier that can serve as guardrails\nagainst unsafe LLM outputs. When assessed on Singlish data, LionGuard\noutperforms existing widely-used moderation APIs, which are not finetuned for\nthe Singapore context, by 14% (binary) and up to 51% (multi-label). Our work\nhighlights the benefits of localization for moderation classifiers and presents\na practical and scalable approach for low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2407.10995v2",
    "published_date": "2024-06-24 14:05:56 UTC",
    "updated_date": "2024-07-19 00:27:42 UTC"
  },
  {
    "arxiv_id": "2406.16641v1",
    "title": "Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment",
    "authors": [
      "Jun Fu",
      "Wei Zhou",
      "Qiuping Jiang",
      "Hantao Liu",
      "Guangtao Zhai"
    ],
    "abstract": "Recently, textual prompt tuning has shown inspirational performance in\nadapting Contrastive Language-Image Pre-training (CLIP) models to natural image\nquality assessment. However, such uni-modal prompt learning method only tunes\nthe language branch of CLIP models. This is not enough for adapting CLIP models\nto AI generated image quality assessment (AGIQA) since AGIs visually differ\nfrom natural images. In addition, the consistency between AGIs and user input\ntext prompts, which correlates with the perceptual quality of AGIs, is not\ninvestigated to guide AGIQA. In this letter, we propose vision-language\nconsistency guided multi-modal prompt learning for blind AGIQA, dubbed\nCLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in\nlanguage and vision branches of CLIP models, respectively. Moreover, we design\na text-to-image alignment quality prediction task, whose learned\nvision-language consistency knowledge is used to guide the optimization of the\nabove multi-modal prompts. Experimental results on two public AGIQA datasets\ndemonstrate that the proposed method outperforms state-of-the-art quality\nassessment models. The source code is available at\nhttps://github.com/JunFu1995/CLIP-AGIQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Signal Processing Letter",
    "pdf_url": "http://arxiv.org/pdf/2406.16641v1",
    "published_date": "2024-06-24 13:45:31 UTC",
    "updated_date": "2024-06-24 13:45:31 UTC"
  },
  {
    "arxiv_id": "2406.16638v1",
    "title": "Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models",
    "authors": [
      "Mohammad Belal",
      "Taimur Hassan",
      "Abdelfatah Ahmed",
      "Ahmad Aljarah",
      "Nael Alsheikh",
      "Irfan Hussain"
    ],
    "abstract": "Human activity recognition (HAR) is a crucial area of research that involves\nunderstanding human movements using computer and machine vision technology.\nDeep learning has emerged as a powerful tool for this task, with models such as\nConvolutional Neural Networks (CNNs) and Transformers being employed to capture\nvarious aspects of human motion. One of the key contributions of this work is\nthe demonstration of the effectiveness of feature fusion in improving HAR\naccuracy by capturing spatial and temporal features, which has important\nimplications for the development of more accurate and robust activity\nrecognition systems. The study uses sensory data from HuGaDB, PKU-MMD, LARa,\nand TUG datasets. Two model, the PO-MS-GCN and a Transformer were trained and\nevaluated, with PO-MS-GCN outperforming state-of-the-art models. HuGaDB and TUG\nachieved high accuracies and f1-scores, while LARa and PKU-MMD had lower\nscores. Feature fusion improved results across datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 1 figure, conference",
    "pdf_url": "http://arxiv.org/pdf/2406.16638v1",
    "published_date": "2024-06-24 13:44:06 UTC",
    "updated_date": "2024-06-24 13:44:06 UTC"
  },
  {
    "arxiv_id": "2406.16635v2",
    "title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models",
    "authors": [
      "Yash Akhauri",
      "Ahmed F AbouElhamayed",
      "Jordan Dotzel",
      "Zhiru Zhang",
      "Alexander M Rush",
      "Safeen Huda",
      "Mohamed S Abdelfattah"
    ],
    "abstract": "The high power consumption and latency-sensitive deployments of large\nlanguage models (LLMs) have motivated efficiency techniques like quantization\nand sparsity. Contextual sparsity, where the sparsity pattern is\ninput-dependent, is crucial in LLMs because the permanent removal of attention\nheads or neurons from LLMs can significantly degrade accuracy. Prior work has\nattempted to model contextual sparsity using neural networks trained to predict\nactivation magnitudes, which can be used to dynamically prune structures with\nlow predicted activation magnitude. In this paper, we look beyond\nmagnitude-based pruning criteria to assess attention head and neuron importance\nin LLMs. We develop a novel predictor called ShadowLLM, which can shadow the\nLLM behavior and enforce better sparsity patterns, resulting in over 15%\nimprovement in end-to-end accuracy compared to prior methods. In addition,\nShadowLLM achieves up to a 20% speed-up over the state-of-the-art DejaVu\nframework. These enhancements are validated on Llama-2 and OPT models with up\nto 30 billion parameters. Our code is available at\n\\href{https://github.com/abdelfattah-lab/shadow_llm/}{ShadowLLM}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EMNLP 2024 (Main, Long Paper)",
    "pdf_url": "http://arxiv.org/pdf/2406.16635v2",
    "published_date": "2024-06-24 13:41:08 UTC",
    "updated_date": "2024-10-17 15:45:10 UTC"
  },
  {
    "arxiv_id": "2406.16626v1",
    "title": "Hacking a surrogate model approach to XAI",
    "authors": [
      "Alexander Wilhelm",
      "Katharina A. Zweig"
    ],
    "abstract": "In recent years, the number of new applications for highly complex AI systems\nhas risen significantly. Algorithmic decision-making systems (ADMs) are one of\nsuch applications, where an AI system replaces the decision-making process of a\nhuman expert. As one approach to ensure fairness and transparency of such\nsystems, explainable AI (XAI) has become more important. One variant to achieve\nexplainability are surrogate models, i.e., the idea to train a new simpler\nmachine learning model based on the input-output-relationship of a black box\nmodel. The simpler machine learning model could, for example, be a decision\ntree, which is thought to be intuitively understandable by humans. However,\nthere is not much insight into how well the surrogate model approximates the\nblack box.\n  Our main assumption is that a good surrogate model approach should be able to\nbring such a discriminating behavior to the attention of humans; prior to our\nresearch we assumed that a surrogate decision tree would identify such a\npattern on one of its first levels. However, in this article we show that even\nif the discriminated subgroup - while otherwise being the same in all\ncategories - does not get a single positive decision from the black box ADM\nsystem, the corresponding question of group membership can be pushed down onto\na level as low as wanted by the operator of the system.\n  We then generalize this finding to pinpoint the exact level of the tree on\nwhich the discriminating question is asked and show that in a more realistic\nscenario, where discrimination only occurs to some fraction of the\ndisadvantaged group, it is even more feasible to hide such discrimination.\n  Our approach can be generalized easily to other surrogate models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16626v1",
    "published_date": "2024-06-24 13:18:02 UTC",
    "updated_date": "2024-06-24 13:18:02 UTC"
  },
  {
    "arxiv_id": "2406.16611v2",
    "title": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings",
    "authors": [
      "Andrea Posada",
      "Daniel Rueckert",
      "Felix Meissen",
      "Philip Müller"
    ],
    "abstract": "Since the Transformer architecture emerged, language model development has\ngrown, driven by their promising potential. Releasing these models into\nproduction requires properly understanding their behavior, particularly in\nsensitive domains like medicine. Despite this need, the medical literature\nstill lacks practical assessment of pre-trained language models, which are\nespecially valuable in settings where only consumer-grade computational\nresources are available. To address this gap, we have conducted a comprehensive\nsurvey of language models in the medical field and evaluated a subset of these\nfor medical text classification and conditional text generation. The subset\nincludes 53 models with 110 million to 13 billion parameters, spanning the\nTransformer-based model families and knowledge domains. Different approaches\nare employed for text classification, including zero-shot learning, enabling\ntuning without the need to train the model. These approaches are helpful in our\ntarget settings, where many users of language models find themselves. The\nresults reveal remarkable performance across the tasks and datasets evaluated,\nunderscoring the potential of certain models to contain medical knowledge, even\nwithout domain specialization. This study thus advocates for further\nexploration of model applications in medical contexts, particularly in\ncomputational resource-constrained settings, to benefit a wide range of users.\nThe code is available on https://github.com/anpoc/Language-models-in-medicine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16611v2",
    "published_date": "2024-06-24 12:52:02 UTC",
    "updated_date": "2024-10-23 18:10:29 UTC"
  },
  {
    "arxiv_id": "2406.16609v1",
    "title": "Evaluating the Robustness of Deep-Learning Algorithm-Selection Models by Evolving Adversarial Instances",
    "authors": [
      "Emma Hart",
      "Quentin Renau",
      "Kevin Sim",
      "Mohamad Alissa"
    ],
    "abstract": "Deep neural networks (DNN) are increasingly being used to perform\nalgorithm-selection in combinatorial optimisation domains, particularly as they\naccommodate input representations which avoid designing and calculating\nfeatures. Mounting evidence from domains that use images as input shows that\ndeep convolutional networks are vulnerable to adversarial samples, in which a\nsmall perturbation of an instance can cause the DNN to misclassify. However, it\nremains unknown as to whether deep recurrent networks (DRN) which have recently\nbeen shown promise as algorithm-selectors in the bin-packing domain are equally\nvulnerable. We use an evolutionary algorithm (EA) to find perturbations of\ninstances from two existing benchmarks for online bin packing that cause\ntrained DRNs to misclassify: adversarial samples are successfully generated\nfrom up to 56% of the original instances depending on the dataset. Analysis of\nthe new misclassified instances sheds light on the `fragility' of some training\ninstances, i.e. instances where it is trivial to find a small perturbation that\nresults in a misclassification and the factors that influence this. Finally,\nthe method generates a large number of new instances misclassified with a wide\nvariation in confidence, providing a rich new source of training data to create\nmore robust models.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "To appear in the proceedings of the 18th International Conference on\n  Parallel Problem Solving from Nature (PPSN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.16609v1",
    "published_date": "2024-06-24 12:48:44 UTC",
    "updated_date": "2024-06-24 12:48:44 UTC"
  },
  {
    "arxiv_id": "2406.16605v1",
    "title": "CLEAR: Can Language Models Really Understand Causal Graphs?",
    "authors": [
      "Sirui Chen",
      "Mengying Xu",
      "Kun Wang",
      "Xingyu Zeng",
      "Rui Zhao",
      "Shengjie Zhao",
      "Chaochao Lu"
    ],
    "abstract": "Causal reasoning is a cornerstone of how humans interpret the world. To model\nand reason about causality, causal graphs offer a concise yet effective\nsolution. Given the impressive advancements in language models, a crucial\nquestion arises: can they really understand causal graphs? To this end, we\npioneer an investigation into language models' understanding of causal graphs.\nSpecifically, we develop a framework to define causal graph understanding, by\nassessing language models' behaviors through four practical criteria derived\nfrom diverse disciplines (e.g., philosophy and psychology). We then develop\nCLEAR, a novel benchmark that defines three complexity levels and encompasses\n20 causal graph-based tasks across these levels. Finally, based on our\nframework and benchmark, we conduct extensive experiments on six leading\nlanguage models and summarize five empirical findings. Our results indicate\nthat while language models demonstrate a preliminary understanding of causal\ngraphs, significant potential for improvement remains. Our project website is\nat https://github.com/OpenCausaLab/CLEAR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16605v1",
    "published_date": "2024-06-24 12:46:15 UTC",
    "updated_date": "2024-06-24 12:46:15 UTC"
  },
  {
    "arxiv_id": "2406.16578v2",
    "title": "QuadrupedGPT: Towards a Versatile Quadruped Agent in Open-ended Worlds",
    "authors": [
      "Yuting Mei",
      "Ye Wang",
      "Sipeng Zheng",
      "Qin Jin"
    ],
    "abstract": "As robotic agents increasingly assist humans in reality, quadruped robots\noffer unique opportunities for interaction in complex scenarios due to their\nagile movement. However, building agents that can autonomously navigate, adapt,\nand respond to versatile goals remains a significant challenge. In this work,\nwe introduce QuadrupedGPT designed to follow diverse commands with agility\ncomparable to that of a pet. The primary challenges addressed include: i)\neffectively utilizing multimodal observations for informed decision-making; ii)\nachieving agile control by integrating locomotion and navigation; iii)\ndeveloping advanced cognition to execute long-term objectives. Our QuadrupedGPT\ninterprets human commands and environmental contexts using a large multimodal\nmodel. Leveraging its extensive knowledge base, the agent autonomously assigns\nparameters for adaptive locomotion policies and devises safe yet efficient\npaths toward its goals. Additionally, it employs high-level reasoning to\ndecompose long-term goals into a sequence of executable subgoals. Through\ncomprehensive experiments, our agent shows proficiency in handling diverse\ntasks and intricate instructions, representing a significant step toward the\ndevelopment of versatile quadruped agents for open-ended environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2406.16578v2",
    "published_date": "2024-06-24 12:14:24 UTC",
    "updated_date": "2024-12-03 03:49:24 UTC"
  },
  {
    "arxiv_id": "2407.10994v4",
    "title": "Panza: Design and Analysis of a Fully-Local Personalized Text Writing Assistant",
    "authors": [
      "Armand Nicolicioiu",
      "Eugenia Iofinova",
      "Andrej Jovanovic",
      "Eldar Kurtic",
      "Mahdi Nikdan",
      "Andrei Panferov",
      "Ilia Markov",
      "Nir Shavit",
      "Dan Alistarh"
    ],
    "abstract": "The availability of powerful open-source large language models (LLMs) opens\nexciting use-cases, such as using personal data to fine-tune these models to\nimitate a user's unique writing style. Two key requirements for such assistants\nare personalization - in the sense that the assistant should recognizably\nreflect the user's own writing style - and privacy - users may justifiably be\nwary of uploading extremely personal data, such as their email archive, to a\nthird-party service. In this paper, we present a new design and evaluation for\nsuch an automated assistant, for the specific use case of email generation,\nwhich we call Panza. Panza's personalization features are based on a\ncombination of fine-tuning using a variant of the Reverse Instructions\ntechnique together with Retrieval-Augmented Generation (RAG). We demonstrate\nthat this combination allows us to fine-tune an LLM to reflect a user's writing\nstyle using limited data, while executing on extremely limited resources, e.g.\non a free Google Colab instance. Our key methodological contribution is the\nfirst detailed study of evaluation metrics for this personalized writing task,\nand of how different choices of system components--the use of RAG and of\ndifferent fine-tuning approaches-impact the system's performance. Additionally,\nwe demonstrate that very little data - under 100 email samples - are sufficient\nto create models that convincingly imitate humans. This finding showcases a\npreviously-unknown attack vector in language models - that access to a small\nnumber of writing samples can allow a bad actor to cheaply create generative\nmodels that imitate a target's writing style. We are releasing the full Panza\ncode as well as three new email datasets licensed for research use at\nhttps://github.com/IST-DASLab/PanzaMail.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Panza is available at https://github.com/IST-DASLab/PanzaMail",
    "pdf_url": "http://arxiv.org/pdf/2407.10994v4",
    "published_date": "2024-06-24 12:09:34 UTC",
    "updated_date": "2025-02-10 15:08:07 UTC"
  },
  {
    "arxiv_id": "2406.16571v1",
    "title": "Differentiable Distributionally Robust Optimization Layers",
    "authors": [
      "Xutao Ma",
      "Chao Ning",
      "Wenli Du"
    ],
    "abstract": "In recent years, there has been a growing research interest in\ndecision-focused learning, which embeds optimization problems as a layer in\nlearning pipelines and demonstrates a superior performance than the\nprediction-focused approach. However, for distributionally robust optimization\n(DRO), a popular paradigm for decision-making under uncertainty, it is still\nunknown how to embed it as a layer, i.e., how to differentiate decisions with\nrespect to an ambiguity set. In this paper, we develop such differentiable DRO\nlayers for generic mixed-integer DRO problems with parameterized second-order\nconic ambiguity sets and discuss its extension to Wasserstein ambiguity sets.\nTo differentiate the mixed-integer decisions, we propose a novel dual-view\nmethodology by handling continuous and discrete parts of decisions via\ndifferent principles. Specifically, we construct a differentiable energy-based\nsurrogate to implement the dual-view methodology and use importance sampling to\nestimate its gradient. We further prove that such a surrogate enjoys the\nasymptotic convergency under regularization. As an application of the proposed\ndifferentiable DRO layers, we develop a novel decision-focused learning\npipeline for contextual distributionally robust decision-making tasks and\ncompare it with the prediction-focused approach in experiments.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC",
    "comment": "In Forty-first International Conference on Machine Learning (2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.16571v1",
    "published_date": "2024-06-24 12:09:19 UTC",
    "updated_date": "2024-06-24 12:09:19 UTC"
  },
  {
    "arxiv_id": "2406.16555v1",
    "title": "Homomorphisms and Embeddings of STRIPS Planning Models",
    "authors": [
      "Arnaud Lequen",
      "Martin C. Cooper",
      "Frédéric Maris"
    ],
    "abstract": "Determining whether two STRIPS planning instances are isomorphic is the\nsimplest form of comparison between planning instances. It is also a particular\ncase of the problem concerned with finding an isomorphism between a planning\ninstance $P$ and a sub-instance of another instance $P_0$ . One application of\nsuch a mapping is to efficiently produce a compiled form containing all\nsolutions to P from a compiled form containing all solutions to $P_0$. We also\nintroduce the notion of embedding from an instance $P$ to another instance\n$P_0$, which allows us to deduce that $P_0$ has no solution-plan if $P$ is\nunsolvable. In this paper, we study the complexity of these problems. We show\nthat the first is GI-complete, and can thus be solved, in theory, in\nquasi-polynomial time. While we prove the remaining problems to be NP-complete,\nwe propose an algorithm to build an isomorphism, when possible. We report\nextensive experimental trials on benchmark problems which demonstrate\nconclusively that applying constraint propagation in preprocessing can greatly\nimprove the efficiency of a SAT solver.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16555v1",
    "published_date": "2024-06-24 11:43:18 UTC",
    "updated_date": "2024-06-24 11:43:18 UTC"
  },
  {
    "arxiv_id": "2406.16552v1",
    "title": "Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs",
    "authors": [
      "Jan von Pichowski",
      "Vincenzo Perri",
      "Lisi Qarkaxhija",
      "Ingo Scholtes"
    ],
    "abstract": "The modelling of temporal patterns in dynamic graphs is an important current\nresearch issue in the development of time-aware GNNs. Whether or not a specific\nsequence of events in a temporal graph constitutes a temporal pattern not only\ndepends on the frequency of its occurrence. We consider whether it deviates\nfrom what is expected in a temporal graph where timestamps are randomly\nshuffled. While accounting for such a random baseline is important to model\ntemporal patterns, it has mostly been ignored by current temporal graph neural\nnetworks. To address this issue we propose HYPA-DBGNN, a novel two-step\napproach that combines (i) the inference of anomalous sequential patterns in\ntime series data on graphs based on a statistically principled null model, with\n(ii) a neural message passing approach that utilizes a higher-order De Bruijn\ngraph whose edges capture overrepresented sequential patterns. Our method\nleverages hypergeometric graph ensembles to identify anomalous edges within\nboth first- and higher-order De Bruijn graphs, which encode the temporal\nordering of events. The model introduces an inductive bias that enhances model\ninterpretability. We evaluate our approach for static node classification using\nbenchmark datasets and a synthetic dataset that showcases its ability to\nincorporate the observed inductive bias regarding over- and under-represented\ntemporal edges. We demonstrate the framework's effectiveness in detecting\nsimilar patterns within empirical datasets, resulting in superior performance\ncompared to baseline methods in node classification tasks. To the best of our\nknowledge, our work is the first to introduce statistically informed GNNs that\nleverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path\nfor bridging the gap between statistical graph inference and neural graph\nrepresentation learning, with potential applications to static GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16552v1",
    "published_date": "2024-06-24 11:41:12 UTC",
    "updated_date": "2024-06-24 11:41:12 UTC"
  },
  {
    "arxiv_id": "2406.16537v4",
    "title": "Character-Adapter: Prompt-Guided Region Control for High-Fidelity Character Customization",
    "authors": [
      "Yuhang Ma",
      "Wenting Xu",
      "Jiji Tang",
      "Qinfeng Jin",
      "Rongsheng Zhang",
      "Zeng Zhao",
      "Changjie Fan",
      "Zhipeng Hu"
    ],
    "abstract": "Customized image generation, which seeks to synthesize images with consistent\ncharacters, holds significant relevance for applications such as storytelling,\nportrait generation, and character design. However, previous approaches have\nencountered challenges in preserving characters with high-fidelity consistency\ndue to inadequate feature extraction and concept confusion of reference\ncharacters. Therefore, we propose Character-Adapter, a plug-and-play framework\ndesigned to generate images that preserve the details of reference characters,\nensuring high-fidelity consistency. Character-Adapter employs prompt-guided\nsegmentation to ensure fine-grained regional features of reference characters\nand dynamic region-level adapters to mitigate concept confusion. Extensive\nexperiments are conducted to validate the effectiveness of Character-Adapter.\nBoth quantitative and qualitative results demonstrate that Character-Adapter\nachieves the state-of-the-art performance of consistent character generation,\nwith an improvement of 24.8% compared with other methods. Our code will be\nreleased at https://github.com/Character-Adapter/Character-Adapter.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16537v4",
    "published_date": "2024-06-24 11:16:37 UTC",
    "updated_date": "2024-09-29 09:07:23 UTC"
  },
  {
    "arxiv_id": "2406.16535v3",
    "title": "Token-based Decision Criteria Are Suboptimal in In-context Learning",
    "authors": [
      "Hakaze Cho",
      "Yoshihiro Sakai",
      "Mariko Kato",
      "Kenshiro Tanaka",
      "Akira Ishii",
      "Naoya Inoue"
    ],
    "abstract": "In-Context Learning (ICL) typically utilizes classification criteria from\noutput probabilities of manually selected label tokens. However, we argue that\nsuch token-based classification criteria lead to suboptimal decision\nboundaries, despite delicate calibrations through translation and constrained\nrotation applied. To address this problem, we propose Hidden Calibration, which\nrenounces token probabilities and uses the nearest centroid classifier on the\nLM's last hidden states. In detail, we assign the label of the nearest centroid\npreviously estimated from a calibration set to the test sample as the predicted\nlabel. Our experiments on 6 models and 10 classification datasets indicate that\nHidden Calibration consistently outperforms current token-based baselines by\nabout 20%~50%, achieving a strong state-of-the-art in ICL. Our further analysis\ndemonstrates that Hidden Calibration finds better classification criteria with\nless inter-class overlap, and LMs provide linearly separable intra-class\nclusters with the help of demonstrations, which supports Hidden Calibration and\ngives new insights into the principle of ICL. Our official code implementation\ncan be found at https://github.com/hc495/Hidden_Calibration.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 15 figures, 13 tables. NAACL 2025 Main Conference Accepted.\n  Camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2406.16535v3",
    "published_date": "2024-06-24 11:16:26 UTC",
    "updated_date": "2025-02-05 13:44:48 UTC"
  },
  {
    "arxiv_id": "2406.16526v1",
    "title": "NARRepair: Non-Autoregressive Code Generation Model for Automatic Program Repair",
    "authors": [
      "Zhenyu Yang",
      "Zhen Yang",
      "Zhongxing Yu"
    ],
    "abstract": "With the advancement of deep learning techniques, the performance of\nAutomatic Program Repair(APR) techniques has reached a new level. Previous deep\nlearning-based APR techniques essentially modified program sentences in the\nAutoregressive(AR) manner, which predicts future values based on past values.\nDue to the manner of word-by-word generation, the AR-based APR technique has a\nhuge time delay. This negative consequence overshadows the widespread adoption\nof APR techniques in real-life software development.\n  To address the issue, we aim to apply the Non-Autoregressive(NAR) method to\nthe APR task, which can output target code in a parallel manner to avoid huge\ninference delays. To effectively adapt the NAR manner for the APR task, we in\nthis paper propose NARRepair, the first customized NAR code generation model\nfor the APR task. The NARRepair features three major novelties, including 1)\nusing repair actions to alleviate the over-correction issue, 2) extracting\ndependency information from AST to alleviate the issue of lacking inter-word\ndependency information, 3) employing two-stage decoding to alleviate the issue\nof lacking contextual information. We evaluated NARRepair on three widely used\ndatasets in the APR community, and the results show that our technique can\nsignificantly improve the inference speed while maintaining high repair\naccuracy.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16526v1",
    "published_date": "2024-06-24 11:04:28 UTC",
    "updated_date": "2024-06-24 11:04:28 UTC"
  },
  {
    "arxiv_id": "2406.16521v1",
    "title": "Carrot and Stick: Inducing Self-Motivation with Positive & Negative Feedback",
    "authors": [
      "Jimin Sohn",
      "Jeihee Cho",
      "Junyong Lee",
      "Songmu Heo",
      "Ji-Eun Han",
      "David R. Mortensen"
    ],
    "abstract": "Positive thinking is thought to be an important component of self-motivation\nin various practical fields such as education and the workplace. Previous work,\nincluding sentiment transfer and positive reframing, has focused on the\npositive side of language. However, self-motivation that drives people to reach\ntheir goals has not yet been studied from a computational perspective.\nMoreover, negative feedback has not yet been explored, even though positive and\nnegative feedback are both necessary to grow self-motivation. To facilitate\nself-motivation, we propose CArrot and STICk (CASTIC) dataset, consisting of\n12,590 sentences with 5 different strategies for enhancing self-motivation. Our\ndata and code are publicly available at here.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16521v1",
    "published_date": "2024-06-24 10:55:31 UTC",
    "updated_date": "2024-06-24 10:55:31 UTC"
  },
  {
    "arxiv_id": "2406.16505v2",
    "title": "$\\text{Alpha}^2$: Discovering Logical Formulaic Alphas using Deep Reinforcement Learning",
    "authors": [
      "Feng Xu",
      "Yan Yin",
      "Xinyu Zhang",
      "Tianyuan Liu",
      "Shengyi Jiang",
      "Zongzhang Zhang"
    ],
    "abstract": "Alphas are pivotal in providing signals for quantitative trading. The\nindustry highly values the discovery of formulaic alphas for their\ninterpretability and ease of analysis, compared with the expressive yet\noverfitting-prone black-box alphas. In this work, we focus on discovering\nformulaic alphas. Prior studies on automatically generating a collection of\nformulaic alphas were mostly based on genetic programming (GP), which is known\nto suffer from the problems of being sensitive to the initial population,\nconverting to local optima, and slow computation speed. Recent efforts\nemploying deep reinforcement learning (DRL) for alpha discovery have not fully\naddressed key practical considerations such as alpha correlations and validity,\nwhich are crucial for their effectiveness. In this work, we propose a novel\nframework for alpha discovery using DRL by formulating the alpha discovery\nprocess as program construction. Our agent, $\\text{Alpha}^2$, assembles an\nalpha program optimized for an evaluation metric. A search algorithm guided by\nDRL navigates through the search space based on value estimates for potential\nalpha outcomes. The evaluation metric encourages both the performance and the\ndiversity of alphas for a better final trading strategy. Our formulation of\nsearching alphas also brings the advantage of pre-calculation dimensional\nanalysis, ensuring the logical soundness of alphas, and pruning the vast search\nspace to a large extent. Empirical experiments on real-world stock markets\ndemonstrates $\\text{Alpha}^2$'s capability to identify a diverse set of logical\nand effective alphas, which significantly improves the performance of the final\ntrading strategy. The code of our method is available at\nhttps://github.com/x35f/alpha2.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16505v2",
    "published_date": "2024-06-24 10:21:29 UTC",
    "updated_date": "2024-06-26 07:40:12 UTC"
  },
  {
    "arxiv_id": "2407.12011v1",
    "title": "Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing",
    "authors": [
      "Ibrahim Aliyu",
      "Awwal M. Arigi",
      "Tai-Won Um",
      "Jinsul Kim"
    ],
    "abstract": "This paper addresses the challenge of representing complex human action (HA)\nin a nuclear power plant (NPP) digital twin (DT) and minimizing latency in\npartial computation offloading (PCO) in sixth-generation-enabled computing in\nthe network (COIN) assisted multiaccess edge computing (MEC). Accurate HA\nrepresentation in the DT-HA model is vital for modeling human interventions\nthat are crucial for the safe and efficient operation of NPPs. In this context,\nDT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities\nto optimize resource allocation and reduce latency effectively. A two-stage\napproach is employed to address system complexity. First, a probabilistic\ngraphical model (PGM) is introduced to capture HAs in the DT abstraction. In\nthe PGM, HA and NPP asset-twin abstractions form coupled systems that evolve\nand interact through observable data and control input. Next, the underlying\nPCO problem is formulated as a multiuser game, where NPP assets can partially\noffload tasks to COIN and MEC. We propose a decentralized algorithm to optimize\noffloading decisions, offloading ratios, and resource allocation. The\nsimulation results demonstrate the effectiveness of the proposed method in\ncapturing complex HAs and optimal resource allocation in DT-enabled NPPs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12011v1",
    "published_date": "2024-06-24 10:13:00 UTC",
    "updated_date": "2024-06-24 10:13:00 UTC"
  },
  {
    "arxiv_id": "2406.16501v1",
    "title": "UNICAD: A Unified Approach for Attack Detection, Noise Reduction and Novel Class Identification",
    "authors": [
      "Alvaro Lopez Pellicer",
      "Kittipos Giatgong",
      "Yi Li",
      "Neeraj Suri",
      "Plamen Angelov"
    ],
    "abstract": "As the use of Deep Neural Networks (DNNs) becomes pervasive, their\nvulnerability to adversarial attacks and limitations in handling unseen classes\nposes significant challenges. The state-of-the-art offers discrete solutions\naimed to tackle individual issues covering specific adversarial attack\nscenarios, classification or evolving learning. However, real-world systems\nneed to be able to detect and recover from a wide range of adversarial attacks\nwithout sacrificing classification accuracy and to flexibly act in {\\bf unseen}\nscenarios. In this paper, UNICAD, is proposed as a novel framework that\nintegrates a variety of techniques to provide an adaptive solution.\n  For the targeted image classification, UNICAD achieves accurate image\nclassification, detects unseen classes, and recovers from adversarial attacks\nusing Prototype and Similarity-based DNNs with denoising autoencoders. Our\nexperiments performed on the CIFAR-10 dataset highlight UNICAD's effectiveness\nin adversarial mitigation and unseen class classification, outperforming\ntraditional models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16501v1",
    "published_date": "2024-06-24 10:10:03 UTC",
    "updated_date": "2024-06-24 10:10:03 UTC"
  },
  {
    "arxiv_id": "2406.16495v3",
    "title": "OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to construct Observer-Thinker-Conceiver-Expresser",
    "authors": [
      "Jingze Shi",
      "Ting Xie",
      "Bingheng Wu",
      "Chunjun Zheng",
      "Kai Wang"
    ],
    "abstract": "Recent research has shown that combining Mamba with Transformer architecture,\nwhich has selective state space and quadratic self-attention mechanism,\noutperforms using Mamba or Transformer architecture alone in language modeling\ntasks. The quadratic self-attention mechanism effectively alleviates the\nshortcomings of selective state space in handling long-term dependencies of any\nelement in the sequence. We propose a position information injection method\nthat connects the selective state space model with the quadratic attention, and\nintegrates these two architectures with hybrid experts with cross-sharing\ndomains, so that we can enjoy the advantages of both. We design a new\narchitecture with a more biomimetic idea: Observer-Thinker-Conceiver-Expresser\n(OTCE), which can compete with well-known medium-scale open-source language\nmodels on a small scale in language modeling tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16495v3",
    "published_date": "2024-06-24 10:05:23 UTC",
    "updated_date": "2024-07-20 03:35:45 UTC"
  },
  {
    "arxiv_id": "2406.16997v2",
    "title": "Gate Recurrent Unit for Efficient Industrial Gas Identification",
    "authors": [
      "Ding Wang"
    ],
    "abstract": "In recent years, gas recognition technology has received considerable\nattention. Nevertheless, the gas recognition area has faced obstacles in\nimplementing deep learning-based recognition solutions due to the absence of\nstandardized protocols. To tackle this problem, we suggest a new GRU. Compared\nto other models, GRU obtains a higher identification accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16997v2",
    "published_date": "2024-06-24 10:05:01 UTC",
    "updated_date": "2024-10-14 13:56:47 UTC"
  },
  {
    "arxiv_id": "2406.16494v1",
    "title": "Cross-domain Transfer of Valence Preferences via a Meta-optimization Approach",
    "authors": [
      "Chuang Zhao",
      "Hongke Zhao",
      "Ming He",
      "Xiaomeng Li",
      "Jianping Fan"
    ],
    "abstract": "Cross-domain recommendation offers a potential avenue for alleviating data\nsparsity and cold-start problems. Embedding and mapping, as a classic\ncross-domain research genre, aims to identify a common mapping function to\nperform representation transformation between two domains. Nevertheless,\nprevious coarse-grained preference representations, non-personalized mapping\nfunctions, and excessive reliance on overlapping users limit their performance,\nespecially in scenarios where overlapping users are sparse. To address\naforementioned challenges, we propose a novel cross-domain approach, namely\nCVPM. CVPM formalizes cross-domain interest transfer as a hybrid architecture\nof parametric meta-learning and self-supervised learning, which not only\ntransfers user preferences at a finer level, but also enables signal\nenhancement with the knowledge of non-overlapping users. Specifically, with\ndeep insights into user preferences and valence preference theory, we believe\nthat there exists significant difference between users' positive preferences\nand negative behaviors, and thus employ differentiated encoders to learn their\ndistributions. In particular, we further utilize the pre-trained model and item\npopularity to sample pseudo-interaction items to ensure the integrity of both\ndistributions. To guarantee the personalization of preference transfer, we\ntreat each user's mapping as two parts, the common transformation and the\npersonalized bias, where the network used to generate the personalized bias is\noutput by a meta-learner. Furthermore, in addition to the supervised loss for\noverlapping users, we design contrastive tasks for non-overlapping users from\nboth group and individual-levels to avoid model skew and enhance the semantics\nof representations. Exhaustive data analysis and extensive experimental results\ndemonstrate the effectiveness and advancement of our proposed framework.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16494v1",
    "published_date": "2024-06-24 10:02:24 UTC",
    "updated_date": "2024-06-24 10:02:24 UTC"
  },
  {
    "arxiv_id": "2406.16486v1",
    "title": "Towards Comprehensive Preference Data Collection for Reward Modeling",
    "authors": [
      "Yulan Hu",
      "Qingyang Li",
      "Sheng Ouyang",
      "Ge Chen",
      "Kaihui Chen",
      "Lijun Mei",
      "Xucheng Ye",
      "Fuzheng Zhang",
      "Yong Liu"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment\nof large language models (LLMs) with human preferences, thereby enhancing the\nquality of responses generated. A critical component of RLHF is the reward\nmodel, which is trained on preference data and outputs a scalar reward during\nthe inference stage. However, the collection of preference data still lacks\nthorough investigation. Recent studies indicate that preference data is\ncollected either by AI or humans, where chosen and rejected instances are\nidentified among pairwise responses. We question whether this process\neffectively filters out noise and ensures sufficient diversity in collected\ndata. To address these concerns, for the first time, we propose a comprehensive\nframework for preference data collection, decomposing the process into four\nincremental steps: Prompt Generation, Response Generation, Response Filtering,\nand Human Labeling. This structured approach ensures the collection of\nhigh-quality preferences while reducing reliance on human labor. We conducted\ncomprehensive experiments based on the data collected at different stages,\ndemonstrating the effectiveness of the proposed data collection method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16486v1",
    "published_date": "2024-06-24 09:40:39 UTC",
    "updated_date": "2024-06-24 09:40:39 UTC"
  },
  {
    "arxiv_id": "2406.16479v1",
    "title": "Emerging NeoHebbian Dynamics in Forward-Forward Learning: Implications for Neuromorphic Computing",
    "authors": [
      "Erik B. Terres-Escudero",
      "Javier Del Ser",
      "Pablo García-Bringas"
    ],
    "abstract": "Advances in neural computation have predominantly relied on the gradient\nbackpropagation algorithm (BP). However, the recent shift towards\nnon-stationary data modeling has highlighted the limitations of this heuristic,\nexposing that its adaptation capabilities are far from those seen in biological\nbrains. Unlike BP, where weight updates are computed through a reverse error\npropagation path, Hebbian learning dynamics provide synaptic updates using only\ninformation within the layer itself. This has spurred interest in biologically\nplausible learning algorithms, hypothesized to overcome BP's shortcomings. In\nthis context, Hinton recently introduced the Forward-Forward Algorithm (FFA),\nwhich employs local learning rules for each layer and has empirically proven\nits efficacy in multiple data modeling tasks. In this work we argue that when\nemploying a squared Euclidean norm as a goodness function driving the local\nlearning, the resulting FFA is equivalent to a neo-Hebbian Learning Rule. To\nverify this result, we compare the training behavior of FFA in analog networks\nwith its Hebbian adaptation in spiking neural networks. Our experiments\ndemonstrate that both versions of FFA produce similar accuracy and latent\ndistributions. The findings herein reported provide empirical evidence linking\nbiological learning rules with currently used training algorithms, thus paving\nthe way towards extrapolating the positive outcomes from FFA to Hebbian\nlearning rules. Simultaneously, our results imply that analog networks trained\nunder FFA could be directly applied to neuromorphic computing, leading to\nreduced energy usage and increased computational speed.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16479v1",
    "published_date": "2024-06-24 09:33:56 UTC",
    "updated_date": "2024-06-24 09:33:56 UTC"
  },
  {
    "arxiv_id": "2406.16473v2",
    "title": "D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise Mitigation in Vision-based Affective Recognition",
    "authors": [
      "Haoran Wang",
      "Xinji Mai",
      "Zeng Tao",
      "Xuan Tong",
      "Junxiong Lin",
      "Yan Wang",
      "Jiawen Yu",
      "Boyang Wang",
      "Shaoqi Yan",
      "Qing Zhao",
      "Ziheng Zhou",
      "Shuyong Gao",
      "Wenqiang Zhang"
    ],
    "abstract": "The contemporary state-of-the-art of Dynamic Facial Expression Recognition\n(DFER) technology facilitates remarkable progress by deriving emotional\nmappings of facial expressions from video content, underpinned by training on\nvoluminous datasets. Yet, the DFER datasets encompass a substantial volume of\nnoise data. Noise arises from low-quality captures that defy logical labeling,\nand instances that suffer from mislabeling due to annotation bias, engendering\ntwo principal types of uncertainty: the uncertainty regarding data usability\nand the uncertainty concerning label reliability. Addressing the two types of\nuncertainty, we have meticulously crafted a two-stage framework aiming at\n\\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain\ndata (SCIU). This initiative aims to purge the DFER datasets of these\nuncertainties, thereby ensuring that only clean, verified data is employed in\ntraining processes. To mitigate the issue of low-quality samples, we introduce\nthe Coarse-Grained Pruning (CGP) stage, which assesses sample weights and\nprunes those deemed unusable due to their low weight. For samples with\nincorrect annotations, the Fine-Grained Correction (FGC) stage evaluates\nprediction stability to rectify mislabeled data. Moreover, SCIU is conceived as\na universally compatible, plug-and-play framework, tailored to integrate\nseamlessly with prevailing DFER methodologies. Rigorous experiments across\nprevalent DFER datasets and against numerous benchmark methods substantiates\nSCIU's capacity to markedly elevate performance metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16473v2",
    "published_date": "2024-06-24 09:25:02 UTC",
    "updated_date": "2024-11-06 02:17:05 UTC"
  },
  {
    "arxiv_id": "2406.16464v5",
    "title": "InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection",
    "authors": [
      "Junjie Chen",
      "Hang Yu",
      "Subin Huang",
      "Sanmin Liu",
      "Linfeng Zhang"
    ],
    "abstract": "Sarcasm in social media, often expressed through text-image combinations,\nposes challenges for sentiment analysis and intention mining. Current\nmulti-modal sarcasm detection methods have been demonstrated to overly rely on\nspurious cues within the textual modality, revealing a limited ability to\ngenuinely identify sarcasm through nuanced text-image interactions. To solve\nthis problem, we propose InterCLIP-MEP, which introduces Interactive CLIP\n(InterCLIP) with an efficient training strategy to extract enriched text-image\nrepresentations by embedding cross-modal information directly into each\nencoder. Additionally, we design a Memory-Enhanced Predictor (MEP) with a\ndynamic dual-channel memory that stores valuable test sample knowledge during\ninference, acting as a non-parametric classifier for robust sarcasm\nrecognition. Experiments on two benchmarks demonstrate that InterCLIP-MEP\nachieves state-of-the-art performance, with significant accuracy and F1 score\nimprovements on MMSD and MMSD2.0. Our code is available at\nhttps://github.com/CoderChen01/InterCLIP-MEP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures, 11 tables; Code and data are available at\n  https://github.com/CoderChen01/InterCLIP-MEP",
    "pdf_url": "http://arxiv.org/pdf/2406.16464v5",
    "published_date": "2024-06-24 09:13:42 UTC",
    "updated_date": "2024-12-16 04:13:38 UTC"
  },
  {
    "arxiv_id": "2407.00081v1",
    "title": "Semantic Revolution from Communications to Orchestration for 6G: Challenges, Enablers, and Research Directions",
    "authors": [
      "Masoud Shokrnezhad",
      "Hamidreza Mazandarani",
      "Tarik Taleb",
      "Jaeseung Song",
      "Richard Li"
    ],
    "abstract": "In the context of emerging 6G services, the realization of\neverything-to-everything interactions involving a myriad of physical and\ndigital entities presents a crucial challenge. This challenge is exacerbated by\nresource scarcity in communication infrastructures, necessitating innovative\nsolutions for effective service implementation. Exploring the potential of\nSemantic Communications (SemCom) to enhance point-to-point physical layer\nefficiency shows great promise in addressing this challenge. However, achieving\nefficient SemCom requires overcoming the significant hurdle of knowledge\nsharing between semantic decoders and encoders, particularly in the dynamic and\nnon-stationary environment with stringent end-to-end quality requirements. To\nbridge this gap in existing literature, this paper introduces the Knowledge\nBase Management And Orchestration (KB-MANO) framework. Rooted in the concepts\nof Computing-Network Convergence (CNC) and lifelong learning, KB-MANO is\ncrafted for the allocation of network and computing resources dedicated to\nupdating and redistributing KBs across the system. The primary objective is to\nminimize the impact of knowledge management activities on actual service\nprovisioning. A proof-of-concept is proposed to showcase the integration of\nKB-MANO with resource allocation in radio access networks. Finally, the paper\noffers insights into future research directions, emphasizing the transformative\npotential of semantic-oriented communication systems in the realm of 6G\ntechnology.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at IEEE Network magazine special issue: Goal-oriented\n  Semantic Communication and Networking",
    "pdf_url": "http://arxiv.org/pdf/2407.00081v1",
    "published_date": "2024-06-24 09:04:09 UTC",
    "updated_date": "2024-06-24 09:04:09 UTC"
  },
  {
    "arxiv_id": "2406.16455v1",
    "title": "Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models",
    "authors": [
      "Daniel Lopez-Martinez"
    ],
    "abstract": "Generative AI (GenAI) models have demonstrated remarkable capabilities in a\nwide variety of medical tasks. However, as these models are trained using\ngeneralist datasets with very limited human oversight, they can learn uses of\nmedical products that have not been adequately evaluated for safety and\nefficacy, nor approved by regulatory agencies. Given the scale at which GenAI\nmay reach users, unvetted recommendations pose a public health risk. In this\nwork, we propose an approach to identify potentially harmful product\nrecommendations, and demonstrate it using a recent multimodal large language\nmodel.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "CVPR 2024 Responsible Generative AI (ReGenAI) workshop",
    "pdf_url": "http://arxiv.org/pdf/2406.16455v1",
    "published_date": "2024-06-24 08:50:26 UTC",
    "updated_date": "2024-06-24 08:50:26 UTC"
  },
  {
    "arxiv_id": "2406.16453v2",
    "title": "Learning in Wilson-Cowan model for metapopulation",
    "authors": [
      "Raffaele Marino",
      "Lorenzo Buffoni",
      "Lorenzo Chicchi",
      "Francesca Di Patti",
      "Diego Febbe",
      "Lorenzo Giambagli",
      "Duccio Fanelli"
    ],
    "abstract": "The Wilson-Cowan model for metapopulation, a Neural Mass Network Model,\ntreats different subcortical regions of the brain as connected nodes, with\nconnections representing various types of structural, functional, or effective\nneuronal connectivity between these regions. Each region comprises interacting\npopulations of excitatory and inhibitory cells, consistent with the standard\nWilson-Cowan model. By incorporating stable attractors into such a\nmetapopulation model's dynamics, we transform it into a learning algorithm\ncapable of achieving high image and text classification accuracy. We test it on\nMNIST and Fashion MNIST, in combination with convolutional neural networks, on\nCIFAR-10 and TF-FLOWERS, and, in combination with a transformer architecture\n(BERT), on IMDB, always showing high classification accuracy. These numerical\nevaluations illustrate that minimal modifications to the Wilson-Cowan model for\nmetapopulation can reveal unique and previously unobserved dynamics.",
    "categories": [
      "q-bio.NC",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Paper Accepted in Neural Computation (in press)",
    "pdf_url": "http://arxiv.org/pdf/2406.16453v2",
    "published_date": "2024-06-24 08:45:03 UTC",
    "updated_date": "2024-12-05 16:39:32 UTC"
  },
  {
    "arxiv_id": "2406.16995v2",
    "title": "tcrLM: a lightweight protein language model for predicting T cell receptor and epitope binding specificity",
    "authors": [
      "Xing Fang",
      "Chenpeng Yu",
      "Shiye Tian",
      "Hui Liu"
    ],
    "abstract": "The anti-cancer immune response relies on the bindings between T-cell\nreceptors (TCRs) and antigens, which elicits adaptive immunity to eliminate\ntumor cells. This ability of the immune system to respond to novel various\nneoantigens arises from the immense diversity of TCR repository. However, TCR\ndiversity poses a significant challenge on accurately predicting antigen-TCR\nbindings. In this study, we introduce a lightweight masked language model,\ntermed tcrLM, to address this challenge. Our approach involves randomly masking\nsegments of TCR sequences and training tcrLM to infer the masked segments,\nthereby enabling the extraction of expressive features from TCR sequences. To\nfurther enhance robustness, we incorporate virtual adversarial training into\ntcrLM. We construct the largest TCR CDR3 sequence set with more than 100\nmillion distinct sequences, and pretrain tcrLM on these sequences. The\npre-trained encoder is subsequently applied to predict TCR-antigen binding\nspecificity. We evaluate model performance on three test datasets: independent,\nexternal, and COVID-19 test set. The results demonstrate that tcrLM not only\nsurpasses existing TCR-antigen binding prediction methods, but also outperforms\nother mainstream protein language models. More interestingly, tcrLM effectively\ncaptures the biochemical properties and positional preference of amino acids\nwithin TCR sequences. Additionally, the predicted TCR-neoantigen binding scores\nindicates the immunotherapy responses and clinical outcomes in a melanoma\ncohort. These findings demonstrate the potential of tcrLM in predicting\nTCR-antigen binding specificity, with significant implications for advancing\nimmunotherapy and personalized medicine.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16995v2",
    "published_date": "2024-06-24 08:36:40 UTC",
    "updated_date": "2024-12-04 14:33:44 UTC"
  },
  {
    "arxiv_id": "2406.16437v3",
    "title": "Theory on Mixture-of-Experts in Continual Learning",
    "authors": [
      "Hongbo Li",
      "Sen Lin",
      "Lingjie Duan",
      "Yingbin Liang",
      "Ness B. Shroff"
    ],
    "abstract": "Continual learning (CL) has garnered significant attention because of its\nability to adapt to new tasks that arrive over time. Catastrophic forgetting\n(of old tasks) has been identified as a major issue in CL, as the model adapts\nto new tasks. The Mixture-of-Experts (MoE) model has recently been shown to\neffectively mitigate catastrophic forgetting in CL, by employing a gating\nnetwork to sparsify and distribute diverse tasks among multiple experts.\nHowever, there is a lack of theoretical analysis of MoE and its impact on the\nlearning performance in CL. This paper provides the first theoretical results\nto characterize the impact of MoE in CL via the lens of overparameterized\nlinear regression tasks. We establish the benefit of MoE over a single expert\nby proving that the MoE model can diversify its experts to specialize in\ndifferent tasks, while its router learns to select the right expert for each\ntask and balance the loads across all experts. Our study further suggests an\nintriguing fact that the MoE in CL needs to terminate the update of the gating\nnetwork after sufficient training rounds to attain system convergence, which is\nnot needed in the existing MoE studies that do not consider the continual task\narrival. Furthermore, we provide explicit expressions for the expected\nforgetting and overall generalization error to characterize the benefit of MoE\nin the learning performance in CL. Interestingly, adding more experts requires\nadditional rounds before convergence, which may not enhance the learning\nperformance. Finally, we conduct experiments on both synthetic and real\ndatasets to extend these insights from linear models to deep neural networks\n(DNNs), which also shed light on the practical algorithm design for MoE in CL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2406.16437v3",
    "published_date": "2024-06-24 08:29:58 UTC",
    "updated_date": "2025-02-19 14:35:07 UTC"
  },
  {
    "arxiv_id": "2406.16427v1",
    "title": "Dynamic Pseudo Label Optimization in Point-Supervised Nuclei Segmentation",
    "authors": [
      "Ziyue Wang",
      "Ye Zhang",
      "Yifeng Wang",
      "Linghan Cai",
      "Yongbing Zhang"
    ],
    "abstract": "Deep learning has achieved impressive results in nuclei segmentation, but the\nmassive requirement for pixel-wise labels remains a significant challenge. To\nalleviate the annotation burden, existing methods generate pseudo masks for\nmodel training using point labels. However, the generated masks are inevitably\ndifferent from the ground truth, and these dissimilarities are not handled\nreasonably during the network training, resulting in the subpar performance of\nthe segmentation model. To tackle this issue, we propose a framework named\nDoNuSeg, enabling \\textbf{D}ynamic pseudo label \\textbf{O}ptimization in\npoint-supervised \\textbf{Nu}clei \\textbf{Seg}mentation. Specifically, DoNuSeg\ntakes advantage of class activation maps (CAMs) to adaptively capture regions\nwith semantics similar to annotated points. To leverage semantic diversity in\nthe hierarchical feature levels, we design a dynamic selection module to choose\nthe optimal one among CAMs from different encoder blocks as pseudo masks.\nMeanwhile, a CAM-guided contrastive module is proposed to further enhance the\naccuracy of pseudo masks. In addition to exploiting the semantic information\nprovided by CAMs, we consider location priors inherent to point labels,\ndeveloping a task-decoupled structure for effectively differentiating nuclei.\nExtensive experiments demonstrate that DoNuSeg outperforms state-of-the-art\npoint-supervised methods. The code is available at\nhttps://github.com/shinning0821/MICCAI24-DoNuSeg.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "early accepted by MICCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16427v1",
    "published_date": "2024-06-24 08:20:53 UTC",
    "updated_date": "2024-06-24 08:20:53 UTC"
  },
  {
    "arxiv_id": "2406.16426v3",
    "title": "Fault Detection for agents on power grid topology optimization: A Comprehensive analysis",
    "authors": [
      "Malte Lehna",
      "Mohamed Hassouna",
      "Dmitry Degtyar",
      "Sven Tomforde",
      "Christoph Scholz"
    ],
    "abstract": "Optimizing the topology of transmission networks using Deep Reinforcement\nLearning (DRL) has increasingly come into focus. Various DRL agents have been\nproposed, which are mostly benchmarked on the Grid2Op environment from the\nLearning to Run a Power Network (L2RPN) challenges. The environments have many\nadvantages with their realistic grid scenarios and underlying power flow\nbackends. However, the interpretation of agent survival or failure is not\nalways clear, as there are a variety of potential causes. In this work, we\nfocus on the failures of the power grid simulation to identify patterns and\ndetect them in advance. We collect the failed scenarios of three different\nagents on the WCCI 2022 L2RPN environment, totaling about 40k data points. By\nclustering, we are able to detect five distinct clusters, identifying common\nfailure types. Further, we propose a multi-class prediction approach to detect\nfailures beforehand and evaluate five different prediction models. Here, the\nLight Gradient-Boosting Machine (LightGBM) shows the best failure prediction\nperformance, with an accuracy of 82%. It also accurately classifies whether a\nthe grid survives or fails in 87% of cases. Finally, we provide a detailed\nfeature importance analysis that identifies critical features and regions in\nthe grid.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Pages plus references and appendix. The appendix consist of\n  additional material of the paper and is not included in the initial\n  submission. The paper was presented at the ECML workshop ML4SPS",
    "pdf_url": "http://arxiv.org/pdf/2406.16426v3",
    "published_date": "2024-06-24 08:20:43 UTC",
    "updated_date": "2024-09-17 14:54:29 UTC"
  },
  {
    "arxiv_id": "2406.16424v2",
    "title": "Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial Optimization",
    "authors": [
      "Felix Chalumeau",
      "Refiloe Shabe",
      "Noah De Nicola",
      "Arnu Pretorius",
      "Thomas D. Barrett",
      "Nathan Grinsztajn"
    ],
    "abstract": "Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an approach that leverages memory to improve the adaptation of neural\nsolvers at inference time. MEMENTO enables updating the action distribution\ndynamically based on the outcome of previous decisions. We validate its\neffectiveness on benchmark problems, in particular Traveling Salesman and\nCapacitated Vehicle Routing, demonstrating its superiority over tree-search and\npolicy-gradient fine-tuning; and showing it can be zero-shot combined with\ndiversity-based solvers. We successfully train all RL auto-regressive solvers\non large instances, and show that MEMENTO can scale and is data-efficient.\nOverall, MEMENTO enables to push the state-of-the-art on 11 out of 12 evaluated\ntasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16424v2",
    "published_date": "2024-06-24 08:18:19 UTC",
    "updated_date": "2024-10-07 15:33:37 UTC"
  },
  {
    "arxiv_id": "2406.16422v1",
    "title": "Exploring Cross-Domain Few-Shot Classification via Frequency-Aware Prompting",
    "authors": [
      "Tiange Zhang",
      "Qing Cai",
      "Feng Gao",
      "Lin Qi",
      "Junyu Dong"
    ],
    "abstract": "Cross-Domain Few-Shot Learning has witnessed great stride with the\ndevelopment of meta-learning. However, most existing methods pay more attention\nto learning domain-adaptive inductive bias (meta-knowledge) through\nfeature-wise manipulation or task diversity improvement while neglecting the\nphenomenon that deep networks tend to rely more on high-frequency cues to make\nthe classification decision, which thus degenerates the robustness of learned\ninductive bias since high-frequency information is vulnerable and easy to be\ndisturbed by noisy information. Hence in this paper, we make one of the first\nattempts to propose a Frequency-Aware Prompting method with mutual attention\nfor Cross-Domain Few-Shot classification, which can let networks simulate the\nhuman visual perception of selecting different frequency cues when facing new\nrecognition tasks. Specifically, a frequency-aware prompting mechanism is first\nproposed, in which high-frequency components of the decomposed source image are\nswitched either with normal distribution sampling or zeroing to get\nfrequency-aware augment samples. Then, a mutual attention module is designed to\nlearn generalizable inductive bias under CD-FSL settings. More importantly, the\nproposed method is a plug-and-play module that can be directly applied to most\noff-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks\ndemonstrate the effectiveness of our proposed method as well as robustly\nimprove the performance of existing CD-FLS methods. Resources at\nhttps://github.com/tinkez/FAP_CDFSC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16422v1",
    "published_date": "2024-06-24 08:14:09 UTC",
    "updated_date": "2024-06-24 08:14:09 UTC"
  },
  {
    "arxiv_id": "2406.16994v1",
    "title": "Quantum Multi-Agent Reinforcement Learning for Cooperative Mobile Access in Space-Air-Ground Integrated Networks",
    "authors": [
      "Gyu Seon Kim",
      "Yeryeong Cho",
      "Jaehyun Chung",
      "Soohyun Park",
      "Soyi Jung",
      "Zhu Han",
      "Joongheon Kim"
    ],
    "abstract": "Achieving global space-air-ground integrated network (SAGIN) access only with\nCubeSats presents significant challenges such as the access sustainability\nlimitations in specific regions (e.g., polar regions) and the energy efficiency\nlimitations in CubeSats. To tackle these problems, high-altitude long-endurance\nunmanned aerial vehicles (HALE-UAVs) can complement these CubeSat shortcomings\nfor providing cooperatively global access sustainability and energy efficiency.\nHowever, as the number of CubeSats and HALE-UAVs, increases, the scheduling\ndimension of each ground station (GS) increases. As a result, each GS can fall\ninto the curse of dimensionality, and this challenge becomes one major hurdle\nfor efficient global access. Therefore, this paper provides a quantum\nmulti-agent reinforcement Learning (QMARL)-based method for scheduling between\nGSs and CubeSats/HALE-UAVs in order to improve global access availability and\nenergy efficiency. The main reason why the QMARL-based scheduler can be\nbeneficial is that the algorithm facilitates a logarithmic-scale reduction in\nscheduling action dimensions, which is one critical feature as the number of\nCubeSats and HALE-UAVs expands. Additionally, individual GSs have different\ntraffic demands depending on their locations and characteristics, thus it is\nessential to provide differentiated access services. The superiority of the\nproposed scheduler is validated through data-intensive experiments in realistic\nCubeSat/HALE-UAV settings.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "17 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16994v1",
    "published_date": "2024-06-24 08:12:04 UTC",
    "updated_date": "2024-06-24 08:12:04 UTC"
  },
  {
    "arxiv_id": "2406.16388v1",
    "title": "PenSLR: Persian end-to-end Sign Language Recognition Using Ensembling",
    "authors": [
      "Amirparsa Salmankhah",
      "Amirreza Rajabi",
      "Negin Kheirmand",
      "Ali Fadaeimanesh",
      "Amirreza Tarabkhah",
      "Amirreza Kazemzadeh",
      "Hamed Farbeh"
    ],
    "abstract": "Sign Language Recognition (SLR) is a fast-growing field that aims to fill the\ncommunication gaps between the hearing-impaired and people without hearing\nloss. Existing solutions for Persian Sign Language (PSL) are limited to\nword-level interpretations, underscoring the need for more advanced and\ncomprehensive solutions. Moreover, previous work on other languages mainly\nfocuses on manipulating the neural network architectures or hardware\nconfigurations instead of benefiting from the aggregated results of multiple\nmodels. In this paper, we introduce PenSLR, a glove-based sign language system\nconsisting of an Inertial Measurement Unit (IMU) and five flexible sensors\npowered by a deep learning framework capable of predicting variable-length\nsequences. We achieve this in an end-to-end manner by leveraging the\nConnectionist Temporal Classification (CTC) loss function, eliminating the need\nfor segmentation of input signals. To further enhance its capabilities, we\npropose a novel ensembling technique by leveraging a multiple sequence\nalignment algorithm known as Star Alignment. Furthermore, we introduce a new\nPSL dataset, including 16 PSL signs with more than 3000 time-series samples in\ntotal. We utilize this dataset to evaluate the performance of our system based\non four word-level and sentence-level metrics. Our evaluations show that PenSLR\nachieves a remarkable word accuracy of 94.58% and 96.70% in subject-independent\nand subject-dependent setups, respectively. These achievements are attributable\nto our ensembling algorithm, which not only boosts the word-level performance\nby 0.51% and 1.32% in the respective scenarios but also yields significant\nenhancements of 1.46% and 4.00%, respectively, in sentence-level accuracy.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16388v1",
    "published_date": "2024-06-24 07:59:34 UTC",
    "updated_date": "2024-06-24 07:59:34 UTC"
  },
  {
    "arxiv_id": "2406.16386v3",
    "title": "Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach",
    "authors": [
      "Yuxuan Wan",
      "Chaozheng Wang",
      "Yi Dong",
      "Wenxuan Wang",
      "Shuqing Li",
      "Yintong Huo",
      "Michael R. Lyu"
    ],
    "abstract": "Websites are critical in today's digital world, with over 1.11 billion\ncurrently active and approximately 252,000 new sites launched daily. Converting\nwebsite layout design into functional UI code is a time-consuming yet\nindispensable step of website development. Manual methods of converting visual\ndesigns into functional code present significant challenges, especially for\nnon-experts. To explore automatic design-to-code solutions, we first conduct a\nmotivating study on GPT-4o and identify three types of issues in generating UI\ncode: element omission, element distortion, and element misarrangement. We\nfurther reveal that a focus on smaller visual segments can help multimodal\nlarge language models (MLLMs) mitigate these failures in the generation\nprocess.\n  In this paper, we propose DCGen, a divide-and-conquer-based approach to\nautomate the translation of webpage design to UI code. DCGen starts by dividing\nscreenshots into manageable segments, generating code for each segment, and\nthen reassembling them into complete UI code for the entire screenshot. We\nconduct extensive testing with a dataset comprised of real-world websites and\nvarious MLLMs and demonstrate that DCGen achieves up to a 15% improvement in\nvisual similarity and 8% in code similarity for large input images. Human\nevaluations show that DCGen can help developers implement webpages\nsignificantly faster and more similar to the UI designs. To the best of our\nknowledge, DCGen is the first segment-aware MLLM-based approach for generating\nUI code directly from screenshots.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by FSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.16386v3",
    "published_date": "2024-06-24 07:58:36 UTC",
    "updated_date": "2025-04-25 15:12:34 UTC"
  },
  {
    "arxiv_id": "2406.17732v1",
    "title": "EMVD dataset: a dataset of extreme vocal distortion techniques used in heavy metal",
    "authors": [
      "Modan Tailleur",
      "Julien Pinquier",
      "Laurent Millot",
      "Corsin Vogel",
      "Mathieu Lagrange"
    ],
    "abstract": "In this paper, we introduce the Extreme Metal Vocals Dataset, which comprises\na collection of recordings of extreme vocal techniques performed within the\nrealm of heavy metal music. The dataset consists of 760 audio excerpts of 1\nsecond to 30 seconds long, totaling about 100 min of audio material, roughly\ncomposed of 60 minutes of distorted voices and 40 minutes of clear voice\nrecordings. These vocal recordings are from 27 different singers and are\nprovided without accompanying musical instruments or post-processing effects.\nThe distortion taxonomy within this dataset encompasses four distinct\ndistortion techniques and three vocal effects, all performed in different pitch\nranges. Performance of a state-of-the-art deep learning model is evaluated for\ntwo different classification tasks related to vocal techniques, demonstrating\nthe potential of this resource for the audio processing community.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "physics.class-ph"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17732v1",
    "published_date": "2024-06-24 07:50:52 UTC",
    "updated_date": "2024-06-24 07:50:52 UTC"
  },
  {
    "arxiv_id": "2406.16377v1",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "authors": [
      "Deng Cai",
      "Huayang Li",
      "Tingchen Fu",
      "Siheng Li",
      "Weiwen Xu",
      "Shuaiyi Li",
      "Bowen Cao",
      "Zhisong Zhang",
      "Xinting Huang",
      "Leyang Cui",
      "Yan Wang",
      "Lemao Liu",
      "Taro Watanabe",
      "Shuming Shi"
    ],
    "abstract": "Despite the general capabilities of pre-trained large language models (LLMs),\nthey still need further adaptation to better serve practical applications. In\nthis paper, we demonstrate the interchangeability of three popular and distinct\nadaptation tools: parameter updating, reward modeling, and in-context\nprompting. This interchangeability establishes a triangular framework with six\ntransformation directions, each of which facilitates a variety of applications.\nOur work offers a holistic view that unifies numerous existing studies and\nsuggests potential research directions. We envision our work as a useful\nroadmap for future research on LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16377v1",
    "published_date": "2024-06-24 07:42:32 UTC",
    "updated_date": "2024-06-24 07:42:32 UTC"
  },
  {
    "arxiv_id": "2406.16992v1",
    "title": "Make Graph Neural Networks Great Again: A Generic Integration Paradigm of Topology-Free Patterns for Traffic Speed Prediction",
    "authors": [
      "Yicheng Zhou",
      "Pengfei Wang",
      "Hao Dong",
      "Denghui Zhang",
      "Dingqi Yang",
      "Yanjie Fu",
      "Pengyang Wang"
    ],
    "abstract": "Urban traffic speed prediction aims to estimate the future traffic speed for\nimproving urban transportation services. Enormous efforts have been made to\nexploit Graph Neural Networks (GNNs) for modeling spatial correlations and\ntemporal dependencies of traffic speed evolving patterns, regularized by graph\ntopology.While achieving promising results, current traffic speed prediction\nmethods still suffer from ignoring topology-free patterns, which cannot be\ncaptured by GNNs. To tackle this challenge, we propose a generic model for\nenabling the current GNN-based methods to preserve topology-free patterns.\nSpecifically, we first develop a Dual Cross-Scale Transformer (DCST)\narchitecture, including a Spatial Transformer and a Temporal Transformer, to\npreserve the cross-scale topology-free patterns and associated dynamics,\nrespectively. Then, to further integrate both topology-regularized/-free\npatterns, we propose a distillation-style learning framework, in which the\nexisting GNN-based methods are considered as the teacher model, and the\nproposed DCST architecture is considered as the student model. The teacher\nmodel would inject the learned topology-regularized patterns into the student\nmodel for integrating topology-free patterns. The extensive experimental\nresults demonstrated the effectiveness of our methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16992v1",
    "published_date": "2024-06-24 07:32:58 UTC",
    "updated_date": "2024-06-24 07:32:58 UTC"
  },
  {
    "arxiv_id": "2406.16357v1",
    "title": "Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification",
    "authors": [
      "Beini Xie",
      "Heng Chang",
      "Ziwei Zhang",
      "Zeyang Zhang",
      "Simin Wu",
      "Xin Wang",
      "Yuan Meng",
      "Wenwu Zhu"
    ],
    "abstract": "Graph Neural Architecture Search (GNAS) has achieved superior performance on\nvarious graph-structured tasks. However, existing GNAS studies overlook the\napplications of GNAS in resource-constraint scenarios. This paper proposes to\ndesign a joint graph data and architecture mechanism, which identifies\nimportant sub-architectures via the valuable graph data. To search for optimal\nlightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural\nArchitecture Search with Graph SparsIfication and Network Pruning (GASSIP)\nmethod. In particular, GASSIP comprises an operation-pruned architecture search\nmodule to enable efficient lightweight GNN search. Meanwhile, we design a novel\ncurriculum graph data sparsification module with an architecture-aware\nedge-removing difficulty measurement to help select optimal sub-architectures.\nWith the aid of two differentiable masks, we iteratively optimize these two\nmodules to efficiently search for the optimal lightweight architecture.\nExtensive experiments on five benchmarks demonstrate the effectiveness of\nGASSIP. Particularly, our method achieves on-par or even higher node\nclassification performance with half or fewer model parameters of searched GNNs\nand a sparser graph.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024. The two first authors made equal contributions",
    "pdf_url": "http://arxiv.org/pdf/2406.16357v1",
    "published_date": "2024-06-24 06:53:37 UTC",
    "updated_date": "2024-06-24 06:53:37 UTC"
  },
  {
    "arxiv_id": "2406.16346v1",
    "title": "Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks",
    "authors": [
      "Daniel Wen",
      "Nafisa Hussain"
    ],
    "abstract": "Large language models (LLMs) and large visual language models (LVLMs) have\nbeen at the forefront of the artificial intelligence field, particularly for\ntasks like text generation, video captioning, and question-answering.\nTypically, it is more applicable to train these models on broader knowledge\nbases or datasets to increase generalizability, learn relationships between\ntopics, and recognize patterns. Instead, we propose to provide instructional\ndatasets specific to the task of each modality within a distinct domain and\nthen fine-tune the parameters of the model using LORA. With our approach, we\ncan eliminate all noise irrelevant to the given task while also ensuring that\nthe model generates with enhanced precision. For this work, we use Video-LLaVA\nto generate recipes given cooking videos without transcripts. Video-LLaVA's\nmultimodal architecture allows us to provide cooking images to its image\nencoder, cooking videos to its video encoder, and general cooking questions to\nits text encoder. Thus, we aim to remove all noise unrelated to cooking while\nimproving our model's capabilities to generate specific ingredient lists and\ndetailed instructions. As a result, our approach to fine-tuning Video-LLaVA\nleads to gains over the baseline Video-LLaVA by 2% on the YouCook2 dataset.\nWhile this may seem like a marginal increase, our model trains on an image\ninstruction dataset 2.5% the size of Video-LLaVA's and a video instruction\ndataset 23.76% of Video-LLaVA's.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16346v1",
    "published_date": "2024-06-24 06:39:02 UTC",
    "updated_date": "2024-06-24 06:39:02 UTC"
  },
  {
    "arxiv_id": "2406.16333v1",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "authors": [
      "Yichen Sun",
      "Zhixuan Chu",
      "Zhan Qin",
      "Kui Ren"
    ],
    "abstract": "The rapid advancement of Text-to-Image(T2I) generative models has enabled the\nsynthesis of high-quality images guided by textual descriptions. Despite this\nsignificant progress, these models are often susceptible in generating contents\nthat contradict the input text, which poses a challenge to their reliability\nand practical deployment. To address this problem, we introduce a novel\ndiffusion-based framework to significantly enhance the alignment of generated\nimages with their corresponding descriptions, addressing the inconsistency\nbetween visual output and textual input. Our framework is built upon a\ncomprehensive analysis of inconsistency phenomena, categorizing them based on\ntheir manifestation in the image. Leveraging a state-of-the-art large language\nmodule, we first extract objects and construct a knowledge graph to predict the\nlocations of these objects in potentially generated images. We then integrate a\nstate-of-the-art controllable image generation model with a visual text\ngeneration module to generate an image that is consistent with the original\nprompt, guided by the predicted object locations. Through extensive experiments\non an advanced multimodal hallucination benchmark, we demonstrate the efficacy\nof our approach in accurately generating the images without the inconsistency\nwith the original prompt. The code can be accessed via\nhttps://github.com/TruthAI-Lab/PCIG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16333v1",
    "published_date": "2024-06-24 06:12:16 UTC",
    "updated_date": "2024-06-24 06:12:16 UTC"
  },
  {
    "arxiv_id": "2406.16990v2",
    "title": "AND: Audio Network Dissection for Interpreting Deep Acoustic Models",
    "authors": [
      "Tung-Yu Wu",
      "Yu-Xiang Lin",
      "Tsui-Wei Weng"
    ],
    "abstract": "Neuron-level interpretations aim to explain network behaviors and properties\nby investigating neurons responsive to specific perceptual or structural input\npatterns. Although there is emerging work in the vision and language domains,\nnone is explored for acoustic models. To bridge the gap, we introduce\n$\\textit{AND}$, the first $\\textbf{A}$udio $\\textbf{N}$etwork\n$\\textbf{D}$issection framework that automatically establishes natural language\nexplanations of acoustic neurons based on highly-responsive audio.\n$\\textit{AND}$ features the use of LLMs to summarize mutual acoustic features\nand identities among audio. Extensive experiments are conducted to verify\n$\\textit{AND}$'s precise and informative descriptions. In addition, we\ndemonstrate a potential use of $\\textit{AND}$ for audio machine unlearning by\nconducting concept-specific pruning based on the generated descriptions.\nFinally, we highlight two acoustic model behaviors with analysis by\n$\\textit{AND}$: (i) models discriminate audio with a combination of basic\nacoustic features rather than high-level abstract concepts; (ii) training\nstrategies affect model behaviors and neuron interpretability -- supervised\ntraining guides neurons to gradually narrow their attention, while\nself-supervised learning encourages neurons to be polysemantic for exploring\nhigh-level features.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICML'24",
    "pdf_url": "http://arxiv.org/pdf/2406.16990v2",
    "published_date": "2024-06-24 06:02:07 UTC",
    "updated_date": "2024-06-26 17:36:53 UTC"
  },
  {
    "arxiv_id": "2406.16330v1",
    "title": "Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer Merging",
    "authors": [
      "Deyuan Liu",
      "Zhanyue Qin",
      "Hairu Wang",
      "Zhao Yang",
      "Zecheng Wang",
      "Fangying Rong",
      "Qingbin Liu",
      "Yanchao Hao",
      "Xi Chen",
      "Cunhang Fan",
      "Zhao Lv",
      "Zhiying Tu",
      "Dianhui Chu",
      "Bo Li",
      "Dianbo Sui"
    ],
    "abstract": "While large language models (LLMs) excel in many domains, their complexity\nand scale challenge deployment in resource-limited environments. Current\ncompression techniques, such as parameter pruning, often fail to effectively\nutilize the knowledge from pruned parameters. To address these challenges, we\npropose Manifold-Based Knowledge Alignment and Layer Merging Compression (MKA),\na novel approach that uses manifold learning and the Normalized Pairwise\nInformation Bottleneck (NPIB) measure to merge similar layers, reducing model\nsize while preserving essential performance. We evaluate MKA on multiple\nbenchmark datasets and various LLMs. Our findings show that MKA not only\npreserves model performance but also achieves substantial compression ratios,\noutperforming traditional pruning methods. Moreover, when coupled with\nquantization, MKA delivers even greater compression. Specifically, on the MMLU\ndataset using the Llama3-8B model, MKA achieves a compression ratio of 43.75%\nwith a minimal performance decrease of only 2.82\\%. The proposed MKA method\noffers a resource-efficient and performance-preserving model compression\ntechnique for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16330v1",
    "published_date": "2024-06-24 05:57:55 UTC",
    "updated_date": "2024-06-24 05:57:55 UTC"
  },
  {
    "arxiv_id": "2406.16989v2",
    "title": "Retrieval-Augmented Mixture of LoRA Experts for Uploadable Machine Learning",
    "authors": [
      "Ziyu Zhao",
      "Leilei Gan",
      "Guoyin Wang",
      "Yuwei Hu",
      "Tao Shen",
      "Hongxia Yang",
      "Kun Kuang",
      "Fei Wu"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) offers an efficient way to fine-tune large\nlanguage models (LLMs). Its modular and plug-and-play nature allows the\nintegration of various domain-specific LoRAs, enhancing LLM capabilities.\nOpen-source platforms like Huggingface and Modelscope have introduced a new\ncomputational paradigm, Uploadable Machine Learning (UML). In UML, contributors\nuse decentralized data to train specialized adapters, which are then uploaded\nto a central platform to improve LLMs. This platform uses these domain-specific\nadapters to handle mixed-task requests requiring personalized service. Previous\nresearch on LoRA composition either focuses on specific tasks or fixes the LoRA\nselection during training. However, in UML, the pool of LoRAs is dynamically\nupdated with new uploads, requiring a generalizable selection mechanism for\nunseen LoRAs. Additionally, the mixed-task nature of downstream requests\nnecessitates personalized services. To address these challenges, we propose\nRetrieval-Augmented Mixture of LoRA Experts (RAMoLE), a framework that\nadaptively retrieves and composes multiple LoRAs based on input prompts. RAMoLE\nhas three main components: LoraRetriever for identifying and retrieving\nrelevant LoRAs, an on-the-fly MoLE mechanism for coordinating the retrieved\nLoRAs, and efficient batch inference for handling heterogeneous requests.\nExperimental results show that RAMoLE consistently outperforms baselines,\nhighlighting its effectiveness and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.09997",
    "pdf_url": "http://arxiv.org/pdf/2406.16989v2",
    "published_date": "2024-06-24 05:24:41 UTC",
    "updated_date": "2024-07-16 05:59:06 UTC"
  },
  {
    "arxiv_id": "2406.16321v2",
    "title": "Mosaic of Modalities: A Comprehensive Benchmark for Multimodal Graph Learning",
    "authors": [
      "Jing Zhu",
      "Yuhang Zhou",
      "Shengyi Qian",
      "Zhongmou He",
      "Tong Zhao",
      "Neil Shah",
      "Danai Koutra"
    ],
    "abstract": "Graph machine learning has made significant strides in recent years, yet the\nintegration of visual information with graph structure and its potential for\nimproving performance in downstream tasks remains an underexplored area. To\naddress this critical gap, we introduce the Multimodal Graph Benchmark\n(MM-GRAPH), a pioneering benchmark that incorporates both visual and textual\ninformation into graph learning tasks. MM-GRAPH extends beyond existing\ntext-attributed graph benchmarks, offering a more comprehensive evaluation\nframework for multimodal graph learning Our benchmark comprises seven diverse\ndatasets of varying scales (ranging from thousands to millions of edges),\ndesigned to assess algorithms across different tasks in real-world scenarios.\nThese datasets feature rich multimodal node attributes, including visual data,\nwhich enables a more holistic evaluation of various graph learning frameworks\nin complex, multimodal environments. To support advancements in this emerging\nfield, we provide an extensive empirical study on various graph learning\nframeworks when presented with features from multiple modalities, particularly\nemphasizing the impact of visual information. This study offers valuable\ninsights into the challenges and opportunities of integrating visual data into\ngraph learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.16321v2",
    "published_date": "2024-06-24 05:14:09 UTC",
    "updated_date": "2025-03-30 06:11:30 UTC"
  },
  {
    "arxiv_id": "2406.16316v1",
    "title": "Does Cross-Cultural Alignment Change the Commonsense Morality of Language Models?",
    "authors": [
      "Yuu Jinnai"
    ],
    "abstract": "Alignment of the language model with human preferences is a common approach\nto making a language model useful to end users. However, most alignment work is\ndone in English, and human preference datasets are dominated by English,\nreflecting only the preferences of English-speaking annotators. Nevertheless,\nit is common practice to use the English preference data, either directly or by\ntranslating it into the target language, when aligning a multilingual language\nmodel. The question is whether such an alignment strategy marginalizes the\npreference of non-English speaking users. To this end, we investigate the\neffect of aligning Japanese language models with (mostly) English resources. In\nparticular, we focus on evaluating whether the commonsense morality of the\nresulting fine-tuned models is aligned with Japanese culture using the\nJCommonsenseMorality (JCM) and ETHICS datasets. The experimental results show\nthat the fine-tuned model outperforms the SFT model. However, it does not\ndemonstrate the same level of improvement as a model fine-tuned using the JCM,\nsuggesting that while some aspects of commonsense morality are transferable,\nothers may not be.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The 2nd Workshop on Cross-Cultural Considerations in NLP (C3NLP) at\n  ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16316v1",
    "published_date": "2024-06-24 04:50:12 UTC",
    "updated_date": "2024-06-24 04:50:12 UTC"
  },
  {
    "arxiv_id": "2406.16308v1",
    "title": "Anomaly Detection of Tabular Data Using LLMs",
    "authors": [
      "Aodong Li",
      "Yunhan Zhao",
      "Chen Qiu",
      "Marius Kloft",
      "Padhraic Smyth",
      "Maja Rudolph",
      "Stephan Mandt"
    ],
    "abstract": "Large language models (LLMs) have shown their potential in long-context\nunderstanding and mathematical reasoning. In this paper, we study the problem\nof using LLMs to detect tabular anomalies and show that pre-trained LLMs are\nzero-shot batch-level anomaly detectors. That is, without extra\ndistribution-specific model fitting, they can discover hidden outliers in a\nbatch of data, demonstrating their ability to identify low-density data\nregions. For LLMs that are not well aligned with anomaly detection and\nfrequently output factual errors, we apply simple yet effective data-generating\nprocesses to simulate synthetic batch-level anomaly detection datasets and\npropose an end-to-end fine-tuning strategy to bring out the potential of LLMs\nin detecting real anomalies. Experiments on a large anomaly detection benchmark\n(ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art\ntransductive learning-based anomaly detection methods and ii) the efficacy of\nour synthetic dataset and fine-tuning strategy in aligning LLMs to this task.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at the Anomaly Detection with Foundation Models workshop",
    "pdf_url": "http://arxiv.org/pdf/2406.16308v1",
    "published_date": "2024-06-24 04:17:03 UTC",
    "updated_date": "2024-06-24 04:17:03 UTC"
  },
  {
    "arxiv_id": "2407.12802v1",
    "title": "SimClone: Detecting Tabular Data Clones using Value Similarity",
    "authors": [
      "Xu Yang",
      "Gopi Krishnan Rajbahadur",
      "Dayi Lin",
      "Shaowei Wang",
      "Zhen Ming",
      "Jiang"
    ],
    "abstract": "Data clones are defined as multiple copies of the same data among datasets.\nPresence of data clones between datasets can cause issues such as difficulties\nin managing data assets and data license violations when using datasets with\nclones to build AI software. However, detecting data clones is not trivial.\nMajority of the prior studies in this area rely on structural information to\ndetect data clones (e.g., font size, column header). However, tabular datasets\nused to build AI software are typically stored without any structural\ninformation. In this paper, we propose a novel method called SimClone for data\nclone detection in tabular datasets without relying on structural information.\nSimClone method utilizes value similarities for data clone detection. We also\npropose a visualization approach as a part of our SimClone method to help\nlocate the exact position of the cloned data between a dataset pair. Our\nresults show that our SimClone outperforms the current state-of-the-art method\nby at least 20\\% in terms of both F1-score and AUC. In addition, SimClone's\nvisualization component helps identify the exact location of the data clone in\na dataset with a Precision@10 value of 0.80 in the top 20 true positive\npredictions.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "24 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.12802v1",
    "published_date": "2024-06-24 04:16:32 UTC",
    "updated_date": "2024-06-24 04:16:32 UTC"
  },
  {
    "arxiv_id": "2406.17808v4",
    "title": "Training-Free Exponential Context Extension via Cascading KV Cache",
    "authors": [
      "Jeffrey Willette",
      "Heejun Lee",
      "Youngwan Lee",
      "Myeongjae Jeon",
      "Sung Ju Hwang"
    ],
    "abstract": "The transformer's context window is vital for tasks such as few-shot learning\nand conditional generation as it preserves previous tokens for active memory.\nHowever, as the context lengths increase, the computational costs grow\nquadratically, hindering the deployment of large language models (LLMs) in\nreal-world, long sequence scenarios. Although some recent key-value caching (KV\nCache) methods offer linear inference complexity, they naively manage the\nstored context, prematurely evicting tokens and losing valuable information.\nMoreover, they lack an optimized prefill/prompt stage strategy, resulting in\nhigher latency than even quadratic attention for realistic context sizes. In\nresponse, we introduce a novel mechanism that leverages cascading sub-cache\nbuffers to selectively retain the most relevant tokens, enabling the model to\nmaintain longer context histories without increasing the cache size. Our\napproach outperforms linear caching baselines across key benchmarks, including\nstreaming perplexity, question answering, book summarization, and passkey\nretrieval, where it retains better retrieval accuracy at 1M tokens after four\ndoublings of the cache size of 65K. Additionally, our method reduces prefill\nstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.\nThese innovations not only enhance the computational efficiency of LLMs but\nalso pave the way for their effective deployment in resource-constrained\nenvironments, enabling large-scale, real-time applications with significantly\nreduced latency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.17808v4",
    "published_date": "2024-06-24 03:59:17 UTC",
    "updated_date": "2025-03-31 03:28:44 UTC"
  },
  {
    "arxiv_id": "2407.07723v3",
    "title": "Lossless data compression by large models",
    "authors": [
      "Ziguang Li",
      "Chao Huang",
      "Xuliang Wang",
      "Haibo Hu",
      "Cole Wyeth",
      "Dongbo Bu",
      "Quan Yu",
      "Wen Gao",
      "Xingwu Liu",
      "Ming Li"
    ],
    "abstract": "Modern data compression methods are slowly reaching their limits after 80\nyears of research, millions of papers, and wide range of applications. Yet, the\nextravagant 6G communication speed requirement raises a major open question for\nrevolutionary new ideas of data compression. We have previously shown all\nunderstanding or learning are compression, under reasonable assumptions. Large\nlanguage models (LLMs) understand data better than ever before. Can they help\nus to compress data? The LLMs may be seen to approximate the uncomputable\nSolomonoff induction. Therefore, under this new uncomputable paradigm, we\npresent LMCompress. LMCompress shatters all previous lossless compression\nalgorithms, doubling the lossless compression ratios of JPEG-XL for images,\nFLAC for audios, and H.264 for videos, and quadrupling the compression ratio of\nbz2 for texts. The better a large model understands the data, the better\nLMCompress compresses.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Published by Nature Machine Intelligence at\n  https://www.nature.com/articles/s42256-025-01033-7",
    "pdf_url": "http://arxiv.org/pdf/2407.07723v3",
    "published_date": "2024-06-24 03:58:11 UTC",
    "updated_date": "2025-04-30 15:11:38 UTC"
  },
  {
    "arxiv_id": "2406.16301v1",
    "title": "UBiSS: A Unified Framework for Bimodal Semantic Summarization of Videos",
    "authors": [
      "Yuting Mei",
      "Linli Yao",
      "Qin Jin"
    ],
    "abstract": "With the surge in the amount of video data, video summarization techniques,\nincluding visual-modal(VM) and textual-modal(TM) summarization, are attracting\nmore and more attention. However, unimodal summarization inevitably loses the\nrich semantics of the video. In this paper, we focus on a more comprehensive\nvideo summarization task named Bimodal Semantic Summarization of Videos\n(BiSSV). Specifically, we first construct a large-scale dataset, BIDS, in\n(video, VM-Summary, TM-Summary) triplet format. Unlike traditional processing\nmethods, our construction procedure contains a VM-Summary extraction algorithm\naiming to preserve the most salient content within long videos. Based on BIDS,\nwe propose a Unified framework UBiSS for the BiSSV task, which models the\nsaliency information in the video and generates a TM-summary and VM-summary\nsimultaneously. We further optimize our model with a list-wise ranking-based\nobjective to improve its capacity to capture highlights. Lastly, we propose a\nmetric, $NDCG_{MS}$, to provide a joint evaluation of the bimodal summary.\nExperiments show that our unified framework achieves better performance than\nmulti-stage summarization pipelines. Code and data are available at\nhttps://github.com/MeiYutingg/UBiSS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM International Conference on Multimedia Retrieval\n  (ICMR'24)",
    "pdf_url": "http://arxiv.org/pdf/2406.16301v1",
    "published_date": "2024-06-24 03:55:25 UTC",
    "updated_date": "2024-06-24 03:55:25 UTC"
  },
  {
    "arxiv_id": "2406.16299v1",
    "title": "Compensate Quantization Errors: Make Weights Hierarchical to Compensate Each Other",
    "authors": [
      "Yifei Gao",
      "Jie Ou",
      "Lei Wang",
      "Yuting Xiao",
      "Zhiyuan Xiang",
      "Ruiting Dai",
      "Jun Cheng"
    ],
    "abstract": "Emergent Large Language Models (LLMs) use their extraordinary performance and\npowerful deduction capacity to discern from traditional language models.\nHowever, the expenses of computational resources and storage for these LLMs are\nstunning, quantization then arises as a trending conversation. To address\naccuracy decay caused by quantization, two streams of works in post-training\nquantization methods stand out. One uses other weights to compensate existing\nquantization error, while the other transfers the quantization difficulty to\nother parts in the model. Combining both merits, we introduce Learnable\nSingular value Increment (LSI) as an advanced solution. LSI uses Singular Value\nDecomposition to extract singular values of the weights and make them learnable\nto help weights compensate each other conditioned on activation. Incorporating\nLSI with existing techniques, we achieve state-of-the-art performance in\ndiverse quantization settings, no matter in weight-only, weight-activation or\nextremely low bit scenarios. By unleashing the potential of LSI, efficient\nfinetuning on quantized model is no longer a prohibitive problem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "F.2.3"
    ],
    "primary_category": "cs.CL",
    "comment": "Efficient quantization method",
    "pdf_url": "http://arxiv.org/pdf/2406.16299v1",
    "published_date": "2024-06-24 03:52:52 UTC",
    "updated_date": "2024-06-24 03:52:52 UTC"
  },
  {
    "arxiv_id": "2406.16295v1",
    "title": "Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Physical Dynamics Learning",
    "authors": [
      "Zinan Zheng",
      "Yang Liu",
      "Jia Li",
      "Jianhua Yao",
      "Yu Rong"
    ],
    "abstract": "Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive\nbiases into graph neural networks has improved their generalization ability and\ndata efficiency in unbounded physical dynamics modeling. However, in various\nscientific and engineering applications, the symmetries of dynamics are\nfrequently discrete due to the boundary conditions. Thus, existing GNNs either\noverlook necessary symmetry, resulting in suboptimal representation ability, or\nimpose excessive equivariance, which fails to generalize to unobserved\nsymmetric dynamics. In this work, we propose a general Discrete Equivariant\nGraph Neural Network (DEGNN) that guarantees equivariance to a given discrete\npoint group. Specifically, we show that such discrete equivariant message\npassing could be constructed by transforming geometric features into\npermutation-invariant embeddings. Through relaxing continuous equivariant\nconstraints, DEGNN can employ more geometric feature combinations to\napproximate unobserved physical object interaction functions. Two\nimplementation approaches of DEGNN are proposed based on ranking or pooling\npermutation-invariant functions. We apply DEGNN to various physical dynamics,\nranging from particle, molecular, crowd to vehicle dynamics. In twenty\nscenarios, DEGNN significantly outperforms existing state-of-the-art\napproaches. Moreover, we show that DEGNN is data efficient, learning with less\ndata, and can generalize across scenarios such as unobserved orientation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16295v1",
    "published_date": "2024-06-24 03:37:51 UTC",
    "updated_date": "2024-06-24 03:37:51 UTC"
  },
  {
    "arxiv_id": "2406.16294v1",
    "title": "LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",
    "authors": [
      "Zixia Jia",
      "Mengmeng Wang",
      "Baichen Tong",
      "Song-Chun Zhu",
      "Zilong Zheng"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have shown inspiring\nachievements in constructing autonomous agents that rely on language\ndescriptions as inputs. However, it remains unclear how well LLMs can function\nas few-shot or zero-shot embodied agents in dynamic interactive environments.\nTo address this gap, we introduce LangSuitE, a versatile and simulation-free\ntestbed featuring 6 representative embodied tasks in textual embodied worlds.\nCompared with previous LLM-based testbeds, LangSuitE (i) offers adaptability to\ndiverse environments without multiple simulation engines, (ii) evaluates\nagents' capacity to develop ``internalized world knowledge'' with embodied\nobservations, and (iii) allows easy customization of communication and action\nstrategies. To address the embodiment challenge, we devise a novel\nchain-of-thought (CoT) schema, EmMem, which summarizes embodied states w.r.t.\nhistory information. Comprehensive benchmark results illustrate challenges and\ninsights of embodied planning. LangSuitE represents a significant step toward\nbuilding embodied generalists in the context of language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16294v1",
    "published_date": "2024-06-24 03:36:29 UTC",
    "updated_date": "2024-06-24 03:36:29 UTC"
  },
  {
    "arxiv_id": "2406.16293v1",
    "title": "Combining Supervised Learning and Reinforcement Learning for Multi-Label Classification Tasks with Partial Labels",
    "authors": [
      "Zixia Jia",
      "Junpeng Li",
      "Shichuan Zhang",
      "Anji Liu",
      "Zilong Zheng"
    ],
    "abstract": "Traditional supervised learning heavily relies on human-annotated datasets,\nespecially in data-hungry neural approaches. However, various tasks, especially\nmulti-label tasks like document-level relation extraction, pose challenges in\nfully manual annotation due to the specific domain knowledge and large class\nsets. Therefore, we address the multi-label positive-unlabelled learning\n(MLPUL) problem, where only a subset of positive classes is annotated. We\npropose Mixture Learner for Partially Annotated Classification (MLPAC), an\nRL-based framework combining the exploration ability of reinforcement learning\nand the exploitation ability of supervised learning. Experimental results\nacross various tasks, including document-level relation extraction, multi-label\nimage classification, and binary PU learning, demonstrate the generalization\nand effectiveness of our framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16293v1",
    "published_date": "2024-06-24 03:36:19 UTC",
    "updated_date": "2024-06-24 03:36:19 UTC"
  },
  {
    "arxiv_id": "2406.16282v1",
    "title": "Reducing Fine-Tuning Memory Overhead by Approximate and Memory-Sharing Backpropagation",
    "authors": [
      "Yuchen Yang",
      "Yingdong Shi",
      "Cheems Wang",
      "Xiantong Zhen",
      "Yuxuan Shi",
      "Jun Xu"
    ],
    "abstract": "Fine-tuning pretrained large models to downstream tasks is an important\nproblem, which however suffers from huge memory overhead due to large-scale\nparameters. This work strives to reduce memory overhead in fine-tuning from\nperspectives of activation function and layer normalization. To this end, we\npropose the Approximate Backpropagation (Approx-BP) theory, which provides the\ntheoretical feasibility of decoupling the forward and backward passes. We apply\nour Approx-BP theory to backpropagation training and derive memory-efficient\nalternatives of GELU and SiLU activation functions, which use derivative\nfunctions of ReLUs in the backward pass while keeping their forward pass\nunchanged. In addition, we introduce a Memory-Sharing Backpropagation strategy,\nwhich enables the activation memory to be shared by two adjacent layers,\nthereby removing activation memory usage redundancy. Our method neither induces\nextra computation nor reduces training efficiency. We conduct extensive\nexperiments with pretrained vision and language models, and the results\ndemonstrate that our proposal can reduce up to $\\sim$$30\\%$ of the peak memory\nusage. Our code is released at https://github.com/yyyyychen/LowMemoryBP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, ICML 2024 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2406.16282v1",
    "published_date": "2024-06-24 03:09:15 UTC",
    "updated_date": "2024-06-24 03:09:15 UTC"
  },
  {
    "arxiv_id": "2406.16272v2",
    "title": "Repairing Catastrophic-Neglect in Text-to-Image Diffusion Models via Attention-Guided Feature Enhancement",
    "authors": [
      "Zhiyuan Chang",
      "Mingyang Li",
      "Junjie Wang",
      "Yi Liu",
      "Qing Wang",
      "Yang Liu"
    ],
    "abstract": "Text-to-Image Diffusion Models (T2I DMs) have garnered significant attention\nfor their ability to generate high-quality images from textual descriptions.\nHowever, these models often produce images that do not fully align with the\ninput prompts, resulting in semantic inconsistencies. The most prominent issue\namong these semantic inconsistencies is catastrophic-neglect, where the images\ngenerated by T2I DMs miss key objects mentioned in the prompt. We first conduct\nan empirical study on this issue, exploring the prevalence of\ncatastrophic-neglect, potential mitigation strategies with feature enhancement,\nand the insights gained. Guided by the empirical findings, we propose an\nautomated repair approach named Patcher to address catastrophic-neglect in T2I\nDMs. Specifically, Patcher first determines whether there are any neglected\nobjects in the prompt, and then applies attention-guided feature enhancement to\nthese neglected objects, resulting in a repaired prompt. Experimental results\non three versions of Stable Diffusion demonstrate that Patcher effectively\nrepairs the issue of catastrophic-neglect, achieving 10.1%-16.3% higher Correct\nRate in image generation compared to baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.16272v2",
    "published_date": "2024-06-24 02:38:30 UTC",
    "updated_date": "2024-09-21 04:02:07 UTC"
  },
  {
    "arxiv_id": "2407.10990v1",
    "title": "MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models",
    "authors": [
      "Mianxin Liu",
      "Jinru Ding",
      "Jie Xu",
      "Weiguo Hu",
      "Xiaoyang Li",
      "Lifeng Zhu",
      "Zhian Bai",
      "Xiaoming Shi",
      "Benyou Wang",
      "Haitao Song",
      "Pengfei Liu",
      "Xiaofan Zhang",
      "Shanshan Wang",
      "Kang Li",
      "Haofen Wang",
      "Tong Ruan",
      "Xuanjing Huang",
      "Xin Sun",
      "Shaoting Zhang"
    ],
    "abstract": "Ensuring the general efficacy and goodness for human beings from medical\nlarge language models (LLM) before real-world deployment is crucial. However, a\nwidely accepted and accessible evaluation process for medical LLM, especially\nin the Chinese context, remains to be established. In this work, we introduce\n\"MedBench\", a comprehensive, standardized, and reliable benchmarking system for\nChinese medical LLM. First, MedBench assembles the currently largest evaluation\ndataset (300,901 questions) to cover 43 clinical specialties and performs\nmulti-facet evaluation on medical LLM. Second, MedBench provides a standardized\nand fully automatic cloud-based evaluation infrastructure, with physical\nseparations for question and ground truth. Third, MedBench implements dynamic\nevaluation mechanisms to prevent shortcut learning and answer remembering.\nApplying MedBench to popular general and medical LLMs, we observe unbiased,\nreproducible evaluation results largely aligning with medical professionals'\nperspectives. This study establishes a significant foundation for preparing the\npractical applications of Chinese medical LLMs. MedBench is publicly accessible\nat https://medbench.opencompass.org.cn.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages.4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.10990v1",
    "published_date": "2024-06-24 02:25:48 UTC",
    "updated_date": "2024-06-24 02:25:48 UTC"
  },
  {
    "arxiv_id": "2407.00079v3",
    "title": "Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving",
    "authors": [
      "Ruoyu Qin",
      "Zheming Li",
      "Weiran He",
      "Mingxing Zhang",
      "Yongwei Wu",
      "Weimin Zheng",
      "Xinran Xu"
    ],
    "abstract": "Mooncake is the serving platform for Kimi, a leading LLM service provided by\nMoonshot AI. It features a KVCache-centric disaggregated architecture that\nseparates the prefill and decoding clusters. It also leverages the\nunderutilized CPU, DRAM, and SSD resources of the GPU cluster to implement a\ndisaggregated cache of KVCache. The core of Mooncake is its KVCache-centric\nscheduler, which balances maximizing overall effective throughput while meeting\nlatency-related Service Level Objectives (SLOs). Unlike traditional studies\nthat assume all requests will be processed, Mooncake faces challenges due to\nhighly overloaded scenarios. To mitigate these, we developed a prediction-based\nearly rejection policy. Experiments show that Mooncake excels in long-context\nscenarios. Compared to the baseline method, Mooncake can achieve up to a 525%\nincrease in throughput in certain simulated scenarios while adhering to SLOs.\nUnder real workloads, Mooncake's innovative architecture enables Kimi to handle\n75% more requests.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.DC",
    "comment": "23 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00079v3",
    "published_date": "2024-06-24 02:05:32 UTC",
    "updated_date": "2024-07-09 04:03:10 UTC"
  },
  {
    "arxiv_id": "2406.16264v3",
    "title": "One Thousand and One Pairs: A \"novel\" challenge for long-context language models",
    "authors": [
      "Marzena Karpinska",
      "Katherine Thai",
      "Kyle Lo",
      "Tanya Goyal",
      "Mohit Iyyer"
    ],
    "abstract": "Synthetic long-context LLM benchmarks (e.g., \"needle-in-the-haystack\") test\nonly surface-level retrieval capabilities, but how well can long-context LLMs\nretrieve, synthesize, and reason over information across book-length inputs? We\naddress this question by creating NoCha, a dataset of 1,001 minimally different\npairs of true and false claims about 67 recently-published English fictional\nbooks, written by human readers of those books. In contrast to existing\nlong-context benchmarks, our annotators confirm that the largest share of pairs\nin NoCha require global reasoning over the entire book to verify. Our\nexperiments show that while human readers easily perform this task, it is\nenormously challenging for all ten long-context LLMs that we evaluate: no\nopen-weight model performs above random chance (despite their strong\nperformance on synthetic benchmarks), while GPT-4o achieves the highest\naccuracy at 55.8%. Further analysis reveals that (1) on average, models perform\nmuch better on pairs that require only sentence-level retrieval vs. global\nreasoning; (2) model-generated explanations for their decisions are often\ninaccurate even for correctly-labeled claims; and (3) models perform\nsubstantially worse on speculative fiction books that contain extensive\nworld-building. The methodology proposed in NoCha allows for the evolution of\nthe benchmark dataset and the easy analysis of future models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024, camera ready",
    "pdf_url": "http://arxiv.org/pdf/2406.16264v3",
    "published_date": "2024-06-24 02:03:57 UTC",
    "updated_date": "2024-10-22 15:09:58 UTC"
  },
  {
    "arxiv_id": "2406.16260v1",
    "title": "Video-Infinity: Distributed Long Video Generation",
    "authors": [
      "Zhenxiong Tan",
      "Xingyi Yang",
      "Songhua Liu",
      "Xinchao Wang"
    ],
    "abstract": "Diffusion models have recently achieved remarkable results for video\ngeneration. Despite the encouraging performances, the generated videos are\ntypically constrained to a small number of frames, resulting in clips lasting\nmerely a few seconds. The primary challenges in producing longer videos include\nthe substantial memory requirements and the extended processing time required\non a single GPU. A straightforward solution would be to split the workload\nacross multiple GPUs, which, however, leads to two issues: (1) ensuring all\nGPUs communicate effectively to share timing and context information, and (2)\nmodifying existing video diffusion models, which are usually trained on short\nsequences, to create longer videos without additional training. To tackle\nthese, in this paper we introduce Video-Infinity, a distributed inference\npipeline that enables parallel processing across multiple GPUs for long-form\nvideo generation. Specifically, we propose two coherent mechanisms: Clip\nparallelism and Dual-scope attention. Clip parallelism optimizes the gathering\nand sharing of context information across GPUs which minimizes communication\noverhead, while Dual-scope attention modulates the temporal self-attention to\nbalance local and global contexts efficiently across the devices. Together, the\ntwo mechanisms join forces to distribute the workload and enable the fast\ngeneration of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our\nmethod generates videos up to 2,300 frames in approximately 5 minutes, enabling\nlong video generation at a speed 100 times faster than the prior methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16260v1",
    "published_date": "2024-06-24 01:56:12 UTC",
    "updated_date": "2024-06-24 01:56:12 UTC"
  },
  {
    "arxiv_id": "2406.16259v1",
    "title": "User Story Tutor (UST) to Support Agile Software Developers",
    "authors": [
      "Giseldo da Silva Neo",
      "José Antão Beltrão Moura",
      "Hyggo Oliveira de Almeida",
      "Alana Viana Borges da Silva Neo",
      "Olival de Gusmão Freitas Júnior"
    ],
    "abstract": "User Stories record what must be built in projects that use agile practices.\nUser Stories serve both to estimate effort, generally measured in Story Points,\nand to plan what should be done in a Sprint. Therefore, it is essential to\ntrain software engineers on how to create simple, easily readable, and\ncomprehensive User Stories. For that reason, we designed, implemented, applied,\nand evaluated a web application called User Story Tutor (UST). UST checks the\ndescription of a given User Story for readability, and if needed, recommends\nappropriate practices for improvement. UST also estimates a User Story effort\nin Story Points using Machine Learning techniques. As such UST may support the\ncontinuing education of agile development teams when writing and reviewing User\nStories. UST's ease of use was evaluated by 40 agile practitioners according to\nthe Technology Acceptance Model (TAM) and AttrakDiff. The TAM evaluation\naverages were good in almost all considered variables. Application of the\nAttrakDiff evaluation framework produced similar good results. Apparently, UST\ncan be used with good reliability. Applying UST to assist in the construction\nof User Stories is a viable technique that, at the very least, can be used by\nagile developments to complement and enhance current User Story creation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16259v1",
    "published_date": "2024-06-24 01:55:01 UTC",
    "updated_date": "2024-06-24 01:55:01 UTC"
  },
  {
    "arxiv_id": "2406.16258v2",
    "title": "MEReQ: Max-Ent Residual-Q Inverse RL for Sample-Efficient Alignment from Intervention",
    "authors": [
      "Yuxin Chen",
      "Chen Tang",
      "Chenran Li",
      "Ran Tian",
      "Wei Zhan",
      "Peter Stone",
      "Masayoshi Tomizuka"
    ],
    "abstract": "Aligning robot behavior with human preferences is crucial for deploying\nembodied AI agents in human-centered environments. A promising solution is\ninteractive imitation learning from human intervention, where a human expert\nobserves the policy's execution and provides interventions as feedback.\nHowever, existing methods often fail to utilize the prior policy efficiently to\nfacilitate learning, thus hindering sample efficiency. In this work, we\nintroduce MEReQ (Maximum-Entropy Residual-Q Inverse Reinforcement Learning),\ndesigned for sample-efficient alignment from human intervention. Instead of\ninferring the complete human behavior characteristics, MEReQ infers a residual\nreward function that captures the discrepancy between the human expert's and\nthe prior policy's underlying reward functions. It then employs Residual\nQ-Learning (RQL) to align the policy with human preferences using this residual\nreward function. Extensive evaluations on simulated and real-world tasks\ndemonstrate that MEReQ achieves sample-efficient policy alignment from human\nintervention.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16258v2",
    "published_date": "2024-06-24 01:51:09 UTC",
    "updated_date": "2024-10-28 19:17:41 UTC"
  },
  {
    "arxiv_id": "2406.16986v1",
    "title": "Machine Unlearning with Minimal Gradient Dependence for High Unlearning Ratios",
    "authors": [
      "Tao Huang",
      "Ziyang Chen",
      "Jiayang Meng",
      "Qingyu Huang",
      "Xu Yang",
      "Xun Yi",
      "Ibrahim Khalil"
    ],
    "abstract": "In the context of machine unlearning, the primary challenge lies in\neffectively removing traces of private data from trained models while\nmaintaining model performance and security against privacy attacks like\nmembership inference attacks. Traditional gradient-based unlearning methods\noften rely on extensive historical gradients, which becomes impractical with\nhigh unlearning ratios and may reduce the effectiveness of unlearning.\nAddressing these limitations, we introduce Mini-Unlearning, a novel approach\nthat capitalizes on a critical observation: unlearned parameters correlate with\nretrained parameters through contraction mapping. Our method, Mini-Unlearning,\nutilizes a minimal subset of historical gradients and leverages this\ncontraction mapping to facilitate scalable, efficient unlearning. This\nlightweight, scalable method significantly enhances model accuracy and\nstrengthens resistance to membership inference attacks. Our experiments\ndemonstrate that Mini-Unlearning not only works under higher unlearning ratios\nbut also outperforms existing techniques in both accuracy and security,\noffering a promising solution for applications requiring robust unlearning\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16986v1",
    "published_date": "2024-06-24 01:43:30 UTC",
    "updated_date": "2024-06-24 01:43:30 UTC"
  },
  {
    "arxiv_id": "2406.16255v2",
    "title": "Uncertainty-Aware Reward-Free Exploration with General Function Approximation",
    "authors": [
      "Junkai Zhang",
      "Weitong Zhang",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "abstract": "Mastering multiple tasks through exploration and learning in an environment\nposes a significant challenge in reinforcement learning (RL). Unsupervised RL\nhas been introduced to address this challenge by training policies with\nintrinsic rewards rather than extrinsic rewards. However, current intrinsic\nreward designs and unsupervised RL algorithms often overlook the heterogeneous\nnature of collected samples, thereby diminishing their sample efficiency. To\novercome this limitation, in this paper, we propose a reward-free RL algorithm\ncalled \\alg. The key idea behind our algorithm is an uncertainty-aware\nintrinsic reward for exploring the environment and an uncertainty-weighted\nlearning process to handle heterogeneous uncertainty in different samples.\nTheoretically, we show that in order to find an $\\epsilon$-optimal policy,\nGFA-RFE needs to collect $\\tilde{O} (H^2 \\log N_{\\mathcal F} (\\epsilon)\n\\mathrm{dim} (\\mathcal F) / \\epsilon^2 )$ number of episodes, where $\\mathcal\nF$ is the value function class with covering number $N_{\\mathcal F} (\\epsilon)$\nand generalized eluder dimension $\\mathrm{dim} (\\mathcal F)$. Such a result\noutperforms all existing reward-free RL algorithms. We further implement and\nevaluate GFA-RFE across various domains and tasks in the DeepMind Control\nSuite. Experiment results show that GFA-RFE outperforms or is comparable to the\nperformance of state-of-the-art unsupervised RL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 5 figures, 4 tables, accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16255v2",
    "published_date": "2024-06-24 01:37:18 UTC",
    "updated_date": "2024-06-30 03:55:48 UTC"
  },
  {
    "arxiv_id": "2406.16254v2",
    "title": "Confidence Regulation Neurons in Language Models",
    "authors": [
      "Alessandro Stolfo",
      "Ben Wu",
      "Wes Gurnee",
      "Yonatan Belinkov",
      "Xingyi Song",
      "Mrinmaya Sachan",
      "Neel Nanda"
    ],
    "abstract": "Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.16254v2",
    "published_date": "2024-06-24 01:31:03 UTC",
    "updated_date": "2024-11-08 12:54:16 UTC"
  },
  {
    "arxiv_id": "2406.16252v2",
    "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
    "authors": [
      "Ajan Subramanian",
      "Zhongqi Yang",
      "Iman Azimi",
      "Amir M. Rahmani"
    ],
    "abstract": "Health monitoring systems have revolutionized modern healthcare by enabling\nthe continuous capture of physiological and behavioral data, essential for\npreventive measures and early health intervention. While integrating this data\nwith Large Language Models (LLMs) has shown promise in delivering interactive\nhealth advice, traditional methods like Retrieval-Augmented Generation (RAG)\nand fine-tuning often fail to fully utilize the complex, multi-dimensional, and\ntemporally relevant data from wearable devices. These conventional approaches\ntypically provide limited actionable and personalized health insights due to\ntheir inadequate capacity to dynamically integrate and interpret diverse health\ndata streams. In response, this paper introduces a graph-augmented LLM\nframework designed to significantly enhance the personalization and clarity of\nhealth insights. Utilizing a hierarchical graph structure, the framework\ncaptures inter and intra-patient relationships, enriching LLM prompts with\ndynamic feature importance scores derived from a Random Forest Model. The\neffectiveness of this approach is demonstrated through a sleep analysis case\nstudy involving 20 college students during the COVID-19 lockdown, highlighting\nthe potential of our model to generate actionable and personalized health\ninsights efficiently. We leverage another LLM to evaluate the insights for\nrelevance, comprehensiveness, actionability, and personalization, addressing\nthe critical need for models that process and interpret complex health data\neffectively. Our findings show that augmenting prompts with our framework\nyields significant improvements in all 4 criteria. Through our framework, we\ncan elicit well-crafted, more thoughtful responses tailored to a specific\npatient.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16252v2",
    "published_date": "2024-06-24 01:22:54 UTC",
    "updated_date": "2024-06-25 03:17:40 UTC"
  }
]