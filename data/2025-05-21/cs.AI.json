{
  "date": "2025-05-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-21 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、强化学习应用、LLM 推理与安全、多模态处理和医学图像等领域，重点包括神经启发跨域适应框架、LLM 代理记忆管理，以及扩散模型的理论分析；令人印象深刻的文章有 SynEVO 和 RL Tango，它们展示了 AI 在高效推理和知识转移上的创新，而著名学者如 Christopher Potts 的因果干预研究也值得关注。\n\n### 重点论文讨论\n我将优先讨论重要、创新性和话题度高的论文，包括 LLM 推理优化、强化学习和多模态处理领域，其余论文快速掠过，只列出标题和核心要点。\n\n**SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation**（中文标题：SynEVO：一种神经启发的时空演化框架用于跨域适应）  \n这篇论文提出了一种受神经科学启发的框架 SynEVO，用于提升时空系统模型的泛化能力，通过模仿人类课程学习和模型演化机制，在跨域场景下提升泛化能力最多 42%，为 NeuroAI 知识转移提供新范式。\n\n**Bidirectional Variational Autoencoders**（中文标题：双向变分自编码器）  \n作者 Bart Kosko 等提出 BVAE 架构，使用单网络同时编码和解码图像，参数减少近 50%，在 MNIST 和 CIFAR-10 等数据集上略优于传统 VAE，在图像重建和生成任务中表现出色。\n\n**How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior**（中文标题：内存管理对 LLM 代理的影响：基于经验跟踪行为的实证研究）  \n这篇研究分析了 LLM 代理的内存操作（如添加和删除经验），发现经验跟踪属性会导致错误传播和不相关经验重放，通过选择性策略可提升性能 10%，为设计鲁棒 LLM 代理提供指导。\n\n**RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning**（中文标题：RL Tango：通过强化学习同时优化生成器和验证器以提升语言推理）  \n论文引入 RL Tango 框架，同时训练 LLM 生成器和验证器，使用生成式验证器减少幻觉，提升数学推理准确率（如 GSM8k 上提升 11.2%），并在多基准上表现出色。\n\n**Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions**（中文标题：因果干预揭示英语填充-间隙结构共享）  \n作者 Christopher Potts 等使用因果可解释方法分析 LLM 在英语句法上的结构共享，发现 LLM 能捕捉填充-间隙依赖，但频率和上下文影响结果，为语言理论提供新洞见。\n\n**Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets**（中文标题：跨多国数据集的胸部 X 光诊断模型基准测试）  \n这篇由 Olivier Gevaert 等合作的研究比较了视觉语言模型在胸部 X 光诊断中的性能，MAVL 模型在公共和私有数据集上表现最佳（AUROC 达 0.95），强调了结构化监督在放射学 AI 中的价值。\n\n**Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers**（中文标题：神经坍缩在深度正则化 ResNet 和 Transformer 中是全局最优的）  \n论文证明神经坍缩在深度正则化模型中是全局最优，ResNet 和 Transformer 在高深度下趋向坍缩状态，提升了模型泛化，提供了理论基础。\n\n**Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging**（中文标题：通过操作符合并探索扩散轨迹蒸馏的理论洞见）  \n研究重新解释扩散模型蒸馏为操作符合并问题，提出动态编程算法优化信号保真，揭示了离散化和优化时间对生成质量的影响。\n\n**Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations**（中文标题：稀疏自编码器的可解释性幻觉：评估概念表示的鲁棒性）  \n论文发现稀疏自编码器在 LLM 中概念表示易受扰动影响，揭示了模型鲁棒性不足，可能导致错误解释。\n\n**PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?**（中文标题：PhyX：你的模型有物理推理的“智慧”吗？）  \n作者 Himabindu Lakkaraju 等构建 PhyX 基准测试物理推理能力，现有模型在热力学等任务上表现不佳（准确率低于 46%），暴露了模型对真实物理理解的局限。\n\n### 其他论文快速掠过\n以下论文主题多样，但非核心焦点，我仅列出标题和主要贡献：\n\n- **Merge to Mix: Mixing Datasets via Model Merging**（中文标题：Merge to Mix：通过模型合并混合数据集）  \n  提出模型合并方法加速数据集混合，提升大语言模型微调效率。\n\n- **Mesh-free sparse identification of nonlinear dynamics**（中文标题：无网格稀疏识别非线性动力学）  \n  开发无网格 SINDy 算法，从非均匀数据中识别 PDE 方程，鲁棒性强。\n\n- **Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals**（中文标题：来源信号：AI 生成媒体中视觉和盲人导航指标的实践与挑战）  \n  探讨 AI 媒体来源指标的用户实践，强调无障碍设计。\n\n- **Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models**（中文标题：并非所有模型适合专家卸载：混合专家模型的局部路由一致性）  \n  分析混合专家模型的路由一致性，指导内存高效部署。\n\n- **SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution**（中文标题：SPhyR：材料分布的空间-物理推理基准）  \n  构建拓扑优化基准测试 LLM 的空间推理能力。\n\n- **Causal LLM Routing: End-to-End Regret Minimization from Observational Data**（中文标题：因果 LLM 路由：基于观测数据的端到端遗憾最小化）  \n  提出因果路由框架优化 LLM 查询，提升准确性和成本平衡。\n\n- **Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces**（中文标题：等变 Eikonal 神经网络：无网格、可扩展的均匀空间传播时间预测）  \n  开发等变神经网络预测地震传播时间，提高泛化性。\n\n- **Children's Mental Models of AI Reasoning: Implications for AI Literacy Education**（中文标题：儿童对 AI 推理的心理模型：对 AI 素养教育的启示）  \n  研究儿童 AI 推理模型，促进教育设计。\n\n- **NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning**（中文标题：NOVER：通过无验证器强化学习激励语言模型训练）  \n  引入无验证器 RL 框架，提升模型推理。\n\n其他论文如涉及特定领域（如医学图像或特定算法改进）的，我仅简要提及核心术语和贡献，以控制篇幅。例如，**VideoGameQA-Bench**（中文标题：VideoGameQA-Bench：评估视觉语言模型在游戏质量保证中的基准）构建了游戏 QA 基准；**PhyX**（见上）测试物理推理；其余如 **LAGO**（语言相似性图优化）等则快速掠过不深究。\n\n总之，今天的论文突显了 AI 模型在推理、安全和跨域适应上的进展，相关研究为未来应用提供了坚实基础，但也暴露了模型鲁棒性和泛化性的挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2505.16080v1",
      "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayue Liu",
        "Zhongchao Yi",
        "Zhengyang Zhou",
        "Qihe Huang",
        "Kuo Yang",
        "Xu Wang",
        "Yang Wang"
      ],
      "abstract": "Discovering regularities from spatiotemporal systems can benefit various\nscientific and social planning. Current spatiotemporal learners usually train\nan independent model from a specific source data that leads to limited\ntransferability among sources, where even correlated tasks requires new design\nand training. The key towards increasing cross-domain knowledge is to enable\ncollective intelligence and model evolution. In this paper, inspired by\nneuroscience theories, we theoretically derive the increased information\nboundary via learning cross-domain collective intelligence and propose a\nSynaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the\nmodel independence and enables cross-domain knowledge to be shared and\naggregated. Specifically, we first re-order the sample groups to imitate the\nhuman curriculum learning, and devise two complementary learners, elastic\ncommon container and task-independent extractor to allow model growth and\ntask-wise commonality and personality disentanglement. Then an adaptive dynamic\ncoupler with a new difference metric determines whether the new sample group\nshould be incorporated into common container to achieve model evolution under\nvarious domains. Experiments show that SynEVO improves the generalization\ncapacity by at most 42% under cross-domain scenarios and SynEVO provides a\nparadigm of NeuroAI for knowledge transfer and adaptation.",
      "tldr_zh": "本论文提出 SynEVO，一种受神经科学启发的时空演化框架，旨在解决现有时空学习模型在跨域适应中的转移性问题，通过促进集体智能和模型演化来共享跨域知识。具体而言，SynEVO 通过重新排序样本组模仿人类课程学习，设计弹性公共容器和任务无关提取器来实现模型增长及任务共性与个性的分离，并使用自适应动态耦合器根据新差异度量决定知识整合。实验结果显示，SynEVO 在跨域场景下提高了最多 42% 的泛化能力，并为 NeuroAI 的知识转移和适应提供了一个新范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16080v1",
      "published_date": "2025-05-21 23:45:51 UTC",
      "updated_date": "2025-05-21 23:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:31:09.849300"
    },
    {
      "arxiv_id": "2505.16074v1",
      "title": "Bidirectional Variational Autoencoders",
      "title_zh": "双向变分自动编码器",
      "authors": [
        "Bart Kosko",
        "Olaoluwa Adigun"
      ],
      "abstract": "We present the new bidirectional variational autoencoder (BVAE) network\narchitecture. The BVAE uses a single neural network both to encode and decode\ninstead of an encoder-decoder network pair. The network encodes in the forward\ndirection and decodes in the backward direction through the same synaptic web.\nSimulations compared BVAEs and ordinary VAEs on the four image tasks of image\nreconstruction, classification, interpolation, and generation. The image\ndatasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and\nCelebA-64 face images. The bidirectional structure of BVAEs cut the parameter\ncount by almost 50% and still slightly outperformed the unidirectional VAEs.",
      "tldr_zh": "本文提出了一种新的网络架构Bidirectional Variational Autoencoders (BVAE)，它使用单个神经网络同时进行编码（正向）和解码（反向），而非传统的编码器-解码器对，从而将参数数量减少近50%。在图像重建、分类、插值和生成任务上，BVAE使用MNIST、Fashion-MNIST、CIFAR-10和CelebA-64数据集进行测试，并略微优于传统的VAEs。总体而言，这一设计提升了模型效率，同时保持了良好的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16074v1",
      "published_date": "2025-05-21 23:19:43 UTC",
      "updated_date": "2025-05-21 23:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:31:20.819239"
    },
    {
      "arxiv_id": "2505.16067v1",
      "title": "How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Zidi Xiong",
        "Yuping Lin",
        "Wenya Xie",
        "Pengfei He",
        "Jiliang Tang",
        "Himabindu Lakkaraju",
        "Zhen Xiang"
      ],
      "abstract": "Memory is a critical component in large language model (LLM)-based agents,\nenabling them to store and retrieve past executions to improve task performance\nover time. In this paper, we conduct an empirical study on how memory\nmanagement choices impact the LLM agents' behavior, especially their long-term\nperformance. Specifically, we focus on two fundamental memory operations that\nare widely used by many agent frameworks-addition, which incorporates new\nexperiences into the memory base, and deletion, which selectively removes past\nexperiences-to systematically study their impact on the agent behavior. Through\nour quantitative analysis, we find that LLM agents display an\nexperience-following property: high similarity between a task input and the\ninput in a retrieved memory record often results in highly similar agent\noutputs. Our analysis further reveals two significant challenges associated\nwith this property: error propagation, where inaccuracies in past experiences\ncompound and degrade future performance, and misaligned experience replay,\nwhere outdated or irrelevant experiences negatively influence current tasks.\nThrough controlled experiments, we show that combining selective addition and\ndeletion strategies can help mitigate these negative effects, yielding an\naverage absolute performance gain of 10% compared to naive memory growth.\nFurthermore, we highlight how memory management choices affect agents' behavior\nunder challenging conditions such as task distribution shifts and constrained\nmemory resources. Our findings offer insights into the behavioral dynamics of\nLLM agent memory systems and provide practical guidance for designing memory\ncomponents that support robust, long-term agent performance. We also release\nour code to facilitate further study.",
      "tldr_zh": "本研究通过实证分析探讨了内存管理对LLM agents的影响，焦点在于addition（添加新经验）和deletion（删除过去经验）操作如何影响代理的长期性能。研究发现，LLM agents表现出experience-following属性，即任务输入与记忆记录相似时，输出也高度相似，但这会导致error propagation（错误传播）和misaligned experience replay（不相关经验重放）等问题。实验结果显示，采用选择性addition和deletion策略可缓解这些挑战，平均提升代理性能10%，并为应对任务分布变化和内存资源限制提供实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16067v1",
      "published_date": "2025-05-21 22:35:01 UTC",
      "updated_date": "2025-05-21 22:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:31:33.498518"
    },
    {
      "arxiv_id": "2505.16066v1",
      "title": "Merge to Mix: Mixing Datasets via Model Merging",
      "title_zh": "Merge to Mix：通过模型合并混合数据集",
      "authors": [
        "Zhixu Silvia Tao",
        "Kasper Vinken",
        "Hao-Wei Yeh",
        "Avi Cooper",
        "Xavier Boix"
      ],
      "abstract": "Mixing datasets for fine-tuning large models (LMs) has become critical for\nmaximizing performance on downstream tasks. However, composing effective\ndataset mixtures typically relies on heuristics and trial-and-error, often\nrequiring multiple fine-tuning runs to achieve the desired outcome. We propose\na novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset\nmixtures through model merging. Model merging is a recent technique that\ncombines the abilities of multiple individually fine-tuned LMs into a single LM\nby using a few simple arithmetic operations. Our key insight is that merging\nmodels individually fine-tuned on each dataset in a mixture can effectively\nserve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix\nleverages this insight to accelerate selecting dataset mixtures without\nrequiring full fine-tuning on each candidate mixture. Our experiments\ndemonstrate that Merge to Mix surpasses state-of-the-art methods in dataset\nselection for fine-tuning LMs.",
      "tldr_zh": "该研究解决了混合数据集用于微调大型语言模型 (LMs) 的挑战，该过程通常依赖启发式和多次试验性微调。作者提出了一种新方法 Merge to Mix，通过模型合并 (model merging) 技术将多个在单个数据集上微调的 LMs 结合，从而模拟在整个混合数据集上微调的效果，避免了完整微调的开销。实验结果表明，Merge to Mix 在数据集选择任务上超过了现有最先进的方法，提高了效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16066v1",
      "published_date": "2025-05-21 22:34:13 UTC",
      "updated_date": "2025-05-21 22:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:31:45.867167"
    },
    {
      "arxiv_id": "2505.16058v1",
      "title": "Mesh-free sparse identification of nonlinear dynamics",
      "title_zh": "无网格稀疏识别非线性动力学",
      "authors": [
        "Mars Liyao Gao",
        "J. Nathan Kutz",
        "Bernat Font"
      ],
      "abstract": "Identifying the governing equations of a dynamical system is one of the most\nimportant tasks for scientific modeling. However, this procedure often requires\nhigh-quality spatio-temporal data uniformly sampled on structured grids. In\nthis paper, we propose mesh-free SINDy, a novel algorithm which leverages the\npower of neural network approximation as well as auto-differentiation to\nidentify governing equations from arbitrary sensor placements and non-uniform\ntemporal data sampling. We show that mesh-free SINDy is robust to high noise\nlevels and limited data while remaining computationally efficient. In our\nimplementation, the training procedure is straight-forward and nearly free of\nhyperparameter tuning, making mesh-free SINDy widely applicable to many\nscientific and engineering problems. In the experiments, we demonstrate its\neffectiveness on a series of PDEs including the Burgers' equation, the heat\nequation, the Korteweg-De Vries equation and the 2D advection-diffusion\nequation. We conduct detailed numerical experiments on all datasets, varying\nthe noise levels and number of samples, and we also compare our approach to\nprevious state-of-the-art methods. It is noteworthy that, even in high-noise\nand low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,\nachieving successful identification with up to 75% noise for the Burgers'\nequation using 5,000 samples and with as few as 100 samples and 1% noise. All\nof this is achieved within a training time of under one minute.",
      "tldr_zh": "本论文提出了一种名为 mesh-free SINDy 的新算法，用于从非均匀空间-时间数据中识别非线性动力系统的治理方程，该方法结合神经网络近似和自动微分，支持任意传感器放置。mesh-free SINDy 对高噪声水平和有限样本数据表现出色，且计算效率高，训练过程简单，几乎无需超参数调整。实验在多个偏微分方程（PDEs）如 Burgers' equation、heat equation 等上验证了其有效性，即使在高达75%噪声和5000样本的 Burgers' equation 场景，或仅100样本和1%噪声下，算法仍能成功识别方程，且训练时间不到一分钟，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 13 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16058v1",
      "published_date": "2025-05-21 22:18:37 UTC",
      "updated_date": "2025-05-21 22:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:31:58.645335"
    },
    {
      "arxiv_id": "2505.16057v1",
      "title": "Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals",
      "title_zh": "翻译失败",
      "authors": [
        "Ayae Ide",
        "Tory Park",
        "Jaron Mink",
        "Tanusree Sharma"
      ],
      "abstract": "AI-Generated (AIG) content has become increasingly widespread by recent\nadvances in generative models and the easy-to-use tools that have significantly\nlowered the technical barriers for producing highly realistic audio, images,\nand videos through simple natural language prompts. In response, platforms are\nadopting provable provenance with platforms recommending AIG to be\nself-disclosed and signaled to users. However, these indicators may be often\nmissed, especially when they rely solely on visual cues and make them\nineffective to users with different sensory abilities. To address the gap, we\nconducted semi-structured interviews (N=28) with 15 sighted and 13 BLV\nparticipants to examine their interaction with AIG content through\nself-disclosed AI indicators. Our findings reveal diverse mental models and\npractices, highlighting different strengths and weaknesses of content-based\n(e.g., title, description) and menu-aided (e.g., AI labels) indicators. While\nsighted participants leveraged visual and audio cues, BLV participants\nprimarily relied on audio and existing assistive tools, limiting their ability\nto identify AIG. Across both groups, they frequently overlooked menu-aided\nindicators deployed by platforms and rather interacted with content-based\nindicators such as title and comments. We uncovered usability challenges\nstemming from inconsistent indicator placement, unclear metadata, and cognitive\noverload. These issues were especially critical for BLV individuals due to the\ninsufficient accessibility of interface elements. We provide practical\nrecommendations and design implications for future AIG indicators across\nseveral dimensions.",
      "tldr_zh": "这篇论文探讨了视力正常者和BLV（Blind and Low Vision）个体在处理AI-Generated (AIG) 媒体时，如何导航来源指标的实践与挑战。研究通过半结构化访谈（N=28）考察了参与者的互动模式，发现视力正常者依赖视觉和音频提示，而BLV个体主要依赖音频和辅助工具，导致AIG内容识别能力有限。论文揭示了指标的弱点，如不一致放置、元数据不清楚和认知超载等问题，并提供了实用推荐和设计启示，以提升AIG指标的可访问性和有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16057v1",
      "published_date": "2025-05-21 22:16:59 UTC",
      "updated_date": "2025-05-21 22:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:32:10.197212"
    },
    {
      "arxiv_id": "2505.16056v1",
      "title": "Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jingcong Liang",
        "Siyuan Wang",
        "Miren Tian",
        "Yitong Li",
        "Duyu Tang",
        "Zhongyu Wei"
      ],
      "abstract": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\n(LLMs) with sparsely activated experts during inference. To effectively deploy\nlarge MoE models on memory-constrained devices, many systems introduce *expert\noffloading* that caches a subset of experts in fast memory, leaving others on\nslow memory to run on CPU or load on demand. While some research has exploited\nthe locality of expert activations, where consecutive tokens activate similar\nexperts, the degree of this **local routing consistency** varies across models\nand remains understudied. In this paper, we propose two metrics to measure\nlocal routing consistency of MoE models: (1) **Segment Routing Best Performance\n(SRP)**, which evaluates how well a fixed group of experts can cover the needs\nof a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which\nmeasures the optimal segment-level cache hit rate under a given cache size\nlimit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found\nthat models that apply MoE on every layer and do not use shared experts exhibit\nthe highest local routing consistency. We further showed that\ndomain-specialized experts contribute more to routing consistency than\nvocabulary-specialized ones, and that most models can balance between cache\neffectiveness and efficiency with cache sizes approximately 2x the active\nexperts. These findings pave the way for memory-efficient MoE design and\ndeployment without compromising inference speed. We publish the code for\nreplicating experiments at https://github.com/ljcleo/moe-lrc .",
      "tldr_zh": "本研究探讨了Mixture-of-Experts (MoE)模型在内存受限设备上的专家卸载(expert offloading)问题，强调了本地路由一致性(local routing consistency)的差异对部署效率的影响。作者提出了两个指标：Segment Routing Best Performance (SRP)用于评估固定专家组对一段token的覆盖性能，以及Segment Cache Best Hit Rate (SCH)用于测量给定缓存大小下的最优段级缓存命中率。分析20个不同规模和架构的MoE模型后，发现每层应用MoE且不使用共享专家的模型表现出最高的路由一致性，且领域专用专家比词汇专用专家更显著地提升了这一特性。大多数模型在缓存大小约2倍活跃专家时，能实现缓存有效性和效率的平衡，从而为内存高效的MoE设计和部署提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16056v1",
      "published_date": "2025-05-21 22:13:09 UTC",
      "updated_date": "2025-05-21 22:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:32:21.374447"
    },
    {
      "arxiv_id": "2505.16048v1",
      "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution",
      "title_zh": "SPhyR: 材料分布的空间-物理推理基准",
      "authors": [
        "Philipp D. Siedler"
      ],
      "abstract": "We introduce a novel dataset designed to benchmark the physical and spatial\nreasoning capabilities of Large Language Models (LLM) based on topology\noptimization, a method for computing optimal material distributions within a\ndesign space under prescribed loads and supports. In this dataset, LLMs are\nprovided with conditions such as 2D boundary, applied forces and supports, and\nmust reason about the resulting optimal material distribution. The dataset\nincludes a variety of tasks, ranging from filling in masked regions within\npartial structures to predicting complete material distributions. Solving these\ntasks requires understanding the flow of forces and the required material\ndistribution under given constraints, without access to simulation tools or\nexplicit physical models, challenging models to reason about structural\nstability and spatial organization. Our dataset targets the evaluation of\nspatial and physical reasoning abilities in 2D settings, offering a\ncomplementary perspective to traditional language and logic benchmarks.",
      "tldr_zh": "我们引入了 SPhyR 数据集，用于基准测试 Large Language Models (LLMs) 的物理和空间推理能力，该数据集基于 topology optimization 方法，评估模型在给定2D边界、施加的力和支撑条件下推理最佳材料分布。数据集包含多种任务，如填充部分结构中的masked区域和预测完整材料分布，这些任务要求模型理解力的流动和结构稳定性，而无需访问模拟工具或显式物理模型。SPhyR 针对2D设置提供了一个补充传统语言和逻辑基准的新视角，强调了模型在空间组织和物理推理方面的挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16048v1",
      "published_date": "2025-05-21 22:00:20 UTC",
      "updated_date": "2025-05-21 22:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:32:33.033134"
    },
    {
      "arxiv_id": "2505.16037v1",
      "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data",
      "title_zh": "因果 LLM 路由：基于观察数据的端到端遗憾最小化",
      "authors": [
        "Asterios Tsiourvas",
        "Wei Sun",
        "Georgia Perakis"
      ],
      "abstract": "LLM routing aims to select the most appropriate model for each query,\nbalancing competing performance metrics such as accuracy and cost across a pool\nof language models. Prior approaches typically adopt a decoupled strategy,\nwhere the metrics are first predicted and the model is then selected based on\nthese estimates. This setup is prone to compounding errors and often relies on\nfull-feedback data, where each query is evaluated by all candidate models,\nwhich is costly to obtain and maintain in practice. In contrast, we learn from\nobservational data, which records only the outcome of the model actually\ndeployed. We propose a causal end-to-end framework that learns routing policies\nby minimizing decision-making regret from observational data. To enable\nefficient optimization, we introduce two theoretically grounded surrogate\nobjectives: a classification-based upper bound, and a softmax-weighted regret\napproximation shown to recover the optimal policy at convergence. We further\nextend our framework to handle heterogeneous cost preferences via an\ninterval-conditioned architecture. Experiments on public benchmarks show that\nour method outperforms existing baselines, achieving state-of-the-art\nperformance across different embedding models.",
      "tldr_zh": "本文提出一种因果端到端框架，用于从观察数据中学习LLM routing策略，通过最小化决策遗憾(regret minimization)来平衡模型准确性和成本指标。该框架引入两个理论支持的代理目标：基于分类的上界和softmax加权遗憾近似，以实现高效优化，并扩展至处理异构成本偏好(interval-conditioned architecture)。实验在公共基准上显示，该方法超越现有基线，在不同嵌入模型上达到最先进性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16037v1",
      "published_date": "2025-05-21 21:34:18 UTC",
      "updated_date": "2025-05-21 21:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:32:45.145454"
    },
    {
      "arxiv_id": "2505.16035v1",
      "title": "Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro García-Castellanos",
        "David R. Wessels",
        "Nicky J. van den Berg",
        "Remco Duits",
        "Daniël M. Pelt",
        "Erik J. Bekkers"
      ],
      "abstract": "We introduce Equivariant Neural Eikonal Solvers, a novel framework that\nintegrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our\napproach employs a single neural field where a unified shared backbone is\nconditioned on signal-specific latent variables - represented as point clouds\nin a Lie group - to model diverse Eikonal solutions. The ENF integration\nensures equivariant mapping from these latent representations to the solution\nfield, delivering three key benefits: enhanced representation efficiency\nthrough weight-sharing, robust geometric grounding, and solution steerability.\nThis steerability allows transformations applied to the latent point cloud to\ninduce predictable, geometrically meaningful modifications in the resulting\nEikonal solution. By coupling these steerable representations with\nPhysics-Informed Neural Networks (PINNs), our framework accurately models\nEikonal travel-time solutions while generalizing to arbitrary Riemannian\nmanifolds with regular group actions. This includes homogeneous spaces such as\nEuclidean, position-orientation, spherical, and hyperbolic manifolds. We\nvalidate our approach through applications in seismic travel-time modeling of\n2D and 3D benchmark datasets. Experimental results demonstrate superior\nperformance, scalability, adaptability, and user controllability compared to\nexisting Neural Operator-based Eikonal solver methods.",
      "tldr_zh": "本研究引入了Equivariant Neural Eikonal Solvers框架，将Equivariant Neural Fields (ENFs)与Neural Eikonal Solvers整合，使用单一神经场和Lie群中的点云作为潜在变量来建模多样化的Eikonal解决方案。该框架通过等变映射实现权重共享的表示效率、鲁棒的几何基础以及解决方案的可操控性，并结合Physics-Informed Neural Networks (PINNs)准确预测Riemannian流形上的旅行时间，包括Euclidean、spherical和hyperbolic等齐次空间。实验在2D和3D地震旅行时间基准数据集上验证了该方法的优越性能、可伸缩性、适应性和用户可控性，超越了现有的Neural Operator-based Eikonal求解器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16035v1",
      "published_date": "2025-05-21 21:29:18 UTC",
      "updated_date": "2025-05-21 21:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:32:59.879718"
    },
    {
      "arxiv_id": "2505.16031v1",
      "title": "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education",
      "title_zh": "翻译失败",
      "authors": [
        "Aayushi Dangol",
        "Robert Wolfe",
        "Runhua Zhao",
        "JaeWon Kim",
        "Trushaa Ramanan",
        "Katie Davis",
        "Julie A. Kientz"
      ],
      "abstract": "As artificial intelligence (AI) advances in reasoning capabilities, most\nrecently with the emergence of Large Reasoning Models (LRMs), understanding how\nchildren conceptualize AI's reasoning processes becomes critical for fostering\nAI literacy. While one of the \"Five Big Ideas\" in AI education highlights\nreasoning algorithms as central to AI decision-making, less is known about\nchildren's mental models in this area. Through a two-phase approach, consisting\nof a co-design session with 8 children followed by a field study with 106\nchildren (grades 3-8), we identified three models of AI reasoning: Deductive,\nInductive, and Inherent. Our findings reveal that younger children (grades 3-5)\noften attribute AI's reasoning to inherent intelligence, while older children\n(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions\nthat surfaced in children's understanding of AI reasoning and conclude with\nimplications for scaffolding AI curricula and designing explainable AI tools.",
      "tldr_zh": "本研究探讨了儿童对人工智能（AI）推理过程的心理模型，特别是Large Reasoning Models (LRMs)，以提升AI素养教育。通过两阶段方法，包括与8名儿童的共同设计会议和对106名3-8年级儿童的实地研究，研究者识别出三种AI推理模型：Deductive（演绎）、Inductive（归纳）和Inherent（固有）。结果显示，年轻儿童（3-5年级）往往将AI的推理归因于固有智能，而年长儿童（6-8年级）更倾向于视AI为模式识别器。研究还突出了儿童理解AI推理中的三个张力，并为设计AI课程和可解释AI工具提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16031v1",
      "published_date": "2025-05-21 21:20:12 UTC",
      "updated_date": "2025-05-21 21:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:33:15.894011"
    },
    {
      "arxiv_id": "2505.16027v1",
      "title": "Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Qinmei Xu",
        "Yiheng Li",
        "Xianghao Zhan",
        "Ahmet Gorkem Er",
        "Brittany Dashevsky",
        "Chuanjun Xu",
        "Mohammed Alawad",
        "Mengya Yang",
        "Liu Ya",
        "Changsheng Zhou",
        "Xiao Li",
        "Haruka Itakura",
        "Olivier Gevaert"
      ],
      "abstract": "Foundation models leveraging vision-language pretraining have shown promise\nin chest X-ray (CXR) interpretation, yet their real-world performance across\ndiverse populations and diagnostic tasks remains insufficiently evaluated. This\nstudy benchmarks the diagnostic performance and generalizability of foundation\nmodels versus traditional convolutional neural networks (CNNs) on multinational\nCXR datasets. We evaluated eight CXR diagnostic models - five vision-language\nfoundation models and three CNN-based architectures - across 37 standardized\nclassification tasks using six public datasets from the USA, Spain, India, and\nVietnam, and three private datasets from hospitals in China. Performance was\nassessed using AUROC, AUPRC, and other metrics across both shared and\ndataset-specific tasks. Foundation models outperformed CNNs in both accuracy\nand task coverage. MAVL, a model incorporating knowledge-enhanced prompts and\nstructured supervision, achieved the highest performance on public (mean AUROC:\n0.82; AUPRC: 0.32) and private (mean AUROC: 0.95; AUPRC: 0.89) datasets,\nranking first in 14 of 37 public and 3 of 4 private tasks. All models showed\nreduced performance on pediatric cases, with average AUROC dropping from 0.88\n+/- 0.18 in adults to 0.57 +/- 0.29 in children (p = 0.0202). These findings\nhighlight the value of structured supervision and prompt design in radiologic\nAI and suggest future directions including geographic expansion and ensemble\nmodeling for clinical deployment. Code for all evaluated models is available at\nhttps://drive.google.com/drive/folders/1B99yMQm7bB4h1sVMIBja0RfUu8gLktCE",
      "tldr_zh": "本文通过基准测试评估了基于视觉语言预训练的 Foundation models 与传统 CNNs 在多国胸部 X 光 (CXR) 数据集上的诊断性能，共涉及八个模型（五个 Foundation models 和三个 CNN 架构）在 37 个标准化分类任务上的表现，使用 AUROC 和 AUPRC 等指标。结果显示，Foundation models 在准确性和任务覆盖率上优于 CNNs，其中 MAVL 模型凭借知识增强提示和结构化监督取得了最佳成绩，在公共数据集上均 AUROC 为 0.82 和 AUPRC 为 0.32，在私人数据集上分别为 0.95 和 0.89。所有模型在儿科病例上的表现显著下降，AUROC 从成人 0.88 +/- 0.18 降至 0.57 +/- 0.29（p=0.0202）。这项研究突出了结构化监督和提示设计在放射学 AI 中的价值，并建议未来方向包括地理扩展和集成建模。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.2"
      ],
      "primary_category": "eess.IV",
      "comment": "78 pages, 7 figures, 2 tabeles",
      "pdf_url": "http://arxiv.org/pdf/2505.16027v1",
      "published_date": "2025-05-21 21:16:50 UTC",
      "updated_date": "2025-05-21 21:16:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:33:27.619129"
    },
    {
      "arxiv_id": "2505.16024v1",
      "title": "Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Weiguo Gao",
        "Ming Li"
      ],
      "abstract": "Diffusion trajectory distillation methods aim to accelerate sampling in\ndiffusion models, which produce high-quality outputs but suffer from slow\nsampling speeds. These methods train a student model to approximate the\nmulti-step denoising process of a pretrained teacher model in a single step,\nenabling one-shot generation. However, theoretical insights into the trade-off\nbetween different distillation strategies and generative quality remain\nlimited, complicating their optimization and selection. In this work, we take a\nfirst step toward addressing this gap. Specifically, we reinterpret trajectory\ndistillation as an operator merging problem in the linear regime, where each\nstep of the teacher model is represented as a linear operator acting on noisy\ndata. These operators admit a clear geometric interpretation as projections and\nrescalings corresponding to the noise schedule. During merging, signal\nshrinkage occurs as a convex combination of operators, arising from both\ndiscretization and limited optimization time of the student model. We propose a\ndynamic programming algorithm to compute the optimal merging strategy that\nmaximally preserves signal fidelity. Additionally, we demonstrate the existence\nof a sharp phase transition in the optimal strategy, governed by data\ncovariance structures. Our findings enhance the theoretical understanding of\ndiffusion trajectory distillation and offer practical insights for improving\ndistillation strategies.",
      "tldr_zh": "本文探讨了Diffusion Trajectory Distillation方法，以加速扩散模型的采样过程，这些模型虽能生成高质量输出，但受限于慢速采样。研究将轨迹蒸馏重新解释为线性体制下的Operator Merging问题，将教师模型的每个步骤视为对噪声数据的线性操作符，并分析了信号收缩现象。作者提出一个Dynamic Programming算法来计算最优合并策略，以最大限度保留信号保真度，并证明了最优策略中存在由数据协方差结构控制的尖锐相变。这些理论洞见增强了对Diffusion Trajectory Distillation的理解，并为优化蒸馏策略提供实际指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16024v1",
      "published_date": "2025-05-21 21:13:02 UTC",
      "updated_date": "2025-05-21 21:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:33:38.111118"
    },
    {
      "arxiv_id": "2505.16022v1",
      "title": "NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Liu",
        "Siya Qi",
        "Xinyu Wang",
        "Chen Qian",
        "Yali Du",
        "Yulan He"
      ],
      "abstract": "Recent advances such as DeepSeek R1-Zero highlight the effectiveness of\nincentive training, a reinforcement learning paradigm that computes rewards\nsolely based on the final answer part of a language model's output, thereby\nencouraging the generation of intermediate reasoning steps. However, these\nmethods fundamentally rely on external verifiers, which limits their\napplicability to domains like mathematics and coding where such verifiers are\nreadily available. Although reward models can serve as verifiers, they require\nhigh-quality annotated data and are costly to train. In this work, we propose\nNOVER, NO-VERifier Reinforcement Learning, a general reinforcement learning\nframework that requires only standard supervised fine-tuning data with no need\nfor an external verifier. NOVER enables incentive training across a wide range\nof text-to-text tasks and outperforms the model of the same size distilled from\nlarge reasoning models such as DeepSeek R1 671B by 7.7 percent. Moreover, the\nflexibility of NOVER enables new possibilities for optimizing large language\nmodels, such as inverse incentive training.",
      "tldr_zh": "该研究提出 NOVER，一种无需外部验证器的强化学习框架，用于语言模型的 incentive training，通过仅使用标准监督微调数据来鼓励生成中间推理步骤，从而适用于广泛的文本到文本任务。相比依赖验证器的传统方法，NOVER 避免了高成本的奖励模型训练，并在实验中比从 DeepSeek R1 671B 等大型推理模型蒸馏的同尺寸模型性能提升 7.7%。此外，NOVER 的灵活性还开启了如 inverse incentive training 等新优化可能性，为语言模型训练提供更通用且高效的途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 5 tables, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16022v1",
      "published_date": "2025-05-21 21:12:35 UTC",
      "updated_date": "2025-05-21 21:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:33:48.984550"
    },
    {
      "arxiv_id": "2505.16008v1",
      "title": "LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Wenrui Yu",
        "Yiyi Chen",
        "Johannes Bjerva",
        "Sokol Kosta",
        "Qiongxiu Li"
      ],
      "abstract": "We propose LAGO - Language Similarity-Aware Graph Optimization - a novel\napproach for few-shot cross-lingual embedding inversion attacks, addressing\ncritical privacy vulnerabilities in multilingual NLP systems. Unlike prior work\nin embedding inversion attacks that treat languages independently, LAGO\nexplicitly models linguistic relationships through a graph-based constrained\ndistributed optimization framework. By integrating syntactic and lexical\nsimilarity as edge constraints, our method enables collaborative parameter\nlearning across related languages. Theoretically, we show this formulation\ngeneralizes prior approaches, such as ALGEN, which emerges as a special case\nwhen similarity constraints are relaxed. Our framework uniquely combines\nFrobenius-norm regularization with linear inequality or total variation\nconstraints, ensuring robust alignment of cross-lingual embedding spaces even\nwith extremely limited data (as few as 10 samples per language). Extensive\nexperiments across multiple languages and embedding models demonstrate that\nLAGO substantially improves the transferability of attacks with 10-20% increase\nin Rouge-L score over baselines. This work establishes language similarity as a\ncritical factor in inversion attack transferability, urging renewed focus on\nlanguage-aware privacy-preserving multilingual embeddings.",
      "tldr_zh": "本研究提出LAGO，一种基于语言相似性感知图优化的少样本跨语言嵌入逆转攻击方法，旨在解决多语言NLP系统中的隐私漏洞。LAGO通过图-based约束分布式优化框架显式建模语言关系，将语法和词汇相似性作为边约束，实现相关语言间的协作参数学习，并结合Frobenius-norm正则化与线性不等式或总变差约束，确保在极少数据（如每语言10个样本）下实现嵌入空间的鲁棒对齐。实验结果显示，LAGO显著提升了攻击的可转移性，比基线模型提高10-20%的Rouge-L分数，并强调语言相似性是逆转攻击转移性的关键因素，呼吁开发语言感知的隐私保护多语言嵌入。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16008v1",
      "published_date": "2025-05-21 20:48:24 UTC",
      "updated_date": "2025-05-21 20:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:33:59.980979"
    },
    {
      "arxiv_id": "2505.16004v1",
      "title": "Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Aaron J. Li",
        "Suraj Srinivas",
        "Usha Bhalla",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Sparse autoencoders (SAEs) are commonly used to interpret the internal\nactivations of large language models (LLMs) by mapping them to\nhuman-interpretable concept representations. While existing evaluations of SAEs\nfocus on metrics such as the reconstruction-sparsity tradeoff, human\n(auto-)interpretability, and feature disentanglement, they overlook a critical\naspect: the robustness of concept representations to input perturbations. We\nargue that robustness must be a fundamental consideration for concept\nrepresentations, reflecting the fidelity of concept labeling. To this end, we\nformulate robustness quantification as input-space optimization problems and\ndevelop a comprehensive evaluation framework featuring realistic scenarios in\nwhich adversarial perturbations are crafted to manipulate SAE representations.\nEmpirically, we find that tiny adversarial input perturbations can effectively\nmanipulate concept-based interpretations in most scenarios without notably\naffecting the outputs of the base LLMs themselves. Overall, our results suggest\nthat SAE concept representations are fragile and may be ill-suited for\napplications in model monitoring and oversight.",
      "tldr_zh": "该研究评估了Sparse Autoencoders (SAEs) 在解释大型语言模型 (LLMs) 内部激活时概念表示的鲁棒性，指出现有评估忽略了对输入扰动的抵抗力，而这反映了概念标记的保真度。作者通过将鲁棒性量化为输入空间优化问题，并开发一个全面框架来模拟现实场景，包括创建对抗扰动来操纵SAE表示。实验结果显示，微小的对抗输入扰动即可有效改变基于概念的解释，而不显著影响基础LLMs的输出；总体而言，这表明SAE概念表示较为脆弱，可能不适合用于模型监控和监督应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16004v1",
      "published_date": "2025-05-21 20:42:05 UTC",
      "updated_date": "2025-05-21 20:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:34:11.484070"
    },
    {
      "arxiv_id": "2505.16003v1",
      "title": "SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Roland Daynauth",
        "Christopher Clarke",
        "Krisztian Flautner",
        "Lingjia Tang",
        "Jason Mars"
      ],
      "abstract": "The LLM-as-a-Judge paradigm offers a scalable, reference-free approach for\nevaluating language models. Although several calibration techniques have been\nproposed to better align these evaluators with human judgment, prior studies\nfocus primarily on narrow, well-structured benchmarks. As a result, it remains\nunclear whether such calibrations generalize to real-world, open-ended tasks.\n  In this work, we show that SOTA calibrated evaluators often fail in these\nsettings, exhibiting weak or even negative correlation with human judgments. To\naddress this, we propose SLMEval, a novel and efficient calibration method\nbased on entropy maximization over a small amount of human preference data. By\nestimating a latent distribution over model quality and reweighting evaluator\nscores accordingly, SLMEval achieves strong correlation with human evaluations\nacross two real-world production use cases and the public benchmark. For\nexample, on one such task, SLMEval achieves a Spearman correlation of 0.57 with\nhuman judgments, while G-Eval yields a negative correlation. In addition,\nSLMEval reduces evaluation costs by 5-30x compared to GPT-4-based calibrated\nevaluators such as G-eval.",
      "tldr_zh": "该研究针对LLM-as-a-Judge范式中评估器与人类判断不一致的问题，提出SLMEval，一种基于entropy maximization的校准方法，利用少量人类偏好数据估计模型质量的潜在分布并重新加权分数。SLMEval在两个真实世界生产用例和一个公共基准上表现出色，例如在特定任务中实现Spearman correlation 0.57，而现有方法如G-Eval则显示负相关。相比基于GPT-4的校准评估器，SLMEval将评估成本降低了5-30倍，提供了一种高效且人类对齐的语言模型评估方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.16003v1",
      "published_date": "2025-05-21 20:40:30 UTC",
      "updated_date": "2025-05-21 20:40:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:34:24.855250"
    },
    {
      "arxiv_id": "2505.16002v1",
      "title": "Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions",
      "title_zh": "翻译失败",
      "authors": [
        "Sasha Boguraev",
        "Christopher Potts",
        "Kyle Mahowald"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful sources of evidence for\nlinguists seeking to develop theories of syntax. In this paper, we argue that\ncausal interpretability methods, applied to LLMs, can greatly enhance the value\nof such evidence by helping us characterize the abstract mechanisms that LLMs\nlearn to use. Our empirical focus is a set of English filler-gap dependency\nconstructions (e.g., questions, relative clauses). Linguistic theories largely\nagree that these constructions share many properties. Using experiments based\nin Distributed Interchange Interventions, we show that LLMs converge on similar\nabstract analyses of these constructions. These analyses also reveal previously\noverlooked factors -- relating to frequency, filler type, and surrounding\ncontext -- that could motivate changes to standard linguistic theory. Overall,\nthese results suggest that mechanistic, internal analyses of LLMs can push\nlinguistic theory forward.",
      "tldr_zh": "本研究利用因果可解释性方法（如 Distributed Interchange Interventions）分析 Large Language Models (LLMs)，以揭示英语 filler-gap dependency constructions（如疑问句和相对从句）的共享结构。实验结果显示，LLMs 对这些结构形成了相似的抽象机制，并突显了频率、filler 类型和周围上下文等先前被忽略的因素，可能需要调整标准语言学理论。这些发现表明，对 LLMs 的内部机制分析可以推动语法理论的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 19 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.16002v1",
      "published_date": "2025-05-21 20:37:57 UTC",
      "updated_date": "2025-05-21 20:37:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:34:34.917187"
    },
    {
      "arxiv_id": "2505.16000v1",
      "title": "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model",
      "title_zh": "利用在线数据增强小型波斯语语言模型的医学知识",
      "authors": [
        "Mehrdad ghassabi",
        "Pedram Rostami",
        "Hamidreza Baradaran Kashani",
        "Amirhossein Poursina",
        "Zahra Kazemi",
        "Milad Tavakoli"
      ],
      "abstract": "The rapid advancement of language models has demonstrated the potential of\nartificial intelligence in the healthcare industry. However, small language\nmodels struggle with specialized domains in low-resource languages like\nPersian. While numerous medical-domain websites exist in Persian, no curated\ndataset or corpus has been available making ours the first of its kind. This\nstudy explores the enhancement of medical knowledge in a small language model\nby leveraging accessible online data, including a crawled corpus from medical\nmagazines and a dataset of real doctor-patient QA pairs. We fine-tuned a\nbaseline model using our curated data to improve its medical knowledge.\nBenchmark evaluations demonstrate that the fine-tuned model achieves improved\naccuracy in medical question answering and provides better responses compared\nto its baseline. This work highlights the potential of leveraging open-access\nonline data to enrich small language models in medical fields, providing a\nnovel solution for Persian medical AI applications suitable for\nresource-constrained environments.",
      "tldr_zh": "这篇论文探讨了如何利用在线数据提升小型Persian语言模型在医疗领域的知识，针对低资源语言的挑战。研究者首次创建了一个Persian医疗数据集，包括从医疗杂志爬取的语料库和真实医生-患者问答对，并对基线模型进行fine-tuned以增强其医疗知识。实验结果显示，fine-tuned模型在医疗问答benchmark上准确率和响应质量均有所提升。该工作突出了利用开放访问在线数据的潜力，为Persian医疗AI应用提供了适用于资源受限环境的创新解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.16000v1",
      "published_date": "2025-05-21 20:30:47 UTC",
      "updated_date": "2025-05-21 20:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:34:47.636684"
    },
    {
      "arxiv_id": "2505.15998v1",
      "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics",
      "title_zh": "使用基于好奇心的 AI 科学家探索 Flow-Lenia 宇宙：",
      "authors": [
        "Thomas Michel",
        "Marko Cvjetko",
        "Gautier Hamon",
        "Pierre-Yves Oudeyer",
        "Clément Moulin-Frier"
      ],
      "abstract": "We present a method for the automated discovery of system-level dynamics in\nFlow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and\nparameter localization$-$using a curiosity-driven AI scientist. This method\naims to uncover processes leading to self-organization of evolutionary and\necosystemic dynamics in CAs. We build on previous work which uses diversity\nsearch algorithms in Lenia to find self-organized individual patterns, and\nextend it to large environments that support distinct interacting patterns. We\nadapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive\nexploration of diverse Flow-Lenia environments using simulation-wide metrics,\nsuch as evolutionary activity, compression-based complexity, and multi-scale\nentropy. We test our method in two experiments, showcasing its ability to\nilluminate significantly more diverse dynamics compared to random search. We\nshow qualitative results illustrating how ecosystemic simulations enable\nself-organization of complex collective behaviors not captured by previous\nindividual pattern search and analysis. We complement automated discovery with\nan interactive exploration tool, creating an effective human-AI collaborative\nworkflow for scientific investigation. Though demonstrated specifically with\nFlow-Lenia, this methodology provides a framework potentially applicable to\nother parameterizable complex systems where understanding emergent collective\nproperties is of interest.",
      "tldr_zh": "本研究提出了一种基于好奇心驱动 AI 科学家的方法，用于自动发现 Flow-Lenia（一种具有质量守恒和参数本地化的连续 cellular automaton）中的系统级动态，从而揭示其进化性和生态系统动态的自组织过程。该方法扩展了之前的 Lenia 多样性搜索算法，采用 Intrinsically Motivated Goal Exploration Processes (IMGEPs) 结合模拟范围指标（如 evolutionary activity、compression-based complexity 和 multi-scale entropy），在大型环境中探索多样互动模式。实验结果显示，该方法比随机搜索发现更丰富的动态，并展示了生态系统模拟中复杂集体行为的自我组织，这些行为未被先前个体模式分析捕获。该框架还包括交互式探索工具，支持人类-AI 协作，并可扩展应用于其他参数化复杂系统以理解涌现集体属性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 10 figures, submitted to ALIFE 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.15998v1",
      "published_date": "2025-05-21 20:28:58 UTC",
      "updated_date": "2025-05-21 20:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:34:59.964893"
    },
    {
      "arxiv_id": "2505.15997v1",
      "title": "Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Mehran Zoravar",
        "Shadi Alijani",
        "Homayoun Najjaran"
      ],
      "abstract": "Exploring the trustworthiness of deep learning models is crucial, especially\nin critical domains such as medical imaging decision support systems. Conformal\nprediction has emerged as a rigorous means of providing deep learning models\nwith reliable uncertainty estimates and safety guarantees. However, conformal\nprediction results face challenges due to the backbone model's struggles in\ndomain-shifted scenarios, such as variations in different sources. To aim this\nchallenge, this paper proposes a novel framework termed Conformal Ensemble of\nVision Transformers (CE-ViTs) designed to enhance image classification\nperformance by prioritizing domain adaptation and model robustness, while\naccounting for uncertainty. The proposed method leverages an ensemble of vision\ntransformer models in the backbone, trained on diverse datasets including\nHAM10000, Dermofit, and Skin Cancer ISIC datasets. This ensemble learning\napproach, calibrated through the combined mentioned datasets, aims to enhance\ndomain adaptation through conformal learning. Experimental results underscore\nthat the framework achieves a high coverage rate of 90.38\\%, representing an\nimprovement of 9.95\\% compared to the HAM10000 model. This indicates a strong\nlikelihood that the prediction set includes the true label compared to singular\nmodels. Ensemble learning in CE-ViTs significantly improves conformal\nprediction performance, increasing the average prediction set size for\nchallenging misclassified samples from 1.86 to 3.075.",
      "tldr_zh": "本论文提出了一种名为 Conformal Ensemble of Vision Transformers (CE-ViTs) 的新框架，旨在提升皮肤病变分类任务的领域适应性和模型鲁棒性，同时通过 Conformal Prediction 提供可靠的不确定性估计。框架采用 Vision Transformers 的集成模型，训练于 HAM10000、Dermofit 和 Skin Cancer ISIC 等多样化数据集，以应对领域偏移问题并增强预测准确性。实验结果显示，CE-ViTs 实现了 90.38% 的覆盖率，比基准 HAM10000 模型提高了 9.95%，并将错误分类样本的平均预测集大小从 1.86 增加到 3.075，从而显著提升了模型的可信度和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures, conference (ccece 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.15997v1",
      "published_date": "2025-05-21 20:28:43 UTC",
      "updated_date": "2025-05-21 20:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:35:12.077037"
    },
    {
      "arxiv_id": "2505.15966v1",
      "title": "Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning",
      "title_zh": "Pixel Reasoner：利用好奇心驱动的强化学习激励像素空间推理",
      "authors": [
        "Alex Su",
        "Haozhe Wang",
        "Weimin Ren",
        "Fangzhen Lin",
        "Wenhu Chen"
      ],
      "abstract": "Chain-of-thought reasoning has significantly improved the performance of\nLarge Language Models (LLMs) across various domains. However, this reasoning\nprocess has been confined exclusively to textual space, limiting its\neffectiveness in visually intensive tasks. To address this limitation, we\nintroduce the concept of reasoning in the pixel-space. Within this novel\nframework, Vision-Language Models (VLMs) are equipped with a suite of visual\nreasoning operations, such as zoom-in and select-frame. These operations enable\nVLMs to directly inspect, interrogate, and infer from visual evidences, thereby\nenhancing reasoning fidelity for visual tasks. Cultivating such pixel-space\nreasoning capabilities in VLMs presents notable challenges, including the\nmodel's initially imbalanced competence and its reluctance to adopt the newly\nintroduced pixel-space operations. We address these challenges through a\ntwo-phase training approach. The first phase employs instruction tuning on\nsynthesized reasoning traces to familiarize the model with the novel visual\noperations. Following this, a reinforcement learning (RL) phase leverages a\ncuriosity-driven reward scheme to balance exploration between pixel-space\nreasoning and textual reasoning. With these visual operations, VLMs can\ninteract with complex visual inputs, such as information-rich images or videos\nto proactively gather necessary information. We demonstrate that this approach\nsignificantly improves VLM performance across diverse visual reasoning\nbenchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on\nTallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy\nachieved by any open-source model to date. These results highlight the\nimportance of pixel-space reasoning and the effectiveness of our framework.",
      "tldr_zh": "本论文引入像素空间推理（pixel-space reasoning），让视觉语言模型（VLMs）通过操作如 zoom-in 和 select-frame 来直接检查和推断视觉证据，从而提升视觉密集任务的推理能力。作者采用两阶段训练方法：首先通过指令调整在合成的推理痕迹上熟悉新视觉操作，其次使用好奇心驱动的强化学习（Reinforcement Learning）平衡像素空间和文本推理的探索。实验结果显示，该框架显著提高了 VLMs 的性能，例如他们的 7B 模型在 V* bench 上达到 84%、TallyQA-Complex 上 74% 以及 InfographicsVQA 上 84%，创下开源模型的最高准确率，并突显像素空间推理的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Haozhe Wang and Alex Su contributed equally and listed alphabetically",
      "pdf_url": "http://arxiv.org/pdf/2505.15966v1",
      "published_date": "2025-05-21 19:35:08 UTC",
      "updated_date": "2025-05-21 19:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:35:24.795320"
    },
    {
      "arxiv_id": "2505.15962v1",
      "title": "Pre-training Large Memory Language Models with Internal and External Knowledge",
      "title_zh": "利用内部和外部知识预训练大型记忆语言模型",
      "authors": [
        "Linxi Zhao",
        "Sofian Zalouk",
        "Christian K. Belardi",
        "Justin Lovelace",
        "Jin Peng Zhou",
        "Kilian Q. Weinberger",
        "Yoav Artzi",
        "Jennifer J. Sun"
      ],
      "abstract": "Neural language models are black-boxes -- both linguistic patterns and\nfactual knowledge are distributed across billions of opaque parameters. This\nentangled encoding makes it difficult to reliably inspect, verify, or update\nspecific facts. We propose a new class of language models, Large Memory\nLanguage Models (LMLM) with a pre-training recipe that stores factual knowledge\nin both internal weights and an external database. Our approach strategically\nmasks externally retrieved factual values from the training loss, thereby\nteaching the model to perform targeted lookups rather than relying on\nmemorization in model weights. Our experiments demonstrate that LMLMs achieve\ncompetitive performance compared to significantly larger, knowledge-dense LLMs\non standard benchmarks, while offering the advantages of explicit, editable,\nand verifiable knowledge bases. This work represents a fundamental shift in how\nlanguage models interact with and manage factual knowledge.",
      "tldr_zh": "这篇论文提出 Large Memory Language Models (LMLM)，一种新颖的语言模型，将事实知识存储在内部权重和外部数据库中，以解决传统神经语言模型中知识纠缠导致的检查、验证和更新难题。训练方法通过战略性地屏蔽外部检索的事实值，使模型学会进行针对性查找，而不是依赖参数记忆。实验结果表明，LMLM 在标准基准上与更大、更知识密集型的 LLMs 性能相当，同时提供显式、可编辑和可验证的知识库优势。这代表了语言模型与事实知识互动管理方式的根本性转变。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15962v1",
      "published_date": "2025-05-21 19:26:03 UTC",
      "updated_date": "2025-05-21 19:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:35:36.284385"
    },
    {
      "arxiv_id": "2505.15957v1",
      "title": "Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey",
      "title_zh": "迈向大型音频语言模型的整体评估：一个全面调查",
      "authors": [
        "Chih-Kai Yang",
        "Neo S. Ho",
        "Hung-yi Lee"
      ],
      "abstract": "With advancements in large audio-language models (LALMs), which enhance large\nlanguage models (LLMs) with auditory capabilities, these models are expected to\ndemonstrate universal proficiency across various auditory tasks. While numerous\nbenchmarks have emerged to assess LALMs' performance, they remain fragmented\nand lack a structured taxonomy. To bridge this gap, we conduct a comprehensive\nsurvey and propose a systematic taxonomy for LALM evaluations, categorizing\nthem into four dimensions based on their objectives: (1) General Auditory\nAwareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented\nAbility, and (4) Fairness, Safety, and Trustworthiness. We provide detailed\noverviews within each category and highlight challenges in this field, offering\ninsights into promising future directions. To the best of our knowledge, this\nis the first survey specifically focused on the evaluations of LALMs, providing\nclear guidelines for the community. We will release the collection of the\nsurveyed papers and actively maintain it to support ongoing advancements in the\nfield.",
      "tldr_zh": "这篇论文对大型音频语言模型 (LALMs) 进行了全面调查，旨在解决现有评估基准的碎片化和缺乏结构化分类问题。\n作者提出一个系统化的分类法，将 LALM 评估分为四个维度：(1) General Auditory Awareness and Processing、(2) Knowledge and Reasoning、(3) Dialogue-oriented Ability，以及(4) Fairness, Safety, and Trustworthiness。\n调查详细概述了每个类别的评估内容，并突出了领域面临的挑战以及未来研究方向。\n作为首个专注于 LALM 评估的综述，该论文将发布相关论文集合并持续维护，以指导社区的持续发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Project Website: https://github.com/b08202033/LALM-Evaluation-Survey",
      "pdf_url": "http://arxiv.org/pdf/2505.15957v1",
      "published_date": "2025-05-21 19:17:29 UTC",
      "updated_date": "2025-05-21 19:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:35:47.957076"
    },
    {
      "arxiv_id": "2505.15952v1",
      "title": "VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Reza Taesiri",
        "Abhijay Ghildyal",
        "Saman Zadtootaghaj",
        "Nabajeet Barman",
        "Cor-Paul Bezemer"
      ],
      "abstract": "With video games now generating the highest revenues in the entertainment\nindustry, optimizing game development workflows has become essential for the\nsector's sustained growth. Recent advancements in Vision-Language Models (VLMs)\noffer considerable potential to automate and enhance various aspects of game\ndevelopment, particularly Quality Assurance (QA), which remains one of the\nindustry's most labor-intensive processes with limited automation options. To\naccurately evaluate the performance of VLMs in video game QA tasks and\ndetermine their effectiveness in handling real-world scenarios, there is a\nclear need for standardized benchmarks, as existing benchmarks are insufficient\nto address the specific requirements of this domain. To bridge this gap, we\nintroduce VideoGameQA-Bench, a comprehensive benchmark that covers a wide array\nof game QA activities, including visual unit testing, visual regression\ntesting, needle-in-a-haystack tasks, glitch detection, and bug report\ngeneration for both images and videos of various games. Code and data are\navailable at: https://asgaardlab.github.io/videogameqa-bench/",
      "tldr_zh": "该研究针对视频游戏行业中 Quality Assurance (QA) 流程的劳动密集型问题，探讨了 Vision-Language Models (VLMs) 在自动化游戏开发中的潜力，但指出现有基准不足以评估其在真实场景中的表现。论文引入 VideoGameQA-Bench，这是一个全面的基准数据集，涵盖多种游戏 QA 任务，包括 visual unit testing、visual regression testing、needle-in-a-haystack tasks、glitch detection 和 bug report generation，适用于图像和视频。实验评估显示该基准能有效测试 VLMs 的性能，并提供公开代码和数据（https://asgaardlab.github.io/videogameqa-bench/），为优化游戏开发流程提供标准化工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website with code and data:\n  https://asgaardlab.github.io/videogameqa-bench/",
      "pdf_url": "http://arxiv.org/pdf/2505.15952v1",
      "published_date": "2025-05-21 19:08:38 UTC",
      "updated_date": "2025-05-21 19:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:36:00.366063"
    },
    {
      "arxiv_id": "2505.15946v1",
      "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wei",
        "Yanteng Zhang",
        "Xi Xiao",
        "Tianyang Wang",
        "Xiao Wang",
        "Vince D. Calhoun"
      ],
      "abstract": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.",
      "tldr_zh": "本研究提出 MoRE-Brain 框架，用于从 fMRI 信号中实现高保真、可解释的跨主体视觉重建，旨在提升脑-计算机接口的应用。框架采用分层 Mixture-of-Experts 架构，专家处理功能相关 voxel 组以模仿脑网络，并通过双阶段路由机制动态权重大师输出，将 fMRI 编码到冻结的 CLIP 空间，然后利用微调的扩散模型合成图像。主要贡献包括：引入基于脑网络原则的 Mixture-of-Experts 设计、实现高效的跨主体泛化（通过共享核心专家网络并仅适应主体特定路由器），以及提供机制洞见以揭示脑区域对图像语义和空间属性的影响。实验验证了 MoRE-Brain 的高重建保真度，并通过瓶颈分析证明了其对 fMRI 信号的有效利用，而非过度依赖生成先验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15946v1",
      "published_date": "2025-05-21 19:02:54 UTC",
      "updated_date": "2025-05-21 19:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:36:13.677483"
    },
    {
      "arxiv_id": "2505.15929v1",
      "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Shen",
        "Taiqiang Wu",
        "Qi Han",
        "Yunta Hsieh",
        "Jizhou Wang",
        "Yuyue Zhang",
        "Yuxin Cheng",
        "Zijian Hao",
        "Yuansheng Ni",
        "Xin Wang",
        "Zhongwei Wan",
        "Kai Zhang",
        "Wendong Xu",
        "Jing Xiong",
        "Ping Luo",
        "Wenhu Chen",
        "Chaofan Tao",
        "Zhuoqing Mao",
        "Ngai Wong"
      ],
      "abstract": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy\nrespectively-performance gaps exceeding 29\\% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation.",
      "tldr_zh": "该研究指出，现有的基准测试忽略了物理推理（physical reasoning）这一关键智能能力，即结合领域知识、符号推理和现实世界约束。为解决这一问题，研究者引入PhyX，这是第一个大规模基准，包含3K个精心策划的多模态问题，涵盖6种推理类型、25个子领域和6个核心物理领域（thermodynamics、electromagnetism、mechanics、modern physics、optics和wave & acoustics）。在评估中，先进模型如GPT-4o、Claude 3.7 Sonnet和GPT-4o mini的准确率仅为32.5%、42.2%和45.8%，比人类专家低29%以上，暴露了模型过度依赖记忆知识、数学公式和表面视觉模式匹配而非真正物理理解的局限性。研究提供了细粒度统计、案例研究和基于VLMEvalKit的评估协议，以确保可重复性和深入分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15929v1",
      "published_date": "2025-05-21 18:33:50 UTC",
      "updated_date": "2025-05-21 18:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:36:25.358876"
    },
    {
      "arxiv_id": "2505.15925v1",
      "title": "VERDI: VLM-Embedded Reasoning for Autonomous Driving",
      "title_zh": "VERDI：VLM 嵌入式推理用于自动驾驶",
      "authors": [
        "Bowen Feng",
        "Zhiting Mei",
        "Baiang Li",
        "Julian Ost",
        "Roger Girgis",
        "Anirudha Majumdar",
        "Felix Heide"
      ],
      "abstract": "While autonomous driving (AD) stacks struggle with decision making under\npartial observability and real-world complexity, human drivers are capable of\ncommonsense reasoning to make near-optimal decisions with limited information.\nRecent work has attempted to leverage finetuned Vision-Language Models (VLMs)\nfor trajectory planning at inference time to emulate human behavior. Despite\ntheir success in benchmark evaluations, these methods are often impractical to\ndeploy (a 70B parameter VLM inference at merely 8 tokens per second requires\nmore than 160G of memory), and their monolithic network structure prohibits\nsafety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for\nautonomous Driving (VERDI), a training-time framework that distills the\nreasoning process and commonsense knowledge of VLMs into the AD stack. VERDI\naugments modular differentiable end-to-end (e2e) AD models by aligning\nintermediate module outputs at the perception, prediction, and planning stages\nwith text features explaining the driving reasoning process produced by VLMs.\nBy encouraging alignment in latent space, \\textsc{VERDI} enables the modular AD\nstack to internalize structured reasoning, without incurring the inference-time\ncosts of large VLMs. We demonstrate the effectiveness of our method on the\nNuScenes dataset and find that VERDI outperforms existing e2e methods that do\nnot embed reasoning by 10% in $\\ell_{2}$ distance, while maintaining high\ninference speed.",
      "tldr_zh": "该研究针对自动驾驶（AD）系统在部分可观察性和复杂场景下的决策挑战，提出 VERDI 框架，该框架在训练时从视觉语言模型（VLMs）中提炼推理过程和常识知识，并嵌入到模块化端到端（e2e）AD 模型中。VERDI 通过对齐 AD 模型的感知、预测和规划阶段中间输出与 VLMs 生成的文本特征，实现结构化推理的内部化，从而避免了推理时依赖大型 VLMs 的高内存和低速问题。在 NuScenes 数据集上实验表明，VERDI 比不嵌入推理的 e2e 方法在 l2 距离上提升 10%，并保持高效的推理速度。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15925v1",
      "published_date": "2025-05-21 18:24:36 UTC",
      "updated_date": "2025-05-21 18:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:36:39.790028"
    },
    {
      "arxiv_id": "2505.15918v1",
      "title": "Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization",
      "title_zh": "从大语言模型中提取",
      "authors": [
        "Aliakbar Nafar",
        "Kristen Brent Venable",
        "Zijun Cui",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated potential as factual knowledge\nbases; however, their capability to generate probabilistic knowledge about\nreal-world events remains understudied. This paper investigates using\nprobabilistic knowledge inherent in LLMs to derive probability estimates for\nstatements concerning events and their interrelationships captured via a\nBayesian Network (BN). Using LLMs in this context allows for the\nparameterization of BNs, enabling probabilistic modeling within specific\ndomains. Experiments on eighty publicly available Bayesian Networks, from\nhealthcare to finance, demonstrate that querying LLMs about the conditional\nprobabilities of events provides meaningful results when compared to baselines,\nincluding random and uniform distributions, as well as approaches based on\nnext-token generation probabilities. We explore how these LLM-derived\ndistributions can serve as expert priors to refine distributions extracted from\nminimal data, significantly reducing systematic biases. Overall, this work\nintroduces a promising strategy for automatically constructing Bayesian\nNetworks by combining probabilistic knowledge extracted from LLMs with small\namounts of real-world data. Additionally, we evaluate several prompting\nstrategies for eliciting probabilistic knowledge from LLMs and establish the\nfirst comprehensive baseline for assessing LLM performance in extracting\nprobabilistic knowledge.",
      "tldr_zh": "本文研究了从大型语言模型(LLMs)中提取概率知识，以参数化贝叶斯网络(BN)，从而实现对真实事件及其关系的概率建模。实验在80个公开BN上进行，结果显示LLMs查询得到的条件概率分布比随机、均匀分布或基于下一个标记生成概率的基线更可靠，并能作为专家先验减少系统偏差。总体上，该工作提出了一种结合LLMs概率知识和小量真实数据的策略来自动构建BN，并评估了多种提示策略，建立首个全面基线评估LLMs在概率知识提取方面的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15918v1",
      "published_date": "2025-05-21 18:15:05 UTC",
      "updated_date": "2025-05-21 18:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:36:47.789985"
    },
    {
      "arxiv_id": "2505.15916v1",
      "title": "BR-TaxQA-R: A Dataset for Question Answering with References for Brazilian Personal Income Tax Law, including case law",
      "title_zh": "翻译失败",
      "authors": [
        "Juvenal Domingos Júnior",
        "Augusto Faria",
        "E. Seiti de Oliveira",
        "Erick de Brito",
        "Matheus Teotonio",
        "Andre Assumpção",
        "Diedre Carmo",
        "Roberto Lotufo",
        "Jayr Pereira"
      ],
      "abstract": "This paper presents BR-TaxQA-R, a novel dataset designed to support question\nanswering with references in the context of Brazilian personal income tax law.\nThe dataset contains 715 questions from the 2024 official Q\\&A document\npublished by Brazil's Internal Revenue Service, enriched with statutory norms\nand administrative rulings from the Conselho Administrativo de Recursos Fiscais\n(CARF). We implement a Retrieval-Augmented Generation (RAG) pipeline using\nOpenAI embeddings for searching and GPT-4o-mini for answer generation. We\ncompare different text segmentation strategies and benchmark our system against\ncommercial tools such as ChatGPT and Perplexity.ai using RAGAS-based metrics.\nResults show that our custom RAG pipeline outperforms commercial systems in\nResponse Relevancy, indicating stronger alignment with user queries, while\ncommercial models achieve higher scores in Factual Correctness and fluency.\nThese findings highlight a trade-off between legally grounded generation and\nlinguistic fluency. Crucially, we argue that human expert evaluation remains\nessential to ensure the legal validity of AI-generated answers in high-stakes\ndomains such as taxation. BR-TaxQA-R is publicly available at\nhttps://huggingface.co/datasets/unicamp-dl/BR-TaxQA-R.",
      "tldr_zh": "本文提出BR-TaxQA-R数据集，该数据集针对巴西个人所得税法设计，包含715个问题并附带法定规范和行政裁决，支持带参考的问答系统。研究者构建了基于Retrieval-Augmented Generation (RAG)管道，使用OpenAI embeddings进行检索和GPT-4o-mini生成答案，并比较了不同文本分割策略，同时与ChatGPT和Perplexity.ai等商业工具进行基准测试。结果显示，自定义RAG系统在Response Relevancy上优于商业工具，但商业模型在Factual Correctness和流畅性方面得分更高，突显了法律准确性与语言流利的权衡。作者强调，在高风险领域如税收，AI生成答案需通过人为专家评估确保法律有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15916v1",
      "published_date": "2025-05-21 18:11:41 UTC",
      "updated_date": "2025-05-21 18:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:37:00.853343"
    },
    {
      "arxiv_id": "2505.15888v1",
      "title": "Last Layer Empirical Bayes",
      "title_zh": "最后一层经验贝叶斯",
      "authors": [
        "Valentin Villecroze",
        "Yixin Wang",
        "Gabriel Loaiza-Ganem"
      ],
      "abstract": "The task of quantifying the inherent uncertainty associated with neural\nnetwork predictions is a key challenge in artificial intelligence. Bayesian\nneural networks (BNNs) and deep ensembles are among the most prominent\napproaches to tackle this task. Both approaches produce predictions by\ncomputing an expectation of neural network outputs over some distribution on\nthe corresponding weights; this distribution is given by the posterior in the\ncase of BNNs, and by a mixture of point masses for ensembles. Inspired by\nrecent work showing that the distribution used by ensembles can be understood\nas a posterior corresponding to a learned data-dependent prior, we propose last\nlayer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a\nnormalizing flow, which is then trained to maximize the evidence lower bound;\nto retain tractability we use the flow only on the last layer. We show why LLEB\nis well motivated, and how it interpolates between standard BNNs and ensembles\nin terms of the strength of the prior that they use. LLEB performs on par with\nexisting approaches, highlighting that empirical Bayes is a promising direction\nfor future research in uncertainty quantification.",
      "tldr_zh": "该论文探讨了量化神经网络预测不确定性的关键挑战，比较了Bayesian neural networks (BNNs)和deep ensembles等方法，这些方法通过对权重分布求期望来生成预测。作者提出Last Layer Empirical Bayes (LLEB)，一种新框架，使用normalizing flow作为可学习的prior，仅应用于最后一层，并通过最大化evidence lower bound (ELBO)进行训练，从而在prior强度上介于标准BNNs和ensembles之间。实验结果显示，LLEB的性能与现有方法相当，证明了empirical Bayes在不确定性量化研究中的潜在价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the ICBINB Worshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15888v1",
      "published_date": "2025-05-21 18:00:00 UTC",
      "updated_date": "2025-05-21 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:37:13.692113"
    },
    {
      "arxiv_id": "2505.15810v2",
      "title": "GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Zhou",
        "Sunhao Dai",
        "Shuai Wang",
        "Kaiwen Zhou",
        "Qinglin Jia",
        "Jun Xu"
      ],
      "abstract": "Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm,\ncoupling online Reinforcement Learning (RL) with explicit chain-of-thought\nreasoning prior to object grounding and thereby achieving substantial\nperformance gains. In this paper, we first conduct extensive analysis\nexperiments of three key components of that training pipeline: input design,\noutput evaluation, and policy update-each revealing distinct challenges arising\nfrom blindly applying general-purpose RL without adapting to GUI grounding\ntasks. Input design: Current templates encourage the model to generate\nchain-of-thought reasoning, but longer chains unexpectedly lead to worse\ngrounding performance. Output evaluation: Reward functions based on hit signals\nor box area allow models to exploit box size, leading to reward hacking and\npoor localization quality. Policy update: Online RL tends to overfit easy\nexamples due to biases in length and sample difficulty, leading to\nunder-optimization on harder cases. To address these issues, we propose three\ntargeted solutions. First, we adopt a Fast Thinking Template that encourages\ndirect answer generation, reducing excessive reasoning during training. Second,\nwe incorporate a box size constraint into the reward function to mitigate\nreward hacking. Third, we revise the RL objective by adjusting length\nnormalization and adding a difficulty-aware scaling factor, enabling better\noptimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with\nQwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on\nScreenSpot-Pro. This surpasses all prior models of similar size and even\noutperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI\nagent grounding. The project repository is available at\nhttps://github.com/Yuqi-Zhou/GUI-G1.",
      "tldr_zh": "该论文分析了在 GUI 代理中应用 R1-Zero 范式的训练流程，包括输入设计、输出评估和策略更新的关键挑战：如过长的 chain-of-thought reasoning 导致性能下降、基于 hit signals 或 box area 的奖励函数易受 reward hacking 影响，以及 online RL 因样本难度偏差而过拟合简单示例。针对这些问题，作者提出三点解决方案：采用 Fast Thinking Template 以鼓励直接答案生成、将 box size 约束融入奖励函数中，以及修改 RL 目标通过长度归一化和难度感知缩放因子优化硬样本。实验结果显示，使用 Qwen2.5-VL-3B-Instruct 训练的 GUI-G1-3B 模型在 ScreenSpot 数据集上达到 90.3% 准确率，在 ScreenSpot-Pro 上达到 37.1%，超越了同等规模模型并击败了更大的 UI-TARS-7B，建立新的 GUI 代理视觉定位最先进水平。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15810v2",
      "published_date": "2025-05-21 17:59:09 UTC",
      "updated_date": "2025-05-22 11:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:37:24.865146"
    },
    {
      "arxiv_id": "2505.15808v1",
      "title": "Neural Conditional Transport Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Rodriguez-Pardo",
        "Leonardo Chiani",
        "Emanuele Borgonovo",
        "Massimo Tavoni"
      ],
      "abstract": "We present a neural framework for learning conditional optimal transport (OT)\nmaps between probability distributions. Our approach introduces a conditioning\nmechanism capable of processing both categorical and continuous conditioning\nvariables simultaneously. At the core of our method lies a hypernetwork that\ngenerates transport layer parameters based on these inputs, creating adaptive\nmappings that outperform simpler conditioning methods. Comprehensive ablation\nstudies demonstrate the superior performance of our method over baseline\nconfigurations. Furthermore, we showcase an application to global sensitivity\nanalysis, offering high performance in computing OT-based sensitivity indices.\nThis work advances the state-of-the-art in conditional optimal transport,\nenabling broader application of optimal transport principles to complex,\nhigh-dimensional domains such as generative modeling and black-box model\nexplainability.",
      "tldr_zh": "我们提出了一种神经框架，用于学习条件最优传输 (conditional optimal transport, OT) 地图，该框架引入一种机制，能同时处理分类和连续条件变量。核心是 hypernetwork，根据输入生成传输层参数，实现自适应映射，并超越简单条件方法。全面的消融研究 (ablation studies) 证明了该方法的性能优势，并在全球敏感性分析 (global sensitivity analysis) 中表现出色于基线配置。该工作推进了 OT 原则在生成建模和黑箱模型可解释性等复杂高维领域的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.AP",
        "stat.ML",
        "49Q22 (Primary) 68T07 (Secondary)",
        "I.5.1; I.2.0; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review. Supplementary material included in the pdf",
      "pdf_url": "http://arxiv.org/pdf/2505.15808v1",
      "published_date": "2025-05-21 17:59:02 UTC",
      "updated_date": "2025-05-21 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:37:37.342249"
    },
    {
      "arxiv_id": "2505.15879v1",
      "title": "GRIT: Teaching MLLMs to Think with Images",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Fan",
        "Xuehai He",
        "Diji Yang",
        "Kaizhi Zheng",
        "Ching-Chen Kuo",
        "Yuting Zheng",
        "Sravana Jyothi Narayanaraju",
        "Xinze Guan",
        "Xin Eric Wang"
      ],
      "abstract": "Recent studies have demonstrated the efficacy of using Reinforcement Learning\n(RL) in building reasoning models that articulate chains of thoughts prior to\nproducing final answers. However, despite ongoing advances that aim at enabling\nreasoning for vision-language tasks, existing open-source visual reasoning\nmodels typically generate reasoning content with pure natural language, lacking\nexplicit integration of visual information. This limits their ability to\nproduce clearly articulated and visually grounded reasoning chains. To this\nend, we propose Grounded Reasoning with Images and Texts (GRIT), a novel method\nfor training MLLMs to think with images. GRIT introduces a grounded reasoning\nparadigm, in which models generate reasoning chains that interleave natural\nlanguage and explicit bounding box coordinates. These coordinates point to\nregions of the input image that the model consults during its reasoning\nprocess. Additionally, GRIT is equipped with a reinforcement learning approach,\nGRPO-GR, built upon the GRPO algorithm. GRPO-GR employs robust rewards focused\non the final answer accuracy and format of the grounded reasoning output, which\neliminates the need for data with reasoning chain annotations or explicit\nbounding box labels. As a result, GRIT achieves exceptional data efficiency,\nrequiring as few as 20 image-question-answer triplets from existing datasets.\nComprehensive evaluations demonstrate that GRIT effectively trains MLLMs to\nproduce coherent and visually grounded reasoning chains, showing a successful\nunification of reasoning and grounding abilities.",
      "tldr_zh": "该研究提出 GRIT 方法，旨在训练多模态大语言模型 (MLLMs) 生成视觉 grounded 的推理链，以解决现有视觉推理模型仅使用纯自然语言而缺乏图像整合的问题。GRIT 引入 grounded reasoning 范式，让模型交替输出自然语言和 bounding box 坐标，以明确指向输入图像的推理区域；同时，使用基于 GRPO 的强化学习算法 GRPO-GR，仅需少量数据（如 20 个 image-question-answer triplets）即可训练，无需标注推理链或坐标。实验结果显示，GRIT 显著提升了 MLLMs 的推理和 grounding 能力，实现二者的统一。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15879v1",
      "published_date": "2025-05-21 17:54:49 UTC",
      "updated_date": "2025-05-21 17:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:37:50.008494"
    },
    {
      "arxiv_id": "2505.15801v1",
      "title": "VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models",
      "title_zh": "VerifyBench: 针对大型语言模型的基于参考的奖励系统基准测试",
      "authors": [
        "Yuchen Yan",
        "Jin Jiang",
        "Zhenbang Ren",
        "Yijun Li",
        "Xudong Cai",
        "Yang Liu",
        "Xin Xu",
        "Mengdi Zhang",
        "Jian Shao",
        "Yongliang Shen",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved\nremarkable performance in the domain of reasoning. A key component of their\ntraining is the incorporation of verifiable rewards within reinforcement\nlearning (RL). However, existing reward benchmarks do not evaluate\nreference-based reward systems, leaving researchers with limited understanding\nof the accuracy of verifiers used in RL. In this paper, we introduce two\nbenchmarks, VerifyBench and VerifyBench-Hard, designed to assess the\nperformance of reference-based reward systems. These benchmarks are constructed\nthrough meticulous data collection and curation, followed by careful human\nannotation to ensure high quality. Current models still show considerable room\nfor improvement on both VerifyBench and VerifyBench-Hard, especially\nsmaller-scale models. Furthermore, we conduct a thorough and comprehensive\nanalysis of evaluation results, offering insights for understanding and\ndeveloping reference-based reward systems. Our proposed benchmarks serve as\neffective tools for guiding the development of verifier accuracy and the\nreasoning capabilities of models trained via RL in reasoning tasks.",
      "tldr_zh": "该论文引入了 VerifyBench 和 VerifyBench-Hard 两个基准，用于评估基于参考的奖励系统（reference-based reward systems）在大型语言模型（Large Language Models）中的性能，以填补现有奖励基准的不足。基准通过 meticulous 数据收集、整理和人工标注构建，确保高质量评估。实验结果显示，当前模型在这些基准上仍有较大改进空间，尤其是小型模型；论文还进行了全面分析，提供见解来指导参考-based 奖励系统的开发和通过强化学习（RL）训练的模型在推理任务中的能力提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset: https://huggingface.co/datasets/ZJU-REAL/VerifyBench",
      "pdf_url": "http://arxiv.org/pdf/2505.15801v1",
      "published_date": "2025-05-21 17:54:43 UTC",
      "updated_date": "2025-05-21 17:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:38:03.206425"
    },
    {
      "arxiv_id": "2505.15792v1",
      "title": "Long-Form Information Alignment Evaluation Beyond Atomic Facts",
      "title_zh": "长形式信息对齐评估：超越原子事实",
      "authors": [
        "Danna Zheng",
        "Mirella Lapata",
        "Jeff Z. Pan"
      ],
      "abstract": "Information alignment evaluators are vital for various NLG evaluation tasks\nand trustworthy LLM deployment, reducing hallucinations and enhancing user\ntrust. Current fine-grained methods, like FactScore, verify facts individually\nbut neglect inter-fact dependencies, enabling subtle vulnerabilities. In this\nwork, we introduce MontageLie, a challenging benchmark that constructs\ndeceptive narratives by \"montaging\" truthful statements without introducing\nexplicit hallucinations. We demonstrate that both coarse-grained LLM-based\nevaluators and current fine-grained frameworks are susceptible to this attack,\nwith AUC-ROC scores falling below 65%. To enable more robust fine-grained\nevaluation, we propose DoveScore, a novel framework that jointly verifies\nfactual accuracy and event-order consistency. By modeling inter-fact\nrelationships, DoveScore outperforms existing fine-grained methods by over 8%,\nproviding a more robust solution for long-form text alignment evaluation. Our\ncode and datasets are available at https://github.com/dannalily/DoveScore.",
      "tldr_zh": "本研究指出，现有的信息对齐评估方法（如 FactScore）仅验证单个事实，却忽略事实间依赖性，导致评估易受欺骗性叙述攻击。为此，论文引入 MontageLie 基准，通过“montaging”真实语句构建无显式幻觉的欺骗性文本，实验显示现有评估器（包括粗粒度 LLM 和细粒度框架）的 AUC-ROC 分数低于 65%。为了提升鲁棒性，论文提出 DoveScore 框架，该框架同时验证事实准确性和事件顺序一致性，通过建模事实间关系，比现有方法提高超过 8%，为长文本对齐评估提供更可靠的解决方案。代码和数据集已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15792v1",
      "published_date": "2025-05-21 17:46:38 UTC",
      "updated_date": "2025-05-21 17:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:38:14.092141"
    },
    {
      "arxiv_id": "2505.15790v1",
      "title": "Exploring the Innovation Opportunities for Pre-trained Models",
      "title_zh": "探索预训练模型的创新机会",
      "authors": [
        "Minjung Park",
        "Jodi Forlizzi",
        "John Zimmerman"
      ],
      "abstract": "Innovators transform the world by understanding where services are\nsuccessfully meeting customers' needs and then using this knowledge to identify\nfailsafe opportunities for innovation. Pre-trained models have changed the AI\ninnovation landscape, making it faster and easier to create new AI products and\nservices. Understanding where pre-trained models are successful is critical for\nsupporting AI innovation. Unfortunately, the hype cycle surrounding pre-trained\nmodels makes it hard to know where AI can really be successful. To address\nthis, we investigated pre-trained model applications developed by HCI\nresearchers as a proxy for commercially successful applications. The research\napplications demonstrate technical capabilities, address real user needs, and\navoid ethical challenges. Using an artifact analysis approach, we categorized\ncapabilities, opportunity domains, data types, and emerging interaction design\npatterns, uncovering some of the opportunity space for innovation with\npre-trained models.",
      "tldr_zh": "本研究探讨了 pre-trained models 在 AI 创新中的机会，强调理解这些模型成功之处有助于识别可靠的创新领域，但炒作周期使这变得困难。作者通过分析 HCI 研究人员开发的应用程序作为商业应用的代理，使用工件分析方法分类了模型的能力、机会领域、数据类型以及新兴交互设计模式。这些发现揭示了 pre-trained models 在解决真实用户需求、展示技术潜力并避免伦理挑战方面的创新空间，为 AI 产品和服务开发提供了指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "33 pages, 20 figures, 4 tables, DIS",
      "pdf_url": "http://arxiv.org/pdf/2505.15790v1",
      "published_date": "2025-05-21 17:43:46 UTC",
      "updated_date": "2025-05-21 17:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:38:24.914203"
    },
    {
      "arxiv_id": "2505.15784v1",
      "title": "Large Language Models as Computable Approximations to Solomonoff Induction",
      "title_zh": "大型语言模型作为 Solomonoff Induction 的可计算近似",
      "authors": [
        "Jun Wan",
        "Lingrui Mei"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) calls for a rigorous\ntheoretical framework to explain their empirical success. While significant\nprogress has been made in understanding LLM behaviors, existing theoretical\nframeworks remain fragmented in explaining emergent phenomena through a unified\nmathematical lens. We establish the first formal connection between LLM\narchitectures and Algorithmic Information Theory (AIT) by proving two\nfundamental results: (1) the training process computationally approximates\nSolomonoff prior through loss minimization interpreted as program length\noptimization, and (2) next-token prediction implements approximate Solomonoff\ninduction. We leverage AIT to provide a unified theoretical explanation for\nin-context learning, few-shot learning, and scaling laws. Furthermore, our\ntheoretical insights lead to a principled method for few-shot example selection\nthat prioritizes samples where models exhibit lower predictive confidence. We\ndemonstrate through experiments on diverse text classification benchmarks that\nthis strategy yields significant performance improvements, particularly for\nsmaller model architectures, when compared to selecting high-confidence\nexamples. Our framework bridges the gap between theoretical foundations and\npractical LLM behaviors, providing both explanatory power and actionable\ninsights for future model development.",
      "tldr_zh": "该研究将大型语言模型(LLMs)视为Solomonoff Induction的可计算近似，通过算法信息理论(AIT)建立了LLMs架构的统一理论框架。论文证明了LLMs的训练过程通过损失最小化近似Solomonoff prior，并实现了下一个标记预测的近似Solomonoff归纳，从而解释了in-context learning、few-shot learning和scaling laws等紧急现象。基于此框架，研究提出了一种few-shot示例选择方法，优先选择模型预测信心较低的样本，并在多种文本分类基准上实验验证了其显著性能提升，尤其适用于较小模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Both authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2505.15784v1",
      "published_date": "2025-05-21 17:35:08 UTC",
      "updated_date": "2025-05-21 17:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:38:36.639548"
    },
    {
      "arxiv_id": "2505.15779v1",
      "title": "IA-T2I: Internet-Augmented Text-to-Image Generation",
      "title_zh": "IA-T2I：互联网增强的文本到图像生成",
      "authors": [
        "Chuanhao Li",
        "Jianwen Sun",
        "Yukang Feng",
        "Mingliang Zhai",
        "Yifan Chang",
        "Kaipeng Zhang"
      ],
      "abstract": "Current text-to-image (T2I) generation models achieve promising results, but\nthey fail on the scenarios where the knowledge implied in the text prompt is\nuncertain. For example, a T2I model released in February would struggle to\ngenerate a suitable poster for a movie premiering in April, because the\ncharacter designs and styles are uncertain to the model. To solve this problem,\nwe propose an Internet-Augmented text-to-image generation (IA-T2I) framework to\ncompel T2I models clear about such uncertain knowledge by providing them with\nreference images. Specifically, an active retrieval module is designed to\ndetermine whether a reference image is needed based on the given text prompt; a\nhierarchical image selection module is introduced to find the most suitable\nimage returned by an image search engine to enhance the T2I model; a\nself-reflection mechanism is presented to continuously evaluate and refine the\ngenerated image to ensure faithful alignment with the text prompt. To evaluate\nthe proposed framework's performance, we collect a dataset named Img-Ref-T2I,\nwhere text prompts include three types of uncertain knowledge: (1) known but\nrare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt\nto guide GPT-4o in making preference evaluation, which has been shown to have\nan evaluation accuracy similar to that of human preference evaluation.\nExperimental results demonstrate the effectiveness of our framework,\noutperforming GPT-4o by about 30% in human evaluation.",
      "tldr_zh": "该研究针对文本到图像 (T2I) 生成模型在处理文本中不确定知识（如未来事件或模糊细节）时的不足，提出了一种 Internet-Augmented T2I (IA-T2I) 框架，通过提供参考图像来提升生成质量。具体而言，该框架包括主动检索模块（判断是否需要参考图像）、层次化图像选择模块（从搜索引擎中选出最合适图像）以及自反机制（持续评估和优化生成的图像以匹配文本提示）。为了评估框架效果，研究者构建了 Img-Ref-T2I 数据集，涵盖已知但稀有、未知和模糊三种不确定知识类型，并使用 GPT-4o 进行偏好评估。实验结果显示，IA-T2I 在人类评估中比 GPT-4o 提高了约 30% 的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures, a framework that integrates reference images\n  from the Internet into T2I/TI2I models",
      "pdf_url": "http://arxiv.org/pdf/2505.15779v1",
      "published_date": "2025-05-21 17:31:49 UTC",
      "updated_date": "2025-05-21 17:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:38:49.469159"
    },
    {
      "arxiv_id": "2505.15778v1",
      "title": "Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zhang",
        "Xuehai He",
        "Weixiang Yan",
        "Ao Shen",
        "Chenyang Zhao",
        "Shuohang Wang",
        "Yelong Shen",
        "Xin Eric Wang"
      ],
      "abstract": "Human cognition typically involves thinking through abstract, fluid concepts\nrather than strictly using discrete linguistic tokens. Current reasoning\nmodels, however, are constrained to reasoning within the boundaries of human\nlanguage, processing discrete token embeddings that represent fixed points in\nthe semantic space. This discrete constraint restricts the expressive power and\nupper potential of such reasoning models, often causing incomplete exploration\nof reasoning paths, as standard Chain-of-Thought (CoT) methods rely on sampling\none token per step. In this work, we introduce Soft Thinking, a training-free\nmethod that emulates human-like \"soft\" reasoning by generating soft, abstract\nconcept tokens in a continuous concept space. These concept tokens are created\nby the probability-weighted mixture of token embeddings, which form the\ncontinuous concept space, enabling smooth transitions and richer\nrepresentations that transcend traditional discrete boundaries. In essence,\neach generated concept token encapsulates multiple meanings from related\ndiscrete tokens, implicitly exploring various reasoning paths to converge\neffectively toward the correct answer. Empirical evaluations on diverse\nmathematical and coding benchmarks consistently demonstrate the effectiveness\nand efficiency of Soft Thinking, improving pass@1 accuracy by up to 2.48 points\nwhile simultaneously reducing token usage by up to 22.4% compared to standard\nCoT. Qualitative analysis further reveals that Soft Thinking outputs remain\nhighly interpretable and readable, highlighting the potential of Soft Thinking\nto break the inherent bottleneck of discrete language-based reasoning. Code is\navailable at https://github.com/eric-ai-lab/Soft-Thinking.",
      "tldr_zh": "该论文指出，当前大型语言模型（LLMs）的推理受限于离散 token embeddings，导致探索推理路径不完整。作者提出 Soft Thinking，一种无需训练的方法，通过在连续概念空间中生成软抽象概念 token（基于概率加权混合 token embeddings），实现平滑过渡和更丰富的表示，从而隐式探索多种推理路径。实验结果显示，在数学和编码基准测试中，Soft Thinking 提高了 pass@1 准确率最多 2.48 点，同时减少了高达 22.4% 的 token 使用。整体上，该方法提升了 LLMs 的推理潜力和输出可解释性，打破了 Chain-of-Thought (CoT) 的离散限制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15778v1",
      "published_date": "2025-05-21 17:29:15 UTC",
      "updated_date": "2025-05-21 17:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:39:01.475028"
    },
    {
      "arxiv_id": "2505.15765v1",
      "title": "Constructing a 3D Town from a Single Image",
      "title_zh": "从单张图像构建3D城镇",
      "authors": [
        "Kaizhi Zheng",
        "Ruijian Zhang",
        "Jing Gu",
        "Jie Yang",
        "Xin Eric Wang"
      ],
      "abstract": "Acquiring detailed 3D scenes typically demands costly equipment, multi-view\ndata, or labor-intensive modeling. Therefore, a lightweight alternative,\ngenerating complex 3D scenes from a single top-down image, plays an essential\nrole in real-world applications. While recent 3D generative models have\nachieved remarkable results at the object level, their extension to full-scene\ngeneration often leads to inconsistent geometry, layout hallucinations, and\nlow-quality meshes. In this work, we introduce 3DTown, a training-free\nframework designed to synthesize realistic and coherent 3D scenes from a single\ntop-down view. Our method is grounded in two principles: region-based\ngeneration to improve image-to-3D alignment and resolution, and spatial-aware\n3D inpainting to ensure global scene coherence and high-quality geometry\ngeneration. Specifically, we decompose the input image into overlapping regions\nand generate each using a pretrained 3D object generator, followed by a masked\nrectified flow inpainting process that fills in missing geometry while\nmaintaining structural continuity. This modular design allows us to overcome\nresolution bottlenecks and preserve spatial structure without requiring 3D\nsupervision or fine-tuning. Extensive experiments across diverse scenes show\nthat 3DTown outperforms state-of-the-art baselines, including Trellis,\nHunyuan3D-2, and TripoSG, in terms of geometry quality, spatial coherence, and\ntexture fidelity. Our results demonstrate that high-quality 3D town generation\nis achievable from a single image using a principled, training-free approach.",
      "tldr_zh": "本研究提出了一种无需训练的框架3DTown，用于从单一顶视图图像生成真实连贯的3D场景，旨在解决现有3D生成模型在全场景生成中存在的几何不一致、布局幻觉和低质量网格等问题。框架基于两个核心原则：基于区域的生成以提升图像到3D的alignment和分辨率，以及空间感知3D inpainting以确保全局场景连贯和高质几何。方法包括将输入图像分解为重叠区域，使用预训练的3D object generator生成每个区域，然后通过masked rectified flow inpainting填充缺失几何，同时保持结构连续。实验结果显示，3DTown在各种场景中优于基线模型如Trellis、Hunyuan3D-2和TripoSG，在几何质量、空间连贯性和纹理保真度方面表现出色，证明了这种训练-free方法在高效3D城镇生成中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15765v1",
      "published_date": "2025-05-21 17:10:47 UTC",
      "updated_date": "2025-05-21 17:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:39:16.298145"
    },
    {
      "arxiv_id": "2505.15754v1",
      "title": "Improving planning and MBRL with temporally-extended actions",
      "title_zh": "翻译失败",
      "authors": [
        "Palash Chatterjee",
        "Roni Khardon"
      ],
      "abstract": "Continuous time systems are often modeled using discrete time dynamics but\nthis requires a small simulation step to maintain accuracy. In turn, this\nrequires a large planning horizon which leads to computationally demanding\nplanning problems and reduced performance. Previous work in model free\nreinforcement learning has partially addressed this issue using action repeats\nwhere a policy is learned to determine a discrete action duration. Instead we\npropose to control the continuous decision timescale directly by using\ntemporally-extended actions and letting the planner treat the duration of the\naction as an additional optimization variable along with the standard action\nvariables. This additional structure has multiple advantages. It speeds up\nsimulation time of trajectories and, importantly, it allows for deep horizon\nsearch in terms of primitive actions while using a shallow search depth in the\nplanner. In addition, in the model based reinforcement learning (MBRL) setting,\nit reduces compounding errors from model learning and improves training time\nfor models. We show that this idea is effective and that the range for action\ndurations can be automatically selected using a multi-armed bandit formulation\nand integrated into the MBRL framework. An extensive experimental evaluation\nboth in planning and in MBRL, shows that our approach yields faster planning,\nbetter solutions, and that it enables solutions to problems that are not solved\nin the standard formulation.",
      "tldr_zh": "本文提出一种改进规划和基于模型的强化学习(MBRL)的方法，通过引入temporally-extended actions，将动作持续时间作为额外的优化变量，从而直接控制连续决策时标。相比传统方法，该框架加速了轨迹模拟，允许在浅搜索深度下实现深地平线搜索，并减少模型学习中的累积错误。利用multi-armed bandit公式自动选择动作持续时间范围，并将其整合到MBRL框架中。实验结果显示，该方法在规划和MBRL任务中实现了更快计算、更高品质的解决方案，并能解决标准方法无法处理的复杂问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15754v1",
      "published_date": "2025-05-21 16:59:32 UTC",
      "updated_date": "2025-05-21 16:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:39:25.993011"
    },
    {
      "arxiv_id": "2505.15753v1",
      "title": "Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Taiye Chen",
        "Zeming Wei",
        "Ang Li",
        "Yisen Wang"
      ],
      "abstract": "Large Language Models (LLMs) are known to be vulnerable to jailbreaking\nattacks, wherein adversaries exploit carefully engineered prompts to induce\nharmful or unethical responses. Such threats have raised critical concerns\nabout the safety and reliability of LLMs in real-world deployment. While\nexisting defense mechanisms partially mitigate such risks, subsequent\nadvancements in adversarial techniques have enabled novel jailbreaking methods\nto circumvent these protections, exposing the limitations of static defense\nframeworks. In this work, we explore defending against evolving jailbreaking\nthreats through the lens of context retrieval. First, we conduct a preliminary\nstudy demonstrating that even a minimal set of safety-aligned examples against\na particular jailbreak can significantly enhance robustness against this attack\npattern. Building on this insight, we further leverage the retrieval-augmented\ngeneration (RAG) techniques and propose Safety Context Retrieval (SCR), a\nscalable and robust safeguarding paradigm for LLMs against jailbreaking. Our\ncomprehensive experiments demonstrate how SCR achieves superior defensive\nperformance against both established and emerging jailbreaking tactics,\ncontributing a new paradigm to LLM safety. Our code will be available upon\npublication.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）面对动态jailbreaking攻击的防御问题，这些攻击利用精心设计的提示诱导有害响应。作者提出Safety Context Retrieval (SCR)框架，基于检索增强生成（RAG）技术，通过检索安全对齐示例来增强模型的鲁棒性，从而有效应对已知和新兴攻击策略。实验结果显示，SCR在防御性能上优于现有方法，为LLMs的安全部署提供了一个可扩展的新范式。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15753v1",
      "published_date": "2025-05-21 16:58:14 UTC",
      "updated_date": "2025-05-21 16:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:39:36.658857"
    },
    {
      "arxiv_id": "2505.15747v2",
      "title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Kanan Kiguchi",
        "Yunhao Tu",
        "Katsuhiro Ajito",
        "Fady Alnajjar",
        "Kazuyuki Murase"
      ],
      "abstract": "We propose a novel framework for integrating fragmented multi-modal data in\nAlzheimer's disease (AD) research using large language models (LLMs) and\nknowledge graphs. While traditional multimodal analysis requires matched\npatient IDs across datasets, our approach demonstrates population-level\nintegration of MRI, gene expression, biomarkers, EEG, and clinical indicators\nfrom independent cohorts. Statistical analysis identified significant features\nin each modality, which were connected as nodes in a knowledge graph. LLMs then\nanalyzed the graph to extract potential correlations and generate hypotheses in\nnatural language. This approach revealed several novel relationships, including\na potential pathway linking metabolic risk factors to tau protein abnormalities\nvia neuroinflammation (r>0.6, p<0.001), and unexpected correlations between\nfrontal EEG channels and specific gene expression profiles (r=0.42-0.58,\np<0.01). Cross-validation with independent datasets confirmed the robustness of\nmajor findings, with consistent effect sizes across cohorts (variance <15%).\nThe reproducibility of these findings was further supported by expert review\n(Cohen's k=0.82) and computational validation. Our framework enables cross\nmodal integration at a conceptual level without requiring patient ID matching,\noffering new possibilities for understanding AD pathology through fragmented\ndata reuse and generating testable hypotheses for future research.",
      "tldr_zh": "本研究提出了一种新框架，使用大型语言模型（LLMs）和知识图谱（knowledge graphs），在种群水平整合阿尔茨海默病（Alzheimer's disease, AD）的碎片化多模态数据，如 MRI、基因表达、生物标志物、EEG 和临床指标，而无需匹配患者 ID。框架通过统计分析识别关键特征，将其作为知识图谱节点，并利用 LLMs 提取潜在相关性，生成自然语言假设，包括代谢风险因素通过神经炎症与 tau 蛋白异常的潜在途径（r>0.6, p<0.001）和额叶 EEG 通道与特定基因表达的相关（r=0.42-0.58, p<0.01）。交叉验证和独立数据集确认了这些发现的稳健性（方差<15%），为理解 AD 病理学提供新途径，并生成可测试的假设以支持未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.1; H.3.1; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 8 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15747v2",
      "published_date": "2025-05-21 16:51:49 UTC",
      "updated_date": "2025-05-22 03:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:39:51.196277"
    },
    {
      "arxiv_id": "2505.15746v1",
      "title": "Higher-order Structure Boosts Link Prediction on Temporal Graphs",
      "title_zh": "高阶结构提升时间图上的链接预测",
      "authors": [
        "Jingzhe Liu",
        "Zhigang Hua",
        "Yan Xie",
        "Bingheng Li",
        "Harry Shomer",
        "Yu Song",
        "Kaveh Hassani",
        "Jiliang Tang"
      ],
      "abstract": "Temporal Graph Neural Networks (TGNNs) have gained growing attention for\nmodeling and predicting structures in temporal graphs. However, existing TGNNs\nprimarily focus on pairwise interactions while overlooking higher-order\nstructures that are integral to link formation and evolution in real-world\ntemporal graphs. Meanwhile, these models often suffer from efficiency\nbottlenecks, further limiting their expressive power. To tackle these\nchallenges, we propose a Higher-order structure Temporal Graph Neural Network,\nwhich incorporates hypergraph representations into temporal graph learning. In\nparticular, we develop an algorithm to identify the underlying higher-order\nstructures, enhancing the model's ability to capture the group interactions.\nFurthermore, by aggregating multiple edge features into hyperedge\nrepresentations, HTGN effectively reduces memory cost during training. We\ntheoretically demonstrate the enhanced expressiveness of our approach and\nvalidate its effectiveness and efficiency through extensive experiments on\nvarious real-world temporal graphs. Experimental results show that HTGN\nachieves superior performance on dynamic link prediction while reducing memory\ncosts by up to 50\\% compared to existing methods.",
      "tldr_zh": "这篇论文提出了一种 Higher-order structure Temporal Graph Neural Network (HTGN)，通过整合超图表示来提升时间图上的链接预测性能，解决了现有 Temporal Graph Neural Networks (TGNNs) 忽略更高阶结构和效率问题的局限。HTGN 开发了一种算法来识别底层更高阶结构，并通过聚合多个边特征到超边表示，显著减少了训练过程中的内存成本。实验结果显示，该方法在各种真实世界时间图上实现了动态链接预测的优异性能，并将内存消耗降低多达 50%，同时理论上证明了其增强的表达能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15746v1",
      "published_date": "2025-05-21 16:51:44 UTC",
      "updated_date": "2025-05-21 16:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:40:00.902901"
    },
    {
      "arxiv_id": "2505.15742v1",
      "title": "Neuro-Argumentative Learning with Case-Based Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Gould",
        "Francesca Toni"
      ],
      "abstract": "We introduce Gradual Abstract Argumentation for Case-Based Reasoning (Gradual\nAA-CBR), a data-driven, neurosymbolic classification model in which the outcome\nis determined by an argumentation debate structure that is learned\nsimultaneously with neural-based feature extractors. Each argument in the\ndebate is an observed case from the training data, favouring their labelling.\nCases attack or support those with opposing or agreeing labellings, with the\nstrength of each argument and relationship learned through gradient-based\nmethods. This argumentation debate structure provides human-aligned reasoning,\nimproving model interpretability compared to traditional neural networks (NNs).\nUnlike the existing purely symbolic variant, Abstract Argumentation for\nCase-Based Reasoning (AA-CBR), Gradual AA-CBR is capable of multi-class\nclassification, automatic learning of feature and data point importance,\nassigning uncertainty values to outcomes, using all available data points, and\ndoes not require binary features. We show that Gradual AA-CBR performs\ncomparably to NNs whilst significantly outperforming existing AA-CBR\nformulations.",
      "tldr_zh": "本研究引入了Gradual Abstract Argumentation for Case-Based Reasoning (Gradual AA-CBR)，一种数据驱动的神经符号分类模型，通过同时学习论证辩论结构和基于神经的特征提取器来确定结果。每个论证基于训练数据中的观察案例，这些案例通过攻击或支持关系互动，其强度和关系利用gradient-based methods进行学习，从而提供人类对齐的推理并提升模型可解释性。与传统neural networks (NNs)相比，Gradual AA-CBR支持多类分类、自动学习特征和数据点重要性、分配不确定性值，并能利用所有可用数据点，而无需二进制特征。实验结果显示，Gradual AA-CBR的性能与NNs相当，且显著优于现有Abstract Argumentation for Case-Based Reasoning (AA-CBR)版本。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeSy25",
      "pdf_url": "http://arxiv.org/pdf/2505.15742v1",
      "published_date": "2025-05-21 16:49:47 UTC",
      "updated_date": "2025-05-21 16:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:40:14.575838"
    },
    {
      "arxiv_id": "2505.15740v1",
      "title": "HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement",
      "title_zh": "HybridProver：通过 LLM 驱动的证明合成和精炼增强定理证明",
      "authors": [
        "Jilin Hu",
        "Jianyu Zhang",
        "Yongwang Zhao",
        "Talia Ringer"
      ],
      "abstract": "Formal methods is pivotal for verifying the reliability of critical systems\nthrough rigorous mathematical proofs. However, its adoption is hindered by\nlabor-intensive manual proofs and the expertise required to use theorem\nprovers. Recent advancements in large language models (LLMs) offer new\nopportunities for automated theorem proving. Two promising approaches are\ngenerating tactics step by step and generating a whole proof directly with an\nLLM. However, existing work makes no attempt to combine the two approaches. In\nthis work, we introduce HybridProver, a dual-model proof synthesis framework\nthat combines tactic-based generation and whole-proof synthesis to harness the\nbenefits of both approaches. HybridProver generates whole proof candidates for\nevaluation directly, then extracts proof sketches from those candidates. It\nthen uses a tactic-based generation model that integrates automated tools to\ncomplete the sketches via stepwise refinement. We implement HybridProver for\nthe Isabelle theorem prover and fine-tune LLMs on our optimized Isabelle\ndatasets. Evaluation on the miniF2F dataset illustrates HybridProver's\neffectiveness. We achieve a 59.4% success rate on miniF2F, where the previous\nSOTA is 56.1%. Our ablation studies show that this SOTA result is attributable\nto combining whole-proof and tactic-based generation. Additionally, we show how\nthe dataset quality, training parameters, and sampling diversity affect the\nfinal result during automated theorem proving with LLMs. All of our code,\ndatasets, and LLMs are open source.",
      "tldr_zh": "该研究提出HybridProver，一种双模型框架，用于增强定理证明，通过结合LLM驱动的整体证明合成和策略生成方法，解决手动证明的劳动密集问题。HybridProver首先生成证明候选并提取草图，然后利用策略生成模型结合自动化工具进行逐步完善。实验结果显示，在miniF2F数据集上，该框架的成功率达到59.4%，超过了先前的SOTA 56.1%。此外，论文探讨了数据集质量、训练参数和采样多样性对LLM定理证明的影响，并开源了所有代码、数据集和模型。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.FL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15740v1",
      "published_date": "2025-05-21 16:45:43 UTC",
      "updated_date": "2025-05-21 16:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:40:27.152507"
    },
    {
      "arxiv_id": "2505.15738v1",
      "title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxue Yang",
        "Bozhidar Stevanoski",
        "Matthieu Meeus",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Large language models (LLMs) are rapidly deployed in real-world applications\nranging from chatbots to agentic systems. Alignment is one of the main\napproaches used to defend against attacks such as prompt injection and\njailbreaks. Recent defenses report near-zero Attack Success Rates (ASR) even\nagainst Greedy Coordinate Gradient (GCG), a white-box attack that generates\nadversarial suffixes to induce attacker-desired outputs. However, this search\nspace over discrete tokens is extremely large, making the task of finding\nsuccessful attacks difficult. GCG has, for instance, been shown to converge to\nlocal minima, making it sensitive to initialization choices. In this paper, we\nassess the future-proof robustness of these defenses using a more informed\nthreat model: attackers who have access to some information about the alignment\nprocess. Specifically, we propose an informed white-box attack leveraging the\nintermediate model checkpoints to initialize GCG, with each checkpoint acting\nas a stepping stone for the next one. We show this approach to be highly\neffective across state-of-the-art (SOTA) defenses and models. We further show\nour informed initialization to outperform other initialization methods and show\na gradient-informed checkpoint selection strategy to greatly improve attack\nperformance and efficiency. Importantly, we also show our method to\nsuccessfully find universal adversarial suffixes -- single suffixes effective\nacross diverse inputs. Our results show that, contrary to previous beliefs,\neffective adversarial suffixes do exist against SOTA alignment-based defenses,\nthat these can be found by existing attack methods when adversaries exploit\nalignment knowledge, and that even universal suffixes exist. Taken together,\nour results highlight the brittleness of current alignment-based methods and\nthe need to consider stronger threat models when testing the safety of LLMs.",
      "tldr_zh": "该研究探讨了在评估大型语言模型 (LLMs) 防御时，使用 informed adversaries 的必要性，以揭示当前对齐 (Alignment) 方法的脆弱性。论文提出一种 informed white-box 攻击，通过利用中间模型检查点 (intermediate model checkpoints) 来初始化 Greedy Coordinate Gradient (GCG) 攻击，从而提高攻击成功率 (ASR) 并找到通用对抗后缀 (universal adversarial suffixes)。实验结果显示，这种方法在 state-of-the-art (SOTA) 防御和模型上表现出色，显著优于传统初始化策略，并证明了现有防御的易受攻击性。总之，该工作强调了在测试 LLM 安全时，需要考虑更强的威胁模型，以提升其鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15738v1",
      "published_date": "2025-05-21 16:43:17 UTC",
      "updated_date": "2025-05-21 16:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:40:38.075961"
    },
    {
      "arxiv_id": "2505.15734v1",
      "title": "DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Srivastava",
        "Zhenyu Bi",
        "Meng Lu",
        "Xuan Wang"
      ],
      "abstract": "Large language models (LLMs) have improved significantly in their reasoning\nthrough extensive training on massive datasets. However, relying solely on\nadditional data for improvement is becoming increasingly impractical,\nhighlighting the need for models to autonomously enhance their reasoning\nwithout external supervision. In this paper, we propose Debate, Train, Evolve\n(DTE), a novel ground truth-free training framework that uses multi-agent\ndebate traces to evolve a single language model. We also introduce a new\nprompting strategy Reflect-Critique-Refine, to improve debate quality by\nexplicitly instructing agents to critique and refine their reasoning. Extensive\nevaluations on five reasoning benchmarks with six open-weight models show that\nour DTE framework achieve substantial improvements, with an average accuracy\ngain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe\nstrong cross-domain generalization, with an average accuracy gain of 5.8% on\nall other benchmarks, suggesting that our method captures general reasoning\ncapabilities.",
      "tldr_zh": "本文提出 DTE（Debate, Train, Evolve）框架，一种无需 ground truth 的训练方法，让大型语言模型（LLMs）通过多智能体辩论痕迹自主演化推理能力，以解决依赖外部数据改进的局限性。该框架引入 Reflect-Critique-Refine 提示策略，指导智能体批判和完善推理，从而提升辩论质量。在五个推理基准上测试六款开源模型后，DTE 实现了 GSM-PLUS 数据集平均准确率提升 8.92%，并在其他基准上平均提升 5.8%，显示出强大的跨域泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15734v1",
      "published_date": "2025-05-21 16:40:12 UTC",
      "updated_date": "2025-05-21 16:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:40:50.063062"
    },
    {
      "arxiv_id": "2505.15722v1",
      "title": "Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Luo",
        "Yiyi Chen",
        "Johannes Bjerva",
        "Qiongxiu Li"
      ],
      "abstract": "We present the first comprehensive study of Memorization in Multilingual\nLarge Language Models (MLLMs), analyzing 95 languages using models across\ndiverse model scales, architectures, and memorization definitions. As MLLMs are\nincreasingly deployed, understanding their memorization behavior has become\ncritical. Yet prior work has focused primarily on monolingual models, leaving\nmultilingual memorization underexplored, despite the inherently long-tailed\nnature of training corpora. We find that the prevailing assumption, that\nmemorization is highly correlated with training data availability, fails to\nfully explain memorization patterns in MLLMs. We hypothesize that treating\nlanguages in isolation - ignoring their similarities - obscures the true\npatterns of memorization. To address this, we propose a novel graph-based\ncorrelation metric that incorporates language similarity to analyze\ncross-lingual memorization. Our analysis reveals that among similar languages,\nthose with fewer training tokens tend to exhibit higher memorization, a trend\nthat only emerges when cross-lingual relationships are explicitly modeled.\nThese findings underscore the importance of a language-aware perspective in\nevaluating and mitigating memorization vulnerabilities in MLLMs. This also\nconstitutes empirical evidence that language similarity both explains\nMemorization in MLLMs and underpins Cross-lingual Transferability, with broad\nimplications for multilingual NLP.",
      "tldr_zh": "本文首次对多语言大语言模型(MLLMs)中的记忆化进行全面研究，分析95种语言及其在不同模型规模和架构下的表现。研究提出了一种基于图的关联度量，考虑语言相似性来探索跨语言记忆化模式，发现相似的语言中，训练数据较少的语言往往表现出更高的记忆化。结果强调了采用语言感知视角来评估和缓解MLLMs中的记忆化漏洞的重要性，并提供了经验证据，证明语言相似性既解释了记忆化现象，也支持了Cross-lingual Transferability，对多语言NLP领域具有广泛影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 14 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15722v1",
      "published_date": "2025-05-21 16:30:18 UTC",
      "updated_date": "2025-05-21 16:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:41:02.598159"
    },
    {
      "arxiv_id": "2505.15703v1",
      "title": "HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodong Mei",
        "Sheng Wang",
        "Jie Cheng",
        "Yingbing Chen",
        "Dan Xu"
      ],
      "abstract": "Motion forecasting represents a critical challenge in autonomous driving\nsystems, requiring accurate prediction of surrounding agents' future\ntrajectories. While existing approaches predict future motion states with the\nextracted scene context feature from historical agent trajectories and road\nlayouts, they suffer from the information degradation during the scene feature\nencoding. To address the limitation, we propose HAMF, a novel motion\nforecasting framework that learns future motion representations with the scene\ncontext encoding jointly, to coherently combine the scene understanding and\nfuture motion state prediction. We first embed the observed agent states and\nmap information into 1D token sequences, together with the target multi-modal\nfuture motion features as a set of learnable tokens. Then we design a unified\nAttention-based encoder, which synergistically combines self-attention and\ncross-attention mechanisms to model the scene context information and aggregate\nfuture motion features jointly. Complementing the encoder, we implement the\nMamba module in the decoding stage to further preserve the consistency and\ncorrelations among the learned future motion representations, to generate the\naccurate and diverse final trajectories. Extensive experiments on Argoverse 2\nbenchmark demonstrate that our hybrid Attention-Mamba model achieves\nstate-of-the-art motion forecasting performance with the simple and lightweight\narchitecture.",
      "tldr_zh": "该研究提出HAMF框架，一种混合Attention-Mamba模型，用于联合学习场景上下文理解和未来运动表示，以解决自动驾驶中运动预测的信息退化问题。具体而言，HAMF将观察到的代理状态、地图信息嵌入为1D token序列，并通过Attention-based encoder结合self-attention和cross-attention机制，同时建模场景信息和聚合未来运动特征；随后，在解码阶段使用Mamba模块保持运动表示的一致性与相关性，以生成准确多样的轨迹。实验在Argoverse 2基准上表明，该轻量级架构实现了最先进的运动预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In submission",
      "pdf_url": "http://arxiv.org/pdf/2505.15703v1",
      "published_date": "2025-05-21 16:16:52 UTC",
      "updated_date": "2025-05-21 16:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:41:13.983978"
    },
    {
      "arxiv_id": "2505.15694v1",
      "title": "A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Zhou",
        "Yulian Wu",
        "Francesco Orabona"
      ],
      "abstract": "In this paper, we theoretically investigate the effects of noisy labels in\noffline alignment, with a focus on the interplay between privacy and robustness\nagainst adversarial corruption. Specifically, under linear modeling\nassumptions, we present a unified analysis covering both reinforcement learning\nfrom human feedback (RLHF) and direct preference optimization (DPO) under\ndifferent privacy-corruption scenarios, such as Local differential\nprivacy-then-Corruption (LTC), where human preference labels are privatized\nbefore being corrupted by an adversary, and Corruption-then-Local differential\nprivacy (CTL), where labels are corrupted before privacy protection. Our\nanalysis leverages a reduction framework that reduces the offline alignment\nproblem under linear modeling assumptions to parameter estimation in logistic\nregression. This framework allows us to establish an interesting separation\nresult between LTC and CTL, demonstrating that LTC presents a greater challenge\nthan CTL in offline alignment, even under linear models. As important\nby-products, our findings also advance the state-of-the-art theoretical results\nin offline alignment under privacy-only or corruption-only scenarios.",
      "tldr_zh": "本文通过统一理论分析探讨了离线对齐（offline alignment）中噪声标签的影响，特别关注隐私和鲁棒性（对抗性破坏）的交互，涵盖了RLHF（reinforcement learning from human feedback）和DPO（direct preference optimization）。采用线性建模假设和一个reduction框架，将问题简化为logistic回归参数估计，分析了不同场景如LTC（Local differential privacy-then-Corruption）和CTL（Corruption-then-Local differential privacy），并证明LTC比CTL更具挑战性。作为重要成果，该研究还提升了仅隐私或仅破坏场景下的现有理论结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15694v1",
      "published_date": "2025-05-21 16:07:47 UTC",
      "updated_date": "2025-05-21 16:07:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:41:26.231986"
    },
    {
      "arxiv_id": "2505.15693v1",
      "title": "Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives",
      "title_zh": "针对Omega-Regular和Mean-Payoff目标的平均奖励强化学习",
      "authors": [
        "Milad Kazemi",
        "Mateo Perez",
        "Fabio Somenzi",
        "Sadegh Soudjani",
        "Ashutosh Trivedi",
        "Alvaro Velasquez"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) have renewed focus on the\ndesign of reward functions that shape agent behavior. Manually designing reward\nfunctions is tedious and error-prone. A principled alternative is to specify\nbehaviors in a formal language that can be automatically translated into\nrewards. Omega-regular languages are a natural choice for this purpose, given\ntheir established role in formal verification and synthesis. However, existing\nmethods using omega-regular specifications typically rely on discounted reward\nRL in episodic settings, with periodic resets. This setup misaligns with the\nsemantics of omega-regular specifications, which describe properties over\ninfinite behavior traces. In such cases, the average reward criterion and the\ncontinuing setting -- where the agent interacts with the environment over a\nsingle, uninterrupted lifetime -- are more appropriate.\n  To address the challenges of infinite-horizon, continuing tasks, we focus on\nabsolute liveness specifications -- a subclass of omega-regular languages that\ncannot be violated by any finite behavior prefix, making them well-suited to\nthe continuing setting. We present the first model-free RL framework that\ntranslates absolute liveness specifications to average-reward objectives. Our\napproach enables learning in communicating MDPs without episodic resetting. We\nalso introduce a reward structure for lexicographic multi-objective\noptimization, aiming to maximize an external average-reward objective among the\npolicies that also maximize the satisfaction probability of a given\nomega-regular specification. Our method guarantees convergence in unknown\ncommunicating MDPs and supports on-the-fly reductions that do not require full\nknowledge of the environment, thus enabling model-free RL. Empirical results\nshow our average-reward approach in continuing setting outperforms\ndiscount-based methods across benchmarks.",
      "tldr_zh": "该研究解决了强化学习（RL）中手动设计奖励函数的难题，通过使用 Omega-regular 语言自动生成奖励，以更好地处理无限行为轨迹。作者提出首个无模型 RL 框架，将 absolute liveness 规范（Omega-regular 的子类）转换为平均奖励目标，适用于 communicating MDPs 的 continuing 设置，而非传统的 episodic 重置环境。框架还引入了 lexicographic 多目标优化的奖励结构，优先确保规范满足概率最大化，同时最大化外部平均奖励目标，并在未知环境中保证收敛。实证结果显示，该方法在基准测试中优于基于折扣的 RL 方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 6 figures and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15693v1",
      "published_date": "2025-05-21 16:06:51 UTC",
      "updated_date": "2025-05-21 16:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:41:39.092590"
    },
    {
      "arxiv_id": "2505.15687v1",
      "title": "Discovering Pathology Rationale and Token Allocation for Efficient Multimodal Pathology Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Xu",
        "Cheng Jin",
        "Yihui Wang",
        "Ziyi Liu",
        "Hao Chen"
      ],
      "abstract": "Multimodal pathological image understanding has garnered widespread interest\ndue to its potential to improve diagnostic accuracy and enable personalized\ntreatment through integrated visual and textual data. However, existing methods\nexhibit limited reasoning capabilities, which hamper their ability to handle\ncomplex diagnostic scenarios. Additionally, the enormous size of pathological\nimages leads to severe computational burdens, further restricting their\npractical deployment. To address these limitations, we introduce a novel\nbilateral reinforcement learning framework comprising two synergistic branches.\nOne reinforcement branch enhances the reasoning capability by enabling the\nmodel to learn task-specific decision processes, i.e., pathology rationales,\ndirectly from labels without explicit reasoning supervision. While the other\nbranch dynamically allocates a tailored number of tokens to different images\nbased on both their visual content and task context, thereby optimizing\ncomputational efficiency. We apply our method to various pathological tasks\nsuch as visual question answering, cancer subtyping, and lesion detection.\nExtensive experiments show an average +41.7 absolute performance improvement\nwith 70.3% lower inference costs over the base models, achieving both reasoning\naccuracy and computational efficiency.",
      "tldr_zh": "本研究针对多模态病理图像理解的推理能力有限和计算负担重问题，提出了一种新型双边强化学习框架(bilateral reinforcement learning framework)。该框架包括两个协同分支：一个分支从标签直接学习任务特定的病理推理依据(pathology rationales)，无需显式监督；另一个分支根据图像视觉内容和任务上下文动态分配tokens，以提升计算效率。实验结果显示，在视觉问答、癌症亚型和病变检测等任务上，该方法比基线模型平均性能提升41.7%，同时推理成本降低70.3%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15687v1",
      "published_date": "2025-05-21 16:03:03 UTC",
      "updated_date": "2025-05-21 16:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:41:52.229099"
    },
    {
      "arxiv_id": "2505.15683v1",
      "title": "A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability",
      "title_zh": "翻译失败",
      "authors": [
        "Zishuai Zhang",
        "Hainan Zhang",
        "Jiaying Zheng",
        "Ziwei Wang",
        "Yongxin Tong",
        "Jin Dong",
        "Zhiming Zheng"
      ],
      "abstract": "Private data is typically larger and of higher quality than public data,\noffering great potential to improve LLM. However, its scattered distribution\nacross data silos and the high computational demands of LLMs limit their\ndeployment in federated environments. To address this, the transformer-based\nsplit learning model has emerged, offloading most model parameters to the\nserver while retaining only the embedding and output layers on clients to\nensure privacy. However, it still faces significant challenges in security,\nefficiency, and adaptability: 1) embedding gradients are vulnerable to attacks,\nleading to reverse engineering of private data; 2) the autoregressive nature of\nLLMs means that federated split learning can only train and infer sequentially,\ncausing high communication overhead; 3) fixed partition points lack\nadaptability to downstream tasks. In this paper, we introduce FL-LLaMA, a\nsecure, efficient, and adaptive federated split framework based on LLaMA2.\nFirst, we place some input and output blocks on the local client and inject\nGaussian noise into forward-pass hidden states, enabling secure end-to-end\npropagation. Second, we employ client-batch and server-hierarchical strategies\nto achieve parallel training, along with attention-mask compression and KV\ncache mechanisms to accelerate inference, reducing communication costs\neffectively. Third, we allow users to dynamically adjust the partition points\nfor input/output blocks based on specific task requirements and hardware\nlimitations. Experiments on NLU, summarization and conversational QA tasks show\nthat FL-LLaMA maintains performance comparable to centralized LLaMA2, and\nachieves up to 2x train speedups and 8x inference speedups. Further analysis of\nprivacy attacks and different partition points also demonstrates the\neffectiveness of FL-LLaMA in security and adaptability.",
      "tldr_zh": "该论文提出了一种名为 FL-LLaMA 的联邦分割框架，用于提升大型语言模型（LLMs）的安全、效率和适应性，以解决私有数据分布和计算需求问题。框架在 LLaMA2 基础上，将部分输入和输出块置于本地客户端，并注入 Gaussian noise 到 forward-pass hidden states，以保护 embedding gradients 免受攻击；同时采用 client-batch 和 server-hierarchical 策略实现并行训练，以及 attention-mask compression 和 KV cache 机制来减少通信开销和加速推理。实验结果显示，FL-LLaMA 在 NLU、总结和对话 QA 任务上与集中式 LLaMA2 性能相当，并实现高达 2 倍训练加速和 8 倍推理加速，同时在隐私攻击分析中证明了其安全性和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15683v1",
      "published_date": "2025-05-21 15:58:08 UTC",
      "updated_date": "2025-05-21 15:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:42:03.430369"
    },
    {
      "arxiv_id": "2505.15674v1",
      "title": "UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Yu",
        "Liang Lin",
        "Guibin Zhang",
        "Xinfeng Li",
        "Junfeng Fang",
        "Ningyu Zhang",
        "Kun Wang",
        "Yang Wang"
      ],
      "abstract": "Large language models require iterative updates to address challenges such as\nknowledge conflicts and outdated information (e.g., incorrect, private, or\nillegal contents). Machine unlearning provides a systematic methodology for\ntargeted knowledge removal from trained models, enabling elimination of\nsensitive information influences. However, mainstream fine-tuning-based\nunlearning methods often fail to balance unlearning efficacy and model ability,\nfrequently resulting in catastrophic model collapse under extensive knowledge\nremoval. Meanwhile, in-context unlearning, which relies solely on contextual\nprompting without modifying the model's intrinsic mechanisms, suffers from\nlimited generalizability and struggles to achieve true unlearning. In this\nwork, we introduce UniErase, a novel unlearning paradigm that employs learnable\nparametric suffix (unlearning token) to steer language models toward targeted\nforgetting behaviors. UniErase operates through two key phases: (I) an\noptimization stage that binds desired unlearning outputs to the model's\nautoregressive probability distribution via token optimization, followed by\n(II) a lightweight model editing phase that activates the learned token to\nprobabilistically induce specified forgetting objective. Serving as a new\nresearch direction for token learning to induce unlearning target, UniErase\nachieves state-of-the-art (SOTA) performance across batch, sequential, and\nprecise unlearning under fictitious and real-world knowledge settings.\nRemarkably, in terms of TOFU benchmark, UniErase, modifying only around 3.66%\nof the LLM parameters, outperforms previous forgetting SOTA baseline by around\n4.01 times for model ability with even better unlearning efficacy. Similarly,\nUniErase, maintaining more ability, also surpasses previous retaining SOTA by\n35.96% for unlearning efficacy, showing dual top-tier performances in current\nunlearing domain.",
      "tldr_zh": "这篇论文提出了 UniErase，一种新型的 unlearning 范式，使用 learnable parametric suffix（即 unlearning token）作为通用擦除原语，帮助语言模型实现针对性知识移除，同时避免传统方法导致的模型能力下降或崩溃。UniErase 通过两个关键阶段——优化阶段（绑定 unlearning 输出到模型的 autoregressive 概率分布）和轻量级模型编辑阶段（激活 token 以诱导指定遗忘）——来实现高效的遗忘行为。在 TOFU 基准测试中，UniErase 只修改约 3.66% 的模型参数，就在批量、顺序和精确 unlearning 任务上超越了现有 SOTA 基线，unlearning 效能提高约 4.01 倍，并同时提升了模型整体能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15674v1",
      "published_date": "2025-05-21 15:53:28 UTC",
      "updated_date": "2025-05-21 15:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:42:15.449943"
    },
    {
      "arxiv_id": "2505.15671v1",
      "title": "Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification",
      "title_zh": "增强 Monte Carlo Dropout 的性能以量化不确定性",
      "authors": [
        "Hamzeh Asgharnezhad",
        "Afshar Shamsi",
        "Roohallah Alizadehsani",
        "Arash Mohammadi",
        "Hamid Alinejad-Rokny"
      ],
      "abstract": "Knowing the uncertainty associated with the output of a deep neural network\nis of paramount importance in making trustworthy decisions, particularly in\nhigh-stakes fields like medical diagnosis and autonomous systems. Monte Carlo\nDropout (MCD) is a widely used method for uncertainty quantification, as it can\nbe easily integrated into various deep architectures. However, conventional MCD\noften struggles with providing well-calibrated uncertainty estimates. To\naddress this, we introduce innovative frameworks that enhances MCD by\nintegrating different search solutions namely Grey Wolf Optimizer (GWO),\nBayesian Optimization (BO), and Particle Swarm Optimization (PSO) as well as an\nuncertainty-aware loss function, thereby improving the reliability of\nuncertainty quantification. We conduct comprehensive experiments using\ndifferent backbones, namely DenseNet121, ResNet50, and VGG16, on various\ndatasets, including Cats vs. Dogs, Myocarditis, Wisconsin, and a synthetic\ndataset (Circles). Our proposed algorithm outperforms the MCD baseline by 2-3%\non average in terms of both conventional accuracy and uncertainty accuracy\nwhile achieving significantly better calibration. These results highlight the\npotential of our approach to enhance the trustworthiness of deep learning\nmodels in safety-critical applications.",
      "tldr_zh": "该研究针对 Monte Carlo Dropout (MCD) 在不确定性量化中的校准问题，提出了一种创新框架，通过整合 Grey Wolf Optimizer (GWO)、Bayesian Optimization (BO) 和 Particle Swarm Optimization (PSO) 等搜索算法，以及一个不确定性感知损失函数，来提升 MCD 的性能。实验在 DenseNet121、ResNet50 和 VGG16 等骨干网络上，使用 Cats vs. Dogs、Myocarditis、Wisconsin 和 Circles 数据集进行测试，结果显示该框架在传统准确性和不确定性准确性上比 MCD 基准提高了 2-3%，并显著改善了模型校准。总之，该方法增强了深度学习模型在医疗诊断和自动系统等高风险领域的可信度和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 5 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15671v1",
      "published_date": "2025-05-21 15:50:03 UTC",
      "updated_date": "2025-05-21 15:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:42:27.844969"
    },
    {
      "arxiv_id": "2505.15662v1",
      "title": "Neural Quantum Digital Twins for Optimizing Quantum Annealing",
      "title_zh": "神经量子数字孪生用于优化量子退火",
      "authors": [
        "Jianlong Lu",
        "Hanqiu Peng",
        "Ying Chen"
      ],
      "abstract": "Quantum annealers have shown potential in addressing certain combinatorial\noptimization problems, though their performance is often limited by scalability\nand errors rates. In this work, we propose a Neural Quantum Digital Twin (NQDT)\nframework that reconstructs the energy landscape of quantum many-body systems\nrelevant to quantum annealing. The digital twin models both ground and excited\nstate dynamics, enabling detailed simulation of the adiabatic evolution\nprocess. We benchmark NQDT on systems with known analytical solutions and\ndemonstrate that it accurately captures key quantum phenomena, including\nquantum criticality and phase transitions. Leveraging this framework, one can\nidentify optimal annealing schedules that minimize excitation-related errors.\nThese findings highlight the utility of neural network-based digital twins as a\ndiagnostic and optimization tool for improving the performance of quantum\nannealers.",
      "tldr_zh": "本文提出 Neural Quantum Digital Twin (NQDT) 框架，用于重建量子多体系统的能量景观，从而优化量子退火器的性能。NQDT 通过模拟基态和激发态动态，精确捕捉关键量子现象，如 quantum criticality 和 phase transitions，并在具有已知解析解的系统中进行基准测试。实验结果显示，该框架能识别最优 annealing schedules，以最小化激发相关的错误，提升量子退火器的可扩展性和准确性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "quant-ph",
      "comment": "20 pages, 11 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15662v1",
      "published_date": "2025-05-21 15:38:55 UTC",
      "updated_date": "2025-05-21 15:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:42:37.976498"
    },
    {
      "arxiv_id": "2505.15657v1",
      "title": "LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Yan",
        "Felix Mohr",
        "Tom Viering"
      ],
      "abstract": "Sample-wise learning curves plot performance versus training set size. They\nare useful for studying scaling laws and speeding up hyperparameter tuning and\nmodel selection. Learning curves are often assumed to be well-behaved: monotone\n(i.e. improving with more data) and convex. By constructing the Learning Curves\nDatabase 1.1 (LCDB 1.1), a large-scale database with high-resolution learning\ncurves, we show that learning curves are less often well-behaved than\npreviously thought. Using statistically rigorous methods, we observe\nsignificant ill-behavior in approximately 14% of the learning curves, almost\ntwice as much as in previous estimates. We also identify which learners are to\nblame and show that specific learners are more ill-behaved than others.\nAdditionally, we demonstrate that different feature scalings rarely resolve\nill-behavior. We evaluate the impact of ill-behavior on downstream tasks, such\nas learning curve fitting and model selection, and find it poses significant\nchallenges, underscoring the relevance and potential of LCDB 1.1 as a\nchallenging benchmark for future research.",
      "tldr_zh": "本研究构建了 LCDB 1.1，这是一个大规模、高分辨率的学习 curves 数据库，揭示了学习 curves 的行为比之前认为的更不规律。研究使用统计上严格的方法分析发现，大约 14% 的学习 curves 表现出显著的 ill-behavior，几乎是先前估计的两倍，且特定 learners 如某些算法更容易导致这个问题，而不同的 feature scalings 无法有效解决。论文还评估了 ill-behavior 对下游任务如 learning curve fitting 和 model selection 的负面影响，突显 LCDB 1.1 作为未来研究的挑战性基准的价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15657v1",
      "published_date": "2025-05-21 15:32:42 UTC",
      "updated_date": "2025-05-21 15:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:42:50.835356"
    },
    {
      "arxiv_id": "2505.15647v1",
      "title": "Second-Order Convergence in Private Stochastic Non-Convex Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Youming Tao",
        "Zuyuan Zhang",
        "Dongxiao Yu",
        "Xiuzhen Cheng",
        "Falko Dressler",
        "Di Wang"
      ],
      "abstract": "We investigate the problem of finding second-order stationary points (SOSP)\nin differentially private (DP) stochastic non-convex optimization. Existing\nmethods suffer from two key limitations: (i) inaccurate convergence error rate\ndue to overlooking gradient variance in the saddle point escape analysis, and\n(ii) dependence on auxiliary private model selection procedures for identifying\nDP-SOSP, which can significantly impair utility, particularly in distributed\nsettings. To address these issues, we propose a generic perturbed stochastic\ngradient descent (PSGD) framework built upon Gaussian noise injection and\ngeneral gradient oracles. A core innovation of our framework is using model\ndrift distance to determine whether PSGD escapes saddle points, ensuring\nconvergence to approximate local minima without relying on second-order\ninformation or additional DP-SOSP identification. By leveraging the adaptive\nDP-SPIDER estimator as a specific gradient oracle, we develop a new DP\nalgorithm that rectifies the convergence error rates reported in prior work. We\nfurther extend this algorithm to distributed learning with arbitrarily\nheterogeneous data, providing the first formal guarantees for finding DP-SOSP\nin such settings. Our analysis also highlights the detrimental impacts of\nprivate selection procedures in distributed learning under high-dimensional\nmodels, underscoring the practical benefits of our design. Numerical\nexperiments on real-world datasets validate the efficacy of our approach.",
      "tldr_zh": "本研究探讨了在差分隐私（DP）随机非凸优化中找到二阶静止点（SOSP）的挑战，指出现有方法忽略梯度方差导致收敛误差不准确，并依赖辅助私有模型选择程序影响实用性。作者提出一个通用的扰动随机梯度下降（PSGD）框架，利用Gaussian noise injection和通用梯度预言机，通过模型漂移距离判断逃离鞍点，确保收敛到近似局部最小值，而无需二阶信息或额外DP-SOSP识别。基于自适应DP-SPIDER估算器，该框架开发出新算法，修正了先前工作的收敛误差率，并首次扩展到分布式学习，支持异构数据并提供正式保证。实验结果在真实数据集上验证了方法的有效性，突显了避免私有选择程序的实际优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15647v1",
      "published_date": "2025-05-21 15:25:23 UTC",
      "updated_date": "2025-05-21 15:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:43:03.872537"
    },
    {
      "arxiv_id": "2505.15644v1",
      "title": "FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Sun",
        "Ziyi Zhang",
        "Zeren Luo",
        "Zeyang Sha",
        "Tianshuo Cong",
        "Zheng Li",
        "Shiwen Cui",
        "Weiqiang Wang",
        "Jiaheng Wei",
        "Xinlei He",
        "Qi Li",
        "Qian Wang"
      ],
      "abstract": "Fine-grained edited image detection of localized edits in images is crucial\nfor assessing content authenticity, especially given that modern diffusion\nmodels and image editing methods can produce highly realistic manipulations.\nHowever, this domain faces three challenges: (1) Binary classifiers yield only\na global real-or-fake label without providing localization; (2) Traditional\ncomputer vision methods often rely on costly pixel-level annotations; and (3)\nNo large-scale, high-quality dataset exists for modern image-editing detection\ntechniques. To address these gaps, we develop an automated data-generation\npipeline to create FragFake, the first dedicated benchmark dataset for edited\nimage detection, which includes high-quality images from diverse editing models\nand a wide variety of edited objects. Based on FragFake, we utilize Vision\nLanguage Models (VLMs) for the first time in the task of edited image\nclassification and edited region localization. Experimental results show that\nfine-tuned VLMs achieve higher average Object Precision across all datasets,\nsignificantly outperforming pretrained models. We further conduct ablation and\ntransferability analyses to evaluate the detectors across various\nconfigurations and editing scenarios. To the best of our knowledge, this work\nis the first to reformulate localized image edit detection as a vision-language\nunderstanding task, establishing a new paradigm for the field. We anticipate\nthat this work will establish a solid foundation to facilitate and inspire\nsubsequent research endeavors in the domain of multimodal content authenticity.",
      "tldr_zh": "该研究针对图像编辑检测的挑战，引入了FragFake数据集，这是首个专用于细粒度编辑图像检测的基准数据集，包含多样化编辑模型和高品质图像，以解决二元分类器缺乏定位、标注成本高和数据集缺失等问题。研究首次将Vision Language Models (VLMs)应用于编辑图像分类和编辑区域定位，通过微调VLMs实现了比预训练模型高出显著的平均Object Precision。实验结果显示，FragFake在各种编辑场景中表现出色，并通过消融和可转移性分析验证了其鲁棒性，为多模态内容真实性领域建立了新的视觉语言理解范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "14pages,15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15644v1",
      "published_date": "2025-05-21 15:22:45 UTC",
      "updated_date": "2025-05-21 15:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:43:16.401961"
    },
    {
      "arxiv_id": "2505.15633v1",
      "title": "Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions",
      "title_zh": "翻译失败",
      "authors": [
        "David Thulke",
        "Jakob Kemmler",
        "Christian Dugast",
        "Hermann Ney"
      ],
      "abstract": "Large language models that use retrieval augmented generation have the\npotential to unlock valuable knowledge for researchers, policymakers, and the\npublic by making long and technical climate-related documents more accessible.\nWhile this approach can help alleviate factual hallucinations by relying on\nretrieved passages as additional context, its effectiveness depends on whether\nthe model's output remains faithful to these passages. To address this, we\nexplore the automatic assessment of faithfulness of different models in this\nsetting. We then focus on ClimateGPT, a large language model specialised in\nclimate science, to examine which factors in its instruction fine-tuning impact\nthe model's faithfulness. By excluding unfaithful subsets of the model's\ntraining data, we develop ClimateGPT Faithful+, which achieves an improvement\nin faithfulness from 30% to 57% in supported atomic claims according to our\nautomatic metric.",
      "tldr_zh": "这篇论文探讨了如何提升大语言模型（Large Language Models）在气候问题上的忠实度，特别是通过检索增强生成（Retrieval Augmented Generation）来利用检索到的上下文，减少事实幻觉。研究者评估了不同模型的输出忠实性，并针对 ClimateGPT（一个专注于气候科学的模型）优化其指令微调过程。最终，通过排除训练数据中不忠实的子集，开发了 ClimateGPT Faithful+，使其支持的原子声明忠实度从 30% 提高到 57%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the ClimateNLP 2025 Workshop at ACL",
      "pdf_url": "http://arxiv.org/pdf/2505.15633v1",
      "published_date": "2025-05-21 15:17:38 UTC",
      "updated_date": "2025-05-21 15:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:43:27.906950"
    },
    {
      "arxiv_id": "2505.15612v1",
      "title": "Learn to Reason Efficiently with Adaptive Length-based Reward Shaping",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Liu",
        "Ruochen Zhou",
        "Yiyun Deng",
        "Yuzhen Huang",
        "Junteng Liu",
        "Yuntian Deng",
        "Yizhe Zhang",
        "Junxian He"
      ],
      "abstract": "Large Reasoning Models (LRMs) have shown remarkable capabilities in solving\ncomplex problems through reinforcement learning (RL), particularly by\ngenerating long reasoning traces. However, these extended outputs often exhibit\nsubstantial redundancy, which limits the efficiency of LRMs. In this paper, we\ninvestigate RL-based approaches to promote reasoning efficiency. Specifically,\nwe first present a unified framework that formulates various efficient\nreasoning methods through the lens of length-based reward shaping. Building on\nthis perspective, we propose a novel Length-bAsed StEp Reward shaping method\n(LASER), which employs a step function as the reward, controlled by a target\nlength. LASER surpasses previous methods, achieving a superior Pareto-optimal\nbalance between performance and efficiency. Next, we further extend LASER based\non two key intuitions: (1) The reasoning behavior of the model evolves during\ntraining, necessitating reward specifications that are also adaptive and\ndynamic; (2) Rather than uniformly encouraging shorter or longer chains of\nthought (CoT), we posit that length-based reward shaping should be\ndifficulty-aware i.e., it should penalize lengthy CoTs more for easy queries.\nThis approach is expected to facilitate a combination of fast and slow\nthinking, leading to a better overall tradeoff. The resulting method is termed\nLASER-D (Dynamic and Difficulty-aware). Experiments on\nDeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and\nDeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both\nreasoning performance and response length efficiency. For instance, LASER-D and\nits variant achieve a +6.1 improvement on AIME2024 while reducing token usage\nby 63%. Further analysis reveals our RL-based compression produces more concise\nreasoning patterns with less redundant \"self-reflections\". Resources are at\nhttps://github.com/hkust-nlp/Laser.",
      "tldr_zh": "这篇论文探讨了Large Reasoning Models (LRMs) 在强化学习 (RL) 中生成冗长推理链的问题，提出了一种统一的基于长度的奖励整形框架，以提升推理效率。具体地，作者引入了LASER (Length-bAsed StEp Reward shaping) 方法，使用步函数奖励并控制目标长度，实现性能与效率的Pareto最优平衡。随后，他们扩展为LASER-D (Dynamic and Difficulty-aware)，使其适应训练动态并根据查询难度调整奖励，促进快速和缓慢思考的结合。实验在DeepSeek-R1-Distill-Qwen系列模型上显示，LASER-D 显著提升了推理性能，例如在AIME2024上提高6.1分，同时减少63%的令牌使用，并生成更简洁的推理模式，减少冗余“self-reflections”。这项工作为高效推理提供了新途径，资源可从GitHub获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15612v1",
      "published_date": "2025-05-21 15:03:26 UTC",
      "updated_date": "2025-05-21 15:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:43:40.576174"
    },
    {
      "arxiv_id": "2505.15607v1",
      "title": "From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning",
      "title_zh": "从问题解决到教授问题解决：利用强化学习将 LLMs 与教学法对齐",
      "authors": [
        "David Dinucu-Jianu",
        "Jakub Macina",
        "Nico Daheim",
        "Ido Hakimi",
        "Iryna Gurevych",
        "Mrinmaya Sachan"
      ],
      "abstract": "Large language models (LLMs) can transform education, but their optimization\nfor direct question-answering often undermines effective pedagogy which\nrequires strategically withholding answers. To mitigate this, we propose an\nonline reinforcement learning (RL)-based alignment framework that can quickly\nadapt LLMs into effective tutors using simulated student-tutor interactions by\nemphasizing pedagogical quality and guided problem-solving over simply giving\naway answers. We use our method to train a 7B parameter tutor model without\nhuman annotations which reaches similar performance to larger proprietary\nmodels like LearnLM. We introduce a controllable reward weighting to balance\npedagogical support and student solving accuracy, allowing us to trace the\nPareto frontier between these two objectives. Our models better preserve\nreasoning capabilities than single-turn SFT baselines and can optionally\nenhance interpretability through thinking tags that expose the model's\ninstructional planning.",
      "tldr_zh": "本文提出一种基于在线强化学习 (RL) 的对齐框架，将大型语言模型 (LLMs) 优化为有效的教学导师，通过模拟学生-导师互动强调教学质量和引导问题解决，而不是直接给出答案，从而解决 LLMs 在教育中的局限性。该框架无需人类标注，即可训练出 7B 参数的导师模型，其性能可媲美更大专有模型如 LearnLM，并通过可控奖励权重平衡教学支持与学生准确性，绘制 Pareto 前沿。与单轮监督微调 (SFT) 基线相比，该模型更好地保留了推理能力，并通过思考标签增强可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "David Dinucu-Jianu and Jakub Macina contributed equally. Code\n  available: https://github.com/eth-lre/PedagogicalRL",
      "pdf_url": "http://arxiv.org/pdf/2505.15607v1",
      "published_date": "2025-05-21 15:00:07 UTC",
      "updated_date": "2025-05-21 15:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:43:52.624808"
    },
    {
      "arxiv_id": "2505.15596v1",
      "title": "Exploring LLM-Generated Feedback for Economics Essays: How Teaching Assistants Evaluate and Envision Its Use",
      "title_zh": "探索LLM生成的经济学论文反馈：教学助理如何评估和设想其使用",
      "authors": [
        "Xinyi Lu",
        "Aditya Mahesh",
        "Zejia Shen",
        "Mitchell Dudley",
        "Larissa Sano",
        "Xu Wang"
      ],
      "abstract": "This project examines the prospect of using AI-generated feedback as\nsuggestions to expedite and enhance human instructors' feedback provision. In\nparticular, we focus on understanding the teaching assistants' perspectives on\nthe quality of AI-generated feedback and how they may or may not utilize AI\nfeedback in their own workflows. We situate our work in a foundational college\nEconomics class, which has frequent short essay assignments. We developed an\nLLM-powered feedback engine that generates feedback on students' essays based\non grading rubrics used by the teaching assistants (TAs). To ensure that TAs\ncan meaningfully critique and engage with the AI feedback, we had them complete\ntheir regular grading jobs. For a randomly selected set of essays that they had\ngraded, we used our feedback engine to generate feedback and displayed the\nfeedback as in-text comments in a Word document. We then performed think-aloud\nstudies with 5 TAs over 20 1-hour sessions to have them evaluate the AI\nfeedback, contrast the AI feedback with their handwritten feedback, and share\nhow they envision using the AI feedback if they were offered as suggestions.\nThe study highlights the importance of providing detailed rubrics for AI to\ngenerate high-quality feedback for knowledge-intensive essays. TAs considered\nthat using AI feedback as suggestions during their grading could expedite\ngrading, enhance consistency, and improve overall feedback quality. We discuss\nthe importance of decomposing the feedback generation task into steps and\npresenting intermediate results, in order for TAs to use the AI feedback.",
      "tldr_zh": "这篇论文探讨了使用 LLM 生成的反馈作为建议，以帮助教学助理（TAs）更快地提供经济学作文反馈，并了解 TAs 对其质量的评价和潜在应用。研究在基础经济学课程中开发了一个基于评分 rubrics 的 LLM 反馈引擎，并通过 5 名 TAs 的 20 次 think-aloud 研究，让他们评估 AI 反馈、与自身反馈比较，并分享使用设想。结果显示，提供详细的 grading rubrics 是生成高质量反馈的关键，TAs 认为 AI 反馈能加速评分过程、提升一致性和整体质量。论文强调，将反馈生成任务分解成步骤并呈现中间结果，能使 TAs 更有效地整合 AI 反馈。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in AIED'2025: In Proceedings of the 26th\n  International Conference on Artificial Intelligence in Education. The system\n  prompt and example feedback can be found through\n  http://github.com/UM-Lifelong-Learning-Lab/AIED2025-Exploring-LLM-Generated-Feedback-for-Economics-Essay",
      "pdf_url": "http://arxiv.org/pdf/2505.15596v1",
      "published_date": "2025-05-21 14:50:30 UTC",
      "updated_date": "2025-05-21 14:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:44:04.657275"
    },
    {
      "arxiv_id": "2505.15594v1",
      "title": "Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off",
      "title_zh": "翻译失败",
      "authors": [
        "Yury Belousov",
        "Brian Pulfer",
        "Vitaliy Kinakh",
        "Slava Voloshynovskiy"
      ],
      "abstract": "While foundation models demonstrate impressive performance across various\ntasks, they remain vulnerable to adversarial inputs. Current research explores\nvarious approaches to enhance model robustness, with Diffusion Denoised\nSmoothing emerging as a particularly promising technique. This method employs a\npretrained diffusion model to preprocess inputs before model inference. Yet,\nits effectiveness remains largely unexplored beyond classification. We aim to\naddress this gap by analyzing three datasets with four distinct downstream\ntasks under three different adversarial attack algorithms. Our findings reveal\nthat while foundation models maintain resilience against conventional\ntransformations, applying high-noise diffusion denoising to clean images\nwithout any distortions significantly degrades performance by as high as 57%.\nLow-noise diffusion settings preserve performance but fail to provide adequate\nprotection across all attack types. Moreover, we introduce a novel attack\nstrategy specifically targeting the diffusion process itself, capable of\ncircumventing defenses in the low-noise regime. Our results suggest that the\ntrade-off between adversarial robustness and performance remains a challenge to\nbe addressed.",
      "tldr_zh": "该研究评估了Diffusion Denoised Smoothing技术在提升基础模型对抗鲁棒性方面的效果，超越了传统的分类任务，涉及三个数据集、四个下游任务和三种对抗攻击算法。结果显示，高噪声扩散去噪会对干净图像的性能造成高达57%的显著下降，而低噪声设置虽能保留部分性能，但对各种攻击类型提供的不充分保护。作者还引入了一种针对扩散过程的新攻击策略，能在低噪声环境下绕过防御，强调了在对抗鲁棒性和实用性能之间仍需解决的权衡挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at the 33rd European Signal Processing Conference\n  (EUSIPCO 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.15594v1",
      "published_date": "2025-05-21 14:49:24 UTC",
      "updated_date": "2025-05-21 14:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:44:14.850203"
    },
    {
      "arxiv_id": "2505.15589v1",
      "title": "World Models as Reference Trajectories for Rapid Motor Adaptation",
      "title_zh": "世界模型作为参考轨迹用于快速运动适应",
      "authors": [
        "Carlos Stein Brito",
        "Daniel McNamee"
      ],
      "abstract": "Deploying learned control policies in real-world environments poses a\nfundamental challenge. When system dynamics change unexpectedly, performance\ndegrades until models are retrained on new data. We introduce Reflexive World\nModels (RWM), a dual control framework that uses world model predictions as\nimplicit reference trajectories for rapid adaptation. Our method separates the\ncontrol problem into long-term reward maximization through reinforcement\nlearning and robust motor execution through rapid latent control. This dual\narchitecture achieves significantly faster adaptation with low online\ncomputational cost compared to model-based RL baselines, while maintaining\nnear-optimal performance. The approach combines the benefits of flexible policy\nlearning through reinforcement learning with rapid error correction\ncapabilities, providing a principled approach to maintaining performance in\nhigh-dimensional continuous control tasks under varying dynamics.",
      "tldr_zh": "本研究提出Reflexive World Models (RWM)，一个双重控制框架，将世界模型预测作为隐式参考轨迹，用于实现快速电机适应。该框架将控制问题分为通过reinforcement learning的长期奖励最大化和快速潜在控制的鲁棒运动执行，从而在系统动态变化时显著降低在线计算成本。与基于模型的RL基线相比，RWM实现了更快适应速度并保持近似最优性能，尤其适用于高维连续控制任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15589v1",
      "published_date": "2025-05-21 14:46:41 UTC",
      "updated_date": "2025-05-21 14:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:44:28.410962"
    },
    {
      "arxiv_id": "2505.15581v1",
      "title": "UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Hua Li",
        "Shijie Lian",
        "Zhiyuan Li",
        "Runmin Cong",
        "Sam Kwong"
      ],
      "abstract": "With recent breakthroughs in large-scale modeling, the Segment Anything Model\n(SAM) has demonstrated significant potential in a variety of visual\napplications. However, due to the lack of underwater domain expertise, SAM and\nits variants face performance limitations in end-to-end underwater instance\nsegmentation tasks, while their higher computational requirements further\nhinder their application in underwater scenarios. To address this challenge, we\npropose a large-scale underwater instance segmentation dataset, UIIS10K, which\nincludes 10,048 images with pixel-level annotations for 10 categories. Then, we\nintroduce UWSAM, an efficient model designed for automatic and accurate\nsegmentation of underwater instances. UWSAM efficiently distills knowledge from\nthe SAM ViT-Huge image encoder into the smaller ViT-Small image encoder via the\nMask GAT-based Underwater Knowledge Distillation (MG-UKD) method for effective\nvisual representation learning. Furthermore, we design an End-to-end Underwater\nPrompt Generator (EUPG) for UWSAM, which automatically generates underwater\nprompts instead of explicitly providing foreground points or boxes as prompts,\nthus enabling the network to locate underwater instances accurately for\nefficient segmentation. Comprehensive experimental results show that our model\nis effective, achieving significant performance improvements over\nstate-of-the-art methods on multiple underwater instance datasets. Datasets and\ncodes are available at https://github.com/LiamLian0727/UIIS10K.",
      "tldr_zh": "本研究针对 Segment Anything Model (SAM) 在水下实例分割任务中的性能限制（如缺乏水下领域知识和高计算需求），提出一个大规模数据集 UIIS10K，包含 10,048 张图像和 10 个类别的像素级标注，以支持相关研究。同时，引入 UWSAM 模型，通过 Mask GAT-based Underwater Knowledge Distillation (MG-UKD) 方法将 SAM 的 ViT-Huge 图像编码器知识蒸馏到更小的 ViT-Small 编码器，实现高效的视觉表示学习。UWSAM 还设计了 End-to-end Underwater Prompt Generator (EUPG)，自动生成水下提示以精确定位实例，从而提升分割准确性。实验结果显示，UWSAM 在多个水下实例数据集上显著优于现有方法，数据集和代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15581v1",
      "published_date": "2025-05-21 14:36:01 UTC",
      "updated_date": "2025-05-21 14:36:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:44:41.259848"
    },
    {
      "arxiv_id": "2505.15572v1",
      "title": "Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Wangyang Ying",
        "Haoyue Bai",
        "Nanxu Gong",
        "Xinyuan Wang",
        "Sixun Dong",
        "Haifeng Chen",
        "Yanjie Fu"
      ],
      "abstract": "The data-to-equation (Data2Eqn) task aims to discover interpretable\nmathematical equations that map observed values to labels, offering physical\ninsights and broad applicability across academic and industrial domains.\nGenetic programming and traditional deep learning-based approaches suffer from\nsearch inefficiency and poor generalization on small task-specific datasets.\nFoundation models showed promise in this area, but existing approaches suffer\nfrom: 1) They are pretrained on general-purpose data distributions, making them\nless effective for domain-specific tasks; and 2) their training objectives\nfocus on token-level alignment, overlooking mathematical semantics, which can\nlead to inaccurate equations. To address these issues, we aim to enhance the\ndomain adaptability of foundation models for Data2Eqn tasks. In this work, we\npropose a reinforcement learning-based finetuning framework that directly\noptimizes the generation policy of a pretrained model through reward signals\nderived from downstream numerical fitness. Our method allows the model to adapt\nto specific and complex data distributions and generate mathematically\nmeaningful equations. Extensive experiments demonstrate that our approach\nimproves both the accuracy and robustness of equation generation under complex\ndistributions.",
      "tldr_zh": "本文针对Data-to-Equation (Data2Eqn) 任务，提出了一种基于reinforcement learning的微调框架，以桥接基础模型在领域特定数据集上的适应性差距。该框架通过下游数值fitness派生的奖励信号，直接优化预训练模型的生成策略，确保生成的方程更具数学语义和准确性。与传统方法相比，该方法显著提高了方程生成的准确性和鲁棒性，尤其在复杂数据分布下。实验结果显示，该框架在广泛测试中表现出色，为学术和工业应用提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15572v1",
      "published_date": "2025-05-21 14:25:41 UTC",
      "updated_date": "2025-05-21 14:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:44:53.137252"
    },
    {
      "arxiv_id": "2505.15559v1",
      "title": "Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes",
      "title_zh": "Moonbeam：一个",
      "authors": [
        "Zixun Guo",
        "Simon Dixon"
      ],
      "abstract": "Moonbeam is a transformer-based foundation model for symbolic music,\npretrained on a large and diverse collection of MIDI data totaling 81.6K hours\nof music and 18 billion tokens. Moonbeam incorporates music-domain inductive\nbiases by capturing both absolute and relative musical attributes through the\nintroduction of a novel domain-knowledge-inspired tokenization method and\nMultidimensional Relative Attention (MRA), which captures relative music\ninformation without additional trainable parameters. Leveraging the pretrained\nMoonbeam, we propose 2 finetuning architectures with full anticipatory\ncapabilities, targeting 2 categories of downstream tasks: symbolic music\nunderstanding and conditional music generation (including music infilling). Our\nmodel outperforms other large-scale pretrained music models in most cases in\nterms of accuracy and F1 score across 3 downstream music classification tasks\non 4 datasets. Moreover, our finetuned conditional music generation model\noutperforms a strong transformer baseline with a REMI-like tokenizer. We\nopen-source the code, pretrained model, and generated samples on Github.",
      "tldr_zh": "这篇论文介绍了 Moonbeam，一种基于 Transformer 的 MIDI 基础模型，它通过新型的领域知识驱动 tokenization 方法和 Multidimensional Relative Attention (MRA) 捕获绝对和相对音乐属性，并在总计 81.6K 小时 MIDI 数据上预训练。模型提出两种微调架构，支持符号化音乐理解和条件音乐生成任务（如音乐 infilling），并在 3 个下游分类任务的 4 个数据集上，优于其他大型预训练模型，在准确率和 F1 分数方面表现出色。相比使用 REMI-like tokenizer 的 Transformer 基线，Moonbeam 在生成任务上也表现出优越性能，并开源了代码、预训练模型和生成样本。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15559v1",
      "published_date": "2025-05-21 14:17:25 UTC",
      "updated_date": "2025-05-21 14:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:45:05.290521"
    },
    {
      "arxiv_id": "2505.15558v1",
      "title": "Robo-DM: Data Management For Large Robot Datasets",
      "title_zh": "Robo-DM：大型机器人数据集的数据管理",
      "authors": [
        "Kaiyuan Chen",
        "Letian Fu",
        "David Huang",
        "Yanxiang Zhang",
        "Lawrence Yunliang Chen",
        "Huang Huang",
        "Kush Hari",
        "Ashwin Balakrishna",
        "Ted Xiao",
        "Pannag R Sanketi",
        "John Kubiatowicz",
        "Ken Goldberg"
      ],
      "abstract": "Recent results suggest that very large datasets of teleoperated robot\ndemonstrations can be used to train transformer-based models that have the\npotential to generalize to new scenes, robots, and tasks. However, curating,\ndistributing, and loading large datasets of robot trajectories, which typically\nconsist of video, textual, and numerical modalities - including streams from\nmultiple cameras - remains challenging. We propose Robo-DM, an efficient\nopen-source cloud-based data management toolkit for collecting, sharing, and\nlearning with robot data. With Robo-DM, robot datasets are stored in a\nself-contained format with Extensible Binary Meta Language (EBML). Robo-DM can\nsignificantly reduce the size of robot trajectory data, transfer costs, and\ndata load time during training. Compared to the RLDS format used in OXE\ndatasets, Robo-DM's compression saves space by up to 70x (lossy) and 3.5x\n(lossless). Robo-DM also accelerates data retrieval by load-balancing video\ndecoding with memory-mapped decoding caches. Compared to LeRobot, a framework\nthat also uses lossy video compression, Robo-DM is up to 50x faster when\ndecoding sequentially. We physically evaluate a model trained by Robo-DM with\nlossy compression, a pick-and-place task, and In-Context Robot Transformer.\nRobo-DM uses 75x compression of the original dataset and does not suffer\nreduction in downstream task accuracy.",
      "tldr_zh": "该论文提出Robo-DM，一种高效的开源云端数据管理工具包，用于处理大型机器人数据集，包括视频、文本和数字模态的数据。Robo-DM采用Extensible Binary Meta Language (EBML)格式存储数据，实现高达70倍的有损压缩和3.5倍的无损压缩，同时通过内存映射解码缓存加速数据加载，比LeRobot框架快50倍。实验结果显示，使用Robo-DM的75倍压缩训练Transformer模型后，在pick-and-place任务和In-Context Robot Transformer上，任务准确率保持不变，为机器人数据集的收集、共享和学习提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Best paper finalist of IEEE ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15558v1",
      "published_date": "2025-05-21 14:17:06 UTC",
      "updated_date": "2025-05-21 14:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:45:17.565389"
    },
    {
      "arxiv_id": "2505.15554v1",
      "title": "DayDreamer at CQs-Gen 2025: Generating Critical Questions through Argument Scheme Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Wendi Zhou",
        "Ameer Saadat-Yazdi",
        "Nadin Kökciyan"
      ],
      "abstract": "Critical questions are essential resources to provoke critical thinking when\nencountering an argumentative text. We present our system for the Critical\nQuestions Generation (CQs-Gen) Shared Task at ArgMining 2025. Our approach\nleverages large language models (LLMs) with chain-of-thought prompting to\ngenerate critical questions guided by Walton's argumentation schemes. For each\ninput intervention, we conversationally prompt LLMs to instantiate the\ncorresponding argument scheme template to first obtain structured arguments,\nand then generate relevant critical questions. Following this, we rank all the\navailable critical questions by prompting LLMs to select the top 3 most helpful\nquestions based on the original intervention text. This combination of\nstructured argumentation theory and step-by-step reasoning enables the\ngeneration of contextually relevant and diverse critical questions. Our\npipeline achieves competitive performance in the final test set, showing its\npotential to foster critical thinking given argumentative text and detect\nmissing or uninformed claims. Code available at\n\\href{https://git.ecdf.ed.ac.uk/s2236454/DayDreamer-CQs-Gen}{DayDreamer}.",
      "tldr_zh": "本文提出DayDreamer系统，针对ArgMining 2025的CQs-Gen共享任务，通过参数方案完成生成批判性问题，以促进批判性思维。系统利用大型语言模型(LLMs)结合chain-of-thought prompting和Walton's argumentation schemes，先通过对话式提示实例化参数模板生成结构化参数，然后基于原文本排名并选择前3个最相关问题。该方法实现了上下文相关和多样的关键问题生成，并在测试集上取得竞争性性能，有助于检测缺失声明和提升论证分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ArgMining 2025 CQs-Gen shared task",
      "pdf_url": "http://arxiv.org/pdf/2505.15554v1",
      "published_date": "2025-05-21 14:15:49 UTC",
      "updated_date": "2025-05-21 14:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:45:29.013158"
    },
    {
      "arxiv_id": "2505.15553v2",
      "title": "Social Bias in Popular Question-Answering Benchmarks",
      "title_zh": "流行问答基准中的社会偏见",
      "authors": [
        "Angelie Kraft",
        "Judith Simon",
        "Sonja Schimmler"
      ],
      "abstract": "Question-answering (QA) and reading comprehension (RC) benchmarks are\nessential for assessing the capabilities of large language models (LLMs) in\nretrieving and reproducing knowledge. However, we demonstrate that popular QA\nand RC benchmarks are biased and do not cover questions about different\ndemographics or regions in a representative way, potentially due to a lack of\ndiversity of those involved in their creation. We perform a qualitative content\nanalysis of 30 benchmark papers and a quantitative analysis of 20 respective\nbenchmark datasets to learn (1) who is involved in the benchmark creation, (2)\nhow social bias is addressed or prevented, and (3) whether the demographics of\nthe creators and annotators correspond to particular biases in the content.\nMost analyzed benchmark papers provided insufficient information regarding the\nstakeholders involved in benchmark creation, particularly the annotators.\nNotably, just one of the benchmark papers explicitly reported measures taken to\naddress social representation issues. Moreover, the data analysis revealed\ngender, religion, and geographic biases across a wide range of encyclopedic,\ncommonsense, and scholarly benchmarks. More transparent and bias-aware QA and\nRC benchmark creation practices are needed to facilitate better scrutiny and\nincentivize the development of fairer LLMs.",
      "tldr_zh": "这篇论文揭示了流行问答(QA)和阅读理解(RC)基准测试中存在的社会偏见，这些基准测试在评估大型语言模型(LLMs)能力时未能代表性地覆盖不同人口统计或区域的问题，可能源于创建者缺乏多样性。研究通过对30篇基准论文的定性内容分析和20个数据集的定量分析，考察了参与者身份、偏见处理措施，以及创建者 demographics 与内容偏见的相关性，结果显示大多数论文未提供足够信息，且存在性别、宗教和地理偏见。作者强调，需要更透明和注重偏见的基准创建实践，以促进更好的审查和开发更公平的 LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15553v2",
      "published_date": "2025-05-21 14:14:47 UTC",
      "updated_date": "2025-05-22 09:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:45:41.486942"
    },
    {
      "arxiv_id": "2505.15547v1",
      "title": "Oversmoothing, \"Oversquashing\", Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian Arnaiz-Rodriguez",
        "Federico Errica"
      ],
      "abstract": "After a renaissance phase in which researchers revisited the message-passing\nparadigm through the lens of deep learning, the graph machine learning\ncommunity shifted its attention towards a deeper and practical understanding of\nmessage-passing's benefits and limitations. In this position paper, we notice\nhow the fast pace of progress around the topics of oversmoothing and\noversquashing, the homophily-heterophily dichotomy, and long-range tasks, came\nwith the consolidation of commonly accepted beliefs and assumptions that are\nnot always true nor easy to distinguish from each other. We argue that this has\nled to ambiguities around the investigated problems, preventing researchers\nfrom focusing on and addressing precise research questions while causing a good\namount of misunderstandings. Our contribution wants to make such common beliefs\nexplicit and encourage critical thinking around these topics, supported by\nsimple but noteworthy counterexamples. The hope is to clarify the distinction\nbetween the different issues and promote separate but intertwined research\ndirections to address them.",
      "tldr_zh": "这篇论文审视了图机器学习(Graph Machine Learning)中的常见信念，包括oversmoothing、\"oversquashing\"、heterophily与long-range任务等，指出这些信念在快速进展中被过度巩固，但往往不准确或难以区分。作者通过位置论文的形式，提供简单却有意义的反例，旨在澄清这些问题之间的模糊性，并鼓励批判性思考以避免误解。最终，该研究推动了针对这些独立但相互关联问题的精确研究方向，促进更深入的图机器学习发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15547v1",
      "published_date": "2025-05-21 14:11:59 UTC",
      "updated_date": "2025-05-21 14:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:45:53.657046"
    },
    {
      "arxiv_id": "2505.15524v1",
      "title": "Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Gao",
        "Kaiyang Wan",
        "Wei Liu",
        "Chenxi Wang",
        "Zirui Song",
        "Zixiang Xu",
        "Yanbo Wang",
        "Veselin Stoyanov",
        "Xiuying Chen"
      ],
      "abstract": "Bias in Large Language Models (LLMs) significantly undermines their\nreliability and fairness. We focus on a common form of bias: when two reference\nconcepts in the model's concept space, such as sentiment polarities (e.g.,\n\"positive\" and \"negative\"), are asymmetrically correlated with a third, target\nconcept, such as a reviewing aspect, the model exhibits unintended bias. For\ninstance, the understanding of \"food\" should not skew toward any particular\nsentiment. Existing bias evaluation methods assess behavioral differences of\nLLMs by constructing labeled data for different social groups and measuring\nmodel responses across them, a process that requires substantial human effort\nand captures only a limited set of social concepts. To overcome these\nlimitations, we propose BiasLens, a test-set-free bias analysis framework based\non the structure of the model's vector space. BiasLens combines Concept\nActivation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract\ninterpretable concept representations, and quantifies bias by measuring the\nvariation in representational similarity between the target concept and each of\nthe reference concepts. Even without labeled data, BiasLens shows strong\nagreement with traditional bias evaluation metrics (Spearman correlation r >\n0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect\nusing existing methods. For example, in simulated clinical scenarios, a\npatient's insurance status can cause the LLM to produce biased diagnostic\nassessments. Overall, BiasLens offers a scalable, interpretable, and efficient\nparadigm for bias discovery, paving the way for improving fairness and\ntransparency in LLMs.",
      "tldr_zh": "这篇论文从概念表示视角探讨大型语言模型 (LLMs) 中的偏见问题，提出 BiasLens 框架，以克服传统方法依赖手动测试集的局限。BiasLens 结合 Concept Activation Vectors (CAVs) 和 Sparse Autoencoders (SAEs) 提取可解释的概念表示，并通过测量目标概念与参考概念的表示相似性变化来量化偏见。实验结果显示，BiasLens 无需标签数据即可与传统评估指标高度一致 (Spearman 相关系数 r > 0.85)，并能发现现有方法难以检测的偏见，例如临床场景中患者保险状态对诊断的影响。该框架为提升 LLMs 的公平性和透明度提供了可扩展、高效的偏见发现范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15524v1",
      "published_date": "2025-05-21 13:50:23 UTC",
      "updated_date": "2025-05-21 13:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:46:07.397071"
    },
    {
      "arxiv_id": "2505.15517v1",
      "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Chen",
        "Shuangyu Xie",
        "Zehan Ma",
        "Ken Goldberg"
      ],
      "abstract": "Vision-Language Models (VLMs) acquire real-world knowledge and general\nreasoning ability through Internet-scale image-text corpora. They can augment\nrobotic systems with scene understanding and task planning, and assist\nvisuomotor policies that are trained on robot trajectory data. We explore the\nreverse paradigm - using rich, real, multi-modal robot trajectory data to\nenhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual\nQuestion Answering (VQA) dataset generation framework for VLMs. Given a human\ntele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual\nand non-descriptive sensory modalities, such as end-effector pose, gripper\naperture, and force sensing. Based on these modalities, it segments the robot\ntrajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses\nscene and interaction understanding to identify 3D properties of the robot,\ntask goal, and the target object. The properties are used to generate\nrepresentative VQA queries - images with textural multiple-choice questions -\nbased on spatial, goal-conditioned, and interaction reasoning question\ntemplates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710\nquestions covering 463 distinct scenes and 3,396 robotic manipulation tasks\nfrom 176k real robot trajectories. Results suggest that Robo2VLM-1 can\nbenchmark and improve VLM capabilities in spatial and interaction reasoning.",
      "tldr_zh": "本研究提出Robo2VLM框架，利用大规模真实机器人操作数据集来增强和评估视觉语言模型(VLMs)。框架从机器人轨迹（如末端执行器姿势、抓取器开口和力传感）中提取地面真实数据，将轨迹分割成操作阶段，并基于空间、目标条件和交互推理模板生成视觉问答(VQA)查询。研究创建了Robo2VLM-1数据集，包含68.4万多个问题，覆盖463个场景和3396个机器人任务。结果表明，该数据集可有效基准测试和提升VLMs在空间和交互推理方面的能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15517v1",
      "published_date": "2025-05-21 13:42:52 UTC",
      "updated_date": "2025-05-21 13:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:46:17.279011"
    },
    {
      "arxiv_id": "2505.15516v1",
      "title": "Explainable embeddings with Distance Explainer",
      "title_zh": "使用 Distance Explainer 的可解释嵌入",
      "authors": [
        "Christiaan Meijer",
        "E. G. Patrick Bos"
      ],
      "abstract": "While eXplainable AI (XAI) has advanced significantly, few methods address\ninterpretability in embedded vector spaces where dimensions represent complex\nabstractions. We introduce Distance Explainer, a novel method for generating\nlocal, post-hoc explanations of embedded spaces in machine learning models. Our\napproach adapts saliency-based techniques from RISE to explain the distance\nbetween two embedded data points by assigning attribution values through\nselective masking and distance-ranked mask filtering. We evaluate Distance\nExplainer on cross-modal embeddings (image-image and image-caption pairs) using\nestablished XAI metrics including Faithfulness, Sensitivity/Robustness, and\nRandomization. Experiments with ImageNet and CLIP models demonstrate that our\nmethod effectively identifies features contributing to similarity or\ndissimilarity between embedded data points while maintaining high robustness\nand consistency. We also explore how parameter tuning, particularly mask\nquantity and selection strategy, affects explanation quality. This work\naddresses a critical gap in XAI research and enhances transparency and\ntrustworthiness in deep learning applications utilizing embedded spaces.",
      "tldr_zh": "该研究引入了 Distance Explainer，一种新型后验解释方法，用于提升嵌入向量空间的可解释性，通过适应 RISE 的显著性技术来为两个数据点之间的距离分配归因值，并采用选择性掩码和基于距离的掩码过滤。实验在 ImageNet 和 CLIP 模型上评估了跨模态嵌入（如图像-图像和图像-标题对），结果显示该方法有效识别相似或不相似性的关键特征，并在 Faithfulness、Sensitivity/Robustness 和 Randomization 等指标上表现出高鲁棒性和一致性。作者还探讨了参数调整（如掩码数量和选择策略）对解释质量的影响，从而填补了 XAI 研究中的空白，并提升了利用嵌入空间的深度学习应用的透明度和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "68T99",
        "I.2.m"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 19 figures. Submitted to JMLR. Method implementation:\n  https://research-software-directory.org/software/distance-explainer",
      "pdf_url": "http://arxiv.org/pdf/2505.15516v1",
      "published_date": "2025-05-21 13:42:28 UTC",
      "updated_date": "2025-05-21 13:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:46:30.757537"
    },
    {
      "arxiv_id": "2505.15514v1",
      "title": "AM-PPO: (Advantage) Alpha-Modulation with Proximal Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Sane"
      ],
      "abstract": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning\nalgorithm that heavily relies on accurate advantage estimates for stable and\nefficient training. However, raw advantage signals can exhibit significant\nvariance, noise, and scale-related issues, impeding optimal learning\nperformance. To address this challenge, we introduce Advantage Modulation PPO\n(AM-PPO), a novel enhancement of PPO that adaptively modulates advantage\nestimates using a dynamic, non-linear scaling mechanism. This adaptive\nmodulation employs an alpha controller that dynamically adjusts the scaling\nfactor based on evolving statistical properties of the advantage signals, such\nas their norm, variance, and a predefined target saturation level. By\nincorporating a tanh-based gating function driven by these adaptively scaled\nadvantages, AM-PPO reshapes the advantage signals to stabilize gradient updates\nand improve the conditioning of the policy gradient landscape. Crucially, this\nmodulation also influences value function training by providing consistent and\nadaptively conditioned learning targets. Empirical evaluations across standard\ncontinuous control benchmarks demonstrate that AM-PPO achieves superior reward\ntrajectories, exhibits sustained learning progression, and significantly\nreduces the clipping required by adaptive optimizers. These findings underscore\nthe potential of advantage modulation as a broadly applicable technique for\nenhancing reinforcement learning optimization.",
      "tldr_zh": "该研究针对 Proximal Policy Optimization (PPO) 算法中优势估计的方差、噪声和规模问题，提出了一种新型增强版本 AM-PPO，利用动态非线性缩放机制来调节优势信号。AM-PPO 引入 alpha 控制器，根据优势信号的统计属性（如范数、方差和目标饱和水平）实时调整缩放因子，并通过 tanh-based gating 函数重塑信号，以稳定梯度更新并优化策略梯度景观，同时改善价值函数训练。在标准连续控制基准测试中，AM-PPO 实现了更高的奖励轨迹、更持续的学习进展，并显著减少自适应优化器的剪切操作，展示了优势调节作为强化学习优化技术的广泛潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 4 Tables, 9 Figures, 11 equations",
      "pdf_url": "http://arxiv.org/pdf/2505.15514v1",
      "published_date": "2025-05-21 13:38:45 UTC",
      "updated_date": "2025-05-21 13:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:46:43.046402"
    },
    {
      "arxiv_id": "2505.15507v1",
      "title": "Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning",
      "title_zh": "方向性非交换单子结构用于机器学习中的组合嵌入",
      "authors": [
        "Mahesh Godavarti"
      ],
      "abstract": "We introduce a new algebraic structure for multi-dimensional compositional\nembeddings, built on directional non-commutative monoidal operators. The core\ncontribution of this work is this novel framework, which exhibits appealing\ntheoretical properties (associativity along each dimension and an interchange\nlaw ensuring global consistency) while remaining compatible with modern machine\nlearning architectures. Our construction defines a distinct composition\noperator circ_i for each axis i, ensuring associative combination along each\naxis without imposing global commutativity. Importantly, all axis-specific\noperators commute with one another, enforcing a global interchange law that\nenables consistent crossaxis compositions. This is, to our knowledge, the first\napproach that provides a common foundation that generalizes classical\nsequence-modeling paradigms (e.g., structured state-space models (SSMs) and\ntransformer self-attention) to a unified multi-dimensional framework. For\nexample, specific one-dimensional instances of our framework can recover the\nfamiliar affine transformation algebra, vanilla self-attention, and the\nSSM-style recurrence. The higher-dimensional generalizations naturally support\nrecursive, structure-aware operations in embedding spaces. We outline several\npotential applications unlocked by this structure-including structured\npositional encodings in Transformers, directional image embeddings, and\nsymbolic modeling of sequences or grids-indicating that it could inform future\ndeep learning model designs. We formally establish the algebraic properties of\nour framework and discuss efficient implementations. Finally, as our focus is\ntheoretical, we include no experiments here and defer empirical validation to\nfuture work, which we plan to undertake.",
      "tldr_zh": "本研究引入了一种基于directional non-commutative monoidal operators的新代数结构，用于机器学习中的多维组合嵌入。该框架的核心贡献是定义每个轴i的独特组合算子circ_i，确保每个维度上的associativity，同时通过轴间算子的互换性(interchange law)实现全局一致性，而不强加全局交换性。该结构首次将经典序列建模范式，如structured state-space models (SSMs)和transformer self-attention，泛化为统一的 multi-dimensional 框架，支持递归和结构感知的操作。潜在应用包括Transformer的结构化位置编码、directional image embeddings以及序列或网格的符号建模，论文形式化了其代数属性并讨论了高效实现，但未包含实验，计划未来进行实证验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "20-XX, 08A02",
        "F.4.1; I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages submitted to NeurIPS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15507v1",
      "published_date": "2025-05-21 13:27:14 UTC",
      "updated_date": "2025-05-21 13:27:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:46:54.032100"
    },
    {
      "arxiv_id": "2505.15504v1",
      "title": "Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification",
      "title_zh": "超越线性：用于少样本全滑玻图像分类的挤压与重新校准块",
      "authors": [
        "Conghao Xiong",
        "Zhengrui Guo",
        "Zhe Xu",
        "Yifei Zhang",
        "Raymond Kai-Yu Tong",
        "Si Yong Yeo",
        "Hao Chen",
        "Joseph J. Y. Sung",
        "Irwin King"
      ],
      "abstract": "Deep learning has advanced computational pathology but expert annotations\nremain scarce. Few-shot learning mitigates annotation burdens yet suffers from\noverfitting and discriminative feature mischaracterization. In addition, the\ncurrent few-shot multiple instance learning (MIL) approaches leverage\npretrained vision-language models to alleviate these issues, but at the cost of\ncomplex preprocessing and high computational cost. We propose a\nSqueeze-and-Recalibrate (SR) block, a drop-in replacement for linear layers in\nMIL models to address these challenges. The SR block comprises two core\ncomponents: a pair of low-rank trainable matrices (squeeze pathway, SP) that\nreduces parameter count and imposes a bottleneck to prevent spurious feature\nlearning, and a frozen random recalibration matrix that preserves geometric\nstructure, diversifies feature directions, and redefines the optimization\nobjective for the SP. We provide theoretical guarantees that the SR block can\napproximate any linear mapping to arbitrary precision, thereby ensuring that\nthe performance of a standard MIL model serves as a lower bound for its\nSR-enhanced counterpart. Extensive experiments demonstrate that our SR-MIL\nmodels consistently outperform prior methods while requiring significantly\nfewer parameters and no architectural changes.",
      "tldr_zh": "本文提出 Squeeze-and-Recalibrate (SR) block，作为 few-shot multiple instance learning (MIL) 模型中线性层的替换模块，旨在解决深度学习在计算病理学中的过拟合和特征误判问题，同时避免复杂预处理和高计算成本。SR block 包含一对低秩可训练矩阵 (squeeze pathway) 以减少参数并防止虚假特征学习，以及一个冻结随机重新校准矩阵来保留几何结构、多样化特征方向并优化训练目标；理论上，该模块能近似任何线性映射，确保性能不低于标准 MIL 模型。实验结果表明，SR-MIL 模型在 whole slide image classification 任务上 consistently outperform 先前方法，同时使用更少参数且无需架构修改。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15504v1",
      "published_date": "2025-05-21 13:24:47 UTC",
      "updated_date": "2025-05-21 13:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:47:05.996208"
    },
    {
      "arxiv_id": "2505.15501v1",
      "title": "Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Ranaldi",
        "Andrea Zugarini",
        "Leonardo Ranaldi",
        "Fabio Massimo Zanzotto"
      ],
      "abstract": "We introduce the concept of protoknowledge to formalize and measure how\nsequences of tokens encoding Knowledge Graphs are internalized during\npretraining and utilized at inference time by Large Language Models (LLMs).\nIndeed, LLMs have demonstrated the ability to memorize vast amounts of token\nsequences during pretraining, and a central open question is how they leverage\nthis memorization as reusable knowledge through generalization. We then\ncategorize protoknowledge into lexical, hierarchical, and topological forms,\nvarying on the type of knowledge that needs to be activated. We measure\nprotoknowledge through Knowledge Activation Tasks (KATs), analyzing its general\nproperties such as semantic bias. We then investigate the impact of\nprotoknowledge on Text-to-SPARQL performance by varying prompting strategies\ndepending on input conditions. To this end, we adopt a novel analysis framework\nthat assesses whether model predictions align with the successful activation of\nthe relevant protoknowledge for each query. This methodology provides a\npractical tool to explore Semantic-Level Data Contamination and serves as an\neffective strategy for Closed-Pretraining models.",
      "tldr_zh": "本研究引入了protoknowledge概念，用于量化大型语言模型（LLMs）在预训练期间如何内部化知识图谱（Knowledge Graphs）的令牌序列，并在推理时通过泛化进行利用。论文将protoknowledge分为lexical、hierarchical和topological形式，并通过Knowledge Activation Tasks (KATs)来评估其属性，如语义偏差。研究进一步分析了protoknowledge对Text-to-SPARQL任务的影响，采用不同提示策略的框架来检查模型预测是否成功激活相关知识，从而提供工具探索语义级数据污染并优化Closed-Pretraining模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15501v1",
      "published_date": "2025-05-21 13:22:34 UTC",
      "updated_date": "2025-05-21 13:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:47:18.963373"
    },
    {
      "arxiv_id": "2505.15475v1",
      "title": "LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models",
      "title_zh": "LFTF：先定位然后微调以缓解大语言模型中的性别偏见",
      "authors": [
        "Zhanyue Qin",
        "Yue Ding",
        "Deyuan Liu",
        "Qingbin Liu",
        "Junxian Cai",
        "Xi Chen",
        "Zhiying Tu",
        "Dianhui Chu",
        "Cuiyun Gao",
        "Dianbo Sui"
      ],
      "abstract": "Nowadays, Large Language Models (LLMs) have attracted widespread attention\ndue to their powerful performance. However, due to the unavoidable exposure to\nsocially biased data during training, LLMs tend to exhibit social biases,\nparticularly gender bias. To better explore and quantifying the degree of\ngender bias in LLMs, we propose a pair of datasets named GenBiasEval and\nGenHintEval, respectively. The GenBiasEval is responsible for evaluating the\ndegree of gender bias in LLMs, accompanied by an evaluation metric named\nAFGB-Score (Absolutely Fair Gender Bias Score). Meanwhile, the GenHintEval is\nused to assess whether LLMs can provide responses consistent with prompts that\ncontain gender hints, along with the accompanying evaluation metric UB-Score\n(UnBias Score). Besides, in order to mitigate gender bias in LLMs more\neffectively, we present the LFTF (Locating First and Then Fine-Tuning)\nalgorithm.The algorithm first ranks specific LLM blocks by their relevance to\ngender bias in descending order using a metric called BMI (Block Mitigating\nImportance Score). Based on this ranking, the block most strongly associated\nwith gender bias is then fine-tuned using a carefully designed loss function.\nNumerous experiments have shown that our proposed LFTF algorithm can\nsignificantly mitigate gender bias in LLMs while maintaining their general\ncapabilities.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)中存在的性别偏见问题，提出了两个数据集：GenBiasEval用于评估偏见程度并引入AFGB-Score (Absolutely Fair Gender Bias Score)指标，以及GenHintEval用于检查模型对包含性别提示的输入的响应一致性，并采用UB-Score (UnBias Score)作为评估标准。作者开发了LFTF (Locating First and Then Fine-Tuning)算法，该算法首先利用BMI (Block Mitigating Importance Score)指标对LLMs的模块按性别偏见相关性降序排序，然后针对最相关模块进行微调，以设计好的损失函数减少偏见。实验结果显示，LFTF算法显著降低了LLMs的性别偏见，同时保持了模型的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15475v1",
      "published_date": "2025-05-21 12:49:37 UTC",
      "updated_date": "2025-05-21 12:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:47:30.712101"
    },
    {
      "arxiv_id": "2505.15469v1",
      "title": "A Qualitative Investigation into LLM-Generated Multilingual Code Comments and Automatic Evaluation Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Katzy",
        "Yongcheng Huang",
        "Gopal-Raj Panchu",
        "Maksym Ziemlewski",
        "Paris Loizides",
        "Sander Vermeulen",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "Large Language Models are essential coding assistants, yet their training is\npredominantly English-centric. In this study, we evaluate the performance of\ncode language models in non-English contexts, identifying challenges in their\nadoption and integration into multilingual workflows. We conduct an open-coding\nstudy to analyze errors in code comments generated by five state-of-the-art\ncode models, CodeGemma, CodeLlama, CodeQwen1.5, GraniteCode, and StarCoder2\nacross five natural languages: Chinese, Dutch, English, Greek, and Polish. Our\nstudy yields a dataset of 12,500 labeled generations, which we publicly\nrelease. We then assess the reliability of standard metrics in capturing\ncomment \\textit{correctness} across languages and evaluate their\ntrustworthiness as judgment criteria. Through our open-coding investigation, we\nidentified a taxonomy of 26 distinct error categories in model-generated code\ncomments. They highlight variations in language cohesion, informativeness, and\nsyntax adherence across different natural languages. Our analysis shows that,\nwhile these models frequently produce partially correct comments, modern neural\nmetrics fail to reliably differentiate meaningful completions from random\nnoise. Notably, the significant score overlap between expert-rated correct and\nincorrect comments calls into question the effectiveness of these metrics in\nassessing generated comments.",
      "tldr_zh": "本研究评估了大型语言模型（LLM）在多语言环境中生成代码注释的性能，针对CodeGemma、CodeLlama、CodeQwen1.5、GraniteCode和StarCoder2五个模型，在中文、荷兰语、英语、希腊语和波兰语上进行开放编码分析，识别了26个错误类别，并公开发布了包含12,500个标记生成的数据集。结果显示，这些模型常产生部分正确的注释，但存在语言连贯性、信息性和语法遵守方面的差异，同时现代神经指标无法可靠地区分有意义的输出与随机噪声。专家评分进一步揭示了正确和错误注释之间的得分重叠，质疑了这些自动评估指标的可靠性和有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted PROMISE '25",
      "pdf_url": "http://arxiv.org/pdf/2505.15469v1",
      "published_date": "2025-05-21 12:45:49 UTC",
      "updated_date": "2025-05-21 12:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:47:43.887886"
    },
    {
      "arxiv_id": "2505.15467v1",
      "title": "Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Zhao",
        "Lingyong Yan",
        "Zhenyang Li",
        "Shuaiqiang Wang",
        "Zhumin Chen",
        "Zhaochun Ren",
        "Dawei Yin"
      ],
      "abstract": "Large language models have achieved remarkable success in various tasks.\nHowever, it is challenging for them to learn new tasks incrementally due to\ncatastrophic forgetting. Existing approaches rely on experience replay,\noptimization constraints, or task differentiation, which encounter strict\nlimitations in real-world scenarios. To address these issues, we propose Joint\nFlashback Adaptation. We first introduce flashbacks -- a limited number of\nprompts from old tasks -- when adapting to new tasks and constrain the\ndeviations of the model outputs compared to the original one. We then\ninterpolate latent tasks between flashbacks and new tasks to enable jointly\nlearning relevant latent tasks, new tasks, and flashbacks, alleviating data\nsparsity in flashbacks and facilitating knowledge sharing for smooth\nadaptation. Our method requires only a limited number of flashbacks without\naccess to the replay data and is task-agnostic. We conduct extensive\nexperiments on state-of-the-art large language models across 1000+\ninstruction-following tasks, arithmetic reasoning tasks, and general reasoning\ntasks. The results demonstrate the superior performance of our method in\nimproving generalization on new tasks and reducing forgetting in old tasks.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在增量学习新任务时面临的灾难性遗忘（catastrophic forgetting）问题，提出了一种Joint Flashback Adaptation方法。该方法通过引入有限的flashbacks（来自旧任务的提示）来适应新任务，同时约束模型输出偏差，并在flashbacks与新任务之间插值潜在任务，实现联合学习，从而缓解数据稀疏性和促进知识共享。实验在超过1000个指令跟随任务、算术推理和一般推理任务上验证了该方法的有效性，结果显示它显著提高了新任务的泛化性能并减少了旧任务的遗忘。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15467v1",
      "published_date": "2025-05-21 12:45:28 UTC",
      "updated_date": "2025-05-21 12:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:47:54.200499"
    },
    {
      "arxiv_id": "2505.15447v1",
      "title": "ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning",
      "title_zh": "ViaRL：通过视觉迭代放大强化学习的适应性时间定位",
      "authors": [
        "Ziqiang Xu",
        "Qi Dai",
        "Tian Xie",
        "Yifan Yang",
        "Kai Qiu",
        "DongDong Chen",
        "Zuxuan Wu",
        "Chong Luo"
      ],
      "abstract": "Video understanding is inherently intention-driven-humans naturally focus on\nrelevant frames based on their goals. Recent advancements in multimodal large\nlanguage models (MLLMs) have enabled flexible query-driven reasoning; however,\nvideo-based frameworks like Video Chain-of-Thought lack direct training signals\nto effectively identify relevant frames. Current approaches often rely on\nheuristic methods or pseudo-label supervised annotations, which are both costly\nand limited in scalability across diverse scenarios. To overcome these\nchallenges, we introduce ViaRL, the first framework to leverage rule-based\nreinforcement learning (RL) for optimizing frame selection in intention-driven\nvideo understanding. An iterated amplification strategy is adopted to perform\nalternating cyclic training in the video CoT system, where each component\nundergoes iterative cycles of refinement to improve its capabilities. ViaRL\nutilizes the answer accuracy of a downstream model as a reward signal to train\na frame selector through trial-and-error, eliminating the need for expensive\nannotations while closely aligning with human-like learning processes.\nComprehensive experiments across multiple benchmarks, including VideoMME,\nLVBench, and MLVU, demonstrate that ViaRL consistently delivers superior\ntemporal grounding performance and robust generalization across diverse video\nunderstanding tasks, highlighting its effectiveness and scalability. Notably,\nViaRL achieves a nearly 15\\% improvement on Needle QA, a subset of MLVU, which\nis required to search a specific needle within a long video and regarded as one\nof the most suitable benchmarks for evaluating temporal grounding.",
      "tldr_zh": "该论文提出ViaRL框架，利用基于规则的Reinforcement Learning（RL）优化视频理解中的临时定位（Temporal Grounding），以适应意图驱动的帧选择过程。ViaRL采用迭代放大策略，在视频Chain-of-Thought系统中进行交替循环训练，使用下游模型的答案准确率作为奖励信号，避免了昂贵的标注需求，并模拟人类学习方式。实验结果显示，ViaRL在VideoMME、LVBench和MLVU等基准上表现出色，尤其在Needle QA任务上实现了近15%的性能提升，证明了其在多样化视频任务中的鲁棒性和可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15447v1",
      "published_date": "2025-05-21 12:29:40 UTC",
      "updated_date": "2025-05-21 12:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:48:06.145852"
    },
    {
      "arxiv_id": "2505.15444v1",
      "title": "Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yutao Zhu",
        "Jiajie Jin",
        "Hongjin Qian",
        "Zheng Liu",
        "Zhicheng Dou",
        "Ji-Rong Wen"
      ],
      "abstract": "Existing studies have optimized retrieval-augmented generation (RAG) across\nvarious sub-tasks, such as query understanding and retrieval refinement, but\nintegrating these optimizations into a unified framework remains challenging.\nTo tackle this problem, this work proposes RoleRAG, a unified RAG framework\nthat achieves efficient multi-task processing through role-specific token\noptimization. RoleRAG comprises six modules, each handling a specific sub-task\nwithin the RAG process. Additionally, we introduce a query graph to represent\nthe decomposition of the query, which can be dynamically resolved according to\nthe decomposing state. All modules are driven by the same underlying LLM,\ndistinguished by task-specific role tokens that are individually optimized.\nThis design allows RoleRAG to dynamically activate different modules within a\nsingle LLM instance, thereby streamlining deployment and reducing resource\nconsumption. Experimental results on five open-domain question-answering\ndatasets demonstrate the effectiveness, generalizability, and flexibility of\nour framework.",
      "tldr_zh": "本文提出RoleRAG，一种统一的检索增强生成(RAG)框架，通过角色特定标记优化，实现单个LLM处理多个子任务，包括查询理解和检索精炼。该框架由六个模块组成，使用查询图动态分解查询，所有模块由同一LLM驱动，仅通过优化后的任务特定角色标记进行区分，从而简化部署并降低资源消耗。在五个开放域问答数据集上的实验验证了RoleRAG的有效性、可推广性和灵活性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15444v1",
      "published_date": "2025-05-21 12:25:12 UTC",
      "updated_date": "2025-05-21 12:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:48:17.690184"
    },
    {
      "arxiv_id": "2505.15441v2",
      "title": "Stronger ViTs With Octic Equivariance",
      "title_zh": "翻译失败",
      "authors": [
        "David Nordström",
        "Johan Edstedt",
        "Fredrik Kahl",
        "Georg Bökman"
      ],
      "abstract": "Recent efforts at scaling computer vision models have established Vision\nTransformers (ViTs) as the leading architecture. ViTs incorporate weight\nsharing over image patches as an important inductive bias. In this work, we\nshow that ViTs benefit from incorporating equivariance under the octic group,\ni.e., reflections and 90-degree rotations, as a further inductive bias. We\ndevelop new architectures, octic ViTs, that use octic-equivariant layers and\nput them to the test on both supervised and self-supervised learning. Through\nextensive experiments on DeiT-III and DINOv2 training on ImageNet-1K, we show\nthat octic ViTs yield more computationally efficient networks while also\nimproving performance. In particular, we achieve approximately 40% reduction in\nFLOPs for ViT-H while simultaneously improving both classification and\nsegmentation results.",
      "tldr_zh": "这篇论文探讨了在Vision Transformers (ViTs)中引入octic equivariance（包括反射和90度旋转）作为额外归纳偏差，以提升模型性能和计算效率。研究者开发了新的octic ViTs架构，使用octic-equivariant layers，并在监督和自监督学习中进行测试，包括在DeiT-III和DINOv2上训练ImageNet-1K数据集。实验结果显示，octic ViTs在ViT-H模型上实现了约40% FLOPs的减少，同时改善了分类和分割任务的准确率，为更高效的计算机视觉模型提供了重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15441v2",
      "published_date": "2025-05-21 12:22:53 UTC",
      "updated_date": "2025-05-22 15:33:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:48:30.474466"
    },
    {
      "arxiv_id": "2505.15433v1",
      "title": "Set-LLM: A Permutation-Invariant LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Beni Egressy",
        "Jan Stühmer"
      ],
      "abstract": "While large language models (LLMs) demonstrate impressive capabilities across\nnumerous applications, their robustness remains a critical concern. This paper\nis motivated by a specific vulnerability: the order sensitivity of LLMs. This\nvulnerability manifests itself as the order bias observed when LLMs decide\nbetween possible options (for example, a preference for the first option) and\nthe tendency of LLMs to provide different answers when options are reordered.\nThe use cases for this scenario extend beyond the classical case of\nmultiple-choice question answering to the use of LLMs as automated evaluators\nin AI pipelines, comparing output generated by different models. We introduce\nSet-LLM, a novel architectural adaptation for pretrained LLMs that enables the\nprocessing of mixed set-text inputs with permutation invariance guarantees. The\nadaptations involve a new attention mask and new positional encodings\nspecifically designed for sets. We provide a theoretical proof of invariance\nand demonstrate through experiments that Set-LLM can be trained effectively,\nachieving comparable or improved performance and maintaining the runtime of the\noriginal model, while eliminating order sensitivity.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的顺序敏感性问题（如偏好第一个选项或对输入重排给出不同答案），提出了一种新型架构Set-LLM，以实现置换不变性(permutation invariance)。Set-LLM通过设计新的attention mask和positional encodings，允许LLMs处理混合set-text输入，同时保持模型的原始运行时和性能。实验结果表明，Set-LLM在训练后能有效消除顺序偏见，并在多项任务上实现相当或更高的表现，为LLMs在自动评估等应用中提供更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15433v1",
      "published_date": "2025-05-21 12:14:26 UTC",
      "updated_date": "2025-05-21 12:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:48:41.187405"
    },
    {
      "arxiv_id": "2505.15429v1",
      "title": "Uncertainty Quantification in SVM prediction",
      "title_zh": "SVM 预测中的不确定性量化",
      "authors": [
        "Pritam Anand"
      ],
      "abstract": "This paper explores Uncertainty Quantification (UQ) in SVM predictions,\nparticularly for regression and forecasting tasks. Unlike the Neural Network,\nthe SVM solutions are typically more stable, sparse, optimal and interpretable.\nHowever, there are only few literature which addresses the UQ in SVM\nprediction. At first, we provide a comprehensive summary of existing Prediction\nInterval (PI) estimation and probabilistic forecasting methods developed in the\nSVM framework and evaluate them against the key properties expected from an\nideal PI model. We find that none of the existing SVM PI models achieves a\nsparse solution. To introduce sparsity in SVM model, we propose the Sparse\nSupport Vector Quantile Regression (SSVQR) model, which constructs PIs and\nprobabilistic forecasts by solving a pair of linear programs. Further, we\ndevelop a feature selection algorithm for PI estimation using SSVQR that\neffectively eliminates a significant number of features while improving PI\nquality in case of high-dimensional dataset. Finally we extend the SVM models\nin Conformal Regression setting for obtaining more stable prediction set with\nfinite test set guarantees. Extensive experiments on artificial, real-world\nbenchmark datasets compare the different characteristics of both existing and\nproposed SVM-based PI estimation methods and also highlight the advantages of\nthe feature selection in PI estimation. Furthermore, we compare both, the\nexisting and proposed SVM-based PI estimation models, with modern deep learning\nmodels for probabilistic forecasting tasks on benchmark datasets. Furthermore,\nSVM models show comparable or superior performance to modern complex deep\nlearning models for probabilistic forecasting task in our experiments.",
      "tldr_zh": "这篇论文探讨了支持向量机 (SVM) 预测中的不确定性量化 (UQ)，重点针对回归和预测任务，并总结了现有预测区间 (PI) 估计和概率预测方法，同时评估它们的关键属性，如稳定性、稀疏性和可解释性。作者提出 Sparse Support Vector Quantile Regression (SSVQR) 模型，通过解决一对线性规划来构建 PI 和概率预测，并引入稀疏性，同时开发了基于 SSVQR 的特征选择算法，以有效减少高维数据集中的特征并提升 PI 质量。实验结果表明，提出的 SVM 模型在基准数据集上与复杂深度学习模型相比表现出色或相当，尤其在概率预测任务中，提供更稳定的预测集并具备有限测试集保证。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15429v1",
      "published_date": "2025-05-21 12:11:07 UTC",
      "updated_date": "2025-05-21 12:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:48:56.164246"
    },
    {
      "arxiv_id": "2505.15427v1",
      "title": "Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwen Li",
        "Die Chen",
        "Mingyuan Fan",
        "Cen Chen",
        "Yaliang Li",
        "Yanhao Wang",
        "Wenmeng Zhou"
      ],
      "abstract": "The remarkable ability of diffusion models to generate high-fidelity images\nhas led to their widespread adoption. However, concerns have also arisen\nregarding their potential to produce Not Safe for Work (NSFW) content and\nexhibit social biases, hindering their practical use in real-world\napplications. In response to this challenge, prior work has focused on\nemploying security filters to identify and exclude toxic text, or\nalternatively, fine-tuning pre-trained diffusion models to erase sensitive\nconcepts. Unfortunately, existing methods struggle to achieve satisfactory\nperformance in the sense that they can have a significant impact on the normal\nmodel output while still failing to prevent the generation of harmful content\nin some cases. In this paper, we propose a novel self-discovery approach to\nidentifying a semantic direction vector in the embedding space to restrict text\nembedding within a safe region. Our method circumvents the need for correcting\nindividual words within the input text and steers the entire text prompt\ntowards a safe region in the embedding space, thereby enhancing model\nrobustness against all possibly unsafe prompts. In addition, we employ Low-Rank\nAdaptation (LoRA) for semantic direction vector initialization to reduce the\nimpact on the model performance for other semantics. Furthermore, our method\ncan also be integrated with existing methods to improve their social\nresponsibility. Extensive experiments on benchmark datasets demonstrate that\nour method can effectively reduce NSFW content and mitigate social bias\ngenerated by diffusion models compared to several state-of-the-art baselines.",
      "tldr_zh": "这篇论文针对扩散模型可能生成 Not Safe for Work (NSFW) 内容和社会偏见的问题，提出了一种新型自发现方法，通过在嵌入空间中识别语义方向向量，将文本嵌入约束在安全区域，从而提升模型的鲁棒性。方法避免了对输入文本个别单词的修正，而是整体引导文本提示到安全区域，并使用 Low-Rank Adaptation (LoRA) 初始化语义方向向量，以最小化对模型其他性能的影响。该方法可与现有技术结合，实验在基准数据集上证明其比现有基线更有效地减少了 NSFW 内容和社会偏见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15427v1",
      "published_date": "2025-05-21 12:10:26 UTC",
      "updated_date": "2025-05-21 12:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:49:06.616211"
    },
    {
      "arxiv_id": "2505.15420v1",
      "title": "Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries",
      "title_zh": "Silent Leaks: 通过良性查询对 RAG 系统的隐式知识提取攻击",
      "authors": [
        "Yuhao Wang",
        "Wenjie Qu",
        "Yanze Jiang",
        "Zichen Liu",
        "Yue Liu",
        "Shengfang Zhai",
        "Yinpeng Dong",
        "Jiaheng Zhang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by incorporating external knowledge bases, but they are vulnerable to\nprivacy risks from data extraction attacks. Existing extraction methods\ntypically rely on malicious inputs such as prompt injection or jailbreaking,\nmaking them easily detectable via input- or output-level detection. In this\npaper, we introduce Implicit Knowledge Extraction Attack (IKEA), which conducts\nknowledge extraction on RAG systems through benign queries. IKEA first\nleverages anchor concepts to generate queries with the natural appearance, and\nthen designs two mechanisms to lead to anchor concept thoroughly 'explore' the\nRAG's privacy knowledge: (1) Experience Reflection Sampling, which samples\nanchor concepts based on past query-response patterns to ensure the queries'\nrelevance to RAG documents; (2) Trust Region Directed Mutation, which\niteratively mutates anchor concepts under similarity constraints to further\nexploit the embedding space. Extensive experiments demonstrate IKEA's\neffectiveness under various defenses, surpassing baselines by over 80% in\nextraction efficiency and 90% in attack success rate. Moreover, the substitute\nRAG system built from IKEA's extractions consistently outperforms those based\non baseline methods across multiple evaluation tasks, underscoring the\nsignificant privacy risk in RAG systems.",
      "tldr_zh": "该研究揭示了Retrieval-Augmented Generation (RAG) 系统在增强大语言模型 (LLMs) 时面临的隐私风险，提出了一种名为Implicit Knowledge Extraction Attack (IKEA)的攻击方法，通过良性查询实现知识提取，而非易检测的恶意输入。IKEA 利用 anchor concepts 生成自然查询，并引入 Experience Reflection Sampling 和 Trust Region Directed Mutation 机制，前者基于过去查询响应模式采样以确保相关性，后者通过相似性约束迭代变异锚点概念以探索嵌入空间。实验结果显示，IKEA 在各种防御下比基线方法提升 80% 在提取效率和 90% 在攻击成功率，且基于其提取构建的替代 RAG 系统在多个任务中表现出色，突显了 RAG 系统的重大隐私漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15420v1",
      "published_date": "2025-05-21 12:04:42 UTC",
      "updated_date": "2025-05-21 12:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:49:19.565961"
    },
    {
      "arxiv_id": "2505.15868v1",
      "title": "An Inclusive Foundation Model for Generalizable Cytogenetics in Precision Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Changchun Yang",
        "Weiqian Dai",
        "Yilan Zhang",
        "Siyuan Chen",
        "Jingdong Hu",
        "Junkai Su",
        "Yuxuan Chen",
        "Ao Xu",
        "Na Li",
        "Xin Gao",
        "Yongguo Yu"
      ],
      "abstract": "Chromosome analysis is vital for diagnosing genetic disorders and guiding\ncancer therapy decisions through the identification of somatic clonal\naberrations. However, developing an AI model are hindered by the overwhelming\ncomplexity and diversity of chromosomal abnormalities, requiring extensive\nannotation efforts, while automated methods remain task-specific and lack\ngeneralizability due to the scarcity of comprehensive datasets spanning diverse\nresource conditions. Here, we introduce CHROMA, a foundation model for\ncytogenomics, designed to overcome these challenges by learning generalizable\nrepresentations of chromosomal abnormalities. Pre-trained on over 84,000\nspecimens (~4 million chromosomal images) via self-supervised learning, CHROMA\noutperforms other methods across all types of abnormalities, even when trained\non fewer labelled data and more imbalanced datasets. By facilitating\ncomprehensive mapping of instability and clonal leisons across various\naberration types, CHROMA offers a scalable and generalizable solution for\nreliable and automated clinical analysis, reducing the annotation workload for\nexperts and advancing precision oncology through the early detection of rare\ngenomic abnormalities, enabling broad clinical AI applications and making\nadvanced genomic analysis more accessible.",
      "tldr_zh": "该论文提出CHROMA，一种包容性的基础模型，用于精确肿瘤学（precision oncology）中的通用细胞遗传学（cytogenomics），旨在解决染色体异常分析的复杂性、多样性和数据集稀缺问题。CHROMA通过自监督学习（self-supervised learning）在超过84,000个样本（约4百万染色体图像）上预训练，学习通用的染色体异常表示，从而提升模型的泛化能力。实验结果显示，CHROMA在各种异常类型上优于其他方法，即使在标注数据少且不平衡的数据集上。最终，该模型减少了专家的标注工作量，促进了临床分析的自动化和可扩展性，推动稀有基因组异常的早期检测和更广泛的AI应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "These authors contributed equally to this work: Changchun Yang,\n  Weiqian Dai, Yilan Zhang",
      "pdf_url": "http://arxiv.org/pdf/2505.15868v1",
      "published_date": "2025-05-21 12:03:37 UTC",
      "updated_date": "2025-05-21 12:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:49:32.645880"
    },
    {
      "arxiv_id": "2505.15418v1",
      "title": "Guided Policy Optimization under Partial Observability",
      "title_zh": "部分可观察性下的引导策略优化",
      "authors": [
        "Yueheng Li",
        "Guangming Xie",
        "Zongqing Lu"
      ],
      "abstract": "Reinforcement Learning (RL) in partially observable environments poses\nsignificant challenges due to the complexity of learning under uncertainty.\nWhile additional information, such as that available in simulations, can\nenhance training, effectively leveraging it remains an open problem. To address\nthis, we introduce Guided Policy Optimization (GPO), a framework that co-trains\na guider and a learner. The guider takes advantage of privileged information\nwhile ensuring alignment with the learner's policy that is primarily trained\nvia imitation learning. We theoretically demonstrate that this learning scheme\nachieves optimality comparable to direct RL, thereby overcoming key limitations\ninherent in existing approaches. Empirical evaluations show strong performance\nof GPO across various tasks, including continuous control with partial\nobservability and noise, and memory-based challenges, significantly\noutperforming existing methods.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning, RL) 在部分可观测环境中的不确定性挑战，提出了一种 Guided Policy Optimization (GPO) 框架。该框架通过同时训练一个利用特权信息(privileged information)的 guider 和一个主要基于模仿学习(imitation learning)的 learner，确保策略对齐。理论分析证明，GPO 能实现与直接 RL 相当的优化性能；在实验中，它在连续控制任务、噪声环境和基于记忆的挑战上显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15418v1",
      "published_date": "2025-05-21 12:01:08 UTC",
      "updated_date": "2025-05-21 12:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:49:42.420045"
    },
    {
      "arxiv_id": "2505.15410v1",
      "title": "ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bahar Radmehr",
        "Ekaterina Shved",
        "Fatma Betül Güreş",
        "Adish Singla",
        "Tanja Käser"
      ],
      "abstract": "Clickstream data from digital learning environments offer valuable insights\ninto students' learning behaviors, but are challenging to interpret due to\ntheir high dimensionality and granularity. Prior approaches have relied mainly\non handcrafted features, expert labeling, clustering, or supervised models,\ntherefore often lacking generalizability and scalability. In this work, we\nintroduce ClickSight, an in-context Large Language Model (LLM)-based pipeline\nthat interprets student clickstreams to reveal their learning strategies.\nClickSight takes raw clickstreams and a list of learning strategies as input\nand generates textual interpretations of students' behaviors during\ninteraction. We evaluate four different prompting strategies and investigate\nthe impact of self-refinement on interpretation quality. Our evaluation spans\ntwo open-ended learning environments and uses a rubric-based domain-expert\nevaluation. Results show that while LLMs can reasonably interpret learning\nstrategies from clickstreams, interpretation quality varies by prompting\nstrategy, and self-refinement offers limited improvement. ClickSight\ndemonstrates the potential of LLMs to generate theory-driven insights from\neducational interaction data.",
      "tldr_zh": "该研究提出 ClickSight，一种基于 Large Language Model (LLM) 的 in-context 管道，用于解释学生点击流数据（clickstreams），以揭示他们的学习策略，解决了传统方法在泛化性和可扩展性上的局限。系统以原始点击流和学习策略列表作为输入，生成文本化的行为解释，并评估了四种提示策略及自精炼机制对解释质量的影响。在两个开放式学习环境中进行基于 rubrics 的领域专家评估，结果表明 LLM 可以合理地从点击流中提取理论驱动洞见，但解释质量因提示策略而异，自精炼的改善作用有限。总的来说，ClickSight 展示了 LLM 在教育互动数据分析中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in Latebreaking results track in AIED 2025(26th\n  International Conference on Artificial Intelligence in Education JULY 22-26,\n  2025 PALERMO, ITALY)",
      "pdf_url": "http://arxiv.org/pdf/2505.15410v1",
      "published_date": "2025-05-21 11:52:57 UTC",
      "updated_date": "2025-05-21 11:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:49:55.059768"
    },
    {
      "arxiv_id": "2505.15406v1",
      "title": "Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models",
      "title_zh": "Audio Jailbreak：一个用于越狱大型音频语言模型的公开全面基准",
      "authors": [
        "Zirui Song",
        "Qian Jiang",
        "Mingxuan Cui",
        "Mingzhe Li",
        "Lang Gao",
        "Zeyu Zhang",
        "Zixiang Xu",
        "Yanbo Wang",
        "Chenxi Wang",
        "Guangxian Ouyang",
        "Zhenhao Chen",
        "Xiuying Chen"
      ],
      "abstract": "The rise of Large Audio Language Models (LAMs) brings both potential and\nrisks, as their audio outputs may contain harmful or unethical content.\nHowever, current research lacks a systematic, quantitative evaluation of LAM\nsafety especially against jailbreak attacks, which are challenging due to the\ntemporal and semantic nature of speech. To bridge this gap, we introduce\nAJailBench, the first benchmark specifically designed to evaluate jailbreak\nvulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of\n1,495 adversarial audio prompts spanning 10 policy-violating categories,\nconverted from textual jailbreak attacks using realistic text to speech\nsynthesis. Using this dataset, we evaluate several state-of-the-art LAMs and\nreveal that none exhibit consistent robustness across attacks. To further\nstrengthen jailbreak testing and simulate more realistic attack conditions, we\npropose a method to generate dynamic adversarial variants. Our Audio\nPerturbation Toolkit (APT) applies targeted distortions across time, frequency,\nand amplitude domains. To preserve the original jailbreak intent, we enforce a\nsemantic consistency constraint and employ Bayesian optimization to efficiently\nsearch for perturbations that are both subtle and highly effective. This\nresults in AJailBench-APT, an extended dataset of optimized adversarial audio\nsamples. Our findings demonstrate that even small, semantically preserved\nperturbations can significantly reduce the safety performance of leading LAMs,\nunderscoring the need for more robust and semantically aware defense\nmechanisms.",
      "tldr_zh": "这篇论文引入了 AJailBench，这是一个开放全面的基准，用于评估 Large Audio Language Models (LAMs) 针对 jailbreak 攻击的漏洞，填补了现有研究的空白。研究者构建了 AJailBench-Base 数据集，包含 1,495 个跨越 10 个违反政策类别的对抗音频提示，并使用 Audio Perturbation Toolkit (APT) 结合 Bayesian optimization 生成动态变体，确保扰动微妙且语义一致。实验结果显示，现有 LAMs 缺乏一致的鲁棒性，即使是小规模的语义保持扰动也能显著降低其安全性能，强调了开发更 robust 和语义 aware 防御机制的迫切需求。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "We release AJailBench, including both static and optimized\n  adversarial data, to facilitate future research:\n  https://github.com/mbzuai-nlp/AudioJailbreak",
      "pdf_url": "http://arxiv.org/pdf/2505.15406v1",
      "published_date": "2025-05-21 11:47:47 UTC",
      "updated_date": "2025-05-21 11:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:50:08.134369"
    },
    {
      "arxiv_id": "2505.15400v1",
      "title": "When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning",
      "title_zh": "何时继续思考：自适应思考模式切换用于高效推理",
      "authors": [
        "Xiaoyun Zhang",
        "Jingqing Ruan",
        "Xing Ma",
        "Yawen Zhu",
        "Haodong Zhao",
        "Hao Li",
        "Jiansong Chen",
        "Ke Zeng",
        "Xunliang Cai"
      ],
      "abstract": "Large reasoning models (LRMs) achieve remarkable performance via long\nreasoning chains, but often incur excessive computational overhead due to\nredundant reasoning, especially on simple tasks. In this work, we\nsystematically quantify the upper bounds of LRMs under both Long-Thinking and\nNo-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery\nMechanism\" where models implicitly supplement reasoning during answer\ngeneration. Building on this insight, we propose Adaptive Self-Recovery\nReasoning (ASRR), a framework that suppresses unnecessary reasoning and enables\nimplicit recovery. By introducing accuracy-aware length reward regulation, ASRR\nadaptively allocates reasoning effort according to problem difficulty,\nachieving high efficiency with negligible performance sacrifice. Experiments\nacross multiple benchmarks and models show that, compared with GRPO, ASRR\nreduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal\naccuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates\non safety benchmarks (up to +21.7%). Our results highlight the potential of\nASRR for enabling efficient, adaptive, and safer reasoning in LRMs.",
      "tldr_zh": "本研究发现，大型推理模型（LRMs）在简单任务上因冗余推理导致高计算开销，并揭示了“Internal Self-Recovery Mechanism”，即模型在生成答案时隐式补充推理。针对此，提出 Adaptive Self-Recovery Reasoning (ASRR) 框架，通过 accuracy-aware length reward regulation 自适应地根据问题难度分配推理努力，抑制不必要推理并保持高效性。实验结果显示，与 GRPO 相比，ASRR 在多个基准上减少了推理预算（最高 32.5% 对于 1.5B 模型，25.7% 对于 7B 模型），准确性损失最小（1.2% 和 0.6% pass@1），并显著提升安全基准的无害率（最高 +21.7%），为更高效、适应性和安全的 LRM 推理提供了潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15400v1",
      "published_date": "2025-05-21 11:41:39 UTC",
      "updated_date": "2025-05-21 11:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:50:20.226074"
    },
    {
      "arxiv_id": "2505.15386v1",
      "title": "RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Huang",
        "Junyan Zhang",
        "Zihao Wang",
        "Biquan Bie",
        "Xuming Hu",
        "Yi R.",
        "Fung",
        "Xinlei He"
      ],
      "abstract": "Large Language Models (LLMs) have become powerful, but hallucinations remain\na vital obstacle to their trustworthy use. While previous works improved the\ncapability of hallucination detection by measuring uncertainty, they all lack\nthe ability to explain the provenance behind why hallucinations occur, i.e.,\nwhich part of the inputs tends to trigger hallucinations. Recent works on the\nprompt attack indicate that uncertainty exists in semantic propagation, where\nattention mechanisms gradually fuse local token information into high-level\nsemantics across layers. Meanwhile, uncertainty also emerges in language\ngeneration, due to its probability-based selection of high-level semantics for\nsampled generations. Based on that, we propose RePPL to recalibrate uncertainty\nmeasurement by these two aspects, which dispatches explainable uncertainty\nscores to each token and aggregates in Perplexity-style Log-Average form as\ntotal score. Experiments show that our method achieves the best comprehensive\ndetection performance across various QA datasets on advanced models (average\nAUC of 0.833), and our method is capable of producing token-level uncertainty\nscores as explanations for the hallucination. Leveraging these scores, we\npreliminarily find the chaotic pattern of hallucination and showcase its\npromising usage.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 中的幻觉问题，提出 RePPL 方法，通过重新校准语义传播和语言生成中的不确定性，实现可解释的 QA 幻觉检测。具体而言，RePPL 为每个 token 分配不确定性分数，并以 Perplexity-style 的 Log-Average 形式聚合总分，从而解释输入哪些部分可能触发幻觉。实验结果显示，该方法在多种 QA 数据集上取得了最佳综合性能（平均 AUC 0.833），并初步揭示了幻觉的混沌模式，为可信赖的 LLMs 应用提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15386v1",
      "published_date": "2025-05-21 11:23:05 UTC",
      "updated_date": "2025-05-21 11:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:50:32.800378"
    },
    {
      "arxiv_id": "2505.15380v1",
      "title": "Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Lin",
        "Yang Zhang",
        "Yougen Yuan",
        "Yuming Yan",
        "Jinjiang Liu",
        "Zhiyong Wu",
        "Pengfei Hu",
        "Qun Yu"
      ],
      "abstract": "Modern autoregressive speech synthesis models leveraging language models have\ndemonstrated remarkable performance. However, the sequential nature of next\ntoken prediction in these models leads to significant latency, hindering their\ndeployment in scenarios where inference speed is critical. In this work, we\npropose Speech Speculative Decoding (SSD), a novel framework for autoregressive\nspeech synthesis acceleration. Specifically, our method employs a lightweight\ndraft model to generate candidate token sequences, which are subsequently\nverified in parallel by the target model using the proposed SSD framework.\nExperimental results demonstrate that SSD achieves a significant speedup of\n1.4x compared with conventional autoregressive decoding, while maintaining high\nfidelity and naturalness. Subjective evaluations further validate the\neffectiveness of SSD in preserving the perceptual quality of the target model\nwhile accelerating inference.",
      "tldr_zh": "本研究针对自回归（autoregressive）语音合成模型的推理延迟问题，提出了一种新框架Speech Speculative Decoding (SSD)，旨在加速语音合成过程。该方法使用轻量级草稿模型生成候选标记序列，随后由目标模型进行并行验证，从而显著提高推理效率。实验结果显示，SSD比传统自回归解码加速1.4倍，同时保持高保真度和自然性，主观评估进一步确认了其在保留感知质量方面的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15380v1",
      "published_date": "2025-05-21 11:17:04 UTC",
      "updated_date": "2025-05-21 11:17:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:50:42.041892"
    },
    {
      "arxiv_id": "2505.15367v1",
      "title": "Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Dasol Choi",
        "Seunghyun Lee",
        "Youngsook Song"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated impressive capabilities in\nunderstanding visual content, but their reliability in safety-critical contexts\nremains under-explored. We introduce VERI (Visual Emergency Recognition\nDataset), a carefully designed diagnostic benchmark of 200 images (100\ncontrastive pairs). Each emergency scene is matched with a visually similar but\nsafe counterpart through multi-stage human verification and iterative\nrefinement. Using a two-stage protocol - risk identification and emergency\nresponse - we evaluate 14 VLMs (2B-124B parameters) across medical emergencies,\naccidents, and natural disasters. Our analysis reveals a systematic\noverreaction problem: models excel at identifying real emergencies (70-100\npercent success rate) but suffer from an alarming rate of false alarms,\nmisidentifying 31-96 percent of safe situations as dangerous, with 10 scenarios\nfailed by all models regardless of scale. This \"better-safe-than-sorry\" bias\nmanifests primarily through contextual overinterpretation (88-93 percent of\nerrors), challenging VLMs' reliability for safety applications. These findings\nhighlight persistent limitations that are not resolved by increasing model\nscale, motivating targeted approaches for improving contextual safety\nassessment in visually misleading scenarios.",
      "tldr_zh": "这篇论文探讨了Vision-Language Models (VLMs) 在视觉紧急识别中的过度反应问题，引入了VERI数据集——一个包含200张图像（100对对比图像）的诊断基准，用于评估紧急场景与相似安全场景的区分。研究通过两阶段协议（风险识别和紧急响应）评估了14个VLMs（参数从2B到124B），发现模型在识别真实紧急情况时成功率高达70-100%，但误将31-96%的安全场景识别为危险，导致10个场景全模型失败。过度反应主要源于上下文过度解释（88-93%的错误），这反映了VLMs在安全应用中的可靠性不足。作者强调，这种“better-safe-than-sorry”偏差无法通过增加模型规模解决，需要开发针对性方法来提升在视觉误导场景中的安全评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15367v1",
      "published_date": "2025-05-21 10:57:40 UTC",
      "updated_date": "2025-05-21 10:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:50:55.770047"
    },
    {
      "arxiv_id": "2505.15358v2",
      "title": "Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model",
      "title_zh": "翻译失败",
      "authors": [
        "Angelique Mangubat",
        "Shane Gilroy"
      ],
      "abstract": "Road safety is a critical challenge, particularly for cyclists, who are among\nthe most vulnerable road users. This study aims to enhance road safety by\nproposing a novel benchmark for bicycle occlusion level classification using\nadvanced computer vision techniques. Utilizing a parts-based detection model,\nimages are annotated and processed through a custom image detection pipeline. A\nnovel method of bicycle occlusion level is proposed to objectively quantify the\nvisibility and occlusion level of bicycle semantic parts. The findings indicate\nthat the model robustly quantifies the visibility and occlusion level of\nbicycles, a significant improvement over the subjective methods used by the\ncurrent state of the art. Widespread use of the proposed methodology will\nfacilitate accurate performance reporting of cyclist detection algorithms for\noccluded cyclists, informing the development of more robust vulnerable road\nuser detection methods for autonomous vehicles.",
      "tldr_zh": "本研究针对骑行者道路安全问题，提出一个新的基准，使用 Deformable Parts-Based Model 进行自行车遮挡水平客观分类。\n研究团队开发了一个自定义图像检测管道，对图像进行标注和处理，并引入一种新方法来量化自行车语义部件的可见性和遮挡水平。\n结果表明，该模型在量化方面比现有主观方法更 robust，显著提升了遮挡水平的准确性。\n这项方法将促进骑行者检测算法的性能评估，并支持更可靠的弱势道路用户检测系统在自动驾驶车辆中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15358v2",
      "published_date": "2025-05-21 10:42:41 UTC",
      "updated_date": "2025-05-22 08:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:51:07.018791"
    },
    {
      "arxiv_id": "2505.15345v1",
      "title": "Hadamax Encoding: Elevating Performance in Model-Free Atari",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob E. Kooi",
        "Zhao Yang",
        "Vincent François-Lavet"
      ],
      "abstract": "Neural network architectures have a large impact in machine learning. In\nreinforcement learning, network architectures have remained notably simple, as\nchanges often lead to small gains in performance. This work introduces a novel\nencoder architecture for pixel-based model-free reinforcement learning. The\nHadamax (\\textbf{Hada}mard \\textbf{max}-pooling) encoder achieves\nstate-of-the-art performance by max-pooling Hadamard products between\nGELU-activated parallel hidden layers. Based on the recent PQN algorithm, the\nHadamax encoder achieves state-of-the-art model-free performance in the\nAtari-57 benchmark. Specifically, without applying any algorithmic\nhyperparameter modifications, Hadamax-PQN achieves an 80\\% performance gain\nover vanilla PQN and significantly surpasses Rainbow-DQN. For reproducibility,\nthe full code is available on\n\\href{https://github.com/Jacobkooi/Hadamax}{GitHub}.",
      "tldr_zh": "这篇论文引入了Hadamax编码器，一种新型神经网络架构，旨在提升基于像素的模型无关强化学习在Atari游戏中的性能。Hadamax通过在GELU激活的并行隐藏层之间计算Hadamard乘积并进行max-pooling，实现高效特征提取。基于PQN算法，Hadamax-PQN在Atari-57基准测试中比原版PQN提高了80%的性能，并显著超过了Rainbow-DQN。该框架的完整代码已在GitHub上公开，以支持复现和进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15345v1",
      "published_date": "2025-05-21 10:19:49 UTC",
      "updated_date": "2025-05-21 10:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:51:19.429501"
    },
    {
      "arxiv_id": "2505.15344v1",
      "title": "Alpay Algebra: A Universal Structural Foundation",
      "title_zh": "Alpay Algebra：通用结构基础",
      "authors": [
        "Faruk Alpay"
      ],
      "abstract": "Alpay Algebra is introduced as a universal, category-theoretic framework that\nunifies classical algebraic structures with modern needs in symbolic recursion\nand explainable AI. Starting from a minimal list of axioms, we model each\nalgebra as an object in a small cartesian closed category $\\mathcal{A}$ and\ndefine a transfinite evolution functor $\\phi\\colon\\mathcal{A}\\to\\mathcal{A}$.\nWe prove that the fixed point $\\phi^{\\infty}$ exists for every initial object\nand satisfies an internal universal property that recovers familiar constructs\n-- limits, colimits, adjunctions -- while extending them to ordinal-indexed\nfolds. A sequence of theorems establishes (i) soundness and conservativity over\nstandard universal algebra, (ii) convergence of $\\phi$-iterates under regular\ncardinals, and (iii) an explanatory correspondence between $\\phi^{\\infty}$ and\nminimal sufficient statistics in information-theoretic AI models. We conclude\nby outlining computational applications: type-safe functional languages,\ncategorical model checking, and signal-level reasoning engines that leverage\nAlpay Algebra's structural invariants. All proofs are self-contained; no\nexternal set-theoretic axioms beyond ZFC are required. This exposition\npositions Alpay Algebra as a bridge between foundational mathematics and\nhigh-impact AI systems, and provides a reference for further work in category\ntheory, transfinite fixed-point analysis, and symbolic computation.",
      "tldr_zh": "本论文引入了 Alpay Algebra 作为一种通用的范畴论框架（category-theoretic framework），旨在统一经典代数结构与符号递归及可解释 AI 的需求。作者从最小公理列表出发，将代数建模为小笛卡尔闭范畴（cartesian closed category）$\\mathcal{A}$ 中的对象，并定义超限演化函子（transfinite evolution functor）$\\phi$，证明其固定点$\\phi^{\\infty}$存在且满足内部通用属性，从而扩展了极限（limits）、余极限（colimits）和伴随（adjunctions）到序数索引的折叠。研究还建立了相关定理，包括对标准通用代数的正确性和保守性、$\\phi$ 迭代的收敛性，以及与信息理论 AI 模型的最小充分统计量的对应，并概述了计算应用，如类型安全的函数语言和范畴模型检查（categorical model checking），将基础数学与高影响 AI 系统桥接。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "math.CT",
        "18B99, 68T27",
        "F.4.1; I.2.3"
      ],
      "primary_category": "cs.LO",
      "comment": "37 pages, 0 figures. Self-contained categorical framework built\n  directly on Mac Lane and Bourbaki; minimal references are intentional to\n  foreground the new construction",
      "pdf_url": "http://arxiv.org/pdf/2505.15344v1",
      "published_date": "2025-05-21 10:18:49 UTC",
      "updated_date": "2025-05-21 10:18:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:51:31.758313"
    },
    {
      "arxiv_id": "2505.15337v1",
      "title": "Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Fang",
        "Jiawei Kong",
        "Tianqu Zhuang",
        "Yixiang Qiu",
        "Kuofeng Gao",
        "Bin Chen",
        "Shu-Tao Xia",
        "Yaowei Wang",
        "Min Zhang"
      ],
      "abstract": "The misuse of large language models (LLMs), such as academic plagiarism, has\ndriven the development of detectors to identify LLM-generated texts. To bypass\nthese detectors, paraphrase attacks have emerged to purposely rewrite these\ntexts to evade detection. Despite the success, existing methods require\nsubstantial data and computational budgets to train a specialized paraphraser,\nand their attack efficacy greatly reduces when faced with advanced detection\nalgorithms. To address this, we propose \\textbf{Co}ntrastive\n\\textbf{P}araphrase \\textbf{A}ttack (CoPA), a training-free method that\neffectively deceives text detectors using off-the-shelf LLMs. The first step is\nto carefully craft instructions that encourage LLMs to produce more human-like\ntexts. Nonetheless, we observe that the inherent statistical biases of LLMs can\nstill result in some generated texts carrying certain machine-like attributes\nthat can be captured by detectors. To overcome this, CoPA constructs an\nauxiliary machine-like word distribution as a contrast to the human-like\ndistribution generated by the LLM. By subtracting the machine-like patterns\nfrom the human-like distribution during the decoding process, CoPA is able to\nproduce sentences that are less discernible by text detectors. Our theoretical\nanalysis suggests the superiority of the proposed attack. Extensive experiments\nvalidate the effectiveness of CoPA in fooling text detectors across various\nscenarios.",
      "tldr_zh": "本研究探讨了如何利用大型语言模型（LLMs）规避 LLM 生成文本检测器，提出了一种无需训练的攻击方法：CoPA（Contrastive Paraphrase Attack）。CoPA 通过精心设计的指令引导 LLMs 生成更像人类的文本，同时构建一个辅助的机器-like 词分布作为对比，在解码过程中减去机器特征，以降低检测可能性。理论分析证明了该方法的优越性，广泛实验显示 CoPA 在各种场景下有效欺骗文本检测器，提升了攻击效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15337v1",
      "published_date": "2025-05-21 10:08:39 UTC",
      "updated_date": "2025-05-21 10:08:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:51:44.672462"
    },
    {
      "arxiv_id": "2505.15333v1",
      "title": "Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Zhang",
        "Xiangnan Ma",
        "Kaiqi Kou",
        "Peizhuo Liu",
        "Weiqiao Shan",
        "Benyou Wang",
        "Tong Xiao",
        "Yuxin Huang",
        "Zhengtao Yu",
        "Jingbo Zhu"
      ],
      "abstract": "The success of building textless speech-to-speech translation (S2ST) models\nhas attracted much attention. However, S2ST still faces two main challenges: 1)\nextracting linguistic features for various speech signals, called cross-modal\n(CM), and 2) learning alignment of difference languages in long sequences,\ncalled cross-lingual (CL). We propose the unit language to overcome the two\nmodeling challenges. The unit language can be considered a text-like\nrepresentation format, constructed using $n$-gram language modeling. We\nimplement multi-task learning to utilize the unit language in guiding the\nspeech modeling process. Our initial results reveal a conflict when applying\nsource and target unit languages simultaneously. We propose task prompt\nmodeling to mitigate this conflict. We conduct experiments on four languages of\nthe Voxpupil dataset. Our method demonstrates significant improvements over a\nstrong baseline and achieves performance comparable to models trained with\ntext.",
      "tldr_zh": "该论文针对无文本语音到语音翻译（Speech-to-Speech Translation, S2ST）中的两大挑战——提取跨模态（cross-modal, CM）语言特征和学习跨语言（cross-lingual, CL）序列对齐——提出使用 unit language 作为一种基于 n-gram language modeling 的文本-like 表示格式。作者采用多任务学习（multi-task learning）来指导语音建模过程，但发现同时应用源和目标 unit language 会导致冲突，因此引入 task prompt modeling 来缓解这一问题。在 Voxpupil 数据集的四个语言上进行实验，结果显示该方法显著优于强基线模型，并实现与基于文本训练的模型相当的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.15333v1",
      "published_date": "2025-05-21 10:05:25 UTC",
      "updated_date": "2025-05-21 10:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:51:56.629637"
    },
    {
      "arxiv_id": "2505.15311v1",
      "title": "Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning",
      "title_zh": "轨迹 Bellman 残差最小化：一种简单的基于价值的方法用于 LLM 推理",
      "authors": [
        "Yurun Yuan",
        "Fan Chen",
        "Zeyu Jia",
        "Alexander Rakhlin",
        "Tengyang Xie"
      ],
      "abstract": "Policy-based methods currently dominate reinforcement learning (RL) pipelines\nfor large language model (LLM) reasoning, leaving value-based approaches\nlargely unexplored. We revisit the classical paradigm of Bellman Residual\nMinimization and introduce Trajectory Bellman Residual Minimization (TBRM), an\nalgorithm that naturally adapts this idea to LLMs, yielding a simple yet\neffective off-policy algorithm that optimizes a single trajectory-level Bellman\nobjective using the model's own logits as $Q$-values. TBRM removes the need for\ncritics, importance-sampling ratios, or clipping, and operates with only one\nrollout per prompt. We prove convergence to the near-optimal KL-regularized\npolicy from arbitrary off-policy data via an improved\nchange-of-trajectory-measure analysis. Experiments on standard\nmathematical-reasoning benchmarks show that TBRM consistently outperforms\npolicy-based baselines, like PPO and GRPO, with comparable or lower\ncomputational and memory overhead. Our results indicate that value-based RL\nmight be a principled and efficient alternative for enhancing reasoning\ncapabilities in LLMs.",
      "tldr_zh": "本研究重新审视了强化学习（RL）在大型语言模型（LLMs）推理中的应用，引入了Trajectory Bellman Residual Minimization (TBRM)算法，这是一种简单的value-based方法，基于Bellman Residual Minimization原理，使用模型自身的logits作为Q-values来优化轨迹级别的目标。TBRM无需critics、importance-sampling ratios或clipping，仅需每个提示一个rollout，便能从任意off-policy数据收敛到近似最优的KL-regularized policy。实验结果显示，在标准数学推理基准上，TBRM比政策-based基线如PPO和GRPO表现出色，同时计算和内存开销相当或更低，表明value-based RL可能是提升LLMs推理能力的有效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15311v1",
      "published_date": "2025-05-21 09:41:53 UTC",
      "updated_date": "2025-05-21 09:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:52:07.583888"
    },
    {
      "arxiv_id": "2505.15308v1",
      "title": "BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Guo",
        "Xiaolei Wen",
        "Wenbo Jiang",
        "Cheng Huang",
        "Jinjin Li",
        "Hongwei Li"
      ],
      "abstract": "With the widespread application of super-resolution (SR) in various fields,\nresearchers have begun to investigate its security. Previous studies have\ndemonstrated that SR models can also be subjected to backdoor attacks through\ndata poisoning, affecting downstream tasks. A backdoor SR model generates an\nattacker-predefined target image when given a triggered image while producing a\nnormal high-resolution (HR) output for clean images. However, prior backdoor\nattacks on SR models have primarily focused on the stealthiness of poisoned\nlow-resolution (LR) images while ignoring the stealthiness of poisoned HR\nimages, making it easy for users to detect anomalous data. To address this\nproblem, we propose BadSR, which improves the stealthiness of poisoned HR\nimages. The key idea of BadSR is to approximate the clean HR image and the\npre-defined target image in the feature space while ensuring that modifications\nto the clean HR image remain within a constrained range. The poisoned HR images\ngenerated by BadSR can be integrated with existing triggers. To further improve\nthe effectiveness of BadSR, we design an adversarially optimized trigger and a\nbackdoor gradient-driven poisoned sample selection method based on a genetic\nalgorithm. The experimental results show that BadSR achieves a high attack\nsuccess rate in various models and data sets, significantly affecting\ndownstream tasks.",
      "tldr_zh": "本文提出BadSR，一种针对图像Super-Resolution (SR) 模型的隐蔽标签后门攻击方法，旨在解决现有攻击忽略高分辨率 (HR) 图像隐蔽性问题，导致数据易被检测。BadSR的关键思路是在特征空间逼近干净HR图像和预定义目标图像，同时确保修改幅度受约束，并可整合现有触发器；此外，该方法还引入对抗优化触发器和基于遗传算法的背门梯度驱动毒样选择策略，以提升攻击有效性。实验结果表明，BadSR在多种模型和数据集上实现了高攻击成功率，并显著影响下游任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15308v1",
      "published_date": "2025-05-21 09:36:35 UTC",
      "updated_date": "2025-05-21 09:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:52:19.696979"
    },
    {
      "arxiv_id": "2505.15306v1",
      "title": "Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Song",
        "Qianyue Hao",
        "Qingmin Liao",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Model ensemble is a useful approach in reinforcement learning (RL) for\ntraining effective agents. Despite wide success of RL, training effective\nagents remains difficult due to the multitude of factors requiring careful\ntuning, such as algorithm selection, hyperparameter settings, and even random\nseed choices, all of which can significantly influence an agent's performance.\nModel ensemble helps overcome this challenge by combining multiple weak agents\ninto a single, more powerful one, enhancing overall performance. However,\nexisting ensemble methods, such as majority voting and Boltzmann addition, are\ndesigned as fixed strategies and lack a semantic understanding of specific\ntasks, limiting their adaptability and effectiveness. To address this, we\npropose LLM-Ens, a novel approach that enhances RL model ensemble with\ntask-specific semantic understandings driven by large language models (LLMs).\nGiven a task, we first design an LLM to categorize states in this task into\ndistinct 'situations', incorporating high-level descriptions of the task\nconditions. Then, we statistically analyze the strengths and weaknesses of each\nindividual agent to be used in the ensemble in each situation. During the\ninference time, LLM-Ens dynamically identifies the changing task situation and\nswitches to the agent that performs best in the current situation, ensuring\ndynamic model selection in the evolving task condition. Our approach is\ndesigned to be compatible with agents trained with different random seeds,\nhyperparameter settings, and various RL algorithms. Extensive experiments on\nthe Atari benchmark show that LLM-Ens significantly improves the RL model\nensemble, surpassing well-known baselines by up to 20.9%. For reproducibility,\nour code is open-source at\nhttps://anonymous.4open.science/r/LLM4RLensemble-F7EE.",
      "tldr_zh": "该研究提出 LLM-Ens，一种创新方法，利用 Large Language Models (LLMs) 增强强化学习 (RL) 模型集成，通过任务特定的语义理解将多个弱代理整合成更强大的单一代理。方法包括使用 LLM 将任务状态分类为不同 'situations'，分析每个代理在这些情况下的优缺点，并在推理时动态切换到表现最佳的代理，以适应任务变化。该方法兼容各种 RL 算法、超参数和随机种子，在 Atari 基准测试中比传统基线提升高达 20.9%，证明了其在提高 RL 代理有效性的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15306v1",
      "published_date": "2025-05-21 09:35:43 UTC",
      "updated_date": "2025-05-21 09:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:52:31.402554"
    },
    {
      "arxiv_id": "2505.15303v1",
      "title": "Laplace Sample Information: Data Informativeness Through a Bayesian Lens",
      "title_zh": "Laplace Sample Information：通过贝叶斯视角的数据信息性",
      "authors": [
        "Johannes Kaiser",
        "Kristian Schwethelm",
        "Daniel Rueckert",
        "Georgios Kaissis"
      ],
      "abstract": "Accurately estimating the informativeness of individual samples in a dataset\nis an important objective in deep learning, as it can guide sample selection,\nwhich can improve model efficiency and accuracy by removing redundant or\npotentially harmful samples. We propose Laplace Sample Information (LSI)\nmeasure of sample informativeness grounded in information theory widely\napplicable across model architectures and learning settings. LSI leverages a\nBayesian approximation to the weight posterior and the KL divergence to measure\nthe change in the parameter distribution induced by a sample of interest from\nthe dataset. We experimentally show that LSI is effective in ordering the data\nwith respect to typicality, detecting mislabeled samples, measuring class-wise\ninformativeness, and assessing dataset difficulty. We demonstrate these\ncapabilities of LSI on image and text data in supervised and unsupervised\nsettings. Moreover, we show that LSI can be computed efficiently through probes\nand transfers well to the training of large models.",
      "tldr_zh": "本文提出 Laplace Sample Information (LSI)，一种基于贝叶斯视角的信息理论方法，用于评估数据集样本的信息量，从而指导样本选择以提升模型效率和准确性。LSI 通过 Laplace 近似权重后验和 KL divergence 计算样本对参数分布的改变影响，适用于各种模型架构和学习设置。实验结果显示，LSI 有效排序数据、检测错误标记样本、测量类别信息量和评估数据集难度，并在图像及文本数据的监督和无监督环境中表现出色，且计算高效，可转移到大型模型训练中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15303v1",
      "published_date": "2025-05-21 09:34:27 UTC",
      "updated_date": "2025-05-21 09:34:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:52:42.297543"
    },
    {
      "arxiv_id": "2505.15293v1",
      "title": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyue Hao",
        "Yiwen Song",
        "Qingmin Liao",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Policy exploration is critical in reinforcement learning (RL), where existing\napproaches include greedy, Gaussian process, etc. However, these approaches\nutilize preset stochastic processes and are indiscriminately applied in all\nkinds of RL tasks without considering task-specific features that influence\npolicy exploration. Moreover, during RL training, the evolution of such\nstochastic processes is rigid, which typically only incorporates a decay in the\nvariance, failing to adjust flexibly according to the agent's real-time\nlearning status. Inspired by the analyzing and reasoning capability of large\nlanguage models (LLMs), we design LLM-Explorer to adaptively generate\ntask-specific exploration strategies with LLMs, enhancing the policy\nexploration in RL. In our design, we sample the learning trajectory of the\nagent during the RL training in a given task and prompt the LLM to analyze the\nagent's current policy learning status and then generate a probability\ndistribution for future policy exploration. Updating the probability\ndistribution periodically, we derive a stochastic process specialized for the\nparticular task and dynamically adjusted to adapt to the learning process. Our\ndesign is a plug-in module compatible with various widely applied RL\nalgorithms, including the DQN series, DDPG, TD3, and any possible variants\ndeveloped based on them. Through extensive experiments on the Atari and MuJoCo\nbenchmarks, we demonstrate LLM-Explorer's capability to enhance RL policy\nexploration, achieving an average performance improvement up to 37.27%. Our\ncode is open-source at https://anonymous.4open.science/r/LLM-Explorer-19BE for\nreproducibility.",
      "tldr_zh": "该论文提出LLM-Explorer，一种基于大型语言模型(LLMs)的插件式模块，用于增强强化学习(RL)中的策略探索问题。LLM-Explorer通过采样代理的学习轨迹，提示LLMs分析当前学习状态并生成任务特定的概率分布，从而动态调整随机过程，使探索策略更灵活适应RL任务。实验结果显示，该方法兼容多种RL算法（如DQN系列、DDPG和TD3），在Atari和MuJoCo基准测试中平均性能提升达37.27%，代码已开源以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15293v1",
      "published_date": "2025-05-21 09:24:23 UTC",
      "updated_date": "2025-05-21 09:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:52:56.373125"
    },
    {
      "arxiv_id": "2505.15285v1",
      "title": "Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction",
      "title_zh": "重新审视基于深度学习的网格重建中的模板网格",
      "authors": [
        "Fengting Zhang",
        "Boxu Liang",
        "Qinghao Liu",
        "Min Liu",
        "Xiang Chen",
        "Yaonan Wang"
      ],
      "abstract": "Mesh reconstruction is a cornerstone process across various applications,\nincluding in-silico trials, digital twins, surgical planning, and navigation.\nRecent advancements in deep learning have notably enhanced mesh reconstruction\nspeeds. Yet, traditional methods predominantly rely on deforming a standardised\ntemplate mesh for individual subjects, which overlooks the unique anatomical\nvariations between them, and may compromise the fidelity of the\nreconstructions. In this paper, we propose an adaptive-template-based mesh\nreconstruction network (ATMRN), which generates adaptive templates from the\ngiven images for the subsequent deformation, moving beyond the constraints of a\nsingular, fixed template. Our approach, validated on cortical magnetic\nresonance (MR) images from the OASIS dataset, sets a new benchmark in\nvoxel-to-cortex mesh reconstruction, achieving an average symmetric surface\ndistance of 0.267mm across four cortical structures. Our proposed method is\ngeneric and can be easily transferred to other image modalities and anatomical\nstructures.",
      "tldr_zh": "本文重新审视了深度学习-based mesh reconstruction 中的模板网格问题，指出传统方法依赖固定模板会忽略个体解剖差异，从而影响重建的精确性。作者提出了一种自适应模板网格重建网络(ATMRN)，该网络从给定图像生成自适应模板，并进行后续变形，以提升重建的忠实度。在OASIS数据集的皮层磁共振(MR)图像上验证，ATMRN实现了平均symmetric surface distance为0.267mm的新基准。该方法通用，可轻松转移到其他图像模态和解剖结构。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15285v1",
      "published_date": "2025-05-21 09:10:31 UTC",
      "updated_date": "2025-05-21 09:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:53:08.681989"
    },
    {
      "arxiv_id": "2505.15276v1",
      "title": "When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning",
      "title_zh": "大型推理模型何时能节省思考？ 推理中行为分歧的机制分析",
      "authors": [
        "Rongzhi Zhu",
        "Yi Liu",
        "Zequn Sun",
        "Yiwei Wang",
        "Wei Hu"
      ],
      "abstract": "Large reasoning models (LRMs) have significantly advanced performance on\ncomplex tasks, yet their tendency to overthink introduces inefficiencies. This\nstudy investigates the internal mechanisms of reinforcement learning\n(RL)-trained LRMs when prompted to save thinking, revealing three distinct\nthinking modes: no thinking (NT), explicit thinking (ET), and implicit thinking\n(IT). Through comprehensive analysis of confidence in thinking termination,\nattention from thinking to generation, and attentional focus on input sections,\nwe uncover key factors influencing the reasoning behaviors. We further find\nthat NT reduces output length at the cost of accuracy, while ET and IT maintain\naccuracy with reduced response length. Our findings expose fundamental\ninconsistencies in RL-optimized LRMs, necessitating adaptive improvements for\nreliable efficiency.",
      "tldr_zh": "本研究分析了大型推理模型（LRMs）在被提示节省思考时的内部机制，揭示了强化学习（RL）训练下三种思考模式：无思考（NT）、显式思考（ET）和隐式思考（IT）。通过考察思考终止信心、从思考到生成的注意力以及对输入部分的注意力焦点，研究者识别了影响LRMs推理行为的关键因素。结果显示，NT模式虽能缩短输出长度但会降低准确性，而ET和IT模式在维持准确性的同时减少响应长度；这些发现暴露了RL优化LRMs的基本不一致性，并呼吁采用自适应改进以实现可靠的效率。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15276v1",
      "published_date": "2025-05-21 08:55:35 UTC",
      "updated_date": "2025-05-21 08:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:53:21.251259"
    },
    {
      "arxiv_id": "2505.15275v1",
      "title": "Learning-based Autonomous Oversteer Control and Collision Avoidance",
      "title_zh": "基于学习的自主过转向控制与碰撞避免",
      "authors": [
        "Seokjun Lee",
        "Seung-Hyun Kong"
      ],
      "abstract": "Oversteer, wherein a vehicle's rear tires lose traction and induce\nunintentional excessive yaw, poses critical safety challenges. Failing to\ncontrol oversteer often leads to severe traffic accidents. Although recent\nautonomous driving efforts have attempted to handle oversteer through\nstabilizing maneuvers, the majority rely on expert-defined trajectories or\nassume obstacle-free environments, limiting real-world applicability. This\npaper introduces a novel end-to-end (E2E) autonomous driving approach that\ntackles oversteer control and collision avoidance simultaneously. Existing E2E\ntechniques, including Imitation Learning (IL), Reinforcement Learning (RL), and\nHybrid Learning (HL), generally require near-optimal demonstrations or\nextensive experience. Yet even skilled human drivers struggle to provide\nperfect demonstrations under oversteer, and high transition variance hinders\naccumulating sufficient data. Hence, we present Q-Compared Soft Actor-Critic\n(QC-SAC), a new HL algorithm that effectively learns from suboptimal\ndemonstration data and adapts rapidly to new conditions. To evaluate QC-SAC, we\nintroduce a benchmark inspired by real-world driver training: a vehicle\nencounters sudden oversteer on a slippery surface and must avoid randomly\nplaced obstacles ahead. Experimental results show QC-SAC attains near-optimal\ndriving policies, significantly surpassing state-of-the-art IL, RL, and HL\nbaselines. Our method demonstrates the world's first safe autonomous oversteer\ncontrol with obstacle avoidance.",
      "tldr_zh": "本论文针对车辆 oversteer（后轮失控导致过度偏航）的安全挑战，提出了一种新型端到端 (E2E) 自主驾驶方法，该方法同时处理 oversteer 控制和 collision avoidance，以提升真实场景下的适用性。论文引入 Q-Compared Soft Actor-Critic (QC-SAC) 算法，这是一种 Hybrid Learning (HL) 技术，能够从次优示范数据中有效学习并快速适应新条件，克服了传统 Imitation Learning (IL) 和 Reinforcement Learning (RL) 的局限性。在模拟基准测试中，QC-SAC 实现了近优驾驶策略，准确率显著高于现有基线，并首次实现了安全的自主 oversteer 控制与障碍避让。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15275v1",
      "published_date": "2025-05-21 08:53:38 UTC",
      "updated_date": "2025-05-21 08:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:53:34.753649"
    },
    {
      "arxiv_id": "2505.15274v1",
      "title": "Identification of Probabilities of Causation: A Complete Characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Shu",
        "Shuai Wang",
        "Ang Li"
      ],
      "abstract": "Probabilities of causation are fundamental to modern decision-making. Pearl\nfirst introduced three binary probabilities of causation, and Tian and Pearl\nlater derived tight bounds for them using Balke's linear programming. The\ntheoretical characterization of probabilities of causation with multi-valued\ntreatments and outcomes has remained unresolved for decades, limiting the scope\nof causality-based decision-making. In this paper, we resolve this foundational\ngap by proposing a complete set of representative probabilities of causation\nand proving that they are sufficient to characterize all possible probabilities\nof causation within the framework of Structural Causal Models (SCMs). We then\nformally derive tight bounds for these representative quantities using formal\nmathematical proofs. Finally, we demonstrate the practical relevance of our\nresults through illustrative toy examples.",
      "tldr_zh": "本文对因果概率（Probabilities of Causation）的完全表征进行了研究，解决了多值处理和结果（multi-valued treatments and outcomes）领域长期未解的理论难题。作者提出了一套完整的代表性因果概率集合，并证明这些概率在 Structural Causal Models (SCMs) 框架下足以覆盖所有可能情况。接着，通过正式数学证明推导了这些代表性量的紧致界限（tight bounds）。最后，通过玩具例子展示了这些结果在因果决策中的实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15274v1",
      "published_date": "2025-05-21 08:50:12 UTC",
      "updated_date": "2025-05-21 08:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:53:44.651366"
    },
    {
      "arxiv_id": "2505.15270v1",
      "title": "Scaling Diffusion Transformers Efficiently via $μ$P",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Zheng",
        "Xinyu Zhang",
        "Rongzhen Wang",
        "Wei Huang",
        "Zhi Tian",
        "Weilin Huang",
        "Jun Zhu",
        "Chongxuan Li"
      ],
      "abstract": "Diffusion Transformers have emerged as the foundation for vision generative\nmodels, but their scalability is limited by the high cost of hyperparameter\n(HP) tuning at large scales. Recently, Maximal Update Parametrization ($\\mu$P)\nwas proposed for vanilla Transformers, which enables stable HP transfer from\nsmall to large language models, and dramatically reduces tuning costs. However,\nit remains unclear whether $\\mu$P of vanilla Transformers extends to diffusion\nTransformers, which differ architecturally and objectively. In this work, we\ngeneralize standard $\\mu$P to diffusion Transformers and validate its\neffectiveness through large-scale experiments. First, we rigorously prove that\n$\\mu$P of mainstream diffusion Transformers, including DiT, U-ViT,\nPixArt-$\\alpha$, and MMDiT, aligns with that of the vanilla Transformer,\nenabling the direct application of existing $\\mu$P methodologies. Leveraging\nthis result, we systematically demonstrate that DiT-$\\mu$P enjoys robust HP\ntransferability. Notably, DiT-XL-2-$\\mu$P with transferred learning rate\nachieves 2.9 times faster convergence than the original DiT-XL-2. Finally, we\nvalidate the effectiveness of $\\mu$P on text-to-image generation by scaling\nPixArt-$\\alpha$ from 0.04B to 0.61B and MMDiT from 0.18B to 18B. In both cases,\nmodels under $\\mu$P outperform their respective baselines while requiring small\ntuning cost, only 5.5% of one training run for PixArt-$\\alpha$ and 3% of\nconsumption by human experts for MMDiT-18B. These results establish $\\mu$P as a\nprincipled and efficient framework for scaling diffusion Transformers.",
      "tldr_zh": "本研究探讨了如何通过 Maximal Update Parametrization ($μ$P) 高效扩展 Diffusion Transformers，以降低超参数 (HP) 调优成本。作者证明了 $μ$P 可直接应用于主流 Diffusion Transformers（如 DiT、U-ViT、PixArt-α 和 MMDiT），并通过大规模实验验证其兼容性。实验结果显示，DiT-XL-2-$μ$P 的收敛速度比原版快 2.9 倍，且在文本到图像生成任务中，扩展后的 PixArt-α 和 MMDiT 模型性能优于基线，仅需 3-5.5% 的调优成本。这些发现确立了 $μ$P 作为一种可靠框架，用于提升 Diffusion Transformers 的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 10 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15270v1",
      "published_date": "2025-05-21 08:49:03 UTC",
      "updated_date": "2025-05-21 08:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:53:57.229361"
    },
    {
      "arxiv_id": "2505.15265v1",
      "title": "Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs",
      "title_zh": "盲点导航：针对 LVLMs 的敏感语义概念进化发现",
      "authors": [
        "Zihao Pan",
        "Yu Tong",
        "Weibin Wu",
        "Jingyi Wang",
        "Lifeng Chen",
        "Zhe Zhao",
        "Jiajia Wei",
        "Yitong Qiao",
        "Zibin Zheng"
      ],
      "abstract": "Adversarial attacks aim to generate malicious inputs that mislead deep\nmodels, but beyond causing model failure, they cannot provide certain\ninterpretable information such as ``\\textit{What content in inputs make models\nmore likely to fail?}'' However, this information is crucial for researchers to\nspecifically improve model robustness. Recent research suggests that models may\nbe particularly sensitive to certain semantics in visual inputs (such as\n``wet,'' ``foggy''), making them prone to errors. Inspired by this, in this\npaper we conducted the first exploration on large vision-language models\n(LVLMs) and found that LVLMs indeed are susceptible to hallucinations and\nvarious errors when facing specific semantic concepts in images. To efficiently\nsearch for these sensitive concepts, we integrated large language models (LLMs)\nand text-to-image (T2I) models to propose a novel semantic evolution framework.\nRandomly initialized semantic concepts undergo LLM-based crossover and mutation\noperations to form image descriptions, which are then converted by T2I models\ninto visual inputs for LVLMs. The task-specific performance of LVLMs on each\ninput is quantified as fitness scores for the involved semantics and serves as\nreward signals to further guide LLMs in exploring concepts that induce LVLMs.\nExtensive experiments on seven mainstream LVLMs and two multimodal tasks\ndemonstrate the effectiveness of our method. Additionally, we provide\ninteresting findings about the sensitive semantics of LVLMs, aiming to inspire\nfurther in-depth research.",
      "tldr_zh": "这篇论文探讨了大型视觉语言模型 (LVLMs) 对特定语义概念（如“wet”或“foggy”）的敏感性，这些概念可能导致模型出现幻觉和错误，从而影响鲁棒性。研究提出了一种创新的语义演化框架，利用大型语言模型 (LLMs) 和文本到图像 (T2I) 模型，通过交叉、变异操作生成图像描述，并以 LVLMs 的任务性能作为适应度分数来引导敏感概念的探索。实验在七个主流 LVLMs 和两个多模态任务上验证了框架的有效性，并揭示了 LVLMs 的敏感语义特性，为提升模型鲁棒性提供了关键见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15265v1",
      "published_date": "2025-05-21 08:45:43 UTC",
      "updated_date": "2025-05-21 08:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:54:08.609242"
    },
    {
      "arxiv_id": "2505.15256v1",
      "title": "Zero-Shot Gaze-based Volumetric Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Tatyana Shmykova",
        "Leila Khaertdinova",
        "Ilya Pershin"
      ],
      "abstract": "Accurate segmentation of anatomical structures in volumetric medical images\nis crucial for clinical applications, including disease monitoring and cancer\ntreatment planning. Contemporary interactive segmentation models, such as\nSegment Anything Model 2 (SAM-2) and its medical variant (MedSAM-2), rely on\nmanually provided prompts like bounding boxes and mouse clicks. In this study,\nwe introduce eye gaze as a novel informational modality for interactive\nsegmentation, marking the application of eye-tracking for 3D medical image\nsegmentation. We evaluate the performance of using gaze-based prompts with\nSAM-2 and MedSAM-2 using both synthetic and real gaze data. Compared to\nbounding boxes, gaze-based prompts offer a time-efficient interaction approach\nwith slightly lower segmentation quality. Our findings highlight the potential\nof using gaze as a complementary input modality for interactive 3D medical\nimage segmentation.",
      "tldr_zh": "本研究提出了一种Zero-Shot Gaze-based方法，用于体医图像的交互式分割，首次将眼部注视作为提示模态应用于3D医图像分割，以解决传统模型依赖手动提示（如边界框和鼠标点击）的局限性。研究评估了注视-based提示与SAM-2和MedSAM-2模型的性能，使用合成和真实注视数据进行测试。结果表明，与边界框相比，注视提示显著提高了交互效率，但分割质量略低，同时强调了注视作为交互式3D医图像分割的潜在补充输入模态。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to MMFM-BIOMED Workshop @ CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15256v1",
      "published_date": "2025-05-21 08:34:13 UTC",
      "updated_date": "2025-05-21 08:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:54:20.872521"
    },
    {
      "arxiv_id": "2505.15250v1",
      "title": "Margin-aware Fuzzy Rough Feature Selection: Bridging Uncertainty Characterization and Pattern Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Suping Xu",
        "Lin Shang",
        "Keyu Liu",
        "Hengrong Ju",
        "Xibei Yang",
        "Witold Pedrycz"
      ],
      "abstract": "Fuzzy rough feature selection (FRFS) is an effective means of addressing the\ncurse of dimensionality in high-dimensional data. By removing redundant and\nirrelevant features, FRFS helps mitigate classifier overfitting, enhance\ngeneralization performance, and lessen computational overhead. However, most\nexisting FRFS algorithms primarily focus on reducing uncertainty in pattern\nclassification, neglecting that lower uncertainty does not necessarily result\nin improved classification performance, despite it commonly being regarded as a\nkey indicator of feature selection effectiveness in the FRFS literature. To\nbridge uncertainty characterization and pattern classification, we propose a\nMargin-aware Fuzzy Rough Feature Selection (MAFRFS) framework that considers\nboth the compactness and separation of label classes. MAFRFS effectively\nreduces uncertainty in pattern classification tasks, while guiding the feature\nselection towards more separable and discriminative label class structures.\nExtensive experiments on 15 public datasets demonstrate that MAFRFS is highly\nscalable and more effective than FRFS. The algorithms developed using MAFRFS\noutperform six state-of-the-art feature selection algorithms.",
      "tldr_zh": "本研究针对模糊粗糙特征选择 (Fuzzy Rough Feature Selection, FRFS) 在处理高维数据维度诅咒时存在的局限性，指出现有算法虽减少不确定性但未直接提升分类性能。作者提出 Margin-aware Fuzzy Rough Feature Selection (MAFRFS) 框架，通过考虑标签类的紧凑性和分离性，来桥接不确定性表征与模式分类的关联，从而实现更有效的特征选择。实验在15个公共数据集上证明，MAFRFS 高度可扩展，并优于FRFS及其它六种最先进算法，在分类性能上表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15250v1",
      "published_date": "2025-05-21 08:26:20 UTC",
      "updated_date": "2025-05-21 08:26:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:54:33.614214"
    },
    {
      "arxiv_id": "2505.15245v1",
      "title": "Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Jiang",
        "Ben Liu",
        "Miao Peng",
        "Wenjie Xu",
        "Yao Xiao",
        "Zhenyan Shan",
        "Min Peng"
      ],
      "abstract": "While large language models (LLMs) show great potential in temporal\nreasoning, most existing work focuses heavily on enhancing performance, often\nneglecting the explainable reasoning processes underlying the results. To\naddress this gap, we introduce a comprehensive benchmark covering a wide range\nof temporal granularities, designed to systematically evaluate LLMs'\ncapabilities in explainable temporal reasoning. Furthermore, our findings\nreveal that LLMs struggle to deliver convincing explanations when relying\nsolely on textual information. To address challenge, we propose GETER, a novel\nstructure-aware generative framework that integrates Graph structures with text\nfor Explainable TEmporal Reasoning. Specifically, we first leverage temporal\nknowledge graphs to develop a temporal encoder that captures structural\ninformation for the query. Subsequently, we introduce a structure-text prefix\nadapter to map graph structure features into the text embedding space. Finally,\nLLMs generate explanation text by seamlessly integrating the soft graph token\nwith instruction-tuning prompt tokens. Experimental results indicate that GETER\nachieves state-of-the-art performance while also demonstrating its\neffectiveness as well as strong generalization capabilities. Our dataset and\ncode are available at https://github.com/carryTatum/GETER.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在时间推理中的可解释性不足问题，引入了一个全面基准，涵盖多种时间粒度，以系统评估LLMs的解释能力。研究发现，LLMs仅依赖文本信息无法提供可靠的解释，因此提出GETER框架——一个基于Graph structures的生成框架，通过temporal knowledge graphs的编码器捕获结构信息，并利用structure-text prefix adapter将图结构特征映射到文本嵌入空间，最终整合软图令牌与提示令牌生成解释文本。实验结果表明，GETER实现了state-of-the-art性能，并展示了出色的有效性和泛化能力，为可解释时间推理提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In Findings of the Association for Computational Linguistics: ACL\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15245v1",
      "published_date": "2025-05-21 08:20:35 UTC",
      "updated_date": "2025-05-21 08:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:54:47.183627"
    },
    {
      "arxiv_id": "2505.15242v2",
      "title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing",
      "title_zh": "自适应计划-执行框架用于智能合约安全审计",
      "authors": [
        "Zhiyuan Wei",
        "Jing Sun",
        "Zijian Zhang",
        "Zhe Hou",
        "Zixiao Zhao"
      ],
      "abstract": "Large Language Models (LLMs) have shown great promise in code analysis and\nauditing; however, they still struggle with hallucinations and limited\ncontext-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute\nframework that enhances smart contract security analysis through dynamic audit\nplanning and structured execution. Unlike conventional LLM-based auditing\napproaches that follow fixed workflows and predefined steps, SmartAuditFlow\ndynamically generates and refines audit plans based on the unique\ncharacteristics of each smart contract. It continuously adjusts its auditing\nstrategy in response to intermediate LLM outputs and newly detected\nvulnerabilities, ensuring a more adaptive and precise security assessment. The\nframework then executes these plans step by step, applying a structured\nreasoning process to enhance vulnerability detection accuracy while minimizing\nhallucinations and false positives. To further improve audit precision,\nSmartAuditFlow integrates iterative prompt optimization and external knowledge\nsources, such as static analysis tools and Retrieval-Augmented Generation\n(RAG). This ensures audit decisions are contextually informed and backed by\nreal-world security knowledge, producing comprehensive security reports.\nExtensive evaluations across multiple benchmarks demonstrate that\nSmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on\ncommon and critical vulnerabilities, 41.2 percent accuracy for comprehensive\ncoverage of known smart contract weaknesses in real-world projects, and\nsuccessfully identifying all 13 tested CVEs. These results highlight\nSmartAuditFlow's scalability, cost-effectiveness, and superior adaptability\nover traditional static analysis tools and contemporary LLM-based approaches,\nestablishing it as a robust solution for automated smart contract auditing.",
      "tldr_zh": "本研究提出SmartAuditFlow，一种自适应Plan-Execute框架，用于提升智能合约安全审计，通过动态生成和优化审计计划来应对Large Language Models (LLMs) 的幻觉和上下文推理限制。该框架根据合约特性实时调整策略，结合结构化执行、迭代提示优化以及外部知识来源（如静态分析工具和Retrieval-Augmented Generation (RAG)），从而提高漏洞检测准确性和减少假阳性。实验结果显示，SmartAuditFlow在多个基准上优于现有方法，实现了100%准确率在常见漏洞上、41.2%在全面覆盖上，并成功识别所有13个测试的CVE，展示了其可扩展性、成本效益和适应性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "30 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15242v2",
      "published_date": "2025-05-21 08:18:41 UTC",
      "updated_date": "2025-05-22 06:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:54:56.993487"
    },
    {
      "arxiv_id": "2505.15240v1",
      "title": "Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge",
      "title_zh": "翻译失败",
      "authors": [
        "Yassir Fathullah",
        "Mark J. F. Gales"
      ],
      "abstract": "This paper explores generalised probabilistic modelling and uncertainty\nestimation in comparative LLM-as-a-judge frameworks. We show that existing\nProduct-of-Experts methods are specific cases of a broader framework, enabling\ndiverse modelling options. Furthermore, we propose improved uncertainty\nestimates for individual comparisons, enabling more efficient selection and\nachieving strong performance with fewer evaluations. We also introduce a method\nfor estimating overall ranking uncertainty. Finally, we demonstrate that\ncombining absolute and comparative scoring improves performance. Experiments\nshow that the specific expert model has a limited impact on final rankings but\nour proposed uncertainty estimates, especially the probability of reordering,\nsignificantly improve the efficiency of systems reducing the number of needed\ncomparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used\nto identify low-performing predictions, where the nature of the probabilistic\nmodel has a notable impact on the quality of the overall uncertainty.",
      "tldr_zh": "这篇论文探讨了在比较性 LLM-as-a-judge 框架中广义的概率建模和改进的不确定性估计，展示了现有的 Product-of-Experts 方法是更广泛框架的特定案例，从而支持多样化的建模选项。作者提出了增强的单个比较不确定性估计方法，以更高效地选择模型，并引入了估计整体排名不确定性的新方法，同时证明了结合绝对和比较评分能提升性能。实验显示，特定专家模型对最终排名影响有限，但提出的不确定性估计（如重新排序概率）显著提高了效率，减少了约50%的比较次数，并能通过排名级不确定性指标有效识别低性能预测。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in UAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15240v1",
      "published_date": "2025-05-21 08:16:18 UTC",
      "updated_date": "2025-05-21 08:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:55:09.018741"
    },
    {
      "arxiv_id": "2505.15239v1",
      "title": "Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Súkeník",
        "Christoph H. Lampert",
        "Marco Mondelli"
      ],
      "abstract": "The empirical emergence of neural collapse -- a surprising symmetry in the\nfeature representations of the training data in the penultimate layer of deep\nneural networks -- has spurred a line of theoretical research aimed at its\nunderstanding. However, existing work focuses on data-agnostic models or, when\ndata structure is taken into account, it remains limited to multi-layer\nperceptrons. Our paper fills both these gaps by analyzing modern architectures\nin a data-aware regime: we prove that global optima of deep regularized\ntransformers and residual networks (ResNets) with LayerNorm trained with cross\nentropy or mean squared error loss are approximately collapsed, and the\napproximation gets tighter as the depth grows. More generally, we formally\nreduce any end-to-end large-depth ResNet or transformer training into an\nequivalent unconstrained features model, thus justifying its wide use in the\nliterature even beyond data-agnostic settings. Our theoretical results are\nsupported by experiments on computer vision and language datasets showing that,\nas the depth grows, neural collapse indeed becomes more prominent.",
      "tldr_zh": "该研究证明了在深度正则化的 ResNets 和 Transformers 中，neural collapse（一种训练数据特征表示的对称现象）是全局最优解，随着网络深度增加，这种近似性会变得更精确。论文通过理论分析，将端到端训练的深度 ResNet 或 Transformer 简化为等价的无约束特征模型，从而扩展了neural collapse的理解。实验结果显示，在计算机视觉和语言数据集上，随着深度增长，neural collapse现象确实更加显著，支持了该理论框架的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15239v1",
      "published_date": "2025-05-21 08:16:03 UTC",
      "updated_date": "2025-05-21 08:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:55:20.135836"
    },
    {
      "arxiv_id": "2505.15234v1",
      "title": "SAMA-UNet: Enhancing Medical Image Segmentation with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Saqib Qamar",
        "Mohd Fazil",
        "Parvez Ahmad",
        "Ghulam Muhammad"
      ],
      "abstract": "Medical image segmentation plays an important role in various clinical\napplications, but existing models often struggle with the computational\ninefficiencies and challenges posed by complex medical data. State Space\nSequence Models (SSMs) have demonstrated promise in modeling long-range\ndependencies with linear computational complexity, yet their application in\nmedical image segmentation remains hindered by incompatibilities with image\ntokens and autoregressive assumptions. Moreover, it is difficult to achieve a\nbalance in capturing both local fine-grained information and global semantic\ndependencies. To address these challenges, we introduce SAMA-UNet, a novel\narchitecture for medical image segmentation. A key innovation is the\nSelf-Adaptive Mamba-like Aggregated Attention (SAMA) block, which integrates\ncontextual self-attention with dynamic weight modulation to prioritise the most\nrelevant features based on local and global contexts. This approach reduces\ncomputational complexity and improves the representation of complex image\nfeatures across multiple scales. We also suggest the Causal-Resonance\nMulti-Scale Module (CR-MSM), which enhances the flow of information between the\nencoder and decoder by using causal resonance learning. This mechanism allows\nthe model to automatically adjust feature resolution and causal dependencies\nacross scales, leading to better semantic alignment between the low-level and\nhigh-level features in U-shaped architectures. Experiments on MRI, CT, and\nendoscopy images show that SAMA-UNet performs better in segmentation accuracy\nthan current methods using CNN, Transformer, and Mamba. The implementation is\npublicly available at GitHub.",
      "tldr_zh": "本研究针对医疗图像分割的计算效率和复杂数据挑战，提出了一种新型架构SAMA-UNet，以解决State Space Sequence Models (SSMs)在图像处理中的兼容性问题和局部与全局信息平衡难题。SAMA-UNet的关键创新包括Self-Adaptive Mamba-like Aggregated Attention (SAMA)块，该模块通过上下文自注意力与动态权重调制，优先处理相关特征，降低计算复杂性并提升多尺度图像表示；以及Causal-Resonance Multi-Scale Module (CR-MSM)，通过因果共振学习增强编码器与解码器间的信息流，实现特征分辨率和语义对齐的自动调整。在MRI、CT和内窥镜图像的实验中，SAMA-UNet在分割准确性上优于CNN、Transformer和Mamba等现有方法，代码已在GitHub上公开。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15234v1",
      "published_date": "2025-05-21 08:12:31 UTC",
      "updated_date": "2025-05-21 08:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:55:33.718489"
    },
    {
      "arxiv_id": "2505.15216v1",
      "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Andy K. Zhang",
        "Joey Ji",
        "Celeste Menders",
        "Riya Dulepet",
        "Thomas Qin",
        "Ron Y. Wang",
        "Junrong Wu",
        "Kyleen Liao",
        "Jiliang Li",
        "Jinghan Hu",
        "Sara Hong",
        "Nardos Demilew",
        "Shivatmica Murgai",
        "Jason Tran",
        "Nishka Kacheria",
        "Ethan Ho",
        "Denis Liu",
        "Lauren McLane",
        "Olivia Bruvik",
        "Dai-Rong Han",
        "Seungwoo Kim",
        "Akhil Vyas",
        "Cuiyuanxiu Chen",
        "Ryan Li",
        "Weiran Xu",
        "Jonathan Z. Ye",
        "Prerit Choudhary",
        "Siddharth M. Bhatia",
        "Vikram Sivashankar",
        "Yuxuan Bao",
        "Dawn Song",
        "Dan Boneh",
        "Daniel E. Ho",
        "Percy Liang"
      ],
      "abstract": "AI agents have the potential to significantly alter the cybersecurity\nlandscape. To help us understand this change, we introduce the first framework\nto capture offensive and defensive cyber-capabilities in evolving real-world\nsystems. Instantiating this framework with BountyBench, we set up 25 systems\nwith complex, real-world codebases. To capture the vulnerability lifecycle, we\ndefine three task types: Detect (detecting a new vulnerability), Exploit\n(exploiting a specific vulnerability), and Patch (patching a specific\nvulnerability). For Detect, we construct a new success indicator, which is\ngeneral across vulnerability types and provides localized evaluation. We\nmanually set up the environment for each system, including installing packages,\nsetting up server(s), and hydrating database(s). We add 40 bug bounties, which\nare vulnerabilities with monetary awards from \\$10 to \\$30,485, and cover 9 of\nthe OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy\nbased on information to guide detection, interpolating from identifying a zero\nday to exploiting a specific vulnerability. We evaluate 5 agents: Claude Code,\nOpenAI Codex CLI, and custom agents with GPT-4.1, Gemini 2.5 Pro Preview, and\nClaude 3.7 Sonnet Thinking. Given up to three attempts, the top-performing\nagents are Claude Code (5% on Detect, mapping to \\$1,350), Custom Agent with\nClaude 3.7 Sonnet Thinking (5% on Detect, mapping to \\$1,025; 67.5% on\nExploit), and OpenAI Codex CLI (5% on Detect, mapping to \\$2,400; 90% on Patch,\nmapping to \\$14,422). OpenAI Codex CLI and Claude Code are more capable at\ndefense, achieving higher Patch scores of 90% and 87.5%, compared to Exploit\nscores of 32.5% and 57.5% respectively; in contrast, the custom agents are\nrelatively balanced between offense and defense, achieving Exploit scores of\n40-67.5% and Patch scores of 45-60%.",
      "tldr_zh": "该研究引入了BountyBench框架，用于评估AI代理在真实网络安全系统中的进攻和防御能力，量化其经济影响。框架定义了三个任务类型：Detect（检测新漏洞）、Exploit（利用特定漏洞）和Patch（修复特定漏洞），并在25个复杂真实代码库系统中设置了40个bug bounties，覆盖OWASP Top 10 Risks。实验评估了5个AI代理，如Claude Code和OpenAI Codex CLI，结果显示OpenAI Codex CLI在Patch任务上表现最佳（90%，对应$14,422经济影响），而代理在防御（如Patch）上整体优于进攻（如Exploit），突显了AI在网络安全领域的潜在优势和平衡挑战。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "78 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15216v1",
      "published_date": "2025-05-21 07:44:52 UTC",
      "updated_date": "2025-05-21 07:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:55:45.548058"
    },
    {
      "arxiv_id": "2505.15206v1",
      "title": "EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Kit Ng",
        "Long Bai",
        "Guankun Wang",
        "Yupeng Wang",
        "Huxin Gao",
        "Kun Yuan",
        "Chenhan Jin",
        "Tieyong Zeng",
        "Hongliang Ren"
      ],
      "abstract": "In endoscopic procedures, autonomous tracking of abnormal regions and\nfollowing circumferential cutting markers can significantly reduce the\ncognitive burden on endoscopists. However, conventional model-based pipelines\nare fragile for each component (e.g., detection, motion planning) requires\nmanual tuning and struggles to incorporate high-level endoscopic intent,\nleading to poor generalization across diverse scenes. Vision-Language-Action\n(VLA) models, which integrate visual perception, language grounding, and motion\nplanning within an end-to-end framework, offer a promising alternative by\nsemantically adapting to surgeon prompts without manual recalibration. Despite\ntheir potential, applying VLA models to robotic endoscopy presents unique\nchallenges due to the complex and dynamic anatomical environments of the\ngastrointestinal (GI) tract. To address this, we introduce EndoVLA, designed\nspecifically for continuum robots in GI interventions. Given endoscopic images\nand surgeon-issued tracking prompts, EndoVLA performs three core tasks: (1)\npolyp tracking, (2) delineation and following of abnormal mucosal regions, and\n(3) adherence to circular markers during circumferential cutting. To tackle\ndata scarcity and domain shifts, we propose a dual-phase strategy comprising\nsupervised fine-tuning on our EndoVLA-Motion dataset and reinforcement\nfine-tuning with task-aware rewards. Our approach significantly improves\ntracking performance in endoscopy and enables zero-shot generalization in\ndiverse scenes and complex sequential tasks.",
      "tldr_zh": "本文提出EndoVLA，一种双阶段Vision-Language-Action (VLA) 模型，旨在实现内镜手术中的自主跟踪，包括息肉跟踪、异常粘膜区域描绘及环形标记遵循，从而减轻内镜医生的认知负担。EndoVLA将视觉感知、语言接地和运动规划整合到端到端框架中，并采用监督微调（基于EndoVLA-Motion数据集）和强化微调（使用任务感知奖励）的双阶段策略，以应对数据稀缺和领域偏移问题。实验结果显示，该模型显著提升跟踪性能，并实现零样本泛化，在多样场景和复杂顺序任务中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15206v1",
      "published_date": "2025-05-21 07:35:00 UTC",
      "updated_date": "2025-05-21 07:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:55:58.256223"
    },
    {
      "arxiv_id": "2505.15201v1",
      "title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems",
      "title_zh": "Pass@K 策略优化：解决更难的强化学习问题",
      "authors": [
        "Christian Walder",
        "Deep Karkhanis"
      ],
      "abstract": "Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts\nfor each problem and reward them independently. This optimizes for pass@1\nperformance and prioritizes the strength of isolated samples at the expense of\nthe diversity and collective utility of sets of samples. This under-utilizes\nthe sampling capacity, limiting exploration and eventual improvement on harder\nexamples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a\ntransformation on the final rewards which leads to direct optimization of\npass@k performance, thus optimizing for sets of samples that maximize reward\nwhen considered jointly. Our contribution is to derive novel low variance\nunbiased estimators for pass@k and its gradient, in both the binary and\ncontinuous reward settings. We show optimization with our estimators reduces to\nstandard RL with rewards that have been jointly transformed by a stable and\nefficient transformation function.\n  While previous efforts are restricted to k=n, ours is the first to enable\nrobust optimization of pass@k for any arbitrary k <= n. Moreover, instead of\ntrading off pass@1 performance for pass@k gains, our method allows annealing k\nduring training, optimizing both metrics and often achieving strong pass@1\nnumbers alongside significant pass@k gains.\n  We validate our reward transformations on toy experiments, which reveal the\nvariance reducing properties of our formulations. We also include real-world\nexamples using the open-source LLM, GEMMA-2. We find that our transformation\neffectively optimizes for the target k. Furthermore, higher k values enable\nsolving more and harder problems, while annealing k boosts both the pass@1 and\npass@k . Crucially, for challenging task sets where conventional pass@1\noptimization stalls, our pass@k approach unblocks learning, likely due to\nbetter exploration by prioritizing joint utility over the utility of individual\nsamples.",
      "tldr_zh": "本研究针对强化学习（RL）算法的传统优化问题，即只针对单个样本的 pass@1 性能进行优化，导致探索不足和难题难以解决，提出了一种 Pass-at-k Policy Optimization (PKPO) 方法。该方法通过对奖励进行联合转换，直接优化 pass@k 性能，从而提升样本集的多样性和集体效用。贡献包括推导低方差无偏估计器，支持任意 k ≤ n，并引入 k 退火（annealing k）策略，以同时提升 pass@1 和 pass@k 表现。实验在玩具任务和真实场景（如使用 GEMMA-2 的 LLM）中验证，PKPO 能解决更难问题，提高探索效率，并在传统优化停滞时显著提升整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15201v1",
      "published_date": "2025-05-21 07:26:36 UTC",
      "updated_date": "2025-05-21 07:26:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:56:09.254751"
    },
    {
      "arxiv_id": "2505.15197v1",
      "title": "Intentional Gesture: Deliver Your Intentions with Gestures for Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Pinxin Liu",
        "Haiyang Liu",
        "Luchuan Song",
        "Chenliang Xu"
      ],
      "abstract": "When humans speak, gestures help convey communicative intentions, such as\nadding emphasis or describing concepts. However, current co-speech gesture\ngeneration methods rely solely on superficial linguistic cues (\\textit{e.g.}\nspeech audio or text transcripts), neglecting to understand and leverage the\ncommunicative intention that underpins human gestures. This results in outputs\nthat are rhythmically synchronized with speech but are semantically shallow. To\naddress this gap, we introduce \\textbf{Intentional-Gesture}, a novel framework\nthat casts gesture generation as an intention-reasoning task grounded in\nhigh-level communicative functions. % First, we curate the \\textbf{InG} dataset\nby augmenting BEAT-2 with gesture-intention annotations (\\textit{i.e.}, text\nsentences summarizing intentions), which are automatically annotated using\nlarge vision-language models. Next, we introduce the \\textbf{Intentional\nGesture Motion Tokenizer} to leverage these intention annotations. It injects\nhigh-level communicative functions (\\textit{e.g.}, intentions) into tokenized\nmotion representations to enable intention-aware gesture synthesis that are\nboth temporally aligned and semantically meaningful, achieving new\nstate-of-the-art performance on the BEAT-2 benchmark. Our framework offers a\nmodular foundation for expressive gesture generation in digital humans and\nembodied AI. Project Page: https://andypinxinliu.github.io/Intentional-Gesture",
      "tldr_zh": "现有的手势生成方法仅依赖于表面的语言线索（如语音或文本），忽略了沟通意图，导致手势在节奏上同步但语义上浅薄。论文提出 Intentional-Gesture 框架，将手势生成视为基于高层沟通功能的意图推理任务，并创建 InG 数据集，通过增强 BEAT-2 数据集并使用大型视觉语言模型自动注解意图。框架引入 Intentional Gesture Motion Tokenizer，将意图注入标记化的动作表示中，实现时间对齐且语义丰富的意图感知手势合成，在 BEAT-2 基准上达到新的最先进性能，并为数字人类和具身 AI 的表达性手势生成提供模块化基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15197v1",
      "published_date": "2025-05-21 07:24:51 UTC",
      "updated_date": "2025-05-21 07:24:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:56:23.415361"
    },
    {
      "arxiv_id": "2505.15182v1",
      "title": "ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Jeonghye Kim",
        "Sojeong Rhee",
        "Minbeom Kim",
        "Dohyung Kim",
        "Sangmook Lee",
        "Youngchul Sung",
        "Kyomin Jung"
      ],
      "abstract": "Recent advances in LLM agents have largely built on reasoning backbones like\nReAct, which interleave thought and action in complex environments. However,\nReAct often produces ungrounded or incoherent reasoning steps, leading to\nmisalignment between the agent's actual state and goal. Our analysis finds that\nthis stems from ReAct's inability to maintain consistent internal beliefs and\ngoal alignment, causing compounding errors and hallucinations. To address this,\nwe introduce ReflAct, a novel backbone that shifts reasoning from merely\nplanning next actions to continuously reflecting on the agent's state relative\nto its goal. By explicitly grounding decisions in states and enforcing ongoing\ngoal alignment, ReflAct dramatically improves strategic reliability. This\ndesign delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7%\non average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even\noutperforms ReAct with added enhancement modules (e.g., Reflexion, WKM),\nshowing that strengthening the core reasoning backbone is key to reliable agent\nperformance.",
      "tldr_zh": "该研究分析了现有ReAct框架在LLM Agents中的问题，即其推理步骤常出现不连贯或脱离实际，导致代理状态与目标 misalignment和错误积累。为解决此问题，研究提出ReflAct框架，将推理从单纯规划下一个动作转向持续反思代理状态与目标的相对关系，从而增强决策的grounded性和目标对齐。实验结果显示，ReflAct平均比ReAct提升27.7%，在ALFWorld环境中达到93.3%的成功率，甚至优于ReAct添加增强模块（如Reflexion和WKM），证明强化核心推理骨干是提升代理可靠性的关键。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15182v1",
      "published_date": "2025-05-21 06:57:39 UTC",
      "updated_date": "2025-05-21 06:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:56:32.984157"
    },
    {
      "arxiv_id": "2505.15173v1",
      "title": "AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection",
      "title_zh": "AvatarShield：视觉强化学习用于以人为中心的视频伪造检测",
      "authors": [
        "Zhipei Xu",
        "Xuanyu Zhang",
        "Xing Zhou",
        "Jian Zhang"
      ],
      "abstract": "The rapid advancement of Artificial Intelligence Generated Content (AIGC)\ntechnologies, particularly in video generation, has led to unprecedented\ncreative capabilities but also increased threats to information integrity,\nidentity security, and public trust. Existing detection methods, while\neffective in general scenarios, lack robust solutions for human-centric videos,\nwhich pose greater risks due to their realism and potential for legal and\nethical misuse. Moreover, current detection approaches often suffer from poor\ngeneralization, limited scalability, and reliance on labor-intensive supervised\nfine-tuning. To address these challenges, we propose AvatarShield, the first\ninterpretable MLLM-based framework for detecting human-centric fake videos,\nenhanced via Group Relative Policy Optimization (GRPO). Through our carefully\ndesigned accuracy detection reward and temporal compensation reward, it\neffectively avoids the use of high-cost text annotation data, enabling precise\ntemporal modeling and forgery detection. Meanwhile, we design a dual-encoder\narchitecture, combining high-level semantic reasoning and low-level artifact\namplification to guide MLLMs in effective forgery detection. We further collect\nFakeHumanVid, a large-scale human-centric video benchmark that includes\nsynthesis methods guided by pose, audio, and text inputs, enabling rigorous\nevaluation of detection methods in real-world scenes. Extensive experiments\nshow that AvatarShield significantly outperforms existing approaches in both\nin-domain and cross-domain detection, setting a new standard for human-centric\nvideo forensics.",
      "tldr_zh": "本研究针对AI生成内容（AIGC）导致的人类中心视频伪造问题，提出AvatarShield，一种基于多模态大型语言模型（MLLM）的可解释框架，利用Group Relative Policy Optimization (GRPO)及准确性检测奖励和时间补偿奖励，实现高效的伪造检测，同时避免高成本文本标注数据。框架采用双编码器架构，结合高层语义推理和低层伪造痕迹放大，以精确建模视频时间序列并提升检测性能。为此，研究者构建了FakeHumanVid数据集，一个大规模基准，涵盖基于姿势、音频和文本输入的合成视频。实验结果表明，AvatarShield在域内和跨域检测中显著优于现有方法，建立新的视频取证标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15173v1",
      "published_date": "2025-05-21 06:43:34 UTC",
      "updated_date": "2025-05-21 06:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:56:46.601107"
    },
    {
      "arxiv_id": "2505.15155v1",
      "title": "R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuante Li",
        "Xu Yang",
        "Xiao Yang",
        "Minrui Xu",
        "Xisen Wang",
        "Weiqing Liu",
        "Jiang Bian"
      ],
      "abstract": "Financial markets pose fundamental challenges for asset return prediction due\nto their high dimensionality, non-stationarity, and persistent volatility.\nDespite advances in large language models and multi-agent systems, current\nquantitative research pipelines suffer from limited automation, weak\ninterpretability, and fragmented coordination across key components such as\nfactor mining and model innovation. In this paper, we propose R&D-Agent for\nQuantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent\nframework designed to automate the full-stack research and development of\nquantitative strategies via coordinated factor-model co-optimization.\nRD-Agent(Q) decomposes the quant process into two iterative stages: a Research\nstage that dynamically sets goal-aligned prompts, formulates hypotheses based\non domain priors, and maps them to concrete tasks, and a Development stage that\nemploys a code-generation agent, Co-STEER, to implement task-specific code,\nwhich is then executed in real-market backtests. The two stages are connected\nthrough a feedback stage that thoroughly evaluates experimental outcomes and\ninforms subsequent iterations, with a multi-armed bandit scheduler for adaptive\ndirection selection. Empirically, RD-Agent(Q) achieves up to 2X higher\nannualized returns than classical factor libraries using 70% fewer factors, and\noutperforms state-of-the-art deep time-series models on real markets. Its joint\nfactor-model optimization delivers a strong balance between predictive accuracy\nand strategy robustness. Our code is available at:\nhttps://github.com/microsoft/RD-Agent.",
      "tldr_zh": "本文提出 RD-Agent(Q)，一个数据中心的多智能体框架，旨在通过因子和模型的联合优化自动化量化金融策略的研发，解决现有管道中自动化不足、可解释性弱和协调碎片化等问题。该框架将过程分解为 Research 阶段（设置目标提示、基于领域先验制定假设并映射任务）和 Development 阶段（使用代码生成智能体 Co-STEER 实现代码，并在真实市场回测），并通过反馈阶段和 multi-armed bandit 调度器进行迭代优化。实验结果显示，RD-Agent(Q) 比经典因子库实现 2 倍年化回报，使用 70% 更少的因子，并优于最先进深度时间序列模型，在预测准确性和策略稳健性之间取得良好平衡。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15155v1",
      "published_date": "2025-05-21 06:20:56 UTC",
      "updated_date": "2025-05-21 06:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:56:58.040525"
    },
    {
      "arxiv_id": "2505.15154v1",
      "title": "Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghui Lu",
        "Haiyang Yu",
        "Siliang Xu",
        "Shiwei Ran",
        "Guozhi Tang",
        "Siqi Wang",
        "Bin Shan",
        "Teng Fu",
        "Hao Feng",
        "Jingqun Tang",
        "Han Wang",
        "Can Huang"
      ],
      "abstract": "Recent advancements in reasoning have significantly enhanced the capabilities\nof Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)\nacross diverse tasks. However, excessive reliance on chain-of-thought (CoT)\nreasoning can impair model performance and brings unnecessarily lengthened\noutputs, reducing efficiency. Our work reveals that prolonged reasoning does\nnot universally improve accuracy and even degrade performance on simpler tasks.\nTo address this, we propose Certainty-based Adaptive Reasoning (CAR), a novel\nframework that dynamically switches between short answers and long-form\nreasoning based on the model perplexity. CAR first generates a short answer and\nevaluates its perplexity, triggering reasoning only when the model exhibits low\nconfidence (i.e., high perplexity). Experiments across diverse multimodal\nVQA/KIE benchmarks and text reasoning datasets show that CAR outperforms both\nshort-answer and long-form reasoning approaches, striking an optimal balance\nbetween accuracy and efficiency.",
      "tldr_zh": "该研究发现，过度依赖 Chain-of-Thought (CoT) 推理会降低 Large Language Models (LLMs) 和 Multimodal Large Language Models (MLLMs) 的性能，并导致输出冗长和效率低下，尤其在简单任务上。针对这一问题，作者提出 Certainty-based Adaptive Reasoning (CAR) 框架，该框架先生成短答案并评估其 perplexity，只有在模型置信度低（perplexity 高）时才触发长形式推理，从而动态平衡准确性和效率。在多模态 VQA/KIE 基准和文本推理数据集上的实验表明，CAR 优于纯短答案或长形式方法，提供了一种更高效的推理策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15154v1",
      "published_date": "2025-05-21 06:20:17 UTC",
      "updated_date": "2025-05-21 06:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:57:09.326375"
    },
    {
      "arxiv_id": "2505.15862v1",
      "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Long Wanga",
        "Jiongzhi Zheng",
        "Zhengda Xiong",
        "ChuMin Li",
        "Kun He"
      ],
      "abstract": "Algorithms designed for routing problems typically rely on high-quality\ncandidate edges to guide their search, aiming to reduce the search space and\nenhance the search efficiency. However, many existing algorithms, like the\nclassical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem (TSP), often use predetermined candidate edges that remain static\nthroughout local searches. This rigidity could cause the algorithm to get\ntrapped in local optima, limiting its potential to find better solutions. To\naddress this issue, we propose expanding the candidate sets to include other\npromising edges, providing them an opportunity for selection. Specifically, we\nincorporate multi-armed bandit models to dynamically select the most suitable\ncandidate edges in each iteration, enabling LKH to make smarter choices and\nlead to improved solutions. Extensive experiments on multiple TSP benchmarks\nshow the excellent performance of our method. Moreover, we employ this\nbandit-based method to LKH-3, an extension of LKH tailored for solving various\nTSP variant problems, and our method also significantly enhances LKH-3's\nperformance across typical TSP variants.",
      "tldr_zh": "该研究针对旅行 salesman problem (TSP) 的求解，提出了一种基于多臂赌博机 (multi-armed bandit) 的动态候选边选择方法，以解决传统 Lin-Kernighan-Helsgaun (LKH) 算法使用静态候选边而易陷入局部最优的局限。\n该方法通过扩展候选边集，并在每次迭代中动态选择最合适的边，增强了算法的搜索效率和全局优化能力。\n实验在多个 TSP 基准上验证了该方法的优异性能，并将其应用于 LKH-3 算法后，显著提升了其在各种 TSP 变体问题上的表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15862v1",
      "published_date": "2025-05-21 06:11:00 UTC",
      "updated_date": "2025-05-21 06:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:57:21.297695"
    },
    {
      "arxiv_id": "2505.15146v1",
      "title": "lmgame-Bench: How Good are LLMs at Playing Games?",
      "title_zh": "lmgame-Bench: LLMs 在玩游戏方面的表现如何？",
      "authors": [
        "Lanxiang Hu",
        "Mingjia Huo",
        "Yuxuan Zhang",
        "Haoyang Yu",
        "Eric P. Xing",
        "Ion Stoica",
        "Tajana Rosing",
        "Haojian Jin",
        "Hao Zhang"
      ],
      "abstract": "Playing video games requires perception, memory, and planning, exactly the\nfaculties modern large language model (LLM) agents are expected to master. We\nstudy the major challenges in using popular video games to evaluate modern LLMs\nand find that directly dropping LLMs into games cannot make an effective\nevaluation, for three reasons -- brittle vision perception, prompt sensitivity,\nand potential data contamination. We introduce lmgame-Bench to turn games into\nreliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and\nnarrative games delivered through a unified Gym-style API and paired with\nlightweight perception and memory scaffolds, and is designed to stabilize\nprompt variance and remove contamination. Across 13 leading models, we show\nlmgame-Bench is challenging while still separating models well. Correlation\nanalysis shows that every game probes a unique blend of capabilities often\ntested in isolation elsewhere. More interestingly, performing reinforcement\nlearning on a single game from lmgame-Bench transfers both to unseen games and\nto external planning tasks. Our evaluation code is available at\nhttps://github.com/lmgame-org/GamingAgent/lmgame-bench.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在视频游戏中的表现，识别出视觉感知不稳定、提示敏感性和数据污染等主要挑战，导致直接应用LLMs效果不佳。为解决这些问题，研究引入了lmgame-Bench，这是一个包含平台游戏、谜题游戏和叙事游戏的基准套件，通过统一的Gym-style API和轻量级感知与记忆支架来稳定提示变异并去除污染。在13个领先模型上的测试显示，lmgame-Bench具有挑战性且能有效区分模型性能，且相关性分析表明每个游戏测试了独特的能力组合；此外，在单个游戏上进行强化学习可转移到未见游戏和外部规划任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15146v1",
      "published_date": "2025-05-21 06:02:55 UTC",
      "updated_date": "2025-05-21 06:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:57:33.238129"
    },
    {
      "arxiv_id": "2505.15141v1",
      "title": "BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Yunlong Hou",
        "Fengzhuo Zhang",
        "Cunxiao Du",
        "Xuan Zhang",
        "Jiachun Pan",
        "Tianyu Pang",
        "Chao Du",
        "Vincent Y. F. Tan",
        "Zhuoran Yang"
      ],
      "abstract": "Speculative decoding has emerged as a popular method to accelerate the\ninference of Large Language Models (LLMs) while retaining their superior text\ngeneration performance. Previous methods either adopt a fixed speculative\ndecoding configuration regardless of the prefix tokens, or train draft models\nin an offline or online manner to align them with the context. This paper\nproposes a training-free online learning framework to adaptively choose the\nconfiguration of the hyperparameters for speculative decoding as text is being\ngenerated. We first formulate this hyperparameter selection problem as a\nMulti-Armed Bandit problem and provide a general speculative decoding framework\nBanditSpec. Furthermore, two bandit-based hyperparameter selection algorithms,\nUCBSpec and EXP3Spec, are designed and analyzed in terms of a novel quantity,\nthe stopping time regret. We upper bound this regret under both stochastic and\nadversarial reward settings. By deriving an information-theoretic impossibility\nresult, it is shown that the regret performance of UCBSpec is optimal up to\nuniversal constants. Finally, extensive empirical experiments with LLaMA3 and\nQwen2 demonstrate that our algorithms are effective compared to existing\nmethods, and the throughput is close to the oracle best hyperparameter in\nsimulated real-life LLM serving scenarios with diverse input prompts.",
      "tldr_zh": "本研究提出BanditSpec，一种基于Bandit Algorithms的无需训练的在线学习框架，用于适应性Speculative Decoding，以加速Large Language Models (LLMs)的推理过程。框架将超参数选择问题形式化为Multi-Armed Bandit问题，并设计了UCBSpec和EXP3Spec算法，对stopping time regret进行分析和上界证明，证明UCBSpec的遗憾性能是最优的。实验在LLaMA3和Qwen2模型上显示，该方法比现有方法更有效，吞吐量接近理想的最佳超参数，尤其在多样化输入提示的真实场景中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15141v1",
      "published_date": "2025-05-21 05:56:31 UTC",
      "updated_date": "2025-05-21 05:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:57:44.757007"
    },
    {
      "arxiv_id": "2505.15138v1",
      "title": "Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Xu",
        "Swetha Ganesh",
        "Washim Uddin Mondal",
        "Qinbo Bai",
        "Vaneet Aggarwal"
      ],
      "abstract": "This paper investigates infinite-horizon average reward Constrained Markov\nDecision Processes (CMDPs) with general parametrization. We propose a\nPrimal-Dual Natural Actor-Critic algorithm that adeptly manages constraints\nwhile ensuring a high convergence rate. In particular, our algorithm achieves\nglobal convergence and constraint violation rates of\n$\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ over a horizon of length $T$ when the mixing\ntime, $\\tau_{\\mathrm{mix}}$, is known to the learner. In absence of knowledge\nof $\\tau_{\\mathrm{mix}}$, the achievable rates change to\n$\\tilde{\\mathcal{O}}(1/T^{0.5-\\epsilon})$ provided that $T \\geq\n\\tilde{\\mathcal{O}}\\left(\\tau_{\\mathrm{mix}}^{2/\\epsilon}\\right)$. Our results\nmatch the theoretical lower bound for Markov Decision Processes and establish a\nnew benchmark in the theoretical exploration of average reward CMDPs.",
      "tldr_zh": "本研究探讨了无限地平线平均奖励 Constrained Markov Decision Processes (CMDPs)，提出了一种 Primal-Dual Natural Actor-Critic 算法，以有效管理约束并实现高收敛率。该算法在已知 mixing time τ_mix 的情况下，实现全局收敛和约束违反率约 Ũ(1/√T)；若未知 τ_mix，则收敛率变为 Ũ(1/T^{0.5-ε})，前提是 T ≥ Ũ(τ_mix^{2/ε})。这些结果与 Markov Decision Processes 的理论下界相匹配，并为平均奖励 CMDPs 的理论研究设定新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15138v1",
      "published_date": "2025-05-21 05:49:11 UTC",
      "updated_date": "2025-05-21 05:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:57:56.848028"
    },
    {
      "arxiv_id": "2505.15134v1",
      "title": "The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning",
      "title_zh": "熵最小化在LLM推理中的不可思议有效性",
      "authors": [
        "Shivam Agarwal",
        "Zimin Zhang",
        "Lifan Yuan",
        "Jiawei Han",
        "Hao Peng"
      ],
      "abstract": "Entropy minimization (EM) trains the model to concentrate even more\nprobability mass on its most confident outputs. We show that this simple\nobjective alone, without any labeled data, can substantially improve large\nlanguage models' (LLMs) performance on challenging math, physics, and coding\ntasks. We explore three approaches: (1) EM-FT minimizes token-level entropy\nsimilarly to instruction finetuning, but on unlabeled outputs drawn from the\nmodel; (2) EM-RL: reinforcement learning with negative entropy as the only\nreward to maximize; (3) EM-INF: inference-time logit adjustment to reduce\nentropy without any training data or parameter updates. On Qwen-7B, EM-RL,\nwithout any labeled data, achieves comparable or better performance than strong\nRL baselines such as GRPO and RLOO that are trained on 60K labeled examples.\nFurthermore, EM-INF enables Qwen-32B to match or exceed the performance of\nproprietary models like GPT-4o, Claude 3 Opus, and Gemini 1.5 Pro on the\nchallenging SciCode benchmark, while being 3x more efficient than\nself-consistency and sequential refinement. Our findings reveal that many\npretrained LLMs possess previously underappreciated reasoning capabilities that\ncan be effectively elicited through entropy minimization alone, without any\nlabeled data or even any parameter updates.",
      "tldr_zh": "该研究探索了熵最小化 (Entropy Minimization) 在大语言模型 (LLM) 推理中的显著效果，通过该方法无需标记数据即可提升模型在数学、物理和编码任务上的性能。研究提出三种方法：EM-FT 使用模型的无标签输出最小化 token-level 熵；EM-RL 通过负熵作为唯一奖励进行强化学习；EM-INF 在推理时调整 logit 以减少熵，而不需训练数据或参数更新。在实验中，EM-RL 使 Qwen-7B 模型在无标记数据下达到或超过使用 60K 标记示例的基线如 GRPO 和 RLOO，而 EM-INF 让 Qwen-32B 在 SciCode 基准上匹敌或超越 GPT-4o、Claude 3 Opus 和 Gemini 1.5 Pro，且效率提升 3 倍。这些发现表明，许多预训练 LLM 拥有未被充分挖掘的推理能力，可仅通过 Entropy Minimization 有效激发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15134v1",
      "published_date": "2025-05-21 05:39:11 UTC",
      "updated_date": "2025-05-21 05:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:58:09.864160"
    },
    {
      "arxiv_id": "2505.15133v1",
      "title": "DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer",
      "title_zh": "翻译失败",
      "authors": [
        "Haiduo Huang",
        "Jiangcheng Song",
        "Yadong Zhang",
        "Pengju Ren"
      ],
      "abstract": "Recent advances in knowledge distillation have emphasized the importance of\ndecoupling different knowledge components. While existing methods utilize\nmomentum mechanisms to separate task-oriented and distillation gradients, they\noverlook the inherent conflict between target-class and non-target-class\nknowledge flows. Furthermore, low-confidence dark knowledge in non-target\nclasses introduces noisy signals that hinder effective knowledge transfer. To\naddress these limitations, we propose DeepKD, a novel training framework that\nintegrates dual-level decoupling with adaptive denoising. First, through\ntheoretical analysis of gradient signal-to-noise ratio (GSNR) characteristics\nin task-oriented and non-task-oriented knowledge distillation, we design\nindependent momentum updaters for each component to prevent mutual\ninterference. We observe that the optimal momentum coefficients for\ntask-oriented gradient (TOG), target-class gradient (TCG), and non-target-class\ngradient (NCG) should be positively related to their GSNR. Second, we introduce\na dynamic top-k mask (DTM) mechanism that gradually increases K from a small\ninitial value to incorporate more non-target classes as training progresses,\nfollowing curriculum learning principles. The DTM jointly filters\nlow-confidence logits from both teacher and student models, effectively\npurifying dark knowledge during early training. Extensive experiments on\nCIFAR-100, ImageNet, and MS-COCO demonstrate DeepKD's effectiveness. Our code\nis available at https://github.com/haiduo/DeepKD.",
      "tldr_zh": "该研究提出了一种新型知识蒸馏训练框架 DeepKD，通过双层解耦和自适应去噪机制，解决现有方法中目标类和非目标类知识流的冲突问题，以及非目标类低置信度暗知识带来的噪声干扰。具体而言，DeepKD 通过分析梯度信噪比（GSNR），设计独立的动量更新器来分离任务导向梯度（TOG）、目标类梯度（TCG）和非目标类梯度（NCG），从而防止相互干扰；同时引入动态 top-k 掩码（DTM）机制，按照课程学习原则逐步纳入更多非目标类，并过滤教师和学生模型的低置信度 logits。实验结果显示，DeepKD 在 CIFAR-100、ImageNet 和 MS-COCO 数据集上表现出色，显著提升了知识蒸馏的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15133v1",
      "published_date": "2025-05-21 05:38:57 UTC",
      "updated_date": "2025-05-21 05:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:58:21.211159"
    },
    {
      "arxiv_id": "2505.15123v1",
      "title": "Seeing the Trees for the Forest: Rethinking Weakly-Supervised Medical Visual Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Ta Duc Huy",
        "Duy Anh Huynh",
        "Yutong Xie",
        "Yuankai Qi",
        "Qi Chen",
        "Phi Le Nguyen",
        "Sen Kim Tran",
        "Son Lam Phung",
        "Anton van den Hengel",
        "Zhibin Liao",
        "Minh-Son To",
        "Johan W. Verjans",
        "Vu Minh Hieu Phan"
      ],
      "abstract": "Visual grounding (VG) is the capability to identify the specific regions in\nan image associated with a particular text description. In medical imaging, VG\nenhances interpretability by highlighting relevant pathological features\ncorresponding to textual descriptions, improving model transparency and\ntrustworthiness for wider adoption of deep learning models in clinical\npractice. Current models struggle to associate textual descriptions with\ndisease regions due to inefficient attention mechanisms and a lack of\nfine-grained token representations. In this paper, we empirically demonstrate\ntwo key observations. First, current VLMs assign high norms to background\ntokens, diverting the model's attention from regions of disease. Second, the\nglobal tokens used for cross-modal learning are not representative of local\ndisease tokens. This hampers identifying correlations between the text and\ndisease tokens. To address this, we introduce simple, yet effective\nDisease-Aware Prompting (DAP) process, which uses the explainability map of a\nVLM to identify the appropriate image features. This simple strategy amplifies\ndisease-relevant regions while suppressing background interference. Without any\nadditional pixel-level annotations, DAP improves visual grounding accuracy by\n20.74% compared to state-of-the-art methods across three major chest X-ray\ndatasets.",
      "tldr_zh": "本论文重新审视了弱监督医疗视觉 grounding (VG)，强调其在医疗成像中的作用，即通过关联文本描述与图像中的病理区域，提升深度学习模型的可解释性和可信度。研究发现，当前视觉语言模型 (VLMs) 存在问题，如将高范数分配给背景 token，导致注意力分散，以及全局 token 无法代表局部疾病 token，从而影响文本与疾病区域的相关性。为解决此问题，作者提出了一种简单有效的 Disease-Aware Prompting (DAP) 方法，利用 VLM 的解释性映射来突出疾病相关区域并抑制背景干扰。实验结果显示，在三个主要胸部 X 光数据集上，DAP 无需额外像素级标注，便将视觉 grounding 准确率提高了 20.74%，优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.15123v1",
      "published_date": "2025-05-21 05:16:45 UTC",
      "updated_date": "2025-05-21 05:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:58:33.937303"
    },
    {
      "arxiv_id": "2505.15117v1",
      "title": "An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jin",
        "Jinsung Yoon",
        "Priyanka Kargupta",
        "Sercan O. Arik",
        "Jiawei Han"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated strong potential in training\nlarge language models (LLMs) capable of complex reasoning for real-world\nproblem solving. More recently, RL has been leveraged to create sophisticated\nLLM-based search agents that adeptly combine reasoning with search engine use.\nWhile the use of RL for training search agents is promising, the optimal design\nof such agents remains not fully understood. In particular, key factors -- such\nas (1) reward formulation, (2) the choice and characteristics of the underlying\nLLM, and (3) the role of the search engine in the RL process -- require further\ninvestigation. In this work, we conduct comprehensive empirical studies to\nsystematically investigate these and offer actionable insights. We highlight\nseveral key findings: format rewards are effective in improving final\nperformance, whereas intermediate retrieval rewards have limited impact; the\nscale and initialization of the LLM (general-purpose vs. reasoning-specialized)\nsignificantly influence RL outcomes; and the choice of search engine plays a\ncritical role in shaping RL training dynamics and the robustness of the trained\nagent during inference. These establish important guidelines for successfully\nbuilding and deploying LLM-based search agents in real-world applications. Code\nis available at https://github.com/PeterGriffinJin/Search-R1.",
      "tldr_zh": "本研究通过实证分析探讨了强化学习 (RL) 在训练推理与搜索交织的大型语言模型 (LLMs) 代理方面的应用，重点调查奖励制定、底层 LLM 的选择和搜索引擎的作用。研究者设计了全面实验来评估这些关键因素，结果显示格式化奖励能显著提升最终性能，而中间检索奖励的影响有限；LLM 的规模和初始化（如通用型 vs. 推理专用型）对 RL 结果有重大影响；搜索引擎的选择会塑造训练动态并提升代理的鲁棒性。这些发现为构建和部署 LLM 基于搜索代理提供重要指导，帮助其在实际应用中更有效地解决问题。代码可在 https://github.com/PeterGriffinJin/Search-R1 获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15117v1",
      "published_date": "2025-05-21 05:09:43 UTC",
      "updated_date": "2025-05-21 05:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:58:45.797967"
    },
    {
      "arxiv_id": "2505.15116v1",
      "title": "Graph Foundation Models: A Comprehensive Survey",
      "title_zh": "图基础模型：全面综述",
      "authors": [
        "Zehong Wang",
        "Zheyuan Liu",
        "Tianyi Ma",
        "Jiazheng Li",
        "Zheyuan Zhang",
        "Xingbo Fu",
        "Yiyang Li",
        "Zhengqing Yuan",
        "Wei Song",
        "Yijun Ma",
        "Qingkai Zeng",
        "Xiusi Chen",
        "Jianan Zhao",
        "Jundong Li",
        "Meng Jiang",
        "Pietro Lio",
        "Nitesh Chawla",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Graph-structured data pervades domains such as social networks, biological\nsystems, knowledge graphs, and recommender systems. While foundation models\nhave transformed natural language processing, vision, and multimodal learning\nthrough large-scale pretraining and generalization, extending these\ncapabilities to graphs -- characterized by non-Euclidean structures and complex\nrelational semantics -- poses unique challenges and opens new opportunities. To\nthis end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose\nintelligence to structured data, enabling broad transfer across graph-centric\ntasks and domains. This survey provides a comprehensive overview of GFMs,\nunifying diverse efforts under a modular framework comprising three key\ncomponents: backbone architectures, pretraining strategies, and adaptation\nmechanisms. We categorize GFMs by their generalization scope -- universal,\ntask-specific, and domain-specific -- and review representative methods, key\ninnovations, and theoretical insights within each category. Beyond methodology,\nwe examine theoretical foundations including transferability and emergent\ncapabilities, and highlight key challenges such as structural alignment,\nheterogeneity, scalability, and evaluation. Positioned at the intersection of\ngraph learning and general-purpose AI, GFMs are poised to become foundational\ninfrastructure for open-ended reasoning over structured data. This survey\nconsolidates current progress and outlines future directions to guide research\nin this rapidly evolving field. Resources are available at\nhttps://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs.",
      "tldr_zh": "这篇调查论文全面概述了Graph Foundation Models (GFMs)，旨在将基础模型的通用智能扩展到图结构数据中，解决其非欧结构和复杂关联语义的独特挑战。论文采用一个模块化框架，包括backbone architectures、pretraining strategies 和adaptation mechanisms，并将GFMs分类为universal、task-specific 和domain-specific类型，审视了代表性方法、创新和理论见解，如transferability和emergent capabilities。最终，它突出了关键挑战（如structural alignment、heterogeneity和scalability），并为图学习与通用AI的交叉领域指出了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Github Repo:\n  https://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs. 93 pages,\n  438 references",
      "pdf_url": "http://arxiv.org/pdf/2505.15116v1",
      "published_date": "2025-05-21 05:08:00 UTC",
      "updated_date": "2025-05-21 05:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:58:58.126991"
    },
    {
      "arxiv_id": "2505.15111v1",
      "title": "iPad: Iterative Proposal-centric End-to-End Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Guo",
        "Haochen Liu",
        "Xiaojun Wu",
        "Jia Pan",
        "Chen Lv"
      ],
      "abstract": "End-to-end (E2E) autonomous driving systems offer a promising alternative to\ntraditional modular pipelines by reducing information loss and error\naccumulation, with significant potential to enhance both mobility and safety.\nHowever, most existing E2E approaches directly generate plans based on dense\nbird's-eye view (BEV) grid features, leading to inefficiency and limited\nplanning awareness. To address these limitations, we propose iterative\nProposal-centric autonomous driving (iPad), a novel framework that places\nproposals - a set of candidate future plans - at the center of feature\nextraction and auxiliary tasks. Central to iPad is ProFormer, a BEV encoder\nthat iteratively refines proposals and their associated features through\nproposal-anchored attention, effectively fusing multi-view image data.\nAdditionally, we introduce two lightweight, proposal-centric auxiliary tasks -\nmapping and prediction - that improve planning quality with minimal\ncomputational overhead. Extensive experiments on the NAVSIM and CARLA\nBench2Drive benchmarks demonstrate that iPad achieves state-of-the-art\nperformance while being significantly more efficient than prior leading\nmethods.",
      "tldr_zh": "这篇论文提出 iPad，一种迭代提案中心的端到端 (E2E) 自动驾驶框架，以解决现有方法基于密集鸟瞰视图 (BEV) 网格特征生成计划的效率低下和规划意识有限问题。iPad 的核心组件是 ProFormer，一个 BEV 编码器，通过提案锚定注意力机制迭代精炼候选未来计划及其特征，并融合多视图图像数据。同时，引入了两个轻量级的提案中心辅助任务——映射和预测，以最小计算开销提升规划质量。在 NAVSIM 和 CARLA Bench2Drive 基准测试中，iPad 实现了最先进性能，同时比领先方法更高效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15111v1",
      "published_date": "2025-05-21 05:05:38 UTC",
      "updated_date": "2025-05-21 05:05:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:59:09.256290"
    },
    {
      "arxiv_id": "2505.15108v1",
      "title": "A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents",
      "title_zh": "一种用于评估AI驱动心理治疗智能体的风险分类法",
      "authors": [
        "Ian Steenstra",
        "Timothy W. Bickmore"
      ],
      "abstract": "The proliferation of Large Language Models (LLMs) and Intelligent Virtual\nAgents acting as psychotherapists presents significant opportunities for\nexpanding mental healthcare access. However, their deployment has also been\nlinked to serious adverse outcomes, including user harm and suicide,\nfacilitated by a lack of standardized evaluation methodologies capable of\ncapturing the nuanced risks of therapeutic interaction. Current evaluation\ntechniques lack the sensitivity to detect subtle changes in patient cognition\nand behavior during therapy sessions that may lead to subsequent\ndecompensation. We introduce a novel risk taxonomy specifically designed for\nthe systematic evaluation of conversational AI psychotherapists. Developed\nthrough an iterative process including review of the psychotherapy risk\nliterature, qualitative interviews with clinical and legal experts, and\nalignment with established clinical criteria (e.g., DSM-5) and existing\nassessment tools (e.g., NEQ, UE-ATR), the taxonomy aims to provide a structured\napproach to identifying and assessing user/patient harms. We provide a\nhigh-level overview of this taxonomy, detailing its grounding, and discuss\npotential use cases. We discuss two use cases in detail: monitoring cognitive\nmodel-based risk factors during a counseling conversation to detect unsafe\ndeviations, in both human-AI counseling sessions and in automated benchmarking\nof AI psychotherapists with simulated patients. The proposed taxonomy offers a\nfoundational step towards establishing safer and more responsible innovation in\nthe domain of AI-driven mental health support.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)和智能虚拟代理作为心理治疗师的潜在风险（如用户伤害和自杀），提出了一种新型风险分类法(risk taxonomy)，用于系统评估对话式AI心理治疗代理。分类法通过迭代过程开发，包括审查心理治疗文献、临床和法律专家访谈，以及对齐DSM-5等临床标准和现有工具(如NEQ, UE-ATR)，以捕捉治疗互动中的微妙认知和行为变化。论文概述了该分类法的结构和基础，并详细讨论了两个用例：监控认知模型中的风险因素以检测不安全偏差，在人类-AI咨询会话和AI心理治疗师的自动基准测试中。总体而言，这一框架为更安全、更负责任的AI驱动心理健康支持奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15108v1",
      "published_date": "2025-05-21 05:01:39 UTC",
      "updated_date": "2025-05-21 05:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:59:21.980990"
    },
    {
      "arxiv_id": "2505.15107v1",
      "title": "StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Ziliang Wang",
        "Xuhui Zheng",
        "Kang An",
        "Cijun Ouyang",
        "Jialu Cai",
        "Yuhang Wang",
        "Yichao Wu"
      ],
      "abstract": "Efficient multi-hop reasoning requires Large Language Models (LLMs) based\nagents to acquire high-value external knowledge iteratively. Previous work has\nexplored reinforcement learning (RL) to train LLMs to perform search-based\ndocument retrieval, achieving notable improvements in QA performance, but\nunderperform on complex, multi-hop QA resulting from the sparse rewards from\nglobal signal only. To address this gap in existing research, we introduce\nStepSearch, a framework for search LLMs that trained with step-wise proximal\npolicy optimization method. It consists of richer and more detailed\nintermediate search rewards and token-level process supervision based on\ninformation gain and redundancy penalties to better guide each search step. We\nconstructed a fine-grained question-answering dataset containing\nsub-question-level search trajectories based on open source datasets through a\nset of data pipeline method. On standard multi-hop QA benchmarks, it\nsignificantly outperforms global-reward baselines, achieving 11.2% and 4.2%\nabsolute improvements for 3B and 7B models over various search with RL\nbaselines using only 19k training data, demonstrating the effectiveness of\nfine-grained, stepwise supervision in optimizing deep search LLMs. Our\nimplementation is publicly available at\nhttps://github.com/zxh20001117/StepSearch.",
      "tldr_zh": "该论文提出 StepSearch 框架，通过步进式近端策略优化 (step-wise proximal policy optimization) 来提升大型语言模型 (LLMs) 在多跳推理中的搜索能力，解决现有 reinforcement learning (RL) 方法因稀疏全局奖励而表现不佳的问题。框架引入更丰富的中间搜索奖励和基于信息增益及冗余惩罚的 token-level 过程监督，以更好地指导每个搜索步骤，并构建了一个细粒度的 QA 数据集，包含子问题级别的搜索轨迹。在标准多跳 QA 基准测试中，StepSearch 仅用 19k 训练数据，就使 3B 和 7B 模型分别比全局奖励基线提升 11.2% 和 4.2%，证明细粒度步进监督的有效性。该实现已开源，可从指定仓库获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15107v1",
      "published_date": "2025-05-21 05:01:31 UTC",
      "updated_date": "2025-05-21 05:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:59:33.977169"
    },
    {
      "arxiv_id": "2505.15105v1",
      "title": "Mechanistic evaluation of Transformers and state space models",
      "title_zh": "对 Transformer 模型和状态空间模型的机制评估",
      "authors": [
        "Aryaman Arora",
        "Neil Rathi",
        "Nikil Roashan Selvam",
        "Róbert Csórdas",
        "Dan Jurafsky",
        "Christopher Potts"
      ],
      "abstract": "State space models (SSMs) for language modelling promise an efficient and\nperformant alternative to quadratic-attention Transformers, yet show variable\nperformance on recalling basic information from the context. While performance\non synthetic tasks like Associative Recall (AR) can point to this deficiency,\nbehavioural metrics provide little information as to why--on a mechanistic\nlevel--certain architectures fail and others succeed. To address this, we\nconduct experiments on AR and find that only Transformers and Based SSM models\nfully succeed at AR, with Mamba a close third, whereas the other SSMs (H3,\nHyena) fail. We then use causal interventions to explain why. We find that\nTransformers and Based learn to store key-value associations in-context using\ninduction heads. By contrast, the SSMs compute these associations only at the\nlast state, with only Mamba succeeding because of its short convolution\ncomponent. To extend and deepen these findings, we introduce Associative\nTreecall (ATR), a synthetic task similar to AR based on PCFG induction. ATR\nintroduces language-like hierarchical structure into the AR setting. We find\nthat all architectures learn the same mechanism as they did for AR, and the\nsame three models succeed at the task. These results reveal that architectures\nwith similar accuracy may still have substantive differences, motivating the\nadoption of mechanistic evaluations.",
      "tldr_zh": "本研究评估了Transformers和state space models (SSMs)在语言建模中的机制表现，特别是它们在回忆上下文信息（如Associative Recall (AR)任务）上的差异。实验发现，只有Transformers和Based SSM模型完全成功于AR任务，Mamba表现接近，而H3和Hyena失败；通过因果干预分析，Transformers和Based依赖induction heads存储关键值关联，而Mamba的部分成功归因于其短卷积组件。研究者引入了新任务Associative Treecall (ATR)，基于PCFG induction添加语言-like层次结构，结果显示相同模型表现出色，并强调即使准确率相似的架构可能有实质机制差异，建议采用机制评估以深入理解模型行为。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 page main text, 6 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.15105v1",
      "published_date": "2025-05-21 04:56:09 UTC",
      "updated_date": "2025-05-21 04:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:59:44.875031"
    },
    {
      "arxiv_id": "2505.15098v1",
      "title": "Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Li",
        "Tianle Zhang",
        "Xuelong Wei",
        "Jiayi Li",
        "Lin Zhao",
        "Dongchi Huang",
        "Zhirui Fang",
        "Minhua Zheng",
        "Wenjun Dai",
        "Xiaodong He"
      ],
      "abstract": "Robot manipulation learning from human demonstrations offers a rapid means to\nacquire skills but often lacks generalization across diverse scenes and object\nplacements. This limitation hinders real-world applications, particularly in\ncomplex tasks requiring dexterous manipulation. Vision-Language-Action (VLA)\nparadigm leverages large-scale data to enhance generalization. However, due to\ndata scarcity, VLA's performance remains limited. In this work, we introduce\nObject-Focus Actor (OFA), a novel, data-efficient approach for generalized\ndexterous manipulation. OFA exploits the consistent end trajectories observed\nin dexterous manipulation tasks, allowing for efficient policy training. Our\nmethod employs a hierarchical pipeline: object perception and pose estimation,\npre-manipulation pose arrival and OFA policy execution. This process ensures\nthat the manipulation is focused and efficient, even in varied backgrounds and\npositional layout. Comprehensive real-world experiments across seven tasks\ndemonstrate that OFA significantly outperforms baseline methods in both\npositional and background generalization tests. Notably, OFA achieves robust\nperformance with only 10 demonstrations, highlighting its data efficiency.",
      "tldr_zh": "本研究针对机器人从人类演示中学习操纵技能的泛化问题，提出了一种数据高效的方法 Object-Focus Actor (OFA)，以提升复杂灵巧操纵任务在不同场景和物体放置下的性能。OFA 利用灵巧操纵任务中一致的末端轨迹，采用分层管道，包括对象感知、姿势估计、预操纵姿势到达和策略执行，从而实现高效且专注的操纵。实验在七个真实任务中显示，OFA 仅需 10 个演示就显著优于基线方法，在位置和背景泛化测试中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15098v1",
      "published_date": "2025-05-21 04:37:56 UTC",
      "updated_date": "2025-05-21 04:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T02:59:57.309778"
    },
    {
      "arxiv_id": "2505.15095v1",
      "title": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English",
      "title_zh": "翻译失败",
      "authors": [
        "Ishmanbir Singh",
        "Dipankar Srirag",
        "Aditya Joshi"
      ],
      "abstract": "Sarcasm is a challenge to sentiment analysis because of the incongruity\nbetween stated and implied sentiment. The challenge is exacerbated when the\nimplication may be relevant to a specific country or geographical region.\nPragmatic metacognitive prompting (PMP) is a cognition-inspired technique that\nhas been used for pragmatic reasoning. In this paper, we harness PMP for\nexplainable sarcasm detection for Australian and Indian English, alongside a\nbenchmark dataset for standard English. We manually add sarcasm explanations to\nan existing sarcasm-labeled dataset for Australian and Indian English called\nBESSTIE, and compare the performance for explainable sarcasm detection for them\nwith FLUTE, a standard English dataset containing sarcasm explanations. Our\napproach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA)\nachieves statistically significant performance improvement across all tasks and\ndatasets when compared with four alternative prompting strategies. We also find\nthat alternative techniques such as agentic prompting mitigate context-related\nfailures by enabling external knowledge retrieval. The focused contribution of\nour work is utilising PMP in generating sarcasm explanations for varieties of\nEnglish.",
      "tldr_zh": "这篇论文利用Pragmatic Metacognitive Prompting (PMP)——一种受认知启发的提示技术——来实现澳大利亚和印度英语的可解释讽刺检测，并与标准英语基准数据集进行比较。研究者手动为BESSTIE数据集添加讽刺解释，并在FLUTE数据集上评估，证明PMP在GEMMA和LLAMA等开源LLMs上比其他四种提示策略有统计显著的性能提升。论文还发现，agentic prompting可以通过外部知识检索缓解上下文相关问题，主要贡献在于将PMP应用于英语变体的讽刺解释生成。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review. 4 pages + references",
      "pdf_url": "http://arxiv.org/pdf/2505.15095v1",
      "published_date": "2025-05-21 04:34:22 UTC",
      "updated_date": "2025-05-21 04:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:00:09.864835"
    },
    {
      "arxiv_id": "2505.15859v1",
      "title": "AutoData: A Multi-Agent System for Open Web Data Collection",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Ma",
        "Yiyue Qian",
        "Zheyuan Zhang",
        "Zehong Wang",
        "Xiaoye Qian",
        "Feifan Bai",
        "Yifan Ding",
        "Xuwei Luo",
        "Shinan Zhang",
        "Keerthiram Murugesan",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "The exponential growth of data-driven systems and AI technologies has\nintensified the demand for high-quality web-sourced datasets. While existing\ndatasets have proven valuable, conventional web data collection approaches face\nsignificant limitations in terms of human effort and scalability. Current\ndata-collecting solutions fall into two categories: wrapper-based methods that\nstruggle with adaptability and reproducibility, and large language model\n(LLM)-based approaches that incur substantial computational and financial\ncosts. To address these challenges, we propose AutoData, a novel multi-agent\nsystem for Automated web Data collection, that requires minimal human\nintervention, i.e., only necessitating a natural language instruction\nspecifying the desired dataset. In addition, AutoData is designed with a robust\nmulti-agent architecture, featuring a novel oriented message hypergraph\ncoordinated by a central task manager, to efficiently organize agents across\nresearch and development squads. Besides, we introduce a novel hypergraph cache\nsystem to advance the multi-agent collaboration process that enables efficient\nautomated data collection and mitigates the token cost issues prevalent in\nexisting LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark\ndataset supporting live data collection from web sources across three domains:\nacademic, finance, and sports. Comprehensive evaluations over Instruct2DS and\nthree existing benchmark datasets demonstrate AutoData's superior performance\ncompared to baseline methods. Case studies on challenging tasks such as picture\nbook collection and paper extraction from surveys further validate its\napplicability. Our source code and dataset are available at\nhttps://github.com/GraphResearcher/AutoData.",
      "tldr_zh": "该研究提出 AutoData，一种创新的 multi-agent system，用于自动收集开放网络数据，仅需自然语言指令即可实现高效数据采集，解决了传统 wrapper-based 和 LLM-based 方法在适应性、可重复性和成本方面的局限。AutoData 采用 oriented message hypergraph 架构，由中央任务管理器协调代理，并引入超图缓存系统来提升多智能体协作效率并降低 token 成本。同时，论文引入 Instruct2DS 基准数据集，支持学术、金融和体育领域的实时数据收集。综合评估显示，AutoData 在 Instruct2DS 和其他基准上显著优于基线方法，并在实际案例如图片书收集和论文提取中展现出强大适用性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15859v1",
      "published_date": "2025-05-21 04:32:35 UTC",
      "updated_date": "2025-05-21 04:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:00:21.808294"
    },
    {
      "arxiv_id": "2505.15091v2",
      "title": "ThinkRec: Thinking-based recommendation via LLM",
      "title_zh": "ThinkRec：通过 LLM 的基于思考的推荐",
      "authors": [
        "Qihang Yu",
        "Kairui Fu",
        "Shengyu Zhang",
        "Zheqi Lv",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled more\nsemantic-aware recommendations through natural language generation. Existing\nLLM for recommendation (LLM4Rec) methods mostly operate in a System 1-like\nmanner, relying on superficial features to match similar items based on click\nhistory, rather than reasoning through deeper behavioral logic. This often\nleads to superficial and erroneous recommendations. Motivated by this, we\npropose ThinkRec, a thinking-based framework that shifts LLM4Rec from System 1\nto System 2 (rational system). Technically, ThinkRec introduces a thinking\nactivation mechanism that augments item metadata with keyword summarization and\ninjects synthetic reasoning traces, guiding the model to form interpretable\nreasoning chains that consist of analyzing interaction histories, identifying\nuser preferences, and making decisions based on target items. On top of this,\nwe propose an instance-wise expert fusion mechanism to reduce the reasoning\ndifficulty. By dynamically assigning weights to expert models based on users'\nlatent features, ThinkRec adapts its reasoning path to individual users,\nthereby enhancing precision and personalization. Extensive experiments on\nreal-world datasets demonstrate that ThinkRec significantly improves the\naccuracy and interpretability of recommendations. Our implementations are\navailable in anonymous Github: https://github.com/Yu-Qi-hang/ThinkRec.",
      "tldr_zh": "该论文提出ThinkRec，一种基于大型语言模型(LLM)的思考型推荐框架，将现有LLM for recommendation (LLM4Rec)从System 1（直觉系统）转向System 2（理性系统），以解决浅层特征匹配导致的推荐错误问题。ThinkRec引入思考激活机制，通过关键词总结项目元数据和注入合成推理痕迹，形成可解释的推理链，包括分析用户交互历史、识别偏好并基于目标项目决策；同时，采用实例-wise专家融合机制，根据用户潜在特征动态分配权重，实现个性化推理路径。实验在真实数据集上证明，ThinkRec显著提升了推荐的准确性和可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15091v2",
      "published_date": "2025-05-21 04:25:18 UTC",
      "updated_date": "2025-05-22 14:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:00:33.344269"
    },
    {
      "arxiv_id": "2505.15090v1",
      "title": "DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Sona Elza Simon",
        "Preethi Jyothi"
      ],
      "abstract": "Effective cross-lingual transfer remains a critical challenge in scaling the\nbenefits of large language models from high-resource to low-resource languages.\nTowards this goal, prior studies have explored many approaches to combine task\nknowledge from task-specific data in a (high-resource) source language and\nlanguage knowledge from unlabeled text in a (low-resource) target language. One\nnotable approach proposed composable sparse fine-tuning (SFT) for cross-lingual\ntransfer that learns task-specific and language-specific sparse masks to select\na subset of the pretrained model's parameters that are further fine-tuned.\nThese sparse fine-tuned vectors (SFTs) are subsequently composed with the\npretrained model to facilitate zero-shot cross-lingual transfer to a task in a\ntarget language, using only task-specific data from a source language. These\nsparse masks for SFTs were identified using a simple magnitude-based pruning.\nIn our work, we introduce DeFT-X, a novel composable SFT approach that denoises\nthe weight matrices of a pretrained model before magnitude pruning using\nsingular value decomposition, thus yielding more robust SFTs. We evaluate\nDeFT-X on a diverse set of extremely low-resource languages for sentiment\nclassification (NusaX) and natural language inference (AmericasNLI) and\ndemonstrate that it performs at par or outperforms SFT and other prominent\ncross-lingual transfer baselines.",
      "tldr_zh": "该研究针对大型语言模型从高资源语言向低资源语言的零样本跨语言转移（Zero-Shot Cross-Lingual Transfer）问题，提出了一种改进的Composable Sparse Fine-Tuning (SFT)方法，即DeFT-X。DeFT-X通过使用奇异值分解（Singular Value Decomposition）对预训练模型的权重矩阵进行去噪处理，然后再进行基于大小的修剪，从而生成更稳健的稀疏微调向量。实验在情感分类任务（NusaX）和自然语言推理任务（AmericasNLI）上评估了DeFT-X，结果显示它在多种极低资源语言中与SFT或其他基线方法相当或表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15090v1",
      "published_date": "2025-05-21 04:20:30 UTC",
      "updated_date": "2025-05-21 04:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:00:45.227873"
    },
    {
      "arxiv_id": "2505.15088v1",
      "title": "Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects",
      "title_zh": "利用大型语言模型进行 Python 中的命令注入漏洞分析：对流行开源项目的实证研究",
      "authors": [
        "Yuxuan Wang",
        "Jingshu Chen",
        "Qingyang Wang"
      ],
      "abstract": "Command injection vulnerabilities are a significant security threat in\ndynamic languages like Python, particularly in widely used open-source projects\nwhere security issues can have extensive impact. With the proven effectiveness\nof Large Language Models(LLMs) in code-related tasks, such as testing,\nresearchers have explored their potential for vulnerabilities analysis. This\nstudy evaluates the potential of large language models (LLMs), such as GPT-4,\nas an alternative approach for automated testing for vulnerability detection.\nIn particular, LLMs have demonstrated advanced contextual understanding and\nadaptability, making them promising candidates for identifying nuanced security\nvulnerabilities within code. To evaluate this potential, we applied LLM-based\nanalysis to six high-profile GitHub projects-Django, Flask, TensorFlow,\nScikit-learn, PyTorch, and Langchain-each with over 50,000 stars and extensive\nadoption across software development and academic research. Our analysis\nassesses both the strengths and limitations of LLMs in detecting command\ninjection vulnerabilities, evaluating factors such as detection accuracy,\nefficiency, and practical integration into development workflows. In addition,\nwe provide a comparative analysis of different LLM tools to identify those most\nsuitable for security applications. Our findings offer guidance for developers\nand security researchers on leveraging LLMs as innovative and automated\napproaches to enhance software security.",
      "tldr_zh": "本研究探讨了利用 Large Language Models (LLMs) 如 GPT-4 来分析 Python 中的命令注入 vulnerabilities 的潜力，通过实证研究评估其在自动化测试中的应用。研究团队对六个高人气的开源项目（包括 Django、Flask、TensorFlow、Scikit-learn、PyTorch 和 Langchain）进行了分析，评估了 LLMs 的检测准确性、效率以及与开发流程的集成性。结果显示，LLMs 在识别这些漏洞方面表现出色，但也存在局限性；论文通过比较不同 LLM 工具，为开发者和安全研究者提供了利用 LLMs 增强软件安全的实用指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15088v1",
      "published_date": "2025-05-21 04:14:35 UTC",
      "updated_date": "2025-05-21 04:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:00:58.023088"
    },
    {
      "arxiv_id": "2505.15083v1",
      "title": "Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features",
      "title_zh": "稳健的多模态预测：整合静态和动态特征",
      "authors": [
        "Jeremy Qin"
      ],
      "abstract": "Time series forecasting plays a crucial role in various applications,\nparticularly in healthcare, where accurate predictions of future health\ntrajectories can significantly impact clinical decision-making. Ensuring\ntransparency and explainability of the models responsible for these tasks is\nessential for their adoption in critical settings. Recent work has explored a\ntop-down approach to bi-level transparency, focusing on understanding trends\nand properties of predicted time series using static features. In this work, we\nextend this framework by incorporating exogenous time series features alongside\nstatic features in a structured manner, while maintaining cohesive\ninterpretation. Our approach leverages the insights of trajectory comprehension\nto introduce an encoding mechanism for exogenous time series, where they are\ndecomposed into meaningful trends and properties, enabling the extraction of\ninterpretable patterns. Through experiments on several synthetic datasets, we\ndemonstrate that our approach remains predictive while preserving\ninterpretability and robustness. This work represents a step towards developing\nrobust, and generalized time series forecasting models. The code is available\nat https://github.com/jeremy-qin/TIMEVIEW",
      "tldr_zh": "该论文扩展了时间序列预测框架，旨在整合静态特征和外生时间序列（exogenous time series）特征，以提升模型在医疗等领域的透明性和可解释性。研究方法引入了基于轨迹理解（trajectory comprehension）的编码机制，将外生时间序列分解成可解释的趋势和属性，同时保持预测的连贯性。在合成数据集上的实验结果显示，该方法在保持预测准确性的同时，显著提高了模型的鲁棒性和泛化能力，并提供了开源代码（https://github.com/jeremy-qin/TIMEVIEW）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15083v1",
      "published_date": "2025-05-21 04:12:12 UTC",
      "updated_date": "2025-05-21 04:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:01:08.899206"
    },
    {
      "arxiv_id": "2505.15080v1",
      "title": "SUS backprop: linear backpropagation algorithm for long inputs in transformers",
      "title_zh": "SUS backprop：用于 Transformer 中长输入的线性反向传播算法",
      "authors": [
        "Sergey Pankov",
        "Georges Harik"
      ],
      "abstract": "It is straightforward to design an unbiased gradient estimator that\nstochastically cuts the backpropagation flow through any part of a\ncomputational graph. By cutting the parts that have little effect on the\ncomputation, one can potentially save a significant amount of back-propagation\ncomputation in exchange for a minimal increase in the stochastic gradient\nvariance, in some situations. Such a situation occurs in the attention\nmechanism of the transformer architecture. For long sequences, attention\nbecomes the limiting factor, as its compute requirements increase quadratically\nwith sequence length $n$. At the same time, most attention weights become very\nsmall, as most attention heads tend to connect a given token with only a small\nfraction of other tokens in the sequence. These weights become promising\ntargets for cutting backpropagation. We propose a simple probabilistic rule\ncontrolled by a single parameter $c$ that cuts backpropagation through most\nattention weights, leaving at most $c$ interactions per token per attention\nhead. This brings a factor of $c/n$ reduction in the compute required for the\nattention backpropagation, turning it from quadratic $O(n^2)$ to linear\ncomplexity $O(nc)$. We have empirically verified that, for a typical\ntransformer model, cutting $99\\%$ of the attention gradient flow (i.e. choosing\n$c \\sim 20-30$) results in relative gradient variance increase of only about\n$1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is amenable\nto efficient sparse matrix implementation, thus being promising for making the\ncost of a backward pass negligible relative to the cost of a forward pass when\ntraining a transformer model on long sequences.",
      "tldr_zh": "该论文提出了一种名为 SUS backprop 的线性反向传播算法，旨在优化 Transformer 模型处理长序列输入时的计算效率。算法通过一个随机切断规则，利用参数 c 来选择性地切断对计算影响小的注意力权重，从而将注意力机制的反向传播复杂度从 O(n^2) 降至 O(nc)。实验结果显示，对于序列长度约 2000 的情况，切断 99% 的注意力梯度流仅导致梯度方差增加约 1%，并支持高效的稀疏矩阵实现，使训练时反向传播成本相对于前向传播变得可忽略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15080v1",
      "published_date": "2025-05-21 04:00:38 UTC",
      "updated_date": "2025-05-21 04:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:01:21.192450"
    },
    {
      "arxiv_id": "2505.15077v1",
      "title": "Data Augmentation and Resolution Enhancement using GANs and Diffusion Models for Tree Segmentation",
      "title_zh": "使用 GANs 和扩散模型进行数据增强和分辨率提升以实现树木分割",
      "authors": [
        "Alessandro dos Santos Ferreira",
        "Ana Paula Marques Ramos",
        "José Marcato Junior",
        "Wesley Nunes Gonçalves"
      ],
      "abstract": "Urban forests play a key role in enhancing environmental quality and\nsupporting biodiversity in cities. Mapping and monitoring these green spaces\nare crucial for urban planning and conservation, yet accurately detecting trees\nis challenging due to complex landscapes and the variability in image\nresolution caused by different satellite sensors or UAV flight altitudes. While\ndeep learning architectures have shown promise in addressing these challenges,\ntheir effectiveness remains strongly dependent on the availability of large and\nmanually labeled datasets, which are often expensive and difficult to obtain in\nsufficient quantity. In this work, we propose a novel pipeline that integrates\ndomain adaptation with GANs and Diffusion models to enhance the quality of\nlow-resolution aerial images. Our proposed pipeline enhances low-resolution\nimagery while preserving semantic content, enabling effective tree segmentation\nwithout requiring large volumes of manually annotated data. Leveraging models\nsuch as pix2pix, Real-ESRGAN, Latent Diffusion, and Stable Diffusion, we\ngenerate realistic and structurally consistent synthetic samples that expand\nthe training dataset and unify scale across domains. This approach not only\nimproves the robustness of segmentation models across different acquisition\nconditions but also provides a scalable and replicable solution for remote\nsensing scenarios with scarce annotation resources. Experimental results\ndemonstrated an improvement of over 50% in IoU for low-resolution images,\nhighlighting the effectiveness of our method compared to traditional pipelines.",
      "tldr_zh": "本研究针对城市森林树木分割面临的挑战（如复杂景观和图像分辨率变化），提出了一种整合域适应的管道，使用 GANs（如 pix2pix 和 Real-ESRGAN）和 Diffusion models（如 Latent Diffusion 和 Stable Diffusion）来增强低分辨率航空图像质量。 该管道通过生成真实合成样本扩展训练数据集、统一尺度并保留语义内容，从而实现有效的树分割，而无需大量手动标注数据。 实验结果显示，与传统方法相比，该方法在低分辨率图像上将 IoU 指标提高了超过 50%，为资源稀缺的遥感场景提供了一个鲁棒、可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T07 (Primary), 68U10, 68T45 (Secondary)",
        "I.4.8; I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15077v1",
      "published_date": "2025-05-21 03:57:10 UTC",
      "updated_date": "2025-05-21 03:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:01:33.002085"
    },
    {
      "arxiv_id": "2505.15076v1",
      "title": "Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories",
      "title_zh": "代理式特征增强：通过团队协作、规划和记忆统一选择和生成",
      "authors": [
        "Nanxu Gong",
        "Sixun Dong",
        "Haoyue Bai",
        "Xinyuan Wang",
        "Wangyang Ying",
        "Yanjie Fu"
      ],
      "abstract": "As a widely-used and practical tool, feature engineering transforms raw data\ninto discriminative features to advance AI model performance. However, existing\nmethods usually apply feature selection and generation separately, failing to\nstrive a balance between reducing redundancy and adding meaningful dimensions.\nTo fill this gap, we propose an agentic feature augmentation concept, where the\nunification of feature generation and selection is modeled as agentic teaming\nand planning. Specifically, we develop a Multi-Agent System with Long and\nShort-Term Memory (MAGS), comprising a selector agent to eliminate redundant\nfeatures, a generator agent to produce informative new dimensions, and a router\nagent that strategically coordinates their actions. We leverage in-context\nlearning with short-term memory for immediate feedback refinement and long-term\nmemory for globally optimal guidance. Additionally, we employ offline Proximal\nPolicy Optimization (PPO) reinforcement fine-tuning to train the router agent\nfor effective decision-making to navigate a vast discrete feature space.\nExtensive experiments demonstrate that this unified agentic framework\nconsistently achieves superior task performance by intelligently orchestrating\nfeature selection and generation.",
      "tldr_zh": "该论文提出 Agentic Feature Augmentation 概念，通过代理团队和规划统一特征选择和生成，旨在平衡减少冗余与添加有意义维度。研究开发了 Multi-Agent System with Long and Short-Term Memory (MAGS)，包括 selector agent 用于消除冗余特征、generator agent 用于产生信息丰富的维度，以及 router agent 负责战略协调。系统结合 in-context learning 与 short-term memory 进行即时反馈精炼，并利用 long-term memory 提供全局指导，同时通过 offline Proximal Policy Optimization (PPO) 强化学习训练 router agent 以优化决策。实验结果显示，该框架在任务性能上显著优于现有方法，实现了智能编排的特征增强。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15076v1",
      "published_date": "2025-05-21 03:49:24 UTC",
      "updated_date": "2025-05-21 03:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:01:45.542416"
    },
    {
      "arxiv_id": "2505.15075v1",
      "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Pinzhi Huang",
        "Jihan Yang",
        "Saining Xie",
        "Daisuke Kawahara"
      ],
      "abstract": "The rapid evolution of multimodal large language models (MLLMs) has\nsignificantly enhanced their real-world applications. However, achieving\nconsistent performance across languages, especially when integrating cultural\nknowledge, remains a significant challenge. To better assess this issue, we\nintroduce two new benchmarks: KnowRecall and VisRecall, which evaluate\ncross-lingual consistency in MLLMs. KnowRecall is a visual question answering\nbenchmark designed to measure factual knowledge consistency in 15 languages,\nfocusing on cultural and historical questions about global landmarks. VisRecall\nassesses visual memory consistency by asking models to describe landmark\nappearances in 9 languages without access to images. Experimental results\nreveal that state-of-the-art MLLMs, including proprietary ones, still struggle\nto achieve cross-lingual consistency. This underscores the need for more robust\napproaches that produce truly multilingual and culturally aware models.",
      "tldr_zh": "这篇论文介绍了两个新基准KnowRecall和VisRecall，用于评估多模态大型语言模型(MLLMs)的跨语言一致性，特别是整合文化知识的挑战。KnowRecall是一个视觉问答基准，测试MLLMs在15种语言中对全球地标的文化和历史事实知识的一致性，而VisRecall则评估模型在9种语言中描述地标外观的视觉记忆一致性，而不依赖图像。实验结果显示，现有的最先进MLLMs（包括专有模型）在跨语言一致性上表现不佳，突显了开发更鲁棒的多语言和文化感知模型的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/nlp-waseda/traveling-across-languages",
      "pdf_url": "http://arxiv.org/pdf/2505.15075v1",
      "published_date": "2025-05-21 03:43:37 UTC",
      "updated_date": "2025-05-21 03:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:01:57.237200"
    },
    {
      "arxiv_id": "2505.15074v1",
      "title": "DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Zhou",
        "Jing Zhu",
        "Shengyi Qian",
        "Zhuokai Zhao",
        "Xiyao Wang",
        "Xiaoyu Liu",
        "Ming Li",
        "Paiheng Xu",
        "Wei Ai",
        "Furong Huang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly aligned with human preferences\nthrough Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods,\nGroup Relative Policy Optimization (GRPO) has gained attention for its\nsimplicity and strong performance, notably eliminating the need for a learned\nvalue function. However, GRPO implicitly assumes a balanced domain distribution\nand uniform semantic alignment across groups - assumptions that rarely hold in\nreal-world datasets. When applied to multi-domain, imbalanced data, GRPO\ndisproportionately optimizes for dominant domains, neglecting underrepresented\nones and resulting in poor generalization and fairness. We propose\nDomain-Informed Self-Consistency Policy Optimization (DISCO), a principled\nextension to GRPO that addresses inter-group imbalance with two key\ninnovations. Domain-aware reward scaling counteracts frequency bias by\nreweighting optimization based on domain prevalence. Difficulty-aware reward\nscaling leverages prompt-level self-consistency to identify and prioritize\nuncertain prompts that offer greater learning value. Together, these strategies\npromote more equitable and effective policy learning across domains. Extensive\nexperiments across multiple LLMs and skewed training distributions show that\nDISCO improves generalization, outperforms existing GRPO variants by 5% on\nQwen3 models, and sets new state-of-the-art results on multi-domain alignment\nbenchmarks.",
      "tldr_zh": "这篇论文针对 Group Relative Policy Optimization (GRPO) 在多领域不平衡数据上的局限性，提出了 Domain-Informed Self-Consistency Policy Optimization (DISCO) 方法，以解决 GRPO 过度优化主导领域而忽略次要领域的偏见问题。DISCO 引入了 Domain-aware reward scaling 来根据领域流行度重新加权优化，以及 Difficulty-aware reward scaling 通过提示级别的自一致性识别和优先处理不确定性提示，从而实现更公平有效的策略学习。在多个 Large Language Models (LLMs) 和倾斜训练分布的实验中，DISCO 提升了泛化性能，在 Qwen3 模型上比现有 GRPO 变体提高 5%，并在多领域对齐基准上设置了新状态-of-the-art 结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15074v1",
      "published_date": "2025-05-21 03:43:29 UTC",
      "updated_date": "2025-05-21 03:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:02:09.805427"
    },
    {
      "arxiv_id": "2505.15068v1",
      "title": "ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges",
      "title_zh": "ModelingAgent: 桥接 LLMs 与数学建模以应对真实世界挑战",
      "authors": [
        "Cheng Qian",
        "Hongyi Du",
        "Hongru Wang",
        "Xiusi Chen",
        "Yuji Zhang",
        "Avirup Sil",
        "Chengxiang Zhai",
        "Kathleen McKeown",
        "Heng Ji"
      ],
      "abstract": "Recent progress in large language models (LLMs) has enabled substantial\nadvances in solving mathematical problems. However, existing benchmarks often\nfail to reflect the complexity of real-world problems, which demand open-ended,\ninterdisciplinary reasoning and integration of computational tools. To address\nthis gap, we introduce ModelingBench, a novel benchmark featuring\nreal-world-inspired, open-ended problems from math modeling competitions across\ndiverse domains, ranging from urban traffic optimization to ecosystem resource\nplanning. These tasks require translating natural language into formal\nmathematical formulations, applying appropriate tools, and producing\nstructured, defensible reports. ModelingBench also supports multiple valid\nsolutions, capturing the ambiguity and creativity of practical modeling. We\nalso present ModelingAgent, a multi-agent framework that coordinates tool use,\nsupports structured workflows, and enables iterative self-refinement to\ngenerate well-grounded, creative solutions. To evaluate outputs, we further\npropose ModelingJudge, an expert-in-the-loop system leveraging LLMs as\ndomain-specialized judges assessing solutions from multiple expert\nperspectives. Empirical results show that ModelingAgent substantially\noutperforms strong baselines and often produces solutions indistinguishable\nfrom those of human experts. Together, our work provides a comprehensive\nframework for evaluating and advancing real-world problem-solving in\nopen-ended, interdisciplinary modeling challenges.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在处理真实世界复杂问题时的局限性，引入了ModelingBench基准测试，该基准包含跨领域开放式问题，如城市交通优化和生态资源规划，要求将自然语言转化为正式数学公式并使用工具生成结构化报告。论文提出ModelingAgent多智能体框架，通过协调工具使用、支持结构化工作流和迭代自优化，实现可靠且创新的解决方案生成。同时，ModelingJudge系统利用LLMs作为领域专家进行多视角评估，实验结果显示ModelingAgent显著优于强基线模型，其输出质量可媲美人类专家，为LLMs在跨学科建模挑战中的实际应用提供了全面框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "36 Pages, 26 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15068v1",
      "published_date": "2025-05-21 03:33:23 UTC",
      "updated_date": "2025-05-21 03:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:02:22.594348"
    },
    {
      "arxiv_id": "2505.15065v1",
      "title": "The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support",
      "title_zh": "对同理心的追求：评估小型语言模型用于 PTSD 对话支持",
      "authors": [
        "Suhas BN",
        "Yash Mahajan",
        "Dominik Mattioli",
        "Andrew M. Sherrill",
        "Rosa I. Arriaga",
        "Chris W. Wiese",
        "Saeed Abdullah"
      ],
      "abstract": "Can small language models with 0.5B to 5B parameters meaningfully engage in\ntrauma-informed, empathetic dialogue for individuals with PTSD? We address this\nquestion by introducing TIDE, a dataset of 10,000 two-turn dialogues spanning\n500 diverse PTSD client personas and grounded in a three-factor empathy model:\nemotion recognition, distress normalization, and supportive reflection. All\nscenarios and reference responses were reviewed for realism and trauma\nsensitivity by a clinical psychologist specializing in PTSD. We evaluate eight\nsmall language models before and after fine-tuning, comparing their outputs to\na frontier model (Claude Sonnet 3.5). Our IRB-approved human evaluation and\nautomatic metrics show that fine-tuning generally improves perceived empathy,\nbut gains are highly scenario- and user-dependent, with smaller models facing\nan empathy ceiling. Demographic analysis shows older adults value distress\nvalidation and graduate-educated users prefer nuanced replies, while gender\neffects are minimal. We highlight the limitations of automatic metrics and the\nneed for context- and user-aware system design. Our findings, along with the\nplanned release of TIDE, provide a foundation for building safe,\nresource-efficient, and ethically sound empathetic AI to supplement, not\nreplace, clinical mental health care.",
      "tldr_zh": "本研究评估了小语言模型（0.5B至5B参数）在PTSD对话支持中的表现，旨在探讨它们是否能提供创伤知情且富有同理心的互动，引入了TIDE数据集，该数据集包含10,000个两轮对话，覆盖500个多样化PTSD患者角色，并基于三因素同理心模型（emotion recognition、distress normalization和supportive reflection）。通过IRB批准的人类评估和自动指标，实验显示微调后模型的同理心感知有所提升，但效果依赖于具体场景和用户特征，如老年人更重视痛苦验证，而研究生教育用户偏好细微回复。研究突出了自动指标的局限性，并为开发安全、资源高效的同理心AI提供基础，强调其作为临床心理健康补充而非替代的角色，并计划发布TIDE数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "68T50, 68T05",
        "I.2.7; I.2.1; H.5.2"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.15065v1",
      "published_date": "2025-05-21 03:32:46 UTC",
      "updated_date": "2025-05-21 03:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:02:36.042990"
    },
    {
      "arxiv_id": "2505.15062v1",
      "title": "Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiashu He",
        "Jinxuan Fan",
        "Bowen Jiang",
        "Ignacio Houine",
        "Dan Roth",
        "Alejandro Ribeiro"
      ],
      "abstract": "When addressing complex questions that require new information, people often\nassociate the question with existing knowledge to derive a sensible answer. For\ninstance, when evaluating whether melatonin aids insomnia, one might associate\n\"hormones helping mental disorders\" with \"melatonin being a hormone and\ninsomnia a mental disorder\" to complete the reasoning. Large Language Models\n(LLMs) also require such associative thinking, particularly in resolving\nscientific inquiries when retrieved knowledge is insufficient and does not\ndirectly answer the question. Graph Inspired Veracity Extrapolation (GIVE)\naddresses this by using a knowledge graph (KG) to extrapolate structured\nknowledge. However, it involves the construction and pruning of many\nhypothetical triplets, which limits efficiency and generalizability. We propose\nSelf-GIVE, a retrieve-RL framework that enhances LLMs with automatic\nassociative thinking through reinforcement learning. Self-GIVE extracts\nstructured information and entity sets to assist the model in linking to the\nqueried concepts. We address GIVE's key limitations: (1) extensive LLM calls\nand token overhead for knowledge extrapolation, (2) difficulty in deploying on\nsmaller LLMs (3B or 7B) due to complex instructions, and (3) inaccurate\nknowledge from LLM pruning. Specifically, after fine-tuning using self-GIVE\nwith a 135 node UMLS KG, it improves the performance of the Qwen2.5 3B and 7B\nmodels by up to $\\textbf{28.5%$\\rightarrow$71.4%}$ and\n$\\textbf{78.6$\\rightarrow$90.5%}$ in samples $\\textbf{unseen}$ in challenging\nbiomedical QA tasks. In particular, Self-GIVE allows the 7B model to match or\noutperform GPT3.5 turbo with GIVE, while cutting token usage by over 90\\%.\nSelf-GIVE enhances the scalable integration of structured retrieval and\nreasoning with associative thinking.",
      "tldr_zh": "该论文提出 Self-GIVE，一种基于强化学习的 retrieve-RL 框架，用于增强大型语言模型 (LLMs) 的联想思考能力，尤其在结构化知识有限时处理复杂科学问题。它通过提取结构化信息和实体集，帮助模型链接查询概念，同时解决 GIVE 方法的局限性，如减少 LLM 调用和 token 开销、适用于较小模型（如 3B 或 7B）、并提升知识准确性。实验结果显示，在 UMLS 知识图 (KG) 上微调后，Qwen2.5 3B 和 7B 模型在生物医学 QA 任务的未见样本上性能提升显著（3B 从 28.5% 到 71.4%，7B 从 78.6% 到 90.5%），并将 token 使用减少 90%，使 7B 模型能与 GPT3.5 turbo 相当或更好。这为 LLMs 与结构化检索和推理的集成提供了可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15062v1",
      "published_date": "2025-05-21 03:30:55 UTC",
      "updated_date": "2025-05-21 03:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:02:47.785078"
    },
    {
      "arxiv_id": "2505.15058v1",
      "title": "AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars",
      "title_zh": "AsynFusion：面向解耦全身音频",
      "authors": [
        "Tianbao Zhang",
        "Jian Zhao",
        "Yuer Li",
        "Zheng Zhu",
        "Ping Hu",
        "Zhaoxin Fan",
        "Wenjun Wu",
        "Xuelong Li"
      ],
      "abstract": "Whole-body audio-driven avatar pose and expression generation is a critical\ntask for creating lifelike digital humans and enhancing the capabilities of\ninteractive virtual agents, with wide-ranging applications in virtual reality,\ndigital entertainment, and remote communication. Existing approaches often\ngenerate audio-driven facial expressions and gestures independently, which\nintroduces a significant limitation: the lack of seamless coordination between\nfacial and gestural elements, resulting in less natural and cohesive\nanimations. To address this limitation, we propose AsynFusion, a novel\nframework that leverages diffusion transformers to achieve harmonious\nexpression and gesture synthesis. The proposed method is built upon a\ndual-branch DiT architecture, which enables the parallel generation of facial\nexpressions and gestures. Within the model, we introduce a Cooperative\nSynchronization Module to facilitate bidirectional feature interaction between\nthe two modalities, and an Asynchronous LCM Sampling strategy to reduce\ncomputational overhead while maintaining high-quality outputs. Extensive\nexperiments demonstrate that AsynFusion achieves state-of-the-art performance\nin generating real-time, synchronized whole-body animations, consistently\noutperforming existing methods in both quantitative and qualitative\nevaluations.",
      "tldr_zh": "本研究提出 AsynFusion 框架，利用 diffusion transformers 实现音频驱动的全身头像动画，解决现有方法中面部表情和手势独立生成导致的不协调问题。该框架基于双分支 DiT 架构，实现平行生成表情和手势，并通过 Cooperative Synchronization Module 进行双向特征交互，以及 Asynchronous LCM Sampling strategy 减少计算开销。实验结果表明，AsynFusion 在实时同步全身动画生成上达到最先进性能，在定量和定性评估中均优于现有方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "eess.AS",
        "68T10"
      ],
      "primary_category": "cs.SD",
      "comment": "11pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2505.15058v1",
      "published_date": "2025-05-21 03:28:53 UTC",
      "updated_date": "2025-05-21 03:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:02:56.746845"
    },
    {
      "arxiv_id": "2505.15054v1",
      "title": "MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Cai",
        "Jiahui Bai",
        "Tao Tang",
        "Joshua Luo",
        "Tianyu Zhu",
        "Ling Liu",
        "Feng Luo"
      ],
      "abstract": "Precise recognition, editing, and generation of molecules are essential\nprerequisites for both chemists and AI systems tackling various chemical tasks.\nWe present MolLangBench, a comprehensive benchmark designed to evaluate\nfundamental molecule-language interface tasks: language-prompted molecular\nstructure recognition, editing, and generation. To ensure high-quality,\nunambiguous, and deterministic outputs, we construct the recognition tasks\nusing automated cheminformatics tools, and curate editing and generation tasks\nthrough rigorous expert annotation and validation. MolLangBench supports the\nevaluation of models that interface language with different molecular\nrepresentations, including linear strings, molecular images, and molecular\ngraphs. Evaluations of state-of-the-art models reveal significant limitations:\nthe strongest model (o3) achieves $79.2\\%$ and $78.5\\%$ accuracy on recognition\nand editing tasks, which are intuitively simple for humans, and performs even\nworse on the generation task, reaching only $29.0\\%$ accuracy. These results\nhighlight the shortcomings of current AI systems in handling even preliminary\nmolecular recognition and manipulation tasks. We hope MolLangBench will\ncatalyze further research toward more effective and reliable AI systems for\nchemical applications.",
      "tldr_zh": "本文提出 MolLangBench，这是一个全面基准，用于评估语言提示下的分子结构 recognition、editing 和 generation 任务。该基准通过自动化 cheminformatics 工具构建识别任务，并通过专家注释和验证确保 editing 和 generation 任务的高质量和确定性，支持多种分子表示如线性字符串、分子图像和分子图。评估结果显示，最先进模型 o3 在 recognition 和 editing 任务上的准确率分别为 79.2% 和 78.5%，而在 generation 任务上仅为 29.0%，突显了当前 AI 系统在分子任务上的显著局限性。该基准旨在推动更有效可靠的 AI 系统在化学应用中的研究和发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15054v1",
      "published_date": "2025-05-21 03:22:01 UTC",
      "updated_date": "2025-05-21 03:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:03:09.730273"
    },
    {
      "arxiv_id": "2505.15049v1",
      "title": "Towards a Working Definition of Designing Generative User Interfaces",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungho Lee"
      ],
      "abstract": "Generative UI is transforming interface design by facilitating AI-driven\ncollaborative workflows between designers and computational systems. This study\nestablishes a working definition of Generative UI through a multi-method\nqualitative approach, integrating insights from a systematic literature review\nof 127 publications, expert interviews with 18 participants, and analyses of 12\ncase studies. Our findings identify five core themes that position Generative\nUI as an iterative and co-creative process. We highlight emerging design\nmodels, including hybrid creation, curation-based workflows, and AI-assisted\nrefinement strategies. Additionally, we examine ethical challenges, evaluation\ncriteria, and interaction models that shape the field. By proposing a\nconceptual foundation, this study advances both theoretical discourse and\npractical implementation, guiding future HCI research toward responsible and\neffective generative UI design practices.",
      "tldr_zh": "这篇论文旨在为 Generative UI（生成式用户界面）设计建立一个工作定义，通过多方法定性研究整合系统文献综述（127 篇出版物）、专家访谈（18 名参与者）和案例分析（12 个案例）。研究识别了五个核心主题，将 Generative UI 定位为一个迭代且共同创造的过程，并突出新兴设计模型，如混合创建、基于策展的工作流和 AI 辅助精炼策略，同时探讨了伦理挑战、评估标准和交互模型。最终，该研究为 HCI（人机交互）领域提供了概念基础，推进理论讨论和实际应用，促进负责任且有效的生成式 UI 设计实践。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2; D.2.2; H.1.2; I.3.6"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15049v1",
      "published_date": "2025-05-21 03:14:09 UTC",
      "updated_date": "2025-05-21 03:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:03:21.507428"
    },
    {
      "arxiv_id": "2505.15047v1",
      "title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration",
      "title_zh": "PiFlow: ",
      "authors": [
        "Yingming Pu",
        "Tao Lin",
        "Hongyu Chen"
      ],
      "abstract": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate\nremarkable potential for scientific discovery. Existing approaches, however,\noften automate scientific discovery using predefined workflows that lack\nrationality constraints. This often leads to aimless hypothesizing and a\nfailure to consistently link hypotheses with evidence, thereby hindering\nsystematic uncertainty reduction. Overcoming these limitations fundamentally\nrequires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an\ninformation-theoretical framework, treating automated scientific discovery as a\nstructured uncertainty reduction problem guided by principles (e.g., scientific\nlaws). In evaluations across three distinct scientific domains -- discovering\nnanomaterial structures, bio-molecules, and superconductor candidates with\ntargeted properties -- our method significantly improves discovery efficiency,\nreflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property\nvalues versus exploration steps, and enhances solution quality by 94.06\\%\ncompared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a\nPlug-and-Play method, establishing a novel paradigm shift in highly efficient\nautomated scientific discovery, paving the way for more robust and accelerated\nAI-driven research. Code is publicly available at our\n\\href{https://github.com/amair-lab/PiFlow}{GitHub}.",
      "tldr_zh": "本文提出 PiFlow，一种基于信息理论的框架，将自动科学发现视为结构化的不确定性减少问题，并通过原则（如科学定律）指导多智能体系统（MAS），以克服现有 LLM-based 方法中假设随意和证据链接不足的局限性。在纳米材料结构、生物分子和超导体候选物的三个领域评估中，PiFlow 显著提升了发现效率，AUC 指标较基础系统提高了 73.55%，并将解决方案质量提升 94.06%。总体而言，PiFlow 作为即插即用方法，开启了高效 AI 驱动科学发现的新范式，促进更稳健和加速的研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15047v1",
      "published_date": "2025-05-21 03:09:39 UTC",
      "updated_date": "2025-05-21 03:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:03:35.624777"
    },
    {
      "arxiv_id": "2505.15046v2",
      "title": "ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding",
      "title_zh": "ChartCards: ",
      "authors": [
        "Yifan Wu",
        "Lutao Yan",
        "Leixian Shen",
        "Yinan Mei",
        "Jiannan Wang",
        "Yuyu Luo"
      ],
      "abstract": "The emergence of Multi-modal Large Language Models (MLLMs) presents new\nopportunities for chart understanding. However, due to the fine-grained nature\nof these tasks, applying MLLMs typically requires large, high-quality datasets\nfor task-specific fine-tuning, leading to high data collection and training\ncosts. To address this, we propose ChartCards, a unified chart-metadata\ngeneration framework for multi-task chart understanding. ChartCards\nsystematically synthesizes various chart information, including data tables,\nvisualization code, visual elements, and multi-dimensional semantic captions.\nBy structuring this information into organized metadata, ChartCards enables a\nsingle chart to support multiple downstream tasks, such as text-to-chart\nretrieval, chart summarization, chart-to-table conversion, chart description,\nand chart question answering. Using ChartCards, we further construct MetaChart,\na large-scale high-quality dataset containing 10,862 data tables, 85K charts,\nand 170 K high-quality chart captions. We validate the dataset through\nqualitative crowdsourcing evaluations and quantitative fine-tuning experiments\nacross various chart understanding tasks. Fine-tuning six different models on\nMetaChart resulted in an average performance improvement of 5% across all\ntasks. The most notable improvements are seen in text-to-chart retrieval and\nchart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements\nof 17% and 28%, respectively.",
      "tldr_zh": "本文提出 ChartCards 框架，一种统一的图表元数据生成方法，旨在解决 Multi-modal Large Language Models (MLLMs) 在多任务图表理解中面临的数据收集和训练成本高的问题。ChartCards 通过系统合成数据表、可视化代码、视觉元素和多维语义标题等信息，使单个图表能够支持多种下游任务，包括文本到图表检索、图表总结、图表到表格转换、图表描述和图表问答。基于此框架，作者构建了大规模高质量数据集 MetaChart，包含 10,862 个数据表、85K 图表和 170K 图表标题；实验结果显示，微调六种模型后，任务性能平均提升5%，其中文本到图表检索和图表到表格任务分别由 Long-CLIP 和 Llama 3.2-11B 实现17% 和 28% 的显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15046v2",
      "published_date": "2025-05-21 03:07:47 UTC",
      "updated_date": "2025-05-22 15:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:03:46.328005"
    },
    {
      "arxiv_id": "2505.15044v1",
      "title": "Learning-based Airflow Inertial Odometry for MAVs using Thermal Anemometers in a GPS and vision denied environment",
      "title_zh": "翻译失败",
      "authors": [
        "Ze Wang",
        "Jingang Qu",
        "Zhenyu Gao",
        "Pascal Morin"
      ],
      "abstract": "This work demonstrates an airflow inertial based odometry system with\nmulti-sensor data fusion, including thermal anemometer, IMU, ESC, and\nbarometer. This goal is challenging because low-cost IMUs and barometers have\nsignificant bias, and anemometer measurements are very susceptible to\ninterference from spinning propellers and ground effects. We employ a GRU-based\ndeep neural network to estimate relative air speed from noisy and disturbed\nanemometer measurements, and an observer with bias model to fuse the sensor\ndata and thus estimate the state of aerial vehicle. A complete flight data,\nincluding takeoff and landing on the ground, shows that the approach is able to\ndecouple the downwash induced wind speed caused by propellers and the ground\neffect, and accurately estimate the flight speed in a wind-free indoor\nenvironment. IMU, and barometer bias are effectively estimated, which\nsignificantly reduces the position integration drift, which is only 5.7m for\n203s manual random flight. The open source is available on\nhttps://github.com/SyRoCo-ISIR/Flight-Speed-Estimation-Airflow.",
      "tldr_zh": "本文提出了一种基于学习的空气流惯性里程计系统，用于微型航空器(MAVs)在GPS和视觉不可用环境下的定位，通过融合热风速计、IMU、ESC和气压计等多传感器数据来实现。系统采用GRU-based深度神经网络从噪声测量中估计相对空气速度，并使用带有偏差模型的观测器融合数据，以有效分离螺旋桨向下气流和地效应干扰。实验结果显示，该方法在203秒手动随机飞行中仅产生5.7m的位置积分漂移，显著提高了定位准确性，并提供了开源代码（https://github.com/SyRoCo-ISIR/Flight-Speed-Estimation-Airflow）。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15044v1",
      "published_date": "2025-05-21 02:53:49 UTC",
      "updated_date": "2025-05-21 02:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:03:57.921031"
    },
    {
      "arxiv_id": "2505.15039v1",
      "title": "LogiCase: Effective Test Case Generation from Logical Description in Competitive Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Sicheol Sung",
        "Aditi",
        "Dogyu kim",
        "Yo-Sub Han",
        "Sang-Ki Ko"
      ],
      "abstract": "Automated Test Case Generation (ATCG) is crucial for evaluating software\nreliability, particularly in competitive programming where robust algorithm\nassessments depend on diverse and accurate test cases. However, existing ATCG\nmethods often fail to meet complex specifications or generate effective corner\ncases, limiting their utility. In this work, we introduce Context-Free Grammars\nwith Counters (CCFGs), a formalism that captures both syntactic and semantic\nstructures in input specifications. Using a fine-tuned CodeT5 model, we\ntranslate natural language input specifications into CCFGs, enabling the\nsystematic generation of high-quality test cases. Experiments on the\nCodeContests dataset demonstrate that CCFG-based test cases outperform baseline\nmethods in identifying incorrect algorithms, achieving significant gains in\nvalidity and effectiveness. Our approach provides a scalable and reliable\ngrammar-driven framework for enhancing automated competitive programming\nevaluations.",
      "tldr_zh": "本论文针对 Automated Test Case Generation (ATCG) 在竞争性编程中的挑战，提出 LogiCase 方法，以解决现有方法无法有效处理复杂规范和边界测试用例的问题。LogiCase 引入 Context-Free Grammars with Counters (CCFGs) 形式主义来捕捉输入规范的语法和语义结构，并使用 fine-tuned CodeT5 模型将自然语言规范转化为 CCFGs，从而系统生成高质量测试用例。在 CodeContests 数据集上的实验显示，该方法在识别错误算法方面显著优于基线方法，提高了测试用例的有效性和可靠性，并提供了一个可扩展的基于语法的框架来提升自动化编程评估。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15039v1",
      "published_date": "2025-05-21 02:48:01 UTC",
      "updated_date": "2025-05-21 02:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:04:10.503942"
    },
    {
      "arxiv_id": "2505.15038v1",
      "title": "Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyan Zhao",
        "Xuansheng Wu",
        "Fan Yang",
        "Bo Shen",
        "Ninghao Liu",
        "Mengnan Du"
      ],
      "abstract": "Linear Concept Vectors have proven effective for steering large language\nmodels (LLMs). While existing approaches like linear probing and\ndifference-in-means derive these vectors from LLM hidden representations,\ndiverse data introduces noises (i.e., irrelevant features) that challenge\nsteering robustness. To address this, we propose Sparse Autoencoder-Denoised\nConcept Vectors (SDCV), which uses Sparse Autoencoders to filter out noisy\nfeatures from hidden representations. When applied to linear probing and\ndifference-in-means, our method improves their steering success rates. We\nvalidate our noise hypothesis through counterfactual experiments and feature\nvisualizations.",
      "tldr_zh": "该研究针对线性概念向量(Linear Concept Vectors)在引导大型语言模型(LLMs)时面临的噪声问题（如无关特征），提出了一种Sparse Autoencoder-Denoised Concept Vectors (SDCV)方法，使用Sparse Autoencoders过滤隐藏表示中的噪声特征。SDCV应用于linear probing和difference-in-means技术后，显著提高了引导成功率。通过反事实实验和特征可视化，验证了噪声假设的准确性。该方法增强了LLMs引导的鲁棒性，为更可靠的模型操控提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15038v1",
      "published_date": "2025-05-21 02:45:11 UTC",
      "updated_date": "2025-05-21 02:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:04:20.959001"
    },
    {
      "arxiv_id": "2505.15036v1",
      "title": "Fault-Tolerant Multi-Robot Coordination with Limited Sensing within Confined Environments",
      "title_zh": "在受限环境中具有有限感知的多机器人容错协调",
      "authors": [
        "Kehinde O. Aina",
        "Hosain Bagheri",
        "Daniel I. Goldman"
      ],
      "abstract": "As robots are increasingly deployed to collaborate on tasks within shared\nworkspaces and resources, the failure of an individual robot can critically\naffect the group's performance. This issue is particularly challenging when\nrobots lack global information or direct communication, relying instead on\nsocial interaction for coordination and to complete their tasks. In this study,\nwe propose a novel fault-tolerance technique leveraging physical contact\ninteractions in multi-robot systems, specifically under conditions of limited\nsensing and spatial confinement. We introduce the \"Active Contact Response\"\n(ACR) method, where each robot modulates its behavior based on the likelihood\nof encountering an inoperative (faulty) robot. Active robots are capable of\ncollectively repositioning stationary and faulty peers to reduce obstructions\nand maintain optimal group functionality. We implement our algorithm in a team\nof autonomous robots, equipped with contact-sensing and collision-tolerance\ncapabilities, tasked with collectively excavating cohesive model pellets.\nExperimental results indicate that the ACR method significantly improves the\nsystem's recovery time from robot failures, enabling continued collective\nexcavation with minimal performance degradation. Thus, this work demonstrates\nthe potential of leveraging local, social, and physical interactions to enhance\nfault tolerance and coordination in multi-robot systems operating in\nconstrained and extreme environments.",
      "tldr_zh": "本文研究了在受限环境中，多机器人系统面对有限感知时如何实现容错协调，以应对单个机器人故障对整体性能的影响。提出了一种名为“Active Contact Response”(ACR)的方法，利用物理接触交互，让活跃机器人根据故障可能性调整行为，并集体移动故障机器人以减少障碍并维持群组功能。在配备接触感应和碰撞耐受能力的机器人团队中进行实验，结果显示ACR显著缩短了系统从故障中恢复的时间，并在集体挖掘任务中最小化性能下降。该工作证明了通过本地、社会和物理交互来提升多机器人系统在约束环境中的容错性和协调性的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 4 figures. Accepted to DARS 2024 (Distributed Autonomous\n  Robotic Systems), to appear in Springer Proceedings in Advanced Robotics",
      "pdf_url": "http://arxiv.org/pdf/2505.15036v1",
      "published_date": "2025-05-21 02:43:36 UTC",
      "updated_date": "2025-05-21 02:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:04:33.598104"
    },
    {
      "arxiv_id": "2505.15034v1",
      "title": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning",
      "title_zh": "RL Tango：强化生成器",
      "authors": [
        "Kaiwen Zha",
        "Zhengqi Gao",
        "Maohao Shen",
        "Zhang-Wei Hong",
        "Duane S. Boning",
        "Dina Katabi"
      ],
      "abstract": "Reinforcement learning (RL) has recently emerged as a compelling approach for\nenhancing the reasoning capabilities of large language models (LLMs), where an\nLLM generator serves as a policy guided by a verifier (reward model). However,\ncurrent RL post-training methods for LLMs typically use verifiers that are\nfixed (rule-based or frozen pretrained) or trained discriminatively via\nsupervised fine-tuning (SFT). Such designs are susceptible to reward hacking\nand generalize poorly beyond their training distributions. To overcome these\nlimitations, we propose Tango, a novel framework that uses RL to concurrently\ntrain both an LLM generator and a verifier in an interleaved manner. A central\ninnovation of Tango is its generative, process-level LLM verifier, which is\ntrained via RL and co-evolves with the generator. Importantly, the verifier is\ntrained solely based on outcome-level verification correctness rewards without\nrequiring explicit process-level annotations. This generative RL-trained\nverifier exhibits improved robustness and superior generalization compared to\ndeterministic or SFT-trained verifiers, fostering effective mutual\nreinforcement with the generator. Extensive experiments demonstrate that both\ncomponents of Tango achieve state-of-the-art results among 7B/8B-scale models:\nthe generator attains best-in-class performance across five competition-level\nmath benchmarks and four challenging out-of-domain reasoning tasks, while the\nverifier leads on the ProcessBench dataset. Remarkably, both components exhibit\nparticularly substantial improvements on the most difficult mathematical\nreasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.",
      "tldr_zh": "该研究提出RL Tango框架，利用强化学习（RL）同时训练大型语言模型（LLMs）的生成器和验证器，以提升语言推理能力。该框架创新性地采用生成式、过程级别的LLM验证器，通过RL交替训练方式，使验证器与生成器共同演化，仅基于结果级正确性奖励，而非需要显式过程级注解，从而避免了传统验证器（如基于SFT的）易受reward hacking和泛化差的问题。实验结果显示，Tango的生成器在五个竞赛级数学基准和四个挑战性推理任务上达到7B/8B规模模型的顶尖性能，而验证器在ProcessBench数据集上领先，尤其在最难的数学推理问题上表现出显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Tech report. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2505.15034v1",
      "published_date": "2025-05-21 02:43:15 UTC",
      "updated_date": "2025-05-21 02:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:04:44.927870"
    },
    {
      "arxiv_id": "2505.15033v1",
      "title": "Toward Task Capable Active Matter: Learning to Avoid Clogging in Confined Collectives via Collisions",
      "title_zh": "翻译失败",
      "authors": [
        "Kehinde O. Aina",
        "Ram Avinery",
        "Hui-Shun Kuan",
        "Meredith D. Betterton",
        "Michael A. D. Goodisman",
        "Daniel I. Goldman"
      ],
      "abstract": "Social organisms which construct nests consisting of tunnels and chambers\nnecessarily navigate confined and crowded conditions. Unlike low-density\ncollectives like bird flocks and insect swarms, in which hydrodynamic and\nstatistical phenomena dominate, the physics of glasses and supercooled fluids\nis important to understand clogging behaviors in high-density collectives. Our\nprevious work revealed that fire ants flowing in confined tunnels utilize\ndiverse behaviors like unequal workload distributions, spontaneous direction\nreversals, and limited interaction times to mitigate clogging and jamming and\nthus maintain functional flow; implementation of similar rules in a small\nrobophysical swarm led to high performance through spontaneous dissolution of\nclogs and clusters. However, how the insects learn such behaviors, and how we\ncan develop \"task capable\" active matter in such regimes, remains a challenge\nin part because interaction dynamics are dominated by local, time-consuming\ncollisions and no single agent can guide the entire collective. Here, we\nhypothesized that effective flow and clog mitigation could emerge purely\nthrough local learning. We tasked small groups of robots with pellet excavation\nin a narrow tunnel, allowing them to modify reversal probabilities over time.\nInitially, robots had equal probabilities and clogs were common. Reversals\nimproved flow. When reversal probabilities adapted via collisions and noisy\ntunnel length estimates, workload inequality and performance improved. Our\nrobophysical study of an excavating swarm shows that, despite the seeming\ncomplexity and difficulty of the task, simple learning rules can mitigate or\nleverage unavoidable features in task-capable dense active matter, leading to\nhypotheses for dense biological and robotic swarms.",
      "tldr_zh": "本研究探讨了高密度集体（如蚂蚁或机器人群）在狭窄环境中通过碰撞学习来避免堵塞(clogging)的机制，针对active matter的物理特性提出假设。研究者设计实验，让小型机器人群在隧道中进行颗粒挖掘，通过调整反转概率基于局部碰撞和噪音隧道长度估计，实现工作负载不均等分布和流动改善。结果显示，这种简单学习规则显著提升了集体性能，为密集生物和机器人swarms提供新假设，推动任务导向active matter的发展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 9 figures. Published in Frontiers in Physics, Social\n  Physics section. Includes experimental and simulation analysis of multi-robot\n  excavation using decentralized learning",
      "pdf_url": "http://arxiv.org/pdf/2505.15033v1",
      "published_date": "2025-05-21 02:42:32 UTC",
      "updated_date": "2025-05-21 02:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:04:57.013609"
    },
    {
      "arxiv_id": "2505.15031v1",
      "title": "Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Wu",
        "Haixu Xi",
        "Chengzhi Zhang"
      ],
      "abstract": "Peer review is vital in academia for evaluating research quality. Top AI\nconferences use reviewer confidence scores to ensure review reliability, but\nexisting studies lack fine-grained analysis of text-score consistency,\npotentially missing key details. This work assesses consistency at word,\nsentence, and aspect levels using deep learning and NLP conference review data.\nWe employ deep learning to detect hedge sentences and aspects, then analyze\nreport length, hedge word/sentence frequency, aspect mentions, and sentiment to\nevaluate text-score alignment. Correlation, significance, and regression tests\nexamine confidence scores' impact on paper outcomes. Results show high\ntext-score consistency across all levels, with regression revealing higher\nconfidence scores correlate with paper rejection, validating expert assessments\nand peer review fairness.",
      "tldr_zh": "本文研究了顶级 AI 会议中审稿人的 confidence scores 是否与审稿内容一致，通过对 peer review 数据进行细粒度分析填补了现有研究的空白。研究采用 deep learning 和 NLP 技术，在词、句子和方面级别评估文本-分数一致性，包括检测 hedge sentences、分析报告长度、模糊词/句频率、方面提及和情感。结果显示高一致性，且回归测试表明更高 confidence scores 与论文被拒相关，这验证了专家评估和 peer review 过程的公平性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15031v1",
      "published_date": "2025-05-21 02:26:47 UTC",
      "updated_date": "2025-05-21 02:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:05:09.227859"
    },
    {
      "arxiv_id": "2505.15023v1",
      "title": "Towards a Science of Causal Interpretability in Deep Learning for Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "David N. Palacio"
      ],
      "abstract": "This dissertation addresses achieving causal interpretability in Deep\nLearning for Software Engineering (DL4SE). While Neural Code Models (NCMs) show\nstrong performance in automating software tasks, their lack of transparency in\ncausal relationships between inputs and outputs limits full understanding of\ntheir capabilities. To build trust in NCMs, researchers and practitioners must\nexplain code predictions. Associational interpretability, which identifies\ncorrelations, is often insufficient for tasks requiring intervention and change\nanalysis. To address this, the dissertation introduces DoCode, a novel post hoc\ninterpretability method for NCMs. DoCode uses causal inference to provide\nprogramming language-oriented explanations of model predictions. It follows a\nfour-step pipeline: modeling causal problems using Structural Causal Models\n(SCMs), identifying the causal estimand, estimating effects with metrics like\nAverage Treatment Effect (ATE), and refuting effect estimates. Its framework is\nextensible, with an example that reduces spurious correlations by grounding\nexplanations in programming language properties. A case study on deep code\ngeneration across interpretability scenarios and various deep learning\narchitectures demonstrates DoCode's benefits. Results show NCMs' sensitivity to\ncode syntax changes and their ability to learn certain programming concepts\nwhile minimizing confounding bias. The dissertation also examines associational\ninterpretability as a foundation, analyzing software information's causal\nnature using tools like COMET and TraceXplainer for traceability. It highlights\nthe need to identify code confounders and offers practical guidelines for\napplying causal interpretability to NCMs, contributing to more trustworthy AI\nin software engineering.",
      "tldr_zh": "这篇论文探讨了在深度学习用于软件工程 (DL4SE) 中实现因果可解释性的科学问题，针对 Neural Code Models (NCMs) 的预测缺乏透明度导致的信任缺失。论文引入了 DoCode，一种新型后验解释方法，利用 Structural Causal Models (SCMs) 和因果推理（如 Average Treatment Effect, ATE）构建四步管道，以提供针对编程语言的解释，并减少虚假相关性。通过案例研究，DoCode 证明了 NCMs 对代码语法变化的敏感性、学习编程概念的能力，同时最小化混淆偏差，并为更可信的 AI 应用提供了实用指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "PhD thesis, To appear in ProQuest",
      "pdf_url": "http://arxiv.org/pdf/2505.15023v1",
      "published_date": "2025-05-21 02:13:11 UTC",
      "updated_date": "2025-05-21 02:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:05:22.491783"
    },
    {
      "arxiv_id": "2505.15011v1",
      "title": "HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning",
      "title_zh": "HAVA：通过奖励加权实现价值对齐的混合方法，用于强化学习",
      "authors": [
        "Kryspin Varys",
        "Federico Cerutti",
        "Adam Sobey",
        "Timothy J. Norman"
      ],
      "abstract": "Our society is governed by a set of norms which together bring about the\nvalues we cherish such as safety, fairness or trustworthiness. The goal of\nvalue-alignment is to create agents that not only do their tasks but through\ntheir behaviours also promote these values. Many of the norms are written as\nlaws or rules (legal / safety norms) but even more remain unwritten (social\nnorms). Furthermore, the techniques used to represent these norms also differ.\nSafety / legal norms are often represented explicitly, for example, in some\nlogical language while social norms are typically learned and remain hidden in\nthe parameter space of a neural network. There is a lack of approaches in the\nliterature that could combine these various norm representations into a single\nalgorithm. We propose a novel method that integrates these norms into the\nreinforcement learning process. Our method monitors the agent's compliance with\nthe given norms and summarizes it in a quantity we call the agent's reputation.\nThis quantity is used to weigh the received rewards to motivate the agent to\nbecome value-aligned. We carry out a series of experiments including a\ncontinuous state space traffic problem to demonstrate the importance of the\nwritten and unwritten norms and show how our method can find the value-aligned\npolicies. Furthermore, we carry out ablations to demonstrate why it is better\nto combine these two groups of norms rather than using either separately.",
      "tldr_zh": "该论文提出了一种混合方法HAVA，用于强化学习中的价值对齐（value-alignment），旨在让代理不仅完成任务，还通过行为促进社会价值观如安全、公平和可信度。HAVA通过监控代理对书面规范（如法律规则）和非书面规范（如社交规范）的遵守，计算一个“reputation”量来权衡奖励，从而激励代理生成价值对齐的政策。在实验中，包括一个连续状态空间的交通问题，HAVA展示了整合两种规范的必要性，并通过消融实验证明了比单独使用任一规范更有效的优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15011v1",
      "published_date": "2025-05-21 01:32:54 UTC",
      "updated_date": "2025-05-21 01:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:05:32.824056"
    },
    {
      "arxiv_id": "2505.15009v1",
      "title": "One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Nguyen",
        "Thanh Nguyen-Tang"
      ],
      "abstract": "We study the approximation capabilities and on-convergence behaviors of\none-layer transformers on the noiseless and noisy in-context reasoning of\nnext-token prediction. Existing theoretical results focus on understanding the\nin-context reasoning behaviors for either the first gradient step or when the\nnumber of samples is infinite. Furthermore, no convergence rates nor\ngeneralization abilities were known. Our work addresses these gaps by showing\nthat there exists a class of one-layer transformers that are provably\nBayes-optimal with both linear and ReLU attention. When being trained with\ngradient descent, we show via a finite-sample analysis that the expected loss\nof these transformers converges at linear rate to the Bayes risk. Moreover, we\nprove that the trained models generalize to unseen samples as well as exhibit\nlearning behaviors that were empirically observed in previous works. Our\ntheoretical findings are further supported by extensive empirical validations.",
      "tldr_zh": "该研究证明，一层 Transformer 在无噪声和有噪声的 in-context reasoning 和 distributional association learning 任务中，对于 next-token prediction 是 provably Bayes-optimal 的，使用线性或 ReLU attention。论文通过有限样本分析显示，这些模型在 gradient descent 训练下，预期损失以线性速率收敛到 Bayes risk，并能泛化到未见样本，同时展现出之前实证观察到的学习行为。理论结果通过广泛的实证验证得到支持，为理解 Transformer 的近似能力和收敛行为提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15009v1",
      "published_date": "2025-05-21 01:26:44 UTC",
      "updated_date": "2025-05-21 01:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:05:45.535047"
    },
    {
      "arxiv_id": "2505.15008v1",
      "title": "Know When to Abstain: Optimal Selective Classification with Likelihood Ratios",
      "title_zh": "翻译失败",
      "authors": [
        "Alvin Heng",
        "Harold Soh"
      ],
      "abstract": "Selective classification enhances the reliability of predictive models by\nallowing them to abstain from making uncertain predictions. In this work, we\nrevisit the design of optimal selection functions through the lens of the\nNeyman--Pearson lemma, a classical result in statistics that characterizes the\noptimal rejection rule as a likelihood ratio test. We show that this\nperspective not only unifies the behavior of several post-hoc selection\nbaselines, but also motivates new approaches to selective classification which\nwe propose here. A central focus of our work is the setting of covariate shift,\nwhere the input distribution at test time differs from that at training. This\nrealistic and challenging scenario remains relatively underexplored in the\ncontext of selective classification. We evaluate our proposed methods across a\nrange of vision and language tasks, including both supervised learning and\nvision-language models. Our experiments demonstrate that our\nNeyman--Pearson-informed methods consistently outperform existing baselines,\nindicating that likelihood ratio-based selection offers a robust mechanism for\nimproving selective classification under covariate shifts. Our code is publicly\navailable at https://github.com/clear-nus/sc-likelihood-ratios.",
      "tldr_zh": "这项研究重新审视了 Selective Classification 的设计，利用 Neyman-Pearson lemma 将最优拒绝规则表述为 Likelihood Ratio Test，从而统一了现有后验选择基线的行为，并提出了新的方法。论文重点关注 Covariate Shift 场景，即测试时的输入分布与训练时不同，这种现实挑战下，新方法在视觉和语言任务（如监督学习和视觉语言模型）中 consistently outperform 了现有基线。实验结果表明，Likelihood Ratio-based 选择机制显著提升了模型的可靠性和鲁棒性，代码已公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15008v1",
      "published_date": "2025-05-21 01:26:21 UTC",
      "updated_date": "2025-05-21 01:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:05:58.311542"
    },
    {
      "arxiv_id": "2505.15002v1",
      "title": "Unraveling the iterative CHAD",
      "title_zh": "揭示迭代 CHAD",
      "authors": [
        "Fernando Lucatelli Nunes",
        "Gordon Plotkin",
        "Matthijs Vákár"
      ],
      "abstract": "Combinatory Homomorphic Automatic Differentiation (CHAD) was originally\nformulated as a semantics-driven source transformation for reverse-mode AD in\ntotal programming languages. We extend this framework to partial languages with\nfeatures such as potentially non-terminating operations, real-valued\nconditionals, and iteration constructs like while-loops, while preserving\nCHAD's structure-preserving semantics principle. A key contribution is the\nintroduction of iteration-extensive indexed categories, which allow iteration\nin the base category to lift to parameterized initial algebras in the indexed\ncategory. This enables iteration to be interpreted in the Grothendieck\nconstruction of the target language in a principled way. The resulting fibred\niterative structure cleanly models iteration in the categorical semantics.\nConsequently, the extended CHAD transformation remains the unique\nstructure-preserving functor (an iterative Freyd category morphism) from the\nfreely generated iterative Freyd category of the source language to the\nGrothendieck construction of the target's syntactic semantics, mapping each\nprimitive operation to its derivative. We prove the correctness of this\ntransformation using the universal property of the source language's syntax,\nshowing that the transformed programs compute correct reverse-mode derivatives.\nOur development also contributes to understanding iteration constructs within\ndependently typed languages and categories of containers. As our primary\nmotivation and application, we generalize CHAD to languages with data types,\npartial features, and iteration, providing the first rigorous categorical\nsemantics for reverse-mode CHAD in such settings and formally guaranteeing the\ncorrectness of the source-to-source CHAD technique.",
      "tldr_zh": "本研究扩展了 Combinatory Homomorphic Automatic Differentiation (CHAD)，将其从总编程语言应用到部分语言中，包括非终止操作、实值条件和迭代结构（如 while-loops），同时保持 CHAD 的结构保留语义原则。关键创新是引入 iteration-extensive indexed categories 和 Grothendieck construction，以使迭代在目标语言的范畴语义中得到系统化解释，从而确保扩展后的 CHAD 变换作为唯一的 iterative Freyd category morphism。研究证明了此变换的正确性，通过源语言的通用属性验证转换程序能计算准确的反向模式导数，并为 dependently typed languages 和 categories of containers 中的迭代提供新的理解，最终为处理数据类型、部分特性和迭代的语言提供首个严格的范畴语义和正确性保证。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LG",
        "math.CT",
        "math.LO",
        "18C10, 18C15, 18C20, 18D05, 03B70, 03F52, 68Q55, 68N18, 68T07",
        "F.3.2; F.3.3; D.3.1; D.3.2; D.2.4; G.4; I.2.3; I.2.6; G.1.10"
      ],
      "primary_category": "cs.PL",
      "comment": "57 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15002v1",
      "published_date": "2025-05-21 01:10:40 UTC",
      "updated_date": "2025-05-21 01:10:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:06:09.728237"
    },
    {
      "arxiv_id": "2505.14999v1",
      "title": "Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision",
      "title_zh": "学习排序链式思考：一种基于结果监督的能量基方法",
      "authors": [
        "Eric Hanchen Jiang",
        "Haozheng Luo",
        "Shengyuan Pang",
        "Xiaomin Li",
        "Zhenting Qi",
        "Hengli Li",
        "Cheng-Fu Yang",
        "Zongyu Lin",
        "Xinfeng Li",
        "Hao Xu",
        "Kai-Wei Chang",
        "Ying Nian Wu"
      ],
      "abstract": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs), often requiring robust multi step logical consistency. While\nChain of Thought (CoT) prompting elicits reasoning steps, it doesn't guarantee\ncorrectness, and improving reliability via extensive sampling is\ncomputationally costly. This paper introduces the Energy Outcome Reward Model\n(EORM), an effective, lightweight, post hoc verifier. EORM leverages Energy\nBased Models (EBMs) to simplify the training of reward models by learning to\nassign a scalar energy score to CoT solutions using only outcome labels,\nthereby avoiding detailed annotations. It achieves this by interpreting\ndiscriminator output logits as negative energies, effectively ranking\ncandidates where lower energy is assigned to solutions leading to correct final\noutcomes implicitly favoring coherent reasoning. On mathematical benchmarks\n(GSM8k, MATH), EORM significantly improves final answer accuracy (e.g., with\nLlama 3 8B, achieving 90.7% on GSM8k and 63.7% on MATH). EORM effectively\nleverages a given pool of candidate solutions to match or exceed the\nperformance of brute force sampling, thereby enhancing LLM reasoning outcome\nreliability through its streamlined post hoc verification process.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在数学推理中的多步逻辑一致性挑战，提出了一种基于 Energy Based Models (EBMs) 的方法，名为 Energy Outcome Reward Model (EORM)，通过仅使用结果标签（outcome supervision）来训练一个轻量级后处理验证器，从而为 Chain-of-Thought (CoT) 解决方案分配能量分数并进行排名。EORM 将鉴别器输出 logits 解释为负能量，优先选择导致正确最终结果的候选方案，隐式提升推理连贯性。实验结果显示，在 GSM8k 和 MATH 基准测试上，EORM 显著提高了准确率，例如使用 Llama 3 8B 模型，在 GSM8k 上达到 90.7%，并能匹配或超过暴力采样的性能，从而提升了 LLM 推理的可靠性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14999v1",
      "published_date": "2025-05-21 01:06:29 UTC",
      "updated_date": "2025-05-21 01:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:06:22.861996"
    },
    {
      "arxiv_id": "2505.14996v1",
      "title": "Meta-Design Matters: A Self-Design Multi-Agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Ke",
        "Austin Xu",
        "Yifei Ming",
        "Xuan-Phi Nguyen",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "Multi-agent systems (MAS) leveraging the impressive capabilities of Large\nLanguage Models (LLMs) hold significant potential for tackling complex tasks.\nHowever, most current MAS depend on manually designed agent roles and\ncommunication protocols. These manual designs often fail to align with the\nunderlying LLMs' strengths and struggle to adapt to novel tasks. Recent\nautomatic MAS approaches attempt to mitigate these limitations but typically\nnecessitate a validation-set for tuning and yield static MAS designs lacking\nadaptability during inference. We introduce SELF-MAS, the first\nself-supervised, inference-time only framework for automatic MAS design.\nSELF-MAS employs meta-level design to iteratively generate, evaluate, and\nrefine MAS configurations tailored to each problem instance, without requiring\na validation set. Critically, it enables dynamic agent composition and problem\ndecomposition through meta-feedback on solvability and completeness.\nExperiments across math, graduate-level QA, and software engineering\nbenchmarks, using both closed-source and open-source LLM back-bones of varying\nsizes, demonstrate that SELF-MAS outperforms both manual and automatic MAS\nbaselines, achieving a 7.44% average accuracy improvement over the next\nstrongest baseline while maintaining cost-efficiency. These findings underscore\nthe promise of meta-level self-supervised design for creating effective and\nadaptive MAS.",
      "tldr_zh": "该研究指出，现有的多智能体系统（MAS）依赖手动设计的代理角色和通信协议，缺乏适应性，且自动方法通常需要验证集。本文引入SELF-MAS，一种首个自监督的、仅在推理时的框架，通过元级别设计（meta-level design）迭代生成、评估和优化MAS配置，实现动态代理组合和问题分解，而无需验证集。实验在数学、研究生级QA和软件工程基准上，使用不同规模的封闭源和开源Large Language Models (LLMs)作为后端，SELF-MAS比其他基线平均准确率提升7.44%，并保持成本效率，证明了元级别自监督设计的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14996v1",
      "published_date": "2025-05-21 00:56:09 UTC",
      "updated_date": "2025-05-21 00:56:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:06:32.742182"
    },
    {
      "arxiv_id": "2505.14983v1",
      "title": "Toward Informed AV Decision-Making: Computational Model of Well-being and Trust in Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Zahedi",
        "Shashank Mehrotra",
        "Teruhisa Misu",
        "Kumar Akash"
      ],
      "abstract": "For future human-autonomous vehicle (AV) interactions to be effective and\nsmooth, human-aware systems that analyze and align human needs with automation\ndecisions are essential. Achieving this requires systems that account for human\ncognitive states. We present a novel computational model in the form of a\nDynamic Bayesian Network (DBN) that infers the cognitive states of both AV\nusers and other road users, integrating this information into the AV's\ndecision-making process. Specifically, our model captures the well-being of\nboth an AV user and an interacting road user as cognitive states alongside\ntrust. Our DBN models infer beliefs over the AV user's evolving well-being,\ntrust, and intention states, as well as the possible well-being of other road\nusers, based on observed interaction experiences. Using data collected from an\ninteraction study, we refine the model parameters and empirically assess its\nperformance. Finally, we extend our model into a causal inference model (CIM)\nframework for AV decision-making, enabling the AV to enhance user well-being\nand trust while balancing these factors with its own operational costs and the\nwell-being of interacting road users. Our evaluation demonstrates the model's\neffectiveness in accurately predicting user's states and guiding informed,\nhuman-centered AV decisions.",
      "tldr_zh": "本研究提出一个计算模型，使用 Dynamic Bayesian Network (DBN) 来推断自动驾驶车辆 (AV) 用户和其他道路使用者的认知状态，包括福祉 (well-being) 和信任 (trust)，以实现更人性化的 AV 决策。该模型基于交互经验推断用户状态变化和意图，并将这些信息整合到 AV 的决策流程中。研究通过交互数据优化模型参数，并扩展为 causal inference model (CIM) 框架，帮助 AV 平衡用户福祉、信任与自身成本。实验评估证明，该模型在准确预测用户状态和指导人类中心决策方面表现出显著有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14983v1",
      "published_date": "2025-05-21 00:02:39 UTC",
      "updated_date": "2025-05-21 00:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T03:06:45.786659"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 178,
  "processed_papers_count": 178,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T03:07:11.188121"
}