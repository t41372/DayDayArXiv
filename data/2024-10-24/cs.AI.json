{
  "date": "2024-10-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 110 篇论文，主要聚焦于 AI 模型优化（如 LLM 的微调和偏好对齐）、生成模型应用（扩散模型和图像处理）、医疗 AI（如药物反应预测）和机器人路径规划等领域。其中，LLM 在数学推理和生成任务的论文（如 Skywork-Reward 和 LOGO）令人印象深刻，展示了高效的知识蒸馏和代理系统；同时，知名学者如 Zhiyong Lu 和 Heng Ji 的医疗 AI 工作也值得关注。\n\n### LLM 和生成模型领域\n这些论文探讨了大型语言模型（LLMs）的优化、生成和应用，强调了高效训练和实际部署。\n- **Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs**（英文原题：Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs）：该论文提出了一种奖励建模框架，使用数据筛选和优化策略训练小型数据集，显著提升了 LLM 的偏好对齐性能；Skywork-Reward-Gemma-27B 模型在 RewardBench 排行榜上位居第一。\n- **LOGO: Long cOntext aliGnment via efficient preference Optimization**（英文原题：LOGO -- Long cOntext aliGnment via efficient preference Optimization）：贡献在于引入偏好优化策略处理长上下文对齐，显著提升了 LLM 在长序列任务中的性能，仅需少量数据即可与 GPT-4 匹敌。\n- **SIKeD: Self-guided Iterative Knowledge Distillation for mathematical reasoning**（英文原题：SIKeD: Self-guided Iterative Knowledge Distillation for mathematical reasoning）：通过自引导知识蒸馏，LLM 学会多策略数学推理，提升了在 GSM8K 等数据集上的准确率。\n- **PRISM: A Methodology for Auditing Biases in Large Language Models**（英文原题：PRISM: A Methodology for Auditing Biases in Large Language Models）：提出了一种基于任务查询的偏差审计方法，揭示了 LLM 在政治偏好等任务中的潜在问题。\n- **PDL: A Declarative Prompt Programming Language**（英文原题：PDL: A Declarative Prompt Programming Language）：设计了一种简单声明式语言简化 LLM 提示编程，提升了交互应用的鲁棒性。\n\n其他如 **Adversarial Attacks on Large Language Models Using Regularized Relaxation**（英文原题：Adversarial Attacks on Large Language Models Using Regularized Relaxation）快速掠过：它优化了对抗攻击方法，提高了成功率，但对 LLM 安全的影响需进一步验证。\n\n### 医疗和生物领域\n这些论文关注 AI 在医疗中的应用，强调隐私保护和诊断辅助。\n- **Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**（英文原题：Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use）：Zhiyong Lu 等作者发现 LLM 在药物反应预测中与专家对齐率仅 70.86%，并提出 Psych-ADR 基准评估框架。\n- **Bio2Token: All-atom tokenization of any biomolecular structure with Mamba**（英文原题：Bio2Token: All-atom tokenization of any biomolecular structure with Mamba）：使用 Mamba 模型实现生物分子结构的原子级标记化，重建精度低于 1 埃，适用于大规模生物设计。\n- **Demystifying Large Language Models for Medicine: A Primer**（英文原题：Demystifying Large Language Models for Medicine: A Primer）：Zhiyong Lu 团队提供了一个 LLM 在医疗中的实用指南，涵盖任务制定、微调和部署，强调伦理和监管挑战。\n\n### 图像处理和机器人领域\n这些论文创新了生成和导航技术，展示 AI 的实际应用潜力。\n- **PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views**（英文原题：PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views）：提出一种动态高斯重建框架，提升了 3D 图像质量，适用于任意视角。\n- **Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling**（英文原题：Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling）：使用高斯表示和图神经网络实现机器人物体动态预测，显著提高了模拟精度。\n- **SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment**（英文原题：SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment）：自动生成机器人演示数据，提升技能学习效率，实现在真实世界任务中的零样本转移。\n\n其他如 **GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided Adversarial Data Transformation**（英文原题：GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided Adversarial Data Transformation）快速掠过：它优化了对抗攻击策略，但对图像安全的影响需谨慎评估。\n\n### 其他领域\n今天还有一些论文涉及时间序列预测和数学推理，如 **Context is Key: A Benchmark for Forecasting with Essential Textual Information**（英文原题：Context is Key: A Benchmark for Forecasting with Essential Textual Information），提出新基准整合文本信息提升预测准确率；以及 **ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning**（英文原题：ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning），使用符号程序评估 LLM 的推理鲁棒性。这些工作虽有创新，但影响力较小，仅供参考。\n\n总之，今天的论文突出了 AI 模型在实际应用中的优化和挑战，LLM 相关研究尤其值得关注。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2410.19217v1",
      "title": "No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Changlong Wu",
        "Ananth Grama",
        "Wojciech Szpankowski"
      ],
      "abstract": "Generative models have shown impressive capabilities in synthesizing\nhigh-quality outputs across various domains. However, a persistent challenge is\nthe occurrence of \"hallucinations\", where the model produces outputs that are\nplausible but invalid. While empirical strategies have been explored to\nmitigate this issue, a rigorous theoretical understanding remains elusive. In\nthis paper, we develop a theoretical framework to analyze the learnability of\nnon-hallucinating generative models from a learning-theoretic perspective. Our\nresults reveal that non-hallucinating learning is statistically impossible when\nrelying solely on the training dataset, even for a hypothesis class of size two\nand when the entire training set is truthful. To overcome these limitations, we\nshow that incorporating inductive biases aligned with the actual facts into the\nlearning process is essential. We provide a systematic approach to achieve this\nby restricting the facts set to a concept class of finite VC-dimension and\ndemonstrate its effectiveness under various learning paradigms. Although our\nfindings are primarily conceptual, they represent a first step towards a\nprincipled approach to addressing hallucinations in learning generative models.",
      "tldr_zh": "本研究探讨了生成模型（generative models）学习非hallucinating（非幻觉生成）能力的根本限制，强调了即使在简单假设类和完整训练数据集下，仅依赖训练数据也无法统计上实现非hallucinating学习。作者从学习理论（learning-theoretic）视角建立框架，揭示了这一“无免费午餐”（No Free Lunch）现象的核心挑战。论文提出，通过将归纳偏差（inductive biases）与实际事实对齐，并将事实集限制到有限VC-dimension的概念类中，可以在各种学习范式下有效缓解hallucinations问题。这一概念性贡献为解决生成模型幻觉问题提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19217v1",
      "published_date": "2024-10-24 23:57:11 UTC",
      "updated_date": "2024-10-24 23:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:53:33.450992"
    },
    {
      "arxiv_id": "2410.19207v2",
      "title": "Equitable Federated Learning with Activation Clustering",
      "title_zh": "基于激活聚类的公平联邦学习",
      "authors": [
        "Antesh Upadhyay",
        "Abolfazl Hashemi"
      ],
      "abstract": "Federated learning is a prominent distributed learning paradigm that\nincorporates collaboration among diverse clients, promotes data locality, and\nthus ensures privacy. These clients have their own technological, cultural, and\nother biases in the process of data generation. However, the present standard\noften ignores this bias/heterogeneity, perpetuating bias against certain groups\nrather than mitigating it. In response to this concern, we propose an equitable\nclustering-based framework where the clients are categorized/clustered based on\nhow similar they are to each other. We propose a unique way to construct the\nsimilarity matrix that uses activation vectors. Furthermore, we propose a\nclient weighing mechanism to ensure that each cluster receives equal importance\nand establish $O(1/\\sqrt{K})$ rate of convergence to reach an\n$\\epsilon-$stationary solution. We assess the effectiveness of our proposed\nstrategy against common baselines, demonstrating its efficacy in terms of\nreducing the bias existing amongst various client clusters and consequently\nameliorating algorithmic bias against specific groups.",
      "tldr_zh": "该论文针对联邦学习（Federated Learning）中客户端的偏见问题，提出了一种基于激活聚类（Activation Clustering）的公平框架，将客户端根据激活向量构建的相似性矩阵进行聚类分类。框架引入客户端加权机制，确保每个聚类获得平等重要性，并证明了算法的收敛率可达 O(1/√K) 以实现 ε-平稳解。通过实验对比基线模型，该方法有效减少了客户端聚类间的偏见，并显著改善了对特定群体的算法偏见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19207v2",
      "published_date": "2024-10-24 23:36:39 UTC",
      "updated_date": "2024-11-01 04:14:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:53:44.271235"
    },
    {
      "arxiv_id": "2410.19203v1",
      "title": "An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm Based on Decomposition",
      "title_zh": "基于分解的逆向建模约束多目标进化算法",
      "authors": [
        "Lucas R. C. Farias",
        "Aluizio F. R. Araújo"
      ],
      "abstract": "This paper introduces the inverse modeling constrained multi-objective\nevolutionary algorithm based on decomposition (IM-C-MOEA/D) for addressing\nconstrained real-world optimization problems. Our research builds upon the\nadvancements made in evolutionary computing-based inverse modeling, and it\nstrategically bridges the gaps in applying inverse models based on\ndecomposition to problem domains with constraints. The proposed approach is\nexperimentally evaluated on diverse real-world problems (RWMOP1-35), showing\nsuperior performance to state-of-the-art constrained multi-objective\nevolutionary algorithms (CMOEAs). The experimental results highlight the\nrobustness of the algorithm and its applicability in real-world constrained\noptimization scenarios.",
      "tldr_zh": "这篇论文提出了 IM-C-MOEA/D 算法，一种基于分解的逆向建模约束多目标进化算法（MOEA/D），旨在解决真实世界优化问题中的约束挑战。该算法构建于进化计算的逆向建模进展之上，通过战略性地整合分解策略，填补了逆向模型在约束问题领域的应用空白。实验结果显示，IM-C-MOEA/D 在 RWMOP1-35 等多样化真实问题上表现优于现有最先进的多目标进化算法（CMOEAs），突显了其鲁棒性和在实际优化场景中的适用性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "6 pages, 1 figure, 1 algorithm, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19203v1",
      "published_date": "2024-10-24 23:24:44 UTC",
      "updated_date": "2024-10-24 23:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:53:57.356868"
    },
    {
      "arxiv_id": "2410.19198v1",
      "title": "MAP: Multi-Human-Value Alignment Palette",
      "title_zh": "翻译失败",
      "authors": [
        "Xinran Wang",
        "Qi Le",
        "Ammar Ahmed",
        "Enmao Diao",
        "Yi Zhou",
        "Nathalie Baracaldo",
        "Jie Ding",
        "Ali Anwar"
      ],
      "abstract": "Ensuring that generative AI systems align with human values is essential but\nchallenging, especially when considering multiple human values and their\npotential trade-offs. Since human values can be personalized and dynamically\nchange over time, the desirable levels of value alignment vary across different\nethnic groups, industry sectors, and user cohorts. Within existing frameworks,\nit is hard to define human values and align AI systems accordingly across\ndifferent directions simultaneously, such as harmlessness, helpfulness, and\npositiveness. To address this, we develop a novel, first-principle approach\ncalled Multi-Human-Value Alignment Palette (MAP), which navigates the alignment\nacross multiple human values in a structured and reliable way. MAP formulates\nthe alignment problem as an optimization task with user-defined constraints,\nwhich define human value targets. It can be efficiently solved via a\nprimal-dual approach, which determines whether a user-defined alignment target\nis achievable and how to achieve it. We conduct a detailed theoretical analysis\nof MAP by quantifying the trade-offs between values, the sensitivity to\nconstraints, the fundamental connection between multi-value alignment and\nsequential alignment, and proving that linear weighted rewards are sufficient\nfor multi-value alignment. Extensive experiments demonstrate MAP's ability to\nalign multiple values in a principled manner while delivering strong empirical\nperformance across various tasks.",
      "tldr_zh": "该研究针对生成式 AI 系统与多人类价值观的校准问题，提出了一种新框架 Multi-Human-Value Alignment Palette (MAP)，以处理价值观间的权衡和个性化差异，如无害性、帮助性和积极性。MAP 将校准问题表述为优化任务，使用用户定义的约束来设定价值观目标，并通过 primal-dual approach 高效求解，确保目标的可达性和实现路径。理论分析量化了价值观权衡、约束敏感性，以及多值校准与顺序校准的联系，并证明线性加权奖励足以支持多值校准；实验结果显示，MAP 在各种任务中表现出色，实现了可靠的价值观校准。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19198v1",
      "published_date": "2024-10-24 23:16:39 UTC",
      "updated_date": "2024-10-24 23:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:54:08.952567"
    },
    {
      "arxiv_id": "2410.19193v2",
      "title": "Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Bruno Croso Cunha da Silva",
        "Thomas Palmeira Ferraz",
        "Roseli De Deus Lopes"
      ],
      "abstract": "Disinformation on social media poses both societal and technical challenges,\nrequiring robust detection systems. While previous studies have integrated\ntextual information into propagation networks, they have yet to fully leverage\nthe advancements in Transformer-based language models for high-quality\ncontextual text representations. This work addresses this gap by incorporating\nTransformer-based textual features into Graph Neural Networks (GNNs) for fake\nnews detection. We demonstrate that contextual text representations enhance GNN\nperformance, achieving 33.8% relative improvement in Macro F1 over models\nwithout textual features and 9.3% over static text representations. We further\ninvestigate the impact of different feature sources and the effects of noisy\ndata augmentation. We expect our methodology to open avenues for further\nresearch, and we made code publicly available.",
      "tldr_zh": "本研究针对社交媒体上的虚假信息传播问题，提出了一种将 Transformer-based 文本上下文表示整合到 Graph Neural Networks (GNNs) 中的方法，以提升假新闻检测的准确性。该方法利用高级文本特征，相比不使用文本特征的模型，Macro F1 指标相对提高了 33.8%，并比使用静态文本表示的模型提高了 9.3%。此外，研究还探讨了不同特征来源和噪声数据增强的影响，并公开了代码，以促进后续研究的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Work still in progress. Accepted as Extended Abstract Poster at LoG\n  Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19193v2",
      "published_date": "2024-10-24 22:57:17 UTC",
      "updated_date": "2024-11-23 03:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:54:20.604883"
    },
    {
      "arxiv_id": "2410.19185v2",
      "title": "Tailored-LLaMA: Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Danyal Aftab",
        "Steven Davy"
      ],
      "abstract": "Large language models demonstrate impressive proficiency in language\nunderstanding and generation. Nonetheless, training these models from scratch,\neven the least complex billion-parameter variant demands significant\ncomputational resources rendering it economically impractical for many\norganizations. With large language models functioning as general-purpose task\nsolvers, this paper investigates their task-specific fine-tuning. We employ\ntask-specific datasets and prompts to fine-tune two pruned LLaMA models having\n5 billion and 4 billion parameters. This process utilizes the pre-trained\nweights and focuses on a subset of weights using the LoRA method. One challenge\nin fine-tuning the LLaMA model is crafting a precise prompt tailored to the\nspecific task. To address this, we propose a novel approach to fine-tune the\nLLaMA model under two primary constraints: task specificity and prompt\neffectiveness. Our approach, Tailored LLaMA initially employs structural\npruning to reduce the model sizes from 7B to 5B and 4B parameters.\nSubsequently, it applies a carefully designed prompt specific to the task and\nutilizes the LoRA method to accelerate the fine-tuning process. Moreover,\nfine-tuning a model pruned by 50\\% for less than one hour restores the mean\naccuracy of classification tasks to 95.68\\% at a 20\\% compression ratio and to\n86.54\\% at a 50\\% compression ratio through few-shot learning with 50 shots.\nOur validation of Tailored LLaMA on these two pruned variants demonstrates that\neven when compressed to 50\\%, the models maintain over 65\\% of the baseline\nmodel accuracy in few-shot classification and generation tasks. These findings\nhighlight the efficacy of our tailored approach in maintaining high performance\nwith significantly reduced model sizes.",
      "tldr_zh": "本研究提出Tailored-LLaMA方法，针对资源有限的场景优化修剪后LLaMA模型在few-shot learning中的性能，通过任务特定提示和LoRA微调技术来提升模型效率。方法包括先对原7B参数LLaMA模型进行结构修剪，减至5B和4B参数，然后结合任务特定数据集和精心设计的提示进行快速微调。实验结果显示，在50%压缩比下，模型通过少量样本学习恢复分类任务准确率达95.68%（20%压缩）和86.54%（50%压缩），并在few-shot分类和生成任务中保持基线模型65%以上的性能，证明了该方法在减少模型大小的同时维持高准确率的效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19185v2",
      "published_date": "2024-10-24 22:34:27 UTC",
      "updated_date": "2025-01-09 17:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:54:33.974552"
    },
    {
      "arxiv_id": "2410.19184v2",
      "title": "No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Israel Fama",
        "Bárbara Bueno",
        "Alexandre Alcoforado",
        "Thomas Palmeira Ferraz",
        "Arnold Moya",
        "Anna Helena Reali Costa"
      ],
      "abstract": "In a context where the Brazilian judiciary system, the largest in the world,\nfaces a crisis due to the slow processing of millions of cases, it becomes\nimperative to develop efficient methods for analyzing legal texts. We introduce\nuBERT, a hybrid model that combines Transformer and Recurrent Neural Network\narchitectures to effectively handle long legal texts. Our approach processes\nthe full text regardless of its length while maintaining reasonable\ncomputational overhead. Our experiments demonstrate that uBERT achieves\nsuperior performance compared to BERT+LSTM when overlapping input is used and\nis significantly faster than ULMFiT for processing long legal documents.",
      "tldr_zh": "针对巴西司法系统处理数百万案件的缓慢问题，本文引入了 uBERT，一种结合 Transformer 和 Recurrent Neural Network (RNN) 的混合模型，用于高效分析任意长度的法律文本。uBERT 通过采用重叠输入（overlapping chunks）策略，能够处理完整文本的同时保持合理的计算开销。实验结果显示，uBERT 在性能上优于 BERT+LSTM，并且比 ULMFiT 处理长法律文档更快，从而为大规模法律文本处理提供了更高效的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at 15th Symposium in Information and Human Language\n  Technology (STIL) @ BRACIS'24",
      "pdf_url": "http://arxiv.org/pdf/2410.19184v2",
      "published_date": "2024-10-24 22:33:30 UTC",
      "updated_date": "2024-12-15 23:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:00.442864"
    },
    {
      "arxiv_id": "2410.19183v1",
      "title": "Can Self Supervision Rejuvenate Similarity-Based Link Prediction?",
      "title_zh": "自监督能否重振基于相似度的链接预测？",
      "authors": [
        "Chenhan Zhang",
        "Weiqi Wang",
        "Zhiyi Tian",
        "James Jianqiao Yu",
        "Mohamed Ali Kaafar",
        "An Liu",
        "Shui Yu"
      ],
      "abstract": "Although recent advancements in end-to-end learning-based link prediction\n(LP) methods have shown remarkable capabilities, the significance of\ntraditional similarity-based LP methods persists in unsupervised scenarios\nwhere there are no known link labels. However, the selection of node features\nfor similarity computation in similarity-based LP can be challenging. Less\ninformative node features can result in suboptimal LP performance. To address\nthese challenges, we integrate self-supervised graph learning techniques into\nsimilarity-based LP and propose a novel method: Self-Supervised\nSimilarity-based LP (3SLP). 3SLP is suitable for the unsupervised condition of\nsimilarity-based LP without the assistance of known link labels. Specifically,\n3SLP introduces a dual-view contrastive node representation learning (DCNRL)\nwith crafted data augmentation and node representation learning. DCNRL is\ndedicated to developing more informative node representations, replacing the\nnode attributes as inputs in the similarity-based LP backbone. Extensive\nexperiments over benchmark datasets demonstrate the salient improvement of\n3SLP, outperforming the baseline of traditional similarity-based LP by up to\n21.2% (AUC).",
      "tldr_zh": "该研究探讨了自监督学习是否能提升基于相似度的链接预测（Link Prediction, LP）方法在无监督场景中的性能，针对传统方法中节点特征选择困难导致的低效问题。作者提出了一种新方法Self-Supervised Similarity-based LP (3SLP)，通过整合自监督图学习技术，包括双视图对比节点表示学习 (DCNRL)，利用数据增强和节点表示学习来生成更具信息性的节点表示，从而取代原始节点属性。实验结果显示，3SLP 在基准数据集上比传统相似度-based LP 基准提升高达21.2% (AUC)，证明了其在无监督链接预测中的显著优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19183v1",
      "published_date": "2024-10-24 22:31:12 UTC",
      "updated_date": "2024-10-24 22:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:55:59.502020"
    },
    {
      "arxiv_id": "2410.19168v1",
      "title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark",
      "title_zh": "MMAU：大规模多任务音频理解与推理基准",
      "authors": [
        "S Sakshi",
        "Utkarsh Tyagi",
        "Sonal Kumar",
        "Ashish Seth",
        "Ramaneswaran Selvakumar",
        "Oriol Nieto",
        "Ramani Duraiswami",
        "Sreyan Ghosh",
        "Dinesh Manocha"
      ],
      "abstract": "The ability to comprehend audio--which includes speech, non-speech sounds,\nand music--is crucial for AI agents to interact effectively with the world. We\npresent MMAU, a novel benchmark designed to evaluate multimodal audio\nunderstanding models on tasks requiring expert-level knowledge and complex\nreasoning. MMAU comprises 10k carefully curated audio clips paired with\nhuman-annotated natural language questions and answers spanning speech,\nenvironmental sounds, and music. It includes information extraction and\nreasoning questions, requiring models to demonstrate 27 distinct skills across\nunique and challenging tasks. Unlike existing benchmarks, MMAU emphasizes\nadvanced perception and reasoning with domain-specific knowledge, challenging\nmodels to tackle tasks akin to those faced by experts. We assess 18 open-source\nand proprietary (Large) Audio-Language Models, demonstrating the significant\nchallenges posed by MMAU. Notably, even the most advanced Gemini Pro v1.5\nachieves only 52.97% accuracy, and the state-of-the-art open-source Qwen2-Audio\nachieves only 52.50%, highlighting considerable room for improvement. We\nbelieve MMAU will drive the audio and multimodal research community to develop\nmore advanced audio understanding models capable of solving complex audio\ntasks.",
      "tldr_zh": "该研究引入了MMAU，一种大规模多任务音频理解和推理基准，用于评估多模态音频理解模型在需要专家级知识和复杂推理的任务中的表现。MMAU包含10k个精心策划的音频剪辑，配以人工标注的自然语言问题和答案，涵盖语音、环境声音和音乐领域，并要求模型展示27种技能，包括信息提取和高级推理。与现有基准不同，它强调领域特定知识和专家级挑战。实验评估了18个开源和专有音频语言模型，结果显示顶尖模型如Gemini Pro v1.5仅达到52.97%的准确率，Qwen2-Audio为52.50%，凸显了现有技术的改进空间，并有望推动音频和多模态研究的发展。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Project Website: https://sakshi113.github.io/mmau_homepage/",
      "pdf_url": "http://arxiv.org/pdf/2410.19168v1",
      "published_date": "2024-10-24 21:20:10 UTC",
      "updated_date": "2024-10-24 21:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:55:09.303835"
    },
    {
      "arxiv_id": "2410.19160v1",
      "title": "Adversarial Attacks on Large Language Models Using Regularized Relaxation",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Jacob Chacko",
        "Sajib Biswas",
        "Chashi Mahiul Islam",
        "Fatema Tabassum Liza",
        "Xiuwen Liu"
      ],
      "abstract": "As powerful Large Language Models (LLMs) are now widely used for numerous\npractical applications, their safety is of critical importance. While alignment\ntechniques have significantly improved overall safety, LLMs remain vulnerable\nto carefully crafted adversarial inputs. Consequently, adversarial attack\nmethods are extensively used to study and understand these vulnerabilities.\nHowever, current attack methods face significant limitations. Those relying on\noptimizing discrete tokens suffer from limited efficiency, while continuous\noptimization techniques fail to generate valid tokens from the model's\nvocabulary, rendering them impractical for real-world applications. In this\npaper, we propose a novel technique for adversarial attacks that overcomes\nthese limitations by leveraging regularized gradients with continuous\noptimization methods. Our approach is two orders of magnitude faster than the\nstate-of-the-art greedy coordinate gradient-based method, significantly\nimproving the attack success rate on aligned language models. Moreover, it\ngenerates valid tokens, addressing a fundamental limitation of existing\ncontinuous optimization methods. We demonstrate the effectiveness of our attack\non five state-of-the-art LLMs using four datasets.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的安全漏洞，提出了一种基于正则化梯度(regularized gradients)和连续优化的新对抗性攻击方法，以克服现有方法的局限，如离散token优化效率低下和连续优化无法生成有效token的问题。该方法比最先进的贪婪坐标梯度方法快两个数量级，同时显著提高了对齐语言模型的攻击成功率，并确保生成有效token。在五个最先进的LLMs和四个数据集上进行的实验证明了其有效性，为深入理解和提升LLMs的安全性提供了重要工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19160v1",
      "published_date": "2024-10-24 21:01:45 UTC",
      "updated_date": "2024-10-24 21:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:55:21.580919"
    },
    {
      "arxiv_id": "2410.19155v3",
      "title": "Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Chandra",
        "Siddharth Sriraman",
        "Gaurav Verma",
        "Harneet Singh Khanuja",
        "Jose Suarez Campayo",
        "Zihang Li",
        "Michael L. Birnbaum",
        "Munmun De Choudhury"
      ],
      "abstract": "Adverse Drug Reactions (ADRs) from psychiatric medications are the leading\ncause of hospitalizations among mental health patients. With healthcare systems\nand online communities facing limitations in resolving ADR-related issues,\nLarge Language Models (LLMs) have the potential to fill this gap. Despite the\nincreasing capabilities of LLMs, past research has not explored their\ncapabilities in detecting ADRs related to psychiatric medications or in\nproviding effective harm reduction strategies. To address this, we introduce\nthe Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment\n(ADRA) framework to systematically evaluate LLM performance in detecting ADR\nexpressions and delivering expert-aligned mitigation strategies. Our analyses\nshow that LLMs struggle with understanding the nuances of ADRs and\ndifferentiating between types of ADRs. While LLMs align with experts in terms\nof expressed emotions and tone of the text, their responses are more complex,\nharder to read, and only 70.86% aligned with expert strategies. Furthermore,\nthey provide less actionable advice by a margin of 12.32% on average. Our work\nprovides a comprehensive benchmark and evaluation framework for assessing LLMs\nin strategy-driven tasks within high-risk domains.",
      "tldr_zh": "这项研究探讨了大语言模型（LLMs）在处理精神药物不良反应（ADRs）时的局限性，强调 ADRs 是导致精神健康患者住院的主要原因，而 LLMs 可能填补医疗系统和在线社区的空白。研究引入了 Psych-ADR 基准和 Adverse Drug Reaction Response Assessment (ADRA) 框架，用于评估 LLMs 在检测 ADR 表达和提供专家对齐的缓解策略方面的性能。结果显示，LLMs 难以理解 ADR 的细微差别和区分类型，尽管在情感和语气上与专家一致，但其响应更复杂、难读，且仅有 70.86% 与专家策略对齐，同时提供可操作建议平均少 12.32%。这项工作提供了全面的基准和评估框架，推动 LLMs 在高风险领域策略驱动任务的改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 8 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19155v3",
      "published_date": "2024-10-24 20:49:22 UTC",
      "updated_date": "2025-01-07 15:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:12.568454"
    },
    {
      "arxiv_id": "2410.19144v1",
      "title": "Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Abhirama Subramanyam Penamakuri",
        "Anand Mishra"
      ],
      "abstract": "We revisit knowledge-aware text-based visual question answering, also known\nas Text-KVQA, in the light of modern advancements in large multimodal models\n(LMMs), and make the following contributions: (i) We propose VisTEL - a\nprincipled approach to perform visual text entity linking. The proposed VisTEL\nmodule harnesses a state-of-the-art visual text recognition engine and the\npower of a large multimodal model to jointly reason using textual and visual\ncontext obtained using surrounding cues in the image to link the visual text\nentity to the correct knowledge base entity. (ii) We present KaLMA - a\nknowledge-aware large multimodal assistant that augments an LMM with knowledge\nassociated with visual text entity in the image to arrive at an accurate\nanswer. Further, we provide a comprehensive experimental analysis and\ncomparison of our approach with traditional visual question answering,\npre-large multimodal models, and large multimodal models, as well as prior\ntop-performing approaches. Averaging over three splits of Text-KVQA, our\nproposed approach surpasses the previous best approach by a substantial 23.3%\non an absolute scale and establishes a new state of the art. We make our\nimplementation publicly available.",
      "tldr_zh": "该论文针对知识感知文本-based 视觉问答（Text-KVQA）问题，提出了一种改进方法，利用大型多模态模型（LMM）的优势。研究者开发了 VisTEL 模块，该模块结合先进的视觉文本识别引擎和 LMM，通过图像中的文本和视觉上下文进行实体链接，将视觉文本实体准确连接到知识库。论文还引入了 KaLMA 框架，该框架在 LMM 中整合视觉文本实体的相关知识，以提升答案准确性。实验结果显示，在 Text-KVQA 的三个数据集上，KaLMA 比之前最佳方法提高了 23.3%，建立了新的 state of the art，并公开了实现代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to EMNLP (Main) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19144v1",
      "published_date": "2024-10-24 20:25:38 UTC",
      "updated_date": "2024-10-24 20:25:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:38.107031"
    },
    {
      "arxiv_id": "2410.19135v1",
      "title": "PDL: A Declarative Prompt Programming Language",
      "title_zh": "翻译失败",
      "authors": [
        "Mandana Vaziri",
        "Louis Mandel",
        "Claudio Spiess",
        "Martin Hirzel"
      ],
      "abstract": "Large language models (LLMs) have taken the world by storm by making many\npreviously difficult uses of AI feasible. LLMs are controlled via highly\nexpressive textual prompts and return textual answers. Unfortunately, this\nunstructured text as input and output makes LLM-based applications brittle.\nThis motivates the rise of prompting frameworks, which mediate between LLMs and\nthe external world. However, existing prompting frameworks either have a high\nlearning curve or take away control over the exact prompts from the developer.\nTo overcome this dilemma, this paper introduces the Prompt Declaration Language\n(PDL). PDL is a simple declarative data-oriented language that puts prompts at\nthe forefront, based on YAML. PDL works well with many LLM platforms and LLMs.\nIt supports writing interactive applications that call LLMs and tools, and\nmakes it easy to implement common use-cases such as chatbots, RAG, or agents.\nWe hope PDL will make prompt programming simpler, less brittle, and more\nenjoyable.",
      "tldr_zh": "这篇论文介绍了PDL（Prompt Declaration Language），一种简单声明式的、数据导向的编程语言，基于YAML，旨在解决大型语言模型（LLMs）通过文本提示控制应用时存在的易碎性问题。PDL 将提示置于核心位置，与多种LLM平台兼容，支持开发交互式应用，如聊天机器人、RAG（检索增强生成）和代理。相比现有框架，PDL 降低了学习曲线，同时保留了开发人员对提示的控制，最终使提示编程更简单、更可靠且更具吸引力。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19135v1",
      "published_date": "2024-10-24 20:07:08 UTC",
      "updated_date": "2024-10-24 20:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:35.581763"
    },
    {
      "arxiv_id": "2410.19130v2",
      "title": "Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models",
      "title_zh": "跨云联邦训练大型语言模型的关键技术研究",
      "authors": [
        "Haowei Yang",
        "Mingxiu Sui",
        "Shaobo Liu",
        "Xinyue Qian",
        "Zhaoyang Zhang",
        "Bingying Liu"
      ],
      "abstract": "With the rapid development of natural language processing technology, large\nlanguage models have demonstrated exceptional performance in various\napplication scenarios. However, training these models requires significant\ncomputational resources and data processing capabilities. Cross-cloud federated\ntraining offers a new approach to addressing the resource bottlenecks of a\nsingle cloud platform, allowing the computational resources of multiple clouds\nto collaboratively complete the training tasks of large models. This study\nanalyzes the key technologies of cross-cloud federated training, including data\npartitioning and distribution, communication optimization, model aggregation\nalgorithms, and the compatibility of heterogeneous cloud platforms.\nAdditionally, the study examines data security and privacy protection\nstrategies in cross-cloud training, particularly the application of data\nencryption and differential privacy techniques. Through experimental\nvalidation, the proposed technical framework demonstrates enhanced training\nefficiency, ensured data security, and reduced training costs, highlighting the\nbroad application prospects of cross-cloud federated training.",
      "tldr_zh": "这篇论文探讨了跨云联邦训练大型语言模型(Large Language Models)的关键技术，以解决单一云平台资源瓶颈的问题。研究分析了核心方法，包括数据分区和分布、通信优化、模型聚合算法，以及异构云平台的兼容性策略。同时，论文强调了数据安全和隐私保护措施，如数据加密和差分隐私技术。通过实验验证，该框架显著提高了训练效率、确保了数据安全，并降低了成本，展示了其在实际应用中的广阔前景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19130v2",
      "published_date": "2024-10-24 19:57:17 UTC",
      "updated_date": "2024-12-23 03:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:47.497453"
    },
    {
      "arxiv_id": "2410.19110v3",
      "title": "Bio2Token: All-atom tokenization of any biomolecular structure with Mamba",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Liu",
        "Axel Elaldi",
        "Nathan Russell",
        "Olivia Viessmann"
      ],
      "abstract": "Efficient encoding and representation of large 3D molecular structures with\nhigh fidelity is critical for biomolecular design applications. Despite this,\nmany representation learning approaches restrict themselves to modeling smaller\nsystems or use coarse-grained approximations of the systems, for example\nmodeling proteins at the resolution of amino acid residues rather than at the\nlevel of individual atoms. To address this, we develop quantized auto-encoders\nthat learn atom-level tokenizations of complete proteins, RNA and small\nmolecule structures with reconstruction accuracies well below 1 Angstrom. We\ndemonstrate that a simple Mamba state space model architecture is efficient\ncompared to an SE(3)-invariant IPA architecture, reaches competitive accuracies\nand can scale to systems with almost 100,000 atoms. The learned structure\ntokens of bio2token may serve as the input for all-atom generative models in\nthe future.",
      "tldr_zh": "该研究提出了Bio2Token框架，利用量化自编码器实现对蛋白质、RNA 和小分子等生物分子结构的原子级别tokenization，重构精度低于1 Angstrom，以高效编码大型3D分子结构。相比SE(3)-invariant IPA架构，Bio2Token采用简单的Mamba状态空间模型，表现出更高的计算效率、竞争性准确率，并能扩展到近10万原子的系统。未来，这些学到的结构tokens可作为全原子生成模型的输入，推动生物分子设计应用的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19110v3",
      "published_date": "2024-10-24 19:23:09 UTC",
      "updated_date": "2025-04-08 23:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:56:59.116112"
    },
    {
      "arxiv_id": "2410.19109v1",
      "title": "RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Wang",
        "Vera Demberg"
      ],
      "abstract": "Despite significant advancements in natural language generation, controlling\nlanguage models to produce texts with desired attributes remains a formidable\nchallenge. In this work, we introduce RSA-Control, a training-free controllable\ntext generation framework grounded in pragmatics. RSA-Control directs the\ngeneration process by recursively reasoning between imaginary speakers and\nlisteners, enhancing the likelihood that target attributes are correctly\ninterpreted by listeners amidst distractors. Additionally, we introduce a\nself-adjustable rationality parameter, which allows for automatic adjustment of\ncontrol strength based on context. Our experiments, conducted with two task\ntypes and two types of language models, demonstrate that RSA-Control achieves\nstrong attribute control while maintaining language fluency and content\nconsistency. Our code is available at https://github.com/Ewanwong/RSA-Control.",
      "tldr_zh": "本研究提出 RSA-Control，一种基于 pragmatics 的轻量级可控文本生成框架，无需训练即可使用。该框架通过递归 reasoning 想象中的说话者和听众，增强目标属性的正确解释能力，同时引入自调整的 rationality parameter 根据上下文自动调节控制强度。实验在两种任务类型和语言模型上表明，RSA-Control 实现了强属性控制，同时保持了语言流畅性和内容一致性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2410.19109v1",
      "published_date": "2024-10-24 19:21:04 UTC",
      "updated_date": "2024-10-24 19:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:57:12.214589"
    },
    {
      "arxiv_id": "2410.19105v3",
      "title": "Conditional diffusions for amortized neural posterior estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Chen",
        "Vansh Bansal",
        "James G. Scott"
      ],
      "abstract": "Neural posterior estimation (NPE), a simulation-based computational approach\nfor Bayesian inference, has shown great success in approximating complex\nposterior distributions. Existing NPE methods typically rely on normalizing\nflows, which approximate a distribution by composing many simple, invertible\ntransformations. But flow-based models, while state of the art for NPE, are\nknown to suffer from several limitations, including training instability and\nsharp trade-offs between representational power and computational cost. In this\nwork, we demonstrate the effectiveness of conditional diffusions coupled with\nhigh-capacity summary networks for amortized NPE. Conditional diffusions\naddress many of the challenges faced by flow-based methods. Our results show\nthat, across a highly varied suite of benchmarking problems for NPE\narchitectures, diffusions offer improved stability, superior accuracy, and\nfaster training times, even with simpler, shallower models. Building on prior\nwork on diffusions for NPE, we show that these gains persist across a variety\nof different summary network architectures. Code is available at\nhttps://github.com/TianyuCodings/cDiff.",
      "tldr_zh": "该论文提出使用条件扩散（conditional diffusions）结合高容量摘要网络（high-capacity summary networks），作为一种改进的摊销神经后验估计（amortized neural posterior estimation, NPE）方法，以克服现有基于 normalizing flows 的 NPE 模型的训练不稳定性和计算成本问题。条件扩散通过更有效的分布近似技术，解决了这些局限性，并在各种基准问题上展示了优越的性能。实验结果表明，该方法在稳定性、准确性和训练速度方面均优于传统模型，即使采用更简单、更浅的架构；此外，这些优势在不同摘要网络架构中保持一致。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19105v3",
      "published_date": "2024-10-24 19:13:13 UTC",
      "updated_date": "2025-03-13 02:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:57:23.222713"
    },
    {
      "arxiv_id": "2410.19100v3",
      "title": "VideoWebArena: Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Lawrence Jang",
        "Yinheng Li",
        "Dan Zhao",
        "Charles Ding",
        "Justin Lin",
        "Paul Pu Liang",
        "Rogerio Bonatti",
        "Kazuhito Koishida"
      ],
      "abstract": "Videos are often used to learn or extract the necessary information to\ncomplete tasks in ways different than what text and static imagery alone can\nprovide. However, many existing agent benchmarks neglect long-context video\nunderstanding, instead focusing on text or static image inputs. To bridge this\ngap, we introduce VideoWebArena (VideoWA), a benchmark for evaluating the\ncapabilities of long-context multimodal agents for video understanding. VideoWA\nconsists of 2,021 web agent tasks based on manually crafted video tutorials,\nwhich total almost four hours of content. For our benchmark, we define a\ntaxonomy of long-context video-based agent tasks with two main areas of focus:\nskill retention and factual retention. While skill retention tasks evaluate\nwhether an agent can use a given human demonstration to complete a task\nefficiently, the factual retention task evaluates whether an agent can retrieve\ninstruction-relevant information from a video to complete a task. We find that\nthe best model achieves 13.3% success on factual retention tasks and 45.8% on\nfactual retention QA pairs, far below human performance at 73.9% and 79.3%,\nrespectively. On skill retention tasks, long-context models perform worse with\ntutorials than without, exhibiting a 5% performance decrease in WebArena tasks\nand a 10.3% decrease in VisualWebArena tasks. Our work highlights the need to\nimprove the agentic abilities of long-context multimodal models and provides a\ntestbed for future development with long-context video agents.",
      "tldr_zh": "本文引入 VideoWebArena（VideoWA）基准，用于评估长上下文多模态代理在视频理解任务中的性能，该基准包含 2,021 个基于视频教程的任务，总时长近四小时，并分为技能保留和事实保留两大类。技能保留任务测试代理是否能利用人类演示高效完成任务，而事实保留任务评估代理从视频中检索相关信息的能力。实验发现，最佳模型在事实保留任务上的成功率仅为 13.3%，远低于人类的 73.9%，在使用教程时表现反而下降（如 WebArena 任务减少 5%）。这项工作强调了提升长上下文多模态模型代理能力的必要性，并提供了一个未来开发的测试平台。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19100v3",
      "published_date": "2024-10-24 19:03:01 UTC",
      "updated_date": "2025-02-15 05:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:57:36.937247"
    },
    {
      "arxiv_id": "2410.19085v1",
      "title": "A Counterexample in Cross-Correlation Template Matching",
      "title_zh": "交叉相关模板匹配中的一个反例",
      "authors": [
        "Serap A. Savari"
      ],
      "abstract": "Sampling and quantization are standard practices in signal and image\nprocessing, but a theoretical understanding of their impact is incomplete. We\nconsider discrete image registration when the underlying function is a\none-dimensional spatially-limited piecewise constant function. For ideal\nnoiseless sampling the number of samples from each region of the support of the\nfunction generally depends on the placement of the sampling grid. Therefore, if\nthe samples of the function are noisy, then image registration requires\nalignment and segmentation of the data sequences. One popular strategy for\naligning images is selecting the maximum from cross-correlation template\nmatching. To motivate more robust and accurate approaches which also address\nsegmentation, we provide an example of a one-dimensional spatially-limited\npiecewise constant function for which the cross-correlation technique can\nperform poorly on noisy samples. While earlier approaches to improve the method\ninvolve normalization, our example suggests a novel strategy in our setting.\nDifference sequences, thresholding, and dynamic programming are well-known\ntechniques in image processing. We prove that they are tools to correctly align\nand segment noisy data sequences under some conditions on the noise. We also\naddress some of the potential difficulties that could arise in a more general\ncase.",
      "tldr_zh": "这篇论文通过一个一维空间有限的分段常数函数的反例，展示了跨-correlation template matching 在噪声样本上的表现不佳，强调了采样和量化对图像配准的影响。论文指出，这种方法在对齐和分割数据序列时可能失败，并提出使用 difference sequences、thresholding 和 dynamic programming 等技术来改进处理。实验证明，这些方法在某些噪声条件下能正确对齐和分割数据序列，并讨论了在更一般场景下的潜在困难，为更鲁棒的图像处理策略提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19085v1",
      "published_date": "2024-10-24 18:42:01 UTC",
      "updated_date": "2024-10-24 18:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:57:48.320894"
    },
    {
      "arxiv_id": "2410.19064v1",
      "title": "From a Tiny Slip to a Giant Leap: An LLM-Based Simulation for Fake News Evolution",
      "title_zh": "从一个微小失误到巨大飞跃：基于LL",
      "authors": [
        "Yuhan Liu",
        "Zirui Song",
        "Xiaoqing Zhang",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "abstract": "With the growing spread of misinformation online, research has increasingly\nfocused on detecting and tracking fake news. However, an overlooked issue is\nthat fake news does not naturally exist in social networks -- it often\noriginates from distorted facts or deliberate fabrication by malicious actors.\nUnderstanding how true news gradually evolves into fake news is critical for\nearly detection and prevention, reducing its spread and impact. Hence, in this\npaper, we take the first step toward simulating and revealing this evolution,\nproposing a Fake News evolUtion Simulation framEwork (FUSE) based on large\nlanguage models (LLMs). Specifically, we employ LLM as agents to represent\nindividuals in a simulated social network. We define four types of agents\ncommonly observed in daily interactions: spreaders, who propagate information;\ncommentators, who provide opinions and interpretations; verifiers, who check\nthe accuracy of information; and bystanders, who passively observe without\nengaging. For simulated environments, we model various social network\nstructures, such as high-clustering networks and scale-free networks, to mirror\nreal-world network dynamics. Each day, the agents engage in belief exchanges,\nreflect on their thought processes, and reintroduce the news accordingly. Given\nthe lack of prior work in this area, we developed a FUSE-EVAL evaluation\nframework to measure the deviation from true news during the fake news\nevolution process. The results show that FUSE successfully captures the\nunderlying patterns of how true news transforms into fake news and accurately\nreproduces previously discovered instances of fake news, aligning closely with\nhuman evaluations. Moreover, our work provides insights into the fact that\ncombating fake news should not be delayed until it has fully evolved; instead,\nprevention in advance is key to achieving better outcomes.",
      "tldr_zh": "本研究提出了一种基于大型语言模型（LLMs）的假新闻演化模拟框架FUSE，旨在揭示真实新闻如何逐步演变为假新闻，从而支持早期检测和预防。框架中，使用LLMs作为代理模拟社会网络中的个体，包括spreaders（传播者）、commentators（评论者）、verifiers（验证者）和bystanders（旁观者），并在各种社会网络结构（如high-clustering networks和scale-free networks）中进行信念交换和反思。研究开发了FUSE-EVAL评估框架，实验结果显示FUSE成功捕捉假新闻演化模式，与人类评估一致，并强调提前干预比事后应对更有效。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19064v1",
      "published_date": "2024-10-24 18:17:16 UTC",
      "updated_date": "2024-10-24 18:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:00.022126"
    },
    {
      "arxiv_id": "2410.19056v1",
      "title": "ReasonAgain: Using Extractable Symbolic Programs to Evaluate Mathematical Reasoning",
      "title_zh": "ReasonAgain：利用可提取符号程序评估数学推理",
      "authors": [
        "Xiaodong Yu",
        "Ben Zhou",
        "Hao Cheng",
        "Dan Roth"
      ],
      "abstract": "Existing math datasets evaluate the reasoning abilities of large language\nmodels (LLMs) by either using the final answer or the intermediate reasoning\nsteps derived from static examples. However, the former approach fails to\nsurface model's uses of shortcuts and wrong reasoning while the later poses\nchallenges in accommodating alternative solutions. In this work, we seek to use\nsymbolic programs as a means for automated evaluation if a model can\nconsistently produce correct final answers across various inputs to the\nprogram. We begin by extracting programs for popular math datasets (GSM8K and\nMATH) using GPT4-o. For those executable programs verified using the original\ninput-output pairs, they are found to encapsulate the proper reasoning required\nto solve the original text questions. We then prompt GPT4-o to generate new\nquestions using alternative input-output pairs based the extracted program. We\napply the resulting datasets to evaluate a collection of LLMs. In our\nexperiments, we observe significant accuracy drops using our proposed\nevaluation compared with original static examples, suggesting the fragility of\nmath reasoning in state-of-the-art LLMs.",
      "tldr_zh": "本文提出ReasonAgain方法，使用可提取的symbolic programs来评估大语言模型（LLMs）的数学推理能力，从而解决现有数据集仅依赖最终答案或静态中间步骤的局限性。研究团队利用GPT-4o从GSM8K和MATH数据集提取可执行程序，并基于这些程序生成新问题，以测试模型在不同输入下的一致性。实验结果显示，与原静态示例相比，多种LLMs的准确率显著下降，揭示了其数学推理的脆弱性和不稳定性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19056v1",
      "published_date": "2024-10-24 18:02:37 UTC",
      "updated_date": "2024-10-24 18:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:11.511085"
    },
    {
      "arxiv_id": "2410.19054v1",
      "title": "Infogent: An Agent-Based Framework for Web Information Aggregation",
      "title_zh": "Infogent：基于代理的网络信息聚合框架",
      "authors": [
        "Revanth Gangi Reddy",
        "Sagnik Mukherjee",
        "Jeonghwan Kim",
        "Zhenhailong Wang",
        "Dilek Hakkani-Tur",
        "Heng Ji"
      ],
      "abstract": "Despite seemingly performant web agents on the task-completion benchmarks,\nmost existing methods evaluate the agents based on a presupposition: the web\nnavigation task consists of linear sequence of actions with an end state that\nmarks task completion. In contrast, our work focuses on web navigation for\ninformation aggregation, wherein the agent must explore different websites to\ngather information for a complex query. We consider web information aggregation\nfrom two different perspectives: (i) Direct API-driven Access relies on a\ntext-only view of the Web, leveraging external tools such as Google Search API\nto navigate the web and a scraper to extract website contents. (ii) Interactive\nVisual Access uses screenshots of the webpages and requires interaction with\nthe browser to navigate and access information. Motivated by these diverse\ninformation access settings, we introduce Infogent, a novel modular framework\nfor web information aggregation involving three distinct components: Navigator,\nExtractor and Aggregator. Experiments on different information access settings\ndemonstrate Infogent beats an existing SOTA multi-agent search framework by 7%\nunder Direct API-Driven Access on FRAMES, and improves over an existing\ninformation-seeking web agent by 4.3% under Interactive Visual Access on\nAssistantBench.",
      "tldr_zh": "这篇论文提出了 Infogent，一种基于智能体的框架，用于处理网络信息聚合任务，该任务需要代理探索多个网站以收集复杂查询的信息，而非简单线性序列。Infogent 包括三个模块：Navigator（负责导航）、Extractor（负责提取内容）和 Aggregator（负责信息整合），并支持 Direct API-driven Access（使用文本视图和外部工具如 Google Search API）和 Interactive Visual Access（通过网页截图和浏览器交互）两种访问方式。实验结果显示，Infogent 在 FRAMES 基准下的 Direct API-Driven Access 场景中比现有 SOTA 多智能体框架提高了 7%，而在 AssistantBench 下的 Interactive Visual Access 场景中比现有信息搜索代理提高了 4.3%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.19054v1",
      "published_date": "2024-10-24 18:01:28 UTC",
      "updated_date": "2024-10-24 18:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:24.685648"
    },
    {
      "arxiv_id": "2410.18979v1",
      "title": "PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views",
      "title_zh": "PixelGaussian：从任意视图进行可泛化 3D 高斯重建",
      "authors": [
        "Xin Fei",
        "Wenzhao Zheng",
        "Yueqi Duan",
        "Wei Zhan",
        "Masayoshi Tomizuka",
        "Kurt Keutzer",
        "Jiwen Lu"
      ],
      "abstract": "We propose PixelGaussian, an efficient feed-forward framework for learning\ngeneralizable 3D Gaussian reconstruction from arbitrary views. Most existing\nmethods rely on uniform pixel-wise Gaussian representations, which learn a\nfixed number of 3D Gaussians for each view and cannot generalize well to more\ninput views. Differently, our PixelGaussian dynamically adapts both the\nGaussian distribution and quantity based on geometric complexity, leading to\nmore efficient representations and significant improvements in reconstruction\nquality. Specifically, we introduce a Cascade Gaussian Adapter to adjust\nGaussian distribution according to local geometry complexity identified by a\nkeypoint scorer. CGA leverages deformable attention in context-aware\nhypernetworks to guide Gaussian pruning and splitting, ensuring accurate\nrepresentation in complex regions while reducing redundancy. Furthermore, we\ndesign a transformer-based Iterative Gaussian Refiner module that refines\nGaussian representations through direct image-Gaussian interactions. Our\nPixelGaussian can effectively reduce Gaussian redundancy as input views\nincrease. We conduct extensive experiments on the large-scale ACID and\nRealEstate10K datasets, where our method achieves state-of-the-art performance\nwith good generalization to various numbers of views. Code:\nhttps://github.com/Barrybarry-Smith/PixelGaussian.",
      "tldr_zh": "本研究提出 PixelGaussian，一种高效的前向框架，用于从任意视图学习可泛化的 3D Gaussian 重建，解决了现有方法依赖固定数量 Gaussian 表示而泛化能力不足的问题。该框架动态调整 Gaussian 的分布和数量，根据局部几何复杂度（如通过关键点评分器识别）来指导 Cascade Gaussian Adapter 的可变形注意力机制，实现 Gaussian 的修剪和分割，从而减少冗余并提升复杂区域的准确表示。此外，基于 transformer 的 Iterative Gaussian Refiner 模块通过直接图像-Gaussian 交互进一步精炼表示。在 ACID 和 RealEstate10K 数据集上的实验显示，PixelGaussian 实现了最先进的重建性能，并对不同视图数量具有良好的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at:\n  https://github.com/Barrybarry-Smith/PixelGaussian",
      "pdf_url": "http://arxiv.org/pdf/2410.18979v1",
      "published_date": "2024-10-24 17:59:58 UTC",
      "updated_date": "2024-10-24 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:36.366293"
    },
    {
      "arxiv_id": "2410.18976v1",
      "title": "CAMEL-Bench: A Comprehensive Arabic LMM Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Ghaboura",
        "Ahmed Heakl",
        "Omkar Thawakar",
        "Ali Alharthi",
        "Ines Riahi",
        "Abduljalil Saif",
        "Jorma Laaksonen",
        "Fahad S. Khan",
        "Salman Khan",
        "Rao M. Anwer"
      ],
      "abstract": "Recent years have witnessed a significant interest in developing large\nmultimodal models (LMMs) capable of performing various visual reasoning and\nunderstanding tasks. This has led to the introduction of multiple LMM\nbenchmarks to evaluate LMMs on different tasks. However, most existing LMM\nevaluation benchmarks are predominantly English-centric. In this work, we\ndevelop a comprehensive LMM evaluation benchmark for the Arabic language to\nrepresent a large population of over 400 million speakers. The proposed\nbenchmark, named CAMEL-Bench, comprises eight diverse domains and 38\nsub-domains including, multi-image understanding, complex visual perception,\nhandwritten document understanding, video understanding, medical imaging, plant\ndiseases, and remote sensing-based land use understanding to evaluate broad\nscenario generalizability. Our CAMEL-Bench comprises around 29,036 questions\nthat are filtered from a larger pool of samples, where the quality is manually\nverified by native speakers to ensure reliable model assessment. We conduct\nevaluations of both closed-source, including GPT-4 series, and open-source\nLMMs. Our analysis reveals the need for substantial improvement, especially\namong the best open-source models, with even the closed-source GPT-4o achieving\nan overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",
      "tldr_zh": "本研究开发了CAMEL-Bench，一种全面的LMM（Large Multimodal Models）基准，针对阿拉伯语以代表超过4亿人口的语言需求，填补现有以英语为主的LMM评估基准的空白。该基准涵盖8个多样化领域和38个子领域，包括多图像理解、复杂视觉感知、手写文档理解、视频理解、医疗成像、植物疾病以及遥感土地使用理解，总计约29,036个经母语者手动验证的问题，以评估模型的广泛场景泛化能力。通过评估闭源模型（如GPT-4系列）和开源LMMs，结果显示即使是GPT-4o也仅获得62%的整体分数，突显了开源模型的显著改进空间；基准及其评估脚本已开源以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures, NAACL",
      "pdf_url": "http://arxiv.org/pdf/2410.18976v1",
      "published_date": "2024-10-24 17:59:38 UTC",
      "updated_date": "2024-10-24 17:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:48.848209"
    },
    {
      "arxiv_id": "2410.18975v2",
      "title": "Unbounded: A Generative Infinite Game of Character Life Simulation",
      "title_zh": "Unbounded: 生成式无限游戏的角色生活模拟",
      "authors": [
        "Jialu Li",
        "Yuanzhen Li",
        "Neal Wadhwa",
        "Yael Pritch",
        "David E. Jacobs",
        "Michael Rubinstein",
        "Mohit Bansal",
        "Nataniel Ruiz"
      ],
      "abstract": "We introduce the concept of a generative infinite game, a video game that\ntranscends the traditional boundaries of finite, hard-coded systems by using\ngenerative models. Inspired by James P. Carse's distinction between finite and\ninfinite games, we leverage recent advances in generative AI to create\nUnbounded: a game of character life simulation that is fully encapsulated in\ngenerative models. Specifically, Unbounded draws inspiration from sandbox life\nsimulations and allows you to interact with your autonomous virtual character\nin a virtual world by feeding, playing with and guiding it - with open-ended\nmechanics generated by an LLM, some of which can be emergent. In order to\ndevelop Unbounded, we propose technical innovations in both the LLM and visual\ngeneration domains. Specifically, we present: (1) a specialized, distilled\nlarge language model (LLM) that dynamically generates game mechanics,\nnarratives, and character interactions in real-time, and (2) a new dynamic\nregional image prompt Adapter (IP-Adapter) for vision models that ensures\nconsistent yet flexible visual generation of a character across multiple\nenvironments. We evaluate our system through both qualitative and quantitative\nanalysis, showing significant improvements in character life simulation, user\ninstruction following, narrative coherence, and visual consistency for both\ncharacters and the environments compared to traditional related approaches.",
      "tldr_zh": "该论文引入了“Unbounded”——一个基于生成模型的无限游戏概念，超越传统有限游戏系统，允许玩家通过LLM动态生成开放式机制与自主虚拟角色互动，灵感来源于James P. Carse的有限与无限游戏理论。论文提出技术创新，包括一个专门的蒸馏LLM，用于实时生成游戏机制、叙事和角色互动，以及一个新的动态区域图像提示适配器(IP-Adapter)，以确保角色和环境的视觉一致性。实验评估显示，与传统方法相比，Unbounded在角色生命模拟、用户指令遵循、叙事连贯性和视觉一致性方面取得了显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://generative-infinite-game.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.18975v2",
      "published_date": "2024-10-24 17:59:31 UTC",
      "updated_date": "2024-10-30 16:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:58:59.890243"
    },
    {
      "arxiv_id": "2410.18974v2",
      "title": "3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hansheng Chen",
        "Bokui Shen",
        "Yulin Liu",
        "Ruoxi Shi",
        "Linqi Zhou",
        "Connor Z. Lin",
        "Jiayuan Gu",
        "Hao Su",
        "Gordon Wetzstein",
        "Leonidas Guibas"
      ],
      "abstract": "Multi-view image diffusion models have significantly advanced open-domain 3D\nobject generation. However, most existing models rely on 2D network\narchitectures that lack inherent 3D biases, resulting in compromised geometric\nconsistency. To address this challenge, we introduce 3D-Adapter, a plug-in\nmodule designed to infuse 3D geometry awareness into pretrained image diffusion\nmodels. Central to our approach is the idea of 3D feedback augmentation: for\neach denoising step in the sampling loop, 3D-Adapter decodes intermediate\nmulti-view features into a coherent 3D representation, then re-encodes the\nrendered RGBD views to augment the pretrained base model through feature\naddition. We study two variants of 3D-Adapter: a fast feed-forward version\nbased on Gaussian splatting and a versatile training-free version utilizing\nneural fields and meshes. Our extensive experiments demonstrate that 3D-Adapter\nnot only greatly enhances the geometry quality of text-to-multi-view models\nsuch as Instant3D and Zero123++, but also enables high-quality 3D generation\nusing the plain text-to-image Stable Diffusion. Furthermore, we showcase the\nbroad application potential of 3D-Adapter by presenting high quality results in\ntext-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.",
      "tldr_zh": "本文提出3D-Adapter，一种插件模块，用于向预训练图像扩散模型注入3D几何意识，从而解决多视图扩散模型在生成3D对象时存在的几何一致性问题。核心方法是3D反馈增强机制，在每个去噪步骤中，将中间多视图特征解码成连贯的3D表示，并通过渲染RGBD视图和特征添加来增强基模型。实验结果显示，3D-Adapter显著提升了Instant3D和Zero123++的几何质量，并使Stable Diffusion能够实现高质量的3D生成，还扩展到文本到3D、图像到3D、文本到纹理和文本到头像等任务中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://lakonik.github.io/3d-adapter/",
      "pdf_url": "http://arxiv.org/pdf/2410.18974v2",
      "published_date": "2024-10-24 17:59:30 UTC",
      "updated_date": "2025-02-20 02:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:59:13.730125"
    },
    {
      "arxiv_id": "2410.18972v1",
      "title": "Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "David Ortiz-Perez",
        "Manuel Benavent-Lledo",
        "Jose Garcia-Rodriguez",
        "David Tomás",
        "M. Flores Vizcaya-Moreno"
      ],
      "abstract": "Cognitive decline is a natural part of aging, often resulting in reduced\ncognitive abilities. In some cases, however, this decline is more pronounced,\ntypically due to disorders such as Alzheimer's disease. Early detection of\nanomalous cognitive decline is crucial, as it can facilitate timely\nprofessional intervention. While medical data can help in this detection, it\noften involves invasive procedures. An alternative approach is to employ\nnon-intrusive techniques such as speech or handwriting analysis, which do not\nnecessarily affect daily activities. This survey reviews the most relevant\nmethodologies that use deep learning techniques to automate the cognitive\ndecline estimation task, including audio, text, and visual processing. We\ndiscuss the key features and advantages of each modality and methodology,\nincluding state-of-the-art approaches like Transformer architecture and\nfoundation models. In addition, we present works that integrate different\nmodalities to develop multimodal models. We also highlight the most significant\ndatasets and the quantitative results from studies using these resources. From\nthis review, several conclusions emerge. In most cases, the textual modality\nachieves the best results and is the most relevant for detecting cognitive\ndecline. Moreover, combining various approaches from individual modalities into\na multimodal model consistently enhances performance across nearly all\nscenarios.",
      "tldr_zh": "这篇调查论文探讨了利用非侵入性模态（如语音和手写分析）结合深度学习技术来检测认知衰退的方法，以实现早期干预。论文回顾了音频、文本和视觉处理的深度学习方法，包括Transformer架构和foundation models，并讨论了多模态模型的整合优势。研究发现，文本模态在认知衰退检测中表现出最佳效果，而结合多种模态通常能显著提升整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18972v1",
      "published_date": "2024-10-24 17:59:21 UTC",
      "updated_date": "2024-10-24 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:59:23.206836"
    },
    {
      "arxiv_id": "2410.18970v3",
      "title": "WASP: A Weight-Space Approach to Detecting Learned Spuriousness",
      "title_zh": "翻译失败",
      "authors": [
        "Cristian Daniel Păduraru",
        "Antonio Bărbălau",
        "Radu Filipescu",
        "Andrei Liviu Nicolicioiu",
        "Elena Burceanu"
      ],
      "abstract": "It is of crucial importance to train machine learning models such that they\nclearly understand what defines each class in a given task. Though there is a\nsum of works dedicated to identifying the spurious correlations featured by a\ndataset that may impact the model's understanding of the classes, all current\napproaches rely solely on data or error analysis. That is, they cannot point\nout spurious correlations learned by the model that are not already pointed out\nby the counterexamples featured in the validation or training sets. We propose\na method that transcends this limitation, switching the focus from analyzing a\nmodel's predictions to analyzing the model's weights, the mechanism behind the\nmaking of the decisions, which proves to be more insightful. Our proposed\nWeight-space Approach to detecting Spuriousness (WASP) relies on analyzing the\nweights of foundation models as they drift towards capturing various (spurious)\ncorrelations while being fine-tuned on a given dataset. We demonstrate that\ndifferent from previous works, our method (i) can expose spurious correlations\nfeatured by a dataset even when they are not exposed by training or validation\ncounterexamples, (ii) it works for multiple modalities such as image and text,\nand (iii) it can uncover previously untapped spurious correlations learned by\nImageNet-1k classifiers.",
      "tldr_zh": "本研究强调了训练机器学习模型以正确理解类别定义的重要性，并指出现有方法仅依赖数据或错误分析，无法检测训练或验证集中未显露的虚假相关性（spurious correlations）。为了解决这一问题，作者提出WASP（Weight-space Approach to Detecting Learned Spuriousness），一种通过分析模型权重在微调过程中的变化来识别模型学到的虚假相关性的方法。该方法适用于图像和文本等多模态数据，并在ImageNet-1k分类器上揭示了先前未发现的虚假相关性，从而为更可靠的模型训练提供新洞见。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, 6 tables, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.18970v3",
      "published_date": "2024-10-24 17:59:16 UTC",
      "updated_date": "2025-02-13 17:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:59:35.641830"
    },
    {
      "arxiv_id": "2410.18963v1",
      "title": "OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoqiang Wang",
        "Bang Liu"
      ],
      "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have shown\ngreat potential in automating complex tasks like web browsing and gaming.\nHowever, their ability to generalize across diverse applications remains\nlimited, hindering broader utility. To address this challenge, we present\nOSCAR: Operating System Control via state-Aware reasoning and Re-planning.\nOSCAR is a generalist agent designed to autonomously navigate and interact with\nvarious desktop and mobile applications through standardized controls, such as\nmouse and keyboard inputs, while processing screen images to fulfill user\ncommands. OSCAR translates human instructions into executable Python code,\nenabling precise control over graphical user interfaces (GUIs). To enhance\nstability and adaptability, OSCAR operates as a state machine, equipped with\nerror-handling mechanisms and dynamic task re-planning, allowing it to\nefficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's\neffectiveness through extensive experiments on diverse benchmarks across\ndesktop and mobile platforms, where it transforms complex workflows into simple\nnatural language commands, significantly boosting user productivity. Our code\nwill be open-source upon publication.",
      "tldr_zh": "本研究提出OSCAR，一种通用代理，通过状态感知推理和动态任务重新规划，自主导航并交互桌面和移动应用，利用鼠标、键盘输入以及屏幕图像处理来执行用户指令。OSCAR将自然语言命令转化为可执行Python代码，并采用状态机机制进行错误处理和实时调整，以提升系统稳定性和适应性。在跨平台基准测试中，OSCAR显著提高了用户生产力，将复杂工作流程简化为简单指令，并计划开源代码以促进进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.18963v1",
      "published_date": "2024-10-24 17:58:08 UTC",
      "updated_date": "2024-10-24 17:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:59:47.518237"
    },
    {
      "arxiv_id": "2410.18959v3",
      "title": "Context is Key: A Benchmark for Forecasting with Essential Textual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Robert Williams",
        "Arjun Ashok",
        "Étienne Marcotte",
        "Valentina Zantedeschi",
        "Jithendaraa Subramanian",
        "Roland Riachi",
        "James Requeima",
        "Alexandre Lacoste",
        "Irina Rish",
        "Nicolas Chapados",
        "Alexandre Drouin"
      ],
      "abstract": "Forecasting is a critical task in decision-making across numerous domains.\nWhile historical numerical data provide a start, they fail to convey the\ncomplete context for reliable and accurate predictions. Human forecasters\nfrequently rely on additional information, such as background knowledge and\nconstraints, which can efficiently be communicated through natural language.\nHowever, in spite of recent progress with LLM-based forecasters, their ability\nto effectively integrate this textual information remains an open question. To\naddress this, we introduce \"Context is Key\" (CiK), a time-series forecasting\nbenchmark that pairs numerical data with diverse types of carefully crafted\ntextual context, requiring models to integrate both modalities; crucially,\nevery task in CiK requires understanding textual context to be solved\nsuccessfully. We evaluate a range of approaches, including statistical models,\ntime series foundation models, and LLM-based forecasters, and propose a simple\nyet effective LLM prompting method that outperforms all other tested methods on\nour benchmark. Our experiments highlight the importance of incorporating\ncontextual information, demonstrate surprising performance when using LLM-based\nforecasting models, and also reveal some of their critical shortcomings. This\nbenchmark aims to advance multimodal forecasting by promoting models that are\nboth accurate and accessible to decision-makers with varied technical\nexpertise. The benchmark can be visualized at\nhttps://servicenow.github.io/context-is-key-forecasting/v0/.",
      "tldr_zh": "这篇论文引入了“Context is Key”（CiK）基准，用于评估时间序列预测模型整合文本上下文的能力，强调了文本信息（如背景知识和约束）在提升预测准确性方面的关键作用。CiK将数值数据与多样化的文本配对，每个任务都要求模型理解文本才能成功完成。作者评估了统计模型、时间序列基础模型和LLM-based forecasters等多种方法，并提出了一种简单有效的LLM prompting方法，该方法在基准上表现出色。实验结果展示了整合上下文信息的重要性，同时揭示了LLM-based模型的潜力与局限性，推动了多模态预测模型的开发，使其更适合不同技术背景的决策者。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint; under review. First two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2410.18959v3",
      "published_date": "2024-10-24 17:56:08 UTC",
      "updated_date": "2025-02-06 19:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:00:01.169619"
    },
    {
      "arxiv_id": "2410.18952v2",
      "title": "Dynamic Vocabulary Pruning in Early-Exit LLMs",
      "title_zh": "早退出大语言模型中的动态词汇修剪",
      "authors": [
        "Jort Vincenti",
        "Karim Abdel Sadek",
        "Joan Velja",
        "Matteo Nulli",
        "Metod Jazbec"
      ],
      "abstract": "Increasing the size of large language models (LLMs) has been shown to lead to\nbetter performance. However, this comes at the cost of slower and more\nexpensive inference. Early-exiting is a promising approach for improving the\nefficiency of LLM inference by enabling next token prediction at intermediate\nlayers. Yet, the large vocabulary size in modern LLMs makes the confidence\nestimation required for exit decisions computationally expensive, diminishing\nthe efficiency gains. To address this, we propose dynamically pruning the\nvocabulary at test time for each token. Specifically, the vocabulary is pruned\nat one of the initial layers, and the smaller vocabulary is then used\nthroughout the rest of the forward pass. Our experiments demonstrate that such\npost-hoc dynamic vocabulary pruning improves the efficiency of confidence\nestimation in early-exit LLMs while maintaining competitive performance.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）规模增大导致的推理效率低下问题，提出了一种动态词汇修剪技术，用于Early-Exit LLMs，以优化置信度估计过程。具体方法是在测试时于初始层修剪词汇表，然后在后续转发中使用较小词汇，从而减少计算开销。实验结果显示，这种后处理动态修剪方法显著提高了Early-Exit LLMs的效率，同时保持了与基线模型相当的性能表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18952v2",
      "published_date": "2024-10-24 17:52:31 UTC",
      "updated_date": "2024-10-30 15:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:00:11.684540"
    },
    {
      "arxiv_id": "2410.18935v1",
      "title": "Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play",
      "title_zh": "翻译失败",
      "authors": [
        "Sha Li",
        "Revanth Gangi Reddy",
        "Khanh Duy Nguyen",
        "Qingyun Wang",
        "May Fung",
        "Chi Han",
        "Jiawei Han",
        "Kartik Natarajan",
        "Clare R. Voss",
        "Heng Ji"
      ],
      "abstract": "Complex news events, such as natural disasters and socio-political conflicts,\nrequire swift responses from the government and society. Relying on historical\nevents to project the future is insufficient as such events are sparse and do\nnot cover all possible conditions and nuanced situations. Simulation of these\ncomplex events can help better prepare and reduce the negative impact. We\ndevelop a controllable complex news event simulator guided by both the event\nschema representing domain knowledge about the scenario and user-provided\nassumptions representing case-specific conditions. As event dynamics depend on\nthe fine-grained social and cultural context, we further introduce a\ngeo-diverse commonsense and cultural norm-aware knowledge enhancement\ncomponent. To enhance the coherence of the simulation, apart from the global\ntimeline of events, we take an agent-based approach to simulate the individual\ncharacter states, plans, and actions. By incorporating the schema and cultural\nnorms, our generated simulations achieve much higher coherence and\nappropriateness and are received favorably by participants from a humanitarian\nassistance organization.",
      "tldr_zh": "本文提出了一种基于事件模式（event schema）和用户假设的复杂新闻事件模拟器，用于模拟自然灾害和社会政治冲突等情景，以弥补历史事件数据的不足。模拟器整合了地理多样性的常识和文化规范知识，并采用多代理角色扮演（Multi-Agent Role-Play）方法来模拟个体角色的状态、计划和行动，从而提升整体连贯性。实验结果表明，该方法生成的模拟更具适当性和真实性，并获得人道主义组织参与者的积极评价。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as EMNLP 2024 Demo",
      "pdf_url": "http://arxiv.org/pdf/2410.18935v1",
      "published_date": "2024-10-24 17:21:43 UTC",
      "updated_date": "2024-10-24 17:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:00:24.692758"
    },
    {
      "arxiv_id": "2410.18932v1",
      "title": "ANAVI: Audio Noise Awareness using Visuals of Indoor environments for NAVIgation",
      "title_zh": "翻译失败",
      "authors": [
        "Vidhi Jain",
        "Rishi Veerapaneni",
        "Yonatan Bisk"
      ],
      "abstract": "We propose Audio Noise Awareness using Visuals of Indoors for NAVIgation for\nquieter robot path planning. While humans are naturally aware of the noise they\nmake and its impact on those around them, robots currently lack this awareness.\nA key challenge in achieving audio awareness for robots is estimating how loud\nwill the robot's actions be at a listener's location? Since sound depends upon\nthe geometry and material composition of rooms, we train the robot to passively\nperceive loudness using visual observations of indoor environments. To this\nend, we generate data on how loud an 'impulse' sounds at different listener\nlocations in simulated homes, and train our Acoustic Noise Predictor (ANP).\nNext, we collect acoustic profiles corresponding to different actions for\nnavigation. Unifying ANP with action acoustics, we demonstrate experiments with\nwheeled (Hello Robot Stretch) and legged (Unitree Go2) robots so that these\nrobots adhere to the noise constraints of the environment. See code and data at\nhttps://anavi-corl24.github.io/",
      "tldr_zh": "我们提出 ANAVI 系统，利用室内视觉观察来实现机器人的音频噪音感知，从而规划更安静的导航路径。针对噪音取决于房间几何和材料特性的挑战，该系统通过在模拟家居环境中生成冲击声数据并训练 Acoustic Noise Predictor (ANP)，使机器人能被动估计其动作在听众位置的噪音水平。实验在 Hello Robot Stretch 和 Unitree Go2 机器人上验证了这一方法，确保机器人遵守环境噪音约束，并提供了相关代码和数据。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "8th Conference on Robot Learning (CoRL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18932v1",
      "published_date": "2024-10-24 17:19:53 UTC",
      "updated_date": "2024-10-24 17:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:00:37.198744"
    },
    {
      "arxiv_id": "2410.18923v2",
      "title": "SegLLM: Multi-round Reasoning Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "XuDong Wang",
        "Shaolun Zhang",
        "Shufan Li",
        "Konstantinos Kallidromitis",
        "Kehan Li",
        "Yusuke Kato",
        "Kazuki Kozuka",
        "Trevor Darrell"
      ],
      "abstract": "We present SegLLM, a novel multi-round interactive reasoning segmentation\nmodel that enhances LLM-based segmentation by exploiting conversational memory\nof both visual and textual outputs. By leveraging a mask-aware multimodal LLM,\nSegLLM re-integrates previous segmentation results into its input stream,\nenabling it to reason about complex user intentions and segment objects in\nrelation to previously identified entities, including positional,\ninteractional, and hierarchical relationships, across multiple interactions.\nThis capability allows SegLLM to respond to visual and text queries in a\nchat-like manner. Evaluated on the newly curated MRSeg benchmark, SegLLM\noutperforms existing methods in multi-round interactive reasoning segmentation\nby over 20%. Additionally, we observed that training on multi-round reasoning\nsegmentation data enhances performance on standard single-round referring\nsegmentation and localization tasks, resulting in a 5.5% increase in cIoU for\nreferring expression segmentation and a 4.5% improvement in Acc@0.5 for\nreferring expression localization.",
      "tldr_zh": "我们介绍了 SegLLM，一种新型的多轮交互推理分割模型，它通过利用 mask-aware 多模态 LLM 和对话记忆，将之前的视觉和文本输出重新整合到输入中，从而处理复杂的用户意图，包括位置、交互和层次关系。SegLLM 支持聊天式响应，并在新创建的 MRSeg 基准上，比现有方法提高了 20% 以上。进一步发现，训练多轮推理数据后，它还提升了单轮任务的表现，包括 referring expression segmentation 的 cIoU 提高了 5.5%，以及 referring expression localization 的 Acc@0.5 提高了 4.5%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 10 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.18923v2",
      "published_date": "2024-10-24 17:11:52 UTC",
      "updated_date": "2024-10-31 19:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:00:48.935785"
    },
    {
      "arxiv_id": "2410.18921v2",
      "title": "From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems",
      "title_zh": "翻译失败",
      "authors": [
        "A M Muntasir Rahman",
        "Junyi Ye",
        "Wei Yao",
        "Sierra S. Liu",
        "Jesse Yu",
        "Jonathan Yu",
        "Wenpeng Yin",
        "Guiling Wang"
      ],
      "abstract": "Consider the math problem: \"Lily received 3 cookies from her best friend\nyesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.\nHow many cookies does Lily have now?\" Many large language models (LLMs) in\nprevious research approach this problem by calculating the answer \"1\" using the\nequation \"3 - 5 + 3.\" However, from a human perspective, we recognize the\ninherent flaw in this problem: Lily cannot eat 5 cookies if she initially only\nhad 3. This discrepancy prompts a key question: Are current LLMs merely Blind\nSolver that apply mathematical operations without deeper reasoning, or can they\nfunction as Logical Thinker capable of identifying logical inconsistencies?\n  To explore this question, we propose a benchmark dataset, FaultyMath, which\nincludes faulty math problems of rich diversity: i) multiple mathematical\ncategories, e.g., algebra, geometry, number theory, etc., ii) varying levels of\ndifficulty, and iii) different origins of faultiness -- ranging from violations\nof common sense and ambiguous statements to mathematical contradictions and\nmore. We evaluate a broad spectrum of LLMs, including open-source,\nclosed-source, and math-specialized models, using FaultyMath across three\ndimensions: (i) How accurately can the models detect faulty math problems\nwithout being explicitly prompted to do so? (ii) When provided with hints --\neither correct or misleading -- about the validity of the problems, to what\nextent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy\nare the explanations generated by LLMs when they recognize a math problem as\nflawed? Through extensive experimentation and detailed analysis, our results\ndemonstrate that existing LLMs largely function as Blind Solver and fall short\nof the reasoning capabilities required to perform as Logical Thinker.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在处理有缺陷数学问题时的逻辑完整性，提出一个名为 FaultyMath 的基准数据集，该数据集涵盖多种数学类别（如代数、几何、数论）、难度级别以及错误来源（如常识违背、模糊语句或数学矛盾）。研究评估了多种 LLMs（包括开源、闭源和数学专用模型）在三个维度上的表现：（i）不经提示检测错误的准确性；（ii）在正确或误导性提示下适应成为逻辑思考者；（iii）生成可信解释的能力。结果显示，现有的 LLMs 主要充当“Blind Solver”，缺乏足够的推理能力，无法有效充当“Logical Thinker”。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18921v2",
      "published_date": "2024-10-24 17:10:39 UTC",
      "updated_date": "2025-04-04 20:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:01:00.462076"
    },
    {
      "arxiv_id": "2410.18912v1",
      "title": "Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Mingtong Zhang",
        "Kaifeng Zhang",
        "Yunzhu Li"
      ],
      "abstract": "Videos of robots interacting with objects encode rich information about the\nobjects' dynamics. However, existing video prediction approaches typically do\nnot explicitly account for the 3D information from videos, such as robot\nactions and objects' 3D states, limiting their use in real-world robotic\napplications. In this work, we introduce a framework to learn object dynamics\ndirectly from multi-view RGB videos by explicitly considering the robot's\naction trajectories and their effects on scene dynamics. We utilize the 3D\nGaussian representation of 3D Gaussian Splatting (3DGS) to train a\nparticle-based dynamics model using Graph Neural Networks. This model operates\non sparse control particles downsampled from the densely tracked 3D Gaussian\nreconstructions. By learning the neural dynamics model on offline robot\ninteraction data, our method can predict object motions under varying initial\nconfigurations and unseen robot actions. The 3D transformations of Gaussians\ncan be interpolated from the motions of control particles, enabling the\nrendering of predicted future object states and achieving action-conditioned\nvideo prediction. The dynamics model can also be applied to model-based\nplanning frameworks for object manipulation tasks. We conduct experiments on\nvarious kinds of deformable materials, including ropes, clothes, and stuffed\nanimals, demonstrating our framework's ability to model complex shapes and\ndynamics. Our project page is available at https://gs-dynamics.github.io.",
      "tldr_zh": "本研究提出了一种动态3D Gaussian跟踪框架，用于基于Graph Neural Networks的神经动态建模，旨在从多视图RGB视频中学习物体动态，同时考虑机器人动作轨迹及其对场景的影响。框架利用3D Gaussian Splatting (3DGS)表示，通过Graph Neural Networks训练一个基于粒子的动态模型，该模型在从密集跟踪的3D Gaussian重建中下采样的稀疏控制粒子上操作，以预测不同初始配置和未见机器人动作下的物体运动。实验结果显示，该方法在绳子、衣服和毛绒玩具等可变形材料上表现出色，能实现动作条件下的视频预测和基于模型的物体操作规划任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page: https://gs-dynamics.github.io",
      "pdf_url": "http://arxiv.org/pdf/2410.18912v1",
      "published_date": "2024-10-24 17:02:52 UTC",
      "updated_date": "2024-10-24 17:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:01:13.320120"
    },
    {
      "arxiv_id": "2410.18907v1",
      "title": "SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Caelan Garrett",
        "Ajay Mandlekar",
        "Bowen Wen",
        "Dieter Fox"
      ],
      "abstract": "Imitation learning from human demonstrations is an effective paradigm for\nrobot manipulation, but acquiring large datasets is costly and\nresource-intensive, especially for long-horizon tasks. To address this issue,\nwe propose SkillMimicGen (SkillGen), an automated system for generating\ndemonstration datasets from a few human demos. SkillGen segments human demos\ninto manipulation skills, adapts these skills to new contexts, and stitches\nthem together through free-space transit and transfer motion. We also propose a\nHybrid Skill Policy (HSP) framework for learning skill initiation, control, and\ntermination components from SkillGen datasets, enabling skills to be sequenced\nusing motion planning at test-time. We demonstrate that SkillGen greatly\nimproves data generation and policy learning performance over a\nstate-of-the-art data generation framework, resulting in the capability to\nproduce data for large scene variations, including clutter, and agents that are\non average 24% more successful. We demonstrate the efficacy of SkillGen by\ngenerating over 24K demonstrations across 18 task variants in simulation from\njust 60 human demonstrations, and training proficient, often near-perfect, HSP\nagents. Finally, we apply SkillGen to 3 real-world manipulation tasks and also\ndemonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.\nVideos, and more at https://skillgen.github.io.",
      "tldr_zh": "本文提出 SkillMimicGen (SkillGen)，一个自动化系统，用于从少数人类演示生成大规模数据集，以解决机器人操作的 imitation learning 中数据采集成本高的问题。SkillGen 通过将人类演示分割成 manipulation skills、适应新上下文并通过 free-space transit and transfer motion 拼接它们，结合 Hybrid Skill Policy (HSP) 框架学习技能的启动、控制和终止组件，并在测试时使用 motion planning 序列化技能。实验显示，SkillGen 比现有框架提升数据生成和策略学习性能，平均使代理成功率提高 24%，并从 60 个人类演示生成超过 24K 个演示，支持 18 个任务变体，还实现了零-shot sim-to-real transfer 在真实世界任务上的应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18907v1",
      "published_date": "2024-10-24 16:59:26 UTC",
      "updated_date": "2024-10-24 16:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:01:26.076228"
    },
    {
      "arxiv_id": "2410.18906v2",
      "title": "PRISM: A Methodology for Auditing Biases in Large Language Models",
      "title_zh": "PRISM: 一种用于审计大型语言模型偏差的方法论",
      "authors": [
        "Leif Azzopardi",
        "Yashar Moshfeghi"
      ],
      "abstract": "Auditing Large Language Models (LLMs) to discover their biases and\npreferences is an emerging challenge in creating Responsible Artificial\nIntelligence (AI). While various methods have been proposed to elicit the\npreferences of such models, countermeasures have been taken by LLM trainers,\nsuch that LLMs hide, obfuscate or point blank refuse to disclosure their\npositions on certain subjects. This paper presents PRISM, a flexible,\ninquiry-based methodology for auditing LLMs - that seeks to illicit such\npositions indirectly through task-based inquiry prompting rather than direct\ninquiry of said preferences. To demonstrate the utility of the methodology, we\napplied PRISM on the Political Compass Test, where we assessed the political\nleanings of twenty-one LLMs from seven providers. We show LLMs, by default,\nespouse positions that are economically left and socially liberal (consistent\nwith prior work). We also show the space of positions that these models are\nwilling to espouse - where some models are more constrained and less compliant\nthan others - while others are more neutral and objective. In sum, PRISM can\nmore reliably probe and audit LLMs to understand their preferences, biases and\nconstraints.",
      "tldr_zh": "本文提出 PRISM，一种灵活的基于任务询问的方法，用于审计 Large Language Models (LLMs) 的偏见和偏好，通过间接的任务-based inquiry prompting 绕过模型的隐藏或拒绝策略。研究者将 PRISM 应用于 Political Compass Test，对 21 个来自 7 个提供者的 LLMs 进行评估，结果显示这些模型默认倾向于经济左倾和社会自由主义。实验还揭示了模型间的差异，有些更受限而保守，其他则更中立和客观。总之，PRISM 提供了一种更可靠的工具来探测 LLMs 的偏好、偏见和约束，从而促进负责任的 AI 发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18906v2",
      "published_date": "2024-10-24 16:57:20 UTC",
      "updated_date": "2024-11-10 11:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:01:37.567675"
    },
    {
      "arxiv_id": "2410.18893v1",
      "title": "Creating and Repairing Robot Programs in Open-World Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Claire Schlesinger",
        "Arjun Guha",
        "Joydeep Biswas"
      ],
      "abstract": "Using Large Language Models (LLMs) to produce robot programs from natural\nlanguage has allowed for robot systems that can complete a higher diversity of\ntasks. However, LLM-generated programs may be faulty, either due to ambiguity\nin instructions, misinterpretation of the desired task, or missing information\nabout the world state. As these programs run, the state of the world changes\nand they gather new information. When a failure occurs, it is important that\nthey recover from the current world state and avoid repeating steps that they\nthey previously completed successfully. We propose RoboRepair, a system which\ntraces the execution of a program up until error, and then runs an LLM-produced\nrecovery program that minimizes repeated actions.\n  To evaluate the efficacy of our system, we create a benchmark consisting of\neleven tasks with various error conditions that require the generation of a\nrecovery program. We compare the efficiency of the recovery program to a plan\nbuilt with an oracle that has foreknowledge of future errors.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)从自然语言生成机器人程序的问题，这些程序可能因指令模糊、任务误解或世界状态信息缺失而出错，导致执行失败。作者提出了RoboRepair系统，该系统通过追踪程序执行至错误点，并运行LLM生成的恢复程序，以最小化重复动作并从当前世界状态恢复。论文创建了一个包含11个任务的基准，并比较了恢复程序的效率与预知未来错误的预言机计划，展示了该方法的实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review at ACL Rolling Review",
      "pdf_url": "http://arxiv.org/pdf/2410.18893v1",
      "published_date": "2024-10-24 16:30:14 UTC",
      "updated_date": "2024-10-24 16:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:01:48.476645"
    },
    {
      "arxiv_id": "2410.18890v1",
      "title": "Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks",
      "title_zh": "提升小规模大语言模型的功能调用以用于推理任务",
      "authors": [
        "Graziano A. Manduzio",
        "Federico A. Galatolo",
        "Mario G. C. A. Cimino",
        "Enzo Pasquale Scilingo",
        "Lorenzo Cominelli"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nexceptional capabilities in natural language understanding and generation.\nWhile these models excel in general complex reasoning tasks, they still face\nchallenges in mathematical problem-solving and logical reasoning. To address\nthese limitations, researchers have explored function calling abilities,\nallowing LLMs to execute provided functions and utilize their outputs for task\ncompletion. However, concentrating on specific tasks can be very inefficient\nfor large-scale LLMs to be used, because of the expensive cost of training and\ninference stages they need in terms of computational resources. This study\nintroduces a novel framework for training smaller language models in function\ncalling, focusing on specific logical and mathematical reasoning tasks. The\napproach aims to improve performances of small-scale models for these tasks\nusing function calling, ensuring a high level of accuracy. Our framework\nemploys an agent that, given a problem and a set of callable functions, queries\nthe LLM by injecting a description and examples of the usable functions into\nthe prompt and managing their calls in a step-by-step reasoning chain. This\nprocess is used to create a dataset of correct and incorrect reasoning chain\nchat completions from a large-scale LLM. This dataset is used to train a\nsmaller LLM using Reinforcement Learning from Human Feedback (RLHF),\nspecifically employing the Direct Preference Optimization (DPO) technique.\nExperimental results demonstrate how the proposed approach balances the\ntrade-off between model size and performance, improving the ability of function\ncalling for reasoning tasks, in smaller models.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在数学和逻辑推理任务中的局限性，提出了一种新框架，以提升小型语言模型的功能调用能力。该框架通过一个代理系统，将函数描述和示例注入提示，并管理逐步推理链，从而从大型LLMs生成包含正确和错误推理的数据集。随后，利用强化学习从人类反馈（RLHF）和直接偏好优化（DPO）技术训练小型模型，确保在推理任务中实现高准确性。实验结果显示，这种方法在模型大小与性能之间取得平衡，显著提高了小型LLMs的功能调用效能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18890v1",
      "published_date": "2024-10-24 16:27:35 UTC",
      "updated_date": "2024-10-24 16:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:02:01.026984"
    },
    {
      "arxiv_id": "2410.18881v1",
      "title": "Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences",
      "title_zh": "Diff-Instruct++：训练一步式文本到图像生成器模型以与人类偏好对齐",
      "authors": [
        "Weijian Luo"
      ],
      "abstract": "One-step text-to-image generator models offer advantages such as swift\ninference efficiency, flexible architectures, and state-of-the-art generation\nperformance. In this paper, we study the problem of aligning one-step generator\nmodels with human preferences for the first time. Inspired by the success of\nreinforcement learning using human feedback (RLHF), we formulate the alignment\nproblem as maximizing expected human reward functions while adding an Integral\nKullback-Leibler divergence term to prevent the generator from diverging. By\novercoming technical challenges, we introduce Diff-Instruct++ (DI++), the\nfirst, fast-converging and image data-free human preference alignment method\nfor one-step text-to-image generators. We also introduce novel theoretical\ninsights, showing that using CFG for diffusion distillation is secretly doing\nRLHF with DI++. Such an interesting finding brings understanding and potential\ncontributions to future research involving CFG. In the experiment sections, we\nalign both UNet-based and DiT-based one-step generators using DI++, which use\nthe Stable Diffusion 1.5 and the PixelArt-$\\alpha$ as the reference diffusion\nprocesses. The resulting DiT-based one-step text-to-image model achieves a\nstrong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO\nvalidation prompt dataset. It also achieves a leading Human preference Score\n(HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable\nDiffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\\alpha$. Both theoretical\ncontributions and empirical evidence indicate that DI++ is a strong\nhuman-preference alignment approach for one-step text-to-image models.",
      "tldr_zh": "该研究首次探讨了将一歩式文本到图像生成模型与人类偏好对齐的问题，提出Diff-Instruct++ (DI++)方法，该方法基于RLHF（Reinforcement Learning from Human Feedback）框架，通过最大化预期人类奖励函数并添加Integral Kullback-Leibler散度约束，实现快速收敛且无需图像数据。\nDI++的理论贡献包括揭示使用CFG（Classifier-Free Guidance）进行扩散蒸馏实际上等同于RLHF过程，为未来相关研究提供新见解。\n实验中，对UNet-based和DiT-based生成器进行对齐，使用Stable Diffusion 1.5和PixelArt-α作为参考，结果显示DiT-based模型在COCO数据集上达到Aesthetic Score 6.19、Image Reward 1.24和HPSv2.0 28.48，优于开源模型如Stable Diffusion XL和SD-Turbo。\n总之，DI++证明了其作为一歩式生成器偏好对齐的有效性，提升了模型的生成性能和人类满意度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18881v1",
      "published_date": "2024-10-24 16:17:18 UTC",
      "updated_date": "2024-10-24 16:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:02:14.692532"
    },
    {
      "arxiv_id": "2410.18876v1",
      "title": "Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Beaux",
        "Pegah Karimi",
        "Otilia Pop",
        "Rob Clark"
      ],
      "abstract": "In this innovative practice full paper, we address the equity gap for\nneurodivergent and situationally limited learners by identifying the spectrum\nof dynamic factors that impact learning and function. Educators have shown a\ngrowing interest in identifying learners' cognitive abilities and learning\npreferences to measure their impact on academic achievement. Often institutions\nemploy one-size-fits-all approaches leaving the burden on disabled students to\nself-advocate or tolerate inadequate support. Emerging frameworks guide\nneurodivergent learners through instructional approaches, such as online\neducation. However, these frameworks fail to address holistic environmental\nneeds or recommend technology interventions, particularly for those with\nundisclosed learning or developmental disabilities and situational limitations.\nIn this article, we integrate a neurodivergent perspective through secondary\nresearch of around 100 articles to introduce a Guiding Empowerment Model\ninvolving key cognitive and situational factors that contextualize day-to-day\nexperiences affecting learner ability. We synthesize three sample student\nprofiles that highlight user problems in functioning. We use this model to\nevaluate sample learning platform features and other supportive technology\nsolutions. The proposed approach augments frameworks such as Universal Design\nfor Learning to consider factors including various sensory processing\ndifferences, social connection challenges, and environmental limitations. We\nsuggest that by applying the mode through technology-enabled features such as\ncustomizable task management, guided varied content access, and guided\nmulti-modal collaboration, major learning barriers of neurodivergent and\nsituationally limited learners will be removed to activate the successful\npursuit of their academic goals.",
      "tldr_zh": "本研究针对在线高等教育中神经多样性(neurodivergent)学习者和情境受限学习者的公平差距，提出Guiding Empowerment Model，该模型整合认知和情境因素，以解决现有框架（如Universal Design for Learning）对整体环境需求和技术干预的忽视。研究通过对约100篇文献的二次分析，合成三类学生案例，评估学习平台功能和支持性技术解决方案。模型强调考虑感官处理差异、社会连接挑战和环境限制，通过技术功能如可自定义任务管理、多模态内容访问和协作，帮助消除主要学习障碍，促进这些学习者成功实现学术目标。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 1 Figure, 1 Table, Accepted in FIE 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18876v1",
      "published_date": "2024-10-24 16:05:38 UTC",
      "updated_date": "2024-10-24 16:05:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:02:23.728892"
    },
    {
      "arxiv_id": "2410.18866v1",
      "title": "The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models and Detection Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Linda Laurier",
        "Ave Giulietta",
        "Arlo Octavia",
        "Meade Cleti"
      ],
      "abstract": "The emergence of diffusion models has transformed synthetic media generation,\noffering unmatched realism and control over content creation. These\nadvancements have driven innovation across fields such as art, design, and\nscientific visualization. However, they also introduce significant ethical and\nsocietal challenges, particularly through the creation of hyper-realistic\nimages that can facilitate deepfakes, misinformation, and unauthorized\nreproduction of copyrighted material. In response, the need for effective\ndetection mechanisms has become increasingly urgent. This review examines the\nevolving adversarial relationship between diffusion model development and the\nadvancement of detection methods. We present a thorough analysis of\ncontemporary detection strategies, including frequency and spatial domain\ntechniques, deep learning-based approaches, and hybrid models that combine\nmultiple methodologies. We also highlight the importance of diverse datasets\nand standardized evaluation metrics in improving detection accuracy and\ngeneralizability. Our discussion explores the practical applications of these\ndetection systems in copyright protection, misinformation prevention, and\nforensic analysis, while also addressing the ethical implications of synthetic\nmedia. Finally, we identify key research gaps and propose future directions to\nenhance the robustness and adaptability of detection methods in line with the\nrapid advancements of diffusion models. This review emphasizes the necessity of\na comprehensive approach to mitigating the risks associated with AI-generated\ncontent in an increasingly digital world.",
      "tldr_zh": "这篇评论文章探讨了扩散模型（diffusion models）在生成合成媒体方面的快速发展及其带来的双重影响，包括创新应用（如艺术和科学可视化）以及伦理挑战（如深度伪造、误信息和版权侵犯）。作者分析了检测方法的演进，包括频率和空间域技术、基于深度学习的策略以及混合模型，并强调了多样数据集和标准化评估指标在提升检测准确性和泛化能力方面的作用。最终，该文指出了关键研究空白，提出未来方向以加强检测方法的鲁棒性，并呼吁采用全面策略来缓解AI生成内容在数字世界中的风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.18866v1",
      "published_date": "2024-10-24 15:51:04 UTC",
      "updated_date": "2024-10-24 15:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:02:36.631991"
    },
    {
      "arxiv_id": "2410.18861v1",
      "title": "Provably Robust Watermarks for Open-Source Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Miranda Christ",
        "Sam Gunn",
        "Tal Malkin",
        "Mariana Raykova"
      ],
      "abstract": "The recent explosion of high-quality language models has necessitated new\nmethods for identifying AI-generated text. Watermarking is a leading solution\nand could prove to be an essential tool in the age of generative AI. Existing\napproaches embed watermarks at inference and crucially rely on the large\nlanguage model (LLM) specification and parameters being secret, which makes\nthem inapplicable to the open-source setting. In this work, we introduce the\nfirst watermarking scheme for open-source LLMs. Our scheme works by modifying\nthe parameters of the model, but the watermark can be detected from just the\noutputs of the model. Perhaps surprisingly, we prove that our watermarks are\nunremovable under certain assumptions about the adversary's knowledge. To\ndemonstrate the behavior of our construction under concrete parameter\ninstantiations, we present experimental results with OPT-6.7B and OPT-1.3B. We\ndemonstrate robustness to both token substitution and perturbation of the model\nparameters. We find that the stronger of these attacks, the model-perturbation\nattack, requires deteriorating the quality score to 0 out of 100 in order to\nbring the detection rate down to 50%.",
      "tldr_zh": "该研究提出了一种首个适用于开源大语言模型（LLMs）的鲁棒水印方案，旨在解决AI生成文本识别问题，同时克服现有水印方法对模型参数保密性的依赖。方法通过修改模型参数来嵌入水印，但水印检测仅基于模型输出，并在特定假设下证明其不可移除。实验在OPT-6.7B和OPT-1.3B模型上显示，该水印对token替换和模型参数扰动攻击具有高鲁棒性，其中最强攻击需将模型质量分数降至0分，才能使检测率降至50%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18861v1",
      "published_date": "2024-10-24 15:44:34 UTC",
      "updated_date": "2024-10-24 15:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:02:48.114200"
    },
    {
      "arxiv_id": "2410.18860v1",
      "title": "DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Aryo Pradipta Gema",
        "Chen Jin",
        "Ahmed Abdulaal",
        "Tom Diethe",
        "Philip Teare",
        "Beatrice Alex",
        "Pasquale Minervini",
        "Amrutha Saseendran"
      ],
      "abstract": "Large Language Models (LLMs) often hallucinate, producing unfaithful or\nfactually incorrect outputs by misrepresenting the provided context or\nincorrectly recalling internal knowledge. Recent studies have identified\nspecific attention heads within the Transformer architecture, known as\nretrieval heads, responsible for extracting relevant contextual information. We\nhypothesise that masking these retrieval heads can induce hallucinations and\nthat contrasting the outputs of the base LLM and the masked LLM can reduce\nhallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads\n(DeCoRe), a novel training-free decoding strategy that amplifies information\nfound in the context and model parameters. DeCoRe mitigates potentially\nhallucinated responses by dynamically contrasting the outputs of the base LLM\nand the masked LLM, using conditional entropy as a guide. Our extensive\nexperiments confirm that DeCoRe significantly improves performance on tasks\nrequiring high contextual faithfulness, such as summarisation (XSum by 18.6%),\ninstruction following (MemoTrap by 10.9%), and open-book question answering\n(NQ-Open by 2.4% and NQ-Swap by 5.5%).",
      "tldr_zh": "该论文探讨了大语言模型（LLMs）产生的幻觉问题，提出DeCoRe，一种无需训练的解码策略，通过对比base LLM和masked retrieval heads的输出，利用conditional entropy作为指导，放大上下文信息并减少幻觉。DeCoRe的工作原理是动态对比模型输出，增强信息忠实性。实验结果显示，该方法在高上下文忠诚度任务上表现出色，包括总结任务（XSum提升18.6%）、指令遵循（MemoTrap提升10.9%）以及开放式问答（NQ-Open提升2.4%、NQ-Swap提升5.5%）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18860v1",
      "published_date": "2024-10-24 15:44:33 UTC",
      "updated_date": "2024-10-24 15:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:03:01.001752"
    },
    {
      "arxiv_id": "2410.18856v3",
      "title": "Demystifying Large Language Models for Medicine: A Primer",
      "title_zh": "揭开医学大语言模型的神秘面纱：入门指南",
      "authors": [
        "Qiao Jin",
        "Nicholas Wan",
        "Robert Leaman",
        "Shubo Tian",
        "Zhizheng Wang",
        "Yifan Yang",
        "Zifeng Wang",
        "Guangzhi Xiong",
        "Po-Ting Lai",
        "Qingqing Zhu",
        "Benjamin Hou",
        "Maame Sarfo-Gyamfi",
        "Gongbo Zhang",
        "Aidan Gilson",
        "Balu Bhasuran",
        "Zhe He",
        "Aidong Zhang",
        "Jimeng Sun",
        "Chunhua Weng",
        "Ronald M. Summers",
        "Qingyu Chen",
        "Yifan Peng",
        "Zhiyong Lu"
      ],
      "abstract": "Large language models (LLMs) represent a transformative class of AI tools\ncapable of revolutionizing various aspects of healthcare by generating\nhuman-like responses across diverse contexts and adapting to novel tasks\nfollowing human instructions. Their potential application spans a broad range\nof medical tasks, such as clinical documentation, matching patients to clinical\ntrials, and answering medical questions. In this primer paper, we propose an\nactionable guideline to help healthcare professionals more efficiently utilize\nLLMs in their work, along with a set of best practices. This approach consists\nof several main phases, including formulating the task, choosing LLMs, prompt\nengineering, fine-tuning, and deployment. We start with the discussion of\ncritical considerations in identifying healthcare tasks that align with the\ncore capabilities of LLMs and selecting models based on the selected task and\ndata, performance requirements, and model interface. We then review the\nstrategies, such as prompt engineering and fine-tuning, to adapt standard LLMs\nto specialized medical tasks. Deployment considerations, including regulatory\ncompliance, ethical guidelines, and continuous monitoring for fairness and\nbias, are also discussed. By providing a structured step-by-step methodology,\nthis tutorial aims to equip healthcare professionals with the tools necessary\nto effectively integrate LLMs into clinical practice, ensuring that these\npowerful technologies are applied in a safe, reliable, and impactful manner.",
      "tldr_zh": "这篇论文介绍了大型语言模型(LLMs)在医疗领域的应用潜力，包括生成临床文档、匹配患者到临床试验以及回答医疗问题等任务。作为入门指南，它提出一个行动框架，帮助医疗专业人士高效利用LLMs，包括任务制定、模型选择、prompt engineering、fine-tuning和部署等阶段。论文强调了关键考虑因素，如模型适应性、监管合规和持续监控，以确保LLMs在临床实践中安全、可靠并减少偏见。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.18856v3",
      "published_date": "2024-10-24 15:41:56 UTC",
      "updated_date": "2024-11-20 01:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:03:12.225870"
    },
    {
      "arxiv_id": "2410.18852v1",
      "title": "DL-Polycube: Deep learning enhanced polycube method for high-quality hexahedral mesh generation and volumetric spline construction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Yu",
        "Yuzhuo Fang",
        "Hua Tong",
        "Yongjie Jessica Zhang"
      ],
      "abstract": "In this paper, we present a novel algorithm that integrates deep learning\nwith the polycube method (DL-Polycube) to generate high-quality hexahedral\n(hex) meshes, which are then used to construct volumetric splines for\nisogeometric analysis. Our DL-Polycube algorithm begins by establishing a\nconnection between surface triangular meshes and polycube structures. We employ\ndeep neural network to classify surface triangular meshes into their\ncorresponding polycube structures. Following this, we combine the acquired\npolycube structural information with unsupervised learning to perform surface\nsegmentation of triangular meshes. This step addresses the issue of\nsegmentation not corresponding to a polycube while reducing manual\nintervention. Quality hex meshes are then generated from the polycube\nstructures, with employing octree subdivision, parametric mapping and quality\nimprovement techniques. The incorporation of deep learning for creating\npolycube structures, combined with unsupervised learning for segmentation of\nsurface triangular meshes, substantially accelerates hex mesh generation.\nFinally, truncated hierarchical B-splines are constructed on the generated hex\nmeshes. We extract trivariate B\\'ezier elements from these splines and apply\nthem directly in isogeometric analysis. We offer several examples to\ndemonstrate the robustness of our DL-Polycube algorithm.",
      "tldr_zh": "本文提出DL-Polycube算法，将深度学习与polycube方法相结合，用于生成高质量的hexahedral mesh，并应用于体积样条构建和isogeometric analysis。该算法首先使用深度神经网络对表面三角网格进行分类，结合无监督学习实现表面分割，减少手动干预并加速网格生成过程。随后，通过octree subdivision、parametric mapping和质量改进技术，从polycube结构生成高质量hex mesh，并在这些网格上构建truncated hierarchical B-splines，并提取trivariate Bézier elements用于分析。实验结果显示，该方法显著提高了hex mesh生成效率，并在多个例子中证明了其鲁棒性。",
      "categories": [
        "cs.CG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.CG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18852v1",
      "published_date": "2024-10-24 15:35:08 UTC",
      "updated_date": "2024-10-24 15:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:03:25.762134"
    },
    {
      "arxiv_id": "2410.18845v1",
      "title": "Expanding AI Awareness Through Everyday Interactions with AI: A Reflective Journal Study",
      "title_zh": "通过与 AI 的日常互动扩展 AI 意识：一个反思性日志研究",
      "authors": [
        "Ashish Hingle",
        "Aditya Johri"
      ],
      "abstract": "As the application of AI continues to expand, students in technology programs\nare poised to be both producers and users of the technologies. They are also\npositioned to engage with AI applications within and outside the classroom.\nWhile focusing on the curriculum when examining students' AI knowledge is\ncommon, extending this connection to students' everyday interactions with AI\nprovides a more complete picture of their learning. In this paper, we explore\nstudent's awareness and engagement with AI in the context of school and their\ndaily lives. Over six weeks, 22 undergraduate students participated in a\nreflective journal study and submitted a weekly journal entry about their\ninteractions with AI. The participants were recruited from a technology and\nsociety course that focuses on the implications of technology on people,\ncommunities, and processes. In their weekly journal entries, participants\nreflected on interactions with AI on campus (coursework, advertises campus\nevents, or seminars) and beyond (social media, news, or conversations with\nfriends and family). The journal prompts were designed to help them think\nthrough what they had read, watched, or been told and reflect on the\ndevelopment of their own perspectives, knowledge, and literacy on the topic.\nOverall, students described nine categories of interactions: coursework, news\nand current events, using software and applications, university events, social\nmedia related to their work, personal discussions with friends and family,\ninteracting with content, and gaming. Students reported that completing the\ndiaries allowed them time for reflection and made them more aware of the\npresence of AI in their daily lives and of its potential benefits and\ndrawbacks. This research contributes to the ongoing work on AI awareness and\nliteracy by bringing in perspectives from beyond a formal educational context.",
      "tldr_zh": "本研究探讨了学生通过日常生活与AI互动来提升AI意识，采用为期六周的反思日志研究（reflective journal study），让22名本科生每周记录他们在校园（如课程和事件）和日常（如社交媒体、新闻和对话）中的AI互动。\n学生描述了九个互动类别，包括课程、新闻、软件使用、大学事件等。\n通过这项活动，参与者报告说日志帮助他们进行反思，提高了对AI在日常生活中的存在、潜在益处和缺点的意识。\n该研究为AI awareness和literacy领域做出了贡献，扩展了视角从正式教育到更广泛的非正式环境。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted and presented at the Frontiers in Education 2024 (FIE2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.18845v1",
      "published_date": "2024-10-24 15:26:34 UTC",
      "updated_date": "2024-10-24 15:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:03:37.101888"
    },
    {
      "arxiv_id": "2410.18844v1",
      "title": "Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Udvas Das",
        "Debabrota Basu"
      ],
      "abstract": "Pure exploration in bandits models multiple real-world problems, such as\ntuning hyper-parameters or conducting user studies, where different safety,\nresource, and fairness constraints on the decision space naturally appear. We\nstudy these problems as pure exploration in multi-armed bandits with unknown\nlinear constraints, where the aim is to identify an $r$$\\textit{-good feasible\npolicy}$. First, we propose a Lagrangian relaxation of the sample complexity\nlower bound for pure exploration under constraints. We show how this lower\nbound evolves with the sequential estimation of constraints. Second, we\nleverage the Lagrangian lower bound and the properties of convex optimisation\nto propose two computationally efficient extensions of Track-and-Stop and\nGamified Explorer, namely LATS and LAGEX. To this end, we propose a\nconstraint-adaptive stopping rule, and while tracking the lower bound, use\npessimistic estimate of the feasible set at each step. We show that these\nalgorithms achieve asymptotically optimal sample complexity upper bounds up to\nconstraint-dependent constants. Finally, we conduct numerical experiments with\ndifferent reward distributions and constraints that validate efficient\nperformance of LAGEX and LATS with respect to baselines.",
      "tldr_zh": "该论文研究了多臂老虎机(multi-armed bandits)中的纯探索问题，特别是在未知线性约束下，目标是识别一个 r-good feasible policy，以应对安全、资源和公平性等限制。作者提出使用拉格朗日松弛(Lagrangian relaxation)来优化样本复杂度的下界，并据此开发了两个算法：LATS 和 LAGEX，这些算法扩展了 Track-and-Stop 和 Gamified Explorer，通过约束自适应停止规则和悲观估计(pessimistic estimate)来实现渐进最优样本复杂度。实验结果显示，LAGEX 和 LATS 在不同奖励分布和约束场景下表现出色，验证了其高效性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18844v1",
      "published_date": "2024-10-24 15:26:14 UTC",
      "updated_date": "2024-10-24 15:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:03:49.383387"
    },
    {
      "arxiv_id": "2410.18841v1",
      "title": "From Efficiency to Equity: Measuring Fairness in Preference Learning",
      "title_zh": "从效率到公平：测量偏好学习中的公平性",
      "authors": [
        "Shreeyash Gowaikar",
        "Hugo Berard",
        "Rashid Mushkani",
        "Shin Koseki"
      ],
      "abstract": "As AI systems, particularly generative models, increasingly influence\ndecision-making, ensuring that they are able to fairly represent diverse human\npreferences becomes crucial. This paper introduces a novel framework for\nevaluating epistemic fairness in preference learning models inspired by\neconomic theories of inequality and Rawlsian justice. We propose metrics\nadapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to\nquantify fairness in these models. We validate our approach using two datasets:\na custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.\nOur analysis reveals variations in model performance across users, highlighting\npotential epistemic injustices. We explore pre-processing and in-processing\ntechniques to mitigate these inequalities, demonstrating a complex relationship\nbetween model efficiency and fairness. This work contributes to AI ethics by\nproviding a framework for evaluating and improving epistemic fairness in\npreference learning models, offering insights for developing more inclusive AI\nsystems in contexts where diverse human preferences are crucial.",
      "tldr_zh": "这篇论文提出了一种新框架，用于评估偏好学习模型中的认知公平性（epistemic fairness），其灵感来源于经济学的平等理论和罗尔斯正义理论。作者改编了Gini Coefficient、Atkinson Index和Kuznets Ratio等指标来量化模型公平性，并使用AI-EDI-Space和Jester Jokes数据集进行验证，结果显示模型性能在不同用户间存在差异，突显潜在的不公问题。论文还探索了预处理和处理中技术来缓解这些不平等，揭示了模型效率与公平性之间的复杂关系，并为开发更具包容性的AI系统提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18841v1",
      "published_date": "2024-10-24 15:25:56 UTC",
      "updated_date": "2024-10-24 15:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:04:00.722906"
    },
    {
      "arxiv_id": "2410.18836v1",
      "title": "From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages",
      "title_zh": "从英语为中心到有效的双语：使用自定义分词器的大型语言模型，用于代表性不足的语言",
      "authors": [
        "Artur Kiulian",
        "Anton Polishko",
        "Mykola Khandoga",
        "Yevhen Kostiuk",
        "Guillermo Gabrielli",
        "Łukasz Gagała",
        "Fadi Zaraket",
        "Qusai Abu Obaida",
        "Hrishikesh Garud",
        "Wendy Wing Yee Mak",
        "Dmytro Chaplynskyi",
        "Selma Belhadj Amor",
        "Grigol Peradze"
      ],
      "abstract": "In this paper, we propose a model-agnostic cost-effective approach to\ndeveloping bilingual base large language models (LLMs) to support English and\nany target language. The method includes vocabulary expansion, initialization\nof new embeddings, model training and evaluation. We performed our experiments\nwith three languages, each using a non-Latin script - Ukrainian, Arabic, and\nGeorgian.\n  Our approach demonstrates improved language performance while reducing\ncomputational costs. It mitigates the disproportionate penalization of\nunderrepresented languages, promoting fairness and minimizing adverse phenomena\nsuch as code-switching and broken grammar. Additionally, we introduce new\nmetrics to evaluate language quality, revealing that vocabulary size\nsignificantly impacts the quality of generated text.",
      "tldr_zh": "这篇论文提出了一种模型无关且成本有效的approach，用于开发支持英语和目标语言的双语基础大型语言模型（LLMs），方法包括vocabulary expansion、新嵌入初始化、模型训练和评估。实验在Ukrainian、Arabic和Georgian等非拉丁脚本的underrepresented languages上进行，展示了显著的语言性能提升，同时降低了计算成本，并缓解了这些语言的不公平惩罚，如减少code-switching和语法错误。论文还引入了新的metrics来评估语言质量，发现vocabulary size对生成文本的质量有重要影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18836v1",
      "published_date": "2024-10-24 15:20:54 UTC",
      "updated_date": "2024-10-24 15:20:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:04:12.634762"
    },
    {
      "arxiv_id": "2410.18823v2",
      "title": "Towards Visual Text Design Transfer Across Languages",
      "title_zh": "迈向跨语言的视觉文本设计转移",
      "authors": [
        "Yejin Choi",
        "Jiwan Chung",
        "Sumin Shim",
        "Giyeong Oh",
        "Youngjae Yu"
      ],
      "abstract": "Visual text design plays a critical role in conveying themes, emotions, and\natmospheres in multimodal formats such as film posters and album covers.\nTranslating these visual and textual elements across languages extends the\nconcept of translation beyond mere text, requiring the adaptation of aesthetic\nand stylistic features. To address this, we introduce a novel task of\nMultimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the\nability of visual text generation models to perform translation across\ndifferent writing systems while preserving design intent. Our initial\nexperiments on MuST-Bench reveal that existing visual text generation models\nstruggle with the proposed task due to the inadequacy of textual descriptions\nin conveying visual design. In response, we introduce SIGIL, a framework for\nmultimodal style translation that eliminates the need for style descriptions.\nSIGIL enhances image generation models through three innovations: glyph latent\nfor multilingual settings, pretrained VAEs for stable style guidance, and an\nOCR model with reinforcement learning feedback for optimizing readable\ncharacter generation. SIGIL outperforms existing baselines by achieving\nsuperior style consistency and legibility while maintaining visual fidelity,\nsetting itself apart from traditional description-based approaches. We release\nMuST-Bench publicly for broader use and exploration\nhttps://huggingface.co/datasets/yejinc/MuST-Bench.",
      "tldr_zh": "本研究探讨了视觉文本设计的跨语言转移问题，强调其在多模态格式（如电影海报和专辑封面）中传达主题、情感和氛围的重要性，并引入了新的基准任务Multimodal Style Translation (MuST-Bench)，用于评估视觉文本生成模型在不同书写系统间翻译的能力，同时保留设计意图。实验发现，现有的模型因文本描述不足而难以有效处理此任务。针对此问题，研究提出SIGIL框架，通过glyph latent支持多语言设置、pretrained VAEs提供稳定的风格指导，以及OCR模型结合reinforcement learning反馈优化可读字符生成，从而提升风格一致性、可读性和视觉保真度。SIGIL在性能上优于现有基线，并公开发布了MuST-Bench数据集以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18823v2",
      "published_date": "2024-10-24 15:15:01 UTC",
      "updated_date": "2024-10-29 08:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:04:26.773270"
    },
    {
      "arxiv_id": "2410.18786v1",
      "title": "Applying Neural Monte Carlo Tree Search to Unsignalized Multi-intersection Scheduling for Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Shi",
        "Wenlong Wang",
        "Xiaowen Tao",
        "Ivana Dusparic",
        "Vinny Cahill"
      ],
      "abstract": "Dynamic scheduling of access to shared resources by autonomous systems is a\nchallenging problem, characterized as being NP-hard. The complexity of this\ntask leads to a combinatorial explosion of possibilities in highly dynamic\nsystems where arriving requests must be continuously scheduled subject to\nstrong safety and time constraints. An example of such a system is an\nunsignalized intersection, where automated vehicles' access to potential\nconflict zones must be dynamically scheduled. In this paper, we apply Neural\nMonte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons\nof vehicles crossing unsignalized intersections. Crucially, we introduce a\ntransformation model that maps successive sequences of potentially conflicting\nroad-space reservation requests from platoons of vehicles into a series of\nboard-game-like problems and use NMCTS to search for solutions representing\noptimal road-space allocation schedules in the context of past allocations. To\noptimize search, we incorporate a prioritized re-sampling method with parallel\nNMCTS (PNMCTS) to improve the quality of training data. To optimize training, a\ncurriculum learning strategy is used to train the agent to schedule\nprogressively more complex boards culminating in overlapping boards that\nrepresent busy intersections. In a busy single four-way unsignalized\nintersection simulation, PNMCTS solved 95\\% of unseen scenarios, reducing\ncrossing time by 43\\% in light and 52\\% in heavy traffic versus first-in,\nfirst-out control. In a 3x3 multi-intersection network, the proposed method\nmaintained free-flow in light traffic when all intersections are under control\nof PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers\nin average travel time by 74.5\\% and total throughput by 16\\% in heavy traffic.",
      "tldr_zh": "该论文将 Neural Monte Carlo Tree Search (NMCTS) 应用于无信号灯多交叉路口的自治车辆调度问题，通过一个转换模型将车辆预约请求转化为类似棋盘游戏的序列问题，并使用 prioritized re-sampling 和 parallel NMCTS (PNMCTS) 优化搜索过程，同时采用 curriculum learning 策略训练代理处理复杂场景。\n这种方法解决了 NP-hard 的动态调度挑战，确保车辆安全高效穿越交叉路口。\n实验结果显示，在单四向交叉路口模拟中，PNMCTS 解决了95% 的未见场景，减少通行时间43%（轻交通）和52%（重交通）；在3x3多交叉路口网络中，它在重交通下比现有RL-based控制器降低平均旅行时间74.5%并提高总吞吐量16%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18786v1",
      "published_date": "2024-10-24 14:37:55 UTC",
      "updated_date": "2024-10-24 14:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:04:38.516710"
    },
    {
      "arxiv_id": "2410.18785v1",
      "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Li",
        "Xiang Liu",
        "Zhenheng Tang",
        "Peijie Dong",
        "Zeyu Li",
        "Xinglin Pan",
        "Xiaowen Chu"
      ],
      "abstract": "Model editing has become an increasingly popular alternative for efficiently\nupdating knowledge within language models. Current methods mainly focus on\nreliability, generalization, and locality, with many methods excelling across\nthese criteria. Some recent works disclose the pitfalls of these editing\nmethods such as knowledge distortion or conflict. However, the general\nabilities of post-edited language models remain unexplored. In this paper, we\nperform a comprehensive evaluation on various editing methods and different\nlanguage models, and have following findings. (1) Existing editing methods lead\nto inevitable performance deterioration on general benchmarks, indicating that\nexisting editing methods maintain the general abilities of the model within\nonly a few dozen edits. When the number of edits is slightly large, the\nintrinsic knowledge structure of the model is disrupted or even completely\ndamaged. (2) Instruction-tuned models are more robust to editing, showing less\nperformance drop on general knowledge after editing. (3) Language model with\nlarge scale is more resistant to editing compared to small model. (4) The\nsafety of the edited model, is significantly weakened, even for those\nsafety-aligned models. Our findings indicate that current editing methods are\nonly suitable for small-scale knowledge updates within language models, which\nmotivates further research on more practical and reliable editing methods. The\ndetails of code and reproduction can be found in\nhttps://github.com/lqinfdim/EditingEvaluation.",
      "tldr_zh": "这篇论文评估了语言模型的模型编辑方法，探讨其对模型整体性能的影响。研究发现，现有的编辑方法会导致模型在通用基准上的性能下降，尤其在编辑次数较多时，会破坏模型的内在知识结构。指令调优模型和大型语言模型对编辑更robust，而编辑后模型的安全性显著减弱。作者得出结论，当前方法仅适用于小规模知识更新，并呼吁开发更可靠的编辑技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 https://github.com/lqinfdim/EditingEvaluation",
      "pdf_url": "http://arxiv.org/pdf/2410.18785v1",
      "published_date": "2024-10-24 14:36:48 UTC",
      "updated_date": "2024-10-24 14:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:04:48.681702"
    },
    {
      "arxiv_id": "2410.18775v2",
      "title": "Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances",
      "title_zh": "使用生成式先验的鲁棒水印技术对抗图像编辑：从基准测试到",
      "authors": [
        "Shilin Lu",
        "Zihan Zhou",
        "Jiayou Lu",
        "Yuanzhi Zhu",
        "Adams Wai-Kin Kong"
      ],
      "abstract": "Current image watermarking methods are vulnerable to advanced image editing\ntechniques enabled by large-scale text-to-image models. These models can\ndistort embedded watermarks during editing, posing significant challenges to\ncopyright protection. In this work, we introduce W-Bench, the first\ncomprehensive benchmark designed to evaluate the robustness of watermarking\nmethods against a wide range of image editing techniques, including image\nregeneration, global editing, local editing, and image-to-video generation.\nThrough extensive evaluations of eleven representative watermarking methods\nagainst prevalent editing techniques, we demonstrate that most methods fail to\ndetect watermarks after such edits. To address this limitation, we propose\nVINE, a watermarking method that significantly enhances robustness against\nvarious image editing techniques while maintaining high image quality. Our\napproach involves two key innovations: (1) we analyze the frequency\ncharacteristics of image editing and identify that blurring distortions exhibit\nsimilar frequency properties, which allows us to use them as surrogate attacks\nduring training to bolster watermark robustness; (2) we leverage a large-scale\npretrained diffusion model SDXL-Turbo, adapting it for the watermarking task to\nachieve more imperceptible and robust watermark embedding. Experimental results\nshow that our method achieves outstanding watermarking performance under\nvarious image editing techniques, outperforming existing methods in both image\nquality and robustness. Code is available at https://github.com/Shilin-LU/VINE.",
      "tldr_zh": "本文研究了图像水印方法对基于大型文本到图像模型的编辑技术的脆弱性，引入了 W-Bench 作为首个全面基准，用于评估水印在图像再生、全局编辑、局部编辑和图像到视频生成等场景下的鲁棒性。实验显示，11 种代表性方法在编辑后大多无法检测水印；为此，提出 VINE 方法，通过分析编辑的频率特性（如模糊失真）作为训练代理攻击，并利用预训练扩散模型 SDXL-Turbo 实现更隐蔽且鲁棒的水印嵌入。结果表明，VINE 在图像质量和抗编辑性能上均优于现有方法，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18775v2",
      "published_date": "2024-10-24 14:28:32 UTC",
      "updated_date": "2025-03-15 02:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:05:01.797606"
    },
    {
      "arxiv_id": "2410.18749v1",
      "title": "Does Differential Privacy Impact Bias in Pretrained NLP Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Khairul Islam",
        "Andrew Wang",
        "Tianhao Wang",
        "Yangfeng Ji",
        "Judy Fox",
        "Jieyu Zhao"
      ],
      "abstract": "Differential privacy (DP) is applied when fine-tuning pre-trained large\nlanguage models (LLMs) to limit leakage of training examples. While most DP\nresearch has focused on improving a model's privacy-utility tradeoff, some find\nthat DP can be unfair to or biased against underrepresented groups. In this\nwork, we show the impact of DP on bias in LLMs through empirical analysis.\nDifferentially private training can increase the model bias against protected\ngroups w.r.t AUC-based bias metrics. DP makes it more difficult for the model\nto differentiate between the positive and negative examples from the protected\ngroups and other groups in the rest of the population. Our results also show\nthat the impact of DP on bias is not only affected by the privacy protection\nlevel but also the underlying distribution of the dataset.",
      "tldr_zh": "本研究探讨了差分隐私 (DP) 在微调预训练大型语言模型 (LLMs) 时是否会加剧模型偏见，通过实证分析评估其对受保护群体的影响。研究发现，DP 训练可能会增加模型对这些群体的偏见，尤其在 AUC-based bias metrics 上，导致模型更难区分受保护群体与其他群体的正负示例。主要结果显示，这种偏见影响不仅取决于隐私保护级别，还受数据集底层分布的影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Github https://github.com/khairulislam/DP-on-NLP-Bias",
      "pdf_url": "http://arxiv.org/pdf/2410.18749v1",
      "published_date": "2024-10-24 13:59:03 UTC",
      "updated_date": "2024-10-24 13:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:05:12.220971"
    },
    {
      "arxiv_id": "2410.19878v3",
      "title": "Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies",
      "title_zh": "翻译失败",
      "authors": [
        "Luping Wang",
        "Sheng Chen",
        "Linnan Jiang",
        "Shu Pan",
        "Runze Cai",
        "Sen Yang",
        "Fei Yang"
      ],
      "abstract": "The large models, as predicted by scaling raw forecasts, have made\ngroundbreaking progress in many fields, particularly in natural language\ngeneration tasks, where they have approached or even surpassed human levels.\nHowever, the unprecedented scale of their parameters brings significant\ncomputational and storage costs. These large models require substantial\ncomputational resources and GPU memory to operate. When adapting large models\nto specific downstream tasks, their massive parameter scale poses a significant\nchallenge in fine-tuning on hardware platforms with limited computational power\nand GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT)\noffers a practical solution by efficiently adjusting the parameters of large\npre-trained models to suit various downstream tasks. Specifically, PEFT adjusts\nthe parameters of pre-trained large models to adapt to specific tasks or\ndomains, minimizing the introduction of additional parameters and the\ncomputational resources required. This review mainly introduces the preliminary\nknowledge of PEFT, the core ideas and principles of various PEFT algorithms,\nthe applications of PEFT, and potential future research directions. By reading\nthis review, we believe that interested parties can quickly grasp the PEFT\nmethodology, thereby accelerating its development and innovation.",
      "tldr_zh": "这篇综述探讨了大型模型（large models）在自然语言生成等任务中取得的突破性进展，但其海量参数导致的计算和存储成本问题，使得在资源有限的硬件上进行微调（fine-tuning）变得具有挑战性。Parameter-Efficient Fine-Tuning (PEFT) 作为一种高效解决方案，仅调整少量参数以适应特定下游任务，从而减少额外参数引入和资源需求。论文详细介绍了 PEFT 的基础知识、各种算法的核心原理和应用场景，并探讨了潜在的未来研究方向，帮助读者快速掌握该方法并推动其创新发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19878v3",
      "published_date": "2024-10-24 13:58:59 UTC",
      "updated_date": "2025-04-24 07:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:05:24.000749"
    },
    {
      "arxiv_id": "2410.18738v1",
      "title": "Cellpose+, a morphological analysis tool for feature extraction of stained cell images",
      "title_zh": "翻译失败",
      "authors": [
        "Israel A. Huaman",
        "Fares D. E. Ghorabe",
        "Sofya S. Chumakova",
        "Alexandra A. Pisarenko",
        "Alexey E. Dudaev",
        "Tatiana G. Volova",
        "Galina A. Ryltseva",
        "Sviatlana A. Ulasevich",
        "Ekaterina I. Shishatskaya",
        "Ekaterina V. Skorb",
        "Pavel S. Zun"
      ],
      "abstract": "Advanced image segmentation and processing tools present an opportunity to\nstudy cell processes and their dynamics. However, image analysis is often\nroutine and time-consuming. Nowadays, alternative data-driven approaches using\ndeep learning are potentially offering automatized, accurate, and fast image\nanalysis. In this paper, we extend the applications of Cellpose, a\nstate-of-the-art cell segmentation framework, with feature extraction\ncapabilities to assess morphological characteristics. We also introduce a\ndataset of DAPI and FITC stained cells to which our new method is applied.",
      "tldr_zh": "该论文扩展了Cellpose框架，增加特征提取功能，用于评估染色细胞图像的形态特征，从而实现更高效的细胞过程研究。研究采用深度学习的数据驱动方法，提供自动化、准确且快速的图像分析解决方案。同时，引入了一个包含DAPI和FITC染色细胞的数据集，并应用新方法进行形态特征提取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18738v1",
      "published_date": "2024-10-24 13:41:40 UTC",
      "updated_date": "2024-10-24 13:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:05:36.000260"
    },
    {
      "arxiv_id": "2410.18725v2",
      "title": "AI Readiness in Healthcare through Storytelling XAI",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Dubey",
        "Zewen Yang",
        "Georges Hattab"
      ],
      "abstract": "Artificial Intelligence is rapidly advancing and radically impacting everyday\nlife, driven by the increasing availability of computing power. Despite this\ntrend, the adoption of AI in real-world healthcare is still limited. One of the\nmain reasons is the trustworthiness of AI models and the potential hesitation\nof domain experts with model predictions. Explainable Artificial Intelligence\n(XAI) techniques aim to address these issues. However, explainability can mean\ndifferent things to people with different backgrounds, expertise, and goals. To\naddress the target audience with diverse needs, we develop storytelling XAI. In\nthis research, we have developed an approach that combines multi-task\ndistillation with interpretability techniques to enable audience-centric\nexplainability. Using multi-task distillation allows the model to exploit the\nrelationships between tasks, potentially improving interpretability as each\ntask supports the other leading to an enhanced interpretability from the\nperspective of a domain expert. The distillation process allows us to extend\nthis research to large deep models that are highly complex. We focus on both\nmodel-agnostic and model-specific methods of interpretability, supported by\ntextual justification of the results in healthcare through our use case. Our\nmethods increase the trust of both the domain experts and the machine learning\nexperts to enable a responsible AI.",
      "tldr_zh": "这篇论文探讨了AI在医疗领域的采用受限问题，主要由于模型可信度和专家对预测的犹豫。研究提出storytelling XAI方法，通过multi-task distillation与解释性技术相结合，实现面向受众的解释性，使模型能够利用任务间关系提升从领域专家视角的解读。实验验证了该方法适用于大型复杂模型，并结合模型无关和模型相关的解释技术，提供文本支持，最终增强了领域专家和机器学习专家的信任，促进负责任的AI发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-print of the accepted manuscript in EXPLIMED - First Workshop on\n  Explainable Artificial Intelligence for the Medical Domain, European\n  Conference on Artificial Intelligence (ECAI) - 2024, Santiago de Compostela,\n  Spain",
      "pdf_url": "http://arxiv.org/pdf/2410.18725v2",
      "published_date": "2024-10-24 13:30:18 UTC",
      "updated_date": "2024-11-28 09:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:05:48.299555"
    },
    {
      "arxiv_id": "2410.18720v1",
      "title": "GeoLoRA: Geometric integration for parameter efficient fine-tuning",
      "title_zh": "GeoLoRA：几何积分用于参数高效微调",
      "authors": [
        "Steffen Schotthöfer",
        "Emanuele Zangrando",
        "Gianluca Ceruti",
        "Francesco Tudisco",
        "Jonas Kusch"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has become a widely used method for\nparameter-efficient fine-tuning of large-scale, pre-trained neural networks.\nHowever, LoRA and its extensions face several challenges, including the need\nfor rank adaptivity, robustness, and computational efficiency during the\nfine-tuning process. We introduce GeoLoRA, a novel approach that addresses\nthese limitations by leveraging dynamical low-rank approximation theory.\nGeoLoRA requires only a single backpropagation pass over the small-rank\nadapters, significantly reducing computational cost as compared to similar\ndynamical low-rank training methods and making it faster than popular baselines\nsuch as AdaLoRA. This allows GeoLoRA to efficiently adapt the allocated\nparameter budget across the model, achieving smaller low-rank adapters compared\nto heuristic methods like AdaLoRA and LoRA, while maintaining critical\nconvergence, descent, and error-bound theoretical guarantees. The resulting\nmethod is not only more efficient but also more robust to varying\nhyperparameter settings. We demonstrate the effectiveness of GeoLoRA on several\nstate-of-the-art benchmarks, showing that it outperforms existing methods in\nboth accuracy and computational efficiency.",
      "tldr_zh": "本研究提出 GeoLoRA，一种基于 dynamical low-rank approximation theory 的参数高效微调方法，旨在解决 Low-Rank Adaptation (LoRA) 及其扩展在 rank adaptivity、robustness 和 computational efficiency 方面的挑战。GeoLoRA 通过仅需单次 backpropagation 过小-rank adapters 来优化训练过程，比 AdaLoRA 和 LoRA 更高效，并能动态适应参数预算，同时保持 convergence, descent 和 error-bound 理论保证。实验结果显示，GeoLoRA 在多个 state-of-the-art 基准测试中，实现了更高的 accuracy 和 computational efficiency。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18720v1",
      "published_date": "2024-10-24 13:26:10 UTC",
      "updated_date": "2024-10-24 13:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:06:00.161780"
    },
    {
      "arxiv_id": "2410.18718v1",
      "title": "LLM-based Online Prediction of Time-varying Graph Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Dayu Qin",
        "Yi Yan",
        "Ercan Engin Kuruoglu"
      ],
      "abstract": "In this paper, we propose a novel framework that leverages large language\nmodels (LLMs) for predicting missing values in time-varying graph signals by\nexploiting spatial and temporal smoothness. We leverage the power of LLM to\nachieve a message-passing scheme. For each missing node, its neighbors and\nprevious estimates are fed into and processed by LLM to infer the missing\nobservations. Tested on the task of the online prediction of wind-speed graph\nsignals, our model outperforms online graph filtering algorithms in terms of\naccuracy, demonstrating the potential of LLMs in effectively addressing\npartially observed signals in graphs.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型(LLMs)的框架，用于在线预测时间变化图信号中的缺失值，通过利用空间和时间平滑性(spatial and temporal smoothness)。框架采用消息传递机制(message-passing scheme)，将每个缺失节点的邻居信息和先前估计输入LLMs进行推断。实验结果显示，在风速图信号预测任务上，该模型的准确性超过了在线图过滤算法，证明了LLMs在处理部分观察图信号方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18718v1",
      "published_date": "2024-10-24 13:22:50 UTC",
      "updated_date": "2024-10-24 13:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:06:12.841802"
    },
    {
      "arxiv_id": "2410.18717v1",
      "title": "Low-Latency Video Anonymization for Crowd Anomaly Detection: Privacy vs. Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Mulugeta Weldezgina Asres",
        "Lei Jiao",
        "Christian Walter Omlin"
      ],
      "abstract": "Recent advancements in artificial intelligence promise ample potential in\nmonitoring applications with surveillance cameras. However, concerns about\nprivacy and model bias have made it challenging to utilize them in public.\nAlthough de-identification approaches have been proposed in the literature,\naiming to achieve a certain level of anonymization, most of them employ deep\nlearning models that are computationally demanding for real-time edge\ndeployment. In this study, we revisit conventional anonymization solutions for\nprivacy protection and real-time video anomaly detection (VAD) applications. We\npropose a novel lightweight adaptive anonymization for VAD (LA3D) that employs\ndynamic adjustment to enhance privacy protection. We evaluated the approaches\non publicly available privacy and VAD data sets to examine the strengths and\nweaknesses of the different anonymization techniques and highlight the\npromising efficacy of our approach. Our experiment demonstrates that LA3D\nenables substantial improvement in the privacy anonymization capability without\nmajorly degrading VAD efficacy.",
      "tldr_zh": "本研究探讨了在视频异常检测（VAD）中实现低延迟视频匿名化的挑战，旨在平衡隐私保护与性能需求。作者提出了一种新型轻量级自适应匿名化方法LA3D，通过动态调整技术来增强隐私保护，同时避免使用计算密集的深度学习模型以支持实时边缘部署。在公开数据集上的实验评估显示，LA3D显著提高了匿名化能力，而VAD的效能未大幅下降，证明了其在监控应用中的潜在价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16pages, 8 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.18717v1",
      "published_date": "2024-10-24 13:22:33 UTC",
      "updated_date": "2024-10-24 13:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:06:24.275745"
    },
    {
      "arxiv_id": "2410.18697v2",
      "title": "How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Zhang",
        "Wei Zhao",
        "Steffen Eger"
      ],
      "abstract": "Recent research has focused on literary machine translation (MT) as a new\nchallenge in MT. However, the evaluation of literary MT remains an open\nproblem. We contribute to this ongoing discussion by introducing\nLITEVAL-CORPUS, a paragraph-level parallel corpus containing verified human\ntranslations and outputs from 9 MT systems, which totals over 2k translations\nand 13k evaluated sentences across four language pairs, costing 4.5k C. This\ncorpus enables us to (i) examine the consistency and adequacy of human\nevaluation schemes with various degrees of complexity, (ii) compare evaluations\nby students and professionals, assess the effectiveness of (iii) LLM-based\nmetrics and (iv) LLMs themselves. Our findings indicate that the adequacy of\nhuman evaluation is controlled by two factors: the complexity of the evaluation\nscheme (more complex is less adequate) and the expertise of evaluators (higher\nexpertise yields more adequate evaluations). For instance, MQM\n(Multidimensional Quality Metrics), a complex scheme and the de facto standard\nfor non-literary human MT evaluation, is largely inadequate for literary\ntranslation evaluation: with student evaluators, nearly 60% of human\ntranslations are misjudged as indistinguishable or inferior to machine\ntranslations. In contrast, BWS (BEST-WORST SCALING), a much simpler scheme,\nidentifies human translations at a rate of 80-100%. Automatic metrics fare\ndramatically worse, with rates of at most 20%. Our overall evaluation indicates\nthat published human translations consistently outperform LLM translations,\nwhere even the most recent LLMs tend to produce considerably more literal and\nless diverse translations compared to humans.",
      "tldr_zh": "本研究构建了LITEVAL-CORPUS数据集，该语料库包含超过2k个人类和机器翻译样本，涵盖4个语言对，用于评估文学机器翻译（MT）的质量。研究比较了不同人类评估方案（如复杂方案MQM和简单方案BWS）、学生与专业评估者的表现，以及LLM-based metrics和LLMs本身的有效性，发现复杂方案易导致误判，而专业评估者更可靠，自动指标准确率不超过20%。总体结果表明，人类翻译在多样性和质量上远优于LLM翻译，后者往往更字面化且缺乏创意。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL Camera-Ready version",
      "pdf_url": "http://arxiv.org/pdf/2410.18697v2",
      "published_date": "2024-10-24 12:48:03 UTC",
      "updated_date": "2025-02-25 10:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:06:37.479508"
    },
    {
      "arxiv_id": "2410.18693v1",
      "title": "Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Ding",
        "Xinyu Shi",
        "Xiaobo Liang",
        "Juntao Li",
        "Qiaoming Zhu",
        "Min Zhang"
      ],
      "abstract": "The availability of high-quality data is one of the most important factors in\nimproving the reasoning capability of LLMs. Existing works have demonstrated\nthe effectiveness of creating more instruction data from seed questions or\nknowledge bases. Recent research indicates that continually scaling up data\nsynthesis from strong models (e.g., GPT-4) can further elicit reasoning\nperformance. Though promising, the open-sourced community still lacks\nhigh-quality data at scale and scalable data synthesis methods with affordable\ncosts. To address this, we introduce ScaleQuest, a scalable and novel data\nsynthesis method that utilizes \"small-size\" (e.g., 7B) open-source models to\ngenerate questions from scratch without the need for seed data with complex\naugmentation constraints. With the efficient ScaleQuest, we automatically\nconstructed a mathematical reasoning dataset consisting of 1 million\nproblem-solution pairs, which are more effective than existing open-sourced\ndatasets. It can universally increase the performance of mainstream open-source\nmodels (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2%\nto 46.4% gains on MATH. Notably, simply fine-tuning the Qwen2-Math-7B-Base\nmodel with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and\nwell-aligned model on closed-source data, and proprietary models such as\nGPT-4-Turbo and Claude-3.5 Sonnet.",
      "tldr_zh": "该研究提出 ScaleQuest，一种可扩展的数据合成方法，使用小型开源模型（如 7B 模型）从零生成问题数据，而无需种子数据或复杂增强，从而解决开源社区缺乏高质量大规模推理数据的问题。利用 ScaleQuest，他们构建了一个包含 1 百万对问题-解决方案的数学推理数据集，该数据集比现有开源数据集更有效。实验结果显示，该数据集能普遍提升主流开源模型（如 Mistral、Llama3、DeepSeekMath 和 Qwen2-Math）的性能，在 MATH 基准上实现 29.2% 到 46.4% 的收益。特别地，仅通过微调 Qwen2-Math-7B-Base 模型，即可超越 Qwen2-Math-7B-Instruct 以及专有模型如 GPT-4-Turbo 和 Claude-3.5 Sonnet。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Project page: https://scalequest.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.18693v1",
      "published_date": "2024-10-24 12:42:04 UTC",
      "updated_date": "2024-10-24 12:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:06:50.560801"
    },
    {
      "arxiv_id": "2410.19025v1",
      "title": "Large Language Models for Financial Aid in Financial Time-series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Md Khairul Islam",
        "Ayush Karmacharya",
        "Timothy Sue",
        "Judy Fox"
      ],
      "abstract": "Considering the difficulty of financial time series forecasting in financial\naid, much of the current research focuses on leveraging big data analytics in\nfinancial services. One modern approach is to utilize \"predictive analysis\",\nanalogous to forecasting financial trends. However, many of these time series\ndata in Financial Aid (FA) pose unique challenges due to limited historical\ndatasets and high dimensional financial information, which hinder the\ndevelopment of effective predictive models that balance accuracy with efficient\nruntime and memory usage. Pre-trained foundation models are employed to address\nthese challenging tasks. We use state-of-the-art time series models including\npre-trained LLMs (GPT-2 as the backbone), transformers, and linear models to\ndemonstrate their ability to outperform traditional approaches, even with\nminimal (\"few-shot\") or no fine-tuning (\"zero-shot\"). Our benchmark study,\nwhich includes financial aid with seven other time series tasks, shows the\npotential of using LLMs for scarce financial datasets.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在金融时间序列预测中的应用，特别是针对金融援助 (Financial Aid) 领域的挑战，如有限历史数据集和高维信息导致的模型准确性和效率问题。作者使用预训练模型（如 GPT-2 作为骨干的 LLMs、transformer 和线性模型）在 few-shot 或 zero-shot 条件下进行预测，证明这些模型能超越传统方法。基准研究涵盖金融援助和七个其他时间序列任务，展示了 LLMs 在处理稀缺金融数据集时的显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "GitHub link https://github.com/UVA-MLSys/Financial-Time-Series",
      "pdf_url": "http://arxiv.org/pdf/2410.19025v1",
      "published_date": "2024-10-24 12:41:47 UTC",
      "updated_date": "2024-10-24 12:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:07:01.668853"
    },
    {
      "arxiv_id": "2410.18678v1",
      "title": "Ali-AUG: Innovative Approaches to Labeled Data Augmentation using One-Step Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Hamza",
        "Aizea Lojo",
        "Adrian Núñez-Marcos",
        "Aitziber Atutxa"
      ],
      "abstract": "This paper introduces Ali-AUG, a novel single-step diffusion model for\nefficient labeled data augmentation in industrial applications. Our method\naddresses the challenge of limited labeled data by generating synthetic,\nlabeled images with precise feature insertion. Ali-AUG utilizes a stable\ndiffusion architecture enhanced with skip connections and LoRA modules to\nefficiently integrate masks and images, ensuring accurate feature placement\nwithout affecting unrelated image content. Experimental validation across\nvarious industrial datasets demonstrates Ali-AUG's superiority in generating\nhigh-quality, defect-enhanced images while maintaining rapid single-step\ninference. By offering precise control over feature insertion and minimizing\nrequired training steps, our technique significantly enhances data augmentation\ncapabilities, providing a powerful tool for improving the performance of deep\nlearning models in scenarios with limited labeled data. Ali-AUG is especially\nuseful for use cases like defective product image generation to train AI-based\nmodels to improve their ability to detect defects in manufacturing processes.\nUsing different data preparation strategies, including Classification Accuracy\nScore (CAS) and Naive Augmentation Score (NAS), we show that Ali-AUG improves\nmodel performance by 31% compared to other augmentation methods and by 45%\ncompared to models without data augmentation. Notably, Ali-AUG reduces training\ntime by 32% and supports both paired and unpaired datasets, enhancing\nflexibility in data preparation.",
      "tldr_zh": "本研究提出 Ali-AUG，一种创新的单步 diffusion model，用于工业应用的标记数据增强，旨在解决标记数据有限的问题，通过精确特征插入生成高质量合成图像。Ali-AUG 采用稳定的扩散架构，结合 skip connections 和 LoRA 模块，确保特征放置准确而不影响无关内容，同时支持快速单步推理和配对/非配对数据集。实验结果显示，该方法在各种工业数据集上提升模型性能 31% 比其他增强方法和 45% 比无增强基准，并减少训练时间 32%，特别适用于缺陷产品图像生成以提高 AI 检测能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18678v1",
      "published_date": "2024-10-24 12:12:46 UTC",
      "updated_date": "2024-10-24 12:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:07:12.281673"
    },
    {
      "arxiv_id": "2410.18670v1",
      "title": "Health Misinformation in Social Networks: A Survey of IT Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Vasiliki Papanikou",
        "Panagiotis Papadakos",
        "Theodora Karamanidou",
        "Thanos G. Stavropoulos",
        "Evaggelia Pitoura",
        "Panayiotis Tsaparas"
      ],
      "abstract": "In this paper, we present a comprehensive survey on the pervasive issue of\nmedical misinformation in social networks from the perspective of information\ntechnology. The survey aims at providing a systematic review of related\nresearch and helping researchers and practitioners navigate through this\nfast-changing field. Specifically, we first present manual and automatic\napproaches for fact-checking. We then explore fake news detection methods,\nusing content, propagation features, or source features, as well as mitigation\napproaches for countering the spread of misinformation. We also provide a\ndetailed list of several datasets on health misinformation and of publicly\navailable tools. We conclude the survey with a discussion on the open\nchallenges and future research directions in the battle against health\nmisinformation.",
      "tldr_zh": "这篇论文对社交网络中医疗虚假信息问题进行了全面调查，从信息技术角度审视相关研究，旨在为研究者和从业者提供系统性指南。论文回顾了手动和自动 fact-checking 方法，以及基于内容、传播特征或来源特征的 fake news detection 技术，并探讨了缓解虚假信息传播的策略。作者还列出了健康虚假信息的多个数据集和公开工具，并讨论了当前挑战和未来研究方向，如改进检测准确性和跨平台协作。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Preprint -- Under review in the ACM Transactions on Computing for\n  Healthcare (HEALTH) journal",
      "pdf_url": "http://arxiv.org/pdf/2410.18670v1",
      "published_date": "2024-10-24 12:00:51 UTC",
      "updated_date": "2024-10-24 12:00:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:07:25.442508"
    },
    {
      "arxiv_id": "2410.18652v7",
      "title": "$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Woosung Koh",
        "Jang Han Yoon",
        "MinHyung Lee",
        "Youngjin Song",
        "Jaegwan Cho",
        "Jaehyun Kang",
        "Taehyeon Kim",
        "Se-Young Yun",
        "Youngjae Yu",
        "Bongshin Lee"
      ],
      "abstract": "Generating high-quality charts with Large Language Models (LLMs) presents\nsignificant challenges due to limited data and the high cost of scaling through\nhuman curation. $\\langle \\text{instruction}, \\text{data}, \\text{code} \\rangle$\ntriplets are scarce and expensive to manually curate as their creation demands\ntechnical expertise. To address this scalability challenge, we introduce a\nreference-free automatic feedback generator, which eliminates the need for\ncostly human intervention. Our novel framework, C$^2$, consists of (1) an\nautomatic feedback provider (ChartAF) and (2) a diverse, reference-free dataset\n(ChartUIE-8K). The results are compelling: in our first experiment, 74% of\nrespondents strongly preferred, and 10% preferred, the results after feedback.\nThe second post-feedback experiment demonstrates that ChartAF outperform nine\nbaselines. Moreover, ChartUIE-8K significantly improves data diversity by\nincreasing queries, datasets, and chart types by 5982%, 1936%, and 91%,\nrespectively, over benchmarks. Finally, a study of LLM users revealed that 94%\nof participants preferred ChartUIE-8K's queries, with 93% deeming them aligned\nwith real-world use cases. Core contributions are available as open-source at\nchartsquared.github.io, with ample qualitative examples.",
      "tldr_zh": "这篇论文提出了C²框架，用于解决Large Language Models (LLMs)生成高质量图表时的数据稀缺和高扩展成本问题。该框架包括自动反馈提供器(ChartAF)和一个多样化的无参考数据集(ChartUIE-8K)，通过参考-free自动反馈机制消除手动干预需求。实验结果显示，ChartAF优于9个基线模型，用户偏好反馈后结果的比例高达84%，而ChartUIE-8K将查询、数据集和图表类型的多样性分别提升5982%、1936%和91%。这些贡献已开源，提供于chartsquared.github.io，以支持真实世界应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NAACL 2025 Main (Long)",
      "pdf_url": "http://arxiv.org/pdf/2410.18652v7",
      "published_date": "2024-10-24 11:32:00 UTC",
      "updated_date": "2025-02-12 12:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:07:37.209854"
    },
    {
      "arxiv_id": "2410.18648v1",
      "title": "GADT: Enhancing Transferable Adversarial Attacks through Gradient-guided Adversarial Data Transformation",
      "title_zh": "GADT: 通过梯度引导的对抗数据变换增强可转移的对抗攻击",
      "authors": [
        "Yating Ma",
        "Xiaogang Xu",
        "Liming Fang",
        "Zhe Liu"
      ],
      "abstract": "Current Transferable Adversarial Examples (TAE) are primarily generated by\nadding Adversarial Noise (AN). Recent studies emphasize the importance of\noptimizing Data Augmentation (DA) parameters along with AN, which poses a\ngreater threat to real-world AI applications. However, existing DA-based\nstrategies often struggle to find optimal solutions due to the challenging DA\nsearch procedure without proper guidance. In this work, we propose a novel\nDA-based attack algorithm, GADT. GADT identifies suitable DA parameters through\niterative antagonism and uses posterior estimates to update AN based on these\nparameters. We uniquely employ a differentiable DA operation library to\nidentify adversarial DA parameters and introduce a new loss function as a\nmetric during DA optimization. This loss term enhances adversarial effects\nwhile preserving the original image content, maintaining attack crypticity.\nExtensive experiments on public datasets with various networks demonstrate that\nGADT can be integrated with existing transferable attack methods, updating\ntheir DA parameters effectively while retaining their AN formulation\nstrategies. Furthermore, GADT can be utilized in other black-box attack\nscenarios, e.g., query-based attacks, offering a new avenue to enhance attacks\non real-world AI applications in both research and industrial contexts.",
      "tldr_zh": "本研究针对现有可转移对抗攻击（Transferable Adversarial Attacks）方法依赖对抗噪声（Adversarial Noise, AN）且数据增强（Data Augmentation, DA）参数优化困难的问题，提出了一种新型算法GADT，通过梯度引导的对抗数据转换来提升攻击效果。GADT采用迭代对抗机制识别合适的DA参数，并利用后验估计更新AN，同时引入一个新损失函数，以增强对抗性能的同时保留图像内容并保持攻击隐秘性。实验结果显示，GADT可与现有攻击方法无缝整合，在公共数据集和各种网络上显著提升攻击转移性，并扩展适用于黑盒攻击场景，如基于查询的攻击。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18648v1",
      "published_date": "2024-10-24 11:21:49 UTC",
      "updated_date": "2024-10-24 11:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:07:48.991861"
    },
    {
      "arxiv_id": "2410.18641v1",
      "title": "Smart ETL and LLM-based contents classification: the European Smart Tourism Tools Observatory experience",
      "title_zh": "智能ETL和基于LLM的内容分类：欧洲智能旅游工具观测站的经验",
      "authors": [
        "Diogo Cosme",
        "António Galvão",
        "Fernando Brito e Abreu"
      ],
      "abstract": "Purpose: Our research project focuses on improving the content update of the\nonline European Smart Tourism Tools (STTs) Observatory by incorporating and\ncategorizing STTs. The categorization is based on their taxonomy, and it\nfacilitates the end user's search process. The use of a Smart ETL (Extract,\nTransform, and Load) process, where \\emph{Smart} indicates the use of\nArtificial Intelligence (AI), is central to this endeavor.\n  Methods: The contents describing STTs are derived from PDF catalogs, where\nPDF-scraping techniques extract QR codes, images, links, and text information.\nDuplicate STTs between the catalogs are removed, and the remaining ones are\nclassified based on their text information using Large Language Models (LLMs).\nFinally, the data is transformed to comply with the Dublin Core metadata\nstructure (the observatory's metadata structure), chosen for its wide\nacceptance and flexibility.\n  Results: The Smart ETL process to import STTs to the observatory combines\nPDF-scraping techniques with LLMs for text content-based classification. Our\npreliminary results have demonstrated the potential of LLMs for text\ncontent-based classification.\n  Conclusion: The proposed approach's feasibility is a step towards efficient\ncontent-based classification, not only in Smart Tourism but also adaptable to\nother fields. Future work will mainly focus on refining this classification\nprocess.",
      "tldr_zh": "本文研究旨在通过Smart ETL和LLM-based内容分类改进欧洲智能旅游工具(STTs)在线观察站的内容更新和分类过程，从而提升用户搜索效率。方法包括使用PDF-scraping技术从PDF目录提取QR码、图像、链接和文本信息，去除重复内容，并借助Large Language Models (LLMs)进行文本分类，最后将数据转换为Dublin Core元数据结构。初步结果证明了LLMs在文本内容分类中的潜力，该方法不仅适用于智能旅游领域，还可扩展到其他领域，未来将重点优化分类过程。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3; I.2.7; I.5.2"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18641v1",
      "published_date": "2024-10-24 11:10:54 UTC",
      "updated_date": "2024-10-24 11:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:08:01.661894"
    },
    {
      "arxiv_id": "2410.18639v4",
      "title": "Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Models",
      "title_zh": "扩散归因分数：评估扩散模型中训练数据的影响",
      "authors": [
        "Jinxu Lin",
        "Linwei Tao",
        "Minjing Dong",
        "Chang Xu"
      ],
      "abstract": "As diffusion models become increasingly popular, the misuse of copyrighted\nand private images has emerged as a major concern. One promising solution to\nmitigate this issue is identifying the contribution of specific training\nsamples in generative models, a process known as data attribution. Existing\ndata attribution methods for diffusion models typically quantify the\ncontribution of a training sample by evaluating the change in diffusion loss\nwhen the sample is included or excluded from the training process. However, we\nargue that the direct usage of diffusion loss cannot represent such a\ncontribution accurately due to the calculation of diffusion loss. Specifically,\nthese approaches measure the divergence between predicted and ground truth\ndistributions, which leads to an indirect comparison between the predicted\ndistributions and cannot represent the variances between model behaviors. To\naddress these issues, we aim to measure the direct comparison between predicted\ndistributions with an attribution score to analyse the training sample\nimportance, which is achieved by Diffusion Attribution Score (\\textit{DAS}).\nUnderpinned by rigorous theoretical analysis, we elucidate the effectiveness of\nDAS. Additionally, we explore strategies to accelerate DAS calculations,\nfacilitating its application to large-scale diffusion models. Our extensive\nexperiments across various datasets and diffusion models demonstrate that DAS\nsignificantly surpasses previous benchmarks in terms of the linear\ndata-modelling score, establishing new state-of-the-art performance. Code is\navailable at \\hyperlink{here}{https://github.com/Jinxu-Lin/DAS}.",
      "tldr_zh": "该论文针对扩散模型中训练数据的滥用问题（如版权和隐私图像），提出了一种新方法 Diffusion Attribution Score (DAS)，通过直接比较预测分布来准确评估训练样本的重要性，而不是依赖传统的扩散损失计算。DAS 的设计基于严格的理论分析，并包括加速计算策略，以适用于大规模模型。实验结果显示，在多个数据集和扩散模型上，DAS 在线性数据建模分数上比现有基准提高了性能，达到了新的最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18639v4",
      "published_date": "2024-10-24 10:58:17 UTC",
      "updated_date": "2025-03-21 05:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:08:12.451414"
    },
    {
      "arxiv_id": "2410.18636v2",
      "title": "Multi-agent cooperation through learning-aware policy gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Meulemans",
        "Seijin Kobayashi",
        "Johannes von Oswald",
        "Nino Scherrer",
        "Eric Elmoznino",
        "Blake Richards",
        "Guillaume Lajoie",
        "Blaise Agüera y Arcas",
        "João Sacramento"
      ],
      "abstract": "Self-interested individuals often fail to cooperate, posing a fundamental\nchallenge for multi-agent learning. How can we achieve cooperation among\nself-interested, independent learning agents? Promising recent work has shown\nthat in certain tasks cooperation can be established between learning-aware\nagents who model the learning dynamics of each other. Here, we present the\nfirst unbiased, higher-derivative-free policy gradient algorithm for\nlearning-aware reinforcement learning, which takes into account that other\nagents are themselves learning through trial and error based on multiple noisy\ntrials. We then leverage efficient sequence models to condition behavior on\nlong observation histories that contain traces of the learning dynamics of\nother agents. Training long-context policies with our algorithm leads to\ncooperative behavior and high returns on standard social dilemmas, including a\nchallenging environment where temporally-extended action coordination is\nrequired. Finally, we derive from the iterated prisoner's dilemma a novel\nexplanation for how and when cooperation arises among self-interested\nlearning-aware agents.",
      "tldr_zh": "这篇论文解决了自私智能体在多智能体学习中的合作难题，提出了一种无偏、更高阶导数自由的 policy gradients 算法，用于 learning-aware reinforcement learning，该算法考虑其他代理通过多次嘈杂试验的学习动态。研究利用高效的 sequence models 来基于包含其他代理学习历史的长期观察调节行为，导致在标准 social dilemmas 中实现合作行为和高回报，包括需要时间扩展行动协调的挑战环境。最后，论文从 iterated prisoner's dilemma 推导出一个新解释，阐述自私 learning-aware 代理何时及如何产生合作。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18636v2",
      "published_date": "2024-10-24 10:48:42 UTC",
      "updated_date": "2025-03-19 13:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:08:24.784530"
    },
    {
      "arxiv_id": "2410.18634v2",
      "title": "Little Giants: Synthesizing High-Quality Embedding Data at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Haonan Chen",
        "Liang Wang",
        "Nan Yang",
        "Yutao Zhu",
        "Ziliang Zhao",
        "Furu Wei",
        "Zhicheng Dou"
      ],
      "abstract": "Synthetic data generation has become an increasingly popular way of training\nmodels without the need for large, manually labeled datasets. For tasks like\ntext embedding, synthetic data offers diverse and scalable training examples,\nsignificantly reducing the cost of human annotation. However, most current\napproaches rely heavily on proprietary models like GPT-4, which are expensive\nand inefficient for generating large-scale embedding data. In this paper, we\nintroduce SPEED, a framework that aligns open-source small models (8B) to\nefficiently generate large-scale synthetic embedding data. Through supervised\nfine-tuning, preference optimization, and self-improvement, SPEED enables small\nopen-source models to produce high-quality data. Remarkably, SPEED uses only\nless than 1/10 of the GPT API calls, outperforming the state-of-the-art\nembedding model E5_mistral when both are trained solely on their synthetic\ndata. Using this efficient generator, we conduct a comprehensive study on how\nvarious factors within the alignment pipeline impact data quality and reveal\nthe scaling law for synthetic embedding data.",
      "tldr_zh": "本论文提出 Little Giants 中的 SPEED 框架，利用开源小模型（8B）高效合成大规模高质量嵌入数据（embedding data），以替代依赖昂贵专有模型如 GPT-4 的传统方法。通过 supervised fine-tuning、preference optimization 和 self-improvement 等技术，SPEED 使小模型能够生成高品质数据，仅使用不到 1/10 的 GPT API 调用即超越了状态-of-the-art 模型 E5_mistral。研究还系统分析了 alignment 管道中的各种因素对数据质量的影响，并揭示了 synthetic embedding data 的 scaling law，为大规模文本嵌入训练提供高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18634v2",
      "published_date": "2024-10-24 10:47:30 UTC",
      "updated_date": "2024-11-03 08:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:08:37.792337"
    },
    {
      "arxiv_id": "2410.18628v1",
      "title": "Wavetable Synthesis Using CVAE for Timbre Control Based on Semantic Label",
      "title_zh": "翻译失败",
      "authors": [
        "Tsugumasa Yutani",
        "Yuya Yamamoto",
        "Shuyo Nakatani",
        "Hiroko Terasawa"
      ],
      "abstract": "Synthesizers are essential in modern music production. However, their complex\ntimbre parameters, often filled with technical terms, require expertise. This\nresearch introduces a method of timbre control in wavetable synthesis that is\nintuitive and sensible and utilizes semantic labels. Using a conditional\nvariational autoencoder (CVAE), users can select a wavetable and define the\ntimbre with labels such as bright, warm, and rich. The CVAE model, featuring\nconvolutional and upsampling layers, effectively captures the wavetable\nnuances, ensuring real-time performance owing to their processing in the time\ndomain. Experiments demonstrate that this approach allows for real-time,\neffective control of the timbre of the wavetable using semantic inputs and aims\nfor intuitive timbre control through data-based semantic control.",
      "tldr_zh": "这篇论文提出了一种基于语义标签的波表合成音色控制方法，使用条件变分自编码器 (CVAE) 来简化合成器操作，避免了复杂的专业参数。CVAE 模型通过卷积和上采样层在时域处理波表数据，允许用户以直观的标签（如 bright、warm 和 rich）选择和定义音色，实现实时性能。实验结果显示，该方法能有效控制波表音色，并通过数据驱动的语义输入提升了用户体验。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 4 figures, Accepted at APSIPA ASC 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18628v1",
      "published_date": "2024-10-24 10:37:54 UTC",
      "updated_date": "2024-10-24 10:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:08:48.024836"
    },
    {
      "arxiv_id": "2410.18626v2",
      "title": "SAMG: Offline-to-Online Reinforcement Learning via State-Action-Conditional Offline Model Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Liyu Zhang",
        "Haochi Wu",
        "Xu Wan",
        "Quan Kong",
        "Ruilong Deng",
        "Mingyang Sun"
      ],
      "abstract": "Offline-to-online (O2O) reinforcement learning (RL) pre-trains models on\noffline data and refines policies through online fine-tuning. However, existing\nO2O RL algorithms typically require maintaining the tedious offline datasets to\nmitigate the effects of out-of-distribution (OOD) data, which significantly\nlimits their efficiency in exploiting online samples. To address this\ndeficiency, we introduce a new paradigm for O2O RL called\nState-Action-Conditional Offline \\Model Guidance (SAMG). It freezes the\npre-trained offline critic to provide compact offline understanding for each\nstate-action sample, thus eliminating the need for retraining on offline data.\nThe frozen offline critic is incorporated with the online target critic\nweighted by a state-action-adaptive coefficient. This coefficient aims to\ncapture the offline degree of samples at the state-action level, and is updated\nadaptively during training. In practice, SAMG could be easily integrated with\nQ-function-based algorithms. Theoretical analysis shows good optimality and\nlower estimation error. Empirically, SAMG outperforms state-of-the-art O2O RL\nalgorithms on the D4RL benchmark.",
      "tldr_zh": "该研究针对 Offline-to-Online (O2O) Reinforcement Learning (RL) 的问题，提出了一种新范式 SAMG (State-Action-Conditional Offline Model Guidance)，通过冻结预训练的离线 critic 来提供状态-动作样本的紧凑理解，从而避免了维护离线数据集的低效性。SAMG 将冻结的离线 critic 与在线目标 critic 结合，使用状态-动作自适应系数进行加权，该系数在训练过程中动态更新，以更好地处理 Out-of-Distribution (OOD) 数据。理论分析显示 SAMG 具有良好的最优性和较低估计错误，在 D4RL 基准测试中，它超过了现有最先进 O2O RL 算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18626v2",
      "published_date": "2024-10-24 10:35:02 UTC",
      "updated_date": "2025-02-21 11:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:09:01.187256"
    },
    {
      "arxiv_id": "2410.18624v1",
      "title": "Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "David Thulke",
        "Yingbo Gao",
        "Rricha Jalota",
        "Christian Dugast",
        "Hermann Ney"
      ],
      "abstract": "This paper explores the rapid development of a telephone call summarization\nsystem utilizing large language models (LLMs). Our approach involves initial\nexperiments with prompting existing LLMs to generate summaries of telephone\nconversations, followed by the creation of a tailored synthetic training\ndataset utilizing stronger frontier models. We place special focus on the\ndiversity of the generated data and on the ability to control the length of the\ngenerated summaries to meet various use-case specific requirements. The\neffectiveness of our method is evaluated using two state-of-the-art\nLLM-as-a-judge-based evaluation techniques to ensure the quality and relevance\nof the summaries. Our results show that fine-tuned Llama-2-7B-based\nsummarization model performs on-par with GPT-4 in terms of factual accuracy,\ncompleteness and conciseness. Our findings demonstrate the potential for\nquickly bootstrapping a practical and efficient call summarization system.",
      "tldr_zh": "这篇论文探讨了使用提示 (Prompting) 和微调 (Fine-Tuning) 小规模大型语言模型 (LLMs) 来开发可控长度的电话通话摘要系统。研究方法包括先通过提示现有 LLMs 生成摘要，然后创建定制的合成训练数据集，利用更强的前沿模型来确保数据多样性和摘要长度控制。评估采用两种先进的 LLM-as-a-judge 技术，结果显示微调后的 Llama-2-7B 模型在事实准确性、完整性和简洁性方面与 GPT-4 相当。该方法证明了快速构建实用高效的通话摘要系统的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the The International Conference on Foundation and Large\n  Language Models (FLLM2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.18624v1",
      "published_date": "2024-10-24 10:32:10 UTC",
      "updated_date": "2024-10-24 10:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:09:13.514699"
    },
    {
      "arxiv_id": "2410.18615v1",
      "title": "FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation",
      "title_zh": "FairQueue: 重新审视提示学习用于公平的文本到图像生成",
      "authors": [
        "Christopher T. H Teo",
        "Milad Abdollahzadeh",
        "Xinda Ma",
        "Ngai-man Cheung"
      ],
      "abstract": "Recently, prompt learning has emerged as the state-of-the-art (SOTA) for fair\ntext-to-image (T2I) generation. Specifically, this approach leverages readily\navailable reference images to learn inclusive prompts for each target Sensitive\nAttribute (tSA), allowing for fair image generation. In this work, we first\nreveal that this prompt learning-based approach results in degraded sample\nquality. Our analysis shows that the approach's training objective -- which\naims to align the embedding differences of learned prompts and reference images\n-- could be sub-optimal, resulting in distortion of the learned prompts and\ndegraded generated images. To further substantiate this claim, as our major\ncontribution, we deep dive into the denoising subnetwork of the T2I model to\ntrack down the effect of these learned prompts by analyzing the cross-attention\nmaps. In our analysis, we propose a novel prompt switching analysis: I2H and\nH2I. Furthermore, we propose new quantitative characterization of\ncross-attention maps. Our analysis reveals abnormalities in the early denoising\nsteps, perpetuating improper global structure that results in degradation in\nthe generated samples. Building on insights from our analysis, we propose two\nideas: (i) Prompt Queuing and (ii) Attention Amplification to address the\nquality issue. Extensive experimental results on a wide range of tSAs show that\nour proposed method outperforms SOTA approach's image generation quality, while\nachieving competitive fairness. More resources at FairQueue Project site:\nhttps://sutd-visual-computing-group.github.io/FairQueue",
      "tldr_zh": "本研究重新审视了提示学习在公平文本到图像（T2I）生成中的应用，发现现有基于参考图像的方法虽能提升公平性，但会导致生成样本质量下降，因为其训练目标可能次优，造成提示扭曲和交叉注意力图（cross-attention maps）异常。作者通过提出I2H和H2I提示切换分析以及新型量化表征，深入分析T2I模型的去噪子网络，揭示了早期去噪步骤中的全局结构问题。基于这些洞见，他们引入FairQueue框架，包括Prompt Queuing和Attention Amplification机制，在多种目标敏感属性（tSAs）上实验证明，该方法显著提高了图像生成质量，同时保持与SOTA方法相当的公平性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in NeurIPS24",
      "pdf_url": "http://arxiv.org/pdf/2410.18615v1",
      "published_date": "2024-10-24 10:16:09 UTC",
      "updated_date": "2024-10-24 10:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:09:25.811900"
    },
    {
      "arxiv_id": "2410.18612v1",
      "title": "TripCast: Pre-training of Masked 2D Transformers for Trip Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhua Liao",
        "Zetian Wang",
        "Peng Wei",
        "Qiangqiang Nie",
        "Zhenhua Zhang"
      ],
      "abstract": "Deep learning and pre-trained models have shown great success in time series\nforecasting. However, in the tourism industry, time series data often exhibit a\nleading time property, presenting a 2D structure. This introduces unique\nchallenges for forecasting in this sector. In this study, we propose a novel\nmodelling paradigm, TripCast, which treats trip time series as 2D data and\nlearns representations through masking and reconstruction processes.\nPre-trained on large-scale real-world data, TripCast notably outperforms other\nstate-of-the-art baselines in in-domain forecasting scenarios and demonstrates\nstrong scalability and transferability in out-domain forecasting scenarios.",
      "tldr_zh": "本研究提出TripCast，一种针对旅游业行程时间序列的预训练模型，将数据视为2D结构，使用Masked 2D Transformers通过掩码和重建过程学习表示，以应对时间序列预测的独特挑战。TripCast在大型真实数据上预训练后，在领域内预测场景中显著优于现有基准模型。实验结果还显示，该模型在领域外预测中表现出强大的可扩展性和可转移性，为旅游行业的时间序列预测提供了新范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICONIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18612v1",
      "published_date": "2024-10-24 10:08:05 UTC",
      "updated_date": "2024-10-24 10:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:10:44.593594"
    },
    {
      "arxiv_id": "2410.18607v1",
      "title": "STTATTS: Unified Speech-To-Text And Text-To-Speech Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hawau Olamide Toyin",
        "Hao Li",
        "Hanan Aldarmaki"
      ],
      "abstract": "Speech recognition and speech synthesis models are typically trained\nseparately, each with its own set of learning objectives, training data, and\nmodel parameters, resulting in two distinct large networks. We propose a\nparameter-efficient approach to learning ASR and TTS jointly via a multi-task\nlearning objective and shared parameters. Our evaluation demonstrates that the\nperformance of our multi-task model is comparable to that of individually\ntrained models while significantly saving computational and memory costs\n($\\sim$50\\% reduction in the total number of parameters required for the two\ntasks combined). We experiment with English as a resource-rich language, and\nArabic as a relatively low-resource language due to shortage of TTS data. Our\nmodels are trained with publicly available data, and both the training code and\nmodel checkpoints are openly available for further research.",
      "tldr_zh": "本论文提出 STTATTS，一种统一训练 Speech-To-Text (ASR) 和 Text-To-Speech (TTS) 的参数高效模型，通过 multi-task learning 目标和 shared parameters 实现联合学习，解决了传统分开训练的局限性。实验结果表明，该模型的性能与独立训练模型相当，但总参数量减少约 50%，显著降低计算和内存成本。研究在英语（资源丰富语言）和阿拉伯语（低资源语言）上进行验证，并开源了训练代码和模型检查点，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 Figures, EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.18607v1",
      "published_date": "2024-10-24 10:04:24 UTC",
      "updated_date": "2024-10-24 10:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:09:50.297797"
    },
    {
      "arxiv_id": "2410.18603v1",
      "title": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant",
      "title_zh": "AgentStore：异构代理的可扩展集成，作为专业化通才计算机助手",
      "authors": [
        "Chengyou Jia",
        "Minnan Luo",
        "Zhuohang Dang",
        "Qiushi Sun",
        "Fangzhi Xu",
        "Junlin Hu",
        "Tianbao Xie",
        "Zhiyong Wu"
      ],
      "abstract": "Digital agents capable of automating complex computer tasks have attracted\nconsiderable attention due to their immense potential to enhance human-computer\ninteraction. However, existing agent methods exhibit deficiencies in their\ngeneralization and specialization capabilities, especially in handling\nopen-ended computer tasks in real-world environments. Inspired by the rich\nfunctionality of the App store, we present AgentStore, a scalable platform\ndesigned to dynamically integrate heterogeneous agents for automating computer\ntasks. AgentStore empowers users to integrate third-party agents, allowing the\nsystem to continuously enrich its capabilities and adapt to rapidly evolving\noperating systems. Additionally, we propose a novel core \\textbf{MetaAgent}\nwith the \\textbf{AgentToken} strategy to efficiently manage diverse agents and\nutilize their specialized and generalist abilities for both domain-specific and\nsystem-wide tasks. Extensive experiments on three challenging benchmarks\ndemonstrate that AgentStore surpasses the limitations of previous systems with\nnarrow capabilities, particularly achieving a significant improvement from\n11.21\\% to 23.85\\% on the OSWorld benchmark, more than doubling the previous\nresults. Comprehensive quantitative and qualitative results further demonstrate\nAgentStore's ability to enhance agent systems in both generalization and\nspecialization, underscoring its potential for developing the specialized\ngeneralist computer assistant. All our codes will be made publicly available in\nhttps://chengyou-jia.github.io/AgentStore-Home.",
      "tldr_zh": "该研究提出AgentStore，一种可扩展平台，受App Store启发，用于动态整合异构代理（heterogeneous agents），以自动化复杂计算机任务并提升系统在泛化和专业化方面的能力。核心组件包括MetaAgent和AgentToken策略，该策略能高效管理多样代理，利用它们的专长处理特定领域任务，同时支持系统级任务。实验在三个挑战性基准上显示，AgentStore显著超越先前系统，尤其在OSWorld基准上将性能从11.21%提升至23.85%，几乎翻倍，展示了其作为专业化泛化计算机助手的潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18603v1",
      "published_date": "2024-10-24 09:58:40 UTC",
      "updated_date": "2024-10-24 09:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:10:00.995626"
    },
    {
      "arxiv_id": "2410.18585v1",
      "title": "Aligning CodeLLMs with Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Miao",
        "Bofei Gao",
        "Shanghaoran Quan",
        "Junyang Lin",
        "Daoguang Zan",
        "Jiaheng Liu",
        "Jian Yang",
        "Tianyu Liu",
        "Zhijie Deng"
      ],
      "abstract": "The last year has witnessed the rapid progress of large language models\n(LLMs) across diverse domains. Among them, CodeLLMs have garnered particular\nattention because they can not only assist in completing various programming\ntasks but also represent the decision-making and logical reasoning capabilities\nof LLMs. However, current CodeLLMs mainly focus on pre-training and supervised\nfine-tuning scenarios, leaving the alignment stage, which is important for\npost-training LLMs, under-explored. This work first identifies that the\ncommonly used PPO algorithm may be suboptimal for the alignment of CodeLLM\nbecause the involved reward rules are routinely coarse-grained and potentially\nflawed. We then advocate addressing this using the DPO algorithm. Based on only\npreference data pairs, DPO can render the model rank data automatically, giving\nrise to a fine-grained rewarding pattern more robust than human intervention.\nWe also contribute a pipeline for collecting preference pairs for DPO on\nCodeLLMs. Studies show that our method significantly improves the performance\nof existing CodeLLMs on benchmarks such as MBPP and HumanEval.",
      "tldr_zh": "本研究发现，现有的 CodeLLMs 主要聚焦于预训练和监督微调，而对齐阶段（如使用 PPO 算法）存在问题，因为其奖励规则过于粗糙且可能有缺陷。作者提出采用 DPO（Direct Preference Optimization）算法，通过基于偏好数据对的自动排名机制，提供更细粒度的奖励模式，并贡献了一个收集偏好数据对的管道。该方法显著提升了 CodeLLMs 在 MBPP 和 HumanEval 等基准上的性能，展示了其在编程任务和逻辑推理方面的改进。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18585v1",
      "published_date": "2024-10-24 09:36:13 UTC",
      "updated_date": "2024-10-24 09:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:10:56.189862"
    },
    {
      "arxiv_id": "2410.19874v2",
      "title": "Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Sukanya Randhawa",
        "Eren Aygun",
        "Guntaj Randhawa",
        "Benjamin Herfort",
        "Sven Lautenbach",
        "Alexander Zipf"
      ],
      "abstract": "We have released an open dataset with global coverage on road surface\ncharacteristics (paved or unpaved) derived utilising 105 million images from\nthe world's largest crowdsourcing-based street view platform, Mapillary,\nleveraging state-of-the-art geospatial AI methods. We propose a hybrid deep\nlearning approach which combines SWIN-Transformer based road surface prediction\nand CLIP-and-DL segmentation based thresholding for filtering of bad quality\nimages. The road surface prediction results have been matched and integrated\nwith OpenStreetMap (OSM) road geometries. This study provides global data\ninsights derived from maps and statistics about spatial distribution of\nMapillary coverage and road pavedness on a continent and countries scale, with\nrural and urban distinction. This dataset expands the availability of global\nroad surface information by over 3 million kilometers, now representing\napproximately 36% of the total length of the global road network. Most regions\nshowed moderate to high paved road coverage (60-80%), but significant gaps were\nnoted in specific areas of Africa and Asia. Urban areas tend to have\nnear-complete paved coverage, while rural regions display more variability.\nModel validation against OSM surface data achieved strong performance, with F1\nscores for paved roads between 91-97% across continents. Taking forward the\nwork of Mapillary and their contributors and enrichment of OSM road attributes,\nour work provides valuable insights for applications in urban planning,\ndisaster routing, logistics optimisation and addresses various Sustainable\nDevelopment Goals (SDGS): especially SDGs 1 (No poverty), 3 (Good health and\nwell-being), 8 (Decent work and economic growth), 9 (Industry, Innovation and\nInfrastructure), 11 (Sustainable cities and communities), 12 (Responsible\nconsumption and production), and 13 (Climate action).",
      "tldr_zh": "本研究发布了一个全球覆盖的开放道路表面数据集（paved or unpaved），基于 Mapillary 的 1.05 亿街景图像，通过混合深度学习方法（结合 SWIN-Transformer 预测和 CLIP-and-DL 分割过滤）进行衍生，并与 OpenStreetMap (OSM) 道路几何数据整合。数据集扩展了全球道路网络信息超过 300 万公里，覆盖约 36% 的总长度，显示出城市地区铺装覆盖率近乎完整，而农村地区存在显著变异，且非洲和亚洲部分区域有明显差距。验证结果显示，铺装道路的 F1 scores 在各大陆达到 91-97%，为城市规划、灾害路由和物流优化等应用提供洞见，并支持多个 Sustainable Development Goals (SDGs)，如消除贫困和可持续城市发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19874v2",
      "published_date": "2024-10-24 09:32:53 UTC",
      "updated_date": "2024-10-29 10:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:11:08.124274"
    },
    {
      "arxiv_id": "2410.18574v1",
      "title": "SIKeD: Self-guided Iterative Knowledge Distillation for mathematical reasoning",
      "title_zh": "SIKeD：自我引导迭代知识蒸馏用于数学推理",
      "authors": [
        "Shivam Adarsh",
        "Kumar Shridhar",
        "Caglar Gulcehre",
        "Nicholas Monath",
        "Mrinmaya Sachan"
      ],
      "abstract": "Large Language Models (LLMs) can transfer their reasoning skills to smaller\nmodels by teaching them to generate the intermediate reasoning process required\nto solve multistep reasoning tasks. While LLMs can accurately solve reasoning\ntasks through a variety of strategies, even without fine-tuning, smaller models\nare not expressive enough to fit the LLMs distribution on all strategies when\ndistilled and tend to prioritize one strategy over the others. This reliance on\none strategy poses a challenge for smaller models when attempting to solve\nreasoning tasks that may be difficult with their preferred strategy. To address\nthis, we propose a distillation method SIKeD (Self-guided Iterative Knowledge\nDistillation for mathematical reasoning), where the LLM teaches the smaller\nmodel to approach a task using different strategies and the smaller model uses\nits self-generated on-policy outputs to choose the most suitable strategy for\nthe given task. The training continues in a self-guided iterative manner, where\nfor each training iteration, a decision is made on how to combine the LLM data\nwith the self-generated outputs. Unlike traditional distillation methods, SIKeD\nallows the smaller model to learn which strategy is suitable for a given task\nwhile continuously learning to solve a task using different strategies. Our\nexperiments on various mathematical reasoning datasets show that SIKeD\nsignificantly outperforms traditional distillation techniques across smaller\nmodels of different sizes. Our code is available at:\nhttps://github.com/kumar-shridhar/SIKeD",
      "tldr_zh": "本研究提出 SIKeD（Self-guided Iterative Knowledge Distillation），一种自导迭代知识蒸馏方法，用于提升大语言模型（LLMs）向更小模型转移数学推理技能的问题。SIKeD 让 LLMs 教导更小模型使用多种策略，同时更小模型通过自身生成的输出选择最适合任务的策略，并以迭代方式结合 LLM 数据进行训练。与传统蒸馏技术相比，这一方法使更小模型能够灵活适应不同策略，并在各种数学推理数据集上显著提升性能。实验结果显示，SIKeD 在不同大小的更小模型上表现出色，代码已在 GitHub 上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18574v1",
      "published_date": "2024-10-24 09:29:18 UTC",
      "updated_date": "2024-10-24 09:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:11:21.202927"
    },
    {
      "arxiv_id": "2410.18572v1",
      "title": "Taipan: Efficient and Expressive State Space Language Models with Selective Attention",
      "title_zh": "Taipan：高效且富有表现力的状态空间语言模型，带有选择性注意力",
      "authors": [
        "Chien Van Nguyen",
        "Huy Huu Nguyen",
        "Thang M. Pham",
        "Ruiyi Zhang",
        "Hanieh Deilamsalehy",
        "Puneet Mathur",
        "Ryan A. Rossi",
        "Trung Bui",
        "Viet Dac Lai",
        "Franck Dernoncourt",
        "Thien Huu Nguyen"
      ],
      "abstract": "Efficient long-context language modeling remains a significant challenge in\nNatural Language Processing (NLP). While Transformers dominate language tasks,\nthey struggle with long sequences due to quadratic computational complexity in\ntraining and linearly scaling memory costs during inference. Recent State Space\nModels (SSMs) such as Mamba offer alternatives with constant memory usage, but\nthey underperform in tasks requiring extensive in-context retrieval. We\nintroduce Taipan, a novel hybrid architecture that combines Mamba-2 with\nSelective Attention Layers (SALs). These SALs identify tokens requiring\nlong-range interactions, remove less important features, and then augment their\nrepresentations using the attention module. This approach balances Mamba's\nefficiency with Transformer-like performance in memory-intensive tasks. By\nconstraining the attention budget, Taipan extends accurate predictions to\ncontext lengths of up to 1 million tokens while preserving computational\nefficiency. Our experiments demonstrate Taipan's superior performance across\nvarious scales and tasks, offering a promising solution for efficient\nlong-context language modeling.",
      "tldr_zh": "本文提出 Taipan，一种高效且富有表现力的 State Space Models (SSMs) 语言模型架构，将 Mamba-2 与 Selective Attention Layers (SALs) 结合，以解决 Transformers 在长序列处理中存在的二次计算复杂性和线性内存成本问题。Taipan 通过 SALs 识别需要长距离交互的标记、移除不重要特征并增强表示，从而平衡了 SSMs 的常量内存效率与 Transformers 的上下文检索能力。实验结果表明，Taipan 在各种规模和任务上表现出色，支持高达 1 百万标记的上下文长度，并为高效长上下文语言建模提供了可行解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18572v1",
      "published_date": "2024-10-24 09:25:37 UTC",
      "updated_date": "2024-10-24 09:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:11:33.144158"
    },
    {
      "arxiv_id": "2410.18570v1",
      "title": "Zero-shot Object Navigation with Vision-Language Models Reasoning",
      "title_zh": "基于视觉语言模型推理的零样本物体导航",
      "authors": [
        "Congcong Wen",
        "Yisiyuan Huang",
        "Hao Huang",
        "Yanjia Huang",
        "Shuaihang Yuan",
        "Yu Hao",
        "Hui Lin",
        "Yu-Shen Liu",
        "Yi Fang"
      ],
      "abstract": "Object navigation is crucial for robots, but traditional methods require\nsubstantial training data and cannot be generalized to unknown environments.\nZero-shot object navigation (ZSON) aims to address this challenge, allowing\nrobots to interact with unknown objects without specific training data.\nLanguage-driven zero-shot object navigation (L-ZSON) is an extension of ZSON\nthat incorporates natural language instructions to guide robot navigation and\ninteraction with objects. In this paper, we propose a novel Vision Language\nmodel with a Tree-of-thought Network (VLTNet) for L-ZSON. VLTNet comprises four\nmain modules: vision language model understanding, semantic mapping,\ntree-of-thought reasoning and exploration, and goal identification. Among these\nmodules, Tree-of-Thought (ToT) reasoning and exploration module serves as a\ncore component, innovatively using the ToT reasoning framework for navigation\nfrontier selection during robot exploration. Compared to conventional frontier\nselection without reasoning, navigation using ToT reasoning involves multi-path\nreasoning processes and backtracking when necessary, enabling globally informed\ndecision-making with higher accuracy. Experimental results on PASTURE and\nRoboTHOR benchmarks demonstrate the outstanding performance of our model in\nLZSON, particularly in scenarios involving complex natural language as target\ninstructions.",
      "tldr_zh": "本论文提出了一种基于视觉语言模型的零-shot Object Navigation方法，旨在让机器人无需特定训练数据即可在未知环境中导航并与物体互动，特别是通过自然语言指令的语言驱动零-shot Object Navigation (L-ZSON)来提升任务执行。核心创新是Vision Language model with a Tree-of-Thought Network (VLTNet)，该模型包括视觉语言理解、语义映射、Tree-of-Thought (ToT) 推理和探索以及目标识别模块，其中ToT推理模块通过多路径推理和回溯机制实现更精确的导航决策。实验结果显示，VLTNet在PASTURE和RoboTHOR基准上表现出色，尤其在处理复杂自然语言指令的场景中，显著提高了导航准确性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by the International Conference on Pattern Recognition\n  (ICPR) for Oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2410.18570v1",
      "published_date": "2024-10-24 09:24:07 UTC",
      "updated_date": "2024-10-24 09:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:11:44.070997"
    },
    {
      "arxiv_id": "2410.18565v1",
      "title": "Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Krzysztof Ociepa",
        "Łukasz Flis",
        "Krzysztof Wróbel",
        "Adrian Gwoździej",
        "Remigiusz Kinas"
      ],
      "abstract": "We introduce Bielik 7B v0.1, a 7-billion-parameter generative text model for\nPolish language processing. Trained on curated Polish corpora, this model\naddresses key challenges in language model development through innovative\ntechniques. These include Weighted Instruction Cross-Entropy Loss, which\nbalances the learning of different instruction types, and Adaptive Learning\nRate, which dynamically adjusts the learning rate based on training progress.\nTo evaluate performance, we created the Open PL LLM Leaderboard and Polish\nMT-Bench, novel frameworks assessing various NLP tasks and conversational\nabilities. Bielik 7B v0.1 demonstrates significant improvements, achieving a 9\npercentage point increase in average score compared to Mistral-7B-v0.1 on the\nRAG Reader task. It also excels in the Polish MT-Bench, particularly in\nReasoning (6.15/10) and Role-playing (7.83/10) categories. This model\nrepresents a substantial advancement in Polish language AI, offering a powerful\ntool for diverse linguistic applications and setting new benchmarks in the\nfield.",
      "tldr_zh": "我们引入 Bielik 7B v0.1，这是一个 7 亿参数的生成文本模型，专门针对波兰语处理，通过训练于精选的波兰语语料库来解决语言模型开发的关键挑战。模型采用 Weighted Instruction Cross-Entropy Loss 和 Adaptive Learning Rate 等创新技术，分别平衡不同指令类型学习并动态调整学习率。评估结果显示，在 Open PL LLM Leaderboard 和 Polish MT-Bench 上，Bielik 7B v0.1 在 RAG Reader 任务中比 Mistral-7B-v0.1 平均分数提高了 9 个百分点，并在 Polish MT-Bench 的 Reasoning (6.15/10) 和 Role-playing (7.83/10) 类别中表现出色，推动了波兰语 AI 的发展并设定了新基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18565v1",
      "published_date": "2024-10-24 09:16:09 UTC",
      "updated_date": "2024-10-24 09:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:13:49.461948"
    },
    {
      "arxiv_id": "2410.18560v1",
      "title": "Explainable News Summarization -- Analysis and mitigation of Disagreement Problem",
      "title_zh": "可解释新闻摘要——分歧问题的分析和缓解",
      "authors": [
        "Seema Aswani",
        "Sujala D. Shetty"
      ],
      "abstract": "Explainable AI (XAI) techniques for text summarization provide valuable\nunderstanding of how the summaries are generated. Recent studies have\nhighlighted a major challenge in this area, known as the disagreement problem.\nThis problem occurs when different XAI methods offer contradictory explanations\nfor the summary generated from the same input article. This inconsistency\nacross XAI methods has been evaluated using predefined metrics designed to\nquantify agreement levels between them, revealing significant disagreement.\nThis impedes the reliability and interpretability of XAI in this area. To\naddress this challenge, we propose a novel approach that utilizes sentence\ntransformers and the k-means clustering algorithm to first segment the input\narticle and then generate the explanation of the summary generated for each\nsegment. By producing regional or segmented explanations rather than\ncomprehensive ones, a decrease in the observed disagreement between XAI methods\nis hypothesized. This segmentation-based approach was used on two news\nsummarization datasets, namely Extreme Summarization(XSum) and CNN-DailyMail,\nand the experiment was conducted using multiple disagreement metrics. Our\nexperiments validate the hypothesis by showing a significant reduction in\ndisagreement among different XAI methods. Additionally, a JavaScript\nvisualization tool is developed, that is easy to use and allows users to\ninteractively explore the color-coded visualization of the input article and\nthe machine-generated summary based on the attribution scores of each\nsentences.",
      "tldr_zh": "该论文分析了 Explainable AI (XAI) 在新闻摘要中的主要挑战，即 disagreement problem，即不同 XAI 方法对同一输入文章的摘要生成提供矛盾解释，导致可靠性降低。作者提出了一种新方法，使用 sentence transformers 和 k-means clustering 算法来分割输入文章，并为每个段生成区域解释，以减少 XAI 方法之间的分歧。实验在 XSum 和 CNN-DailyMail 数据集上进行，使用多种 disagreement metrics，验证了该方法显著降低了解释不一致性。此外，论文还开发了一个 JavaScript 视觉化工具，允许用户交互式探索文章和摘要的句子归因分数，从而提升了 XAI 的可解释性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18560v1",
      "published_date": "2024-10-24 09:07:44 UTC",
      "updated_date": "2024-10-24 09:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:12:08.747489"
    },
    {
      "arxiv_id": "2410.18556v1",
      "title": "Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "David Khachaturov",
        "Robert Mullins"
      ],
      "abstract": "Quantifying robustness in a single measure for the purposes of model\nselection, development of adversarial training methods, and anticipating trends\nhas so far been elusive. The simplest metric to consider is the number of\ntrainable parameters in a model but this has previously been shown to be\ninsufficient at explaining robustness properties. A variety of other metrics,\nsuch as ones based on boundary thickness and gradient flatness have been\nproposed but have been shown to be inadequate proxies for robustness.\n  In this work, we investigate the relationship between a model's effective\ndimensionality, which can be thought of as model complexity, and its robustness\nproperties. We run experiments on commercial-scale models that are often used\nin real-world environments such as YOLO and ResNet. We reveal a near-linear\ninverse relationship between effective dimensionality and adversarial\nrobustness, that is models with a lower dimensionality exhibit better\nrobustness. We investigate the effect of a variety of adversarial training\nmethods on effective dimensionality and find the same inverse linear\nrelationship present, suggesting that effective dimensionality can serve as a\nuseful criterion for model selection and robustness evaluation, providing a\nmore nuanced and effective metric than parameter count or previously-tested\nmeasures.",
      "tldr_zh": "本文研究了模型的有效维度(effective dimensionality)作为衡量对抗鲁棒性(adversarial robustness)的单一指标，旨在解决现有方法（如参数数量或边界厚度指标）的不足。通过实验分析YOLO和ResNet等商业模型，发现有效维度与鲁棒性呈近似线性反比关系，即有效维度较低的模型表现出更好的鲁棒性。进一步测试各种对抗训练方法后，证实了这一关系的一致性，从而提出有效维度作为模型选择和鲁棒性评估的更精确标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18556v1",
      "published_date": "2024-10-24 09:01:34 UTC",
      "updated_date": "2024-10-24 09:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:12:20.274135"
    },
    {
      "arxiv_id": "2410.18551v1",
      "title": "IMAN: An Adaptive Network for Robust NPC Mortality Prediction with Missing Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Yejing Huo",
        "Guoheng Huang",
        "Lianglun Cheng",
        "Jianbin He",
        "Xuhang Chen",
        "Xiaochen Yuan",
        "Guo Zhong",
        "Chi-Man Pun"
      ],
      "abstract": "Accurate prediction of mortality in nasopharyngeal carcinoma (NPC), a complex\nmalignancy particularly challenging in advanced stages, is crucial for\noptimizing treatment strategies and improving patient outcomes. However, this\npredictive process is often compromised by the high-dimensional and\nheterogeneous nature of NPC-related data, coupled with the pervasive issue of\nincomplete multi-modal data, manifesting as missing radiological images or\nincomplete diagnostic reports. Traditional machine learning approaches suffer\nsignificant performance degradation when faced with such incomplete data, as\nthey fail to effectively handle the high-dimensionality and intricate\ncorrelations across modalities. Even advanced multi-modal learning techniques\nlike Transformers struggle to maintain robust performance in the presence of\nmissing modalities, as they lack specialized mechanisms to adaptively integrate\nand align the diverse data types, while also capturing nuanced patterns and\ncontextual relationships within the complex NPC data. To address these problem,\nwe introduce IMAN: an adaptive network for robust NPC mortality prediction with\nmissing modalities.",
      "tldr_zh": "本研究针对鼻咽癌(NPC)死亡率预测的挑战，指出传统机器学习和多模态方法如Transformers在面对高维度异质数据和缺失模态（如放射图像或诊断报告）时，性能显著下降。论文提出IMAN，一种适应性网络，通过动态整合多模态数据并捕捉复杂模式，实现鲁棒的预测。IMAN有望优化治疗策略并改善患者预后，为处理缺失模态的医疗AI应用提供新框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted by BIBM 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18551v1",
      "published_date": "2024-10-24 08:54:08 UTC",
      "updated_date": "2024-10-24 08:54:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:12:32.517162"
    },
    {
      "arxiv_id": "2410.18541v1",
      "title": "On Explaining with Attention Matrices",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Naim",
        "Nicholas Asher"
      ],
      "abstract": "This paper explores the much discussed, possible explanatory link between\nattention weights (AW) in transformer models and predicted output. Contrary to\nintuition and early research on attention, more recent prior research has\nprovided formal arguments and empirical evidence that AW are not explanatorily\nrelevant. We show that the formal arguments are incorrect. We introduce and\neffectively compute efficient attention, which isolates the effective\ncomponents of attention matrices in tasks and models in which AW play an\nexplanatory role. We show that efficient attention has a causal role (provides\nminimally necessary and sufficient conditions) for predicting model output in\nNLP tasks requiring contextual information, and we show, contrary to [7], that\nefficient attention matrices are probability distributions and are effectively\ncalculable. Thus, they should play an important part in the explanation of\nattention based model behavior. We offer empirical experiments in support of\nour method illustrating various properties of efficient attention with various\nmetrics on four datasets.",
      "tldr_zh": "本论文质疑了现有研究对Transformer模型中注意力权重（AW）解释性的否定论据，证明AW在某些任务中确实具有解释作用。作者引入了efficient attention的概念，通过有效计算方法隔离注意力矩阵的关键组件，并在需要上下文信息的NLP任务中展示了其因果作用（即提供最小必要和充分条件）。实验结果表明，efficient attention是可计算的概率分布，能够显著提升对模型行为的解释力，并在四个数据集上通过多种指标验证了其性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "46-04",
        "I.2.7; I.7.0"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18541v1",
      "published_date": "2024-10-24 08:43:33 UTC",
      "updated_date": "2024-10-24 08:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:12:44.246801"
    },
    {
      "arxiv_id": "2410.18533v1",
      "title": "LOGO -- Long cOntext aliGnment via efficient preference Optimization",
      "title_zh": "LOGO —— 通过高效偏好优化的长",
      "authors": [
        "Zecheng Tang",
        "Zechen Sun",
        "Juntao Li",
        "Qiaoming Zhu",
        "Min Zhang"
      ],
      "abstract": "Long-context models(LCMs) have shown great potential in processing long input\nsequences(even more than 100M tokens) conveniently and effectively. With\nsignificant progress, recent research has pointed out that LCMs can accurately\nlocate token-level salient information within the context. Yet, the generation\nperformance of these LCMs is far from satisfactory and might result in\nmisaligned responses, such as hallucinations. To enhance the generation\ncapability of LCMs, existing works have investigated the effects of data size\nand quality for both pre-training and instruction tuning. Though achieving\nmeaningful improvement, previous methods fall short in either effectiveness or\nefficiency. In this paper, we introduce LOGO(Long cOntext aliGnment via\nefficient preference Optimization), a training strategy that first introduces\npreference optimization for long-context alignment. To overcome the GPU\nmemory-bound issue caused by the long sequence, LOGO employs a reference-free\npreference optimization strategy and adopts a position synthesis method to\nconstruct the training data. By training with only 0.3B data on a single\n8$\\times$A800 GPU machine for 16 hours, LOGO allows the Llama-3-8B-Instruct-80K\nmodel to achieve comparable performance with GPT-4 in real-world long-context\ntasks while preserving the model's original capabilities on other tasks, e.g.,\nlanguage modeling and MMLU. Moreover, LOGO can extend the model's context\nwindow size while enhancing its generation performance.",
      "tldr_zh": "本研究提出LOGO（Long cOntext aliGnment via efficient preference Optimization），一种高效的训练策略，用于提升Long-context models (LCMs)的生成性能，解决其在处理长序列时可能出现的幻觉（hallucinations）等问题。LOGO首次引入preference optimization进行长上下文对齐，通过参考-free偏好优化策略和位置合成方法构建训练数据，以克服GPU内存限制。实验结果显示，仅用0.3B数据在单机8×A800 GPU上训练16小时，LOGO即可使Llama-3-8B-Instruct-80K模型在真实长上下文任务上达到与GPT-4相当的性能，同时保留模型在语言建模和MMLU等任务上的原有能力，并扩展其上下文窗口大小。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18533v1",
      "published_date": "2024-10-24 08:27:26 UTC",
      "updated_date": "2024-10-24 08:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:14:01.430152"
    },
    {
      "arxiv_id": "2410.18528v1",
      "title": "PRACT: Optimizing Principled Reasoning and Acting of LLM Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Liu",
        "Weiran Yao",
        "Jianguo Zhang",
        "Rithesh Murthy",
        "Liangwei Yang",
        "Zuxin Liu",
        "Tian Lan",
        "Ming Zhu",
        "Juntao Tan",
        "Shirley Kokane",
        "Thai Hoang",
        "Juan Carlos Niebles",
        "Shelby Heinecke",
        "Huan Wang",
        "Silvio Savarese",
        "Caiming Xiong"
      ],
      "abstract": "We introduce the Principled Reasoning and Acting (PRAct) framework, a novel\nmethod for learning and enforcing action principles from trajectory data.\nCentral to our approach is the use of text gradients from a reflection and\noptimization engine to derive these action principles. To adapt action\nprinciples to specific task requirements, we propose a new optimization\nframework, Reflective Principle Optimization (RPO). After execution, RPO\nemploys a reflector to critique current action principles and an optimizer to\nupdate them accordingly. We develop the RPO framework under two scenarios:\nReward-RPO, which uses environmental rewards for reflection, and Self-RPO,\nwhich conducts self-reflection without external rewards. Additionally, two RPO\nmethods, RPO-Traj and RPO-Batch, is introduced to adapt to different settings.\nExperimental results across four environments demonstrate that the PRAct agent,\nleveraging the RPO framework, effectively learns and applies action principles\nto enhance performance.",
      "tldr_zh": "本论文提出PRAct框架，一种从轨迹数据中学习和执行行动原则的新方法，通过文本梯度从反射和优化引擎中获取原则，以优化LLM代理的推理和行动。论文引入Reflective Principle Optimization (RPO)框架，包括Reward-RPO（利用环境奖励进行反射）和Self-RPO（无需外部奖励的自反射），以及RPO-Traj和RPO-Batch两种方法，以适应不同任务需求并更新行动原则。实验结果显示，在四个环境中，PRAct代理应用RPO框架后有效提升了性能，证明了其在原则性决策方面的优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to SIG CoNLL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18528v1",
      "published_date": "2024-10-24 08:21:51 UTC",
      "updated_date": "2024-10-24 08:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:14:13.207892"
    },
    {
      "arxiv_id": "2410.18517v1",
      "title": "KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Yang",
        "Zouying Cao",
        "Qiguang Chen",
        "Libo Qin",
        "Dongjie Yang",
        "Hai Zhao",
        "Zhi Chen"
      ],
      "abstract": "The development of large language models (LLMs) has significantly expanded\nmodel sizes, resulting in substantial GPU memory requirements during inference.\nThe key and value storage of the attention map in the KV (key-value) cache\naccounts for more than 80\\% of this memory consumption. Nowadays, most existing\nKV cache compression methods focus on intra-layer compression within a single\nTransformer layer but few works consider layer-wise compression. In this paper,\nwe propose a plug-and-play method called \\textit{KVSharer}, which shares the KV\ncache between layers to achieve layer-wise compression. Rather than intuitively\nsharing based on higher similarity, we discover a counterintuitive phenomenon:\nsharing dissimilar KV caches better preserves the model performance.\nExperiments show that \\textit{KVSharer} can reduce KV cache computation by\n30\\%, thereby lowering memory consumption without significantly impacting model\nperformance and it can also achieve at least 1.3 times generation acceleration.\nAdditionally, we verify that \\textit{KVSharer} is compatible with existing\nintra-layer KV cache compression methods, and combining both can further save\nmemory.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）推理过程中高 GPU 内存消耗问题，提出了一种即插即用的方法 KVSharer，通过在 Transformer 层间共享不相似 KV cache 实现层级压缩。不同于直觉上的相似缓存共享，研究发现共享不相似 KV cache 能更好地保留模型性能，从而减少 30% 的 KV cache 计算。实验结果显示，KVSharer 显著降低内存消耗，实现至少 1.3 倍的生成加速，并与现有单层压缩方法兼容，进一步提升整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review by ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18517v1",
      "published_date": "2024-10-24 08:06:41 UTC",
      "updated_date": "2024-10-24 08:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:14:25.071730"
    },
    {
      "arxiv_id": "2410.18514v3",
      "title": "Scaling up Masked Diffusion Models on Text",
      "title_zh": "在文本上扩展掩码扩散模型",
      "authors": [
        "Shen Nie",
        "Fengqi Zhu",
        "Chao Du",
        "Tianyu Pang",
        "Qian Liu",
        "Guangtao Zeng",
        "Min Lin",
        "Chongxuan Li"
      ],
      "abstract": "Masked diffusion models (MDMs) have shown promise in language modeling, yet\ntheir scalability and effectiveness in core language tasks, such as text\ngeneration and language understanding, remain underexplored. This paper\nestablishes the first scaling law for MDMs, demonstrating a scaling rate\ncomparable to autoregressive models (ARMs) and a relatively small compute gap.\nMotivated by their scalability, we train a family of MDMs with up to 1.1\nbillion (B) parameters to systematically evaluate their performance against\nARMs of comparable or larger sizes. Fully leveraging the probabilistic\nformulation of MDMs, we propose a simple yet effective unsupervised\nclassifier-free guidance that effectively exploits large-scale unpaired data,\nboosting performance for conditional inference. In language understanding, the\n1.1B MDM outperforms the 1.1B TinyLlama model trained on the same data across\nfour of eight zero-shot benchmarks. Notably, it achieves competitive math\nreasoning ability with the 7B Llama-2 model on the GSM8K dataset. In text\ngeneration, MDMs with 16 times more pre-training time offer a flexible\ntrade-off against ARMs with the accelerated sampling technique KV-Cache: MDMs\nmatch ARMs in performance while being 1.4 times faster during sampling.\nMoreover, MDMs address challenging tasks for ARMs by effectively handling\nbidirectional reasoning and adapting to temporal shifts in data. Notably, a\n1.1B MDM breaks the reverse curse encountered by much larger ARMs with\nsignificantly more data and computation, such as 13B Llama-2 and 175B GPT-3.\nOur code is available at https://github.com/ML-GSAI/SMDM.",
      "tldr_zh": "本文首次建立了 Masked Diffusion Models (MDMs) 在文本领域的缩放定律，发现其缩放率与 autoregressive models (ARMs) 相当，且计算差距较小。研究者训练了一系列规模达 1.1 亿参数的 MDMs，并提出了一种简单有效的无监督 classifier-free guidance 方法，利用大规模非配对数据提升条件推理性能。在语言理解任务中，1.1B MDM 在四个零样本基准上超越了使用相同数据的 1.1B TinyLlama 模型，并在 GSM8K 数据集的数学推理上与 7B Llama-2 模型相当。在文本生成任务中，MDMs 通过加速采样技术 KV-Cache 与 ARMs 匹配性能，同时采样速度快 1.4 倍，并成功处理 ARMs 的挑战，如双向推理和数据时间偏移问题。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18514v3",
      "published_date": "2024-10-24 08:01:22 UTC",
      "updated_date": "2025-02-28 07:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:14:38.897894"
    },
    {
      "arxiv_id": "2410.18510v1",
      "title": "A framework for GNSS-based solutions performance analysis in an ERTMS context",
      "title_zh": "一种用于ERTMS语境中GNSS-based解决方案性能分析的框架",
      "authors": [
        "Juliette Marais",
        "Quentin Mayolle",
        "Martin Fasquelle",
        "Vincent Tardif",
        "Emilie Chéneau-Grehalle"
      ],
      "abstract": "Context Progresses in GNSS-based solution introduction in rail applications\nGNSS (Global Navigation Satellite System) is now used in most of our travels\nand each of our smartphone apps. Most of the usages are not safety-critical.\nBut Europe identified GNSS for more applications and to be integrated in rail\nin general as part of the toolset to help railway to contribute to reduce\ntransport carbon footprint. To increase the use of trains in European\ntransports, railways must improve their attractiveness for passengers and\nfreight, but also increase reliability, availability and efficiency by reducing\ncapital expenditure and operational costs. GNSS is part of the global\ndigitalization scheme of freight that aims to offer added value to the clients\nknowledge of accurate time of arrival, continuous monitoring of transport\nconditions (temperature, humidity...). But a major challenge will be to reach\nstringent applications and in particular, GNSS is today seen as a realistic and\nserious game changer for the future of the ERTMS (European Rail Traffic\nManagement System). The localisation function is today performed with both\nodometry and balises. Odometer provides a continuous train position in time\nfrom a reference point. But as the distance delivered by the odometer shows a\ngrowing bias with distance, due to wear and wheel sliding, the use of on-track\nbalises allows to reduce this error. Future systems will be based on on-board\nlocalisation solutions with GNSS receivers. It will allow the development of\nnew concepts for moving blocks, virtual coupling and automation. Its use for\ntrain integrity is also investigated. But the environmental conditions of track\nand surroundings configuration, i.e, tunnels, dense urban areas or vegetation\noften degrade positioning performance and thus its efficiency and safety.\nIndeed, GNSS satellites are moving and their visibility (availability and\nrelative position from the receiver) vary with time. Moreover, for optimal\nperformance, the system requires open sky environments, which are the cases of\nmost of the aeronautical uses but not of train uses. Trains often circulate in\nareas where signal reception can be disturbed (multipath, intentional or\nunintentional interferences) and thus, performances degraded. If many\nprogresses have been made in the past years to develop more robust receivers\n[Puccitelli, 2022], multi-sensor solutions [CLUG website] or missing tools such\nas Digital Maps [Crespillo, 2023], in projects such as the Shift2Rail Project\nX2Rail-5 or CLUG, some questions remain and in particular related to\nperformance evaluation. How can we evaluate performances in a dynamic\nenvironment (train, satellite, obstacles)? How can we be sure that every\nconfiguration has been tested? What is the impact of a failure (inaccuracy,\nmissed detection) on operation? Some of these issues are addressed in the\non-going R2DATO project funded by Europe's rail.",
      "tldr_zh": "这篇论文提出一个框架，用于分析GNSS（Global Navigation Satellite System）在ERTMS（European Rail Traffic Management System）环境下的性能，旨在解决铁路应用中GNSS定位的准确性和可靠性问题。框架针对动态环境（如列车运动、卫星可见性变化以及隧道或城市干扰）中的性能评估，探讨了如何确保所有配置被测试以及故障（如不准确或检测缺失）对操作的影响。研究强调GNSS可提升铁路效率、减少碳足迹，但需克服环境挑战，并通过项目如R2DATO来验证其潜力。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18510v1",
      "published_date": "2024-10-24 07:53:47 UTC",
      "updated_date": "2024-10-24 07:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:16:41.822142"
    },
    {
      "arxiv_id": "2410.18506v1",
      "title": "Enhancing Graph Attention Neural Network Performance for Marijuana Consumption Classification through Large-scale Augmented Granger Causality (lsAGC) Analysis of Functional MR Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Vosoughi",
        "Akhil Kasturi",
        "Axel Wismueller"
      ],
      "abstract": "In the present research, the effectiveness of large-scale Augmented Granger\nCausality (lsAGC) as a tool for gauging brain network connectivity was examined\nto differentiate between marijuana users and typical controls by utilizing\nresting-state functional Magnetic Resonance Imaging (fMRI). The relationship\nbetween marijuana consumption and alterations in brain network connectivity is\na recognized fact in scientific literature. This study probes how lsAGC can\naccurately discern these changes. The technique used integrates dimension\nreduction with the augmentation of source time-series in a model that predicts\ntime-series, which helps in estimating the directed causal relationships among\nfMRI time-series. As a multivariate approach, lsAGC uncovers the connection of\nthe inherent dynamic system while considering all other time-series. A dataset\nof 60 adults with an ADHD diagnosis during childhood, drawn from the Addiction\nConnectome Preprocessed Initiative (ACPI), was used in the study. The brain\nconnections assessed by lsAGC were utilized as classification attributes. A\nGraph Attention Neural Network (GAT) was chosen to carry out the classification\ntask, particularly for its ability to harness graph-based data and recognize\nintricate interactions between brain regions, making it appropriate for\nfMRI-based brain connectivity data. The performance was analyzed using a\nfive-fold cross-validation system. The average accuracy achieved by the\ncorrelation coefficient method was roughly 52.98%, with a 1.65 standard\ndeviation, whereas the lsAGC approach yielded an average accuracy of 61.47%,\nwith a standard deviation of 1.44. The suggested method enhances the body of\nknowledge in the field of neuroimaging-based classification and emphasizes the\nnecessity to consider directed causal connections in brain network connectivity\nanalysis when studying marijuana's effects on the brain.",
      "tldr_zh": "本研究利用 large-scale Augmented Granger Causality (lsAGC) 分析方法，基于休息态 functional Magnetic Resonance Imaging (fMRI) 数据，评估脑网络连接性以区分大麻使用者与正常对照组。研究整合了维度减少和时间序列增强技术，使用 Graph Attention Neural Network (GAT) 作为分类模型，对来自 Addiction Connectome Preprocessed Initiative (ACPI) 的60名成年受试者数据进行五折交叉验证。结果显示，lsAGC 方法的平均准确率达61.47%（标准差1.44%），显著高于相关系数方法的52.98%（标准差1.65%），从而增强了神经影像分类的知识，并强调了在研究大麻对脑影响时考虑定向因果连接的重要性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18506v1",
      "published_date": "2024-10-24 07:50:10 UTC",
      "updated_date": "2024-10-24 07:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:15:01.621112"
    },
    {
      "arxiv_id": "2410.18503v1",
      "title": "SFB-net for cardiac segmentation: Bridging the semantic gap with attention",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Portal",
        "Nadjia Kachenoura",
        "Thomas Dietenbeck",
        "Catherine Achard"
      ],
      "abstract": "In the past few years, deep learning algorithms have been widely used for\ncardiac image segmentation. However, most of these architectures rely on\nconvolutions that hardly model long-range dependencies, limiting their ability\nto extract contextual information. In order to tackle this issue, this article\nintroduces the Swin Filtering Block network (SFB-net) which takes advantage of\nboth conventional and swin transformer layers. The former are used to introduce\nspatial attention at the bottom of the network, while the latter are applied to\nfocus on high level semantically rich features between the encoder and decoder.\nAn average Dice score of 92.4 was achieved on the ACDC dataset. To the best of\nour knowledge, this result outperforms any other work on this dataset. The\naverage Dice score of 87.99 obtained on the M\\&amp;M's dataset demonstrates\nthat the proposed method generalizes well to data from different vendors and\ncentres.",
      "tldr_zh": "该论文提出SFB-net（Swin Filtering Block network）用于心脏图像分割，通过结合传统卷积层和Swin Transformer层来解决现有模型难以捕捉长距离依赖性的问题。SFB-net在网络底层使用卷积层引入空间注意力，并在编码器和解码器之间应用Swin Transformer层以关注高级语义特征。实验结果显示，该方法在ACDC数据集上达到了92.4的平均Dice score，优于现有工作，并在M&M's数据集上取得了87.99的Dice score，证明了其在不同数据来源上的良好泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18503v1",
      "published_date": "2024-10-24 07:48:13 UTC",
      "updated_date": "2024-10-24 07:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:15:12.900809"
    },
    {
      "arxiv_id": "2411.05793v3",
      "title": "A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Jongseon Kim",
        "Hyungjoon Kim",
        "HyunGi Kim",
        "Dongjun Lee",
        "Sungroh Yoon"
      ],
      "abstract": "Time series forecasting is a critical task that provides key information for\ndecision-making. After traditional statistical and machine learning approaches,\nvarious fundamental deep learning architectures such as MLPs, CNNs, RNNs, and\nGNNs have been developed. However, the structural limitations caused by the\ninductive biases of each deep learning architecture constrained their\nperformance. Transformer models, which excel at handling long-term\ndependencies, have become significant architectural components for time series\nforecasting. However, recent research has shown that alternatives such as\nsimple linear layers can outperform Transformers. These findings have opened up\nnew possibilities for using diverse architectures, ranging from fundamental\ndeep learning models to emerging architectures and hybrid approaches. In this\ncontext, architectural modeling of time series forecasting has now entered a\nrenaissance. This survey not only provides a historical context for time series\nforecasting but also offers comprehensive and timely analysis of the movement\ntoward architectural diversification. By comparing and re-examining deep\nlearning models, we uncover new perspectives and present recent trends,\nincluding hybrid, diffusion, Mamba, and foundation models. By focusing on the\ninherent characteristics of time series data, we also address open challenges\nthat have gained attention in time series forecasting, such as channel\ndependency, distribution shift, causality, and feature extraction. These\ncontributions help lower entry barriers for newcomers by providing a systematic\nunderstanding of the diverse research areas in time series forecasting (TSF),\nwhile offering seasoned researchers broader perspectives and new opportunities\nthrough in-depth exploration of TSF challenges. (Shortened due to arXiv's\n1,920-character limit. Full version in the paper.)",
      "tldr_zh": "这篇调查综述了深度学习在时间序列预测(Time Series Forecasting)中的应用，回顾了从传统统计方法到各种架构的演变，包括 MLPs、CNNs、RNNs、GNNs 和 Transformers，并强调了这些模型的局限性以及简单线性层可能优于 Transformers 的新发现。论文分析了当前架构多样化的复兴趋势，如混合模型、扩散模型、Mamba 和基础模型，旨在通过比较不同方法揭示时间序列数据的内在特性。最终，它讨论了关键开放挑战，包括通道依赖(Channel Dependency)、分布偏移(Distribution Shift)、因果关系和特征提取，并为新手提供系统性理解，同时为资深研究者开辟更广阔的视角和机会。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the accepted manuscript of the article published in\n  Artificial Intelligence Review. The final authenticated version is available\n  at: https://doi.org/10.1007/s10462-025-11223-9",
      "pdf_url": "http://arxiv.org/pdf/2411.05793v3",
      "published_date": "2024-10-24 07:43:55 UTC",
      "updated_date": "2025-05-01 05:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:15:26.558906"
    },
    {
      "arxiv_id": "2410.18489v1",
      "title": "LLM as a code generator in Agile Model Driven Development",
      "title_zh": "LLM 作为代码生成器在敏捷模型驱动开发中",
      "authors": [
        "Ahmed R. Sadik",
        "Sebastian Brulin",
        "Markus Olhofer",
        "Antonello Ceravola",
        "Frank Joublin"
      ],
      "abstract": "Leveraging Large Language Models (LLM) like GPT4 in the auto generation of\ncode represents a significant advancement, yet it is not without its\nchallenges. The ambiguity inherent in natural language descriptions of software\nposes substantial obstacles to generating deployable, structured artifacts.\nThis research champions Model Driven Development (MDD) as a viable strategy to\novercome these challenges, proposing an Agile Model Driven Development (AMDD)\napproach that employs GPT4 as a code generator. This approach enhances the\nflexibility and scalability of the code auto generation process and offers\nagility that allows seamless adaptation to changes in models or deployment\nenvironments. We illustrate this by modeling a multi agent Unmanned Vehicle\nFleet (UVF) system using the Unified Modeling Language (UML), significantly\nreducing model ambiguity by integrating the Object Constraint Language (OCL)\nfor code structure meta modeling, and the FIPA ontology language for\ncommunication semantics meta modeling. Applying GPT4 auto generation\ncapabilities yields Java and Python code that is compatible with the JADE and\nPADE frameworks, respectively. Our thorough evaluation of the auto generated\ncode verifies its alignment with expected behaviors and identifies enhancements\nin agent interactions. Structurally, we assessed the complexity of code derived\nfrom a model constrained solely by OCL meta models, against that influenced by\nboth OCL and FIPA ontology meta models. The results indicate that the ontology\nconstrained meta model produces inherently more complex code, yet its\ncyclomatic complexity remains within manageable levels, suggesting that\nadditional meta model constraints can be incorporated without exceeding the\nhigh risk threshold for complexity.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLM）如 GPT-4 作为代码生成器在 Agile Model Driven Development (AMDD) 中的应用，以解决自然语言描述的模糊性带来的挑战。研究提出了一种基于 Model Driven Development (MDD) 的方法，通过 Unified Modeling Language (UML)、Object Constraint Language (OCL) 和 FIPA 语义建模来减少模型歧义，并生成兼容 JADE 和 PADE 框架的 Java 和 Python 代码。实验结果显示，生成的代码与预期行为一致，且添加 OCL 和 FIPA 约束虽增加了代码复杂度，但保持在可管理范围内，从而提升了代码生成的灵活性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18489v1",
      "published_date": "2024-10-24 07:24:11 UTC",
      "updated_date": "2024-10-24 07:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:17:36.560995"
    },
    {
      "arxiv_id": "2410.18481v2",
      "title": "Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction",
      "title_zh": "Dialog2",
      "authors": [
        "Sergio Burdisso",
        "Srikanth Madikeri",
        "Petr Motlicek"
      ],
      "abstract": "Efficiently deriving structured workflows from unannotated dialogs remains an\nunderexplored and formidable challenge in computational linguistics. Automating\nthis process could significantly accelerate the manual design of workflows in\nnew domains and enable the grounding of large language models in\ndomain-specific flowcharts, enhancing transparency and controllability. In this\npaper, we introduce Dialog2Flow (D2F) embeddings, which differ from\nconventional sentence embeddings by mapping utterances to a latent space where\nthey are grouped according to their communicative and informative functions\n(i.e., the actions they represent). D2F allows for modeling dialogs as\ncontinuous trajectories in a latent space with distinct action-related regions.\nBy clustering D2F embeddings, the latent space is quantized, and dialogs can be\nconverted into sequences of region/action IDs, facilitating the extraction of\nthe underlying workflow. To pre-train D2F, we build a comprehensive dataset by\nunifying twenty task-oriented dialog datasets with normalized per-turn action\nannotations. We also introduce a novel soft contrastive loss that leverages the\nsemantic information of these actions to guide the representation learning\nprocess, showing superior performance compared to standard supervised\ncontrastive loss. Evaluation against various sentence embeddings, including\ndialog-specific ones, demonstrates that D2F yields superior qualitative and\nquantitative results across diverse domains.",
      "tldr_zh": "本文提出 Dialog2Flow (D2F) 嵌入方法，用于从未标注对话中自动提取结构化工作流，从而加速新领域工作流的构建并提升大型语言模型的领域特定可控性。D2F 通过将话语映射到潜在空间中基于动作功能的区域，将对话建模为连续轨迹，并通过聚类量化生成动作 ID 序列以提取底层工作流。为此，研究者构建了一个统一 20 个任务导向对话数据集，并引入软对比损失（soft contrastive loss）来利用动作语义信息指导表示学习，比标准监督对比损失更有效。实验评估显示，D2F 在定性和定量指标上优于其他句子嵌入方法，在多样领域中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2410.18481v2",
      "published_date": "2024-10-24 07:10:18 UTC",
      "updated_date": "2024-11-05 11:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:15:49.706570"
    },
    {
      "arxiv_id": "2410.18475v2",
      "title": "Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production",
      "title_zh": "翻译失败",
      "authors": [
        "Kexuan Xin",
        "Qingyun Wang",
        "Junyu Chen",
        "Pengfei Yu",
        "Huimin Zhao",
        "Heng Ji"
      ],
      "abstract": "In the rapidly evolving field of metabolic engineering, the quest for\nefficient and precise gene target identification for metabolite production\nenhancement presents significant challenges. Traditional approaches, whether\nknowledge-based or model-based, are notably time-consuming and labor-intensive,\ndue to the vast scale of research literature and the approximation nature of\ngenome-scale metabolic model (GEM) simulations. Therefore, we propose a new\ntask, Gene-Metabolite Association Prediction based on metabolic graphs, to\nautomate the process of candidate gene discovery for a given pair of metabolite\nand candidate-associated genes, as well as presenting the first benchmark\ncontaining 2474 metabolites and 1947 genes of two commonly used microorganisms\nSaccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is\nchallenging due to the incompleteness of the metabolic graphs and the\nheterogeneity among distinct metabolisms. To overcome these limitations, we\npropose an Interactive Knowledge Transfer mechanism based on Metabolism Graph\n(IKT4Meta), which improves the association prediction accuracy by integrating\nthe knowledge from different metabolism graphs. First, to build a bridge\nbetween two graphs for knowledge transfer, we utilize Pretrained Language\nModels (PLMs) with external knowledge of genes and metabolites to help generate\ninter-graph links, significantly alleviating the impact of heterogeneity.\nSecond, we propagate intra-graph links from different metabolic graphs using\ninter-graph links as anchors. Finally, we conduct the gene-metabolite\nassociation prediction based on the enriched metabolism graphs, which integrate\nthe knowledge from multiple microorganisms. Experiments on both types of\norganisms demonstrate that our proposed methodology outperforms baselines by up\nto 12.3% across various link prediction frameworks.",
      "tldr_zh": "该研究针对代谢工程中基因目标识别的效率问题，提出了Gene-Metabolite Association Prediction新任务，并构建了首个基准数据集，涵盖2474种代谢物和1947种基因，涉及Saccharomyces cerevisiae和Issatchenkia orientalis两种微生物。\n为了应对代谢图不完整和异质性挑战，他们开发了Interactive Knowledge Transfer mechanism based on Metabolism Graph (IKT4Meta)，该方法利用Pretrained Language Models (PLMs)结合外部知识生成inter-graph链接，并通过这些链接作为锚点传播intra-graph知识，从而增强图结构并提高关联预测准确率。\n实验结果表明，IKT4Meta在各种链接预测框架上比基线方法提高了高达12.3%的性能，为自动化候选基因发现提供了高效工具。",
      "categories": [
        "cs.AI",
        "IEEEtran"
      ],
      "primary_category": "cs.AI",
      "comment": "10 PAGES, 4 FIGURES; bibm 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18475v2",
      "published_date": "2024-10-24 06:54:27 UTC",
      "updated_date": "2024-10-31 05:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:17:49.203239"
    },
    {
      "arxiv_id": "2410.18460v1",
      "title": "Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare",
      "title_zh": "超越多选题准确性：在医疗保健中实施大型语言模型的",
      "authors": [
        "Yifan Yang",
        "Qiao Jin",
        "Qingqing Zhu",
        "Zhizheng Wang",
        "Francisco Erramuspe Álvarez",
        "Nicholas Wan",
        "Benjamin Hou",
        "Zhiyong Lu"
      ],
      "abstract": "Large Language Models (LLMs) have gained significant attention in the medical\ndomain for their human-level capabilities, leading to increased efforts to\nexplore their potential in various healthcare applications. However, despite\nsuch a promising future, there are multiple challenges and obstacles that\nremain for their real-world uses in practical settings. This work discusses key\nchallenges for LLMs in medical applications from four unique aspects:\noperational vulnerabilities, ethical and social considerations, performance and\nassessment difficulties, and legal and regulatory compliance. Addressing these\nchallenges is crucial for leveraging LLMs to their full potential and ensuring\ntheir responsible integration into healthcare.",
      "tldr_zh": "这篇论文探讨了在医疗领域应用大型语言模型（LLMs）的实际挑战，超越了传统多项选择准确性的评估。论文从四个关键方面分析这些问题：操作漏洞、伦理和社会考虑、性能和评估困难，以及法律和监管合规性。这些挑战突显了LLMs在真实场景中可能面临的障碍，并强调了解决它们的重要性，以充分发挥LLMs的潜力并确保其负责任地融入医疗实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18460v1",
      "published_date": "2024-10-24 06:12:03 UTC",
      "updated_date": "2024-10-24 06:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:17:59.497913"
    },
    {
      "arxiv_id": "2410.18456v3",
      "title": "Progressive Curriculum Learning with Scale-Enhanced U-Net for Continuous Airway Segmentation",
      "title_zh": "渐进式课程学习结合 Scale-Enhanced U-Net 用于连续气道分割",
      "authors": [
        "Bingyu Yang",
        "Qingyao Tian",
        "Huai Liao",
        "Xinyan Huang",
        "Jinlin Wu",
        "Jingdi Hu",
        "Hongbin Liu"
      ],
      "abstract": "Continuous and accurate segmentation of airways in chest CT images is\nessential for preoperative planning and real-time bronchoscopy navigation.\nDespite advances in deep learning for medical image segmentation, maintaining\nairway continuity remains a challenge, particularly due to intra-class\nimbalance between large and small branches and blurred CT scan details. To\naddress these challenges, we propose a progressive curriculum learning pipeline\nand a Scale-Enhanced U-Net (SE-UNet) to enhance segmentation continuity.\nSpecifically, our progressive curriculum learning pipeline consists of three\nstages: extracting main airways, identifying small airways, and repairing\ndiscontinuities. The cropping sampling strategy in each stage reduces feature\ninterference between airways of different scales, effectively addressing the\nchallenge of intra-class imbalance. In the third training stage, we present an\nAdaptive Topology-Responsive Loss (ATRL) to guide the network to focus on\nairway continuity. The progressive training pipeline shares the same SE-UNet,\nintegrating multi-scale inputs and Detail Information Enhancers (DIEs) to\nenhance information flow and effectively capture the intricate details of small\nairways. Additionally, we propose a robust airway tree parsing method and\nhierarchical evaluation metrics to provide more clinically relevant and precise\nanalysis. Experiments on both in-house and public datasets demonstrate that our\nmethod outperforms existing approaches, significantly improving the accuracy of\nsmall airways and the completeness of the airway tree. The code will be\nreleased upon publication.",
      "tldr_zh": "本研究针对胸部 CT 图像中气道分割的连续性和准确性问题，提出了一种 Progressive Curriculum Learning 管道和 Scale-Enhanced U-Net (SE-UNet)，以解决气道分支间的不平衡和图像细节模糊挑战。该管道分为三个阶段：提取主气道、识别小气道和修复不连续性，通过 Cropping Sampling Strategy 减少不同规模特征的干扰，并在第三阶段引入 Adaptive Topology-Responsive Loss (ATRL) 来强化连续性优化。SE-UNet 整合多尺度输入和 Detail Information Enhancers (DIEs)，提升信息流并捕捉小气道细节。实验在内部和公共数据集上显示，该方法优于现有方法，显著提高了小气道的准确性和气道树的完整性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18456v3",
      "published_date": "2024-10-24 06:10:09 UTC",
      "updated_date": "2025-02-28 15:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:20:13.372471"
    },
    {
      "arxiv_id": "2410.18454v1",
      "title": "Verifying Non-friendly Formal Verification Designs: Can We Start Earlier?",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Olmos",
        "Daniel Gerl",
        "Aman Kumar",
        "Djones Lettnin"
      ],
      "abstract": "The design of Systems on Chips (SoCs) is becoming more and more complex due\nto technological advancements. Missed bugs can cause drastic failures in\nsafety-critical environments leading to the endangerment of lives. To overcome\nthese drastic failures, formal property verification (FPV) has been applied in\nthe industry. However, there exist multiple hardware designs where the results\nof FPV are not conclusive even for long runtimes of model-checking tools. For\nthis reason, the use of High-level Equivalence Checking (HLEC) tools has been\nproposed in the last few years. However, the procedure for how to use it inside\nan industrial toolchain has not been defined. For this reason, we proposed an\nautomated methodology based on metamodeling techniques which consist of two\nmain steps. First, an untimed algorithmic description written in C++ is\nverified in an early stage using generated assertions; the advantage of this\nstep is that the assertions at the software level run in seconds and we can\nstart our analysis with conclusive results about our algorithm before starting\nto write the RTL (Register Transfer Level) design. Second, this algorithmic\ndescription is verified against its sequential design using HLEC and the\nrespective metamodel parameters. The results show that the presented\nmethodology can find bugs early related to the algorithmic description and\nprepare the setup for the HLEC verification. This helps to reduce the\nverification efforts to set up the tool and write the properties manually which\nis always error-prone. The proposed framework can help teams working on\ndatapaths to verify and make decisions in an early stage of the verification\nflow.",
      "tldr_zh": "该论文探讨了SoC（Systems on Chips）设计复杂性导致的验证挑战，指出传统FPV（Formal Property Verification）可能无法得出结论性结果。作者提出了一种基于元建模（metamodeling）的自动化方法，包括两个步骤：首先，在早期阶段使用C++编写的untimed algorithmic description和生成的assertions进行快速验证；其次，通过HLEC（High-level Equivalence Checking）和相关参数验证算法与sequential design的等价性。实验结果显示，该框架能及早发现算法相关bugs，减少手动编写属性和工具设置的努力，从而帮助团队在验证流程早期做出决策。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Published in DVCon Europe 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18454v1",
      "published_date": "2024-10-24 06:09:40 UTC",
      "updated_date": "2024-10-24 06:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:18:24.692850"
    },
    {
      "arxiv_id": "2410.18451v1",
      "title": "Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Yuhao Liu",
        "Liang Zeng",
        "Jiacai Liu",
        "Rui Yan",
        "Jujie He",
        "Chaojie Wang",
        "Shuicheng Yan",
        "Yang Liu",
        "Yahui Zhou"
      ],
      "abstract": "In this report, we introduce a collection of methods to enhance reward\nmodeling for LLMs, focusing specifically on data-centric techniques. We propose\neffective data selection and filtering strategies for curating high-quality\nopen-source preference datasets, culminating in the Skywork-Reward data\ncollection, which contains only 80K preference pairs -- significantly smaller\nthan existing datasets. Using this curated dataset, we developed the\nSkywork-Reward model series -- Skywork-Reward-Gemma-27B and\nSkywork-Reward-Llama-3.1-8B -- with the former currently holding the top\nposition on the RewardBench leaderboard. Notably, our techniques and datasets\nhave directly enhanced the performance of many top-ranked models on\nRewardBench, highlighting the practical impact of our contributions in\nreal-world preference learning applications.",
      "tldr_zh": "该论文介绍了Skywork-Reward，一系列针对大型语言模型(LLMs)奖励建模的技巧，重点关注数据中心方法，包括有效的数据选择和过滤策略，以构建高质量的Skywork-Reward数据集，该数据集仅包含80K偏好对。利用这一数据集，他们开发了Skywork-Reward模型系列，如Skywork-Reward-Gemma-27B和Skywork-Reward-Llama-3.1-8B，其中Skywork-Reward-Gemma-27B目前在RewardBench排行榜上排名第一。这些方法不仅提升了模型性能，还直接改善了许多顶级模型在实际偏好学习应用中的表现。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18451v1",
      "published_date": "2024-10-24 06:06:26 UTC",
      "updated_date": "2024-10-24 06:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:20:29.830927"
    },
    {
      "arxiv_id": "2410.18441v1",
      "title": "The Nature of Mathematical Modeling and Probabilistic Optimization Engineering in Generative AI",
      "title_zh": "生成式 AI 中数学建模与概率优化工程的本质",
      "authors": [
        "Fulu Li"
      ],
      "abstract": "In this paper, we give an in-depth analysis on the mathematical problem\nformulations and the probabilistic optimization explorations for some of the\nkey components in Transformer model [33] in the field of generative AI. We\nexplore and discuss some potential further enhancement for current state of the\nart methods for some key underlying technologies of generative AI models from\nalgorithmic and probabilistic optimization perspective. In particular, we\npresent an optimal solution for sub-word encoding (SWE) based on similar\ninitial settings as that of byte-pair encoding (BPE) algorithm in [9] with\nsimilar objectives as that of WordPiece approach in [28, 31] to maximize the\nlikelihood of the training data. We also present cross entropy optimization\nmethod to optimize hyperparameters for word2vec model [17]. In addition, we\npropose a factored combination of rotary positional encoding (RoPE) [32] and\nattention with linear biases (ALiBi) [23] with a harmonic series. We also\npresent a probabilistic FlashAttention [6, 7] (PrFlashAttention) method with a\nprobability distribution over block distances in the matrix to decide which\nblock is likely to participate in a given round of attention computation while\nmaintaining the lower triangle shape of the tensor for autoregressive language\nmodels by re-shaping the tensors. Finally, we present staircase adaptive\nquantization (SAQ) of key-value (KV) cache for multi-query attention (MQA)\nbased on the framework presented in [16] to have gradual quantization\ndegradation while achieving reasonable model quality and cost savings.",
      "tldr_zh": "这篇论文深入分析了Transformer模型在生成式 AI 中的数学建模和概率优化问题，探讨了算法和概率优化视角下的潜在改进。\n\n作者提出了一种最优子词编码(SWE)解决方案，基于与BPE和WordPiece类似的目标，以最大化训练数据的似然。\n\n论文还介绍了交叉熵优化方法来调整word2vec模型的超参数，并提出Rotary Positional Encoding(RoPE)和Attention with Linear Biases(ALiBi)的组合优化。\n\n此外，他们开发了Probabilistic FlashAttention(PrFlashAttention)和Staircase Adaptive Quantization(SAQ)，以提升注意力计算效率和关键-值缓存的量化性能，同时平衡模型质量和成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18441v1",
      "published_date": "2024-10-24 05:29:20 UTC",
      "updated_date": "2024-10-24 05:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:18:48.830173"
    },
    {
      "arxiv_id": "2410.18406v1",
      "title": "MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases",
      "title_zh": "MoMQ：混合",
      "authors": [
        "Zhisheng Lin",
        "Yifu Liu",
        "Zhiling Luo",
        "Jinyang Gao",
        "Yu Li"
      ],
      "abstract": "The improvement in translating natural language to structured query language\n(SQL) can be attributed to the advancements in large language models (LLMs).\nOpen-source LLMs, tailored for specific database dialects such as MySQL, have\nshown great performance. However, cloud service providers are looking for a\nunified database manager service (e.g., Cosmos DB from Azure, Amazon Aurora\nfrom AWS, Lindorm from AlibabaCloud) that can support multiple dialects. This\nrequirement has led to the concept of multi-dialect query generation, which\npresents challenges to LLMs. These challenges include syntactic differences\namong dialects and imbalanced data distribution across multiple dialects. To\ntackle these challenges, we propose MoMQ, a novel Mixture-of-Experts-based\nmulti-dialect query generation framework across both relational and\nnon-relational databases. MoMQ employs a dialect expert group for each dialect\nand a multi-level routing strategy to handle dialect-specific knowledge,\nreducing interference during query generation. Additionally, a shared expert\ngroup is introduced to address data imbalance, facilitating the transfer of\ncommon knowledge from high-resource dialects to low-resource ones. Furthermore,\nwe have developed a high-quality multi-dialect query generation benchmark that\ncovers relational and non-relational databases such as MySQL, PostgreSQL,\nCypher for Neo4j, and nGQL for NebulaGraph. Extensive experiments have shown\nthat MoMQ performs effectively and robustly even in resource-imbalanced\nscenarios.",
      "tldr_zh": "本研究提出MoMQ框架，利用Mixture-of-Experts机制来提升大型语言模型（LLMs）在多方言查询生成方面的性能，针对关系型和非关系型数据库（如MySQL、PostgreSQL、Cypher for Neo4j和nGQL for NebulaGraph）的语法差异和数据分布不平衡问题。MoMQ包括每个方言的专家组、多级路由策略来处理特定知识，以及共享专家组来促进高资源方言知识向低资源方言的转移，从而减少干扰并提升生成效率。该框架在开发的高质量多方言查询生成基准上进行广泛实验，显示出在资源不平衡场景下显著的鲁棒性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18406v1",
      "published_date": "2024-10-24 03:42:43 UTC",
      "updated_date": "2024-10-24 03:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:21:01.473194"
    },
    {
      "arxiv_id": "2410.18385v2",
      "title": "Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Dae Yon Hwang",
        "Bilal Taha",
        "Harshit Pande",
        "Yaroslav Nechaev"
      ],
      "abstract": "Despite the recent advancements in information retrieval (IR), zero-shot IR\nremains a significant challenge, especially when dealing with new domains,\nlanguages, and newly-released use cases that lack historical query traffic from\nexisting users. For such cases, it is common to use query augmentations\nfollowed by fine-tuning pre-trained models on the document data paired with\nsynthetic queries. In this work, we propose a novel Universal Document Linking\n(UDL) algorithm, which links similar documents to enhance synthetic query\ngeneration across multiple datasets with different characteristics. UDL\nleverages entropy for the choice of similarity models and named entity\nrecognition (NER) for the link decision of documents using similarity scores.\nOur empirical studies demonstrate the effectiveness and universality of the UDL\nacross diverse datasets and IR models, surpassing state-of-the-art methods in\nzero-shot cases. The developed code for reproducibility is included in\nhttps://github.com/eoduself/UDL",
      "tldr_zh": "本研究针对零-shot 信息检索 (zero-shot IR) 在新领域、语言或用例中的挑战，提出了一种名为 Universal Document Linking (UDL) 的算法，通过链接类似文档来增强合成查询生成，从而适用于多种数据集。UDL 利用 entropy 选择相似性模型，并结合 named entity recognition (NER) 和相似性分数来决定文档链接决策。该方法在跨多样数据集和 IR 模型的实证研究中，超越了现有最先进技术，展示了其有效性和通用性；相关代码已在 GitHub 开源以便复现。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.18385v2",
      "published_date": "2024-10-24 02:52:19 UTC",
      "updated_date": "2024-10-25 02:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:19:11.322570"
    },
    {
      "arxiv_id": "2410.18374v1",
      "title": "Integrating Canonical Neural Units and Multi-Scale Training for Handwritten Text Recognition",
      "title_zh": "针对手写文本识别的规范神经单元整合与多尺度训练",
      "authors": [
        "Zi-Rui Wang"
      ],
      "abstract": "The segmentation-free research efforts for addressing handwritten text\nrecognition can be divided into three categories: connectionist temporal\nclassification (CTC), hidden Markov model and encoder-decoder methods. In this\npaper, inspired by the above three modeling methods, we propose a new\nrecognition network by using a novel three-dimensional (3D) attention module\nand global-local context information. Based on the feature maps of the last\nconvolutional layer, a series of 3D blocks with different resolutions are\nsplit. Then, these 3D blocks are fed into the 3D attention module to generate\nsequential visual features. Finally, by integrating the visual features and the\ncorresponding global-local context features, a well-designed representation can\nbe obtained. Main canonical neural units including attention mechanisms,\nfully-connected layer, recurrent unit and convolutional layer are efficiently\norganized into a network and can be jointly trained by the CTC loss and the\ncross-entropy loss. Experiments on the latest Chinese handwritten text datasets\n(the SCUT-HCCDoc and the SCUT-EPT) and one English handwritten text dataset\n(the IAM) show that the proposed method can make a new milestone.",
      "tldr_zh": "该论文提出了一种新的无分割手写文本识别方法，通过整合规范神经单元和多尺度训练，融合了 connectionist temporal classification (CTC)、hidden Markov model 和编码器-解码器方法的核心思想。方法的核心是使用三维 (3D) 注意力模块处理从最后一个卷积层分割出的不同分辨率 3D 块，并结合全局-局部上下文信息生成序列视觉特征。论文将注意力机制、fully-connected layer、recurrent unit 和 convolutional layer 等主要神经单元高效组织成网络，并通过 CTC loss 和 cross-entropy loss 联合训练。在 SCUT-HCCDoc、SCUT-EPT 和 IAM 数据集上的实验显示，该方法显著提升了识别性能，达到了新的里程碑。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18374v1",
      "published_date": "2024-10-24 02:33:12 UTC",
      "updated_date": "2024-10-24 02:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:19:25.729838"
    },
    {
      "arxiv_id": "2410.18371v2",
      "title": "Gibberish is All You Need for Membership Inference Detection in Contrastive Language-Audio Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxi Cheng",
        "Yizhong Ding",
        "Shuirong Cao",
        "Shitong Shao",
        "Zhiqiang Wang"
      ],
      "abstract": "Audio can disclose PII, particularly when combined with related text data.\nTherefore, it is essential to develop tools to detect privacy leakage in\nContrastive Language-Audio Pretraining(CLAP). Existing MIAs need audio as\ninput, risking exposure of voiceprint and requiring costly shadow models. We\nfirst propose PRMID, a membership inference detector based probability ranking\ngiven by CLAP, which does not require training shadow models but still requires\nboth audio and text of the individual as input. To address these limitations,\nwe then propose USMID, a textual unimodal speaker-level membership inference\ndetector, querying the target model using only text data. We randomly generate\ntextual gibberish that are clearly not in training dataset. Then we extract\nfeature vectors from these texts using the CLAP model and train a set of\nanomaly detectors on them. During inference, the feature vector of each test\ntext is input into the anomaly detector to determine if the speaker is in the\ntraining set (anomalous) or not (normal). If available, USMID can further\nenhance detection by integrating real audio of the tested speaker. Extensive\nexperiments on various CLAP model architectures and datasets demonstrate that\nUSMID outperforms baseline methods using only text data.",
      "tldr_zh": "这篇论文针对 Contrastive Language-Audio Pretraining (CLAP) 中的隐私泄露问题，提出两种成员推断检测方法，以避免音频输入带来的风险。PRMID 基于 CLAP 的概率排名进行检测，不需要训练影子模型，但仍需音频和文本作为输入；USMID 则是一种仅使用文本数据的单模态检测器，通过生成随机文本乱码 (gibberish) 提取特征向量并训练异常检测器，来判断说话者是否在训练集中。如果有可用音频，USMID 可进一步整合以提升性能。实验在多种 CLAP 模型和数据集上证明，USMID 使用仅文本数据时优于基线方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18371v2",
      "published_date": "2024-10-24 02:26:57 UTC",
      "updated_date": "2024-11-02 10:00:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:19:38.516999"
    },
    {
      "arxiv_id": "2410.18368v1",
      "title": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Runzhen Xue",
        "Hao Wu",
        "Mingyu Yan",
        "Ziheng Xiao",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Design space exploration (DSE) enables architects to systematically evaluate\nvarious design options, guiding decisions on the most suitable configurations\nto meet specific objectives such as optimizing performance, power, and area.\nHowever, the growing complexity of modern CPUs has dramatically increased the\nnumber of micro-architectural parameters and expanded the overall design space,\nmaking DSE more challenging and time-consuming. Existing DSE frameworks\nstruggle in large-scale design spaces due to inaccurate models and limited\ninsights into parameter impact, hindering efficient identification of optimal\nmicro-architectures within tight timeframes.\n  In this work, we introduce AttentionDSE. Its key idea is to use the attention\nmechanism to establish a direct mapping of micro-architectural parameters to\ntheir contributions to predicted performance. This approach enhances both the\nprediction accuracy and interpretability of the performance model. Furthermore,\nthe weights are dynamically adjusted, enabling the model to respond to design\nchanges and effectively pinpoint the key micro-architectural\nparameters/components responsible for performance bottlenecks. Thus,\nAttentionDSE accurately, purposefully, and rapidly discovers optimal designs.\nExperiments on SPEC 2017 demonstrate that AttentionDSE significantly reduces\nexploration time by over 80\\% and achieves 3.9\\% improvement in Pareto\nHypervolume compared to state-of-the-art DSE frameworks while maintaining\nsuperior prediction accuracy and efficiency with an increasing number of\nparameters.",
      "tldr_zh": "该研究针对 CPU 设计空间探索 (DSE) 的多目标优化问题，指出现有框架在处理复杂微架构参数时面临模型不准确和探索时间长的挑战。AttentionDSE 框架引入 attention 机制，直接映射微架构参数对性能的贡献，并动态调整权重，以提升预测准确性和可解释性，从而快速识别性能瓶颈和最佳设计。实验在 SPEC 2017 基准上显示，AttentionDSE 比现有框架减少探索时间超过 80%，Pareto Hypervolume 改善 3.9%，实现了高效的多目标优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18368v1",
      "published_date": "2024-10-24 02:20:17 UTC",
      "updated_date": "2024-10-24 02:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:21:13.085106"
    },
    {
      "arxiv_id": "2410.18363v1",
      "title": "Contextual Biasing to Improve Domain-specific Custom Vocabulary Audio Transcription without Explicit Fine-Tuning of Whisper Model",
      "title_zh": "翻译失败",
      "authors": [
        "Vishakha Lall",
        "Yisi Liu"
      ],
      "abstract": "OpenAI's Whisper Automated Speech Recognition model excels in generalizing\nacross diverse datasets and domains. However, this broad adaptability can lead\nto diminished performance in tasks requiring recognition of specific\nvocabularies. Addressing this challenge typically involves fine-tuning the\nmodel, which demands extensive labeled audio data that is often difficult to\nacquire and unavailable for specific domains. In this study, we propose a\nmethod to enhance transcription accuracy without explicit fine-tuning or\naltering model parameters, using a relatively small training dataset. Our\nmethod leverages contextual biasing, to direct Whisper model's output towards a\nspecific vocabulary by integrating a neural-symbolic prefix tree structure to\nguide the model's transcription output. To validate our approach, we conducted\nexperiments using a validation dataset comprising maritime data collected\nwithin a simulated training environment. A comparison between the original\nWhisper models of varying parameter sizes and our biased model revealed a\nnotable reduction in transcription word error rate and enhanced performance of\ndownstream applications. Our findings suggest that this methodology holds\npromise for improving speech-to-text translation performance in domains\ncharacterized by limited vocabularies.",
      "tldr_zh": "本研究针对OpenAI的Whisper模型在特定词汇识别上的性能下降问题，提出了一种无需显式fine-tuning的方法，利用contextual biasing技术来提升领域特定音频转录准确性。该方法通过整合neural-symbolic prefix tree结构引导模型输出，仅需较小数据集即可实现，而不改变模型参数。在模拟的maritime数据集实验中，与原始Whisper模型相比，该偏置模型显著降低了transcription word error rate，并提升了下游应用性能。该方法为词汇有限的领域提供了一种高效的speech-to-text优化策略。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18363v1",
      "published_date": "2024-10-24 01:58:11 UTC",
      "updated_date": "2024-10-24 01:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:21:25.184010"
    },
    {
      "arxiv_id": "2410.18345v1",
      "title": "Geometric Feature Enhanced Knowledge Graph Embedding and Spatial Reasoning",
      "title_zh": "几何特征增强的知识图谱嵌入与空间推理",
      "authors": [
        "Lei Hu",
        "Wenwen Li",
        "Yunqiang Zhu"
      ],
      "abstract": "Geospatial Knowledge Graphs (GeoKGs) model geoentities (e.g., places and\nnatural features) and spatial relationships in an interconnected manner,\nproviding strong knowledge support for geographic applications, including data\nretrieval, question-answering, and spatial reasoning. However, existing methods\nfor mining and reasoning from GeoKGs, such as popular knowledge graph embedding\n(KGE) techniques, lack geographic awareness. This study aims to enhance\ngeneral-purpose KGE by developing new strategies and integrating geometric\nfeatures of spatial relations, including topology, direction, and distance, to\ninfuse the embedding process with geographic intuition. The new model is tested\non downstream link prediction tasks, and the results show that the inclusion of\ngeometric features, particularly topology and direction, improves prediction\naccuracy for both geoentities and spatial relations. Our research offers new\nperspectives for integrating spatial concepts and principles into the GeoKG\nmining process, providing customized GeoAI solutions for geospatial challenges.",
      "tldr_zh": "本研究针对Geospatial Knowledge Graphs (GeoKGs)中的地理实体和空间关系，提出了一种增强Knowledge Graph Embedding (KGE)的方法，通过整合几何特征如topology、direction和distance，来注入地理直觉并提升KGE的地理感知能力。新的策略在KGE嵌入过程中融合这些特征，针对下游链接预测任务进行测试，结果显示topology和direction特征显著提高了预测准确率。总体而言，该工作为GeoKG挖掘提供了新视角，并为地理应用挑战提供了定制的GeoAI解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 1 figure, Accepted for the 7th ACM SIGSPATIAL International\n  Workshop on AI for Geographic Knowledge Discovery",
      "pdf_url": "http://arxiv.org/pdf/2410.18345v1",
      "published_date": "2024-10-24 00:53:48 UTC",
      "updated_date": "2024-10-24 00:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:21:37.007084"
    },
    {
      "arxiv_id": "2410.18344v1",
      "title": "Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models",
      "title_zh": "聚合知识模型：利用微调和检索增强生成模型增强特定领域的问答系统",
      "authors": [
        "Fengchen Liu",
        "Jordan Jung",
        "Wei Feinstein",
        "Jeff DAmbrogia",
        "Gary Jung"
      ],
      "abstract": "This paper introduces a novel approach to enhancing closed-domain Question\nAnswering (QA) systems, focusing on the specific needs of the Lawrence Berkeley\nNational Laboratory (LBL) Science Information Technology (ScienceIT) domain.\nUtilizing a rich dataset derived from the ScienceIT documentation, our study\nembarks on a detailed comparison of two fine-tuned large language models and\nfive retrieval-augmented generation (RAG) models. Through data processing\ntechniques, we transform the documentation into structured\ncontext-question-answer triples, leveraging the latest Large Language Models\n(AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for\ndata-driven insights. Additionally, we introduce the Aggregated Knowledge Model\n(AKM), which synthesizes responses from the seven models mentioned above using\nK-means clustering to select the most representative answers. The evaluation of\nthese models across multiple metrics offers a comprehensive look into their\neffectiveness and suitability for the LBL ScienceIT environment. The results\ndemonstrate the potential benefits of integrating fine-tuning and\nretrieval-augmented strategies, highlighting significant performance\nimprovements achieved with the AKM. The insights gained from this study can be\napplied to develop specialized QA systems tailored to specific domains.",
      "tldr_zh": "本研究提出了一种增强特定领域问答（QA）系统的方法，针对 Lawrence Berkeley National Laboratory (LBL) 的 ScienceIT 领域，利用 ScienceIT 文档数据集比较两种微调的大型语言模型（LLMs）和五种检索增强生成（RAG）模型。研究通过数据处理将文档转化为结构化的上下文-问题-答案三元组，并引入 Aggregated Knowledge Model (AKM)，该模型使用 K-means clustering 聚合七个模型（如 AWS Bedrock、GCP PaLM2、Meta LLaMA2、OpenAI GPT-4 和 Google Gemini-Pro）的响应，以选择最具代表性的答案。实验结果显示，AKM 在多指标评估中显著提升了性能，证明了整合微调和 RAG 策略的有效性，并为开发定制化领域 QA 系统提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18344v1",
      "published_date": "2024-10-24 00:49:46 UTC",
      "updated_date": "2024-10-24 00:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:21:49.599920"
    },
    {
      "arxiv_id": "2410.18336v1",
      "title": "Assessing the Creativity of LLMs in Proposing Novel Solutions to Mathematical Problems",
      "title_zh": "评估 LLMs 在提出数学问题新颖解决方案方面的创造力",
      "authors": [
        "Junyi Ye",
        "Jingyi Gu",
        "Xinyun Zhao",
        "Wenpeng Yin",
        "Guiling Wang"
      ],
      "abstract": "The mathematical capabilities of AI systems are complex and multifaceted.\nMost existing research has predominantly focused on the correctness of\nAI-generated solutions to mathematical problems. In this work, we argue that\nbeyond producing correct answers, AI systems should also be capable of, or\nassist humans in, developing novel solutions to mathematical challenges. This\nstudy explores the creative potential of Large Language Models (LLMs) in\nmathematical reasoning, an aspect that has received limited attention in prior\nresearch. We introduce a novel framework and benchmark, CreativeMath, which\nencompasses problems ranging from middle school curricula to Olympic-level\ncompetitions, designed to assess LLMs' ability to propose innovative solutions\nafter some known solutions have been provided. Our experiments demonstrate\nthat, while LLMs perform well on standard mathematical tasks, their capacity\nfor creative problem-solving varies considerably. Notably, the Gemini-1.5-Pro\nmodel outperformed other LLMs in generating novel solutions. This research\nopens a new frontier in evaluating AI creativity, shedding light on both the\nstrengths and limitations of LLMs in fostering mathematical innovation, and\nsetting the stage for future developments in AI-assisted mathematical\ndiscovery.",
      "tldr_zh": "本研究评估了大语言模型（LLMs）在提出数学问题新颖解决方案方面的创造力，强调AI不仅仅需提供正确答案，还应辅助创新。研究引入了CreativeMath框架和基准，涵盖从中学到奥林匹克级别的数学问题，测试LLMs在已知解决方案基础上生成创新想法的能力。实验结果显示，LLMs在标准任务中表现良好，但创造力差异显著，其中Gemini-1.5-Pro模型领先；这项工作揭示了LLMs的潜力与局限性，为AI辅助数学创新开辟了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18336v1",
      "published_date": "2024-10-24 00:12:49 UTC",
      "updated_date": "2024-10-24 00:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:22:00.332788"
    },
    {
      "arxiv_id": "2410.18333v2",
      "title": "Search-Based Path Planning in Interactive Environments among Movable Obstacles",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongqiang Ren",
        "Bunyod Suvonov",
        "Guofei Chen",
        "Botao He",
        "Yijie Liao",
        "Cornelia Fermuller",
        "Ji Zhang"
      ],
      "abstract": "This paper investigates Path planning Among Movable Obstacles (PAMO), which\nseeks a minimum cost collision-free path among static obstacles from start to\ngoal while allowing the robot to push away movable obstacles (i.e., objects)\nalong its path when needed. To develop planners that are complete and optimal\nfor PAMO, the planner has to search a giant state space involving both the\nlocation of the robot as well as the locations of the objects, which grows\nexponentially with respect to the number of objects. This paper leverages a\nsimple yet under-explored idea that, only a small fraction of this giant state\nspace needs to be searched during planning as guided by a heuristic, and most\nof the objects far away from the robot are intact, which thus leads to runtime\nefficient algorithms. Based on this idea, this paper introduces two PAMO\nformulations, i.e., bi-objective and resource constrained problems in an\noccupancy grid, and develops PAMO*, a planning method with completeness and\nsolution optimality guarantees, to solve the two problems. We then further\nextend PAMO* to hybrid-state PAMO* to plan in continuous spaces with\nhigh-fidelity interaction between the robot and the objects. Our results show\nthat, PAMO* can often find optimal solutions within a second in cluttered maps\nwith up to 400 objects.",
      "tldr_zh": "这篇论文研究了Path Planning Among Movable Obstacles (PAMO)问题，即机器人从起点到终点规划最小成本无碰撞路径，同时允许推动可移动障碍物。论文提出PAMO*算法，通过启发式引导仅搜索必要状态空间，避免探索巨大量状态，从而实现高效规划，并解决了bi-objective和resource constrained问题，具有完整性和最优性保证。该算法扩展到hybrid-state PAMO*，适用于连续空间中的高保真机器人与物体交互。实验结果显示，在杂乱地图中包含多达400个物体时，PAMO*通常能在1秒内找到最优解。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18333v2",
      "published_date": "2024-10-24 00:02:58 UTC",
      "updated_date": "2025-03-06 05:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:22:19.970877"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 116,
  "processed_papers_count": 116,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T16:22:40.759705"
}