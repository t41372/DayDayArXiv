[
  {
    "arxiv_id": "2410.21315v1",
    "title": "GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization",
    "authors": [
      "Margarita Bugueño",
      "Hazem Abou Hamdan",
      "Gerard de Melo"
    ],
    "abstract": "Heterogeneous graph neural networks have recently gained attention for long\ndocument summarization, modeling the extraction as a node classification task.\nAlthough effective, these models often require external tools or additional\nmachine learning models to define graph components, producing highly complex\nand less intuitive structures. We present GraphLSS, a heterogeneous graph\nconstruction for long document extractive summarization, incorporating Lexical,\nStructural, and Semantic features. It defines two levels of information (words\nand sentences) and four types of edges (sentence semantic similarity, sentence\noccurrence order, word in sentence, and word semantic similarity) without any\nneed for auxiliary learning models. Experiments on two benchmark datasets show\nthat GraphLSS is competitive with top-performing graph-based methods,\noutperforming recent non-graph models. We release our code on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Short paper submitted to ACL ARR November cycle",
    "pdf_url": "http://arxiv.org/pdf/2410.21315v1",
    "published_date": "2024-10-25 23:48:59 UTC",
    "updated_date": "2024-10-25 23:48:59 UTC"
  },
  {
    "arxiv_id": "2410.20007v1",
    "title": "Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models",
    "authors": [
      "Danqing Wang",
      "Zhuorui Ye",
      "Fei Fang",
      "Lei Li"
    ],
    "abstract": "Enhancing the reasoning capabilities of large language models (LLMs) is\ncrucial for enabling them to tackle complex, multi-step problems. Multi-agent\nframeworks have shown great potential in enhancing LLMs' reasoning\ncapabilities. However, the lack of effective cooperation between LLM agents\nhinders their performance, especially for multi-step reasoning tasks. This\npaper proposes a novel cooperative multi-agent reasoning framework (CoPlanner)\nby separating reasoning steps and assigning distinct duties to different\nagents. CoPlanner consists of two LLM agents: a planning agent and a reasoning\nagent. The planning agent provides high-level strategic hints, while the\nreasoning agent follows these hints and infers answers. By training the\nplanning agent's policy through the interactive reasoning process via Proximal\nPolicy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the\nprevious best method by 9.94\\% on LogiQA and 3.09\\% on BBH. Our results\ndemonstrate that the guidance from the planning agent and the effective\ncooperation between the agents contribute to the superior performance of\nCoPlanner in tackling multi-step reasoning problems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2410.20007v1",
    "published_date": "2024-10-25 23:32:48 UTC",
    "updated_date": "2024-10-25 23:32:48 UTC"
  },
  {
    "arxiv_id": "2410.20005v1",
    "title": "Enhancing Battery Storage Energy Arbitrage with Deep Reinforcement Learning and Time-Series Forecasting",
    "authors": [
      "Manuel Sage",
      "Joshua Campbell",
      "Yaoyao Fiona Zhao"
    ],
    "abstract": "Energy arbitrage is one of the most profitable sources of income for battery\noperators, generating revenues by buying and selling electricity at different\nprices. Forecasting these revenues is challenging due to the inherent\nuncertainty of electricity prices. Deep reinforcement learning (DRL) emerged in\nrecent years as a promising tool, able to cope with uncertainty by training on\nlarge quantities of historical data. However, without access to future\nelectricity prices, DRL agents can only react to the currently observed price\nand not learn to plan battery dispatch. Therefore, in this study, we combine\nDRL with time-series forecasting methods from deep learning to enhance the\nperformance on energy arbitrage. We conduct a case study using price data from\nAlberta, Canada that is characterized by irregular price spikes and highly\nnon-stationary. This data is challenging to forecast even when state-of-the-art\ndeep learning models consisting of convolutional layers, recurrent layers, and\nattention modules are deployed. Our results show that energy arbitrage with\nDRL-enabled battery control still significantly benefits from these imperfect\npredictions, but only if predictors for several horizons are combined. Grouping\nmultiple predictions for the next 24-hour window, accumulated rewards increased\nby 60% for deep Q-networks (DQN) compared to the experiments without forecasts.\nWe hypothesize that multiple predictors, despite their imperfections, convey\nuseful information regarding the future development of electricity prices\nthrough a \"majority vote\" principle, enabling the DRL agent to learn more\nprofitable control policies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.OS",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at the 18th ASME International Conference on\n  Energy Sustainability",
    "pdf_url": "http://arxiv.org/pdf/2410.20005v1",
    "published_date": "2024-10-25 23:18:43 UTC",
    "updated_date": "2024-10-25 23:18:43 UTC"
  },
  {
    "arxiv_id": "2410.19998v1",
    "title": "Artificial Intelligence of Things: A Survey",
    "authors": [
      "Shakhrul Iman Siam",
      "Hyunho Ahn",
      "Li Liu",
      "Samiul Alam",
      "Hui Shen",
      "Zhichao Cao",
      "Ness Shroff",
      "Bhaskar Krishnamachari",
      "Mani Srivastava",
      "Mi Zhang"
    ],
    "abstract": "The integration of the Internet of Things (IoT) and modern Artificial\nIntelligence (AI) has given rise to a new paradigm known as the Artificial\nIntelligence of Things (AIoT). In this survey, we provide a systematic and\ncomprehensive review of AIoT research. We examine AIoT literature related to\nsensing, computing, and networking & communication, which form the three key\ncomponents of AIoT. In addition to advancements in these areas, we review\ndomain-specific AIoT systems that are designed for various important\napplication domains. We have also created an accompanying GitHub repository,\nwhere we compile the papers included in this survey:\nhttps://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively\nmaintained and updated with new research as it becomes available. As both IoT\nand AI become increasingly critical to our society, we believe AIoT is emerging\nas an essential research field at the intersection of IoT and modern AI. We\nhope this survey will serve as a valuable resource for those engaged in AIoT\nresearch and act as a catalyst for future explorations to bridge gaps and drive\nadvancements in this exciting field.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted in ACM Transactions on Sensor Networks (TOSN)",
    "pdf_url": "http://arxiv.org/pdf/2410.19998v1",
    "published_date": "2024-10-25 22:45:58 UTC",
    "updated_date": "2024-10-25 22:45:58 UTC"
  },
  {
    "arxiv_id": "2410.19982v3",
    "title": "Random Policy Enables In-Context Reinforcement Learning within Trust Horizons",
    "authors": [
      "Weiqin Chen",
      "Santiago Paternain"
    ],
    "abstract": "Pretrained foundation models have exhibited extraordinary in-context learning\nperformance, allowing zero-shot generalization to new tasks not encountered\nduring pretraining. In the case of reinforcement learning (RL), in-context RL\n(ICRL) emerges when pretraining FMs on decision-making problems in an\nautoregressive-supervised manner. Nevertheless, current state-of-the-art ICRL\nalgorithms, like Algorithm Distillation, Decision Pretrained Transformer and\nDecision Importance Transformer, impose stringent requirements on the\npretraining dataset concerning the source policies, context information, and\naction labels. Notably, these algorithms either demand optimal policies or\nrequire varying degrees of well-trained behavior policies for all pretraining\nenvironments. This significantly hinders the application of ICRL to real-world\nscenarios, where acquiring optimal or well-trained policies for a substantial\nvolume of real-world training environments can be intractable. To overcome this\nchallenge, we introduce a novel approach, termed State-Action Distillation\n(SAD), that allows to generate an effective pretraining dataset guided solely\nby random policies. In particular, SAD selects query states and corresponding\naction labels by distilling outstanding state-action pairs from the entire\nstate and action spaces by using random policies within a trust horizon, and\nthen inherits the classical autoregressive-supervised mechanism during\npretraining. To the best of our knowledge, this is the first work that enables\neffective ICRL under random policies and random contexts. We also establish\nquantitative analysis of the trustworthiness as well as the performance\nguarantees of SAD. Moreover, our empirical results across multiple popular ICRL\nbenchmark environments demonstrate that, on average, SAD outperforms the best\nbaseline by 236.3% in the offline evaluation and by 135.2% in the online\nevaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19982v3",
    "published_date": "2024-10-25 21:46:25 UTC",
    "updated_date": "2025-05-02 03:19:49 UTC"
  },
  {
    "arxiv_id": "2410.21314v2",
    "title": "Decoding Diffusion: A Scalable Framework for Unsupervised Analysis of Latent Space Biases and Representations Using Natural Language Prompts",
    "authors": [
      "E. Zhixuan Zeng",
      "Yuhao Chen",
      "Alexander Wong"
    ],
    "abstract": "Recent advances in image generation have made diffusion models powerful tools\nfor creating high-quality images. However, their iterative denoising process\nmakes understanding and interpreting their semantic latent spaces more\nchallenging than other generative models, such as GANs. Recent methods have\nattempted to address this issue by identifying semantically meaningful\ndirections within the latent space. However, they often need manual\ninterpretation or are limited in the number of vectors that can be trained,\nrestricting their scope and utility. This paper proposes a novel framework for\nunsupervised exploration of diffusion latent spaces. We directly leverage\nnatural language prompts and image captions to map latent directions. This\nmethod allows for the automatic understanding of hidden features and supports a\nbroader range of analysis without the need to train specific vectors. Our\nmethod provides a more scalable and interpretable understanding of the semantic\nknowledge encoded within diffusion models, facilitating comprehensive analysis\nof latent biases and the nuanced representations these models learn.\nExperimental results show that our framework can uncover hidden patterns and\nassociations in various domains, offering new insights into the\ninterpretability of diffusion model latent spaces.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21314v2",
    "published_date": "2024-10-25 21:44:51 UTC",
    "updated_date": "2024-11-04 19:12:54 UTC"
  },
  {
    "arxiv_id": "2410.19965v1",
    "title": "OReole-FM: successes and challenges toward billion-parameter foundation models for high-resolution satellite imagery",
    "authors": [
      "Philipe Dias",
      "Aristeidis Tsaris",
      "Jordan Bowman",
      "Abhishek Potnis",
      "Jacob Arndt",
      "H. Lexie Yang",
      "Dalton Lunga"
    ],
    "abstract": "While the pretraining of Foundation Models (FMs) for remote sensing (RS)\nimagery is on the rise, models remain restricted to a few hundred million\nparameters. Scaling models to billions of parameters has been shown to yield\nunprecedented benefits including emergent abilities, but requires data scaling\nand computing resources typically not available outside industry R&D labs. In\nthis work, we pair high-performance computing resources including Frontier\nsupercomputer, America's first exascale system, and high-resolution optical RS\ndata to pretrain billion-scale FMs. Our study assesses performance of different\npretrained variants of vision Transformers across image classification,\nsemantic segmentation and object detection benchmarks, which highlight the\nimportance of data scaling for effective model scaling. Moreover, we discuss\nconstruction of a novel TIU pretraining dataset, model initialization, with\ndata and pretrained models intended for public release. By discussing technical\nchallenges and details often lacking in the related literature, this work is\nintended to offer best practices to the geospatial community toward efficient\ntraining and benchmarking of larger FMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19965v1",
    "published_date": "2024-10-25 20:55:12 UTC",
    "updated_date": "2024-10-25 20:55:12 UTC"
  },
  {
    "arxiv_id": "2410.19964v1",
    "title": "Understanding Adam Requires Better Rotation Dependent Assumptions",
    "authors": [
      "Lucas Maes",
      "Tianyue H. Zhang",
      "Alexia Jolicoeur-Martineau",
      "Ioannis Mitliagkas",
      "Damien Scieur",
      "Simon Lacoste-Julien",
      "Charles Guille-Escuret"
    ],
    "abstract": "Despite its widespread adoption, Adam's advantage over Stochastic Gradient\nDescent (SGD) lacks a comprehensive theoretical explanation. This paper\ninvestigates Adam's sensitivity to rotations of the parameter space. We\ndemonstrate that Adam's performance in training transformers degrades under\nrandom rotations of the parameter space, indicating a crucial sensitivity to\nthe choice of basis. This reveals that conventional rotation-invariant\nassumptions are insufficient to capture Adam's advantages theoretically. To\nbetter understand the rotation-dependent properties that benefit Adam, we also\nidentify structured rotations that preserve or even enhance its empirical\nperformance. We then examine the rotation-dependent assumptions in the\nliterature, evaluating their adequacy in explaining Adam's behavior across\nvarious rotation types. This work highlights the need for new,\nrotation-dependent theoretical frameworks to fully understand Adam's empirical\nsuccess in modern machine learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19964v1",
    "published_date": "2024-10-25 20:53:03 UTC",
    "updated_date": "2024-10-25 20:53:03 UTC"
  },
  {
    "arxiv_id": "2410.21313v1",
    "title": "Towards Robust Out-of-Distribution Generalization: Data Augmentation and Neural Architecture Search Approaches",
    "authors": [
      "Haoyue Bai"
    ],
    "abstract": "Deep learning has been demonstrated with tremendous success in recent years.\nDespite so, its performance in practice often degenerates drastically when\nencountering out-of-distribution (OoD) data, i.e. training and test data are\nsampled from different distributions. In this thesis, we study ways toward\nrobust OoD generalization for deep learning, i.e., its performance is not\nsusceptible to distribution shift in the test data.\n  We first propose a novel and effective approach to disentangle the spurious\ncorrelation between features that are not essential for recognition. It employs\ndecomposed feature representation by orthogonalizing the two gradients of\nlosses for category and context branches. Furthermore, we perform\ngradient-based augmentation on context-related features (e.g., styles,\nbackgrounds, or scenes of target objects) to improve the robustness of learned\nrepresentations. Results show that our approach generalizes well for different\ndistribution shifts.\n  We then study the problem of strengthening neural architecture search in OoD\nscenarios. We propose to optimize the architecture parameters that minimize the\nvalidation loss on synthetic OoD data, under the condition that corresponding\nnetwork parameters minimize the training loss. Moreover, to obtain a proper\nvalidation set, we learn a conditional generator by maximizing their losses\ncomputed by different neural architectures. Results show that our approach\neffectively discovers robust architectures that perform well for OoD\ngeneralization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Hong Kong University of Science and Technology Thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.21313v1",
    "published_date": "2024-10-25 20:50:32 UTC",
    "updated_date": "2024-10-25 20:50:32 UTC"
  },
  {
    "arxiv_id": "2410.19955v2",
    "title": "Bridging Stepwise Lab-Informed Pretraining and Knowledge-Guided Learning for Diagnostic Reasoning",
    "authors": [
      "Pengfei Hu",
      "Chang Lu",
      "Fei Wang",
      "Yue Ning"
    ],
    "abstract": "Despite the growing use of Electronic Health Records (EHR) for AI-assisted\ndiagnosis prediction, most data-driven models struggle to incorporate\nclinically meaningful medical knowledge. They often rely on limited ontologies,\nlacking structured reasoning capabilities and comprehensive coverage. This\nraises an important research question: Will medical knowledge improve\npredictive models to support stepwise clinical reasoning as performed by human\ndoctors? To address this problem, we propose DuaLK, a dual-expertise framework\nthat combines two complementary sources of information. For external knowledge,\nwe construct a Diagnosis Knowledge Graph (KG) that encodes both hierarchical\nand semantic relations enriched by large language models (LLM). To align with\npatient data, we further introduce a lab-informed proxy task that guides the\nmodel to follow a clinically consistent, stepwise reasoning process based on\nlab test signals. Experimental results on two public EHR datasets demonstrate\nthat DuaLK consistently outperforms existing baselines across four clinical\nprediction tasks. These findings highlight the potential of combining\nstructured medical knowledge with individual-level clinical signals to achieve\nmore accurate and interpretable diagnostic predictions. The source code is\npublicly available on https://github.com/humphreyhuu/DuaLK.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19955v2",
    "published_date": "2024-10-25 20:25:22 UTC",
    "updated_date": "2025-04-15 23:36:25 UTC"
  },
  {
    "arxiv_id": "2411.08881v2",
    "title": "Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI",
    "authors": [
      "José Antonio Siqueira de Cerqueira",
      "Mamia Agbese",
      "Rebekah Rousi",
      "Nannan Xi",
      "Juho Hamari",
      "Pekka Abrahamsson"
    ],
    "abstract": "AI-based systems, including Large Language Models (LLM), impact millions by\nsupporting diverse tasks but face issues like misinformation, bias, and misuse.\nAI ethics is crucial as new technologies and concerns emerge, but objective,\npractical guidance remains debated. This study examines the use of LLMs for AI\nethics in practice, assessing how LLM trustworthiness-enhancing techniques\naffect software development in this context. Using the Design Science Research\n(DSR) method, we identify techniques for LLM trustworthiness: multi-agents,\ndistinct roles, structured communication, and multiple rounds of debate. We\ndesign a multi-agent prototype LLM-MAS, where agents engage in structured\ndiscussions on real-world AI ethics issues from the AI Incident Database. We\nevaluate the prototype across three case scenarios using thematic analysis,\nhierarchical clustering, comparative (baseline) studies, and running source\ncode. The system generates approximately 2,000 lines of code per case, compared\nto only 80 lines in baseline trials. Discussions reveal terms like bias\ndetection, transparency, accountability, user consent, GDPR compliance,\nfairness evaluation, and EU AI Act compliance, showing this prototype ability\nto generate extensive source code and documentation addressing often overlooked\nAI ethics issues. However, practical challenges in source code integration and\ndependency management may limit its use by practitioners.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; K.6.3"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08881v2",
    "published_date": "2024-10-25 20:17:59 UTC",
    "updated_date": "2025-05-16 13:05:27 UTC"
  },
  {
    "arxiv_id": "2410.19948v1",
    "title": "Assessing the societal influence of academic research with ChatGPT: Impact case study evaluations",
    "authors": [
      "Kayvan Kousha",
      "Mike Thelwall"
    ],
    "abstract": "Academics and departments are sometimes judged by how their research has\nbenefitted society. For example, the UK Research Excellence Framework (REF)\nassesses Impact Case Studies (ICS), which are five-page evidence-based claims\nof societal impacts. This study investigates whether ChatGPT can evaluate\nsocietal impact claims and therefore potentially support expert human\nassessors. For this, various parts of 6,220 public ICS from REF2021 were fed to\nChatGPT 4o-mini along with the REF2021 evaluation guidelines, comparing the\nresults with published departmental average ICS scores. The results suggest\nthat the optimal strategy for high correlations with expert scores is to input\nthe title and summary of an ICS but not the remaining text, and to modify the\noriginal REF guidelines to encourage a stricter evaluation. The scores\ngenerated by this approach correlated positively with departmental average\nscores in all 34 Units of Assessment (UoAs), with values between 0.18\n(Economics and Econometrics) and 0.56 (Psychology, Psychiatry and\nNeuroscience). At the departmental level, the corresponding correlations were\nhigher, reaching 0.71 for Sport and Exercise Sciences, Leisure and Tourism.\nThus, ChatGPT-based ICS evaluations are simple and viable to support or\ncross-check expert judgments, although their value varies substantially between\nfields.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19948v1",
    "published_date": "2024-10-25 19:51:10 UTC",
    "updated_date": "2024-10-25 19:51:10 UTC"
  },
  {
    "arxiv_id": "2410.19940v1",
    "title": "Cobblestone: Iterative Automation for Formal Verification",
    "authors": [
      "Saketh Ram Kasibatla",
      "Arpan Agarwal",
      "Yuriy Brun",
      "Sorin Lerner",
      "Talia Ringer",
      "Emily First"
    ],
    "abstract": "Formal verification using proof assistants, such as Coq, is an effective way\nof improving software quality, but it is expensive. Writing proofs manually\nrequires both significant effort and expertise. Recent research has used\nmachine learning to automatically synthesize proofs, reducing verification\neffort, but these tools are able to prove only a fraction of the desired\nsoftware properties. We introduce Cobblestone, a new proof-synthesis approach\nthat improves on the state of the art by taking advantage of partial progress\nin proof synthesis attempts. Unlike prior tools, Cobblestone can produce\nmultiple unsuccessful proofs using a large language model (LLM), identify the\nworking portions of those proofs, and combine them into a single, successful\nproof, taking advantage of internal partial progress. We evaluate Cobblestone\non two benchmarks of open-source Coq projects, controlling for training data\nleakage in LLM datasets. Fully automatically, Cobblestone can prove 48% of the\ntheorems, while Proverbot9001, the previous state-of-the-art, learning-based,\nproof-synthesis tool, can prove 17%. Cobblestone establishes a new state of the\nart for fully automated proof synthesis tools for Coq. We also evaluate\nCobblestone in a setting where it is given external partial proof progress from\noracles, serving as proxies for a human proof engineer or another tool. When\nthe theorem is broken down into a set of subgoals and Cobblestone is given a\nset of relevant lemmas already proven in the project, it can prove up to 58% of\nthe theorems. We qualitatively study the theorems Cobblestone is and is not\nable to prove to outline potential future research directions to further\nimprove proof synthesis, including developing interactive, semi-automated\ntools. Our research shows that tools can make better use of partial progress\nmade during proof synthesis to more effectively automate formal verification.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "13 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19940v1",
    "published_date": "2024-10-25 19:25:00 UTC",
    "updated_date": "2024-10-25 19:25:00 UTC"
  },
  {
    "arxiv_id": "2410.19937v1",
    "title": "RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction",
    "authors": [
      "Tanqiu Jiang",
      "Zian Wang",
      "Jiacheng Liang",
      "Changjiang Li",
      "Yuhui Wang",
      "Ting Wang"
    ],
    "abstract": "Jailbreak attacks circumvent LLMs' built-in safeguards by concealing harmful\nqueries within jailbreak prompts. While existing defenses primarily focus on\nmitigating the effects of jailbreak prompts, they often prove inadequate as\njailbreak prompts can take arbitrary, adaptive forms. This paper presents\nRobustKV, a novel defense that adopts a fundamentally different approach by\nselectively removing critical tokens of harmful queries from key-value (KV)\ncaches. Intuitively, for a jailbreak prompt to be effective, its tokens must\nachieve sufficient `importance' (as measured by attention scores), which\ninevitably lowers the importance of tokens in the concealed harmful query.\nThus, by strategically evicting the KVs of the lowest-ranked tokens, RobustKV\ndiminishes the presence of the harmful query in the KV cache, thus preventing\nthe LLM from generating malicious responses. Extensive evaluation using\nbenchmark datasets and models demonstrates that RobustKV effectively counters\nstate-of-the-art jailbreak attacks while maintaining the LLM's general\nperformance on benign queries. Moreover, RobustKV creates an intriguing\nevasiveness dilemma for adversaries, forcing them to balance between evading\nRobustKV and bypassing the LLM's built-in safeguards. This trade-off\ncontributes to RobustKV's robustness against adaptive attacks. (warning: this\npaper contains potentially harmful content generated by LLMs.)",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19937v1",
    "published_date": "2024-10-25 19:18:22 UTC",
    "updated_date": "2024-10-25 19:18:22 UTC"
  },
  {
    "arxiv_id": "2410.21312v1",
    "title": "$\\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis",
    "authors": [
      "Xin Wang",
      "Yifan Zhang",
      "Xiaojing Zhang",
      "Longhui Yu",
      "Xinna Lin",
      "Jindong Jiang",
      "Bin Ma",
      "Kaicheng Yu"
    ],
    "abstract": "Pharmaceutical patents play a vital role in biochemical industries,\nespecially in drug discovery, providing researchers with unique early access to\ndata, experimental results, and research insights. With the advancement of\nmachine learning, patent analysis has evolved from manual labor to tasks\nassisted by automatic tools. However, there still lacks an unified agent that\nassists every aspect of patent analysis, from patent reading to core chemical\nidentification. Leveraging the capabilities of Large Language Models (LLMs) to\nunderstand requests and follow instructions, we introduce the $\\textbf{first}$\nintelligent agent in this domain, $\\texttt{PatentAgent}$, poised to advance and\npotentially revolutionize the landscape of pharmaceutical research.\n$\\texttt{PatentAgent}$ comprises three key end-to-end modules --\n$\\textit{PA-QA}$, $\\textit{PA-Img2Mol}$, and $\\textit{PA-CoreId}$ -- that\nrespectively perform (1) patent question-answering, (2)\nimage-to-molecular-structure conversion, and (3) core chemical structure\nidentification, addressing the essential needs of scientists and practitioners\nin pharmaceutical patent analysis. Each module of $\\texttt{PatentAgent}$\ndemonstrates significant effectiveness with the updated algorithm and the\nsynergistic design of $\\texttt{PatentAgent}$ framework. $\\textit{PA-Img2Mol}$\noutperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks\nwith an accuracy gain between 2.46% and 8.37% while $\\textit{PA-CoreId}$\nrealizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML\nbenchmark. Our code and dataset will be publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21312v1",
    "published_date": "2024-10-25 19:15:08 UTC",
    "updated_date": "2024-10-25 19:15:08 UTC"
  },
  {
    "arxiv_id": "2410.19933v2",
    "title": "Enhancing Safety in Reinforcement Learning with Human Feedback via Rectified Policy Optimization",
    "authors": [
      "Xiyue Peng",
      "Hengquan Guo",
      "Jiawei Zhang",
      "Dongqing Zou",
      "Ziyu Shao",
      "Honghao Wei",
      "Xin Liu"
    ],
    "abstract": "Balancing helpfulness and safety (harmlessness) is a critical challenge in\naligning large language models (LLMs). Current approaches often decouple these\ntwo objectives, training separate preference models for helpfulness and safety,\nwhile framing safety as a constraint within a constrained Markov Decision\nProcess (CMDP) framework. This paper identifies a potential issue when using\nthe widely adopted expected safety constraints for LLM safety alignment, termed\n\"safety compensation\", where the constraints are satisfied on expectation, but\nindividual prompts may trade off safety, resulting in some responses being\noverly restrictive while others remain unsafe. To address this issue, we\npropose Rectified Policy Optimization (RePO), which replaces the expected\nsafety constraint with critical safety constraints imposed on every prompt. At\nthe core of RePO is a policy update mechanism driven by rectified policy\ngradients, which penalizes the strict safety violation of every prompt, thereby\nenhancing safety across nearly all prompts. Our experiments demonstrate that\nRePO outperforms strong baseline methods and significantly enhances LLM safety\nalignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19933v2",
    "published_date": "2024-10-25 19:08:23 UTC",
    "updated_date": "2025-02-27 07:28:35 UTC"
  },
  {
    "arxiv_id": "2410.19923v1",
    "title": "Language Agents Meet Causality -- Bridging LLMs and Causal World Models",
    "authors": [
      "John Gkountouras",
      "Matthias Lindemann",
      "Phillip Lippe",
      "Efstratios Gavves",
      "Ivan Titov"
    ],
    "abstract": "Large Language Models (LLMs) have recently shown great promise in planning\nand reasoning applications. These tasks demand robust systems, which arguably\nrequire a causal understanding of the environment. While LLMs can acquire and\nreflect common sense causal knowledge from their pretraining data, this\ninformation is often incomplete, incorrect, or inapplicable to a specific\nenvironment. In contrast, causal representation learning (CRL) focuses on\nidentifying the underlying causal structure within a given environment. We\npropose a framework that integrates CRLs with LLMs to enable causally-aware\nreasoning and planning. This framework learns a causal world model, with causal\nvariables linked to natural language expressions. This mapping provides LLMs\nwith a flexible interface to process and generate descriptions of actions and\nstates in text form. Effectively, the causal world model acts as a simulator\nthat the LLM can query and interact with. We evaluate the framework on causal\ninference and planning tasks across temporal scales and environmental\ncomplexities. Our experiments demonstrate the effectiveness of the approach,\nwith the causally-aware method outperforming LLM-based reasoners, especially\nfor longer planning horizons.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "Project page: https://j0hngou.github.io/LLMCWM/",
    "pdf_url": "http://arxiv.org/pdf/2410.19923v1",
    "published_date": "2024-10-25 18:36:37 UTC",
    "updated_date": "2024-10-25 18:36:37 UTC"
  },
  {
    "arxiv_id": "2410.19922v1",
    "title": "Disentangling Genotype and Environment Specific Latent Features for Improved Trait Prediction using a Compositional Autoencoder",
    "authors": [
      "Anirudha Powadi",
      "Talukder Zaki Jubery",
      "Michael C. Tross",
      "James C. Schnable",
      "Baskar Ganapathysubramanian"
    ],
    "abstract": "This study introduces a compositional autoencoder (CAE) framework designed to\ndisentangle the complex interplay between genotypic and environmental factors\nin high-dimensional phenotype data to improve trait prediction in plant\nbreeding and genetics programs. Traditional predictive methods, which use\ncompact representations of high-dimensional data through handcrafted features\nor latent features like PCA or more recently autoencoders, do not separate\ngenotype-specific and environment-specific factors. We hypothesize that\ndisentangling these features into genotype-specific and environment-specific\ncomponents can enhance predictive models. To test this, we developed a\ncompositional autoencoder (CAE) that decomposes high-dimensional data into\ndistinct genotype-specific and environment-specific latent features.\n  Our CAE framework employs a hierarchical architecture within an autoencoder\nto effectively separate these entangled latent features. Applied to a maize\ndiversity panel dataset, the CAE demonstrates superior modeling of\nenvironmental influences and 5-10 times improved predictive performance for key\ntraits like Days to Pollen and Yield, compared to the traditional methods,\nincluding standard autoencoders, PCA with regression, and Partial Least Squares\nRegression (PLSR). By disentangling latent features, the CAE provides powerful\ntool for precision breeding and genetic research. This work significantly\nenhances trait prediction models, advancing agricultural and biological\nsciences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19922v1",
    "published_date": "2024-10-25 18:30:27 UTC",
    "updated_date": "2024-10-25 18:30:27 UTC"
  },
  {
    "arxiv_id": "2410.19919v1",
    "title": "Provably Adaptive Average Reward Reinforcement Learning for Metric Spaces",
    "authors": [
      "Avik Kar",
      "Rahul Singh"
    ],
    "abstract": "We study infinite-horizon average-reward reinforcement learning (RL) for\nLipschitz MDPs and develop an algorithm ZoRL that discretizes the state-action\nspace adaptively and zooms into promising regions of the state-action space. We\nshow that its regret can be bounded as $\\mathcal{\\tilde{O}}\\big(T^{1 -\nd_{\\text{eff.}}^{-1}}\\big)$, where $d_{\\text{eff.}} = 2d_\\mathcal{S} + d_z +\n3$, $d_\\mathcal{S}$ is the dimension of the state space, and $d_z$ is the\nzooming dimension. $d_z$ is a problem-dependent quantity, which allows us to\nconclude that if MDP is benign, then its regret will be small. We note that the\nexisting notion of zooming dimension for average reward RL is defined in terms\nof policy coverings, and hence it can be huge when the policy class is rich\neven though the underlying MDP is simple, so that the regret upper bound is\nnearly $O(T)$. The zooming dimension proposed in the current work is bounded\nabove by $d$, the dimension of the state-action space, and hence is truly\nadaptive, i.e., shows how to capture adaptivity gains for infinite-horizon\naverage-reward RL. ZoRL outperforms other state-of-the-art algorithms in\nexperiments; thereby demonstrating the gains arising due to adaptivity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19919v1",
    "published_date": "2024-10-25 18:14:42 UTC",
    "updated_date": "2024-10-25 18:14:42 UTC"
  },
  {
    "arxiv_id": "2410.19915v2",
    "title": "AI-Driven Scenarios for Urban Mobility: Quantifying the Role of ODE Models and Scenario Planning in Reducing Traffic Congestion",
    "authors": [
      "Katsiaryna Bahamazava"
    ],
    "abstract": "Urbanization and technological advancements are reshaping urban mobility,\npresenting both challenges and opportunities. This paper investigates how\nArtificial Intelligence (AI)-driven technologies can impact traffic congestion\ndynamics and explores their potential to enhance transportation systems'\nefficiency. Specifically, we assess the role of AI innovations, such as\nautonomous vehicles and intelligent traffic management, in mitigating\ncongestion under varying regulatory frameworks. Autonomous vehicles reduce\ncongestion through optimized traffic flow, real-time route adjustments, and\ndecreased human errors.\n  The study employs Ordinary Differential Equations (ODEs) to model the dynamic\nrelationship between AI adoption rates and traffic congestion, capturing\nsystemic feedback loops. Quantitative outputs include threshold levels of AI\nadoption needed to achieve significant congestion reduction, while qualitative\ninsights stem from scenario planning exploring regulatory and societal\nconditions. This dual-method approach offers actionable strategies for\npolicymakers to create efficient, sustainable, and equitable urban\ntransportation systems. While safety implications of AI are acknowledged, this\nstudy primarily focuses on congestion reduction dynamics.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19915v2",
    "published_date": "2024-10-25 18:09:02 UTC",
    "updated_date": "2025-01-07 13:14:25 UTC"
  },
  {
    "arxiv_id": "2410.19912v1",
    "title": "Simmering: Sufficient is better than optimal for training neural networks",
    "authors": [
      "Irina Babayan",
      "Hazhir Aliahmadi",
      "Greg van Anders"
    ],
    "abstract": "The broad range of neural network training techniques that invoke\noptimization but rely on ad hoc modification for validity suggests that\noptimization-based training is misguided. Shortcomings of optimization-based\ntraining are brought to particularly strong relief by the problem of\noverfitting, where naive optimization produces spurious outcomes. The broad\nsuccess of neural networks for modelling physical processes has prompted\nadvances that are based on inverting the direction of investigation and\ntreating neural networks as if they were physical systems in their own right\nThese successes raise the question of whether broader, physical perspectives\ncould motivate the construction of improved training algorithms. Here, we\nintroduce simmering, a physics-based method that trains neural networks to\ngenerate weights and biases that are merely ``good enough'', but which,\nparadoxically, outperforms leading optimization-based approaches. Using\nclassification and regression examples we show that simmering corrects neural\nnetworks that are overfit by Adam, and show that simmering avoids overfitting\nif deployed from the outset. Our results question optimization as a paradigm\nfor neural network training, and leverage information-geometric arguments to\npoint to the existence of classes of sufficient training algorithms that do not\ntake optimization as their starting point.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19912v1",
    "published_date": "2024-10-25 18:02:08 UTC",
    "updated_date": "2024-10-25 18:02:08 UTC"
  },
  {
    "arxiv_id": "2410.19733v1",
    "title": "The Potential and Value of AI Chatbot in Personalized Cognitive Training",
    "authors": [
      "Zilong Wang",
      "Nan Chen",
      "Luna K. Qiu",
      "Ling Yue",
      "Geli Guo",
      "Yang Ou",
      "Shiqi Jiang",
      "Yuqing Yang",
      "Lili Qiu"
    ],
    "abstract": "In recent years, the rapid aging of the global population has led to an\nincrease in cognitive disorders, such as Alzheimer's disease, presenting\nsignificant public health challenges. Although no effective treatments\ncurrently exist to reverse Alzheimer's, prevention and early intervention,\nincluding cognitive training, are critical. This report explores the potential\nof AI chatbots in enhancing personalized cognitive training. We introduce ReMe,\na web-based framework designed to create AI chatbots that facilitate cognitive\ntraining research, specifically targeting episodic memory tasks derived from\npersonal life logs. By leveraging large language models, ReMe provides enhanced\nuser-friendly, interactive, and personalized training experiences. Case studies\ndemonstrate ReMe's effectiveness in engaging users through life recall and\nopen-ended language puzzles, highlighting its potential to improve cognitive\ntraining design. Despite promising results, further research is needed to\nvalidate training effectiveness through large-scale studies that include\ncognitive ability evaluations. Overall, ReMe offers a promising approach to\npersonalized cognitive training, utilizing AI capabilities to meet the growing\ndemand for non-pharmacological interventions in cognitive health, with future\nresearch aiming to expand its applications and efficacy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19733v1",
    "published_date": "2024-10-25 17:59:36 UTC",
    "updated_date": "2024-10-25 17:59:36 UTC"
  },
  {
    "arxiv_id": "2410.19730v2",
    "title": "Counting Ability of Large Language Models and Impact of Tokenization",
    "authors": [
      "Xiang Zhang",
      "Juntai Cao",
      "Chenyu You"
    ],
    "abstract": "Transformers, the backbone of modern large language models (LLMs), face\ninherent architectural limitations that impede their reasoning capabilities.\nUnlike recurrent networks, Transformers lack recurrent connections, confining\nthem to constant-depth computation. This restriction places them in the\ncomplexity class TC$^0$, making them theoretically incapable of solving tasks\nthat demand increasingly deep reasoning as input length grows. Counting, a\nfundamental component of many reasoning tasks, also requires reasoning depth to\ngrow linearly to be performed inductively. While previous studies have\nestablished the upper limits of counting ability in Transformer-based expert\nmodels (i.e., models specifically trained for counting tasks), these findings\ndo not directly extend to general-purpose LLMs due to differences in reasoning\nmechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning\ncan help alleviate some of the architectural limitations of Transformers in\ncounting tasks. However, little attention has been paid to the role of\ntokenization in these models. Unlike expert models that often use\ncharacter-level tokenization, LLMs typically rely on byte-level (BPE)\ntokenizers, which fundamentally alters the way reasoning is processed. Our work\ninvestigates the impact of tokenization on the counting abilities of LLMs,\nuncovering substantial performance variations based on input tokenization\ndifferences. We provide both theoretical and experimental analyses, offering\ninsights into how tokenization choices can undermine models' theoretical\ncomputability, thereby inspiring the design of new tokenization methods to\nenhance reasoning in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19730v2",
    "published_date": "2024-10-25 17:56:24 UTC",
    "updated_date": "2024-10-29 03:48:33 UTC"
  },
  {
    "arxiv_id": "2410.19727v1",
    "title": "FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning",
    "authors": [
      "Nicole Cho",
      "Nishan Srishankar",
      "Lucas Cecchi",
      "William Watson"
    ],
    "abstract": "Financial intelligence generation from vast data sources has typically relied\non traditional methods of knowledge-graph construction or database engineering.\nRecently, fine-tuned financial domain-specific Large Language Models (LLMs),\nhave emerged. While these advancements are promising, limitations such as high\ninference costs, hallucinations, and the complexity of concurrently analyzing\nhigh-dimensional financial data, emerge. This motivates our invention FISHNET\n(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,\nExpert swarming, and Task planning), an agentic architecture that accomplishes\nhighly complex analytical tasks for more than 98,000 regulatory filings that\nvary immensely in terms of semantics, data hierarchy, or format. FISHNET shows\nremarkable performance for financial insight generation (61.8% success rate\nover 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to\nempirically prove the success of FISHNET, each agent's importance, and the\noptimized performance of assembling all agents. Our modular architecture can be\nleveraged for a myriad of use-cases, enabling scalability, flexibility, and\ndata integrity that are critical for financial tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 5th ACM International Conference on AI in Finance\n  (ICAIF '24)",
    "pdf_url": "http://arxiv.org/pdf/2410.19727v1",
    "published_date": "2024-10-25 17:53:47 UTC",
    "updated_date": "2024-10-25 17:53:47 UTC"
  },
  {
    "arxiv_id": "2410.19723v2",
    "title": "Sparse Decomposition of Graph Neural Networks",
    "authors": [
      "Yaochen Hu",
      "Mai Zeng",
      "Ge Zhang",
      "Pavel Rumiantsev",
      "Liheng Ma",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "abstract": "Graph Neural Networks (GNN) exhibit superior performance in graph\nrepresentation learning, but their inference cost can be high, due to an\naggregation operation that can require a memory fetch for a very large number\nof nodes. This inference cost is the major obstacle to deploying GNN models\nwith \\emph{online prediction} to reflect the potentially dynamic node features.\nTo address this, we propose an approach to reduce the number of nodes that are\nincluded during aggregation. We achieve this through a sparse decomposition,\nlearning to approximate node representations using a weighted sum of linearly\ntransformed features of a carefully selected subset of nodes within the\nextended neighbourhood. The approach achieves linear complexity with respect to\nthe average node degree and the number of layers in the graph neural network.\nWe introduce an algorithm to compute the optimal parameters for the sparse\ndecomposition, ensuring an accurate approximation of the original GNN model,\nand present effective strategies to reduce the training time and improve the\nlearning process. We demonstrate via extensive experiments that our method\noutperforms other baselines designed for inference speedup, achieving\nsignificant accuracy gains with comparable inference times for both node\nclassification and spatio-temporal forecasting tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19723v2",
    "published_date": "2024-10-25 17:52:16 UTC",
    "updated_date": "2025-03-15 06:38:30 UTC"
  },
  {
    "arxiv_id": "2410.19720v1",
    "title": "2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision",
    "authors": [
      "Shilong Li",
      "Yancheng He",
      "Hui Huang",
      "Xingyuan Bu",
      "Jiaheng Liu",
      "Hangyu Guo",
      "Weixun Wang",
      "Jihao Gu",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Recent advancements in Direct Preference Optimization (DPO) have\nsignificantly enhanced the alignment of Large Language Models (LLMs) with human\npreferences, owing to its simplicity and effectiveness. However, existing\nmethods typically optimize a scalar score or ranking reward, thereby\noverlooking the multi-dimensional nature of human preferences. In this work, we\npropose to extend the preference of DPO to two dimensions: segments and\naspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For\nthe segment dimension, we divide the response into sentences and assign scores\nto each segment. For the aspect dimension, we meticulously design several\ncriteria covering the response quality rubrics. With the 2-dimensional signals\nas feedback, we develop a 2D-DPO framework, decomposing the overall objective\ninto multi-segment and multi-aspect objectives. Extensive experiments on\npopular benchmarks demonstrate that 2D-DPO performs better than methods that\noptimize for scalar or 1-dimensional preferences.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The first four authors contributed equally, 25 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19720v1",
    "published_date": "2024-10-25 17:47:35 UTC",
    "updated_date": "2024-10-25 17:47:35 UTC"
  },
  {
    "arxiv_id": "2410.19719v1",
    "title": "Arabic Music Classification and Generation using Deep Learning",
    "authors": [
      "Mohamed Elshaarawy",
      "Ashrakat Saeed",
      "Mariam Sheta",
      "Abdelrahman Said",
      "Asem Bakr",
      "Omar Bahaa",
      "Walid Gomaa"
    ],
    "abstract": "This paper proposes a machine learning approach for classifying classical and\nnew Egyptian music by composer and generating new similar music. The proposed\nsystem utilizes a convolutional neural network (CNN) for classification and a\nCNN autoencoder for generation. The dataset used in this project consists of\nnew and classical Egyptian music pieces composed by different composers.\n  To classify the music by composer, each sample is normalized and transformed\ninto a mel spectrogram. The CNN model is trained on the dataset using the mel\nspectrograms as input features and the composer labels as output classes. The\nmodel achieves 81.4\\% accuracy in classifying the music by composer,\ndemonstrating the effectiveness of the proposed approach.\n  To generate new music similar to the original pieces, a CNN autoencoder is\ntrained on a similar dataset. The model is trained to encode the mel\nspectrograms of the original pieces into a lower-dimensional latent space and\nthen decode them back into the original mel spectrogram. The generated music is\nproduced by sampling from the latent space and decoding the samples back into\nmel spectrograms, which are then transformed into audio.\n  In conclusion, the proposed system provides a promising approach to\nclassifying and generating classical Egyptian music, which can be applied in\nvarious musical applications, such as music recommendation systems, music\nproduction, and music education.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19719v1",
    "published_date": "2024-10-25 17:47:08 UTC",
    "updated_date": "2024-10-25 17:47:08 UTC"
  },
  {
    "arxiv_id": "2410.19898v1",
    "title": "A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection",
    "authors": [
      "Muath Alsuhaibani",
      "Ali Pourramezan Fard",
      "Jian Sun",
      "Farida Far Poor",
      "Peter S. Pressman",
      "Mohammad H. Mahoor"
    ],
    "abstract": "This review paper explores recent advances in deep learning approaches for\nnon-invasive cognitive impairment detection. We examine various non-invasive\nindicators of cognitive decline, including speech and language, facial, and\nmotoric mobility. The paper provides an overview of relevant datasets,\nfeature-extracting techniques, and deep-learning architectures applied to this\ndomain. We have analyzed the performance of different methods across modalities\nand observed that speech and language-based methods generally achieved the\nhighest detection performance. Studies combining acoustic and linguistic\nfeatures tended to outperform those using a single modality. Facial analysis\nmethods showed promise for visual modalities but were less extensively studied.\nMost papers focused on binary classification (impaired vs. non-impaired), with\nfewer addressing multi-class or regression tasks. Transfer learning and\npre-trained language models emerged as popular and effective techniques,\nespecially for linguistic analysis. Despite significant progress, several\nchallenges remain, including data standardization and accessibility, model\nexplainability, longitudinal analysis limitations, and clinical adaptation.\nLastly, we propose future research directions, such as investigating\nlanguage-agnostic speech analysis methods, developing multi-modal diagnostic\nsystems, and addressing ethical considerations in AI-assisted healthcare. By\nsynthesizing current trends and identifying key obstacles, this review aims to\nguide further development of deep learning-based cognitive impairment detection\nsystems to improve early diagnosis and ultimately patient outcomes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19898v1",
    "published_date": "2024-10-25 17:44:59 UTC",
    "updated_date": "2024-10-25 17:44:59 UTC"
  },
  {
    "arxiv_id": "2410.21276v1",
    "title": "GPT-4o System Card",
    "authors": [
      "OpenAI",
      ":",
      "Aaron Hurst",
      "Adam Lerer",
      "Adam P. Goucher",
      "Adam Perelman",
      "Aditya Ramesh",
      "Aidan Clark",
      "AJ Ostrow",
      "Akila Welihinda",
      "Alan Hayes",
      "Alec Radford",
      "Aleksander Mądry",
      "Alex Baker-Whitcomb",
      "Alex Beutel",
      "Alex Borzunov",
      "Alex Carney",
      "Alex Chow",
      "Alex Kirillov",
      "Alex Nichol",
      "Alex Paino",
      "Alex Renzin",
      "Alex Tachard Passos",
      "Alexander Kirillov",
      "Alexi Christakis",
      "Alexis Conneau",
      "Ali Kamali",
      "Allan Jabri",
      "Allison Moyer",
      "Allison Tam",
      "Amadou Crookes",
      "Amin Tootoochian",
      "Amin Tootoonchian",
      "Ananya Kumar",
      "Andrea Vallone",
      "Andrej Karpathy",
      "Andrew Braunstein",
      "Andrew Cann",
      "Andrew Codispoti",
      "Andrew Galu",
      "Andrew Kondrich",
      "Andrew Tulloch",
      "Andrey Mishchenko",
      "Angela Baek",
      "Angela Jiang",
      "Antoine Pelisse",
      "Antonia Woodford",
      "Anuj Gosalia",
      "Arka Dhar",
      "Ashley Pantuliano",
      "Avi Nayak",
      "Avital Oliver",
      "Barret Zoph",
      "Behrooz Ghorbani",
      "Ben Leimberger",
      "Ben Rossen",
      "Ben Sokolowsky",
      "Ben Wang",
      "Benjamin Zweig",
      "Beth Hoover",
      "Blake Samic",
      "Bob McGrew",
      "Bobby Spero",
      "Bogo Giertler",
      "Bowen Cheng",
      "Brad Lightcap",
      "Brandon Walkin",
      "Brendan Quinn",
      "Brian Guarraci",
      "Brian Hsu",
      "Bright Kellogg",
      "Brydon Eastman",
      "Camillo Lugaresi",
      "Carroll Wainwright",
      "Cary Bassin",
      "Cary Hudson",
      "Casey Chu",
      "Chad Nelson",
      "Chak Li",
      "Chan Jun Shern",
      "Channing Conger",
      "Charlotte Barette",
      "Chelsea Voss",
      "Chen Ding",
      "Cheng Lu",
      "Chong Zhang",
      "Chris Beaumont",
      "Chris Hallacy",
      "Chris Koch",
      "Christian Gibson",
      "Christina Kim",
      "Christine Choi",
      "Christine McLeavey",
      "Christopher Hesse",
      "Claudia Fischer",
      "Clemens Winter",
      "Coley Czarnecki",
      "Colin Jarvis",
      "Colin Wei",
      "Constantin Koumouzelis",
      "Dane Sherburn",
      "Daniel Kappler",
      "Daniel Levin",
      "Daniel Levy",
      "David Carr",
      "David Farhi",
      "David Mely",
      "David Robinson",
      "David Sasaki",
      "Denny Jin",
      "Dev Valladares",
      "Dimitris Tsipras",
      "Doug Li",
      "Duc Phong Nguyen",
      "Duncan Findlay",
      "Edede Oiwoh",
      "Edmund Wong",
      "Ehsan Asdar",
      "Elizabeth Proehl",
      "Elizabeth Yang",
      "Eric Antonow",
      "Eric Kramer",
      "Eric Peterson",
      "Eric Sigler",
      "Eric Wallace",
      "Eugene Brevdo",
      "Evan Mays",
      "Farzad Khorasani",
      "Felipe Petroski Such",
      "Filippo Raso",
      "Francis Zhang",
      "Fred von Lohmann",
      "Freddie Sulit",
      "Gabriel Goh",
      "Gene Oden",
      "Geoff Salmon",
      "Giulio Starace",
      "Greg Brockman",
      "Hadi Salman",
      "Haiming Bao",
      "Haitang Hu",
      "Hannah Wong",
      "Haoyu Wang",
      "Heather Schmidt",
      "Heather Whitney",
      "Heewoo Jun",
      "Hendrik Kirchner",
      "Henrique Ponde de Oliveira Pinto",
      "Hongyu Ren",
      "Huiwen Chang",
      "Hyung Won Chung",
      "Ian Kivlichan",
      "Ian O'Connell",
      "Ian O'Connell",
      "Ian Osband",
      "Ian Silber",
      "Ian Sohl",
      "Ibrahim Okuyucu",
      "Ikai Lan",
      "Ilya Kostrikov",
      "Ilya Sutskever",
      "Ingmar Kanitscheider",
      "Ishaan Gulrajani",
      "Jacob Coxon",
      "Jacob Menick",
      "Jakub Pachocki",
      "James Aung",
      "James Betker",
      "James Crooks",
      "James Lennon",
      "Jamie Kiros",
      "Jan Leike",
      "Jane Park",
      "Jason Kwon",
      "Jason Phang",
      "Jason Teplitz",
      "Jason Wei",
      "Jason Wolfe",
      "Jay Chen",
      "Jeff Harris",
      "Jenia Varavva",
      "Jessica Gan Lee",
      "Jessica Shieh",
      "Ji Lin",
      "Jiahui Yu",
      "Jiayi Weng",
      "Jie Tang",
      "Jieqi Yu",
      "Joanne Jang",
      "Joaquin Quinonero Candela",
      "Joe Beutler",
      "Joe Landers",
      "Joel Parish",
      "Johannes Heidecke",
      "John Schulman",
      "Jonathan Lachman",
      "Jonathan McKay",
      "Jonathan Uesato",
      "Jonathan Ward",
      "Jong Wook Kim",
      "Joost Huizinga",
      "Jordan Sitkin",
      "Jos Kraaijeveld",
      "Josh Gross",
      "Josh Kaplan",
      "Josh Snyder",
      "Joshua Achiam",
      "Joy Jiao",
      "Joyce Lee",
      "Juntang Zhuang",
      "Justyn Harriman",
      "Kai Fricke",
      "Kai Hayashi",
      "Karan Singhal",
      "Katy Shi",
      "Kavin Karthik",
      "Kayla Wood",
      "Kendra Rimbach",
      "Kenny Hsu",
      "Kenny Nguyen",
      "Keren Gu-Lemberg",
      "Kevin Button",
      "Kevin Liu",
      "Kiel Howe",
      "Krithika Muthukumar",
      "Kyle Luther",
      "Lama Ahmad",
      "Larry Kai",
      "Lauren Itow",
      "Lauren Workman",
      "Leher Pathak",
      "Leo Chen",
      "Li Jing",
      "Lia Guy",
      "Liam Fedus",
      "Liang Zhou",
      "Lien Mamitsuka",
      "Lilian Weng",
      "Lindsay McCallum",
      "Lindsey Held",
      "Long Ouyang",
      "Louis Feuvrier",
      "Lu Zhang",
      "Lukas Kondraciuk",
      "Lukasz Kaiser",
      "Luke Hewitt",
      "Luke Metz",
      "Lyric Doshi",
      "Mada Aflak",
      "Maddie Simens",
      "Madelaine Boyd",
      "Madeleine Thompson",
      "Marat Dukhan",
      "Mark Chen",
      "Mark Gray",
      "Mark Hudnall",
      "Marvin Zhang",
      "Marwan Aljubeh",
      "Mateusz Litwin",
      "Matthew Zeng",
      "Max Johnson",
      "Maya Shetty",
      "Mayank Gupta",
      "Meghan Shah",
      "Mehmet Yatbaz",
      "Meng Jia Yang",
      "Mengchao Zhong",
      "Mia Glaese",
      "Mianna Chen",
      "Michael Janner",
      "Michael Lampe",
      "Michael Petrov",
      "Michael Wu",
      "Michele Wang",
      "Michelle Fradin",
      "Michelle Pokrass",
      "Miguel Castro",
      "Miguel Oom Temudo de Castro",
      "Mikhail Pavlov",
      "Miles Brundage",
      "Miles Wang",
      "Minal Khan",
      "Mira Murati",
      "Mo Bavarian",
      "Molly Lin",
      "Murat Yesildal",
      "Nacho Soto",
      "Natalia Gimelshein",
      "Natalie Cone",
      "Natalie Staudacher",
      "Natalie Summers",
      "Natan LaFontaine",
      "Neil Chowdhury",
      "Nick Ryder",
      "Nick Stathas",
      "Nick Turley",
      "Nik Tezak",
      "Niko Felix",
      "Nithanth Kudige",
      "Nitish Keskar",
      "Noah Deutsch",
      "Noel Bundick",
      "Nora Puckett",
      "Ofir Nachum",
      "Ola Okelola",
      "Oleg Boiko",
      "Oleg Murk",
      "Oliver Jaffe",
      "Olivia Watkins",
      "Olivier Godement",
      "Owen Campbell-Moore",
      "Patrick Chao",
      "Paul McMillan",
      "Pavel Belov",
      "Peng Su",
      "Peter Bak",
      "Peter Bakkum",
      "Peter Deng",
      "Peter Dolan",
      "Peter Hoeschele",
      "Peter Welinder",
      "Phil Tillet",
      "Philip Pronin",
      "Philippe Tillet",
      "Prafulla Dhariwal",
      "Qiming Yuan",
      "Rachel Dias",
      "Rachel Lim",
      "Rahul Arora",
      "Rajan Troll",
      "Randall Lin",
      "Rapha Gontijo Lopes",
      "Raul Puri",
      "Reah Miyara",
      "Reimar Leike",
      "Renaud Gaubert",
      "Reza Zamani",
      "Ricky Wang",
      "Rob Donnelly",
      "Rob Honsby",
      "Rocky Smith",
      "Rohan Sahai",
      "Rohit Ramchandani",
      "Romain Huet",
      "Rory Carmichael",
      "Rowan Zellers",
      "Roy Chen",
      "Ruby Chen",
      "Ruslan Nigmatullin",
      "Ryan Cheu",
      "Saachi Jain",
      "Sam Altman",
      "Sam Schoenholz",
      "Sam Toizer",
      "Samuel Miserendino",
      "Sandhini Agarwal",
      "Sara Culver",
      "Scott Ethersmith",
      "Scott Gray",
      "Sean Grove",
      "Sean Metzger",
      "Shamez Hermani",
      "Shantanu Jain",
      "Shengjia Zhao",
      "Sherwin Wu",
      "Shino Jomoto",
      "Shirong Wu",
      "Shuaiqi",
      "Xia",
      "Sonia Phene",
      "Spencer Papay",
      "Srinivas Narayanan",
      "Steve Coffey",
      "Steve Lee",
      "Stewart Hall",
      "Suchir Balaji",
      "Tal Broda",
      "Tal Stramer",
      "Tao Xu",
      "Tarun Gogineni",
      "Taya Christianson",
      "Ted Sanders",
      "Tejal Patwardhan",
      "Thomas Cunninghman",
      "Thomas Degry",
      "Thomas Dimson",
      "Thomas Raoux",
      "Thomas Shadwell",
      "Tianhao Zheng",
      "Todd Underwood",
      "Todor Markov",
      "Toki Sherbakov",
      "Tom Rubin",
      "Tom Stasi",
      "Tomer Kaftan",
      "Tristan Heywood",
      "Troy Peterson",
      "Tyce Walters",
      "Tyna Eloundou",
      "Valerie Qi",
      "Veit Moeller",
      "Vinnie Monaco",
      "Vishal Kuo",
      "Vlad Fomenko",
      "Wayne Chang",
      "Weiyi Zheng",
      "Wenda Zhou",
      "Wesam Manassra",
      "Will Sheu",
      "Wojciech Zaremba",
      "Yash Patil",
      "Yilei Qian",
      "Yongjik Kim",
      "Youlong Cheng",
      "Yu Zhang",
      "Yuchen He",
      "Yuchen Zhang",
      "Yujia Jin",
      "Yunxing Dai",
      "Yury Malkov"
    ],
    "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination\nof text, audio, image, and video, and generates any combination of text, audio,\nand image outputs. It's trained end-to-end across text, vision, and audio,\nmeaning all inputs and outputs are processed by the same neural network. GPT-4o\ncan respond to audio inputs in as little as 232 milliseconds, with an average\nof 320 milliseconds, which is similar to human response time in conversation.\nIt matches GPT-4 Turbo performance on text in English and code, with\nsignificant improvement on text in non-English languages, while also being much\nfaster and 50\\% cheaper in the API. GPT-4o is especially better at vision and\naudio understanding compared to existing models. In line with our commitment to\nbuilding AI safely and consistent with our voluntary commitments to the White\nHouse, we are sharing the GPT-4o System Card, which includes our Preparedness\nFramework evaluations. In this System Card, we provide a detailed look at\nGPT-4o's capabilities, limitations, and safety evaluations across multiple\ncategories, focusing on speech-to-speech while also evaluating text and image\ncapabilities, and measures we've implemented to ensure the model is safe and\naligned. We also include third-party assessments on dangerous capabilities, as\nwell as discussion of potential societal impacts of GPT-4o's text and vision\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21276v1",
    "published_date": "2024-10-25 17:43:01 UTC",
    "updated_date": "2024-10-25 17:43:01 UTC"
  },
  {
    "arxiv_id": "2410.19718v1",
    "title": "Evolving Neural Networks Reveal Emergent Collective Behavior from Minimal Agent Interactions",
    "authors": [
      "Guilherme S. Y. Giardini",
      "John F. Hardy II",
      "Carlo R. da Cunha"
    ],
    "abstract": "Understanding the mechanisms behind emergent behaviors in multi-agent systems\nis critical for advancing fields such as swarm robotics and artificial\nintelligence. In this study, we investigate how neural networks evolve to\ncontrol agents' behavior in a dynamic environment, focusing on the relationship\nbetween the network's complexity and collective behavior patterns. By\nperforming quantitative and qualitative analyses, we demonstrate that the\ndegree of network non-linearity correlates with the complexity of emergent\nbehaviors. Simpler behaviors, such as lane formation and laminar flow, are\ncharacterized by more linear network operations, while complex behaviors like\nswarming and flocking show highly non-linear neural processing. Moreover,\nspecific environmental parameters, such as moderate noise, broader field of\nview, and lower agent density, promote the evolution of non-linear networks\nthat drive richer, more intricate collective behaviors. These results highlight\nthe importance of tuning evolutionary conditions to induce desired behaviors in\nmulti-agent systems, offering new pathways for optimizing coordination in\nautonomous swarms. Our findings contribute to a deeper understanding of how\nneural mechanisms influence collective dynamics, with implications for the\ndesign of intelligent, self-organizing systems.",
    "categories": [
      "nlin.AO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "nlin.AO",
    "comment": "25 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19718v1",
    "published_date": "2024-10-25 17:43:00 UTC",
    "updated_date": "2024-10-25 17:43:00 UTC"
  },
  {
    "arxiv_id": "2410.19715v2",
    "title": "Adversarial Environment Design via Regret-Guided Diffusion Models",
    "authors": [
      "Hojun Chung",
      "Junseo Lee",
      "Minsoo Kim",
      "Dohyeong Kim",
      "Songhwai Oh"
    ],
    "abstract": "Training agents that are robust to environmental changes remains a\nsignificant challenge in deep reinforcement learning (RL). Unsupervised\nenvironment design (UED) has recently emerged to address this issue by\ngenerating a set of training environments tailored to the agent's capabilities.\nWhile prior works demonstrate that UED has the potential to learn a robust\npolicy, their performance is constrained by the capabilities of the environment\ngeneration. To this end, we propose a novel UED algorithm, adversarial\nenvironment design via regret-guided diffusion models (ADD). The proposed\nmethod guides the diffusion-based environment generator with the regret of the\nagent to produce environments that the agent finds challenging but conducive to\nfurther improvement. By exploiting the representation power of diffusion\nmodels, ADD can directly generate adversarial environments while maintaining\nthe diversity of training environments, enabling the agent to effectively learn\na robust policy. Our experimental results demonstrate that the proposed method\nsuccessfully generates an instructive curriculum of environments, outperforming\nUED baselines in zero-shot generalization across novel, out-of-distribution\nenvironments. Project page: https://rllab-snu.github.io/projects/ADD",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "38th Conference on Neural Information Processing Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.19715v2",
    "published_date": "2024-10-25 17:35:03 UTC",
    "updated_date": "2024-11-15 01:01:44 UTC"
  },
  {
    "arxiv_id": "2410.19704v3",
    "title": "Multi-view biomedical foundation models for molecule-target and property prediction",
    "authors": [
      "Parthasarathy Suryanarayanan",
      "Yunguang Qiu",
      "Shreyans Sethi",
      "Diwakar Mahajan",
      "Hongyang Li",
      "Yuxin Yang",
      "Elif Eyigoz",
      "Aldo Guzman Saenz",
      "Daniel E. Platt",
      "Timothy H. Rumbell",
      "Kenney Ng",
      "Sanjoy Dey",
      "Myson Burch",
      "Bum Chul Kwon",
      "Pablo Meyer",
      "Feixiong Cheng",
      "Jianying Hu",
      "Joseph A. Morrone"
    ],
    "abstract": "Foundation models applied to bio-molecular space hold promise to accelerate\ndrug discovery. Molecular representation is key to building such models.\nPrevious works have typically focused on a single representation or view of the\nmolecules. Here, we develop a multi-view foundation model approach, that\nintegrates molecular views of graph, image and text. Single-view foundation\nmodels are each pre-trained on a dataset of up to 200M molecules and then\naggregated into combined representations. Our multi-view model is validated on\na diverse set of 18 tasks, encompassing ligand-protein binding, molecular\nsolubility, metabolism and toxicity. We show that the multi-view models perform\nrobustly and are able to balance the strengths and weaknesses of specific\nviews. We then apply this model to screen compounds against a large (>100\ntargets) set of G Protein-Coupled receptors (GPCRs). From this library of\ntargets, we identify 33 that are related to Alzheimer's disease. On this\nsubset, we employ our model to identify strong binders, which are validated\nthrough structure-based modeling and identification of key binding motifs.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "37 pages including supplement. 10 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.19704v3",
    "published_date": "2024-10-25 17:22:33 UTC",
    "updated_date": "2025-01-31 19:35:46 UTC"
  },
  {
    "arxiv_id": "2410.19702v2",
    "title": "TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning",
    "authors": [
      "Xiangyu Zeng",
      "Kunchang Li",
      "Chenting Wang",
      "Xinhao Li",
      "Tianxiang Jiang",
      "Ziang Yan",
      "Songze Li",
      "Yansong Shi",
      "Zhengrong Yue",
      "Yi Wang",
      "Yali Wang",
      "Yu Qiao",
      "Limin Wang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\nperformance in short video understanding. However, understanding long-form\nvideos still remains challenging for MLLMs. This paper proposes TimeSuite, a\ncollection of new designs to adapt the existing short-form video MLLMs for long\nvideo understanding, including a simple yet efficient framework to process long\nvideo sequence, a high-quality video dataset for grounded tuning of MLLMs, and\na carefully-designed instruction tuning task to explicitly incorporate the\ngrounding supervision in the traditional QA format. Specifically, based on\nVideoChat, we propose our long-video MLLM, coined as VideoChat-T, by\nimplementing a token shuffling to compress long video tokens and introducing\nTemporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of\nvisual representation. Meanwhile, we introduce the TimePro, a comprehensive\ngrounding-centric instruction tuning dataset composed of 9 tasks and 349k\nhigh-quality grounded annotations. Notably, we design a new instruction tuning\ntask type, called Temporal Grounded Caption, to peform detailed video\ndescriptions with the corresponding time stamps prediction. This explicit\ntemporal location prediction will guide MLLM to correctly attend on the visual\ncontent when generating description, and thus reduce the hallucination risk\ncaused by the LLMs. Experimental results demonstrate that our TimeSuite\nprovides a successful solution to enhance the long video understanding\ncapability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the\nbenchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T\nexhibits robust zero-shot temporal grounding capabilities, significantly\noutperforming the existing state-of-the-art MLLMs. After fine-tuning, it\nperforms on par with the traditional supervised expert models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.19702v2",
    "published_date": "2024-10-25 17:19:55 UTC",
    "updated_date": "2025-02-12 16:47:30 UTC"
  },
  {
    "arxiv_id": "2410.19701v1",
    "title": "Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "This paper investigates the inclusion of microservices architecture in the\ndevelopment of scalable and reliable airline reservation systems. Most of the\ntraditional reservation systems are very rigid and centralized which makes them\nprone to bottlenecks and a single point of failure. As such, systems do not\nmeet the requirements of modern airlines which are dynamic. Microservices offer\nbetter resiliency and scalability because the services do not depend on one\nanother and can be deployed independently. The approach is grounded on the\nCircuit Breaker Pattern to maintain fault tolerance while consuming foreign\nresources such as flight APIs and payment systems. This avoided the failure\npropagation to the systems by 60% enabling the systems to function under\nexternal failures. Traffic rerouting also bolstered this with a guarantee of\nabove 99.95% uptime in systems where high availability was demanded. To address\nthis, load balancing was used, particularly the Round-Robin method which\nmanaged to enhance performance by 35% through the equal distribution of user\nrequests among the service instances. Health checks, as well as monitoring in\nreal-time, helped as well with failure management as they helped to contain\nfailures before the users of the system were affected. The results suggest that\nthe use of microservices led to a 40% increase in system scalability, a 50%\ndecrease in downtime and a support for 30% more concurrent users than the use\nof monolithic architectures. These findings affirm the capability of\nmicroservices in the development of robust and flexible airline ticket booking\nsystems that are responsive to change and recover from external system\nunavailability.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19701v1",
    "published_date": "2024-10-25 17:19:42 UTC",
    "updated_date": "2024-10-25 17:19:42 UTC"
  },
  {
    "arxiv_id": "2410.19697v1",
    "title": "IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation",
    "authors": [
      "Kaixian Qu",
      "Jie Tan",
      "Tingnan Zhang",
      "Fei Xia",
      "Cesar Cadena",
      "Marco Hutter"
    ],
    "abstract": "Navigating efficiently to an object in an unexplored environment is a\ncritical skill for general-purpose intelligent robots. Recent approaches to\nthis object goal navigation problem have embraced a modular strategy,\nintegrating classical exploration algorithms-notably frontier exploration-with\na learned semantic mapping/exploration module. This paper introduces a novel\ninformative path planning and 3D object probability mapping approach. The\nmapping module computes the probability of the object of interest through\nsemantic segmentation and a Bayes filter. Additionally, it stores probabilities\nfor common objects, which semantically guides the exploration based on common\nsense priors from a large language model. The planner terminates when the\ncurrent viewpoint captures enough voxels identified with high confidence as the\nobject of interest. Although our planner follows a zero-shot approach, it\nachieves state-of-the-art performance as measured by the Success weighted by\nPath Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023,\noutperforming other works by more than 20%. Furthermore, we validate its\neffectiveness on real robots. Project webpage: https://ippon-paper.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19697v1",
    "published_date": "2024-10-25 17:11:33 UTC",
    "updated_date": "2024-10-25 17:11:33 UTC"
  },
  {
    "arxiv_id": "2410.19694v1",
    "title": "Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs",
    "authors": [
      "Yifei Zhang",
      "Hao Zhu",
      "Aiwei Liu",
      "Han Yu",
      "Piotr Koniusz",
      "Irwin King"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) has become a crucial technique for\nadapting pre-trained models to downstream tasks. However, the enormous size of\nLLMs poses significant challenges in terms of computational complexity and\nresource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising\nsolution. However, there exists a gap between the practical performance of\nlow-rank adaptations and its theoretical optimum. In this work, we propose\neXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this\ngap by leveraging the power of ensemble learning. Inspired by gradient\nboosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations\nto refine model predictions. It achieves better performance than the standard\nLoRA, while enjoying the computational efficiency of rank-1 adaptations. We\nprovide theoretical analysis to show the convergence and optimality of our\napproach, and conduct extensive experiments on a range of natural language\nprocessing tasks. The results demonstrate that XGBLoRA consistently outperforms\nstandard LoRA and achieves performance comparable to full fine-tuning with\nsignificantly fewer trainable parameters. This work advances\nparameter-efficient fine-tuning for LLMs, and offers a promising solution for\nadapting LLMs to downstream tasks while optimizing performance and efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19694v1",
    "published_date": "2024-10-25 17:07:13 UTC",
    "updated_date": "2024-10-25 17:07:13 UTC"
  },
  {
    "arxiv_id": "2410.19693v1",
    "title": "MILES: Making Imitation Learning Easy with Self-Supervision",
    "authors": [
      "Georgios Papagiannis",
      "Edward Johns"
    ],
    "abstract": "Data collection in imitation learning often requires significant, laborious\nhuman supervision, such as numerous demonstrations, and/or frequent environment\nresets for methods that incorporate reinforcement learning. In this work, we\npropose an alternative approach, MILES: a fully autonomous, self-supervised\ndata collection paradigm, and we show that this enables efficient policy\nlearning from just a single demonstration and a single environment reset. MILES\nautonomously learns a policy for returning to and then following the single\ndemonstration, whilst being self-guided during data collection, eliminating the\nneed for additional human interventions. We evaluated MILES across several\nreal-world tasks, including tasks that require precise contact-rich\nmanipulation such as locking a lock with a key. We found that, under the\nconstraints of a single demonstration and no repeated environment resetting,\nMILES significantly outperforms state-of-the-art alternatives like imitation\nlearning methods that leverage reinforcement learning. Videos of our\nexperiments and code can be found on our webpage: www.robot-learning.uk/miles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at the Conference on Robot Learning (CoRL) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19693v1",
    "published_date": "2024-10-25 17:06:50 UTC",
    "updated_date": "2024-10-25 17:06:50 UTC"
  },
  {
    "arxiv_id": "2410.19692v1",
    "title": "AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs",
    "authors": [
      "Clemencia Siro",
      "Yifei Yuan",
      "Mohammad Aliannejadi",
      "Maarten de Rijke"
    ],
    "abstract": "Generating diverse and effective clarifying questions is crucial for\nimproving query understanding and retrieval performance in open-domain\nconversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration,\nand evaluaTion of Clarifying Questions), an end-to-end LLM-based framework\naddressing the challenges of scalability and adaptability faced by existing\nmethods that rely on manual curation or template-based approaches. AGENT-CQ\nconsists of two stages: a generation stage employing LLM prompting strategies\nto generate clarifying questions, and an evaluation stage (CrowdLLM) that\nsimulates human crowdsourcing judgments using multiple LLM instances to assess\ngenerated questions and answers based on comprehensive quality metrics.\nExtensive experiments on the ClariQ dataset demonstrate CrowdLLM's\neffectiveness in evaluating question and answer quality. Human evaluation and\nCrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms\nbaselines in various aspects of question and answer quality. In retrieval-based\nevaluation, LLM-generated questions significantly enhance retrieval\neffectiveness for both BM25 and cross-encoder models compared to\nhuman-generated questions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19692v1",
    "published_date": "2024-10-25 17:06:27 UTC",
    "updated_date": "2024-10-25 17:06:27 UTC"
  },
  {
    "arxiv_id": "2411.10448v3",
    "title": "Goetterfunke: Creativity in Machinae Sapiens. About the Qualitative Shift in Generative AI with a Focus on Text-To-Image",
    "authors": [
      "Jens Knappe"
    ],
    "abstract": "The year 2022 marks a watershed in technology, and arguably in human history,\nwith the release of powerful generative AIs capable of convincingly performing\ncreative tasks. With the help of these systems, anyone can create something\nthat would previously have been considered a remarkable work of art. In\nhuman-AI collaboration, the computer seems to have become more than a tool.\nMany who have made their first contact with current generative AIs see them as\n\"creativity machines\" while for others the term \"machine creativity\" remains an\noxymoron. This article is about (the possibility of) creativity in computers\nwithin the current Machine Learning paradigm. It outlines some of the key\nconcepts behind the technologies and the innovations that have contributed to\nthis qualitative shift, with a focus on text-to-image systems. The nature of\nArtificial Creativity as such is discussed, as well as what this might mean for\nart. AI may become a responsible collaborator with elements of independent\nmachine authorship in the artistic process.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "3 figures (images), 33 pages typo, minor layout and text format\n  issues fixed",
    "pdf_url": "http://arxiv.org/pdf/2411.10448v3",
    "published_date": "2024-10-25 16:04:11 UTC",
    "updated_date": "2024-12-11 23:03:28 UTC"
  },
  {
    "arxiv_id": "2410.21311v1",
    "title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding",
    "authors": [
      "Fengbin Zhu",
      "Ziyang Liu",
      "Xiang Yao Ng",
      "Haohui Wu",
      "Wenjie Wang",
      "Fuli Feng",
      "Chao Wang",
      "Huanbo Luan",
      "Tat Seng Chua"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in\nmany vision-language tasks, yet their capabilities in fine-grained visual\nunderstanding remain insufficiently evaluated. Existing benchmarks either\ncontain limited fine-grained evaluation samples that are mixed with other data,\nor are confined to object-level assessments in natural images. To holistically\nassess LVLMs' fine-grained visual understanding capabilities, we propose using\ndocument images with multi-granularity and multi-modal information to\nsupplement natural images. In this light, we construct MMDocBench, a benchmark\nwith various OCR-free document understanding tasks for the evaluation of\nfine-grained visual perception and reasoning abilities. MMDocBench defines 15\nmain tasks with 4,338 QA pairs and 11,353 supporting regions, covering various\ndocument images such as research papers, receipts, financial reports, Wikipedia\ntables, charts, and infographics. Based on MMDocBench, we conduct extensive\nexperiments using 13 open-source and 3 proprietary advanced LVLMs, assessing\ntheir strengths and weaknesses across different tasks and document image types.\nThe benchmark, task instructions, and evaluation code will be made publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2410.21311v1",
    "published_date": "2024-10-25 16:00:55 UTC",
    "updated_date": "2024-10-25 16:00:55 UTC"
  },
  {
    "arxiv_id": "2410.19646v2",
    "title": "Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers",
    "authors": [
      "Vivek Singh",
      "Shikha Chaganti",
      "Matthias Siebert",
      "Sowmya Rajesh",
      "Andrei Puiu",
      "Raj Gopalan",
      "Jamie Gramz",
      "Dorin Comaniciu",
      "Ali Kamen"
    ],
    "abstract": "Early screening for cancer has proven to improve the survival rate and spare\npatients from intensive and costly treatments due to late diagnosis. Cancer\nscreening in the healthy population involves an initial risk stratification\nstep to determine the screening method and frequency, primarily to optimize\nresource allocation by targeting screening towards individuals who draw most\nbenefit. For most screening programs, age and clinical risk factors such as\nfamily history are part of the initial risk stratification algorithm. In this\npaper, we focus on developing a blood marker-based risk stratification\napproach, which could be used to identify patients with elevated cancer risk to\nbe encouraged for taking a diagnostic test or participate in a screening\nprogram. We demonstrate that the combination of simple, widely available blood\ntests, such as complete blood count and complete metabolic panel, could\npotentially be used to identify patients at risk for colorectal, liver, and\nlung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.\nFurthermore, we hypothesize that such an approach could not only be used as\npre-screening risk assessment for individuals but also as population health\nmanagement tool, for example to better interrogate the cancer risk in certain\nsub-populations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19646v2",
    "published_date": "2024-10-25 15:50:27 UTC",
    "updated_date": "2025-01-06 02:17:10 UTC"
  },
  {
    "arxiv_id": "2410.19643v3",
    "title": "Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites",
    "authors": [
      "Nicolás Nieto",
      "Simon B. Eickhoff",
      "Christian Jung",
      "Martin Reuter",
      "Kersten Diers",
      "Malte Kelm",
      "Artur Lichtenberg",
      "Federico Raimondo",
      "Kaustubh R. Patil"
    ],
    "abstract": "Machine learning (ML) models benefit from large datasets. Collecting data in\nbiomedical domains is costly and challenging, hence, combining datasets has\nbecome a common practice. However, datasets obtained under different conditions\ncould present undesired site-specific variability. Data harmonization methods\naim to remove site-specific variance while retaining biologically relevant\ninformation. This study evaluates the effectiveness of popularly used\nComBat-based methods for harmonizing data in scenarios where the class balance\nis not equal across sites. We find that these methods struggle with data\nleakage issues. To overcome this problem, we propose a novel approach\nPrettYharmonize, designed to harmonize data by pretending the target labels. We\nvalidate our approach using controlled datasets designed to benchmark the\nutility of harmonization. Finally, using real-world MRI and clinical data, we\ncompare leakage-prone methods with PrettYharmonize and show that it achieves\ncomparable performance while avoiding data leakage, particularly in\nsite-target-dependence scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19643v3",
    "published_date": "2024-10-25 15:49:04 UTC",
    "updated_date": "2024-12-10 18:50:37 UTC"
  },
  {
    "arxiv_id": "2410.19642v1",
    "title": "VARS: Vision-based Assessment of Risk in Security Systems",
    "authors": [
      "Pranav Gupta",
      "Pratham Gohil",
      "Sridhar S"
    ],
    "abstract": "The accurate prediction of danger levels in video content is critical for\nenhancing safety and security systems, particularly in environments where quick\nand reliable assessments are essential. In this study, we perform a comparative\nanalysis of various machine learning and deep learning models to predict danger\nratings in a custom dataset of 100 videos, each containing 50 frames, annotated\nwith human-rated danger scores ranging from 0 to 10. The danger ratings are\nfurther classified into three categories: no alert (less than 7)and high alert\n(greater than equal to 7). Our evaluation covers classical machine learning\nmodels, such as Support Vector Machines, as well as Neural Networks, and\ntransformer-based models. Model performance is assessed using standard metrics\nsuch as accuracy, F1-score, and mean absolute error (MAE), and the results are\ncompared to identify the most robust approach. This research contributes to\ndeveloping a more accurate and generalizable danger assessment framework for\nvideo-based risk detection.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19642v1",
    "published_date": "2024-10-25 15:47:13 UTC",
    "updated_date": "2024-10-25 15:47:13 UTC"
  },
  {
    "arxiv_id": "2410.19639v2",
    "title": "Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving",
    "authors": [
      "Liu Yunhao",
      "Ding Hong",
      "Zhang Ziming",
      "Wang Huixin",
      "Liu Jinzhao",
      "Xi Suyang"
    ],
    "abstract": "Autonomous driving technology has seen significant advancements, but existing\nmodels often fail to fully capture the complexity of multi-agent environments,\nwhere interactions between dynamic agents are critical. To address this, we\npropose the Planning-Integrated Forecasting Model (PIFM), a novel framework\ninspired by neural mechanisms governing decision-making and multi-agent\ncoordination in the brain. PIFM leverages rich contextual information,\nintegrating road structures, traffic rules, and the behavior of surrounding\nvehicles to improve both the accuracy and interpretability of predictions. By\nadopting a diffusion-based architecture, akin to neural diffusion processes\ninvolved in predicting and planning, PIFM is able to forecast future\ntrajectories of all agents within a scenario. This architecture enhances model\ntransparency, as it parallels the brain's method of dynamically adjusting\npredictions based on external stimuli and other agents'behaviors. Extensive\nexperiments validate PIFM's capacity to provide interpretable,\nneuroscience-driven solutions for safer and more efficient autonomous driving\nsystems, with an extremely low number of parameters.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The experimental verification section has some issues",
    "pdf_url": "http://arxiv.org/pdf/2410.19639v2",
    "published_date": "2024-10-25 15:44:51 UTC",
    "updated_date": "2024-11-04 07:24:15 UTC"
  },
  {
    "arxiv_id": "2410.19627v2",
    "title": "Knowledge Graph Enhanced Language Agents for Recommendation",
    "authors": [
      "Taicheng Guo",
      "Chaochun Liu",
      "Hai Wang",
      "Varun Mannam",
      "Fang Wang",
      "Xin Chen",
      "Xiangliang Zhang",
      "Chandan K. Reddy"
    ],
    "abstract": "Language agents have recently been used to simulate human behavior and\nuser-item interactions for recommendation systems. However, current language\nagent simulations do not understand the relationships between users and items,\nleading to inaccurate user profiles and ineffective recommendations. In this\nwork, we explore the utility of Knowledge Graphs (KGs), which contain extensive\nand reliable relationships between users and items, for recommendation. Our key\ninsight is that the paths in a KG can capture complex relationships between\nusers and items, eliciting the underlying reasons for user preferences and\nenriching user profiles. Leveraging this insight, we propose Knowledge Graph\nEnhanced Language Agents(KGLA), a framework that unifies language agents and KG\nfor recommendation systems. In the simulated recommendation scenario, we\nposition the user and item within the KG and integrate KG paths as natural\nlanguage descriptions into the simulation. This allows language agents to\ninteract with each other and discover sufficient rationale behind their\ninteractions, making the simulation more accurate and aligned with real-world\ncases, thus improving recommendation performance. Our experimental results show\nthat KGLA significantly improves recommendation performance (with a 33%-95%\nboost in NDCG@1 among three widely used benchmarks) compared to the previous\nbest baseline method.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19627v2",
    "published_date": "2024-10-25 15:25:36 UTC",
    "updated_date": "2025-01-24 20:49:16 UTC"
  },
  {
    "arxiv_id": "2410.19612v2",
    "title": "Shared Control with Black Box Agents using Oracle Queries",
    "authors": [
      "Inbal Avraham",
      "Reuth Mirsky"
    ],
    "abstract": "Shared control problems involve a robot learning to collaborate with a human.\nWhen learning a shared control policy, short communication between the agents\ncan often significantly reduce running times and improve the system's accuracy.\nWe extend the shared control problem to include the ability to directly query a\ncooperating agent. We consider two types of potential responses to a query,\nnamely oracles: one that can provide the learner with the best action they\nshould take, even when that action might be myopically wrong, and one with a\nbounded knowledge limited to its part of the system. Given this additional\ninformation channel, this work further presents three heuristics for choosing\nwhen to query: reinforcement learning-based, utility-based, and entropy-based.\nThese heuristics aim to reduce a system's overall learning cost. Empirical\nresults on two environments show the benefits of querying to learn a better\ncontrol policy and the tradeoffs between the proposed heuristics.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in the 2025 IEEE International Conference on\n  AI and Data Analytics (ICAD 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.19612v2",
    "published_date": "2024-10-25 15:04:37 UTC",
    "updated_date": "2025-02-21 14:19:38 UTC"
  },
  {
    "arxiv_id": "2410.19609v1",
    "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
    "authors": [
      "Hongliang He",
      "Wenlin Yao",
      "Kaixin Ma",
      "Wenhao Yu",
      "Hongming Zhang",
      "Tianqing Fang",
      "Zhenzhong Lan",
      "Dong Yu"
    ],
    "abstract": "The rapid development of large language and multimodal models has sparked\nsignificant interest in using proprietary models, such as GPT-4o, to develop\nautonomous agents capable of handling real-world scenarios like web navigation.\nAlthough recent open-source efforts have tried to equip agents with the ability\nto explore environments and continuously improve over time, they are building\ntext-only agents in synthetic environments where the reward signals are clearly\ndefined. Such agents struggle to generalize to realistic settings that require\nmultimodal perception abilities and lack ground-truth signals. In this paper,\nwe introduce an open-source framework designed to facilitate the development of\nmultimodal web agent that can autonomously conduct real-world exploration and\nimprove itself. We first train the base model with imitation learning to gain\nthe basic abilities. We then let the agent explore the open web and collect\nfeedback on its trajectories. After that, it further improves its policy by\nlearning from well-performing trajectories judged by another general-purpose\nmodel. This exploration-feedback-optimization cycle can continue for several\niterations. Experimental results show that our web agent successfully improves\nitself after each iteration, demonstrating strong performance across multiple\ntest sets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19609v1",
    "published_date": "2024-10-25 15:01:27 UTC",
    "updated_date": "2024-10-25 15:01:27 UTC"
  },
  {
    "arxiv_id": "2410.19605v1",
    "title": "CoqPilot, a plugin for LLM-based generation of proofs",
    "authors": [
      "Andrei Kozyrev",
      "Gleb Solovev",
      "Nikita Khramov",
      "Anton Podkopaev"
    ],
    "abstract": "We present CoqPilot, a VS Code extension designed to help automate writing of\nCoq proofs. The plugin collects the parts of proofs marked with the admit\ntactic in a Coq file, i.e., proof holes, and combines LLMs along with\nnon-machine-learning methods to generate proof candidates for the holes. Then,\nCoqPilot checks if each proof candidate solves the given subgoal and, if\nsuccessful, replaces the hole with it. The focus of CoqPilot is twofold.\nFirstly, we want to allow users to seamlessly combine multiple Coq generation\napproaches and provide a zero-setup experience for our tool. Secondly, we want\nto deliver a platform for LLM-based experiments on Coq proof generation. We\ndeveloped a benchmarking system for Coq generation methods, available in the\nplugin, and conducted an experiment using it, showcasing the framework's\npossibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo.\nCode at: https://github.com/JetBrains-Research/coqpilot",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.SE",
    "comment": "Published in the proceedings of the ASE'24 Tool Demonstrations Track",
    "pdf_url": "http://arxiv.org/pdf/2410.19605v1",
    "published_date": "2024-10-25 14:57:29 UTC",
    "updated_date": "2024-10-25 14:57:29 UTC"
  },
  {
    "arxiv_id": "2410.19599v3",
    "title": "Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina",
    "authors": [
      "Yuan Gao",
      "Dokyun Lee",
      "Gordon Burtch",
      "Sina Fazelpour"
    ],
    "abstract": "Recent studies suggest large language models (LLMs) can exhibit human-like\nreasoning, aligning with human behavior in economic experiments, surveys, and\npolitical discourse. This has led many to propose that LLMs can be used as\nsurrogates or simulations for humans in social science research. However, LLMs\ndiffer fundamentally from humans, relying on probabilistic patterns, absent the\nembodied experiences or survival objectives that shape human cognition. We\nassess the reasoning depth of LLMs using the 11-20 money request game. Nearly\nall advanced approaches fail to replicate human behavior distributions across\nmany models. Causes of failure are diverse and unpredictable, relating to input\nlanguage, roles, and safeguarding. These results advise caution when using LLMs\nto study human behavior or as surrogates or simulations.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19599v3",
    "published_date": "2024-10-25 14:46:07 UTC",
    "updated_date": "2025-01-23 17:05:40 UTC"
  },
  {
    "arxiv_id": "2410.19560v1",
    "title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning",
    "authors": [
      "Shentong Mo",
      "Shengbang Tong"
    ],
    "abstract": "In recent advancements in unsupervised visual representation learning, the\nJoint-Embedding Predictive Architecture (JEPA) has emerged as a significant\nmethod for extracting visual features from unlabeled imagery through an\ninnovative masking strategy. Despite its success, two primary limitations have\nbeen identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA\nin preventing entire collapse and the inadequacy of I-JEPA prediction in\naccurately learning the mean of patch representations. Addressing these\nchallenges, this study introduces a novel framework, namely C-JEPA\n(Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive\nArchitecture with the Variance-Invariance-Covariance Regularization (VICReg)\nstrategy. This integration is designed to effectively learn the\nvariance/covariance for preventing entire collapse and ensuring invariance in\nthe mean of augmented views, thereby overcoming the identified limitations.\nThrough empirical and theoretical evaluations, our work demonstrates that\nC-JEPA significantly enhances the stability and quality of visual\nrepresentation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA\nexhibits rapid and improved convergence in both linear probing and fine-tuning\nperformance metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19560v1",
    "published_date": "2024-10-25 13:48:12 UTC",
    "updated_date": "2024-10-25 13:48:12 UTC"
  },
  {
    "arxiv_id": "2410.19553v1",
    "title": "On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes",
    "authors": [
      "Rajat Modi",
      "Vibhav Vineet",
      "Yogesh Singh Rawat"
    ],
    "abstract": "This paper explores the impact of occlusions in video action detection. We\nfacilitate this study by introducing five new benchmark datasets namely O-UCF\nand O-JHMDB consisting of synthetically controlled static/dynamic occlusions,\nOVIS-UCF and OVIS-JHMDB consisting of occlusions with realistic motions and\nReal-OUCF for occlusions in realistic-world scenarios. We formally confirm an\nintuitive expectation: existing models suffer a lot as occlusion severity is\nincreased and exhibit different behaviours when occluders are static vs when\nthey are moving. We discover several intriguing phenomenon emerging in neural\nnets: 1) transformers can naturally outperform CNN models which might have even\nused occlusion as a form of data augmentation during training 2) incorporating\nsymbolic-components like capsules to such backbones allows them to bind to\noccluders never even seen during training and 3) Islands of agreement can\nemerge in realistic images/videos without instance-level supervision,\ndistillation or contrastive-based objectives2(eg. video-textual training). Such\nemergent properties allow us to derive simple yet effective training recipes\nwhich lead to robust occlusion models inductively satisfying the first two\nstages of the binding mechanism (grouping/segregation). Models leveraging these\nrecipes outperform existing video action-detectors under occlusion by 32.3% on\nO-UCF, 32.7% on O-JHMDB & 2.6% on Real-OUCF in terms of the vMAP metric. The\ncode for this work has been released at\nhttps://github.com/rajatmodi62/OccludedActionBenchmark.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper was accepted to NeurIPS 2023 Dataset And Benchmark Track.\n  It also showcases: Hinton's Islands of Agreement on realistic datasets which\n  were previously hypothesized in his GLOM paper",
    "pdf_url": "http://arxiv.org/pdf/2410.19553v1",
    "published_date": "2024-10-25 13:27:55 UTC",
    "updated_date": "2024-10-25 13:27:55 UTC"
  },
  {
    "arxiv_id": "2410.19550v2",
    "title": "DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks",
    "authors": [
      "Yu Qiao",
      "Lina Gong",
      "Yu Zhao",
      "Yongwei Wang",
      "Mingqiang Wei"
    ],
    "abstract": "Software defect prediction (SDP) aims to identify high-risk defect modules in\nsoftware development, optimizing resource allocation. While previous studies\nshow that dependency network metrics improve defect prediction, most methods\nfocus on code-based dependency graphs, overlooking developer factors. Current\nmetrics, based on handcrafted features like ego and global network metrics,\nfail to fully capture defect-related information. To address this, we propose\nDeMuVGN, a defect prediction model that learns multi-view software dependency\nvia graph neural networks. We introduce a Multi-view Software Dependency Graph\n(MSDG) that integrates data, call, and developer dependencies. DeMuVGN also\nleverages the Synthetic Minority Oversampling Technique (SMOTE) to address\nclass imbalance and enhance defect module identification. In a case study of\neight open-source projects across 20 versions, DeMuVGN demonstrates significant\nimprovements: i) models based on multi-view graphs improve F1 scores by 11.1%\nto 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to\n45.8% in within-project contexts and by 17.9% to 41.0% in cross-project\ncontexts. Additionally, DeMuVGN excels in software evolution, showing more\nimprovement in later-stage software versions. Its strong performance across\ndifferent projects highlights its generalizability. We recommend future\nresearch focus on multi-view dependency graphs for defect prediction in both\nmature and newly developed projects.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "The current paper is not comprehensive enough. We are seeking further\n  improvement",
    "pdf_url": "http://arxiv.org/pdf/2410.19550v2",
    "published_date": "2024-10-25 13:24:04 UTC",
    "updated_date": "2025-05-07 05:20:30 UTC"
  },
  {
    "arxiv_id": "2410.19546v3",
    "title": "Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?",
    "authors": [
      "Antonia Wüst",
      "Tim Tobiasch",
      "Lukas Helff",
      "Inga Ibs",
      "Wolfgang Stammer",
      "Devendra S. Dhami",
      "Constantin A. Rothkopf",
      "Kristian Kersting"
    ],
    "abstract": "Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1,\nhave emerged, seemingly demonstrating advanced reasoning capabilities across\ntext and image modalities. However, the depth of these advances in\nlanguage-guided perception and abstract reasoning remains underexplored, and it\nis unclear whether these models can truly live up to their ambitious promises.\nTo assess the progress and identify shortcomings, we enter the wonderland of\nBongard problems, a set of classic visual reasoning puzzles that require\nhuman-like abilities of pattern recognition and abstract reasoning. With our\nextensive evaluation setup, we show that while VLMs occasionally succeed in\nidentifying discriminative concepts and solving some of the problems, they\nfrequently falter. Surprisingly, even elementary concepts that may seem trivial\nto humans, such as simple spirals, pose significant challenges. Moreover, when\nexplicitly asked to recognize ground truth concepts, they continue to falter,\nsuggesting not only a lack of understanding of these elementary visual concepts\nbut also an inability to generalize to unseen concepts. We compare the results\nof VLMs to human performance and observe that a significant gap remains between\nhuman visual reasoning capabilities and machine cognition.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19546v3",
    "published_date": "2024-10-25 13:19:26 UTC",
    "updated_date": "2025-02-25 09:27:57 UTC"
  },
  {
    "arxiv_id": "2410.19544v1",
    "title": "PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation",
    "authors": [
      "Huajian Liu",
      "Wei Dong",
      "Kunpeng Fan",
      "Chao Wang",
      "Yongzhuo Gao"
    ],
    "abstract": "Analyzing and forecasting trajectories of agents like pedestrians plays a\npivotal role for embodied intelligent applications. The inherent indeterminacy\nof human behavior and complex social interaction among a rich variety of agents\nmake this task more challenging than common time-series forecasting. In this\nletter, we aim to explore a distinct formulation for multi-agent trajectory\nprediction framework. Specifically, we proposed a patching-based temporal\nfeature extraction module and a graph-based social feature extraction module,\nenabling effective feature extraction and cross-scenario generalization.\nMoreover, we reassess the role of social interaction and present a novel method\nbased on explicit modality modulation to integrate temporal and social\nfeatures, thereby constructing an efficient single-stage inference pipeline.\nResults on public benchmark datasets demonstrate the superior performance of\nour model compared with the state-of-the-art methods. The code is available at:\ngithub.com/TIB-K330/pmm-net.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19544v1",
    "published_date": "2024-10-25 13:16:27 UTC",
    "updated_date": "2024-10-25 13:16:27 UTC"
  },
  {
    "arxiv_id": "2410.19542v2",
    "title": "Brain-like Functional Organization within Large Language Models",
    "authors": [
      "Haiyang Sun",
      "Lin Zhao",
      "Zihao Wu",
      "Xiaohui Gao",
      "Yutao Hu",
      "Mengfei Zuo",
      "Wei Zhang",
      "Junwei Han",
      "Tianming Liu",
      "Xintao Hu"
    ],
    "abstract": "The human brain has long inspired the pursuit of artificial intelligence\n(AI). Recently, neuroimaging studies provide compelling evidence of alignment\nbetween the computational representation of artificial neural networks (ANNs)\nand the neural responses of the human brain to stimuli, suggesting that ANNs\nmay employ brain-like information processing strategies. While such alignment\nhas been observed across sensory modalities--visual, auditory, and\nlinguistic--much of the focus has been on the behaviors of artificial neurons\n(ANs) at the population level, leaving the functional organization of\nindividual ANs that facilitates such brain-like processes largely unexplored.\nIn this study, we bridge this gap by directly coupling sub-groups of artificial\nneurons with functional brain networks (FBNs), the foundational organizational\nstructure of the human brain. Specifically, we extract representative patterns\nfrom temporal responses of ANs in large language models (LLMs), and use them as\nfixed regressors to construct voxel-wise encoding models to predict brain\nactivity recorded by functional magnetic resonance imaging (fMRI). This\nframework links the AN sub-groups to FBNs, enabling the delineation of\nbrain-like functional organization within LLMs. Our findings reveal that LLMs\n(BERT and Llama 1-3) exhibit brain-like functional architecture, with\nsub-groups of artificial neurons mirroring the organizational patterns of\nwell-established FBNs. Notably, the brain-like functional organization of LLMs\nevolves with the increased sophistication and capability, achieving an improved\nbalance between the diversity of computational behaviors and the consistency of\nfunctional specializations. This research represents the first exploration of\nbrain-like functional organization within LLMs, offering novel insights to\ninform the development of artificial general intelligence (AGI) with human\nbrain principles.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19542v2",
    "published_date": "2024-10-25 13:15:17 UTC",
    "updated_date": "2024-10-31 03:24:57 UTC"
  },
  {
    "arxiv_id": "2410.19540v1",
    "title": "CloserMusicDB: A Modern Multipurpose Dataset of High Quality Music",
    "authors": [
      "Aleksandra Piekarzewicz",
      "Tomasz Sroka",
      "Aleksander Tym",
      "Mateusz Modrzejewski"
    ],
    "abstract": "In this paper, we introduce CloserMusicDB, a collection of full length studio\nquality tracks annotated by a team of human experts. We describe the selected\nqualities of our dataset, along with three example tasks possible to perform\nusing this dataset: hook detection, contextual tagging and artist\nidentification. We conduct baseline experiments and provide initial benchmarks\nfor these tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19540v1",
    "published_date": "2024-10-25 13:11:19 UTC",
    "updated_date": "2024-10-25 13:11:19 UTC"
  },
  {
    "arxiv_id": "2410.19504v1",
    "title": "DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction",
    "authors": [
      "Zelin Zang",
      "Yuhao Wang",
      "Jinlin Wu",
      "Hong Liu",
      "Yue Shen",
      "Stan. Z Li",
      "Zhen Lei"
    ],
    "abstract": "Dimensionality reduction (DR) plays a crucial role in various fields,\nincluding data engineering and visualization, by simplifying complex datasets\nwhile retaining essential information. However, the challenge of balancing DR\naccuracy and interpretability remains crucial, particularly for users dealing\nwith high-dimensional data. Traditional DR methods often face a trade-off\nbetween precision and transparency, where optimizing for performance can lead\nto reduced interpretability, and vice versa. This limitation is especially\nprominent in real-world applications such as image, tabular, and text data\nanalysis, where both accuracy and interpretability are critical. To address\nthese challenges, this work introduces the MOE-based Hyperbolic Interpretable\nDeep Manifold Transformation (DMT-HI). The proposed approach combines\nhyperbolic embeddings, which effectively capture complex hierarchical\nstructures, with Mixture of Experts (MOE) models, which dynamically allocate\ntasks based on input features. DMT-HI enhances DR accuracy by leveraging\nhyperbolic embeddings to represent the hierarchical nature of data, while also\nimproving interpretability by explicitly linking input data, embedding\noutcomes, and key features through the MOE structure. Extensive experiments\ndemonstrate that DMT-HI consistently achieves superior performance in both DR\naccuracy and model interpretability, making it a robust solution for complex\ndata analysis. The code is available at\n\\url{https://github.com/zangzelin/code_dmthi}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19504v1",
    "published_date": "2024-10-25 12:11:32 UTC",
    "updated_date": "2024-10-25 12:11:32 UTC"
  },
  {
    "arxiv_id": "2410.19479v1",
    "title": "Peter Parker or Spiderman? Disambiguating Multiple Class Labels",
    "authors": [
      "Nuthan Mummani",
      "Simran Ketha",
      "Venkatakrishnan Ramaswamy"
    ],
    "abstract": "In the supervised classification setting, during inference, deep networks\ntypically make multiple predictions. For a pair of such predictions (that are\nin the top-k predictions), two distinct possibilities might occur. On the one\nhand, each of the two predictions might be primarily driven by two distinct\nsets of entities in the input. On the other hand, it is possible that there is\na single entity or set of entities that is driving the prediction for both the\nclasses in question. This latter case, in effect, corresponds to the network\nmaking two separate guesses about the identity of a single entity type.\nClearly, both the guesses cannot be true, i.e. both the labels cannot be\npresent in the input. Current techniques in interpretability research do not\nreadily disambiguate these two cases, since they typically consider input\nattributions for one class label at a time. Here, we present a framework and\nmethod to do so, leveraging modern segmentation and input attribution\ntechniques. Notably, our framework also provides a simple counterfactual\n\"proof\" of each case, which can be verified for the input on the model (i.e.\nwithout running the method again). We demonstrate that the method performs well\nfor a number of samples from the ImageNet validation set and on multiple\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to Neural Information Processing Systems (NeurIPS 2024).\n  ATTRIB Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.19479v1",
    "published_date": "2024-10-25 11:16:28 UTC",
    "updated_date": "2024-10-25 11:16:28 UTC"
  },
  {
    "arxiv_id": "2410.19471v1",
    "title": "Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization",
    "authors": [
      "Ryan Park",
      "Darren J. Hsu",
      "C. Brian Roland",
      "Maria Korshunova",
      "Chen Tessler",
      "Shie Mannor",
      "Olivia Viessmann",
      "Bruno Trentini"
    ],
    "abstract": "Inverse folding models play an important role in structure-based design by\npredicting amino acid sequences that fold into desired reference structures.\nModels like ProteinMPNN, a message-passing encoder-decoder model, are trained\nto reliably produce new sequences from a reference structure. However, when\napplied to peptides, these models are prone to generating repetitive sequences\nthat do not fold into the reference structure. To address this, we fine-tune\nProteinMPNN to produce diverse and structurally consistent peptide sequences\nvia Direct Preference Optimization (DPO). We derive two enhancements to DPO:\nonline diversity regularization and domain-specific priors. Additionally, we\ndevelop a new understanding on improving diversity in decoder models. When\nconditioned on OpenFold generated structures, our fine-tuned models achieve\nstate-of-the-art structural similarity scores, improving base ProteinMPNN by at\nleast 8%. Compared to standard DPO, our regularized method achieves up to 20%\nhigher sequence diversity with no loss in structural similarity score.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. 10 pages plus appendices",
    "pdf_url": "http://arxiv.org/pdf/2410.19471v1",
    "published_date": "2024-10-25 11:04:02 UTC",
    "updated_date": "2024-10-25 11:04:02 UTC"
  },
  {
    "arxiv_id": "2410.19469v1",
    "title": "Unified Causality Analysis Based on the Degrees of Freedom",
    "authors": [
      "András Telcs",
      "Marcell T. Kurbucz",
      "Antal Jakovác"
    ],
    "abstract": "Temporally evolving systems are typically modeled by dynamic equations. A key\nchallenge in accurate modeling is understanding the causal relationships\nbetween subsystems, as well as identifying the presence and influence of\nunobserved hidden drivers on the observed dynamics. This paper presents a\nunified method capable of identifying fundamental causal relationships between\npairs of systems, whether deterministic or stochastic. Notably, the method also\nuncovers hidden common causes beyond the observed variables. By analyzing the\ndegrees of freedom in the system, our approach provides a more comprehensive\nunderstanding of both causal influence and hidden confounders. This unified\nframework is validated through theoretical models and simulations,\ndemonstrating its robustness and potential for broader application.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "stat.ME",
    "comment": "32 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19469v1",
    "published_date": "2024-10-25 10:57:35 UTC",
    "updated_date": "2024-10-25 10:57:35 UTC"
  },
  {
    "arxiv_id": "2410.19464v4",
    "title": "LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data",
    "authors": [
      "Jiajun Zhang",
      "Boyang Qiang",
      "Xiaoyu Guo",
      "Weiwei Xing",
      "Yue Cheng",
      "Witold Pedrycz"
    ],
    "abstract": "Discovering the underlying Directed Acyclic Graph (DAG) from time series\nobservational data is highly challenging due to the dynamic nature and complex\nnonlinear interactions between variables. Existing methods typically search for\nthe optimal DAG by optimizing an objective function but face scalability\nchallenges, as their computational demands grow exponentially with the\ndimensional expansion of variables. To this end, we propose LOCAL, a highly\nefficient, easy-to-implement, and constraint-free method for recovering dynamic\ncausal structures. LOCAL is the first attempt to formulate a quasi-maximum\nlikelihood-based score function for learning the dynamic DAG equivalent to the\nground truth. Building on this, we introduce two adaptive modules that enhance\nthe algebraic characterization of acyclicity: Asymptotic Causal Mask Learning\n(ACML) and Dynamic Graph Parameter Learning (DGPL). ACML constructs causal\nmasks using learnable priority vectors and the Gumbel-Sigmoid function,\nensuring DAG formation while optimizing computational efficiency. DGPL\ntransforms causal learning into decomposed matrix products, capturing dynamic\ncausal structure in high-dimensional data and improving interpretability.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nLOCAL significantly outperforms existing methods and highlight LOCAL's\npotential as a robust and efficient method for dynamic causal discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19464v4",
    "published_date": "2024-10-25 10:48:41 UTC",
    "updated_date": "2025-03-20 03:32:03 UTC"
  },
  {
    "arxiv_id": "2410.19461v2",
    "title": "EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data",
    "authors": [
      "Xuetian Chen",
      "Hangcheng Li",
      "Jiaqing Liang",
      "Sihang Jiang",
      "Deqing Yang"
    ],
    "abstract": "Autonomous agents operating on the graphical user interfaces (GUIs) of\nvarious applications hold immense practical value. Unlike the large language\nmodel (LLM)-based methods which rely on structured texts and customized\nbackends, the approaches using large vision-language models (LVLMs) are more\nintuitive and adaptable as they can visually perceive and directly interact\nwith screens, making them indispensable in general scenarios without text\nmetadata and tailored backends. Given the lack of high-quality training data\nfor GUI-related tasks in existing work, this paper aims to enhance the GUI\nunderstanding and interacting capabilities of LVLMs through a data-driven\napproach. We propose EDGE, a general data synthesis framework that\nautomatically generates large-scale, multi-granularity training data from\nwebpages across the Web. Evaluation results on various GUI and agent benchmarks\ndemonstrate that the model trained with the dataset generated through EDGE\nexhibits superior webpage understanding capabilities, which can then be easily\ntransferred to previously unseen desktop and mobile environments. Our approach\nsignificantly reduces the dependence on manual annotations, empowering\nresearchers to harness the vast public resources available on the Web to\nadvance their work. Our source code, the dataset and the model are available at\nhttps://anonymous.4open.science/r/EDGE-1CDB.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19461v2",
    "published_date": "2024-10-25 10:46:17 UTC",
    "updated_date": "2024-11-02 08:54:21 UTC"
  },
  {
    "arxiv_id": "2410.19460v2",
    "title": "Accelerating AI Performance using Anderson Extrapolation on GPUs",
    "authors": [
      "Saleem Abdul Fattah Ahmed Al Dajani",
      "David E. Keyes"
    ],
    "abstract": "We present a novel approach for accelerating AI performance by leveraging\nAnderson extrapolation, a vector-to-vector mapping technique based on a window\nof historical iterations. By identifying the crossover point (Fig. 1) where a\nmixing penalty is incurred, the method focuses on reducing iterations to\nconvergence, with fewer more compute-intensive but generally cacheable\niterations, balancing speed and memory usage with accuracy and algorithmic\nstability, respectively. We demonstrate significant improvements, in both\ntraining and inference, motivated by scalability and efficiency extensions to\nthe realm of high-performance computing (HPC).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "cs.PF",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 6 figures, 1 table, Accepted by NeurIPS 2024 Workshop MLNCP\n  https://openreview.net/forum?id=wkP2ZFRn9e",
    "pdf_url": "http://arxiv.org/pdf/2410.19460v2",
    "published_date": "2024-10-25 10:45:17 UTC",
    "updated_date": "2024-12-19 04:49:52 UTC"
  },
  {
    "arxiv_id": "2410.19452v3",
    "title": "NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction",
    "authors": [
      "Zixuan Gong",
      "Guangyin Bao",
      "Qi Zhang",
      "Zhongwei Wan",
      "Duoqian Miao",
      "Shoujin Wang",
      "Lei Zhu",
      "Changwei Wang",
      "Rongtao Xu",
      "Liang Hu",
      "Ke Liu",
      "Yu Zhang"
    ],
    "abstract": "Reconstruction of static visual stimuli from non-invasion brain activity fMRI\nachieves great success, owning to advanced deep learning models such as CLIP\nand Stable Diffusion. However, the research on fMRI-to-video reconstruction\nremains limited since decoding the spatiotemporal perception of continuous\nvisual experiences is formidably challenging. We contend that the key to\naddressing these challenges lies in accurately decoding both high-level\nsemantics and low-level perception flows, as perceived by the brain in response\nto video stimuli. To the end, we propose NeuroClips, an innovative framework to\ndecode high-fidelity and smooth video from fMRI. NeuroClips utilizes a\nsemantics reconstructor to reconstruct video keyframes, guiding semantic\naccuracy and consistency, and employs a perception reconstructor to capture\nlow-level perceptual details, ensuring video smoothness. During inference, it\nadopts a pre-trained T2V diffusion model injected with both keyframes and\nlow-level perception flows for video reconstruction. Evaluated on a publicly\navailable fMRI-video dataset, NeuroClips achieves smooth high-fidelity video\nreconstruction of up to 6s at 8FPS, gaining significant improvements over\nstate-of-the-art models in various metrics, e.g., a 128% improvement in SSIM\nand an 81% improvement in spatiotemporal metrics. Our project is available at\nhttps://github.com/gongzix/NeuroClips.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "NeurIPS 2024 Oral",
    "pdf_url": "http://arxiv.org/pdf/2410.19452v3",
    "published_date": "2024-10-25 10:28:26 UTC",
    "updated_date": "2024-12-15 08:24:41 UTC"
  },
  {
    "arxiv_id": "2410.19451v1",
    "title": "Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework",
    "authors": [
      "Yirui Chen",
      "Qinyu Xiao",
      "Jia Yi",
      "Jing Chen",
      "Mengyang Wang"
    ],
    "abstract": "This paper explores the application of prompt engineering to enhance the\nperformance of large language models (LLMs) in the domain of Traditional\nChinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates\nvarious pre-trained language models (PLMs), templates, tokenization, and\nverbalization methods, allowing researchers to easily construct and fine-tune\nmodels for specific TCM-related tasks. We conducted experiments on disease\nclassification, syndrome identification, herbal medicine recommendation, and\ngeneral NLP tasks, demonstrating the effectiveness and superiority of our\napproach compared to baseline methods. Our findings suggest that prompt\nengineering is a promising technique for improving the performance of LLMs in\nspecialized domains like TCM, with potential applications in digitalization,\nmodernization, and personalized medicine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19451v1",
    "published_date": "2024-10-25 10:24:30 UTC",
    "updated_date": "2024-10-25 10:24:30 UTC"
  },
  {
    "arxiv_id": "2410.19450v1",
    "title": "Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration",
    "authors": [
      "Hai Zhong",
      "Xun Wang",
      "Zhuoran Li",
      "Longbo Huang"
    ],
    "abstract": "Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm,\nleveraging offline data for initialization and online fine-tuning to enhance\nboth sample efficiency and performance. However, most existing research has\nfocused on single-agent settings, with limited exploration of the multi-agent\nextension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O\nMARL). In O2O MARL, two critical challenges become more prominent as the number\nof agents increases: (i) the risk of unlearning pre-trained Q-values due to\ndistributional shifts during the transition from offline-to-online phases, and\n(ii) the difficulty of efficient exploration in the large joint state-action\nspace. To tackle these challenges, we propose a novel O2O MARL framework called\nOffline Value Function Memory with Sequential Exploration (OVMSE). First, we\nintroduce the Offline Value Function Memory (OVM) mechanism to compute target\nQ-values, preserving knowledge gained during offline training, ensuring\nsmoother transitions, and enabling efficient fine-tuning. Second, we propose a\ndecentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which\neffectively utilizes the pre-trained offline policy for exploration, thereby\nsignificantly reducing the joint state-action space to be explored. Extensive\nexperiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that\nOVMSE significantly outperforms existing baselines, achieving superior sample\nefficiency and overall performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19450v1",
    "published_date": "2024-10-25 10:24:19 UTC",
    "updated_date": "2024-10-25 10:24:19 UTC"
  },
  {
    "arxiv_id": "2410.19448v1",
    "title": "Gradient Descent Efficiency Index",
    "authors": [
      "Aviral Dhingra"
    ],
    "abstract": "Gradient descent is a widely used iterative algorithm for finding local\nminima in multivariate functions. However, the final iterations often either\novershoot the minima or make minimal progress, making it challenging to\ndetermine an optimal stopping point. This study introduces a new efficiency\nmetric, Ek, designed to quantify the effectiveness of each iteration. The\nproposed metric accounts for both the relative change in error and the\nstability of the loss function across iterations. This measure is particularly\nvaluable in resource-constrained environments, where costs are closely tied to\ntraining time. Experimental validation across multiple datasets and models\ndemonstrates that Ek provides valuable insights into the convergence behavior\nof gradient descent, complementing traditional performance metrics. The index\nhas the potential to guide more informed decisions in the selection and tuning\nof optimization algorithms in machine learning applications and be used to\ncompare the \"effectiveness\" of models relative to each other.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "12 Pages, 3 Figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19448v1",
    "published_date": "2024-10-25 10:22:22 UTC",
    "updated_date": "2024-10-25 10:22:22 UTC"
  },
  {
    "arxiv_id": "2410.19427v1",
    "title": "Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models",
    "authors": [
      "Yige Li",
      "Hanxun Huang",
      "Jiaming Zhang",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "abstract": "Backdoor attacks covertly implant triggers into deep neural networks (DNNs)\nby poisoning a small portion of the training data with pre-designed backdoor\ntriggers. This vulnerability is exacerbated in the era of large models, where\nextensive (pre-)training on web-crawled datasets is susceptible to compromise.\nIn this paper, we introduce a novel two-step defense framework named Expose\nBefore You Defend (EBYD). EBYD unifies existing backdoor defense methods into a\ncomprehensive defense system with enhanced performance. Specifically, EBYD\nfirst exposes the backdoor functionality in the backdoored model through a\nmodel preprocessing step called backdoor exposure, and then applies detection\nand removal methods to the exposed model to identify and eliminate the backdoor\nfeatures. In the first step of backdoor exposure, we propose a novel technique\ncalled Clean Unlearning (CUL), which proactively unlearns clean features from\nthe backdoored model to reveal the hidden backdoor features. We also explore\nvarious model editing/modification techniques for backdoor exposure, including\nfine-tuning, model sparsification, and weight perturbation. Using EBYD, we\nconduct extensive experiments on 10 image attacks and 6 text attacks across 2\nvision datasets (CIFAR-10 and an ImageNet subset) and 4 language datasets\n(SST-2, IMDB, Twitter, and AG's News). The results demonstrate the importance\nof backdoor exposure for backdoor defense, showing that the exposed models can\nsignificantly benefit a range of downstream defense tasks, including backdoor\nlabel detection, backdoor trigger recovery, backdoor model detection, and\nbackdoor removal. We hope our work could inspire more research in developing\nadvanced defense frameworks with exposed models. Our code is available at:\nhttps://github.com/bboylyg/Expose-Before-You-Defend.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19427v1",
    "published_date": "2024-10-25 09:36:04 UTC",
    "updated_date": "2024-10-25 09:36:04 UTC"
  },
  {
    "arxiv_id": "2410.19412v1",
    "title": "Robust Time Series Causal Discovery for Agent-Based Model Validation",
    "authors": [
      "Gene Yu",
      "Ce Guo",
      "Wayne Luk"
    ],
    "abstract": "Agent-Based Model (ABM) validation is crucial as it helps ensuring the\nreliability of simulations, and causal discovery has become a powerful tool in\nthis context. However, current causal discovery methods often face accuracy and\nrobustness challenges when applied to complex and noisy time series data, which\nis typical in ABM scenarios. This study addresses these issues by proposing a\nRobust Cross-Validation (RCV) approach to enhance causal structure learning for\nABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two\nprominent causal discovery algorithms. These aim to reduce the impact of noise\nbetter and give more reliable causal relation results, even with\nhigh-dimensional, time-dependent data. The proposed approach is then integrated\ninto an enhanced ABM validation framework, which is designed to handle diverse\ndata and model structures.\n  The approach is evaluated using synthetic datasets and a complex simulated\nfMRI dataset. The results demonstrate greater reliability in causal structure\nidentification. The study examines how various characteristics of datasets\naffect the performance of established causal discovery methods. These\ncharacteristics include linearity, noise distribution, stationarity, and causal\nstructure density. This analysis is then extended to the RCV method to see how\nit compares in these different situations. This examination helps confirm\nwhether the results are consistent with existing literature and also reveals\nthe strengths and weaknesses of the novel approaches.\n  By tackling key methodological challenges, the study aims to enhance ABM\nvalidation with a more resilient valuation framework presented. These\nimprovements increase the reliability of model-driven decision making processes\nin complex systems analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "econ.EM",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19412v1",
    "published_date": "2024-10-25 09:13:26 UTC",
    "updated_date": "2024-10-25 09:13:26 UTC"
  },
  {
    "arxiv_id": "2410.19400v4",
    "title": "Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression",
    "authors": [
      "Yixiu Mao",
      "Qi Wang",
      "Chen Chen",
      "Yun Qu",
      "Xiangyang Ji"
    ],
    "abstract": "In offline reinforcement learning (RL), addressing the out-of-distribution\n(OOD) action issue has been a focus, but we argue that there exists an OOD\nstate issue that also impairs performance yet has been underexplored. Such an\nissue describes the scenario when the agent encounters states out of the\noffline dataset during the test phase, leading to uncontrolled behavior and\nperformance degradation. To this end, we propose SCAS, a simple yet effective\napproach that unifies OOD state correction and OOD action suppression in\noffline RL. Technically, SCAS achieves value-aware OOD state correction,\ncapable of correcting the agent from OOD states to high-value in-distribution\nstates. Theoretical and empirical results show that SCAS also exhibits the\neffect of suppressing OOD actions. On standard offline RL benchmarks, SCAS\nachieves excellent performance without additional hyperparameter tuning.\nMoreover, benefiting from its OOD state correction feature, SCAS demonstrates\nenhanced robustness against environmental perturbations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19400v4",
    "published_date": "2024-10-25 09:01:37 UTC",
    "updated_date": "2024-11-01 07:20:10 UTC"
  },
  {
    "arxiv_id": "2410.19394v2",
    "title": "Analysis of Financial Risk Behavior Prediction Using Deep Learning and Big Data Algorithms",
    "authors": [
      "Haowei Yang",
      "Zhan Cheng",
      "Zhaoyang Zhang",
      "Yuanshuai Luo",
      "Shuaishuai Huang",
      "Ao Xiang"
    ],
    "abstract": "As the complexity and dynamism of financial markets continue to grow,\ntraditional financial risk prediction methods increasingly struggle to handle\nlarge datasets and intricate behavior patterns. This paper explores the\nfeasibility and effectiveness of using deep learning and big data algorithms\nfor financial risk behavior prediction. First, the application and advantages\nof deep learning and big data algorithms in the financial field are analyzed.\nThen, a deep learning-based big data risk prediction framework is designed and\nexperimentally validated on actual financial datasets. The experimental results\nshow that this method significantly improves the accuracy of financial risk\nbehavior prediction and provides valuable support for risk management in\nfinancial institutions. Challenges in the application of deep learning are also\ndiscussed, along with potential directions for future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19394v2",
    "published_date": "2024-10-25 08:52:04 UTC",
    "updated_date": "2024-12-23 03:08:49 UTC"
  },
  {
    "arxiv_id": "2410.19390v1",
    "title": "CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation",
    "authors": [
      "Qiufan Lin",
      "Hengxin Ruan",
      "Dominique Fouchez",
      "Shupei Chen",
      "Rui Li",
      "Paulo Montero-Camacho",
      "Nicola R. Napolitano",
      "Yuan-Sen Ting",
      "Wei Zhang"
    ],
    "abstract": "Obtaining well-calibrated photometric redshift probability densities for\ngalaxies without a spectroscopic measurement remains a challenge. Deep learning\ndiscriminative models, typically fed with multi-band galaxy images, can produce\noutputs that mimic probability densities and achieve state-of-the-art accuracy.\nHowever, such models may be affected by miscalibration that would result in\ndiscrepancies between the model outputs and the actual distributions of true\nredshifts. Our work develops a novel method called the Contrastive Learning and\nAdaptive KNN for Photometric Redshift (CLAP) that resolves this issue. It\nleverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)\nto construct and calibrate raw probability density estimates, and implements a\nrefitting procedure to resume end-to-end discriminative models ready to produce\nfinal estimates for large-scale imaging data. The harmonic mean is adopted to\ncombine an ensemble of estimates from multiple realisations for improving\naccuracy. Our experiments demonstrate that CLAP takes advantage of both deep\nlearning and KNN, outperforming benchmark methods on the calibration of\nprobability density estimates and retaining high accuracy and computational\nefficiency. With reference to CLAP, we point out that miscalibration is\nparticularly sensitive to the method-induced excessive correlations among data\ninstances in addition to the unaccounted-for epistemic uncertainties. Reducing\nthe uncertainties may not guarantee the removal of miscalibration due to the\npresence of such excessive correlations, yet this is a problem for conventional\ndeep learning methods rather than CLAP. These discussions underscore the\nrobustness of CLAP for obtaining photometric redshift probability densities\nrequired by astrophysical and cosmological applications. This is the first\npaper in our series on CLAP.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "22 + 6 pages, 9 + 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19390v1",
    "published_date": "2024-10-25 08:46:55 UTC",
    "updated_date": "2024-10-25 08:46:55 UTC"
  },
  {
    "arxiv_id": "2410.19385v1",
    "title": "Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models",
    "authors": [
      "Liam Barkley",
      "Brink van der Merwe"
    ],
    "abstract": "Large Language Models (LLMs) are powerful computational models trained on\nextensive corpora of human-readable text, enabling them to perform\ngeneral-purpose language understanding and generation. LLMs have garnered\nsignificant attention in both industry and academia due to their exceptional\nperformance across various natural language processing (NLP) tasks. Despite\nthese successes, LLMs often produce inaccuracies, commonly referred to as\nhallucinations. Prompt engineering, the process of designing and formulating\ninstructions for LLMs to perform specific tasks, has emerged as a key approach\nto mitigating hallucinations. This paper provides a comprehensive empirical\nevaluation of different prompting strategies and frameworks aimed at reducing\nhallucinations in LLMs. Various prompting techniques are applied to a broad set\nof benchmark datasets to assess the accuracy and hallucination rate of each\nmethod. Additionally, the paper investigates the influence of tool-calling\nagents (LLMs augmented with external tools to enhance their capabilities beyond\nlanguage generation) on hallucination rates in the same benchmarks. The\nfindings demonstrate that the optimal prompting technique depends on the type\nof problem, and that simpler techniques often outperform more complex methods\nin reducing hallucinations. Furthermore, it is shown that LLM agents can\nexhibit significantly higher hallucination rates due to the added complexity of\nexternal tool usage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19385v1",
    "published_date": "2024-10-25 08:34:53 UTC",
    "updated_date": "2024-10-25 08:34:53 UTC"
  },
  {
    "arxiv_id": "2410.19384v1",
    "title": "Learning Neural Strategy-Proof Matching Mechanism from Examples",
    "authors": [
      "Ryota Maruo",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "abstract": "Designing effective two-sided matching mechanisms is a major problem in\nmechanism design, and the goodness of matching cannot always be formulated.\n  The existing work addresses this issue by searching over a parameterized\nfamily of mechanisms with certain properties by learning to fit a human-crafted\ndataset containing examples of preference profiles and matching results.\n  However, this approach does not consider a strategy-proof mechanism,\nimplicitly assumes the number of agents to be a constant, and does not consider\nthe public contextual information of the agents.\n  In this paper, we propose a new parametric family of strategy-proof matching\nmechanisms by extending the serial dictatorship (SD).\n  We develop a novel attention-based neural network called NeuralSD, which can\nlearn a strategy-proof mechanism from a human-crafted dataset containing public\ncontextual information.\n  NeuralSD is constructed by tensor operations that make SD differentiable and\nlearns a parameterized mechanism by estimating an order of SD from the\ncontextual information.\n  We conducted experiments to learn a strategy-proof matching from matching\nexamples with different numbers of agents.\n  We demonstrated that our method shows the superiority of learning with\ncontext-awareness over a baseline in terms of regression performance and other\nmetrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19384v1",
    "published_date": "2024-10-25 08:34:25 UTC",
    "updated_date": "2024-10-25 08:34:25 UTC"
  },
  {
    "arxiv_id": "2410.19382v2",
    "title": "Multi-Agent Reinforcement Learning with Selective State-Space Models",
    "authors": [
      "Jemma Daniel",
      "Ruan de Kock",
      "Louay Ben Nessir",
      "Sasha Abramowitz",
      "Omayma Mahjoub",
      "Wiem Khlifi",
      "Claude Formanek",
      "Arnu Pretorius"
    ],
    "abstract": "The Transformer model has demonstrated success across a wide range of\ndomains, including in Multi-Agent Reinforcement Learning (MARL) where the\nMulti-Agent Transformer (MAT) has emerged as a leading algorithm in the field.\nHowever, a significant drawback of Transformer models is their quadratic\ncomputational complexity relative to input size, making them computationally\nexpensive when scaling to larger inputs. This limitation restricts MAT's\nscalability in environments with many agents. Recently, State-Space Models\n(SSMs) have gained attention due to their computational efficiency, but their\napplication in MARL remains unexplored. In this work, we investigate the use of\nMamba, a recent SSM, in MARL and assess whether it can match the performance of\nMAT while providing significant improvements in efficiency. We introduce a\nmodified version of MAT that incorporates standard and bi-directional Mamba\nblocks, as well as a novel \"cross-attention\" Mamba block. Extensive testing\nshows that our Multi-Agent Mamba (MAM) matches the performance of MAT across\nmultiple standard multi-agent environments, while offering superior scalability\nto larger agent scenarios. This is significant for the MARL community, because\nit indicates that SSMs could replace Transformers without compromising\nperformance, whilst also supporting more effective scaling to higher numbers of\nagents. Our project page is available at\nhttps://sites.google.com/view/multi-agent-mamba .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19382v2",
    "published_date": "2024-10-25 08:32:21 UTC",
    "updated_date": "2024-10-28 11:09:26 UTC"
  },
  {
    "arxiv_id": "2410.19367v1",
    "title": "BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training",
    "authors": [
      "Houming Wu",
      "Ling Chen",
      "Wenjie Yu"
    ],
    "abstract": "With the increasing scale of models, the need for efficient distributed\ntraining has become increasingly urgent. Recently, many synchronous pipeline\nparallelism approaches have been proposed to improve training throughput.\nHowever, these approaches still suffer from two major issues, i.e., pipeline\nbubbles caused by periodic flushing and extra communication due to the\nincreasing number of pipeline stages. To this end, we propose BitPipe, a\nbidirectional interleaved pipeline parallelism for accelerating large models\ntraining. Specifically, a hybrid scheme of fusing interleaved pipelines with\nbidirectional pipelines is proposed to reduce the computational time of each\nsingle micro-batch and multiply the number of devices executing simultaneously.\nA V-shaped schedule with eager gradient synchronization is introduced to reduce\nand overlap the communication between devices. Experiments conducted on up to\n32 GPUs show that BitPipe improves the training throughput of GPT-style and\nBERT-style models by 1.05x-1.28x compared to the state-of-the-art synchronous\napproaches. The code of our implementation is available at\nhttps://github.com/wuhouming/BitPipe.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19367v1",
    "published_date": "2024-10-25 08:08:51 UTC",
    "updated_date": "2024-10-25 08:08:51 UTC"
  },
  {
    "arxiv_id": "2410.19361v2",
    "title": "Engineering Trustworthy AI: A Developer Guide for Empirical Risk Minimization",
    "authors": [
      "Diana Pfau",
      "Alexander Jung"
    ],
    "abstract": "AI systems increasingly shape critical decisions across personal and societal\ndomains. While empirical risk minimization (ERM) drives much of the AI success,\nit typically prioritizes accuracy over trustworthiness, often resulting in\nbiases, opacity, and other adverse effects. This paper discusses how key\nrequirements for trustworthy AI can be translated into design choices for the\ncomponents of ERM. We hope to provide actionable guidance for building AI\nsystems that meet emerging standards for trustworthiness of AI.",
    "categories": [
      "cs.AI",
      "I.2; K.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19361v2",
    "published_date": "2024-10-25 07:53:32 UTC",
    "updated_date": "2024-11-06 18:52:44 UTC"
  },
  {
    "arxiv_id": "2410.19360v1",
    "title": "LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function",
    "authors": [
      "Zhijie Chen",
      "Xinglin Zhang"
    ],
    "abstract": "This paper proposes a novel approach for designing Single-Parameterized\nKolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function\n(SFunc) constructed from trigonometric functions. Three new SKAN variants are\ndeveloped: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on\nthe MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and\ncomputational efficiency. Specifically, LArctan-SKAN significantly improves\ntest set accuracy over existing models, outperforming all pure KAN variants\ncompared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed\nMLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore,\nLArctan-SKAN exhibits remarkable computational efficiency, with a training\nspeed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN,\nrespectively. These results confirm the effectiveness and potential of SKANs\nconstructed with trigonometric functions. The experiment code is available at\nhttps://github.com/chikkkit/LArctan-SKAN .",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 3 figures, experiment code is available at\n  https://github.com/chikkkit/LArctan-SKAN",
    "pdf_url": "http://arxiv.org/pdf/2410.19360v1",
    "published_date": "2024-10-25 07:41:56 UTC",
    "updated_date": "2024-10-25 07:41:56 UTC"
  },
  {
    "arxiv_id": "2410.19353v1",
    "title": "Interleaving Text and Number Embeddings to Solve Mathemathics Problems",
    "authors": [
      "Marvin Alberts",
      "Gianmarco Gabrieli",
      "Irina Espejo Morales"
    ],
    "abstract": "Integrating text and numbers effectively is a crucial step towards enhancing\nLarge Language Models (LLMs) capabilities in assisting in scientific tasks.\nWhile most current approaches rely on discrete tokenization of numbers, for\ninstance, conversion to scientific notation or base 10-decomposition, a recent\napproach proposed a continuous numerical encoding as an inductive bias. In this\npaper, we build upon this approach by introducing more expressive numerical\nembeddings. Our method addresses key shortcomings, including the elimination of\nnumerical artefacts and the ability to handle a wide range of magnitudes\nwithout clipping.\n  Our work presents two key contributions. First, we employ an MLP to assign\ndistinct directions in the embedding space to different numbers. Our second\ncontribution is the introduction of a routing layer that differentiates between\nnumerical and text embeddings. We hypothesise that this combined approach\nenables the model to distinguish between text and number distributions while\nmaintaining its capacity for arithmetic operations.\n  Using only a 45 M parameter encoder-decoder architecture our method achieves\na $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition,\nwe empirically observe a reduction of the numerical artefacts and biases\nobserved compared to the baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19353v1",
    "published_date": "2024-10-25 07:21:57 UTC",
    "updated_date": "2024-10-25 07:21:57 UTC"
  },
  {
    "arxiv_id": "2410.19352v1",
    "title": "Interpreting Neural Networks through Mahalanobis Distance",
    "authors": [
      "Alan Oursland"
    ],
    "abstract": "This paper introduces a theoretical framework that connects neural network\nlinear layers with the Mahalanobis distance, offering a new perspective on\nneural network interpretability. While previous studies have explored\nactivation functions primarily for performance optimization, our work\ninterprets these functions through statistical distance measures, a less\nexplored area in neural network research. By establishing this connection, we\nprovide a foundation for developing more interpretable neural network models,\nwhich is crucial for applications requiring transparency. Although this work is\ntheoretical and does not include empirical data, the proposed distance-based\ninterpretation has the potential to enhance model robustness, improve\ngeneralization, and provide more intuitive explanations of neural network\ndecisions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, October 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19352v1",
    "published_date": "2024-10-25 07:21:44 UTC",
    "updated_date": "2024-10-25 07:21:44 UTC"
  },
  {
    "arxiv_id": "2410.19349v1",
    "title": "pEBR: A Probabilistic Approach to Embedding Based Retrieval",
    "authors": [
      "Han Zhang",
      "Yunjing Jiang",
      "Mingming Li",
      "Haowei Yuan",
      "Wen-Yun Yang"
    ],
    "abstract": "Embedding retrieval aims to learn a shared semantic representation space for\nboth queries and items, thus enabling efficient and effective item retrieval\nusing approximate nearest neighbor (ANN) algorithms. In current industrial\npractice, retrieval systems typically retrieve a fixed number of items for\ndifferent queries, which actually leads to insufficient retrieval (low recall)\nfor head queries and irrelevant retrieval (low precision) for tail queries.\nMostly due to the trend of frequentist approach to loss function designs, till\nnow there is no satisfactory solution to holistically address this challenge in\nthe industry. In this paper, we move away from the frequentist approach, and\ntake a novel \\textbf{p}robabilistic approach to \\textbf{e}mbedding\n\\textbf{b}ased \\textbf{r}etrieval (namely \\textbf{pEBR}) by learning the item\ndistribution for different queries, which enables a dynamic cosine similarity\nthreshold calculated by the probabilistic cumulative distribution function\n(CDF) value. The experimental results show that our approach improves both the\nretrieval precision and recall significantly. Ablation studies also illustrate\nhow the probabilistic approach is able to capture the differences between head\nand tail queries.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19349v1",
    "published_date": "2024-10-25 07:14:12 UTC",
    "updated_date": "2024-10-25 07:14:12 UTC"
  },
  {
    "arxiv_id": "2410.19343v1",
    "title": "High Resolution Seismic Waveform Generation using Denoising Diffusion",
    "authors": [
      "Andreas Bergmeister",
      "Kadek Hendrawan Palgunadi",
      "Andrea Bosisio",
      "Laura Ermert",
      "Maria Koroni",
      "Nathanaël Perraudin",
      "Simon Dirmeier",
      "Men-Andrin Meier"
    ],
    "abstract": "Accurate prediction and synthesis of seismic waveforms are crucial for\nseismic hazard assessment and earthquake-resistant infrastructure design.\nExisting prediction methods, such as Ground Motion Models and physics-based\nsimulations, often fail to capture the full complexity of seismic wavefields,\nparticularly at higher frequencies. This study introduces a novel, efficient,\nand scalable generative model for high-frequency seismic waveform generation.\nOur approach leverages a spectrogram representation of seismic waveform data,\nwhich is reduced to a lower-dimensional submanifold via an autoencoder. A\nstate-of-the-art diffusion model is trained to generate this latent\nrepresentation, conditioned on key input parameters: earthquake magnitude,\nrecording distance, site conditions, and faulting type. The model generates\nwaveforms with frequency content up to 50 Hz. Any scalar ground motion\nstatistic, such as peak ground motion amplitudes and spectral accelerations,\ncan be readily derived from the synthesized waveforms. We validate our model\nusing commonly used seismological metrics, and performance metrics from image\ngeneration studies. Our results demonstrate that our openly available model can\ngenerate distributions of realistic high-frequency seismic waveforms across a\nwide range of input parameters, even in data-sparse regions. For the scalar\nground motion statistics commonly used in seismic hazard and earthquake\nengineering studies, we show that the model accurately reproduces both the\nmedian trends of the real data and its variability. To evaluate and compare the\ngrowing number of this and similar 'Generative Waveform Models' (GWM), we argue\nthat they should generally be openly available and that they should be included\nin community efforts for ground motion model evaluations.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19343v1",
    "published_date": "2024-10-25 07:01:48 UTC",
    "updated_date": "2024-10-25 07:01:48 UTC"
  },
  {
    "arxiv_id": "2410.19318v1",
    "title": "Two are better than one: Context window extension with multi-grained self-injection",
    "authors": [
      "Wei Han",
      "Pan Zhou",
      "Soujanya Poria",
      "Shuicheng Yan"
    ],
    "abstract": "The limited context window of contemporary large language models (LLMs)\nremains a huge barrier to their broader application across various domains.\nWhile continual pre-training on long-context data is a straightforward and\neffective solution, it incurs substantial costs in terms of data acquisition\nand computational resources. To alleviate this issue, we propose SharedLLM, a\nnovel approach grounded in the design philosophy of multi-grained context\ncompression and query-aware information retrieval. SharedLLM is composed of two\nshort-context LLMs such as LLaMA-2, termed upper model and lower model. The\nlower model functions as a compressor while the upper model acts as a decoder.\nThe upper model receives compressed, multi-grained context information from the\nlower model and performs context-aware modeling on the running text.\nInformation transfer between the compressor and decoder occurs only at the\nlowest layers to refrain from long forward paths in the lower model and\nredundant cross-attention modules in the upper model. Based on this\narchitecture, we introduce a specialized tree-style data structure to\nefficiently encode, store and retrieve multi-grained contextual information for\ntext chunks. This structure, combined with a search algorithm, enables rapid\nencoding and retrieval of relevant information from various levels of the tree\nbased on the input query. This entire process, wherein the sender and receiver\nare derived from the same LLM layer, is referred to as self-injection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The code is available at https://github.com/Clement25/SharedLLM",
    "pdf_url": "http://arxiv.org/pdf/2410.19318v1",
    "published_date": "2024-10-25 06:08:59 UTC",
    "updated_date": "2024-10-25 06:08:59 UTC"
  },
  {
    "arxiv_id": "2410.19315v2",
    "title": "Brain-like variational inference",
    "authors": [
      "Hadi Vafaii",
      "Dekel Galor",
      "Jacob L. Yates"
    ],
    "abstract": "Inference in both brains and machines can be formalized by optimizing a\nshared objective: maximizing the evidence lower bound (ELBO) in machine\nlearning, or minimizing variational free energy (F) in neuroscience (ELBO =\n-F). While this equivalence suggests a unifying framework, it leaves open how\ninference is implemented in neural systems. Here, we show that online natural\ngradient descent on F, under Poisson assumptions, leads to a recurrent spiking\nneural network that performs variational inference via membrane potential\ndynamics. The resulting model -- the iterative Poisson variational autoencoder\n(iP-VAE) -- replaces the encoder network with local updates derived from\nnatural gradient descent on F. Theoretically, iP-VAE yields a number of\ndesirable features such as emergent normalization via lateral competition, and\nhardware-efficient integer spike count representations. Empirically, iP-VAE\noutperforms both standard VAEs and Gaussian-based predictive coding models in\nsparsity, reconstruction, and biological plausibility. iP-VAE also exhibits\nstrong generalization to out-of-distribution inputs, exceeding hybrid\niterative-amortized VAEs. These results demonstrate how deriving inference\nalgorithms from first principles can yield concrete architectures that are\nsimultaneously biologically plausible and empirically effective.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19315v2",
    "published_date": "2024-10-25 06:00:18 UTC",
    "updated_date": "2025-05-16 04:12:05 UTC"
  },
  {
    "arxiv_id": "2410.19313v3",
    "title": "COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training",
    "authors": [
      "Haocheng Xi",
      "Han Cai",
      "Ligeng Zhu",
      "Yao Lu",
      "Kurt Keutzer",
      "Jianfei Chen",
      "Song Han"
    ],
    "abstract": "FP8 training has emerged as a promising method for improving training\nefficiency. Existing frameworks accelerate training by applying FP8 computation\nto linear layers while leaving optimizer states and activations in higher\nprecision, which fails to fully optimize memory usage. This paper introduces\nCOAT (Compressing Optimizer States and Activations for FP8 Training), a novel\nFP8 training framework designed to significantly reduce memory footprint when\ntraining large models. COAT addresses current limitations through two key\ninnovations: (1) Dynamic Range Expansion, which aligns optimizer state\ndistributions more closely with the FP8 representation range, thereby reducing\nquantization error, and (2) Mixed-Granularity Activation Quantization, which\noptimizes activation memory using a combination of per-tensor and per-group\nquantization strategies. Experiments demonstrate that COAT effectively reduces\nend-to-end training memory footprint by 1.54x compared to BF16 while achieving\nnearly lossless performance across various tasks, such as Large Language Model\npretraining and fine-tuning and Vision Language Model training. COAT also\nachieves a 1.43x end-to-end training speedup compared to BF16, performing on\npar with or surpassing TransformerEngine's speedup. COAT enables efficient\nfull-parameter training of large models on fewer GPUs, and facilitates doubling\nthe batch size in distributed training settings, providing a practical solution\nfor scaling large-scale model training. The code is available at\nhttps://github.com/NVlabs/COAT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR 2025. 22 pages. 9 Figures. 13 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.19313v3",
    "published_date": "2024-10-25 05:59:30 UTC",
    "updated_date": "2025-02-12 23:37:50 UTC"
  },
  {
    "arxiv_id": "2411.07245v1",
    "title": "Navigating AI in Social Work and Beyond: A Multidisciplinary Review",
    "authors": [
      "Matt Victor Dalziel",
      "Krystal Schaffer",
      "Neil Martin"
    ],
    "abstract": "This review began with the modest goal of drafting a brief commentary on how\nthe social work profession engages with and is impacted by artificial\nintelligence (AI). However, it quickly became apparent that a deeper\nexploration was required to adequately capture the profound influence of AI,\none of the most transformative and debated innovations in modern history. As a\nresult, this review evolved into an interdisciplinary endeavour, gathering\nseminal texts, critical articles, and influential voices from across industries\nand academia. This review aims to provide a comprehensive yet accessible\noverview, situating AI within broader societal and academic conversations as\n2025 dawns. We explore perspectives from leading tech entrepreneurs, cultural\nicons, CEOs, and politicians alongside the pioneering contributions of AI\nengineers, innovators, and academics from fields as diverse as mathematics,\nsociology, philosophy, economics, and more. This review also briefly analyses\nAI's real-world impacts, ethical challenges, and implications for social work.\nIt presents a vision for AI-facilitated simulations that could transform social\nwork education through Advanced Personalised Simulation Training (APST). This\ntool uses AI to tailor high-fidelity simulations to individual student needs,\nproviding real-time feedback and preparing them for the complexities of their\nfuture practice environments. We maintain a critical tone throughout, balancing\nour awe of AI's remarkable advancements with necessary caution. As AI continues\nto permeate every professional realm, understanding its subtleties, challenges,\nand opportunities becomes essential. Those who fully grasp the intricacies of\nthis technology will be best positioned to navigate the impending AI Era.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.07245v1",
    "published_date": "2024-10-25 05:51:23 UTC",
    "updated_date": "2024-10-25 05:51:23 UTC"
  },
  {
    "arxiv_id": "2410.19310v1",
    "title": "Flow Generator Matching",
    "authors": [
      "Zemin Huang",
      "Zhengyang Geng",
      "Weijian Luo",
      "Guo-jun Qi"
    ],
    "abstract": "In the realm of Artificial Intelligence Generated Content (AIGC),\nflow-matching models have emerged as a powerhouse, achieving success due to\ntheir robust theoretical underpinnings and solid ability for large-scale\ngenerative modeling. These models have demonstrated state-of-the-art\nperformance, but their brilliance comes at a cost. The process of sampling from\nthese models is notoriously demanding on computational resources, as it\nnecessitates the use of multi-step numerical ordinary differential equations\n(ODEs). Against this backdrop, this paper presents a novel solution with\ntheoretical guarantees in the form of Flow Generator Matching (FGM), an\ninnovative approach designed to accelerate the sampling of flow-matching models\ninto a one-step generation, while maintaining the original performance. On the\nCIFAR10 unconditional generation benchmark, our one-step FGM model achieves a\nnew record Fr\\'echet Inception Distance (FID) score of 3.08 among few-step\nflow-matching-based models, outperforming original 50-step flow-matching\nmodels. Furthermore, we use the FGM to distill the Stable Diffusion 3, a\nleading text-to-image flow-matching model based on the MM-DiT architecture. The\nresulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding\nindustry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM\nhas delivered remarkable generating qualities, rivaling other multi-step models\nin light of the efficiency of a single generation step.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19310v1",
    "published_date": "2024-10-25 05:41:28 UTC",
    "updated_date": "2024-10-25 05:41:28 UTC"
  },
  {
    "arxiv_id": "2410.19308v1",
    "title": "Semantics in Robotics: Environmental Data Can't Yield Conventions of Human Behaviour",
    "authors": [
      "Jamie Milton Freestone"
    ],
    "abstract": "The word semantics, in robotics and AI, has no canonical definition. It\nusually serves to denote additional data provided to autonomous agents to aid\nHRI. Most researchers seem, implicitly, to understand that such data cannot\nsimply be extracted from environmental data. I try to make explicit why this is\nso and argue that so-called semantics are best understood as data comprised of\nconventions of human behaviour. This includes labels, most obviously, but also\nplaces, ontologies, and affordances. Object affordances are especially\nproblematic because they require not only semantics that are not in the\nenvironmental data (conventions of object use) but also an understanding of\nphysics and object combinations that would, if achieved, constitute artificial\nsuperintelligence.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19308v1",
    "published_date": "2024-10-25 05:38:23 UTC",
    "updated_date": "2024-10-25 05:38:23 UTC"
  },
  {
    "arxiv_id": "2411.07244v1",
    "title": "A Tutorial on Teaching Data Analytics with Generative AI",
    "authors": [
      "Robert L. Bray"
    ],
    "abstract": "This tutorial addresses the challenge of incorporating large language models\n(LLMs), such as ChatGPT, in a data analytics class. It details several new\nin-class and out-of-class teaching techniques enabled by AI. For example,\ninstructors can parallelize instruction by having students interact with\ndifferent custom-made GPTs to learn different parts of an analysis and then\nteach each other what they learned from their AIs. For another example,\ninstructors can turn problem sets into AI tutoring sessions, whereby a\ncustom-made GPT guides a student through the problems, and the student uploads\nthe chatlog for their homework submission. For a third example, you can assign\ndifferent labs to each section of your class and have each section create AI\nassistants to help the other sections work through their labs. This tutorial\nadvocates the programming in the English paradigm, in which students express\nthe desired data transformations in prose and then use AI to generate the\ncorresponding code. Students can wrangle data more effectively by programming\nin English than by manipulating in Excel. However, some students will program\nin English better than others, so you will still derive a robust grade\ndistribution (at least with current LLMs).",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07244v1",
    "published_date": "2024-10-25 05:27:48 UTC",
    "updated_date": "2024-10-25 05:27:48 UTC"
  },
  {
    "arxiv_id": "2410.19887v1",
    "title": "TBBC: Predict True Bacteraemia in Blood Cultures via Deep Learning",
    "authors": [
      "Kira Sam"
    ],
    "abstract": "Bacteraemia, a bloodstream infection with high morbidity and mortality rates,\nposes significant diagnostic challenges. Accurate diagnosis through blood\ncultures is resource-intensive. Developing a machine learning model to predict\nblood culture outcomes in emergency departments offers potential for improved\ndiagnosis, reduced healthcare costs, and mitigated antibiotic use.This thesis\naims to identify optimal machine learning techniques for predicting bacteraemia\nand develop a predictive model using data from St. Antonius Hospital's\nemergency department. Based on current literature, CatBoost and Random Forest\nwere selected as the most promising techniques. Model optimization using Optuna\nprioritized sensitivity.The final Random Forest model achieved an ROC AUC of\n0.78 and demonstrated 0.92 sensitivity on the test set. Notably, it accurately\nidentified 36.02% of patients at low risk of bacteraemia, with only 0.85% false\nnegatives.Implementation of this model in St. Antonius Hospital's emergency\ndepartment could reduce blood cultures, healthcare costs, and antibiotic\ntreatments. Future studies should focus on external validation, exploring\nadvanced techniques, and addressing potential confounders to ensure model\ngeneralizability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19887v1",
    "published_date": "2024-10-25 05:25:01 UTC",
    "updated_date": "2024-10-25 05:25:01 UTC"
  },
  {
    "arxiv_id": "2410.19302v2",
    "title": "TEARS: Textual Representations for Scrutable Recommendations",
    "authors": [
      "Emiliano Penaloza",
      "Olivier Gouvert",
      "Haolun Wu",
      "Laurent Charlin"
    ],
    "abstract": "Traditional recommender systems rely on high-dimensional (latent) embeddings\nfor modeling user-item interactions, often resulting in opaque representations\nthat lack interpretability. Moreover, these systems offer limited control to\nusers over their recommendations. Inspired by recent work, we introduce TExtuAl\nRepresentations for Scrutable recommendations (TEARS) to address these\nchallenges. Instead of representing a user's interests through a latent\nembedding, TEARS encodes them in natural text, providing transparency and\nallowing users to edit them. To do so, TEARS uses a modern LLM to generate user\nsummaries based on user preferences. We find the summaries capture user\npreferences uniquely. Using these summaries, we take a hybrid approach where we\nuse an optimal transport procedure to align the summaries' representation with\nthe learned representation of a standard VAE for collaborative filtering. We\nfind this approach can surpass the performance of three popular VAE models\nwhile providing user-controllable recommendations. We also analyze the\ncontrollability of TEARS through three simulated user tasks to evaluate the\neffectiveness of a user editing its summary.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19302v2",
    "published_date": "2024-10-25 04:26:00 UTC",
    "updated_date": "2025-03-03 21:07:27 UTC"
  },
  {
    "arxiv_id": "2410.19291v2",
    "title": "A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images",
    "authors": [
      "Zhiyuan Pei",
      "Jianqi Yan",
      "Jin Yan",
      "Bailing Yang",
      "Ziyuan Li",
      "Lin Zhang",
      "Xin Liu",
      "Yang Zhang"
    ],
    "abstract": "Recently, deep learning in stock prediction has become an important branch.\nImage-based methods show potential by capturing complex visual patterns and\nspatial correlations, offering advantages in interpretability over time series\nmodels. However, image-based approaches are more prone to overfitting,\nhindering robust predictive performance. To improve accuracy, this paper\nproposes a novel method, named Sequence-based Multi-scale Fusion Regression\nConvolutional Neural Network (SMSFR-CNN), for predicting stock price movements\nin the China A-share market.\n  By utilizing CNN to learn sequential features and combining them with image\nfeatures, we improve the accuracy of stock trend prediction on the A-share\nmarket stock dataset. This approach reduces the search space for image\nfeatures, stabilizes, and accelerates the training process. Extensive\ncomparative experiments on 4,454 A-share stocks show that the model achieves a\n61.15% positive predictive value and a 63.37% negative predictive value for the\nnext 5 days, resulting in a total profit of 165.09%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.19291v2",
    "published_date": "2024-10-25 03:50:54 UTC",
    "updated_date": "2024-10-29 08:18:05 UTC"
  },
  {
    "arxiv_id": "2410.19283v1",
    "title": "ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study",
    "authors": [
      "Liang Qiu",
      "Liyue Shen",
      "Lianli Liu",
      "Junyan Liu",
      "Yizheng Chen",
      "Lei Xing"
    ],
    "abstract": "During and after a course of therapy, imaging is routinely used to monitor\nthe disease progression and assess the treatment responses. Despite of its\nsignificance, reliably capturing and predicting the spatial-temporal anatomic\nchanges from a sequence of patient-specific image series presents a\nconsiderable challenge. Thus, the development of a computational framework\nbecomes highly desirable for a multitude of practical applications. In this\ncontext, we propose a strategy of Spatial-Temporal Neural Representation\nlearning with Prior embedding (ST-NeRP) for patient-specific imaging study. Our\nstrategy involves leveraging an Implicit Neural Representation (INR) network to\nencode the image at the reference time point into a prior embedding.\nSubsequently, a spatial-temporally continuous deformation function is learned\nthrough another INR network. This network is trained using the whole\npatient-specific image sequence, enabling the prediction of deformation fields\nat various target time points. The efficacy of the ST-NeRP model is\ndemonstrated through its application to diverse sequential image series,\nincluding 4D CT and longitudinal CT datasets within thoracic and abdominal\nimaging. The proposed ST-NeRP model exhibits substantial potential in enabling\nthe monitoring of anatomical changes within a patient throughout the\ntherapeutic journey.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "14 pages with 10 figures and 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.19283v1",
    "published_date": "2024-10-25 03:33:17 UTC",
    "updated_date": "2024-10-25 03:33:17 UTC"
  },
  {
    "arxiv_id": "2410.19279v1",
    "title": "UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices",
    "authors": [
      "Haoyu Bian",
      "Bin Guo",
      "Sicong Liu",
      "Yasan Ding",
      "Shanshan Gao",
      "Zhiwen Yu"
    ],
    "abstract": "Ubiquitous on-device heart rate sensing is vital for high-stress individuals\nand chronic patients. Non-contact sensing, compared to contact-based tools,\nallows for natural user monitoring, potentially enabling more accurate and\nholistic data collection. However, in open and uncontrolled mobile\nenvironments, user movement and lighting introduce. Existing methods, such as\ncurve-based or short-range deep learning recognition based on adjacent frames,\nstrike the optimal balance between real-time performance and accuracy,\nespecially under limited device resources. In this paper, we present UbiHR, a\nubiquitous device-based heart rate sensing system. Key to UbiHR is a real-time\nlong-range spatio-temporal model enabling noise-independent heart rate\nrecognition and display on commodity mobile devices, along with a set of\nmechanisms for prompt and energy-efficient sampling and preprocessing. Diverse\nexperiments and user studies involving four devices, four tasks, and 80\nparticipants demonstrate UbiHR's superior performance, enhancing accuracy by up\nto 74.2\\% and reducing latency by 51.2\\%.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19279v1",
    "published_date": "2024-10-25 03:28:19 UTC",
    "updated_date": "2024-10-25 03:28:19 UTC"
  },
  {
    "arxiv_id": "2410.19278v2",
    "title": "Applying sparse autoencoders to unlearn knowledge in language models",
    "authors": [
      "Eoin Farrell",
      "Yeu-Tong Lau",
      "Arthur Conmy"
    ],
    "abstract": "We investigate whether sparse autoencoders (SAEs) can be used to remove\nknowledge from language models. We use the biology subset of the Weapons of\nMass Destruction Proxy dataset and test on the gemma-2b-it and gemma-2-2b-it\nlanguage models. We demonstrate that individual interpretable biology-related\nSAE features can be used to unlearn a subset of WMDP-Bio questions with minimal\nside-effects in domains other than biology. Our results suggest that negative\nscaling of feature activations is necessary and that zero ablating features is\nineffective. We find that intervening using multiple SAE features\nsimultaneously can unlearn multiple different topics, but with similar or\nlarger unwanted side-effects than the existing Representation Misdirection for\nUnlearning technique. Current SAE quality or intervention techniques would need\nto improve to make SAE-based unlearning comparable to the existing fine-tuning\nbased techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19278v2",
    "published_date": "2024-10-25 03:21:14 UTC",
    "updated_date": "2024-11-02 23:02:44 UTC"
  },
  {
    "arxiv_id": "2410.19274v2",
    "title": "Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management",
    "authors": [
      "Tuowei Wang",
      "Ruwen Fan",
      "Minxing Huang",
      "Zixu Hao",
      "Kun Li",
      "Ting Cao",
      "Youyou Lu",
      "Yaoxue Zhang",
      "Ju Ren"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains, yet deploying them on mobile devices remains an arduous challenge due\nto their extensive computational and memory demands. While lightweight LLMs\nhave been developed to fit mobile environments, they suffer from degraded model\naccuracy. In contrast, sparsity-based techniques minimize DRAM usage by\nselectively transferring only relevant neurons to DRAM while retaining the full\nmodel in external storage, such as flash. However, such approaches are\ncritically limited by numerous I/O operations, particularly on smartphones with\nsevere IOPS constraints.\n  In this paper, we propose Ripple, a novel approach that accelerates LLM\ninference on smartphones by optimizing neuron placement in flash memory. Ripple\nleverages the concept of Neuron Co-Activation, where neurons frequently\nactivated together are linked to facilitate continuous read access and optimize\ndata transfer efficiency. Our approach incorporates a two-stage solution: an\noffline stage that reorganizes neuron placement based on co-activation\npatterns, and an online stage that employs tailored data access and caching\nstrategies to align well with hardware characteristics. Evaluations conducted\non a variety of smartphones and LLMs demonstrate that Ripple achieves up to\n5.93x improvements in I/O latency compared to the state-of-the-art. As the\nfirst solution to optimize storage placement under sparsity, Ripple explores a\nnew optimization space at the intersection of sparsity-driven algorithm and\nstorage-level system co-design in LLM inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.OS",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19274v2",
    "published_date": "2024-10-25 03:01:19 UTC",
    "updated_date": "2024-10-29 17:33:19 UTC"
  },
  {
    "arxiv_id": "2410.19262v1",
    "title": "Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model",
    "authors": [
      "Reachsak Ly",
      "Alireza Shojaei"
    ],
    "abstract": "Current autonomous building research primarily focuses on energy efficiency\nand automation. While traditional artificial intelligence has advanced\nautonomous building research, it often relies on predefined rules and struggles\nto adapt to complex, evolving building operations. Moreover, the centralized\norganizational structures of facilities management hinder transparency in\ndecision-making, limiting true building autonomy. Research on decentralized\ngovernance and adaptive building infrastructure, which could overcome these\nchallenges, remains relatively unexplored. This paper addresses these\nlimitations by introducing a novel Decentralized Autonomous Building\nCyber-Physical System framework that integrates Decentralized Autonomous\nOrganizations, Large Language Models, and digital twins to create a smart,\nself-managed, operational, and financially autonomous building infrastructure.\nThis study develops a full-stack decentralized application to facilitate\ndecentralized governance of building infrastructure. An LLM-based artificial\nintelligence assistant is developed to provide intuitive human-building\ninteraction for blockchain and building operation management-related tasks and\nenable autonomous building operation. Six real-world scenarios were tested to\nevaluate the autonomous building system's workability, including building\nrevenue and expense management, AI-assisted facility control, and autonomous\nadjustment of building systems. Results indicate that the prototype\nsuccessfully executes these operations, confirming the framework's suitability\nfor developing building infrastructure with decentralized governance and\nautonomous operation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19262v1",
    "published_date": "2024-10-25 02:34:54 UTC",
    "updated_date": "2024-10-25 02:34:54 UTC"
  },
  {
    "arxiv_id": "2410.19258v3",
    "title": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning",
    "authors": [
      "Yu Fu",
      "Zefan Cai",
      "Abedelkadir Asi",
      "Wayne Xiong",
      "Yue Dong",
      "Wen Xiao"
    ],
    "abstract": "Key-Value (KV) caching is a common technique to enhance the computational\nefficiency of Large Language Models (LLMs), but its memory overhead grows\nrapidly with input length. Prior work has shown that not all tokens are equally\nimportant for text generation, proposing layer-level KV cache compression to\nselectively retain key information. Recognizing the distinct roles of attention\nheads in generation, we propose HeadKV, a head-level KV cache compression\nmethod, and HeadKV-R2, which leverages a novel contextual reasoning ability\nestimation for compression. Our approach operates at the level of individual\nheads, estimating their importance for contextual QA tasks that require both\nretrieval and reasoning capabilities. Extensive experiments across diverse\nbenchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,\nMistral-7B-Instruct), and long-context abilities tests demonstrate that our\nhead-level KV cache compression significantly outperforms strong baselines,\nparticularly in low-resource settings (KV size = 64 & 128). Notably, our method\nretains just 1.5% of the KV cache while achieving 97% of the performance of the\nfull KV cache on the contextual question answering benchmark.Codes are\navailable at https://github.com/FYYFU/HeadKV",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18pages",
    "pdf_url": "http://arxiv.org/pdf/2410.19258v3",
    "published_date": "2024-10-25 02:22:00 UTC",
    "updated_date": "2024-11-14 01:56:11 UTC"
  },
  {
    "arxiv_id": "2410.19247v2",
    "title": "Non-rigid Relative Placement through 3D Dense Diffusion",
    "authors": [
      "Eric Cai",
      "Octavian Donca",
      "Ben Eisner",
      "David Held"
    ],
    "abstract": "The task of \"relative placement\" is to predict the placement of one object in\nrelation to another, e.g. placing a mug onto a mug rack. Through explicit\nobject-centric geometric reasoning, recent methods for relative placement have\nmade tremendous progress towards data-efficient learning for robot manipulation\nwhile generalizing to unseen task variations. However, they have yet to\nrepresent deformable transformations, despite the ubiquity of non-rigid bodies\nin real world settings. As a first step towards bridging this gap, we propose\n``cross-displacement\" - an extension of the principles of relative placement to\ngeometric relationships between deformable objects - and present a novel\nvision-based method to learn cross-displacement through dense diffusion. To\nthis end, we demonstrate our method's ability to generalize to unseen object\ninstances, out-of-distribution scene configurations, and multimodal goals on\nmultiple highly deformable tasks (both in simulation and in the real world)\nbeyond the scope of prior works. Supplementary information and videos can be\nfound at https://sites.google.com/view/tax3d-corl-2024 .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning (CoRL), 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19247v2",
    "published_date": "2024-10-25 01:54:17 UTC",
    "updated_date": "2024-10-29 13:41:28 UTC"
  },
  {
    "arxiv_id": "2410.21306v2",
    "title": "Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models, and Challenges",
    "authors": [
      "Farid Ariai",
      "Gianluca Demartini"
    ],
    "abstract": "Natural Language Processing (NLP) is revolutionising the way legal\nprofessionals and laypersons operate in the legal field. The considerable\npotential for NLP in the legal sector, especially in developing computational\ntools for various legal processes, has captured the interest of researchers for\nyears. This survey follows the Preferred Reporting Items for Systematic Reviews\nand Meta-Analyses framework, reviewing 154 studies, with a final selection of\n133 after manual filtering. It explores foundational concepts related to NLP in\nthe legal domain, illustrating the unique aspects and challenges of processing\nlegal texts, such as extensive document length, complex language, and limited\nopen legal datasets. We provide an overview of NLP tasks specific to legal\ntext, such as Legal Document Summarisation, legal Named Entity Recognition,\nLegal Question Answering, Legal Argument Mining, Legal Text Classification, and\nLegal Judgement Prediction. In the section on legal Language Models (LMs), we\nanalyse both developed LMs and approaches for adapting general LMs to the legal\ndomain. Additionally, we identify 16 Open Research Challenges, including bias\nin Artificial Intelligence applications, the need for more robust and\ninterpretable models, and improving explainability to handle the complexities\nof legal language and reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "A.1; I.2.7; J.1"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21306v2",
    "published_date": "2024-10-25 01:17:02 UTC",
    "updated_date": "2025-03-25 03:45:48 UTC"
  },
  {
    "arxiv_id": "2410.19238v1",
    "title": "Designing LLM-Agents with Personalities: A Psychometric Approach",
    "authors": [
      "Muhua Huang",
      "Xijuan Zhang",
      "Christopher Soto",
      "James Evans"
    ],
    "abstract": "This research introduces a novel methodology for assigning quantifiable,\ncontrollable and psychometrically validated personalities to Large Language\nModels-Based Agents (Agents) using the Big Five personality framework. It seeks\nto overcome the constraints of human subject studies, proposing Agents as an\naccessible tool for social science inquiry. Through a series of four studies,\nthis research demonstrates the feasibility of assigning psychometrically valid\npersonality traits to Agents, enabling them to replicate complex human-like\nbehaviors. The first study establishes an understanding of personality\nconstructs and personality tests within the semantic space of an LLM. Two\nsubsequent studies -- using empirical and simulated data -- illustrate the\nprocess of creating Agents and validate the results by showing strong\ncorrespondence between human and Agent answers to personality tests. The final\nstudy further corroborates this correspondence by using Agents to replicate\nknown human correlations between personality traits and decision-making\nbehaviors in scenarios involving risk-taking and ethical dilemmas, thereby\nvalidating the effectiveness of the psychometric approach to design Agents and\nits applicability to social and behavioral research.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19238v1",
    "published_date": "2024-10-25 01:05:04 UTC",
    "updated_date": "2024-10-25 01:05:04 UTC"
  },
  {
    "arxiv_id": "2410.19235v1",
    "title": "Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation",
    "authors": [
      "Malek Aburub",
      "Cristian C. Beltran-Hernandez",
      "Tatsuya Kamijo",
      "Masashi Hamaya"
    ],
    "abstract": "Robots hold great promise for performing repetitive or hazardous tasks, but\nachieving human-like dexterity, especially in contact-rich and dynamic\nenvironments, remains challenging. Rigid robots, which rely on position or\nvelocity control, often struggle with maintaining stable contact and applying\nconsistent force in force-intensive tasks. Learning from Demonstration has\nemerged as a solution, but tasks requiring intricate maneuvers, such as powder\ngrinding, present unique difficulties. This paper introduces Diffusion Policies\nFor Compliant Manipulation (DIPCOM), a novel diffusion-based framework designed\nfor compliant control tasks. By leveraging generative diffusion models, we\ndevelop a policy that predicts Cartesian end-effector poses and adjusts arm\nstiffness to maintain the necessary force. Our approach enhances force control\nthrough multimodal distribution modeling, improves the integration of diffusion\npolicies in compliance control, and extends our previous work by demonstrating\nits effectiveness in real-world tasks. We present a detailed comparison between\nour framework and existing methods, highlighting the advantages and best\npractices for deploying diffusion-based compliance control.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19235v1",
    "published_date": "2024-10-25 00:56:15 UTC",
    "updated_date": "2024-10-25 00:56:15 UTC"
  },
  {
    "arxiv_id": "2410.19231v1",
    "title": "Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use",
    "authors": [
      "Menna Fateen",
      "Tsunenori Mine"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown promise for\nscalable educational applications, but their use in dialog-based tutoring\nsystems remains challenging due to the need for effective pedagogical\nstrategies and the high costs associated with expert-curated datasets. Our\nstudy explores the use of smaller, more affordable LLMs for one-on-one tutoring\nin the context of solving reading comprehension problems. We developed a\nsynthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned\na smaller LLM using this dataset. Furthermore, we conducted an interactive\nexperiment comparing the performance of the fine-tuned model with a larger\nmodel in real-world tutoring scenarios. Our results show that the fine-tuned\nmodel performs on par with the larger model but at a lower cost, demonstrating\na viable, cost-effective approach for implementing LLM-based tutoring systems\nin educational settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19231v1",
    "published_date": "2024-10-25 00:40:21 UTC",
    "updated_date": "2024-10-25 00:40:21 UTC"
  },
  {
    "arxiv_id": "2410.19225v4",
    "title": "Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis",
    "authors": [
      "Weikai Li",
      "Ding Wang",
      "Zijian Ding",
      "Atefeh Sohrabizadeh",
      "Zongyue Qin",
      "Jason Cong",
      "Yizhou Sun"
    ],
    "abstract": "High-level synthesis (HLS) is a widely used tool in designing Field\nProgrammable Gate Array (FPGA). HLS enables FPGA design with software\nprogramming languages by compiling the source code into an FPGA circuit. The\nsource code includes a program (called \"kernel\") and several pragmas that\ninstruct hardware synthesis, such as parallelization, pipeline, etc. While it\nis relatively easy for software developers to design the program, it heavily\nrelies on hardware knowledge to design the pragmas, posing a big challenge for\nsoftware developers. Recently, different machine learning algorithms, such as\nGNNs, have been proposed to automate the pragma design via performance\nprediction. However, when applying the trained model on new kernels, the\nsignificant domain shift often leads to unsatisfactory performance. We propose\na more domain-generalizable model structure: a two-level hierarchical Mixture\nof Experts (MoE), that can be flexibly adapted to any GNN model. Different\nexpert networks can learn to deal with different regions in the representation\nspace, and they can utilize similar patterns between the old kernels and new\nkernels. In the low-level MoE, we apply MoE on three natural granularities of a\nprogram: node, basic block, and graph. The high-level MoE learns to aggregate\nthe three granularities for the final decision. To train the hierarchical MoE\nstably, we further propose a two-stage training method to avoid expert\npolarization. Extensive experiments verify the effectiveness of the proposed\nhierarchical MoE. We publicized our codes at\nhttps://github.com/weikai-li/HierarchicalMoE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.19225v4",
    "published_date": "2024-10-25 00:27:53 UTC",
    "updated_date": "2025-03-14 04:31:59 UTC"
  },
  {
    "arxiv_id": "2410.19223v1",
    "title": "Integrating Large Language Models with Internet of Things Applications",
    "authors": [
      "Mingyu Zong",
      "Arvin Hekmati",
      "Michael Guastalla",
      "Yiyi Li",
      "Bhaskar Krishnamachari"
    ],
    "abstract": "This paper identifies and analyzes applications in which Large Language\nModels (LLMs) can make Internet of Things (IoT) networks more intelligent and\nresponsive through three case studies from critical topics: DDoS attack\ndetection, macroprogramming over IoT systems, and sensor data processing. Our\nresults reveal that the GPT model under few-shot learning achieves 87.6%\ndetection accuracy, whereas the fine-tuned GPT increases the value to 94.9%.\nGiven a macroprogramming framework, the GPT model is capable of writing scripts\nusing high-level functions from the framework to handle possible incidents.\nMoreover, the GPT model shows efficacy in processing a vast amount of sensor\ndata by offering fast and high-quality responses, which comprise expected\nresults and summarized insights. Overall, the model demonstrates its potential\nto power a natural language interface. We hope that researchers will find these\ncase studies inspiring to develop further.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19223v1",
    "published_date": "2024-10-25 00:21:45 UTC",
    "updated_date": "2024-10-25 00:21:45 UTC"
  },
  {
    "arxiv_id": "2410.19221v1",
    "title": "Can Stories Help LLMs Reason? Curating Information Space Through Narrative",
    "authors": [
      "Vahid Sadiri Javadi",
      "Johanne R. Trippas",
      "Yash Kumar Lal",
      "Lucie Flek"
    ],
    "abstract": "Narratives are widely recognized as a powerful tool for structuring\ninformation and facilitating comprehension of complex ideas in various domains\nsuch as science communication. This paper investigates whether incorporating\nnarrative elements can assist Large Language Models (LLMs) in solving complex\nproblems more effectively. We propose a novel approach, Story of Thought (SoT),\nintegrating narrative structures into prompting techniques for problem-solving.\nThis approach involves constructing narratives around problem statements and\ncreating a framework to identify and organize relevant information. Our\nexperiments show that using various LLMs with SoT consistently surpasses using\nthem with other techniques on physics, chemistry, math, and biology questions\nin both the GPQA and JEEBench datasets. The narrative-based information\ncuration process in SoT enhances problem comprehension by contextualizing\ncritical in-domain information and highlighting causal relationships within the\nproblem space.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19221v1",
    "published_date": "2024-10-25 00:13:15 UTC",
    "updated_date": "2024-10-25 00:13:15 UTC"
  },
  {
    "arxiv_id": "2410.19219v1",
    "title": "Robot Behavior Personalization from Sparse User Feedback",
    "authors": [
      "Maithili Patel",
      "Sonia Chernova"
    ],
    "abstract": "As service robots become more general-purpose, they will need to adapt to\ntheir users' preferences over a large set of all possible tasks that they can\nperform. This includes preferences regarding which actions the users prefer to\ndelegate to robots as opposed to doing themselves. Existing personalization\napproaches require task-specific data for each user. To handle diversity across\nall household tasks and users, and nuances in user preferences across tasks, we\npropose to learn a task adaptation function independently, which can be used in\ntandem with any universal robot policy to customize robot behavior. We create\nTask Adaptation using Abstract Concepts (TAACo) framework. TAACo can learn to\npredict the user's preferred manner of assistance with any given task, by\nmediating reasoning through a representation composed of abstract concepts\nbuilt based on user feedback. TAACo can generalize to an open set of household\ntasks from small amount of user feedback and explain its inferences through\nintuitive concepts. We evaluate our model on a dataset we collected of 5\npeople's preferences, and show that TAACo outperforms GPT-4 by 16% and a\nrule-based system by 54%, on prediction accuracy, with 40 samples of user\nfeedback.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19219v1",
    "published_date": "2024-10-25 00:08:38 UTC",
    "updated_date": "2024-10-25 00:08:38 UTC"
  },
  {
    "arxiv_id": "2410.19218v1",
    "title": "Taxonomy-guided Semantic Indexing for Academic Paper Search",
    "authors": [
      "SeongKu Kang",
      "Yunyi Zhang",
      "Pengcheng Jiang",
      "Dongha Lee",
      "Jiawei Han",
      "Hwanjo Yu"
    ],
    "abstract": "Academic paper search is an essential task for efficient literature discovery\nand scientific advancement. While dense retrieval has advanced various ad-hoc\nsearches, it often struggles to match the underlying academic concepts between\nqueries and documents, which is critical for paper search. To enable effective\nacademic concept matching for paper search, we propose Taxonomy-guided Semantic\nIndexing (TaxoIndex) framework. TaxoIndex extracts key concepts from papers and\norganizes them as a semantic index guided by an academic taxonomy, and then\nleverages this index as foundational knowledge to identify academic concepts\nand link queries and documents. As a plug-and-play framework, TaxoIndex can be\nflexibly employed to enhance existing dense retrievers. Extensive experiments\nshow that TaxoIndex brings significant improvements, even with highly limited\ntraining data, and greatly enhances interpretability.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "EMNLP'24",
    "pdf_url": "http://arxiv.org/pdf/2410.19218v1",
    "published_date": "2024-10-25 00:00:17 UTC",
    "updated_date": "2024-10-25 00:00:17 UTC"
  }
]