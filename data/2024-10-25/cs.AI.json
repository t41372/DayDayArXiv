{
  "date": "2024-10-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-25 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括大型语言模型（LLM）的优化、多代理强化学习、脑科学与 AI 的整合，以及医疗和机器人应用等热门话题。其中，OpenAI 团队发布的 GPT-4o 系统卡令人印象深刻，展示了 LLM 在多模态处理和安全评估上的新进展，同时一些脑- AI 交叉研究如“Brain-like Functional Organization within Large Language Models”突显了 AI 模型的生物启发性创新。\n\n下面，我将挑选并讨论今天更重要的论文，先从 AI 和 LLM 相关的高影响力文章入手，然后简要聊聊机器人、医疗等领域。其他较常规或专题性较强的论文（如金融风险预测或特定领域实验），我会快速掠过，以控制篇幅。每个论文会列出标题（中文 + 英文），并清晰描述其主要贡献和发现。\n\n### AI 和 LLM 领域：重点讨论创新框架和模型优化\n- **GPT-4o System Card**（中文：GPT-4o 系统卡；英文：GPT-4o System Card）  \n  OpenAI 团队发布了这篇论文，详细评估了 GPT-4o 多模态模型的安全性和性能。贡献在于全面分析其文本、图像和音频处理能力，以及潜在风险，主要发现是 GPT-4o 在非英语语言和视觉任务上表现出色，同时响应延迟低至 232 毫秒，但强调了社会影响和偏置问题。\n\n- **Brain-like Functional Organization within Large Language Models**（中文：大型语言模型中的脑-like 功能组织；英文：Brain-like Functional Organization within Large Language Models）  \n  这篇论文探索了 LLM（如 BERT 和 Llama）如何模仿大脑功能网络。贡献是通过 fMRI 数据将 LLM 的神经子群与大脑功能网络对齐，主要发现是更先进的 LLM 能更好地平衡计算多样性和功能专化，提升了模型的生物启发性和泛化能力。\n\n- **Flow Generator Matching**（中文：流生成器匹配；英文：Flow Generator Matching）  \n  论文提出了一种新方法，用于加速流匹配模型的采样。贡献是开发 FGM 框架，实现一步生成高频波形，主要发现是它在图像生成任务中显著提高效率，FID 分数达 3.08，超越多步基线。\n\n- **TimeSuite: Improving MLLMs for Long Video Understanding**（中文：TimeSuite：提升多模态大型语言模型的长视频理解；英文：TimeSuite: Improving MLLMs for Long Video Understanding）  \n  这篇工作针对多模态 LLM 的长视频处理提出新框架。贡献是通过关键帧重建和感知模块提升视频理解，实验显示在 Egoschema 和 VideoMME 基准上提升 5.6% 和 6.8%，主要发现是它减少了幻觉风险。\n\n- **2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision**（中文：2D-DPO：使用二维监督扩展直接偏好优化；英文：2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision）  \n  论文扩展了偏好优化方法。贡献是将偏好分解为段落和方面两个维度，实验在基准上提升性能，主要发现是多维度优化能更好地处理 LLM 的响应质量。\n\n其他 AI 相关论文，如“Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation”，涉及强化学习，但影响较小，我这里快速掠过：它提出扩散策略用于机器人柔性操作，提升了任务适应性。\n\n### 机器人和多代理系统：关注实用性和扩展性\n- **Multi-Agent Reinforcement Learning with Selective State-Space Models**（中文：使用选择性状态空间模型的多代理强化学习；英文：Multi-Agent Reinforcement Learning with Selective State-Space Models）  \n  这篇论文优化了多代理强化学习。贡献是引入状态空间模型和混合架构，实验显示在多环境基准上性能提升，主要发现是它在高代理数量场景下比 Transformer 更高效。\n\n- **IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation**（中文：IPPON：基于常识的物体目标导航信息路径规划；英文：IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation）  \n  论文为机器人导航提出新方法。贡献是结合常识先验和概率映射，提升导航精度，主要发现是在 Habitat 基准上成功率提升 20%，并在真实机器人上验证了鲁棒性。\n\n其他机器人论文，如“Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations”，涉及 AI 在建筑中的应用，但较为应用导向，我简要提到：它整合 DAO 和 LLM 实现建筑自治，贡献在于提升决策透明度。\n\n### 医疗和生物领域：突出 AI 的实际影响\n- **Multi-view biomedical foundation models for molecule-target and property prediction**（中文：多视图生物医学基础模型用于分子-目标和属性预测；英文：Multi-view biomedical foundation models for molecule-target and property prediction）  \n  论文开发多视图模型预测分子属性。贡献是整合图、图像和文本视图，实验在药物筛选中准确率提升，主要发现是它能识别 Alzheimer 相关受体，提升药物发现效率。\n\n- **NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction**（中文：NeuroClips：高保真平滑的 fMRI 到视频重建；英文：NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction）  \n  这篇工作重建脑活动视频。贡献是通过扩散模型处理 fMRI 数据，SSIM 指标提升 128%，主要发现是它能生成 6 秒 8FPS 的高保真视频，应用于脑科学研究。\n\n其他医疗论文，如“Deep learning-based identification of patients at increased risk of cancer”，使用深度学习预测癌症风险，贡献在于基于实验室数据准确率达 85%，但整体影响有限，我这里不展开。\n\n### 其他领域：快速掠过\n今天还有一些论文涉及金融（如“Enhancing Battery Storage Energy Arbitrage with Deep Reinforcement Learning”）、法律（如“A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection”）和物理领域，但这些相对专业或实验性强，我只简要总结：金融论文探索 DRL 在能源优化中的应用，提升了收益预测；法律论文综述了深度学习在认知障碍检测中的进展。这些论文虽有实际价值，但未见突破性创新，故不详细讨论。\n\n总之，今天 arXiv 的论文展示了 AI 在多领域的潜力，特别是 LLM 和脑科学的融合。感兴趣的读者可关注 OpenAI 的 GPT-4o 或脑- AI 相关工作，探索更多创新点。明天见，继续追踪最新动态！",
  "papers": [
    {
      "arxiv_id": "2410.21315v1",
      "title": "GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Margarita Bugueño",
        "Hazem Abou Hamdan",
        "Gerard de Melo"
      ],
      "abstract": "Heterogeneous graph neural networks have recently gained attention for long\ndocument summarization, modeling the extraction as a node classification task.\nAlthough effective, these models often require external tools or additional\nmachine learning models to define graph components, producing highly complex\nand less intuitive structures. We present GraphLSS, a heterogeneous graph\nconstruction for long document extractive summarization, incorporating Lexical,\nStructural, and Semantic features. It defines two levels of information (words\nand sentences) and four types of edges (sentence semantic similarity, sentence\noccurrence order, word in sentence, and word semantic similarity) without any\nneed for auxiliary learning models. Experiments on two benchmark datasets show\nthat GraphLSS is competitive with top-performing graph-based methods,\noutperforming recent non-graph models. We release our code on GitHub.",
      "tldr_zh": "本研究提出GraphLSS，一种异构图神经网络框架，用于长文档提取式摘要，通过整合Lexical、Structural和Semantic特征来建模节点分类任务。该框架无需外部工具或辅助模型，仅基于单词和句子的两个信息级别，以及四种边（句子语义相似度、句子出现顺序、单词在句子中、和单词语义相似度）构建简洁直观的图结构。在两个基准数据集上的实验显示，GraphLSS与顶级图-based方法竞争表现，并优于最近的非图模型，同时代码已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Short paper submitted to ACL ARR November cycle",
      "pdf_url": "http://arxiv.org/pdf/2410.21315v1",
      "published_date": "2024-10-25 23:48:59 UTC",
      "updated_date": "2024-10-25 23:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:23:01.995817"
    },
    {
      "arxiv_id": "2410.20007v1",
      "title": "Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models",
      "title_zh": "合作战略规划增强大型语言模型的推理能力",
      "authors": [
        "Danqing Wang",
        "Zhuorui Ye",
        "Fei Fang",
        "Lei Li"
      ],
      "abstract": "Enhancing the reasoning capabilities of large language models (LLMs) is\ncrucial for enabling them to tackle complex, multi-step problems. Multi-agent\nframeworks have shown great potential in enhancing LLMs' reasoning\ncapabilities. However, the lack of effective cooperation between LLM agents\nhinders their performance, especially for multi-step reasoning tasks. This\npaper proposes a novel cooperative multi-agent reasoning framework (CoPlanner)\nby separating reasoning steps and assigning distinct duties to different\nagents. CoPlanner consists of two LLM agents: a planning agent and a reasoning\nagent. The planning agent provides high-level strategic hints, while the\nreasoning agent follows these hints and infers answers. By training the\nplanning agent's policy through the interactive reasoning process via Proximal\nPolicy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the\nprevious best method by 9.94\\% on LogiQA and 3.09\\% on BBH. Our results\ndemonstrate that the guidance from the planning agent and the effective\ncooperation between the agents contribute to the superior performance of\nCoPlanner in tackling multi-step reasoning problems.",
      "tldr_zh": "这篇论文提出了一种合作多智能体推理框架 CoPlanner，以提升大型语言模型 (LLMs) 的推理能力，特别是针对复杂多步问题。CoPlanner 由两个 LLM 智能体组成：planning agent 负责提供高层战略提示，reasoning agent 则根据这些提示进行推理，并通过 Proximal Policy Optimization (PPO) 训练 planning agent's policy。实验结果显示，基于 LLaMA-3-8B 的 CoPlanner 在 LogiQA 数据集上比最佳方法提升 9.94%，在 BBH 数据集上提升 3.09%，证明了代理间有效合作对多步推理性能的显著贡献。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.20007v1",
      "published_date": "2024-10-25 23:32:48 UTC",
      "updated_date": "2024-10-25 23:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:23:14.550613"
    },
    {
      "arxiv_id": "2410.20005v1",
      "title": "Enhancing Battery Storage Energy Arbitrage with Deep Reinforcement Learning and Time-Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Sage",
        "Joshua Campbell",
        "Yaoyao Fiona Zhao"
      ],
      "abstract": "Energy arbitrage is one of the most profitable sources of income for battery\noperators, generating revenues by buying and selling electricity at different\nprices. Forecasting these revenues is challenging due to the inherent\nuncertainty of electricity prices. Deep reinforcement learning (DRL) emerged in\nrecent years as a promising tool, able to cope with uncertainty by training on\nlarge quantities of historical data. However, without access to future\nelectricity prices, DRL agents can only react to the currently observed price\nand not learn to plan battery dispatch. Therefore, in this study, we combine\nDRL with time-series forecasting methods from deep learning to enhance the\nperformance on energy arbitrage. We conduct a case study using price data from\nAlberta, Canada that is characterized by irregular price spikes and highly\nnon-stationary. This data is challenging to forecast even when state-of-the-art\ndeep learning models consisting of convolutional layers, recurrent layers, and\nattention modules are deployed. Our results show that energy arbitrage with\nDRL-enabled battery control still significantly benefits from these imperfect\npredictions, but only if predictors for several horizons are combined. Grouping\nmultiple predictions for the next 24-hour window, accumulated rewards increased\nby 60% for deep Q-networks (DQN) compared to the experiments without forecasts.\nWe hypothesize that multiple predictors, despite their imperfections, convey\nuseful information regarding the future development of electricity prices\nthrough a \"majority vote\" principle, enabling the DRL agent to learn more\nprofitable control policies.",
      "tldr_zh": "这篇论文提出了一种结合深度强化学习(DRL)和时间序列预测的方法，以提升电池存储能源套利的性能，通过买卖电力应对电力价格的不确定性。研究使用阿尔伯塔省加拿大的价格数据（特征为不规则峰值和高非平稳性），并发现即使预测不完美，将多个预测地平线（如24小时窗口）结合后，DRL代理（如Deep Q-Networks, DQN）的累积奖励可提高60%。作者假设这些预测通过“多数投票”原则提供有用信息，帮助DRL学习更盈利的电池调度策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.OS",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at the 18th ASME International Conference on\n  Energy Sustainability",
      "pdf_url": "http://arxiv.org/pdf/2410.20005v1",
      "published_date": "2024-10-25 23:18:43 UTC",
      "updated_date": "2024-10-25 23:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:23:26.762904"
    },
    {
      "arxiv_id": "2410.19998v1",
      "title": "Artificial Intelligence of Things: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Shakhrul Iman Siam",
        "Hyunho Ahn",
        "Li Liu",
        "Samiul Alam",
        "Hui Shen",
        "Zhichao Cao",
        "Ness Shroff",
        "Bhaskar Krishnamachari",
        "Mani Srivastava",
        "Mi Zhang"
      ],
      "abstract": "The integration of the Internet of Things (IoT) and modern Artificial\nIntelligence (AI) has given rise to a new paradigm known as the Artificial\nIntelligence of Things (AIoT). In this survey, we provide a systematic and\ncomprehensive review of AIoT research. We examine AIoT literature related to\nsensing, computing, and networking & communication, which form the three key\ncomponents of AIoT. In addition to advancements in these areas, we review\ndomain-specific AIoT systems that are designed for various important\napplication domains. We have also created an accompanying GitHub repository,\nwhere we compile the papers included in this survey:\nhttps://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively\nmaintained and updated with new research as it becomes available. As both IoT\nand AI become increasingly critical to our society, we believe AIoT is emerging\nas an essential research field at the intersection of IoT and modern AI. We\nhope this survey will serve as a valuable resource for those engaged in AIoT\nresearch and act as a catalyst for future explorations to bridge gaps and drive\nadvancements in this exciting field.",
      "tldr_zh": "这篇调查论文系统回顾了Artificial Intelligence of Things (AIoT)，它是Internet of Things (IoT)与现代Artificial Intelligence (AI)的整合。论文重点考察了AIoT的关键组件，包括sensing、computing和networking & communication领域的研究进展，以及针对重要应用领域的特定AIoT系统。作者还创建并维护了一个GitHub仓库（https://github.com/AIoT-MLSys-Lab/AIoT-Survey）来收集相关论文，并强调AIoT作为IoT和AI交汇的重要领域，希望此调查能作为资源推动未来研究和创新。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted in ACM Transactions on Sensor Networks (TOSN)",
      "pdf_url": "http://arxiv.org/pdf/2410.19998v1",
      "published_date": "2024-10-25 22:45:58 UTC",
      "updated_date": "2024-10-25 22:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:52.161805"
    },
    {
      "arxiv_id": "2410.19982v3",
      "title": "Random Policy Enables In-Context Reinforcement Learning within Trust Horizons",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqin Chen",
        "Santiago Paternain"
      ],
      "abstract": "Pretrained foundation models have exhibited extraordinary in-context learning\nperformance, allowing zero-shot generalization to new tasks not encountered\nduring pretraining. In the case of reinforcement learning (RL), in-context RL\n(ICRL) emerges when pretraining FMs on decision-making problems in an\nautoregressive-supervised manner. Nevertheless, current state-of-the-art ICRL\nalgorithms, like Algorithm Distillation, Decision Pretrained Transformer and\nDecision Importance Transformer, impose stringent requirements on the\npretraining dataset concerning the source policies, context information, and\naction labels. Notably, these algorithms either demand optimal policies or\nrequire varying degrees of well-trained behavior policies for all pretraining\nenvironments. This significantly hinders the application of ICRL to real-world\nscenarios, where acquiring optimal or well-trained policies for a substantial\nvolume of real-world training environments can be intractable. To overcome this\nchallenge, we introduce a novel approach, termed State-Action Distillation\n(SAD), that allows to generate an effective pretraining dataset guided solely\nby random policies. In particular, SAD selects query states and corresponding\naction labels by distilling outstanding state-action pairs from the entire\nstate and action spaces by using random policies within a trust horizon, and\nthen inherits the classical autoregressive-supervised mechanism during\npretraining. To the best of our knowledge, this is the first work that enables\neffective ICRL under random policies and random contexts. We also establish\nquantitative analysis of the trustworthiness as well as the performance\nguarantees of SAD. Moreover, our empirical results across multiple popular ICRL\nbenchmark environments demonstrate that, on average, SAD outperforms the best\nbaseline by 236.3% in the offline evaluation and by 135.2% in the online\nevaluation.",
      "tldr_zh": "该论文探讨了 In-Context Reinforcement Learning (ICRL) 的挑战，即现有算法如 Algorithm Distillation 需要最优或良好训练策略，这在现实环境中难以实现。论文提出了一种新方法 State-Action Distillation (SAD)，通过使用随机策略在信任范围内提炼出色的状态-动作对，并结合自回归监督机制生成预训练数据集，从而实现有效的 ICRL。实验结果显示，SAD 在多个基准环境中平均比最佳基线提升 236.3% 的离线性能和 135.2% 的在线性能，并提供了该方法的可靠性和性能保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19982v3",
      "published_date": "2024-10-25 21:46:25 UTC",
      "updated_date": "2025-05-02 03:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:23:50.809050"
    },
    {
      "arxiv_id": "2410.21314v2",
      "title": "Decoding Diffusion: A Scalable Framework for Unsupervised Analysis of Latent Space Biases and Representations Using Natural Language Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "E. Zhixuan Zeng",
        "Yuhao Chen",
        "Alexander Wong"
      ],
      "abstract": "Recent advances in image generation have made diffusion models powerful tools\nfor creating high-quality images. However, their iterative denoising process\nmakes understanding and interpreting their semantic latent spaces more\nchallenging than other generative models, such as GANs. Recent methods have\nattempted to address this issue by identifying semantically meaningful\ndirections within the latent space. However, they often need manual\ninterpretation or are limited in the number of vectors that can be trained,\nrestricting their scope and utility. This paper proposes a novel framework for\nunsupervised exploration of diffusion latent spaces. We directly leverage\nnatural language prompts and image captions to map latent directions. This\nmethod allows for the automatic understanding of hidden features and supports a\nbroader range of analysis without the need to train specific vectors. Our\nmethod provides a more scalable and interpretable understanding of the semantic\nknowledge encoded within diffusion models, facilitating comprehensive analysis\nof latent biases and the nuanced representations these models learn.\nExperimental results show that our framework can uncover hidden patterns and\nassociations in various domains, offering new insights into the\ninterpretability of diffusion model latent spaces.",
      "tldr_zh": "这篇论文提出了一种可扩展框架，用于无监督分析diffusion models的潜在空间偏差和表示，解决这些模型在语义解读上的挑战。\n该框架通过直接利用natural language prompts和图像标题来映射潜在方向，实现自动理解隐藏特征，而无需手动解释或训练特定向量。\n这种方法提升了diffusion models中语义知识的可解释性和可扩展性，便于全面分析潜在偏差和细微表示。\n实验结果表明，该框架在各种领域揭示了隐藏模式和关联，为diffusion models的解读提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21314v2",
      "published_date": "2024-10-25 21:44:51 UTC",
      "updated_date": "2024-11-04 19:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:02.952396"
    },
    {
      "arxiv_id": "2410.19965v1",
      "title": "OReole-FM: successes and challenges toward billion-parameter foundation models for high-resolution satellite imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Philipe Dias",
        "Aristeidis Tsaris",
        "Jordan Bowman",
        "Abhishek Potnis",
        "Jacob Arndt",
        "H. Lexie Yang",
        "Dalton Lunga"
      ],
      "abstract": "While the pretraining of Foundation Models (FMs) for remote sensing (RS)\nimagery is on the rise, models remain restricted to a few hundred million\nparameters. Scaling models to billions of parameters has been shown to yield\nunprecedented benefits including emergent abilities, but requires data scaling\nand computing resources typically not available outside industry R&D labs. In\nthis work, we pair high-performance computing resources including Frontier\nsupercomputer, America's first exascale system, and high-resolution optical RS\ndata to pretrain billion-scale FMs. Our study assesses performance of different\npretrained variants of vision Transformers across image classification,\nsemantic segmentation and object detection benchmarks, which highlight the\nimportance of data scaling for effective model scaling. Moreover, we discuss\nconstruction of a novel TIU pretraining dataset, model initialization, with\ndata and pretrained models intended for public release. By discussing technical\nchallenges and details often lacking in the related literature, this work is\nintended to offer best practices to the geospatial community toward efficient\ntraining and benchmarking of larger FMs.",
      "tldr_zh": "本文研究了使用高性能计算资源（如Frontier超级计算机）和高分辨率光学遥感(RS)数据来预训练亿级参数的Foundation Models (FMs)，以克服当前RS图像模型规模限制的问题。通过评估不同预训练的vision Transformers在图像分类、语义分割和目标检测基准上的性能，研究强调了数据扩展对有效模型扩展的关键作用。作者构建了新型TIU预训练数据集，并计划公开数据和预训练模型，同时讨论了技术挑战和最佳实践，为地理空间社区提供高效训练和基准测试的指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19965v1",
      "published_date": "2024-10-25 20:55:12 UTC",
      "updated_date": "2024-10-25 20:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:15.256641"
    },
    {
      "arxiv_id": "2410.19964v1",
      "title": "Understanding Adam Requires Better Rotation Dependent Assumptions",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Maes",
        "Tianyue H. Zhang",
        "Alexia Jolicoeur-Martineau",
        "Ioannis Mitliagkas",
        "Damien Scieur",
        "Simon Lacoste-Julien",
        "Charles Guille-Escuret"
      ],
      "abstract": "Despite its widespread adoption, Adam's advantage over Stochastic Gradient\nDescent (SGD) lacks a comprehensive theoretical explanation. This paper\ninvestigates Adam's sensitivity to rotations of the parameter space. We\ndemonstrate that Adam's performance in training transformers degrades under\nrandom rotations of the parameter space, indicating a crucial sensitivity to\nthe choice of basis. This reveals that conventional rotation-invariant\nassumptions are insufficient to capture Adam's advantages theoretically. To\nbetter understand the rotation-dependent properties that benefit Adam, we also\nidentify structured rotations that preserve or even enhance its empirical\nperformance. We then examine the rotation-dependent assumptions in the\nliterature, evaluating their adequacy in explaining Adam's behavior across\nvarious rotation types. This work highlights the need for new,\nrotation-dependent theoretical frameworks to fully understand Adam's empirical\nsuccess in modern machine learning tasks.",
      "tldr_zh": "尽管Adam优化器在机器学习中广泛应用，其相对于Stochastic Gradient Descent (SGD)的优势仍缺乏全面理论解释，本文揭示了Adam对参数空间旋转的敏感性。研究发现，Adam在训练Transformer时，随机旋转会导致性能下降，表明传统旋转不变假设不足以捕捉其优势。通过识别结构化旋转能维持或提升Adam的实证性能，论文评估了现有文献中旋转相关的假设，并强调需要新的、依赖旋转的理论框架来更好地理解Adam在现代任务中的成功。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19964v1",
      "published_date": "2024-10-25 20:53:03 UTC",
      "updated_date": "2024-10-25 20:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:25.534593"
    },
    {
      "arxiv_id": "2410.21313v1",
      "title": "Towards Robust Out-of-Distribution Generalization: Data Augmentation and Neural Architecture Search Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyue Bai"
      ],
      "abstract": "Deep learning has been demonstrated with tremendous success in recent years.\nDespite so, its performance in practice often degenerates drastically when\nencountering out-of-distribution (OoD) data, i.e. training and test data are\nsampled from different distributions. In this thesis, we study ways toward\nrobust OoD generalization for deep learning, i.e., its performance is not\nsusceptible to distribution shift in the test data.\n  We first propose a novel and effective approach to disentangle the spurious\ncorrelation between features that are not essential for recognition. It employs\ndecomposed feature representation by orthogonalizing the two gradients of\nlosses for category and context branches. Furthermore, we perform\ngradient-based augmentation on context-related features (e.g., styles,\nbackgrounds, or scenes of target objects) to improve the robustness of learned\nrepresentations. Results show that our approach generalizes well for different\ndistribution shifts.\n  We then study the problem of strengthening neural architecture search in OoD\nscenarios. We propose to optimize the architecture parameters that minimize the\nvalidation loss on synthetic OoD data, under the condition that corresponding\nnetwork parameters minimize the training loss. Moreover, to obtain a proper\nvalidation set, we learn a conditional generator by maximizing their losses\ncomputed by different neural architectures. Results show that our approach\neffectively discovers robust architectures that perform well for OoD\ngeneralization.",
      "tldr_zh": "这篇论文探讨了深度学习模型在 out-of-distribution (OoD) 数据上的鲁棒性问题，旨在通过 data augmentation 和 neural architecture search 提升模型对分布偏移的抵抗力。作者首先提出一种方法，通过梯度正交化分离无关特征的虚假相关性，并对上下文相关特征（如风格或背景）进行基于梯度的增强，实验结果显示该方法在不同分布偏移下实现了良好的泛化性能。其次，论文优化了 neural architecture search 过程，使架构参数在合成 OoD 数据上最小化验证损失，同时使用条件生成器来最大化不同架构的损失，从而发现更鲁棒的网络结构。整体贡献为提供了有效的策略，帮助深度学习模型在实际场景中更可靠地泛化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Hong Kong University of Science and Technology Thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.21313v1",
      "published_date": "2024-10-25 20:50:32 UTC",
      "updated_date": "2024-10-25 20:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:39.293079"
    },
    {
      "arxiv_id": "2410.19955v2",
      "title": "Bridging Stepwise Lab-Informed Pretraining and Knowledge-Guided Learning for Diagnostic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Hu",
        "Chang Lu",
        "Fei Wang",
        "Yue Ning"
      ],
      "abstract": "Despite the growing use of Electronic Health Records (EHR) for AI-assisted\ndiagnosis prediction, most data-driven models struggle to incorporate\nclinically meaningful medical knowledge. They often rely on limited ontologies,\nlacking structured reasoning capabilities and comprehensive coverage. This\nraises an important research question: Will medical knowledge improve\npredictive models to support stepwise clinical reasoning as performed by human\ndoctors? To address this problem, we propose DuaLK, a dual-expertise framework\nthat combines two complementary sources of information. For external knowledge,\nwe construct a Diagnosis Knowledge Graph (KG) that encodes both hierarchical\nand semantic relations enriched by large language models (LLM). To align with\npatient data, we further introduce a lab-informed proxy task that guides the\nmodel to follow a clinically consistent, stepwise reasoning process based on\nlab test signals. Experimental results on two public EHR datasets demonstrate\nthat DuaLK consistently outperforms existing baselines across four clinical\nprediction tasks. These findings highlight the potential of combining\nstructured medical knowledge with individual-level clinical signals to achieve\nmore accurate and interpretable diagnostic predictions. The source code is\npublicly available on https://github.com/humphreyhuu/DuaLK.",
      "tldr_zh": "该论文探讨了AI在电子健康记录(EHR)中的诊断预测问题，现有模型难以整合临床知识，导致推理能力不足。为解决此问题，研究提出DuaLK框架，该框架结合Diagnosis Knowledge Graph (KG)——由大型语言模型(LLM)丰富层次和语义关系的外部知识——以及基于实验室测试信号的lab-informed proxy task，以指导模型进行临床一致的逐步推理。在两个公共EHR数据集上的实验中，DuaLK在四个临床预测任务中均优于现有基线，提升了诊断准确性和可解释性。这些发现强调了整合结构化医疗知识与个体临床信号的潜力，可支持更可靠的AI辅助诊断。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19955v2",
      "published_date": "2024-10-25 20:25:22 UTC",
      "updated_date": "2025-04-15 23:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:24:51.229131"
    },
    {
      "arxiv_id": "2411.08881v2",
      "title": "Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI",
      "title_zh": "我们能信任 AI 代理吗？ 基于 LLM 的多代理系统在伦理 AI 中的",
      "authors": [
        "José Antonio Siqueira de Cerqueira",
        "Mamia Agbese",
        "Rebekah Rousi",
        "Nannan Xi",
        "Juho Hamari",
        "Pekka Abrahamsson"
      ],
      "abstract": "AI-based systems, including Large Language Models (LLM), impact millions by\nsupporting diverse tasks but face issues like misinformation, bias, and misuse.\nAI ethics is crucial as new technologies and concerns emerge, but objective,\npractical guidance remains debated. This study examines the use of LLMs for AI\nethics in practice, assessing how LLM trustworthiness-enhancing techniques\naffect software development in this context. Using the Design Science Research\n(DSR) method, we identify techniques for LLM trustworthiness: multi-agents,\ndistinct roles, structured communication, and multiple rounds of debate. We\ndesign a multi-agent prototype LLM-MAS, where agents engage in structured\ndiscussions on real-world AI ethics issues from the AI Incident Database. We\nevaluate the prototype across three case scenarios using thematic analysis,\nhierarchical clustering, comparative (baseline) studies, and running source\ncode. The system generates approximately 2,000 lines of code per case, compared\nto only 80 lines in baseline trials. Discussions reveal terms like bias\ndetection, transparency, accountability, user consent, GDPR compliance,\nfairness evaluation, and EU AI Act compliance, showing this prototype ability\nto generate extensive source code and documentation addressing often overlooked\nAI ethics issues. However, practical challenges in source code integration and\ndependency management may limit its use by practitioners.",
      "tldr_zh": "这篇论文探讨了LLM（Large Language Models）在AI伦理中的可信度问题，通过一个案例研究评估多智能体系统如何提升AI系统的trustworthiness。研究采用Design Science Research (DSR)方法，设计了LLM-MAS原型，该系统利用multi-agents、distinct roles、structured communication和多轮debate来讨论真实AI伦理案例，如从AI Incident Database中提取的问题。结果显示，原型生成约2,000行代码，显著高于基线的80行，并覆盖关键主题如bias detection、transparency和GDPR compliance，但存在source code integration和dependency management的实际挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.6.3"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08881v2",
      "published_date": "2024-10-25 20:17:59 UTC",
      "updated_date": "2025-05-16 13:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:25:04.558702"
    },
    {
      "arxiv_id": "2410.19948v1",
      "title": "Assessing the societal influence of academic research with ChatGPT: Impact case study evaluations",
      "title_zh": "使用 ChatGPT 评估学术研究的社会影响：影响案例研究",
      "authors": [
        "Kayvan Kousha",
        "Mike Thelwall"
      ],
      "abstract": "Academics and departments are sometimes judged by how their research has\nbenefitted society. For example, the UK Research Excellence Framework (REF)\nassesses Impact Case Studies (ICS), which are five-page evidence-based claims\nof societal impacts. This study investigates whether ChatGPT can evaluate\nsocietal impact claims and therefore potentially support expert human\nassessors. For this, various parts of 6,220 public ICS from REF2021 were fed to\nChatGPT 4o-mini along with the REF2021 evaluation guidelines, comparing the\nresults with published departmental average ICS scores. The results suggest\nthat the optimal strategy for high correlations with expert scores is to input\nthe title and summary of an ICS but not the remaining text, and to modify the\noriginal REF guidelines to encourage a stricter evaluation. The scores\ngenerated by this approach correlated positively with departmental average\nscores in all 34 Units of Assessment (UoAs), with values between 0.18\n(Economics and Econometrics) and 0.56 (Psychology, Psychiatry and\nNeuroscience). At the departmental level, the corresponding correlations were\nhigher, reaching 0.71 for Sport and Exercise Sciences, Leisure and Tourism.\nThus, ChatGPT-based ICS evaluations are simple and viable to support or\ncross-check expert judgments, although their value varies substantially between\nfields.",
      "tldr_zh": "本研究评估了使用 ChatGPT 评估学术研究对社会影响的可行性，特别针对 UK Research Excellence Framework (REF) 中的 Impact Case Studies (ICS)，通过将 6,220 个 ICS 的标题和摘要输入 ChatGPT 4o-mini 并修改评估指南来进行比较。结果显示，这种方法能与专家评分产生正相关性，在 34 个 Units of Assessment (UoAs) 中相关系数从 0.18 (Economics and Econometrics) 到 0.56 (Psychology, Psychiatry and Neuroscience)，部门层面最高达 0.71 (Sport and Exercise Sciences, Leisure and Tourism)。总体而言，ChatGPT 提供了一种简单有效的工具来支持或交叉检查专家判断，但其准确性因领域而有显著差异。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19948v1",
      "published_date": "2024-10-25 19:51:10 UTC",
      "updated_date": "2024-10-25 19:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:25:17.158441"
    },
    {
      "arxiv_id": "2410.19940v1",
      "title": "Cobblestone: Iterative Automation for Formal Verification",
      "title_zh": "Cobblestone：用于形式验证的迭代自动化",
      "authors": [
        "Saketh Ram Kasibatla",
        "Arpan Agarwal",
        "Yuriy Brun",
        "Sorin Lerner",
        "Talia Ringer",
        "Emily First"
      ],
      "abstract": "Formal verification using proof assistants, such as Coq, is an effective way\nof improving software quality, but it is expensive. Writing proofs manually\nrequires both significant effort and expertise. Recent research has used\nmachine learning to automatically synthesize proofs, reducing verification\neffort, but these tools are able to prove only a fraction of the desired\nsoftware properties. We introduce Cobblestone, a new proof-synthesis approach\nthat improves on the state of the art by taking advantage of partial progress\nin proof synthesis attempts. Unlike prior tools, Cobblestone can produce\nmultiple unsuccessful proofs using a large language model (LLM), identify the\nworking portions of those proofs, and combine them into a single, successful\nproof, taking advantage of internal partial progress. We evaluate Cobblestone\non two benchmarks of open-source Coq projects, controlling for training data\nleakage in LLM datasets. Fully automatically, Cobblestone can prove 48% of the\ntheorems, while Proverbot9001, the previous state-of-the-art, learning-based,\nproof-synthesis tool, can prove 17%. Cobblestone establishes a new state of the\nart for fully automated proof synthesis tools for Coq. We also evaluate\nCobblestone in a setting where it is given external partial proof progress from\noracles, serving as proxies for a human proof engineer or another tool. When\nthe theorem is broken down into a set of subgoals and Cobblestone is given a\nset of relevant lemmas already proven in the project, it can prove up to 58% of\nthe theorems. We qualitatively study the theorems Cobblestone is and is not\nable to prove to outline potential future research directions to further\nimprove proof synthesis, including developing interactive, semi-automated\ntools. Our research shows that tools can make better use of partial progress\nmade during proof synthesis to more effectively automate formal verification.",
      "tldr_zh": "本研究引入 Cobblestone，一种迭代式自动化方法，用于提升正式验证（formal verification）的效率，通过利用大型语言模型 (LLM) 生成多个部分证明，并将有效部分组合成完整证明，从而解决现有工具（如 Proverbot9001）只能证明部分属性的局限性。在两个开源 Coq 项目基准测试中，Cobblestone 自动证明了 48% 的定理，远超 Proverbot9001 的 17%，确立了 Coq 证明合成工具的新标准。当提供外部部分证明进展时，其证明率可达 58%。该工作强调了更好地利用部分进展来自动化验证的潜力，并为未来开发交互式工具指出了研究方向。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LO",
      "comment": "13 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19940v1",
      "published_date": "2024-10-25 19:25:00 UTC",
      "updated_date": "2024-10-25 19:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:25:28.290281"
    },
    {
      "arxiv_id": "2410.19937v1",
      "title": "RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction",
      "title_zh": "翻译失败",
      "authors": [
        "Tanqiu Jiang",
        "Zian Wang",
        "Jiacheng Liang",
        "Changjiang Li",
        "Yuhui Wang",
        "Ting Wang"
      ],
      "abstract": "Jailbreak attacks circumvent LLMs' built-in safeguards by concealing harmful\nqueries within jailbreak prompts. While existing defenses primarily focus on\nmitigating the effects of jailbreak prompts, they often prove inadequate as\njailbreak prompts can take arbitrary, adaptive forms. This paper presents\nRobustKV, a novel defense that adopts a fundamentally different approach by\nselectively removing critical tokens of harmful queries from key-value (KV)\ncaches. Intuitively, for a jailbreak prompt to be effective, its tokens must\nachieve sufficient `importance' (as measured by attention scores), which\ninevitably lowers the importance of tokens in the concealed harmful query.\nThus, by strategically evicting the KVs of the lowest-ranked tokens, RobustKV\ndiminishes the presence of the harmful query in the KV cache, thus preventing\nthe LLM from generating malicious responses. Extensive evaluation using\nbenchmark datasets and models demonstrates that RobustKV effectively counters\nstate-of-the-art jailbreak attacks while maintaining the LLM's general\nperformance on benign queries. Moreover, RobustKV creates an intriguing\nevasiveness dilemma for adversaries, forcing them to balance between evading\nRobustKV and bypassing the LLM's built-in safeguards. This trade-off\ncontributes to RobustKV's robustness against adaptive attacks. (warning: this\npaper contains potentially harmful content generated by LLMs.)",
      "tldr_zh": "该论文提出 RobustKV，一种创新防御机制，用于保护 Large Language Models (LLMs) 免受 Jailbreak Attacks 的影响，通过从 key-value (KV) caches 中选择性地移除有害查询的关键 tokens。RobustKV 利用注意力分数评估 tokens 的重要性，优先 eviction 低排名 tokens，从而减少隐藏有害查询在模型中的影响力，同时保持模型对 benign queries 的正常性能。实验结果显示，该方法在基准数据集上有效对抗最先进的攻击，并迫使攻击者面临权衡 evade RobustKV 与绕过 LLM 内置安全机制的困境，提升了防御的整体鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19937v1",
      "published_date": "2024-10-25 19:18:22 UTC",
      "updated_date": "2024-10-25 19:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:25:40.679044"
    },
    {
      "arxiv_id": "2410.21312v1",
      "title": "$\\texttt{PatentAgent}$: Intelligent Agent for Automated Pharmaceutical Patent Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Wang",
        "Yifan Zhang",
        "Xiaojing Zhang",
        "Longhui Yu",
        "Xinna Lin",
        "Jindong Jiang",
        "Bin Ma",
        "Kaicheng Yu"
      ],
      "abstract": "Pharmaceutical patents play a vital role in biochemical industries,\nespecially in drug discovery, providing researchers with unique early access to\ndata, experimental results, and research insights. With the advancement of\nmachine learning, patent analysis has evolved from manual labor to tasks\nassisted by automatic tools. However, there still lacks an unified agent that\nassists every aspect of patent analysis, from patent reading to core chemical\nidentification. Leveraging the capabilities of Large Language Models (LLMs) to\nunderstand requests and follow instructions, we introduce the $\\textbf{first}$\nintelligent agent in this domain, $\\texttt{PatentAgent}$, poised to advance and\npotentially revolutionize the landscape of pharmaceutical research.\n$\\texttt{PatentAgent}$ comprises three key end-to-end modules --\n$\\textit{PA-QA}$, $\\textit{PA-Img2Mol}$, and $\\textit{PA-CoreId}$ -- that\nrespectively perform (1) patent question-answering, (2)\nimage-to-molecular-structure conversion, and (3) core chemical structure\nidentification, addressing the essential needs of scientists and practitioners\nin pharmaceutical patent analysis. Each module of $\\texttt{PatentAgent}$\ndemonstrates significant effectiveness with the updated algorithm and the\nsynergistic design of $\\texttt{PatentAgent}$ framework. $\\textit{PA-Img2Mol}$\noutperforms existing methods across CLEF, JPO, UOB, and USPTO patent benchmarks\nwith an accuracy gain between 2.46% and 8.37% while $\\textit{PA-CoreId}$\nrealizes accuracy improvement ranging from 7.15% to 7.62% on PatentNetML\nbenchmark. Our code and dataset will be publicly available.",
      "tldr_zh": "本研究引入了$\\texttt{PatentAgent}$，第一个利用Large Language Models (LLMs)的智能代理，用于自动化制药专利分析，以解决从专利阅读到核心化学识别的全面需求。$\\texttt{PatentAgent}$包括三个关键模块：$\\textit{PA-QA}$负责专利问答、$\\textit{PA-Img2Mol}$处理图像到分子结构转换，以及$\\textit{PA-CoreId}$进行核心化学结构识别，这些模块通过协同设计显著提升了分析效率。实验结果显示，$\\textit{PA-Img2Mol}$在CLEF、JPO、UOB和USPTO基准上准确率提高了2.46%至8.37%，而$\\textit{PA-CoreId}$在PatentNetML基准上提升了7.15%至7.62%，有望革命化制药研究领域。代码和数据集将公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.21312v1",
      "published_date": "2024-10-25 19:15:08 UTC",
      "updated_date": "2024-10-25 19:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:25:53.792554"
    },
    {
      "arxiv_id": "2410.19933v2",
      "title": "Enhancing Safety in Reinforcement Learning with Human Feedback via Rectified Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyue Peng",
        "Hengquan Guo",
        "Jiawei Zhang",
        "Dongqing Zou",
        "Ziyu Shao",
        "Honghao Wei",
        "Xin Liu"
      ],
      "abstract": "Balancing helpfulness and safety (harmlessness) is a critical challenge in\naligning large language models (LLMs). Current approaches often decouple these\ntwo objectives, training separate preference models for helpfulness and safety,\nwhile framing safety as a constraint within a constrained Markov Decision\nProcess (CMDP) framework. This paper identifies a potential issue when using\nthe widely adopted expected safety constraints for LLM safety alignment, termed\n\"safety compensation\", where the constraints are satisfied on expectation, but\nindividual prompts may trade off safety, resulting in some responses being\noverly restrictive while others remain unsafe. To address this issue, we\npropose Rectified Policy Optimization (RePO), which replaces the expected\nsafety constraint with critical safety constraints imposed on every prompt. At\nthe core of RePO is a policy update mechanism driven by rectified policy\ngradients, which penalizes the strict safety violation of every prompt, thereby\nenhancing safety across nearly all prompts. Our experiments demonstrate that\nRePO outperforms strong baseline methods and significantly enhances LLM safety\nalignment.",
      "tldr_zh": "这篇论文针对强化学习中安全约束的问题，提出了Rectified Policy Optimization (RePO)方法，以解决当前方法在处理大型语言模型(LLMs)安全对齐时出现的“安全补偿”现象，即期望约束满足但个别提示可能牺牲安全。RePO的核心是通过rectified policy gradients的策略更新机制，在每个提示上施加严格的安全约束，惩罚任何安全违规，从而提升整体安全性。实验结果表明，RePO优于强基线方法，并显著增强了LLMs的安全对齐性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19933v2",
      "published_date": "2024-10-25 19:08:23 UTC",
      "updated_date": "2025-02-27 07:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:26:05.009819"
    },
    {
      "arxiv_id": "2410.19923v1",
      "title": "Language Agents Meet Causality -- Bridging LLMs and Causal World Models",
      "title_zh": "翻译失败",
      "authors": [
        "John Gkountouras",
        "Matthias Lindemann",
        "Phillip Lippe",
        "Efstratios Gavves",
        "Ivan Titov"
      ],
      "abstract": "Large Language Models (LLMs) have recently shown great promise in planning\nand reasoning applications. These tasks demand robust systems, which arguably\nrequire a causal understanding of the environment. While LLMs can acquire and\nreflect common sense causal knowledge from their pretraining data, this\ninformation is often incomplete, incorrect, or inapplicable to a specific\nenvironment. In contrast, causal representation learning (CRL) focuses on\nidentifying the underlying causal structure within a given environment. We\npropose a framework that integrates CRLs with LLMs to enable causally-aware\nreasoning and planning. This framework learns a causal world model, with causal\nvariables linked to natural language expressions. This mapping provides LLMs\nwith a flexible interface to process and generate descriptions of actions and\nstates in text form. Effectively, the causal world model acts as a simulator\nthat the LLM can query and interact with. We evaluate the framework on causal\ninference and planning tasks across temporal scales and environmental\ncomplexities. Our experiments demonstrate the effectiveness of the approach,\nwith the causally-aware method outperforming LLM-based reasoners, especially\nfor longer planning horizons.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在规划和推理任务中的局限性，特别是因果知识的不完整问题，并提出一个整合因果表示学习 (CRL) 的框架，以桥接 LLMs 和因果世界模型。框架通过学习一个因果世界模型，将因果变量链接到自然语言表达，允许 LLMs 以文本形式查询和交互环境模拟，从而实现更准确的因果感知推理和规划。实验结果表明，该方法在各种因果推理和规划任务上优于纯 LLM 基线，尤其在长期规划场景中表现出显著优势。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://j0hngou.github.io/LLMCWM/",
      "pdf_url": "http://arxiv.org/pdf/2410.19923v1",
      "published_date": "2024-10-25 18:36:37 UTC",
      "updated_date": "2024-10-25 18:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:28:18.072504"
    },
    {
      "arxiv_id": "2410.19922v1",
      "title": "Disentangling Genotype and Environment Specific Latent Features for Improved Trait Prediction using a Compositional Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Anirudha Powadi",
        "Talukder Zaki Jubery",
        "Michael C. Tross",
        "James C. Schnable",
        "Baskar Ganapathysubramanian"
      ],
      "abstract": "This study introduces a compositional autoencoder (CAE) framework designed to\ndisentangle the complex interplay between genotypic and environmental factors\nin high-dimensional phenotype data to improve trait prediction in plant\nbreeding and genetics programs. Traditional predictive methods, which use\ncompact representations of high-dimensional data through handcrafted features\nor latent features like PCA or more recently autoencoders, do not separate\ngenotype-specific and environment-specific factors. We hypothesize that\ndisentangling these features into genotype-specific and environment-specific\ncomponents can enhance predictive models. To test this, we developed a\ncompositional autoencoder (CAE) that decomposes high-dimensional data into\ndistinct genotype-specific and environment-specific latent features.\n  Our CAE framework employs a hierarchical architecture within an autoencoder\nto effectively separate these entangled latent features. Applied to a maize\ndiversity panel dataset, the CAE demonstrates superior modeling of\nenvironmental influences and 5-10 times improved predictive performance for key\ntraits like Days to Pollen and Yield, compared to the traditional methods,\nincluding standard autoencoders, PCA with regression, and Partial Least Squares\nRegression (PLSR). By disentangling latent features, the CAE provides powerful\ntool for precision breeding and genetic research. This work significantly\nenhances trait prediction models, advancing agricultural and biological\nsciences.",
      "tldr_zh": "本研究引入了 compositional autoencoder (CAE) 框架，用于分离高维表型数据中 genotype 和 environment 因素的相互作用，从而提升植物育种和遗传学中的性状预测性能。CAE 采用分层架构，将数据分解为独立的 genotype-specific 和 environment-specific 潜变量，解决了传统方法如 PCA、标准 autoencoders 和 PLSR 在分离这些因素方面的不足。在玉米多样性面板数据集上，CAE 显著改善了关键性状（如 Days to Pollen 和 Yield）的预测性能，提高了 5-10 倍，为精确育种和遗传研究提供了强大工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19922v1",
      "published_date": "2024-10-25 18:30:27 UTC",
      "updated_date": "2024-10-25 18:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:28:21.009804"
    },
    {
      "arxiv_id": "2410.19919v1",
      "title": "Provably Adaptive Average Reward Reinforcement Learning for Metric Spaces",
      "title_zh": "针对度量空间的可证明自适应平均奖励强化学习",
      "authors": [
        "Avik Kar",
        "Rahul Singh"
      ],
      "abstract": "We study infinite-horizon average-reward reinforcement learning (RL) for\nLipschitz MDPs and develop an algorithm ZoRL that discretizes the state-action\nspace adaptively and zooms into promising regions of the state-action space. We\nshow that its regret can be bounded as $\\mathcal{\\tilde{O}}\\big(T^{1 -\nd_{\\text{eff.}}^{-1}}\\big)$, where $d_{\\text{eff.}} = 2d_\\mathcal{S} + d_z +\n3$, $d_\\mathcal{S}$ is the dimension of the state space, and $d_z$ is the\nzooming dimension. $d_z$ is a problem-dependent quantity, which allows us to\nconclude that if MDP is benign, then its regret will be small. We note that the\nexisting notion of zooming dimension for average reward RL is defined in terms\nof policy coverings, and hence it can be huge when the policy class is rich\neven though the underlying MDP is simple, so that the regret upper bound is\nnearly $O(T)$. The zooming dimension proposed in the current work is bounded\nabove by $d$, the dimension of the state-action space, and hence is truly\nadaptive, i.e., shows how to capture adaptivity gains for infinite-horizon\naverage-reward RL. ZoRL outperforms other state-of-the-art algorithms in\nexperiments; thereby demonstrating the gains arising due to adaptivity.",
      "tldr_zh": "本文提出一种自适应算法 ZoRL，用于无限地平线平均奖励强化学习（RL）在 Lipschitz MDPs 中的应用。ZoRL 通过自适应离散化状态-动作空间并聚焦于有前景区域，实现 regret 上界为 \\(\\mathcal{\\tilde{O}}(T^{1 - d_{\\text{eff.}}^{-1}})\\)，其中 \\(d_{\\text{eff.}} = 2d_\\mathcal{S} + d_z + 3\\)，并引入了一个新的 zooming dimension \\(d_z\\)，其上限为状态-动作空间维度 \\(d\\)，从而真正捕捉问题适应性。相比现有方法，该框架能更好地处理良性 MDP，并实验证明 ZoRL 在性能上优于最先进算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19919v1",
      "published_date": "2024-10-25 18:14:42 UTC",
      "updated_date": "2024-10-25 18:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:26:42.134578"
    },
    {
      "arxiv_id": "2410.19915v2",
      "title": "AI-Driven Scenarios for Urban Mobility: Quantifying the Role of ODE Models and Scenario Planning in Reducing Traffic Congestion",
      "title_zh": "AI 驱动的城市移动场景：",
      "authors": [
        "Katsiaryna Bahamazava"
      ],
      "abstract": "Urbanization and technological advancements are reshaping urban mobility,\npresenting both challenges and opportunities. This paper investigates how\nArtificial Intelligence (AI)-driven technologies can impact traffic congestion\ndynamics and explores their potential to enhance transportation systems'\nefficiency. Specifically, we assess the role of AI innovations, such as\nautonomous vehicles and intelligent traffic management, in mitigating\ncongestion under varying regulatory frameworks. Autonomous vehicles reduce\ncongestion through optimized traffic flow, real-time route adjustments, and\ndecreased human errors.\n  The study employs Ordinary Differential Equations (ODEs) to model the dynamic\nrelationship between AI adoption rates and traffic congestion, capturing\nsystemic feedback loops. Quantitative outputs include threshold levels of AI\nadoption needed to achieve significant congestion reduction, while qualitative\ninsights stem from scenario planning exploring regulatory and societal\nconditions. This dual-method approach offers actionable strategies for\npolicymakers to create efficient, sustainable, and equitable urban\ntransportation systems. While safety implications of AI are acknowledged, this\nstudy primarily focuses on congestion reduction dynamics.",
      "tldr_zh": "这篇论文探讨了 AI 驱动技术在城市交通中的作用，评估了自动驾驶车辆和智能交通管理如何通过优化流量、实时路线调整和减少人为错误来缓解交通拥堵。\n研究采用 Ordinary Differential Equations (ODEs) 模型来模拟 AI 采用率与拥堵动态的关系，捕捉系统反馈循环，并结合 scenario planning 分析监管和社会条件的影响。\n结果量化了实现显著拥堵减少所需的 AI 采用阈值，并为政策制定者提供可操作策略，以构建高效、可持续和公平的城市交通系统。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19915v2",
      "published_date": "2024-10-25 18:09:02 UTC",
      "updated_date": "2025-01-07 13:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:26:52.488155"
    },
    {
      "arxiv_id": "2410.19912v1",
      "title": "Simmering: Sufficient is better than optimal for training neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Babayan",
        "Hazhir Aliahmadi",
        "Greg van Anders"
      ],
      "abstract": "The broad range of neural network training techniques that invoke\noptimization but rely on ad hoc modification for validity suggests that\noptimization-based training is misguided. Shortcomings of optimization-based\ntraining are brought to particularly strong relief by the problem of\noverfitting, where naive optimization produces spurious outcomes. The broad\nsuccess of neural networks for modelling physical processes has prompted\nadvances that are based on inverting the direction of investigation and\ntreating neural networks as if they were physical systems in their own right\nThese successes raise the question of whether broader, physical perspectives\ncould motivate the construction of improved training algorithms. Here, we\nintroduce simmering, a physics-based method that trains neural networks to\ngenerate weights and biases that are merely ``good enough'', but which,\nparadoxically, outperforms leading optimization-based approaches. Using\nclassification and regression examples we show that simmering corrects neural\nnetworks that are overfit by Adam, and show that simmering avoids overfitting\nif deployed from the outset. Our results question optimization as a paradigm\nfor neural network training, and leverage information-geometric arguments to\npoint to the existence of classes of sufficient training algorithms that do not\ntake optimization as their starting point.",
      "tldr_zh": "本论文批评了基于优化的神经网络训练方法，认为其依赖临时修改且容易导致 overfitting，从而产生虚假结果。作者引入了新的 physics-based 方法“simmering”，该方法训练神经网络生成“足够好”的权重和偏差，而不是追求最优解。实验结果显示，simmering 能够修正 Adam 优化器引起的 overfitting，并在从一开始应用时有效避免过拟合；此外，论文通过信息几何论点质疑优化范式，并指出存在其他“sufficient”训练算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19912v1",
      "published_date": "2024-10-25 18:02:08 UTC",
      "updated_date": "2024-10-25 18:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:30:33.695542"
    },
    {
      "arxiv_id": "2410.19733v1",
      "title": "The Potential and Value of AI Chatbot in Personalized Cognitive Training",
      "title_zh": "AI 聊天机器人在个性化认知训练中的潜力与价值",
      "authors": [
        "Zilong Wang",
        "Nan Chen",
        "Luna K. Qiu",
        "Ling Yue",
        "Geli Guo",
        "Yang Ou",
        "Shiqi Jiang",
        "Yuqing Yang",
        "Lili Qiu"
      ],
      "abstract": "In recent years, the rapid aging of the global population has led to an\nincrease in cognitive disorders, such as Alzheimer's disease, presenting\nsignificant public health challenges. Although no effective treatments\ncurrently exist to reverse Alzheimer's, prevention and early intervention,\nincluding cognitive training, are critical. This report explores the potential\nof AI chatbots in enhancing personalized cognitive training. We introduce ReMe,\na web-based framework designed to create AI chatbots that facilitate cognitive\ntraining research, specifically targeting episodic memory tasks derived from\npersonal life logs. By leveraging large language models, ReMe provides enhanced\nuser-friendly, interactive, and personalized training experiences. Case studies\ndemonstrate ReMe's effectiveness in engaging users through life recall and\nopen-ended language puzzles, highlighting its potential to improve cognitive\ntraining design. Despite promising results, further research is needed to\nvalidate training effectiveness through large-scale studies that include\ncognitive ability evaluations. Overall, ReMe offers a promising approach to\npersonalized cognitive training, utilizing AI capabilities to meet the growing\ndemand for non-pharmacological interventions in cognitive health, with future\nresearch aiming to expand its applications and efficacy.",
      "tldr_zh": "全球人口老龄化导致认知障碍如阿尔茨海默病增加，本文探讨AI chatbot在个性化认知训练中的潜力，作为预防和早期干预的有效手段。研究引入ReMe框架，这是一个基于网络的系统，利用large language models从个人生活日志中衍生情景记忆任务，提供用户友好的交互式训练体验。案例研究证明ReMe通过生活回忆和开放式语言谜题提升用户参与度和训练设计，尽管未来需进行大规模研究以验证其对认知能力的实际影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19733v1",
      "published_date": "2024-10-25 17:59:36 UTC",
      "updated_date": "2024-10-25 17:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:28:45.039776"
    },
    {
      "arxiv_id": "2410.19730v2",
      "title": "Counting Ability of Large Language Models and Impact of Tokenization",
      "title_zh": "大型语言模型的计数能力及分词的影响",
      "authors": [
        "Xiang Zhang",
        "Juntai Cao",
        "Chenyu You"
      ],
      "abstract": "Transformers, the backbone of modern large language models (LLMs), face\ninherent architectural limitations that impede their reasoning capabilities.\nUnlike recurrent networks, Transformers lack recurrent connections, confining\nthem to constant-depth computation. This restriction places them in the\ncomplexity class TC$^0$, making them theoretically incapable of solving tasks\nthat demand increasingly deep reasoning as input length grows. Counting, a\nfundamental component of many reasoning tasks, also requires reasoning depth to\ngrow linearly to be performed inductively. While previous studies have\nestablished the upper limits of counting ability in Transformer-based expert\nmodels (i.e., models specifically trained for counting tasks), these findings\ndo not directly extend to general-purpose LLMs due to differences in reasoning\nmechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning\ncan help alleviate some of the architectural limitations of Transformers in\ncounting tasks. However, little attention has been paid to the role of\ntokenization in these models. Unlike expert models that often use\ncharacter-level tokenization, LLMs typically rely on byte-level (BPE)\ntokenizers, which fundamentally alters the way reasoning is processed. Our work\ninvestigates the impact of tokenization on the counting abilities of LLMs,\nuncovering substantial performance variations based on input tokenization\ndifferences. We provide both theoretical and experimental analyses, offering\ninsights into how tokenization choices can undermine models' theoretical\ncomputability, thereby inspiring the design of new tokenization methods to\nenhance reasoning in LLMs.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在计数任务中的能力及其与 tokenization 的关系，指出 Transformers 架构由于缺乏循环连接而受限于 TC^0 复杂度，无法有效处理需要线性增长深度推理的任务。作者分析了 Chain of Thought (CoT) 推理如何缓解这些限制，并重点考察了 LLMs 采用的 byte-level (BPE) tokenizers 与专家模型的字符级 tokenization 之间的差异，导致性能显著变化。通过理论和实验分析，研究揭示 tokenization 选择可能破坏模型的计算能力，并提出设计新 tokenization 方法来增强 LLMs 的推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19730v2",
      "published_date": "2024-10-25 17:56:24 UTC",
      "updated_date": "2024-10-29 03:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:28:57.000912"
    },
    {
      "arxiv_id": "2410.19727v1",
      "title": "FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Nicole Cho",
        "Nishan Srishankar",
        "Lucas Cecchi",
        "William Watson"
      ],
      "abstract": "Financial intelligence generation from vast data sources has typically relied\non traditional methods of knowledge-graph construction or database engineering.\nRecently, fine-tuned financial domain-specific Large Language Models (LLMs),\nhave emerged. While these advancements are promising, limitations such as high\ninference costs, hallucinations, and the complexity of concurrently analyzing\nhigh-dimensional financial data, emerge. This motivates our invention FISHNET\n(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,\nExpert swarming, and Task planning), an agentic architecture that accomplishes\nhighly complex analytical tasks for more than 98,000 regulatory filings that\nvary immensely in terms of semantics, data hierarchy, or format. FISHNET shows\nremarkable performance for financial insight generation (61.8% success rate\nover 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to\nempirically prove the success of FISHNET, each agent's importance, and the\noptimized performance of assembling all agents. Our modular architecture can be\nleveraged for a myriad of use-cases, enabling scalability, flexibility, and\ndata integrity that are critical for financial tasks.",
      "tldr_zh": "该论文提出 FISHNET 架构，一种多代理系统，用于从超过 98,000 个监管文件中生成金融智能，解决传统知识图谱方法和微调 LLMs 的高成本、幻觉以及高维数据分析复杂性问题。FISHNET 通过子查询 (Sub-querying)、协调 (Harmonizing)、神经条件 (Neural-Conditioning)、专家群 (Expert Swarms) 和任务规划 (Task Planning) 等机制，实现对语义和格式多样数据的复杂分析。实验结果显示，FISHNET 在金融洞察生成中取得 61.8% 的成功率，远超基线模型（如 5.0% Routing 和 45.6% RAG R-Precision）。该模块化设计增强了系统的可扩展性、灵活性和数据完整性，适用于各种金融任务。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 5th ACM International Conference on AI in Finance\n  (ICAIF '24)",
      "pdf_url": "http://arxiv.org/pdf/2410.19727v1",
      "published_date": "2024-10-25 17:53:47 UTC",
      "updated_date": "2024-10-25 17:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:29:10.777941"
    },
    {
      "arxiv_id": "2410.19723v2",
      "title": "Sparse Decomposition of Graph Neural Networks",
      "title_zh": "图神经网络的稀疏分解",
      "authors": [
        "Yaochen Hu",
        "Mai Zeng",
        "Ge Zhang",
        "Pavel Rumiantsev",
        "Liheng Ma",
        "Yingxue Zhang",
        "Mark Coates"
      ],
      "abstract": "Graph Neural Networks (GNN) exhibit superior performance in graph\nrepresentation learning, but their inference cost can be high, due to an\naggregation operation that can require a memory fetch for a very large number\nof nodes. This inference cost is the major obstacle to deploying GNN models\nwith \\emph{online prediction} to reflect the potentially dynamic node features.\nTo address this, we propose an approach to reduce the number of nodes that are\nincluded during aggregation. We achieve this through a sparse decomposition,\nlearning to approximate node representations using a weighted sum of linearly\ntransformed features of a carefully selected subset of nodes within the\nextended neighbourhood. The approach achieves linear complexity with respect to\nthe average node degree and the number of layers in the graph neural network.\nWe introduce an algorithm to compute the optimal parameters for the sparse\ndecomposition, ensuring an accurate approximation of the original GNN model,\nand present effective strategies to reduce the training time and improve the\nlearning process. We demonstrate via extensive experiments that our method\noutperforms other baselines designed for inference speedup, achieving\nsignificant accuracy gains with comparable inference times for both node\nclassification and spatio-temporal forecasting tasks.",
      "tldr_zh": "这篇论文针对Graph Neural Networks (GNN)的高推理成本问题，提出了一种稀疏分解方法，通过学习使用子集节点的加权和来近似节点表示，从而减少聚合操作中的节点数量。该方法实现与平均节点度数和层数成线性复杂度的推理，并引入算法计算最优参数，同时提供策略优化训练过程。实验结果显示，该方法在节点分类和时空预测任务中优于其他基线模型，显著提升准确率，同时保持可比的推理时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19723v2",
      "published_date": "2024-10-25 17:52:16 UTC",
      "updated_date": "2025-03-15 06:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:29:20.846932"
    },
    {
      "arxiv_id": "2410.19720v1",
      "title": "2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Li",
        "Yancheng He",
        "Hui Huang",
        "Xingyuan Bu",
        "Jiaheng Liu",
        "Hangyu Guo",
        "Weixun Wang",
        "Jihao Gu",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in Direct Preference Optimization (DPO) have\nsignificantly enhanced the alignment of Large Language Models (LLMs) with human\npreferences, owing to its simplicity and effectiveness. However, existing\nmethods typically optimize a scalar score or ranking reward, thereby\noverlooking the multi-dimensional nature of human preferences. In this work, we\npropose to extend the preference of DPO to two dimensions: segments and\naspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For\nthe segment dimension, we divide the response into sentences and assign scores\nto each segment. For the aspect dimension, we meticulously design several\ncriteria covering the response quality rubrics. With the 2-dimensional signals\nas feedback, we develop a 2D-DPO framework, decomposing the overall objective\ninto multi-segment and multi-aspect objectives. Extensive experiments on\npopular benchmarks demonstrate that 2D-DPO performs better than methods that\noptimize for scalar or 1-dimensional preferences.",
      "tldr_zh": "本文提出了一种扩展 Direct Preference Optimization (DPO) 的方法，名为 2D-DPO，通过引入二维监督（segments 和 aspects）来更好地处理人类偏好的多维性。研究者构建了 HelpSteer-2D 数据集，其中 segments 维度将响应分成句子并分配分数，aspects 维度则设计了多个标准来评估响应质量。2D-DPO 框架将优化目标分解为多段落和多方面目标，并在流行基准测试中表现出色，比优化标量或一维偏好的方法性能提升明显。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first four authors contributed equally, 25 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19720v1",
      "published_date": "2024-10-25 17:47:35 UTC",
      "updated_date": "2024-10-25 17:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:29:33.865217"
    },
    {
      "arxiv_id": "2410.19719v1",
      "title": "Arabic Music Classification and Generation using Deep Learning",
      "title_zh": "使用深度学习的阿拉伯音乐分类与生成",
      "authors": [
        "Mohamed Elshaarawy",
        "Ashrakat Saeed",
        "Mariam Sheta",
        "Abdelrahman Said",
        "Asem Bakr",
        "Omar Bahaa",
        "Walid Gomaa"
      ],
      "abstract": "This paper proposes a machine learning approach for classifying classical and\nnew Egyptian music by composer and generating new similar music. The proposed\nsystem utilizes a convolutional neural network (CNN) for classification and a\nCNN autoencoder for generation. The dataset used in this project consists of\nnew and classical Egyptian music pieces composed by different composers.\n  To classify the music by composer, each sample is normalized and transformed\ninto a mel spectrogram. The CNN model is trained on the dataset using the mel\nspectrograms as input features and the composer labels as output classes. The\nmodel achieves 81.4\\% accuracy in classifying the music by composer,\ndemonstrating the effectiveness of the proposed approach.\n  To generate new music similar to the original pieces, a CNN autoencoder is\ntrained on a similar dataset. The model is trained to encode the mel\nspectrograms of the original pieces into a lower-dimensional latent space and\nthen decode them back into the original mel spectrogram. The generated music is\nproduced by sampling from the latent space and decoding the samples back into\nmel spectrograms, which are then transformed into audio.\n  In conclusion, the proposed system provides a promising approach to\nclassifying and generating classical Egyptian music, which can be applied in\nvarious musical applications, such as music recommendation systems, music\nproduction, and music education.",
      "tldr_zh": "这篇论文提出了一种基于深度学习的系统，用于分类古典和新埃及音乐（按作曲家分类）并生成类似的新音乐。系统采用CNN模型对mel spectrogram进行训练，实现作曲家分类，准确率达到81.4%。此外，通过CNN autoencoder将mel spectrogram编码到低维潜空间并采样解码，生成与原音乐相似的音频。总体而言，该方法为埃及音乐的分类和生成提供了一个有前景的框架，可应用于音乐推荐系统、生产和教育等领域。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19719v1",
      "published_date": "2024-10-25 17:47:08 UTC",
      "updated_date": "2024-10-25 17:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:29:45.033576"
    },
    {
      "arxiv_id": "2410.19898v1",
      "title": "A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection",
      "title_zh": "非侵入性认知障碍检测的深度",
      "authors": [
        "Muath Alsuhaibani",
        "Ali Pourramezan Fard",
        "Jian Sun",
        "Farida Far Poor",
        "Peter S. Pressman",
        "Mohammad H. Mahoor"
      ],
      "abstract": "This review paper explores recent advances in deep learning approaches for\nnon-invasive cognitive impairment detection. We examine various non-invasive\nindicators of cognitive decline, including speech and language, facial, and\nmotoric mobility. The paper provides an overview of relevant datasets,\nfeature-extracting techniques, and deep-learning architectures applied to this\ndomain. We have analyzed the performance of different methods across modalities\nand observed that speech and language-based methods generally achieved the\nhighest detection performance. Studies combining acoustic and linguistic\nfeatures tended to outperform those using a single modality. Facial analysis\nmethods showed promise for visual modalities but were less extensively studied.\nMost papers focused on binary classification (impaired vs. non-impaired), with\nfewer addressing multi-class or regression tasks. Transfer learning and\npre-trained language models emerged as popular and effective techniques,\nespecially for linguistic analysis. Despite significant progress, several\nchallenges remain, including data standardization and accessibility, model\nexplainability, longitudinal analysis limitations, and clinical adaptation.\nLastly, we propose future research directions, such as investigating\nlanguage-agnostic speech analysis methods, developing multi-modal diagnostic\nsystems, and addressing ethical considerations in AI-assisted healthcare. By\nsynthesizing current trends and identifying key obstacles, this review aims to\nguide further development of deep learning-based cognitive impairment detection\nsystems to improve early diagnosis and ultimately patient outcomes.",
      "tldr_zh": "这篇综述论文回顾了深度学习在非侵入性认知障碍检测中的最新进展，涵盖了语音和语言、面部以及运动能力等指标，并概述了相关数据集、特征提取技术和深度学习架构。研究发现，语音和语言方法（如结合声学和语言特征）通常表现出最高检测性能，而转移学习和预训练语言模型在语言分析中特别有效；然而，面部分析虽有潜力，但研究较少，且大多数工作仅限于二分类任务。论文指出了数据标准化、模型可解释性以及临床适应等挑战，并建议未来方向包括开发语言无关的语音分析和多模态诊断系统，以推动早期诊断和改善患者结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19898v1",
      "published_date": "2024-10-25 17:44:59 UTC",
      "updated_date": "2024-10-25 17:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:29:57.293764"
    },
    {
      "arxiv_id": "2410.21276v1",
      "title": "GPT-4o System Card",
      "title_zh": "GPT-4o 系统卡",
      "authors": [
        "OpenAI",
        ":",
        "Aaron Hurst",
        "Adam Lerer",
        "Adam P. Goucher",
        "Adam Perelman",
        "Aditya Ramesh",
        "Aidan Clark",
        "AJ Ostrow",
        "Akila Welihinda",
        "Alan Hayes",
        "Alec Radford",
        "Aleksander Mądry",
        "Alex Baker-Whitcomb",
        "Alex Beutel",
        "Alex Borzunov",
        "Alex Carney",
        "Alex Chow",
        "Alex Kirillov",
        "Alex Nichol",
        "Alex Paino",
        "Alex Renzin",
        "Alex Tachard Passos",
        "Alexander Kirillov",
        "Alexi Christakis",
        "Alexis Conneau",
        "Ali Kamali",
        "Allan Jabri",
        "Allison Moyer",
        "Allison Tam",
        "Amadou Crookes",
        "Amin Tootoochian",
        "Amin Tootoonchian",
        "Ananya Kumar",
        "Andrea Vallone",
        "Andrej Karpathy",
        "Andrew Braunstein",
        "Andrew Cann",
        "Andrew Codispoti",
        "Andrew Galu",
        "Andrew Kondrich",
        "Andrew Tulloch",
        "Andrey Mishchenko",
        "Angela Baek",
        "Angela Jiang",
        "Antoine Pelisse",
        "Antonia Woodford",
        "Anuj Gosalia",
        "Arka Dhar",
        "Ashley Pantuliano",
        "Avi Nayak",
        "Avital Oliver",
        "Barret Zoph",
        "Behrooz Ghorbani",
        "Ben Leimberger",
        "Ben Rossen",
        "Ben Sokolowsky",
        "Ben Wang",
        "Benjamin Zweig",
        "Beth Hoover",
        "Blake Samic",
        "Bob McGrew",
        "Bobby Spero",
        "Bogo Giertler",
        "Bowen Cheng",
        "Brad Lightcap",
        "Brandon Walkin",
        "Brendan Quinn",
        "Brian Guarraci",
        "Brian Hsu",
        "Bright Kellogg",
        "Brydon Eastman",
        "Camillo Lugaresi",
        "Carroll Wainwright",
        "Cary Bassin",
        "Cary Hudson",
        "Casey Chu",
        "Chad Nelson",
        "Chak Li",
        "Chan Jun Shern",
        "Channing Conger",
        "Charlotte Barette",
        "Chelsea Voss",
        "Chen Ding",
        "Cheng Lu",
        "Chong Zhang",
        "Chris Beaumont",
        "Chris Hallacy",
        "Chris Koch",
        "Christian Gibson",
        "Christina Kim",
        "Christine Choi",
        "Christine McLeavey",
        "Christopher Hesse",
        "Claudia Fischer",
        "Clemens Winter",
        "Coley Czarnecki",
        "Colin Jarvis",
        "Colin Wei",
        "Constantin Koumouzelis",
        "Dane Sherburn",
        "Daniel Kappler",
        "Daniel Levin",
        "Daniel Levy",
        "David Carr",
        "David Farhi",
        "David Mely",
        "David Robinson",
        "David Sasaki",
        "Denny Jin",
        "Dev Valladares",
        "Dimitris Tsipras",
        "Doug Li",
        "Duc Phong Nguyen",
        "Duncan Findlay",
        "Edede Oiwoh",
        "Edmund Wong",
        "Ehsan Asdar",
        "Elizabeth Proehl",
        "Elizabeth Yang",
        "Eric Antonow",
        "Eric Kramer",
        "Eric Peterson",
        "Eric Sigler",
        "Eric Wallace",
        "Eugene Brevdo",
        "Evan Mays",
        "Farzad Khorasani",
        "Felipe Petroski Such",
        "Filippo Raso",
        "Francis Zhang",
        "Fred von Lohmann",
        "Freddie Sulit",
        "Gabriel Goh",
        "Gene Oden",
        "Geoff Salmon",
        "Giulio Starace",
        "Greg Brockman",
        "Hadi Salman",
        "Haiming Bao",
        "Haitang Hu",
        "Hannah Wong",
        "Haoyu Wang",
        "Heather Schmidt",
        "Heather Whitney",
        "Heewoo Jun",
        "Hendrik Kirchner",
        "Henrique Ponde de Oliveira Pinto",
        "Hongyu Ren",
        "Huiwen Chang",
        "Hyung Won Chung",
        "Ian Kivlichan",
        "Ian O'Connell",
        "Ian O'Connell",
        "Ian Osband",
        "Ian Silber",
        "Ian Sohl",
        "Ibrahim Okuyucu",
        "Ikai Lan",
        "Ilya Kostrikov",
        "Ilya Sutskever",
        "Ingmar Kanitscheider",
        "Ishaan Gulrajani",
        "Jacob Coxon",
        "Jacob Menick",
        "Jakub Pachocki",
        "James Aung",
        "James Betker",
        "James Crooks",
        "James Lennon",
        "Jamie Kiros",
        "Jan Leike",
        "Jane Park",
        "Jason Kwon",
        "Jason Phang",
        "Jason Teplitz",
        "Jason Wei",
        "Jason Wolfe",
        "Jay Chen",
        "Jeff Harris",
        "Jenia Varavva",
        "Jessica Gan Lee",
        "Jessica Shieh",
        "Ji Lin",
        "Jiahui Yu",
        "Jiayi Weng",
        "Jie Tang",
        "Jieqi Yu",
        "Joanne Jang",
        "Joaquin Quinonero Candela",
        "Joe Beutler",
        "Joe Landers",
        "Joel Parish",
        "Johannes Heidecke",
        "John Schulman",
        "Jonathan Lachman",
        "Jonathan McKay",
        "Jonathan Uesato",
        "Jonathan Ward",
        "Jong Wook Kim",
        "Joost Huizinga",
        "Jordan Sitkin",
        "Jos Kraaijeveld",
        "Josh Gross",
        "Josh Kaplan",
        "Josh Snyder",
        "Joshua Achiam",
        "Joy Jiao",
        "Joyce Lee",
        "Juntang Zhuang",
        "Justyn Harriman",
        "Kai Fricke",
        "Kai Hayashi",
        "Karan Singhal",
        "Katy Shi",
        "Kavin Karthik",
        "Kayla Wood",
        "Kendra Rimbach",
        "Kenny Hsu",
        "Kenny Nguyen",
        "Keren Gu-Lemberg",
        "Kevin Button",
        "Kevin Liu",
        "Kiel Howe",
        "Krithika Muthukumar",
        "Kyle Luther",
        "Lama Ahmad",
        "Larry Kai",
        "Lauren Itow",
        "Lauren Workman",
        "Leher Pathak",
        "Leo Chen",
        "Li Jing",
        "Lia Guy",
        "Liam Fedus",
        "Liang Zhou",
        "Lien Mamitsuka",
        "Lilian Weng",
        "Lindsay McCallum",
        "Lindsey Held",
        "Long Ouyang",
        "Louis Feuvrier",
        "Lu Zhang",
        "Lukas Kondraciuk",
        "Lukasz Kaiser",
        "Luke Hewitt",
        "Luke Metz",
        "Lyric Doshi",
        "Mada Aflak",
        "Maddie Simens",
        "Madelaine Boyd",
        "Madeleine Thompson",
        "Marat Dukhan",
        "Mark Chen",
        "Mark Gray",
        "Mark Hudnall",
        "Marvin Zhang",
        "Marwan Aljubeh",
        "Mateusz Litwin",
        "Matthew Zeng",
        "Max Johnson",
        "Maya Shetty",
        "Mayank Gupta",
        "Meghan Shah",
        "Mehmet Yatbaz",
        "Meng Jia Yang",
        "Mengchao Zhong",
        "Mia Glaese",
        "Mianna Chen",
        "Michael Janner",
        "Michael Lampe",
        "Michael Petrov",
        "Michael Wu",
        "Michele Wang",
        "Michelle Fradin",
        "Michelle Pokrass",
        "Miguel Castro",
        "Miguel Oom Temudo de Castro",
        "Mikhail Pavlov",
        "Miles Brundage",
        "Miles Wang",
        "Minal Khan",
        "Mira Murati",
        "Mo Bavarian",
        "Molly Lin",
        "Murat Yesildal",
        "Nacho Soto",
        "Natalia Gimelshein",
        "Natalie Cone",
        "Natalie Staudacher",
        "Natalie Summers",
        "Natan LaFontaine",
        "Neil Chowdhury",
        "Nick Ryder",
        "Nick Stathas",
        "Nick Turley",
        "Nik Tezak",
        "Niko Felix",
        "Nithanth Kudige",
        "Nitish Keskar",
        "Noah Deutsch",
        "Noel Bundick",
        "Nora Puckett",
        "Ofir Nachum",
        "Ola Okelola",
        "Oleg Boiko",
        "Oleg Murk",
        "Oliver Jaffe",
        "Olivia Watkins",
        "Olivier Godement",
        "Owen Campbell-Moore",
        "Patrick Chao",
        "Paul McMillan",
        "Pavel Belov",
        "Peng Su",
        "Peter Bak",
        "Peter Bakkum",
        "Peter Deng",
        "Peter Dolan",
        "Peter Hoeschele",
        "Peter Welinder",
        "Phil Tillet",
        "Philip Pronin",
        "Philippe Tillet",
        "Prafulla Dhariwal",
        "Qiming Yuan",
        "Rachel Dias",
        "Rachel Lim",
        "Rahul Arora",
        "Rajan Troll",
        "Randall Lin",
        "Rapha Gontijo Lopes",
        "Raul Puri",
        "Reah Miyara",
        "Reimar Leike",
        "Renaud Gaubert",
        "Reza Zamani",
        "Ricky Wang",
        "Rob Donnelly",
        "Rob Honsby",
        "Rocky Smith",
        "Rohan Sahai",
        "Rohit Ramchandani",
        "Romain Huet",
        "Rory Carmichael",
        "Rowan Zellers",
        "Roy Chen",
        "Ruby Chen",
        "Ruslan Nigmatullin",
        "Ryan Cheu",
        "Saachi Jain",
        "Sam Altman",
        "Sam Schoenholz",
        "Sam Toizer",
        "Samuel Miserendino",
        "Sandhini Agarwal",
        "Sara Culver",
        "Scott Ethersmith",
        "Scott Gray",
        "Sean Grove",
        "Sean Metzger",
        "Shamez Hermani",
        "Shantanu Jain",
        "Shengjia Zhao",
        "Sherwin Wu",
        "Shino Jomoto",
        "Shirong Wu",
        "Shuaiqi",
        "Xia",
        "Sonia Phene",
        "Spencer Papay",
        "Srinivas Narayanan",
        "Steve Coffey",
        "Steve Lee",
        "Stewart Hall",
        "Suchir Balaji",
        "Tal Broda",
        "Tal Stramer",
        "Tao Xu",
        "Tarun Gogineni",
        "Taya Christianson",
        "Ted Sanders",
        "Tejal Patwardhan",
        "Thomas Cunninghman",
        "Thomas Degry",
        "Thomas Dimson",
        "Thomas Raoux",
        "Thomas Shadwell",
        "Tianhao Zheng",
        "Todd Underwood",
        "Todor Markov",
        "Toki Sherbakov",
        "Tom Rubin",
        "Tom Stasi",
        "Tomer Kaftan",
        "Tristan Heywood",
        "Troy Peterson",
        "Tyce Walters",
        "Tyna Eloundou",
        "Valerie Qi",
        "Veit Moeller",
        "Vinnie Monaco",
        "Vishal Kuo",
        "Vlad Fomenko",
        "Wayne Chang",
        "Weiyi Zheng",
        "Wenda Zhou",
        "Wesam Manassra",
        "Will Sheu",
        "Wojciech Zaremba",
        "Yash Patil",
        "Yilei Qian",
        "Yongjik Kim",
        "Youlong Cheng",
        "Yu Zhang",
        "Yuchen He",
        "Yuchen Zhang",
        "Yujia Jin",
        "Yunxing Dai",
        "Yury Malkov"
      ],
      "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination\nof text, audio, image, and video, and generates any combination of text, audio,\nand image outputs. It's trained end-to-end across text, vision, and audio,\nmeaning all inputs and outputs are processed by the same neural network. GPT-4o\ncan respond to audio inputs in as little as 232 milliseconds, with an average\nof 320 milliseconds, which is similar to human response time in conversation.\nIt matches GPT-4 Turbo performance on text in English and code, with\nsignificant improvement on text in non-English languages, while also being much\nfaster and 50\\% cheaper in the API. GPT-4o is especially better at vision and\naudio understanding compared to existing models. In line with our commitment to\nbuilding AI safely and consistent with our voluntary commitments to the White\nHouse, we are sharing the GPT-4o System Card, which includes our Preparedness\nFramework evaluations. In this System Card, we provide a detailed look at\nGPT-4o's capabilities, limitations, and safety evaluations across multiple\ncategories, focusing on speech-to-speech while also evaluating text and image\ncapabilities, and measures we've implemented to ensure the model is safe and\naligned. We also include third-party assessments on dangerous capabilities, as\nwell as discussion of potential societal impacts of GPT-4o's text and vision\ncapabilities.",
      "tldr_zh": "GPT-4o 是一个 autoregressive omni model，能够处理文本、音频、图像和视频的任意组合输入，并生成文本、音频和图像输出，通过端到端训练实现跨模态处理。相比 GPT-4 Turbo，它在英语和代码文本上性能相当，但在非英语语言、视觉和音频理解上显著提升，同时响应速度更快（平均320毫秒），API 调用成本降低50%。该系统卡详细评估了 GPT-4o 的能力、局限性和安全措施，包括 Preparedness Framework 和第三方评估，聚焦语音到语音功能，并讨论了潜在的社会影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21276v1",
      "published_date": "2024-10-25 17:43:01 UTC",
      "updated_date": "2024-10-25 17:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:30:09.242605"
    },
    {
      "arxiv_id": "2410.19718v1",
      "title": "Evolving Neural Networks Reveal Emergent Collective Behavior from Minimal Agent Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Guilherme S. Y. Giardini",
        "John F. Hardy II",
        "Carlo R. da Cunha"
      ],
      "abstract": "Understanding the mechanisms behind emergent behaviors in multi-agent systems\nis critical for advancing fields such as swarm robotics and artificial\nintelligence. In this study, we investigate how neural networks evolve to\ncontrol agents' behavior in a dynamic environment, focusing on the relationship\nbetween the network's complexity and collective behavior patterns. By\nperforming quantitative and qualitative analyses, we demonstrate that the\ndegree of network non-linearity correlates with the complexity of emergent\nbehaviors. Simpler behaviors, such as lane formation and laminar flow, are\ncharacterized by more linear network operations, while complex behaviors like\nswarming and flocking show highly non-linear neural processing. Moreover,\nspecific environmental parameters, such as moderate noise, broader field of\nview, and lower agent density, promote the evolution of non-linear networks\nthat drive richer, more intricate collective behaviors. These results highlight\nthe importance of tuning evolutionary conditions to induce desired behaviors in\nmulti-agent systems, offering new pathways for optimizing coordination in\nautonomous swarms. Our findings contribute to a deeper understanding of how\nneural mechanisms influence collective dynamics, with implications for the\ndesign of intelligent, self-organizing systems.",
      "tldr_zh": "本研究探讨神经网络(neural networks)在多智能体系统(multi-agent systems)中演化如何从最小代理互动中产生涌现集体行为(emergent collective behavior)，并分析网络复杂度和行为模式的关系。研究通过定量和定性分析发现，网络非线性程度与行为复杂性正相关：简单行为如车道形成(lane formation)和层流(laminar flow)主要依赖线性操作，而复杂行为如群聚(swarming)和成群飞行(flocking)则涉及高度非线性处理。此外，特定环境参数如适度噪声、更大视野和更低代理密度能促进非线性网络的演化，从而诱导更丰富的集体行为，为优化自主群系统和智能自组织系统的设计提供新途径。",
      "categories": [
        "nlin.AO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "nlin.AO",
      "comment": "25 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19718v1",
      "published_date": "2024-10-25 17:43:00 UTC",
      "updated_date": "2024-10-25 17:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:30:22.441715"
    },
    {
      "arxiv_id": "2410.19715v2",
      "title": "Adversarial Environment Design via Regret-Guided Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hojun Chung",
        "Junseo Lee",
        "Minsoo Kim",
        "Dohyeong Kim",
        "Songhwai Oh"
      ],
      "abstract": "Training agents that are robust to environmental changes remains a\nsignificant challenge in deep reinforcement learning (RL). Unsupervised\nenvironment design (UED) has recently emerged to address this issue by\ngenerating a set of training environments tailored to the agent's capabilities.\nWhile prior works demonstrate that UED has the potential to learn a robust\npolicy, their performance is constrained by the capabilities of the environment\ngeneration. To this end, we propose a novel UED algorithm, adversarial\nenvironment design via regret-guided diffusion models (ADD). The proposed\nmethod guides the diffusion-based environment generator with the regret of the\nagent to produce environments that the agent finds challenging but conducive to\nfurther improvement. By exploiting the representation power of diffusion\nmodels, ADD can directly generate adversarial environments while maintaining\nthe diversity of training environments, enabling the agent to effectively learn\na robust policy. Our experimental results demonstrate that the proposed method\nsuccessfully generates an instructive curriculum of environments, outperforming\nUED baselines in zero-shot generalization across novel, out-of-distribution\nenvironments. Project page: https://rllab-snu.github.io/projects/ADD",
      "tldr_zh": "该研究针对深度强化学习（RL）中训练对环境变化鲁棒的代理这一挑战，提出了一种新型无监督环境设计（UED）算法：基于遗憾引导的扩散模型的对抗环境设计（Adversarial Environment Design via Regret-Guided Diffusion Models，ADD）。ADD 通过代理的遗憾值指导扩散模型生成具有挑战性但有助于改进的环境，从而保持训练环境的多样性和教育性。实验结果显示，该方法在零样本泛化任务中优于UED基线，能够在分布外的新环境中有效提升代理的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Conference on Neural Information Processing Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.19715v2",
      "published_date": "2024-10-25 17:35:03 UTC",
      "updated_date": "2024-11-15 01:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:32:44.843557"
    },
    {
      "arxiv_id": "2410.19704v3",
      "title": "Multi-view biomedical foundation models for molecule-target and property prediction",
      "title_zh": "多视图生物医学基础模型用于分子-靶点和属性预测",
      "authors": [
        "Parthasarathy Suryanarayanan",
        "Yunguang Qiu",
        "Shreyans Sethi",
        "Diwakar Mahajan",
        "Hongyang Li",
        "Yuxin Yang",
        "Elif Eyigoz",
        "Aldo Guzman Saenz",
        "Daniel E. Platt",
        "Timothy H. Rumbell",
        "Kenney Ng",
        "Sanjoy Dey",
        "Myson Burch",
        "Bum Chul Kwon",
        "Pablo Meyer",
        "Feixiong Cheng",
        "Jianying Hu",
        "Joseph A. Morrone"
      ],
      "abstract": "Foundation models applied to bio-molecular space hold promise to accelerate\ndrug discovery. Molecular representation is key to building such models.\nPrevious works have typically focused on a single representation or view of the\nmolecules. Here, we develop a multi-view foundation model approach, that\nintegrates molecular views of graph, image and text. Single-view foundation\nmodels are each pre-trained on a dataset of up to 200M molecules and then\naggregated into combined representations. Our multi-view model is validated on\na diverse set of 18 tasks, encompassing ligand-protein binding, molecular\nsolubility, metabolism and toxicity. We show that the multi-view models perform\nrobustly and are able to balance the strengths and weaknesses of specific\nviews. We then apply this model to screen compounds against a large (>100\ntargets) set of G Protein-Coupled receptors (GPCRs). From this library of\ntargets, we identify 33 that are related to Alzheimer's disease. On this\nsubset, we employ our model to identify strong binders, which are validated\nthrough structure-based modeling and identification of key binding motifs.",
      "tldr_zh": "本文提出了一种多视图生物医学基础模型，整合分子图、图像和文本三种视图，每个单视图模型在高达2亿分子的数据集上预训练后聚合表示，以提升分子目标预测和属性预测的准确性。该模型在18个任务上（如配体-蛋白质结合、分子溶解度、代谢和毒性）表现出色，能平衡不同视图的优缺点。应用该模型筛选G Protein-Coupled receptors (GPCRs)化合物库，成功识别出与阿尔茨海默病相关的33个目标的强结合物，并通过结构建模和关键结合基序验证其有效性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "37 pages including supplement. 10 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19704v3",
      "published_date": "2024-10-25 17:22:33 UTC",
      "updated_date": "2025-01-31 19:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:30:57.934010"
    },
    {
      "arxiv_id": "2410.19702v2",
      "title": "TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Zeng",
        "Kunchang Li",
        "Chenting Wang",
        "Xinhao Li",
        "Tianxiang Jiang",
        "Ziang Yan",
        "Songze Li",
        "Yansong Shi",
        "Zhengrong Yue",
        "Yi Wang",
        "Yali Wang",
        "Yu Qiao",
        "Limin Wang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\nperformance in short video understanding. However, understanding long-form\nvideos still remains challenging for MLLMs. This paper proposes TimeSuite, a\ncollection of new designs to adapt the existing short-form video MLLMs for long\nvideo understanding, including a simple yet efficient framework to process long\nvideo sequence, a high-quality video dataset for grounded tuning of MLLMs, and\na carefully-designed instruction tuning task to explicitly incorporate the\ngrounding supervision in the traditional QA format. Specifically, based on\nVideoChat, we propose our long-video MLLM, coined as VideoChat-T, by\nimplementing a token shuffling to compress long video tokens and introducing\nTemporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of\nvisual representation. Meanwhile, we introduce the TimePro, a comprehensive\ngrounding-centric instruction tuning dataset composed of 9 tasks and 349k\nhigh-quality grounded annotations. Notably, we design a new instruction tuning\ntask type, called Temporal Grounded Caption, to peform detailed video\ndescriptions with the corresponding time stamps prediction. This explicit\ntemporal location prediction will guide MLLM to correctly attend on the visual\ncontent when generating description, and thus reduce the hallucination risk\ncaused by the LLMs. Experimental results demonstrate that our TimeSuite\nprovides a successful solution to enhance the long video understanding\ncapability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the\nbenchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T\nexhibits robust zero-shot temporal grounding capabilities, significantly\noutperforming the existing state-of-the-art MLLMs. After fine-tuning, it\nperforms on par with the traditional supervised expert models.",
      "tldr_zh": "该论文提出 TimeSuite，一种通过 grounded tuning 提升 Multimodal Large Language Models (MLLMs) 在长视频理解能力的框架，包括一个高效处理长视频序列的机制（使用 token shuffling 压缩视频 tokens 和 Temporal Adaptive Position Encoding (TAPE) 增强时间感知）。为了支持训练，作者构建了高质量数据集 TimePro，包含 9 个任务和 349k 标注，并设计了新指令调优任务 Temporal Grounded Caption，以预测时间戳并减少模型幻觉。实验结果显示，基于 VideoChat 的 VideoChat-T 模型在 Egoschema 和 VideoMME 基准上分别提高了 5.6% 和 6.8%，并在零样本时间 grounding 上优于现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.19702v2",
      "published_date": "2024-10-25 17:19:55 UTC",
      "updated_date": "2025-02-12 16:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:31:10.402931"
    },
    {
      "arxiv_id": "2410.19701v1",
      "title": "Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery",
      "title_zh": "提升旅行预订系统的弹性和可伸缩性：一种微服务方法用于",
      "authors": [
        "Biman Barua",
        "M. Shamim Kaiser"
      ],
      "abstract": "This paper investigates the inclusion of microservices architecture in the\ndevelopment of scalable and reliable airline reservation systems. Most of the\ntraditional reservation systems are very rigid and centralized which makes them\nprone to bottlenecks and a single point of failure. As such, systems do not\nmeet the requirements of modern airlines which are dynamic. Microservices offer\nbetter resiliency and scalability because the services do not depend on one\nanother and can be deployed independently. The approach is grounded on the\nCircuit Breaker Pattern to maintain fault tolerance while consuming foreign\nresources such as flight APIs and payment systems. This avoided the failure\npropagation to the systems by 60% enabling the systems to function under\nexternal failures. Traffic rerouting also bolstered this with a guarantee of\nabove 99.95% uptime in systems where high availability was demanded. To address\nthis, load balancing was used, particularly the Round-Robin method which\nmanaged to enhance performance by 35% through the equal distribution of user\nrequests among the service instances. Health checks, as well as monitoring in\nreal-time, helped as well with failure management as they helped to contain\nfailures before the users of the system were affected. The results suggest that\nthe use of microservices led to a 40% increase in system scalability, a 50%\ndecrease in downtime and a support for 30% more concurrent users than the use\nof monolithic architectures. These findings affirm the capability of\nmicroservices in the development of robust and flexible airline ticket booking\nsystems that are responsive to change and recover from external system\nunavailability.",
      "tldr_zh": "这篇论文探讨了在航空预订系统中采用Microservices架构，以提升系统的韧性和可伸缩性，解决传统集中式系统的瓶颈和单点故障问题。方法包括使用Circuit Breaker Pattern来提高容错性、减少失败传播60%，以及Round-Robin负载均衡来优化性能，提升35%的请求处理效率，同时结合流量重定向、健康检查和实时监控确保99.95%以上的可用性。实验结果显示，Microservices导致系统可伸缩性提高40%、停机时间减少50%，并支持30%更多并发用户，证明了其在构建鲁棒灵活的订票系统中的显著优势。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19701v1",
      "published_date": "2024-10-25 17:19:42 UTC",
      "updated_date": "2024-10-25 17:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:32:31.956764"
    },
    {
      "arxiv_id": "2410.19697v1",
      "title": "IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation",
      "title_zh": "IPPON：基于常识引导的信息性路径规划，用于对象目标导航",
      "authors": [
        "Kaixian Qu",
        "Jie Tan",
        "Tingnan Zhang",
        "Fei Xia",
        "Cesar Cadena",
        "Marco Hutter"
      ],
      "abstract": "Navigating efficiently to an object in an unexplored environment is a\ncritical skill for general-purpose intelligent robots. Recent approaches to\nthis object goal navigation problem have embraced a modular strategy,\nintegrating classical exploration algorithms-notably frontier exploration-with\na learned semantic mapping/exploration module. This paper introduces a novel\ninformative path planning and 3D object probability mapping approach. The\nmapping module computes the probability of the object of interest through\nsemantic segmentation and a Bayes filter. Additionally, it stores probabilities\nfor common objects, which semantically guides the exploration based on common\nsense priors from a large language model. The planner terminates when the\ncurrent viewpoint captures enough voxels identified with high confidence as the\nobject of interest. Although our planner follows a zero-shot approach, it\nachieves state-of-the-art performance as measured by the Success weighted by\nPath Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023,\noutperforming other works by more than 20%. Furthermore, we validate its\neffectiveness on real robots. Project webpage: https://ippon-paper.github.io/",
      "tldr_zh": "该论文提出IPPON，一种基于常识指导的信息路径规划方法，用于机器人实现物体目标导航（Object Goal Navigation），通过语义分割（Semantic Segmentation）和Bayes过滤器计算目标物体的3D概率映射，并利用大型语言模型（Large Language Model）的常识先验来优化探索路径。IPPON采用零样本（Zero-Shot）策略，当当前视角捕获到高置信度的目标体素时终止规划，从而提升导航效率。实验结果显示，该方法在Habitat ObjectNav Challenge 2023中取得了最先进性能，SPL（Success weighted by Path Length）和Soft SPL指标比其他方法高出20%以上，并在真实机器人上验证了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19697v1",
      "published_date": "2024-10-25 17:11:33 UTC",
      "updated_date": "2024-10-25 17:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:31:33.860671"
    },
    {
      "arxiv_id": "2410.19694v1",
      "title": "Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Zhang",
        "Hao Zhu",
        "Aiwei Liu",
        "Han Yu",
        "Piotr Koniusz",
        "Irwin King"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) has become a crucial technique for\nadapting pre-trained models to downstream tasks. However, the enormous size of\nLLMs poses significant challenges in terms of computational complexity and\nresource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising\nsolution. However, there exists a gap between the practical performance of\nlow-rank adaptations and its theoretical optimum. In this work, we propose\neXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this\ngap by leveraging the power of ensemble learning. Inspired by gradient\nboosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations\nto refine model predictions. It achieves better performance than the standard\nLoRA, while enjoying the computational efficiency of rank-1 adaptations. We\nprovide theoretical analysis to show the convergence and optimality of our\napproach, and conduct extensive experiments on a range of natural language\nprocessing tasks. The results demonstrate that XGBLoRA consistently outperforms\nstandard LoRA and achieves performance comparable to full fine-tuning with\nsignificantly fewer trainable parameters. This work advances\nparameter-efficient fine-tuning for LLMs, and offers a promising solution for\nadapting LLMs to downstream tasks while optimizing performance and efficiency.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 微调的计算复杂性和资源需求问题，提出了一种高效框架 eXtreme Gradient Boosting LoRA (XGBLoRA)。XGBLoRA 通过借鉴梯度提升算法，迭代学习并合并一系列 rank-1 Low-Rank Adaptation (LoRA) 适配，从而提升模型性能，同时保持计算效率。相比标准 LoRA，该方法在各种自然语言处理任务上表现出色，实现了与全微调相当的性能，但仅需更少的训练参数。论文还提供了理论分析，证明了 XGBLoRA 的收敛性和最优性，为参数高效的 LLMs 微调提供了重要进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19694v1",
      "published_date": "2024-10-25 17:07:13 UTC",
      "updated_date": "2024-10-25 17:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:31:45.718685"
    },
    {
      "arxiv_id": "2410.19693v1",
      "title": "MILES: Making Imitation Learning Easy with Self-Supervision",
      "title_zh": "MILES：通过自监督使模仿学习",
      "authors": [
        "Georgios Papagiannis",
        "Edward Johns"
      ],
      "abstract": "Data collection in imitation learning often requires significant, laborious\nhuman supervision, such as numerous demonstrations, and/or frequent environment\nresets for methods that incorporate reinforcement learning. In this work, we\npropose an alternative approach, MILES: a fully autonomous, self-supervised\ndata collection paradigm, and we show that this enables efficient policy\nlearning from just a single demonstration and a single environment reset. MILES\nautonomously learns a policy for returning to and then following the single\ndemonstration, whilst being self-guided during data collection, eliminating the\nneed for additional human interventions. We evaluated MILES across several\nreal-world tasks, including tasks that require precise contact-rich\nmanipulation such as locking a lock with a key. We found that, under the\nconstraints of a single demonstration and no repeated environment resetting,\nMILES significantly outperforms state-of-the-art alternatives like imitation\nlearning methods that leverage reinforcement learning. Videos of our\nexperiments and code can be found on our webpage: www.robot-learning.uk/miles.",
      "tldr_zh": "这篇论文提出了MILES，一种基于自监督的自治数据收集方法，用于简化模仿学习（Imitation Learning），它仅需一个演示和一个环境重置即可高效学习策略。MILES通过自主学习返回并跟随演示路径，并在数据收集过程中自我引导，消除了额外人类干预的需求。在真实世界任务（如精确接触操作的锁锁任务）上评估显示，MILES在单一演示和无重复重置的约束下，显著优于结合Reinforcement Learning的现有方法。实验结果证明了其有效性，并提供了相关代码和视频支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at the Conference on Robot Learning (CoRL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19693v1",
      "published_date": "2024-10-25 17:06:50 UTC",
      "updated_date": "2024-10-25 17:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:31:56.990930"
    },
    {
      "arxiv_id": "2410.19692v1",
      "title": "AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Clemencia Siro",
        "Yifei Yuan",
        "Mohammad Aliannejadi",
        "Maarten de Rijke"
      ],
      "abstract": "Generating diverse and effective clarifying questions is crucial for\nimproving query understanding and retrieval performance in open-domain\nconversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration,\nand evaluaTion of Clarifying Questions), an end-to-end LLM-based framework\naddressing the challenges of scalability and adaptability faced by existing\nmethods that rely on manual curation or template-based approaches. AGENT-CQ\nconsists of two stages: a generation stage employing LLM prompting strategies\nto generate clarifying questions, and an evaluation stage (CrowdLLM) that\nsimulates human crowdsourcing judgments using multiple LLM instances to assess\ngenerated questions and answers based on comprehensive quality metrics.\nExtensive experiments on the ClariQ dataset demonstrate CrowdLLM's\neffectiveness in evaluating question and answer quality. Human evaluation and\nCrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms\nbaselines in various aspects of question and answer quality. In retrieval-based\nevaluation, LLM-generated questions significantly enhance retrieval\neffectiveness for both BM25 and cross-encoder models compared to\nhuman-generated questions.",
      "tldr_zh": "本研究提出 AGENT-CQ，一种基于 LLMs 的端到端框架，用于自动生成和评估对话搜索中的澄清问题，以提升查询理解和检索性能。框架包括生成阶段，利用 LLM 提示策略创建高质量澄清问题，以及评估阶段（CrowdLLM），通过多个 LLM 实例模拟人类判断并基于全面质量指标评估问题和答案。在 ClariQ 数据集上的实验显示，AGENT-CQ 生成的澄清问题在质量和检索效果上优于基线模型，包括显著提升 BM25 和跨编码器模型的检索性能，甚至超越人类生成的问题。总的来说，该框架解决了现有手动或模板方法的局限性，提高了对话搜索系统的可扩展性和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19692v1",
      "published_date": "2024-10-25 17:06:27 UTC",
      "updated_date": "2024-10-25 17:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:32:09.716131"
    },
    {
      "arxiv_id": "2411.10448v3",
      "title": "Goetterfunke: Creativity in Machinae Sapiens. About the Qualitative Shift in Generative AI with a Focus on Text-To-Image",
      "title_zh": "翻译失败",
      "authors": [
        "Jens Knappe"
      ],
      "abstract": "The year 2022 marks a watershed in technology, and arguably in human history,\nwith the release of powerful generative AIs capable of convincingly performing\ncreative tasks. With the help of these systems, anyone can create something\nthat would previously have been considered a remarkable work of art. In\nhuman-AI collaboration, the computer seems to have become more than a tool.\nMany who have made their first contact with current generative AIs see them as\n\"creativity machines\" while for others the term \"machine creativity\" remains an\noxymoron. This article is about (the possibility of) creativity in computers\nwithin the current Machine Learning paradigm. It outlines some of the key\nconcepts behind the technologies and the innovations that have contributed to\nthis qualitative shift, with a focus on text-to-image systems. The nature of\nArtificial Creativity as such is discussed, as well as what this might mean for\nart. AI may become a responsible collaborator with elements of independent\nmachine authorship in the artistic process.",
      "tldr_zh": "该论文探讨了2022年生成式AI（Generative AI）的质变里程碑，焦点在于文本到图像（Text-To-Image）系统，这些AI能够执行创造性任务，使任何人能生成艺术杰作。文章概述了机器学习（Machine Learning）范式下AI的关键概念和技术创新，分析了“机器创造力”（Machine Creativity）的可能性及其对艺术的意义。最终，作者认为AI可能成为艺术过程中的负责任合作者，具有独立机器作者（Machine Authorship）的元素。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "3 figures (images), 33 pages typo, minor layout and text format\n  issues fixed",
      "pdf_url": "http://arxiv.org/pdf/2411.10448v3",
      "published_date": "2024-10-25 16:04:11 UTC",
      "updated_date": "2024-12-11 23:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:34:21.032730"
    },
    {
      "arxiv_id": "2410.21311v1",
      "title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding",
      "title_zh": "MMDocBench：细粒度视觉文档理解的大型视觉语言模型基准测试",
      "authors": [
        "Fengbin Zhu",
        "Ziyang Liu",
        "Xiang Yao Ng",
        "Haohui Wu",
        "Wenjie Wang",
        "Fuli Feng",
        "Chao Wang",
        "Huanbo Luan",
        "Tat Seng Chua"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in\nmany vision-language tasks, yet their capabilities in fine-grained visual\nunderstanding remain insufficiently evaluated. Existing benchmarks either\ncontain limited fine-grained evaluation samples that are mixed with other data,\nor are confined to object-level assessments in natural images. To holistically\nassess LVLMs' fine-grained visual understanding capabilities, we propose using\ndocument images with multi-granularity and multi-modal information to\nsupplement natural images. In this light, we construct MMDocBench, a benchmark\nwith various OCR-free document understanding tasks for the evaluation of\nfine-grained visual perception and reasoning abilities. MMDocBench defines 15\nmain tasks with 4,338 QA pairs and 11,353 supporting regions, covering various\ndocument images such as research papers, receipts, financial reports, Wikipedia\ntables, charts, and infographics. Based on MMDocBench, we conduct extensive\nexperiments using 13 open-source and 3 proprietary advanced LVLMs, assessing\ntheir strengths and weaknesses across different tasks and document image types.\nThe benchmark, task instructions, and evaluation code will be made publicly\navailable.",
      "tldr_zh": "这篇论文针对 Large Vision-Language Models (LVLMs) 在细粒度视觉理解方面的不足，提出了 MMDocBench 基准，用于全面评估其视觉感知和推理能力。MMDocBench 利用文档图像（包括多粒度和多模态信息）补充自然图像，定义了 15 个主要任务、4,338 个 QA 对和 11,353 个支持区域，涵盖研究论文、收据、金融报告、维基百科表格、图表和信息图等类型。通过实验评估了 13 个开源和 3 个专有 LVLMs 的表现，突出了它们在不同任务和文档类型中的优势与劣势。该基准、任务指令和评估代码将公开可用，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.21311v1",
      "published_date": "2024-10-25 16:00:55 UTC",
      "updated_date": "2024-10-25 16:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:32:34.048990"
    },
    {
      "arxiv_id": "2410.19646v2",
      "title": "Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek Singh",
        "Shikha Chaganti",
        "Matthias Siebert",
        "Sowmya Rajesh",
        "Andrei Puiu",
        "Raj Gopalan",
        "Jamie Gramz",
        "Dorin Comaniciu",
        "Ali Kamen"
      ],
      "abstract": "Early screening for cancer has proven to improve the survival rate and spare\npatients from intensive and costly treatments due to late diagnosis. Cancer\nscreening in the healthy population involves an initial risk stratification\nstep to determine the screening method and frequency, primarily to optimize\nresource allocation by targeting screening towards individuals who draw most\nbenefit. For most screening programs, age and clinical risk factors such as\nfamily history are part of the initial risk stratification algorithm. In this\npaper, we focus on developing a blood marker-based risk stratification\napproach, which could be used to identify patients with elevated cancer risk to\nbe encouraged for taking a diagnostic test or participate in a screening\nprogram. We demonstrate that the combination of simple, widely available blood\ntests, such as complete blood count and complete metabolic panel, could\npotentially be used to identify patients at risk for colorectal, liver, and\nlung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.\nFurthermore, we hypothesize that such an approach could not only be used as\npre-screening risk assessment for individuals but also as population health\nmanagement tool, for example to better interrogate the cancer risk in certain\nsub-populations.",
      "tldr_zh": "该研究利用深度学习（deep learning）分析常规实验室标记（如全血细胞计数和代谢面板），开发了一种血液标记物-based的风险分层方法，以识别结肠癌、肝癌和肺癌的高风险患者。结果显示，该方法在这些癌症的ROC曲线面积（AUC）分别为0.76、0.85和0.78，证明了其有效性。该方法不仅可用于个人预筛查风险评估，还能作为人群健康管理工具，帮助优化资源分配和针对特定亚群的癌症风险筛查。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19646v2",
      "published_date": "2024-10-25 15:50:27 UTC",
      "updated_date": "2025-01-06 02:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:34:32.410098"
    },
    {
      "arxiv_id": "2410.19643v3",
      "title": "Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolás Nieto",
        "Simon B. Eickhoff",
        "Christian Jung",
        "Martin Reuter",
        "Kersten Diers",
        "Malte Kelm",
        "Artur Lichtenberg",
        "Federico Raimondo",
        "Kaustubh R. Patil"
      ],
      "abstract": "Machine learning (ML) models benefit from large datasets. Collecting data in\nbiomedical domains is costly and challenging, hence, combining datasets has\nbecome a common practice. However, datasets obtained under different conditions\ncould present undesired site-specific variability. Data harmonization methods\naim to remove site-specific variance while retaining biologically relevant\ninformation. This study evaluates the effectiveness of popularly used\nComBat-based methods for harmonizing data in scenarios where the class balance\nis not equal across sites. We find that these methods struggle with data\nleakage issues. To overcome this problem, we propose a novel approach\nPrettYharmonize, designed to harmonize data by pretending the target labels. We\nvalidate our approach using controlled datasets designed to benchmark the\nutility of harmonization. Finally, using real-world MRI and clinical data, we\ncompare leakage-prone methods with PrettYharmonize and show that it achieves\ncomparable performance while avoiding data leakage, particularly in\nsite-target-dependence scenarios.",
      "tldr_zh": "本研究探讨了数据协调（Data Harmonization）在机器学习（ML）管道中的挑战，特别是当类别不平衡（Class Imbalance）跨站点时，常用ComBat-based方法会因数据泄露（Data Leakage）问题而表现不佳。研究者提出了一种新方法PrettYharmonize，通过“假装”目标标签来协调数据，从而有效避免泄露问题。实验使用控制数据集验证了该方法的实用性，并在真实世界的MRI和临床数据上比较显示，PrettYharmonize在性能上与易泄露方法相当，同时在站点-目标依赖场景中更具鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19643v3",
      "published_date": "2024-10-25 15:49:04 UTC",
      "updated_date": "2024-12-10 18:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:34:44.503142"
    },
    {
      "arxiv_id": "2410.19642v1",
      "title": "VARS: Vision-based Assessment of Risk in Security Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Gupta",
        "Pratham Gohil",
        "Sridhar S"
      ],
      "abstract": "The accurate prediction of danger levels in video content is critical for\nenhancing safety and security systems, particularly in environments where quick\nand reliable assessments are essential. In this study, we perform a comparative\nanalysis of various machine learning and deep learning models to predict danger\nratings in a custom dataset of 100 videos, each containing 50 frames, annotated\nwith human-rated danger scores ranging from 0 to 10. The danger ratings are\nfurther classified into three categories: no alert (less than 7)and high alert\n(greater than equal to 7). Our evaluation covers classical machine learning\nmodels, such as Support Vector Machines, as well as Neural Networks, and\ntransformer-based models. Model performance is assessed using standard metrics\nsuch as accuracy, F1-score, and mean absolute error (MAE), and the results are\ncompared to identify the most robust approach. This research contributes to\ndeveloping a more accurate and generalizable danger assessment framework for\nvideo-based risk detection.",
      "tldr_zh": "这篇论文介绍了 VARS 系统，一种基于视觉的安保系统风险评估方法，旨在通过准确预测视频内容中的危险水平来提升安全措施。研究比较了多种机器学习和深度学习模型，包括 Support Vector Machines、Neural Networks 和 transformer-based models，在一个自定义数据集上进行评估，该数据集包含 100 个视频（每视频 50 帧），并以 0-10 的危险分数手动标注，分类为 no alert（小于 7）和 high alert（大于等于 7）。通过使用 accuracy、F1-score 和 mean absolute error (MAE) 等指标，论文识别了最鲁棒的模型，并为视频风险检测提供了更准确和可推广的评估框架。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19642v1",
      "published_date": "2024-10-25 15:47:13 UTC",
      "updated_date": "2024-10-25 15:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:10.120793"
    },
    {
      "arxiv_id": "2410.19639v2",
      "title": "Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Yunhao",
        "Ding Hong",
        "Zhang Ziming",
        "Wang Huixin",
        "Liu Jinzhao",
        "Xi Suyang"
      ],
      "abstract": "Autonomous driving technology has seen significant advancements, but existing\nmodels often fail to fully capture the complexity of multi-agent environments,\nwhere interactions between dynamic agents are critical. To address this, we\npropose the Planning-Integrated Forecasting Model (PIFM), a novel framework\ninspired by neural mechanisms governing decision-making and multi-agent\ncoordination in the brain. PIFM leverages rich contextual information,\nintegrating road structures, traffic rules, and the behavior of surrounding\nvehicles to improve both the accuracy and interpretability of predictions. By\nadopting a diffusion-based architecture, akin to neural diffusion processes\ninvolved in predicting and planning, PIFM is able to forecast future\ntrajectories of all agents within a scenario. This architecture enhances model\ntransparency, as it parallels the brain's method of dynamically adjusting\npredictions based on external stimuli and other agents'behaviors. Extensive\nexperiments validate PIFM's capacity to provide interpretable,\nneuroscience-driven solutions for safer and more efficient autonomous driving\nsystems, with an extremely low number of parameters.",
      "tldr_zh": "该研究针对自动驾驶中多代理环境复杂性的挑战，提出了一种名为 Planning-Integrated Forecasting Model (PIFM) 的新框架，该框架受大脑决策和多代理协调神经机制启发。PIFM 通过整合道路结构、交通规则以及周围车辆行为等丰富上下文信息，并采用 diffusion-based architecture 来预测所有代理的未来轨迹，从而提升预测的准确性和可解释性。实验结果表明，PIFM 提供可解释的神经科学驱动解决方案，提高了自动驾驶系统的安全性和效率，同时保持参数数量极低。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The experimental verification section has some issues",
      "pdf_url": "http://arxiv.org/pdf/2410.19639v2",
      "published_date": "2024-10-25 15:44:51 UTC",
      "updated_date": "2024-11-04 07:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:08.715948"
    },
    {
      "arxiv_id": "2410.19627v2",
      "title": "Knowledge Graph Enhanced Language Agents for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Taicheng Guo",
        "Chaochun Liu",
        "Hai Wang",
        "Varun Mannam",
        "Fang Wang",
        "Xin Chen",
        "Xiangliang Zhang",
        "Chandan K. Reddy"
      ],
      "abstract": "Language agents have recently been used to simulate human behavior and\nuser-item interactions for recommendation systems. However, current language\nagent simulations do not understand the relationships between users and items,\nleading to inaccurate user profiles and ineffective recommendations. In this\nwork, we explore the utility of Knowledge Graphs (KGs), which contain extensive\nand reliable relationships between users and items, for recommendation. Our key\ninsight is that the paths in a KG can capture complex relationships between\nusers and items, eliciting the underlying reasons for user preferences and\nenriching user profiles. Leveraging this insight, we propose Knowledge Graph\nEnhanced Language Agents(KGLA), a framework that unifies language agents and KG\nfor recommendation systems. In the simulated recommendation scenario, we\nposition the user and item within the KG and integrate KG paths as natural\nlanguage descriptions into the simulation. This allows language agents to\ninteract with each other and discover sufficient rationale behind their\ninteractions, making the simulation more accurate and aligned with real-world\ncases, thus improving recommendation performance. Our experimental results show\nthat KGLA significantly improves recommendation performance (with a 33%-95%\nboost in NDCG@1 among three widely used benchmarks) compared to the previous\nbest baseline method.",
      "tldr_zh": "该研究发现，现有的语言代理（Language Agents）在模拟用户-物品交互时，无法理解用户和物品之间的关系，导致推荐系统用户画像不准确和性能低下。为解决此问题，作者提出 Knowledge Graph Enhanced Language Agents (KGLA) 框架，利用 Knowledge Graphs (KGs) 中的路径来捕捉复杂关系，并将其作为自然语言描述整合到模拟中，从而增强代理间的交互和推荐推理。实验结果显示，KGLA 在三个常用基准上显著提升推荐性能，NDCG@1 指标提升 33%-95%，为更准确的推荐系统提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19627v2",
      "published_date": "2024-10-25 15:25:36 UTC",
      "updated_date": "2025-01-24 20:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:21.785053"
    },
    {
      "arxiv_id": "2410.19612v2",
      "title": "Shared Control with Black Box Agents using Oracle Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Inbal Avraham",
        "Reuth Mirsky"
      ],
      "abstract": "Shared control problems involve a robot learning to collaborate with a human.\nWhen learning a shared control policy, short communication between the agents\ncan often significantly reduce running times and improve the system's accuracy.\nWe extend the shared control problem to include the ability to directly query a\ncooperating agent. We consider two types of potential responses to a query,\nnamely oracles: one that can provide the learner with the best action they\nshould take, even when that action might be myopically wrong, and one with a\nbounded knowledge limited to its part of the system. Given this additional\ninformation channel, this work further presents three heuristics for choosing\nwhen to query: reinforcement learning-based, utility-based, and entropy-based.\nThese heuristics aim to reduce a system's overall learning cost. Empirical\nresults on two environments show the benefits of querying to learn a better\ncontrol policy and the tradeoffs between the proposed heuristics.",
      "tldr_zh": "这篇论文扩展了共享控制(shared control)问题，允许机器人通过查询黑箱代理(black box agents)来提升协作效率，具体定义了两种查询响应类型(oracles): 一种提供最佳行动(即使短期错误)，另一种限于部分系统知识。作者提出了三种查询决策启发式: 基于强化学习的(reinforcement learning-based)、基于效用的(utility-based)和基于熵的(entropy-based)，旨在最小化整体学习成本。实验结果在两个环境中展示了查询机制能显著改善控制策略的学习效果，并揭示了这些启发式方法之间的权衡取舍。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the 2025 IEEE International Conference on\n  AI and Data Analytics (ICAD 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.19612v2",
      "published_date": "2024-10-25 15:04:37 UTC",
      "updated_date": "2025-02-21 14:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:32.908952"
    },
    {
      "arxiv_id": "2410.19609v1",
      "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang He",
        "Wenlin Yao",
        "Kaixin Ma",
        "Wenhao Yu",
        "Hongming Zhang",
        "Tianqing Fang",
        "Zhenzhong Lan",
        "Dong Yu"
      ],
      "abstract": "The rapid development of large language and multimodal models has sparked\nsignificant interest in using proprietary models, such as GPT-4o, to develop\nautonomous agents capable of handling real-world scenarios like web navigation.\nAlthough recent open-source efforts have tried to equip agents with the ability\nto explore environments and continuously improve over time, they are building\ntext-only agents in synthetic environments where the reward signals are clearly\ndefined. Such agents struggle to generalize to realistic settings that require\nmultimodal perception abilities and lack ground-truth signals. In this paper,\nwe introduce an open-source framework designed to facilitate the development of\nmultimodal web agent that can autonomously conduct real-world exploration and\nimprove itself. We first train the base model with imitation learning to gain\nthe basic abilities. We then let the agent explore the open web and collect\nfeedback on its trajectories. After that, it further improves its policy by\nlearning from well-performing trajectories judged by another general-purpose\nmodel. This exploration-feedback-optimization cycle can continue for several\niterations. Experimental results show that our web agent successfully improves\nitself after each iteration, demonstrating strong performance across multiple\ntest sets.",
      "tldr_zh": "本研究引入了 OpenWebVoyager 框架，旨在通过迭代的真实世界探索、反馈和优化来构建多模态网络代理，以处理如网络导航等现实场景。框架首先使用 imitation learning 训练基础模型，使其获得基本能力；随后，代理在开放网络中自主探索，收集轨迹反馈，并通过另一个通用模型评估性能好的轨迹来进一步优化策略。这个探索-反馈-优化循环可重复进行。实验结果表明，代理在每次迭代后均实现性能提升，并在多个测试集上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19609v1",
      "published_date": "2024-10-25 15:01:27 UTC",
      "updated_date": "2024-10-25 15:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:44.411943"
    },
    {
      "arxiv_id": "2410.19605v1",
      "title": "CoqPilot, a plugin for LLM-based generation of proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Kozyrev",
        "Gleb Solovev",
        "Nikita Khramov",
        "Anton Podkopaev"
      ],
      "abstract": "We present CoqPilot, a VS Code extension designed to help automate writing of\nCoq proofs. The plugin collects the parts of proofs marked with the admit\ntactic in a Coq file, i.e., proof holes, and combines LLMs along with\nnon-machine-learning methods to generate proof candidates for the holes. Then,\nCoqPilot checks if each proof candidate solves the given subgoal and, if\nsuccessful, replaces the hole with it. The focus of CoqPilot is twofold.\nFirstly, we want to allow users to seamlessly combine multiple Coq generation\napproaches and provide a zero-setup experience for our tool. Secondly, we want\nto deliver a platform for LLM-based experiments on Coq proof generation. We\ndeveloped a benchmarking system for Coq generation methods, available in the\nplugin, and conducted an experiment using it, showcasing the framework's\npossibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo.\nCode at: https://github.com/JetBrains-Research/coqpilot",
      "tldr_zh": "本研究介绍了 CoqPilot，一款基于大型语言模型（LLMs）的 VS Code 扩展，用于自动化 Coq 证明的生成。该插件识别 Coq 文件中用 admit tactic 标记的证明漏洞（proof holes），并结合 LLMs 和非机器学习方法生成证明候选，然后验证并替换成功的候选。CoqPilot 的重点在于提供无缝整合多种 Coq 生成方法的无设置体验，以及一个实验平台，包括一个基准系统来评估证明生成技术。实验结果展示了该框架在 Coq 证明生成中的潜力，并附带演示视频和开源代码。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.SE",
      "comment": "Published in the proceedings of the ASE'24 Tool Demonstrations Track",
      "pdf_url": "http://arxiv.org/pdf/2410.19605v1",
      "published_date": "2024-10-25 14:57:29 UTC",
      "updated_date": "2024-10-25 14:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:35:56.846289"
    },
    {
      "arxiv_id": "2410.19599v3",
      "title": "Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Gao",
        "Dokyun Lee",
        "Gordon Burtch",
        "Sina Fazelpour"
      ],
      "abstract": "Recent studies suggest large language models (LLMs) can exhibit human-like\nreasoning, aligning with human behavior in economic experiments, surveys, and\npolitical discourse. This has led many to propose that LLMs can be used as\nsurrogates or simulations for humans in social science research. However, LLMs\ndiffer fundamentally from humans, relying on probabilistic patterns, absent the\nembodied experiences or survival objectives that shape human cognition. We\nassess the reasoning depth of LLMs using the 11-20 money request game. Nearly\nall advanced approaches fail to replicate human behavior distributions across\nmany models. Causes of failure are diverse and unpredictable, relating to input\nlanguage, roles, and safeguarding. These results advise caution when using LLMs\nto study human behavior or as surrogates or simulations.",
      "tldr_zh": "该研究警告使用大型语言模型（LLMs）作为人类代理的潜在风险，尽管LLMs在经济实验、调查和政治讨论中表现出类似人类的推理能力，但它们本质上依赖概率模式，而非人类的经验或生存目标。研究通过11-20 money request game评估LLMs的推理深度，发现几乎所有先进模型都无法准确复制人类行为分布，失败原因涉及输入语言、角色设定和安全机制。作者建议在社会科学研究中使用LLMs模拟人类行为时需谨慎，以避免不可预测的偏差。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19599v3",
      "published_date": "2024-10-25 14:46:07 UTC",
      "updated_date": "2025-01-23 17:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:38:08.148746"
    },
    {
      "arxiv_id": "2410.19560v1",
      "title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shentong Mo",
        "Shengbang Tong"
      ],
      "abstract": "In recent advancements in unsupervised visual representation learning, the\nJoint-Embedding Predictive Architecture (JEPA) has emerged as a significant\nmethod for extracting visual features from unlabeled imagery through an\ninnovative masking strategy. Despite its success, two primary limitations have\nbeen identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA\nin preventing entire collapse and the inadequacy of I-JEPA prediction in\naccurately learning the mean of patch representations. Addressing these\nchallenges, this study introduces a novel framework, namely C-JEPA\n(Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive\nArchitecture with the Variance-Invariance-Covariance Regularization (VICReg)\nstrategy. This integration is designed to effectively learn the\nvariance/covariance for preventing entire collapse and ensuring invariance in\nthe mean of augmented views, thereby overcoming the identified limitations.\nThrough empirical and theoretical evaluations, our work demonstrates that\nC-JEPA significantly enhances the stability and quality of visual\nrepresentation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA\nexhibits rapid and improved convergence in both linear probing and fine-tuning\nperformance metrics.",
      "tldr_zh": "本研究针对 Joint-Embedding Predictive Architecture (JEPA) 在无监督视觉表示学习中的局限性，包括 Exponential Moving Average (EMA) 失效和 I-JEPA 预测不准等问题，提出了一种新框架 C-JEPA，将 JEPA 与 Variance-Invariance-Covariance Regularization (VICReg) 策略整合，以有效防止整个崩溃并确保增强视图的均值不变性。C-JEPA 通过这种整合提升了视觉表示学习的稳定性和质量。在 ImageNet-1K 数据集上预训练时，该框架表现出更快的收敛以及在线性探测和微调性能上的显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19560v1",
      "published_date": "2024-10-25 13:48:12 UTC",
      "updated_date": "2024-10-25 13:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:36:21.166043"
    },
    {
      "arxiv_id": "2410.19553v1",
      "title": "On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes",
      "title_zh": "翻译失败",
      "authors": [
        "Rajat Modi",
        "Vibhav Vineet",
        "Yogesh Singh Rawat"
      ],
      "abstract": "This paper explores the impact of occlusions in video action detection. We\nfacilitate this study by introducing five new benchmark datasets namely O-UCF\nand O-JHMDB consisting of synthetically controlled static/dynamic occlusions,\nOVIS-UCF and OVIS-JHMDB consisting of occlusions with realistic motions and\nReal-OUCF for occlusions in realistic-world scenarios. We formally confirm an\nintuitive expectation: existing models suffer a lot as occlusion severity is\nincreased and exhibit different behaviours when occluders are static vs when\nthey are moving. We discover several intriguing phenomenon emerging in neural\nnets: 1) transformers can naturally outperform CNN models which might have even\nused occlusion as a form of data augmentation during training 2) incorporating\nsymbolic-components like capsules to such backbones allows them to bind to\noccluders never even seen during training and 3) Islands of agreement can\nemerge in realistic images/videos without instance-level supervision,\ndistillation or contrastive-based objectives2(eg. video-textual training). Such\nemergent properties allow us to derive simple yet effective training recipes\nwhich lead to robust occlusion models inductively satisfying the first two\nstages of the binding mechanism (grouping/segregation). Models leveraging these\nrecipes outperform existing video action-detectors under occlusion by 32.3% on\nO-UCF, 32.7% on O-JHMDB & 2.6% on Real-OUCF in terms of the vMAP metric. The\ncode for this work has been released at\nhttps://github.com/rajatmodi62/OccludedActionBenchmark.",
      "tldr_zh": "这篇论文探讨了视频动作检测中遮挡的影响，引入了五个新基准数据集（O-UCF、O-JHMDB、OVIS-UCF、OVIS-JHMDB 和 Real-OUCF），分别针对合成静态/动态遮挡、真实运动遮挡和真实场景遮挡，以评估模型性能。研究发现，现有模型在遮挡严重时显著下降，且 Transformers 模型天然优于 CNN，即使后者使用遮挡数据增强；此外，加入符号组件如 capsules 能处理训练中未见的遮挡，并观察到无监督的 emergent properties，如 Islands of agreement。作者提出了简单有效的训练配方，提升模型的遮挡鲁棒性，结果显示在新数据集上，vMAP 指标分别在 O-UCF 上提高 32.3%、O-JHMDB 上提高 32.7%、Real-OUCF 上提高 2.6%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper was accepted to NeurIPS 2023 Dataset And Benchmark Track.\n  It also showcases: Hinton's Islands of Agreement on realistic datasets which\n  were previously hypothesized in his GLOM paper",
      "pdf_url": "http://arxiv.org/pdf/2410.19553v1",
      "published_date": "2024-10-25 13:27:55 UTC",
      "updated_date": "2024-10-25 13:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:38:21.160980"
    },
    {
      "arxiv_id": "2410.19550v2",
      "title": "DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Qiao",
        "Lina Gong",
        "Yu Zhao",
        "Yongwei Wang",
        "Mingqiang Wei"
      ],
      "abstract": "Software defect prediction (SDP) aims to identify high-risk defect modules in\nsoftware development, optimizing resource allocation. While previous studies\nshow that dependency network metrics improve defect prediction, most methods\nfocus on code-based dependency graphs, overlooking developer factors. Current\nmetrics, based on handcrafted features like ego and global network metrics,\nfail to fully capture defect-related information. To address this, we propose\nDeMuVGN, a defect prediction model that learns multi-view software dependency\nvia graph neural networks. We introduce a Multi-view Software Dependency Graph\n(MSDG) that integrates data, call, and developer dependencies. DeMuVGN also\nleverages the Synthetic Minority Oversampling Technique (SMOTE) to address\nclass imbalance and enhance defect module identification. In a case study of\neight open-source projects across 20 versions, DeMuVGN demonstrates significant\nimprovements: i) models based on multi-view graphs improve F1 scores by 11.1%\nto 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to\n45.8% in within-project contexts and by 17.9% to 41.0% in cross-project\ncontexts. Additionally, DeMuVGN excels in software evolution, showing more\nimprovement in later-stage software versions. Its strong performance across\ndifferent projects highlights its generalizability. We recommend future\nresearch focus on multi-view dependency graphs for defect prediction in both\nmature and newly developed projects.",
      "tldr_zh": "本研究提出DeMuVGN，一种基于图神经网络(Graph Neural Networks)的软件缺陷预测模型，通过学习多视图软件依赖来提升预测准确性。DeMuVGN引入Multi-view Software Dependency Graph (MSDG)，整合数据、调用和开发者依赖，并结合Synthetic Minority Oversampling Technique (SMOTE)处理类别不平衡问题，以更全面地捕获缺陷相关信息。在八个开源项目的20个版本案例研究中，DeMuVGN在项目内场景提高F1分数17.4%至45.8%，在跨项目场景提高17.9%至41.0%，并在软件演化后期表现出色。该模型的多视图方法比单视图模型提升11.1%至12.1%，证明其泛化性和有效性，并建议未来研究聚焦多视图依赖图。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "The current paper is not comprehensive enough. We are seeking further\n  improvement",
      "pdf_url": "http://arxiv.org/pdf/2410.19550v2",
      "published_date": "2024-10-25 13:24:04 UTC",
      "updated_date": "2025-05-07 05:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:38:33.167449"
    },
    {
      "arxiv_id": "2410.19546v3",
      "title": "Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?",
      "title_zh": "翻译失败",
      "authors": [
        "Antonia Wüst",
        "Tim Tobiasch",
        "Lukas Helff",
        "Inga Ibs",
        "Wolfgang Stammer",
        "Devendra S. Dhami",
        "Constantin A. Rothkopf",
        "Kristian Kersting"
      ],
      "abstract": "Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1,\nhave emerged, seemingly demonstrating advanced reasoning capabilities across\ntext and image modalities. However, the depth of these advances in\nlanguage-guided perception and abstract reasoning remains underexplored, and it\nis unclear whether these models can truly live up to their ambitious promises.\nTo assess the progress and identify shortcomings, we enter the wonderland of\nBongard problems, a set of classic visual reasoning puzzles that require\nhuman-like abilities of pattern recognition and abstract reasoning. With our\nextensive evaluation setup, we show that while VLMs occasionally succeed in\nidentifying discriminative concepts and solving some of the problems, they\nfrequently falter. Surprisingly, even elementary concepts that may seem trivial\nto humans, such as simple spirals, pose significant challenges. Moreover, when\nexplicitly asked to recognize ground truth concepts, they continue to falter,\nsuggesting not only a lack of understanding of these elementary visual concepts\nbut also an inability to generalize to unseen concepts. We compare the results\nof VLMs to human performance and observe that a significant gap remains between\nhuman visual reasoning capabilities and machine cognition.",
      "tldr_zh": "这篇论文评估了视觉语言模型（VLMs），如 OpenAI 的 o1，在语言引导感知和抽象推理方面的真实能力，使用经典的 Bongard 问题作为视觉推理测试基准。研究通过广泛的评估发现，VLMs 偶尔能识别鉴别性概念并解决问题，但经常在处理人类眼中简单的元素（如简单螺旋）时失败。结果表明，VLMs 不仅缺乏对基本视觉概念的理解，还无法有效泛化到未见过的新概念，与人类在视觉推理方面的性能存在显著差距。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19546v3",
      "published_date": "2024-10-25 13:19:26 UTC",
      "updated_date": "2025-02-25 09:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:38:43.993946"
    },
    {
      "arxiv_id": "2410.19544v1",
      "title": "PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation",
      "title_zh": "翻译失败",
      "authors": [
        "Huajian Liu",
        "Wei Dong",
        "Kunpeng Fan",
        "Chao Wang",
        "Yongzhuo Gao"
      ],
      "abstract": "Analyzing and forecasting trajectories of agents like pedestrians plays a\npivotal role for embodied intelligent applications. The inherent indeterminacy\nof human behavior and complex social interaction among a rich variety of agents\nmake this task more challenging than common time-series forecasting. In this\nletter, we aim to explore a distinct formulation for multi-agent trajectory\nprediction framework. Specifically, we proposed a patching-based temporal\nfeature extraction module and a graph-based social feature extraction module,\nenabling effective feature extraction and cross-scenario generalization.\nMoreover, we reassess the role of social interaction and present a novel method\nbased on explicit modality modulation to integrate temporal and social\nfeatures, thereby constructing an efficient single-stage inference pipeline.\nResults on public benchmark datasets demonstrate the superior performance of\nour model compared with the state-of-the-art methods. The code is available at:\ngithub.com/TIB-K330/pmm-net.",
      "tldr_zh": "这篇论文提出了 PMM-Net，一种单阶段多代理轨迹预测框架，针对人类行为的固有不确定性和复杂社交互动问题。该框架包括 patching-based temporal feature extraction module 和 graph-based social feature extraction module，用于高效提取时序特征和社交特征，并实现跨场景泛化。通过 explicit modal modulation 方法整合这些特征，构建了一个高效的单阶段推理管道。在公共基准数据集上的实验结果显示，PMM-Net 优于现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19544v1",
      "published_date": "2024-10-25 13:16:27 UTC",
      "updated_date": "2024-10-25 13:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:38:57.085458"
    },
    {
      "arxiv_id": "2410.19542v2",
      "title": "Brain-like Functional Organization within Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyang Sun",
        "Lin Zhao",
        "Zihao Wu",
        "Xiaohui Gao",
        "Yutao Hu",
        "Mengfei Zuo",
        "Wei Zhang",
        "Junwei Han",
        "Tianming Liu",
        "Xintao Hu"
      ],
      "abstract": "The human brain has long inspired the pursuit of artificial intelligence\n(AI). Recently, neuroimaging studies provide compelling evidence of alignment\nbetween the computational representation of artificial neural networks (ANNs)\nand the neural responses of the human brain to stimuli, suggesting that ANNs\nmay employ brain-like information processing strategies. While such alignment\nhas been observed across sensory modalities--visual, auditory, and\nlinguistic--much of the focus has been on the behaviors of artificial neurons\n(ANs) at the population level, leaving the functional organization of\nindividual ANs that facilitates such brain-like processes largely unexplored.\nIn this study, we bridge this gap by directly coupling sub-groups of artificial\nneurons with functional brain networks (FBNs), the foundational organizational\nstructure of the human brain. Specifically, we extract representative patterns\nfrom temporal responses of ANs in large language models (LLMs), and use them as\nfixed regressors to construct voxel-wise encoding models to predict brain\nactivity recorded by functional magnetic resonance imaging (fMRI). This\nframework links the AN sub-groups to FBNs, enabling the delineation of\nbrain-like functional organization within LLMs. Our findings reveal that LLMs\n(BERT and Llama 1-3) exhibit brain-like functional architecture, with\nsub-groups of artificial neurons mirroring the organizational patterns of\nwell-established FBNs. Notably, the brain-like functional organization of LLMs\nevolves with the increased sophistication and capability, achieving an improved\nbalance between the diversity of computational behaviors and the consistency of\nfunctional specializations. This research represents the first exploration of\nbrain-like functional organization within LLMs, offering novel insights to\ninform the development of artificial general intelligence (AGI) with human\nbrain principles.",
      "tldr_zh": "本研究探索了大型语言模型（LLMs，如 BERT 和 Llama 1-3）中人工神经元（ANs）的功能组织是否类似于人类大脑的功能脑网络（FBNs），通过将 ANs 的子群与大脑活动联系起来，填补了现有研究的空白。研究方法包括从 LLMs 的 ANs 时间响应中提取模式，作为固定回归器构建体素级编码模型，以预测功能磁共振成像（fMRI）记录的大脑活动。结果显示，LLMs 展示了脑-like 功能架构，其 ANs 子群镜像了 FBNs 的组织模式，并随着模型复杂性增加而实现计算行为多样性和功能专业化的一致性平衡。该工作首次揭示了 LLMs 的这种功能组织，为基于人类大脑原则开发人工通用智能（AGI）提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19542v2",
      "published_date": "2024-10-25 13:15:17 UTC",
      "updated_date": "2024-10-31 03:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:39:09.184869"
    },
    {
      "arxiv_id": "2410.19540v1",
      "title": "CloserMusicDB: A Modern Multipurpose Dataset of High Quality Music",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandra Piekarzewicz",
        "Tomasz Sroka",
        "Aleksander Tym",
        "Mateusz Modrzejewski"
      ],
      "abstract": "In this paper, we introduce CloserMusicDB, a collection of full length studio\nquality tracks annotated by a team of human experts. We describe the selected\nqualities of our dataset, along with three example tasks possible to perform\nusing this dataset: hook detection, contextual tagging and artist\nidentification. We conduct baseline experiments and provide initial benchmarks\nfor these tasks.",
      "tldr_zh": "本论文引入了CloserMusicDB，这是一个由人类专家标注的高质量全长音乐曲目数据集，旨在为音乐分析提供现代多用途资源。该数据集支持多种任务，例如hook detection、contextual tagging和artist identification，并描述了其关键特性。研究者进行了基线实验，并为这些任务提供了初始基准，以促进后续研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19540v1",
      "published_date": "2024-10-25 13:11:19 UTC",
      "updated_date": "2024-10-25 13:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:39:20.395259"
    },
    {
      "arxiv_id": "2410.19504v1",
      "title": "DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Zelin Zang",
        "Yuhao Wang",
        "Jinlin Wu",
        "Hong Liu",
        "Yue Shen",
        "Stan. Z Li",
        "Zhen Lei"
      ],
      "abstract": "Dimensionality reduction (DR) plays a crucial role in various fields,\nincluding data engineering and visualization, by simplifying complex datasets\nwhile retaining essential information. However, the challenge of balancing DR\naccuracy and interpretability remains crucial, particularly for users dealing\nwith high-dimensional data. Traditional DR methods often face a trade-off\nbetween precision and transparency, where optimizing for performance can lead\nto reduced interpretability, and vice versa. This limitation is especially\nprominent in real-world applications such as image, tabular, and text data\nanalysis, where both accuracy and interpretability are critical. To address\nthese challenges, this work introduces the MOE-based Hyperbolic Interpretable\nDeep Manifold Transformation (DMT-HI). The proposed approach combines\nhyperbolic embeddings, which effectively capture complex hierarchical\nstructures, with Mixture of Experts (MOE) models, which dynamically allocate\ntasks based on input features. DMT-HI enhances DR accuracy by leveraging\nhyperbolic embeddings to represent the hierarchical nature of data, while also\nimproving interpretability by explicitly linking input data, embedding\noutcomes, and key features through the MOE structure. Extensive experiments\ndemonstrate that DMT-HI consistently achieves superior performance in both DR\naccuracy and model interpretability, making it a robust solution for complex\ndata analysis. The code is available at\n\\url{https://github.com/zangzelin/code_dmthi}.",
      "tldr_zh": "本研究提出了一种基于 Mixture of Experts (MOE) 的超曲面可解释深度流形变换方法，DMT-HI，用于无监督的 Dimensionality Reduction (DR)，旨在解决传统方法在精度和可解释性之间的权衡问题。DMT-HI 通过结合 hyperbolic embeddings 来捕捉数据中的复杂分层结构，并利用 MOE 模型动态分配任务，从而将输入数据、嵌入结果和关键特征明确关联，提高了 DR 的准确性和透明度。在广泛实验中，DMT-HI 在图像、表格和文本数据分析上表现出色，显著提升了性能，并提供了开源代码以便进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19504v1",
      "published_date": "2024-10-25 12:11:32 UTC",
      "updated_date": "2024-10-25 12:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:39:33.048176"
    },
    {
      "arxiv_id": "2410.19479v1",
      "title": "Peter Parker or Spiderman? Disambiguating Multiple Class Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Nuthan Mummani",
        "Simran Ketha",
        "Venkatakrishnan Ramaswamy"
      ],
      "abstract": "In the supervised classification setting, during inference, deep networks\ntypically make multiple predictions. For a pair of such predictions (that are\nin the top-k predictions), two distinct possibilities might occur. On the one\nhand, each of the two predictions might be primarily driven by two distinct\nsets of entities in the input. On the other hand, it is possible that there is\na single entity or set of entities that is driving the prediction for both the\nclasses in question. This latter case, in effect, corresponds to the network\nmaking two separate guesses about the identity of a single entity type.\nClearly, both the guesses cannot be true, i.e. both the labels cannot be\npresent in the input. Current techniques in interpretability research do not\nreadily disambiguate these two cases, since they typically consider input\nattributions for one class label at a time. Here, we present a framework and\nmethod to do so, leveraging modern segmentation and input attribution\ntechniques. Notably, our framework also provides a simple counterfactual\n\"proof\" of each case, which can be verified for the input on the model (i.e.\nwithout running the method again). We demonstrate that the method performs well\nfor a number of samples from the ImageNet validation set and on multiple\nmodels.",
      "tldr_zh": "这篇论文解决了深度网络在监督分类中的多标签预测歧义问题，即区分两个预测是否由输入中的不同实体驱动，还是同一个实体驱动了多个猜测。作者提出一个框架，利用现代segmentation和input attribution技术来识别这些情况，并提供简单的counterfactual proof作为验证。实验结果显示，该方法在ImageNet验证集上的多个样本和模型中表现良好，从而提升了模型预测的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to Neural Information Processing Systems (NeurIPS 2024).\n  ATTRIB Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.19479v1",
      "published_date": "2024-10-25 11:16:28 UTC",
      "updated_date": "2024-10-25 11:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:39:44.005871"
    },
    {
      "arxiv_id": "2410.19471v1",
      "title": "Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization",
      "title_zh": "通过多样性正则化直接偏好优化改进肽设计的逆折叠",
      "authors": [
        "Ryan Park",
        "Darren J. Hsu",
        "C. Brian Roland",
        "Maria Korshunova",
        "Chen Tessler",
        "Shie Mannor",
        "Olivia Viessmann",
        "Bruno Trentini"
      ],
      "abstract": "Inverse folding models play an important role in structure-based design by\npredicting amino acid sequences that fold into desired reference structures.\nModels like ProteinMPNN, a message-passing encoder-decoder model, are trained\nto reliably produce new sequences from a reference structure. However, when\napplied to peptides, these models are prone to generating repetitive sequences\nthat do not fold into the reference structure. To address this, we fine-tune\nProteinMPNN to produce diverse and structurally consistent peptide sequences\nvia Direct Preference Optimization (DPO). We derive two enhancements to DPO:\nonline diversity regularization and domain-specific priors. Additionally, we\ndevelop a new understanding on improving diversity in decoder models. When\nconditioned on OpenFold generated structures, our fine-tuned models achieve\nstate-of-the-art structural similarity scores, improving base ProteinMPNN by at\nleast 8%. Compared to standard DPO, our regularized method achieves up to 20%\nhigher sequence diversity with no loss in structural similarity score.",
      "tldr_zh": "本研究旨在改进逆折叠模型（Inverse Folding）用于肽设计，通过引入多样性正则化直接偏好优化（Diversity-regularized Direct Preference Optimization, DPO）来微调 ProteinMPNN 模型，以生成多样性和结构一致的肽序列。作者对 DPO 进行了两个增强：在线多样性正则化（online diversity regularization）和领域特定先验（domain-specific priors），并发展了对解码器模型多样性改进的新理解。实验结果显示，在 OpenFold 生成的结构上，该模型的结构相似性得分比基础 ProteinMPNN 至少提高了 8%，且与标准 DPO 相比，序列多样性提高了高达 20%，而未牺牲结构相似性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. 10 pages plus appendices",
      "pdf_url": "http://arxiv.org/pdf/2410.19471v1",
      "published_date": "2024-10-25 11:04:02 UTC",
      "updated_date": "2024-10-25 11:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:39:57.365751"
    },
    {
      "arxiv_id": "2410.19469v1",
      "title": "Unified Causality Analysis Based on the Degrees of Freedom",
      "title_zh": "基于自由度的统一因果分析",
      "authors": [
        "András Telcs",
        "Marcell T. Kurbucz",
        "Antal Jakovác"
      ],
      "abstract": "Temporally evolving systems are typically modeled by dynamic equations. A key\nchallenge in accurate modeling is understanding the causal relationships\nbetween subsystems, as well as identifying the presence and influence of\nunobserved hidden drivers on the observed dynamics. This paper presents a\nunified method capable of identifying fundamental causal relationships between\npairs of systems, whether deterministic or stochastic. Notably, the method also\nuncovers hidden common causes beyond the observed variables. By analyzing the\ndegrees of freedom in the system, our approach provides a more comprehensive\nunderstanding of both causal influence and hidden confounders. This unified\nframework is validated through theoretical models and simulations,\ndemonstrating its robustness and potential for broader application.",
      "tldr_zh": "这篇论文提出了一种基于degrees of freedom的统一因果分析方法，用于识别成对系统（包括确定性和随机系统）之间的基本causal relationships，并同时揭示观察变量之外的hidden common causes。通过分析系统的degrees of freedom，该方法提供了更全面的理解，包括因果影响和hidden confounders的评估。该框架通过理论模型和模拟进行验证，证明了其稳健性和在时间演化系统建模中的广泛应用潜力。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "math-ph",
        "math.MP"
      ],
      "primary_category": "stat.ME",
      "comment": "32 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19469v1",
      "published_date": "2024-10-25 10:57:35 UTC",
      "updated_date": "2024-10-25 10:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:40:08.043984"
    },
    {
      "arxiv_id": "2410.19464v4",
      "title": "LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data",
      "title_zh": "LOCAL：利用方向矩阵学习从时间序列数据中推断因果结构",
      "authors": [
        "Jiajun Zhang",
        "Boyang Qiang",
        "Xiaoyu Guo",
        "Weiwei Xing",
        "Yue Cheng",
        "Witold Pedrycz"
      ],
      "abstract": "Discovering the underlying Directed Acyclic Graph (DAG) from time series\nobservational data is highly challenging due to the dynamic nature and complex\nnonlinear interactions between variables. Existing methods typically search for\nthe optimal DAG by optimizing an objective function but face scalability\nchallenges, as their computational demands grow exponentially with the\ndimensional expansion of variables. To this end, we propose LOCAL, a highly\nefficient, easy-to-implement, and constraint-free method for recovering dynamic\ncausal structures. LOCAL is the first attempt to formulate a quasi-maximum\nlikelihood-based score function for learning the dynamic DAG equivalent to the\nground truth. Building on this, we introduce two adaptive modules that enhance\nthe algebraic characterization of acyclicity: Asymptotic Causal Mask Learning\n(ACML) and Dynamic Graph Parameter Learning (DGPL). ACML constructs causal\nmasks using learnable priority vectors and the Gumbel-Sigmoid function,\nensuring DAG formation while optimizing computational efficiency. DGPL\ntransforms causal learning into decomposed matrix products, capturing dynamic\ncausal structure in high-dimensional data and improving interpretability.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nLOCAL significantly outperforms existing methods and highlight LOCAL's\npotential as a robust and efficient method for dynamic causal discovery.",
      "tldr_zh": "本文提出 LOCAL 方法，用于从时间序列数据中推断动态因果结构（Directed Acyclic Graph, DAG），通过优化一个基于准最大似然的评分函数来高效恢复真实动态图。LOCAL 引入 Asymptotic Causal Mask Learning (ACML) 和 Dynamic Graph Parameter Learning (DGPL) 模块，分别通过可学习优先级向量与 Gumbel-Sigmoid 函数构建因果掩码，以及将因果学习转化为分解矩阵乘积，以提升计算效率和可解释性。在合成和真实数据集上的广泛实验中，LOCAL 显著优于现有方法，证明其在高维动态因果发现中的鲁棒性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19464v4",
      "published_date": "2024-10-25 10:48:41 UTC",
      "updated_date": "2025-03-20 03:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:40:20.131191"
    },
    {
      "arxiv_id": "2410.19461v2",
      "title": "EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xuetian Chen",
        "Hangcheng Li",
        "Jiaqing Liang",
        "Sihang Jiang",
        "Deqing Yang"
      ],
      "abstract": "Autonomous agents operating on the graphical user interfaces (GUIs) of\nvarious applications hold immense practical value. Unlike the large language\nmodel (LLM)-based methods which rely on structured texts and customized\nbackends, the approaches using large vision-language models (LVLMs) are more\nintuitive and adaptable as they can visually perceive and directly interact\nwith screens, making them indispensable in general scenarios without text\nmetadata and tailored backends. Given the lack of high-quality training data\nfor GUI-related tasks in existing work, this paper aims to enhance the GUI\nunderstanding and interacting capabilities of LVLMs through a data-driven\napproach. We propose EDGE, a general data synthesis framework that\nautomatically generates large-scale, multi-granularity training data from\nwebpages across the Web. Evaluation results on various GUI and agent benchmarks\ndemonstrate that the model trained with the dataset generated through EDGE\nexhibits superior webpage understanding capabilities, which can then be easily\ntransferred to previously unseen desktop and mobile environments. Our approach\nsignificantly reduces the dependence on manual annotations, empowering\nresearchers to harness the vast public resources available on the Web to\nadvance their work. Our source code, the dataset and the model are available at\nhttps://anonymous.4open.science/r/EDGE-1CDB.",
      "tldr_zh": "该论文提出EDGE框架，通过从网络网页自动生成大规模、多粒度合成数据，来提升大型视觉语言模型(LVLMs)在图形用户界面(GUI)理解和交互方面的能力，以解决现有训练数据不足的问题。EDGE采用数据驱动方法，生成丰富的训练数据集，减少了对手动标注的依赖，并使模型能够轻松转移到未见过的桌面和移动环境。实验结果显示，在各种GUI和代理基准上，使用EDGE生成的数据训练的模型表现出色，显著提高了网页理解性能，并利用网络公共资源推进相关研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19461v2",
      "published_date": "2024-10-25 10:46:17 UTC",
      "updated_date": "2024-11-02 08:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:40:31.874588"
    },
    {
      "arxiv_id": "2410.19460v2",
      "title": "Accelerating AI Performance using Anderson Extrapolation on GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Saleem Abdul Fattah Ahmed Al Dajani",
        "David E. Keyes"
      ],
      "abstract": "We present a novel approach for accelerating AI performance by leveraging\nAnderson extrapolation, a vector-to-vector mapping technique based on a window\nof historical iterations. By identifying the crossover point (Fig. 1) where a\nmixing penalty is incurred, the method focuses on reducing iterations to\nconvergence, with fewer more compute-intensive but generally cacheable\niterations, balancing speed and memory usage with accuracy and algorithmic\nstability, respectively. We demonstrate significant improvements, in both\ntraining and inference, motivated by scalability and efficiency extensions to\nthe realm of high-performance computing (HPC).",
      "tldr_zh": "本研究提出了一种新方法，使用 Anderson extrapolation 技术来加速 AI 在 GPUs 上的性能，该技术是一种基于历史迭代的向量映射，旨在通过识别 crossover point 减少迭代次数，同时平衡速度、内存使用、准确性和算法稳定性。方法强调使用更少的计算密集型但易缓存的迭代，以提升整体效率。实验结果显示，该方法在 AI 训练和推理过程中实现了显著改进，并扩展到高性能计算（HPC）领域，提高了可扩展性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.PF",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 6 figures, 1 table, Accepted by NeurIPS 2024 Workshop MLNCP\n  https://openreview.net/forum?id=wkP2ZFRn9e",
      "pdf_url": "http://arxiv.org/pdf/2410.19460v2",
      "published_date": "2024-10-25 10:45:17 UTC",
      "updated_date": "2024-12-19 04:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:40:43.549199"
    },
    {
      "arxiv_id": "2410.19452v3",
      "title": "NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Gong",
        "Guangyin Bao",
        "Qi Zhang",
        "Zhongwei Wan",
        "Duoqian Miao",
        "Shoujin Wang",
        "Lei Zhu",
        "Changwei Wang",
        "Rongtao Xu",
        "Liang Hu",
        "Ke Liu",
        "Yu Zhang"
      ],
      "abstract": "Reconstruction of static visual stimuli from non-invasion brain activity fMRI\nachieves great success, owning to advanced deep learning models such as CLIP\nand Stable Diffusion. However, the research on fMRI-to-video reconstruction\nremains limited since decoding the spatiotemporal perception of continuous\nvisual experiences is formidably challenging. We contend that the key to\naddressing these challenges lies in accurately decoding both high-level\nsemantics and low-level perception flows, as perceived by the brain in response\nto video stimuli. To the end, we propose NeuroClips, an innovative framework to\ndecode high-fidelity and smooth video from fMRI. NeuroClips utilizes a\nsemantics reconstructor to reconstruct video keyframes, guiding semantic\naccuracy and consistency, and employs a perception reconstructor to capture\nlow-level perceptual details, ensuring video smoothness. During inference, it\nadopts a pre-trained T2V diffusion model injected with both keyframes and\nlow-level perception flows for video reconstruction. Evaluated on a publicly\navailable fMRI-video dataset, NeuroClips achieves smooth high-fidelity video\nreconstruction of up to 6s at 8FPS, gaining significant improvements over\nstate-of-the-art models in various metrics, e.g., a 128% improvement in SSIM\nand an 81% improvement in spatiotemporal metrics. Our project is available at\nhttps://github.com/gongzix/NeuroClips.",
      "tldr_zh": "本文提出 NeuroClips 框架，旨在实现从 fMRI 数据到高保真和平滑视频的重建，解决连续视觉体验的空间时间感知挑战。框架包括语义重建器用于重建视频关键帧以确保语义准确性，以及感知重建器捕获低级感知细节，并结合预训练的 T2V 扩散模型注入关键帧和感知流进行视频生成。在公开数据集上评估，NeuroClips 成功重建高达 6 秒的视频（8 FPS），在 SSIM 等指标上比现有模型提升显著，如 SSIM 提高 128% 和时空指标提高 81%。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "NeurIPS 2024 Oral",
      "pdf_url": "http://arxiv.org/pdf/2410.19452v3",
      "published_date": "2024-10-25 10:28:26 UTC",
      "updated_date": "2024-12-15 08:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:40:56.299980"
    },
    {
      "arxiv_id": "2410.19451v1",
      "title": "Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yirui Chen",
        "Qinyu Xiao",
        "Jia Yi",
        "Jing Chen",
        "Mengyang Wang"
      ],
      "abstract": "This paper explores the application of prompt engineering to enhance the\nperformance of large language models (LLMs) in the domain of Traditional\nChinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates\nvarious pre-trained language models (PLMs), templates, tokenization, and\nverbalization methods, allowing researchers to easily construct and fine-tune\nmodels for specific TCM-related tasks. We conducted experiments on disease\nclassification, syndrome identification, herbal medicine recommendation, and\ngeneral NLP tasks, demonstrating the effectiveness and superiority of our\napproach compared to baseline methods. Our findings suggest that prompt\nengineering is a promising technique for improving the performance of LLMs in\nspecialized domains like TCM, with potential applications in digitalization,\nmodernization, and personalized medicine.",
      "tldr_zh": "本论文探讨了基于提示工程（Prompt Engineering）框架提升大语言模型（LLMs）在中医（Traditional Chinese Medicine, TCM）领域的智能理解能力。提出了 TCM-Prompt 框架，该框架整合了预训练语言模型（PLMs）、模板、tokenization 和 verbalization 方法，便于研究人员构建和微调模型以处理特定 TCM 任务。实验结果显示，在疾病分类、症候识别、草药推荐以及一般 NLP 任务上，该框架的表现优于基线方法。总体而言，该研究证明了提示工程在 TCM 的数字化、现代化和个性化医学应用中的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19451v1",
      "published_date": "2024-10-25 10:24:30 UTC",
      "updated_date": "2024-10-25 10:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:41:08.432263"
    },
    {
      "arxiv_id": "2410.19450v1",
      "title": "Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Hai Zhong",
        "Xun Wang",
        "Zhuoran Li",
        "Longbo Huang"
      ],
      "abstract": "Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm,\nleveraging offline data for initialization and online fine-tuning to enhance\nboth sample efficiency and performance. However, most existing research has\nfocused on single-agent settings, with limited exploration of the multi-agent\nextension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O\nMARL). In O2O MARL, two critical challenges become more prominent as the number\nof agents increases: (i) the risk of unlearning pre-trained Q-values due to\ndistributional shifts during the transition from offline-to-online phases, and\n(ii) the difficulty of efficient exploration in the large joint state-action\nspace. To tackle these challenges, we propose a novel O2O MARL framework called\nOffline Value Function Memory with Sequential Exploration (OVMSE). First, we\nintroduce the Offline Value Function Memory (OVM) mechanism to compute target\nQ-values, preserving knowledge gained during offline training, ensuring\nsmoother transitions, and enabling efficient fine-tuning. Second, we propose a\ndecentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which\neffectively utilizes the pre-trained offline policy for exploration, thereby\nsignificantly reducing the joint state-action space to be explored. Extensive\nexperiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that\nOVMSE significantly outperforms existing baselines, achieving superior sample\nefficiency and overall performance.",
      "tldr_zh": "本文提出了一种名为 OVMSE 的 Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL) 框架，旨在解决多代理环境中从离线到在线阶段的分销偏移导致 Q 值丢失以及在大型联合状态-动作空间中探索效率低下的问题。框架的核心包括 Offline Value Function Memory (OVM) 机制，用于保留离线训练的知识以确保平滑过渡和高效微调，以及 Decentralized Sequential Exploration (SE) 策略，通过利用预训练离线策略来减少探索空间。实验结果显示，在 StarCraft Multi-Agent Challenge (SMAC) 上，OVMSE 显著优于现有基线，提升了样本效率和整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19450v1",
      "published_date": "2024-10-25 10:24:19 UTC",
      "updated_date": "2024-10-25 10:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:41:21.869554"
    },
    {
      "arxiv_id": "2410.19448v1",
      "title": "Gradient Descent Efficiency Index",
      "title_zh": "梯度下降效率指标",
      "authors": [
        "Aviral Dhingra"
      ],
      "abstract": "Gradient descent is a widely used iterative algorithm for finding local\nminima in multivariate functions. However, the final iterations often either\novershoot the minima or make minimal progress, making it challenging to\ndetermine an optimal stopping point. This study introduces a new efficiency\nmetric, Ek, designed to quantify the effectiveness of each iteration. The\nproposed metric accounts for both the relative change in error and the\nstability of the loss function across iterations. This measure is particularly\nvaluable in resource-constrained environments, where costs are closely tied to\ntraining time. Experimental validation across multiple datasets and models\ndemonstrates that Ek provides valuable insights into the convergence behavior\nof gradient descent, complementing traditional performance metrics. The index\nhas the potential to guide more informed decisions in the selection and tuning\nof optimization algorithms in machine learning applications and be used to\ncompare the \"effectiveness\" of models relative to each other.",
      "tldr_zh": "这篇论文针对梯度下降算法在寻找函数局部最小值时的效率问题，引入了一个新指标 Ek，用于量化每个迭代的有效性。Ek 考虑了误差的相对变化和损失函数的稳定性，从而帮助在资源受限环境中优化训练时间。实验结果显示，该指标能提供梯度下降收敛行为的宝贵洞见，补充传统性能指标，并指导机器学习中优化算法的选择和模型比较。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "12 Pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19448v1",
      "published_date": "2024-10-25 10:22:22 UTC",
      "updated_date": "2024-10-25 10:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:41:30.853673"
    },
    {
      "arxiv_id": "2410.19427v1",
      "title": "Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models",
      "title_zh": "先暴露再防御：通过暴露模型统一和增强后门防御",
      "authors": [
        "Yige Li",
        "Hanxun Huang",
        "Jiaming Zhang",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "abstract": "Backdoor attacks covertly implant triggers into deep neural networks (DNNs)\nby poisoning a small portion of the training data with pre-designed backdoor\ntriggers. This vulnerability is exacerbated in the era of large models, where\nextensive (pre-)training on web-crawled datasets is susceptible to compromise.\nIn this paper, we introduce a novel two-step defense framework named Expose\nBefore You Defend (EBYD). EBYD unifies existing backdoor defense methods into a\ncomprehensive defense system with enhanced performance. Specifically, EBYD\nfirst exposes the backdoor functionality in the backdoored model through a\nmodel preprocessing step called backdoor exposure, and then applies detection\nand removal methods to the exposed model to identify and eliminate the backdoor\nfeatures. In the first step of backdoor exposure, we propose a novel technique\ncalled Clean Unlearning (CUL), which proactively unlearns clean features from\nthe backdoored model to reveal the hidden backdoor features. We also explore\nvarious model editing/modification techniques for backdoor exposure, including\nfine-tuning, model sparsification, and weight perturbation. Using EBYD, we\nconduct extensive experiments on 10 image attacks and 6 text attacks across 2\nvision datasets (CIFAR-10 and an ImageNet subset) and 4 language datasets\n(SST-2, IMDB, Twitter, and AG's News). The results demonstrate the importance\nof backdoor exposure for backdoor defense, showing that the exposed models can\nsignificantly benefit a range of downstream defense tasks, including backdoor\nlabel detection, backdoor trigger recovery, backdoor model detection, and\nbackdoor removal. We hope our work could inspire more research in developing\nadvanced defense frameworks with exposed models. Our code is available at:\nhttps://github.com/bboylyg/Expose-Before-You-Defend.",
      "tldr_zh": "这篇论文提出了一种名为EBYD（Expose Before You Defend）的创新框架，用于统一和提升后门攻击（backdoor attacks）防御，针对深度神经网络（DNNs）在训练数据中被植入触发器的漏洞。EBYD通过后门暴露（backdoor exposure）步骤，首先利用Clean Unlearning (CUL)技术主动移除干净特征以揭示隐藏的后门特征，并结合fine-tuning、model sparsification和weight perturbation等方法进行模型预处理。实验在CIFAR-10、ImageNet子集、SST-2、IMDB、Twitter和AG's News等数据集上评估了10种图像攻击和6种文本攻击，结果显示EBYD显著提高了下游防御任务的性能，包括后门标签检测、触发器恢复、模型检测和后门移除，平均准确率和效果得到增强。作者开源了代码，并呼吁更多研究探索基于暴露模型的先进防御系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19427v1",
      "published_date": "2024-10-25 09:36:04 UTC",
      "updated_date": "2024-10-25 09:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:41:47.591879"
    },
    {
      "arxiv_id": "2410.19412v1",
      "title": "Robust Time Series Causal Discovery for Agent-Based Model Validation",
      "title_zh": "针对代理基模型验证的稳健时间序列因果发现",
      "authors": [
        "Gene Yu",
        "Ce Guo",
        "Wayne Luk"
      ],
      "abstract": "Agent-Based Model (ABM) validation is crucial as it helps ensuring the\nreliability of simulations, and causal discovery has become a powerful tool in\nthis context. However, current causal discovery methods often face accuracy and\nrobustness challenges when applied to complex and noisy time series data, which\nis typical in ABM scenarios. This study addresses these issues by proposing a\nRobust Cross-Validation (RCV) approach to enhance causal structure learning for\nABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two\nprominent causal discovery algorithms. These aim to reduce the impact of noise\nbetter and give more reliable causal relation results, even with\nhigh-dimensional, time-dependent data. The proposed approach is then integrated\ninto an enhanced ABM validation framework, which is designed to handle diverse\ndata and model structures.\n  The approach is evaluated using synthetic datasets and a complex simulated\nfMRI dataset. The results demonstrate greater reliability in causal structure\nidentification. The study examines how various characteristics of datasets\naffect the performance of established causal discovery methods. These\ncharacteristics include linearity, noise distribution, stationarity, and causal\nstructure density. This analysis is then extended to the RCV method to see how\nit compares in these different situations. This examination helps confirm\nwhether the results are consistent with existing literature and also reveals\nthe strengths and weaknesses of the novel approaches.\n  By tackling key methodological challenges, the study aims to enhance ABM\nvalidation with a more resilient valuation framework presented. These\nimprovements increase the reliability of model-driven decision making processes\nin complex systems analysis.",
      "tldr_zh": "这篇论文针对 Agent-Based Model (ABM) 验证中的准确性和鲁棒性挑战，提出 Robust Cross-Validation (RCV) 方法，以提升时间序列因果发现的可靠性。研究开发了 RCV-VarLiNGAM 和 RCV-PCMCI 算法，这些扩展基于现有因果发现技术，减少噪声影响，并整合到一个增强的 ABM 验证框架中，支持处理高维和时间依赖数据。实验结果显示，该方法在合成数据集和复杂模拟 fMRI 数据集上表现出更高的因果结构识别可靠性，并分析了数据集特性（如线性、噪声分布、平稳性和因果结构密度）对性能的影响，最终为复杂系统分析中的模型驱动决策提供更坚实的支撑。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "econ.EM",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19412v1",
      "published_date": "2024-10-25 09:13:26 UTC",
      "updated_date": "2024-10-25 09:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:41:58.518993"
    },
    {
      "arxiv_id": "2410.19400v4",
      "title": "Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiu Mao",
        "Qi Wang",
        "Chen Chen",
        "Yun Qu",
        "Xiangyang Ji"
      ],
      "abstract": "In offline reinforcement learning (RL), addressing the out-of-distribution\n(OOD) action issue has been a focus, but we argue that there exists an OOD\nstate issue that also impairs performance yet has been underexplored. Such an\nissue describes the scenario when the agent encounters states out of the\noffline dataset during the test phase, leading to uncontrolled behavior and\nperformance degradation. To this end, we propose SCAS, a simple yet effective\napproach that unifies OOD state correction and OOD action suppression in\noffline RL. Technically, SCAS achieves value-aware OOD state correction,\ncapable of correcting the agent from OOD states to high-value in-distribution\nstates. Theoretical and empirical results show that SCAS also exhibits the\neffect of suppressing OOD actions. On standard offline RL benchmarks, SCAS\nachieves excellent performance without additional hyperparameter tuning.\nMoreover, benefiting from its OOD state correction feature, SCAS demonstrates\nenhanced robustness against environmental perturbations.",
      "tldr_zh": "该论文关注离线强化学习（offline RL）中的OOD state问题，认为其与OOD action问题一样会损害性能，但尚未得到充分探讨。作者提出SCAS方法，该方法统一了value-aware OOD state correction和OOD action suppression，通过将代理从OOD states修正到高价值in-distribution states来提升表现。实验结果显示，SCAS在标准离线RL基准上表现出色，无需额外超参数调整，并显著增强了环境扰动下的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19400v4",
      "published_date": "2024-10-25 09:01:37 UTC",
      "updated_date": "2024-11-01 07:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:44:08.834795"
    },
    {
      "arxiv_id": "2410.19394v2",
      "title": "Analysis of Financial Risk Behavior Prediction Using Deep Learning and Big Data Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Yang",
        "Zhan Cheng",
        "Zhaoyang Zhang",
        "Yuanshuai Luo",
        "Shuaishuai Huang",
        "Ao Xiang"
      ],
      "abstract": "As the complexity and dynamism of financial markets continue to grow,\ntraditional financial risk prediction methods increasingly struggle to handle\nlarge datasets and intricate behavior patterns. This paper explores the\nfeasibility and effectiveness of using deep learning and big data algorithms\nfor financial risk behavior prediction. First, the application and advantages\nof deep learning and big data algorithms in the financial field are analyzed.\nThen, a deep learning-based big data risk prediction framework is designed and\nexperimentally validated on actual financial datasets. The experimental results\nshow that this method significantly improves the accuracy of financial risk\nbehavior prediction and provides valuable support for risk management in\nfinancial institutions. Challenges in the application of deep learning are also\ndiscussed, along with potential directions for future research.",
      "tldr_zh": "该论文分析了传统金融风险预测方法在处理大数据和复杂行为模式时的局限性，并探讨了使用深度学习和大数据算法的可行性与有效性。通过分析这些算法在金融领域的应用优势，该研究设计了一个基于深度学习的金融风险行为预测框架，并在实际数据集上进行实验验证。结果显示，该框架显著提高了预测准确率，为金融机构的风险管理提供了有力支持；同时，论文讨论了深度学习应用的挑战，并提出了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19394v2",
      "published_date": "2024-10-25 08:52:04 UTC",
      "updated_date": "2024-12-23 03:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:44:20.359937"
    },
    {
      "arxiv_id": "2410.19390v1",
      "title": "CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation",
      "title_zh": "CLAP. I. 解决基于深度学习的星系光度学",
      "authors": [
        "Qiufan Lin",
        "Hengxin Ruan",
        "Dominique Fouchez",
        "Shupei Chen",
        "Rui Li",
        "Paulo Montero-Camacho",
        "Nicola R. Napolitano",
        "Yuan-Sen Ting",
        "Wei Zhang"
      ],
      "abstract": "Obtaining well-calibrated photometric redshift probability densities for\ngalaxies without a spectroscopic measurement remains a challenge. Deep learning\ndiscriminative models, typically fed with multi-band galaxy images, can produce\noutputs that mimic probability densities and achieve state-of-the-art accuracy.\nHowever, such models may be affected by miscalibration that would result in\ndiscrepancies between the model outputs and the actual distributions of true\nredshifts. Our work develops a novel method called the Contrastive Learning and\nAdaptive KNN for Photometric Redshift (CLAP) that resolves this issue. It\nleverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)\nto construct and calibrate raw probability density estimates, and implements a\nrefitting procedure to resume end-to-end discriminative models ready to produce\nfinal estimates for large-scale imaging data. The harmonic mean is adopted to\ncombine an ensemble of estimates from multiple realisations for improving\naccuracy. Our experiments demonstrate that CLAP takes advantage of both deep\nlearning and KNN, outperforming benchmark methods on the calibration of\nprobability density estimates and retaining high accuracy and computational\nefficiency. With reference to CLAP, we point out that miscalibration is\nparticularly sensitive to the method-induced excessive correlations among data\ninstances in addition to the unaccounted-for epistemic uncertainties. Reducing\nthe uncertainties may not guarantee the removal of miscalibration due to the\npresence of such excessive correlations, yet this is a problem for conventional\ndeep learning methods rather than CLAP. These discussions underscore the\nrobustness of CLAP for obtaining photometric redshift probability densities\nrequired by astrophysical and cosmological applications. This is the first\npaper in our series on CLAP.",
      "tldr_zh": "本研究提出 CLAP 方法，用于解决深度学习模型在星系光度红移估计（Photometric Redshift Estimation）中的校准问题，该问题会导致模型输出与实际红移分布不符。CLAP 结合监督对比学习（Supervised Contrastive Learning, SCL）和 k-Nearest Neighbours (KNN) 来构建并校准原始概率密度估计，并通过重拟合过程恢复端到端的判别模型，同时采用调和均值整合多个估计以提升准确性。实验结果显示，CLAP 优于基准方法，在概率密度估计的校准上表现出色，同时保持高准确性和计算效率。该方法强调过度数据相关性对校准的影响，并证明 CLAP 在天体物理和宇宙学应用中更具鲁棒性，作为系列论文的第一篇，为改进光度红移估计奠定基础。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "22 + 6 pages, 9 + 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19390v1",
      "published_date": "2024-10-25 08:46:55 UTC",
      "updated_date": "2024-10-25 08:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:44:33.500475"
    },
    {
      "arxiv_id": "2410.19385v1",
      "title": "Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Barkley",
        "Brink van der Merwe"
      ],
      "abstract": "Large Language Models (LLMs) are powerful computational models trained on\nextensive corpora of human-readable text, enabling them to perform\ngeneral-purpose language understanding and generation. LLMs have garnered\nsignificant attention in both industry and academia due to their exceptional\nperformance across various natural language processing (NLP) tasks. Despite\nthese successes, LLMs often produce inaccuracies, commonly referred to as\nhallucinations. Prompt engineering, the process of designing and formulating\ninstructions for LLMs to perform specific tasks, has emerged as a key approach\nto mitigating hallucinations. This paper provides a comprehensive empirical\nevaluation of different prompting strategies and frameworks aimed at reducing\nhallucinations in LLMs. Various prompting techniques are applied to a broad set\nof benchmark datasets to assess the accuracy and hallucination rate of each\nmethod. Additionally, the paper investigates the influence of tool-calling\nagents (LLMs augmented with external tools to enhance their capabilities beyond\nlanguage generation) on hallucination rates in the same benchmarks. The\nfindings demonstrate that the optimal prompting technique depends on the type\nof problem, and that simpler techniques often outperform more complex methods\nin reducing hallucinations. Furthermore, it is shown that LLM agents can\nexhibit significantly higher hallucination rates due to the added complexity of\nexternal tool usage.",
      "tldr_zh": "这篇论文调查了提示工程(prompting)和外部工具在Large Language Models (LLMs)幻觉(hallucinations)率中的作用，通过实证评估各种提示策略在基准数据集上的表现，以评估其准确性和幻觉率。研究还探讨了tool-calling agents（使用外部工具增强LLMs能力的代理）对幻觉率的影响。结果显示，最佳prompting技术取决于问题类型，简单方法通常比复杂方法更有效，而外部工具的使用可能显著增加幻觉率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19385v1",
      "published_date": "2024-10-25 08:34:53 UTC",
      "updated_date": "2024-10-25 08:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:44:44.410809"
    },
    {
      "arxiv_id": "2410.19384v1",
      "title": "Learning Neural Strategy-Proof Matching Mechanism from Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Ryota Maruo",
        "Koh Takeuchi",
        "Hisashi Kashima"
      ],
      "abstract": "Designing effective two-sided matching mechanisms is a major problem in\nmechanism design, and the goodness of matching cannot always be formulated.\n  The existing work addresses this issue by searching over a parameterized\nfamily of mechanisms with certain properties by learning to fit a human-crafted\ndataset containing examples of preference profiles and matching results.\n  However, this approach does not consider a strategy-proof mechanism,\nimplicitly assumes the number of agents to be a constant, and does not consider\nthe public contextual information of the agents.\n  In this paper, we propose a new parametric family of strategy-proof matching\nmechanisms by extending the serial dictatorship (SD).\n  We develop a novel attention-based neural network called NeuralSD, which can\nlearn a strategy-proof mechanism from a human-crafted dataset containing public\ncontextual information.\n  NeuralSD is constructed by tensor operations that make SD differentiable and\nlearns a parameterized mechanism by estimating an order of SD from the\ncontextual information.\n  We conducted experiments to learn a strategy-proof matching from matching\nexamples with different numbers of agents.\n  We demonstrated that our method shows the superiority of learning with\ncontext-awareness over a baseline in terms of regression performance and other\nmetrics.",
      "tldr_zh": "本文提出了一种新的参数化 Strategy-Proof 匹配机制，通过扩展 Serial Dictatorship (SD) 来解决现有机制在策略证明、代理数量变化和公共上下文信息方面的局限性。研究开发了 NeuralSD，一个基于注意力的神经网络，利用张量操作使 SD 可微分，并从人类制作的数据集中学习机制顺序，以处理带有上下文信息的匹配任务。实验结果显示，NeuralSD 在不同代理数量的匹配示例上，显著优于基线模型，在回归性能和其他指标方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19384v1",
      "published_date": "2024-10-25 08:34:25 UTC",
      "updated_date": "2024-10-25 08:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:44:57.045122"
    },
    {
      "arxiv_id": "2410.19382v2",
      "title": "Multi-Agent Reinforcement Learning with Selective State-Space Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jemma Daniel",
        "Ruan de Kock",
        "Louay Ben Nessir",
        "Sasha Abramowitz",
        "Omayma Mahjoub",
        "Wiem Khlifi",
        "Claude Formanek",
        "Arnu Pretorius"
      ],
      "abstract": "The Transformer model has demonstrated success across a wide range of\ndomains, including in Multi-Agent Reinforcement Learning (MARL) where the\nMulti-Agent Transformer (MAT) has emerged as a leading algorithm in the field.\nHowever, a significant drawback of Transformer models is their quadratic\ncomputational complexity relative to input size, making them computationally\nexpensive when scaling to larger inputs. This limitation restricts MAT's\nscalability in environments with many agents. Recently, State-Space Models\n(SSMs) have gained attention due to their computational efficiency, but their\napplication in MARL remains unexplored. In this work, we investigate the use of\nMamba, a recent SSM, in MARL and assess whether it can match the performance of\nMAT while providing significant improvements in efficiency. We introduce a\nmodified version of MAT that incorporates standard and bi-directional Mamba\nblocks, as well as a novel \"cross-attention\" Mamba block. Extensive testing\nshows that our Multi-Agent Mamba (MAM) matches the performance of MAT across\nmultiple standard multi-agent environments, while offering superior scalability\nto larger agent scenarios. This is significant for the MARL community, because\nit indicates that SSMs could replace Transformers without compromising\nperformance, whilst also supporting more effective scaling to higher numbers of\nagents. Our project page is available at\nhttps://sites.google.com/view/multi-agent-mamba .",
      "tldr_zh": "本文研究了在多智能体强化学习(MARL)中，使用状态空间模型(SSMs)如Mamba来解决Transformer模型的二次计算复杂度问题，从而提升可扩展性。研究者开发了Multi-Agent Mamba(MAM)，它基于Multi-Agent Transformer(MAT)进行了修改，加入了标准、双向Mamba块以及一个新颖的“cross-attention”Mamba块。实验结果显示，MAM在多个标准MARL环境中与MAT性能相当，但对更大代理数量的场景具有显著更好的扩展性。这为MARL社区提供了重要启示，即SSMs可作为Transformer的替代方案，实现高效扩展而不牺牲表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19382v2",
      "published_date": "2024-10-25 08:32:21 UTC",
      "updated_date": "2024-10-28 11:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:45:10.724111"
    },
    {
      "arxiv_id": "2410.19367v1",
      "title": "BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training",
      "title_zh": "翻译失败",
      "authors": [
        "Houming Wu",
        "Ling Chen",
        "Wenjie Yu"
      ],
      "abstract": "With the increasing scale of models, the need for efficient distributed\ntraining has become increasingly urgent. Recently, many synchronous pipeline\nparallelism approaches have been proposed to improve training throughput.\nHowever, these approaches still suffer from two major issues, i.e., pipeline\nbubbles caused by periodic flushing and extra communication due to the\nincreasing number of pipeline stages. To this end, we propose BitPipe, a\nbidirectional interleaved pipeline parallelism for accelerating large models\ntraining. Specifically, a hybrid scheme of fusing interleaved pipelines with\nbidirectional pipelines is proposed to reduce the computational time of each\nsingle micro-batch and multiply the number of devices executing simultaneously.\nA V-shaped schedule with eager gradient synchronization is introduced to reduce\nand overlap the communication between devices. Experiments conducted on up to\n32 GPUs show that BitPipe improves the training throughput of GPT-style and\nBERT-style models by 1.05x-1.28x compared to the state-of-the-art synchronous\napproaches. The code of our implementation is available at\nhttps://github.com/wuhouming/BitPipe.",
      "tldr_zh": "本论文针对大型模型训练中同步流水线并行方法存在的pipeline bubbles和额外通信问题，提出BitPipe，一种bidirectional interleaved pipeline parallelism框架。BitPipe采用融合交错管道和双向管道的混合方案，以减少每个micro-batch的计算时间并增加同时执行的设备数量，同时引入V-shaped schedule和eager gradient synchronization来减少并重叠设备间通信。实验结果显示，在多达32个GPU上，BitPipe将GPT-style和BERT-style模型的训练吞吐量比最先进方法提高了1.05x-1.28x。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19367v1",
      "published_date": "2024-10-25 08:08:51 UTC",
      "updated_date": "2024-10-25 08:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:45:21.978730"
    },
    {
      "arxiv_id": "2410.19361v2",
      "title": "Engineering Trustworthy AI: A Developer Guide for Empirical Risk Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Diana Pfau",
        "Alexander Jung"
      ],
      "abstract": "AI systems increasingly shape critical decisions across personal and societal\ndomains. While empirical risk minimization (ERM) drives much of the AI success,\nit typically prioritizes accuracy over trustworthiness, often resulting in\nbiases, opacity, and other adverse effects. This paper discusses how key\nrequirements for trustworthy AI can be translated into design choices for the\ncomponents of ERM. We hope to provide actionable guidance for building AI\nsystems that meet emerging standards for trustworthiness of AI.",
      "tldr_zh": "这篇论文探讨了Empirical Risk Minimization (ERM) 在AI系统中优先准确性而忽略可信性问题，导致偏见、不透明和其他负面影响的问题。作者提供了行动指南，将可信AI的关键要求转化为ERM组件的设计选择，从而帮助开发者构建更可靠的AI系统。最终，该指南旨在提升AI的整体信任度，以满足不断演进的可信AI标准。",
      "categories": [
        "cs.AI",
        "I.2; K.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19361v2",
      "published_date": "2024-10-25 07:53:32 UTC",
      "updated_date": "2024-11-06 18:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:45:32.244112"
    },
    {
      "arxiv_id": "2410.19360v1",
      "title": "LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijie Chen",
        "Xinglin Zhang"
      ],
      "abstract": "This paper proposes a novel approach for designing Single-Parameterized\nKolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function\n(SFunc) constructed from trigonometric functions. Three new SKAN variants are\ndeveloped: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on\nthe MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and\ncomputational efficiency. Specifically, LArctan-SKAN significantly improves\ntest set accuracy over existing models, outperforming all pure KAN variants\ncompared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed\nMLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore,\nLArctan-SKAN exhibits remarkable computational efficiency, with a training\nspeed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN,\nrespectively. These results confirm the effectiveness and potential of SKANs\nconstructed with trigonometric functions. The experiment code is available at\nhttps://github.com/chikkkit/LArctan-SKAN .",
      "tldr_zh": "本论文提出了一种简洁高效的单参数化 Kolmogorov-Arnold Networks (SKAN)，通过使用可学习的三角函数构建 Single-Parameterized Function (SFunc)，开发了三个新变体：LSin-SKAN、LCos-SKAN 和 LArctan-SKAN。实验在 MNIST 数据集上验证了这些模型，其中 LArctan-SKAN 在准确性和计算效率方面表现出色，测试准确率超过了纯 KAN 变体（如 FourierKAN、LSS-SKAN 和 Spl-KAN）以及混合 MLP 模型（如 MLP+rKAN 和 MLP+fKAN）。此外，LArctan-SKAN 的训练速度比 MLP+rKAN 提高了 535.01%，比 MLP+fKAN 提高了 49.55%，证明了其在效率上的显著优势。实验代码可在 GitHub 仓库（https://github.com/chikkkit/LArctan-SKAN）获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 3 figures, experiment code is available at\n  https://github.com/chikkkit/LArctan-SKAN",
      "pdf_url": "http://arxiv.org/pdf/2410.19360v1",
      "published_date": "2024-10-25 07:41:56 UTC",
      "updated_date": "2024-10-25 07:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:45:48.139191"
    },
    {
      "arxiv_id": "2410.19353v1",
      "title": "Interleaving Text and Number Embeddings to Solve Mathemathics Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Marvin Alberts",
        "Gianmarco Gabrieli",
        "Irina Espejo Morales"
      ],
      "abstract": "Integrating text and numbers effectively is a crucial step towards enhancing\nLarge Language Models (LLMs) capabilities in assisting in scientific tasks.\nWhile most current approaches rely on discrete tokenization of numbers, for\ninstance, conversion to scientific notation or base 10-decomposition, a recent\napproach proposed a continuous numerical encoding as an inductive bias. In this\npaper, we build upon this approach by introducing more expressive numerical\nembeddings. Our method addresses key shortcomings, including the elimination of\nnumerical artefacts and the ability to handle a wide range of magnitudes\nwithout clipping.\n  Our work presents two key contributions. First, we employ an MLP to assign\ndistinct directions in the embedding space to different numbers. Our second\ncontribution is the introduction of a routing layer that differentiates between\nnumerical and text embeddings. We hypothesise that this combined approach\nenables the model to distinguish between text and number distributions while\nmaintaining its capacity for arithmetic operations.\n  Using only a 45 M parameter encoder-decoder architecture our method achieves\na $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition,\nwe empirically observe a reduction of the numerical artefacts and biases\nobserved compared to the baselines.",
      "tldr_zh": "本研究旨在提升大型语言模型 (LLMs) 在科学任务中的能力，通过改进数字嵌入方法来整合文本和数字。论文提出两种关键贡献：首先，使用多层感知机 (MLP) 为不同数字分配独特的嵌入空间方向，以消除数字伪像并处理广泛的量级范围；其次，引入路由层来区分数字和文本嵌入，从而帮助模型同时维持算术运算能力。实验结果显示，使用一个45 M参数的编码器-解码器架构，该方法在$10^{-3}$至$10^{8}$的量级范围内达到$R^2$=0.9988，并显著减少了基线模型的数字偏差和伪像。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19353v1",
      "published_date": "2024-10-25 07:21:57 UTC",
      "updated_date": "2024-10-25 07:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:45:58.660719"
    },
    {
      "arxiv_id": "2410.19352v1",
      "title": "Interpreting Neural Networks through Mahalanobis Distance",
      "title_zh": "翻译失败",
      "authors": [
        "Alan Oursland"
      ],
      "abstract": "This paper introduces a theoretical framework that connects neural network\nlinear layers with the Mahalanobis distance, offering a new perspective on\nneural network interpretability. While previous studies have explored\nactivation functions primarily for performance optimization, our work\ninterprets these functions through statistical distance measures, a less\nexplored area in neural network research. By establishing this connection, we\nprovide a foundation for developing more interpretable neural network models,\nwhich is crucial for applications requiring transparency. Although this work is\ntheoretical and does not include empirical data, the proposed distance-based\ninterpretation has the potential to enhance model robustness, improve\ngeneralization, and provide more intuitive explanations of neural network\ndecisions.",
      "tldr_zh": "这篇论文提出一个理论框架，将神经网络的线性层与 Mahalanobis Distance 联系起来，提供神经网络可解释性的新视角。不同于以往主要关注激活函数的性能优化，本研究通过统计距离测量来解读激活函数，这是一个较少探索的领域。该框架为开发更可解释的神经网络模型奠定基础，有助于提升模型的鲁棒性、泛化能力和决策解释的直观性，尽管该工作是纯理论性的，没有实证数据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, October 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19352v1",
      "published_date": "2024-10-25 07:21:44 UTC",
      "updated_date": "2024-10-25 07:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:46:08.122836"
    },
    {
      "arxiv_id": "2410.19349v1",
      "title": "pEBR: A Probabilistic Approach to Embedding Based Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Yunjing Jiang",
        "Mingming Li",
        "Haowei Yuan",
        "Wen-Yun Yang"
      ],
      "abstract": "Embedding retrieval aims to learn a shared semantic representation space for\nboth queries and items, thus enabling efficient and effective item retrieval\nusing approximate nearest neighbor (ANN) algorithms. In current industrial\npractice, retrieval systems typically retrieve a fixed number of items for\ndifferent queries, which actually leads to insufficient retrieval (low recall)\nfor head queries and irrelevant retrieval (low precision) for tail queries.\nMostly due to the trend of frequentist approach to loss function designs, till\nnow there is no satisfactory solution to holistically address this challenge in\nthe industry. In this paper, we move away from the frequentist approach, and\ntake a novel \\textbf{p}robabilistic approach to \\textbf{e}mbedding\n\\textbf{b}ased \\textbf{r}etrieval (namely \\textbf{pEBR}) by learning the item\ndistribution for different queries, which enables a dynamic cosine similarity\nthreshold calculated by the probabilistic cumulative distribution function\n(CDF) value. The experimental results show that our approach improves both the\nretrieval precision and recall significantly. Ablation studies also illustrate\nhow the probabilistic approach is able to capture the differences between head\nand tail queries.",
      "tldr_zh": "本研究针对嵌入式检索（Embedding retrieval）中的问题，提出了一种概率方法（probabilistic approach）名为 pEBR，以解决现有系统为不同查询检索固定数量物品导致的 head queries 低召回（low recall）和 tail queries 低精度（low precision）问题。该方法通过学习不同查询的物品分布，并利用概率累积分布函数（CDF）计算动态余弦相似度阈值，实现更精确的近似最近邻（ANN）检索。实验结果显示，pEBR 显著提高了检索精度和召回率，消融研究进一步证明了它能有效捕捉 head 和 tail queries 的差异。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19349v1",
      "published_date": "2024-10-25 07:14:12 UTC",
      "updated_date": "2024-10-25 07:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:46:20.970406"
    },
    {
      "arxiv_id": "2410.19343v1",
      "title": "High Resolution Seismic Waveform Generation using Denoising Diffusion",
      "title_zh": "基于去噪扩散的高分辨率地震波形生成",
      "authors": [
        "Andreas Bergmeister",
        "Kadek Hendrawan Palgunadi",
        "Andrea Bosisio",
        "Laura Ermert",
        "Maria Koroni",
        "Nathanaël Perraudin",
        "Simon Dirmeier",
        "Men-Andrin Meier"
      ],
      "abstract": "Accurate prediction and synthesis of seismic waveforms are crucial for\nseismic hazard assessment and earthquake-resistant infrastructure design.\nExisting prediction methods, such as Ground Motion Models and physics-based\nsimulations, often fail to capture the full complexity of seismic wavefields,\nparticularly at higher frequencies. This study introduces a novel, efficient,\nand scalable generative model for high-frequency seismic waveform generation.\nOur approach leverages a spectrogram representation of seismic waveform data,\nwhich is reduced to a lower-dimensional submanifold via an autoencoder. A\nstate-of-the-art diffusion model is trained to generate this latent\nrepresentation, conditioned on key input parameters: earthquake magnitude,\nrecording distance, site conditions, and faulting type. The model generates\nwaveforms with frequency content up to 50 Hz. Any scalar ground motion\nstatistic, such as peak ground motion amplitudes and spectral accelerations,\ncan be readily derived from the synthesized waveforms. We validate our model\nusing commonly used seismological metrics, and performance metrics from image\ngeneration studies. Our results demonstrate that our openly available model can\ngenerate distributions of realistic high-frequency seismic waveforms across a\nwide range of input parameters, even in data-sparse regions. For the scalar\nground motion statistics commonly used in seismic hazard and earthquake\nengineering studies, we show that the model accurately reproduces both the\nmedian trends of the real data and its variability. To evaluate and compare the\ngrowing number of this and similar 'Generative Waveform Models' (GWM), we argue\nthat they should generally be openly available and that they should be included\nin community efforts for ground motion model evaluations.",
      "tldr_zh": "本文提出了一种基于 Denoising Diffusion 的生成模型，用于高效合成高频地震波形，以解决现有 Ground Motion Models 和物理模拟在捕捉复杂波场方面的不足。该模型通过 autoencoder 将地震波形频谱图简化为低维子流形，然后使用条件 diffusion model 生成波形，基于输入参数如地震震级、记录距离、场地条件和断层类型，输出频率高达 50 Hz 的波形，并可导出峰值地面运动幅度等统计指标。实验验证显示，该模型能准确再现真实数据的中间趋势和变异性，即使在数据稀缺区域也能生成现实波形分布。作者主张此类 Generative Waveform Models 应公开可用，并纳入社区评估努力，以促进地震灾害评估和工程应用。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19343v1",
      "published_date": "2024-10-25 07:01:48 UTC",
      "updated_date": "2024-10-25 07:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:46:34.341691"
    },
    {
      "arxiv_id": "2410.19318v1",
      "title": "Two are better than one: Context window extension with multi-grained self-injection",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Han",
        "Pan Zhou",
        "Soujanya Poria",
        "Shuicheng Yan"
      ],
      "abstract": "The limited context window of contemporary large language models (LLMs)\nremains a huge barrier to their broader application across various domains.\nWhile continual pre-training on long-context data is a straightforward and\neffective solution, it incurs substantial costs in terms of data acquisition\nand computational resources. To alleviate this issue, we propose SharedLLM, a\nnovel approach grounded in the design philosophy of multi-grained context\ncompression and query-aware information retrieval. SharedLLM is composed of two\nshort-context LLMs such as LLaMA-2, termed upper model and lower model. The\nlower model functions as a compressor while the upper model acts as a decoder.\nThe upper model receives compressed, multi-grained context information from the\nlower model and performs context-aware modeling on the running text.\nInformation transfer between the compressor and decoder occurs only at the\nlowest layers to refrain from long forward paths in the lower model and\nredundant cross-attention modules in the upper model. Based on this\narchitecture, we introduce a specialized tree-style data structure to\nefficiently encode, store and retrieve multi-grained contextual information for\ntext chunks. This structure, combined with a search algorithm, enables rapid\nencoding and retrieval of relevant information from various levels of the tree\nbased on the input query. This entire process, wherein the sender and receiver\nare derived from the same LLM layer, is referred to as self-injection.",
      "tldr_zh": "该论文提出 SharedLLM，一种创新方法，通过 multi-grained self-injection 扩展大型语言模型 (LLMs) 的上下文窗口，以解决其有限上下文的限制问题。该方法采用两个短上下文 LLM：lower model 作为压缩器负责多粒度上下文信息的编码和存储，而 upper model 作为解码器进行查询感知的建模和检索。信息传输仅在最低层进行，并结合树式数据结构实现高效的编码、存储和查询过程，从而避免了持续预训练的高成本。整体架构通过 self-injection 机制提升了信息处理的效率和准确性，为LLMs在长上下文任务中的应用提供了可行路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The code is available at https://github.com/Clement25/SharedLLM",
      "pdf_url": "http://arxiv.org/pdf/2410.19318v1",
      "published_date": "2024-10-25 06:08:59 UTC",
      "updated_date": "2024-10-25 06:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:46:45.689715"
    },
    {
      "arxiv_id": "2410.19315v2",
      "title": "Brain-like variational inference",
      "title_zh": "脑似变分推断",
      "authors": [
        "Hadi Vafaii",
        "Dekel Galor",
        "Jacob L. Yates"
      ],
      "abstract": "Inference in both brains and machines can be formalized by optimizing a\nshared objective: maximizing the evidence lower bound (ELBO) in machine\nlearning, or minimizing variational free energy (F) in neuroscience (ELBO =\n-F). While this equivalence suggests a unifying framework, it leaves open how\ninference is implemented in neural systems. Here, we show that online natural\ngradient descent on F, under Poisson assumptions, leads to a recurrent spiking\nneural network that performs variational inference via membrane potential\ndynamics. The resulting model -- the iterative Poisson variational autoencoder\n(iP-VAE) -- replaces the encoder network with local updates derived from\nnatural gradient descent on F. Theoretically, iP-VAE yields a number of\ndesirable features such as emergent normalization via lateral competition, and\nhardware-efficient integer spike count representations. Empirically, iP-VAE\noutperforms both standard VAEs and Gaussian-based predictive coding models in\nsparsity, reconstruction, and biological plausibility. iP-VAE also exhibits\nstrong generalization to out-of-distribution inputs, exceeding hybrid\niterative-amortized VAEs. These results demonstrate how deriving inference\nalgorithms from first principles can yield concrete architectures that are\nsimultaneously biologically plausible and empirically effective.",
      "tldr_zh": "该研究将大脑和机器的推理形式化为优化证据下界 (ELBO) 或最小化变分自由能 (F) 的统一框架。作者提出迭代 Poisson 变分自编码器 (iP-VAE) 模型，通过在线自然梯度下降和 Poisson 假设，实现基于膜电位动态的变分推理，从而替换传统编码器网络。iP-VAE 理论上支持突发标准化 (emergent normalization) 和硬件高效的整数 spike count 表示，在实验中优于标准 VAEs 和 Gaussian-based 预测编码模型，尤其在稀疏性、重构、生物合理性和泛化能力方面表现出色。总的来说，该模型从第一原则推导出的架构兼具生物可信性和实际有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19315v2",
      "published_date": "2024-10-25 06:00:18 UTC",
      "updated_date": "2025-05-16 04:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:46:57.201416"
    },
    {
      "arxiv_id": "2410.19313v3",
      "title": "COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training",
      "title_zh": "翻译失败",
      "authors": [
        "Haocheng Xi",
        "Han Cai",
        "Ligeng Zhu",
        "Yao Lu",
        "Kurt Keutzer",
        "Jianfei Chen",
        "Song Han"
      ],
      "abstract": "FP8 training has emerged as a promising method for improving training\nefficiency. Existing frameworks accelerate training by applying FP8 computation\nto linear layers while leaving optimizer states and activations in higher\nprecision, which fails to fully optimize memory usage. This paper introduces\nCOAT (Compressing Optimizer States and Activations for FP8 Training), a novel\nFP8 training framework designed to significantly reduce memory footprint when\ntraining large models. COAT addresses current limitations through two key\ninnovations: (1) Dynamic Range Expansion, which aligns optimizer state\ndistributions more closely with the FP8 representation range, thereby reducing\nquantization error, and (2) Mixed-Granularity Activation Quantization, which\noptimizes activation memory using a combination of per-tensor and per-group\nquantization strategies. Experiments demonstrate that COAT effectively reduces\nend-to-end training memory footprint by 1.54x compared to BF16 while achieving\nnearly lossless performance across various tasks, such as Large Language Model\npretraining and fine-tuning and Vision Language Model training. COAT also\nachieves a 1.43x end-to-end training speedup compared to BF16, performing on\npar with or surpassing TransformerEngine's speedup. COAT enables efficient\nfull-parameter training of large models on fewer GPUs, and facilitates doubling\nthe batch size in distributed training settings, providing a practical solution\nfor scaling large-scale model training. The code is available at\nhttps://github.com/NVlabs/COAT.",
      "tldr_zh": "本文提出 COAT，一种新型 FP8 训练框架，旨在通过压缩优化器状态和激活来显著降低大型模型训练的内存占用。COAT 的关键创新包括 Dynamic Range Expansion，用于调整优化器状态分布以减少量化错误，以及 Mixed-Granularity Activation Quantization，通过结合 per-tensor 和 per-group 策略优化激活内存。实验结果显示，COAT 相较于 BF16 减少了 1.54 倍端到端训练内存占用，同时在大型语言模型预训练、微调和视觉语言模型训练等任务中实现几乎无损性能，并获得 1.43 倍训练加速，支持在更少 GPU 上进行全参数训练并加倍分布式训练批次大小。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025. 22 pages. 9 Figures. 13 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19313v3",
      "published_date": "2024-10-25 05:59:30 UTC",
      "updated_date": "2025-02-12 23:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:47:09.196979"
    },
    {
      "arxiv_id": "2411.07245v1",
      "title": "Navigating AI in Social Work and Beyond: A Multidisciplinary Review",
      "title_zh": "在社会工作及更广泛领域导航人工智能：一项多学科综述",
      "authors": [
        "Matt Victor Dalziel",
        "Krystal Schaffer",
        "Neil Martin"
      ],
      "abstract": "This review began with the modest goal of drafting a brief commentary on how\nthe social work profession engages with and is impacted by artificial\nintelligence (AI). However, it quickly became apparent that a deeper\nexploration was required to adequately capture the profound influence of AI,\none of the most transformative and debated innovations in modern history. As a\nresult, this review evolved into an interdisciplinary endeavour, gathering\nseminal texts, critical articles, and influential voices from across industries\nand academia. This review aims to provide a comprehensive yet accessible\noverview, situating AI within broader societal and academic conversations as\n2025 dawns. We explore perspectives from leading tech entrepreneurs, cultural\nicons, CEOs, and politicians alongside the pioneering contributions of AI\nengineers, innovators, and academics from fields as diverse as mathematics,\nsociology, philosophy, economics, and more. This review also briefly analyses\nAI's real-world impacts, ethical challenges, and implications for social work.\nIt presents a vision for AI-facilitated simulations that could transform social\nwork education through Advanced Personalised Simulation Training (APST). This\ntool uses AI to tailor high-fidelity simulations to individual student needs,\nproviding real-time feedback and preparing them for the complexities of their\nfuture practice environments. We maintain a critical tone throughout, balancing\nour awe of AI's remarkable advancements with necessary caution. As AI continues\nto permeate every professional realm, understanding its subtleties, challenges,\nand opportunities becomes essential. Those who fully grasp the intricacies of\nthis technology will be best positioned to navigate the impending AI Era.",
      "tldr_zh": "这篇综述探讨了人工智能（AI）在社会工作领域的应用及其更广泛的社会影响，通过跨学科视角整合了技术企业家、文化名人、CEO、政治家以及AI工程师和学术界（如数学、社会学、哲学和经济学）的观点。论文分析了AI的实际影响、伦理挑战，并提出Advanced Personalised Simulation Training (APST)作为一种AI驱动的个性化模拟工具，以提升社会工作教育的真实性和反馈机制。最终，作者强调在AI时代理解其复杂性至关重要，以帮助专业人士应对机遇与风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.07245v1",
      "published_date": "2024-10-25 05:51:23 UTC",
      "updated_date": "2024-10-25 05:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:47:21.439753"
    },
    {
      "arxiv_id": "2410.19310v1",
      "title": "Flow Generator Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Zemin Huang",
        "Zhengyang Geng",
        "Weijian Luo",
        "Guo-jun Qi"
      ],
      "abstract": "In the realm of Artificial Intelligence Generated Content (AIGC),\nflow-matching models have emerged as a powerhouse, achieving success due to\ntheir robust theoretical underpinnings and solid ability for large-scale\ngenerative modeling. These models have demonstrated state-of-the-art\nperformance, but their brilliance comes at a cost. The process of sampling from\nthese models is notoriously demanding on computational resources, as it\nnecessitates the use of multi-step numerical ordinary differential equations\n(ODEs). Against this backdrop, this paper presents a novel solution with\ntheoretical guarantees in the form of Flow Generator Matching (FGM), an\ninnovative approach designed to accelerate the sampling of flow-matching models\ninto a one-step generation, while maintaining the original performance. On the\nCIFAR10 unconditional generation benchmark, our one-step FGM model achieves a\nnew record Fr\\'echet Inception Distance (FID) score of 3.08 among few-step\nflow-matching-based models, outperforming original 50-step flow-matching\nmodels. Furthermore, we use the FGM to distill the Stable Diffusion 3, a\nleading text-to-image flow-matching model based on the MM-DiT architecture. The\nresulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding\nindustry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM\nhas delivered remarkable generating qualities, rivaling other multi-step models\nin light of the efficiency of a single generation step.",
      "tldr_zh": "本文提出 Flow Generator Matching (FGM)，一种创新方法，用于加速 flow-matching 模型的采样过程，将多步数值 ODE 生成简化为一步，同时提供理论保证并保持原性能。在 CIFAR10 无条件生成基准上，FGM 一步模型的 Fréchet Inception Distance (FID) 得分达到 3.08，优于原 50 步模型。该方法还应用于蒸馏 Stable Diffusion 3，生成 MM-DiT-FGM 一步文本到图像模型，在 GenEval 基准上表现出色，与多步模型的生成质量相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19310v1",
      "published_date": "2024-10-25 05:41:28 UTC",
      "updated_date": "2024-10-25 05:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:47:33.544743"
    },
    {
      "arxiv_id": "2410.19308v1",
      "title": "Semantics in Robotics: Environmental Data Can't Yield Conventions of Human Behaviour",
      "title_zh": "翻译失败",
      "authors": [
        "Jamie Milton Freestone"
      ],
      "abstract": "The word semantics, in robotics and AI, has no canonical definition. It\nusually serves to denote additional data provided to autonomous agents to aid\nHRI. Most researchers seem, implicitly, to understand that such data cannot\nsimply be extracted from environmental data. I try to make explicit why this is\nso and argue that so-called semantics are best understood as data comprised of\nconventions of human behaviour. This includes labels, most obviously, but also\nplaces, ontologies, and affordances. Object affordances are especially\nproblematic because they require not only semantics that are not in the\nenvironmental data (conventions of object use) but also an understanding of\nphysics and object combinations that would, if achieved, constitute artificial\nsuperintelligence.",
      "tldr_zh": "这篇论文探讨了机器人和人工智能（AI）领域的语义（semantics），指出它缺乏标准定义，通常指提供给自主代理的额外数据以辅助人机交互（HRI），但无法从环境数据中直接提取。作者论证，语义本质上是人类行为约定的表现形式，包括标签、地点、本体（ontologies）和可供性（affordances）。特别强调，物体可供性（object affordances）尤其复杂，因为它需要超出环境数据的知识，如物体使用约定和物理理解，这可能要求实现人工智能超级智能（artificial superintelligence）。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19308v1",
      "published_date": "2024-10-25 05:38:23 UTC",
      "updated_date": "2024-10-25 05:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:47:45.568096"
    },
    {
      "arxiv_id": "2411.07244v1",
      "title": "A Tutorial on Teaching Data Analytics with Generative AI",
      "title_zh": "使用生成式 AI 教授数据分析的教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程教程",
      "authors": [
        "Robert L. Bray"
      ],
      "abstract": "This tutorial addresses the challenge of incorporating large language models\n(LLMs), such as ChatGPT, in a data analytics class. It details several new\nin-class and out-of-class teaching techniques enabled by AI. For example,\ninstructors can parallelize instruction by having students interact with\ndifferent custom-made GPTs to learn different parts of an analysis and then\nteach each other what they learned from their AIs. For another example,\ninstructors can turn problem sets into AI tutoring sessions, whereby a\ncustom-made GPT guides a student through the problems, and the student uploads\nthe chatlog for their homework submission. For a third example, you can assign\ndifferent labs to each section of your class and have each section create AI\nassistants to help the other sections work through their labs. This tutorial\nadvocates the programming in the English paradigm, in which students express\nthe desired data transformations in prose and then use AI to generate the\ncorresponding code. Students can wrangle data more effectively by programming\nin English than by manipulating in Excel. However, some students will program\nin English better than others, so you will still derive a robust grade\ndistribution (at least with current LLMs).",
      "tldr_zh": "这篇教程探讨了如何在数据分析课程中整合大型语言模型(LLMs)如 ChatGPT，以提升教学效果。教程介绍了几个创新技巧，例如让学生使用自定义 GPTs 进行并行学习（即学生互动不同 AI 后互相教授知识）、将问题集转化为 AI 辅导会（学生上传聊天记录作为作业），以及让不同课程部分创建 AI 助手互助。另一个关键方法是推广“programming in the English paradigm”，让学生用散文表达数据转换，由 AI 生成代码，从而比使用 Excel 更高效地处理数据。尽管学生能力差异存在，但这种方法能产生稳健的成绩分布。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07244v1",
      "published_date": "2024-10-25 05:27:48 UTC",
      "updated_date": "2024-10-25 05:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:47:57.271711"
    },
    {
      "arxiv_id": "2410.19887v1",
      "title": "TBBC: Predict True Bacteraemia in Blood Cultures via Deep Learning",
      "title_zh": "TBBC：通过深度学习预测血培养中的真实菌血症",
      "authors": [
        "Kira Sam"
      ],
      "abstract": "Bacteraemia, a bloodstream infection with high morbidity and mortality rates,\nposes significant diagnostic challenges. Accurate diagnosis through blood\ncultures is resource-intensive. Developing a machine learning model to predict\nblood culture outcomes in emergency departments offers potential for improved\ndiagnosis, reduced healthcare costs, and mitigated antibiotic use.This thesis\naims to identify optimal machine learning techniques for predicting bacteraemia\nand develop a predictive model using data from St. Antonius Hospital's\nemergency department. Based on current literature, CatBoost and Random Forest\nwere selected as the most promising techniques. Model optimization using Optuna\nprioritized sensitivity.The final Random Forest model achieved an ROC AUC of\n0.78 and demonstrated 0.92 sensitivity on the test set. Notably, it accurately\nidentified 36.02% of patients at low risk of bacteraemia, with only 0.85% false\nnegatives.Implementation of this model in St. Antonius Hospital's emergency\ndepartment could reduce blood cultures, healthcare costs, and antibiotic\ntreatments. Future studies should focus on external validation, exploring\nadvanced techniques, and addressing potential confounders to ensure model\ngeneralizability.",
      "tldr_zh": "该研究针对血流感染（Bacteraemia）的高发病率和诊断挑战，开发了一个基于机器学习的预测模型，旨在通过分析急诊数据提高诊断准确性、降低医疗成本并减少抗生素使用。研究者选择了CatBoost和Random Forest作为主要算法，并使用Optuna优化模型，以优先提升敏感性，最终选定Random Forest模型在测试集上达到ROC AUC 0.78和敏感性0.92。结果显示，该模型能准确识别36.02%的低风险患者，仅有0.85%的假阴性，并建议在医院实施以减少血培养和不必要治疗，同时呼吁未来进行外部验证和探索高级技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19887v1",
      "published_date": "2024-10-25 05:25:01 UTC",
      "updated_date": "2024-10-25 05:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:48:09.144725"
    },
    {
      "arxiv_id": "2410.19302v2",
      "title": "TEARS: Textual Representations for Scrutable Recommendations",
      "title_zh": "TEARS：用于可解释推荐的文本表示",
      "authors": [
        "Emiliano Penaloza",
        "Olivier Gouvert",
        "Haolun Wu",
        "Laurent Charlin"
      ],
      "abstract": "Traditional recommender systems rely on high-dimensional (latent) embeddings\nfor modeling user-item interactions, often resulting in opaque representations\nthat lack interpretability. Moreover, these systems offer limited control to\nusers over their recommendations. Inspired by recent work, we introduce TExtuAl\nRepresentations for Scrutable recommendations (TEARS) to address these\nchallenges. Instead of representing a user's interests through a latent\nembedding, TEARS encodes them in natural text, providing transparency and\nallowing users to edit them. To do so, TEARS uses a modern LLM to generate user\nsummaries based on user preferences. We find the summaries capture user\npreferences uniquely. Using these summaries, we take a hybrid approach where we\nuse an optimal transport procedure to align the summaries' representation with\nthe learned representation of a standard VAE for collaborative filtering. We\nfind this approach can surpass the performance of three popular VAE models\nwhile providing user-controllable recommendations. We also analyze the\ncontrollability of TEARS through three simulated user tasks to evaluate the\neffectiveness of a user editing its summary.",
      "tldr_zh": "本研究提出 TEARS（Textual Representations for Scrutable Recommendations），一种使用自然文本表示用户兴趣的推荐系统框架，以解决传统推荐系统依赖不透明的高维隐式嵌入问题，并增强用户控制能力。TEARS 利用现代 LLM 生成基于用户偏好的文本摘要，然后采用最优传输（optimal transport）方法将这些摘要表示与标准 VAE（Variational Autoencoder）模型的表示对齐，实现混合推荐。实验结果显示，TEARS 在性能上超越三个流行 VAE 模型，同时通过三个模拟用户任务验证了用户编辑摘要的可控性和有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19302v2",
      "published_date": "2024-10-25 04:26:00 UTC",
      "updated_date": "2025-03-03 21:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:48:22.039040"
    },
    {
      "arxiv_id": "2410.19291v2",
      "title": "A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Pei",
        "Jianqi Yan",
        "Jin Yan",
        "Bailing Yang",
        "Ziyuan Li",
        "Lin Zhang",
        "Xin Liu",
        "Yang Zhang"
      ],
      "abstract": "Recently, deep learning in stock prediction has become an important branch.\nImage-based methods show potential by capturing complex visual patterns and\nspatial correlations, offering advantages in interpretability over time series\nmodels. However, image-based approaches are more prone to overfitting,\nhindering robust predictive performance. To improve accuracy, this paper\nproposes a novel method, named Sequence-based Multi-scale Fusion Regression\nConvolutional Neural Network (SMSFR-CNN), for predicting stock price movements\nin the China A-share market.\n  By utilizing CNN to learn sequential features and combining them with image\nfeatures, we improve the accuracy of stock trend prediction on the A-share\nmarket stock dataset. This approach reduces the search space for image\nfeatures, stabilizes, and accelerates the training process. Extensive\ncomparative experiments on 4,454 A-share stocks show that the model achieves a\n61.15% positive predictive value and a 63.37% negative predictive value for the\nnext 5 days, resulting in a total profit of 165.09%.",
      "tldr_zh": "本文提出了一种新型股票价格预测方法 SMSFR-CNN（Sequence-based Multi-scale Fusion Regression Convolutional Neural Network），旨在解决图像-based 模型易过拟合的问题，通过时间序列分解和多尺度 CNN 结合 OHLCT 图像特征来提升预测准确性。该方法利用 CNN 学习序列特征并与图像特征融合，减少特征搜索空间并加速训练过程，在中国 A 股市场中实现了更稳定的表现。在 4,454 支 A 股股票的实验中，模型对未来 5 天的预测达到 61.15% 阳性预测值和 63.37% 阴性预测值，总利润为 165.09%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19291v2",
      "published_date": "2024-10-25 03:50:54 UTC",
      "updated_date": "2024-10-29 08:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:48:33.879225"
    },
    {
      "arxiv_id": "2410.19283v1",
      "title": "ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study",
      "title_zh": "ST-NeRP：时空神经表示学习，结合先验嵌入，用于患者特定的影像学研究",
      "authors": [
        "Liang Qiu",
        "Liyue Shen",
        "Lianli Liu",
        "Junyan Liu",
        "Yizheng Chen",
        "Lei Xing"
      ],
      "abstract": "During and after a course of therapy, imaging is routinely used to monitor\nthe disease progression and assess the treatment responses. Despite of its\nsignificance, reliably capturing and predicting the spatial-temporal anatomic\nchanges from a sequence of patient-specific image series presents a\nconsiderable challenge. Thus, the development of a computational framework\nbecomes highly desirable for a multitude of practical applications. In this\ncontext, we propose a strategy of Spatial-Temporal Neural Representation\nlearning with Prior embedding (ST-NeRP) for patient-specific imaging study. Our\nstrategy involves leveraging an Implicit Neural Representation (INR) network to\nencode the image at the reference time point into a prior embedding.\nSubsequently, a spatial-temporally continuous deformation function is learned\nthrough another INR network. This network is trained using the whole\npatient-specific image sequence, enabling the prediction of deformation fields\nat various target time points. The efficacy of the ST-NeRP model is\ndemonstrated through its application to diverse sequential image series,\nincluding 4D CT and longitudinal CT datasets within thoracic and abdominal\nimaging. The proposed ST-NeRP model exhibits substantial potential in enabling\nthe monitoring of anatomical changes within a patient throughout the\ntherapeutic journey.",
      "tldr_zh": "该论文提出了一种名为 ST-NeRP 的策略，用于患者特定图像研究，以捕捉和预测治疗过程中图像序列的空间-时间解剖变化。ST-NeRP 利用 Implicit Neural Representation (INR) 网络将参考时间点的图像编码成 prior embedding，然后通过另一个 INR 网络学习空间-时间连续的变形函数，从而基于整个图像序列预测不同目标时间点的变形场。该方法在 4D CT 和纵向 CT 数据集（如胸部和腹部成像）上进行了验证，展示了在监测患者解剖变化和评估治疗响应方面的显著潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "14 pages with 10 figures and 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.19283v1",
      "published_date": "2024-10-25 03:33:17 UTC",
      "updated_date": "2024-10-25 03:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:48:44.897877"
    },
    {
      "arxiv_id": "2410.19279v1",
      "title": "UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Bian",
        "Bin Guo",
        "Sicong Liu",
        "Yasan Ding",
        "Shanshan Gao",
        "Zhiwen Yu"
      ],
      "abstract": "Ubiquitous on-device heart rate sensing is vital for high-stress individuals\nand chronic patients. Non-contact sensing, compared to contact-based tools,\nallows for natural user monitoring, potentially enabling more accurate and\nholistic data collection. However, in open and uncontrolled mobile\nenvironments, user movement and lighting introduce. Existing methods, such as\ncurve-based or short-range deep learning recognition based on adjacent frames,\nstrike the optimal balance between real-time performance and accuracy,\nespecially under limited device resources. In this paper, we present UbiHR, a\nubiquitous device-based heart rate sensing system. Key to UbiHR is a real-time\nlong-range spatio-temporal model enabling noise-independent heart rate\nrecognition and display on commodity mobile devices, along with a set of\nmechanisms for prompt and energy-efficient sampling and preprocessing. Diverse\nexperiments and user studies involving four devices, four tasks, and 80\nparticipants demonstrate UbiHR's superior performance, enhancing accuracy by up\nto 74.2\\% and reducing latency by 51.2\\%.",
      "tldr_zh": "本文提出 UbiHR 系统，一种资源高效的长距离心率 sensing 解决方案，旨在在日常设备上实现无接触式心率监测，以应对开放环境中的用户移动和光照变化挑战。UbiHR 的核心是实时长距离 spatio-temporal model 及其配套的快速节能采样和预处理机制，确保噪声无关的心率识别和显示。实验涉及四种设备、四种任务和80名参与者，证明 UbiHR 相比现有方法提升准确性最多74.2%，并降低延迟51.2%。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19279v1",
      "published_date": "2024-10-25 03:28:19 UTC",
      "updated_date": "2024-10-25 03:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:48:56.834798"
    },
    {
      "arxiv_id": "2410.19278v2",
      "title": "Applying sparse autoencoders to unlearn knowledge in language models",
      "title_zh": "翻译失败",
      "authors": [
        "Eoin Farrell",
        "Yeu-Tong Lau",
        "Arthur Conmy"
      ],
      "abstract": "We investigate whether sparse autoencoders (SAEs) can be used to remove\nknowledge from language models. We use the biology subset of the Weapons of\nMass Destruction Proxy dataset and test on the gemma-2b-it and gemma-2-2b-it\nlanguage models. We demonstrate that individual interpretable biology-related\nSAE features can be used to unlearn a subset of WMDP-Bio questions with minimal\nside-effects in domains other than biology. Our results suggest that negative\nscaling of feature activations is necessary and that zero ablating features is\nineffective. We find that intervening using multiple SAE features\nsimultaneously can unlearn multiple different topics, but with similar or\nlarger unwanted side-effects than the existing Representation Misdirection for\nUnlearning technique. Current SAE quality or intervention techniques would need\nto improve to make SAE-based unlearning comparable to the existing fine-tuning\nbased techniques.",
      "tldr_zh": "本研究探讨了使用稀疏自动编码器（SAEs）从语言模型中移除特定知识，聚焦于Weapons of Mass Destruction Proxy数据集（WMDP-Bio）的生物学子集，并测试了gemma-2b-it和gemma-2-2b-it模型。结果显示，针对单个可解释的生物学相关SAE特征进行负缩放激活干预，可以有效unlearn部分WMDP-Bio问题，同时在非生物领域产生最小副作用，而零消融特征则无效。使用多个SAE特征同时干预虽能处理多种主题，但副作用与现有Representation Misdirection for Unlearning技术相当或更大，表明当前SAE质量和干预方法需改进，以与基于微调的技术媲美。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19278v2",
      "published_date": "2024-10-25 03:21:14 UTC",
      "updated_date": "2024-11-02 23:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:49:10.105062"
    },
    {
      "arxiv_id": "2410.19274v2",
      "title": "Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management",
      "title_zh": "Ripple：利用相关性感知神经元管理在智能手机上加速LLM推理",
      "authors": [
        "Tuowei Wang",
        "Ruwen Fan",
        "Minxing Huang",
        "Zixu Hao",
        "Kun Li",
        "Ting Cao",
        "Youyou Lu",
        "Yaoxue Zhang",
        "Ju Ren"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains, yet deploying them on mobile devices remains an arduous challenge due\nto their extensive computational and memory demands. While lightweight LLMs\nhave been developed to fit mobile environments, they suffer from degraded model\naccuracy. In contrast, sparsity-based techniques minimize DRAM usage by\nselectively transferring only relevant neurons to DRAM while retaining the full\nmodel in external storage, such as flash. However, such approaches are\ncritically limited by numerous I/O operations, particularly on smartphones with\nsevere IOPS constraints.\n  In this paper, we propose Ripple, a novel approach that accelerates LLM\ninference on smartphones by optimizing neuron placement in flash memory. Ripple\nleverages the concept of Neuron Co-Activation, where neurons frequently\nactivated together are linked to facilitate continuous read access and optimize\ndata transfer efficiency. Our approach incorporates a two-stage solution: an\noffline stage that reorganizes neuron placement based on co-activation\npatterns, and an online stage that employs tailored data access and caching\nstrategies to align well with hardware characteristics. Evaluations conducted\non a variety of smartphones and LLMs demonstrate that Ripple achieves up to\n5.93x improvements in I/O latency compared to the state-of-the-art. As the\nfirst solution to optimize storage placement under sparsity, Ripple explores a\nnew optimization space at the intersection of sparsity-driven algorithm and\nstorage-level system co-design in LLM inference.",
      "tldr_zh": "该研究提出 Ripple，一种针对智能手机上大语言模型(LLMs)推理的加速方法，通过相关性感知神经元管理优化神经元在闪存中的放置。Ripple 利用 Neuron Co-Activation 概念，将频繁共同激活的神经元链接起来，实现连续读取和高效数据传输，并采用两阶段解决方案：离线阶段重新组织神经元布局，在线阶段使用定制数据访问和缓存策略以适应硬件特性。实验结果显示，Ripple 在多种智能手机和 LLMs 上将 I/O 延迟比最先进方法改善高达 5.93 倍。作为首个针对稀疏性优化的存储放置方案，它探索了算法与系统共同设计的创新空间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.OS",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19274v2",
      "published_date": "2024-10-25 03:01:19 UTC",
      "updated_date": "2024-10-29 17:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:49:21.618982"
    },
    {
      "arxiv_id": "2410.19262v1",
      "title": "Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Reachsak Ly",
        "Alireza Shojaei"
      ],
      "abstract": "Current autonomous building research primarily focuses on energy efficiency\nand automation. While traditional artificial intelligence has advanced\nautonomous building research, it often relies on predefined rules and struggles\nto adapt to complex, evolving building operations. Moreover, the centralized\norganizational structures of facilities management hinder transparency in\ndecision-making, limiting true building autonomy. Research on decentralized\ngovernance and adaptive building infrastructure, which could overcome these\nchallenges, remains relatively unexplored. This paper addresses these\nlimitations by introducing a novel Decentralized Autonomous Building\nCyber-Physical System framework that integrates Decentralized Autonomous\nOrganizations, Large Language Models, and digital twins to create a smart,\nself-managed, operational, and financially autonomous building infrastructure.\nThis study develops a full-stack decentralized application to facilitate\ndecentralized governance of building infrastructure. An LLM-based artificial\nintelligence assistant is developed to provide intuitive human-building\ninteraction for blockchain and building operation management-related tasks and\nenable autonomous building operation. Six real-world scenarios were tested to\nevaluate the autonomous building system's workability, including building\nrevenue and expense management, AI-assisted facility control, and autonomous\nadjustment of building systems. Results indicate that the prototype\nsuccessfully executes these operations, confirming the framework's suitability\nfor developing building infrastructure with decentralized governance and\nautonomous operation.",
      "tldr_zh": "该论文针对传统建筑自治系统的局限性（如依赖预定义规则和集中式决策的不透明），提出了一种新型 Decentralized Autonomous Building Cyber-Physical System 框架。该框架整合 Decentralized Autonomous Organizations、Large Language Models 和 digital twins，实现建筑基础设施的智能、自管理和去中心化治理。具体而言，研究开发了一个全栈去中心化应用和基于 LLM 的 AI 助手，用于人-建筑交互、区块链管理及自治操作。在六个真实场景测试中，包括建筑收入支出管理、AI 辅助设施控制和系统自治调整，结果证明原型成功执行，验证了框架在提升建筑自治性和适应性方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19262v1",
      "published_date": "2024-10-25 02:34:54 UTC",
      "updated_date": "2024-10-25 02:34:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:49:34.160600"
    },
    {
      "arxiv_id": "2410.19258v3",
      "title": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Fu",
        "Zefan Cai",
        "Abedelkadir Asi",
        "Wayne Xiong",
        "Yue Dong",
        "Wen Xiao"
      ],
      "abstract": "Key-Value (KV) caching is a common technique to enhance the computational\nefficiency of Large Language Models (LLMs), but its memory overhead grows\nrapidly with input length. Prior work has shown that not all tokens are equally\nimportant for text generation, proposing layer-level KV cache compression to\nselectively retain key information. Recognizing the distinct roles of attention\nheads in generation, we propose HeadKV, a head-level KV cache compression\nmethod, and HeadKV-R2, which leverages a novel contextual reasoning ability\nestimation for compression. Our approach operates at the level of individual\nheads, estimating their importance for contextual QA tasks that require both\nretrieval and reasoning capabilities. Extensive experiments across diverse\nbenchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,\nMistral-7B-Instruct), and long-context abilities tests demonstrate that our\nhead-level KV cache compression significantly outperforms strong baselines,\nparticularly in low-resource settings (KV size = 64 & 128). Notably, our method\nretains just 1.5% of the KV cache while achieving 97% of the performance of the\nfull KV cache on the contextual question answering benchmark.Codes are\navailable at https://github.com/FYYFU/HeadKV",
      "tldr_zh": "本文提出 HeadKV，一种头级 KV cache 压缩方法，以及 HeadKV-R2，它通过评估注意力 heads 在上下文问答任务中的重要性来整合 retrieval and reasoning 能力，从而减少 Large Language Models (LLMs) 在长输入处理中的内存开销。相比层级压缩方法，该方法在单个 attention heads 级别选择性保留关键信息，提升了压缩效率。实验结果显示，在 LongBench 和 LooGLE 等基准上，HeadKV-R2 显著优于基线模型，尤其在低资源设置（KV size = 64 & 128）下，仅保留 1.5% 的 KV cache 即可实现全缓存 97% 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18pages",
      "pdf_url": "http://arxiv.org/pdf/2410.19258v3",
      "published_date": "2024-10-25 02:22:00 UTC",
      "updated_date": "2024-11-14 01:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:49:47.031912"
    },
    {
      "arxiv_id": "2410.19247v2",
      "title": "Non-rigid Relative Placement through 3D Dense Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Cai",
        "Octavian Donca",
        "Ben Eisner",
        "David Held"
      ],
      "abstract": "The task of \"relative placement\" is to predict the placement of one object in\nrelation to another, e.g. placing a mug onto a mug rack. Through explicit\nobject-centric geometric reasoning, recent methods for relative placement have\nmade tremendous progress towards data-efficient learning for robot manipulation\nwhile generalizing to unseen task variations. However, they have yet to\nrepresent deformable transformations, despite the ubiquity of non-rigid bodies\nin real world settings. As a first step towards bridging this gap, we propose\n``cross-displacement\" - an extension of the principles of relative placement to\ngeometric relationships between deformable objects - and present a novel\nvision-based method to learn cross-displacement through dense diffusion. To\nthis end, we demonstrate our method's ability to generalize to unseen object\ninstances, out-of-distribution scene configurations, and multimodal goals on\nmultiple highly deformable tasks (both in simulation and in the real world)\nbeyond the scope of prior works. Supplementary information and videos can be\nfound at https://sites.google.com/view/tax3d-corl-2024 .",
      "tldr_zh": "本文提出了一种扩展相对放置（relative placement）任务的方法，引入“cross-displacement”概念，以处理非刚性物体（deformable objects）之间的几何关系。作者开发了一种基于视觉的3D dense diffusion 方法，通过密集扩散模型学习这些关系的预测和泛化。实验结果显示，该方法在模拟和真实世界中，能够泛化到未见物体实例、分布外场景配置以及多模态目标，并在高度可变形任务上超越了现有工作。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Conference on Robot Learning (CoRL), 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19247v2",
      "published_date": "2024-10-25 01:54:17 UTC",
      "updated_date": "2024-10-29 13:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:49:56.878725"
    },
    {
      "arxiv_id": "2410.21306v2",
      "title": "Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models, and Challenges",
      "title_zh": "法律领域的自然语言处理：任务、数据集、模型和挑战的调查综述",
      "authors": [
        "Farid Ariai",
        "Gianluca Demartini"
      ],
      "abstract": "Natural Language Processing (NLP) is revolutionising the way legal\nprofessionals and laypersons operate in the legal field. The considerable\npotential for NLP in the legal sector, especially in developing computational\ntools for various legal processes, has captured the interest of researchers for\nyears. This survey follows the Preferred Reporting Items for Systematic Reviews\nand Meta-Analyses framework, reviewing 154 studies, with a final selection of\n133 after manual filtering. It explores foundational concepts related to NLP in\nthe legal domain, illustrating the unique aspects and challenges of processing\nlegal texts, such as extensive document length, complex language, and limited\nopen legal datasets. We provide an overview of NLP tasks specific to legal\ntext, such as Legal Document Summarisation, legal Named Entity Recognition,\nLegal Question Answering, Legal Argument Mining, Legal Text Classification, and\nLegal Judgement Prediction. In the section on legal Language Models (LMs), we\nanalyse both developed LMs and approaches for adapting general LMs to the legal\ndomain. Additionally, we identify 16 Open Research Challenges, including bias\nin Artificial Intelligence applications, the need for more robust and\ninterpretable models, and improving explainability to handle the complexities\nof legal language and reasoning.",
      "tldr_zh": "本调查综述了 Natural Language Processing (NLP) 在法律领域的应用，涵盖了相关任务、数据集、模型和挑战，通过 Preferred Reporting Items for Systematic Reviews and Meta-Analyses 框架审查了 154 篇研究，最终筛选出 133 篇。论文详细探讨了处理法律文本的独特难题，如文档长度、复杂语言和数据集有限等问题，并概述了关键任务包括 Legal Document Summarisation、Legal Named Entity Recognition、Legal Question Answering、Legal Argument Mining、Legal Text Classification 和 Legal Judgement Prediction。针对法律 Language Models (LMs)，它分析了专用模型的开发和一般模型的适应方法，同时指出了 16 个开放研究挑战，如 AI 偏见、模型鲁棒性及解释性，以推动该领域的未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "A.1; I.2.7; J.1"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.21306v2",
      "published_date": "2024-10-25 01:17:02 UTC",
      "updated_date": "2025-03-25 03:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:50:09.910906"
    },
    {
      "arxiv_id": "2410.19238v1",
      "title": "Designing LLM-Agents with Personalities: A Psychometric Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Muhua Huang",
        "Xijuan Zhang",
        "Christopher Soto",
        "James Evans"
      ],
      "abstract": "This research introduces a novel methodology for assigning quantifiable,\ncontrollable and psychometrically validated personalities to Large Language\nModels-Based Agents (Agents) using the Big Five personality framework. It seeks\nto overcome the constraints of human subject studies, proposing Agents as an\naccessible tool for social science inquiry. Through a series of four studies,\nthis research demonstrates the feasibility of assigning psychometrically valid\npersonality traits to Agents, enabling them to replicate complex human-like\nbehaviors. The first study establishes an understanding of personality\nconstructs and personality tests within the semantic space of an LLM. Two\nsubsequent studies -- using empirical and simulated data -- illustrate the\nprocess of creating Agents and validate the results by showing strong\ncorrespondence between human and Agent answers to personality tests. The final\nstudy further corroborates this correspondence by using Agents to replicate\nknown human correlations between personality traits and decision-making\nbehaviors in scenarios involving risk-taking and ethical dilemmas, thereby\nvalidating the effectiveness of the psychometric approach to design Agents and\nits applicability to social and behavioral research.",
      "tldr_zh": "本研究提出了一种心理测量方法（psychometric approach），利用 Big Five 个性框架为基于大型语言模型的代理（LLM-Agents）分配可量化、可控制且经过验证的个性，从而克服人类研究受限的问题，并将其作为社会科学调查的工具。  \n通过四个研究，包括探索个性结构在 LLM 语义空间中的表现、使用实证和模拟数据创建代理、以及验证代理回答与人类回答的对应性，该方法证明了代理能够复制复杂的人类行为。  \n最终发现，Agents 成功复制了人类个性特征与决策行为（如风险承担和伦理困境）的相关性，验证了这一方法的有效性和在社会及行为研究中的潜在应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19238v1",
      "published_date": "2024-10-25 01:05:04 UTC",
      "updated_date": "2024-10-25 01:05:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:50:22.653383"
    },
    {
      "arxiv_id": "2410.19235v1",
      "title": "Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Malek Aburub",
        "Cristian C. Beltran-Hernandez",
        "Tatsuya Kamijo",
        "Masashi Hamaya"
      ],
      "abstract": "Robots hold great promise for performing repetitive or hazardous tasks, but\nachieving human-like dexterity, especially in contact-rich and dynamic\nenvironments, remains challenging. Rigid robots, which rely on position or\nvelocity control, often struggle with maintaining stable contact and applying\nconsistent force in force-intensive tasks. Learning from Demonstration has\nemerged as a solution, but tasks requiring intricate maneuvers, such as powder\ngrinding, present unique difficulties. This paper introduces Diffusion Policies\nFor Compliant Manipulation (DIPCOM), a novel diffusion-based framework designed\nfor compliant control tasks. By leveraging generative diffusion models, we\ndevelop a policy that predicts Cartesian end-effector poses and adjusts arm\nstiffness to maintain the necessary force. Our approach enhances force control\nthrough multimodal distribution modeling, improves the integration of diffusion\npolicies in compliance control, and extends our previous work by demonstrating\nits effectiveness in real-world tasks. We present a detailed comparison between\nour framework and existing methods, highlighting the advantages and best\npractices for deploying diffusion-based compliance control.",
      "tldr_zh": "本文探讨了机器人处理接触丰富的动态任务（如粉末研磨）面临的挑战，特别是在维持稳定接触和施加一致力方面。论文提出DIPCOM（Diffusion Policies For Compliant Manipulation），一种基于扩散模型的框架，通过从演示中学习来预测Cartesian end-effector poses并动态调整arm stiffness，从而增强力控制和顺从操作。实验结果显示，该方法在真实世界任务中优于现有方法，提供更好的多模态分布建模和最佳部署实践。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19235v1",
      "published_date": "2024-10-25 00:56:15 UTC",
      "updated_date": "2024-10-25 00:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:50:35.134042"
    },
    {
      "arxiv_id": "2410.19231v1",
      "title": "Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use",
      "title_zh": "翻译失败",
      "authors": [
        "Menna Fateen",
        "Tsunenori Mine"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown promise for\nscalable educational applications, but their use in dialog-based tutoring\nsystems remains challenging due to the need for effective pedagogical\nstrategies and the high costs associated with expert-curated datasets. Our\nstudy explores the use of smaller, more affordable LLMs for one-on-one tutoring\nin the context of solving reading comprehension problems. We developed a\nsynthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned\na smaller LLM using this dataset. Furthermore, we conducted an interactive\nexperiment comparing the performance of the fine-tuned model with a larger\nmodel in real-world tutoring scenarios. Our results show that the fine-tuned\nmodel performs on par with the larger model but at a lower cost, demonstrating\na viable, cost-effective approach for implementing LLM-based tutoring systems\nin educational settings.",
      "tldr_zh": "这篇论文探讨了优化大型语言模型 (LLMs) 用于教育辅导的挑战，特别针对对话式辅导系统中的教学策略和数据集成本问题。研究团队开发了一个合成辅导对话数据集，通过人类教师评估，并使用该数据集微调了一个较小的 LLM，以支持一对一的阅读理解辅导。实验结果显示，微调后的模型在真实场景中与更大模型性能相当，但成本更低，从而提供了一种可行的、成本有效的 LLM 辅导系统解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19231v1",
      "published_date": "2024-10-25 00:40:21 UTC",
      "updated_date": "2024-10-25 00:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:50:45.862470"
    },
    {
      "arxiv_id": "2410.19225v4",
      "title": "Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Weikai Li",
        "Ding Wang",
        "Zijian Ding",
        "Atefeh Sohrabizadeh",
        "Zongyue Qin",
        "Jason Cong",
        "Yizhou Sun"
      ],
      "abstract": "High-level synthesis (HLS) is a widely used tool in designing Field\nProgrammable Gate Array (FPGA). HLS enables FPGA design with software\nprogramming languages by compiling the source code into an FPGA circuit. The\nsource code includes a program (called \"kernel\") and several pragmas that\ninstruct hardware synthesis, such as parallelization, pipeline, etc. While it\nis relatively easy for software developers to design the program, it heavily\nrelies on hardware knowledge to design the pragmas, posing a big challenge for\nsoftware developers. Recently, different machine learning algorithms, such as\nGNNs, have been proposed to automate the pragma design via performance\nprediction. However, when applying the trained model on new kernels, the\nsignificant domain shift often leads to unsatisfactory performance. We propose\na more domain-generalizable model structure: a two-level hierarchical Mixture\nof Experts (MoE), that can be flexibly adapted to any GNN model. Different\nexpert networks can learn to deal with different regions in the representation\nspace, and they can utilize similar patterns between the old kernels and new\nkernels. In the low-level MoE, we apply MoE on three natural granularities of a\nprogram: node, basic block, and graph. The high-level MoE learns to aggregate\nthe three granularities for the final decision. To train the hierarchical MoE\nstably, we further propose a two-stage training method to avoid expert\npolarization. Extensive experiments verify the effectiveness of the proposed\nhierarchical MoE. We publicized our codes at\nhttps://github.com/weikai-li/HierarchicalMoE.",
      "tldr_zh": "本研究针对高水平综合 (HLS) 在 Field Programmable Gate Array (FPGA) 设计中的问题，提出了一种层次化 Mixture of Experts (MoE) 模型，以解决现有机器学习算法如 GNNs 在新内核上因 domain shift 而导致性能不佳的问题。该模型采用两级结构：低级 MoE 处理程序的不同粒度（node、basic block 和 graph），而高级 MoE 聚合这些粒度信息，实现更强的领域泛化能力。为避免 expert polarization，论文引入了两阶段训练方法。实验结果验证了该方法的有效性，并在 GitHub 上公开了代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.19225v4",
      "published_date": "2024-10-25 00:27:53 UTC",
      "updated_date": "2025-03-14 04:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:50:58.239422"
    },
    {
      "arxiv_id": "2410.19223v1",
      "title": "Integrating Large Language Models with Internet of Things Applications",
      "title_zh": "将大型语言模型与物联网应用集成",
      "authors": [
        "Mingyu Zong",
        "Arvin Hekmati",
        "Michael Guastalla",
        "Yiyi Li",
        "Bhaskar Krishnamachari"
      ],
      "abstract": "This paper identifies and analyzes applications in which Large Language\nModels (LLMs) can make Internet of Things (IoT) networks more intelligent and\nresponsive through three case studies from critical topics: DDoS attack\ndetection, macroprogramming over IoT systems, and sensor data processing. Our\nresults reveal that the GPT model under few-shot learning achieves 87.6%\ndetection accuracy, whereas the fine-tuned GPT increases the value to 94.9%.\nGiven a macroprogramming framework, the GPT model is capable of writing scripts\nusing high-level functions from the framework to handle possible incidents.\nMoreover, the GPT model shows efficacy in processing a vast amount of sensor\ndata by offering fast and high-quality responses, which comprise expected\nresults and summarized insights. Overall, the model demonstrates its potential\nto power a natural language interface. We hope that researchers will find these\ncase studies inspiring to develop further.",
      "tldr_zh": "这篇论文探讨了如何将 Large Language Models (LLMs) 整合到 Internet of Things (IoT) 应用中，以提升网络的智能性和响应性，通过三个案例研究：DDoS 攻击检测、IoT 系统宏编程以及传感器数据处理。研究结果显示，GPT 模型在 few-shot learning 下达到 87.6% 的 DDoS 检测准确率，微调后提升至 94.9%；同时，GPT 能够使用宏编程框架编写脚本处理事件，并高效处理大量传感器数据，提供高质量响应和总结见解。总体上，这展示了 LLMs 作为自然语言接口的潜力，并旨在激励更多相关研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19223v1",
      "published_date": "2024-10-25 00:21:45 UTC",
      "updated_date": "2024-10-25 00:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:51:11.266975"
    },
    {
      "arxiv_id": "2410.19221v1",
      "title": "Can Stories Help LLMs Reason? Curating Information Space Through Narrative",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Sadiri Javadi",
        "Johanne R. Trippas",
        "Yash Kumar Lal",
        "Lucie Flek"
      ],
      "abstract": "Narratives are widely recognized as a powerful tool for structuring\ninformation and facilitating comprehension of complex ideas in various domains\nsuch as science communication. This paper investigates whether incorporating\nnarrative elements can assist Large Language Models (LLMs) in solving complex\nproblems more effectively. We propose a novel approach, Story of Thought (SoT),\nintegrating narrative structures into prompting techniques for problem-solving.\nThis approach involves constructing narratives around problem statements and\ncreating a framework to identify and organize relevant information. Our\nexperiments show that using various LLMs with SoT consistently surpasses using\nthem with other techniques on physics, chemistry, math, and biology questions\nin both the GPQA and JEEBench datasets. The narrative-based information\ncuration process in SoT enhances problem comprehension by contextualizing\ncritical in-domain information and highlighting causal relationships within the\nproblem space.",
      "tldr_zh": "这篇论文探讨了是否通过整合叙述元素，能帮助 Large Language Models (LLMs) 更有效地解决复杂问题。作者提出了一种新方法 Story of Thought (SoT)，将叙述结构融入提示技术中，围绕问题语句构建叙述并组织相关信息。实验结果显示，在 GPQA 和 JEEBench 数据集的物理、化学、数学和生物问题上，使用 SoT 的各种 LLMs 比其他技术表现出色。SoT 通过上下文化关键领域信息和突出问题空间中的因果关系，提升了问题理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19221v1",
      "published_date": "2024-10-25 00:13:15 UTC",
      "updated_date": "2024-10-25 00:13:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:51:21.763211"
    },
    {
      "arxiv_id": "2410.19219v1",
      "title": "Robot Behavior Personalization from Sparse User Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Maithili Patel",
        "Sonia Chernova"
      ],
      "abstract": "As service robots become more general-purpose, they will need to adapt to\ntheir users' preferences over a large set of all possible tasks that they can\nperform. This includes preferences regarding which actions the users prefer to\ndelegate to robots as opposed to doing themselves. Existing personalization\napproaches require task-specific data for each user. To handle diversity across\nall household tasks and users, and nuances in user preferences across tasks, we\npropose to learn a task adaptation function independently, which can be used in\ntandem with any universal robot policy to customize robot behavior. We create\nTask Adaptation using Abstract Concepts (TAACo) framework. TAACo can learn to\npredict the user's preferred manner of assistance with any given task, by\nmediating reasoning through a representation composed of abstract concepts\nbuilt based on user feedback. TAACo can generalize to an open set of household\ntasks from small amount of user feedback and explain its inferences through\nintuitive concepts. We evaluate our model on a dataset we collected of 5\npeople's preferences, and show that TAACo outperforms GPT-4 by 16% and a\nrule-based system by 54%, on prediction accuracy, with 40 samples of user\nfeedback.",
      "tldr_zh": "这篇论文探讨了服务机器人如何从稀疏用户反馈中个性化行为，以适应用户在各种任务中的偏好，包括哪些任务愿意委托给机器人。论文提出 Task Adaptation using Abstract Concepts (TAACo) 框架，该框架通过基于抽象概念的推理，学习一个独立的任务适应函数，并与任何通用机器人策略结合，实现对新任务的泛化和直观解释。实验结果显示，在一个包含5个用户偏好的数据集上，TAACo 比 GPT-4 准确率提高16%，比基于规则的系统提高54%，仅需40个样本即可实现高效学习。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19219v1",
      "published_date": "2024-10-25 00:08:38 UTC",
      "updated_date": "2024-10-25 00:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:51:33.352224"
    },
    {
      "arxiv_id": "2410.19218v1",
      "title": "Taxonomy-guided Semantic Indexing for Academic Paper Search",
      "title_zh": "翻译失败",
      "authors": [
        "SeongKu Kang",
        "Yunyi Zhang",
        "Pengcheng Jiang",
        "Dongha Lee",
        "Jiawei Han",
        "Hwanjo Yu"
      ],
      "abstract": "Academic paper search is an essential task for efficient literature discovery\nand scientific advancement. While dense retrieval has advanced various ad-hoc\nsearches, it often struggles to match the underlying academic concepts between\nqueries and documents, which is critical for paper search. To enable effective\nacademic concept matching for paper search, we propose Taxonomy-guided Semantic\nIndexing (TaxoIndex) framework. TaxoIndex extracts key concepts from papers and\norganizes them as a semantic index guided by an academic taxonomy, and then\nleverages this index as foundational knowledge to identify academic concepts\nand link queries and documents. As a plug-and-play framework, TaxoIndex can be\nflexibly employed to enhance existing dense retrievers. Extensive experiments\nshow that TaxoIndex brings significant improvements, even with highly limited\ntraining data, and greatly enhances interpretability.",
      "tldr_zh": "本研究针对学术论文搜索中，dense retrieval 在匹配查询和文档的学术概念上存在的挑战，提出了一种 Taxonomy-guided Semantic Indexing (TaxoIndex) 框架。该框架从论文中提取关键概念，并利用 academic taxonomy 指导构建语义索引，作为基础知识来识别学术概念并连接查询与文档。作为一个 plug-and-play 框架，TaxoIndex 可以灵活增强现有 dense retrievers 的性能。实验结果显示，即使在训练数据有限的情况下，它显著提高了检索准确率，并增强了系统的可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "EMNLP'24",
      "pdf_url": "http://arxiv.org/pdf/2410.19218v1",
      "published_date": "2024-10-25 00:00:17 UTC",
      "updated_date": "2024-10-25 00:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T16:51:45.375636"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 108,
  "processed_papers_count": 108,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T16:52:09.339254"
}