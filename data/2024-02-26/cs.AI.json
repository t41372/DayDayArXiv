{
  "date": "2024-02-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-26 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型优化、生成式 AI 应用、强化学习和多模态处理等领域，强调大型语言模型（LLMs）的安全性和鲁棒性、图像生成技术，以及高效算法的创新。其中，令人印象深刻的是如 \"Pandora's White-Box\" 等涉及 LLM 隐私攻击的论文，以及 ICLR 和 NeurIPS 等会议接受的创新工作，如 \"REFACTOR\" 和 \"Contextualized Diffusion Models\"。\n\n下面，我将挑选并讨论部分关键论文，先从 AI 和 LLM 相关主题入手（如安全、生成和优化），然后快速触及其他领域（如强化学习和图神经网络）。我会优先选取有话题度或突破性的论文，简要概述其核心贡献和发现，并跳过一些较为常规或无聊的内容（如纯理论回顾或重复性实验）。\n\n### AI 和 LLM 相关\n- **Pandora's White-Box: Precise Training Data Detection and Extraction in Large Language Models**（中文：潘多拉的白盒：大型语言模型中训练数据检测和提取的精确方法；英文：Pandora's White-Box）  \n  这篇论文提出了一种先进的隐私攻击方法，用于检测和提取 LLM 的训练数据。主要贡献是通过监督和无监督攻击（如基于梯度的分类器），实现比基线高数百倍的成员推断准确率，并展示了在 PyTorch 和 Llama 模型上提取超过 50% 的微调数据。该发现突显了 LLM 隐私风险，并为未来模型安全提供警示。\n\n- **Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings**（中文：多任务对比学习用于 8192 标记双语文本嵌入；英文：Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings）  \n  作者团队包括多位知名研究者（如 Han Xiao）。论文引入一种多任务对比学习框架，优化双语文本嵌入，支持长序列（8192 标记）。主要发现是，该方法在文本检索和语义相似性任务上超越多语言模型，提高了目标语言理解，并扩展了 MTEB 基准以支持德语和西班牙语，展示了高效的多模态 AI 应用潜力。\n\n- **Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering**（中文：讨论链：多模型框架用于复杂证据支持的问答；英文：Chain-of-Discussion）  \n  这篇论文提出一个多 LLM 协作框架，用于处理复杂问答任务。主要贡献是通过多模型讨论机制（如证据整合），提升答案的准确性和全面性。实验显示，该方法在证据稀缺场景下显著提高性能，强调了 LLM 协同的实际价值。\n\n- **Contextualized Diffusion Models for Text-Guided Image and Video Generation**（中文：上下文化扩散模型用于文本引导的图像和视频生成；英文：Contextualized Diffusion Models for Text-Guided Image and Video Generation）  \n  论文创新性地将上下文信息融入扩散模型的正向和反向过程。主要发现是，该方法在文本到图像生成任务中提升了语义对齐精度，并在 KILT 基准上实现最先进性能。该工作为生成式 AI 提供了更精确的控制机制。\n\n- **REFACTOR: Learning to Extract Theorems from Proofs**（中文：REFACTOR：从证明中学习提取定理；英文：REFACTOR: Learning to Extract Theorems from Proofs）  \n  作者包括 Yuhuai Wu（知名 AI 学者）。论文提出一个神经网络框架，用于从形式化证明中提取可重用定理。主要贡献是通过神经网络模仿人类模块化证明，实验显示提取率达 19.6%，并在 Metamath 上重构证明，显著缩短证明长度。该发现推进了 AI 在数学推理中的应用。\n\n- **MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs**（中文：MathGenie：通过问题反向翻译生成合成数据以提升 LLM 的数学推理；英文：MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs）  \n  论文引入一种数据增强方法，使用 LLM 生成数学问题-答案对。主要发现是通过合成数据训练，模型在 GSM8K 和 MATH 数据集上提升 5-7 点准确率，实现最先进性能。该工作突出了合成数据在 LLM 数学任务中的高效性。\n\n### 强化学习和决策优化\n- **Adapting to Teammates in a Cooperative Language Game**（中文：适应队友的合作语言游戏；英文：Adapting to Teammates in a Cooperative Language Game）  \n  这篇论文针对 Codenames 游戏提出首个适应性代理。主要贡献是使用集成方法动态选择最佳内部专家，提升团队协作性能。实验显示，该代理在无先验知识下接近最佳专家水平，展示了强化学习在语言协作中的潜力。\n\n- **Hyperdimensional Representation Learning for Node Classification and Link Prediction**（中文：超维度表示学习用于节点分类和链接预测；英文：Hyperdimensional Representation Learning for Node Classification and Link Prediction）  \n  论文引入 HDGL 方法，用于图神经网络任务。主要发现是通过超维度空间聚合信息，实现高效节点分类和链接预测，与最先进模型相当但计算成本更低。该工作在 WSDM 2025 接受，强调了图学习的实用性。\n\n- **Generative Retrieval with Large Language Models**（中文：基于大型语言模型的生成式检索；英文：Generative Retrieval with Large Language Models）  \n  作者探索 LLM 在知识密集任务中的检索能力。主要贡献是使用约束解码从 LLM 参数中召回参考段落，提升下游任务性能。该方法无需额外模型，展示了 LLM 在检索领域的潜力。\n\n### 其他领域快速掠过\n其他论文涉及图像处理、医疗 AI 和网络安全等，但许多是常规扩展或初步调查，我将简要提及有潜在影响的几篇：\n- **Taming the Tail in Class-Conditional GANs**（中文：驯服类别条件 GAN 中的长尾分布；英文：Taming the Tail in Class-Conditional GANs）  \n  提出一种知识共享方法，改善 GAN 在长尾数据上的生成质量。主要发现是，通过无条件训练低分辨率层，提升图像多样性和保真度。\n\n- **Towards Generalizing Inferences from Trials to Target Populations**（中文：从试验向目标人群推广推断；英文：Towards Generalizing Inferences from Trials to Target Populations）  \n  讨论 RCT 结果的外推问题。主要贡献是整合多学科方法，提升因果推断的泛化性。\n\n- **Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials**（中文：监控在线强化学习算法在临床试验中的保真度；英文：Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials）  \n  提出框架监控 RL 算法的可靠性。主要发现是，在真实试验中实现自主干预，展示了 RL 在医疗中的应用潜力。\n\n其余论文（如纯理论回顾或小数据集实验）未详细讨论，以控制篇幅。这些论文总体上强化了 AI 在实际应用中的进展，但许多仍需进一步验证。\n\n总之，今天的 arXiv 论文展示了 AI 领域的活力，尤其在 LLM 安全和生成优化上。感兴趣的读者可关注这些主题的后续发展！",
  "papers": [
    {
      "arxiv_id": "2402.17087v1",
      "title": "A Note on Bayesian Networks with Latent Root Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Zaffalon",
        "Alessandro Antonucci"
      ],
      "abstract": "We characterise the likelihood function computed from a Bayesian network with\nlatent variables as root nodes. We show that the marginal distribution over the\nremaining, manifest, variables also factorises as a Bayesian network, which we\ncall empirical. A dataset of observations of the manifest variables allows us\nto quantify the parameters of the empirical Bayesian net. We prove that (i) the\nlikelihood of such a dataset from the original Bayesian network is dominated by\nthe global maximum of the likelihood from the empirical one; and that (ii) such\na maximum is attained if and only if the parameters of the Bayesian network are\nconsistent with those of the empirical model.",
      "tldr_zh": "本论文探讨了带有潜在根变量（latent root variables）的Bayesian networks的似然函数，证明了剩余显变量（manifest variables）的边际分布可以表示为一个经验Bayesian network（empirical Bayesian net）。通过对显变量观测数据集的参数量化，研究者证明了原Bayesian network的似然函数被empirical Bayesian net的全局最大似然函数主导，且这种最大值仅在两者参数一致时实现。该发现为处理潜在变量的Bayesian networks提供了重要理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17087v1",
      "published_date": "2024-02-26 23:53:34 UTC",
      "updated_date": "2024-02-26 23:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:01:59.032405"
    },
    {
      "arxiv_id": "2402.17082v1",
      "title": "Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs",
      "title_zh": "翻译失败",
      "authors": [
        "Yasmine Kotturi",
        "Angel Anderson",
        "Glenn Ford",
        "Michael Skirpan",
        "Jeffrey P. Bigham"
      ],
      "abstract": "Generative AI platforms and features are permeating many aspects of work.\nEntrepreneurs from lean economies in particular are well positioned to\noutsource tasks to generative AI given limited resources. In this paper, we\nwork to address a growing disparity in use of these technologies by building on\na four-year partnership with a local entrepreneurial hub dedicated to equity in\ntech and entrepreneurship. Together, we co-designed an interactive workshops\nseries aimed to onboard local entrepreneurs to generative AI platforms.\nAlongside four community-driven and iterative workshops with entrepreneurs\nacross five months, we conducted interviews with 15 local entrepreneurs and\ncommunity providers. We detail the importance of communal and supportive\nexposure to generative AI tools for local entrepreneurs, scaffolding actionable\nuse (and supporting non-use), demystifying generative AI technologies by\nemphasizing entrepreneurial power, while simultaneously deconstructing the\nveneer of simplicity to address the many operational skills needed for\nsuccessful application.",
      "tldr_zh": "这篇论文探讨了与本地创业中心的合作，共同设计生成式 AI 入门工作坊，以弥合资源有限的创业者在使用这些技术的差距。研究团队通过四场社区驱动的迭代工作坊和对15位本地创业者及社区提供者的采访，强调了社区支持和集体学习在推广生成式 AI 平台中的重要性。工作坊不仅帮助创业者构建可操作的使用策略（包括支持非使用），还通过强调创业者自主权和拆解“veneer of simplicity”，揭示了成功应用所需的操作技能，从而促进更公平的技术采用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17082v1",
      "published_date": "2024-02-26 23:40:33 UTC",
      "updated_date": "2024-02-26 23:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:02:10.158047"
    },
    {
      "arxiv_id": "2403.00823v1",
      "title": "Adapting to Teammates in a Cooperative Language Game",
      "title_zh": "在合作语言游戏中适应队友",
      "authors": [
        "Christopher Archibald",
        "Spencer Brosnahan"
      ],
      "abstract": "The game of Codenames has recently emerged as a domain of interest for\nintelligent agent design. The game is unique due to the way that language and\ncoordination between teammates play important roles. Previous approaches to\ndesigning agents for this game have utilized a single internal language model\nto determine action choices. This often leads to good performance with some\nteammates and inferior performance with other teammates, as the agent cannot\nadapt to any specific teammate. In this paper we present the first adaptive\nagent for playing Codenames. We adopt an ensemble approach with the goal of\ndetermining, during the course of interacting with a specific teammate, which\nof our internal expert agents, each potentially with its own language model, is\nthe best match. One difficulty faced in this approach is the lack of a single\nnumerical metric that accurately captures the performance of a Codenames team.\nPrior Codenames research has utilized a handful of different metrics to\nevaluate agent teams. We propose a novel single metric to evaluate the\nperformance of a Codenames team, whether playing a single team (solitaire)\ngame, or a competitive game against another team. We then present and analyze\nan ensemble agent which selects an internal expert on each turn in order to\nmaximize this proposed metric. Experimental analysis shows that this ensemble\napproach adapts to individual teammates and often performs nearly as well as\nthe best internal expert with a teammate. Crucially, this success does not\ndepend on any previous knowledge about the teammates, the ensemble agents, or\ntheir compatibility. This research represents an important step to making\nlanguage-based agents for cooperative language settings like Codenames more\nadaptable to individual teammates.",
      "tldr_zh": "这篇论文针对合作语言游戏 Codenames，提出第一个适应性代理，使用 ensemble approach 在互动过程中动态选择最佳内部专家代理（每个可能有自己的 language model），以解决传统单一 language model 无法适应不同队友的问题。研究者开发了一个新的单一指标来统一评估 Codenames 团队的表现，包括单队或竞争游戏。实验结果显示，该 ensemble 代理能有效适应个别队友，几乎与最佳内部专家相当，且不需任何先验知识关于队友或代理的兼容性，为合作语言环境中的智能代理更具适应性奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00823v1",
      "published_date": "2024-02-26 23:15:07 UTC",
      "updated_date": "2024-02-26 23:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:02:22.409029"
    },
    {
      "arxiv_id": "2402.17073v3",
      "title": "Hyperdimensional Representation Learning for Node Classification and Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Dalvi",
        "Vasant Honavar"
      ],
      "abstract": "We introduce Hyperdimensional Graph Learner (HDGL), a novel method for node\nclassification and link prediction in graphs. HDGL maps node features into a\nvery high-dimensional space (\\textit{hyperdimensional} or HD space for short)\nusing the \\emph{injectivity} property of node representations in a family of\nGraph Neural Networks (GNNs) and then uses HD operators such as\n\\textit{bundling} and \\textit{binding} to aggregate information from the local\nneighborhood of each node yielding latent node representations that can support\nboth node classification and link prediction tasks. HDGL, unlike GNNs that rely\non computationally expensive iterative optimization and hyperparameter tuning,\nrequires only a single pass through the data set. We report results of\nexperiments using widely used benchmark datasets which demonstrate that, on the\nnode classification task, HDGL achieves accuracy that is competitive with that\nof the state-of-the-art GNN methods at substantially reduced computational\ncost; and on the link prediction task, HDGL matches the performance of DeepWalk\nand related methods, although it falls short of computationally demanding\nstate-of-the-art GNNs.",
      "tldr_zh": "本研究提出了一种名为 Hyperdimensional Graph Learner (HDGL) 的新方法，用于图中的节点分类和链接预测任务。HDGL 通过 Graph Neural Networks (GNNs) 的 injectivity 属性，将节点特征映射到高维（hyperdimensional 或 HD）空间，并利用 HD operators 如 bundling 和 binding 来聚合节点邻居信息，从而生成高效的潜在节点表示。不同于依赖迭代优化和超参数调整的 GNNs，HDGL 仅需单次数据遍历即可完成。实验结果显示，在基准数据集上，HDGL 在节点分类任务中达到与最先进 GNNs 相当的准确率，但计算成本显著降低；在链接预测任务中，其性能与 DeepWalk 等方法持平，但略逊于计算密集型 GNNs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.17073v3",
      "published_date": "2024-02-26 23:15:01 UTC",
      "updated_date": "2025-02-27 00:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:02:34.263451"
    },
    {
      "arxiv_id": "2402.17065v2",
      "title": "Taming the Tail in Class-Conditional GANs: Knowledge Sharing via Unconditional Training at Lower Resolutions",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed Khorram",
        "Mingqi Jiang",
        "Mohamad Shahbazi",
        "Mohamad H. Danesh",
        "Li Fuxin"
      ],
      "abstract": "Despite extensive research on training generative adversarial networks (GANs)\nwith limited training data, learning to generate images from long-tailed\ntraining distributions remains fairly unexplored. In the presence of imbalanced\nmulti-class training data, GANs tend to favor classes with more samples,\nleading to the generation of low-quality and less diverse samples in tail\nclasses. In this study, we aim to improve the training of class-conditional\nGANs with long-tailed data. We propose a straightforward yet effective method\nfor knowledge sharing, allowing tail classes to borrow from the rich\ninformation from classes with more abundant training data. More concretely, we\npropose modifications to existing class-conditional GAN architectures to ensure\nthat the lower-resolution layers of the generator are trained entirely\nunconditionally while reserving class-conditional generation for the\nhigher-resolution layers. Experiments on several long-tail benchmarks and GAN\narchitectures demonstrate a significant improvement over existing methods in\nboth the diversity and fidelity of the generated images. The code is available\nat https://github.com/khorrams/utlo.",
      "tldr_zh": "该研究针对类别不平衡的长尾分布数据，探讨了如何改进 class-conditional GANs 的训练，以解决尾部类别生成图像质量低和多样性差的问题。作者提出了一种知识共享方法，通过修改 GAN 架构，让生成器的低分辨率层进行无条件训练，而高分辨率层保留类别条件生成，从而允许尾部类别借用丰富类别的信息。实验在多个长尾基准和 GAN 架构上显示，该方法显著提升了生成图像的多样性和保真度，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17065v2",
      "published_date": "2024-02-26 23:03:00 UTC",
      "updated_date": "2024-06-16 22:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:02:45.861278"
    },
    {
      "arxiv_id": "2402.17045v2",
      "title": "An Investigation into the Performances of the State-of-the-art Machine Learning Approaches for Various Cyber-attack Detection: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Tosin Ige",
        "Christopher Kiekintveld",
        "Aritran Piplai"
      ],
      "abstract": "In this research, we analyzed the suitability of each of the current\nstate-of-the-art machine learning models for various cyberattack detection from\nthe past 5 years with a major emphasis on the most recent works for comparative\nstudy to identify the knowledge gap where work is still needed to be done with\nregard to detection of each category of cyberattack. We also reviewed the\nsuitability, effeciency and limitations of recent research on state-of-the-art\nclassifiers and novel frameworks in the detection of differnet cyberattacks.\nOur result shows the need for; further research and exploration on machine\nlearning approach for the detection of drive-by download attacks, an\ninvestigation into the mix performance of Naive Bayes to identify possible\nresearch direction on improvement to existing state-of-the-art Naive Bayes\nclassifier, we also identify that current machine learning approach to the\ndetection of SQLi attack cannot detect an already compromised database with\nSQLi attack signifying another possible future research direction.",
      "tldr_zh": "这篇论文调查了状态-of-the-art 机器学习方法在各种网络攻击检测中的性能，通过回顾过去 5 年的研究，特别是最近的作品，进行比较分析以识别知识空白。作者评估了不同分类器和框架的适用性、效率和局限性，结果显示当前方法在检测 drive-by download attacks 方面仍需进一步探索。论文还指出，需要改进 Naive Bayes 分类器的混合性能，并解决现有机器学习方法无法检测已受 SQLi attack 影响的数据库的问题，为未来研究方向提供指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10",
      "pdf_url": "http://arxiv.org/pdf/2402.17045v2",
      "published_date": "2024-02-26 22:04:25 UTC",
      "updated_date": "2024-05-10 06:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:02:58.748022"
    },
    {
      "arxiv_id": "2402.17042v2",
      "title": "Towards Generalizing Inferences from Trials to Target Populations",
      "title_zh": "翻译失败",
      "authors": [
        "Melody Y Huang",
        "Harsh Parikh"
      ],
      "abstract": "Randomized Controlled Trials (RCTs) are pivotal in generating internally\nvalid estimates with minimal assumptions, serving as a cornerstone for\nresearchers dedicated to advancing causal inference methods. However, extending\nthese findings beyond the experimental cohort to achieve externally valid\nestimates is crucial for broader scientific inquiry. This paper delves into the\nforefront of addressing these external validity challenges, encapsulating the\nessence of a multidisciplinary workshop held at the Institute for Computational\nand Experimental Research in Mathematics (ICERM), Brown University, in Fall\n2023. The workshop congregated experts from diverse fields including social\nscience, medicine, public health, statistics, computer science, and education,\nto tackle the unique obstacles each discipline faces in extrapolating\nexperimental findings. Our study presents three key contributions: we integrate\nongoing efforts, highlighting methodological synergies across fields; provide\nan exhaustive review of generalizability and transportability based on the\nworkshop's discourse; and identify persistent hurdles while suggesting avenues\nfor future research. By doing so, this paper aims to enhance the collective\nunderstanding of the generalizability and transportability of causal effects,\nfostering cross-disciplinary collaboration and offering valuable insights for\nresearchers working on refining and applying causal inference methods.",
      "tldr_zh": "本论文探讨了如何将随机对照试验 (RCTs) 的内部有效推断推广到目标人群，以实现外部有效性，从而提升因果推断方法的应用。该研究基于2023年在布朗大学ICERM举办的多学科研讨会，汇集了社会科学、医学、公共卫生、统计学、计算机科学和教育领域的专家，分析各领域在推广实验发现时面临的独特挑战。主要贡献包括：整合跨领域的方法协同、提供一般izability和transportability的详尽回顾，以及识别持续障碍并提出未来研究方向。通过此工作，论文旨在加强因果效应的可推广性理解，促进跨学科合作，并为因果推断方法的改进提供见解。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "econ.EM"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17042v2",
      "published_date": "2024-02-26 21:49:44 UTC",
      "updated_date": "2024-05-25 00:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:03:10.555739"
    },
    {
      "arxiv_id": "2402.17032v1",
      "title": "REFACTOR: Learning to Extract Theorems from Proofs",
      "title_zh": "REFACTOR：学习从证明中提取定理",
      "authors": [
        "Jin Peng Zhou",
        "Yuhuai Wu",
        "Qiyang Li",
        "Roger Grosse"
      ],
      "abstract": "Human mathematicians are often good at recognizing modular and reusable\ntheorems that make complex mathematical results within reach. In this paper, we\npropose a novel method called theoREm-from-prooF extrACTOR (REFACTOR) for\ntraining neural networks to mimic this ability in formal mathematical theorem\nproving. We show on a set of unseen proofs, REFACTOR is able to extract 19.6%\nof the theorems that humans would use to write the proofs. When applying the\nmodel to the existing Metamath library, REFACTOR extracted 16 new theorems.\nWith newly extracted theorems, we show that the existing proofs in the MetaMath\ndatabase can be refactored. The new theorems are used very frequently after\nrefactoring, with an average usage of 733.5 times, and help shorten the proof\nlengths. Lastly, we demonstrate that the prover trained on the new-theorem\nrefactored dataset proves more test theorems and outperforms state-of-the-art\nbaselines by frequently leveraging a diverse set of newly extracted theorems.\nCode can be found at https://github.com/jinpz/refactor.",
      "tldr_zh": "论文提出 REFACTOR 方法，通过训练神经网络从形式化数学证明中提取模块化和可重用的定理，模仿人类数学家识别定理的能力。实验显示，在未见证明集上，REFACTOR 提取了 19.6% 的定理，与人类选择相匹配，并在 Metamath 库中提取了 16 个新定理。使用这些新定理重构证明后，平均每条定理被使用 733.5 次，显著缩短证明长度，并使基于重构数据集训练的证明器性能超越最先进基线。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17032v1",
      "published_date": "2024-02-26 21:21:30 UTC",
      "updated_date": "2024-02-26 21:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:03:23.615778"
    },
    {
      "arxiv_id": "2402.17018v1",
      "title": "A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection",
      "title_zh": "一个奇特案例：通过全卷积、可微前端和跳跃连接实现对梯度攻击的显著抗性",
      "authors": [
        "Leonid Boytsov",
        "Ameya Joshi",
        "Filipe Condessa"
      ],
      "abstract": "We tested front-end enhanced neural models where a frozen classifier was\nprepended by a differentiable and fully convolutional model with a skip\nconnection. By training them using a small learning rate for about one epoch,\nwe obtained models that retained the accuracy of the backbone classifier while\nbeing unusually resistant to gradient attacks including APGD and FAB-T attacks\nfrom the AutoAttack package, which we attributed to gradient masking. The\ngradient masking phenomenon is not new, but the degree of masking was quite\nremarkable for fully differentiable models that did not have\ngradient-shattering components such as JPEG compression or components that are\nexpected to cause diminishing gradients.\n  Though black box attacks can be partially effective against gradient masking,\nthey are easily defeated by combining models into randomized ensembles. We\nestimate that such ensembles achieve near-SOTA AutoAttack accuracy on CIFAR10,\nCIFAR100, and ImageNet despite having virtually zero accuracy under adaptive\nattacks. Adversarial training of the backbone classifier can further increase\nresistance of the front-end enhanced model to gradient attacks. On CIFAR10, the\nrespective randomized ensemble achieved 90.8$\\pm 2.5$% (99% CI) accuracy under\nAutoAttack while having only 18.2$\\pm 3.6$% accuracy under the adaptive attack.\n  We do not establish SOTA in adversarial robustness. Instead, we make\nmethodological contributions and further supports the thesis that adaptive\nattacks designed with the complete knowledge of model architecture are crucial\nin demonstrating model robustness and that even the so-called white-box\ngradient attacks can have limited applicability. Although gradient attacks can\nbe complemented with black-box attack such as the SQUARE attack or the\nzero-order PGD, black-box attacks can be weak against randomized ensembles,\ne.g., when ensemble models mask gradients.",
      "tldr_zh": "本研究探索了一种在冻结分类器前添加可微分、全卷积前端（fully convolutional and differentiable front end）并带有跳跃连接（skip connection）的神经网络模型，通过小学习率训练约一轮，实现了对梯度攻击（如APGD和FAB-T）的异常抵抗力，该现象归因于梯度屏蔽（gradient masking）。尽管黑盒攻击能部分突破梯度屏蔽，但通过构建随机集成（randomized ensembles），这些攻击可被轻松击败，并在CIFAR10、CIFAR100和ImageNet上实现近SOTA的AutoAttack准确率。进一步结合adversarial training后，该模型在CIFAR10上的AutoAttack准确率达90.8±2.5%，但在自适应攻击下仅为18.2±3.6%。论文强调了自适应攻击在评估模型鲁棒性中的关键作用，并为梯度攻击的局限性提供了方法论贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17018v1",
      "published_date": "2024-02-26 20:55:47 UTC",
      "updated_date": "2024-02-26 20:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:03:35.827639"
    },
    {
      "arxiv_id": "2402.17016v1",
      "title": "Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Isabelle Mohr",
        "Markus Krimmel",
        "Saba Sturua",
        "Mohammad Kalim Akram",
        "Andreas Koukounas",
        "Michael Günther",
        "Georgios Mastrapas",
        "Vinit Ravishankar",
        "Joan Fontanals Martínez",
        "Feng Wang",
        "Qi Liu",
        "Ziniu Yu",
        "Jie Fu",
        "Saahil Ognawala",
        "Susana Guzman",
        "Bo Wang",
        "Maximilian Werk",
        "Nan Wang",
        "Han Xiao"
      ],
      "abstract": "We introduce a novel suite of state-of-the-art bilingual text embedding\nmodels that are designed to support English and another target language. These\nmodels are capable of processing lengthy text inputs with up to 8192 tokens,\nmaking them highly versatile for a range of natural language processing tasks\nsuch as text retrieval, clustering, and semantic textual similarity (STS)\ncalculations.\n  By focusing on bilingual models and introducing a unique multi-task learning\nobjective, we have significantly improved the model performance on STS tasks,\nwhich outperforms the capabilities of existing multilingual models in both\ntarget language understanding and cross-lingual evaluation tasks. Moreover, our\nbilingual models are more efficient, requiring fewer parameters and less memory\ndue to their smaller vocabulary needs. Furthermore, we have expanded the\nMassive Text Embedding Benchmark (MTEB) to include benchmarks for German and\nSpanish embedding models. This integration aims to stimulate further research\nand advancement in text embedding technologies for these languages.",
      "tldr_zh": "本研究提出了一种基于多任务对比学习(Multi-Task Contrastive Learning)的双语文本嵌入模型，支持英语和另一种目标语言，能处理长达8192标记的文本输入，适用于文本检索、聚类和语义文本相似性(STS)计算等任务。相比现有多语种模型，该模型在STS任务上显著提升了性能，尤其在目标语言理解和跨语言评估中表现出色，同时通过更小的词汇量实现了更高的效率，减少了参数和内存需求。研究者还扩展了Massive Text Embedding Benchmark (MTEB)，新增了德语和西班牙语的基准测试，以推动这些语言的文本嵌入技术发展。总的来说，这一创新为双语文本处理提供了更强大且实用的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17016v1",
      "published_date": "2024-02-26 20:53:12 UTC",
      "updated_date": "2024-02-26 20:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:03:46.412765"
    },
    {
      "arxiv_id": "2402.17013v1",
      "title": "Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Santosh T. Y. S. S",
        "Nina Baumgartner",
        "Matthias Stürmer",
        "Matthias Grabmair",
        "Joel Niklaus"
      ],
      "abstract": "The assessment of explainability in Legal Judgement Prediction (LJP) systems\nis of paramount importance in building trustworthy and transparent systems,\nparticularly considering the reliance of these systems on factors that may lack\nlegal relevance or involve sensitive attributes. This study delves into the\nrealm of explainability and fairness in LJP models, utilizing Swiss Judgement\nPrediction (SJP), the only available multilingual LJP dataset. We curate a\ncomprehensive collection of rationales that `support' and `oppose' judgement\nfrom legal experts for 108 cases in German, French, and Italian. By employing\nan occlusion-based explainability approach, we evaluate the explainability\nperformance of state-of-the-art monolingual and multilingual BERT-based LJP\nmodels, as well as models developed with techniques such as data augmentation\nand cross-lingual transfer, which demonstrated prediction performance\nimprovement. Notably, our findings reveal that improved prediction performance\ndoes not necessarily correspond to enhanced explainability performance,\nunderscoring the significance of evaluating models from an explainability\nperspective. Additionally, we introduce a novel evaluation framework, Lower\nCourt Insertion (LCI), which allows us to quantify the influence of lower court\ninformation on model predictions, exposing current models' biases.",
      "tldr_zh": "本研究聚焦于法律判断预测（LJP）系统的解释性和公平性评估，使用瑞士判断预测（SJP）数据集，这是目前唯一的多语言LJP数据集。研究人员为108个德语、法语和意大利语案例收集了支持和反对判断的理由，并采用基于遮挡（occlusion-based）的解释性方法，评估了单语和多语BERT-based模型的性能，包括通过数据增强和跨语言转移技术改进的模型。结果显示，提升预测性能并不必然带来更好的解释性性能，突显了从解释性角度评估模型的重要性。此外，引入了Lower Court Insertion (LCI)新框架，用于量化下级法院信息对模型预测的影响，从而暴露和缓解模型偏差。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.17013v1",
      "published_date": "2024-02-26 20:42:40 UTC",
      "updated_date": "2024-02-26 20:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:03:59.318965"
    },
    {
      "arxiv_id": "2402.17012v4",
      "title": "Pandora's White-Box: Precise Training Data Detection and Extraction in Large Language Models",
      "title_zh": "Pandora's White-Box：在大型语言模型中精确的训练数据检测和提取",
      "authors": [
        "Jeffrey G. Wang",
        "Jason Wang",
        "Marvin Li",
        "Seth Neel"
      ],
      "abstract": "In this paper we develop state-of-the-art privacy attacks against Large\nLanguage Models (LLMs), where an adversary with some access to the model tries\nto learn something about the underlying training data. Our headline results are\nnew membership inference attacks (MIAs) against pretrained LLMs that perform\nhundreds of times better than baseline attacks, and a pipeline showing that\nover 50% (!) of the fine-tuning dataset can be extracted from a fine-tuned LLM\nin natural settings. We consider varying degrees of access to the underlying\nmodel, pretraining and fine-tuning data, and both MIAs and training data\nextraction. For pretraining data, we propose two new MIAs: a supervised neural\nnetwork classifier that predicts training data membership on the basis of\n(dimensionality-reduced) model gradients, as well as a variant of this attack\nthat only requires logit access to the model by leveraging recent\nmodel-stealing work on LLMs. To our knowledge this is the first MIA that\nexplicitly incorporates model-stealing information. Both attacks outperform\nexisting black-box baselines, and our supervised attack closes the gap between\nMIA attack success against LLMs and the strongest known attacks for other\nmachine learning models. In fine-tuning, we find that a simple attack based on\nthe ratio of the loss between the base and fine-tuned models is able to achieve\nnear-perfect MIA performance; we then leverage our MIA to extract a large\nfraction of the fine-tuning dataset from fine-tuned Pythia and Llama models.\nOur code is available at github.com/safr-ai-lab/pandora-llm.",
      "tldr_zh": "本研究开发了针对大型语言模型（LLMs）的先进隐私攻击方法，旨在揭示模型训练数据的潜在信息。研究提出两种新成员推断攻击（MIAs）：一个基于模型梯度的监督神经网络分类器，以及一个仅需 logit 访问的变体，通过整合模型窃取技术，显著优于现有黑盒基线攻击。实验结果显示，这些攻击在预训练数据上性能提升数百倍，而在微调场景中，一个简单的损失比攻击实现了近乎完美的 MIA 性能，并成功从微调的 Pythia 和 Llama 模型中提取超过 50% 的训练数据集。该工作为评估和提升 LLMs 的隐私保护提供了重要洞见，并公开了相关代码。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Found software bug in experiments, withdrawing in order to address\n  and update results",
      "pdf_url": "http://arxiv.org/pdf/2402.17012v4",
      "published_date": "2024-02-26 20:41:50 UTC",
      "updated_date": "2024-07-15 02:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:04:11.473195"
    },
    {
      "arxiv_id": "2402.17010v2",
      "title": "Generative Retrieval with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Wang",
        "Xinrun Xu",
        "Rui Xie",
        "Wenxin Hu",
        "Wei Ye"
      ],
      "abstract": "When completing knowledge-intensive tasks, humans sometimes need not just an\nanswer but also a corresponding reference passage for auxiliary reading.\nPrevious methods required obtaining pre-segmented article chunks through\nadditional retrieval models. This paper explores leveraging the parameterized\nknowledge stored during the pre-training phase of large language models (LLMs)\nto independently recall reference passage from any starting position. We\npropose a two-stage framework that simulates the scenario of humans recalling\neasily forgotten references. Initially, the LLM is prompted to recall document\ntitle identifiers to obtain a coarse-grained document set. Then, based on the\nacquired coarse-grained document set, it recalls fine-grained passage. In the\ntwo-stage recall process, we use constrained decoding to ensure that content\noutside of the stored documents is not generated. To increase speed, we only\nrecall a short prefix in the second stage, then locate its position to retrieve\na complete passage. Experiments on KILT knowledge-sensitive tasks have verified\nthat LLMs can independently recall reference passage location in various task\nforms, and the obtained reference significantly assist downstream tasks.",
      "tldr_zh": "本论文探讨了利用大型语言模型 (LLMs) 进行生成式检索的方法，旨在从模型预训练参数中独立回忆参考段落，以支持知识密集型任务，而非依赖额外检索模型。框架采用两阶段过程：首先，LLM 通过提示回忆文档标题标识符获取粗粒度文档集；其次，在此基础上回忆细粒度段落，并使用约束解码确保只生成存储内容。实验在 KILT 知识敏感任务上证明，该方法能准确定位参考段落位置，并显著提升下游任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17010v2",
      "published_date": "2024-02-26 20:35:32 UTC",
      "updated_date": "2024-10-29 08:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:04:23.516783"
    },
    {
      "arxiv_id": "2402.17003v2",
      "title": "Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials",
      "title_zh": "翻译失败",
      "authors": [
        "Anna L. Trella",
        "Kelly W. Zhang",
        "Inbal Nahum-Shani",
        "Vivek Shetty",
        "Iris Yan",
        "Finale Doshi-Velez",
        "Susan A. Murphy"
      ],
      "abstract": "Online reinforcement learning (RL) algorithms offer great potential for\npersonalizing treatment for participants in clinical trials. However, deploying\nan online, autonomous algorithm in the high-stakes healthcare setting makes\nquality control and data quality especially difficult to achieve. This paper\nproposes algorithm fidelity as a critical requirement for deploying online RL\nalgorithms in clinical trials. It emphasizes the responsibility of the\nalgorithm to (1) safeguard participants and (2) preserve the scientific utility\nof the data for post-trial analyses. We also present a framework for\npre-deployment planning and real-time monitoring to help algorithm developers\nand clinical researchers ensure algorithm fidelity. To illustrate our\nframework's practical application, we present real-world examples from the\nOralytics clinical trial. Since Spring 2023, this trial successfully deployed\nan autonomous, online RL algorithm to personalize behavioral interventions for\nparticipants at risk for dental disease.",
      "tldr_zh": "这篇论文强调在线 reinforcement learning (RL) 算法在临床试验中的算法忠诚度 (algorithm fidelity) 至关重要，以保护参与者和保留数据科学效用。作者提出一个框架，包括部署前规划和实时监控，帮助算法开发者与临床研究者确保算法质量。该框架已在 Oralytics 临床试验中成功应用，自 2023 年春季以来，通过自主在线 RL 算法个性化行为干预，证明了其实际有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17003v2",
      "published_date": "2024-02-26 20:19:14 UTC",
      "updated_date": "2024-08-12 16:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:04:35.197935"
    },
    {
      "arxiv_id": "2402.16998v2",
      "title": "What Do Language Models Hear? Probing for Auditory Representations in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Ngo",
        "Yoon Kim"
      ],
      "abstract": "This work explores whether language models encode meaningfully grounded\nrepresentations of sounds of objects. We learn a linear probe that retrieves\nthe correct text representation of an object given a snippet of audio related\nto that object, where the sound representation is given by a pretrained audio\nmodel. This probe is trained via a contrastive loss that pushes the language\nrepresentations and sound representations of an object to be close to one\nanother. After training, the probe is tested on its ability to generalize to\nobjects that were not seen during training. Across different language models\nand audio models, we find that the probe generalization is above chance in many\ncases, indicating that despite being trained only on raw text, language models\nencode grounded knowledge of sounds for some objects.",
      "tldr_zh": "本文研究探讨了语言模型是否编码了物体的声音表示（auditory representations）。研究人员训练了一个线性探针（linear probe），通过对比损失（contrastive loss）将语言模型的文本表示与预训练音频模型的声音表示对齐，从而从音频片段中检索物体的正确文本表示。实验结果显示，该探针在不同语言模型和音频模型上，对未见训练的物体表现出超出随机水平的泛化能力，表明即使仅在纯文本上训练，语言模型也可能内嵌某些物体的 grounded 声音知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16998v2",
      "published_date": "2024-02-26 20:13:58 UTC",
      "updated_date": "2024-08-16 08:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:04:47.594743"
    },
    {
      "arxiv_id": "2403.00011v1",
      "title": "Introducing User Feedback-based Counterfactual Explanations (UFCE)",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Suffian",
        "Jose M. Alonso-Moral",
        "Alessandro Bogliolo"
      ],
      "abstract": "Machine learning models are widely used in real-world applications. However,\ntheir complexity makes it often challenging to interpret the rationale behind\ntheir decisions. Counterfactual explanations (CEs) have emerged as a viable\nsolution for generating comprehensible explanations in eXplainable Artificial\nIntelligence (XAI). CE provides actionable information to users on how to\nachieve the desired outcome with minimal modifications to the input. However,\ncurrent CE algorithms usually operate within the entire feature space when\noptimizing changes to turn over an undesired outcome, overlooking the\nidentification of key contributors to the outcome and disregarding the\npracticality of the suggested changes. In this study, we introduce a novel\nmethodology, that is named as user feedback-based counterfactual explanation\n(UFCE), which addresses these limitations and aims to bolster confidence in the\nprovided explanations. UFCE allows for the inclusion of user constraints to\ndetermine the smallest modifications in the subset of actionable features while\nconsidering feature dependence, and evaluates the practicality of suggested\nchanges using benchmark evaluation metrics. We conducted three experiments with\nfive datasets, demonstrating that UFCE outperforms two well-known CE methods in\nterms of \\textit{proximity}, \\textit{sparsity}, and \\textit{feasibility}.\nReported results indicate that user constraints influence the generation of\nfeasible CEs.",
      "tldr_zh": "该论文提出了一种新方法，名为 User Feedback-based Counterfactual Explanations (UFCE)，旨在解决现有 Counterfactual explanations (CEs) 在解释机器学习模型决策时忽略关键特征和实用性问题的局限性。UFCE 通过整合用户约束，在可行动特征的子集中进行最小修改，同时考虑特征依赖，并使用基准指标评估建议变化的可行性。实验结果显示，在五个数据集上的三个实验中，UFCE 在 proximity、sparsity 和 feasibility 方面优于两种知名 CE 方法，并证明用户约束能显著影响可行 CE 的生成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint of paper submitted to IJCIS Springer",
      "pdf_url": "http://arxiv.org/pdf/2403.00011v1",
      "published_date": "2024-02-26 20:09:44 UTC",
      "updated_date": "2024-02-26 20:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:04:58.683735"
    },
    {
      "arxiv_id": "2402.16994v2",
      "title": "GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitry Petrov",
        "Pradyumn Goyal",
        "Vikas Thamizharasan",
        "Vladimir G. Kim",
        "Matheus Gadelha",
        "Melinos Averkiou",
        "Siddhartha Chaudhuri",
        "Evangelos Kalogerakis"
      ],
      "abstract": "We introduce GEM3D -- a new deep, topology-aware generative model of 3D\nshapes. The key ingredient of our method is a neural skeleton-based\nrepresentation encoding information on both shape topology and geometry.\nThrough a denoising diffusion probabilistic model, our method first generates\nskeleton-based representations following the Medial Axis Transform (MAT), then\ngenerates surfaces through a skeleton-driven neural implicit formulation. The\nneural implicit takes into account the topological and geometric information\nstored in the generated skeleton representations to yield surfaces that are\nmore topologically and geometrically accurate compared to previous neural field\nformulations. We discuss applications of our method in shape synthesis and\npoint cloud reconstruction tasks, and evaluate our method both qualitatively\nand quantitatively. We demonstrate significantly more faithful surface\nreconstruction and diverse shape generation results compared to the\nstate-of-the-art, also involving challenging scenarios of reconstructing and\nsynthesizing structurally complex, high-genus shape surfaces from Thingi10K and\nShapeNet.",
      "tldr_zh": "本研究引入了 GEM3D，一种新的深度拓扑感知生成模型，用于 3D 形状合成，该模型利用神经骨骼表示来编码形状的拓扑和几何信息。\nGEM3D 通过去噪扩散概率模型（denoising diffusion probabilistic model）首先生成基于 Medial Axis Transform (MAT) 的骨骼表示，然后采用骨骼驱动的神经隐式公式合成表面，从而实现比传统神经场方法更高的拓扑和几何准确性。\n实验结果显示，该方法在形状合成和点云重建任务中表现出色，在 Thingi10K 和 ShapeNet 数据集上实现了更忠实的表面重建和更丰富的形状生成，尤其适用于复杂高属形状。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Webpage: https://lodurality.github.io/GEM3D/ -- Cond. accept. to\n  SIGGRAPH 2024 (conf. track) -- Changes (based on reviews): changed style to\n  sigconf; rearranged figures for readability; added missing citations; fixed\n  misaligned centers in Fig. 3; added failure cases (Fig. 10); rewrote\n  discussion; added categories averages to Tab. 8; added Tab. 10 with model\n  capacities",
      "pdf_url": "http://arxiv.org/pdf/2402.16994v2",
      "published_date": "2024-02-26 20:00:57 UTC",
      "updated_date": "2024-04-11 03:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:05:12.492071"
    },
    {
      "arxiv_id": "2402.16973v2",
      "title": "Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections",
      "title_zh": "翻译失败",
      "authors": [
        "Lingjun Zhao",
        "Khanh Nguyen",
        "Hal Daumé III"
      ],
      "abstract": "Language models will inevitably err in situations with which they are\nunfamiliar. However, by effectively communicating uncertainties, they can still\nguide humans toward making sound decisions in those contexts. We demonstrate\nthis idea by developing HEAR, a system that can successfully guide humans in\nsimulated residential environments despite generating potentially inaccurate\ninstructions. Diverging from systems that provide users with only the\ninstructions they generate, HEAR warns users of potential errors in its\ninstructions and suggests corrections. This rich uncertainty information\neffectively prevents misguidance and reduces the search space for users.\nEvaluation with 80 users shows that HEAR achieves a 13% increase in success\nrate and a 29% reduction in final location error distance compared to only\npresenting instructions to users. Interestingly, we find that offering users\npossibilities to explore, HEAR motivates them to make more attempts at the\ntask, ultimately leading to a higher success rate. To our best knowledge, this\nwork is the first to show the practical benefits of uncertainty communication\nin a long-horizon sequential decision-making problem.",
      "tldr_zh": "这篇论文提出 HEAR 系统，用于指导人类在模拟住宅环境中执行任务，尽管语言模型的指令可能不准确。HEAR 通过突出潜在错误并建议修正来有效沟通不确定性，从而防止误导并缩小用户的搜索空间。实验结果显示，与仅提供指令相比，HEAR 使成功率提高了 13%，最终位置错误距离减少了 29%，并鼓励用户更多尝试，最终首次证明了不确定性沟通在长时序决策问题中的实际益处。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16973v2",
      "published_date": "2024-02-26 19:16:04 UTC",
      "updated_date": "2024-10-05 01:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:05:22.647903"
    },
    {
      "arxiv_id": "2402.16968v1",
      "title": "A Survey of Large Language Models in Cybersecurity",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel de Jesus Coelho da Silva",
        "Carlos Becker Westphall"
      ],
      "abstract": "Large Language Models (LLMs) have quickly risen to prominence due to their\nability to perform at or close to the state-of-the-art in a variety of fields\nwhile handling natural language. An important field of research is the\napplication of such models at the cybersecurity context. This survey aims to\nidentify where in the field of cybersecurity LLMs have already been applied,\nthe ways in which they are being used and their limitations in the field.\nFinally, suggestions are made on how to improve such limitations and what can\nbe expected from these systems once these limitations are overcome.",
      "tldr_zh": "本调查综述了Large Language Models (LLMs)在网络安全领域的应用，识别了这些模型已在诸如威胁检测、漏洞分析和响应自动化等领域中的具体用途。论文分析了LLMs的优势，如处理自然语言的能力，以及其局限性，包括潜在的准确性问题和易受攻击的风险。最终，作者提出了改进建议，如增强模型鲁棒性和整合更多领域知识，并展望了克服这些限制后，LLMs在网络安全中实现更大潜力的前景。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16968v1",
      "published_date": "2024-02-26 19:06:02 UTC",
      "updated_date": "2024-02-26 19:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:05:34.067758"
    },
    {
      "arxiv_id": "2402.16965v1",
      "title": "WIPI: A New Web Threat for LLM-Driven Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Fangzhou Wu",
        "Shutong Wu",
        "Yulong Cao",
        "Chaowei Xiao"
      ],
      "abstract": "With the fast development of large language models (LLMs), LLM-driven Web\nAgents (Web Agents for short) have obtained tons of attention due to their\nsuperior capability where LLMs serve as the core part of making decisions like\nthe human brain equipped with multiple web tools to actively interact with\nexternal deployed websites. As uncountable Web Agents have been released and\nsuch LLM systems are experiencing rapid development and drawing closer to\nwidespread deployment in our daily lives, an essential and pressing question\narises: \"Are these Web Agents secure?\". In this paper, we introduce a novel\nthreat, WIPI, that indirectly controls Web Agent to execute malicious\ninstructions embedded in publicly accessible webpages. To launch a successful\nWIPI works in a black-box environment. This methodology focuses on the form and\ncontent of indirect instructions within external webpages, enhancing the\nefficiency and stealthiness of the attack. To evaluate the effectiveness of the\nproposed methodology, we conducted extensive experiments using 7 plugin-based\nChatGPT Web Agents, 8 Web GPTs, and 3 different open-source Web Agents. The\nresults reveal that our methodology achieves an average attack success rate\n(ASR) exceeding 90% even in pure black-box scenarios. Moreover, through an\nablation study examining various user prefix instructions, we demonstrated that\nthe WIPI exhibits strong robustness, maintaining high performance across\ndiverse prefix instructions.",
      "tldr_zh": "本文研究了大型语言模型 (LLM) 驱动的 Web Agents 的安全问题，引入了一种新型威胁 WIPI，该威胁通过在公共网页中嵌入恶意指令来间接控制 Web Agents，在黑箱环境中实现高效且隐蔽的攻击。WIPI 的方法专注于指令的形式和内容，并在 7 个插件-based ChatGPT Web Agents、8 个 Web GPTs 和 3 个开源 Web Agents 上进行实验，结果显示平均攻击成功率 (ASR) 超过 90%。此外，消融研究证明 WIPI 对各种用户前缀指令具有强鲁棒性，为评估和提升 Web Agents 的安全性提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16965v1",
      "published_date": "2024-02-26 19:01:54 UTC",
      "updated_date": "2024-02-26 19:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:05:47.555748"
    },
    {
      "arxiv_id": "2402.16846v2",
      "title": "GROUNDHOG: Grounding Large Language Models to Holistic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yichi Zhang",
        "Ziqiao Ma",
        "Xiaofeng Gao",
        "Suhaila Shakiah",
        "Qiaozi Gao",
        "Joyce Chai"
      ],
      "abstract": "Most multimodal large language models (MLLMs) learn language-to-object\ngrounding through causal language modeling where grounded objects are captured\nby bounding boxes as sequences of location tokens. This paradigm lacks\npixel-level representations that are important for fine-grained visual\nunderstanding and diagnosis. In this work, we introduce GROUNDHOG, an MLLM\ndeveloped by grounding Large Language Models to holistic segmentation.\nGROUNDHOG incorporates a masked feature extractor and converts extracted\nfeatures into visual entity tokens for the MLLM backbone, which then connects\ngroundable phrases to unified grounding masks by retrieving and merging the\nentity masks. To train GROUNDHOG, we carefully curated M3G2, a grounded visual\ninstruction tuning dataset with Multi-Modal Multi-Grained Grounding, by\nharvesting a collection of segmentation-grounded datasets with rich\nannotations. Our experimental results show that GROUNDHOG achieves superior\nperformance on various language grounding tasks without task-specific\nfine-tuning, and significantly reduces object hallucination. GROUNDHOG also\ndemonstrates better grounding towards complex forms of visual input and\nprovides easy-to-understand diagnosis in failure cases.",
      "tldr_zh": "本研究提出 GROUNDHOG，一种将大语言模型 grounding 到整体分割的多模态大语言模型 (MLLMs)，以解决现有模型因依赖边界框而缺少像素级表示，从而无法实现细粒度视觉理解和诊断的问题。GROUNDHOG 通过 masked feature extractor 提取特征，并将这些特征转换为视觉实体 tokens，然后在 MLLM 主干中检索和合并实体 masks，将可 grounding 短语连接到统一的 grounding masks。研究者构建了 M3G2 数据集，这是一个多模态多粒度 grounding 的视觉指令微调数据集，由多种带有丰富注释的分割数据集汇集而成。实验结果显示，GROUNDHOG 在各种语言 grounding 任务上无需任务特定微调即可实现优越性能，显著减少对象 hallucination，并对复杂视觉输入提供更好的 grounding 和易于理解的失败诊断。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2024. Website: https://groundhog-mllm.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.16846v2",
      "published_date": "2024-02-26 18:59:33 UTC",
      "updated_date": "2024-04-16 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:06:00.207774"
    },
    {
      "arxiv_id": "2402.16845v2",
      "title": "Neural Operators with Localized Integral and Differential Kernels",
      "title_zh": "具有局部积分和微分核的神经算子",
      "authors": [
        "Miguel Liu-Schiaffini",
        "Julius Berner",
        "Boris Bonev",
        "Thorsten Kurth",
        "Kamyar Azizzadenesheli",
        "Anima Anandkumar"
      ],
      "abstract": "Neural operators learn mappings between function spaces, which is practical\nfor learning solution operators of PDEs and other scientific modeling\napplications. Among them, the Fourier neural operator (FNO) is a popular\narchitecture that performs global convolutions in the Fourier space. However,\nsuch global operations are often prone to over-smoothing and may fail to\ncapture local details. In contrast, convolutional neural networks (CNN) can\ncapture local features but are limited to training and inference at a single\nresolution. In this work, we present a principled approach to operator learning\nthat can capture local features under two frameworks by learning differential\noperators and integral operators with locally supported kernels. Specifically,\ninspired by stencil methods, we prove that we obtain differential operators\nunder an appropriate scaling of the kernel values of CNNs. To obtain local\nintegral operators, we utilize suitable basis representations for the kernels\nbased on discrete-continuous convolutions. Both these approaches preserve the\nproperties of operator learning and, hence, the ability to predict at any\nresolution. Adding our layers to FNOs significantly improves their performance,\nreducing the relative L2-error by 34-72% in our experiments, which include a\nturbulent 2D Navier-Stokes and the spherical shallow water equations.",
      "tldr_zh": "这篇论文提出了一种改进神经算子（neural operators）的框架，使用局部积分和差分核来学习函数空间映射，特别是针对PDEs解算子的科学建模应用，以克服Fourier neural operator (FNO)的全局卷积问题。方法包括基于stencil methods的差分算子学习，通过适当缩放CNN的核值实现局部特征捕捉，以及利用discrete-continuous convolutions的核表示来构建局部积分算子，这些均保留了在任意分辨率下预测的能力。在实验中，将这些层添加到FNO中后，性能显著提升，在2D Navier-Stokes和spherical shallow water equations等任务上，相对L2-error降低了34-72%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2024 International Conference on Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2402.16845v2",
      "published_date": "2024-02-26 18:59:31 UTC",
      "updated_date": "2024-06-08 22:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:06:13.474954"
    },
    {
      "arxiv_id": "2402.16844v3",
      "title": "Think Big, Generate Quick: LLM-to-SLM for Fast Autoregressive Decoding",
      "title_zh": "Think Big, Generate Quick：LLM-to-SLM 用于快速自回归解码",
      "authors": [
        "Benjamin Bergner",
        "Andrii Skliar",
        "Amelie Royer",
        "Tijmen Blankevoort",
        "Yuki Asano",
        "Babak Ehteshami Bejnordi"
      ],
      "abstract": "Large language models (LLMs) have become ubiquitous in practice and are\nwidely used for generation tasks such as translation, summarization and\ninstruction following. However, their enormous size and reliance on\nautoregressive decoding increase deployment costs and complicate their use in\nlatency-critical applications. In this work, we propose a hybrid approach that\ncombines language models of different sizes to increase the efficiency of\nautoregressive decoding while maintaining high performance. Our method utilizes\na pretrained frozen LLM that encodes all prompt tokens once in parallel, and\nuses the resulting representations to condition and guide a small language\nmodel (SLM), which then generates the response more efficiently. We investigate\nthe combination of encoder-decoder LLMs with both encoder-decoder and\ndecoder-only SLMs from different model families and only require fine-tuning of\nthe SLM. Experiments with various benchmarks show substantial speedups of up to\n$4\\times$, with minor performance penalties of $1-2\\%$ for translation and\nsummarization tasks compared to the LLM.",
      "tldr_zh": "本文提出了一种混合方法“LLM-to-SLM”，旨在通过结合大型语言模型 (LLM) 和小型语言模型 (SLM) 来提升自回归解码的效率，同时保持高性能。方法利用预训练的冻结 LLM 一次性并行编码所有提示标记，然后用这些表示来指导 SLM 生成响应，仅需对 SLM 进行微调。实验结果显示，在各种基准任务上，该方法实现了高达 4 倍的速度提升，而在翻译和总结任务中，仅有 1-2% 的性能损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work presented at the ES-FoMo II Workshop at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16844v3",
      "published_date": "2024-02-26 18:59:28 UTC",
      "updated_date": "2024-07-17 13:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:06:24.756609"
    },
    {
      "arxiv_id": "2402.16843v2",
      "title": "Multi-LoRA Composition for Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Zhong",
        "Yelong Shen",
        "Shuohang Wang",
        "Yadong Lu",
        "Yizhu Jiao",
        "Siru Ouyang",
        "Donghan Yu",
        "Jiawei Han",
        "Weizhu Chen"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) is extensively utilized in text-to-image models\nfor the accurate rendition of specific elements like distinct characters or\nunique styles in generated images. Nonetheless, existing methods face\nchallenges in effectively composing multiple LoRAs, especially as the number of\nLoRAs to be integrated grows, thus hindering the creation of complex imagery.\nIn this paper, we study multi-LoRA composition through a decoding-centric\nperspective. We present two training-free methods: LoRA Switch, which\nalternates between different LoRAs at each denoising step, and LoRA Composite,\nwhich simultaneously incorporates all LoRAs to guide more cohesive image\nsynthesis. To evaluate the proposed approaches, we establish ComposLoRA, a new\ncomprehensive testbed as part of this research. It features a diverse range of\nLoRA categories with 480 composition sets. Utilizing an evaluation framework\nbased on GPT-4V, our findings demonstrate a clear improvement in performance\nwith our methods over the prevalent baseline, particularly evident when\nincreasing the number of LoRAs in a composition. The code, benchmarks, LoRA\nweights, and all evaluation details are available on our project website:\nhttps://maszhongming.github.io/Multi-LoRA-Composition.",
      "tldr_zh": "该论文探讨了在图像生成中组合多个 Low-Rank Adaptation (LoRA) 的挑战，提出两种无训练方法：LoRA Switch（在每个去噪步骤切换不同 LoRA）和 LoRA Composite（同时整合所有 LoRA 以实现更连贯的图像合成）。这些方法从解码视角优化多 LoRA 组合，提升了复杂图像生成的准确性。论文还建立了 ComposLoRA 基准，包括 480 个多样化组合集，并通过 GPT-4V 评估框架证明了新方法在增加 LoRA 数量时比基线模型有显著性能改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Transactions on Machine Learning Research (TMLR), 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16843v2",
      "published_date": "2024-02-26 18:59:18 UTC",
      "updated_date": "2024-11-19 02:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:06:36.176035"
    },
    {
      "arxiv_id": "2402.16836v1",
      "title": "PhyGrasp: Generalizing Robotic Grasping with Physics-informed Large Multimodal Models",
      "title_zh": "PhyGrasp：基于物理信息的大型多模态模型用于机器人抓",
      "authors": [
        "Dingkun Guo",
        "Yuqi Xiang",
        "Shuqi Zhao",
        "Xinghao Zhu",
        "Masayoshi Tomizuka",
        "Mingyu Ding",
        "Wei Zhan"
      ],
      "abstract": "Robotic grasping is a fundamental aspect of robot functionality, defining how\nrobots interact with objects. Despite substantial progress, its\ngeneralizability to counter-intuitive or long-tailed scenarios, such as objects\nwith uncommon materials or shapes, remains a challenge. In contrast, humans can\neasily apply their intuitive physics to grasp skillfully and change grasps\nefficiently, even for objects they have never seen before.\n  This work delves into infusing such physical commonsense reasoning into\nrobotic manipulation. We introduce PhyGrasp, a multimodal large model that\nleverages inputs from two modalities: natural language and 3D point clouds,\nseamlessly integrated through a bridge module. The language modality exhibits\nrobust reasoning capabilities concerning the impacts of diverse physical\nproperties on grasping, while the 3D modality comprehends object shapes and\nparts. With these two capabilities, PhyGrasp is able to accurately assess the\nphysical properties of object parts and determine optimal grasping poses.\nAdditionally, the model's language comprehension enables human instruction\ninterpretation, generating grasping poses that align with human preferences. To\ntrain PhyGrasp, we construct a dataset PhyPartNet with 195K object instances\nwith varying physical properties and human preferences, alongside their\ncorresponding language descriptions. Extensive experiments conducted in the\nsimulation and on the real robots demonstrate that PhyGrasp achieves\nstate-of-the-art performance, particularly in long-tailed cases, e.g., about\n10% improvement in success rate over GraspNet. Project page:\nhttps://sites.google.com/view/phygrasp",
      "tldr_zh": "该研究针对机器人抓取在反直觉或长尾场景（如不常见材料或形状物体）的泛化挑战，提出PhyGrasp，一种基于physics-informed的多模态大型模型。该模型通过桥接模块整合自然语言（处理物理属性影响）和3D point clouds（理解物体形状和部分），实现对物体物理属性的准确评估和最佳抓取姿势的生成，同时支持人类指令解释。为训练PhyGrasp，研究者构建了数据集PhyPartNet，包含195K物体实例、物理属性、人类偏好及语言描述。在模拟和真实机器人实验中，PhyGrasp 实现了state-of-the-art性能，尤其在长尾案例中，比GraspNet成功率提高了约10%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16836v1",
      "published_date": "2024-02-26 18:57:52 UTC",
      "updated_date": "2024-02-26 18:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:06:49.432052"
    },
    {
      "arxiv_id": "2402.16832v2",
      "title": "Cross-Modal Projection in Multimodal LLMs Doesn't Really Project Visual Attributes to Textual Space",
      "title_zh": "多模态大语言模型中的跨模态投影并不真正将视觉属性投影到文本空间",
      "authors": [
        "Gaurav Verma",
        "Minje Choi",
        "Kartik Sharma",
        "Jamelle Watson-Daniels",
        "Sejoon Oh",
        "Srijan Kumar"
      ],
      "abstract": "Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable\ngeneral-purpose conversations about images with the language modality. As\noff-the-shelf MLLMs may have limited capabilities on images from domains like\ndermatology and agriculture, they must be fine-tuned to unlock domain-specific\napplications. The prevalent architecture of current open-source MLLMs comprises\ntwo major modules: an image-language (cross-modal) projection network and a\nlarge language model. It is desirable to understand the roles of these two\nmodules in modeling domain-specific visual attributes to inform the design of\nfuture models and streamline the interpretability efforts on the current\nmodels. To this end, via experiments on 4 datasets and under 2 fine-tuning\nsettings, we find that as the MLLM is fine-tuned, it indeed gains\ndomain-specific visual capabilities, but the updates do not lead to the\nprojection extracting relevant domain-specific visual attributes. Our results\nindicate that the domain-specific visual attributes are modeled by the LLM,\neven when only the projection is fine-tuned. Through this study, we offer a\npotential reinterpretation of the role of cross-modal projections in MLLM\narchitectures. Project webpage:\nhttps://claws-lab.github.io/projection-in-MLLMs/",
      "tldr_zh": "本研究质疑了多模态大型语言模型（Multimodal LLMs）中跨模态投影（cross-modal projection）的实际作用，通过在4个数据集和2个fine-tuning设置下的实验，揭示了模型在获得领域特定视觉能力后，这些能力并非由投影提取相关视觉属性，而是由大型语言模型（LLM）来建模。结果表明，即使只微调投影，领域特定视觉属性也主要依赖LLM，这为MLLMs架构的设计和可解释性提供了新的解读视角。项目网页：https://claws-lab.github.io/projection-in-MLLMs/。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 (Main, Short)",
      "pdf_url": "http://arxiv.org/pdf/2402.16832v2",
      "published_date": "2024-02-26 18:56:48 UTC",
      "updated_date": "2024-07-21 18:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:01.712898"
    },
    {
      "arxiv_id": "2402.16828v2",
      "title": "Training Neural Networks from Scratch with Parallel Low-Rank Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Minyoung Huh",
        "Brian Cheung",
        "Jeremy Bernstein",
        "Phillip Isola",
        "Pulkit Agrawal"
      ],
      "abstract": "The scalability of deep learning models is fundamentally limited by computing\nresources, memory, and communication. Although methods like low-rank adaptation\n(LoRA) have reduced the cost of model finetuning, its application in model\npre-training remains largely unexplored. This paper explores extending LoRA to\nmodel pre-training, identifying the inherent constraints and limitations of\nstandard LoRA in this context. We introduce LoRA-the-Explorer (LTE), a novel\nbi-level optimization algorithm designed to enable parallel training of\nmultiple low-rank heads across computing nodes, thereby reducing the need for\nfrequent synchronization. Our approach includes extensive experimentation on\nvision transformers using various vision datasets, demonstrating that LTE is\ncompetitive with standard pre-training.",
      "tldr_zh": "本论文探讨了使用 Parallel Low-Rank Adapters 进行神经网络从零预训练，以解决计算资源、内存和通信的限制问题。作者引入了 LoRA-the-Explorer (LTE)，一种双层优化算法，支持在多个计算节点上并行训练多个低秩头，从而减少同步需求。该方法在视觉变压器和各种视觉数据集上的实验显示，LTE 的性能与标准预训练相当，证明了其在高效预训练方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16828v2",
      "published_date": "2024-02-26 18:55:13 UTC",
      "updated_date": "2024-07-26 21:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:12.466296"
    },
    {
      "arxiv_id": "2402.16823v3",
      "title": "Language Agents as Optimizable Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Mingchen Zhuge",
        "Wenyi Wang",
        "Louis Kirsch",
        "Francesco Faccio",
        "Dmitrii Khizbullin",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Various human-designed prompt engineering techniques have been proposed to\nimprove problem solvers based on Large Language Models (LLMs), yielding many\ndisparate code bases. We unify these approaches by describing LLM-based agents\nas computational graphs. The nodes implement functions to process multimodal\ndata or query LLMs, and the edges describe the information flow between\noperations. Graphs can be recursively combined into larger composite graphs\nrepresenting hierarchies of inter-agent collaboration (where edges connect\noperations of different agents). Our novel automatic graph optimizers (1)\nrefine node-level LLM prompts (node optimization) and (2) improve agent\norchestration by changing graph connectivity (edge optimization). Experiments\ndemonstrate that our framework can be used to efficiently develop, integrate,\nand automatically improve various LLM agents. The code can be found at\nhttps://github.com/metauto-ai/gptswarm.",
      "tldr_zh": "该论文将基于 Large Language Models (LLMs) 的代理建模为可优化的计算图，统一了各种提示工程技巧，其中节点处理多模态数据或查询 LLMs，边表示信息流，支持递归组合以实现代理间的层次协作。研究引入自动图优化器，包括节点优化（优化 LLM prompts）和边优化（调整图连接以改进代理编排）。实验结果显示，该框架能高效开发、整合和自动提升各种 LLM 代理的性能，为代理优化提供了通用方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Project Website: https://gptswarm.org ; Github Repo:\n  https://github.com/metauto-ai/gptswarm . In Forty-first International\n  Conference on Machine Learning (2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.16823v3",
      "published_date": "2024-02-26 18:48:27 UTC",
      "updated_date": "2024-08-22 13:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:23.258956"
    },
    {
      "arxiv_id": "2402.16822v3",
      "title": "Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Mikayel Samvelyan",
        "Sharath Chandra Raparthy",
        "Andrei Lupu",
        "Eric Hambro",
        "Aram H. Markosyan",
        "Manish Bhatt",
        "Yuning Mao",
        "Minqi Jiang",
        "Jack Parker-Holder",
        "Jakob Foerster",
        "Tim Rocktäschel",
        "Roberta Raileanu"
      ],
      "abstract": "As large language models (LLMs) become increasingly prevalent across many\nreal-world applications, understanding and enhancing their robustness to\nadversarial attacks is of paramount importance. Existing methods for\nidentifying adversarial prompts tend to focus on specific domains, lack\ndiversity, or require extensive human annotations. To address these\nlimitations, we present Rainbow Teaming, a novel black-box approach for\nproducing a diverse collection of adversarial prompts. Rainbow Teaming casts\nadversarial prompt generation as a quality-diversity problem and uses\nopen-ended search to generate prompts that are both effective and diverse.\nFocusing on the safety domain, we use Rainbow Teaming to target various\nstate-of-the-art LLMs, including the Llama 2 and Llama 3 models. Our approach\nreveals hundreds of effective adversarial prompts, with an attack success rate\nexceeding 90% across all tested models. Furthermore, we demonstrate that\nprompts generated by Rainbow Teaming are highly transferable and that\nfine-tuning models with synthetic data generated by our method significantly\nenhances their safety without sacrificing general performance or helpfulness.\nWe additionally explore the versatility of Rainbow Teaming by applying it to\nquestion answering and cybersecurity, showcasing its potential to drive robust\nopen-ended self-improvement in a wide range of applications.",
      "tldr_zh": "这篇论文提出了 Rainbow Teaming，一种黑盒方法，用于生成多样化的对抗提示(adversarial prompts)，以提升大型语言模型(LLMs)的鲁棒性。该方法将对抗提示生成视为质量-多样性问题，通过开放式搜索创建有效且多样的提示，并在安全领域针对 Llama 2 和 Llama 3 等模型进行测试。实验结果显示，攻击成功率超过90%，生成的提示具有高转移性，且使用合成数据微调后，模型的安全性显著提升，而不影响一般性能或帮助性。此外，Rainbow Teaming 展示了其在问答和网络安全等领域的广泛应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16822v3",
      "published_date": "2024-02-26 18:47:27 UTC",
      "updated_date": "2024-12-11 18:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:36.937870"
    },
    {
      "arxiv_id": "2402.16819v2",
      "title": "Nemotron-4 15B Technical Report",
      "title_zh": "Nemotron-4 15B 技术报告",
      "authors": [
        "Jupinder Parmar",
        "Shrimai Prabhumoye",
        "Joseph Jennings",
        "Mostofa Patwary",
        "Sandeep Subramanian",
        "Dan Su",
        "Chen Zhu",
        "Deepak Narayanan",
        "Aastha Jhunjhunwala",
        "Ayush Dattagupta",
        "Vibhu Jawa",
        "Jiwei Liu",
        "Ameya Mahabaleshwarkar",
        "Osvald Nitski",
        "Annika Brundyn",
        "James Maki",
        "Miguel Martinez",
        "Jiaxuan You",
        "John Kamalu",
        "Patrick LeGresley",
        "Denys Fridman",
        "Jared Casper",
        "Ashwath Aithal",
        "Oleksii Kuchaiev",
        "Mohammad Shoeybi",
        "Jonathan Cohen",
        "Bryan Catanzaro"
      ],
      "abstract": "We introduce Nemotron-4 15B, a 15-billion-parameter large multilingual\nlanguage model trained on 8 trillion text tokens. Nemotron-4 15B demonstrates\nstrong performance when assessed on English, multilingual, and coding tasks: it\noutperforms all existing similarly-sized open models on 4 out of 7 downstream\nevaluation areas and achieves competitive performance to the leading open\nmodels in the remaining ones. Specifically, Nemotron-4 15B exhibits the best\nmultilingual capabilities of all similarly-sized models, even outperforming\nmodels over four times larger and those explicitly specialized for multilingual\ntasks.",
      "tldr_zh": "我们介绍了 Nemotron-4 15B，这是一个 15 亿参数的 multilingual 语言模型，训练于 8 万亿文本 tokens。模型在 English、multilingual 和 coding 任务上表现出色，超越了所有同等规模的开源模型在 7 个下游评估领域的 4 个，并与领先开源模型在其他领域竞争。具体来说，Nemotron-4 15B 在 multilingual 能力上表现出最佳表现，甚至超过了四倍大的模型和那些专门针对 multilingual 任务设计的模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16819v2",
      "published_date": "2024-02-26 18:43:45 UTC",
      "updated_date": "2024-02-27 15:22:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:47.564103"
    },
    {
      "arxiv_id": "2402.17793v1",
      "title": "A Surprising Failure? Multimodal LLMs and the NLVR Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Anne Wu",
        "Kianté Brantley",
        "Yoav Artzi"
      ],
      "abstract": "This study evaluates three state-of-the-art MLLMs -- GPT-4V, Gemini Pro, and\nthe open-source model IDEFICS -- on the compositional natural language vision\nreasoning task NLVR. Given a human-written sentence paired with a synthetic\nimage, this task requires the model to determine the truth value of the\nsentence with respect to the image. Despite the strong performance demonstrated\nby these models, we observe they perform poorly on NLVR, which was constructed\nto require compositional and spatial reasoning, and to be robust for semantic\nand systematic biases.",
      "tldr_zh": "本研究评估了三个最先进的 Multimodal LLMs（GPT-4V、Gemini Pro 和 IDEFICS）在 NLVR（自然语言视觉推理）任务上的表现。NLVR 任务要求模型判断人类编写的句子相对于合成图像的真值，强调组合式和空间推理，同时避免语义和系统偏差。尽管这些模型在其他任务中表现出色，但实验结果显示它们在 NLVR 上表现不佳，揭示了 Multimodal LLMs 在处理复杂推理时的局限性。该发现突出了提升模型在真实世界推理能力的需求。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.17793v1",
      "published_date": "2024-02-26 18:37:18 UTC",
      "updated_date": "2024-02-26 18:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:07:59.816181"
    },
    {
      "arxiv_id": "2402.16795v2",
      "title": "If in a Crowdsourced Data Annotation Pipeline, a GPT-4",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu He",
        "Chieh-Yang Huang",
        "Chien-Kuang Cornelia Ding",
        "Shaurya Rohatgi",
        "Ting-Hao 'Kenneth' Huang"
      ],
      "abstract": "Recent studies indicated GPT-4 outperforms online crowd workers in data\nlabeling accuracy, notably workers from Amazon Mechanical Turk (MTurk).\nHowever, these studies were criticized for deviating from standard\ncrowdsourcing practices and emphasizing individual workers' performances over\nthe whole data-annotation process. This paper compared GPT-4 and an ethical and\nwell-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments\nfrom 200 scholarly articles using the CODA-19 scheme. Two worker interfaces\nyielded 127,080 labels, which were then used to infer the final labels through\neight label-aggregation algorithms. Our evaluation showed that despite best\npractices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved\n83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected\nvia an advanced worker interface for aggregation, 2 out of the 8 algorithms\nachieved an even higher accuracy (87.5%, 87.0%). Further analysis suggested\nthat, when the crowd's and GPT-4's labeling strengths are complementary,\naggregating them could increase labeling accuracy.",
      "tldr_zh": "本研究比较了GPT-4与Amazon Mechanical Turk (MTurk)在线众包管道在数据标注准确性上的表现，针对先前研究的不足，使用了包含415名工人的道德MTurk流程标注3,177个句子段（基于CODA-19方案），并通过八种label-aggregation algorithms聚合127,080个标签。结果显示，MTurk管道最高准确率为81.5%，而GPT-4达到了83.6%。进一步分析发现，将GPT-4的标签与MTurk的众包标签结合时，某些算法的准确率可提升至87.5%和87.0%，表明当二者的标注优势互补时，聚合方法能显著提高数据标注质量。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted By CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16795v2",
      "published_date": "2024-02-26 18:08:52 UTC",
      "updated_date": "2024-06-28 19:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:08:12.685172"
    },
    {
      "arxiv_id": "2402.16790v1",
      "title": "Beyond Self-learned Attention: Mitigating Attention Bias in Transformer-based Models Using Attention Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Jiri Gesi",
        "Iftekhar Ahmed"
      ],
      "abstract": "Transformer-based models have demonstrated considerable potential for source\ncode modeling tasks in software engineering. However, they are limited by their\ndependence solely on automatic self-attention weight learning mechanisms.\nPrevious studies have shown that these models overemphasize delimiters added by\ntokenizers (e.g., [CLS], [SEP]), which may lead to overlooking essential\ninformation in the original input source code. To address this challenge, we\nintroduce SyntaGuid, a novel approach that utilizes the observation that\nattention weights tend to be biased towards specific source code syntax tokens\nand abstract syntax tree (AST) elements in fine-tuned language models when they\nmake correct predictions. SyntaGuid facilitates the guidance of\nattention-weight learning, leading to improved model performance on various\nsoftware engineering tasks. We evaluate the effectiveness of SyntaGuid on\nmultiple tasks and demonstrate that it outperforms existing state-of-the-art\nmodels in overall performance without requiring additional data. Experimental\nresult shows that SyntaGuid can improve overall performance up to 3.25% and fix\nup to 28.3% wrong predictions. Our work represents the first attempt to guide\nthe attention of Transformer-based models towards critical source code tokens\nduring fine-tuning, highlighting the potential for enhancing Transformer-based\nmodels in software engineering.",
      "tldr_zh": "该论文揭示了 Transformer-based models 在源代码建模任务中存在的注意力偏差问题，即过度关注分隔符（如 [CLS], [SEP]）而忽略关键代码信息。作者提出 SyntaGuid 一种新方法，利用注意力权重偏向特定源代码语法标记和 abstract syntax tree (AST) 元素的观察，来指导注意力权重学习，从而提升模型性能。实验结果显示，SyntaGuid 在多个软件工程任务上优于现有最先进模型，提高整体性能高达 3.25%，并修复多达 28.3% 的错误预测，这标志着首次在微调过程中对 Transformer-based models 的注意力进行指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16790v1",
      "published_date": "2024-02-26 18:03:50 UTC",
      "updated_date": "2024-02-26 18:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:08:25.471101"
    },
    {
      "arxiv_id": "2402.16788v4",
      "title": "Why Transformers Need Adam: A Hessian Perspective",
      "title_zh": "为什么 Transformer 需要 Adam：Hessian 视角",
      "authors": [
        "Yushun Zhang",
        "Congliang Chen",
        "Tian Ding",
        "Ziniu Li",
        "Ruoyu Sun",
        "Zhi-Quan Luo"
      ],
      "abstract": "SGD performs worse than Adam by a significant margin on Transformers, but the\nreason remains unclear. In this work, we provide an explanation through the\nlens of Hessian: (i) Transformers are \"heterogeneous\": the Hessian spectrum\nacross parameter blocks vary dramatically, a phenomenon we call \"block\nheterogeneity\"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam on\nproblems with block heterogeneity. To validate (i) and (ii), we check various\nTransformers, CNNs, MLPs, and quadratic problems, and find that SGD can perform\non par with Adam on problems without block heterogeneity, but performs worse\nthan Adam when the heterogeneity exists. Our initial theoretical analysis\nindicates that SGD performs worse because it applies one single learning rate\nto all blocks, which cannot handle the heterogeneity among blocks. This\nlimitation could be ameliorated if we use coordinate-wise learning rates, as\ndesigned in Adam.",
      "tldr_zh": "这篇论文从 Hessian 的视角解释了为什么 Transformers 在训练中使用 Adam 比 SGD 表现更好。研究发现，Transformers 存在 \"block heterogeneity\"，即参数块之间的 Hessian 谱差异很大，这导致 SGD 无法有效优化。作者通过实验验证了各种模型（如 Transformers、CNNs 和 MLPs），证明在有 \"block heterogeneity\" 的问题上，SGD 显著劣于 Adam，而初步理论分析表明，使用单一学习率的 SGD 无法处理这种异质性，Adam 的坐标-wise 学习率则能缓解这一局限。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Advances in Neural Information Processing Systems, 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16788v4",
      "published_date": "2024-02-26 18:01:41 UTC",
      "updated_date": "2024-10-21 08:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:08:37.940985"
    },
    {
      "arxiv_id": "2402.16786v2",
      "title": "Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Röttger",
        "Valentin Hofmann",
        "Valentina Pyatkin",
        "Musashi Hinck",
        "Hannah Rose Kirk",
        "Hinrich Schütze",
        "Dirk Hovy"
      ],
      "abstract": "Much recent work seeks to evaluate values and opinions in large language\nmodels (LLMs) using multiple-choice surveys and questionnaires. Most of this\nwork is motivated by concerns around real-world LLM applications. For example,\npolitically-biased LLMs may subtly influence society when they are used by\nmillions of people. Such real-world concerns, however, stand in stark contrast\nto the artificiality of current evaluations: real users do not typically ask\nLLMs survey questions. Motivated by this discrepancy, we challenge the\nprevailing constrained evaluation paradigm for values and opinions in LLMs and\nexplore more realistic unconstrained evaluations. As a case study, we focus on\nthe popular Political Compass Test (PCT). In a systematic review, we find that\nmost prior work using the PCT forces models to comply with the PCT's\nmultiple-choice format. We show that models give substantively different\nanswers when not forced; that answers change depending on how models are\nforced; and that answers lack paraphrase robustness. Then, we demonstrate that\nmodels give different answers yet again in a more realistic open-ended answer\nsetting. We distill these findings into recommendations and open challenges in\nevaluating values and opinions in LLMs.",
      "tldr_zh": "该论文批评了当前评估大型语言模型(LLMs)价值观和意见的多选调查方法，认为这些方法过于人工化，与现实应用（如用户互动）脱节。研究者通过对Political Compass Test (PCT)的系统审查，发现强制模型遵守多选格式会导致答案不一致、易受提问方式影响，并缺乏paraphrase robustness。实验显示，在非强制或开放式回答设置中，模型的回应进一步变化。论文据此提出改进评估的推荐和开放挑战，以实现更真实、可靠的LLMs价值观评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2402.16786v2",
      "published_date": "2024-02-26 18:00:49 UTC",
      "updated_date": "2024-06-05 10:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:08:48.574127"
    },
    {
      "arxiv_id": "2402.16934v1",
      "title": "FedReview: A Review Mechanism for Rejecting Poisoned Updates in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhang Zheng",
        "Baochun Li"
      ],
      "abstract": "Federated learning has recently emerged as a decentralized approach to learn\na high-performance model without access to user data. Despite its\neffectiveness, federated learning gives malicious users opportunities to\nmanipulate the model by uploading poisoned model updates to the server. In this\npaper, we propose a review mechanism called FedReview to identify and decline\nthe potential poisoned updates in federated learning. Under our mechanism, the\nserver randomly assigns a subset of clients as reviewers to evaluate the model\nupdates on their training datasets in each round. The reviewers rank the model\nupdates based on the evaluation results and count the number of the updates\nwith relatively low quality as the estimated number of poisoned updates. Based\non review reports, the server employs a majority voting mechanism to integrate\nthe rankings and remove the potential poisoned updates in the model aggregation\nprocess. Extensive evaluation on multiple datasets demonstrate that FedReview\ncan assist the server to learn a well-performed global model in an adversarial\nenvironment.",
      "tldr_zh": "本论文针对 Federated Learning 中恶意用户通过上传 poisoned updates 来操纵模型的问题，提出了一种审查机制 FedReview。该机制让服务器随机选定部分客户端作为 reviewers，使用他们的训练数据集评估模型更新，并基于评估结果进行排名以估计 poisoned updates 的数量。服务器随后通过多数投票整合排名，并在模型聚合过程中移除潜在的 poisoned updates；在多个数据集上的广泛实验证明，FedReview 能有效帮助服务器在对抗环境中学习高性能的全局模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16934v1",
      "published_date": "2024-02-26 17:53:15 UTC",
      "updated_date": "2024-02-26 17:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:09:00.188702"
    },
    {
      "arxiv_id": "2403.00822v2",
      "title": "InteraRec: Screenshot Based Recommendations Using Multimodal Large Language Models",
      "title_zh": "InteraRec：基于截屏的推荐，使用多模态大型语言模型",
      "authors": [
        "Saketh Reddy Karra",
        "Theja Tulabandhula"
      ],
      "abstract": "Weblogs, comprised of records detailing user activities on any website, offer\nvaluable insights into user preferences, behavior, and interests. Numerous\nrecommendation algorithms, employing strategies such as collaborative\nfiltering, content-based filtering, and hybrid methods, leverage the data mined\nthrough these weblogs to provide personalized recommendations to users. Despite\nthe abundance of information available in these weblogs, identifying and\nextracting pertinent information and key features from them necessitate\nextensive engineering endeavors. The intricate nature of the data also poses a\nchallenge for interpretation, especially for non-experts. In this study, we\nintroduce a sophisticated and interactive recommendation framework denoted as\nInteraRec, which diverges from conventional approaches that exclusively depend\non weblogs for recommendation generation. InteraRec framework captures\nhigh-frequency screenshots of web pages as users navigate through a website.\nLeveraging state-of-the-art multimodal large language models (MLLMs), it\nextracts valuable insights into user preferences from these screenshots by\ngenerating a textual summary based on predefined keywords. Subsequently, an\nLLM-integrated optimization setup utilizes this summary to generate tailored\nrecommendations. Through our experiments, we demonstrate the effectiveness of\nInteraRec in providing users with valuable and personalized offerings.\nFurthermore, we explore the integration of session-based recommendation systems\ninto the InteraRec framework, aiming to enhance its overall performance.\nFinally, we curate a new dataset comprising of screenshots from product web\npages on the Amazon website for the validation of the InteraRec framework.\nDetailed experiments demonstrate the efficacy of the InteraRec framework in\ndelivering valuable and personalized recommendations tailored to individual\nuser preferences.",
      "tldr_zh": "本文提出 InteraRec 框架，这是一种基于截图的推荐系统，使用 Multimodal Large Language Models (MLLMs) 从用户浏览网页的高频截图中提取偏好，并生成文本摘要以提供个性化推荐。该框架不同于传统依赖网络日志（weblogs）的系统，通过 LLM 整合的优化设置增强推荐准确性，并探索与 session-based recommendation systems 的整合。实验结果显示 InteraRec 在新创建的 Amazon 产品网页截图数据集上表现出色，能有效交付有价值且个性化的用户推荐。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00822v2",
      "published_date": "2024-02-26 17:47:57 UTC",
      "updated_date": "2024-06-16 00:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:09:12.399901"
    },
    {
      "arxiv_id": "2402.16775v2",
      "title": "A Comprehensive Evaluation of Quantization Strategies for Large Language Models",
      "title_zh": "大语言模型量化策略的全面评估",
      "authors": [
        "Renren Jin",
        "Jiangcun Du",
        "Wuwei Huang",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang",
        "Deyi Xiong"
      ],
      "abstract": "Increasing the number of parameters in large language models (LLMs) usually\nimproves performance in downstream tasks but raises compute and memory costs,\nmaking deployment difficult in resource-limited settings. Quantization\ntechniques, which reduce the bits needed for model weights or activations with\nminimal performance loss, have become popular due to the rise of LLMs. However,\nmost quantization studies use pre-trained LLMs, and the impact of quantization\non instruction-tuned LLMs and the relationship between perplexity and benchmark\nperformance of quantized LLMs are not well understood. Evaluation of quantized\nLLMs is often limited to language modeling and a few classification tasks,\nleaving their performance on other benchmarks unclear. To address these gaps,\nwe propose a structured evaluation framework consisting of three critical\ndimensions: (1) knowledge \\& capacity, (2) alignment, and (3) efficiency, and\nconduct extensive experiments across ten diverse benchmarks. Our experimental\nresults indicate that LLMs with 4-bit quantization can retain performance\ncomparable to their non-quantized counterparts, and perplexity can serve as a\nproxy metric for quantized LLMs on most benchmarks. Furthermore, quantized LLMs\nwith larger parameter scales can outperform smaller LLMs. Despite the memory\nsavings achieved through quantization, it can also slow down the inference\nspeed of LLMs. Consequently, substantial engineering efforts and hardware\nsupport are imperative to achieve a balanced optimization of decoding speed and\nmemory consumption in the context of quantized LLMs.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）的量化策略进行了全面评估，旨在解决模型参数增加带来的计算和内存成本问题。研究者提出一个结构化的评估框架，包括知识与容量、对齐和效率三个维度，并在十个多样化基准上进行实验。结果显示，4-bit 量化LLMs 可以保持与非量化模型相似的性能，困惑度（Perplexity）可作为量化LLMs 在大多数基准的代理指标；此外，更大规模的量化LLMs 表现优于较小模型，但量化虽节省内存，却可能减慢推理速度，因此需要工程努力和硬件支持来优化平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.16775v2",
      "published_date": "2024-02-26 17:45:36 UTC",
      "updated_date": "2024-06-06 13:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:09:25.828542"
    },
    {
      "arxiv_id": "2402.16763v2",
      "title": "ELiSe: Efficient Learning of Sequences in Structured Recurrent Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Kriener",
        "Kristin Völk",
        "Ben von Hünerbein",
        "Federico Benitez",
        "Walter Senn",
        "Mihai A. Petrovici"
      ],
      "abstract": "Behavior can be described as a temporal sequence of actions driven by neural\nactivity. To learn complex sequential patterns in neural networks, memories of\npast activities need to persist on significantly longer timescales than the\nrelaxation times of single-neuron activity. While recurrent networks can\nproduce such long transients, training these networks is a challenge. Learning\nvia error propagation confers models such as FORCE, RTRL or BPTT a significant\nfunctional advantage, but at the expense of biological plausibility. While\nreservoir computing circumvents this issue by learning only the readout\nweights, it does not scale well with problem complexity. We propose that two\nprominent structural features of cortical networks can alleviate these issues:\nthe presence of a certain network scaffold at the onset of learning and the\nexistence of dendritic compartments for enhancing neuronal information storage\nand computation. Our resulting model for Efficient Learning of Sequences\n(ELiSe) builds on these features to acquire and replay complex non-Markovian\nspatio-temporal patterns using only local, always-on and phase-free synaptic\nplasticity. We showcase the capabilities of ELiSe in a mock-up of birdsong\nlearning, and demonstrate its flexibility with respect to parametrization, as\nwell as its robustness to external disturbances.",
      "tldr_zh": "本研究提出 ELiSe 模型，一种高效的学习序列的结构化循环网络（Structured Recurrent Networks），旨在解决神经网络在处理复杂时空模式时的问题，如记忆持久性和训练挑战。ELiSe 利用皮层网络的初始支架和树突区段（dendritic compartments）增强信息存储和计算，并采用本地、始终开启且无相位依赖的突触可塑性来学习和重放非马尔可夫（non-Markovian）时空模式。实验在鸟鸣学习模拟中验证了其灵活的参数设置和对外部干扰的鲁棒性，展示了比传统方法如 reservoir computing 更高效的性能。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2402.16763v2",
      "published_date": "2024-02-26 17:30:34 UTC",
      "updated_date": "2024-09-27 11:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:09:36.502298"
    },
    {
      "arxiv_id": "2402.16933v2",
      "title": "Incremental Concept Formation over Visual Images Without Catastrophic Forgetting",
      "title_zh": "无需灾难性遗忘的视觉图像增量概念形成",
      "authors": [
        "Nicki Barari",
        "Xin Lian",
        "Christopher J. MacLellan"
      ],
      "abstract": "Deep neural networks have excelled in machine learning, particularly in\nvision tasks, however, they often suffer from catastrophic forgetting when\nlearning new tasks sequentially. In this work, we introduce Cobweb4V, an\nalternative to traditional neural network approaches. Cobweb4V is a novel\nvisual classification method that builds on Cobweb, a human like learning\nsystem that is inspired by the way humans incrementally learn new concepts over\ntime. In this research, we conduct a comprehensive evaluation, showcasing\nCobweb4Vs proficiency in learning visual concepts, requiring less data to\nachieve effective learning outcomes compared to traditional methods,\nmaintaining stable performance over time, and achieving commendable asymptotic\nbehavior, without catastrophic forgetting effects. These characteristics align\nwith learning strategies in human cognition, positioning Cobweb4V as a\npromising alternative to neural network approaches.",
      "tldr_zh": "本研究提出 Cobweb4V，一种新型视觉分类方法，基于 Cobweb 系统模仿人类逐步学习新概念的方式，避免深度神经网络在顺序任务学习中常见的 catastrophic forgetting 问题。相比传统方法，Cobweb4V 需要更少的数据即可实现有效学习，保持性能稳定，并展示出优秀的渐近行为。通过全面评估，该方法证明了其在视觉任务中的优势，与人类认知策略一致，是神经网络方法的 promising alternative。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by The Eleventh Annual Conference on Advances in Cognitive\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2402.16933v2",
      "published_date": "2024-02-26 17:20:16 UTC",
      "updated_date": "2024-09-19 03:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:09:47.936349"
    },
    {
      "arxiv_id": "2402.16751v3",
      "title": "Value Preferences Estimation and Disambiguation in Hybrid Participatory Systems",
      "title_zh": "混合参与式系统中的价值偏好估计与消歧",
      "authors": [
        "Enrico Liscio",
        "Luciano C. Siebert",
        "Catholijn M. Jonker",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Understanding citizens' values in participatory systems is crucial for\ncitizen-centric policy-making. We envision a hybrid participatory system where\nparticipants make choices and provide motivations for those choices, and AI\nagents estimate their value preferences by interacting with them. We focus on\nsituations where a conflict is detected between participants' choices and\nmotivations, and propose methods for estimating value preferences while\naddressing detected inconsistencies by interacting with the participants. We\noperationalize the philosophical stance that \"valuing is deliberatively\nconsequential.\" That is, if a participant's choice is based on a deliberation\nof value preferences, the value preferences can be observed in the motivation\nthe participant provides for the choice. Thus, we propose and compare value\npreferences estimation methods that prioritize the values estimated from\nmotivations over the values estimated from choices alone. Then, we introduce a\ndisambiguation strategy that combines Natural Language Processing and Active\nLearning to address the detected inconsistencies between choices and\nmotivations. We evaluate the proposed methods on a dataset of a large-scale\nsurvey on energy transition. The results show that explicitly addressing\ninconsistencies between choices and motivations improves the estimation of an\nindividual's value preferences. The disambiguation strategy does not show\nsubstantial improvements when compared to similar baselines--however, we\ndiscuss how the novelty of the approach can open new research avenues and\npropose improvements to address the current limitations.",
      "tldr_zh": "该研究探讨了在混合参与系统中估计和消歧公民价值偏好（Value Preferences）的重要性，以支持公民导向的政策制定。论文提出一种框架，其中参与者提供选择和动机，AI 代理通过互动估计价值偏好，并优先使用从动机中推断的值来处理选择与动机之间的不一致。作者引入一种结合 Natural Language Processing 和 Active Learning 的消歧策略来解决这些冲突，并在能源转型的大型调查数据集上进行评估，结果显示处理不一致能显著改善价值偏好估计，尽管消歧策略与基线相比未见重大提升，但其新颖性为未来研究开辟了新路径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16751v3",
      "published_date": "2024-02-26 17:16:28 UTC",
      "updated_date": "2025-02-11 07:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:10:00.280831"
    },
    {
      "arxiv_id": "2402.16749v3",
      "title": "MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large Multimodal Model",
      "title_zh": "MISC：由大型多模态模型驱动的超低码率图像语义压缩",
      "authors": [
        "Chunyi Li",
        "Guo Lu",
        "Donghui Feng",
        "Haoning Wu",
        "Zicheng Zhang",
        "Xiaohong Liu",
        "Guangtao Zhai",
        "Weisi Lin",
        "Wenjun Zhang"
      ],
      "abstract": "With the evolution of storage and communication protocols, ultra-low bitrate\nimage compression has become a highly demanding topic. However, existing\ncompression algorithms must sacrifice either consistency with the ground truth\nor perceptual quality at ultra-low bitrate. In recent years, the rapid\ndevelopment of the Large Multimodal Model (LMM) has made it possible to balance\nthese two goals. To solve this problem, this paper proposes a method called\nMultimodal Image Semantic Compression (MISC), which consists of an LMM encoder\nfor extracting the semantic information of the image, a map encoder to locate\nthe region corresponding to the semantic, an image encoder generates an\nextremely compressed bitstream, and a decoder reconstructs the image based on\nthe above information. Experimental results show that our proposed MISC is\nsuitable for compressing both traditional Natural Sense Images (NSIs) and\nemerging AI-Generated Images (AIGIs) content. It can achieve optimal\nconsistency and perception results while saving 50% bitrate, which has strong\npotential applications in the next generation of storage and communication. The\ncode will be released on https://github.com/lcysyzxdxc/MISC.",
      "tldr_zh": "该论文提出了一种名为 MISC 的图像语义压缩方法，利用 Large Multimodal Model (LMM) 在超低比特率下平衡图像的一致性和感知质量，以解决现有算法的权衡问题。MISC 包括 LMM encoder 提取图像语义信息、map encoder 定位语义区域、image encoder 生成极度压缩的比特流，以及 decoder 基于这些信息重建图像。实验结果显示，MISC 适用于 Natural Sense Images (NSIs) 和 AI-Generated Images (AIGIs)，能够在节省 50% 比特率的同时实现最佳的一致性和感知质量，具有广阔的应用潜力于下一代存储和通信系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 page, 11 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.16749v3",
      "published_date": "2024-02-26 17:11:11 UTC",
      "updated_date": "2024-04-17 14:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:10:13.028237"
    },
    {
      "arxiv_id": "2402.16726v4",
      "title": "Towards Empirical Interpretation of Internal Circuits and Properties in Grokked Transformers on Modular Polynomials",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Furuta",
        "Gouki Minegishi",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "abstract": "Grokking has been actively explored to reveal the mystery of delayed\ngeneralization and identifying interpretable representations and algorithms\ninside the grokked models is a suggestive hint to understanding its mechanism.\nGrokking on modular addition has been known to implement Fourier representation\nand its calculation circuits with trigonometric identities in Transformers.\nConsidering the periodicity in modular arithmetic, the natural question is to\nwhat extent these explanations and interpretations hold for the grokking on\nother modular operations beyond addition. For a closer look, we first\nhypothesize that any modular operations can be characterized with distinctive\nFourier representation or internal circuits, grokked models obtain common\nfeatures transferable among similar operations, and mixing datasets with\nsimilar operations promotes grokking. Then, we extensively examine them by\nlearning Transformers on complex modular arithmetic tasks, including\npolynomials. Our Fourier analysis and novel progress measure for modular\narithmetic, Fourier Frequency Density and Fourier Coefficient Ratio,\ncharacterize distinctive internal representations of grokked models per modular\noperation; for instance, polynomials often result in the superposition of the\nFourier components seen in elementary arithmetic, but clear patterns do not\nemerge in challenging non-factorizable polynomials. In contrast, our ablation\nstudy on the pre-grokked models reveals that the transferability among the\nmodels grokked with each operation can be only limited to specific\ncombinations, such as from elementary arithmetic to linear expressions.\nMoreover, some multi-task mixtures may lead to co-grokking -- where grokking\nsimultaneously happens for all the tasks -- and accelerate generalization,\nwhile others may not find optimal solutions. We provide empirical steps towards\nthe interpretability of internal circuits.",
      "tldr_zh": "本研究探讨了 Grokking 现象在 Transformer 模型中的内部电路和属性，焦点在于模块化多项式任务，旨在揭示延迟泛化机制及其可解释性。作者假设模块化运算可通过独特 Fourier representation 或内部电路描述，并通过实验验证了 Grokked 模型的共同特征转移性及混合数据集的影响；他们引入了 Fourier Frequency Density 和 Fourier Coefficient Ratio 等新指标来分析内部表示。结果显示，多项式任务往往导致 Fourier 组件叠加，但非因子化多项式缺乏清晰模式，且模型转移性仅限于特定组合，如从基本算术到线性表达式；此外，多任务混合可促进 co-grokking 并加速泛化。该工作为 Transformer 内部电路的实证解释提供了重要步骤。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Transactions on Machine Learning Research (TMLR), Code:\n  https://github.com/frt03/grok_mod_poly",
      "pdf_url": "http://arxiv.org/pdf/2402.16726v4",
      "published_date": "2024-02-26 16:48:12 UTC",
      "updated_date": "2024-12-30 11:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:10:26.504254"
    },
    {
      "arxiv_id": "2402.16718v1",
      "title": "An Overview of the Development of Stereotactic Body Radiation Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Yanqi Zong",
        "Zhengrong Cui",
        "Luqi Lin",
        "Sihao Wang",
        "Yizhi Chen"
      ],
      "abstract": "Stereotactic body radiation therapy (SBRT) refers to focusing high-energy\nrays in three-dimensional space on the tumor lesion area, reducing the dose\nreceived by surrounding normal tissues, which can effectively improve the local\ncontrol rate of the tumor and reduce the probability of complications. With the\ncomprehensive development of medical imaging, radiation biology and other\ndisciplines, this less-fractional, high-dose radiotherapy method has been\nincreasingly developed and applied in clinical practice. The background,\nradio-biological basis, key technologies and main equipment of SBRT are\ndiscussed, and its future development direction is prospected.",
      "tldr_zh": "本论文概述了立体定向放射治疗（Stereotactic Body Radiation Therapy, SBRT）的开发历程，强调其通过三维空间聚焦高能量射线，改善肿瘤局部控制率并降低周围正常组织受损风险。论文讨论了SBRT的背景、放射生物学基础（radio-biological basis）、关键技术和主要设备，推动其在临床中的广泛应用。展望未来，该技术有望随着医学影像和辐射生物学的发展进一步优化，实现更高效的肿瘤治疗。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16718v1",
      "published_date": "2024-02-26 16:38:22 UTC",
      "updated_date": "2024-02-26 16:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:10:36.177835"
    },
    {
      "arxiv_id": "2402.16717v1",
      "title": "CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huijie Lv",
        "Xiao Wang",
        "Yuansen Zhang",
        "Caishuang Huang",
        "Shihan Dou",
        "Junjie Ye",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Adversarial misuse, particularly through `jailbreaking' that circumvents a\nmodel's safety and ethical protocols, poses a significant challenge for Large\nLanguage Models (LLMs). This paper delves into the mechanisms behind such\nsuccessful attacks, introducing a hypothesis for the safety mechanism of\naligned LLMs: intent security recognition followed by response generation.\nGrounded in this hypothesis, we propose CodeChameleon, a novel jailbreak\nframework based on personalized encryption tactics. To elude the intent\nsecurity recognition phase, we reformulate tasks into a code completion format,\nenabling users to encrypt queries using personalized encryption functions. To\nguarantee response generation functionality, we embed a decryption function\nwithin the instructions, which allows the LLM to decrypt and execute the\nencrypted queries successfully. We conduct extensive experiments on 7 LLMs,\nachieving state-of-the-art average Attack Success Rate (ASR). Remarkably, our\nmethod achieves an 86.6\\% ASR on GPT-4-1106.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 面临的jailbreaking攻击问题，提出一个假设：LLMs的安全机制包括intent security recognition（意图安全识别）和response generation（响应生成）。为此，作者开发了CodeChameleon框架，一种基于personalized encryption tactics（个性化加密策略）的攻击方法，通过将任务重构为code completion格式并使用加密函数隐藏查询，同时嵌入decryption function以确保LLM能解密并执行。实验结果显示，该框架在7个LLMs上实现了state-of-the-art的平均Attack Success Rate (ASR)，在GPT-4-1106上达到86.6%，证明了其高效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16717v1",
      "published_date": "2024-02-26 16:35:59 UTC",
      "updated_date": "2024-02-26 16:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:10:50.948996"
    },
    {
      "arxiv_id": "2402.16714v2",
      "title": "Quantum linear algebra is all you need for Transformer architectures",
      "title_zh": "量子线性代数就是 Transformer 架构所需的一切",
      "authors": [
        "Naixu Guo",
        "Zhan Yu",
        "Matthew Choi",
        "Aman Agrawal",
        "Kouhei Nakaji",
        "Alán Aspuru-Guzik",
        "Patrick Rebentrost"
      ],
      "abstract": "Generative machine learning methods such as large-language models are\nrevolutionizing the creation of text and images. While these models are\npowerful they also harness a large amount of computational resources. The\ntransformer is a key component in large language models that aims to generate a\nsuitable completion of a given partial sequence. In this work, we investigate\ntransformer architectures under the lens of fault-tolerant quantum computing.\nThe input model is one where trained weight matrices are given as block\nencodings and we construct the query, key, and value matrices for the\ntransformer. We show how to prepare a block encoding of the self-attention\nmatrix, with a new subroutine for the row-wise application of the softmax\nfunction. In addition, we combine quantum subroutines to construct important\nbuilding blocks in the transformer, the residual connection and layer\nnormalization, and the feed-forward neural network. Our subroutines prepare an\namplitude encoding of the transformer output, which can be measured to obtain a\nprediction. Based on common open-source large-language models, we provide\ninsights into the behavior of important parameters determining the run time of\nthe quantum algorithm. We discuss the potential and challenges for obtaining a\nquantum advantage.",
      "tldr_zh": "本论文探讨了利用量子线性代数优化Transformer架构，以提升生成式机器学习模型（如大语言模型）的计算效率。研究假设训练权重矩阵作为block encodings提供，并展示了如何构建查询、键和值矩阵，以及准备自注意力矩阵的block encoding，包括一个新的子程序用于行-wise应用softmax函数。作者还结合量子子程序实现了Transformer的关键组件，如残差连接、层归一化和前馈神经网络，最终通过幅度编码(amplitude encoding)获得输出预测。基于开源大语言模型的分析，该方法揭示了影响量子算法运行时间的参数，并讨论了实现量子优势的潜力与挑战。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "quant-ph",
      "comment": "31 pages, 4 figures, 2 tables, comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2402.16714v2",
      "published_date": "2024-02-26 16:31:28 UTC",
      "updated_date": "2024-05-31 03:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:11:01.408363"
    },
    {
      "arxiv_id": "2402.16705v2",
      "title": "SelectIT: Selective Instruction Tuning for LLMs via Uncertainty-Aware Self-Reflection",
      "title_zh": "SelectIT：通过不确定性感知自我反思进行的大语言模型选择性指令微调",
      "authors": [
        "Liangxin Liu",
        "Xuebo Liu",
        "Derek F. Wong",
        "Dongfang Li",
        "Ziyi Wang",
        "Baotian Hu",
        "Min Zhang"
      ],
      "abstract": "Instruction tuning (IT) is crucial to tailoring large language models (LLMs)\ntowards human-centric interactions. Recent advancements have shown that the\ncareful selection of a small, high-quality subset of IT data can significantly\nenhance the performance of LLMs. Despite this, common approaches often rely on\nadditional models or data, which increases costs and limits widespread\nadoption. In this work, we propose a novel approach, termed SelectIT, that\ncapitalizes on the foundational capabilities of the LLM itself. Specifically,\nwe exploit the intrinsic uncertainty present in LLMs to more effectively select\nhigh-quality IT data, without the need for extra resources. Furthermore, we\nintroduce a curated IT dataset, the Selective Alpaca, created by applying\nSelectIT to the Alpaca-GPT4 dataset. Empirical results demonstrate that IT\nusing Selective Alpaca leads to substantial model ability enhancement. The\nrobustness of SelectIT has also been corroborated in various foundation models\nand domain-specific tasks. Our findings suggest that longer and more\ncomputationally intensive IT data may serve as superior sources of IT, offering\nvaluable insights for future research in this area. Data, code, and scripts are\nfreely available at https://github.com/Blue-Raincoat/SelectIT.",
      "tldr_zh": "本研究提出了一种名为 SelectIT 的新方法，用于通过不确定性感知自省（Uncertainty-Aware Self-Reflection）对大型语言模型（LLMs）进行选择性指令微调（Instruction Tuning, IT），以提升模型性能，而无需依赖额外模型或数据资源。SelectIT 利用 LLMs 自身的内在不确定性来筛选高质量 IT 数据，并基于此创建了 Selective Alpaca 数据集，从 Alpaca-GPT4 数据集中精选子集。实验结果显示，使用 Selective Alpaca 进行 IT 可显著增强模型能力，并在各种基础模型和领域特定任务中展现出鲁棒性；此外，该方法揭示了更长和计算密集的 IT 数据可能作为更优来源，为未来研究提供宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16705v2",
      "published_date": "2024-02-26 16:21:53 UTC",
      "updated_date": "2025-01-15 08:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:11:13.585182"
    },
    {
      "arxiv_id": "2402.16700v1",
      "title": "Generating Effective Ensembles for Sentiment Analysis",
      "title_zh": "生成有效的集成模型用于情感分析",
      "authors": [
        "Itay Etelis",
        "Avi Rosenfeld",
        "Abraham Itzhak Weinberg",
        "David Sarne"
      ],
      "abstract": "In recent years, transformer models have revolutionized Natural Language\nProcessing (NLP), achieving exceptional results across various tasks, including\nSentiment Analysis (SA). As such, current state-of-the-art approaches for SA\npredominantly rely on transformer models alone, achieving impressive accuracy\nlevels on benchmark datasets. In this paper, we show that the key for further\nimproving the accuracy of such ensembles for SA is to include not only\ntransformers, but also traditional NLP models, despite the inferiority of the\nlatter compared to transformer models. However, as we empirically show, this\nnecessitates a change in how the ensemble is constructed, specifically relying\non the Hierarchical Ensemble Construction (HEC) algorithm we present. Our\nempirical studies across eight canonical SA datasets reveal that ensembles\nincorporating a mix of model types, structured via HEC, significantly\noutperform traditional ensembles. Finally, we provide a comparative analysis of\nthe performance of the HEC and GPT-4, demonstrating that while GPT-4 closely\napproaches state-of-the-art SA methods, it remains outperformed by our proposed\nensemble strategy.",
      "tldr_zh": "该论文探讨了如何通过集成多种模型来提升情感分析（Sentiment Analysis, SA）的准确率，强调结合 transformer 模型和传统 NLP 模型的重要性，尽管后者性能较弱。作者提出了 Hierarchical Ensemble Construction (HEC) 算法，用于优化集成结构，确保模型间有效协作。实验结果显示，在八个标准 SA 数据集上，该方法显著优于传统集成策略，且在性能上超越了 GPT-4，为 SA 领域提供了更有效的集成框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16700v1",
      "published_date": "2024-02-26 16:14:47 UTC",
      "updated_date": "2024-02-26 16:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:11:24.803066"
    },
    {
      "arxiv_id": "2402.16689v1",
      "title": "Adaptation of Biomedical and Clinical Pretrained Models to French Long Documents: A Comparative Study",
      "title_zh": "翻译失败",
      "authors": [
        "Adrien Bazoge",
        "Emmanuel Morin",
        "Beatrice Daille",
        "Pierre-Antoine Gourraud"
      ],
      "abstract": "Recently, pretrained language models based on BERT have been introduced for\nthe French biomedical domain. Although these models have achieved\nstate-of-the-art results on biomedical and clinical NLP tasks, they are\nconstrained by a limited input sequence length of 512 tokens, which poses\nchallenges when applied to clinical notes. In this paper, we present a\ncomparative study of three adaptation strategies for long-sequence models,\nleveraging the Longformer architecture. We conducted evaluations of these\nmodels on 16 downstream tasks spanning both biomedical and clinical domains.\nOur findings reveal that further pre-training an English clinical model with\nFrench biomedical texts can outperform both converting a French biomedical BERT\nto the Longformer architecture and pre-training a French biomedical Longformer\nfrom scratch. The results underscore that long-sequence French biomedical\nmodels improve performance across most downstream tasks regardless of sequence\nlength, but BERT based models remain the most efficient for named entity\nrecognition tasks.",
      "tldr_zh": "本研究比较了三种适应策略，将BERT预训练模型应用于法文长文档的生物医学和临床NLP任务，针对输入序列长度限制问题采用了Longformer架构。研究评估了这些模型在16个下游任务上的性能，包括生物医学和临床领域。结果表明，进一步预训练英文临床模型并融入法文生物医学文本的效果最优，出色于直接转换法文生物医学BERT为Longformer或从零预训练法文生物医学Longformer。总体上，长序列模型提升了大多数任务的性能，但BERT基于模型在named entity recognition任务中更高效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16689v1",
      "published_date": "2024-02-26 16:05:33 UTC",
      "updated_date": "2024-02-26 16:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:11:37.122894"
    },
    {
      "arxiv_id": "2402.16684v1",
      "title": "Automated Floodwater Depth Estimation Using Large Multimodal Model for Rapid Flood Mapping",
      "title_zh": "使用大型多模态模型的自动洪水深度估计，用于快速洪水映射",
      "authors": [
        "Temitope Akinboyewa",
        "Huan Ning",
        "M. Naser Lessani",
        "Zhenlong Li"
      ],
      "abstract": "Information on the depth of floodwater is crucial for rapid mapping of areas\naffected by floods. However, previous approaches for estimating floodwater\ndepth, including field surveys, remote sensing, and machine learning\ntechniques, can be time-consuming and resource-intensive. This paper presents\nan automated and fast approach for estimating floodwater depth from on-site\nflood photos. A pre-trained large multimodal model, GPT-4 Vision, was used\nspecifically for estimating floodwater. The input data were flooding photos\nthat contained referenced objects, such as street signs, cars, people, and\nbuildings. Using the heights of the common objects as references, the model\nreturned the floodwater depth as the output. Results show that the proposed\napproach can rapidly provide a consistent and reliable estimation of floodwater\ndepth from flood photos. Such rapid estimation is transformative in flood\ninundation mapping and assessing the severity of the flood in near-real time,\nwhich is essential for effective flood response strategies.",
      "tldr_zh": "本文提出了一种自动化的洪水深度估算方法，使用大型多模态模型（Large Multimodal Model）如 GPT-4 Vision，从现场洪水照片中快速获取深度信息。该方法通过照片中参考对象（如街道路牌、汽车、人和建筑物）的已知高度作为基准，生成可靠的洪水深度输出。实验结果显示，该方法显著提高了洪水淹没映射（flood inundation mapping）的速度和准确性，有助于实时评估洪水严重程度并优化响应策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16684v1",
      "published_date": "2024-02-26 16:02:15 UTC",
      "updated_date": "2024-02-26 16:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:11:49.960029"
    },
    {
      "arxiv_id": "2402.16668v1",
      "title": "Program-Based Strategy Induction for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos G. Correa",
        "Thomas L. Griffiths",
        "Nathaniel D. Daw"
      ],
      "abstract": "Typical models of learning assume incremental estimation of\ncontinuously-varying decision variables like expected rewards. However, this\nclass of models fails to capture more idiosyncratic, discrete heuristics and\nstrategies that people and animals appear to exhibit. Despite recent advances\nin strategy discovery using tools like recurrent networks that generalize the\nclassic models, the resulting strategies are often onerous to interpret, making\nconnections to cognition difficult to establish. We use Bayesian program\ninduction to discover strategies implemented by programs, letting the\nsimplicity of strategies trade off against their effectiveness. Focusing on\nbandit tasks, we find strategies that are difficult or unexpected with\nclassical incremental learning, like asymmetric learning from rewarded and\nunrewarded trials, adaptive horizon-dependent random exploration, and discrete\nstate switching.",
      "tldr_zh": "该研究指出，传统强化学习(Reinforcement Learning)模型依赖于增量估计决策变量（如预期奖励），但无法有效捕捉人们和动物使用的独特离散策略。作者引入Bayesian program induction方法，通过程序实现策略，让策略的简单性和有效性进行权衡，从而发现更易解释的认知行为。实验聚焦于Bandit tasks，发现了如不对称学习（从奖励和非奖励试验中不对称学习）、适应性随机探索和离散状态切换等策略，这些结果扩展了强化学习的策略发现能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16668v1",
      "published_date": "2024-02-26 15:40:46 UTC",
      "updated_date": "2024-02-26 15:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:12:02.915725"
    },
    {
      "arxiv_id": "2402.16667v1",
      "title": "RepoAgent: An LLM-Powered Open-Source Framework for Repository-level Code Documentation Generation",
      "title_zh": "RepoAgent：一个基于LLM驱动的开源框架，用于仓库级代码文档生成",
      "authors": [
        "Qinyu Luo",
        "Yining Ye",
        "Shihao Liang",
        "Zhong Zhang",
        "Yujia Qin",
        "Yaxi Lu",
        "Yesai Wu",
        "Xin Cong",
        "Yankai Lin",
        "Yingli Zhang",
        "Xiaoyin Che",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Generative models have demonstrated considerable potential in software\nengineering, particularly in tasks such as code generation and debugging.\nHowever, their utilization in the domain of code documentation generation\nremains underexplored. To this end, we introduce RepoAgent, a large language\nmodel powered open-source framework aimed at proactively generating,\nmaintaining, and updating code documentation. Through both qualitative and\nquantitative evaluations, we have validated the effectiveness of our approach,\nshowing that RepoAgent excels in generating high-quality repository-level\ndocumentation. The code and results are publicly accessible at\nhttps://github.com/OpenBMB/RepoAgent.",
      "tldr_zh": "本研究引入了 RepoAgent，一种基于 LLM（Large Language Model）的开源框架，旨在主动生成、维护和更新仓库级代码文档，以填补生成式模型在代码文档领域的研究空白。通过定性和定量评估，该框架证明了其在生成高质量文档方面的优越性能。RepoAgent 的代码和结果已公开在 GitHub 上（https://github.com/OpenBMB/RepoAgent），促进了进一步的软件工程应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; F.2.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16667v1",
      "published_date": "2024-02-26 15:39:52 UTC",
      "updated_date": "2024-02-26 15:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:12:14.805800"
    },
    {
      "arxiv_id": "2402.16654v2",
      "title": "GigaPevt: Multimodal Medical Assistant",
      "title_zh": "GigaPevt：多模态医疗",
      "authors": [
        "Pavel Blinov",
        "Konstantin Egorov",
        "Ivan Sviridov",
        "Nikolay Ivanov",
        "Stepan Botman",
        "Evgeniy Tagin",
        "Stepan Kudin",
        "Galina Zubkova",
        "Andrey Savchenko"
      ],
      "abstract": "Building an intelligent and efficient medical assistant is still a\nchallenging AI problem. The major limitation comes from the data modality\nscarceness, which reduces comprehensive patient perception. This demo paper\npresents the GigaPevt, the first multimodal medical assistant that combines the\ndialog capabilities of large language models with specialized medical models.\nSuch an approach shows immediate advantages in dialog quality and metric\nperformance, with a 1.18% accuracy improvement in the question-answering task.",
      "tldr_zh": "该论文提出 GigaPevt，这是一个多模态医疗助手，旨在解决构建智能医疗助手的挑战，特别是数据模态稀缺导致的患者感知不全面问题。GigaPevt 通过结合大型语言模型（Large Language Models）的对话能力与专业医疗模型，实现更高效的对话质量和指标性能提升。在问答任务中，该系统比传统方法准确率提高了 1.18%，为全面的患者感知和医疗辅助提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "68T07",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "IJCAI 2024, 4 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.16654v2",
      "published_date": "2024-02-26 15:26:56 UTC",
      "updated_date": "2024-07-30 06:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:12:26.571552"
    },
    {
      "arxiv_id": "2402.16651v1",
      "title": "A Comprehensive Survey of Belief Rule Base (BRB) Hybrid Expert system: Bridging Decision Science and Professional Services",
      "title_zh": "翻译失败",
      "authors": [
        "Karim Derrick"
      ],
      "abstract": "The Belief Rule Base (BRB) system that adopts a hybrid approach integrating\nthe precision of expert systems with the adaptability of data-driven models.\nCharacterized by its use of if-then rules to accommodate various types of\nuncertainty through belief degrees, BRB adeptly handles fuzziness, randomness,\nand ignorance. This semi-quantitative tool excels in processing both numerical\ndata and linguistic knowledge from diverse sources, making it as an\nindispensable resource in modelling complex nonlinear systems. Notably, BRB's\ntransparent, white-box nature ensures accessibility and clarity for\ndecision-makers and stakeholders, further enhancing its applicability. With its\ngrowing adoption in fields ranging from decision-making and reliability\nevaluation in network security and fault diagnosis, this study aims to explore\nthe evolution and the multifaceted applications of BRB. By analysing its\ndevelopment across different domains, we highlight BRB's potential to\nrevolutionize sectors traditionally resistant to technological disruption, in\nparticular insurance and law.",
      "tldr_zh": "该论文对 Belief Rule Base (BRB) 混合专家系统进行了全面调查，强调其将专家系统的精确性与数据驱动模型的适应性相结合，使用 if-then 规则来处理模糊性、随机性和无知的不确定性。BRB 系统作为一种半定量工具，能够有效整合数字数据和语言知识，用于建模复杂的非线性系统，并以其透明的白盒特性增强决策者的可访问性。调查探讨了 BRB 在决策、可靠性评估、网络安全和故障诊断等领域的演变与应用，并突出其在保险和法律等传统行业推动变革的潜力。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16651v1",
      "published_date": "2024-02-26 15:23:27 UTC",
      "updated_date": "2024-02-26 15:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:12:38.991102"
    },
    {
      "arxiv_id": "2402.17792v1",
      "title": "EGNN-C+: Interpretable Evolving Granular Neural Network and Application in Classification of Weakly-Supervised EEG Data Streams",
      "title_zh": "EGNN-C+：可解释的演化颗粒神经网络及其在弱监督 EEG 数据流分类中的应用",
      "authors": [
        "Daniel Leite",
        "Alisson Silva",
        "Gabriella Casalino",
        "Arnab Sharma",
        "Danielle Fortunato",
        "Axel-Cyrille Ngomo"
      ],
      "abstract": "We introduce a modified incremental learning algorithm for evolving Granular\nNeural Network Classifiers (eGNN-C+). We use double-boundary hyper-boxes to\nrepresent granules, and customize the adaptation procedures to enhance the\nrobustness of outer boxes for data coverage and noise suppression, while\nensuring that inner boxes remain flexible to capture drifts. The classifier\nevolves from scratch, incorporates new classes on the fly, and performs local\nincremental feature weighting. As an application, we focus on the\nclassification of emotion-related patterns within electroencephalogram (EEG)\nsignals. Emotion recognition is crucial for enhancing the realism and\ninteractivity of computer systems. We extract features from the Fourier\nspectrum of EEG signals obtained from 28 individuals engaged in playing\ncomputer games -- a public dataset. Each game elicits a different predominant\nemotion: boredom, calmness, horror, or joy. We analyze individual electrodes,\ntime window lengths, and frequency bands to assess the accuracy and\ninterpretability of resulting user-independent neural models. The findings\nindicate that both brain hemispheres assist classification, especially\nelectrodes on the temporal (T8) and parietal (P7) areas, alongside\ncontributions from frontal and occipital electrodes. While patterns may\nmanifest in any band, the Alpha (8-13Hz), Delta (1-4Hz), and Theta (4-8Hz)\nbands, in this order, exhibited higher correspondence with the emotion classes.\nThe eGNN-C+ demonstrates effectiveness in learning EEG data. It achieves an\naccuracy of 81.7% and a 0.0029 II interpretability using 10-second time\nwindows, even in face of a highly-stochastic time-varying 4-class\nclassification problem.",
      "tldr_zh": "本研究引入了eGNN-C+，一种可解释的演化颗粒神经网络分类器，使用双边界超盒子（double-boundary hyper-boxes）改进适应过程，以提升数据覆盖和噪声抑制能力，同时支持增量学习、动态添加新类和局部特征加权。应用于弱监督EEG数据流的分类任务，该方法分析了28个个体的脑电图信号，针对游戏引发的四种情绪（boredom、calmness、horror、joy）评估了不同电极（如颞区T8和顶区P7）、时间窗口和频率带（Alpha 8-13Hz、Delta 1-4Hz、Theta 4-8Hz）的贡献。实验结果显示，eGNN-C+在10秒时间窗口下实现了81.7%的准确率和0.0029的可解释性指标，证明其在处理高度随机EEG分类问题中的有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "eess.SP",
      "comment": "10 pages, IEEE International Conference on Evolving and Adaptive\n  Intelligent Systems 2024 (IEEE EAIS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.17792v1",
      "published_date": "2024-02-26 15:11:41 UTC",
      "updated_date": "2024-02-26 15:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:12:53.824750"
    },
    {
      "arxiv_id": "2402.16929v2",
      "title": "LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Wang",
        "Yuanzhong Liu",
        "Xiaoyu Liang",
        "Songlian Li",
        "Yijie Huang",
        "Xiaoming Zhang",
        "Sijia Shen",
        "Chaofeng Guan",
        "Daling Wang",
        "Shi Feng",
        "Huaiwen Zhang",
        "Yifei Zhang",
        "Minghui Zheng",
        "Chi Zhang"
      ],
      "abstract": "LLMs have demonstrated commendable performance across diverse domains.\nNevertheless, formulating high-quality prompts to instruct LLMs proficiently\nposes a challenge for non-AI experts. Existing research in prompt engineering\nsuggests somewhat scattered optimization principles and designs empirically\ndependent prompt optimizers. Unfortunately, these endeavors lack a structured\ndesign template, incurring high learning costs and resulting in low\nreusability. In addition, it is not conducive to the iterative updating of\nprompts. Inspired by structured reusable programming languages, we propose\nLangGPT, a dual-layer prompt design framework as the programming language for\nLLMs. LangGPT has an easy-to-learn normative structure and provides an extended\nstructure for migration and reuse. Experiments illustrate that LangGPT\nsignificantly enhances the performance of LLMs. Moreover, the case study shows\nthat LangGPT leads LLMs to generate higher-quality responses. Furthermore, we\nanalyzed the ease of use and reusability of LangGPT through a user survey in\nour online community.",
      "tldr_zh": "该论文指出，现有的提示工程(prompt engineering)缺乏结构化模板，导致非AI专家难以创建高效提示，并降低可重用性。受编程语言启发，作者提出LangGPT，这是一个双层提示设计框架，提供规范结构和扩展机制，支持提示的迁移、重用和迭代更新。实验结果显示，LangGPT显著提升了LLMs的性能，并在案例研究中帮助LLMs生成更高质量的响应。通过用户调查，进一步验证了LangGPT的易用性和可重用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16929v2",
      "published_date": "2024-02-26 15:05:16 UTC",
      "updated_date": "2024-06-29 14:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:13:02.715721"
    },
    {
      "arxiv_id": "2402.16631v3",
      "title": "GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zou",
        "Qiyang Zhao",
        "Samson Lasaulce",
        "Lina Bariah",
        "Mehdi Bennis",
        "Merouane Debbah"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) and communication networks are\nexpected to have groundbreaking synergies for 6G. Connecting GenAI agents via a\nwireless network can potentially unleash the power of Collective Intelligence\n(CI) and pave the way for Artificial General Intelligence (AGI). However,\ncurrent wireless networks are designed as a \"data pipe\" and are not suited to\naccommodate and leverage the power of GenAI. In this paper, we propose the\nGenAINet framework in which distributed GenAI agents communicate knowledge\n(facts, experiences, and methods) to accomplish arbitrary tasks. We first\npropose an architecture for a single GenAI agent and then provide a network\narchitecture integrating GenAI capabilities to manage both network protocols\nand applications. Building on this, we investigate effective communication and\nreasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI\nagents extract semantics from heterogeneous raw data, build and maintain a\nknowledge model representing the semantic relationships among pieces of\nknowledge, which is retrieved by GenAI models for planning and reasoning. Under\nthis paradigm, different levels of collaboration can be achieved flexibly\ndepending on the complexity of targeted tasks. Furthermore, we conduct two case\nstudies in which, through wireless device queries, we demonstrate that\nextracting, compressing and transferring common knowledge can improve query\naccuracy while reducing communication costs; and in the wireless power control\nproblem, we show that distributed agents can complete general tasks\nindependently through collaborative reasoning without predefined communication\nprotocols. Finally, we discuss challenges and future research directions in\napplying Large Language Models (LLMs) in 6G networks.",
      "tldr_zh": "本文提出 GenAINet 框架，利用 Generative Artificial Intelligence (GenAI) 通过知识转移和推理，实现无线集体智能 (Collective Intelligence) 在 6G 网络中的应用，以解决当前网络仅作为“数据管道”的局限性。框架包括分布式 GenAI 代理的架构设计，这些代理从异构数据中提取语义、构建知识模型，并用于规划和推理，支持不同级别的协作任务。实验案例显示，这种方法能提升查询准确率并降低通信成本，并在无线功率控制问题中实现代理独立协作完成任务，而无需预定义协议。最后，讨论了在 6G 网络中使用 Large Language Models (LLMs) 的挑战和未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16631v3",
      "published_date": "2024-02-26 15:03:46 UTC",
      "updated_date": "2025-05-04 20:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:13:16.312180"
    },
    {
      "arxiv_id": "2402.16627v3",
      "title": "Contextualized Diffusion Models for Text-Guided Image and Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Yang",
        "Zhilong Zhang",
        "Zhaochen Yu",
        "Jingwei Liu",
        "Minkai Xu",
        "Stefano Ermon",
        "Bin Cui"
      ],
      "abstract": "Conditional diffusion models have exhibited superior performance in\nhigh-fidelity text-guided visual generation and editing. Nevertheless,\nprevailing text-guided visual diffusion models primarily focus on incorporating\ntext-visual relationships exclusively into the reverse process, often\ndisregarding their relevance in the forward process. This inconsistency between\nforward and reverse processes may limit the precise conveyance of textual\nsemantics in visual synthesis results. To address this issue, we propose a\nnovel and general contextualized diffusion model (ContextDiff) by incorporating\nthe cross-modal context encompassing interactions and alignments between text\ncondition and visual sample into forward and reverse processes. We propagate\nthis context to all timesteps in the two processes to adapt their trajectories,\nthereby facilitating cross-modal conditional modeling. We generalize our\ncontextualized diffusion to both DDPMs and DDIMs with theoretical derivations,\nand demonstrate the effectiveness of our model in evaluations with two\nchallenging tasks: text-to-image generation, and text-to-video editing. In each\ntask, our ContextDiff achieves new state-of-the-art performance, significantly\nenhancing the semantic alignment between text condition and generated samples,\nas evidenced by quantitative and qualitative evaluations. Our code is available\nat https://github.com/YangLing0818/ContextDiff",
      "tldr_zh": "该论文提出了一种新型的 Contextualized Diffusion Models（ContextDiff），通过将跨模态上下文（包括文本条件与视觉样本的互动和对齐）融入扩散模型的正向和逆向过程，从而解决现有文本引导视觉生成中语义传达不精确的问题。模型将此上下文传播到所有时间步，适应过程轨迹，并理论上推广到 DDPMs 和 DDIMs。实验结果显示，ContextDiff 在文本到图像生成和文本到视频编辑任务上实现了新的最先进性能，显著提升了文本条件与生成样本的语义对齐。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024. Project: https://github.com/YangLing0818/ContextDiff",
      "pdf_url": "http://arxiv.org/pdf/2402.16627v3",
      "published_date": "2024-02-26 15:01:16 UTC",
      "updated_date": "2024-06-04 01:08:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:13:27.908727"
    },
    {
      "arxiv_id": "2402.16928v1",
      "title": "CLAP: Learning Transferable Binary Code Representations with Natural Language Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Zeyu Gao",
        "Chao Zhang",
        "Zihan Sha",
        "Mingyang Sun",
        "Yuchen Zhou",
        "Wenyu Zhu",
        "Wenju Sun",
        "Han Qiu",
        "Xi Xiao"
      ],
      "abstract": "Binary code representation learning has shown significant performance in\nbinary analysis tasks. But existing solutions often have poor transferability,\nparticularly in few-shot and zero-shot scenarios where few or no training\nsamples are available for the tasks. To address this problem, we present CLAP\n(Contrastive Language-Assembly Pre-training), which employs natural language\nsupervision to learn better representations of binary code (i.e., assembly\ncode) and get better transferability. At the core, our approach boosts superior\ntransfer learning capabilities by effectively aligning binary code with their\nsemantics explanations (in natural language), resulting a model able to\ngenerate better embeddings for binary code. To enable this alignment training,\nwe then propose an efficient dataset engine that could automatically generate a\nlarge and diverse dataset comprising of binary code and corresponding natural\nlanguage explanations. We have generated 195 million pairs of binary code and\nexplanations and trained a prototype of CLAP. The evaluations of CLAP across\nvarious downstream tasks in binary analysis all demonstrate exceptional\nperformance. Notably, without any task-specific training, CLAP is often\ncompetitive with a fully supervised baseline, showing excellent\ntransferability. We release our pre-trained model and code at\nhttps://github.com/Hustcw/CLAP.",
      "tldr_zh": "这篇论文提出CLAP（Contrastive Language-Assembly Pre-training），一种利用自然语言监督来学习可转移的二进制代码表示的方法，以解决现有模型在少样本或零样本场景下的转移性问题。通过对比学习将二进制代码与其语义解释对齐，CLAP能够生成更有效的嵌入表示，并通过一个高效的数据集引擎自动生成1.95亿对二进制代码和自然语言解释的数据集进行训练。实验结果显示，CLAP在各种二进制分析下游任务中表现出色，即使没有任务特定训练，也能与全监督基线竞争，展示了优秀的转移性。作者开源了预训练模型和代码，以促进进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16928v1",
      "published_date": "2024-02-26 13:49:52 UTC",
      "updated_date": "2024-02-26 13:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:13:38.978568"
    },
    {
      "arxiv_id": "2402.16567v3",
      "title": "Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL",
      "title_zh": "将大型语言模型对齐到特定领域的图数据库",
      "authors": [
        "Yuanyuan Liang",
        "Keren Tan",
        "Tingyu Xie",
        "Wenbiao Tao",
        "Siyuan Wang",
        "Yunshi Lan",
        "Weining Qian"
      ],
      "abstract": "Graph Databases (Graph DB) find extensive application across diverse domains\nsuch as finance, social networks, and medicine. Yet, the translation of Natural\nLanguage (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses\nsignificant challenges owing to its intricate and specialized nature. Some\napproaches have sought to utilize Large Language Models (LLMs) to address\nanalogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks\ntailored to a particular domain, the absence of domain-specific NL-GQL data\npairs adds complexity to aligning LLMs with the graph DB. To tackle this\nchallenge, we present a well-defined pipeline. Initially, we utilize ChatGPT to\ngenerate NL-GQL data pairs, leveraging the provided graph DB with\nself-instruction. Subsequently, we employ the generated data to fine-tune LLMs,\nensuring alignment between LLMs and the graph DB. Moreover, we find the\nimportance of relevant schema in efficiently generating accurate GQLs. Thus, we\nintroduce a method to extract relevant schema as the input context. We evaluate\nour method using two carefully constructed datasets derived from graph DBs in\nthe finance and medicine domains, named FinGQL and MediGQL. Experimental\nresults reveal that our approach significantly outperforms a set of baseline\nmethods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and\n7.09 absolute points on EX for FinGQL and MediGQL, respectively.",
      "tldr_zh": "本研究针对自然语言到图查询语言（NL2GQL）的挑战，提出一种管道方法，将Large Language Models (LLMs)与特定领域的Graph Databases (Graph DB)对齐，以解决领域特定数据缺失的问题。方法包括使用ChatGPT生成NL-GQL数据对进行自指令训练，随后微调LLMs并引入相关schema提取作为输入上下文，以提升GQL生成的准确性和效率。在FinGQL（金融领域）和MediGQL（医学领域）数据集上的实验显示，该方法在EM指标上分别比基线提升5.90和6.36绝对点，在EX指标上提升6.00和7.09绝对点，显著提高了NL2GQL的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages,2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16567v3",
      "published_date": "2024-02-26 13:46:51 UTC",
      "updated_date": "2024-09-05 06:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:13:51.213732"
    },
    {
      "arxiv_id": "2402.16562v4",
      "title": "QF-tuner: Breaking Tradition in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmood A. Jumaah",
        "Yossra H. Ali",
        "Tarik A. Rashid"
      ],
      "abstract": "In reinforcement learning algorithms, the hyperparameters tuning method\nrefers to choosing the optimal parameters that may increase the overall\nperformance. Manual or random hyperparameter tuning methods can lead to\ndifferent results in the reinforcement learning algorithms. In this paper, we\npropose a new method called QF-tuner for automatic hyperparameter tuning in the\nQ learning algorithm using the FOX optimization algorithm (FOX). Furthermore, a\nnew objective function has been employed within FOX that prioritizes reward\nover learning error and time. QF tuner starts by running the FOX and tries to\nminimize the fitness value derived from observations at each iteration by\nexecuting the Q-learning algorithm. The proposed method has been evaluated\nusing two control tasks from the OpenAI Gym: CartPole and FrozenLake. The\nempirical results indicate that the QF-tuner outperforms other optimization\nalgorithms, such as particle swarm optimization (PSO), bees algorithm (BA),\ngenetic algorithms (GA), and the random method. However, on the FrozenLake\ntask, the QF-tuner increased rewards by 36% and reduced learning time by 26%,\nwhile on the CartPole task, it increased rewards by 57% and reduced learning\ntime by 20%. Thus, the QF-tuner is an essential method for hyperparameter\ntuning in Q-learning algorithms, enabling more effective solutions to control\ntask problems.",
      "tldr_zh": "本文提出了一种名为 QF-tuner's 新方法，用于强化学习中 Q-learning 算法的自动超参数调优，采用 FOX optimization algorithm 作为优化工具，并引入一个优先考虑奖励的目标函数，以最小化适应值。实验在 OpenAI Gym 的 CartPole 和 FrozenLake 任务上进行，结果显示 QF-tuner 优于 PSO、BA、GA 和随机方法：在 FrozenLake 上，奖励提升 36% 且学习时间减少 26%；在 CartPole 上，奖励提升 57% 且学习时间减少 20%。该方法打破了传统手动调优的局限性，提供更高效的控制任务解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.16562v4",
      "published_date": "2024-02-26 13:39:04 UTC",
      "updated_date": "2025-03-18 01:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:14:04.789256"
    },
    {
      "arxiv_id": "2403.07905v1",
      "title": "Enhancing Kubernetes Automated Scheduling with Deep Learning and Reinforcement Techniques for Large-Scale Cloud Computing Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Xu",
        "Yulu Gong",
        "Yanlin Zhou",
        "Qiaozhi Bao",
        "Wenpin Qian"
      ],
      "abstract": "With the continuous expansion of the scale of cloud computing applications,\nartificial intelligence technologies such as Deep Learning and Reinforcement\nLearning have gradually become the key tools to solve the automated task\nscheduling of large-scale cloud computing systems. Aiming at the complexity and\nreal-time requirement of task scheduling in large-scale cloud computing system,\nthis paper proposes an automatic task scheduling scheme based on deep learning\nand reinforcement learning. Firstly, the deep learning technology is used to\nmonitor and predict the parameters in the cloud computing system in real time\nto obtain the system status information. Then, combined with reinforcement\nlearning algorithm, the task scheduling strategy is dynamically adjusted\naccording to the real-time system state and task characteristics to achieve the\noptimal utilization of system resources and the maximum of task execution\nefficiency. This paper verifies the effectiveness and performance advantages of\nthe proposed scheme in experiments, and proves the potential and application\nprospect of deep learning and reinforcement learning in automatic task\nscheduling in large-scale cloud computing systems.",
      "tldr_zh": "这篇论文针对大规模云计算系统的任务调度复杂性和实时需求，提出了一种基于 Deep Learning 和 Reinforcement Learning 的自动调度方案，以优化 Kubernetes 环境下的资源利用。方案首先利用 Deep Learning 技术实时监控和预测系统参数，获取系统状态信息；然后结合 Reinforcement Learning 算法，根据实时状态和任务特性动态调整调度策略。实验结果证明，该方法显著提高了任务执行效率和系统性能，展示了其在大型云计算优化中的应用潜力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07905v1",
      "published_date": "2024-02-26 13:12:44 UTC",
      "updated_date": "2024-02-26 13:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:14:14.949278"
    },
    {
      "arxiv_id": "2402.16546v1",
      "title": "Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects",
      "title_zh": "超越准确性：开源深度学习项目中单元测试的实证研究",
      "authors": [
        "Han Wang",
        "Sijia Yu",
        "Chunyang Chen",
        "Burak Turhan",
        "Xiaodong Zhu"
      ],
      "abstract": "Deep Learning (DL) models have rapidly advanced, focusing on achieving high\nperformance through testing model accuracy and robustness. However, it is\nunclear whether DL projects, as software systems, are tested thoroughly or\nfunctionally correct when there is a need to treat and test them like other\nsoftware systems. Therefore, we empirically study the unit tests in open-source\nDL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit tested\nDL projects have positive correlation with the open-source project metrics and\nhave a higher acceptance rate of pull requests, 2) 68% of the sampled DL\nprojects are not unit tested at all, 3) the layer and utilities (utils) of DL\nmodels have the most unit tests. Based on these findings and previous research\noutcomes, we built a mapping taxonomy between unit tests and faults in DL\nprojects. We discuss the implications of our findings for developers and\nresearchers and highlight the need for unit testing in open-source DL projects\nto ensure their reliability and stability. The study contributes to this\ncommunity by raising awareness of the importance of unit testing in DL projects\nand encouraging further research in this area.",
      "tldr_zh": "本研究通过分析 GitHub 上 9,129 个开源深度学习 (Deep Learning) 项目，对 unit testing 的实施情况进行实证研究，发现有 unit testing 的项目与开源指标正相关，且拉取请求接受率更高，但 68% 的项目完全缺乏 unit testing，且模型的 layer 和 utils 部分有最多的测试。基于这些发现，研究者构建了一个 unit testing 与 DL 项目故障之间的映射分类法 (mapping taxonomy)。这项工作强调了 unit testing 在确保 DL 项目可靠性和稳定性的重要性，并呼吁开发者和研究者提高重视，推动相关领域的研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "ACM Transactions on Software Engineering and Methodology (2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.16546v1",
      "published_date": "2024-02-26 13:08:44 UTC",
      "updated_date": "2024-02-26 13:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:14:29.428033"
    },
    {
      "arxiv_id": "2402.16542v2",
      "title": "RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Alt",
        "Florian Stöckl",
        "Silvan Müller",
        "Christopher Braun",
        "Julian Raible",
        "Saad Alhasan",
        "Oliver Rettig",
        "Lukas Ringle",
        "Darko Katic",
        "Rainer Jäkel",
        "Michael Beetz",
        "Marcus Strand",
        "Marco F. Huber"
      ],
      "abstract": "Surface treatment tasks such as grinding, sanding or polishing are a vital\nstep of the value chain in many industries, but are notoriously challenging to\nautomate. We present RoboGrind, an integrated system for the intuitive,\ninteractive automation of surface treatment tasks with industrial robots. It\ncombines a sophisticated 3D perception pipeline for surface scanning and\nautomatic defect identification, an interactive voice-controlled wizard system\nfor the AI-assisted bootstrapping and parameterization of robot programs, and\nan automatic planning and execution pipeline for force-controlled robotic\nsurface treatment. RoboGrind is evaluated both under laboratory and real-world\nconditions in the context of refabricating fiberglass wind turbine blades.",
      "tldr_zh": "该研究介绍了RoboGrind系统，一种用于直观交互式自动化表面处理任务（如研磨、打磨或抛光）的集成解决方案，旨在解决工业机器人应用的挑战。系统结合了先进的3D perception pipeline用于表面扫描和自动缺陷识别、交互式语音-controlled wizard system辅助AI启动和参数化机器人程序，以及自动planning and execution pipeline实现力控机器人操作。在实验室和真实世界条件下，RoboGrind在修复玻璃纤维风力涡轮机叶片的任务中表现出色，证明了其在工业自动化中的实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40",
        "I.2.6; I.2.2; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 6 figures, accepted to the 2024 IEEE International\n  Conference on Robotics and Automation (ICRA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.16542v2",
      "published_date": "2024-02-26 13:01:28 UTC",
      "updated_date": "2024-02-27 08:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:14:39.186046"
    },
    {
      "arxiv_id": "2402.17791v1",
      "title": "Label Informed Contrastive Pretraining for Node Importance Estimation on Knowledge Graphs",
      "title_zh": "标签指导的对比预训练用于知识图谱上的节点重要性估计",
      "authors": [
        "Tianyu Zhang",
        "Chengbin Hou",
        "Rui Jiang",
        "Xuegong Zhang",
        "Chenghu Zhou",
        "Ke Tang",
        "Hairong Lv"
      ],
      "abstract": "Node Importance Estimation (NIE) is a task of inferring importance scores of\nthe nodes in a graph. Due to the availability of richer data and knowledge,\nrecent research interests of NIE have been dedicating to knowledge graphs for\npredicting future or missing node importance scores. Existing state-of-the-art\nNIE methods train the model by available labels, and they consider every\ninterested node equally before training. However, the nodes with higher\nimportance often require or receive more attention in real-world scenarios,\ne.g., people may care more about the movies or webpages with higher importance.\nTo this end, we introduce Label Informed ContrAstive Pretraining (LICAP) to the\nNIE problem for being better aware of the nodes with high importance scores.\nSpecifically, LICAP is a novel type of contrastive learning framework that aims\nto fully utilize the continuous labels to generate contrastive samples for\npretraining embeddings. Considering the NIE problem, LICAP adopts a novel\nsampling strategy called top nodes preferred hierarchical sampling to first\ngroup all interested nodes into a top bin and a non-top bin based on node\nimportance scores, and then divide the nodes within top bin into several finer\nbins also based on the scores. The contrastive samples are generated from those\nbins, and are then used to pretrain node embeddings of knowledge graphs via a\nnewly proposed Predicate-aware Graph Attention Networks (PreGAT), so as to\nbetter separate the top nodes from non-top nodes, and distinguish the top nodes\nwithin top bin by keeping the relative order among finer bins. Extensive\nexperiments demonstrate that the LICAP pretrained embeddings can further boost\nthe performance of existing NIE methods and achieve the new state-of-the-art\nperformance regarding both regression and ranking metrics. The source code for\nreproducibility is available at https://github.com/zhangtia16/LICAP",
      "tldr_zh": "这篇论文针对知识图谱上的 Node Importance Estimation (NIE) 任务，提出了一种新的 Label Informed ContrAstive Pretraining (LICAP) 方法，通过利用连续标签生成对比样本，以更好地关注高重要性节点。LICAP 采用 top nodes preferred hierarchical sampling 策略，将节点分组为 top bin 和 non-top bin，并进一步细分 top bin，然后使用 Predicate-aware Graph Attention Networks (PreGAT) 预训练节点嵌入，从而提升节点之间的区分度和相对顺序。实验结果表明，LICAP 预训练的嵌入显著提升了现有 NIE 方法的性能，在回归和排名指标上达到了新的 state-of-the-art 水平。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE TNNLS",
      "pdf_url": "http://arxiv.org/pdf/2402.17791v1",
      "published_date": "2024-02-26 12:28:51 UTC",
      "updated_date": "2024-02-26 12:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:14:52.388480"
    },
    {
      "arxiv_id": "2402.16926v1",
      "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Georg Pichler",
        "Marco Romanelli",
        "Divya Prakash Manivannan",
        "Prashanth Krishnamurthy",
        "Farshad Khorrami",
        "Siddharth Garg"
      ],
      "abstract": "We introduce a formal statistical definition for the problem of backdoor\ndetection in machine learning systems and use it to analyze the feasibility of\nsuch problems, providing evidence for the utility and applicability of our\ndefinition. The main contributions of this work are an impossibility result and\nan achievability result for backdoor detection. We show a no-free-lunch\ntheorem, proving that universal (adversary-unaware) backdoor detection is\nimpossible, except for very small alphabet sizes. Thus, we argue, that backdoor\ndetection methods need to be either explicitly, or implicitly adversary-aware.\nHowever, our work does not imply that backdoor detection cannot work in\nspecific scenarios, as evidenced by successful backdoor detection methods in\nthe scientific literature. Furthermore, we connect our definition to the\nprobably approximately correct (PAC) learnability of the out-of-distribution\ndetection problem.",
      "tldr_zh": "本研究将机器学习中的后门检测（backdoor detection）问题形式化为统计假设测试问题，并引入一个正式定义来分析其可行性。主要贡献包括一个不可能结果，即证明了通用后门检测（universal backdoor detection）是不可能的，除非字母表大小非常小，从而导出无免费午餐定理（no-free-lunch theorem）。论文强调，后门检测方法需显式或隐式地意识到对手（adversary-aware），尽管这并不排除特定场景下的成功应用。最终，该定义与分布外检测问题的PAC learnability（probably approximately correct learnability）相关联，为未来后门检测策略提供了重要指导。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16926v1",
      "published_date": "2024-02-26 11:43:01 UTC",
      "updated_date": "2024-02-26 11:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:15:03.699261"
    },
    {
      "arxiv_id": "2402.16505v2",
      "title": "Memory GAPS: Would LLMs pass the Tulving Test?",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Marie Chauvet"
      ],
      "abstract": "The Tulving Test was designed to investigate memory performance in\nrecognition and recall tasks. Its results help assess the relevance of the\n\"Synergistic Ecphory Model\" of memory and similar RK paradigms in human\nperformance. This paper starts investigating whether the more than\nforty-year-old framework sheds some light on LLMs' acts of remembering.",
      "tldr_zh": "这篇论文探讨大型语言模型(LLMs)是否能通过Tulving Test，该测试用于评估人类在识别和回忆任务中的记忆表现。\nTulving Test基于“Synergistic Ecphory Model”和类似RK paradigms的框架，帮助分析记忆机制在人类表现中的相关性。\n论文开始调查这个已有四十多年历史的框架是否能为LLMs的记忆行为提供启示，从而扩展AI记忆研究的理论基础。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16505v2",
      "published_date": "2024-02-26 11:40:51 UTC",
      "updated_date": "2024-02-28 15:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:15:16.739889"
    },
    {
      "arxiv_id": "2403.07904v3",
      "title": "Addressing the regulatory gap: moving towards an EU AI audit ecosystem beyond the AI Act by including civil society",
      "title_zh": "解决监管缺口：通过纳入民间社会，迈向",
      "authors": [
        "David Hartmann",
        "José Renato Laranjeira de Pereira",
        "Chiara Streitbörger",
        "Bettina Berendt"
      ],
      "abstract": "The European legislature has proposed the Digital Services Act (DSA) and\nArtificial Intelligence Act (AIA) to regulate platforms and Artificial\nIntelligence (AI) products. We review to what extent third-party audits are\npart of both laws and how is access to information on models and the data\nprovided. By considering the value of third-party audits and third-party data\naccess in an audit ecosystem, we identify a regulatory gap in that the AIA does\nnot provide access to data for researchers and civil society. Our contributions\nto the literature include: (1) Defining an AI audit ecosystem incorporating\ncompliance and oversight. (2) Highlighting a regulatory gap within the DSA and\nAIA regulatory framework, preventing the establishment of an AI audit ecosystem\nthat has effective oversight by civil society and academia. (3) Emphasizing\nthat third-party audits by research and civil society must be part of that\necosystem, we call for AIA amendments and delegated acts to include data and\nmodel access for certain AI products. Furthermore, we call for the DSA to\nprovide NGOs and investigative journalists with data access to platforms by\ndelegated acts and for adaptions and amendments of the AIA to provide\nthird-party audits and data and model access, at least for high-risk systems.\nRegulations modeled after EU AI regulations should enable data access and\nthird-party audits, fostering an AI audit ecosystem that promotes compliance\nand oversight mechanisms.",
      "tldr_zh": "本研究审查了欧盟的 Digital Services Act (DSA) 和 Artificial Intelligence Act (AIA)，发现这些法规虽包含第三方审计机制，但未为研究者和民间社会提供数据和模型访问，从而导致监管缺口。论文定义了 AI audit ecosystem 的概念，强调其需整合合规和监督机制，以实现有效 oversight。关键贡献包括突出 DSA 和 AIA 的不足，并呼吁通过修改 AIA 的 delegated acts 允许第三方审计和数据访问，尤其是针对高风险 AI 系统。同时，建议 DSA 扩展数据访问权限给 NGOs 和调查记者，以构建一个更全面的 AI 审计生态系统，促进 AI 产品的合规和监督。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07904v3",
      "published_date": "2024-02-26 11:32:42 UTC",
      "updated_date": "2025-02-19 15:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:15:29.749010"
    },
    {
      "arxiv_id": "2402.17599v2",
      "title": "DAGnosis: Localized Identification of Data Inconsistencies using Structures",
      "title_zh": "DAGnosis：利用结构进行数据不一致性的本地化识别",
      "authors": [
        "Nicolas Huynh",
        "Jeroen Berrevoets",
        "Nabeel Seedat",
        "Jonathan Crabbé",
        "Zhaozhi Qian",
        "Mihaela van der Schaar"
      ],
      "abstract": "Identification and appropriate handling of inconsistencies in data at\ndeployment time is crucial to reliably use machine learning models. While\nrecent data-centric methods are able to identify such inconsistencies with\nrespect to the training set, they suffer from two key limitations: (1)\nsuboptimality in settings where features exhibit statistical independencies,\ndue to their usage of compressive representations and (2) lack of localization\nto pin-point why a sample might be flagged as inconsistent, which is important\nto guide future data collection. We solve these two fundamental limitations\nusing directed acyclic graphs (DAGs) to encode the training set's features\nprobability distribution and independencies as a structure. Our method, called\nDAGnosis, leverages these structural interactions to bring valuable and\ninsightful data-centric conclusions. DAGnosis unlocks the localization of the\ncauses of inconsistencies on a DAG, an aspect overlooked by previous\napproaches. Moreover, we show empirically that leveraging these interactions\n(1) leads to more accurate conclusions in detecting inconsistencies, as well as\n(2) provides more detailed insights into why some samples are flagged.",
      "tldr_zh": "该论文提出DAGnosis，一种利用有向无环图 (DAGs) 的方法，来识别和定位机器学习模型部署时的数据不一致性。现有数据中心方法存在两大问题：(1) 在特征显示统计独立性时因使用压缩表示而表现不佳，以及(2) 无法精确定位不一致原因，从而影响后续数据收集。实验结果显示，DAGnosis 通过编码训练集特征的概率分布和独立性结构，不仅提高了不一致性检测的准确性，还提供了更详细的洞见，帮助理解样本被标记的原因。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2024; added correspondance email",
      "pdf_url": "http://arxiv.org/pdf/2402.17599v2",
      "published_date": "2024-02-26 11:29:16 UTC",
      "updated_date": "2024-02-28 10:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:15:39.705345"
    },
    {
      "arxiv_id": "2402.16925v1",
      "title": "Minimize Control Inputs for Strong Structural Controllability Using Reinforcement Learning with Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Mengbang Zou",
        "Weisi Guo",
        "Bailu Jin"
      ],
      "abstract": "Strong structural controllability (SSC) guarantees networked system with\nlinear-invariant dynamics controllable for all numerical realizations of\nparameters. Current research has established algebraic and graph-theoretic\nconditions of SSC for zero/nonzero or zero/nonzero/arbitrary structure. One\nrelevant practical problem is how to fully control the system with the minimal\nnumber of input signals and identify which nodes must be imposed signals.\nPrevious work shows that this optimization problem is NP-hard and it is\ndifficult to find the solution. To solve this problem, we formulate the graph\ncoloring process as a Markov decision process (MDP) according to the\ngraph-theoretical condition of SSC for both zero/nonzero and\nzero/nonzero/arbitrary structure. We use Actor-critic method with Directed\ngraph neural network which represents the color information of graph to\noptimize MDP. Our method is validated in a social influence network with real\ndata and different complex network models. We find that the number of input\nnodes is determined by the average degree of the network and the input nodes\ntend to select nodes with low in-degree and avoid high-degree nodes.",
      "tldr_zh": "本研究针对强结构可控性 (SSC) 的优化问题，提出一种最小化控制输入的方法，以确保网络系统在所有参数实现下可控。论文将图着色过程形式化为 Markov Decision Process (MDP)，并使用 Actor-critic 方法结合 Directed Graph Neural Network 来优化输入节点的选择，从而解决这一 NP-hard 问题。在社交影响网络和各种复杂网络模型上的实验验证显示，所需输入节点的数量取决于网络的平均度，且输入节点倾向于选择入度低的节点而避免高度节点。总的来说，该方法为高效控制网络系统提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16925v1",
      "published_date": "2024-02-26 11:18:53 UTC",
      "updated_date": "2024-02-26 11:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:15:51.860234"
    },
    {
      "arxiv_id": "2402.16486v1",
      "title": "Intelligent Known and Novel Aircraft Recognition -- A Shift from Classification to Similarity Learning for Combat Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Saeed",
        "Haasha Bin Atif",
        "Usman Habib",
        "Mohsin Bilal"
      ],
      "abstract": "Precise aircraft recognition in low-resolution remote sensing imagery is a\nchallenging yet crucial task in aviation, especially combat identification.\nThis research addresses this problem with a novel, scalable, and AI-driven\nsolution. The primary hurdle in combat identification in remote sensing imagery\nis the accurate recognition of Novel/Unknown types of aircraft in addition to\nKnown types. Traditional methods, human expert-driven combat identification and\nimage classification, fall short in identifying Novel classes. Our methodology\nemploys similarity learning to discern features of a broad spectrum of military\nand civilian aircraft. It discerns both Known and Novel aircraft types,\nleveraging metric learning for the identification and supervised few-shot\nlearning for aircraft type classification. To counter the challenge of limited\nlow-resolution remote sensing data, we propose an end-to-end framework that\nadapts to the diverse and versatile process of military aircraft recognition by\ntraining a generalized embedder in fully supervised manner. Comparative\nanalysis with earlier aircraft image classification methods shows that our\napproach is effective for aircraft image classification (F1-score Aircraft Type\nof 0.861) and pioneering for quantifying the identification of Novel types\n(F1-score Bipartitioning of 0.936). The proposed methodology effectively\naddresses inherent challenges in remote sensing data, thereby setting new\nstandards in dataset quality. The research opens new avenues for domain experts\nand demonstrates unique capabilities in distinguishing various aircraft types,\ncontributing to a more robust, domain-adapted potential for real-time aircraft\nrecognition.",
      "tldr_zh": "这篇论文提出了一种智能的已知和新型飞机识别方法，通过从传统图像分类转向相似性学习（similarity learning），以提升低分辨率遥感图像中的战斗识别准确性。该方法利用度量学习（metric learning）来识别已知和新型飞机类型，并结合监督少样本学习（supervised few-shot learning）及一个端到端框架，在有限数据下训练通用的嵌入器（generalized embedder）。实验结果显示，该方法在飞机类型分类的 F1-score 达到 0.861，在新型飞机识别（bipartitioning）的 F1-score 达到 0.936，显著解决了遥感数据挑战并为实时识别开辟新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16486v1",
      "published_date": "2024-02-26 11:08:26 UTC",
      "updated_date": "2024-02-26 11:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:16:05.722569"
    },
    {
      "arxiv_id": "2402.16482v1",
      "title": "On Languaging a Simulation Engine",
      "title_zh": "翻译失败",
      "authors": [
        "Han Liu",
        "Liantang Li"
      ],
      "abstract": "Language model intelligence is revolutionizing the way we program materials\nsimulations. However, the diversity of simulation scenarios renders it\nchallenging to precisely transform human language into a tailored simulator.\nHere, using three functionalized types of language model, we propose a\nlanguage-to-simulation (Lang2Sim) framework that enables interactive navigation\non languaging a simulation engine, by taking a scenario instance of water\nsorption in porous matrices. Unlike line-by-line coding of a target simulator,\nthe language models interpret each simulator as an assembly of invariant tool\nfunction and its variant input-output pair. Lang2Sim enables the precise\ntransform of textual description by functionalizing and sequentializing the\nlanguage models of, respectively, rationalizing the tool categorization,\ncustomizing its input-output combinations, and distilling the simulator input\ninto executable format. Importantly, depending on its functionalized type, each\nlanguage model features a distinct processing of chat history to best balance\nits memory limit and information completeness, thus leveraging the model\nintelligence to unstructured nature of human request. Overall, this work\nestablishes language model as an intelligent platform to unlock the era of\nlanguaging a simulation engine.",
      "tldr_zh": "本研究探讨了如何使用语言模型（language models）来编程材料模拟引擎，提出了一种 Language-to-Simulation (Lang2Sim) 框架，以水在多孔矩阵中的吸附场景为例，实现交互式导航。框架将模拟器视为不变的工具函数（tool function）和可变输入输出对的组合，通过三种功能化的语言模型——理性化工具分类、自定义输入输出组合以及提炼模拟器输入为可执行格式——来精确转换文本描述，并优化聊天历史处理以平衡内存限制和信息完整性。与传统逐行编码相比，该方法显著提高了模拟引擎的灵活性和准确性。整体而言，此工作确立了语言模型作为智能平台，推动了“languaging a simulation engine”的新时代。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16482v1",
      "published_date": "2024-02-26 11:01:54 UTC",
      "updated_date": "2024-02-26 11:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:16:17.447118"
    },
    {
      "arxiv_id": "2403.04772v2",
      "title": "Representing Pedagogic Content Knowledge Through Rough Sets",
      "title_zh": "翻译失败",
      "authors": [
        "A Mani"
      ],
      "abstract": "A teacher's knowledge base consists of knowledge of mathematics content,\nknowledge of student epistemology, and pedagogical knowledge. It has severe\nimplications on the understanding of student's knowledge of content, and the\nlearning context in general. The necessity to formalize the different content\nknowledge in approximate senses is recognized in the education research\nliterature. A related problem is that of coherent formalizability. Existing\nresponsive or smart AI-based software systems do not concern themselves with\nmeaning, and trained ones are replete with their own issues. In the present\nresearch, many issues in modeling teachers' understanding of content are\nidentified, and a two-tier rough set-based model is proposed by the present\nauthor for the purpose of developing software that can aid the varied tasks of\na teacher. The main advantage of the proposed approach is in its ability to\ncoherently handle vagueness, granularity and multi-modality. An extended\nexample to equational reasoning is used to demonstrate these. The paper is\nmeant for rough set researchers intending to build logical models or develop\nmeaning-aware AI-software to aid teachers, and education research experts.",
      "tldr_zh": "该论文探讨了教师知识基础（包括数学内容知识、学生认识论和教学知识）的正式化问题，强调了处理模糊性和连贯性的必要性。作者提出一个两层 Rough Sets 模型，用于开发辅助教师任务的 AI 软件，该模型能有效处理知识的模糊性、粒度化和多模态性。通过等式推理的扩展示例，论文展示了该方法的优势，旨在为 Rough Sets 研究者和教育研究专家提供有价值的工具。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "15+ pages",
      "pdf_url": "http://arxiv.org/pdf/2403.04772v2",
      "published_date": "2024-02-26 11:00:45 UTC",
      "updated_date": "2024-04-15 20:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:16:28.875176"
    },
    {
      "arxiv_id": "2402.16924v1",
      "title": "Theoretical Unification of the Fractured Aspects of Information",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin J. Schroeder"
      ],
      "abstract": "The article has as its main objective the identification of fundamental\nepistemological obstacles in the study of information related to unnecessary\nmethodological assumptions and the demystification of popular beliefs in the\nfundamental divisions of the aspects of information that can be understood as\nBachelardian rupture of epistemological obstacles. These general considerations\nare preceded by an overview of the motivations for the study of information and\nthe role of the concept of information in the conceptualization of\nintelligence, complexity, and consciousness justifying the need for a\nsufficiently general perspective in the study of information, and are followed\nat the end of the article by a brief exposition of an example of a possible\napplication in the development of the unified theory of information free from\nunnecessary divisions and claims of superiority of the existing preferences in\nmethodology. The reference to Gaston Bachelard and his ideas of epistemological\nobstacles and epistemological ruptures seems highly appropriate for the\nreflection on the development of information study, in particular in the\ncontext of obstacles such as the absence of semantics of information,\nnegligence of its structural analysis, separation of its digital and analog\nforms, and misguided use of mathematics.",
      "tldr_zh": "这篇论文旨在统一信息研究的碎片化方面，通过识别和克服基本认识论障碍（epistemological obstacles），如不必要的假设和对信息划分的流行信念。该研究首先概述了研究信息的需求及其在智能、复杂性和意识中的核心作用，强调需要一个更一般的视角。随后，论文引用Gaston Bachelard的认识论断裂（epistemological ruptures）理念，分析问题如信息语义缺失、结构分析的忽视、数字与模拟形式的分离，以及数学的误用。作为主要贡献，论文提供了一个统一的理论示例，旨在摆脱现有方法论偏好，促进信息研究的全面发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "52 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.16924v1",
      "published_date": "2024-02-26 10:35:41 UTC",
      "updated_date": "2024-02-26 10:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:16:40.458063"
    },
    {
      "arxiv_id": "2402.16472v2",
      "title": "mEdIT: Multilingual Text Editing via Instruction Tuning",
      "title_zh": "mEdIT：通过指令微调的多语言文本编辑",
      "authors": [
        "Vipul Raheja",
        "Dimitris Alikaniotis",
        "Vivek Kulkarni",
        "Bashar Alhafni",
        "Dhruv Kumar"
      ],
      "abstract": "We introduce mEdIT, a multi-lingual extension to CoEdIT -- the recent\nstate-of-the-art text editing models for writing assistance. mEdIT models are\ntrained by fine-tuning multi-lingual large, pre-trained language models (LLMs)\nvia instruction tuning. They are designed to take instructions from the user\nspecifying the attributes of the desired text in the form of natural language\ninstructions, such as Grammatik korrigieren (German) or Parafrasee la oraci\\'on\n(Spanish). We build mEdIT by curating data from multiple publicly available\nhuman-annotated text editing datasets for three text editing tasks (Grammatical\nError Correction (GEC), Text Simplification, and Paraphrasing) across diverse\nlanguages belonging to six different language families. We detail the design\nand training of mEdIT models and demonstrate their strong performance on many\nmulti-lingual text editing benchmarks against other multilingual LLMs. We also\nfind that mEdIT generalizes effectively to new languages over multilingual\nbaselines. We publicly release our data, code, and trained models at\nhttps://github.com/vipulraheja/medit.",
      "tldr_zh": "该研究引入了 mEdIT，一种基于指令微调(instruction tuning)的多语言文本编辑模型，作为 CoEdIT 的扩展，用于写作辅助。mEdIT 通过微调多语言预训练大型语言模型(LLMs)，接受自然语言指令（如语法错误修正(Grammatical Error Correction)或文本简化），并利用多个公开数据集汇集了 Grammatical Error Correction (GEC)、Text Simplification 和 Paraphrasing 等任务的数据，覆盖六种语言家族。实验结果显示，mEdIT 在多语言文本编辑基准上优于其他多语言 LLMs，并能有效泛化到新语言；研究团队在 GitHub 上公开了数据、代码和模型以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 (Main). 23 pages, 8 tables, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16472v2",
      "published_date": "2024-02-26 10:33:36 UTC",
      "updated_date": "2024-04-17 16:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:16:53.706080"
    },
    {
      "arxiv_id": "2402.16459v3",
      "title": "Defending LLMs against Jailbreaking Attacks via Backtranslation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihan Wang",
        "Zhouxing Shi",
        "Andrew Bai",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Although many large language models (LLMs) have been trained to refuse\nharmful requests, they are still vulnerable to jailbreaking attacks which\nrewrite the original prompt to conceal its harmful intent. In this paper, we\npropose a new method for defending LLMs against jailbreaking attacks by\n``backtranslation''. Specifically, given an initial response generated by the\ntarget LLM from an input prompt, our backtranslation prompts a language model\nto infer an input prompt that can lead to the response. The inferred prompt is\ncalled the backtranslated prompt which tends to reveal the actual intent of the\noriginal prompt, since it is generated based on the LLM's response and not\ndirectly manipulated by the attacker. We then run the target LLM again on the\nbacktranslated prompt, and we refuse the original prompt if the model refuses\nthe backtranslated prompt. We explain that the proposed defense provides\nseveral benefits on its effectiveness and efficiency. We empirically\ndemonstrate that our defense significantly outperforms the baselines, in the\ncases that are hard for the baselines, and our defense also has little impact\non the generation quality for benign input prompts. Our implementation is based\non our library for LLM jailbreaking defense algorithms at\n\\url{https://github.com/YihanWang617/llm-jailbreaking-defense}, and the code\nfor reproducing our experiments is available at\n\\url{https://github.com/YihanWang617/LLM-Jailbreaking-Defense-Backtranslation}.",
      "tldr_zh": "该论文提出了一种名为 Backtranslation 的方法，用于防御大型语言模型（LLMs）免受 Jailbreaking Attacks，这些攻击通过改写提示来隐藏有害意图。具体而言，该方法从LLMs的初始响应中推断出一个 Backtranslated Prompt，以揭示原提示的真实意图，然后通过重新运行LLMs来决定是否拒绝原输入。实验结果表明，该防御机制在基线模型难以处理的场景中准确率显著提升，同时对良性提示的生成质量影响很小，并提供了开源代码以便复现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16459v3",
      "published_date": "2024-02-26 10:03:33 UTC",
      "updated_date": "2024-06-06 19:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:17:05.183739"
    },
    {
      "arxiv_id": "2402.16455v1",
      "title": "Performance Comparison of Surrogate-Assisted Evolutionary Algorithms on Computational Fluid Dynamics Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Kudela",
        "Ladislav Dobrovsky"
      ],
      "abstract": "Surrogate-assisted evolutionary algorithms (SAEAs) are recently among the\nmost widely studied methods for their capability to solve expensive real-world\noptimization problems. However, the development of new methods and benchmarking\nwith other techniques still relies almost exclusively on artificially created\nproblems. In this paper, we use two real-world computational fluid dynamics\nproblems to compare the performance of eleven state-of-the-art single-objective\nSAEAs. We analyze the performance by investigating the quality and robustness\nof the obtained solutions and the convergence properties of the selected\nmethods. Our findings suggest that the more recently published methods, as well\nas the techniques that utilize differential evolution as one of their\noptimization mechanisms, perform significantly better than the other considered\nmethods.",
      "tldr_zh": "本文比较了 Surrogate-Assisted Evolutionary Algorithms (SAEAs) 在真实 Computational Fluid Dynamics (CFD) 问题上的性能，旨在解决这些算法在昂贵优化问题中的应用。研究使用两个真实 CFD 问题作为基准，评估了 11 个最先进的单目标 SAEAs 的解决方案质量、稳健性和收敛特性。结果表明，较新的方法以及那些采用 Differential Evolution 作为优化机制的技术，显著优于其他算法。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16455v1",
      "published_date": "2024-02-26 09:58:36 UTC",
      "updated_date": "2024-02-26 09:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:17:16.581012"
    },
    {
      "arxiv_id": "2402.16449v1",
      "title": "Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhang",
        "Guangyao Tian",
        "Long Wen",
        "Xiangtong Yao",
        "Liding Zhang",
        "Zhenshan Bing",
        "Wei He",
        "Alois Knoll"
      ],
      "abstract": "This paper proposes a LiDAR-based goal-seeking and exploration framework,\naddressing the efficiency of online obstacle avoidance in unstructured\nenvironments populated with static and moving obstacles. This framework\naddresses two significant challenges associated with traditional dynamic\ncontrol barrier functions (D-CBFs): their online construction and the\ndiminished real-time performance caused by utilizing multiple D-CBFs. To tackle\nthe first challenge, the framework's perception component begins with\nclustering point clouds via the DBSCAN algorithm, followed by encapsulating\nthese clusters with the minimum bounding ellipses (MBEs) algorithm to create\nelliptical representations. By comparing the current state of MBEs with those\nstored from previous moments, the differentiation between static and dynamic\nobstacles is realized, and the Kalman filter is utilized to predict the\nmovements of the latter. Such analysis facilitates the D-CBF's online\nconstruction for each MBE. To tackle the second challenge, we introduce buffer\nzones, generating Type-II D-CBFs online for each identified obstacle. Utilizing\nthese buffer zones as activation areas substantially reduces the number of\nD-CBFs that need to be activated. Upon entering these buffer zones, the system\nprioritizes safety, autonomously navigating safe paths, and hence referred to\nas the exploration mode. Exiting these buffer zones triggers the system's\ntransition to goal-seeking mode. We demonstrate that the system's states under\nthis framework achieve safety and asymptotic stabilization. Experimental\nresults in simulated and real-world environments have validated our framework's\ncapability, allowing a LiDAR-equipped mobile robot to efficiently and safely\nreach the desired location within dynamic environments containing multiple\nobstacles.",
      "tldr_zh": "这篇论文提出了一种基于 LiDAR 的在线高效安全关键控制框架，用于移动机器人在未知动态多障碍环境中的目标寻找和探索，解决了传统动态控制屏障函数 (D-CBFs) 在在线构建和实时性能方面的挑战。框架采用 DBSCAN 算法聚类点云、最小边界椭圆 (MBEs) 封装障碍物、Kalman 滤波器预测动态障碍物运动，并引入缓冲区机制在线生成 Type-II D-CBFs，仅在激活区域内启用以优先确保安全。实验在模拟和真实环境中验证，该框架使机器人高效、安全地到达目标位置，实现系统状态的渐近稳定和性能提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16449v1",
      "published_date": "2024-02-26 09:53:37 UTC",
      "updated_date": "2024-02-26 09:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:17:30.351529"
    },
    {
      "arxiv_id": "2402.16442v3",
      "title": "On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Böther",
        "Abraham Sebastian",
        "Pranjal Awasthi",
        "Ana Klimovic",
        "Srikumar Ramalingam"
      ],
      "abstract": "Modern datasets span billions of samples, making training on all available\ndata infeasible. Selecting a high quality subset helps in reducing training\ncosts and enhancing model quality. Submodularity, a discrete analogue of\nconvexity, is commonly used for solving such subset selection problems.\nHowever, existing algorithms for optimizing submodular functions are\nsequential, and the prior distributed methods require at least one central\nmachine to fit the target subset in DRAM. At billion datapoint scale, even the\nsubset may not fit a single machine, and the sequential algorithms are\nprohibitively slow. In this paper, we relax the requirement of having a central\nmachine for the target subset by proposing a novel distributed bounding\nalgorithm with provable approximation guarantees. The algorithm iteratively\nbounds the minimum and maximum utility values to select high quality points and\ndiscard the unimportant ones. When bounding does not find the complete subset,\nwe use a multi-round, partition-based distributed greedy algorithm to identify\nthe remaining subset. We discuss how to implement these algorithms in a\ndistributed data processing framework and empirically analyze different\nconfigurations. We find high quality subsets on CIFAR-100 and ImageNet with\nmarginal or no loss in quality compared to centralized methods, and scale to a\ndataset with 13 billion points.",
      "tldr_zh": "该论文解决了大规模数据集（数十亿样本）中子集选择的问题，提出了一种分布式边界算法（distributed bounding algorithm），它通过迭代界定最小和最大效用值来选择高质量数据点，并丢弃不重要样本，从而避免了传统方法对中心机器的需求。论文还结合了多轮基于分区的分布式贪心算法（distributed greedy algorithm）来补充剩余子集，确保算法在内存不足场景下具有可证明的近似保证。在实验中，该方法在 CIFAR-100 和 ImageNet 数据集上取得了与集中式方法相当的高质量子集，并成功扩展到 130 亿点的超大规模数据集，显著降低了训练成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at MLSys 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.16442v3",
      "published_date": "2024-02-26 09:38:39 UTC",
      "updated_date": "2025-04-03 08:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:17:40.810806"
    },
    {
      "arxiv_id": "2402.16435v1",
      "title": "Training Implicit Generative Models via an Invariant Statistical Loss",
      "title_zh": "翻译失败",
      "authors": [
        "José Manuel de Frutos",
        "Pablo M. Olmos",
        "Manuel A. Vázquez",
        "Joaquín Míguez"
      ],
      "abstract": "Implicit generative models have the capability to learn arbitrary complex\ndata distributions. On the downside, training requires telling apart real data\nfrom artificially-generated ones using adversarial discriminators, leading to\nunstable training and mode-dropping issues. As reported by Zahee et al. (2017),\neven in the one-dimensional (1D) case, training a generative adversarial\nnetwork (GAN) is challenging and often suboptimal. In this work, we develop a\ndiscriminator-free method for training one-dimensional (1D) generative implicit\nmodels and subsequently expand this method to accommodate multivariate cases.\nOur loss function is a discrepancy measure between a suitably chosen\ntransformation of the model samples and a uniform distribution; hence, it is\ninvariant with respect to the true distribution of the data. We first formulate\nour method for 1D random variables, providing an effective solution for\napproximate reparameterization of arbitrary complex distributions. Then, we\nconsider the temporal setting (both univariate and multivariate), in which we\nmodel the conditional distribution of each sample given the history of the\nprocess. We demonstrate through numerical simulations that this new method\nyields promising results, successfully learning true distributions in a variety\nof scenarios and mitigating some of the well-known problems that\nstate-of-the-art implicit methods present.",
      "tldr_zh": "该研究针对隐式生成模型(Implicit Generative Models)的训练问题，提出了一种基于不变统计损失(Invariant Statistical Loss)的方法，以避免传统GAN生成对抗网络的不稳定性和模式丢失问题。该损失函数通过测量模型样本变换与均匀分布的差异，实现无判别器的训练，先应用于一维随机变量，并扩展到多变量和时间序列场景。实验结果显示，该方法在各种模拟中成功学习真实分布，并有效缓解了现有隐式模型的常见缺陷。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16435v1",
      "published_date": "2024-02-26 09:32:28 UTC",
      "updated_date": "2024-02-26 09:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:17:52.753972"
    },
    {
      "arxiv_id": "2403.05574v3",
      "title": "HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy",
      "title_zh": "HealMe：利用大型语言模型中的认知重构进行心理治疗",
      "authors": [
        "Mengxi Xiao",
        "Qianqian Xie",
        "Ziyan Kuang",
        "Zhicheng Liu",
        "Kailai Yang",
        "Min Peng",
        "Weiguang Han",
        "Jimin Huang"
      ],
      "abstract": "Large Language Models (LLMs) can play a vital role in psychotherapy by\nadeptly handling the crucial task of cognitive reframing and overcoming\nchallenges such as shame, distrust, therapist skill variability, and resource\nscarcity. Previous LLMs in cognitive reframing mainly converted negative\nemotions to positive ones, but these approaches have limited efficacy, often\nnot promoting clients' self-discovery of alternative perspectives. In this\npaper, we unveil the Helping and Empowering through Adaptive Language in Mental\nEnhancement (HealMe) model. This novel cognitive reframing therapy method\neffectively addresses deep-rooted negative thoughts and fosters rational,\nbalanced perspectives. Diverging from traditional LLM methods, HealMe employs\nempathetic dialogue based on psychotherapeutic frameworks. It systematically\nguides clients through distinguishing circumstances from feelings,\nbrainstorming alternative viewpoints, and developing empathetic, actionable\nsuggestions. Moreover, we adopt the first comprehensive and expertly crafted\npsychological evaluation metrics, specifically designed to rigorously assess\nthe performance of cognitive reframing, in both AI-simulated dialogues and\nreal-world therapeutic conversations. Experimental results show that our model\noutperforms others in terms of empathy, guidance, and logical coherence,\ndemonstrating its effectiveness and potential positive impact on psychotherapy.",
      "tldr_zh": "本研究提出 HealMe 模型，利用 Large Language Models (LLMs) 进行认知重构（Cognitive Reframing），以解决传统方法在心理治疗中存在的局限性，如仅简单转换负面情绪而非促进自我发现。HealMe 通过基于心理治疗框架的移情对话（empathetic dialogue），系统引导用户区分情境与感受、 brainstorm 替代观点，并提供实用的移情建议，从而培养理性平衡的视角。研究采用首个全面专家设计的心理评估指标，在 AI 模拟对话和真实对话中评估模型表现，结果显示 HealMe 在移情、指导和逻辑连贯性方面优于其他模型，具有提升心理治疗潜力的显著效果。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.05574v3",
      "published_date": "2024-02-26 09:10:34 UTC",
      "updated_date": "2024-07-29 12:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:18:05.321853"
    },
    {
      "arxiv_id": "2402.16402v1",
      "title": "Graph Learning with Distributional Edge Layouts",
      "title_zh": "基于分布边布局的图学习",
      "authors": [
        "Xinjian Zhao",
        "Chaolong Ying",
        "Tianshu Yu"
      ],
      "abstract": "Graph Neural Networks (GNNs) learn from graph-structured data by passing\nlocal messages between neighboring nodes along edges on certain topological\nlayouts. Typically, these topological layouts in modern GNNs are\ndeterministically computed (e.g., attention-based GNNs) or locally sampled\n(e.g., GraphSage) under heuristic assumptions. In this paper, we for the first\ntime pose that these layouts can be globally sampled via Langevin dynamics\nfollowing Boltzmann distribution equipped with explicit physical energy,\nleading to higher feasibility in the physical world. We argue that such a\ncollection of sampled/optimized layouts can capture the wide energy\ndistribution and bring extra expressivity on top of WL-test, therefore easing\ndownstream tasks. As such, we propose Distributional Edge Layouts (DELs) to\nserve as a complement to a variety of GNNs. DEL is a pre-processing strategy\nindependent of subsequent GNN variants, thus being highly flexible.\nExperimental results demonstrate that DELs consistently and substantially\nimprove a series of GNN baselines, achieving state-of-the-art performance on\nmultiple datasets.",
      "tldr_zh": "本论文提出了一种新颖的图学习方法，通过使用 Langevin dynamics 全局采样边布局，使其遵循 Boltzmann distribution 并结合显式物理能量，从而提升图神经网络 (GNNs) 的物理可行性和表达性。相较于传统 GNNs 的确定性计算或局部采样，Distributional Edge Layouts (DELs) 作为一种独立的预处理策略，能捕捉能量分布并增强 Weisfeiler-Lehman (WL) 测试的性能，支持下游任务。实验结果显示，DELs 显著提高了多种 GNN 基线的表现，在多个数据集上达到了最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16402v1",
      "published_date": "2024-02-26 08:55:10 UTC",
      "updated_date": "2024-02-26 08:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:18:17.034492"
    },
    {
      "arxiv_id": "2402.16397v1",
      "title": "Investigating Deep Watermark Security: An Adversarial Transferability Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Biqing Qi",
        "Junqi Gao",
        "Yiang Luo",
        "Jianxing Liu",
        "Ligang Wu",
        "Bowen Zhou"
      ],
      "abstract": "The rise of generative neural networks has triggered an increased demand for\nintellectual property (IP) protection in generated content. Deep watermarking\ntechniques, recognized for their flexibility in IP protection, have garnered\nsignificant attention. However, the surge in adversarial transferable attacks\nposes unprecedented challenges to the security of deep watermarking\ntechniques-an area currently lacking systematic investigation. This study fills\nthis gap by introducing two effective transferable attackers to assess the\nvulnerability of deep watermarks against erasure and tampering risks.\nSpecifically, we initially define the concept of local sample density,\nutilizing it to deduce theorems on the consistency of model outputs. Upon\ndiscovering that perturbing samples towards high sample density regions (HSDR)\nof the target class enhances targeted adversarial transferability, we propose\nthe Easy Sample Selection (ESS) mechanism and the Easy Sample Matching Attack\n(ESMA) method. Additionally, we propose the Bottleneck Enhanced Mixup (BEM)\nthat integrates information bottleneck theory to reduce the generator's\ndependence on irrelevant noise. Experiments show a significant enhancement in\nthe success rate of targeted transfer attacks for both ESMA and BEM-ESMA\nmethods. We further conduct a comprehensive evaluation using ESMA and BEM-ESMA\nas measurements, considering model architecture and watermark encoding length,\nand achieve some impressive findings.",
      "tldr_zh": "本文研究了深度水印技术的安全性，从对抗转移性的视角出发，针对生成式神经网络中知识产权保护的挑战，引入了两种有效攻击方法：Easy Sample Selection (ESS) 机制和 Easy Sample Matching Attack (ESMA)，以及整合信息瓶颈理论的 Bottleneck Enhanced Mixup (BEM)。这些方法利用局部样本密度和 High Sample Density Regions (HSDR) 的概念，增强了针对性攻击的可转移性，并在实验中显著提高了攻击成功率。最终，通过对模型架构和水印编码长度的全面评估，论文揭示了深度水印的潜在脆弱性，为提升其安全性提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16397v1",
      "published_date": "2024-02-26 08:41:14 UTC",
      "updated_date": "2024-02-26 08:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:18:31.609246"
    },
    {
      "arxiv_id": "2402.16389v1",
      "title": "MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property",
      "title_zh": "翻译失败",
      "authors": [
        "Shiwen Ni",
        "Minghuan Tan",
        "Yuelin Bai",
        "Fuqiang Niu",
        "Min Yang",
        "Bowen Zhang",
        "Ruifeng Xu",
        "Xiaojun Chen",
        "Chengming Li",
        "Xiping Hu",
        "Ye Li",
        "Jianping Fan"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nvarious natural language processing (NLP) tasks. However, there is limited\nunderstanding of how well LLMs perform in specific domains (e.g, the\nintellectual property (IP) domain). In this paper, we contribute a new\nbenchmark, the first Multilingual-oriented quiZ on Intellectual Property\n(MoZIP), for the evaluation of LLMs in the IP domain. The MoZIP benchmark\nincludes three challenging tasks: IP multiple-choice quiz (IPQuiz), IP question\nanswering (IPQA), and patent matching (PatentMatch). In addition, we also\ndevelop a new IP-oriented multilingual large language model (called MoZi),\nwhich is a BLOOMZ-based model that has been supervised fine-tuned with\nmultilingual IP-related text data. We evaluate our proposed MoZi model and four\nwell-known LLMs (i.e., BLOOMZ, BELLE, ChatGLM and ChatGPT) on the MoZIP\nbenchmark. Experimental results demonstrate that MoZi outperforms BLOOMZ, BELLE\nand ChatGLM by a noticeable margin, while it had lower scores compared with\nChatGPT. Notably, the performance of current LLMs on the MoZIP benchmark has\nmuch room for improvement, and even the most powerful ChatGPT does not reach\nthe passing level. Our source code, data, and models are available at\n\\url{https://github.com/AI-for-Science/MoZi}.",
      "tldr_zh": "本研究引入了MoZIP基准，这是一个多语言评估框架，用于测试大型语言模型(LLMs)在知识产权(IP)领域的性能。MoZIP包括三个挑战任务：IP multiple-choice quiz (IPQuiz)、IP question answering (IPQA)和patent matching (PatentMatch)。研究者开发了基于BLOOMZ的IP导向多语言模型MoZi，通过监督微调多语言IP相关文本，并与BLOOMZ、BELLE、ChatGLM和ChatGPT等模型进行比较，结果显示MoZi在基准上显著优于前三者，但仍落后于ChatGPT，且所有模型的表现仍有较大改进空间。模型和数据已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16389v1",
      "published_date": "2024-02-26 08:27:50 UTC",
      "updated_date": "2024-02-26 08:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:18:41.370743"
    },
    {
      "arxiv_id": "2402.16387v1",
      "title": "On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method",
      "title_zh": "时间图学习算法的泛化能力：理论见解和一个更简单的方法",
      "authors": [
        "Weilin Cong",
        "Jian Kang",
        "Hanghang Tong",
        "Mehrdad Mahdavi"
      ],
      "abstract": "Temporal Graph Learning (TGL) has become a prevalent technique across diverse\nreal-world applications, especially in domains where data can be represented as\na graph and evolves over time. Although TGL has recently seen notable progress\nin algorithmic solutions, its theoretical foundations remain largely\nunexplored. This paper aims at bridging this gap by investigating the\ngeneralization ability of different TGL algorithms (e.g., GNN-based, RNN-based,\nand memory-based methods) under the finite-wide over-parameterized regime. We\nestablish the connection between the generalization error of TGL algorithms and\n\"the number of layers/steps\" in the GNN-/RNN-based TGL methods and \"the\nfeature-label alignment (FLA) score\", where FLA can be used as a proxy for the\nexpressive power and explains the performance of memory-based methods. Guided\nby our theoretical analysis, we propose Simplified-Temporal-Graph-Network,\nwhich enjoys a small generalization error, improved overall performance, and\nlower model complexity. Extensive experiments on real-world datasets\ndemonstrate the effectiveness of our method. Our theoretical findings and\nproposed algorithm offer essential insights into TGL from a theoretical\nstandpoint, laying the groundwork for the designing practical TGL algorithms in\nfuture studies.",
      "tldr_zh": "本研究探讨了Temporal Graph Learning (TGL)算法的泛化能力，针对GNN-based、RNN-based和memory-based方法，在有限宽度过参数化条件下，建立了泛化错误与层数/步骤数以及feature-label alignment (FLA)得分的关联，FLA得分可作为表达能力的代理指标。论文通过理论分析揭示了这些因素如何影响TGL的表现，并据此提出Simplified-Temporal-Graph-Network方法，该方法具备较低的泛化错误、更优的整体性能和简化模型复杂度。在真实数据集上的广泛实验验证了该方法的有效性，为未来TGL算法设计提供了重要理论指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16387v1",
      "published_date": "2024-02-26 08:22:22 UTC",
      "updated_date": "2024-02-26 08:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:18:54.037764"
    },
    {
      "arxiv_id": "2402.16380v1",
      "title": "An Automated End-to-End Open-Source Software for High-Quality Text-to-Speech Dataset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmet Gunduz",
        "Kamer Ali Yuksel",
        "Kareem Darwish",
        "Golara Javadi",
        "Fabio Minazzi",
        "Nicola Sobieski",
        "Sebastien Bratieres"
      ],
      "abstract": "Data availability is crucial for advancing artificial intelligence\napplications, including voice-based technologies. As content creation,\nparticularly in social media, experiences increasing demand, translation and\ntext-to-speech (TTS) technologies have become essential tools. Notably, the\nperformance of these TTS technologies is highly dependent on the quality of the\ntraining data, emphasizing the mutual dependence of data availability and\ntechnological progress. This paper introduces an end-to-end tool to generate\nhigh-quality datasets for text-to-speech (TTS) models to address this critical\nneed for high-quality data. The contributions of this work are manifold and\ninclude: the integration of language-specific phoneme distribution into sample\nselection, automation of the recording process, automated and human-in-the-loop\nquality assurance of recordings, and processing of recordings to meet specified\nformats. The proposed application aims to streamline the dataset creation\nprocess for TTS models through these features, thereby facilitating\nadvancements in voice-based technologies.",
      "tldr_zh": "这篇论文提出了一种自动化端到端的开源软件，用于生成高质量的 Text-to-Speech (TTS) 数据集，以解决语音技术发展对高质量训练数据的需求。软件的关键贡献包括整合语言特定音素分布到样本选择、自动化录音过程、结合自动化和人工参与的质量保证，以及处理录音以符合指定格式。这些功能简化了 TTS 数据集创建流程，通过提升数据可用性促进语音技术进步。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "9 Pages, 6 Figures, 4 Tables, LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16380v1",
      "published_date": "2024-02-26 07:58:33 UTC",
      "updated_date": "2024-02-26 07:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:19:04.415010"
    },
    {
      "arxiv_id": "2402.16379v3",
      "title": "TEaR: Improving LLM-based Machine Translation with Systematic Self-Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaopeng Feng",
        "Yan Zhang",
        "Hao Li",
        "Bei Wu",
        "Jiayu Liao",
        "Wenqiang Liu",
        "Jun Lang",
        "Yang Feng",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive results in Machine\nTranslation (MT). However, careful evaluations by human reveal that the\ntranslations produced by LLMs still contain multiple errors. Importantly,\nfeeding back such error information into the LLMs can lead to self-refinement\nand result in improved translation performance. Motivated by these insights, we\nintroduce a systematic LLM-based self-refinement translation framework, named\n\\textbf{TEaR}, which stands for \\textbf{T}ranslate, \\textbf{E}stimate,\n\\textbf{a}nd \\textbf{R}efine, marking a significant step forward in this\ndirection. Our findings demonstrate that 1) our self-refinement framework\nsuccessfully assists LLMs in improving their translation quality across a wide\nrange of languages, whether it's from high-resource languages to low-resource\nones or whether it's English-centric or centered around other languages; 2)\nTEaR exhibits superior systematicity and interpretability; 3) different\nestimation strategies yield varied impacts, directly affecting the\neffectiveness of the final corrections. Additionally, traditional neural\ntranslation models and evaluation models operate separately, often focusing on\nsingular tasks due to their limited capabilities, while general-purpose LLMs\npossess the capability to undertake both tasks simultaneously. We further\nconduct cross-model correction experiments to investigate the potential\nrelationship between the translation and evaluation capabilities of\ngeneral-purpose LLMs. Our code and data are available at\nhttps://github.com/fzp0424/self_correct_mt",
      "tldr_zh": "本研究提出TEaR框架，通过翻译、评估和改进的系统化自精炼过程，提升LLM在Machine Translation中的性能，针对LLMs的翻译错误进行反馈优化。\nTEaR框架适用于多种语言对，包括高资源到低资源语言，以及非English-centric场景，展示了优越的系统性和可解释性。\n实验发现，不同的评估策略会直接影响修正效果，而LLMs能同时承担翻译和评估任务，超越传统神经翻译模型的单一功能。\n此外，跨模型修正实验揭示了LLMs的翻译和评估能力之间的潜在关联，并提供了相关代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Our code and data are available at\n  https://github.com/fzp0424/self_correct_mt",
      "pdf_url": "http://arxiv.org/pdf/2402.16379v3",
      "published_date": "2024-02-26 07:58:12 UTC",
      "updated_date": "2024-06-21 07:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:19:18.148878"
    },
    {
      "arxiv_id": "2402.16369v1",
      "title": "Generative AI in Vision: A Survey on Models, Metrics and Applications",
      "title_zh": "生成式人工智能在视觉中的应用：模型、指标和应用的综述",
      "authors": [
        "Gaurav Raut",
        "Apoorv Singh"
      ],
      "abstract": "Generative AI models have revolutionized various fields by enabling the\ncreation of realistic and diverse data samples. Among these models, diffusion\nmodels have emerged as a powerful approach for generating high-quality images,\ntext, and audio. This survey paper provides a comprehensive overview of\ngenerative AI diffusion and legacy models, focusing on their underlying\ntechniques, applications across different domains, and their challenges. We\ndelve into the theoretical foundations of diffusion models, including concepts\nsuch as denoising diffusion probabilistic models (DDPM) and score-based\ngenerative modeling. Furthermore, we explore the diverse applications of these\nmodels in text-to-image, image inpainting, and image super-resolution, along\nwith others, showcasing their potential in creative tasks and data\naugmentation. By synthesizing existing research and highlighting critical\nadvancements in this field, this survey aims to provide researchers and\npractitioners with a comprehensive understanding of generative AI diffusion and\nlegacy models and inspire future innovations in this exciting area of\nartificial intelligence.",
      "tldr_zh": "这篇调查论文概述了生成式 AI 在视觉领域的模型，包括 diffusion models 和 legacy models，聚焦于其底层技术、应用以及面临的挑战。论文深入探讨了 diffusion models 的理论基础，如 denoising diffusion probabilistic models (DDPM) 和 score-based generative modeling，并总结了这些模型在文本到图像 (text-to-image)、图像修复 (image inpainting) 和图像超分辨率 (image super-resolution) 等领域的实际应用。最终，该研究通过综合现有成果，提供全面理解，帮助研究者和从业者识别创新机会，并推动人工智能领域的进步。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16369v1",
      "published_date": "2024-02-26 07:47:12 UTC",
      "updated_date": "2024-02-26 07:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:19:29.541038"
    },
    {
      "arxiv_id": "2402.16363v6",
      "title": "LLM Inference Unveiled: Survey and Roofline Model Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihang Yuan",
        "Yuzhang Shang",
        "Yang Zhou",
        "Zhen Dong",
        "Zhe Zhou",
        "Chenhao Xue",
        "Bingzhe Wu",
        "Zhikai Li",
        "Qingyi Gu",
        "Yong Jae Lee",
        "Yan Yan",
        "Beidi Chen",
        "Guangyu Sun",
        "Kurt Keutzer"
      ],
      "abstract": "The field of efficient Large Language Model (LLM) inference is rapidly\nevolving, presenting a unique blend of opportunities and challenges. Although\nthe field has expanded and is vibrant, there hasn't been a concise framework\nthat analyzes the various methods of LLM Inference to provide a clear\nunderstanding of this domain. Our survey stands out from traditional literature\nreviews by not only summarizing the current state of research but also by\nintroducing a framework based on roofline model for systematic analysis of LLM\ninference techniques. This framework identifies the bottlenecks when deploying\nLLMs on hardware devices and provides a clear understanding of practical\nproblems, such as why LLMs are memory-bound, how much memory and computation\nthey need, and how to choose the right hardware. We systematically collate the\nlatest advancements in efficient LLM inference, covering crucial areas such as\nmodel compression (e.g., Knowledge Distillation and Quantization), algorithm\nimprovements (e.g., Early Exit and Mixture-of-Expert), and both hardware and\nsystem-level enhancements. Our survey stands out by analyzing these methods\nwith roofline model, helping us understand their impact on memory access and\ncomputation. This distinctive approach not only showcases the current research\nlandscape but also delivers valuable insights for practical implementation,\npositioning our work as an indispensable resource for researchers new to the\nfield as well as for those seeking to deepen their understanding of efficient\nLLM deployment. The analyze tool, LLM-Viewer, is open-sourced.",
      "tldr_zh": "这篇论文调研了高效LLM（Large Language Model）推理领域的最新进展，并引入基于Roofline模型的框架来系统分析推理技术。该框架识别了LLM部署中的瓶颈，如内存绑定问题、计算和内存需求，以及硬件选择策略，并涵盖了模型压缩（如Knowledge Distillation和Quantization）、算法改进（如Early Exit和Mixture-of-Expert）以及硬件和系统级增强。论文通过Roofline模型评估这些方法的内存访问和计算影响，提供实用见解，帮助研究者优化LLM部署，并开源了分析工具LLM-Viewer。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16363v6",
      "published_date": "2024-02-26 07:33:05 UTC",
      "updated_date": "2024-05-01 20:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:19:42.138691"
    },
    {
      "arxiv_id": "2402.16361v1",
      "title": "Layer-wise Regularized Dropout for Neural Language Models",
      "title_zh": "层级正则化 Dropout 用于神经语言模型",
      "authors": [
        "Shiwen Ni",
        "Min Yang",
        "Ruifeng Xu",
        "Chengming Li",
        "Xiping Hu"
      ],
      "abstract": "Among the various pre-trained neural language models that are popular today,\ndropout is already an indispensable regularization technique. To solve the\ninconsistency between training and inference caused by the randomness of\ndropout, some studies use consistency training to regularize dropout at the\noutput layer. In this paper, we propose a novel Layer-wise Regularized Dropout\n(LR-Drop), which is specially designed for Transformer-based Language models.\nSpecifically, LR-Drop layer-wise regularizes each Transformer layer using the\nconsistency training strategy. Each training sample passes through the two\nsiamese sub-models sampled by dropout, and then LR-Drop forces the hidden\nstates, multi-head attention matrices, and output distribution of the two\nsiamese sub-models to be consistent. The proposed LR-Drop can be regarded as a\n\"self-distillation\" framework, in which each sub-model generated by dropout is\nthe other's \"teacher\" model and \"student\" model. Through extensive experiments\non 8 natural language understanding datasets, 6 neural machine translation\ndatasets, and 1 abstractive summarization dataset (a total of 15 datasets), we\nshow that LR-Drop achieves superior performances, including state-of-the-art\nresults.",
      "tldr_zh": "本文提出了一种新型正则化技术Layer-wise Regularized Dropout (LR-Drop)，专门针对Transformer-based Language Models，以解决dropout随机性导致的训练和推理不一致问题。LR-Drop在每个Transformer层应用一致性训练策略，通过两个由dropout采样的孪生子模型，强制它们的隐藏状态、多头注意力矩阵和输出分布保持一致，并将其视为一个“self-distillation”框架，其中子模型互为教师和学生。实验结果显示，LR-Drop在8个自然语言理解数据集、6个神经机器翻译数据集和1个抽象摘要数据集（共15个数据集）上取得了优越性能，包括state-of-the-art结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16361v1",
      "published_date": "2024-02-26 07:31:35 UTC",
      "updated_date": "2024-02-26 07:31:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:19:54.787636"
    },
    {
      "arxiv_id": "2402.16359v3",
      "title": "Feedback Efficient Online Fine-Tuning of Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Masatoshi Uehara",
        "Yulai Zhao",
        "Kevin Black",
        "Ehsan Hajiramezanali",
        "Gabriele Scalia",
        "Nathaniel Lee Diamant",
        "Alex M Tseng",
        "Sergey Levine",
        "Tommaso Biancalani"
      ],
      "abstract": "Diffusion models excel at modeling complex data distributions, including\nthose of images, proteins, and small molecules. However, in many cases, our\ngoal is to model parts of the distribution that maximize certain properties:\nfor example, we may want to generate images with high aesthetic quality, or\nmolecules with high bioactivity. It is natural to frame this as a reinforcement\nlearning (RL) problem, in which the objective is to fine-tune a diffusion model\nto maximize a reward function that corresponds to some property. Even with\naccess to online queries of the ground-truth reward function, efficiently\ndiscovering high-reward samples can be challenging: they might have a low\nprobability in the initial distribution, and there might be many infeasible\nsamples that do not even have a well-defined reward (e.g., unnatural images or\nphysically impossible molecules). In this work, we propose a novel\nreinforcement learning procedure that efficiently explores on the manifold of\nfeasible samples. We present a theoretical analysis providing a regret\nguarantee, as well as empirical validation across three domains: images,\nbiological sequences, and molecules.",
      "tldr_zh": "这篇论文提出了一种高效的强化学习（reinforcement learning）方法，用于在线微调 diffusion models，以最大化特定属性的数据分布，例如高美学质量的图像或高生物活性的分子。方法通过专注于可行样本的流形探索，解决了高奖励样本在初始分布中概率低以及不可行样本的问题，并提供了 regret guarantee 的理论分析。实证验证显示，该方法在图像、生物序列和分子领域表现出色，显著提升了微调效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16359v3",
      "published_date": "2024-02-26 07:24:32 UTC",
      "updated_date": "2024-07-18 08:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:20:07.382936"
    },
    {
      "arxiv_id": "2402.16354v2",
      "title": "Language-guided Skill Learning with Temporal Variational Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Fu",
        "Pratyusha Sharma",
        "Elias Stengel-Eskin",
        "George Konidaris",
        "Nicolas Le Roux",
        "Marc-Alexandre Côté",
        "Xingdi Yuan"
      ],
      "abstract": "We present an algorithm for skill discovery from expert demonstrations. The\nalgorithm first utilizes Large Language Models (LLMs) to propose an initial\nsegmentation of the trajectories. Following that, a hierarchical variational\ninference framework incorporates the LLM-generated segmentation information to\ndiscover reusable skills by merging trajectory segments. To further control the\ntrade-off between compression and reusability, we introduce a novel auxiliary\nobjective based on the Minimum Description Length principle that helps guide\nthis skill discovery process. Our results demonstrate that agents equipped with\nour method are able to discover skills that help accelerate learning and\noutperform baseline skill learning approaches on new long-horizon tasks in\nBabyAI, a grid world navigation environment, as well as ALFRED, a household\nsimulation environment.",
      "tldr_zh": "这篇论文提出了一种基于语言引导的技能学习算法，使用 Temporal Variational Inference，从专家演示中发现可重用的技能。算法首先利用 Large Language Models (LLMs) 对轨迹进行初始分割，然后通过分层变分推理框架整合这些分割信息来合并轨迹段。作者引入了一个基于 Minimum Description Length 原则的辅助目标，以平衡技能的压缩程度和可重用性。实验结果显示，该方法使代理在 BabyAI 和 ALFRED 环境中加速学习新任务，并优于基线技能学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16354v2",
      "published_date": "2024-02-26 07:19:23 UTC",
      "updated_date": "2024-05-27 14:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:20:19.783572"
    },
    {
      "arxiv_id": "2402.16352v2",
      "title": "MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs",
      "title_zh": "MathGenie：利用问题回译生成合成数据以增强LLMs的数学推理",
      "authors": [
        "Zimu Lu",
        "Aojun Zhou",
        "Houxing Ren",
        "Ke Wang",
        "Weikang Shi",
        "Junting Pan",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "abstract": "Large language models (LLMs) have exhibited great potential in mathematical\nreasoning. However, there remains a performance gap in this area between\nexisting open-source models and closed-source models such as GPT-4. In this\npaper, we introduce MathGenie, a novel method for generating diverse and\nreliable math problems from a small-scale problem-solution dataset (denoted as\nseed data). We augment the ground-truth solutions of our seed data and train a\nback-translation model to translate the augmented solutions back into new\nquestions. Subsequently, we generate code-integrated solutions for the new\nquestions. To ensure the correctness of the code-integrated solutions, we\nemploy rationale-based strategy for solution verification. Various pretrained\nmodels, ranging from 7B to 70B, are trained on the newly curated data to test\nthe effectiveness of the proposed augmentation technique, resulting in a family\nof models known as MathGenieLM. These models consistently outperform previous\nopen-source models across five representative mathematical reasoning datasets,\nachieving state-of-the-art performance. In particular, MathGenieLM-InternLM2\nachieves an accuracy of 87.7% on GSM8K and 55.7% on MATH, securing the best\noverall score among open-source language models.",
      "tldr_zh": "本论文提出了 MathGenie 方法，通过问题回译（Question Back-translation）从小型种子数据集生成多样且可靠的数学问题，从而增强 LLMs 的数学推理能力。具体而言，该方法包括增强原始解决方案、训练回译模型生成新问题、创建代码集成解决方案，并采用基于理据的策略进行验证。实验结果显示，训练得到的 MathGenieLM 模型系列（如 MathGenieLM-InternLM2）在五个代表性数据集上超越了现有开源模型，实现了最先进性能，例如在 GSM8K 上达到87.7%准确率，在 MATH 上达到55.7%。这为提升开源 LLMs 的数学能力提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2402.16352v2",
      "published_date": "2024-02-26 07:17:25 UTC",
      "updated_date": "2024-09-11 08:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:20:31.669924"
    },
    {
      "arxiv_id": "2402.16342v1",
      "title": "Contingency Planning Using Bi-level Markov Decision Processes for Space Missions",
      "title_zh": "翻译失败",
      "authors": [
        "Somrita Banerjee",
        "Edward Balaban",
        "Mark Shirley",
        "Kevin Bradner",
        "Marco Pavone"
      ],
      "abstract": "This work focuses on autonomous contingency planning for scientific missions\nby enabling rapid policy computation from any off-nominal point in the state\nspace in the event of a delay or deviation from the nominal mission plan.\nSuccessful contingency planning involves managing risks and rewards, often\nprobabilistically associated with actions, in stochastic scenarios. Markov\nDecision Processes (MDPs) are used to mathematically model decision-making in\nsuch scenarios. However, in the specific case of planetary rover traverse\nplanning, the vast action space and long planning time horizon pose\ncomputational challenges. A bi-level MDP framework is proposed to improve\ncomputational tractability, while also aligning with existing mission planning\npractices and enhancing explainability and trustworthiness of AI-driven\nsolutions. We discuss the conversion of a mission planning MDP into a bi-level\nMDP, and test the framework on RoverGridWorld, a modified GridWorld environment\nfor rover mission planning. We demonstrate the computational tractability and\nnear-optimal policies achievable with the bi-level MDP approach, highlighting\nthe trade-offs between compute time and policy optimality as the problem's\ncomplexity grows. This work facilitates more efficient and flexible contingency\nplanning in the context of scientific missions.",
      "tldr_zh": "本研究针对空间任务的自主应急规划问题，提出使用Bi-level Markov Decision Processes (MDPs)框架，以快速从任何非正常状态计算策略，解决传统MDPs在行星探测器路径规划中面临的计算挑战，如庞大行动空间和长规划时间。该框架通过分层结构优化决策过程，同时提升AI解决方案的可解释性和可信度，并与现有任务规划实践兼容。在RoverGridWorld测试环境中，实验证明了bi-level MDP的计算可行性，能够生成接近最优策略，同时揭示了计算时间与策略最优性之间的权衡，从而促进科学任务中更高效、灵活的应急规划。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16342v1",
      "published_date": "2024-02-26 06:42:30 UTC",
      "updated_date": "2024-02-26 06:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:20:44.030495"
    },
    {
      "arxiv_id": "2402.16321v1",
      "title": "Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Szu-Wei Fu",
        "Kuo-Hsuan Hung",
        "Yu Tsao",
        "Yu-Chiang Frank Wang"
      ],
      "abstract": "Speech quality estimation has recently undergone a paradigm shift from\nhuman-hearing expert designs to machine-learning models. However, current\nmodels rely mainly on supervised learning, which is time-consuming and\nexpensive for label collection. To solve this problem, we propose VQScore, a\nself-supervised metric for evaluating speech based on the quantization error of\na vector-quantized-variational autoencoder (VQ-VAE). The training of VQ-VAE\nrelies on clean speech; hence, large quantization errors can be expected when\nthe speech is distorted. To further improve correlation with real quality\nscores, domain knowledge of speech processing is incorporated into the model\ndesign. We found that the vector quantization mechanism could also be used for\nself-supervised speech enhancement (SE) model training. To improve the\nrobustness of the encoder for SE, a novel self-distillation mechanism combined\nwith adversarial training is introduced. In summary, the proposed speech\nquality estimation method and enhancement models require only clean speech for\ntraining without any label requirements. Experimental results show that the\nproposed VQScore and enhancement model are competitive with supervised\nbaselines. The code will be released after publication.",
      "tldr_zh": "本文提出 VQScore，一种自监督的语音质量评估方法，仅使用干净语音训练，通过 vector-quantized-variational autoencoder (VQ-VAE) 的量化误差来衡量语音失真，并整合语音处理领域知识以提高与真实质量分数的相关性。作者发现 VQ-VAE 的向量量化机制可扩展到自监督语音增强 (SE) 模型训练中，并引入自蒸馏机制结合对抗训练来提升编码器的鲁棒性。该方法无需任何标签，实验结果显示 VQScore 和增强模型的表现与监督基线相当。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16321v1",
      "published_date": "2024-02-26 06:01:38 UTC",
      "updated_date": "2024-02-26 06:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:20:56.582708"
    },
    {
      "arxiv_id": "2402.16313v3",
      "title": "Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxu Tao",
        "Dongyan Zhao",
        "Yansong Feng"
      ],
      "abstract": "Open-ended question answering requires models to find appropriate evidence to\nform wellreasoned, comprehensive and helpful answers. In practical\napplications, models also need to engage in extended discussions on potential\nscenarios closely relevant to the question. With augmentation of retrieval\nmodule, open-source Large Language Models (LLMs) can produce coherent answers\noften with different focuses, but are still sub-optimal in terms of reliable\nevidence selection and in-depth question analysis. In this paper, we propose a\nnovel Chain-ofDiscussion framework to leverage the synergy among multiple\nopen-source LLMs aiming to provide more correct and more comprehensive answers\nfor open-ended QA, although they are not strong enough individually. Our\nexperiments show that discussions among multiple LLMs play a vital role in\nenhancing the quality of answers.",
      "tldr_zh": "这篇论文提出了 Chain-of-Discussion 框架，一个多模型系统，旨在通过多个开源 Large Language Models (LLMs) 的协同讨论，提供更准确和全面的开放式问答答案。框架针对复杂证据-based 问答问题，强调证据选择和深度分析的优化，利用检索模块增强和讨论机制来弥补单个 LLM 的不足。实验结果显示，这种多 LLM 讨论方法显著提升了答案的质量和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.16313v3",
      "published_date": "2024-02-26 05:31:34 UTC",
      "updated_date": "2024-12-16 07:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:21:07.877928"
    },
    {
      "arxiv_id": "2402.16312v1",
      "title": "Federated Contextual Cascading Bandits with Asynchronous Communication and Heterogeneous Users",
      "title_zh": "联邦上下文级联多臂老虎机，带有异步通信和异构用户",
      "authors": [
        "Hantao Yang",
        "Xutong Liu",
        "Zhiyong Wang",
        "Hong Xie",
        "John C. S. Lui",
        "Defu Lian",
        "Enhong Chen"
      ],
      "abstract": "We study the problem of federated contextual combinatorial cascading bandits,\nwhere $|\\mathcal{U}|$ agents collaborate under the coordination of a central\nserver to provide tailored recommendations to the $|\\mathcal{U}|$ corresponding\nusers. Existing works consider either a synchronous framework, necessitating\nfull agent participation and global synchronization, or assume user homogeneity\nwith identical behaviors. We overcome these limitations by considering (1)\nfederated agents operating in an asynchronous communication paradigm, where no\nmandatory synchronization is required and all agents communicate independently\nwith the server, (2) heterogeneous user behaviors, where users can be\nstratified into $J \\le |\\mathcal{U}|$ latent user clusters, each exhibiting\ndistinct preferences. For this setting, we propose a UCB-type algorithm with\ndelicate communication protocols. Through theoretical analysis, we give\nsub-linear regret bounds on par with those achieved in the synchronous\nframework, while incurring only logarithmic communication costs. Empirical\nevaluation on synthetic and real-world datasets validates our algorithm's\nsuperior performance in terms of regrets and communication costs.",
      "tldr_zh": "我们研究了Federated Contextual Cascading Bandits问题，其中多个代理在中央服务器协调下，为异质用户提供个性化推荐，克服了现有同步框架和用户同质假设的局限。提出了一种UCB-type算法，结合精细的异步通信协议，允许代理独立与服务器通信，并将用户分为潜在集群以处理不同偏好。通过理论分析，该算法实现了与同步框架相当的sub-linear regret bounds，同时通信成本仅为对数级别。在合成和真实数据集上的实证评估证明了其在遗憾和通信效率方面的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16312v1",
      "published_date": "2024-02-26 05:31:14 UTC",
      "updated_date": "2024-02-26 05:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:21:19.758044"
    },
    {
      "arxiv_id": "2402.16311v3",
      "title": "Cross-domain Chinese Sentence Pattern Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Jingsi Yu",
        "Cunliang Kong",
        "Liner Yang",
        "Meishan Zhang",
        "Lin Zhu",
        "Yujie Wang",
        "Haozhe Lin",
        "Maosong Sun",
        "Erhong Yang"
      ],
      "abstract": "Sentence Pattern Structure (SPS) parsing is a syntactic analysis method\nprimarily employed in language teaching.Existing SPS parsers rely heavily on\ntextbook corpora for training, lacking cross-domain capability.To overcome this\nconstraint, this paper proposes an innovative approach leveraging large\nlanguage models (LLMs) within a self-training framework. Partial syntactic\nrules from a source domain are combined with target domain sentences to\ndynamically generate training data, enhancing the adaptability of the parser to\ndiverse domains.Experiments conducted on textbook and news domains demonstrate\nthe effectiveness of the proposed method, outperforming rule-based baselines by\n1.68 points on F1 metrics.",
      "tldr_zh": "本研究针对 Sentence Pattern Structure (SPS) 解析在语言教学中的应用，提出了一种基于大型语言模型 (LLMs) 的自训练框架，以解决现有解析器依赖教科书语料并缺乏跨领域能力的局限性。该方法通过将源领域的部分句法规则与目标领域句子结合，动态生成训练数据，从而提升解析器的适应性和泛化能力。在教科书和新闻领域的实验中，该框架在 F1 指标上比基于规则的基线方法提高了 1.68 点，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16311v3",
      "published_date": "2024-02-26 05:30:48 UTC",
      "updated_date": "2024-04-08 03:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:21:31.511236"
    },
    {
      "arxiv_id": "2402.16310v4",
      "title": "REPLAY: Modeling Time-Varying Temporal Regularities of Human Mobility for Location Prediction over Sparse Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Bangchao Deng",
        "Bingqing Qu",
        "Pengyang Wang",
        "Dingqi Yang",
        "Benjamin Fankhauser",
        "Philippe Cudre-Mauroux"
      ],
      "abstract": "Location prediction forecasts a user's location based on historical user\nmobility traces. To tackle the intrinsic sparsity issue of real-world user\nmobility traces, spatiotemporal contexts have been shown as significantly\nuseful. Existing solutions mostly incorporate spatiotemporal distances between\nlocations in mobility traces, either by feeding them as additional inputs to\nRecurrent Neural Networks (RNNs) or by using them to search for informative\npast hidden states for prediction. However, such distance-based methods fail to\ncapture the time-varying temporal regularities of human mobility, where human\nmobility is often more regular in the morning than in other periods, for\nexample; this suggests the usefulness of the actual timestamps besides the\ntemporal distances. Against this background, we propose REPLAY, a general RNN\narchitecture learning to capture the time-varying temporal regularities for\nlocation prediction. Specifically, REPLAY not only resorts to the\nspatiotemporal distances in sparse trajectories to search for the informative\npast hidden states, but also accommodates the time-varying temporal\nregularities by incorporating smoothed timestamp embeddings using Gaussian\nweighted averaging with timestamp-specific learnable bandwidths, which can\nflexibly adapt to the temporal regularities of different strengths across\ndifferent timestamps. Our extensive evaluation compares REPLAY against a\nsizable collection of state-of-the-art techniques on two real-world datasets.\nResults show that REPLAY consistently and significantly outperforms\nstate-of-the-art methods by 7.7\\%-10.5\\% in the location prediction task, and\nthe bandwidths reveal interesting patterns of the time-varying temporal\nregularities.",
      "tldr_zh": "该论文提出 REPLAY，一种基于 RNN 的通用架构，用于处理稀疏用户移动轨迹的位置预测问题，通过捕捉时间变化的 temporal regularities（时序规律）来提升预测准确性。REPLAY 不仅利用 spatiotemporal distances（时空距离）来搜索信息丰富的过去隐藏状态，还通过高斯加权平均（Gaussian weighted averaging）结合时间戳特定可学习带宽来平滑时间戳嵌入，从而适应不同时间戳的时序规律强度。在两个真实数据集上的广泛实验表明，REPLAY 比现有最先进方法提高了 7.7% 到 10.5% 的预测性能，并揭示了时序规律的模式，为用户移动建模提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Transactions on Mobile Computing",
      "pdf_url": "http://arxiv.org/pdf/2402.16310v4",
      "published_date": "2024-02-26 05:28:36 UTC",
      "updated_date": "2025-05-05 01:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:21:43.630652"
    },
    {
      "arxiv_id": "2402.16305v1",
      "title": "Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion",
      "title_zh": "翻译失败",
      "authors": [
        "Xuantong Liu",
        "Tianyang Hu",
        "Wenjia Wang",
        "Kenji Kawaguchi",
        "Yuan Yao"
      ],
      "abstract": "As a dominant force in text-to-image generation tasks, Diffusion\nProbabilistic Models (DPMs) face a critical challenge in controllability,\nstruggling to adhere strictly to complex, multi-faceted instructions. In this\nwork, we aim to address this alignment challenge for conditional generation\ntasks. First, we provide an alternative view of state-of-the-art DPMs as a way\nof inverting advanced Vision-Language Models (VLMs). With this formulation, we\nnaturally propose a training-free approach that bypasses the conventional\nsampling process associated with DPMs. By directly optimizing images with the\nsupervision of discriminative VLMs, the proposed method can potentially achieve\na better text-image alignment. As proof of concept, we demonstrate the pipeline\nwith the pre-trained BLIP-2 model and identify several key designs for improved\nimage generation. To further enhance the image fidelity, a Score Distillation\nSampling module of Stable Diffusion is incorporated. By carefully balancing the\ntwo components during optimization, our method can produce high-quality images\nwith near state-of-the-art performance on T2I-Compbench.",
      "tldr_zh": "该研究提出了一种基于模型逆运算（Model Inversion）的替代方法，用于提升条件生成任务中的文本到图像（T2I）对齐性，解决Diffusion Probabilistic Models (DPMs) 在处理复杂指令时的控制性挑战。方法通过将先进的Vision-Language Models (VLMs)视为DPMs的逆过程，实现训练-free的图像优化，直接在VLMs的监督下生成图像，并整合Stable Diffusion的Score Distillation Sampling模块以提高图像保真度。实验结果显示，通过平衡这些组件，该方法在T2I-Compbench基准上达到了接近最先进水平的性能，为更精确的文本图像生成提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16305v1",
      "published_date": "2024-02-26 05:08:40 UTC",
      "updated_date": "2024-02-26 05:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:21:55.118099"
    },
    {
      "arxiv_id": "2402.16302v2",
      "title": "Graph Diffusion Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yijing Liu",
        "Chao Du",
        "Tianyu Pang",
        "Chongxuan Li",
        "Min Lin",
        "Wei Chen"
      ],
      "abstract": "Recent research has made significant progress in optimizing diffusion models\nfor downstream objectives, which is an important pursuit in fields such as\ngraph generation for drug design. However, directly applying these models to\ngraph presents challenges, resulting in suboptimal performance. This paper\nintroduces graph diffusion policy optimization (GDPO), a novel approach to\noptimize graph diffusion models for arbitrary (e.g., non-differentiable)\nobjectives using reinforcement learning. GDPO is based on an eager policy\ngradient tailored for graph diffusion models, developed through meticulous\nanalysis and promising improved performance. Experimental results show that\nGDPO achieves state-of-the-art performance in various graph generation tasks\nwith complex and diverse objectives. Code is available at\nhttps://github.com/sail-sg/GDPO.",
      "tldr_zh": "这篇论文提出了 Graph Diffusion Policy Optimization (GDPO)，一种新方法，使用强化学习优化图扩散模型，以处理任意（如非微分）目标在图生成任务中的挑战。GDPO 基于为图扩散模型量身定制的 eager policy gradient，通过仔细分析实现性能提升。实验结果显示，GDPO 在各种复杂多样的图生成任务中（如药物设计）达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.16302v2",
      "published_date": "2024-02-26 04:58:42 UTC",
      "updated_date": "2024-10-25 15:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:22:07.140112"
    },
    {
      "arxiv_id": "2402.16298v1",
      "title": "MV-Swin-T: Mammogram Classification with Multi-view Swin Transformer",
      "title_zh": "MV-Swin-T：多视图 Swin Transformer 的乳腺X光片分类",
      "authors": [
        "Sushmita Sarker",
        "Prithul Sarker",
        "George Bebis",
        "Alireza Tavakkoli"
      ],
      "abstract": "Traditional deep learning approaches for breast cancer classification has\npredominantly concentrated on single-view analysis. In clinical practice,\nhowever, radiologists concurrently examine all views within a mammography exam,\nleveraging the inherent correlations in these views to effectively detect\ntumors. Acknowledging the significance of multi-view analysis, some studies\nhave introduced methods that independently process mammogram views, either\nthrough distinct convolutional branches or simple fusion strategies,\ninadvertently leading to a loss of crucial inter-view correlations. In this\npaper, we propose an innovative multi-view network exclusively based on\ntransformers to address challenges in mammographic image classification. Our\napproach introduces a novel shifted window-based dynamic attention block,\nfacilitating the effective integration of multi-view information and promoting\nthe coherent transfer of this information between views at the spatial feature\nmap level. Furthermore, we conduct a comprehensive comparative analysis of the\nperformance and effectiveness of transformer-based models under diverse\nsettings, employing the CBIS-DDSM and Vin-Dr Mammo datasets. Our code is\npublicly available at https://github.com/prithuls/MV-Swin-T",
      "tldr_zh": "本文提出 MV-Swin-T，一种基于 Swin Transformer 的多视图网络，用于改进乳腺癌乳房 X 光图像分类，解决传统方法忽略多视图间相关性的问题。该网络引入了 shifted window-based dynamic attention block，能够有效整合多视图信息，并在空间特征图级别促进信息传输。实验在 CBIS-DDSM 和 Vin-Dr Mammo 数据集上进行全面比较分析，展示了其优越性能，并提供了公开代码以便复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16298v1",
      "published_date": "2024-02-26 04:41:04 UTC",
      "updated_date": "2024-02-26 04:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:22:19.707120"
    },
    {
      "arxiv_id": "2402.16297v2",
      "title": "A Poisson-Gamma Dynamic Factor Model with Time-Varying Transition Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Wang",
        "Sikun Yang",
        "Heinz Koeppl",
        "Xiuzhen Cheng",
        "Pengfei Hu",
        "Guoming Zhang"
      ],
      "abstract": "Probabilistic approaches for handling count-valued time sequences have\nattracted amounts of research attentions because their ability to infer\nexplainable latent structures and to estimate uncertainties, and thus are\nespecially suitable for dealing with \\emph{noisy} and \\emph{incomplete} count\ndata. Among these models, Poisson-Gamma Dynamical Systems (PGDSs) are proven to\nbe effective in capturing the evolving dynamics underlying observed count\nsequences. However, the state-of-the-art PGDS still fails to capture the\n\\emph{time-varying} transition dynamics that are commonly observed in\nreal-world count time sequences. To mitigate this gap, a non-stationary PGDS is\nproposed to allow the underlying transition matrices to evolve over time, and\nthe evolving transition matrices are modeled by sophisticatedly-designed\nDirichlet Markov chains. Leveraging Dirichlet-Multinomial-Beta data\naugmentation techniques, a fully-conjugate and efficient Gibbs sampler is\ndeveloped to perform posterior simulation. Experiments show that, in comparison\nwith related models, the proposed non-stationary PGDS achieves improved\npredictive performance due to its capacity to learn non-stationary dependency\nstructure captured by the time-evolving transition matrices.",
      "tldr_zh": "这篇论文提出了一种非平稳的 Poisson-Gamma Dynamical Systems (PGDS)，旨在处理计数序列中常见的 time-varying transition dynamics，从而解决现有模型在捕捉动态变化方面的不足。方法包括使用 Dirichlet Markov chains 建模随时间演化的过渡矩阵，并通过 Dirichlet-Multinomial-Beta 数据增强技术开发一个高效的 fully-conjugate Gibbs sampler 进行后验模拟。实验结果表明，该模型在预测性能上优于相关模型，因为它能有效学习非平稳依赖结构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16297v2",
      "published_date": "2024-02-26 04:39:01 UTC",
      "updated_date": "2024-05-23 07:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:22:31.483711"
    },
    {
      "arxiv_id": "2402.16294v2",
      "title": "BlockFUL: Enabling Unlearning in Blockchained Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Mingyuan Li",
        "Xu Wang",
        "Guangsheng Yu",
        "Wei Ni",
        "Lixiang Li",
        "Haipeng Peng",
        "Renping Liu"
      ],
      "abstract": "Unlearning in Federated Learning (FL) presents significant challenges, as\nmodels grow and evolve with complex inheritance relationships. This complexity\nis amplified when blockchain is employed to ensure the integrity and\ntraceability of FL, where the need to edit multiple interlinked blockchain\nrecords and update all inherited models complicates the process.In this paper,\nwe introduce Blockchained Federated Unlearning (BlockFUL), a novel framework\nwith a dual-chain structure comprising a live chain and an archive chain for\nenabling unlearning capabilities within Blockchained FL. BlockFUL introduces\ntwo new unlearning paradigms, i.e., parallel and sequential paradigms, which\ncan be effectively implemented through gradient-ascent-based and\nre-training-based unlearning methods. These methods enhance the unlearning\nprocess across multiple inherited models by enabling efficient consensus\noperations and reducing computational costs. Our extensive experiments validate\nthat these methods effectively reduce data dependency and operational overhead,\nthereby boosting the overall performance of unlearning inherited models within\nBlockFUL on CIFAR-10 and Fashion-MNIST datasets using AlexNet, ResNet18, and\nMobileNetV2 models.",
      "tldr_zh": "这篇论文提出了 BlockFUL 框架，一种用于 Blockchained Federated Learning 中的 Unlearning 机制，采用双链结构（live chain 和 archive chain）来处理模型继承关系的复杂性。BlockFUL 引入了两种新范式：parallel 和 sequential 范式，通过 gradient-ascent-based 和 re-training-based 方法，实现高效的共识操作和计算成本降低。实验在 CIFAR-10 和 Fashion-MNIST 数据集上使用 AlexNet、ResNet18 和 MobileNetV2 模型验证了该框架，能有效减少数据依赖和操作开销，提升 Unlearning 的整体性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16294v2",
      "published_date": "2024-02-26 04:31:53 UTC",
      "updated_date": "2024-08-14 10:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:22:44.932061"
    },
    {
      "arxiv_id": "2402.16288v1",
      "title": "PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Du",
        "Hongru Wang",
        "Zhengyi Zhao",
        "Bin Liang",
        "Baojun Wang",
        "Wanjun Zhong",
        "Zezhong Wang",
        "Kam-Fai Wong"
      ],
      "abstract": "Long-term memory plays a critical role in personal interaction, considering\nlong-term memory can better leverage world knowledge, historical information,\nand preferences in dialogues. Our research introduces PerLTQA, an innovative QA\ndataset that combines semantic and episodic memories, including world\nknowledge, profiles, social relationships, events, and dialogues. This dataset\nis collected to investigate the use of personalized memories, focusing on\nsocial interactions and events in the QA task. PerLTQA features two types of\nmemory and a comprehensive benchmark of 8,593 questions for 30 characters,\nfacilitating the exploration and application of personalized memories in Large\nLanguage Models (LLMs). Based on PerLTQA, we propose a novel framework for\nmemory integration and generation, consisting of three main components: Memory\nClassification, Memory Retrieval, and Memory Synthesis. We evaluate this\nframework using five LLMs and three retrievers. Experimental results\ndemonstrate that BERT-based classification models significantly outperform LLMs\nsuch as ChatGLM3 and ChatGPT in the memory classification task. Furthermore,\nour study highlights the importance of effective memory integration in the QA\ntask.",
      "tldr_zh": "该研究引入了 PerLTQA，这是一个创新的 QA 数据集，结合语义和情节记忆（如世界知识、个人资料、社会关系、事件和对话），用于调查个性化记忆在问答任务中的应用，并提供针对 30 个角色的 8,593 个问题基准。论文提出一个新框架，包括 Memory Classification、Memory Retrieval 和 Memory Synthesis 的组件，以实现记忆的整合和生成。实验结果显示，BERT-based 分类模型在 Memory Classification 任务中优于 ChatGLM3 和 ChatGPT 等 LLMs，并突出了有效记忆整合对提升 QA 性能的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16288v1",
      "published_date": "2024-02-26 04:09:53 UTC",
      "updated_date": "2024-02-26 04:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:22:56.027926"
    },
    {
      "arxiv_id": "2402.16281v2",
      "title": "RobKiNet: Robotic Kinematics Informed Neural Network for Optimal Robot Configuration Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlong Peng",
        "Zhigang Wang",
        "Yisheng Zhang",
        "Pengxu Chang",
        "Ziwen He",
        "Kai Gu",
        "Hongshen Zhang",
        "Ming Chen"
      ],
      "abstract": "Task and Motion Planning (TAMP) is essential for robots to interact with the\nworld and accomplish complex tasks. The TAMP problem involves a critical gap:\nexploring the robot's configuration parameters (such as chassis position and\nrobotic arm joint angles) within continuous space to ensure that task-level\nglobal constraints are met while also enhancing the efficiency of subsequent\nmotion planning. Existing methods still have significant room for improvement\nin terms of efficiency. Recognizing that robot kinematics is a key factor in\nmotion planning, we propose a framework called the Robotic Kinematics Informed\nNeural Network (RobKiNet) as a bridge between task and motion layers. RobKiNet\nintegrates kinematic knowledge into neural networks to train models capable of\nefficient configuration prediction. We designed a Chassis Motion Predictor(CMP)\nand a Full Motion Predictor(FMP) using RobKiNet, which employed two entirely\ndifferent sets of forward and inverse kinematics constraints to achieve loosely\ncoupled control and whole-body control, respectively. Experiments demonstrate\nthat CMP and FMP can predict configuration parameters with 96.67% and 98%\naccuracy, respectively. That means that the corresponding motion planning can\nachieve a speedup of 24.24x and 153x compared to random sampling. Furthermore,\nRobKiNet demonstrates remarkable data efficiency. CMP only requires 1/71 and\nFMP only requires 1/15052 of the training data for the same prediction accuracy\ncompared to other deep learning methods. These results demonstrate the great\npotential of RoboKiNet in robot applications.",
      "tldr_zh": "该论文针对 Task and Motion Planning (TAMP) 中机器人配置参数预测的效率问题，提出 Robotic Kinematics Informed Neural Network (RobKiNet) 框架，将运动学知识整合到神经网络中，作为任务层和运动层的桥梁。框架设计了 Chassis Motion Predictor (CMP) 和 Full Motion Predictor (FMP)，分别使用不同的正向和逆向运动学约束，实现松耦合控制和全身体控制。实验结果显示，CMP 和 FMP 的预测准确率分别为96.67% 和98%，比随机采样加速24.24倍和153倍，且数据效率显著提升，仅需传统深度学习方法的1/71和1/15052的数据量。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16281v2",
      "published_date": "2024-02-26 03:54:32 UTC",
      "updated_date": "2025-03-04 07:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:23:09.193758"
    },
    {
      "arxiv_id": "2402.16278v3",
      "title": "A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction",
      "title_zh": "一种结合注释嵌入模型的自匹配训练方法，用于本体子类预测",
      "authors": [
        "Yukihiro Shiraishi",
        "Ken Kaneiwa"
      ],
      "abstract": "Recently, ontology embeddings representing entities in a low-dimensional\nspace have been proposed for ontology completion. However, the ontology\nembeddings for concept subsumption prediction do not address the difficulties\nof similar and isolated entities and fail to extract the global information of\nannotation axioms from an ontology. In this paper, we propose a self-matching\ntraining method for the two ontology embedding models: Inverted-index Matrix\nEmbedding (InME) and Co-occurrence Matrix Embedding (CoME). The two embeddings\ncapture the global and local information in annotation axioms by means of the\noccurring locations of each word in a set of axioms and the co-occurrences of\nwords in each axiom. The self-matching training method increases the robustness\nof the concept subsumption prediction when predicted superclasses are similar\nto subclasses and are isolated to other entities in an ontology. Our evaluation\nexperiments show that the self-matching training method with InME outperforms\nthe existing ontology embeddings for the GO and FoodOn ontologies and that the\nmethod with the concatenation of CoME and OWL2Vec* outperforms them for the\nHeLiS ontology.",
      "tldr_zh": "本文提出了一种自匹配训练方法（self-matching training method），用于提升本体嵌入模型（ontology embeddings）在概念包含预测（concept subsumption prediction）中的性能，特别针对相似和孤立实体以及注释公理全局信息的提取问题。该方法应用于 Inverted-index Matrix Embedding (InME) 和 Co-occurrence Matrix Embedding (CoME)，通过单词在公理集中的出现位置和共现关系来捕获全局和局部信息，从而提高预测的鲁棒性。实验结果表明，该方法结合 InME 在 GO 和 FoodOn 本体上优于现有模型，而与 CoME 和 OWL2Vec* 结合后在 HeLiS 本体上也表现出色。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16278v3",
      "published_date": "2024-02-26 03:46:01 UTC",
      "updated_date": "2024-03-10 10:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:23:21.031216"
    },
    {
      "arxiv_id": "2402.16269v1",
      "title": "From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto",
      "title_zh": "翻译失败",
      "authors": [
        "Segev Wasserkrug",
        "Leonard Boussioux",
        "Dick den Hertog",
        "Farzaneh Mirzazadeh",
        "Ilker Birbil",
        "Jannis Kurtz",
        "Donato Maragno"
      ],
      "abstract": "Significantly simplifying the creation of optimization models for real-world\nbusiness problems has long been a major goal in applying mathematical\noptimization more widely to important business and societal decisions. The\nrecent capabilities of Large Language Models (LLMs) present a timely\nopportunity to achieve this goal. Therefore, we propose research at the\nintersection of LLMs and optimization to create a Decision Optimization CoPilot\n(DOCP) - an AI tool designed to assist any decision maker, interacting in\nnatural language to grasp the business problem, subsequently formulating and\nsolving the corresponding optimization model. This paper outlines our DOCP\nvision and identifies several fundamental requirements for its implementation.\nWe describe the state of the art through a literature survey and experiments\nusing ChatGPT. We show that a) LLMs already provide substantial novel\ncapabilities relevant to a DOCP, and b) major research challenges remain to be\naddressed. We also propose possible research directions to overcome these gaps.\nWe also see this work as a call to action to bring together the LLM and\noptimization communities to pursue our vision, thereby enabling much more\nwidespread improved decision-making.",
      "tldr_zh": "该研究提出了一种愿景，即利用 Large Language Models (LLMs) 来简化真实商业问题的优化模型创建，从而更广泛地应用于决策。该论文介绍了 Decision Optimization CoPilot (DOCP)，一个通过自然语言交互帮助决策者理解问题、制定并解决优化模型的 AI 工具。通过文献综述和 ChatGPT 实验，研究发现 LLMs 已具备相关的新能力，但仍存在重大挑战，如精确性和可靠性问题。作者建议未来的研究方向并呼吁 LLM 和优化社区合作，以推动更有效的决策支持系统。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16269v1",
      "published_date": "2024-02-26 03:10:11 UTC",
      "updated_date": "2024-02-26 03:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:23:31.573013"
    },
    {
      "arxiv_id": "2402.16268v1",
      "title": "Foundation Model Transparency Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Rishi Bommasani",
        "Kevin Klyman",
        "Shayne Longpre",
        "Betty Xiong",
        "Sayash Kapoor",
        "Nestor Maslej",
        "Arvind Narayanan",
        "Percy Liang"
      ],
      "abstract": "Foundation models are critical digital technologies with sweeping societal\nimpact that necessitates transparency. To codify how foundation model\ndevelopers should provide transparency about the development and deployment of\ntheir models, we propose Foundation Model Transparency Reports, drawing upon\nthe transparency reporting practices in social media. While external\ndocumentation of societal harms prompted social media transparency reports, our\nobjective is to institutionalize transparency reporting for foundation models\nwhile the industry is still nascent. To design our reports, we identify 6\ndesign principles given the successes and shortcomings of social media\ntransparency reporting. To further schematize our reports, we draw upon the 100\ntransparency indicators from the Foundation Model Transparency Index. Given\nthese indicators, we measure the extent to which they overlap with the\ntransparency requirements included in six prominent government policies (e.g.,\nthe EU AI Act, the US Executive Order on Safe, Secure, and Trustworthy AI).\nWell-designed transparency reports could reduce compliance costs, in part due\nto overlapping regulatory requirements across different jurisdictions. We\nencourage foundation model developers to regularly publish transparency\nreports, building upon recommendations from the G7 and the White House.",
      "tldr_zh": "本研究提出“Foundation Model Transparency Reports”，旨在为基础模型（foundation models）的开发和部署提供标准化透明报告框架，以应对其社会影响。作者借鉴社交媒体透明报告的经验，制定了6个设计原则，并基于“Foundation Model Transparency Index”的100个透明指标来构建报告结构。研究发现，这些报告能减少合规成本，因为其指标与欧盟AI法案（EU AI Act）和美国AI行政令等六大政策要求存在重叠。最后，作者鼓励基础模型开发者定期发布此类报告，以响应G7和白宫的推荐，促进行业透明度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16268v1",
      "published_date": "2024-02-26 03:09:06 UTC",
      "updated_date": "2024-02-26 03:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:23:43.268817"
    },
    {
      "arxiv_id": "2402.16255v1",
      "title": "Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinqian Chen",
        "Jihua Zhu",
        "Qinghai Zheng",
        "Zhongyu Li",
        "Zhiqiang Tian"
      ],
      "abstract": "Federated learning encounters substantial challenges with heterogeneous data,\nleading to performance degradation and convergence issues. While considerable\nprogress has been achieved in mitigating such an impact, the reliability aspect\nof federated models has been largely disregarded. In this study, we conduct\nextensive experiments to investigate the reliability of both generic and\npersonalized federated models. Our exploration uncovers a significant finding:\n\\textbf{federated models exhibit unreliability when faced with heterogeneous\ndata}, demonstrating poor calibration on in-distribution test data and low\nuncertainty levels on out-of-distribution data. This unreliability is primarily\nattributed to the presence of biased projection heads, which introduce\nmiscalibration into the federated models. Inspired by this observation, we\npropose the \"Assembled Projection Heads\" (APH) method for enhancing the\nreliability of federated models. By treating the existing projection head\nparameters as priors, APH randomly samples multiple initialized parameters of\nprojection heads from the prior and further performs targeted fine-tuning on\nlocally available data under varying learning rates. Such a head ensemble\nintroduces parameter diversity into the deterministic model, eliminating the\nbias and producing reliable predictions via head averaging. We evaluate the\neffectiveness of the proposed APH method across three prominent federated\nbenchmarks. Experimental results validate the efficacy of APH in model\ncalibration and uncertainty estimation. Notably, APH can be seamlessly\nintegrated into various federated approaches but only requires less than 30\\%\nadditional computation cost for 100$\\times$ inferences within large models.",
      "tldr_zh": "本研究探讨了联邦学习（Federated Learning）在异构数据（heterogeneous data）下的可靠性问题，发现现有联邦模型在分布内数据上校准不良，在分布外数据上不确定性（uncertainty）水平低，主要归因于偏置的投影头（projection heads）。为此，提出“Assembled Projection Heads”（APH）方法，该方法将现有投影头参数作为先验，随机采样多个初始化参数，并在本地数据上进行针对性微调和学习率调整，以通过头集成（head ensemble）和平均消除偏置。实验在三个主要联邦基准上验证了APH的有效性，提高了模型校准和不确定性估计，同时仅增加不到30%的计算成本，便于无缝集成到各种联邦方法中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2402.16255v1",
      "published_date": "2024-02-26 02:37:39 UTC",
      "updated_date": "2024-02-26 02:37:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:23:56.541737"
    },
    {
      "arxiv_id": "2402.16248v1",
      "title": "Topic-to-essay generation with knowledge-based content selection",
      "title_zh": "翻译失败",
      "authors": [
        "Jieyong Wang",
        "Chunyao Song",
        "Yihao Wu"
      ],
      "abstract": "The topic-to-essay generation task is a challenging natural language\ngeneration task that aims to generate paragraph-level text with high semantic\ncoherence based on a given set of topic words. Previous work has focused on the\nintroduction of external knowledge, ignoring the insufficient generated text\ndiversity. In order to improve the generation diversity, we propose a novel\ncopy mechanism model with a content selection module that integrates rich\nsemantic knowledge from the language model into the decoder. Furthermore, we\nintroduce the improved prefix tuning method to train the model, enabling it to\nadapt to varying input complexities. In addition, we have contributed a new\nChinese dataset for TEG tasks. Experimental results demonstrate that the\nproposed model can improve the generated text diversity by 35\\% to 59\\%\ncompared to the state-of-the-art method, while maintaining a high level of\ntopic consistency.",
      "tldr_zh": "该论文针对主题到文章生成（topic-to-essay generation）任务，提出了一种新模型，该模型通过copy mechanism和content selection module整合外部知识到解码器中，以提升生成文本的多样性，同时使用改进的prefix tuning方法适应不同输入复杂度。\n此外，论文贡献了一个新的中文数据集，用于TEG任务的训练和评估。\n实验结果表明，与最先进方法相比，该模型将生成文本多样性提高了35%到59%，并保持了高主题一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16248v1",
      "published_date": "2024-02-26 02:14:42 UTC",
      "updated_date": "2024-02-26 02:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:24:09.529173"
    },
    {
      "arxiv_id": "2402.16242v1",
      "title": "HSONet:A Siamese foreground association-driven hard case sample optimization network for high-resolution remote sensing image change detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Tao",
        "Dongsheng Kuang",
        "Zhenyang Huang",
        "Chengli Peng",
        "Haifeng Li"
      ],
      "abstract": "In the later training stages, further improvement of the models ability to\ndetermine changes relies on how well the change detection (CD) model learns\nhard cases; however, there are two additional challenges to learning hard case\nsamples: (1) change labels are limited and tend to pointer only to foreground\ntargets, yet hard case samples are prevalent in the background, which leads to\noptimizing the loss function focusing on the foreground targets and ignoring\nthe background hard cases, which we call imbalance. (2) Complex situations,\nsuch as light shadows, target occlusion, and seasonal changes, induce hard case\nsamples, and in the absence of both supervisory and scene information, it is\ndifficult for the model to learn hard case samples directly to accurately\nobtain the feature representations of the change information, which we call\nmissingness. We propose a Siamese foreground association-driven hard case\nsample optimization network (HSONet). To deal with this imbalance, we propose\nan equilibrium optimization loss function to regulate the optimization focus of\nthe foreground and background, determine the hard case samples through the\ndistribution of the loss values, and introduce dynamic weights in the loss term\nto gradually shift the optimization focus of the loss from the foreground to\nthe background hard cases as the training progresses. To address this\nmissingness, we understand hard case samples with the help of the scene\ncontext, propose the scene-foreground association module, use potential remote\nsensing spatial scene information to model the association between the target\nof interest in the foreground and the related context to obtain scene\nembedding, and apply this information to the feature reinforcement of hard\ncases. Experiments on four public datasets show that HSONet outperforms current\nstate-of-the-art CD methods, particularly in detecting hard case samples.",
      "tldr_zh": "该论文提出HSONet，一种Siamese前台关联驱动的困难样本优化网络，用于高分辨率遥感图像变化检测，旨在解决模型在后期训练中学习困难样本的挑战，包括前景背景不平衡和场景信息缺失问题。HSONet通过引入平衡优化损失函数来动态调整优化焦点，从前景目标逐步转向背景困难样本，并利用场景-前景关联模块基于遥感空间场景信息建模目标与上下文的关联，以增强困难样本的特征表示。实验在四个公共数据集上表明，该方法优于现有最先进的变化检测技术，尤其在检测复杂情况下的困难样本方面。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 figures, 8 tables, 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.16242v1",
      "published_date": "2024-02-26 02:03:08 UTC",
      "updated_date": "2024-02-26 02:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:24:22.071775"
    },
    {
      "arxiv_id": "2402.16237v1",
      "title": "Active Level Set Estimation for Continuous Search Space with Theoretical Guarantee",
      "title_zh": "针对连续搜索空间的主动水平集估计，具有理论保证",
      "authors": [
        "Giang Ngo",
        "Dang Nguyen",
        "Dat Phan-Trong",
        "Sunil Gupta"
      ],
      "abstract": "A common problem encountered in many real-world applications is level set\nestimation where the goal is to determine the region in the function domain\nwhere the function is above or below a given threshold. When the function is\nblack-box and expensive to evaluate, the level sets need to be found in a\nminimum set of function evaluations. Existing methods often assume a discrete\nsearch space with a finite set of data points for function evaluations and\nestimating the level sets. When applied to a continuous search space, these\nmethods often need to first discretize the space which leads to poor results\nwhile needing high computational time. While some methods cater for the\ncontinuous setting, they still lack a proper guarantee for theoretical\nconvergence. To address this problem, we propose a novel algorithm that does\nnot need any discretization and can directly work in continuous search spaces.\nOur method suggests points by constructing an acquisition function that is\ndefined as a measure of confidence of the function being higher or lower than\nthe given threshold. A theoretical analysis for the convergence of the\nalgorithm to an accurate solution is provided. On multiple synthetic and\nreal-world datasets, our algorithm successfully outperforms state-of-the-art\nmethods.",
      "tldr_zh": "该论文解决了水平集估计（level set estimation）问题，即在连续搜索空间中，通过最小函数评估次数找到函数值高于或低于给定阈值的区域。现有方法通常依赖离散化，导致计算效率低下且缺乏理论保证，而该研究提出了一种新型算法，直接在连续搜索空间工作，通过构建一个获取函数（acquisition function）来衡量函数值相对于阈值的置信度，从而建议评估点。该算法提供了严格的理论收敛分析，并在多个合成和真实数据集上，显著优于现有方法，证明了其有效性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16237v1",
      "published_date": "2024-02-26 01:46:56 UTC",
      "updated_date": "2024-02-26 01:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:24:33.064773"
    },
    {
      "arxiv_id": "2402.16235v2",
      "title": "Human-AI Co-Creation of Worked Examples for Programming Classes",
      "title_zh": "人类-AI 共同创建编程课程的已解决示例",
      "authors": [
        "Mohammad Hassany",
        "Peter Brusilovsky",
        "Jiaze Ke",
        "Kamil Akhuseyinoglu",
        "Arun Balajiee Lekshmi Narayanan"
      ],
      "abstract": "Worked examples (solutions to typical programming problems presented as a\nsource code in a certain language and are used to explain the topics from a\nprogramming class) are among the most popular types of learning content in\nprogramming classes. Most approaches and tools for presenting these examples to\nstudents are based on line-by-line explanations of the example code. However,\ninstructors rarely have time to provide line-by-line explanations for a large\nnumber of examples typically used in a programming class. In this paper, we\nexplore and assess a human-AI collaboration approach to authoring worked\nexamples for Java programming. We introduce an authoring system for creating\nJava worked examples that generates a starting version of code explanations and\npresents it to the instructor to edit if necessary.We also present a study that\nassesses the quality of explanations created with this approach",
      "tldr_zh": "本论文探讨了编程课程中 Worked Examples（典型编程问题的代码解决方案）的重要性，但教师难以提供逐行解释。研究提出了一种人类-AI 协作系统，用于创建 Java Worked Examples，该系统自动生成初始代码解释，并允许教师编辑以优化内容。通过评估研究，证明了这种方法能有效提升解释质量，为编程教育提供高效的工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2312.02105",
      "pdf_url": "http://arxiv.org/pdf/2402.16235v2",
      "published_date": "2024-02-26 01:44:24 UTC",
      "updated_date": "2024-02-29 05:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:24:45.076561"
    },
    {
      "arxiv_id": "2402.16230v1",
      "title": "GARNN: An Interpretable Graph Attentive Recurrent Neural Network for Predicting Blood Glucose Levels via Multivariate Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Chengzhe Piao",
        "Taiyu Zhu",
        "Stephanie E Baldeweg",
        "Paul Taylor",
        "Pantelis Georgiou",
        "Jiahao Sun",
        "Jun Wang",
        "Kezhi Li"
      ],
      "abstract": "Accurate prediction of future blood glucose (BG) levels can effectively\nimprove BG management for people living with diabetes, thereby reducing\ncomplications and improving quality of life. The state of the art of BG\nprediction has been achieved by leveraging advanced deep learning methods to\nmodel multi-modal data, i.e., sensor data and self-reported event data,\norganised as multi-variate time series (MTS). However, these methods are mostly\nregarded as ``black boxes'' and not entirely trusted by clinicians and\npatients. In this paper, we propose interpretable graph attentive recurrent\nneural networks (GARNNs) to model MTS, explaining variable contributions via\nsummarizing variable importance and generating feature maps by graph attention\nmechanisms instead of post-hoc analysis. We evaluate GARNNs on four datasets,\nrepresenting diverse clinical scenarios. Upon comparison with twelve\nwell-established baseline methods, GARNNs not only achieve the best prediction\naccuracy but also provide high-quality temporal interpretability, in particular\nfor postprandial glucose levels as a result of corresponding meal intake and\ninsulin injection. These findings underline the potential of GARNN as a robust\ntool for improving diabetes care, bridging the gap between deep learning\ntechnology and real-world healthcare solutions.",
      "tldr_zh": "本研究提出 GARNN（Interpretable Graph Attentive Recurrent Neural Network），一种可解释的图注意力循环神经网络，用于通过多变量时间序列（Multivariate Time Series）预测血糖（BG）水平，以改善糖尿病患者的血糖管理并减少并发症。GARNN 通过图注意力机制（Graph Attention Mechanisms）总结变量重要性和生成特征映射，提供内在解释性，而非依赖事后分析，从而增强模型的可信度。在四个数据集上的实验显示，GARNN 比12个基线方法实现了最佳预测准确性，并为餐后血糖水平（如受进食和胰岛素注射影响）提供高质量的时间可解释性。该方法桥接了深度学习技术和实际医疗应用，具有提升糖尿病护理潜力的重要意义。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16230v1",
      "published_date": "2024-02-26 01:18:53 UTC",
      "updated_date": "2024-02-26 01:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:24:58.853975"
    },
    {
      "arxiv_id": "2403.00816v3",
      "title": "Read and Think: An Efficient Step-wise Multimodal Language Model for Document Understanding and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinxu Zhang"
      ],
      "abstract": "Understanding the contents of multimodal documents is essential to accurately\nextract relevant evidence and use it for reasoning. Existing document\nunderstanding models tend to generate answers with a single word or phrase\ndirectly, ignoring the source document's evidence and lacking interpretability.\nIn this work, we address the lack of step-wise capabilities through data\naugmentation and extension. Specifically, We use Multi-modal Large Language\nModels (MLLMs), which have strong visual understanding and reasoning abilities,\nas data generators to generate step-wise question-and-answer pairs for document\nimages and use a high-performance LLM as the error detector to filter out noisy\ndata. This step-wise data generation pipeline is implemented using both\ntemplate-based and few-shot methods. We then use the generated high-quality\ndata to train a humanized document understanding and reasoning model,\nspecifically designed to solve complex questions that require reasoning or\nmulti-hop question answering, dubbed DocAssistant. Experimental results\ndemonstrate the effectiveness and application value of step-wise generation,\nshowing a 5 improvement on InfoVQA with complex layouts and a 7 improvement on\nChartQA with complex reasoning, compared to directly generated answers. We hope\nour work highlights the potential of synthetic data and encourages further\nexploration of multi-modal document reasoning capabilities.",
      "tldr_zh": "该论文提出了一种高效的逐步多模态语言模型“Read and Think”，旨在提升文档理解和推理能力，通过数据增强解决现有模型直接生成答案而忽略证据来源的问题。具体方法包括使用 Multi-modal Large Language Models (MLLMs) 生成逐步问答对，并结合高性能 LLM 作为错误检测器过滤噪音数据，采用模板-based 和 few-shot 方法来训练名为 DocAssistant 的模型，以处理复杂推理和多跳问答任务。实验结果显示，该模型在 InfoVQA 数据集上提升 5%，在 ChartQA 数据集上提升 7%，证明了逐步生成数据在多模态文档推理中的潜力，并鼓励进一步探索合成数据应用。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.00816v3",
      "published_date": "2024-02-26 01:17:50 UTC",
      "updated_date": "2024-08-14 07:26:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T10:25:10.384061"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 116,
  "processed_papers_count": 116,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T10:25:37.056785"
}