{
  "date": "2024-02-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-22 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态处理和强化学习应用，亮点包括大型语言模型 (LLM) 在代码生成和偏置检测中的创新，以及知名会议如 ICML 和 ICLR 的高质量研究，如 Zhuoyan Xu 的多任务微调和 Wonjeong Choi 的校准策略，这些工作展示了 LLM 在实际场景中的潜力。\n\n### 重点论文讨论\n我将优先讨论那些创新性强、可能引发话题的论文，包括 LLM 优化、偏置和多模态领域的研究。其他次要论文会简要掠过。\n\n**LLM 优化与代码生成**  \n- **tinyBenchmarks: evaluating LLMs with fewer examples** (英文标题：\"tinyBenchmarks: evaluating LLMs with fewer examples\")  \n  这篇论文的主要贡献是提出一种高效评估 LLM 的方法，通过减少样本数量（仅需 100 个样本）评估模型性能，显著降低计算成本。发现这种方法能准确再现基准测试结果，适用于大规模 LLM 评估，如 MMLU 和 HELM。\n\n- **Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning** (英文标题：\"Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning\")  \n  作者 Zhuoyan Xu 等提出多任务微调框架，针对少样本场景优化基础模型。关键发现是，通过任务多样性（diversity 和 consistency 指标），模型在目标任务上显著减少错误，实验在 ICLR 2024 数据集上验证了其有效性。\n\n- **Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning** (英文标题：\"Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning\")  \n  这篇 ACL 2024 论文引入多视角自反方法（Mirror），通过 Navigator 和 Reasoner 模块提升 LLM 在知识密集任务中的推理能力。发现它能避免自反迭代卡住，提升多样性和一致性，在五个推理数据集上表现出色。\n\n- **MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases** (英文标题：\"MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases\")  \n  论文优化了少于十亿参数的 LLM，提出深层瘦架构和分组查询注意力机制。贡献包括提高模型效率（训练速度提升 3.31 倍），在设备端任务中超越基线，如 AlpacaEval 2.0。\n\n这些 LLM 相关论文整体展示了模型在资源有限场景下的潜力，但也暴露了知识冲突和偏置问题，值得进一步探索。\n\n**多模态处理与偏置检测**  \n- **Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration** (英文标题：\"Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration\")  \n  作者 Wonjeong Choi 等在 AAAI-24 提出 CTS 方法，提升深度神经网络在域外校准的鲁棒性。关键发现是通过风格和内容一致性减少过自信，提升 OOD 校准性能，而不牺牲准确性。\n\n- **Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging** (英文标题：\"Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging\")  \n  论文揭示多模态模型在医学图像中的人口偏置问题，如对女性和黑人患者的诊断不足。贡献包括使用真实数据集分析偏置，并提供代码，强调模型在医疗应用中的公平性挑战。\n\n- **WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition** (英文标题：\"WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition\")  \n  这篇 ACM MM 2024 论文结合 Segment Anything Model 和弱监督学习，提高对象检测和分割性能。发现通过自适应伪标签生成，提升 WSOD 和 WSIS 基准 7.4% 和 8.5%，在弱监督场景中更高效。\n\n这些工作突出了多模态模型的实际应用瓶颈，如偏置和泛化问题，相关于 AI 伦理讨论。\n\n**强化学习与机器人应用**  \n- **Learning Inverse Kinodynamics for Autonomous Vehicle Drifting** (英文标题：\"Learning Inverse Kinodynamics for Autonomous Vehicle Drifting\")  \n  论文使用数据驱动方法学习车辆动力学模型，支持自动漂移导航。贡献包括基于惯性测量修正轨迹，提升高速度场景下的鲁棒性，实验验证了其在障碍避让中的潜力。\n\n- **ACE: Off-Policy Actor-Critic with Causality-Aware Entropy Regularization** (英文标题：\"ACE: Off-Policy Actor-Critic with Causality-Aware Entropy Regularization\")  \n  ICLR 2024 亮点论文提出因果熵正则化，提升强化学习在连续控制任务中的性能。发现它在 29 个任务上超越基线，强调行动因果关系在探索中的作用。\n\n这些强化学习论文展示了 AI 在机器人和车辆控制中的进展，但需关注实际部署的稳定性。\n\n### 其他论文掠过\n剩余论文涉及领域广泛，如医学图像生成（SynthBrainGrow）、文本简化（MultiLS）和知识图谱（L+M-24），但这些相对次要或较为专业，因此快速总结：SynthBrainGrow 通过扩散模型模拟脑部老化，贡献在于高效生成纵向 MRI 数据；MultiLS 构建多任务词汇简化框架，提升 NLP 任务性能；L+M-24 扩展语言-分子数据集，支持多模态生成。这些工作虽有技术创新，但影响力不如上述重点论文，建议感兴趣读者查阅具体摘要。\n\n总之，今天的论文强调 AI 模型的优化和应用挑战，LLM 和多模态领域的突破尤为值得关注，助力未来 AI 研究。更多细节请查看 arXiv！",
  "papers": [
    {
      "arxiv_id": "2402.15027v2",
      "title": "Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education",
      "title_zh": "多利益相关者视角下的负责任人工智能与可接受性在教育领域",
      "authors": [
        "A. J. Karran",
        "P. Charland",
        "J-T. Martineau",
        "A. Ortiz de Guinea Lopez de Arana",
        "AM. Lesage",
        "S. Senecal",
        "P-M. Leger"
      ],
      "abstract": "This study investigates the acceptability of different artificial\nintelligence (AI) applications in education from a multi-stakeholder\nperspective, including students, teachers, and parents. Acknowledging the\ntransformative potential of AI in education, it addresses concerns related to\ndata privacy, AI agency, transparency, explainability and the ethical\ndeployment of AI. Through a vignette methodology, participants were presented\nwith four scenarios where AI's agency, transparency, explainability, and\nprivacy were manipulated. After each scenario, participants completed a survey\nthat captured their perceptions of AI's global utility, individual usefulness,\njustice, confidence, risk, and intention to use each scenario's AI if\navailable. The data collection comprising a final sample of 1198\nmulti-stakeholder participants was distributed through a partner institution\nand social media campaigns and focused on individual responses to four AI use\ncases. A mediation analysis of the data indicated that acceptance and trust in\nAI varies significantly across stakeholder groups. We found that the key\nmediators between high and low levels of AI's agency, transparency, and\nexplainability, as well as the intention to use the different educational AI,\nincluded perceived global utility, justice, and confidence. The study\nhighlights that the acceptance of AI in education is a nuanced and multifaceted\nissue that requires careful consideration of specific AI applications and their\ncharacteristics, in addition to the diverse stakeholders' perceptions.",
      "tldr_zh": "这篇论文从学生、教师和家长的多利益相关者视角，探讨了AI在教育中的可接受性，关注数据隐私、AI代理性、透明度和可解释性等伦理问题。研究采用虚构场景（vignette methodology）方法，向1198名参与者呈现四个AI应用场景，并通过调查和中介分析评估了AI的全球效用、个体有用性、公正性、信心、风险及使用意愿。结果显示，AI的接受度和信任在不同利益相关者群体间显著差异，关键中介因素包括感知到的全球效用、公正性和信心；论文强调，AI在教育中的部署需综合考虑特定应用特性及多利益相关者的感知，以实现负责任的实施。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "K.3.1; I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "28 pages, 2 appendices, 3 figures, 5 tables, original research",
      "pdf_url": "http://arxiv.org/pdf/2402.15027v2",
      "published_date": "2024-02-22 23:59:59 UTC",
      "updated_date": "2024-02-28 14:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:54:28.486068"
    },
    {
      "arxiv_id": "2402.15019v1",
      "title": "Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Wonjeong Choi",
        "Jungwuk Park",
        "Dong-Jun Han",
        "Younghyun Park",
        "Jaekyun Moon"
      ],
      "abstract": "Research interests in the robustness of deep neural networks against domain\nshifts have been rapidly increasing in recent years. Most existing works,\nhowever, focus on improving the accuracy of the model, not the calibration\nperformance which is another important requirement for trustworthy AI systems.\nTemperature scaling (TS), an accuracy-preserving post-hoc calibration method,\nhas been proven to be effective in in-domain settings, but not in out-of-domain\n(OOD) due to the difficulty in obtaining a validation set for the unseen domain\nbeforehand. In this paper, we propose consistency-guided temperature scaling\n(CTS), a new temperature scaling strategy that can significantly enhance the\nOOD calibration performance by providing mutual supervision among data samples\nin the source domains. Motivated by our observation that over-confidence\nstemming from inconsistent sample predictions is the main obstacle to OOD\ncalibration, we propose to guide the scaling process by taking consistencies\ninto account in terms of two different aspects -- style and content -- which\nare the key components that can well-represent data samples in multi-domain\nsettings. Experimental results demonstrate that our proposed strategy\noutperforms existing works, achieving superior OOD calibration performance on\nvarious datasets. This can be accomplished by employing only the source domains\nwithout compromising accuracy, making our scheme directly applicable to various\ntrustworthy AI systems.",
      "tldr_zh": "该论文针对深度神经网络在领域转移（Out-of-Domain, OOD）场景下的校准性能问题，提出了一种Consistency-Guided Temperature Scaling (CTS)方法，以提升模型的可靠性。CTS通过源域数据样本之间的相互监督，利用风格（style）和内容（content）一致性来指导温度缩放（Temperature Scaling, TS）过程，从而缓解过度自信（over-confidence）导致的预测不一致问题。实验结果显示，该方法在多种数据集上显著优于现有技术，提高了OOD校准性能，同时不影响模型准确性，仅依赖源域数据即可实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI-24 (The 38th AAAI Conference on Artificial\n  Intelligence, February 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.15019v1",
      "published_date": "2024-02-22 23:36:18 UTC",
      "updated_date": "2024-02-22 23:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:54:38.936988"
    },
    {
      "arxiv_id": "2402.15017v1",
      "title": "Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Xu",
        "Zhenmei Shi",
        "Junyi Wei",
        "Fangzhou Mu",
        "Yin Li",
        "Yingyu Liang"
      ],
      "abstract": "Foundation models have emerged as a powerful tool for many AI problems.\nDespite the tremendous success of foundation models, effective adaptation to\nnew tasks, particularly those with limited labels, remains an open question and\nlacks theoretical understanding. An emerging solution with recent success in\nvision and NLP involves finetuning a foundation model on a selection of\nrelevant tasks, before its adaptation to a target task with limited labeled\nsamples. In this paper, we study the theoretical justification of this\nmultitask finetuning approach. Our theoretical analysis reveals that with a\ndiverse set of related tasks, this multitask finetuning leads to reduced error\nin the target task, in comparison to directly adapting the same pretrained\nmodel. We quantify the relationship between finetuning tasks and target tasks\nby diversity and consistency metrics, and further propose a practical task\nselection algorithm. We substantiate our theoretical claims with extensive\nempirical evidence. Further, we present results affirming our task selection\nalgorithm adeptly chooses related finetuning tasks, providing advantages to the\nmodel performance on target tasks. We believe our study shed new light on the\neffective adaptation of foundation models to new tasks that lack abundant\nlabels. Our code is available at\nhttps://github.com/OliverXUZY/Foudation-Model_Multitask.",
      "tldr_zh": "本研究探讨了基础模型（foundation models）在少样本（few-shot）任务上的适应问题，提出通过多任务微调（multitask finetuning）的方法来提升性能。论文通过理论分析证明，使用多样化相关任务进行微调，能降低目标任务的错误率，并引入多样性和一致性（diversity and consistency）指标来量化任务关系，同时提出一个实用的任务选择算法。实验结果证实，该方法优于直接适应预训练模型，且任务选择算法能有效选择相关任务，提升模型在目标任务上的表现，为基础模型的少样本适应提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024. 54 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.15017v1",
      "published_date": "2024-02-22 23:29:42 UTC",
      "updated_date": "2024-02-22 23:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:54:51.015818"
    },
    {
      "arxiv_id": "2402.15012v1",
      "title": "Ar-Spider: Text-to-SQL in Arabic",
      "title_zh": "Ar-Spider：阿拉伯语文本到SQL",
      "authors": [
        "Saleh Almohaimeed",
        "Saad Almohaimeed",
        "Mansour Al Ghanim",
        "Liqiang Wang"
      ],
      "abstract": "In Natural Language Processing (NLP), one of the most important tasks is\ntext-to-SQL semantic parsing, which focuses on enabling users to interact with\nthe database in a more natural manner. In recent years, text-to-SQL has made\nsignificant progress, but most were English-centric. In this paper, we\nintroduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset. Due\nto the unique nature of the language, two major challenges have been\nencountered, namely schema linguistic and SQL structural challenges. In order\nto handle these issues and conduct the experiments, we adopt two baseline\nmodels LGESQL [4] and S2SQL [12], both of which are tested with two\ncross-lingual models to alleviate the effects of schema linguistic and SQL\nstructure linking challenges. The baselines demonstrate decent single-language\nperformance on our Arabic text-to-SQL dataset, Ar-Spider, achieving 62.48% for\nS2SQL and 65.57% for LGESQL, only 8.79% below the highest results achieved by\nthe baselines when trained in English dataset. To achieve better performance on\nArabic text-to-SQL, we propose the context similarity relationship (CSR)\napproach, which results in a significant increase in the overall performance of\nabout 1.52% for S2SQL and 1.06% for LGESQL and closes the gap between Arabic\nand English languages to 7.73%.",
      "tldr_zh": "本研究引入了 Ar-Spider，这是第一个阿拉伯语跨领域 Text-to-SQL 数据集，旨在解决 NLP 中 Text-to-SQL 语义解析的语言限制问题。面对 schema linguistic 和 SQL structural challenges，该团队采用了基线模型 LGESQL 和 S2SQL，并结合跨语言模型进行测试，结果显示这两个模型在 Ar-Spider 数据集上的性能分别为 62.48% 和 65.57%，仅比英语数据集低 8.79%。此外，提出 context similarity relationship (CSR)  approach 显著提升了性能，S2SQL 提高 1.52%、LGESQL 提高 1.06%，将阿拉伯语与英语的差距缩小至 7.73%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACM SAC Conference (SAC 24)",
      "pdf_url": "http://arxiv.org/pdf/2402.15012v1",
      "published_date": "2024-02-22 23:11:17 UTC",
      "updated_date": "2024-02-22 23:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:55:03.214547"
    },
    {
      "arxiv_id": "2402.15011v2",
      "title": "A Conversational Brain-Artificial Intelligence Interface",
      "title_zh": "翻译失败",
      "authors": [
        "Anja Meunier",
        "Michal Robert Žák",
        "Lucas Munz",
        "Sofiya Garkot",
        "Manuel Eder",
        "Jiachen Xu",
        "Moritz Grosse-Wentrup"
      ],
      "abstract": "We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class\nof Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on\nintact cognitive capabilities, BAIs leverage the power of artificial\nintelligence to replace parts of the neuro-cognitive processing pipeline. BAIs\nallow users to accomplish complex tasks by providing high-level intentions,\nwhile a pre-trained AI agent determines low-level details. This approach\nenlarges the target audience of BCIs to individuals with cognitive impairments,\na population often excluded from the benefits of conventional BCIs. We present\nthe general concept of BAIs and illustrate the potential of this new approach\nwith a Conversational BAI based on EEG. In particular, we show in an experiment\nwith simulated phone conversations that the Conversational BAI enables complex\ncommunication without the need to generate language. Our work thus\ndemonstrates, for the first time, the ability of a speech neuroprosthesis to\nenable fluent communication in realistic scenarios with non-invasive\ntechnologies.",
      "tldr_zh": "本文提出 Brain-Artificial Intelligence Interfaces (BAIs) 作为 Brain-Computer Interfaces (BCIs) 的新类别，利用人工智能替换部分神经认知处理管道，让用户只需提供高层意图，AI 代理则处理底层细节，从而扩展 BCIs 的应用至有认知障碍的个体。不同于传统 BCIs，该方法通过基于 EEG 的 Conversational BAI 实现复杂通信，例如在模拟电话对话实验中，用户无需生成语言即可进行流畅交流。实验结果首次证明，非侵入性技术能在现实场景中启用有效的言语神经假体，为更广泛的脑机接口应用奠定基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages (39 with supplementary meterial), 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.15011v2",
      "published_date": "2024-02-22 23:11:12 UTC",
      "updated_date": "2024-03-14 23:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:55:15.937914"
    },
    {
      "arxiv_id": "2402.15010v2",
      "title": "How Important Is Tokenization in French Medical Masked Language Models?",
      "title_zh": "在 French 医疗掩码语言模型中，分词",
      "authors": [
        "Yanis Labrak",
        "Adrien Bazoge",
        "Beatrice Daille",
        "Mickael Rouvier",
        "Richard Dufour"
      ],
      "abstract": "Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods.",
      "tldr_zh": "该论文探讨了子词 tokenization 在法语医疗 masked language models 中的重要性，分析了其成功因素如最佳分段粒度、数据来源影响以及形态学信息的作用，尤其针对生物医学术语的凝聚性问题。研究者评估了经典算法如 BPE 和 SentencePiece，并提出了一种原创策略，将形态学丰富的词分段整合到现有 tokenization 方法中。结果表明，这种方法有助于改善法语生物医学领域的 NLP 任务性能，并识别出进一步优化的关键领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 2024 Joint International Conference on\n  Computational Linguistics, Language Resources and Evaluation (LREC-COLING\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.15010v2",
      "published_date": "2024-02-22 23:11:08 UTC",
      "updated_date": "2024-06-09 15:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:55:27.271096"
    },
    {
      "arxiv_id": "2403.17379v1",
      "title": "Exploring and Applying Audio-Based Sentiment Analysis in Music",
      "title_zh": "探索和应用基于音频的情感分析在音乐中",
      "authors": [
        "Etash Jhanji"
      ],
      "abstract": "Sentiment analysis is a continuously explored area of text processing that\ndeals with the computational analysis of opinions, sentiments, and subjectivity\nof text. However, this idea is not limited to text and speech, in fact, it\ncould be applied to other modalities. In reality, humans do not express\nthemselves in text as deeply as they do in music. The ability of a\ncomputational model to interpret musical emotions is largely unexplored and\ncould have implications and uses in therapy and musical queuing. In this paper,\ntwo individual tasks are addressed. This study seeks to (1) predict the emotion\nof a musical clip over time and (2) determine the next emotion value after the\nmusic in a time series to ensure seamless transitions. Utilizing data from the\nEmotions in Music Database, which contains clips of songs selected from the\nFree Music Archive annotated with levels of valence and arousal as reported on\nRussel's circumplex model of affect by multiple volunteers, models are trained\nfor both tasks. Overall, the performance of these models reflected that they\nwere able to perform the tasks they were designed for effectively and\naccurately.",
      "tldr_zh": "该论文探讨了基于音频的情感分析在音乐中的应用，扩展了传统文本领域的 sentiment analysis 到音乐模态，以捕捉人类在音乐中更深层次的情感表达。研究针对两个任务：（1）预测音乐片段随时间变化的情感，以及（2）确定时间序列中的下一个情感值，以实现无缝过渡。作者使用 Emotions in Music Database 数据，该数据集基于 Russel's circumplex model of affect 标注了 valence 和 arousal 水平，并训练相应模型。结果显示，这些模型在预测任务中表现出色，证明了音频情感分析在疗法和音乐队列中的潜在应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 7 figures, 2 tables. For source code, see\n  https://github.com/etashj/Exploring-and-Applying-Audio-Based-Sentiment-Analysis",
      "pdf_url": "http://arxiv.org/pdf/2403.17379v1",
      "published_date": "2024-02-22 22:34:06 UTC",
      "updated_date": "2024-02-22 22:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:55:39.504242"
    },
    {
      "arxiv_id": "2402.14992v2",
      "title": "tinyBenchmarks: evaluating LLMs with fewer examples",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Maia Polo",
        "Lucas Weber",
        "Leshem Choshen",
        "Yuekai Sun",
        "Gongjun Xu",
        "Mikhail Yurochkin"
      ],
      "abstract": "The versatility of large language models (LLMs) led to the creation of\ndiverse benchmarks that thoroughly test a variety of language models'\nabilities. These benchmarks consist of tens of thousands of examples making\nevaluation of LLMs very expensive. In this paper, we investigate strategies to\nreduce the number of evaluations needed to assess the performance of an LLM on\nseveral key benchmarks. For example, we show that to accurately estimate the\nperformance of an LLM on MMLU, a popular multiple-choice QA benchmark\nconsisting of 14K examples, it is sufficient to evaluate this LLM on 100\ncurated examples. We release evaluation tools and tiny versions of popular\nbenchmarks: Open LLM Leaderboard, MMLU, HELM, and AlpacaEval 2.0. Our empirical\nanalysis demonstrates that these tools and tiny benchmarks are sufficient to\nreliably and efficiently reproduce the original evaluation results.",
      "tldr_zh": "该论文探讨了如何通过减少评估样本来高效评估大型语言模型(LLMs)的性能，针对现有基准测试中数万个例子的成本问题提出优化策略。例如，他们证明对于MMLU（一个包含14K例子的多选问答基准），只需评估100个精选例子即可准确估计模型表现。论文发布了评估工具和缩小版基准，包括Open LLM Leaderboard、MMLU、HELM和AlpacaEval 2.0，并通过实证分析证实这些工具能可靠地复制原评估结果，从而提升LLMs评估的效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML)",
      "pdf_url": "http://arxiv.org/pdf/2402.14992v2",
      "published_date": "2024-02-22 22:05:23 UTC",
      "updated_date": "2024-05-26 22:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:55:52.016811"
    },
    {
      "arxiv_id": "2402.14989v6",
      "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "YongKyung Oh",
        "Dong-Young Lim",
        "Sungil Kim"
      ],
      "abstract": "Irregular sampling intervals and missing values in real-world time series\ndata present challenges for conventional methods that assume consistent\nintervals and complete data. Neural Ordinary Differential Equations (Neural\nODEs) offer an alternative approach, utilizing neural networks combined with\nODE solvers to learn continuous latent representations through parameterized\nvector fields. Neural Stochastic Differential Equations (Neural SDEs) extend\nNeural ODEs by incorporating a diffusion term, although this addition is not\ntrivial, particularly when addressing irregular intervals and missing values.\nConsequently, careful design of drift and diffusion functions is crucial for\nmaintaining stability and enhancing performance, while incautious choices can\nresult in adverse properties such as the absence of strong solutions,\nstochastic destabilization, or unstable Euler discretizations, significantly\naffecting Neural SDEs' performance. In this study, we propose three stable\nclasses of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE.\nThen, we rigorously demonstrate their robustness in maintaining excellent\nperformance under distribution shift, while effectively preventing overfitting.\nTo assess the effectiveness of our approach, we conduct extensive experiments\non four benchmark datasets for interpolation, forecasting, and classification\ntasks, and analyze the robustness of our methods with 30 public datasets under\ndifferent missing rates. Our results demonstrate the efficacy of the proposed\nmethod in handling real-world irregular time series data.",
      "tldr_zh": "本研究针对真实世界时间序列数据的非规则采样间隔和缺失值问题，提出三种稳定的Neural SDEs模型，包括Langevin-type SDE、Linear Noise SDE和Geometric SDE，以解决传统Neural ODEs的局限性。作者通过严格证明这些模型在分布偏移下的鲁棒性能，并有效防止过拟合。实验在四个基准数据集上评估了插值、预测和分类任务，并在30个公共数据集上测试不同缺失率下的表现，结果显示该方法显著提高了处理不规则时间序列数据的效能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the Twelfth International Conference on Learning\n  Representations (ICLR 2024), Spotlight presentation (Notable Top 5%).\n  https://openreview.net/forum?id=4VIgNuQ1pY",
      "pdf_url": "http://arxiv.org/pdf/2402.14989v6",
      "published_date": "2024-02-22 22:00:03 UTC",
      "updated_date": "2025-01-24 23:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:56:03.128311"
    },
    {
      "arxiv_id": "2402.14978v2",
      "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation",
      "title_zh": "翻译失败",
      "authors": [
        "Orit Shaer",
        "Angelora Cooper",
        "Osnat Mokryn",
        "Andrew L. Kun",
        "Hagit Ben Shoshan"
      ],
      "abstract": "The growing availability of generative AI technologies such as large language\nmodels (LLMs) has significant implications for creative work. This paper\nexplores twofold aspects of integrating LLMs into the creative process - the\ndivergence stage of idea generation, and the convergence stage of evaluation\nand selection of ideas. We devised a collaborative group-AI Brainwriting\nideation framework, which incorporated an LLM as an enhancement into the group\nideation process, and evaluated the idea generation process and the resulted\nsolution space. To assess the potential of using LLMs in the idea evaluation\nprocess, we design an evaluation engine and compared it to idea ratings\nassigned by three expert and six novice evaluators. Our findings suggest that\nintegrating LLM in Brainwriting could enhance both the ideation process and its\noutcome. We also provide evidence that LLMs can support idea evaluation. We\nconclude by discussing implications for HCI education and practice.",
      "tldr_zh": "本论文探讨了将大型语言模型(LLMs)整合到群组创意过程的Brainwriting框架中，焦点在于idea generation（发散阶段）和idea evaluation（收敛阶段）。研究设计了一个协作的group-AI Brainwriting系统，并通过一个evaluation engine与专家和初学者评委的评分进行比较，评估LLMs对创意过程的增强作用。结果表明，LLMs能显著提升ideation的效率和产出质量，并提供证据支持其在idea evaluation中的应用，为HCI教育和实践带来重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2; J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "Conditionally Accepted to CHI24. 27 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.14978v2",
      "published_date": "2024-02-22 21:34:52 UTC",
      "updated_date": "2024-02-29 22:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:56:15.332475"
    },
    {
      "arxiv_id": "2402.14976v1",
      "title": "Unsupervised Domain Adaptation within Deep Foundation Latent Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitry Kangin",
        "Plamen Angelov"
      ],
      "abstract": "The vision transformer-based foundation models, such as ViT or Dino-V2, are\naimed at solving problems with little or no finetuning of features. Using a\nsetting of prototypical networks, we analyse to what extent such foundation\nmodels can solve unsupervised domain adaptation without finetuning over the\nsource or target domain. Through quantitative analysis, as well as qualitative\ninterpretations of decision making, we demonstrate that the suggested method\ncan improve upon existing baselines, as well as showcase the limitations of\nsuch approach yet to be solved.",
      "tldr_zh": "本研究探讨了在深度基础模型潜在空间（Deep Foundation Latent Spaces）内进行无监督域适应（Unsupervised Domain Adaptation），利用 Vision Transformer（如 ViT 或 Dino-V2）等模型，而无需对源域或目标域进行微调。基于原型网络（Prototypical Networks）的框架，通过定量分析和定性决策解释，证明该方法在性能上超过了现有基线。实验结果突出了方法的优势，同时揭示了其尚未解决的局限性，例如在复杂场景下的适用性不足。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14976v1",
      "published_date": "2024-02-22 21:25:20 UTC",
      "updated_date": "2024-02-22 21:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:56:27.405707"
    },
    {
      "arxiv_id": "2402.14974v2",
      "title": "Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data",
      "title_zh": "翻译失败",
      "authors": [
        "Majid Farhadloo",
        "Arun Sharma",
        "Jayant Gupta",
        "Alexey Leontovich",
        "Svetomir N. Markovic",
        "Shashi Shekhar"
      ],
      "abstract": "Given multi-category point sets from different place-types, our goal is to\ndevelop a spatially-lucid classifier that can distinguish between two classes\nbased on the arrangements of their points. This problem is important for many\napplications, such as oncology, for analyzing immune-tumor relationships and\ndesigning new immunotherapies. It is challenging due to spatial variability and\ninterpretability needs. Previously proposed techniques require dense training\ndata or have limited ability to handle significant spatial variability within a\nsingle place-type. Most importantly, these deep neural network (DNN) approaches\nare not designed to work in non-Euclidean space, particularly point sets.\nExisting non-Euclidean DNN methods are limited to one-size-fits-all approaches.\nWe explore a spatial ensemble framework that explicitly uses different training\nstrategies, including weighted-distance learning rate and spatial domain\nadaptation, on various place-types for spatially-lucid classification.\nExperimental results on real-world datasets (e.g., MxIF oncology data) show\nthat the proposed framework provides higher prediction accuracy than baseline\nmethods.",
      "tldr_zh": "本研究旨在开发一种空间明晰(spatially-lucid) AI 分类器，用于区分非欧空间(non-Euclidean space)中多类别点集的排列差异，特别是应用于 MxIF oncology data 的肿瘤免疫关系分析，以应对空间变异性和可解释性挑战。论文提出了一种空间集成框架，结合加权距离学习率(weighted-distance learning rate)和空间域适应(spatial domain adaptation)等策略，在不同地点类型上进行训练，以提升分类性能。与现有方法相比，该框架在真实世界数据集上实现了更高的预测准确率，为肿瘤学应用提供了更可靠的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "SIAM International Conference on Data Mining (SDM24)",
      "pdf_url": "http://arxiv.org/pdf/2402.14974v2",
      "published_date": "2024-02-22 21:22:21 UTC",
      "updated_date": "2025-04-24 16:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:56:40.533679"
    },
    {
      "arxiv_id": "2402.14973v4",
      "title": "GenCeption: Evaluate Vision LLMs with Unlabeled Unimodal Data",
      "title_zh": "翻译失败",
      "authors": [
        "Lele Cao",
        "Valentin Buchner",
        "Zineb Senane",
        "Fangkai Yang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are typically assessed using\nexpensive annotated multimodal benchmarks, which often lag behind the rapidly\nevolving demands of MLLM evaluation. This paper outlines and validates\nGenCeption, a novel, annotation-free evaluation method that requires only\nunimodal data to measure inter-modality semantic coherence and inversely\nassesses MLLMs' tendency to hallucinate. This approach eliminates the need for\ncostly data annotation, minimizes the risk of training data contamination, is\nexpected to result in slower benchmark saturation, and avoids the illusion of\nemerging abilities. Inspired by the DrawCeption game, GenCeption begins with a\nnon-textual sample and proceeds through iterative description and generation\nsteps. The semantic drift across iterations is quantified using the GC@T\nmetric. While GenCeption is principally applicable to MLLMs across various\nmodalities, this paper focuses on its implementation and validation for Vision\nLLMs (VLLMs). Based on the GenCeption method, we establish the MMECeption\nbenchmark for evaluating VLLMs, and compare the performance of several popular\nVLLMs and human annotators. Our empirical results validate GenCeption's\neffectiveness, demonstrating strong correlations with established VLLM\nbenchmarks. VLLMs still significantly lag behind human performance and struggle\nespecially with text-intensive tasks.",
      "tldr_zh": "本论文提出 GenCeption，一种无需标注的评估方法，仅使用单模态数据来评估 Multimodal Large Language Models (MLLMs)，特别是 Vision LLMs (VLLMs)，通过量化跨模态语义一致性和幻觉倾向，避免了昂贵的标注和基准饱和问题。  \nGenCeption 受 DrawCeption 游戏启发，从非文本样本开始，进行迭代描述和生成步骤，并使用 GC@T 指标测量语义漂移，从而间接评估模型性能。  \n实验基于 MMECeption 基准测试了多个流行 VLLMs 和人类表现，结果显示 GenCeption 与现有基准高度相关，但 VLLMs 在文本密集任务上显著落后于人类。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.7; I.4"
      ],
      "primary_category": "cs.CL",
      "comment": "Published by Computer Speech & Language\n  (https://doi.org/10.1016/j.csl.2025.101785). Source code and Leaderboard:\n  https://github.com/llcresearch/GenCeption",
      "pdf_url": "http://arxiv.org/pdf/2402.14973v4",
      "published_date": "2024-02-22 21:22:04 UTC",
      "updated_date": "2025-03-05 21:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:56:52.506674"
    },
    {
      "arxiv_id": "2402.14972v1",
      "title": "MultiLS: A Multi-task Lexical Simplification Framework",
      "title_zh": "MultiLS：多任务词汇简化框架",
      "authors": [
        "Kai North",
        "Tharindu Ranasinghe",
        "Matthew Shardlow",
        "Marcos Zampieri"
      ],
      "abstract": "Lexical Simplification (LS) automatically replaces difficult to read words\nfor easier alternatives while preserving a sentence's original meaning. LS is a\nprecursor to Text Simplification with the aim of improving text accessibility\nto various target demographics, including children, second language learners,\nindividuals with reading disabilities or low literacy. Several datasets exist\nfor LS. These LS datasets specialize on one or two sub-tasks within the LS\npipeline. However, as of this moment, no single LS dataset has been developed\nthat covers all LS sub-tasks. We present MultiLS, the first LS framework that\nallows for the creation of a multi-task LS dataset. We also present MultiLS-PT,\nthe first dataset to be created using the MultiLS framework. We demonstrate the\npotential of MultiLS-PT by carrying out all LS sub-tasks of (1). lexical\ncomplexity prediction (LCP), (2). substitute generation, and (3). substitute\nranking for Portuguese. Model performances are reported, ranging from\ntransformer-based models to more recent large language models (LLMs).",
      "tldr_zh": "本研究提出了 MultiLS 框架，这是第一个多任务词汇简化 (Lexical Simplification, LS) 框架，用于创建涵盖所有 LS 子任务的完整数据集，从而解决现有数据集只专注于一两个子任务的局限性。  \nMultiLS 框架被用于生成 MultiLS-PT，这是针对葡萄牙语 (Portuguese) 的首个多任务 LS 数据集，支持词汇复杂性预测 (Lexical Complexity Prediction, LCP)、替代词生成和替代词排名等子任务。  \n实验结果显示，使用从 transformer-based 模型到大型语言模型 (LLMs) 的各种模型，在 MultiLS-PT 上执行这些任务，展示了框架的潜力，并为提升文本可访问性提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14972v1",
      "published_date": "2024-02-22 21:16:18 UTC",
      "updated_date": "2024-02-22 21:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:57:05.017667"
    },
    {
      "arxiv_id": "2402.14963v2",
      "title": "Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning",
      "title_zh": "Mirror：一种多视角自我反思方法，用于知识丰富的推理",
      "authors": [
        "Hanqi Yan",
        "Qinglin Zhu",
        "Xinyu Wang",
        "Lin Gui",
        "Yulan He"
      ],
      "abstract": "While Large language models (LLMs) have the capability to iteratively reflect\non their own outputs, recent studies have observed their struggles with\nknowledge-rich problems without access to external resources. In addition to\nthe inefficiency of LLMs in self-assessment, we also observe that LLMs struggle\nto revisit their predictions despite receiving explicit negative feedback.\nTherefore, We propose Mirror, a Multiple-perspective self-reflection method for\nknowledge-rich reasoning, to avoid getting stuck at a particular reflection\niteration. Mirror enables LLMs to reflect from multiple-perspective clues,\nachieved through a heuristic interaction between a Navigator and a Reasoner. It\nguides agents toward diverse yet plausibly reliable reasoning trajectory\nwithout access to ground truth by encouraging (1) diversity of directions\ngenerated by Navigator and (2) agreement among strategically induced\nperturbations in responses generated by the Reasoner. The experiments on five\nreasoning datasets demonstrate that Mirror's superiority over several\ncontemporary self-reflection approaches. Additionally, the ablation study\nstudies clearly indicate that our strategies alleviate the aforementioned\nchallenges.",
      "tldr_zh": "大语言模型(LLMs)在处理知识丰富的推理任务时，常面临自我评估效率低和无法有效修正预测的问题。论文提出Mirror方法，一种多视角自我反思机制，通过Navigator生成多样化方向和Reasoner处理响应一致性，实现可靠的推理轨迹，而无需访问真实数据。在五个推理数据集上的实验证明，Mirror优于其他自我反思方法，且消融研究证实其策略有效缓解了上述挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL24, Main Conference, long paper. Code is available at\n  https://github.com/hanqi-qi/Mirror.git",
      "pdf_url": "http://arxiv.org/pdf/2402.14963v2",
      "published_date": "2024-02-22 20:57:17 UTC",
      "updated_date": "2024-06-24 10:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:57:16.392158"
    },
    {
      "arxiv_id": "2405.00682v1",
      "title": "SynthBrainGrow: Synthetic Diffusion Brain Aging for Longitudinal MRI Data Generation in Young People",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Zapaishchykova",
        "Benjamin H. Kann",
        "Divyanshu Tak",
        "Zezhong Ye",
        "Daphne A. Haas-Kogan",
        "Hugo J. W. L. Aerts"
      ],
      "abstract": "Synthetic longitudinal brain MRI simulates brain aging and would enable more\nefficient research on neurodevelopmental and neurodegenerative conditions.\nSynthetically generated, age-adjusted brain images could serve as valuable\nalternatives to costly longitudinal imaging acquisitions, serve as internal\ncontrols for studies looking at the effects of environmental or therapeutic\nmodifiers on brain development, and allow data augmentation for diverse\npopulations. In this paper, we present a diffusion-based approach called\nSynthBrainGrow for synthetic brain aging with a two-year step. To validate the\nfeasibility of using synthetically-generated data on downstream tasks, we\ncompared structural volumetrics of two-year-aged brains against\nsynthetically-aged brain MRI. Results show that SynthBrainGrow can accurately\ncapture substructure volumetrics and simulate structural changes such as\nventricle enlargement and cortical thinning. Our approach provides a novel way\nto generate longitudinal brain datasets from cross-sectional data to enable\naugmented training and benchmarking of computational tools for analyzing\nlifespan trajectories. This work signifies an important advance in generative\nmodeling to synthesize realistic longitudinal data with limited lifelong MRI\nscans. The code is available at XXX.",
      "tldr_zh": "本论文提出SynthBrainGrow，一种基于diffusion的approach，用于从横断面MRI数据合成两年的纵向脑衰老图像，旨在模拟年轻人的脑部发育变化并减少昂贵的纵向成像需求。\n该方法生成年龄调整的合成脑图像，可作为内部对照或数据增强工具，支持对神经发育和退行性疾病的研究。\n实验结果显示，SynthBrainGrow能准确捕捉脑子结构体积，并成功模拟结构变化，如脑室enlargement和cortical thinning。\n这项工作为生成真实纵向数据集提供了新途径，促进计算工具的训练和基准测试，尤其在有限的lifespan MRI扫描场景下。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.SP",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00682v1",
      "published_date": "2024-02-22 20:47:40 UTC",
      "updated_date": "2024-02-22 20:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:57:28.963991"
    },
    {
      "arxiv_id": "2403.00791v2",
      "title": "L+M-24: Building a Dataset for Language + Molecules @ ACL 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Carl Edwards",
        "Qingyun Wang",
        "Lawrence Zhao",
        "Heng Ji"
      ],
      "abstract": "Language-molecule models have emerged as an exciting direction for molecular\ndiscovery and understanding. However, training these models is challenging due\nto the scarcity of molecule-language pair datasets. At this point, datasets\nhave been released which are 1) small and scraped from existing databases, 2)\nlarge but noisy and constructed by performing entity linking on the scientific\nliterature, and 3) built by converting property prediction datasets to natural\nlanguage using templates. In this document, we detail the $\\textit{L+M-24}$\ndataset, which has been created for the Language + Molecules Workshop shared\ntask at ACL 2024. In particular, $\\textit{L+M-24}$ is designed to focus on\nthree key benefits of natural language in molecule design: compositionality,\nfunctionality, and abstraction.",
      "tldr_zh": "本研究探讨了语言-分子模型（Language + Molecules）在分子发现和理解中的潜力，但强调了训练这些模型面临的挑战，即分子-语言对数据集的稀缺性。现有数据集要么规模小且仅从数据库中抓取，要么噪声大（通过实体链接构建），或依赖模板转换属性预测数据集。论文介绍了L+M-24数据集，该数据集是为ACL 2024的Language + Molecules Workshop共享任务设计的，专注于自然语言在分子设计中的三个关键益处：compositionality（组合性）、functionality（功能性）和abstraction（抽象性）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.BM",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "The dataset, finetuned baselines, and evaluation code are released\n  publicly at https://github.com/language-plus-molecules/LPM-24-Dataset through\n  https://huggingface.co/language-plus-molecules",
      "pdf_url": "http://arxiv.org/pdf/2403.00791v2",
      "published_date": "2024-02-22 20:11:24 UTC",
      "updated_date": "2024-07-04 17:21:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:57:40.195836"
    },
    {
      "arxiv_id": "2402.14933v1",
      "title": "Path Planning based on 2D Object Bounding-box",
      "title_zh": "基于 2D 对象边界框的路径规划",
      "authors": [
        "Yanliang Huang",
        "Liguo Zhou",
        "Chang Liu",
        "Alois Knoll"
      ],
      "abstract": "The implementation of Autonomous Driving (AD) technologies within urban\nenvironments presents significant challenges. These challenges necessitate the\ndevelopment of advanced perception systems and motion planning algorithms\ncapable of managing situations of considerable complexity. Although the\nend-to-end AD method utilizing LiDAR sensors has achieved significant success\nin this scenario, we argue that its drawbacks may hinder its practical\napplication. Instead, we propose the vision-centric AD as a promising\nalternative offering a streamlined model without compromising performance. In\nthis study, we present a path planning method that utilizes 2D bounding boxes\nof objects, developed through imitation learning in urban driving scenarios.\nThis is achieved by integrating high-definition (HD) map data with images\ncaptured by surrounding cameras. Subsequent perception tasks involve\nbounding-box detection and tracking, while the planning phase employs both\nlocal embeddings via Graph Neural Network (GNN) and global embeddings via\nTransformer for temporal-spatial feature aggregation, ultimately producing\noptimal path planning information. We evaluated our model on the nuPlan\nplanning task and observed that it performs competitively in comparison to\nexisting vision-centric methods.",
      "tldr_zh": "这篇论文针对城市环境中的自动驾驶（Autonomous Driving, AD）挑战，提出了一种基于2D对象边界框（2D bounding boxes）的路径规划方法，作为视觉中心（vision-centric）AD的替代方案，以克服LiDAR端到端方法的缺点。方法通过模仿学习（imitation learning）整合高清地图（HD map）和摄像头图像，进行边界框检测和跟踪，并利用Graph Neural Network (GNN)处理局部嵌入以及Transformer处理全局嵌入，实现时空特征聚合以生成最优路径。实验结果显示，该模型在nuPlan规划任务上与现有视觉中心方法相比具有竞争力，提供了一种高效且性能可靠的路径规划方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14933v1",
      "published_date": "2024-02-22 19:34:56 UTC",
      "updated_date": "2024-02-22 19:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:57:52.630911"
    },
    {
      "arxiv_id": "2402.14929v1",
      "title": "Federated Fairness without Access to Sensitive Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Afroditi Papadaki",
        "Natalia Martinez",
        "Martin Bertran",
        "Guillermo Sapiro",
        "Miguel Rodrigues"
      ],
      "abstract": "Current approaches to group fairness in federated learning assume the\nexistence of predefined and labeled sensitive groups during training. However,\ndue to factors ranging from emerging regulations to dynamics and\nlocation-dependency of protected groups, this assumption may be unsuitable in\nmany real-world scenarios. In this work, we propose a new approach to guarantee\ngroup fairness that does not rely on any predefined definition of sensitive\ngroups or additional labels. Our objective allows the federation to learn a\nPareto efficient global model ensuring worst-case group fairness and it\nenables, via a single hyper-parameter, trade-offs between fairness and utility,\nsubject only to a group size constraint. This implies that any sufficiently\nlarge subset of the population is guaranteed to receive at least a minimum\nlevel of utility performance from the model. The proposed objective encompasses\nexisting approaches as special cases, such as empirical risk minimization and\nsubgroup robustness objectives from centralized machine learning. We provide an\nalgorithm to solve this problem in federation that enjoys convergence and\nexcess risk guarantees. Our empirical results indicate that the proposed\napproach can effectively improve the worst-performing group that may be present\nwithout unnecessarily hurting the average performance, exhibits superior or\ncomparable performance to relevant baselines, and achieves a large set of\nsolutions with different fairness-utility trade-offs.",
      "tldr_zh": "该研究提出了一种新的联邦学习（Federated Learning）群组公平方法，无需访问预定义的敏感群组或额外标签，解决了现实场景中群组动态和法规限制的问题。该方法通过学习一个Pareto efficient全局模型，确保最坏情况下的群组公平，并利用单一超参数平衡公平性和实用性，仅需满足群组大小约束，从而保证任何足够大的子集都能获得最小水平的性能。该方法涵盖了现有目标，如经验风险最小化（Empirical Risk Minimization）和子群鲁棒性（Subgroup Robustness），并提供了一个收敛且具有超额风险保证的算法。实验结果显示，该方法能有效提升最差表现群组的性能，同时保持或优于基线的平均性能，并提供多种公平-实用性权衡方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14929v1",
      "published_date": "2024-02-22 19:24:59 UTC",
      "updated_date": "2024-02-22 19:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:58:04.767257"
    },
    {
      "arxiv_id": "2402.14928v1",
      "title": "Learning Inverse Kinodynamics for Autonomous Vehicle Drifting",
      "title_zh": "翻译失败",
      "authors": [
        "M. Suvarna",
        "O. Tehrani"
      ],
      "abstract": "In this work, we explore a data-driven learning-based approach to learning\nthe kinodynamic model of a small autonomous vehicle, and observe the effect it\nhas on motion planning, specifically autonomous drifting. When executing a\nmotion plan in the real world, there are numerous causes for error, and what is\nplanned is often not what is executed on the actual car. Learning a kinodynamic\nplanner based off of inertial measurements and executed commands can help us\nlearn the world state. In our case, we look towards the realm of drifting; it\nis a complex maneuver that requires a smooth enough surface, high enough speed,\nand a drastic change in velocity. We attempt to learn the kinodynamic model for\nthese drifting maneuvers, and attempt to tighten the slip of the car. Our\napproach is able to learn a kinodynamic model for high-speed circular\nnavigation, and is able to avoid obstacles on an autonomous drift at high speed\nby correcting an executed curvature for loose drifts. We seek to adjust our\nkinodynamic model for success in tighter drifts in future work.",
      "tldr_zh": "本研究提出了一种数据驱动的学习方法，用于学习小型自主车辆的逆运动动力学（Inverse Kinodynamics）模型，旨在改善运动规划中的误差问题，特别是针对自动漂移（autonomous drifting）。通过利用惯性测量和执行命令，该方法成功学习了车辆在高速圆形导航中的动力学模型，并通过修正执行曲率来避免障碍和减少滑动。实验结果显示，该模型在高速漂移任务中表现出色，但未来工作将进一步优化以实现更紧凑的漂移操作。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14928v1",
      "published_date": "2024-02-22 19:24:56 UTC",
      "updated_date": "2024-02-22 19:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:58:15.826307"
    },
    {
      "arxiv_id": "2402.14922v1",
      "title": "Practical Insights into Knowledge Distillation for Pre-Trained Models",
      "title_zh": "针对预训练模型的",
      "authors": [
        "Norah Alballa",
        "Marco Canini"
      ],
      "abstract": "This research investigates the enhancement of knowledge distillation (KD)\nprocesses in pre-trained models, an emerging field in knowledge transfer with\nsignificant implications for distributed training and federated learning\nenvironments. These environments benefit from reduced communication demands and\naccommodate various model architectures. Despite the adoption of numerous KD\napproaches for transferring knowledge among pre-trained models, a comprehensive\nunderstanding of KD's application in these scenarios is lacking. Our study\nconducts an extensive comparison of multiple KD techniques, including standard\nKD, tuned KD (via optimized temperature and weight parameters), deep mutual\nlearning, and data partitioning KD. We assess these methods across various data\ndistribution strategies to identify the most effective contexts for each.\nThrough detailed examination of hyperparameter tuning, informed by extensive\ngrid search evaluations, we pinpoint when adjustments are crucial to enhance\nmodel performance. This paper sheds light on optimal hyperparameter settings\nfor distinct data partitioning scenarios and investigates KD's role in\nimproving federated learning by minimizing communication rounds and expediting\nthe training process. By filling a notable void in current research, our\nfindings serve as a practical framework for leveraging KD in pre-trained models\nwithin collaborative and federated learning frameworks.",
      "tldr_zh": "本研究探讨了知识蒸馏 (KD) 在预训练模型中的应用，旨在提升分布式训练和联邦学习的环境效率，通过减少通信需求并支持多种模型架构。研究者比较了多种 KD 技术，包括标准 KD、优化温度和权重参数的调整 KD、深度互学习以及数据分区 KD，并在不同数据分布策略下进行评估，同时通过网格搜索优化超参数设置。结果显示，针对特定数据分区场景的最佳超参数配置可显著提升模型性能，减少联邦学习的通信轮次并加速训练过程，为在协作学习框架中应用 KD 提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14922v1",
      "published_date": "2024-02-22 19:07:08 UTC",
      "updated_date": "2024-02-22 19:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:58:29.142548"
    },
    {
      "arxiv_id": "2402.14815v1",
      "title": "Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging",
      "title_zh": "专家级视觉-语言基础模型在医学成像中的人口统计偏差",
      "authors": [
        "Yuzhe Yang",
        "Yujia Liu",
        "Xin Liu",
        "Avanti Gulhane",
        "Domenico Mastrodicasa",
        "Wei Wu",
        "Edward J Wang",
        "Dushyant W Sahani",
        "Shwetak Patel"
      ],
      "abstract": "Advances in artificial intelligence (AI) have achieved expert-level\nperformance in medical imaging applications. Notably, self-supervised\nvision-language foundation models can detect a broad spectrum of pathologies\nwithout relying on explicit training annotations. However, it is crucial to\nensure that these AI models do not mirror or amplify human biases, thereby\ndisadvantaging historically marginalized groups such as females or Black\npatients. The manifestation of such biases could systematically delay essential\nmedical care for certain patient subgroups. In this study, we investigate the\nalgorithmic fairness of state-of-the-art vision-language foundation models in\nchest X-ray diagnosis across five globally-sourced datasets. Our findings\nreveal that compared to board-certified radiologists, these foundation models\nconsistently underdiagnose marginalized groups, with even higher rates seen in\nintersectional subgroups, such as Black female patients. Such demographic\nbiases present over a wide range of pathologies and demographic attributes.\nFurther analysis of the model embedding uncovers its significant encoding of\ndemographic information. Deploying AI systems with these biases in medical\nimaging can intensify pre-existing care disparities, posing potential\nchallenges to equitable healthcare access and raising ethical questions about\ntheir clinical application.",
      "tldr_zh": "本研究调查了专家级视觉语言基础模型（vision-language foundation models）在医疗成像中的算法公平性（algorithmic fairness），重点关注其潜在人口偏见。研究者使用五个全球数据集分析了这些模型在胸部 X 光（chest X-ray）诊断中的表现，发现模型比放射科医生更常低估边缘化群体的疾病诊断，尤其在交叉群体（如黑人女性患者）中偏见更为严重。进一步的模型嵌入分析显示，这些偏见源于模型对人口属性的显著编码，可能加剧现有医疗护理不平等，并引发关于AI临床应用的伦理问题。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Code and data are available at\n  https://github.com/YyzHarry/vlm-fairness",
      "pdf_url": "http://arxiv.org/pdf/2402.14815v1",
      "published_date": "2024-02-22 18:59:53 UTC",
      "updated_date": "2024-02-22 18:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:58:41.311656"
    },
    {
      "arxiv_id": "2402.14812v2",
      "title": "WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Lianghui Zhu",
        "Junwei Zhou",
        "Yan Liu",
        "Xin Hao",
        "Wenyu Liu",
        "Xinggang Wang"
      ],
      "abstract": "Weakly supervised visual recognition using inexact supervision is a critical\nyet challenging learning problem. It significantly reduces human labeling costs\nand traditionally relies on multi-instance learning and pseudo-labeling. This\npaper introduces WeakSAM and solves the weakly-supervised object detection\n(WSOD) and segmentation by utilizing the pre-learned world knowledge contained\nin a vision foundation model, i.e., the Segment Anything Model (SAM). WeakSAM\naddresses two critical limitations in traditional WSOD retraining, i.e., pseudo\nground truth (PGT) incompleteness and noisy PGT instances, through adaptive PGT\ngeneration and Region of Interest (RoI) drop regularization. It also addresses\nthe SAM's problems of requiring prompts and category unawareness for automatic\nobject detection and segmentation. Our results indicate that WeakSAM\nsignificantly surpasses previous state-of-the-art methods in WSOD and WSIS\nbenchmarks with large margins, i.e. average improvements of 7.4% and 8.5%,\nrespectively. The code is available at \\url{https://github.com/hustvl/WeakSAM}.",
      "tldr_zh": "本论文提出WeakSAM，一种结合Segment Anything Model (SAM)的框架，用于解决弱监督对象检测 (WSOD) 和实例分割 (WSIS) 的挑战，通过利用SAM的预学世界知识来减少标注成本。WeakSAM通过自适应伪地面真实 (PGT) 生成和Region of Interest (RoI) drop 正则化，解决了传统WSOD中PGT不完整和噪声问题，同时克服了SAM对提示的依赖和类别无感知的局限。实验结果显示，WeakSAM在WSOD和WSIS基准上分别比现有最先进方法平均提升7.4%和8.5%，显著提高了弱监督视觉识别的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM 2024. Code is available at\n  https://github.com/hustvl/WeakSAM",
      "pdf_url": "http://arxiv.org/pdf/2402.14812v2",
      "published_date": "2024-02-22 18:59:24 UTC",
      "updated_date": "2024-08-17 04:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:58:52.224983"
    },
    {
      "arxiv_id": "2402.14810v1",
      "title": "GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyi Liu",
        "Li Yi"
      ],
      "abstract": "In this work, we tackle the challenging problem of denoising hand-object\ninteractions (HOI). Given an erroneous interaction sequence, the objective is\nto refine the incorrect hand trajectory to remove interaction artifacts for a\nperceptually realistic sequence. This challenge involves intricate interaction\nnoise, including unnatural hand poses and incorrect hand-object relations,\nalongside the necessity for robust generalization to new interactions and\ndiverse noise patterns. We tackle those challenges through a novel approach,\nGeneOH Diffusion, incorporating two key designs: an innovative contact-centric\nHOI representation named GeneOH and a new domain-generalizable denoising\nscheme. The contact-centric representation GeneOH informatively parameterizes\nthe HOI process, facilitating enhanced generalization across various HOI\nscenarios. The new denoising scheme consists of a canonical denoising model\ntrained to project noisy data samples from a whitened noise space to a clean\ndata manifold and a \"denoising via diffusion\" strategy which can handle input\ntrajectories with various noise patterns by first diffusing them to align with\nthe whitened noise space and cleaning via the canonical denoiser. Extensive\nexperiments on four benchmarks with significant domain variations demonstrate\nthe superior effectiveness of our method. GeneOH Diffusion also shows promise\nfor various downstream applications. Project website:\nhttps://meowuu7.github.io/GeneOH-Diffusion/.",
      "tldr_zh": "本文提出 GeneOH Diffusion 方法，用于处理手-物体交互 (HOI) 的去噪问题，旨在修正错误的交互序列（如不自然的手部姿势和手-物体关系），以实现更真实的输出，并提升对新交互和噪声模式的泛化能力。关键创新包括一种基于接触中心的 HOI 表示 GeneOH，以及一个新的去噪方案，结合规范去噪模型和“denoising via diffusion”策略，将噪声数据投影到干净数据流形。实验在四个基准上展示了该方法的优越性能，尤其在领域变化大的场景中，并展示了其在下游应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR 2024. Project website:\n  https://meowuu7.github.io/GeneOH-Diffusion/; Huggingface Demo:\n  https://huggingface.co/spaces/xymeow7/gene-hoi-denoising; Code:\n  https://github.com/Meowuu7/GeneOH-Diffusion",
      "pdf_url": "http://arxiv.org/pdf/2402.14810v1",
      "published_date": "2024-02-22 18:59:21 UTC",
      "updated_date": "2024-02-22 18:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:59:05.283723"
    },
    {
      "arxiv_id": "2402.14809v4",
      "title": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zicheng Lin",
        "Zhibin Gou",
        "Tian Liang",
        "Ruilin Luo",
        "Haowei Liu",
        "Yujiu Yang"
      ],
      "abstract": "The ability of Large Language Models (LLMs) to critique and refine their\nreasoning is crucial for their application in evaluation, feedback provision,\nand self-improvement. This paper introduces CriticBench, a comprehensive\nbenchmark designed to assess LLMs' abilities to critique and rectify their\nreasoning across a variety of tasks. CriticBench encompasses five reasoning\ndomains: mathematical, commonsense, symbolic, coding, and algorithmic. It\ncompiles 15 datasets and incorporates responses from three LLM families.\nUtilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in\ngeneration, critique, and correction reasoning, i.e., GQC reasoning. Our\nfindings reveal: (1) a linear relationship in GQC capabilities, with\ncritique-focused training markedly enhancing performance; (2) a task-dependent\nvariation in correction effectiveness, with logic-oriented tasks being more\namenable to correction; (3) GQC knowledge inconsistencies that decrease as\nmodel size increases; and (4) an intriguing inter-model critiquing dynamic,\nwhere stronger models are better at critiquing weaker ones, while weaker models\ncan surprisingly surpass stronger ones in their self-critique. We hope these\ninsights into the nuanced critique-correct reasoning of LLMs will foster\nfurther research in LLM critique and self-improvement.",
      "tldr_zh": "本论文引入CriticBench，一种全面基准测试，用于评估大型语言模型(LLMs)在生成、批评和修正推理(GQC reasoning)方面的能力，涵盖数学、常识、符号、编码和算法等五个领域，并整合15个数据集和三个LLM家族的响应。研究评估了17个LLMs的性能，发现批评焦点训练能显著提升GQC能力，修正效果因任务而异（逻辑导向任务更易改进），且模型规模增大可减少GQC知识不一致性，同时揭示了模型间动态：更强模型更擅长批评弱模型，而弱模型在自我批评中可能表现更佳。这些见解有望推动LLMs批评和自我改进的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.14809v4",
      "published_date": "2024-02-22 18:59:02 UTC",
      "updated_date": "2024-06-01 07:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:59:17.168716"
    },
    {
      "arxiv_id": "2402.14905v2",
      "title": "MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Zechun Liu",
        "Changsheng Zhao",
        "Forrest Iandola",
        "Chen Lai",
        "Yuandong Tian",
        "Igor Fedorov",
        "Yunyang Xiong",
        "Ernie Chang",
        "Yangyang Shi",
        "Raghuraman Krishnamoorthi",
        "Liangzhen Lai",
        "Vikas Chandra"
      ],
      "abstract": "This paper addresses the growing need for efficient large language models\n(LLMs) on mobile devices, driven by increasing cloud costs and latency\nconcerns. We focus on designing top-quality LLMs with fewer than a billion\nparameters, a practical choice for mobile deployment. Contrary to prevailing\nbelief emphasizing the pivotal role of data and parameter quantity in\ndetermining model quality, our investigation underscores the significance of\nmodel architecture for sub-billion scale LLMs. Leveraging deep and thin\narchitectures, coupled with embedding sharing and grouped-query attention\nmechanisms, we establish a strong baseline network denoted as MobileLLM, which\nattains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M\nstate-of-the-art models. Additionally, we propose an immediate block-wise\nweight-sharing approach with no increase in model size and only marginal\nlatency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a\nfurther accuracy enhancement of 0.7%/0.8% than MobileLLM 125M/350M. Moreover,\nMobileLLM model family shows significant improvements compared to previous\nsub-billion models on chat benchmarks, and demonstrates close correctness to\nLLaMA-v2 7B in API calling tasks, highlighting the capability of small models\nfor common on-device use cases.",
      "tldr_zh": "本论文针对移动设备上部署大型语言模型 (LLMs) 的需求，优化了少于10亿参数的模型，以降低云端成本和延迟问题。研究强调模型架构的重要性，而非数据或参数数量，通过采用深而窄架构、嵌入共享和grouped-query attention机制，开发了MobileLLM基线模型，该模型比之前的125M/350M模型提高了2.7%/4.3%的准确率。此外，提出block-wise weight-sharing方法，进一步提升MobileLLM-LS模型的准确率（125M/350M版本分别增加0.7%/0.8%），并在聊天基准上显著优于现有亚十亿模型，在API调用任务中接近LLaMA-v2 7B的性能。这些优化突出了小模型在设备端应用的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024. Code is available at\n  https://github.com/facebookresearch/MobileLLM",
      "pdf_url": "http://arxiv.org/pdf/2402.14905v2",
      "published_date": "2024-02-22 18:58:55 UTC",
      "updated_date": "2024-06-27 03:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:59:28.820620"
    },
    {
      "arxiv_id": "2402.14807v4",
      "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Behari",
        "Edwin Zhang",
        "Yunfan Zhao",
        "Aparna Taneja",
        "Dheeraj Nagaraj",
        "Milind Tambe"
      ],
      "abstract": "Restless multi-armed bandits (RMAB) have demonstrated success in optimizing\nresource allocation for large beneficiary populations in public health\nsettings. Unfortunately, RMAB models lack flexibility to adapt to evolving\npublic health policy priorities. Concurrently, Large Language Models (LLMs)\nhave emerged as adept automated planners across domains of robotic control and\nnavigation. In this paper, we propose a Decision Language Model (DLM) for\nRMABs, enabling dynamic fine-tuning of RMAB policies in public health settings\nusing human-language commands. We propose using LLMs as automated planners to\n(1) interpret human policy preference prompts, (2) propose reward functions as\ncode for a multi-agent RMAB environment, and (3) iterate on the generated\nreward functions using feedback from grounded RMAB simulations. We illustrate\nthe application of DLM in collaboration with ARMMAN, an India-based non-profit\npromoting preventative care for pregnant mothers, that currently relies on RMAB\npolicies to optimally allocate health worker calls to low-resource populations.\nWe conduct a technology demonstration in simulation using the Gemini Pro model,\nshowing DLM can dynamically shape policy outcomes using only human prompts as\ninput.",
      "tldr_zh": "该论文提出 Decision Language Model (DLM)，一种将 Large Language Models (LLMs) 整合到 Restless Multi-Armed Bandits (RMAB) 中的框架，用于动态调整公共卫生资源分配策略，以适应不断变化的政策优先级。DLM 通过 LLMs 作为自动化规划器，解释人类语言提示、生成奖励函数代码，并利用 RMAB 模拟反馈进行迭代优化，从而实现灵活的政策微调。研究与印度非营利组织 ARMMAN 合作，在模拟环境中使用 Gemini Pro 模型演示，显示 DLM 仅凭人类提示即可动态塑造健康工作者通话分配策略，提升了 RMAB 的适应性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14807v4",
      "published_date": "2024-02-22 18:58:27 UTC",
      "updated_date": "2024-10-25 13:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:59:40.962722"
    },
    {
      "arxiv_id": "2402.14805v1",
      "title": "Identifying Multiple Personalities in Large Language Models with External Evaluation",
      "title_zh": "使用外部评估识别大型语言模型中的多种人格",
      "authors": [
        "Xiaoyang Song",
        "Yuta Adachi",
        "Jessie Feng",
        "Mouwei Lin",
        "Linhao Yu",
        "Frank Li",
        "Akshat Gupta",
        "Gopala Anumanchipalli",
        "Simerjot Kaur"
      ],
      "abstract": "As Large Language Models (LLMs) are integrated with human daily applications\nrapidly, many societal and ethical concerns are raised regarding the behavior\nof LLMs. One of the ways to comprehend LLMs' behavior is to analyze their\npersonalities. Many recent studies quantify LLMs' personalities using\nself-assessment tests that are created for humans. Yet many critiques question\nthe applicability and reliability of these self-assessment tests when applied\nto LLMs. In this paper, we investigate LLM personalities using an alternate\npersonality measurement method, which we refer to as the external evaluation\nmethod, where instead of prompting LLMs with multiple-choice questions in the\nLikert scale, we evaluate LLMs' personalities by analyzing their responses\ntoward open-ended situational questions using an external machine learning\nmodel. We first fine-tuned a Llama2-7B model as the MBTI personality predictor\nthat outperforms the state-of-the-art models as the tool to analyze LLMs'\nresponses. Then, we prompt the LLMs with situational questions and ask them to\ngenerate Twitter posts and comments, respectively, in order to assess their\npersonalities when playing two different roles. Using the external personality\nevaluation method, we identify that the obtained personality types for LLMs are\nsignificantly different when generating posts versus comments, whereas humans\nshow a consistent personality profile in these two different situations. This\nshows that LLMs can exhibit different personalities based on different\nscenarios, thus highlighting a fundamental difference between personality in\nLLMs and humans. With our work, we call for a re-evaluation of personality\ndefinition and measurement in LLMs.",
      "tldr_zh": "本文提出了一种外部评估方法（external evaluation method），用于识别 Large Language Models (LLMs) 的多重个性，通过分析 LLMs 对开放式情境问题的响应，而非传统的自我评估测试。研究团队微调了 Llama2-7B 模型作为 MBTI 个性预测器，并让 LLMs 生成 Twitter 帖子和评论，以评估其在不同角色下的个性表现。结果显示，LLMs 在生成帖子和评论时表现出显著不同的个性类型，与人类在类似情境下的一致性形成鲜明对比，这突显了 LLMs 个性与人类之间的根本差异。作者呼吁重新定义和测量 LLMs 中的个性，以应对其社会和伦理挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14805v1",
      "published_date": "2024-02-22 18:57:20 UTC",
      "updated_date": "2024-02-22 18:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T08:59:54.162898"
    },
    {
      "arxiv_id": "2402.14804v1",
      "title": "Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset",
      "title_zh": "利用 MATH-Vision 数据集测量多模态数学推理",
      "authors": [
        "Ke Wang",
        "Junting Pan",
        "Weikang Shi",
        "Zimu Lu",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "abstract": "Recent advancements in Large Multimodal Models (LMMs) have shown promising\nresults in mathematical reasoning within visual contexts, with models\napproaching human-level performance on existing benchmarks such as MathVista.\nHowever, we observe significant limitations in the diversity of questions and\nbreadth of subjects covered by these benchmarks. To address this issue, we\npresent the MATH-Vision (MATH-V) dataset, a meticulously curated collection of\n3,040 high-quality mathematical problems with visual contexts sourced from real\nmath competitions. Spanning 16 distinct mathematical disciplines and graded\nacross 5 levels of difficulty, our dataset provides a comprehensive and diverse\nset of challenges for evaluating the mathematical reasoning abilities of LMMs.\nThrough extensive experimentation, we unveil a notable performance gap between\ncurrent LMMs and human performance on MATH-V, underscoring the imperative for\nfurther advancements in LMMs. Moreover, our detailed categorization allows for\na thorough error analysis of LMMs, offering valuable insights to guide future\nresearch and development. The project is available at\nhttps://mathvision-cuhk.github.io",
      "tldr_zh": "本研究介绍了 MATH-Vision (MATH-V) 数据集，该数据集包含 3,040 个高质量数学问题，旨在解决现有基准如 MathVista 在问题多样性和主题广度上的局限性。MATH-V 涵盖 16 个数学学科、5 个难度级别，并结合视觉上下文，源自真实数学竞赛，用于评估 Large Multimodal Models (LMMs) 的多模态数学推理能力。通过实验发现，当前 LMMs 在 MATH-V 上与人类性能存在显著差距，并通过详细分类进行错误分析，为 LMMs 的未来研究提供宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "math.HO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14804v1",
      "published_date": "2024-02-22 18:56:38 UTC",
      "updated_date": "2024-02-22 18:56:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:00:03.861590"
    },
    {
      "arxiv_id": "2402.14800v2",
      "title": "Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Lu",
        "Qi Liu",
        "Yuhui Xu",
        "Aojun Zhou",
        "Siyuan Huang",
        "Bo Zhang",
        "Junchi Yan",
        "Hongsheng Li"
      ],
      "abstract": "A pivotal advancement in the progress of large language models (LLMs) is the\nemergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs,\nMoE LLMs can achieve higher performance with fewer parameters, but it is still\nhard to deploy them due to their immense parameter sizes. Different from\nprevious weight pruning methods that rely on specifically designed hardware,\nthis paper mainly aims to enhance the deployment efficiency of MoE LLMs by\nintroducing plug-and-play expert-level sparsification techniques. Specifically,\nwe propose, for the first time to our best knowledge, post-training approaches\nfor task-agnostic and task-specific expert pruning and skipping of MoE LLMs,\ntailored to improve deployment efficiency while maintaining model performance\nacross a wide range of tasks. Extensive experiments show that our proposed\nmethods can simultaneously reduce model sizes and increase the inference speed,\nwhile maintaining satisfactory performance. Data and code will be available at\nhttps://github.com/Lucky-Lance/Expert_Sparsity.",
      "tldr_zh": "这项研究针对Mixture-of-Experts (MoE)大型语言模型(MoE LLMs)提出高效的专家修剪和跳过技术，以解决其庞大参数导致的部署难题。这些方法首次引入后训练的专家级稀疏化策略，包括task-agnostic和task-specific专家pruning和skipping，旨在在不依赖特定硬件的情况下优化模型性能。实验结果显示，该方法能同时减少模型大小、提升推理速度，同时保持在广泛任务上的满意表现。总之，这为MoE LLMs的实际部署提供了可插拔的改进方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Mixture-of-Experts Large Language Models, ACL2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14800v2",
      "published_date": "2024-02-22 18:56:07 UTC",
      "updated_date": "2024-05-30 16:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:00:17.167892"
    },
    {
      "arxiv_id": "2402.14904v2",
      "title": "Watermarking Makes Language Models Radioactive",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Sander",
        "Pierre Fernandez",
        "Alain Durmus",
        "Matthijs Douze",
        "Teddy Furon"
      ],
      "abstract": "We investigate the radioactivity of text generated by large language models\n(LLM), i.e. whether it is possible to detect that such synthetic input was used\nto train a subsequent LLM. Current methods like membership inference or active\nIP protection either work only in settings where the suspected text is known or\ndo not provide reliable statistical guarantees. We discover that, on the\ncontrary, it is possible to reliably determine if a language model was trained\non synthetic data if that data is output by a watermarked LLM. Our new methods,\nspecialized for radioactivity, detects with a provable confidence weak\nresiduals of the watermark signal in the fine-tuned LLM. We link the\nradioactivity contamination level to the following properties: the watermark\nrobustness, its proportion in the training set, and the fine-tuning process.\nFor instance, if the suspect model is open-weight, we demonstrate that training\non watermarked instructions can be detected with high confidence ($p$-value $<\n10^{-5}$) even when as little as $5\\%$ of training text is watermarked.",
      "tldr_zh": "该研究探讨了大型语言模型（LLM）生成文本的“放射性”，即是否能检测到这些合成文本被用于训练后续LLM。现有方法如membership inference或active IP protection要么仅适用于已知文本，要么缺乏可靠统计保证。论文提出了一种新方法，专注于watermark（水印）信号的弱残留，能够以可证明置信度检测LLM是否训练在watermarked文本上，并将放射性污染水平与watermark robustness、水印在训练集的比例以及微调过程相关联。例如，在开源模型中，即使训练文本中只有5%的部分是watermarked，也能以高置信度（p-value < 10^{-5}）进行检测，从而为LLM训练数据来源提供可靠的防护机制。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Published at NeurIPS 2024 (Spotlight). Code at\n  https://github.com/facebookresearch/radioactive-watermark - webpage at\n  https://pierrefdz.github.io/publications/radioactive/",
      "pdf_url": "http://arxiv.org/pdf/2402.14904v2",
      "published_date": "2024-02-22 18:55:22 UTC",
      "updated_date": "2024-10-25 18:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:00:30.548764"
    },
    {
      "arxiv_id": "2402.14798v3",
      "title": "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Weir",
        "Kate Sanders",
        "Orion Weller",
        "Shreya Sharma",
        "Dongwei Jiang",
        "Zhengping Jiang",
        "Bhavana Dalvi Mishra",
        "Oyvind Tafjord",
        "Peter Jansen",
        "Peter Clark",
        "Benjamin Van Durme"
      ],
      "abstract": "Recent language models enable new opportunities for structured reasoning with\ntext, such as the construction of intuitive, proof-like textual entailment\ntrees without relying on brittle formal logic. However, progress in this\ndirection has been hampered by a long-standing lack of a clear protocol for\ndetermining what valid compositional entailment is. This absence causes noisy\ndatasets and limited performance gains by modern neuro-symbolic engines. To\naddress these problems, we formulate a consistent and theoretically grounded\napproach to annotating decompositional entailment and evaluate its impact on\nLLM-based textual inference. We find that our new dataset, RDTE (Recognizing\nDecompositional Textual Entailment), has a substantially higher internal\nconsistency (+9%) than prior decompositional entailment datasets. We also find\nthat training an RDTE-oriented entailment classifier via knowledge distillation\nand employing it in an entailment tree reasoning engine significantly improves\nboth accuracy and proof quality, illustrating the practical benefit of this\nadvance for textual inference.",
      "tldr_zh": "该论文针对自然语言推理(Natural Language Inference)中的问题，提出使用非形式逻辑(Informal Logic)来增强系统化的分解文本蕴涵过程，以解决数据集噪声和性能提升有限的挑战。研究者创建了新数据集RDTE (Recognizing Decompositional Textual Entailment)，其内部一致性比现有数据集高9%。通过知识蒸馏(knowledge distillation)训练一个RDTE导向的蕴涵分类器，并将其应用于蕴涵树(entailment trees)推理引擎，显著提高了准确性和证明质量，展示了这一方法的实际益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14798v3",
      "published_date": "2024-02-22 18:55:17 UTC",
      "updated_date": "2024-08-12 23:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:00:41.559802"
    },
    {
      "arxiv_id": "2402.14797v1",
      "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Willi Menapace",
        "Aliaksandr Siarohin",
        "Ivan Skorokhodov",
        "Ekaterina Deyneka",
        "Tsai-Shien Chen",
        "Anil Kag",
        "Yuwei Fang",
        "Aleksei Stoliar",
        "Elisa Ricci",
        "Jian Ren",
        "Sergey Tulyakov"
      ],
      "abstract": "Contemporary models for generating images show remarkable quality and\nversatility. Swayed by these advantages, the research community repurposes them\nto generate videos. Since video content is highly redundant, we argue that\nnaively bringing advances of image models to the video generation domain\nreduces motion fidelity, visual quality and impairs scalability. In this work,\nwe build Snap Video, a video-first model that systematically addresses these\nchallenges. To do that, we first extend the EDM framework to take into account\nspatially and temporally redundant pixels and naturally support video\ngeneration. Second, we show that a U-Net - a workhorse behind image generation\n- scales poorly when generating videos, requiring significant computational\noverhead. Hence, we propose a new transformer-based architecture that trains\n3.31 times faster than U-Nets (and is ~4.5 faster at inference). This allows us\nto efficiently train a text-to-video model with billions of parameters for the\nfirst time, reach state-of-the-art results on a number of benchmarks, and\ngenerate videos with substantially higher quality, temporal consistency, and\nmotion complexity. The user studies showed that our model was favored by a\nlarge margin over the most recent methods. See our website at\nhttps://snap-research.github.io/snapvideo/.",
      "tldr_zh": "该研究指出，现有的图像生成模型应用于视频生成时，会因忽略视频的空间和时间冗余而降低运动保真度、视觉质量和可扩展性。为此，论文提出 Snap Video，一种视频优先的模型，通过扩展 EDM 框架来处理冗余像素并支持视频生成，并引入新的基于 Transformer 的架构，比 U-Net 训练快 3.31 倍、推理快 4.5 倍，从而高效训练首个拥有数十亿参数的 text-to-video 模型。实验结果显示，Snap Video 在多个基准上达到最先进水平，生成视频的质量更高、时间一致性更强、运动复杂度更佳，且用户研究表明它大幅优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14797v1",
      "published_date": "2024-02-22 18:55:08 UTC",
      "updated_date": "2024-02-22 18:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:00:55.748754"
    },
    {
      "arxiv_id": "2402.14789v1",
      "title": "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Johnathan Xie",
        "Yoonho Lee",
        "Annie S. Chen",
        "Chelsea Finn"
      ],
      "abstract": "Self-supervised learning excels in learning representations from large\namounts of unlabeled data, demonstrating success across multiple data\nmodalities. Yet, extending self-supervised learning to new modalities is\nnon-trivial because the specifics of existing methods are tailored to each\ndomain, such as domain-specific augmentations which reflect the invariances in\nthe target task. While masked modeling is promising as a domain-agnostic\nframework for self-supervised learning because it does not rely on input\naugmentations, its mask sampling procedure remains domain-specific. We present\nSelf-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling\nmethod. SMA trains an attention based model using a masked modeling objective,\nby learning masks to sample without any domain-specific assumptions. We\nevaluate SMA on three self-supervised learning benchmarks in protein biology,\nchemical property prediction, and particle physics. We find SMA is capable of\nlearning representations without domain-specific knowledge and achieves\nstate-of-the-art performance on these three benchmarks.",
      "tldr_zh": "该研究提出了一种名为 Self-Guided Masked Autoencoders (SMA) 的方法，用于实现领域无关的 Self-Supervised Learning。SMA 通过训练一个基于注意力的模型，使用掩码建模目标来自动学习掩码采样策略，而不依赖任何领域特定的假设或增强操作。实验在蛋白生物学、化学属性预测和粒子物理学的三个基准上进行，结果显示 SMA 能够在缺乏领域知识的情况下学习有效表示，并达到这些任务的最先进性能。整体上，该方法为扩展自监督学习到新领域提供了通用框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14789v1",
      "published_date": "2024-02-22 18:46:22 UTC",
      "updated_date": "2024-02-22 18:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:01:05.370855"
    },
    {
      "arxiv_id": "2402.14781v3",
      "title": "Effective Bayesian Causal Inference via Structural Marginalisation and Autoregressive Orders",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Toth",
        "Christian Knoll",
        "Franz Pernkopf",
        "Robert Peharz"
      ],
      "abstract": "The traditional two-stage approach to causal inference first identifies a\nsingle causal model (or equivalence class of models), which is then used to\nanswer causal queries. However, this neglects any epistemic model uncertainty.\nIn contrast, Bayesian causal inference does incorporate epistemic uncertainty\ninto query estimates via Bayesian marginalisation (posterior averaging) over\nall causal models. While principled, this marginalisation over entire causal\nmodels, i.e., both causal structures (graphs) and mechanisms, poses a\ntremendous computational challenge. In this work, we address this challenge by\ndecomposing structure marginalisation into the marginalisation over (i) causal\norders and (ii) directed acyclic graphs (DAGs) given an order. We can\nmarginalise the latter in closed form by limiting the number of parents per\nvariable and utilising Gaussian processes to model mechanisms. To marginalise\nover orders, we use a sampling-based approximation, for which we devise a novel\nauto-regressive distribution over causal orders (ARCO). Our method outperforms\nstate-of-the-art in structure learning on simulated non-linear additive noise\nbenchmarks, and yields competitive results on real-world data. Furthermore, we\ncan accurately infer interventional distributions and average causal effects.",
      "tldr_zh": "这篇论文提出了一种有效的Bayesian因果推理方法，通过结构边缘化（structural marginalisation）和自回归顺序（autoregressive orders）来处理传统因果模型不确定性的计算挑战。具体而言，该方法将边缘化分解为对因果顺序和给定顺序的DAG（directed acyclic graphs）的边缘化，利用Gaussian processes建模机制并限制每个变量的父节点数量，同时引入ARCO（autoregressive distribution over causal orders）进行采样近似。实验结果显示，该方法在模拟非线性加性噪声基准上优于现有结构学习技术，并在真实数据上表现出色，能够准确推断干预分布和平均因果效应。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages + references + appendices (37 pages total)",
      "pdf_url": "http://arxiv.org/pdf/2402.14781v3",
      "published_date": "2024-02-22 18:39:24 UTC",
      "updated_date": "2025-04-23 11:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:01:18.558711"
    },
    {
      "arxiv_id": "2402.14778v2",
      "title": "Zero-shot cross-lingual transfer in instruction tuning of large language models",
      "title_zh": "零样本跨语言迁移在大语言模型指令微调中的应用",
      "authors": [
        "Nadezhda Chirkova",
        "Vassilina Nikoulina"
      ],
      "abstract": "Instruction tuning (IT) is widely used to teach pretrained large language\nmodels (LLMs) to follow arbitrary instructions, but is under-studied in\nmultilingual settings. In this work, we conduct a systematic study of zero-shot\ncross-lingual transfer in IT, when an LLM is instruction-tuned on English-only\ndata and then tested on user prompts in other languages. We advocate for the\nimportance of evaluating various aspects of model responses in multilingual\ninstruction following and investigate the influence of different model\nconfiguration choices. We find that cross-lingual transfer does happen\nsuccessfully in IT even if all stages of model training are English-centric,\nbut only if multiliguality is taken into account in hyperparameter tuning and\nwith large enough IT data. English-trained LLMs are capable of generating\ncorrect-language, comprehensive and helpful responses in other languages, but\nsuffer from low factuality and may occasionally have fluency errors.",
      "tldr_zh": "这篇论文系统研究了大型语言模型（LLMs）的指令微调（Instruction Tuning, IT）中零样本跨语言转移的效果，即模型仅在英语数据上训练后，在其他语言的用户提示上进行测试。研究强调了评估模型响应在多语言指令遵循方面的多维度重要性，并发现跨语言转移可成功实现，但需在超参数调整中考虑多语言因素并使用足够大的IT数据。结果显示，英语训练的LLMs能生成正确语言、全面且有帮助的响应，但常面临事实准确性低和流畅性错误的问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14778v2",
      "published_date": "2024-02-22 18:37:33 UTC",
      "updated_date": "2024-04-22 10:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:01:29.885654"
    },
    {
      "arxiv_id": "2402.14762v3",
      "title": "MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Bai",
        "Jie Liu",
        "Xingyuan Bu",
        "Yancheng He",
        "Jiaheng Liu",
        "Zhanhui Zhou",
        "Zhuoran Lin",
        "Wenbo Su",
        "Tiezheng Ge",
        "Bo Zheng",
        "Wanli Ouyang"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has drastically enhanced dialogue\nsystems. However, comprehensively evaluating the dialogue abilities of LLMs\nremains a challenge. Previous benchmarks have primarily focused on single-turn\ndialogues or provided coarse-grained and incomplete assessments of multi-turn\ndialogues, overlooking the complexity and fine-grained nuances of real-life\ndialogues. To address this issue, we introduce MT-Bench-101, specifically\ndesigned to evaluate the fine-grained abilities of LLMs in multi-turn\ndialogues. By conducting a detailed analysis of real multi-turn dialogue data,\nwe construct a three-tier hierarchical ability taxonomy comprising 4208 turns\nacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21\npopular LLMs based on MT-Bench-101, conducting comprehensive analyses from both\nability and task perspectives and observing differing trends in LLMs\nperformance across dialogue turns within various tasks. Further analysis\nindicates that neither utilizing common alignment techniques nor chat-specific\ndesigns has led to obvious enhancements in the multi-turn abilities of LLMs.\nExtensive case studies suggest that our designed tasks accurately assess the\ncorresponding multi-turn abilities. The data and code are available at\n\\url{https://github.com/mtbench101/mt-bench-101}.",
      "tldr_zh": "该研究引入了 MT-Bench-101，这是一个细粒度基准，用于评估大型语言模型 (LLMs) 在多轮对话中的能力，旨在解决现有基准对单轮对话的偏重和对多轮对话的粗略评估问题。通过分析真实多轮对话数据，论文构建了一个三层层次能力分类，涵盖 1388 个多轮对话、4208 个回合和 13 个任务。评估结果显示，21 个热门 LLMs 在不同任务中的性能存在差异趋势，且常见的对齐技术和聊天设计并未显著提升多轮能力。广泛的案例研究证实了该基准的有效性，并提供了数据和代码资源以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "[ACL 2024] The first three authors contribute equally, 34 pages, repo\n  at https://github.com/mtbench101/mt-bench-101",
      "pdf_url": "http://arxiv.org/pdf/2402.14762v3",
      "published_date": "2024-02-22 18:21:59 UTC",
      "updated_date": "2024-11-05 16:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:01:42.689182"
    },
    {
      "arxiv_id": "2402.14759v1",
      "title": "Generalising realisability in statistical learning theory under epistemic uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Fabio Cuzzolin"
      ],
      "abstract": "The purpose of this paper is to look into how central notions in statistical\nlearning theory, such as realisability, generalise under the assumption that\ntrain and test distribution are issued from the same credal set, i.e., a convex\nset of probability distributions. This can be considered as a first step\ntowards a more general treatment of statistical learning under epistemic\nuncertainty.",
      "tldr_zh": "这篇论文探讨了统计学习理论中 realisability 等核心概念在认识论不确定性（epistemic uncertainty）下的推广，假设 train 和 test 分布均来自同一个 credal set（即一个凸集的概率分布）。通过这一假设，论文旨在为统计学习理论提供更一般的框架，以应对不确定性挑战。最终，这被视为在 epistemic uncertainty 下处理统计学习的初步步骤，为未来研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2401.09435",
      "pdf_url": "http://arxiv.org/pdf/2402.14759v1",
      "published_date": "2024-02-22 18:20:25 UTC",
      "updated_date": "2024-02-22 18:20:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:01:52.956824"
    },
    {
      "arxiv_id": "2402.14758v2",
      "title": "Batch and match: black-box variational inference with a score-based divergence",
      "title_zh": "翻译失败",
      "authors": [
        "Diana Cai",
        "Chirag Modi",
        "Loucas Pillaud-Vivien",
        "Charles C. Margossian",
        "Robert M. Gower",
        "David M. Blei",
        "Lawrence K. Saul"
      ],
      "abstract": "Most leading implementations of black-box variational inference (BBVI) are\nbased on optimizing a stochastic evidence lower bound (ELBO). But such\napproaches to BBVI often converge slowly due to the high variance of their\ngradient estimates and their sensitivity to hyperparameters. In this work, we\npropose batch and match (BaM), an alternative approach to BBVI based on a\nscore-based divergence. Notably, this score-based divergence can be optimized\nby a closed-form proximal update for Gaussian variational families with full\ncovariance matrices. We analyze the convergence of BaM when the target\ndistribution is Gaussian, and we prove that in the limit of infinite batch size\nthe variational parameter updates converge exponentially quickly to the target\nmean and covariance. We also evaluate the performance of BaM on Gaussian and\nnon-Gaussian target distributions that arise from posterior inference in\nhierarchical and deep generative models. In these experiments, we find that BaM\ntypically converges in fewer (and sometimes significantly fewer) gradient\nevaluations than leading implementations of BBVI based on ELBO maximization.",
      "tldr_zh": "本文提出了一种新的黑箱变分推断（BBVI）方法，名为batch and match (BaM)，它基于score-based divergence，以解决传统基于evidence lower bound (ELBO)的BBVI在梯度估计方差高和超参数敏感性方面的收敛问题。对于高斯变分家族，BaM可通过闭式形式近端更新进行优化，并证明在无限批量大小下，其参数更新会指数快速收敛到目标均值和协方差。实验显示，在高斯和非高斯目标分布（如分层和深度生成模型的后验推断）上，BaM通常在更少的梯度评估中收敛，比领先的ELBO优化方法高效。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.CO"
      ],
      "primary_category": "stat.ML",
      "comment": "49 pages, 14 figures. To appear in the Proceedings of the 41st\n  International Conference on Machine Learning (ICML), 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14758v2",
      "published_date": "2024-02-22 18:20:22 UTC",
      "updated_date": "2024-06-12 16:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:02:06.911794"
    },
    {
      "arxiv_id": "2402.14757v1",
      "title": "SHM-Traffic: DRL and Transfer learning based UAV Control for Structural Health Monitoring of Bridges with Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Divija Swetha Gadiraju",
        "Saeed Eftekhar Azam",
        "Deepak Khazanchi"
      ],
      "abstract": "This work focuses on using advanced techniques for structural health\nmonitoring (SHM) for bridges with Traffic. We propose an approach using deep\nreinforcement learning (DRL)-based control for Unmanned Aerial Vehicle (UAV).\nOur approach conducts a concrete bridge deck survey while traffic is ongoing\nand detects cracks. The UAV performs the crack detection, and the location of\ncracks is initially unknown. We use two edge detection techniques. First, we\nuse canny edge detection for crack detection. We also use a Convolutional\nNeural Network (CNN) for crack detection and compare it with canny edge\ndetection. Transfer learning is applied using CNN with pre-trained weights\nobtained from a crack image dataset. This enables the model to adapt and\nimprove its performance in identifying and localizing cracks. Proximal Policy\nOptimization (PPO) is applied for UAV control and bridge surveys. The\nexperimentation across various scenarios is performed to evaluate the\nperformance of the proposed methodology. Key metrics such as task completion\ntime and reward convergence are observed to gauge the effectiveness of the\napproach. We observe that the Canny edge detector offers up to 40\\% lower task\ncompletion time, while the CNN excels in up to 12\\% better damage detection and\n1.8 times better rewards.",
      "tldr_zh": "本研究提出SHM-Traffic框架，利用深度强化学习(DRL)和转移学习(Transfer learning)来控制无人驾驶飞机(UAV)，以实现桥梁结构健康监测(SHM)，特别是在交通繁忙条件下的混凝土桥面调查和裂缝检测。方法包括使用Canny edge detection和Convolutional Neural Network (CNN)进行裂缝检测，其中CNN通过预训练权重和Transfer learning优化了识别性能，而Proximal Policy Optimization (PPO)算法用于UAV的路径控制和任务执行。实验结果显示，Canny edge detection可将任务完成时间降低高达40%，而CNN在损伤检测准确率上提升高达12%，并获得1.8倍的奖励改善，从而证明了该方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14757v1",
      "published_date": "2024-02-22 18:19:45 UTC",
      "updated_date": "2024-02-22 18:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:02:18.155315"
    },
    {
      "arxiv_id": "2402.14753v1",
      "title": "Prompting a Pretrained Transformer Can Be a Universal Approximator",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandar Petrov",
        "Philip H. S. Torr",
        "Adel Bibi"
      ],
      "abstract": "Despite the widespread adoption of prompting, prompt tuning and prefix-tuning\nof transformer models, our theoretical understanding of these fine-tuning\nmethods remains limited. A key question is whether one can arbitrarily modify\nthe behavior of pretrained model by prompting or prefix-tuning it. Formally,\nwhether prompting and prefix-tuning a pretrained model can universally\napproximate sequence-to-sequence functions. This paper answers in the\naffirmative and demonstrates that much smaller pretrained models than\npreviously thought can be universal approximators when prefixed. In fact, the\nattention mechanism is uniquely suited for universal approximation with\nprefix-tuning a single attention head being sufficient to approximate any\ncontinuous function. Moreover, any sequence-to-sequence function can be\napproximated by prefixing a transformer with depth linear in the sequence\nlength. Beyond these density-type results, we also offer Jackson-type bounds on\nthe length of the prefix needed to approximate a function to a desired\nprecision.",
      "tldr_zh": "本研究证明，通过提示（prompting）和前缀微调（prefix-tuning），预训练的Transformer模型可以成为通用逼近器，能够任意逼近序列到序列函数（sequence-to-sequence functions）。论文发现，即使是比之前认为更小的预训练模型，通过添加前缀也能实现这一功能，且仅需一个注意力头（attention head）即可逼近任何连续函数。进一步，任何序列到序列函数可以通过深度线性于序列长度的Transformer前缀来逼近，并提供了Jackson-type bounds来量化所需前缀长度的精确界限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.FA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14753v1",
      "published_date": "2024-02-22 18:12:48 UTC",
      "updated_date": "2024-02-22 18:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:02:30.229895"
    },
    {
      "arxiv_id": "2402.14901v2",
      "title": "A Usage-centric Take on Intent Understanding in E-Commerce",
      "title_zh": "翻译失败",
      "authors": [
        "Wendi Zhou",
        "Tianyi Li",
        "Pavlos Vougiouklis",
        "Mark Steedman",
        "Jeff Z. Pan"
      ],
      "abstract": "Identifying and understanding user intents is a pivotal task for E-Commerce.\nDespite its essential role in product recommendation and business user\nprofiling analysis, intent understanding has not been consistently defined or\naccurately benchmarked. In this paper, we focus on predicative user intents as\n\"how a customer uses a product\", and pose intent understanding as a natural\nlanguage reasoning task, independent of product ontologies. We identify two\nweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:\ncategory-rigidity and property-ambiguity. They limit its ability to strongly\nalign user intents with products having the most desirable property, and to\nrecommend useful products across diverse categories. Following these\nobservations, we introduce a Product Recovery Benchmark featuring a novel\nevaluation framework and an example dataset. We further validate the above\nFolkScope weaknesses on this benchmark. Our code and dataset are available at\nhttps://github.com/stayones/Usgae-Centric-Intent-Understanding.",
      "tldr_zh": "本论文从用户使用角度重新定义电商中的意图理解(intent understanding)，将之视为独立于产品本体的自然语言推理任务(natural language reasoning task)，旨在更好地识别用户意图如“如何使用产品”以提升产品推荐和用户画像分析。论文指出了现有SOTA模型FolkScope的两个主要弱点：category-rigidity（类别刚性）和property-ambiguity（属性模糊），这些问题导致模型难以将用户意图与最合适的产品匹配，并跨类别推荐产品。为此，作者引入了Product Recovery Benchmark，包括一个新颖的评估框架和示例数据集，并在该基准上验证了FolkScope的局限性。代码和数据集已公开在GitHub上，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Acepted by EMNLP 2024 main",
      "pdf_url": "http://arxiv.org/pdf/2402.14901v2",
      "published_date": "2024-02-22 18:09:33 UTC",
      "updated_date": "2024-10-07 16:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:02:42.246341"
    },
    {
      "arxiv_id": "2402.14744v3",
      "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Wang",
        "Renhe Jiang",
        "Chuang Yang",
        "Zengqing Wu",
        "Makoto Onizuka",
        "Ryosuke Shibasaki",
        "Noboru Koshizuka",
        "Chuan Xiao"
      ],
      "abstract": "This paper introduces a novel approach using Large Language Models (LLMs)\nintegrated into an agent framework for flexible and effective personal mobility\ngeneration. LLMs overcome the limitations of previous models by effectively\nprocessing semantic data and offering versatility in modeling various tasks.\nOur approach addresses three research questions: aligning LLMs with real-world\nurban mobility data, developing reliable activity generation strategies, and\nexploring LLM applications in urban mobility. The key technical contribution is\na novel LLM agent framework that accounts for individual activity patterns and\nmotivations, including a self-consistency approach to align LLMs with\nreal-world activity data and a retrieval-augmented strategy for interpretable\nactivity generation. We evaluate our LLM agent framework and compare it with\nstate-of-the-art personal mobility generation approaches, demonstrating the\neffectiveness of our approach and its potential applications in urban mobility.\nOverall, this study marks the pioneering work of designing an LLM agent\nframework for activity generation based on real-world human activity data,\noffering a promising tool for urban mobility analysis.",
      "tldr_zh": "本研究提出了一种创新框架，将大型语言模型（LLMs）整合到代理系统中，模拟城市居民的个人移动性生成，从而克服传统模型在处理语义数据方面的局限性。该框架针对三个关键问题：将LLMs与真实城市移动数据对齐、开发可靠的活动生成策略，以及探索LLMs在城市移动中的应用；其核心贡献包括自一致性方法（self-consistency approach）用于数据对齐，以及检索增强策略（retrieval-augmented strategy）实现可解释的活动生成。实验结果显示，该框架在个人移动性生成任务中优于现有最先进方法，并为城市移动分析提供了一个有前景的工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024. Source codes are available at\n  https://github.com/Wangjw6/LLMob/",
      "pdf_url": "http://arxiv.org/pdf/2402.14744v3",
      "published_date": "2024-02-22 18:03:14 UTC",
      "updated_date": "2024-10-27 20:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:02:54.580518"
    },
    {
      "arxiv_id": "2402.14730v3",
      "title": "Clifford-Steerable Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Maksim Zhdanov",
        "David Ruhe",
        "Maurice Weiler",
        "Ana Lucic",
        "Johannes Brandstetter",
        "Patrick Forré"
      ],
      "abstract": "We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a\nnovel class of $\\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector\nfields on pseudo-Euclidean spaces $\\mathbb{R}^{p,q}$. They cover, for instance,\n$\\mathrm{E}(3)$-equivariance on $\\mathbb{R}^3$ and Poincar\\'e-equivariance on\nMinkowski spacetime $\\mathbb{R}^{1,3}$. Our approach is based on an implicit\nparametrization of $\\mathrm{O}(p,q)$-steerable kernels via Clifford group\nequivariant neural networks. We significantly and consistently outperform\nbaseline methods on fluid dynamics as well as relativistic electrodynamics\nforecasting tasks.",
      "tldr_zh": "本研究提出了一种新型的 Clifford-Steerable Convolutional Neural Networks (CS-CNNs)，这是一种 E(p, q)-equivariant CNNs，用于处理伪欧空间 $\\mathbb{R}^{p,q}$ 上的多矢量场，例如支持 E(3)-equivariance on $\\mathbb{R}^3$ 和 Poincaré-equivariance on Minkowski spacetime $\\mathbb{R}^{1,3}$。该方法通过 Clifford group equivariant neural networks 隐式参数化 O(p,q)-steerable kernels，实现对这些空间的等变处理。实验结果显示，CS-CNNs 在流体动力学以及相对论电动力学预测任务中，显著且一致地优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14730v3",
      "published_date": "2024-02-22 17:42:15 UTC",
      "updated_date": "2024-07-06 16:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:03:06.703578"
    },
    {
      "arxiv_id": "2402.14899v3",
      "title": "Stop Reasoning! When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image",
      "title_zh": "翻译失败",
      "authors": [
        "Zefeng Wang",
        "Zhen Han",
        "Shuo Chen",
        "Fan Xue",
        "Zifeng Ding",
        "Xun Xiao",
        "Volker Tresp",
        "Philip Torr",
        "Jindong Gu"
      ],
      "abstract": "Multimodal LLMs (MLLMs) with a great ability of text and image understanding\nhave received great attention. To achieve better reasoning with MLLMs,\nChain-of-Thought (CoT) reasoning has been widely explored, which further\npromotes MLLMs' explainability by giving intermediate reasoning steps. Despite\nthe strong power demonstrated by MLLMs in multimodal reasoning, recent studies\nshow that MLLMs still suffer from adversarial images. This raises the following\nopen questions: Does CoT also enhance the adversarial robustness of MLLMs? What\ndo the intermediate reasoning steps of CoT entail under adversarial attacks? To\nanswer these questions, we first generalize existing attacks to CoT-based\ninferences by attacking the two main components, i.e., rationale and answer. We\nfind that CoT indeed improves MLLMs' adversarial robustness against the\nexisting attack methods by leveraging the multi-step reasoning process, but not\nsubstantially. Based on our findings, we further propose a novel attack method,\ntermed as stop-reasoning attack, that attacks the model while bypassing the CoT\nreasoning process. Experiments on three MLLMs and two visual reasoning datasets\nverify the effectiveness of our proposed method. We show that stop-reasoning\nattack can result in misled predictions and outperform baseline attacks by a\nsignificant margin.",
      "tldr_zh": "这篇论文探讨了Multimodal LLMs (MLLMs) 在使用Chain-of-Thought (CoT) 推理时，对抗性图像攻击的鲁棒性问题。研究发现，CoT 推理能略微提升 MLLMs 的对抗鲁棒性，但幅度有限；同时，通过泛化现有攻击方法来针对 CoT 的中间步骤（rationale 和 answer），揭示了其潜在弱点。作者提出了一种新颖的 stop-reasoning attack 方法，该方法绕过 CoT 推理过程，导致模型预测误导，并在三个 MLLMs 和两个视觉推理数据集上的实验中，显著优于基线攻击。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14899v3",
      "published_date": "2024-02-22 17:36:34 UTC",
      "updated_date": "2024-09-22 14:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:03:19.249803"
    },
    {
      "arxiv_id": "2402.14728v2",
      "title": "The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success",
      "title_zh": "欧洲对以人为本技术的承诺：HCI 在 EU AI Act 成功中的核心作用",
      "authors": [
        "André Calero Valdez",
        "Moreen Heine",
        "Thomas Franke",
        "Nicole Jochems",
        "Hans-Christian Jetter",
        "Tim Schrills"
      ],
      "abstract": "The evolution of AI is set to profoundly reshape the future. The European\nUnion, recognizing this impending prominence, has enacted the AI Act,\nregulating market access for AI-based systems. A salient feature of the Act is\nto guard democratic and humanistic values by focusing regulation on\ntransparency, explainability, and the human ability to understand and control\nAI systems. Hereby, the EU AI Act does not merely specify technological\nrequirements for AI systems. The EU issues a democratic call for human-centered\nAI systems and, in turn, an interdisciplinary research agenda for\nhuman-centered innovation in AI development. Without robust methods to assess\nAI systems and their effect on individuals and society, the EU AI Act may lead\nto repeating the mistakes of the General Data Protection Regulation of the EU\nand to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more\nconfusion than lending guidance. Moreover, determined research activities in\nHuman-AI interaction will be pivotal for both regulatory compliance and the\nadvancement of AI in a manner that is both ethical and effective. Such an\napproach will ensure that AI development aligns with human values and needs,\nfostering a technology landscape that is innovative, responsible, and an\nintegral part of our society.",
      "tldr_zh": "欧盟通过了 AI Act 来监管 AI 系统，强调透明性、explainability 和人类对 AI 的控制，以保护民主和人文价值。论文指出，该法案不仅仅是技术要求，而是呼吁以人为中心的人工智能发展，并强调 Human-Computer Interaction (HCI) 的跨学科研究在实现这一目标中的关键作用。如果缺乏 robust 的评估方法，AI Act 可能像 General Data Protection Regulation (GDPR) 一样导致混乱和不完善的实施。论文主张加强 Human-AI 交互研究，以确保 AI 符合伦理标准，促进创新和负责任的技术融入社会。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 1 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14728v2",
      "published_date": "2024-02-22 17:35:29 UTC",
      "updated_date": "2024-06-13 14:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:03:30.289495"
    },
    {
      "arxiv_id": "2402.14726v1",
      "title": "Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning",
      "title_zh": "在基于概念的学习框架中，将专家规则整合到神经网络",
      "authors": [
        "Andrei V. Konstantinov",
        "Lev V. Utkin"
      ],
      "abstract": "A problem of incorporating the expert rules into machine learning models for\nextending the concept-based learning is formulated in the paper. It is proposed\nhow to combine logical rules and neural networks predicting the concept\nprobabilities. The first idea behind the combination is to form constraints for\na joint probability distribution over all combinations of concept values to\nsatisfy the expert rules. The second idea is to represent a feasible set of\nprobability distributions in the form of a convex polytope and to use its\nvertices or faces. We provide several approaches for solving the stated problem\nand for training neural networks which guarantee that the output probabilities\nof concepts would not violate the expert rules. The solution of the problem can\nbe viewed as a way for combining the inductive and deductive learning. Expert\nrules are used in a broader sense when any logical function that connects\nconcepts and class labels or just concepts with each other can be regarded as a\nrule. This feature significantly expands the class of the proposed results.\nNumerical examples illustrate the approaches. The code of proposed algorithms\nis publicly available.",
      "tldr_zh": "这篇论文探讨了在概念-based学习框架下，如何将专家规则整合到神经网络中，以扩展模型预测概念概率的能力。研究提出两种关键方法：首先，通过形成约束来确保联合概率分布满足专家规则；其次，将可行概率分布表示为凸 polytope，并利用其顶点或面来训练神经网络，保证输出概率不违反规则。该方法结合了归纳（inductive）和演绎（deductive）学习，扩展了规则的定义（如连接概念和类标签的逻辑函数），并通过数值例子和公开代码进行了验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14726v1",
      "published_date": "2024-02-22 17:33:49 UTC",
      "updated_date": "2024-02-22 17:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:03:42.626858"
    },
    {
      "arxiv_id": "2402.14897v3",
      "title": "Chain-of-Thought Unfaithfulness as Disguised Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Bentham",
        "Nathan Stringham",
        "Ana Marasović"
      ],
      "abstract": "Understanding the extent to which Chain-of-Thought (CoT) generations align\nwith a large language model's (LLM) internal computations is critical for\ndeciding whether to trust an LLM's output. As a proxy for CoT faithfulness,\nLanham et al. (2023) propose a metric that measures a model's dependence on its\nCoT for producing an answer. Within a single family of proprietary models, they\nfind that LLMs exhibit a scaling-then-inverse-scaling relationship between\nmodel size and their measure of faithfulness, and that a 13 billion parameter\nmodel exhibits increased faithfulness compared to models ranging from 810\nmillion to 175 billion parameters in size. We evaluate whether these results\ngeneralize as a property of all LLMs. We replicate the experimental setup in\ntheir section focused on scaling experiments with three different families of\nmodels and, under specific conditions, successfully reproduce the scaling\ntrends for CoT faithfulness they report. However, after normalizing the metric\nto account for a model's bias toward certain answer choices, unfaithfulness\ndrops significantly for smaller less-capable models. This normalized\nfaithfulness metric is also strongly correlated ($R^2$=0.74) with accuracy,\nraising doubts about its validity for evaluating faithfulness.",
      "tldr_zh": "本文研究了Chain-of-Thought (CoT) 生成是否与大型语言模型 (LLMs) 的内部计算一致，并评估了Lanham et al. (2023) 提出的CoT忠实度指标的可扩展性。该指标测量模型对CoT的依赖，但在标准化以校正模型对答案选择的偏好后，较小模型的不忠实度显著降低。该研究通过复制实验于三个不同模型家族中发现，标准化忠实度指标与模型准确率高度相关（R²=0.74），这质疑了原指标评估CoT忠实度的有效性，并暗示不忠实度可能被准确率所掩盖。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "TMLR accepted paper camera-ready version. First two authors\n  contributed equally. 8 pages main, 13 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.14897v3",
      "published_date": "2024-02-22 17:23:53 UTC",
      "updated_date": "2024-06-21 13:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:03:55.651179"
    },
    {
      "arxiv_id": "2402.14714v1",
      "title": "Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models",
      "title_zh": "高效且有效的词汇扩展面向多语言大型语言模型",
      "authors": [
        "Seungduk Kim",
        "Seungtaek Choi",
        "Myeongho Jeong"
      ],
      "abstract": "This report introduces \\texttt{EEVE-Korean-v1.0}, a Korean adaptation of\nlarge language models that exhibit remarkable capabilities across English and\nKorean text understanding. Building on recent highly capable but\nEnglish-centric LLMs, such as SOLAR-10.7B and Phi-2, where non-English texts\nare inefficiently processed with English-centric tokenizers, we present an\nefficient and effective vocabulary expansion (EEVE) method, which encompasses\nparameter freezing and subword initialization. In contrast to previous efforts\nthat believe new embeddings require trillions of training tokens, we show that\nour method can significantly boost non-English proficiency within just 2\nbillion tokens. Surpassing most instruction-tuned LLMs on the Open Ko-LLM\nLeaderboard, as of January 2024, our model \\texttt{EEVE-Korean-10.8B-v1.0}\nranks as the leading Korean pre-trained model in the open-source community,\naccording to Hugging Face's leaderboard. We open-source our models on\nHuggingface to empower the open research community in various languages.",
      "tldr_zh": "本研究提出了一种高效有效的词汇扩展方法（EEVE），用于提升以英语为中心的大型语言模型（LLMs）如 SOLAR-10.7B 和 Phi-2 在处理非英语文本（如韩语）时的性能，通过参数冻结和子词初始化技术，仅需 2 亿训练 tokens 即可显著提高非英语能力，而非传统的数万亿 tokens。EEVE 方法被应用于 EEVE-Korean-v1.0 模型，该模型在 Open Ko-LLM Leaderboard 上超越了大多数指令调整的 LLMs，并成为 Hugging Face 排行榜上领先的开源韩语预训练模型。研究者开源了这些模型，以支持多语言研究社区的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14714v1",
      "published_date": "2024-02-22 17:12:39 UTC",
      "updated_date": "2024-02-22 17:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:04:06.763908"
    },
    {
      "arxiv_id": "2402.14710v3",
      "title": "IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus",
      "title_zh": "翻译失败",
      "authors": [
        "Honghao Gui",
        "Lin Yuan",
        "Hongbin Ye",
        "Ningyu Zhang",
        "Mengshu Sun",
        "Lei Liang",
        "Huajun Chen"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable potential across various\ndomains; however, they exhibit a significant performance gap in Information\nExtraction (IE). Note that high-quality instruction data is the vital key for\nenhancing the specific capabilities of LLMs, while current IE datasets tend to\nbe small in scale, fragmented, and lack standardized schema. To this end, we\nintroduce IEPile, a comprehensive bilingual (English and Chinese) IE\ninstruction corpus, which contains approximately 0.32B tokens. We construct\nIEPile by collecting and cleaning 33 existing IE datasets, and introduce\nschema-based instruction generation to unearth a large-scale corpus.\nExperimentally, IEPile enhance the performance of LLMs for IE, with notable\nimprovements in zero-shot generalization. We open-source the resource and\npre-trained models, hoping to provide valuable support to the NLP community.",
      "tldr_zh": "本论文指出，大型语言模型 (LLMs) 在信息提取 (Information Extraction, IE) 任务上存在显著性能差距，主要由于缺乏高质量的指令数据和标准化 schema。研究者构建了 IEPile，一个规模庞大的双语 (English 和 Chinese) IE 指令语料库，包含约 0.32B tokens，通过收集并清洗 33 个现有数据集，并引入 schema-based instruction generation 方法来生成高质量语料。实验结果显示，IEPile 显著提升了 LLMs 在 IE 任务的性能，特别是零样本泛化 (zero-shot generalization) 能力，并开源了资源和预训练模型，以支持 NLP 社区的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 (short); 21 pages; Github: https://github.com/zjunlp/IEPile",
      "pdf_url": "http://arxiv.org/pdf/2402.14710v3",
      "published_date": "2024-02-22 17:11:38 UTC",
      "updated_date": "2024-05-26 15:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:04:19.188864"
    },
    {
      "arxiv_id": "2402.14708v2",
      "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Duan",
        "Guibin Zhang",
        "Shilong Wang",
        "Xiaojiang Peng",
        "Wang Ziqi",
        "Junyuan Mao",
        "Hao Wu",
        "Xinke Jiang",
        "Kun Wang"
      ],
      "abstract": "Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions.",
      "tldr_zh": "本研究提出了一种新型信用卡欺诈检测方法，CaT-GNN（Causal Temporal Graph Neural Networks），通过因果不变学习（causal invariant learning）揭示交易数据中的内在相关性，以解决传统 Graph Neural Network (GNN) 方法忽略节点局部结构因果效应的局限性。CaT-GNN 将问题分解为发现阶段和干预阶段，其中 Causal-Inspector 利用时间注意机制（temporal attention mechanism）的注意力权重识别因果节点和环境节点，而 Causal-Intervener 通过因果混合策略（causal mixup）增强环境节点的处理，提高模型的鲁棒性和可解释性。在三个数据集（包括一个私有金融数据集和两个公共数据集）的评估中，CaT-GNN 优于现有最先进方法，证明了整合因果推理与 GNN 在金融欺诈检测中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14708v2",
      "published_date": "2024-02-22 17:08:09 UTC",
      "updated_date": "2024-11-27 12:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:04:31.568871"
    },
    {
      "arxiv_id": "2402.14703v2",
      "title": "On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Zhang",
        "Nan Jiang"
      ],
      "abstract": "We study off-policy evaluation (OPE) in partially observable environments\nwith complex observations, with the goal of developing estimators whose\nguarantee avoids exponential dependence on the horizon. While such estimators\nexist for MDPs and POMDPs can be converted to history-based MDPs, their\nestimation errors depend on the state-density ratio for MDPs which becomes\nhistory ratios after conversion, an exponential object. Recently, Uehara et al.\n[2022a] proposed future-dependent value functions as a promising framework to\naddress this issue, where the guarantee for memoryless policies depends on the\ndensity ratio over the latent state space. However, it also depends on the\nboundedness of the future-dependent value function and other related\nquantities, which we show could be exponential-in-length and thus erasing the\nadvantage of the method. In this paper, we discover novel coverage assumptions\ntailored to the structure of POMDPs, such as outcome coverage and belief\ncoverage, which enable polynomial bounds on the aforementioned quantities. As a\nside product, our analyses also lead to the discovery of new algorithms with\ncomplementary properties.",
      "tldr_zh": "这篇论文探讨了在部分可观测环境（POMDPs）中进行 off-policy evaluation (OPE) 的挑战，重点解决估计算法的误差避免对时间步数的指数级依赖问题。作者分析了现有 future-dependent value functions 方法的局限性，发现其依赖的量可能指数级增长，从而削弱了优势。论文提出了新的覆盖假设，如 outcome coverage 和 belief coverage，这些假设针对 POMDP 的结构，提供多项式界的保证，并作为副产品导出了具有互补特性的新算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14703v2",
      "published_date": "2024-02-22 17:00:50 UTC",
      "updated_date": "2024-10-03 06:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:04:43.568291"
    },
    {
      "arxiv_id": "2402.14701v3",
      "title": "COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Baihan Lin",
        "Djallel Bouneffouf",
        "Yulia Landa",
        "Rachel Jespersen",
        "Cheryl Corcoran",
        "Guillermo Cecchi"
      ],
      "abstract": "The therapeutic working alliance is a critical predictor of psychotherapy\nsuccess. Traditionally, working alliance assessment relies on questionnaires\ncompleted by both therapists and patients. In this paper, we present COMPASS, a\nnovel framework to directly infer the therapeutic working alliance from the\nnatural language used in psychotherapy sessions. Our approach leverages\nadvanced large language models (LLMs) to analyze session transcripts and map\nthem to distributed representations. These representations capture the semantic\nsimilarities between the dialogues and psychometric instruments, such as the\nWorking Alliance Inventory. Analyzing a dataset of over 950 sessions spanning\ndiverse psychiatric conditions -- including anxiety (N=498), depression\n(N=377), schizophrenia (N=71), and suicidal tendencies (N=12) -- collected\nbetween 1970 and 2012, we demonstrate the effectiveness of our method in\nproviding fine-grained mapping of patient-therapist alignment trajectories,\noffering interpretable insights for clinical practice, and identifying emerging\npatterns related to the condition being treated. By employing various deep\nlearning-based topic modeling techniques in combination with prompting\ngenerative language models, we analyze the topical characteristics of different\npsychiatric conditions and how these topics evolve during each turn of the\nconversation. This integrated framework enhances the understanding of\ntherapeutic interactions, enables timely feedback for therapists on the quality\nof therapeutic relationships, and provides clear, actionable insights to\nimprove the effectiveness of psychotherapy.",
      "tldr_zh": "这篇论文提出了COMPASS框架，利用大型语言模型(LLMs)从心理治疗会话的自然语言中直接推断治疗工作联盟，从而取代传统问卷评估方法。框架通过分析会话转录，将对话映射到分布式表示，以捕捉其与Working Alliance Inventory等心理测量工具的语义相似性，并在超过950个会话的数据集上（涵盖焦虑、抑郁、精神分裂症和自杀倾向）展示了细粒度患者-治疗师对齐轨迹的映射。结合深度学习主题建模和提示生成技术，该方法识别了不同精神疾病的主题特征及其在对话中的演变，提供可解释见解和及时反馈。最终，COMPASS增强了对治疗互动的理解，并为改善心理治疗效果提供行动性指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "Translational Psychiatry, in press. This work extends our research\n  series in computational psychiatry (e.g auto annotation in arXiv:2204.05522,\n  topic extraction in arXiv:2204.10189, and diagnosis in arXiv:2210.15603) with\n  the introduction of LLMs to complete the full cycle of interpreting and\n  understanding psychotherapy strategies as a comprehensive analytical\n  framework",
      "pdf_url": "http://arxiv.org/pdf/2402.14701v3",
      "published_date": "2024-02-22 16:56:44 UTC",
      "updated_date": "2025-04-14 16:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:04:56.932601"
    },
    {
      "arxiv_id": "2402.14698v3",
      "title": "Using construction waste hauling trucks' GPS data to classify earthwork-related locations: A Chengdu case study",
      "title_zh": "利用建筑废物运输卡车的 GPS 数据来分类土方工程相关地点：一个成都案例研究",
      "authors": [
        "Lei Yu",
        "Ke Han"
      ],
      "abstract": "Earthwork-related locations (ERLs), such as construction sites, earth dumping\nground, and concrete mixing stations, are major sources of urban dust pollution\n(particulate matters). The effective management of ERLs is crucial and requires\ntimely and efficient tracking of these locations throughout the city. This work\naims to identify and classify urban ERLs using GPS trajectory data of over\n16,000 construction waste hauling trucks (CWHTs), as well as 58 urban features\nencompassing geographic, land cover, POI and transport dimensions. We compare\nseveral machine learning models and examine the impact of various\nspatial-temporal features on classification performance using real-world data\nin Chengdu, China. The results demonstrate that 77.8% classification accuracy\ncan be achieved with a limited number of features. This classification\nframework was implemented in the Alpha MAPS system in Chengdu, which has\nsuccessfully identified 724 construction cites/earth dumping ground, 48\nconcrete mixing stations, and 80 truck parking locations in the city during\nDecember 2023, which has enabled local authority to effectively manage urban\ndust pollution at low personnel costs.",
      "tldr_zh": "本研究利用超过16,000辆建筑废物运输卡车（CWHTs）的GPS轨迹数据以及58种城市特征（如地理、土地覆盖、POI和交通维度），开发了一个机器学习框架来识别和分类城市土方相关地点（ERLs），以应对这些地点作为城市粉尘污染主要来源的问题。研究比较了多种机器学习模型，并评估了空间-时间特征对分类性能的影响，在成都真实数据上实现了77.8%的准确率。该框架已应用于Chengdu的Alpha MAPS系统，成功识别了724个建筑工地/土方倾倒地、48个混凝土搅拌站和80个卡车停车位置，帮助当地当局以低人员成本有效管理城市粉尘污染。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14698v3",
      "published_date": "2024-02-22 16:50:32 UTC",
      "updated_date": "2024-04-04 11:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:05:07.911059"
    },
    {
      "arxiv_id": "2402.14895v2",
      "title": "On Evaluation Protocols for Data Augmentation in a Limited Data Scenario",
      "title_zh": "数据增强在数据有限场景下的评估协议",
      "authors": [
        "Frédéric Piedboeuf",
        "Philippe Langlais"
      ],
      "abstract": "Textual data augmentation (DA) is a prolific field of study where novel\ntechniques to create artificial data are regularly proposed, and that has\ndemonstrated great efficiency on small data settings, at least for text\nclassification tasks. In this paper, we challenge those results, showing that\nclassical data augmentation (which modify sentences) is simply a way of\nperforming better fine-tuning, and that spending more time doing so before\napplying data augmentation negates its effect. This is a significant\ncontribution as it answers several questions that were left open in recent\nyears, namely~: which DA technique performs best (all of them as long as they\ngenerate data close enough to the training set, as to not impair training) and\nwhy did DA show positive results (facilitates training of network). We further\nshow that zero- and few-shot DA via conversational agents such as ChatGPT or\nLLama2 can increase performances, confirming that this form of data\naugmentation is preferable to classical methods.",
      "tldr_zh": "这篇论文质疑了文本数据增强（DA）在小数据场景下的传统效果，认为经典 DA（如修改句子）仅相当于更好的 fine-tuning，如果在应用 DA 前延长 fine-tuning 时间，其效果就会消失。作者通过实验回答了关键问题：最佳 DA 技术是那些生成的数据接近训练集的任何方法，因为这有助于网络训练。最终，论文证明，使用对话代理如 ChatGPT 或 LLaMA2 进行 zero-shot 和 few-shot DA 可以提升性能，并推荐这种方法作为优于经典 DA 的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.14895v2",
      "published_date": "2024-02-22 16:42:37 UTC",
      "updated_date": "2024-09-16 20:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:05:20.051707"
    },
    {
      "arxiv_id": "2402.14683v2",
      "title": "Visual Hallucinations of Multi-modal Large Language Models",
      "title_zh": "多模态大型语言模型的视觉幻觉",
      "authors": [
        "Wen Huang",
        "Hongbin Liu",
        "Minxin Guo",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines\nincorrect details about an image in visual question answering. Existing studies\nfind VH instances only in existing image datasets, which results in biased\nunderstanding of MLLMs' performance under VH due to limited diversity of such\nVH instances. In this work, we propose a tool called VHTest to generate a\ndiverse set of VH instances. Specifically, VHTest finds some initial VH\ninstances in existing image datasets (e.g., COCO), generates a text description\nfor each VH mode, and uses a text-to-image generative model (e.g., DALL-E-3) to\ngenerate VH images based on the text descriptions. We collect a benchmark\ndataset with 1,200 VH instances in 8 VH modes using VHTest. We find that\nexisting MLLMs such as GPT-4V, LLaVA-1.5, and MiniGPT-v2 hallucinate for a\nlarge fraction of the instances in our benchmark. Moreover, we find that\nfine-tuning an MLLM using our benchmark dataset reduces its likelihood to\nhallucinate without sacrificing its performance on other benchmarks. Our\nbenchmarks are publicly available: https://github.com/wenhuang2000/VHTest.",
      "tldr_zh": "本文研究了多模态大语言模型(MLLM)中的视觉幻觉(VH)问题，即模型在视觉问答中对图像生成不正确细节，并指出现有研究因受限于图像数据集多样性而导致性能评估偏差。作者提出工具VHTest，通过从数据集（如COCO）提取初始VH实例、生成文本描述并使用文本到图像模型（如DALL-E-3）创建图像，构建了一个包含1200个VH实例的基准数据集，覆盖8个VH模式。实验结果显示，现有MLLM如GPT-4V、LLaVA-1.5和MiniGPT-v2在该基准上出现大量幻觉现象。通过使用该数据集微调MLLM，可以显著降低幻觉发生率，同时不影响其在其他基准上的表现。该基准数据集已公开可用（https://github.com/wenhuang2000/VHTest）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in ACL Findings, 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14683v2",
      "published_date": "2024-02-22 16:40:33 UTC",
      "updated_date": "2024-06-16 18:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:05:33.928203"
    },
    {
      "arxiv_id": "2402.14894v1",
      "title": "Data-Driven Ground-Fault Location Method in Distribution Power System With Distributed Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mauro Caporuscio",
        "Antoine Dupuis",
        "Welf Löwe"
      ],
      "abstract": "The recent increase in renewable energy penetration at the distribution level\nintroduces a multi-directional power flow that outdated traditional fault\nlocation techniques. To this extent, the development of new methods is needed\nto ensure fast and accurate fault localization and, hence, strengthen power\nsystem reliability. This paper proposes a data-driven ground fault location\nmethod for the power distribution system. An 11-bus 20 kV power system is\nmodeled in Matlab/Simulink to simulate ground faults. The faults are generated\nat different locations and under various system operational states. Time-domain\nfaulted three-phase voltages at the system substation are then analyzed with\ndiscrete wavelet transform. Statistical quantities of the processed data are\neventually used to train an Artificial Neural Network (ANN) to find a mapping\nbetween computed voltage features and faults. Specifically, three ANNs allow\nthe prediction of faulted phase, faulted branch, and fault distance from the\nsystem substation separately. According to the results, the method shows good\npotential, with a total relative error of 0,4% for fault distance prediction.\nThe method is applied to datasets with unknown system states to test\nrobustness.",
      "tldr_zh": "这篇论文针对分布式发电导致的配电系统多向功率流动问题，提出了一种数据驱动的接地故障定位方法，以提升系统可靠性。方法包括在Matlab/Simulink中模拟11-bus 20 kV系统下的各种故障场景，使用discrete wavelet transform分析 substation的三相电压数据，并训练三个Artificial Neural Network (ANN)模型分别预测故障相、故障支路和距离。实验结果显示，该方法在故障距离预测上总相对错误仅为0.4%，并在未知系统状态的数据集上表现出良好的鲁棒性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SP"
      ],
      "primary_category": "eess.SY",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2402.14894v1",
      "published_date": "2024-02-22 16:25:32 UTC",
      "updated_date": "2024-02-22 16:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:05:43.585356"
    },
    {
      "arxiv_id": "2402.14672v2",
      "title": "Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Gu",
        "Yiheng Shu",
        "Hao Yu",
        "Xiao Liu",
        "Yuxiao Dong",
        "Jie Tang",
        "Jayanth Srinivasa",
        "Hugo Latapie",
        "Yu Su"
      ],
      "abstract": "The applications of large language models (LLMs) have expanded well beyond\nthe confines of text processing, signaling a new era where LLMs are envisioned\nas generalist agents capable of operating within complex environments. These\nenvironments are often highly expansive, making it impossible for the LLM to\nprocess them within its short-term memory. Motivated by recent research on\nextending the capabilities of LLMs with tools, we seek to investigate the\nintriguing potential of tools to augment LLMs in handling such complexity by\nintroducing a novel class of tools, termed middleware, to aid in the proactive\nexploration within these massive environments. Such specialized tools can serve\nas a middleware layer shielding the LLM from environmental complexity. In two\nrepresentative complex environments -- knowledge bases (KBs) and databases --\nwe demonstrate the significant potential of augmenting language agents with\ntools in complex environments. Notably, equipped with the middleware, GPT-4\nachieves 2.8X the performance of the best baseline in tasks requiring access to\ndatabase content and 2.2X in KB tasks. Our findings illuminate the path for\nadvancing language agents in real-world applications.",
      "tldr_zh": "这篇论文探讨了如何通过工具增强大型语言模型 (LLMs) 的能力，使其作为语言代理在复杂环境中运作。论文引入了一种新型工具类，称为 middleware，用以主动探索庞大的环境（如知识库 (KBs) 和数据库），并充当中间层屏蔽环境复杂性。实验结果显示，配备 middleware 的 GPT-4 在数据库任务中比最佳基线提高了 2.8 倍，在 KB 任务中提高了 2.2 倍。这些发现为 LLMs 在真实世界应用的语言代理提供了重要的推进路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP'2024; 18 pages, 8 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.14672v2",
      "published_date": "2024-02-22 16:18:07 UTC",
      "updated_date": "2024-10-04 07:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:05:57.101863"
    },
    {
      "arxiv_id": "2402.14664v2",
      "title": "Bayesian Off-Policy Evaluation and Learning for Large Action Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Imad Aouali",
        "Victor-Emmanuel Brunel",
        "David Rohde",
        "Anna Korba"
      ],
      "abstract": "In interactive systems, actions are often correlated, presenting an\nopportunity for more sample-efficient off-policy evaluation (OPE) and learning\n(OPL) in large action spaces. We introduce a unified Bayesian framework to\ncapture these correlations through structured and informative priors. In this\nframework, we propose sDM, a generic Bayesian approach for OPE and OPL,\ngrounded in both algorithmic and theoretical foundations. Notably, sDM\nleverages action correlations without compromising computational efficiency.\nMoreover, inspired by online Bayesian bandits, we introduce Bayesian metrics\nthat assess the average performance of algorithms across multiple problem\ninstances, deviating from the conventional worst-case assessments. We analyze\nsDM in OPE and OPL, highlighting the benefits of leveraging action\ncorrelations. Empirical evidence showcases the strong performance of sDM.",
      "tldr_zh": "本文提出一个统一的 Bayesian framework，用于处理大型动作空间中的 off-policy evaluation (OPE) 和 off-policy learning (OPL)，通过结构化和信息丰富的先验捕捉动作关联，以提升样本效率。作者引入了 sDM，这是一种通用的 Bayesian 方法，能够利用这些关联进行 OPE 和 OPL，而不影响计算效率；同时，sDM 基于算法和理论基础，并引入 Bayesian metrics 来评估算法在多个问题实例上的平均性能，而非传统的 worst-case 评估。实验结果证明，sDM 在利用动作关联方面表现出色，显著提高了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.14664v2",
      "published_date": "2024-02-22 16:09:45 UTC",
      "updated_date": "2025-04-08 13:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:06:10.491242"
    },
    {
      "arxiv_id": "2402.14660v2",
      "title": "ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yanan Wu",
        "Jie Liu",
        "Xingyuan Bu",
        "Jiaheng Liu",
        "Zhanhui Zhou",
        "Yuanxing Zhang",
        "Chenchen Zhang",
        "Zhiqi Bai",
        "Haibin Chen",
        "Tiezheng Ge",
        "Wanli Ouyang",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "This paper introduces ConceptMath, a bilingual (English and Chinese),\nfine-grained benchmark that evaluates concept-wise mathematical reasoning of\nLarge Language Models (LLMs). Unlike traditional benchmarks that evaluate\ngeneral mathematical reasoning with an average accuracy, ConceptMath\nsystematically organizes math problems under a hierarchy of math concepts, so\nthat mathematical reasoning can be evaluated at different granularity with\nconcept-wise accuracies. Based on our ConcepthMath, we evaluate a broad range\nof LLMs, and we observe existing LLMs, though achieving high average accuracies\non traditional benchmarks, exhibit significant performance variations across\ndifferent math concepts and may even fail catastrophically on the most basic\nones. Besides, we also introduce an efficient fine-tuning strategy to enhance\nthe weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the\ndevelopers to understand the fine-grained mathematical abilities of their\nmodels and facilitate the growth of foundation models.",
      "tldr_zh": "本文引入了 ConceptMath，这是一个双语（英语和中文）的概念级基准，用于评估 Large Language Models (LLMs) 的数学推理能力，与传统基准不同，它通过将数学问题组织在概念层次结构下，实现细粒度的准确率评估。实验结果显示，现有的 LLMs 尽管在传统基准上取得高平均准确率，但不同数学概念间的性能存在显著差异，甚至在最基本概念上可能出现灾难性失败。此外，论文提出了一种高效的微调策略来增强 LLMs 的弱点，并希望 ConceptMath 能帮助开发者理解模型的细粒度数学能力，促进基础模型的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The benchmark dataset will be released soon",
      "pdf_url": "http://arxiv.org/pdf/2402.14660v2",
      "published_date": "2024-02-22 16:06:49 UTC",
      "updated_date": "2024-02-23 07:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:06:20.675701"
    },
    {
      "arxiv_id": "2402.14658v3",
      "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement",
      "title_zh": "OpenCodeInterpreter：代码生成与执行和精炼的集成",
      "authors": [
        "Tianyu Zheng",
        "Ge Zhang",
        "Tianhao Shen",
        "Xueling Liu",
        "Bill Yuchen Lin",
        "Jie Fu",
        "Wenhu Chen",
        "Xiang Yue"
      ],
      "abstract": "The introduction of large language models has significantly advanced code\ngeneration. However, open-source models often lack the execution capabilities\nand iterative refinement of advanced systems like the GPT-4 Code Interpreter.\nTo address this, we introduce OpenCodeInterpreter, a family of open-source code\nsystems designed for generating, executing, and iteratively refining code.\nSupported by Code-Feedback, a dataset featuring 68K multi-turn interactions,\nOpenCodeInterpreter integrates execution and human feedback for dynamic code\nrefinement. Our comprehensive evaluation of OpenCodeInterpreter across key\nbenchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus\nreveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves\nan accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and\nMBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6)\nwith synthesized human feedback from GPT-4. OpenCodeInterpreter brings the gap\nbetween open-source code generation models and proprietary systems like GPT-4\nCode Interpreter.",
      "tldr_zh": "本文介绍了OpenCodeInterpreter，这是一个开源代码系统，集成了代码生成、执行和迭代优化功能，以弥补开源模型在执行能力和反馈处理方面的不足。系统利用Code-Feedback数据集（包含68K多轮互动）整合执行过程和人类反馈，实现动态代码改进。在HumanEval、MBPP和EvalPlus基准测试中，OpenCodeInterpreter-33B的准确率达到83.2（76.4），接近GPT-4的84.2（76.2），并通过GPT-4合成的反馈提升至91.6（84.6）。这项工作显著缩小了开源代码生成模型与专有系统如GPT-4 Code Interpreter的性能差距。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14658v3",
      "published_date": "2024-02-22 16:06:23 UTC",
      "updated_date": "2025-01-07 05:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:06:35.610924"
    },
    {
      "arxiv_id": "2402.14648v3",
      "title": "Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off",
      "title_zh": "翻译失败",
      "authors": [
        "Futa Waseda",
        "Ching-Chun Chang",
        "Isao Echizen"
      ],
      "abstract": "Adversarial training often suffers from a robustness-accuracy trade-off,\nwhere achieving high robustness comes at the cost of accuracy. One approach to\nmitigate this trade-off is leveraging invariance regularization, which\nencourages model invariance under adversarial perturbations; however, it still\nleads to accuracy loss. In this work, we closely analyze the challenges of\nusing invariance regularization in adversarial training and understand how to\naddress them. Our analysis identifies two key issues: (1) a ``gradient\nconflict\" between invariance and classification objectives, leading to\nsuboptimal convergence, and (2) the mixture distribution problem arising from\ndiverged distributions between clean and adversarial inputs. To address these\nissues, we propose Asymmetric Representation-regularized Adversarial Training\n(ARAT), which incorporates asymmetric invariance loss with stop-gradient\noperation and a predictor to avoid gradient conflict, and a split-BatchNorm\n(BN) structure to resolve the mixture distribution problem. Our detailed\nanalysis demonstrates that each component effectively addresses the identified\nissues, offering novel insights into adversarial defense. ARAT shows\nsuperiority over existing methods across various settings. Finally, we discuss\nthe implications of our findings to knowledge distillation-based defenses,\nproviding a new perspective on their relative successes.",
      "tldr_zh": "本研究重新审视了对抗训练(adversarial training)中不变性正则化(invariance regularization)的应用，以缓解鲁棒性与准确性之间的权衡问题。作者分析了两个关键挑战：（1）不变性和分类目标间的“gradient conflict”导致收敛不佳，以及（2）干净输入与对抗输入分布分歧引起的混合分布问题。为解决这些问题，他们提出Asymmetric Representation-regularized Adversarial Training (ARAT)方法，该方法通过非对称不变性损失结合stop-gradient操作和预测器避免梯度冲突，并采用split-BatchNorm结构处理混合分布。实验结果显示，ARAT在多种设置下优于现有方法，并为知识蒸馏-based防御提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2402.14648v3",
      "published_date": "2024-02-22 15:53:46 UTC",
      "updated_date": "2025-01-23 10:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:06:44.138078"
    },
    {
      "arxiv_id": "2402.14623v1",
      "title": "RoboScript: Code Generation for Free-Form Manipulation Tasks across Real and Simulation",
      "title_zh": "RoboScript：跨越真实与模拟环境的自由形式操作任务代码生成",
      "authors": [
        "Junting Chen",
        "Yao Mu",
        "Qiaojun Yu",
        "Tianming Wei",
        "Silang Wu",
        "Zhecheng Yuan",
        "Zhixuan Liang",
        "Chao Yang",
        "Kaipeng Zhang",
        "Wenqi Shao",
        "Yu Qiao",
        "Huazhe Xu",
        "Mingyu Ding",
        "Ping Luo"
      ],
      "abstract": "Rapid progress in high-level task planning and code generation for open-world\nrobot manipulation has been witnessed in Embodied AI. However, previous studies\nput much effort into general common sense reasoning and task planning\ncapabilities of large-scale language or multi-modal models, relatively little\neffort on ensuring the deployability of generated code on real robots, and\nother fundamental components of autonomous robot systems including robot\nperception, motion planning, and control. To bridge this ``ideal-to-real'' gap,\nthis paper presents \\textbf{RobotScript}, a platform for 1) a deployable robot\nmanipulation pipeline powered by code generation; and 2) a code generation\nbenchmark for robot manipulation tasks in free-form natural language. The\nRobotScript platform addresses this gap by emphasizing the unified interface\nwith both simulation and real robots, based on abstraction from the Robot\nOperating System (ROS), ensuring syntax compliance and simulation validation\nwith Gazebo. We demonstrate the adaptability of our code generation framework\nacross multiple robot embodiments, including the Franka and UR5 robot arms, and\nmultiple grippers. Additionally, our benchmark assesses reasoning abilities for\nphysical space and constraints, highlighting the differences between GPT-3.5,\nGPT-4, and Gemini in handling complex physical interactions. Finally, we\npresent a thorough evaluation on the whole system, exploring how each module in\nthe pipeline: code generation, perception, motion planning, and even object\ngeometric properties, impact the overall performance of the system.",
      "tldr_zh": "该论文介绍了RoboScript平台，一个基于代码生成的部署式机器人操作管道，旨在弥合Embodied AI中任务规划与实际机器人部署的差距，通过ROS抽象实现模拟（Gazebo）和真实环境的统一接口。\nRoboScript支持多种机器人（如Franka和UR5机械臂）及抓取器，并提供了一个基准来评估代码生成在自由形式自然语言任务中的性能。\n该基准测试了GPT-3.5、GPT-4和Gemini在处理物理空间和约束的推理能力，并全面评估了系统模块（如代码生成、感知和运动规划）对整体性能的影响。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "I.2.7; I.2.8; I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages of main paper, 4 pages of appendix; 10 figures in main\n  paper, 3 figures in appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.14623v1",
      "published_date": "2024-02-22 15:12:00 UTC",
      "updated_date": "2024-02-22 15:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:06:59.686733"
    },
    {
      "arxiv_id": "2402.14622v2",
      "title": "From Keywords to Structured Summaries: Streamlining Scholarly Information Access",
      "title_zh": "从关键词到结构化摘要：优化学术信息访问",
      "authors": [
        "Mahsa Shamsabadi",
        "Jennifer D'Souza"
      ],
      "abstract": "This paper highlights the growing importance of information retrieval (IR)\nengines in the scientific community, addressing the inefficiency of traditional\nkeyword-based search engines due to the rising volume of publications. The\nproposed solution involves structured records, underpinning advanced\ninformation technology (IT) tools, including visualization dashboards, to\nrevolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the \"reproductive number estimate of infectious diseases\"\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation information access system as\nan IR method accessible at https://orkg.org/usecases/r0-estimates.",
      "tldr_zh": "这篇论文强调了信息检索（IR）引擎在科学社区的重要性，并指出传统关键词搜索因出版物数量激增而效率低下。作者提出使用结构化记录结合高级信息技术（IT）工具（如可视化仪表板），以取代传统的文本密集型方法，从而革新研究人员访问和过滤文章的方式。该方法通过一个以“传染病再生产数估计”主题的证明概念，利用微调的大型语言模型（LLM）自动生成结构化记录，填充后端数据库。最终，开发出新一代 IR 系统，可在 https://orkg.org/usecases/r0-estimates 访问，提升了学术信息获取的效率和准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DL"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 3 figures | Accepted for publication as a poster paper at\n  the International Semantic Web Conference (ISWC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.14622v2",
      "published_date": "2024-02-22 15:10:45 UTC",
      "updated_date": "2024-10-23 10:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:07:10.259075"
    },
    {
      "arxiv_id": "2403.18838v1",
      "title": "Unleashing the Power of AI. A Systematic Review of Cutting-Edge Techniques in AI-Enhanced Scientometrics, Webometrics, and Bibliometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Hamid Reza Saeidnia",
        "Elaheh Hosseini",
        "Shadi Abdoli",
        "Marcel Ausloos"
      ],
      "abstract": "Purpose: The study aims to analyze the synergy of Artificial Intelligence\n(AI), with scientometrics, webometrics, and bibliometrics to unlock and to\nemphasize the potential of the applications and benefits of AI algorithms in\nthese fields.\n  Design/methodology/approach: By conducting a systematic literature review,\nour aim is to explore the potential of AI in revolutionizing the methods used\nto measure and analyze scholarly communication, identify emerging research\ntrends, and evaluate the impact of scientific publications. To achieve this, we\nimplemented a comprehensive search strategy across reputable databases such as\nProQuest, IEEE Explore, EBSCO, Web of Science, and Scopus. Our search\nencompassed articles published from January 1, 2000, to September 2022,\nresulting in a thorough review of 61 relevant articles.\n  Findings: (i) Regarding scientometrics, the application of AI yields various\ndistinct advantages, such as conducting analyses of publications, citations,\nresearch impact prediction, collaboration, research trend analysis, and\nknowledge mapping, in a more objective and reliable framework. (ii) In terms of\nwebometrics, AI algorithms are able to enhance web crawling and data\ncollection, web link analysis, web content analysis, social media analysis, web\nimpact analysis, and recommender systems. (iii) Moreover, automation of data\ncollection, analysis of citations, disambiguation of authors, analysis of\nco-authorship networks, assessment of research impact, text mining, and\nrecommender systems are considered as the potential of AI integration in the\nfield of bibliometrics.\n  Originality/value: This study covers the particularly new benefits and\npotential of AI-enhanced scientometrics, webometrics, and bibliometrics to\nhighlight the significant prospects of the synergy of this integration through\nAI.",
      "tldr_zh": "这篇论文通过系统文献综述，探讨了 AI 在 Scientometrics、Webometrics 和 Bibliometrics 中的应用潜力，分析了 AI 算法如何提升这些领域的学术评估和数据分析。研究方法包括搜索 ProQuest、IEEE Explore 等数据库，从 2000 年到 2022 年审阅 61 篇相关文章，发现 AI 可提供更客观的出版物分析、引文预测、网络爬取和作者消歧等优势。总体而言，该研究突出了 AI 整合的原创价值，为识别研究趋势和评估科学影响提供了新前景。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.DL",
      "comment": "to be published in Library High Tech; 30 pages; 80 references; 4\n  figures; 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.18838v1",
      "published_date": "2024-02-22 15:10:02 UTC",
      "updated_date": "2024-02-22 15:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:07:22.016888"
    },
    {
      "arxiv_id": "2402.14609v3",
      "title": "Federated Neural Graph Databases",
      "title_zh": "联邦神经图数据库",
      "authors": [
        "Qi Hu",
        "Weifeng Jiang",
        "Haoran Li",
        "Zihao Wang",
        "Jiaxin Bai",
        "Qianren Mao",
        "Yangqiu Song",
        "Lixin Fan",
        "Jianxin Li"
      ],
      "abstract": "The increasing demand for large-scale language models (LLMs) has highlighted\nthe importance of efficient data retrieval mechanisms. Neural graph databases\n(NGDBs) have emerged as a promising approach to storing and querying\ngraph-structured data in neural space, enabling the retrieval of relevant\ninformation for LLMs. However, existing NGDBs are typically designed to operate\non a single graph, limiting their ability to reason across multiple graphs.\nFurthermore, the lack of support for multi-source graph data in existing NGDBs\nhinders their ability to capture the complexity and diversity of real-world\ndata. In many applications, data is distributed across multiple sources, and\nthe ability to reason across these sources is crucial for making informed\ndecisions. This limitation is particularly problematic when dealing with\nsensitive graph data, as directly sharing and aggregating such data poses\nsignificant privacy risks. As a result, many applications that rely on NGDBs\nare forced to choose between compromising data privacy or sacrificing the\nability to reason across multiple graphs. To address these limitations, we\npropose Federated Neural Graph Database (FedNGDB), a novel framework that\nenables reasoning over multi-source graph-based data while preserving privacy.\nFedNGDB leverages federated learning to collaboratively learn graph\nrepresentations across multiple sources, enriching relationships between\nentities and improving the overall quality of the graph data. Unlike existing\nmethods, FedNGDB can handle complex graph structures and relationships, making\nit suitable for various downstream tasks.",
      "tldr_zh": "现有 Neural Graph Databases (NGDBs) 通常仅限于处理单个图，无法跨多个图进行推理，且缺乏对多源图数据的支持，这导致在处理敏感数据时面临隐私风险和决策局限。该研究提出 Federated Neural Graph Database (FedNGDB)，一种新型框架，利用 federated learning 在多个来源上协作学习图表示，从而丰富实体关系并提升数据质量。FedNGDB 能够处理复杂图结构，支持跨源推理，同时保护隐私，适用于各种下游任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14609v3",
      "published_date": "2024-02-22 14:57:44 UTC",
      "updated_date": "2024-08-23 08:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:07:32.027198"
    },
    {
      "arxiv_id": "2402.14569v2",
      "title": "Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyeob Kim",
        "Sumin Kang",
        "Sungwoo Yang",
        "Beomjoon Kim",
        "Jargalbaatar Yura",
        "Donghan Kim"
      ],
      "abstract": "Robot navigation has transitioned from prioritizing obstacle avoidance to\nadopting socially aware navigation strategies that accommodate human presence.\nAs a result, the recognition of socially aware navigation within dynamic\nhuman-centric environments has gained prominence in the field of robotics.\nAlthough reinforcement learning technique has fostered the advancement of\nsocially aware navigation, defining appropriate reward functions, especially in\ncongested environments, has posed a significant challenge. These rewards,\ncrucial in guiding robot actions, demand intricate human-crafted design due to\ntheir complex nature and inability to be automatically set. The multitude of\nmanually designed rewards poses issues with hyperparameter redundancy,\nimbalance, and inadequate representation of unique object characteristics. To\naddress these challenges, we introduce a transformable gaussian reward function\n(TGRF). The TGRF significantly reduces the burden of hyperparameter tuning,\ndisplays adaptability across various reward functions, and demonstrates\naccelerated learning rates, particularly excelling in crowded environments\nutilizing deep reinforcement learning (DRL). We introduce and validate TGRF\nthrough sections highlighting its conceptual background, characteristics,\nexperiments, and real-world application, paving the way for a more effective\nand adaptable approach in robotics.The complete source code is available on\nhttps://github.com/JinnnK/TGRF",
      "tldr_zh": "机器人导航正从单纯避障转向社会感知导航，以适应动态的人类环境，但强化学习中的奖励函数设计面临挑战，如超参数冗余、不平衡和无法捕捉独特物体特征。我们引入了可转换高斯奖励函数(TGRF)，它基于高斯函数减少了手动超参数调整需求，并提高了适应性和学习速度，尤其在拥挤环境中结合深度强化学习(DRL)。实验和实际应用验证了TGRF的有效性，为机器人社会感知导航提供了更高效、可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14569v2",
      "published_date": "2024-02-22 14:20:07 UTC",
      "updated_date": "2024-06-06 13:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:07:45.603117"
    },
    {
      "arxiv_id": "2405.00021v3",
      "title": "SIMPLOT: Enhancing Chart Question Answering by Distilling Essentials",
      "title_zh": "翻译失败",
      "authors": [
        "Wonjoong Kim",
        "Sangwu Park",
        "Yeonjun In",
        "Seokwon Han",
        "Chanyoung Park"
      ],
      "abstract": "Recently, interpreting complex charts with logical reasoning has emerged as\nchallenges due to the development of vision-language models. A prior\nstate-of-the-art (SOTA) model has presented an end-to-end method that leverages\nthe vision-language model to convert charts into table format utilizing Large\nLanguage Model (LLM) for reasoning. However, unlike natural images, charts\ncontain a mix of essential and irrelevant information required for chart\nreasoning, and we discover that this characteristic can lower the performance\nof chart-to-table extraction. In this paper, we introduce SIMPLOT, a method\ndesigned to extract only the elements necessary for chart reasoning. The\nproposed method involves two steps: 1) training to mimic a simple plot that\ncontains only the essential information from a complex chart for table\nextraction, followed by 2) performing reasoning based on the table. Our model\nenables accurate chart reasoning without the need for additional annotations or\ndatasets, and its effectiveness is demonstrated through various experiments.\nFurthermore, we propose a novel prompt mimicking how human interpret charts for\nmore accurate reasoning. Our source code is available at\nhttps://github.com/sangwu99/Simplot.",
      "tldr_zh": "本论文提出SIMPLOT方法，以提升图表问题回答（Chart Question Answering）的性能，针对现有SOTA模型在处理图表中混杂的必要和无关信息时存在的提取效率问题。SIMPLOT通过两个步骤实现：首先训练模型从复杂图表中提炼出仅包含本质信息的简单图表用于表格提取，其次基于该表格进行推理，从而避免了额外标注或数据集的需求。实验结果证明，SIMPLOT显著提高了图表推理的准确性，并引入了一种模仿人类解读图表的提示策略，进一步增强了模型的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.00021v3",
      "published_date": "2024-02-22 14:04:22 UTC",
      "updated_date": "2025-02-03 17:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:07:57.205144"
    },
    {
      "arxiv_id": "2402.14551v2",
      "title": "CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Zijun Long",
        "George Killick",
        "Lipeng Zhuang",
        "Gerardo Aragon-Camarasa",
        "Zaiqiao Meng",
        "Richard Mccreadie"
      ],
      "abstract": "State-of-the-art pre-trained image models predominantly adopt a two-stage\napproach: initial unsupervised pre-training on large-scale datasets followed by\ntask-specific fine-tuning using Cross-Entropy loss~(CE). However, it has been\ndemonstrated that CE can compromise model generalization and stability. While\nrecent works employing contrastive learning address some of these limitations\nby enhancing the quality of embeddings and producing better decision\nboundaries, they often overlook the importance of hard negative mining and rely\non resource intensive and slow training using large sample batches. To counter\nthese issues, we introduce a novel approach named CLCE, which integrates\nLabel-Aware Contrastive Learning with CE. Our approach not only maintains the\nstrengths of both loss functions but also leverages hard negative mining in a\nsynergistic way to enhance performance. Experimental results demonstrate that\nCLCE significantly outperforms CE in Top-1 accuracy across twelve benchmarks,\nachieving gains of up to 3.52% in few-shot learning scenarios and 3.41% in\ntransfer learning settings with the BEiT-3 model. Importantly, our proposed\nCLCE approach effectively mitigates the dependency of contrastive learning on\nlarge batch sizes such as 4096 samples per batch, a limitation that has\npreviously constrained the application of contrastive learning in\nbudget-limited hardware environments.",
      "tldr_zh": "本研究针对传统Cross-Entropy loss (CE)可能损害模型泛化和稳定性的问题，提出CLCE方法，将标签感知Contrastive Learning与CE整合，并通过硬负样本挖掘优化学习过程。\nCLCE结合了两种损失函数的优势，提升了嵌入质量和决策边界，同时减少了对资源密集型大批量训练（如4096样本）的依赖。\n实验结果显示，在十二个图像基准上，CLCE在Top-1准确率上比CE高出最多3.52%，特别是在少样本学习和迁移学习场景中分别提升3.52%和3.41%。这为高效的图像模型训练提供了更实用且高性能的方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14551v2",
      "published_date": "2024-02-22 13:45:01 UTC",
      "updated_date": "2024-11-15 15:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:08:10.428169"
    },
    {
      "arxiv_id": "2402.14547v6",
      "title": "OmniPred: Language Models as Universal Regressors",
      "title_zh": "OmniPred：语言模型作为通用回归器",
      "authors": [
        "Xingyou Song",
        "Oscar Li",
        "Chansoo Lee",
        "Bangding Yang",
        "Daiyi Peng",
        "Sagi Perel",
        "Yutian Chen"
      ],
      "abstract": "Regression is a powerful tool to accurately predict the outcome metric of a\nsystem given a set of parameters, but has traditionally been restricted to\nmethods which are only applicable to a specific task. In this paper, we propose\nOmniPred, a framework for training language models as universal end-to-end\nregressors over $(x,y)$ data from arbitrary formats. Using data sourced from\nGoogle Vizier, one of the largest proprietary blackbox optimization databases\nin the world, our extensive experiments demonstrate that language models are\ncapable of very precise numerical regression using only textual representations\nof mathematical parameters and values, and if given the opportunity to train at\nscale over multiple tasks, can significantly outperform traditional regression\nmodels.",
      "tldr_zh": "该论文提出 OmniPred 框架，将 language models 训练为通用的端到端 regressors，能够处理任意格式的 (x, y) 数据，从而克服传统回归方法仅限于特定任务的局限性。框架利用文本表示来处理数学参数和值，并基于 Google Vizier 的庞大黑箱优化数据库进行训练。实验结果表明，language models 在多任务规模训练下，能实现非常精确的数值回归，并显著优于传统回归模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (TMLR) 2024.\n  Code can be found in\n  https://github.com/google-research/optformer/tree/main/optformer/omnipred",
      "pdf_url": "http://arxiv.org/pdf/2402.14547v6",
      "published_date": "2024-02-22 13:36:53 UTC",
      "updated_date": "2025-01-30 22:12:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:08:20.624869"
    },
    {
      "arxiv_id": "2402.14528v5",
      "title": "ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Tianying Ji",
        "Yongyuan Liang",
        "Yan Zeng",
        "Yu Luo",
        "Guowei Xu",
        "Jiawei Guo",
        "Ruijie Zheng",
        "Furong Huang",
        "Fuchun Sun",
        "Huazhe Xu"
      ],
      "abstract": "The varying significance of distinct primitive behaviors during the policy\nlearning process has been overlooked by prior model-free RL algorithms.\nLeveraging this insight, we explore the causal relationship between different\naction dimensions and rewards to evaluate the significance of various primitive\nbehaviors during training. We introduce a causality-aware entropy term that\neffectively identifies and prioritizes actions with high potential impacts for\nefficient exploration. Furthermore, to prevent excessive focus on specific\nprimitive behaviors, we analyze the gradient dormancy phenomenon and introduce\na dormancy-guided reset mechanism to further enhance the efficacy of our\nmethod. Our proposed algorithm, ACE: Off-policy Actor-critic with\nCausality-aware Entropy regularization, demonstrates a substantial performance\nadvantage across 29 diverse continuous control tasks spanning 7 domains\ncompared to model-free RL baselines, which underscores the effectiveness,\nversatility, and efficient sample efficiency of our approach. Benchmark results\nand videos are available at https://ace-rl.github.io/.",
      "tldr_zh": "本文提出 ACE 算法，即 Off-Policy Actor-Critic with Causality-Aware Entropy Regularization，用于解决强化学习中不同原始行为重要性差异的问题。通过分析动作维度与奖励的因果关系，引入因果感知熵项来优先考虑高影响动作，从而提升探索效率；同时，添加休眠引导重置机制（dormancy-guided reset mechanism）以避免过度关注特定行为。实验结果显示，ACE 在 29 个跨越 7 个领域的连续控制任务上，比无模型强化学习基线性能提升显著，展示了其有效性、多功能性和高效样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024 as oral paper",
      "pdf_url": "http://arxiv.org/pdf/2402.14528v5",
      "published_date": "2024-02-22 13:22:06 UTC",
      "updated_date": "2024-11-04 05:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:08:34.107720"
    },
    {
      "arxiv_id": "2402.14526v2",
      "title": "Balanced Data Sampling for Language Model Training with Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Yunfan Shao",
        "Linyang Li",
        "Zhaoye Fei",
        "Hang Yan",
        "Dahua Lin",
        "Xipeng Qiu"
      ],
      "abstract": "Data plays a fundamental role in the training of Large Language Models\n(LLMs). While attention has been paid to the collection and composition of\ndatasets, determining the data sampling strategy in training remains an open\nquestion. Most LLMs are trained with a simple strategy, random sampling.\nHowever, this sampling strategy ignores the unbalanced nature of training data\ndistribution, which can be sub-optimal. In this paper, we propose ClusterClip\nSampling to balance the text distribution of training data for better model\ntraining. Specifically, ClusterClip Sampling utilizes data clustering to\nreflect the data distribution of the training set and balances the common\nsamples and rare samples during training based on the cluster results. A\nrepetition clip operation is introduced to mitigate the overfitting issue led\nby samples from certain clusters. Extensive experiments validate the\neffectiveness of ClusterClip Sampling, which outperforms random sampling and\nother cluster-based sampling variants under various training datasets and large\nlanguage models.",
      "tldr_zh": "本文探讨了在Large Language Models (LLMs)训练中，随机采样策略忽略数据分布不平衡的问题，提出了一种ClusterClip Sampling方法来优化数据采样。该方法通过数据聚类反映训练集的文本分布，并基于聚类结果平衡常见样本和稀有样本，同时引入repetition clip操作以缓解过拟合风险。实验结果表明，ClusterClip Sampling在多种训练数据集和LLMs上表现优于随机采样和其他基于聚类的采样变体，从而提升了模型的训练效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 (findings), Code is released at\n  https://github.com/choosewhatulike/cluster-clip",
      "pdf_url": "http://arxiv.org/pdf/2402.14526v2",
      "published_date": "2024-02-22 13:20:53 UTC",
      "updated_date": "2024-06-03 06:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:08:44.831652"
    },
    {
      "arxiv_id": "2402.14505v3",
      "title": "Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Lu",
        "Lijun Zhang",
        "Xiangyuan Lan",
        "Shuting Dong",
        "Yaowei Wang",
        "Chun Yuan"
      ],
      "abstract": "Recent studies show that vision models pre-trained in generic visual learning\ntasks with large-scale data can provide useful feature representations for a\nwide range of visual perception problems. However, few attempts have been made\nto exploit pre-trained foundation models in visual place recognition (VPR). Due\nto the inherent difference in training objectives and data between the tasks of\nmodel pre-training and VPR, how to bridge the gap and fully unleash the\ncapability of pre-trained models for VPR is still a key issue to address. To\nthis end, we propose a novel method to realize seamless adaptation of\npre-trained models for VPR. Specifically, to obtain both global and local\nfeatures that focus on salient landmarks for discriminating places, we design a\nhybrid adaptation method to achieve both global and local adaptation\nefficiently, in which only lightweight adapters are tuned without adjusting the\npre-trained model. Besides, to guide effective adaptation, we propose a mutual\nnearest neighbor local feature loss, which ensures proper dense local features\nare produced for local matching and avoids time-consuming spatial verification\nin re-ranking. Experimental results show that our method outperforms the\nstate-of-the-art methods with less training data and training time, and uses\nabout only 3% retrieval runtime of the two-stage VPR methods with RANSAC-based\nspatial verification. It ranks 1st on the MSLS challenge leaderboard (at the\ntime of submission). The code is released at\nhttps://github.com/Lu-Feng/SelaVPR.",
      "tldr_zh": "这篇论文针对视觉位置识别 (VPR) 的挑战，提出了一种无缝适应预训练模型的方法，以桥接模型预训练与 VPR 任务间的差异。具体而言，该方法采用混合适应技术，只需微调轻量级 adapters 来获取关注显著地标的全局和局部特征，并引入 mutual nearest neighbor local feature loss 来指导有效适应，避免耗时的 RANSAC-based spatial verification。实验结果表明，该方法在少量训练数据和训练时间下优于现有方法，仅需两阶段 VPR 方法的 3% 检索运行时间，并在 MSLS challenge 排行榜上排名第一。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14505v3",
      "published_date": "2024-02-22 12:55:01 UTC",
      "updated_date": "2024-04-03 14:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:08:59.048069"
    },
    {
      "arxiv_id": "2402.14498v2",
      "title": "A Collision-Aware Cable Grasping Method in Cluttered Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhang",
        "Kaixin Bai",
        "Qiang Li",
        "Zhaopeng Chen",
        "Jianwei Zhang"
      ],
      "abstract": "We introduce a Cable Grasping-Convolutional Neural Network designed to\nfacilitate robust cable grasping in cluttered environments. Utilizing physics\nsimulations, we generate an extensive dataset that mimics the intricacies of\ncable grasping, factoring in potential collisions between cables and robotic\ngrippers. We employ the Approximate Convex Decomposition technique to dissect\nthe non-convex cable model, with grasp quality autonomously labeled based on\nsimulated grasping attempts. The CG-CNN is refined using this simulated dataset\nand enhanced through domain randomization techniques. Subsequently, the trained\nmodel predicts grasp quality, guiding the optimal grasp pose to the robot\ncontroller for execution. Grasping efficacy is assessed across both synthetic\nand real-world settings. Given our model implicit collision sensitivity, we\nachieved commendable success rates of 92.3% for known cables and 88.4% for\nunknown cables, surpassing contemporary state-of-the-art approaches.\nSupplementary materials can be found at\nhttps://leizhang-public.github.io/cg-cnn/ .",
      "tldr_zh": "我们提出了一种 Collision-Aware Cable Grasping 方法，利用 Cable Grasping-Convolutional Neural Network (CG-CNN) 在杂乱环境中实现鲁棒的电缆抓取。方法通过物理模拟生成数据集，结合 Approximate Convex Decomposition 技术分解非凸电缆模型，并基于模拟抓取尝试自动标注抓取质量，同时采用领域随机化技术优化模型训练。实验结果显示，该方法在合成和真实环境中取得了92.3%的已知电缆成功率和88.4%的未知电缆成功率，超过了现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.14498v2",
      "published_date": "2024-02-22 12:47:04 UTC",
      "updated_date": "2024-03-04 12:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:09:09.779831"
    },
    {
      "arxiv_id": "2402.14891v5",
      "title": "LLMBind: A Unified Modality-Task Integration Framework",
      "title_zh": "LLMBind：一个统一的模态-任务整合框架",
      "authors": [
        "Bin Zhu",
        "Munan Ning",
        "Peng Jin",
        "Bin Lin",
        "Jinfa Huang",
        "Qi Song",
        "Junwu Zhang",
        "Zhenyu Tang",
        "Mingjun Pan",
        "Xing Zhou",
        "Li Yuan"
      ],
      "abstract": "In the multi-modal domain, the dependence of various models on specific input\nformats leads to user confusion and hinders progress. To address this\nchallenge, we introduce \\textbf{LLMBind}, a novel framework designed to unify a\ndiverse array of multi-modal tasks. By harnessing a Mixture-of-Experts (MoE)\nLarge Language Model (LLM), LLMBind processes multi-modal inputs and generates\ntask-specific tokens, enabling the invocation of corresponding models to\naccomplish tasks. This unique approach empowers LLMBind to interpret inputs and\ngenerate outputs across various modalities, including image, text, video, and\naudio. Furthermore, we have constructed an interaction dataset comprising 400k\ninstructions, which unlocks the ability of LLMBind for interactive visual\ngeneration and editing tasks. Extensive experimentation demonstrates that\nLLMBind achieves very superior performance across diverse tasks and outperforms\nexisting models in user evaluations conducted in real-world scenarios.\nMoreover, the adaptability of LLMBind allows for seamless integration with the\nlatest models and extension to new modality tasks, highlighting its potential\nto serve as a unified AI agent for modeling universal modalities.",
      "tldr_zh": "该论文提出LLMBind，一种统一的模态-任务整合框架，旨在解决多模态领域中模型对特定输入格式的依赖问题，从而减少用户困惑并促进进展。LLMBind利用Mixture-of-Experts (MoE) Large Language Model (LLM)处理图像、文本、视频和音频等多模态输入，生成任务特定tokens并调用相应模型来执行任务。此外，研究构建了包含40万指令的交互数据集，支持交互式视觉生成和编辑任务。实验结果显示，LLMBind在各种任务上表现出色，超越现有模型，并在真实场景的用户评估中表现出优越性能，同时具备与最新模型无缝集成的适应性，可扩展到新模态任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14891v5",
      "published_date": "2024-02-22 12:36:31 UTC",
      "updated_date": "2024-04-19 03:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:09:21.827684"
    },
    {
      "arxiv_id": "2402.14492v2",
      "title": "Towards Robust Instruction Tuning on Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Han",
        "Hui Chen",
        "Soujanya Poria"
      ],
      "abstract": "Fine-tuning large language models (LLMs) on multi-task instruction-following\ndata has been proven to be a powerful learning paradigm for improving their\nzero-shot capabilities on new tasks. Recent works about high-quality\ninstruction-following data generation and selection require amounts of human\nlabor to conceive model-understandable instructions for the given tasks and\ncarefully filter the LLM-generated data. In this work, we introduce an\nautomatic instruction augmentation method named INSTRAUG in multimodal tasks.\nIt starts from a handful of basic and straightforward meta instructions but can\nexpand an instruction-following dataset by 30 times. Results on two popular\nmultimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show\nthat INSTRAUG can significantly improve the alignment of multimodal large\nlanguage models (MLLMs) across 12 multimodal tasks, which is even equivalent to\nthe benefits of scaling up training data multiple times.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)的指令微调问题，提出了一种自动指令增强方法INSTRAUG，以减少对人工劳动的依赖。该方法从少量基本元指令出发，能将指令遵循数据集扩展30倍。在MULTIINSTRUCT和InstructBLIP等基准测试中，INSTRAUG显著提升了MLLMs在12个多模态任务上的对齐性能，其效果相当于大规模扩展训练数据。整体而言，这一方法为鲁棒的指令调优提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14492v2",
      "published_date": "2024-02-22 12:35:50 UTC",
      "updated_date": "2024-06-14 13:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:09:33.091550"
    },
    {
      "arxiv_id": "2402.14486v1",
      "title": "Are Bounded Contracts Learnable and Approximately Optimal?",
      "title_zh": "翻译失败",
      "authors": [
        "Yurong Chen",
        "Zhaohua Chen",
        "Xiaotie Deng",
        "Zhiyi Huang"
      ],
      "abstract": "This paper considers the hidden-action model of the principal-agent problem,\nin which a principal incentivizes an agent to work on a project using a\ncontract. We investigate whether contracts with bounded payments are learnable\nand approximately optimal. Our main results are two learning algorithms that\ncan find a nearly optimal bounded contract using a polynomial number of\nqueries, under two standard assumptions in the literature: a costlier action\nfor the agent leads to a better outcome distribution for the principal, and the\nagent's cost/effort has diminishing returns. Our polynomial query complexity\nupper bound shows that standard assumptions are sufficient for achieving an\nexponential improvement upon the known lower bound for general instances.\nUnlike the existing algorithms, which relied on discretizing the contract\nspace, our algorithms directly learn the underlying outcome distributions. As\nfor the approximate optimality of bounded contracts, we find that they could be\nfar from optimal in terms of multiplicative or additive approximation, but\nsatisfy a notion of mixed approximation.",
      "tldr_zh": "这篇论文探讨了委托代理问题中的隐藏行动模型（hidden-action model），研究了边界支付合约（bounded contracts）是否可学习并近似最优。作者提出了两个学习算法，在代理人更昂贵的行动导致更好结果分布且成本有递减收益的标准假设下，使用多项式查询复杂度（polynomial query complexity）直接学习结果分布，从而实现指数级改进。结果表明，虽然边界合约在乘法或加法近似（multiplicative or additive approximation）上可能远非最优，但它们满足混合近似（mixed approximation）的概念。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14486v1",
      "published_date": "2024-02-22 12:19:19 UTC",
      "updated_date": "2024-02-22 12:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:09:45.443531"
    },
    {
      "arxiv_id": "2402.14473v1",
      "title": "Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation",
      "title_zh": "个性化的行为感知 Transformer 用于多行为序列推荐",
      "authors": [
        "Jiajie Su",
        "Chaochao Chen",
        "Zibin Lin",
        "Xi Li",
        "Weiming Liu",
        "Xiaolin Zheng"
      ],
      "abstract": "Sequential Recommendation (SR) captures users' dynamic preferences by\nmodeling how users transit among items. However, SR models that utilize only\nsingle type of behavior interaction data encounter performance degradation when\nthe sequences are short. To tackle this problem, we focus on Multi-Behavior\nSequential Recommendation (MBSR) in this paper, which aims to leverage\ntime-evolving heterogeneous behavioral dependencies for better exploring users'\npotential intents on the target behavior. Solving MBSR is challenging. On the\none hand, users exhibit diverse multi-behavior patterns due to personal\ncharacteristics. On the other hand, there exists comprehensive co-influence\nbetween behavior correlations and item collaborations, the intensity of which\nis deeply affected by temporal factors. To tackle these challenges, we propose\na Personalized Behavior-Aware Transformer framework (PBAT) for MBSR problem,\nwhich models personalized patterns and multifaceted sequential collaborations\nin a novel way to boost recommendation performance. First, PBAT develops a\npersonalized behavior pattern generator in the representation layer, which\nextracts dynamic and discriminative behavior patterns for sequential learning.\nSecond, PBAT reforms the self-attention layer with a behavior-aware\ncollaboration extractor, which introduces a fused behavior-aware attention\nmechanism for incorporating both behavioral and temporal impacts into\ncollaborative transitions. We conduct experiments on three benchmark datasets\nand the results demonstrate the effectiveness and interpretability of our\nframework. Our implementation code is released at\nhttps://github.com/TiliaceaeSU/PBAT.",
      "tldr_zh": "本研究针对多行为序列推荐（MBSR）问题，提出了一种个性化行为感知Transformer框架（PBAT），旨在通过利用多种行为交互数据来更好地捕捉用户动态偏好和潜在意图。PBAT 在表示层引入个性化行为模式生成器，以提取动态和区分性的行为模式；同时，在自注意力层改革为行为感知协作提取器，通过融合的行为感知注意力机制整合行为相关性、物品协作和时间因素的影响。实验结果显示，该框架在三个基准数据集上显著提升了推荐性能，并展示了良好的可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14473v1",
      "published_date": "2024-02-22 12:03:21 UTC",
      "updated_date": "2024-02-22 12:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:09:56.612078"
    },
    {
      "arxiv_id": "2402.14890v2",
      "title": "Vygotsky Distance: Measure for Benchmark Task Similarity",
      "title_zh": "Vygotsky Distance：基准任务相似性的度量",
      "authors": [
        "Maxim K. Surkov",
        "Ivan P. Yamshchikov"
      ],
      "abstract": "Evaluation plays a significant role in modern natural language processing.\nMost modern NLP benchmarks consist of arbitrary sets of tasks that neither\nguarantee any generalization potential for the model once applied outside the\ntest set nor try to minimize the resource consumption needed for model\nevaluation. This paper presents a theoretical instrument and a practical\nalgorithm to calculate similarity between benchmark tasks, we call this\nsimilarity measure \"Vygotsky distance\". The core idea of this similarity\nmeasure is that it is based on relative performance of the \"students\" on a\ngiven task, rather that on the properties of the task itself. If two tasks are\nclose to each other in terms of Vygotsky distance the models tend to have\nsimilar relative performance on them. Thus knowing Vygotsky distance between\ntasks one can significantly reduce the number of evaluation tasks while\nmaintaining a high validation quality. Experiments on various benchmarks,\nincluding GLUE, SuperGLUE, CLUE, and RussianSuperGLUE, demonstrate that a vast\nmajority of NLP benchmarks could be at least 40% smaller in terms of the tasks\nincluded. Most importantly, Vygotsky distance could also be used for the\nvalidation of new tasks thus increasing the generalization potential of the\nfuture NLP models.",
      "tldr_zh": "本文提出\"Vygotsky distance\"作为一种衡量自然语言处理(NLP)基准任务相似度的指标，旨在解决现有基准任务集合的泛化潜力不足和资源消耗过高问题。该度量基于模型在任务上的相对性能而非任务本身属性，如果两个任务的Vygotsky distance较小，模型的相对表现相似，从而能显著减少评估任务数量。实验在GLUE、SuperGLUE、CLUE和RussianSuperGLUE等基准上表明，大多数NLP基准可至少减少40%的任务，同时提升新任务验证和模型的泛化潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T01, 97P80, 97C30, 68Q32",
        "H.1.1; I.2.4; I.2.6; F.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14890v2",
      "published_date": "2024-02-22 12:00:32 UTC",
      "updated_date": "2024-02-26 12:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:10:09.488099"
    },
    {
      "arxiv_id": "2402.14460v1",
      "title": "Reframing the Expected Free Energy: Four Formulations and a Unification",
      "title_zh": "期望自由能的重构：四种表述与统一",
      "authors": [
        "Théophile Champion",
        "Howard Bowman",
        "Dimitrije Marković",
        "Marek Grześ"
      ],
      "abstract": "Active inference is a leading theory of perception, learning and decision\nmaking, which can be applied to neuroscience, robotics, psychology, and machine\nlearning. Active inference is based on the expected free energy, which is\nmostly justified by the intuitive plausibility of its formulations, e.g., the\nrisk plus ambiguity and information gain / pragmatic value formulations. This\npaper seek to formalize the problem of deriving these formulations from a\nsingle root expected free energy definition, i.e., the unification problem.\nThen, we study two settings, each one having its own root expected free energy\ndefinition. In the first setting, no justification for the expected free energy\nhas been proposed to date, but all the formulations can be recovered from it.\nHowever, in this setting, the agent cannot have arbitrary prior preferences\nover observations. Indeed, only a limited class of prior preferences over\nobservations is compatible with the likelihood mapping of the generative model.\nIn the second setting, a justification of the root expected free energy\ndefinition is known, but this setting only accounts for two formulations, i.e.,\nthe risk over states plus ambiguity and entropy plus expected energy\nformulations.",
      "tldr_zh": "该论文重新框架了主动推理（active inference）理论中的期望自由能（expected free energy），旨在从一个根源定义统一其四个公式，包括风险加模糊性、信息增益等。作者研究了两个设置：第一个设置允许从根源定义中恢复所有公式，但仅支持有限的代理先验偏好，与生成模型的似然映射兼容；第二个设置虽有已知理由，但只涵盖风险加模糊性和熵加期望能量公式。总体上，这为期望自由能在神经科学、机器人、心理学和机器学习领域的应用提供了更系统的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14460v1",
      "published_date": "2024-02-22 11:38:43 UTC",
      "updated_date": "2024-02-22 11:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:10:22.039003"
    },
    {
      "arxiv_id": "2402.14458v1",
      "title": "NLAS-multi: A Multilingual Corpus of Automatically Generated Natural Language Argumentation Schemes",
      "title_zh": "翻译失败",
      "authors": [
        "Ramon Ruiz-Dolz",
        "Joaquin Taverner",
        "John Lawrence",
        "Chris Reed"
      ],
      "abstract": "Some of the major limitations identified in the areas of argument mining,\nargument generation, and natural language argument analysis are related to the\ncomplexity of annotating argumentatively rich data, the limited size of these\ncorpora, and the constraints that represent the different languages and domains\nin which these data is annotated. To address these limitations, in this paper\nwe present the following contributions: (i) an effective methodology for the\nautomatic generation of natural language arguments in different topics and\nlanguages, (ii) the largest publicly available corpus of natural language\nargumentation schemes, and (iii) a set of solid baselines and fine-tuned models\nfor the automatic identification of argumentation schemes.",
      "tldr_zh": "本论文针对论点挖掘（argument mining）、论点生成（argument generation）和自然语言论点分析（natural language argument analysis）领域的关键限制，包括数据标注的复杂性、语料库规模有限以及语言和领域的多样性问题，提出了一系列解决方案。贡献包括：（i）一种有效的自动生成自然语言论点的方法，支持不同主题和语言，（ii）最大的公开可用自然语言论证方案（natural language argumentation schemes）语料库，以及（iii）一套坚实的基线和微调模型，用于自动识别论证方案。这些创新有助于提升相关领域的效率和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14458v1",
      "published_date": "2024-02-22 11:31:50 UTC",
      "updated_date": "2024-02-22 11:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:10:35.591233"
    },
    {
      "arxiv_id": "2402.14889v3",
      "title": "COBIAS: Contextual Reliability in Bias Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanshul Govil",
        "Hemang Jain",
        "Vamshi Krishna Bonagiri",
        "Aman Chadha",
        "Ponnurangam Kumaraguru",
        "Manas Gaur",
        "Sanorita Dey"
      ],
      "abstract": "Large Language Models (LLMs) often inherit biases from the web data they are\ntrained on, which contains stereotypes and prejudices. Current methods for\nevaluating and mitigating these biases rely on bias-benchmark datasets. These\nbenchmarks measure bias by observing an LLM's behavior on biased statements.\nHowever, these statements lack contextual considerations of the situations they\ntry to present. To address this, we introduce a contextual reliability\nframework, which evaluates model robustness to biased statements by considering\nthe various contexts in which they may appear. We develop the Context-Oriented\nBias Indicator and Assessment Score (COBIAS) to measure a biased statement's\nreliability in detecting bias based on the variance in model behavior across\ndifferent contexts. To evaluate the metric, we augment 2,291 stereotyped\nstatements from two existing benchmark datasets by adding contextual\ninformation. We show that COBIAS aligns with human judgment on the contextual\nreliability of biased statements (Spearman's $\\rho = 0.65$, $p = 3.4 *\n10^{-60}$) and can be used to create reliable datasets, which would assist bias\nmitigation works.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)从训练数据中继承的偏见问题，引入了上下文可靠性框架，以评估模型对偏见语句的鲁棒性。研究者开发了Context-Oriented Bias Indicator and Assessment Score (COBIAS)指标，通过分析模型行为在不同上下文中的方差，来测量偏见语句的可靠性，并对2,291个刻板印象语句进行了上下文扩充。实验结果显示，COBIAS与人类判断高度一致（Spearman's ρ = 0.65），可用于构建可靠数据集，从而提升偏见缓解工作。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14889v3",
      "published_date": "2024-02-22 10:46:11 UTC",
      "updated_date": "2024-09-17 09:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:10:46.676234"
    },
    {
      "arxiv_id": "2402.14433v1",
      "title": "A Language Model's Guide Through Latent Space",
      "title_zh": "语言模型穿越潜在",
      "authors": [
        "Dimitri von Rütte",
        "Sotiris Anagnostidis",
        "Gregor Bachmann",
        "Thomas Hofmann"
      ],
      "abstract": "Concept guidance has emerged as a cheap and simple way to control the\nbehavior of language models by probing their hidden representations for concept\nvectors and using them to perturb activations at inference time. While the\nfocus of previous work has largely been on truthfulness, in this paper we\nextend this framework to a richer set of concepts such as appropriateness,\nhumor, creativity and quality, and explore to what degree current detection and\nguidance strategies work in these challenging settings. To facilitate\nevaluation, we develop a novel metric for concept guidance that takes into\naccount both the success of concept elicitation as well as the potential\ndegradation in fluency of the guided model. Our extensive experiments reveal\nthat while some concepts such as truthfulness more easily allow for guidance\nwith current techniques, novel concepts such as appropriateness or humor either\nremain difficult to elicit, need extensive tuning to work, or even experience\nconfusion. Moreover, we find that probes with optimal detection accuracies do\nnot necessarily make for the optimal guides, contradicting previous\nobservations for truthfulness. Our work warrants a deeper investigation into\nthe interplay between detectability, guidability, and the nature of the\nconcept, and we hope that our rich experimental test-bed for guidance research\ninspires stronger follow-up approaches.",
      "tldr_zh": "本研究扩展了概念引导（concept guidance）框架，用于通过在语言模型的隐藏表示（latent space）中探测概念向量并扰动激活，来控制模型行为，涵盖了真实性（truthfulness）、适当性（appropriateness）、幽默（humor）、创造力（creativity）和质量（quality）等概念。论文开发了一个新指标，综合评估概念引导的成功率和模型流畅性下降，以更全面地衡量效果。实验结果显示，一些概念如truthfulness较易引导，而其他概念则需大量调优或面临困难，甚至出现混淆；此外，最优探测准确率并不总是对应最佳引导效果，呼吁进一步探索概念的可检测性和可引导性之间的关系。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14433v1",
      "published_date": "2024-02-22 10:25:14 UTC",
      "updated_date": "2024-02-22 10:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:10:59.726813"
    },
    {
      "arxiv_id": "2402.14428v2",
      "title": "KoCoSa: Korean Context-aware Sarcasm Detection Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yumin Kim",
        "Heejae Suh",
        "Mingi Kim",
        "Dongyeon Won",
        "Hwanhee Lee"
      ],
      "abstract": "Sarcasm is a way of verbal irony where someone says the opposite of what they\nmean, often to ridicule a person, situation, or idea. It is often difficult to\ndetect sarcasm in the dialogue since detecting sarcasm should reflect the\ncontext (i.e., dialogue history). In this paper, we introduce a new dataset for\nthe Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware\nSarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and\nthe labels for this task on the last response. To build the dataset, we propose\nan efficient sarcasm detection dataset generation pipeline: 1) generating new\nsarcastic dialogues from source dialogues with large language models, 2)\nautomatic and manual filtering of abnormal and toxic dialogues, and 3) human\nannotation for the sarcasm detection task. We also provide a simple but\neffective baseline for the Korean sarcasm detection task trained on our\ndataset. Experimental results on the dataset show that our baseline system\noutperforms strong baselines like large language models, such as GPT-3.5, in\nthe Korean sarcasm detection task. We show that the sarcasm detection task\nrelies deeply on the existence of sufficient context. We will release the\ndataset at https://github.com/Yu-billie/KoCoSa_sarcasm_detection.",
      "tldr_zh": "这篇论文引入了KoCoSa数据集，用于韩语对话中的上下文感知Sarcasm Detection，包含12.8K条日常对话及其最后响应的讽刺标签。研究团队提出了一种高效的数据集生成管道，包括利用大型语言模型(LLMs)从源对话生成新讽刺对话、自动及手动过滤异常和有毒内容，以及人类标注任务。他们提供了一个简单有效的基线模型，并在实验中证明其在KoCoSa数据集上优于GPT-3.5等强大基线，强调Sarcasm Detection高度依赖于足够的上下文支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14428v2",
      "published_date": "2024-02-22 10:17:57 UTC",
      "updated_date": "2024-03-22 06:29:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:11:11.291291"
    },
    {
      "arxiv_id": "2402.14424v3",
      "title": "Automating psychological hypothesis generation with AI: when large language models meet causal graph",
      "title_zh": "使用人工智能自动化心理假设生成：当大语言模型遇到因果图",
      "authors": [
        "Song Tong",
        "Kai Mao",
        "Zhen Huang",
        "Yukun Zhao",
        "Kaiping Peng"
      ],
      "abstract": "Leveraging the synergy between causal knowledge graphs and a large language\nmodel (LLM), our study introduces a groundbreaking approach for computational\nhypothesis generation in psychology. We analyzed 43,312 psychology articles\nusing a LLM to extract causal relation pairs. This analysis produced a\nspecialized causal graph for psychology. Applying link prediction algorithms,\nwe generated 130 potential psychological hypotheses focusing on `well-being',\nthen compared them against research ideas conceived by doctoral scholars and\nthose produced solely by the LLM. Interestingly, our combined approach of a LLM\nand causal graphs mirrored the expert-level insights in terms of novelty,\nclearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) =\n4.32, p<0.001, respectively). This alignment was further corroborated using\ndeep semantic analysis. Our results show that combining LLM with machine\nlearning techniques such as causal knowledge graphs can revolutionize automated\ndiscovery in psychology, extracting novel insights from the extensive\nliterature. This work stands at the crossroads of psychology and artificial\nintelligence, championing a new enriched paradigm for data-driven hypothesis\ngeneration in psychological research.",
      "tldr_zh": "本研究提出了一种结合大型语言模型(LLM)和因果知识图的方法，用于自动化心理学假设生成，通过分析43,312篇心理学文章提取因果关系对并构建专用因果图。研究者应用链接预测算法，针对“well-being”主题生成130个潜在假设，并与博士生想法及纯LLM生成结果进行比较。结果显示，这种结合方法在假设新颖性上显著优于纯LLM（t(59)=3.34, p=0.007和t(59)=4.32, p<0.001），并与专家水平相当，经深度语义分析进一步证实。该方法革新了心理学的自动发现过程，从大量文献中提取新见解，推动AI在数据驱动研究中的应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14424v3",
      "published_date": "2024-02-22 10:12:16 UTC",
      "updated_date": "2024-07-16 03:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:11:24.371857"
    },
    {
      "arxiv_id": "2402.14418v2",
      "title": "Uncertainty-Aware Evaluation for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vasily Kostumov",
        "Bulat Nutfullin",
        "Oleg Pilipenko",
        "Eugene Ilyushin"
      ],
      "abstract": "Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in\npopularity recently due to their impressive performance in several\nvision-language tasks. Current evaluation methods, however, overlook an\nessential component: uncertainty, which is crucial for a comprehensive\nassessment of VLMs. Addressing this oversight, we present a benchmark\nincorporating uncertainty quantification into evaluating VLMs.\n  Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question\nAnswering (VQA) task. We examine models on 5 datasets that evaluate various\nvision-language capabilities.\n  Using conformal prediction as an uncertainty estimation approach, we\ndemonstrate that the models' uncertainty is not aligned with their accuracy.\nSpecifically, we show that models with the highest accuracy may also have the\nhighest uncertainty, which confirms the importance of measuring it for VLMs.\nOur empirical findings also reveal a correlation between model uncertainty and\nits language model part.",
      "tldr_zh": "该研究指出，现有的视觉语言模型(VLMs)评估方法忽略了不确定性这一关键因素，因此提出一个新的基准，将不确定性量化纳入评估框架中。\n他们评估了20多个VLMs在多选Visual Question Answering (VQA)任务上的性能，使用5个数据集和conformal prediction作为不确定性估计方法。\n结果显示，模型的准确性和不确定性不一致，准确率最高的模型可能具有最高的不确定性，且不确定性与模型的语言模型部分密切相关。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14418v2",
      "published_date": "2024-02-22 10:04:17 UTC",
      "updated_date": "2024-02-24 12:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:11:35.114545"
    },
    {
      "arxiv_id": "2403.05572v1",
      "title": "Is ChatGPT More Empathetic than Humans?",
      "title_zh": "翻译失败",
      "authors": [
        "Anuradha Welivita",
        "Pearl Pu"
      ],
      "abstract": "This paper investigates the empathetic responding capabilities of ChatGPT,\nparticularly its latest iteration, GPT-4, in comparison to human-generated\nresponses to a wide range of emotional scenarios, both positive and negative.\nWe employ a rigorous evaluation methodology, involving a between-groups study\nwith 600 participants, to evaluate the level of empathy in responses generated\nby humans and ChatGPT. ChatGPT is prompted in two distinct ways: a standard\napproach and one explicitly detailing empathy's cognitive, affective, and\ncompassionate counterparts. Our findings indicate that the average empathy\nrating of responses generated by ChatGPT exceeds those crafted by humans by\napproximately 10%. Additionally, instructing ChatGPT to incorporate a clear\nunderstanding of empathy in its responses makes the responses align\napproximately 5 times more closely with the expectations of individuals\npossessing a high degree of empathy, compared to human responses. The proposed\nevaluation framework serves as a scalable and adaptable framework to assess the\nempathetic capabilities of newer and updated versions of large language models,\neliminating the need to replicate the current study's results in future\nresearch.",
      "tldr_zh": "这篇论文评估了ChatGPT（尤其是GPT-4）的移情响应能力，与人类在正面和负面情感场景中的响应进行比较。研究采用一个涉及600名参与者的分组实验，ChatGPT被以标准方式和明确包括认知、情感及同情成分的提示方式进行测试。结果显示，ChatGPT的平均移情评分比人类高约10%，而当被指导理解移情时，其响应与高度移情个体的期望一致性提高了约5倍。该框架为评估未来大型语言模型的移情能力提供了一个可扩展且无需重复实验的方法。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.05572v1",
      "published_date": "2024-02-22 09:52:45 UTC",
      "updated_date": "2024-02-22 09:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:11:46.917251"
    },
    {
      "arxiv_id": "2402.14409v1",
      "title": "Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models",
      "title_zh": "知识之间的拉锯战：探索和解决检索增强语言模型中的知识冲突",
      "authors": [
        "Zhuoran Jin",
        "Pengfei Cao",
        "Yubo Chen",
        "Kang Liu",
        "Xiaojian Jiang",
        "Jiexin Xu",
        "Qiuxia Li",
        "Jun Zhao"
      ],
      "abstract": "Retrieval-augmented language models (RALMs) have demonstrated significant\npotential in refining and expanding their internal memory by retrieving\nevidence from external sources. However, RALMs will inevitably encounter\nknowledge conflicts when integrating their internal memory with external\nsources. Knowledge conflicts can ensnare RALMs in a tug-of-war between\nknowledge, limiting their practical applicability. In this paper, we focus on\nexploring and resolving knowledge conflicts in RALMs. First, we present an\nevaluation framework for assessing knowledge conflicts across various\ndimensions. Then, we investigate the behavior and preference of RALMs from the\nfollowing two perspectives: (1) Conflicts between internal memory and external\nsources: We find that stronger RALMs emerge with the Dunning-Kruger effect,\npersistently favoring their faulty internal memory even when correct evidence\nis provided. Besides, RALMs exhibit an availability bias towards common\nknowledge; (2) Conflicts between truthful, irrelevant and misleading evidence:\nWe reveal that RALMs follow the principle of majority rule, leaning towards\nplacing trust in evidence that appears more frequently. Moreover, we find that\nRALMs exhibit confirmation bias, and are more willing to choose evidence that\nis consistent with their internal memory. To solve the challenge of knowledge\nconflicts, we propose a method called Conflict-Disentangle Contrastive Decoding\n(CD2) to better calibrate the model's confidence. Experimental results\ndemonstrate that our CD2 can effectively resolve knowledge conflicts in RALMs.",
      "tldr_zh": "本文探讨了检索增强语言模型 (RALMs) 在整合内部记忆和外部来源时面临的知识冲突问题，这些冲突可能导致模型出现邓宁-克鲁格效应 (Dunning-Kruger effect)、可用性偏差 (availability bias)、多数规则 (majority rule) 和确认偏差 (confirmation bias)。研究首先提出一个评估框架来评估知识冲突的各个维度，并通过实验揭示 RALMs 在处理内部与外部冲突时更倾向于坚持错误记忆或频繁证据。针对这些问题，作者开发了 Conflict-Disentangle Contrastive Decoding (CD2) 方法，用于校准模型的信心。实验结果显示，CD2 能够有效解决 RALMs 中的知识冲突，提升模型的实际适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14409v1",
      "published_date": "2024-02-22 09:51:08 UTC",
      "updated_date": "2024-02-22 09:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:12:01.268965"
    },
    {
      "arxiv_id": "2402.14404v2",
      "title": "On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe",
      "title_zh": "翻译失败",
      "authors": [
        "Ningyu Xu",
        "Qi Zhang",
        "Menghan Zhang",
        "Peng Qian",
        "Xuanjing Huang"
      ],
      "abstract": "Probing and enhancing large language models' reasoning capacity remains a\ncrucial open question. Here we re-purpose the reverse dictionary task as a case\nstudy to probe LLMs' capacity for conceptual inference. We use in-context\nlearning to guide the models to generate the term for an object concept implied\nin a linguistic description. Models robustly achieve high accuracy in this\ntask, and their representation space encodes information about object\ncategories and fine-grained features. Further experiments suggest that the\nconceptual inference ability as probed by the reverse-dictionary task predicts\nmodel's general reasoning performance across multiple benchmarks, despite\nsimilar syntactic generalization behaviors across models. Explorative analyses\nsuggest that prompting LLMs with description$\\Rightarrow$word examples may\ninduce generalization beyond surface-level differences in task construals and\nfacilitate models on broader commonsense reasoning problems.",
      "tldr_zh": "本研究利用反向字典任务(reverse-dictionary task)作为探针，分析大型语言模型(LLMs)的概念推理能力，通过in-context learning引导模型从语言描述中生成对应术语。结果显示，模型在任务中表现出高准确率，其表征空间能够编码对象类别和细粒度特征。进一步实验表明，这种概念推理能力能预测模型在多个基准上的整体推理性能，尽管模型在句法泛化方面相似；此外，使用描述⇒词的提示可帮助模型超越表面差异，提升更广泛的常识推理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14404v2",
      "published_date": "2024-02-22 09:45:26 UTC",
      "updated_date": "2024-02-26 11:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:12:11.113090"
    },
    {
      "arxiv_id": "2402.14888v1",
      "title": "Efficient data selection employing Semantic Similarity-based Graph Structures for model training",
      "title_zh": "翻译失败",
      "authors": [
        "Roxana Petcu",
        "Subhadeep Maji"
      ],
      "abstract": "Recent developments in natural language processing (NLP) have highlighted the\nneed for substantial amounts of data for models to capture textual information\naccurately. This raises concerns regarding the computational resources and time\nrequired for training such models. This paper introduces Semantics for data\nSAliency in Model performance Estimation (SeSaME). It is an efficient data\nsampling mechanism solely based on textual information without passing the data\nthrough a compute-heavy model or other intensive pre-processing\ntransformations. The application of this approach is demonstrated in the use\ncase of low-resource automated speech recognition (ASR) models, which\nexcessively rely on text-to-speech (TTS) calls when using augmented data.\nSeSaME learns to categorize new incoming data points into speech recognition\ndifficulty buckets by employing semantic similarity-based graph structures and\ndiscrete ASR information from homophilous neighbourhoods through message\npassing. The results indicate reliable projections of ASR performance, with a\n93% accuracy increase when using the proposed method compared to random\npredictions, bringing non-trivial information on the impact of textual\nrepresentations in speech models. Furthermore, a series of experiments show\nboth the benefits and challenges of using the ASR information on incoming data\nto fine-tune the model. We report a 7% drop in validation loss compared to\nrandom sampling, 7% WER drop with non-local aggregation when evaluating against\na highly difficult dataset, and 1.8% WER drop with local aggregation and high\nsemantic similarity between datasets.",
      "tldr_zh": "这篇论文引入了SeSaME，一种基于文本信息的效率数据采样机制，用于优化模型训练，而无需依赖计算密集型模型或预处理。SeSaME通过Semantic Similarity-based Graph Structures和消息传递（message passing）从同质邻域获取离散ASR信息，将新数据点分类到语音识别难度桶中。实验结果显示，该方法与随机预测相比，ASR性能预测准确率提高了93%，验证损失降低了7%，并在评估困难数据集时，通过非局部聚合降低了7%的WER，通过局部聚合和高质量语义相似性降低了1.8%的WER。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2023 Workshop: Sampling and Optimization in Discrete Space",
      "pdf_url": "http://arxiv.org/pdf/2402.14888v1",
      "published_date": "2024-02-22 09:43:53 UTC",
      "updated_date": "2024-02-22 09:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:12:22.870551"
    },
    {
      "arxiv_id": "2402.14399v1",
      "title": "Ensure Timeliness and Accuracy: A Novel Sliding Window Data Stream Paradigm for Live Streaming Recommendation",
      "title_zh": "确保及时性和准确性：一种新型滑动窗口数据流范式用于直播推荐",
      "authors": [
        "Fengqi Liang",
        "Baigong Zheng",
        "Liqin Zhao",
        "Guorui Zhou",
        "Qian Wang",
        "Yanan Niu"
      ],
      "abstract": "Live streaming recommender system is specifically designed to recommend\nreal-time live streaming of interest to users. Due to the dynamic changes of\nlive content, improving the timeliness of the live streaming recommender system\nis a critical problem. Intuitively, the timeliness of the data determines the\nupper bound of the timeliness that models can learn. However, none of the\nprevious works addresses the timeliness problem of the live streaming\nrecommender system from the perspective of data stream design. Employing the\nconventional fixed window data stream paradigm introduces a trade-off dilemma\nbetween labeling accuracy and timeliness. In this paper, we propose a new data\nstream design paradigm, dubbed Sliver, that addresses the timeliness and\naccuracy problem of labels by reducing the window size and implementing a\nsliding window correspondingly. Meanwhile, we propose a time-sensitive re-reco\nstrategy reducing the latency between request and impression to improve the\ntimeliness of the recommendation service and features by periodically\nrequesting the recommendation service. To demonstrate the effectiveness of our\napproach, we conduct offline experiments on a multi-task live streaming dataset\nwith labeling timestamps collected from the Kuaishou live streaming platform.\nExperimental results demonstrate that Sliver outperforms two fixed-window data\nstreams with varying window sizes across all targets in four typical multi-task\nrecommendation models. Furthermore, we deployed Sliver on the Kuaishou live\nstreaming platform. Results of the online A/B test show a significant\nimprovement in click-through rate (CTR), and new follow number (NFN), further\nvalidating the effectiveness of Sliver.",
      "tldr_zh": "该论文针对直播推荐系统的实时性问题，提出了一种新型数据流设计范式Sliver，以解决传统固定窗口数据流在准确性和及时性之间的权衡困境。Sliver通过采用滑动窗口减少窗口大小并结合时间敏感的re-reco策略，降低请求与印象之间的延迟，从而提升推荐服务的及时性和特征更新效率。在Kuaishou平台的离线实验和在线A/B测试中，Sliver在多种多任务推荐模型上优于固定窗口方法，并显著提高了点击率(CTR)和新关注数(NFN)。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14399v1",
      "published_date": "2024-02-22 09:32:34 UTC",
      "updated_date": "2024-02-22 09:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:12:34.543883"
    },
    {
      "arxiv_id": "2402.14398v1",
      "title": "Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing",
      "title_zh": "渐进残差对齐：GAN 反演和图像属性编辑的双流框架",
      "authors": [
        "Hao Li",
        "Mengqi Huang",
        "Lei Zhang",
        "Bo Hu",
        "Yi Liu",
        "Zhendong Mao"
      ],
      "abstract": "GAN-based image attribute editing firstly leverages GAN Inversion to project\nreal images into the latent space of GAN and then manipulates corresponding\nlatent codes. Recent inversion methods mainly utilize additional high-bit\nfeatures to improve image details preservation, as low-bit codes cannot\nfaithfully reconstruct source images, leading to the loss of details. However,\nduring editing, existing works fail to accurately complement the lost details\nand suffer from poor editability. The main reason is they inject all the lost\ndetails indiscriminately at one time, which inherently induces the position and\nquantity of details to overfit source images, resulting in inconsistent content\nand artifacts in edited images. This work argues that details should be\ngradually injected into both the reconstruction and editing process in a\nmulti-stage coarse-to-fine manner for better detail preservation and high\neditability. Therefore, a novel dual-stream framework is proposed to accurately\ncomplement details at each stage. The Reconstruction Stream is employed to\nembed coarse-to-fine lost details into residual features and then adaptively\nadd them to the GAN generator. In the Editing Stream, residual features are\naccurately aligned by our Selective Attention mechanism and then injected into\nthe editing process in a multi-stage manner. Extensive experiments have shown\nthe superiority of our framework in both reconstruction accuracy and editing\nquality compared with existing methods.",
      "tldr_zh": "本文提出Gradual Residuals Alignment双流框架，用于解决GAN Inversion中图像细节丢失和编辑过程中的伪影问题。该框架通过多阶段从粗到细的方式逐步注入细节：Reconstruction Stream将丢失细节嵌入残差特征并自适应添加到GAN生成器，而Editing Stream利用Selective Attention机制对残差特征进行精确对齐并注入编辑过程。与现有方法相比，实验证明该框架显著提高了图像重建准确性和编辑质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 18 figures, published to AAAI24",
      "pdf_url": "http://arxiv.org/pdf/2402.14398v1",
      "published_date": "2024-02-22 09:28:47 UTC",
      "updated_date": "2024-02-22 09:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:12:47.594815"
    },
    {
      "arxiv_id": "2404.07216v1",
      "title": "A Bio-Medical Snake Optimizer System Driven by Logarithmic Surviving Global Search for Optimizing Feature Selection and its application for Disorder Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Ruba Abu Khurma",
        "Esraa Alhenawi",
        "Malik Braik",
        "Fatma A. Hashim",
        "Amit Chhabra",
        "Pedro A. Castillo"
      ],
      "abstract": "It is of paramount importance to enhance medical practices, given how\nimportant it is to protect human life. Medical therapy can be accelerated by\nautomating patient prediction using machine learning techniques. To double the\nefficiency of classifiers, several preprocessing strategies must be adopted for\ntheir crucial duty in this field. Feature selection (FS) is one tool that has\nbeen used frequently to modify data and enhance classification outcomes by\nlowering the dimensionality of datasets. Excluded features are those that have\na poor correlation coefficient with the label class, that is, they have no\nmeaningful correlation with classification and do not indicate where the\ninstance belongs. Along with the recurring features, which show a strong\nassociation with the remainder of the features. Contrarily, the model being\nproduced during training is harmed, and the classifier is misled by their\npresence. This causes overfitting and increases algorithm complexity and\nprocessing time. These are used in exploration to allow solutions to be found\nmore thoroughly and in relation to a chosen solution than at random. TLSO,\nPLSO, and LLSO stand for Tournament Logarithmic Snake Optimizer, Proportional\nLogarithmic Snake Optimizer, and Linear Order Logarithmic Snake Optimizer,\nrespectively. A number of 22 reference medical datasets were used in\nexperiments. The findings indicate that, among 86 % of the datasets, TLSO\nattained the best accuracy, and among 82 % of the datasets, the best feature\nreduction. In terms of the standard deviation, the TLSO also attained\nnoteworthy reliability and stability. On the basis of running duration, it is,\nnonetheless, quite effective.",
      "tldr_zh": "本研究提出了一种基于对数生存全局搜索的生物医学蛇优化器系统，用于优化特征选择（Feature Selection），旨在提升医疗数据集的分类效率并减少过拟合风险。该系统包括三种算法：TLSO（Tournament Logarithmic Snake Optimizer）、PLSO（Proportional Logarithmic Snake Optimizer）和LLSO（Linear Order Logarithmic Snake Optimizer），这些算法通过全局搜索策略排除不相关特征并改进模型性能。在22个参考医疗数据集上的实验结果表明，TLSO在86%的数据集上实现了最佳准确率，在82%的数据集上取得了最佳特征减少，同时显示出显著的稳定性和运行效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07216v1",
      "published_date": "2024-02-22 09:08:18 UTC",
      "updated_date": "2024-02-22 09:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:13:01.136794"
    },
    {
      "arxiv_id": "2402.17778v1",
      "title": "Dynamic Anchor Selection and Real-Time Pose Prediction for Ultra-wideband Tagless Gate",
      "title_zh": "翻译失败",
      "authors": [
        "Junyoung Choi",
        "Sagnik Bhattacharya",
        "Joohyun Lee"
      ],
      "abstract": "Ultra-wideband (UWB) is emerging as a promising solution that can realize\nproximity services, such as UWB tagless gate (UTG), thanks to centimeter-level\nlocalization accuracy based on two different ranging methods such as downlink\ntime-difference of arrival (DL-TDoA) and double-sided two-way ranging (DS-TWR).\nThe UTG is a UWB-based proximity service that provides a seamless gate pass\nsystem without requiring real-time mobile device (MD) tapping. The location of\nMD is calculated using DL-TDoA, and the MD communicates with the nearest UTG\nusing DS-TWR to open the gate. Therefore, the knowledge about the exact\nlocation of MD is the main challenge of UTG, and hence we provide the solutions\nfor both DL-TDoA and DS-TWR. In this paper, we propose dynamic anchor selection\nfor extremely accurate DL-TDoA localization and pose prediction for DS-TWR,\ncalled DynaPose. The pose is defined as the actual location of MD on the human\nbody, which affects the localization accuracy. DynaPose is based on\nline-of-sight (LOS) and non-LOS (NLOS) classification using deep learning for\nanchor selection and pose prediction. Deep learning models use the UWB channel\nimpulse response and the inertial measurement unit embedded in the smartphone.\nDynaPose is implemented on Samsung Galaxy Note20 Ultra and Qorvo UWB board to\nshow the feasibility and applicability. DynaPose achieves a LOS/NLOS\nclassification accuracy of 0.984, 62% higher DL-TDoA localization accuracy, and\nultimately detects four different poses with an accuracy of 0.961 in real-time.",
      "tldr_zh": "本研究针对 Ultra-wideband (UWB) 技术在 UWB tagless gate (UTG) 中的定位挑战，提出 DynaPose 方法，实现动态锚点选择和实时姿态预测，以提升设备定位准确性。DynaPose 利用深度学习模型基于 UWB 通道冲激响应和智能手机的惯性测量单元 (IMU) 进行 line-of-sight (LOS) 和 non-LOS (NLOS) 分类，从而优化 downlink time-difference of arrival (DL-TDoA) 定位和 double-sided two-way ranging (DS-TWR) 通信。实验结果显示，DynaPose 在 Samsung Galaxy Note20 Ultra 和 Qorvo UWB 板上实现了 LOS/NLOS 分类准确率 0.984、DL-TDoA 定位准确率提高 62%，并以 0.961 的准确率实时检测四种不同姿态，为无缝门禁系统提供了高效解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.08399",
      "pdf_url": "http://arxiv.org/pdf/2402.17778v1",
      "published_date": "2024-02-22 08:41:49 UTC",
      "updated_date": "2024-02-22 08:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:13:13.370776"
    },
    {
      "arxiv_id": "2402.14886v1",
      "title": "Applying Reinforcement Learning to Optimize Traffic Light Cycles",
      "title_zh": "应用强化学习优化交通灯周期",
      "authors": [
        "Seungah Son",
        "Juhee Jin"
      ],
      "abstract": "Manual optimization of traffic light cycles is a complex and time-consuming\ntask, necessitating the development of automated solutions. In this paper, we\npropose the application of reinforcement learning to optimize traffic light\ncycles in real-time. We present a case study using the Simulation Urban\nMobility simulator to train a Deep Q-Network algorithm. The experimental\nresults showed 44.16% decrease in the average number of Emergency stops,\nshowing the potential of our approach to reduce traffic congestion and improve\ntraffic flow. Furthermore, we discuss avenues for future research and\nenhancements to the reinforcement learning model.",
      "tldr_zh": "本文提出使用 Reinforcement Learning 优化交通灯周期的自动化方法，以解决手动优化的复杂性和耗时问题。具体通过在 Simulation Urban Mobility 模拟器中训练 Deep Q-Network 算法进行案例研究，实验结果显示平均紧急停车次数减少 44.16%，从而有效降低交通拥堵并改善交通流量。该方法展示了强化学习的潜力，并讨论了未来模型增强和研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14886v1",
      "published_date": "2024-02-22 07:37:04 UTC",
      "updated_date": "2024-02-22 07:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:13:23.720298"
    },
    {
      "arxiv_id": "2402.14346v1",
      "title": "Dependable Distributed Training of Compressed Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Malandrino",
        "Giuseppe Di Giacomo",
        "Marco Levorato",
        "Carla Fabiana Chiasserini"
      ],
      "abstract": "The existing work on the distributed training of machine learning (ML) models\nhas consistently overlooked the distribution of the achieved learning quality,\nfocusing instead on its average value. This leads to a poor dependability}of\nthe resulting ML models, whose performance may be much worse than expected. We\nfill this gap by proposing DepL, a framework for dependable learning\norchestration, able to make high-quality, efficient decisions on (i) the data\nto leverage for learning, (ii) the models to use and when to switch among them,\nand (iii) the clusters of nodes, and the resources thereof, to exploit. For\nconcreteness, we consider as possible available models a full DNN and its\ncompressed versions. Unlike previous studies, DepL guarantees that a target\nlearning quality is reached with a target probability, while keeping the\ntraining cost at a minimum. We prove that DepL has constant competitive ratio\nand polynomial complexity, and show that it outperforms the state-of-the-art by\nover 27% and closely matches the optimum.",
      "tldr_zh": "该研究指出，现有的分布式训练方法忽略了机器学习(ML)模型学习质量的分布，仅关注平均值，导致模型性能不可靠。作者提出 DepL 框架，一种可信赖的学习编排系统，能够高效决策（i）选择哪些数据、（ii）使用哪些模型并何时切换（如全 DNN 和其压缩版本）、以及（iii）利用哪些节点集群和资源。DepL 确保以目标概率达到预设学习质量，同时最小化训练成本，并证明其具有恒定竞争比率和多项式复杂度。实验结果显示，DepL 比现有方法提高超过 27%，并接近最优性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14346v1",
      "published_date": "2024-02-22 07:24:26 UTC",
      "updated_date": "2024-02-22 07:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:13:35.945689"
    },
    {
      "arxiv_id": "2402.14335v1",
      "title": "HyperFast: Instant Classification for Tabular Data",
      "title_zh": "HyperFast：针对表格数据的即时分类",
      "authors": [
        "David Bonet",
        "Daniel Mas Montserrat",
        "Xavier Giró-i-Nieto",
        "Alexander G. Ioannidis"
      ],
      "abstract": "Training deep learning models and performing hyperparameter tuning can be\ncomputationally demanding and time-consuming. Meanwhile, traditional machine\nlearning methods like gradient-boosting algorithms remain the preferred choice\nfor most tabular data applications, while neural network alternatives require\nextensive hyperparameter tuning or work only in toy datasets under limited\nsettings. In this paper, we introduce HyperFast, a meta-trained hypernetwork\ndesigned for instant classification of tabular data in a single forward pass.\nHyperFast generates a task-specific neural network tailored to an unseen\ndataset that can be directly used for classification inference, removing the\nneed for training a model. We report extensive experiments with OpenML and\ngenomic data, comparing HyperFast to competing tabular data neural networks,\ntraditional ML methods, AutoML systems, and boosting machines. HyperFast shows\nhighly competitive results, while being significantly faster. Additionally, our\napproach demonstrates robust adaptability across a variety of classification\ntasks with little to no fine-tuning, positioning HyperFast as a strong solution\nfor numerous applications and rapid model deployment. HyperFast introduces a\npromising paradigm for fast classification, with the potential to substantially\ndecrease the computational burden of deep learning. Our code, which offers a\nscikit-learn-like interface, along with the trained HyperFast model, can be\nfound at https://github.com/AI-sandbox/HyperFast.",
      "tldr_zh": "该论文提出HyperFast，一种meta-trained hypernetwork，用于表格数据（tabular data）的即时分类，仅需单次前向传播即可生成任务特定神经网络，从而避免了传统模型训练和超参数调优的耗时问题。相比于梯度提升算法、其他神经网络、AutoML系统和提升机器，HyperFast在OpenML和基因组数据上的广泛实验中表现出高度竞争力，同时显著提升了速度。实验结果显示，它在各种分类任务中具有强大的适应性，几乎无需微调，为快速模型部署和减少深度学习计算负担提供了新范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures, AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14335v1",
      "published_date": "2024-02-22 07:07:16 UTC",
      "updated_date": "2024-02-22 07:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:13:46.929923"
    },
    {
      "arxiv_id": "2402.14323v2",
      "title": "REPOFUSE: Repository-Level Code Completion with Fused Dual Context",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Liang",
        "Xiaoheng Xie",
        "Gehao Zhang",
        "Xunjin Zheng",
        "Peng Di",
        "wei jiang",
        "Hongwei Chen",
        "Chengpeng Wang",
        "Gang Fan"
      ],
      "abstract": "The success of language models in code assistance has spurred the proposal of\nrepository-level code completion as a means to enhance prediction accuracy,\nutilizing the context from the entire codebase. However, this amplified context\ncan inadvertently increase inference latency, potentially undermining the\ndeveloper experience and deterring tool adoption - a challenge we termed the\nContext-Latency Conundrum. This paper introduces REPOFUSE, a pioneering\nsolution designed to enhance repository-level code completion without the\nlatency trade-off. REPOFUSE uniquely fuses two types of context: the analogy\ncontext, rooted in code analogies, and the rationale context, which encompasses\nin-depth semantic relationships. We propose a novel rank truncated generation\n(RTG) technique that efficiently condenses these contexts into prompts with\nrestricted size. This enables REPOFUSE to deliver precise code completions\nwhile maintaining inference efficiency. Through testing with the CrossCodeEval\nsuite, REPOFUSE has demonstrated a significant leap over existing models,\nachieving a 40.90% to 59.75% increase in exact match (EM) accuracy for code\ncompletions and a 26.8% enhancement in inference speed. Beyond experimental\nvalidation, REPOFUSE has been integrated into the workflow of a large\nenterprise, where it actively supports various coding tasks.",
      "tldr_zh": "这篇论文提出了REPOFUSE，一种仓库级代码补全框架，旨在解决使用整个代码库上下文带来的推理延迟问题（Context-Latency Conundrum）。REPOFUSE通过融合analogy context（基于代码类比）和rationale context（包括深入语义关系），并采用novel rank truncated generation (RTG)技术，将这些上下文压缩成大小受限的提示，从而实现高效的代码补全。实验结果显示，在CrossCodeEval测试中，REPOFUSE比现有模型的exact match (EM)准确率提高了40.90%至59.75%，并提升了26.8%的推理速度；此外，它已整合到大型企业的编码流程中，支持实际任务。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14323v2",
      "published_date": "2024-02-22 06:34:50 UTC",
      "updated_date": "2024-02-23 02:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:14:00.129039"
    },
    {
      "arxiv_id": "2402.14320v6",
      "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering",
      "title_zh": "Triad：一种利用多角色LLM-based代理的框架来解决知识库问答",
      "authors": [
        "Chang Zong",
        "Yuchen Yan",
        "Weiming Lu",
        "Jian Shao",
        "Eliot Huang",
        "Heng Chang",
        "Yueting Zhuang"
      ],
      "abstract": "Recent progress with LLM-based agents has shown promising results across\nvarious tasks. However, their use in answering questions from knowledge bases\nremains largely unexplored. Implementing a KBQA system using traditional\nmethods is challenging due to the shortage of task-specific training data and\nthe complexity of creating task-focused model structures. In this paper, we\npresent Triad, a unified framework that utilizes an LLM-based agent with three\nroles for KBQA tasks. The agent is assigned three roles to tackle different\nKBQA subtasks: agent as a generalist for mastering various subtasks, as a\ndecision maker for the selection of candidates, and as an advisor for answering\nquestions with knowledge. Our KBQA framework is executed in four phases,\ninvolving the collaboration of the agent's multiple roles. We evaluated the\nperformance of our framework using three benchmark datasets, and the results\nshow that our framework outperforms state-of-the-art systems on the LC-QuAD and\nYAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.",
      "tldr_zh": "本研究提出 Triad 框架，利用一个多角色 LLM-based 代理来解决知识库问答 (KBQA) 问题，该代理包括三个角色：generalist 处理各种子任务、decision maker 选择候选项，以及 advisor 用知识回答问题。  \n框架通过四个协作阶段执行 KBQA 任务，克服了传统方法的训练数据不足和模型结构复杂性挑战。  \n实验结果显示，Triad 在 LC-QuAD 和 YAGO-QA 基准数据集上超过了最先进系统，分别获得 11.8% 和 20.7% 的 F1 得分。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.14320v6",
      "published_date": "2024-02-22 06:23:37 UTC",
      "updated_date": "2024-09-29 02:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:14:11.820825"
    },
    {
      "arxiv_id": "2402.15444v1",
      "title": "Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Yichi Zhang",
        "Zhuo Chen",
        "Lei Liang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to predict the missing\ntriples in the multi-modal knowledge graphs by incorporating structural,\nvisual, and textual information of entities into the discriminant models. The\ninformation from different modalities will work together to measure the triple\nplausibility. Existing MMKGC methods overlook the imbalance problem of modality\ninformation among entities, resulting in inadequate modal fusion and\ninefficient utilization of the raw modality information. To address the\nmentioned problems, we propose Adaptive Multi-modal Fusion and Modality\nAdversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality\ninformation for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive\nmodality weights and further generates adversarial samples by\nmodality-adversarial training to enhance the imbalanced modality information.\nOur approach is a co-design of the MMKGC model and training strategy which can\noutperform 19 recent MMKGC methods and achieve new state-of-the-art results on\nthree public MMKGC benchmarks. Our code and data have been released at\nhttps://github.com/zjukg/AdaMF-MAT.",
      "tldr_zh": "本文研究了多模态知识图谱补全(MMKGC)，旨在通过整合结构、视觉和文本信息预测缺失三元组，但现有方法忽略了实体间模态信息的不平衡问题，导致模态融合不足。作者提出AdaMF-MAT方法，使用自适应多模态融合(Adaptive Multi-modal Fusion)分配动态权重，并通过模态对抗训练(Modality Adversarial Training)生成对抗样本来增强不平衡模态信息。该方法作为MMKGC模型和训练策略的联合设计，在三个公共基准上超越了19个最近方法，实现了新的最先进结果，并已公开代码和数据。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.15444v1",
      "published_date": "2024-02-22 05:48:03 UTC",
      "updated_date": "2024-02-22 05:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:14:24.539987"
    },
    {
      "arxiv_id": "2402.14304v2",
      "title": "Vision-Language Navigation with Embodied Intelligence: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Gao",
        "Peng Wang",
        "Feng Gao",
        "Fei Wang",
        "Ruyue Yuan"
      ],
      "abstract": "As a long-term vision in the field of artificial intelligence, the core goal\nof embodied intelligence is to improve the perception, understanding, and\ninteraction capabilities of agents and the environment. Vision-language\nnavigation (VLN), as a critical research path to achieve embodied intelligence,\nfocuses on exploring how agents use natural language to communicate effectively\nwith humans, receive and understand instructions, and ultimately rely on visual\ninformation to achieve accurate navigation. VLN integrates artificial\nintelligence, natural language processing, computer vision, and robotics. This\nfield faces technical challenges but shows potential for application such as\nhuman-computer interaction. However, due to the complex process involved from\nlanguage understanding to action execution, VLN faces the problem of aligning\nvisual information and language instructions, improving generalization ability,\nand many other challenges. This survey systematically reviews the research\nprogress of VLN and details the research direction of VLN with embodied\nintelligence. After a detailed summary of its system architecture and research\nbased on methods and commonly used benchmark datasets, we comprehensively\nanalyze the problems and challenges faced by current research and explore the\nfuture development direction of this field, aiming to provide a practical\nreference for researchers.",
      "tldr_zh": "这篇论文对Vision-Language Navigation (VLN) 进行了全面调查，强调其作为实现Embodied Intelligence的关键路径，帮助代理通过自然语言处理指令并依赖视觉信息实现精确导航。论文整合了人工智能、自然语言处理、计算机视觉和机器人学等领域，系统总结了VLN的系统架构、研究方法以及常用基准数据集。作者分析了当前面临的挑战，如视觉信息与语言指令的对齐问题和泛化能力不足，并探讨了未来发展方向，为研究者提供实用参考。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "The pictures in Figures 2, 4, and 5 are used without authorization,\n  and the literatures in Table 1 have been cited improperly",
      "pdf_url": "http://arxiv.org/pdf/2402.14304v2",
      "published_date": "2024-02-22 05:45:17 UTC",
      "updated_date": "2024-03-15 12:31:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:14:37.591737"
    },
    {
      "arxiv_id": "2402.14299v1",
      "title": "We Choose to Go to Space: Agent-driven Human and Multi-Robot Collaboration in Microgravity",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Xin",
        "Zhongrui You",
        "Zihan Zhang",
        "Taoran Jiang",
        "Tingjia Xu",
        "Haotian Liang",
        "Guojing Ge",
        "Yuchen Ji",
        "Shentong Mo",
        "Jian Cheng"
      ],
      "abstract": "We present SpaceAgents-1, a system for learning human and multi-robot\ncollaboration (HMRC) strategies under microgravity conditions. Future space\nexploration requires humans to work together with robots. However, acquiring\nproficient robot skills and adept collaboration under microgravity conditions\nposes significant challenges within ground laboratories. To address this issue,\nwe develop a microgravity simulation environment and present three typical\nconfigurations of intra-cabin robots. We propose a hierarchical heterogeneous\nmulti-agent collaboration architecture: guided by foundation models, a\nDecision-Making Agent serves as a task planner for human-robot collaboration,\nwhile individual Skill-Expert Agents manage the embodied control of robots.\nThis mechanism empowers the SpaceAgents-1 system to execute a range of\nintricate long-horizon HMRC tasks.",
      "tldr_zh": "该论文提出 SpaceAgents-1 系统，用于在微重力条件下学习人类和多机器人协作（HMRC）策略，以应对未来太空探索中的挑战。系统包括一个微重力模拟环境和三种舱内机器人配置，并采用分层异构多代理架构：由基础模型指导的 Decision-Making Agent 负责任务规划，而 Skill-Expert Agents 则处理机器人控制。实验结果显示，该系统能够高效执行各种复杂的长期 HMRC 任务，为人类与机器人协作提供可靠框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14299v1",
      "published_date": "2024-02-22 05:32:27 UTC",
      "updated_date": "2024-02-22 05:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:14:48.758777"
    },
    {
      "arxiv_id": "2402.14883v3",
      "title": "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Shen Li",
        "Liuyi Yao",
        "Jinyang Gao",
        "Lan Zhang",
        "Yaliang Li"
      ],
      "abstract": "To support various applications, a prevalent and efficient approach for\nbusiness owners is leveraging their valuable datasets to fine-tune a\npre-trained LLM through the API provided by LLM owners or cloud servers.\nHowever, this process carries a substantial risk of model misuse, potentially\nresulting in severe economic consequences for business owners. Thus,\nsafeguarding the copyright of these customized models during LLM fine-tuning\nhas become an urgent practical requirement, but there are limited existing\nsolutions to provide such protection. To tackle this pressing issue, we propose\na novel watermarking approach named ``Double-I watermark''. Specifically, based\non the instruct-tuning data, two types of backdoor data paradigms are\nintroduced with trigger in the instruction and the input, respectively. By\nleveraging LLM's learning capability to incorporate customized backdoor samples\ninto the dataset, the proposed approach effectively injects specific\nwatermarking information into the customized model during fine-tuning, which\nmakes it easy to inject and verify watermarks in commercial scenarios. We\nevaluate the proposed \"Double-I watermark\" under various fine-tuning methods,\ndemonstrating its harmlessness, robustness, uniqueness, imperceptibility, and\nvalidity through both quantitative and qualitative analyses.",
      "tldr_zh": "该研究针对大型语言模型(LLM)微调过程中模型版权保护的问题，提出了一种名为“Double-I watermark”的新型水印方法，以防止模型误用。方法基于指令微调数据，引入两种后门数据范式（trigger in the instruction 和 trigger in the input），利用LLM的学习能力在微调时注入特定水印信息，便于在商业场景中注入和验证。实验结果显示，该水印在各种微调方法下表现出无害性、鲁棒性、唯一性、隐蔽性和有效性，通过定量和定性分析证实了其可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14883v3",
      "published_date": "2024-02-22 04:55:14 UTC",
      "updated_date": "2024-06-05 11:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:15:00.547943"
    },
    {
      "arxiv_id": "2402.14279v3",
      "title": "Mitigating the Linguistic Gap with Phonemic Representations for Robust Cross-lingual Transfer",
      "title_zh": "通过音位表示缓解语言鸿沟以实现稳健的跨语言迁移",
      "authors": [
        "Haeji Jung",
        "Changdae Oh",
        "Jooeon Kang",
        "Jimin Sohn",
        "Kyungwoo Song",
        "Jinkyu Kim",
        "David R. Mortensen"
      ],
      "abstract": "Approaches to improving multilingual language understanding often struggle\nwith significant performance gaps between high-resource and low-resource\nlanguages. While there are efforts to align the languages in a single latent\nspace to mitigate such gaps, how different input-level representations\ninfluence such gaps has not been investigated, particularly with phonemic\ninputs. We hypothesize that the performance gaps are affected by representation\ndiscrepancies between these languages, and revisit the use of phonemic\nrepresentations as a means to mitigate these discrepancies. To demonstrate the\neffectiveness of phonemic representations, we present experiments on three\nrepresentative cross-lingual tasks on 12 languages in total. The results show\nthat phonemic representations exhibit higher similarities between languages\ncompared to orthographic representations, and it consistently outperforms\ngrapheme-based baseline model on languages that are relatively low-resourced.\nWe present quantitative evidence from three cross-lingual tasks that\ndemonstrate the effectiveness of phonemic representations, and it is further\njustified by a theoretical analysis of the cross-lingual performance gap.",
      "tldr_zh": "本研究探讨了多语言理解中高资源语言与低资源语言之间的性能差距问题，假设这种差距源于语言表示的差异，并提出使用 phonemic representations 来缓解这些差异。通过在 12 种语言上的三个跨语言任务进行实验，结果显示 phonemic representations 比正字（orthographic）表示具有更高的语言相似性，并在低资源语言上 consistently 胜过基于字形（grapheme-based）的基线模型。该方法通过定量证据和理论分析证明了其有效性，为 robust cross-lingual transfer 提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 4th Multilingual Representation Learning (MRL)\n  Workshop (co-located with EMNLP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.14279v3",
      "published_date": "2024-02-22 04:41:52 UTC",
      "updated_date": "2024-11-15 17:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:15:13.010894"
    },
    {
      "arxiv_id": "2402.14277v1",
      "title": "GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Spencer Rarrick",
        "Ranjita Naik",
        "Sundar Poudel",
        "Vishal Chowdhary"
      ],
      "abstract": "Neural Machine Translation (NMT) continues to improve in quality and\nadoption, yet the inadvertent perpetuation of gender bias remains a significant\nconcern. Despite numerous studies on gender bias in translations into English\nfrom weakly gendered-languages, there are no benchmarks for evaluating this\nphenomenon or for assessing mitigation strategies. To address this gap, we\nintroduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus,\nthat consists of human translations from Turkish, Hungarian, Finnish, and\nPersian into English. Each translation is accompanied by feminine, masculine,\nand neutral variants. The dataset, which contains between 1250 and 1850\ninstances for each of the four language pairs, features natural sentences with\na wide range of sentence lengths and domains, challenging translation rewriters\non various linguistic phenomena. Additionally, we present a translation gender\nrewriting solution built with GPT-4 and use GATE X-E to evaluate it. We open\nsource our contributions to encourage further research on gender debiasing.",
      "tldr_zh": "本研究针对神经机器翻译(NMT)中从弱性别语言到英语的性别偏见问题，引入了GATE X-E数据集，这是GATE语料库的扩展，包含从土耳其语、匈牙利语、芬兰语和波斯语到英语的人类翻译，每个翻译附带女性、男性中性和中性变体。数据集涵盖1250至1850个实例，涉及各种句子长度和领域，以评估和缓解性别偏见现象。研究者还构建了基于GPT-4的翻译性别重写解决方案，并开源数据集以推动进一步的性别 debiasing 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2311.08836",
      "pdf_url": "http://arxiv.org/pdf/2402.14277v1",
      "published_date": "2024-02-22 04:36:14 UTC",
      "updated_date": "2024-02-22 04:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:15:27.296776"
    },
    {
      "arxiv_id": "2402.14268v1",
      "title": "Can Large Language Models Detect Misinformation in Scientific News Reporting?",
      "title_zh": "大型语言模型能检测科学新闻报道中的误信息吗？",
      "authors": [
        "Yupeng Cao",
        "Aishwarya Muralidharan Nair",
        "Elyon Eyimife",
        "Nastaran Jamalipour Soofi",
        "K. P. Subbalakshmi",
        "John R. Wullert II",
        "Chumki Basu",
        "David Shallcross"
      ],
      "abstract": "Scientific facts are often spun in the popular press with the intent to\ninfluence public opinion and action, as was evidenced during the COVID-19\npandemic. Automatic detection of misinformation in the scientific domain is\nchallenging because of the distinct styles of writing in these two media types\nand is still in its nascence. Most research on the validity of scientific\nreporting treats this problem as a claim verification challenge. In doing so,\nsignificant expert human effort is required to generate appropriate claims. Our\nsolution bypasses this step and addresses a more real-world scenario where such\nexplicit, labeled claims may not be available. The central research question of\nthis paper is whether it is possible to use large language models (LLMs) to\ndetect misinformation in scientific reporting. To this end, we first present a\nnew labeled dataset SciNews, containing 2.4k scientific news stories drawn from\ntrusted and untrustworthy sources, paired with related abstracts from the\nCORD-19 database. Our dataset includes both human-written and LLM-generated\nnews articles, making it more comprehensive in terms of capturing the growing\ntrend of using LLMs to generate popular press articles. Then, we identify\ndimensions of scientific validity in science news articles and explore how this\ncan be integrated into the automated detection of scientific misinformation. We\npropose several baseline architectures using LLMs to automatically detect false\nrepresentations of scientific findings in the popular press. For each of these\narchitectures, we use several prompt engineering strategies including\nzero-shot, few-shot, and chain-of-thought prompting. We also test these\narchitectures and prompting strategies on GPT-3.5, GPT-4, and Llama2-7B,\nLlama2-13B.",
      "tldr_zh": "这篇论文探讨大型语言模型（LLMs）是否能检测科学新闻报道中的误信息，特别是在缺乏显式声明的情况下。研究者构建了一个新数据集SciNews，包含2.4k条科学新闻故事（来自可信和不可信来源），并配对CORD-19数据库的摘要，同时涵盖人类撰写和LLM生成的文章。论文识别了科学有效性维度，并提出几种基于LLMs的基线架构，使用zero-shot、few-shot和chain-of-thought prompting策略，在GPT-3.5、GPT-4、Llama2-7B和Llama2-13B模型上进行测试，以自动检测科学发现的虚假表示。实验结果表明，这种方法为更高效的误信息检测提供了可行路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14268v1",
      "published_date": "2024-02-22 04:07:00 UTC",
      "updated_date": "2024-02-22 04:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:15:39.037975"
    },
    {
      "arxiv_id": "2402.14261v1",
      "title": "Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming",
      "title_zh": "Copilot 评估框架：评估 LLM 引导的软件编程",
      "authors": [
        "Anisha Agarwal",
        "Aaron Chan",
        "Shubham Chandel",
        "Jinu Jang",
        "Shaun Miller",
        "Roshanak Zilouchian Moghaddam",
        "Yevhen Mohylevskyy",
        "Neel Sundaresan",
        "Michele Tufano"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into Development Environments\n(IDEs) has become a focal point in modern software development. LLMs such as\nOpenAI GPT-3.5/4 and Code Llama offer the potential to significantly augment\ndeveloper productivity by serving as intelligent, chat-driven programming\nassistants. However, utilizing LLMs out of the box is unlikely to be optimal\nfor any given scenario. Rather, each system requires the LLM to be honed to its\nset of heuristics to ensure the best performance. In this paper, we introduce\nthe Copilot evaluation harness: a set of data and tools for evaluating\nLLM-guided IDE interactions, covering various programming scenarios and\nlanguages. We propose our metrics as a more robust and information-dense\nevaluation than previous state of the art evaluation systems. We design and\ncompute both static and execution based success metrics for scenarios\nencompassing a wide range of developer tasks, including code generation from\nnatural language (generate), documentation generation from code (doc), test\ncase generation (test), bug-fixing (fix), and workspace understanding and query\nresolution (workspace). These success metrics are designed to evaluate the\nperformance of LLMs within a given IDE and its respective parameter space. Our\nlearnings from evaluating three common LLMs using these metrics can inform the\ndevelopment and validation of future scenarios in LLM guided IDEs.",
      "tldr_zh": "本文提出 Copilot evaluation harness，一套用于评估 Large Language Models (LLMs) 在 Integrated Development Environments (IDEs) 中的数据和工具，以优化 LLMs 在编程场景中的性能。框架涵盖多种开发者任务，包括代码生成 (generate)、文档生成 (doc)、测试用例生成 (test)、bug 修复 (fix) 和工作区理解及查询解决 (workspace)，并设计了更稳健的静态和执行-based 成功指标来量化评估结果。实验评估了三个常见 LLMs 的表现，为未来 LLM 引导 IDE 的开发和验证提供了重要指导。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14261v1",
      "published_date": "2024-02-22 03:51:34 UTC",
      "updated_date": "2024-02-22 03:51:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:15:49.501538"
    },
    {
      "arxiv_id": "2402.14259v2",
      "title": "Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Wang",
        "Jinhao Duan",
        "Chenxi Yuan",
        "Qingyu Chen",
        "Tianlong Chen",
        "Yue Zhang",
        "Ren Wang",
        "Xiaoshuang Shi",
        "Kaidi Xu"
      ],
      "abstract": "Uncertainty estimation is crucial for the reliability of safety-critical\nhuman and artificial intelligence (AI) interaction systems, particularly in the\ndomain of healthcare engineering. However, a robust and general uncertainty\nmeasure for free-form answers has not been well-established in open-ended\nmedical question-answering (QA) tasks, where generative inequality introduces a\nlarge number of irrelevant words and sequences within the generated set for\nuncertainty quantification (UQ), which can lead to biases. This paper\nintroduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at\nboth the word and sequence levels, considering semantic relevance. WSE\nquantifies uncertainty in a way that is more closely aligned with the\nreliability of LLMs during uncertainty quantification (UQ). We compare WSE with\nsix baseline methods on five free-form medical QA datasets, utilizing seven\npopular large language models (LLMs). Experimental results demonstrate that WSE\nexhibits superior performance in UQ under two standard criteria for correctness\nevaluation. Additionally, in terms of real-world medical QA applications, the\nperformance of LLMs is significantly enhanced (e.g., a 6.36% improvement in\nmodel accuracy on the COVID-QA dataset) by employing responses with lower\nuncertainty that are identified by WSE as final answers, without any additional\ntask-specific fine-tuning or architectural modifications.",
      "tldr_zh": "本论文提出Word-Sequence Entropy (WSE)，一种新型不确定性估计方法，旨在解决开放式医疗问答(QA)任务中生成式模型的偏差问题，通过在词和序列层面校准不确定性并考虑语义相关性，提升大型语言模型(LLMs)的可靠性。WSE 与六种基线方法在五个免费形式医疗 QA 数据集上进行比较，使用七个流行 LLMs，结果显示其在不确定性量化(UQ)方面表现出色，满足两个标准正确性评估标准。实验证明，采用 WSE 识别低不确定性响应作为最终答案，能显著提升模型性能，例如在 COVID-QA 数据集上准确率提高 6.36%，且无需额外任务特定微调或架构修改。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by Engineering Applications of Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2402.14259v2",
      "published_date": "2024-02-22 03:46:08 UTC",
      "updated_date": "2024-11-18 09:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:16:01.057053"
    },
    {
      "arxiv_id": "2402.14882v1",
      "title": "Deep Generative Model-based Synthesis of Four-bar Linkage Mechanisms with Target Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Sumin Lee",
        "Jihoon Kim",
        "Namwoo Kang"
      ],
      "abstract": "Mechanisms are essential components designed to perform specific tasks in\nvarious mechanical systems. However, designing a mechanism that satisfies\ncertain kinematic or quasi-static requirements is a challenging task. The\nkinematic requirements may include the workspace of a mechanism, while the\nquasi-static requirements of a mechanism may include its torque transmission,\nwhich refers to the ability of the mechanism to transfer power and torque\neffectively. In this paper, we propose a deep learning-based generative model\nfor generating multiple crank-rocker four-bar linkage mechanisms that satisfy\nboth the kinematic and quasi-static requirements aforementioned. The proposed\nmodel is based on a conditional generative adversarial network (cGAN) with\nmodifications for mechanism synthesis, which is trained to learn the\nrelationship between the requirements of a mechanism with respect to linkage\nlengths. The results demonstrate that the proposed model successfully generates\nmultiple distinct mechanisms that satisfy specific kinematic and quasi-static\nrequirements. To evaluate the novelty of our approach, we provide a comparison\nof the samples synthesized by the proposed cGAN, traditional cVAE and NSGA-II.\nOur approach has several advantages over traditional design methods. It enables\ndesigners to efficiently generate multiple diverse and feasible design\ncandidates while exploring a large design space. Also, the proposed model\nconsiders both the kinematic and quasi-static requirements, which can lead to\nmore efficient and effective mechanisms for real-world use, making it a\npromising tool for linkage mechanism design.",
      "tldr_zh": "本论文提出了一种基于深度生成模型的四-bar linkage mechanisms 合成方法，旨在解决设计满足运动学（如工作空间）和准静态（如扭矩传输）要求的机制的挑战。方法采用修改后的条件生成对抗网络 (cGAN)，通过学习机制要求与连杆长度的关系，生成多种 crank-rocker 四杆机构。实验结果显示，该模型成功产生多样化的机制，并与传统 cVAE 和 NSGA-II 方法相比，表现出更高的效率和探索设计空间的能力，最终为实际应用提供更高效有效的机制设计工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14882v1",
      "published_date": "2024-02-22 03:31:00 UTC",
      "updated_date": "2024-02-22 03:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:16:13.033692"
    },
    {
      "arxiv_id": "2403.00790v2",
      "title": "Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations",
      "title_zh": "利用基于音乐语法的激活，通过音乐五度圈构建概念空间",
      "authors": [
        "Tofara Moyo"
      ],
      "abstract": "In this paper, we explore the intriguing similarities between the structure\nof a discrete neural network, such as a spiking network, and the composition of\na piano piece. While both involve nodes or notes that are activated\nsequentially or in parallel, the latter benefits from the rich body of music\ntheory to guide meaningful combinations. We propose a novel approach that\nleverages musical grammar to regulate activations in a spiking neural network,\nallowing for the representation of symbols as attractors. By applying rules for\nchord progressions from music theory, we demonstrate how certain activations\nnaturally follow others, akin to the concept of attraction. Furthermore, we\nintroduce the concept of modulating keys to navigate different basins of\nattraction within the network. Ultimately, we show that the map of concepts in\nour model is structured by the musical circle of fifths, highlighting the\npotential for leveraging music theory principles in deep learning algorithms.",
      "tldr_zh": "本研究探索了脉冲神经网络(spiking neural network)与钢琴音乐结构的相似性，提出一种新方法利用音乐语法(music grammar)来调节网络激活，将符号表示为吸引子(attractors)。通过应用音乐理论中的和弦进行(chord progressions)规则，该方法使某些激活自然跟随其他激活，并引入调性调制(modulating keys)来导航网络中的不同吸引子盆地(basins of attraction)。最终，结果显示模型的概念空间被音乐五度圈(musical circle of fifths)结构化，展示了音乐理论原则在深度学习算法中的潜在应用价值。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "3 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.00790v2",
      "published_date": "2024-02-22 03:28:25 UTC",
      "updated_date": "2024-10-24 14:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:16:23.974752"
    },
    {
      "arxiv_id": "2402.14245v1",
      "title": "Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models",
      "title_zh": "通过多模态大型语言模型的 AI 反馈增强机器人操控",
      "authors": [
        "Jinyi Liu",
        "Yifu Yuan",
        "Jianye Hao",
        "Fei Ni",
        "Lingzhi Fu",
        "Yibin Chen",
        "Yan Zheng"
      ],
      "abstract": "Recently, there has been considerable attention towards leveraging large\nlanguage models (LLMs) to enhance decision-making processes. However, aligning\nthe natural language text instructions generated by LLMs with the vectorized\noperations required for execution presents a significant challenge, often\nnecessitating task-specific details. To circumvent the need for such\ntask-specific granularity, inspired by preference-based policy learning\napproaches, we investigate the utilization of multimodal LLMs to provide\nautomated preference feedback solely from image inputs to guide\ndecision-making. In this study, we train a multimodal LLM, termed CriticGPT,\ncapable of understanding trajectory videos in robot manipulation tasks, serving\nas a critic to offer analysis and preference feedback. Subsequently, we\nvalidate the effectiveness of preference labels generated by CriticGPT from a\nreward modeling perspective. Experimental evaluation of the algorithm's\npreference accuracy demonstrates its effective generalization ability to new\ntasks. Furthermore, performance on Meta-World tasks reveals that CriticGPT's\nreward model efficiently guides policy learning, surpassing rewards based on\nstate-of-the-art pre-trained representation models.",
      "tldr_zh": "该研究探讨了利用多模态大型语言模型(Multimodal LLMs)提供AI反馈来提升机器人操作决策的过程，以解决LLMs生成的自然语言指令与向量化操作对齐的挑战。研究引入CriticGPT，一种训练好的多模态LLM，能从图像输入理解机器人轨迹视频，并作为批评者生成偏好反馈，从而指导决策学习。实验结果显示，CriticGPT的奖励模型在Meta-World任务中表现出色，不仅在偏好准确性上具有良好的泛化能力，还超过了最先进的前训练表示模型的性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Presented at AAAI 2024 RL+LLMs Workshop",
      "pdf_url": "http://arxiv.org/pdf/2402.14245v1",
      "published_date": "2024-02-22 03:14:03 UTC",
      "updated_date": "2024-02-22 03:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:16:36.693523"
    },
    {
      "arxiv_id": "2402.14244v2",
      "title": "MENTOR: Guiding Hierarchical Reinforcement Learning with Human Feedback and Dynamic Distance Constraint",
      "title_zh": "MENTOR：利用人类反馈和动态距离约束指导层次强化学习",
      "authors": [
        "Xinglin Zhou",
        "Yifu Yuan",
        "Shaofu Yang",
        "Jianye Hao"
      ],
      "abstract": "Hierarchical reinforcement learning (HRL) provides a promising solution for\ncomplex tasks with sparse rewards of intelligent agents, which uses a\nhierarchical framework that divides tasks into subgoals and completes them\nsequentially. However, current methods struggle to find suitable subgoals for\nensuring a stable learning process. Without additional guidance, it is\nimpractical to rely solely on exploration or heuristics methods to determine\nsubgoals in a large goal space. To address the issue, We propose a general\nhierarchical reinforcement learning framework incorporating human feedback and\ndynamic distance constraints (MENTOR). MENTOR acts as a \"mentor\", incorporating\nhuman feedback into high-level policy learning, to find better subgoals. As for\nlow-level policy, MENTOR designs a dual policy for exploration-exploitation\ndecoupling respectively to stabilize the training. Furthermore, although humans\ncan simply break down tasks into subgoals to guide the right learning\ndirection, subgoals that are too difficult or too easy can still hinder\ndownstream learning efficiency. We propose the Dynamic Distance Constraint\n(DDC) mechanism dynamically adjusting the space of optional subgoals. Thus\nMENTOR can generate subgoals matching the low-level policy learning process\nfrom easy to hard. Extensive experiments demonstrate that MENTOR uses a small\namount of human feedback to achieve significant improvement in complex tasks\nwith sparse rewards.",
      "tldr_zh": "本研究针对分层强化学习(Hierarchical Reinforcement Learning, HRL)中子目标选择困难的问题，提出了一种通用框架MENTOR，该框架整合人类反馈到高层政策中，以指导子目标的生成，并设计双重政策来分离探索和利用，从而稳定低层政策的训练。MENTOR还引入动态距离约束(Dynamic Distance Constraint, DDC)机制，动态调整子目标空间，从易到难匹配学习过程，确保高效学习。实验结果显示，在稀疏奖励的复杂任务中，MENTOR仅需少量人类反馈即可显著提升性能，证明了其在智能代理任务分解方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in IEEE Transactions on Emerging Topics in\n  Computational Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2402.14244v2",
      "published_date": "2024-02-22 03:11:09 UTC",
      "updated_date": "2024-11-27 13:27:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:16:49.076075"
    },
    {
      "arxiv_id": "2402.14241v1",
      "title": "A Self-supervised Pressure Map human keypoint Detection Approch: Optimizing Generalization and Computational Efficiency Across Datasets",
      "title_zh": "一种自我监督的压力地图人体关键点检测",
      "authors": [
        "Chengzhang Yu",
        "Xianjun Yang",
        "Wenxia Bao",
        "Shaonan Wang",
        "Zhiming Yao"
      ],
      "abstract": "In environments where RGB images are inadequate, pressure maps is a viable\nalternative, garnering scholarly attention. This study introduces a novel\nself-supervised pressure map keypoint detection (SPMKD) method, addressing the\ncurrent gap in specialized designs for human keypoint extraction from pressure\nmaps. Central to our contribution is the Encoder-Fuser-Decoder (EFD) model,\nwhich is a robust framework that integrates a lightweight encoder for precise\nhuman keypoint detection, a fuser for efficient gradient propagation, and a\ndecoder that transforms human keypoints into reconstructed pressure maps. This\nstructure is further enhanced by the Classification-to-Regression Weight\nTransfer (CRWT) method, which fine-tunes accuracy through initial\nclassification task training. This innovation not only enhances human keypoint\ngeneralization without manual annotations but also showcases remarkable\nefficiency and generalization, evidenced by a reduction to only $5.96\\%$ in\nFLOPs and $1.11\\%$ in parameter count compared to the baseline methods.",
      "tldr_zh": "本文提出了一种自监督压力映射关键点检测（SPMKD）方法，针对 RGB 图像不足的环境，优化了在不同数据集上的泛化和计算效率。核心框架是 Encoder-Fuser-Decoder (EFD) 模型，包括轻量级编码器用于精确检测人类关键点、融合器确保高效梯度传播，以及解码器将关键点转化为重建的压力映射。该方法结合 Classification-to-Regression Weight Transfer (CRWT) 技术，通过初始分类任务训练来微调准确性，实现无需手动标注的泛化提升。与基线方法相比，SPMKD 显著降低了计算开销，FLOPs 减少至 5.96%，参数数量减少至 1.11%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5pages, 6figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14241v1",
      "published_date": "2024-02-22 02:54:43 UTC",
      "updated_date": "2024-02-22 02:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:17:02.776116"
    },
    {
      "arxiv_id": "2402.14236v2",
      "title": "Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Gao",
        "Tao Yu",
        "Fei Wang",
        "Ru-Yue Yuan"
      ],
      "abstract": "Designing distributed filter circuits (DFCs) is complex and time-consuming,\ninvolving setting and optimizing multiple hyperparameters. Traditional\noptimization methods, such as using the commercial finite element solver HFSS\n(High-Frequency Structure Simulator) to enumerate all parameter combinations\nwith fixed steps and then simulate each combination, are not only\ntime-consuming and labor-intensive but also rely heavily on the expertise and\nexperience of electronics engineers, making it difficult to adapt to rapidly\nchanging design requirements. Additionally, these commercial tools struggle\nwith precise adjustments when parameters are sensitive to numerical changes,\nresulting in limited optimization effectiveness. This study proposes a novel\nend-to-end automated method for DFC design. The proposed method harnesses\nreinforcement learning (RL) algorithms, eliminating the dependence on the\ndesign experience of engineers. Thus, it significantly reduces the subjectivity\nand constraints associated with circuit design. The experimental findings\ndemonstrate clear improvements in design efficiency and quality when comparing\nthe proposed method with traditional engineer-driven methods. Furthermore, the\nproposed method achieves superior performance when designing complex or rapidly\nevolving DFCs, highlighting the substantial potential of RL in circuit design\nautomation. In particular, compared to the existing DFC automation design\nmethod CircuitGNN, our method achieves an average performance improvement of\n8.72%. Additionally, the execution efficiency of our method is 2000 times\nhigher than CircuitGNN on the CPU and 241 times higher on the GPU.",
      "tldr_zh": "本文研究了分布式滤波电路（DFCs）的设计优化问题，指出传统方法依赖于如 HFSS 的商业工具枚举参数组合，过程耗时且高度依赖工程师经验，导致适应性差和优化效果有限。作者提出了一种基于 Reinforcement Learning (RL) 的端到端自动化设计方法，消除对人工经验的依赖，并显著提升设计效率和质量。与现有方法 CircuitGNN 相比，该方法平均性能提升 8.72%，执行效率在 CPU 上高出 2000 倍，在 GPU 上高出 241 倍。总的来说，这一创新为复杂电路设计自动化提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14236v2",
      "published_date": "2024-02-22 02:36:14 UTC",
      "updated_date": "2024-07-29 02:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:17:14.052024"
    },
    {
      "arxiv_id": "2402.14230v2",
      "title": "MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Lichi Li",
        "Zainul Abi Din",
        "Zhen Tan",
        "Sam London",
        "Tianlong Chen",
        "Ajay Daptardar"
      ],
      "abstract": "In the evolving e-commerce field, recommendation systems crucially shape user\nexperience and engagement. The rise of Consumer-to-Consumer (C2C)\nrecommendation systems, noted for their flexibility and ease of access for\ncustomer vendors, marks a significant trend. However, the academic focus\nremains largely on Business-to-Consumer (B2C) models, leaving a gap filled by\nthe limited C2C recommendation datasets that lack in item attributes, user\ndiversity, and scale. The intricacy of C2C recommendation systems is further\naccentuated by the dual roles users assume as both sellers and buyers,\nintroducing a spectrum of less uniform and varied inputs. Addressing this, we\nintroduce MerRec, the first large-scale dataset specifically for C2C\nrecommendations, sourced from the Mercari e-commerce platform, covering\nmillions of users and products over 6 months in 2023. MerRec not only includes\nstandard features such as user_id, item_id, and session_id, but also unique\nelements like timestamped action types, product taxonomy, and textual product\nattributes, offering a comprehensive dataset for research. This dataset,\nextensively evaluated across four recommendation tasks, establishes a new\nbenchmark for the development of advanced recommendation algorithms in\nreal-world scenarios, bridging the gap between academia and industry and\npropelling the study of C2C recommendations. Our experiment code is available\nat https://github.com/mercari/mercari-ml-merrec-pub-us and dataset at\nhttps://huggingface.co/datasets/mercari-us/merrec.",
      "tldr_zh": "本研究针对学术界对 C2C (Consumer-to-Consumer) 推荐系统的关注不足，引入了 MerRec，这是一个大规模多用途数据集，源自 Mercari 电商平台，涵盖2023年6个月内的数百万用户和产品。MerRec 包括标准特征如 user_id、item_id 和 session_id，以及独特元素如 timestamped action types、product taxonomy 和 textual product attributes，提供全面的数据支持。数据集在四个推荐任务上进行了评估，建立新的基准，促进了 C2C 推荐算法的开发，并桥接了学术与行业的差距。实验代码和数据集可分别在 GitHub 和 Hugging Face 上获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Dataset available at:\n  https://huggingface.co/datasets/mercari-us/merrec, code available at:\n  https://github.com/mercari/mercari-ml-merrec-pub-us",
      "pdf_url": "http://arxiv.org/pdf/2402.14230v2",
      "published_date": "2024-02-22 02:21:59 UTC",
      "updated_date": "2024-07-17 01:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:17:25.563715"
    },
    {
      "arxiv_id": "2402.14228v3",
      "title": "COPR: Continual Human Preference Learning via Optimal Policy Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Han Zhang",
        "Lin Gui",
        "Yu Lei",
        "Yuanzhao Zhai",
        "Yehong Zhang",
        "Yulan He",
        "Hui Wang",
        "Yue Yu",
        "Kam-Fai Wong",
        "Bin Liang",
        "Ruifeng Xu"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to\nimprove the alignment of Large Language Models (LLMs) with human preferences.\nGiven the evolving nature of human preferences, continual alignment becomes\nmore crucial and practical in comparison to traditional static alignment.\nNevertheless, making RLHF compatible with Continual Learning (CL) is\nchallenging due to its complex process. Meanwhile, directly learning new human\npreferences may lead to Catastrophic Forgetting (CF) of historical preferences,\nresulting in helpless or harmful outputs. To overcome these challenges, we\npropose the Continual Optimal Policy Regularization (COPR) method, which draws\ninspiration from the optimal policy theory. COPR utilizes a sampling\ndistribution as a demonstration and regularization constraints for CL. It\nadopts the Lagrangian Duality (LD) method to dynamically regularize the current\npolicy based on the historically optimal policy, which prevents CF and avoids\nover-emphasizing unbalanced objectives. We also provide formal proof for the\nlearnability of COPR. The experimental results show that COPR outperforms\nstrong CL baselines on our proposed benchmark, in terms of reward-based, GPT-4\nevaluations and human assessment. Furthermore, we validate the robustness of\nCOPR under various CL settings, including different backbones, replay memory\nsizes, and learning orders.",
      "tldr_zh": "该论文针对基于人类反馈的强化学习 (RLHF) 在持续对齐大语言模型 (LLMs) 时面临的挑战，提出 COPR 方法，以解决 Continual Learning (CL) 的兼容性和 Catastrophic Forgetting (CF) 问题。COPR 借鉴最优策略理论，使用采样分布作为演示，并通过 Lagrangian Duality (LD) 动态调节当前策略基于历史最优策略，从而平衡新旧偏好并避免过度强调不平衡目标。实验结果表明，COPR 在奖励-based、GPT-4 评估和人类评估上超过了强有力的 CL 基准，并在不同骨干模型、重放内存大小和学习顺序等设置下显示出鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is a duplicate submission to arXiv:2310.15694, and we believe\n  that this submission has affected the citation of our original paper\n  arXiv:2310.15694",
      "pdf_url": "http://arxiv.org/pdf/2402.14228v3",
      "published_date": "2024-02-22 02:20:08 UTC",
      "updated_date": "2024-12-21 02:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:17:38.889915"
    },
    {
      "arxiv_id": "2402.14212v1",
      "title": "Moonwalk: Inverse-Forward Differentiation",
      "title_zh": "Moonwalk：逆向-前向微分",
      "authors": [
        "Dmitrii Krylov",
        "Armin Karamzade",
        "Roy Fox"
      ],
      "abstract": "Backpropagation, while effective for gradient computation, falls short in\naddressing memory consumption, limiting scalability. This work explores\nforward-mode gradient computation as an alternative in invertible networks,\nshowing its potential to reduce the memory footprint without substantial\ndrawbacks. We introduce a novel technique based on a vector-inverse-Jacobian\nproduct that accelerates the computation of forward gradients while retaining\nthe advantages of memory reduction and preserving the fidelity of true\ngradients. Our method, Moonwalk, has a time complexity linear in the depth of\nthe network, unlike the quadratic time complexity of na\\\"ive forward, and\nempirically reduces computation time by several orders of magnitude without\nallocating more memory. We further accelerate Moonwalk by combining it with\nreverse-mode differentiation to achieve time complexity comparable with\nbackpropagation while maintaining a much smaller memory footprint. Finally, we\nshowcase the robustness of our method across several architecture choices.\nMoonwalk is the first forward-based method to compute true gradients in\ninvertible networks in computation time comparable to backpropagation and using\nsignificantly less memory.",
      "tldr_zh": "这篇论文提出了 Moonwalk，一种基于 Inverse-Forward Differentiation 的新方法，用于在可逆网络中计算梯度，以解决反向传播（Backpropagation）的内存消耗问题。Moonwalk 利用向量-逆雅可比乘积（vector-inverse-Jacobian product）技术，实现线性于网络深度的时间复杂度，并显著减少计算时间，同时保持梯度准确性。作者进一步结合反向模式（reverse-mode）差异化，使其计算时间与 Backpropagation 相当，但内存占用更低，并在多种架构中验证了方法的鲁棒性，是首个在可逆网络中高效计算真实梯度的前向-based 方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14212v1",
      "published_date": "2024-02-22 01:33:31 UTC",
      "updated_date": "2024-02-22 01:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:17:50.483729"
    },
    {
      "arxiv_id": "2402.14208v3",
      "title": "LLM-Assisted Content Conditional Debiasing for Fair Text Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Wenlong Deng",
        "Blair Chen",
        "Beidi Zhao",
        "Chiyu Zhang",
        "Xiaoxiao Li",
        "Christos Thrampoulidis"
      ],
      "abstract": "Mitigating biases in machine learning models has become an increasing concern\nin Natural Language Processing (NLP), particularly in developing fair text\nembeddings, which are crucial yet challenging for real-world applications like\nsearch engines. In response, this paper proposes a novel method for learning\nfair text embeddings. First, we define a novel content-conditional equal\ndistance (CCED) fairness for text embeddings, ensuring content-conditional\nindependence between sensitive attributes and text embeddings. Building on\nCCED, we introduce a content-conditional debiasing (CCD) loss to ensure that\nembeddings of texts with different sensitive attributes but identical content\nmaintain the same distance from the embedding of their corresponding neutral\ntext. Additionally, we tackle the issue of insufficient training data by using\nLarge Language Models (LLMs) with instructions to fairly augment texts into\ndifferent sensitive groups. Our extensive evaluations show that our approach\neffectively enhances fairness while maintaining the utility of embeddings.\nFurthermore, our augmented dataset, combined with the CCED metric, serves as an\nnew benchmark for evaluating fairness.",
      "tldr_zh": "本研究针对自然语言处理(NLP)中的偏见问题，提出了一种LLM-Assisted Content Conditional Debiasing方法，以生成公平的文本嵌入。首先，定义了Content-Conditional Equal Distance (CCED)公平性标准，确保敏感属性与文本嵌入在内容条件下的独立性，并引入Content-Conditional Debiasing (CCD)损失函数，使相同内容的文本嵌入在不同敏感属性下与中性文本保持一致距离。为解决训练数据不足，该方法利用Large Language Models (LLMs)通过指令公平地增强文本数据集。实验结果显示，该方法显著提升了嵌入的公平性，同时保持了其实用性，并提供了CCED指标和增强数据集作为新的公平性评估基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14208v3",
      "published_date": "2024-02-22 01:20:51 UTC",
      "updated_date": "2024-06-24 04:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:18:00.957920"
    },
    {
      "arxiv_id": "2402.14207v2",
      "title": "Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models",
      "title_zh": "使用大型语言模型从零开始辅助撰写类似于维基百科的",
      "authors": [
        "Yijia Shao",
        "Yucheng Jiang",
        "Theodore A. Kanell",
        "Peter Xu",
        "Omar Khattab",
        "Monica S. Lam"
      ],
      "abstract": "We study how to apply large language models to write grounded and organized\nlong-form articles from scratch, with comparable breadth and depth to Wikipedia\npages. This underexplored problem poses new challenges at the pre-writing\nstage, including how to research the topic and prepare an outline prior to\nwriting. We propose STORM, a writing system for the Synthesis of Topic Outlines\nthrough Retrieval and Multi-perspective Question Asking. STORM models the\npre-writing stage by (1) discovering diverse perspectives in researching the\ngiven topic, (2) simulating conversations where writers carrying different\nperspectives pose questions to a topic expert grounded on trusted Internet\nsources, (3) curating the collected information to create an outline.\n  For evaluation, we curate FreshWiki, a dataset of recent high-quality\nWikipedia articles, and formulate outline assessments to evaluate the\npre-writing stage. We further gather feedback from experienced Wikipedia\neditors. Compared to articles generated by an outline-driven\nretrieval-augmented baseline, more of STORM's articles are deemed to be\norganized (by a 25% absolute increase) and broad in coverage (by 10%). The\nexpert feedback also helps identify new challenges for generating grounded long\narticles, such as source bias transfer and over-association of unrelated facts.",
      "tldr_zh": "本研究探讨如何利用大型语言模型（Large Language Models）从零开始撰写类似于Wikipedia的结构化长文，包括广度和深度。研究提出STORM系统，通过检索增强生成（Retrieval-Augmented）和多视角问题提问，模拟对话以发现主题多样视角、向基于可信互联网来源的主题专家提问，并整理信息生成大纲。实验使用FreshWiki数据集评估，结果显示STORM生成的文章在组织性上比基线模型提高25%，在覆盖广度上提高10%。此外，Wikipedia编辑的反馈揭示了新挑战，如来源偏差转移和无关事实的过度关联。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, NAACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2402.14207v2",
      "published_date": "2024-02-22 01:20:17 UTC",
      "updated_date": "2024-04-08 05:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:18:12.914834"
    },
    {
      "arxiv_id": "2402.14187v1",
      "title": "From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Zhou",
        "Xuan Lu",
        "Wei Ai"
      ],
      "abstract": "In the rapidly evolving landscape of social media, the introduction of new\nemojis in Unicode release versions presents a structured opportunity to explore\ndigital language evolution. Analyzing a large dataset of sampled English\ntweets, we examine how newly released emojis gain traction and evolve in\nmeaning. We find that community size of early adopters and emoji semantics are\ncrucial in determining their popularity. Certain emojis experienced notable\nshifts in the meanings and sentiment associations during the diffusion process.\nAdditionally, we propose a novel framework utilizing language models to extract\nwords and pre-existing emojis with semantically similar contexts, which\nenhances interpretation of new emojis. The framework demonstrates its\neffectiveness in improving sentiment classification performance by substituting\nunknown new emojis with familiar ones. This study offers a new perspective in\nunderstanding how new language units are adopted, adapted, and integrated into\nthe fabric of online communication.",
      "tldr_zh": "本研究分析了新表情符号（emojis）在Twitter上的传播与演变，通过一个大型英文Twitter数据集考察了这些符号的采用过程。结果显示，早期采用者的社区规模和表情符号的语义是决定其流行度的关键因素，且某些emojis在传播中经历了含义和情感关联的显著变化。研究提出一个新框架，利用语言模型提取语义相似的词和现有emojis，从而提升对新emojis的解释，并证明该框架可通过替换未知emojis来改善情感分类性能。该工作为理解新语言单位如何被采用、适应并融入在线通信提供了新视角。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages, 3 page appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.14187v1",
      "published_date": "2024-02-22 00:24:44 UTC",
      "updated_date": "2024-02-22 00:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:18:24.716266"
    },
    {
      "arxiv_id": "2402.14182v1",
      "title": "Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization",
      "title_zh": "机器和人类是否关注相似的代码？ 探索大语言模型在代码总结中的可解释性",
      "authors": [
        "Jiliang Li",
        "Yifan Zhang",
        "Zachary Karas",
        "Collin McMillan",
        "Kevin Leach",
        "Yu Huang"
      ],
      "abstract": "Recent language models have demonstrated proficiency in summarizing source\ncode. However, as in many other domains of machine learning, language models of\ncode lack sufficient explainability. Informally, we lack a formulaic or\nintuitive understanding of what and how models learn from code. Explainability\nof language models can be partially provided if, as the models learn to produce\nhigher-quality code summaries, they also align in deeming the same code parts\nimportant as those identified by human programmers. In this paper, we report\nnegative results from our investigation of explainability of language models in\ncode summarization through the lens of human comprehension. We measure human\nfocus on code using eye-tracking metrics such as fixation counts and duration\nin code summarization tasks. To approximate language model focus, we employ a\nstate-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP\n(SHapley Additive exPlanations), to identify which code tokens influence that\ngeneration of summaries. Using these settings, we find no statistically\nsignificant relationship between language models' focus and human programmers'\nattention. Furthermore, alignment between model and human foci in this setting\ndoes not seem to dictate the quality of the LLM-generated summaries. Our study\nhighlights an inability to align human focus with SHAP-based model focus\nmeasures. This result calls for future investigation of multiple open questions\nfor explainable language models for code summarization and software engineering\ntasks in general, including the training mechanisms of language models for\ncode, whether there is an alignment between human and model attention on code,\nwhether human attention can improve the development of language models, and\nwhat other model focus measures are appropriate for improving explainability.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在代码总结中的可解释性问题，specifically 是否机器和人类在代码关注点上存在相似性。研究通过眼动追踪(eye-tracking)技术测量人类程序员的注意力（如 fixation counts 和 duration），并使用 SHAP (SHapley Additive exPlanations) 方法分析模型对代码标记的影响。结果显示，LLMs 的关注点与人类注意力之间没有统计显著的相关性，且这种对齐并不决定总结质量的优劣。论文呼吁进一步调查 LLMs 的训练机制、人类与模型注意力的潜在对齐，以及其他措施来提升代码总结和软件工程任务的可解释性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14182v1",
      "published_date": "2024-02-22 00:01:02 UTC",
      "updated_date": "2024-02-22 00:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T09:18:37.664862"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 121,
  "processed_papers_count": 121,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T09:18:59.968542"
}