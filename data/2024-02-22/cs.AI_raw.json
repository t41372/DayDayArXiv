[
  {
    "arxiv_id": "2402.15027v2",
    "title": "Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education",
    "authors": [
      "A. J. Karran",
      "P. Charland",
      "J-T. Martineau",
      "A. Ortiz de Guinea Lopez de Arana",
      "AM. Lesage",
      "S. Senecal",
      "P-M. Leger"
    ],
    "abstract": "This study investigates the acceptability of different artificial\nintelligence (AI) applications in education from a multi-stakeholder\nperspective, including students, teachers, and parents. Acknowledging the\ntransformative potential of AI in education, it addresses concerns related to\ndata privacy, AI agency, transparency, explainability and the ethical\ndeployment of AI. Through a vignette methodology, participants were presented\nwith four scenarios where AI's agency, transparency, explainability, and\nprivacy were manipulated. After each scenario, participants completed a survey\nthat captured their perceptions of AI's global utility, individual usefulness,\njustice, confidence, risk, and intention to use each scenario's AI if\navailable. The data collection comprising a final sample of 1198\nmulti-stakeholder participants was distributed through a partner institution\nand social media campaigns and focused on individual responses to four AI use\ncases. A mediation analysis of the data indicated that acceptance and trust in\nAI varies significantly across stakeholder groups. We found that the key\nmediators between high and low levels of AI's agency, transparency, and\nexplainability, as well as the intention to use the different educational AI,\nincluded perceived global utility, justice, and confidence. The study\nhighlights that the acceptance of AI in education is a nuanced and multifaceted\nissue that requires careful consideration of specific AI applications and their\ncharacteristics, in addition to the diverse stakeholders' perceptions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "K.3.1; I.2.0"
    ],
    "primary_category": "cs.CY",
    "comment": "28 pages, 2 appendices, 3 figures, 5 tables, original research",
    "pdf_url": "http://arxiv.org/pdf/2402.15027v2",
    "published_date": "2024-02-22 23:59:59 UTC",
    "updated_date": "2024-02-28 14:21:52 UTC"
  },
  {
    "arxiv_id": "2402.15019v1",
    "title": "Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration",
    "authors": [
      "Wonjeong Choi",
      "Jungwuk Park",
      "Dong-Jun Han",
      "Younghyun Park",
      "Jaekyun Moon"
    ],
    "abstract": "Research interests in the robustness of deep neural networks against domain\nshifts have been rapidly increasing in recent years. Most existing works,\nhowever, focus on improving the accuracy of the model, not the calibration\nperformance which is another important requirement for trustworthy AI systems.\nTemperature scaling (TS), an accuracy-preserving post-hoc calibration method,\nhas been proven to be effective in in-domain settings, but not in out-of-domain\n(OOD) due to the difficulty in obtaining a validation set for the unseen domain\nbeforehand. In this paper, we propose consistency-guided temperature scaling\n(CTS), a new temperature scaling strategy that can significantly enhance the\nOOD calibration performance by providing mutual supervision among data samples\nin the source domains. Motivated by our observation that over-confidence\nstemming from inconsistent sample predictions is the main obstacle to OOD\ncalibration, we propose to guide the scaling process by taking consistencies\ninto account in terms of two different aspects -- style and content -- which\nare the key components that can well-represent data samples in multi-domain\nsettings. Experimental results demonstrate that our proposed strategy\noutperforms existing works, achieving superior OOD calibration performance on\nvarious datasets. This can be accomplished by employing only the source domains\nwithout compromising accuracy, making our scheme directly applicable to various\ntrustworthy AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI-24 (The 38th AAAI Conference on Artificial\n  Intelligence, February 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.15019v1",
    "published_date": "2024-02-22 23:36:18 UTC",
    "updated_date": "2024-02-22 23:36:18 UTC"
  },
  {
    "arxiv_id": "2402.15017v1",
    "title": "Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning",
    "authors": [
      "Zhuoyan Xu",
      "Zhenmei Shi",
      "Junyi Wei",
      "Fangzhou Mu",
      "Yin Li",
      "Yingyu Liang"
    ],
    "abstract": "Foundation models have emerged as a powerful tool for many AI problems.\nDespite the tremendous success of foundation models, effective adaptation to\nnew tasks, particularly those with limited labels, remains an open question and\nlacks theoretical understanding. An emerging solution with recent success in\nvision and NLP involves finetuning a foundation model on a selection of\nrelevant tasks, before its adaptation to a target task with limited labeled\nsamples. In this paper, we study the theoretical justification of this\nmultitask finetuning approach. Our theoretical analysis reveals that with a\ndiverse set of related tasks, this multitask finetuning leads to reduced error\nin the target task, in comparison to directly adapting the same pretrained\nmodel. We quantify the relationship between finetuning tasks and target tasks\nby diversity and consistency metrics, and further propose a practical task\nselection algorithm. We substantiate our theoretical claims with extensive\nempirical evidence. Further, we present results affirming our task selection\nalgorithm adeptly chooses related finetuning tasks, providing advantages to the\nmodel performance on target tasks. We believe our study shed new light on the\neffective adaptation of foundation models to new tasks that lack abundant\nlabels. Our code is available at\nhttps://github.com/OliverXUZY/Foudation-Model_Multitask.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2024. 54 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.15017v1",
    "published_date": "2024-02-22 23:29:42 UTC",
    "updated_date": "2024-02-22 23:29:42 UTC"
  },
  {
    "arxiv_id": "2402.15012v1",
    "title": "Ar-Spider: Text-to-SQL in Arabic",
    "authors": [
      "Saleh Almohaimeed",
      "Saad Almohaimeed",
      "Mansour Al Ghanim",
      "Liqiang Wang"
    ],
    "abstract": "In Natural Language Processing (NLP), one of the most important tasks is\ntext-to-SQL semantic parsing, which focuses on enabling users to interact with\nthe database in a more natural manner. In recent years, text-to-SQL has made\nsignificant progress, but most were English-centric. In this paper, we\nintroduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset. Due\nto the unique nature of the language, two major challenges have been\nencountered, namely schema linguistic and SQL structural challenges. In order\nto handle these issues and conduct the experiments, we adopt two baseline\nmodels LGESQL [4] and S2SQL [12], both of which are tested with two\ncross-lingual models to alleviate the effects of schema linguistic and SQL\nstructure linking challenges. The baselines demonstrate decent single-language\nperformance on our Arabic text-to-SQL dataset, Ar-Spider, achieving 62.48% for\nS2SQL and 65.57% for LGESQL, only 8.79% below the highest results achieved by\nthe baselines when trained in English dataset. To achieve better performance on\nArabic text-to-SQL, we propose the context similarity relationship (CSR)\napproach, which results in a significant increase in the overall performance of\nabout 1.52% for S2SQL and 1.06% for LGESQL and closes the gap between Arabic\nand English languages to 7.73%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACM SAC Conference (SAC 24)",
    "pdf_url": "http://arxiv.org/pdf/2402.15012v1",
    "published_date": "2024-02-22 23:11:17 UTC",
    "updated_date": "2024-02-22 23:11:17 UTC"
  },
  {
    "arxiv_id": "2402.15011v2",
    "title": "A Conversational Brain-Artificial Intelligence Interface",
    "authors": [
      "Anja Meunier",
      "Michal Robert Žák",
      "Lucas Munz",
      "Sofiya Garkot",
      "Manuel Eder",
      "Jiachen Xu",
      "Moritz Grosse-Wentrup"
    ],
    "abstract": "We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class\nof Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on\nintact cognitive capabilities, BAIs leverage the power of artificial\nintelligence to replace parts of the neuro-cognitive processing pipeline. BAIs\nallow users to accomplish complex tasks by providing high-level intentions,\nwhile a pre-trained AI agent determines low-level details. This approach\nenlarges the target audience of BCIs to individuals with cognitive impairments,\na population often excluded from the benefits of conventional BCIs. We present\nthe general concept of BAIs and illustrate the potential of this new approach\nwith a Conversational BAI based on EEG. In particular, we show in an experiment\nwith simulated phone conversations that the Conversational BAI enables complex\ncommunication without the need to generate language. Our work thus\ndemonstrates, for the first time, the ability of a speech neuroprosthesis to\nenable fluent communication in realistic scenarios with non-invasive\ntechnologies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages (39 with supplementary meterial), 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.15011v2",
    "published_date": "2024-02-22 23:11:12 UTC",
    "updated_date": "2024-03-14 23:52:30 UTC"
  },
  {
    "arxiv_id": "2402.15010v2",
    "title": "How Important Is Tokenization in French Medical Masked Language Models?",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Beatrice Daille",
      "Mickael Rouvier",
      "Richard Dufour"
    ],
    "abstract": "Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 2024 Joint International Conference on\n  Computational Linguistics, Language Resources and Evaluation (LREC-COLING\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.15010v2",
    "published_date": "2024-02-22 23:11:08 UTC",
    "updated_date": "2024-06-09 15:11:31 UTC"
  },
  {
    "arxiv_id": "2403.17379v1",
    "title": "Exploring and Applying Audio-Based Sentiment Analysis in Music",
    "authors": [
      "Etash Jhanji"
    ],
    "abstract": "Sentiment analysis is a continuously explored area of text processing that\ndeals with the computational analysis of opinions, sentiments, and subjectivity\nof text. However, this idea is not limited to text and speech, in fact, it\ncould be applied to other modalities. In reality, humans do not express\nthemselves in text as deeply as they do in music. The ability of a\ncomputational model to interpret musical emotions is largely unexplored and\ncould have implications and uses in therapy and musical queuing. In this paper,\ntwo individual tasks are addressed. This study seeks to (1) predict the emotion\nof a musical clip over time and (2) determine the next emotion value after the\nmusic in a time series to ensure seamless transitions. Utilizing data from the\nEmotions in Music Database, which contains clips of songs selected from the\nFree Music Archive annotated with levels of valence and arousal as reported on\nRussel's circumplex model of affect by multiple volunteers, models are trained\nfor both tasks. Overall, the performance of these models reflected that they\nwere able to perform the tasks they were designed for effectively and\naccurately.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 7 figures, 2 tables. For source code, see\n  https://github.com/etashj/Exploring-and-Applying-Audio-Based-Sentiment-Analysis",
    "pdf_url": "http://arxiv.org/pdf/2403.17379v1",
    "published_date": "2024-02-22 22:34:06 UTC",
    "updated_date": "2024-02-22 22:34:06 UTC"
  },
  {
    "arxiv_id": "2402.14992v2",
    "title": "tinyBenchmarks: evaluating LLMs with fewer examples",
    "authors": [
      "Felipe Maia Polo",
      "Lucas Weber",
      "Leshem Choshen",
      "Yuekai Sun",
      "Gongjun Xu",
      "Mikhail Yurochkin"
    ],
    "abstract": "The versatility of large language models (LLMs) led to the creation of\ndiverse benchmarks that thoroughly test a variety of language models'\nabilities. These benchmarks consist of tens of thousands of examples making\nevaluation of LLMs very expensive. In this paper, we investigate strategies to\nreduce the number of evaluations needed to assess the performance of an LLM on\nseveral key benchmarks. For example, we show that to accurately estimate the\nperformance of an LLM on MMLU, a popular multiple-choice QA benchmark\nconsisting of 14K examples, it is sufficient to evaluate this LLM on 100\ncurated examples. We release evaluation tools and tiny versions of popular\nbenchmarks: Open LLM Leaderboard, MMLU, HELM, and AlpacaEval 2.0. Our empirical\nanalysis demonstrates that these tools and tiny benchmarks are sufficient to\nreliably and efficiently reproduce the original evaluation results.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 41st International Conference on Machine Learning\n  (ICML)",
    "pdf_url": "http://arxiv.org/pdf/2402.14992v2",
    "published_date": "2024-02-22 22:05:23 UTC",
    "updated_date": "2024-05-26 22:27:23 UTC"
  },
  {
    "arxiv_id": "2402.14989v6",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data",
    "authors": [
      "YongKyung Oh",
      "Dong-Young Lim",
      "Sungil Kim"
    ],
    "abstract": "Irregular sampling intervals and missing values in real-world time series\ndata present challenges for conventional methods that assume consistent\nintervals and complete data. Neural Ordinary Differential Equations (Neural\nODEs) offer an alternative approach, utilizing neural networks combined with\nODE solvers to learn continuous latent representations through parameterized\nvector fields. Neural Stochastic Differential Equations (Neural SDEs) extend\nNeural ODEs by incorporating a diffusion term, although this addition is not\ntrivial, particularly when addressing irregular intervals and missing values.\nConsequently, careful design of drift and diffusion functions is crucial for\nmaintaining stability and enhancing performance, while incautious choices can\nresult in adverse properties such as the absence of strong solutions,\nstochastic destabilization, or unstable Euler discretizations, significantly\naffecting Neural SDEs' performance. In this study, we propose three stable\nclasses of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE.\nThen, we rigorously demonstrate their robustness in maintaining excellent\nperformance under distribution shift, while effectively preventing overfitting.\nTo assess the effectiveness of our approach, we conduct extensive experiments\non four benchmark datasets for interpolation, forecasting, and classification\ntasks, and analyze the robustness of our methods with 30 public datasets under\ndifferent missing rates. Our results demonstrate the efficacy of the proposed\nmethod in handling real-world irregular time series data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the Twelfth International Conference on Learning\n  Representations (ICLR 2024), Spotlight presentation (Notable Top 5%).\n  https://openreview.net/forum?id=4VIgNuQ1pY",
    "pdf_url": "http://arxiv.org/pdf/2402.14989v6",
    "published_date": "2024-02-22 22:00:03 UTC",
    "updated_date": "2025-01-24 23:48:15 UTC"
  },
  {
    "arxiv_id": "2402.14978v2",
    "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation",
    "authors": [
      "Orit Shaer",
      "Angelora Cooper",
      "Osnat Mokryn",
      "Andrew L. Kun",
      "Hagit Ben Shoshan"
    ],
    "abstract": "The growing availability of generative AI technologies such as large language\nmodels (LLMs) has significant implications for creative work. This paper\nexplores twofold aspects of integrating LLMs into the creative process - the\ndivergence stage of idea generation, and the convergence stage of evaluation\nand selection of ideas. We devised a collaborative group-AI Brainwriting\nideation framework, which incorporated an LLM as an enhancement into the group\nideation process, and evaluated the idea generation process and the resulted\nsolution space. To assess the potential of using LLMs in the idea evaluation\nprocess, we design an evaluation engine and compared it to idea ratings\nassigned by three expert and six novice evaluators. Our findings suggest that\nintegrating LLM in Brainwriting could enhance both the ideation process and its\noutcome. We also provide evidence that LLMs can support idea evaluation. We\nconclude by discussing implications for HCI education and practice.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "H.5.2; J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "Conditionally Accepted to CHI24. 27 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.14978v2",
    "published_date": "2024-02-22 21:34:52 UTC",
    "updated_date": "2024-02-29 22:47:21 UTC"
  },
  {
    "arxiv_id": "2402.14976v1",
    "title": "Unsupervised Domain Adaptation within Deep Foundation Latent Spaces",
    "authors": [
      "Dmitry Kangin",
      "Plamen Angelov"
    ],
    "abstract": "The vision transformer-based foundation models, such as ViT or Dino-V2, are\naimed at solving problems with little or no finetuning of features. Using a\nsetting of prototypical networks, we analyse to what extent such foundation\nmodels can solve unsupervised domain adaptation without finetuning over the\nsource or target domain. Through quantitative analysis, as well as qualitative\ninterpretations of decision making, we demonstrate that the suggested method\ncan improve upon existing baselines, as well as showcase the limitations of\nsuch approach yet to be solved.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14976v1",
    "published_date": "2024-02-22 21:25:20 UTC",
    "updated_date": "2024-02-22 21:25:20 UTC"
  },
  {
    "arxiv_id": "2402.14974v2",
    "title": "Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data",
    "authors": [
      "Majid Farhadloo",
      "Arun Sharma",
      "Jayant Gupta",
      "Alexey Leontovich",
      "Svetomir N. Markovic",
      "Shashi Shekhar"
    ],
    "abstract": "Given multi-category point sets from different place-types, our goal is to\ndevelop a spatially-lucid classifier that can distinguish between two classes\nbased on the arrangements of their points. This problem is important for many\napplications, such as oncology, for analyzing immune-tumor relationships and\ndesigning new immunotherapies. It is challenging due to spatial variability and\ninterpretability needs. Previously proposed techniques require dense training\ndata or have limited ability to handle significant spatial variability within a\nsingle place-type. Most importantly, these deep neural network (DNN) approaches\nare not designed to work in non-Euclidean space, particularly point sets.\nExisting non-Euclidean DNN methods are limited to one-size-fits-all approaches.\nWe explore a spatial ensemble framework that explicitly uses different training\nstrategies, including weighted-distance learning rate and spatial domain\nadaptation, on various place-types for spatially-lucid classification.\nExperimental results on real-world datasets (e.g., MxIF oncology data) show\nthat the proposed framework provides higher prediction accuracy than baseline\nmethods.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "SIAM International Conference on Data Mining (SDM24)",
    "pdf_url": "http://arxiv.org/pdf/2402.14974v2",
    "published_date": "2024-02-22 21:22:21 UTC",
    "updated_date": "2025-04-24 16:45:16 UTC"
  },
  {
    "arxiv_id": "2402.14973v4",
    "title": "GenCeption: Evaluate Vision LLMs with Unlabeled Unimodal Data",
    "authors": [
      "Lele Cao",
      "Valentin Buchner",
      "Zineb Senane",
      "Fangkai Yang"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are typically assessed using\nexpensive annotated multimodal benchmarks, which often lag behind the rapidly\nevolving demands of MLLM evaluation. This paper outlines and validates\nGenCeption, a novel, annotation-free evaluation method that requires only\nunimodal data to measure inter-modality semantic coherence and inversely\nassesses MLLMs' tendency to hallucinate. This approach eliminates the need for\ncostly data annotation, minimizes the risk of training data contamination, is\nexpected to result in slower benchmark saturation, and avoids the illusion of\nemerging abilities. Inspired by the DrawCeption game, GenCeption begins with a\nnon-textual sample and proceeds through iterative description and generation\nsteps. The semantic drift across iterations is quantified using the GC@T\nmetric. While GenCeption is principally applicable to MLLMs across various\nmodalities, this paper focuses on its implementation and validation for Vision\nLLMs (VLLMs). Based on the GenCeption method, we establish the MMECeption\nbenchmark for evaluating VLLMs, and compare the performance of several popular\nVLLMs and human annotators. Our empirical results validate GenCeption's\neffectiveness, demonstrating strong correlations with established VLLM\nbenchmarks. VLLMs still significantly lag behind human performance and struggle\nespecially with text-intensive tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.7; I.4"
    ],
    "primary_category": "cs.CL",
    "comment": "Published by Computer Speech & Language\n  (https://doi.org/10.1016/j.csl.2025.101785). Source code and Leaderboard:\n  https://github.com/llcresearch/GenCeption",
    "pdf_url": "http://arxiv.org/pdf/2402.14973v4",
    "published_date": "2024-02-22 21:22:04 UTC",
    "updated_date": "2025-03-05 21:42:27 UTC"
  },
  {
    "arxiv_id": "2402.14972v1",
    "title": "MultiLS: A Multi-task Lexical Simplification Framework",
    "authors": [
      "Kai North",
      "Tharindu Ranasinghe",
      "Matthew Shardlow",
      "Marcos Zampieri"
    ],
    "abstract": "Lexical Simplification (LS) automatically replaces difficult to read words\nfor easier alternatives while preserving a sentence's original meaning. LS is a\nprecursor to Text Simplification with the aim of improving text accessibility\nto various target demographics, including children, second language learners,\nindividuals with reading disabilities or low literacy. Several datasets exist\nfor LS. These LS datasets specialize on one or two sub-tasks within the LS\npipeline. However, as of this moment, no single LS dataset has been developed\nthat covers all LS sub-tasks. We present MultiLS, the first LS framework that\nallows for the creation of a multi-task LS dataset. We also present MultiLS-PT,\nthe first dataset to be created using the MultiLS framework. We demonstrate the\npotential of MultiLS-PT by carrying out all LS sub-tasks of (1). lexical\ncomplexity prediction (LCP), (2). substitute generation, and (3). substitute\nranking for Portuguese. Model performances are reported, ranging from\ntransformer-based models to more recent large language models (LLMs).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14972v1",
    "published_date": "2024-02-22 21:16:18 UTC",
    "updated_date": "2024-02-22 21:16:18 UTC"
  },
  {
    "arxiv_id": "2402.14963v2",
    "title": "Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning",
    "authors": [
      "Hanqi Yan",
      "Qinglin Zhu",
      "Xinyu Wang",
      "Lin Gui",
      "Yulan He"
    ],
    "abstract": "While Large language models (LLMs) have the capability to iteratively reflect\non their own outputs, recent studies have observed their struggles with\nknowledge-rich problems without access to external resources. In addition to\nthe inefficiency of LLMs in self-assessment, we also observe that LLMs struggle\nto revisit their predictions despite receiving explicit negative feedback.\nTherefore, We propose Mirror, a Multiple-perspective self-reflection method for\nknowledge-rich reasoning, to avoid getting stuck at a particular reflection\niteration. Mirror enables LLMs to reflect from multiple-perspective clues,\nachieved through a heuristic interaction between a Navigator and a Reasoner. It\nguides agents toward diverse yet plausibly reliable reasoning trajectory\nwithout access to ground truth by encouraging (1) diversity of directions\ngenerated by Navigator and (2) agreement among strategically induced\nperturbations in responses generated by the Reasoner. The experiments on five\nreasoning datasets demonstrate that Mirror's superiority over several\ncontemporary self-reflection approaches. Additionally, the ablation study\nstudies clearly indicate that our strategies alleviate the aforementioned\nchallenges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL24, Main Conference, long paper. Code is available at\n  https://github.com/hanqi-qi/Mirror.git",
    "pdf_url": "http://arxiv.org/pdf/2402.14963v2",
    "published_date": "2024-02-22 20:57:17 UTC",
    "updated_date": "2024-06-24 10:05:24 UTC"
  },
  {
    "arxiv_id": "2405.00682v1",
    "title": "SynthBrainGrow: Synthetic Diffusion Brain Aging for Longitudinal MRI Data Generation in Young People",
    "authors": [
      "Anna Zapaishchykova",
      "Benjamin H. Kann",
      "Divyanshu Tak",
      "Zezhong Ye",
      "Daphne A. Haas-Kogan",
      "Hugo J. W. L. Aerts"
    ],
    "abstract": "Synthetic longitudinal brain MRI simulates brain aging and would enable more\nefficient research on neurodevelopmental and neurodegenerative conditions.\nSynthetically generated, age-adjusted brain images could serve as valuable\nalternatives to costly longitudinal imaging acquisitions, serve as internal\ncontrols for studies looking at the effects of environmental or therapeutic\nmodifiers on brain development, and allow data augmentation for diverse\npopulations. In this paper, we present a diffusion-based approach called\nSynthBrainGrow for synthetic brain aging with a two-year step. To validate the\nfeasibility of using synthetically-generated data on downstream tasks, we\ncompared structural volumetrics of two-year-aged brains against\nsynthetically-aged brain MRI. Results show that SynthBrainGrow can accurately\ncapture substructure volumetrics and simulate structural changes such as\nventricle enlargement and cortical thinning. Our approach provides a novel way\nto generate longitudinal brain datasets from cross-sectional data to enable\naugmented training and benchmarking of computational tools for analyzing\nlifespan trajectories. This work signifies an important advance in generative\nmodeling to synthesize realistic longitudinal data with limited lifelong MRI\nscans. The code is available at XXX.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.SP",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.00682v1",
    "published_date": "2024-02-22 20:47:40 UTC",
    "updated_date": "2024-02-22 20:47:40 UTC"
  },
  {
    "arxiv_id": "2403.00791v2",
    "title": "L+M-24: Building a Dataset for Language + Molecules @ ACL 2024",
    "authors": [
      "Carl Edwards",
      "Qingyun Wang",
      "Lawrence Zhao",
      "Heng Ji"
    ],
    "abstract": "Language-molecule models have emerged as an exciting direction for molecular\ndiscovery and understanding. However, training these models is challenging due\nto the scarcity of molecule-language pair datasets. At this point, datasets\nhave been released which are 1) small and scraped from existing databases, 2)\nlarge but noisy and constructed by performing entity linking on the scientific\nliterature, and 3) built by converting property prediction datasets to natural\nlanguage using templates. In this document, we detail the $\\textit{L+M-24}$\ndataset, which has been created for the Language + Molecules Workshop shared\ntask at ACL 2024. In particular, $\\textit{L+M-24}$ is designed to focus on\nthree key benefits of natural language in molecule design: compositionality,\nfunctionality, and abstraction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "The dataset, finetuned baselines, and evaluation code are released\n  publicly at https://github.com/language-plus-molecules/LPM-24-Dataset through\n  https://huggingface.co/language-plus-molecules",
    "pdf_url": "http://arxiv.org/pdf/2403.00791v2",
    "published_date": "2024-02-22 20:11:24 UTC",
    "updated_date": "2024-07-04 17:21:48 UTC"
  },
  {
    "arxiv_id": "2402.14933v1",
    "title": "Path Planning based on 2D Object Bounding-box",
    "authors": [
      "Yanliang Huang",
      "Liguo Zhou",
      "Chang Liu",
      "Alois Knoll"
    ],
    "abstract": "The implementation of Autonomous Driving (AD) technologies within urban\nenvironments presents significant challenges. These challenges necessitate the\ndevelopment of advanced perception systems and motion planning algorithms\ncapable of managing situations of considerable complexity. Although the\nend-to-end AD method utilizing LiDAR sensors has achieved significant success\nin this scenario, we argue that its drawbacks may hinder its practical\napplication. Instead, we propose the vision-centric AD as a promising\nalternative offering a streamlined model without compromising performance. In\nthis study, we present a path planning method that utilizes 2D bounding boxes\nof objects, developed through imitation learning in urban driving scenarios.\nThis is achieved by integrating high-definition (HD) map data with images\ncaptured by surrounding cameras. Subsequent perception tasks involve\nbounding-box detection and tracking, while the planning phase employs both\nlocal embeddings via Graph Neural Network (GNN) and global embeddings via\nTransformer for temporal-spatial feature aggregation, ultimately producing\noptimal path planning information. We evaluated our model on the nuPlan\nplanning task and observed that it performs competitively in comparison to\nexisting vision-centric methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14933v1",
    "published_date": "2024-02-22 19:34:56 UTC",
    "updated_date": "2024-02-22 19:34:56 UTC"
  },
  {
    "arxiv_id": "2402.14929v1",
    "title": "Federated Fairness without Access to Sensitive Groups",
    "authors": [
      "Afroditi Papadaki",
      "Natalia Martinez",
      "Martin Bertran",
      "Guillermo Sapiro",
      "Miguel Rodrigues"
    ],
    "abstract": "Current approaches to group fairness in federated learning assume the\nexistence of predefined and labeled sensitive groups during training. However,\ndue to factors ranging from emerging regulations to dynamics and\nlocation-dependency of protected groups, this assumption may be unsuitable in\nmany real-world scenarios. In this work, we propose a new approach to guarantee\ngroup fairness that does not rely on any predefined definition of sensitive\ngroups or additional labels. Our objective allows the federation to learn a\nPareto efficient global model ensuring worst-case group fairness and it\nenables, via a single hyper-parameter, trade-offs between fairness and utility,\nsubject only to a group size constraint. This implies that any sufficiently\nlarge subset of the population is guaranteed to receive at least a minimum\nlevel of utility performance from the model. The proposed objective encompasses\nexisting approaches as special cases, such as empirical risk minimization and\nsubgroup robustness objectives from centralized machine learning. We provide an\nalgorithm to solve this problem in federation that enjoys convergence and\nexcess risk guarantees. Our empirical results indicate that the proposed\napproach can effectively improve the worst-performing group that may be present\nwithout unnecessarily hurting the average performance, exhibits superior or\ncomparable performance to relevant baselines, and achieves a large set of\nsolutions with different fairness-utility trade-offs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14929v1",
    "published_date": "2024-02-22 19:24:59 UTC",
    "updated_date": "2024-02-22 19:24:59 UTC"
  },
  {
    "arxiv_id": "2402.14928v1",
    "title": "Learning Inverse Kinodynamics for Autonomous Vehicle Drifting",
    "authors": [
      "M. Suvarna",
      "O. Tehrani"
    ],
    "abstract": "In this work, we explore a data-driven learning-based approach to learning\nthe kinodynamic model of a small autonomous vehicle, and observe the effect it\nhas on motion planning, specifically autonomous drifting. When executing a\nmotion plan in the real world, there are numerous causes for error, and what is\nplanned is often not what is executed on the actual car. Learning a kinodynamic\nplanner based off of inertial measurements and executed commands can help us\nlearn the world state. In our case, we look towards the realm of drifting; it\nis a complex maneuver that requires a smooth enough surface, high enough speed,\nand a drastic change in velocity. We attempt to learn the kinodynamic model for\nthese drifting maneuvers, and attempt to tighten the slip of the car. Our\napproach is able to learn a kinodynamic model for high-speed circular\nnavigation, and is able to avoid obstacles on an autonomous drift at high speed\nby correcting an executed curvature for loose drifts. We seek to adjust our\nkinodynamic model for success in tighter drifts in future work.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14928v1",
    "published_date": "2024-02-22 19:24:56 UTC",
    "updated_date": "2024-02-22 19:24:56 UTC"
  },
  {
    "arxiv_id": "2402.14922v1",
    "title": "Practical Insights into Knowledge Distillation for Pre-Trained Models",
    "authors": [
      "Norah Alballa",
      "Marco Canini"
    ],
    "abstract": "This research investigates the enhancement of knowledge distillation (KD)\nprocesses in pre-trained models, an emerging field in knowledge transfer with\nsignificant implications for distributed training and federated learning\nenvironments. These environments benefit from reduced communication demands and\naccommodate various model architectures. Despite the adoption of numerous KD\napproaches for transferring knowledge among pre-trained models, a comprehensive\nunderstanding of KD's application in these scenarios is lacking. Our study\nconducts an extensive comparison of multiple KD techniques, including standard\nKD, tuned KD (via optimized temperature and weight parameters), deep mutual\nlearning, and data partitioning KD. We assess these methods across various data\ndistribution strategies to identify the most effective contexts for each.\nThrough detailed examination of hyperparameter tuning, informed by extensive\ngrid search evaluations, we pinpoint when adjustments are crucial to enhance\nmodel performance. This paper sheds light on optimal hyperparameter settings\nfor distinct data partitioning scenarios and investigates KD's role in\nimproving federated learning by minimizing communication rounds and expediting\nthe training process. By filling a notable void in current research, our\nfindings serve as a practical framework for leveraging KD in pre-trained models\nwithin collaborative and federated learning frameworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14922v1",
    "published_date": "2024-02-22 19:07:08 UTC",
    "updated_date": "2024-02-22 19:07:08 UTC"
  },
  {
    "arxiv_id": "2402.14815v1",
    "title": "Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging",
    "authors": [
      "Yuzhe Yang",
      "Yujia Liu",
      "Xin Liu",
      "Avanti Gulhane",
      "Domenico Mastrodicasa",
      "Wei Wu",
      "Edward J Wang",
      "Dushyant W Sahani",
      "Shwetak Patel"
    ],
    "abstract": "Advances in artificial intelligence (AI) have achieved expert-level\nperformance in medical imaging applications. Notably, self-supervised\nvision-language foundation models can detect a broad spectrum of pathologies\nwithout relying on explicit training annotations. However, it is crucial to\nensure that these AI models do not mirror or amplify human biases, thereby\ndisadvantaging historically marginalized groups such as females or Black\npatients. The manifestation of such biases could systematically delay essential\nmedical care for certain patient subgroups. In this study, we investigate the\nalgorithmic fairness of state-of-the-art vision-language foundation models in\nchest X-ray diagnosis across five globally-sourced datasets. Our findings\nreveal that compared to board-certified radiologists, these foundation models\nconsistently underdiagnose marginalized groups, with even higher rates seen in\nintersectional subgroups, such as Black female patients. Such demographic\nbiases present over a wide range of pathologies and demographic attributes.\nFurther analysis of the model embedding uncovers its significant encoding of\ndemographic information. Deploying AI systems with these biases in medical\nimaging can intensify pre-existing care disparities, posing potential\nchallenges to equitable healthcare access and raising ethical questions about\ntheir clinical application.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Code and data are available at\n  https://github.com/YyzHarry/vlm-fairness",
    "pdf_url": "http://arxiv.org/pdf/2402.14815v1",
    "published_date": "2024-02-22 18:59:53 UTC",
    "updated_date": "2024-02-22 18:59:53 UTC"
  },
  {
    "arxiv_id": "2402.14812v2",
    "title": "WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition",
    "authors": [
      "Lianghui Zhu",
      "Junwei Zhou",
      "Yan Liu",
      "Xin Hao",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "abstract": "Weakly supervised visual recognition using inexact supervision is a critical\nyet challenging learning problem. It significantly reduces human labeling costs\nand traditionally relies on multi-instance learning and pseudo-labeling. This\npaper introduces WeakSAM and solves the weakly-supervised object detection\n(WSOD) and segmentation by utilizing the pre-learned world knowledge contained\nin a vision foundation model, i.e., the Segment Anything Model (SAM). WeakSAM\naddresses two critical limitations in traditional WSOD retraining, i.e., pseudo\nground truth (PGT) incompleteness and noisy PGT instances, through adaptive PGT\ngeneration and Region of Interest (RoI) drop regularization. It also addresses\nthe SAM's problems of requiring prompts and category unawareness for automatic\nobject detection and segmentation. Our results indicate that WeakSAM\nsignificantly surpasses previous state-of-the-art methods in WSOD and WSIS\nbenchmarks with large margins, i.e. average improvements of 7.4% and 8.5%,\nrespectively. The code is available at \\url{https://github.com/hustvl/WeakSAM}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024. Code is available at\n  https://github.com/hustvl/WeakSAM",
    "pdf_url": "http://arxiv.org/pdf/2402.14812v2",
    "published_date": "2024-02-22 18:59:24 UTC",
    "updated_date": "2024-08-17 04:55:22 UTC"
  },
  {
    "arxiv_id": "2402.14810v1",
    "title": "GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion",
    "authors": [
      "Xueyi Liu",
      "Li Yi"
    ],
    "abstract": "In this work, we tackle the challenging problem of denoising hand-object\ninteractions (HOI). Given an erroneous interaction sequence, the objective is\nto refine the incorrect hand trajectory to remove interaction artifacts for a\nperceptually realistic sequence. This challenge involves intricate interaction\nnoise, including unnatural hand poses and incorrect hand-object relations,\nalongside the necessity for robust generalization to new interactions and\ndiverse noise patterns. We tackle those challenges through a novel approach,\nGeneOH Diffusion, incorporating two key designs: an innovative contact-centric\nHOI representation named GeneOH and a new domain-generalizable denoising\nscheme. The contact-centric representation GeneOH informatively parameterizes\nthe HOI process, facilitating enhanced generalization across various HOI\nscenarios. The new denoising scheme consists of a canonical denoising model\ntrained to project noisy data samples from a whitened noise space to a clean\ndata manifold and a \"denoising via diffusion\" strategy which can handle input\ntrajectories with various noise patterns by first diffusing them to align with\nthe whitened noise space and cleaning via the canonical denoiser. Extensive\nexperiments on four benchmarks with significant domain variations demonstrate\nthe superior effectiveness of our method. GeneOH Diffusion also shows promise\nfor various downstream applications. Project website:\nhttps://meowuu7.github.io/GeneOH-Diffusion/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICLR 2024. Project website:\n  https://meowuu7.github.io/GeneOH-Diffusion/; Huggingface Demo:\n  https://huggingface.co/spaces/xymeow7/gene-hoi-denoising; Code:\n  https://github.com/Meowuu7/GeneOH-Diffusion",
    "pdf_url": "http://arxiv.org/pdf/2402.14810v1",
    "published_date": "2024-02-22 18:59:21 UTC",
    "updated_date": "2024-02-22 18:59:21 UTC"
  },
  {
    "arxiv_id": "2402.14809v4",
    "title": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning",
    "authors": [
      "Zicheng Lin",
      "Zhibin Gou",
      "Tian Liang",
      "Ruilin Luo",
      "Haowei Liu",
      "Yujiu Yang"
    ],
    "abstract": "The ability of Large Language Models (LLMs) to critique and refine their\nreasoning is crucial for their application in evaluation, feedback provision,\nand self-improvement. This paper introduces CriticBench, a comprehensive\nbenchmark designed to assess LLMs' abilities to critique and rectify their\nreasoning across a variety of tasks. CriticBench encompasses five reasoning\ndomains: mathematical, commonsense, symbolic, coding, and algorithmic. It\ncompiles 15 datasets and incorporates responses from three LLM families.\nUtilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in\ngeneration, critique, and correction reasoning, i.e., GQC reasoning. Our\nfindings reveal: (1) a linear relationship in GQC capabilities, with\ncritique-focused training markedly enhancing performance; (2) a task-dependent\nvariation in correction effectiveness, with logic-oriented tasks being more\namenable to correction; (3) GQC knowledge inconsistencies that decrease as\nmodel size increases; and (4) an intriguing inter-model critiquing dynamic,\nwhere stronger models are better at critiquing weaker ones, while weaker models\ncan surprisingly surpass stronger ones in their self-critique. We hope these\ninsights into the nuanced critique-correct reasoning of LLMs will foster\nfurther research in LLM critique and self-improvement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2402.14809v4",
    "published_date": "2024-02-22 18:59:02 UTC",
    "updated_date": "2024-06-01 07:46:28 UTC"
  },
  {
    "arxiv_id": "2402.14905v2",
    "title": "MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases",
    "authors": [
      "Zechun Liu",
      "Changsheng Zhao",
      "Forrest Iandola",
      "Chen Lai",
      "Yuandong Tian",
      "Igor Fedorov",
      "Yunyang Xiong",
      "Ernie Chang",
      "Yangyang Shi",
      "Raghuraman Krishnamoorthi",
      "Liangzhen Lai",
      "Vikas Chandra"
    ],
    "abstract": "This paper addresses the growing need for efficient large language models\n(LLMs) on mobile devices, driven by increasing cloud costs and latency\nconcerns. We focus on designing top-quality LLMs with fewer than a billion\nparameters, a practical choice for mobile deployment. Contrary to prevailing\nbelief emphasizing the pivotal role of data and parameter quantity in\ndetermining model quality, our investigation underscores the significance of\nmodel architecture for sub-billion scale LLMs. Leveraging deep and thin\narchitectures, coupled with embedding sharing and grouped-query attention\nmechanisms, we establish a strong baseline network denoted as MobileLLM, which\nattains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M\nstate-of-the-art models. Additionally, we propose an immediate block-wise\nweight-sharing approach with no increase in model size and only marginal\nlatency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a\nfurther accuracy enhancement of 0.7%/0.8% than MobileLLM 125M/350M. Moreover,\nMobileLLM model family shows significant improvements compared to previous\nsub-billion models on chat benchmarks, and demonstrates close correctness to\nLLaMA-v2 7B in API calling tasks, highlighting the capability of small models\nfor common on-device use cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024. Code is available at\n  https://github.com/facebookresearch/MobileLLM",
    "pdf_url": "http://arxiv.org/pdf/2402.14905v2",
    "published_date": "2024-02-22 18:58:55 UTC",
    "updated_date": "2024-06-27 03:53:46 UTC"
  },
  {
    "arxiv_id": "2402.14807v4",
    "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health",
    "authors": [
      "Nikhil Behari",
      "Edwin Zhang",
      "Yunfan Zhao",
      "Aparna Taneja",
      "Dheeraj Nagaraj",
      "Milind Tambe"
    ],
    "abstract": "Restless multi-armed bandits (RMAB) have demonstrated success in optimizing\nresource allocation for large beneficiary populations in public health\nsettings. Unfortunately, RMAB models lack flexibility to adapt to evolving\npublic health policy priorities. Concurrently, Large Language Models (LLMs)\nhave emerged as adept automated planners across domains of robotic control and\nnavigation. In this paper, we propose a Decision Language Model (DLM) for\nRMABs, enabling dynamic fine-tuning of RMAB policies in public health settings\nusing human-language commands. We propose using LLMs as automated planners to\n(1) interpret human policy preference prompts, (2) propose reward functions as\ncode for a multi-agent RMAB environment, and (3) iterate on the generated\nreward functions using feedback from grounded RMAB simulations. We illustrate\nthe application of DLM in collaboration with ARMMAN, an India-based non-profit\npromoting preventative care for pregnant mothers, that currently relies on RMAB\npolicies to optimally allocate health worker calls to low-resource populations.\nWe conduct a technology demonstration in simulation using the Gemini Pro model,\nshowing DLM can dynamically shape policy outcomes using only human prompts as\ninput.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14807v4",
    "published_date": "2024-02-22 18:58:27 UTC",
    "updated_date": "2024-10-25 13:34:14 UTC"
  },
  {
    "arxiv_id": "2402.14805v1",
    "title": "Identifying Multiple Personalities in Large Language Models with External Evaluation",
    "authors": [
      "Xiaoyang Song",
      "Yuta Adachi",
      "Jessie Feng",
      "Mouwei Lin",
      "Linhao Yu",
      "Frank Li",
      "Akshat Gupta",
      "Gopala Anumanchipalli",
      "Simerjot Kaur"
    ],
    "abstract": "As Large Language Models (LLMs) are integrated with human daily applications\nrapidly, many societal and ethical concerns are raised regarding the behavior\nof LLMs. One of the ways to comprehend LLMs' behavior is to analyze their\npersonalities. Many recent studies quantify LLMs' personalities using\nself-assessment tests that are created for humans. Yet many critiques question\nthe applicability and reliability of these self-assessment tests when applied\nto LLMs. In this paper, we investigate LLM personalities using an alternate\npersonality measurement method, which we refer to as the external evaluation\nmethod, where instead of prompting LLMs with multiple-choice questions in the\nLikert scale, we evaluate LLMs' personalities by analyzing their responses\ntoward open-ended situational questions using an external machine learning\nmodel. We first fine-tuned a Llama2-7B model as the MBTI personality predictor\nthat outperforms the state-of-the-art models as the tool to analyze LLMs'\nresponses. Then, we prompt the LLMs with situational questions and ask them to\ngenerate Twitter posts and comments, respectively, in order to assess their\npersonalities when playing two different roles. Using the external personality\nevaluation method, we identify that the obtained personality types for LLMs are\nsignificantly different when generating posts versus comments, whereas humans\nshow a consistent personality profile in these two different situations. This\nshows that LLMs can exhibit different personalities based on different\nscenarios, thus highlighting a fundamental difference between personality in\nLLMs and humans. With our work, we call for a re-evaluation of personality\ndefinition and measurement in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14805v1",
    "published_date": "2024-02-22 18:57:20 UTC",
    "updated_date": "2024-02-22 18:57:20 UTC"
  },
  {
    "arxiv_id": "2402.14804v1",
    "title": "Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset",
    "authors": [
      "Ke Wang",
      "Junting Pan",
      "Weikang Shi",
      "Zimu Lu",
      "Mingjie Zhan",
      "Hongsheng Li"
    ],
    "abstract": "Recent advancements in Large Multimodal Models (LMMs) have shown promising\nresults in mathematical reasoning within visual contexts, with models\napproaching human-level performance on existing benchmarks such as MathVista.\nHowever, we observe significant limitations in the diversity of questions and\nbreadth of subjects covered by these benchmarks. To address this issue, we\npresent the MATH-Vision (MATH-V) dataset, a meticulously curated collection of\n3,040 high-quality mathematical problems with visual contexts sourced from real\nmath competitions. Spanning 16 distinct mathematical disciplines and graded\nacross 5 levels of difficulty, our dataset provides a comprehensive and diverse\nset of challenges for evaluating the mathematical reasoning abilities of LMMs.\nThrough extensive experimentation, we unveil a notable performance gap between\ncurrent LMMs and human performance on MATH-V, underscoring the imperative for\nfurther advancements in LMMs. Moreover, our detailed categorization allows for\na thorough error analysis of LMMs, offering valuable insights to guide future\nresearch and development. The project is available at\nhttps://mathvision-cuhk.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "math.HO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14804v1",
    "published_date": "2024-02-22 18:56:38 UTC",
    "updated_date": "2024-02-22 18:56:38 UTC"
  },
  {
    "arxiv_id": "2402.14800v2",
    "title": "Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models",
    "authors": [
      "Xudong Lu",
      "Qi Liu",
      "Yuhui Xu",
      "Aojun Zhou",
      "Siyuan Huang",
      "Bo Zhang",
      "Junchi Yan",
      "Hongsheng Li"
    ],
    "abstract": "A pivotal advancement in the progress of large language models (LLMs) is the\nemergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs,\nMoE LLMs can achieve higher performance with fewer parameters, but it is still\nhard to deploy them due to their immense parameter sizes. Different from\nprevious weight pruning methods that rely on specifically designed hardware,\nthis paper mainly aims to enhance the deployment efficiency of MoE LLMs by\nintroducing plug-and-play expert-level sparsification techniques. Specifically,\nwe propose, for the first time to our best knowledge, post-training approaches\nfor task-agnostic and task-specific expert pruning and skipping of MoE LLMs,\ntailored to improve deployment efficiency while maintaining model performance\nacross a wide range of tasks. Extensive experiments show that our proposed\nmethods can simultaneously reduce model sizes and increase the inference speed,\nwhile maintaining satisfactory performance. Data and code will be available at\nhttps://github.com/Lucky-Lance/Expert_Sparsity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Mixture-of-Experts Large Language Models, ACL2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14800v2",
    "published_date": "2024-02-22 18:56:07 UTC",
    "updated_date": "2024-05-30 16:24:16 UTC"
  },
  {
    "arxiv_id": "2402.14904v2",
    "title": "Watermarking Makes Language Models Radioactive",
    "authors": [
      "Tom Sander",
      "Pierre Fernandez",
      "Alain Durmus",
      "Matthijs Douze",
      "Teddy Furon"
    ],
    "abstract": "We investigate the radioactivity of text generated by large language models\n(LLM), i.e. whether it is possible to detect that such synthetic input was used\nto train a subsequent LLM. Current methods like membership inference or active\nIP protection either work only in settings where the suspected text is known or\ndo not provide reliable statistical guarantees. We discover that, on the\ncontrary, it is possible to reliably determine if a language model was trained\non synthetic data if that data is output by a watermarked LLM. Our new methods,\nspecialized for radioactivity, detects with a provable confidence weak\nresiduals of the watermark signal in the fine-tuned LLM. We link the\nradioactivity contamination level to the following properties: the watermark\nrobustness, its proportion in the training set, and the fine-tuning process.\nFor instance, if the suspect model is open-weight, we demonstrate that training\non watermarked instructions can be detected with high confidence ($p$-value $<\n10^{-5}$) even when as little as $5\\%$ of training text is watermarked.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Published at NeurIPS 2024 (Spotlight). Code at\n  https://github.com/facebookresearch/radioactive-watermark - webpage at\n  https://pierrefdz.github.io/publications/radioactive/",
    "pdf_url": "http://arxiv.org/pdf/2402.14904v2",
    "published_date": "2024-02-22 18:55:22 UTC",
    "updated_date": "2024-10-25 18:12:01 UTC"
  },
  {
    "arxiv_id": "2402.14798v3",
    "title": "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic",
    "authors": [
      "Nathaniel Weir",
      "Kate Sanders",
      "Orion Weller",
      "Shreya Sharma",
      "Dongwei Jiang",
      "Zhengping Jiang",
      "Bhavana Dalvi Mishra",
      "Oyvind Tafjord",
      "Peter Jansen",
      "Peter Clark",
      "Benjamin Van Durme"
    ],
    "abstract": "Recent language models enable new opportunities for structured reasoning with\ntext, such as the construction of intuitive, proof-like textual entailment\ntrees without relying on brittle formal logic. However, progress in this\ndirection has been hampered by a long-standing lack of a clear protocol for\ndetermining what valid compositional entailment is. This absence causes noisy\ndatasets and limited performance gains by modern neuro-symbolic engines. To\naddress these problems, we formulate a consistent and theoretically grounded\napproach to annotating decompositional entailment and evaluate its impact on\nLLM-based textual inference. We find that our new dataset, RDTE (Recognizing\nDecompositional Textual Entailment), has a substantially higher internal\nconsistency (+9%) than prior decompositional entailment datasets. We also find\nthat training an RDTE-oriented entailment classifier via knowledge distillation\nand employing it in an entailment tree reasoning engine significantly improves\nboth accuracy and proof quality, illustrating the practical benefit of this\nadvance for textual inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14798v3",
    "published_date": "2024-02-22 18:55:17 UTC",
    "updated_date": "2024-08-12 23:47:48 UTC"
  },
  {
    "arxiv_id": "2402.14797v1",
    "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis",
    "authors": [
      "Willi Menapace",
      "Aliaksandr Siarohin",
      "Ivan Skorokhodov",
      "Ekaterina Deyneka",
      "Tsai-Shien Chen",
      "Anil Kag",
      "Yuwei Fang",
      "Aleksei Stoliar",
      "Elisa Ricci",
      "Jian Ren",
      "Sergey Tulyakov"
    ],
    "abstract": "Contemporary models for generating images show remarkable quality and\nversatility. Swayed by these advantages, the research community repurposes them\nto generate videos. Since video content is highly redundant, we argue that\nnaively bringing advances of image models to the video generation domain\nreduces motion fidelity, visual quality and impairs scalability. In this work,\nwe build Snap Video, a video-first model that systematically addresses these\nchallenges. To do that, we first extend the EDM framework to take into account\nspatially and temporally redundant pixels and naturally support video\ngeneration. Second, we show that a U-Net - a workhorse behind image generation\n- scales poorly when generating videos, requiring significant computational\noverhead. Hence, we propose a new transformer-based architecture that trains\n3.31 times faster than U-Nets (and is ~4.5 faster at inference). This allows us\nto efficiently train a text-to-video model with billions of parameters for the\nfirst time, reach state-of-the-art results on a number of benchmarks, and\ngenerate videos with substantially higher quality, temporal consistency, and\nmotion complexity. The user studies showed that our model was favored by a\nlarge margin over the most recent methods. See our website at\nhttps://snap-research.github.io/snapvideo/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14797v1",
    "published_date": "2024-02-22 18:55:08 UTC",
    "updated_date": "2024-02-22 18:55:08 UTC"
  },
  {
    "arxiv_id": "2402.14789v1",
    "title": "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning",
    "authors": [
      "Johnathan Xie",
      "Yoonho Lee",
      "Annie S. Chen",
      "Chelsea Finn"
    ],
    "abstract": "Self-supervised learning excels in learning representations from large\namounts of unlabeled data, demonstrating success across multiple data\nmodalities. Yet, extending self-supervised learning to new modalities is\nnon-trivial because the specifics of existing methods are tailored to each\ndomain, such as domain-specific augmentations which reflect the invariances in\nthe target task. While masked modeling is promising as a domain-agnostic\nframework for self-supervised learning because it does not rely on input\naugmentations, its mask sampling procedure remains domain-specific. We present\nSelf-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling\nmethod. SMA trains an attention based model using a masked modeling objective,\nby learning masks to sample without any domain-specific assumptions. We\nevaluate SMA on three self-supervised learning benchmarks in protein biology,\nchemical property prediction, and particle physics. We find SMA is capable of\nlearning representations without domain-specific knowledge and achieves\nstate-of-the-art performance on these three benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14789v1",
    "published_date": "2024-02-22 18:46:22 UTC",
    "updated_date": "2024-02-22 18:46:22 UTC"
  },
  {
    "arxiv_id": "2402.14781v3",
    "title": "Effective Bayesian Causal Inference via Structural Marginalisation and Autoregressive Orders",
    "authors": [
      "Christian Toth",
      "Christian Knoll",
      "Franz Pernkopf",
      "Robert Peharz"
    ],
    "abstract": "The traditional two-stage approach to causal inference first identifies a\nsingle causal model (or equivalence class of models), which is then used to\nanswer causal queries. However, this neglects any epistemic model uncertainty.\nIn contrast, Bayesian causal inference does incorporate epistemic uncertainty\ninto query estimates via Bayesian marginalisation (posterior averaging) over\nall causal models. While principled, this marginalisation over entire causal\nmodels, i.e., both causal structures (graphs) and mechanisms, poses a\ntremendous computational challenge. In this work, we address this challenge by\ndecomposing structure marginalisation into the marginalisation over (i) causal\norders and (ii) directed acyclic graphs (DAGs) given an order. We can\nmarginalise the latter in closed form by limiting the number of parents per\nvariable and utilising Gaussian processes to model mechanisms. To marginalise\nover orders, we use a sampling-based approximation, for which we devise a novel\nauto-regressive distribution over causal orders (ARCO). Our method outperforms\nstate-of-the-art in structure learning on simulated non-linear additive noise\nbenchmarks, and yields competitive results on real-world data. Furthermore, we\ncan accurately infer interventional distributions and average causal effects.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages + references + appendices (37 pages total)",
    "pdf_url": "http://arxiv.org/pdf/2402.14781v3",
    "published_date": "2024-02-22 18:39:24 UTC",
    "updated_date": "2025-04-23 11:48:41 UTC"
  },
  {
    "arxiv_id": "2402.14778v2",
    "title": "Zero-shot cross-lingual transfer in instruction tuning of large language models",
    "authors": [
      "Nadezhda Chirkova",
      "Vassilina Nikoulina"
    ],
    "abstract": "Instruction tuning (IT) is widely used to teach pretrained large language\nmodels (LLMs) to follow arbitrary instructions, but is under-studied in\nmultilingual settings. In this work, we conduct a systematic study of zero-shot\ncross-lingual transfer in IT, when an LLM is instruction-tuned on English-only\ndata and then tested on user prompts in other languages. We advocate for the\nimportance of evaluating various aspects of model responses in multilingual\ninstruction following and investigate the influence of different model\nconfiguration choices. We find that cross-lingual transfer does happen\nsuccessfully in IT even if all stages of model training are English-centric,\nbut only if multiliguality is taken into account in hyperparameter tuning and\nwith large enough IT data. English-trained LLMs are capable of generating\ncorrect-language, comprehensive and helpful responses in other languages, but\nsuffer from low factuality and may occasionally have fluency errors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14778v2",
    "published_date": "2024-02-22 18:37:33 UTC",
    "updated_date": "2024-04-22 10:44:21 UTC"
  },
  {
    "arxiv_id": "2402.14762v3",
    "title": "MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues",
    "authors": [
      "Ge Bai",
      "Jie Liu",
      "Xingyuan Bu",
      "Yancheng He",
      "Jiaheng Liu",
      "Zhanhui Zhou",
      "Zhuoran Lin",
      "Wenbo Su",
      "Tiezheng Ge",
      "Bo Zheng",
      "Wanli Ouyang"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has drastically enhanced dialogue\nsystems. However, comprehensively evaluating the dialogue abilities of LLMs\nremains a challenge. Previous benchmarks have primarily focused on single-turn\ndialogues or provided coarse-grained and incomplete assessments of multi-turn\ndialogues, overlooking the complexity and fine-grained nuances of real-life\ndialogues. To address this issue, we introduce MT-Bench-101, specifically\ndesigned to evaluate the fine-grained abilities of LLMs in multi-turn\ndialogues. By conducting a detailed analysis of real multi-turn dialogue data,\nwe construct a three-tier hierarchical ability taxonomy comprising 4208 turns\nacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21\npopular LLMs based on MT-Bench-101, conducting comprehensive analyses from both\nability and task perspectives and observing differing trends in LLMs\nperformance across dialogue turns within various tasks. Further analysis\nindicates that neither utilizing common alignment techniques nor chat-specific\ndesigns has led to obvious enhancements in the multi-turn abilities of LLMs.\nExtensive case studies suggest that our designed tasks accurately assess the\ncorresponding multi-turn abilities. The data and code are available at\n\\url{https://github.com/mtbench101/mt-bench-101}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "[ACL 2024] The first three authors contribute equally, 34 pages, repo\n  at https://github.com/mtbench101/mt-bench-101",
    "pdf_url": "http://arxiv.org/pdf/2402.14762v3",
    "published_date": "2024-02-22 18:21:59 UTC",
    "updated_date": "2024-11-05 16:40:21 UTC"
  },
  {
    "arxiv_id": "2402.14759v1",
    "title": "Generalising realisability in statistical learning theory under epistemic uncertainty",
    "authors": [
      "Fabio Cuzzolin"
    ],
    "abstract": "The purpose of this paper is to look into how central notions in statistical\nlearning theory, such as realisability, generalise under the assumption that\ntrain and test distribution are issued from the same credal set, i.e., a convex\nset of probability distributions. This can be considered as a first step\ntowards a more general treatment of statistical learning under epistemic\nuncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2401.09435",
    "pdf_url": "http://arxiv.org/pdf/2402.14759v1",
    "published_date": "2024-02-22 18:20:25 UTC",
    "updated_date": "2024-02-22 18:20:25 UTC"
  },
  {
    "arxiv_id": "2402.14758v2",
    "title": "Batch and match: black-box variational inference with a score-based divergence",
    "authors": [
      "Diana Cai",
      "Chirag Modi",
      "Loucas Pillaud-Vivien",
      "Charles C. Margossian",
      "Robert M. Gower",
      "David M. Blei",
      "Lawrence K. Saul"
    ],
    "abstract": "Most leading implementations of black-box variational inference (BBVI) are\nbased on optimizing a stochastic evidence lower bound (ELBO). But such\napproaches to BBVI often converge slowly due to the high variance of their\ngradient estimates and their sensitivity to hyperparameters. In this work, we\npropose batch and match (BaM), an alternative approach to BBVI based on a\nscore-based divergence. Notably, this score-based divergence can be optimized\nby a closed-form proximal update for Gaussian variational families with full\ncovariance matrices. We analyze the convergence of BaM when the target\ndistribution is Gaussian, and we prove that in the limit of infinite batch size\nthe variational parameter updates converge exponentially quickly to the target\nmean and covariance. We also evaluate the performance of BaM on Gaussian and\nnon-Gaussian target distributions that arise from posterior inference in\nhierarchical and deep generative models. In these experiments, we find that BaM\ntypically converges in fewer (and sometimes significantly fewer) gradient\nevaluations than leading implementations of BBVI based on ELBO maximization.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "stat.ML",
    "comment": "49 pages, 14 figures. To appear in the Proceedings of the 41st\n  International Conference on Machine Learning (ICML), 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14758v2",
    "published_date": "2024-02-22 18:20:22 UTC",
    "updated_date": "2024-06-12 16:53:22 UTC"
  },
  {
    "arxiv_id": "2402.14757v1",
    "title": "SHM-Traffic: DRL and Transfer learning based UAV Control for Structural Health Monitoring of Bridges with Traffic",
    "authors": [
      "Divija Swetha Gadiraju",
      "Saeed Eftekhar Azam",
      "Deepak Khazanchi"
    ],
    "abstract": "This work focuses on using advanced techniques for structural health\nmonitoring (SHM) for bridges with Traffic. We propose an approach using deep\nreinforcement learning (DRL)-based control for Unmanned Aerial Vehicle (UAV).\nOur approach conducts a concrete bridge deck survey while traffic is ongoing\nand detects cracks. The UAV performs the crack detection, and the location of\ncracks is initially unknown. We use two edge detection techniques. First, we\nuse canny edge detection for crack detection. We also use a Convolutional\nNeural Network (CNN) for crack detection and compare it with canny edge\ndetection. Transfer learning is applied using CNN with pre-trained weights\nobtained from a crack image dataset. This enables the model to adapt and\nimprove its performance in identifying and localizing cracks. Proximal Policy\nOptimization (PPO) is applied for UAV control and bridge surveys. The\nexperimentation across various scenarios is performed to evaluate the\nperformance of the proposed methodology. Key metrics such as task completion\ntime and reward convergence are observed to gauge the effectiveness of the\napproach. We observe that the Canny edge detector offers up to 40\\% lower task\ncompletion time, while the CNN excels in up to 12\\% better damage detection and\n1.8 times better rewards.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14757v1",
    "published_date": "2024-02-22 18:19:45 UTC",
    "updated_date": "2024-02-22 18:19:45 UTC"
  },
  {
    "arxiv_id": "2402.14753v1",
    "title": "Prompting a Pretrained Transformer Can Be a Universal Approximator",
    "authors": [
      "Aleksandar Petrov",
      "Philip H. S. Torr",
      "Adel Bibi"
    ],
    "abstract": "Despite the widespread adoption of prompting, prompt tuning and prefix-tuning\nof transformer models, our theoretical understanding of these fine-tuning\nmethods remains limited. A key question is whether one can arbitrarily modify\nthe behavior of pretrained model by prompting or prefix-tuning it. Formally,\nwhether prompting and prefix-tuning a pretrained model can universally\napproximate sequence-to-sequence functions. This paper answers in the\naffirmative and demonstrates that much smaller pretrained models than\npreviously thought can be universal approximators when prefixed. In fact, the\nattention mechanism is uniquely suited for universal approximation with\nprefix-tuning a single attention head being sufficient to approximate any\ncontinuous function. Moreover, any sequence-to-sequence function can be\napproximated by prefixing a transformer with depth linear in the sequence\nlength. Beyond these density-type results, we also offer Jackson-type bounds on\nthe length of the prefix needed to approximate a function to a desired\nprecision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14753v1",
    "published_date": "2024-02-22 18:12:48 UTC",
    "updated_date": "2024-02-22 18:12:48 UTC"
  },
  {
    "arxiv_id": "2402.14901v2",
    "title": "A Usage-centric Take on Intent Understanding in E-Commerce",
    "authors": [
      "Wendi Zhou",
      "Tianyi Li",
      "Pavlos Vougiouklis",
      "Mark Steedman",
      "Jeff Z. Pan"
    ],
    "abstract": "Identifying and understanding user intents is a pivotal task for E-Commerce.\nDespite its essential role in product recommendation and business user\nprofiling analysis, intent understanding has not been consistently defined or\naccurately benchmarked. In this paper, we focus on predicative user intents as\n\"how a customer uses a product\", and pose intent understanding as a natural\nlanguage reasoning task, independent of product ontologies. We identify two\nweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:\ncategory-rigidity and property-ambiguity. They limit its ability to strongly\nalign user intents with products having the most desirable property, and to\nrecommend useful products across diverse categories. Following these\nobservations, we introduce a Product Recovery Benchmark featuring a novel\nevaluation framework and an example dataset. We further validate the above\nFolkScope weaknesses on this benchmark. Our code and dataset are available at\nhttps://github.com/stayones/Usgae-Centric-Intent-Understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Acepted by EMNLP 2024 main",
    "pdf_url": "http://arxiv.org/pdf/2402.14901v2",
    "published_date": "2024-02-22 18:09:33 UTC",
    "updated_date": "2024-10-07 16:38:35 UTC"
  },
  {
    "arxiv_id": "2402.14744v3",
    "title": "Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation",
    "authors": [
      "Jiawei Wang",
      "Renhe Jiang",
      "Chuang Yang",
      "Zengqing Wu",
      "Makoto Onizuka",
      "Ryosuke Shibasaki",
      "Noboru Koshizuka",
      "Chuan Xiao"
    ],
    "abstract": "This paper introduces a novel approach using Large Language Models (LLMs)\nintegrated into an agent framework for flexible and effective personal mobility\ngeneration. LLMs overcome the limitations of previous models by effectively\nprocessing semantic data and offering versatility in modeling various tasks.\nOur approach addresses three research questions: aligning LLMs with real-world\nurban mobility data, developing reliable activity generation strategies, and\nexploring LLM applications in urban mobility. The key technical contribution is\na novel LLM agent framework that accounts for individual activity patterns and\nmotivations, including a self-consistency approach to align LLMs with\nreal-world activity data and a retrieval-augmented strategy for interpretable\nactivity generation. We evaluate our LLM agent framework and compare it with\nstate-of-the-art personal mobility generation approaches, demonstrating the\neffectiveness of our approach and its potential applications in urban mobility.\nOverall, this study marks the pioneering work of designing an LLM agent\nframework for activity generation based on real-world human activity data,\noffering a promising tool for urban mobility analysis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024. Source codes are available at\n  https://github.com/Wangjw6/LLMob/",
    "pdf_url": "http://arxiv.org/pdf/2402.14744v3",
    "published_date": "2024-02-22 18:03:14 UTC",
    "updated_date": "2024-10-27 20:02:01 UTC"
  },
  {
    "arxiv_id": "2402.14730v3",
    "title": "Clifford-Steerable Convolutional Neural Networks",
    "authors": [
      "Maksim Zhdanov",
      "David Ruhe",
      "Maurice Weiler",
      "Ana Lucic",
      "Johannes Brandstetter",
      "Patrick Forré"
    ],
    "abstract": "We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a\nnovel class of $\\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector\nfields on pseudo-Euclidean spaces $\\mathbb{R}^{p,q}$. They cover, for instance,\n$\\mathrm{E}(3)$-equivariance on $\\mathbb{R}^3$ and Poincar\\'e-equivariance on\nMinkowski spacetime $\\mathbb{R}^{1,3}$. Our approach is based on an implicit\nparametrization of $\\mathrm{O}(p,q)$-steerable kernels via Clifford group\nequivariant neural networks. We significantly and consistently outperform\nbaseline methods on fluid dynamics as well as relativistic electrodynamics\nforecasting tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14730v3",
    "published_date": "2024-02-22 17:42:15 UTC",
    "updated_date": "2024-07-06 16:10:29 UTC"
  },
  {
    "arxiv_id": "2402.14899v3",
    "title": "Stop Reasoning! When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image",
    "authors": [
      "Zefeng Wang",
      "Zhen Han",
      "Shuo Chen",
      "Fan Xue",
      "Zifeng Ding",
      "Xun Xiao",
      "Volker Tresp",
      "Philip Torr",
      "Jindong Gu"
    ],
    "abstract": "Multimodal LLMs (MLLMs) with a great ability of text and image understanding\nhave received great attention. To achieve better reasoning with MLLMs,\nChain-of-Thought (CoT) reasoning has been widely explored, which further\npromotes MLLMs' explainability by giving intermediate reasoning steps. Despite\nthe strong power demonstrated by MLLMs in multimodal reasoning, recent studies\nshow that MLLMs still suffer from adversarial images. This raises the following\nopen questions: Does CoT also enhance the adversarial robustness of MLLMs? What\ndo the intermediate reasoning steps of CoT entail under adversarial attacks? To\nanswer these questions, we first generalize existing attacks to CoT-based\ninferences by attacking the two main components, i.e., rationale and answer. We\nfind that CoT indeed improves MLLMs' adversarial robustness against the\nexisting attack methods by leveraging the multi-step reasoning process, but not\nsubstantially. Based on our findings, we further propose a novel attack method,\ntermed as stop-reasoning attack, that attacks the model while bypassing the CoT\nreasoning process. Experiments on three MLLMs and two visual reasoning datasets\nverify the effectiveness of our proposed method. We show that stop-reasoning\nattack can result in misled predictions and outperform baseline attacks by a\nsignificant margin.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14899v3",
    "published_date": "2024-02-22 17:36:34 UTC",
    "updated_date": "2024-09-22 14:46:30 UTC"
  },
  {
    "arxiv_id": "2402.14728v2",
    "title": "The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success",
    "authors": [
      "André Calero Valdez",
      "Moreen Heine",
      "Thomas Franke",
      "Nicole Jochems",
      "Hans-Christian Jetter",
      "Tim Schrills"
    ],
    "abstract": "The evolution of AI is set to profoundly reshape the future. The European\nUnion, recognizing this impending prominence, has enacted the AI Act,\nregulating market access for AI-based systems. A salient feature of the Act is\nto guard democratic and humanistic values by focusing regulation on\ntransparency, explainability, and the human ability to understand and control\nAI systems. Hereby, the EU AI Act does not merely specify technological\nrequirements for AI systems. The EU issues a democratic call for human-centered\nAI systems and, in turn, an interdisciplinary research agenda for\nhuman-centered innovation in AI development. Without robust methods to assess\nAI systems and their effect on individuals and society, the EU AI Act may lead\nto repeating the mistakes of the General Data Protection Regulation of the EU\nand to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more\nconfusion than lending guidance. Moreover, determined research activities in\nHuman-AI interaction will be pivotal for both regulatory compliance and the\nadvancement of AI in a manner that is both ethical and effective. Such an\napproach will ensure that AI development aligns with human values and needs,\nfostering a technology landscape that is innovative, responsible, and an\nintegral part of our society.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages, 1 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14728v2",
    "published_date": "2024-02-22 17:35:29 UTC",
    "updated_date": "2024-06-13 14:30:26 UTC"
  },
  {
    "arxiv_id": "2402.14726v1",
    "title": "Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning",
    "authors": [
      "Andrei V. Konstantinov",
      "Lev V. Utkin"
    ],
    "abstract": "A problem of incorporating the expert rules into machine learning models for\nextending the concept-based learning is formulated in the paper. It is proposed\nhow to combine logical rules and neural networks predicting the concept\nprobabilities. The first idea behind the combination is to form constraints for\na joint probability distribution over all combinations of concept values to\nsatisfy the expert rules. The second idea is to represent a feasible set of\nprobability distributions in the form of a convex polytope and to use its\nvertices or faces. We provide several approaches for solving the stated problem\nand for training neural networks which guarantee that the output probabilities\nof concepts would not violate the expert rules. The solution of the problem can\nbe viewed as a way for combining the inductive and deductive learning. Expert\nrules are used in a broader sense when any logical function that connects\nconcepts and class labels or just concepts with each other can be regarded as a\nrule. This feature significantly expands the class of the proposed results.\nNumerical examples illustrate the approaches. The code of proposed algorithms\nis publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14726v1",
    "published_date": "2024-02-22 17:33:49 UTC",
    "updated_date": "2024-02-22 17:33:49 UTC"
  },
  {
    "arxiv_id": "2402.14897v3",
    "title": "Chain-of-Thought Unfaithfulness as Disguised Accuracy",
    "authors": [
      "Oliver Bentham",
      "Nathan Stringham",
      "Ana Marasović"
    ],
    "abstract": "Understanding the extent to which Chain-of-Thought (CoT) generations align\nwith a large language model's (LLM) internal computations is critical for\ndeciding whether to trust an LLM's output. As a proxy for CoT faithfulness,\nLanham et al. (2023) propose a metric that measures a model's dependence on its\nCoT for producing an answer. Within a single family of proprietary models, they\nfind that LLMs exhibit a scaling-then-inverse-scaling relationship between\nmodel size and their measure of faithfulness, and that a 13 billion parameter\nmodel exhibits increased faithfulness compared to models ranging from 810\nmillion to 175 billion parameters in size. We evaluate whether these results\ngeneralize as a property of all LLMs. We replicate the experimental setup in\ntheir section focused on scaling experiments with three different families of\nmodels and, under specific conditions, successfully reproduce the scaling\ntrends for CoT faithfulness they report. However, after normalizing the metric\nto account for a model's bias toward certain answer choices, unfaithfulness\ndrops significantly for smaller less-capable models. This normalized\nfaithfulness metric is also strongly correlated ($R^2$=0.74) with accuracy,\nraising doubts about its validity for evaluating faithfulness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "TMLR accepted paper camera-ready version. First two authors\n  contributed equally. 8 pages main, 13 pages appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.14897v3",
    "published_date": "2024-02-22 17:23:53 UTC",
    "updated_date": "2024-06-21 13:39:14 UTC"
  },
  {
    "arxiv_id": "2402.14714v1",
    "title": "Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models",
    "authors": [
      "Seungduk Kim",
      "Seungtaek Choi",
      "Myeongho Jeong"
    ],
    "abstract": "This report introduces \\texttt{EEVE-Korean-v1.0}, a Korean adaptation of\nlarge language models that exhibit remarkable capabilities across English and\nKorean text understanding. Building on recent highly capable but\nEnglish-centric LLMs, such as SOLAR-10.7B and Phi-2, where non-English texts\nare inefficiently processed with English-centric tokenizers, we present an\nefficient and effective vocabulary expansion (EEVE) method, which encompasses\nparameter freezing and subword initialization. In contrast to previous efforts\nthat believe new embeddings require trillions of training tokens, we show that\nour method can significantly boost non-English proficiency within just 2\nbillion tokens. Surpassing most instruction-tuned LLMs on the Open Ko-LLM\nLeaderboard, as of January 2024, our model \\texttt{EEVE-Korean-10.8B-v1.0}\nranks as the leading Korean pre-trained model in the open-source community,\naccording to Hugging Face's leaderboard. We open-source our models on\nHuggingface to empower the open research community in various languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14714v1",
    "published_date": "2024-02-22 17:12:39 UTC",
    "updated_date": "2024-02-22 17:12:39 UTC"
  },
  {
    "arxiv_id": "2402.14710v3",
    "title": "IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus",
    "authors": [
      "Honghao Gui",
      "Lin Yuan",
      "Hongbin Ye",
      "Ningyu Zhang",
      "Mengshu Sun",
      "Lei Liang",
      "Huajun Chen"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable potential across various\ndomains; however, they exhibit a significant performance gap in Information\nExtraction (IE). Note that high-quality instruction data is the vital key for\nenhancing the specific capabilities of LLMs, while current IE datasets tend to\nbe small in scale, fragmented, and lack standardized schema. To this end, we\nintroduce IEPile, a comprehensive bilingual (English and Chinese) IE\ninstruction corpus, which contains approximately 0.32B tokens. We construct\nIEPile by collecting and cleaning 33 existing IE datasets, and introduce\nschema-based instruction generation to unearth a large-scale corpus.\nExperimentally, IEPile enhance the performance of LLMs for IE, with notable\nimprovements in zero-shot generalization. We open-source the resource and\npre-trained models, hoping to provide valuable support to the NLP community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (short); 21 pages; Github: https://github.com/zjunlp/IEPile",
    "pdf_url": "http://arxiv.org/pdf/2402.14710v3",
    "published_date": "2024-02-22 17:11:38 UTC",
    "updated_date": "2024-05-26 15:54:41 UTC"
  },
  {
    "arxiv_id": "2402.14708v2",
    "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks",
    "authors": [
      "Yifan Duan",
      "Guibin Zhang",
      "Shilong Wang",
      "Xiaojiang Peng",
      "Wang Ziqi",
      "Junyuan Mao",
      "Hao Wu",
      "Xinke Jiang",
      "Kun Wang"
    ],
    "abstract": "Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14708v2",
    "published_date": "2024-02-22 17:08:09 UTC",
    "updated_date": "2024-11-27 12:15:06 UTC"
  },
  {
    "arxiv_id": "2402.14703v2",
    "title": "On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation",
    "authors": [
      "Yuheng Zhang",
      "Nan Jiang"
    ],
    "abstract": "We study off-policy evaluation (OPE) in partially observable environments\nwith complex observations, with the goal of developing estimators whose\nguarantee avoids exponential dependence on the horizon. While such estimators\nexist for MDPs and POMDPs can be converted to history-based MDPs, their\nestimation errors depend on the state-density ratio for MDPs which becomes\nhistory ratios after conversion, an exponential object. Recently, Uehara et al.\n[2022a] proposed future-dependent value functions as a promising framework to\naddress this issue, where the guarantee for memoryless policies depends on the\ndensity ratio over the latent state space. However, it also depends on the\nboundedness of the future-dependent value function and other related\nquantities, which we show could be exponential-in-length and thus erasing the\nadvantage of the method. In this paper, we discover novel coverage assumptions\ntailored to the structure of POMDPs, such as outcome coverage and belief\ncoverage, which enable polynomial bounds on the aforementioned quantities. As a\nside product, our analyses also lead to the discovery of new algorithms with\ncomplementary properties.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14703v2",
    "published_date": "2024-02-22 17:00:50 UTC",
    "updated_date": "2024-10-03 06:55:03 UTC"
  },
  {
    "arxiv_id": "2402.14701v3",
    "title": "COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling",
    "authors": [
      "Baihan Lin",
      "Djallel Bouneffouf",
      "Yulia Landa",
      "Rachel Jespersen",
      "Cheryl Corcoran",
      "Guillermo Cecchi"
    ],
    "abstract": "The therapeutic working alliance is a critical predictor of psychotherapy\nsuccess. Traditionally, working alliance assessment relies on questionnaires\ncompleted by both therapists and patients. In this paper, we present COMPASS, a\nnovel framework to directly infer the therapeutic working alliance from the\nnatural language used in psychotherapy sessions. Our approach leverages\nadvanced large language models (LLMs) to analyze session transcripts and map\nthem to distributed representations. These representations capture the semantic\nsimilarities between the dialogues and psychometric instruments, such as the\nWorking Alliance Inventory. Analyzing a dataset of over 950 sessions spanning\ndiverse psychiatric conditions -- including anxiety (N=498), depression\n(N=377), schizophrenia (N=71), and suicidal tendencies (N=12) -- collected\nbetween 1970 and 2012, we demonstrate the effectiveness of our method in\nproviding fine-grained mapping of patient-therapist alignment trajectories,\noffering interpretable insights for clinical practice, and identifying emerging\npatterns related to the condition being treated. By employing various deep\nlearning-based topic modeling techniques in combination with prompting\ngenerative language models, we analyze the topical characteristics of different\npsychiatric conditions and how these topics evolve during each turn of the\nconversation. This integrated framework enhances the understanding of\ntherapeutic interactions, enables timely feedback for therapists on the quality\nof therapeutic relationships, and provides clear, actionable insights to\nimprove the effectiveness of psychotherapy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "Translational Psychiatry, in press. This work extends our research\n  series in computational psychiatry (e.g auto annotation in arXiv:2204.05522,\n  topic extraction in arXiv:2204.10189, and diagnosis in arXiv:2210.15603) with\n  the introduction of LLMs to complete the full cycle of interpreting and\n  understanding psychotherapy strategies as a comprehensive analytical\n  framework",
    "pdf_url": "http://arxiv.org/pdf/2402.14701v3",
    "published_date": "2024-02-22 16:56:44 UTC",
    "updated_date": "2025-04-14 16:58:34 UTC"
  },
  {
    "arxiv_id": "2402.14698v3",
    "title": "Using construction waste hauling trucks' GPS data to classify earthwork-related locations: A Chengdu case study",
    "authors": [
      "Lei Yu",
      "Ke Han"
    ],
    "abstract": "Earthwork-related locations (ERLs), such as construction sites, earth dumping\nground, and concrete mixing stations, are major sources of urban dust pollution\n(particulate matters). The effective management of ERLs is crucial and requires\ntimely and efficient tracking of these locations throughout the city. This work\naims to identify and classify urban ERLs using GPS trajectory data of over\n16,000 construction waste hauling trucks (CWHTs), as well as 58 urban features\nencompassing geographic, land cover, POI and transport dimensions. We compare\nseveral machine learning models and examine the impact of various\nspatial-temporal features on classification performance using real-world data\nin Chengdu, China. The results demonstrate that 77.8% classification accuracy\ncan be achieved with a limited number of features. This classification\nframework was implemented in the Alpha MAPS system in Chengdu, which has\nsuccessfully identified 724 construction cites/earth dumping ground, 48\nconcrete mixing stations, and 80 truck parking locations in the city during\nDecember 2023, which has enabled local authority to effectively manage urban\ndust pollution at low personnel costs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14698v3",
    "published_date": "2024-02-22 16:50:32 UTC",
    "updated_date": "2024-04-04 11:41:04 UTC"
  },
  {
    "arxiv_id": "2402.14895v2",
    "title": "On Evaluation Protocols for Data Augmentation in a Limited Data Scenario",
    "authors": [
      "Frédéric Piedboeuf",
      "Philippe Langlais"
    ],
    "abstract": "Textual data augmentation (DA) is a prolific field of study where novel\ntechniques to create artificial data are regularly proposed, and that has\ndemonstrated great efficiency on small data settings, at least for text\nclassification tasks. In this paper, we challenge those results, showing that\nclassical data augmentation (which modify sentences) is simply a way of\nperforming better fine-tuning, and that spending more time doing so before\napplying data augmentation negates its effect. This is a significant\ncontribution as it answers several questions that were left open in recent\nyears, namely~: which DA technique performs best (all of them as long as they\ngenerate data close enough to the training set, as to not impair training) and\nwhy did DA show positive results (facilitates training of network). We further\nshow that zero- and few-shot DA via conversational agents such as ChatGPT or\nLLama2 can increase performances, confirming that this form of data\naugmentation is preferable to classical methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.14895v2",
    "published_date": "2024-02-22 16:42:37 UTC",
    "updated_date": "2024-09-16 20:11:19 UTC"
  },
  {
    "arxiv_id": "2402.14683v2",
    "title": "Visual Hallucinations of Multi-modal Large Language Models",
    "authors": [
      "Wen Huang",
      "Hongbin Liu",
      "Minxin Guo",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines\nincorrect details about an image in visual question answering. Existing studies\nfind VH instances only in existing image datasets, which results in biased\nunderstanding of MLLMs' performance under VH due to limited diversity of such\nVH instances. In this work, we propose a tool called VHTest to generate a\ndiverse set of VH instances. Specifically, VHTest finds some initial VH\ninstances in existing image datasets (e.g., COCO), generates a text description\nfor each VH mode, and uses a text-to-image generative model (e.g., DALL-E-3) to\ngenerate VH images based on the text descriptions. We collect a benchmark\ndataset with 1,200 VH instances in 8 VH modes using VHTest. We find that\nexisting MLLMs such as GPT-4V, LLaVA-1.5, and MiniGPT-v2 hallucinate for a\nlarge fraction of the instances in our benchmark. Moreover, we find that\nfine-tuning an MLLM using our benchmark dataset reduces its likelihood to\nhallucinate without sacrificing its performance on other benchmarks. Our\nbenchmarks are publicly available: https://github.com/wenhuang2000/VHTest.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in ACL Findings, 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14683v2",
    "published_date": "2024-02-22 16:40:33 UTC",
    "updated_date": "2024-06-16 18:43:50 UTC"
  },
  {
    "arxiv_id": "2402.14894v1",
    "title": "Data-Driven Ground-Fault Location Method in Distribution Power System With Distributed Generation",
    "authors": [
      "Mauro Caporuscio",
      "Antoine Dupuis",
      "Welf Löwe"
    ],
    "abstract": "The recent increase in renewable energy penetration at the distribution level\nintroduces a multi-directional power flow that outdated traditional fault\nlocation techniques. To this extent, the development of new methods is needed\nto ensure fast and accurate fault localization and, hence, strengthen power\nsystem reliability. This paper proposes a data-driven ground fault location\nmethod for the power distribution system. An 11-bus 20 kV power system is\nmodeled in Matlab/Simulink to simulate ground faults. The faults are generated\nat different locations and under various system operational states. Time-domain\nfaulted three-phase voltages at the system substation are then analyzed with\ndiscrete wavelet transform. Statistical quantities of the processed data are\neventually used to train an Artificial Neural Network (ANN) to find a mapping\nbetween computed voltage features and faults. Specifically, three ANNs allow\nthe prediction of faulted phase, faulted branch, and fault distance from the\nsystem substation separately. According to the results, the method shows good\npotential, with a total relative error of 0,4% for fault distance prediction.\nThe method is applied to datasets with unknown system states to test\nrobustness.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SP"
    ],
    "primary_category": "eess.SY",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2402.14894v1",
    "published_date": "2024-02-22 16:25:32 UTC",
    "updated_date": "2024-02-22 16:25:32 UTC"
  },
  {
    "arxiv_id": "2402.14672v2",
    "title": "Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments",
    "authors": [
      "Yu Gu",
      "Yiheng Shu",
      "Hao Yu",
      "Xiao Liu",
      "Yuxiao Dong",
      "Jie Tang",
      "Jayanth Srinivasa",
      "Hugo Latapie",
      "Yu Su"
    ],
    "abstract": "The applications of large language models (LLMs) have expanded well beyond\nthe confines of text processing, signaling a new era where LLMs are envisioned\nas generalist agents capable of operating within complex environments. These\nenvironments are often highly expansive, making it impossible for the LLM to\nprocess them within its short-term memory. Motivated by recent research on\nextending the capabilities of LLMs with tools, we seek to investigate the\nintriguing potential of tools to augment LLMs in handling such complexity by\nintroducing a novel class of tools, termed middleware, to aid in the proactive\nexploration within these massive environments. Such specialized tools can serve\nas a middleware layer shielding the LLM from environmental complexity. In two\nrepresentative complex environments -- knowledge bases (KBs) and databases --\nwe demonstrate the significant potential of augmenting language agents with\ntools in complex environments. Notably, equipped with the middleware, GPT-4\nachieves 2.8X the performance of the best baseline in tasks requiring access to\ndatabase content and 2.2X in KB tasks. Our findings illuminate the path for\nadvancing language agents in real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP'2024; 18 pages, 8 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.14672v2",
    "published_date": "2024-02-22 16:18:07 UTC",
    "updated_date": "2024-10-04 07:40:57 UTC"
  },
  {
    "arxiv_id": "2402.14664v2",
    "title": "Bayesian Off-Policy Evaluation and Learning for Large Action Spaces",
    "authors": [
      "Imad Aouali",
      "Victor-Emmanuel Brunel",
      "David Rohde",
      "Anna Korba"
    ],
    "abstract": "In interactive systems, actions are often correlated, presenting an\nopportunity for more sample-efficient off-policy evaluation (OPE) and learning\n(OPL) in large action spaces. We introduce a unified Bayesian framework to\ncapture these correlations through structured and informative priors. In this\nframework, we propose sDM, a generic Bayesian approach for OPE and OPL,\ngrounded in both algorithmic and theoretical foundations. Notably, sDM\nleverages action correlations without compromising computational efficiency.\nMoreover, inspired by online Bayesian bandits, we introduce Bayesian metrics\nthat assess the average performance of algorithms across multiple problem\ninstances, deviating from the conventional worst-case assessments. We analyze\nsDM in OPE and OPL, highlighting the benefits of leveraging action\ncorrelations. Empirical evidence showcases the strong performance of sDM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2402.14664v2",
    "published_date": "2024-02-22 16:09:45 UTC",
    "updated_date": "2025-04-08 13:22:27 UTC"
  },
  {
    "arxiv_id": "2402.14660v2",
    "title": "ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models",
    "authors": [
      "Yanan Wu",
      "Jie Liu",
      "Xingyuan Bu",
      "Jiaheng Liu",
      "Zhanhui Zhou",
      "Yuanxing Zhang",
      "Chenchen Zhang",
      "Zhiqi Bai",
      "Haibin Chen",
      "Tiezheng Ge",
      "Wanli Ouyang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "This paper introduces ConceptMath, a bilingual (English and Chinese),\nfine-grained benchmark that evaluates concept-wise mathematical reasoning of\nLarge Language Models (LLMs). Unlike traditional benchmarks that evaluate\ngeneral mathematical reasoning with an average accuracy, ConceptMath\nsystematically organizes math problems under a hierarchy of math concepts, so\nthat mathematical reasoning can be evaluated at different granularity with\nconcept-wise accuracies. Based on our ConcepthMath, we evaluate a broad range\nof LLMs, and we observe existing LLMs, though achieving high average accuracies\non traditional benchmarks, exhibit significant performance variations across\ndifferent math concepts and may even fail catastrophically on the most basic\nones. Besides, we also introduce an efficient fine-tuning strategy to enhance\nthe weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the\ndevelopers to understand the fine-grained mathematical abilities of their\nmodels and facilitate the growth of foundation models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The benchmark dataset will be released soon",
    "pdf_url": "http://arxiv.org/pdf/2402.14660v2",
    "published_date": "2024-02-22 16:06:49 UTC",
    "updated_date": "2024-02-23 07:13:00 UTC"
  },
  {
    "arxiv_id": "2402.14658v3",
    "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement",
    "authors": [
      "Tianyu Zheng",
      "Ge Zhang",
      "Tianhao Shen",
      "Xueling Liu",
      "Bill Yuchen Lin",
      "Jie Fu",
      "Wenhu Chen",
      "Xiang Yue"
    ],
    "abstract": "The introduction of large language models has significantly advanced code\ngeneration. However, open-source models often lack the execution capabilities\nand iterative refinement of advanced systems like the GPT-4 Code Interpreter.\nTo address this, we introduce OpenCodeInterpreter, a family of open-source code\nsystems designed for generating, executing, and iteratively refining code.\nSupported by Code-Feedback, a dataset featuring 68K multi-turn interactions,\nOpenCodeInterpreter integrates execution and human feedback for dynamic code\nrefinement. Our comprehensive evaluation of OpenCodeInterpreter across key\nbenchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus\nreveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves\nan accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and\nMBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6)\nwith synthesized human feedback from GPT-4. OpenCodeInterpreter brings the gap\nbetween open-source code generation models and proprietary systems like GPT-4\nCode Interpreter.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14658v3",
    "published_date": "2024-02-22 16:06:23 UTC",
    "updated_date": "2025-01-07 05:37:04 UTC"
  },
  {
    "arxiv_id": "2402.14648v3",
    "title": "Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off",
    "authors": [
      "Futa Waseda",
      "Ching-Chun Chang",
      "Isao Echizen"
    ],
    "abstract": "Adversarial training often suffers from a robustness-accuracy trade-off,\nwhere achieving high robustness comes at the cost of accuracy. One approach to\nmitigate this trade-off is leveraging invariance regularization, which\nencourages model invariance under adversarial perturbations; however, it still\nleads to accuracy loss. In this work, we closely analyze the challenges of\nusing invariance regularization in adversarial training and understand how to\naddress them. Our analysis identifies two key issues: (1) a ``gradient\nconflict\" between invariance and classification objectives, leading to\nsuboptimal convergence, and (2) the mixture distribution problem arising from\ndiverged distributions between clean and adversarial inputs. To address these\nissues, we propose Asymmetric Representation-regularized Adversarial Training\n(ARAT), which incorporates asymmetric invariance loss with stop-gradient\noperation and a predictor to avoid gradient conflict, and a split-BatchNorm\n(BN) structure to resolve the mixture distribution problem. Our detailed\nanalysis demonstrates that each component effectively addresses the identified\nissues, offering novel insights into adversarial defense. ARAT shows\nsuperiority over existing methods across various settings. Finally, we discuss\nthe implications of our findings to knowledge distillation-based defenses,\nproviding a new perspective on their relative successes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2402.14648v3",
    "published_date": "2024-02-22 15:53:46 UTC",
    "updated_date": "2025-01-23 10:21:52 UTC"
  },
  {
    "arxiv_id": "2402.14623v1",
    "title": "RoboScript: Code Generation for Free-Form Manipulation Tasks across Real and Simulation",
    "authors": [
      "Junting Chen",
      "Yao Mu",
      "Qiaojun Yu",
      "Tianming Wei",
      "Silang Wu",
      "Zhecheng Yuan",
      "Zhixuan Liang",
      "Chao Yang",
      "Kaipeng Zhang",
      "Wenqi Shao",
      "Yu Qiao",
      "Huazhe Xu",
      "Mingyu Ding",
      "Ping Luo"
    ],
    "abstract": "Rapid progress in high-level task planning and code generation for open-world\nrobot manipulation has been witnessed in Embodied AI. However, previous studies\nput much effort into general common sense reasoning and task planning\ncapabilities of large-scale language or multi-modal models, relatively little\neffort on ensuring the deployability of generated code on real robots, and\nother fundamental components of autonomous robot systems including robot\nperception, motion planning, and control. To bridge this ``ideal-to-real'' gap,\nthis paper presents \\textbf{RobotScript}, a platform for 1) a deployable robot\nmanipulation pipeline powered by code generation; and 2) a code generation\nbenchmark for robot manipulation tasks in free-form natural language. The\nRobotScript platform addresses this gap by emphasizing the unified interface\nwith both simulation and real robots, based on abstraction from the Robot\nOperating System (ROS), ensuring syntax compliance and simulation validation\nwith Gazebo. We demonstrate the adaptability of our code generation framework\nacross multiple robot embodiments, including the Franka and UR5 robot arms, and\nmultiple grippers. Additionally, our benchmark assesses reasoning abilities for\nphysical space and constraints, highlighting the differences between GPT-3.5,\nGPT-4, and Gemini in handling complex physical interactions. Finally, we\npresent a thorough evaluation on the whole system, exploring how each module in\nthe pipeline: code generation, perception, motion planning, and even object\ngeometric properties, impact the overall performance of the system.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "I.2.7; I.2.8; I.2.9; I.2.10"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages of main paper, 4 pages of appendix; 10 figures in main\n  paper, 3 figures in appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.14623v1",
    "published_date": "2024-02-22 15:12:00 UTC",
    "updated_date": "2024-02-22 15:12:00 UTC"
  },
  {
    "arxiv_id": "2402.14622v2",
    "title": "From Keywords to Structured Summaries: Streamlining Scholarly Information Access",
    "authors": [
      "Mahsa Shamsabadi",
      "Jennifer D'Souza"
    ],
    "abstract": "This paper highlights the growing importance of information retrieval (IR)\nengines in the scientific community, addressing the inefficiency of traditional\nkeyword-based search engines due to the rising volume of publications. The\nproposed solution involves structured records, underpinning advanced\ninformation technology (IT) tools, including visualization dashboards, to\nrevolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the \"reproductive number estimate of infectious diseases\"\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation information access system as\nan IR method accessible at https://orkg.org/usecases/r0-estimates.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 3 figures | Accepted for publication as a poster paper at\n  the International Semantic Web Conference (ISWC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.14622v2",
    "published_date": "2024-02-22 15:10:45 UTC",
    "updated_date": "2024-10-23 10:06:10 UTC"
  },
  {
    "arxiv_id": "2403.18838v1",
    "title": "Unleashing the Power of AI. A Systematic Review of Cutting-Edge Techniques in AI-Enhanced Scientometrics, Webometrics, and Bibliometrics",
    "authors": [
      "Hamid Reza Saeidnia",
      "Elaheh Hosseini",
      "Shadi Abdoli",
      "Marcel Ausloos"
    ],
    "abstract": "Purpose: The study aims to analyze the synergy of Artificial Intelligence\n(AI), with scientometrics, webometrics, and bibliometrics to unlock and to\nemphasize the potential of the applications and benefits of AI algorithms in\nthese fields.\n  Design/methodology/approach: By conducting a systematic literature review,\nour aim is to explore the potential of AI in revolutionizing the methods used\nto measure and analyze scholarly communication, identify emerging research\ntrends, and evaluate the impact of scientific publications. To achieve this, we\nimplemented a comprehensive search strategy across reputable databases such as\nProQuest, IEEE Explore, EBSCO, Web of Science, and Scopus. Our search\nencompassed articles published from January 1, 2000, to September 2022,\nresulting in a thorough review of 61 relevant articles.\n  Findings: (i) Regarding scientometrics, the application of AI yields various\ndistinct advantages, such as conducting analyses of publications, citations,\nresearch impact prediction, collaboration, research trend analysis, and\nknowledge mapping, in a more objective and reliable framework. (ii) In terms of\nwebometrics, AI algorithms are able to enhance web crawling and data\ncollection, web link analysis, web content analysis, social media analysis, web\nimpact analysis, and recommender systems. (iii) Moreover, automation of data\ncollection, analysis of citations, disambiguation of authors, analysis of\nco-authorship networks, assessment of research impact, text mining, and\nrecommender systems are considered as the potential of AI integration in the\nfield of bibliometrics.\n  Originality/value: This study covers the particularly new benefits and\npotential of AI-enhanced scientometrics, webometrics, and bibliometrics to\nhighlight the significant prospects of the synergy of this integration through\nAI.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.DL",
    "comment": "to be published in Library High Tech; 30 pages; 80 references; 4\n  figures; 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.18838v1",
    "published_date": "2024-02-22 15:10:02 UTC",
    "updated_date": "2024-02-22 15:10:02 UTC"
  },
  {
    "arxiv_id": "2402.14609v3",
    "title": "Federated Neural Graph Databases",
    "authors": [
      "Qi Hu",
      "Weifeng Jiang",
      "Haoran Li",
      "Zihao Wang",
      "Jiaxin Bai",
      "Qianren Mao",
      "Yangqiu Song",
      "Lixin Fan",
      "Jianxin Li"
    ],
    "abstract": "The increasing demand for large-scale language models (LLMs) has highlighted\nthe importance of efficient data retrieval mechanisms. Neural graph databases\n(NGDBs) have emerged as a promising approach to storing and querying\ngraph-structured data in neural space, enabling the retrieval of relevant\ninformation for LLMs. However, existing NGDBs are typically designed to operate\non a single graph, limiting their ability to reason across multiple graphs.\nFurthermore, the lack of support for multi-source graph data in existing NGDBs\nhinders their ability to capture the complexity and diversity of real-world\ndata. In many applications, data is distributed across multiple sources, and\nthe ability to reason across these sources is crucial for making informed\ndecisions. This limitation is particularly problematic when dealing with\nsensitive graph data, as directly sharing and aggregating such data poses\nsignificant privacy risks. As a result, many applications that rely on NGDBs\nare forced to choose between compromising data privacy or sacrificing the\nability to reason across multiple graphs. To address these limitations, we\npropose Federated Neural Graph Database (FedNGDB), a novel framework that\nenables reasoning over multi-source graph-based data while preserving privacy.\nFedNGDB leverages federated learning to collaboratively learn graph\nrepresentations across multiple sources, enriching relationships between\nentities and improving the overall quality of the graph data. Unlike existing\nmethods, FedNGDB can handle complex graph structures and relationships, making\nit suitable for various downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14609v3",
    "published_date": "2024-02-22 14:57:44 UTC",
    "updated_date": "2024-08-23 08:40:23 UTC"
  },
  {
    "arxiv_id": "2402.14569v2",
    "title": "Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning",
    "authors": [
      "Jinyeob Kim",
      "Sumin Kang",
      "Sungwoo Yang",
      "Beomjoon Kim",
      "Jargalbaatar Yura",
      "Donghan Kim"
    ],
    "abstract": "Robot navigation has transitioned from prioritizing obstacle avoidance to\nadopting socially aware navigation strategies that accommodate human presence.\nAs a result, the recognition of socially aware navigation within dynamic\nhuman-centric environments has gained prominence in the field of robotics.\nAlthough reinforcement learning technique has fostered the advancement of\nsocially aware navigation, defining appropriate reward functions, especially in\ncongested environments, has posed a significant challenge. These rewards,\ncrucial in guiding robot actions, demand intricate human-crafted design due to\ntheir complex nature and inability to be automatically set. The multitude of\nmanually designed rewards poses issues with hyperparameter redundancy,\nimbalance, and inadequate representation of unique object characteristics. To\naddress these challenges, we introduce a transformable gaussian reward function\n(TGRF). The TGRF significantly reduces the burden of hyperparameter tuning,\ndisplays adaptability across various reward functions, and demonstrates\naccelerated learning rates, particularly excelling in crowded environments\nutilizing deep reinforcement learning (DRL). We introduce and validate TGRF\nthrough sections highlighting its conceptual background, characteristics,\nexperiments, and real-world application, paving the way for a more effective\nand adaptable approach in robotics.The complete source code is available on\nhttps://github.com/JinnnK/TGRF",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14569v2",
    "published_date": "2024-02-22 14:20:07 UTC",
    "updated_date": "2024-06-06 13:41:46 UTC"
  },
  {
    "arxiv_id": "2405.00021v3",
    "title": "SIMPLOT: Enhancing Chart Question Answering by Distilling Essentials",
    "authors": [
      "Wonjoong Kim",
      "Sangwu Park",
      "Yeonjun In",
      "Seokwon Han",
      "Chanyoung Park"
    ],
    "abstract": "Recently, interpreting complex charts with logical reasoning has emerged as\nchallenges due to the development of vision-language models. A prior\nstate-of-the-art (SOTA) model has presented an end-to-end method that leverages\nthe vision-language model to convert charts into table format utilizing Large\nLanguage Model (LLM) for reasoning. However, unlike natural images, charts\ncontain a mix of essential and irrelevant information required for chart\nreasoning, and we discover that this characteristic can lower the performance\nof chart-to-table extraction. In this paper, we introduce SIMPLOT, a method\ndesigned to extract only the elements necessary for chart reasoning. The\nproposed method involves two steps: 1) training to mimic a simple plot that\ncontains only the essential information from a complex chart for table\nextraction, followed by 2) performing reasoning based on the table. Our model\nenables accurate chart reasoning without the need for additional annotations or\ndatasets, and its effectiveness is demonstrated through various experiments.\nFurthermore, we propose a novel prompt mimicking how human interpret charts for\nmore accurate reasoning. Our source code is available at\nhttps://github.com/sangwu99/Simplot.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.00021v3",
    "published_date": "2024-02-22 14:04:22 UTC",
    "updated_date": "2025-02-03 17:53:26 UTC"
  },
  {
    "arxiv_id": "2402.14551v2",
    "title": "CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion",
    "authors": [
      "Zijun Long",
      "George Killick",
      "Lipeng Zhuang",
      "Gerardo Aragon-Camarasa",
      "Zaiqiao Meng",
      "Richard Mccreadie"
    ],
    "abstract": "State-of-the-art pre-trained image models predominantly adopt a two-stage\napproach: initial unsupervised pre-training on large-scale datasets followed by\ntask-specific fine-tuning using Cross-Entropy loss~(CE). However, it has been\ndemonstrated that CE can compromise model generalization and stability. While\nrecent works employing contrastive learning address some of these limitations\nby enhancing the quality of embeddings and producing better decision\nboundaries, they often overlook the importance of hard negative mining and rely\non resource intensive and slow training using large sample batches. To counter\nthese issues, we introduce a novel approach named CLCE, which integrates\nLabel-Aware Contrastive Learning with CE. Our approach not only maintains the\nstrengths of both loss functions but also leverages hard negative mining in a\nsynergistic way to enhance performance. Experimental results demonstrate that\nCLCE significantly outperforms CE in Top-1 accuracy across twelve benchmarks,\nachieving gains of up to 3.52% in few-shot learning scenarios and 3.41% in\ntransfer learning settings with the BEiT-3 model. Importantly, our proposed\nCLCE approach effectively mitigates the dependency of contrastive learning on\nlarge batch sizes such as 4096 samples per batch, a limitation that has\npreviously constrained the application of contrastive learning in\nbudget-limited hardware environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14551v2",
    "published_date": "2024-02-22 13:45:01 UTC",
    "updated_date": "2024-11-15 15:16:56 UTC"
  },
  {
    "arxiv_id": "2402.14547v6",
    "title": "OmniPred: Language Models as Universal Regressors",
    "authors": [
      "Xingyou Song",
      "Oscar Li",
      "Chansoo Lee",
      "Bangding Yang",
      "Daiyi Peng",
      "Sagi Perel",
      "Yutian Chen"
    ],
    "abstract": "Regression is a powerful tool to accurately predict the outcome metric of a\nsystem given a set of parameters, but has traditionally been restricted to\nmethods which are only applicable to a specific task. In this paper, we propose\nOmniPred, a framework for training language models as universal end-to-end\nregressors over $(x,y)$ data from arbitrary formats. Using data sourced from\nGoogle Vizier, one of the largest proprietary blackbox optimization databases\nin the world, our extensive experiments demonstrate that language models are\ncapable of very precise numerical regression using only textual representations\nof mathematical parameters and values, and if given the opportunity to train at\nscale over multiple tasks, can significantly outperform traditional regression\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (TMLR) 2024.\n  Code can be found in\n  https://github.com/google-research/optformer/tree/main/optformer/omnipred",
    "pdf_url": "http://arxiv.org/pdf/2402.14547v6",
    "published_date": "2024-02-22 13:36:53 UTC",
    "updated_date": "2025-01-30 22:12:27 UTC"
  },
  {
    "arxiv_id": "2402.14528v5",
    "title": "ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization",
    "authors": [
      "Tianying Ji",
      "Yongyuan Liang",
      "Yan Zeng",
      "Yu Luo",
      "Guowei Xu",
      "Jiawei Guo",
      "Ruijie Zheng",
      "Furong Huang",
      "Fuchun Sun",
      "Huazhe Xu"
    ],
    "abstract": "The varying significance of distinct primitive behaviors during the policy\nlearning process has been overlooked by prior model-free RL algorithms.\nLeveraging this insight, we explore the causal relationship between different\naction dimensions and rewards to evaluate the significance of various primitive\nbehaviors during training. We introduce a causality-aware entropy term that\neffectively identifies and prioritizes actions with high potential impacts for\nefficient exploration. Furthermore, to prevent excessive focus on specific\nprimitive behaviors, we analyze the gradient dormancy phenomenon and introduce\na dormancy-guided reset mechanism to further enhance the efficacy of our\nmethod. Our proposed algorithm, ACE: Off-policy Actor-critic with\nCausality-aware Entropy regularization, demonstrates a substantial performance\nadvantage across 29 diverse continuous control tasks spanning 7 domains\ncompared to model-free RL baselines, which underscores the effectiveness,\nversatility, and efficient sample efficiency of our approach. Benchmark results\nand videos are available at https://ace-rl.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024 as oral paper",
    "pdf_url": "http://arxiv.org/pdf/2402.14528v5",
    "published_date": "2024-02-22 13:22:06 UTC",
    "updated_date": "2024-11-04 05:18:20 UTC"
  },
  {
    "arxiv_id": "2402.14526v2",
    "title": "Balanced Data Sampling for Language Model Training with Clustering",
    "authors": [
      "Yunfan Shao",
      "Linyang Li",
      "Zhaoye Fei",
      "Hang Yan",
      "Dahua Lin",
      "Xipeng Qiu"
    ],
    "abstract": "Data plays a fundamental role in the training of Large Language Models\n(LLMs). While attention has been paid to the collection and composition of\ndatasets, determining the data sampling strategy in training remains an open\nquestion. Most LLMs are trained with a simple strategy, random sampling.\nHowever, this sampling strategy ignores the unbalanced nature of training data\ndistribution, which can be sub-optimal. In this paper, we propose ClusterClip\nSampling to balance the text distribution of training data for better model\ntraining. Specifically, ClusterClip Sampling utilizes data clustering to\nreflect the data distribution of the training set and balances the common\nsamples and rare samples during training based on the cluster results. A\nrepetition clip operation is introduced to mitigate the overfitting issue led\nby samples from certain clusters. Extensive experiments validate the\neffectiveness of ClusterClip Sampling, which outperforms random sampling and\nother cluster-based sampling variants under various training datasets and large\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (findings), Code is released at\n  https://github.com/choosewhatulike/cluster-clip",
    "pdf_url": "http://arxiv.org/pdf/2402.14526v2",
    "published_date": "2024-02-22 13:20:53 UTC",
    "updated_date": "2024-06-03 06:48:34 UTC"
  },
  {
    "arxiv_id": "2402.14505v3",
    "title": "Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition",
    "authors": [
      "Feng Lu",
      "Lijun Zhang",
      "Xiangyuan Lan",
      "Shuting Dong",
      "Yaowei Wang",
      "Chun Yuan"
    ],
    "abstract": "Recent studies show that vision models pre-trained in generic visual learning\ntasks with large-scale data can provide useful feature representations for a\nwide range of visual perception problems. However, few attempts have been made\nto exploit pre-trained foundation models in visual place recognition (VPR). Due\nto the inherent difference in training objectives and data between the tasks of\nmodel pre-training and VPR, how to bridge the gap and fully unleash the\ncapability of pre-trained models for VPR is still a key issue to address. To\nthis end, we propose a novel method to realize seamless adaptation of\npre-trained models for VPR. Specifically, to obtain both global and local\nfeatures that focus on salient landmarks for discriminating places, we design a\nhybrid adaptation method to achieve both global and local adaptation\nefficiently, in which only lightweight adapters are tuned without adjusting the\npre-trained model. Besides, to guide effective adaptation, we propose a mutual\nnearest neighbor local feature loss, which ensures proper dense local features\nare produced for local matching and avoids time-consuming spatial verification\nin re-ranking. Experimental results show that our method outperforms the\nstate-of-the-art methods with less training data and training time, and uses\nabout only 3% retrieval runtime of the two-stage VPR methods with RANSAC-based\nspatial verification. It ranks 1st on the MSLS challenge leaderboard (at the\ntime of submission). The code is released at\nhttps://github.com/Lu-Feng/SelaVPR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14505v3",
    "published_date": "2024-02-22 12:55:01 UTC",
    "updated_date": "2024-04-03 14:59:08 UTC"
  },
  {
    "arxiv_id": "2402.14498v2",
    "title": "A Collision-Aware Cable Grasping Method in Cluttered Environment",
    "authors": [
      "Lei Zhang",
      "Kaixin Bai",
      "Qiang Li",
      "Zhaopeng Chen",
      "Jianwei Zhang"
    ],
    "abstract": "We introduce a Cable Grasping-Convolutional Neural Network designed to\nfacilitate robust cable grasping in cluttered environments. Utilizing physics\nsimulations, we generate an extensive dataset that mimics the intricacies of\ncable grasping, factoring in potential collisions between cables and robotic\ngrippers. We employ the Approximate Convex Decomposition technique to dissect\nthe non-convex cable model, with grasp quality autonomously labeled based on\nsimulated grasping attempts. The CG-CNN is refined using this simulated dataset\nand enhanced through domain randomization techniques. Subsequently, the trained\nmodel predicts grasp quality, guiding the optimal grasp pose to the robot\ncontroller for execution. Grasping efficacy is assessed across both synthetic\nand real-world settings. Given our model implicit collision sensitivity, we\nachieved commendable success rates of 92.3% for known cables and 88.4% for\nunknown cables, surpassing contemporary state-of-the-art approaches.\nSupplementary materials can be found at\nhttps://leizhang-public.github.io/cg-cnn/ .",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.14498v2",
    "published_date": "2024-02-22 12:47:04 UTC",
    "updated_date": "2024-03-04 12:56:23 UTC"
  },
  {
    "arxiv_id": "2402.14891v5",
    "title": "LLMBind: A Unified Modality-Task Integration Framework",
    "authors": [
      "Bin Zhu",
      "Munan Ning",
      "Peng Jin",
      "Bin Lin",
      "Jinfa Huang",
      "Qi Song",
      "Junwu Zhang",
      "Zhenyu Tang",
      "Mingjun Pan",
      "Xing Zhou",
      "Li Yuan"
    ],
    "abstract": "In the multi-modal domain, the dependence of various models on specific input\nformats leads to user confusion and hinders progress. To address this\nchallenge, we introduce \\textbf{LLMBind}, a novel framework designed to unify a\ndiverse array of multi-modal tasks. By harnessing a Mixture-of-Experts (MoE)\nLarge Language Model (LLM), LLMBind processes multi-modal inputs and generates\ntask-specific tokens, enabling the invocation of corresponding models to\naccomplish tasks. This unique approach empowers LLMBind to interpret inputs and\ngenerate outputs across various modalities, including image, text, video, and\naudio. Furthermore, we have constructed an interaction dataset comprising 400k\ninstructions, which unlocks the ability of LLMBind for interactive visual\ngeneration and editing tasks. Extensive experimentation demonstrates that\nLLMBind achieves very superior performance across diverse tasks and outperforms\nexisting models in user evaluations conducted in real-world scenarios.\nMoreover, the adaptability of LLMBind allows for seamless integration with the\nlatest models and extension to new modality tasks, highlighting its potential\nto serve as a unified AI agent for modeling universal modalities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14891v5",
    "published_date": "2024-02-22 12:36:31 UTC",
    "updated_date": "2024-04-19 03:07:59 UTC"
  },
  {
    "arxiv_id": "2402.14492v2",
    "title": "Towards Robust Instruction Tuning on Multimodal Large Language Models",
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Soujanya Poria"
    ],
    "abstract": "Fine-tuning large language models (LLMs) on multi-task instruction-following\ndata has been proven to be a powerful learning paradigm for improving their\nzero-shot capabilities on new tasks. Recent works about high-quality\ninstruction-following data generation and selection require amounts of human\nlabor to conceive model-understandable instructions for the given tasks and\ncarefully filter the LLM-generated data. In this work, we introduce an\nautomatic instruction augmentation method named INSTRAUG in multimodal tasks.\nIt starts from a handful of basic and straightforward meta instructions but can\nexpand an instruction-following dataset by 30 times. Results on two popular\nmultimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show\nthat INSTRAUG can significantly improve the alignment of multimodal large\nlanguage models (MLLMs) across 12 multimodal tasks, which is even equivalent to\nthe benefits of scaling up training data multiple times.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14492v2",
    "published_date": "2024-02-22 12:35:50 UTC",
    "updated_date": "2024-06-14 13:38:14 UTC"
  },
  {
    "arxiv_id": "2402.14486v1",
    "title": "Are Bounded Contracts Learnable and Approximately Optimal?",
    "authors": [
      "Yurong Chen",
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Zhiyi Huang"
    ],
    "abstract": "This paper considers the hidden-action model of the principal-agent problem,\nin which a principal incentivizes an agent to work on a project using a\ncontract. We investigate whether contracts with bounded payments are learnable\nand approximately optimal. Our main results are two learning algorithms that\ncan find a nearly optimal bounded contract using a polynomial number of\nqueries, under two standard assumptions in the literature: a costlier action\nfor the agent leads to a better outcome distribution for the principal, and the\nagent's cost/effort has diminishing returns. Our polynomial query complexity\nupper bound shows that standard assumptions are sufficient for achieving an\nexponential improvement upon the known lower bound for general instances.\nUnlike the existing algorithms, which relied on discretizing the contract\nspace, our algorithms directly learn the underlying outcome distributions. As\nfor the approximate optimality of bounded contracts, we find that they could be\nfar from optimal in terms of multiplicative or additive approximation, but\nsatisfy a notion of mixed approximation.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14486v1",
    "published_date": "2024-02-22 12:19:19 UTC",
    "updated_date": "2024-02-22 12:19:19 UTC"
  },
  {
    "arxiv_id": "2402.14473v1",
    "title": "Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation",
    "authors": [
      "Jiajie Su",
      "Chaochao Chen",
      "Zibin Lin",
      "Xi Li",
      "Weiming Liu",
      "Xiaolin Zheng"
    ],
    "abstract": "Sequential Recommendation (SR) captures users' dynamic preferences by\nmodeling how users transit among items. However, SR models that utilize only\nsingle type of behavior interaction data encounter performance degradation when\nthe sequences are short. To tackle this problem, we focus on Multi-Behavior\nSequential Recommendation (MBSR) in this paper, which aims to leverage\ntime-evolving heterogeneous behavioral dependencies for better exploring users'\npotential intents on the target behavior. Solving MBSR is challenging. On the\none hand, users exhibit diverse multi-behavior patterns due to personal\ncharacteristics. On the other hand, there exists comprehensive co-influence\nbetween behavior correlations and item collaborations, the intensity of which\nis deeply affected by temporal factors. To tackle these challenges, we propose\na Personalized Behavior-Aware Transformer framework (PBAT) for MBSR problem,\nwhich models personalized patterns and multifaceted sequential collaborations\nin a novel way to boost recommendation performance. First, PBAT develops a\npersonalized behavior pattern generator in the representation layer, which\nextracts dynamic and discriminative behavior patterns for sequential learning.\nSecond, PBAT reforms the self-attention layer with a behavior-aware\ncollaboration extractor, which introduces a fused behavior-aware attention\nmechanism for incorporating both behavioral and temporal impacts into\ncollaborative transitions. We conduct experiments on three benchmark datasets\nand the results demonstrate the effectiveness and interpretability of our\nframework. Our implementation code is released at\nhttps://github.com/TiliaceaeSU/PBAT.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14473v1",
    "published_date": "2024-02-22 12:03:21 UTC",
    "updated_date": "2024-02-22 12:03:21 UTC"
  },
  {
    "arxiv_id": "2402.14890v2",
    "title": "Vygotsky Distance: Measure for Benchmark Task Similarity",
    "authors": [
      "Maxim K. Surkov",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "Evaluation plays a significant role in modern natural language processing.\nMost modern NLP benchmarks consist of arbitrary sets of tasks that neither\nguarantee any generalization potential for the model once applied outside the\ntest set nor try to minimize the resource consumption needed for model\nevaluation. This paper presents a theoretical instrument and a practical\nalgorithm to calculate similarity between benchmark tasks, we call this\nsimilarity measure \"Vygotsky distance\". The core idea of this similarity\nmeasure is that it is based on relative performance of the \"students\" on a\ngiven task, rather that on the properties of the task itself. If two tasks are\nclose to each other in terms of Vygotsky distance the models tend to have\nsimilar relative performance on them. Thus knowing Vygotsky distance between\ntasks one can significantly reduce the number of evaluation tasks while\nmaintaining a high validation quality. Experiments on various benchmarks,\nincluding GLUE, SuperGLUE, CLUE, and RussianSuperGLUE, demonstrate that a vast\nmajority of NLP benchmarks could be at least 40% smaller in terms of the tasks\nincluded. Most importantly, Vygotsky distance could also be used for the\nvalidation of new tasks thus increasing the generalization potential of the\nfuture NLP models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T01, 97P80, 97C30, 68Q32",
      "H.1.1; I.2.4; I.2.6; F.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14890v2",
    "published_date": "2024-02-22 12:00:32 UTC",
    "updated_date": "2024-02-26 12:09:43 UTC"
  },
  {
    "arxiv_id": "2402.14460v1",
    "title": "Reframing the Expected Free Energy: Four Formulations and a Unification",
    "authors": [
      "Théophile Champion",
      "Howard Bowman",
      "Dimitrije Marković",
      "Marek Grześ"
    ],
    "abstract": "Active inference is a leading theory of perception, learning and decision\nmaking, which can be applied to neuroscience, robotics, psychology, and machine\nlearning. Active inference is based on the expected free energy, which is\nmostly justified by the intuitive plausibility of its formulations, e.g., the\nrisk plus ambiguity and information gain / pragmatic value formulations. This\npaper seek to formalize the problem of deriving these formulations from a\nsingle root expected free energy definition, i.e., the unification problem.\nThen, we study two settings, each one having its own root expected free energy\ndefinition. In the first setting, no justification for the expected free energy\nhas been proposed to date, but all the formulations can be recovered from it.\nHowever, in this setting, the agent cannot have arbitrary prior preferences\nover observations. Indeed, only a limited class of prior preferences over\nobservations is compatible with the likelihood mapping of the generative model.\nIn the second setting, a justification of the root expected free energy\ndefinition is known, but this setting only accounts for two formulations, i.e.,\nthe risk over states plus ambiguity and entropy plus expected energy\nformulations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14460v1",
    "published_date": "2024-02-22 11:38:43 UTC",
    "updated_date": "2024-02-22 11:38:43 UTC"
  },
  {
    "arxiv_id": "2402.14458v1",
    "title": "NLAS-multi: A Multilingual Corpus of Automatically Generated Natural Language Argumentation Schemes",
    "authors": [
      "Ramon Ruiz-Dolz",
      "Joaquin Taverner",
      "John Lawrence",
      "Chris Reed"
    ],
    "abstract": "Some of the major limitations identified in the areas of argument mining,\nargument generation, and natural language argument analysis are related to the\ncomplexity of annotating argumentatively rich data, the limited size of these\ncorpora, and the constraints that represent the different languages and domains\nin which these data is annotated. To address these limitations, in this paper\nwe present the following contributions: (i) an effective methodology for the\nautomatic generation of natural language arguments in different topics and\nlanguages, (ii) the largest publicly available corpus of natural language\nargumentation schemes, and (iii) a set of solid baselines and fine-tuned models\nfor the automatic identification of argumentation schemes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14458v1",
    "published_date": "2024-02-22 11:31:50 UTC",
    "updated_date": "2024-02-22 11:31:50 UTC"
  },
  {
    "arxiv_id": "2402.14889v3",
    "title": "COBIAS: Contextual Reliability in Bias Assessment",
    "authors": [
      "Priyanshul Govil",
      "Hemang Jain",
      "Vamshi Krishna Bonagiri",
      "Aman Chadha",
      "Ponnurangam Kumaraguru",
      "Manas Gaur",
      "Sanorita Dey"
    ],
    "abstract": "Large Language Models (LLMs) often inherit biases from the web data they are\ntrained on, which contains stereotypes and prejudices. Current methods for\nevaluating and mitigating these biases rely on bias-benchmark datasets. These\nbenchmarks measure bias by observing an LLM's behavior on biased statements.\nHowever, these statements lack contextual considerations of the situations they\ntry to present. To address this, we introduce a contextual reliability\nframework, which evaluates model robustness to biased statements by considering\nthe various contexts in which they may appear. We develop the Context-Oriented\nBias Indicator and Assessment Score (COBIAS) to measure a biased statement's\nreliability in detecting bias based on the variance in model behavior across\ndifferent contexts. To evaluate the metric, we augment 2,291 stereotyped\nstatements from two existing benchmark datasets by adding contextual\ninformation. We show that COBIAS aligns with human judgment on the contextual\nreliability of biased statements (Spearman's $\\rho = 0.65$, $p = 3.4 *\n10^{-60}$) and can be used to create reliable datasets, which would assist bias\nmitigation works.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14889v3",
    "published_date": "2024-02-22 10:46:11 UTC",
    "updated_date": "2024-09-17 09:24:42 UTC"
  },
  {
    "arxiv_id": "2402.14433v1",
    "title": "A Language Model's Guide Through Latent Space",
    "authors": [
      "Dimitri von Rütte",
      "Sotiris Anagnostidis",
      "Gregor Bachmann",
      "Thomas Hofmann"
    ],
    "abstract": "Concept guidance has emerged as a cheap and simple way to control the\nbehavior of language models by probing their hidden representations for concept\nvectors and using them to perturb activations at inference time. While the\nfocus of previous work has largely been on truthfulness, in this paper we\nextend this framework to a richer set of concepts such as appropriateness,\nhumor, creativity and quality, and explore to what degree current detection and\nguidance strategies work in these challenging settings. To facilitate\nevaluation, we develop a novel metric for concept guidance that takes into\naccount both the success of concept elicitation as well as the potential\ndegradation in fluency of the guided model. Our extensive experiments reveal\nthat while some concepts such as truthfulness more easily allow for guidance\nwith current techniques, novel concepts such as appropriateness or humor either\nremain difficult to elicit, need extensive tuning to work, or even experience\nconfusion. Moreover, we find that probes with optimal detection accuracies do\nnot necessarily make for the optimal guides, contradicting previous\nobservations for truthfulness. Our work warrants a deeper investigation into\nthe interplay between detectability, guidability, and the nature of the\nconcept, and we hope that our rich experimental test-bed for guidance research\ninspires stronger follow-up approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14433v1",
    "published_date": "2024-02-22 10:25:14 UTC",
    "updated_date": "2024-02-22 10:25:14 UTC"
  },
  {
    "arxiv_id": "2402.14428v2",
    "title": "KoCoSa: Korean Context-aware Sarcasm Detection Dataset",
    "authors": [
      "Yumin Kim",
      "Heejae Suh",
      "Mingi Kim",
      "Dongyeon Won",
      "Hwanhee Lee"
    ],
    "abstract": "Sarcasm is a way of verbal irony where someone says the opposite of what they\nmean, often to ridicule a person, situation, or idea. It is often difficult to\ndetect sarcasm in the dialogue since detecting sarcasm should reflect the\ncontext (i.e., dialogue history). In this paper, we introduce a new dataset for\nthe Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware\nSarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and\nthe labels for this task on the last response. To build the dataset, we propose\nan efficient sarcasm detection dataset generation pipeline: 1) generating new\nsarcastic dialogues from source dialogues with large language models, 2)\nautomatic and manual filtering of abnormal and toxic dialogues, and 3) human\nannotation for the sarcasm detection task. We also provide a simple but\neffective baseline for the Korean sarcasm detection task trained on our\ndataset. Experimental results on the dataset show that our baseline system\noutperforms strong baselines like large language models, such as GPT-3.5, in\nthe Korean sarcasm detection task. We show that the sarcasm detection task\nrelies deeply on the existence of sufficient context. We will release the\ndataset at https://github.com/Yu-billie/KoCoSa_sarcasm_detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14428v2",
    "published_date": "2024-02-22 10:17:57 UTC",
    "updated_date": "2024-03-22 06:29:26 UTC"
  },
  {
    "arxiv_id": "2402.14424v3",
    "title": "Automating psychological hypothesis generation with AI: when large language models meet causal graph",
    "authors": [
      "Song Tong",
      "Kai Mao",
      "Zhen Huang",
      "Yukun Zhao",
      "Kaiping Peng"
    ],
    "abstract": "Leveraging the synergy between causal knowledge graphs and a large language\nmodel (LLM), our study introduces a groundbreaking approach for computational\nhypothesis generation in psychology. We analyzed 43,312 psychology articles\nusing a LLM to extract causal relation pairs. This analysis produced a\nspecialized causal graph for psychology. Applying link prediction algorithms,\nwe generated 130 potential psychological hypotheses focusing on `well-being',\nthen compared them against research ideas conceived by doctoral scholars and\nthose produced solely by the LLM. Interestingly, our combined approach of a LLM\nand causal graphs mirrored the expert-level insights in terms of novelty,\nclearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) =\n4.32, p<0.001, respectively). This alignment was further corroborated using\ndeep semantic analysis. Our results show that combining LLM with machine\nlearning techniques such as causal knowledge graphs can revolutionize automated\ndiscovery in psychology, extracting novel insights from the extensive\nliterature. This work stands at the crossroads of psychology and artificial\nintelligence, championing a new enriched paradigm for data-driven hypothesis\ngeneration in psychological research.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14424v3",
    "published_date": "2024-02-22 10:12:16 UTC",
    "updated_date": "2024-07-16 03:12:45 UTC"
  },
  {
    "arxiv_id": "2402.14418v2",
    "title": "Uncertainty-Aware Evaluation for Vision-Language Models",
    "authors": [
      "Vasily Kostumov",
      "Bulat Nutfullin",
      "Oleg Pilipenko",
      "Eugene Ilyushin"
    ],
    "abstract": "Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in\npopularity recently due to their impressive performance in several\nvision-language tasks. Current evaluation methods, however, overlook an\nessential component: uncertainty, which is crucial for a comprehensive\nassessment of VLMs. Addressing this oversight, we present a benchmark\nincorporating uncertainty quantification into evaluating VLMs.\n  Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question\nAnswering (VQA) task. We examine models on 5 datasets that evaluate various\nvision-language capabilities.\n  Using conformal prediction as an uncertainty estimation approach, we\ndemonstrate that the models' uncertainty is not aligned with their accuracy.\nSpecifically, we show that models with the highest accuracy may also have the\nhighest uncertainty, which confirms the importance of measuring it for VLMs.\nOur empirical findings also reveal a correlation between model uncertainty and\nits language model part.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14418v2",
    "published_date": "2024-02-22 10:04:17 UTC",
    "updated_date": "2024-02-24 12:30:40 UTC"
  },
  {
    "arxiv_id": "2403.05572v1",
    "title": "Is ChatGPT More Empathetic than Humans?",
    "authors": [
      "Anuradha Welivita",
      "Pearl Pu"
    ],
    "abstract": "This paper investigates the empathetic responding capabilities of ChatGPT,\nparticularly its latest iteration, GPT-4, in comparison to human-generated\nresponses to a wide range of emotional scenarios, both positive and negative.\nWe employ a rigorous evaluation methodology, involving a between-groups study\nwith 600 participants, to evaluate the level of empathy in responses generated\nby humans and ChatGPT. ChatGPT is prompted in two distinct ways: a standard\napproach and one explicitly detailing empathy's cognitive, affective, and\ncompassionate counterparts. Our findings indicate that the average empathy\nrating of responses generated by ChatGPT exceeds those crafted by humans by\napproximately 10%. Additionally, instructing ChatGPT to incorporate a clear\nunderstanding of empathy in its responses makes the responses align\napproximately 5 times more closely with the expectations of individuals\npossessing a high degree of empathy, compared to human responses. The proposed\nevaluation framework serves as a scalable and adaptable framework to assess the\nempathetic capabilities of newer and updated versions of large language models,\neliminating the need to replicate the current study's results in future\nresearch.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.05572v1",
    "published_date": "2024-02-22 09:52:45 UTC",
    "updated_date": "2024-02-22 09:52:45 UTC"
  },
  {
    "arxiv_id": "2402.14409v1",
    "title": "Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models",
    "authors": [
      "Zhuoran Jin",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Xiaojian Jiang",
      "Jiexin Xu",
      "Qiuxia Li",
      "Jun Zhao"
    ],
    "abstract": "Retrieval-augmented language models (RALMs) have demonstrated significant\npotential in refining and expanding their internal memory by retrieving\nevidence from external sources. However, RALMs will inevitably encounter\nknowledge conflicts when integrating their internal memory with external\nsources. Knowledge conflicts can ensnare RALMs in a tug-of-war between\nknowledge, limiting their practical applicability. In this paper, we focus on\nexploring and resolving knowledge conflicts in RALMs. First, we present an\nevaluation framework for assessing knowledge conflicts across various\ndimensions. Then, we investigate the behavior and preference of RALMs from the\nfollowing two perspectives: (1) Conflicts between internal memory and external\nsources: We find that stronger RALMs emerge with the Dunning-Kruger effect,\npersistently favoring their faulty internal memory even when correct evidence\nis provided. Besides, RALMs exhibit an availability bias towards common\nknowledge; (2) Conflicts between truthful, irrelevant and misleading evidence:\nWe reveal that RALMs follow the principle of majority rule, leaning towards\nplacing trust in evidence that appears more frequently. Moreover, we find that\nRALMs exhibit confirmation bias, and are more willing to choose evidence that\nis consistent with their internal memory. To solve the challenge of knowledge\nconflicts, we propose a method called Conflict-Disentangle Contrastive Decoding\n(CD2) to better calibrate the model's confidence. Experimental results\ndemonstrate that our CD2 can effectively resolve knowledge conflicts in RALMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14409v1",
    "published_date": "2024-02-22 09:51:08 UTC",
    "updated_date": "2024-02-22 09:51:08 UTC"
  },
  {
    "arxiv_id": "2402.14404v2",
    "title": "On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe",
    "authors": [
      "Ningyu Xu",
      "Qi Zhang",
      "Menghan Zhang",
      "Peng Qian",
      "Xuanjing Huang"
    ],
    "abstract": "Probing and enhancing large language models' reasoning capacity remains a\ncrucial open question. Here we re-purpose the reverse dictionary task as a case\nstudy to probe LLMs' capacity for conceptual inference. We use in-context\nlearning to guide the models to generate the term for an object concept implied\nin a linguistic description. Models robustly achieve high accuracy in this\ntask, and their representation space encodes information about object\ncategories and fine-grained features. Further experiments suggest that the\nconceptual inference ability as probed by the reverse-dictionary task predicts\nmodel's general reasoning performance across multiple benchmarks, despite\nsimilar syntactic generalization behaviors across models. Explorative analyses\nsuggest that prompting LLMs with description$\\Rightarrow$word examples may\ninduce generalization beyond surface-level differences in task construals and\nfacilitate models on broader commonsense reasoning problems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14404v2",
    "published_date": "2024-02-22 09:45:26 UTC",
    "updated_date": "2024-02-26 11:40:45 UTC"
  },
  {
    "arxiv_id": "2402.14888v1",
    "title": "Efficient data selection employing Semantic Similarity-based Graph Structures for model training",
    "authors": [
      "Roxana Petcu",
      "Subhadeep Maji"
    ],
    "abstract": "Recent developments in natural language processing (NLP) have highlighted the\nneed for substantial amounts of data for models to capture textual information\naccurately. This raises concerns regarding the computational resources and time\nrequired for training such models. This paper introduces Semantics for data\nSAliency in Model performance Estimation (SeSaME). It is an efficient data\nsampling mechanism solely based on textual information without passing the data\nthrough a compute-heavy model or other intensive pre-processing\ntransformations. The application of this approach is demonstrated in the use\ncase of low-resource automated speech recognition (ASR) models, which\nexcessively rely on text-to-speech (TTS) calls when using augmented data.\nSeSaME learns to categorize new incoming data points into speech recognition\ndifficulty buckets by employing semantic similarity-based graph structures and\ndiscrete ASR information from homophilous neighbourhoods through message\npassing. The results indicate reliable projections of ASR performance, with a\n93% accuracy increase when using the proposed method compared to random\npredictions, bringing non-trivial information on the impact of textual\nrepresentations in speech models. Furthermore, a series of experiments show\nboth the benefits and challenges of using the ASR information on incoming data\nto fine-tune the model. We report a 7% drop in validation loss compared to\nrandom sampling, 7% WER drop with non-local aggregation when evaluating against\na highly difficult dataset, and 1.8% WER drop with local aggregation and high\nsemantic similarity between datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2023 Workshop: Sampling and Optimization in Discrete Space",
    "pdf_url": "http://arxiv.org/pdf/2402.14888v1",
    "published_date": "2024-02-22 09:43:53 UTC",
    "updated_date": "2024-02-22 09:43:53 UTC"
  },
  {
    "arxiv_id": "2402.14399v1",
    "title": "Ensure Timeliness and Accuracy: A Novel Sliding Window Data Stream Paradigm for Live Streaming Recommendation",
    "authors": [
      "Fengqi Liang",
      "Baigong Zheng",
      "Liqin Zhao",
      "Guorui Zhou",
      "Qian Wang",
      "Yanan Niu"
    ],
    "abstract": "Live streaming recommender system is specifically designed to recommend\nreal-time live streaming of interest to users. Due to the dynamic changes of\nlive content, improving the timeliness of the live streaming recommender system\nis a critical problem. Intuitively, the timeliness of the data determines the\nupper bound of the timeliness that models can learn. However, none of the\nprevious works addresses the timeliness problem of the live streaming\nrecommender system from the perspective of data stream design. Employing the\nconventional fixed window data stream paradigm introduces a trade-off dilemma\nbetween labeling accuracy and timeliness. In this paper, we propose a new data\nstream design paradigm, dubbed Sliver, that addresses the timeliness and\naccuracy problem of labels by reducing the window size and implementing a\nsliding window correspondingly. Meanwhile, we propose a time-sensitive re-reco\nstrategy reducing the latency between request and impression to improve the\ntimeliness of the recommendation service and features by periodically\nrequesting the recommendation service. To demonstrate the effectiveness of our\napproach, we conduct offline experiments on a multi-task live streaming dataset\nwith labeling timestamps collected from the Kuaishou live streaming platform.\nExperimental results demonstrate that Sliver outperforms two fixed-window data\nstreams with varying window sizes across all targets in four typical multi-task\nrecommendation models. Furthermore, we deployed Sliver on the Kuaishou live\nstreaming platform. Results of the online A/B test show a significant\nimprovement in click-through rate (CTR), and new follow number (NFN), further\nvalidating the effectiveness of Sliver.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14399v1",
    "published_date": "2024-02-22 09:32:34 UTC",
    "updated_date": "2024-02-22 09:32:34 UTC"
  },
  {
    "arxiv_id": "2402.14398v1",
    "title": "Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing",
    "authors": [
      "Hao Li",
      "Mengqi Huang",
      "Lei Zhang",
      "Bo Hu",
      "Yi Liu",
      "Zhendong Mao"
    ],
    "abstract": "GAN-based image attribute editing firstly leverages GAN Inversion to project\nreal images into the latent space of GAN and then manipulates corresponding\nlatent codes. Recent inversion methods mainly utilize additional high-bit\nfeatures to improve image details preservation, as low-bit codes cannot\nfaithfully reconstruct source images, leading to the loss of details. However,\nduring editing, existing works fail to accurately complement the lost details\nand suffer from poor editability. The main reason is they inject all the lost\ndetails indiscriminately at one time, which inherently induces the position and\nquantity of details to overfit source images, resulting in inconsistent content\nand artifacts in edited images. This work argues that details should be\ngradually injected into both the reconstruction and editing process in a\nmulti-stage coarse-to-fine manner for better detail preservation and high\neditability. Therefore, a novel dual-stream framework is proposed to accurately\ncomplement details at each stage. The Reconstruction Stream is employed to\nembed coarse-to-fine lost details into residual features and then adaptively\nadd them to the GAN generator. In the Editing Stream, residual features are\naccurately aligned by our Selective Attention mechanism and then injected into\nthe editing process in a multi-stage manner. Extensive experiments have shown\nthe superiority of our framework in both reconstruction accuracy and editing\nquality compared with existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 18 figures, published to AAAI24",
    "pdf_url": "http://arxiv.org/pdf/2402.14398v1",
    "published_date": "2024-02-22 09:28:47 UTC",
    "updated_date": "2024-02-22 09:28:47 UTC"
  },
  {
    "arxiv_id": "2404.07216v1",
    "title": "A Bio-Medical Snake Optimizer System Driven by Logarithmic Surviving Global Search for Optimizing Feature Selection and its application for Disorder Recognition",
    "authors": [
      "Ruba Abu Khurma",
      "Esraa Alhenawi",
      "Malik Braik",
      "Fatma A. Hashim",
      "Amit Chhabra",
      "Pedro A. Castillo"
    ],
    "abstract": "It is of paramount importance to enhance medical practices, given how\nimportant it is to protect human life. Medical therapy can be accelerated by\nautomating patient prediction using machine learning techniques. To double the\nefficiency of classifiers, several preprocessing strategies must be adopted for\ntheir crucial duty in this field. Feature selection (FS) is one tool that has\nbeen used frequently to modify data and enhance classification outcomes by\nlowering the dimensionality of datasets. Excluded features are those that have\na poor correlation coefficient with the label class, that is, they have no\nmeaningful correlation with classification and do not indicate where the\ninstance belongs. Along with the recurring features, which show a strong\nassociation with the remainder of the features. Contrarily, the model being\nproduced during training is harmed, and the classifier is misled by their\npresence. This causes overfitting and increases algorithm complexity and\nprocessing time. These are used in exploration to allow solutions to be found\nmore thoroughly and in relation to a chosen solution than at random. TLSO,\nPLSO, and LLSO stand for Tournament Logarithmic Snake Optimizer, Proportional\nLogarithmic Snake Optimizer, and Linear Order Logarithmic Snake Optimizer,\nrespectively. A number of 22 reference medical datasets were used in\nexperiments. The findings indicate that, among 86 % of the datasets, TLSO\nattained the best accuracy, and among 82 % of the datasets, the best feature\nreduction. In terms of the standard deviation, the TLSO also attained\nnoteworthy reliability and stability. On the basis of running duration, it is,\nnonetheless, quite effective.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07216v1",
    "published_date": "2024-02-22 09:08:18 UTC",
    "updated_date": "2024-02-22 09:08:18 UTC"
  },
  {
    "arxiv_id": "2402.17778v1",
    "title": "Dynamic Anchor Selection and Real-Time Pose Prediction for Ultra-wideband Tagless Gate",
    "authors": [
      "Junyoung Choi",
      "Sagnik Bhattacharya",
      "Joohyun Lee"
    ],
    "abstract": "Ultra-wideband (UWB) is emerging as a promising solution that can realize\nproximity services, such as UWB tagless gate (UTG), thanks to centimeter-level\nlocalization accuracy based on two different ranging methods such as downlink\ntime-difference of arrival (DL-TDoA) and double-sided two-way ranging (DS-TWR).\nThe UTG is a UWB-based proximity service that provides a seamless gate pass\nsystem without requiring real-time mobile device (MD) tapping. The location of\nMD is calculated using DL-TDoA, and the MD communicates with the nearest UTG\nusing DS-TWR to open the gate. Therefore, the knowledge about the exact\nlocation of MD is the main challenge of UTG, and hence we provide the solutions\nfor both DL-TDoA and DS-TWR. In this paper, we propose dynamic anchor selection\nfor extremely accurate DL-TDoA localization and pose prediction for DS-TWR,\ncalled DynaPose. The pose is defined as the actual location of MD on the human\nbody, which affects the localization accuracy. DynaPose is based on\nline-of-sight (LOS) and non-LOS (NLOS) classification using deep learning for\nanchor selection and pose prediction. Deep learning models use the UWB channel\nimpulse response and the inertial measurement unit embedded in the smartphone.\nDynaPose is implemented on Samsung Galaxy Note20 Ultra and Qorvo UWB board to\nshow the feasibility and applicability. DynaPose achieves a LOS/NLOS\nclassification accuracy of 0.984, 62% higher DL-TDoA localization accuracy, and\nultimately detects four different poses with an accuracy of 0.961 in real-time.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.08399",
    "pdf_url": "http://arxiv.org/pdf/2402.17778v1",
    "published_date": "2024-02-22 08:41:49 UTC",
    "updated_date": "2024-02-22 08:41:49 UTC"
  },
  {
    "arxiv_id": "2402.14886v1",
    "title": "Applying Reinforcement Learning to Optimize Traffic Light Cycles",
    "authors": [
      "Seungah Son",
      "Juhee Jin"
    ],
    "abstract": "Manual optimization of traffic light cycles is a complex and time-consuming\ntask, necessitating the development of automated solutions. In this paper, we\npropose the application of reinforcement learning to optimize traffic light\ncycles in real-time. We present a case study using the Simulation Urban\nMobility simulator to train a Deep Q-Network algorithm. The experimental\nresults showed 44.16% decrease in the average number of Emergency stops,\nshowing the potential of our approach to reduce traffic congestion and improve\ntraffic flow. Furthermore, we discuss avenues for future research and\nenhancements to the reinforcement learning model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14886v1",
    "published_date": "2024-02-22 07:37:04 UTC",
    "updated_date": "2024-02-22 07:37:04 UTC"
  },
  {
    "arxiv_id": "2402.14346v1",
    "title": "Dependable Distributed Training of Compressed Machine Learning Models",
    "authors": [
      "Francesco Malandrino",
      "Giuseppe Di Giacomo",
      "Marco Levorato",
      "Carla Fabiana Chiasserini"
    ],
    "abstract": "The existing work on the distributed training of machine learning (ML) models\nhas consistently overlooked the distribution of the achieved learning quality,\nfocusing instead on its average value. This leads to a poor dependability}of\nthe resulting ML models, whose performance may be much worse than expected. We\nfill this gap by proposing DepL, a framework for dependable learning\norchestration, able to make high-quality, efficient decisions on (i) the data\nto leverage for learning, (ii) the models to use and when to switch among them,\nand (iii) the clusters of nodes, and the resources thereof, to exploit. For\nconcreteness, we consider as possible available models a full DNN and its\ncompressed versions. Unlike previous studies, DepL guarantees that a target\nlearning quality is reached with a target probability, while keeping the\ntraining cost at a minimum. We prove that DepL has constant competitive ratio\nand polynomial complexity, and show that it outperforms the state-of-the-art by\nover 27% and closely matches the optimum.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14346v1",
    "published_date": "2024-02-22 07:24:26 UTC",
    "updated_date": "2024-02-22 07:24:26 UTC"
  },
  {
    "arxiv_id": "2402.14335v1",
    "title": "HyperFast: Instant Classification for Tabular Data",
    "authors": [
      "David Bonet",
      "Daniel Mas Montserrat",
      "Xavier Giró-i-Nieto",
      "Alexander G. Ioannidis"
    ],
    "abstract": "Training deep learning models and performing hyperparameter tuning can be\ncomputationally demanding and time-consuming. Meanwhile, traditional machine\nlearning methods like gradient-boosting algorithms remain the preferred choice\nfor most tabular data applications, while neural network alternatives require\nextensive hyperparameter tuning or work only in toy datasets under limited\nsettings. In this paper, we introduce HyperFast, a meta-trained hypernetwork\ndesigned for instant classification of tabular data in a single forward pass.\nHyperFast generates a task-specific neural network tailored to an unseen\ndataset that can be directly used for classification inference, removing the\nneed for training a model. We report extensive experiments with OpenML and\ngenomic data, comparing HyperFast to competing tabular data neural networks,\ntraditional ML methods, AutoML systems, and boosting machines. HyperFast shows\nhighly competitive results, while being significantly faster. Additionally, our\napproach demonstrates robust adaptability across a variety of classification\ntasks with little to no fine-tuning, positioning HyperFast as a strong solution\nfor numerous applications and rapid model deployment. HyperFast introduces a\npromising paradigm for fast classification, with the potential to substantially\ndecrease the computational burden of deep learning. Our code, which offers a\nscikit-learn-like interface, along with the trained HyperFast model, can be\nfound at https://github.com/AI-sandbox/HyperFast.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures, AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14335v1",
    "published_date": "2024-02-22 07:07:16 UTC",
    "updated_date": "2024-02-22 07:07:16 UTC"
  },
  {
    "arxiv_id": "2402.14323v2",
    "title": "REPOFUSE: Repository-Level Code Completion with Fused Dual Context",
    "authors": [
      "Ming Liang",
      "Xiaoheng Xie",
      "Gehao Zhang",
      "Xunjin Zheng",
      "Peng Di",
      "wei jiang",
      "Hongwei Chen",
      "Chengpeng Wang",
      "Gang Fan"
    ],
    "abstract": "The success of language models in code assistance has spurred the proposal of\nrepository-level code completion as a means to enhance prediction accuracy,\nutilizing the context from the entire codebase. However, this amplified context\ncan inadvertently increase inference latency, potentially undermining the\ndeveloper experience and deterring tool adoption - a challenge we termed the\nContext-Latency Conundrum. This paper introduces REPOFUSE, a pioneering\nsolution designed to enhance repository-level code completion without the\nlatency trade-off. REPOFUSE uniquely fuses two types of context: the analogy\ncontext, rooted in code analogies, and the rationale context, which encompasses\nin-depth semantic relationships. We propose a novel rank truncated generation\n(RTG) technique that efficiently condenses these contexts into prompts with\nrestricted size. This enables REPOFUSE to deliver precise code completions\nwhile maintaining inference efficiency. Through testing with the CrossCodeEval\nsuite, REPOFUSE has demonstrated a significant leap over existing models,\nachieving a 40.90% to 59.75% increase in exact match (EM) accuracy for code\ncompletions and a 26.8% enhancement in inference speed. Beyond experimental\nvalidation, REPOFUSE has been integrated into the workflow of a large\nenterprise, where it actively supports various coding tasks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14323v2",
    "published_date": "2024-02-22 06:34:50 UTC",
    "updated_date": "2024-02-23 02:53:20 UTC"
  },
  {
    "arxiv_id": "2402.14320v6",
    "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering",
    "authors": [
      "Chang Zong",
      "Yuchen Yan",
      "Weiming Lu",
      "Jian Shao",
      "Eliot Huang",
      "Heng Chang",
      "Yueting Zhuang"
    ],
    "abstract": "Recent progress with LLM-based agents has shown promising results across\nvarious tasks. However, their use in answering questions from knowledge bases\nremains largely unexplored. Implementing a KBQA system using traditional\nmethods is challenging due to the shortage of task-specific training data and\nthe complexity of creating task-focused model structures. In this paper, we\npresent Triad, a unified framework that utilizes an LLM-based agent with three\nroles for KBQA tasks. The agent is assigned three roles to tackle different\nKBQA subtasks: agent as a generalist for mastering various subtasks, as a\ndecision maker for the selection of candidates, and as an advisor for answering\nquestions with knowledge. Our KBQA framework is executed in four phases,\ninvolving the collaboration of the agent's multiple roles. We evaluated the\nperformance of our framework using three benchmark datasets, and the results\nshow that our framework outperforms state-of-the-art systems on the LC-QuAD and\nYAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.14320v6",
    "published_date": "2024-02-22 06:23:37 UTC",
    "updated_date": "2024-09-29 02:41:12 UTC"
  },
  {
    "arxiv_id": "2402.15444v1",
    "title": "Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion",
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to predict the missing\ntriples in the multi-modal knowledge graphs by incorporating structural,\nvisual, and textual information of entities into the discriminant models. The\ninformation from different modalities will work together to measure the triple\nplausibility. Existing MMKGC methods overlook the imbalance problem of modality\ninformation among entities, resulting in inadequate modal fusion and\ninefficient utilization of the raw modality information. To address the\nmentioned problems, we propose Adaptive Multi-modal Fusion and Modality\nAdversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality\ninformation for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive\nmodality weights and further generates adversarial samples by\nmodality-adversarial training to enhance the imbalanced modality information.\nOur approach is a co-design of the MMKGC model and training strategy which can\noutperform 19 recent MMKGC methods and achieve new state-of-the-art results on\nthree public MMKGC benchmarks. Our code and data have been released at\nhttps://github.com/zjukg/AdaMF-MAT.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.15444v1",
    "published_date": "2024-02-22 05:48:03 UTC",
    "updated_date": "2024-02-22 05:48:03 UTC"
  },
  {
    "arxiv_id": "2402.14304v2",
    "title": "Vision-Language Navigation with Embodied Intelligence: A Survey",
    "authors": [
      "Peng Gao",
      "Peng Wang",
      "Feng Gao",
      "Fei Wang",
      "Ruyue Yuan"
    ],
    "abstract": "As a long-term vision in the field of artificial intelligence, the core goal\nof embodied intelligence is to improve the perception, understanding, and\ninteraction capabilities of agents and the environment. Vision-language\nnavigation (VLN), as a critical research path to achieve embodied intelligence,\nfocuses on exploring how agents use natural language to communicate effectively\nwith humans, receive and understand instructions, and ultimately rely on visual\ninformation to achieve accurate navigation. VLN integrates artificial\nintelligence, natural language processing, computer vision, and robotics. This\nfield faces technical challenges but shows potential for application such as\nhuman-computer interaction. However, due to the complex process involved from\nlanguage understanding to action execution, VLN faces the problem of aligning\nvisual information and language instructions, improving generalization ability,\nand many other challenges. This survey systematically reviews the research\nprogress of VLN and details the research direction of VLN with embodied\nintelligence. After a detailed summary of its system architecture and research\nbased on methods and commonly used benchmark datasets, we comprehensively\nanalyze the problems and challenges faced by current research and explore the\nfuture development direction of this field, aiming to provide a practical\nreference for researchers.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "The pictures in Figures 2, 4, and 5 are used without authorization,\n  and the literatures in Table 1 have been cited improperly",
    "pdf_url": "http://arxiv.org/pdf/2402.14304v2",
    "published_date": "2024-02-22 05:45:17 UTC",
    "updated_date": "2024-03-15 12:31:35 UTC"
  },
  {
    "arxiv_id": "2402.14299v1",
    "title": "We Choose to Go to Space: Agent-driven Human and Multi-Robot Collaboration in Microgravity",
    "authors": [
      "Miao Xin",
      "Zhongrui You",
      "Zihan Zhang",
      "Taoran Jiang",
      "Tingjia Xu",
      "Haotian Liang",
      "Guojing Ge",
      "Yuchen Ji",
      "Shentong Mo",
      "Jian Cheng"
    ],
    "abstract": "We present SpaceAgents-1, a system for learning human and multi-robot\ncollaboration (HMRC) strategies under microgravity conditions. Future space\nexploration requires humans to work together with robots. However, acquiring\nproficient robot skills and adept collaboration under microgravity conditions\nposes significant challenges within ground laboratories. To address this issue,\nwe develop a microgravity simulation environment and present three typical\nconfigurations of intra-cabin robots. We propose a hierarchical heterogeneous\nmulti-agent collaboration architecture: guided by foundation models, a\nDecision-Making Agent serves as a task planner for human-robot collaboration,\nwhile individual Skill-Expert Agents manage the embodied control of robots.\nThis mechanism empowers the SpaceAgents-1 system to execute a range of\nintricate long-horizon HMRC tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14299v1",
    "published_date": "2024-02-22 05:32:27 UTC",
    "updated_date": "2024-02-22 05:32:27 UTC"
  },
  {
    "arxiv_id": "2402.14883v3",
    "title": "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
    "authors": [
      "Shen Li",
      "Liuyi Yao",
      "Jinyang Gao",
      "Lan Zhang",
      "Yaliang Li"
    ],
    "abstract": "To support various applications, a prevalent and efficient approach for\nbusiness owners is leveraging their valuable datasets to fine-tune a\npre-trained LLM through the API provided by LLM owners or cloud servers.\nHowever, this process carries a substantial risk of model misuse, potentially\nresulting in severe economic consequences for business owners. Thus,\nsafeguarding the copyright of these customized models during LLM fine-tuning\nhas become an urgent practical requirement, but there are limited existing\nsolutions to provide such protection. To tackle this pressing issue, we propose\na novel watermarking approach named ``Double-I watermark''. Specifically, based\non the instruct-tuning data, two types of backdoor data paradigms are\nintroduced with trigger in the instruction and the input, respectively. By\nleveraging LLM's learning capability to incorporate customized backdoor samples\ninto the dataset, the proposed approach effectively injects specific\nwatermarking information into the customized model during fine-tuning, which\nmakes it easy to inject and verify watermarks in commercial scenarios. We\nevaluate the proposed \"Double-I watermark\" under various fine-tuning methods,\ndemonstrating its harmlessness, robustness, uniqueness, imperceptibility, and\nvalidity through both quantitative and qualitative analyses.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14883v3",
    "published_date": "2024-02-22 04:55:14 UTC",
    "updated_date": "2024-06-05 11:30:02 UTC"
  },
  {
    "arxiv_id": "2402.14279v3",
    "title": "Mitigating the Linguistic Gap with Phonemic Representations for Robust Cross-lingual Transfer",
    "authors": [
      "Haeji Jung",
      "Changdae Oh",
      "Jooeon Kang",
      "Jimin Sohn",
      "Kyungwoo Song",
      "Jinkyu Kim",
      "David R. Mortensen"
    ],
    "abstract": "Approaches to improving multilingual language understanding often struggle\nwith significant performance gaps between high-resource and low-resource\nlanguages. While there are efforts to align the languages in a single latent\nspace to mitigate such gaps, how different input-level representations\ninfluence such gaps has not been investigated, particularly with phonemic\ninputs. We hypothesize that the performance gaps are affected by representation\ndiscrepancies between these languages, and revisit the use of phonemic\nrepresentations as a means to mitigate these discrepancies. To demonstrate the\neffectiveness of phonemic representations, we present experiments on three\nrepresentative cross-lingual tasks on 12 languages in total. The results show\nthat phonemic representations exhibit higher similarities between languages\ncompared to orthographic representations, and it consistently outperforms\ngrapheme-based baseline model on languages that are relatively low-resourced.\nWe present quantitative evidence from three cross-lingual tasks that\ndemonstrate the effectiveness of phonemic representations, and it is further\njustified by a theoretical analysis of the cross-lingual performance gap.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the 4th Multilingual Representation Learning (MRL)\n  Workshop (co-located with EMNLP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.14279v3",
    "published_date": "2024-02-22 04:41:52 UTC",
    "updated_date": "2024-11-15 17:11:08 UTC"
  },
  {
    "arxiv_id": "2402.14277v1",
    "title": "GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages",
    "authors": [
      "Spencer Rarrick",
      "Ranjita Naik",
      "Sundar Poudel",
      "Vishal Chowdhary"
    ],
    "abstract": "Neural Machine Translation (NMT) continues to improve in quality and\nadoption, yet the inadvertent perpetuation of gender bias remains a significant\nconcern. Despite numerous studies on gender bias in translations into English\nfrom weakly gendered-languages, there are no benchmarks for evaluating this\nphenomenon or for assessing mitigation strategies. To address this gap, we\nintroduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus,\nthat consists of human translations from Turkish, Hungarian, Finnish, and\nPersian into English. Each translation is accompanied by feminine, masculine,\nand neutral variants. The dataset, which contains between 1250 and 1850\ninstances for each of the four language pairs, features natural sentences with\na wide range of sentence lengths and domains, challenging translation rewriters\non various linguistic phenomena. Additionally, we present a translation gender\nrewriting solution built with GPT-4 and use GATE X-E to evaluate it. We open\nsource our contributions to encourage further research on gender debiasing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2311.08836",
    "pdf_url": "http://arxiv.org/pdf/2402.14277v1",
    "published_date": "2024-02-22 04:36:14 UTC",
    "updated_date": "2024-02-22 04:36:14 UTC"
  },
  {
    "arxiv_id": "2402.14268v1",
    "title": "Can Large Language Models Detect Misinformation in Scientific News Reporting?",
    "authors": [
      "Yupeng Cao",
      "Aishwarya Muralidharan Nair",
      "Elyon Eyimife",
      "Nastaran Jamalipour Soofi",
      "K. P. Subbalakshmi",
      "John R. Wullert II",
      "Chumki Basu",
      "David Shallcross"
    ],
    "abstract": "Scientific facts are often spun in the popular press with the intent to\ninfluence public opinion and action, as was evidenced during the COVID-19\npandemic. Automatic detection of misinformation in the scientific domain is\nchallenging because of the distinct styles of writing in these two media types\nand is still in its nascence. Most research on the validity of scientific\nreporting treats this problem as a claim verification challenge. In doing so,\nsignificant expert human effort is required to generate appropriate claims. Our\nsolution bypasses this step and addresses a more real-world scenario where such\nexplicit, labeled claims may not be available. The central research question of\nthis paper is whether it is possible to use large language models (LLMs) to\ndetect misinformation in scientific reporting. To this end, we first present a\nnew labeled dataset SciNews, containing 2.4k scientific news stories drawn from\ntrusted and untrustworthy sources, paired with related abstracts from the\nCORD-19 database. Our dataset includes both human-written and LLM-generated\nnews articles, making it more comprehensive in terms of capturing the growing\ntrend of using LLMs to generate popular press articles. Then, we identify\ndimensions of scientific validity in science news articles and explore how this\ncan be integrated into the automated detection of scientific misinformation. We\npropose several baseline architectures using LLMs to automatically detect false\nrepresentations of scientific findings in the popular press. For each of these\narchitectures, we use several prompt engineering strategies including\nzero-shot, few-shot, and chain-of-thought prompting. We also test these\narchitectures and prompting strategies on GPT-3.5, GPT-4, and Llama2-7B,\nLlama2-13B.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14268v1",
    "published_date": "2024-02-22 04:07:00 UTC",
    "updated_date": "2024-02-22 04:07:00 UTC"
  },
  {
    "arxiv_id": "2402.14261v1",
    "title": "Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming",
    "authors": [
      "Anisha Agarwal",
      "Aaron Chan",
      "Shubham Chandel",
      "Jinu Jang",
      "Shaun Miller",
      "Roshanak Zilouchian Moghaddam",
      "Yevhen Mohylevskyy",
      "Neel Sundaresan",
      "Michele Tufano"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into Development Environments\n(IDEs) has become a focal point in modern software development. LLMs such as\nOpenAI GPT-3.5/4 and Code Llama offer the potential to significantly augment\ndeveloper productivity by serving as intelligent, chat-driven programming\nassistants. However, utilizing LLMs out of the box is unlikely to be optimal\nfor any given scenario. Rather, each system requires the LLM to be honed to its\nset of heuristics to ensure the best performance. In this paper, we introduce\nthe Copilot evaluation harness: a set of data and tools for evaluating\nLLM-guided IDE interactions, covering various programming scenarios and\nlanguages. We propose our metrics as a more robust and information-dense\nevaluation than previous state of the art evaluation systems. We design and\ncompute both static and execution based success metrics for scenarios\nencompassing a wide range of developer tasks, including code generation from\nnatural language (generate), documentation generation from code (doc), test\ncase generation (test), bug-fixing (fix), and workspace understanding and query\nresolution (workspace). These success metrics are designed to evaluate the\nperformance of LLMs within a given IDE and its respective parameter space. Our\nlearnings from evaluating three common LLMs using these metrics can inform the\ndevelopment and validation of future scenarios in LLM guided IDEs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14261v1",
    "published_date": "2024-02-22 03:51:34 UTC",
    "updated_date": "2024-02-22 03:51:34 UTC"
  },
  {
    "arxiv_id": "2402.14259v2",
    "title": "Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond",
    "authors": [
      "Zhiyuan Wang",
      "Jinhao Duan",
      "Chenxi Yuan",
      "Qingyu Chen",
      "Tianlong Chen",
      "Yue Zhang",
      "Ren Wang",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "abstract": "Uncertainty estimation is crucial for the reliability of safety-critical\nhuman and artificial intelligence (AI) interaction systems, particularly in the\ndomain of healthcare engineering. However, a robust and general uncertainty\nmeasure for free-form answers has not been well-established in open-ended\nmedical question-answering (QA) tasks, where generative inequality introduces a\nlarge number of irrelevant words and sequences within the generated set for\nuncertainty quantification (UQ), which can lead to biases. This paper\nintroduces Word-Sequence Entropy (WSE), a method that calibrates uncertainty at\nboth the word and sequence levels, considering semantic relevance. WSE\nquantifies uncertainty in a way that is more closely aligned with the\nreliability of LLMs during uncertainty quantification (UQ). We compare WSE with\nsix baseline methods on five free-form medical QA datasets, utilizing seven\npopular large language models (LLMs). Experimental results demonstrate that WSE\nexhibits superior performance in UQ under two standard criteria for correctness\nevaluation. Additionally, in terms of real-world medical QA applications, the\nperformance of LLMs is significantly enhanced (e.g., a 6.36% improvement in\nmodel accuracy on the COVID-QA dataset) by employing responses with lower\nuncertainty that are identified by WSE as final answers, without any additional\ntask-specific fine-tuning or architectural modifications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by Engineering Applications of Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2402.14259v2",
    "published_date": "2024-02-22 03:46:08 UTC",
    "updated_date": "2024-11-18 09:19:25 UTC"
  },
  {
    "arxiv_id": "2402.14882v1",
    "title": "Deep Generative Model-based Synthesis of Four-bar Linkage Mechanisms with Target Conditions",
    "authors": [
      "Sumin Lee",
      "Jihoon Kim",
      "Namwoo Kang"
    ],
    "abstract": "Mechanisms are essential components designed to perform specific tasks in\nvarious mechanical systems. However, designing a mechanism that satisfies\ncertain kinematic or quasi-static requirements is a challenging task. The\nkinematic requirements may include the workspace of a mechanism, while the\nquasi-static requirements of a mechanism may include its torque transmission,\nwhich refers to the ability of the mechanism to transfer power and torque\neffectively. In this paper, we propose a deep learning-based generative model\nfor generating multiple crank-rocker four-bar linkage mechanisms that satisfy\nboth the kinematic and quasi-static requirements aforementioned. The proposed\nmodel is based on a conditional generative adversarial network (cGAN) with\nmodifications for mechanism synthesis, which is trained to learn the\nrelationship between the requirements of a mechanism with respect to linkage\nlengths. The results demonstrate that the proposed model successfully generates\nmultiple distinct mechanisms that satisfy specific kinematic and quasi-static\nrequirements. To evaluate the novelty of our approach, we provide a comparison\nof the samples synthesized by the proposed cGAN, traditional cVAE and NSGA-II.\nOur approach has several advantages over traditional design methods. It enables\ndesigners to efficiently generate multiple diverse and feasible design\ncandidates while exploring a large design space. Also, the proposed model\nconsiders both the kinematic and quasi-static requirements, which can lead to\nmore efficient and effective mechanisms for real-world use, making it a\npromising tool for linkage mechanism design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14882v1",
    "published_date": "2024-02-22 03:31:00 UTC",
    "updated_date": "2024-02-22 03:31:00 UTC"
  },
  {
    "arxiv_id": "2403.00790v2",
    "title": "Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations",
    "authors": [
      "Tofara Moyo"
    ],
    "abstract": "In this paper, we explore the intriguing similarities between the structure\nof a discrete neural network, such as a spiking network, and the composition of\na piano piece. While both involve nodes or notes that are activated\nsequentially or in parallel, the latter benefits from the rich body of music\ntheory to guide meaningful combinations. We propose a novel approach that\nleverages musical grammar to regulate activations in a spiking neural network,\nallowing for the representation of symbols as attractors. By applying rules for\nchord progressions from music theory, we demonstrate how certain activations\nnaturally follow others, akin to the concept of attraction. Furthermore, we\nintroduce the concept of modulating keys to navigate different basins of\nattraction within the network. Ultimately, we show that the map of concepts in\nour model is structured by the musical circle of fifths, highlighting the\npotential for leveraging music theory principles in deep learning algorithms.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "3 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.00790v2",
    "published_date": "2024-02-22 03:28:25 UTC",
    "updated_date": "2024-10-24 14:14:04 UTC"
  },
  {
    "arxiv_id": "2402.14245v1",
    "title": "Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models",
    "authors": [
      "Jinyi Liu",
      "Yifu Yuan",
      "Jianye Hao",
      "Fei Ni",
      "Lingzhi Fu",
      "Yibin Chen",
      "Yan Zheng"
    ],
    "abstract": "Recently, there has been considerable attention towards leveraging large\nlanguage models (LLMs) to enhance decision-making processes. However, aligning\nthe natural language text instructions generated by LLMs with the vectorized\noperations required for execution presents a significant challenge, often\nnecessitating task-specific details. To circumvent the need for such\ntask-specific granularity, inspired by preference-based policy learning\napproaches, we investigate the utilization of multimodal LLMs to provide\nautomated preference feedback solely from image inputs to guide\ndecision-making. In this study, we train a multimodal LLM, termed CriticGPT,\ncapable of understanding trajectory videos in robot manipulation tasks, serving\nas a critic to offer analysis and preference feedback. Subsequently, we\nvalidate the effectiveness of preference labels generated by CriticGPT from a\nreward modeling perspective. Experimental evaluation of the algorithm's\npreference accuracy demonstrates its effective generalization ability to new\ntasks. Furthermore, performance on Meta-World tasks reveals that CriticGPT's\nreward model efficiently guides policy learning, surpassing rewards based on\nstate-of-the-art pre-trained representation models.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Presented at AAAI 2024 RL+LLMs Workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.14245v1",
    "published_date": "2024-02-22 03:14:03 UTC",
    "updated_date": "2024-02-22 03:14:03 UTC"
  },
  {
    "arxiv_id": "2402.14244v2",
    "title": "MENTOR: Guiding Hierarchical Reinforcement Learning with Human Feedback and Dynamic Distance Constraint",
    "authors": [
      "Xinglin Zhou",
      "Yifu Yuan",
      "Shaofu Yang",
      "Jianye Hao"
    ],
    "abstract": "Hierarchical reinforcement learning (HRL) provides a promising solution for\ncomplex tasks with sparse rewards of intelligent agents, which uses a\nhierarchical framework that divides tasks into subgoals and completes them\nsequentially. However, current methods struggle to find suitable subgoals for\nensuring a stable learning process. Without additional guidance, it is\nimpractical to rely solely on exploration or heuristics methods to determine\nsubgoals in a large goal space. To address the issue, We propose a general\nhierarchical reinforcement learning framework incorporating human feedback and\ndynamic distance constraints (MENTOR). MENTOR acts as a \"mentor\", incorporating\nhuman feedback into high-level policy learning, to find better subgoals. As for\nlow-level policy, MENTOR designs a dual policy for exploration-exploitation\ndecoupling respectively to stabilize the training. Furthermore, although humans\ncan simply break down tasks into subgoals to guide the right learning\ndirection, subgoals that are too difficult or too easy can still hinder\ndownstream learning efficiency. We propose the Dynamic Distance Constraint\n(DDC) mechanism dynamically adjusting the space of optional subgoals. Thus\nMENTOR can generate subgoals matching the low-level policy learning process\nfrom easy to hard. Extensive experiments demonstrate that MENTOR uses a small\namount of human feedback to achieve significant improvement in complex tasks\nwith sparse rewards.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in IEEE Transactions on Emerging Topics in\n  Computational Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2402.14244v2",
    "published_date": "2024-02-22 03:11:09 UTC",
    "updated_date": "2024-11-27 13:27:41 UTC"
  },
  {
    "arxiv_id": "2402.14241v1",
    "title": "A Self-supervised Pressure Map human keypoint Detection Approch: Optimizing Generalization and Computational Efficiency Across Datasets",
    "authors": [
      "Chengzhang Yu",
      "Xianjun Yang",
      "Wenxia Bao",
      "Shaonan Wang",
      "Zhiming Yao"
    ],
    "abstract": "In environments where RGB images are inadequate, pressure maps is a viable\nalternative, garnering scholarly attention. This study introduces a novel\nself-supervised pressure map keypoint detection (SPMKD) method, addressing the\ncurrent gap in specialized designs for human keypoint extraction from pressure\nmaps. Central to our contribution is the Encoder-Fuser-Decoder (EFD) model,\nwhich is a robust framework that integrates a lightweight encoder for precise\nhuman keypoint detection, a fuser for efficient gradient propagation, and a\ndecoder that transforms human keypoints into reconstructed pressure maps. This\nstructure is further enhanced by the Classification-to-Regression Weight\nTransfer (CRWT) method, which fine-tunes accuracy through initial\nclassification task training. This innovation not only enhances human keypoint\ngeneralization without manual annotations but also showcases remarkable\nefficiency and generalization, evidenced by a reduction to only $5.96\\%$ in\nFLOPs and $1.11\\%$ in parameter count compared to the baseline methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5pages, 6figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14241v1",
    "published_date": "2024-02-22 02:54:43 UTC",
    "updated_date": "2024-02-22 02:54:43 UTC"
  },
  {
    "arxiv_id": "2402.14236v2",
    "title": "Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning",
    "authors": [
      "Peng Gao",
      "Tao Yu",
      "Fei Wang",
      "Ru-Yue Yuan"
    ],
    "abstract": "Designing distributed filter circuits (DFCs) is complex and time-consuming,\ninvolving setting and optimizing multiple hyperparameters. Traditional\noptimization methods, such as using the commercial finite element solver HFSS\n(High-Frequency Structure Simulator) to enumerate all parameter combinations\nwith fixed steps and then simulate each combination, are not only\ntime-consuming and labor-intensive but also rely heavily on the expertise and\nexperience of electronics engineers, making it difficult to adapt to rapidly\nchanging design requirements. Additionally, these commercial tools struggle\nwith precise adjustments when parameters are sensitive to numerical changes,\nresulting in limited optimization effectiveness. This study proposes a novel\nend-to-end automated method for DFC design. The proposed method harnesses\nreinforcement learning (RL) algorithms, eliminating the dependence on the\ndesign experience of engineers. Thus, it significantly reduces the subjectivity\nand constraints associated with circuit design. The experimental findings\ndemonstrate clear improvements in design efficiency and quality when comparing\nthe proposed method with traditional engineer-driven methods. Furthermore, the\nproposed method achieves superior performance when designing complex or rapidly\nevolving DFCs, highlighting the substantial potential of RL in circuit design\nautomation. In particular, compared to the existing DFC automation design\nmethod CircuitGNN, our method achieves an average performance improvement of\n8.72%. Additionally, the execution efficiency of our method is 2000 times\nhigher than CircuitGNN on the CPU and 241 times higher on the GPU.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14236v2",
    "published_date": "2024-02-22 02:36:14 UTC",
    "updated_date": "2024-07-29 02:34:20 UTC"
  },
  {
    "arxiv_id": "2402.14230v2",
    "title": "MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems",
    "authors": [
      "Lichi Li",
      "Zainul Abi Din",
      "Zhen Tan",
      "Sam London",
      "Tianlong Chen",
      "Ajay Daptardar"
    ],
    "abstract": "In the evolving e-commerce field, recommendation systems crucially shape user\nexperience and engagement. The rise of Consumer-to-Consumer (C2C)\nrecommendation systems, noted for their flexibility and ease of access for\ncustomer vendors, marks a significant trend. However, the academic focus\nremains largely on Business-to-Consumer (B2C) models, leaving a gap filled by\nthe limited C2C recommendation datasets that lack in item attributes, user\ndiversity, and scale. The intricacy of C2C recommendation systems is further\naccentuated by the dual roles users assume as both sellers and buyers,\nintroducing a spectrum of less uniform and varied inputs. Addressing this, we\nintroduce MerRec, the first large-scale dataset specifically for C2C\nrecommendations, sourced from the Mercari e-commerce platform, covering\nmillions of users and products over 6 months in 2023. MerRec not only includes\nstandard features such as user_id, item_id, and session_id, but also unique\nelements like timestamped action types, product taxonomy, and textual product\nattributes, offering a comprehensive dataset for research. This dataset,\nextensively evaluated across four recommendation tasks, establishes a new\nbenchmark for the development of advanced recommendation algorithms in\nreal-world scenarios, bridging the gap between academia and industry and\npropelling the study of C2C recommendations. Our experiment code is available\nat https://github.com/mercari/mercari-ml-merrec-pub-us and dataset at\nhttps://huggingface.co/datasets/mercari-us/merrec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Dataset available at:\n  https://huggingface.co/datasets/mercari-us/merrec, code available at:\n  https://github.com/mercari/mercari-ml-merrec-pub-us",
    "pdf_url": "http://arxiv.org/pdf/2402.14230v2",
    "published_date": "2024-02-22 02:21:59 UTC",
    "updated_date": "2024-07-17 01:09:31 UTC"
  },
  {
    "arxiv_id": "2402.14228v3",
    "title": "COPR: Continual Human Preference Learning via Optimal Policy Regularization",
    "authors": [
      "Han Zhang",
      "Lin Gui",
      "Yu Lei",
      "Yuanzhao Zhai",
      "Yehong Zhang",
      "Yulan He",
      "Hui Wang",
      "Yue Yu",
      "Kam-Fai Wong",
      "Bin Liang",
      "Ruifeng Xu"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to\nimprove the alignment of Large Language Models (LLMs) with human preferences.\nGiven the evolving nature of human preferences, continual alignment becomes\nmore crucial and practical in comparison to traditional static alignment.\nNevertheless, making RLHF compatible with Continual Learning (CL) is\nchallenging due to its complex process. Meanwhile, directly learning new human\npreferences may lead to Catastrophic Forgetting (CF) of historical preferences,\nresulting in helpless or harmful outputs. To overcome these challenges, we\npropose the Continual Optimal Policy Regularization (COPR) method, which draws\ninspiration from the optimal policy theory. COPR utilizes a sampling\ndistribution as a demonstration and regularization constraints for CL. It\nadopts the Lagrangian Duality (LD) method to dynamically regularize the current\npolicy based on the historically optimal policy, which prevents CF and avoids\nover-emphasizing unbalanced objectives. We also provide formal proof for the\nlearnability of COPR. The experimental results show that COPR outperforms\nstrong CL baselines on our proposed benchmark, in terms of reward-based, GPT-4\nevaluations and human assessment. Furthermore, we validate the robustness of\nCOPR under various CL settings, including different backbones, replay memory\nsizes, and learning orders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This is a duplicate submission to arXiv:2310.15694, and we believe\n  that this submission has affected the citation of our original paper\n  arXiv:2310.15694",
    "pdf_url": "http://arxiv.org/pdf/2402.14228v3",
    "published_date": "2024-02-22 02:20:08 UTC",
    "updated_date": "2024-12-21 02:55:16 UTC"
  },
  {
    "arxiv_id": "2402.14212v1",
    "title": "Moonwalk: Inverse-Forward Differentiation",
    "authors": [
      "Dmitrii Krylov",
      "Armin Karamzade",
      "Roy Fox"
    ],
    "abstract": "Backpropagation, while effective for gradient computation, falls short in\naddressing memory consumption, limiting scalability. This work explores\nforward-mode gradient computation as an alternative in invertible networks,\nshowing its potential to reduce the memory footprint without substantial\ndrawbacks. We introduce a novel technique based on a vector-inverse-Jacobian\nproduct that accelerates the computation of forward gradients while retaining\nthe advantages of memory reduction and preserving the fidelity of true\ngradients. Our method, Moonwalk, has a time complexity linear in the depth of\nthe network, unlike the quadratic time complexity of na\\\"ive forward, and\nempirically reduces computation time by several orders of magnitude without\nallocating more memory. We further accelerate Moonwalk by combining it with\nreverse-mode differentiation to achieve time complexity comparable with\nbackpropagation while maintaining a much smaller memory footprint. Finally, we\nshowcase the robustness of our method across several architecture choices.\nMoonwalk is the first forward-based method to compute true gradients in\ninvertible networks in computation time comparable to backpropagation and using\nsignificantly less memory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14212v1",
    "published_date": "2024-02-22 01:33:31 UTC",
    "updated_date": "2024-02-22 01:33:31 UTC"
  },
  {
    "arxiv_id": "2402.14208v3",
    "title": "LLM-Assisted Content Conditional Debiasing for Fair Text Embedding",
    "authors": [
      "Wenlong Deng",
      "Blair Chen",
      "Beidi Zhao",
      "Chiyu Zhang",
      "Xiaoxiao Li",
      "Christos Thrampoulidis"
    ],
    "abstract": "Mitigating biases in machine learning models has become an increasing concern\nin Natural Language Processing (NLP), particularly in developing fair text\nembeddings, which are crucial yet challenging for real-world applications like\nsearch engines. In response, this paper proposes a novel method for learning\nfair text embeddings. First, we define a novel content-conditional equal\ndistance (CCED) fairness for text embeddings, ensuring content-conditional\nindependence between sensitive attributes and text embeddings. Building on\nCCED, we introduce a content-conditional debiasing (CCD) loss to ensure that\nembeddings of texts with different sensitive attributes but identical content\nmaintain the same distance from the embedding of their corresponding neutral\ntext. Additionally, we tackle the issue of insufficient training data by using\nLarge Language Models (LLMs) with instructions to fairly augment texts into\ndifferent sensitive groups. Our extensive evaluations show that our approach\neffectively enhances fairness while maintaining the utility of embeddings.\nFurthermore, our augmented dataset, combined with the CCED metric, serves as an\nnew benchmark for evaluating fairness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14208v3",
    "published_date": "2024-02-22 01:20:51 UTC",
    "updated_date": "2024-06-24 04:49:16 UTC"
  },
  {
    "arxiv_id": "2402.14207v2",
    "title": "Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models",
    "authors": [
      "Yijia Shao",
      "Yucheng Jiang",
      "Theodore A. Kanell",
      "Peter Xu",
      "Omar Khattab",
      "Monica S. Lam"
    ],
    "abstract": "We study how to apply large language models to write grounded and organized\nlong-form articles from scratch, with comparable breadth and depth to Wikipedia\npages. This underexplored problem poses new challenges at the pre-writing\nstage, including how to research the topic and prepare an outline prior to\nwriting. We propose STORM, a writing system for the Synthesis of Topic Outlines\nthrough Retrieval and Multi-perspective Question Asking. STORM models the\npre-writing stage by (1) discovering diverse perspectives in researching the\ngiven topic, (2) simulating conversations where writers carrying different\nperspectives pose questions to a topic expert grounded on trusted Internet\nsources, (3) curating the collected information to create an outline.\n  For evaluation, we curate FreshWiki, a dataset of recent high-quality\nWikipedia articles, and formulate outline assessments to evaluate the\npre-writing stage. We further gather feedback from experienced Wikipedia\neditors. Compared to articles generated by an outline-driven\nretrieval-augmented baseline, more of STORM's articles are deemed to be\norganized (by a 25% absolute increase) and broad in coverage (by 10%). The\nexpert feedback also helps identify new challenges for generating grounded long\narticles, such as source bias transfer and over-association of unrelated facts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, NAACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2402.14207v2",
    "published_date": "2024-02-22 01:20:17 UTC",
    "updated_date": "2024-04-08 05:38:50 UTC"
  },
  {
    "arxiv_id": "2402.14187v1",
    "title": "From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter",
    "authors": [
      "Yuhang Zhou",
      "Xuan Lu",
      "Wei Ai"
    ],
    "abstract": "In the rapidly evolving landscape of social media, the introduction of new\nemojis in Unicode release versions presents a structured opportunity to explore\ndigital language evolution. Analyzing a large dataset of sampled English\ntweets, we examine how newly released emojis gain traction and evolve in\nmeaning. We find that community size of early adopters and emoji semantics are\ncrucial in determining their popularity. Certain emojis experienced notable\nshifts in the meanings and sentiment associations during the diffusion process.\nAdditionally, we propose a novel framework utilizing language models to extract\nwords and pre-existing emojis with semantically similar contexts, which\nenhances interpretation of new emojis. The framework demonstrates its\neffectiveness in improving sentiment classification performance by substituting\nunknown new emojis with familiar ones. This study offers a new perspective in\nunderstanding how new language units are adopted, adapted, and integrated into\nthe fabric of online communication.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages, 3 page appendix",
    "pdf_url": "http://arxiv.org/pdf/2402.14187v1",
    "published_date": "2024-02-22 00:24:44 UTC",
    "updated_date": "2024-02-22 00:24:44 UTC"
  },
  {
    "arxiv_id": "2402.14182v1",
    "title": "Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization",
    "authors": [
      "Jiliang Li",
      "Yifan Zhang",
      "Zachary Karas",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ],
    "abstract": "Recent language models have demonstrated proficiency in summarizing source\ncode. However, as in many other domains of machine learning, language models of\ncode lack sufficient explainability. Informally, we lack a formulaic or\nintuitive understanding of what and how models learn from code. Explainability\nof language models can be partially provided if, as the models learn to produce\nhigher-quality code summaries, they also align in deeming the same code parts\nimportant as those identified by human programmers. In this paper, we report\nnegative results from our investigation of explainability of language models in\ncode summarization through the lens of human comprehension. We measure human\nfocus on code using eye-tracking metrics such as fixation counts and duration\nin code summarization tasks. To approximate language model focus, we employ a\nstate-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP\n(SHapley Additive exPlanations), to identify which code tokens influence that\ngeneration of summaries. Using these settings, we find no statistically\nsignificant relationship between language models' focus and human programmers'\nattention. Furthermore, alignment between model and human foci in this setting\ndoes not seem to dictate the quality of the LLM-generated summaries. Our study\nhighlights an inability to align human focus with SHAP-based model focus\nmeasures. This result calls for future investigation of multiple open questions\nfor explainable language models for code summarization and software engineering\ntasks in general, including the training mechanisms of language models for\ncode, whether there is an alignment between human and model attention on code,\nwhether human attention can improve the development of language models, and\nwhat other model focus measures are appropriate for improving explainability.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.14182v1",
    "published_date": "2024-02-22 00:01:02 UTC",
    "updated_date": "2024-02-22 00:01:02 UTC"
  }
]