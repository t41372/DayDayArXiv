{
  "date": "2025-02-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-25 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化（如 LLM 的推理和对齐）、多模态处理、安全性挑战，以及医疗和科学计算应用，其中 DeepSeek-R1 在科学计算和复杂推理任务中的表现尤为突出，同时 Michael I. Jordan 等著名学者参与的 LLM 综述值得关注。\n\n### 重点论文讨论\n今天共有 149 篇论文，我将优先讨论那些在 AI 安全、LLM 优化、医疗应用和图神经网络等领域具有话题度和影响力的文章，这些领域可能带来更广泛的学术和实际影响。其他较基础或小众论文（如某些优化算法或特定领域实验）将快速掠过，只提核心点。\n\n#### LLM 优化与对齐\n这些论文探讨了大型语言模型（LLMs）的性能提升、对齐策略和测试时间计算，DeepSeek-R1 的表现尤其引人注目。\n- **SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution**（中文：通过开源软件演化强化学习提升 LLM 推理能力；英文：SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution）  \n  主要贡献：提出 SWE-RL 框架，使用强化学习在软件演化数据上训练 LLM，实现弱到强的泛化提升。发现训练后模型在 SWE-bench Verified 数据集上达到 41.0% 的解决率，超越 GPT-4o，强调了 LLM 在软件工程中的实用性。\n  \n- **DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks**（中文：DeepSeek 与 ChatGPT 和 Claude 在科学计算和科学机器学习任务中的比较研究；英文：DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks）  \n  主要贡献：比较 DeepSeek、ChatGPT 和 Claude 在科学任务中的性能，DeepSeek-R1 表现出色，尤其在偏好优化版本中。发现 DeepSeek 在科学计算中优于其他模型，突出了其在复杂推理中的潜力。\n\n- **AgentRM: Enhancing Agent Generalization with Reward Modeling**（中文：通过奖励建模提升代理泛化能力的框架；英文：AgentRM: Enhancing Agent Generalization with Reward Modeling）  \n  主要贡献：引入奖励建模方法，帮助 LLM 代理在多任务环境中泛化，显著提升了在 SWE-bench Verified 等基准上的性能，平均提升 8.8%，展示了代理学习的鲁棒性。\n\n- **MAFE: Multi-Agent Fair Environments for Decision-Making Systems**（中文：多代理公平环境框架，用于决策系统的公平性研究；英文：MAFE: Multi-Agent Fair Environments for Decision-Making Systems）  \n  主要贡献：构建多代理公平环境，解决 AI 决策中的长期公平问题，实验显示在混合自治系统中提升了决策效率，Michael I. Jordan 等学者的参与增加了其学术影响力。\n\n- **An Overview of Large Language Models for Statisticians**（中文：面向统计学家的 LLM 综述；英文：An Overview of Large Language Models for Statisticians）  \n  主要贡献：Michael I. Jordan 参与的综述，讨论了 LLM 在统计学中的应用，如不确定性量化和社会公平，强调了统计方法在提升 LLM 可靠性的作用，是 LLM 领域的重要理论总结。\n\n其他 LLM 相关论文，如 \"Scaling LLM Pre-training with Vocabulary Curriculum\"，则快速掠过：该文提出词汇课程学习提升预训练效率，但影响较小，仅在小规模实验中显示改进。\n\n#### AI 安全与鲁棒性\nAI 安全是热门话题，这些论文揭示了 LLM 的漏洞并提出防护策略。\n- **MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks**（中文：通过局部和全局中毒攻击破坏多模态 RAG 的框架；英文：MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks）  \n  主要贡献：提出 MM-PoisonRAG 攻击框架，模拟知识中毒攻击，导致多模态 RAG 在 QA 任务中准确率降至 0%，并在 MultiModalQA 上达到 56% 成功率，突出了多模态系统的安全风险。\n\n- **AIR: Complex Instruction Generation via Automatic Iterative Refinement**（中文：通过自动迭代细化生成复杂指令的框架；英文：AIR: Complex Instruction Generation via Automatic Iterative Refinement）  \n  主要贡献：开发 AIR 框架，使用 LLM 迭代生成复杂指令，提高模型遵循能力的可扩展性，实验显示在真实场景中提升了指令质量。\n\n#### 医疗与生物应用\n医疗 AI 论文较多，以创新性和实际影响为优先。\n- **Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline**（中文：提升肝病临床试验效率的安全 LLM 预筛选管道；英文：Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline）  \n  主要贡献：提出安全 LLM 管道用于肝病试验预筛选，精度达 92.1%，显著减少手动筛选时间，实验验证了其在肝癌和肝硬化任务中的有效性。\n\n- **A graph neural network-based multispectral-view learning model for diabetic macular ischemia detection from color fundus photographs**（中文：基于图神经网络的多光谱视图学习模型，用于从彩色眼底照片检测糖尿病黄斑缺血；英文：A graph neural network-based multispectral-view learning model for diabetic macular ischemia detection from color fundus photographs）  \n  主要贡献：开发 GNN 模型结合多光谱图像检测黄斑缺血，AUROC 达 0.900，显著优于基线，展示了 AI 在眼科诊断中的潜力。\n\n其他医疗论文，如 ECG 分析方法，则快速掠过：它们改进检测精度（如 AUROC 提升），但多为技术优化，无重大突破。\n\n#### 图神经网络与多模态处理\n这些论文扩展了图学习和多模态应用。\n- **DeGEM: Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs**（中文：用于异质图节点分布外检测的解耦图能量模型；英文：DeGEM: Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs）  \n  主要贡献：提出 DeGEM 框架，提升异质图中 OOD 检测性能，AUROC 平均提升 20.29%，解决了传统 GNN 在异质环境中的局限。\n\n- **ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents**（中文：通过动态迭代推理代理的多模态文档检索增强生成；英文：ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents）  \n  主要贡献：构建 ViDoRAG 框架，提升多模态 RAG 在文档推理中的准确性，实验显示在 ViDoSeek 基准上提升 10%，强调了代理协作的重要性。\n\n其他图网络论文，如 \"GNN-XAR\"，则快速掠过：它使用 GNN 改进智能家居活动识别，但影响局限于特定应用。\n\n### 快速掠过其他论文\n剩余论文涉及量子计算、视频生成和优化算法等（如 \"Quantum Machine Learning in Precision Medicine\" 和 \"Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization\"），这些领域虽有创新（如量子模型在药物发现中的潜力），但整体影响力较小，或重复现有工作，因此仅简要提及：它们提供了技术改进，但未见重大突破。\n\n总之，今天的 arXiv 论文展示了 AI 在复杂任务中的潜力，特别是 LLM 的优化和医疗应用，但也暴露了安全隐患。感兴趣的读者可关注 DeepSeek-R1 和医疗 AI 方向的进展！如果有特定主题，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2503.01872v1",
      "title": "FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Mintong Kang",
        "Vinayshekhar Bannihatti Kumar",
        "Shamik Roy",
        "Abhishek Kumar",
        "Sopan Khosla",
        "Balakrishnan Murali Narayanaswamy",
        "Rashmi Gangadharaiah"
      ],
      "abstract": "Text-to-image diffusion models often exhibit biases toward specific\ndemographic groups, such as generating more males than females when prompted to\ngenerate images of engineers, raising ethical concerns and limiting their\nadoption. In this paper, we tackle the challenge of mitigating generation bias\ntowards any target attribute value (e.g., \"male\" for \"gender\") in diffusion\nmodels while preserving generation quality. We propose FairGen, an adaptive\nlatent guidance mechanism which controls the generation distribution during\ninference. In FairGen, a latent guidance module dynamically adjusts the\ndiffusion process to enforce specific attributes, while a memory module tracks\nthe generation statistics and steers latent guidance to align with the targeted\nfair distribution of the attribute values. Further, given the limitations of\nexisting datasets in comprehensively assessing bias in diffusion models, we\nintroduce a holistic bias evaluation benchmark HBE, covering diverse domains\nand incorporating complex prompts across various applications. Extensive\nevaluations on HBE and Stable Bias datasets demonstrate that FairGen\noutperforms existing bias mitigation approaches, achieving substantial bias\nreduction (e.g., 68.5% gender bias reduction on Stable Diffusion 2). Ablation\nstudies highlight FairGen's ability to flexibly and precisely control\ngeneration distribution at any user-specified granularity, ensuring adaptive\nand targeted bias mitigation.",
      "tldr_zh": "本论文提出 FairGen，一种自适应潜在指导机制，用于在 diffusion models 中减轻生成偏见（如性别偏见），同时保持图像生成质量。FairGen 通过潜在指导模块动态调整扩散过程以强制特定属性，并利用记忆模块跟踪生成统计数据，确保输出分布符合目标公平分布。此外，论文引入了一个全面的偏见评估基准 HBE，涵盖多样领域和复杂提示；在 HBE 和 Stable Bias 数据集上的实验显示，FairGen 比现有方法显著减少偏见（如 Stable Diffusion 2 中性别偏见降低 68.5%），并支持灵活的用户指定粒度控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under submission",
      "pdf_url": "http://arxiv.org/pdf/2503.01872v1",
      "published_date": "2025-02-25 23:47:22 UTC",
      "updated_date": "2025-02-25 23:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:31:38.616688"
    },
    {
      "arxiv_id": "2503.00043v2",
      "title": "VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Nilay Yilmaz",
        "Maitreya Patel",
        "Yiran Lawrence Luo",
        "Tejas Gokhale",
        "Chitta Baral",
        "Suren Jayasuriya",
        "Yezhou Yang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have become a powerful tool for\nintegrating visual and textual information. Despite their exceptional\nperformance on visual understanding benchmarks, measuring their ability to\nreason abstractly across multiple images remains a significant challenge. To\naddress this, we introduce VOILA, a large-scale, open-ended, dynamic benchmark\ndesigned to evaluate MLLMs' perceptual understanding and abstract relational\nreasoning. VOILA employs an analogical mapping approach in the visual domain,\nrequiring models to generate an image that completes an analogy between two\ngiven image pairs, reference and application, without relying on predefined\nchoices. Our experiments demonstrate that the analogical reasoning tasks in\nVOILA present a challenge to MLLMs. Through multi-step analysis, we reveal that\ncurrent MLLMs struggle to comprehend inter-image relationships and exhibit\nlimited capabilities in high-level relational reasoning. Notably, we observe\nthat performance improves when following a multi-step strategy of least-to-most\nprompting. Comprehensive evaluations on open-source models and GPT-4o show that\non text-based answers, the best accuracy for challenging scenarios is 13%\n(LLaMa 3.2) and even for simpler tasks is only 29% (GPT-4o), while human\nperformance is significantly higher at 70% across both difficulty levels.",
      "tldr_zh": "这篇论文引入了 VOILA，这是一个大型开放式动态基准，用于评估多模态大型语言模型 (MLLMs) 在感知理解和类比推理方面的能力。VOILA 通过视觉领域的类比映射方法，要求模型基于两个图像对（参考和应用）生成完成类比的图像，而不依赖预定义选项。实验发现，当前 MLLMs 在理解图像间关系和高层次关系推理上表现不佳，但采用 least-to-most prompting 的多步策略可改善性能。评估结果显示，开源模型如 LLaMa 3.2 在挑战任务中的准确率仅为 13%，而 GPT-4o 在简单任务上也只有 29%，远低于人类的 70%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025. Code and data: https://github.com/nlylmz/Voila",
      "pdf_url": "http://arxiv.org/pdf/2503.00043v2",
      "published_date": "2025-02-25 23:36:19 UTC",
      "updated_date": "2025-03-04 18:47:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:31:52.856367"
    },
    {
      "arxiv_id": "2502.18697v1",
      "title": "H-FLTN: A Privacy-Preserving Hierarchical Framework for Electric Vehicle Spatio-Temporal Charge Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Marlin",
        "Raja Jurdak",
        "Alsharif Abuadbba"
      ],
      "abstract": "The widespread adoption of Electric Vehicles (EVs) poses critical challenges\nfor energy providers, particularly in predicting charging time (temporal\nprediction), ensuring user privacy, and managing resources efficiently in\nmobility-driven networks. This paper introduces the Hierarchical Federated\nLearning Transformer Network (H-FLTN) framework to address these challenges.\nH-FLTN employs a three-tier hierarchical architecture comprising EVs, community\nDistributed Energy Resource Management Systems (DERMS), and the Energy Provider\nData Centre (EPDC) to enable accurate spatio-temporal predictions of EV\ncharging needs while preserving privacy. Temporal prediction is enhanced using\nTransformer-based learning, capturing complex dependencies in charging\nbehavior. Privacy is ensured through Secure Aggregation, Additive Secret\nSharing, and Peer-to-Peer (P2P) Sharing with Augmentation, which allow only\nsecret shares of model weights to be exchanged while securing all\ntransmissions. To improve training efficiency and resource management, H-FLTN\nintegrates Dynamic Client Capping Mechanism (DCCM) and Client Rotation\nManagement (CRM), ensuring that training remains both computationally and\ntemporally efficient as the number of participating EVs increases. DCCM\noptimises client participation by limiting excessive computational loads, while\nCRM balances training contributions across epochs, preventing imbalanced\nparticipation. Our simulation results based on large-scale empirical vehicle\nmobility data reveal that DCCM and CRM reduce the training time complexity with\nincreasing EVs from linear to constant. Its integration into real-world smart\ncity infrastructure enhances energy demand forecasting, resource allocation,\nand grid stability, ensuring reliability and sustainability in future mobility\necosystems.",
      "tldr_zh": "这篇论文提出 H-FLTN 框架，一种隐私保护的层次化系统，用于预测电动汽车 (EVs) 的时空充电需求，解决充电时间 (temporal prediction) 预测、用户隐私和资源管理挑战。框架采用三层架构，包括 EVs、社区 DERMS 和 EPDC，利用 Transformer-based learning 捕捉充电行为的复杂依赖关系，同时通过 Secure Aggregation、Additive Secret Sharing 和 Peer-to-Peer (P2P) Sharing with Augmentation 确保数据隐私。H-FLTN 还整合 Dynamic Client Capping Mechanism (DCCM) 和 Client Rotation Management (CRM) 来优化训练效率，实验基于大规模车辆移动数据显示，这些机制将训练时间复杂度从线性减少到常量。整体框架可提升智能城市基础设施的能源需求预测、资源分配和电网稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "I.6.5"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 7 tables, 2 figures, Journal Paper",
      "pdf_url": "http://arxiv.org/pdf/2502.18697v1",
      "published_date": "2025-02-25 23:20:53 UTC",
      "updated_date": "2025-02-25 23:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:32:04.866226"
    },
    {
      "arxiv_id": "2502.18695v1",
      "title": "Policy-as-Prompt: Rethinking Content Moderation in the Age of Large Language Models",
      "title_zh": "Policy-as-Prompt：在大型语言模型时代重新思考内容审核",
      "authors": [
        "Konstantina Palla",
        "José Luis Redondo García",
        "Claudia Hauff",
        "Francesco Fabbri",
        "Henrik Lindström",
        "Daniel R. Taber",
        "Andreas Damianou",
        "Mounia Lalmas"
      ],
      "abstract": "Content moderation plays a critical role in shaping safe and inclusive online\nenvironments, balancing platform standards, user expectations, and regulatory\nframeworks. Traditionally, this process involves operationalising policies into\nguidelines, which are then used by downstream human moderators for enforcement,\nor to further annotate datasets for training machine learning moderation\nmodels. However, recent advancements in large language models (LLMs) are\ntransforming this landscape. These models can now interpret policies directly\nas textual inputs, eliminating the need for extensive data curation. This\napproach offers unprecedented flexibility, as moderation can be dynamically\nadjusted through natural language interactions. This paradigm shift raises\nimportant questions about how policies are operationalised and the implications\nfor content moderation practices. In this paper, we formalise the emerging\npolicy-as-prompt framework and identify five key challenges across four\ndomains: Technical Implementation (1. translating policy to prompts, 2.\nsensitivity to prompt structure and formatting), Sociotechnical (3. the risk of\ntechnological determinism in policy formation), Organisational (4. evolving\nroles between policy and machine learning teams), and Governance (5. model\ngovernance and accountability). Through analysing these challenges across\ntechnical, sociotechnical, organisational, and governance dimensions, we\ndiscuss potential mitigation approaches. This research provides actionable\ninsights for practitioners and lays the groundwork for future exploration of\nscalable and adaptive content moderation systems in digital ecosystems.",
      "tldr_zh": "本研究重新审视了大型语言模型(LLMs)时代的内容审核实践，提出“policy-as-prompt”框架，该框架允许LLMs直接将政策作为文本输入进行解释，从而避免传统方法的繁琐数据标注和模型训练，提供更灵活的动态调整机制。论文识别了五个关键挑战，分为技术实现(翻译政策为提示、对提示结构敏感)、社会技术(技术决定论风险)、组织(政策和机器学习团队角色演变)以及治理(模型治理和责任)四个领域，并讨论了潜在的缓解策略。通过这一分析，该研究为从业者提供了可操作见解，并为构建可扩展、适应性的数字内容审核系统奠定了基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18695v1",
      "published_date": "2025-02-25 23:15:16 UTC",
      "updated_date": "2025-02-25 23:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:32:16.260099"
    },
    {
      "arxiv_id": "2502.18690v1",
      "title": "Hybrid Voting-Based Task Assignment in Role-Playing Games",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Weiner",
        "Raj Korpan"
      ],
      "abstract": "In role-playing games (RPGs), the level of immersion is critical-especially\nwhen an in-game agent conveys tasks, hints, or ideas to the player. For an\nagent to accurately interpret the player's emotional state and contextual\nnuances, a foundational level of understanding is required, which can be\nachieved using a Large Language Model (LLM). Maintaining the LLM's focus across\nmultiple context changes, however, necessitates a more robust approach, such as\nintegrating the LLM with a dedicated task allocation model to guide its\nperformance throughout gameplay. In response to this need, we introduce\nVoting-Based Task Assignment (VBTA), a framework inspired by human reasoning in\ntask allocation and completion. VBTA assigns capability profiles to agents and\ntask descriptions to tasks, then generates a suitability matrix that quantifies\nthe alignment between an agent's abilities and a task's requirements.\nLeveraging six distinct voting methods, a pre-trained LLM, and integrating\nconflict-based search (CBS) for path planning, VBTA efficiently identifies and\nassigns the most suitable agent to each task. While existing approaches focus\non generating individual aspects of gameplay, such as single quests, or combat\nencounters, our method shows promise when generating both unique combat\nencounters and narratives because of its generalizable nature.",
      "tldr_zh": "在角色扮演游戏（RPGs）中，为提升代理对玩家情感和上下文的理解，本文提出了一种混合投票-based任务分配（VBTA）框架，利用大型语言模型（LLM）和冲突-based search (CBS)来维持代理的焦点并高效分配任务。VBTA 通过为代理分配能力配置文件和任务描述，生成适合性矩阵，并应用六种投票方法来量化代理与任务的匹配度，从而选择最合适的代理。实验结果表明，该框架在生成独特战斗遭遇和叙事方面表现出色，比现有方法更具通用性和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at Dungeons, Neurons, and Dialogues: Social\n  Interaction Dynamics in Contextual Games Workshop at 20th Annual ACM/IEEE\n  International Conference on Human-Robot Interaction (HRI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.18690v1",
      "published_date": "2025-02-25 22:58:21 UTC",
      "updated_date": "2025-02-25 22:58:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:32:28.357027"
    },
    {
      "arxiv_id": "2503.00042v2",
      "title": "An Analysis of Data Transformation Effects on Segment Anything 2",
      "title_zh": "翻译失败",
      "authors": [
        "Clayton Bromley",
        "Alexander Moore",
        "Amar Saini",
        "Doug Poland",
        "Carmen Carrano"
      ],
      "abstract": "Video object segmentation (VOS) is a critical task in the development of\nvideo perception and understanding. The Segment-Anything Model 2 (SAM 2),\nreleased by Meta AI, is the current state-of-the-art architecture for\nend-to-end VOS. SAM 2 performs very well on both clean video data and augmented\ndata, and completely intelligent video perception requires an understanding of\nhow this architecture is capable of achieving such quality results. To better\nunderstand how each step within the SAM 2 architecture permits high-quality\nvideo segmentation, a variety of complex video transformations are passed\nthrough the architecture, and the impact at each stage of the process is\nmeasured. It is observed that each progressive stage enables the filtering of\ncomplex transformation noise and the emphasis of the object of interest.\nContributions include the creation of complex transformation video datasets, an\nanalysis of how each stage of the SAM 2 architecture interprets these\ntransformations, and visualizations of segmented objects through each stage. By\nbetter understanding how each model structure impacts overall video\nunderstanding, VOS development can work to improve real-world applicability and\nperformance tracking, localizing, and segmenting objects despite complex\ncluttered scenes and obscurations.",
      "tldr_zh": "这篇论文分析了数据变换对 Segment-Anything Model 2 (SAM 2) 在视频对象分割 (VOS) 中的影响，旨在探究该模型如何在复杂视频变换下保持高性能。研究方法包括将各种复杂视频变换（如噪声和遮挡）输入 SAM 2 的每个阶段，并测量其过滤噪声和强调目标对象的能力。关键发现显示，每个处理阶段逐步提升了对变换的鲁棒性，最终提高了对象跟踪、定位和分割的准确性。论文的贡献在于创建了复杂变换视频数据集、提供了对 SAM 2 架构各阶段的详细分析，以及通过可视化结果推动 VOS 在真实世界复杂场景中的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68T45",
        "I.4.6; I.2.10"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 30 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.00042v2",
      "published_date": "2025-02-25 22:58:13 UTC",
      "updated_date": "2025-05-13 02:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:32:40.586312"
    },
    {
      "arxiv_id": "2502.18685v1",
      "title": "Speaking the Right Language: The Impact of Expertise Alignment in User-AI Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Shramay Palta",
        "Nirupama Chandrasekaran",
        "Rachel Rudinger",
        "Scott Counts"
      ],
      "abstract": "Using a sample of 25,000 Bing Copilot conversations, we study how the agent\nresponds to users of varying levels of domain expertise and the resulting\nimpact on user experience along multiple dimensions. Our findings show that\nacross a variety of topical domains, the agent largely responds at proficient\nor expert levels of expertise (77% of conversations) which correlates with\npositive user experience regardless of the user's level of expertise.\nMisalignment, such that the agent responds at a level of expertise below that\nof the user, has a negative impact on overall user experience, with the impact\nmore profound for more complex tasks. We also show that users engage more, as\nmeasured by the number of words in the conversation, when the agent responds at\na level of expertise commensurate with that of the user. Our findings\nunderscore the importance of alignment between user and AI when designing\nhuman-centered AI systems, to ensure satisfactory and productive interactions.",
      "tldr_zh": "本研究分析了25,000个Bing Copilot会话，探讨了AI代理对不同领域专业水平用户的响应方式及其对用户体验的影响。结果显示，AI代理主要以熟练或专家水平回应（77%的会话），这与积极的用户 experience相关，无论用户专业水平如何；然而，如果AI响应水平低于用户水平，会显著降低整体用户体验，尤其在更复杂的任务中。研究还发现，当AI响应水平与用户专业水平匹配时，用户参与度（如对话字数）会增加。这些发现强调了在设计human-centered AI系统时，确保expertise alignment的重要性，以实现更满意和高效的互动。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv Version",
      "pdf_url": "http://arxiv.org/pdf/2502.18685v1",
      "published_date": "2025-02-25 22:46:51 UTC",
      "updated_date": "2025-02-25 22:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:32:51.351325"
    },
    {
      "arxiv_id": "2502.18682v2",
      "title": "AI Mismatches: Identifying Potential Algorithmic Harms Before AI Development",
      "title_zh": "翻译失败",
      "authors": [
        "Devansh Saxena",
        "Ji-Youn Jung",
        "Jodi Forlizzi",
        "Kenneth Holstein",
        "John Zimmerman"
      ],
      "abstract": "AI systems are often introduced with high expectations, yet many fail to\ndeliver, resulting in unintended harm and missed opportunities for benefit. We\nfrequently observe significant \"AI Mismatches\", where the system's actual\nperformance falls short of what is needed to ensure safety and co-create value.\nThese mismatches are particularly difficult to address once development is\nunderway, highlighting the need for early-stage intervention. Navigating\ncomplex, multi-dimensional risk factors that contribute to AI Mismatches is a\npersistent challenge. To address it, we propose an AI Mismatch approach to\nanticipate and mitigate risks early on, focusing on the gap between realistic\nmodel performance and required task performance. Through an analysis of 774 AI\ncases, we extracted a set of critical factors, which informed the development\nof seven matrices that map the relationships between these factors and\nhighlight high-risk areas. Through case studies, we demonstrate how our\napproach can help reduce risks in AI development.",
      "tldr_zh": "该论文探讨了“AI Mismatches”问题，即AI系统实际性能低于预期，导致潜在算法伤害和价值损失，这些问题在开发过程中难以修正。作者提出了一种早期干预方法，通过分析774个AI案例提取关键风险因素，并开发七个矩阵来映射这些因素之间的关系，突出高风险区域。该方法通过案例研究证明，能够有效预测和缓解AI开发中的风险差距，提升系统安全性和性能。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI Conference on Human Factors in Computing Systems (CHI '25), April\n  26-May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2502.18682v2",
      "published_date": "2025-02-25 22:43:00 UTC",
      "updated_date": "2025-04-15 03:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:33:02.843112"
    },
    {
      "arxiv_id": "2502.18681v1",
      "title": "Comparing Native and Non-native English Speakers' Behaviors in Collaborative Writing through Visual Analytics",
      "title_zh": "通过视觉分析比较本地英语说话者和非本地英语说话者在协作写作中的行为",
      "authors": [
        "Yuexi Chen",
        "Yimin Xiao",
        "Kazi Tasnim Zinat",
        "Naomi Yamashita",
        "Ge Gao",
        "Zhicheng Liu"
      ],
      "abstract": "Understanding collaborative writing dynamics between native speakers (NS) and\nnon-native speakers (NNS) is critical for enhancing collaboration quality and\nteam inclusivity. In this paper, we partnered with communication researchers to\ndevelop visual analytics solutions for comparing NS and NNS behaviors in 162\nwriting sessions across 27 teams. The primary challenges in analyzing writing\nbehaviors are data complexity and the uncertainties introduced by automated\nmethods. In response, we present \\textsc{COALA}, a novel visual analytics tool\nthat improves model interpretability by displaying uncertainties in author\nclusters, generating behavior summaries using large language models, and\nvisualizing writing-related actions at multiple granularities. We validated the\neffectiveness of \\textsc{COALA} through user studies with domain experts\n(N=2+2) and researchers with relevant experience (N=8). We present the insights\ndiscovered by participants using \\textsc{COALA}, suggest features for future\nAI-assisted collaborative writing tools, and discuss the broader implications\nfor analyzing collaborative processes beyond writing.",
      "tldr_zh": "本研究通过视觉分析（visual analytics）比较本地英语使用者（NS）和非本地英语使用者（NNS）在协作写作中的行为差异，旨在提升协作质量和团队包容性。研究者开发了\\textsc{COALA}工具来处理数据复杂性和自动化方法的不确定性，该工具通过显示作者聚类不确定性、使用大型语言模型生成行为摘要，以及在多个粒度可视化写作行动，从而提高模型可解释性。经用户研究（包括领域专家N=2+2和相关经验研究人员N=8）验证，\\textsc{COALA}帮助发现重要洞见，并为未来AI辅助协作写作工具提出功能建议，同时扩展到分析更广泛的协作过程。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "accepted by CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18681v1",
      "published_date": "2025-02-25 22:39:55 UTC",
      "updated_date": "2025-02-25 22:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:33:15.219922"
    },
    {
      "arxiv_id": "2503.01871v1",
      "title": "Data Augmentation for Instruction Following Policies via Trajectory Segmentation",
      "title_zh": "通过轨迹分割对指令跟随策略进行数据增强",
      "authors": [
        "Niklas Höpner",
        "Ilaria Tiddi",
        "Herke van Hoof"
      ],
      "abstract": "The scalability of instructable agents in robotics or gaming is often\nhindered by limited data that pairs instructions with agent trajectories.\nHowever, large datasets of unannotated trajectories containing sequences of\nvarious agent behaviour (play trajectories) are often available. In a\nsemi-supervised setup, we explore methods to extract labelled segments from\nplay trajectories. The goal is to augment a small annotated dataset of\ninstruction-trajectory pairs to improve the performance of an\ninstruction-following policy trained downstream via imitation learning.\nAssuming little variation in segment length, recent video segmentation methods\ncan effectively extract labelled segments. To address the constraint of segment\nlength, we propose Play Segmentation (PS), a probabilistic model that finds\nmaximum likely segmentations of extended subsegments, while only being trained\non individual instruction segments. Our results in a game environment and a\nsimulated robotic gripper setting underscore the importance of segmentation;\nrandomly sampled segments diminish performance, while incorporating labelled\nsegments from PS improves policy performance to the level of a policy trained\non twice the amount of labelled data.",
      "tldr_zh": "该研究针对指令跟随策略（如机器人或游戏代理）的可扩展性问题，提出了一种数据增强方法，通过轨迹分段（Trajectory Segmentation）从大量未标注的轨迹数据中提取标注段，以扩充小型标注数据集。作者引入了Play Segmentation (PS)，一个概率模型，能够在仅使用单个指令段训练的情况下，找到最大似然的分段，从而处理段长度变化的挑战。在游戏环境和模拟机器人抓取设置的实验中，PS提取的标注段显著提升了下游模仿学习（Imitation Learning）训练的策略性能，相当于使用两倍的标注数据，而随机采样段则无法实现类似效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01871v1",
      "published_date": "2025-02-25 22:06:01 UTC",
      "updated_date": "2025-02-25 22:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:33:24.965045"
    },
    {
      "arxiv_id": "2503.01870v1",
      "title": "Can Large Language Models Extract Customer Needs as well as Professional Analysts?",
      "title_zh": "大语言模型能否像专业分析师一样提取客户需求？",
      "authors": [
        "Artem Timoshenko",
        "Chengfeng Mao",
        "John R. Hauser"
      ],
      "abstract": "Identifying customer needs (CNs) is important for product management, product\ndevelopment, and marketing. Applications rely on professional analysts\ninterpreting textual data (e.g., interview transcripts, online reviews) to\nunderstand the nuances of customer experience and concisely formulate \"jobs to\nbe done.\" The task is cognitively complex and time-consuming. Current practice\nfacilitates the process with keyword search and machine learning but relies on\nhuman judgment to formulate CNs. We examine whether Large Language Models\n(LLMs) can automatically extract CNs. Because evaluating CNs requires\nprofessional judgment, we partnered with a marketing consulting firm to conduct\na blind study of CNs extracted by: (1) a foundational LLM with prompt\nengineering only (Base LLM), (2) an LLM fine-tuned with professionally\nidentified CNs (SFT LLM), and (3) professional analysts. The SFT LLM performs\nas well as or better than professional analysts when extracting CNs. The\nextracted CNs are well-formulated, sufficiently specific to identify\nopportunities, and justified by source content (no hallucinations). The SFT LLM\nis efficient and provides more complete coverage of CNs. The Base LLM was not\nsufficiently accurate or specific. Organizations can rely on SFT LLMs to reduce\nmanual effort, enhance the precision of CN articulation, and provide improved\ninsight for innovation and marketing strategy.",
      "tldr_zh": "这篇论文探讨大型语言模型（LLMs）是否能像专业分析师一样提取客户需求（CNs），以优化产品管理和营销过程。研究通过与营销咨询公司合作进行盲测，比较了基础 LLM（仅用提示工程）、SFT LLM（用专业 CNs 微调）和专业分析师的提取效果。结果显示，SFT LLM 的表现优于或等同于专业分析师，提取的 CNs 更准确、具体、无幻觉，且覆盖更全面。总体而言，该方法能减少手动努力，提高 CNs 提取的效率，并为创新和营销策略提供更好的洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01870v1",
      "published_date": "2025-02-25 21:55:35 UTC",
      "updated_date": "2025-02-25 21:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:33:38.352111"
    },
    {
      "arxiv_id": "2502.18658v2",
      "title": "Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support",
      "title_zh": "辅助还是干扰？探索和评估主动 AI 编程支持的设计与权衡",
      "authors": [
        "Kevin Pu",
        "Daniel Lazaro",
        "Ian Arawjo",
        "Haijun Xia",
        "Ziang Xiao",
        "Tovi Grossman",
        "Yan Chen"
      ],
      "abstract": "AI programming tools enable powerful code generation, and recent prototypes\nattempt to reduce user effort with proactive AI agents, but their impact on\nprogramming workflows remains unexplored. We introduce and evaluate\nCodellaborator, a design probe LLM agent that initiates programming assistance\nbased on editor activities and task context. We explored three interface\nvariants to assess trade-offs between increasingly salient AI support:\nprompt-only, proactive agent, and proactive agent with presence and context\n(Codellaborator). In a within-subject study (N=18), we find that proactive\nagents increase efficiency compared to prompt-only paradigm, but also incur\nworkflow disruptions. However, presence indicators and interaction context\nsupport alleviated disruptions and improved users' awareness of AI processes.\nWe underscore trade-offs of Codellaborator on user control, ownership, and code\nunderstanding, emphasizing the need to adapt proactivity to programming\nprocesses. Our research contributes to the design exploration and evaluation of\nproactive AI systems, presenting design implications on AI-integrated\nprogramming workflow.",
      "tldr_zh": "本文探讨了主动 AI 代理在编程支持中的设计权衡，引入 Codellaborator 作为一种基于 LLM 的设计探针，它根据编辑器活动和任务上下文主动提供帮助，以减少用户努力。研究通过三种界面变体（prompt-only、proactive agent 和 Codellaborator）在 N=18 的内部受试者实验中评估，发现主动代理提高了编程效率，但也导致工作流中断；然而，添加存在指示和交互上下文能缓解中断并提升用户对 AI 过程的意识。最终，研究强调了 Codellaborator 在用户控制、所有权和代码理解方面的权衡，并为主动 AI 集成编程工作流的优化提供了设计启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18658v2",
      "published_date": "2025-02-25 21:37:25 UTC",
      "updated_date": "2025-03-04 15:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:33:51.725262"
    },
    {
      "arxiv_id": "2502.18653v1",
      "title": "Enhancing Text Classification with a Novel Multi-Agent Collaboration Framework Leveraging BERT",
      "title_zh": "翻译失败",
      "authors": [
        "Hediyeh Baban",
        "Sai A Pidapar",
        "Aashutosh Nema",
        "Sichen Lu"
      ],
      "abstract": "We introduce a novel multi-agent collaboration framework designed to enhance\nthe accuracy and robustness of text classification models. Leveraging BERT as\nthe primary classifier, our framework dynamically escalates low-confidence\npredictions to a specialized multi-agent system comprising Lexical, Contextual,\nLogic, Consensus, and Explainability agents. This collaborative approach allows\nfor comprehensive analysis and consensus-driven decision-making, significantly\nimproving classification performance across diverse text classification tasks.\nEmpirical evaluations on benchmark datasets demonstrate that our framework\nachieves a 5.5% increase in accuracy compared to standard BERT-based\nclassifiers, underscoring its effectiveness and academic novelty in advancing\nmulti-agent systems within natural language processing.",
      "tldr_zh": "本研究提出了一种新型多智能体协作框架，以提升文本分类模型的准确性和鲁棒性。框架以 BERT 作为主要分类器，通过动态升级低置信度预测，调用 Lexical、Contextual、Logic、Consensus 和 Explainability 代理进行全面分析和共识驱动决策。实验结果显示，在基准数据集上，该框架比标准 BERT 分类器提高了 5.5% 的准确率，展示了其在自然语言处理中推进多智能体系统的创新潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18653v1",
      "published_date": "2025-02-25 21:30:16 UTC",
      "updated_date": "2025-02-25 21:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:34:01.932974"
    },
    {
      "arxiv_id": "2502.18652v2",
      "title": "Independent Mobility GPT (IDM-GPT): A Self-Supervised Multi-Agent Large Language Model Framework for Customized Traffic Mobility Analysis Using Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fengze Yang",
        "Xiaoyue Cathy Liu",
        "Lingjiu Lu",
        "Bingzhang Wang",
        "Chenxi Dylan Liu"
      ],
      "abstract": "With the urbanization process, an increasing number of sensors are being\ndeployed in transportation systems, leading to an explosion of big data. To\nharness the power of this vast transportation data, various machine learning\n(ML) and artificial intelligence (AI) methods have been introduced to address\nnumerous transportation challenges. However, these methods often require\nsignificant investment in data collection, processing, storage, and the\nemployment of professionals with expertise in transportation and ML.\nAdditionally, privacy issues are a major concern when processing data for\nreal-world traffic control and management. To address these challenges, the\nresearch team proposes an innovative Multi-agent framework named Independent\nMobility GPT (IDM-GPT) based on large language models (LLMs) for customized\ntraffic analysis, management suggestions, and privacy preservation. IDM-GPT\nefficiently connects users, transportation databases, and ML models\neconomically. IDM-GPT trains, customizes, and applies various LLM-based AI\nagents for multiple functions, including user query comprehension, prompts\noptimization, data analysis, model selection, and performance evaluation and\nenhancement. With IDM-GPT, users without any background in transportation or ML\ncan efficiently and intuitively obtain data analysis and customized suggestions\nin near real-time based on their questions. Experimental results demonstrate\nthat IDM-GPT delivers satisfactory performance across multiple traffic-related\ntasks, providing comprehensive and actionable insights that support effective\ntraffic management and urban mobility improvement.",
      "tldr_zh": "该论文提出了一种名为 IDM-GPT 的自监督多智能体大型语言模型 (LLMs) 框架，用于定制化交通流动分析，旨在解决数据处理成本高、隐私问题和专业知识需求等挑战。框架通过 LLM-based AI 代理实现用户查询理解、提示优化、数据分析、模型选择以及性能评估等功能，允许非专业用户高效获取实时分析和建议。实验结果显示，IDM-GPT 在多个交通相关任务上表现出色，提供全面可操作的见解，支持交通管理和城市流动优化。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 4 figures, TRR accepted",
      "pdf_url": "http://arxiv.org/pdf/2502.18652v2",
      "published_date": "2025-02-25 21:28:15 UTC",
      "updated_date": "2025-03-03 19:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:34:15.781063"
    },
    {
      "arxiv_id": "2504.03650v1",
      "title": "BoxRL-NNV: Boxed Refinement of Latin Hypercube Samples for Neural Network Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Sarthak Das"
      ],
      "abstract": "BoxRL-NNV is a Python tool for the detection of safety violations in neural\nnetworks by computing the bounds of the output variables, given the bounds of\nthe input variables of the network. This is done using global extrema\nestimation via Latin Hypercube Sampling, and further refinement using L-BFGS-B\nfor local optimization around the initial guess. This paper presents an\noverview of BoxRL-NNV, as well as our results for a subset of the ACAS Xu\nbenchmark. A complete evaluation of the tool's performance, including benchmark\ncomparisons with state-of-the-art tools, shall be presented at the Sixth\nInternational Verification of Neural Networks Competition (VNN-COMP'25).",
      "tldr_zh": "该论文介绍了BoxRL-NNV，一种Python工具，用于通过计算神经网络输入变量边界下的输出变量边界来检测安全违规。工具采用Latin Hypercube Sampling进行全局极值估计，并结合L-BFGS-B算法进行局部优化以进一步精炼结果。在ACAS Xu基准子集上的实验展示了初步性能，并计划在VNN-COMP'25上进行完整评估和与其他先进工具的基准比较。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03650v1",
      "published_date": "2025-02-25 21:15:55 UTC",
      "updated_date": "2025-02-25 21:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:34:26.399138"
    },
    {
      "arxiv_id": "2502.18641v1",
      "title": "WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction for AI-bridged Interactive Storytelling",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoran Lu",
        "Qian Zhou",
        "Yi Wang"
      ],
      "abstract": "Generative AI significantly enhances player agency in interactive narratives\n(IN) by enabling just-in-time content generation that adapts to player actions.\nWhile delegating generation to AI makes IN more interactive, it becomes\nchallenging for authors to control the space of possible narratives - within\nwhich the final story experienced by the player emerges from their interaction\nwith AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system\nthat creates narrative possibility spaces from example stories. WhatELSE\nprovides three views (narrative pivot, outline, and variants) to help authors\nunderstand the narrative space and corresponding tools leveraging linguistic\nabstraction to control the boundaries of the narrative space. Taking innovative\nLLM-based narrative planning approaches, WhatELSE further unfolds the narrative\nspace into executable game events. Through a user study (N=12) and technical\nevaluations, we found that WhatELSE enables authors to perceive and edit the\nnarrative space and generates engaging interactive narratives at play-time.",
      "tldr_zh": "该研究提出WhatELSE系统，一种AI-bridged互动叙事(IN)创作工具，旨在帮助作者从示例故事中构建可配置抽象水平的叙事可能性空间，从而解决generative AI增强玩家代理但难以控制叙事边界的问题。WhatELSE提供三视图（narrative pivot、outline和variants）以及基于linguistic abstraction的工具，让作者能理解和编辑叙事空间，并采用LLM-based narrative planning方法将空间展开为可执行游戏事件。通过用户研究（N=12）和技术评估，结果显示WhatELSE显著提升了作者对叙事空间的感知和控制能力，并生成引人入胜的互动叙事。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "In Proceedings of CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18641v1",
      "published_date": "2025-02-25 21:02:15 UTC",
      "updated_date": "2025-02-25 21:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:34:39.414804"
    },
    {
      "arxiv_id": "2502.18639v1",
      "title": "Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Bertl",
        "Alan Mott",
        "Salvatore Sinno",
        "Bhavika Bhalgamiya"
      ],
      "abstract": "The digitization of healthcare presents numerous challenges, including the\ncomplexity of biological systems, vast data generation, and the need for\npersonalized treatment plans. Traditional computational methods often fall\nshort, leading to delayed and sometimes ineffective diagnoses and treatments.\nQuantum Computing (QC) and Quantum Machine Learning (QML) offer transformative\nadvancements with the potential to revolutionize medicine. This paper\nsummarizes areas where QC promises unprecedented computational power, enabling\nfaster, more accurate diagnostics, personalized treatments, and enhanced drug\ndiscovery processes. However, integrating quantum technologies into precision\nmedicine also presents challenges, including errors in algorithms and high\ncosts. We show that mathematically-based techniques for specifying, developing,\nand verifying software (formal methods) can enhance the reliability and\ncorrectness of QC. By providing a rigorous mathematical framework, formal\nmethods help to specify, develop, and verify systems with high precision. In\ngenomic data analysis, formal specification languages can precisely (1) define\nthe behavior and properties of quantum algorithms designed to identify genetic\nmarkers associated with diseases. Model checking tools can systematically\nexplore all possible states of the algorithm to (2) ensure it behaves correctly\nunder all conditions, while theorem proving techniques provide mathematical (3)\nproof that the algorithm meets its specified properties, ensuring accuracy and\nreliability. Additionally, formal optimization techniques can (4) enhance the\nefficiency and performance of quantum algorithms by reducing resource usage,\nsuch as the number of qubits and gate operations. Therefore, we posit that\nformal methods can significantly contribute to enabling QC to realize its full\npotential as a game changer in precision medicine.",
      "tldr_zh": "这篇论文探讨了量子计算 (QC) 和量子机器学习 (QML) 在精准医学和药物发现中的潜力，旨在解决传统方法在处理生物系统复杂性、海量数据和个性化治疗方面的不足。QC 和 QML 可提供更快的诊断、更精确的个性化治疗方案以及加速药物发现过程，但面临算法错误和高成本等挑战。作者强调使用形式方法来提升 QC 的可靠性和正确性，例如通过形式规范语言定义量子算法的行为、模型检查工具验证其在所有条件下的正确性，以及定理证明确保算法属性符合要求。形式方法还可优化量子算法的效率，减少资源使用，如降低量子比特和门操作数量。最终，论文认为这些方法将使 QC 成为精准医学领域的变革性技术，推动个性化治疗的实现。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "presented at AISoLA 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.18639v1",
      "published_date": "2025-02-25 20:59:22 UTC",
      "updated_date": "2025-02-25 20:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:34:53.266014"
    },
    {
      "arxiv_id": "2502.18635v2",
      "title": "Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Barker",
        "Andrew Bell",
        "Evan Thomas",
        "James Carr",
        "Thomas Andrews",
        "Umang Bhatt"
      ],
      "abstract": "While Retrieval Augmented Generation (RAG) has emerged as a popular technique\nfor improving Large Language Model (LLM) systems, it introduces a large number\nof choices, parameters and hyperparameters that must be made or tuned. This\nincludes the LLM, embedding, and ranker models themselves, as well as\nhyperparameters governing individual RAG components. Yet, collectively\noptimizing the entire configuration in a RAG or LLM system remains\nunder-explored - especially in multi-objective settings - due to intractably\nlarge solution spaces, noisy objective evaluations, and the high cost of\nevaluations. In this work, we introduce the first approach for multi-objective\nparameter optimization of cost, latency, safety and alignment over entire LLM\nand RAG systems. We find that Bayesian optimization methods significantly\noutperform baseline approaches, obtaining a superior Pareto front on two new\nRAG benchmark tasks. We conclude our work with important considerations for\npractitioners who are designing multi-objective RAG systems, highlighting\nnuances such as how optimal configurations may not generalize across tasks and\nobjectives.",
      "tldr_zh": "该论文探讨了针对LLM（Large Language Model）和RAG（Retrieval Augmented Generation）系统的多目标超参数优化问题，旨在同时优化成本、延迟、安全性和对齐，以应对巨大的解空间、嘈杂评估和高成本挑战。研究引入了首个全面多目标参数优化方法，使用Bayesian optimization显著优于基线方法，在两个新的RAG基准任务上获得了更好的Pareto front。论文还强调了实际应用中的关键考虑，例如最优配置可能无法跨任务和目标泛化，为设计高效RAG系统提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T20, 68Q32, 90C29, 62P30",
        "I.2.6; I.2.7; G.1.6; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18635v2",
      "published_date": "2025-02-25 20:52:06 UTC",
      "updated_date": "2025-05-08 10:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:35:04.466820"
    },
    {
      "arxiv_id": "2502.18632v1",
      "title": "Automated Knowledge Component Generation and Knowledge Tracing for Coding Problems",
      "title_zh": "针对编程问题的自动知识组件生成和知识追踪",
      "authors": [
        "Zhangqi Duan",
        "Nigel Fernandez",
        "Sri Kanakadandi",
        "Bita Akram",
        "Andrew Lan"
      ],
      "abstract": "Knowledge components (KCs) mapped to problems help model student learning,\ntracking their mastery levels on fine-grained skills thereby facilitating\npersonalized learning and feedback in online learning platforms. However,\ncrafting and tagging KCs to problems, traditionally performed by human domain\nexperts, is highly labor-intensive. We present a fully automated, LLM-based\npipeline for KC generation and tagging for open-ended programming problems. We\nalso develop an LLM-based knowledge tracing (KT) framework to leverage these\nLLM-generated KCs, which we refer to as KCGen-KT. We conduct extensive\nquantitative and qualitative evaluations validating the effectiveness of\nKCGen-KT. On a real-world dataset of student code submissions to open-ended\nprogramming problems, KCGen-KT outperforms existing KT methods. We investigate\nthe learning curves of generated KCs and show that LLM-generated KCs have a\ncomparable level-of-fit to human-written KCs under the performance factor\nanalysis (PFA) model. We also conduct a human evaluation to show that the KC\ntagging accuracy of our pipeline is reasonably accurate when compared to that\nby human domain experts.",
      "tldr_zh": "本文提出一个基于LLM的自动化管道，用于为开放式编程问题生成和标记Knowledge Components (KCs)，以取代传统的人工密集型过程。该管道还整合了LLM-based Knowledge Tracing (KT) 框架，即KCGen-KT，用于追踪学生技能掌握水平。在真实数据集上的实验显示，KCGen-KT优于现有KT方法，且LLM生成的KCs在Performance Factor Analysis (PFA) 模型下与人类编写的KCs具有可比拟的拟合度，同时其标记准确性经人类评估接近专家水平。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18632v1",
      "published_date": "2025-02-25 20:40:51 UTC",
      "updated_date": "2025-02-25 20:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:35:16.349047"
    },
    {
      "arxiv_id": "2502.18620v1",
      "title": "Diffusion Models for conditional MRI generation",
      "title_zh": "用于条件 MRI 生成的扩散模型",
      "authors": [
        "Miguel Herencia García del Castillo",
        "Ricardo Moya Garcia",
        "Manuel Jesús Cerezo Mazón",
        "Ekaitz Arriola Garcia",
        "Pablo Menéndez Fernández-Miranda"
      ],
      "abstract": "In this article, we present a Latent Diffusion Model (LDM) for the generation\nof brain Magnetic Resonance Imaging (MRI), conditioning its generation based on\npathology (Healthy, Glioblastoma, Sclerosis, Dementia) and acquisition modality\n(T1w, T1ce, T2w, Flair, PD).\n  To evaluate the quality of the generated images, the Fr\\'echet Inception\nDistance (FID) and Multi-Scale Structural Similarity Index (MS-SSIM) metrics\nwere employed. The results indicate that the model generates images with a\ndistribution similar to real ones, maintaining a balance between visual\nfidelity and diversity. Additionally, the model demonstrates extrapolation\ncapability, enabling the generation of configurations that were not present in\nthe training data.\n  The results validate the potential of the model to increase in the number of\nsamples in clinical datasets, balancing underrepresented classes, and\nevaluating AI models in medicine, contributing to the development of diagnostic\ntools in radiology without compromising patient privacy.",
      "tldr_zh": "本文提出了一种 Latent Diffusion Model (LDM) 用于条件生成脑部 Magnetic Resonance Imaging (MRI) 图像，根据病理（如 Healthy, Glioblastoma, Sclerosis, Dementia）和获取模式（如 T1w, T1ce, T2w, Flair, PD）进行控制。模型通过 Fréchet Inception Distance (FID) 和 Multi-Scale Structural Similarity Index (MS-SSIM) 指标评估，结果显示生成的图像在分布上接近真实图像，同时兼顾视觉保真度和多样性，并展现出外推能力，能生成训练数据中不存在的配置。该方法有助于扩充临床数据集、平衡 underrepresented classes，并支持 AI 在医学诊断中的应用，同时保护患者隐私。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18620v1",
      "published_date": "2025-02-25 20:08:29 UTC",
      "updated_date": "2025-02-25 20:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:35:27.726966"
    },
    {
      "arxiv_id": "2503.01868v1",
      "title": "Systems and Algorithms for Convolutional Multi-Hybrid Language Models at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Jerome Ku",
        "Eric Nguyen",
        "David W. Romero",
        "Garyk Brixi",
        "Brandon Yang",
        "Anton Vorontsov",
        "Ali Taghibakhshi",
        "Amy X. Lu",
        "Dave P. Burke",
        "Greg Brockman",
        "Stefano Massaroli",
        "Christopher Ré",
        "Patrick D. Hsu",
        "Brian L. Hie",
        "Stefano Ermon",
        "Michael Poli"
      ],
      "abstract": "We introduce convolutional multi-hybrid architectures, with a design grounded\non two simple observations. First, operators in hybrid models can be tailored\nto token manipulation tasks such as in-context recall, multi-token recall, and\ncompression, with input-dependent convolutions and attention offering\ncomplementary performance. Second, co-designing convolution operators and\nhardware-aware algorithms enables efficiency gains in regimes where previous\nalternative architectures struggle to surpass Transformers. At the 40 billion\nparameter scale, we train end-to-end 1.2 to 2.9 times faster than optimized\nTransformers, and 1.1 to 1.4 times faster than previous generation hybrids. On\nH100 GPUs and model width 4096, individual operators in the proposed\nmulti-hybrid StripedHyena 2 architecture achieve two-fold throughput\nimprovement over linear attention and state-space models. Multi-hybrids excel\nat sequence modeling over byte-tokenized data, as demonstrated by the Evo 2\nline of models. We discuss the foundations that enable these results, including\narchitecture design, overlap-add blocked kernels for tensor cores, and\ndedicated all-to-all and point-to-point context parallelism strategies.",
      "tldr_zh": "本论文引入了卷积多混合架构（convolutional multi-hybrid architectures），基于两个关键观察：混合模型操作可针对上下文回忆、多标记回忆和压缩任务进行优化，利用输入依赖的卷积和注意力机制实现互补性能；并通过硬件感知算法设计提升效率。实验显示，在400亿参数规模下，该架构的训练速度比优化过的Transformers快1.2到2.9倍，比前代混合模型快1.1到1.4倍；在H100 GPUs上，StripedHyena 2架构的运算符吞吐量较线性注意力或状态空间模型提高两倍。多混合模型特别适用于字节标记数据的序列建模任务，并通过架构设计、块级内核和并行策略奠定了高效基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01868v1",
      "published_date": "2025-02-25 19:47:20 UTC",
      "updated_date": "2025-02-25 19:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:35:41.793112"
    },
    {
      "arxiv_id": "2502.18604v1",
      "title": "Mind the Gap: Bridging the Divide Between AI Aspirations and the Reality of Autonomous Characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Grace Guinan",
        "Addison Salvador",
        "Michelle A. Smeaton",
        "Andrew Glaws",
        "Hilary Egan",
        "Brian C. Wyatt",
        "Babak Anasori",
        "Kevin R. Fiedler",
        "Matthew J. Olszta",
        "Steven R. Spurgeon"
      ],
      "abstract": "What does materials science look like in the \"Age of Artificial\nIntelligence?\" Each materials domain-synthesis, characterization, and\nmodeling-has a different answer to this question, motivated by unique\nchallenges and constraints. This work focuses on the tremendous potential of\nautonomous characterization within electron microscopy. We present our recent\nadvancements in developing domain-aware, multimodal models for microscopy\nanalysis capable of describing complex atomic systems. We then address the\ncritical gap between the theoretical promise of autonomous microscopy and its\ncurrent practical limitations, showcasing recent successes while highlighting\nthe necessary developments to achieve robust, real-world autonomy.",
      "tldr_zh": "本论文探讨了材料科学在AI时代的发展，聚焦于合成、表征和建模领域的独特挑战，特别强调电子显微镜（electron microscopy）中的自主表征（autonomous characterization）的潜力。研究者介绍了最近在开发领域感知的多模态模型（domain-aware, multimodal models）方面的进展，这些模型能够描述复杂的原子系统，从而提升显微镜分析能力。论文突出了理论承诺与实际限制之间的关键差距，通过展示最近成功案例，指出实现稳健的真实世界自主性所需的进一步发展。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "33 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18604v1",
      "published_date": "2025-02-25 19:43:47 UTC",
      "updated_date": "2025-02-25 19:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:35:52.394979"
    },
    {
      "arxiv_id": "2502.18586v1",
      "title": "Autonomous Vision-Guided Resection of Central Airway Obstruction",
      "title_zh": "翻译失败",
      "authors": [
        "M. E. Smith",
        "N. Yilmaz",
        "T. Watts",
        "P. M. Scheikl",
        "J. Ge",
        "A. Deguet",
        "A. Kuntz",
        "A. Krieger"
      ],
      "abstract": "Existing tracheal tumor resection methods often lack the precision required\nfor effective airway clearance, and robotic advancements offer new potential\nfor autonomous resection. We present a vision-guided, autonomous approach for\npalliative resection of tracheal tumors. This system models the tracheal\nsurface with a fifth-degree polynomial to plan tool trajectories, while a\ncustom Faster R-CNN segmentation pipeline identifies the trachea and tumor\nboundaries. The electrocautery tool angle is optimized using handheld surgical\ndemonstrations, and trajectories are planned to maintain a 1 mm safety\nclearance from the tracheal surface. We validated the workflow successfully in\nfive consecutive experiments on ex-vivo animal tissue models, successfully\nclearing the airway obstruction without trachea perforation in all cases (with\nmore than 90% volumetric tumor removal). These results support the feasibility\nof an autonomous resection platform, paving the way for future developments in\nminimally-invasive autonomous resection.",
      "tldr_zh": "本研究提出了一种视觉引导的自主系统，用于切除中心气道阻塞（如气管肿瘤），以解决现有方法的精度不足问题。该系统使用五次多项式建模气管表面规划工具轨迹，并采用自定义 Faster R-CNN 管道进行气管和肿瘤边界的分割识别，同时优化电灼工具角度并保持 1 mm 安全距离。在 ex-vivo 动物组织模型上进行的五次实验中，该系统成功清除气道阻塞，无气管穿孔，并实现了超过 90% 的 volumetric tumor removal。这些结果验证了自主切除平台的 feasibility，并为微创自主手术的未来发展奠定基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to World Scientific, Journal of Medical Robotics Research\n  (JMRR) 2025. 10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18586v1",
      "published_date": "2025-02-25 19:11:11 UTC",
      "updated_date": "2025-02-25 19:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:36:03.732031"
    },
    {
      "arxiv_id": "2502.18581v1",
      "title": "Scalable Best-of-N Selection for Large Language Models via Self-Certainty",
      "title_zh": "翻译失败",
      "authors": [
        "Zhewei Kang",
        "Xuandong Zhao",
        "Dawn Song"
      ],
      "abstract": "Best-of-N selection is a key technique for improving the reasoning\nperformance of Large Language Models (LLMs) through increased test-time\ncomputation. Current state-of-the-art methods often employ computationally\nintensive reward models for response evaluation and selection. Reward-free\nalternatives, like self-consistency and universal self-consistency, are limited\nin their ability to handle open-ended generation tasks or scale effectively. To\naddress these limitations, we propose self-certainty, a novel and efficient\nmetric that leverages the inherent probability distribution of LLM outputs to\nestimate response quality without requiring external reward models. We\nhypothesize that higher distributional self-certainty, aggregated across\nmultiple samples, correlates with improved response accuracy, as it reflects\ngreater confidence in the generated output. Through extensive experiments on\nvarious reasoning tasks, we demonstrate that self-certainty (1) scales\neffectively with increasing sample size $N$, akin to reward models but without\nthe computational overhead; (2) complements chain-of-thought, improving\nreasoning performance beyond greedy decoding; and (3) generalizes to open-ended\ntasks where traditional self-consistency methods fall short. Our findings\nestablish self-certainty as a practical and efficient way for improving LLM\nreasoning capabilities. The code is available at\nhttps://github.com/backprop07/Self-Certainty",
      "tldr_zh": "本文提出self-certainty，一种新型高效指标，用于Large Language Models (LLMs)的Best-of-N选择，通过利用LLM输出概率分布估算响应质量，而无需外部奖励模型。该方法假设更高的分布自确定性与响应准确性相关，并在各种推理任务上实验证明：它能有效扩展到更大样本大小N、结合chain-of-thought提升性能超过greedy decoding，并适用于传统self-consistency方法无法处理的开放生成任务。与现有方法相比，self-certainty减少了计算开销，提供了一种实用方式来改善LLMs的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18581v1",
      "published_date": "2025-02-25 19:08:07 UTC",
      "updated_date": "2025-02-25 19:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:36:16.702523"
    },
    {
      "arxiv_id": "2502.18578v1",
      "title": "Differentially Private Iterative Screening Rules for Linear Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Amol Khanna",
        "Fred Lu",
        "Edward Raff"
      ],
      "abstract": "Linear $L_1$-regularized models have remained one of the simplest and most\neffective tools in data science. Over the past decade, screening rules have\nrisen in popularity as a way to eliminate features when producing the sparse\nregression weights of $L_1$ models. However, despite the increasing need of\nprivacy-preserving models for data analysis, to the best of our knowledge, no\ndifferentially private screening rule exists. In this paper, we develop the\nfirst private screening rule for linear regression. We initially find that this\nscreening rule is too strong: it screens too many coefficients as a result of\nthe private screening step. However, a weakened implementation of private\nscreening reduces overscreening and improves performance.",
      "tldr_zh": "本研究针对线性回归中的 L1 正则化模型，开发了第一个 Differentially Private 筛选规则，以在保持数据隐私的同时消除不必要的特征。传统的筛选规则（Screening Rules）用于产生稀疏回归权重，但缺乏隐私保护；本文的方法通过迭代私有筛选来解决这一问题。实验发现，初始的私有筛选规则导致过度筛选（overscreening）系数，但通过弱化实现方式，显著改善了模型性能。总的来说，这一贡献为隐私保护的数据科学工具提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 15th ACM Conference on Data and Application\n  Security and Privacy",
      "pdf_url": "http://arxiv.org/pdf/2502.18578v1",
      "published_date": "2025-02-25 19:06:19 UTC",
      "updated_date": "2025-02-25 19:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:36:27.491152"
    },
    {
      "arxiv_id": "2502.18573v1",
      "title": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Radu Marinescu",
        "Debarun Bhattacharjya",
        "Junkyu Lee",
        "Tigran Tchrakian",
        "Javier Carnerero Cano",
        "Yufang Hou",
        "Elizabeth Daly",
        "Alessandra Pascale"
      ],
      "abstract": "Large language models (LLMs) have demonstrated vast capabilities on\ngenerative tasks in recent years, yet they struggle with guaranteeing the\nfactual correctness of the generated content. This makes these models\nunreliable in realistic situations where factually accurate responses are\nexpected. In this paper, we propose FactReasoner, a new factuality assessor\nthat relies on probabilistic reasoning to assess the factuality of a long-form\ngenerated response. Specifically, FactReasoner decomposes the response into\natomic units, retrieves relevant contexts for them from an external knowledge\nsource, and constructs a joint probability distribution over the atoms and\ncontexts using probabilistic encodings of the logical relationships\n(entailment, contradiction) between the textual utterances corresponding to the\natoms and contexts. FactReasoner then computes the posterior probability of\nwhether atomic units in the response are supported by the retrieved contexts.\nOur experiments on labeled and unlabeled benchmark datasets demonstrate clearly\nthat FactReasoner improves considerably over state-of-the-art prompt-based\napproaches in terms of both factual precision and recall.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在生成长形式内容时难以保证事实正确性的问题，提出 FactReasoner，一种基于 probabilistic reasoning 的事实性评估方法。FactReasoner 将响应分解为 atomic units，从外部知识源检索相关上下文，并通过 probabilistic encodings 构建 atoms 和 contexts 之间的联合概率分布，考虑逻辑关系如 entailment 和 contradiction，以计算原子单位被支持的后验概率。实验在标记和未标记的基准数据集上表明，FactReasoner 在 factual precision 和 recall 上显著优于现有的 prompt-based approaches。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18573v1",
      "published_date": "2025-02-25 19:01:48 UTC",
      "updated_date": "2025-02-25 19:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:36:41.305211"
    },
    {
      "arxiv_id": "2502.18462v1",
      "title": "Scalable Equilibrium Sampling with Sequential Boltzmann Generators",
      "title_zh": "可扩展的平衡采样：基于顺序 Boltzmann 生成器",
      "authors": [
        "Charlie B. Tan",
        "Avishek Joey Bose",
        "Chen Lin",
        "Leon Klein",
        "Michael M. Bronstein",
        "Alexander Tong"
      ],
      "abstract": "Scalable sampling of molecular states in thermodynamic equilibrium is a\nlong-standing challenge in statistical physics. Boltzmann generators tackle\nthis problem by pairing powerful normalizing flows with importance sampling to\nobtain statistically independent samples under the target distribution. In this\npaper, we extend the Boltzmann generator framework and introduce Sequential\nBoltzmann generators (SBG) with two key improvements. The first is a highly\nefficient non-equivariant Transformer-based normalizing flow operating directly\non all-atom Cartesian coordinates. In contrast to equivariant continuous flows\nof prior methods, we leverage exactly invertible non-equivariant architectures\nwhich are highly efficient both during sample generation and likelihood\ncomputation. As a result, this unlocks more sophisticated inference strategies\nbeyond standard importance sampling. More precisely, as a second key\nimprovement we perform inference-time scaling of flow samples using annealed\nLangevin dynamics which transports samples toward the target distribution\nleading to lower variance (annealed) importance weights which enable higher\nfidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art\nperformance w.r.t. all metrics on molecular systems, demonstrating the first\nequilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides\nthat were so far intractable for prior Boltzmann generators.",
      "tldr_zh": "本文提出 Sequential Boltzmann Generators (SBG)，一种扩展 Boltzmann generators 的框架，用于解决分子热力学平衡采样中的可扩展性挑战。SBG 的关键改进包括高效的非等变 Transformer-based normalizing flow，直接在所有原子笛卡尔坐标上操作，以实现精确可逆的样本生成和似然计算；以及推理时的 annealed Langevin dynamics，对 flow samples 进行缩放，降低方差并提升 sequential Monte Carlo 的重采样保真度。实验结果显示，SBG 在分子系统中达到了最先进性能，首次实现了 tri, tetra 和 hexapeptides 在笛卡尔坐标下的平衡采样。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.18462v1",
      "published_date": "2025-02-25 18:59:13 UTC",
      "updated_date": "2025-02-25 18:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:36:52.456150"
    },
    {
      "arxiv_id": "2503.05773v1",
      "title": "Between Innovation and Oversight: A Cross-Regional Study of AI Risk Management Frameworks in the EU, U.S., UK, and China",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Al-Maamari"
      ],
      "abstract": "As artificial intelligence (AI) technologies increasingly enter important\nsectors like healthcare, transportation, and finance, the development of\neffective governance frameworks is crucial for dealing with ethical, security,\nand societal risks. This paper conducts a comparative analysis of AI risk\nmanagement strategies across the European Union (EU), United States (U.S.),\nUnited Kingdom (UK), and China. A multi-method qualitative approach, including\ncomparative policy analysis, thematic analysis, and case studies, investigates\nhow these regions classify AI risks, implement compliance measures, structure\noversight, prioritize transparency, and respond to emerging innovations.\nExamples from high-risk contexts like healthcare diagnostics, autonomous\nvehicles, fintech, and facial recognition demonstrate the advantages and\nlimitations of different regulatory models. The findings show that the EU\nimplements a structured, risk-based framework that prioritizes transparency and\nconformity assessments, while the U.S. uses decentralized, sector-specific\nregulations that promote innovation but may lead to fragmented enforcement. The\nflexible, sector-specific strategy of the UK facilitates agile responses but\nmay lead to inconsistent coverage across domains. China's centralized\ndirectives allow rapid large-scale implementation while constraining public\ntransparency and external oversight. These insights show the necessity for AI\nregulation that is globally informed yet context-sensitive, aiming to balance\neffective risk management with technological progress. The paper concludes with\npolicy recommendations and suggestions for future research aimed at enhancing\neffective, adaptive, and inclusive AI governance globally.",
      "tldr_zh": "本研究通过比较分析欧盟（EU）、美国（U.S.）、英国（UK）和中国在AI风险管理框架上的策略，探讨这些地区如何分类AI风险、实施合规措施、构建监督并平衡创新与监管。采用多方法定性方法，包括比较政策分析、主题分析和案例研究，该论文以医疗诊断、自动驾驶车辆、金融科技及面部识别等高风险领域的例子，揭示了欧盟的结构化风险框架强调透明度，美国的分散式规定促进创新但易导致执行碎片化，UK的灵活策略便于响应但覆盖不均，以及中国的集中式指令加速实施却限制透明度。研究结论强调需要全球视野且上下文敏感的AI治理，以有效管理风险并推动技术进步，并提出政策推荐和未来研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05773v1",
      "published_date": "2025-02-25 18:52:17 UTC",
      "updated_date": "2025-02-25 18:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:37:04.861405"
    },
    {
      "arxiv_id": "2502.18452v1",
      "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
      "title_zh": "翻译失败",
      "authors": [
        "Mollie Shichman",
        "Claire Bonial",
        "Austin Blodgett",
        "Taylor Hudson",
        "Francis Ferraro",
        "Rachel Rudinger"
      ],
      "abstract": "Large Language Models (LLMs) have the potential for substantial common sense\nreasoning. However, these capabilities are often emergent in larger models.\nThis means smaller models that can be run locally are less helpful and capable\nwith respect to certain reasoning tasks. To meet our problem space\nrequirements, we fine-tune smaller LLMs to disaster domains, as these domains\ninvolve complex and low-frequency physical common sense knowledge. We introduce\na pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models,\nwhere domain experts and linguists combine their knowledge to make high-quality\nseed data that is used to generate synthetic data for fine-tuning. We create a\nset of 130 seed instructions for synthetic generation, a synthetic dataset of\n25000 instructions, and 119 evaluation instructions relating to both general\nand earthquake-specific object affordances. We fine-tune several LLaMa and\nMistral instruction-tuned models and find that FRIDA models outperform their\nbase models at a variety of sizes. We then run an ablation study to understand\nwhich kinds of synthetic data most affect performance and find that training\nphysical state and object function common sense knowledge alone improves over\nFRIDA models trained on all data. We conclude that the FRIDA pipeline is\ncapable of instilling general common sense, but needs to be augmented with\ninformation retrieval for specific domain knowledge.",
      "tldr_zh": "这篇论文探讨了使用合成数据微调较小 LLMs（Large Language Models），以提升灾害响应中的物体基于常见感推理能力，特别是针对复杂、低频的物理知识。研究引入了 FRIDA 管道，由领域专家和语言学家创建高质量种子数据（130 条指令），并生成 25000 条合成指令数据集，用于微调 LLaMa 和 Mistral 模型。实验结果显示，FRIDA 模型在各种规模上优于基线模型，且通过消融研究发现，专注于物理状态和对象功能常见感知识的训练能进一步提升性能。最终结论是，FRIDA 管道可增强一般常见感，但需结合信息检索以处理特定领域知识。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18452v1",
      "published_date": "2025-02-25 18:51:06 UTC",
      "updated_date": "2025-02-25 18:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:37:17.508373"
    },
    {
      "arxiv_id": "2502.18555v1",
      "title": "Application of Attention Mechanism with Bidirectional Long Short-Term Memory (BiLSTM) and CNN for Human Conflict Detection using Computer Vision",
      "title_zh": "注意力机制与双向长短期记忆网络 (BiLSTM) 和 CNN 在计算机视觉人类冲突检测中的应用",
      "authors": [
        "Erick da Silva Farias",
        "Eduardo Palhares Junior"
      ],
      "abstract": "The automatic detection of human conflicts through videos is a crucial area\nin computer vision, with significant applications in monitoring and public\nsafety policies. However, the scarcity of public datasets and the complexity of\nhuman interactions make this task challenging. This study investigates the\nintegration of advanced deep learning techniques, including Attention\nMechanism, Convolutional Neural Networks (CNNs), and Bidirectional Long\nShortTerm Memory (BiLSTM), to improve the detection of violent behaviors in\nvideos. The research explores how the use of the attention mechanism can help\nfocus on the most relevant parts of the video, enhancing the accuracy and\nrobustness of the model. The experiments indicate that the combination of CNNs\nwith BiLSTM and the attention mechanism provides a promising solution for\nconflict monitoring, offering insights into the effectiveness of different\nstrategies. This work opens new possibilities for the development of automated\nsurveillance systems that can operate more efficiently in real-time detection\nof violent events.",
      "tldr_zh": "该研究探讨了利用计算机视觉技术自动检测视频中人类冲突的问题，强调了数据集稀缺和互动复杂性的挑战。研究整合了 Attention Mechanism、CNN 和 BiLSTM 等深度学习方法，通过 Attention Mechanism 聚焦视频的关键部分，提高了暴力行为检测的准确性和鲁棒性。实验结果表明，这种组合策略为实时自动监控系统提供了高效解决方案，并为公共安全政策应用提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18555v1",
      "published_date": "2025-02-25 18:48:34 UTC",
      "updated_date": "2025-02-25 18:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:37:26.988007"
    },
    {
      "arxiv_id": "2502.18449v1",
      "title": "SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution",
      "title_zh": "SWE-RL：通过在开源软件演化上应用强化学习提升LLM推理能力",
      "authors": [
        "Yuxiang Wei",
        "Olivier Duchenne",
        "Jade Copet",
        "Quentin Carbonneaux",
        "Lingming Zhang",
        "Daniel Fried",
        "Gabriel Synnaeve",
        "Rishabh Singh",
        "Sida I. Wang"
      ],
      "abstract": "The recent DeepSeek-R1 release has demonstrated the immense potential of\nreinforcement learning (RL) in enhancing the general reasoning capabilities of\nlarge language models (LLMs). While DeepSeek-R1 and other follow-up work\nprimarily focus on applying RL to competitive coding and math problems, this\npaper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for\nreal-world software engineering. Leveraging a lightweight rule-based reward\n(e.g., the similarity score between ground-truth and LLM-generated solutions),\nSWE-RL enables LLMs to autonomously recover a developer's reasoning processes\nand solutions by learning from extensive open-source software evolution data --\nthe record of a software's entire lifecycle, including its code snapshots, code\nchanges, and events such as issues and pull requests. Trained on top of Llama\n3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve\nrate on SWE-bench Verified -- a human-verified collection of real-world GitHub\nissues. To our knowledge, this is the best performance reported for\nmedium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs\nlike GPT-4o. Surprisingly, despite performing RL solely on software evolution\ndata, Llama3-SWE-RL has even emerged with generalized reasoning skills. For\nexample, it shows improved results on five out-of-domain tasks, namely,\nfunction coding, library use, code reasoning, mathematics, and general language\nunderstanding, whereas a supervised-finetuning baseline even leads to\nperformance degradation on average. Overall, SWE-RL opens up a new direction to\nimprove the reasoning capabilities of LLMs through reinforcement learning on\nmassive software engineering data.",
      "tldr_zh": "本研究引入SWE-RL，一种新型方法，通过强化学习（RL）在开源软件演化数据上提升大型语言模型（LLMs）的推理能力，首次将RL扩展到真实世界软件工程领域。SWE-RL使用轻量级规则-based奖励（如ground-truth与LLM生成解决方案的相似度分数），让模型从软件生命周期数据（如代码快照、变更、issues和pull requests）中自主学习开发者的推理过程。基于Llama 3训练的Llama3-SWE-RL-70B在SWE-bench Verified数据集上达到41.0%的解决率，超越其他中等规模（<100B）LLMs，甚至与GPT-4o相当；此外，该模型在非领域任务（如函数编码、库使用、代码推理、数学和一般语言理解）上也表现出泛化改进，为利用软件工程数据增强LLM推理能力开辟新方向。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18449v1",
      "published_date": "2025-02-25 18:45:04 UTC",
      "updated_date": "2025-02-25 18:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:37:40.706983"
    },
    {
      "arxiv_id": "2502.18448v1",
      "title": "Disambiguate First Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Irina Saparina",
        "Mirella Lapata"
      ],
      "abstract": "Handling ambiguity and underspecification is an important challenge in\nnatural language interfaces, particularly for tasks like text-to-SQL semantic\nparsing. We propose a modular approach that resolves ambiguity using natural\nlanguage interpretations before mapping these to logical forms (e.g., SQL\nqueries). Although LLMs excel at parsing unambiguous utterances, they show\nstrong biases for ambiguous ones, typically predicting only preferred\ninterpretations. We constructively exploit this bias to generate an initial set\nof preferred disambiguations and then apply a specialized infilling model to\nidentify and generate missing interpretations. To train the infilling model, we\nintroduce an annotation method that uses SQL execution to validate different\nmeanings. Our approach improves interpretation coverage and generalizes across\ndatasets with different annotation styles, database structures, and ambiguity\ntypes.",
      "tldr_zh": "该论文针对文本到-SQL 语义解析中的歧义和不明确性问题，提出了一种模块化方法：先使用自然语言解释进行消歧义，然后再映射到逻辑形式（如 SQL 查询）。该方法利用 LLMs 的偏好生成初始首选解释，并应用专门的 infilling 模型来识别和生成缺失解释。训练 infilling 模型时，引入基于 SQL 执行的注释方法来验证不同含义，从而提高解释覆盖率。该方法在不同数据集上表现出良好的泛化能力，适用于各种注释风格、数据库结构和歧义类型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18448v1",
      "published_date": "2025-02-25 18:42:26 UTC",
      "updated_date": "2025-02-25 18:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:37:53.222108"
    },
    {
      "arxiv_id": "2502.18439v1",
      "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chanwoo Park",
        "Seungju Han",
        "Xingzhi Guo",
        "Asuman Ozdaglar",
        "Kaiqing Zhang",
        "Joo-Kyung Kim"
      ],
      "abstract": "Leveraging multiple large language models (LLMs) to build collaborative\nmulti-agentic workflows has demonstrated significant potential. However, most\nprevious studies focus on prompting the out-of-the-box LLMs, relying on their\ninnate capability for collaboration, which may not improve LLMs' performance as\nshown recently. In this paper, we introduce a new post-training paradigm MAPoRL\n(Multi-Agent Post-co-training for collaborative LLMs with Reinforcement\nLearning), to explicitly elicit the collaborative behaviors and further unleash\nthe power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first\ngenerate their own responses independently and engage in a multi-turn\ndiscussion to collaboratively improve the final answer. In the end, a MAPoRL\nverifier evaluates both the answer and the discussion, by assigning a score\nthat verifies the correctness of the answer, while adding incentives to\nencourage corrective and persuasive discussions. The score serves as the\nco-training reward, and is then maximized through multi-agent RL. Unlike\nexisting LLM post-training paradigms, MAPoRL advocates the co-training of\nmultiple LLMs together using RL for better generalization. Accompanied by\nanalytical insights, our experiments demonstrate that training individual LLMs\nalone is insufficient to induce effective collaboration. In contrast,\nmulti-agent co-training can boost the collaboration performance across\nbenchmarks, with generalization to unseen domains.",
      "tldr_zh": "本研究提出了一种新的后训练范式 MAPoRL（Multi-Agent Post-Co-Training），旨在通过强化学习（Reinforcement Learning）增强大型语言模型（LLMs）的协作行为，实现多智能体框架的潜力。MAPoRL 让多个 LLMs 首先独立生成响应，然后进行多轮讨论以共同优化最终答案，同时使用一个验证器评估答案和讨论过程，并通过分数作为奖励来激励正确的输出和建设性对话。实验结果表明，单独训练单个 LLMs 无法有效促进协作，而多智能体联合训练可显著提升性能，并在基准测试中实现更好的泛化能力，适用于未见领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18439v1",
      "published_date": "2025-02-25 18:33:48 UTC",
      "updated_date": "2025-02-25 18:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:38:03.790035"
    },
    {
      "arxiv_id": "2502.18438v2",
      "title": "ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Sequeira",
        "Vidyasagar Sadhu",
        "Melinda Gervasio"
      ],
      "abstract": "In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in\nTeams), a new framework for generating ToM-conditioned trajectories. It\ncombines a meta-learning mechanism, that performs ToM reasoning over teammates'\nunderlying goals and future behavior, with a multiagent denoising-diffusion\nmodel, that generates plans for an agent and its teammates conditioned on both\nthe agent's goals and its teammates' characteristics, as computed via ToM. We\nimplemented an online planning system that dynamically samples new trajectories\n(replans) from the diffusion model whenever it detects a divergence between a\npreviously generated plan and the current state of the world. We conducted\nseveral experiments using ToMCAT in a simulated cooking domain. Our results\nhighlight the importance of the dynamic replanning mechanism in reducing the\nusage of resources without sacrificing team performance. We also show that\nrecent observations about the world and teammates' behavior collected by an\nagent over the course of an episode combined with ToM inferences are crucial to\ngenerate team-aware plans for dynamic adaptation to teammates, especially when\nno prior information is provided about them.",
      "tldr_zh": "本研究提出了 ToMCAT 框架，用于生成基于 Theory-of-Mind (ToM) 的团队合作代理轨迹，该框架结合元学习机制对队友目标和行为进行推理，以及多智能体去噪扩散模型生成代理计划。ToMCAT 包括一个在线规划系统，能动态采样新轨迹（重新规划），以应对计划与实际状态的偏差。在模拟烹饪领域的实验中，该框架显著减少了资源消耗，同时保持团队性能，并证明了代理收集的实时观察和 ToM 推理对动态适应未知队友至关重要。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Appears in Proc. of the Adaptive and Learning Agents Workshop (ALA\n  2025), ala-workshop.github.io",
      "pdf_url": "http://arxiv.org/pdf/2502.18438v2",
      "published_date": "2025-02-25 18:31:55 UTC",
      "updated_date": "2025-05-06 05:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:38:17.569359"
    },
    {
      "arxiv_id": "2503.01867v1",
      "title": "Neural Manifolds and Cognitive Consistency: A New Approach to Memory Consolidation in Artificial Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Phuong-Nam Nguyen"
      ],
      "abstract": "We introduce a novel mathematical framework that unifies neural population\ndynamics, hippocampal sharp wave-ripple (SpWR) generation, and cognitive\nconsistency constraints inspired by Heider's theory. Our model leverages\nlow-dimensional manifold representations to capture structured neural drift and\nincorporates a balance energy function to enforce coherent synaptic\ninteractions, effectively simulating the memory consolidation processes\nobserved in biological systems. Simulation results demonstrate that our\napproach not only reproduces key features of SpWR events but also enhances\nnetwork interpretability. This work paves the way for scalable neuromorphic\narchitectures that bridge neuroscience and artificial intelligence, offering\nmore robust and adaptive learning mechanisms for future intelligent systems.",
      "tldr_zh": "本研究提出了一种新颖的数学框架，将neural manifolds、低维流形表示与Heider's theory启发的认知一致性约束相结合，统一了neural population dynamics和海马体sharp wave-ripple (SpWR)生成过程，以模拟生物系统的记忆巩固机制。该框架通过平衡能量函数强制执行相干的突触互动，捕捉结构化的神经漂移，从而提升了网络的可解释性和鲁棒性。模拟结果显示，该方法成功重现了SpWR事件的特征，并为可扩展的neuromorphic architectures提供了基础，有望桥接神经科学和人工智能，实现更具适应性的学习系统。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01867v1",
      "published_date": "2025-02-25 18:28:25 UTC",
      "updated_date": "2025-02-25 18:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:38:28.245001"
    },
    {
      "arxiv_id": "2502.18431v1",
      "title": "TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Frederikus Hudi",
        "Genta Indra Winata",
        "Ruochen Zhang",
        "Alham Fikri Aji"
      ],
      "abstract": "Reasoning is a fundamental capability of large language models (LLMs),\nenabling them to comprehend, analyze, and solve complex problems. In this\npaper, we introduce TextGames, an innovative benchmark specifically crafted to\nassess LLMs through demanding text-based games that require advanced skills in\npattern recognition, spatial awareness, arithmetic, and logical reasoning. Our\nanalysis probes LLMs' performance in both single-turn and multi-turn reasoning,\nand their abilities in leveraging feedback to correct subsequent answers\nthrough self-reflection. Our findings reveal that, although LLMs exhibit\nproficiency in addressing most easy and medium-level problems, they face\nsignificant challenges with more difficult tasks. In contrast, humans are\ncapable of solving all tasks when given sufficient time. Moreover, we observe\nthat LLMs show improved performance in multi-turn predictions through\nself-reflection, yet they still struggle with sequencing, counting, and\nfollowing complex rules consistently. Additionally, models optimized for\nreasoning outperform pre-trained LLMs that prioritize instruction following,\nhighlighting the crucial role of reasoning skills in addressing highly complex\nproblems.",
      "tldr_zh": "本研究引入了 TextGames 基准，用于评估大型语言模型 (LLMs) 在文本-based 谜题游戏中的推理能力，这些游戏需要模式识别、空间意识、算术和逻辑推理等高级技能。研究通过分析 LLMs 在 single-turn 和 multi-turn 推理中的表现，以及利用反馈进行自我反思的能力，发现 LLMs 在简单和中等问题上表现出色，但难以处理复杂任务，而人类则能解决所有问题。结果显示，通过自我反思，LLMs 在多轮预测中有所改善，但仍存在序列处理、计数和遵循复杂规则的挑战；此外，优化推理的模型比注重指令遵循的预训练 LLMs 表现更佳，强调了推理技能的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18431v1",
      "published_date": "2025-02-25 18:26:48 UTC",
      "updated_date": "2025-02-25 18:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:38:39.784970"
    },
    {
      "arxiv_id": "2502.18425v1",
      "title": "PyEvalAI: AI-assisted evaluation of Jupyter Notebooks for immediate personalized feedback",
      "title_zh": "Py",
      "authors": [
        "Nils Wandel",
        "David Stotko",
        "Alexander Schier",
        "Reinhard Klein"
      ],
      "abstract": "Grading student assignments in STEM courses is a laborious and repetitive\ntask for tutors, often requiring a week to assess an entire class. For\nstudents, this delay of feedback prevents iterating on incorrect solutions,\nhampers learning, and increases stress when exercise scores determine admission\nto the final exam. Recent advances in AI-assisted education, such as automated\ngrading and tutoring systems, aim to address these challenges by providing\nimmediate feedback and reducing grading workload. However, existing solutions\noften fall short due to privacy concerns, reliance on proprietary closed-source\nmodels, lack of support for combining Markdown, LaTeX and Python code, or\nexcluding course tutors from the grading process. To overcome these\nlimitations, we introduce PyEvalAI, an AI-assisted evaluation system, which\nautomatically scores Jupyter notebooks using a combination of unit tests and a\nlocally hosted language model to preserve privacy. Our approach is free,\nopen-source, and ensures tutors maintain full control over the grading process.\nA case study demonstrates its effectiveness in improving feedback speed and\ngrading efficiency for exercises in a university-level course on numerics.",
      "tldr_zh": "该研究针对STEM课程中评分任务的繁重和学生反馈延迟问题，引入PyEvalAI——一个AI-assisted评估系统，用于自动评分Jupyter Notebooks。PyEvalAI结合unit tests和本地托管language model，确保隐私保护、开源免费，并让tutors保持对评分过程的完全控制。该系统通过案例研究证明，在大学数值课程中显著提高了反馈速度和评分效率，为AI-assisted教育提供了实用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18425v1",
      "published_date": "2025-02-25 18:20:20 UTC",
      "updated_date": "2025-02-25 18:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:38:51.360874"
    },
    {
      "arxiv_id": "2502.18553v3",
      "title": "Applications of Statistical Field Theory in Deep Learning",
      "title_zh": "统计场论在深度学习中的应用",
      "authors": [
        "Zohar Ringel",
        "Noa Rubin",
        "Edo Mor",
        "Moritz Helias",
        "Inbar Seroussi"
      ],
      "abstract": "Deep learning algorithms have made incredible strides in the past decade, yet\ndue to their complexity, the science of deep learning remains in its early\nstages. Being an experimentally driven field, it is natural to seek a theory of\ndeep learning within the physics paradigm. As deep learning is largely about\nlearning functions and distributions over functions, statistical field theory,\na rich and versatile toolbox for tackling complex distributions over functions\n(fields) is an obvious choice of formalism. Research efforts carried out in the\npast few years have demonstrated the ability of field theory to provide useful\ninsights on generalization, implicit bias, and feature learning effects. Here\nwe provide a pedagogical review of this emerging line of research.",
      "tldr_zh": "本论文探讨了统计场理论（statistical field theory）在深度学习（deep learning）中的应用，以应对其复杂性和科学基础薄弱的问题。作者指出，由于深度学习涉及函数和分布的学习，统计场理论作为处理复杂函数分布的工具非常适合，并回顾了过去几年的相关研究。研究结果显示，该理论能提供对泛化（generalization）、隐式偏差（implicit bias）和特征学习（feature learning）等方面的有用见解，为深度学习的理论发展奠定基础。",
      "categories": [
        "stat.ML",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18553v3",
      "published_date": "2025-02-25 18:19:06 UTC",
      "updated_date": "2025-04-17 07:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:39:03.568863"
    },
    {
      "arxiv_id": "2502.18412v1",
      "title": "Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data",
      "title_zh": "翻译失败",
      "authors": [
        "Paula Santos"
      ],
      "abstract": "This study presents a comparative evaluation of a Variational Autoencoder\n(VAE) enhanced with Minimum Description Length (MDL) regularization against a\nStandard Autoencoder for reconstructing high-dimensional gynecological data.\nThe MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE)\nand more structured latent representations, driven by effective KL divergence\nregularization. Statistical analyses confirm these performance improvements are\nsignificant. Furthermore, the MDL-VAE shows consistent training and validation\nlosses and achieves efficient inference times, underscoring its robustness and\npractical viability. Our findings suggest that incorporating MDL principles\ninto VAE architectures can substantially improve data reconstruction and\ngeneralization, making it a promising approach for advanced applications in\nhealthcare data modeling and analysis.",
      "tldr_zh": "本研究比较了采用 Minimum Description Length (MDL) 正则化的 Variational Autoencoder (MDL-VAE) 与标准 VAE 在处理 202 年妇科数据时的表现。结果显示，MDL-VAE 在重建高维数据方面表现出显著优势，包括更低的重建错误（MSE、MAE、RMSE）和更结构化的潜在表示，这得益于有效的 KL divergence 正则化。统计分析证实了这些改进的显著性，且 MDL-VAE 实现了更一致的训练与验证损失以及高效的推理时间。总体而言，该方法证明了将 MDL 原则融入 VAE 架构可大幅提升数据重建和泛化能力，为医疗数据建模提供有前景的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pagas, 5 figures, 9th International Conference on Signal, Image\n  Processing (SIPO 2025), Vancouver CA",
      "pdf_url": "http://arxiv.org/pdf/2502.18412v1",
      "published_date": "2025-02-25 18:05:46 UTC",
      "updated_date": "2025-02-25 18:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:39:16.263265"
    },
    {
      "arxiv_id": "2502.18410v2",
      "title": "TSKANMixer: Kolmogorov-Arnold Networks with MLP-Mixer Model for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Young-Chae Hong",
        "Bei Xiao",
        "Yangho Chen"
      ],
      "abstract": "Time series forecasting has long been a focus of research across diverse\nfields, including economics, energy, healthcare, and traffic management. Recent\nworks have introduced innovative architectures for time series models, such as\nthe Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs)\nto enhance prediction accuracy by effectively capturing both spatial and\ntemporal dependencies within the data. In this paper, we investigate the\ncapabilities of the Kolmogorov-Arnold Networks (KANs) for time-series\nforecasting by modifying TSMixer with a KAN layer (TSKANMixer). Experimental\nresults demonstrate that TSKANMixer tends to improve prediction accuracy over\nthe original TSMixer across multiple datasets, ranking among the top-performing\nmodels compared to other time series approaches. Our results show that the KANs\nare promising alternatives to improve the performance of time series\nforecasting by replacing or extending traditional MLPs.",
      "tldr_zh": "该论文探讨了Kolmogorov-Arnold Networks (KANs) 在时间序列预测中的应用，通过将 KAN 层整合到 Time-Series Mixer (TSMixer) 中，创建出新的 TSKANMixer 模型，以提升预测准确性。TSKANMixer 修改了 TSMixer 的多层感知器 (MLPs) 结构，利用 KANs 更好地捕捉数据中的空间和时间依赖。实验结果显示，TSKANMixer 在多个数据集上优于原 TSMixer，并与其他时间序列模型相比表现出色，表明 KANs 可以作为传统 MLPs 的有效替代或扩展方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, 7 tables and accepted at the AI4TS: AI for Time\n  Series Analysis workshop, AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18410v2",
      "published_date": "2025-02-25 18:04:45 UTC",
      "updated_date": "2025-03-27 16:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:39:28.426237"
    },
    {
      "arxiv_id": "2502.18407v1",
      "title": "AgentRM: Enhancing Agent Generalization with Reward Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Xia",
        "Jingru Fan",
        "Weize Chen",
        "Siyu Yan",
        "Xin Cong",
        "Zhong Zhang",
        "Yaxi Lu",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Existing LLM-based agents have achieved strong performance on held-in tasks,\nbut their generalizability to unseen tasks remains poor. Hence, some recent\nwork focus on fine-tuning the policy model with more diverse tasks to improve\nthe generalizability. In this work, we find that finetuning a reward model to\nguide the policy model is more robust than directly finetuning the policy\nmodel. Based on this finding, we propose AgentRM, a generalizable reward model,\nto guide the policy model for effective test-time search. We comprehensively\ninvestigate three approaches to construct the reward model, including explicit\nreward modeling, implicit reward modeling and LLM-as-a-judge. We then use\nAgentRM to guide the answer generation with Best-of-N sampling and step-level\nbeam search. On four types of nine agent tasks, AgentRM enhances the base\npolicy model by $8.8$ points on average, surpassing the top general agent by\n$4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding\ngreater improvement of $12.6$ on LLaMA-3-70B policy model. As for the\nspecializability, AgentRM can also boost a finetuned policy model and\noutperform the top specialized agent by $11.4$ on three held-in tasks. Further\nanalysis verifies its effectiveness in test-time scaling. Codes will be\nreleased to facilitate the research in this area.",
      "tldr_zh": "该研究发现，直接微调策略模型(policy model)难以提升LLM-based agents在新任务上的泛化能力，而通过微调奖励模型(reward model)来指导策略模型更具鲁棒性。作者提出AgentRM，一种通用奖励模型，通过显式奖励建模(explicit reward modeling)、隐式奖励建模(implicit reward modeling)和LLM-as-a-judge三种方法构建，并结合Best-of-N sampling和step-level beam search优化答案生成。在九个代理任务上，AgentRM平均提升基线策略模型8.8点，比顶级通用代理高4.0点，并在LLaMA-3-70B模型上实现12.6点的弱到强泛化改进，同时还能增强已微调的策略模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18407v1",
      "published_date": "2025-02-25 17:58:02 UTC",
      "updated_date": "2025-02-25 17:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:39:41.182909"
    },
    {
      "arxiv_id": "2502.18406v1",
      "title": "The Gradient of Algebraic Model Counting",
      "title_zh": "代数模型计数的梯度",
      "authors": [
        "Jaron Maene",
        "Luc De Raedt"
      ],
      "abstract": "Algebraic model counting unifies many inference tasks on logic formulas by\nexploiting semirings. Rather than focusing on inference, we consider learning,\nespecially in statistical-relational and neurosymbolic AI, which combine\nlogical, probabilistic and neural representations. Concretely, we show that the\nvery same semiring perspective of algebraic model counting also applies to\nlearning. This allows us to unify various learning algorithms by generalizing\ngradients and backpropagation to different semirings. Furthermore, we show how\ncancellation and ordering properties of a semiring can be exploited for more\nmemory-efficient backpropagation. This allows us to obtain some interesting\nvariations of state-of-the-art gradient-based optimisation methods for\nprobabilistic logical models. We also discuss why algebraic model counting on\ntractable circuits does not lead to more efficient second-order optimization.\nEmpirically, our algebraic backpropagation exhibits considerable speed-ups as\ncompared to existing approaches.",
      "tldr_zh": "该论文将 algebraic model counting 的 semiring 视角扩展到学习领域，特别是 statistical-relational 和 neurosymbolic AI 中，统一了逻辑、概率和神经表示的学习算法。通过泛化 gradients 和 backpropagation 到不同 semirings，作者利用 semiring 的 cancellation 和 ordering properties 实现了更内存高效的 backpropagation，从而衍生出对 probabilistic logical models 的优化变体。实验结果显示，algebraic backpropagation 比现有方法显著提速，但作者也指出，在 tractable circuits 上，该方法不会带来更有效的 second-order optimization。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18406v1",
      "published_date": "2025-02-25 17:57:55 UTC",
      "updated_date": "2025-02-25 17:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:39:52.768079"
    },
    {
      "arxiv_id": "2502.18387v2",
      "title": "How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Minhua Lin",
        "Hui Liu",
        "Xianfeng Tang",
        "Jingying Zeng",
        "Zhenwei Dai",
        "Chen Luo",
        "Zheng Li",
        "Xiang Zhang",
        "Qi He",
        "Suhang Wang"
      ],
      "abstract": "Search plays a fundamental role in problem-solving across various domains,\nwith most real-world decision-making problems being solvable through systematic\nsearch. Drawing inspiration from recent discussions on search and learning, we\nsystematically explore the complementary relationship between search and Large\nLanguage Models (LLMs) from three perspectives. First, we analyze how learning\ncan enhance search efficiency and propose Search via Learning (SeaL), a\nframework that leverages LLMs for effective and efficient search. Second, we\nfurther extend SeaL to SeaL-C to ensure rigorous completeness during search.\nOur evaluation across three real-world planning tasks demonstrates that SeaL\nachieves near-perfect accuracy while reducing search spaces by up to 99.1%\ncompared to traditional approaches. Finally, we explore how far LLMs are from\nreal search by investigating whether they can develop search capabilities\nindependently. Our analysis reveals that while current LLMs struggle with\nefficient search in complex problems, incorporating systematic search\nstrategies significantly enhances their problem-solving capabilities. These\nfindings not only validate the effectiveness of our approach but also highlight\nthe need for improving LLMs' search abilities for real-world applications.",
      "tldr_zh": "本研究系统探讨了大型语言模型(LLMs)与真实搜索的差距，从效率、完整性和内在能力三个角度分析二者的互补关系。论文提出Search via Learning (SeaL)框架，利用LLMs提升搜索效率，并在扩展版本SeaL-C中确保搜索的完整性；在三个真实世界规划任务的评估中，SeaL实现了近乎完美的准确率，同时将搜索空间减少高达99.1%。结果表明，当前LLMs在复杂问题中难以独立进行高效搜索，但通过整合系统搜索策略可显著增强其问题解决能力，强调了提升LLMs搜索能力的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 9 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18387v2",
      "published_date": "2025-02-25 17:30:40 UTC",
      "updated_date": "2025-02-26 06:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:40:06.238237"
    },
    {
      "arxiv_id": "2502.18373v1",
      "title": "EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Hollidt",
        "Paul Streli",
        "Jiaxi Jiang",
        "Yasaman Haghighi",
        "Changlin Qian",
        "Xintong Liu",
        "Christian Holz"
      ],
      "abstract": "Research on egocentric tasks in computer vision has mostly focused on\nhead-mounted cameras, such as fisheye cameras or embedded cameras inside\nimmersive headsets. We argue that the increasing miniaturization of optical\nsensors will lead to the prolific integration of cameras into many more\nbody-worn devices at various locations. This will bring fresh perspectives to\nestablished tasks in computer vision and benefit key areas such as human motion\ntracking, body pose estimation, or action recognition -- particularly for the\nlower body, which is typically occluded.\n  In this paper, we introduce EgoSim, a novel simulator of body-worn cameras\nthat generates realistic egocentric renderings from multiple perspectives\nacross a wearer's body. A key feature of EgoSim is its use of real motion\ncapture data to render motion artifacts, which are especially noticeable with\narm- or leg-worn cameras. In addition, we introduce MultiEgoView, a dataset of\negocentric footage from six body-worn cameras and ground-truth full-body 3D\nposes during several activities: 119 hours of data are derived from AMASS\nmotion sequences in four high-fidelity virtual environments, which we augment\nwith 5 hours of real-world motion data from 13 participants using six GoPro\ncameras and 3D body pose references from an Xsens motion capture suit.\n  We demonstrate EgoSim's effectiveness by training an end-to-end video-only 3D\npose estimation network. Analyzing its domain gap, we show that our dataset and\nsimulator substantially aid training for inference on real-world data.\n  EgoSim code & MultiEgoView dataset: https://siplab.org/projects/EgoSim",
      "tldr_zh": "本文提出 EgoSim，一种新型模拟器，用于生成身体穿戴相机（如手臂或腿部）的多视角 egocentric 渲染，并利用真实动作捕捉数据模拟运动伪影，以解决传统头戴相机在 human motion tracking 和 body pose estimation 中的局限。研究同时引入 MultiEgoView 数据集，包含 119 小时基于 AMASS 序列的模拟数据和 5 小时来自 13 名参与者的真实世界视频数据，涵盖多种活动并提供地面真实的全身 3D 姿势。实验通过训练端到端的视频-only 3D pose estimation 网络，证明 EgoSim 和数据集显著缩小了模拟与真实世界的领域差距，提升了在实际场景中的性能。该工作为 action recognition 等领域带来新视角，尤其在处理下肢遮挡问题上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18373v1",
      "published_date": "2025-02-25 17:11:14 UTC",
      "updated_date": "2025-02-25 17:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:40:18.011110"
    },
    {
      "arxiv_id": "2502.18371v1",
      "title": "MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sepehr Asgarian",
        "Qayam Jetha",
        "Jouhyun Jeon"
      ],
      "abstract": "In the competitive landscape of advertising, success hinges on effectively\nnavigating and leveraging complex interactions among consumers, advertisers,\nand advertisement platforms. These multifaceted interactions compel advertisers\nto optimize strategies for modeling consumer behavior, enhancing brand recall,\nand tailoring advertisement content. To address these challenges, we present\nMindMem, a multimodal predictive model for advertisement memorability. By\nintegrating textual, visual, and auditory data, MindMem achieves\nstate-of-the-art performance, with a Spearman's correlation coefficient of\n0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently\nsurpassing existing methods. Furthermore, our analysis identified key factors\ninfluencing advertisement memorability, such as video pacing, scene complexity,\nand emotional resonance. Expanding on this, we introduced MindMem-ReAd\n(MindMem-Driven Re-generated Advertisement), which employs Large Language\nModel-based simulations to optimize advertisement content and placement,\nresulting in up to a 74.12% improvement in advertisement memorability. Our\nresults highlight the transformative potential of Artificial Intelligence in\nadvertising, offering advertisers a robust tool to drive engagement, enhance\ncompetitiveness, and maximize impact in a rapidly evolving market.",
      "tldr_zh": "本研究提出MindMem，一种多模态模型，使用LLMs和深度学习整合文本、视觉和听觉数据，来预测广告的可记忆性，并在LAMBDA数据集上达到0.631的Spearman's correlation coefficient，在Memento10K上达到0.731，超越现有方法。分析识别了关键影响因素，包括视频节奏、场景复杂度和情感共鸣。进一步，研究引入MindMem-ReAd，通过LLMs模拟优化广告内容和放置，实现高达74.12%的可记忆性提升。该工作突显了AI在广告领域的潜力，帮助广告商提升参与度、竞争力和整体影响力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures, 4 Tables, AAAI 2025 Economics of Modern ML:\n  Markets, Incentives, and Generative AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2502.18371v1",
      "published_date": "2025-02-25 17:09:12 UTC",
      "updated_date": "2025-02-25 17:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:40:29.851547"
    },
    {
      "arxiv_id": "2502.18357v1",
      "title": "Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica He",
        "Stephanie Houde",
        "Justin D. Weisz"
      ],
      "abstract": "AI systems powered by large language models can act as capable assistants for\nwriting and editing. In these tasks, the AI system acts as a co-creative\npartner, making novel contributions to an artifact-under-creation alongside its\nhuman partner(s). One question that arises in these scenarios is the extent to\nwhich AI should be credited for its contributions. We examined knowledge\nworkers' views of attribution through a survey study (N=155) and found that\nthey assigned different levels of credit across different contribution types,\namounts, and initiative. Compared to a human partner, we observed a consistent\npattern in which AI was assigned less credit for equivalent contributions.\nParticipants felt that disclosing AI involvement was important and used a\nvariety of criteria to make attribution judgments, including the quality of\ncontributions, personal values, and technology considerations. Our results\nmotivate and inform new approaches for crediting AI contributions to co-created\nwork.",
      "tldr_zh": "本研究探讨了在人类-AI 合作创作中，AI 贡献应获得多少信用的问题，通过对 155 名知识工作者的调查，分析了不同贡献类型、数量和主动性对归因的影响。结果显示，与人类伙伴相比，AI 为相同贡献获得较少的信用，且参与者使用多种标准（如贡献质量、个人价值观和技术考虑）进行判断，同时认为披露 AI 参与至关重要。这些发现为开发新的 AI 贡献归因方法提供了重要指导和启发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "30 pages, 5 figures. In CHI Conference on Human Factors in Computing\n  Systems (CHI '25), April 26-May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2502.18357v1",
      "published_date": "2025-02-25 16:48:10 UTC",
      "updated_date": "2025-02-25 16:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:40:40.265063"
    },
    {
      "arxiv_id": "2503.05770v1",
      "title": "Generative Artificial Intelligence: Evolving Technology, Growing Societal Impact, and Opportunities for Information Systems Research",
      "title_zh": "生成式人工智能：演进的技术、日益增长的社会影响，以及信息系统研究的机会",
      "authors": [
        "Veda C. Storey",
        "Wei Thoo Yue",
        "J. Leon Zhao",
        "Roman Lukyanenko"
      ],
      "abstract": "The continuing, explosive developments in generative artificial intelligence\n(GenAI), built on large language models and related algorithms, has led to much\nexcitement and speculation about the potential impact of this new technology.\nClaims include AI being poised to revolutionize business and society and\ndramatically change personal life. However, it remains unclear exactly how this\ntechnology, with its significantly distinct features from past AI technologies,\nhas transformative potential. Nor is it clear how researchers in information\nsystems (IS) should respond. In this paper, we consider the evolving and\nemerging trends of AI in order to examine its present and predict its future\nimpacts. Many existing papers on GenAI are either too technical for most IS\nresearchers or lack the depth needed to appreciate the potential impacts of\nGenAI. We, therefore, attempt to bridge the technical and organizational\ncommunities of GenAI from a system-oriented sociotechnical perspective.\nSpecifically, we explore the unique features of GenAI, which are rooted in the\ncontinued change from symbolism to connectionism, and the deep systemic and\ninherent properties of human-AI ecosystems. We retrace the evolution of AI that\nproceeded the level of adoption, adaption, and use found today, in order to\npropose future research on various impacts of GenAI in both business and\nsociety within the context of information systems research. Our efforts are\nintended to contribute to the creation of a well-structured research agenda in\nthe IS community to support innovative strategies and operations enabled by\nthis new wave of AI.",
      "tldr_zh": "该论文探讨生成式人工智能(GenAI)的快速发展及其对商业、社会和个人生活的潜在革命性影响，强调GenAI与以往AI技术的显著差异。作者从系统导向的 sociotechnical 视角分析GenAI的独特特征，包括从symbolism到connectionism的转变，以及human-AI ecosystems的深层属性，以桥接技术与组织社区。论文回顾AI演变历史，提出信息系统(IS)研究议程，聚焦GenAI在商业和社会中的影响，并为创新策略和运营提供结构化指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05770v1",
      "published_date": "2025-02-25 16:34:23 UTC",
      "updated_date": "2025-02-25 16:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:40:53.087155"
    },
    {
      "arxiv_id": "2502.18328v1",
      "title": "From Vision to Sound: Advancing Audio Anomaly Detection with Vision-Based Algorithms",
      "title_zh": "从视觉",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Davide Dalle Pezze",
        "Francesco Paissan",
        "Elisabetta Farella",
        "Gian Antonio Susto"
      ],
      "abstract": "Recent advances in Visual Anomaly Detection (VAD) have introduced\nsophisticated algorithms leveraging embeddings generated by pre-trained feature\nextractors. Inspired by these developments, we investigate the adaptation of\nsuch algorithms to the audio domain to address the problem of Audio Anomaly\nDetection (AAD). Unlike most existing AAD methods, which primarily classify\nanomalous samples, our approach introduces fine-grained temporal-frequency\nlocalization of anomalies within the spectrogram, significantly improving\nexplainability. This capability enables a more precise understanding of where\nand when anomalies occur, making the results more actionable for end users. We\nevaluate our approach on industrial and environmental benchmarks, demonstrating\nthe effectiveness of VAD techniques in detecting anomalies in audio signals.\nMoreover, they improve explainability by enabling localized anomaly\nidentification, making audio anomaly detection systems more interpretable and\npractical.",
      "tldr_zh": "本研究受视觉异常检测 (VAD) 算法的启发，将其适应到音频异常检测 (AAD) 领域，使用预训练特征提取器生成的嵌入来处理音频信号。不同于传统 AAD 方法，该方法不仅分类异常样本，还实现了频谱图 (spectrogram) 中的精细时间-频率定位，提高了异常的可解释性和实用性。实验在工业和环境基准上验证了其有效性，展示了 VAD 技术在音频信号异常检测中的潜力，并使系统更易于解释和应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18328v1",
      "published_date": "2025-02-25 16:22:42 UTC",
      "updated_date": "2025-02-25 16:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:41:03.920498"
    },
    {
      "arxiv_id": "2502.18315v1",
      "title": "GraphRank Pro+: Advancing Talent Analytics Through Knowledge Graphs and Sentiment-Enhanced Skill Profiling",
      "title_zh": "翻译失败",
      "authors": [
        "Sirisha Velampalli",
        "Chandrashekar Muniyappa"
      ],
      "abstract": "The extraction of information from semi-structured text, such as resumes, has\nlong been a challenge due to the diverse formatting styles and subjective\ncontent organization. Conventional solutions rely on specialized logic tailored\nfor specific use cases. However, we propose a revolutionary approach leveraging\nstructured Graphs, Natural Language Processing (NLP), and Deep Learning. By\nabstracting intricate logic into Graph structures, we transform raw data into a\ncomprehensive Knowledge Graph. This innovative framework enables precise\ninformation extraction and sophisticated querying. We systematically construct\ndictionaries assigning skill weights, paving the way for nuanced talent\nanalysis. Our system not only benefits job recruiters and curriculum designers\nbut also empowers job seekers with targeted query-based filtering and ranking\ncapabilities.",
      "tldr_zh": "该论文提出GraphRank Pro+，一种创新方法，通过Knowledge Graphs、Natural Language Processing (NLP) 和Deep Learning处理半结构化文本（如简历）的提取挑战，将复杂逻辑抽象为图结构，构建全面的Knowledge Graph以实现精确信息提取和高级查询。系统还构建了分配技能权重的字典，并融入Sentiment-Enhanced Skill Profiling，实现细致的才能分析。最终，该框架不仅帮助招聘人员和课程设计师，还为求职者提供针对性查询、过滤和排名功能，提升了整体人才分析效率。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "05C81",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18315v1",
      "published_date": "2025-02-25 16:07:40 UTC",
      "updated_date": "2025-02-25 16:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:41:16.764899"
    },
    {
      "arxiv_id": "2502.18548v3",
      "title": "What is the Alignment Objective of GRPO?",
      "title_zh": "什么是 GRPO 的对齐目标？",
      "authors": [
        "Milan Vojnovic",
        "Se-Young Yun"
      ],
      "abstract": "In this note, we examine the aggregation of preferences achieved by the Group\nPolicy Optimisation (GRPO) algorithm, a reinforcement learning method used to\ntrain advanced artificial intelligence models such as DeepSeek-R1-Zero and\nDeepSeekMath. The GRPO algorithm trains a policy using a reward preference\nmodel, which is computed by sampling a set of outputs for a given context,\nobserving the corresponding rewards, and applying shift-and-scale normalisation\nto these reward values. Additionally, it incorporates a penalty function to\ndiscourage deviations from a reference policy.\n  We present a framework that enables us to characterise the stationary\npolicies of the GRPO algorithm. This analysis reveals that the aggregation of\npreferences differs fundamentally from standard logarithmic pooling, which is\nimplemented by other approaches such as RLHF. The precise form of preference\naggregation arises from the way the reward preference model is defined and from\nthe penalty function, which we show to essentially correspond to the reverse\nKullback-Leibler (KL) divergence between the aggregation policy and the\nreference policy.\n  Interestingly, we demonstrate that for groups of size two, the reward\npreference model corresponds to pairwise comparison preferences, similar to\nthose in other alignment methods based on pairwise comparison feedback. We\nprovide explicit characterisations of the aggregate preference for binary\nquestions, for groups of size two, and in the limit of large group size. This\nprovides insights into the dependence of the aggregate preference on parameters\nsuch as the regularisation constant and the confidence margin of question\nanswers.\n  Finally, we discuss the aggregation of preferences obtained by modifying the\nGRPO algorithm to use direct KL divergence as the penalty or to use rewards\nwithout scale normalisation.",
      "tldr_zh": "本研究分析了 Group Policy Optimisation (GRPO) 算法在训练 AI 模型（如 DeepSeek-R1-Zero 和 DeepSeekMath）时的偏好聚合机制，该算法使用奖励偏好模型结合 shift-and-scale normalisation 和惩罚函数，以避免偏离参考策略。作者通过一个框架表征了 GRPO 的平稳策略，发现其偏好聚合不同于标准对数池化（如 RLHF），而更类似于反向 Kullback-Leibler (KL) 散度。研究还提供了聚合偏好的显式表征，包括大小为二的组中类似于成对比较的偏好，以及在大组极限下的行为，并讨论了修改算法（如使用直接 KL 散度或无尺度规范化的奖励）对偏好聚合的影响。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18548v3",
      "published_date": "2025-02-25 15:56:56 UTC",
      "updated_date": "2025-03-13 16:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:41:28.864890"
    },
    {
      "arxiv_id": "2502.18547v2",
      "title": "Steganography Beyond Space-Time with Chain of Multimodal AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ching-Chun Chang",
        "Isao Echizen"
      ],
      "abstract": "Steganography is the art and science of covert writing, with a broad range of\napplications interwoven within the realm of cybersecurity. As artificial\nintelligence continues to evolve, its ability to synthesise realistic content\nemerges as a threat in the hands of cybercriminals who seek to manipulate and\nmisrepresent the truth. Such synthetic content introduces a non-trivial risk of\noverwriting the subtle changes made for the purpose of steganography. When the\nsignals in both the spatial and temporal domains are vulnerable to unforeseen\noverwriting, it calls for reflection on what, if any, remains invariant. This\nstudy proposes a paradigm in steganography for audiovisual media, where\nmessages are concealed beyond both spatial and temporal domains. A chain of\nmultimodal artificial intelligence is developed to deconstruct audiovisual\ncontent into a cover text, embed a message within the linguistic domain, and\nthen reconstruct the audiovisual content through synchronising both auditory\nand visual modalities with the resultant stego text. The message is encoded by\nbiasing the word sampling process of a language generation model and decoded by\nanalysing the probability distribution of word choices. The accuracy of message\ntransmission is evaluated under both zero-bit and multi-bit capacity settings.\nFidelity is assessed through both biometric and semantic similarities,\ncapturing the identities of the recorded face and voice, as well as the core\nideas conveyed through the media. Secrecy is examined through statistical\ncomparisons between cover and stego texts. Robustness is tested across various\nscenarios, including audiovisual resampling, face-swapping, voice-cloning and\ntheir combinations.",
      "tldr_zh": "本研究提出了一种超越空间和时间域的隐写术（Steganography）新范式，利用Chain of Multimodal AI链条，将消息隐藏在语言域中。方法包括通过多模态AI解构视听内容为覆盖文本、在语言生成模型的单词采样过程中偏置编码消息、并同步重建视听内容以确保消息传输准确性。实验评估显示，该方法在零位和多位容量设置下表现出高准确性，同时在保真度（通过生物特征和语义相似性）、隐秘性（统计比较）和鲁棒性（抵抗视听重采样、换脸和语音克隆等攻击）方面表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA",
        "cs.MM"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18547v2",
      "published_date": "2025-02-25 15:56:09 UTC",
      "updated_date": "2025-04-20 02:50:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:41:42.249104"
    },
    {
      "arxiv_id": "2502.18298v1",
      "title": "Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Taha Ahmadi Pargo",
        "Mohsen Akbarpour Shirazi",
        "Dawud Fadai"
      ],
      "abstract": "Regarding problems like reduced precipitation and an increase in population,\nwater resource scarcity has become one of the most critical problems in\nmodern-day societies, as a consequence, there is a shortage of available water\nresources for irrigation in arid and semi-arid countries. On the other hand, it\nis possible to utilize modern technologies to control irrigation and reduce\nwater loss. One of these technologies is the Internet of Things (IoT). Despite\nthe possibility of using the IoT in irrigation control systems, there are\ncomplexities in designing such systems. Considering this issue, it is possible\nto use agent-oriented software engineering (AOSE) methodologies to design\ncomplex cyber-physical systems such as IoT-based systems. In this research, a\nsmart irrigation system is designed based on Prometheus AOSE methodology, to\nreduce water loss by maintaining soil moisture in a suitable interval. The\ndesigned system comprises sensors, a central agent, and irrigation nodes. These\nagents follow defined rules to maintain soil moisture at a desired level\ncooperatively. For system simulation, a hybrid agent-based and system dynamics\nmodel was designed. In this hybrid model, soil moisture dynamics were modeled\nbased on the system dynamics approach. The proposed model, was implemented in\nAnyLogic computer simulation software. Utilizing the simulation model,\nirrigation rules were examined. The system's functionality in automatic\nirrigation mode was tested based on a 256-run, fractional factorial design, and\nthe effects of important factors such as soil properties on total irrigated\nwater and total operation time were analyzed. Based on the tests, the system\nconsistently irrigated nearly optimal water amounts in all tests. Moreover, the\nresults were also used to minimize the system's energy consumption by reducing\nthe system's operational time.",
      "tldr_zh": "该研究针对水资源短缺问题，设计了一个基于物联网 (IoT) 的智能灌溉系统，利用 Prometheus AOSE 方法ology 减少灌溉水损失。系统由传感器、中央代理和灌溉节点组成，这些代理遵循预定义规则合作保持土壤湿度在合适水平。研究采用混合代理-based 和系统动态模型，在 AnyLogic 软件中进行模拟，并通过 256 次分数析因设计实验分析了土壤特性等因素对灌溉水量和操作时间的影响。结果表明，该系统在所有测试中实现了近乎最优的灌溉水量，并通过减少系统运行时间有效最小化了能源消耗。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "stat.AP",
        "I.6.6, I.2.1, J.2"
      ],
      "primary_category": "cs.MA",
      "comment": "50 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18298v1",
      "published_date": "2025-02-25 15:34:38 UTC",
      "updated_date": "2025-02-25 15:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:41:55.364907"
    },
    {
      "arxiv_id": "2502.18296v1",
      "title": "Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "James C. A. Main",
        "Mickael Randour"
      ],
      "abstract": "We consider multi-dimensional payoff functions in Markov decision processes,\nand ask whether a given expected payoff vector can be achieved or not. In\ngeneral, pure strategies (i.e., not resorting to randomisation) do not suffice\nfor this problem.\n  We study the structure of the set of expected payoff vectors of all\nstrategies given a multi-dimensional payoff function and its consequences\nregarding randomisation requirements for strategies. In particular, we prove\nthat for any payoff for which the expectation is well-defined under all\nstrategies, it is sufficient to mix (i.e., randomly select a pure strategy at\nthe start of a play and committing to it for the rest of the play) finitely\nmany pure strategies to approximate any expected payoff vector up to any\nprecision. Furthermore, for any payoff for which the expected payoff is finite\nunder all strategies, any expected payoff can be obtained exactly by mixing\nfinitely many strategies.",
      "tldr_zh": "本研究探讨了多目标Markov决策过程(MDPs)中回报集的结构，以及其对随机策略的影响。论文证明，对于回报期望在所有策略下定义的支付函数，仅需混合有限数量的纯策略，即可任意精度逼近任何期望回报向量；若期望回报在所有策略下有限，则可以通过混合有限策略精确实现任何期望回报。纯策略往往不足以解决问题，这一发现为优化多维回报函数的随机化策略提供了理论基础。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.FL",
        "cs.LO",
        "math.PR"
      ],
      "primary_category": "cs.GT",
      "comment": "64 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.18296v1",
      "published_date": "2025-02-25 15:33:59 UTC",
      "updated_date": "2025-02-25 15:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:42:04.401799"
    },
    {
      "arxiv_id": "2502.18293v1",
      "title": "AMPO: Active Multi-Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Taneesh Gupta",
        "Rahul Madhavan",
        "Xuchao Zhang",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "Multi-preference optimization enriches language-model alignment beyond\npairwise preferences by contrasting entire sets of helpful and undesired\nresponses, thereby enabling richer training signals for large language models.\nDuring self-play alignment, these models often produce numerous candidate\nanswers per query, rendering it computationally infeasible to include all\nresponses in the training objective. In this work, we propose $\\textit{Active\nMulti-Preference Optimization}$ (AMPO), a novel approach that combines\non-policy generation, a multi-preference group-contrastive loss, and active\nsubset selection. Specifically, we score and embed large candidate pools of\nresponses and then select a small, yet informative, subset that covers reward\nextremes and distinct semantic clusters for preference optimization. Our\ncontrastive training scheme is capable of identifying not only the best and\nworst answers but also subtle, underexplored modes that are crucial for robust\nalignment. Theoretically, we provide guarantees for expected reward\nmaximization using our active selection method, and empirically, AMPO achieves\nstate-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B.",
      "tldr_zh": "这篇论文提出了 AMPO（Active Multi-Preference Optimization），一种创新方法，用于超越成对偏好的多偏好优化，以丰富大型语言模型的训练信号。AMPO 结合 on-policy 生成、多偏好组对比损失和主动子集选择，通过对候选响应进行评分和嵌入，选择覆盖奖励极端和语义集群的子集，从而识别最佳、最差答案以及微妙模式。实验结果显示，AMPO 在 AlpacaEval 上使用 Llama 8B 模型达到了最先进性能，并提供了预期奖励最大化的理论保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18293v1",
      "published_date": "2025-02-25 15:29:51 UTC",
      "updated_date": "2025-02-25 15:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:42:17.855317"
    },
    {
      "arxiv_id": "2502.18274v2",
      "title": "Citrus: Leveraging Expert Cognitive Pathways in a Medical Language Model for Advanced Medical Decision Support",
      "title_zh": "翻译失败",
      "authors": [
        "Guoxin Wang",
        "Minyu Gao",
        "Shuai Yang",
        "Ya Zhang",
        "Lizhi He",
        "Liang Huang",
        "Hanlin Xiao",
        "Yexuan Zhang",
        "Wanyue Li",
        "Lu Chen",
        "Jintao Fei",
        "Xin Li"
      ],
      "abstract": "Large language models (LLMs), particularly those with reasoning capabilities,\nhave rapidly advanced in recent years, demonstrating significant potential\nacross a wide range of applications. However, their deployment in healthcare,\nespecially in disease reasoning tasks, is hindered by the challenge of\nacquiring expert-level cognitive data. In this paper, we introduce Citrus, a\nmedical language model that bridges the gap between clinical expertise and AI\nreasoning by emulating the cognitive processes of medical experts. The model is\ntrained on a large corpus of simulated expert disease reasoning data,\nsynthesized using a novel approach that accurately captures the decision-making\npathways of clinicians. This approach enables Citrus to better simulate the\ncomplex reasoning processes involved in diagnosing and treating medical\nconditions. To further address the lack of publicly available datasets for\nmedical reasoning tasks, we release the last-stage training data, including a\ncustom-built medical diagnostic dialogue dataset. This open-source contribution\naims to support further research and development in the field. Evaluations\nusing authoritative benchmarks such as MedQA, covering tasks in medical\nreasoning and language understanding, show that Citrus achieves superior\nperformance compared to other models of similar size. These results highlight\nCitrus potential to significantly enhance medical decision support systems,\nproviding a more accurate and efficient tool for clinical decision-making.",
      "tldr_zh": "本研究引入了 Citrus，一种医疗语言模型，通过模拟专家的认知路径（如决策流程）来提升 AI 在医疗决策支持中的表现，解决了获取专家级数据挑战。Citrus 采用新型方法合成大规模专家疾病推理数据进行训练，并发布了开源数据集，包括自定义的医疗诊断对话数据集，以支持进一步研究。在 MedQA 等权威基准测试中，Citrus 比同规模模型表现出色，显著提高了医疗推理任务的准确性和效率。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18274v2",
      "published_date": "2025-02-25 15:05:12 UTC",
      "updated_date": "2025-02-26 02:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:42:29.128385"
    },
    {
      "arxiv_id": "2502.18545v1",
      "title": "PII-Bench: Evaluating Query-Aware Privacy Protection Systems",
      "title_zh": "PII-Bench：评估查询感知隐私保护系统",
      "authors": [
        "Hao Shen",
        "Zhouhong Gu",
        "Haokai Hong",
        "Weili Han"
      ],
      "abstract": "The widespread adoption of Large Language Models (LLMs) has raised\nsignificant privacy concerns regarding the exposure of personally identifiable\ninformation (PII) in user prompts. To address this challenge, we propose a\nquery-unrelated PII masking strategy and introduce PII-Bench, the first\ncomprehensive evaluation framework for assessing privacy protection systems.\nPII-Bench comprises 2,842 test samples across 55 fine-grained PII categories,\nfeaturing diverse scenarios from single-subject descriptions to complex\nmulti-party interactions. Each sample is carefully crafted with a user query,\ncontext description, and standard answer indicating query-relevant PII. Our\nempirical evaluation reveals that while current models perform adequately in\nbasic PII detection, they show significant limitations in determining PII query\nrelevance. Even state-of-the-art LLMs struggle with this task, particularly in\nhandling complex multi-subject scenarios, indicating substantial room for\nimprovement in achieving intelligent PII masking.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在用户提示中暴露 personally identifiable information (PII) 的隐私问题，提出了一种 query-unrelated PII masking strategy，并引入了 PII-Bench，这是首个全面评估框架。PII-Bench 包含 2,842 个测试样本，覆盖 55 个细粒度 PII 类别，从单主体描述到复杂多方互动，每个样本包括用户查询、上下文描述和标准答案以标识查询相关 PII。实验评估显示，当前模型在基本 PII 检测方面表现尚可，但在线判断 PII 与查询相关性上存在显著缺陷，特别是处理多主体场景时，即使是先进的 LLMs 也面临挑战，表明智能 PII 屏蔽技术仍有较大改进空间。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18545v1",
      "published_date": "2025-02-25 14:49:08 UTC",
      "updated_date": "2025-02-25 14:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:42:42.548425"
    },
    {
      "arxiv_id": "2502.18220v1",
      "title": "UASTrack: A Unified Adaptive Selection Framework with Modality-Customization in Single Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "He Wang",
        "Tianyang Xu",
        "Zhangyong Tang",
        "Xiao-Jun Wu",
        "Josef Kittler"
      ],
      "abstract": "Multi-modal tracking is essential in single-object tracking (SOT), as\ndifferent sensor types contribute unique capabilities to overcome challenges\ncaused by variations in object appearance. However, existing unified RGB-X\ntrackers (X represents depth, event, or thermal modality) either rely on the\ntask-specific training strategy for individual RGB-X image pairs or fail to\naddress the critical importance of modality-adaptive perception in real-world\napplications. In this work, we propose UASTrack, a unified adaptive selection\nframework that facilitates both model and parameter unification, as well as\nadaptive modality discrimination across various multi-modal tracking tasks. To\nachieve modality-adaptive perception in joint RGB-X pairs, we design a\nDiscriminative Auto-Selector (DAS) capable of identifying modality labels,\nthereby distinguishing the data distributions of auxiliary modalities.\nFurthermore, we propose a Task-Customized Optimization Adapter (TCOA) tailored\nto various modalities in the latent space. This strategy effectively filters\nnoise redundancy and mitigates background interference based on the specific\ncharacteristics of each modality. Extensive comparisons conducted on five\nbenchmarks including LasHeR, GTOT, RGBT234, VisEvent, and DepthTrack, covering\nRGB-T, RGB-E, and RGB-D tracking scenarios, demonstrate our innovative approach\nachieves comparative performance by introducing only additional training\nparameters of 1.87M and flops of 1.95G. The code will be available at\nhttps://github.com/wanghe/UASTrack.",
      "tldr_zh": "本文提出UASTrack，一种统一的适应性选择框架，用于单对象跟踪中的多模态定制，旨在解决现有RGB-X跟踪器在模态自适应感知方面的不足。框架的核心组件包括Discriminative Auto-Selector (DAS)，用于识别模态标签并区分辅助模态的数据分布，以及Task-Customized Optimization Adapter (TCOA)，在潜在空间中针对不同模态过滤噪声并减少背景干扰。在五个基准测试（如LasHeR、GTOT等）中，UASTrack仅增加1.87M训练参数和1.95G FLOPs，就在RGB-T、RGB-E和RGB-D场景中实现了与基线方法相当的性能表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18220v1",
      "published_date": "2025-02-25 14:04:31 UTC",
      "updated_date": "2025-02-25 14:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:42:54.793275"
    },
    {
      "arxiv_id": "2502.18218v3",
      "title": "FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records",
      "title_zh": "FLARE：一种利用恒星物理属性和历史记录进行恒",
      "authors": [
        "Bingke Zhu",
        "Xiaoxiao Wang",
        "Minghui Jia",
        "Yihan Tao",
        "Xiao Kong",
        "Ali Luo",
        "Yingying Chen",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Stellar flare events are critical observational samples for astronomical\nresearch; however, recorded flare events remain limited. Stellar flare\nforecasting can provide additional flare event samples to support research\nefforts. Despite this potential, no specialized models for stellar flare\nforecasting have been proposed to date. In this paper, we present extensive\nexperimental evidence demonstrating that both stellar physical properties and\nhistorical flare records are valuable inputs for flare forecasting tasks. We\nthen introduce FLARE (Forecasting Light-curve-based Astronomical Records via\nfeatures Ensemble), the first-of-its-kind large model specifically designed for\nstellar flare forecasting. FLARE integrates stellar physical properties and\nhistorical flare records through a novel Soft Prompt Module and Residual Record\nFusion Module. Our experiments on the publicly available Kepler light curve\ndataset demonstrate that FLARE achieves superior performance compared to other\nmethods across all evaluation metrics. Finally, we validate the forecast\ncapability of our model through a comprehensive case study.",
      "tldr_zh": "该论文探讨了恒星耀斑预测的重要性，因为现有记录有限，通过预测可提供更多研究样本。研究者首次提出FLARE框架，这是一个专为恒星耀斑预报设计的大型模型，通过Soft Prompt Module和Residual Record Fusion Module整合恒星物理属性和历史耀斑记录。实验结果显示，FLARE在Kepler光曲线数据集上优于其他方法，并在全面案例研究中验证了其预测能力。",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18218v3",
      "published_date": "2025-02-25 14:03:15 UTC",
      "updated_date": "2025-05-22 10:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:43:04.365478"
    },
    {
      "arxiv_id": "2502.18209v1",
      "title": "LAG: LLM agents for Leaderboard Auto Generation on Demanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Wu",
        "Jiayu Zhang",
        "Dongyuan Li",
        "Linyi Yang",
        "Aoxiao Zhong",
        "Renhe Jiang",
        "Qingsong Wen",
        "Yue Zhang"
      ],
      "abstract": "This paper introduces Leaderboard Auto Generation (LAG), a novel and\nwell-organized framework for automatic generation of leaderboards on a given\nresearch topic in rapidly evolving fields like Artificial Intelligence (AI).\nFaced with a large number of AI papers updated daily, it becomes difficult for\nresearchers to track every paper's proposed methods, experimental results, and\nsettings, prompting the need for efficient automatic leaderboard construction.\nWhile large language models (LLMs) offer promise in automating this process,\nchallenges such as multi-document summarization, leaderboard generation, and\nexperiment fair comparison still remain under exploration. LAG solves these\nchallenges through a systematic approach that involves the paper collection,\nexperiment results extraction and integration, leaderboard generation, and\nquality evaluation. Our contributions include a comprehensive solution to the\nleaderboard construction problem, a reliable evaluation method, and\nexperimental results showing the high quality of leaderboards.",
      "tldr_zh": "本论文提出 LAG 框架，这是一种基于 LLM agents 的系统，用于自动生成特定研究主题（如 AI 领域）的排行榜（leaderboard），以帮助研究者高效跟踪众多论文的方法、实验结果和设置。LAG 通过系统化流程解决多文档摘要、排行榜生成和实验公平比较等挑战，包括论文收集、实验结果提取与整合、排行榜生成以及质量评估。该框架的贡献在于提供了一个全面的排行榜构建解决方案、可靠的评估方法，以及实验结果证明了其生成的高质量排行榜。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18209v1",
      "published_date": "2025-02-25 13:54:03 UTC",
      "updated_date": "2025-02-25 13:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:43:16.480474"
    },
    {
      "arxiv_id": "2502.18202v1",
      "title": "DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches",
      "title_zh": "DenoMAE2.0：通过分类局部补丁改进去噪掩码自动编码器",
      "authors": [
        "Atik Faysal",
        "Mohammad Rostami",
        "Taha Boushine",
        "Reihaneh Gh. Roshan",
        "Huaxia Wang",
        "Nikhil Muralidhar"
      ],
      "abstract": "We introduce DenoMAE2.0, an enhanced denoising masked autoencoder that\nintegrates a local patch classification objective alongside traditional\nreconstruction loss to improve representation learning and robustness. Unlike\nconventional Masked Autoencoders (MAE), which focus solely on reconstructing\nmissing inputs, DenoMAE2.0 introduces position-aware classification of unmasked\npatches, enabling the model to capture fine-grained local features while\nmaintaining global coherence. This dual-objective approach is particularly\nbeneficial in semi-supervised learning for wireless communication, where high\nnoise levels and data scarcity pose significant challenges. We conduct\nextensive experiments on modulation signal classification across a wide range\nof signal-to-noise ratios (SNRs), from extremely low to moderately high\nconditions and in a low data regime. Our results demonstrate that DenoMAE2.0\nsurpasses its predecessor, Deno-MAE, and other baselines in both denoising\nquality and downstream classification accuracy. DenoMAE2.0 achieves a 1.1%\nimprovement over DenoMAE on our dataset and 11.83%, 16.55% significant improved\naccuracy gains on the RadioML benchmark, over DenoMAE, for constellation\ndiagram classification of modulation signals.",
      "tldr_zh": "本研究提出DenoMAE2.0，一种改进的去噪掩码自动编码器(Denoising Masked Autoencoder)，通过整合局部补丁分类目标与传统的重建损失(reconstruction loss)，提升了表示学习和模型鲁棒性。不同于常规Masked Autoencoders (MAE)，DenoMAE2.0引入位置感知分类(position-aware classification)来捕获细粒度的局部特征，同时保持全局一致性，这在无线通信的半监督学习(semi-supervised learning)中特别有效，可应对高噪声水平和数据稀缺挑战。实验在调制信号分类任务上进行，涵盖各种信噪比(SNRs)条件，结果显示DenoMAE2.0在去噪质量和下游分类准确率上超过了前身Deno-MAE及其他基线模型，包括在自身数据集上提升1.1%，以及在RadioML基准上实现11.83%和16.55%的显著准确率改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18202v1",
      "published_date": "2025-02-25 13:41:56 UTC",
      "updated_date": "2025-02-25 13:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:43:30.744363"
    },
    {
      "arxiv_id": "2502.18185v3",
      "title": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with LoRA and Atrous Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Adnan Iltaf",
        "Rayan Merghani Ahmed",
        "Zhenxi Zhang",
        "Bin Li",
        "Shoujun Zhou"
      ],
      "abstract": "Medical image segmentation is crucial for clinical diagnosis and treatment\nplanning, especially when dealing with complex anatomical structures such as\nvessels. However, accurately segmenting vessels remains challenging due to\ntheir small size, intricate edge structures, and susceptibility to artifacts\nand imaging noise. In this work, we propose VesselSAM, an enhanced version of\nthe Segment Anything Model (SAM), specifically tailored for aortic vessel\nsegmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating\nAtrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation\nperformance. Atrous Attention enables the model to capture multi-scale\ncontextual information, preserving both fine-grained local details and broader\nglobal context. Additionally, LoRA facilitates efficient fine-tuning of the\nfrozen SAM image encoder, reducing the number of trainable parameters and\nthereby enhancing computational efficiency. We evaluate VesselSAM using two\nchallenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B\nAortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art\nperformance, attaining DSC scores of 93.50\\%, 93.25\\%, 93.02\\%, and 93.26\\%\nacross multi-center datasets. Our results demonstrate that VesselSAM delivers\nhigh segmentation accuracy while significantly reducing computational overhead\ncompared to existing large-scale models. This development paves the way for\nenhanced AI-based aortic vessel segmentation in clinical environments. The code\nand models will be released at https://github.com/Adnan-CAS/AtrousLora.",
      "tldr_zh": "该研究提出 VesselSAM，一种基于 Segment Anything Model (SAM) 的增强模型，针对主动脉血管分割问题，解决血管尺寸小、边缘复杂以及易受噪声干扰的挑战。VesselSAM 引入 AtrousLoRA 模块，将 Atrous Attention 用于捕捉多尺度上下文信息以保留局部细节和全局信息，同时利用 Low-Rank Adaptation (LoRA) 实现高效微调，减少可训练参数并提升计算效率。在 Aortic Vessel Tree (AVT) 和 Type-B Aortic Dissection (TBAD) 数据集上，VesselSAM 实现了 state-of-the-art 性能，DSC 分数高达 93.50%，显著优于现有模型。该方法为临床环境中 AI 辅助血管分割铺平了道路，并已开源代码。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.18185v3",
      "published_date": "2025-02-25 13:26:06 UTC",
      "updated_date": "2025-03-26 06:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:43:44.169977"
    },
    {
      "arxiv_id": "2502.18180v2",
      "title": "ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Li",
        "Sen Jia",
        "Jianhao Wang",
        "Zhaochong An",
        "Jiaang Li",
        "Jenq-Neng Hwang",
        "Serge Belongie"
      ],
      "abstract": "Advancements in Multimodal Large Language Models (MLLMs) have improved human\nmotion understanding. However, these models remain constrained by their\n\"instruct-only\" nature, lacking interactivity and adaptability for diverse\nanalytical perspectives. To address these challenges, we introduce ChatMotion,\na multimodal multi-agent framework for human motion analysis. ChatMotion\ndynamically interprets user intent, decomposes complex tasks into meta-tasks,\nand activates specialized function modules for motion comprehension. It\nintegrates multiple specialized modules, such as the MotionCore, to analyze\nhuman motion from various perspectives. Extensive experiments demonstrate\nChatMotion's precision, adaptability, and user engagement for human motion\nunderstanding.",
      "tldr_zh": "该研究引入了ChatMotion，一种多模态多智能体框架，旨在解决Multimodal Large Language Models (MLLMs)在人类运动分析中的互动性和适应性不足问题。ChatMotion通过动态解释用户意图，将复杂任务分解为元任务，并激活专用模块如MotionCore，从多种角度进行运动理解。实验结果证明，该框架在精确性、适应性和用户参与度上表现出显著优势。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18180v2",
      "published_date": "2025-02-25 13:12:55 UTC",
      "updated_date": "2025-02-27 13:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:43:54.669788"
    },
    {
      "arxiv_id": "2502.18179v1",
      "title": "Problem Solved? Information Extraction Design Space for Layout-Rich Documents using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Gaye Colakoglu",
        "Gürkan Solmaz",
        "Jonathan Fürst"
      ],
      "abstract": "This paper defines and explores the design space for information extraction\n(IE) from layout-rich documents using large language models (LLMs). The three\ncore challenges of layout-aware IE with LLMs are 1) data structuring, 2) model\nengagement, and 3) output refinement. Our study delves into the sub-problems\nwithin these core challenges, such as input representation, chunking,\nprompting, and selection of LLMs and multimodal models. It examines the\noutcomes of different design choices through a new layout-aware IE test suite,\nbenchmarking against the state-of-art (SoA) model LayoutLMv3. The results show\nthat the configuration from one-factor-at-a-time (OFAT) trial achieves\nnear-optimal results with 14.1 points F1-score gain from the baseline model,\nwhile full factorial exploration yields only a slightly higher 15.1 points gain\nat around 36x greater token usage. We demonstrate that well-configured\ngeneral-purpose LLMs can match the performance of specialized models, providing\na cost-effective alternative. Our test-suite is freely available at\nhttps://github.com/gayecolakoglu/LayIE-LLM.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）从布局丰富的文档中进行信息提取（IE）的设计空间，定义了三大核心挑战：数据结构化、模型参与和输出精炼。研究者分析了这些挑战下的子问题，包括输入表示、块划分、提示策略以及LLMs和多模态模型的选择，并通过一个新的布局感知IE测试套件与LayoutLMv3基准模型进行比较。结果显示，一因素一次（OFAT）试验的配置比基线模型提升14.1分F1分数，而全因子探索仅略高15.1分，但token使用量增加约36倍。论文证明，配置良好的通用LLMs可匹敌专业模型，提供更具成本效益的IE解决方案，并开源了测试套件。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18179v1",
      "published_date": "2025-02-25 13:11:53 UTC",
      "updated_date": "2025-02-25 13:11:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:44:08.139203"
    },
    {
      "arxiv_id": "2502.18176v2",
      "title": "CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mingkun Zhang",
        "Keping Bi",
        "Wei Chen",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "In this paper, we aim to build an adversarially robust zero-shot image\nclassifier. We ground our work on CLIP, a vision-language pre-trained encoder\nmodel that can perform zero-shot classification by matching an image with text\nprompts ``a photo of a <class-name>.''. Purification is the path we choose\nsince it does not require adversarial training on specific attack types and\nthus can cope with any foreseen attacks. We then formulate purification risk as\nthe KL divergence between the joint distributions of the purification process\nof denoising the adversarial samples and the attack process of adding\nperturbations to benign samples, through bidirectional Stochastic Differential\nEquations (SDEs). The final derived results inspire us to explore purification\nin the multi-modal latent space of CLIP. We propose two variants for our\nCLIPure approach: CLIPure-Diff which models the likelihood of images' latent\nvectors with the DiffusionPrior module in DaLLE-2 (modeling the generation\nprocess of CLIP's latent vectors), and CLIPure-Cos which models the likelihood\nwith the cosine similarity between the embeddings of an image and ``a photo of\na.''. As far as we know, CLIPure is the first purification method in\nmulti-modal latent space and CLIPure-Cos is the first purification method that\nis not based on generative models, which substantially improves defense\nefficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13\ndatasets that previous CLIP-based defense methods used for evaluating zero-shot\nclassification robustness. Results show that CLIPure boosts the SOTA robustness\nby a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on\nImageNet, and 108% relative improvements of average robustness on the 13\ndatasets over previous SOTA. The code is available at\nhttps://github.com/TMLResearchGroup-CAS/CLIPure.",
      "tldr_zh": "本论文提出 CLIPure，一种在 CLIP 的多模态潜在空间中进行净化的方法，以提升零样本图像分类的对抗鲁棒性。作者将净化风险形式化为净化过程与攻击过程之间的 KL 散度，使用双向随机微分方程 (SDEs) 进行理论指导，并开发了两种变体：CLIPure-Diff 利用 DiffusionPrior 模块模拟图像潜在向量的似然，以及 CLIPure-Cos 通过图像和文本嵌入的余弦相似度进行非生成模型净化，从而提高了防御效率。实验结果显示，CLIPure 在 CIFAR-10 上将 SOTA 鲁棒性从 71.7% 提升至 91.1%，在 ImageNet 上从 59.6% 提升至 72.6%，并在 13 个数据集上实现了平均鲁棒性相对提升 108%。这标志着 CLIPure 是首个在多模态潜在空间中的净化方法，为对抗鲁棒分类提供了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18176v2",
      "published_date": "2025-02-25 13:09:34 UTC",
      "updated_date": "2025-03-02 09:22:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:44:22.176298"
    },
    {
      "arxiv_id": "2502.18168v4",
      "title": "SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention and Low-Rank Adaptation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Zhang"
      ],
      "abstract": "With the rapid development of large language models (LLMs), fully fine-tuning\n(FT) these models is becoming increasingly infeasible due to high computational\ndemands. Moreover, FT also increases the risk of catastrophic forgetting. As an\nalternative, Low-Rank Adaptation (LoRA) has been proposed. By fine-tuning only\na small subset of parameters, LoRA achieves performance similar to FT while\nsignificantly reducing resource requirements. However, since LoRA inherits FT's\ndesign, the issue of catastrophic forgetting still remains. To address these\nlimitations, we propose SECURA: Sigmoid-Enhanced CUR Decomposition LoRA, a\nnovel PEFT variant designed to mitigate catastrophic forgetting while improving\nfine-tuning performance. Our method introduces a novel normalization technique,\nSigmoid-based Magnitude Norm (S-MagNorm), which enhances parameter retention\nand fine-tuning efficiency. SECURA has been evaluated on a diverse range of\ntasks, including mathematical problem-solving (GSM8K), complex\nquestion-answering (CNNDM), translation (NewsDE), and complex multiple-choice\nreasoning (LogiQA). Experimental results demonstrate that it achieves an\naverage fine-tuning improvement of 3.59% across four MCQ tasks and 2.51% across\nfive QA tasks on Gemma2 2B, Qwen2 1.5B, Qwen2 7B, Llama3 8B, and Llama3.1 8B,\noutperforming DoRA. Additionally, SECURA demonstrates superior knowledge\nretention capabilities, achieving state-of-the-art performance in 16 continual\nlearning tests and maintaining more than 70% accuracy on LLMs' basic knowledge\ncompared to Experience Replay (ER), sequential learning (SEQ), EWC, I-LoRA, and\nCUR-LoRA.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的全微调（FT）问题，提出SECURA，一种基于Sigmoid-Enhanced CUR分解的Low-Rank Adaptation（LoRA）变体，以缓解灾难性遗忘并提升微调性能。SECURA引入Sigmoid-based Magnitude Norm（S-MagNorm）技术，增强参数保留和微调效率，使模型在连续学习中保持更强的知识稳定性。实验结果显示，SECURA在Gemma2 2B、Qwen2 1.5B等模型上，平均在四种多选任务上提升3.59%、在五种问答任务上提升2.51%，并在16个连续学习测试中超越DoRA等基线方法，保留超过70%的基本知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "New work on PEFT for LLMs, introducing S-MagNorm and CABR-LoRA to\n  enhance fine-tuning performance and knowledge retention. In v4, we renamed\n  Sigmoid-based Magnitude Normalization to S-MagNorm for clarity and added a\n  gradient comparison between SECURA and CABR-LoRA to highlight their\n  contributions",
      "pdf_url": "http://arxiv.org/pdf/2502.18168v4",
      "published_date": "2025-02-25 13:00:05 UTC",
      "updated_date": "2025-03-04 06:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:44:31.683048"
    },
    {
      "arxiv_id": "2502.18161v1",
      "title": "iTrash: Incentivized Token Rewards for Automated Sorting and Handling",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Ortega",
        "Eduardo Castelló Ferrer"
      ],
      "abstract": "As robotic systems (RS) become more autonomous, they are becoming\nincreasingly used in small spaces and offices to automate tasks such as\ncleaning, infrastructure maintenance, or resource management. In this paper, we\npropose iTrash, an intelligent trashcan that aims to improve recycling rates in\nsmall office spaces. For that, we ran a 5 day experiment and found that iTrash\ncan produce an efficiency increase of more than 30% compared to traditional\ntrashcans. The findings derived from this work, point to the fact that using\niTrash not only increase recyclying rates, but also provides valuable data such\nas users behaviour or bin usage patterns, which cannot be taken from a normal\ntrashcan. This information can be used to predict and optimize some tasks in\nthese spaces. Finally, we explored the potential of using blockchain technology\nto create economic incentives for recycling, following a Save-as-you-Throw\n(SAYT) model.",
      "tldr_zh": "本研究提出 iTrash 系统，这是一种智能垃圾桶，结合 Incentivized Token Rewards 和 Automated Sorting and Handling 机制，旨在提高办公室空间的回收率。实验结果显示，通过为期 5 天的测试，iTrash 比传统垃圾桶效率提升超过 30%，并能收集用户行为和垃圾桶使用模式等宝贵数据，用于预测和优化相关任务。最后，论文探讨了利用 blockchain technology 创建经济激励的潜力，采用 Save-as-you-Throw (SAYT) 模型，以进一步促进可持续回收行为。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "Article submitted to IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18161v1",
      "published_date": "2025-02-25 12:46:45 UTC",
      "updated_date": "2025-02-25 12:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:44:43.550328"
    },
    {
      "arxiv_id": "2502.18157v1",
      "title": "Monitoring snow avalanches from SAR data with deep learning",
      "title_zh": "利用深度学习从 SAR 数据监测雪崩",
      "authors": [
        "Filippo Maria Bianchi",
        "Jakob Grahn"
      ],
      "abstract": "Snow avalanches present significant risks to human life and infrastructure,\nparticularly in mountainous regions, making effective monitoring crucial.\nTraditional monitoring methods, such as field observations, are limited by\naccessibility, weather conditions, and cost. Satellite-borne Synthetic Aperture\nRadar (SAR) data has become an important tool for large-scale avalanche\ndetection, as it can capture data in all weather conditions and across remote\nareas. However, traditional processing methods struggle with the complexity and\nvariability of avalanches. This chapter reviews the application of deep\nlearning for detecting and segmenting snow avalanches from SAR data. Early\nefforts focused on the binary classification of SAR images, while recent\nadvances have enabled pixel-level segmentation, providing greater accuracy and\nspatial resolution. A case study using Sentinel-1 SAR data demonstrates the\neffectiveness of deep learning models for avalanche segmentation, achieving\nsuperior results over traditional methods. We also present an extension of this\nwork, testing recent state-of-the-art segmentation architectures on an expanded\ndataset of over 4,500 annotated SAR images. The best-performing model among\nthose tested was applied for large-scale avalanche detection across the whole\nof Norway, revealing important spatial and temporal patterns over several\nwinter seasons.",
      "tldr_zh": "本研究探讨了使用深度学习从 Synthetic Aperture Radar (SAR) 数据监测雪崩的风险和方法，强调 SAR 数据能克服传统监测（如实地观察）的天气和成本限制。早期工作专注于 SAR 图像的二元分类，而最新进展实现了像素级分割，提高了准确性和空间分辨率。案例研究利用 Sentinel-1 SAR 数据证明了深度学习模型在雪崩分割中的优越性，并在扩展数据集（超过4,500张标注图像）上测试了最先进的分段架构，最终将最佳模型应用于整个挪威的雪崩检测，揭示了重要的空间和时间模式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18157v1",
      "published_date": "2025-02-25 12:41:08 UTC",
      "updated_date": "2025-02-25 12:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:44:54.326780"
    },
    {
      "arxiv_id": "2502.18156v1",
      "title": "Can LLMs Explain Themselves Counterfactually?",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Dehghanighobadi",
        "Asja Fischer",
        "Muhammad Bilal Zafar"
      ],
      "abstract": "Explanations are an important tool for gaining insights into the behavior of\nML models, calibrating user trust and ensuring regulatory compliance. Past few\nyears have seen a flurry of post-hoc methods for generating model explanations,\nmany of which involve computing model gradients or solving specially designed\noptimization problems. However, owing to the remarkable reasoning abilities of\nLarge Language Model (LLMs), self-explanation, that is, prompting the model to\nexplain its outputs has recently emerged as a new paradigm. In this work, we\nstudy a specific type of self-explanations, self-generated counterfactual\nexplanations (SCEs). We design tests for measuring the efficacy of LLMs in\ngenerating SCEs. Analysis over various LLM families, model sizes, temperature\nsettings, and datasets reveals that LLMs sometimes struggle to generate SCEs.\nEven when they do, their prediction often does not agree with their own\ncounterfactual reasoning.",
      "tldr_zh": "该研究探讨大型语言模型（LLMs）是否能够通过自生成反事实解释（counterfactual explanations）来解释自身行为，以提供模型洞见、校准用户信任并符合法规要求。作者设计了测试方法，评估不同LLMs家族、模型尺寸、温度设置和数据集下的自解释效能。结果显示，LLMs 经常在生成反事实解释时遇到困难，且其预测结果往往与自身反事实推理不一致，这突显了LLMs 自解释能力的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18156v1",
      "published_date": "2025-02-25 12:40:41 UTC",
      "updated_date": "2025-02-25 12:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:45:06.034228"
    },
    {
      "arxiv_id": "2502.18153v1",
      "title": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Dahun Shin",
        "Dongyeop Lee",
        "Jinseok Chung",
        "Namhoon Lee"
      ],
      "abstract": "Approximate second-order optimization methods often exhibit poorer\ngeneralization compared to first-order approaches. In this work, we look into\nthis issue through the lens of the loss landscape and find that existing\nsecond-order methods tend to converge to sharper minima compared to SGD. In\nresponse, we propose Sassha, a novel second-order method designed to enhance\ngeneralization by explicitly reducing sharpness of the solution, while\nstabilizing the computation of approximate Hessians along the optimization\ntrajectory. In fact, this sharpness minimization scheme is crafted also to\naccommodate lazy Hessian updates, so as to secure efficiency besides flatness.\nTo validate its effectiveness, we conduct a wide range of standard deep\nlearning experiments where Sassha demonstrates its outstanding generalization\nperformance that is comparable to, and mostly better than, other methods. We\nprovide a comprehensive set of analyses including convergence, robustness,\nstability, efficiency, and cost.",
      "tldr_zh": "本研究发现，现有的 second-order optimization 方法往往收敛到 sharper minima，导致泛化性能不如 first-order 方法如 SGD。为解决这一问题，提出 SASSHA，一种 sharpness-aware 的自适应 second-order 优化方法，通过稳定 Hessian 近似和尖锐度最小化方案来提升模型泛化，同时支持高效的懒惰 Hessian 更新。实验结果显示，SASSHA 在多种标准深度学习任务中表现出色，泛化性能优于或相当其他方法。该方法还通过全面分析验证了其收敛性、鲁棒性、稳定性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18153v1",
      "published_date": "2025-02-25 12:35:05 UTC",
      "updated_date": "2025-02-25 12:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:45:19.227210"
    },
    {
      "arxiv_id": "2502.18151v1",
      "title": "A Real-time Spatio-Temporal Trajectory Planner for Autonomous Vehicles with Semantic Graph Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shan He",
        "Yalong Ma",
        "Tao Song",
        "Yongzhi Jiang",
        "Xinkai Wu"
      ],
      "abstract": "Planning a safe and feasible trajectory for autonomous vehicles in real-time\nby fully utilizing perceptual information in complex urban environments is\nchallenging. In this paper, we propose a spatio-temporal trajectory planning\nmethod based on graph optimization. It efficiently extracts the multi-modal\ninformation of the perception module by constructing a semantic spatio-temporal\nmap through separation processing of static and dynamic obstacles, and then\nquickly generates feasible trajectories via sparse graph optimization based on\na semantic spatio-temporal hypergraph. Extensive experiments have proven that\nthe proposed method can effectively handle complex urban public road scenarios\nand perform in real time. We will also release our codes to accommodate\nbenchmarking for the research community",
      "tldr_zh": "该论文提出了一种基于语义图优化的实时时空轨迹规划方法（spatio-temporal trajectory planner），旨在为自动驾驶车辆在复杂城市环境中利用感知信息生成安全可行的轨迹。该方法通过构建语义时空地图（semantic spatio-temporal map）来分离处理静态和动态障碍物，并利用稀疏图优化（sparse graph optimization）基于语义时空超图（semantic spatio-temporal hypergraph）快速生成轨迹。实验结果显示，该方法能有效应对复杂城市公共道路场景，并实现实时性能；此外，作者计划发布代码以支持研究社区的基准测试。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L). The final published version is available in IEEE\n  Xplore (DOI: 10.1109/LRA.2024.3504239)",
      "pdf_url": "http://arxiv.org/pdf/2502.18151v1",
      "published_date": "2025-02-25 12:27:06 UTC",
      "updated_date": "2025-02-25 12:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:45:29.933948"
    },
    {
      "arxiv_id": "2502.18147v1",
      "title": "Jacobian Sparse Autoencoders: Sparsify Computations, Not Just Activations",
      "title_zh": "Jacobian 稀疏自编码器：稀疏化计算，而不仅仅是激活",
      "authors": [
        "Lucy Farnik",
        "Tim Lawson",
        "Conor Houghton",
        "Laurence Aitchison"
      ],
      "abstract": "Sparse autoencoders (SAEs) have been successfully used to discover sparse and\nhuman-interpretable representations of the latent activations of LLMs. However,\nwe would ultimately like to understand the computations performed by LLMs and\nnot just their representations. The extent to which SAEs can help us understand\ncomputations is unclear because they are not designed to \"sparsify\"\ncomputations in any sense, only latent activations. To solve this, we propose\nJacobian SAEs (JSAEs), which yield not only sparsity in the input and output\nactivations of a given model component but also sparsity in the computation\n(formally, the Jacobian) connecting them. With a na\\\"ive implementation, the\nJacobians in LLMs would be computationally intractable due to their size. One\nkey technical contribution is thus finding an efficient way of computing\nJacobians in this setup. We find that JSAEs extract a relatively large degree\nof computational sparsity while preserving downstream LLM performance\napproximately as well as traditional SAEs. We also show that Jacobians are a\nreasonable proxy for computational sparsity because MLPs are approximately\nlinear when rewritten in the JSAE basis. Lastly, we show that JSAEs achieve a\ngreater degree of computational sparsity on pre-trained LLMs than on the\nequivalent randomized LLM. This shows that the sparsity of the computational\ngraph appears to be a property that LLMs learn through training, and suggests\nthat JSAEs might be more suitable for understanding learned transformer\ncomputations than standard SAEs.",
      "tldr_zh": "本文提出Jacobian Sparse Autoencoders (JSAEs)，一种扩展传统Sparse Autoencoders (SAEs)的框架，不仅使大型语言模型 (LLMs) 的输入和输出激活稀疏，还实现了连接它们的计算稀疏性（即Jacobian）。通过高效计算Jacobian的方法，JSAEs在保持LLMs下游性能的同时，显著提高了计算稀疏度，并证明了MLP在JSAE基础上近似线性，从而使Jacobian成为计算稀疏性的合理代理。研究发现，这种计算稀疏性是LLMs训练过程学到的特性，因此JSAEs比标准SAEs更适合理解transformer的计算过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18147v1",
      "published_date": "2025-02-25 12:21:45 UTC",
      "updated_date": "2025-02-25 12:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:45:43.895171"
    },
    {
      "arxiv_id": "2502.18138v1",
      "title": "Large Language Model Driven Agents for Simulating Echo Chamber Formation",
      "title_zh": "大语言模型驱动的智能体用于模拟回声室形成",
      "authors": [
        "Chenhao Gu",
        "Ling Luo",
        "Zainab Razia Zaidi",
        "Shanika Karunasekera"
      ],
      "abstract": "The rise of echo chambers on social media platforms has heightened concerns\nabout polarization and the reinforcement of existing beliefs. Traditional\napproaches for simulating echo chamber formation have often relied on\npredefined rules and numerical simulations, which, while insightful, may lack\nthe nuance needed to capture complex, real-world interactions. In this paper,\nwe present a novel framework that leverages large language models (LLMs) as\ngenerative agents to simulate echo chamber dynamics within social networks. The\nnovelty of our approach is that it incorporates both opinion updates and\nnetwork rewiring behaviors driven by LLMs, allowing for a context-aware and\nsemantically rich simulation of social interactions. Additionally, we utilize\nreal-world Twitter (now X) data to benchmark the LLM-based simulation against\nactual social media behaviors, providing insights into the accuracy and realism\nof the generated opinion trends. Our results demonstrate the efficacy of LLMs\nin modeling echo chamber formation, capturing both structural and semantic\ndimensions of opinion clustering. %This work contributes to a deeper\nunderstanding of social influence dynamics and offers a new tool for studying\npolarization in online communities.",
      "tldr_zh": "该研究提出了一种新框架，使用 Large Language Models (LLMs) 作为生成代理来模拟社交媒体上的 echo chamber 形成，克服了传统基于规则的模拟方法在捕捉复杂互动方面的局限性。该框架整合了 LLMs 驱动的意见更新和网络重构行为，并以真实 Twitter 数据进行基准测试，以评估模拟的准确性和真实性。实验结果表明，LLMs 能有效捕捉意见聚类的结构和语义维度，为深入理解社交影响动态和在线社区极化提供了一个强大工具。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18138v1",
      "published_date": "2025-02-25 12:05:11 UTC",
      "updated_date": "2025-02-25 12:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:45:54.308489"
    },
    {
      "arxiv_id": "2502.18137v2",
      "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
      "title_zh": "SpargeAttn：准确的稀疏注意力加速任意模型推理",
      "authors": [
        "Jintao Zhang",
        "Chendong Xiang",
        "Haofeng Huang",
        "Jia Wei",
        "Haocheng Xi",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "An efficient attention implementation is essential for large models due to\nits quadratic time complexity. Fortunately, attention commonly exhibits\nsparsity, i.e., many values in the attention map are near zero, allowing for\nthe omission of corresponding computations. Many studies have utilized the\nsparse pattern to accelerate attention. However, most existing works focus on\noptimizing attention within specific models by exploiting certain sparse\npatterns of the attention map. A universal sparse attention that guarantees\nboth the speedup and end-to-end performance of diverse models remains elusive.\nIn this paper, we propose SpargeAttn, a universal sparse and quantized\nattention for any model. Our method uses a two-stage online filter: in the\nfirst stage, we rapidly and accurately predict the attention map, enabling the\nskip of some matrix multiplications in attention. In the second stage, we\ndesign an online softmax-aware filter that incurs no extra overhead and further\nskips some matrix multiplications. Experiments show that our method\nsignificantly accelerates diverse models, including language, image, and video\ngeneration, without sacrificing end-to-end metrics. The codes are available at\nhttps://github.com/thu-ml/SpargeAttn.",
      "tldr_zh": "这篇论文提出了 SpargeAttn，一种准确的稀疏注意力机制，用于加速任何模型的推理过程，针对注意力机制的二次时间复杂度问题。方法采用两阶段在线过滤器：第一阶段快速预测注意力图以跳过某些矩阵乘法，第二阶段的 softmax-aware 过滤器进一步优化计算，而不增加额外开销。实验结果显示，SpargeAttn 显著加速了语言、图像和视频生成模型，同时保持端到端性能不变。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18137v2",
      "published_date": "2025-02-25 12:02:17 UTC",
      "updated_date": "2025-05-01 05:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:46:06.837521"
    },
    {
      "arxiv_id": "2502.18122v1",
      "title": "EU-Nets: Enhanced, Explainable and Parsimonious U-Nets",
      "title_zh": "翻译失败",
      "authors": [
        "B. Sun",
        "P. Liò"
      ],
      "abstract": "In this study, we propose MHEX+, a framework adaptable to any U-Net\narchitecture. Built upon MHEX+, we introduce novel U-Net variants, EU-Nets,\nwhich enhance explainability and uncertainty estimation, addressing the\nlimitations of traditional U-Net models while improving performance and\nstability. A key innovation is the Equivalent Convolutional Kernel, which\nunifies consecutive convolutional layers, boosting interpretability. For\nuncertainty estimation, we propose the collaboration gradient approach,\nmeasuring gradient consistency across decoder layers. Notably, EU-Nets achieve\nan average accuracy improvement of 1.389\\% and a variance reduction of 0.83\\%\nacross all networks and datasets in our experiments, requiring fewer than 0.1M\nparameters.",
      "tldr_zh": "这篇论文提出了MHEX+框架，并基于其开发了EU-Nets，一种增强型、可解释且参数精简的U-Net变体，以解决传统U-Net在解释性和不确定性估计方面的局限性。EU-Nets的关键创新包括Equivalent Convolutional Kernel，用于统一连续卷积层以提升模型可解释性，以及collaboration gradient方法，通过测量解码器层间的梯度一致性来实现不确定性估计。实验结果显示，EU-Nets在所有网络和数据集上平均准确率提高了1.389%，方差降低了0.83%，且仅需少于0.1M参数，从而提高了性能和稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18122v1",
      "published_date": "2025-02-25 11:44:30 UTC",
      "updated_date": "2025-02-25 11:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:46:19.034503"
    },
    {
      "arxiv_id": "2502.18116v2",
      "title": "Bayesian Optimization for Controlled Image Editing via LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkun Cai",
        "Haoliang Liu",
        "Xu Zhao",
        "Zhongyu Jiang",
        "Tianfang Zhang",
        "Zongkai Wu",
        "Jenq-Neng Hwang",
        "Serge Belongie",
        "Lei Li"
      ],
      "abstract": "In the rapidly evolving field of image generation, achieving precise control\nover generated content and maintaining semantic consistency remain significant\nlimitations, particularly concerning grounding techniques and the necessity for\nmodel fine-tuning. To address these challenges, we propose BayesGenie, an\noff-the-shelf approach that integrates Large Language Models (LLMs) with\nBayesian Optimization to facilitate precise and user-friendly image editing.\nOur method enables users to modify images through natural language descriptions\nwithout manual area marking, while preserving the original image's semantic\nintegrity. Unlike existing techniques that require extensive pre-training or\nfine-tuning, our approach demonstrates remarkable adaptability across various\nLLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian\noptimization strategy to automatically refine the inference process parameters,\nachieving high-precision image editing with minimal user intervention. Through\nextensive experiments across diverse scenarios, we demonstrate that our\nframework significantly outperforms existing methods in both editing accuracy\nand semantic preservation, as validated using different LLMs including Claude3\nand GPT-4.",
      "tldr_zh": "这篇论文提出 BayesGenie，一种结合 Large Language Models (LLMs) 和 Bayesian Optimization 的现成方法，用于实现精确且用户友好的图像编辑。用户可以通过自然语言描述修改图像，而无需手动标记区域，同时保持原图像的语义完整性；该方法采用模型无关设计，避免了广泛的预训练或微调。实验结果显示，BayesGenie 在各种场景中显著优于现有技术，在编辑准确性和语义保留方面表现出色，并验证了其在不同 LLMs（如 Claude3 和 GPT-4）上的适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18116v2",
      "published_date": "2025-02-25 11:41:33 UTC",
      "updated_date": "2025-02-26 06:53:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:46:31.886351"
    },
    {
      "arxiv_id": "2502.18097v1",
      "title": "The Built-In Robustness of Decentralized Federated Averaging to Bad Data",
      "title_zh": "去中心化联邦平均对不良数据的内置鲁棒性",
      "authors": [
        "Samuele Sabella",
        "Chiara Boldrini",
        "Lorenzo Valerio",
        "Andrea Passarella",
        "Marco Conti"
      ],
      "abstract": "Decentralized federated learning (DFL) enables devices to collaboratively\ntrain models over complex network topologies without relying on a central\ncontroller. In this setting, local data remains private, but its quality and\nquantity can vary significantly across nodes. The extent to which a fully\ndecentralized system is vulnerable to poor-quality or corrupted data remains\nunclear, but several factors could contribute to potential risks. Without a\ncentral authority, there can be no unified mechanism to detect or correct\nerrors, and each node operates with a localized view of the data distribution,\nmaking it difficult for the node to assess whether its perspective aligns with\nthe true distribution. Moreover, models trained on low-quality data can\npropagate through the network, amplifying errors. To explore the impact of\nlow-quality data on DFL, we simulate two scenarios with degraded data quality\n-- one where the corrupted data is evenly distributed in a subset of nodes and\none where it is concentrated on a single node -- using a decentralized\nimplementation of FedAvg. Our results reveal that averaging-based decentralized\nlearning is remarkably robust to localized bad data, even when the corrupted\ndata resides in the most influential nodes of the network. Counterintuitively,\nthis robustness is further enhanced when the corrupted data is concentrated on\na single node, regardless of its centrality in the communication network\ntopology. This phenomenon is explained by the averaging process, which ensures\nthat no single node -- however central -- can disproportionately influence the\noverall learning process.",
      "tldr_zh": "该研究探讨了去中心化联邦学习 (DFL) 在面对低质量或损坏数据时的内置鲁棒性，特别是在没有中央控制器的复杂网络拓扑下。研究者使用去中心化FedAvg算法模拟两种场景：坏数据均匀分布在部分节点，或集中在单个节点。结果显示，基于平均的DFL对局部坏数据表现出显著鲁棒性，即使坏数据位于网络中最有影响的节点。令人意外的是，当坏数据集中在单个节点时，这种鲁棒性进一步增强，主要归因于平均过程，确保任何节点无法主导整体学习过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Funding: SoBigData PPP (101079043), SoBigData.it (PNRR IR0000013),\n  FAIR (PNRR PE00000013), RESTART (PNRR PE00000001)",
      "pdf_url": "http://arxiv.org/pdf/2502.18097v1",
      "published_date": "2025-02-25 11:06:51 UTC",
      "updated_date": "2025-02-25 11:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:46:42.995114"
    },
    {
      "arxiv_id": "2502.18080v1",
      "title": "Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenkai Yang",
        "Shuming Ma",
        "Yankai Lin",
        "Furu Wei"
      ],
      "abstract": "Recent studies have shown that making a model spend more time thinking\nthrough longer Chain of Thoughts (CoTs) enables it to gain significant\nimprovements in complex reasoning tasks. While current researches continue to\nexplore the benefits of increasing test-time compute by extending the CoT\nlengths of Large Language Models (LLMs), we are concerned about a potential\nissue hidden behind the current pursuit of test-time scaling: Would excessively\nscaling the CoT length actually bring adverse effects to a model's reasoning\nperformance? Our explorations on mathematical reasoning tasks reveal an\nunexpected finding that scaling with longer CoTs can indeed impair the\nreasoning performance of LLMs in certain domains. Moreover, we discover that\nthere exists an optimal scaled length distribution that differs across\ndifferent domains. Based on these insights, we propose a Thinking-Optimal\nScaling strategy. Our method first uses a small set of seed data with varying\nresponse length distributions to teach the model to adopt different reasoning\nefforts for deep thinking. Then, the model selects its shortest correct\nresponse under different reasoning efforts on additional problems for\nself-improvement. Our self-improved models built upon Qwen2.5-32B-Instruct\noutperform other distillation-based 32B o1-like models across various math\nbenchmarks, and achieve performance on par with QwQ-32B-Preview.",
      "tldr_zh": "该研究探讨了在大型语言模型(LLMs)推理任务中，通过延长Chain of Thoughts (CoTs)来增加测试时计算量的潜在问题，发现过度扩展CoT长度可能损害模型在某些领域的性能，并存在领域特定的最佳缩放长度分布。为此，提出Thinking-Optimal Scaling策略，该方法先利用种子数据训练模型采用不同推理努力，然后通过选择最短正确响应进行自我改进。基于Qwen2.5-32B-Instruct的改进模型在各种数学基准上超越其他32B o1-like模型，并与QwQ-32B-Preview的性能相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18080v1",
      "published_date": "2025-02-25 10:48:05 UTC",
      "updated_date": "2025-02-25 10:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:46:56.204785"
    },
    {
      "arxiv_id": "2502.18072v1",
      "title": "MRBTP: Efficient Multi-Robot Behavior Tree Planning and Collaboration",
      "title_zh": "MRBTP：高效的多机器人行为树规划和协作",
      "authors": [
        "Yishuai Cai",
        "Xinglin Chen",
        "Zhongxuan Cai",
        "Yunxin Mao",
        "Minglong Li",
        "Wenjing Yang",
        "Ji Wang"
      ],
      "abstract": "Multi-robot task planning and collaboration are critical challenges in\nrobotics. While Behavior Trees (BTs) have been established as a popular control\narchitecture and are plannable for a single robot, the development of effective\nmulti-robot BT planning algorithms remains challenging due to the complexity of\ncoordinating diverse action spaces. We propose the Multi-Robot Behavior Tree\nPlanning (MRBTP) algorithm, with theoretical guarantees of both soundness and\ncompleteness. MRBTP features cross-tree expansion to coordinate heterogeneous\nactions across different BTs to achieve the team's goal. For homogeneous\nactions, we retain backup structures among BTs to ensure robustness and prevent\nredundant execution through intention sharing. While MRBTP is capable of\ngenerating BTs for both homogeneous and heterogeneous robot teams, its\nefficiency can be further improved. We then propose an optional plugin for\nMRBTP when Large Language Models (LLMs) are available to reason goal-related\nactions for each robot. These relevant actions can be pre-planned to form\nlong-horizon subtrees, significantly enhancing the planning speed and\ncollaboration efficiency of MRBTP. We evaluate our algorithm in warehouse\nmanagement and everyday service scenarios. Results demonstrate MRBTP's\nrobustness and execution efficiency under varying settings, as well as the\nability of the pre-trained LLM to generate effective task-specific subtrees for\nMRBTP.",
      "tldr_zh": "该论文提出MRBTP算法，用于高效的多机器人行为树(Behavior Trees, BTs)规划和协作，解决了多机器人协调异构动作空间的复杂挑战。MRBTP通过cross-tree expansion协调不同BTs中的异构动作，并为同构动作保留backup structures和intention sharing，以确保鲁棒性和避免冗余执行。该算法具有soundness和completeness的理论保证，并在可选的Large Language Models (LLMs)插件支持下，通过预规划长horizon subtrees来提升规划速度和协作效率。实验在仓库管理和日常服务场景中验证了MRBTP的鲁棒性、执行效率，以及LLMs生成任务特定子树的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18072v1",
      "published_date": "2025-02-25 10:39:28 UTC",
      "updated_date": "2025-02-25 10:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:47:07.554776"
    },
    {
      "arxiv_id": "2502.18064v1",
      "title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng Wang",
        "Yi Zhao"
      ],
      "abstract": "Low-cost accelerometers play a crucial role in modern society due to their\nadvantages of small size, ease of integration, wearability, and mass\nproduction, making them widely applicable in automotive systems, aerospace, and\nwearable technology. However, this widely used sensor suffers from severe\naccuracy and range limitations. To this end, we propose a honed-energy\nregularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost\nsensor signals into high-cost equivalents, thereby overcoming the precision and\nrange limitations of low-cost accelerometers. Due to the lack of frame-level\npaired low-cost and high-cost signals for training, we propose an Optimal\nTransport Supervision (OTS), which leverages optimal transport theory to\nexplore potential consistency between unpaired data, thereby maximizing\nsupervisory information. Moreover, we propose a Modulated Laplace Energy (MLE),\nwhich injects appropriate energy into the generator to encourage it to break\nrange limitations, enhance local changes, and enrich signal details. Given the\nabsence of a dedicated dataset, we specifically establish a Low-cost\nAccelerometer Signal Enhancement Dataset (LASED) containing tens of thousands\nof samples, which is the first dataset serving to improve the accuracy and\nrange of accelerometers and is released in Github. Experimental results\ndemonstrate that a GAN combined with either OTS or MLE alone can surpass the\nprevious signal enhancement SOTA methods by an order of magnitude. Integrating\nboth OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the\naccelerometer range while reducing signal noise by two orders of magnitude,\nestablishing a benchmark in the accelerometer signal processing.",
      "tldr_zh": "本研究针对低成本加速度计的准确性和范围限制问题，提出了一种 Honed-Energy Regularized and Optimal Supervised GAN（HEROS-GAN）框架，用于将低成本传感器信号转化为高成本等效信号。HEROS-GAN 引入 Optimal Transport Supervision (OTS)，利用最优传输理论从未配对数据中挖掘潜在一致性，以最大化监督信息；同时，Modulated Laplace Energy (MLE) 被用于注入能量，突破范围限制并增强信号细节。为支持实验，该团队建立了首个 Low-cost Accelerometer Signal Enhancement Dataset (LASED)，包含数万个样本，并已在 GitHub 上发布。实验结果显示，HEROS-GAN 单独使用 OTS 或 MLE 即可超越现有信号增强方法一个数量级，而结合两者后，可将加速度计范围扩展一倍，并将信号噪声减少两个数量级，树立了新的基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SP",
        "math.PR"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI Oral; AI for Sensors; Generative Deep Learning",
      "pdf_url": "http://arxiv.org/pdf/2502.18064v1",
      "published_date": "2025-02-25 10:31:01 UTC",
      "updated_date": "2025-02-25 10:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:47:19.887126"
    },
    {
      "arxiv_id": "2502.18060v1",
      "title": "Defining bias in AI-systems: Biased models are fair models",
      "title_zh": "翻译失败",
      "authors": [
        "Chiara Lindloff",
        "Ingo Siegert"
      ],
      "abstract": "The debate around bias in AI systems is central to discussions on algorithmic\nfairness. However, the term bias often lacks a clear definition, despite\nfrequently being contrasted with fairness, implying that an unbiased model is\ninherently fair. In this paper, we challenge this assumption and argue that a\nprecise conceptualization of bias is necessary to effectively address fairness\nconcerns. Rather than viewing bias as inherently negative or unfair, we\nhighlight the importance of distinguishing between bias and discrimination. We\nfurther explore how this shift in focus can foster a more constructive\ndiscourse within academic debates on fairness in AI systems.",
      "tldr_zh": "本论文探讨AI系统中“bias”（偏见）的定义，挑战了传统观点，即无偏模型即为公平（fairness）的假设。作者强调，需要对bias进行精确概念化，以区分其与“discrimination”（歧视）的差异，而非简单地将bias视为负面因素。这种视角转变有助于在学术界推动更具建设性的对话，促进AI系统的公平性研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "ISCA/ITG Workshop on Diversity in Large Speech and Language Models",
      "pdf_url": "http://arxiv.org/pdf/2502.18060v1",
      "published_date": "2025-02-25 10:28:16 UTC",
      "updated_date": "2025-02-25 10:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:47:30.109198"
    },
    {
      "arxiv_id": "2503.05769v1",
      "title": "Effect of Gender Fair Job Description on Generative AI Images",
      "title_zh": "性别公平工作描述对生成式 AI 图像的影响",
      "authors": [
        "Finn Böckling",
        "Jan Marquenie",
        "Ingo Siegert"
      ],
      "abstract": "STEM fields are traditionally male-dominated, with gender biases shaping\nperceptions of job accessibility. This study analyzed gender representation in\nSTEM occupation images generated by OpenAI DALL-E 3 \\& Black Forest FLUX.1\nusing 150 prompts in three linguistic forms: German generic masculine, German\npair form, and English. As control, 20 pictures of social occupations were\ngenerated as well. Results revealed significant male bias across all forms,\nwith the German pair form showing reduced bias but still overrepresenting men\nfor the STEM-Group and mixed results for the Group of Social Occupations. These\nfindings highlight generative AI's role in reinforcing societal biases,\nemphasizing the need for further discussion on diversity (in AI). Further\naspects analyzed are age-distribution and ethnic diversity.",
      "tldr_zh": "本研究考察了使用不同语言形式的职位描述（如 German generic masculine、German pair form 和 English）对生成式 AI 图像中性别代表性的影响，具体分析了 OpenAI DALL-E 3 和 Black Forest FLUX.1 模型生成的 150 个 STEM 职业图像，以及作为对照的 20 个社会职业图像。结果显示，所有形式都存在显著的 gender bias，男性过度代表，其中 German pair form 略微减少了偏见，但 STEM 领域仍以男性为主，而社会职业组显示混合结果。研究还评估了年龄分布和 ethnic diversity，进一步强调了生成式 AI 在强化社会偏见方面的作用，并呼吁加强 AI 中的多样性讨论。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "ISCA/ITG Workshop on Diversity in Large Speech and Language Models",
      "pdf_url": "http://arxiv.org/pdf/2503.05769v1",
      "published_date": "2025-02-25 10:21:29 UTC",
      "updated_date": "2025-02-25 10:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:47:43.572783"
    },
    {
      "arxiv_id": "2502.18042v1",
      "title": "VLM-E2E: Enhancing End-to-End Autonomous Driving with Multimodal Driver Attention Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Pei Liu",
        "Haipeng Liu",
        "Haichao Liu",
        "Xin Liu",
        "Jinxin Ni",
        "Jun Ma"
      ],
      "abstract": "Human drivers adeptly navigate complex scenarios by utilizing rich\nattentional semantics, but the current autonomous systems struggle to replicate\nthis ability, as they often lose critical semantic information when converting\n2D observations into 3D space. In this sense, it hinders their effective\ndeployment in dynamic and complex environments. Leveraging the superior scene\nunderstanding and reasoning abilities of Vision-Language Models (VLMs), we\npropose VLM-E2E, a novel framework that uses the VLMs to enhance training by\nproviding attentional cues. Our method integrates textual representations into\nBird's-Eye-View (BEV) features for semantic supervision, which enables the\nmodel to learn richer feature representations that explicitly capture the\ndriver's attentional semantics. By focusing on attentional semantics, VLM-E2E\nbetter aligns with human-like driving behavior, which is critical for\nnavigating dynamic and complex environments. Furthermore, we introduce a\nBEV-Text learnable weighted fusion strategy to address the issue of modality\nimportance imbalance in fusing multimodal information. This approach\ndynamically balances the contributions of BEV and text features, ensuring that\nthe complementary information from visual and textual modality is effectively\nutilized. By explicitly addressing the imbalance in multimodal fusion, our\nmethod facilitates a more holistic and robust representation of driving\nenvironments. We evaluate VLM-E2E on the nuScenes dataset and demonstrate its\nsuperiority over state-of-the-art approaches, showcasing significant\nimprovements in performance.",
      "tldr_zh": "本研究提出VLM-E2E框架，利用Vision-Language Models (VLMs)增强端到端自动驾驶系统，通过多模态驱动注意力融合来解决当前系统在2D到3D空间转换中丢失关键语义信息的问题。该框架将文本表示整合到Bird's-Eye-View (BEV)特征中进行语义监督，并引入BEV-Text可学习加权融合策略，以动态平衡视觉和文本模态的重要性，实现更全面的驾驶环境表示。实验在nuScenes数据集上评估，VLM-E2E显著优于现有方法，提升了自动驾驶的性能和对复杂场景的适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18042v1",
      "published_date": "2025-02-25 10:02:12 UTC",
      "updated_date": "2025-02-25 10:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:47:55.853305"
    },
    {
      "arxiv_id": "2502.18040v1",
      "title": "AutoCas: Autoregressive Cascade Predictor in Social Networks via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Zheng",
        "Chenghua Gong",
        "Rui Sun",
        "Juyuan Zhang",
        "Liming Pan",
        "Linyuan Lv"
      ],
      "abstract": "Popularity prediction in information cascades plays a crucial role in social\ncomputing, with broad applications in viral marketing, misinformation control,\nand content recommendation. However, information propagation mechanisms, user\nbehavior, and temporal activity patterns exhibit significant diversity,\nnecessitating a foundational model capable of adapting to such variations. At\nthe same time, the amount of available cascade data remains relatively limited\ncompared to the vast datasets used for training large language models (LLMs).\nRecent studies have demonstrated the feasibility of leveraging LLMs for\ntime-series prediction by exploiting commonalities across different time-series\ndomains. Building on this insight, we introduce the Autoregressive Information\nCascade Predictor (AutoCas), an LLM-enhanced model designed specifically for\ncascade popularity prediction. Unlike natural language sequences, cascade data\nis characterized by complex local topologies, diffusion contexts, and evolving\ndynamics, requiring specialized adaptations for effective LLM integration. To\naddress these challenges, we first tokenize cascade data to align it with\nsequence modeling principles. Next, we reformulate cascade diffusion as an\nautoregressive modeling task to fully harness the architectural strengths of\nLLMs. Beyond conventional approaches, we further introduce prompt learning to\nenhance the synergy between LLMs and cascade prediction. Extensive experiments\ndemonstrate that AutoCas significantly outperforms baseline models in cascade\npopularity prediction while exhibiting scaling behavior inherited from LLMs.\nCode is available at this repository:\nhttps://anonymous.4open.science/r/AutoCas-85C6",
      "tldr_zh": "这篇论文提出 AutoCas，一种基于 Large Language Models (LLMs) 的自回归级联预测器，用于社交网络中信息级联的流行度预测，以应对传播机制多样性和数据有限的挑战。方法包括对级联数据进行标记化（tokenize），将扩散过程重构为自回归建模任务，并引入 prompt learning 来增强 LLMs 与预测任务的协同作用。实验结果表明，AutoCas 显著优于基线模型，并在流行度预测性能上继承了 LLMs 的缩放行为。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.18040v1",
      "published_date": "2025-02-25 09:54:33 UTC",
      "updated_date": "2025-02-25 09:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:48:07.196026"
    },
    {
      "arxiv_id": "2502.18026v1",
      "title": "ExPath: Towards Explaining Targeted Pathways for Biological Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Rikuto Kotoge",
        "Ziwei Yang",
        "Zheng Chen",
        "Yushun Dong",
        "Yasuko Matsubara",
        "Jimeng Sun",
        "Yasushi Sakurai"
      ],
      "abstract": "Biological knowledge bases provide systemically functional pathways of cells\nor organisms in terms of molecular interaction. However, recognizing more\ntargeted pathways, particularly when incorporating wet-lab experimental data,\nremains challenging and typically requires downstream biological analyses and\nexpertise. In this paper, we frame this challenge as a solvable graph learning\nand explaining task and propose a novel pathway inference framework, ExPath,\nthat explicitly integrates experimental data, specifically amino acid sequences\n(AA-seqs), to classify various graphs (bio-networks) in biological databases.\nThe links (representing pathways) that contribute more to classification can be\nconsidered as targeted pathways. Technically, ExPath comprises three\ncomponents: (1) a large protein language model (pLM) that encodes and embeds\nAA-seqs into graph, overcoming traditional obstacles in processing AA-seq data,\nsuch as BLAST; (2) PathMamba, a hybrid architecture combining graph neural\nnetworks (GNNs) with state-space sequence modeling (Mamba) to capture both\nlocal interactions and global pathway-level dependencies; and (3)\nPathExplainer, a subgraph learning module that identifies functionally critical\nnodes and edges through trainable pathway masks. We also propose ML-oriented\nbiological evaluations and a new metric. The experiments involving 301\nbio-networks evaluations demonstrate that pathways inferred by ExPath maintain\nbiological meaningfulness. We will publicly release curated 301 bio-network\ndata soon.",
      "tldr_zh": "本研究针对生物知识库中识别针对性途径的挑战，提出ExPath框架，将其视为图学习和解释任务，通过整合湿实验数据（如氨基酸序列AA-seqs）来分类生物网络，并识别贡献较大的链接作为目标途径。ExPath包括三个核心组件：(1)大型蛋白质语言模型(pLM)用于编码和嵌入AA-seqs到图中，克服传统处理障碍；(2)PathMamba混合架构，结合图神经网络(GNNs)和状态空间序列建模(Mamba)，捕捉局部互动和全局依赖；(3)PathExplainer子图学习模块，通过可训练的途径掩码识别关键节点和边。实验在301个生物网络上验证了ExPath的生物学意义性，并计划公开数据，为生物分析提供新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.18026v1",
      "published_date": "2025-02-25 09:33:15 UTC",
      "updated_date": "2025-02-25 09:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:48:19.993212"
    },
    {
      "arxiv_id": "2502.18020v1",
      "title": "AfroXLMR-Comet: Multilingual Knowledge Distillation with Attention Matching for Low-Resource languages",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Sakthivel Raju",
        "Sanjay S",
        "Jaskaran Singh Walia",
        "Srinivas Raghav",
        "Vukosi Marivate"
      ],
      "abstract": "Language model compression through knowledge distillation has emerged as a\npromising approach for deploying large language models in resource-constrained\nenvironments. However, existing methods often struggle to maintain performance\nwhen distilling multilingual models, especially for low-resource languages. In\nthis paper, we present a novel hybrid distillation approach that combines\ntraditional knowledge distillation with a simplified attention matching\nmechanism, specifically designed for multilingual contexts. Our method\nintroduces an extremely compact student model architecture, significantly\nsmaller than conventional multilingual models. We evaluate our approach on five\nAfrican languages: Kinyarwanda, Swahili, Hausa, Igbo, and Yoruba. The distilled\nstudent model; AfroXLMR-Comet successfully captures both the output\ndistribution and internal attention patterns of a larger teacher model\n(AfroXLMR-Large) while reducing the model size by over 85%. Experimental\nresults demonstrate that our hybrid approach achieves competitive performance\ncompared to the teacher model, maintaining an accuracy within 85% of the\noriginal model's performance while requiring substantially fewer computational\nresources. Our work provides a practical framework for deploying efficient\nmultilingual models in resource-constrained environments, particularly\nbenefiting applications involving African languages.",
      "tldr_zh": "本研究提出了一种新型混合知识蒸馏方法（knowledge distillation），结合简化注意力匹配机制（attention matching），针对低资源语言的多语言模型（multilingual models）进行压缩，以适应资源受限环境。该方法创建了紧凑的AfroXLMR-Comet学生模型，从AfroXLMR-Large教师模型中学习输出分布和内部注意力模式，模型大小减少超过85%。在Kinyarwanda、Swahili、Hausa、Igbo和Yoruba等五个非洲语言上的实验表明，学生模型性能接近教师模型，准确率达到原模型的85%，为部署高效多语言模型提供了实用框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18020v1",
      "published_date": "2025-02-25 09:28:47 UTC",
      "updated_date": "2025-02-25 09:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:48:32.088315"
    },
    {
      "arxiv_id": "2502.18017v1",
      "title": "ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents",
      "title_zh": "ViDoRAG：通过动态迭代推理代理的视觉文档检索增强生成",
      "authors": [
        "Qiuchen Wang",
        "Ruixue Ding",
        "Zehui Chen",
        "Weiqi Wu",
        "Shihang Wang",
        "Pengjun Xie",
        "Feng Zhao"
      ],
      "abstract": "Understanding information from visually rich documents remains a significant\nchallenge for traditional Retrieval-Augmented Generation (RAG) methods.\nExisting benchmarks predominantly focus on image-based question answering (QA),\noverlooking the fundamental challenges of efficient retrieval, comprehension,\nand reasoning within dense visual documents. To bridge this gap, we introduce\nViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich\ndocuments requiring complex reasoning. Based on it, we identify key limitations\nin current RAG approaches: (i) purely visual retrieval methods struggle to\neffectively integrate both textual and visual features, and (ii) previous\napproaches often allocate insufficient reasoning tokens, limiting their\neffectiveness. To address these challenges, we propose ViDoRAG, a novel\nmulti-agent RAG framework tailored for complex reasoning across visual\ndocuments. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy\nto effectively handle multi-modal retrieval. To further elicit the model's\nreasoning capabilities, we introduce an iterative agent workflow incorporating\nexploration, summarization, and reflection, providing a framework for\ninvestigating test-time scaling in RAG domains. Extensive experiments on\nViDoSeek validate the effectiveness and generalization of our approach.\nNotably, ViDoRAG outperforms existing methods by over 10% on the competitive\nViDoSeek benchmark.",
      "tldr_zh": "该研究针对传统Retrieval-Augmented Generation (RAG)方法在处理视觉丰富文档时的挑战，引入了ViDoSeek数据集，以评估RAG在复杂推理任务中的性能。论文识别出当前方法的局限性，包括纯视觉检索无法有效整合文本和视觉特征，以及推理标记分配不足，并提出ViDoRAG框架，一个多智能体RAG系统，利用Gaussian Mixture Model (GMM)-based混合策略进行多模态检索，并通过迭代智能体工作流（包括exploration、summarization和reflection）增强推理能力。实验结果显示，ViDoRAG在ViDoSeek基准上比现有方法提升超过10%，证明了其有效性和泛化性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18017v1",
      "published_date": "2025-02-25 09:26:12 UTC",
      "updated_date": "2025-02-25 09:26:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:48:42.575099"
    },
    {
      "arxiv_id": "2502.18008v5",
      "title": "NotaGen: Advancing Musicality in Symbolic Music Generation with Large Language Model Training Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Yashan Wang",
        "Shangda Wu",
        "Jianhuai Hu",
        "Xingjian Du",
        "Yueqi Peng",
        "Yongxin Huang",
        "Shuai Fan",
        "Xiaobing Li",
        "Feng Yu",
        "Maosong Sun"
      ],
      "abstract": "We introduce NotaGen, a symbolic music generation model aiming to explore the\npotential of producing high-quality classical sheet music. Inspired by the\nsuccess of Large Language Models (LLMs), NotaGen adopts pre-training,\nfine-tuning, and reinforcement learning paradigms (henceforth referred to as\nthe LLM training paradigms). It is pre-trained on 1.6M pieces of music in ABC\nnotation, and then fine-tuned on approximately 9K high-quality classical\ncompositions conditioned on \"period-composer-instrumentation\" prompts. For\nreinforcement learning, we propose the CLaMP-DPO method, which further enhances\ngeneration quality and controllability without requiring human annotations or\npredefined rewards. Our experiments demonstrate the efficacy of CLaMP-DPO in\nsymbolic music generation models with different architectures and encoding\nschemes. Furthermore, subjective A/B tests show that NotaGen outperforms\nbaseline models against human compositions, greatly advancing musical\naesthetics in symbolic music generation.",
      "tldr_zh": "该研究引入了 NotaGen，一种符号音乐生成模型，旨在提升古典乐谱的质量，通过借鉴 Large Language Models (LLMs) 的训练范式，包括预训练、微调和强化学习。模型首先在 1.6M 件 ABC 符号音乐上进行预训练，然后在约 9K 高质量古典作曲上进行微调，使用“period-composer-instrumentation”提示来增强生成的可控性；此外，提出 CLaMP-DPO 方法进行强化学习，提升音乐生成质量，而无需人类标注或预定义奖励。实验结果显示，CLaMP-DPO 在不同模型架构和编码方案中有效，且主观 A/B 测试证明 NotaGen 在音乐美学方面显著优于基线模型，推动了符号音乐生成的整体进步。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18008v5",
      "published_date": "2025-02-25 09:12:07 UTC",
      "updated_date": "2025-03-21 12:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:48:53.985286"
    },
    {
      "arxiv_id": "2502.18002v2",
      "title": "A Radon-Nikodým Perspective on Anomaly Detection: Theory and Implications",
      "title_zh": "从 Radon-Nikodým 视角看异常检测：理论与含义",
      "authors": [
        "Shlok Mehendale",
        "Aditya Challa",
        "Rahul Yedida",
        "Sravan Danda",
        "Santonu Sarkar",
        "Snehanshu Saha"
      ],
      "abstract": "Which principle underpins the design of an effective anomaly detection loss\nfunction? The answer lies in the concept of Radon-Nikod\\'ym theorem, a\nfundamental concept in measure theory. The key insight from this article is:\nMultiplying the vanilla loss function with the Radon-Nikod\\'ym derivative\nimproves the performance across the board. We refer to this as RN-Loss. We\nprove this using the setting of PAC (Probably Approximately Correct)\nlearnability.\n  Depending on the context a Radon-Nikod\\'ym derivative takes different forms.\nIn the simplest case of supervised anomaly detection, Radon-Nikod\\'ym\nderivative takes the form of a simple weighted loss. In the case of\nunsupervised anomaly detection (with distributional assumptions),\nRadon-Nikod\\'ym derivative takes the form of the popular cluster based local\noutlier factor. We evaluate our algorithm on 96 datasets, including univariate\nand multivariate data from diverse domains, including healthcare,\ncybersecurity, and finance. We show that RN-Derivative algorithms outperform\nstate-of-the-art methods on 68% of Multivariate datasets (based on F1 scores)\nand also achieves peak F1-scores on 72% of time series (Univariate) datasets.",
      "tldr_zh": "该论文从 Radon-Nikodým 定理的视角探讨异常检测的理论基础，提出一种改进损失函数的方法，即将普通损失函数乘以 Radon-Nikodým 导数，形成 RN-Loss，以提升整体性能，并通过 PAC learnability 框架进行证明。针对不同场景，RN-Loss 在监督异常检测中表现为简单加权损失，而在无监督异常检测中类似于基于聚类的 Local Outlier Factor。实验在96个数据集上验证，包括医疗、网络安全和金融领域的单变量和多变量数据，结果显示 RN-Derivative 算法在68%的多变量数据集和72%的时间序列数据集上优于现有方法（基于 F1 scores）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18002v2",
      "published_date": "2025-02-25 09:08:50 UTC",
      "updated_date": "2025-05-16 15:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:49:08.399992"
    },
    {
      "arxiv_id": "2502.17999v1",
      "title": "GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Fiori",
        "Davide Mor",
        "Gabriele Civitarese",
        "Claudio Bettini"
      ],
      "abstract": "Sensor-based Human Activity Recognition (HAR) in smart home environments is\ncrucial for several applications, especially in the healthcare domain. The\nmajority of the existing approaches leverage deep learning models. While these\napproaches are effective, the rationale behind their outputs is opaque.\nRecently, eXplainable Artificial Intelligence (XAI) approaches emerged to\nprovide intuitive explanations to the output of HAR models. To the best of our\nknowledge, these approaches leverage classic deep models like CNNs or RNNs.\nRecently, Graph Neural Networks (GNNs) proved to be effective for sensor-based\nHAR. However, existing approaches are not designed with explainability in mind.\nIn this work, we propose the first explainable Graph Neural Network explicitly\ndesigned for smart home HAR. Our results on two public datasets show that this\napproach provides better explanations than state-of-the-art methods while also\nslightly improving the recognition rate.",
      "tldr_zh": "本文提出 GNN-XAR，一种专为智能家居人类活动识别 (HAR) 设计的可解释 Graph Neural Network (GNN)，旨在解决现有深度学习模型如 CNNs 或 RNNs 在解释性方面的不足。GNN-XAR 通过显式设计来提供直观的解释，同时利用 GNN 的优势处理传感器-based HAR 任务。实验结果显示，在两个公共数据集上，该方法比 state-of-the-art 方法略微提高了识别率，并提供了更好的解释输出。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a preprint. Paper accepted for publication at the 21st EAI\n  International Conference on Mobile and Ubiquitous Systems: Computing,\n  Networking and Services (Mobiquitous)",
      "pdf_url": "http://arxiv.org/pdf/2502.17999v1",
      "published_date": "2025-02-25 09:05:13 UTC",
      "updated_date": "2025-02-25 09:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:49:20.628476"
    },
    {
      "arxiv_id": "2502.17987v1",
      "title": "MAGE: Multi-Head Attention Guided Embeddings for Low Resource Sentiment Classification",
      "title_zh": "MAGE：多头注意力引导嵌入用于低资源情感分类",
      "authors": [
        "Varun Vashisht",
        "Samar Singh",
        "Mihir Konduskar",
        "Jaskaran Singh Walia",
        "Vukosi Marivate"
      ],
      "abstract": "Due to the lack of quality data for low-resource Bantu languages, significant\nchallenges are presented in text classification and other practical\nimplementations. In this paper, we introduce an advanced model combining\nLanguage-Independent Data Augmentation (LiDA) with Multi-Head Attention based\nweighted embeddings to selectively enhance critical data points and improve\ntext classification performance. This integration allows us to create robust\ndata augmentation strategies that are effective across various linguistic\ncontexts, ensuring that our model can handle the unique syntactic and semantic\nfeatures of Bantu languages. This approach not only addresses the data scarcity\nissue but also sets a foundation for future research in low-resource language\nprocessing and classification tasks.",
      "tldr_zh": "该论文针对低资源 Bantu languages 的数据缺乏问题，提出 MAGE 模型，该模型结合 Language-Independent Data Augmentation (LiDA) 和 Multi-Head Attention based weighted embeddings，通过选择性地增强关键数据点来提升文本分类性能。这种方法适应了 Bantu languages 的独特语法和语义特征，不仅有效解决了数据稀缺问题，还为低资源语言处理和情感分类任务的研究奠定了基础。实验结果显示，该框架在各种语言语境中表现出色，提高了模型的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17987v1",
      "published_date": "2025-02-25 08:53:27 UTC",
      "updated_date": "2025-02-25 08:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:49:30.916989"
    },
    {
      "arxiv_id": "2502.17986v1",
      "title": "Broadening Discovery through Structural Models: Multimodal Combination of Local and Structural Properties for Predicting Chemical Features",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolai Rekut",
        "Alexey Orlov",
        "Klea Ziu",
        "Elizaveta Starykh",
        "Martin Takac",
        "Aleksandr Beznosikov"
      ],
      "abstract": "In recent years, machine learning has profoundly reshaped the field of\nchemistry, facilitating significant advancements across various applications,\nincluding the prediction of molecular properties and the generation of\nmolecular structures. Language models and graph-based models are extensively\nutilized within this domain, consistently achieving state-of-the-art results\nacross an array of tasks. However, the prevailing practice of representing\nchemical compounds in the SMILES format -- used by most datasets and many\nlanguage models -- presents notable limitations as a training data format. In\ncontrast, chemical fingerprints offer a more physically informed representation\nof compounds, thereby enhancing their suitability for model training. This\nstudy aims to develop a language model that is specifically trained on\nfingerprints. Furthermore, we introduce a bimodal architecture that integrates\nthis language model with a graph model. Our proposed methodology synthesizes\nthese approaches, utilizing RoBERTa as the language model and employing Graph\nIsomorphism Networks (GIN), Graph Convolutional Networks (GCN) and Graphormer\nas graph models. This integration results in a significant improvement in\npredictive performance compared to conventional strategies for tasks such as\nQuantitative Structure-Activity Relationship (QSAR) and the prediction of\nnuclear magnetic resonance (NMR) spectra, among others.",
      "tldr_zh": "这篇论文指出了化学领域常用SMILES格式的局限性，并提出使用化学指纹作为更物理化的分子表示来训练语言模型。研究开发了一个双模架构，将基于指纹的RoBERTa语言模型与图模型（如GIN、GCN和Graphormer）相结合，以整合局部和结构属性。实验结果显示，这种方法在Quantitative Structure-Activity Relationship (QSAR) 和核磁共振 (NMR) 谱预测等任务上，显著超过了传统策略的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17986v1",
      "published_date": "2025-02-25 08:53:18 UTC",
      "updated_date": "2025-02-25 08:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:49:43.800082"
    },
    {
      "arxiv_id": "2503.00038v1",
      "title": "from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Yan",
        "Sheng Sun",
        "Zenghao Duan",
        "Teli Liu",
        "Min Liu",
        "Zhiyi Yin",
        "Qi Li",
        "Jiangyu Lei"
      ],
      "abstract": "Current studies have exposed the risk of Large Language Models (LLMs)\ngenerating harmful content by jailbreak attacks. However, they overlook that\nthe direct generation of harmful content from scratch is more difficult than\ninducing LLM to calibrate benign content into harmful forms. In our study, we\nintroduce a novel attack framework that exploits AdVersArial meTAphoR (AVATAR)\nto induce the LLM to calibrate malicious metaphors for jailbreaking.\nSpecifically, to answer harmful queries, AVATAR adaptively identifies a set of\nbenign but logically related metaphors as the initial seed. Then, driven by\nthese metaphors, the target LLM is induced to reason and calibrate about the\nmetaphorical content, thus jailbroken by either directly outputting harmful\nresponses or calibrating residuals between metaphorical and professional\nharmful content. Experimental results demonstrate that AVATAR can effectively\nand transferable jailbreak LLMs and achieve a state-of-the-art attack success\nrate across multiple advanced LLMs.",
      "tldr_zh": "该研究揭示了大型语言模型 (LLMs) 通过越狱攻击生成有害内容的风险，并提出了一种新框架 AVATAR，利用对抗性隐喻 (AdVersArial meTAphoR) 来诱导 LLM 将良性内容转化为有害形式。具体来说，AVATAR 针对有害查询动态识别相关隐喻作为初始种子，引导 LLM 进行推理和校准，从而直接输出有害响应或调整隐喻内容。实验结果表明，该框架在多个高级 LLM 上实现了最先进的攻击成功率，并展示了良好的可转移性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2412.12145",
      "pdf_url": "http://arxiv.org/pdf/2503.00038v1",
      "published_date": "2025-02-25 08:41:25 UTC",
      "updated_date": "2025-02-25 08:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:49:55.127675"
    },
    {
      "arxiv_id": "2502.17967v1",
      "title": "LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena",
      "title_zh": "翻译失败",
      "authors": [
        "Tianmi Ma",
        "Jiawei Du",
        "Wenxin Huang",
        "Wenjie Wang",
        "Liang Xie",
        "Xian Zhong",
        "Joey Tianyi Zhou"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nimproved performance in natural language processing tasks. However, their\nability to generalize to dynamic, unseen tasks, particularly in numerical\nreasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on\nproblems with predefined optimal solutions, which may not align with real-world\nscenarios where clear answers are absent. To bridge this gap, we design the\nAgent Trading Arena, a virtual numerical game simulating complex economic\nsystems through zero-sum games, where agents invest in stock portfolios. Our\nexperiments reveal that LLMs, including GPT-4o, struggle with algebraic\nreasoning when dealing with plain-text stock data, often focusing on local\ndetails rather than global trends. In contrast, LLMs perform significantly\nbetter with geometric reasoning when presented with visual data, such as\nscatter plots or K-line charts, suggesting that visual representations enhance\nnumerical reasoning. This capability is further improved by incorporating the\nreflection module, which aids in the analysis and interpretation of complex\ndata. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate\nstronger reasoning with visual data compared to text. Our code and data are\npublicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLM，如 GPT-4o）在数值推理中的局限性，特别是代数推理的弱点，而几何推理则更强。研究者设计了 Agent Trading Arena，一个模拟复杂经济系统的零和游戏环境，让 LLM 代理人投资股票组合，以评估其在动态任务中的表现。实验结果显示，LLM 在处理纯文本股票数据时易受局部细节影响，但当使用视觉数据（如散点图或 K-line 图）时，几何推理能力显著提升，且通过引入 reflection module，进一步提高了对复杂数据的分析和解释；在 NASDAQ 股票数据集上验证后，证实视觉表示能增强 LLM 的数值推理性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17967v1",
      "published_date": "2025-02-25 08:41:01 UTC",
      "updated_date": "2025-02-25 08:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:50:09.170355"
    },
    {
      "arxiv_id": "2504.05321v1",
      "title": "VALUE: Value-Aware Large Language Model for Query Rewriting via Weighted Trie in Sponsored Search",
      "title_zh": "翻译失败",
      "authors": [
        "Boyang Zuo",
        "Xiao Zhang",
        "Feng Li",
        "Pengjie Wang",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "In the realm of sponsored search advertising, matching advertisements with\nthe search intent of a user's query is crucial. Query-to-bidwords(i.e. bidding\nkeywords) rewriting is a vital technique that has garnered significant\nattention. Recently, with the prevalence of LLMs, generative retrieval methods\nhave proven effective in producing high-relevance rewrites. However, we have\nidentified a significant limitation in existing approaches: While fine-tuning\nLLMs for specific domains enhances semantic relevance, these models have no\nperception of the intrinsic value of their generated outputs, such as\ncommercial value. Therefore, after SFT, a RLHF phase is often employed to\naddress this issue. Nevertheless, traditional preference alignment methods\noften face challenges in aligning fine-grained values and are susceptible to\noverfitting, which diminishes the effectiveness and quality of the generated\nresults. To address these challenges, we propose VALUE(Value-Aware Large\nlanguage model for qUery rewriting via wEighted trie), the first framework that\nensures the generation of high-value and highly relevant bidwords. Our approach\nutilizes weighted trie, an innovative modification of the traditional trie data\nstructure. By modulating the LLM's output probability distribution with value\ninformation from the trie during decoding process, we constrain the generation\nspace and guide the trajectory of text production. Offline experiments\ndemonstrate the effectiveness of our method in semantic matching and preference\nalignment, showing a remarkable improvement in the value attribute by more than\nfivefold. Online A/B tests further revealed that our Revenue Per Mille (RPM)\nmetric increased by 1.64%. VALUE has been deployed on our advertising system\nsince October 2024 and served the Double Eleven promotions, the biggest\nshopping carnival in China.",
      "tldr_zh": "该论文提出 VALUE 框架，这是一种考虑价值的LLMs，用于在赞助搜索广告中进行查询重写，以生成高相关性和高商业价值的竞价关键词，从而解决现有方法忽略输出价值的局限性。VALUE 创新性地使用 weighted trie 数据结构，通过在解码过程中调节LLMs的输出概率分布来约束生成空间和引导文本生成，避免了传统RLHF方法的细粒度对齐挑战和过拟合问题。实验结果显示，离线测试中价值属性提升超过五倍，在线A/B测试中RPM指标增加1.64%，并已于2024年10月部署于实际广告系统服务双十一促销。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05321v1",
      "published_date": "2025-02-25 08:34:16 UTC",
      "updated_date": "2025-02-25 08:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:50:21.681214"
    },
    {
      "arxiv_id": "2502.18540v1",
      "title": "MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Zike Yuan",
        "Ming Liu",
        "Hui Wang",
        "Bing Qin"
      ],
      "abstract": "Graph-theoretic problems arise in real-world applications like logistics,\ncommunication networks, and traffic optimization. These problems are often\ncomplex, noisy, and irregular, posing challenges for traditional algorithms.\nLarge language models (LLMs) offer potential solutions but face challenges,\nincluding limited accuracy and input length constraints. To address these\nchallenges, we propose MA-GTS (Multi-Agent Graph Theory Solver), a multi-agent\nframework that decomposes these complex problems through agent collaboration.\nMA-GTS maps the implicitly expressed text-based graph data into clear,\nstructured graph representations and dynamically selects the most suitable\nalgorithm based on problem constraints and graph structure scale. This approach\nensures that the solution process remains efficient and the resulting reasoning\npath is interpretable. We validate MA-GTS using the G-REAL dataset, a\nreal-world-inspired graph theory dataset we created. Experimental results show\nthat MA-GTS outperforms state-of-the-art approaches in terms of efficiency,\naccuracy, and scalability, with strong results across multiple benchmarks\n(G-REAL 94.2%, GraCoRe 96.9%, NLGraph 98.4%).MA-GTS is open-sourced at\nhttps://github.com/ZIKEYUAN/MA-GTS.git.",
      "tldr_zh": "该研究提出MA-GTS，一种多智能体框架，用于解决现实应用中复杂图论问题（如物流、通信网络和交通优化），以应对传统算法和大型语言模型(LLMs)的准确性及输入长度限制挑战。MA-GTS通过代理协作分解问题，将隐式文本-based图数据映射为结构化表示，并动态选择最合适的算法，以确保高效且可解释的推理路径。实验在自创的G-REAL数据集上验证，MA-GTS在效率、准确性和可扩展性上优于现有方法，成绩包括G-REAL 94.2%、GraCoRe 96.9%和NLGraph 98.4%。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18540v1",
      "published_date": "2025-02-25 08:34:00 UTC",
      "updated_date": "2025-02-25 08:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:50:31.789129"
    },
    {
      "arxiv_id": "2502.17955v1",
      "title": "Language Models' Factuality Depends on the Language of Inquiry",
      "title_zh": "翻译失败",
      "authors": [
        "Tushar Aggarwal",
        "Kumar Tanmay",
        "Ayush Agrawal",
        "Kumar Ayush",
        "Hamid Palangi",
        "Paul Pu Liang"
      ],
      "abstract": "Multilingual language models (LMs) are expected to recall factual knowledge\nconsistently across languages, yet they often fail to transfer knowledge\nbetween languages even when they possess the correct information in one of the\nlanguages. For example, we find that an LM may correctly identify Rashed Al\nShashai as being from Saudi Arabia when asked in Arabic, but consistently fails\nto do so when asked in English or Swahili. To systematically investigate this\nlimitation, we introduce a benchmark of 10,000 country-related facts across 13\nlanguages and propose three novel metrics: Factual Recall Score, Knowledge\nTransferability Score, and Cross-Lingual Factual Knowledge Transferability\nScore-to quantify factual recall and knowledge transferability in LMs across\ndifferent languages. Our results reveal fundamental weaknesses in today's\nstate-of-the-art LMs, particularly in cross-lingual generalization where models\nfail to transfer knowledge effectively across different languages, leading to\ninconsistent performance sensitive to the language used. Our findings emphasize\nthe need for LMs to recognize language-specific factual reliability and\nleverage the most trustworthy information across languages. We release our\nbenchmark and evaluation framework to drive future research in multilingual\nknowledge transfer.",
      "tldr_zh": "本研究发现，多语言语言模型（LMs）的 factual recall（事实回忆）依赖于查询语言，常无法在语言间有效转移知识，即使模型在一种语言中掌握正确信息。研究者构建了一个包含10,000个国家相关事实的基准数据集，覆盖13种语言，并提出三个新指标：Factual Recall Score、Knowledge Transferability Score和Cross-Lingual Factual Knowledge Transferability Score，用于量化LMs在不同语言中的表现。结果显示，当前最先进的LMs在跨语言泛化方面存在根本缺陷，导致性能不一致，并强调LMs需识别语言特定的factual reliability（事实可靠性）并利用最可靠的信息。该基准和评估框架已发布，以推动多语言知识转移的未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17955v1",
      "published_date": "2025-02-25 08:27:18 UTC",
      "updated_date": "2025-02-25 08:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:50:44.402539"
    },
    {
      "arxiv_id": "2502.17951v1",
      "title": "Robust Polyp Detection and Diagnosis through Compositional Prompt-Guided Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jia Yu",
        "Yan Zhu",
        "Peiyao Fu",
        "Tianyi Chen",
        "Junbo Huang",
        "Quanlin Li",
        "Pinghong Zhou",
        "Zhihua Wang",
        "Fei Wu",
        "Shuo Wang",
        "Xian Yang"
      ],
      "abstract": "Colorectal cancer (CRC) is a significant global health concern, and early\ndetection through screening plays a critical role in reducing mortality. While\ndeep learning models have shown promise in improving polyp detection,\nclassification, and segmentation, their generalization across diverse clinical\nenvironments, particularly with out-of-distribution (OOD) data, remains a\nchallenge. Multi-center datasets like PolypGen have been developed to address\nthese issues, but their collection is costly and time-consuming. Traditional\ndata augmentation techniques provide limited variability, failing to capture\nthe complexity of medical images. Diffusion models have emerged as a promising\nsolution for generating synthetic polyp images, but the image generation\nprocess in current models mainly relies on segmentation masks as the condition,\nlimiting their ability to capture the full clinical context. To overcome these\nlimitations, we propose a Progressive Spectrum Diffusion Model (PSDM) that\nintegrates diverse clinical annotations-such as segmentation masks, bounding\nboxes, and colonoscopy reports-by transforming them into compositional prompts.\nThese prompts are organized into coarse and fine components, allowing the model\nto capture both broad spatial structures and fine details, generating\nclinically accurate synthetic images. By augmenting training data with\nPSDM-generated samples, our model significantly improves polyp detection,\nclassification, and segmentation. For instance, on the PolypGen dataset, PSDM\nincreases the F1 score by 2.12% and the mean average precision by 3.09%,\ndemonstrating superior performance in OOD scenarios and enhanced\ngeneralization.",
      "tldr_zh": "本研究针对结直肠癌（CRC）筛查中的息肉检测、分类和分割问题，提出了一种Robust Polyp Detection and Diagnosis框架，利用Progressive Spectrum Diffusion Model (PSDM)来生成高质量的合成图像。PSDM通过将多种临床注释（如分割掩码、边界框和结肠镜报告）转化为组合提示（compositional prompts），并组织成粗糙和精细组件，从而捕捉图像的宽广空间结构和细节细节，解决了传统扩散模型在临床上下文捕捉上的局限性。在PolypGen数据集上，实验结果显示，使用PSDM增强训练数据后，F1分数提高了2.12%，平均精度（mean average precision）提高了3.09%，尤其在Out-of-Distribution (OOD)场景中表现出色，提升了模型的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17951v1",
      "published_date": "2025-02-25 08:22:45 UTC",
      "updated_date": "2025-02-25 08:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:50:56.262584"
    },
    {
      "arxiv_id": "2502.17947v1",
      "title": "DeepSeek-R1 Outperforms Gemini 2.0 Pro, OpenAI o1, and o3-mini in Bilingual Complex Ophthalmology Reasoning",
      "title_zh": "DeepSeek-R1 在双语复杂眼科推理中优于 Gemini 2.0 Pro、OpenAI o1 和 o3-mini",
      "authors": [
        "Pusheng Xu",
        "Yue Wu",
        "Kai Jin",
        "Xiaolan Chen",
        "Mingguang He",
        "Danli Shi"
      ],
      "abstract": "Purpose: To evaluate the accuracy and reasoning ability of DeepSeek-R1 and\nthree other recently released large language models (LLMs) in bilingual complex\nophthalmology cases. Methods: A total of 130 multiple-choice questions (MCQs)\nrelated to diagnosis (n = 39) and management (n = 91) were collected from the\nChinese ophthalmology senior professional title examination and categorized\ninto six topics. These MCQs were translated into English using DeepSeek-R1. The\nresponses of DeepSeek-R1, Gemini 2.0 Pro, OpenAI o1 and o3-mini were generated\nunder default configurations between February 15 and February 20, 2025.\nAccuracy was calculated as the proportion of correctly answered questions, with\nomissions and extra answers considered incorrect. Reasoning ability was\nevaluated through analyzing reasoning logic and the causes of reasoning error.\nResults: DeepSeek-R1 demonstrated the highest overall accuracy, achieving 0.862\nin Chinese MCQs and 0.808 in English MCQs. Gemini 2.0 Pro, OpenAI o1, and\nOpenAI o3-mini attained accuracies of 0.715, 0.685, and 0.692 in Chinese MCQs\n(all P<0.001 compared with DeepSeek-R1), and 0.746 (P=0.115), 0.723 (P=0.027),\nand 0.577 (P<0.001) in English MCQs, respectively. DeepSeek-R1 achieved the\nhighest accuracy across five topics in both Chinese and English MCQs. It also\nexcelled in management questions conducted in Chinese (all P<0.05). Reasoning\nability analysis showed that the four LLMs shared similar reasoning logic.\nIgnoring key positive history, ignoring key positive signs, misinterpretation\nmedical data, and too aggressive were the most common causes of reasoning\nerrors. Conclusion: DeepSeek-R1 demonstrated superior performance in bilingual\ncomplex ophthalmology reasoning tasks than three other state-of-the-art LLMs.\nWhile its clinical applicability remains challenging, it shows promise for\nsupporting diagnosis and clinical decision-making.",
      "tldr_zh": "这篇论文评估了 DeepSeek-R1 与 Gemini 2.0 Pro、OpenAI o1 和 o3-mini 在双语复杂眼科推理任务中的准确性和推理能力，使用 130 个多选题（MCQs）进行测试，包括诊断和管理相关问题。结果显示，DeepSeek-R1 在中文 MCQs 中准确率达 0.862，在英文 MCQs 中为 0.808，显著优于其他模型（例如 Gemini 2.0 Pro 在中文中的 0.715）。推理能力分析表明，四种 LLMs 的推理逻辑相似，但常见错误如忽略关键病史、误解医疗数据和过于激进的判断影响了表现。总体而言，DeepSeek-R1 展示了在眼科诊断和临床决策支持的潜力，但其临床适用性仍面临挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.17947v1",
      "published_date": "2025-02-25 08:08:53 UTC",
      "updated_date": "2025-02-25 08:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:51:08.939875"
    },
    {
      "arxiv_id": "2502.17941v2",
      "title": "Optimal Brain Apoptosis",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyuan Sun",
        "Zheng Fang",
        "Jiaxu Wang",
        "Junjie Jiang",
        "Delei Kong",
        "Chenming Hu",
        "Yuetong Fang",
        "Renjing Xu"
      ],
      "abstract": "The increasing complexity and parameter count of Convolutional Neural\nNetworks (CNNs) and Transformers pose challenges in terms of computational\nefficiency and resource demands. Pruning has been identified as an effective\nstrategy to address these challenges by removing redundant elements such as\nneurons, channels, or connections, thereby enhancing computational efficiency\nwithout heavily compromising performance. This paper builds on the foundational\nwork of Optimal Brain Damage (OBD) by advancing the methodology of parameter\nimportance estimation using the Hessian matrix. Unlike previous approaches that\nrely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel\npruning method that calculates the Hessian-vector product value directly for\neach parameter. By decomposing the Hessian matrix across network layers and\nidentifying conditions under which inter-layer Hessian submatrices are\nnon-zero, we propose a highly efficient technique for computing the\nsecond-order Taylor expansion of parameters. This approach allows for a more\nprecise pruning process, particularly in the context of CNNs and Transformers,\nas validated in our experiments including VGG19, ResNet32, ResNet50, and\nViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at\nhttps://github.com/NEU-REAL/OBA.",
      "tldr_zh": "这篇论文针对 Convolutional Neural Networks (CNNs) 和 Transformers 的复杂性及参数数量问题，提出了一种新型修剪方法 Optimal Brain Apoptosis (OBA)，以提升计算效率。OBA 基于 Hessian matrix 直接计算每个参数的 Hessian-vector product，并通过分解矩阵并识别非零子矩阵，实现高效的第二阶 Taylor 展开，从而实现更精确的修剪过程。实验结果显示，OBA 在 VGG19、ResNet32、ResNet50 和 ViT-B/16 等模型上，在 CIFAR10、CIFAR100 和 Imagenet 数据集上表现出色，证明了其在不显著牺牲性能的情况下提高资源利用率的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.17941v2",
      "published_date": "2025-02-25 08:03:04 UTC",
      "updated_date": "2025-03-03 12:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:51:19.834963"
    },
    {
      "arxiv_id": "2502.18538v1",
      "title": "Revisiting Convolution Architecture in the Realm of DNA Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Bo",
        "Weian Mao",
        "Yanjun Shao",
        "Weiqiang Bai",
        "Peng Ye",
        "Xinzhu Ma",
        "Junbo Zhao",
        "Hao Chen",
        "Chunhua Shen"
      ],
      "abstract": "In recent years, a variety of methods based on Transformer and state space\nmodel (SSM) architectures have been proposed, advancing foundational DNA\nlanguage models. However, there is a lack of comparison between these recent\napproaches and the classical architecture convolutional networks (CNNs) on\nfoundation model benchmarks. This raises the question: are CNNs truly being\nsurpassed by these recent approaches based on transformer and SSM\narchitectures? In this paper, we develop a simple but well-designed CNN-based\nmethod termed ConvNova. ConvNova identifies and proposes three effective\ndesigns: 1) dilated convolutions, 2) gated convolutions, and 3) a dual-branch\nframework for gating mechanisms. Through extensive empirical experiments, we\ndemonstrate that ConvNova significantly outperforms recent methods on more than\nhalf of the tasks across several foundation model benchmarks. For example, in\nhistone-related tasks, ConvNova exceeds the second-best method by an average of\n5.8%, while generally utilizing fewer parameters and enabling faster\ncomputation. In addition, the experiments observed findings that may be related\nto biological characteristics. This indicates that CNNs are still a strong\ncompetitor compared to Transformers and SSMs. We anticipate that this work will\nspark renewed interest in CNN-based methods for DNA foundation models.",
      "tldr_zh": "该研究重新审视了在 DNA 基础模型领域中，Convolutional Networks (CNNs) 与 Transformer 和 State Space Model (SSMs) 的性能比较，质疑后者是否已真正超越前者。论文提出了一种简洁有效的 CNN-based 方法 ConvNova，包括 dilated convolutions、gated convolutions 和 dual-branch framework for gating mechanisms，通过这些设计提升了模型的性能。在多个基准测试中，ConvNova 在超过一半的任务上优于现有方法，例如在 histone-related 任务上平均超过第二名 5.8%，同时使用更少参数和更快计算。实验结果表明，CNNs 仍是 Transformer 和 SSMs 的强有力竞争者，并可能揭示与生物特性相关的洞见，期望此工作重新激发对 CNN-based 方法的兴趣。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18538v1",
      "published_date": "2025-02-25 08:00:05 UTC",
      "updated_date": "2025-02-25 08:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:51:31.423302"
    },
    {
      "arxiv_id": "2503.04782v1",
      "title": "SMT(LIA) Sampling with High Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Lai",
        "Junjie Li",
        "Chuan Luo"
      ],
      "abstract": "Satisfiability Modulo Linear Integer Arithmetic, SMT(LIA) for short, is\npivotal across various critical domains. Previous research has primarily\nfocused on SMT solving techniques. However, in practical applications such as\nsoftware and hardware testing, there is a need to generate a diverse set of\nsolutions for use as test inputs. We have developed the first sampling\nframework that integrates local search with CDCL(T) techniques, named HighDiv,\ncapable of generating a highly diverse set of solutions for constraints under\nlinear integer theory. Initially, in the local search phase, we introduced a\nnovel operator called boundary-aware movement. This operator performs random\nmoves by considering the current state's constraints on variables, thereby\nenhancing the diversity of variables during the search process. Furthermore, we\nhave conducted an in-depth study of the preprocessing and variable\ninitialization mechanisms within the framework, which significantly enhances\nthe efficiency of subsequent local searches. Lastly, we use the solutions\nobtained from local search sampling as additional constraints to further\nexplore the solution space using the stochastic CDCL(T) method. Experimental\nresults demonstrate that \\HighDiv generates solutions with greater diversity\ncompared to the state-of-the-art SMT(LIA) sampling tool, MeGASampler.",
      "tldr_zh": "本文提出 HighDiv，这是一个首创的采样框架，整合局部搜索和 CDCL(T) 技术，用于生成 SMT(LIA) 约束下的高度多样化解决方案，以满足软件和硬件测试等实际需求。框架引入 boundary-aware movement 操作符，通过考虑变量当前约束进行随机移动，从而提升搜索过程中的变量多样性；同时优化预处理和变量初始化机制，提高整体效率。实验结果表明，HighDiv 与最先进的 SMT(LIA) 采样工具 MeGASampler 相比，能生成更具多样性的解决方案。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04782v1",
      "published_date": "2025-02-25 07:53:46 UTC",
      "updated_date": "2025-02-25 07:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:51:43.929009"
    },
    {
      "arxiv_id": "2502.17929v1",
      "title": "Integrating Boosted learning with Differential Evolution (DE) Optimizer: A Prediction of Groundwater Quality Risk Assessment in Odisha",
      "title_zh": "翻译失败",
      "authors": [
        "Sonalika Subudhi",
        "Alok Kumar Pati",
        "Sephali Bose",
        "Subhasmita Sahoo",
        "Avipsa Pattanaik",
        "Biswa Mohan Acharya"
      ],
      "abstract": "Groundwater is eventually undermined by human exercises, such as fast\nindustrialization, urbanization, over-extraction, and contamination from\nagrarian and urban sources. From among the different contaminants, the presence\nof heavy metals like cadmium (Cd), chromium (Cr), arsenic (As), and lead (Pb)\nproves to have serious dangers when present in huge concentrations in\ngroundwater. Long-term usage of these poisonous components may lead to\nneurological disorders, kidney failure and different sorts of cancer. To\naddress these issues, this study developed a machine learning-based predictive\nmodel to evaluate the Groundwater Quality Index (GWQI) and identify the main\ncontaminants which are affecting the water quality. It has been achieved with\nthe help of a hybrid machine learning model i.e. LCBoost Fusion . The model has\nundergone several processes like data preprocessing, hyperparameter tuning\nusing Differential Evolution (DE) optimization, and evaluation through\ncross-validation. The LCBoost Fusion model outperforms individual models\n(CatBoost and LightGBM), by achieving low RMSE (0.6829), MSE (0.5102), MAE\n(0.3147) and a high R$^2$ score of 0.9809. Feature importance analysis\nhighlights Potassium (K), Fluoride (F) and Total Hardness (TH) as the most\ninfluential indicators of groundwater contamination. This research successfully\ndemonstrates the application of machine learning in assessing groundwater\nquality risks in Odisha. The proposed LCBoost Fusion model offers a reliable\nand efficient approach for real-time groundwater monitoring and risk\nmitigation. These findings will help the environmental organizations and the\npolicy makers to map out targeted places for sustainable groundwater\nmanagement. Future work will focus on using remote sensing data and developing\nan interactive decision-making system for groundwater quality assessment.",
      "tldr_zh": "本研究针对Odisha地区地下水质量风险评估，开发了一种集成Boosted learning与Differential Evolution (DE)优化的混合机器学习模型LCBoost Fusion，用于预测Groundwater Quality Index (GWQI)并识别主要污染物，如重金属(Cd、Cr、As、Pb)。该模型通过数据预处理、DE优化超参数调优和交叉验证，显著优于CatBoost和LightGBM等单个模型，实现了低RMSE (0.6829)、MSE (0.5102)、MAE (0.3147)和高R²分数 (0.9809)。特征重要性分析显示Potassium (K)、Fluoride (F)和Total Hardness (TH)是关键影响因素，为地下水污染风险监测提供可靠工具。未来工作将整合遥感数据，开发交互式决策系统以支持可持续管理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 Figures (8 figs in paper and one additional graphical abstract), 9\n  Tables",
      "pdf_url": "http://arxiv.org/pdf/2502.17929v1",
      "published_date": "2025-02-25 07:47:41 UTC",
      "updated_date": "2025-02-25 07:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:51:57.627954"
    },
    {
      "arxiv_id": "2503.01865v1",
      "title": "Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiao Yang",
        "Zhexin Zhang",
        "Shiyao Cui",
        "Hongning Wang",
        "Minlie Huang"
      ],
      "abstract": "Jailbreaking attacks can effectively induce unsafe behaviors in Large\nLanguage Models (LLMs); however, the transferability of these attacks across\ndifferent models remains limited. This study aims to understand and enhance the\ntransferability of gradient-based jailbreaking methods, which are among the\nstandard approaches for attacking white-box models. Through a detailed analysis\nof the optimization process, we introduce a novel conceptual framework to\nelucidate transferability and identify superfluous constraints-specifically,\nthe response pattern constraint and the token tail constraint-as significant\nbarriers to improved transferability. Removing these unnecessary constraints\nsubstantially enhances the transferability and controllability of\ngradient-based attacks. Evaluated on Llama-3-8B-Instruct as the source model,\nour method increases the overall Transfer Attack Success Rate (T-ASR) across a\nset of target models with varying safety levels from 18.4% to 50.3%, while also\nimproving the stability and controllability of jailbreak behaviors on both\nsource and target models.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的越狱攻击（jailbreaking attacks），发现基于梯度的攻击方法在不同模型间的转移性（transferability）有限，并通过分析优化过程引入一个新概念框架。论文识别出多余约束（superfluous constraints），包括响应模式约束（response pattern constraint）和令牌尾约束（token tail constraint），并提出移除这些约束以提升攻击的转移性和可控性。在以 Llama-3-8B-Instruct 为源模型的实验中，该方法将转移攻击成功率（T-ASR）从 18.4% 提高到 50.3%，并改善了在源模型和目标模型上的稳定性和可控性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01865v1",
      "published_date": "2025-02-25 07:47:41 UTC",
      "updated_date": "2025-02-25 07:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:52:08.997049"
    },
    {
      "arxiv_id": "2502.17928v1",
      "title": "Structure-prior Informed Diffusion Model for Graph Source Localization with Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Chen",
        "Jingtao Ding",
        "Xiaojun Liang",
        "Yong Li",
        "Xiao-Ping Zhang"
      ],
      "abstract": "The source localization problem in graph information propagation is crucial\nfor managing various network disruptions, from misinformation spread to\ninfrastructure failures. While recent deep generative approaches have shown\npromise in this domain, their effectiveness is limited by the scarcity of\nreal-world propagation data. This paper introduces SIDSL\n(\\textbf{S}tructure-prior \\textbf{I}nformed \\textbf{D}iffusion model for\n\\textbf{S}ource \\textbf{L}ocalization), a novel framework that addresses three\nkey challenges in limited-data scenarios: unknown propagation patterns, complex\ntopology-propagation relationships, and class imbalance between source and\nnon-source nodes. SIDSL incorporates topology-aware priors through graph label\npropagation and employs a propagation-enhanced conditional denoiser with a\nGNN-parameterized label propagation module (GNN-LP). Additionally, we propose a\nstructure-prior biased denoising scheme that initializes from structure-based\nsource estimations rather than random noise, effectively countering class\nimbalance issues. Experimental results across four real-world datasets\ndemonstrate SIDSL's superior performance, achieving 7.5-13.3% improvements in\nF1 scores compared to state-of-the-art methods. Notably, when pretrained with\nsimulation data of synthetic patterns, SIDSL maintains robust performance with\nonly 10% of training data, surpassing baselines by more than 18.8%. These\nresults highlight SIDSL's effectiveness in real-world applications where\nlabeled data is scarce.",
      "tldr_zh": "本研究针对图源定位问题在数据稀缺场景下的挑战，提出了一种结构先验 Informed Diffusion Model 框架，即 SIDSL，以处理未知传播模式、复杂的拓扑-传播关系以及源节点与非源节点的类别不平衡问题。SIDSL 通过图标签传播融入拓扑感知先验，并采用传播增强的条件去噪器（包括 GNN-parameterized label propagation module, GNN-LP）和基于结构的源估计初始化方案来优化去噪过程，从而提升模型性能。在四个真实数据集上的实验显示，SIDSL 比现有方法提高了 7.5-13.3% 的 F1 分数；此外，当仅使用 10% 的训练数据并结合模拟预训练时，其表现仍超出基线 18.8%，证明了其在数据有限的实际应用中的鲁棒性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17928v1",
      "published_date": "2025-02-25 07:47:22 UTC",
      "updated_date": "2025-02-25 07:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:52:20.091160"
    },
    {
      "arxiv_id": "2502.17925v2",
      "title": "LeanProgress: Guiding Search for Neural Theorem Proving via Proof Progress Prediction",
      "title_zh": "LeanProgress：通过证明进度预测指导神经定理证明的搜索",
      "authors": [
        "Suozhi Huang",
        "Peiyang Song",
        "Robert Joseph George",
        "Anima Anandkumar"
      ],
      "abstract": "Mathematical reasoning remains a significant challenge for Large Language\nModels (LLMs) due to hallucinations. When combined with formal proof assistants\nlike Lean, these hallucinations can be eliminated through rigorous\nverification, making theorem proving reliable. However, even with formal\nverification, LLMs still struggle with long proofs and complex mathematical\nformalizations. While Lean with LLMs offers valuable assistance with retrieving\nlemmas, generating tactics, or even complete proofs, it lacks a crucial\ncapability: providing a sense of proof progress. This limitation particularly\nimpacts the overall development efficiency in large formalization projects. We\nintroduce LeanProgress, a method that predicts the progress in the proof.\nTraining and evaluating our models made on a large corpus of Lean proofs from\nLean Workbook Plus and Mathlib4 and how many steps remain to complete it, we\nemploy data preprocessing and balancing techniques to handle the skewed\ndistribution of proof lengths. Our experiments show that LeanProgress achieves\nan overall prediction accuracy of 75.1\\% in predicting the amount of progress\nand, hence, the remaining number of steps. When integrated into a best-first\nsearch framework using Reprover, our method shows a 3.8\\% improvement on\nMathlib4 compared to baseline performances of 41.2\\%, particularly for longer\nproofs. These results demonstrate how proof progress prediction can enhance\nboth automated and interactive theorem proving, enabling users to make more\ninformed decisions about proof strategies.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在数学推理中的幻觉问题，提出LeanProgress方法，通过预测证明进展（如剩余步骤数量）来指导神经定理证明过程，从而提升与Lean证明助手的交互效率。研究团队利用Lean Workbook Plus和Mathlib4的庞大语料进行模型训练，并采用数据预处理和平衡技术处理证明长度分布的偏差。实验结果显示，LeanProgress的预测准确率达75.1%，并在整合到Reprover的最佳优先搜索框架后，使Mathlib4上的性能提升3.8%，尤其在长证明上，帮助用户做出更明智的证明策略决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17925v2",
      "published_date": "2025-02-25 07:46:36 UTC",
      "updated_date": "2025-02-27 17:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:52:33.536814"
    },
    {
      "arxiv_id": "2502.17921v1",
      "title": "Unmasking Gender Bias in Recommendation Systems and Enhancing Category-Aware Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Tahsin Alamgir Kheya",
        "Mohamed Reda Bouadjenek",
        "Sunil Aryal"
      ],
      "abstract": "Recommendation systems are now an integral part of our daily lives. We rely\non them for tasks such as discovering new movies, finding friends on social\nmedia, and connecting job seekers with relevant opportunities. Given their\nvital role, we must ensure these recommendations are free from societal\nstereotypes. Therefore, evaluating and addressing such biases in recommendation\nsystems is crucial. Previous work evaluating the fairness of recommended items\nfails to capture certain nuances as they mainly focus on comparing performance\nmetrics for different sensitive groups. In this paper, we introduce a set of\ncomprehensive metrics for quantifying gender bias in recommendations.\nSpecifically, we show the importance of evaluating fairness on a more granular\nlevel, which can be achieved using our metrics to capture gender bias using\ncategories of recommended items like genres for movies. Furthermore, we show\nthat employing a category-aware fairness metric as a regularization term along\nwith the main recommendation loss during training can help effectively minimize\nbias in the models' output. We experiment on three real-world datasets, using\nfive baseline models alongside two popular fairness-aware models, to show the\neffectiveness of our metrics in evaluating gender bias. Our metrics help\nprovide an enhanced insight into bias in recommended items compared to previous\nmetrics. Additionally, our results demonstrate how incorporating our\nregularization term significantly improves the fairness in recommendations for\ndifferent categories without substantial degradation in overall recommendation\nperformance.",
      "tldr_zh": "该研究揭示了推荐系统中的性别偏见问题，并提出了一套全面的指标来量化这种偏见，特别是通过类别感知方式（如电影类型）实现更细粒度的公平评估。作者引入了一种将 category-aware fairness metrics 作为正则化项整合到推荐模型训练中的方法，以有效减少偏见。实验在三个真实数据集上使用五种基线模型和两种公平感知模型进行验证，结果显示，该方法显著提高了推荐的公平性，同时未大幅降低整体性能表现。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17921v1",
      "published_date": "2025-02-25 07:37:28 UTC",
      "updated_date": "2025-02-25 07:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:52:43.193150"
    },
    {
      "arxiv_id": "2502.17912v2",
      "title": "Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Chen",
        "Yihong Luo",
        "Yifan Song",
        "Pengwen Dai",
        "Jing Tang",
        "Xiaochun Cao"
      ],
      "abstract": "Despite extensive research efforts focused on OOD detection on images, OOD\ndetection on nodes in graph learning remains underexplored. The dependence\namong graph nodes hinders the trivial adaptation of existing approaches on\nimages that assume inputs to be i.i.d. sampled, since many unique features and\nchallenges specific to graphs are not considered, such as the heterophily\nissue. Recently, GNNSafe, which considers node dependence, adapted energy-based\ndetection to the graph domain with state-of-the-art performance, however, it\nhas two serious issues: 1) it derives node energy from classification logits\nwithout specifically tailored training for modeling data distribution, making\nit less effective at recognizing OOD data; 2) it highly relies on energy\npropagation, which is based on homophily assumption and will cause significant\nperformance degradation on heterophilic graphs, where the node tends to have\ndissimilar distribution with its neighbors. To address the above issues, we\nsuggest training EBMs by MLE to enhance data distribution modeling and remove\nenergy propagation to overcome the heterophily issues. However, training EBMs\nvia MLE requires performing MCMC sampling on both node feature and node\nneighbors, which is challenging due to the node interdependence and discrete\ngraph topology. To tackle the sampling challenge, we introduce DeGEM, which\ndecomposes the learning process into two parts: a graph encoder that leverages\ntopology information for node representations and an energy head that operates\nin latent space. Extensive experiments validate that DeGEM, without OOD\nexposure during training, surpasses previous state-of-the-art methods,\nachieving an average AUROC improvement of 6.71% on homophilic graphs and 20.29%\non heterophilic graphs, and even outperform methods trained with OOD exposure.\nOur code is available at: https://github.com/draym28/DeGEM.",
      "tldr_zh": "该论文针对异质图（heterophilic graphs）中的节点异常检测（OOD detection）问题，提出了一种解耦的图能量模型（DeGEM），通过最大似然估计（MLE）训练能量基模型（EBMs）来更好地建模数据分布，同时去除能量传播以避免同质性假设带来的性能下降。DeGEM 将学习过程分解为图编码器（利用图拓扑信息生成节点表示）和能量头（在潜在空间操作），从而解决节点互依赖和离散拓扑带来的 MCMC 采样挑战。实验结果显示，该方法在无 OOD 数据训练的情况下，超越了现有最先进方法，在同质图上 AUROC 平均提升 6.71%，在异质图上提升 20.29%，甚至优于使用 OOD 数据训练的模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally to this work; ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.17912v2",
      "published_date": "2025-02-25 07:20:00 UTC",
      "updated_date": "2025-03-17 08:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:52:57.291562"
    },
    {
      "arxiv_id": "2502.17911v1",
      "title": "Enhancing Speech Quality through the Integration of BGRU and Transformer Architectures",
      "title_zh": "通过 BGRU 和 Transformer 架构的整合提升语音质量",
      "authors": [
        "Souliman Alghnam",
        "Mohammad Alhussien",
        "Khaled Shaheen"
      ],
      "abstract": "Speech enhancement plays an essential role in improving the quality of speech\nsignals in noisy environments. This paper investigates the efficacy of\nintegrating Bidirectional Gated Recurrent Units (BGRU) and Transformer models\nfor speech enhancement tasks. Through a comprehensive experimental evaluation,\nour study demonstrates the superiority of this hybrid architecture over\ntraditional methods and standalone models. The combined BGRU-Transformer\nframework excels in capturing temporal dependencies and learning complex signal\npatterns, leading to enhanced noise reduction and improved speech quality.\nResults show significant performance gains compared to existing approaches,\nhighlighting the potential of this integrated model in real-world applications.\nThe seamless integration of BGRU and Transformer architectures not only\nenhances system robustness but also opens the road for advanced speech\nprocessing techniques. This research contributes to the ongoing efforts in\nspeech enhancement technology and sets a solid foundation for future\ninvestigations into optimizing model architectures, exploring many application\nscenarios, and advancing the field of speech processing in noisy environments.",
      "tldr_zh": "本研究探讨了通过整合Bidirectional Gated Recurrent Units (BGRU)和Transformer架构来提升语音增强性能，以改善嘈杂环境中的语音信号质量。混合BGRU-Transformer框架能够更好地捕捉时间依赖性和复杂信号模式，从而实现更有效的噪声减少和语音质量提升。实验结果显示，该方法比传统方法和独立模型表现出显著性能优势，提升了系统鲁棒性，并为高级语音处理技术提供了新方向。研究为语音增强领域奠定了基础，支持未来在模型优化和实际应用场景的探索。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17911v1",
      "published_date": "2025-02-25 07:18:35 UTC",
      "updated_date": "2025-02-25 07:18:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:53:07.969163"
    },
    {
      "arxiv_id": "2502.17910v1",
      "title": "Scaling LLM Pre-training with Vocabulary Curriculum",
      "title_zh": "翻译失败",
      "authors": [
        "Fangyuan Yu"
      ],
      "abstract": "Modern language models rely on static vocabularies, fixed before pretraining,\nin contrast to the adaptive vocabulary acquisition observed in human language\nlearning. To bridge this gap, we introduce vocabulary curriculum learning, an\napproach that improves pretraining efficiency with log-linear scaling gains\nrelative to vocabulary size. Our method alternates between entropy-guided\nvocabulary expansion and model optimization, enabling models to learn\ntransferable representations across diverse tokenization granularities. This\napproach naturally gives rise to an optimal computation allocation pattern:\nlonger tokens capture predictable content, while shorter tokens focus on more\ncomplex, harder-to-predict contexts. Experiments on small-scale GPT models\ndemonstrate improved scaling efficiency, reinforcing the effectiveness of\ndynamic tokenization. We release our code to support further research and plan\nto extend our experiments to larger models and diverse domains.",
      "tldr_zh": "该研究提出了一种词汇课程学习（vocabulary curriculum learning）方法，以提升大型语言模型（LLM）预训练的效率，实现与词汇大小相关的对数线性缩放收益。方法通过交替进行基于熵的词汇扩展（entropy-guided vocabulary expansion）和模型优化，让模型适应不同分词粒度的可转移表示，从而实现最佳计算分配：较长标记处理可预测内容，而较短标记聚焦复杂上下文。在小型 GPT models 的实验中，该方法显著提高了缩放效率，作者已发布代码并计划扩展到更大模型和更多领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2502.17910v1",
      "published_date": "2025-02-25 07:18:29 UTC",
      "updated_date": "2025-02-25 07:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:53:20.159194"
    },
    {
      "arxiv_id": "2502.19532v1",
      "title": "Opus: A Workflow Intention Framework for Complex Workflow Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Kingston",
        "Théo Fagnoni",
        "Mahsun Altin"
      ],
      "abstract": "This paper introduces Workflow Intention, a novel framework for identifying\nand encoding process objectives within complex business environments. Workflow\nIntention is the alignment of Input, Process and Output elements defining a\nWorkflow's transformation objective interpreted from Workflow Signal inside\nBusiness Artefacts. It specifies how Input is processed to achieve desired\nOutput, incorporating quality standards, business rules, compliance\nrequirements and constraints. We adopt an end-to-end Business Artefact Encoder\nand Workflow Signal interpretation methodology involving four steps:\nModality-Specific Encoding, Intra-Modality Attention, Inter-Modality Fusion\nAttention then Intention Decoding. We provide training procedures and critical\nloss function definitions. In this paper we introduce the concepts of Workflow\nSignal and Workflow Intention, where Workflow Signal decomposed into Input,\nProcess and Output elements is interpreted from Business Artefacts, and\nWorkflow Intention is a complete triple of these elements. We introduce a\nmathematical framework for representing Workflow Signal as a vector and\nWorkflow Intention as a tensor, formalizing properties of these objects.\nFinally, we propose a modular, scalable, trainable, attention-based multimodal\ngenerative system to resolve Workflow Intention from Business Artefacts.",
      "tldr_zh": "本论文引入了 Workflow Intention 框架，用于识别和编码复杂商业环境中的过程目标，将 Workflow Signal 从 Business Artefacts 中解释为 Input、Process 和 Output 元素的完整三元组，并考虑质量标准、业务规则和合规约束。框架采用端到端的 Business Artefact Encoder 和 Workflow Signal 解释方法，包括四个步骤：Modality-Specific Encoding、Intra-Modality Attention、Inter-Modality Fusion Attention 和 Intention Decoding，同时提供训练程序和关键损失函数定义。论文还建立了数学框架，将 Workflow Signal 表示为向量、Workflow Intention 表示为张量，并提出一个模块化、可扩展的基于注意力的多模态生成系统，以从 Business Artefacts 中解析 Workflow Intention，从而提升复杂工作流的生成效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "1 Figure, 27 Pages",
      "pdf_url": "http://arxiv.org/pdf/2502.19532v1",
      "published_date": "2025-02-25 07:16:46 UTC",
      "updated_date": "2025-02-25 07:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:53:33.189043"
    },
    {
      "arxiv_id": "2502.17909v1",
      "title": "FactFlow: Automatic Fact Sheet Generation and Customization from Tabular Dataset via AI Chain Design & Implementation",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Duc Vu",
        "Jieshan Chen",
        "Zhenchang Xing",
        "Qinghua Lu",
        "Xiwei Xu",
        "Qian Fu"
      ],
      "abstract": "With the proliferation of data across various domains, there is a critical\ndemand for tools that enable non-experts to derive meaningful insights without\ndeep data analysis skills. To address this need, existing automatic fact sheet\ngeneration tools offer heuristic-based solutions to extract facts and generate\nstories. However, they inadequately grasp the semantics of data and struggle to\ngenerate narratives that fully capture the semantics of the dataset or align\nthe fact sheet with specific user needs. Addressing these shortcomings, this\npaper introduces \\tool, a novel tool designed for the automatic generation and\ncustomisation of fact sheets. \\tool applies the concept of collaborative AI\nworkers to transform raw tabular dataset into comprehensive, visually\ncompelling fact sheets. We define effective taxonomy to profile AI worker for\nspecialised tasks. Furthermore, \\tool empowers users to refine these fact\nsheets through intuitive natural language commands, ensuring the final outputs\nalign closely with individual preferences and requirements. Our user evaluation\nwith 18 participants confirms that \\tool not only surpasses state-of-the-art\nbaselines in automated fact sheet production but also provides a positive user\nexperience during customization tasks.",
      "tldr_zh": "本论文提出 FactFlow，一种通过 AI Chain Design & Implementation 的新工具，用于从 tabular dataset 自动生成和自定义事实表，以解决现有工具在数据语义理解和用户需求对齐方面的不足。FactFlow 采用协作 AI workers 和定义的有效 taxonomy，将原始数据转化为全面、可视化的事实表。用户可以通过直观的 natural language commands 精炼输出，确保结果符合个人偏好。用户评估（涉及 18 名参与者）显示，FactFlow 超过了现有基线，在自动生成和自定义任务中提供了更积极的用户体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; H.4"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.17909v1",
      "published_date": "2025-02-25 07:15:41 UTC",
      "updated_date": "2025-02-25 07:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:53:45.784949"
    },
    {
      "arxiv_id": "2502.17903v1",
      "title": "Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Krupp",
        "Daniel Geißler",
        "Paul Lukowicz",
        "Jakob Karolus"
      ],
      "abstract": "Improvements in the area of large language models have shifted towards the\nconstruction of models capable of using external tools and interpreting their\noutputs. These so-called web agents have the ability to interact autonomously\nwith the internet. This allows them to become powerful daily assistants\nhandling time-consuming, repetitive tasks while supporting users in their daily\nactivities. While web agent research is thriving, the sustainability aspect of\nthis research direction remains largely unexplored. We provide an initial\nexploration of the energy and CO2 cost associated with web agents. Our results\nshow how different philosophies in web agent creation can severely impact the\nassociated expended energy. We highlight lacking transparency regarding the\ndisclosure of model parameters and processes used for some web agents as a\nlimiting factor when estimating energy consumption. As such, our work advocates\na change in thinking when evaluating web agents, warranting dedicated metrics\nfor energy consumption and sustainability.",
      "tldr_zh": "该论文探讨了大型语言模型（Large Language Models）中 web agents 的可持续性问题，强调这些代理能自主与互联网互动并辅助日常任务，但其能源消耗和 CO2 成本尚未得到充分关注。通过初步探索，研究发现不同 web agents 创建哲学会显著影响能源消耗，而模型参数和过程的缺乏透明度阻碍了准确估计。论文呼吁在评估 web agents 时引入专用指标，如能源消耗和可持续性指标，以推动更负责任的研究方向。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17903v1",
      "published_date": "2025-02-25 06:58:40 UTC",
      "updated_date": "2025-02-25 06:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:53:57.090505"
    },
    {
      "arxiv_id": "2502.17900v1",
      "title": "Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Che Liu",
        "Cheng Ouyang",
        "Zhongwei Wan",
        "Haozhe Wang",
        "Wenjia Bai",
        "Rossella Arcucci"
      ],
      "abstract": "Recent advances in multimodal ECG representation learning center on aligning\nECG signals with paired free-text reports. However, suboptimal alignment\npersists due to the complexity of medical language and the reliance on a full\n12-lead setup, which is often unavailable in under-resourced settings. To\ntackle these issues, we propose **K-MERL**, a knowledge-enhanced multimodal ECG\nrepresentation learning framework. **K-MERL** leverages large language models\nto extract structured knowledge from free-text reports and employs a lead-aware\nECG encoder with dynamic lead masking to accommodate arbitrary lead inputs.\nEvaluations on six external ECG datasets show that **K-MERL** achieves\nstate-of-the-art performance in zero-shot classification and linear probing\ntasks, while delivering an average **16%** AUC improvement over existing\nmethods in partial-lead zero-shot classification.",
      "tldr_zh": "本研究提出 K-MERL，一种知识增强的多模态 ECG 表示学习框架，旨在解决 ECG 信号与自由文本报告的对齐问题以及对完整 12 导联的依赖。\nK-MERL 利用 large language models 从文本报告中提取结构化知识，并采用 lead-aware ECG encoder 和 dynamic lead masking 来处理任意导联输入。\n在六个外部 ECG 数据集上评估，该框架在 zero-shot classification 和 linear probing 任务中达到最先进性能，并在部分导联 zero-shot classification 中比现有方法平均提高 16% AUC。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17900v1",
      "published_date": "2025-02-25 06:53:50 UTC",
      "updated_date": "2025-02-25 06:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:54:11.043698"
    },
    {
      "arxiv_id": "2502.17898v1",
      "title": "VeriPlan: Integrating Formal Verification and LLMs into End-User Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Christine Lee",
        "David Porfirio",
        "Xinyu Jessica Wang",
        "Kevin Zhao",
        "Bilge Mutlu"
      ],
      "abstract": "Automated planning is traditionally the domain of experts, utilized in fields\nlike manufacturing and healthcare with the aid of expert planning tools. Recent\nadvancements in LLMs have made planning more accessible to everyday users due\nto their potential to assist users with complex planning tasks. However, LLMs\nface several application challenges within end-user planning, including\nconsistency, accuracy, and user trust issues. This paper introduces VeriPlan, a\nsystem that applies formal verification techniques, specifically model\nchecking, to enhance the reliability and flexibility of LLMs for end-user\nplanning. In addition to the LLM planner, VeriPlan includes three additional\ncore features -- a rule translator, flexibility sliders, and a model checker --\nthat engage users in the verification process. Through a user study (n=12), we\nevaluate VeriPlan, demonstrating improvements in the perceived quality,\nusability, and user satisfaction of LLMs. Our work shows the effective\nintegration of formal verification and user-control features with LLMs for\nend-user planning tasks.",
      "tldr_zh": "该论文提出VeriPlan系统，将形式验证（特别是Model Checking）和大型语言模型（LLMs）整合到端用户规划中，以解决LLMs在一致性、准确性和用户信任方面的挑战。VeriPlan包括LLM规划器、规则翻译器、灵活性滑块和模型检查器等核心组件，允许用户参与验证过程以提升规划的可靠性和灵活性。通过一项用户研究（n=12），结果显示VeriPlan显著提高了LLMs的感知质量、可用性和用户满意度。该工作展示了形式验证与用户控制特性的有效结合，为端用户规划任务提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.1; I.2.5; I.2.2; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "In CHI Conference on Human Factors in Computing Systems (CHI '25),\n  April 26-May 1, 2025, Yokohama, Japan. ACM, New York, NY, USA, 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.17898v1",
      "published_date": "2025-02-25 06:53:00 UTC",
      "updated_date": "2025-02-25 06:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:54:21.575241"
    },
    {
      "arxiv_id": "2503.00037v1",
      "title": "Zero-Shot Defense Against Toxic Images via Inherent Multimodal Alignment in LVLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zhao",
        "Zhe Li",
        "Yige Li",
        "Jun Sun"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have made significant strides in\nmultimodal comprehension, thanks to extensive pre-training and fine-tuning on\nlarge-scale visual datasets. However, despite their robust textual safety\nmechanisms, they remain vulnerable to harmful visual inputs. Existing\nsafeguards-typically relying on pre-filtering or fine-tuning-incur high costs\nand diminish overall utility. To address this critical vulnerability, we\nintroduce SafeCLIP, a lightweight method that leverages LVLMs inherent\nmultimodal alignment for zero-shot toxic image detection. By projecting CLIPs\ndiscarded CLS token into its text space and matching it with toxic descriptors,\nSafeCLIP detects harmful content without any architectural changes-adding\nminimal latency and enabling dynamic safety corrections during inference and\nfine-tuning.Experiments show that SafeCLIP achieves a 66.9% defense success\nrate with only 3.2% false positive rate and 7.2% overhead. In contrast,\nstate-of-the-art methods achieve 52.9% success but have a 10.7% false positive\nrate and 210% overhead. Our work demonstrates that leveraging inherent\nmultimodal alignment can yield efficient, low-cost LVLM safety. Code is\navailable at anonymous.4open.science/r/safeclip-2C01.",
      "tldr_zh": "该研究针对Large Vision-Language Models (LVLMs)对有害视觉输入的脆弱性，提出了一种零样本防御方法SafeCLIP，利用LVLMs的固有多模态对齐进行高效检测。该方法通过将CLIP的丢弃CLS标记投影到文本空间，并与有害描述进行匹配，实现无架构更改的动态安全修正，仅增加7.2%的开销。实验结果显示，SafeCLIP的防御成功率达到66.9%，假阳性率仅3.2%，相比最先进方法的52.9%成功率和10.7%假阳性率，展示了其高效、低成本的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00037v1",
      "published_date": "2025-02-25 06:51:16 UTC",
      "updated_date": "2025-02-25 06:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:54:34.626984"
    },
    {
      "arxiv_id": "2503.01864v1",
      "title": "Larger or Smaller Reward Margins to Select Preferences for Alignment?",
      "title_zh": "翻译失败",
      "authors": [
        "Kexin Huang",
        "Junkang Wu",
        "Ziqian Chen",
        "Xue Wang",
        "Jinyang Gao",
        "Bolin Ding",
        "Jiancan Wu",
        "Xiangnan He",
        "Xiang Wang"
      ],
      "abstract": "Preference learning is critical for aligning large language models (LLMs)\nwith human values, with the quality of preference datasets playing a crucial\nrole in this process. While existing metrics primarily assess data quality\nbased on either explicit or implicit reward margins, they often provide\ncontradictory evaluations for the same data. To address this issue, we\nintroduce the alignment potential metric, which quantifies the gap from the\nmodel's current implicit reward margin to the target explicit reward margin,\nthereby estimating the model's potential to align with the preference data.\nEmpirical results demonstrate that training on data selected by this metric\nconsistently enhances alignment performance, surpassing existing metrics across\ndifferent base models and optimization objectives. Furthermore, our method\nextends to self-play data generation frameworks, where the metric is used to\nidentify high-quality data within the self-generated content by LLMs. Under\nthis data generation scenario, our method surpasses current state-of-the-art\n(SOTA) results across various training settings and demonstrates continuous\nimprovements in alignment performance as dataset size and training iterations\nincrease.",
      "tldr_zh": "本研究探讨了使用奖励边际（reward margins）选择偏好数据以提升大型语言模型（LLMs）与人类价值观对齐的问题，指出现有指标基于显式或隐式奖励边际评估数据时常出现矛盾。论文引入了 alignment potential metric，该指标量化模型从当前隐式奖励边际到目标显式奖励边际的差距，从而评估模型的对齐潜力。实验结果显示，使用此指标选择数据进行训练，能在不同基础模型和优化目标下超越现有指标，提升对齐性能；此外，该方法扩展到自玩数据生成（self-play data generation）框架中，超越当前最先进（SOTA）结果，并随着数据集规模和训练迭代增加而持续改善对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01864v1",
      "published_date": "2025-02-25 06:43:24 UTC",
      "updated_date": "2025-02-25 06:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:54:45.631146"
    },
    {
      "arxiv_id": "2502.17893v1",
      "title": "Sample-efficient diffusion-based control of complex nonlinear systems",
      "title_zh": "样本高效的基于扩散的复杂非线性系统控制",
      "authors": [
        "Hongyi Chen",
        "Jingtao Ding",
        "Jianhai Shu",
        "Xinchun Yu",
        "Xiaojun Liang",
        "Yong Li",
        "Xiao-Ping Zhang"
      ],
      "abstract": "Complex nonlinear system control faces challenges in achieving\nsample-efficient, reliable performance. While diffusion-based methods have\ndemonstrated advantages over classical and reinforcement learning approaches in\nlong-term control performance, they are limited by sample efficiency. This\npaper presents SEDC (Sample-Efficient Diffusion-based Control), a novel\ndiffusion-based control framework addressing three core challenges:\nhigh-dimensional state-action spaces, nonlinear system dynamics, and the gap\nbetween non-optimal training data and near-optimal control solutions. Through\nthree innovations - Decoupled State Diffusion, Dual-Mode Decomposition, and\nGuided Self-finetuning - SEDC achieves 39.5\\%-49.4\\% better control accuracy\nthan baselines while using only 10\\% of the training samples, as validated\nacross three complex nonlinear dynamic systems. Our approach represents a\nsignificant advancement in sample-efficient control of complex nonlinear\nsystems. The implementation of the code can be found at\nhttps://anonymous.4open.science/r/DIFOCON-C019.",
      "tldr_zh": "该论文提出了SEDC（Sample-Efficient Diffusion-based Control），一种新型扩散模型框架，旨在提升复杂非线性系统控制的样本效率，同时解决高维状态-动作空间、非线性动态和训练数据与最优控制方案差距等问题。SEDC 通过三个创新技术——Decoupled State Diffusion、Dual-Mode Decomposition 和 Guided Self-finetuning——实现了高效的控制优化。在三个复杂非线性动态系统中，SEDC 仅使用10%的训练样本，就比基线模型提高了39.5%-49.4%的控制准确率，标志着样本高效控制领域的显著进展。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17893v1",
      "published_date": "2025-02-25 06:30:04 UTC",
      "updated_date": "2025-02-25 06:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:54:57.866968"
    },
    {
      "arxiv_id": "2503.05768v1",
      "title": "A Collection of Innovations in Medical AI for patient records in 2024",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyun Zhang",
        "Shi Li"
      ],
      "abstract": "The field of Artificial Intelligence in healthcare is evolving at an\nunprecedented pace, driven by rapid advancements in machine learning and the\nrecent breakthroughs in large language models. While these innovations hold\nimmense potential to transform clinical decision making, diagnostics, and\npatient care, the accelerating speed of AI development has outpaced traditional\nacademic publishing cycles. As a result, many scholarly contributions quickly\nbecome outdated, failing to capture the latest state of the art methodologies\nand their real world implications. This paper advocates for a new category of\nacademic publications an annualized citation framework that prioritizes the\nmost recent AI driven healthcare innovations. By systematically referencing the\nbreakthroughs of the year, such papers would ensure that research remains\ncurrent, fostering a more adaptive and informed discourse. This approach not\nonly enhances the relevance of AI research in healthcare but also provides a\nmore accurate reflection of the fields ongoing evolution.",
      "tldr_zh": "这篇论文讨论了AI（Artificial Intelligence）在医疗领域的快速演变，特别是机器学习（machine learning）和大型语言模型（large language models）的突破，导致传统学术出版周期无法跟上，导致研究迅速过时。论文提出一种新类别学术出版——年度化引用框架（annualized citation framework），通过系统引用当年的AI驱动医疗创新，确保研究保持最新并提升其相关性。这种方法不仅促进医疗AI研究的适应性和知情讨论，还为临床决策、诊断和患者护理提供更准确的实时反映。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05768v1",
      "published_date": "2025-02-25 06:24:24 UTC",
      "updated_date": "2025-02-25 06:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:55:09.121037"
    },
    {
      "arxiv_id": "2502.17887v1",
      "title": "Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Apostol",
        "Maria Nutu"
      ],
      "abstract": "In Romania, cardiovascular problems are the leading cause of death,\naccounting for nearly one-third of annual fatalities. The severity of this\nsituation calls for innovative diagnosis method for cardiovascular diseases.\nThis article aims to explore efficient, light-weight and rapid methods for\narrhythmia diagnosis, in resource-constrained healthcare settings. Due to the\nlack of Romanian public medical data, we trained our systems using\ninternational public datasets, having in mind that the ECG signals are the same\nregardless the patients' nationality. Within this purpose, we combined multiple\ndatasets, usually used in the field of arrhythmias classification: PTB-XL\nelectrocardiography dataset , PTB Diagnostic ECG Database, China 12-Lead ECG\nChallenge Database, Georgia 12-Lead ECG Challenge Database, and St. Petersburg\nINCART 12-lead Arrhythmia Database. For the input data, we employed ECG signal\nprocessing methods, specifically a variant of the Pan-Tompkins algorithm,\nuseful in arrhythmia classification because it provides a robust and efficient\nmethod for detecting QRS complexes in ECG signals. Additionally, we used\nmachine learning techniques, widely used for the task of classification,\nincluding convolutional neural networks (1D CNNs, 2D CNNs, ResNet) and Vision\nTransformers (ViTs). The systems were evaluated in terms of accuracy and F1\nscore. We annalysed our dataset from two perspectives. First, we fed the\nsystems with the ECG signals and the GRU-based 1D CNN model achieved the\nhighest accuracy of 93.4% among all the tested architectures. Secondly, we\ntransformed ECG signals into images and the CNN2D model achieved an accuracy of\n92.16%.",
      "tldr_zh": "该论文针对罗马尼亚心血管疾病作为主要死因的问题，提出了一种高效、轻量级的心律失常(arrhythmia)诊断方法，适用于资源受限的医疗环境。研究者结合了多个国际公共数据集（如PTB-XL、PTB Diagnostic ECG Database等），并使用ECG信号处理技术（如Pan-Tompkins算法变体）来检测QRS complexes，然后应用卷积神经网络(convolutional neural networks，包括1D CNNs、2D CNNs和ResNet)以及Vision Transformers(ViTs)进行分类。实验结果显示，GRU-based 1D CNN模型在直接处理ECG信号时达到93.4%的准确率，而将信号转化为图像后，CNN2D模型的准确率达92.16%，为快速诊断提供了可靠的基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.17887v1",
      "published_date": "2025-02-25 06:17:52 UTC",
      "updated_date": "2025-02-25 06:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:55:24.295126"
    },
    {
      "arxiv_id": "2502.17886v1",
      "title": "A graph neural network-based multispectral-view learning model for diabetic macular ischemia detection from color fundus photographs",
      "title_zh": "翻译失败",
      "authors": [
        "Qinghua He",
        "Hongyang Jiang",
        "Danqi Fang",
        "Dawei Yang",
        "Truong X. Nguyen",
        "Anran Ran",
        "Clement C. Tham",
        "Simon K. H. Szeto",
        "Sobha Sivaprasad",
        "Carol Y. Cheung"
      ],
      "abstract": "Diabetic macular ischemia (DMI), marked by the loss of retinal capillaries in\nthe macular area, contributes to vision impairment in patients with diabetes.\nAlthough color fundus photographs (CFPs), combined with artificial intelligence\n(AI), have been extensively applied in detecting various eye diseases,\nincluding diabetic retinopathy (DR), their applications in detecting DMI remain\nunexplored, partly due to skepticism among ophthalmologists regarding its\nfeasibility. In this study, we propose a graph neural network-based\nmultispectral view learning (GNN-MSVL) model designed to detect DMI from CFPs.\nThe model leverages higher spectral resolution to capture subtle changes in\nfundus reflectance caused by ischemic tissue, enhancing sensitivity to\nDMI-related features. The proposed approach begins with computational\nmultispectral imaging (CMI) to reconstruct 24-wavelength multispectral fundus\nimages from CFPs. ResNeXt101 is employed as the backbone for multi-view\nlearning to extract features from the reconstructed images. Additionally, a GNN\nwith a customized jumper connection strategy is designed to enhance\ncross-spectral relationships, facilitating comprehensive and efficient\nmultispectral view learning. The study included a total of 1,078\nmacula-centered CFPs from 1,078 eyes of 592 patients with diabetes, of which\n530 CFPs from 530 eyes of 300 patients were diagnosed with DMI. The model\nachieved an accuracy of 84.7 percent and an area under the receiver operating\ncharacteristic curve (AUROC) of 0.900 (95 percent CI: 0.852-0.937) on\neye-level, outperforming both the baseline model trained from CFPs and human\nexperts (p-values less than 0.01). These findings suggest that AI-based CFP\nanalysis holds promise for detecting DMI, contributing to its early and\nlow-cost screening.",
      "tldr_zh": "本研究提出了一种基于图神经网络 (GNN) 的多光谱视图学习 (GNN-MSVL) 模型，用于从彩色眼底照片 (CFPs) 检测糖尿病黄斑缺血 (DMI)，以解决现有 AI 在 DMI 诊断中的空白问题。该模型首先通过计算多光谱成像 (CMI) 重建 24 波长多光谱图像，然后使用 ResNeXt101 作为骨干网络提取特征，并设计带有自定义跳跃连接策略的 GNN 来增强跨光谱关系，从而捕捉缺血组织的细微变化。在包含 1078 张 CFPs 的数据集上，模型实现了 84.7% 的准确率和 0.900 的 AUROC，显著优于基线模型和人类专家（p < 0.01），为 DMI 的早期、低成本筛查提供了可靠的 AI 解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17886v1",
      "published_date": "2025-02-25 06:17:20 UTC",
      "updated_date": "2025-02-25 06:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:55:36.044277"
    },
    {
      "arxiv_id": "2502.17883v1",
      "title": "From underwater to aerial: a novel multi-scale knowledge distillation approach for coral reef monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Contini",
        "Victor Illien",
        "Julien Barde",
        "Sylvain Poulain",
        "Serge Bernard",
        "Alexis Joly",
        "Sylvain Bonhommeau"
      ],
      "abstract": "Drone-based remote sensing combined with AI-driven methodologies has shown\ngreat potential for accurate mapping and monitoring of coral reef ecosystems.\nThis study presents a novel multi-scale approach to coral reef monitoring,\nintegrating fine-scale underwater imagery with medium-scale aerial imagery.\nUnderwater images are captured using an Autonomous Surface Vehicle (ASV), while\naerial images are acquired with an aerial drone. A transformer-based\ndeep-learning model is trained on underwater images to detect the presence of\n31 classes covering various coral morphotypes, associated fauna, and habitats.\nThese predictions serve as annotations for training a second model applied to\naerial images. The transfer of information across scales is achieved through a\nweighted footprint method that accounts for partial overlaps between underwater\nimage footprints and aerial image tiles. The results show that the multi-scale\nmethodology successfully extends fine-scale classification to larger reef\nareas, achieving a high degree of accuracy in predicting coral morphotypes and\nassociated habitats. The method showed a strong alignment between\nunderwater-derived annotations and ground truth data, reflected by an AUC (Area\nUnder the Curve) score of 0.9251. This shows that the integration of underwater\nand aerial imagery, supported by deep-learning models, can facilitate scalable\nand accurate reef assessments. This study demonstrates the potential of\ncombining multi-scale imaging and AI to facilitate the monitoring and\nconservation of coral reefs. Our approach leverages the strengths of underwater\nand aerial imagery, ensuring the precision of fine-scale analysis while\nextending it to cover a broader reef area.",
      "tldr_zh": "这项研究提出了一种新型多尺度知识蒸馏方法，用于珊瑚礁监测，通过整合由 Autonomous Surface Vehicle (ASV) 捕获的水下图像和无人机获取的航拍图像。研究训练了一个基于 Transformer 的深度学习模型在水下图像上检测 31 个类别，包括各种珊瑚形态、相关动物和栖息地，并使用这些预测作为标注来训练第二个模型应用于航拍图像，同时采用加权足迹方法处理图像重叠。结果显示，该方法实现了高准确性（AUC 0.9251），成功地将细尺度分类扩展到更大礁石区域，并证明了结合多尺度成像和 AI 的潜力，有助于珊瑚礁的监测和保护。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17883v1",
      "published_date": "2025-02-25 06:12:33 UTC",
      "updated_date": "2025-02-25 06:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:55:50.227066"
    },
    {
      "arxiv_id": "2502.17882v1",
      "title": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers",
      "title_zh": "科学跨越语言：评估LLM多语言翻译科学",
      "authors": [
        "Hannah Calzi Kleidermacher",
        "James Zou"
      ],
      "abstract": "Scientific research is inherently global. However, the vast majority of\nacademic journals are published exclusively in English, creating barriers for\nnon-native-English-speaking researchers. In this study, we leverage large\nlanguage models (LLMs) to translate published scientific articles while\npreserving their native JATS XML formatting, thereby developing a practical,\nautomated approach for implementation by academic journals. Using our approach,\nwe translate articles across multiple scientific disciplines into 28 languages.\nTo evaluate translation accuracy, we introduce a novel question-and-answer (QA)\nbenchmarking method, in which an LLM generates comprehension-based questions\nfrom the original text and then answers them based on the translated text. Our\nbenchmark results show an average performance of 95.9%, showing that the key\nscientific details are accurately conveyed. In a user study, we translate the\nscientific papers of 15 researchers into their native languages, finding that\nthe authors consistently found the translations to accurately capture the\noriginal information in their articles. Interestingly, a third of the authors\nfound many technical terms \"overtranslated,\" expressing a preference to keep\nterminology more familiar in English untranslated. Finally, we demonstrate how\nin-context learning techniques can be used to align translations with\ndomain-specific preferences such as mitigating overtranslation, highlighting\nthe adaptability and utility of LLM-driven scientific translation. The code and\ntranslated articles are available at https://hankleid.github.io/ProjectMundo.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)翻译科学文章的问题，以打破英语主导的学术障碍，并保留原有的JATS XML格式。研究者开发了一种自动化方法，将多学科文章翻译成28种语言，并引入了一种基于问答(QA)基准测试的评估方式，结果显示翻译准确率平均达95.9%，成功传达关键科学细节。用户研究发现，15位研究者认为翻译准确捕捉原信息，但三分之一的作者指出技术术语被“过度翻译”，并建议通过in-context learning技巧进行调整，以适应领域特定偏好。总的来说，该工作展示了LLMs在科学翻译中的实用性和可扩展性，并提供了相关代码和资源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17882v1",
      "published_date": "2025-02-25 06:08:48 UTC",
      "updated_date": "2025-02-25 06:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:56:02.891124"
    },
    {
      "arxiv_id": "2502.17872v1",
      "title": "Contrastive Learning with Nasty Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Ziruo Zhao"
      ],
      "abstract": "Contrastive learning has emerged as a powerful paradigm for self-supervised\nrepresentation learning. This work analyzes the theoretical limits of\ncontrastive learning under nasty noise, where an adversary modifies or replaces\ntraining samples. Using PAC learning and VC-dimension analysis, lower and upper\nbounds on sample complexity in adversarial settings are established.\nAdditionally, data-dependent sample complexity bounds based on the l2-distance\nfunction are derived.",
      "tldr_zh": "这篇论文探讨了 Contrastive Learning 在恶意噪声（nasty noise）下的理论极限，其中对手可能修改或替换训练样本。作者使用 PAC learning 和 VC-dimension 分析，建立了对抗设置下的样本复杂度下界和上界，以评估自监督表示学习的鲁棒性。此外，基于 l2-distance 函数导出了数据相关的样本复杂度界限，为对比学习在噪声环境中的应用提供了重要理论指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17872v1",
      "published_date": "2025-02-25 05:55:15 UTC",
      "updated_date": "2025-02-25 05:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:56:11.206891"
    },
    {
      "arxiv_id": "2502.17863v1",
      "title": "ASurvey: Spatiotemporal Consistency in Video Generation",
      "title_zh": "ASurvey: 视频生成中的时空一致性",
      "authors": [
        "Zhiyu Yin",
        "Kehai Chen",
        "Xuefeng Bai",
        "Ruili Jiang",
        "Juntao Li",
        "Hongdong Li",
        "Jin Liu",
        "Yang Xiang",
        "Jun Yu",
        "Min Zhang"
      ],
      "abstract": "Video generation, by leveraging a dynamic visual generation method, pushes\nthe boundaries of Artificial Intelligence Generated Content (AIGC). Video\ngeneration presents unique challenges beyond static image generation, requiring\nboth high-quality individual frames and temporal coherence to maintain\nconsistency across the spatiotemporal sequence. Recent works have aimed at\naddressing the spatiotemporal consistency issue in video generation, while few\nliterature review has been organized from this perspective. This gap hinders a\ndeeper understanding of the underlying mechanisms for high-quality video\ngeneration. In this survey, we systematically review the recent advances in\nvideo generation, covering five key aspects: foundation models, information\nrepresentations, generation schemes, post-processing techniques, and evaluation\nmetrics. We particularly focus on their contributions to maintaining\nspatiotemporal consistency. Finally, we discuss the future directions and\nchallenges in this field, hoping to inspire further efforts to advance the\ndevelopment of video generation.",
      "tldr_zh": "这篇调查论文（ASurvey）聚焦于视频生成中的时空一致性（Spatiotemporal Consistency），强调了其在人工智能生成内容（AIGC）领域的独特挑战，如确保帧质量和时间序列连贯性。论文系统回顾了最近进展，从五个关键方面——foundation models、信息 representations、generation schemes、post-processing techniques 和 evaluation metrics——分析了它们对维护时空一致性的贡献。该研究填补了现有文献的空白，并讨论了未来方向和挑战，以推动高品质视频生成的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17863v1",
      "published_date": "2025-02-25 05:20:51 UTC",
      "updated_date": "2025-02-25 05:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:56:24.190825"
    },
    {
      "arxiv_id": "2502.18535v1",
      "title": "A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhizhi Peng",
        "Taotao Wang",
        "Chonghe Zhao",
        "Guofu Liao",
        "Zibin Lin",
        "Yifeng Liu",
        "Bin Cao",
        "Long Shi",
        "Qing Yang",
        "Shengli Zhang"
      ],
      "abstract": "As machine learning technologies advance rapidly across various domains,\nconcerns over data privacy and model security have grown significantly. These\nchallenges are particularly pronounced when models are trained and deployed on\ncloud platforms or third-party servers due to the computational resource\nlimitations of users' end devices. In response, zero-knowledge proof (ZKP)\ntechnology has emerged as a promising solution, enabling effective validation\nof model performance and authenticity in both training and inference processes\nwithout disclosing sensitive data. Thus, ZKP ensures the verifiability and\nsecurity of machine learning models, making it a valuable tool for\nprivacy-preserving AI. Although some research has explored the verifiable\nmachine learning solutions that exploit ZKP, a comprehensive survey and summary\nof these efforts remain absent. This survey paper aims to bridge this gap by\nreviewing and analyzing all the existing Zero-Knowledge Machine Learning (ZKML)\nresearch from June 2017 to December 2024. We begin by introducing the concept\nof ZKML and outlining its ZKP algorithmic setups under three key categories:\nverifiable training, verifiable inference, and verifiable testing. Next, we\nprovide a comprehensive categorization of existing ZKML research within these\ncategories and analyze the works in detail. Furthermore, we explore the\nimplementation challenges faced in this field and discuss the improvement works\nto address these obstacles. Additionally, we highlight several commercial\napplications of ZKML technology. Finally, we propose promising directions for\nfuture advancements in this domain.",
      "tldr_zh": "这篇调查论文回顾了从2017年6月到2024年12月的Zero-Knowledge Proof (ZKP) 技术在可验证机器学习(Verifiable Machine Learning)中的应用，旨在解决机器学习中数据隐私和模型安全问题，尤其是在云平台部署场景。论文首先介绍了Zero-Knowledge Machine Learning (ZKML)概念，并将ZKP算法分为可验证训练、可验证推理和可验证测试三大类别，对现有研究进行全面分类和详细分析。论文还探讨了实施挑战、改进策略、商业应用，并提出未来发展方向，如增强隐私保护AI的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18535v1",
      "published_date": "2025-02-25 05:04:27 UTC",
      "updated_date": "2025-02-25 05:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:56:35.348825"
    },
    {
      "arxiv_id": "2502.17840v1",
      "title": "A Combinatorial Identities Benchmark for Theorem Proving via Automated Theorem Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Beibei Xiong",
        "Hangyu Lv",
        "Haojia Shan",
        "Jianlin Wang",
        "Zhengfeng Yang",
        "Lihong Zhi"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced formal theorem\nproving, yet the scarcity of high-quality training data constrains their\ncapabilities in complex mathematical domains. Combinatorics, a cornerstone of\nmathematics, provides essential tools for analyzing discrete structures and\nsolving optimization problems. However, its inherent complexity makes it\nparticularly challenging for automated theorem proving (ATP) for combinatorial\nidentities. To address this, we manually construct LeanComb, combinatorial\nidentities benchmark in Lean, which is, to our knowledge, the first formalized\ntheorem proving benchmark built for combinatorial identities. We develop an\nAutomated Theorem Generator for Combinatorial Identities, ATG4CI, which\ncombines candidate tactics suggested by a self-improving large language model\nwith a Reinforcement Learning Tree Search approach for tactic prediction. By\nutilizing ATG4CI, we generate a LeanComb-Enhanced dataset comprising 260K\ncombinatorial identities theorems, each with a complete formal proof in Lean,\nand experimental evaluations demonstrate that models trained on this dataset\ncan generate more effective tactics, thereby improving success rates in\nautomated theorem proving for combinatorial identities.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在正式定理证明中的数据稀缺问题，构建了首个组合恒等式基准 LeanComb，这是一个在 Lean 环境中的手动构建数据集。作者开发了 Automated Theorem Generator for Combinatorial Identities（ATG4CI），该工具结合自提升 LLMs 建议的候选策略和 Reinforcement Learning Tree Search 方法来自动生成定理和证明。通过 ATG4CI，他们创建了 LeanComb-Enhanced 数据集，包含 26 万个组合恒等式定理，每个都附有完整的 Lean 证明。实验结果表明，在此数据集上训练的模型能生成更有效的策略，从而显著提升了组合恒等式自动定理证明（ATP）的成功率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17840v1",
      "published_date": "2025-02-25 04:41:49 UTC",
      "updated_date": "2025-02-25 04:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:56:50.037024"
    },
    {
      "arxiv_id": "2502.17839v2",
      "title": "Say Less, Mean More: Leveraging Pragmatics in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haris Riaz",
        "Ellen Riloff",
        "Mihai Surdeanu"
      ],
      "abstract": "We propose a simple, unsupervised method that injects pragmatic principles in\nretrieval-augmented generation (RAG) frameworks such as Dense Passage Retrieval\nto enhance the utility of retrieved contexts. Our approach first identifies\nwhich sentences in a pool of documents retrieved by RAG are most relevant to\nthe question at hand, cover all the topics addressed in the input question and\nno more, and then highlights these sentences within their context, before they\nare provided to the LLM, without truncating or altering the context in any\nother way. We show that this simple idea brings consistent improvements in\nexperiments on three question answering tasks (ARC-Challenge, PubHealth and\nPopQA) using five different LLMs. It notably enhances relative accuracy by up\nto 19.7% on PubHealth and 10% on ARC-Challenge compared to a conventional RAG\nsystem.",
      "tldr_zh": "该论文提出了一种简单、无监督的方法，将语用学原则注入到 Retrieval-Augmented Generation (RAG) 框架（如 Dense Passage Retrieval）中，以提高检索上下文的效用。该方法首先识别出与问题最相关的句子，确保这些句子完全覆盖输入问题的话题且不额外扩展，然后在不截断或修改上下文的情况下突出这些句子并提供给 LLM。实验结果显示，在 ARC-Challenge、PubHealth 和 PopQA 等问答任务上，使用五种不同 LLM 时，该方法使相对准确率在 PubHealth 上提升多达 19.7%，在 ARC-Challenge 上提升 10%，比传统 RAG 系统更有效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 2 figures, 8 tables. Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.17839v2",
      "published_date": "2025-02-25 04:38:38 UTC",
      "updated_date": "2025-02-27 12:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:57:00.219402"
    },
    {
      "arxiv_id": "2503.00036v1",
      "title": "A Novel Spatiotemporal Correlation Anomaly Detection Method Based on Time-Frequency-Domain Feature Fusion and a Dynamic Graph Neural Network in Wireless Sensor Network",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Ye",
        "Zhibang Jiang",
        "Xingsi Xue",
        "Xingwang Li",
        "Peng Wen",
        "Yong Wang"
      ],
      "abstract": "Attention-based transformers have played an important role in wireless sensor\nnetwork (WSN) timing anomaly detection due to their ability to capture\nlong-term dependencies. However, there are several issues that must be\naddressed, such as the fact that their ability to capture long-term\ndependencies is not completely reliable, their computational complexity levels\nare high, and the spatiotemporal features of WSN timing data are not\nsufficiently extracted for detecting the correlation anomalies of multinode WSN\ntiming data. To address these limitations, this paper proposes a WSN anomaly\ndetection method that integrates frequency-domain features with dynamic graph\nneural networks (GNN) under a designed self-encoder reconstruction framework.\nFirst, the discrete wavelet transform effectively decomposes trend and seasonal\ncomponents of time series to solve the poor long-term reliability of\ntransformers. Second, a frequency-domain attention mechanism is designed to\nmake full use of the difference between the amplitude distributions of normal\ndata and anomalous data in this domain. Finally, a multimodal fusion-based\ndynamic graph convolutional network (MFDGCN) is designed by combining an\nattention mechanism and a graph convolutional network (GCN) to adaptively\nextract spatial correlation features. A series of experiments conducted on\npublic datasets and their results demonstrate that the anomaly detection method\ndesigned in this paper exhibits superior precision and recall than the existing\nmethods do, with an F1 score of 93.5%, representing an improvement of 2.9% over\nthat of the existing models.",
      "tldr_zh": "本研究针对无线传感器网络 (WSN) 时间异常检测中，基于 Attention 的 Transformer 模型存在的长期依赖性不可靠、计算复杂度高以及时空特征提取不足等问题，提出了一种新型时空相关异常检测方法。该方法在自编码器重建框架下，融合时间-频域特征和动态图神经网络 (GNN)，首先利用离散小波变换 (Discrete Wavelet Transform) 分解时间序列的趋势和季节成分，并设计频域注意力机制来突出正常与异常数据的幅度分布差异。其次，引入基于多模态融合的动态图卷积网络 (MFDGCN)，结合注意力机制和图卷积网络 (GCN) 自适应提取空间相关特征。实验结果显示，该方法在公开数据集上实现 F1 分数 93.5%，比现有模型提升 2.9%，展现出更高的精确率和召回率。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00036v1",
      "published_date": "2025-02-25 04:34:18 UTC",
      "updated_date": "2025-02-25 04:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:57:13.819379"
    },
    {
      "arxiv_id": "2502.17832v2",
      "title": "MM-PoisonRAG: Disrupting Multimodal RAG with Local and Global Poisoning Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonjeong Ha",
        "Qiusi Zhan",
        "Jeonghwan Kim",
        "Dimitrios Bralios",
        "Saikrishna Sanniboina",
        "Nanyun Peng",
        "Kai-Wei Chang",
        "Daniel Kang",
        "Heng Ji"
      ],
      "abstract": "Multimodal large language models (MLLMs) equipped with Retrieval Augmented\nGeneration (RAG) leverage both their rich parametric knowledge and the dynamic,\nexternal knowledge to excel in tasks such as Question Answering. While RAG\nenhances MLLMs by grounding responses in query-relevant external knowledge,\nthis reliance poses a critical yet underexplored safety risk: knowledge\npoisoning attacks, where misinformation or irrelevant knowledge is\nintentionally injected into external knowledge bases to manipulate model\noutputs to be incorrect and even harmful. To expose such vulnerabilities in\nmultimodal RAG, we propose MM-PoisonRAG, a novel knowledge poisoning attack\nframework with two attack strategies: Localized Poisoning Attack (LPA), which\ninjects query-specific misinformation in both text and images for targeted\nmanipulation, and Globalized Poisoning Attack (GPA) to provide false guidance\nduring MLLM generation to elicit nonsensical responses across all queries. We\nevaluate our attacks across multiple tasks, models, and access settings,\ndemonstrating that LPA successfully manipulates the MLLM to generate\nattacker-controlled answers, with a success rate of up to 56% on MultiModalQA.\nMoreover, GPA completely disrupts model generation to 0% accuracy with just a\nsingle irrelevant knowledge injection. Our results highlight the urgent need\nfor robust defenses against knowledge poisoning to safeguard multimodal RAG\nframeworks.",
      "tldr_zh": "这篇论文提出了 MM-PoisonRAG 框架，用于揭示 Multimodal large language models (MLLMs) 与 Retrieval Augmented Generation (RAG) 系统面对知识中毒攻击的脆弱性。框架包括两种策略：Localized Poisoning Attack (LPA)，通过针对特定查询注入虚假文本和图像来操纵模型输出；以及 Globalized Poisoning Attack (GPA)，通过注入无关知识破坏整体生成过程。实验结果显示，LPA 在 MultiModalQA 任务上成功率高达 56%，而 GPA 可将模型准确率降至 0%，突显了需要开发鲁棒防御措施以保护多模态 RAG 框架的安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at https://github.com/HyeonjeongHa/MM-PoisonRAG",
      "pdf_url": "http://arxiv.org/pdf/2502.17832v2",
      "published_date": "2025-02-25 04:23:59 UTC",
      "updated_date": "2025-03-09 02:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:57:25.637831"
    },
    {
      "arxiv_id": "2502.18534v1",
      "title": "MAFE: Multi-Agent Fair Environments for Decision-Making Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary McBride Lazri",
        "Anirudh Nakra",
        "Ivan Brugere",
        "Danial Dervovic",
        "Antigoni Polychroniadou",
        "Furong Huang",
        "Dana Dachman-Soled",
        "Min Wu"
      ],
      "abstract": "Fairness constraints applied to machine learning (ML) models in static\ncontexts have been shown to potentially produce adverse outcomes among\ndemographic groups over time. To address this issue, emerging research focuses\non creating fair solutions that persist over time. While many approaches treat\nthis as a single-agent decision-making problem, real-world systems often\nconsist of multiple interacting entities that influence outcomes. Explicitly\nmodeling these entities as agents enables more flexible analysis of their\ninterventions and the effects they have on a system's underlying dynamics. A\nsignificant challenge in conducting research on multi-agent systems is the lack\nof realistic environments that leverage the limited real-world data available\nfor analysis. To address this gap, we introduce the concept of a Multi-Agent\nFair Environment (MAFE) and present and analyze three MAFEs that model distinct\nsocial systems. Experimental results demonstrate the utility of our MAFEs as\ntestbeds for developing multi-agent fair algorithms.",
      "tldr_zh": "该研究指出，应用于机器学习 (ML) 模型的静态公平性约束可能在时间上导致人口群体不利结果，而现有方法多视其为单代理决策问题，忽略了现实系统中多个互动实体的影响。论文引入 Multi-Agent Fair Environment (MAFE) 的概念，并构建并分析了三个模型不同社会系统的 MAFE，以解决多代理系统研究中缺乏现实环境的挑战。实验结果证明，这些 MAFE 可作为开发多代理公平算法的测试平台，促进更持久的公平决策系统。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18534v1",
      "published_date": "2025-02-25 04:03:50 UTC",
      "updated_date": "2025-02-25 04:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:57:36.130497"
    },
    {
      "arxiv_id": "2502.17821v1",
      "title": "CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems",
      "title_zh": "CAML：面向多智能体系统的协作辅助模态学习",
      "authors": [
        "Rui Liu",
        "Yu Shen",
        "Peng Gao",
        "Pratap Tokekar",
        "Ming Lin"
      ],
      "abstract": "Multi-modality learning has become a crucial technique for improving the\nperformance of machine learning applications across domains such as autonomous\ndriving, robotics, and perception systems. While existing frameworks such as\nAuxiliary Modality Learning (AML) effectively utilize multiple data sources\nduring training and enable inference with reduced modalities, they primarily\noperate in a single-agent context. This limitation is particularly critical in\ndynamic environments, such as connected autonomous vehicles (CAV), where\nincomplete data coverage can lead to decision-making blind spots. To address\nthese challenges, we propose Collaborative Auxiliary Modality Learning\n($\\textbf{CAML}$), a novel multi-agent multi-modality framework that enables\nagents to collaborate and share multimodal data during training while allowing\ninference with reduced modalities per agent during testing. We systematically\nanalyze the effectiveness of $\\textbf{CAML}$ from the perspective of\nuncertainty reduction and data coverage, providing theoretical insights into\nits advantages over AML. Experimental results in collaborative decision-making\nfor CAV in accident-prone scenarios demonstrate that \\ours~achieves up to a\n${\\bf 58.13}\\%$ improvement in accident detection. Additionally, we validate\n$\\textbf{CAML}$ on real-world aerial-ground robot data for collaborative\nsemantic segmentation, achieving up to a ${\\bf 10.61}\\%$ improvement in mIoU.",
      "tldr_zh": "该研究提出了一种协作辅助模态学习框架（CAML），针对多代理系统中的多模态学习问题，允许代理在训练时协作共享多模态数据，而在测试时每个代理仅使用减少的模态，从而解决单代理框架如 Auxiliary Modality Learning (AML) 在动态环境中的局限性。CAML 通过减少不确定性和提升数据覆盖来提升性能，并提供了理论分析支持其优势。实验结果显示，在连接自主车辆 (CAV) 的协作决策场景中，CAML 在事故检测上比基线方法提高了 58.13%，而在真实世界空中-地面机器人协作语义分割任务上，mIoU 提升了 10.61%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17821v1",
      "published_date": "2025-02-25 03:59:40 UTC",
      "updated_date": "2025-02-25 03:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:57:48.262106"
    },
    {
      "arxiv_id": "2503.00035v1",
      "title": "Constraining Sequential Model Editing with Editing Anchor Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Xiang Xu",
        "Jun-Yu Ma",
        "Zhen-Hua Ling",
        "Ningyu Zhang",
        "Jia-Chen Gu"
      ],
      "abstract": "Large language models (LLMs) struggle with hallucinations due to false or\noutdated knowledge. Given the high resource demands of retraining these models,\nthere is an increasing focus on developing model editing. However, the general\nabilities of LLMs across downstream tasks are prone to significant degradation\nduring sequential editing. This paper statistically observes that the parameter\nmatrix after editing exhibits a significant deviation compared to its previous\nstate as the number of edits increases. This serious deviation affects the\noriginal knowledge associations within LLMs and leads to the degradation of\ntheir general abilities. To this end, a framework termed Editing Anchor\nCompression (EAC) is proposed to constrain the deviation of the parameter\nmatrix during sequential editing. It compresses the editing information by\nselecting editing anchors that are important in encoding new relations without\ndeviating too much from the original matrix, thereby preserving the general\nabilities. Experiments of applying EAC to two popular editing methods on three\nLLMs across four tasks are conducted. Evaluation results show that EAC\neffectively minimizes unreasonable deviations caused by model editing,\npreserving over 70% of the general abilities while better retaining the editing\nknowledge compared to the original counterpart methods.",
      "tldr_zh": "大型语言模型（LLMs）在顺序编辑过程中，由于参数矩阵偏差增大，往往导致下游任务的整体能力显著下降。论文提出 Editing Anchor Compression (EAC) 框架，通过选择关键编辑锚点来压缩编辑信息，约束参数矩阵的偏差，从而保留模型的一般能力。实验在三个 LLMs 上应用 EAC 到两种流行编辑方法，结果显示它能保留超过 70% 的一般能力，同时更好地保留编辑知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00035v1",
      "published_date": "2025-02-25 03:56:49 UTC",
      "updated_date": "2025-02-25 03:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:58:00.436128"
    },
    {
      "arxiv_id": "2503.00034v1",
      "title": "MergeIT: From Selection to Merging for Efficient Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Cai",
        "Yuqian Fu",
        "Hongming Fu",
        "Bo Zhao"
      ],
      "abstract": "Instruction tuning is crucial for optimizing Large Language Models (LLMs),\nyet mainstream data selection methods heavily rely on LLMs as instruction\nquality scorers, leading to high computational costs and reduced data\ndiversity. To address these limitations, we propose MergeIT, a novel LLM-based\nMerging strategy for better Instruction Tuning that shifts the focus from\nselection to synthesis. MergeIT operates in two stages: first, topic-aware\nfiltering clusters and refines the dataset, preserving diversity while\neliminating redundancy without relying on LLM-based scoring. Second, LLM-based\nmerging synthesizes semantically similar instructions into more informative and\ncompact training data, enhancing data richness while further reducing dataset\nsize. Experimental results demonstrate that MergeIT enables efficient, diverse,\nand scalable instruction selection and synthesis, establishing LLM-based\nmerging as a promising alternative to conventional scoring-based selection\nmethods for instruction tuning. Our source code and datasets are now available\nat https://github.com/XcloudFance/MergeIT",
      "tldr_zh": "该研究提出 MergeIT，一种创新的策略，用于优化 Large Language Models (LLMs) 的 Instruction Tuning，通过从数据选择转向合成来降低计算成本并提升数据多样性。MergeIT 包括两个阶段：首先进行主题感知过滤，对数据集进行聚类和精炼，以去除冗余并保留多样性，而不依赖 LLM-based 评分；其次，通过 LLM-based merging 将语义相似的指令合成更具信息性和紧凑的训练数据，从而提高数据丰富性并减少数据集规模。实验结果表明，MergeIT 实现了高效、多样和可扩展的指令调整方法，比传统基于评分的策略更具优势，并提供了开源代码和数据集以供进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00034v1",
      "published_date": "2025-02-25 03:43:20 UTC",
      "updated_date": "2025-02-25 03:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:58:13.031799"
    },
    {
      "arxiv_id": "2502.17814v1",
      "title": "An Overview of Large Language Models for Statisticians",
      "title_zh": "大型语言模型的概述：针对统计学家",
      "authors": [
        "Wenlong Ji",
        "Weizhe Yuan",
        "Emily Getzen",
        "Kyunghyun Cho",
        "Michael I. Jordan",
        "Song Mei",
        "Jason E Weston",
        "Weijie J. Su",
        "Jing Xu",
        "Linjun Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as transformative tools in\nartificial intelligence (AI), exhibiting remarkable capabilities across diverse\ntasks such as text generation, reasoning, and decision-making. While their\nsuccess has primarily been driven by advances in computational power and deep\nlearning architectures, emerging problems -- in areas such as uncertainty\nquantification, decision-making, causal inference, and distribution shift --\nrequire a deeper engagement with the field of statistics. This paper explores\npotential areas where statisticians can make important contributions to the\ndevelopment of LLMs, particularly those that aim to engender trustworthiness\nand transparency for human users. Thus, we focus on issues such as uncertainty\nquantification, interpretability, fairness, privacy, watermarking and model\nadaptation. We also consider possible roles for LLMs in statistical analysis.\nBy bridging AI and statistics, we aim to foster a deeper collaboration that\nadvances both the theoretical foundations and practical applications of LLMs,\nultimately shaping their role in addressing complex societal challenges.",
      "tldr_zh": "这篇论文概述了大型语言模型 (LLMs) 在统计学领域的应用，强调统计学家如何通过解决不确定性量化、决策、因果推理和分布偏移等问题来提升 LLMs 的可信性和透明度。论文重点讨论了统计学家在解释性、公平性、隐私、水印和模型适应的贡献，以促进 LLMs 的可靠发展。同时，它探讨了 LLMs 在统计分析中的潜在角色，旨在桥接 AI 和统计学，促进理论基础与实际应用的融合，共同应对社会挑战。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17814v1",
      "published_date": "2025-02-25 03:40:36 UTC",
      "updated_date": "2025-02-25 03:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:58:23.870973"
    },
    {
      "arxiv_id": "2502.17807v1",
      "title": "DocPuzzle: A Process-Aware Benchmark for Evaluating Realistic Long-Context Reasoning Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhuang",
        "Chuqiao Kuang",
        "Xiaoguang Li",
        "Yihua Teng",
        "Jihao Wu",
        "Yasheng Wang",
        "Lifeng Shang"
      ],
      "abstract": "We present DocPuzzle, a rigorously constructed benchmark for evaluating\nlong-context reasoning capabilities in large language models (LLMs). This\nbenchmark comprises 100 expert-level QA problems requiring multi-step reasoning\nover long real-world documents. To ensure the task quality and complexity, we\nimplement a human-AI collaborative annotation-validation pipeline. DocPuzzle\nintroduces an innovative evaluation framework that mitigates guessing bias\nthrough checklist-guided process analysis, establishing new standards for\nassessing reasoning capacities in LLMs. Our evaluation results show that:\n1)Advanced slow-thinking reasoning models like o1-preview(69.7%) and\nDeepSeek-R1(66.3%) significantly outperform best general instruct models like\nClaude 3.5 Sonnet(57.7%); 2)Distilled reasoning models like\nDeepSeek-R1-Distill-Qwen-32B(41.3%) falls far behind the teacher model,\nsuggesting challenges to maintain the generalization of reasoning capabilities\nrelying solely on distillation.",
      "tldr_zh": "该研究提出DocPuzzle，一个针对大型语言模型(LLMs)的长上下文推理能力进行评估的过程感知基准。该基准包含100个专家级QA问题，需要在真实世界长文档上进行多步推理，并通过人类-AI协作的注释-验证管道确保任务质量和复杂性。DocPuzzle引入创新评估框架，利用检查列表引导的过程分析来减少猜测偏差。实验结果显示，高级慢速推理模型如o1-preview(69.7%)和DeepSeek-R1(66.3%)显著优于通用指令模型如Claude 3.5 Sonnet(57.7%)，而蒸馏模型如DeepSeek-R1-Distill-Qwen-32B(41.3%)远低于教师模型，突显了维持推理泛化能力的挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17807v1",
      "published_date": "2025-02-25 03:29:53 UTC",
      "updated_date": "2025-02-25 03:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:58:36.698920"
    },
    {
      "arxiv_id": "2502.18532v1",
      "title": "CuDIP: Enhancing Theorem Proving in LLMs via Curriculum Learning-based Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shuming Shi",
        "Ruobing Zuo",
        "Gaolei He",
        "Jianlin Wang",
        "Chenyang Xu",
        "Zhengfeng Yang"
      ],
      "abstract": "Automated theorem proving (ATP) is one of the most challenging mathematical\nreasoning tasks for Large Language Models (LLMs). Most existing LLM-based ATP\nmethods rely on supervised fine-tuning, which results in a limited alignment\nbetween the theorem proving process and human preferences. Direct Preference\nOptimization (DPO), which aligns LLMs with human preferences, has shown\npositive effects for certain tasks. However, the lack of high-quality\npreference data for theorem proving presents a significant challenge. In this\npaper, we innovatively apply DPO to formal automated theorem proving and\nintroduces a Curriculum Learning-based DPO Iterative Theorem Proving (CuDIP)\nmethod. Specifically, we propose a method for constructing preference data\nwhich utilizes LLMs and existing theorem proving data to enhance the diversity\nof the preference data while reducing the reliance on human preference\nannotations. We then integrate this preference data construction method with\ncurriculum learning to iteratively fine-tune the theorem proving model through\nDPO. Experimental results on the MiniF2F and ProofNet datasets demonstrate the\neffectiveness of the proposed method.",
      "tldr_zh": "本文提出 CuDIP 方法，通过 Curriculum Learning 结合 Direct Preference Optimization (DPO) 来提升 Large Language Models (LLMs) 在 Automated Theorem Proving (ATP) 任务中的性能，以更好地对齐人类偏好。作者创新性地设计了一种偏好数据构建方法，利用 LLMs 和现有定理证明数据增强数据多样性，同时减少对人类注解的依赖，并通过迭代微调实现模型优化。在 MiniF2F 和 ProofNet 数据集上的实验结果证明，该方法显著提高了 ATP 的准确性和有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18532v1",
      "published_date": "2025-02-25 03:07:02 UTC",
      "updated_date": "2025-02-25 03:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:58:49.092742"
    },
    {
      "arxiv_id": "2502.17801v2",
      "title": "Research on Enhancing Cloud Computing Network Security using Artificial Intelligence Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Wang",
        "Xiao Yang"
      ],
      "abstract": "Cloud computing environments are increasingly vulnerable to security threats\nsuch as distributed denial-of-service (DDoS) attacks and SQL injection.\nTraditional security mechanisms, based on rule matching and feature\nrecognition, struggle to adapt to evolving attack strategies. This paper\nproposes an adaptive security protection framework leveraging deep learning to\nconstruct a multi-layered defense architecture. The proposed system is\nevaluated in a real-world business environment, achieving a detection accuracy\nof 97.3%, an average response time of 18 ms, and an availability rate of\n99.999%. Experimental results demonstrate that the proposed method\nsignificantly enhances detection accuracy, response efficiency, and resource\nutilization, offering a novel and effective approach to cloud computing\nsecurity.",
      "tldr_zh": "本文研究了如何利用人工智能算法提升云计算网络安全，针对DDoS攻击和SQL注入等威胁，传统基于规则匹配和特征识别的安全机制难以适应演变的攻击策略。论文提出一个自适应安全保护框架，使用深度学习构建多层防御架构，以提高检测和响应能力。在真实业务环境中测试，该框架实现了97.3%的检测准确率、18 ms的平均响应时间和99.999%的可用率，显著提升了检测准确率、响应效率和资源利用率，提供了一种新颖有效的云安全解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17801v2",
      "published_date": "2025-02-25 03:06:40 UTC",
      "updated_date": "2025-04-10 16:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:59:01.247715"
    },
    {
      "arxiv_id": "2502.17793v2",
      "title": "SYNTHIA: Novel Concept Design with Affordance Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonjeong Ha",
        "Xiaomeng Jin",
        "Jeonghwan Kim",
        "Jiateng Liu",
        "Zhenhailong Wang",
        "Khanh Duy Nguyen",
        "Ansel Blume",
        "Nanyun Peng",
        "Kai-Wei Chang",
        "Heng Ji"
      ],
      "abstract": "Text-to-image (T2I) models enable rapid concept design, making them widely\nused in AI-driven design. While recent studies focus on generating semantic and\nstylistic variations of given design concepts, functional coherence--the\nintegration of multiple affordances into a single coherent concept--remains\nlargely overlooked. In this paper, we introduce SYNTHIA, a framework for\ngenerating novel, functionally coherent designs based on desired affordances.\nOur approach leverages a hierarchical concept ontology that decomposes concepts\ninto parts and affordances, serving as a crucial building block for\nfunctionally coherent design. We also develop a curriculum learning scheme\nbased on our ontology that contrastively fine-tunes T2I models to progressively\nlearn affordance composition while maintaining visual novelty. To elaborate, we\n(i) gradually increase affordance distance, guiding models from basic\nconcept-affordance association to complex affordance compositions that\nintegrate parts of distinct affordances into a single, coherent form, and (ii)\nenforce visual novelty by employing contrastive objectives to push learned\nrepresentations away from existing concepts. Experimental results show that\nSYNTHIA outperforms state-of-the-art T2I models, demonstrating absolute gains\nof 25.1% and 14.7% for novelty and functional coherence in human evaluation,\nrespectively.",
      "tldr_zh": "本文提出 SYNTHIA 框架，用于基于期望的 affordances 生成新颖且功能连贯的设计概念，解决现有 T2I models 在功能一致性方面的不足。框架利用分层的 concept ontology 将概念分解成 parts 和 affordances，并通过 curriculum learning scheme 对比微调 T2I models：逐步增加 affordance distance 以学习从基本关联到复杂 affordance composition，同时采用 contrastive objectives 确保视觉新颖性。实验结果显示，SYNTHIA 在人类评估中比最先进模型在新颖性上提升 25.1%，在功能连贯性上提升 14.7%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available https://github.com/HyeonjeongHa/SYNTHIA",
      "pdf_url": "http://arxiv.org/pdf/2502.17793v2",
      "published_date": "2025-02-25 02:54:11 UTC",
      "updated_date": "2025-04-10 18:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:59:13.789825"
    },
    {
      "arxiv_id": "2502.17787v2",
      "title": "AIR: Complex Instruction Generation via Automatic Iterative Refinement",
      "title_zh": "AIR：通过自动迭代精炼的复杂指令生成",
      "authors": [
        "Wei Liu",
        "Yancheng He",
        "Hui Huang",
        "Chengwei Hu",
        "Jiaheng Liu",
        "Shilong Li",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "With the development of large language models, their ability to follow simple\ninstructions has significantly improved. However, adhering to complex\ninstructions remains a major challenge. Current approaches to generating\ncomplex instructions are often irrelevant to the current instruction\nrequirements or suffer from limited scalability and diversity. Moreover,\nmethods such as back-translation, while effective for simple instruction\ngeneration, fail to leverage the rich contents and structures in large web\ncorpora. In this paper, we propose a novel automatic iterative refinement\nframework to generate complex instructions with constraints, which not only\nbetter reflects the requirements of real scenarios but also significantly\nenhances LLMs' ability to follow complex instructions. The AIR framework\nconsists of two stages: (1)Generate an initial instruction from a document;\n(2)Iteratively refine instructions with LLM-as-judge guidance by comparing the\nmodel's output with the document to incorporate valuable constraints. Finally,\nwe construct the AIR-10K dataset with 10K complex instructions and demonstrate\nthat instructions generated with our approach significantly improve the model's\nability to follow complex instructions, outperforming existing methods for\ninstruction generation.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在遵循复杂指令方面的挑战，提出了一种新型框架 AIR（Automatic Iterative Refinement），通过自动迭代改进来生成带有约束的复杂指令。AIR 框架分为两个阶段：首先从文档中生成初始指令，其次利用 LLM-as-judge 机制，通过比较模型输出与文档来迭代精炼指令，从而增强指令的多样性和相关性。研究构建了 AIR-10K 数据集，包含 10K 条复杂指令，并证明该方法显著提升了 LLMs 的指令遵循能力，在性能上优于现有生成方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first three authors contributed equally, 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.17787v2",
      "published_date": "2025-02-25 02:39:57 UTC",
      "updated_date": "2025-02-27 16:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:59:24.287798"
    },
    {
      "arxiv_id": "2502.17773v2",
      "title": "Uncertainty Quantification for LLM-Based Survey Simulations",
      "title_zh": "基于 LLM 的调查模拟的不确定性量化",
      "authors": [
        "Chengpiao Huang",
        "Yuhang Wu",
        "Kaizheng Wang"
      ],
      "abstract": "We investigate the use of large language models (LLMs) to simulate human\nresponses to survey questions, and perform uncertainty quantification to gain\nreliable insights. Our approach converts imperfect LLM-simulated responses into\nconfidence sets for population parameters of human responses, addressing the\ndistribution shift between the simulated and real populations. A key innovation\nlies in determining the optimal number of simulated responses: too many produce\noverly narrow confidence sets with poor coverage, while too few yield\nexcessively loose estimates. To resolve this, our method adaptively selects the\nsimulation sample size, ensuring valid average-case coverage guarantees. It is\nbroadly applicable to any LLM, irrespective of its fidelity, and any procedure\nfor constructing confidence sets. Additionally, the selected sample size\nquantifies the degree of misalignment between the LLM and the target human\npopulation. We illustrate our method on real datasets and LLMs.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 模拟人类对调查问题的响应，并通过不确定性量化 (Uncertainty Quantification) 生成可靠的人口参数置信集 (confidence sets)，以解决模拟响应与真实人群分布偏移的问题。关键创新在于自适应选择模拟样本大小，避免样本过多导致置信集过于狭窄或覆盖率不足，以及样本过少导致估计宽松，从而确保有效的平均覆盖保证。该方法适用于任何 LLM 和置信集构建过程，同时能量化 LLM 与目标人类人群的错位程度，并在真实数据集上进行了验证。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "33 pages, 7 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.17773v2",
      "published_date": "2025-02-25 02:07:29 UTC",
      "updated_date": "2025-05-16 15:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:59:36.893711"
    },
    {
      "arxiv_id": "2502.18531v1",
      "title": "Enhancing Hepatopathy Clinical Trial Efficiency: A Secure, Large Language Model-Powered Pre-Screening Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongbin Gui",
        "Hanlin Lv",
        "Xiao Wang",
        "Longting Lv",
        "Yi Xiao",
        "Lei Wang"
      ],
      "abstract": "Background: Recruitment for cohorts involving complex liver diseases, such as\nhepatocellular carcinoma and liver cirrhosis, often requires interpreting\nsemantically complex criteria. Traditional manual screening methods are\ntime-consuming and prone to errors. While AI-powered pre-screening offers\npotential solutions, challenges remain regarding accuracy, efficiency, and data\nprivacy. Methods: We developed a novel patient pre-screening pipeline that\nleverages clinical expertise to guide the precise, safe, and efficient\napplication of large language models. The pipeline breaks down complex criteria\ninto a series of composite questions and then employs two strategies to perform\nsemantic question-answering through electronic health records - (1) Pathway A,\nAnthropomorphized Experts' Chain of Thought strategy, and (2) Pathway B, Preset\nStances within an Agent Collaboration strategy, particularly in managing\ncomplex clinical reasoning scenarios. The pipeline is evaluated on three key\nmetrics-precision, time consumption, and counterfactual inference - at both the\nquestion and criterion levels. Results: Our pipeline achieved high precision\n(0.921, in criteria level) and efficiency (0.44s per task). Pathway B excelled\nin complex reasoning, while Pathway A was effective in precise data extraction\nwith faster processing times. Both pathways achieved comparable precision. The\npipeline showed promising results in hepatocellular carcinoma (0.878) and\ncirrhosis trials (0.843). Conclusions: This data-secure and time-efficient\npipeline shows high precision in hepatopathy trials, providing promising\nsolutions for streamlining clinical trial workflows. Its efficiency and\nadaptability make it suitable for improving patient recruitment. And its\ncapability to function in resource-constrained environments further enhances\nits utility in clinical settings.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models 的安全预筛选管道，旨在提升肝病临床试验的效率，解决传统手动筛选的准确性和隐私问题。管道将复杂标准分解为复合问题，并采用两种策略：Pathway A (Anthropomorphized Experts' Chain of Thought strategy) 用于精确数据提取，以及 Pathway B (Preset Stances within an Agent Collaboration strategy) 用于处理复杂临床推理。实验结果显示，该管道在标准级别达到高精确性（0.921）和高效处理（每任务 0.44 秒），在肝癌（0.878）和肝硬化（0.843）试验中表现出色。总体而言，该方法为简化临床试验招募流程提供了可扩展的解决方案，尤其适合资源受限环境。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18531v1",
      "published_date": "2025-02-25 02:06:39 UTC",
      "updated_date": "2025-02-25 02:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T18:59:51.059045"
    },
    {
      "arxiv_id": "2502.17771v1",
      "title": "Sample Selection via Contrastive Fragmentation for Noisy Label Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Dongjoo Kim",
        "Sangwoo Moon",
        "Jihwan Moon",
        "Dongyeon Woo",
        "Gunhee Kim"
      ],
      "abstract": "As with many other problems, real-world regression is plagued by the presence\nof noisy labels, an inevitable issue that demands our attention. Fortunately,\nmuch real-world data often exhibits an intrinsic property of continuously\nordered correlations between labels and features, where data points with\nsimilar labels are also represented with closely related features. In response,\nwe propose a novel approach named ConFrag, where we collectively model the\nregression data by transforming them into disjoint yet contrasting\nfragmentation pairs. This enables the training of more distinctive\nrepresentations, enhancing the ability to select clean samples. Our ConFrag\nframework leverages a mixture of neighboring fragments to discern noisy labels\nthrough neighborhood agreement among expert feature extractors. We extensively\nperform experiments on six newly curated benchmark datasets of diverse domains,\nincluding age prediction, price prediction, and music production year\nestimation. We also introduce a metric called Error Residual Ratio (ERR) to\nbetter account for varying degrees of label noise. Our approach consistently\noutperforms fourteen state-of-the-art baselines, being robust against symmetric\nand random Gaussian label noise.",
      "tldr_zh": "这篇论文针对回归任务中的噪声标签（noisy labels）问题，提出了一种名为 ConFrag 的新方法，通过对比碎片（Contrastive Fragmentation）将数据转化为不相交的对比对，以训练更独特的表示并选择干净样本。ConFrag 框架利用混合邻近碎片和专家特征提取器的邻域一致性来识别噪声标签，从而提升模型鲁棒性。作者在六个新基准数据集上进行实验，包括年龄预测、价格预测和音乐制作年份估计，并引入 Error Residual Ratio (ERR) 指标来量化标签噪声程度。该方法在对称和随机高斯标签噪声下，优于 14 个最先进基线，展现出显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.17771v1",
      "published_date": "2025-02-25 02:04:14 UTC",
      "updated_date": "2025-02-25 02:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:00:01.772058"
    },
    {
      "arxiv_id": "2502.17764v2",
      "title": "DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Qile Jiang",
        "Zhiwei Gao",
        "George Em Karniadakis"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for tackling a\nwide range of problems, including those in scientific computing, particularly\nin solving partial differential equations (PDEs). However, different models\nexhibit distinct strengths and preferences, resulting in varying levels of\nperformance. In this paper, we compare the capabilities of the most advanced\nLLMs--DeepSeek, ChatGPT, and Claude--along with their reasoning-optimized\nversions in addressing computational challenges. Specifically, we evaluate\ntheir proficiency in solving traditional numerical problems in scientific\ncomputing as well as leveraging scientific machine learning techniques for\nPDE-based problems. We designed all our experiments so that a non-trivial\ndecision is required, e.g. defining the proper space of input functions for\nneural operator learning. Our findings show that reasoning and hybrid-reasoning\nmodels consistently and significantly outperform non-reasoning ones in solving\nchallenging problems, with ChatGPT o3-mini-high generally offering the fastest\nreasoning speed.",
      "tldr_zh": "这篇论文比较了 DeepSeek、ChatGPT 和 Claude 等大型语言模型（LLMs）及其推理优化版本，在科学计算和科学机器学习任务中的性能，特别是解决偏微分方程（PDEs）问题。研究通过设计需要非平凡决策的实验（如定义神经算子学习的适当输入函数空间），评估这些模型在传统数值问题和科学机器学习技术上的能力。结果显示，推理和混合推理模型在处理挑战性任务时显著优于非推理模型，且 ChatGPT o3-mini-high 提供了最快的推理速度，为选择适合科学计算的 LLMs 提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17764v2",
      "published_date": "2025-02-25 01:49:50 UTC",
      "updated_date": "2025-03-08 22:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:00:13.739937"
    },
    {
      "arxiv_id": "2502.17763v1",
      "title": "Design and implementation of a distributed security threat detection system integrating federated learning and multimodal LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Wang",
        "Xiao Yang"
      ],
      "abstract": "Traditional security protection methods struggle to address sophisticated\nattack vectors in large-scale distributed systems, particularly when balancing\ndetection accuracy with data privacy concerns. This paper presents a novel\ndistributed security threat detection system that integrates federated learning\nwith multimodal large language models (LLMs). Our system leverages federated\nlearning to ensure data privacy while employing multimodal LLMs to process\nheterogeneous data sources including network traffic, system logs, images, and\nsensor data. Experimental evaluation on a 10TB distributed dataset demonstrates\nthat our approach achieves 96.4% detection accuracy, outperforming traditional\nbaseline models by 4.1 percentage points. The system reduces both false\npositive and false negative rates by 1.8 and 2.4 percentage points\nrespectively. Performance analysis shows that our system maintains efficient\nprocessing capabilities in distributed environments, requiring 180 seconds for\nmodel training and 3.8 seconds for threat detection across the distributed\nnetwork. These results demonstrate significant improvements in detection\naccuracy and computational efficiency while preserving data privacy, suggesting\nstrong potential for real-world deployment in large-scale security systems.",
      "tldr_zh": "该论文提出了一种分布式安全威胁检测系统，整合了federated learning和multimodal LLMs，以解决传统方法在处理大规模分布式系统复杂攻击时的准确性和数据隐私平衡问题。该系统利用federated learning确保数据隐私，同时通过multimodal LLMs处理异构数据源，如网络流量、系统日志、图像和传感器数据。在10TB分布式数据集的实验中，该系统实现了96.4%的检测准确率，比传统基线模型高出4.1%，并分别降低了1.8和2.4百分点的假阳性和假阴性率。性能分析显示，该系统在分布式环境中训练耗时180秒、检测耗时3.8秒，显著提升了计算效率，并为实际大规模安全系统的部署提供了潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17763v1",
      "published_date": "2025-02-25 01:44:08 UTC",
      "updated_date": "2025-02-25 01:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:00:25.371150"
    },
    {
      "arxiv_id": "2502.17751v1",
      "title": "Graded Neural Networks",
      "title_zh": "分级神经网络",
      "authors": [
        "Tony Shaska"
      ],
      "abstract": "This paper presents a novel framework for graded neural networks (GNNs) built\nover graded vector spaces $\\V_\\w^n$, extending classical neural architectures\nby incorporating algebraic grading. Leveraging a coordinate-wise grading\nstructure with scalar action $\\lambda \\star \\x = (\\lambda^{q_i} x_i)$, defined\nby a tuple $\\w = (q_0, \\ldots, q_{n-1})$, we introduce graded neurons, layers,\nactivation functions, and loss functions that adapt to feature significance.\nTheoretical properties of graded spaces are established, followed by a\ncomprehensive GNN design, addressing computational challenges like numerical\nstability and gradient scaling. Potential applications span machine learning\nand photonic systems, exemplified by high-speed laser-based implementations.\nThis work offers a foundational step toward graded computation, unifying\nmathematical rigor with practical potential, with avenues for future empirical\nand hardware exploration.",
      "tldr_zh": "本论文提出了一种新型的graded neural networks (GNNs)框架，建立在graded vector spaces $\\V_\\w^n$之上，通过整合algebraic grading扩展了经典神经网络架构。框架引入了graded neurons、layers、activation functions和loss functions，这些组件基于coordinate-wise grading结构（如$\\lambda \\star \\x = (\\lambda^{q_i} x_i)$）来适应feature significance，并建立了graded spaces的理论属性，同时解决了计算挑战如numerical stability和gradient scaling。GNNs的潜在应用涵盖machine learning和photonic systems，例如高速laser-based implementations，这为graded computation提供了基础，并为未来的empirical和hardware探索开辟了途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "16W50, 13A02,",
        "I.2; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17751v1",
      "published_date": "2025-02-25 01:08:07 UTC",
      "updated_date": "2025-02-25 01:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:00:38.312533"
    },
    {
      "arxiv_id": "2503.00032v2",
      "title": "Detecting LLM-Generated Korean Text through Linguistic Feature Analysis",
      "title_zh": "通过语言特征分析检测 LLM 生成的韩文文本",
      "authors": [
        "Shinwoo Park",
        "Shubin Kim",
        "Do-Kyung Kim",
        "Yo-Sub Han"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) increases the\ndifficulty of distinguishing between human-written and LLM-generated text.\nDetecting LLM-generated text is crucial for upholding academic integrity,\npreventing plagiarism, protecting copyrights, and ensuring ethical research\npractices. Most prior studies on detecting LLM-generated text focus primarily\non English text. However, languages with distinct morphological and syntactic\ncharacteristics require specialized detection approaches. Their unique\nstructures and usage patterns can hinder the direct application of methods\nprimarily designed for English. Among such languages, we focus on Korean, which\nhas relatively flexible spacing rules, a rich morphological system, and less\nfrequent comma usage compared to English. We introduce KatFish, the first\nbenchmark dataset for detecting LLM-generated Korean text. The dataset consists\nof text written by humans and generated by four LLMs across three genres.\n  By examining spacing patterns, part-of-speech diversity, and comma usage, we\nilluminate the linguistic differences between human-written and LLM-generated\nKorean text. Building on these observations, we propose KatFishNet, a detection\nmethod specifically designed for the Korean language. KatFishNet achieves an\naverage of 19.78% higher AUROC compared to the best-performing existing\ndetection method. Our code and data are available at\nhttps://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.",
      "tldr_zh": "本研究探讨了检测大型语言模型(LLM)生成的韩文文本问题，强调韩文独特形态和句法特征（如灵活空格规则、丰富形态系统和较少逗号使用）使得现有英文导向方法难以直接应用。作者构建了KatFish，这是首个韩文LLM生成文本基准数据集，包含人类写作和四种LLM生成的文本，涵盖三种类型。 通过分析空格模式、词性多样性和逗号使用等语言特征，他们提出了KatFishNet检测方法，该方法相较于现有最佳方法平均AUROC提高了19.78%。 代码和数据集已公开，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00032v2",
      "published_date": "2025-02-25 00:59:27 UTC",
      "updated_date": "2025-03-04 06:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:00:49.934179"
    },
    {
      "arxiv_id": "2502.17749v2",
      "title": "Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features",
      "title_zh": "使用编码风格特征检测 LLM 改写的代码并识别负责的 LLM",
      "authors": [
        "Shinwoo Park",
        "Hyundong Jin",
        "Jeong-won Cha",
        "Yo-Sub Han"
      ],
      "abstract": "Recent progress in large language models (LLMs) for code generation has\nraised serious concerns about intellectual property protection. Malicious users\ncan exploit LLMs to produce paraphrased versions of proprietary code that\nclosely resemble the original. While the potential for LLM-assisted code\nparaphrasing continues to grow, research on detecting it remains limited,\nunderscoring an urgent need for detection system. We respond to this need by\nproposing two tasks. The first task is to detect whether code generated by an\nLLM is a paraphrased version of original human-written code. The second task is\nto identify which LLM is used to paraphrase the original code. For these tasks,\nwe construct a dataset LPcode consisting of pairs of human-written code and\nLLM-paraphrased code using various LLMs.\n  We statistically confirm significant differences in the coding styles of\nhuman-written and LLM-paraphrased code, particularly in terms of naming\nconsistency, code structure, and readability. Based on these findings, we\ndevelop LPcodedec, a detection method that identifies paraphrase relationships\nbetween human-written and LLM-generated code, and discover which LLM is used\nfor the paraphrasing. LPcodedec outperforms the best baselines in two tasks,\nimproving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and\n213x, respectively. Our code and data are available at\nhttps://github.com/Shinwoo-Park/detecting_llm_paraphrased_code_via_coding_style_features.",
      "tldr_zh": "该论文针对大型语言模型(LLM)生成的代码改写问题，提出了两个关键任务：检测代码是否为LLM对原始人类代码的改写版本，以及识别负责改写的LLM。研究者构建了LPcode数据集，包括人类代码和各种LLM改写代码的配对，并通过统计分析发现两者在命名一致性、代码结构和可读性等方面存在显著差异。基于这些差异，他们开发了LPcodedec检测方法，该方法在两个任务上优于基线模型，提高F1分数2.64%和15.17%，并实现了1,343x和213x的加速。代码和数据已在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17749v2",
      "published_date": "2025-02-25 00:58:06 UTC",
      "updated_date": "2025-02-28 08:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:01:03.026991"
    },
    {
      "arxiv_id": "2502.18529v1",
      "title": "Heterogeneous Decision Making in Mixed Traffic: Uncertainty-aware Planning and Bounded Rationality",
      "title_zh": "混合交通中的异质决策：不确定性感知规划和有限",
      "authors": [
        "Hang Wang",
        "Qiaoyi Fang",
        "Junshan Zhang"
      ],
      "abstract": "The past few years have witnessed a rapid growth of the deployment of\nautomated vehicles (AVs). Clearly, AVs and human-driven vehicles (HVs) will\nco-exist for many years, and AVs will have to operate around HVs, pedestrians,\ncyclists, and more, calling for fundamental breakthroughs in AI designed for\nmixed traffic to achieve mixed autonomy. Thus motivated, we study heterogeneous\ndecision making by AVs and HVs in a mixed traffic environment, aiming to\ncapture the interactions between human and machine decision-making and develop\nan AI foundation that enables vehicles to operate safely and efficiently. There\nare a number of challenges to achieve mixed autonomy, including 1) humans\ndrivers make driving decisions with bounded rationality, and it remains open to\ndevelop accurate models for HVs' decision making; and 2) uncertainty-aware\nplanning plays a critical role for AVs to take safety maneuvers in response to\nthe human behavior. In this paper, we introduce a formulation of AV-HV\ninteraction, where the HV makes decisions with bounded rationality and the AV\nemploys uncertainty-aware planning based on the prediction on HV's future\nactions. We conduct a comprehensive analysis on AV and HV's learning regret to\nanswer the questions: 1) {How does the learning performance depend on HV's\nbounded rationality and AV's planning}; 2) {How do different decision making\nstrategies impact the overall learning performance}? Our findings reveal some\nintriguing phenomena, such as Goodhart's Law in AV's learning performance and\ncompounding effects in HV's decision making process. By examining the dynamics\nof the regrets, we gain insights into the interplay between human and machine\ndecision making.",
      "tldr_zh": "本研究探讨了自动驾驶车辆 (AVs) 和人类驾驶车辆 (HVs) 在混合交通环境中的异质决策问题，旨在通过不确定性感知规划 (uncertainty-aware planning) 和有限理性模型 (bounded rationality) 实现安全高效的混合自治。论文引入了 AV-HV 交互的公式化模型，其中 HV 的决策基于有限理性，而 AV 通过预测 HV 行为进行不确定性感知规划，并对学习遗憾 (learning regret) 进行全面分析。结果揭示了诸如 Goodhart's Law 在 AV 学习性能中的表现以及 HV 决策过程中的复合效应等有趣现象，为理解人类和机器决策互动提供了关键洞察。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "CPAL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18529v1",
      "published_date": "2025-02-25 00:32:33 UTC",
      "updated_date": "2025-02-25 00:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:01:14.970381"
    },
    {
      "arxiv_id": "2503.00031v1",
      "title": "Efficient Test-Time Scaling via Self-Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Chengsong Huang",
        "Langlin Huang",
        "Jixuan Leng",
        "Jiacheng Liu",
        "Jiaxin Huang"
      ],
      "abstract": "Increasing test-time computation is a straightforward approach to enhancing\nthe quality of responses in Large Language Models (LLMs). While Best-of-N\nsampling and Self-Consistency with majority voting are simple and effective,\nthey require a fixed number of sampling responses for each query, regardless of\nits complexity. This could result in wasted computation for simpler questions\nand insufficient exploration for more challenging ones. In this work, we argue\nthat model confidence of responses can be used for improving the efficiency of\ntest-time scaling. Unfortunately, LLMs are known to be overconfident and\nprovide unreliable confidence estimation. To address this limitation, we\nintroduce Self-Calibration by distilling Self-Consistency-derived confidence\ninto the model itself. This enables reliable confidence estimation at test time\nwith one forward pass. We then design confidence-based efficient test-time\nscaling methods to handle queries of various difficulty, such as Early-Stopping\nfor Best-of-N and Self-Consistency with calibrated confidence. Experiments on\nthree LLMs across six datasets demonstrate the effectiveness of our approach.\nSpecifically, applying confidence-based Early Stopping to Best-of-N improves\nMathQA accuracy from 81.0 to 83.6 with a sample budget of 16 responses,\nindicating the efficacy of confidence-based sampling strategy at inference\ntime.",
      "tldr_zh": "该研究针对大语言模型(LLMs)测试时计算效率问题，提出一种基于自校准(Self-Calibration)的方法，通过蒸馏Self-Consistency的置信度到模型中，实现可靠的置信度估计，仅需一个前向传递。相比传统Best-of-N采样和Self-Consistency方法，该方法能根据查询复杂度动态调整采样策略，例如通过置信度-based Early-Stopping来优化资源分配。实验在三个LLMs和六个数据集上验证了其有效性，其中在MathQA数据集上，应用置信度-based Early Stopping使Best-of-N的准确率从81.0提升至83.6，使用16个响应预算。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00031v1",
      "published_date": "2025-02-25 00:21:14 UTC",
      "updated_date": "2025-02-25 00:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:01:25.869735"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 149,
  "processed_papers_count": 149,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T19:01:53.710911"
}