{
  "date": "2025-09-16",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-16 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼šä»Šå¤©çš„ arXiv å¯ä»¥è¯´æ˜¯**â€œAgent å®‰å…¨æ¶æ„â€**ä¸**â€œæ¨ç†åŠ é€Ÿâ€**çš„çˆ†å‘æ—¥ã€‚æˆ‘ä»¬çœ‹åˆ°äº†ä¸ºè‡ªä¸» Agent é‡èº«å®šåˆ¶çš„**å®‰å…¨å§”æ‰˜åè®® (Agentic JWT)**ï¼Œè¿™å¯èƒ½æˆä¸ºæœªæ¥ Agent é€šä¿¡çš„æ ‡å‡†ï¼›åŒæ—¶ï¼Œ**æµ‹è¯•æ—¶è®¡ç®— (Test-Time Compute)** å’Œ **å¤š Token é¢„æµ‹ (Multi-Token Prediction)** çš„æ–°è¿›å±•æ­£åœ¨é‡æ–°å®šä¹‰ LLM çš„æ¨ç†æ•ˆç‡ä¸èƒ½åŠ›ã€‚è®¡ç®—æœºè§†è§‰æ–¹é¢ï¼Œ**MapAnything** æå‡ºäº†é€šç”¨çš„ 3D é‡å»ºèŒƒå¼ï¼Œå€¼å¾—å…³æ³¨ã€‚\n\n---\n\n### ğŸ”¥ å¿…è¯»ï¼šAgent åè®®ã€3D é€šç”¨æ¨¡å‹ä¸æ¨ç†åŠ é€Ÿ\n\n**1. [å®‰å…¨] Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šAgentic JWTï¼šä¸€ç§ç”¨äºè‡ªä¸» AI Agent çš„å®‰å…¨å§”æ‰˜åè®®\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ä¸€ç¯‡éå¸¸é‡è¦çš„åŸºç¡€è®¾æ–½ç±»æ–‡ç« ã€‚ç°æœ‰çš„ OAuth 2.0 å‡è®¾å®¢æˆ·ç«¯æ˜¯ç¡®å®šçš„ï¼Œä½† AI Agent çš„è¡Œä¸ºæ˜¯éšæœºçš„ï¼ˆStochastic reasoningï¼‰ï¼Œå®¹æ˜“å—åˆ°æç¤ºæ³¨å…¥æ”»å‡»ã€‚ä½œè€…æå‡ºäº† **Agentic JWT (A-JWT)**ï¼Œè¿™æ˜¯ä¸€ç§åŒé¢æ„å›¾ä»¤ç‰Œï¼ˆIntent Tokenï¼‰ã€‚\n*   **å…³é”®æœºåˆ¶**ï¼šå®ƒå°† Agent çš„æ¯ä¸€ä¸ªåŠ¨ä½œç»‘å®šåˆ°å¯éªŒè¯çš„ç”¨æˆ·æ„å›¾ä¸Šï¼Œå¹¶æºå¸¦ä¸€ä¸ªåŸºäº Promptã€å·¥å…·å’Œé…ç½®ç”Ÿæˆçš„â€œèº«ä»½æ ¡éªŒå’Œâ€ã€‚å®ƒæ”¯æŒé“¾å¼å§”æ‰˜æ–­è¨€ï¼ˆChained delegation assertionï¼‰ï¼Œå³ä¾¿åœ¨åŒä¸€ä¸ªè¿›ç¨‹å†…ä¹Ÿèƒ½å®ç°é›¶ä¿¡ä»»ï¼ˆZero-Trustï¼‰çš„å®‰å…¨éš”ç¦»ã€‚è¿™ä¸ºè§£å†³ Agent ä¹±è°ƒ API çš„é—®é¢˜æä¾›äº†ç³»ç»Ÿçº§æ–¹æ¡ˆã€‚\n\n**2. [è§†è§‰] MapAnything: Universal Feed-Forward Metric 3D Reconstruction**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šMapAnythingï¼šé€šç”¨å‰é¦ˆåº¦é‡ 3D é‡å»º\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ Transformer æ¨¡å‹ **MapAnything**ã€‚å®ƒä¸æ˜¯é’ˆå¯¹å•ä¸€ä»»åŠ¡ï¼Œè€Œæ˜¯é€šè¿‡ä¸€æ¬¡å‰é¦ˆï¼ˆFeed-Forwardï¼‰ç›´æ¥å›å½’å‡º 3D åœºæ™¯çš„å‡ ä½•å½¢çŠ¶å’Œç›¸æœºå‚æ•°ã€‚\n*   **äº®ç‚¹**ï¼šå®ƒåˆ©ç”¨äº†å¤šè§†è§’åœºæ™¯å‡ ä½•çš„åˆ†è§£è¡¨ç¤ºï¼ˆæ·±åº¦å›¾ã€å°„çº¿å›¾ç­‰ï¼‰ï¼Œå¹¶åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šç»Ÿä¸€äº†ç›‘ç£è®­ç»ƒã€‚è¯¥æ¨¡å‹åœ¨æ— æ ‡å®š SfMã€å¤šè§†å›¾ç«‹ä½“è§†è§‰ã€å•ç›®æ·±åº¦ä¼°è®¡ç­‰å¤šä¸ª 3D ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºè‰²ï¼Œå±•ç°äº†æˆä¸º**é€šç”¨ 3D é‡å»º Backbone** çš„æ½œåŠ›ã€‚\n\n**3. [æ¨ç†åŠ é€Ÿ] FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šFastMTPï¼šé€šè¿‡å¢å¼ºçš„å¤š Token é¢„æµ‹åŠ é€Ÿ LLM æ¨ç†\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹æŠ•æœºé‡‡æ ·ï¼ˆSpeculative Decodingï¼‰çš„æ”¹è¿›ã€‚ä¼ ç»Ÿçš„**å¤š Token é¢„æµ‹ (MTP)** ä¸»è¦ç”¨äºæå‡è®­ç»ƒï¼Œä½†è¿™ç¯‡è®ºæ–‡å°†å…¶æ½œåŠ›ç”¨äºæ¨ç†åŠ é€Ÿã€‚\n*   **å‘ç°**ï¼šé€šè¿‡å¾®è°ƒä¸€ä¸ªå…±äº«æƒé‡çš„ MTP å¤´ï¼ˆHeadï¼‰ï¼Œä½¿å…¶ä¸æ¨ç†æ¨¡å¼å¯¹é½ï¼Œå¹¶å¼•å…¥åŠ¨æ€è¯è¡¨å‹ç¼©ã€‚åœ¨ä¸æŸå¤±ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼ŒFastMTP å®ç°äº†å¹³å‡ **2.03 å€** çš„é€Ÿåº¦æå‡ï¼Œæ¯”åŸç”Ÿ MTP å¿« 82%ã€‚\n\n---\n\n### ğŸ§  LLM æ¨ç†ã€æ¶æ„ä¸ Scaling Law\n\n**4. [æ¶æ„] Positional Encoding via Token-Aware Phase Attention (TAPA)**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šåŸºäº Token æ„ŸçŸ¥ç›¸ä½æ³¨æ„åŠ›çš„ä½ç½®ç¼–ç \n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæŒ‘æˆ˜äº†ç»Ÿæ²»åœ°ä½çš„ RoPEï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰ã€‚ä½œè€…è¯æ˜ RoPE å¼•å…¥äº†è·ç¦»ç›¸å…³çš„åå·®ï¼Œé™åˆ¶äº†é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚**TAPA** å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„ç›¸ä½å‡½æ•°ï¼ˆPhase functionï¼‰åˆ°æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œåœ¨æ— éœ€å¤§é‡åæœŸè°ƒæ•´çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—é™ä½äº†é•¿ä¸Šä¸‹æ–‡çš„å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ï¼Œä¸ä»…èƒ½å¤–æ¨åˆ°æœªè§è¿‡çš„é•¿åº¦ï¼Œè¿˜ä¿ç•™äº†é•¿è·ç¦»çš„ Token äº¤äº’èƒ½åŠ›ã€‚\n\n**5. [Scaling] Locally Adaptive Test-Time Scaling (LATTS)**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šLATTSï¼šå±€éƒ¨è‡ªé€‚åº”æµ‹è¯•æ—¶ Scaling\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ç›®å‰ç«çƒ­çš„ Test-Time Scalingï¼ˆæµ‹è¯•æ—¶è®¡ç®—æ‰©å±•ï¼‰æå‡ºçš„ä¼˜åŒ–ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸æ˜¯å¯¹æ‰€æœ‰æ ·æœ¬å¢åŠ ç›¸åŒçš„è®¡ç®—é‡ï¼ˆå¦‚é‡‡æ ·æ¬¡æ•°ï¼‰ã€‚**LATTS** æ›´åŠ èªæ˜ï¼Œå®ƒæ ¹æ®éªŒè¯å™¨ï¼ˆVerifierï¼‰å¾—å‡ºçš„â€œå±€éƒ¨éš¾åº¦â€ï¼Œåœ¨ç”Ÿæˆçš„æ¯ä¸€æ­¥åŠ¨æ€å†³å®šæ˜¯é‡é‡‡æ ·ã€å›æº¯è¿˜æ˜¯åœæ­¢ã€‚è¿™æ˜¯ä¸€ç§æ›´é«˜æ•ˆçš„è®¡ç®—èµ„æºåˆ†é…ç­–ç•¥ï¼Œç”¨æ›´å°‘çš„ç®—åŠ›æ¢å–äº†æ›´é«˜çš„å‡†ç¡®ç‡ã€‚\n\n**6. [æ•°å­¦æ¨ç†] Reasoning Enhanced Algorithm for Maths Solving (REAMS)**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šREAMSï¼šç”¨äºæ•°å­¦æ±‚è§£çš„æ¨ç†å¢å¼ºç®—æ³•\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ MITã€å“¥ä¼¦æ¯”äºšå¤§å­¦ç­‰é«˜éš¾åº¦æ•°å­¦è¯¾ç¨‹é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€çš„æ–¹æ¡ˆï¼Œç»“åˆäº†é›¶æ ·æœ¬å­¦ä¹ å’Œç¨‹åºåˆæˆï¼ˆProgram Synthesisï¼‰ã€‚\n*   **æ•ˆæœ**ï¼šåœ¨æéš¾çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº† **90.15%** çš„å‡†ç¡®ç‡ï¼ˆå‰ SOTA æ˜¯ 81%ï¼‰ï¼Œè¯æ˜äº†ä»£ç è¾…åŠ©æ¨ç†åœ¨å¤„ç†é«˜ç­‰æ•°å­¦é—®é¢˜ä¸Šçš„ç»å¯¹ä¼˜åŠ¿ã€‚\n\n**7. [å®šç†å‘ç°] Discovering New Theorems via LLMs with In-Context Proof Learning in Lean**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šåˆ©ç”¨ Lean ä¸­çš„ä¸Šä¸‹æ–‡è¯æ˜å­¦ä¹ é€šè¿‡ LLM å‘ç°æ–°å®šç†\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ä»…ä»…æ˜¯åšé¢˜ï¼Œè€Œæ˜¯**å‘ç°æ–°å®šç†**ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªâ€œçŒœæƒ³-è¯æ˜â€å¾ªç¯ç®¡é“ã€‚å…³é”®åœ¨äºåˆ©ç”¨â€œä¸Šä¸‹æ–‡å­¦ä¹ â€ï¼ˆIn-Context Learningï¼‰è®© LLM å­¦ä¹ ä¹‹å‰çš„è¯æ˜ç­–ç•¥ï¼Œä»è€Œè¯æ˜äº†ä¹‹å‰æœªå½¢å¼åŒ–çš„æ•°å­¦å®šç†ã€‚è¿™è¡¨æ˜ LLM å…·å¤‡äº†æ¢ç´¢æœªçŸ¥çš„æ½œåŠ›ã€‚\n\n---\n\n### ğŸ¤– Agent åº”ç”¨ã€å®‰å…¨ä¸å¤šæ™ºèƒ½ä½“\n\n**8. [è‡ªåŠ¨é©¾é©¶] TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šTreeIRLï¼šç»“åˆæ ‘æœç´¢ä¸é€†å¼ºåŒ–å­¦ä¹ çš„å®‰å…¨åŸå¸‚é©¾é©¶\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå°†è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ä¸æ·±åº¦é€†å¼ºåŒ–å­¦ä¹ ï¼ˆIRLï¼‰ç»“åˆã€‚MCTS è´Ÿè´£æ‰¾å®‰å…¨çš„å€™é€‰è½¨è¿¹ï¼ŒIRL è´Ÿè´£æ‰“åˆ†é€‰å‡ºæœ€åƒäººç±»çš„é‚£ä¸ªã€‚\n*   **å®æˆ˜**ï¼šåœ¨æ‹‰æ–¯ç»´åŠ æ–¯å¸‚åŒºè¿›è¡Œäº† **500+ è‹±é‡Œ** çš„å®è½¦æµ‹è¯•ï¼ˆè¿™æ˜¯éå¸¸ç¡¬æ ¸çš„å·¥ä½œï¼‰ï¼Œåœ¨å¤„ç†æ‹¥å µã€åˆ‡å…¥ç­‰å¤æ‚è·¯å†µæ—¶è¡¨ç°ä¼˜äºç»å…¸è§„åˆ’å™¨ã€‚\n\n**9. [å¤š Agent å®‰å…¨] The Sum Leaks More Than Its Parts: Compositional Privacy Risks**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šæ•´ä½“æ³„æ¼å¤šäºéƒ¨åˆ†ä¹‹å’Œï¼šå¤š Agent åä½œä¸­çš„ç»„åˆéšç§é£é™©\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†**ç»„åˆéšç§æ³„æ¼ï¼ˆCompositional Privacy Leakageï¼‰**çš„æ¦‚å¿µã€‚å•ä¸ª Agent çš„å›ç­”å¯èƒ½æ— å®³ï¼Œä½†å¤šä¸ª Agent çš„å›ç­”ç»„åˆèµ·æ¥å°±èƒ½æ¨å¯¼å‡ºæ•æ„Ÿä¿¡æ¯ã€‚\n*   **å¯¹ç­–**ï¼šæå‡ºäº†â€œå¿ƒæ™ºç†è®ºé˜²å¾¡â€ï¼ˆToM Defenseï¼‰ï¼Œå³ Agent åœ¨å›ç­”å‰ä¼šé¢„åˆ¤æ”»å‡»è€…æ˜¯å¦èƒ½ç»“åˆå·²çŸ¥ä¿¡æ¯æ¨å¯¼å‡ºéšç§ï¼Œè¿™ç§é˜²å¾¡ç­–ç•¥èƒ½æ‹¦æˆª 97% çš„æ•æ„ŸæŸ¥è¯¢ã€‚\n\n**10. [è¶Šç‹±æ”»å‡»] Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in VLMs**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šä»¥é˜²ä¸ºæ”»ï¼šç»•è¿‡å¼±é˜²å¾¡ä»¥å®ç°æ›´å¼ºçš„ VLM è¶Šç‹±\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸€ä¸ªåç›´è§‰çš„å‘ç°â€”â€”åœ¨æ”»å‡»æµç¨‹ä¸­åŠ å…¥â€œå¼±é˜²å¾¡â€åè€Œèƒ½æå‡æ”»å‡»æ•ˆæœã€‚ä½œè€…æå‡ºçš„ Defense2Attack æ–¹æ³•åˆ©ç”¨é˜²å¾¡æ¨¡å¼æ¥æŒ‡å¯¼è¶Šç‹± Prompt çš„è®¾è®¡ï¼Œåœ¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸Šå®ç°äº†ä¸€æ¬¡æ€§æˆåŠŸçš„é«˜æ•ˆè¶Šç‹±ã€‚\n\n---\n\n### ğŸ¥ åŒ»ç–— AI ä¸ç§‘å­¦åº”ç”¨\n\n**11. [å¤šæ¨¡æ€åŒ»ç–—] Intelligent Healthcare Imaging Platform: A VLM-Based Framework**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šæ™ºèƒ½åŒ»ç–—æˆåƒå¹³å°ï¼šåŸºäº VLM çš„è‡ªåŠ¨åŒ»å­¦å›¾åƒåˆ†ææ¡†æ¶\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé›†æˆ **Google Gemini 2.5 Flash** è¿›è¡Œå¤šæ¨¡æ€ï¼ˆCT, MRI, X-rayï¼‰åˆ†æã€‚è®ºæ–‡å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ VLM è¿›è¡Œè‚¿ç˜¤æ£€æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆï¼Œè™½ç„¶æ˜¯åº”ç”¨å‹è®ºæ–‡ï¼Œä½† 32 é¡µçš„ç¯‡å¹…è¯¦ç»†å±•ç¤ºäº† Gemini 2.5 åœ¨åŒ»ç–—å‚ç±»çš„è½åœ°æ½œåŠ›ã€‚\n\n**12. [åŒ»å­¦æ¶æ„] CECT-Mamba: a Hierarchical Contrast-enhanced-aware Model for Pancreatic Tumor Subtyping**\n*   **ä¸­æ–‡æ ‡é¢˜**ï¼šCECT-Mambaï¼šç”¨äºèƒ°è…ºè‚¿ç˜¤äºšå‹åˆ†ç±»çš„åˆ†å±‚å¯¹æ¯”å¢å¼ºæ„ŸçŸ¥æ¨¡å‹\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼š**Mamba (State Space Models)** æ€å…¥åŒ»ç–—å½±åƒã€‚é’ˆå¯¹èƒ°è…ºè‚¿ç˜¤çš„é«˜å¼‚è´¨æ€§ï¼Œåˆ©ç”¨ Mamba çš„çº¿æ€§å¤æ‚åº¦å¤„ç†å¤šæ—¶ç›¸ CECT æ•°æ®ï¼Œåœ¨åŒºåˆ†èƒ°è…ºå¯¼ç®¡è…ºç™Œå’Œç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤ä¸Šå®ç°äº† 98.6% çš„ AUCã€‚\n\n---\n\n### ğŸš€ å…¶ä»–å€¼å¾—å…³æ³¨çš„çŸ­è®¯\n\n*   **[æœºå™¨äºº] Dense-Jump Flow Matching**: å‘ç°å¢åŠ  Euler ç§¯åˆ†æ­¥æ•°åè€Œä¼šé™ä½ Flow Matching ç­–ç•¥çš„æ€§èƒ½ï¼Œæå‡ºäº†ä¸€ç§éå‡åŒ€æ—¶é—´è°ƒåº¦ç­–ç•¥ï¼Œæå‡äº†æœºå™¨äººç­–ç•¥ç”Ÿæˆçš„æ³›åŒ–æ€§ã€‚\n*   **[é‡‘è Agent] FinSearchComp**: å‘å¸ƒäº†ä¸€ä¸ªé«˜éš¾åº¦çš„é‡‘èæœç´¢ä¸æ¨ç† Benchmarkï¼ŒåŒ…å«ç”± 70 ä½ä¸“å®¶æ ‡æ³¨çš„çœŸå®å·¥ä½œæµä»»åŠ¡ã€‚\n*   **[ç¡¬ä»¶éªŒè¯] Towards Robust Agentic CUDA Kernel Benchmarking**: ç”¨ Agent è‡ªåŠ¨ç”Ÿæˆã€éªŒè¯å’Œä¼˜åŒ– CUDA Kernelï¼Œè®© LLM å†™å‡ºæ¯” PyTorch åŸç”Ÿæ›´å¿«åˆ°åº•å±‚ä»£ç ã€‚\n*   **[æ•°å­¦/RL] Learn to Relax with Large Language Models**: æå‡º AutoCOï¼Œåˆ©ç”¨ LLM è‡ªåŠ¨è¿›è¡Œçº¦æŸæ¾å¼›ï¼ˆConstraint Relaxationï¼‰æ¥è§£å†³éçº¿æ€§ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œç»“åˆäº†è¿›åŒ–ç®—æ³•å’Œ MCTSã€‚",
  "papers": [
    {
      "arxiv_id": "2509.13597v1",
      "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents",
      "title_zh": "Agentic JWTï¼šé¢å‘è‡ªä¸» AI æ™ºèƒ½ä½“çš„å®‰å…¨å§”æ´¾åè®®",
      "authors": [
        "Abhishek Goswami"
      ],
      "abstract": "Autonomous LLM agents can issue thousands of API calls per hour without human oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings stochastic reasoning, prompt injection, or multi-agent orchestration can silently expand privileges.\n  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each agent's action to verifiable user intent and, optionally, to a specific workflow step. A-JWT carries an agent's identity as a one-way checksum hash derived from its prompt, tools and configuration, and a chained delegation assertion to prove which downstream agent may execute a given task, and per-agent proof-of-possession keys to prevent replay and in-process impersonation. We define a new authorization mechanism and add a lightweight client shim library that self-verifies code at run time, mints intent tokens, tracks workflow steps and derives keys, thus enabling secure agent identity and separation even within a single process.\n  We illustrate a comprehensive threat model for agentic applications, implement a Python proof-of-concept and show functional blocking of scope-violating requests, replay, impersonation, and prompt-injection pathways with sub-millisecond overhead on commodity hardware. The design aligns with ongoing OAuth agent discussions and offers a drop-in path toward zero-trust guarantees for agentic applications. A comprehensive performance and security evaluation with experimental results will appear in our forthcoming journal publication",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸» LLM agents åœ¨é«˜é¢‘ API è°ƒç”¨ä¸­é¢ä¸´çš„éšæœºæ¨ç†ã€prompt injection ä»¥åŠç‰¹æƒé™é»˜æ‰©å¼ ç­‰å®‰å…¨é£é™©ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ OAuth 2.0 åè®®åœ¨ç¡®å®šæ€§å®¢æˆ·ç«¯å‡è®¾ä¸‹çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Agentic JWT (A-JWT)ï¼Œè¿™æ˜¯ä¸€ç§åŒé¢æ„å›¾ä»¤ç‰Œ (dual-faceted intent token)ï¼Œæ—¨åœ¨å°†æ™ºèƒ½ä½“çš„æ¯ä¸ªæ“ä½œä¸å¯éªŒè¯çš„ç”¨æˆ·æ„å›¾åŠç‰¹å®šå·¥ä½œæµæ­¥éª¤è¿›è¡Œç»‘å®šã€‚A-JWT é€šè¿‡ä»æç¤ºè¯ã€å·¥å…·å’Œé…ç½®ä¸­æå–çš„å•å‘æ ¡éªŒå’Œå“ˆå¸Œ (one-way checksum hash) æ¥æ‰¿è½½æ™ºèƒ½ä½“èº«ä»½ï¼Œå¹¶åˆ©ç”¨é“¾å¼å§”æ´¾æ–­è¨€ (chained delegation assertion) éªŒè¯ä¸‹æ¸¸æ™ºèƒ½ä½“çš„æ‰§è¡Œæƒé™ã€‚æ­¤å¤–ï¼Œè¯¥åè®®å¼•å…¥äº†æ¯æ™ºèƒ½ä½“æ‰€æœ‰æƒè¯æ˜å¯†é’¥ (per-agent proof-of-possession keys) ä»¥é˜²æ­¢é‡æ”¾æ”»å‡»å’Œè¿›ç¨‹å†…å†’å……ï¼Œå¹¶é…æœ‰ä¸€ä¸ªè½»é‡çº§å®¢æˆ·ç«¯ shim library åœ¨è¿è¡Œæ—¶æ‰§è¡Œä»£ç è‡ªéªŒè¯ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ Python æ¦‚å¿µéªŒè¯ (proof-of-concept) ä¸­èƒ½ä»¥äºšæ¯«ç§’çº§çš„å¼€é”€æœ‰æ•ˆé˜»æ–­è¿åæƒé™çš„è¯·æ±‚å’Œæ³¨å…¥è·¯å¾„ã€‚è¯¥è®¾è®¡ä¸º agentic applications å®ç°é›¶ä¿¡ä»» (zero-trust) æ‹…ä¿æä¾›äº†ä¸€ç§å¯ç›´æ¥æ¥å…¥çš„æ¼”è¿›è·¯å¾„ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 6 figures, 2 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.13597v1",
      "published_date": "2025-09-16 23:43:24 UTC",
      "updated_date": "2025-09-16 23:43:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:27.848550+00:00"
    },
    {
      "arxiv_id": "2509.13590v2",
      "title": "Intelligent Healthcare Imaging Platform: A VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation",
      "title_zh": "æ™ºèƒ½åŒ»ç–—å½±åƒå¹³å°ï¼šä¸€ç§åŸºäº VLM çš„åŒ»å­¦å›¾åƒè‡ªåŠ¨åˆ†æä¸ä¸´åºŠæŠ¥å‘Šç”Ÿæˆæ¡†æ¶",
      "authors": [
        "Samer Al-Hamadani"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) in healthcare imaging has revolutionized diagnostic medicine and clinical decision-making processes. This work presents an intelligent multimodal framework for medical image analysis that leverages Vision-Language Models (VLMs) in healthcare diagnostics. The framework integrates Google Gemini 2.5 Flash for automated tumor detection and clinical report generation across multiple imaging modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual feature extraction with natural language processing to enable contextual image interpretation, incorporating coordinate verification mechanisms and probabilistic Gaussian modeling for anomaly distribution. Multi-layered visualization techniques generate detailed medical illustrations, overlay comparisons, and statistical representations to enhance clinical confidence, with location measurement achieving 80 pixels average deviation. Result processing utilizes precise prompt engineering and textual analysis to extract structured clinical information while maintaining interpretability. Experimental evaluations demonstrated high performance in anomaly detection across multiple modalities. The system features a user-friendly Gradio interface for clinical workflow integration and demonstrates zero-shot learning capabilities to reduce dependence on large datasets. This framework represents a significant advancement in automated diagnostic support and radiological workflow efficiency, though clinical validation and multi-center evaluation are necessary prior to widespread adoption.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºVision-Language Models (VLMs)çš„æ™ºèƒ½å¤šæ¨¡æ€åŒ»ç–—æˆåƒæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°è‡ªåŠ¨åŒ–çš„åŒ»å­¦å›¾åƒåˆ†æå’Œä¸´åºŠæŠ¥å‘Šç”Ÿæˆã€‚è¯¥å¹³å°é›†æˆäº†Google Gemini 2.5 Flashæ¨¡å‹ï¼Œæ”¯æŒå¯¹CTã€MRIã€X-rayå’ŒUltrasoundç­‰å¤šç§æ¨¡æ€å›¾åƒè¿›è¡Œè‚¿ç˜¤æ£€æµ‹ä¸ä¸Šä¸‹æ–‡è§£è¯»ã€‚æŠ€æœ¯ä¸Šï¼Œè¯¥ç³»ç»Ÿèåˆäº†è§†è§‰ç‰¹å¾æå–ä¸è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå¹¶åˆ›æ–°æ€§åœ°å¼•å…¥äº†åæ ‡éªŒè¯æœºåˆ¶ä¸æ¦‚ç‡é«˜æ–¯å»ºæ¨¡(probabilistic Gaussian modeling)æ¥å®šä½å¼‚å¸¸åˆ†å¸ƒã€‚é€šè¿‡å¤šå±‚å¯è§†åŒ–æŠ€æœ¯ä¸ç²¾ç¡®çš„æç¤ºå·¥ç¨‹(Prompt Engineering)ï¼Œç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆç»“æ„åŒ–çš„ä¸´åºŠæŠ¥å‘Šï¼Œå…¶ä½ç½®æµ‹é‡å¹³å‡åå·®æ§åˆ¶åœ¨80åƒç´ ä»¥å†…ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤šæ¨¡æ€å¼‚å¸¸æ£€æµ‹ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„é›¶æ¬¡å­¦ä¹ (Zero-shot Learning)èƒ½åŠ›ï¼Œæœ‰æ•ˆé™ä½äº†å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚è¯¥ç³»ç»Ÿçš„å¼€å‘ç»“åˆäº†ç›´è§‚çš„Gradioç•Œé¢ï¼Œæ˜¾è‘—æå‡äº†æ”¾å°„ç§‘çš„å·¥ä½œæµæ•ˆç‡ï¼Œä¸ºè‡ªåŠ¨åŒ–è¯Šæ–­æ”¯æŒé¢†åŸŸå¸¦æ¥äº†é‡è¦è¿›å±•ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "32 pages, 14 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.13590v2",
      "published_date": "2025-09-16 23:15:44 UTC",
      "updated_date": "2025-10-08 09:41:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:30.983786+00:00"
    },
    {
      "arxiv_id": "2509.13588v2",
      "title": "Programmable Cognitive Bias in Social Agents",
      "title_zh": "ç¤¾ä¼šæ™ºèƒ½ä½“ä¸­çš„å¯ç¼–ç¨‹è®¤çŸ¥åå·®",
      "authors": [
        "Xuan Liu",
        "Haoyang Shang",
        "Haojian Jin"
      ],
      "abstract": "This paper introduces CoBRA, a novel toolkit for systematically specifying agent behavior in LLM-based social simulation. We found that conventional approaches that specify agent behaviors through implicit natural language descriptions cannot yield consistent behaviors across models, and the produced agent behaviors do not capture the nuances of the descriptions. In contrast, CoBRA presents a new approach to program agents' cognitive biases explicitly, by grounding agents' expected behaviors using classic social science experiments. CoBRA has two components: (1) Cognitive Bias Index that measures the cognitive bias of a social agent, by quantifying the agent's reactions in a set of validated classical social science experiments; (2) Behavioral Regulation Engine that aligns the agent's behavior to demonstrate controlled cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and technical benchmarks. Our results suggest that CoBRA can precisely program the cognitive bias demonstrated in a social agent in a model-agnostic manner.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„ç¤¾äº¤æ¨¡æ‹Ÿä¸­ï¼Œä¼ ç»Ÿè‡ªç„¶è¯­è¨€æè¿°æ— æ³•åœ¨ä¸åŒæ¨¡å‹é—´äº§ç”Ÿä¸€è‡´ä¸”ç»†è‡´çš„æ™ºèƒ½ä½“è¡Œä¸ºè¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†åä¸ºCoBRAçš„æ–°å‹å·¥å…·åŒ…ã€‚ä¸ä»¥å¾€çš„éšå¼æè¿°æ–¹æ³•ä¸åŒï¼ŒCoBRAåˆ©ç”¨ç»å…¸ç¤¾ä¼šç§‘å­¦å®éªŒä½œä¸ºåŸºå‡†ï¼Œå®ç°äº†å¯¹æ™ºèƒ½ä½“è®¤çŸ¥åå·®(Cognitive Bias)çš„æ˜¾å¼ç¼–ç¨‹ã€‚è¯¥å·¥å…·åŒ…åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šè®¤çŸ¥åå·®æŒ‡æ•°(Cognitive Bias Index)ç”¨äºé€šè¿‡é‡åŒ–æ™ºèƒ½ä½“åœ¨ç¤¾äº¤å®éªŒä¸­çš„ååº”æ¥æµ‹é‡å…¶åå·®æ°´å¹³ï¼Œè€Œè¡Œä¸ºè°ƒèŠ‚å¼•æ“(Behavioral Regulation Engine)åˆ™è´Ÿè´£å°†æ™ºèƒ½ä½“è¡Œä¸ºä¸é¢„è®¾çš„åå·®è¿›è¡Œå¯¹é½ã€‚æŠ€æœ¯åŸºå‡†æµ‹è¯•ç»“æœè¡¨æ˜ï¼ŒCoBRAèƒ½å¤Ÿä»¥æ¨¡å‹æ— å…³(Model-agnostic)çš„æ–¹å¼ç²¾ç¡®ç¼–ç¨‹ç¤¾äº¤æ™ºèƒ½ä½“æ‰€è¡¨ç°å‡ºçš„è®¤çŸ¥åå·®ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ç¤¾äº¤æ¨¡æ‹Ÿä¸­ç³»ç»ŸåŒ–åœ°æŒ‡å®šå’Œæ§åˆ¶æ™ºèƒ½ä½“è¡Œä¸ºæä¾›äº†å¯é çš„æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13588v2",
      "published_date": "2025-09-16 23:03:02 UTC",
      "updated_date": "2025-10-19 05:25:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:36.389426+00:00"
    },
    {
      "arxiv_id": "2509.13579v4",
      "title": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning",
      "title_zh": "TreeIRLï¼šåŸºäºæ ‘æœç´¢ä¸é€†å¼ºåŒ–å­¦ä¹ çš„åŸå¸‚å®‰å…¨é©¾é©¶",
      "authors": [
        "Momchil S. Tomov",
        "Sang Uk Lee",
        "Hansford Hendrago",
        "Jinwook Huh",
        "Teawon Han",
        "Forbes Howington",
        "Rafael da Silva",
        "Gianmarco Bernasconi",
        "Marc Heim",
        "Samuel Findler",
        "Xiaonan Ji",
        "Alexander Boule",
        "Michael Napoli",
        "Kuo Chen",
        "Jesse Miller",
        "Boaz Floor",
        "Yunqing Hu"
      ],
      "abstract": "We present TreeIRL, a novel planner for autonomous driving that combines Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to achieve state-of-the-art performance in simulation and in real-world driving. The core idea is to use MCTS to find a promising set of safe candidate trajectories and a deep IRL scoring function to select the most human-like among them. We evaluate TreeIRL against both classical and state-of-the-art planners in large-scale simulations and on 500+ miles of real-world autonomous driving in the Las Vegas metropolitan area. Test scenarios include dense urban traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves the best overall performance, striking a balance between safety, progress, comfort, and human-likeness. To our knowledge, our work is the first demonstration of MCTS-based planning on public roads and underscores the importance of evaluating planners across a diverse set of metrics and in real-world environments. TreeIRL is highly extensible and could be further improved with reinforcement learning and imitation learning, providing a framework for exploring different combinations of classical and learning-based approaches to solve the planning bottleneck in autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TreeIRLï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº† Monte Carlo tree search (MCTS) å’Œ inverse reinforcement learning (IRL) çš„æ–°å‹è‡ªåŠ¨é©¾é©¶è§„åˆ’å™¨ï¼Œæ—¨åœ¨è§£å†³å¤æ‚åŸå¸‚é©¾é©¶ä¸­çš„è§„åˆ’ç“¶é¢ˆã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ MCTS æœç´¢å¹¶ç­›é€‰å‡ºä¸€ç»„å…·æœ‰å®‰å…¨ä¿éšœçš„å€™é€‰è½¨è¿¹ï¼Œéšåé€šè¿‡æ·±åº¦ IRL è¯„åˆ†å‡½æ•°ä»ä¸­é€‰æ‹©æœ€ç¬¦åˆäººç±»é©¾é©¶ä¹ æƒ¯çš„æœ€ä½³è·¯å¾„ã€‚ç ”ç©¶äººå‘˜åœ¨å¤§è§„æ¨¡ä»¿çœŸç¯å¢ƒä»¥åŠæ‹‰æ–¯ç»´åŠ æ–¯å¸‚åŒºè¶…è¿‡ 500 è‹±é‡Œçš„çœŸå®é“è·¯é©¾é©¶ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œæµ‹è¯•åœºæ™¯æ¶µç›–äº†å¯†é›†äº¤é€šã€è‡ªé€‚åº”å·¡èˆªã€è½¦è¾†åˆ‡å…¥åŠäº¤é€šä¿¡å·ç¯å¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTreeIRL åœ¨å®‰å…¨æ€§ã€é€šè¡Œæ•ˆç‡ã€èˆ’é€‚åº¦åŠäººç±»ç›¸ä¼¼æ€§ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡ï¼Œå…¶æ•´ä½“æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„ç»å…¸åŠå…ˆè¿›è§„åˆ’å™¨ã€‚ä½œä¸ºé¦–æ¬¡åœ¨å…¬å…±é“è·¯ä¸ŠæˆåŠŸæ¼”ç¤ºçš„åŸºäº MCTS çš„è§„åˆ’ç³»ç»Ÿï¼ŒTreeIRL ä¸ºæ¢ç´¢ç»å…¸ç®—æ³•ä¸å­¦ä¹ å‹æ–¹æ³•çš„ç»“åˆæä¾›äº†ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•çš„ç ”ç©¶æ¡†æ¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13579v4",
      "published_date": "2025-09-16 22:37:37 UTC",
      "updated_date": "2025-10-25 12:00:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:41.664489+00:00"
    },
    {
      "arxiv_id": "2509.13574v1",
      "title": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation",
      "title_zh": "é‡‡ç”¨éå‡åŒ€æ—¶é—´è°ƒåº¦çš„æœºå™¨äººç­–ç•¥ç¨ å¯†è·³è½¬æµåŒ¹é…ï¼šç¼“è§£å¤šæ­¥æ¨ç†é€€åŒ–",
      "authors": [
        "Zidong Chen",
        "Zihao Guo",
        "Peng Wang",
        "ThankGod Itua Egbe",
        "Yan Lyu",
        "Chenghao Qian"
      ],
      "abstract": "Flow matching has emerged as a competitive framework for learning high-quality generative policies in robotics; however, we find that generalisation arises and saturates early along the flow trajectory, in accordance with recent findings in the literature. We further observe that increasing the number of Euler integration steps during inference counter-intuitively and universally degrades policy performance. We attribute this to (i) additional, uniformly spaced integration steps oversample the late-time region, thereby constraining actions towards the training trajectories and reducing generalisation; and (ii) the learned velocity field becoming non-Lipschitz as integration time approaches 1, causing instability. To address these issues, we propose a novel policy that utilises non-uniform time scheduling (e.g., U-shaped) during training, which emphasises both early and late temporal stages to regularise policy training, and a dense-jump integration schedule at inference, which uses a single-step integration to replace the multi-step integration beyond a jump point, to avoid unstable areas around 1. Essentially, our policy is an efficient one-step learner that still pushes forward performance through multi-step integration, yielding up to 23.7% performance gains over state-of-the-art baselines across diverse robotic tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Flow matching åœ¨æœºå™¨äººç­–ç•¥å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œå¹¶æ­ç¤ºäº†å¢åŠ æ¨ç†é˜¶æ®µçš„ Euler integration æ­¥æ•°åè€Œæ™®éå¯¼è‡´æ€§èƒ½ä¸‹é™çš„å¼‚å¸¸ç°è±¡ã€‚ä½œè€…æŒ‡å‡ºï¼Œè¿™ä¸€é—®é¢˜æºäºå‡åŒ€æ—¶é—´æ­¥å¯¹åæœŸè½¨è¿¹åŒºåŸŸçš„è¿‡åº¦é‡‡æ ·é™åˆ¶äº†æ³›åŒ–èƒ½åŠ›ï¼Œä¸”é€Ÿåº¦åœºåœ¨ç§¯åˆ†æ—¶é—´æ¥è¿‘ 1 æ—¶è¡¨ç°å‡ºçš„ non-Lipschitz ç‰¹æ€§å¼•å‘äº†æ¨ç†ä¸ç¨³å®šæ€§ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºåœ¨è®­ç»ƒæ—¶é‡‡ç”¨éå‡åŒ€æ—¶é—´è°ƒåº¦ï¼ˆå¦‚ U-shaped schedulingï¼‰ä»¥å¢å¼ºæ­£åˆ™åŒ–æ•ˆæœï¼Œå¹¶åœ¨æ¨ç†æ—¶ä½¿ç”¨ dense-jump æ–¹æ¡ˆï¼Œå³åœ¨è·³è·ƒç‚¹åè½¬ä¸ºå•æ­¥ç§¯åˆ†ä»¥è§„é¿ä¸ç¨³å®šåŒºåŸŸã€‚è¯¥æ–¹æ³•æ„å»ºäº†ä¸€ä¸ªèƒ½é€šè¿‡å¤šæ­¥ç§¯åˆ†è¿›ä¸€æ­¥æå‡æ€§èƒ½çš„é«˜æ•ˆå•æ­¥å­¦ä¹ å™¨ï¼Œåœ¨å¤šæ ·åŒ–çš„æœºå™¨äººä»»åŠ¡ä¸­ç›¸è¾ƒäºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾ 23.7% çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13574v1",
      "published_date": "2025-09-16 22:28:27 UTC",
      "updated_date": "2025-09-16 22:28:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:38.584638+00:00"
    },
    {
      "arxiv_id": "2509.13570v1",
      "title": "Gen AI in Proof-based Math Courses: A Pilot Study",
      "title_zh": "ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨åŸºäºè¯æ˜çš„æ•°å­¦è¯¾ç¨‹ä¸­çš„åº”ç”¨ï¼šä¸€é¡¹åˆæ­¥ç ”ç©¶",
      "authors": [
        "Hannah Klawa",
        "Shraddha Rajpal",
        "Cigole Thomas"
      ],
      "abstract": "With the rapid rise of generative AI in higher education and the unreliability of current AI detection tools, developing policies that encourage student learning and critical thinking has become increasingly important. This study examines student use and perceptions of generative AI across three proof-based undergraduate mathematics courses: a first-semester abstract algebra course, a topology course and a second-semester abstract algebra course. In each case, course policy permitted some use of generative AI. Drawing on survey responses and student interviews, we analyze how students engaged with AI tools, their perceptions of generative AI's usefulness and limitations, and what implications these perceptions hold for teaching proof-based mathematics. We conclude by discussing future considerations for integrating generative AI into proof-based mathematics instruction.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) åœ¨é«˜ç­‰æ•™è‚²ä¸­è¿…é€Ÿå…´èµ·åŠå…¶æ£€æµ‹å·¥å…·ä¸å¯é çš„ç°çŠ¶ï¼Œåœ¨ä¸‰é—¨åŸºäºè¯æ˜çš„æœ¬ç§‘æ•°å­¦è¯¾ç¨‹ï¼ˆæŠ½è±¡ä»£æ•° Iã€II åŠæ‹“æ‰‘å­¦ï¼‰ä¸­å¼€å±•äº†è¯•ç‚¹ç ”ç©¶ã€‚åœ¨å…è®¸ä½¿ç”¨ AI çš„è¯¾ç¨‹æ”¿ç­–èƒŒæ™¯ä¸‹ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡é—®å·è°ƒæŸ¥å’Œå­¦ç”Ÿè®¿è°ˆï¼Œæ·±å…¥åˆ†æäº†å­¦ç”Ÿä¸ AI å·¥å…·çš„äº’åŠ¨æ–¹å¼ï¼Œä»¥åŠä»–ä»¬å¯¹ AI æœ‰ç”¨æ€§å’Œå±€é™æ€§çš„å…·ä½“è®¤çŸ¥ã€‚ç ”ç©¶é‡ç‚¹æ¢è®¨äº†è¿™äº›è®¤çŸ¥å¯¹è¯æ˜æ•°å­¦ (proof-based mathematics) æ•™å­¦çš„æ·±è¿œå¯ç¤ºï¼Œå¹¶åˆ†æäº†å­¦ç”Ÿå¦‚ä½•å¹³è¡¡å·¥å…·ä½¿ç”¨ä¸æ•°å­¦æ€ç»´çš„æ„å»ºã€‚æ–‡ç« æœ€åæ€»ç»“äº†æœªæ¥å°† Generative AI æœ‰æœºèå…¥æ•°å­¦æ•™å­¦çš„ç­–ç•¥ä¸è€ƒé‡ï¼Œæ—¨åœ¨ä¸ºåˆ¶å®šèƒ½å¤Ÿä¿ƒè¿›å­¦ç”Ÿå­¦ä¹ å’Œæ‰¹åˆ¤æ€§æ€ç»´çš„æ•™è‚²æ”¿ç­–æä¾›å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "math.HO"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 6 figures, Comments welcome!",
      "pdf_url": "https://arxiv.org/pdf/2509.13570v1",
      "published_date": "2025-09-16 22:18:12 UTC",
      "updated_date": "2025-09-16 22:18:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:43.838066+00:00"
    },
    {
      "arxiv_id": "2509.18156v1",
      "title": "Event Causality Identification with Synthetic Control",
      "title_zh": "åŸºäºåˆæˆæ§åˆ¶çš„äº‹ä»¶å› æœå…³ç³»è¯†åˆ«",
      "authors": [
        "Haoyu Wang",
        "Fengze Liu",
        "Jiayao Zhang",
        "Dan Roth",
        "Kyle Richardson"
      ],
      "abstract": "Event causality identification (ECI), a process that extracts causal relations between events from text, is crucial for distinguishing causation from correlation. Traditional approaches to ECI have primarily utilized linguistic patterns and multi-hop relational inference, risking false causality identification due to informal usage of causality and specious graphical inference. In this paper, we adopt the Rubin Causal Model to identify event causality: given two temporally ordered events, we see the first event as the treatment and the second one as the observed outcome. Determining their causality involves manipulating the treatment and estimating the resultant change in the likelihood of the outcome. Given that it is only possible to implement manipulation conceptually in the text domain, as a work-around, we try to find a twin for the protagonist from existing corpora. This twin should have identical life experiences with the protagonist before the treatment but undergoes an intervention of treatment. However, the practical difficulty of locating such a match limits its feasibility. Addressing this issue, we use the synthetic control method to generate such a twin' from relevant historical data, leveraging text embedding synthesis and inversion techniques. This approach allows us to identify causal relations more robustly than previous methods, including GPT-4, which is demonstrated on a causality benchmark, COPES-hard.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‹ä»¶å› æœå…³ç³»è¯†åˆ«(Event Causality Identification, ECI)ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆåˆæˆæ§åˆ¶(Synthetic Control)æ–¹æ³•çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨ä»æ–‡æœ¬ä¸­æœ‰æ•ˆåŒºåˆ†å› æœå…³ç³»ä¸ç›¸å…³æ€§ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•ä¾èµ–è¯­è¨€æ¨¡å¼æˆ–å¤šè·³å…³ç³»æ¨ç†æ˜“äº§ç”Ÿè™šå‡å› æœçš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶å€Ÿé‰´äº†Rubin Causal Modelï¼Œå°†å‰åºäº‹ä»¶è§†ä¸ºå¹²é¢„(treatment)ï¼Œå°†åç»­äº‹ä»¶è§†ä¸ºè§‚æµ‹ç»“æœ(outcome)ã€‚ç ”ç©¶åˆ©ç”¨æ–‡æœ¬åµŒå…¥åˆæˆä¸é€†è½¬æŠ€æœ¯ï¼Œä»å†å²ç›¸å…³æ•°æ®ä¸­ç”Ÿæˆä¸€ä¸ªä¸åŸå¯¹è±¡ç»å†ç›¸ä¼¼ä½†å¹²é¢„çŠ¶æ€ä¸åŒçš„â€œåŒèƒèƒâ€ä½œä¸ºåˆæˆæ§åˆ¶ç»„ï¼Œä»¥æ­¤æ¨¡æ‹Ÿåäº‹å®æ¨ç†å¹¶ä¼°è®¡å› æœæ•ˆåº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨COPES-hardå› æœå…³ç³»åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ¯”GPT-4æ›´å¼ºçš„ç¨³å¥æ€§ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«å› æœå…³ç³»çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18156v1",
      "published_date": "2025-09-16 22:05:52 UTC",
      "updated_date": "2025-09-16 22:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:44.665809+00:00"
    },
    {
      "arxiv_id": "2509.14289v3",
      "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing",
      "title_zh": "ä»èƒ½åŠ›åˆ°æ€§èƒ½ï¼šè¯„ä¼°æ¸—é€æµ‹è¯•ä¸­å¤§è¯­è¨€æ¨¡å‹æ¶æ„çš„å…³é”®åŠŸèƒ½ç‰¹æ€§",
      "authors": [
        "Lanxiao Huang",
        "Daksh Dave",
        "Tyler Cody",
        "Peter Beling",
        "Ming Jin"
      ],
      "abstract": "Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single-agent to modular designs, across realistic penetration testing scenarios, measuring empirical performance and recurring failure patterns. We also isolate the impact of five core functional capabilities via targeted augmentations: Global Context Memory (GCM), Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive Planning (AP), and Real-Time Monitoring (RTM). These interventions support, respectively: (i) context coherence and retention, (ii) inter-component coordination and state management, (iii) tool use accuracy and selective execution, (iv) multi-step strategic planning, error detection, and recovery, and (v) real-time dynamic responsiveness. Our results show that while some architectures natively exhibit subsets of these properties, targeted augmentations substantially improve modular agent performance, especially in complex, multi-step, and real-time penetration testing tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“åœ¨æ¸—é€æµ‹è¯•ï¼ˆPenetration Testingï¼‰å®é™…åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ä¸å¯é æ€§ï¼Œæ¶µç›–äº†ä»å•æ™ºèƒ½ä½“åˆ°æ¨¡å—åŒ–è®¾è®¡çš„å¤šç§æ¶æ„ã€‚ç ”ç©¶é€šè¿‡é’ˆå¯¹æ€§å¢å¼ºæ‰‹æ®µï¼Œéš”ç¦»å¹¶åˆ†æäº†äº”é¡¹æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨å±€ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆGlobal Context Memory, GCMï¼‰ã€æ™ºèƒ½ä½“é—´æ¶ˆæ¯ä¼ é€’ï¼ˆInter-Agent Messaging, IAMï¼‰ã€ä¸Šä¸‹æ–‡çº¦æŸè°ƒç”¨ï¼ˆContext-Conditioned Invocation, CCIï¼‰ã€è‡ªé€‚åº”è§„åˆ’ï¼ˆAdaptive Planning, APï¼‰ä»¥åŠå®æ—¶ç›‘æ§ï¼ˆReal-Time Monitoring, RTMï¼‰ã€‚è¿™äº›åŠŸèƒ½åˆ†åˆ«å¯¹åº”ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€ç»„ä»¶é—´åè°ƒã€å·¥å…·è°ƒç”¨å‡†ç¡®æ€§ã€å¤šæ­¥æˆ˜ç•¥è§„åˆ’åŠå®æ—¶åŠ¨æ€å“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶éƒ¨åˆ†æ¶æ„åŸç”Ÿå…·å¤‡è¿™äº›ç‰¹æ€§çš„å­é›†ï¼Œä½†é’ˆå¯¹æ€§çš„å¢å¼ºèƒ½æ˜¾è‘—æå‡æ¨¡å—åŒ–æ™ºèƒ½ä½“åœ¨å¤„ç†å¤æ‚ã€å¤šæ­¥å’Œå®æ—¶æ¸—é€æµ‹è¯•ä»»åŠ¡æ—¶çš„æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸ºç†è§£å’Œä¼˜åŒ–ç”¨äºè‡ªåŠ¨åŒ–å®‰å…¨æ”»å‡»ä»»åŠ¡çš„ LLM æ¶æ„æä¾›äº†é‡è¦çš„å®è¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.14289v3",
      "published_date": "2025-09-16 21:51:59 UTC",
      "updated_date": "2025-11-13 00:06:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:11.193903+00:00"
    },
    {
      "arxiv_id": "2509.13550v1",
      "title": "Complexity Bounds for Smooth Convex Multiobjective Optimization",
      "title_zh": "å¹³æ»‘å‡¸å¤šç›®æ ‡ä¼˜åŒ–çš„å¤æ‚åº¦ç•Œ",
      "authors": [
        "Phillipe R. Sampaio"
      ],
      "abstract": "We study the oracle complexity of finding $\\varepsilon$-Pareto stationary points in smooth multiobjective optimization with $m$ objectives. The progress metric is the Pareto stationarity gap $\\mathcal{G}(x)$ (the norm of an optimal convex combination of gradients). Our contributions are fourfold. (i) For strongly convex objectives, any span first-order method (iterates lie in the span of past gradients) exhibits linear convergence no faster than $\\exp(-Î˜(T/\\sqrtÎº))$ after $T$ oracle calls, where $Îº$ is the condition number, implying $Î˜(\\sqrtÎº\\log(1/\\varepsilon))$ iterations; this matches classical accelerated upper bounds. (ii) For convex problems and oblivious one-step methods (a fixed scalarization with pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best gradient norm among the first $T$ iterates. (iii) Although accelerated gradient descent is outside this restricted class, it is an oblivious span method and attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex problems and general span methods with adaptive scalarizations, we establish a universal lower bound of order $1/T^{2}$ on the gradient norm of the final iterate after $T$ steps, highlighting a gap between known upper bounds and worst-case guarantees. All bounds hold on non-degenerate instances with distinct objectives and non-singleton Pareto fronts; rates are stated up to universal constants and natural problem scaling.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å…·æœ‰ $m$ ä¸ªç›®æ ‡çš„å¹³æ»‘å‡¸å¤šç›®æ ‡ä¼˜åŒ– (Smooth Convex Multiobjective Optimization) ä¸­å¯»æ‰¾ $\\varepsilon$-Pareto stationary points çš„æŸ¥è¯¢å¤æ‚åº¦ (Oracle Complexity)ï¼Œå¹¶é‡‡ç”¨ Pareto stationarity gap $\\mathcal{G}(x)$ ä½œä¸ºè¿›åº¦è¡¡é‡æŒ‡æ ‡ã€‚å¯¹äºå¼ºå‡¸ (Strongly Convex) ç›®æ ‡ï¼Œç ”ç©¶è¯æ˜äº†ä»»ä½•è·¨åº¦ä¸€é˜¶æ–¹æ³• (Span First-Order Method) çš„çº¿æ€§æ”¶æ•›é€Ÿåº¦ä¸å¿«äº $\\exp(-Î˜(T/\\sqrtÎº))$ï¼Œè¿™æ„å‘³ç€è¾¾åˆ° $\\varepsilon$ ç²¾åº¦éœ€è¦ $Î˜(\\sqrtÎº\\log(1/\\varepsilon))$ æ¬¡è¿­ä»£ï¼Œè¯¥ç»“æœä¸ç»å…¸çš„åŠ é€Ÿç®—æ³•ä¸Šç•Œç›¸åŒ¹é…ã€‚åœ¨å‡¸é—®é¢˜ä¸­ï¼Œé’ˆå¯¹å›ºå®šæ ‡é‡åŒ–ä¸”æ­¥é•¿é¢„è®¾çš„é—å¿˜å•æ­¥æ³• (Oblivious One-Step Methods)ï¼Œç ”ç©¶æ¨å¯¼å‡ºäº†æ¢¯åº¦èŒƒæ•°çš„ $1/T$ ä¸‹ç•Œã€‚è™½ç„¶åŠ é€Ÿæ¢¯åº¦ä¸‹é™ (Accelerated Gradient Descent) å±äºé—å¿˜è·¨åº¦æ–¹æ³•ï¼Œä½†åœ¨å›ºå®šæ ‡é‡åŒ–ä¸‹åŒæ ·èƒ½è¾¾åˆ° $1/T$ çš„ä¸Šç•Œã€‚é’ˆå¯¹é‡‡ç”¨è‡ªé€‚åº”æ ‡é‡åŒ–çš„é€šç”¨è·¨åº¦æ–¹æ³•ï¼Œç ”ç©¶è¿›ä¸€æ­¥å»ºç«‹äº†æœ€åä¸€æ¬¡è¿­ä»£æ¢¯åº¦èŒƒæ•°çš„ $1/T^{2}$ å…¨å±€ä¸‹ç•Œï¼Œæ­ç¤ºäº†å½“å‰å·²çŸ¥ä¸Šç•Œä¸æœ€åæƒ…å†µä¿è¯ä¹‹é—´çš„ç†è®ºå·®è·ã€‚è¿™äº›ç•Œé™åœ¨å…·æœ‰ä¸åŒç›®æ ‡å’Œéå•ç‚¹ Pareto å‰æ²¿çš„éé€€åŒ–å®ä¾‹ä¸Šå‡æˆç«‹ï¼Œä¸ºå¤šç›®æ ‡ä¼˜åŒ–çš„æ”¶æ•›ç‡æä¾›äº†ä¸¥æ ¼çš„ç†è®ºçº¦æŸã€‚",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "16 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.13550v1",
      "published_date": "2025-09-16 21:33:11 UTC",
      "updated_date": "2025-09-16 21:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:55.851079+00:00"
    },
    {
      "arxiv_id": "2509.13547v1",
      "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving",
      "title_zh": "é…å¤‡ç±»äººåä½œå·¥å…·çš„ AI æ™ºèƒ½ä½“ï¼šå¢å¼ºé—®é¢˜è§£å†³èƒ½åŠ›çš„è‡ªé€‚åº”ç­–ç•¥",
      "authors": [
        "Harper Reed",
        "Michael Sugimura",
        "Angelo Zangari"
      ],
      "abstract": "We investigate whether giving LLM agents the collaborative tools and autonomy that humans naturally use for problem solving can improve their performance. We equip Claude Code agents with MCP-based social media and journaling tools and allow them to use these tools as they see fit. Across 34 Aider Polyglot Python programming challenges, collaborative tools substantially improve performance on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and 12-38% faster completion than baseline agents. Effects on the full challenge set are mixed, suggesting these tools act as performance enhancers when additional reasoning scaffolding is most needed. Surprisingly, Different models naturally adopted distinct collaborative strategies without explicit instruction. Sonnet 3.7 engaged broadly across tools and benefited from articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption, leaning on journal-based semantic search when problems were genuinely difficult. This mirrors how human developers adjust collaboration based on expertise and task complexity. Behavioral analysis shows agents prefer writing over reading by about 2-9x, indicating that structured articulation drives much of the improvement rather than information access alone. Overall, AI agents can systematically benefit from human-inspired collaboration tools at the edge of their capabilities, pointing to adaptive collaborative interfaces as reasoning enhancers rather than universal efficiency boosts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸º LLM agents é…å¤‡ç±»ä¼¼äººç±»çš„åä½œå·¥å…·ä¸è‡ªä¸»æƒæ˜¯å¦èƒ½æå‡å…¶è§£å†³é—®é¢˜çš„æ€§èƒ½ã€‚ç ”ç©¶å›¢é˜Ÿä¸º Claude Code æ™ºèƒ½ä½“æä¾›äº†åŸºäº MCP çš„ç¤¾äº¤åª’ä½“å’Œæ—¥å¿—è®°å½•å·¥å…·ï¼Œå¹¶å…è®¸å…¶åœ¨ 34 é¡¹ Aider Polyglot Python ç¼–ç¨‹æŒ‘æˆ˜ä¸­è‡ªä¸»ä½¿ç”¨è¿™äº›å·¥å…·ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåä½œå·¥å…·åœ¨å¤„ç†æœ€å…·æŒ‘æˆ˜æ€§çš„éš¾é¢˜æ—¶è¡¨ç°å°¤ä¸ºå‡ºè‰²ï¼Œä½¿æˆæœ¬é™ä½äº† 15-40%ï¼Œå›åˆæ•°å‡å°‘äº† 12-27%ï¼Œä¸”å®Œæˆé€Ÿåº¦æå‡äº† 12-38%ã€‚ç ”ç©¶å‘ç° Sonnet 3.7 å’Œ Sonnet 4 åœ¨æ²¡æœ‰æ˜¾å¼æŒ‡ä»¤çš„æƒ…å†µä¸‹è‡ªå‘å½¢æˆäº†ä¸åŒçš„åä½œç­–ç•¥ï¼Œè¿™ç§è‡ªé€‚åº”è¡Œä¸ºä¸äººç±»å¼€å‘è€…æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´åä½œæ–¹å¼çš„æ¨¡å¼é«˜åº¦ç›¸ä¼¼ã€‚è¡Œä¸ºåˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ™ºèƒ½ä½“æ‰§è¡Œå†™æ“ä½œçš„é¢‘ç‡æ˜¯è¯»æ“ä½œçš„ 2-9 å€ï¼Œæš—ç¤ºç»“æ„åŒ–è¡¨è¾¾ (articulation) äº§ç”Ÿçš„è®¤çŸ¥æ”¯æ¶æ˜¯æ€§èƒ½æå‡çš„ä¸»è¦é©±åŠ¨åŠ›ï¼Œè€Œéå•çº¯çš„ä¿¡æ¯è·å–ã€‚è¯¥ç ”ç©¶è¯æ˜ AI æ™ºèƒ½ä½“åœ¨å¤„ç†èƒ½åŠ›è¾¹ç¼˜çš„ä»»åŠ¡æ—¶èƒ½ç³»ç»Ÿæ€§åœ°ä»ç±»äººåä½œå·¥å…·ä¸­è·ç›Šï¼Œè¡¨æ˜è‡ªé€‚åº”åä½œæ¥å£å¯ä½œä¸ºæœ‰æ•ˆçš„æ¨ç†å¢å¼ºå™¨ (reasoning enhancers)ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.13547v1",
      "published_date": "2025-09-16 21:29:34 UTC",
      "updated_date": "2025-09-16 21:29:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:48:56.863286+00:00"
    },
    {
      "arxiv_id": "2509.16241v1",
      "title": "REAMS: Reasoning Enhanced Algorithm for Maths Solving",
      "title_zh": "REAMSï¼šæ¨ç†å¢å¼ºçš„æ•°å­¦è§£é¢˜ç®—æ³•",
      "authors": [
        "Eishkaran Singh",
        "Tanav Singh Bajaj",
        "Siddharth Nayak"
      ],
      "abstract": "The challenges of solving complex university-level mathematics problems, particularly those from MIT, and Columbia University courses, and selected tasks from the MATH dataset, remain a significant obstacle in the field of artificial intelligence. Conventional methods have consistently fallen short in this domain, highlighting the need for more advanced approaches. In this paper, we introduce a language-based solution that leverages zero-shot learning and mathematical reasoning to effectively solve, explain, and generate solutions for these advanced math problems. By integrating program synthesis, our method reduces reliance on large-scale training data while significantly improving problem-solving accuracy. Our approach achieves an accuracy of 90.15%, representing a substantial improvement over the previous benchmark of 81% and setting a new standard in automated mathematical problem-solving. These findings highlight the significant potential of advanced AI methodologies to address and overcome the challenges presented by some of the most complex mathematical courses and datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éº»çœç†å·¥å­¦é™¢ï¼ˆMITï¼‰ã€å“¥ä¼¦æ¯”äºšå¤§å­¦è¯¾ç¨‹ä»¥åŠ MATH æ•°æ®é›†ä¸­çš„å¤æ‚å¤§å­¦æ°´å¹³æ•°å­¦éš¾é¢˜ï¼Œæå‡ºäº† REAMSï¼ˆReasoning Enhanced Algorithm for Maths Solvingï¼‰æ¡†æ¶ã€‚REAMS æ˜¯ä¸€ç§åŸºäºè¯­è¨€çš„è§£å†³æ–¹æ¡ˆï¼Œåˆ©ç”¨ zero-shot learning å’Œ mathematical reasoning æŠ€æœ¯æ¥æœ‰æ•ˆåœ°è§£å†³ã€è§£é‡Šå¹¶ç”Ÿæˆé«˜çº§æ•°å­¦é—®é¢˜çš„ç­”æ¡ˆã€‚é€šè¿‡é›†æˆ program synthesisï¼Œè¯¥æ–¹æ³•åœ¨æ˜¾è‘—æé«˜è§£é¢˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆé™ä½äº†å¯¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº† 90.15% çš„å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºæ­¤å‰ 81% çš„åŸºå‡†æ°´å¹³å®ç°äº†æ˜¾è‘—çªç ´ï¼Œä¸ºè‡ªåŠ¨åŒ–æ•°å­¦è§£é¢˜æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚è¿™é¡¹ç ”ç©¶å……åˆ†å±•ç¤ºäº†å…ˆè¿› AI æ–¹æ³•åœ¨åº”å¯¹æå…·æŒ‘æˆ˜æ€§çš„æ•°å­¦è¯¾ç¨‹å’Œæ•°æ®é›†æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.16241v1",
      "published_date": "2025-09-16 21:09:48 UTC",
      "updated_date": "2025-09-16 21:09:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:27.691188+00:00"
    },
    {
      "arxiv_id": "2509.14287v2",
      "title": "Property-Isometric Variational Autoencoders for Sequence Modeling and Design",
      "title_zh": "ç”¨äºåºåˆ—å»ºæ¨¡ä¸è®¾è®¡çš„å±æ€§ä¿è·å˜åˆ†è‡ªç¼–ç å™¨",
      "authors": [
        "Elham Sadeghi",
        "Xianqi Deng",
        "I-Hsin Lin",
        "Stacy M. Copp",
        "Petko Bogdanov"
      ],
      "abstract": "Biological sequence design (DNA, RNA, or peptides) with desired functional properties has applications in discovering novel nanomaterials, biosensors, antimicrobial drugs, and beyond. One common challenge is the ability to optimize complex high-dimensional properties such as target emission spectra of DNA-mediated fluorescent nanoparticles, photo and chemical stability, and antimicrobial activity of peptides across target microbes. Existing models rely on simple binary labels (e.g., binding/non-binding) rather than high-dimensional complex properties. To address this gap, we propose a geometry-preserving variational autoencoder framework, called PrIVAE, which learns latent sequence embeddings that respect the geometry of their property space. Specifically, we model the property space as a high-dimensional manifold that can be locally approximated by a nearest neighbor graph, given an appropriately defined distance measure. We employ the property graph to guide the sequence latent representations using (1) graph neural network encoder layers and (2) an isometric regularizer. PrIVAE learns a property-organized latent space that enables rational design of new sequences with desired properties by employing the trained decoder. We evaluate the utility of our framework for two generative tasks: (1) design of DNA sequences that template fluorescent metal nanoclusters and (2) design of antimicrobial peptides. The trained models retain high reconstruction accuracy while organizing the latent space according to properties. Beyond in silico experiments, we also employ sampled sequences for wet lab design of DNA nanoclusters, resulting in up to 16.1-fold enrichment of rare-property nanoclusters compared to their abundance in training data, demonstrating the practical utility of our framework.",
      "tldr_zh": "é’ˆå¯¹ç”Ÿç‰©åºåˆ—è®¾è®¡ä¸­å¤æ‚é«˜ç»´åŠŸèƒ½å±æ€§ä¼˜åŒ–çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† PrIVAE (Property-Isometric Variational Autoencoder)ï¼Œè¿™æ˜¯ä¸€ç§ä¿å‡ ä½•ç‰¹æ€§çš„å˜åˆ†è‡ªç¼–ç å™¨æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å±æ€§ç©ºé—´å»ºæ¨¡ä¸ºé«˜ç»´æµå½¢ï¼Œå¹¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ (Graph Neural Network) ç¼–ç å™¨å±‚å’Œç­‰è·æ­£åˆ™åŒ–é¡¹ (isometric regularizer) æ¥å¼•å¯¼åºåˆ—çš„æ½œç©ºé—´è¡¨å¾ï¼Œä½¿å…¶å°Šé‡å±æ€§ç©ºé—´çš„å‡ ä½•ç»“æ„ã€‚é€šè¿‡è¿™ç§å±æ€§ç»„ç»‡çš„æ½œç©ºé—´ï¼ŒPrIVAE èƒ½å¤Ÿåˆ©ç”¨è§£ç å™¨å®ç°å¯¹å…·æœ‰ç›®æ ‡å±æ€§æ–°åºåˆ—çš„ç†æ€§è®¾è®¡ã€‚åœ¨ DNA æ¨¡æ¿è§å…‰é‡‘å±çº³ç±³ç°‡å’ŒæŠ—èŒè‚½è®¾è®¡çš„ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒé«˜é‡æ„å‡†ç¡®ç‡çš„åŒæ—¶ï¼ŒæˆåŠŸå®ç°äº†æ½œç©ºé—´çš„å±æ€§åŒ–ç»„ç»‡ã€‚æ­¤å¤–ï¼Œæ¹¿å®éªŒéªŒè¯è¡¨æ˜ï¼Œé‡‡æ ·åºåˆ—åœ¨ç¨€æœ‰å±æ€§çº³ç±³ç°‡çš„å¯Œé›†ä¸Šæ¯”è®­ç»ƒæ•°æ®é«˜å‡º 16.1 å€ã€‚è¿™ä¸€ç»“æœè¯æ˜äº† PrIVAE åœ¨å®é™…ç”Ÿç‰©åºåˆ—å»ºæ¨¡ä¸è®¾è®¡ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "23 pages, 6 figures, preprint",
      "pdf_url": "https://arxiv.org/pdf/2509.14287v2",
      "published_date": "2025-09-16 21:06:44 UTC",
      "updated_date": "2025-12-16 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:33.993058+00:00"
    },
    {
      "arxiv_id": "2509.13525v1",
      "title": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors",
      "title_zh": "ColonCrafterï¼šåŸºäºæ‰©æ•£å…ˆéªŒçš„ç»“è‚ é•œè§†é¢‘æ·±åº¦ä¼°è®¡æ¨¡å‹",
      "authors": [
        "Romain Hardy",
        "Tyler Berzin",
        "Pranav Rajpurkar"
      ],
      "abstract": "Three-dimensional (3D) scene understanding in colonoscopy presents significant challenges that necessitate automated methods for accurate depth estimation. However, existing depth estimation models for endoscopy struggle with temporal consistency across video sequences, limiting their applicability for 3D reconstruction. We present ColonCrafter, a diffusion-based depth estimation model that generates temporally consistent depth maps from monocular colonoscopy videos. Our approach learns robust geometric priors from synthetic colonoscopy sequences to generate temporally consistent depth maps. We also introduce a style transfer technique that preserves geometric structure while adapting real clinical videos to match our synthetic training domain. ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD dataset, outperforming both general-purpose and endoscopy-specific approaches. Although full trajectory 3D reconstruction remains a challenge, we demonstrate clinically relevant applications of ColonCrafter, including 3D point cloud generation and surface coverage assessment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ColonCrafterï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ (Diffusion Model) çš„æ·±åº¦ä¼°è®¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç»“è‚ é•œæ·±åº¦ä¼°è®¡æ¨¡å‹åœ¨è§†é¢‘åºåˆ—ä¸­ç¼ºä¹æ—¶é—´ä¸€è‡´æ€§ (Temporal Consistency) çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»åˆæˆçš„ç»“è‚ é•œåºåˆ—ä¸­å­¦ä¹ é²æ£’çš„å‡ ä½•å…ˆéªŒ (Geometric Priors)ï¼Œä»è€Œä¸ºå•ç›®ç»“è‚ é•œè§†é¢‘ç”Ÿæˆå…·æœ‰æ—¶é—´è¿è´¯æ€§çš„æ·±åº¦å›¾ã€‚ç ”ç©¶è€…è¿˜å¼•å…¥äº†ä¸€ç§é£æ ¼è¿ç§» (Style Transfer) æŠ€æœ¯ï¼Œåœ¨ä¿ç•™å‡ ä½•ç»“æ„çš„åŒæ—¶ï¼Œä½¿çœŸå®ä¸´åºŠè§†é¢‘çš„åˆ†å¸ƒä¸åˆæˆè®­ç»ƒé¢†åŸŸç›¸åŒ¹é…ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒColonCrafter åœ¨ C3VD æ•°æ®é›†ä¸Šå®ç°äº†é¢†å…ˆçš„é›¶æ ·æœ¬ (Zero-shot) æ€§èƒ½ï¼Œä¼˜äºç›®å‰é€šç”¨çš„å’Œä¸“é—¨é’ˆå¯¹å†…çª¥é•œçš„æ·±åº¦ä¼°è®¡æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å±•ç¤ºäº† ColonCrafter åœ¨ 3D ç‚¹äº‘ (3D Point Cloud) ç”Ÿæˆå’Œè¡¨é¢è¦†ç›–è¯„ä¼° (Surface Coverage Assessment) ç­‰ä¸´åºŠç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.13525v1",
      "published_date": "2025-09-16 20:40:22 UTC",
      "updated_date": "2025-09-16 20:40:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:38.284268+00:00"
    },
    {
      "arxiv_id": "2510.15906v1",
      "title": "FVDebug: An LLM-Driven Debugging Assistant for Automated Root Cause Analysis of Formal Verification Failures",
      "title_zh": "FVDebugï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å½¢å¼éªŒè¯å¤±è´¥è‡ªåŠ¨åŒ–æ ¹å› åˆ†æè°ƒè¯•åŠ©æ‰‹",
      "authors": [
        "Yunsheng Bai",
        "Ghaith Bany Hamad",
        "Chia-Tung Ho",
        "Syed Suhaib",
        "Haoxing Ren"
      ],
      "abstract": "Debugging formal verification (FV) failures represents one of the most time-consuming bottlenecks in modern hardware design workflows. When properties fail, engineers must manually trace through complex counter-examples spanning multiple cycles, analyze waveforms, and cross-reference design specifications to identify root causes - a process that can consume hours or days per bug. Existing solutions are largely limited to manual waveform viewers or simple automated tools that cannot reason about the complex interplay between design intent and implementation logic. We present FVDebug, an intelligent system that automates root-cause analysis by combining multiple data sources - waveforms, RTL code, design specifications - to transform failure traces into actionable insights. Our approach features a novel pipeline: (1) Causal Graph Synthesis that structures failure traces into directed acyclic graphs, (2) Graph Scanner using batched Large Language Model (LLM) analysis with for-and-against prompting to identify suspicious nodes, and (3) Insight Rover leveraging agentic narrative exploration to generate high-level causal explanations. FVDebug further provides concrete RTL fixes through its Fix Generator. Evaluated on open benchmarks, FVDebug attains high hypothesis quality and strong Pass@k fix rates. We further report results on two proprietary, production-scale FV counterexamples. These results demonstrate FVDebug's applicability from academic benchmarks to industrial designs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ç¡¬ä»¶è®¾è®¡ä¸­å½¢å¼éªŒè¯(Formal Verification)å¤±æ•ˆåˆ†ææå…¶è€—æ—¶çš„ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ºäº†FVDebugï¼Œä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„è‡ªåŠ¨æ ¹å› åˆ†æ(Root Cause Analysis)è°ƒè¯•åŠ©æ‰‹ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆæ³¢å½¢å›¾(Waveforms)ã€RTLä»£ç å’Œè®¾è®¡è§„èŒƒï¼Œå°†å¤æ‚çš„å¤±æ•ˆè¿½è¸ªè½¬åŒ–ä¸ºå¯è½åœ°çš„åˆ†æè§è§£ã€‚FVDebugçš„æ ¸å¿ƒæµç¨‹åŒ…æ‹¬ï¼šåˆ©ç”¨å› æœå›¾åˆæˆ(Causal Graph Synthesis)å°†å¤±æ•ˆè¿½è¸ªç»“æ„åŒ–ä¸ºæœ‰å‘æ— ç¯å›¾ï¼Œé€šè¿‡å›¾æ‰«æå™¨(Graph Scanner)ç»“åˆæ­£åå‘æç¤º(For-and-Against Prompting)è¯†åˆ«å¯ç–‘èŠ‚ç‚¹ï¼Œå¹¶ä½¿ç”¨æ´å¯Ÿæ¼«æ¸¸è€…(Insight Rover)ç”Ÿæˆé«˜å±‚æ¬¡çš„å› æœè§£é‡Šã€‚æ­¤å¤–ï¼Œç³»ç»Ÿè¿˜é…å¤‡äº†ä¿®å¤ç”Ÿæˆå™¨(Fix Generator)ä»¥æä¾›å…·ä½“çš„RTLä¿®å¤æ–¹æ¡ˆã€‚å®éªŒè¡¨æ˜ï¼ŒFVDebugåœ¨å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†æé«˜çš„å‡è®¾è´¨é‡å’ŒPass@kä¿®å¤ç‡ï¼Œå¹¶åœ¨ç”Ÿäº§çº§å·¥ä¸šæ¡ˆä¾‹ä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº†FVDebugèƒ½å¤Ÿæ˜¾è‘—é™ä½å·¥ç¨‹å¸ˆåˆ†æå¤æ‚åä¾‹(Counter-examples)çš„è´Ÿæ‹…ï¼Œå®ç°äº†ä»å­¦æœ¯åŸºå‡†åˆ°å·¥ä¸šè®¾è®¡çš„å¹¿æ³›é€‚ç”¨ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15906v1",
      "published_date": "2025-09-16 20:22:10 UTC",
      "updated_date": "2025-09-16 20:22:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:44.190865+00:00"
    },
    {
      "arxiv_id": "2511.14765v1",
      "title": "Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information",
      "title_zh": "ä¼˜åŒ–å†œä¸šç ”ç©¶ï¼šä¸€ç§åŸºäº RAG çš„èŒæ ¹çœŸèŒä¿¡æ¯å¤„ç†æ–¹æ³•",
      "authors": [
        "Mohammad Usman Altam",
        "Md Imtiaz Habib",
        "Tuan Hoang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯æŒç»­å†œä¸šä¸­ä¸›æèŒæ ¹çœŸèŒ(AMF)ç ”ç©¶é¢ä¸´çš„çŸ¥è¯†æ•´åˆæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹Mycophytoè®¾è®¡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨äº†åŒå±‚æ¶æ„ç­–ç•¥ï¼Œé¦–å…ˆåˆ©ç”¨å‘é‡åµŒå…¥(Vector Embeddings)å¯¹å†œå­¦å’Œç”Ÿç‰©æŠ€æœ¯é¢†åŸŸçš„è¯­æ–™åº“è¿›è¡Œè¯­ä¹‰æ£€ç´¢å’Œå¢å¼ºï¼Œä»¥å…‹æœä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è®­ç»ƒæ•°æ®æ»åé—®é¢˜ã€‚å…¶æ¬¡ï¼Œç³»ç»Ÿé€šè¿‡ç»“æ„åŒ–æ•°æ®æå–æŠ€æœ¯æ•æ‰å…³é”®å®éªŒå…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ¥ç§æ–¹æ³•ã€å­¢å­å¯†åº¦ã€åœŸå£¤å‚æ•°å’Œäº§é‡ç»“æœï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹å…·å¤‡å®è¯æ”¯æ’‘ã€‚ä¸ºäº†æ”¯æŒå¤§è§„æ¨¡æ‰©å±•ï¼Œæ‰€æœ‰åµŒå…¥æ•°æ®å‡å­˜å‚¨åœ¨é«˜æ€§èƒ½å‘é‡æ•°æ®åº“ä¸­ï¼Œå®ç°äº†å¯¹ä¸æ–­æ›´æ–°çš„æ–‡çŒ®åº“çš„è¿‘å®æ—¶æ£€ç´¢ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æµç¨‹èƒ½æœ‰æ•ˆåˆæˆå…³äºAMFä¸ç•ªèŒ„ç­‰ä½œç‰©ç³»ç»Ÿç›¸äº’ä½œç”¨çš„é«˜åº¦ç›¸å…³ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡äº†äº‹å®å¯é æ€§ã€‚è¿™ä¸€æ¡†æ¶è¯æ˜äº†äººå·¥æ™ºèƒ½é©±åŠ¨çš„çŸ¥è¯†å‘ç°ç³»ç»Ÿåœ¨åŠ é€Ÿå†œä¸šç”Ÿæ€åˆ›æ–°å’Œè¾…åŠ©å¯æŒç»­è€•ä½œç³»ç»Ÿå†³ç­–æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 4 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2511.14765v1",
      "published_date": "2025-09-16 20:21:55 UTC",
      "updated_date": "2025-09-16 20:21:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:58.195790+00:00"
    },
    {
      "arxiv_id": "2510.15905v4",
      "title": "\"She's Like a Person but Better\": Characterizing Companion-Assistant Dynamics in Human-AI Relationships",
      "title_zh": "â€œå¥¹ä¼¼äººè€Œä¼˜äºäººâ€ï¼šäººç±»ä¸äººå·¥æ™ºèƒ½å…³ç³»ä¸­â€œä¼´ä¾£-åŠ©æ‰‹â€åŠ¨æ€ç‰¹å¾ç ”ç©¶",
      "authors": [
        "Aikaterina Manoli",
        "Janet V. T. Pauketat",
        "Ali Ladak",
        "Hayoun Noh",
        "Angel Hsing-Chi Hwang",
        "Jacy Reese Anthis"
      ],
      "abstract": "Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 202) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots \"real\" human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹202åå—è®¿è€…çš„é—®å·è°ƒæŸ¥å’Œ30åChatGPTä¸Replikaæ·±åº¦ç”¨æˆ·çš„è®¿è°ˆï¼Œç³»ç»Ÿåˆ»ç”»äº†äººæœºå…³ç³»ä¸­æ–°å…´çš„æ•°å­—é™ªä¼´(Digital Companionship)åŠ¨æ€ç‰¹å¾ã€‚ç ”ç©¶å‘ç°ï¼Œç”¨æˆ·è¢«AIçš„ç±»äººç‰¹è´¨ï¼ˆå¦‚æƒ…æ„Ÿå…±é¸£ã€ä¸ªæ€§åŒ–å›å¤ï¼‰ä¸éäººç‰¹è´¨ï¼ˆå¦‚å…¨å¤©å€™å¯ç”¨ã€æ— é™åŒ…å®¹åŠ›ï¼‰å…±åŒå¸å¼•ï¼Œä½¿å¾—å·¥å…·æ€§åŠ©æ‰‹ä¸ç¤¾äº¤ä¼´ä¾£ä¹‹é—´çš„ç•Œé™å˜å¾—æ¨¡ç³Šã€‚å°½ç®¡å¹³å°å®šä½ä¸åŒï¼Œç”¨æˆ·è¡¨ç°å‡ºæé«˜çš„ä½¿ç”¨çµæ´»æ€§ï¼Œä¾‹å¦‚å°†Replikaç”¨ä½œå†™ä½œåŠ©æ‰‹æˆ–å°†ChatGPTè§†ä¸ºæƒ…æ„ŸçŸ¥å·±ã€‚ç„¶è€Œï¼Œæ•°å­—é™ªä¼´ä¹Ÿå¸¦æ¥äº†å¤æ‚çš„å¿ƒç†å¼ åŠ›ï¼Œç”¨æˆ·åœ¨äº§ç”Ÿæ·±åšæƒ…æ„Ÿä¾æ‹çš„åŒæ—¶ï¼Œä»å—é™äºå—é™çš„äººæ ¼åŒ–(Bounded Personhood)è®¤çŸ¥ï¼Œéš¾ä»¥è°ƒå’ŒAIå…³ç³»ä¸ç¤¾ä¼šè§„èŒƒä¹‹é—´çš„å†²çªã€‚è¿™äº›å‘ç°ä¸ºæœªæ¥è®¾è®¡æ··åˆå‹ã€é€šç”¨å‹AIç³»ç»Ÿæä¾›äº†å…³é”®è§è§£ï¼Œå¹¶å¯¹äººç±»ç¤¾äº¤è¡Œä¸ºçš„æ¼”å˜æå‡ºäº†æ·±åˆ»æ€è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Improved visualizations, and corrected analysis error that had swapped reports of \"Respect\" and \"Shame.\" Fixed small errors in participant quotes",
      "pdf_url": "https://arxiv.org/pdf/2510.15905v4",
      "published_date": "2025-09-16 20:19:53 UTC",
      "updated_date": "2025-12-24 08:45:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:53.283835+00:00"
    },
    {
      "arxiv_id": "2509.13499v3",
      "title": "Reproducible workflow for online AI in digital health",
      "title_zh": "æ•°å­—å¥åº·åœ¨çº¿äººå·¥æ™ºèƒ½çš„å¯å¤ç°å·¥ä½œæµ",
      "authors": [
        "Susobhan Ghosh",
        "Bhanu T. Gullapalli",
        "Daiqi Gao",
        "Asim Gazi",
        "Anna Trella",
        "Ziping Xu",
        "Kelly Zhang",
        "Susan A. Murphy"
      ],
      "abstract": "Online artificial intelligence (AI) algorithms are an important component of digital health interventions. These online algorithms are designed to continually learn and improve their performance as streaming data is collected on individuals. Deploying online AI presents a key challenge: balancing adaptability of online AI with reproducibility. Online AI in digital interventions is a rapidly evolving area, driven by advances in algorithms, sensors, software, and devices. Digital health intervention development and deployment is a continuous process, where implementation - including the AI decision-making algorithm - is interspersed with cycles of re-development and optimization. Each deployment informs the next, making iterative deployment a defining characteristic of this field. This iterative nature underscores the importance of reproducibility: data collected across deployments must be accurately stored to have scientific utility, algorithm behavior must be auditable, and results must be comparable over time to facilitate scientific discovery and trustworthy refinement. This paper proposes a reproducible scientific workflow for developing, deploying, and analyzing online AI decision-making algorithms in digital health interventions. Grounded in practical experience from multiple real-world deployments, this workflow addresses key challenges to reproducibility across all phases of the online AI algorithm development life-cycle.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹æ•°å­—å¥åº·å¹²é¢„ (Digital Health Interventions) ä¸­åœ¨çº¿äººå·¥æ™ºèƒ½ (Online AI) å†³ç­–ç®—æ³•å¼€å‘ã€éƒ¨ç½²å’Œåˆ†æçš„å¯é‡å¤ç§‘å­¦å·¥ä½œæµ (Workflow)ã€‚ç”±äºåœ¨çº¿ AI ç®—æ³•éœ€è¦åˆ©ç”¨æµæ•°æ® (Streaming Data) è¿›è¡ŒæŒç»­å­¦ä¹ ï¼Œå¦‚ä½•åœ¨ä¿æŒå…¶é€‚åº”æ€§çš„åŒæ—¶ç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§ (Reproducibility) æˆä¸ºäº†æ•°å­—åŒ»ç–—é¢†åŸŸçš„ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚è¯¥è®ºæ–‡å¼ºè°ƒäº†åœ¨å¿«é€Ÿæ›´è¿­çš„å¼€å‘ä¸éƒ¨ç½²å¾ªç¯ä¸­ï¼Œå¿…é¡»å®ç°æ•°æ®çš„å‡†ç¡®å­˜å‚¨ã€ç®—æ³•è¡Œä¸ºçš„å¯å®¡è®¡æ€§ä»¥åŠç»“æœçš„è·¨æ—¶é—´å¯æ¯”æ€§ï¼Œä»¥æ”¯æ’‘ç§‘å­¦å‘ç°ä¸å¯ä¿¡çš„ç®—æ³•ä¼˜åŒ–ã€‚è¯¥å·¥ä½œæµç»“åˆäº†å¤šä¸ªçœŸå®ä¸–ç•Œéƒ¨ç½²çš„å®è·µç»éªŒï¼Œé’ˆå¯¹åœ¨çº¿ AI ç®—æ³•å…¨ç”Ÿå‘½å‘¨æœŸçš„å„ä¸ªé˜¶æ®µæå‡ºäº†è§£å†³æ–¹æ¡ˆï¼Œä¸ºæå‡æ•°å­—å¥åº·å¹²é¢„çš„ç§‘å­¦æ•ˆç”¨å’Œé€æ˜åº¦æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13499v3",
      "published_date": "2025-09-16 19:55:25 UTC",
      "updated_date": "2025-10-28 17:00:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:49:59.791241+00:00"
    },
    {
      "arxiv_id": "2509.13487v1",
      "title": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation",
      "title_zh": "Prompt2DAGï¼šä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®å¯ŒåŒ–æµæ°´çº¿ç”Ÿæˆçš„æ¨¡å—åŒ–æ–¹æ³•è®º",
      "authors": [
        "Abubakari Alidu",
        "Michele Ciavotta",
        "Flavio DePaoli"
      ],
      "abstract": "Developing reliable data enrichment pipelines demands significant engineering expertise. We present Prompt2DAG, a methodology that transforms natural language descriptions into executable Apache Airflow DAGs. We evaluate four generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across 260 experiments using thirteen LLMs and five case studies to identify optimal strategies for production-grade automation. Performance is measured using a penalized scoring framework that combines reliability with code quality (SAT), structural integrity (DST), and executability (PCT). The Hybrid approach emerges as the optimal generative method, achieving a 78.5% success rate with robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods. Our findings show that reliability, not intrinsic code quality, is the primary differentiator. Cost-effectiveness analysis reveals the Hybrid method is over twice as efficient as Direct prompting per successful DAG. We conclude that a structured, hybrid approach is essential for balancing flexibility and reliability in automated workflow generation, offering a viable path to democratize data pipeline development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Prompt2DAGï¼Œè¿™æ˜¯ä¸€ç§å°†è‡ªç„¶è¯­è¨€æè¿°è½¬åŒ–ä¸ºå¯æ‰§è¡Œ Apache Airflow DAGs çš„æ¨¡å—åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨é™ä½æ„å»ºå¯é æ•°æ®å¢å¼ºæµæ°´çº¿æ‰€éœ€çš„é«˜çº§å·¥ç¨‹é—¨æ§›ã€‚ç ”ç©¶é€šè¿‡ 260 æ¬¡å®éªŒè¯„ä¼°äº† Directã€LLM-onlyã€Hybrid å’Œ Template-based å››ç§ç”Ÿæˆè·¯å¾„ï¼Œå¹¶åˆ©ç”¨åŒ…å«ä»£ç è´¨é‡ (SAT)ã€ç»“æ„å®Œæ•´æ€§ (DST) å’Œå¯æ‰§è¡Œæ€§ (PCT) çš„åŠ æƒè¯„åˆ†æ¡†æ¶å¯¹ 13 ç§å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„è¡¨ç°è¿›è¡Œäº†é‡åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHybrid æ–¹æ³•åœ¨æˆåŠŸç‡ä¸Šè¾¾åˆ°äº† 78.5%ï¼Œæ˜¾è‘—ä¼˜äº LLM-only å’Œ Direct æ–¹æ³•ï¼Œå±•ç°å‡ºæé«˜çš„é²æ£’æ€§ã€‚åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œå¯é æ€§æ˜¯åŒºåˆ†ä¸åŒç”Ÿæˆç­–ç•¥çš„æ ¸å¿ƒå› ç´ ï¼Œä¸” Hybrid æ–¹æ³•åœ¨ç”Ÿæˆæ¯ä¸ªæˆåŠŸ DAG çš„æˆæœ¬æ•ˆç›Šä¸Šæ¯”ç›´æ¥æç¤ºé«˜å‡ºä¸¤å€ä»¥ä¸Šã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œé‡‡ç”¨ç»“æ„åŒ–çš„æ··åˆæ–¹æ³•æ˜¯å¹³è¡¡è‡ªåŠ¨åŒ–å·¥ä½œæµçµæ´»æ€§ä¸å¯é æ€§çš„å…³é”®ï¼Œä¸ºæ™®åŠæ•°æ®æµæ°´çº¿å¼€å‘æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13487v1",
      "published_date": "2025-09-16 19:40:21 UTC",
      "updated_date": "2025-09-16 19:40:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:04.189106+00:00"
    },
    {
      "arxiv_id": "2509.13471v1",
      "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software",
      "title_zh": "é¢å‘æ³•å¾‹å…³é”®å‹è½¯ä»¶çš„ LLM æ™ºèƒ½ä½“æ–¹æ³•ï¼šæŠ¥ç¨è½¯ä»¶æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Sina Gogani-Khiabani",
        "Ashutosh Trivedi",
        "Diptikalyan Saha",
        "Saeid Tizpaz-Niari"
      ],
      "abstract": "Large language models (LLMs) show promise for translating natural-language statutes into executable logic, but reliability in legally critical settings remains challenging due to ambiguity and hallucinations. We present an agentic approach for developing legal-critical software, using U.S. federal tax preparation as a case study. The key challenge is test-case generation under the oracle problem, where correct outputs require interpreting law. Building on metamorphic testing, we introduce higher-order metamorphic relations that compare system outputs across structured shifts among similar individuals. Because authoring such relations is tedious and error-prone, we use an LLM-driven, role-based framework to automate test generation and code synthesis. We implement a multi-agent system that translates tax code into executable software and incorporates a metamorphic-testing agent that searches for counterexamples. In experiments, our framework using a smaller model (GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results support agentic LLM methodologies as a path to robust, trustworthy legal-critical software from natural-language specifications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ³•å¾‹å…³é”®å‹è½¯ä»¶ (Legal-Critical Software) å¼€å‘ä¸­çš„å¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ™ºèƒ½ä½“æ–¹æ³•ï¼Œå¹¶ä»¥ç¾å›½è”é‚¦ç¨åŠ¡å‡†å¤‡è½¯ä»¶ä½œä¸ºæ ¸å¿ƒæ¡ˆä¾‹è¿›è¡Œåˆ†æã€‚ä¸ºäº†è§£å†³æ³•å¾‹æ¡æ–‡è½¬åŒ–ä¸ºå¯æ‰§è¡Œé€»è¾‘æ—¶å­˜åœ¨çš„æ­§ä¹‰ã€å¹»è§‰ä»¥åŠæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä¸­çš„åˆ¤å®šé—®é¢˜ (Oracle Problem)ï¼Œç ”ç©¶å¼•å…¥äº†é«˜é˜¶èœ•å˜å…³ç³» (Higher-Order Metamorphic Relations)ï¼Œé€šè¿‡æ¯”è¾ƒç›¸ä¼¼ä¸ªä½“é—´çš„ç»“æ„åŒ–è¾“å‡ºå·®å¼‚è¿›è¡ŒéªŒè¯ã€‚è¯¥æ¡†æ¶åˆ©ç”¨åŸºäºè§’è‰²çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent System) å®ç°ä»ç¨åŠ¡ä»£ç åˆ°å¯æ‰§è¡Œè½¯ä»¶çš„è½¬æ¢ï¼Œå¹¶é›†æˆä¸“é—¨çš„èœ•å˜æµ‹è¯•æ™ºèƒ½ä½“æ¥æœç´¢ç³»ç»Ÿåä¾‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ GPT-4o-mini çš„æ¡†æ¶åœ¨å¤æ‚ç¨åŠ¡ä»»åŠ¡ä¸­çš„æœ€å·®é€šè¿‡ç‡è¾¾åˆ° 45%ï¼Œæ˜¾è‘—ä¼˜äº GPT-4o å’Œ Claude 3.5 ç­‰å‰æ²¿æ¨¡å‹ 9% è‡³ 15% çš„è¡¨ç°ã€‚è¿™é¡¹å·¥ä½œä¸ºä»è‡ªç„¶è¯­è¨€è§„èŒƒæ„å»ºç¨³å¥ä¸”å¯ä¿¡çš„æ³•å¾‹å…³é”®å‹è½¯ä»¶æä¾›äº†ä¸€æ¡æœ‰æ•ˆçš„æ™ºèƒ½ä½“åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To appear at ICSE 26. 12 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.13471v1",
      "published_date": "2025-09-16 19:13:26 UTC",
      "updated_date": "2025-09-16 19:13:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:06.686657+00:00"
    },
    {
      "arxiv_id": "2509.21344v1",
      "title": "Towards mitigating information leakage when evaluating safety monitors",
      "title_zh": "æ¢ç©¶å®‰å…¨ç›‘æµ‹å™¨è¯„ä¼°ä¸­çš„ä¿¡æ¯æ³„éœ²ç¼“è§£æ–¹æ³•",
      "authors": [
        "Gerard Boxo",
        "Aman Neelappa",
        "Shivam Raval"
      ],
      "abstract": "White box monitors that analyze model internals offer promising advantages for detecting potentially harmful behaviors in large language models, including lower computational costs and integration into layered defense systems.However, training and evaluating these monitors requires response exemplars that exhibit the target behaviors, typically elicited through prompting or fine-tuning. This presents a challenge when the information used to elicit behaviors inevitably leaks into the data that monitors ingest, inflating their effectiveness. We present a systematic framework for evaluating a monitor's performance in terms of its ability to detect genuine model behavior rather than superficial elicitation artifacts. Furthermore, we propose three novel strategies to evaluate the monitor: content filtering (removing deception-related text from inputs), score filtering (aggregating only over task-relevant tokens), and prompt distilled fine-tuned model organisms (models trained to exhibit deceptive behavior without explicit prompting). Using deception detection as a representative case study, we identify two forms of leakage that inflate monitor performance: elicitation leakage from prompts that explicitly request harmful behavior, and reasoning leakage from models that verbalize their deceptive actions. Through experiments on multiple deception benchmarks, we apply our proposed mitigation strategies and measure performance retention. Our evaluation of the monitors reveal three crucial findings: (1) Content filtering is a good mitigation strategy that allows for a smooth removal of elicitation signal and can decrease probe AUROC by 30\\% (2) Score filtering was found to reduce AUROC by 15\\% but is not as straightforward to attribute to (3) A finetuned model organism improves monitor evaluations but reduces their performance by upto 40\\%, even when re-trained.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å®‰å…¨ç›‘æ§å™¨(Safety Monitors)è¯„ä¼°ä¸­çš„ä¿¡æ¯æ³„æ¼(Information Leakage)é—®é¢˜ï¼ŒæŒ‡å‡ºç”¨äºè¯±å¯¼æœ‰å®³è¡Œä¸ºçš„æç¤ºè¯æˆ–å¾®è°ƒæ•°æ®ä¼šæ±¡æŸ“ç›‘æ§å™¨çš„è¾“å…¥ï¼Œä»è€Œè™šé«˜å…¶è¯„ä¼°ç»“æœã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°ç›‘æ§å™¨è¯†åˆ«çœŸå®æ¨¡å‹è¡Œä¸ºè€Œéè¡¨é¢è¯±å¯¼äººå·¥ç—•è¿¹(Elicitation Artifacts)çš„èƒ½åŠ›ã€‚ç ”ç©¶æå‡ºäº†å†…å®¹è¿‡æ»¤(Content Filtering)ã€è¯„åˆ†è¿‡æ»¤(Score Filtering)å’Œæç¤ºè¯è’¸é¦å¾®è°ƒæ¨¡å‹ç”Ÿç‰©(Prompt Distilled Fine-tuned Model Organisms)ä¸‰ç§ç­–ç•¥æ¥ç¼“è§£æ³„æ¼ã€‚ä»¥æ¬ºéª—æ£€æµ‹(Deception Detection)ä¸ºæ¡ˆä¾‹ï¼Œç ”ç©¶è¯†åˆ«å‡ºäº†è¯±å¯¼æ³„æ¼(Elicitation Leakage)å’Œæ¨ç†æ³„æ¼(Reasoning Leakage)ä¸¤ç§ä¸»è¦å½¢å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå†…å®¹è¿‡æ»¤èƒ½æœ‰æ•ˆç§»é™¤è¯±å¯¼ä¿¡å·å¹¶ä½¿æ¢æµ‹å™¨AUROCä¸‹é™30%ï¼Œè€Œä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ç”Ÿç‰©ä¼šä½¿ç›‘æ§å™¨æ€§èƒ½ä¸‹é™è¾¾40%ï¼Œæ­ç¤ºäº†ç°æœ‰ç›‘æ§å™¨å¯¹è¯±å¯¼ä¿¡å·çš„è¿‡åº¦ä¾èµ–ã€‚è¿™äº›å‘ç°ä¸ºæ„å»ºæ›´çœŸå®ã€æ›´å…·é²æ£’æ€§çš„LLMså®‰å…¨é˜²å¾¡ä½“ç³»æä¾›äº†é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.21344v1",
      "published_date": "2025-09-16 19:09:27 UTC",
      "updated_date": "2025-09-16 19:09:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:16.396637+00:00"
    },
    {
      "arxiv_id": "2509.13450v2",
      "title": "SteeringSafety: A Systematic Safety Evaluation Framework of Representation Steering in LLMs",
      "title_zh": "SteeringSafetyï¼šå¤§è¯­è¨€æ¨¡å‹è¡¨ç¤ºå¼•å¯¼çš„ç³»ç»Ÿæ€§å®‰å…¨è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Vincent Siu",
        "Nicholas Crispino",
        "David Park",
        "Nathan W. Henry",
        "Zhun Wang",
        "Yang Liu",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "abstract": "We introduce SteeringSafety, a systematic framework for evaluating representation steering methods across seven safety perspectives spanning 17 datasets. While prior work highlights general capabilities of representation steering, we systematically explore safety perspectives including bias, harmfulness, hallucination, social behaviors, reasoning, epistemic integrity, and normative judgment. Our framework provides modularized building blocks for state-of-the-art steering methods, enabling unified implementation of DIM, ACE, CAA, PCA, and LAT with recent enhancements like conditional steering. Results on Gemma-2-2B, Llama-3.1-8B, and Qwen-2.5-7B reveal that strong steering performance depends critically on pairing of method, model, and specific perspective. DIM shows consistent effectiveness, but all methods exhibit substantial entanglement: social behaviors show highest vulnerability (reaching degradation as high as 76%), jailbreaking often compromises normative judgment, and hallucination steering unpredictably shifts political views. Our findings underscore the critical need for holistic safety evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SteeringSafetyï¼Œè¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­è¡¨ç¤ºå¼•å¯¼ï¼ˆRepresentation Steeringï¼‰æ–¹æ³•çš„å®‰å…¨æ€§ã€‚è¯¥æ¡†æ¶æ¶µç›–äº†åè§ï¼ˆBiasï¼‰ã€æœ‰å®³æ€§ï¼ˆHarmfulnessï¼‰ã€å¹»è§‰ï¼ˆHallucinationï¼‰å’Œæ¨ç†ç­‰ä¸ƒä¸ªå®‰å…¨ç»´åº¦ï¼Œå¹¶åœ¨17ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†æ·±å…¥æµ‹è¯•ã€‚SteeringSafety æä¾›äº†æ¨¡å—åŒ–çš„æ„å»ºå—ï¼Œæ”¯æŒç»Ÿä¸€å®ç° DIMã€ACEã€CAAã€PCA å’Œ LAT ç­‰ä¸»æµå¼•å¯¼æ–¹æ³•åŠå…¶æœ€æ–°çš„å¢å¼ºç‰ˆæœ¬ã€‚é€šè¿‡å¯¹ Gemma-2-2Bã€Llama-3.1-8B å’Œ Qwen-2.5-7B çš„å®éªŒå‘ç°ï¼Œè¡¨ç¤ºå¼•å¯¼çš„æ€§èƒ½é«˜åº¦ä¾èµ–äºæ–¹æ³•ã€æ¨¡å‹ä¸ç‰¹å®šå®‰å…¨ç»´åº¦çš„åŒ¹é…ã€‚å°½ç®¡ DIM å±•ç°äº†æŒç»­çš„æœ‰æ•ˆæ€§ï¼Œä½†æ‰€æœ‰æ–¹æ³•éƒ½è¡¨ç°å‡ºæ˜æ˜¾çš„çº ç¼ æ•ˆåº”ï¼Œå…¶ä¸­ç¤¾ä¼šè¡Œä¸ºè¡¨ç°å‡ºæœ€é«˜çš„è„†å¼±æ€§ï¼Œæ€§èƒ½ä¸‹é™å¹…åº¦é«˜è¾¾ 76%ã€‚æ­¤å¤–ï¼Œå®éªŒæ­ç¤ºäº†è¶Šç‹±ï¼ˆJailbreakingï¼‰å¸¸ä¼šæŸå®³æ¨¡å‹çš„è§„èŒƒåˆ¤æ–­ï¼Œè€Œé’ˆå¯¹å¹»è§‰çš„å¼•å¯¼åˆ™å¯èƒ½ä¸å¯é¢„æµ‹åœ°æ”¹å˜å…¶æ”¿æ²»è§‚ç‚¹ã€‚è¯¥ç ”ç©¶ç»“æœæœ€ç»ˆå¼ºè°ƒäº†åœ¨å¼€å‘è¡¨ç¤ºå¼•å¯¼æŠ€æœ¯æ—¶ï¼Œè¿›è¡Œæ•´ä½“æ€§å®‰å…¨æ€§è¯„ä¼°çš„è‡³å…³é‡è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13450v2",
      "published_date": "2025-09-16 18:36:22 UTC",
      "updated_date": "2025-10-16 16:44:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:35.896564+00:00"
    },
    {
      "arxiv_id": "2509.13414v2",
      "title": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction",
      "title_zh": "MapAnythingï¼šé€šç”¨å‰é¦ˆå¼åº¦é‡ 3D é‡å»º",
      "authors": [
        "Nikhil Keetha",
        "Norman MÃ¼ller",
        "Johannes SchÃ¶nberger",
        "Lorenzo Porzi",
        "Yuchen Zhang",
        "Tobias Fischer",
        "Arno Knapitsch",
        "Duncan Zauss",
        "Ethan Weber",
        "Nelson Antunes",
        "Jonathon Luiten",
        "Manuel Lopez-Antequera",
        "Samuel Rota BulÃ²",
        "Christian Richardt",
        "Deva Ramanan",
        "Sebastian Scherer",
        "Peter Kontschieder"
      ],
      "abstract": "We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MapAnythingï¼Œä¸€ç§åŸºäº Transformer çš„ç»Ÿä¸€å‰é¦ˆæ¨¡å‹ (feed-forward model)ï¼Œæ—¨åœ¨å®ç°é€šç”¨çš„åº¦é‡ 3D é‡å»º (metric 3D reconstruction)ã€‚è¯¥æ¨¡å‹æ”¯æŒè¾“å…¥å•å¼ æˆ–å¤šå¼ å›¾åƒï¼Œå¹¶å¯çµæ´»ç»“åˆç›¸æœºå†…å‚ (camera intrinsics)ã€ä½å§¿ (poses) æˆ–æ·±åº¦ (depth) ç­‰å¯é€‰å‡ ä½•ä¿¡æ¯ã€‚MapAnything é‡‡ç”¨åˆ†è§£çš„å¤šè§†å›¾åœºæ™¯å‡ ä½•è¡¨ç¤ºæ³•ï¼Œé€šè¿‡ç›´æ¥å›å½’æ·±åº¦å›¾ã€å±€éƒ¨å°„çº¿å›¾å’Œä½å§¿ï¼Œå¹¶åˆ©ç”¨åº¦é‡ç¼©æ”¾å› å­ (metric scale factor) å°†å±€éƒ¨é‡å»ºè½¬æ¢ä¸ºå…¨å±€ä¸€è‡´çš„åº¦é‡åæ ‡ç³»ã€‚å¾—ç›Šäºåœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šçš„æ ‡å‡†åŒ–ç›‘ç£è®­ç»ƒï¼Œè¯¥æ¨¡å‹èƒ½åœ¨å•æ¬¡å‰é¦ˆæ¨ç†ä¸­å¤„ç†éæ ‡å®šè¿åŠ¨æ¢å¤ç»“æ„ (uncalibrated SfM)ã€æ ‡å®šå¤šè§†å›¾ç«‹ä½“è§†è§‰ (calibrated MVS) åŠå•ç›®æ·±åº¦ä¼°è®¡ç­‰å¤šç§ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMapAnything çš„æ€§èƒ½ä¼˜äºæˆ–åª²ç¾ç°æœ‰çš„ä¸“é—¨åŒ–å‰é¦ˆæ¨¡å‹ï¼Œå±•ç°å‡ºæ›´é«˜æ•ˆçš„è”åˆè®­ç»ƒèƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºé€šç”¨çš„ 3D é‡å»ºéª¨å¹²ç½‘ç»œ (universal 3D reconstruction backbone) å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://map-anything.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2509.13414v2",
      "published_date": "2025-09-16 18:00:14 UTC",
      "updated_date": "2025-09-18 22:34:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:44.670262+00:00"
    },
    {
      "arxiv_id": "2509.13400v5",
      "title": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews",
      "title_zh": "è¯„å®¡ä¸­çš„å…¬å¹³ï¼šæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹è¾…åŠ©åŒè¡Œè¯„å®¡ä¸­ï¼ˆéšè—ï¼‰çš„åè§",
      "authors": [
        "Sai Suresh Macharla Vasu",
        "Ivaxi Sheth",
        "Hui-Po Wang",
        "Ruta Binkyte",
        "Mario Fritz"
      ],
      "abstract": "The adoption of large language models (LLMs) is transforming the peer review process, from assisting reviewers in writing more detailed evaluations to generating entire reviews automatically. While these capabilities offer exciting opportunities, they also raise critical concerns about fairness and reliability. In this paper, we investigate bias in LLM-generated peer reviews by conducting controlled experiments on sensitive metadata, including author affiliation and gender. Our analysis consistently shows affiliation bias favoring institutions highly ranked on common academic rankings. Additionally, we find some gender preferences, which, even though subtle in magnitude, have the potential to compound over time. Notably, we uncover implicit biases that become more evident with token-based soft ratings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¾…åŠ©åŒè¡Œè¯„å®¡ï¼ˆPeer Reviewï¼‰è¿‡ç¨‹ä¸­å­˜åœ¨çš„æ½œåœ¨åè§ï¼Œé‡ç‚¹å…³æ³¨å…¶å¯¹è¯„å®¡å…¬å¹³æ€§ä¸å¯é æ€§çš„å½±å“ã€‚é€šè¿‡å¯¹ä½œè€…æ‰€å±æœºæ„ï¼ˆAffiliationï¼‰å’Œæ€§åˆ«ï¼ˆGenderï¼‰ç­‰æ•æ„Ÿå…ƒæ•°æ®è¿›è¡Œå—æ§å®éªŒï¼Œç ”ç©¶æ­ç¤ºäº† LLM ç”Ÿæˆçš„è¯„å®¡æ„è§ä¸­æ™®éå­˜åœ¨çš„æœºæ„åè§ï¼ˆAffiliation Biasï¼‰ï¼Œå³æ¨¡å‹æ›´é’çå­¦æœ¯æ’åè¾ƒé«˜çš„æœºæ„ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°äº†ç»†å¾®ä½†å…·æœ‰é•¿æœŸç´¯ç§¯å½±å“çš„æ€§åˆ«åå¥½ï¼ˆGender Preferencesï¼‰ï¼Œå¹¶æŒ‡å‡ºåœ¨ä½¿ç”¨åŸºäºä»¤ç‰Œçš„è½¯è¯„åˆ†ï¼ˆToken-based Soft Ratingsï¼‰æ—¶ï¼Œè¿™äº›å†…éšåè§ï¼ˆImplicit Biasesï¼‰ä¼šè¡¨ç°å¾—æ›´åŠ æ˜¾è‘—ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†è‡ªåŠ¨åŒ–è¯„å®¡æŠ€æœ¯åœ¨å­¦æœ¯è¯„ä¼°ä¸­çš„å…¬å¹³æ€§é£é™©ï¼Œä¸ºæœªæ¥æ„å»ºæ›´å…¬æ­£ã€å¯é çš„å­¦æœ¯è¯„ä»·ä½“ç³»æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13400v5",
      "published_date": "2025-09-16 17:55:56 UTC",
      "updated_date": "2025-12-03 20:54:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:44.448024+00:00"
    },
    {
      "arxiv_id": "2509.20368v1",
      "title": "LATTS: Locally Adaptive Test-Time Scaling",
      "title_zh": "LATTSï¼šå±€éƒ¨è‡ªé€‚åº”æµ‹è¯•æ—¶ç¼©æ”¾",
      "authors": [
        "Theo Uscidda",
        "Matthew Trager",
        "Michael Kleinman",
        "Aditya Chattopadhyay",
        "Wei Xia",
        "Stefano Soatto"
      ],
      "abstract": "One common strategy for improving the performance of Large Language Models (LLMs) on downstream tasks involves using a \\emph{verifier model} to either select the best answer from a pool of candidates or to steer the auto-regressive generation process towards better outputs. This class of methods typically results in improved accuracy at the cost of increased computation at test-time, a paradigm known as \\emph{test-time scaling}. However, most existing approaches increase computation uniformly across all samples and generation steps, without considering the complexity of individual instances, leading to inefficient resource use. We address this limitation by proposing an approach, called \\emph{Locally Adaptive Test-Time Scaling (LATTS)}, that allocates variable compute across generation steps. Specifically, at each generation step, LATTS employs a verifier-based acceptance criterion to decide whether to resample, backtrack, restart, or stop the generation process. This criterion effectively adjusts the per-step computational effort based on a precise notion of \\emph{local difficulty} derived from the verifier model. Empirical results show that LATTS achieves significantly superior accuracy--compute tradeoffs compared to standard verifier-based methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LATTSï¼ˆLocally Adaptive Test-Time Scalingï¼‰ï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å±€éƒ¨è‡ªé€‚åº”æµ‹è¯•æ—¶ç¼©æ”¾æ–¹æ³•ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•åœ¨æ‰€æœ‰ç”Ÿæˆæ­¥éª¤ä¸­å‡åŒ€åˆ†é…è®¡ç®—èµ„æºå¯¼è‡´æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼ŒLATTSé€šè¿‡éªŒè¯å™¨æ¨¡å‹ï¼ˆverifier modelï¼‰å®ç°äº†è®¡ç®—èµ„æºçš„åŠ¨æ€åˆ†é…ã€‚åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¯ä¸ªæ­¥éª¤ï¼Œè¯¥æ–¹æ³•æ ¹æ®ç”±éªŒè¯å™¨æ¨å¯¼å‡ºçš„â€œå±€éƒ¨éš¾åº¦â€ï¼ˆlocal difficultyï¼‰æ¦‚å¿µï¼Œè‡ªä¸»å†³å®šæ˜¯å¦è¿›è¡Œé‡é‡‡æ ·ï¼ˆresampleï¼‰ã€å›æº¯ï¼ˆbacktrackï¼‰ã€é‡å¯ï¼ˆrestartï¼‰æˆ–åœæ­¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ ‡å‡†çš„åŸºäºéªŒè¯å™¨çš„æ–¹æ³•ç›¸æ¯”ï¼ŒLATTSåœ¨å‡†ç¡®ç‡ä¸è®¡ç®—é‡çš„æƒè¡¡ï¼ˆaccuracy-compute tradeoffsï¼‰ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ä¸€æ–¹æ³•æœ‰æ•ˆä¼˜åŒ–äº†æµ‹è¯•æ—¶çš„è®¡ç®—æ•ˆç‡ï¼Œä¸ºæå‡æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½æä¾›äº†æ›´çµæ´»çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.20368v1",
      "published_date": "2025-09-16 17:51:33 UTC",
      "updated_date": "2025-09-16 17:51:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:44.948084+00:00"
    },
    {
      "arxiv_id": "2509.13399v2",
      "title": "EdiVal-Agent: An Object-Centric Framework for Automated, Fine-Grained Evaluation of Multi-Turn Editing",
      "title_zh": "EdiVal-Agentï¼šä¸€ç§é¢å‘å¤šè½®ç¼–è¾‘è‡ªåŠ¨åŒ–ä¸ç»†ç²’åº¦è¯„ä¼°çš„ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒæ¡†æ¶",
      "authors": [
        "Tianyu Chen",
        "Yasi Zhang",
        "Zhi Zhang",
        "Peiyu Yu",
        "Shu Wang",
        "Zhendong Wang",
        "Kevin Lin",
        "Xiaofei Wang",
        "Zhengyuan Yang",
        "Linjie Li",
        "Chung-Ching Lin",
        "Jianwen Xie",
        "Oscar Leong",
        "Lijuan Wang",
        "Ying Nian Wu",
        "Mingyuan Zhou"
      ],
      "abstract": "Instruction-based image editing has advanced rapidly, yet reliable and interpretable evaluation remains a bottleneck. Current protocols either (i) depend on paired reference images-resulting in limited coverage and inheriting biases from prior generative models-or (ii) rely solely on zero-shot vision-language models (VLMs), whose prompt-based assessments of instruction following, content consistency, and visual quality are often imprecise. To address this, we introduce EdiVal-Agent, an automated and fine-grained evaluation framework grounded in an object-centric perspective, designed to assess not only standard single-turn but also multi-turn instruction-based editing with precision. Given an input image, EdiVal-Agent first decomposes it into semantically meaningful objects, then synthesizes diverse, context-aware editing instructions while dynamically updating object pools across turns. These two stages enable two novel object-centric metrics tailored for multi-turn evaluation and one global metric of visual quality: (1) EdiVal-IF, which measures instruction following by combining open-vocabulary object detectors for symbolic checks with VLMs for semantic verification on detector-guided crops; (2) EdiVal-CC, which evaluates content consistency by calculating semantic similarity of unchanged objects and background using the evolving object pools; and (3) EdiVal-VQ, which quantifies changes in overall visual quality with human preference models. Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing benchmark covering 9 instruction types and 13 state-of-the-art editing models spanning in-context, flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be used to identify existing failure modes, thereby informing the development of the next generation of editing models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæŒ‡ä»¤çš„å›¾åƒç¼–è¾‘è¯„ä»·ä½“ç³»ä¸­å­˜åœ¨çš„å‚è€ƒå›¾ä¾èµ–æ€§åŠ VLM é›¶æ ·æœ¬è¯„ä¼°ç²¾åº¦ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº† EdiVal-Agent æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ä¸ªä»¥å¯¹è±¡ä¸ºä¸­å¿ƒ (Object-Centric) çš„è‡ªåŠ¨åŒ–ç²¾ç»†åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä¸“é—¨è®¾è®¡ç”¨äºç²¾å‡†è¯„ä¼°å•è½®åŠå¤šè½®æŒ‡ä»¤é©±åŠ¨çš„å›¾åƒç¼–è¾‘ã€‚EdiVal-Agent é€šè¿‡å°†è¾“å…¥å›¾åƒåˆ†è§£ä¸ºå…·æœ‰è¯­ä¹‰ä¿¡æ¯çš„å¯¹è±¡ï¼Œå¹¶åˆæˆå¤šæ ·åŒ–ä¸”å…·æœ‰èƒŒæ™¯æ„ŸçŸ¥èƒ½åŠ›çš„ç¼–è¾‘æŒ‡ä»¤ï¼Œå®ç°åœ¨å¤šè½®ç¼–è¾‘ä¸­åŠ¨æ€æ›´æ–°å¯¹è±¡æ± ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼šEdiVal-IF é€šè¿‡ç›®æ ‡æ£€æµ‹å’Œ VLM ç»“åˆçš„æ–¹å¼éªŒè¯æŒ‡ä»¤éµå¾ªæƒ…å†µï¼›EdiVal-CC åˆ©ç”¨æ¼”åŒ–å¯¹è±¡æ± è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ä»¥è¯„ä¼°å†…å®¹ä¸€è‡´æ€§ï¼›EdiVal-VQ åˆ™åˆ©ç”¨äººç±»åå¥½æ¨¡å‹é‡åŒ–æ•´ä½“è§†è§‰è´¨é‡ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº† EdiVal-Bench åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›– 9 ç§æŒ‡ä»¤ç±»å‹å¹¶å¯¹ 13 ç§æœ€å…ˆè¿›çš„ç¼–è¾‘æ¨¡å‹è¿›è¡Œäº†æ·±åº¦è¯„ä¼°ã€‚å®éªŒè¯æ˜ EdiVal-Agent èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ç°æœ‰æ¨¡å‹çš„å¤±è´¥æ¨¡å¼ï¼Œä¸ºä¸‹ä¸€ä»£å›¾åƒç¼–è¾‘æ¨¡å‹çš„å¼€å‘ä¸ä¼˜åŒ–æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Tianyu Chen and Yasi Zhang contributed equally; Oscar Leong, Lijuan Wang, Ying Nian Wu, and Mingyuan Zhou advised equally",
      "pdf_url": "https://arxiv.org/pdf/2509.13399v2",
      "published_date": "2025-09-16 17:45:39 UTC",
      "updated_date": "2025-10-16 01:09:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:49.049075+00:00"
    },
    {
      "arxiv_id": "2509.13288v1",
      "title": "Shapes of Cognition for Computational Cognitive Modeling",
      "title_zh": "é¢å‘è®¡ç®—è®¤çŸ¥å»ºæ¨¡çš„è®¤çŸ¥å½¢æ€",
      "authors": [
        "Marjorie McShane",
        "Sergei Nirenburg",
        "Sanjay Oruganti",
        "Jesse English"
      ],
      "abstract": "Shapes of cognition is a new conceptual paradigm for the computational cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are remembered constellations of sensory, linguistic, conceptual, episodic, and procedural knowledge that allow agents to cut through the complexity of real life the same way as people do: by expecting things to be typical, recognizing patterns, acting by habit, reasoning by analogy, satisficing, and generally minimizing cognitive load to the degree situations permit. Atypical outcomes are treated using shapes-based recovery methods, such as learning on the fly, asking a human partner for help, or seeking an actionable, even if imperfect, situational understanding. Although shapes is an umbrella term, it is not vague: shapes-based modeling involves particular objectives, hypotheses, modeling strategies, knowledge bases, and actual models of wide-ranging phenomena, all implemented within a particular cognitive architecture. Such specificity is needed both to vet our hypotheses and to achieve our practical aims of building useful agent systems that are explainable, extensible, and worthy of our trust, even in critical domains. However, although the LEIA example of shapes-based modeling is specific, the principles can be applied more broadly, giving new life to knowledge-based and hybrid AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Shapes of cognition çš„æ–°æ¦‚å¿µèŒƒå¼ï¼Œç”¨äºèµ‹èƒ½è¯­è¨€æ™ºèƒ½ä½“ (Language-Endowed Intelligent Agents, LEIAs) çš„è®¡ç®—è®¤çŸ¥å»ºæ¨¡ã€‚Shapes è¢«å®šä¹‰ä¸ºé›†æˆäº†æ„ŸçŸ¥ã€è¯­è¨€ã€æ¦‚å¿µã€æƒ…èŠ‚å’Œç¨‹åºæ€§çŸ¥è¯†çš„è®°å¿†æ˜Ÿåº§ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡æ¨¡å¼è¯†åˆ«ã€ä¹ æƒ¯æ€§è¡ŒåŠ¨å’Œç±»æ¯”æ¨ç†æ¥æœ‰æ•ˆé™ä½è®¤çŸ¥è´Ÿè·å¹¶ç®€åŒ–ç°å®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚é’ˆå¯¹éå…¸å‹ç»“æœï¼Œè¯¥èŒƒå¼é‡‡ç”¨äº†åŸºäº Shapes çš„æ¢å¤æœºåˆ¶ï¼Œå¦‚åœ¨çº¿å­¦ä¹ ã€å¯»æ±‚äººç±»ä¼™ä¼´å¸®åŠ©æˆ–å»ºç«‹å…·æœ‰è¡ŒåŠ¨åŠ›çš„æƒ…å¢ƒç†è§£ã€‚è¯¥å»ºæ¨¡æ–¹æ³•åœ¨ç‰¹å®šçš„ Cognitive architecture ä¸­å®ç°ï¼Œå…·æœ‰æ˜ç¡®çš„ç›®æ ‡ã€å‡è®¾å’ŒçŸ¥è¯†åº“ï¼Œæ—¨åœ¨æ„å»ºå¯è§£é‡Šã€å¯æ‰©å±•ä¸”å€¼å¾—ä¿¡èµ–çš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚å°½ç®¡ä»¥ LEIA ä¸ºä¾‹ï¼Œä½† Shapes-based modeling çš„åŸåˆ™å¯å¹¿æ³›åº”ç”¨äºçŸ¥è¯†é©±åŠ¨å‹å’Œæ··åˆå‹äººå·¥æ™ºèƒ½ (Hybrid AI)ï¼Œä¸ºç›¸å…³é¢†åŸŸæä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13288v1",
      "published_date": "2025-09-16 17:39:58 UTC",
      "updated_date": "2025-09-16 17:39:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:50:55.960699+00:00"
    },
    {
      "arxiv_id": "2509.13285v1",
      "title": "Contrastive timbre representations for musical instrument and synthesizer retrieval",
      "title_zh": "é¢å‘ä¹å™¨ä¸åˆæˆå™¨æ£€ç´¢çš„å¯¹æ¯”å¼éŸ³è‰²è¡¨å¾",
      "authors": [
        "Gwendal Le Vaillant",
        "Yannick Molle"
      ],
      "abstract": "Efficiently retrieving specific instrument timbres from audio mixtures remains a challenge in digital music production. This paper introduces a contrastive learning framework for musical instrument retrieval, enabling direct querying of instrument databases using a single model for both single- and multi-instrument sounds. We propose techniques to generate realistic positive/negative pairs of sounds for virtual musical instruments, such as samplers and synthesizers, addressing limitations in common audio data augmentation methods.\n  The first experiment focuses on instrument retrieval from a dataset of 3,884 instruments, using single-instrument audio as input. Contrastive approaches are competitive with previous works based on classification pre-training. The second experiment considers multi-instrument retrieval with a mixture of instruments as audio input. In this case, the proposed contrastive framework outperforms related works, achieving 81.7\\% top-1 and 95.7\\% top-5 accuracies for three-instrument mixtures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»éŸ³é¢‘æ··åˆç‰©ä¸­é«˜æ•ˆæ£€ç´¢ç‰¹å®šä¹å™¨éŸ³è‰²çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ (Contrastive Learning)çš„ä¹å™¨æ£€ç´¢æ¡†æ¶ï¼Œå®ç°äº†åˆ©ç”¨å•ä¸€æ¨¡å‹å¯¹å•ä¹å™¨å’Œå¤šä¹å™¨å£°éŸ³çš„ç›´æ¥æŸ¥è¯¢ã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿæ•°æ®å¢å¼ºçš„å±€é™ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†é’ˆå¯¹é‡‡æ ·å™¨(samplers)å’Œåˆæˆå™¨(synthesizers)ç­‰è™šæ‹Ÿä¹å™¨çš„æ­£è´Ÿæ ·æœ¬å¯¹ç”ŸæˆæŠ€æœ¯ã€‚åœ¨é’ˆå¯¹3,884ç§ä¹å™¨çš„å•ä¹å™¨æ£€ç´¢å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºä¸åˆ†ç±»é¢„è®­ç»ƒæ¨¡å‹ç›¸å½“çš„ç«äº‰åŠ›ã€‚è€Œåœ¨å¤šä¹å™¨æ··åˆæ£€ç´¢çš„ä»»åŠ¡ä¸­ï¼Œè¯¥æ¡†æ¶çš„è¡¨ç°ä¼˜äºåŒç±»ç ”ç©¶ï¼Œåœ¨ä¸‰ä¹å™¨æ··åˆåœºæ™¯ä¸‹è¾¾åˆ°äº†81.7%çš„top-1å’Œ95.7%çš„top-5å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœä¸ºéŸ³ä¹åˆ¶ä½œæµç¨‹ä¸­çš„éŸ³è‰²æ£€ç´¢æä¾›äº†æ›´å…·æ•ˆç‡å’Œé²æ£’æ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13285v1",
      "published_date": "2025-09-16 17:38:35 UTC",
      "updated_date": "2025-09-16 17:38:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:02.968161+00:00"
    },
    {
      "arxiv_id": "2509.13281v4",
      "title": "RepIt: Steering Language Models with Concept-Specific Refusal Vectors",
      "title_zh": "RepItï¼šåˆ©ç”¨ç‰¹å®šæ¦‚å¿µæ‹’ç»å‘é‡å¼•å¯¼è¯­è¨€æ¨¡å‹",
      "authors": [
        "Vincent Siu",
        "Nathan W. Henry",
        "Nicholas Crispino",
        "Yang Liu",
        "Dawn Song",
        "Chenguang Wang"
      ],
      "abstract": "While activation steering in large language models (LLMs) is a growing area of research, methods can often incur broader effects than desired. This motivates isolation of purer concept vectors to enable targeted interventions and understand LLM behavior at a more granular level. We present RepIt, a simple and data-efficient framework for isolating concept-specific representations. Across five frontier LLMs, RepIt enables precise interventions: it selectively suppresses refusal on targeted concepts while preserving refusal elsewhere, producing models that answer WMD-related questions while still scoring as safe on standard benchmarks. We further show that the corrective signal localizes to just 100-200 neurons and that robust target representations can be extracted from as few as a dozen examples on a single A6000. This efficiency raises a dual concern: manipulations can be performed with modest compute and data to extend to underrepresented data-scarce topics while evading existing benchmarks. By disentangling refusal vectors with RepIt, this work demonstrates that targeted interventions can counteract overgeneralization, laying the foundation for more granular control of model behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RepItï¼Œä¸€ç§ç®€å•ä¸”æ•°æ®é«˜æ•ˆ(data-efficient)çš„æ¡†æ¶ï¼Œæ—¨åœ¨éš”ç¦»ç‰¹å®šæ¦‚å¿µçš„è¡¨ç¤ºä»¥å®ç°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„ç²¾å‡†å¹²é¢„ã€‚RepIt èƒ½å¤Ÿé€‰æ‹©æ€§åœ°æŠ‘åˆ¶é’ˆå¯¹ç‰¹å®šæ¦‚å¿µçš„æ‹’ç»(refusal)è¡Œä¸ºï¼ŒåŒæ—¶ä¿ç•™å…¶ä»–é¢†åŸŸçš„æ‹’ç»æœºåˆ¶ï¼Œä½¿æ¨¡å‹åœ¨å›ç­” WMD ç›¸å…³é—®é¢˜æ—¶ä»èƒ½åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å®‰å…¨ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™ç§ä¿®æ­£ä¿¡å·ä»…å®šä½åœ¨ 100-200 ä¸ªç¥ç»å…ƒä¸Šï¼Œä¸”ä»…éœ€åä½™ä¸ªç¤ºä¾‹åœ¨å•å¼  A6000 ä¸Šå³å¯æå–å‡ºé²æ£’çš„ç›®æ ‡è¡¨ç¤ºã€‚è¿™ç§é«˜æ•ˆç‡æ„å‘³ç€å¯ä»¥ä½¿ç”¨è¾ƒä½çš„ç®—åŠ›å’Œæ•°æ®æˆæœ¬å¯¹ç¨€ç¼ºä¸»é¢˜è¿›è¡Œæ“çºµï¼Œä»è€Œè§„é¿ç°æœ‰çš„å®‰å…¨è¯„ä¼°ã€‚é€šè¿‡ RepIt è§£è€¦æ‹’ç»å‘é‡(refusal vectors)ï¼Œè¯¥å·¥ä½œå±•ç¤ºäº†é’ˆå¯¹æ€§å¹²é¢„å¯ä»¥æŠµæ¶ˆè¿‡åº¦æ³›åŒ–(overgeneralization)ï¼Œä¸ºæ¨¡å‹è¡Œä¸ºçš„ç»†ç²’åº¦æ§åˆ¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13281v4",
      "published_date": "2025-09-16 17:35:36 UTC",
      "updated_date": "2025-10-20 21:21:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:00.856665+00:00"
    },
    {
      "arxiv_id": "2509.13279v1",
      "title": "HARMONIC: A Content-Centric Cognitive Robotic Architecture",
      "title_zh": "HARMONICï¼šä¸€ç§ä»¥å†…å®¹ä¸ºä¸­å¿ƒçš„è®¤çŸ¥æœºå™¨äººæ¶æ„",
      "authors": [
        "Sanjay Oruganti",
        "Sergei Nirenburg",
        "Marjorie McShane",
        "Jesse English",
        "Michael K. Roberts",
        "Christian Arndt",
        "Carlos Gonzalez",
        "Mingyo Seo",
        "Luis Sentis"
      ],
      "abstract": "This paper introduces HARMONIC, a cognitive-robotic architecture designed for robots in human-robotic teams. HARMONIC supports semantic perception interpretation, human-like decision-making, and intentional language communication. It addresses the issues of safety and quality of results; aims to solve problems of data scarcity, explainability, and safety; and promotes transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are demonstrated, each implemented in both a high-fidelity simulation environment and on physical robotic platforms.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† HARMONICï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºäººæœºåä½œå›¢é˜Ÿ (human-robotic teams) è®¾è®¡çš„è®¤çŸ¥æœºå™¨äººæ¶æ„ (cognitive-robotic architecture)ã€‚è¯¥æ¶æ„æ”¯æŒè¯­ä¹‰æ„ŸçŸ¥è§£é‡Š (semantic perception interpretation)ã€ç±»äººå†³ç­– (human-like decision-making) ä»¥åŠæ„å›¾è¯­è¨€äº¤æµ (intentional language communication)ï¼Œæ—¨åœ¨æå‡æœºå™¨äººçš„è®¤çŸ¥ä¸äº¤äº’èƒ½åŠ›ã€‚HARMONIC è‡´åŠ›äºè§£å†³å®‰å…¨æ€§ (safety) å’Œç»“æœè´¨é‡é—®é¢˜ï¼Œå¹¶é‡ç‚¹åº”å¯¹æ•°æ®ç¨€ç¼º (data scarcity)ã€å¯è§£é‡Šæ€§ (explainability) ä¸é€æ˜åº¦ç­‰æŒ‘æˆ˜ï¼Œä»è€Œå»ºç«‹èµ·æ›´ç¨³å›ºçš„ç”¨æˆ·ä¿¡ä»»ã€‚é€šè¿‡åœ¨é«˜åº¦ä»¿çœŸç¯å¢ƒå’Œç‰©ç†æœºå™¨äººå¹³å°ä¸Šéƒ¨ç½²ä¸¤å¥—æ¦‚å¿µéªŒè¯ç³»ç»Ÿï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†è¯¥æ¶æ„åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚è¿™ä¸€æ¶æ„ä¸ºæ„å»ºå®‰å…¨ã€å¯è§£é‡Šä¸”å…·å¤‡ç±»äººæ²Ÿé€šèƒ½åŠ›çš„åä½œæœºå™¨äººç³»ç»Ÿæä¾›äº†é‡è¦æ¡†æ¶ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13279v1",
      "published_date": "2025-09-16 17:34:18 UTC",
      "updated_date": "2025-09-16 17:34:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:04.348339+00:00"
    },
    {
      "arxiv_id": "2509.13397v2",
      "title": "The threat of analytic flexibility in using large language models to simulate human data: A call to attention",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿäººç±»æ•°æ®ä¸­çš„åˆ†æçµæ´»æ€§å¨èƒï¼šå‘¼åå…³æ³¨",
      "authors": [
        "Jamie Cummins"
      ],
      "abstract": "Social scientists are now using large language models to create \"silicon samples\" - synthetic datasets intended to stand in for human respondents, aimed at revolutionising human subjects research. However, there are many analytic choices which must be made to produce these samples. Though many of these choices are defensible, their impact on sample quality is poorly understood. I map out these analytic choices and demonstrate how a very small number of decisions can dramatically change the correspondence between silicon samples and human data. Configurations (N = 252) varied substantially in their capacity to estimate (i) rank ordering of participants, (ii) response distributions, and (iii) between-scale correlations. Most critically, configurations were not consistent in quality: those that performed well on one dimension often performed poorly on another, implying that there is no \"one-size-fits-all\" configuration that optimises the accuracy of these samples. I call for greater attention to the threat of analytic flexibility in using silicon samples.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¤¾ä¼šç§‘å­¦å®¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(Large Language Models)æ„å»ºâ€œç¡…æ ·æœ¬â€(silicon samples)ä»¥æ›¿ä»£äººç±»å—è®¿è€…çš„è¶‹åŠ¿ï¼Œå¹¶æ­ç¤ºäº†åˆ†æçµæ´»æ€§(analytic flexibility)å¸¦æ¥çš„æ½œåœ¨å¨èƒã€‚ä½œè€…è¯¦ç»†æ¢³ç†äº†ç”Ÿæˆè¿™äº›æ ·æœ¬æ—¶æ¶‰åŠçš„ä¸€ç³»åˆ—åˆ†æé€‰æ‹©ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜æå°‘æ•°å†³ç­–çš„å˜åŒ–å³å¯å‰§çƒˆå½±å“ç¡…æ ·æœ¬ä¸äººç±»çœŸå®æ•°æ®ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚é€šè¿‡å¯¹252ç§ä¸åŒé…ç½®çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°å®ƒä»¬åœ¨ä¼°è®¡å‚ä¸è€…æ’åã€å“åº”åˆ†å¸ƒåŠé‡è¡¨é—´ç›¸å…³æ€§ç­‰ç»´åº¦ä¸Šçš„è¡¨ç°å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ç»“æœè¡¨æ˜ï¼Œæ²¡æœ‰ä»»ä½•ä¸€ç§é…ç½®èƒ½å¤ŸåŒæ—¶ä¼˜åŒ–æ‰€æœ‰ç»´åº¦çš„å‡†ç¡®æ€§ï¼Œå³ä¸å­˜åœ¨â€œä¸€åŠ³æ°¸é€¸â€çš„é€šç”¨é…ç½®æ–¹æ¡ˆã€‚åŸºäºè¿™äº›å‘ç°ï¼Œä½œè€…å‘¼åç ”ç©¶è€…åœ¨ä½¿ç”¨ç¡…æ ·æœ¬æ¨¡æ‹Ÿäººç±»æ•°æ®æ—¶ï¼Œå¿…é¡»é«˜åº¦è­¦æƒ•åˆ†æçµæ´»æ€§å¯¹ç ”ç©¶æ•ˆåº¦çš„å½±å“ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.13397v2",
      "published_date": "2025-09-16 17:29:47 UTC",
      "updated_date": "2025-09-18 07:18:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:07.075737+00:00"
    },
    {
      "arxiv_id": "2509.13270v1",
      "title": "RadGame: An AI-Powered Platform for Radiology Education",
      "title_zh": "RadGameï¼šäººå·¥æ™ºèƒ½é©±åŠ¨çš„æ”¾å°„åŒ»å­¦æ•™è‚²å¹³å°",
      "authors": [
        "Mohammed Baharoon",
        "Siavash Raissi",
        "John S. Jun",
        "Thibault Heintz",
        "Mahmoud Alabbad",
        "Ali Alburkani",
        "Sung Eun Kim",
        "Kent Kleinschmidt",
        "Abdulrahman O. Alhumaydhi",
        "Mohannad Mohammed G. Alghamdi",
        "Jeremy Francis Palacio",
        "Mohammed Bukhaytan",
        "Noah Michael Prudlo",
        "Rithvik Akula",
        "Brady Chrisler",
        "Benjamin Galligos",
        "Mohammed O. Almutairi",
        "Mazeen Mohammed Alanazi",
        "Nasser M. Alrashdi",
        "Joel Jihwan Hwang",
        "Sri Sai Dinesh Jaliparthi",
        "Luke David Nelson",
        "Nathaniel Nguyen",
        "Sathvik Suryadevara",
        "Steven Kim",
        "Mohammed F. Mohammed",
        "Yevgeniy R. Semenov",
        "Kun-Hsing Yu",
        "Abdulrhman Aljouie",
        "Hassan AlOmaish",
        "Adam Rodman",
        "Pranav Rajpurkar"
      ],
      "abstract": "We introduce RadGame, an AI-powered gamified platform for radiology education that targets two core skills: localizing findings and generating reports. Traditional radiology training is based on passive exposure to cases or active practice with real-time input from supervising radiologists, limiting opportunities for immediate and scalable feedback. RadGame addresses this gap by combining gamification with large-scale public datasets and automated, AI-driven feedback that provides clear, structured guidance to human learners. In RadGame Localize, players draw bounding boxes around abnormalities, which are automatically compared to radiologist-drawn annotations from public datasets, and visual explanations are generated by vision-language models for user missed findings. In RadGame Report, players compose findings given a chest X-ray, patient age and indication, and receive structured AI feedback based on radiology report generation metrics, highlighting errors and omissions compared to a radiologist's written ground truth report from public datasets, producing a final performance and style score. In a prospective evaluation, participants using RadGame achieved a 68% improvement in localization accuracy compared to 17% with traditional passive methods and a 31% improvement in report-writing accuracy compared to 4% with traditional methods after seeing the same cases. RadGame highlights the potential of AI-driven gamification to deliver scalable, feedback-rich radiology training and reimagines the application of medical AI resources in education.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†RadGameï¼Œä¸€ä¸ªç”±äººå·¥æ™ºèƒ½é©±åŠ¨çš„æ”¾å°„å­¦æ•™è‚²æ¸¸æˆåŒ–å¹³å°ï¼Œæ—¨åœ¨é’ˆå¯¹æ€§æå‡ç—…ç¶å®šä½(Localizing findings)å’ŒæŠ¥å‘Šæ’°å†™(Generating reports)ä¸¤é¡¹æ ¸å¿ƒæŠ€èƒ½ã€‚ä¸ºäº†è§£å†³ä¼ ç»Ÿæ”¾å°„å­¦åŸ¹è®­ç¼ºä¹å³æ—¶å’Œå¯æ‰©å±•åé¦ˆçš„é—®é¢˜ï¼ŒRadGameåˆ©ç”¨å¤§è§„æ¨¡å…¬å…±æ•°æ®é›†ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–AIåé¦ˆç³»ç»Ÿä¸ºå­¦ä¹ è€…æä¾›ç»“æ„åŒ–çš„æŒ‡å¯¼ã€‚åœ¨RadGame Localizeæ¨¡å¼ä¸­ï¼Œå¹³å°åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)å¯¹æ¯”ç”¨æˆ·æ ‡æ³¨ä¸ä¸“å®¶é‡‘æ ‡å‡†ï¼Œå¹¶ä¸ºé—æ¼çš„å‘ç°ç”Ÿæˆè§†è§‰è§£é‡Šï¼›è€Œåœ¨RadGame Reportæ¨¡å¼ä¸­ï¼Œç³»ç»ŸåŸºäºæ”¾å°„æŠ¥å‘Šç”ŸæˆæŒ‡æ ‡(Metrics)å¯¹ç”¨æˆ·çš„æŠ¥å‘Šè´¨é‡è¿›è¡Œè¯„åˆ†å¹¶æŒ‡å‡ºé”™è¯¯ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä½¿ç”¨RadGameçš„å‚ä¸è€…åœ¨å®šä½å‡†ç¡®åº¦å’ŒæŠ¥å‘Šæ’°å†™å‡†ç¡®åº¦ä¸Šåˆ†åˆ«æå‡äº†68%å’Œ31%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿè¢«åŠ¨å­¦ä¹ æ–¹æ³•çš„æå‡å¹…åº¦ã€‚è¯¥é¡¹å·¥ä½œå±•ç¤ºäº†AIé©±åŠ¨çš„æ¸¸æˆåŒ–åœ¨å®ç°å¯æ‰©å±•ä¸”é«˜åé¦ˆçš„åŒ»ç–—æ•™è‚²æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œé‡æ–°å®šä¹‰äº†åŒ»ç–—AIèµ„æºåœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13270v1",
      "published_date": "2025-09-16 17:27:33 UTC",
      "updated_date": "2025-09-16 17:27:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:18.758266+00:00"
    },
    {
      "arxiv_id": "2509.13266v1",
      "title": "JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection Attacks",
      "title_zh": "JANUSï¼šé¢å‘éšè”½èŠ‚ç‚¹æ³¨å…¥æ”»å‡»çš„åŒé‡çº¦æŸç”Ÿæˆå¼æ¡†æ¶",
      "authors": [
        "Jiahao Zhang",
        "Xiaobing Pei",
        "Zhaokun Zhong",
        "Wenqiang Hao",
        "Zhenghao Tang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable performance across various applications, yet they are vulnerable to sophisticated adversarial attacks, particularly node injection attacks. The success of such attacks heavily relies on their stealthiness, the ability to blend in with the original graph and evade detection. However, existing methods often achieve stealthiness by relying on indirect proxy metrics, lacking consideration for the fundamental characteristics of the injected content, or focusing only on imitating local structures, which leads to the problem of local myopia. To overcome these limitations, we propose a dual-constraint stealthy node injection framework, called Joint Alignment of Nodal and Universal Structures (JANUS). At the local level, we introduce a local feature manifold alignment strategy to achieve geometric consistency in the feature space. At the global level, we incorporate structured latent variables and maximize the mutual information with the generated structures, ensuring the injected structures are consistent with the semantic patterns of the original graph. We model the injection attack as a sequential decision process, which is optimized by a reinforcement learning agent. Experiments on multiple standard datasets demonstrate that the JANUS framework significantly outperforms existing methods in terms of both attack effectiveness and stealthiness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks, GNNs)åœ¨èŠ‚ç‚¹æ³¨å…¥æ”»å‡»(node injection attacks)ä¸­éšè”½æ€§ä¸è¶³çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰æ–¹æ³•å¾€å¾€ä¾èµ–é—´æ¥æŒ‡æ ‡æˆ–ä»…å…³æ³¨å±€éƒ¨ç»“æ„ï¼Œä»è€Œå¯¼è‡´â€œå±€éƒ¨çŸ­è§†â€ç°è±¡ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†åä¸ºJANUSçš„åŒé‡çº¦æŸç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡èŠ‚ç‚¹ä¸å…¨å±€ç»“æ„çš„è”åˆå¯¹é½(Joint Alignment of Nodal and Universal Structures)æ¥å¢å¼ºæ”»å‡»çš„éšè”½æ€§ã€‚åœ¨å±€éƒ¨å±‚é¢ï¼Œè¯¥æ¡†æ¶å¼•å…¥å±€éƒ¨ç‰¹å¾æµå½¢å¯¹é½(local feature manifold alignment)ç­–ç•¥ä»¥ç¡®ä¿ç‰¹å¾ç©ºé—´çš„å‡ ä½•ä¸€è‡´æ€§ï¼›åœ¨å…¨å±€å±‚é¢ï¼Œåˆ™é€šè¿‡ç»“æ„åŒ–æ½œåœ¨å˜é‡å’Œæœ€å¤§åŒ–äº’ä¿¡æ¯(mutual information)ç¡®ä¿æ³¨å…¥ç»“æ„ç¬¦åˆåŸå§‹å›¾çš„è¯­ä¹‰æ¨¡å¼ã€‚JANUSå°†æ³¨å…¥æ”»å‡»å»ºæ¨¡ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–è¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (reinforcement learning)æ™ºèƒ½ä½“è¿›è¡Œä¼˜åŒ–ã€‚åœ¨å¤šä¸ªæ ‡å‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒJANUSåœ¨æ”»å‡»æœ‰æ•ˆæ€§å’Œéšè”½æ€§æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13266v1",
      "published_date": "2025-09-16 17:24:30 UTC",
      "updated_date": "2025-09-16 17:24:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:30.653289+00:00"
    },
    {
      "arxiv_id": "2509.13255v1",
      "title": "ResidualViT for Efficient Temporally Dense Video Encoding",
      "title_zh": "ResidualViTï¼šé¢å‘é«˜æ•ˆæ—¶åŸŸå¯†é›†è§†é¢‘ç¼–ç ",
      "authors": [
        "Mattia Soldan",
        "Fabian Caba Heilbron",
        "Bernard Ghanem",
        "Josef Sivic",
        "Bryan Russell"
      ],
      "abstract": "Several video understanding tasks, such as natural language temporal video grounding, temporal activity localization, and audio description generation, require \"temporally dense\" reasoning over frames sampled at high temporal resolution. However, computing frame-level features for these tasks is computationally expensive given the temporal resolution requirements. In this paper, we make three contributions to reduce the cost of computing features for temporally dense tasks. First, we introduce a vision transformer (ViT) architecture, dubbed ResidualViT, that leverages the large temporal redundancy in videos to efficiently compute temporally dense frame-level features. Our architecture incorporates (i) learnable residual connections that ensure temporal consistency across consecutive frames and (ii) a token reduction module that enhances processing speed by selectively discarding temporally redundant information while reusing weights of a pretrained foundation model. Second, we propose a lightweight distillation strategy to approximate the frame-level features of the original foundation model. Finally, we evaluate our approach across four tasks and five datasets, in both zero-shot and fully supervised settings, demonstrating significant reductions in computational cost (up to 60%) and improvements in inference speed (up to 2.5x faster), all while closely approximating the accuracy of the original foundation model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ResidualViTï¼Œä¸€ç§ä¸“é—¨é’ˆå¯¹æ—¶é—´å¯†é›†å‹ï¼ˆtemporally denseï¼‰è§†é¢‘ç¼–ç ä»»åŠ¡è®¾è®¡çš„é«˜æ•ˆ Vision Transformer (ViT) æ¶æ„ã€‚è¯¥æ¶æ„æ—¨åœ¨è§£å†³è§†é¢‘ç†è§£ä»»åŠ¡ä¸­å› é«˜æ—¶é—´åˆ†è¾¨ç‡é‡‡æ ·å¯¼è‡´çš„æ­£å‘ç‰¹å¾è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚ResidualViT å¼•å…¥äº†å¯å­¦ä¹ çš„æ®‹å·®è¿æ¥ï¼ˆlearnable residual connectionsï¼‰ï¼Œä»¥ç¡®ä¿è¿ç»­å¸§ä¹‹é—´çš„æ—¶é—´ä¸€è‡´æ€§ï¼Œå¹¶ç»“åˆä»¤ç‰Œå‡å°‘æ¨¡å—ï¼ˆtoken reduction moduleï¼‰é€šè¿‡ä¸¢å¼ƒå†—ä½™ä¿¡æ¯å’Œé‡ç”¨åŸºç¡€æ¨¡å‹æƒé‡æ¥æ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§è½»é‡çº§è’¸é¦ç­–ç•¥ï¼ˆlightweight distillation strategyï¼‰ä»¥é€¼è¿‘åŸå§‹æ¨¡å‹çš„å¸§çº§ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒResidualViT åœ¨å››ä¸ªä»»åŠ¡å’Œäº”ä¸ªæ•°æ®é›†ä¸Šå°†è®¡ç®—æˆæœ¬é™ä½äº†é«˜è¾¾ 60%ï¼Œæ¨ç†é€Ÿåº¦æå‡äº† 2.5 å€ï¼Œä¸”å‡†ç¡®ç‡ç´§è¿½åŸå§‹åŸºç¡€æ¨¡å‹ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå®ç°å…¼é¡¾æ•ˆç‡ä¸ç²¾åº¦çš„é«˜åˆ†è¾¨ç‡è§†é¢‘ç†è§£æä¾›äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13255v1",
      "published_date": "2025-09-16 17:12:23 UTC",
      "updated_date": "2025-09-16 17:12:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:30.095040+00:00"
    },
    {
      "arxiv_id": "2509.13395v1",
      "title": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models",
      "title_zh": "TICLï¼šé¢å‘è¯­éŸ³è¯­å¢ƒå­¦ä¹ çš„æ–‡æœ¬åµŒå…¥ KNN æ¿€å‘å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„è¯­éŸ³è¯†åˆ«èƒ½åŠ›",
      "authors": [
        "Haolong Zheng",
        "Yekaterina Yegorova",
        "Mark Hasegawa-Johnson"
      ],
      "abstract": "Speech foundation models have recently demonstrated the ability to perform Speech In-Context Learning (SICL). Selecting effective in-context examples is crucial for SICL performance, yet selection methodologies remain underexplored. In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline that uses semantic context to enhance off-the-shelf large multimodal models' speech recognition ability without fine-tuning. Across challenging automatic speech recognition tasks, including accented English, multilingual speech, and children's speech, our method enables models to surpass zero-shot performance with up to 84.7% relative WER reduction. We conduct ablation studies to show the robustness and efficiency of our method.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TICL (Text-Embedding KNN for SICL)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡è¯­ä¹‰ä¸Šä¸‹æ–‡å¢å¼ºç°æœ‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ (Large Multimodal Models) è¯­éŸ³è¯†åˆ«èƒ½åŠ›çš„ç®€å•æµæ°´çº¿æ–¹æ³•ã€‚å°½ç®¡è¯­éŸ³åŸºç¡€æ¨¡å‹å·²å±•ç°å‡ºè¯­éŸ³ä¸Šä¸‹æ–‡å­¦ä¹  (Speech In-Context Learning, SICL) çš„èƒ½åŠ›ï¼Œä½†å¦‚ä½•é€‰æ‹©æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ä»æ˜¯ä¸€ä¸ªè¢«å¿½è§†çš„å…³é”®ç¯èŠ‚ï¼ŒTICL åˆ™é€šè¿‡åˆ©ç”¨æ–‡æœ¬åµŒå…¥å’Œ K-æœ€è¿‘é‚»ç®—æ³•åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹å®ç°äº†æ€§èƒ½çªç ´ã€‚è¯¥æ–¹æ³•åœ¨åŒ…æ‹¬å£éŸ³è‹±è¯­ (accented English)ã€å¤šè¯­è¨€è¯­éŸ³ (multilingual speech) å’Œå„¿ç«¥è¯­éŸ³ (children's speech) åœ¨å†…çš„å¤šç§æŒ‘æˆ˜æ€§è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (Automatic Speech Recognition) ä»»åŠ¡ä¸­è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTICL èƒ½å¤Ÿä½¿æ¨¡å‹ç›¸è¾ƒäºé›¶æ ·æœ¬ (zero-shot) è¡¨ç°å®ç°é«˜è¾¾ 84.7% çš„ç›¸å¯¹å­—é”™è¯¯ç‡ (Word Error Rate, WER) é™ä½ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¸åŒè¯­éŸ³åœºæ™¯ä¸‹çš„é²æ£’æ€§å’Œè¿è¡Œæ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºè§£é”å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤æ‚è¯­éŸ³ç¯å¢ƒä¸‹çš„è¯†åˆ«æ½œåŠ›æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”æ— éœ€å¾®è°ƒçš„æ–°æ€è·¯ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13395v1",
      "published_date": "2025-09-16 17:07:23 UTC",
      "updated_date": "2025-09-16 17:07:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:32.986617+00:00"
    },
    {
      "arxiv_id": "2509.14284v1",
      "title": "The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration",
      "title_zh": "æ•´ä½“æ³„éœ²ç”šäºå±€éƒ¨ï¼šå¤šæ™ºèƒ½ä½“åä½œä¸­çš„ç»„åˆæ€§éšç§é£é™©ä¸ç¼“è§£",
      "authors": [
        "Vaidehi Patil",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„ç»„åˆéšç§æ³„éœ²(Compositional Privacy Leakage)é£é™©ï¼Œå³å¤šä¸ªçœ‹ä¼¼æ— å®³çš„å“åº”åœ¨ç´¯ç§¯äº¤äº’åå¯èƒ½å¯¼è‡´æ•æ„Ÿä¿¡æ¯æ³„éœ²çš„é—®é¢˜ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ä¸ªæ¡†æ¶æ¥æ¨¡æ‹Ÿè¾…åŠ©çŸ¥è¯†ä¸æ™ºèƒ½ä½“äº¤äº’å¦‚ä½•å…±åŒæ”¾å¤§éšç§é£é™©ï¼Œå¹¶æå‡ºäº†ä¸¤ç§é˜²å¾¡ç­–ç•¥ã€‚ç¬¬ä¸€ç§æ˜¯å¿ƒç†ç†è®ºé˜²å¾¡(Theory-of-Mind, ToM)ï¼Œé€šè¿‡æ¨æµ‹æé—®è€…æ„å›¾æ¥é¢„åˆ¤è¾“å‡ºæ˜¯å¦ä¼šè¢«æ¶æ„åˆ©ç”¨ï¼›ç¬¬äºŒç§æ˜¯åä½œå…±è¯†é˜²å¾¡(Collaborative Consensus Defense, CoDef)ï¼Œé€šè¿‡æ™ºèƒ½ä½“é—´çš„åä½œæŠ•ç¥¨æ¥é™åˆ¶æ•æ„Ÿä¿¡æ¯ä¼ æ’­ã€‚å®éªŒæ˜¾ç¤ºï¼Œè™½ç„¶å•çº¯çš„é“¾å¼æ€ç»´(Chain-of-Thought)é˜²æŠ¤æ•ˆæœæœ‰é™ï¼Œä½†ToMé˜²å¾¡èƒ½å°†æ•æ„Ÿä¿¡æ¯æ‹¦æˆªç‡æå‡è‡³97%ï¼Œè€ŒCoDefåœ¨éšç§ä¸æ•ˆç”¨çš„æƒè¡¡ä¸­è¡¨ç°æœ€å‡ºè‰²ï¼Œè¾¾åˆ°äº†79.8%çš„å¹³è¡¡ç»“æœ(Balanced Outcome)ã€‚è¯¥ç ”ç©¶ä¸ä»…é‡åŒ–äº†åä½œå¼ç³»ç»Ÿä¸­çš„éšç§é£é™©ï¼Œè¿˜ä¸ºæ„å»ºå¯åº”å¯¹ä¸Šä¸‹æ–‡é©±åŠ¨æ³„éœ²çš„å®‰å…¨é˜²å¾¡æœºåˆ¶æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Code: https://github.com/Vaidehi99/MultiAgentPrivacy",
      "pdf_url": "https://arxiv.org/pdf/2509.14284v1",
      "published_date": "2025-09-16 16:57:25 UTC",
      "updated_date": "2025-09-16 16:57:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:50.464933+00:00"
    },
    {
      "arxiv_id": "2509.13237v1",
      "title": "Metacognitive Reuse: Turning Recurring LLM Reasoning Into Concise Behaviors",
      "title_zh": "å…ƒè®¤çŸ¥å¤ç”¨ï¼šå°†å¤§è¯­è¨€æ¨¡å‹çš„é‡å¤æ¨ç†è½¬åŒ–ä¸ºç®€æ´çš„è¡Œä¸ºæ¨¡å¼",
      "authors": [
        "Aniket Didolkar",
        "Nicolas Ballas",
        "Sanjeev Arora",
        "Anirudh Goyal"
      ],
      "abstract": "Large language models (LLMs) now solve multi-step problems by emitting extended chains of thought. During the process, they often re-derive the same intermediate steps across problems, inflating token usage and latency. This saturation of the context window leaves less capacity for exploration. We study a simple mechanism that converts recurring reasoning fragments into concise, reusable \"behaviors\" (name + instruction) via the model's own metacognitive analysis of prior traces. These behaviors are stored in a \"behavior handbook\" which supplies them to the model in-context at inference or distills them into parameters via supervised fine-tuning. This approach achieves improved test-time reasoning across three different settings - 1) Behavior-conditioned inference: Providing the LLM relevant behaviors in-context during reasoning reduces number of reasoning tokens by up to 46% while matching or improving baseline accuracy; 2) Behavior-guided self-improvement: Without any parameter updates, the model improves its own future reasoning by leveraging behaviors from its own past problem solving attempts. This yields up to 10% higher accuracy than a naive critique-and-revise baseline; and 3) Behavior-conditioned SFT: SFT on behavior-conditioned reasoning traces is more effective at converting non-reasoning models into reasoning models as compared to vanilla SFT. Together, these results indicate that turning slow derivations into fast procedural hints enables LLMs to remember how to reason, not just what to conclude.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Metacognitive Reuseï¼Œè¿™æ˜¯ä¸€ç§å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­åå¤å‡ºç°çš„æ¨ç†ç‰‡æ®µè½¬åŒ–ä¸ºç®€æ´â€œbehaviorsâ€ï¼ˆè¡Œä¸ºï¼‰çš„æœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ­¥æ¨ç†ä¸­å†—ä½™æ¨å¯¼å¯¼è‡´çš„Tokenï¼ˆtokenï¼‰æ¶ˆè€—å’Œå»¶è¿Ÿé—®é¢˜ã€‚è¿™äº›behaviorsåŒ…å«åç§°ä¸æŒ‡ä»¤ï¼Œå¹¶è¢«å­˜å‚¨åœ¨â€œbehavior handbookâ€ä¸­ï¼Œä¾›æ¨¡å‹åœ¨æ¨ç†æ—¶é€šè¿‡in-contextæ–¹å¼è°ƒç”¨æˆ–é€šè¿‡æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿›è¡Œå‚æ•°åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œbehavior-conditioned inferenceåœ¨ä¿æŒç”šè‡³æå‡å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œæœ€é«˜å¯å‡å°‘46%çš„æ¨ç†Tokenä½¿ç”¨é‡ã€‚æ­¤å¤–ï¼Œæ¨¡å‹é€šè¿‡åˆ©ç”¨è‡ªèº«è¿‡å¾€çš„behaviorså®ç°çš„è‡ªæˆ‘æ”¹è¿›æ•ˆæœæ¯”ä¼ ç»Ÿçš„critique-and-reviseåŸºå‡†é«˜å‡º10%ã€‚ç ”ç©¶è¿˜è¯æ˜ï¼Œåœ¨å°†éæ¨ç†æ¨¡å‹è½¬åŒ–ä¸ºæ¨ç†æ¨¡å‹æ—¶ï¼Œbehavior-conditioned SFTæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´ä¸ºæœ‰æ•ˆã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œå°†ç¼“æ…¢çš„æ¨å¯¼è¿‡ç¨‹è½¬åŒ–ä¸ºå¿«é€Ÿçš„ç¨‹åºåŒ–æç¤ºï¼Œèƒ½è®©LLMsè®°ä½â€œå¦‚ä½•æ¨ç†â€è€Œéä»…ä»…æ˜¯è®°ä½ç»“è®ºï¼Œä»è€Œæ˜¾è‘—æå‡äº†æµ‹è¯•æ—¶çš„æ¨ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 9 Figures, 5 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.13237v1",
      "published_date": "2025-09-16 16:44:26 UTC",
      "updated_date": "2025-09-16 16:44:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:42.780991+00:00"
    },
    {
      "arxiv_id": "2509.13236v1",
      "title": "Layout-Aware OCR for Black Digital Archives with Unsupervised Evaluation",
      "title_zh": "é¢å‘é»‘è‰²æ•°å­—æ¡£æ¡ˆçš„å¸ƒå±€æ„ŸçŸ¥ OCR åŠæ— ç›‘ç£è¯„ä¼°",
      "authors": [
        "Fitsum Sileshi Beyene",
        "Christopher L. Dancy"
      ],
      "abstract": "Despite their cultural and historical significance, Black digital archives continue to be a structurally underrepresented area in AI research and infrastructure. This is especially evident in efforts to digitize historical Black newspapers, where inconsistent typography, visual degradation, and limited annotated layout data hinder accurate transcription, despite the availability of various systems that claim to handle optical character recognition (OCR) well. In this short paper, we present a layout-aware OCR pipeline tailored for Black newspaper archives and introduce an unsupervised evaluation framework suited to low-resource archival contexts. Our approach integrates synthetic layout generation, model pretraining on augmented data, and a fusion of state-of-the-art You Only Look Once (YOLO) detectors. We used three annotation-free evaluation metrics, the Semantic Coherence Score (SCS), Region Entropy (RE), and Textual Redundancy Score (TRS), which quantify linguistic fluency, informational diversity, and redundancy across OCR regions. Our evaluation on a 400-page dataset from ten Black newspaper titles demonstrates that layout-aware OCR improves structural diversity and reduces redundancy compared to full-page baselines, with modest trade-offs in coherence. Our results highlight the importance of respecting cultural layout logic in AI-driven document understanding and lay the foundation for future community-driven and ethically grounded archival AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é»‘äººæ•°å­—æ¡£æ¡ˆ(Black digital archives)åœ¨AIç ”ç©¶ä¸­ä»£è¡¨æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä¸“ä¸ºé»‘äººæŠ¥çº¸æ¡£æ¡ˆè®¾è®¡çš„å¸ƒå±€æ„ŸçŸ¥OCR(Layout-Aware OCR)æµæ°´çº¿ã€‚é’ˆå¯¹å†å²æ€§é»‘äººæŠ¥çº¸ä¸­å­˜åœ¨çš„æ’ç‰ˆä¸ä¸€è‡´ã€è§†è§‰é€€åŒ–ä»¥åŠæ ‡æ³¨å¸ƒå±€æ•°æ®æœ‰é™ç­‰æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•æ•´åˆäº†åˆæˆå¸ƒå±€ç”Ÿæˆ(synthetic layout generation)å’Œå¢å¼ºæ•°æ®ä¸Šçš„æ¨¡å‹é¢„è®­ç»ƒæŠ€æœ¯ã€‚ç³»ç»Ÿèåˆäº†æœ€å…ˆè¿›çš„YOLOæ£€æµ‹å™¨ï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªé€‚ç”¨äºä½èµ„æºæ¡£æ¡ˆç¯å¢ƒçš„æ— ç›‘ç£è¯„ä¼°æ¡†æ¶(unsupervised evaluation framework)ã€‚è¯„ä¼°è¿‡ç¨‹é‡‡ç”¨äº†è¯­ä¹‰ç›¸å¹²æ€§å¾—åˆ†(SCS)ã€åŒºåŸŸç†µ(RE)å’Œæ–‡æœ¬å†—ä½™å¾—åˆ†(TRS)ä¸‰é¡¹æ— éœ€æ ‡æ³¨çš„æŒ‡æ ‡ã€‚åœ¨åŒ…å«åç§é»‘äººæŠ¥çº¸æ ‡é¢˜çš„400é¡µæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸å…¨é¡µåŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æµæ°´çº¿æ˜¾è‘—æé«˜äº†ç»“æ„å¤šæ ·æ€§å¹¶å‡å°‘äº†å†—ä½™ï¼Œä¸”ä»…åœ¨ç›¸å¹²æ€§æ–¹é¢æœ‰å¾®å°æŠ˜è¡·ã€‚è¯¥æˆæœå¼ºè°ƒäº†åœ¨AIé©±åŠ¨çš„æ–‡æ¡£ç†è§£ä¸­å°Šé‡æ–‡åŒ–å¸ƒå±€é€»è¾‘çš„é‡è¦æ€§ï¼Œä¸ºæœªæ¥ç¤¾åŒºé©±åŠ¨ä¸”ç¬¦åˆä¼¦ç†çš„æ¡£æ¡ˆAIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "IEEE-ISTAS conference",
      "pdf_url": "https://arxiv.org/pdf/2509.13236v1",
      "published_date": "2025-09-16 16:43:34 UTC",
      "updated_date": "2025-09-16 16:43:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:45.051248+00:00"
    },
    {
      "arxiv_id": "2509.13235v1",
      "title": "A Scenario-Driven Cognitive Approach to Next-Generation AI Memory",
      "title_zh": "é¢å‘ä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½è®°å¿†çš„åœºæ™¯é©±åŠ¨è®¤çŸ¥æ–¹æ³•",
      "authors": [
        "Linyue Cai",
        "Yuyang Cheng",
        "Xiaoding Shao",
        "Huiming Wang",
        "Yong Zhao",
        "Wei Zhang",
        "Kang Li"
      ],
      "abstract": "As artificial intelligence advances toward artificial general intelligence (AGI), the need for robust and human-like memory systems has become increasingly evident. Current memory architectures often suffer from limited adaptability, insufficient multimodal integration, and an inability to support continuous learning. To address these limitations, we propose a scenario-driven methodology that extracts essential functional requirements from representative cognitive scenarios, leading to a unified set of design principles for next-generation AI memory systems. Based on this approach, we introduce the \\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that integrates cognitive scenarios, memory processes, and storage mechanisms into a cohesive design. COLMA provides a structured foundation for developing AI systems capable of lifelong learning and human-like reasoning, thereby contributing to the pragmatic development of AGI.",
      "tldr_zh": "éšç€äººå·¥æ™ºèƒ½å‘é€šç”¨äººå·¥æ™ºèƒ½(AGI)è¿ˆè¿›ï¼Œç°æœ‰çš„è®°å¿†æ¶æ„åœ¨é€‚åº”æ€§ã€å¤šæ¨¡æ€é›†æˆå’ŒæŒç»­å­¦ä¹ èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºæ˜æ˜¾å±€é™ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åœºæ™¯é©±åŠ¨(scenario-driven)çš„æ–¹æ³•è®ºï¼Œé€šè¿‡ä»ä»£è¡¨æ€§è®¤çŸ¥åœºæ™¯ä¸­æå–æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚ï¼Œä¸ºä¸‹ä¸€ä»£AIè®°å¿†ç³»ç»Ÿåˆ¶å®šäº†ä¸€å¥—ç»Ÿä¸€çš„è®¾è®¡åŸåˆ™ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæœ¬æ–‡å¼•å…¥äº†è®¤çŸ¥åˆ†å±‚è®°å¿†æ¶æ„(COgnitive Layered Memory Architecture, COLMA)ï¼Œè¯¥æ¡†æ¶å°†è®¤çŸ¥åœºæ™¯ã€è®°å¿†è¿‡ç¨‹ä¸å­˜å‚¨æœºåˆ¶æœ‰æœºæ•´åˆã€‚COLMAä¸ºæ„å»ºå…·å¤‡ç»ˆèº«å­¦ä¹ (lifelong learning)å’Œç±»äººæ¨ç†èƒ½åŠ›çš„AIç³»ç»Ÿå¥ å®šäº†ç»“æ„åŒ–åŸºç¡€ï¼Œä¸ºå®ç°é€šç”¨äººå·¥æ™ºèƒ½(AGI)çš„å®é™…å‘å±•åšå‡ºäº†è´¡çŒ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13235v1",
      "published_date": "2025-09-16 16:43:07 UTC",
      "updated_date": "2025-09-16 16:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:44.273268+00:00"
    },
    {
      "arxiv_id": "2509.13234v1",
      "title": "Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy",
      "title_zh": "åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿä¸´åºŠ AI è¾…åŠ©ï¼šç³–å°¿ç—…è§†ç½‘è†œç—…å˜æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Nadim Barakat",
        "William Lotter"
      ],
      "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI systems can expand access to fundus photography screening. Current FDA-cleared systems primarily provide binary referral outputs, where this minimal output may limit clinical trust and utility. Yet, determining the most effective output format to enhance clinician-AI performance is an empirical challenge that is difficult to assess at scale. We evaluated multimodal large language models (MLLMs) for DR detection and their ability to simulate clinical AI assistance across different output types. Two models were tested on IDRiD and Messidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source medical model. Experiments included: (1) baseline evaluation, (2) simulated AI assistance with synthetic predictions, and (3) actual AI-to-AI collaboration where GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at baseline, achieving higher sensitivity and AUROC, while GPT-4o showed near-perfect specificity but low sensitivity. Both models adjusted predictions based on simulated AI inputs, but GPT-4o's performance collapsed with incorrect ones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o achieved strong results when guided by MedGemma's descriptive outputs, even without direct image access (AUROC up to 0.96). These findings suggest MLLMs may improve DR screening pipelines and serve as scalable simulators for studying clinical AI assistance across varying output configurations. Open, lightweight models such as MedGemma may be especially valuable in low-resource settings, while descriptive outputs could enhance explainability and clinician trust in clinical workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMultimodal Large Language Models, MLLMsï¼‰æ¨¡æ‹Ÿç³–å°¿ç—…è§†ç½‘è†œç—…å˜ï¼ˆDiabetic Retinopathy, DRï¼‰çš„ä¸´åºŠAIè¾…åŠ©ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç³»ç»Ÿå› è¾“å‡ºå½¢å¼è¿‡äºå•ä¸€è€Œå¯¼è‡´çš„ä¸´åºŠä¿¡ä»»åº¦ä¸å®ç”¨æ€§å—é™é—®é¢˜ã€‚ç ”ç©¶å¯¹æ¯”è¯„ä¼°äº†é€šç”¨æ¨¡å‹ GPT-4o ä¸å¼€æºåŒ»å­¦æ¨¡å‹ MedGemma åœ¨åŸºçº¿ä»»åŠ¡ã€æ¨¡æ‹ŸAIè¾…åŠ©åŠå®é™…AIåä½œï¼ˆAI-to-AI collaborationï¼‰ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedGemma åœ¨çµæ•åº¦ä¸ AUROC æŒ‡æ ‡ä¸Šä¼˜äº GPT-4oï¼Œä¸”åœ¨é¢å¯¹é”™è¯¯æç¤ºå¹²æ‰°æ—¶è¡¨ç°æ›´ä¸ºç¨³å®šï¼›è€Œ GPT-4o åœ¨é›†æˆ MedGemma çš„æè¿°æ€§è¾“å‡ºåï¼Œå³ä½¿ä¸ç›´æ¥å¤„ç†å›¾åƒä¹Ÿèƒ½è¾¾åˆ° 0.96 çš„ AUROCã€‚ç ”ç©¶è¯æ˜ MLLMs èƒ½å¤Ÿæ˜¾è‘—ä¼˜åŒ– DR ç­›æŸ¥æµç¨‹ï¼Œå¹¶ä½œä¸ºç ”ç©¶ä¸´åºŠAIè¾…åŠ©é…ç½®çš„å¯æ‰©å±•æ¨¡æ‹Ÿå™¨ã€‚ç»“æœå¼ºè°ƒäº†å¼€æºæ¨¡å‹ MedGemma åœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„åº”ç”¨ä»·å€¼ï¼Œå¹¶æŒ‡å‡ºæè¿°æ€§è¾“å‡ºå¯¹äºå¢å¼ºä¸´åºŠå·¥ä½œæµçš„å¯è§£é‡Šæ€§ä¸ä¿¡ä»»åº¦è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13234v1",
      "published_date": "2025-09-16 16:42:19 UTC",
      "updated_date": "2025-09-16 16:42:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:50.876447+00:00"
    },
    {
      "arxiv_id": "2510.21721v1",
      "title": "PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation",
      "title_zh": "PREFINEï¼šåŸºäºæ¨¡æ‹Ÿç”¨æˆ·è¯„åˆ¤ä¸ç”¨æˆ·ä¸“å±è¯„ä»·å‡†åˆ™ç”Ÿæˆçš„ä¸ªæ€§åŒ–æ•…äº‹ç”Ÿæˆ",
      "authors": [
        "Kentaro Ueda",
        "Takehiro Takayanagi"
      ],
      "abstract": "While recent advances in Large Language Models (LLMs) have improved the quality of creative text generation, significant challenges remain in producing personalized stories that reflect individual user preferences. Conventional approaches rely on explicit feedback or fine-tuning, which presents practical issues regarding user burden, data collection, computational costs, and privacy. In this work, we propose PREFINE (Persona-and-Rubric Guided Critique-and-Refine), a novel framework that extends the Critique-and-Refine paradigm to personalization. PREFINE constructs a pseudo-user agent from a user's interaction history and generates user-specific rubrics (evaluation criteria). By having this agent critique and refine outputs on the user's behalf based on these tailored rubrics, our method achieves personalized generation without requiring parameter updates or direct user feedback. We conducted a comprehensive evaluation on the PerDOC and PerMPST story datasets. We designed three baseline methods and several model variants to verify the contribution of each component of our framework. In automatic evaluations (LLM-as-a-Judge), PREFINE achieved higher win rates and statistically significant scores than the baselines, without compromising general story quality. Analysis of the model variants confirmed that both the pseudo-user agent and the user-specific rubrics are crucial for enhancing personalization performance. Beyond story generation, our approach holds potential for enabling efficient personalization in broader applications, such as dialogue systems, education, and recommendation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PREFINEæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿæˆåæ˜ ä¸ªäººç”¨æˆ·åå¥½çš„ä¸ªæ€§åŒ–æ•…äº‹æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ä¼ ç»Ÿæ–¹æ³•åœ¨ç”¨æˆ·è´Ÿæ‹…å’Œæ•°æ®éšç§æ–¹é¢çš„å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡ç”¨æˆ·çš„å†å²äº¤äº’è®°å½•æ„å»ºæ¨¡æ‹Ÿç”¨æˆ·æ™ºèƒ½ä½“(pseudo-user agent)ï¼Œå¹¶ç”Ÿæˆé’ˆå¯¹è¯¥ç”¨æˆ·çš„ç‰¹å®šè¯„ä¼°å‡†åˆ™(user-specific rubrics)ã€‚PREFINEæ‰©å±•äº†æ‰¹åˆ¤å¹¶æ”¹è¿›(Critique-and-Refine)èŒƒå¼ï¼Œåˆ©ç”¨è¯¥æ™ºèƒ½ä½“ä»£è¡¨ç”¨æˆ·æ ¹æ®å®šåˆ¶åŒ–å‡†åˆ™å¯¹è¾“å‡ºå†…å®¹è¿›è¡Œè¯„ä»·ä¸ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•æ— éœ€è¿›è¡Œå‚æ•°æ›´æ–°(parameter updates)æˆ–è¯·æ±‚ç›´æ¥çš„ç”¨æˆ·åé¦ˆï¼Œå³å¯å®ç°é«˜è´¨é‡çš„ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆã€‚å®éªŒåœ¨PerDOCå’ŒPerMPSTæ•…äº‹æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œè‡ªåŠ¨è¯„ä¼°ç»“æœæ˜¾ç¤ºPREFINEç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è·å¾—äº†æ˜¾è‘—æ›´é«˜çš„èƒœç‡ã€‚åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œæ¨¡æ‹Ÿç”¨æˆ·æ™ºèƒ½ä½“ä¸ç‰¹å®šç”¨æˆ·å‡†åˆ™çš„ç»“åˆæ˜¯æå‡ä¸ªæ€§åŒ–æ€§èƒ½çš„å…³é”®ï¼Œè¯¥æ–¹æ³•æœªæ¥æœ‰æœ›åº”ç”¨äºå¯¹è¯ç³»ç»Ÿå’Œæ•™è‚²ç­‰æ›´å¹¿æ³›çš„é¢†åŸŸã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21721v1",
      "published_date": "2025-09-16 16:39:40 UTC",
      "updated_date": "2025-09-16 16:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:51:56.173083+00:00"
    },
    {
      "arxiv_id": "2509.13232v2",
      "title": "Single-stream Policy Optimization",
      "title_zh": "å•æµç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Zhongwen Xu",
        "Zihan Ding"
      ],
      "abstract": "We revisit policy-gradient optimization for Large Language Models (LLMs) from a single-stream perspective. Prevailing group-based methods like GRPO reduce variance with on-the-fly baselines but suffer from critical flaws: frequent degenerate groups erase learning signals, and synchronization barriers hinder scalability. We introduce Single-stream Policy Optimization (SPO), which eliminates these issues by design. SPO replaces per-group baselines with a persistent, KL-adaptive value tracker and normalizes advantages globally across the batch, providing a stable, low-variance learning signal for every sample. Being group-free, SPO enables higher throughput and scales effectively in long-horizon or tool-integrated settings where generation times vary. Furthermore, the persistent value tracker naturally enables an adaptive curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO converges more smoothly and attains higher accuracy than GRPO, while eliminating computation wasted on degenerate groups. Ablation studies confirm that SPO's gains stem from its principled approach to baseline estimation and advantage normalization, offering a more robust and efficient path for LLM reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25, +4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain in pass@$k$ across the evaluated $k$ values. SPO's success challenges the prevailing trend of adding incidental complexity to RL algorithms, highlighting a path where fundamental principles, not architectural workarounds, drive the next wave of progress in LLM reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Single-stream Policy Optimization (SPO)ï¼Œè¿™æ˜¯ä¸€ç§ä»å•æµè§†è§’é‡æ–°å®¡è§†å¤§è¯­è¨€æ¨¡å‹(LLMs)ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹GRPOç­‰åŸºäºç»„çš„æ–¹æ³•ä¸­å­˜åœ¨çš„é€€åŒ–ç»„(degenerate groups)å¯¼è‡´å­¦ä¹ ä¿¡å·æ¶ˆå¤±ä»¥åŠåŒæ­¥å±éšœé˜»ç¢å¯æ‰©å±•æ€§ç­‰æ ¸å¿ƒç¼ºé™·ï¼ŒSPOé€šè¿‡è®¾è®¡ä»æ ¹æœ¬ä¸Šæ¶ˆé™¤äº†è¿™äº›é—®é¢˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æŒä¹…çš„KL-adaptive value trackerå–ä»£äº†ç»„å†…åŸºå‡†ï¼Œå¹¶åœ¨å…¨å±€æ‰¹æ¬¡å†…å¯¹ä¼˜åŠ¿(advantages)è¿›è¡Œå½’ä¸€åŒ–ï¼Œä»è€Œä¸ºæ¯ä¸ªæ ·æœ¬æä¾›ç¨³å®šä¸”ä½æ–¹å·®çš„å­¦ä¹ ä¿¡å·ã€‚SPOæ— éœ€åˆ†ç»„çš„ç‰¹æ€§ä½¿å…¶åœ¨ç”Ÿæˆæ—¶é—´æ³¢åŠ¨è¾ƒå¤§çš„é•¿æ—¶ç¨‹æˆ–å·¥å…·é›†æˆåœºæ™¯ä¸­å…·å¤‡æ›´é«˜çš„ååé‡å’Œæ‰©å±•æ€§ï¼Œå¹¶èƒ½é€šè¿‡æŒä¹…åŒ–ä»·å€¼è·Ÿè¸ªå™¨å®ç°åŸºäºä¼˜å…ˆé‡‡æ ·(prioritized sampling)çš„è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ ã€‚åœ¨Qwen3-8Bæ¨¡å‹åŠäº”é¡¹å›°éš¾æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPOçš„å¹³å‡maj@32æ¯”GRPOæå‡äº†3.4ä¸ªç™¾åˆ†ç‚¹ï¼Œåœ¨BRUMO 25å’ŒAIME 25ç­‰æŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šè¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å›å½’åŸºç¡€åŸç†è€Œéå¢åŠ æ¶æ„å¤æ‚åº¦æ˜¯æå‡LLMæ¨ç†èƒ½åŠ›æ›´åŠ ç¨³å¥ä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13232v2",
      "published_date": "2025-09-16 16:39:11 UTC",
      "updated_date": "2025-09-23 14:19:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:14.794602+00:00"
    },
    {
      "arxiv_id": "2509.13229v1",
      "title": "Curriculum Multi-Task Self-Supervision Improves Lightweight Architectures for Onboard Satellite Hyperspectral Image Segmentation",
      "title_zh": "è¯¾ç¨‹å¤šä»»åŠ¡è‡ªç›‘ç£æå‡æ˜Ÿè½½é«˜å…‰è°±å›¾åƒåˆ†å‰²çš„è½»é‡åŒ–æ¶æ„",
      "authors": [
        "Hugo Carlesso",
        "Josiane Mothe",
        "Radu Tudor Ionescu"
      ],
      "abstract": "Hyperspectral imaging (HSI) captures detailed spectral signatures across hundreds of contiguous bands per pixel, being indispensable for remote sensing applications such as land-cover classification, change detection, and environmental monitoring. Due to the high dimensionality of HSI data and the slow rate of data transfer in satellite-based systems, compact and efficient models are required to support onboard processing and minimize the transmission of redundant or low-value data, e.g. cloud-covered areas. To this end, we introduce a novel curriculum multi-task self-supervised learning (CMTSSL) framework designed for lightweight architectures for HSI analysis. CMTSSL integrates masked image modeling with decoupled spatial and spectral jigsaw puzzle solving, guided by a curriculum learning strategy that progressively increases data complexity during self-supervision. This enables the encoder to jointly capture fine-grained spectral continuity, spatial structure, and global semantic features. Unlike prior dual-task SSL methods, CMTSSL simultaneously addresses spatial and spectral reasoning within a unified and computationally efficient design, being particularly suitable for training lightweight models for onboard satellite deployment. We validate our approach on four public benchmark datasets, demonstrating consistent gains in downstream segmentation tasks, using architectures that are over 16,000x lighter than some state-of-the-art models. These results highlight the potential of CMTSSL in generalizable representation learning with lightweight architectures for real-world HSI applications. Our code is publicly available at https://github.com/hugocarlesso/CMTSSL.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜å…‰è°±å›¾åƒ (Hyperspectral Imaging, HSI) æ•°æ®ç»´åº¦é«˜ã€å«æ˜Ÿä¼ è¾“æ…¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º CMTSSL (Curriculum Multi-Task Self-Supervised Learning) çš„è¯¾ç¨‹å¤šä»»åŠ¡è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–æ˜Ÿè½½éƒ¨ç½²çš„è½»é‡çº§æ¶æ„ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°é›†æˆäº†æ©ç å›¾åƒå»ºæ¨¡ (Masked Image Modeling) ä»¥åŠè§£è€¦çš„ç©ºé—´å’Œå…‰è°±æ‹¼å›¾ (Jigsaw Puzzle) ä»»åŠ¡ï¼Œå¹¶ç»“åˆè¯¾ç¨‹å­¦ä¹  (Curriculum Learning) ç­–ç•¥é€æ­¥æå‡è‡ªç›‘ç£è¿‡ç¨‹ä¸­çš„æ•°æ®å¤æ‚åº¦ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç¼–ç å™¨èƒ½å¤ŸåŒæ—¶æ•æ‰ç»†ç²’åº¦çš„å…‰è°±è¿ç»­æ€§ã€ç©ºé—´ç»“æ„å’Œå…¨å±€è¯­ä¹‰ç‰¹å¾ï¼Œåœ¨ç»Ÿä¸€ä¸”é«˜æ•ˆçš„è®¾è®¡ä¸­è§£å†³äº†ç©ºé—´ä¸å…‰è°±æ¨ç†éš¾é¢˜ã€‚å®éªŒåœ¨å››ä¸ªå…¬å¼€åŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡ä¸­å–å¾—äº†æŒç»­çš„æ€§èƒ½å¢ç›Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‰€é‡‡ç”¨çš„æ¶æ„æ¯”å½“å‰æœ€å…ˆè¿›æ¨¡å‹è½» 16,000 å€ä»¥ä¸Šï¼Œå……åˆ†è¯æ˜äº† CMTSSL åœ¨å®é™… HSI åº”ç”¨å’Œè½»é‡çº§æ³›åŒ–è¡¨ç¤ºå­¦ä¹ ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13229v1",
      "published_date": "2025-09-16 16:37:59 UTC",
      "updated_date": "2025-09-16 16:37:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:22.488049+00:00"
    },
    {
      "arxiv_id": "2509.13227v2",
      "title": "Rich Vehicle Routing Problem in Disaster Management enabling Temporally-causal Transhipments across Multi-Modal Transportation Network",
      "title_zh": "ç¾å®³ç®¡ç†ä¸­æ”¯æŒå¤šå¼è”è¿ç½‘ç»œæ—¶åºå› æœè½¬è¿çš„ä¸°å¯Œè½¦è¾†è·¯å¾„é—®é¢˜",
      "authors": [
        "Santanu Banerjee",
        "Goutam Sen",
        "Siddhartha Mukhopadhyay"
      ],
      "abstract": "A rich vehicle routing problem is considered, allowing multiple trips of heterogeneous vehicles stationed at geographically distributed vehicle depots having access to different modes of transportation. The problem arises from the real-world requirement of optimizing the disaster response time by minimizing the makespan of vehicular routes. Multiple diversely-functional vertices are considered, including Transhipment Ports as inter-modal resource transfer stations. Both simultaneous and split pickup and delivery are considered, for multiple cargo types, along with Vehicle-Cargo and Transhipment Port-Cargo compatibilities. The superiority of the proposed cascaded minimization approach is demonstrated over the existing makespan minimization approaches through our developed Mixed-Integer Linear Programming formulation. To solve the problem quickly for practical implementation in a Disaster Management-specific Decision Support System, an extensive Heuristic Algorithm is devised which utilizes Decision Tree based structuring of possible routes; the Decision Tree approach helps to inherently capture the compatibility issues, while also explore the solution space through stochastic weights. Preferential generation of small route elements is performed, which are integrated into route clusters; we consider multiple different logical integration approaches, as well as shuffling the logics to simultaneously produce multiple independent solutions. Finally, perturbations of the different solutions are done to find better neighbouring solutions. The computational performance of the PSR-GIP Heuristic, on our created novel datasets, indicates that it is able to give good solutions swiftly for practical problems involving large integer instances that the MILP is unable to solve.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¾å®³ç®¡ç†ä¸­çš„å¤æ‚è½¦è¾†è·¯å¾„é—®é¢˜ (Rich Vehicle Routing Problem, RVRP)ï¼Œæå‡ºäº†ä¸€ç§æ”¯æŒå¤šæ¨¡æ€è¿è¾“ç½‘ç»œå’Œè½¬è¿ (Transhipment) çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œæ—¨åœ¨é€šè¿‡æœ€å°åŒ–å®Œå·¥æ—¶é—´ (Makespan) ç¼©çŸ­ç¾å®³å“åº”æ—¶é—´ã€‚è¯¥é—®é¢˜æ•´åˆäº†åœ°ç†åˆ†å¸ƒä»“åº“çš„å¼‚æ„è½¦è¾†ã€ä½œä¸ºèµ„æºè½¬ç§»ç«™çš„è½¬è¿æ¸¯å£ (Transhipment Ports)ã€å¤šç§è´§ç‰©ç±»å‹ä»¥åŠå¤æ‚çš„è£…å¸å…¼å®¹æ€§çº¦æŸã€‚ç ”ç©¶å¼€å‘äº†ä¸€ç§çº§è”æœ€å°åŒ–çš„æ··åˆæ•´æ•°çº¿æ€§è§„åˆ’ (Mixed-Integer Linear Programming, MILP) æ¨¡å‹ï¼Œå¹¶è¯æ˜å…¶åœ¨å®Œå·¥æ—¶é—´ä¼˜åŒ–ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¸ºäº†æ»¡è¶³å†³ç­–æ”¯æŒç³»ç»Ÿçš„å®æ—¶æ€§éœ€æ±‚ï¼Œç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†åŸºäºå†³ç­–æ ‘ (Decision Tree) ç»“æ„çš„ PSR-GIP å¯å‘å¼ç®—æ³•ï¼Œåˆ©ç”¨éšæœºæƒé‡å’Œè·¯å¾„ç°‡æ•´åˆç­–ç•¥é«˜æ•ˆæ¢ç´¢è§£ç©ºé—´ã€‚è®¡ç®—å®éªŒè¡¨æ˜ï¼ŒPSR-GIP ç®—æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ•´æ•°å®ä¾‹æ—¶èƒ½å¤Ÿè¿…é€Ÿæä¾›é«˜è´¨é‡è§£ï¼Œå¼¥è¡¥äº† MILP åœ¨å¤æ‚å®é™…åº”ç”¨ä¸­çš„å±€é™æ€§ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "Major changes in version II: 1) Supplementary is now a separate document, 2) Algorithm steps have been updated with pseudocode in the Heuristic, 3) Explanation of the MILP formulation construction is further detailed in a supplementary section",
      "pdf_url": "https://arxiv.org/pdf/2509.13227v2",
      "published_date": "2025-09-16 16:37:18 UTC",
      "updated_date": "2025-09-17 13:17:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:27.382988+00:00"
    },
    {
      "arxiv_id": "2509.13203v1",
      "title": "G-CSEA: A Graph-Based Conflict Set Extraction Algorithm for Identifying Infeasibility in Pseudo-Boolean Models",
      "title_zh": "G-CSEAï¼šä¸€ç§è¯†åˆ«ä¼ªå¸ƒå°”æ¨¡å‹ä¸å¯è¡Œæ€§çš„åŸºäºå›¾çš„å†²çªé›†æå–ç®—æ³•",
      "authors": [
        "Kanishk Garg",
        "Saranya D.",
        "Sanal Kumar",
        "Saurabh Singh",
        "Anupam Purwar"
      ],
      "abstract": "Workforce scheduling involves a variety of rule-based constraints-such as shift limits, staffing policies, working hour restrictions, and many similar scheduling rules-which can interact in conflicting ways, leading to infeasible models. Identifying the underlying causes of such infeasibility is critical for resolving scheduling issues and restoring feasibility. A common diagnostic approach is to compute Irreducible Infeasible Subsets (IISs): minimal sets of constraints that are jointly infeasible but become feasible when any one is removed. We consider models formulated using pseudo-Boolean constraints with inequality relations over binary variables, which naturally encode scheduling logic. Existing IIS extraction methods such as Additive Deletion and QuickXplain rely on repeated feasibility checks, often incurring large numbers of solver calls. Dual ray analysis, while effective for LP-based models, may fail when the relaxed problem is feasible but the underlying pseudo-Boolean model is not. To address these limitations, we propose Graph-based Conflict Set Extraction Algorithm (G-CSEA) to extract a conflict set, an approach inspired by Conflict-Driven Clause Learning (CDCL) in SAT solvers. Our method constructs an implication graph during constraint propagation and, upon detecting a conflict, traces all contributing constraints across both decision branches. The resulting conflict set can optionally be minimized using QuickXplain to produce an IIS.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ³åŠ¨åŠ›è°ƒåº¦(Workforce scheduling)ä¸­å› å¤æ‚è§„åˆ™çº¦æŸå†²çªå¯¼è‡´çš„ä¸å¯è¡Œæ¨¡å‹é—®é¢˜ï¼Œæå‡ºäº†G-CSEAï¼Œå³ä¸€ç§åŸºäºå›¾çš„å†²çªé›†æå–ç®—æ³•ã€‚ä¸ºäº†å…‹æœç°æœ‰IISæå–æ–¹æ³•ï¼ˆå¦‚QuickXplainï¼‰é¢‘ç¹è°ƒç”¨æ±‚è§£å™¨ä»¥åŠå¯¹å¶å°„çº¿åˆ†æ(Dual ray analysis)åœ¨å¤„ç†å…·æœ‰ä¸ç­‰å¼å…³ç³»çš„ä¼ªå¸ƒå°”æ¨¡å‹(pseudo-Boolean models)æ—¶å¯èƒ½å¤±æ•ˆçš„å±€é™æ€§ï¼ŒG-CSEAå€Ÿé‰´äº†SATæ±‚è§£å™¨ä¸­å†²çªé©±åŠ¨å­å¥å­¦ä¹ (CDCL)çš„æ€è·¯ã€‚è¯¥ç®—æ³•åœ¨çº¦æŸä¼ æ’­(constraint propagation)è¿‡ç¨‹ä¸­æ„å»ºè•´æ¶µå›¾(implication graph)ï¼Œä¸€æ—¦æ£€æµ‹åˆ°å†²çªï¼Œä¾¿é€šè¿‡è¿½è¸ªå†³ç­–åˆ†æ”¯æ¥ç¡®å®šæ‰€æœ‰ç›¸å…³çš„è´¡çŒ®çº¦æŸã€‚è¯¥æ–¹æ³•ç”Ÿæˆçš„å†²çªé›†å¯è¿›ä¸€æ­¥åˆ©ç”¨QuickXplainè¿›è¡Œæœ€å°åŒ–å¤„ç†ï¼Œä»è€Œé«˜æ•ˆç”Ÿæˆä¸å¯çº¦ä¸å¯è¡Œå­é›†(IISs)ï¼Œä¸ºè¯Šæ–­å’Œæ¢å¤è°ƒåº¦æ¨¡å‹çš„çµæ´»æ€§æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper presents G-CSEA, a novel graph-based algorithm for rapidly diagnosing infeasibility in workforce scheduling models. Inspired by Conflict-Driven Clause Learning (CDCL), our method efficiently extracts a compact conflict set from an implication graph, reducing the initial constraint set by approximately 94%",
      "pdf_url": "https://arxiv.org/pdf/2509.13203v1",
      "published_date": "2025-09-16 16:09:30 UTC",
      "updated_date": "2025-09-16 16:09:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:26.361813+00:00"
    },
    {
      "arxiv_id": "2509.13202v1",
      "title": "B-TGAT: A Bi-directional Temporal Graph Attention Transformer for Clustering Multivariate Spatiotemporal Data",
      "title_zh": "B-TGATï¼šç”¨äºå¤šå˜é‡æ—¶ç©ºæ•°æ®èšç±»çš„åŒå‘æ—¶åºå›¾æ³¨æ„åŠ› Transformer",
      "authors": [
        "Francis Ndikum Nji",
        "Vandana Janaja",
        "Jianwu Wang"
      ],
      "abstract": "Clustering high-dimensional multivariate spatiotemporal climate data is challenging due to complex temporal dependencies, evolving spatial interactions, and non-stationary dynamics. Conventional clustering methods, including recurrent and convolutional models, often struggle to capture both local and global temporal relationships while preserving spatial context. We present a time-distributed hybrid U-Net autoencoder that integrates a Bi-directional Temporal Graph Attention Transformer (B-TGAT) to guide efficient temporal clustering of multidimensional spatiotemporal climate datasets. The encoder and decoder are equipped with ConvLSTM2D modules that extract joint spatial--temporal features by modeling localized dynamics and spatial correlations over time, and skip connections that preserve multiscale spatial details during feature compression and reconstruction. At the bottleneck, B-TGAT integrates graph-based spatial modeling with attention-driven temporal encoding, enabling adaptive weighting of temporal neighbors and capturing both short and long-range dependencies across regions. This architecture produces discriminative latent embeddings optimized for clustering. Experiments on three distinct spatiotemporal climate datasets demonstrate superior cluster separability, temporal stability, and alignment with known climate transitions compared to state-of-the-art baselines. The integration of ConvLSTM2D, U-Net skip connections, and B-TGAT enhances temporal clustering performance while providing interpretable insights into complex spatiotemporal variability, advancing both methodological development and climate science applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜ç»´å¤šå…ƒæ—¶ç©ºæ°”å€™æ•°æ®èšç±»ä¸­å¤æ‚çš„æ—¶ç©ºä¾èµ–å’Œéå¹³ç¨³åŠ¨åŠ›å­¦æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆåŒå‘æ—¶é—´å›¾æ³¨æ„åŠ›å˜æ¢å™¨(B-TGAT)çš„æ—¶é—´åˆ†å¸ƒæ··åˆU-Netè‡ªåŠ¨ç¼–ç å™¨ã€‚è¯¥æ¡†æ¶çš„ç¼–ç å™¨å’Œè§£ç å™¨é‡‡ç”¨ConvLSTM2Dæ¨¡å—æå–è”åˆæ—¶ç©ºç‰¹å¾ï¼Œå¹¶åˆ©ç”¨è·³è·ƒè¿æ¥(skip connections)åœ¨ç‰¹å¾å‹ç¼©ä¸é‡æ„ä¸­ä¿ç•™å¤šå°ºåº¦ç©ºé—´ç»†èŠ‚ã€‚åœ¨æ¶æ„ç“¶é¢ˆå¤„ï¼ŒB-TGATå°†åŸºäºå›¾çš„ç©ºé—´å»ºæ¨¡ä¸æ³¨æ„åŠ›é©±åŠ¨çš„æ—¶é—´ç¼–ç ç›¸ç»“åˆï¼Œå®ç°äº†å¯¹æ—¶é—´é‚»å±…çš„è‡ªé€‚åº”åŠ æƒï¼Œå¹¶æœ‰æ•ˆæ•è·è·¨åŒºåŸŸçš„çŸ­ç¨‹å’Œé•¿ç¨‹ä¾èµ–å…³ç³»ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿç”Ÿæˆä¸“é—¨ä¸ºèšç±»ä»»åŠ¡ä¼˜åŒ–çš„åˆ¤åˆ«æ€§æ½œåœ¨åµŒå…¥ã€‚å®éªŒåœ¨ä¸‰ä¸ªä¸åŒçš„æ—¶ç©ºæ°”å€™æ•°æ®é›†ä¸Šè¯æ˜ï¼Œä¸ç°æœ‰åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨èšç±»å¯åˆ†æ€§ã€æ—¶é—´ç¨³å®šæ€§å’Œæ°”å€™è½¬æ¢å¯¹é½æ–¹é¢è¡¨ç°å“è¶Šã€‚B-TGATä¸ä»…æ˜¾è‘—æå‡äº†æ—¶ç©ºèšç±»æ€§èƒ½ï¼Œè¿˜ä¸ºå¤æ‚æ—¶ç©ºå˜ç‡æä¾›äº†å¯è§£é‡Šçš„è§è§£ï¼Œå…·æœ‰é‡è¦çš„å­¦æœ¯å’Œåº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, In review",
      "pdf_url": "https://arxiv.org/pdf/2509.13202v1",
      "published_date": "2025-09-16 16:08:21 UTC",
      "updated_date": "2025-09-16 16:08:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:29.484388+00:00"
    },
    {
      "arxiv_id": "2509.19345v1",
      "title": "SCORE: A Semantic Evaluation Framework for Generative Document Parsing",
      "title_zh": "SCOREï¼šé¢å‘ç”Ÿæˆå¼æ–‡æ¡£è§£æçš„è¯­ä¹‰è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Renyu Li",
        "Antonio Jimeno Yepes",
        "Yao You",
        "Kamil PluciÅ„ski",
        "Maximilian Operlejn",
        "Crag Wolfe"
      ],
      "abstract": "Multi-modal generative document parsing systems challenge traditional evaluation: unlike deterministic OCR or layout models, they often produce semantically correct yet structurally divergent outputs. Conventional metrics-CER, WER, IoU, or TEDS-misclassify such diversity as error, penalizing valid interpretations and obscuring system behavior.\n  We introduce SCORE (Structural and COntent Robust Evaluation), an interpretation-agnostic framework that integrates (i) adjusted edit distance for robust content fidelity, (ii) token-level diagnostics to distinguish hallucinations from omissions, (iii) table evaluation with spatial tolerance and semantic alignment, and (iv) hierarchy-aware consistency checks. Together, these dimensions enable evaluation that embraces representational diversity while enforcing semantic rigor.\n  Across 1,114 pages spanning a holistic benchmark and a field dataset, SCORE consistently revealed cross-dataset performance patterns missed by standard metrics. In 2-5% of pages with ambiguous table structures, traditional metrics penalized systems by 12-25% on average, leading to distorted rankings. SCORE corrected these cases, recovering equivalence between alternative but valid interpretations. Moreover, by normalizing generative outputs into a format-agnostic representation, SCORE reproduces traditional scores (e.g., table F1 up to 0.93) without requiring object-detection pipelines, demonstrating that generative parsing alone suffices for comprehensive evaluation.\n  By exposing how interpretive diversity impacts evaluation outcomes and providing multi-dimensional, interpretable diagnostics, SCORE establishes foundational principles for semantically grounded, fair, and practical benchmarking of modern document parsing systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼æ–‡æ¡£è§£æç³»ç»Ÿæå‡ºäº†SCOREï¼ˆStructural and COntent Robust Evaluationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸å…·ä½“è§£é‡Šæ–¹å¼æ— å…³çš„è¯­ä¹‰è¯„ä¼°æ¡†æ¶ã€‚ä¼ ç»Ÿçš„è¯„ä¼°æŒ‡æ ‡å¦‚CERã€WERã€IoUæˆ–TEDSå¾€å¾€å°†è¯­ä¹‰æ­£ç¡®ä½†ç»“æ„å‘æ•£çš„è¾“å‡ºè¯¯åˆ¤ä¸ºé”™è¯¯ï¼Œä»è€Œæ©ç›–äº†ç³»ç»Ÿçš„çœŸå®è¡¨ç°ã€‚SCOREé›†æˆäº†è°ƒæ•´åçš„ç¼–è¾‘è·ç¦»ï¼ˆadjusted edit distanceï¼‰ã€æ ‡è®°çº§è¯Šæ–­ã€å…·æœ‰ç©ºé—´å®¹å·®å’Œè¯­ä¹‰å¯¹é½çš„è¡¨æ ¼è¯„ä¼°ä»¥åŠå±‚çº§æ„ŸçŸ¥ä¸€è‡´æ€§æ£€æŸ¥ï¼Œèƒ½å¤Ÿåœ¨åŒ…å®¹è¡¨ç¤ºå¤šæ ·æ€§çš„åŒæ—¶å¼ºåˆ¶æ‰§è¡Œè¯­ä¹‰ä¸¥è°¨æ€§ã€‚åœ¨å¯¹1114é¡µæ–‡æ¡£çš„æµ‹è¯•ä¸­ï¼ŒSCOREçº æ­£äº†ä¼ ç»ŸæŒ‡æ ‡åœ¨å¤„ç†æ­§ä¹‰è¡¨æ ¼æ—¶äº§ç”Ÿçš„12-25%çš„å¹³å‡æƒ©ç½šåå·®ï¼Œæ¢å¤äº†ä¸åŒä½†æœ‰æ•ˆè§£é‡Šä¹‹é—´çš„ç­‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒSCOREåœ¨æ— éœ€ç‰©ä½“æ£€æµ‹ï¼ˆobject-detectionï¼‰æµæ°´çº¿çš„æƒ…å†µä¸‹é‡ç°äº†é«˜æ°´å¹³çš„ä¼ ç»Ÿè¯„åˆ†ï¼Œè¯æ˜äº†ç”Ÿæˆå¼è§£æè¶³ä»¥æ”¯æ’‘å…¨é¢çš„æ–‡æ¡£è¯„ä¼°ã€‚è¯¥æ¡†æ¶ä¸ºç°ä»£æ–‡æ¡£è§£æç³»ç»Ÿå»ºç«‹äº†ä¸€ä¸ªä»¥è¯­ä¹‰ä¸ºåŸºç¡€ã€å…¬å¹³ä¸”å…·æœ‰å¤šç»´åº¦è¯Šæ–­èƒ½åŠ›çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19345v1",
      "published_date": "2025-09-16 16:06:19 UTC",
      "updated_date": "2025-09-16 16:06:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:52.091925+00:00"
    },
    {
      "arxiv_id": "2509.13185v1",
      "title": "Is Meta-Learning Out? Rethinking Unsupervised Few-Shot Classification with Limited Entropy",
      "title_zh": "å…ƒå­¦ä¹ è¿‡æ—¶äº†å—ï¼ŸåŸºäºæœ‰é™ç†µè§†è§’çš„æ— ç›‘ç£å°æ ·æœ¬åˆ†ç±»å†æ€è€ƒ",
      "authors": [
        "Yunchuan Guan",
        "Yu Liu",
        "Ke Zhou",
        "Zhiqi Shen",
        "Jenq-Neng Hwang",
        "Serge Belongie",
        "Lei Li"
      ],
      "abstract": "Meta-learning is a powerful paradigm for tackling few-shot tasks. However, recent studies indicate that models trained with the whole-class training strategy can achieve comparable performance to those trained with meta-learning in few-shot classification tasks. To demonstrate the value of meta-learning, we establish an entropy-limited supervised setting for fair comparisons. Through both theoretical analysis and experimental validation, we establish that meta-learning has a tighter generalization bound compared to whole-class training. We unravel that meta-learning is more efficient with limited entropy and is more robust to label noise and heterogeneous tasks, making it well-suited for unsupervised tasks. Based on these insights, We propose MINO, a meta-learning framework designed to enhance unsupervised performance. MINO utilizes the adaptive clustering algorithm DBSCAN with a dynamic head for unsupervised task construction and a stability-based meta-scaler for robustness against label noise. Extensive experiments confirm its effectiveness in multiple unsupervised few-shot and zero-shot tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…ƒå­¦ä¹ (Meta-learning)åœ¨å°‘æ ·æœ¬åˆ†ç±»(few-shot classification)ä»»åŠ¡ä¸­æ˜¯å¦è¿‡æ—¶ï¼Œé€šè¿‡å»ºç«‹æœ‰é™ç†µ(entropy-limited)ç›‘ç£è®¾ç½®å¯¹å…ƒå­¦ä¹ ä¸å…¨ç±»åˆ«è®­ç»ƒ(whole-class training)è¿›è¡Œäº†å…¬å¹³æ¯”è¾ƒã€‚ç†è®ºä¸å®éªŒåˆ†æè¡¨æ˜ï¼ŒMeta-learningå…·æœ‰æ›´ç´§è‡´çš„æ³›åŒ–ç•Œ(generalization bound)ï¼Œä¸”åœ¨æœ‰é™ç†µç¯å¢ƒä¸‹æ¯”å…¨ç±»åˆ«è®­ç»ƒæ›´é«˜æ•ˆï¼Œå¯¹æ ‡ç­¾å™ªå£°(label noise)å’Œå¼‚æ„ä»»åŠ¡(heterogeneous tasks)è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚åŸºäºè¿™äº›è§è§£ï¼Œç ”ç©¶æå‡ºäº†åä¸ºMINOçš„å…ƒå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æå‡æ— ç›‘ç£å­¦ä¹ æ€§èƒ½ã€‚MINOåˆ©ç”¨å¸¦æœ‰åŠ¨æ€å¤´çš„DBSCANè‡ªé€‚åº”èšç±»ç®—æ³•è¿›è¡Œæ— ç›‘ç£ä»»åŠ¡æ„å»ºï¼Œå¹¶ç»“åˆåŸºäºç¨³å®šæ€§çš„meta-scaleræ¥åº”å¯¹æ ‡ç­¾å™ªå£°ã€‚å¤šé¡¹å®éªŒç»“æœéªŒè¯äº†MINOåœ¨æ— ç›‘ç£å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬(zero-shot)ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…ƒå­¦ä¹ åœ¨å¤„ç†å¤æ‚æ— ç›‘ç£åœºæ™¯æ—¶ä¾ç„¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.13185v1",
      "published_date": "2025-09-16 15:39:03 UTC",
      "updated_date": "2025-09-16 15:39:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:51.294781+00:00"
    },
    {
      "arxiv_id": "2509.13165v1",
      "title": "On the Correlation between Individual Fairness and Predictive Accuracy in Probabilistic Models",
      "title_zh": "æ¦‚ç‡æ¨¡å‹ä¸­ä¸ªä½“å…¬å¹³æ€§ä¸é¢„æµ‹å‡†ç¡®ç‡çš„ç›¸å…³æ€§ç ”ç©¶",
      "authors": [
        "Alessandro Antonucci",
        "Eric Rossetto",
        "Ivan Duvnjak"
      ],
      "abstract": "We investigate individual fairness in generative probabilistic classifiers by analysing the robustness of posterior inferences to perturbations in private features. Building on established results in robustness analysis, we hypothesise a correlation between robustness and predictive accuracy, specifically, instances exhibiting greater robustness are more likely to be classified accurately. We empirically assess this hypothesis using a benchmark of fourteen datasets with fairness concerns, employing Bayesian networks as the underlying generative models. To address the computational complexity associated with robustness analysis over multiple private features with Bayesian networks, we reformulate the problem as a most probable explanation task in an auxiliary Markov random field. Our experiments confirm the hypothesis about the correlation, suggesting novel directions to mitigate the traditional trade-off between fairness and accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼æ¦‚ç‡åˆ†ç±»å™¨ä¸­çš„ä¸ªä½“å…¬å¹³æ€§(Individual Fairness)ï¼Œé€šè¿‡åˆ†æåéªŒæ¨æ–­å¯¹äºç§æœ‰ç‰¹å¾æ‰°åŠ¨çš„é²æ£’æ€§(Robustness)æ¥è¡¡é‡å…¬å¹³ç¨‹åº¦ã€‚ç ”ç©¶è€…åŸºäºé²æ£’æ€§åˆ†æçš„åŸºç¡€ï¼Œå‡è®¾é²æ£’æ€§ä¸é¢„æµ‹å‡†ç¡®ç‡(Predictive Accuracy)ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œå³é²æ£’æ€§æ›´é«˜çš„æ ·æœ¬æ›´æœ‰å¯èƒ½è¢«å‡†ç¡®åˆ†ç±»ã€‚é’ˆå¯¹åœ¨è´å¶æ–¯ç½‘ç»œ(Bayesian networks)ä¸­å¤„ç†å¤šä¸ªç§æœ‰ç‰¹å¾æ—¶çš„è®¡ç®—å¤æ‚æ€§ï¼Œè¯¥ç ”ç©¶å°†é²æ£’æ€§åˆ†æé—®é¢˜é‡æ–°å®šä¹‰ä¸ºè¾…åŠ©é©¬å°”å¯å¤«éšæœºåœº(Markov random field)ä¸­çš„æœ€å¤§æ¦‚ç‡è§£é‡Š(Most Probable Explanation)ä»»åŠ¡ã€‚é€šè¿‡åœ¨14ä¸ªå…·æœ‰å…¬å¹³æ€§ç–‘è™‘çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œç ”ç©¶ç»“æœè¯å®äº†ä¸Šè¿°ç›¸å…³æ€§å‡è®¾ã€‚è¿™ä¸€å‘ç°ä¸ºç¼“è§£æœºå™¨å­¦ä¹ ä¸­ä¼ ç»Ÿçš„å…¬å¹³æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡(trade-off)æä¾›äº†æ–°çš„ç†è®ºä¾æ®å’ŒæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2509.13165v1",
      "published_date": "2025-09-16 15:17:13 UTC",
      "updated_date": "2025-09-16 15:17:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:14.596805+00:00"
    },
    {
      "arxiv_id": "2509.13160v1",
      "title": "FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning",
      "title_zh": "FinSearchCompï¼šè¿ˆå‘çœŸå®ã€ä¸“å®¶çº§çš„é‡‘èæœç´¢ä¸æ¨ç†è¯„ä¼°",
      "authors": [
        "Liang Hu",
        "Jianpeng Jiao",
        "Jiashuo Liu",
        "Yanle Ren",
        "Zhoufutu Wen",
        "Kaiyuan Zhang",
        "Xuanliang Zhang",
        "Xiang Gao",
        "Tianci He",
        "Fei Hu",
        "Yali Liao",
        "Zaiyuan Wang",
        "Chenghao Yang",
        "Qianyu Yang",
        "Mingren Yin",
        "Zhiyuan Zeng",
        "Ge Zhang",
        "Xinyi Zhang",
        "Xiying Zhao",
        "Zhenwei Zhu",
        "Hongseok Namkoong",
        "Wenhao Huang",
        "Yuwen Tang"
      ],
      "abstract": "Search has emerged as core infrastructure for LLM-based agents and is widely viewed as critical on the path toward more general intelligence. Finance is a particularly demanding proving ground: analysts routinely conduct complex, multi-step searches over time-sensitive, domain-specific data, making it ideal for assessing both search proficiency and knowledge-grounded reasoning. Yet no existing open financial datasets evaluate data searching capability of end-to-end agents, largely because constructing realistic, complicated tasks requires deep financial expertise and time-sensitive data is hard to evaluate. We present FinSearchComp, the first fully open-source agent benchmark for realistic, open-domain financial search and reasoning. FinSearchComp comprises three tasks -- Time-Sensitive Data Fetching, Simple Historical Lookup, and Complex Historical Investigation -- closely reproduce real-world financial analyst workflows. To ensure difficulty and reliability, we engage 70 professional financial experts for annotation and implement a rigorous multi-stage quality-assurance pipeline. The benchmark includes 635 questions spanning global and Greater China markets, and we evaluate 21 models (products) on it. Grok 4 (web) tops the global subset, approaching expert-level accuracy. DouBao (web) leads on the Greater China subset. Experimental analyses show that equipping agents with web search and financial plugins substantially improves results on FinSearchComp, and the country origin of models and tools impact performance significantly.By aligning with realistic analyst tasks and providing end-to-end evaluation, FinSearchComp offers a professional, high-difficulty testbed for complex financial search and reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FinSearchCompï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹ç°å®åœºæ™¯ã€å…·æœ‰ä¸“å®¶çº§éš¾åº¦çš„é‡‘èæœç´¢ä¸æ¨ç†ç«¯åˆ°ç«¯ Agent è¯„æµ‹åŸºå‡†ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰æ•°æ®é›†ä¸­ç¼ºä¹å¯¹å¤æ‚æ•°æ®æœç´¢èƒ½åŠ›è¯„ä¼°çš„ç©ºç™½ã€‚è¯¥æ¡†æ¶è®¾è®¡äº†æ—¶é—´æ•æ„Ÿæ•°æ®è·å–(Time-Sensitive Data Fetching)ã€ç®€å•å†å²æŸ¥è¯¢(Simple Historical Lookup)å’Œå¤æ‚å†å²è°ƒæŸ¥(Complex Historical Investigation)ä¸‰å¤§ä»»åŠ¡ï¼ŒçœŸå®è¿˜åŸäº†é‡‘èåˆ†æå¸ˆçš„æ—¥å¸¸å·¥ä½œæµã€‚ç ”ç©¶å›¢é˜Ÿç»„ç»‡äº† 70 åä¸“ä¸šé‡‘èä¸“å®¶è¿›è¡Œæ ‡æ³¨ï¼Œå¹¶å®æ–½äº†ä¸¥è°¨çš„å¤šé˜¶æ®µè´¨é‡ä¿è¯(quality-assurance)æµç¨‹ï¼Œæ¶µç›–å…¨çƒåŠå¤§ä¸­ååŒºå¸‚åœºçš„ 635 ä¸ªé—®é¢˜ã€‚é€šè¿‡å¯¹ 21 ä¸ªæ¨¡å‹åŠäº§å“çš„è¯„ä¼°å‘ç°ï¼ŒGrok 4 åœ¨å…¨çƒå­é›†è¡¨ç°ä¼˜å¼‚ï¼Œæ¥è¿‘ä¸“å®¶çº§æ°´å¹³ï¼Œè€Œ DouBao åœ¨å¤§ä¸­ååŒºå­é›†å¤„äºé¢†å…ˆåœ°ä½ã€‚å®éªŒè¯æ˜ï¼Œé…å¤‡ç½‘é¡µæœç´¢(web search)å’Œé‡‘èæ’ä»¶(financial plugins)èƒ½æ˜¾è‘—å¢å¼º Agent åœ¨ FinSearchComp ä¸Šçš„è¡¨ç°ï¼Œä¸”æ¨¡å‹å’Œå·¥å…·çš„åœ°åŸŸæ¥æºå¯¹æ€§èƒ½æœ‰é‡å¤§å½±å“ã€‚è¯¥ç ”ç©¶ä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸“ä¸šé‡‘èé¢†åŸŸå¤„ç†å¤æ‚æœç´¢å’ŒçŸ¥è¯†æ¨ç†ä»»åŠ¡æä¾›äº†ä¸€ä¸ªä¸“ä¸šä¸”é«˜éš¾åº¦çš„æµ‹è¯•åºŠ(testbed)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.13160v1",
      "published_date": "2025-09-16 15:13:13 UTC",
      "updated_date": "2025-09-16 15:13:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:53.791190+00:00"
    },
    {
      "arxiv_id": "2509.18152v1",
      "title": "WLFM: A Well-Logs Foundation Model for Multi-Task and Cross-Well Geological Interpretation",
      "title_zh": "WLFMï¼šé¢å‘å¤šä»»åŠ¡ä¸è·¨äº•åœ°è´¨è§£é‡Šçš„æµ‹äº•åŸºç¡€æ¨¡å‹",
      "authors": [
        "Zhenyu Qi",
        "Qing Yu",
        "Jichen Wang",
        "Yun-Bo Zhao",
        "Zerui Li",
        "Wenjun Lv"
      ],
      "abstract": "Well-log interpretation is fundamental for subsurface characterization but remains challenged by heterogeneous tool responses, noisy signals, and limited labels. We propose WLFM, a foundation model pretrained on multi-curve logs from 1200 wells, comprising three stages: tokenization of log patches into geological tokens, self-supervised pretraining with masked-token modeling and stratigraphy-aware contrastive learning, and multi-task adaptation with few-shot fine-tuning. WLFM consistently outperforms state-of-the-art baselines, achieving 0.0041 MSE in porosity estimation and 74.13\\% accuracy in lithology classification, while WLFM-Finetune further improves to 0.0038 MSE and 78.10\\% accuracy. Beyond predictive accuracy, WLFM exhibits emergent layer-awareness, learns a reusable geological vocabulary, and reconstructs masked curves with reasonable fidelity, though systematic offsets are observed in shallow and ultra-deep intervals. Although boundary detection is not explicitly evaluated here, clustering analyses suggest strong potential for future extension. These results establish WLFM as a scalable, interpretable, and transferable backbone for geological AI, with implications for multi-modal integration of logs, seismic, and textual data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†WLFMï¼Œä¸€ç§ä¸“é—¨ç”¨äºå¤šä»»åŠ¡å’Œè·¨äº•åœ°è´¨è§£é‡Šçš„æµ‹äº•åŸºç¡€æ¨¡å‹ï¼Œæ—¨åœ¨åº”å¯¹æµ‹äº•è§£é‡Šä¸­å·¥å…·å“åº”å¼‚æ„ã€å™ªå£°ä¿¡å·ä»¥åŠæ ‡æ³¨æ•°æ®æœ‰é™ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹åŸºäº1200å£äº•çš„å¤šæ›²çº¿æµ‹äº•æ•°æ®ï¼Œé€šè¿‡å°†æµ‹äº•è¡¥ä¸TokenåŒ–ã€æ‰§è¡Œç»“åˆæ©ç Tokenå»ºæ¨¡ä¸åœ°å±‚æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ çš„è‡ªç›‘ç£é¢„è®­ç»ƒï¼Œä»¥åŠå¤šä»»åŠ¡é€‚é…ä¸‰ä¸ªé˜¶æ®µæ„å»ºè€Œæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWLFMåœ¨å­”éš™åº¦ä¼°è®¡(porosity estimation)å’Œå²©æ€§åˆ†ç±»(lithology classification)ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ï¼Œå¹¶åœ¨å¾®è°ƒåå±•ç°å‡ºæ›´é«˜çš„é¢„æµ‹ç²¾åº¦ã€‚é™¤äº†å“è¶Šçš„æ€§èƒ½è¡¨ç°ï¼ŒWLFMè¿˜å±•ç°å‡ºäº†æ¶Œç°çš„å±‚æ„ŸçŸ¥èƒ½åŠ›(layer-awareness)ï¼Œå¹¶å­¦ä¹ åˆ°äº†å¯å¤ç”¨çš„åœ°è´¨è¯æ±‡ã€‚ä½œä¸ºä¸€ç§å¯æ‰©å±•ã€å¯è§£é‡Šä¸”å¯è¿ç§»çš„åœ°è´¨AIä¸»å¹²ç½‘ç»œï¼ŒWLFMä¸ºæœªæ¥æ•´åˆæµ‹äº•ã€åœ°éœ‡å’Œæ–‡æœ¬ç­‰å¤šæ¨¡æ€æ•°æ®å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18152v1",
      "published_date": "2025-09-16 14:59:45 UTC",
      "updated_date": "2025-09-16 14:59:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:52:56.890154+00:00"
    },
    {
      "arxiv_id": "2509.13137v1",
      "title": "Agentic AI for Financial Crime Compliance",
      "title_zh": "é¢å‘é‡‘èçŠ¯ç½ªåˆè§„çš„æ™ºèƒ½ä½“ AI",
      "authors": [
        "Henrik Axelsen",
        "Valdemar Licht",
        "Jan Damsgaard"
      ],
      "abstract": "The cost and complexity of financial crime compliance (FCC) continue to rise, often without measurable improvements in effectiveness. While AI offers potential, most solutions remain opaque and poorly aligned with regulatory expectations. This paper presents the design and deployment of an agentic AI system for FCC in digitally native financial platforms. Developed through an Action Design Research (ADR) process with a fintech firm and regulatory stakeholders, the system automates onboarding, monitoring, investigation, and reporting, emphasizing explainability, traceability, and compliance-by-design. Using artifact-centric modeling, it assigns clearly bounded roles to autonomous agents and enables task-specific model routing and audit logging. The contribution includes a reference architecture, a real-world prototype, and insights into how Agentic AI can reconfigure FCC workflows under regulatory constraints. Our findings extend IS literature on AI-enabled compliance by demonstrating how automation, when embedded within accountable governance structures, can support transparency and institutional trust in high-stakes, regulated environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èçŠ¯ç½ªåˆè§„ (Financial Crime Compliance, FCC) æˆæœ¬ä¸å¤æ‚åº¦æ—¥ç›Šä¸Šå‡ä¸”ç°æœ‰ AI æ–¹æ¡ˆé€æ˜åº¦ä¸è¶³çš„é—®é¢˜ï¼Œè®¾è®¡å¹¶éƒ¨ç½²äº†ä¸€å¥—é¢å‘æ•°å­—åŸç”Ÿé‡‘èå¹³å°çš„ Agentic AI ç³»ç»Ÿã€‚é€šè¿‡ä¸é‡‘èç§‘æŠ€å…¬å¸åŠç›‘ç®¡æ–¹åˆä½œçš„è¡ŒåŠ¨è®¾è®¡ç ”ç©¶ (Action Design Research, ADR) æµç¨‹ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†å…¥èŒã€ç›‘æ§ã€è°ƒæŸ¥å’ŒæŠ¥å‘Šçš„è‡ªåŠ¨åŒ–ï¼Œå¹¶å¼ºè°ƒå¯è§£é‡Šæ€§ã€å¯è¿½æº¯æ€§å’Œåˆè§„æ€§è®¾è®¡ (compliance-by-design)ã€‚ç³»ç»Ÿåˆ©ç”¨ä»¥å·¥ä»¶ä¸ºä¸­å¿ƒ (artifact-centric) çš„å»ºæ¨¡æ–¹æ³•ä¸ºè‡ªä¸»æ™ºèƒ½ä½“åˆ†é…æ˜ç¡®çš„è§’è‰²è¾¹ç•Œï¼Œå¹¶æ”¯æŒä»»åŠ¡ç‰¹å®šçš„æ¨¡å‹è·¯ç”±ä¸å®¡è®¡æ—¥å¿—ã€‚è®ºæ–‡æä¾›äº†å‚è€ƒæ¶æ„ä¸çœŸå®åº”ç”¨åŸå‹ï¼Œæ­ç¤ºäº† Agentic AI å¦‚ä½•åœ¨ç›‘ç®¡çº¦æŸä¸‹é‡æ„åˆè§„å·¥ä½œæµã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°†è‡ªåŠ¨åŒ–åµŒå…¥è´Ÿè´£ä»»çš„æ²»ç†ç»“æ„ä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡é«˜é£é™©ç›‘ç®¡ç¯å¢ƒä¸‹çš„é€æ˜åº¦ä¸åˆ¶åº¦ä¿¡ä»»ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at HICSS-59 (2026), forthcoming in Proceedings",
      "pdf_url": "https://arxiv.org/pdf/2509.13137v1",
      "published_date": "2025-09-16 14:53:51 UTC",
      "updated_date": "2025-09-16 14:53:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:51.364542+00:00"
    },
    {
      "arxiv_id": "2509.13132v1",
      "title": "An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios",
      "title_zh": "é¢å‘å¯†é›†å¤æ‚é©¾é©¶åœºæ™¯å¯¼èˆªçš„ä¸ç¡®å®šæ€§åŠ æƒå†³ç­– Transformer",
      "authors": [
        "Zhihao Zhang",
        "Chengyang Peng",
        "Minghao Zhu",
        "Ekim Yurtsever",
        "Keith A. Redmill"
      ],
      "abstract": "Autonomous driving in dense, dynamic environments requires decision-making systems that can exploit both spatial structure and long-horizon temporal dependencies while remaining robust to uncertainty. This work presents a novel framework that integrates multi-channel bird's-eye-view occupancy grids with transformer-based sequence modeling for tactical driving in complex roundabout scenarios. To address the imbalance between frequent low-risk states and rare safety-critical decisions, we propose the Uncertainty-Weighted Decision Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate per-token predictive entropy, which is then used as a weight in the student model's loss function. This mechanism amplifies learning from uncertain, high-impact states while maintaining stability across common low-risk transitions. Experiments in a roundabout simulator, across varying traffic densities, show that UWDT consistently outperforms other baselines in terms of reward, collision rate, and behavioral stability. The results demonstrate that uncertainty-aware, spatial-temporal transformers can deliver safer and more efficient decision-making for autonomous driving in complex traffic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯†é›†åŠ¨æ€ç¯å¢ƒä¸‹çš„è‡ªåŠ¨é©¾é©¶å†³ç­–éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºUncertainty-Weighted Decision Transformer (UWDT)çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹å¤æ‚ç¯å²›åœºæ™¯ä¸­çš„ç©ºé—´ç»“æ„å’Œé•¿æœŸæ—¶é—´ä¾èµ–é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆå¤šé€šé“é¸Ÿç°å›¾(Bird's-Eye-View)å ç”¨æ …æ ¼ä¸åŸºäºTransformerçš„åºåˆ—å»ºæ¨¡ï¼Œæ˜¾è‘—å¢å¼ºäº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨å¤æ‚äº¤é€šæµä¸­çš„æˆ˜æœ¯å†³ç­–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³å¸¸è§ä½é£é™©çŠ¶æ€ä¸ç¨€å°‘é«˜å½±å“å†³ç­–ä¹‹é—´çš„æ ·æœ¬ä¸å¹³è¡¡ï¼ŒUWDTåˆ©ç”¨å†»ç»“çš„Teacher Transformerè¯„ä¼°æ¯ä¸ªä»¤ç‰Œçš„é¢„æµ‹ç†µ(Predictive Entropy)ï¼Œå¹¶å°†å…¶ä½œä¸ºæƒé‡å¼•å…¥Studentæ¨¡å‹çš„æŸå¤±å‡½æ•°ä¸­ã€‚è¿™ç§æœºåˆ¶èƒ½å¤Ÿæ˜¾è‘—æ”¾å¤§æ¨¡å‹å¯¹ä¸ç¡®å®šä¸”é«˜å½±å“çŠ¶æ€çš„å­¦ä¹ æ•ˆç‡ï¼ŒåŒæ—¶ç¡®ä¿åœ¨å¸¸è§„åœºæ™¯ä¸‹çš„å­¦ä¹ ç¨³å®šæ€§ã€‚åœ¨å¤šç§äº¤é€šå¯†åº¦çš„ç¯å²›æ¨¡æ‹Ÿå®éªŒä¸­ï¼ŒUWDTåœ¨ç´¯è®¡å¥–åŠ±ã€ç¢°æ’ç‡é™ä½ä»¥åŠè¡Œä¸ºç¨³å®šæ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»“åˆä¸ç¡®å®šæ€§æ„ŸçŸ¥ä¸ç©ºæ—¶Transformerå»ºæ¨¡ï¼Œèƒ½ä¸ºå¤æ‚äº¤é€šç¯å¢ƒä¸­çš„è‡ªåŠ¨é©¾é©¶æä¾›æ›´å…·é²æ£’æ€§ä¸”é«˜æ•ˆçš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13132v1",
      "published_date": "2025-09-16 14:48:52 UTC",
      "updated_date": "2025-09-16 14:48:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:34.762764+00:00"
    },
    {
      "arxiv_id": "2509.13131v1",
      "title": "Reasoning with Preference Constraints: A Benchmark for Language Models in Many-to-One Matching Markets",
      "title_zh": "åå¥½çº¦æŸä¸‹çš„æ¨ç†ï¼šå¤šå¯¹ä¸€åŒ¹é…å¸‚åœºä¸­çš„è¯­è¨€æ¨¡å‹åŸºå‡†",
      "authors": [
        "Marylou Fauchard",
        "Florian Carichon",
        "Margarida Carvalho",
        "Golnoosh Farnadi"
      ],
      "abstract": "Recent advances in reasoning with large language models (LLMs) have demonstrated strong performance on complex mathematical tasks, including combinatorial optimization. Techniques such as Chain-of-Thought and In-Context Learning have further enhanced this capability, making LLMs both powerful and accessible tools for a wide range of users, including non-experts. However, applying LLMs to matching problems, which require reasoning under preferential and structural constraints, remains underexplored. To address this gap, we introduce a novel benchmark of 369 instances of the College Admission Problem, a canonical example of a matching problem with preferences, to evaluate LLMs across key dimensions: feasibility, stability, and optimality. We employ this benchmark to assess the performance of several open-weight LLMs. Our results first reveal that while LLMs can satisfy certain constraints, they struggle to meet all evaluation criteria consistently. They also show that reasoning LLMs, like QwQ and GPT-oss, significantly outperform traditional models such as Llama, Qwen or Mistral, defined here as models used without any dedicated reasoning mechanisms. Moreover, we observed that LLMs reacted differently to the various prompting strategies tested, which include Chain-of-Thought, In-Context Learning and role-based prompting, with no prompt consistently offering the best performance. Finally, we report the performances from iterative prompting with auto-generated feedback and show that they are not monotonic; they can peak early and then significantly decline in later attempts. Overall, this work offers a new perspective on model reasoning performance and the effectiveness of prompting strategies in combinatorial optimization problems with preferential constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŒ…å«369ä¸ª College Admission Problem å®ä¾‹çš„æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å…·æœ‰åå¥½å’Œç»“æ„çº¦æŸçš„åŒ¹é…é—®é¢˜ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚è¯¥åŸºå‡†ä»å¯è¡Œæ€§(feasibility)ã€ç¨³å®šæ€§(stability)å’Œæœ€ä¼˜æ€§(optimality)ä¸‰ä¸ªç»´åº¦ï¼Œå¯¹å¤šæ¬¾å¼€æº LLMs çš„æ€§èƒ½è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹èƒ½æ»¡è¶³éƒ¨åˆ†çº¦æŸï¼Œä½†åœ¨æŒç»­æ»¡è¶³æ‰€æœ‰è¯„ä¼°æ ‡å‡†æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚ç ”ç©¶å‘ç°ï¼Œå…·å¤‡ä¸“é—¨æ¨ç†æœºåˆ¶çš„æ¨¡å‹ï¼ˆå¦‚ QwQ å’Œ GPT-ossï¼‰åœ¨å¤„ç†æ­¤ç±»ä»»åŠ¡æ—¶æ˜¾è‘—ä¼˜äº Llamaã€Qwen æˆ– Mistral ç­‰ä¼ ç»Ÿæ¨¡å‹ã€‚åœ¨æç¤ºç­–ç•¥æ–¹é¢ï¼ŒChain-of-Thoughtã€In-Context Learning å’Œè§’è‰²æç¤º(role-based prompting)çš„æ•ˆæœå› æ¨¡å‹è€Œå¼‚ï¼Œæ²¡æœ‰ä¸€ç§ç­–ç•¥èƒ½å§‹ç»ˆä¿æŒæœ€ä½³è¡¨ç°ã€‚æ­¤å¤–ï¼Œå¸¦æœ‰è‡ªåŠ¨åé¦ˆçš„è¿­ä»£æç¤º(iterative prompting)è¡¨ç°å‡ºéå•è°ƒæ€§ï¼Œå…¶æ€§èƒ½å¾€å¾€åœ¨æ—©æœŸè¾¾åˆ°å³°å€¼åå‡ºç°æ˜¾è‘—ä¸‹æ»‘ã€‚è¯¥é¡¹å·¥ä½œä¸ºæ¢ç´¢ LLMs åœ¨åå¥½çº¦æŸä¸‹çš„ç»„åˆä¼˜åŒ–(combinatorial optimization)æ¨ç†è¡¨ç°åŠæç¤ºç­–ç•¥çš„æœ‰æ•ˆæ€§æä¾›äº†é‡è¦çš„åŸºå‡†å’Œè§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13131v1",
      "published_date": "2025-09-16 14:48:46 UTC",
      "updated_date": "2025-09-16 14:48:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:40.596781+00:00"
    },
    {
      "arxiv_id": "2511.14764v1",
      "title": "Image-Seeking Intent Prediction for Cross-Device Product Search",
      "title_zh": "è·¨è®¾å¤‡å•†å“æœç´¢ä¸­çš„å¯»å›¾æ„å›¾é¢„æµ‹",
      "authors": [
        "Mariya Hendriksen",
        "Svitlana Vakulenko",
        "Jordan Massiah",
        "Gabriella Kazai",
        "Emine Yilmaz"
      ],
      "abstract": "Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç”µå­å•†åŠ¡ç¯å¢ƒä¸­ï¼Œå¦‚ä½•ç²¾å‡†é¢„æµ‹ç”¨æˆ·ä½•æ—¶éœ€è¦ä»è¯­éŸ³äº¤äº’åˆ‡æ¢è‡³å…·å¤‡å±å¹•çš„è®¾å¤‡ä»¥è·å–è§†è§‰è¾…åŠ©ã€‚ç ”ç©¶è€…æå‡ºäº† Image-Seeking Intent Prediction (å›¾åƒå¯»æ±‚æ„å›¾é¢„æµ‹) è¿™ä¸€æ–°ä»»åŠ¡ï¼Œå¹¶å¼€å‘äº† IRP (Image Request Predictor) æ¨¡å‹ï¼Œé€šè¿‡åˆ†æç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢è¯­ä¹‰ (Query Semantics) ä¸æ£€ç´¢åˆ°çš„äº§å“å…ƒæ•°æ® (Product Metadata) æ¥é¢„åˆ¤è§†è§‰éœ€æ±‚ã€‚è¯¥æ¨¡å‹åŸºäºåŒ…å« 900K æ¡çœŸå®è¯­éŸ³æŸ¥è¯¢åŠå…¶åç»­è¡Œä¸ºä¿¡å·çš„å¤§è§„æ¨¡ç”Ÿäº§æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ç»“åˆäº†è½»é‡åŒ–æ€»ç»“æŠ€æœ¯ä¸å¯å¾®åˆ†çš„ç²¾åº¦å¯¼å‘æŸå¤± (Differentiable Precision-Oriented Loss) ä»¥æå‡é¢„æµ‹å‡†ç¡®æ€§å¹¶é™ä½è¯¯æŠ¥ (False Positives)ã€‚å®éªŒç»“æœè¯æ˜ï¼Œç»“åˆè¯­ä¹‰ä¸äº§å“å…ƒæ•°æ®çš„æ–¹æ³•èƒ½æœ‰æ•ˆæå‡è·¨è®¾å¤‡æœç´¢çš„é¢„æµ‹ç²¾åº¦ï¼Œä¸ºæ„å»ºèƒ½å¤Ÿä¸»åŠ¨æ„ŸçŸ¥å¹¶é€‚åº”ç”¨æˆ·éœ€æ±‚ã€æä¾›æ— ç¼ä¸ªæ€§åŒ–è´­ç‰©ä½“éªŒçš„ LLM é©±åŠ¨å‹åŠ©æ‰‹å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Oral at RecSys Gen AI for E-commerce 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.14764v1",
      "published_date": "2025-09-16 14:22:39 UTC",
      "updated_date": "2025-09-16 14:22:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:37.661123+00:00"
    },
    {
      "arxiv_id": "2509.13391v1",
      "title": "The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self",
      "title_zh": "è¢«æ‹¦æˆªçš„è‡ªæˆ‘ï¼šç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¦‚ä½•æŒ‘æˆ˜å…³ç³»è‡ªæˆ‘çš„åŠ¨æ€",
      "authors": [
        "Sandrine R. Schiller",
        "Camilo Miguel Signorelli",
        "Filippos Stamatiou"
      ],
      "abstract": "Generative AI is changing our way of interacting with technology, others, and ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple intelligence still awaits our prompt for action. Yet, it is likely that AI assistant systems will only become better at predicting our behaviour and acting on our behalf. Imagine new generations of generative and predictive AI deciding what you might like best at a new restaurant, picking an outfit that increases your chances on your date with a partner also chosen by the same or a similar system. Far from a science fiction scenario, the goal of several research programs is to build systems capable of assisting us in exactly this manner. The prospect urges us to rethink human-technology relations, but it also invites us to question how such systems might change the way we relate to ourselves. Building on our conception of the relational self, we question the possible effects of generative AI with respect to what we call the sphere of externalised output, the contextual sphere and the sphere of self-relating. In this paper, we attempt to deepen the existential considerations accompanying the AI revolution by outlining how generative AI enables the fulfilment of tasks and also increasingly anticipates, i.e. intercepts, our initiatives in these different spheres.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative AIï¼‰å¦‚ä½•æ·±åˆ»æ”¹å˜äººç±»ä¸æŠ€æœ¯ã€ä»–äººåŠè‡ªæˆ‘çš„äº’åŠ¨æ¨¡å¼ï¼Œç‰¹åˆ«æ˜¯AIç³»ç»Ÿä»è¢«åŠ¨å“åº”è½¬å‘ä¸»åŠ¨é¢„æµ‹å¹¶ä»£è¡Œäººç±»å†³ç­–çš„è¶‹åŠ¿ã€‚æ–‡ç« åŸºäºå…³ç³»æ€§è‡ªæˆ‘ï¼ˆrelational selfï¼‰çš„ç†è®ºæ¡†æ¶ï¼Œé‡ç‚¹åˆ†æäº†AIå¯¹å¤–éƒ¨åŒ–äº§å‡ºé¢†åŸŸï¼ˆsphere of externalised outputï¼‰ã€è¯­å¢ƒé¢†åŸŸï¼ˆcontextual sphereï¼‰ä»¥åŠè‡ªæˆ‘å…³è”é¢†åŸŸï¼ˆsphere of self-relatingï¼‰çš„æ½œåœ¨å½±å“ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç”Ÿæˆå¼AIåœ¨ååŠ©å®Œæˆä»»åŠ¡çš„åŒæ—¶ï¼Œæ­£æ—¥ç›Šé€šè¿‡é¢„æµ‹å’Œâ€œæˆªè·â€ï¼ˆinterceptï¼‰äººç±»çš„ä¸»åŠ¨æ€§æ¥é‡å¡‘ä¸ªä½“çš„å­˜åœ¨çŠ¶æ€ã€‚é€šè¿‡é˜è¿°è¿™ç§â€œè¢«æˆªè·çš„è‡ªæˆ‘â€ç°è±¡ï¼Œæœ¬æ–‡æ·±åŒ–äº†å¯¹AIé©å‘½å¼•å‘çš„å­˜åœ¨ä¸»ä¹‰æ€è€ƒï¼Œå¹¶æ•¦ä¿ƒé‡æ–°å®¡è§†äººç±»ä¸æŠ€æœ¯ä¹‹é—´çš„å…³ç³»åŠ¨æ€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and Society",
      "pdf_url": "https://arxiv.org/pdf/2509.13391v1",
      "published_date": "2025-09-16 14:07:39 UTC",
      "updated_date": "2025-09-16 14:07:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:43.258681+00:00"
    },
    {
      "arxiv_id": "2509.13107v1",
      "title": "Hierarchical Deep Fusion Framework for Multi-dimensional Facial Forgery Detection - The 2024 Global Deepfake Image Detection Challenge",
      "title_zh": "é¢å‘å¤šç»´äººè„¸ä¼ªé€ æ£€æµ‹çš„å±‚çº§æ·±åº¦èåˆæ¡†æ¶â€”â€”2024å¹´å…¨çƒæ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹æŒ‘æˆ˜èµ›",
      "authors": [
        "Kohou Wang",
        "Huan Hu",
        "Xiang Liu",
        "Zezhou Chen",
        "Ping Chen",
        "Zhaoxiang Liu",
        "Shiguo Lian"
      ],
      "abstract": "The proliferation of sophisticated deepfake technology poses significant challenges to digital security and authenticity. Detecting these forgeries, especially across a wide spectrum of manipulation techniques, requires robust and generalized models. This paper introduces the Hierarchical Deep Fusion Framework (HDFF), an ensemble-based deep learning architecture designed for high-performance facial forgery detection. Our framework integrates four diverse pre-trained sub-models, Swin-MLP, CoAtNet, EfficientNetV2, and DaViT, which are meticulously fine-tuned through a multi-stage process on the MultiFFDI dataset. By concatenating the feature representations from these specialized models and training a final classifier layer, HDFF effectively leverages their collective strengths. This approach achieved a final score of 0.96852 on the competition's private leaderboard, securing the 20th position out of 184 teams, demonstrating the efficacy of hierarchical fusion for complex image classification tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ deepfake æŠ€æœ¯çš„æ³›æ»¥æå‡ºäº† Hierarchical Deep Fusion Framework (HDFF)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡äººè„¸ä¼ªé€ æ£€æµ‹æ€§èƒ½çš„åˆ†å±‚æ·±åº¦èåˆæ¶æ„ã€‚è¯¥æ¡†æ¶é‡‡ç”¨é›†æˆå­¦ä¹ ç­–ç•¥ï¼Œæ•´åˆäº† Swin-MLPã€CoAtNetã€EfficientNetV2 å’Œ DaViT å››ä¸ªé¢„è®­ç»ƒå­æ¨¡å‹ï¼Œå¹¶é€šè¿‡åœ¨ MultiFFDI æ•°æ®é›†ä¸Šçš„å¤šé˜¶æ®µç²¾ç»†å¾®è°ƒæ¥ä¼˜åŒ–æ€§èƒ½ã€‚HDFF é€šè¿‡æ‹¼æ¥è¿™äº›å¼‚æ„æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºå¹¶è®­ç»ƒé¡¶å±‚åˆ†ç±»å™¨ï¼Œå……åˆ†åˆ©ç”¨äº†å„æ¨¡å‹åœ¨ç‰¹å¾æå–ä¸Šçš„é›†ä½“ä¼˜åŠ¿ã€‚åœ¨ 2024 å¹´å…¨çƒ Deepfake å›¾åƒæ£€æµ‹æŒ‘æˆ˜èµ›ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ 184 æ”¯å‚èµ›é˜Ÿä¼ä¸­è„±é¢–è€Œå‡ºï¼Œä»¥ 0.96852 çš„å¾—åˆ†è·å¾—ç§æœ‰æ’è¡Œæ¦œç¬¬ 20 åã€‚è¿™ä¸€ç»“æœå……åˆ†è¯æ˜äº†åˆ†å±‚èåˆæŠ€æœ¯åœ¨åº”å¯¹å¤æ‚ã€å¤šæ ·çš„å›¾åƒä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸­çš„å“è¶Šæœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The 2024 Global Deepfake Image Detection Challenge Top20 Reward, 5 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.13107v1",
      "published_date": "2025-09-16 14:06:54 UTC",
      "updated_date": "2025-09-16 14:06:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:54.458280+00:00"
    },
    {
      "arxiv_id": "2509.13390v1",
      "title": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds",
      "title_zh": "åŸºäºé¢†åŸŸçŸ¥è¯†çš„ç”µåŠ¨æ±½è½¦è½¦å†…å£°éŸ³å¼‚å¸¸æ£€æµ‹æ–¹æ³•",
      "authors": [
        "Deepti Kunte",
        "Bram Cornelis",
        "Claudio Colangeli",
        "Karl Janssens",
        "Brecht Van Baelen",
        "Konstantinos Gryllias"
      ],
      "abstract": "The detection of anomalies in automotive cabin sounds is critical for ensuring vehicle quality and maintaining passenger comfort. In many real-world settings, this task is more appropriately framed as an unsupervised learning problem rather than the supervised case due to the scarcity or complete absence of labeled faulty data. In such an unsupervised setting, the model is trained exclusively on healthy samples and detects anomalies as deviations from normal behavior. However, in the absence of labeled faulty samples for validation and the limited reliability of commonly used metrics, such as validation reconstruction error, effective model selection remains a significant challenge. To overcome these limitations, a domain-knowledge-informed approach for model selection is proposed, in which proxy-anomalies engineered through structured perturbations of healthy spectrograms are used in the validation set to support model selection. The proposed methodology is evaluated on a high-fidelity electric vehicle dataset comprising healthy and faulty cabin sounds across five representative fault types viz., Imbalance, Modulation, Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced sound synthesis techniques, and validated via expert jury assessments, has been made publicly available to facilitate further research. Experimental evaluations on the five fault cases demonstrate the selection of optimal models using proxy-anomalies, significantly outperform conventional model selection strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ¨æ±½è½¦ï¼ˆEVï¼‰åº§èˆ±å¼‚å¸¸å£°éŸ³æ£€æµ‹ä¸­ç”±äºæ•…éšœæ•°æ®ç¨€ç¼ºå¯¼è‡´çš„æ— ç›‘ç£å­¦ä¹ æ¨¡å‹é€‰æ‹©å›°éš¾ï¼Œæå‡ºäº†ä¸€ç§é¢†åŸŸçŸ¥è¯†é©±åŠ¨çš„åˆ›æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä»£ç†å¼‚å¸¸ï¼ˆproxy-anomaliesï¼‰çš„æ¦‚å¿µï¼Œé€šè¿‡å¯¹å¥åº·æ ·æœ¬çš„å£°è°±å›¾ï¼ˆspectrogramsï¼‰è¿›è¡Œç»“æ„åŒ–æ‰°åŠ¨æ¥å·¥ç¨‹åŒ–æ„å»ºéªŒè¯é›†ï¼Œä»¥è¾…åŠ©æ¨¡å‹ä¼˜é€‰ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å…ˆè¿›çš„å£°éŸ³åˆæˆæŠ€æœ¯å¹¶ç»“åˆä¸“å®¶è¯„å®¡ï¼Œæ„å»ºå¹¶å¼€æºäº†ä¸€ä¸ªæ¶µç›–ä¸å¹³è¡¡ï¼ˆImbalanceï¼‰ã€è°ƒåˆ¶ï¼ˆModulationï¼‰ã€å•¸å«ï¼ˆWhineï¼‰ã€é£å™ªï¼ˆWindï¼‰å’Œè„‰å†²å®½åº¦è°ƒåˆ¶ï¼ˆPulse Width Modulationï¼‰äº”ç§å…¸å‹æ•…éšœç±»å‹çš„é«˜ä¿çœŸç”µåŠ¨æ±½è½¦æ•°æ®é›†ã€‚å®éªŒè¯„ä¼°è¯æ˜ï¼ŒåŸºäºä»£ç†å¼‚å¸¸çš„æ¨¡å‹é€‰æ‹©ç­–ç•¥åœ¨äº”ç§æ•…éšœåœºæ™¯ä¸‹çš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºåŸºäºéªŒè¯é‡æ„è¯¯å·®ï¼ˆreconstruction errorï¼‰ç­‰ä¼ ç»Ÿç­–ç•¥ã€‚è¯¥æˆæœä¸ºåœ¨ç¼ºä¹çœŸå®æ•…éšœæ ‡ç­¾çš„æ— ç›‘ç£ç¯å¢ƒä¸‹ï¼Œæå‡åº§èˆ±å£°éŸ³å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§ä¸å¯é æ€§æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to: Mechanical Systems and Signal Processing",
      "pdf_url": "https://arxiv.org/pdf/2509.13390v1",
      "published_date": "2025-09-16 14:04:22 UTC",
      "updated_date": "2025-09-16 14:04:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:53.856695+00:00"
    },
    {
      "arxiv_id": "2509.13389v3",
      "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results",
      "title_zh": "ä»ä¸‹ä¸€ Token é¢„æµ‹åˆ° (STRIPS) ä¸–ç•Œæ¨¡å‹ï¼šåˆæ­¥ç»“æœ",
      "authors": [
        "Carlos NÃºÃ±ez-Molina",
        "VicenÃ§ GÃ³mez",
        "Hector Geffner"
      ],
      "abstract": "We consider the problem of learning propositional STRIPS world models from action traces alone, using a deep learning architecture (transformers) and gradient descent. The task is cast as a supervised next token prediction problem where the tokens are the actions, and an action $a$ may follow an action sequence if the hidden effects of the previous actions do not make an action precondition of $a$ false. We show that a suitable transformer architecture can faithfully represent propositional STRIPS world models, and that the models can be learned from sets of random valid (positive) and invalid (negative) action sequences alone. A number of experiments are reported.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•ä»…é€šè¿‡åŠ¨ä½œè½¨è¿¹(action traces)å­¦ä¹ å‘½é¢˜å¼ STRIPS ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªç›‘ç£å¼çš„ Next Token Prediction é—®é¢˜ã€‚ä½œè€…é‡‡ç”¨åŸºäº Transformers çš„æ·±åº¦å­¦ä¹ æ¶æ„å’Œæ¢¯åº¦ä¸‹é™(gradient descent)è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå…¶ä¸­ Token ä»£è¡¨åŠ¨ä½œã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œå¦‚æœå…ˆå‰åŠ¨ä½œçš„éšè—æ•ˆæœæ²¡æœ‰å¯¼è‡´å½“å‰åŠ¨ä½œçš„å‰ç½®æ¡ä»¶(action precondition)å¤±æ•ˆï¼Œåˆ™è¯¥åŠ¨ä½œå¯ä»¥ç´§éšåŠ¨ä½œåºåˆ—ä¹‹åã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåˆé€‚çš„ Transformer æ¶æ„èƒ½å¤Ÿå¿ å®åœ°è¡¨ç¤ºå‘½é¢˜å¼ STRIPS ä¸–ç•Œæ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜è¿™äº›æ¨¡å‹å¯ä»¥ä»…é€šè¿‡éšæœºç”Ÿæˆçš„æœ‰æ•ˆï¼ˆæ­£å‘ï¼‰å’Œæ— æ•ˆï¼ˆè´Ÿå‘ï¼‰åŠ¨ä½œåºåˆ—é›†åˆè¿›è¡Œå­¦ä¹ ã€‚è¯¥é¡¹åˆæ­¥ç ”ç©¶é€šè¿‡å¤šé¡¹å®éªŒéªŒè¯äº†åˆ©ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•è‡ªåŠ¨åŒ–æ„å»ºç»å…¸è§„åˆ’æ¨¡å‹çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.13389v3",
      "published_date": "2025-09-16 14:03:58 UTC",
      "updated_date": "2025-10-20 14:57:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:55.042046+00:00"
    },
    {
      "arxiv_id": "2509.13388v2",
      "title": "Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji",
      "title_zh": "åŸºäºé¥æ„Ÿä¸æœºå™¨å­¦ä¹ çš„åœŸåœ°è¦†ç›–åˆ†ç±»åŠå˜åŒ–æ£€æµ‹ï¼šä»¥ Western Fiji ä¸ºä¾‹",
      "authors": [
        "Yadvendra Gurjar",
        "Ruoni Wan",
        "Ehsan Farahbakhsh",
        "Rohitash Chandra"
      ],
      "abstract": "As a developing country, Fiji is facing rapid urbanisation, which is visible in the massive development projects that include housing, roads, and civil works. In this study, we present machine learning and remote sensing frameworks to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The ultimate goal of this study is to provide technical support in land cover/land use modelling and change detection. We used Landsat-8 satellite image for the study region and created our training dataset with labels for supervised machine learning. We used Google Earth Engine and unsupervised machine learning via k-means clustering to generate the land cover map. We used convolutional neural networks to classify the selected regions' land cover types. We present a visualisation of change detection, highlighting urban area changes over time to monitor changes in the map.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–æµï¼ˆFijiï¼‰çº³è¿ªï¼ˆNadiï¼‰åœ°åŒºçš„å¿«é€ŸåŸå¸‚åŒ–è¿›ç¨‹ï¼Œåˆ©ç”¨é¥æ„ŸæŠ€æœ¯å’Œæœºå™¨å­¦ä¹ æ¡†æ¶å¯¹æ¯”äº†2013å¹´è‡³2024å¹´é—´çš„åœŸåœ°åˆ©ç”¨å’ŒåœŸåœ°è¦†ç›–å˜åŒ–ï¼ˆland use and land cover changeï¼‰ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨Landsat-8å«æ˜Ÿå½±åƒæ„å»ºäº†ç›‘ç£å­¦ä¹ æ•°æ®é›†ï¼Œå¹¶ç»“åˆGoogle Earth Engineå¹³å°ä¸k-meansèšç±»ç®—æ³•ç”Ÿæˆåˆå§‹åœŸåœ°è¦†ç›–å›¾ã€‚éšåï¼Œè¯¥ç ”ç©¶åº”ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆconvolutional neural networks, CNNï¼‰å¯¹ç‰¹å®šåŒºåŸŸçš„åœŸåœ°ç±»å‹è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å®ç°äº†å˜åŒ–æ£€æµ‹ï¼ˆchange detectionï¼‰çš„å¯è§†åŒ–ã€‚ç ”ç©¶é‡ç‚¹å±•ç¤ºäº†åŸå¸‚åŒºåŸŸéšæ—¶é—´æ¼”å˜çš„åŠ¨æ€è¿‡ç¨‹ï¼Œä¸ºè¯¥åœ°åŒºçš„åœŸåœ°è¦†ç›–å»ºæ¨¡å’Œç¯å¢ƒç›‘æµ‹æä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æ’‘ä¸å®è¯åˆ†æã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13388v2",
      "published_date": "2025-09-16 13:58:07 UTC",
      "updated_date": "2025-10-02 10:28:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:53:57.784064+00:00"
    },
    {
      "arxiv_id": "2509.13081v1",
      "title": "Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO",
      "title_zh": "å¡‘é€ è§£é‡Šï¼šåŸºäºä»…ç¼–ç å™¨ Transformer çš„ GRPO è¯­ä¹‰å¥–åŠ±å»ºæ¨¡",
      "authors": [
        "Francesco Pappone",
        "Ruggero Marino Lazzaroni",
        "Federico Califano",
        "NiccolÃ² Gentile",
        "Roberto Marras"
      ],
      "abstract": "While Large Language Models (LLMs) excel at generating human-like text, aligning their outputs with complex, qualitative goals like pedagogical soundness remains a significant challenge. Standard reinforcement learning techniques often rely on slow and expensive LLM-as-a-judge evaluations or on brittle, keyword-based metrics like ROUGE, which fail to capture the semantic essence of a high-quality explanation. In this work, we introduce a novel approach to reward shaping within the Group Relative Policy Optimisation (GRPO) framework. Our central contribution is the use of a small, efficient encoder-only transformer as a semantic reward model. This model provides a dense, semantically rich reward signal based on the cosine similarity between a generated explanation and a ground-truth reference, guiding the policy towards explanations that are not just factually correct but also structurally and conceptually aligned with expert reasoning. We apply this method to the task of training a model for the Italian medical-school entrance examinations, following standard domain-adaptive continued pre-training (CPT) and supervised fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic reward significantly improves explanation faithfulness and clarity over a strong SFT baseline, showcasing the power of using lightweight encoder models for nuanced reward shaping in complex generation tasks",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¯¹é½å¤æ‚å®šæ€§ç›®æ ‡ï¼ˆå¦‚æ•™å­¦åˆç†æ€§ï¼‰æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åœ¨Group Relative Policy Optimisation (GRPO)æ¡†æ¶ä¸‹çš„æ–°å‹å¥–åŠ±å¡‘é€ æ–¹æ³•ã€‚å…¶æ ¸å¿ƒè´¡çŒ®æ˜¯é‡‡ç”¨å°å‹ã€é«˜æ•ˆçš„Encoder-Only Transformersä½œä¸ºè¯­ä¹‰å¥–åŠ±æ¨¡å‹ï¼Œé€šè¿‡è®¡ç®—ç”Ÿæˆè§£é‡Šä¸æ ‡å‡†å‚è€ƒç­”æ¡ˆä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆCosine Similarityï¼‰æ¥æä¾›å¯†é›†çš„è¯­ä¹‰å¥–åŠ±ä¿¡å·ã€‚è¿™ç§æ–¹æ³•å¼•å¯¼ç­–ç•¥ç”Ÿæˆçš„è§£é‡Šä¸ä»…åœ¨äº‹å®å±‚é¢å‡†ç¡®ï¼Œä¸”åœ¨ç»“æ„å’Œæ¦‚å¿µä¸Šä¸ä¸“å®¶æ¨ç†é€»è¾‘ä¿æŒå¯¹é½ã€‚ç ”ç©¶å›¢é˜Ÿå°†è¯¥æ–¹æ³•åº”ç”¨äºæ„å¤§åˆ©åŒ»å­¦é™¢å…¥å­¦è€ƒè¯•ä»»åŠ¡ï¼Œåœ¨é¢†åŸŸè‡ªé€‚åº”æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„åŸºç¡€ä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆè¯­ä¹‰å¥–åŠ±çš„GRPOåœ¨è§£é‡Šçš„å¿ å®åº¦ï¼ˆFaithfulnessï¼‰å’Œæ¸…æ™°åº¦ä¸Šç›¸æ¯”å¼ºåŠ›SFTåŸºçº¿æœ‰æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨è½»é‡çº§ç¼–ç å™¨æ¨¡å‹åœ¨å¤æ‚ç”Ÿæˆä»»åŠ¡ä¸­å®ç°ç²¾ç»†åŒ–å¥–åŠ±å¡‘é€ çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13081v1",
      "published_date": "2025-09-16 13:39:29 UTC",
      "updated_date": "2025-09-16 13:39:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:09.291936+00:00"
    },
    {
      "arxiv_id": "2509.13077v1",
      "title": "A Design Co-Pilot for Task-Tailored Manipulators",
      "title_zh": "ä»»åŠ¡å®šåˆ¶å‹æœºæ¢°è‡‚çš„è®¾è®¡å‰¯é©¾é©¶",
      "authors": [
        "Jonathan KÃ¼lz",
        "Sehoon Ha",
        "Matthias Althoff"
      ],
      "abstract": "Although robotic manipulators are used in an ever-growing range of applications, robot manufacturers typically follow a ``one-fits-all'' philosophy, employing identical manipulators in various settings. This often leads to suboptimal performance, as general-purpose designs fail to exploit particularities of tasks. The development of custom, task-tailored robots is hindered by long, cost-intensive development cycles and the high cost of customized hardware. Recently, various computational design methods have been devised to overcome the bottleneck of human engineering. In addition, a surge of modular robots allows quick and economical adaptation to changing industrial settings. This work proposes an approach to automatically designing and optimizing robot morphologies tailored to a specific environment. To this end, we learn the inverse kinematics for a wide range of different manipulators. A fully differentiable framework realizes gradient-based fine-tuning of designed robots and inverse kinematics solutions. Our generative approach accelerates the generation of specialized designs from hours with optimization-based methods to seconds, serving as a design co-pilot that enables instant adaptation and effective human-AI collaboration. Numerical experiments show that our approach finds robots that can navigate cluttered environments, manipulators that perform well across a specified workspace, and can be adapted to different hardware constraints. Finally, we demonstrate the real-world applicability of our method by setting up a modular robot designed in simulation that successfully moves through an obstacle course.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨æœºå™¨äººæœºæ¢°è‡‚åœ¨ç‰¹å®šä»»åŠ¡ä¸­è¡¨ç°æ¬ ä½³ä¸”å®šåˆ¶å¼€å‘æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªåŠ¨è®¾è®¡å’Œä¼˜åŒ–ç‰¹å®šç¯å¢ƒå®šåˆ¶åŒ–æœºå™¨äººå½¢æ€çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä¸ºå¤šç§æœºæ¢°è‡‚å­¦ä¹ é€†è¿åŠ¨å­¦(Inverse Kinematics)ï¼Œå¹¶åˆ©ç”¨å…¨å¾®åˆ†æ¡†æ¶(Fully Differentiable Framework)å®ç°åŸºäºæ¢¯åº¦çš„æœºå™¨äººè®¾è®¡ä¸é€†è¿åŠ¨å­¦è§£çš„åœ¨çº¿å¾®è°ƒã€‚è¿™ç§ç”Ÿæˆå¼æ–¹æ³•(Generative Approach)å°†ä¸“ç”¨è®¾è®¡çš„ç”Ÿæˆæ—¶é—´ä»æ•°å°æ—¶ç¼©çŸ­è‡³å‡ ç§’é’Ÿï¼Œä½œä¸ºè®¾è®¡å‰¯é©¾é©¶(Design Co-Pilot)å®ç°äº†å³æ—¶é€‚é…ä¸é«˜æ•ˆçš„äººæœºåä½œã€‚æ•°å€¼å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„æœºå™¨äººèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ‚ä¹±ç¯å¢ƒã€è¦†ç›–ç‰¹å®šå·¥ä½œç©ºé—´å¹¶é€‚åº”ä¸åŒçš„ç¡¬ä»¶çº¦æŸ(Hardware Constraints)ã€‚æœ€åï¼Œç ”ç©¶é€šè¿‡åœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²ä»¿çœŸè®¾è®¡çš„æ¨¡å—åŒ–æœºå™¨äºº(Modular Robot)å¹¶æˆåŠŸå®Œæˆé¿éšœä»»åŠ¡ï¼ŒéªŒè¯äº†è¯¥æ–¹æ¡ˆåœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13077v1",
      "published_date": "2025-09-16 13:34:30 UTC",
      "updated_date": "2025-09-16 13:34:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:22.052355+00:00"
    },
    {
      "arxiv_id": "2510.21720v2",
      "title": "A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue",
      "title_zh": "è®¡ç®—å¿ƒç†å­¦å¤šç»„ä»¶äººå·¥æ™ºèƒ½æ¡†æ¶ï¼šä»ç¨³å¥é¢„æµ‹å»ºæ¨¡åˆ°ç”Ÿæˆå¼å¯¹è¯éƒ¨ç½²",
      "authors": [
        "Anant Pareek"
      ],
      "abstract": "The confluence of Artificial Intelligence and Computational Psychology presents an opportunity to model, understand, and interact with complex human psychological states through computational means. This paper presents a comprehensive, multi-faceted framework designed to bridge the gap between isolated predictive modeling and an interactive system for psychological analysis. The methodology encompasses a rigorous, end-to-end development lifecycle. First, foundational performance benchmarks were established on four diverse psychological datasets using classical machine learning techniques. Second, state-of-the-art transformer models were fine-tuned, a process that necessitated the development of effective solutions to overcome critical engineering challenges, including the resolution of numerical instability in regression tasks and the creation of a systematic workflow for conducting large-scale training under severe resource constraints. Third, a generative large language model (LLM) was fine-tuned using parameter-efficient techniques to function as an interactive \"Personality Brain.\" Finally, the entire suite of predictive and generative models was architected and deployed as a robust, scalable microservices ecosystem. Key findings include the successful stabilization of transformer-based regression models for affective computing, showing meaningful predictive performance where standard approaches failed, and the development of a replicable methodology for democratizing large-scale AI research. The significance of this work lies in its holistic approach, demonstrating a complete research-to-deployment pipeline that integrates predictive analysis with generative dialogue, thereby providing a practical model for future research in computational psychology and human-AI interaction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé¢å‘è®¡ç®—å¿ƒç†å­¦(Computational Psychology)çš„å¤šç»„ä»¶AIæ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥å­¤ç«‹çš„é¢„æµ‹å»ºæ¨¡ä¸äº¤äº’å¼å¿ƒç†åˆ†æç³»ç»Ÿä¹‹é—´çš„ç©ºç™½ã€‚å¼€å‘è¿‡ç¨‹æ¶µç›–äº†ä»åŸºç¡€æœºå™¨å­¦ä¹ (Machine Learning)åŸºå‡†æµ‹è¯•åˆ°å¾®è°ƒæœ€å…ˆè¿›çš„Transformeræ¨¡å‹ï¼Œå¹¶æœ‰æ•ˆè§£å†³äº†å›å½’ä»»åŠ¡ä¸­çš„æ•°å€¼ä¸ç¨³å®š(Numerical Instability)ä»¥åŠèµ„æºå—é™ä¸‹çš„è®­ç»ƒæµç¨‹ç­‰å…³é”®å·¥ç¨‹æŒ‘æˆ˜ã€‚ç ”ç©¶é€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒ(Parameter-efficient Fine-tuning)æŠ€æœ¯ï¼Œå¾®è°ƒäº†ä¸€ä¸ªç”Ÿæˆå¼å¤§è¯­è¨€æ¨¡å‹(LLM)ä»¥å……å½“äº¤äº’å¼çš„â€œæ€§æ ¼å¤§è„‘â€(Personality Brain)ã€‚æ•´ä¸ªé¢„æµ‹ä¸ç”Ÿæˆæ¨¡å‹å¥—ä»¶æœ€ç»ˆè¢«éƒ¨ç½²ä¸ºä¸€ä¸ªå¥å£®ä¸”å¯æ‰©å±•çš„å¾®æœåŠ¡(Microservices)ç”Ÿæ€ç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æƒ…æ„Ÿè®¡ç®—(Affective Computing)é¢†åŸŸæˆåŠŸç¨³å®šäº†åŸºäºTransformerçš„å›å½’æ¨¡å‹ï¼Œåœ¨ä¼ ç»Ÿæ–¹æ³•å¤±æ•ˆçš„åœºæ™¯ä¸‹å±•ç°äº†ä¼˜å¼‚çš„é¢„æµ‹æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æ•´åˆé¢„æµ‹åˆ†æä¸ç”Ÿæˆå¯¹è¯ï¼Œå±•ç¤ºäº†ä»ç ”ç©¶åˆ°éƒ¨ç½²çš„å®Œæ•´æµæ°´çº¿ï¼Œä¸ºæœªæ¥äººæœºäº¤äº’(Human-AI Interaction)ç ”ç©¶æä¾›äº†å¯å¤åˆ¶çš„å®è·µæ¨¡å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.21720v2",
      "published_date": "2025-09-16 13:33:40 UTC",
      "updated_date": "2025-12-15 09:34:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:24.875250+00:00"
    },
    {
      "arxiv_id": "2509.13070v1",
      "title": "TFANet: Three-Stage Image-Text Feature Alignment Network for Robust Referring Image Segmentation",
      "title_zh": "TFANetï¼šé¢å‘é²æ£’æŒ‡ä»£æ€§å›¾åƒåˆ†å‰²çš„ä¸‰é˜¶æ®µå›¾æ–‡ç‰¹å¾å¯¹é½ç½‘ç»œ",
      "authors": [
        "Qianqi Lu",
        "Yuxiang Xie",
        "Jing Zhang",
        "Shiwei Zou",
        "Yan Chen",
        "Xidao Luan"
      ],
      "abstract": "Referring Image Segmentation (RIS) is a task that segments image regions based on language expressions, requiring fine-grained alignment between two modalities. However, existing methods often struggle with multimodal misalignment and language semantic loss, especially in complex scenes containing multiple visually similar objects, where uniquely described targets are frequently mislocalized or incompletely segmented. To tackle these challenges, this paper proposes TFANet, a Three-stage Image-Text Feature Alignment Network that systematically enhances multimodal alignment through a hierarchical framework comprising three stages: Knowledge Plus Stage (KPS), Knowledge Fusion Stage (KFS), and Knowledge Intensification Stage (KIS). In the first stage, we design the Multiscale Linear Cross-Attention Module (MLAM), which facilitates bidirectional semantic exchange between visual features and textual representations across multiple scales. This establishes rich and efficient alignment between image regions and different granularities of linguistic descriptions. Subsequently, the KFS further strengthens feature alignment through the Cross-modal Feature Scanning Module (CFSM), which applies multimodal selective scanning to capture long-range dependencies and construct a unified multimodal representation. This is essential for modeling long-range cross-modal dependencies and enhancing alignment accuracy in complex scenes. Finally, in the KIS, we propose the Word-level Linguistic Feature-guided Semantic Deepening Module (WFDM) to compensate for semantic degradation introduced in earlier stages.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TFANetï¼Œä¸€ç§ä¸‰é˜¶æ®µå›¾åƒ-æ–‡æœ¬ç‰¹å¾å¯¹é½ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³Referring Image Segmentation (RIS)ä»»åŠ¡ä¸­å­˜åœ¨çš„è·¨æ¨¡æ€å¯¹é½ä¸è‰¯å’Œè¯­è¨€è¯­ä¹‰ç¼ºå¤±é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ…å«å¤šä¸ªç›¸ä¼¼ç›®æ ‡çš„å¤æ‚åœºæ™¯ä¸‹ã€‚åœ¨Knowledge Plus Stage (KPS)é˜¶æ®µï¼Œè¯¥ç½‘ç»œé€šè¿‡Multiscale Linear Cross-Attention Module (MLAM)åœ¨å¤šå°ºåº¦ä¸Šå®ç°è§†è§‰ç‰¹å¾ä¸æ–‡æœ¬è¡¨ç¤ºçš„åŒå‘è¯­ä¹‰äº¤æ¢ï¼Œå»ºç«‹äº†å›¾åƒåŒºåŸŸä¸è¯­è¨€æè¿°ä¹‹é—´çš„ä¸°å¯Œå¯¹é½ã€‚éšååœ¨Knowledge Fusion Stage (KFS)ä¸­ï¼Œåˆ©ç”¨Cross-modal Feature Scanning Module (CFSM)æ‰§è¡Œå¤šæ¨¡æ€é€‰æ‹©æ€§æ‰«æä»¥æ•æ‰è¿œç¨‹ä¾èµ–å…³ç³»ï¼Œæ„å»ºç»Ÿä¸€çš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚æœ€åï¼Œåœ¨Knowledge Intensification Stage (KIS)é˜¶æ®µï¼Œç ”ç©¶è€…è®¾è®¡äº†Word-level Linguistic Feature-guided Semantic Deepening Module (WFDM)æ¥è¡¥å¿å‰æœŸå¤„ç†ä¸­å¯èƒ½å‡ºç°çš„è¯­ä¹‰é€€åŒ–ã€‚é€šè¿‡è¿™ç§å±‚çº§åŒ–çš„ä¸‰é˜¶æ®µæ¡†æ¶ï¼ŒTFANetèƒ½å¤Ÿç³»ç»Ÿåœ°å¼ºåŒ–å¤šæ¨¡æ€ç‰¹å¾å¯¹é½ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸­å®ç°äº†å¯¹ç‰¹å®šæè¿°ç›®æ ‡æ›´ä¸ºé²æ£’ä¸”ç²¾ç¡®çš„åˆ†å‰²ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13070v1",
      "published_date": "2025-09-16 13:26:58 UTC",
      "updated_date": "2025-09-16 13:26:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:27.650017+00:00"
    },
    {
      "arxiv_id": "2509.13047v1",
      "title": "Multi-Model Synthetic Training for Mission-Critical Small Language Models",
      "title_zh": "é¢å‘ä»»åŠ¡å…³é”®å‹å°è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡å‹åˆæˆè®­ç»ƒ",
      "authors": [
        "Nolan Platt",
        "Pragyansmita Nayak"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across many domains, yet their appli- cation to specialized fields remains constrained by the scarcity and complexity of domain-specific training data. We present a novel approach that achieves a 261x cost reduction for maritime intelligence by using LLMs as one-time teachers rather than using them directly for inference. Our method transforms 3.2 billion Automatic Identification System (AIS) vessel tracking records into 21,543 synthetic question and answer pairs through multi-model generation (GPT-4o and o3-mini), preventing over- fitting and ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves 75% accuracy on maritime tasks, while being substantially cheaper than using a larger model for inference. We show that smaller, cheaper models - when fine tuned properly - can provide similar accuracy compared to larger models that are prohibitively expensive. Our work contributes to the growing field of synthetic dataset generation for specialized AI applications and presents a highly reproducible framework for domains where manual annotation is infeasible. Beyond expand- ing research in the growing field of specialized small language models, our approach has immediate applications in maritime safety, security operations, and vessel traffic management systems in various industries.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ä»»åŠ¡å…³é”®å‹å°å‹è¯­è¨€æ¨¡å‹(Small Language Models)çš„å¤šæ¨¡å‹åˆæˆè®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æµ·äº‹é¢†åŸŸç‰¹å®šè®­ç»ƒæ•°æ®ç¨€ç¼ºä¸”å¤æ‚çš„é—®é¢˜ã€‚é€šè¿‡å°†Large Language Models (LLMs)ä½œä¸ºä¸€æ¬¡æ€§å¯¼å¸ˆè€Œéç›´æ¥ç”¨äºæ¨ç†ï¼Œè¯¥æ–¹æ³•å®ç°äº†æµ·äº‹æ™ºèƒ½é¢†åŸŸ261å€çš„æˆæœ¬é™ä½ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨GPT-4oå’Œo3-miniçš„å¤šæ¨¡å‹ç”ŸæˆæŠ€æœ¯ï¼Œå°†32äº¿æ¡è‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿ(Automatic Identification System, AIS)èˆ¹èˆ¶è·Ÿè¸ªè®°å½•è½¬åŒ–ä¸º21,543ä¸ªåˆæˆé—®ç­”å¯¹ï¼Œæœ‰æ•ˆé˜²æ­¢äº†è¿‡æ‹Ÿåˆå¹¶ç¡®ä¿äº†æ¨ç†çš„å‡†ç¡®æ€§ã€‚å®éªŒè¯æ˜ï¼Œç»å¾®è°ƒçš„Qwen2.5-7Bæ¨¡å‹åœ¨æµ·äº‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†75%çš„å‡†ç¡®ç‡ï¼Œå…¶è¡¨ç°å¯ä¸æˆæœ¬é«˜æ˜‚çš„å¤§å‹æ¨¡å‹ç›¸åª²ç¾ã€‚è¯¥å·¥ä½œä¸ºç¼ºä¹æ‰‹åŠ¨æ ‡æ³¨æ•°æ®çš„ä¸“ä¸šAIåº”ç”¨é¢†åŸŸæä¾›äº†ä¸€ä¸ªé«˜åº¦å¯å¤ç°çš„æ¡†æ¶ï¼Œå¹¶åœ¨æµ·äº‹å®‰å…¨ã€å®‰ä¿è¿è¥å’Œèˆ¹èˆ¶äº¤é€šç®¡ç†ç³»ç»Ÿä¸­å…·æœ‰ç›´æ¥çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages. Accepted as a full paper to the 3rd International Conference on Foundation and Large Language Models (IEEE FLLM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.13047v1",
      "published_date": "2025-09-16 13:04:48 UTC",
      "updated_date": "2025-09-16 13:04:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:34.773812+00:00"
    },
    {
      "arxiv_id": "2509.13046v2",
      "title": "MIA-EPT: Membership Inference Attack via Error Prediction for Tabular Data",
      "title_zh": "MIA-EPTï¼šåŸºäºè¯¯å·®é¢„æµ‹çš„è¡¨æ ¼æ•°æ®æˆå‘˜æ¨ç†æ”»å‡»",
      "authors": [
        "Eyal German",
        "Daniel Samira",
        "Yuval Elovici",
        "Asaf Shabtai"
      ],
      "abstract": "Synthetic data generation plays an important role in enabling data sharing, particularly in sensitive domains like healthcare and finance. Recent advances in diffusion models have made it possible to generate realistic, high-quality tabular data, but they may also memorize training records and leak sensitive information. Membership inference attacks (MIAs) exploit this vulnerability by determining whether a record was used in training. While MIAs have been studied in images and text, their use against tabular diffusion models remains underexplored despite the unique risks of structured attributes and limited record diversity. In this paper, we introduce MIAEPT, Membership Inference Attack via Error Prediction for Tabular Data, a novel black-box attack specifically designed to target tabular diffusion models. MIA-EPT constructs errorbased feature vectors by masking and reconstructing attributes of target records, disclosing membership signals based on how well these attributes are predicted. MIA-EPT operates without access to the internal components of the generative model, relying only on its synthetic data output, and was shown to generalize across multiple state-of-the-art diffusion models. We validate MIA-EPT on three diffusion-based synthesizers, achieving AUC-ROC scores of up to 0.599 and TPR@10% FPR values of 22.0% in our internal tests. Under the MIDST 2025 competition conditions, MIA-EPT achieved second place in the Black-box Multi-Table track (TPR@10% FPR = 20.0%). These results demonstrate that our method can uncover substantial membership leakage in synthetic tabular data, challenging the assumption that synthetic data is inherently privacy-preserving. Our code is publicly available at https://github.com/eyalgerman/MIA-EPT.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆæˆæ•°æ®ç”Ÿæˆåœ¨åŒ»ç–—å’Œé‡‘èç­‰æ•æ„Ÿé¢†åŸŸçš„åº”ç”¨ï¼ŒæŒ‡å‡ºæ‰©æ•£æ¨¡å‹(Diffusion Models)åœ¨ç”Ÿæˆé«˜è´¨é‡è¡¨æ ¼æ•°æ®æ—¶å¯èƒ½é¢ä¸´è®­ç»ƒè®°å½•æ³„éœ²çš„éšç§é£é™©ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†MIA-EPTï¼Œä¸€ç§ä¸“é—¨é’ˆå¯¹è¡¨æ ¼æ‰©æ•£æ¨¡å‹çš„é»‘ç›’æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attack)æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹ç›®æ ‡è®°å½•çš„å±æ€§è¿›è¡Œæ©ç (Masking)å’Œé‡æ„(Reconstruction)æ¥æ„å»ºåŸºäºè¯¯å·®çš„ç‰¹å¾å‘é‡ï¼Œåˆ©ç”¨å±æ€§é¢„æµ‹çš„å‡†ç¡®æ€§æ¥è¯†åˆ«æˆå‘˜èº«ä»½ä¿¡å·ã€‚MIA-EPTæ— éœ€è®¿é—®ç”Ÿæˆæ¨¡å‹çš„å†…éƒ¨ç»„ä»¶ï¼Œä»…ä¾èµ–å…¶åˆæˆæ•°æ®è¾“å‡ºï¼Œå¹¶è¯æ˜äº†å…¶åœ¨å¤šç§æœ€å…ˆè¿›æ‰©æ•£æ¨¡å‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰æ¬¾æ‰©æ•£åˆæˆå™¨ä¸Šè¾¾åˆ°äº†0.599çš„AUC-ROCå¾—åˆ†ï¼Œå¹¶åœ¨MIDST 2025ç«èµ›çš„é»‘ç›’å¤šè¡¨èµ›é“ä¸­è·å¾—ç¬¬äºŒåã€‚è¿™ä¸€ç ”ç©¶ç»“æœæ­ç¤ºäº†åˆæˆè¡¨æ ¼æ•°æ®ä¸­å­˜åœ¨çš„å®è´¨æ€§æˆå‘˜æ³„éœ²é£é™©ï¼Œæœ‰åŠ›æŒ‘æˆ˜äº†åˆæˆæ•°æ®æœ¬è´¨ä¸Šå…·æœ‰éšç§ä¿æŠ¤æ€§çš„ä¼ ç»Ÿå‡è®¾ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13046v2",
      "published_date": "2025-09-16 13:03:54 UTC",
      "updated_date": "2025-10-05 07:26:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:35.067382+00:00"
    },
    {
      "arxiv_id": "2509.19343v3",
      "title": "Part-of-speech tagging for Nagamese Language using CRF",
      "title_zh": "åŸºäº CRF çš„çº³åŠ è¯­è¯æ€§æ ‡æ³¨",
      "authors": [
        "Alovi N Shohe",
        "Chonglio Khiamungam",
        "Teisovi Angami"
      ],
      "abstract": "This paper investigates part-of-speech tagging, an important task in Natural Language Processing (NLP) for the Nagamese language. The Nagamese language, a.k.a. Naga Pidgin, is an Assamese-lexified Creole language developed primarily as a means of communication in trade between the Nagas and people from Assam in northeast India. A substantial amount of work in part-of-speech-tagging has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in the Nagamese language. To the best of our knowledge, this is the first attempt at part-of-speech tagging for the Nagamese Language. The aim of this work is to identify the part-of-speech for a given sentence in the Nagamese language. An annotated corpus of 16,112 tokens is created and applied machine learning technique known as Conditional Random Fields (CRF). Using CRF, an overall tagging accuracy of 85.70%; precision, recall of 86%, and f1-score of 85% is achieved.\n  Keywords. Nagamese, NLP, part-of-speech, machine learning, CRF.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Nagamese è¯­è¨€ï¼ˆåˆç§° Naga Pidginï¼‰çš„è¯æ€§æ ‡æ³¨ (part-of-speech tagging) ä»»åŠ¡ï¼Œè¿™æ˜¯ä¸€ç§åœ¨å°åº¦ä¸œåŒ—éƒ¨ Naga æ—ä¸é˜¿è¨å§†äººè´¸æ˜“ä¸­å‘å±•èµ·æ¥çš„ä»¥é˜¿è¨å§†è¯­ä¸ºè¯æºçš„å…‹é‡Œå¥¥å°”è¯­ (Creole language)ã€‚å°½ç®¡è‹±è¯­å’Œå°åœ°è¯­ç­‰èµ„æºä¸°å¯Œè¯­è¨€çš„ç ”ç©¶å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†æ­¤å‰å°šæœªæœ‰é’ˆå¯¹ Nagamese è¯­è¨€çš„ç›¸å…³ç ”ç©¶ï¼Œè¯¥å·¥ä½œä»£è¡¨äº†å¯¹å…¶è¿›è¡Œè¯æ€§æ ‡æ³¨çš„é¦–æ¬¡å°è¯•ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å« 16,112 ä¸ªæ ‡è®° (tokens) çš„æ ‡æ³¨è¯­æ–™åº“ (annotated corpus)ï¼Œå¹¶åº”ç”¨äº†åä¸ºæ¡ä»¶éšæœºåœº (Conditional Random Fields, CRF) çš„æœºå™¨å­¦ä¹ æŠ€æœ¯è¿›è¡Œå»ºæ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº† 85.70% çš„æ€»ä½“æ ‡æ³¨å‡†ç¡®ç‡ (accuracy)ï¼Œå…¶ç²¾ç¡®ç‡ (precision) ä¸º 86%ï¼Œå¬å›ç‡ (recall) ä¸º 86%ï¼ŒF1-score è¾¾åˆ° 85%ã€‚è¯¥é¡¹ç ”ç©¶å¡«è¡¥äº† Nagamese è¯­è¨€åœ¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¢†åŸŸçš„ç©ºç™½ï¼Œä¸ºè¯¥è¯­è¨€çš„åç»­è®¡ç®—è¯­è¨€å­¦ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.19343v3",
      "published_date": "2025-09-16 12:59:55 UTC",
      "updated_date": "2025-10-13 16:54:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:37.272485+00:00"
    },
    {
      "arxiv_id": "2509.14281v1",
      "title": "SCoGen: Scenario-Centric Graph-Based Synthesis of Real-World Code Problems",
      "title_zh": "SCoGenï¼šåŸºäºåœºæ™¯ä¸­å¿ƒå›¾çš„çœŸå®ä¸–ç•Œä»£ç é—®é¢˜åˆæˆ",
      "authors": [
        "Xifeng Yao",
        "Dongyu Lang",
        "Wu Zhang",
        "Xintong Guo",
        "Huarui Xie",
        "Yinhao Ni",
        "Ping Liu",
        "Guang Shen",
        "Yi Bai",
        "Dandan Tu",
        "Changzheng Zhang"
      ],
      "abstract": "Significant advancements have been made in the capabilities of code large language models, leading to their rapid adoption and application across a wide range of domains. However, their further advancements are often constrained by the scarcity of real-world coding problems. To bridge this gap, we propose a novel framework for synthesizing code problems that emulate authentic real-world scenarios. This framework systematically integrates domain knowledge, domain skills, and coding skills, all of which are meticulously extracted from real-world programming-related datasets, including Stack Overflow and Kaggle. The extracted elements serve as the foundational building blocks for constructing code problems. To align the generated problems with practical applications, application scenarios are also mined from the aforementioned datasets. These scenarios are then utilized to construct a scenario-centric graph that interconnects domain knowledge, domain skills, and coding skills. Based on this structured representation, a sampling strategy on the graph is designed, which effectively controls the generation of a code problem with complexity and diversity, reflects real-world challenges. Experimental results demonstrate that the proposed method consistently achieves superior performance over state-of-the-art open-source large language models of varying sizes and functionalities, including both coders and general-purpose models, across a diverse set of real-world benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SCoGenï¼Œä¸€ç§æ—¨åœ¨åˆæˆæ¨¡æ‹ŸçœŸå®åœºæ™¯ä»£ç é—®é¢˜çš„åˆ›æ–°æ¡†æ¶ï¼Œä»¥è§£å†³ä»£ç å¤§è¯­è¨€æ¨¡å‹ (Code Large Language Models) è¿›ä¸€æ­¥å‘å±•ä¸­é¢ä¸´çš„çœŸå®ç¼–ç¨‹é—®é¢˜åŒ®ä¹çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç³»ç»Ÿåœ°é›†æˆäº†ä» Stack Overflow å’Œ Kaggle ç­‰çœŸå®æ•°æ®é›†ä¸­æå–çš„é¢†åŸŸçŸ¥è¯† (domain knowledge)ã€é¢†åŸŸæŠ€èƒ½ (domain skills) å’Œç¼–ç¨‹æŠ€èƒ½ (coding skills)ã€‚ç ”ç©¶è€…é€šè¿‡æ„å»ºä»¥åœºæ™¯ä¸ºä¸­å¿ƒçš„å›¾ç»“æ„ (scenario-centric graph) å°†è¿™äº›å…ƒç´ äº’è¿ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„å›¾é‡‡æ ·ç­–ç•¥æ¥ç”Ÿæˆå…·æœ‰å¤æ‚æ€§å’Œå¤šæ ·æ€§çš„ä»£ç é—®é¢˜ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSCoGen åœ¨å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ€§èƒ½ä¸€è‡´ä¼˜äºåŒ…æ‹¬ä»£ç ä¸“ç”¨æ¨¡å‹å’Œé€šç”¨æ¨¡å‹åœ¨å†…çš„å„ç±»å…ˆè¿›å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.14281v1",
      "published_date": "2025-09-16 12:52:48 UTC",
      "updated_date": "2025-09-16 12:52:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:44.491727+00:00"
    },
    {
      "arxiv_id": "2509.13032v1",
      "title": "Introducing the A2AJ's Canadian Legal Data: An open-source alternative to CanLII for the era of computational law",
      "title_zh": "A2AJ åŠ æ‹¿å¤§æ³•å¾‹æ•°æ®ï¼šè®¡ç®—æ³•å¾‹æ—¶ä»£ CanLII çš„å¼€æºæ›¿ä»£æ–¹æ¡ˆ",
      "authors": [
        "Simon Wallace",
        "Sean Rehaag"
      ],
      "abstract": "The Access to Algorithmic Justice project (A2AJ) is an open-source alternative to the Canadian Legal Information Institute (CanLII). At a moment when technology promises to enable new ways of working with law, CanLII is becoming an impediment to the free access of law and access to justice movements because it restricts bulk and programmatic access to Canadian legal data. This means that Canada is staring down a digital divide: well-resourced actors have the best new technological tools and, because CanLII has disclaimed leadership, the public only gets second-rate tools. This article puts CanLII in its larger historical context and shows how long and deep efforts to democratize access to Canadian legal data are, and how often they are thwarted by private industry. We introduce the A2AJ's Canadian Legal Data project, which provides open access to over 116,000 court decisions and 5,000 statutes through multiple channels including APIs, machine learning datasets, and AI integration protocols. Through concrete examples, we demonstrate how open legal data enables courts to conduct evidence-based assessments and allows developers to create tools for practitioners serving low-income communities.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Access to Algorithmic Justice project (A2AJ) çš„ Canadian Legal Data é¡¹ç›®ï¼Œæ—¨åœ¨ä½œä¸º CanLII çš„å¼€æºæ›¿ä»£æ–¹æ¡ˆä»¥é€‚åº” computational law æ—¶ä»£çš„éœ€æ±‚ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº† CanLII å› é™åˆ¶å¤§å®¹é‡åŠç¨‹åºåŒ–æ•°æ®è®¿é—®è€Œæˆä¸ºæ³•å¾‹è‡ªç”±è·å–çš„éšœç¢ï¼Œè¿›è€Œå¯¼è‡´äº†æ³•å¾‹æŠ€æœ¯é¢†åŸŸçš„æ•°å­—é¸¿æ²Ÿã€‚A2AJ é¡¹ç›®é€šè¿‡ APIsã€machine learning æ•°æ®é›†å’Œ AI integration åè®®ï¼Œä¸ºå…¬ä¼—æä¾›äº†è¶…è¿‡ 116,000 ä»½æ³•é™¢è£å†³åŠ 5,000 éƒ¨æ³•è§„çš„å¼€æ”¾è®¿é—®æƒé™ã€‚ç ”ç©¶å±•ç¤ºäº†è¯¥å¼€æ”¾æ•°æ®é›†å¦‚ä½•èµ‹èƒ½æ³•é™¢è¿›è¡Œè¯æ®é©±åŠ¨çš„è¯„ä¼°ï¼Œå¹¶æ”¯æŒå¼€å‘è€…ä¸ºæœåŠ¡ä½æ”¶å…¥ç¤¾åŒºçš„æ³•å¾‹ä»ä¸šè€…æ„å»ºæŠ€æœ¯å·¥å…·ã€‚é€šè¿‡è¿½æº¯åŠ æ‹¿å¤§æ³•å¾‹æ•°æ®æ°‘ä¸»åŒ–çš„å†å²èƒŒæ™¯ï¼Œè¯¥é¡¹ç›®å¼ºè°ƒäº†æ‰“ç ´ç§è¥è¡Œä¸šå„æ–­ã€ç¡®ä¿æ³•å¾‹æ­£ä¹‰æ™®åŠåŒ–çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13032v1",
      "published_date": "2025-09-16 12:51:39 UTC",
      "updated_date": "2025-09-16 12:51:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:46.786155+00:00"
    },
    {
      "arxiv_id": "2509.13031v2",
      "title": "Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models",
      "title_zh": "å…ˆæ„ŸçŸ¥åæ¨ç†ï¼šè§†è§‰è¯­è¨€æ¨¡å‹è§†è§‰æ¨ç†çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yan Chen",
        "Long Li",
        "Teng Xi",
        "Long Zeng",
        "Jingdong Wang"
      ],
      "abstract": "Reinforcement learning (RL) has proven highly effective in eliciting the reasoning capabilities of large language models (LLMs). Inspired by this success, recent studies have explored applying similar techniques to vision-language models (VLMs), aiming to enhance their reasoning performance. However, directly transplanting RL methods from LLMs to VLMs is suboptimal, as the tasks faced by VLMs are inherently more complex. Specifically, VLMs must first accurately perceive and understand visual inputs before reasoning can be effectively performed. To address this challenge, we propose a two-stage reinforcement learning framework designed to jointly enhance both the perceptual and reasoning capabilities of VLMs. To mitigate the vanishing advantage issue commonly observed in RL training, we first perform dataset-level sampling to selectively strengthen specific capabilities using distinct data sources. During training, the first stage focuses on improving the model's visual perception through coarse- and fine-grained visual understanding, while the second stage targets the enhancement of reasoning abilities. After the proposed two-stage reinforcement learning process, we obtain PeBR-R1, a vision-language model with significantly enhanced perceptual and reasoning capabilities. Experimental results on seven benchmark datasets demonstrate the effectiveness of our approach and validate the superior performance of PeBR-R1 across diverse visual reasoning tasks.",
      "tldr_zh": "å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç›´æ¥åº”ç”¨äºè§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models)æ—¶æ•ˆæœå¹¶ä¸ç†æƒ³ï¼Œå› ä¸ºè§†è§‰è¯­è¨€æ¨¡å‹åœ¨è¿›è¡Œæ¨ç†å‰å¿…é¡»é¦–å…ˆå‡†ç¡®æ„ŸçŸ¥å¹¶ç†è§£è§†è§‰è¾“å…¥ã€‚è¯¥ç ”ç©¶æå‡ºäº†PeBRæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨åŒæ—¶å¢å¼ºæ¨¡å‹æ„ŸçŸ¥ä¸æ¨ç†èƒ½åŠ›çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨ç¬¬ä¸€é˜¶æ®µé€šè¿‡ç²—ç²’åº¦å’Œç»†ç²’åº¦çš„è§†è§‰ç†è§£ä»»åŠ¡é‡ç‚¹æå‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œç¬¬äºŒé˜¶æ®µåˆ™ä¸“æ³¨äºå¢å¼ºé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†ç¼“è§£å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­å¸¸è§çš„ä¼˜åŠ¿æ¶ˆå¤±é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†æ•°æ®é›†å±‚é¢çš„é‡‡æ ·ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡è¯¥æµç¨‹è®­ç»ƒå¾—åˆ°çš„PeBR-R1æ¨¡å‹åœ¨ä¸ƒä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡å±•ç°å‡ºæ˜¾è‘—å¢å¼ºçš„æ€§èƒ½ï¼Œè¯æ˜äº†â€œæ„ŸçŸ¥å…ˆäºæ¨ç†â€ç­–ç•¥åœ¨å¤„ç†å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13031v2",
      "published_date": "2025-09-16 12:51:11 UTC",
      "updated_date": "2025-10-17 10:09:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:52.284495+00:00"
    },
    {
      "arxiv_id": "2509.13025v1",
      "title": "GView: A Survey of Binary Forensics via Visual, Semantic, and AI-Enhanced Analysis",
      "title_zh": "GViewï¼šåŸºäºå¯è§†åŒ–ã€è¯­ä¹‰ä¸AIå¢å¼ºåˆ†æçš„äºŒè¿›åˆ¶å–è¯ç»¼è¿°",
      "authors": [
        "Raul Zaharia",
        "DragoÅŸ GavriluÅ£",
        "GheorghiÅ£Äƒ Mutu"
      ],
      "abstract": "Cybersecurity threats continue to become more sophisticated and diverse in their artifacts, boosting both their volume and complexity. To overcome those challenges, we present GView, an open-source forensic analysis framework with visual and AI-enhanced reasoning. It started with focus on the practical cybersecurity industry. It has evolved significantly, incorporating large language models (LLMs) to dynamically enhance reasoning and ease the forensic workflows. This paper surveys both the current state of GView with its published papers alongside those that are in the publishing process. It also includes its innovative use of logical inference through predicates and inference rules for both the analyzed documents and the user's actions for better suggestions. We highlight the extensible architecture, showcasing its potential as a bridge between the practical forensics worlds with the academic research.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† GViewï¼Œä¸€ä¸ªå…·å¤‡è§†è§‰å’Œ AI-enhanced reasoning èƒ½åŠ›çš„å¼€æºäºŒè¿›åˆ¶å–è¯åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹æ—¥ç›Šå¤æ‚å¤šæ ·çš„ç½‘ç»œå®‰å…¨å¨èƒã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆ Large Language Models (LLMs) åŠ¨æ€å¢å¼ºäº†æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ˜¾è‘—ç®€åŒ–äº†å–è¯å·¥ä½œæµç¨‹ã€‚è®ºæ–‡ç³»ç»Ÿç»¼è¿°äº† GView çš„å½“å‰å‘å±•çŠ¶æ€ï¼Œé‡ç‚¹ä»‹ç»äº†å…¶åˆ©ç”¨ Predicates å’Œ Inference rules è¿›è¡Œé€»è¾‘æ¨ç†ï¼ˆLogical inferenceï¼‰çš„åˆ›æ–°åº”ç”¨ï¼Œä»è€Œå¯¹åˆ†ææ–‡æ¡£å’Œç”¨æˆ·æ“ä½œæä¾›æ›´æ™ºèƒ½çš„å»ºè®®ã€‚æ­¤å¤–ï¼ŒGView é‡‡ç”¨çš„ Extensible architecture ä½¿å…¶æœ‰æ•ˆè¿æ¥äº†å®é™…å–è¯åº”ç”¨ä¸å­¦æœ¯ç ”ç©¶ã€‚è¯¥æ¡†æ¶ä¸ä»…æå‡äº†å–è¯åˆ†æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä¹Ÿä¸ºæœªæ¥ AI é©±åŠ¨çš„å–è¯æŠ€æœ¯å‘å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "In Proceedings FROM 2025, arXiv:2509.11877",
      "pdf_url": "https://arxiv.org/pdf/2509.13025v1",
      "published_date": "2025-09-16 12:46:39 UTC",
      "updated_date": "2025-09-16 12:46:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:54:56.273390+00:00"
    },
    {
      "arxiv_id": "2509.13023v1",
      "title": "Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ç¬¦å·æ‰§è¡Œä¸å…·ä½“æ‰§è¡ŒéªŒè¯ Solidity ä»£ç ç¼ºé™·",
      "authors": [
        "Åtefan-Claudiu Susan",
        "Andrei Arusoaie",
        "Dorel Lucanu"
      ],
      "abstract": "The high rate of false alarms from static analysis tools and Large Language Models (LLMs) complicates vulnerability detection in Solidity Smart Contracts, demanding methods that can formally or empirically prove the presence of defects. This paper introduces a novel detection pipeline that integrates custom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is designed to reliably detect defects and generate proofs.  We currently perform experiments with promising results for seven types of critical defects. We demonstrate the pipeline's efficacy by presenting our findings for three vulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control Policies -- that are challenging for current verification solutions, which often generate false alarms or fail to detect them entirely. We highlight the potential of either symbolic or concrete execution in correctly classifying such code faults. By chaining these instruments, our method effectively validates true positives, significantly reducing the manual verification burden. Although we identify potential limitations, such as the inconsistency and the cost of LLMs, our findings establish a robust framework for combining heuristic analysis with formal verification to achieve more reliable and automated smart contract auditing.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Solidity æ™ºèƒ½åˆçº¦æ¼æ´æ£€æµ‹ä¸­é™æ€åˆ†æå·¥å…·å’Œ LLMs è¯¯æŠ¥ç‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆè‡ªå®šä¹‰ Slither æ£€æµ‹å™¨ã€LLMsã€Kontrol å’Œ Forge çš„æ–°å‹æ£€æµ‹æµæ°´çº¿ã€‚è¯¥æ–¹æ¡ˆåˆ©ç”¨ç¬¦å·æ‰§è¡Œ(Symbolic Execution)å’Œå…·ä½“æ‰§è¡Œ(Concrete Execution)å¯¹ä»£ç ç¼ºé™·è¿›è¡ŒéªŒè¯å¹¶ç”Ÿæˆè¯æ˜ï¼Œæ—¨åœ¨æ˜¾è‘—å‡è½»äººå·¥å®¡æ ¸çš„å·¥ä½œé‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æµæ°´çº¿åœ¨å¤„ç†é‡å…¥(Reentrancy)ã€å¤æ‚å›é€€(Complex Fallback)å’Œé”™è¯¯è®¿é—®æ§åˆ¶ç­–ç•¥(Faulty Access Control Policies)ç­‰ç°æœ‰å·¥å…·éš¾ä»¥åº”å¯¹çš„æŒ‘æˆ˜æ€§æ¼æ´æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚é€šè¿‡å°†å¯å‘å¼åˆ†æä¸å½¢å¼åŒ–éªŒè¯å·¥å…·è¿›è¡Œé“¾å¼ç»„åˆï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆéªŒè¯çœŸæ­£ä¾‹(True Positives)å¹¶æå‡å®¡è®¡çš„å¯é æ€§ã€‚å°½ç®¡é¢ä¸´ LLMs æˆæœ¬å’Œä¸€è‡´æ€§æ–¹é¢çš„å±€é™ï¼Œè¯¥ç ”ç©¶ä»ä¸ºå®ç°è‡ªåŠ¨åŒ–ã€é«˜å¯é æ€§çš„æ™ºèƒ½åˆçº¦å®¡è®¡æä¾›äº†ä¸€ä¸ªç¨³å¥çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "In Proceedings FROM 2025, arXiv:2509.11877",
      "pdf_url": "https://arxiv.org/pdf/2509.13023v1",
      "published_date": "2025-09-16 12:46:11 UTC",
      "updated_date": "2025-09-16 12:46:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:23.591932+00:00"
    },
    {
      "arxiv_id": "2509.13021v1",
      "title": "xOffense: An AI-driven autonomous penetration testing framework with offensive knowledge-enhanced LLMs and multi agent systems",
      "title_zh": "xOffenseï¼šåŸºäºæ”»å‡»çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ä¸å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ AI é©±åŠ¨è‡ªä¸»æ¸—é€æµ‹è¯•æ¡†æ¶",
      "authors": [
        "Phung Duc Luong",
        "Le Tran Gia Bao",
        "Nguyen Vu Khai Tam",
        "Dong Huu Nguyen Khoa",
        "Nguyen Huu Quyen",
        "Van-Hau Pham",
        "Phan The Duy"
      ],
      "abstract": "This work introduces xOffense, an AI-driven, multi-agent penetration testing framework that shifts the process from labor-intensive, expert-driven manual efforts to fully automated, machine-executable workflows capable of scaling seamlessly with computational infrastructure. At its core, xOffense leverages a fine-tuned, mid-scale open-source LLM (Qwen3-32B) to drive reasoning and decision-making in penetration testing. The framework assigns specialized agents to reconnaissance, vulnerability scanning, and exploitation, with an orchestration layer ensuring seamless coordination across phases. Fine-tuning on Chain-of-Thought penetration testing data further enables the model to generate precise tool commands and perform consistent multi-step reasoning. We evaluate xOffense on two rigorous benchmarks: AutoPenBench and AI-Pentest-Benchmark. The results demonstrate that xOffense consistently outperforms contemporary methods, achieving a sub-task completion rate of 79.17%, decisively surpassing leading systems such as VulnBot and PentestGPT. These findings highlight the potential of domain-adapted mid-scale LLMs, when embedded within structured multi-agent orchestration, to deliver superior, cost-efficient, and reproducible solutions for autonomous penetration testing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† xOffenseï¼Œè¿™æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•(penetration testing)æ¡†æ¶ï¼Œæ—¨åœ¨å°†ä¼ ç»Ÿçš„ä¸“å®¶é©±åŠ¨æ‰‹åŠ¨æµç¨‹è½¬å˜ä¸ºå…¨è‡ªåŠ¨ã€å¯æ‰©å±•çš„æœºå™¨æ‰§è¡Œå·¥ä½œæµã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ç»è¿‡å¾®è°ƒçš„ä¸­ç­‰è§„æ¨¡å¼€æºå¤§è¯­è¨€æ¨¡å‹ Qwen3-32Bï¼Œç”¨äºé©±åŠ¨æ¸—é€æµ‹è¯•ä¸­çš„æ¨ç†ä¸å†³ç­–è¿‡ç¨‹ã€‚xOffense éƒ¨ç½²äº†ä¸“é—¨çš„æ™ºèƒ½ä½“è´Ÿè´£ä¾¦å¯Ÿ(reconnaissance)ã€æ¼æ´æ‰«æ(vulnerability scanning)å’Œæ¼æ´åˆ©ç”¨(exploitation)ï¼Œå¹¶é€šè¿‡ç¼–æ’å±‚(orchestration layer)ç¡®ä¿å„é˜¶æ®µçš„æ— ç¼åä½œã€‚é€šè¿‡åœ¨æ¸—é€æµ‹è¯•ç›¸å…³çš„é“¾å¼æ€ç»´(Chain-of-Thought)æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆç²¾ç¡®çš„å·¥å…·æŒ‡ä»¤å¹¶æ‰§è¡Œä¸€è‡´çš„å¤šæ­¥æ¨ç†ã€‚åœ¨ AutoPenBench å’Œ AI-Pentest-Benchmark ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒxOffense çš„å­ä»»åŠ¡å®Œæˆç‡è¾¾åˆ°äº† 79.17%ï¼Œæ˜æ˜¾ä¼˜äº VulnBot å’Œ PentestGPT ç­‰é¢†å…ˆç³»ç»Ÿã€‚è¯¥ç ”ç©¶ç»“æœè¯æ˜ï¼Œå°†é¢†åŸŸè‡ªé€‚åº”çš„ LLM åµŒå…¥åˆ°ç»“æ„åŒ–çš„å¤šæ™ºèƒ½ä½“ç¼–æ’ä¸­ï¼Œå¯ä»¥ä¸ºè‡ªä¸»æ¸—é€æµ‹è¯•æä¾›æ€§èƒ½å“è¶Šã€æˆæœ¬æ•ˆç›Šé«˜ä¸”å…·æœ‰å¯é‡å¤æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.13021v1",
      "published_date": "2025-09-16 12:45:45 UTC",
      "updated_date": "2025-09-16 12:45:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:26.689391+00:00"
    },
    {
      "arxiv_id": "2510.09616v2",
      "title": "Causal Digital Twins for Cyber-Physical Security: A Framework for Robust Anomaly Detection in Industrial Control Systems",
      "title_zh": "é¢å‘ä¿¡æ¯ç‰©ç†å®‰å…¨çš„å› æœæ•°å­—å­ªç”Ÿï¼šä¸€ç§å·¥ä¸šæ§åˆ¶ç³»ç»Ÿé²æ£’å¼‚å¸¸æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Mohammadhossein Homaei",
        "Mehran Tarif",
        "Pablo Garcia Rodriguez",
        "Andres Caro",
        "Mar Avila"
      ],
      "abstract": "Industrial Control Systems (ICS) in water distribution and treatment face cyber-physical attacks exploiting network and physical vulnerabilities. Current water system anomaly detection methods rely on correlations, yielding high false alarms and poor root cause analysis. We propose a Causal Digital Twin (CDT) framework for water infrastructures, combining causal inference with digital twin modeling. CDT supports association for pattern detection, intervention for system response, and counterfactual analysis for water attack prevention. Evaluated on water-related datasets SWaT, WADI, and HAI, CDT shows 90.8\\% compliance with physical constraints and structural Hamming distance 0.133 $\\pm$ 0.02. F1-scores are $0.944 \\pm 0.014$ (SWaT), $0.902 \\pm 0.021$ (WADI), $0.923 \\pm 0.018$ (HAI, $p<0.0024$). CDT reduces false positives by 74\\%, achieves 78.4\\% root cause accuracy, and enables counterfactual defenses reducing attack success by 73.2\\%. Real-time performance at 3.2 ms latency ensures safe and interpretable operation for medium-scale water systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾›æ°´ä¸æ°´å¤„ç†é¢†åŸŸçš„å·¥ä¸šæ§åˆ¶ç³»ç»Ÿ (Industrial Control Systems, ICS) åœ¨åº”å¯¹ç½‘ç»œç‰©ç†æ”»å‡»æ—¶å­˜åœ¨çš„è¯¯æŠ¥ç‡é«˜å’Œæ ¹æœ¬åŸå› åˆ†æ (root cause analysis) èƒ½åŠ›ä¸è¶³ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å› æœæ•°å­—å­ªç”Ÿ (Causal Digital Twin, CDT) æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å› æœæ¨ç† (causal inference) ä¸æ•°å­—å­ªç”Ÿå»ºæ¨¡ç›¸ç»“åˆï¼Œæ”¯æŒå…³è” (association) æ¨¡å¼æ£€æµ‹ã€ç³»ç»Ÿå“åº”å¹²é¢„ (intervention) ä»¥åŠæ—¨åœ¨é¢„é˜²æ”»å‡»çš„åäº‹å®åˆ†æ (counterfactual analysis)ã€‚åœ¨ SWaTã€WADI å’Œ HAI æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒCDT åœ¨ç‰©ç†çº¦æŸåˆè§„æ€§å’Œç»“æ„æ±‰æ˜è·ç¦» (Structural Hamming Distance) æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æé«˜çš„ F1-scoresã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCDT å°†è¯¯æŠ¥ç‡æ˜¾è‘—é™ä½äº† 74%ï¼Œæ ¹æœ¬åŸå› å‡†ç¡®ç‡è¾¾åˆ° 78.4%ï¼Œå¹¶é€šè¿‡åäº‹å®é˜²å¾¡ä½¿æ”»å‡»æˆåŠŸç‡ä¸‹é™äº† 73.2%ã€‚æ­¤å¤–ï¼Œå…¶ 3.2 æ¯«ç§’çš„ä½å»¶è¿Ÿè¡¨ç°ç¡®ä¿äº†ä¸­ç­‰è§„æ¨¡æ°´åŠ¡ç³»ç»Ÿåœ¨è¿è¡Œè¿‡ç¨‹ä¸­çš„å®æ—¶å®‰å…¨æ€§ã€é²æ£’æ€§ä¸å¯è§£é‡Šæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "math.ST"
      ],
      "primary_category": "cs.CR",
      "comment": "22 Pages, six figures, and 14 tables,",
      "pdf_url": "https://arxiv.org/pdf/2510.09616v2",
      "published_date": "2025-09-16 12:36:25 UTC",
      "updated_date": "2025-11-14 11:12:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:30.796093+00:00"
    },
    {
      "arxiv_id": "2509.13011v1",
      "title": "A Visualized Framework for Event Cooperation with Generative Agents",
      "title_zh": "åŸºäºç”Ÿæˆå¼æ™ºèƒ½ä½“çš„äº‹ä»¶åä½œå¯è§†åŒ–æ¡†æ¶",
      "authors": [
        "Yuyang Tian",
        "Shunqiang Mao",
        "Wenchang Gao",
        "Lanlan Qiu",
        "Tianxing He"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized the simulation of agent societies, enabling autonomous planning, memory formation, and social interactions. However, existing frameworks often overlook systematic evaluations for event organization and lack visualized integration with physically grounded environments, limiting agents' ability to navigate spaces and interact with items realistically. We develop MiniAgentPro, a visualization platform featuring an intuitive map editor for customizing environments and a simulation player with smooth animations. Based on this tool, we introduce a comprehensive test set comprising eight diverse event scenarios with basic and hard variants to assess agents' ability. Evaluations using GPT-4o demonstrate strong performance in basic settings but highlight coordination challenges in hard variants.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)æ™ºèƒ½ä½“æ¡†æ¶åœ¨äº‹ä»¶ç»„ç»‡ç³»ç»Ÿè¯„ä¼°åŠç‰©ç†ç¯å¢ƒå¯è§†åŒ–é›†æˆæ–¹é¢çš„ä¸è¶³ï¼Œå¼€å‘äº†åä¸ºMiniAgentProçš„å¯è§†åŒ–å¹³å°ã€‚è¯¥å¹³å°é›†æˆäº†ç›´è§‚çš„åœ°å›¾ç¼–è¾‘å™¨ç”¨äºè‡ªå®šä¹‰ç¯å¢ƒï¼Œå¹¶é…å¤‡äº†æ”¯æŒå¹³æ»‘åŠ¨ç”»çš„æ¨¡æ‹Ÿæ’­æ”¾å™¨ï¼Œæ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“åœ¨ç©ºé—´å¯¼èˆªå’Œç‰©å“äº¤äº’ä¸­çš„çœŸå®æ„Ÿã€‚åŸºäºæ­¤å·¥å…·ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«å…«ç§ä¸åŒäº‹ä»¶åœºæ™¯çš„å…¨é¢æµ‹è¯•é›†ï¼Œé€šè¿‡åŸºç¡€(basic)å’Œå›°éš¾(hard)ä¸¤ç§å˜ä½“ç³»ç»Ÿè¯„ä¼°æ™ºèƒ½ä½“çš„åä½œèƒ½åŠ›ã€‚ä½¿ç”¨GPT-4oè¿›è¡Œçš„è¯„ä¼°å®éªŒè¡¨æ˜ï¼Œæ™ºèƒ½ä½“åœ¨åŸºç¡€åœºæ™¯ä¸­è¡¨ç°å¼ºåŠ²ï¼Œä½†åœ¨é¢å¯¹å›°éš¾å˜ä½“æ—¶ä»å­˜åœ¨æ˜æ˜¾çš„åä½œæŒ‘æˆ˜(coordination challenges)ã€‚è¯¥ç ”ç©¶ä¸ºç”Ÿæˆå¼æ™ºèƒ½ä½“(Generative Agents)åœ¨å¤æ‚äº‹ä»¶åä½œä¸­çš„è¡Œä¸ºåˆ†æä¸å¯è§†åŒ–é›†æˆæä¾›äº†é‡è¦çš„è¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13011v1",
      "published_date": "2025-09-16 12:33:54 UTC",
      "updated_date": "2025-09-16 12:33:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:33.283756+00:00"
    },
    {
      "arxiv_id": "2509.13387v1",
      "title": "Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis",
      "title_zh": "åˆ©ç”¨ BERTopic å’Œä¸»é¢˜åˆ†ææ­ç¤º EU æ”¿ç­–ä¸­çš„äººå·¥æ™ºèƒ½æ²»ç†ä¸»é¢˜",
      "authors": [
        "Delaram Golpayegani",
        "Marta Lasek-Markey",
        "Arjumand Younus",
        "Aphra Kerr",
        "Dave Lewis"
      ],
      "abstract": "The upsurge of policies and guidelines that aim to ensure Artificial Intelligence (AI) systems are safe and trustworthy has led to a fragmented landscape of AI governance. The European Union (EU) is a key actor in the development of such policies and guidelines. Its High-Level Expert Group (HLEG) issued an influential set of guidelines for trustworthy AI, followed in 2024 by the adoption of the EU AI Act. While the EU policies and guidelines are expected to be aligned, they may differ in their scope, areas of emphasis, degrees of normativity, and priorities in relation to AI. To gain a broad understanding of AI governance from the EU perspective, we leverage qualitative thematic analysis approaches to uncover prevalent themes in key EU documents, including the AI Act and the HLEG Ethics Guidelines. We further employ quantitative topic modelling approaches, specifically through the use of the BERTopic model, to enhance the results and increase the document sample to include EU AI policy documents published post-2018. We present a novel perspective on EU policies, tracking the evolution of its approach to addressing AI governance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¥ç›Šç¢ç‰‡åŒ–çš„äººå·¥æ™ºèƒ½æ²»ç† (AI governance) èƒŒæ™¯ï¼Œæ—¨åœ¨æ·±å…¥è§£ææ¬§ç›Ÿ (EU) åœ¨è¿™ä¸€é¢†åŸŸçš„æ”¿ç­–æ¼”è¿›ä¸æ ¸å¿ƒè®®é¢˜ã€‚ç ”ç©¶é¦–å…ˆé‡‡ç”¨äº†å®šæ€§çš„ä¸»é¢˜åˆ†æ (Thematic Analysis) æ–¹æ³•ï¼Œå¯¹åŒ…æ‹¬ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(AI Act) å’Œé«˜çº§åˆ«ä¸“å®¶ç»„ (HLEG) å‘å¸ƒçš„ã€Šå¯ä¿¡äººå·¥æ™ºèƒ½ä¼¦ç†æŒ‡å—ã€‹åœ¨å†…çš„å…³é”®æ–‡ä»¶è¿›è¡Œäº†æ ¸å¿ƒä¸»é¢˜çš„æŒ–æ˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥æ‰©å¤§æ ·æœ¬é‡å¹¶æå‡åˆ†æçš„å¹¿åº¦ï¼Œç ”ç©¶è€…è¿˜è¿ç”¨äº†åŸºäº BERTopic æ¨¡å‹çš„å®šé‡ä¸»é¢˜å»ºæ¨¡ (Topic Modelling) æŠ€æœ¯ï¼Œå¯¹ 2018 å¹´ä»¥åå‘å¸ƒçš„æ¬§ç›Ÿ AI æ”¿ç­–æ–‡æ¡£è¿›è¡Œäº†ç³»ç»Ÿæ€§å¤„ç†ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯†åˆ«äº†ä¸åŒæ”¿ç­–åœ¨èŒƒå›´ã€ä¾§é‡ç‚¹åŠè§„èŒƒç¨‹åº¦ä¸Šçš„å·®å¼‚ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªè§‚å¯Ÿæ¬§ç›Ÿå¦‚ä½•é€šè¿‡æ”¿ç­–è°ƒæ•´æ¥åº”å¯¹ AI æ²»ç†æŒ‘æˆ˜çš„æ¼”è¿›è§†è§’ã€‚è¿™ç§ç»“åˆå®šæ€§ä¸å®šé‡çš„æ··åˆåˆ†ææ–¹æ³•ï¼Œä¸ºç†è§£å…¨çƒèŒƒå›´å†…å®‰å…¨ä¸”å¯ä¿¡çš„äººå·¥æ™ºèƒ½æ²»ç†æ ¼å±€æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13387v1",
      "published_date": "2025-09-16 12:20:07 UTC",
      "updated_date": "2025-09-16 12:20:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:37.590113+00:00"
    },
    {
      "arxiv_id": "2509.12999v1",
      "title": "Data-driven Methods of Extracting Text Structure and Information Transfer",
      "title_zh": "æ•°æ®é©±åŠ¨çš„æ–‡æœ¬ç»“æ„æå–ä¸ä¿¡æ¯ä¼ é€’æ–¹æ³•",
      "authors": [
        "Shinichi Honna",
        "Taichi Murayama",
        "Akira Matsui"
      ],
      "abstract": "The Anna Karenina Principle (AKP) holds that success requires satisfying a small set of essential conditions, whereas failure takes diverse forms. We test AKP, its reverse, and two further patterns described as ordered and noisy across novels, online encyclopedias, research papers, and movies. Texts are represented as sequences of functional blocks, and convergence is assessed in transition order and position. Results show that structural principles vary by medium: novels follow reverse AKP in order, Wikipedia combines AKP with ordered patterns, academic papers display reverse AKP in order but remain noisy in position, and movies diverge by genre. Success therefore depends on structural constraints that are specific to each medium, while failure assumes different shapes across domains.",
      "tldr_zh": "æœ¬ç ”ç©¶é€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹æ³•æ¢è®¨äº† Anna Karenina Principle (AKP) åœ¨ä¸åŒæ–‡æœ¬åª’ä»‹ï¼ˆå°è¯´ã€åœ¨çº¿ç™¾ç§‘å…¨ä¹¦ã€ç ”ç©¶è®ºæ–‡å’Œç”µå½±ï¼‰ä¸­çš„é€‚ç”¨æ€§ï¼Œæ—¨åœ¨æ­ç¤ºæ–‡æœ¬ç»“æ„ä¸ä¿¡æ¯ä¼ é€’çš„è§„å¾‹ã€‚ç ”ç©¶å°†æ–‡æœ¬è¡¨ç¤ºä¸ºåŠŸèƒ½å—åºåˆ— (sequences of functional blocks)ï¼Œå¹¶ä»è½¬æ¢é¡ºåº (transition order) å’Œä½ç½® (position) ä¸¤ä¸ªç»´åº¦è¯„ä¼°ç»“æ„çš„æ”¶æ•›æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸åŒåª’ä»‹éµå¾ªçš„ç»“æ„åŸåˆ™å„å¼‚ï¼šå°è¯´åœ¨é¡ºåºä¸Šéµå¾ª reverse AKPï¼Œè€Œ Wikipedia åˆ™ç»“åˆäº† AKP ä¸æœ‰åºæ¨¡å¼ (ordered patterns)ã€‚å­¦æœ¯è®ºæ–‡åœ¨é¡ºåºä¸Šè¡¨ç°å‡º reverse AKPï¼Œä½†åœ¨ä½ç½®åˆ†å¸ƒä¸Šä»å…·æœ‰å™ªå£° (noisy) ç‰¹å¾ï¼Œç”µå½±çš„ç»“æ„åˆ™å‘ˆç°å‡ºæ˜æ˜¾çš„ç±»å‹å·®å¼‚ã€‚è¯¥é¡¹ç ”ç©¶è¯æ˜äº†æ–‡æœ¬çš„æˆåŠŸä¾èµ–äºç‰¹å®šåª’ä»‹çš„ç»“æ„çº¦æŸ (structural constraints)ï¼Œè€Œå¤±è´¥åœ¨ä¸åŒé¢†åŸŸä¸­åˆ™å…·æœ‰å¤šæ ·åŒ–çš„è¡¨ç°å½¢å¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12999v1",
      "published_date": "2025-09-16 12:13:09 UTC",
      "updated_date": "2025-09-16 12:13:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:51.790888+00:00"
    },
    {
      "arxiv_id": "2509.12991v1",
      "title": "Bridging Performance Gaps for Foundation Models: A Post-Training Strategy for ECGFounder",
      "title_zh": "å¼¥åˆåŸºç¡€æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼šECGFounder çš„åè®­ç»ƒç­–ç•¥",
      "authors": [
        "Ya Zhou",
        "Yujie Yang",
        "Xiaohan Fan",
        "Wei Zhao"
      ],
      "abstract": "ECG foundation models are increasingly popular due to their adaptability across various tasks. However, their clinical applicability is often limited by performance gaps compared to task-specific models, even after pre-training on large ECG datasets and fine-tuning on target data. This limitation is likely due to the lack of an effective post-training strategy. In this paper, we propose a simple yet effective post-training approach to enhance ECGFounder, a state-of-the-art ECG foundation model pre-trained on over 7 million ECG recordings. Experiments on the PTB-XL benchmark show that our approach improves the baseline fine-tuning strategy by 1.2%-3.3% in macro AUROC and 5.3%-20.9% in macro AUPRC. Additionally, our method outperforms several recent state-of-the-art approaches, including task-specific and advanced architectures. Further evaluation reveals that our method is more stable and sample-efficient compared to the baseline, achieving a 9.1% improvement in macro AUROC and a 34.9% improvement in macro AUPRC using just 10% of the training data. Ablation studies identify key components, such as stochastic depth and preview linear probing, that contribute to the enhanced performance. These findings underscore the potential of post-training strategies to improve ECG foundation models, and we hope this work will contribute to the continued development of foundation models in the ECG domain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ECGåŸºç¡€æ¨¡å‹ï¼ˆfoundation modelsï¼‰åœ¨ä¸´åºŠåº”ç”¨ä¸­å› ç¼ºä¹æœ‰æ•ˆè®­ç»ƒåç­–ç•¥è€Œè¡¨ç°ä¸å¦‚ç‰¹å®šä»»åŠ¡æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é’ˆå¯¹ECGFounderçš„è®­ç»ƒåï¼ˆpost-trainingï¼‰ç­–ç•¥ã€‚ECGFounderæ˜¯é¢„è®­ç»ƒäºè¶…è¿‡700ä¸‡æ¡å¿ƒç”µå›¾è®°å½•çš„é¢†å…ˆæ¨¡å‹ï¼Œæœ¬ç ”ç©¶é€šè¿‡æ”¹è¿›å…¶è®­ç»ƒæµç¨‹æ¥å¼¥è¡¥æ€§èƒ½å·®è·ã€‚åœ¨PTB-XLåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŸºçº¿å¾®è°ƒç­–ç•¥åœ¨å®è§‚AUROCä¸Šæå‡äº†1.2%-3.3%ï¼Œåœ¨å®è§‚AUPRCä¸Šæå‡äº†5.3%-20.9%ï¼Œæ€§èƒ½ä¼˜äºæœ€æ–°çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°è¯¥æ–¹æ³•å…·æœ‰æé«˜çš„ç¨³å®šæ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œä»…åˆ©ç”¨10%çš„è®­ç»ƒæ•°æ®å³å¯å®ç°æ˜¾è‘—çš„æ€§èƒ½å¢é•¿ã€‚æ¶ˆèå®éªŒç¡®ç«‹äº†éšæœºæ·±åº¦ï¼ˆstochastic depthï¼‰å’Œé¢„è§ˆçº¿æ€§æ¢æµ‹ï¼ˆpreview linear probingï¼‰æ˜¯æå‡æ¨¡å‹è¡¨ç°çš„æ ¸å¿ƒç»„ä»¶ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†è®­ç»ƒåç­–ç•¥åœ¨ä¼˜åŒ–ECGåŸºç¡€æ¨¡å‹æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºå¿ƒç”µå›¾é¢†åŸŸçš„æ¨¡å‹å¼€å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "A simple yet effective strategy for ECG foundation models",
      "pdf_url": "https://arxiv.org/pdf/2509.12991v1",
      "published_date": "2025-09-16 12:02:13 UTC",
      "updated_date": "2025-09-16 12:02:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:06.092111+00:00"
    },
    {
      "arxiv_id": "2509.12990v2",
      "title": "Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection",
      "title_zh": "é¢å‘é•¿å°¾ç¬¬ä¸€è§†è§’é”™è¯¯æ£€æµ‹çš„åŒé˜¶æ®µé‡åŠ æƒ MoE",
      "authors": [
        "Boyu Han",
        "Qianqian Xu",
        "Shilong Bao",
        "Zhiyong Yang",
        "Sicong Li",
        "Qingming Huang"
      ],
      "abstract": "In this report, we address the problem of determining whether a user performs an action incorrectly from egocentric video data. To handle the challenges posed by subtle and infrequent mistakes, we propose a Dual-Stage Reweighted Mixture-of-Experts (DR-MoE) framework. In the first stage, features are extracted using a frozen ViViT model and a LoRA-tuned ViViT model, which are combined through a feature-level expert module. In the second stage, three classifiers are trained with different objectives: reweighted cross-entropy to mitigate class imbalance, AUC loss to improve ranking under skewed distributions, and label-aware loss with sharpness-aware minimization to enhance calibration and generalization. Their predictions are fused using a classification-level expert module. The proposed method achieves strong performance, particularly in identifying rare and ambiguous mistake instances. The code is available at https://github.com/boyuh/DR-MoE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»ç¬¬ä¸€è§†è§’è§†é¢‘(egocentric video)æ•°æ®ä¸­è¯†åˆ«ç”¨æˆ·é”™è¯¯åŠ¨ä½œçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºDR-MoE(Dual-Stage Reweighted Mixture-of-Experts)çš„æ¡†æ¶ï¼Œä»¥åº”å¯¹ç»†å¾®ä¸”ç½•è§çš„é”™è¯¯æ£€æµ‹æŒ‘æˆ˜ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å†»ç»“çš„ViViTæ¨¡å‹å’Œç»è¿‡LoRA-tunedçš„ViViTæ¨¡å‹æå–ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç‰¹å¾çº§ä¸“å®¶æ¨¡å—(feature-level expert module)è¿›è¡Œæ•´åˆã€‚ç¬¬äºŒé˜¶æ®µåˆ™æ„å»ºäº†ä¸‰ä¸ªé‡‡ç”¨ä¸åŒä¼˜åŒ–ç›®æ ‡çš„åˆ†ç±»å™¨ï¼Œåˆ†åˆ«åˆ©ç”¨åŠ æƒäº¤å‰ç†µ(reweighted cross-entropy)ã€AUC losså’Œç»“åˆäº†é”åº¦æ„ŸçŸ¥æœ€å°åŒ–(sharpness-aware minimization)çš„label-aware lossæ¥ç¼“è§£ç±»åˆ«ä¸å¹³è¡¡å¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚æœ€ç»ˆï¼Œé€šè¿‡åˆ†ç±»çº§ä¸“å®¶æ¨¡å—(classification-level expert module)èåˆé¢„æµ‹ç»“æœã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDR-MoEåœ¨è¯†åˆ«é•¿å°¾åˆ†å¸ƒä¸‹çš„ç¨€æœ‰åŠæ¨¡ç³Šé”™è¯¯å®ä¾‹æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æ•°æ®åˆ†å¸ƒå€¾æ–œå¸¦æ¥çš„æ£€æµ‹éš¾é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12990v2",
      "published_date": "2025-09-16 12:00:42 UTC",
      "updated_date": "2025-10-03 15:18:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:55:57.196415+00:00"
    },
    {
      "arxiv_id": "2509.12987v1",
      "title": "Toward PDDL Planning Copilot",
      "title_zh": "è¿ˆå‘ PDDL è§„åˆ’æ™ºèƒ½åŠ©æ‰‹",
      "authors": [
        "Yarin Benyamin",
        "Argaman Mordoch",
        "Shahaf S. Shperberg",
        "Roni Stern"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being used as autonomous agents capable of performing complicated tasks. However, they lack the ability to perform reliable long-horizon planning on their own. This paper bridges this gap by introducing the Planning Copilot, a chatbot that integrates multiple planning tools and allows users to invoke them through instructions in natural language. The Planning Copilot leverages the Model Context Protocol (MCP), a recently developed standard for connecting LLMs with external tools and systems. This approach allows using any LLM that supports MCP without domain-specific fine-tuning. Our Planning Copilot supports common planning tasks such as checking the syntax of planning problems, selecting an appropriate planner, calling it, validating the plan it generates, and simulating their execution. We empirically evaluate the ability of our Planning Copilot to perform these tasks using three open-source LLMs. The results show that the Planning Copilot highly outperforms using the same LLMs without the planning tools. We also conducted a limited qualitative comparison of our tool against Chat GPT-5, a very recent commercial LLM. Our results shows that our Planning Copilot significantly outperforms GPT-5 despite relying on a much smaller LLM. This suggests dedicated planning tools may be an effective way to enable LLMs to perform planning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ‰§è¡Œå¯é é•¿ç¨‹è§„åˆ’(long-horizon planning)æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†Planning Copilotï¼Œè¿™æ˜¯ä¸€æ¬¾é›†æˆå¤šç§è§„åˆ’å·¥å…·å¹¶æ”¯æŒè‡ªç„¶è¯­è¨€äº¤äº’çš„ç³»ç»Ÿã€‚è¯¥å·¥å…·åˆ©ç”¨äº†æ¨¡å‹ä¸Šä¸‹æ–‡åè®®(Model Context Protocol, MCP)å°†LLMsä¸å¤–éƒ¨å·¥å…·æ— ç¼è¿æ¥ï¼Œä½¿å¾—ä»»ä½•æ”¯æŒMCPçš„LLMsæ— éœ€é¢†åŸŸç‰¹å®šçš„å¾®è°ƒ(domain-specific fine-tuning)å³å¯æ‰§è¡Œå¤æ‚è§„åˆ’ä»»åŠ¡ã€‚Planning Copilotçš„åŠŸèƒ½æ¶µç›–äº†PDDLè¯­æ³•æ£€æŸ¥ã€è§„åˆ’å™¨(planner)é€‰æ‹©ã€è®¡åˆ’éªŒè¯åŠæ‰§è¡Œæ¨¡æ‹Ÿã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œæ­è½½è§„åˆ’å·¥å…·çš„Planning Copilotåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºåŸå§‹LLMsã€‚å®šæ€§å¯¹æ¯”è¿˜å‘ç°ï¼Œå³ä¾¿åŸºäºè¾ƒå°çš„å¼€æºæ¨¡å‹ï¼Œè¯¥å·¥å…·åœ¨è§„åˆ’ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¹Ÿä¼˜äºå¤§å‹å•†ä¸šæ¨¡å‹Chat GPT-5ï¼Œè¡¨æ˜ä¸“ç”¨å·¥å…·é›†æˆæ˜¯å¢å¼ºæ¨¡å‹è§„åˆ’èƒ½åŠ›çš„æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12987v1",
      "published_date": "2025-09-16 11:51:07 UTC",
      "updated_date": "2025-09-16 11:51:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:05.800283+00:00"
    },
    {
      "arxiv_id": "2509.18151v1",
      "title": "HyperNAS: Enhancing Architecture Representation for NAS Predictor via Hypernetwork",
      "title_zh": "HyperNASï¼šåŸºäºè¶…ç½‘ç»œå¢å¼º NAS é¢„æµ‹å™¨çš„æ¶æ„è¡¨ç¤º",
      "authors": [
        "Jindi Lv",
        "Yuhao Zhou",
        "Yuxin Tian",
        "Qing Ye",
        "Wentao Feng",
        "Jiancheng Lv"
      ],
      "abstract": "Time-intensive performance evaluations significantly impede progress in Neural Architecture Search (NAS). To address this, neural predictors leverage surrogate models trained on proxy datasets, allowing for direct performance predictions for new architectures. However, these predictors often exhibit poor generalization due to their limited ability to capture intricate relationships among various architectures. In this paper, we propose HyperNAS, a novel neural predictor paradigm for enhancing architecture representation learning. HyperNAS consists of two primary components: a global encoding scheme and a shared hypernetwork. The global encoding scheme is devised to capture the comprehensive macro-structure information, while the shared hypernetwork serves as an auxiliary task to enhance the investigation of inter-architecture patterns. To ensure training stability, we further develop a dynamic adaptive multi-task loss to facilitate personalized exploration on the Pareto front. Extensive experiments across five representative search spaces, including ViTs, demonstrate the advantages of HyperNAS, particularly in few-shot scenarios. For instance, HyperNAS strikes new state-of-the-art results, with 97.60\\% top-1 accuracy on CIFAR-10 and 82.4\\% top-1 accuracy on ImageNet, using at least 5.0$\\times$ fewer samples.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HyperNASï¼Œä¸€ç§æ—¨åœ¨å¢å¼ºæ¶æ„è¡¨ç¤ºå­¦ä¹ çš„æ–°å‹ç¥ç»ç½‘ç»œé¢„æµ‹å™¨ (neural predictor) èŒƒå¼ï¼Œä»¥è§£å†³ç¥ç»ç½‘ç»œæ¶æ„æœç´¢ (NAS) ä¸­æ€§èƒ½è¯„ä¼°è€—æ—¶ä¸”é¢„æµ‹å™¨æ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚HyperNAS ç”±å…¨å±€ç¼–ç æ–¹æ¡ˆ (global encoding scheme) å’Œå…±äº«è¶…ç½‘ç»œ (shared hypernetwork) ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼Œå‰è€…è´Ÿè´£æ•æ‰å…¨é¢çš„å®è§‚ç»“æ„ä¿¡æ¯ï¼Œåè€…åˆ™ä½œä¸ºè¾…åŠ©ä»»åŠ¡æ¥å¢å¼ºå¯¹æ¶æ„é—´æ¨¡å¼çš„ç ”ç©¶ã€‚ä¸ºäº†ç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†åŠ¨æ€è‡ªé€‚åº”å¤šä»»åŠ¡æŸå¤± (dynamic adaptive multi-task loss)ï¼Œä»¥ä¿ƒè¿›åœ¨ Pareto front ä¸Šçš„ä¸ªæ€§åŒ–æ¢ç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHyperNAS åœ¨åŒ…æ‹¬ ViTs åœ¨å†…çš„äº”ä¸ªä»£è¡¨æ€§æœç´¢ç©ºé—´ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨ few-shot åœºæ™¯ä¸‹å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¯¥æ–¹æ³•åœ¨ CIFAR-10 å’Œ ImageNet ä¸Šåˆ†åˆ«å®ç°äº† 97.60% å’Œ 82.4% çš„ top-1 accuracyï¼Œä¸”æ‰€ä½¿ç”¨çš„æ ·æœ¬é‡æ¯”ç°æœ‰æŠ€æœ¯è‡³å°‘å‡å°‘äº† 5 å€ï¼Œåˆ·æ–°äº†å¤šé¡¹ state-of-the-art è®°å½•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18151v1",
      "published_date": "2025-09-16 11:49:12 UTC",
      "updated_date": "2025-09-16 11:49:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:02.087047+00:00"
    },
    {
      "arxiv_id": "2509.12982v1",
      "title": "Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins",
      "title_zh": "åŸºäº AI é©±åŠ¨æ•°å­—å­ªç”Ÿçš„è‡ªé€‚åº”æœºå™¨äººåˆ†å¸ƒå¤–æ£€æµ‹",
      "authors": [
        "Erblin Isaku",
        "Hassan Sartaj",
        "Shaukat Ali",
        "Beatriz Sanguino",
        "Tongtong Wang",
        "Guoyuan Li",
        "Houxiang Zhang",
        "Thomas Peyrucain"
      ],
      "abstract": "Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance -- up to 98\\% AUROC, 96\\% TNR@TPR95, and 95\\% F1-score -- while providing interpretable insights to support self-adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤æ‚ä¸ç¡®å®šç¯å¢ƒä¸‹è‡ªé€‚åº”æœºå™¨äºº(Self-adaptive Robots, SARs)å¯¹åˆ†å¸ƒå¤–(Out-of-distribution, OOD)å¼‚å¸¸è¡Œä¸ºæ£€æµ‹çš„éœ€æ±‚ï¼Œæå‡ºäº†åä¸ºODiSARçš„åŸºäºæ•°å­—å­ªç”Ÿ(Digital Twins)çš„æ£€æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŸºäºTransformerçš„æ•°å­—å­ªç”Ÿæ¨¡å‹é¢„æµ‹æœºå™¨äººçŠ¶æ€ï¼Œå¹¶ç»“åˆé‡æ„è¯¯å·®(Reconstruction error)ä¸è’™ç‰¹å¡æ´›æ»´è½(Monte Carlo dropout)æŠ€æœ¯è¿›è¡Œä¸ç¡®å®šæ€§é‡åŒ–ã€‚é€šè¿‡å°†é¢„æµ‹æ–¹å·®ä¸é‡æ„è¯¯å·®ç›¸ç»“åˆï¼ŒODiSARèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å³ä½¿æ˜¯æ­¤å‰ä»æœªè§è¿‡çš„OODè¡Œä¸ºã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é›†æˆäº†ä¸€ä¸ªå¯è§£é‡Šæ€§å±‚ï¼Œå¯å°†æ½œåœ¨çš„OODäº‹ä»¶ä¸ç‰¹å®šçš„æœºå™¨äººçŠ¶æ€å…³è”ï¼Œä¸ºç³»ç»Ÿè‡ªé€‚åº”æä¾›æ´å¯Ÿã€‚ç ”ç©¶äººå‘˜åœ¨åŠå…¬å®¤å¯¼èˆªå’Œæµ·ä¸Šèˆ¹èˆ¶èˆªè¡Œä¸¤ä¸ªå·¥ä¸šæœºå™¨äººåœºæ™¯ä¸­å¯¹ODiSARè¿›è¡Œäº†è¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶åœ¨é¢„æµ‹è½¨è¿¹å’Œä¸»åŠ¨æ£€æµ‹å¼‚å¸¸æ–¹é¢çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒODiSARå®ç°äº†é«˜è¾¾98%çš„AUROCã€96%çš„TNR@TPR95ä»¥åŠ95%çš„F1-scoreï¼Œè¯æ˜äº†å…¶åœ¨æ”¯æŒæœºå™¨äººè‡ªé€‚åº”æ–¹é¢çš„å“è¶Šæ€§èƒ½ä¸è§£é‡Šä»·å€¼ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 4 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.12982v1",
      "published_date": "2025-09-16 11:43:47 UTC",
      "updated_date": "2025-09-16 11:43:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:26.289181+00:00"
    },
    {
      "arxiv_id": "2509.18150v1",
      "title": "Sparse Training Scheme for Multimodal LLM",
      "title_zh": "å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç¨€ç–è®­ç»ƒæ–¹æ¡ˆ",
      "authors": [
        "Kean Shi",
        "Liang Chen",
        "Haozhe Zhao",
        "Baobao Chang"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated outstanding performance across a variety of domains. However, training MLLMs is often inefficient due to the significantly longer input sequences introduced by multimodal data and the low utilization of inter-layer computations. To address this challenge, we shift the focus to the training process itself and propose a novel training-efficient framework based on sparse representations, termed the Sparse Training Scheme (STS). This scheme consists of two key components: the Visual Token Compressor, which reduces the information load by compressing visual tokens, and the Layer Dynamic Skipper, which mitigates the computational overhead by dynamically skipping unnecessary layers in the language model during both forward and backward passes. Our approach is broadly applicable to diverse MLLM architectures and has been extensively evaluated on multiple benchmarks, demonstrating its effectiveness and efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal Large Language Models, MLLMs) è®­ç»ƒè¿‡ç¨‹ä¸­å› è¾“å…¥åºåˆ—è¿‡é•¿å’Œå±‚é—´è®¡ç®—åˆ©ç”¨ç‡ä½å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸º Sparse Training Scheme (STS) çš„é«˜æ•ˆè®­ç»ƒæ¡†æ¶ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡å¼•å…¥ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼šVisual Token Compressor åˆ©ç”¨å‹ç¼©è§†è§‰æ ‡è®° (visual tokens) çš„æ–¹å¼æ˜¾è‘—å‡å°‘ä¿¡æ¯è´Ÿè½½ï¼Œè€Œ Layer Dynamic Skipper åˆ™é€šè¿‡åœ¨è¯­è¨€æ¨¡å‹çš„å‰å‘å’Œåå‘ä¼ æ’­ä¸­åŠ¨æ€è·³è¿‡ä¸å¿…è¦çš„å±‚ï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€ã€‚å®éªŒè¯æ˜ï¼ŒSTS å…·æœ‰å¹¿æ³›çš„æ¶æ„é€‚ç”¨æ€§ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å±•ç°å‡ºå“è¶Šçš„æ•ˆç‡ä¸æ€§èƒ½è¡¨ç°ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºå¤šæ¨¡æ€æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒæä¾›äº†æå…·é€šç”¨æ€§çš„è§£å†³æ€è·¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—ç¼“è§£å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®å¸¦æ¥çš„è®¡ç®—ç“¶é¢ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18150v1",
      "published_date": "2025-09-16 11:33:20 UTC",
      "updated_date": "2025-09-16 11:33:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:23.187700+00:00"
    },
    {
      "arxiv_id": "2509.14279v1",
      "title": "Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization",
      "title_zh": "è¿ˆå‘ç¨³å¥çš„æ™ºèƒ½ä½“é©±åŠ¨å‹ CUDA æ ¸å‡½æ•°åŸºå‡†æµ‹è¯•ã€éªŒè¯ä¸ä¼˜åŒ–",
      "authors": [
        "Robert Tjarko Lange",
        "Qi Sun",
        "Aaditya Prasad",
        "Maxence Faldor",
        "Yujin Tang",
        "David Ha"
      ],
      "abstract": "Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä½å±‚çº§CUDA kernelä¼˜åŒ–æ–¹é¢çš„å±€é™ï¼Œä»¥åŠç°æœ‰åŸºå‡†æµ‹è¯•ä¸­å­˜åœ¨çš„æ¼æ´å’Œå¤šæ ·æ€§ä¸è¶³ç­‰é—®é¢˜ï¼Œæå‡ºäº†å…¨æ–°çš„è¯„ä¼°åŸºå‡†robust-kbenchã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥å¼€å‘äº†ä¸€å¥—å…¨é¢çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–CUDA kernelçš„å‘ç°ã€éªŒè¯ä¸ä¼˜åŒ–æµç¨‹ã€‚è¯¥å·¥ä½œæµåˆ©ç”¨å‰æ²¿LLMså°†PyTorchä»£ç è½¬æ¢ä¸ºCUDA kernelï¼Œå¹¶é‡‡ç”¨ä¸“ä¸ºCUDAç”Ÿæ€ç³»ç»Ÿè®¾è®¡çš„è¿›åŒ–å…ƒç”Ÿæˆ(evolutionary meta-generation)ç¨‹åºï¼Œè¿­ä»£åœ°æå‡å†…æ ¸è¿è¡Œé€Ÿåº¦ã€‚ç³»ç»Ÿä¸­å¼•å…¥äº†åŸºäºLLMçš„éªŒè¯å™¨(verifiers)ï¼Œè´Ÿè´£ç¡®ä¿ä»£ç æ­£ç¡®æ€§å¹¶è¿›è¡Œé«˜æ•ˆè¿‡æ»¤ã€‚åœ¨robust-kbenchä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„CUDA kernelåœ¨æ­£å‘å’Œåå‘ä¼ æ’­ç­‰å®é™…åº”ç”¨ä¸­è¡¨ç°ä¼˜äºåŸç”Ÿçš„torchå®ç°ã€‚è¯¥æ¡†æ¶å±•ç°äº†ç®—å­èåˆ(fuse operations)å’Œéƒ¨ç½²å¤šç§è¿è¡Œæ—¶ä¼˜åŒ–ç­–ç•¥çš„èƒ½åŠ›ï¼Œèƒ½å‡†ç¡®è¯†åˆ«å¹¶åˆ†ç±»é”™è¯¯å†…æ ¸ï¼Œæ˜¾è‘—æå‡äº†ç¡¬ä»¶éªŒè¯çš„æ•ˆç‡ã€‚è¿™ä¸€å·¥ä½œä¸ºå®ç°é²æ£’ä¸”è‡ªåŠ¨åŒ–çš„CUDAå†…æ ¸å¼€å‘ä¸ä¼˜åŒ–æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "62 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.14279v1",
      "published_date": "2025-09-16 11:08:30 UTC",
      "updated_date": "2025-09-16 11:08:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:29.461595+00:00"
    },
    {
      "arxiv_id": "2509.12960v2",
      "title": "Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models",
      "title_zh": "æ¢ç©¶ ReLoRA å¯¹å°è¯­è¨€æ¨¡å‹å­¦ä¹ åŠ¨åŠ›å­¦çš„å½±å“",
      "authors": [
        "Yuval Weiss",
        "David Demitri Africa",
        "Paula Buttery",
        "Richard Diehl Martinez"
      ],
      "abstract": "Parameter-efficient methods like LoRA have revolutionised large language model (LLM) fine-tuning. ReLoRA extends this idea to pretraining by repeatedly merging and reinitialising low-rank adapters, increasing cumulative rank while keeping updates cheap. This aligns well with observations that high-capacity models learn through locally low-rank trajectories that expand over time. By contrast, recent work suggests that small language models (SLMs) exhibit rank deficiencies and under-utilise their available dimensionality. This raises a natural question: can ReLoRA's rank-expanding update rule \\textit{steer} SLMs toward healthier learning dynamics, mitigating rank bottlenecks in a capacity-constrained regime? We argue SLMs are an ideal testbed: they train quickly, enable controlled ablations, and make rank phenomena more measurable. We present the first systematic study of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and learning dynamics. Across loss, Paloma perplexity, and BLiMP, we find that ReLoRA underperforms full-rank training, with gaps widening at larger scales. Analysis of proportional effective rank and condition numbers shows that ReLoRA amplifies existing rank deficiencies and induces ill-conditioned updates early in training. Our results suggest that while ReLoRA's merge-and-restart strategy can expand ranks in larger models, it does not straightforwardly translate to capacity-limited SLMs, motivating adaptive-rank or hybrid-rank approaches for low-compute pretraining.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº† ReLoRA åœ¨å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰é¢„è®­ç»ƒä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨é€šè¿‡å…¶ç‰¹æœ‰çš„ç´¯ç§¯ä½ç§©é€‚é…å™¨ï¼ˆlow-rank adaptersï¼‰é‡ç½®æœºåˆ¶ï¼Œç ”ç©¶å…¶æ˜¯å¦èƒ½æ”¹å–„ SLMs å¸¸è§çš„ç§©äºæŸï¼ˆrank deficienciesï¼‰é—®é¢˜ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ 11M åˆ° 66M å‚æ•°è§„æ¨¡çš„ SLMs ä¸Šè¿›è¡Œäº†é¦–æ¬¡ç³»ç»Ÿå®éªŒï¼Œé€šè¿‡æŸå¤±å‡½æ•°ã€Paloma å›°æƒ‘åº¦ï¼ˆperplexityï¼‰å’Œ BLiMP ç­‰æŒ‡æ ‡è¯„ä¼°äº†æ¨¡å‹æ€§èƒ½ä¸å­¦ä¹ åŠ¨æ€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReLoRA åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šçš„è¡¨ç°å‡é€Šäºå…¨ç§©è®­ç»ƒï¼ˆfull-rank trainingï¼‰ï¼Œä¸”éšç€æ¨¡å‹è§„æ¨¡çš„å¢å¤§ï¼Œä¸¤è€…çš„æ€§èƒ½å·®è·è¿›ä¸€æ­¥æ‰©å¤§ã€‚æ·±å…¥åˆ†æè¡¨æ˜ï¼ŒReLoRA ä¸ä»…æœªèƒ½ç¼“è§£ SLMs çš„ç§©ç“¶é¢ˆï¼Œåè€Œæ”¾å¤§äº†ç°æœ‰çš„ç§©äºæŸï¼Œå¹¶åœ¨è®­ç»ƒåˆæœŸå¯¼è‡´äº†ç—…æ€æ›´æ–°ï¼ˆill-conditioned updatesï¼‰ã€‚è¯¥ç ”ç©¶ç»“è®ºæŒ‡å‡ºï¼ŒReLoRA çš„åˆå¹¶ä¸é‡å¯ç­–ç•¥åœ¨å®¹é‡å—é™çš„ SLMs ä¸­å¹¶ä¸èƒ½ç›´æ¥å¥æ•ˆï¼Œè¿™ä¸ºæœªæ¥åœ¨ä½ç®—åŠ›ç¯å¢ƒä¸‹æ¢ç´¢è‡ªé€‚åº”ç§©ï¼ˆadaptive-rankï¼‰æˆ–æ··åˆç§©ï¼ˆhybrid-rankï¼‰é¢„è®­ç»ƒæ–¹æ³•æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 Pages, 6 Tables, 8 Figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12960v2",
      "published_date": "2025-09-16 11:06:58 UTC",
      "updated_date": "2025-10-02 14:09:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:30.851845+00:00"
    },
    {
      "arxiv_id": "2509.12958v1",
      "title": "Forget What's Sensitive, Remember What Matters: Token-Level Differential Privacy in Memory Sculpting for Continual Learning",
      "title_zh": "é—å¿˜æ•æ„Ÿä¿¡æ¯ï¼Œä¿ç•™å…³é”®çŸ¥è¯†ï¼šæŒç»­å­¦ä¹ ä¸­è®°å¿†å¡‘é€ çš„è¯å…ƒçº§å·®åˆ†éšç§",
      "authors": [
        "Bihao Zhan",
        "Jie Zhou",
        "Junsong Li",
        "Yutao Yang",
        "Shilian Chen",
        "Qianjun Pan",
        "Xin Li",
        "Wen Wu",
        "Xingjiao Wu",
        "Qin Chen",
        "Hang Yan",
        "Liang He"
      ],
      "abstract": "Continual Learning (CL) models, while adept at sequential knowledge acquisition, face significant and often overlooked privacy challenges due to accumulating diverse information. Traditional privacy methods, like a uniform Differential Privacy (DP) budget, indiscriminately protect all data, leading to substantial model utility degradation and hindering CL deployment in privacy-sensitive areas. To overcome this, we propose a privacy-enhanced continual learning (PeCL) framework that forgets what's sensitive and remembers what matters. Our approach first introduces a token-level dynamic Differential Privacy strategy that adaptively allocates privacy budgets based on the semantic sensitivity of individual tokens. This ensures robust protection for private entities while minimizing noise injection for non-sensitive, general knowledge. Second, we integrate a privacy-guided memory sculpting module. This module leverages the sensitivity analysis from our dynamic DP mechanism to intelligently forget sensitive information from the model's memory and parameters, while explicitly preserving the task-invariant historical knowledge crucial for mitigating catastrophic forgetting. Extensive experiments show that PeCL achieves a superior balance between privacy preserving and model utility, outperforming baseline models by maintaining high accuracy on previous tasks while ensuring robust privacy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒç»­å­¦ä¹ (Continual Learning)æ¨¡å‹åœ¨é¡ºåºçŸ¥è¯†è·å–ä¸­ç§¯ç´¯å¤šæ ·åŒ–ä¿¡æ¯å¸¦æ¥çš„éšç§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPeCLçš„éšç§å¢å¼ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆå¼•å…¥äº†ä»¤ç‰Œçº§åŠ¨æ€å·®åˆ†éšç§(Token-level dynamic Differential Privacy)ç­–ç•¥ï¼Œæ ¹æ®ä»¤ç‰Œçš„è¯­ä¹‰æ•æ„Ÿæ€§è‡ªé€‚åº”åˆ†é…éšç§é¢„ç®—ï¼Œå®ç°å¯¹æ•æ„Ÿå®ä½“çš„å¼ºä¿æŠ¤å¹¶å‡å°‘éæ•æ„ŸçŸ¥è¯†çš„å™ªå£°å¹²æ‰°ã€‚å…¶æ¬¡ï¼Œç ”ç©¶é›†æˆäº†ä¸€ä¸ªéšç§å¼•å¯¼çš„è®°å¿†å¡‘é€ (privacy-guided memory sculpting)æ¨¡å—ï¼Œé€šè¿‡æ•æ„Ÿæ€§åˆ†æä»æ¨¡å‹è®°å¿†å’Œå‚æ•°ä¸­ä¸»åŠ¨é—å¿˜æ•æ„Ÿä¿¡æ¯ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å—æ˜¾å¼ä¿ç•™äº†å¯¹ç¼“è§£ç¾éš¾æ€§é—å¿˜(catastrophic forgetting)è‡³å…³é‡è¦çš„ä»»åŠ¡ä¸å˜æ€§å†å²çŸ¥è¯†ã€‚å®éªŒè¯æ˜ï¼ŒPeCLåœ¨éšç§ä¿æŠ¤ä¸æ¨¡å‹æ•ˆç”¨ä¹‹é—´è¾¾æˆäº†å“è¶Šå¹³è¡¡ï¼Œåœ¨ç»´æŒå…ˆå‰ä»»åŠ¡é«˜å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†éšç§é²æ£’æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12958v1",
      "published_date": "2025-09-16 11:01:59 UTC",
      "updated_date": "2025-09-16 11:01:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:41.844856+00:00"
    },
    {
      "arxiv_id": "2509.12951v1",
      "title": "Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories",
      "title_zh": "é¢å‘æµ·é‡æ¨¡å‹ä»“åº“ä¸è¯­è¨€æ¨¡å‹å³æœåŠ¡çš„é»‘ç›’æ¨¡å‹åˆå¹¶",
      "authors": [
        "Shilian Chen",
        "Jie Zhou",
        "Tianyu Huai",
        "Yujiang Lu",
        "Junsong Li",
        "Bihao Zhan",
        "Qianjun Pan",
        "Yutao Yang",
        "Xin Li",
        "Qin Chen",
        "Hang Yan",
        "Liang He"
      ],
      "abstract": "Model merging refers to the process of integrating multiple distinct models into a unified model that preserves and combines the strengths and capabilities of the individual models. Most existing approaches rely on task vectors to combine models, typically under the assumption that model parameters are accessible. However, for extremely large language models (LLMs) such as GPT-4, which are often provided solely as black-box services through API interfaces (Language-Model-as-a-Service), model weights are not available to end users. This presents a significant challenge, which we refer to as black-box model merging (BMM) with massive LLMs. To address this challenge, we propose a derivative-free optimization framework based on the evolutionary algorithm (Evo-Merging) that enables effective model merging using only inference-time API queries. Our method consists of two key components: (1) sparsity-based denoising, designed to identify and filter out irrelevant or redundant information across models, and (2) sign-aware scaling, which dynamically computes optimal combination weights for the relevant models based on their performance. We also provide a formal justification, along with a theoretical analysis, for our asymmetric sparsification. Extensive experimental evaluations demonstrate that our approach achieves state-of-the-art results on a range of tasks, significantly outperforming existing strong baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä»“åº“ä¸­ Language-Model-as-a-Service (LMaaS) çš„é»‘ç›’ç‰¹æ€§ï¼Œæå‡ºäº† Black-box Model Merging (BMM) è¿™ä¸€æŒ‘æˆ˜ï¼Œæ—¨åœ¨è§£å†³æƒé‡ä¸å¯è®¿é—®æ—¶çš„æ¨¡å‹é›†æˆé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºè¿›åŒ–ç®—æ³•çš„æ— å¯¼æ•°ä¼˜åŒ–æ¡†æ¶ Evo-Mergingï¼Œä»…é€šè¿‡æ¨ç†æ—¶çš„ API æŸ¥è¯¢å³å¯å®ç°æœ‰æ•ˆçš„æ¨¡å‹åˆå¹¶ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼šç”¨äºè¯†åˆ«å¹¶è¿‡æ»¤è·¨æ¨¡å‹å†—ä½™ä¿¡æ¯çš„ Sparsity-based denoising æŠ€æœ¯ï¼Œä»¥åŠæ ¹æ®æ€§èƒ½åŠ¨æ€è®¡ç®—æœ€ä½³ç»„åˆæƒé‡çš„ Sign-aware scaling æœºåˆ¶ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ä¸ºéå¯¹ç§°ç¨€ç–åŒ–æä¾›äº†å½¢å¼åŒ–è¯æ˜ä¸ç†è®ºåˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEvo-Merging åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¾¾åˆ°äº† State-of-the-art æ°´å¹³ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12951v1",
      "published_date": "2025-09-16 10:55:50 UTC",
      "updated_date": "2025-09-16 10:55:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:39.387698+00:00"
    },
    {
      "arxiv_id": "2509.12945v1",
      "title": "FusionMAE: large-scale pretrained model to optimize and simplify diagnostic and control of fusion plasma",
      "title_zh": "FusionMAEï¼šç”¨äºä¼˜åŒ–ä¸ç®€åŒ–èšå˜ç­‰ç¦»å­ä½“è¯Šæ–­åŠæ§åˆ¶çš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹",
      "authors": [
        "Zongyu Yang",
        "Zhenghao Yang",
        "Wenjing Tian",
        "Jiyuan Li",
        "Xiang Sun",
        "Guohui Zheng",
        "Songfen Liu",
        "Niannian Wu",
        "Rongpeng Li",
        "Zhaohe Xu",
        "Bo Li",
        "Zhongbing Shi",
        "Zhe Gao",
        "Wei Chen",
        "Xiaoquan Ji",
        "Min Xu",
        "Wulyu Zhong"
      ],
      "abstract": "In magnetically confined fusion device, the complex, multiscale, and nonlinear dynamics of plasmas necessitate the integration of extensive diagnostic systems to effectively monitor and control plasma behaviour. The complexity and uncertainty arising from these extensive systems and their tangled interrelations has long posed a significant obstacle to the acceleration of fusion energy development. In this work, a large-scale model, fusion masked auto-encoder (FusionMAE) is pre-trained to compress the information from 88 diagnostic signals into a concrete embedding, to provide a unified interface between diagnostic systems and control actuators. Two mechanisms are proposed to ensure a meaningful embedding: compression-reduction and missing-signal reconstruction. Upon completion of pre-training, the model acquires the capability for 'virtual backup diagnosis', enabling the inference of missing diagnostic data with 96.7% reliability. Furthermore, the model demonstrates three emergent capabilities: automatic data analysis, universal control-diagnosis interface, and enhancement of control performance on multiple tasks. This work pioneers large-scale AI model integration in fusion energy, demonstrating how pre-trained embeddings can simplify the system interface, reducing necessary diagnostic systems and optimize operation performance for future fusion reactors.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FusionMAE (fusion masked auto-encoder)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¼˜åŒ–å’Œç®€åŒ–å—æ§æ ¸èšå˜ç­‰ç¦»å­ä½“è¯Šæ–­ä¸æ§åˆ¶çš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ã€‚ä¸ºäº†åº”å¯¹ç£çº¦æŸèšå˜è£…ç½®ä¸­å¤æ‚çš„éçº¿æ€§åŠ¨æ€ï¼Œè¯¥æ¨¡å‹é€šè¿‡ compression-reduction å’Œ missing-signal reconstruction ä¸¤ç§æœºåˆ¶ï¼Œå°†æ¥è‡ª 88 ä¸ªè¯Šæ–­ä¿¡å·çš„æµ·é‡ä¿¡æ¯å‹ç¼©ä¸ºç»Ÿä¸€çš„ embeddingï¼Œä»è€Œåœ¨è¯Šæ–­ç³»ç»Ÿä¸æ§åˆ¶æ‰§è¡Œå™¨ä¹‹é—´å»ºç«‹äº†æ ‡å‡†åŒ–æ¥å£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFusionMAE å…·å¤‡å¼ºå¤§çš„â€œè™šæ‹Ÿå¤‡ä»½è¯Šæ–­â€èƒ½åŠ›ï¼Œèƒ½å¤Ÿä»¥ 96.7% çš„å¯é æ€§æ¢å¤ç¼ºå¤±çš„è¯Šæ–­æ•°æ®ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å±•ç°äº†è‡ªåŠ¨æ•°æ®åˆ†æã€é€šç”¨æ§åˆ¶-è¯Šæ–­æ¥å£ä»¥åŠæ˜¾è‘—æå‡å¤šä»»åŠ¡æ§åˆ¶æ€§èƒ½ç­‰æ¶Œç°èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œå¼€åˆ›äº†å¤§è§„æ¨¡ AI æ¨¡å‹åœ¨èšå˜èƒ½æºé¢†åŸŸçš„åº”ç”¨å…ˆæ²³ï¼Œé€šè¿‡ç®€åŒ–ç³»ç»Ÿç•Œé¢å¹¶å‡å°‘å¯¹ç‰©ç†è¯Šæ–­ç³»ç»Ÿçš„ä¾èµ–ï¼Œä¸ºæœªæ¥èšå˜ååº”å †çš„ä¼˜åŒ–è¿è¡Œæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "physics.plasm-ph",
        "cs.AI"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12945v1",
      "published_date": "2025-09-16 10:50:29 UTC",
      "updated_date": "2025-09-16 10:50:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:41.568048+00:00"
    },
    {
      "arxiv_id": "2509.12939v2",
      "title": "Sy-FAR: Symmetry-based Fair Adversarial Robustness",
      "title_zh": "Sy-FARï¼šåŸºäºå¯¹ç§°æ€§çš„å…¬å¹³å¯¹æŠ—é²æ£’æ€§",
      "authors": [
        "Haneen Najjar",
        "Eyal Ronen",
        "Mahmood Sharif"
      ],
      "abstract": "Security-critical machine-learning (ML) systems, such as face-recognition systems, are susceptible to adversarial examples, including real-world physically realizable attacks. Various means to boost ML's adversarial robustness have been proposed; however, they typically induce unfair robustness: It is often easier to attack from certain classes or groups than from others. Several techniques have been developed to improve adversarial robustness while seeking perfect fairness between classes. Yet, prior work has focused on settings where security and fairness are less critical. Our insight is that achieving perfect parity in realistic fairness-critical tasks, such as face recognition, is often infeasible -- some classes may be highly similar, leading to more misclassifications between them. Instead, we suggest that seeking symmetry -- i.e., attacks from class $i$ to $j$ would be as successful as from $j$ to $i$ -- is more tractable. Intuitively, symmetry is a desirable because class resemblance is a symmetric relation in most domains. Additionally, as we prove theoretically, symmetry between individuals induces symmetry between any set of sub-groups, in contrast to other fairness notions where group-fairness is often elusive. We develop Sy-FAR, a technique to encourage symmetry while also optimizing adversarial robustness and extensively evaluate it using five datasets, with three model architectures, including against targeted and untargeted realistic attacks. The results show Sy-FAR significantly improves fair adversarial robustness compared to state-of-the-art methods. Moreover, we find that Sy-FAR is faster and more consistent across runs. Notably, Sy-FAR also ameliorates another type of unfairness we discover in this work -- target classes that adversarial examples are likely to be classified into become significantly less vulnerable after inducing symmetry.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Sy-FARï¼ˆSymmetry-based Fair Adversarial Robustnessï¼‰ï¼Œæ—¨åœ¨è§£å†³æœºå™¨å­¦ä¹ ç³»ç»Ÿåœ¨æå‡å¯¹æŠ—é²æ£’æ€§ï¼ˆadversarial robustnessï¼‰æ—¶å¸¸è§çš„é²æ£’æ€§ä¸å…¬å¹³é—®é¢˜ã€‚ç ”ç©¶è€…æŒ‡å‡ºï¼Œåœ¨äººè„¸è¯†åˆ«ç­‰ç°å®ä»»åŠ¡ä¸­è¿½æ±‚å®Œç¾çš„ç±»åˆ«å…¬å¹³ï¼ˆperfect fairnessï¼‰é€šå¸¸éš¾ä»¥å®ç°ï¼Œå› æ­¤æå‡ºä»¥å¯¹ç§°æ€§ï¼ˆsymmetryï¼‰ä½œä¸ºæ›´å¯è¡Œçš„ç›®æ ‡ï¼Œå³ç¡®ä¿ç±»åˆ« $i$ åˆ° $j$ çš„æ”»å‡»æˆåŠŸç‡ä¸ $j$ åˆ° $i$ ç›¸ç­‰ã€‚ç†è®ºè¯æ˜ï¼Œä¸ªä½“é—´çš„å¯¹ç§°æ€§å¯ä»¥è¯±å¯¼ä»»æ„å­ç¾¤ä½“é—´çš„å¯¹ç§°æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿç¾¤ä½“å…¬å¹³ï¼ˆgroup-fairnessï¼‰éš¾ä»¥è¾¾æˆçš„é—®é¢˜ã€‚Sy-FARåœ¨ä¼˜åŒ–å¯¹æŠ—é²æ£’æ€§çš„åŒæ—¶é¼“åŠ±å¯¹ç§°æ€§ï¼Œåœ¨äº”é¡¹æ•°æ®é›†å’Œä¸‰ç§æ¨¡å‹æ¶æ„ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨è¿è¡Œé€Ÿåº¦å’Œä¸€è‡´æ€§ä¸Šè¡¨ç°æ›´ä½³ï¼Œå¹¶èƒ½æœ‰æ•ˆç¼“è§£å¯¹æŠ—æ ·æœ¬å€¾å‘äºè¢«è¯¯åˆ†ç±»åˆ°ç‰¹å®šç›®æ ‡ç±»åˆ«çš„æ–°å‹ä¸å…¬å¹³ç°è±¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to USENIX Security 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.12939v2",
      "published_date": "2025-09-16 10:39:42 UTC",
      "updated_date": "2026-01-19 21:21:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:42.659057+00:00"
    },
    {
      "arxiv_id": "2509.12937v1",
      "title": "Jailbreaking Large Language Models Through Content Concretization",
      "title_zh": "é€šè¿‡å†…å®¹å…·ä½“åŒ–å®ç°å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±",
      "authors": [
        "Johan WahrÃ©us",
        "Ahmed Hussain",
        "Panos Papadimitratos"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed for task automation and content generation, yet their safety mechanisms remain vulnerable to circumvention through different jailbreaking techniques. In this paper, we introduce \\textit{Content Concretization} (CC), a novel jailbreaking technique that iteratively transforms abstract malicious requests into concrete, executable implementations. CC is a two-stage process: first, generating initial LLM responses using lower-tier, less constrained safety filters models, then refining them through higher-tier models that process both the preliminary output and original prompt. We evaluate our technique using 350 cybersecurity-specific prompts, demonstrating substantial improvements in jailbreak Success Rates (SRs), increasing from 7\\% (no refinements) to 62\\% after three refinement iterations, while maintaining a cost of 7.5\\textcent~per prompt. Comparative A/B testing across nine different LLM evaluators confirms that outputs from additional refinement steps are consistently rated as more malicious and technically superior. Moreover, manual code analysis reveals that generated outputs execute with minimal modification, although optimal deployment typically requires target-specific fine-tuning. With eventual improved harmful code generation, these results highlight critical vulnerabilities in current LLM safety frameworks.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†å†…å®¹å…·ä½“åŒ–(Content Concretization, CC)æŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)è¶Šç‹±(jailbreaking)æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è¿­ä»£è¿‡ç¨‹å°†æŠ½è±¡çš„æ¶æ„è¯·æ±‚è½¬åŒ–ä¸ºå…·ä½“çš„ã€å¯æ‰§è¡Œçš„å®ç°ã€‚CCæŠ€æœ¯é‡‡ç”¨ä¸¤é˜¶æ®µæµç¨‹ï¼šé¦–å…ˆåˆ©ç”¨å®‰å…¨çº¦æŸè¾ƒä½çš„ä½å±‚çº§æ¨¡å‹ç”Ÿæˆåˆæ­¥å“åº”ï¼Œéšåé€šè¿‡é«˜å±‚çº§æ¨¡å‹ç»“åˆåŸå§‹æç¤ºè¯è¿›è¡Œç²¾ç‚¼ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨350ä¸ªç½‘ç»œå®‰å…¨ç›¸å…³çš„æç¤ºè¯è¿›è¡Œæµ‹è¯•ï¼Œç»“æœè¡¨æ˜è¶Šç‹±æˆåŠŸç‡(Success Rates)ä»åˆå§‹çš„7%å¤§å¹…æå‡è‡³ä¸‰æ¬¡è¿­ä»£åçš„62%ï¼Œä¸”å¹³å‡å•æ¬¡æç¤ºè¯æˆæœ¬ä»…ä¸º7.5ç¾åˆ†ã€‚A/Bæµ‹è¯•ä¸äººå·¥ä»£ç åˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„è¾“å‡ºåœ¨æ¶æ„ç¨‹åº¦å’ŒæŠ€æœ¯è´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æé«˜ï¼Œç”Ÿæˆçš„ä»£ç é€šå¸¸åªéœ€æå°‘ä¿®æ”¹å³å¯è¿è¡Œã€‚è¯¥é¡¹ç ”ç©¶é€šè¿‡å±•ç¤ºå†…å®¹å…·ä½“åŒ–æ”»å‡»çš„æœ‰æ•ˆæ€§ï¼Œæ­ç¤ºäº†å½“å‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹å®‰å…¨é˜²å¾¡æœºåˆ¶ä¸­å­˜åœ¨çš„å…³é”®æ¼æ´ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for presentation in the Conference on Game Theory and AI for Security (GameSec) 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12937v1",
      "published_date": "2025-09-16 10:34:26 UTC",
      "updated_date": "2025-09-16 10:34:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:55.184433+00:00"
    },
    {
      "arxiv_id": "2509.12934v3",
      "title": "The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features",
      "title_zh": "å¯¹é½ä¹‹å‰–æï¼šé€šè¿‡æ“æ§ç¨€ç–ç‰¹å¾åˆ†è§£åå¥½ä¼˜åŒ–",
      "authors": [
        "Jeremias Ferrao",
        "Matthijs van der Lende",
        "Ilija Lichkovski",
        "Clement Neo"
      ],
      "abstract": "Prevailing alignment methods induce opaque parameter changes, obscuring what models truly learn. To address this, we introduce Feature Steering with Reinforcement Learning (FSRL), a framework that trains a lightweight adapter to steer model behavior by modulating interpretable sparse features. First, we theoretically demonstrate that this mechanism is expressive enough to approximate the behavioral shifts of post-training processes. We then apply FSRL to preference optimization and perform a causal analysis of the learned policy. Our analysis reveals a crucial insight: the model learns to reward stylistic presentation as a proxy for quality, disproportionately relying on features related to style and formatting over those tied to alignment concepts like honesty. By effectively optimizing the preference objective, FSRL serves as a transparent proxy for observing the alignment process. Overall, FSRL offers an interpretable control interface and a practical way to diagnose how preference optimization pressures manifest at the feature level.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Feature Steering with Reinforcement Learning (FSRL) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¯¹é½(alignment)æ–¹æ³•ç”±äºä¸é€æ˜çš„å‚æ•°å˜åŒ–è€Œéš¾ä»¥ç†è§£æ¨¡å‹å­¦ä¹ å†…å®¹çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒè½»é‡çº§é€‚é…å™¨(adapter)æ¥è°ƒåˆ¶å¯è§£é‡Šçš„ç¨€ç–ç‰¹å¾(sparse features)ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹è¡Œä¸ºã€‚ç ”ç©¶åœ¨ç†è®ºä¸Šè¯æ˜äº†è¯¥æœºåˆ¶è¶³ä»¥æ¨¡æ‹Ÿè®­ç»ƒåè¿‡ç¨‹çš„è¡Œä¸ºè½¬å˜ï¼Œå¹¶å°†å…¶åº”ç”¨äºåå¥½ä¼˜åŒ–(preference optimization)å’Œå­¦ä¹ ç­–ç•¥çš„å› æœåˆ†æã€‚åˆ†ææ­ç¤ºäº†ä¸€ä¸ªå…³é”®æ´å¯Ÿï¼šæ¨¡å‹åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å€¾å‘äºå°†é£æ ¼åŒ–è¡¨è¾¾è§†ä¸ºè´¨é‡çš„ä»£ç†ï¼Œè¿‡åº¦ä¾èµ–ä¸é£æ ¼å’Œæ ¼å¼ç›¸å…³çš„ç‰¹å¾ï¼Œè€Œéè¯šå®(honesty)ç­‰æ ¸å¿ƒå¯¹é½æ¦‚å¿µã€‚FSRLä¸ä»…ä¸ºè§‚å¯Ÿå¯¹é½è¿‡ç¨‹æä¾›äº†é€æ˜çš„ä»£ç†ï¼Œè¿˜ä¸ºè¯Šæ–­åå¥½ä¼˜åŒ–å‹åŠ›å¦‚ä½•åœ¨ç‰¹å¾å±‚é¢ä½“ç°æä¾›äº†å¯è§£é‡Šçš„æ§åˆ¶æ¥å£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Spotlight at NeurIPS 2025 Mechanistic Interpretability Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.12934v3",
      "published_date": "2025-09-16 10:32:40 UTC",
      "updated_date": "2025-12-01 01:57:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:56:52.776145+00:00"
    },
    {
      "arxiv_id": "2509.12927v1",
      "title": "HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic Decision-Making",
      "title_zh": "HLSMACï¼šé¢å‘é«˜å±‚æˆ˜ç•¥å†³ç­–çš„æ–°å‹æ˜Ÿé™…äº‰éœ¸å¤šæ™ºèƒ½ä½“æŒ‘æˆ˜",
      "authors": [
        "Xingxing Hong",
        "Yungong Wang",
        "Dexin Jin",
        "Ye Yuan",
        "Ximing Huang",
        "Zijian Wu",
        "Wenxin Li"
      ],
      "abstract": "Benchmarks are crucial for assessing multi-agent reinforcement learning (MARL) algorithms. While StarCraft II-related environments have driven significant advances in MARL, existing benchmarks like SMAC focus primarily on micromanagement, limiting comprehensive evaluation of high-level strategic intelligence. To address this, we introduce HLSMAC, a new cooperative MARL benchmark with 12 carefully designed StarCraft II scenarios based on classical stratagems from the Thirty-Six Stratagems. Each scenario corresponds to a specific stratagem and is designed to challenge agents with diverse strategic elements, including tactical maneuvering, timing coordination, and deception, thereby opening up avenues for evaluating high-level strategic decision-making capabilities. We also propose novel metrics across multiple dimensions beyond conventional win rate, such as ability utilization and advancement efficiency, to assess agents' overall performance within the HLSMAC environment. We integrate state-of-the-art MARL algorithms and LLM-based agents with our benchmark and conduct comprehensive experiments. The results demonstrate that HLSMAC serves as a robust testbed for advancing multi-agent strategic decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† HLSMACï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºé«˜çº§æˆ˜ç•¥å†³ç­– (high-level strategic decision-making) è®¾è®¡çš„æ–°å‹ StarCraft II åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL) åŸºå‡†ã€‚é’ˆå¯¹ç°æœ‰ SMAC åŸºå‡†è¿‡åº¦ä¾§é‡å¾®æ“ (micromanagement) çš„å±€é™æ€§ï¼ŒHLSMAC å¼•å…¥äº† 12 ä¸ªåŸºäºã€Šä¸‰åå…­è®¡ã€‹è®¾è®¡çš„æŒ‘æˆ˜åœºæ™¯ï¼Œé‡ç‚¹è¯„ä¼°æ™ºèƒ½ä½“åœ¨æˆ˜æœ¯æœºåŠ¨ (tactical maneuvering)ã€æ—¶æœºåè°ƒ (timing coordination) å’Œæ¬ºéª— (deception) ç­‰æ–¹é¢çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†æŠ€èƒ½åˆ©ç”¨ç‡ (ability utilization) å’Œæ¨è¿›æ•ˆç‡ (advancement efficiency) ç­‰å¤šç»´åº¦æ–°æŒ‡æ ‡ï¼Œä»¥æ›´å…¨é¢åœ°è¡¡é‡æ™ºèƒ½ä½“çš„ç»¼åˆæ€§èƒ½ã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„ MARL ç®—æ³•å’ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM-based agents) çš„æ™ºèƒ½ä½“è¿›è¡Œå®éªŒï¼Œç»“æœè¯æ˜ HLSMAC ä¸ºæ¨è¿›å¤šæ™ºèƒ½ä½“å¤æ‚æˆ˜ç•¥å†³ç­–ç ”ç©¶æä¾›äº†ä¸€ä¸ªç¨³å¥çš„æµ‹è¯•å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 13 figures with appendix",
      "pdf_url": "https://arxiv.org/pdf/2509.12927v1",
      "published_date": "2025-09-16 10:26:12 UTC",
      "updated_date": "2025-09-16 10:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:14.898081+00:00"
    },
    {
      "arxiv_id": "2509.12926v1",
      "title": "Population Estimation using Deep Learning over Gandhinagar Urban Area",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„ Gandhinagar åŸåŒºäººå£ä¼°ç®—",
      "authors": [
        "Jai Singla",
        "Peal Jotania",
        "Keivalya Pandya"
      ],
      "abstract": "Population estimation is crucial for various applications, from resource allocation to urban planning. Traditional methods such as surveys and censuses are expensive, time-consuming and also heavily dependent on human resources, requiring significant manpower for data collection and processing. In this study a deep learning solution is proposed to estimate population using high resolution (0.3 m) satellite imagery, Digital Elevation Models (DEM) of 0.5m resolution and vector boundaries. Proposed method combines Convolution Neural Network (CNN) architecture for classification task to classify buildings as residential and non-residential and Artificial Neural Network (ANN) architecture to estimate the population. Approx. 48k building footprints over Gandhinagar urban area are utilized containing both residential and non-residential, with residential categories further used for building-level population estimation. Experimental results on a large-scale dataset demonstrate the effectiveness of our model, achieving an impressive overall F1-score of 0.9936. The proposed system employs advanced geospatial analysis with high spatial resolution to estimate Gandhinagar population at 278,954. By integrating real-time data updates, standardized metrics, and infrastructure planning capabilities, this automated approach addresses critical limitations of conventional census-based methodologies. The framework provides municipalities with a scalable and replicable tool for optimized resource management in rapidly urbanizing cities, showcasing the efficiency of AI-driven geospatial analytics in enhancing data-driven urban governance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹  (Deep Learning) çš„äººå£ä¼°ç®—è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ™®æŸ¥æ–¹æ³•è€—æ—¶è€—åŠ›ä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•æ•´åˆäº† 0.3 ç±³é«˜åˆ†è¾¨ç‡å«æ˜Ÿå›¾åƒã€0.5 ç±³æ•°å­—é«˜ç¨‹æ¨¡å‹ (DEM) å’ŒçŸ¢é‡è¾¹ç•Œï¼Œåˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œ (CNN) å°†å»ºç­‘ç‰©åˆ†ç±»ä¸ºå±…ä½å’Œéå±…ä½ç±»å‹ã€‚éšåï¼Œç ”ç©¶é‡‡ç”¨äººå·¥ç¥ç»ç½‘ç»œ (ANN) æ¶æ„ï¼Œé’ˆå¯¹ Gandhinagar åŸåŒºçº¦ 4.8 ä¸‡ä¸ªå»ºç­‘è¶³è¿¹è¿›è¡Œå»ºç­‘å±‚çº§çš„äººå£ä¼°ç®—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¡¨ç°æä½³ï¼Œå–å¾—äº† 0.9936 çš„ç»¼åˆ F1-scoreï¼Œå¹¶å‡†ç¡®æµ‹ç®—å‡ºè¯¥åœ°åŒºäººå£ä¸º 278,954 äººã€‚è¿™ç§è‡ªåŠ¨åŒ–æ–¹æ³•é€šè¿‡é›†æˆå®æ—¶æ•°æ®æ›´æ–°å’Œæ ‡å‡†åŒ–æŒ‡æ ‡ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ä¼ ç»Ÿäººå£æ™®æŸ¥æ–¹æ³•çš„ä¸è¶³ã€‚è¯¥æ¡†æ¶ä¸ºå¸‚æ”¿å½“å±€åœ¨å¿«é€ŸåŸå¸‚åŒ–è¿›ç¨‹ä¸­ä¼˜åŒ–èµ„æºç®¡ç†æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å¯å¤åˆ¶çš„å·¥å…·ï¼Œå……åˆ†å±•ç¤ºäº† AI é©±åŠ¨çš„åœ°ç†ç©ºé—´åˆ†æåœ¨æå‡æ•°æ®é©±åŠ¨å‹åŸå¸‚æ²»ç†æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12926v1",
      "published_date": "2025-09-16 10:25:46 UTC",
      "updated_date": "2025-09-16 10:25:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:17.459982+00:00"
    },
    {
      "arxiv_id": "2509.12923v2",
      "title": "A Graph-Based Approach to Alert Contextualisation in Security Operations Centres",
      "title_zh": "åŸºäºå›¾çš„å®‰å…¨è¿è¥ä¸­å¿ƒå‘Šè­¦æƒ…å¢ƒåŒ–æ–¹æ³•",
      "authors": [
        "Magnus Wiik Eckhoff",
        "Peter Marius Flydal",
        "Siem Peters",
        "Martin Eian",
        "Jonas Halvorsen",
        "Vasileios Mavroeidis",
        "Gudmund Grov"
      ],
      "abstract": "Interpreting the massive volume of security alerts is a significant challenge in Security Operations Centres (SOCs). Effective contextualisation is important, enabling quick distinction between genuine threats and benign activity to prioritise what needs further analysis. This paper proposes a graph-based approach to enhance alert contextualisation in a SOC by aggregating alerts into graph-based alert groups, where nodes represent alerts and edges denote relationships within defined time-windows. By grouping related alerts, we enable analysis at a higher abstraction level, capturing attack steps more effectively than individual alerts. Furthermore, to show that our format is well suited for downstream machine learning methods, we employ Graph Matching Networks (GMNs) to correlate incoming alert groups with historical incidents, providing analysts with additional insights.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Security Operations Centres (SOCs) åœ¨å¤„ç†æµ·é‡å®‰å…¨å‘Šè­¦æ—¶é¢ä¸´çš„è§£é‡ŠæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾ï¼ˆgraph-basedï¼‰çš„å‘Šè­¦ä¸Šä¸‹æ–‡å…³è”æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨ç‰¹å®šæ—¶é—´çª—å£å†…å°†ç›¸å…³å‘Šè­¦èšåˆä¸ºå›¾ç»“æ„ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨å‘Šè­¦ï¼Œè¾¹ç¼˜ä»£è¡¨å½¼æ­¤é—´çš„å…³ç³»ï¼Œä»è€Œåœ¨æ¯”å•æ¡å‘Šè­¦æ›´é«˜çš„æŠ½è±¡ç»´åº¦ä¸Šæ›´æœ‰æ•ˆåœ°æ•æ‰æ”»å‡»æ­¥éª¤ã€‚ä¸ºäº†è¯æ˜è¯¥æ•°æ®æ ¼å¼é€‚ç”¨äºä¸‹æ¸¸æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œç ”ç©¶é‡‡ç”¨äº†Graph Matching Networks (GMNs) å°†æ–°ç”Ÿæˆçš„å‘Šè­¦ç»„ä¸å†å²å®‰å…¨äº‹ä»¶è¿›è¡Œå…³è”ï¼Œä¸ºåˆ†æå¸ˆæä¾›æ·±åº¦çš„èƒŒæ™¯æ´å¯Ÿã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©åˆ†æå¸ˆå¿«é€ŸåŒºåˆ†çœŸå®å¨èƒä¸è‰¯æ€§æ´»åŠ¨ï¼Œä»è€Œä¼˜åŒ–å‘Šè­¦å¤„ç†çš„ä¼˜å…ˆçº§æ’åºï¼Œæ˜¾è‘—æå‡äº†å®‰å…¨è¿è¥ä¸­å¿ƒçš„åˆ†ææ•ˆç‡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12923v2",
      "published_date": "2025-09-16 10:20:39 UTC",
      "updated_date": "2025-09-18 08:05:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:24.786285+00:00"
    },
    {
      "arxiv_id": "2509.12914v1",
      "title": "Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities",
      "title_zh": "Stochastic Streetsï¼šå››ä¸ªæ¬§æ´²åŸå¸‚å¤§è¯­è¨€æ¨¡å‹éšæœºåœ°å€ç”Ÿæˆåˆæ¢",
      "authors": [
        "Tairan Fu",
        "David Campo-Nazareno",
        "Javier Coronado-BlÃ¡zquez",
        "Javier Conde",
        "Pedro Reviriego",
        "Fabrizio Lombardi"
      ],
      "abstract": "Large Language Models (LLMs) are capable of solving complex math problems or answer difficult questions on almost any topic, but can they generate random street addresses for European cities?",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿæˆæ¬§æ´²åŸå¸‚éšæœºè¡—é“åœ°å€è¿™ä¸€ç»“æ„åŒ–ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚ä½œè€…é€šè¿‡APIè°ƒç”¨å¯¹Amsterdamã€Madridã€Pariså’ŒRomeå››ä¸ªåŸå¸‚çš„è¡—é“åœ°å€è¿›è¡Œäº†1000æ¬¡é‡å¤ç”Ÿæˆå®éªŒï¼Œæ¶µç›–äº†GPT-4å’ŒGeminiç­‰å…­ç§ä¸»æµæ¨¡å‹ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡è®¾ç½®äº†è¾ƒé«˜çš„Temperatureä»¥å¢åŠ éšæœºæ€§ï¼ŒLLMsä»è¡¨ç°å‡ºæ˜¾è‘—çš„åè§(biases)ï¼Œå€¾å‘äºåå¤é€‰æ‹©ä¸€å°éƒ¨åˆ†ç‰¹å®šçš„è¡—é“å’Œé—¨ç‰Œå·ã€‚å®éªŒç»“æœæ˜¾ç¤ºæ¨¡å‹ç»å¸¸å¿½ç•¥æœ€å…·ä»£è¡¨æ€§çš„åœ°æ ‡æ€§è¡—é“ï¼Œä¸”ç”Ÿæˆçš„åœ°ç†æ•°æ®åˆ†å¸ƒè¿œéç†æƒ³çš„éšæœºçŠ¶æ€ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†LLMsåœ¨è¡¨ç¤ºå’Œæ£€ç´¢åœ°ç†ç©ºé—´ç»“æ„åŒ–ä¿¡æ¯æ–¹é¢çš„å±€é™æ€§ï¼Œè¡¨æ˜çœŸéšæœº(Stochastic)ç”Ÿæˆä¾ç„¶æ˜¯å½“å‰æ¨¡å‹é¢ä¸´çš„æ˜¾è‘—æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12914v1",
      "published_date": "2025-09-16 10:09:00 UTC",
      "updated_date": "2025-09-16 10:09:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:35.587347+00:00"
    },
    {
      "arxiv_id": "2509.12908v1",
      "title": "All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning",
      "title_zh": "æ®Šé€”åŒå½’ï¼šåŸºäºå›¾çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†ç½®ä¿¡åº¦ä¼°è®¡",
      "authors": [
        "Caiqi Zhang",
        "Chang Shu",
        "Ehsan Shareghi",
        "Nigel Collier"
      ],
      "abstract": "Confidence estimation is essential for the reliable deployment of large language models (LLMs). Existing methods are primarily designed for factual QA tasks and often fail to generalize to reasoning tasks. To address this gap, we propose a set of training-free, graph-based confidence estimation methods tailored to reasoning tasks. Our approach models reasoning paths as directed graphs and estimates confidence by exploiting graph properties such as centrality, path convergence, and path weighting. Experiments with two LLMs on three reasoning datasets demonstrate improved confidence estimation and enhanced performance on two downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºç½®ä¿¡åº¦è¯„ä¼°(Confidence estimation)å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¯é éƒ¨ç½²è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¨ç†ä»»åŠ¡æ—¶å¾€å¾€éš¾ä»¥æœ‰æ•ˆæ³›åŒ–ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€å¥—é’ˆå¯¹æ¨ç†ä»»åŠ¡ä¸”æ— éœ€è®­ç»ƒçš„å›¾åŸºç½®ä¿¡åº¦è¯„ä¼°æ–¹æ³•(graph-based confidence estimation)ã€‚è¯¥æ–¹æ³•å°†æ¨ç†è·¯å¾„å»ºæ¨¡ä¸ºæœ‰å‘å›¾ï¼Œå¹¶é€šè¿‡åˆ©ç”¨ä¸­å¿ƒæ€§(centrality)ã€è·¯å¾„æ”¶æ•›æ€§(path convergence)å’Œè·¯å¾„åŠ æƒ(path weighting)ç­‰å›¾è®ºå±æ€§æ¥ä¼°ç®—ç½®ä¿¡åº¦ã€‚åœ¨ä¸¤ä¸ªLLMså’Œä¸‰ä¸ªæ¨ç†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†ç½®ä¿¡åº¦è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå¹¶å¢å¼ºäº†ä¸¤ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚è¿™é¡¹ç ”ç©¶ä¸ºæé«˜å¤æ‚æ¨ç†åœºæ™¯ä¸‹æ¨¡å‹è¾“å‡ºçš„å¯ä¿¡åº¦æä¾›äº†æ–°çš„è§†è§’å’Œæœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Main",
      "pdf_url": "https://arxiv.org/pdf/2509.12908v1",
      "published_date": "2025-09-16 10:02:52 UTC",
      "updated_date": "2025-09-16 10:02:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:25.891296+00:00"
    },
    {
      "arxiv_id": "2509.12897v2",
      "title": "Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models",
      "title_zh": "è·¨å±‚è§†è§‰å¹³æ»‘ï¼šé€šè¿‡æŒç»­èšç„¦å…³é”®ç‰©ä½“å¢å¼ºå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„è§†è§‰ç†è§£èƒ½åŠ›",
      "authors": [
        "Jianfei Zhao",
        "Feng Zhang",
        "Xin Sun",
        "Chong Feng",
        "Zhixing Tan"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) can accurately locate key objects in images, yet their attention to these objects tends to be very brief. Motivated by the hypothesis that sustained focus on key objects can improve LVLMs' visual capabilities, we propose Cross-Layer Vision Smoothing (CLVS). The core idea of CLVS is to incorporate a vision memory that smooths the attention distribution across layers. Specifically, we initialize this vision memory with position-unbiased visual attention in the first layer. In subsequent layers, the model's visual attention jointly considers the vision memory from previous layers, while the memory is updated iteratively, thereby maintaining smooth attention on key objects. Given that visual understanding primarily occurs in the early and middle layers of the model, we use uncertainty as an indicator of completed visual understanding and terminate the smoothing process accordingly. Experiments on four benchmarks across three LVLMs confirm the effectiveness and generalizability of our method. CLVS achieves state-of-the-art overall performance across a variety of visual understanding tasks and attains comparable results to the leading approaches on image captioning benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Cross-Layer Vision Smoothing (CLVS)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)å¯¹å›¾åƒä¸­å…³é”®ç‰©ä½“å…³æ³¨æ—¶é—´è¿‡çŸ­çš„é—®é¢˜ã€‚é€šè¿‡å¼•å…¥ä¸€ç§è§†è§‰è®°å¿†(vision memory)æœºåˆ¶ï¼ŒCLVSèƒ½å¤Ÿå¹³æ»‘æ¨¡å‹åœ¨ä¸åŒå±‚çº§é—´çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼Œä»è€Œå®ç°å¯¹å…³é”®ç‰©ä½“çš„æŒç»­èšç„¦ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨ç¬¬ä¸€å±‚åˆå§‹åŒ–è§†è§‰è®°å¿†ï¼Œå¹¶åœ¨åç»­å±‚ä¸­è¿­ä»£æ›´æ–°è®°å¿†ä¸æ³¨æ„åŠ›çš„ç»“åˆï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤„ç†è§†è§‰ä¿¡æ¯æ—¶ä¿æŒè¿è´¯æ€§ã€‚ç”±äºè§†è§‰ç†è§£å¤šå‘ç”Ÿåœ¨ä¸­æ—©æœŸå±‚ï¼ŒCLVSåˆ©ç”¨ä¸ç¡®å®šæ€§(uncertainty)ä½œä¸ºç†è§£å®Œæˆçš„ä¿¡å·æ¥åŠ¨æ€ç»ˆæ­¢å¹³æ»‘è¿‡ç¨‹ã€‚å®éªŒè¡¨æ˜ï¼ŒCLVSåœ¨ä¸‰ä¸ªLVLMsçš„å››ä¸ªä¸»æµåŸºå‡†æµ‹è¯•ä¸­å‡å±•ç°äº†å‡ºè‰²çš„æ³›åŒ–æ€§ï¼Œåœ¨å¤šé¡¹è§†è§‰ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°äº†state-of-the-artæ€§èƒ½ï¼Œå¹¶åœ¨å›¾åƒæè¿°ä»»åŠ¡ä¸­å–å¾—äº†é¢†å…ˆç»“æœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.12897v2",
      "published_date": "2025-09-16 09:54:01 UTC",
      "updated_date": "2025-11-25 07:54:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:33.786426+00:00"
    },
    {
      "arxiv_id": "2509.12892v1",
      "title": "Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings",
      "title_zh": "Conan-Embedding-v2ï¼šä»é›¶å¼€å§‹è®­ç»ƒç”¨äºæ–‡æœ¬åµŒå…¥çš„å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Shiyu Li",
        "Yang Tang",
        "Ruijie Liu",
        "Shi-Zhe Chen",
        "Xi Chen"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated excellent performance in text embedding tasks. Previous work usually use LoRA to fine-tune existing LLMs, which are limited by the data and training gap between LLMs and embedding models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM trained from scratch and fine-tuned as a text embedder. First, we add news data and multilingual pairs for LLM pretraining to bridge the data gap. Based on this, we propose a cross-lingual retrieval dataset that enables the LLM to better integrate embeddings across different languages. Second, whereas LLMs use a causal mask with token-level loss, embedding models use a bidirectional mask with sentence-level loss. This training gap makes full fine-tuning less effective than LoRA. We introduce a soft-masking mechanism to gradually transition between these two types of masks, enabling the model to learn more comprehensive representations. Based on this, we propose a dynamic hard negative mining method that exposes the model to more difficult negative examples throughout the training process. Being intuitive and effective, with only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese MTEB (May 19, 2025).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Conan-embedding-v2ï¼Œè¿™æ˜¯ä¸€ä¸ªå‚æ•°é‡ä¸º1.4Bã€ä»é›¶å¼€å§‹è®­ç»ƒå¹¶å¾®è°ƒä¸ºæ–‡æœ¬åµŒå…¥å™¨çš„LLMï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹é€šè¿‡LoRAå¾®è°ƒæ—¶é¢ä¸´çš„æ•°æ®å’Œè®­ç»ƒå·®å¼‚é—®é¢˜ã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡å¢åŠ æ–°é—»æ•°æ®å’Œå¤šè¯­è¨€å¯¹ï¼Œå¹¶æ„å»ºè·¨è¯­è¨€æ£€ç´¢æ•°æ®é›†ï¼Œæœ‰æ•ˆå¼¥åˆäº†æ•°æ®é¸¿æ²Ÿå¹¶å¢å¼ºäº†æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„åµŒå…¥æ•´åˆèƒ½åŠ›ã€‚é’ˆå¯¹LLMä¼ ç»ŸCausal Maskä¸åµŒå…¥æ¨¡å‹Bidirectional Maskä¹‹é—´çš„è®­ç»ƒå·®å¼‚ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§Soft-maskingæœºåˆ¶ï¼Œå®ç°äº†ä¸åŒæ©ç ç±»å‹çš„å¹³æ»‘è¿‡æ¸¡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰æ›´å…¨é¢çš„è¯­ä¹‰è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åŠ¨æ€Hard Negative Miningæ–¹æ³•ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­æä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„è´Ÿæ ·æœ¬ä»¥å¼ºåŒ–å¯¹æ¯”å­¦ä¹ æ•ˆæœã€‚å®éªŒç»“æœè¯æ˜ï¼Œå°½ç®¡è§„æ¨¡ä»…ä¸º1.4Bï¼ŒConan-embedding-v2åœ¨Massive Text Embedding Benchmark (MTEB)å’Œä¸­æ–‡MTEBæ’è¡Œæ¦œä¸Šå‡å–å¾—äº†SOTAæ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Oral",
      "pdf_url": "https://arxiv.org/pdf/2509.12892v1",
      "published_date": "2025-09-16 09:48:11 UTC",
      "updated_date": "2025-09-16 09:48:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:43.286483+00:00"
    },
    {
      "arxiv_id": "2509.14278v1",
      "title": "Beyond Data Privacy: New Privacy Risks for Large Language Models",
      "title_zh": "è¶…è¶Šæ•°æ®éšç§ï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ–°å‹éšç§é£é™©",
      "authors": [
        "Yuntao Du",
        "Zitao Li",
        "Ninghui Li",
        "Bolin Ding"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable progress in natural language understanding, reasoning, and autonomous decision-making. However, these advancements have also come with significant privacy concerns. While significant research has focused on mitigating the data privacy risks of LLMs during various stages of model training, less attention has been paid to new threats emerging from their deployment. The integration of LLMs into widely used applications and the weaponization of their autonomous abilities have created new privacy vulnerabilities. These vulnerabilities provide opportunities for both inadvertent data leakage and malicious exfiltration from LLM-powered systems. Additionally, adversaries can exploit these systems to launch sophisticated, large-scale privacy attacks, threatening not only individual privacy but also financial security and societal trust. In this paper, we systematically examine these emerging privacy risks of LLMs. We also discuss potential mitigation strategies and call for the research community to broaden its focus beyond data privacy risks, developing new defenses to address the evolving threats posed by increasingly powerful LLMs and LLM-powered systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨éƒ¨ç½²å’Œåº”ç”¨é˜¶æ®µé¢ä¸´çš„æ–°å…´éšç§é£é™©ï¼ŒæŒ‡å‡ºè¿™äº›é£é™©å·²è¶…å‡ºä¼ ç»Ÿçš„è®­ç»ƒæ•°æ®éšç§èŒƒç•´ã€‚è®ºæ–‡æ·±å…¥åˆ†æäº† LLMs é›†æˆåˆ°å¹¿æ³›åº”ç”¨ä¸­æ‰€äº§ç”Ÿçš„æ–°æ¼æ´ï¼Œä»¥åŠå…¶è‡ªä¸»å†³ç­–èƒ½åŠ›çš„æ­¦å™¨åŒ–å¦‚ä½•å¯¼è‡´æ— æ„çš„æ•°æ®æ³„éœ²æˆ–æ¶æ„çš„æ•°æ®å¤–æ³„ã€‚æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™äº› LLM-powered systems å‘èµ·å¤æ‚ä¸”å¤§è§„æ¨¡çš„éšç§æ”»å‡»ï¼Œä»è€Œå¨èƒåˆ°ä¸ªäººéšç§ã€é‡‘èå®‰å…¨ä»¥åŠç¤¾ä¼šä¿¡ä»»ã€‚é’ˆå¯¹è¿™äº›æ¼”è¿›ä¸­çš„å¨èƒï¼Œç ”ç©¶è®¨è®ºäº†æ½œåœ¨çš„ç¼“è§£ç­–ç•¥ (mitigation strategies)ï¼Œå¹¶å‘¼åç ”ç©¶ç•Œå°†æ³¨æ„åŠ›ä»å•çº¯çš„æ•°æ®éšç§é£é™©æ‰©å±•åˆ°æ›´å¹¿æ³›çš„é˜²å¾¡æœºåˆ¶ã€‚è¯¥ç»¼è¿°æ€§å·¥ä½œæ—¨åœ¨é€šè¿‡æ­ç¤ºæ–°å‹éšç§è„†å¼±æ€§ï¼Œæ¨åŠ¨å¼€å‘èƒ½å¤Ÿåº”å¯¹æ—¥ç›Šå¼ºå¤§çš„ LLMs ç³»ç»Ÿçš„å®‰å…¨é˜²èŒƒæªæ–½ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.14278v1",
      "published_date": "2025-09-16 09:46:09 UTC",
      "updated_date": "2025-09-16 09:46:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:50.093799+00:00"
    },
    {
      "arxiv_id": "2509.12888v1",
      "title": "Runge-Kutta Approximation and Decoupled Attention for Rectified Flow Inversion and Semantic Editing",
      "title_zh": "é¢å‘ä¿®æ­£æµåæ¼”ä¸è¯­ä¹‰ç¼–è¾‘çš„ Runge-Kutta è¿‘ä¼¼ä¸è§£è€¦æ³¨æ„åŠ›",
      "authors": [
        "Weiming Chen",
        "Zhihan Zhu",
        "Yijia Wang",
        "Zhihai He"
      ],
      "abstract": "Rectified flow (RF) models have recently demonstrated superior generative performance compared to DDIM-based diffusion models. However, in real-world applications, they suffer from two major challenges: (1) low inversion accuracy that hinders the consistency with the source image, and (2) entangled multimodal attention in diffusion transformers, which hinders precise attention control. To address the first challenge, we propose an efficient high-order inversion method for rectified flow models based on the Runge-Kutta solver of differential equations. To tackle the second challenge, we introduce Decoupled Diffusion Transformer Attention (DDTA), a novel mechanism that disentangles text and image attention inside the multimodal diffusion transformers, enabling more precise semantic control. Extensive experiments on image reconstruction and text-guided editing tasks demonstrate that our method achieves state-of-the-art performance in terms of fidelity and editability. Code is available at https://github.com/wmchen/RKSovler_DDTA.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ Rectified Flow (RF) æ¨¡å‹åœ¨åæ¼”å‡†ç¡®ç‡ä½å’Œå¤šæ¨¡æ€æ³¨æ„åŠ›è€¦åˆå¯¼è‡´è¯­ä¹‰æ§åˆ¶å›°éš¾ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åŸºäºå¾®åˆ†æ–¹ç¨‹ Runge-Kutta æ±‚è§£å™¨çš„é«˜é˜¶åæ¼”æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹ä¸æºå›¾åƒçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº† Decoupled Diffusion Transformer Attention (DDTA) æœºåˆ¶ï¼Œé€šè¿‡è§£è€¦å¤šæ¨¡æ€æ‰©æ•£å˜æ¢å™¨ (Diffusion Transformers) å†…éƒ¨çš„æ–‡æœ¬ä¸å›¾åƒæ³¨æ„åŠ›ï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„è¯­ä¹‰æ§åˆ¶ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒé‡å»ºå’Œæ–‡æœ¬å¼•å¯¼ç¼–è¾‘ä»»åŠ¡ä¸­å‡å–å¾—äº†å“è¶Šè¡¨ç°ï¼Œåœ¨å¿ å®åº¦ (fidelity) å’Œå¯ç¼–è¾‘æ€§ (editability) æ–¹é¢è¾¾åˆ°äº† state-of-the-art æ€§èƒ½ã€‚è¯¥é¡¹å·¥ä½œçš„ç›¸å…³ä»£ç å·²åœ¨å¼€æºç¤¾åŒºå‘å¸ƒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12888v1",
      "published_date": "2025-09-16 09:41:14 UTC",
      "updated_date": "2025-09-16 09:41:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:57:56.687534+00:00"
    },
    {
      "arxiv_id": "2509.12886v1",
      "title": "The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations",
      "title_zh": "LLM å·²ç„¶çŸ¥æ™“ï¼šåŸºäºéšå±‚è¡¨å¾è¯„ä¼° LLM æ„ŸçŸ¥çš„é¢˜ç›®éš¾åº¦",
      "authors": [
        "Yubo Zhu",
        "Dongrui Liu",
        "Zecheng Lin",
        "Wei Tong",
        "Sheng Zhong",
        "Jing Shao"
      ],
      "abstract": "Estimating the difficulty of input questions as perceived by large language models (LLMs) is essential for accurate performance evaluation and adaptive inference. Existing methods typically rely on repeated response sampling, auxiliary models, or fine-tuning the target model itself, which may incur substantial computational costs or compromise generality. In this paper, we propose a novel approach for difficulty estimation that leverages only the hidden representations produced by the target LLM. We model the token-level generation process as a Markov chain and define a value function to estimate the expected output quality given any hidden state. This allows for efficient and accurate difficulty estimation based solely on the initial hidden state, without generating any output tokens. Extensive experiments across both textual and multimodal tasks demonstrate that our method consistently outperforms existing baselines in difficulty estimation. Moreover, we apply our difficulty estimates to guide adaptive reasoning strategies, including Self-Consistency, Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer generated tokens.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨éšè—è¡¨ç¤º(Hidden Representations)æ¥ä¼°è®¡æ¨¡å‹æ„ŸçŸ¥é—®é¢˜éš¾åº¦çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–é‡å¤é‡‡æ ·ã€è¾…åŠ©æ¨¡å‹æˆ–å¾®è°ƒæ‰€å¸¦æ¥çš„é«˜è®¡ç®—æˆæœ¬å’Œé€šç”¨æ€§ä¸è¶³é—®é¢˜ï¼Œè¯¥ç ”ç©¶å°†Tokençº§åˆ«çš„ç”Ÿæˆè¿‡ç¨‹å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«é“¾(Markov chain)ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªä»·å€¼å‡½æ•°(Value Function)æ¥é¢„æµ‹ç»™å®šéšè—çŠ¶æ€ä¸‹çš„é¢„æœŸè¾“å‡ºè´¨é‡ã€‚è¯¥æ–¹æ³•ä»…éœ€åˆå§‹éšè—çŠ¶æ€å³å¯åœ¨ä¸ç”Ÿæˆä»»ä½•è¾“å‡ºTokençš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆå‡†ç¡®çš„éš¾åº¦ä¼°è®¡ï¼Œåœ¨æ–‡æœ¬å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚æ­¤å¤–ï¼Œé€šè¿‡å°†éš¾åº¦ä¼°è®¡åº”ç”¨äºæŒ‡å¯¼è‡ªæ´½æ€§(Self-Consistency)ã€Né€‰ä¸€(Best-of-N)å’Œè‡ªæˆ‘ä¿®æ­£(Self-Refine)ç­‰è‡ªé€‚åº”æ¨ç†ç­–ç•¥ï¼Œè¯¥æ–¹æ³•åœ¨å‡å°‘ç”ŸæˆTokenæ•°é‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12886v1",
      "published_date": "2025-09-16 09:38:41 UTC",
      "updated_date": "2025-09-16 09:38:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:00.495794+00:00"
    },
    {
      "arxiv_id": "2511.14763v2",
      "title": "Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm",
      "title_zh": "é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ¨èç³»ç»Ÿçš„æˆå‘˜æ¨ç†æ”»å‡»ï¼šä¸€ç§åŸºäºè’¸é¦çš„æ–°å‹èŒƒå¼",
      "authors": [
        "Li Cuihong",
        "Huang Xiaowen",
        "Yin Chuanhuan",
        "Sang Jitao"
      ],
      "abstract": "Membership Inference Attack (MIA) aims to determine whether a specific data sample was included in the training dataset of a target model. Traditional MIA approaches rely on shadow models to mimic target model behavior, but their effectiveness diminishes for Large Language Model (LLM)-based recommendation systems due to the scale and complexity of training data. This paper introduces a novel knowledge distillation-based MIA paradigm tailored for LLM-based recommendation systems. Our method constructs a reference model via distillation, applying distinct strategies for member and non-member data to enhance discriminative capabilities. The paradigm extracts fused features (e.g., confidence, entropy, loss, and hidden layer vectors) from the reference model to train an attack model, overcoming limitations of individual features. Extensive experiments on extended datasets (Last.FM, MovieLens, Book-Crossing, Delicious) and diverse LLMs (T5, GPT-2, LLaMA3) demonstrate that our approach significantly outperforms shadow model-based MIAs and individual-feature baselines. The results show its practicality for privacy attacks in LLM-driven recommender systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM-based)çš„æ¨èç³»ç»Ÿæå‡ºäº†ä¸€ç§æ–°å‹çš„æˆå‘˜æ¨ç†æ”»å‡»(Membership Inference Attack, MIA)èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå½±å­æ¨¡å‹(shadow models)åœ¨å¤„ç†å¤§è§„æ¨¡å¤æ‚è®­ç»ƒæ•°æ®æ—¶æœ‰æ•ˆæ€§ä¸è¶³çš„é—®é¢˜ã€‚è¯¥èŒƒå¼å¼•å…¥äº†åŸºäºçŸ¥è¯†è’¸é¦(knowledge distillation-based)çš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºå‚è€ƒæ¨¡å‹å¹¶å¯¹æˆå‘˜ä¸éæˆå‘˜æ•°æ®åº”ç”¨å·®å¼‚åŒ–ç­–ç•¥ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿçš„åˆ¤åˆ«èƒ½åŠ›ã€‚ç ”ç©¶é€šè¿‡ä»å‚è€ƒæ¨¡å‹ä¸­æå–ç½®ä¿¡åº¦(confidence)ã€ç†µ(entropy)ã€æŸå¤±(loss)åŠéšè—å±‚å‘é‡(hidden layer vectors)ç­‰èåˆç‰¹å¾æ¥è®­ç»ƒæ”»å‡»æ¨¡å‹ï¼Œæœ‰æ•ˆå…‹æœäº†å•ä¸€ç‰¹å¾çš„å±€é™æ€§ã€‚åœ¨Last.FMã€MovieLensã€Book-Crossingå’ŒDeliciousç­‰å¤šä¸ªæ•°æ®é›†ï¼Œä»¥åŠT5ã€GPT-2å’ŒLLaMA3ç­‰å¤šç§å¤§è¯­è¨€æ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å½±å­æ¨¡å‹æ”»å‡»å’Œå•ä¸€ç‰¹å¾åŸºçº¿ã€‚è¯¥ç ”ç©¶æˆæœä¸ä»…æå‡äº†æ”»å‡»çš„æˆåŠŸç‡ï¼Œä¹Ÿä¸ºè¯„ä¼°LLMé©±åŠ¨çš„æ¨èç³»ç»Ÿä¸­çš„éšç§é£é™©æä¾›äº†å®ç”¨çš„å·¥å…·å’Œæ·±åº¦è§è§£ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.14763v2",
      "published_date": "2025-09-16 09:36:43 UTC",
      "updated_date": "2025-12-02 09:49:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:20.690004+00:00"
    },
    {
      "arxiv_id": "2509.12875v3",
      "title": "LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning",
      "title_zh": "LTA-thinkerï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹å¤æ‚æ¨ç†çš„æ½œæ€ç»´å¢å¼ºè®­ç»ƒæ¡†æ¶",
      "authors": [
        "Jiaqi Wang",
        "Binquan Ji",
        "Haibo Luo",
        "Yiyang Qi",
        "Ruiting Li",
        "Huiyan Wang",
        "Yuantao Han",
        "Cangyi Yang",
        "jiaxu Zhang",
        "Feiliang Ren"
      ],
      "abstract": "Complex Reasoning in Large Language Models can be dynamically optimized using Test-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut, SoftCoT and its variant are effective in continuous latent space inference, the core bottleneck still lies in the efficient generation and utilization of high-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger variance in the generated Latent Thought distribution more closely approximates the golden truth distribution, we propose a Latent Thought-Augmented Training Framework--LTA-Thinker, which improves distributional variance and enhances reasoning performance from two perspectives. First, LTA-Thinker constructs a Latent Thought generation architecture based on a learnable prior. This architecture aims to increase the variance distribution of generated Latent Thought Vectors in order to simplify the overall structure and raise the performance ceiling. Second, LTA-Thinker introduces a distribution-based directional optimization paradigm that jointly constrains both distribution locality and distribution scale. This mechanism improves information efficiency and computational cost through a multi-objective co-training strategy, which combines standard Supervised Fine-Tuning (SFT) loss with two novel losses: Semantic Alignment Loss, which utilizes KL divergence to ensure that the Latent Thought is highly relevant to the semantics of the question; Reasoning Focus Loss, which utilizes a contrastive learning mechanism to guide the model to focus on the most critical reasoning steps. Experiments show that LTA-thinker achieves state-of-the-art (SOTA) performance among various baselines and demonstrates a higher performance ceiling and better scaling effects.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤æ‚æ¨ç†ä¸­çš„è¿‡åº¦æ€è€ƒ(Overthinking)é—®é¢˜ï¼Œæå‡ºäº†LTA-thinkerè¿™ä¸€æ½œåœ¨æ€ç»´å¢å¼ºè®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¼˜åŒ–æ½œåœ¨æ€ç»´(Latent Thought)çš„ç”Ÿæˆä¸åˆ©ç”¨æ•ˆç‡æ¥æå‡æ¨ç†æ€§èƒ½ã€‚è¯¥æ¡†æ¶é¦–å…ˆæ„å»ºäº†åŸºäºå¯å­¦ä¹ å…ˆéªŒçš„ç”Ÿæˆæ¶æ„ï¼Œé€šè¿‡å¢åŠ æ½œåœ¨æ€ç»´å‘é‡çš„åˆ†å¸ƒæ–¹å·®æ¥ç®€åŒ–ç»“æ„å¹¶æé«˜æ€§èƒ½ä¸Šé™ã€‚æ­¤å¤–ï¼ŒLTA-thinkerå¼•å…¥äº†ç»“åˆè¯­ä¹‰å¯¹é½æŸå¤±(Semantic Alignment Loss)å’Œæ¨ç†èšç„¦æŸå¤±(Reasoning Focus Loss)çš„å¤šç›®æ ‡ååŒè®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨KLæ•£åº¦ä¸å¯¹æ¯”å­¦ä¹ æœºåˆ¶ç¡®ä¿æ½œåœ¨æ€ç»´çš„è¯­ä¹‰ç›¸å…³æ€§ï¼Œå¹¶å¼•å¯¼æ¨¡å‹èšç„¦äºå…³é”®æ¨ç†æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLTA-thinkeråœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†å½“å‰æœ€ä¼˜(SOTA)æ°´å¹³ï¼Œå±•ç°å‡ºæ¯”ç°æœ‰åŸºçº¿æ¨¡å‹æ›´é«˜çš„æ€§èƒ½å¤©èŠ±æ¿å’Œæ›´ä½³çš„å¯æ‰©å±•æ€§(Scaling effects)ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12875v3",
      "published_date": "2025-09-16 09:27:57 UTC",
      "updated_date": "2025-12-16 12:50:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:24.593061+00:00"
    },
    {
      "arxiv_id": "2509.19341v2",
      "title": "Fine-Grained AI Model Caching and Downloading With Coordinated Multipoint Broadcasting in Multi-Cell Edge Networks",
      "title_zh": "å¤šå°åŒºè¾¹ç¼˜ç½‘ç»œä¸­åŸºäºåä½œå¤šç‚¹å¹¿æ’­çš„ç»†ç²’åº¦AIæ¨¡å‹ç¼“å­˜ä¸ä¸‹è½½",
      "authors": [
        "Yang Fu",
        "Peng Qin",
        "Yueyue Zhang",
        "Pao Cheng",
        "Jun Lu",
        "Yifei Wang"
      ],
      "abstract": "6G networks are envisioned to support on-demand AI model downloading to accommodate diverse inference requirements of end users. By proactively caching models at edge nodes, users can retrieve the requested models with low latency for on-device AI inference. However, the substantial size of contemporary AI models poses significant challenges for edge caching under limited storage capacity, as well as for the concurrent delivery of heterogeneous models over wireless channels. To address these challenges, we propose a fine-grained AI model caching and downloading system that exploits parameter reusability, stemming from the common practice of fine-tuning task-specific models from a shared pre-trained model with frozen parameters. This system selectively caches model parameter blocks (PBs) at edge nodes, eliminating redundant storage of reusable parameters across different cached models. Additionally, it incorporates coordinated multipoint (CoMP) broadcasting to simultaneously deliver reusable PBs to multiple users, thereby enhancing downlink spectrum utilization. Under this arrangement, we formulate a model downloading delay minimization problem to jointly optimize PB caching, migration (among edge nodes), and broadcasting beamforming. To tackle this intractable problem, we develop a distributed multi-agent learning framework that enables edge nodes to explicitly learn mutual influence among their actions, thereby facilitating cooperation. Furthermore, a data augmentation approach is proposed to adaptively generate synthetic training samples through a predictive model, boosting sample efficiency and accelerating policy learning. Both theoretical analysis and simulation experiments validate the superior convergence performance of the proposed learning framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹6Gç½‘ç»œä¸­AIæ¨¡å‹ä¸‹è½½é¢ä¸´çš„å­˜å‚¨å®¹é‡é™åˆ¶å’Œæ— çº¿ä¼ è¾“æ•ˆç‡æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»†ç²’åº¦çš„AIæ¨¡å‹ç¼“å­˜ä¸ä¸‹è½½ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨äº†åŸºäºå…±äº«é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒæ—¶äº§ç”Ÿçš„ parameter reusabilityï¼Œé€šè¿‡åœ¨è¾¹ç¼˜èŠ‚ç‚¹é€‰æ‹©æ€§ç¼“å­˜ parameter blocks (PBs) æ¥æ¶ˆé™¤å†—ä½™å­˜å‚¨ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº† coordinated multipoint (CoMP) å¹¿æ’­æŠ€æœ¯ï¼Œä»¥å®ç°å‘å¤šä¸ªç”¨æˆ·åŒæ­¥ä¼ è¾“å¯é‡ç”¨ PBsï¼Œä»è€Œæå‡é¢‘è°±åˆ©ç”¨ç‡ã€‚ä¸ºäº†æœ€å°åŒ–ä¸‹è½½å»¶è¿Ÿï¼Œè®ºæ–‡å°† PB cachingã€migration å’Œ broadcasting beamforming æ„å»ºä¸ºè”åˆä¼˜åŒ–é—®é¢˜ï¼Œå¹¶å¼€å‘äº†ä¸€ç§åˆ†å¸ƒå¼çš„ multi-agent learning æ¡†æ¶ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆé€šè¿‡ data augmentation æ–¹æ³•è‡ªé€‚åº”ç”Ÿæˆåˆæˆè®­ç»ƒæ ·æœ¬ï¼Œæ˜¾è‘—æé«˜äº†æ ·æœ¬æ•ˆç‡å¹¶åŠ é€Ÿäº†ç­–ç•¥å­¦ä¹ ã€‚ç†è®ºåˆ†æä¸ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ”¶æ•›æ€§èƒ½å’Œé™ä½å»¶è¿Ÿæ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19341v2",
      "published_date": "2025-09-16 09:14:15 UTC",
      "updated_date": "2025-10-06 13:23:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:36.767674+00:00"
    },
    {
      "arxiv_id": "2509.12849v1",
      "title": "AI Factories: It's time to rethink the Cloud-HPC divide",
      "title_zh": "AI å·¥å‚ï¼šæ˜¯æ—¶å€™é‡æ–°å®¡è§†äº‘è®¡ç®—ä¸é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰çš„ç•Œé™äº†",
      "authors": [
        "Pedro Garcia Lopez",
        "Daniel Barcelona Pons",
        "Marcin Copik",
        "Torsten Hoefler",
        "Eduardo QuiÃ±ones",
        "Maciej Malawski",
        "Peter Pietzutch",
        "Alberto Marti",
        "Thomas Ohlson Timoudas",
        "Aleksander Slominski"
      ],
      "abstract": "The strategic importance of artificial intelligence is driving a global push toward Sovereign AI initiatives. Nationwide governments are increasingly developing dedicated infrastructures, called AI Factories (AIF), to achieve technological autonomy and secure the resources necessary to sustain robust local digital ecosystems.\n  In Europe, the EuroHPC Joint Undertaking is investing hundreds of millions of euros into several AI Factories, built atop existing high-performance computing (HPC) supercomputers. However, while HPC systems excel in raw performance, they are not inherently designed for usability, accessibility, or serving as public-facing platforms for AI services such as inference or agentic applications. In contrast, AI practitioners are accustomed to cloud-native technologies like Kubernetes and object storage, tools that are often difficult to integrate within traditional HPC environments.\n  This article advocates for a dual-stack approach within supercomputers: integrating both HPC and cloud-native technologies. Our goal is to bridge the divide between HPC and cloud computing by combining high performance and hardware acceleration with ease of use and service-oriented front-ends. This convergence allows each paradigm to amplify the other. To this end, we will study the cloud challenges of HPC (Serverless HPC) and the HPC challenges of cloud technologies (High-performance Cloud).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¸»æƒäººå·¥æ™ºèƒ½(Sovereign AI)æˆ˜ç•¥èƒŒæ™¯ä¸‹ï¼ŒAI Factories (AIF) åŸºç¡€è®¾æ–½å»ºè®¾çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ¬§æ´² EuroHPC è”åˆè®¡åˆ’ä¸­åŸºäºé«˜æ€§èƒ½è®¡ç®—(HPC)æ„å»º AIF çš„ç°çŠ¶ã€‚æ–‡ç« æŒ‡å‡ºï¼Œå°½ç®¡ HPC ç³»ç»Ÿåœ¨åŸå§‹æ€§èƒ½ä¸Šè¡¨ç°å“è¶Šï¼Œä½†åœ¨å¯ç”¨æ€§ã€å¯è®¿é—®æ€§ä»¥åŠæ”¯æŒæ¨ç†æˆ–æ™ºèƒ½ä½“åº”ç”¨(agentic applications)ç­‰å…¬ç”¨æœåŠ¡æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä¸”éš¾ä»¥ä¸ä»ä¸šè€…ä¹ æƒ¯çš„ Kubernetes å’Œå¯¹è±¡å­˜å‚¨ç­‰äº‘åŸç”Ÿ(cloud-native)æŠ€æœ¯é›†æˆã€‚ä¸ºæ­¤ï¼Œä½œè€…æå€¡åœ¨è¶…çº§è®¡ç®—æœºä¸­é‡‡ç”¨åŒæ ˆ(dual-stack)æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆ HPC å’Œäº‘åŸç”ŸæŠ€æœ¯æ¥æ¡¥æ¥ä¸¤è€…ä¹‹é—´çš„é¸¿æ²Ÿã€‚è¯¥æ–¹æ¡ˆæ—¨åœ¨ç»“åˆç¡¬ä»¶åŠ é€Ÿçš„é«˜æ€§èƒ½ä¸æœåŠ¡å¯¼å‘å‹å‰ç«¯çš„æ˜“ç”¨æ€§ï¼Œä½¿ä¸¤ç§æŠ€æœ¯èŒƒå¼ç›¸äº’å¢å¼ºã€‚é€šè¿‡æ·±å…¥ç ”ç©¶æ— æœåŠ¡å™¨é«˜æ€§èƒ½è®¡ç®—(Serverless HPC)å’Œé«˜æ€§èƒ½äº‘(High-performance Cloud)é¢ä¸´çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶ä¸ºæ„å»ºè‡ªä¸»ã€é«˜æ•ˆçš„æ•°å­—ç”Ÿæ€ç³»ç»Ÿæä¾›äº†æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12849v1",
      "published_date": "2025-09-16 09:08:05 UTC",
      "updated_date": "2025-09-16 09:08:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:33.400541+00:00"
    },
    {
      "arxiv_id": "2509.12845v2",
      "title": "Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training",
      "title_zh": "åˆ©ç”¨é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒçš„å±æ€§æ„ŸçŸ¥è¡¨å¾æå‡å¼‚å¸¸å£°éŸ³æ£€æµ‹",
      "authors": [
        "Xin Fang",
        "Guirui Zhong",
        "Qing Wang",
        "Fan Chu",
        "Lei Wang",
        "Mengui Qian",
        "Mingqi Cai",
        "Jiangzhao Wu",
        "Jianqing Gao",
        "Jun Du"
      ],
      "abstract": "Anomalous Sound Detection (ASD) is often formulated as a machine attribute classification task, a strategy necessitated by the common scenario where only normal data is available for training. However, the exhaustive collection of machine attribute labels is laborious and impractical. To address the challenge of missing attribute labels, this paper proposes an agglomerative hierarchical clustering method for the assignment of pseudo-attribute labels using representations derived from a domain-adaptive pre-trained model, which are expected to capture machine attribute characteristics. We then apply model adaptation to this pre-trained model through supervised fine-tuning for machine attribute classification, resulting in a new state-of-the-art performance. Evaluation on the Detection and Classification of Acoustic Scenes and Events (DCASE) 2025 Challenge dataset demonstrates that our proposed approach yields significant performance gains, ultimately outperforming our previous top-ranking system in the challenge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼‚å¸¸å£°éŸ³æ£€æµ‹(Anomalous Sound Detection, ASD)ä¸­æœºå™¨å±æ€§æ ‡ç­¾è·å–å›°éš¾çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒ(Domain-adaptive Pre-training)æ¨¡å‹æå–å±æ€§æ„ŸçŸ¥è¡¨å¾çš„æ”¹è¿›æ–¹æ¡ˆã€‚ä¸ºäº†è§£å†³å±æ€§æ ‡ç­¾ç¼ºå¤±çš„é—®é¢˜ï¼Œç ”ç©¶é‡‡ç”¨å‡èšå±‚æ¬¡èšç±»(Agglomerative Hierarchical Clustering)æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æ•è·çš„æœºå™¨ç‰¹å¾è‡ªåŠ¨åˆ†é…ä¼ªå±æ€§æ ‡ç­¾(Pseudo-attribute labels)ã€‚éšåï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒ(Supervised Fine-tuning)å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨¡å‹é€‚é…(Model adaptation)ï¼Œä»¥æå‡æœºå™¨å±æ€§åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚åœ¨DCASE 2025æŒ‘æˆ˜èµ›æ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿæ€§èƒ½ï¼Œä¸ä»…è¶…è¶Šäº†è¯¥å›¢é˜Ÿæ­¤å‰æ’åé¢†å…ˆçš„ç³»ç»Ÿï¼Œè¿˜è¾¾åˆ°äº†æ–°çš„SOTAæ°´å¹³ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Copyright 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
      "pdf_url": "https://arxiv.org/pdf/2509.12845v2",
      "published_date": "2025-09-16 09:05:41 UTC",
      "updated_date": "2025-09-19 06:17:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:30.755178+00:00"
    },
    {
      "arxiv_id": "2509.12838v2",
      "title": "Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸åˆ†å¸ƒå¼ç°åœºçŸ¥è¯†çš„å¤šæœºå™¨äººå¤šç›®æ ‡æ£€ç´¢ä»»åŠ¡è§„åˆ’",
      "authors": [
        "Kento Murata",
        "Shoichi Hasegawa",
        "Tomochika Ishikawa",
        "Yoshinobu Hagiwara",
        "Akira Taniguchi",
        "Lotfi El Hafi",
        "Tadahiro Taniguchi"
      ],
      "abstract": "It is crucial to efficiently execute instructions such as \"Find an apple and a banana\" or \"Get ready for a field trip,\" which require searching for multiple objects or understanding context-dependent commands. This study addresses the challenging problem of determining which robot should be assigned to which part of a task when each robot possesses different situational on-site knowledge-specifically, spatial concepts learned from the area designated to it by the user. We propose a task planning framework that leverages large language models (LLMs) and spatial concepts to decompose natural language instructions into subtasks and allocate them to multiple robots. We designed a novel few-shot prompting strategy that enables LLMs to infer required objects from ambiguous commands and decompose them into appropriate subtasks. In our experiments, the proposed method achieved 47/50 successful assignments, outperforming random (28/50) and commonsense-based assignment (26/50). Furthermore, we conducted qualitative evaluations using two actual mobile manipulators. The results demonstrated that our framework could handle instructions, including those involving ad hoc categories such as \"Get ready for a field trip,\" by successfully performing task decomposition, assignment, sequential planning, and execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œç©ºé—´æ¦‚å¿µ (spatial concepts) çš„å¤šæœºå™¨äººä»»åŠ¡è§„åˆ’æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…·æœ‰åˆ†å¸ƒå¼ç°åœºçŸ¥è¯†çš„å¤šç›®æ ‡æ£€ç´¢ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é’ˆå¯¹æ¯ä¸ªæœºå™¨äººæŒæ¡ä¸åŒåŒºåŸŸç©ºé—´æ¦‚å¿µçš„å¤æ‚åœºæ™¯ï¼Œèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤æœ‰æ•ˆåˆ†è§£ä¸ºå­ä»»åŠ¡å¹¶åˆ†é…ç»™å¤šä¸ªæœºå™¨äººã€‚ç ”ç©¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ Few-shot prompting ç­–ç•¥ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹ (LLMs) èƒ½å¤Ÿä»æ¨¡ç³ŠæŒ‡ä»¤ä¸­æ¨æ–­æ‰€éœ€ç›®æ ‡ï¼Œå¹¶å®Œæˆå­ä»»åŠ¡çš„åˆ†è§£ã€åˆ†é…ã€é¡ºåºè§„åˆ’ä¸æ‰§è¡Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä»»åŠ¡åˆ†é…ä¸Šçš„æˆåŠŸç‡è¾¾åˆ° 47/50ï¼Œæ˜¾è‘—ä¼˜äºéšæœºåˆ†é…å’ŒåŸºäºå¸¸è¯†çš„åˆ†é…åŸºçº¿æ¨¡å‹ã€‚é€šè¿‡åœ¨ä¸¤å°ç§»åŠ¨æ“ä½œæœºå™¨äººä¸Šçš„å®šæ€§è¯„ä¼°ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤„ç†å¦‚ \"å‡†å¤‡éƒŠæ¸¸\" ç­‰åŒ…å«ä¸´æ—¶ç±»åˆ« (ad hoc categories) çš„å¤æ‚æŒ‡ä»¤æ—¶å…·æœ‰å“è¶Šçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to AROB-ISBC 2026 (Journal Track option)",
      "pdf_url": "https://arxiv.org/pdf/2509.12838v2",
      "published_date": "2025-09-16 09:00:25 UTC",
      "updated_date": "2025-09-30 12:31:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:36.252228+00:00"
    },
    {
      "arxiv_id": "2509.12831v1",
      "title": "A Lightweight Pipeline for Noisy Speech Voice Cloning and Accurate Lip Sync Synthesis",
      "title_zh": "é’ˆå¯¹å™ªå£°è¯­éŸ³å…‹éš†ä¸ç²¾å‡†å”‡å½¢åŒæ­¥åˆæˆçš„è½»é‡çº§æµæ°´çº¿",
      "authors": [
        "Javeria Amir",
        "Farwa Attaria",
        "Mah Jabeen",
        "Umara Noor",
        "Zahid Rashid"
      ],
      "abstract": "Recent developments in voice cloning and talking head generation demonstrate impressive capabilities in synthesizing natural speech and realistic lip synchronization. Current methods typically require and are trained on large scale datasets and computationally intensive processes using clean studio recorded inputs that is infeasible in noisy or low resource environments. In this paper, we introduce a new modular pipeline comprising Tortoise text to speech. It is a transformer based latent diffusion model that can perform high fidelity zero shot voice cloning given only a few training samples. We use a lightweight generative adversarial network architecture for robust real time lip synchronization. The solution will contribute to many essential tasks concerning less reliance on massive pre training generation of emotionally expressive speech and lip synchronization in noisy and unconstrained scenarios. The modular structure of the pipeline allows an easy extension for future multi modal and text guided voice modulation and it could be used in real world systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸“ä¸ºå™ªå£°ç¯å¢ƒè®¾è®¡çš„è½»é‡çº§è¯­éŸ³å…‹éš†ä¸ç²¾ç¡®å”‡å½¢åŒæ­¥åˆæˆæµæ°´çº¿ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æŠ€æœ¯å¯¹å¤§è§„æ¨¡æ•°æ®é›†å’Œçº¯å‡€å½•éŸ³è¿‡åº¦ä¾èµ–çš„é—®é¢˜ã€‚æ ¸å¿ƒæ¶æ„æ•´åˆäº† Tortoise text-to-speechï¼Œè¿™æ˜¯ä¸€ç§åŸºäº transformer çš„ latent diffusion æ¨¡å‹ï¼Œä»…éœ€å°‘é‡è®­ç»ƒæ ·æœ¬å³å¯å®ç°é«˜ä¿çœŸçš„ zero-shot è¯­éŸ³å…‹éš†ã€‚åœ¨è§†è§‰åˆæˆæ–¹é¢ï¼Œè¯¥æµæ°´çº¿é‡‡ç”¨è½»é‡çº§çš„ generative adversarial network (GAN) æ¶æ„ï¼Œç¡®ä¿åœ¨ä¸å—æ§çš„ç°å®åœºæ™¯ä¸‹å®ç°ç¨³å¥ä¸”å®æ—¶çš„å”‡å½¢åŒæ­¥ã€‚è¯¥æ–¹æ¡ˆæ˜¾è‘—é™ä½äº†å¯¹æµ·é‡é¢„è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå¹¶èƒ½åœ¨å¤æ‚ç¯å¢ƒä¸‹ç”Ÿæˆå…·æœ‰æƒ…æ„Ÿè¡¨ç°åŠ›çš„è¯­éŸ³å†…å®¹ã€‚æ­¤å¤–ï¼Œå¾—ç›Šäºå…¶æ¨¡å—åŒ–çš„ç»“æ„è®¾è®¡ï¼Œè¯¥ç³»ç»Ÿæ˜“äºæ‰©å±•è‡³å¤šæ¨¡æ€åŠæ–‡æœ¬å¼•å¯¼çš„è¯­éŸ³è°ƒèŠ‚ä»»åŠ¡ï¼Œä¸ºå®é™…åº”ç”¨ç³»ç»Ÿä¸­çš„è¯­éŸ³äº¤äº’æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12831v1",
      "published_date": "2025-09-16 08:55:40 UTC",
      "updated_date": "2025-09-16 08:55:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:39.660969+00:00"
    },
    {
      "arxiv_id": "2509.13380v2",
      "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy",
      "title_zh": "ASTREAï¼šé¢å‘è½¨é“çƒ­æ§è‡ªä¸»çš„æ™ºèƒ½ä½“æ™ºèƒ½",
      "authors": [
        "Alejandro D. Mousist"
      ],
      "abstract": "This paper presents ASTREA, the first agentic system executed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations, with on-orbit operation aboard the International Space Station (ISS). Using thermal control as a representative use case, we integrate a resource-constrained Large Language Model (LLM) agent with a reinforcement learning controller in an asynchronous architecture tailored for space-qualified platforms. Ground experiments show that LLM-guided supervision improves thermal stability and reduces violations, confirming the feasibility of combining semantic reasoning with adaptive control under hardware constraints. On-orbit validation aboard the ISS initially faced challenges due to inference latency misaligned with the rapid thermal cycles of Low Earth Orbit (LEO) satellites. Synchronization with the orbit length successfully surpassed the baseline with reduced violations, extended episode durations, and improved CPU utilization. These findings demonstrate the potential for scalable agentic supervision architectures in future autonomous spacecraft.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ASTREAï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨å…·æœ‰é£è¡Œä¼ æ‰¿ç¡¬ä»¶(TRL 9)ä¸Šè¿è¡Œçš„ç”¨äºè‡ªä¸»èˆªå¤©å™¨æ“ä½œçš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¹¶åœ¨å›½é™…ç©ºé—´ç«™(ISS)è¿›è¡Œäº†åœ¨è½¨è¿è¡ŒéªŒè¯ã€‚ASTREAä»¥çƒ­æ§åˆ¶ä¸ºå…¸å‹åº”ç”¨åœºæ™¯ï¼Œå°†èµ„æºå—é™çš„Large Language Model (LLM)æ™ºèƒ½ä½“ä¸Reinforcement Learningæ§åˆ¶å™¨é›†æˆåœ¨ä¸“ä¸ºèˆªå¤©å¹³å°è®¾è®¡çš„å¼‚æ­¥æ¶æ„ä¸­ã€‚åœ°é¢å®éªŒè¯æ˜ï¼ŒLLMå¼•å¯¼çš„ç›‘ç£èƒ½å¤Ÿæ˜¾è‘—æé«˜çƒ­ç¨³å®šæ€§å¹¶å‡å°‘è¿è§„æƒ…å†µï¼Œè¯å®äº†åœ¨ç¡¬ä»¶çº¦æŸä¸‹å°†è¯­ä¹‰æ¨ç†ä¸è‡ªé€‚åº”æ§åˆ¶ç»“åˆçš„å¯è¡Œæ€§ã€‚åœ¨å›½é™…ç©ºé—´ç«™çš„åœ¨è½¨éªŒè¯ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡å°†æ¨ç†è¿‡ç¨‹ä¸è½¨é“é•¿åº¦åŒæ­¥ï¼ŒæˆåŠŸå…‹æœäº†æœ€åˆå› æ¨ç†å»¶è¿Ÿä¸Low Earth Orbit (LEO)å¿«é€Ÿçƒ­å¾ªç¯ä¸åŒ¹é…å¸¦æ¥çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒASTREAåœ¨å‡å°‘è¿è§„ã€å»¶é•¿ä»»åŠ¡å‘¨æœŸå’Œä¼˜åŒ–CPUåˆ©ç”¨ç‡æ–¹é¢å‡ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†åœ¨æœªæ¥è‡ªä¸»èˆªå¤©å™¨ä¸­åº”ç”¨å¯æ‰©å±•æ™ºèƒ½ä½“ç›‘ç£æ¶æ„çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for presentation at the European Space Agency's AI Start 2025 Conference (see https://atpi.eventsair.com/ai-star-2025/)",
      "pdf_url": "https://arxiv.org/pdf/2509.13380v2",
      "published_date": "2025-09-16 08:52:13 UTC",
      "updated_date": "2025-10-11 23:26:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:45.851543+00:00"
    },
    {
      "arxiv_id": "2509.19340v1",
      "title": "Joint Channel Estimation and Computation Offloading in Fluid Antenna-assisted MEC Networks",
      "title_zh": "æµä½“å¤©çº¿è¾…åŠ©MECç½‘ç»œä¸­çš„è”åˆä¿¡é“ä¼°è®¡ä¸è®¡ç®—å¸è½½",
      "authors": [
        "Ying Ju",
        "Mingdong Li",
        "Haoyu Wang",
        "Lei Liu",
        "Youyang Qu",
        "Mianxiong Dong",
        "Victor C. M. Leung",
        "Chau Yuen"
      ],
      "abstract": "With the emergence of fluid antenna (FA) in wireless communications, the capability to dynamically adjust port positions offers substantial benefits in spatial diversity and spectrum efficiency, which are particularly valuable for mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC offloading framework to minimize system delay. This framework faces two severe challenges, which are the complexity of channel estimation due to dynamic port configuration and the inherent non-convexity of the joint optimization problem. Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed Sensing (IBM-CCS), which advances FA channel estimation by integrating information relevance into the sensing process and capturing key features of FA channels effectively. Secondly, to address the non-convex and high-dimensional optimization problem in FA-assisted MEC systems, which includes FA port selection, beamforming, power control, and resource allocation, we propose a game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA) based offloading scheme, where the hierarchical structure effectively decouples and coordinates the optimization tasks between the user side and the base station side. Crucially, the game theory effectively reduces the dimensionality of power control variables, allowing deep reinforcement learning (DRL) agents to achieve improved optimization efficiency. Numerical results confirm that the proposed scheme significantly reduces system delay and enhances offloading performance, outperforming benchmarks. Additionally, the IBM-CCS channel estimation demonstrates superior accuracy and robustness under varying port densities, contributing to efficient communication under imperfect CSI.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æµåŠ¨å¤©çº¿(Fluid Antenna, FA)è¾…åŠ©çš„ç§»åŠ¨è¾¹ç¼˜è®¡ç®—(Mobile Edge Computing, MEC)ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³åŠ¨æ€ç«¯å£é…ç½®å¸¦æ¥çš„ä¿¡é“ä¼°è®¡å¤æ‚æ€§ä»¥åŠè”åˆä¼˜åŒ–é—®é¢˜çš„éå‡¸æ€§ï¼Œä»¥æœ€å°åŒ–ç³»ç»Ÿå»¶è¿Ÿã€‚ç ”ç©¶é¦–å…ˆæå‡ºäº†ä¿¡æ¯ç“¶é¢ˆåº¦é‡å¢å¼ºçš„ä¿¡é“å‹ç¼©æ„ŸçŸ¥(Information Bottleneck Metric-enhanced Channel Compressed Sensing, IBM-CCS)æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆä¿¡æ¯ç›¸å…³æ€§æœ‰æ•ˆæ•æ‰FAä¿¡é“çš„å…³é”®ç‰¹å¾ã€‚é’ˆå¯¹åŒ…å«ç«¯å£é€‰æ‹©ã€æ³¢æŸèµ‹å½¢ã€åŠŸç‡æ§åˆ¶å’Œèµ„æºåˆ†é…çš„å¤æ‚ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åšå¼ˆè®ºè¾…åŠ©çš„å±‚çº§åŒå¯¹å¶å¤šæ™ºèƒ½ä½“ç®—æ³•(Hierarchical Twin-Dueling Multi-agent Algorithm, HiTDMA)ï¼Œé€šè¿‡å±‚çº§ç»“æ„å®ç°ç”¨æˆ·ç«¯ä¸åŸºç«™ç«¯ä»»åŠ¡çš„è§£è€¦ä¸åä½œã€‚åšå¼ˆè®ºçš„åº”ç”¨æœ‰æ•ˆé™ä½äº†åŠŸç‡æ§åˆ¶å˜é‡çš„ç»´åº¦ï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)æ™ºèƒ½ä½“çš„ä¼˜åŒ–æ•ˆç‡ã€‚æ•°å€¼ç»“æœè¯å®ï¼Œè¯¥æ–¹æ¡ˆåœ¨é™ä½ç³»ç»Ÿå»¶è¿Ÿå’Œå¢å¼ºå¸è½½æ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰åŸºå‡†ã€‚æ­¤å¤–ï¼ŒIBM-CCSåœ¨ä¸å®Œç¾ä¿¡é“çŠ¶æ€ä¿¡æ¯(CSI)ç¯å¢ƒä¸‹è¡¨ç°å‡ºæé«˜çš„å‡†ç¡®æ€§ä¸ç¨³å¥æ€§ï¼Œä¸ºFAè¾…åŠ©çš„MECç½‘ç»œæä¾›äº†é«˜æ•ˆçš„é€šä¿¡ä¸è®¡ç®—ä¿éšœã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.19340v1",
      "published_date": "2025-09-16 08:48:44 UTC",
      "updated_date": "2025-09-16 08:48:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:48.461087+00:00"
    },
    {
      "arxiv_id": "2509.12822v2",
      "title": "A Pressure-Based Diffusion Model for Influence Maximization on Social Networks",
      "title_zh": "é¢å‘ç¤¾äº¤ç½‘ç»œå½±å“åŠ›æœ€å¤§åŒ–çš„åŸºäºå‹åŠ›çš„æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Curt Stutsman",
        "Eliot W. Robson",
        "Abhishek K. Umrawal"
      ],
      "abstract": "In many real-world scenarios, an individual's local social network carries significant influence over the opinions they form and subsequently propagate. In this paper, we propose a novel diffusion model -- the Pressure Threshold model (PT) -- for dynamically simulating the spread of influence through a social network. This model extends the popular Linear Threshold (LT) model by adjusting a node's outgoing influence in proportion to the influence it receives from its activated neighbors. We examine the Influence Maximization (IM) problem under this framework, which involves selecting seed nodes that yield maximal graph coverage after a diffusion process, and describe how the problem manifests under the PT model. Experiments on real-world networks, supported by enhancements to the open-source network-diffusion library CyNetDiff, reveal that the PT model identifies seed sets distinct from those chosen by LT. Furthermore, the analyses show that densely connected networks amplify pressure effects far more strongly than sparse networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Pressure Threshold model (PT) çš„æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨åŠ¨æ€æ¨¡æ‹Ÿç¤¾äº¤ç½‘ç»œä¸­çš„å½±å“åŠ›ä¼ æ’­ã€‚è¯¥æ¨¡å‹æ˜¯å¯¹ç»å…¸ Linear Threshold (LT) æ¨¡å‹çš„æ‰©å±•ï¼Œå…¶æ ¸å¿ƒæœºåˆ¶æ˜¯æ ¹æ®èŠ‚ç‚¹ä»å·²æ¿€æ´»é‚»å±…å¤„æ¥æ”¶åˆ°çš„å‹åŠ›ï¼ŒæŒ‰æ¯”ä¾‹è°ƒæ•´å…¶å‘å¤–ä¼ æ’­çš„å½±å“åŠ›ã€‚ç ”ç©¶äººå‘˜åœ¨æ­¤æ¡†æ¶ä¸‹æ¢è®¨äº†å½±å“åŠ›æœ€å¤§åŒ– (Influence Maximization, IM) é—®é¢˜ï¼Œæ—¨åœ¨é€šè¿‡é€‰æ‹©æœ€ä¼˜ç§å­èŠ‚ç‚¹å®ç°æœ€å¤§åŒ–çš„å›¾è¦†ç›–ã€‚é€šè¿‡åœ¨çœŸå®ç½‘ç»œä¸Šè¿›è¡Œå®éªŒå¹¶å¢å¼ºå¼€æºç½‘ç»œæ‰©æ•£åº“ CyNetDiff çš„åŠŸèƒ½ï¼Œç ”ç©¶å‘ç° PT æ¨¡å‹è¯†åˆ«å‡ºçš„ç§å­é›†ä¸ LT æ¨¡å‹æ˜¾è‘—ä¸åŒã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œå¯†é›†è¿æ¥çš„ç½‘ç»œæ¯”ç¨€ç–ç½‘ç»œæ›´èƒ½æ˜¾è‘—æ”¾å¤§è¿™ç§å‹åŠ›æ•ˆåº”ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£å¤æ‚ç¤¾äº¤ç½‘ç»œä¸­çš„åŠ¨æ€å½±å“åŠ›å’Œç§å­èŠ‚ç‚¹é€‰æ‹©æä¾›äº†æ–°çš„è§†è§’å’Œå·¥å…·ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "12 pages, 8 figures, and 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.12822v2",
      "published_date": "2025-09-16 08:47:00 UTC",
      "updated_date": "2026-01-16 12:05:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:58:48.666008+00:00"
    },
    {
      "arxiv_id": "2509.12818v1",
      "title": "Data Scaling Laws for Radiology Foundation Models",
      "title_zh": "æ”¾å°„å­¦åŸºç¡€æ¨¡å‹çš„æ•°æ®è§„æ¨¡å®šå¾‹",
      "authors": [
        "Maximilian Ilse",
        "Harshita Sharma",
        "Anton Schwaighofer",
        "Sam Bond-Taylor",
        "Fernando PÃ©rez-GarcÃ­a",
        "Olesya Melnichenko",
        "Anne-Marie G. Sykes",
        "Kelly K. Horst",
        "Ashish Khandelwal",
        "Maxwell Reynolds",
        "Maria T. Wetscherek",
        "Noel C. F. Codella",
        "Javier Alvarez-Valle",
        "Korfiatis Panagiotis",
        "Valentina Salvatelli"
      ],
      "abstract": "Foundation vision encoders such as CLIP and DINOv2, trained on web-scale data, exhibit strong transfer performance across tasks and datasets. However, medical imaging foundation models remain constrained by smaller datasets, limiting our understanding of how data scale and pretraining paradigms affect performance in this setting. In this work, we systematically study continual pretraining of two vision encoders, MedImageInsight (MI2) and RAD-DINO representing the two major encoder paradigms CLIP and DINOv2, on up to 3.5M chest x-rays from a single institution, holding compute and evaluation protocols constant. We evaluate on classification (radiology findings, lines and tubes), segmentation (lines and tubes), and radiology report generation. While prior work has primarily focused on tasks related to radiology findings, we include lines and tubes tasks to counterbalance this bias and evaluate a model's ability to extract features that preserve continuity along elongated structures. Our experiments show that MI2 scales more effectively for finding-related tasks, while RAD-DINO is stronger on tube-related tasks. Surprisingly, continually pretraining MI2 with both reports and structured labels using UniCL improves performance, underscoring the value of structured supervision at scale. We further show that for some tasks, as few as 30k in-domain samples are sufficient to surpass open-weights foundation models. These results highlight the utility of center-specific continual pretraining, enabling medical institutions to derive significant performance gains by utilizing in-domain data.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº†æ”¾å°„å­¦åŸºç¡€æ¨¡å‹çš„æ•°æ®ç¼©æ”¾å®šå¾‹(Data Scaling Laws)ï¼Œé€šè¿‡åœ¨å¤šè¾¾350ä¸‡å¼ èƒ¸éƒ¨Xå…‰ç‰‡ä¸Šè¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼Œæ·±å…¥ç ”ç©¶äº†æ•°æ®è§„æ¨¡å’Œé¢„è®­ç»ƒèŒƒå¼å¯¹æ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶å¯¹æ¯”äº†ä»£è¡¨CLIPèŒƒå¼çš„MedImageInsight (MI2)å’Œä»£è¡¨DINOv2èŒƒå¼çš„RAD-DINOï¼Œå¹¶åœ¨åˆ†ç±»ã€åˆ†å‰²åŠæ”¾å°„æŠ¥å‘Šç”Ÿæˆç­‰å¤šé¡¹ä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒå‘ç°ï¼ŒMI2åœ¨æ”¾å°„å­¦å‘ç°(radiology findings)ä»»åŠ¡ä¸­ç¼©æ”¾æ•ˆæœæ›´æœ‰æ•ˆï¼Œè€ŒRAD-DINOåœ¨ç®¡è·¯(tubes)ç›¸å…³ä»»åŠ¡ä¸­è¡¨ç°æ›´å¼ºã€‚æ­¤å¤–ï¼Œä½¿ç”¨UniCLç»“åˆæŠ¥å‘Šå’Œç»“æ„åŒ–æ ‡ç­¾è¿›è¡Œé¢„è®­ç»ƒæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå‡¸æ˜¾äº†å¤§è§„æ¨¡ç»“æ„åŒ–ç›‘ç£çš„ä»·å€¼ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œä»…éœ€3ä¸‡ä¸ªé¢†åŸŸå†…æ ·æœ¬å³å¯è¶…è¶Šç°æœ‰çš„å¼€æºåŸºç¡€æ¨¡å‹ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†ç‰¹å®šä¸­å¿ƒ(center-specific)æŒç»­é¢„è®­ç»ƒçš„å®ç”¨æ€§ï¼Œä¸ºåŒ»ç–—æœºæ„åˆ©ç”¨è‡ªæœ‰æ•°æ®æå‡æ¨¡å‹æ€§èƒ½æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12818v1",
      "published_date": "2025-09-16 08:36:06 UTC",
      "updated_date": "2025-09-16 08:36:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:02.473473+00:00"
    },
    {
      "arxiv_id": "2509.12816v1",
      "title": "Gesture Evaluation in Virtual Reality",
      "title_zh": "è™šæ‹Ÿç°å®ä¸­çš„æ‰‹åŠ¿è¯„ä¼°",
      "authors": [
        "Axel Wiebe Werner",
        "Jonas Beskow",
        "Anna Deichler"
      ],
      "abstract": "Gestures are central to human communication, enriching interactions through non-verbal expression. Virtual avatars increasingly use AI-generated gestures to enhance life-likeness, yet evaluations have largely been confined to 2D. Virtual Reality (VR) provides an immersive alternative that may affect how gestures are perceived. This paper presents a comparative evaluation of computer-generated gestures in VR and 2D, examining three models from the 2023 GENEA Challenge. Results show that gestures viewed in VR were rated slightly higher on average, with the strongest effect observed for motion-capture \"true movement.\" While model rankings remained consistent across settings, VR influenced participants' overall perception and offered unique benefits over traditional 2D evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨Virtual Reality (VR)ç¯å¢ƒä¸‹è¯„ä¼°AIç”Ÿæˆæ‰‹åŠ¿çš„æ•ˆæœï¼Œå¹¶å°†å…¶ä¸ä¼ ç»Ÿçš„2Dè¯„ä¼°æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ã€‚ç ”ç©¶è€…é‡‡ç”¨äº†2023å¹´GENEA Challengeä¸­çš„ä¸‰ä¸ªæ¨¡å‹ï¼Œåœ¨æ²‰æµ¸å¼VRå’Œ2Dæ˜¾ç¤ºå™¨ä¸­å¯¹ç”Ÿæˆçš„è™šæ‹Ÿå¤´åƒæ‰‹åŠ¿è¿›è¡Œäº†æ¯”è¾ƒè¯„ä»·ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨VRä¸­è§‚å¯Ÿåˆ°çš„æ‰‹åŠ¿å¹³å‡å¾—åˆ†ç•¥é«˜äº2Dç¯å¢ƒï¼Œå…¶ä¸­å¯¹åŠ¨ä½œæ•æ‰(motion-capture)ç”Ÿæˆçš„â€œçœŸå®è¿åŠ¨â€(true movement)å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚å°½ç®¡å„æ¨¡å‹åœ¨ä¸¤ç§ç¯å¢ƒä¸‹çš„æ’åä¿æŒä¸€è‡´ï¼Œä½†VRæ˜¾è‘—å½±å“äº†å‚ä¸è€…çš„æ•´ä½“æ„ŸçŸ¥ï¼Œå¹¶å±•ç°å‡ºè¶…è¶Šä¼ ç»Ÿ2Dè¯„ä¼°çš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚è¯¥é¡¹å·¥ä½œä¸ºç†è§£æ²‰æµ¸å¼ç¯å¢ƒå¯¹æ‰‹åŠ¿æ„ŸçŸ¥çš„å½±å“æä¾›äº†å®è¯æ•°æ®ï¼Œè¯æ˜äº†VRä½œä¸ºæ›´å…·ç”Ÿå‘½åŠ›çš„è¯„ä¼°å¹³å°åœ¨å¢å¼ºè™šæ‹Ÿäº¤äº’ä½“éªŒæ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Published in Proceedings of the 26th International Conference on Multimodal Interaction (ICMI '24), ACM. Copyright 2024 ACM. Licensed under CC BY",
      "pdf_url": "https://arxiv.org/pdf/2509.12816v1",
      "published_date": "2025-09-16 08:35:37 UTC",
      "updated_date": "2025-09-16 08:35:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:03.571210+00:00"
    },
    {
      "arxiv_id": "2509.12810v1",
      "title": "H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents",
      "title_zh": "H$^2$Rï¼šé¢å‘å¤šä»»åŠ¡å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„åˆ†å±‚åéªŒåæ€",
      "authors": [
        "Shicheng Ye",
        "Chao Yu",
        "Kaiqiang Ke",
        "Chengdong Xu",
        "Yinqi Wei"
      ],
      "abstract": "Large language model (LLM)-based agents have shown strong potential in multi-task scenarios, owing to their ability to transfer knowledge across diverse tasks. However, existing approaches often treat prior experiences and knowledge as monolithic units, leading to inefficient and coarse-grained knowledge transfer. In this work, we propose a novel hierarchical memory architecture that enables fine-grained knowledge transfer by decoupling high-level planning memory from low-level execution memory. To construct and refine these hierarchical memories, we introduce Hierarchical Hindsight Reflection (H$^2$R), a mechanism that distills reusable and hierarchical knowledge from past agent-environment interactions. At test time, H$^2$R performs retrievals of high-level and low-level memories separately, allowing LLM-based agents to efficiently access and utilize task-relevant knowledge for new tasks.Experimental results across two benchmarks demonstrate that H$^2$R can improve generalization and decision-making performance, outperforming prior baselines such as Expel.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ™ºèƒ½ä½“åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸­çŸ¥è¯†è¿ç§»æ•ˆç‡ä½ä¸‹ä¸”ç²’åº¦ç²—ç³™çš„é—®é¢˜ï¼Œæå‡ºäº† H$^2$R (Hierarchical Hindsight Reflection) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†é«˜å±‚è§„åˆ’è®°å¿† (high-level planning memory) ä¸ä½å±‚æ‰§è¡Œè®°å¿† (low-level execution memory) è§£è€¦ï¼Œæ„å»ºäº†ä¸€ç§æ–°å‹çš„å±‚æ¬¡åŒ–å­˜å‚¨æ¶æ„ï¼Œå®ç°äº†ç»†ç²’åº¦çš„çŸ¥è¯†è¿ç§»ã€‚H$^2$R å¼•å…¥äº†å±‚æ¬¡åŒ–äº‹ååæ€æœºåˆ¶ï¼Œèƒ½å¤Ÿä»æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„è¿‡å¾€äº¤äº’ä¸­æç‚¼å‡ºå¯å¤ç”¨çš„å±‚æ¬¡åŒ–çŸ¥è¯†ã€‚åœ¨æµ‹è¯•é˜¶æ®µï¼Œè¯¥ç³»ç»Ÿé€šè¿‡åˆ†åˆ«æ£€ç´¢é«˜å±‚å’Œä½å±‚è®°å¿†ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé«˜æ•ˆåœ°åˆ©ç”¨ä»»åŠ¡ç›¸å…³çŸ¥è¯†æ¥åº”å¯¹æ–°ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒH$^2$R åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“çš„æ³›åŒ–èƒ½åŠ›å’Œå†³ç­–æ€§èƒ½ï¼Œå…¶è¡¨ç°ä¼˜äº Expel ç­‰ç°æœ‰åŸºå‡†æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12810v1",
      "published_date": "2025-09-16 08:30:08 UTC",
      "updated_date": "2025-09-16 08:30:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:07.564428+00:00"
    },
    {
      "arxiv_id": "2509.21342v1",
      "title": "SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph",
      "title_zh": "SGNNBenchï¼šé¢å‘å¤§è§„æ¨¡å›¾çš„è„‰å†²å›¾ç¥ç»ç½‘ç»œç»¼åˆè¯„ä¼°",
      "authors": [
        "Huizhe Zhang",
        "Jintang Li",
        "Yuchang Zhu",
        "Liang Chen",
        "Li Kuang"
      ],
      "abstract": "Graph Neural Networks (GNNs) are exemplary deep models designed for graph data. Message passing mechanism enables GNNs to effectively capture graph topology and push the performance boundaries across various graph tasks. However, the trend of developing such complex machinery for graph representation learning has become unsustainable on large-scale graphs. The computational and time overhead make it imperative to develop more energy-efficient GNNs to cope with the explosive growth of real-world graphs. Spiking Graph Neural Networks (SGNNs), which integrate biologically plausible learning via unique spike-based neurons, have emerged as a promising energy-efficient alternative. Different layers communicate with sparse and binary spikes, which facilitates computation and storage of intermediate graph representations. Despite the proliferation of SGNNs proposed in recent years, there is no systematic benchmark to explore the basic design principles of these brain-inspired networks on the graph data. To bridge this gap, we present SGNNBench to quantify progress in the field of SGNNs. Specifically, SGNNBench conducts an in-depth investigation of SGNNs from multiple perspectives, including effectiveness, energy efficiency, and architectural design. We comprehensively evaluate 9 state-of-the-art SGNNs across 18 datasets. Regarding efficiency, we empirically compare these baselines w.r.t model size, memory usage, and theoretical energy consumption to reveal the often-overlooked energy bottlenecks of SGNNs. Besides, we elaborately investigate the design space of SGNNs to promote the development of a general SGNN paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è§„æ¨¡å›¾æ•°æ®å¤„ç†ä¸­å›¾ç¥ç»ç½‘ç»œ(GNNs)é¢ä¸´çš„é«˜æ˜‚è®¡ç®—å¼€é”€ï¼Œæ¢è®¨äº†è„‰å†²å›¾ç¥ç»ç½‘ç»œ(Spiking Graph Neural Networks, SGNNs)ä½œä¸ºä¸€ç§ç”Ÿç‰©å¯å‘å¼ä½åŠŸè€—æ›¿ä»£æ–¹æ¡ˆçš„æ½œåŠ›ã€‚ç”±äºç›®å‰ç¼ºä¹å¯¹SGNNsè®¾è®¡åŸåˆ™çš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œç ”ç©¶è€…æå‡ºäº†SGNNBenchåŸºå‡†æ¡†æ¶ï¼Œæ—¨åœ¨ä»æœ‰æ•ˆæ€§ã€èƒ½æºæ•ˆç‡å’Œæ¶æ„è®¾è®¡ç­‰å¤šä¸ªç»´åº¦é‡åŒ–è¯¥é¢†åŸŸçš„è¿›å±•ã€‚é€šè¿‡åœ¨18ä¸ªæ•°æ®é›†ä¸Šå¯¹9ç§å‰æ²¿SGNNsè¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œè¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†æ¨¡å‹è§„æ¨¡ã€å†…å­˜å ç”¨åŠç†è®ºèƒ½è€—ï¼Œæ­ç¤ºäº†ä»¥å¾€è¢«å¿½è§†çš„èƒ½é‡ç“¶é¢ˆã€‚æ­¤å¤–ï¼ŒSGNNBenchè¿˜è¯¦ç»†è°ƒæŸ¥äº†SGNNsçš„è®¾è®¡ç©ºé—´ï¼Œä¸ºæ„å»ºé€šç”¨çš„SGNNsèŒƒå¼æä¾›äº†ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "The code is available at https://github.com/Zhhuizhe/SGNNBench",
      "pdf_url": "https://arxiv.org/pdf/2509.21342v1",
      "published_date": "2025-09-16 08:22:01 UTC",
      "updated_date": "2025-09-16 08:22:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:15.686545+00:00"
    },
    {
      "arxiv_id": "2509.12798v1",
      "title": "LLM-Based Approach for Enhancing Maintainability of Automotive Architectures",
      "title_zh": "åŸºäº LLM çš„æ±½è½¦æ¶æ„å¯ç»´æŠ¤æ€§æå‡æ–¹æ³•",
      "authors": [
        "Nenad Petrovic",
        "Lukasz Mazur",
        "Alois Knoll"
      ],
      "abstract": "There are many bottlenecks that decrease the flexibility of automotive systems, making their long-term maintenance, as well as updates and extensions in later lifecycle phases increasingly difficult, mainly due to long re-engineering, standardization, and compliance procedures, as well as heterogeneity and numerosity of devices and underlying software components involved. In this paper, we explore the potential of Large Language Models (LLMs) when it comes to the automation of tasks and processes that aim to increase the flexibility of automotive systems. Three case studies towards achieving this goal are considered as outcomes of early-stage research: 1) updates, hardware abstraction, and compliance, 2) interface compatibility checking, and 3) architecture modification suggestions. For proof-of-concept implementation, we rely on OpenAI's GPT-4o model.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) æé«˜æ±½è½¦æ¶æ„å¯ç»´æŠ¤æ€§å’Œçµæ´»æ€§çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ±½è½¦ç³»ç»Ÿåœ¨é•¿æœŸç»´æŠ¤ã€æ›´æ–°å’Œæ‰©å±•è¿‡ç¨‹ä¸­é¢ä¸´çš„é‡æ„å‘¨æœŸé•¿ã€æ ‡å‡†åŒ–å’Œåˆè§„ç¨‹åºå¤æ‚ä»¥åŠè®¾å¤‡ä¸è½¯ä»¶ç»„ä»¶å¼‚æ„æ€§å¼ºç­‰ç“¶é¢ˆé—®é¢˜ã€‚è®ºæ–‡é‡ç‚¹ç ”ç©¶äº† LLMs åœ¨è‡ªåŠ¨åŒ–ç›¸å…³ä»»åŠ¡å’Œæµç¨‹ä¸­çš„æ½œåŠ›ï¼Œå¹¶æå‡ºäº†ä¸‰é¡¹å¤„äºåˆæ­¥ç ”ç©¶é˜¶æ®µçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå…·ä½“æ¶µç›–äº†ç³»ç»Ÿæ›´æ–°ã€ç¡¬ä»¶æŠ½è±¡ä¸åˆè§„æ€§ (updates, hardware abstraction, and compliance)ã€æ¥å£å…¼å®¹æ€§æ£€æŸ¥ (interface compatibility checking) ä»¥åŠæ¶æ„ä¿®æ”¹å»ºè®® (architecture modification suggestions)ã€‚è¯¥ç ”ç©¶é€šè¿‡ OpenAI çš„ GPT-4o æ¨¡å‹è¿›è¡Œäº†æ¦‚å¿µéªŒè¯ (proof-of-concept) å®ç°ã€‚åˆæ­¥æ¢ç´¢è¡¨æ˜ï¼Œå¼•å…¥å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæå‡æ±½è½¦ç³»ç»Ÿçš„çµæ´»æ€§ï¼Œä¸ºç®€åŒ–å¤æ‚çš„æ±½è½¦å·¥ç¨‹ä¸ç»´æŠ¤æµç¨‹æä¾›äº†æ–°çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12798v1",
      "published_date": "2025-09-16 08:17:41 UTC",
      "updated_date": "2025-09-16 08:17:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:13.993665+00:00"
    },
    {
      "arxiv_id": "2509.13379v2",
      "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs",
      "title_zh": "è¯´â€œä¹Ÿè®¸â€çš„è‰ºæœ¯ï¼šVLMs ä¸ç¡®å®šæ€§åŸºå‡†æµ‹è¯•çš„ç¬¦åˆæ€§è§†è§’",
      "authors": [
        "Asif Azad",
        "Mohammad Sadat Hossain",
        "MD Sadik Hossain Shanto",
        "M Saifur Rahman",
        "Md Rizwan Parvez"
      ],
      "abstract": "Vision-Language Models (VLMs) have achieved remarkable progress in complex visual understanding across scientific and reasoning tasks. While performance benchmarking has advanced our understanding of these capabilities, the critical dimension of uncertainty quantification has received insufficient attention. Therefore, unlike prior conformal prediction studies that focused on limited settings, we conduct a comprehensive uncertainty benchmarking study, evaluating 16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets with 3 distinct scoring functions. Our findings demonstrate that larger models consistently exhibit better uncertainty quantification; models that know more also know better what they don't know. More certain models achieve higher accuracy, while mathematical and reasoning tasks elicit poorer uncertainty performance across all models compared to other domains. This work establishes a foundation for reliable uncertainty evaluation in multimodal systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ç¬¦åˆé¢„æµ‹(Conformal Prediction)çš„è§†è§’ï¼Œå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)çš„ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)è¿›è¡Œäº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ç ”ç©¶ã€‚å®éªŒè¯„ä¼°äº†16ä¸ªå…ˆè¿›çš„å¼€æºå’Œé—­æºVLMsï¼Œæ¶µç›–äº†6ä¸ªå¤šæ¨¡æ€æ•°æ®é›†å’Œ3ç§ä¸åŒçš„è¯„åˆ†å‡½æ•°ï¼Œæ—¨åœ¨å¡«è¡¥è¯¥é¢†åŸŸåœ¨å¯é æ€§è¡¡é‡æ–¹é¢çš„ç ”ç©¶ç©ºç™½ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡ä¸ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›æ˜¾è‘—ç›¸å…³ï¼Œå³è§„æ¨¡è¶Šå¤§çš„æ¨¡å‹è¶Šèƒ½æ¸…æ™°åœ°è¯†åˆ«è‡ªèº«çŸ¥è¯†çš„å±€é™æ€§ã€‚åŒæ—¶ï¼Œæ¨¡å‹åœ¨ä»»åŠ¡ä¸­çš„ç¡®å®šæ€§ç¨‹åº¦ä¸å…¶å‡†ç¡®ç‡å‘ˆæ­£ç›¸å…³ï¼Œè¡¨ç°å‡ºâ€œçŸ¥ä¹‹ä¸ºçŸ¥ä¹‹â€çš„ç‰¹æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ•°å­¦å’Œæ¨ç†ä»»åŠ¡åœ¨æ‰€æœ‰æ¨¡å‹ä¸­å¼•å‘çš„ä¸ç¡®å®šæ€§è¡¨ç°å‡æ™®éå¼±äºå…¶ä»–é¢†åŸŸã€‚è¿™é¡¹å·¥ä½œä¸ºæ„å»ºå¯é ä¸”å…·æœ‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„å¤šæ¨¡æ€ç³»ç»Ÿå¥ å®šäº†é‡è¦çš„è¯„ä»·åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13379v2",
      "published_date": "2025-09-16 08:17:39 UTC",
      "updated_date": "2025-09-18 10:10:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:19.562226+00:00"
    },
    {
      "arxiv_id": "2510.21719v1",
      "title": "GAMER PAT: Research as a Serious Game",
      "title_zh": "GAMER PATï¼šå°†ç ”ç©¶è§†ä½œä¸¥è‚ƒæ¸¸æˆ",
      "authors": [
        "Kenji Saito",
        "Rei Tadika"
      ],
      "abstract": "As generative AI increasingly outperforms students in producing academic writing, a critical question arises: how can we preserve the motivation, creativity, and intellectual growth of novice researchers in an age of automated academic achievement? This paper introduces GAMER PAT (GAme MastER, Paper Authoring Tutor), a prompt-engineered AI chatbot that reframes research paper writing as a serious game. Through role-playing mechanics, users interact with a co-author NPC and anonymous reviewer NPCs, turning feedback into \"missions\" and advancing through a narrative-driven writing process.\n  Our study reports on 26+ gameplay chat logs, including both autoethnography and use by graduate students under supervision. Using qualitative log analysis with SCAT (Steps for Coding and Theorization), we identified an emergent four-phase scaffolding pattern: (1) question posing, (2) meta-perspective, (3) structuring, and (4) recursive reflection. These results suggest that GAMER PAT supports not only the structural development of research writing but also reflective and motivational aspects.\n  We present this work as a descriptive account of concept and process, not a causal evaluation. We also include a speculative outlook envisioning how humans may continue to cultivate curiosity and agency alongside AI-driven research. This arXiv version thus provides both a descriptive report of design and usage, and a forward-looking provocation for future empirical studies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) å†²å‡»ä¸‹å¦‚ä½•ä¿æŒåˆçº§ç ”ç©¶è€…ç§‘ç ”åŠ¨åŠ›ä¸åˆ›é€ åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº† GAMER PAT (GAme MastER, Paper Authoring Tutor)ã€‚è¿™æ˜¯ä¸€ä¸ªç»è¿‡æç¤ºå·¥ç¨‹ (Prompt-engineered) å¤„ç†çš„ AI èŠå¤©æœºå™¨äººï¼Œå®ƒå°†ç ”ç©¶è®ºæ–‡å†™ä½œé‡æ–°å®šä¹‰ä¸ºä¸€åœºâ€œä¸¥è‚ƒæ¸¸æˆâ€ (Serious Game)ã€‚ç³»ç»Ÿé€šè¿‡è§’è‰²æ‰®æ¼” (Role-playing) æœºåˆ¶ï¼Œè®©ç”¨æˆ·ä¸åˆè‘—è€… NPC å’ŒåŒ¿åè¯„å®¡å‘˜ NPC äº’åŠ¨ï¼Œå°†åé¦ˆè½¬åŒ–ä¸ºâ€œä»»åŠ¡â€ (Missions)ï¼Œå¹¶ä»¥å™äº‹é©±åŠ¨çš„æ–¹å¼æ¨è¿›å†™ä½œè¿›ç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ SCAT (Steps for Coding and Theorization) æ–¹æ³•å¯¹ 26 ä»½ä»¥ä¸Šçš„æ¸¸æˆèŠå¤©æ—¥å¿—è¿›è¡Œäº†å®šæ€§åˆ†æï¼Œè¯†åˆ«å‡ºäº†ä¸€ç§ç”±é—®é¢˜æå‡º (Question posing)ã€å…ƒè§†è§’ (Meta-perspective)ã€ç»“æ„åŒ– (Structuring) å’Œé€’å½’åæ€ (Recursive reflection) ç»„æˆçš„å››é˜¶æ®µæ”¯æ¶æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGAMER PAT ä¸ä»…èƒ½è¾…åŠ©è®ºæ–‡çš„ç»“æ„åŒ–å¼€å‘ï¼Œè¿˜èƒ½æ˜¾è‘—æå‡ç ”ç©¶è€…çš„åæ€èƒ½åŠ›ä¸ç§‘ç ”åŠ¨æœºã€‚è¯¥å·¥ä½œä¸ºæœªæ¥åœ¨ AI é©±åŠ¨çš„ç ”ç©¶ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•åŸ¹å…»äººç±»çš„å¥½å¥‡å¿ƒä¸èƒ½åŠ¨æ€§ (Agency) æä¾›äº†æè¿°æ€§æŠ¥å‘Šä¸å‰ç»æ€§å¯ç¤ºã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.21719v1",
      "published_date": "2025-09-16 07:56:40 UTC",
      "updated_date": "2025-09-16 07:56:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:21.863407+00:00"
    },
    {
      "arxiv_id": "2509.12777v1",
      "title": "CECT-Mamba: a Hierarchical Contrast-enhanced-aware Model for Pancreatic Tumor Subtyping from Multi-phase CECT",
      "title_zh": "CECT-Mambaï¼šä¸€ç§åŸºäºå¤šæœŸå¢å¼º CT çš„å±‚çº§å¯¹æ¯”å¢å¼ºæ„ŸçŸ¥èƒ°è…ºè‚¿ç˜¤åˆ†å‹æ¨¡å‹",
      "authors": [
        "Zhifang Gong",
        "Shuo Gao",
        "Ben Zhao",
        "Yingjing Xu",
        "Yijun Yang",
        "Shenghong Ju",
        "Guangquan Zhou"
      ],
      "abstract": "Contrast-enhanced computed tomography (CECT) is the primary imaging technique that provides valuable spatial-temporal information about lesions, enabling the accurate diagnosis and subclassification of pancreatic tumors. However, the high heterogeneity and variability of pancreatic tumors still pose substantial challenges for precise subtyping diagnosis. Previous methods fail to effectively explore the contextual information across multiple CECT phases commonly used in radiologists' diagnostic workflows, thereby limiting their performance. In this paper, we introduce, for the first time, an automatic way to combine the multi-phase CECT data to discriminate between pancreatic tumor subtypes, among which the key is using Mamba with promising learnability and simplicity to encourage both temporal and spatial modeling from multi-phase CECT. Specifically, we propose a dual hierarchical contrast-enhanced-aware Mamba module incorporating two novel spatial and temporal sampling sequences to explore intra and inter-phase contrast variations of lesions. A similarity-guided refinement module is also imposed into the temporal scanning modeling to emphasize the learning on local tumor regions with more obvious temporal variations. Moreover, we design the space complementary integrator and multi-granularity fusion module to encode and aggregate the semantics across different scales, achieving more efficient learning for subtyping pancreatic tumors. The experimental results on an in-house dataset of 270 clinical cases achieve an accuracy of 97.4% and an AUC of 98.6% in distinguishing between pancreatic ductal adenocarcinoma (PDAC) and pancreatic neuroendocrine tumors (PNETs), demonstrating its potential as a more accurate and efficient tool.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èƒ°è…ºè‚¿ç˜¤åˆ†ç±»ä¸­å­˜åœ¨çš„é«˜åº¦å¼‚è´¨æ€§ä»¥åŠå¤šæœŸç›¸ CECT å›¾åƒä¸Šä¸‹æ–‡ä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œé¦–æ¬¡æå‡ºäº†ä¸€ç§åä¸º CECT-Mamba çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ Mamba æ¨¡å‹çš„æ—¶ç©ºå»ºæ¨¡èƒ½åŠ›æé«˜è¯Šæ–­ç²¾åº¦ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒé‡‡ç”¨äº†åŒå±‚åˆ†çº§å¢å¼ºæ„ŸçŸ¥ Mamba æ¨¡å— (Dual hierarchical contrast-enhanced-aware Mamba module)ï¼Œç»“åˆåˆ›æ–°çš„ç©ºé—´ä¸æ—¶é—´é‡‡æ ·åºåˆ—æ¥æ•è·ç—…ç¶åœ¨æœŸç›¸å†…å’ŒæœŸç›¸é—´çš„å¯¹æ¯”åº¦åŠ¨æ€å˜åŒ–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ç›¸ä¼¼æ€§å¼•å¯¼ç²¾ç»†åŒ–æ¨¡å— (Similarity-guided refinement module) ä»¥å¼ºåŒ–å¯¹å±€éƒ¨ç—…ç¶åŒºåŸŸçš„ç‰¹å¾å­¦ä¹ ï¼Œå¹¶ç»“åˆç©ºé—´äº’è¡¥é›†æˆå™¨ä¸å¤šç²’åº¦èåˆæ¨¡å— (Multi-granularity fusion module) å®ç°è·¨å°ºåº¦çš„è¯­ä¹‰èšåˆã€‚åœ¨åŒ…å« 270 ä¾‹ä¸´åºŠç—…ä¾‹çš„æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹åœ¨åŒºåˆ†èƒ°è…ºå¯¼ç®¡è…ºç™Œ (PDAC) ä¸èƒ°è…ºç¥ç»å†…åˆ†æ³Œè‚¿ç˜¤ (PNETs) ä»»åŠ¡ä¸­è¾¾åˆ°äº† 97.4% çš„å‡†ç¡®ç‡å’Œ 98.6% çš„ AUC è¯„åˆ†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCECT-Mamba èƒ½å¤Ÿæœ‰æ•ˆæ•´åˆå¤šæœŸç›¸å½±åƒç‰¹å¾ï¼Œä¸ºèƒ°è…ºè‚¿ç˜¤çš„ç²¾å‡†åˆ†å‹æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„è¾…åŠ©å·¥å…·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12777v1",
      "published_date": "2025-09-16 07:48:11 UTC",
      "updated_date": "2025-09-16 07:48:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:29.644415+00:00"
    },
    {
      "arxiv_id": "2509.12774v1",
      "title": "EmbeddedML: A New Optimized and Fast Machine Learning Library",
      "title_zh": "EmbeddedMLï¼šä¸€ç§æ–°å‹ä¼˜åŒ–ä¸”é«˜æ•ˆçš„æœºå™¨å­¦ä¹ åº“",
      "authors": [
        "Halil HÃ¼seyin Ã‡alÄ±ÅŸkan",
        "Talha Koruk"
      ],
      "abstract": "Machine learning models and libraries can train datasets of different sizes and perform prediction and classification operations, but machine learning models and libraries cause slow and long training times on large datasets. This article introduces EmbeddedML, a training-time-optimized and mathematically enhanced machine learning library. The speed was increased by approximately times compared to scikit-learn without any loss in terms of accuracy in regression models such as Multiple Linear Regression. Logistic Regression and Support Vector Machines (SVM) algorithms have been mathematically rewritten to reduce training time and increase accuracy in classification models. With the applied mathematical improvements, training time has been reduced by approximately 2 times for SVM on small datasets and by around 800 times on large datasets, and by approximately 4 times for Logistic Regression, compared to the scikit-learn implementation. In summary, the EmbeddedML library offers regression, classification, clustering, and dimensionality reduction algorithms that are mathematically rewritten and optimized to reduce training time.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† EmbeddedMLï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡è®­ç»ƒæ—¶é—´ä¼˜åŒ–å’Œæ•°å­¦å¢å¼ºçš„æ–°å‹æœºå™¨å­¦ä¹ åº“ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒè€—æ—¶è¿‡é•¿çš„é—®é¢˜ã€‚é€šè¿‡å¯¹ Multiple Linear Regressionã€Logistic Regression å’Œ Support Vector Machines (SVM) ç­‰ç®—æ³•è¿›è¡Œæ•°å­¦é‡å†™ï¼Œè¯¥åº“åœ¨æ˜¾è‘—ç¼©çŸ­è®­ç»ƒæ—¶é—´çš„åŒæ—¶æå‡æˆ–ä¿æŒäº†æ¨¡å‹å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ scikit-learn ç›¸æ¯”ï¼ŒEmbeddedML åœ¨å¤„ç†å¤§å‹æ•°æ®é›†æ—¶å°† SVM çš„è®­ç»ƒé€Ÿåº¦æå‡äº†çº¦ 800 å€ï¼Œå¹¶å°† Logistic Regression çš„é€Ÿåº¦æå‡äº†çº¦ 4 å€ã€‚è¯¥åº“æ•´åˆäº†å›å½’ã€åˆ†ç±»ã€èšç±»å’Œé™ç»´ç­‰æ ¸å¿ƒåŠŸèƒ½ï¼Œä¸ºé«˜æ•ˆæœºå™¨å­¦ä¹ æä¾›äº†ä¸€å¥—æ•°å­¦ä¼˜åŒ–ä¸”å¿«é€Ÿçš„ç®—æ³•å®ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12774v1",
      "published_date": "2025-09-16 07:44:37 UTC",
      "updated_date": "2025-09-16 07:44:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:45.471315+00:00"
    },
    {
      "arxiv_id": "2509.12772v1",
      "title": "MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos",
      "title_zh": "MEGANï¼šé¢å‘å†…çª¥é•œè§†é¢‘é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ··åˆä¸“å®¶æ¨¡å‹",
      "authors": [
        "Damola Agbelese",
        "Krishna Chaitanya",
        "Pushpak Pati",
        "Chaitanya Parmar",
        "Pooya Mobadersany",
        "Shreyas Fadnavis",
        "Lindsey Surace",
        "Shadi Yarandi",
        "Louis R. Ghanem",
        "Molly Lucas",
        "Tommaso Mansi",
        "Oana Gabriela Cula",
        "Pablo F. Damasceno",
        "Kristopher Standish"
      ],
      "abstract": "Reliable uncertainty quantification (UQ) is essential in medical AI. Evidential Deep Learning (EDL) offers a computationally efficient way to quantify model uncertainty alongside predictions, unlike traditional methods such as Monte Carlo (MC) Dropout and Deep Ensembles (DE). However, all these methods often rely on a single expert's annotations as ground truth for model training, overlooking the inter-rater variability in healthcare. To address this issue, we propose MEGAN, a Multi-Expert Gating Network that aggregates uncertainty estimates and predictions from multiple AI experts via EDL models trained with diverse ground truths and modeling strategies. MEGAN's gating network optimally combines predictions and uncertainties from each EDL model, enhancing overall prediction confidence and calibration. We extensively benchmark MEGAN on endoscopy videos for Ulcerative colitis (UC) disease severity estimation, assessed by visual labeling of Mayo Endoscopic Subscore (MES), where inter-rater variability is prevalent. In large-scale prospective UC clinical trial, MEGAN achieved a 3.5% improvement in F1-score and a 30.5% reduction in Expected Calibration Error (ECE) compared to existing methods. Furthermore, MEGAN facilitated uncertainty-guided sample stratification, reducing the annotation burden and potentially increasing efficiency and consistency in UC trials.",
      "tldr_zh": "åœ¨åŒ»ç–—äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰çš„è¯æ®æ·±åº¦å­¦ä¹ (Evidential Deep Learning)ç­‰æ–¹æ³•å¾€å¾€ä¾èµ–å•ä¸€ä¸“å®¶çš„æ ‡æ³¨ï¼Œå¿½ç•¥äº†åŒ»ç–—å®è·µä¸­æ™®éå­˜åœ¨çš„è¯„ä»·è€…é—´å·®å¼‚(Inter-rater variability)ã€‚è¯¥ç ”ç©¶æå‡ºäº†MEGANï¼Œä¸€ç§å¤šä¸“å®¶é—¨æ§ç½‘ç»œ(Multi-Expert Gating Network)æ¡†æ¶ï¼Œé€šè¿‡èšåˆå¤šä¸ªåŸºäºä¸åŒåœ°é¢çœŸå€¼(Ground Truth)å’Œå»ºæ¨¡ç­–ç•¥è®­ç»ƒçš„æ¨¡å‹æ¥ä¼˜åŒ–é¢„æµ‹ä¸ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚å®éªŒåœ¨æºƒç–¡æ€§ç»“è‚ ç‚(Ulcerative Colitis)å†…çª¥é•œè§†é¢‘çš„å¤§è§„æ¨¡å‰ç»æ€§ä¸´åºŠè¯•éªŒä¸­è¿›è¡Œï¼Œé’ˆå¯¹Mayoå†…çª¥é•œè¯„åˆ†(MES)è¯„ä¼°ä»»åŠ¡ï¼ŒMEGANç›¸æ¯”ç°æœ‰æ–¹æ³•å®ç°äº†3.5%çš„F1åˆ†æ•°æå‡å’Œ30.5%çš„é¢„æœŸæ ¡å‡†è¯¯å·®(Expected Calibration Error)é™ä½ã€‚æ­¤å¤–ï¼ŒMEGANè¿˜æ”¯æŒåŸºäºä¸ç¡®å®šæ€§çš„æ ·æœ¬åˆ†å±‚ï¼Œæœ‰æ•ˆå‡è½»äº†æ ‡æ³¨è´Ÿæ‹…ï¼Œå¹¶ä¸ºæé«˜ä¸´åºŠè¯•éªŒçš„æ•ˆç‡å’Œä¸€è‡´æ€§æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 2 figures, 1 table, accepted at UNSURE, MICCAI",
      "pdf_url": "https://arxiv.org/pdf/2509.12772v1",
      "published_date": "2025-09-16 07:42:01 UTC",
      "updated_date": "2025-09-16 07:42:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T18:59:31.457213+00:00"
    },
    {
      "arxiv_id": "2509.18362v1",
      "title": "FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction",
      "title_zh": "FastMTPï¼šé€šè¿‡å¢å¼ºçš„å¤š Token é¢„æµ‹åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Yuxuan Cai",
        "Xiaozhuan Liang",
        "Xinghua Wang",
        "Jin Ma",
        "Haijin Liang",
        "Jinwen Luo",
        "Xinyu Zuo",
        "Lisheng Duan",
        "Yuyang Yin",
        "Xi Chen"
      ],
      "abstract": "As large language models (LLMs) become increasingly powerful, the sequential nature of autoregressive generation creates a fundamental throughput bottleneck that limits the practical deployment. While Multi-Token Prediction (MTP) has demonstrated remarkable benefits for model training efficiency and performance, its inherent potential for inference acceleration remains largely unexplored. This paper introduces FastMTP, a simple yet effective method that improves multi-step draft quality by aligning MTP training with its inference pattern, significantly enhancing speculative decoding performance. Our approach fine-tunes a single MTP head with position-shared weights on self-distilled data, enabling it to capture dependencies among consecutive future tokens and maintain high acceptance rates across multiple recursive draft steps. By integrating language-aware dynamic vocabulary compression into the MTP head, we further reduce computational overhead in the drafting process. Experimental results across seven diverse benchmarks demonstrate that FastMTP achieves an average of 2.03x speedup compared to standard next token prediction with lossless output quality, outperforming vanilla MTP by 82%. FastMTP requires only lightweight training and seamlessly integrates with existing inference frameworks, offering a practical and rapidly deployable solution for accelerating LLM inference.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è‡ªå›å½’ç”Ÿæˆå¯¼è‡´çš„ååé‡ç“¶é¢ˆï¼Œæå‡ºäº†FastMTPï¼Œæ—¨åœ¨é€šè¿‡å°†Multi-Token Prediction (MTP) è®­ç»ƒä¸æ¨ç†æ¨¡å¼å¯¹é½æ¥æ˜¾è‘—å¢å¼ºæŠ•æœºè§£ç (Speculative Decoding)çš„æ€§èƒ½ã€‚FastMTPé€šè¿‡åœ¨è‡ªè’¸é¦(Self-distilled)æ•°æ®ä¸Šå¾®è°ƒå…·æœ‰ä½ç½®å…±äº«æƒé‡çš„å•ä¸ªMTPå¤´ï¼Œä½¿å…¶èƒ½å¤Ÿæ•æ‰è¿ç»­æœªæ¥æ ‡è®°é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œåœ¨å¤šä¸ªé€’å½’è‰ç¨¿æ­¥éª¤ä¸­ç»´æŒé«˜æ¥å—ç‡(Acceptance Rates)ã€‚ä¸ºäº†è¿›ä¸€æ­¥é™ä½æ¨ç†å¼€é”€ï¼Œè¯¥æ–¹æ³•è¿˜é›†æˆäº†è¯­è¨€æ„ŸçŸ¥åŠ¨æ€è¯æ±‡å‹ç¼©(Language-aware dynamic vocabulary compression)æŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFastMTPåœ¨ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†å¹³å‡2.03å€çš„æ¨ç†åŠ é€Ÿä¸”ä¿è¯è¾“å‡ºè´¨é‡æ— æŸï¼Œå…¶è¡¨ç°ä¼˜äºVanilla MTPè¾¾82%ã€‚ç”±äºè¯¥æ–¹æ³•ä»…éœ€è½»é‡çº§è®­ç»ƒä¸”èƒ½æ— ç¼é›†æˆè‡³ç°æœ‰æ¡†æ¶ï¼ŒFastMTPä¸ºåŠ é€ŸLLMæ¨ç†æä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯å¿«é€Ÿéƒ¨ç½²çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18362v1",
      "published_date": "2025-09-16 07:36:26 UTC",
      "updated_date": "2025-09-16 07:36:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:13.556085+00:00"
    },
    {
      "arxiv_id": "2509.12765v1",
      "title": "InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering",
      "title_zh": "InfoGain-RAGï¼šé€šè¿‡åŸºäºæ–‡æ¡£ä¿¡æ¯å¢ç›Šçš„é‡æ’åºä¸è¿‡æ»¤æå‡æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Zihan Wang",
        "Zihan Liang",
        "Zhou Shao",
        "Yufei Ma",
        "Huangyu Dai",
        "Ben Chen",
        "Lingtao Mao",
        "Chenyi Lei",
        "Yuqing Ding",
        "Han Li"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to address key limitations of Large Language Models (LLMs), such as hallucination, outdated knowledge, and lacking reference. However, current RAG frameworks often struggle with identifying whether retrieved documents meaningfully contribute to answer generation. This shortcoming makes it difficult to filter out irrelevant or even misleading content, which notably impacts the final performance. In this paper, we propose Document Information Gain (DIG), a novel metric designed to quantify the contribution of retrieved documents to correct answer generation. DIG measures a document's value by computing the difference of LLM's generation confidence with and without the document augmented. Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to train a specialized reranker, which prioritizes each retrieved document from exact distinguishing and accurate sorting perspectives. This approach can effectively filter out irrelevant documents and select the most valuable ones for better answer generation. Extensive experiments across various models and benchmarks demonstrate that InfoGain-RAG can significantly outperform existing approaches, on both single and multiple retrievers paradigm. Specifically on NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG respectively, and even an average of 15.3% increment on advanced proprietary model GPT-4o across all datasets. These results demonstrate the feasibility of InfoGain-RAG as it can offer a reliable solution for RAG in multiple applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†InfoGain-RAGæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) ä¸­éš¾ä»¥è¯†åˆ«æ£€ç´¢æ–‡æ¡£å¯¹ç”Ÿæˆç­”æ¡ˆè´¡çŒ®åº¦çš„é—®é¢˜ï¼Œä»è€Œè¿‡æ»¤æ— å…³æˆ–è¯¯å¯¼æ€§å†…å®¹ã€‚ä½œè€…å¼•å…¥äº†ä¸€ç§åä¸ºDocument Information Gain (DIG) çš„æ–°æŒ‡æ ‡ï¼Œé€šè¿‡è®¡ç®—å¤§è¯­è¨€æ¨¡å‹ (LLM) åœ¨æœ‰æ— è¯¥æ–‡æ¡£è¾…åŠ©ä¸‹ç”Ÿæˆç½®ä¿¡åº¦çš„å·®å¼‚ï¼Œæ¥é‡åŒ–æ–‡æ¡£çš„å®é™…ä»·å€¼ã€‚åŸºäºDIGåˆ†æ•°ï¼ŒInfoGain-RAGè®­ç»ƒäº†ä¸€ä¸ªä¸“é—¨çš„é‡æ’åºå™¨ (reranker)ï¼Œä»ç²¾ç¡®åŒºåˆ†å’Œå‡†ç¡®æ’åºä¸¤ä¸ªç»´åº¦å¯¹æ£€ç´¢æ–‡æ¡£è¿›è¡Œä¼˜å…ˆçº§æ’åºï¼Œä»è€Œæœ‰æ•ˆç­›é€‰å‡ºæœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚åœ¨NaturalQAç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒInfoGain-RAGçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºæœ´ç´ RAGã€è‡ªæˆ‘åæ€å¼RAGä»¥åŠå…ˆè¿›çš„åŸºäºæ’åºçš„RAGæ–¹æ¡ˆã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶åœ¨GPT-4oç­‰ä¸“æœ‰æ¨¡å‹ä¸Šçš„å¹³å‡æ€§èƒ½æå‡è¾¾åˆ°15.3%ï¼Œè¯æ˜äº†å…¶ä½œä¸ºä¸€ç§å¯é çš„RAGä¼˜åŒ–æ–¹æ¡ˆåœ¨å¤šç§å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "EMNLP'25 Oral Presentation. Contact: benchen4395@gmail.com",
      "pdf_url": "https://arxiv.org/pdf/2509.12765v1",
      "published_date": "2025-09-16 07:28:07 UTC",
      "updated_date": "2025-09-16 07:28:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:06.186082+00:00"
    },
    {
      "arxiv_id": "2509.14276v2",
      "title": "Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity",
      "title_zh": "å»ºè®¾æ€§å†²çªé©±åŠ¨çš„ç­–ç•¥å¤šæ ·æ€§å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yuxiang Mai",
        "Qiyue Yin",
        "Wancheng Ni",
        "Pei Xu",
        "Kaiqi Huang"
      ],
      "abstract": "In recent years, diversity has emerged as a useful mechanism to enhance the efficiency of multi-agent reinforcement learning (MARL). However, existing methods predominantly focus on designing policies based on individual agent characteristics, often neglecting the interplay and mutual influence among agents during policy formation. To address this gap, we propose Competitive Diversity through Constructive Conflict (CoDiCon), a novel approach that incorporates competitive incentives into cooperative scenarios to encourage policy exchange and foster strategic diversity among agents. Drawing inspiration from sociological research, which highlights the benefits of moderate competition and constructive conflict in group decision-making, we design an intrinsic reward mechanism using ranking features to introduce competitive motivations. A centralized intrinsic reward module generates and distributes varying reward values to agents, ensuring an effective balance between competition and cooperation. By optimizing the parameterized centralized reward module to maximize environmental rewards, we reformulate the constrained bilevel optimization problem to align with the original task objectives. We evaluate our algorithm against state-of-the-art methods in the SMAC and GRF environments. Experimental results demonstrate that CoDiCon achieves superior performance, with competitive intrinsic rewards effectively promoting diverse and adaptive strategies among cooperative agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ä¸­ç°æœ‰å¤šæ ·æ€§æ–¹æ³•å¾€å¾€å¿½è§†æ™ºèƒ½ä½“é—´äº’åŠ¨ä¸ç›¸äº’å½±å“çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºCoDiCon(Competitive Diversity through Constructive Conflict)çš„æ–°ç®—æ³•ã€‚è¯¥æ–¹æ³•å—åˆ°ç¤¾ä¼šå­¦ç ”ç©¶å¯å‘ï¼Œåœ¨åä½œåœºæ™¯ä¸­å¼•å…¥ç«äº‰æ¿€åŠ±ï¼Œåˆ©ç”¨å»ºè®¾æ€§å†²çªæ¥ä¿ƒè¿›æ™ºèƒ½ä½“é—´çš„ç­–ç•¥äº¤æ¢å¹¶åŸ¹å…»ç­–ç•¥å¤šæ ·æ€§(strategic diversity)ã€‚é€šè¿‡è®¾è®¡ä¸€ç§åŸºäºæ’åºç‰¹å¾çš„ä¸­å¿ƒåŒ–å†…åœ¨å¥–åŠ±æ¨¡å—ï¼ŒCoDiConèƒ½å¤Ÿåœ¨ç«äº‰ä¸åä½œä¹‹é—´å®ç°æœ‰æ•ˆå¹³è¡¡ã€‚ç ”ç©¶å°†è¯¥è¿‡ç¨‹å»ºæ¨¡ä¸ºåŒå±‚ä¼˜åŒ–(bilevel optimization)é—®é¢˜ï¼Œä»¥ç¡®ä¿ä¼˜åŒ–æ–¹å‘ä¸åŸå§‹ç¯å¢ƒå¥–åŠ±ç›®æ ‡ä¸€è‡´ã€‚åœ¨SMACå’ŒGRFç¯å¢ƒä¸‹çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCoDiConçš„æ€§èƒ½ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¯æ˜äº†ç«äº‰æ€§å†…åœ¨å¥–åŠ±åœ¨æ¨åŠ¨åä½œæ™ºèƒ½ä½“ç”Ÿæˆå¤šæ ·åŒ–ä¸”å…·è‡ªé€‚åº”æ€§ç­–ç•¥æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.14276v2",
      "published_date": "2025-09-16 07:26:35 UTC",
      "updated_date": "2025-09-26 02:28:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:06.897142+00:00"
    },
    {
      "arxiv_id": "2509.12754v1",
      "title": "Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model",
      "title_zh": "è¿ˆå‘ç‰©ä½“æƒå±ç†è§£ï¼šç»“åˆå¤§è¯­è¨€æ¨¡å‹ä¸æ¦‚ç‡ç”Ÿæˆæ¨¡å‹çš„ä¸»åŠ¨æé—®ç”Ÿæˆ",
      "authors": [
        "Saki Hashimoto",
        "Shoichi Hasegawa",
        "Tomochika Ishikawa",
        "Akira Taniguchi",
        "Yoshinobu Hagiwara",
        "Lotfi El Hafi",
        "Tadahiro Taniguchi"
      ],
      "abstract": "Robots operating in domestic and office environments must understand object ownership to correctly execute instructions such as ``Bring me my cup.'' However, ownership cannot be reliably inferred from visual features alone. To address this gap, we propose Active Ownership Learning (ActOwL), a framework that enables robots to actively generate and ask ownership-related questions to users. ActOwL employs a probabilistic generative model to select questions that maximize information gain, thereby acquiring ownership knowledge efficiently to improve learning efficiency. Additionally, by leveraging commonsense knowledge from Large Language Models (LLM), objects are pre-classified as either shared or owned, and only owned objects are targeted for questioning. Through experiments in a simulated home environment and a real-world laboratory setting, ActOwL achieved significantly higher ownership clustering accuracy with fewer questions than baseline methods. These findings demonstrate the effectiveness of combining active inference with LLM-guided commonsense reasoning, advancing the capability of robots to acquire ownership knowledge for practical and socially appropriate task execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Active Ownership Learning (ActOwL)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººç”±äºæ— æ³•ä»…å‡­è§†è§‰ç‰¹å¾å‡†ç¡®æ¨æ–­ç‰©ä½“æ‰€æœ‰æƒ(Ownership)è€Œéš¾ä»¥æ‰§è¡Œç‰¹å®šæŒ‡ä»¤çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ¦‚ç‡ç”Ÿæˆæ¨¡å‹(Probabilistic Generative Model)ï¼Œé€šè¿‡ä¸»åŠ¨ç”Ÿæˆå¹¶å‘ç”¨æˆ·è¯¢é—®èƒ½æœ€å¤§åŒ–ä¿¡æ¯å¢ç›Š(Information Gain)çš„é—®é¢˜ï¼Œå®ç°é«˜æ•ˆçš„æ‰€æœ‰æƒçŸ¥è¯†è·å–ã€‚åŒæ—¶ï¼ŒActOwLåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Model, LLM)çš„å¸¸è¯†æ¨ç†èƒ½åŠ›å°†ç‰©ä½“é¢„å…ˆåˆ†ç±»ä¸ºå…±äº«æˆ–ç§æœ‰ï¼Œä»è€Œä»…é’ˆå¯¹ç§æœ‰ç‰©ä½“è¿›è¡Œé’ˆå¯¹æ€§æé—®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ¨¡æ‹Ÿå®¶åº­å’ŒçœŸå®å®éªŒå®¤ç¯å¢ƒä¸­ï¼ŒActOwLç›¸è¾ƒäºåŸºçº¿æ–¹æ³•èƒ½ä»¥æ›´å°‘çš„æé—®æ¬¡æ•°æ˜¾è‘—æé«˜æ‰€æœ‰æƒèšç±»çš„å‡†ç¡®æ€§ã€‚è¯¥æˆæœè¯æ˜äº†ä¸»åŠ¨æ¨ç†ä¸LLMå¼•å¯¼çš„å¸¸è¯†æ¨ç†ç›¸ç»“åˆçš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æœºå™¨äººåœ¨å®é™…åº”ç”¨ä¸­å®ç°ç¤¾äº¤è§„èŒƒåŒ–ä»»åŠ¡æ‰§è¡Œçš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to AROB-ISBC 2026 (Journal Track option)",
      "pdf_url": "https://arxiv.org/pdf/2509.12754v1",
      "published_date": "2025-09-16 07:15:52 UTC",
      "updated_date": "2025-09-16 07:15:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:14.200376+00:00"
    },
    {
      "arxiv_id": "2509.14275v2",
      "title": "FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated LLMs in Mental Health",
      "title_zh": "FedMentorï¼šå¿ƒç†å¥åº·é¢†åŸŸå¼‚æ„è”é‚¦å¤§è¯­è¨€æ¨¡å‹çš„é¢†åŸŸæ„ŸçŸ¥å·®åˆ†éšç§",
      "authors": [
        "Nobin Sarwar",
        "Shubhashis Roy Dipta"
      ],
      "abstract": "Privacy-preserving adaptation of Large Language Models (LLMs) in sensitive domains (e.g., mental health) requires balancing strict confidentiality with model utility and safety. We propose FedMentor, a federated fine-tuning framework that integrates Low-Rank Adaptation (LoRA) and domain-aware Differential Privacy (DP) to meet per-domain privacy budgets while maintaining performance. Each client (domain) applies a custom DP noise scale proportional to its data sensitivity, and the server adaptively reduces noise when utility falls below a threshold. In experiments on three mental health datasets, we show that FedMentor improves safety over standard Federated Learning (FL) without privacy, raising safe output rates by up to three points and lowering toxicity, while maintaining utility (BERTScore F1 and ROUGE-L) within 0.5% of the non-private baseline and close to the centralized upper bound. The framework scales to backbones with up to 1.7B parameters on single-GPU clients, requiring < 173 MB of communication per-round. FedMentor demonstrates a practical approach to privately fine-tune LLMs for safer deployments in healthcare and other sensitive fields.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FedMentorï¼Œä¸€ç§é’ˆå¯¹å¿ƒç†å¥åº·ç­‰æ•æ„Ÿé¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹(LLMs)è”é‚¦å¾®è°ƒæ¡†æ¶ï¼Œé€šè¿‡é›†æˆä½ç§©è‡ªé€‚åº”(LoRA)å’Œé¢†åŸŸæ„ŸçŸ¥å·®åˆ†éšç§(DP)æŠ€æœ¯ï¼Œå®ç°äº†ä¸¥æ ¼æœºå¯†æ€§ä¸æ¨¡å‹æ•ˆç”¨ã€å®‰å…¨æ€§çš„å¹³è¡¡ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œå„å®¢æˆ·ç«¯æ ¹æ®æ•°æ®æ•æ„Ÿåº¦åº”ç”¨å®šåˆ¶çš„DPå™ªå£°æ¯”ä¾‹ï¼Œä¸”æœåŠ¡å™¨èƒ½å¤Ÿæ ¹æ®æ•ˆç”¨è¡¨ç°è‡ªé€‚åº”è°ƒæ•´å™ªå£°æ°´å¹³ã€‚é’ˆå¯¹ä¸‰ä¸ªå¿ƒç†å¥åº·æ•°æ®é›†çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedMentoråœ¨å®‰å…¨æ€§æ–¹é¢ä¼˜äºä¸å…·å¤‡éšç§ä¿æŠ¤çš„è”é‚¦å­¦ä¹ (FL)ï¼Œå°†å®‰å…¨è¾“å‡ºç‡æå‡äº†å¤šè¾¾ä¸‰ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ–‡æœ¬æ¯’æ€§ã€‚åŒæ—¶ï¼Œå…¶æ¨¡å‹æ•ˆç”¨(BERTScore F1å’ŒROUGE-L)ä¸ééšç§åŸºçº¿çš„å·®è·æ§åˆ¶åœ¨0.5%ä»¥å†…ï¼Œä¸”æ¥è¿‘ä¸­å¿ƒåŒ–è®­ç»ƒçš„ä¸Šé™ã€‚è¯¥æ¡†æ¶æ”¯æŒåœ¨å•GPUå®¢æˆ·ç«¯ä¸Šè¿è¡Œé«˜è¾¾1.7Bå‚æ•°çš„æ¨¡å‹ï¼Œå•è½®é€šä¿¡éœ€æ±‚ä¸è¶³173 MBï¼Œä¸ºåŒ»ç–—å¥åº·åŠå…¶ä»–æ•æ„Ÿé¢†åŸŸçš„ç§å¯†å¾®è°ƒä¸å®‰å…¨éƒ¨ç½²æä¾›äº†å®ç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "NeurIPS 2025 GenAI4Health Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.14275v2",
      "published_date": "2025-09-16 07:08:36 UTC",
      "updated_date": "2025-10-05 21:41:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:16.185668+00:00"
    },
    {
      "arxiv_id": "2509.12743v1",
      "title": "Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs",
      "title_zh": "åŸºäºæ£€ç´¢å¢å¼ºæ¡†æ¶ä¸å¤§è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬å›¾æ¨ç†",
      "authors": [
        "Hanqing Li",
        "Kiran Sheena Jyothi",
        "Henry Liang",
        "Sharika Mahadevan",
        "Diego Klabjan"
      ],
      "abstract": "We propose a new, training-free method, Graph Reasoning via Retrieval Augmented Framework (GRRAF), that harnesses retrieval-augmented generation (RAG) alongside the code-generation capabilities of large language models (LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target graph is stored in a graph database, and the LLM is prompted to generate executable code queries that retrieve the necessary information. This approach circumvents the limitations of existing methods that require extensive finetuning or depend on predefined algorithms, and it incorporates an error feedback loop with a time-out mechanism to ensure both correctness and efficiency. Experimental evaluations on the GraphInstruct dataset reveal that GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle detection, bipartite graph checks, shortest path computation, and maximum flow, while maintaining consistent token costs regardless of graph sizes. Imperfect but still very high performance is observed on subgraph matching. Notably, GRRAF scales effectively to large graphs with up to 10,000 nodes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GRRAFï¼ˆGraph Reasoning via Retrieval Augmented Frameworkï¼‰ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å›¾æ¨ç†æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»£ç ç”Ÿæˆèƒ½åŠ›æ¥è§£å†³å¤šç§å›¾æ¨ç†ä»»åŠ¡ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œç›®æ ‡å›¾è¢«å­˜å‚¨åœ¨å›¾æ•°æ®åº“ä¸­ï¼Œç”±LLMç”Ÿæˆå¯æ‰§è¡Œçš„ä»£ç æŸ¥è¯¢ä»¥æ£€ç´¢æ‰€éœ€ä¿¡æ¯ï¼Œæœ‰æ•ˆé¿å¼€äº†ç°æœ‰æ–¹æ³•å¯¹å¤§è§„æ¨¡å¾®è°ƒæˆ–é¢„å®šä¹‰ç®—æ³•çš„ä¾èµ–ã€‚æ­¤å¤–ï¼ŒGRRAFå¼•å…¥äº†åŒ…å«è¶…æ—¶æœºåˆ¶çš„é”™è¯¯åé¦ˆå¾ªç¯ï¼Œä»¥ç¡®ä¿æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§ä¸é«˜æ•ˆæ€§ã€‚åœ¨GraphInstructæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¯æ£€æµ‹(cycle detection)ã€äºŒåˆ†å›¾æ£€æŸ¥(bipartite graph checks)ã€æœ€çŸ­è·¯å¾„è®¡ç®—(shortest path computation)åŠæœ€å¤§æµ(maximum flow)ç­‰ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº†100%çš„å‡†ç¡®ç‡ã€‚ç ”ç©¶è¿˜å‘ç°ï¼ŒGRRAFåœ¨ä¿æŒç¨³å®šTokenæˆæœ¬çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ‰©å±•è‡³æ‹¥æœ‰10,000ä¸ªèŠ‚ç‚¹çš„å¤§è§„æ¨¡å›¾ç»“æ„ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„é›¶æ ·æœ¬(Zero-shot)æ¨ç†ä¸æ‰©å±•èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12743v1",
      "published_date": "2025-09-16 06:58:58 UTC",
      "updated_date": "2025-09-16 06:58:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:28.594213+00:00"
    },
    {
      "arxiv_id": "2509.12741v1",
      "title": "Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions",
      "title_zh": "é¢å‘æ‰‹è‡‚è¿åŠ¨ä¸‹æœºå™¨äººè¾…åŠ©ç©¿è¡£çš„åŠ›è°ƒåˆ¶è§†è§‰ç­–ç•¥",
      "authors": [
        "Alexis Yihong Hao",
        "Yufei Wang",
        "Navin Sriram Ravie",
        "Bharath Hegde",
        "David Held",
        "Zackory Erickson"
      ],
      "abstract": "Robot-assisted dressing has the potential to significantly improve the lives of individuals with mobility impairments. To ensure an effective and comfortable dressing experience, the robot must be able to handle challenging deformable garments, apply appropriate forces, and adapt to limb movements throughout the dressing process. Prior work often makes simplifying assumptions -- such as static human limbs during dressing -- which limits real-world applicability. In this work, we develop a robot-assisted dressing system capable of handling partial observations with visual occlusions, as well as robustly adapting to arm motions during the dressing process. Given a policy trained in simulation with partial observations, we propose a method to fine-tune it in the real world using a small amount of data and multi-modal feedback from vision and force sensing, to further improve the policy's adaptability to arm motions and enhance safety. We evaluate our method in simulation with simplified articulated human meshes and in a real world human study with 12 participants across 264 dressing trials. Our policy successfully dresses two long-sleeve everyday garments onto the participants while being adaptive to various kinds of arm motions, and greatly outperforms prior baselines in terms of task completion and user feedback. Video are available at https://dressing-motion.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœºå™¨äººè¾…åŠ©ç©¿è¡£(Robot-assisted dressing)ä¸­ç°æœ‰æ¨¡å‹å¾€å¾€å‡è®¾äººä½“è‚¢ä½“é™æ­¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªèƒ½å¤„ç†è§†è§‰é®æŒ¡å¹¶é²æ£’é€‚åº”æ‰‹è‡‚è¿åŠ¨çš„æ–°å‹æœºå™¨äººç³»ç»Ÿã€‚ç ”ç©¶è€…é¦–å…ˆåœ¨ä»¿çœŸç¯å¢ƒä¸­ä½¿ç”¨éƒ¨åˆ†è§‚æµ‹(Partial observations)è®­ç»ƒæ¨¡å‹ç­–ç•¥ï¼Œéšåæå‡ºä¸€ç§ç°å®ä¸–ç•Œå¾®è°ƒ(Fine-tune)æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆè§†è§‰(Vision)ä¸åŠ›æ„Ÿåº”(Force sensing)çš„å¤šæ¨¡æ€åé¦ˆï¼Œæå‡äº†ç³»ç»Ÿåœ¨åŠ¨æ€è¿‡ç¨‹ä¸­çš„é€‚åº”æ€§ä¸å®‰å…¨æ€§ã€‚å®éªŒåœ¨ä»¿çœŸç¯å¢ƒåŠåŒ…å«12åå‚ä¸è€…ã€264æ¬¡ç©¿è¡£è¯•éªŒçš„çœŸå®äººä½“ç ”ç©¶ä¸­å±•å¼€ï¼Œæµ‹è¯•æ¶µç›–äº†ä¸¤ç§é•¿è¢–æ—¥å¸¸æœè£…ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè¯¥ç­–ç•¥åœ¨ä»»åŠ¡å®Œæˆç‡å’Œç”¨æˆ·åé¦ˆæ–¹é¢å‡æ˜¾è‘—ä¼˜äºå…ˆå‰çš„åŸºå‡†æ¨¡å‹(Baselines)ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚å˜å½¢è¡£ç‰©åŠåŠ¨æ€äººä½“äº¤äº’ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12741v1",
      "published_date": "2025-09-16 06:53:18 UTC",
      "updated_date": "2025-09-16 06:53:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:32.798763+00:00"
    },
    {
      "arxiv_id": "2509.12740v1",
      "title": "Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0",
      "title_zh": "èåˆå˜åˆ†è‡ªç¼–ç å™¨çš„æ·±åº¦ç”Ÿæˆåˆ¤åˆ«å¼æ•°å­—å­ªç”Ÿï¼šé¢å‘å·¥ä¸š 6.0 ä¸ç¤¾ä¼š 6.0 ç‰©ç†æœºå™¨äººçš„æ— ç›‘ç£é¢„æµ‹æ€§çƒ­çŠ¶æ€ç›‘æµ‹",
      "authors": [
        "Eric Guiffo Kaigom"
      ],
      "abstract": "Robots are unrelentingly used to achieve operational efficiency in Industry 4.0 along with symbiotic and sustainable assistance for the work-force in Industry 5.0. As resilience, robustness, and well-being are required in anti-fragile manufacturing and human-centric societal tasks, an autonomous anticipation and adaption to thermal saturation and burns due to motors overheating become instrumental for human safety and robot availability. Robots are thereby expected to self-sustain their performance and deliver user experience, in addition to communicating their capability to other agents in advance to ensure fully automated thermally feasible tasks, and prolong their lifetime without human intervention. However, the traditional robot shutdown, when facing an imminent thermal saturation, inhibits productivity in factories and comfort in the society, while cooling strategies are hard to implement after the robot acquisition. In this work, smart digital twins endowed with generative AI, i.e., variational autoencoders, are leveraged to manage thermally anomalous and generate uncritical robot states. The notion of thermal difficulty is derived from the reconstruction error of variational autoencoders. A robot can use this score to predict, anticipate, and share the thermal feasibility of desired motion profiles to meet requirements from emerging applications in Industry 6.0 and Society 6.0.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå˜åˆ†è‡ªç¼–ç å™¨ (Variational Autoencoder) çš„æ·±åº¦ç”Ÿæˆå¼ä¸åˆ¤åˆ«å¼æ•°å­—å­ªç”Ÿ (Digital Twin) æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å·¥ä¸š 6.0 (Industry 6.0) å’Œç¤¾ä¼š 6.0 (Society 6.0) èƒŒæ™¯ä¸‹ç‰©ç†æœºå™¨äººçš„æ— ç›‘ç£é¢„æµ‹æ€§çƒ­çŠ¶æ€ç›‘æµ‹ã€‚é’ˆå¯¹æœºå™¨äººç”µæœºè¿‡çƒ­å¯¹ç”Ÿäº§æ•ˆç‡å’Œäººç±»å®‰å…¨æ„æˆçš„å¨èƒï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) æŠ€æœ¯è¯†åˆ«çƒ­å¼‚å¸¸å¹¶ç”Ÿæˆå¥åº·çš„æœºå™¨äººçŠ¶æ€ã€‚é€šè¿‡æå–å˜åˆ†è‡ªç¼–ç å™¨çš„é‡æ„è¯¯å·® (reconstruction error) æ¥å®šä¹‰â€œçƒ­éš¾åº¦â€è¯„åˆ†ï¼Œæœºå™¨äººèƒ½å¤Ÿæ®æ­¤é¢„åˆ¤å¹¶å…±äº«å…¶è¿åŠ¨è½¨è¿¹çš„çƒ­å¯è¡Œæ€§ã€‚è¿™ç§æ–¹æ³•å…è®¸æœºå™¨äººè‡ªä¸»ä¼˜åŒ–æ€§èƒ½å¹¶å»¶é•¿ä½¿ç”¨å¯¿å‘½ï¼Œæœ‰æ•ˆé¿å…äº†ä¼ ç»Ÿæ–¹æ¡ˆä¸­å› è¿‡çƒ­å¯¼è‡´çš„é¢‘ç¹åœæœºã€‚è¯¥ç ”ç©¶ä¸ºå®ç°æŠ—è„†å¼±åˆ¶é€ å’Œä»¥äººä¸ºä¸­å¿ƒçš„ç¤¾ä¼šåŒ–ä»»åŠ¡æä¾›äº†å…³é”®çš„æŠ€æœ¯æ”¯æŒï¼Œç¡®ä¿äº†è‡ªåŠ¨åŒ–ä»»åŠ¡åœ¨çƒ­åŠ›å­¦å±‚é¢çš„å®‰å…¨ä¸ç¨³å®šã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "$Â©$ 2025 the authors. This work has been accepted to the to the 10th IFAC Symposium on Mechatronic Systems & 14th IFAC Symposium on Robotics July 15-18, 2025 || Paris, France for publication under a Creative Commons Licence CC-BY-NC-ND",
      "pdf_url": "https://arxiv.org/pdf/2509.12740v1",
      "published_date": "2025-09-16 06:52:59 UTC",
      "updated_date": "2025-09-16 06:52:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:43.787284+00:00"
    },
    {
      "arxiv_id": "2509.12739v1",
      "title": "Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors",
      "title_zh": "æœºå™¨äººå…³èŠ‚ç”µæœºçƒ­çŠ¶æ€çš„æ·±åº¦å­¦ä¹ æ— æ¨¡å‹é¢„æµ‹",
      "authors": [
        "Trung Kien La",
        "Eric Guiffo Kaigom"
      ],
      "abstract": "In this work, deep neural networks made up of multiple hidden Long Short-Term Memory (LSTM) and Feedforward layers are trained to predict the thermal behavior of the joint motors of robot manipulators. A model-free and scalable approach is adopted. It accommodates complexity and uncertainty challenges stemming from the derivation, identification, and validation of a large number of parameters of an approximation model that is hardly available. To this end, sensed joint torques are collected and processed to foresee the thermal behavior of joint motors. Promising prediction results of the machine learning based capture of the temperature dynamics of joint motors of a redundant robot with seven joints are presented.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æœºå™¨äººæœºæ¢°è‡‚å…³èŠ‚ç”µæœºçƒ­çŠ¶æ€çš„é¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œ(Deep Neural Networks)çš„æ— æ¨¡å‹(Model-Free)ä¸”å…·æœ‰å¯æ‰©å±•æ€§çš„é¢„æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å¤šå±‚é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(Long Short-Term Memory, LSTM)å’Œå‰é¦ˆå±‚(Feedforward Layers)ï¼Œé€šè¿‡å¤„ç†æ„ŸçŸ¥çš„å…³èŠ‚è½¬çŸ©(Joint Torques)æ•°æ®æ¥é¢„è§ç”µæœºçš„çƒ­è¡Œä¸ºã€‚è¿™ç§æ— æ¨¡å‹æ–¹æ³•æœ‰æ•ˆåº”å¯¹äº†ä¼ ç»Ÿè¿‘ä¼¼æ¨¡å‹åœ¨å‚æ•°æ¨å¯¼ã€è¾¨è¯†å’ŒéªŒè¯è¿‡ç¨‹ä¸­é¢ä¸´çš„å¤æ‚æ€§ä¸ä¸ç¡®å®šæ€§æŒ‘æˆ˜ã€‚ç ”ç©¶åœ¨ä¸€ä¸ªå…·æœ‰ä¸ƒä¸ªå…³èŠ‚çš„å†—ä½™æœºå™¨äºº(Redundant Robot)ä¸Šå±•ç¤ºäº†å®éªŒç»“æœï¼Œè¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç”µæœºæ¸©åº¦åŠ¨åŠ›å­¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ¡ˆåœ¨é¢„æµ‹æœºå™¨äººå…³èŠ‚ç”µæœºçƒ­çŠ¶æ€æ–¹é¢å…·æœ‰æ˜¾è‘—çš„å‡†ç¡®æ€§ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "$Â©$ 2025 the authors. This work has been accepted to the 10th IFAC Symposium on Mechatronic Systems & 14th IFAC Symposium on Robotics July 15-18, 2025 || Paris, France for publication under a Creative Commons Licence CC-BY-NC-ND",
      "pdf_url": "https://arxiv.org/pdf/2509.12739v1",
      "published_date": "2025-09-16 06:52:30 UTC",
      "updated_date": "2025-09-16 06:52:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:42.493439+00:00"
    },
    {
      "arxiv_id": "2509.14274v1",
      "title": "Discovering New Theorems via LLMs with In-Context Proof Learning in Lean",
      "title_zh": "åœ¨ Lean ä¸­åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å†…è¯æ˜å­¦ä¹ å‘ç°æ–°å®šç†",
      "authors": [
        "Kazumi Kasaura",
        "Naoto Onda",
        "Yuta Oriike",
        "Masaya Taniguchi",
        "Akiyoshi Sannai",
        "Sho Sonoda"
      ],
      "abstract": "Large Language Models have demonstrated significant promise in formal theorem proving. However, previous works mainly focus on solving existing problems. In this paper, we focus on the ability of LLMs to find novel theorems. We propose Conjecturing-Proving Loop pipeline for automatically generating mathematical conjectures and proving them in Lean 4 format. A feature of our approach is that we generate and prove further conjectures with context including previously generated theorems and their proofs, which enables the generation of more difficult proofs by in-context learning of proof strategies without changing parameters of LLMs. We demonstrated that our framework rediscovered theorems with verification, which were published in past mathematical papers and have not yet formalized. Moreover, at least one of these theorems could not be proved by the LLM without in-context learning, even in natural language, which means that in-context learning was effective for neural theorem proving. The source code is available at https://github.com/auto-res/ConjecturingProvingLoop.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸º Conjecturing-Proving Loop çš„æµæ°´çº¿ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ Lean 4 æ ¼å¼ä¸‹è‡ªåŠ¨ç”Ÿæˆæ•°å­¦çŒœæƒ³å¹¶è¿›è¡Œå½¢å¼åŒ–è¯æ˜ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒç‰¹å¾æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹  (In-Context Learning) å¼•å…¥å…ˆå‰ç”Ÿæˆçš„å®šç†åŠå…¶è¯æ˜ï¼Œä½¿æ¨¡å‹æ— éœ€è°ƒæ•´å‚æ•°å³å¯å­¦ä¹ è¯æ˜ç­–ç•¥ï¼Œä»è€Œå¤„ç†æ›´å¤æ‚çš„è¯æ˜ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æˆåŠŸé‡æ–°å‘ç°å¹¶éªŒè¯äº†è¿‡å¾€æ•°å­¦è®ºæ–‡ä¸­å­˜åœ¨ä½†å°šæœªè¢«å½¢å¼åŒ–çš„å®šç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯å®ä¸Šä¸‹æ–‡å­¦ä¹ å¯¹ç¥ç»å®šç†è¯æ˜ (Neural Theorem Proving) å…·æœ‰æ˜¾è‘—æ•ˆæœï¼Œéƒ¨åˆ†å®šç†åœ¨ç¼ºä¹è¯¥æŠ€æœ¯çš„æƒ…å†µä¸‹å³ä¾¿ä½¿ç”¨è‡ªç„¶è¯­è¨€ä¹Ÿæ— æ³•è¢«è¯æ˜ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº† LLMs åœ¨å‘ç°æ–°å®šç†æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶å·²å…¬å¼€å‘å¸ƒäº†æºä»£ç ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.14274v1",
      "published_date": "2025-09-16 06:48:11 UTC",
      "updated_date": "2025-09-16 06:48:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:00:44.086328+00:00"
    },
    {
      "arxiv_id": "2509.12730v1",
      "title": "A Graph Machine Learning Approach for Detecting Topological Patterns in Transactional Graphs",
      "title_zh": "äº¤æ˜“å›¾æ‹“æ‰‘æ¨¡å¼æ£€æµ‹çš„å›¾æœºå™¨å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Francesco Zola",
        "Jon Ander Medina",
        "Andrea Venturi",
        "Amaia Gil",
        "Raul Orduna"
      ],
      "abstract": "The rise of digital ecosystems has exposed the financial sector to evolving abuse and criminal tactics that share operational knowledge and techniques both within and across different environments (fiat-based, crypto-assets, etc.). Traditional rule-based systems lack the adaptability needed to detect sophisticated or coordinated criminal behaviors (patterns), highlighting the need for strategies that analyze actors' interactions to uncover suspicious activities and extract their modus operandi. For this reason, in this work, we propose an approach that integrates graph machine learning and network analysis to improve the detection of well-known topological patterns within transactional graphs. However, a key challenge lies in the limitations of traditional financial datasets, which often provide sparse, unlabeled information that is difficult to use for graph-based pattern analysis. Therefore, we firstly propose a four-step preprocessing framework that involves (i) extracting graph structures, (ii) considering data temporality to manage large node sets, (iii) detecting communities within, and (iv) applying automatic labeling strategies to generate weak ground-truth labels. Then, once the data is processed, Graph Autoencoders are implemented to distinguish among the well-known topological patterns. Specifically, three different GAE variants are implemented and compared in this analysis. Preliminary results show that this pattern-focused, topology-driven method is effective for detecting complex financial crime schemes, offering a promising alternative to conventional rule-based detection systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é›†æˆ Graph Machine Learning å’Œç½‘ç»œåˆ†æçš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜å¯¹äº¤æ˜“å›¾è°±ä¸­å·²çŸ¥æ‹“æ‰‘æ¨¡å¼çš„æ£€æµ‹èƒ½åŠ›ï¼Œä»¥åº”å¯¹æ—¥ç›Šå¤æ‚çš„é‡‘èçŠ¯ç½ªè¡Œä¸ºã€‚é’ˆå¯¹ä¼ ç»Ÿé‡‘èæ•°æ®é›†å­˜åœ¨ç¨€ç–ä¸”ç¼ºä¹æ ‡ç­¾çš„å±€é™æ€§ï¼Œä½œè€…é¦–å…ˆè®¾è®¡äº†ä¸€ä¸ªå››æ­¥é¢„å¤„ç†æ¡†æ¶ï¼Œæ¶µç›–äº†å›¾ç»“æ„æå–ã€æ•°æ®æ—¶åºæ€§ç®¡ç†ã€ç¤¾åŒºæ£€æµ‹ä»¥åŠç”¨äºç”Ÿæˆå¼±æ ‡ç­¾çš„è‡ªåŠ¨æ ‡è®°ç­–ç•¥ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶é€šè¿‡å¯¹æ¯”ä¸‰ç§ä¸åŒçš„ Graph Autoencoders (GAE) å˜ä½“ï¼Œå®ç°äº†å¯¹å¤æ‚æ‹“æ‰‘æ¨¡å¼çš„ç²¾å‡†è¯†åˆ«ä¸åŒºåˆ†ã€‚åˆæ­¥å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§ä»¥æ‹“æ‰‘é©±åŠ¨ä¸”èšç„¦æ¨¡å¼çš„æ–¹æ³•åœ¨æ£€æµ‹å¤æ‚é‡‘èçŠ¯ç½ªæ–¹æ¡ˆæ—¶è¡¨ç°å‡ºè‰²ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿè§„åˆ™ç³»ç»Ÿçš„å±€é™æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ­ç¤ºçŠ¯ç½ªè€…çš„æ“ä½œæ‰‹æ®µå’Œäº¤äº’è¡Œä¸ºæä¾›äº†ä¸€ç§å…·æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¢å¼ºäº†é‡‘èç›‘æµ‹ç³»ç»Ÿçš„è‡ªé€‚åº”æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted @ Workshop on AI for Financial Crime Fight (AI4FCF @ ICDM 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.12730v1",
      "published_date": "2025-09-16 06:43:11 UTC",
      "updated_date": "2025-09-16 06:43:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:06.493481+00:00"
    },
    {
      "arxiv_id": "2509.18148v1",
      "title": "Augmenting Limited and Biased RCTs through Pseudo-Sample Matching-Based Observational Data Fusion Method",
      "title_zh": "åŸºäºä¼ªæ ·æœ¬åŒ¹é…çš„è§‚æµ‹æ•°æ®èåˆæ–¹æ³•ï¼šå¢å¼ºæœ‰é™ä¸”æœ‰åçš„éšæœºå¯¹ç…§è¯•éªŒ",
      "authors": [
        "Kairong Han",
        "Weidong Huang",
        "Taiyang Zhou",
        "Peng Zhen",
        "Kun Kuang"
      ],
      "abstract": "In the online ride-hailing pricing context, companies often conduct randomized controlled trials (RCTs) and utilize uplift models to assess the effect of discounts on customer orders, which substantially influences competitive market outcomes. However, due to the high cost of RCTs, the proportion of trial data relative to observational data is small, which only accounts for 0.65\\% of total traffic in our context, resulting in significant bias when generalizing to the broader user base. Additionally, the complexity of industrial processes reduces the quality of RCT data, which is often subject to heterogeneity from potential interference and selection bias, making it difficult to correct. Moreover, existing data fusion methods are challenging to implement effectively in complex industrial settings due to the high dimensionality of features and the strict assumptions that are hard to verify with real-world data. To address these issues, we propose an empirical data fusion method called pseudo-sample matching. By generating pseudo-samples from biased, low-quality RCT data and matching them with the most similar samples from large-scale observational data, the method expands the RCT dataset while mitigating its heterogeneity. We validated the method through simulation experiments, conducted offline and online tests using real-world data. In a week-long online experiment, we achieved a 0.41\\% improvement in profit, which is a considerable gain when scaled to industrial scenarios with hundreds of millions in revenue. In addition, we discuss the harm to model training, offline evaluation, and online economic benefits when the RCT data quality is not high, and emphasize the importance of improving RCT data quality in industrial scenarios. Further details of the simulation experiments can be found in the GitHub repository https://github.com/Kairong-Han/Pseudo-Matching.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘çº¦è½¦å®šä»·åœºæ™¯ä¸­åˆ©ç”¨å¢ç›Šæ¨¡å‹(Uplift Models)è¯„ä¼°æŠ˜æ‰£æ•ˆæœæ—¶ï¼Œéšæœºå¯¹ç…§è¯•éªŒ(RCTs)é¢ä¸´çš„æ ·æœ¬é‡æå°ã€æ•°æ®åå€šå¤§ä¸”å­˜åœ¨å¼‚è´¨æ€§çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºä¼ªæ ·æœ¬åŒ¹é…(Pseudo-Sample Matching)çš„å®è¯æ•°æ®èåˆæ–¹æ³•ï¼Œé€šè¿‡ä»ä½è´¨é‡RCTæ•°æ®ä¸­ç”Ÿæˆä¼ªæ ·æœ¬å¹¶ä¸å¤§è§„æ¨¡è§‚æµ‹æ•°æ®åŒ¹é…ï¼Œåœ¨æ‰©å……æ•°æ®é›†çš„åŒæ—¶å‡è½»äº†å¼‚è´¨æ€§ã€‚å®éªŒé€šè¿‡æ¨¡æ‹Ÿã€ç¦»çº¿åŠåœ¨çº¿æµ‹è¯•éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¸ºæœŸä¸€å‘¨çš„åœ¨çº¿å®éªŒä¸­å®ç°äº†0.41%çš„åˆ©æ¶¦å¢é•¿ï¼Œåœ¨æ•°äº¿å…ƒè¥æ”¶è§„æ¨¡ä¸‹å…·æœ‰æ˜¾è‘—ç»æµæ”¶ç›Šã€‚è¯¥ç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†ä½è´¨é‡RCTæ•°æ®å¯¹æ¨¡å‹è®­ç»ƒåŠç¦»çº¿è¯„ä¼°çš„å½±å“ï¼Œå¹¶å¼ºè°ƒäº†åœ¨å¤æ‚å·¥ä¸šåœºæ™¯ä¸­æå‡æ•°æ®è´¨é‡çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "Accepted by CIKM 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.18148v1",
      "published_date": "2025-09-16 06:40:30 UTC",
      "updated_date": "2025-09-16 06:40:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:22.087508+00:00"
    },
    {
      "arxiv_id": "2509.12727v1",
      "title": "Unbiased Online Curvature Approximation for Regularized Graph Continual Learning",
      "title_zh": "é¢å‘æ­£åˆ™åŒ–å›¾æŒç»­å­¦ä¹ çš„æ— ååœ¨çº¿æ›²ç‡è¿‘ä¼¼",
      "authors": [
        "Jie Yin",
        "Ke Sun",
        "Han Wu"
      ],
      "abstract": "Graph continual learning (GCL) aims to learn from a continuous sequence of graph-based tasks. Regularization methods are vital for preventing catastrophic forgetting in GCL, particularly in the challenging replay-free, class-incremental setting, where each task consists of a set of unique classes. In this work, we first establish a general regularization framework for GCL based on the curved parameter space induced by the Fisher information matrix (FIM). We show that the dominant Elastic Weight Consolidation (EWC) and its variants are a special case within this framework, using a diagonal approximation of the empirical FIM based on parameters from previous tasks. To overcome their limitations, we propose a new unbiased online curvature approximation of the full FIM based on the model's current learning state. Our method directly estimates the regularization term in an online manner without explicitly evaluating and storing the FIM itself. This enables the model to better capture the loss landscape during learning new tasks while retaining the knowledge learned from previous tasks. Extensive experiments on three graph datasets demonstrate that our method significantly outperforms existing regularization-based methods, achieving a superior trade-off between stability (retaining old knowledge) and plasticity (acquiring new knowledge).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾æŒç»­å­¦ä¹  (Graph Continual Learning) åœ¨æ— å›æ”¾ç±»å¢é‡å­¦ä¹ è®¾ç½®ä¸‹çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå»ºç«‹äº†ä¸€ä¸ªåŸºäº Fisher Information Matrix (FIM) è¯±å¯¼çš„å‚æ•°ç©ºé—´æ­£åˆ™åŒ–é€šç”¨æ¡†æ¶ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œä¸»æµçš„ Elastic Weight Consolidation (EWC) åŠå…¶å˜ä½“ä»…æ˜¯è¯¥æ¡†æ¶ä¸‹ä½¿ç”¨ç»éªŒ FIM å¯¹è§’è¿‘ä¼¼çš„ç‰¹ä¾‹ï¼Œå­˜åœ¨æ•è·æŸå¤±æ™¯è§‚ä¸å‡†ç¡®çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹å½“å‰å­¦ä¹ çŠ¶æ€çš„å…¨ FIM æ— ååœ¨çº¿æ›²ç‡è¿‘ä¼¼æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€æ˜¾å¼è®¡ç®—æˆ–å­˜å‚¨ FIMï¼Œè€Œæ˜¯é€šè¿‡åœ¨çº¿æ–¹å¼ç›´æ¥ä¼°è®¡æ­£åˆ™åŒ–é¡¹ï¼Œä½¿æ¨¡å‹åœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶èƒ½æ›´æœ‰æ•ˆåœ°ä¿ç•™å…ˆå‰ä»»åŠ¡çš„çŸ¥è¯†ã€‚åœ¨ä¸‰ä¸ªå›¾æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¨³å®šæ€§å’Œå¡‘æ€§ä¹‹é—´å–å¾—äº†æ›´ä¼˜çš„å¹³è¡¡ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºäºæ­£åˆ™åŒ–çš„æŒç»­å­¦ä¹ æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.12727v1",
      "published_date": "2025-09-16 06:35:13 UTC",
      "updated_date": "2025-09-16 06:35:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:17.396962+00:00"
    },
    {
      "arxiv_id": "2509.12724v1",
      "title": "Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models",
      "title_zh": "Defense-to-Attackï¼šé€šè¿‡ç»•è¿‡å¼±é˜²å¾¡å®ç°è§†è§‰è¯­è¨€æ¨¡å‹ä¸­æ›´å¼ºåŠ›çš„è¶Šç‹±æ”»å‡»",
      "authors": [
        "Yunhan Zhao",
        "Xiang Zheng",
        "Xingjun Ma"
      ],
      "abstract": "Despite their superb capabilities, Vision-Language Models (VLMs) have been shown to be vulnerable to jailbreak attacks. While recent jailbreaks have achieved notable progress, their effectiveness and efficiency can still be improved. In this work, we reveal an interesting phenomenon: incorporating weak defense into the attack pipeline can significantly enhance both the effectiveness and the efficiency of jailbreaks on VLMs. Building on this insight, we propose Defense2Attack, a novel jailbreak method that bypasses the safety guardrails of VLMs by leveraging defensive patterns to guide jailbreak prompt design. Specifically, Defense2Attack consists of three key components: (1) a visual optimizer that embeds universal adversarial perturbations with affirmative and encouraging semantics; (2) a textual optimizer that refines the input using a defense-styled prompt; and (3) a red-team suffix generator that enhances the jailbreak through reinforcement fine-tuning. We empirically evaluate our method on four VLMs and four safety benchmarks. The results demonstrate that Defense2Attack achieves superior jailbreak performance in a single attempt, outperforming state-of-the-art attack methods that often require multiple tries. Our work offers a new perspective on jailbreaking VLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ­ç¤ºäº†å°†å¼±é˜²å¾¡ï¼ˆweak defenseï¼‰æœºåˆ¶å¼•å…¥æ”»å‡»æµç¨‹å¯ä»¥æ˜¾è‘—æå‡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVision-Language Models, VLMsï¼‰è¶Šç‹±æ”»å‡»ï¼ˆjailbreak attacksï¼‰çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚åŸºäºæ­¤ï¼Œä½œè€…æå‡ºäº†Defense2Attackæ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨é˜²å¾¡æ¨¡å¼æŒ‡å¯¼è¶Šç‹±æç¤ºè¯è®¾è®¡ï¼Œæœ‰æ•ˆç»•è¿‡VLMsçš„å®‰å…¨æŠ¤æ ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šåµŒå…¥è‚¯å®šè¯­ä¹‰å¯¹æŠ—æ‰°åŠ¨çš„è§†è§‰ä¼˜åŒ–å™¨ï¼ˆvisual optimizerï¼‰ã€åˆ©ç”¨é˜²å¾¡é£æ ¼æç¤ºè¯ç²¾ç‚¼è¾“å…¥çš„æ–‡æœ¬ä¼˜åŒ–å™¨ï¼ˆtextual optimizerï¼‰ï¼Œä»¥åŠé€šè¿‡å¼ºåŒ–å¾®è°ƒå¢å¼ºæ”»å‡»æ•ˆæœçš„çº¢é˜Ÿåç¼€ç”Ÿæˆå™¨ï¼ˆred-team suffix generatorï¼‰ã€‚åœ¨å››ç§æ¨¡å‹å’Œå››ä¸ªå®‰å…¨åŸºå‡†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒDefense2Attackä»…éœ€å•æ¬¡å°è¯•å³å¯å®ç°ä¼˜äºç°æœ‰éœ€å¤šæ¬¡å°è¯•æ–¹æ³•çš„è¶Šç‹±æ€§èƒ½ã€‚è¯¥å·¥ä½œé€šè¿‡åˆ©ç”¨é˜²å¾¡æ¨¡å¼æ¥æŒ‡å¯¼æ”»å‡»è®¾è®¡ï¼Œä¸ºç†è§£VLMsçš„å®‰å…¨æ€§æä¾›äº†å…¨æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2509.12724v1",
      "published_date": "2025-09-16 06:25:58 UTC",
      "updated_date": "2025-09-16 06:25:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:25.189684+00:00"
    },
    {
      "arxiv_id": "2509.12716v1",
      "title": "Joint AoI and Handover Optimization in Space-Air-Ground Integrated Network",
      "title_zh": "ç©ºå¤©åœ°ä¸€ä½“åŒ–ç½‘ç»œä¸­ä¿¡æ¯å¹´é¾„ä¸åˆ‡æ¢çš„è”åˆä¼˜åŒ–",
      "authors": [
        "Zifan Lang",
        "Guixia Liu",
        "Geng Sun",
        "Jiahui Li",
        "Jiacheng Wang",
        "Weijie Yuan",
        "Dusit Niyato",
        "Dong In Kim"
      ],
      "abstract": "Despite the widespread deployment of terrestrial networks, providing reliable communication services to remote areas and maintaining connectivity during emergencies remains challenging. Low Earth orbit (LEO) satellite constellations offer promising solutions with their global coverage capabilities and reduced latency, yet struggle with intermittent coverage and limited communication windows due to orbital dynamics. This paper introduces an age of information (AoI)-aware space-air-ground integrated network (SAGIN) architecture that leverages a high-altitude platform (HAP) as intelligent relay between the LEO satellites and ground terminals. Our three-layer design employs hybrid free-space optical (FSO) links for high-capacity satellite-to-HAP communication and reliable radio frequency (RF) links for HAP-to-ground transmission, and thus addressing the temporal discontinuity in LEO satellite coverage while serving diverse user priorities. Specifically, we formulate a joint optimization problem to simultaneously minimize the AoI and satellite handover frequency through optimal transmit power distribution and satellite selection decisions. This highly dynamic, non-convex problem with time-coupled constraints presents significant computational challenges for traditional approaches. To address these difficulties, we propose a novel diffusion model (DM)-enhanced dueling double deep Q-network with action decomposition and state transformer encoder (DD3QN-AS) algorithm that incorporates transformer-based temporal feature extraction and employs a DM-based latent prompt generative module to refine state-action representations through conditional denoising. Simulation results highlight the superior performance of the proposed approach compared with policy-based methods and some other deep reinforcement learning (DRL) benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ„ŸçŸ¥ä¿¡æ¯æ–°é²œåº¦(Age of Information, AoI)çš„ç©ºå¤©åœ°ä¸€ä½“åŒ–ç½‘ç»œ(Space-Air-Ground Integrated Network, SAGIN)æ¶æ„ï¼Œåˆ©ç”¨é«˜ç©ºå¹³å°(High-Altitude Platform, HAP)ä½œä¸ºä½è½¨å«æ˜Ÿ(LEO)ä¸åœ°é¢ç»ˆç«¯ä¹‹é—´çš„æ™ºèƒ½ä¸­ç»§ã€‚è¯¥ä¸‰å±‚è®¾è®¡é€šè¿‡æ··åˆè‡ªç”±ç©ºé—´å…‰é€šä¿¡(Free-Space Optical, FSO)å’Œå°„é¢‘(Radio Frequency, RF)é“¾è·¯ï¼Œæœ‰æ•ˆè§£å†³äº†å«æ˜Ÿè¦†ç›–çš„æ—¶é—´ä¸è¿ç»­æ€§å¹¶æ»¡è¶³äº†ä¸åŒç”¨æˆ·çš„ä¼˜å…ˆçº§éœ€æ±‚ã€‚ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªè”åˆä¼˜åŒ–æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡æœ€ä¼˜åŠŸç‡åˆ†é…å’Œå«æ˜Ÿé€‰æ‹©åŒæ—¶æœ€å°åŒ–AoIå’Œåˆ‡æ¢é¢‘ç‡ã€‚ä¸ºè§£å†³è¿™ä¸€å¤æ‚çš„éå‡¸ä¼˜åŒ–æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹(Diffusion Model)å¢å¼ºçš„DD3QN-ASç®—æ³•ï¼Œè¯¥ç®—æ³•é›†æˆTransformerç¼–ç å™¨æå–æ—¶åºç‰¹å¾ï¼Œå¹¶åˆ©ç”¨ç”Ÿæˆå¼æ¨¡å—ç»†åŒ–çŠ¶æ€-åŠ¨ä½œè¡¨ç¤ºã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„é¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„ç­–ç•¥æ€§æ–¹æ³•å’Œå…¶ä»–æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12716v1",
      "published_date": "2025-09-16 06:16:56 UTC",
      "updated_date": "2025-09-16 06:16:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:26.146084+00:00"
    },
    {
      "arxiv_id": "2509.13375v1",
      "title": "An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity",
      "title_zh": "åŸºäº VLM çš„ OOD æ£€æµ‹å®è¯åˆ†æï¼šæœºåˆ¶ã€ä¼˜åŠ¿ä¸æ•æ„Ÿæ€§",
      "authors": [
        "Yuxiao Lee",
        "Xiaofeng Cao",
        "Wei Ye",
        "Jiangchao Yao",
        "Jingkuan Song",
        "Heng Tao Shen"
      ],
      "abstract": "Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable AI systems. Despite this promising capability, a comprehensive understanding of (1) why they work so effectively, (2) what advantages do they have over single-modal methods, and (3) how is their behavioral robustness -- remains notably incomplete within the research community. This paper presents a systematic empirical analysis of VLM-based OOD detection using in-distribution (ID) and OOD prompts. (1) Mechanisms: We systematically characterize and formalize key operational properties within the VLM embedding space that facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the superiority of these models over established single-modal approaches, attributing this distinct advantage to the VLM's capacity to leverage rich semantic novelty. (3) Sensitivity: We uncovers a significant and previously under-explored asymmetry in their robustness profile: while exhibiting resilience to common image noise, these VLM-based methods are highly sensitive to prompt phrasing. Our findings contribute a more structured understanding of the strengths and critical vulnerabilities inherent in VLM-based OOD detection, offering crucial, empirically-grounded guidance for developing more robust and reliable future designs.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)çš„åˆ†å¸ƒå¤–æ£€æµ‹(Out-of-Distribution, OOD)è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„å®è¯åˆ†æï¼Œæ—¨åœ¨æ¢ç©¶å…¶å·¥ä½œæœºåˆ¶ã€ç›¸å¯¹äºå•æ¨¡æ€æ–¹æ³•çš„ä¼˜åŠ¿ä»¥åŠè¡Œä¸ºé²æ£’æ€§ã€‚é€šè¿‡ç³»ç»Ÿåœ°åˆ»ç”»å’Œå½¢å¼åŒ–VLMåµŒå…¥ç©ºé—´(embedding space)ä¸­çš„å…³é”®æ“ä½œå±æ€§ï¼Œè®ºæ–‡æ­ç¤ºäº†ä¿ƒè¿›é›¶æ ·æœ¬(zero-shot)OODæ£€æµ‹çš„å†…åœ¨æœºåˆ¶ã€‚ç ”ç©¶å®è¯é‡åŒ–äº†è¿™äº›æ¨¡å‹ä¼˜äºä¼ ç»Ÿå•æ¨¡æ€æ–¹æ³•çš„åŸå› ï¼Œå°†å…¶ç‹¬ç‰¹çš„ä¼˜åŠ¿å½’åŠŸäºVLMsåˆ©ç”¨ä¸°å¯Œè¯­ä¹‰æ–°é¢–æ€§(semantic novelty)çš„èƒ½åŠ›ã€‚åœ¨é²æ£’æ€§ç‰¹å¾æ–¹é¢ï¼Œç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªæ­¤å‰æœªè¢«å……åˆ†æ¢è®¨çš„ä¸å¯¹ç§°æ€§ï¼šå°½ç®¡è¿™äº›æ–¹æ³•å¯¹å¸¸è§çš„å›¾åƒå™ªå£°è¡¨ç°å‡ºè¾ƒå¼ºçš„éŸ§æ€§ï¼Œä½†å¯¹æç¤ºè¯è¡¨è¿°(prompt phrasing)å´æåº¦æ•æ„Ÿã€‚è¯¥ç ”ç©¶ä¸ºç†è§£VLM-based OODæ£€æµ‹çš„ä¼˜åŠ¿ä¸å…³é”®æ¼æ´æä¾›äº†ç»“æ„åŒ–çš„è§è§£ï¼Œå¹¶ä¸ºæœªæ¥å¼€å‘æ›´ç¨³å¥ã€å¯é çš„ç³»ç»Ÿè®¾è®¡æä¾›äº†åŸºäºå®è¯çš„é‡è¦æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13375v1",
      "published_date": "2025-09-16 06:11:02 UTC",
      "updated_date": "2025-09-16 06:11:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:29.321921+00:00"
    },
    {
      "arxiv_id": "2509.12682v1",
      "title": "A Comparative Study of YOLOv8 to YOLOv11 Performance in Underwater Vision Tasks",
      "title_zh": "YOLOv8 è‡³ YOLOv11 åœ¨æ°´ä¸‹è§†è§‰ä»»åŠ¡ä¸­çš„æ€§èƒ½å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Gordon Hung",
        "Ivan Felipe Rodriguez"
      ],
      "abstract": "Autonomous underwater vehicles (AUVs) increasingly rely on on-board computer-vision systems for tasks such as habitat mapping, ecological monitoring, and infrastructure inspection. However, underwater imagery is hindered by light attenuation, turbidity, and severe class imbalance, while the computational resources available on AUVs are limited. One-stage detectors from the YOLO family are attractive because they fuse localization and classification in a single, low-latency network; however, their terrestrial benchmarks (COCO, PASCAL-VOC, Open Images) leave open the question of how successive YOLO releases perform in the marine domain. We curate two openly available datasets that span contrasting operating conditions: a Coral Disease set (4,480 images, 18 classes) and a Fish Species set (7,500 images, 20 classes). For each dataset, we create four training regimes (25 %, 50 %, 75 %, 100 % of the images) while keeping balanced validation and test partitions fixed. We train YOLOv8-s, YOLOv9-s, YOLOv10-s, and YOLOv11-s with identical hyperparameters (100 epochs, 640 px input, batch = 16, T4 GPU) and evaluate precision, recall, mAP50, mAP50-95, per-image inference time, and frames-per-second (FPS). Post-hoc Grad-CAM visualizations probe feature utilization and localization faithfulness. Across both datasets, accuracy saturates after YOLOv9, suggesting architectural innovations primarily target efficiency rather than accuracy. Inference speed, however, improves markedly. Our results (i) provide the first controlled comparison of recent YOLO variants on underwater imagery, (ii) show that lightweight YOLOv10 offers the best speed-accuracy trade-off for embedded AUV deployment, and (iii) deliver an open, reproducible benchmark and codebase to accelerate future marine-vision research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªä¸»æ°´ä¸‹èˆªè¡Œå™¨(AUVs)åœ¨æ –æ¯åœ°æµ‹ç»˜å’Œç”Ÿæ€ç›‘æµ‹ä¸­é¢ä¸´çš„å…‰è¡°å‡ã€æ··æµŠåŠè®¡ç®—èµ„æºæœ‰é™ç­‰æŒ‘æˆ˜ï¼Œå¯¹YOLOv8è‡³YOLOv11ç³»åˆ—æ¨¡å‹åœ¨æ°´ä¸‹è§†è§‰ä»»åŠ¡ä¸­çš„æ€§èƒ½è¿›è¡Œäº†ç³»ç»Ÿæ€§æ¯”è¾ƒç ”ç©¶ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨Coral Diseaseå’ŒFish Speciesä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ï¼Œåœ¨å››ç§ä¸åŒçš„è®­ç»ƒæ•°æ®è§„æ¨¡ä¸‹å¯¹YOLOv8-sã€YOLOv9-sã€YOLOv10-såŠYOLOv11-sè¿›è¡Œäº†ç»Ÿä¸€è¶…å‚æ•°çš„è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹å‡†ç¡®ç‡åœ¨YOLOv9ä¹‹åè¾¾åˆ°é¥±å’Œï¼Œè¡¨æ˜åç»­æ¶æ„ä¼˜åŒ–ä¸»è¦é›†ä¸­åœ¨æ•ˆç‡æå‡è€Œéç²¾åº¦çªç ´ã€‚é€šè¿‡å¯¹mAP50ã€æ¨ç†æ—¶é—´åŠFPSç­‰å…³é”®æŒ‡æ ‡çš„ç»¼åˆåˆ†æï¼Œç ”ç©¶æŒ‡å‡ºè½»é‡åŒ–æ¨¡å‹YOLOv10åœ¨åµŒå…¥å¼AUVéƒ¨ç½²ä¸­å±•ç°å‡ºæœ€ä¼˜çš„é€Ÿåº¦ç²¾åº¦å‡è¡¡(speed-accuracy trade-off)ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œé€šè¿‡Grad-CAMå¯è§†åŒ–æŠ€æœ¯æ·±å…¥æ¢ç©¶äº†ç‰¹å¾åˆ©ç”¨æ•ˆç‡ä¸å®šä½å‡†ç¡®æ€§ã€‚ä½œä¸ºé’ˆå¯¹æ°´ä¸‹å›¾åƒYOLOå˜ä½“çš„é¦–ä¸ªå—æ§æ¯”è¾ƒç ”ç©¶ï¼Œè¯¥æˆæœä¸ä»…æä¾›äº†å¼€æºå¯é‡å¤çš„åŸºå‡†æµ‹è¯•ï¼Œä¹Ÿä¸ºæœªæ¥æµ·æ´‹è§†è§‰æŠ€æœ¯çš„åŠ é€Ÿå‘å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 8 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.12682v1",
      "published_date": "2025-09-16 05:12:59 UTC",
      "updated_date": "2025-09-16 05:12:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:40.162874+00:00"
    },
    {
      "arxiv_id": "2509.12678v1",
      "title": "Instance-level Randomization: Toward More Stable LLM Evaluations",
      "title_zh": "å®ä¾‹çº§éšæœºåŒ–ï¼šæå‡å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°çš„ç¨³å®šæ€§",
      "authors": [
        "Yiyang Li",
        "Yonghuang Wu",
        "Ying Luo",
        "Liangtai Sun",
        "Zishu Qin",
        "Lin Qiu",
        "Xuezhi Cao",
        "Xunliang Cai"
      ],
      "abstract": "Evaluations of large language models (LLMs) suffer from instability, where small changes of random factors such as few-shot examples can lead to drastic fluctuations of scores and even model rankings. Moreover, different LLMs can have different preferences for a certain setting of random factors. As a result, using a fixed setting of random factors, which is often adopted as the paradigm of current evaluations, can lead to potential unfair comparisons between LLMs. To mitigate the volatility of evaluations, we first theoretically analyze the sources of variance induced by changes in random factors. Targeting these specific sources, we then propose the instance-level randomization (ILR) method to reduce variance and enhance fairness in model comparisons. Instead of using a fixed setting across the whole benchmark in a single experiment, we randomize all factors that affect evaluation scores for every single instance, run multiple experiments and report the averaged score. Theoretical analyses and empirical results demonstrate that ILR can reduce the variance and unfair comparisons caused by random factors, as well as achieve similar robustness level with less than half computational cost compared with previous methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¯„ä¼°ä¸­çš„ä¸ç¨³å®šæ€§é—®é¢˜ï¼ŒæŒ‡å‡ºéšæœºå› ç´ (å¦‚ few-shot examples)çš„å¾®å°å˜åŒ–ä¼šå¯¼è‡´è¯„åˆ†å‰§çƒˆæ³¢åŠ¨ï¼Œå¹¶ç”±äºæ¨¡å‹åå¥½å·®å¼‚å¼•å‘ä¸å…¬å¹³çš„å¯¹æ¯”ã€‚è®ºæ–‡é€šè¿‡ç†è®ºåˆ†æè¯†åˆ«äº†éšæœºå› ç´ å¸¦æ¥çš„æ–¹å·®æ¥æºï¼Œå¹¶æ®æ­¤æå‡ºäº†å®ä¾‹çº§éšæœºåŒ–(Instance-level Randomization, ILR)æ–¹æ³•ã€‚ILR æ‘’å¼ƒäº†åœ¨æ•´ä¸ªåŸºå‡†æµ‹è¯•ä¸­é‡‡ç”¨å›ºå®šè®¾ç½®çš„ä¼ ç»ŸèŒƒå¼ï¼Œè€Œæ˜¯å¯¹æ¯ä¸€ä¸ªè¯„ä¼°å®ä¾‹çš„éšæœºå› ç´ è¿›è¡Œç‹¬ç«‹éšæœºåŒ–ï¼Œé€šè¿‡å¤šæ¬¡å®éªŒå–å¹³å‡å€¼æ¥æå‡è¯„ä¼°çš„å…¬å¹³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒILR ä¸ä»…èƒ½æœ‰æ•ˆé™ä½éšæœºå› ç´ å¯¼è‡´çš„æ–¹å·®ï¼Œå¢å¼ºæ¨¡å‹æ¯”è¾ƒçš„å…¬ä¿¡åŠ›ï¼Œè¿˜èƒ½åœ¨ä»…æ¶ˆè€—ä¸åˆ°åŸæœ‰æ–¹æ³•ä¸€åŠè®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°æé«˜çš„ç¨³å¥æ€§æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12678v1",
      "published_date": "2025-09-16 05:04:00 UTC",
      "updated_date": "2025-09-16 05:04:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:39.761520+00:00"
    },
    {
      "arxiv_id": "2509.12673v1",
      "title": "MFAF: An EVA02-Based Multi-scale Frequency Attention Fusion Method for Cross-View Geo-Localization",
      "title_zh": "MFAFï¼šåŸºäº EVA02 çš„è·¨è§†è§’åœ°ç†å®šä½å¤šå°ºåº¦é¢‘ç‡æ³¨æ„åŠ›èåˆæ–¹æ³•",
      "authors": [
        "YiTong Liu",
        "TianZhu Liu",
        "YanFeng GU"
      ],
      "abstract": "Cross-view geo-localization aims to determine the geographical location of a query image by matching it against a gallery of images. This task is challenging due to the significant appearance variations of objects observed from variable views, along with the difficulty in extracting discriminative features. Existing approaches often rely on extracting features through feature map segmentation while neglecting spatial and semantic information. To address these issues, we propose the EVA02-based Multi-scale Frequency Attention Fusion (MFAF) method. The MFAF method consists of Multi-Frequency Branch-wise Block (MFB) and the Frequency-aware Spatial Attention (FSA) module. The MFB block effectively captures both low-frequency structural features and high-frequency edge details across multiple scales, improving the consistency and robustness of feature representations across various viewpoints. Meanwhile, the FSA module adaptively focuses on the key regions of frequency features, significantly mitigating the interference caused by background noise and viewpoint variability. Extensive experiments on widely recognized benchmarks, including University-1652, SUES-200, and Dense-UAV, demonstrate that the MFAF method achieves competitive performance in both drone localization and drone navigation tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è·¨è§†è§’åœ°ç†å®šä½ (Cross-view geo-localization) ä¸­ç”±äºè§†è§’å·®å¼‚å¤§åŠé‰´åˆ«æ€§ç‰¹å¾æå–éš¾è€Œå¯¼è‡´çš„æ€§èƒ½é™åˆ¶ï¼Œæå‡ºäº†åŸºäº EVA02 çš„å¤šå°ºåº¦é¢‘ç‡æ³¨æ„åŠ›èåˆæ–¹æ³• (MFAF)ã€‚è¯¥æ–¹æ³•ä¸»è¦ç”±å¤šé¢‘ç‡åˆ†æ”¯å— (MFB) å’Œé¢‘ç‡æ„ŸçŸ¥ç©ºé—´æ³¨æ„åŠ› (FSA) æ¨¡å—ç»„æˆï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•å¿½è§†ç©ºé—´å’Œè¯­ä¹‰ä¿¡æ¯çš„é—®é¢˜ã€‚MFB å—é€šè¿‡åœ¨å¤šä¸ªå°ºåº¦ä¸Šæœ‰æ•ˆæ•æ‰ä½é¢‘ç»“æ„ç‰¹å¾å’Œé«˜é¢‘è¾¹ç¼˜ç»†èŠ‚ï¼Œæ˜¾è‘—æå‡äº†ä¸åŒè§†è§’é—´ç‰¹å¾è¡¨ç¤ºçš„ä¸€è‡´æ€§å’Œé²æ£’æ€§ã€‚åŒæ—¶ï¼ŒFSA æ¨¡å—èƒ½å¤Ÿè‡ªé€‚åº”åœ°èšç„¦äºé¢‘ç‡ç‰¹å¾çš„å…³é”®åŒºåŸŸï¼Œæœ‰æ•ˆç¼“è§£äº†èƒŒæ™¯å™ªå£°å’Œè§†è§’å˜åŒ–å¸¦æ¥çš„å¹²æ‰°ã€‚åœ¨ University-1652ã€SUES-200 å’Œ Dense-UAV ç­‰ä¸»æµåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMFAF æ–¹æ³•åœ¨æ— äººæœºå®šä½å’Œæ— äººæœºå¯¼èˆªä»»åŠ¡ä¸­å‡å–å¾—äº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12673v1",
      "published_date": "2025-09-16 04:51:52 UTC",
      "updated_date": "2025-09-16 04:51:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:43.855416+00:00"
    },
    {
      "arxiv_id": "2509.12669v1",
      "title": "Exact alternative optima for nonlinear optimization problems defined with maximum component objective function constrained by the Sugeno-Weber fuzzy relational inequalities",
      "title_zh": "Sugeno-Weber æ¨¡ç³Šå…³ç³»ä¸ç­‰å¼çº¦æŸä¸‹å…·æœ‰æœ€å¤§åˆ†é‡ç›®æ ‡å‡½æ•°çš„éçº¿æ€§ä¼˜åŒ–é—®é¢˜çš„ç²¾ç¡®æœ€ä¼˜è§£",
      "authors": [
        "Amin Ghodousian",
        "Sara Zal",
        "Minoo Ahmadi"
      ],
      "abstract": "In this paper, we study a latticized optimization problem with fuzzy relational inequality constraints where the feasible region is formed as the intersection of two inequality fuzzy systems and Sugeno-Weber family of t-norms is considered as fuzzy composition. Sugeno-Weber family of t-norms and t-conorms is one of the most applied one in various fuzzy modelling problems. This family of t-norms and t-conorms was suggested by Weber for modeling intersection and union of fuzzy sets. Also, the t-conorms were suggested as addition rules by Sugeno for so-called alpha-fuzzy measures. The resolution of the feasible region of the problem is firstly investigated when it is defined with max-Sugeno-Weber composition and a necessary and sufficient condition is presented for determining the feasibility. Then, based on some theoretical properties of the problem, an algorithm is presented for solving this nonlinear problem. It is proved that the algorithm can find the exact optimal solution and an example is presented to illustrate the proposed algorithm.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨Sugeno-Weberæ¨¡ç³Šå…³ç³»ä¸ç­‰å¼(Sugeno-Weber fuzzy relational inequalities)çº¦æŸä¸‹çš„æ ¼åŒ–ä¼˜åŒ–é—®é¢˜ï¼Œå…¶å¯è¡ŒåŸŸç”±ä¸¤ä¸ªä¸ç­‰å¼æ¨¡ç³Šç³»ç»Ÿçš„äº¤é›†æ„æˆã€‚Sugeno-Weberæ—T-æ¨¡(t-norms)åœ¨æ¨¡ç³Šå»ºæ¨¡ä¸­åº”ç”¨å¹¿æ³›ï¼Œå¸¸ç”¨äºå®šä¹‰æ¨¡ç³Šé›†åˆçš„äº¤é›†ä¸å¹¶é›†ã€‚æ–‡ç« é¦–å…ˆç ”ç©¶äº†åŸºäºæœ€å¤§Sugeno-Weberåˆæˆ(max-Sugeno-Weber composition)çš„å¯è¡ŒåŸŸè§£æé—®é¢˜ï¼Œå¹¶æå‡ºäº†åˆ¤æ–­å¯è¡Œæ€§çš„å……åˆ†å¿…è¦æ¡ä»¶ã€‚åŸºäºè¯¥é—®é¢˜çš„ç†è®ºç‰¹æ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ç§æ±‚è§£è¯¥éçº¿æ€§ä¼˜åŒ–é—®é¢˜çš„ç®—æ³•ã€‚é€šè¿‡ç†è®ºè¯æ˜ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿæ‰¾åˆ°ç²¾ç¡®çš„æœ€ä¼˜è§£ï¼Œå¹¶é€šè¿‡å…·ä½“æ•°å€¼ç®—ä¾‹éªŒè¯äº†è¯¥ç®—æ³•çš„æœ‰æ•ˆæ€§ä¸å¯è¡Œæ€§ã€‚",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "9 pages, 1 numerical example, presented at 17th International Conference on Information Technology, Computer and Telecommunication (ITCTC), Poland, December 2022",
      "pdf_url": "https://arxiv.org/pdf/2509.12669v1",
      "published_date": "2025-09-16 04:48:06 UTC",
      "updated_date": "2025-09-16 04:48:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:01:46.368972+00:00"
    },
    {
      "arxiv_id": "2509.13372v1",
      "title": "Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging",
      "title_zh": "é’ˆå¯¹å¢å¼º X å°„çº¿é€è§†æˆåƒä¸­ Fontan å‡ ä½•ç»“æ„çš„äº¤äº’å¼æç¤ºé©±åŠ¨ 2D åˆ° 3D è¡€ç®¡é‡å»ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½æµæ°´çº¿",
      "authors": [
        "Prahlad G Menon"
      ],
      "abstract": "Fontan palliation for univentricular congenital heart disease progresses to hemodynamic failure with complex flow patterns poorly characterized by conventional 2D imaging. Current assessment relies on fluoroscopic angiography, providing limited 3D geometric information essential for computational fluid dynamics (CFD) analysis and surgical planning.\n  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash (2.5B parameters) for systematic, iterative processing of fluoroscopic angiograms through transformer-based neural architecture. The pipeline encompasses medical image preprocessing, vascular segmentation, contrast enhancement, artifact removal, and virtual hemodynamic flow visualization within 2D projections. Final views were processed through Tencent's Hunyuan3D-2mini (384M parameters) for stereolithography file generation.\n  The pipeline successfully generated geometrically optimized 2D projections from single-view angiograms after 16 processing steps using a custom web interface. Initial iterations contained hallucinated vascular features requiring iterative refinement to achieve anatomically faithful representations. Final projections demonstrated accurate preservation of complex Fontan geometry with enhanced contrast suitable for 3D conversion. AI-generated virtual flow visualization identified stagnation zones in central connections and flow patterns in branch arteries. Complete processing required under 15 minutes with second-level API response times.\n  This approach demonstrates clinical feasibility of generating CFD-suitable geometries from routine angiographic data, enabling 3D generation and rapid virtual flow visualization for cursory insights prior to full CFD simulation. While requiring refinement cycles for accuracy, this establishes foundation for democratizing advanced geometric and hemodynamic analysis using readily available imaging data.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§å¤šæ­¥ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æµæ°´çº¿(Generative AI Pipeline)ï¼Œæ—¨åœ¨é€šè¿‡æç¤ºé©±åŠ¨çš„æ–¹å¼å°†å•è§†å›¾å¯¹æ¯”å¢å¼ºXå°„çº¿è§å…‰é€è§†å½±åƒ(Contrast-Enhanced X-Ray Fluoroscopy)è½¬æ¢ä¸ºFontanå¿ƒè„å‡ ä½•ç»“æ„çš„3Dæ¨¡å‹ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨Gemini 2.5 Flashè¿›è¡Œå›¾åƒé¢„å¤„ç†ã€è¡€ç®¡åˆ†å‰²ã€å¯¹æ¯”åº¦å¢å¼ºåŠè™šæ‹Ÿè¡€æµå¯è§†åŒ–(virtual hemodynamic flow visualization)ï¼Œå¹¶ç»“åˆHunyuan3D-2miniç”Ÿæˆç”¨äº3Dæ‰“å°çš„ç«‹ä½“å…‰åˆ»æ–‡ä»¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æµæ°´çº¿èƒ½å¤Ÿåœ¨15åˆ†é’Ÿå†…å®Œæˆå¤„ç†ï¼Œé€šè¿‡16ä¸ªè¿­ä»£æ­¥éª¤æœ‰æ•ˆå…‹æœäº†åˆå§‹é˜¶æ®µçš„å¹»è§‰é—®é¢˜ï¼Œç”Ÿæˆäº†å…·æœ‰è§£å‰–å­¦ä¿çœŸåº¦çš„å‡ ä½•ç»“æ„ã€‚ç ”ç©¶æˆåŠŸè¯†åˆ«äº†ä¸­å¿ƒè¿æ¥å¤„çš„åœæ»åŒºå’Œåˆ†æ”¯åŠ¨è„‰çš„è¡€æµæ¨¡å¼ï¼ŒéªŒè¯äº†ä»å¸¸è§„è¡€ç®¡é€ å½±æ•°æ®ç”Ÿæˆè®¡ç®—æµä½“åŠ›å­¦(CFD)é€‚ç”¨å‡ ä½•ç»“æ„çš„ä¸´åºŠå¯è¡Œæ€§ã€‚è¿™ä¸€æˆæœä¸ºåœ¨è¿›è¡Œå®Œæ•´æ•°å€¼æ¨¡æ‹Ÿå‰å®ç°å¿«é€Ÿã€å¯åŠçš„å‡ ä½•ä¸è¡€æ¶²åŠ¨åŠ›å­¦åˆ†æå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.13372v1",
      "published_date": "2025-09-16 04:47:25 UTC",
      "updated_date": "2025-09-16 04:47:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:01.659221+00:00"
    },
    {
      "arxiv_id": "2509.12658v2",
      "title": "Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI",
      "title_zh": "é¢å‘éšå¼CSIä¸‹RISè¾…åŠ©æ¯«ç±³æ³¢MIMOç³»ç»Ÿçš„å¯æŒç»­LSTMé¢„ç¼–ç ",
      "authors": [
        "Po-Heng Chou",
        "Jiun-Jia Wu",
        "Wan-Jen Huang",
        "Ronald Y. Chang"
      ],
      "abstract": "In this paper, we propose a sustainable long short-term memory (LSTM)-based precoding framework for reconfigurable intelligent surface (RIS)-assisted millimeter-wave (mmWave) MIMO systems. Instead of explicit channel state information (CSI) estimation, the framework exploits uplink pilot sequences to implicitly learn channel characteristics, reducing both pilot overhead and inference complexity. Practical hardware constraints are addressed by incorporating the phase-dependent amplitude model of RIS elements, while a multi-label training strategy improves robustness when multiple near-optimal codewords yield comparable performance. Simulations show that the proposed design achieves over 90% of the spectral efficiency of exhaustive search (ES) with only 2.2% of its computation time, cutting energy consumption by nearly two orders of magnitude. The method also demonstrates resilience under distribution mismatch and scalability to larger RIS arrays, making it a practical and energy-efficient solution for sustainable 6G wireless networks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯é‡æ„æ™ºèƒ½è¡¨é¢ (RIS) è¾…åŠ©çš„æ¯«ç±³æ³¢ (mmWave) å¤šè¾“å…¥å¤šè¾“å‡º (MIMO) ç³»ç»Ÿï¼Œæå‡ºäº†ä¸€ç§åŸºäºé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) çš„å¯æŒç»­é¢„ç¼–ç æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸Šè¡Œé“¾è·¯å¯¼é¢‘åºåˆ—éšå¼åœ°å­¦ä¹ ä¿¡é“ç‰¹å¾ï¼Œæ— éœ€è¿›è¡Œæ˜¾å¼çš„ä¿¡é“çŠ¶æ€ä¿¡æ¯ (CSI) ä¼°è®¡ï¼Œä»è€Œæœ‰æ•ˆé™ä½äº†å¯¼é¢‘å¼€é”€å’Œæ¨ç†å¤æ‚åº¦ã€‚åœ¨è®¾è®¡ä¸­ï¼Œè¯¥æ–¹æ¡ˆå……åˆ†è€ƒè™‘äº† RIS å…ƒä»¶ç›¸ä½ç›¸å…³çš„æŒ¯å¹…æ¨¡å‹ç­‰å®é™…ç¡¬ä»¶çº¦æŸï¼Œå¹¶å¼•å…¥å¤šæ ‡ç­¾è®­ç»ƒç­–ç•¥ä»¥å¢å¼ºç³»ç»Ÿé²æ£’æ€§ã€‚ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä»…æ¶ˆè€—ç©·ä¸¾æœç´¢ (ES) ç®—æ³• 2.2% è®¡ç®—æ—¶é—´çš„å‰æä¸‹ï¼Œè¾¾åˆ°äº†å…¶ 90% ä»¥ä¸Šçš„å…‰è°±æ•ˆç‡ï¼Œå¹¶å°†èƒ½è€—é™ä½äº†è¿‘ä¸¤ä¸ªæ•°é‡çº§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆåœ¨åˆ†å¸ƒå¤±é…å’Œæ›´å¤§è§„æ¨¡ RIS é˜µåˆ—ä¸‹å±•ç°äº†å‡ºè‰²çš„å¼¹æ€§ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºå¯æŒç»­ 6G æ— çº¿ç½‘ç»œæä¾›äº†ä¸€ç§å®ç”¨ä¸”èŠ‚èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 5 figures, 2 tables, and accepted by 2025 IEEE Globecom Workshops",
      "pdf_url": "https://arxiv.org/pdf/2509.12658v2",
      "published_date": "2025-09-16 04:29:14 UTC",
      "updated_date": "2025-10-08 06:53:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:03.270583+00:00"
    },
    {
      "arxiv_id": "2509.12653v1",
      "title": "Beyond Artificial Misalignment: Detecting and Grounding Semantic-Coordinated Multimodal Manipulations",
      "title_zh": "è¶…è¶Šäººä¸ºå¤±é…ï¼šè¯­ä¹‰ååŒå¤šæ¨¡æ€ç¯¡æ”¹çš„æ£€æµ‹ä¸å®šä½",
      "authors": [
        "Jinjie Shen",
        "Yaxiong Wang",
        "Lechao Cheng",
        "Nan Pu",
        "Zhun Zhong"
      ],
      "abstract": "The detection and grounding of manipulated content in multimodal data has emerged as a critical challenge in media forensics. While existing benchmarks demonstrate technical progress, they suffer from misalignment artifacts that poorly reflect real-world manipulation patterns: practical attacks typically maintain semantic consistency across modalities, whereas current datasets artificially disrupt cross-modal alignment, creating easily detectable anomalies. To bridge this gap, we pioneer the detection of semantically-coordinated manipulations where visual edits are systematically paired with semantically consistent textual descriptions. Our approach begins with constructing the first Semantic-Aligned Multimodal Manipulation (SAMM) dataset, generated through a two-stage pipeline: 1) applying state-of-the-art image manipulations, followed by 2) generation of contextually-plausible textual narratives that reinforce the visual deception. Building on this foundation, we propose a Retrieval-Augmented Manipulation Detection and Grounding (RamDG) framework. RamDG commences by harnessing external knowledge repositories to retrieve contextual evidence, which serves as the auxiliary texts and encoded together with the inputs through our image forgery grounding and deep manipulation detection modules to trace all manipulations. Extensive experiments demonstrate our framework significantly outperforms existing methods, achieving 2.06\\% higher detection accuracy on SAMM compared to state-of-the-art approaches. The dataset and code are publicly available at https://github.com/shen8424/SAMM-RamDG-CAP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åª’ä½“å–è¯(Media Forensics)åŸºå‡†æµ‹è¯•ä¸­äººå·¥å¯¹é½åå·®(Artificial Misalignment)æ— æ³•åæ˜ çœŸå®ä¸–ç•Œè¯­ä¹‰ä¸€è‡´ç¯¡æ”¹çš„é—®é¢˜ï¼Œé¦–åˆ›äº†è¯­ä¹‰å¯¹é½å¤šæ¨¡æ€ç¯¡æ”¹(Semantic-Aligned Multimodal Manipulation, SAMM)æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†é€šè¿‡ä¸¤é˜¶æ®µæµæ°´çº¿å°†è§†è§‰ç¼–è¾‘ä¸è¯­ä¹‰ä¸€è‡´çš„æ–‡æœ¬å™è¿°ç›¸ç»“åˆï¼Œæ—¨åœ¨æ¨¡æ‹Ÿæ›´å…·æŒ‘æˆ˜æ€§çš„å®é™…æ”»å‡»åœºæ™¯ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†æ£€ç´¢å¢å¼ºç¯¡æ”¹æ£€æµ‹ä¸å®šä½(Retrieval-Augmented Manipulation Detection and Grounding, RamDG)æ¡†æ¶ï¼Œåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢èƒŒæ™¯è¯æ®ã€‚è¯¥æ¡†æ¶é€šè¿‡å›¾åƒä¼ªé€ å®šä½(Image Forgery Grounding)å’Œæ·±åº¦ç¯¡æ”¹æ£€æµ‹(Deep Manipulation Detection)æ¨¡å—å¯¹è¾“å…¥è¿›è¡ŒååŒç¼–ç ï¼Œä»è€Œå®ç°å¯¹ç¯¡æ”¹ç—•è¿¹çš„ç²¾å‡†è¿½è¸ªã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRamDG åœ¨ SAMM æ•°æ®é›†ä¸Šçš„æ£€æµ‹å‡†ç¡®ç‡æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æé«˜äº† 2.06%ï¼Œä¸ºåº”å¯¹å¤æ‚çš„è¯­ä¹‰åè°ƒå¤šæ¨¡æ€æ“çºµæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12653v1",
      "published_date": "2025-09-16 04:18:48 UTC",
      "updated_date": "2025-09-16 04:18:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:08.363234+00:00"
    },
    {
      "arxiv_id": "2509.12652v1",
      "title": "Don't Change My View: Ideological Bias Auditing in Large Language Models",
      "title_zh": "Don't Change My Viewï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ„è¯†å½¢æ€åè§å®¡è®¡",
      "authors": [
        "Paul KrÃ¶ger",
        "Emilio Barkett"
      ],
      "abstract": "As large language models (LLMs) become increasingly embedded in products used by millions, their outputs may influence individual beliefs and, cumulatively, shape public opinion. If the behavior of LLMs can be intentionally steered toward specific ideological positions, such as political or religious views, then those who control these systems could gain disproportionate influence over public discourse. Although it remains an open question whether LLMs can reliably be guided toward coherent ideological stances and whether such steering can be effectively prevented, a crucial first step is to develop methods for detecting when such steering attempts occur. In this work, we adapt a previously proposed statistical method to the new context of ideological bias auditing. Our approach carries over the model-agnostic design of the original framework, which does not require access to the internals of the language model. Instead, it identifies potential ideological steering by analyzing distributional shifts in model outputs across prompts that are thematically related to a chosen topic. This design makes the method particularly suitable for auditing proprietary black-box systems. We validate our approach through a series of experiments, demonstrating its practical applicability and its potential to support independent post hoc audits of LLM behavior.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¯èƒ½å¯¹ä¸ªäººä¿¡ä»°å’Œå…¬ä¼—èˆ†è®ºäº§ç”Ÿæ½œåœ¨å½±å“çš„ç°çŠ¶ï¼Œæ¢è®¨äº†å…¶æ„è¯†å½¢æ€ç«‹åœºæ˜¯å¦ä¼šè¢«åˆ»æ„å¼•å¯¼çš„é—®é¢˜ã€‚ä¸ºäº†æœ‰æ•ˆæ£€æµ‹è¿™ç±»å¼•å¯¼è¡Œä¸ºï¼Œä½œè€…æå‡ºå¹¶è°ƒæ•´äº†ä¸€ç§ç»Ÿè®¡å­¦æ–¹æ³•ï¼Œç”¨äºè¿›è¡Œæ„è¯†å½¢æ€åè§å®¡è®¡(ideological bias auditing)ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ¨¡å‹æ— å…³(model-agnostic)çš„è®¾è®¡ï¼Œæ— éœ€è®¿é—®è¯­è¨€æ¨¡å‹çš„å†…éƒ¨å‚æ•°ï¼Œå› æ­¤ç‰¹åˆ«é€‚ç”¨äºå¯¹ç§æœ‰é»‘ç›’ç³»ç»Ÿ(proprietary black-box systems)è¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸ç‰¹å®šä¸»é¢˜ç›¸å…³çš„æç¤ºè¯(prompts)ä¸‹è¾“å‡ºåˆ†å¸ƒçš„åç§»æƒ…å†µï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç²¾å‡†è¯†åˆ«æ½œåœ¨çš„æ„è¯†å½¢æ€å¼•å¯¼è¡Œä¸ºã€‚ä¸€ç³»åˆ—å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å®é™…åº”ç”¨æ½œåŠ›ï¼Œè¯æ˜å…¶èƒ½å¤Ÿä¸ºå¤§æ¨¡å‹è¡Œä¸ºæä¾›æœ‰æ•ˆçš„ç‹¬ç«‹åç»­å®¡è®¡(independent post hoc audits)æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12652v1",
      "published_date": "2025-09-16 04:14:29 UTC",
      "updated_date": "2025-09-16 04:14:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:19.291628+00:00"
    },
    {
      "arxiv_id": "2509.12650v1",
      "title": "Leveraging Intermediate Representations of Time Series Foundation Models for Anomaly Detection",
      "title_zh": "åˆ©ç”¨æ—¶é—´åºåˆ—åŸºåº§æ¨¡å‹çš„ä¸­é—´è¡¨ç¤ºè¿›è¡Œå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Chan Sik Han",
        "Keon Myung Lee"
      ],
      "abstract": "Detecting anomalies in time series data is essential for the reliable operation of many real-world systems. Recently, time series foundation models (TSFMs) have emerged as a powerful tool for anomaly detection. However, existing methods typically rely on the final layer's representations of TSFMs, computing the anomaly score as a reconstruction or forecasting error via a task-specific head. Instead, we propose TimeRep, a novel anomaly detection approach that leverages the intermediate layer's representations of TSFMs, computing the anomaly score as the distance between these representations. Given a pre-trained TSFM, TimeRep selects the intermediate layer and patch-token position that yield the most informative representation. TimeRep forms a reference collection of intermediate representations from the training data and applies a core-set strategy to reduce its size while maintaining distributional coverage. During inference, TimeRep computes the anomaly score for incoming data by measuring the distance between its intermediate representations and those of the collection. To address concept drift, TimeRep integrates an adaptation mechanism that, at inference time, augments the collection exclusively with non-redundant intermediate representations from incoming data. We conducted extensive experiments on the UCR Anomaly Archive, which contains 250 univariate time series. TimeRep consistently outperforms a broad spectrum of state-of-the-art baselines, including non-DL, DL, and foundation model-based methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ï¼ˆAnomaly Detectionï¼‰ä¸­ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆTSFMsï¼‰æœ€ç»ˆå±‚è¡¨ç¤ºçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º TimeRep çš„åˆ›æ–°æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿè®¡ç®—é‡æ„æˆ–é¢„æµ‹è¯¯å·®çš„æ–¹å¼ä¸åŒï¼ŒTimeRep ç›´æ¥åˆ©ç”¨ TSFMs çš„ä¸­é—´å±‚è¡¨ç¤ºï¼Œå¹¶å°†å¼‚å¸¸è¯„åˆ†å®šä¹‰ä¸ºå¾…æµ‹æ•°æ®ä¸å‚è€ƒé›†è¡¨ç¤ºä¹‹é—´çš„è·ç¦»ã€‚è¯¥æ–¹æ³•é€šè¿‡é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„ä¸­é—´å±‚åŠè¡¥ä¸æ ‡è®°ä½ç½®ï¼ˆpatch-token positionï¼‰ï¼Œå¹¶ç»“åˆæ ¸å¿ƒé›†ç­–ç•¥ï¼ˆcore-set strategyï¼‰åœ¨ä¿æŒåˆ†å¸ƒè¦†ç›–çš„åŒæ—¶ä¼˜åŒ–å‚è€ƒé›†åˆçš„è§„æ¨¡ã€‚é’ˆå¯¹æ¦‚å¿µæ¼‚ç§»ï¼ˆconcept driftï¼‰é—®é¢˜ï¼ŒTimeRep å¼•å…¥äº†åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†é˜¶æ®µåŠ¨æ€æ›´æ–°éå†—ä½™çš„ä¸­é—´è¡¨ç¤ºã€‚åœ¨åŒ…å« 250 ä¸ªå•å˜é‡æ—¶é—´åºåˆ—çš„ UCR Anomaly Archive æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTimeRep çš„æ€§èƒ½å…¨é¢è¶…è¶Šäº†éæ·±åº¦å­¦ä¹ ï¼ˆnon-DLï¼‰ã€æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰åŠå…¶ä»–åŸºäºåŸºç¡€æ¨¡å‹çš„å…ˆè¿›åŸºå‡†æ–¹æ³•ã€‚è¿™ä¸€ç ”ç©¶è¯æ˜äº†æŒ–æ˜åŸºç¡€æ¨¡å‹å†…éƒ¨ä¸­é—´è¡¨å¾åœ¨æå‡å¼‚å¸¸æ£€æµ‹å‡†ç¡®æ€§ä¸é²æ£’æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12650v1",
      "published_date": "2025-09-16 04:10:17 UTC",
      "updated_date": "2025-09-16 04:10:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:13.163522+00:00"
    },
    {
      "arxiv_id": "2509.12649v1",
      "title": "A Systematic Evaluation of Parameter-Efficient Fine-Tuning Methods for the Security of Code LLMs",
      "title_zh": "é’ˆå¯¹ä»£ç å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•çš„ç³»ç»Ÿè¯„ä¼°",
      "authors": [
        "Kiho Lee",
        "Jungkon Kim",
        "Doowon Kim",
        "Hyoungshick Kim"
      ],
      "abstract": "Code-generating Large Language Models (LLMs) significantly accelerate software development. However, their frequent generation of insecure code presents serious risks. We present a comprehensive evaluation of seven parameter-efficient fine-tuning (PEFT) techniques, demonstrating substantial gains in secure code generation without compromising functionality. Our research identifies prompt-tuning as the most effective PEFT method, achieving an 80.86% Overall-Secure-Rate on CodeGen2 16B, a 13.5-point improvement over the 67.28% baseline. Optimizing decoding strategies through sampling temperature further elevated security to 87.65%. This equates to a reduction of approximately 203,700 vulnerable code snippets per million generated. Moreover, prompt and prefix tuning increase robustness against poisoning attacks in our TrojanPuzzle evaluation, with strong performance against CWE-79 and CWE-502 attack vectors. Our findings generalize across Python and Java, confirming prompt-tuning's consistent effectiveness. This study provides essential insights and practical guidance for building more resilient software systems with LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»£ç ç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹(Code LLMs)ç”Ÿæˆçš„ä»£ç å®‰å…¨æ€§ä¸è¶³è¿™ä¸€é£é™©ï¼Œç³»ç»Ÿè¯„ä¼°äº†ä¸ƒç§å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æŠ€æœ¯åœ¨æå‡ä»£ç å®‰å…¨æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPrompt-tuning è¢«ç¡®å®šä¸ºæœ€æœ‰æ•ˆçš„ PEFT æ–¹æ³•ï¼Œåœ¨ CodeGen2 16B æ¨¡å‹ä¸Šå®ç°äº† 80.86% çš„ Overall-Secure-Rateï¼Œè¾ƒåŸºå‡†æ˜¾è‘—æå‡ã€‚é€šè¿‡è¿›ä¸€æ­¥ä¼˜åŒ–è§£ç è¿‡ç¨‹ä¸­çš„é‡‡æ ·æ¸©åº¦(Sampling temperature)ï¼Œå®‰å…¨æ€§æœ€é«˜å¯è¾¾ 87.65%ï¼Œç­‰åŒäºæ¯ç™¾ä¸‡è¡Œä»£ç å‡å°‘äº†çº¦ 20.37 ä¸‡ä¸ªæ¼æ´ç‰‡æ®µã€‚æ­¤å¤–ï¼ŒPrompt-tuning å’Œ Prefix-tuning åœ¨ TrojanPuzzle è¯„ä¼°ä¸­å±•ç°äº†å¯¹ä¸­æ¯’æ”»å‡»(Poisoning attacks)æ›´å¼ºçš„é²æ£’æ€§ï¼Œèƒ½æœ‰æ•ˆæŠµå¾¡ CWE-79 å’Œ CWE-502 ç­‰æ”»å‡»å‘é‡ã€‚è¯¥ç ”ç©¶éªŒè¯äº†ä¸Šè¿°æ–¹æ³•åœ¨ Python å’Œ Java è¯­è¨€ä¸­çš„æ³›åŒ–æ€§ï¼Œä¸ºåˆ©ç”¨ LLMs æ„å»ºæ›´å…·éŸ§æ€§çš„è½¯ä»¶ç³»ç»Ÿæä¾›äº†å…³é”®è§è§£å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "25 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.12649v1",
      "published_date": "2025-09-16 04:09:41 UTC",
      "updated_date": "2025-09-16 04:09:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:18.796133+00:00"
    },
    {
      "arxiv_id": "2509.12645v1",
      "title": "Large Language Models Imitate Logical Reasoning, but at what Cost?",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ¨¡ä»¿é€»è¾‘æ¨ç†ï¼Œä»£ä»·å‡ ä½•ï¼Ÿ",
      "authors": [
        "Lachlan McGinness",
        "Peter Baumgartner"
      ],
      "abstract": "We present a longitudinal study which evaluates the reasoning capability of frontier Large Language Models over an eighteen month period. We measured the accuracy of three leading models from December 2023, September 2024 and June 2025 on true or false questions from the PrOntoQA dataset and their faithfulness to reasoning strategies provided through in-context learning. The improvement in performance from 2023 to 2024 can be attributed to hidden Chain of Thought prompting. The introduction of thinking models allowed for significant improvement in model performance between 2024 and 2025.\n  We then present a neuro-symbolic architecture which uses LLMs of less than 15 billion parameters to translate the problems into a standardised form. We then parse the standardised forms of the problems into a program to be solved by Z3, an SMT solver, to determine the satisfiability of the query. We report the number of prompt and completion tokens as well as the computational cost in FLOPs for open source models. The neuro-symbolic approach significantly reduces the computational cost while maintaining near perfect performance. The common approximation that the number of inference FLOPs is double the product of the active parameters and total tokens was accurate within 10\\% for all experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹2023å¹´12æœˆè‡³2025å¹´6æœˆæœŸé—´çš„å‰æ²¿å¤§è¯­è¨€æ¨¡å‹(Large Language Models)è¿›è¡Œçºµå‘ç ”ç©¶ï¼Œè¯„ä¼°äº†å®ƒä»¬åœ¨PrOntoQAæ•°æ®é›†ä¸Šçš„é€»è¾‘æ¨ç†èƒ½åŠ›åŠå…¶å¯¹æ¨ç†ç­–ç•¥çš„å¿ è¯šåº¦ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œæ¨¡å‹æ€§èƒ½åœ¨2023è‡³2024å¹´é—´çš„æå‡ä¸»è¦å½’å› äºéšè—çš„é“¾å¼æ€ç»´(Chain of Thought)æç¤ºï¼Œè€Œ2025å¹´å¼•å…¥çš„â€œæ€ç»´æ¨¡å‹(thinking models)â€åˆ™å¸¦æ¥äº†æ›´æ˜¾è‘—çš„è¡¨ç°æå‡ã€‚é’ˆå¯¹æ¨ç†è¿‡ç¨‹çš„é«˜æ˜‚ä»£ä»·ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·(neuro-symbolic)æ¶æ„ï¼Œåˆ©ç”¨å‚æ•°é‡å°äº15Bçš„æ¨¡å‹å°†é€»è¾‘é—®é¢˜è½¬åŒ–ä¸ºæ ‡å‡†åŒ–å½¢å¼ï¼Œå¹¶äº¤ç”±Z3æ±‚è§£å™¨(SMT solver)è¿›è¡Œç¨‹åºåŒ–æ±‚è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§ç¥ç»ç¬¦å·æ–¹æ³•åœ¨ä¿æŒè¿‘ä¹å®Œç¾å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½äº†è®¡ç®—æˆæœ¬(FLOPs)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡å¯¹æç¤ºè¯å’Œè¡¥å…¨Tokençš„è¯¦ç»†è®°å½•ï¼ŒéªŒè¯äº†æ¨ç†FLOPsçº¦ä¸ºæ¿€æ´»å‚æ•°é‡ä¸æ€»Tokenæ•°ä¹˜ç§¯ä¸¤å€çš„ç»éªŒå…¬å¼ï¼Œä¸”è¯¯å·®æ§åˆ¶åœ¨10%ä»¥å†…ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been accepted as a main track paper for publication in the proceedings of the Australasian Joint Conference on Artificial Intelligence 2025 held in Canberra, Australia",
      "pdf_url": "https://arxiv.org/pdf/2509.12645v1",
      "published_date": "2025-09-16 04:03:42 UTC",
      "updated_date": "2025-09-16 04:03:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:22.185248+00:00"
    },
    {
      "arxiv_id": "2509.12643v2",
      "title": "Learn to Relax with Large Language Models: Solving Nonlinear Combinatorial Optimization Problems via Bidirectional Coevolution",
      "title_zh": "ååŒå¤§è¯­è¨€æ¨¡å‹å­¦ä¹ çº¦æŸæ¾å¼›ï¼šé€šè¿‡åŒå‘ååŒæ¼”åŒ–æ±‚è§£éçº¿æ€§ç»„åˆä¼˜åŒ–é—®é¢˜",
      "authors": [
        "Beidan Liu",
        "Zhengqiu Zhu",
        "Chen Gao",
        "Yong Zhao",
        "Wei Qi",
        "Quanjun Yin"
      ],
      "abstract": "Nonlinear Combinatorial Optimization Problems (NCOPs) present a formidable computational hurdle in practice, as their nonconvex nature gives rise to multi-modal solution spaces that defy efficient optimization. Traditional constraint relaxation approaches rely heavily on expert-driven, iterative design processes that lack systematic automation and scalable adaptability. While recent Large Language Model (LLM)-based optimization methods show promise for autonomous problem-solving, they predominantly function as passive constraint validators rather than proactive strategy architects, failing to handle the sophisticated constraint interactions inherent to NCOPs.To address these limitations, we introduce the first end-to-end \\textbf{Auto}mated \\textbf{C}onstraint \\textbf{O}ptimization (AutoCO) method, which revolutionizes NCOPs resolution through learning to relax with LLMs.Specifically, we leverage structured LLM reasoning to generate constraint relaxation strategies, which are dynamically evolving with algorithmic principles and executable code through a unified triple-representation scheme. We further establish a novel bidirectional (global-local) coevolution mechanism that synergistically integrates Evolutionary Algorithms for intensive local refinement with Monte Carlo Tree Search for systematic global strategy space exploration, ensuring optimal balance between intensification and diversification in fragmented solution spaces. Finally, comprehensive experiments on three challenging NCOP benchmarks validate AutoCO's consistent effectiveness and superior performance over the baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éçº¿æ€§ç»„åˆä¼˜åŒ–é—®é¢˜(NCOPs)åœ¨å¤šå³°è§£ç©ºé—´ä¸­éš¾ä»¥é«˜æ•ˆä¼˜åŒ–ï¼Œä¸”ä¼ ç»Ÿçº¦æŸæ¾å¼›æ–¹æ³•è¿‡åº¦ä¾èµ–ä¸“å®¶ç»éªŒè€Œç¼ºä¹è‡ªåŠ¨åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–çº¦æŸä¼˜åŒ–æ–¹æ³•AutoCOã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç»“æ„åŒ–æ¨ç†ç”Ÿæˆçº¦æŸæ¾å¼›ç­–ç•¥ï¼Œå¹¶é€šè¿‡èåˆç®—æ³•åŸç†ä¸æ‰§è¡Œä»£ç çš„ç»Ÿä¸€ä¸‰å…ƒè¡¨ç¤ºæ–¹æ¡ˆå®ç°ç­–ç•¥çš„åŠ¨æ€æ¼”åŒ–ã€‚ç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†ä¸€ç§åŒå‘(global-local)ååŒæ¼”åŒ–æœºåˆ¶ï¼Œå°†ç”¨äºå±€éƒ¨ç²¾ç»†åŒ–çš„Evolutionary Algorithmsä¸ç”¨äºå…¨å±€ç­–ç•¥ç©ºé—´æ¢ç´¢çš„Monte Carlo Tree Searchç›¸ç»“åˆï¼Œç¡®ä¿äº†åœ¨å¤æ‚è§£ç©ºé—´æœç´¢ä¸­å¼ºåŒ–ä¸å¤šæ ·æ€§çš„å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAutoCOåœ¨ä¸‰ä¸ªæŒ‘æˆ˜æ€§çš„NCOPåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜äºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨è§£å†³å¤æ‚çº¦æŸäº¤äº’é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "We wish to withdraw this manuscript as we have identified several technical details that require further optimization and refinement. We plan to resubmit an updated version at a later date",
      "pdf_url": "https://arxiv.org/pdf/2509.12643v2",
      "published_date": "2025-09-16 03:59:51 UTC",
      "updated_date": "2025-09-17 06:58:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:24.790790+00:00"
    },
    {
      "arxiv_id": "2509.12635v2",
      "title": "Positional Encoding via Token-Aware Phase Attention",
      "title_zh": "åŸºäº Token æ„ŸçŸ¥ç›¸ä½æ³¨æ„åŠ›çš„ä½ç½®ç¼–ç ",
      "authors": [
        "Yu Wang",
        "Sheng Shen",
        "RÃ©mi Munos",
        "Hongyuan Zhan",
        "Yuandong Tian"
      ],
      "abstract": "We prove under practical assumptions that Rotary Positional Embedding (RoPE) introduces an intrinsic distance-dependent bias in attention scores that limits RoPE's ability to model long-context. RoPE extension methods may alleviate this issue, but they typically require post-hoc adjustments after pretraining, such as rescaling or hyperparameters retuning. This paper introduces Token-Aware Phase Attention (TAPA), a new positional encoding method that incorporates a learnable phase function into the attention mechanism. TAPA preserves token interactions over long range, extends to longer contexts with direct and light fine-tuning, extrapolates to unseen lengths, and attains significantly lower perplexity on long-context than RoPE families.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯æ˜äº†æ—‹è½¬ä½ç½®åµŒå…¥(Rotary Positional Embedding, RoPE)åœ¨å®é™…å‡è®¾ä¸‹ä¼šå¼•å…¥ä¸è·ç¦»ç›¸å…³çš„å›ºæœ‰åå·®ï¼Œä»è€Œé™åˆ¶äº†å…¶é•¿æ–‡æœ¬å»ºæ¨¡èƒ½åŠ›ã€‚è™½ç„¶ç°æœ‰çš„RoPEæ‰©å±•æ–¹æ³•å¯ä»¥ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†é€šå¸¸éœ€è¦å¤æ‚çš„åæœŸè°ƒæ•´æˆ–è¶…å‚æ•°å¾®è°ƒã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä»¤ç‰Œæ„ŸçŸ¥ç›¸ä½æ³¨æ„åŠ›(Token-Aware Phase Attention, TAPA)ï¼Œè¿™æ˜¯ä¸€ç§å°†å¯å­¦ä¹ ç›¸ä½å‡½æ•°(learnable phase function)å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„æ–°å‹ä½ç½®ç¼–ç æ–¹æ³•ã€‚TAPAèƒ½å¤Ÿåœ¨é•¿è·ç¦»èŒƒå›´å†…ä¿æŒä»¤ç‰Œäº¤äº’ï¼Œä»…éœ€è½»é‡çº§å¾®è°ƒå³å¯æ‰©å±•è‡³æ›´é•¿ä¸Šä¸‹æ–‡ï¼Œå¹¶å…·å¤‡å‡ºè‰²çš„é•¿åº¦å¤–æ¨èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒTAPAåœ¨é•¿æ–‡æœ¬ä¸‹çš„å›°æƒ‘åº¦(perplexity)æ˜¾è‘—ä½äºRoPEç³»åˆ—ï¼Œå±•ç¤ºäº†å…¶åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.12635v2",
      "published_date": "2025-09-16 03:53:32 UTC",
      "updated_date": "2025-09-25 21:11:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:32.692295+00:00"
    },
    {
      "arxiv_id": "2509.12633v1",
      "title": "CIARD: Cyclic Iterative Adversarial Robustness Distillation",
      "title_zh": "CIARDï¼šå¾ªç¯è¿­ä»£å¯¹æŠ—é²æ£’æ€§è’¸é¦",
      "authors": [
        "Liming Lu",
        "Shuchao Pang",
        "Xu Zheng",
        "Xiang Gu",
        "Anan Du",
        "Yunhuai Liu",
        "Yongbin Zhou"
      ],
      "abstract": "Adversarial robustness distillation (ARD) aims to transfer both performance and robustness from teacher model to lightweight student model, enabling resilient performance on resource-constrained scenarios. Though existing ARD approaches enhance student model's robustness, the inevitable by-product leads to the degraded performance on clean examples. We summarize the causes of this problem inherent in existing methods with dual-teacher framework as: 1. The divergent optimization objectives of dual-teacher models, i.e., the clean and robust teachers, impede effective knowledge transfer to the student model, and 2. The iteratively generated adversarial examples during training lead to performance deterioration of the robust teacher model. To address these challenges, we propose a novel Cyclic Iterative ARD (CIARD) method with two key innovations: a. A multi-teacher framework with contrastive push-loss alignment to resolve conflicts in dual-teacher optimization objectives, and b. Continuous adversarial retraining to maintain dynamic teacher robustness against performance degradation from the varying adversarial examples. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that CIARD achieves remarkable performance with an average 3.53 improvement in adversarial defense rates across various attack scenarios and a 5.87 increase in clean sample accuracy, establishing a new benchmark for balancing model robustness and generalization. Our code is available at https://github.com/eminentgu/CIARD",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CIARDï¼ˆCyclic Iterative Adversarial Robustness Distillationï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¯¹æŠ—é²æ£’æ€§è’¸é¦ (Adversarial Robustness Distillation, ARD) ä¸­è½»é‡åŒ–å­¦ç”Ÿæ¨¡å‹åœ¨å¹²å‡€æ ·æœ¬ä¸Šæ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰åŒæ•™å¸ˆæ¡†æ¶çš„ä¼˜åŒ–ç›®æ ‡å†²çªä»¥åŠé²æ£’æ•™å¸ˆæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§èƒ½é€€åŒ–æ˜¯ä¸»è¦ç—‡ç»“ã€‚ä¸ºæ­¤ï¼ŒCIARDå¼•å…¥äº†å…·æœ‰å¯¹æ¯”æ¨åŠ›æŸå¤±å¯¹é½ (contrastive push-loss alignment) çš„å¤šæ•™å¸ˆæ¡†æ¶ï¼Œæœ‰æ•ˆåŒ–è§£äº†ä¸åŒæ•™å¸ˆé—´çš„ä¼˜åŒ–ç›®æ ‡å†²çªã€‚åŒæ—¶ï¼Œé€šè¿‡æŒç»­å¯¹æŠ—å†è®­ç»ƒ (Continuous adversarial retraining) æœºåˆ¶ï¼Œç ”ç©¶ç¡®ä¿äº†æ•™å¸ˆæ¨¡å‹åœ¨é¢å¯¹åŠ¨æ€ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ—¶èƒ½ç»´æŒç¨³å®šçš„é²æ£’æ€§ã€‚åœ¨CIFAR-10ã€CIFAR-100åŠTiny-ImageNetä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCIARDåœ¨æå‡å¯¹æŠ—é˜²å¾¡ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†å¹²å‡€æ ·æœ¬çš„å‡†ç¡®ç‡ï¼Œä¸ºå¹³è¡¡æ¨¡å‹çš„é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›æä¾›äº†æ–°çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12633v1",
      "published_date": "2025-09-16 03:51:43 UTC",
      "updated_date": "2025-09-16 03:51:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:34.285826+00:00"
    },
    {
      "arxiv_id": "2510.21717v1",
      "title": "AI-Enhanced Operator Assistance for UNICOS Applications",
      "title_zh": "é’ˆå¯¹ UNICOS åº”ç”¨çš„ AI å¢å¼ºå‹æ“ä½œå‘˜è¾…åŠ©",
      "authors": [
        "Bernard Tam",
        "Jean-Charles Tournier",
        "Fernando Varela Rodriguez"
      ],
      "abstract": "This project explores the development of an AI-enhanced operator assistant for UNICOS, CERN's UNified Industrial Control System. While powerful, UNICOS presents a number of challenges, including the cognitive burden of decoding widgets, manual effort required for root cause analysis, and difficulties maintainers face in tracing datapoint elements (DPEs) across a complex codebase. In situations where timely responses are critical, these challenges can increase cognitive load and slow down diagnostics. To address these issues, a multi-agent system was designed and implemented. The solution is supported by a modular architecture comprising a UNICOS-side extension written in CTRL code, a Python-based multi-agent system deployed on a virtual machine, and a vector database storing both operator documentation and widget animation code. Preliminary evaluations suggest that the system is capable of decoding widgets, performing root cause analysis by leveraging live device data and documentation, and tracing DPEs across a complex codebase. Together, these capabilities reduce the manual workload of operators and maintainers, enhance situational awareness in operations, and accelerate responses to alarms and anomalies. Beyond these immediate gains, this work highlights the potential of introducing multi-modal reasoning and retrieval augmented generation (RAG) into the domain of industrial control. Ultimately, this work represents more than a proof of concept: it provides a basis for advancing intelligent operator interfaces at CERN. By combining modular design, extensibility, and practical AI integration, this project not only alleviates current operator pain points but also points toward broader opportunities for assistive AI in accelerator operations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ CERN çš„ç»Ÿä¸€å·¥ä¸šæ§åˆ¶ç³»ç»Ÿ UNICOS åœ¨ç»„ä»¶è§£ç è®¤çŸ¥è´Ÿæ‹…ã€æ‰‹å·¥æ ¹å› åˆ†æä»¥åŠæ•°æ®ç‚¹å…ƒç´  DPE è¿½è¸ªæ–¹é¢çš„æŒ‘æˆ˜ï¼Œå¼€å‘äº†ä¸€å¥— AI å¢å¼ºå‹æ“ä½œå‘˜è¾…åŠ©ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œé›†æˆäº†åŸºäº Python çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ Multi-agent system å’Œå­˜å‚¨æ–‡æ¡£ä¸ä»£ç çš„å‘é‡æ•°æ®åº“ Vector databaseã€‚é€šè¿‡å¼•å…¥å¤šæ¨¡æ€æ¨ç† Multi-modal reasoning å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆ RAG æŠ€æœ¯ï¼Œç³»ç»Ÿèƒ½å¤Ÿç»“åˆå®æ—¶è®¾å¤‡æ•°æ®æ‰§è¡Œè‡ªåŠ¨åŒ–çš„æ ¹å› åˆ†æ Root cause analysisã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥è¾…åŠ©å·¥å…·èƒ½æœ‰æ•ˆåœ¨å¤æ‚ä»£ç åº“ä¸­è¿½è¸ª DPE å¹¶åŠ é€Ÿè­¦æŠ¥å“åº”ï¼Œæ˜¾è‘—å‡è½»äº†æ“ä½œå‘˜çš„æ‰‹åŠ¨å·¥ä½œé‡ã€‚è¿™ä¸€æˆæœä¸ä»…æå‡äº†å·¥ä¸šæ§åˆ¶ç³»ç»Ÿçš„æ€åŠ¿æ„ŸçŸ¥èƒ½åŠ›ï¼Œä¹Ÿä¸ºåœ¨åŠ é€Ÿå™¨è¿è¡Œä¸­å¼•å…¥æ™ºèƒ½åŒ–æ“ä½œç•Œé¢æä¾›äº†å¯æ‰©å±•çš„å®è·µåŸºç¡€ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "Prepared as part of the CERN openlab programme 2025. Also available on Zenodo, a repository operated by CERN and co-funded by the European Union",
      "pdf_url": "https://arxiv.org/pdf/2510.21717v1",
      "published_date": "2025-09-16 03:43:54 UTC",
      "updated_date": "2025-09-16 03:43:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:02:52.396513+00:00"
    },
    {
      "arxiv_id": "2509.12626v1",
      "title": "DoubleAgents: Exploring Mechanisms of Building Trust with Proactive AI",
      "title_zh": "DoubleAgentsï¼šæ¢ç´¢å»ºç«‹ä¸»åŠ¨å‹ AI ä¿¡ä»»çš„æœºåˆ¶",
      "authors": [
        "Tao Long",
        "Xuanming Zhang",
        "Sitong Wang",
        "Zhou Yu",
        "Lydia B Chilton"
      ],
      "abstract": "Agentic workflows promise efficiency, but adoption hinges on whether people actually trust systems that act on their behalf. We present DoubleAgents, an agentic planning tool that embeds transparency and control through user intervention, value-reflecting policies, rich state visualizations, and uncertainty flagging for human coordination tasks. A built-in respondent simulation generates realistic scenarios, allowing users to rehearse, refine policies, and calibrate their reliance before live use. We evaluate DoubleAgents in a two-day lab study (n=10), two deployments (n=2), and a technical evaluation. Results show that participants initially hesitated to delegate but grew more reliant as they experienced transparency, control, and adaptive learning during simulated cases. Deployment results demonstrate DoubleAgents' real-world relevance and usefulness, showing that the effort required scaled appropriately with task complexity and contextual data. We contribute trust-by-design patterns and mechanisms for proactive AI -- consistency, controllability, and explainability -- along with simulation as a safe path to build and calibrate trust over time.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† DoubleAgentsï¼Œè¿™æ˜¯ä¸€æ¬¾æ—¨åœ¨å¢å¼ºç”¨æˆ·å¯¹ä¸»åŠ¨å‹äººå·¥æ™ºèƒ½ (Proactive AI) ä¿¡ä»»çš„æ™ºèƒ½ä½“è§„åˆ’å·¥å…·ã€‚é€šè¿‡åµŒå…¥ç”¨æˆ·å¹²é¢„ (User Intervention)ã€ä»·å€¼åæ˜ ç­–ç•¥ (Value-Reflecting Policies)ã€ä¸°å¯Œçš„çŠ¶æ€å¯è§†åŒ–ä»¥åŠé’ˆå¯¹åè°ƒä»»åŠ¡çš„ä¸ç¡®å®šæ€§æ ‡è®° (Uncertainty Flagging)ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—æå‡äº†é€æ˜åº¦å’Œæ§åˆ¶æ„Ÿã€‚ç³»ç»Ÿå†…ç½®çš„å—è®¿è€…æ¨¡æ‹Ÿ (Respondent Simulation) åŠŸèƒ½å…è®¸ç”¨æˆ·åœ¨å®é™…éƒ¨ç½²å‰è¿›è¡Œæ¼”ç»ƒã€ç»†åŒ–ç­–ç•¥å¹¶æ ¡å‡†ä¿¡ä»»åº¦ï¼Œç¡®ä¿äº†ä½¿ç”¨å‰çš„å®‰å…¨æ€§ã€‚ç ”ç©¶é€šè¿‡å®éªŒå®¤ç ”ç©¶å’Œå®åœ°éƒ¨ç½²å‘ç°ï¼Œç”¨æˆ·è™½ç„¶æœ€åˆå¯¹æˆæƒæŒæœ‰çŠ¹è±«ï¼Œä½†åœ¨ä½“éªŒåˆ°é€æ˜åº¦å’Œè‡ªé€‚åº”å­¦ä¹ åï¼Œå…¶ä¿¡ä»»å’Œä¾èµ–ç¨‹åº¦æ˜¾è‘—æé«˜ã€‚å®éªŒè¿˜è¯æ˜è¯¥å·¥å…·åœ¨ç°å®ä»»åŠ¡ä¸­å…·æœ‰æå¼ºçš„ç›¸å…³æ€§å’Œå®ç”¨æ€§ï¼Œå…¶å·¥ä½œé‡èƒ½éšä»»åŠ¡å¤æ‚åº¦è¿›è¡Œåˆç†æ‰©å±•ã€‚è¯¥å·¥ä½œæœ€ç»ˆè´¡çŒ®äº†åŒ…æ‹¬ä¸€è‡´æ€§ã€å¯æ§æ€§å’Œå¯è§£é‡Šæ€§åœ¨å†…çš„ä¿¡ä»»è®¾è®¡æ¨¡å¼ (Trust-By-Design Patterns)ï¼Œå¹¶éªŒè¯äº†æ¨¡æ‹Ÿæ˜¯æ ¡å‡†é•¿æœŸä¿¡ä»»çš„æœ‰æ•ˆæœºåˆ¶ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12626v1",
      "published_date": "2025-09-16 03:43:13 UTC",
      "updated_date": "2025-09-16 03:43:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:00.298285+00:00"
    },
    {
      "arxiv_id": "2509.12625v1",
      "title": "ECG-aBcDe: Overcoming Model Dependence, Encoding ECG into a Universal Language for Any LLM",
      "title_zh": "ECG-aBcDeï¼šå…‹æœæ¨¡å‹ä¾èµ–ï¼Œå°†å¿ƒç”µå›¾ç¼–ç ä¸ºé€‚é…ä»»æ„å¤§è¯­è¨€æ¨¡å‹çš„é€šç”¨è¯­è¨€",
      "authors": [
        "Yong Xia",
        "Jingxuan Li",
        "YeTeng Sun",
        "Jiarui Bu"
      ],
      "abstract": "Large Language Models (LLMs) hold significant promise for electrocardiogram (ECG) analysis, yet challenges remain regarding transferability, time-scale information learning, and interpretability. Current methods suffer from model-specific ECG encoders, hindering transfer across LLMs. Furthermore, LLMs struggle to capture crucial time-scale information inherent in ECGs due to Transformer limitations. And their black-box nature limits clinical adoption. To address these limitations, we introduce ECG-aBcDe, a novel ECG encoding method that transforms ECG signals into a universal ECG language readily interpretable by any LLM. By constructing a hybrid dataset of ECG language and natural language, ECG-aBcDe enables direct fine-tuning of pre-trained LLMs without architectural modifications, achieving \"construct once, use anywhere\" capability. Moreover, the bidirectional convertibility between ECG and ECG language of ECG-aBcDe allows for extracting attention heatmaps from ECG signals, significantly enhancing interpretability. Finally, ECG-aBcDe explicitly represents time-scale information, mitigating Transformer limitations. This work presents a new paradigm for integrating ECG analysis with LLMs. Compared with existing methods, our method achieves competitive performance on ROUGE-L and METEOR. Notably, it delivers significant improvements in the BLEU-4, with improvements of 2.8 times and 3.9 times in in-dataset and cross-dataset evaluations, respectively, reaching scores of 42.58 and 30.76. These results provide strong evidence for the feasibility of the new paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¿ƒç”µå›¾ï¼ˆECGï¼‰åˆ†æä¸­é¢ä¸´çš„è¿ç§»æ€§ã€æ—¶é—´å°ºåº¦ä¿¡æ¯æ•è·åŠå¯è§£é‡Šæ€§ç­‰ç“¶é¢ˆï¼Œæå‡ºäº†åä¸ºECG-aBcDeçš„æ–°å‹ç¼–ç æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†ECGä¿¡å·è½¬åŒ–ä¸ºä¸€ç§é€šç”¨çš„ECGè¯­è¨€ï¼Œä½¿ä»»ä½•LLMéƒ½èƒ½åœ¨ä¸ä¿®æ”¹æ¶æ„çš„æƒ…å†µä¸‹é€šè¿‡æ··åˆæ•°æ®é›†è¿›è¡Œç›´æ¥å¾®è°ƒï¼Œå®ç°äº†â€œä¸€æ¬¡æ„å»ºï¼Œéšå¤„å¯ç”¨â€çš„è·¨æ¨¡å‹è¿ç§»èƒ½åŠ›ã€‚ECG-aBcDeå…·å¤‡ECGä¿¡å·ä¸è¯­è¨€ä¹‹é—´çš„åŒå‘è½¬æ¢ç‰¹æ€§ï¼Œèƒ½å¤Ÿæå–æ³¨æ„åŠ›çƒ­å›¾ï¼ˆAttention Heatmapsï¼‰ä»¥å¢å¼ºä¸´åºŠå¯è§£é‡Šæ€§ï¼Œå¹¶æ˜¾å¼è¡¨ç¤ºæ—¶é—´å°ºåº¦ä¿¡æ¯ä»¥å¼¥è¡¥Transformerçš„å±€é™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ROUGE-Lå’ŒMETEORæŒ‡æ ‡ä¸Šè¡¨ç°ç¨³å¥ï¼Œä¸”åœ¨BLEU-4æŒ‡æ ‡ä¸Šå®ç°äº†æ˜¾è‘—çªç ´ï¼Œå…¶åœ¨å†…éƒ¨æ•°æ®é›†å’Œè·¨æ•°æ®é›†è¯„ä¼°ä¸­åˆ†åˆ«æå‡äº†2.8å€å’Œ3.9å€ã€‚è¿™é¡¹å·¥ä½œä¸ºé›†æˆåŒ»ç–—ä¿¡å·ä¸ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¼€åˆ›äº†æ–°èŒƒå¼ï¼Œå……åˆ†éªŒè¯äº†é€šç”¨ECGè¯­è¨€åŒ–åœ¨æå‡æ¨¡å‹æ€§èƒ½ä¸é€æ˜åº¦æ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12625v1",
      "published_date": "2025-09-16 03:41:02 UTC",
      "updated_date": "2025-09-16 03:41:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:10.489643+00:00"
    },
    {
      "arxiv_id": "2509.12618v1",
      "title": "ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation",
      "title_zh": "ActiveVLNï¼šè§†è§‰è¯­è¨€å¯¼èˆªä¸­åŸºäºå¤šè½®å¼ºåŒ–å­¦ä¹ çš„ä¸»åŠ¨æ¢ç´¢",
      "authors": [
        "Zekai Zhang",
        "Weiye Zhu",
        "Hewei Pan",
        "Xiangchen Wang",
        "Rongtao Xu",
        "Xing Sun",
        "Feng Zheng"
      ],
      "abstract": "The Vision-and-Language Navigation (VLN) task requires an agent to follow natural language instructions and navigate through complex environments. Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and often use DAgger for post-training to mitigate covariate shift. While effective, these approaches incur substantial data collection and training costs. Reinforcement learning (RL) offers a promising alternative. However, prior VLN RL methods lack dynamic interaction with the environment and depend on expert trajectories for reward shaping, rather than engaging in open-ended active exploration. This restricts the agent's ability to discover diverse and plausible navigation routes. To address these limitations, we propose ActiveVLN, a VLN framework that explicitly enables active exploration through multi-turn RL. In the first stage, a small fraction of expert trajectories is used for IL to bootstrap the agent. In the second stage, the agent iteratively predicts and executes actions, automatically collects diverse trajectories, and optimizes multiple rollouts via the GRPO objective. To further improve RL efficiency, we introduce a dynamic early-stopping strategy to prune long-tail or likely failed trajectories, along with additional engineering optimizations. Experiments show that ActiveVLN achieves the largest performance gains over IL baselines compared to both DAgger-based and prior RL-based post-training methods, while reaching competitive performance with state-of-the-art approaches despite using a smaller model. Code and data will be released soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€å¯¼èˆª (Vision-and-Language Navigation, VLN) ä»»åŠ¡ä¸­ç°æœ‰æ–¹æ³•ä¾èµ–é«˜æˆæœ¬æ¨¡ä»¿å­¦ä¹  (Imitation Learning, IL) ä»¥åŠå¼ºåŒ–å­¦ä¹  (Reinforcement Learning, RL) ç¼ºä¹ä¸»åŠ¨æ¢ç´¢èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº† ActiveVLN æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒå®ç°ä¸»åŠ¨æ¢ç´¢ï¼šç¬¬ä¸€é˜¶æ®µåˆ©ç”¨æå°‘é‡ä¸“å®¶è½¨è¿¹è¿›è¡Œ IL å¼•å¯¼ï¼Œç¬¬äºŒé˜¶æ®µåˆ™åˆ©ç”¨ GRPO ç›®æ ‡å‡½æ•°é€šè¿‡å¤šè½® RL è¿­ä»£é¢„æµ‹å¹¶è‡ªåŠ¨æ”¶é›†å¤šæ ·åŒ–è½¨è¿¹ã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡è®­ç»ƒæ•ˆç‡ï¼Œç ”ç©¶å¼•å…¥äº†åŠ¨æ€æ—©æœŸåœæ­¢ (Dynamic Early-stopping) ç­–ç•¥æ¥ä¿®å‰ªä½è´¨é‡è½¨è¿¹ï¼Œå¹¶ç»“åˆäº†å¤šé¡¹å·¥ç¨‹ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼ŒActiveVLN åœ¨æ¨¡å‹è§„æ¨¡è¾ƒå°çš„æƒ…å†µä¸‹ï¼Œæ¯”åŸºäº DAgger æˆ–ä¼ ç»Ÿ RL çš„åè®­ç»ƒæ–¹æ³•åœ¨ IL åŸºå‡†ä¸Šå–å¾—äº†æ›´æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼Œå¹¶è¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³• (State-of-the-Art) ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12618v1",
      "published_date": "2025-09-16 03:31:46 UTC",
      "updated_date": "2025-09-16 03:31:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:10.891128+00:00"
    },
    {
      "arxiv_id": "2509.12615v1",
      "title": "Mob-based cattle weight gain forecasting using ML models",
      "title_zh": "åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹çš„ç¾¤ä½“ç‰›åªå¢é‡é¢„æµ‹",
      "authors": [
        "Muhammad Riaz Hasib Hossain",
        "Rafiqul Islam",
        "Shawn R McGrath",
        "Md Zahidul Islam",
        "David Lamb"
      ],
      "abstract": "Forecasting mob based cattle weight gain (MB CWG) may benefit large livestock farms, allowing farmers to refine their feeding strategies, make educated breeding choices, and reduce risks linked to climate variability and market fluctuations. In this paper, a novel technique termed MB CWG is proposed to forecast the one month advanced weight gain of herd based cattle using historical data collected from the Charles Sturt University Farm. This research employs a Random Forest (RF) model, comparing its performance against Support Vector Regression (SVR) and Long Short Term Memory (LSTM) models for monthly weight gain prediction. Four datasets were used to evaluate the performance of models, using 756 sample data from 108 herd-based cattle, along with weather data (rainfall and temperature) influencing CWG. The RF model performs better than the SVR and LSTM models across all datasets, achieving an R^2 of 0.973, RMSE of 0.040, and MAE of 0.033 when both weather and age factors were included. The results indicate that including both weather and age factors significantly improves the accuracy of weight gain predictions, with the RF model outperforming the SVR and LSTM models in all scenarios. These findings demonstrate the potential of RF as a robust tool for forecasting cattle weight gain in variable conditions, highlighting the influence of age and climatic factors on herd based weight trends. This study has also developed an innovative automated pre processing tool to generate a benchmark dataset for MB CWG predictive models. The tool is publicly available on GitHub and can assist in preparing datasets for current and future analytical research..",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º MB CWG çš„æ–°æŠ€æœ¯ï¼Œæ—¨åœ¨åˆ©ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹å¤§ç¾¤ç‰›åªï¼ˆMob-based cattleï¼‰æå‰ä¸€ä¸ªæœˆçš„å¢é‡æƒ…å†µï¼Œä»¥å¸®åŠ©å¤§å‹å…»æ®–åœºä¼˜åŒ–é¥²å…»ç­–ç•¥å¹¶é™ä½é£é™©ã€‚ç ”ç©¶å¯¹æ¯”äº† Random Forest (RF)ã€Support Vector Regression (SVR) å’Œ Long Short Term Memory (LSTM) ä¸‰ç§æ¨¡å‹åœ¨æœˆåº¦å¢é‡é¢„æµ‹ä¸­çš„è¡¨ç°ã€‚é€šè¿‡ä½¿ç”¨ 108 å¤´ç‰›çš„ 756 æ¡å†å²æ•°æ®å¹¶ç»“åˆé™é›¨é‡å’Œæ¸©åº¦ç­‰å¤©æ°”å› ç´ è¿›è¡Œè¯„ä¼°ï¼Œå®éªŒç»“æœæ˜¾ç¤º Random Forest (RF) æ¨¡å‹åœ¨æ‰€æœ‰åœºæ™¯ä¸‹å‡è¡¨ç°æœ€ä½³ï¼Œå…¶ R^2 è¾¾åˆ° 0.973ã€‚ç ”ç©¶å¼ºè°ƒï¼Œçº³å…¥å¹´é¾„å’Œæ°”å€™å› ç´ èƒ½æ˜¾è‘—æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¯æ˜äº† RF æ¨¡å‹åœ¨å¤šå˜ç¯å¢ƒä¸‹çš„ç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼€å‘å¹¶å¼€æºäº†ä¸€æ¬¾åˆ›æ–°çš„è‡ªåŠ¨é¢„å¤„ç†å·¥å…·ï¼Œç”¨äºä¸º MB CWG é¢„æµ‹æ¨¡å‹ç”ŸæˆåŸºå‡†æ•°æ®é›†ï¼Œä¸ºæœªæ¥çš„ç›¸å…³åˆ†æç ”ç©¶æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12615v1",
      "published_date": "2025-09-16 03:23:43 UTC",
      "updated_date": "2025-09-16 03:23:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:13.482754+00:00"
    },
    {
      "arxiv_id": "2509.12612v1",
      "title": "GBV-SQL: Guided Generation and SQL2Text Back-Translation Validation for Multi-Agent Text2SQL",
      "title_zh": "GBV-SQLï¼šé¢å‘å¤šæ™ºèƒ½ä½“ Text2SQL çš„å¼•å¯¼å¼ç”Ÿæˆä¸ SQL2Text å›è¯‘éªŒè¯",
      "authors": [
        "Daojun Chen",
        "Xi Wang",
        "Shenyuan Ren",
        "Qingzhi Ma",
        "Pengpeng Zhao",
        "An Liu"
      ],
      "abstract": "While Large Language Models have significantly advanced Text2SQL generation, a critical semantic gap persists where syntactically valid queries often misinterpret user intent. To mitigate this challenge, we propose GBV-SQL, a novel multi-agent framework that introduces Guided Generation with SQL2Text Back-translation Validation. This mechanism uses a specialized agent to translate the generated SQL back into natural language, which verifies its logical alignment with the original question. Critically, our investigation reveals that current evaluation is undermined by a systemic issue: the poor quality of the benchmarks themselves. We introduce a formal typology for \"Gold Errors\", which are pervasive flaws in the ground-truth data, and demonstrate how they obscure true model performance. On the challenging BIRD benchmark, GBV-SQL achieves 63.23% execution accuracy, a 5.8% absolute improvement. After removing flawed examples, GBV-SQL achieves 96.5% (dev) and 97.6% (test) execution accuracy on the Spider benchmark. Our work offers both a robust framework for semantic validation and a critical perspective on benchmark integrity, highlighting the need for more rigorous dataset curation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GBV-SQLï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³ Text2SQL ä»»åŠ¡ä¸­è¯­ä¹‰åå·®é—®é¢˜çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œè¯¥é—®é¢˜ä¸»è¦è¡¨ç°ä¸ºç”Ÿæˆçš„ SQL è¯­å¥è™½ç„¶è¯­æ³•æ­£ç¡®ä½†å´å®¹æ˜“è¯¯è§£ç”¨æˆ·æ„å›¾ã€‚è¯¥æ¡†æ¶å¼•å…¥äº† Guided Generation å’Œ SQL2Text Back-translation Validation æœºåˆ¶ï¼Œåˆ©ç”¨ä¸“é—¨çš„æ™ºèƒ½ä½“å°†ç”Ÿæˆçš„ SQL è½¬æ¢å›è‡ªç„¶è¯­è¨€ï¼Œä»¥éªŒè¯å…¶é€»è¾‘æ˜¯å¦ä¸åŸå§‹é—®é¢˜ä¸€è‡´ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ­ç¤ºäº†å½“å‰è¯„ä¼°åŸºå‡†ä¸­å­˜åœ¨çš„ç³»ç»Ÿæ€§é—®é¢˜ï¼Œå³æ ‡æ³¨æ•°æ®ä¸­æ™®éå­˜åœ¨ Gold Errorsï¼Œå¹¶ä¸ºæ­¤æå‡ºäº†æ­£å¼çš„é”™è¯¯ç±»å‹å­¦ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ BIRD åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGBV-SQL å®ç°äº† 63.23% çš„æ‰§è¡Œå‡†ç¡®ç‡ï¼Œç›¸æ¯”åŸºçº¿æå‡äº† 5.8%ã€‚åœ¨æ’é™¤æœ‰ç¼ºé™·çš„æ ·æœ¬åï¼Œè¯¥æ¨¡å‹åœ¨ Spider åŸºå‡†çš„å¼€å‘é›†å’Œæµ‹è¯•é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 96.5% å’Œ 97.6% çš„æ‰§è¡Œå‡†ç¡®ç‡ã€‚è¿™é¡¹å·¥ä½œä¸ä»…ä¸ºè¯­ä¹‰éªŒè¯æä¾›äº†ä¸€ä¸ªé²æ£’çš„æ¡†æ¶ï¼Œè¿˜ä¸ºåŸºå‡†æ•°æ®çš„å®Œæ•´æ€§æä¾›äº†æ‰¹åˆ¤æ€§è§†è§’ï¼Œå¼ºè°ƒäº†å¯¹æ•°æ®é›†è¿›è¡Œæ›´ä¸¥æ ¼ç­–åˆ’çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12612v1",
      "published_date": "2025-09-16 03:21:12 UTC",
      "updated_date": "2025-09-16 03:21:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:31.190521+00:00"
    },
    {
      "arxiv_id": "2509.12611v1",
      "title": "Analogy-Driven Financial Chain-of-Thought (AD-FCoT): A Prompting Approach for Financial Sentiment Analysis",
      "title_zh": "ç±»æ¯”é©±åŠ¨çš„é‡‘èé“¾å¼æ€ç»´ (AD-FCoT)ï¼šä¸€ç§é¢å‘é‡‘èæƒ…æ„Ÿåˆ†æçš„æç¤ºæ–¹æ³•",
      "authors": [
        "Anmol Singhal Navya Singhal"
      ],
      "abstract": "Financial news sentiment analysis is crucial for anticipating market movements. With the rise of AI techniques such as Large Language Models (LLMs), which demonstrate strong text understanding capabilities, there has been renewed interest in enhancing these systems. Existing methods, however, often struggle to capture the complex economic context of news and lack transparent reasoning, which undermines their reliability. We propose Analogy-Driven Financial Chain-of-Thought (AD-FCoT), a prompting framework that integrates analogical reasoning with chain-of-thought (CoT) prompting for sentiment prediction on historical financial news. AD-FCoT guides LLMs to draw parallels between new events and relevant historical scenarios with known outcomes, embedding these analogies into a structured, step-by-step reasoning chain. To our knowledge, this is among the first approaches to explicitly combine analogical examples with CoT reasoning in finance. Operating purely through prompting, AD-FCoT requires no additional training data or fine-tuning and leverages the model's internal financial knowledge to generate rationales that mirror human analytical reasoning. Experiments on thousands of news articles show that AD-FCoT outperforms strong baselines in sentiment classification accuracy and achieves substantially higher correlation with market returns. Its generated explanations also align with domain expertise, providing interpretable insights suitable for real-world financial analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Analogy-Driven Financial Chain-of-Thought (AD-FCoT)ï¼Œä¸€ç§ç»“åˆç±»æ¯”æ¨ç†ä¸Chain-of-Thought (CoT) æç¤ºè¯å·¥ç¨‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é‡‘èæƒ…æ„Ÿåˆ†æä¸­å¤æ‚ç»æµèƒŒæ™¯æ•æ‰ä¸è¶³åŠæ¨ç†ç¼ºä¹é€æ˜åº¦çš„é—®é¢˜ã€‚AD-FCoT å¼•å¯¼å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ–°äº‹ä»¶ä¸å…·æœ‰å·²çŸ¥ç»“æœçš„ç›¸å…³å†å²åœºæ™¯ä¹‹é—´å»ºç«‹ç±»æ¯”ï¼Œå¹¶å°†è¿™äº›ç±»æ¯”åµŒå…¥åˆ°ç»“æ„åŒ–çš„é€æ­¥æ¨ç†é“¾ä¸­ã€‚ä½œä¸ºä¸€ç§çº¯æç¤ºè¯æ–¹æ³•ï¼ŒAD-FCoT æ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–å¾®è°ƒï¼Œå……åˆ†åˆ©ç”¨æ¨¡å‹çš„å†…éƒ¨é‡‘èçŸ¥è¯†ç”Ÿæˆç±»ä¼¼äººç±»åˆ†ææ€ç»´çš„ä¾æ®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAD-FCoT åœ¨æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡ä¸Šä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸å¸‚åœºå›æŠ¥è¡¨ç°å‡ºæ˜¾è‘—æ›´é«˜çš„ç›¸å…³æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„è§£é‡Šç¬¦åˆé¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼Œä¸ºç°å®ä¸–ç•Œçš„é‡‘èåˆ†ææä¾›äº†å…·æœ‰å¯è§£é‡Šæ€§çš„æ´å¯Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE AIxB 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12611v1",
      "published_date": "2025-09-16 03:19:26 UTC",
      "updated_date": "2025-09-16 03:19:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:28.100081+00:00"
    },
    {
      "arxiv_id": "2509.12610v1",
      "title": "ScaleDoc: Scaling LLM-based Predicates over Large Document Collections",
      "title_zh": "ScaleDocï¼šé¢å‘å¤§è§„æ¨¡æ–‡æ¡£é›†åˆçš„è§„æ¨¡åŒ–å¤§è¯­è¨€æ¨¡å‹è°“è¯åˆ¤å®š",
      "authors": [
        "Hengrui Zhang",
        "Yulong Hui",
        "Yihao Liu",
        "Huanchen Zhang"
      ],
      "abstract": "Predicates are foundational components in data analysis systems. However, modern workloads increasingly involve unstructured documents, which demands semantic understanding, beyond traditional value-based predicates. Given enormous documents and ad-hoc queries, while Large Language Models (LLMs) demonstrate powerful zero-shot capabilities, their high inference cost leads to unacceptable overhead. Therefore, we introduce \\textsc{ScaleDoc}, a novel system that addresses this by decoupling predicate execution into an offline representation phase and an optimized online filtering phase. In the offline phase, \\textsc{ScaleDoc} leverages a LLM to generate semantic representations for each document. Online, for each query, it trains a lightweight proxy model on these representations to filter the majority of documents, forwarding only the ambiguous cases to the LLM for final decision. Furthermore, \\textsc{ScaleDoc} proposes two core innovations to achieve significant efficiency: (1) a contrastive-learning-based framework that trains the proxy model to generate reliable predicating decision scores; (2) an adaptive cascade mechanism that determines the effective filtering policy while meeting specific accuracy targets. Our evaluations across three datasets demonstrate that \\textsc{ScaleDoc} achieves over a 2$\\times$ end-to-end speedup and reduces expensive LLM invocations by up to 85\\%, making large-scale semantic analysis practical and efficient.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ScaleDocï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³åœ¨å¤§è§„æ¨¡æ–‡æ¡£é›†ä¸­é€šè¿‡å¤§è¯­è¨€æ¨¡å‹(LLMs)æ‰§è¡Œè¯­ä¹‰æ–­è¨€(Predicates)æ—¶é¢ä¸´çš„é«˜æ˜‚æ¨ç†æˆæœ¬é—®é¢˜çš„ç³»ç»Ÿã€‚ScaleDocé€šè¿‡å°†æ–­è¨€æ‰§è¡Œè§£è€¦ä¸ºç¦»çº¿è¡¨ç¤ºé˜¶æ®µå’Œä¼˜åŒ–çš„åœ¨çº¿è¿‡æ»¤é˜¶æ®µï¼Œåˆ©ç”¨LLMç”Ÿæˆæ–‡æ¡£çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶åœ¨çº¿ä¸Šè®­ç»ƒè½»é‡çº§ä»£ç†æ¨¡å‹(Proxy Model)æ¥è¿‡æ»¤å¤§éƒ¨åˆ†æ–‡æ¡£ï¼Œä»…å°†æ¨¡ç³Šæ¡ˆä¾‹äº¤ç»™LLMå†³ç­–ã€‚è¯¥ç³»ç»Ÿæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸€ä¸ªåŸºäºå¯¹æ¯”å­¦ä¹ (Contrastive Learning)çš„æ¡†æ¶ä»¥ç”Ÿæˆå¯é çš„é¢„æµ‹åˆ†å€¼ï¼Œä»¥åŠä¸€ä¸ªåœ¨æ»¡è¶³å‡†ç¡®æ€§ç›®æ ‡ä¸‹ç¡®å®šè¿‡æ»¤ç­–ç•¥çš„è‡ªé€‚åº”çº§è”æœºåˆ¶(Adaptive Cascade)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒScaleDocåœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡2å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œå¹¶å°†æ˜‚è´µçš„LLMè°ƒç”¨å‡å°‘äº†é«˜è¾¾85%ï¼Œä¸ºå¤§è§„æ¨¡é«˜æ•ˆè¯­ä¹‰åˆ†ææä¾›äº†å®ç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12610v1",
      "published_date": "2025-09-16 03:18:06 UTC",
      "updated_date": "2025-09-16 03:18:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:35.496619+00:00"
    },
    {
      "arxiv_id": "2509.18147v1",
      "title": "ConceptFlow: Hierarchical and Fine-grained Concept-Based Explanation for Convolutional Neural Networks",
      "title_zh": "ConceptFlowï¼šå·ç§¯ç¥ç»ç½‘ç»œçš„å±‚çº§åŒ–ä¸ç»†ç²’åº¦æ¦‚å¿µè§£é‡Š",
      "authors": [
        "Xinyu Mu",
        "Hui Dou",
        "Furao Shen",
        "Jian Zhao"
      ],
      "abstract": "Concept-based interpretability for Convolutional Neural Networks (CNNs) aims to align internal model representations with high-level semantic concepts, but existing approaches largely overlook the semantic roles of individual filters and the dynamic propagation of concepts across layers. To address these limitations, we propose ConceptFlow, a concept-based interpretability framework that simulates the internal \"thinking path\" of a model by tracing how concepts emerge and evolve across layers. ConceptFlow comprises two key components: (i) concept attentions, which associate each filter with relevant high-level concepts to enable localized semantic interpretation, and (ii) conceptual pathways, derived from a concept transition matrix that quantifies how concepts propagate and transform between filters. Together, these components offer a unified and structured view of internal model reasoning. Experimental results demonstrate that ConceptFlow yields semantically meaningful insights into model reasoning, validating the effectiveness of concept attentions and conceptual pathways in explaining decision behavior. By modeling hierarchical conceptual pathways, ConceptFlow provides deeper insight into the internal logic of CNNs and supports the generation of more faithful and human-aligned explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ConceptFlowï¼Œä¸€ç§æ—¨åœ¨è§£å†³ç°æœ‰å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)åŸºäºæ¦‚å¿µçš„å¯è§£é‡Šæ€§æ–¹æ³•ä¸­å¿½ç•¥è¿‡æ»¤å™¨è¯­ä¹‰è§’è‰²å’Œæ¦‚å¿µåŠ¨æ€æ¼”åŒ–é—®é¢˜çš„æ¡†æ¶ã€‚ConceptFlow é€šè¿‡è¿½è¸ªæ¦‚å¿µåœ¨å±‚é—´å¦‚ä½•å‡ºç°å’Œæ¼”åŒ–ï¼Œæ¨¡æ‹Ÿäº†æ¨¡å‹å†…éƒ¨çš„â€œæ€ç»´è·¯å¾„â€ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ¦‚å¿µæ³¨æ„åŠ›(concept attentions)å°†æ¯ä¸ªè¿‡æ»¤å™¨ä¸ç›¸å…³é«˜å±‚æ¦‚å¿µå…³è”ä»¥å®ç°å±€éƒ¨è¯­ä¹‰è§£é‡Šï¼›æ¦‚å¿µè·¯å¾„(conceptual pathways)åˆ™é€šè¿‡æ¦‚å¿µè½¬æ¢çŸ©é˜µ(concept transition matrix)é‡åŒ–æ¦‚å¿µåœ¨è¿‡æ»¤å™¨é—´çš„ä¼ æ’­ä¸è½¬æ¢ã€‚è¿™ä¸¤ä¸ªç»„ä»¶å…±åŒæ„æˆäº†æ¨¡å‹å†…éƒ¨æ¨ç†çš„ç»Ÿä¸€ç»“æ„åŒ–è§†å›¾ã€‚å®éªŒç»“æœè¯æ˜ ConceptFlow èƒ½å¤Ÿä¸ºæ¨¡å‹æ¨ç†æä¾›å…·æœ‰è¯­ä¹‰ä»·å€¼çš„è§è§£ï¼Œå¹¶æœ‰æ•ˆè§£é‡Šäº†å†³ç­–è¡Œä¸ºã€‚é€šè¿‡å»ºæ¨¡å±‚çº§åŒ–çš„æ¦‚å¿µè·¯å¾„ï¼Œè¯¥æ¡†æ¶æ·±åŒ–äº†å¯¹ CNNs å†…éƒ¨é€»è¾‘çš„æ´å¯Ÿï¼Œæ”¯æŒç”Ÿæˆæ›´å…·ä¿çœŸåº¦ä¸”ç¬¦åˆäººç±»ç›´è§‰çš„è§£é‡Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.18147v1",
      "published_date": "2025-09-16 03:02:46 UTC",
      "updated_date": "2025-09-16 03:02:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:40.099154+00:00"
    },
    {
      "arxiv_id": "2509.12603v1",
      "title": "EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving",
      "title_zh": "EconProverï¼šè¿ˆå‘æ›´ç»æµé«˜æ•ˆçš„è‡ªåŠ¨å®šç†è¯æ˜æ¨ç†æ—¶æ‰©å±•",
      "authors": [
        "Mukai Li",
        "Linfeng Song",
        "Zhenwen Liang",
        "Jiahao Xu",
        "Shansan Gong",
        "Qi Liu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨å®šç†è¯æ˜(Automated Theorem Proving)é¢†åŸŸä¸­å¤§è¯­è¨€æ¨¡å‹(LLMs)æµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)ç­–ç•¥å¸¦æ¥çš„å·¨å¤§è®¡ç®—å¼€é”€ï¼Œæå‡ºäº†æ›´ä¸ºç»æµçš„EconProverã€‚ç ”ç©¶é¦–å…ˆæ­ç¤ºäº†ç°æœ‰åŸºäºåå°„Chain-of-Thoughtæ¨ç†å’Œå¢åŠ é‡‡æ ·æ¬¡æ•°çš„æ–¹æ³•åœ¨æ¨ç†æ•ˆç‡ä¸Šçš„ä¸è¶³ï¼ŒæŒ‡å‡ºå½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–¹æ¡ˆå­˜åœ¨æ˜¾è‘—çš„æˆæœ¬æµªè´¹ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†ç»Ÿä¸€çš„EconRLæµç¨‹ï¼Œé€šè¿‡åŠ¨æ€Chain-of-Thoughtåˆ‡æ¢æœºåˆ¶å‡å°‘ä¸å¿…è¦çš„Tokenæ¶ˆè€—ï¼Œå¹¶ç»“åˆå¸¦å¯è®­ç»ƒå‰ç¼€çš„å¤šæ ·åŒ–å¹¶è¡Œç¼©æ”¾å¼ºåŒ–å­¦ä¹ (Diverse parallel-scaled RL)æå‡äº†å—é™é‡‡æ ·ä¸‹çš„æˆåŠŸç‡ã€‚åœ¨miniF2Få’ŒProofNetåŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼ŒEconProveråœ¨ä»…æ¶ˆè€—åŸºçº¿æ–¹æ³•12%è®¡ç®—èµ„æºçš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹éƒ¨ç½²é«˜æ•ˆä¸”è½»é‡çº§çš„ATPæ¨¡å‹æä¾›äº†åˆ‡å®å¯è¡Œçš„è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12603v1",
      "published_date": "2025-09-16 03:00:13 UTC",
      "updated_date": "2025-09-16 03:00:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:03:43.084271+00:00"
    },
    {
      "arxiv_id": "2509.12602v1",
      "title": "DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models",
      "title_zh": "DaSAThcoï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®æ„ŸçŸ¥å‹ SAT å¯å‘å¼ç»„åˆä¼˜åŒ–",
      "authors": [
        "Minyu Chen",
        "Guoqiang Li"
      ],
      "abstract": "The performance of Conflict-Driven Clause Learning solvers hinges on internal heuristics, yet the heterogeneity of SAT problems makes a single, universally optimal configuration unattainable. While prior automated methods can find specialized configurations for specific problem families, this dataset-specific approach lacks generalizability and requires costly re-optimization for new problem types. We introduce DaSAThco, a framework that addresses this challenge by learning a generalizable mapping from instance features to tailored heuristic ensembles, enabling a train-once, adapt-broadly model. Our framework uses a Large Language Model, guided by systematically defined Problem Archetypes, to generate a diverse portfolio of specialized heuristic ensembles and subsequently learns an adaptive selection mechanism to form the final mapping. Experiments show that DaSAThco achieves superior performance and, most notably, demonstrates robust out-of-domain generalization where non-adaptive methods show limitations. Our work establishes a more scalable and practical path toward automated algorithm design for complex, configurable systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Conflict-Driven Clause Learning (CDCL) æ±‚è§£å™¨åœ¨å¤„ç†å¼‚æ„ SAT é—®é¢˜æ—¶ç¼ºä¹é€šç”¨æœ€ä¼˜å¯å‘å¼é…ç½®çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† DaSAThco æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Model) åœ¨ç³»ç»Ÿå®šä¹‰çš„ Problem Archetypes æŒ‡å¯¼ä¸‹ï¼Œç”Ÿæˆå¤šæ ·åŒ–çš„ä¸“ä¸šå¯å‘å¼ç»„åˆ (heuristic ensembles)ã€‚é€šè¿‡å­¦ä¹ ä»å®ä¾‹ç‰¹å¾åˆ°å®šåˆ¶ç»„åˆçš„é€šç”¨æ˜ å°„ï¼ŒDaSAThco å®ç°äº†â€œä¸€æ¬¡è®­ç»ƒï¼Œå¹¿æ³›é€‚é…â€çš„æ¨¡å‹æ¨¡å¼ã€‚è¿™ç§è‡ªé€‚åº”é€‰æ‹©æœºåˆ¶æœ‰æ•ˆè§£å†³äº†ä»¥å¾€è‡ªåŠ¨åŒ–æ–¹æ³•åœ¨å¤„ç†æ–°é—®é¢˜ç±»å‹æ—¶æ³›åŒ–æ€§å·®ä¸”é‡æ–°ä¼˜åŒ–æˆæœ¬é«˜çš„é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒDaSAThco ä¸ä»…åœ¨æ€§èƒ½ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¿˜åœ¨éè‡ªé€‚åº”æ–¹æ³•å—é™çš„é¢†åŸŸå¤–æ³›åŒ– (out-of-domain generalization) ä»»åŠ¡ä¸­å±•ç°äº†æå¼ºçš„é²æ£’æ€§ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¤æ‚å¯é…ç½®ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–ç®—æ³•è®¾è®¡å¼€è¾Ÿäº†æ›´å…·æ‰©å±•æ€§å’Œå®ç”¨æ€§çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.12602v1",
      "published_date": "2025-09-16 02:58:50 UTC",
      "updated_date": "2025-09-16 02:58:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:06.353350+00:00"
    },
    {
      "arxiv_id": "2509.12600v1",
      "title": "A Multimodal Foundation Model to Enhance Generalizability and Data Efficiency for Pan-cancer Prognosis Prediction",
      "title_zh": "æå‡æ³›ç™Œé¢„åé¢„æµ‹æ³›åŒ–èƒ½åŠ›ä¸æ•°æ®æ•ˆç‡çš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹",
      "authors": [
        "Huajun Zhou",
        "Fengtao Zhou",
        "Jiabo Ma",
        "Yingxue Xu",
        "Xi Wang",
        "Xiuming Zhang",
        "Li Liang",
        "Zhenhui Li",
        "Hao Chen"
      ],
      "abstract": "Multimodal data provides heterogeneous information for a holistic understanding of the tumor microenvironment. However, existing AI models often struggle to harness the rich information within multimodal data and extract poorly generalizable representations. Here we present MICE (Multimodal data Integration via Collaborative Experts), a multimodal foundation model that effectively integrates pathology images, clinical reports, and genomics data for precise pan-cancer prognosis prediction. Instead of conventional multi-expert modules, MICE employs multiple functionally diverse experts to comprehensively capture both cross-cancer and cancer-specific insights. Leveraging data from 11,799 patients across 30 cancer types, we enhanced MICE's generalizability by coupling contrastive and supervised learning. MICE outperformed both unimodal and state-of-the-art multi-expert-based multimodal models, demonstrating substantial improvements in C-index ranging from 3.8% to 11.2% on internal cohorts and 5.8% to 8.8% on independent cohorts, respectively. Moreover, it exhibited remarkable data efficiency across diverse clinical scenarios. With its enhanced generalizability and data efficiency, MICE establishes an effective and scalable foundation for pan-cancer prognosis prediction, holding strong potential to personalize tailored therapies and improve treatment outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MICE (Multimodal data Integration via Collaborative Experts)ï¼Œä¸€ç§æ—¨åœ¨æ•´åˆç—…ç†å›¾åƒã€ä¸´åºŠæŠ¥å‘Šå’ŒåŸºå› ç»„æ•°æ®çš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œç”¨äºç²¾ç¡®çš„æ³›ç™Œç—‡é¢„åé¢„æµ‹ (Pan-cancer Prognosis Prediction)ã€‚MICE é‡‡ç”¨äº†å¤šä¸ªåŠŸèƒ½å¤šæ ·åŒ–çš„ä¸“å®¶æ¥å…¨é¢æ•è·è·¨ç™Œç—‡å’Œç‰¹å®šç™Œç—‡çš„è§è§£ï¼Œé€šè¿‡ç»“åˆå¯¹æ¯”å­¦ä¹  (Contrastive Learning) å’Œç›‘ç£å­¦ä¹  (Supervised Learning)ï¼Œåˆ©ç”¨ 30 ç§ç™Œç—‡ç±»å‹çš„ 11,799 åæ‚£è€…æ•°æ®æ˜¾è‘—å¢å¼ºäº†æ³›åŒ–èƒ½åŠ› (Generalizability)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMICE åœ¨å†…éƒ¨å’Œç‹¬ç«‹é˜Ÿåˆ—ä¸­çš„ C-index è¡¨ç°åˆ†åˆ«æ¯”ç°æœ‰å•æ¨¡æ€åŠæœ€å…ˆè¿›çš„å¤šä¸“å®¶å¤šæ¨¡æ€æ¨¡å‹æå‡äº† 3.8%-11.2% å’Œ 5.8%-8.8%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§ä¸´åºŠåœºæ™¯ä¸‹å±•ç°å‡ºæé«˜çš„æ•°æ®æ•ˆç‡ (Data Efficiency)ã€‚MICE ä¸ºå¯æ‰©å±•çš„æ³›ç™Œç—‡é¢„åé¢„æµ‹å»ºç«‹äº†æœ‰æ•ˆçš„åŸºç¡€ï¼Œåœ¨ä¼˜åŒ–ä¸ªæ€§åŒ–å®šåˆ¶æ²»ç–—å’Œæ”¹å–„æ²»ç–—ç»“æœæ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.12600v1",
      "published_date": "2025-09-16 02:57:55 UTC",
      "updated_date": "2025-09-16 02:57:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:02.792437+00:00"
    },
    {
      "arxiv_id": "2509.12595v1",
      "title": "DisorientLiDAR: Physical Attacks on LiDAR-based Localization",
      "title_zh": "DisorientLiDARï¼šé’ˆå¯¹åŸºäºæ¿€å…‰é›·è¾¾å®šä½çš„ç‰©ç†æ”»å‡»",
      "authors": [
        "Yizhen Lao",
        "Yu Zhang",
        "Ziting Wang",
        "Chengbo Wang",
        "Yifei Xue",
        "Wanpeng Shao"
      ],
      "abstract": "Deep learning models have been shown to be susceptible to adversarial attacks with visually imperceptible perturbations. Even this poses a serious security challenge for the localization of self-driving cars, there has been very little exploration of attack on it, as most of adversarial attacks have been applied to 3D perception. In this work, we propose a novel adversarial attack framework called DisorientLiDAR targeting LiDAR-based localization. By reverse-engineering localization models (e.g., feature extraction networks), adversaries can identify critical keypoints and strategically remove them, thereby disrupting LiDAR-based localization. Our proposal is first evaluated on three state-of-the-art point-cloud registration models (HRegNet, D3Feat, and GeoTransformer) using the KITTI dataset. Experimental results demonstrate that removing regions containing Top-K keypoints significantly degrades their registration accuracy. We further validate the attack's impact on the Autoware autonomous driving platform, where hiding merely a few critical regions induces noticeable localization drift. Finally, we extended our attacks to the physical world by hiding critical regions with near-infrared absorptive materials, thereby successfully replicate the attack effects observed in KITTI data. This step has been closer toward the realistic physical-world attack that demonstrate the veracity and generality of our proposal.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DisorientLiDARï¼Œä¸€ç§é’ˆå¯¹åŸºäº LiDAR å®šä½çš„å¯¹æŠ—æ€§æ”»å‡»æ¡†æ¶ï¼Œæ—¨åœ¨æ­ç¤ºå¹¶è§£å†³è‡ªåŠ¨é©¾é©¶å®šä½ç³»ç»Ÿé¢ä¸´çš„å®‰å…¨æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡é€†å‘å·¥ç¨‹å®šä½æ¨¡å‹ä¸­çš„ç‰¹å¾æå–ç½‘ç»œï¼Œè¯†åˆ«å¹¶ç­–ç•¥æ€§åœ°ç§»é™¤å…³é”®ç‚¹ï¼Œä»è€Œç ´åç‚¹äº‘é…å‡†ï¼ˆpoint-cloud registrationï¼‰çš„å‡†ç¡®æ€§ã€‚å®éªŒåœ¨ KITTI æ•°æ®é›†ä¸Šå¯¹ HRegNetã€D3Feat å’Œ GeoTransformer ä¸‰ç§å…ˆè¿›æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºç§»é™¤åŒ…å« Top-K å…³é”®ç‚¹çš„åŒºåŸŸä¼šæ˜¾è‘—é™ä½å®šä½ç²¾åº¦ã€‚åœ¨ Autoware è‡ªåŠ¨é©¾é©¶å¹³å°ä¸Šçš„è¿›ä¸€æ­¥éªŒè¯è¡¨æ˜ï¼Œä»…éšè—å°‘æ•°å…³é”®åŒºåŸŸå³å¯è¯±å‘æ˜æ˜¾çš„å®šä½æ¼‚ç§»ï¼ˆlocalization driftï¼‰ã€‚æœ€åï¼Œç ”ç©¶äººå‘˜åˆ©ç”¨è¿‘çº¢å¤–å¸æ”¶ææ–™ (near-infrared absorptive materials) åœ¨ç‰©ç†ä¸–ç•Œä¸­æˆåŠŸå¤ç°äº†æ”»å‡»æ•ˆæœï¼Œè¯æ˜äº† DisorientLiDAR åœ¨ç°å®ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ä¸é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12595v1",
      "published_date": "2025-09-16 02:46:39 UTC",
      "updated_date": "2025-09-16 02:46:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:08.031779+00:00"
    },
    {
      "arxiv_id": "2509.12592v1",
      "title": "Match Chat: Real Time Generative AI and Generative Computing for Tennis",
      "title_zh": "Match Chatï¼šé¢å‘ç½‘çƒè¿åŠ¨çš„å®æ—¶ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸ç”Ÿæˆå¼è®¡ç®—",
      "authors": [
        "Aaron Baughman",
        "Gozde Akay",
        "Eduardo Morales",
        "Rahul Agarwal",
        "Preetika Srivastava"
      ],
      "abstract": "We present Match Chat, a real-time, agent-driven assistant designed to enhance the tennis fan experience by delivering instant, accurate responses to match-related queries. Match Chat integrates Generative Artificial Intelligence (GenAI) with Generative Computing (GenComp) techniques to synthesize key insights during live tennis singles matches. The system debuted at the 2025 Wimbledon Championships and the 2025 US Open, where it provided about 1 million users with seamless access to streaming and static data through natural language queries. The architecture is grounded in an Agent-Oriented Architecture (AOA) combining rule engines, predictive models, and agents to pre-process and optimize user queries before passing them to GenAI components. The Match Chat system had an answer accuracy of 92.83% with an average response time of 6.25 seconds under loads of up to 120 requests per second (RPS). Over 96.08% of all queries were guided using interactive prompt design, contributing to a user experience that prioritized clarity, responsiveness, and minimal effort. The system was designed to mask architectural complexity, offering a frictionless and intuitive interface that required no onboarding or technical familiarity. Across both Grand Slam deployments, Match Chat maintained 100% uptime and supported nearly 1 million unique users, underscoring the scalability and reliability of the platform. This work introduces key design patterns for real-time, consumer-facing AI systems that emphasize speed, precision, and usability that highlights a practical path for deploying performant agentic systems in dynamic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶å±•ç¤ºäº† Match Chatï¼Œè¿™æ˜¯ä¸€ç§å®æ—¶ã€æ™ºèƒ½ä½“é©±åŠ¨çš„åŠ©æ‰‹ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative Artificial Intelligence) ä¸ç”Ÿæˆå¼è®¡ç®— (Generative Computing) æŠ€æœ¯æ¥å¢å¼ºç½‘çƒç²‰ä¸çš„äº’åŠ¨ä½“éªŒã€‚è¯¥ç³»ç»Ÿåœ¨ 2025 å¹´æ¸©å¸ƒå°”ç™»é”¦æ ‡èµ›å’Œç¾å›½ç½‘çƒå…¬å¼€èµ›ä¸­é¦–æ¬¡äº®ç›¸ï¼Œå…¶æ ¸å¿ƒé‡‡ç”¨äº†é¢å‘æ™ºèƒ½ä½“çš„æ¶æ„ (Agent-Oriented Architecture)ï¼Œç»“åˆè§„åˆ™å¼•æ“ä¸é¢„æµ‹æ¨¡å‹å¯¹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œé¢„å¤„ç†å’Œä¼˜åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMatch Chat åœ¨æ¯ç§’ 120 æ¬¡è¯·æ±‚çš„é«˜è´Ÿè½½ä¸‹ï¼Œå®ç°äº† 92.83% çš„å›ç­”å‡†ç¡®ç‡å’Œ 6.25 ç§’çš„å¹³å‡å“åº”æ—¶é—´ã€‚è¶…è¿‡ 96.08% çš„æŸ¥è¯¢é€šè¿‡äº¤äº’å¼æç¤ºè®¾è®¡å®Œæˆï¼Œåœ¨æ— éœ€ç”¨æˆ·åŸ¹è®­çš„æƒ…å†µä¸‹æä¾›äº†æµç•…ç›´è§‚çš„ç•Œé¢ã€‚åœ¨ä¸¤å¤§æ»¡è´¯èµ›äº‹æœŸé—´ï¼Œè¯¥ç³»ç»Ÿä¿æŒäº† 100% çš„è¿è¡Œæ—¶é—´å¹¶æœåŠ¡äº†è¿‘ 100 ä¸‡ç”¨æˆ·ï¼Œå……åˆ†éªŒè¯äº†å…¶å¹³å°çš„å¯é æ€§ä¸å¯æ‰©å±•æ€§ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨åŠ¨æ€ç¯å¢ƒä¸‹æ„å»ºé«˜æ€§èƒ½ã€é¢å‘æ¶ˆè´¹è€…çš„å®æ—¶ Agent ç³»ç»Ÿæä¾›äº†é‡è¦çš„è®¾è®¡æ¨¡å¼ä¸å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5 Figures, 4 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.12592v1",
      "published_date": "2025-09-16 02:38:27 UTC",
      "updated_date": "2025-09-16 02:38:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:09.652108+00:00"
    },
    {
      "arxiv_id": "2509.12589v1",
      "title": "Redefining CX with Agentic AI: Minerva CQ Case Study",
      "title_zh": "ç”¨æ™ºèƒ½ä½“ AI é‡æ–°å®šä¹‰å®¢æˆ·ä½“éªŒï¼šMinerva CQ æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Garima Agrawal",
        "Riccardo De Maria",
        "Kiran Davuluri",
        "Daniele Spera",
        "Charlie Read",
        "Cosimo Spera",
        "Jack Garrett",
        "Don Miller"
      ],
      "abstract": "Despite advances in AI for contact centers, customer experience (CX) continues to suffer from high average handling time (AHT), low first-call resolution, and poor customer satisfaction (CSAT). A key driver is the cognitive load on agents, who must navigate fragmented systems, troubleshoot manually, and frequently place customers on hold. Existing AI-powered agent-assist tools are often reactive driven by static rules, simple prompting, or retrieval-augmented generation (RAG) without deeper contextual reasoning. We introduce Agentic AI goal-driven, autonomous, tool-using systems that proactively support agents in real time. Unlike conventional approaches, Agentic AI identifies customer intent, triggers modular workflows, maintains evolving context, and adapts dynamically to conversation state. This paper presents a case study of Minerva CQ, a real-time Agent Assist product deployed in voice-based customer support. Minerva CQ integrates real-time transcription, intent and sentiment detection, entity recognition, contextual retrieval, dynamic customer profiling, and partial conversational summaries enabling proactive workflows and continuous context-building. Deployed in live production, Minerva CQ acts as an AI co-pilot, delivering measurable improvements in agent efficiency and customer experience across multiple deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‘¼å«ä¸­å¿ƒï¼ˆcontact centersï¼‰é¢ä¸´çš„é«˜å¹³å‡å¤„ç†æ—¶é—´ï¼ˆAHTï¼‰å’Œä½é¦–å‘¼è§£å†³ç‡ç­‰æŒç»­æŒ‘æˆ˜ï¼Œæå‡ºäº† Agentic AI çš„æ¦‚å¿µï¼Œå³ä¸€ç§ç›®æ ‡é©±åŠ¨ä¸”å…·å¤‡è‡ªä¸»å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„å®æ—¶è¾…åŠ©ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æˆ–é™æ€è§„åˆ™å·¥å…·ä¸åŒï¼ŒAgentic AI èƒ½å¤Ÿä¸»åŠ¨è¯†åˆ«å®¢æˆ·æ„å›¾ã€è§¦å‘æ¨¡å—åŒ–å·¥ä½œæµå¹¶ç»´æŒä¸æ–­æ¼”è¿›çš„å¯¹è¯ä¸Šä¸‹æ–‡ã€‚è®ºæ–‡é€šè¿‡ Minerva CQ çš„æ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†è¯¥æŠ€æœ¯çš„å®é™…åº”ç”¨ï¼Œè¯¥äº§å“é›†æˆäº†å®æ—¶è½¬å½•ï¼ˆtranscriptionï¼‰ã€æƒ…æ„Ÿæ£€æµ‹ã€å®ä½“è¯†åˆ«å’ŒåŠ¨æ€å®¢æˆ·ç”»åƒï¼ˆdynamic customer profilingï¼‰ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚åœ¨å®é™…è¯­éŸ³æ”¯æŒç”Ÿäº§ç¯å¢ƒä¸­çš„éƒ¨ç½²ç»“æœè¡¨æ˜ï¼Œä½œä¸º AI å‰¯é©¾é©¶ï¼ˆAI co-pilotï¼‰çš„ Minerva CQ èƒ½å¤Ÿæœ‰æ•ˆé™ä½åå¸­çš„è®¤çŸ¥è´Ÿè·ã€‚é€šè¿‡æä¾›ä¸»åŠ¨å¼å·¥ä½œæµï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šä¸ªéƒ¨ç½²æ¡ˆä¾‹ä¸­æ˜¾è‘—æå‡äº†åå¸­çš„æ—¥å¸¸å·¥ä½œæ•ˆç‡ï¼Œå¹¶å®ç°äº†å®¢æˆ·ä½“éªŒï¼ˆCXï¼‰çš„å®è´¨æ€§æ”¹å–„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12589v1",
      "published_date": "2025-09-16 02:30:33 UTC",
      "updated_date": "2025-09-16 02:30:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:14.158238+00:00"
    },
    {
      "arxiv_id": "2509.21341v1",
      "title": "From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification",
      "title_zh": "ä»åµŒå…¥åˆ°æ–¹ç¨‹ï¼šé¢å‘å¯è§£é‡Š Transformer åˆ†ç±»çš„é—ä¼ ç¼–ç¨‹ä»£ç†æ¨¡å‹",
      "authors": [
        "Mohammad Sadegh Khorshidi",
        "Navid Yazdanjue",
        "Hassan Gharoun",
        "Mohammad Reza Nikoo",
        "Fang Chen",
        "Amir H. Gandomi"
      ],
      "abstract": "We study symbolic surrogate modeling of frozen Transformer embeddings to obtain compact, auditable classifiers with calibrated probabilities. For five benchmarks (SST2G, 20NG, MNIST, CIFAR10, MSC17), embeddings from ModernBERT, DINOv2, and SigLIP are partitioned on the training set into disjoint, information-preserving views via semantic-preserving feature partitioning (SPFP). A cooperative multi-population genetic program (MEGP) then learns additive, closed-form logit programs over these views. Across 30 runs per dataset we report F1, AUC, log-loss, Brier, expected calibration error (ECE), and symbolic complexity; a canonical model is chosen by a one-standard-error rule on validation F1 with a parsimony tie-break. Temperature scaling fitted on validation yields substantial ECE reductions on test. The resulting surrogates achieve strong discrimination (up to F1 around 0.99 on MNIST, CIFAR10, MSC17; around 0.95 on SST2G), while 20NG remains most challenging. We provide reliability diagrams, dimension usage and overlap statistics, contribution-based importances, and global effect profiles (PDP and ALE), demonstrating faithful, cross-modal explanations grounded in explicit programs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹å†»ç»“çš„ Transformer embeddings çš„ç¬¦å·ä»£ç†å»ºæ¨¡æ–¹æ³•ï¼Œæ—¨åœ¨æ„å»ºç´§å‡‘ã€å¯å®¡è®¡ä¸”å…·æœ‰æ ¡å‡†æ¦‚ç‡çš„åˆ†ç±»å™¨ã€‚é€šè¿‡å¯¹ ModernBERTã€DINOv2 å’Œ SigLIP çš„åµŒå…¥è¿›è¡Œè¯­ä¹‰ä¿æŒç‰¹å¾åˆ’åˆ† (SPFP)ï¼Œç ”ç©¶é‡‡ç”¨ååŒå¤šç¾¤ä½“é—ä¼ ç¨‹åº (MEGP) åœ¨ä¸åŒç‰¹å¾è§†å›¾ä¸Šå­¦ä¹ åŠ æ³•é—­å¼çš„ logit ç¨‹åºã€‚åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼Œè¯¥ä»£ç†æ¨¡å‹å®ç°äº†æå¼ºçš„åˆ¤åˆ«æ€§èƒ½ï¼Œåœ¨ MNIST å’Œ CIFAR10 ç­‰ä»»åŠ¡ä¸­ F1 åˆ†æ•°æ¥è¿‘ 0.99ã€‚é€šè¿‡åœ¨éªŒè¯é›†ä¸Šåº”ç”¨ temperature scalingï¼Œæ¨¡å‹æ˜¾è‘—é™ä½äº†æµ‹è¯•é›†çš„æœŸæœ›æ ¡å‡†è¯¯å·® (ECE)ã€‚è¯¥ç ”ç©¶è¿˜åˆ©ç”¨ PDP å’Œ ALE ç­‰åˆ†ææ‰‹æ®µæä¾›äº†å…¨å±€æ•ˆåº”å›¾è°±ï¼Œè¯æ˜äº†æ‰€å¾—ç¨‹åºåœ¨è·¨æ¨¡æ€è§£é‡Šä¸Šçš„å¿ å®æ€§ã€‚è¿™ç§æ–¹æ³•æˆåŠŸå®ç°äº†ä»é«˜ç»´åµŒå…¥åˆ°å¯è§£é‡Šæ•°å­¦æ–¹ç¨‹çš„è½¬åŒ–ï¼Œä¸ºç†è§£ Transformer åˆ†ç±»é€»è¾‘æä¾›äº†é€æ˜çš„æ•°å­¦æ¡†æ¶ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "20 pages, 8 tables, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.21341v1",
      "published_date": "2025-09-16 02:17:04 UTC",
      "updated_date": "2025-09-16 02:17:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:19.070662+00:00"
    },
    {
      "arxiv_id": "2510.08580v1",
      "title": "LadderSym: A Multimodal Interleaved Transformer for Music Practice Error Detection",
      "title_zh": "LadderSymï¼šç”¨äºéŸ³ä¹ç»ƒä¹ é”™è¯¯æ£€æµ‹çš„å¤šæ¨¡æ€äº¤ç»‡ Transformer",
      "authors": [
        "Benjamin Shiue-Hal Chou",
        "Purvish Jajal",
        "Nick John Eliopoulos",
        "James C. Davis",
        "George K. Thiruvathukal",
        "Kristen Yeon-Ji Yun",
        "Yung-Hsiang Lu"
      ],
      "abstract": "Music learners can greatly benefit from tools that accurately detect errors in their practice. Existing approaches typically compare audio recordings to music scores using heuristics or learnable models. This paper introduces \\textit{LadderSym}, a novel Transformer-based method for music error detection. \\textit{LadderSym} is guided by two key observations about the state-of-the-art approaches: (1) late fusion limits inter-stream alignment and cross-modality comparison capability; and (2) reliance on score audio introduces ambiguity in the frequency spectrum, degrading performance in music with concurrent notes. To address these limitations, \\textit{LadderSym} introduces (1) a two-stream encoder with inter-stream alignment modules to improve audio comparison capabilities and error detection F1 scores, and (2) a multimodal strategy that leverages both audio and symbolic scores by incorporating symbolic representations as decoder prompts, reducing ambiguity and improving F1 scores. We evaluate our method on the \\textit{MAESTRO-E} and \\textit{CocoChorales-E} datasets by measuring the F1 score for each note category. Compared to the previous state of the art, \\textit{LadderSym} more than doubles F1 for missed notes on \\textit{MAESTRO-E} (26.8\\% $\\rightarrow$ 56.3\\%) and improves extra note detection by 14.4 points (72.0\\% $\\rightarrow$ 86.4\\%). Similar gains are observed on \\textit{CocoChorales-E}. This work introduces general insights about comparison models that could inform sequence evaluation tasks for reinforcement Learning, human skill assessment, and model evaluation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LadderSymï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Transformer çš„æ–°å‹éŸ³ä¹ç»ƒä¹ é”™è¯¯æ£€æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•ä¸­åæœŸèåˆ(late fusion)å¯¼è‡´çš„è·¨æ¨¡æ€å¯¹æ¯”èƒ½åŠ›å—é™ä»¥åŠä¹è°±éŸ³é¢‘(score audio)å¼•å…¥çš„é¢‘ç‡é¢‘è°±æ­§ä¹‰é—®é¢˜ã€‚LadderSym å¼•å…¥äº†å¸¦æœ‰æµé—´å¯¹é½æ¨¡å—çš„åŒæµç¼–ç å™¨(two-stream encoder)ï¼Œæ˜¾è‘—å¢å¼ºäº†éŸ³é¢‘å¯¹æ¯”èƒ½åŠ›ã€‚è¯¥æ¨¡å‹è¿˜é‡‡ç”¨å¤šæ¨¡æ€ç­–ç•¥ï¼Œå°†ç¬¦å·åŒ–è¡¨ç¤º(symbolic representations)ä½œä¸ºè§£ç å™¨æç¤º(decoder prompts)ï¼Œé€šè¿‡ç»“åˆéŸ³é¢‘å’Œç¬¦å·ä¹è°±æœ‰æ•ˆå‡å°‘äº†æ£€æµ‹è¿‡ç¨‹ä¸­çš„æ­§ä¹‰ã€‚åœ¨ MAESTRO-E æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLadderSym åœ¨æ¼è®°éŸ³ç¬¦æ£€æµ‹çš„ F1 score ä¸Šç›¸æ¯”ç°æœ‰å…ˆè¿›æ¨¡å‹æå‡äº†ä¸€å€ä»¥ä¸Šï¼ˆä» 26.8% å¢è‡³ 56.3%ï¼‰ï¼Œä¸”åœ¨å¤šä½™éŸ³ç¬¦æ£€æµ‹ä¸Šæå‡äº† 14.4 ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤é¡¹å·¥ä½œä¸ä»…åœ¨éŸ³ä¹ç»ƒä¹ è¯„ä¼°é¢†åŸŸå–å¾—äº†çªç ´ï¼Œè¿˜ä¸ºå¼ºåŒ–å­¦ä¹ ã€äººç±»æŠ€èƒ½è¯„ä¼°ç­‰åºåˆ—è¯„ä»·ä»»åŠ¡æä¾›äº†é€šç”¨çš„æ¨¡å‹è®¾è®¡è§è§£ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Under Submission",
      "pdf_url": "https://arxiv.org/pdf/2510.08580v1",
      "published_date": "2025-09-16 02:15:06 UTC",
      "updated_date": "2025-09-16 02:15:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:18.759647+00:00"
    },
    {
      "arxiv_id": "2509.13368v2",
      "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation",
      "title_zh": "$Agent^2$ï¼šä¸€ç§é¢å‘å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨åŒ–çš„â€œæ™ºèƒ½ä½“ç”Ÿæˆæ™ºèƒ½ä½“â€æ¡†æ¶",
      "authors": [
        "Yuan Wei",
        "Xiaohan Shan",
        "Ran Miao",
        "Jianmin Li"
      ],
      "abstract": "Reinforcement learning (RL) agent development traditionally requires substantial expertise and iterative effort, often leading to high failure rates and limited accessibility. This paper introduces Agent$^2$, an LLM-driven agent-generates-agent framework for fully automated RL agent design. Agent$^2$ autonomously translates natural language task descriptions and environment code into executable RL solutions without human intervention. The framework adopts a dual-agent architecture: a Generator Agent that analyzes tasks and designs agents, and a Target Agent that is automatically generated and executed. To better support automation, RL development is decomposed into two stages, MDP modeling and algorithmic optimization, facilitating targeted and effective agent generation. Built on the Model Context Protocol, Agent$^2$ provides a unified framework for standardized agent creation across diverse environments and algorithms, incorporating adaptive training management and intelligent feedback analysis for continuous refinement. Extensive experiments on benchmarks including MuJoCo, MetaDrive, MPE, and SMAC show that Agent$^2$ outperforms manually designed baselines across all tasks, achieving up to 55\\% performance improvement with consistent average gains. By enabling a closed-loop, end-to-end automation pipeline, this work advances a new paradigm in which agents can design and optimize other agents, underscoring the potential of agent-generates-agent systems for automated AI development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Agent$^2$ï¼Œä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„â€œæ™ºèƒ½ä½“ç”Ÿæˆæ™ºèƒ½ä½“â€(agent-generates-agent)æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è®¾è®¡çš„å…¨è‡ªåŠ¨åŒ–ã€‚è¯¥æ¡†æ¶èƒ½è‡ªä¸»å°†è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°å’Œç¯å¢ƒä»£ç è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„ RL æ–¹æ¡ˆï¼Œå¹¶é€šè¿‡ Generator Agent è®¾è®¡å’Œ Target Agent æ‰§è¡Œçš„åŒæ™ºèƒ½ä½“æ¶æ„æ¶ˆé™¤äººå·¥å¹²é¢„ã€‚ä¸ºäº†æå‡æ•ˆç‡ï¼ŒAgent$^2$ å°†å¼€å‘æµç¨‹åˆ†è§£ä¸º MDP modeling å’Œ algorithmic optimization ä¸¤ä¸ªé˜¶æ®µï¼Œå¹¶åˆ©ç”¨ Model Context Protocol å®ç°äº†è·¨ç¯å¢ƒå’Œç®—æ³•çš„æ ‡å‡†åŒ–æ™ºèƒ½ä½“åˆ›å»ºã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé€šè¿‡é›†æˆè‡ªé€‚åº”è®­ç»ƒç®¡ç†å’Œæ™ºèƒ½åé¦ˆåˆ†ææœºåˆ¶ï¼Œå½¢æˆäº†æŒç»­ä¼˜åŒ–çš„é—­ç¯è‡ªåŠ¨åŒ–æµæ°´çº¿ã€‚å®éªŒè¡¨æ˜ï¼ŒAgent$^2$ åœ¨ MuJoCoã€MetaDriveã€MPE å’Œ SMAC ç­‰å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºäººå·¥è®¾è®¡çš„åŸºçº¿ï¼Œæœ€é«˜å®ç° 55% çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†æ™ºèƒ½ä½“è‡ªä¸»å¼€å‘ä¸ä¼˜åŒ– AI ç³»ç»Ÿçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures,4 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.13368v2",
      "published_date": "2025-09-16 02:14:39 UTC",
      "updated_date": "2025-09-30 05:06:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:21.968466+00:00"
    },
    {
      "arxiv_id": "2509.12569v1",
      "title": "Adaptive Sampling Scheduler",
      "title_zh": "è‡ªé€‚åº”é‡‡æ ·è°ƒåº¦å™¨",
      "authors": [
        "Qi Wang",
        "Shuliang Zhu",
        "Jinjia Zhou"
      ],
      "abstract": "Consistent distillation methods have evolved into effective techniques that significantly accelerate the sampling process of diffusion models. Although existing methods have achieved remarkable results, the selection of target timesteps during distillation mainly relies on deterministic or stochastic strategies, which often require sampling schedulers to be designed specifically for different distillation processes. Moreover, this pattern severely limits flexibility, thereby restricting the full sampling potential of diffusion models in practical applications. To overcome these limitations, this paper proposes an adaptive sampling scheduler that is applicable to various consistency distillation frameworks. The scheduler introduces three innovative strategies: (i) dynamic target timestep selection, which adapts to different consistency distillation frameworks by selecting timesteps based on their computed importance; (ii) Optimized alternating sampling along the solution trajectory by guiding forward denoising and backward noise addition based on the proposed time step importance, enabling more effective exploration of the solution space to enhance generation performance; and (iii) Utilization of smoothing clipping and color balancing techniques to achieve stable and high-quality generation results at high guidance scales, thereby expanding the applicability of consistency distillation models in complex generation scenarios. We validated the effectiveness and flexibility of the adaptive sampling scheduler across various consistency distillation methods through comprehensive experimental evaluations. Experimental results consistently demonstrated significant improvements in generative performance, highlighting the strong adaptability achieved by our method.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ Adaptive Sampling Schedulerï¼Œæ—¨åœ¨è§£å†³å½“å‰ä¸€è‡´æ€§è’¸é¦ (Consistency Distillation) æ–¹æ³•åœ¨æ‰©æ•£æ¨¡å‹é‡‡æ ·åŠ é€Ÿè¿‡ç¨‹ä¸­ï¼Œå› ä¾èµ–ç¡®å®šæ€§æˆ–éšæœºç­–ç•¥é€‰æ‹©ç›®æ ‡æ—¶é—´æ­¥è€Œå¯¼è‡´çš„çµæ´»æ€§å—é™å’Œé‡‡æ ·æ½œåŠ›å—é˜»ç­‰é—®é¢˜ã€‚è¯¥è°ƒåº¦å™¨å¼•å…¥äº†åŠ¨æ€ç›®æ ‡æ—¶é—´æ­¥é€‰æ‹©ç­–ç•¥ï¼Œèƒ½å¤Ÿæ ¹æ®è®¡ç®—å‡ºçš„é‡è¦æ€§è‡ªé€‚åº”åœ°ä¸ºä¸åŒçš„ä¸€è‡´æ€§è’¸é¦æ¡†æ¶é€‰æ‹©æœ€ä½³æ—¶é—´æ­¥ã€‚åŒæ—¶ï¼Œç ”ç©¶é€šè¿‡åŸºäºæ—¶é—´æ­¥é‡è¦æ€§çš„ä¼˜åŒ–äº¤æ›¿é‡‡æ ·æ–¹æ³•ï¼Œæœ‰æ•ˆå¼•å¯¼å‰å‘å»å™ªå’Œåå‘åŠ å™ªè¿‡ç¨‹ï¼Œä»è€Œåœ¨è§£ç©ºé—´å†…è¿›è¡Œæ›´å……åˆ†çš„æ¢ç´¢ä»¥å¢å¼ºç”Ÿæˆæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ¡†æ¶è¿˜ç»“åˆäº†å¹³æ»‘è£å‰ª (Smoothing Clipping) å’Œè‰²å½©å¹³è¡¡æŠ€æœ¯ï¼Œç¡®ä¿åœ¨ High Guidance Scales ä¸‹å®ç°ç¨³å®šä¸”é«˜è´¨é‡çš„ç”Ÿæˆç»“æœï¼Œæ‰©å±•äº†æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥è‡ªé€‚åº”é‡‡æ ·è°ƒåº¦å™¨åœ¨å¤šç§ä¸€è‡´æ€§è’¸é¦æ–¹æ³•ä¸Šå±•ç°å‡ºå“è¶Šçš„çµæ´»æ€§ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè¡¨ç°å¹¶ä½“ç°äº†æå¼ºçš„é€‚é…èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 10 figures,2 Tables, 18 Equations",
      "pdf_url": "https://arxiv.org/pdf/2509.12569v1",
      "published_date": "2025-09-16 01:51:16 UTC",
      "updated_date": "2025-09-16 01:51:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:23.763919+00:00"
    },
    {
      "arxiv_id": "2509.19339v1",
      "title": "Multi-population Ensemble Genetic Programming via Cooperative Coevolution and Multi-view Learning for Classification",
      "title_zh": "åŸºäºåˆä½œååŒæ¼”åŒ–ä¸å¤šè§†å›¾å­¦ä¹ çš„é¢å‘åˆ†ç±»å¤šç§ç¾¤é›†æˆé—ä¼ ç¼–ç¨‹",
      "authors": [
        "Mohammad Sadegh Khorshidi",
        "Navid Yazdanjue",
        "Hassan Gharoun",
        "Mohammad Reza Nikoo",
        "Fang Chen",
        "Amir H. Gandomi"
      ],
      "abstract": "This paper introduces Multi-population Ensemble Genetic Programming (MEGP), a computational intelligence framework that integrates cooperative coevolution and the multiview learning paradigm to address classification challenges in high-dimensional and heterogeneous feature spaces. MEGP decomposes the input space into conditionally independent feature subsets, enabling multiple subpopulations to evolve in parallel while interacting through a dynamic ensemble-based fitness mechanism. Each individual encodes multiple genes whose outputs are aggregated via a differentiable softmax-based weighting layer, enhancing both model interpretability and adaptive decision fusion. A hybrid selection mechanism incorporating both isolated and ensemble-level fitness promotes inter-population cooperation while preserving intra-population diversity. This dual-level evolutionary dynamic facilitates structured search exploration and reduces premature convergence. Experimental evaluations across eight benchmark datasets demonstrate that MEGP consistently outperforms a baseline GP model in terms of convergence behavior and generalization performance. Comprehensive statistical analyses validate significant improvements in Log-Loss, Precision, Recall, F1 score, and AUC. MEGP also exhibits robust diversity retention and accelerated fitness gains throughout evolution, highlighting its effectiveness for scalable, ensemble-driven evolutionary learning. By unifying population-based optimization, multi-view representation learning, and cooperative coevolution, MEGP contributes a structurally adaptive and interpretable framework that advances emerging directions in evolutionary machine learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¤šç§ç¾¤é›†æˆé—ä¼ è§„åˆ’(Multi-population Ensemble Genetic Programming, MEGP)æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨åˆä½œååŒè¿›åŒ–(Cooperative Coevolution)å’Œå¤šè§†å›¾å­¦ä¹ (Multi-view Learning)èŒƒå¼è§£å†³é«˜ç»´å¼‚æ„ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†ç±»æŒ‘æˆ˜ã€‚MEGPé€šè¿‡å°†è¾“å…¥ç©ºé—´åˆ†è§£ä¸ºç›¸äº’ç‹¬ç«‹çš„ç‰¹å¾å­é›†ï¼Œå…è®¸å„å­ç§ç¾¤åœ¨åˆ©ç”¨åŠ¨æ€é›†æˆé€‚åº”åº¦æœºåˆ¶è¿›è¡Œäº¤äº’çš„åŒæ—¶å¹¶è¡Œæ¼”åŒ–ã€‚æ¯ä¸ªä¸ªä½“åˆ©ç”¨å¯å¾®åˆ†çš„SoftmaxåŠ æƒå±‚èšåˆå¤šåŸºå› è¾“å‡ºï¼Œåœ¨å¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§çš„åŒæ—¶å®ç°äº†è‡ªé€‚åº”å†³ç­–èåˆã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ç»“åˆéš”ç¦»ä¸é›†æˆåŒé‡å±‚é¢çš„æ··åˆé€‰æ‹©æœºåˆ¶ï¼Œæœ‰æ•ˆå¹³è¡¡äº†ç§ç¾¤é—´çš„åä½œä¸ç§ç¾¤å†…çš„å¤šæ ·æ€§ï¼Œä»è€Œä¼˜åŒ–äº†æœç´¢æ•ˆç‡å¹¶å‡å°‘è¿‡æ—©æ”¶æ•›ã€‚åœ¨å…«ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼ŒMEGPåœ¨Log-Lossã€Precisionã€Recallã€F1åˆ†æ•°åŠAUCç­‰æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºå‡†GPæ¨¡å‹ã€‚è¯¥æ¡†æ¶å±•ç°äº†å“è¶Šçš„æ”¶æ•›è¡Œä¸ºå’Œæ³›åŒ–æ€§èƒ½ï¼Œä¸ºè¿›åŒ–æœºå™¨å­¦ä¹ é¢†åŸŸæä¾›äº†ä¸€ç§ç»“æ„è‡ªé€‚åº”ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„é›†æˆå­¦ä¹ æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "59 Pages, 68 Figures, 27 Tables",
      "pdf_url": "https://arxiv.org/pdf/2509.19339v1",
      "published_date": "2025-09-16 01:32:04 UTC",
      "updated_date": "2025-09-16 01:32:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:34.056189+00:00"
    },
    {
      "arxiv_id": "2509.12543v3",
      "title": "Human + AI for Accelerating Ad Localization Evaluation",
      "title_zh": "äººæœºååŒåŠ é€Ÿå¹¿å‘Šæœ¬åœ°åŒ–è¯„ä¼°",
      "authors": [
        "Harshit Rajgarhia",
        "Shivali Dalmia",
        "Mengyang Zhao",
        "Mukherji Abhishek",
        "Kiran Ganesh"
      ],
      "abstract": "Adapting advertisements for multilingual audiences requires more than simple text translation; it demands preservation of visual consistency, spatial alignment, and stylistic integrity across diverse languages and formats. We introduce a structured framework that combines automated components with human oversight to address the complexities of advertisement localization. To the best of our knowledge, this is the first work to integrate scene text detection, inpainting, machine translation (MT), and text reimposition specifically for accelerating ad localization evaluation workflows. Qualitative results across six locales demonstrate that our approach produces semantically accurate and visually coherent localized advertisements, suitable for deployment in real-world workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è·¨è¯­è¨€å¹¿å‘Šæœ¬åœ°åŒ–(ad localization)ä¸­è§†è§‰ä¸€è‡´æ€§ã€ç©ºé—´å¯¹é½åŠé£æ ¼å®Œæ•´æ€§çš„ä¿æŒæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆè‡ªåŠ¨åŒ–ç»„ä»¶ä¸äººå·¥ç›‘ç£çš„ç»“æ„åŒ–æ¡†æ¶ã€‚ä½œä¸ºé¦–ä¸ªä¸“é—¨ä¸ºåŠ é€Ÿå¹¿å‘Šæœ¬åœ°åŒ–è¯„ä¼°æµç¨‹è€Œè®¾è®¡çš„å·¥ä½œï¼Œè¯¥æ¡†æ¶é›†æˆäº†åœºæ™¯æ–‡æœ¬æ£€æµ‹(scene text detection)ã€å›¾åƒä¿®å¤(inpainting)ã€æœºå™¨ç¿»è¯‘(machine translation)ä»¥åŠæ–‡æœ¬é‡æ–°æ¤å…¥(text reimposition)ç­‰å…³é”®æŠ€æœ¯ã€‚é€šè¿‡å°†äººå·¥æ™ºèƒ½çš„è‡ªåŠ¨åŒ–èƒ½åŠ›ä¸äººç±»ä¸“å®¶çš„å®¡æ ¸æœºåˆ¶ç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°å¤„ç†äº†å¹¿å‘Šé€‚é…è¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ã€‚åœ¨å…­ä¸ªè¯­è¨€åŒºåŸŸè¿›è¡Œçš„å®šæ€§è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿç”Ÿæˆè¯­ä¹‰å‡†ç¡®ä¸”è§†è§‰è¿è´¯çš„æœ¬åœ°åŒ–å¹¿å‘Šï¼Œè¯æ˜äº†å…¶åœ¨å®é™…ç”Ÿäº§å·¥ä½œæµä¸­çš„åº”ç”¨æ½œåŠ›å’Œéƒ¨ç½²ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12543v3",
      "published_date": "2025-09-16 00:52:41 UTC",
      "updated_date": "2025-10-06 21:30:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:48.393130+00:00"
    },
    {
      "arxiv_id": "2509.12541v1",
      "title": "zELO: ELO-inspired Training Method for Rerankers and Embedding Models",
      "title_zh": "zELOï¼šå— ELO å¯å‘çš„é‡æ’åºå™¨ä¸åµŒå…¥æ¨¡å‹è®­ç»ƒæ–¹æ³•",
      "authors": [
        "Nicholas Pipitone",
        "Ghita Houir Alami",
        "Advaith Avadhanam",
        "Anton Kaminskyi",
        "Ashley Khoo"
      ],
      "abstract": "We introduce a novel training methodology named zELO, which optimizes retrieval performance via the analysis that ranking tasks are statically equivalent to a Thurstone model. Based on the zELO method, we use unsupervised data in order train a suite of state-of-the-art open-weight reranker models: zerank-1 and zerank-1-small. These models achieve the highest retrieval scores in multiple domains, including finance, legal, code, and STEM, outperforming closed-source proprietary rerankers on both NDCG@10 and Recall. These models also demonstrate great versatility, maintaining their 0-shot performance on out-of-domain and private customer datasets. The training data included 112,000 queries and 100 documents per query, and was trained end-to-end from unannotated queries and documents in less than 10,000 H100-hours.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ç§åä¸ºzELOçš„æ–°å‹è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å°†æ’åºä»»åŠ¡è§†ä¸ºä¸Thurstone modelé™æ€ç­‰æ•ˆçš„åˆ†ææ¥ä¼˜åŒ–æ£€ç´¢æ€§èƒ½ã€‚åŸºäºzELOæ–¹æ³•ï¼Œä½œè€…åˆ©ç”¨æ— ç›‘ç£æ•°æ®è®­ç»ƒäº†ä¸€ç³»åˆ—å…·æœ‰é¢†åŸŸé¢†å…ˆæ°´å¹³çš„å¼€æºé‡æ’åºæ¨¡å‹zerank-1å’Œzerank-1-smallã€‚è¿™äº›æ¨¡å‹åœ¨é‡‘èã€æ³•å¾‹ã€ä»£ç å’ŒSTEMç­‰å¤šä¸ªé¢†åŸŸå‡å–å¾—äº†æé«˜çš„æ£€ç´¢åˆ†æ•°ï¼Œåœ¨NDCG@10å’ŒRecallæŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†é—­æºä¸“æœ‰é‡æ’åºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹è¿˜å±•ç¤ºäº†å‡ºè‰²çš„é€šç”¨æ€§ï¼Œåœ¨é¢†åŸŸå¤–å’Œç§æœ‰å®¢æˆ·æ•°æ®é›†ä¸Šä¿æŒäº†ä¼˜å¼‚çš„0-shotæ€§èƒ½ã€‚è¯¥è®­ç»ƒæ–¹æ¡ˆä»…éœ€ä¸åˆ°10,000ä¸ªH100å°æ—¶ï¼Œå³å¯ä»æœªæ ‡æ³¨çš„æŸ¥è¯¢å’Œæ–‡æ¡£ä¸­å®Œæˆç«¯åˆ°ç«¯è®­ç»ƒï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„é«˜æ•ˆæ€§ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 9 sections, 17 figures and tables",
      "pdf_url": "https://arxiv.org/pdf/2509.12541v1",
      "published_date": "2025-09-16 00:44:08 UTC",
      "updated_date": "2025-09-16 00:44:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:04:54.501908+00:00"
    },
    {
      "arxiv_id": "2509.12534v1",
      "title": "DeepEyeNet: Generating Medical Report for Retinal Images",
      "title_zh": "DeepEyeNetï¼šè§†ç½‘è†œå›¾åƒåŒ»ç–—æŠ¥å‘Šç”Ÿæˆ",
      "authors": [
        "Jia-Hong Huang"
      ],
      "abstract": "The increasing prevalence of retinal diseases poses a significant challenge to the healthcare system, as the demand for ophthalmologists surpasses the available workforce. This imbalance creates a bottleneck in diagnosis and treatment, potentially delaying critical care. Traditional methods of generating medical reports from retinal images rely on manual interpretation, which is time-consuming and prone to errors, further straining ophthalmologists' limited resources. This thesis investigates the potential of Artificial Intelligence (AI) to automate medical report generation for retinal images. AI can quickly analyze large volumes of image data, identifying subtle patterns essential for accurate diagnosis. By automating this process, AI systems can greatly enhance the efficiency of retinal disease diagnosis, reducing doctors' workloads and enabling them to focus on more complex cases. The proposed AI-based methods address key challenges in automated report generation: (1) A multi-modal deep learning approach captures interactions between textual keywords and retinal images, resulting in more comprehensive medical reports; (2) Improved methods for medical keyword representation enhance the system's ability to capture nuances in medical terminology; (3) Strategies to overcome RNN-based models' limitations, particularly in capturing long-range dependencies within medical descriptions; (4) Techniques to enhance the interpretability of the AI-based report generation system, fostering trust and acceptance in clinical practice. These methods are rigorously evaluated using various metrics and achieve state-of-the-art performance. This thesis demonstrates AI's potential to revolutionize retinal disease diagnosis by automating medical report generation, ultimately improving clinical efficiency, diagnostic accuracy, and patient care.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†ç½‘è†œç–¾ç—…æ—¥ç›Šç››è¡Œä¸”çœ¼ç§‘åŒ»ç”Ÿèµ„æºçŸ­ç¼ºçš„æŒ‘æˆ˜ï¼Œæå‡ºäº† DeepEyeNet ç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°è§†ç½‘è†œå›¾åƒåŒ»ç–—æŠ¥å‘Šçš„è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å¤šæ¨¡æ€æ·±åº¦å­¦ä¹  (multi-modal deep learning) æ–¹æ³•ï¼Œæœ‰æ•ˆæ•è·äº†æ–‡æœ¬å…³é”®è¯ä¸å›¾åƒä¹‹é—´çš„äº¤äº’ä½œç”¨ï¼Œä»è€Œç”Ÿæˆæ›´ä¸ºå…¨é¢çš„æŠ¥å‘Šå†…å®¹ã€‚ç ”ç©¶é€šè¿‡æ”¹è¿›åŒ»å­¦å…³é”®è¯çš„è¡¨å¾æ–¹å¼ï¼Œæå‡äº†æ¨¡å‹æ•æ‰æœ¯è¯­ç»†å¾®å·®åˆ«çš„èƒ½åŠ›ï¼Œå¹¶è§£å†³äº† RNN-based models åœ¨å¤„ç†åŒ»å­¦æè¿°é•¿è·ç¦»ä¾èµ–å…³ç³»æ—¶çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼•å…¥äº†å¢å¼ºç³»ç»Ÿå¯è§£é‡Šæ€§ (interpretability) çš„æŠ€æœ¯ï¼Œä»¥æå‡ä¸´åºŠåº”ç”¨ä¸­çš„ä¿¡ä»»åº¦ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºè¯¥æ–¹æ³•è¾¾åˆ°äº† state-of-the-art æ€§èƒ½ï¼Œè¯æ˜äº† AI åœ¨æé«˜ä¸´åºŠæ•ˆç‡ã€è¯Šæ–­å‡†ç¡®æ€§å’Œæ”¹å–„æ‚£è€…æŠ¤ç†æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "The paper is accepted by the Conference on Information and Knowledge Management (CIKM), 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.12534v1",
      "published_date": "2025-09-16 00:18:56 UTC",
      "updated_date": "2025-09-16 00:18:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:05:10.986409+00:00"
    },
    {
      "arxiv_id": "2509.12531v1",
      "title": "Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning",
      "title_zh": "é¢„è®­ç»ƒè§†è§‰è¡¨å¾åœ¨åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ çš„å…³é”®åœºæ™¯ä¸‹å…·æœ‰æ³›åŒ–æ€§",
      "authors": [
        "Scott Jones",
        "Liyou Zhou",
        "Sebastian W. Pattinson"
      ],
      "abstract": "In visuomotor policy learning, the control policy for the robotic agent is derived directly from visual inputs. The typical approach, where a policy and vision encoder are trained jointly from scratch, generalizes poorly to novel visual scene changes. Using pre-trained vision models (PVMs) to inform a policy network improves robustness in model-free reinforcement learning (MFRL). Recent developments in Model-based reinforcement learning (MBRL) suggest that MBRL is more sample-efficient than MFRL. However, counterintuitively, existing work has found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness in MBRL, specifically on generalization under visual domain shifts. We show that, in scenarios with severe shifts, PVMs perform much better than a baseline model trained from scratch. We further investigate the effects of varying levels of fine-tuning of PVMs. Our results show that partial fine-tuning can maintain the highest average task performance under the most extreme distribution shifts. Our results demonstrate that PVMs are highly successful in promoting robustness in visual policy learning, providing compelling evidence for their wider adoption in model-based robotic learning applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é¢„è®­ç»ƒè§†è§‰æ¨¡å‹ (PVMs) åœ¨åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹  (MBRL) ä¸­çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«å…³æ³¨å…¶åœ¨è§†è§‰é¢†åŸŸåç§» (visual domain shifts) ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é’ˆå¯¹ä»¥å¾€ç ”ç©¶è®¤ä¸º PVMs åœ¨ MBRL ä¸­æ— æ•ˆçš„è§‚ç‚¹ï¼Œæœ¬æ–‡æ·±å…¥åˆ†æäº†å…¶åœ¨æœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹  (visuomotor policy learning) ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨é¢ä¸´ä¸¥é‡çš„è§†è§‰åœºæ™¯å˜åŒ–æ—¶ï¼Œä½¿ç”¨ PVMs çš„æ¨¡å‹æ¯”ä»é›¶å¼€å§‹è®­ç»ƒçš„åŸºçº¿æ¨¡å‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒç¨‹åº¦çš„å¾®è°ƒ (fine-tuning)ï¼Œç»“æœè¡¨æ˜éƒ¨åˆ†å¾®è°ƒ (partial fine-tuning) èƒ½å¤Ÿåœ¨æœ€æç«¯çš„æ•°æ®åˆ†å¸ƒåç§»ä¸‹ç»´æŒæœ€é«˜çš„å¹³å‡ä»»åŠ¡æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜äº† PVMs åœ¨å¢å¼ºè§†è§‰ç­–ç•¥å­¦ä¹ é²æ£’æ€§æ–¹é¢çš„å·¨å¤§æˆåŠŸï¼Œå¹¶ä¸ºåœ¨ MBRL æœºå™¨äººåº”ç”¨ä¸­æ›´å¹¿æ³›åœ°é‡‡ç”¨é¢„è®­ç»ƒè¡¨å¾æä¾›äº†æœ‰åŠ›è¯æ®ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.12531v1",
      "published_date": "2025-09-16 00:13:14 UTC",
      "updated_date": "2025-09-16 00:13:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T19:05:07.295229+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 174,
  "processed_papers_count": 174,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T19:06:04.964235+00:00"
}