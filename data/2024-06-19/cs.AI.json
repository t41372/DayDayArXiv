{
  "date": "2024-06-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-19 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、多模态理解和实际应用，强调大型语言模型（LLMs）的知识蒸馏、鲁棒性提升和医疗领域创新，令人印象深刻的包括 GPT-4o 评估以及知识图增强 LLMs 的研究，而知名学者如 Jiliang Tang 和 Vince D. Calhoun 的作品突出在图神经网络和多模态医学分析上。\n\n### 重点论文讨论\n我们先聊聊 AI 和 LLMs 相关的高影响力论文，这些工作推动了模型鲁棒性和实际应用。接着，简要提及图神经网络和医学 AI 的亮点，最后快速掠过其他领域。\n\n1. **Putting GPT-4o to the Sword: A Comprehensive Evaluation of Language, Vision, Speech, and Multimodal Proficiency**  \n   这篇论文评估了 GPT-4o 在语言、视觉、语音和多模态任务上的性能，发现其在少样本学习中表现出色，但处理复杂输入时存在局限，主要贡献是通过标准化基准揭示了其优势和不足，提升了对多模态 LLM 的评估框架。\n\n2. **ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World**  \n   作者包括 Weixiang Yan 等，论文提出 ClinicalLab 框架，用于评估和优化 LLM 在多部门临床诊断中的表现，通过新指标和数据集（如覆盖 24 个部门），发现 LLM 在不同部门表现差异大，主要贡献是改善了医疗代理的实际适用性。\n\n3. **Knowledge Graph-Enhanced Large Language Models via Path Selection**  \n   作者如 Haochen Liu 和 Jundong Li，论文引入 KELP 框架，利用知识图谱路径选择增强 LLM 的事实准确性，避免幻觉问题，主要发现是通过细粒度语义匹配显著提升了 LLM 在知识冲突场景下的性能。\n\n4. **A Pure Transformer Pretraining Framework on Text-attributed Graphs**  \n   作者包括 Jiliang Tang，这篇工作提出 GSPT 框架，使用 Transformer 在文本属性图上进行预训练，捕捉节点特征的交互模式，主要贡献是提升了跨图泛化能力，在节点分类和链接预测任务中表现出色。\n\n5. **SDQ: Sparse Decomposed Quantization for LLM Inference**  \n   论文提出 SDQ 方法，结合结构稀疏和量化技术优化 LLM 推理，实现了 4 倍计算吞吐量而质量损失小于 1%，主要发现是显著提高了 LLM 在资源受限环境下的效率。\n\n6. **AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding**  \n   作者如 Alessandro Suglia，这篇论文开发了 AlanaVLM 模型和 EVUD 数据集，用于第一人称视频理解，实现了多模态任务的 SOTA 性能，主要贡献是通过参数高效方法提升了机器人和可穿戴设备的交互能力。\n\n7. **GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation**  \n   论文构建 GenAI-Bench 基准，评估生成模型在组合文本到视觉任务上的表现，并通过 VQAScore 指标优化生成质量，主要发现是改进了生成模型的人类对齐效果，尤其在复杂提示上。\n\n8. **EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy**  \n   这篇工作提出 EndoUIC 模型，使用扩散 Transformer 统一纠正内窥镜图像的照明问题，并构建了 CEC 数据集，主要贡献是通过迭代纹理增强提高了诊断准确性，适用于外科辅助。\n\n其他领域的论文，如 \"DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection\"（提出 DPO 方法提升 3D 检测鲁棒性）、\"Trapezoidal Gradient Descent for Effective Reinforcement Learning in Spiking Networks\"（优化脉冲神经网络的梯度下降），以及一些强化学习和图优化工作，展示了技术创新，但影响力相对有限，仅快速提及其在特定任务上的性能提升。总之，今天的论文强调了 AI 模型的实用性和鲁棒性，期待后续应用。",
  "papers": [
    {
      "arxiv_id": "2406.13891v2",
      "title": "DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoxiao Chen",
        "Zixin Wang",
        "Yadan Luo",
        "Sen Wang",
        "Zi Huang"
      ],
      "abstract": "LiDAR-based 3D object detection has seen impressive advances in recent times.\nHowever, deploying trained 3D detectors in the real world often yields\nunsatisfactory performance when the distribution of the test data significantly\ndeviates from the training data due to different weather conditions, object\nsizes, \\textit{etc}. A key factor in this performance degradation is the\ndiminished generalizability of pre-trained models, which creates a sharp loss\nlandscape during training. Such sharpness, when encountered during testing, can\nprecipitate significant performance declines, even with minor data variations.\nTo address the aforementioned challenges, we propose \\textbf{dual-perturbation\noptimization (DPO)} for \\textbf{\\underline{T}est-\\underline{t}ime\n\\underline{A}daptation in \\underline{3}D \\underline{O}bject\n\\underline{D}etection (TTA-3OD)}. We minimize the sharpness to cultivate a flat\nloss landscape to ensure model resiliency to minor data variations, thereby\nenhancing the generalization of the adaptation process. To fully capture the\ninherent variability of the test point clouds, we further introduce adversarial\nperturbation to the input BEV features to better simulate the noisy test\nenvironment. As the dual perturbation strategy relies on trustworthy\nsupervision signals, we utilize a reliable Hungarian matcher to filter out\npseudo-labels sensitive to perturbations. Additionally, we introduce early\nHungarian cutoff to avoid error accumulation from incorrect pseudo-labels by\nhalting the adaptation process. Extensive experiments across three types of\ntransfer tasks demonstrate that the proposed DPO significantly surpasses\nprevious state-of-the-art approaches, specifically on Waymo $\\rightarrow$\nKITTI, outperforming the most competitive baseline by 57.72\\% in\n$\\text{AP}_\\text{3D}$ and reaching 91\\% of the fully supervised upper bound.",
      "tldr_zh": "该研究针对 LiDAR-based 3D object detection 在测试数据分布（如天气或物体大小变化）与训练数据偏差时性能下降的问题，提出了一种双扰动优化（DPO）方法，用于测试时适应（TTA-3OD）。DPO 通过最小化损失景观的锐利度来提升模型对数据变异的鲁棒性，同时对输入 BEV features 引入对抗扰动以模拟噪声环境，并利用可靠的 Hungarian matcher 过滤伪标签以及 early Hungarian cutoff 来避免错误积累。实验结果显示，DPO 在三个转移任务中显著优于现有方法，例如在 Waymo → KITTI 任务上，AP3D 指标比最强基线提升 57.72%，并达到 91% 的完全监督上限，从而提高了 3D 物体检测的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in ACM Multimedia 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13891v2",
      "published_date": "2024-06-19 23:46:08 UTC",
      "updated_date": "2024-07-28 07:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:09:50.001555"
    },
    {
      "arxiv_id": "2406.13890v2",
      "title": "ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World",
      "title_zh": "翻译失败",
      "authors": [
        "Weixiang Yan",
        "Haitian Liu",
        "Tengxiao Wu",
        "Qian Chen",
        "Wen Wang",
        "Haoyuan Chai",
        "Jiayi Wang",
        "Weishan Zhao",
        "Yixin Zhang",
        "Renjun Zhang",
        "Li Zhu",
        "Xuandong Zhao"
      ],
      "abstract": "LLMs have achieved significant performance progress in various NLP\napplications. However, LLMs still struggle to meet the strict requirements for\naccuracy and reliability in the medical field and face many challenges in\nclinical applications. Existing clinical diagnostic evaluation benchmarks for\nevaluating medical agents powered by LLMs have severe limitations. Firstly,\nmost existing medical evaluation benchmarks face the risk of data leakage or\ncontamination. Secondly, existing benchmarks often neglect the characteristics\nof multiple departments and specializations in modern medical practice.\nThirdly, existing evaluation methods are limited to multiple-choice questions,\nwhich do not align with the real-world diagnostic scenarios. Lastly, existing\nevaluation methods lack comprehensive evaluations of end-to-end real clinical\nscenarios. These limitations in benchmarks in turn obstruct advancements of\nLLMs and agents for medicine. To address these limitations, we introduce\nClinicalLab, a comprehensive clinical diagnosis agent alignment suite.\nClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical\ndiagnostic evaluation benchmark for evaluating medical agents and LLMs.\nClinicalBench is based on real cases that cover 24 departments and 150\ndiseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for\nevaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate\n17 LLMs and find that their performance varies significantly across different\ndepartments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,\nan end-to-end clinical agent that aligns with real-world clinical diagnostic\npractices. We systematically investigate the performance and applicable\nscenarios of variants of ClinicalAgent on ClinicalBench. Our findings\ndemonstrate the importance of aligning with modern medical practices in\ndesigning medical agents.",
      "tldr_zh": "该研究指出，现有的LLMs在医疗领域面临准确性和可靠性挑战，因为现有临床诊断评估基准存在数据泄露风险、多部门特性忽略、仅限于选择题以及缺乏端到端真实场景评估等问题。为解决这些问题，论文引入ClinicalLab，一个全面的临床诊断代理对齐套件，包括基于真实案例的ClinicalBench（覆盖24个部门和150个疾病）和四个新指标ClinicalMetrics，用于评估LLMs的表现。实验评估了17个LLMs，发现它们在不同部门的表现差异显著，并基于此提出ClinicalAgent，一个端到端临床代理，以更好地与真实临床实践对齐。结果强调，在设计医疗代理时，与现代医疗实践对齐至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13890v2",
      "published_date": "2024-06-19 23:44:25 UTC",
      "updated_date": "2024-10-09 19:09:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:10:01.774975"
    },
    {
      "arxiv_id": "2406.13885v1",
      "title": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Li",
        "Tianlong Xu",
        "Jiliang Tang",
        "Qingsong Wen"
      ],
      "abstract": "Knowledge tagging for questions plays a crucial role in contemporary\nintelligent educational applications, including learning progress diagnosis,\npractice question recommendations, and course content organization.\nTraditionally, these annotations are always conducted by pedagogical experts,\nas the task requires not only a strong semantic understanding of both question\nstems and knowledge definitions but also deep insights into connecting\nquestion-solving logic with corresponding knowledge concepts. With the recent\nemergence of advanced text encoding algorithms, such as pre-trained language\nmodels, many researchers have developed automatic knowledge tagging systems\nbased on calculating the semantic similarity between the knowledge and question\nembeddings. In this paper, we explore automating the task using Large Language\nModels (LLMs), in response to the inability of prior encoding-based methods to\ndeal with the hard cases which involve strong domain knowledge and complicated\nconcept definitions. By showing the strong performance of zero- and few-shot\nresults over math questions knowledge tagging tasks, we demonstrate LLMs' great\npotential in conquering the challenges faced by prior methods. Furthermore, by\nproposing a reinforcement learning-based demonstration retriever, we\nsuccessfully exploit the great potential of different-sized LLMs in achieving\nbetter performance results while keeping the in-context demonstration usage\nefficiency high.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）自动为数学问题进行知识标记，以解决传统方法（如基于语义相似性的编码算法）在处理复杂领域知识和概念定义时的局限性。LLMs 在零样本和少样本设置中表现出色，显著提升了知识标记的准确性。作者提出了一种基于强化学习的灵活演示检索器（reinforcement learning-based demonstration retriever），优化不同规模 LLMs 的性能，同时保持上下文演示的高效利用。该方法为智能教育应用，如学习诊断和问题推荐，提供更可靠的自动化解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13885v1",
      "published_date": "2024-06-19 23:30:01 UTC",
      "updated_date": "2024-06-19 23:30:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:10:12.815116"
    },
    {
      "arxiv_id": "2406.13873v1",
      "title": "A Pure Transformer Pretraining Framework on Text-attributed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Song",
        "Haitao Mao",
        "Jiachen Xiao",
        "Jingzhe Liu",
        "Zhikai Chen",
        "Wei Jin",
        "Carl Yang",
        "Jiliang Tang",
        "Hui Liu"
      ],
      "abstract": "Pretraining plays a pivotal role in acquiring generalized knowledge from\nlarge-scale data, achieving remarkable successes as evidenced by large models\nin CV and NLP. However, progress in the graph domain remains limited due to\nfundamental challenges such as feature heterogeneity and structural\nheterogeneity. Recently, increasing efforts have been made to enhance node\nfeature quality with Large Language Models (LLMs) on text-attributed graphs\n(TAGs), demonstrating superiority to traditional bag-of-words or word2vec\ntechniques. These high-quality node features reduce the previously critical\nrole of graph structure, resulting in a modest performance gap between Graph\nNeural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).\nMotivated by this, we introduce a feature-centric pretraining perspective by\ntreating graph structure as a prior and leveraging the rich, unified feature\nspace to learn refined interaction patterns that generalizes across graphs. Our\nframework, Graph Sequence Pretraining with Transformer (GSPT), samples node\ncontexts through random walks and employs masked feature reconstruction to\ncapture pairwise proximity in the LLM-unified feature space using a standard\nTransformer. By utilizing unified text representations rather than varying\nstructures, our framework achieves significantly better transferability among\ngraphs within the same domain. GSPT can be easily adapted to both node\nclassification and link prediction, demonstrating promising empirical success\non various datasets.",
      "tldr_zh": "该论文提出了一种纯Transformer预训练框架GSPT（Graph Sequence Pretraining with Transformer），针对文本属性图(TAGs)中的特征异质性和结构异质性问题，将图结构视为先验，重点利用Large Language Models (LLMs)生成的统一特征空间学习交互模式。具体方法包括通过随机游走采样节点上下文，并采用masked feature reconstruction在Transformer中捕获成对邻近性，从而提升框架在不同图之间的可转移性。实验结果显示，GSPT在节点分类和链接预测任务上，在各种数据集上表现出色，显著优于传统Graph Neural Networks (GNNs)和Multi-Layer Perceptrons (MLPs)。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13873v1",
      "published_date": "2024-06-19 22:30:08 UTC",
      "updated_date": "2024-06-19 22:30:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:10:26.987226"
    },
    {
      "arxiv_id": "2406.13868v1",
      "title": "SDQ: Sparse Decomposed Quantization for LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Geonhwa Jeong",
        "Po-An Tsai",
        "Stephen W. Keckler",
        "Tushar Krishna"
      ],
      "abstract": "Recently, large language models (LLMs) have shown surprising performance in\ntask-specific workloads as well as general tasks with the given prompts.\nHowever, to achieve unprecedented performance, recent LLMs use billions to\ntrillions of parameters, which hinder the wide adaptation of those models due\nto their extremely large compute and memory requirements. To resolve the issue,\nvarious model compression methods are being actively investigated. In this\nwork, we propose SDQ (Sparse Decomposed Quantization) to exploit both\nstructured sparsity and quantization to achieve both high compute and memory\nefficiency. From our evaluations, we observe that SDQ can achieve 4x effective\ncompute throughput with <1% quality drop.",
      "tldr_zh": "大型语言模型 (LLMs) 由于参数规模庞大，面临高计算和内存需求的挑战，导致其应用受限。论文提出 SDQ（Sparse Decomposed Quantization）方法，通过结合结构化稀疏性和量化技术，实现高效的模型压缩。实验评估显示，SDQ 能将计算吞吐量提高 4 倍，同时模型性能下降不到 1%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2406.13868v1",
      "published_date": "2024-06-19 22:12:51 UTC",
      "updated_date": "2024-06-19 22:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:10:36.027914"
    },
    {
      "arxiv_id": "2406.13862v1",
      "title": "Knowledge Graph-Enhanced Large Language Models via Path Selection",
      "title_zh": "知识图谱增强的大型语言模型通过路径选择",
      "authors": [
        "Haochen Liu",
        "Song Wang",
        "Yaochen Zhu",
        "Yushun Dong",
        "Jundong Li"
      ],
      "abstract": "Large Language Models (LLMs) have shown unprecedented performance in various\nreal-world applications. However, they are known to generate factually\ninaccurate outputs, a.k.a. the hallucination problem. In recent years,\nincorporating external knowledge extracted from Knowledge Graphs (KGs) has\nbecome a promising strategy to improve the factual accuracy of LLM-generated\noutputs. Nevertheless, most existing explorations rely on LLMs themselves to\nperform KG knowledge extraction, which is highly inflexible as LLMs can only\nprovide binary judgment on whether a certain knowledge (e.g., a knowledge path\nin KG) should be used. In addition, LLMs tend to pick only knowledge with\ndirect semantic relationship with the input text, while potentially useful\nknowledge with indirect semantics can be ignored. In this work, we propose a\nprincipled framework KELP with three stages to handle the above problems.\nSpecifically, KELP is able to achieve finer granularity of flexible knowledge\nextraction by generating scores for knowledge paths with input texts via latent\nsemantic matching. Meanwhile, knowledge paths with indirect semantic\nrelationships with the input text can also be considered via trained encoding\nbetween the selected paths in KG and the input text. Experiments on real-world\ndatasets validate the effectiveness of KELP.",
      "tldr_zh": "大语言模型 (LLMs) 常出现幻觉问题，即生成事实不准确的输出，为此，本文提出 KELP 框架，通过知识图谱 (KGs) 的路径选择来增强 LLMs。KELP 采用三个阶段的方法，包括通过潜在语义匹配为知识路径生成分数，实现更细粒度的知识提取，并考虑与输入文本具有间接语义关系的路径，从而提升灵活性。实验在真实数据集上证明，KELP 有效提高了 LLMs 的输出事实准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13862v1",
      "published_date": "2024-06-19 21:45:20 UTC",
      "updated_date": "2024-06-19 21:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:10:50.593990"
    },
    {
      "arxiv_id": "2406.13851v1",
      "title": "Optimizing Quantile-based Trading Strategies in Electricity Arbitrage",
      "title_zh": "在电力套利中优化基于分位数的交易策略",
      "authors": [
        "Ciaran O'Connor",
        "Joseph Collins",
        "Steven Prestwich",
        "Andrea Visentin"
      ],
      "abstract": "Efficiently integrating renewable resources into electricity markets is vital\nfor addressing the challenges of matching real-time supply and demand while\nreducing the significant energy wastage resulting from curtailments. To address\nthis challenge effectively, the incorporation of storage devices can enhance\nthe reliability and efficiency of the grid, improving market liquidity and\nreducing price volatility. In short-term electricity markets, participants\nnavigate numerous options, each presenting unique challenges and opportunities,\nunderscoring the critical role of the trading strategy in maximizing profits.\nThis study delves into the optimization of day-ahead and balancing market\ntrading, leveraging quantile-based forecasts. Employing three trading\napproaches with practical constraints, our research enhances forecast\nassessment, increases trading frequency, and employs flexible timestamp orders.\nOur findings underscore the profit potential of simultaneous participation in\nboth day-ahead and balancing markets, especially with larger battery storage\nsystems; despite increased costs and narrower profit margins associated with\nhigher-volume trading, the implementation of high-frequency strategies plays a\nsignificant role in maximizing profits and addressing market challenges.\nFinally, we modelled four commercial battery storage systems and evaluated\ntheir economic viability through a scenario analysis, with larger batteries\nshowing a shorter return on investment.",
      "tldr_zh": "这篇论文优化了基于分位数(quantile-based)交易策略，用于电力套利，以解决可再生能源整合带来的供需匹配挑战和能源浪费问题。研究通过三种交易方法结合实际约束（如提高预测评估、增加交易频率和使用灵活时间戳订单），探讨了日 ahead 和平衡市场的同时参与策略。结果显示，这种方法能显著提升利润，特别是对于较大的电池存储系统，尽管高频交易会增加成本和缩小利润边际，但整体有助于最大化收益。最后，通过情景分析评估了四种商业电池存储系统的经济可行性，发现较大电池具有更短的投资回报期。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13851v1",
      "published_date": "2024-06-19 21:27:12 UTC",
      "updated_date": "2024-06-19 21:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:11:01.845817"
    },
    {
      "arxiv_id": "2406.13844v3",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "title_zh": "翻译失败",
      "authors": [
        "Lidia Garrucho",
        "Kaisar Kushibar",
        "Claire-Anne Reidel",
        "Smriti Joshi",
        "Richard Osuala",
        "Apostolia Tsirikoglou",
        "Maciej Bobowicz",
        "Javier del Riego",
        "Alessandro Catanese",
        "Katarzyna Gwoździewicz",
        "Maria-Laura Cosaka",
        "Pasant M. Abo-Elhoda",
        "Sara W. Tantawy",
        "Shorouq S. Sakrana",
        "Norhan O. Shawky-Abdelfatah",
        "Amr Muhammad Abdo-Salem",
        "Androniki Kozana",
        "Eugen Divjak",
        "Gordana Ivanac",
        "Katerina Nikiforaki",
        "Michail E. Klontzas",
        "Rosa García-Dosdá",
        "Meltem Gulsun-Akpinar",
        "Oğuz Lafcı",
        "Ritse Mann",
        "Carlos Martín-Isla",
        "Fred Prior",
        "Kostas Marias",
        "Martijn P. A. Starmans",
        "Fredrik Strand",
        "Oliver Díaz",
        "Laura Igual",
        "Karim Lekadir"
      ],
      "abstract": "Artificial Intelligence (AI) research in breast cancer Magnetic Resonance\nImaging (MRI) faces challenges due to limited expert-labeled segmentations. To\naddress this, we present a multicenter dataset of 1506 pre-treatment\nT1-weighted dynamic contrast-enhanced MRI cases, including expert annotations\nof primary tumors and non-mass-enhanced regions. The dataset integrates imaging\ndata from four collections in The Cancer Imaging Archive (TCIA), where only 163\ncases with expert segmentations were initially available. To facilitate the\nannotation process, a deep learning model was trained to produce preliminary\nsegmentations for the remaining cases. These were subsequently corrected and\nverified by 16 breast cancer experts (averaging 9 years of experience),\ncreating a fully annotated dataset. Additionally, the dataset includes 49\nharmonized clinical and demographic variables, as well as pre-trained weights\nfor a baseline nnU-Net model trained on the annotated data. This resource\naddresses a critical gap in publicly available breast cancer datasets, enabling\nthe development, validation, and benchmarking of advanced deep learning models,\nthus driving progress in breast cancer diagnostics, treatment response\nprediction, and personalized care.",
      "tldr_zh": "这篇论文发布了一个大规模多中心乳腺癌DCE-MRI基准数据集，包含1506个预治疗T1加权动态对比增强MRI病例的专家标注，包括原发肿瘤和非团块增强区域。研究团队通过训练一个深度学习模型生成初步分割，然后由16位经验丰富的专家（平均9年经验）进行修正和验证，高效扩展了原本TCIA中仅163个标注病例的资源。数据集还整合了49个协调的临床和人口统计变量，以及预训练的nnU-Net模型权重。该资源填补了公开乳腺癌数据集的空白，推动AI模型在乳腺癌诊断、治疗响应预测和个性化护理中的开发与基准测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CV",
      "comment": "15 paes, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13844v3",
      "published_date": "2024-06-19 21:11:46 UTC",
      "updated_date": "2025-02-21 11:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:11:25.515022"
    },
    {
      "arxiv_id": "2406.13843v2",
      "title": "Generative AI Misuse: A Taxonomy of Tactics and Insights from Real-World Data",
      "title_zh": "翻译失败",
      "authors": [
        "Nahema Marchal",
        "Rachel Xu",
        "Rasmi Elasmar",
        "Iason Gabriel",
        "Beth Goldberg",
        "William Isaac"
      ],
      "abstract": "Generative, multimodal artificial intelligence (GenAI) offers transformative\npotential across industries, but its misuse poses significant risks. Prior\nresearch has shed light on the potential of advanced AI systems to be exploited\nfor malicious purposes. However, we still lack a concrete understanding of how\nGenAI models are specifically exploited or abused in practice, including the\ntactics employed to inflict harm. In this paper, we present a taxonomy of GenAI\nmisuse tactics, informed by existing academic literature and a qualitative\nanalysis of approximately 200 observed incidents of misuse reported between\nJanuary 2023 and March 2024. Through this analysis, we illuminate key and novel\npatterns in misuse during this time period, including potential motivations,\nstrategies, and how attackers leverage and abuse system capabilities across\nmodalities (e.g. image, text, audio, video) in the wild.",
      "tldr_zh": "这篇论文提出了一个Generative AI (GenAI)滥用策略的分类法(taxonomy)，旨在系统化地分析GenAI模型在实际中的恶意利用。研究者通过现有学术文献和对约200个真实事件的定性分析（涵盖2023年1月至2024年3月），揭示了滥用的关键模式，包括潜在动机、攻击策略以及如何跨模态（如图像、文本、音频、视频）利用系统能力。这些发现为防范GenAI滥用提供了宝贵洞见，帮助提升AI系统的安全性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13843v2",
      "published_date": "2024-06-19 21:11:17 UTC",
      "updated_date": "2024-06-21 10:27:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:11:26.758912"
    },
    {
      "arxiv_id": "2406.13840v1",
      "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Davit Abrahamyan",
        "Fatemeh H. Fard"
      ],
      "abstract": "Developers spend much time finding information that is relevant to their\nquestions. Stack Overflow has been the leading resource, and with the advent of\nLarge Language Models (LLMs), generative models such as ChatGPT are used\nfrequently. However, there is a catch in using each one separately. Searching\nfor answers is time-consuming and tedious, as shown by the many tools developed\nby researchers to address this issue. On the other, using LLMs is not reliable,\nas they might produce irrelevant or unreliable answers (i.e., hallucination).\nIn this work, we present StackRAG, a retrieval-augmented Multiagent generation\ntool based on LLMs that combines the two worlds: aggregating the knowledge from\nSO to enhance the reliability of the generated answers. Initial evaluations\nshow that the generated answers are correct, accurate, relevant, and useful.",
      "tldr_zh": "该研究针对开发者在查找信息时的问题，指出使用 Stack Overflow 搜索耗时费力，而 Large Language Models (LLMs) 如 ChatGPT 可能产生 hallucination，导致答案不可靠。StackRAG Agent 是一种基于 LLMs 的检索增强生成（Retrieval-Augmented Generation）多智能体工具，它整合 Stack Overflow 的知识来生成更可靠的答案。初步评估显示，StackRAG 产生的答案在正确性、准确性、相关性和实用性方面均有显著改善。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13840v1",
      "published_date": "2024-06-19 21:07:35 UTC",
      "updated_date": "2024-06-19 21:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:11:36.281233"
    },
    {
      "arxiv_id": "2406.13807v2",
      "title": "AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding",
      "title_zh": "AlanaVLM：一个多模态具身AI基础模型，用于第一人称视角视频理解",
      "authors": [
        "Alessandro Suglia",
        "Claudio Greco",
        "Katie Baker",
        "Jose L. Part",
        "Ioannis Papaioannou",
        "Arash Eshghi",
        "Ioannis Konstas",
        "Oliver Lemon"
      ],
      "abstract": "AI personal assistants deployed via robots or wearables require embodied\nunderstanding to collaborate with humans effectively. However, current\nVision-Language Models (VLMs) primarily focus on third-person view videos,\nneglecting the richness of egocentric perceptual experience. To address this\ngap, we propose three key contributions. First, we introduce the Egocentric\nVideo Understanding Dataset (EVUD) for training VLMs on video captioning and\nquestion answering tasks specific to egocentric videos. Second, we present\nAlanaVLM, a 7B parameter VLM trained using parameter-efficient methods on EVUD.\nFinally, we evaluate AlanaVLM's capabilities on OpenEQA, a challenging\nbenchmark for embodied video question answering. Our model achieves\nstate-of-the-art performance, outperforming open-source models including strong\nSocratic models using GPT-4 as a planner by 3.6%. Additionally, we outperform\nClaude 3 and Gemini Pro Vision 1.0 and showcase competitive results compared to\nGemini Pro 1.5 and GPT-4V, even surpassing the latter in spatial reasoning.\nThis research paves the way for building efficient VLMs that can be deployed in\nrobots or wearables, leveraging embodied video understanding to collaborate\nseamlessly with humans in everyday tasks, contributing to the next generation\nof Embodied AI.",
      "tldr_zh": "这篇论文针对现有的 Vision-Language Models (VLMs) 主要关注第三人称视角视频的问题，提出 AlanaVLM，一种7B参数的多模态 Embodied AI 基础模型，专注于第一人称（egocentric）视频理解。研究者引入了 Egocentric Video Understanding Dataset (EVUD)，用于训练 VLMs 进行视频字幕和问答任务。AlanaVLM 在 OpenEQA 基准上实现了 state-of-the-art 性能，比开源模型（如使用 GPT-4 作为规划器的 Socratic 模型）高出3.6%，并在空间推理上超越 GPT-4V，同时优于 Claude 3 和 Gemini Pro Vision 1.0。该工作为部署在机器人或可穿戴设备上的高效 Embodied AI 提供了新路径，促进人类协作任务的实现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code available https://github.com/alanaai/EVUD",
      "pdf_url": "http://arxiv.org/pdf/2406.13807v2",
      "published_date": "2024-06-19 20:14:14 UTC",
      "updated_date": "2024-06-21 09:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:11:51.291177"
    },
    {
      "arxiv_id": "2406.13805v1",
      "title": "WikiContradict: A Benchmark for Evaluating LLMs on Real-World Knowledge Conflicts from Wikipedia",
      "title_zh": "翻译失败",
      "authors": [
        "Yufang Hou",
        "Alessandra Pascale",
        "Javier Carnerero-Cano",
        "Tigran Tchrakian",
        "Radu Marinescu",
        "Elizabeth Daly",
        "Inkit Padhi",
        "Prasanna Sattigeri"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution to\nmitigate the limitations of large language models (LLMs), such as\nhallucinations and outdated information. However, it remains unclear how LLMs\nhandle knowledge conflicts arising from different augmented retrieved passages,\nespecially when these passages originate from the same source and have equal\ntrustworthiness. In this work, we conduct a comprehensive evaluation of\nLLM-generated answers to questions that have varying answers based on\ncontradictory passages from Wikipedia, a dataset widely regarded as a\nhigh-quality pre-training resource for most LLMs. Specifically, we introduce\nWikiContradict, a benchmark consisting of 253 high-quality, human-annotated\ninstances designed to assess LLM performance when augmented with retrieved\npassages containing real-world knowledge conflicts. We benchmark a diverse\nrange of both closed and open-source LLMs under different QA scenarios,\nincluding RAG with a single passage, and RAG with 2 contradictory passages.\nThrough rigorous human evaluations on a subset of WikiContradict instances\ninvolving 5 LLMs and over 3,500 judgements, we shed light on the behaviour and\nlimitations of these models. For instance, when provided with two passages\ncontaining contradictory facts, all models struggle to generate answers that\naccurately reflect the conflicting nature of the context, especially for\nimplicit conflicts requiring reasoning. Since human evaluation is costly, we\nalso introduce an automated model that estimates LLM performance using a strong\nopen-source language model, achieving an F-score of 0.8. Using this automated\nmetric, we evaluate more than 1,500 answers from seven LLMs across all\nWikiContradict instances. To facilitate future work, we release WikiContradict\non: https://ibm.biz/wikicontradict.",
      "tldr_zh": "这篇论文引入了 WikiContradict，这是一个包含 253 个高质量人类标注实例的基准数据集，用于评估大型语言模型 (LLMs) 在处理来自 Wikipedia 的真实世界知识冲突时的表现。研究重点考察了 LLMs 在 Retrieval-augmented generation (RAG) 框架下，如何应对从同一来源获取的矛盾段落，尤其是当这些段落具有相同可信度时。实验结果显示，各种 LLMs 在处理显性和隐性冲突时均存在挑战，特别是需要推理的隐性冲突，导致生成的答案无法准确反映矛盾性质。通过人类评估（超过 3500 次判断）和一个 F-分数达 0.8 的自动评估模型，论文揭示了 LLMs 的局限性，并公开了数据集以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13805v1",
      "published_date": "2024-06-19 20:13:42 UTC",
      "updated_date": "2024-06-19 20:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:12:03.853875"
    },
    {
      "arxiv_id": "2406.13791v3",
      "title": "IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being",
      "title_zh": "翻译失败",
      "authors": [
        "Amelie Gyrard",
        "Seyedali Mohammadi",
        "Manas Gaur",
        "Antonio Kung"
      ],
      "abstract": "Sustainable Development Goals (SDGs) give the UN a road map for development\nwith Agenda 2030 as a target. SDG3 \"Good Health and Well-Being\" ensures healthy\nlives and promotes well-being for all ages. Digital technologies can support\nSDG3. Burnout and even depression could be reduced by encouraging better\npreventive health. Due to the lack of patient knowledge and focus to take care\nof their health, it is necessary to help patients before it is too late. New\ntrends such as positive psychology and mindfulness are highly encouraged in the\nUSA. Digital Twins (DTs) can help with the continuous monitoring of emotion\nusing physiological signals (e.g., collected via wearables). DTs facilitate\nmonitoring and provide constant health insight to improve quality of life and\nwell-being with better personalization. Healthcare DTs challenges are\nstandardizing data formats, communication protocols, and data exchange\nmechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things\n(IoT) and DTs Working Group, with standards such as \"ISO/IEC 21823-3:2021 IoT -\nInteroperability for IoT Systems - Part 3 Semantic interoperability\", \"ISO/IEC\nCD 30178 - IoT - Data format, value and coding\". To achieve those data\nintegration and knowledge challenges, we designed the Mental Health Knowledge\nGraph (ontology and dataset) to boost mental health. As an example, explicit\nknowledge is described such as chocolate contains magnesium which is\nrecommended for depression. The Knowledge Graph (KG) acquires knowledge from\nontology-based mental health projects classified within the LOV4IoT ontology\ncatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mapped\nto standards when possible. Standards from ETSI SmartM2M can be used such as\nSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,\nW3C, NIST, and IEEE standards relevant to mental health can be considered.",
      "tldr_zh": "本研究旨在通过物联网 (IoT) 和知识图谱 (Knowledge Graph) 支持联合国可持续发展目标 (SDGs) 中的 SDG3（良好健康和福祉），以预防心理健康问题如烧伤和抑郁。研究设计了 Mental Health Knowledge Graph，包括本体和数据集，从 LOV4IoT 等来源获取知识，并映射到相关标准（如 ISO/IEC 21823-3 和 ETSI SmartM2M），以标准化数据格式和提升数据整合。利用 Digital Twins (DTs) 监控生理信号，研究展示了这种方法能提供个性化健康洞见，提高生活质量和福祉。实验示例表明，该框架可帮助患者及早干预心理健康问题，促进正向心理学和正念的应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, Book chapter, Smart Technologies for Achieving Good Health\n  and Well-Being: Towards Sustainable Development Goal, Taylor & Francis",
      "pdf_url": "http://arxiv.org/pdf/2406.13791v3",
      "published_date": "2024-06-19 19:35:14 UTC",
      "updated_date": "2024-10-21 16:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:12:12.942987"
    },
    {
      "arxiv_id": "2406.13781v1",
      "title": "A Primal-Dual Framework for Transformers and Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tan M. Nguyen",
        "Tam Nguyen",
        "Nhat Ho",
        "Andrea L. Bertozzi",
        "Richard G. Baraniuk",
        "Stanley J. Osher"
      ],
      "abstract": "Self-attention is key to the remarkable success of transformers in sequence\nmodeling tasks including many applications in natural language processing and\ncomputer vision. Like neural network layers, these attention mechanisms are\noften developed by heuristics and experience. To provide a principled framework\nfor constructing attention layers in transformers, we show that the\nself-attention corresponds to the support vector expansion derived from a\nsupport vector regression problem, whose primal formulation has the form of a\nneural network layer. Using our framework, we derive popular attention layers\nused in practice and propose two new attentions: 1) the Batch Normalized\nAttention (Attention-BN) derived from the batch normalization layer and 2) the\nAttention with Scaled Head (Attention-SH) derived from using less training data\nto fit the SVR model. We empirically demonstrate the advantages of the\nAttention-BN and Attention-SH in reducing head redundancy, increasing the\nmodel's accuracy, and improving the model's efficiency in a variety of\npractical applications including image and time-series classification.",
      "tldr_zh": "本研究提出一个基于原始-对偶(Primal-Dual)框架，将Transformer的自注意力(Self-Attention)机制与支持向量回归(SVR)问题联系起来，提供了一个原则性的方法来构建注意力层。该框架显示自注意力对应于SVR的对偶展开形式，其原始形式类似于神经网络层，从而推导出了现有流行注意力层，并引入了两个新机制：Batch Normalized Attention (Attention-BN)基于批量归一化层，以及Attention with Scaled Head (Attention-SH)基于使用较少训练数据拟合SVR模型。实验结果表明，Attention-BN和Attention-SH在图像和时间序列分类等任务中显著减少了注意力头冗余，提高了模型准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2023, 26 pages, 4 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13781v1",
      "published_date": "2024-06-19 19:11:22 UTC",
      "updated_date": "2024-06-19 19:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:12:26.417743"
    },
    {
      "arxiv_id": "2407.09519v1",
      "title": "Putting GPT-4o to the Sword: A Comprehensive Evaluation of Language, Vision, Speech, and Multimodal Proficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Sakib Shahriar",
        "Brady Lund",
        "Nishith Reddy Mannuru",
        "Muhammad Arbab Arshad",
        "Kadhim Hayawi",
        "Ravi Varma Kumar Bevara",
        "Aashrith Mannuru",
        "Laiba Batool"
      ],
      "abstract": "As large language models (LLMs) continue to advance, evaluating their\ncomprehensive capabilities becomes significant for their application in various\nfields. This research study comprehensively evaluates the language, vision,\nspeech, and multimodal capabilities of GPT-4o. The study employs standardized\nexam questions, reasoning tasks, and translation assessments to assess the\nmodel's language capability. Additionally, GPT-4o's vision and speech\ncapabilities are tested through image classification and object recognition\ntasks, as well as accent classification. The multimodal evaluation assesses the\nmodel's performance in integrating visual and linguistic data. Our findings\nreveal that GPT-4o demonstrates high accuracy and efficiency across multiple\ndomains in language and reasoning capabilities, excelling in tasks that require\nfew-shot learning. GPT-4o also provides notable improvements in multimodal\ntasks compared to its predecessors. However, the model shows variability and\nfaces limitations in handling complex and ambiguous inputs, particularly in\naudio and vision capabilities. This paper highlights the need for more\ncomprehensive benchmarks and robust evaluation frameworks, encompassing\nqualitative assessments involving human judgment as well as error analysis.\nFuture work should focus on expanding datasets, investigating prompt-based\nassessment, and enhancing few-shot learning techniques to test the model's\npractical applicability and performance in real-world scenarios.",
      "tldr_zh": "本研究对GPT-4o的语言、视觉、语音和多模态能力进行了全面评估，使用标准化考试问题、推理任务、翻译评估、图像分类、物体识别以及口音分类等方法进行测试。结果显示，GPT-4o在语言和推理任务中表现出高准确性和效率，尤其在few-shot learning场景下表现突出，并在多模态任务中比前代模型有显著改善。然而，该模型在处理复杂或模糊输入时存在变异性，特别是音频和视觉能力方面存在局限。论文强调需要更全面的基准框架，包括定性评估和错误分析，并建议未来工作扩展数据集和优化提示评估以提升实际应用性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09519v1",
      "published_date": "2024-06-19 19:00:21 UTC",
      "updated_date": "2024-06-19 19:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:12:37.344897"
    },
    {
      "arxiv_id": "2406.13770v2",
      "title": "Elliptical Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan K. Nielsen",
        "Laziz U. Abdullaev",
        "Rachel S. Y. Teo",
        "Tan M. Nguyen"
      ],
      "abstract": "Pairwise dot-product self-attention is key to the success of transformers\nthat achieve state-of-the-art performance across a variety of applications in\nlanguage and vision. This dot-product self-attention computes attention weights\namong the input tokens using Euclidean distance, which makes the model prone to\nrepresentation collapse and vulnerable to contaminated samples. In this paper,\nwe propose using a Mahalanobis distance metric for computing the attention\nweights to stretch the underlying feature space in directions of high\ncontextual relevance. In particular, we define a hyper-ellipsoidal neighborhood\naround each query to increase the attention weights of the tokens lying in the\ncontextually important directions. We term this novel class of attention\nElliptical Attention. Our Elliptical Attention provides two benefits: 1)\nreducing representation collapse and 2) enhancing the model's robustness as\nElliptical Attention pays more attention to contextually relevant information\nrather than focusing on some small subset of informative features. We\nempirically demonstrate the advantages of Elliptical Attention over the\nbaseline dot-product attention and state-of-the-art attention methods on\nvarious practical tasks, including object classification, image segmentation,\nand language modeling across different data modalities.",
      "tldr_zh": "本研究指出，传统 dot-product self-attention 使用 Euclidean distance 计算注意力权重，导致 representation collapse 和模型对 contaminated samples 的脆弱性。为解决此问题，作者提出 Elliptical Attention 机制，该机制采用 Mahalanobis distance 定义 hyper-ellipsoidal neighborhood 周围每个 query，从而优先关注 contextually relevant information。Elliptical Attention 的优势包括减少 representation collapse 并提升模型鲁棒性。实验结果显示，在物体分类、图像分割和语言建模等任务上，该方法优于基线 dot-product attention 和最先进注意力方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/stefvk/Elliptical-Attention",
      "pdf_url": "http://arxiv.org/pdf/2406.13770v2",
      "published_date": "2024-06-19 18:38:11 UTC",
      "updated_date": "2024-10-31 21:21:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:12:59.832754"
    },
    {
      "arxiv_id": "2406.13768v1",
      "title": "FastPersist: Accelerating Model Checkpointing in Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Guanhua Wang",
        "Olatunji Ruwase",
        "Bing Xie",
        "Yuxiong He"
      ],
      "abstract": "Model checkpoints are critical Deep Learning (DL) artifacts that enable fault\ntolerance for training and downstream applications, such as inference. However,\nwriting checkpoints to persistent storage, and other I/O aspects of DL\ntraining, are mostly ignored by compute-focused optimization efforts for faster\ntraining of rapidly growing models and datasets. Towards addressing this\nimbalance, we propose FastPersist to accelerate checkpoint creation in DL\ntraining. FastPersist combines three novel techniques: (i) NVMe optimizations\nfor faster checkpoint writes to SSDs, (ii) efficient write parallelism using\nthe available SSDs in training environments, and (iii) overlapping\ncheckpointing with independent training computations. Our evaluation using real\nworld dense and sparse DL models shows that FastPersist creates checkpoints in\npersistent storage up to 116x faster than baseline, and enables per-iteration\ncheckpointing with negligible overhead.",
      "tldr_zh": "该研究针对深度学习（Deep Learning）训练中的模型检查点（Model Checkpointing）问题，提出FastPersist框架，以加速检查点写入并提升整体I/O效率。FastPersist结合了三种新颖技术：（i）NVMe优化以加快写入SSD，（ii）利用可用SSD的写入并行性，以及（iii）将检查点过程与独立训练计算重叠，从而减少I/O瓶颈。实验结果显示，使用真实世界的密集和稀疏DL模型，FastPersist比基线方法快达116倍，并实现了每迭代检查点写入而几乎无开销。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.13768v1",
      "published_date": "2024-06-19 18:31:23 UTC",
      "updated_date": "2024-06-19 18:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:13:04.392777"
    },
    {
      "arxiv_id": "2406.13763v1",
      "title": "Through the Theory of Mind's Eye: Reading Minds with Multimodal Video Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhawnen Chen",
        "Tianchun Wang",
        "Yizhou Wang",
        "Michal Kosinski",
        "Xiang Zhang",
        "Yun Fu",
        "Sheng Li"
      ],
      "abstract": "Can large multimodal models have a human-like ability for emotional and\nsocial reasoning, and if so, how does it work? Recent research has discovered\nemergent theory-of-mind (ToM) reasoning capabilities in large language models\n(LLMs). LLMs can reason about people's mental states by solving various\ntext-based ToM tasks that ask questions about the actors' ToM (e.g., human\nbelief, desire, intention). However, human reasoning in the wild is often\ngrounded in dynamic scenes across time. Thus, we consider videos a new medium\nfor examining spatio-temporal ToM reasoning ability. Specifically, we ask\nexplicit probing questions about videos with abundant social and emotional\nreasoning content. We develop a pipeline for multimodal LLM for ToM reasoning\nusing video and text. We also enable explicit ToM reasoning by retrieving key\nframes for answering a ToM question, which reveals how multimodal LLMs reason\nabout ToM.",
      "tldr_zh": "该研究探讨了大型多模态视频语言模型（Multimodal Video Large Language Models）是否具备类似人类的社交和情感推理能力，特别是理论-of-mind (ToM) 推理。作者扩展了现有LLMs在文本-based ToM任务中的表现，转向使用动态视频场景，通过提出关于视频中社交和情感内容的明确问题来评估时空ToM推理。研究开发了一个多模态LLM管道，结合视频和文本输入，并通过检索关键帧启用显式ToM推理，从而揭示模型如何基于视觉-时间线索进行心理状态分析。实验结果表明，这种方法增强了模型在真实世界动态场景中的推理准确性，为情感和社会推理的应用提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13763v1",
      "published_date": "2024-06-19 18:24:31 UTC",
      "updated_date": "2024-06-19 18:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:13:14.646906"
    },
    {
      "arxiv_id": "2406.13762v2",
      "title": "Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Rachel S. Y. Teo",
        "Tan M. Nguyen"
      ],
      "abstract": "The remarkable success of transformers in sequence modeling tasks, spanning\nvarious applications in natural language processing and computer vision, is\nattributed to the critical role of self-attention. Similar to the development\nof most deep learning models, the construction of these attention mechanisms\nrelies on heuristics and experience. In our work, we derive self-attention from\nkernel principal component analysis (kernel PCA) and show that self-attention\nprojects its query vectors onto the principal component axes of its key matrix\nin a feature space. We then formulate the exact formula for the value matrix in\nself-attention, theoretically and empirically demonstrating that this value\nmatrix captures the eigenvectors of the Gram matrix of the key vectors in\nself-attention. Leveraging our kernel PCA framework, we propose Attention with\nRobust Principal Components (RPC-Attention), a novel class of robust attention\nthat is resilient to data contamination. We empirically demonstrate the\nadvantages of RPC-Attention over softmax attention on the ImageNet-1K object\nclassification, WikiText-103 language modeling, and ADE20K image segmentation\ntask.",
      "tldr_zh": "本研究通过核主成分分析（kernel PCA）揭示了self-attention机制的隐藏结构，证明self-attention将query向量投影到key矩阵的主成分轴上，并推导出value矩阵的确切公式，该公式捕捉了key向量的Gram矩阵特征向量。作者基于这一框架提出了一种新型鲁棒注意力机制RPC-Attention（Attention with Robust Principal Components），其对数据污染具有抵抗力。实验结果显示，RPC-Attention在ImageNet-1K物体分类、WikiText-103语言建模和ADE20K图像分割任务上优于softmax attention，展示了其实际优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages in the main text. Published at NeurIPS 2024. The code is\n  available at https://github.com/rachtsy/KPCA_code",
      "pdf_url": "http://arxiv.org/pdf/2406.13762v2",
      "published_date": "2024-06-19 18:22:32 UTC",
      "updated_date": "2024-10-30 20:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:13:35.464983"
    },
    {
      "arxiv_id": "2406.13743v3",
      "title": "GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation",
      "title_zh": "GenAI-Bench：评估和改进组合式文本到视觉生成",
      "authors": [
        "Baiqi Li",
        "Zhiqiu Lin",
        "Deepak Pathak",
        "Jiayao Li",
        "Yixin Fei",
        "Kewen Wu",
        "Tiffany Ling",
        "Xide Xia",
        "Pengchuan Zhang",
        "Graham Neubig",
        "Deva Ramanan"
      ],
      "abstract": "While text-to-visual models now produce photo-realistic images and videos,\nthey struggle with compositional text prompts involving attributes,\nrelationships, and higher-order reasoning such as logic and comparison. In this\nwork, we conduct an extensive human study on GenAI-Bench to evaluate the\nperformance of leading image and video generation models in various aspects of\ncompositional text-to-visual generation. We also compare automated evaluation\nmetrics against our collected human ratings and find that VQAScore -- a metric\nmeasuring the likelihood that a VQA model views an image as accurately\ndepicting the prompt -- significantly outperforms previous metrics such as\nCLIPScore. In addition, VQAScore can improve generation in a black-box manner\n(without finetuning) via simply ranking a few (3 to 9) candidate images.\nRanking by VQAScore is 2x to 3x more effective than other scoring methods like\nPickScore, HPSv2, and ImageReward at improving human alignment ratings for\nDALL-E 3 and Stable Diffusion, especially on compositional prompts that require\nadvanced visio-linguistic reasoning. We release a new GenAI-Rank benchmark with\nover 40,000 human ratings to evaluate scoring metrics on ranking images\ngenerated from the same prompt. Lastly, we discuss promising areas for\nimprovement in VQAScore, such as addressing fine-grained visual details. We\nwill release all human ratings (over 80,000) to facilitate scientific\nbenchmarking of both generative models and automated metrics.",
      "tldr_zh": "该研究介绍了GenAI-Bench，一个用于评估和改进组合性文本到视觉生成（涉及属性、关系和高级推理如逻辑比较）的基准框架。作者通过大规模人类研究评估了领先的图像和视频生成模型的表现，并发现VQAScore（一种基于视觉问答的指标）显著优于CLIPScore等现有方法，能更准确地衡量生成结果与提示的匹配度。VQAScore不仅用于评估，还能通过简单排名（3到9个候选图像）在不需微调的情况下提升生成质量，尤其在复杂提示上，使DALL-E 3和Stable Diffusion的输出更符合人类偏好，比PickScore、HPSv2和ImageReward等方法有效2到3倍。最后，他们发布了GenAI-Rank基准数据集（含逾40,000人类评分），并公开逾80,000条评分以推动生成模型和自动指标的基准测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "We open-source our dataset, model, and code at:\n  https://linzhiqiu.github.io/papers/genai_bench ; Project page:\n  https://linzhiqiu.github.io/papers/genai_bench ; GenAI-Bench was first\n  introduced in arxiv:2404.01291. This article extends it with an additional\n  GenAI-Rank benchmark",
      "pdf_url": "http://arxiv.org/pdf/2406.13743v3",
      "published_date": "2024-06-19 18:00:07 UTC",
      "updated_date": "2024-11-03 20:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:13:40.193083"
    },
    {
      "arxiv_id": "2406.13733v1",
      "title": "You can't handle the (dirty) truth: Data-centric insights improve pseudo-labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Nabeel Seedat",
        "Nicolas Huynh",
        "Fergus Imrie",
        "Mihaela van der Schaar"
      ],
      "abstract": "Pseudo-labeling is a popular semi-supervised learning technique to leverage\nunlabeled data when labeled samples are scarce. The generation and selection of\npseudo-labels heavily rely on labeled data. Existing approaches implicitly\nassume that the labeled data is gold standard and 'perfect'. However, this can\nbe violated in reality with issues such as mislabeling or ambiguity. We address\nthis overlooked aspect and show the importance of investigating labeled data\nquality to improve any pseudo-labeling method. Specifically, we introduce a\nnovel data characterization and selection framework called DIPS to extend\npseudo-labeling. We select useful labeled and pseudo-labeled samples via\nanalysis of learning dynamics. We demonstrate the applicability and impact of\nDIPS for various pseudo-labeling methods across an extensive range of\nreal-world tabular and image datasets. Additionally, DIPS improves data\nefficiency and reduces the performance distinctions between different\npseudo-labelers. Overall, we highlight the significant benefits of a\ndata-centric rethinking of pseudo-labeling in real-world settings.",
      "tldr_zh": "这篇论文指出，pseudo-labeling 作为一种半监督学习技术，在标签数据稀缺时依赖于无标签数据，但现有方法忽略了标签数据的潜在缺陷，如误标签或模糊性，从而影响伪标签的生成和选择。作者引入了 DIPS 框架，通过分析学习动态来筛选有用的标签和伪标签样本，从而扩展 pseudo-labeling 的适用性。在各种真实表格和图像数据集上，DIPS 显著提高了伪标签方法的性能、数据效率，并缩小了不同伪标签器之间的差异，强调了数据中心视角对半监督学习的重要作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Journal of Data-centric Machine Learning Research\n  (DMLR) *Seedat & Huynh contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2406.13733v1",
      "published_date": "2024-06-19 17:58:40 UTC",
      "updated_date": "2024-06-19 17:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:13:53.247837"
    },
    {
      "arxiv_id": "2406.13731v1",
      "title": "Integrating Fuzzy Logic with Causal Inference: Enhancing the Pearl and Neyman-Rubin Methodologies",
      "title_zh": "将模糊逻辑与因果推理整合：增强 Pearl 和 Neyman-Rubin 方法论",
      "authors": [
        "Amir Saki",
        "Usef Faghihi"
      ],
      "abstract": "In this paper, we generalize the Pearl and Neyman-Rubin methodologies in\ncausal inference by introducing a generalized approach that incorporates fuzzy\nlogic. Indeed, we introduce a fuzzy causal inference approach that consider\nboth the vagueness and imprecision inherent in data, as well as the subjective\nhuman perspective characterized by fuzzy terms such as 'high', 'medium', and\n'low'. To do so, we introduce two fuzzy causal effect formulas: the Fuzzy\nAverage Treatment Effect (FATE) and the Generalized Fuzzy Average Treatment\nEffect (GFATE), together with their normalized versions: NFATE and NGFATE. When\ndealing with a binary treatment variable, our fuzzy causal effect formulas\ncoincide with classical Average Treatment Effect (ATE) formula, that is a\nwell-established and popular metric in causal inference. In FATE, all values of\nthe treatment variable are considered equally important. In contrast, GFATE\ntakes into account the rarity and frequency of these values. We show that for\nlinear Structural Equation Models (SEMs), the normalized versions of our\nformulas, NFATE and NGFATE, are equivalent to ATE. Further, we provide\nidentifiability criteria for these formulas and show their stability with\nrespect to minor variations in the fuzzy subsets and the probability\ndistributions involved. This ensures the robustness of our approach in handling\nsmall perturbations in the data. Finally, we provide several experimental\nexamples to empirically validate and demonstrate the practical application of\nour proposed fuzzy causal inference methods.",
      "tldr_zh": "本论文将模糊逻辑（Fuzzy Logic）整合到 Pearl 和 Neyman-Rubin 的因果推断方法中，提出一种泛化方法来处理数据中的模糊性和主观不确定性，如“high”、“medium”和“low”等术语。论文引入了新的因果效应公式，包括 Fuzzy Average Treatment Effect (FATE) 和 Generalized Fuzzy Average Treatment Effect (GFATE)，及其归一化版本 NFATE 和 NGFATE，其中 FATE 视所有治疗变量值为同等重要，而 GFATE 考虑这些值的稀有性和频率。研究发现，在线性 Structural Equation Models (SEMs) 中，NFATE 和 NGFATE 等价于经典的 Average Treatment Effect (ATE)，并提供了这些公式的可识别性标准和稳定性，以应对数据微小变化。通过实验例子，验证了该方法的鲁棒性和实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "62D20, 60A86, 03E72, 93C42, 68T37, 6008, 68T20, 68T27, 68U99",
        "I.2.3; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13731v1",
      "published_date": "2024-06-19 17:54:31 UTC",
      "updated_date": "2024-06-19 17:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:14:07.582901"
    },
    {
      "arxiv_id": "2406.13725v2",
      "title": "Tree-Sliced Wasserstein Distance: A Geometric Perspective",
      "title_zh": "树切片 Wasserstein 距离：一个几何视角",
      "authors": [
        "Viet-Hoang Tran",
        "Trang Pham",
        "Tho Tran",
        "Minh Khoi Nguyen Nhat",
        "Thanh Chu",
        "Tam Le",
        "Tan M. Nguyen"
      ],
      "abstract": "Many variants of Optimal Transport (OT) have been developed to address its\nheavy computation. Among them, notably, Sliced Wasserstein (SW) is widely used\nfor application domains by projecting the OT problem onto one-dimensional\nlines, and leveraging the closed-form expression of the univariate OT to reduce\nthe computational burden. However, projecting measures onto low-dimensional\nspaces can lead to a loss of topological information. To mitigate this issue,\nin this work, we propose to replace one-dimensional lines with a more intricate\nstructure, called tree systems. This structure is metrizable by a tree metric,\nwhich yields a closed-form expression for OT problems on tree systems. We\nprovide an extensive theoretical analysis to formally define tree systems with\ntheir topological properties, introduce the concept of splitting maps, which\noperate as the projection mechanism onto these structures, then finally propose\na novel variant of Radon transform for tree systems and verify its injectivity.\nThis framework leads to an efficient metric between measures, termed\nTree-Sliced Wasserstein distance on Systems of Lines (TSW-SL). By conducting a\nvariety of experiments on gradient flows, image style transfer, and generative\nmodels, we illustrate that our proposed approach performs favorably compared to\nSW and its variants.",
      "tldr_zh": "这篇论文针对 Optimal Transport (OT) 的计算负担问题，提出 Tree-Sliced Wasserstein distance on Systems of Lines (TSW-SL)，通过使用树系统（tree systems）替换 Sliced Wasserstein (SW) 的一维投影，以减少拓扑信息丢失。作者详细定义了树系统的拓扑属性、splitting maps 作为投影机制，并引入树系统的 Radon 变换并证明其注入性，从而构建了一个高效的度量框架。在梯度流、图像风格转移和生成模型的实验中，TSW-SL 表现出比 SW 和其变体更优的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.13725v2",
      "published_date": "2024-06-19 17:40:11 UTC",
      "updated_date": "2025-05-02 04:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:14:17.879912"
    },
    {
      "arxiv_id": "2406.13724v1",
      "title": "Heterogeneous Graph Neural Networks with Post-hoc Explanations for Multi-modal and Explainable Land Use Inference",
      "title_zh": "异构图神经网络结合后验解释，用于多模态和可解释的土地利用推断",
      "authors": [
        "Xuehao Zhai",
        "Junqi Jiang",
        "Adam Dejl",
        "Antonio Rago",
        "Fangce Guo",
        "Francesca Toni",
        "Aruna Sivakumar"
      ],
      "abstract": "Urban land use inference is a critically important task that aids in city\nplanning and policy-making. Recently, the increased use of sensor and location\ntechnologies has facilitated the collection of multi-modal mobility data,\noffering valuable insights into daily activity patterns. Many studies have\nadopted advanced data-driven techniques to explore the potential of these\nmulti-modal mobility data in land use inference. However, existing studies\noften process samples independently, ignoring the spatial correlations among\nneighbouring objects and heterogeneity among different services. Furthermore,\nthe inherently low interpretability of complex deep learning methods poses a\nsignificant barrier in urban planning, where transparency and extrapolability\nare crucial for making long-term policy decisions. To overcome these\nchallenges, we introduce an explainable framework for inferring land use that\nsynergises heterogeneous graph neural networks (HGNs) with Explainable AI\ntechniques, enhancing both accuracy and explainability. The empirical\nexperiments demonstrate that the proposed HGNs significantly outperform\nbaseline graph neural networks for all six land-use indicators, especially in\nterms of 'office' and 'sustenance'. As explanations, we consider feature\nattribution and counterfactual explanations. The analysis of feature\nattribution explanations shows that the symmetrical nature of the `residence'\nand 'work' categories predicted by the framework aligns well with the\ncommuter's 'work' and 'recreation' activities in London. The analysis of the\ncounterfactual explanations reveals that variations in node features and types\nare primarily responsible for the differences observed between the predicted\nland use distribution and the ideal mixed state. These analyses demonstrate\nthat the proposed HGNs can suitably support urban stakeholders in their urban\nplanning and policy-making.",
      "tldr_zh": "该研究针对城市土地用途推断问题，提出了一种结合 Heterogeneous Graph Neural Networks (HGNs) 和 Explainable AI 技术的可解释框架，以处理多模态移动数据中的空间相关性和异质性，同时提升模型的透明度。该框架显著提高了推断准确性，在六种土地用途指标上优于基线模型，尤其在 'office' 和 'sustenance' 类别上。实验分析显示，feature attribution 解释揭示了预测结果与伦敦通勤活动的对称性，而counterfactual explanations 强调了节点特征和类型差异对预测分布的影响，从而为城市规划和政策制定提供可靠支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13724v1",
      "published_date": "2024-06-19 17:39:10 UTC",
      "updated_date": "2024-06-19 17:39:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:14:28.991988"
    },
    {
      "arxiv_id": "2406.13715v1",
      "title": "Converging Dimensions: Information Extraction and Summarization through Multisource, Multimodal, and Multilingual Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Janjani",
        "Mayank Palan",
        "Sarvesh Shirude",
        "Ninad Shegokar",
        "Sunny Kumar",
        "Faruk Kazi"
      ],
      "abstract": "Recent advances in large language models (LLMs) have led to new summarization\nstrategies, offering an extensive toolkit for extracting important information.\nHowever, these approaches are frequently limited by their reliance on isolated\nsources of data. The amount of information that can be gathered is limited and\ncovers a smaller range of themes, which introduces the possibility of falsified\ncontent and limited support for multilingual and multimodal data. The paper\nproposes a novel approach to summarization that tackles such challenges by\nutilizing the strength of multiple sources to deliver a more exhaustive and\ninformative understanding of intricate topics. The research progresses beyond\nconventional, unimodal sources such as text documents and integrates a more\ndiverse range of data, including YouTube playlists, pre-prints, and Wikipedia\npages. The aforementioned varied sources are then converted into a unified\ntextual representation, enabling a more holistic analysis. This multifaceted\napproach to summary generation empowers us to extract pertinent information\nfrom a wider array of sources. The primary tenet of this approach is to\nmaximize information gain while minimizing information overlap and maintaining\na high level of informativeness, which encourages the generation of highly\ncoherent summaries.",
      "tldr_zh": "该论文指出，现有的基于大型语言模型(LLMs)的信息提取和总结策略因依赖单一数据源而存在信息范围有限、潜在虚假内容以及对多语言(multilingual)和多模态(multimodal)数据的支持不足等问题。为解决这些挑战，研究提出了一种新方法，通过多来源(multisource)融合（如文本文档、YouTube 播放列表、pre-prints 和 Wikipedia 页面）将不同数据转换为统一的文本表示，进行更全面的分析。该方法旨在最大化信息获取、减少重叠并提升总结连贯性，从而生成更详尽且信息丰富的摘要。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13715v1",
      "published_date": "2024-06-19 17:15:47 UTC",
      "updated_date": "2024-06-19 17:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:14:40.940976"
    },
    {
      "arxiv_id": "2406.13714v1",
      "title": "BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes",
      "title_zh": "翻译失败",
      "authors": [
        "Vansh Nagpal",
        "Siva Likitha Valluru",
        "Kausik Lakkaraju",
        "Biplav Srivastava"
      ],
      "abstract": "A common, yet regular, decision made by people, whether healthy or with any\nhealth condition, is to decide what to have in meals like breakfast, lunch, and\ndinner, consisting of a combination of foods for appetizer, main course, side\ndishes, desserts, and beverages. However, often this decision is seen as a\ntrade-off between nutritious choices (e.g., low salt and sugar) or convenience\n(e.g., inexpensive, fast to prepare/obtain, taste better). In this preliminary\nwork, we present a data-driven approach for the novel meal recommendation\nproblem that can explore and balance choices for both considerations while also\nreasoning about a food's constituents and cooking process. Beyond the problem\nformulation, our contributions also include a goodness measure, a recipe\nconversion method from text to the recently introduced multimodal rich recipe\nrepresentation (R3) format, and learning methods using contextual bandits that\nshow promising results.",
      "tldr_zh": "该论文提出BEACON框架，针对餐食推荐问题，帮助人们在营养（如低盐低糖）和便利（如价格低、准备快、味道好）之间实现平衡，同时推理食物的成分和烹饪过程。研究贡献包括问题制定、一个goodness measure指标、将文本配方转换为多模态R3格式的方法，以及基于contextual bandits的学习算法。实验结果显示，该方法在探索和平衡餐食选择方面表现出色，具有良好的前景。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages (including references), 1 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13714v1",
      "published_date": "2024-06-19 17:14:41 UTC",
      "updated_date": "2024-06-19 17:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:02.467818"
    },
    {
      "arxiv_id": "2406.13711v1",
      "title": "Imagining In-distribution States: How Predictable Robot Behavior Can Enable User Control Over Learned Policies",
      "title_zh": "想象分布内状态：",
      "authors": [
        "Isaac Sheidlower",
        "Emma Bethel",
        "Douglas Lilly",
        "Reuben M. Aronson",
        "Elaine Schaertl Short"
      ],
      "abstract": "It is crucial that users are empowered to take advantage of the functionality\nof a robot and use their understanding of that functionality to perform novel\nand creative tasks. Given a robot trained with Reinforcement Learning (RL), a\nuser may wish to leverage that autonomy along with their familiarity of how\nthey expect the robot to behave to collaborate with the robot. One technique is\nfor the user to take control of some of the robot's action space through\nteleoperation, allowing the RL policy to simultaneously control the rest. We\nformalize this type of shared control as Partitioned Control (PC). However,\nthis may not be possible using an out-of-the-box RL policy. For example, a\nuser's control may bring the robot into a failure state from the policy's\nperspective, causing it to act unexpectedly and hindering the success of the\nuser's desired task. In this work, we formalize this problem and present\nImaginary Out-of-Distribution Actions, IODA, an initial algorithm which\nempowers users to leverage their expectations of a robot's behavior to\naccomplish new tasks. We deploy IODA in a user study with a real robot and find\nthat IODA leads to both better task performance and a higher degree of\nalignment between robot behavior and user expectation. We also show that in PC,\nthere is a strong and significant correlation between task performance and the\nrobot's ability to meet user expectations, highlighting the need for approaches\nlike IODA. Code is available at https://github.com/AABL-Lab/ioda_roman_2024",
      "tldr_zh": "该论文探讨了如何通过可预测的机器人行为，使用户能够更好地控制基于强化学习（RL）训练的策略，以完成新任务。作者引入了 Partitioned Control (PC) 概念，允许用户部分控制机器人的动作空间，同时让 RL 策略处理其余部分，但这可能导致机器人进入意外状态。针对此问题，他们提出了 Imaginary Out-of-Distribution Actions (IODA) 算法，帮助用户利用对机器人行为的预期进行协作。在真实机器人用户研究中，IODA 显著提高了任务性能，并增强了机器人行为与用户预期的匹配度，同时证明了在 PC 场景中，任务成功与预期一致性之间存在强相关性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE RO-MAN 2024 as a regular paper. arXiv admin note:\n  substantial text overlap with arXiv:2312.05991",
      "pdf_url": "http://arxiv.org/pdf/2406.13711v1",
      "published_date": "2024-06-19 17:08:28 UTC",
      "updated_date": "2024-06-19 17:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:05.834932"
    },
    {
      "arxiv_id": "2406.13706v2",
      "title": "Developing Story: Case Studies of Generative AI's Use in Journalism",
      "title_zh": "翻译失败",
      "authors": [
        "Natalie Grace Brigham",
        "Chongjiu Gao",
        "Tadayoshi Kohno",
        "Franziska Roesner",
        "Niloofar Mireshghallah"
      ],
      "abstract": "Journalists are among the many users of large language models (LLMs). To\nbetter understand the journalist-AI interactions, we conduct a study of LLM\nusage by two news agencies through browsing the WildChat dataset, identifying\ncandidate interactions, and verifying them by matching to online published\narticles. Our analysis uncovers instances where journalists provide sensitive\nmaterial such as confidential correspondence with sources or articles from\nother agencies to the LLM as stimuli and prompt it to generate articles, and\npublish these machine-generated articles with limited intervention (median\noutput-publication ROUGE-L of 0.62). Based on our findings, we call for further\nresearch into what constitutes responsible use of AI, and the establishment of\nclear guidelines and best practices on using LLMs in a journalistic context.",
      "tldr_zh": "该研究通过分析WildChat数据集，调查了两家新闻机构的记者使用大型语言模型(LLMs)的互动情况，发现记者常向LLMs提供敏感材料（如机密通信或他方文章）作为输入，并以有限干预生成并发布文章（输出-发布文章的ROUGE-L中位数为0.62）。这揭示了AI在新闻领域的潜在风险，包括伦理和准确性问题。作者呼吁进一步研究AI的负责任使用，并制定清晰的指导方针和最佳实践，以确保在新闻环境中合理应用LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13706v2",
      "published_date": "2024-06-19 16:58:32 UTC",
      "updated_date": "2024-12-03 04:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:17.695909"
    },
    {
      "arxiv_id": "2406.13705v2",
      "title": "EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Long Bai",
        "Tong Chen",
        "Qiaozhi Tan",
        "Wan Jun Nah",
        "Yanheng Li",
        "Zhicheng He",
        "Sishen Yuan",
        "Zhen Chen",
        "Jinlin Wu",
        "Mobarakol Islam",
        "Zhen Li",
        "Hongbin Liu",
        "Hongliang Ren"
      ],
      "abstract": "Wireless Capsule Endoscopy (WCE) is highly valued for its non-invasive and\npainless approach, though its effectiveness is compromised by uneven\nillumination from hardware constraints and complex internal dynamics, leading\nto overexposed or underexposed images. While researchers have discussed the\nchallenges of low-light enhancement in WCE, the issue of correcting for\ndifferent exposure levels remains underexplored. To tackle this, we introduce\nEndoUIC, a WCE unified illumination correction solution using an end-to-end\npromptable diffusion transformer (DiT) model. In our work, the illumination\nprompt module shall navigate the model to adapt to different exposure levels\nand perform targeted image enhancement, in which the Adaptive Prompt\nIntegration (API) and Global Prompt Scanner (GPS) modules shall further boost\nthe concurrent representation learning between the prompt parameters and\nfeatures. Besides, the U-shaped restoration DiT model shall capture the\nlong-range dependencies and contextual information for unified illumination\nrestoration. Moreover, we present a novel Capsule-endoscopy Exposure Correction\n(CEC) dataset, including ground-truth and corrupted image pairs annotated by\nexpert photographers. Extensive experiments against a variety of\nstate-of-the-art (SOTA) methods on four datasets showcase the effectiveness of\nour proposed method and components in WCE illumination restoration, and the\nadditional downstream experiments further demonstrate its utility for clinical\ndiagnosis and surgical assistance.",
      "tldr_zh": "本文提出EndoUIC，一种基于promptable Diffusion Transformer (DiT)的端到端模型，用于统一纠正无线胶囊内镜(WCE)图像的照明问题，包括过曝和欠曝。模型通过照明prompt模块、Adaptive Prompt Integration (API)和Global Prompt Scanner (GPS)模块，适应不同曝光水平并提升prompt参数与特征的并发表示学习；同时，U-shaped restoration DiT模型捕获长距离依赖和上下文信息，实现精确的图像增强。作者构建了新的Capsule-endoscopy Exposure Correction (CEC)数据集，并在四个数据集上进行的广泛实验中，证明EndoUIC优于现有SOTA方法，并在临床诊断和手术辅助中显示出显著实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "To appear in MICCAI 2024. Code and dataset availability:\n  https://github.com/longbai1006/EndoUIC",
      "pdf_url": "http://arxiv.org/pdf/2406.13705v2",
      "published_date": "2024-06-19 16:58:28 UTC",
      "updated_date": "2024-07-08 15:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:30.131854"
    },
    {
      "arxiv_id": "2406.13695v1",
      "title": "Multilingual De-Duplication Strategies: Applying scalable similarity search with monolingual & multilingual embedding models",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Pasch",
        "Dimitirios Petridis",
        "Jannic Cutura"
      ],
      "abstract": "This paper addresses the deduplication of multilingual textual data using\nadvanced NLP tools. We compare a two-step method involving translation to\nEnglish followed by embedding with mpnet, and a multilingual embedding model\n(distiluse). The two-step approach achieved a higher F1 score (82% vs. 60%),\nparticularly with less widely used languages, which can be increased up to 89%\nby leveraging expert rules based on domain knowledge. We also highlight\nlimitations related to token length constraints and computational efficiency.\nOur methodology suggests improvements for future multilingual deduplication\ntasks.",
      "tldr_zh": "这篇论文探讨了使用 NLP 工具对多语言文本数据进行去重的策略，比较了两种方法：先翻译成英语再用 mpnet 嵌入的二步法，以及直接使用 distiluse 多语言嵌入模型。结果显示，二步法取得了更高的 F1 score（82% vs. 60%），尤其在较少使用的语言上，通过结合基于领域知识的专家规则，可进一步提升至89%。论文还指出了 token 长度限制和计算效率的局限性，并为未来多语言去重任务提供了改进建议。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13695v1",
      "published_date": "2024-06-19 16:48:14 UTC",
      "updated_date": "2024-06-19 16:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:41.873751"
    },
    {
      "arxiv_id": "2407.00071v1",
      "title": "Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines via Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mert Esencan",
        "Tarun Advaith Kumar",
        "Ata Akbari Asanjan",
        "P. Aaron Lott",
        "Masoud Mohseni",
        "Can Unlu",
        "Davide Venturelli",
        "Alan Ho"
      ],
      "abstract": "Recent Large Language Models (LLMs) have demonstrated impressive capabilities\nat tasks that require human intelligence and are a significant step towards\nhuman-like artificial intelligence (AI). Yet the performance of LLMs at\nreasoning tasks have been subpar and the reasoning capability of LLMs is a\nmatter of significant debate. While it has been shown that the choice of the\nprompting technique to the LLM can alter its performance on a multitude of\ntasks, including reasoning, the best performing techniques require human-made\nprompts with the knowledge of the tasks at hand. We introduce a framework for\nwhat we call Combinatorial Reasoning (CR), a fully-automated prompting method,\nwhere reasons are sampled from an LLM pipeline and mapped into a Quadratic\nUnconstrained Binary Optimization (QUBO) problem. The framework investigates\nwhether QUBO solutions can be profitably used to select a useful subset of the\nreasons to construct a Chain-of-Thought style prompt. We explore the\nacceleration of CR with specialized solvers. We also investigate the\nperformance of simpler zero-shot strategies such as linear majority rule or\nrandom selection of reasons. Our preliminary study indicates that coupling a\ncombinatorial solver to generative AI pipelines is an interesting avenue for AI\nreasoning and elucidates design principles for future CR methods.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在推理任务上的不足，并提出 Combinatorial Reasoning (CR) 框架作为一种全自动提示方法。CR 通过从 LLM 管道中采样理由，并将它们映射为 Quadratic Unconstrained Binary Optimization (QUBO) 问题，来选择有用的理由子集，从而构建 Chain-of-Thought 风格的提示。研究还考察了使用专用求解器加速 CR，以及更简单的零样本策略如线性多数规则或随机选择。初步结果表明，这种将组合优化与生成式 AI 管道结合的方法为提升 AI 推理能力提供了新途径，并为未来 CR 方法的设计提供了原则。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.00071v1",
      "published_date": "2024-06-19 16:47:44 UTC",
      "updated_date": "2024-06-19 16:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:15:55.705875"
    },
    {
      "arxiv_id": "2406.13694v1",
      "title": "An Embedded Intelligent System for Attendance Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Touzene Abderraouf",
        "Abed Abdeljalil Wassim",
        "Slimane Larabi"
      ],
      "abstract": "In this paper, we propose an intelligent embedded system for monitoring class\nattendance and sending the attendance list to a remote computer. The proposed\nsystem consists of two parts : an embedded device (Raspberry with PI camera)\nfor facial recognition and a web application for attendance management. The\nproposed solution take into account the different challenges: the limited\nresources of the Raspberry Pi, the need to adapt the facial recognition model\nand achieving acceptable performance using images provided by the Raspberry Pi\ncamera.",
      "tldr_zh": "本论文提出了一种用于课堂出勤监控的智能嵌入式系统（Embedded Intelligent System），该系统可将出勤列表发送到远程计算机。系统由两个部分组成：一个基于 Raspberry Pi 和 PI camera 进行面部识别的嵌入式设备，以及一个用于出勤管理的 web application。该方案针对 Raspberry Pi 的有限资源、面部识别模型的适应性和使用 PI camera 图像实现可接受性能的挑战进行了优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13694v1",
      "published_date": "2024-06-19 16:46:19 UTC",
      "updated_date": "2024-06-19 16:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:16:06.560652"
    },
    {
      "arxiv_id": "2406.13693v1",
      "title": "From Single Agent to Multi-Agent: Improving Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Maksim Tislenko",
        "Dmitrii Kisilev"
      ],
      "abstract": "Due to accelerating urbanization, the importance of solving the signal\ncontrol problem increases. This paper analyzes various existing methods and\nsuggests options for increasing the number of agents to reduce the average\ntravel time. Experiments were carried out with 2 datasets. The results show\nthat in some cases, the implementation of multiple agents can improve existing\nmethods. For a fine-tuned large language model approach there is small\nenhancement on all metrics.",
      "tldr_zh": "这篇论文探讨了从单代理到多代理的方法，以改善交通信号控制问题，旨在通过增加代理数量来减少平均旅行时间。作者分析了现有方法，并在2个数据集上进行实验，结果显示多代理在某些情况下能提升现有方法的性能；对于微调的大型语言模型（fine-tuned large language model）方法，所有指标上均有小幅增强。该研究为城市交通优化提供了潜在的实用策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.13693v1",
      "published_date": "2024-06-19 16:46:15 UTC",
      "updated_date": "2024-06-19 16:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:16:19.356981"
    },
    {
      "arxiv_id": "2406.13688v1",
      "title": "Development of a Dual-Input Neural Model for Detecting AI-Generated Imagery",
      "title_zh": "双输入神经模型的开发，用于检测 AI 生成图像",
      "authors": [
        "Jonathan Gallagher",
        "William Pugsley"
      ],
      "abstract": "Over the past years, images generated by artificial intelligence have become\nmore prevalent and more realistic. Their advent raises ethical questions\nrelating to misinformation, artistic expression, and identity theft, among\nothers. The crux of many of these moral questions is the difficulty in\ndistinguishing between real and fake images. It is important to develop tools\nthat are able to detect AI-generated images, especially when these images are\ntoo realistic-looking for the human eye to identify as fake. This paper\nproposes a dual-branch neural network architecture that takes both images and\ntheir Fourier frequency decomposition as inputs. We use standard CNN-based\nmethods for both branches as described in Stuchi et al. [7], followed by\nfully-connected layers. Our proposed model achieves an accuracy of 94% on the\nCIFAKE dataset, which significantly outperforms classic ML methods and CNNs,\nachieving performance comparable to some state-of-the-art architectures, such\nas ResNet.",
      "tldr_zh": "本文研究了 AI 生成图像的日益普遍性及其引发的道德问题，如误传信息和身份盗用，并提出了一种双输入神经模型（Dual-Input Neural Model）来检测这些图像。模型采用图像及其傅立叶频率分解（Fourier frequency decomposition）作为输入，通过双分支基于 CNN 的架构进行处理。实验结果显示，该模型在 CIFAKE 数据集上达到 94% 的准确率，显著优于经典机器学习方法和标准 CNN，并与 ResNet 等最先进架构的性能相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13688v1",
      "published_date": "2024-06-19 16:42:04 UTC",
      "updated_date": "2024-06-19 16:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:16:33.610991"
    },
    {
      "arxiv_id": "2406.13683v1",
      "title": "IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning",
      "title_zh": "IntCoOp：可解释性感知的视觉-语言提示调优",
      "authors": [
        "Soumya Suvra Ghosal",
        "Samyadeep Basu",
        "Soheil Feizi",
        "Dinesh Manocha"
      ],
      "abstract": "Image-text contrastive models such as CLIP learn transferable and robust\nrepresentations for zero-shot transfer to a variety of downstream tasks.\nHowever, to obtain strong downstream performances, prompts need to be carefully\ncurated, which can be a tedious engineering task. To address the issue of\nmanual prompt engineering, prompt-tuning is used where a set of contextual\nvectors are learned by leveraging information from the training data. Despite\ntheir effectiveness, existing prompt-tuning frameworks often lack\ninterpretability, thus limiting their ability to understand the compositional\nnature of images. In this work, we first identify that incorporating\ncompositional attributes (e.g., a \"green\" tree frog) in the design of manual\nprompts can significantly enhance image-text alignment scores. Building upon\nthis observation, we propose a novel and interpretable prompt-tuning method\nnamed IntCoOp, which learns to jointly align attribute-level inductive biases\nand class embeddings during prompt-tuning. To assess the effectiveness of our\napproach, we evaluate IntCoOp across two representative tasks in a few-shot\nlearning setup: generalization to novel classes, and unseen domain shifts.\nThrough extensive experiments across 10 downstream datasets on CLIP, we find\nthat introducing attribute-level inductive biases leads to superior performance\nagainst state-of-the-art prompt tuning frameworks. Notably, in a 16-shot setup,\nIntCoOp improves CoOp by 7.35% in average performance across 10 diverse\ndatasets.",
      "tldr_zh": "这篇论文针对图像-文本对比模型如 CLIP 的提示调整问题，提出了一种可解释性aware的方法 IntCoOp，以解决现有框架缺乏解释性和对图像组合性质理解不足的局限。IntCoOp 通过联合学习属性级归纳偏差（如“green” tree frog）和类嵌入，在提示调整过程中提升图像-文本对齐分数，并在少样本学习设置下评估泛化到新类和未见域转移。实验结果显示，在 10 个下游数据集上，IntCoOp 在 16-shot 场景下比 CoOp 平均性能提高了 7.35%，证明了引入属性级归纳偏差的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13683v1",
      "published_date": "2024-06-19 16:37:31 UTC",
      "updated_date": "2024-06-19 16:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:16:55.521357"
    },
    {
      "arxiv_id": "2406.13664v1",
      "title": "Root-KGD: A Novel Framework for Root Cause Diagnosis Based on Knowledge Graph and Industrial Data",
      "title_zh": "Root-KGD: 一种基于知识图谱和工业数据的根因诊断新型框架",
      "authors": [
        "Jiyu Chen",
        "Jinchuan Qian",
        "Xinmin Zhang",
        "Zhihuan Song"
      ],
      "abstract": "With the development of intelligent manufacturing and the increasing\ncomplexity of industrial production, root cause diagnosis has gradually become\nan important research direction in the field of industrial fault diagnosis.\nHowever, existing research methods struggle to effectively combine domain\nknowledge and industrial data, failing to provide accurate, online, and\nreliable root cause diagnosis results for industrial processes. To address\nthese issues, a novel fault root cause diagnosis framework based on knowledge\ngraph and industrial data, called Root-KGD, is proposed. Root-KGD uses the\nknowledge graph to represent domain knowledge and employs data-driven modeling\nto extract fault features from industrial data. It then combines the knowledge\ngraph and data features to perform knowledge graph reasoning for root cause\nidentification. The performance of the proposed method is validated using two\nindustrial process cases, Tennessee Eastman Process (TEP) and Multiphase Flow\nFacility (MFF). Compared to existing methods, Root-KGD not only gives more\naccurate root cause variable diagnosis results but also provides interpretable\nfault-related information by locating faults to corresponding physical entities\nin knowledge graph (such as devices and streams). In addition, combined with\nits lightweight nature, Root-KGD is more effective in online industrial\napplications.",
      "tldr_zh": "本研究针对工业故障诊断中的根因诊断问题，提出了一种新型框架 Root-KGD，该框架结合知识图谱（Knowledge Graph）和工业数据，以解决现有方法无法有效整合领域知识和数据导致的诊断不准确和不可靠问题。Root-KGD 使用知识图谱表示领域知识，并通过数据驱动建模提取故障特征，然后进行知识图谱推理（Knowledge Graph Reasoning）来识别根因。实验在 Tennessee Eastman Process (TEP) 和 Multiphase Flow Facility (MFF) 两个工业案例中验证，该框架不仅提供更准确的根因变量诊断结果，还通过定位故障到知识图谱中的物理实体（如设备和流体）实现可解释性，并因其轻量级设计更适合在线工业应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13664v1",
      "published_date": "2024-06-19 16:11:43 UTC",
      "updated_date": "2024-06-19 16:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:16:55.305014"
    },
    {
      "arxiv_id": "2406.13663v4",
      "title": "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jirui Qi",
        "Gabriele Sarti",
        "Raquel Fernández",
        "Arianna Bisazza"
      ],
      "abstract": "Ensuring the verifiability of model answers is a fundamental challenge for\nretrieval-augmented generation (RAG) in the question answering (QA) domain.\nRecently, self-citation prompting was proposed to make large language models\n(LLMs) generate citations to supporting documents along with their answers.\nHowever, self-citing LLMs often struggle to match the required format, refer to\nnon-existent sources, and fail to faithfully reflect LLMs' context usage\nthroughout the generation. In this work, we present MIRAGE --Model\nInternals-based RAG Explanations -- a plug-and-play approach using model\ninternals for faithful answer attribution in RAG applications. MIRAGE detects\ncontext-sensitive answer tokens and pairs them with retrieved documents\ncontributing to their prediction via saliency methods. We evaluate our proposed\napproach on a multilingual extractive QA dataset, finding high agreement with\nhuman answer attribution. On open-ended QA, MIRAGE achieves citation quality\nand efficiency comparable to self-citation while also allowing for a\nfiner-grained control of attribution parameters. Our qualitative evaluation\nhighlights the faithfulness of MIRAGE's attributions and underscores the\npromising application of model internals for RAG answer attribution.",
      "tldr_zh": "本研究针对检索增强生成（RAG）中答案可验证性的挑战，提出了一种基于模型内部的即插即用方法——MIRAGE，用于实现可信赖的答案归因。MIRAGE 通过检测上下文敏感的答案标记，并利用显著性方法将这些标记与贡献于预测的检索文档配对，从而解决现有 self-citation 提示的格式问题和不忠实性。在多语言提取式和开放式 QA 数据集上的实验显示，MIRAGE 与人类归因高度一致，并提供与 self-citation 相当的引用质量和效率，同时允许更细粒度的归因控制，突显了模型内部在 RAG 应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main Conference. Code and data released at\n  https://github.com/Betswish/MIRAGE",
      "pdf_url": "http://arxiv.org/pdf/2406.13663v4",
      "published_date": "2024-06-19 16:10:26 UTC",
      "updated_date": "2024-10-18 13:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:17:10.143806"
    },
    {
      "arxiv_id": "2406.13660v1",
      "title": "Towards Minimal Targeted Updates of Language Models with Targeted Negative Training",
      "title_zh": "翻译失败",
      "authors": [
        "Lily H. Zhang",
        "Rajesh Ranganath",
        "Arya Tafvizi"
      ],
      "abstract": "Generative models of language exhibit impressive capabilities but still place\nnon-negligible probability mass over undesirable outputs. In this work, we\naddress the task of updating a model to avoid unwanted outputs while minimally\nchanging model behavior otherwise, a challenge we refer to as a minimal\ntargeted update. We first formalize the notion of a minimal targeted update and\npropose a method to achieve such updates using negative examples from a model's\ngenerations. Our proposed Targeted Negative Training (TNT) results in updates\nthat keep the new distribution close to the original, unlike existing losses\nfor negative signal which push down probability but do not control what the\nupdated distribution will be. In experiments, we demonstrate that TNT yields a\nbetter trade-off between reducing unwanted behavior and maintaining model\ngeneration behavior than baselines, paving the way towards a modeling paradigm\nbased on iterative training updates that constrain models from generating\nundesirable outputs while preserving their impressive capabilities.",
      "tldr_zh": "这篇论文针对语言模型生成不想要输出的问题，提出了一种最小化针对性更新（minimal targeted update）的方法，以减少不良行为同时尽量不改变模型的其他表现。研究者开发了Targeted Negative Training (TNT)，通过利用模型生成的负例进行训练，确保更新后模型的分布与原分布保持接近，从而避免现有损失函数可能导致的过度改变。实验结果表明，TNT 在减少不想要输出与维持模型生成能力之间提供了更好的权衡，为基于迭代训练的语言模型范式铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in Transactions of Machine Learning Research",
      "pdf_url": "http://arxiv.org/pdf/2406.13660v1",
      "published_date": "2024-06-19 16:06:21 UTC",
      "updated_date": "2024-06-19 16:06:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:17:22.169997"
    },
    {
      "arxiv_id": "2406.13659v1",
      "title": "Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health",
      "title_zh": "利用大型语言模型提升患者参与：对话式人工智能在数字健康中的力量",
      "authors": [
        "Bo Wen",
        "Raquel Norel",
        "Julia Liu",
        "Thaddeus Stappenbeck",
        "Farhana Zulkernine",
        "Huamin Chen"
      ],
      "abstract": "The rapid advancements in large language models (LLMs) have opened up new\nopportunities for transforming patient engagement in healthcare through\nconversational AI. This paper presents an overview of the current landscape of\nLLMs in healthcare, specifically focusing on their applications in analyzing\nand generating conversations for improved patient engagement. We showcase the\npower of LLMs in handling unstructured conversational data through four case\nstudies: (1) analyzing mental health discussions on Reddit, (2) developing a\npersonalized chatbot for cognitive engagement in seniors, (3) summarizing\nmedical conversation datasets, and (4) designing an AI-powered patient\nengagement system. These case studies demonstrate how LLMs can effectively\nextract insights and summarizations from unstructured dialogues and engage\npatients in guided, goal-oriented conversations. Leveraging LLMs for\nconversational analysis and generation opens new doors for many\npatient-centered outcomes research opportunities. However, integrating LLMs\ninto healthcare raises important ethical considerations regarding data privacy,\nbias, transparency, and regulatory compliance. We discuss best practices and\nguidelines for the responsible development and deployment of LLMs in healthcare\nsettings. Realizing the full potential of LLMs in digital health will require\nclose collaboration between the AI and healthcare professionals communities to\naddress technical challenges and ensure these powerful tools' safety, efficacy,\nand equity.",
      "tldr_zh": "本论文探讨了利用大型语言模型（LLMs）提升患者参与度的潜力，强调Conversational AI在数字健康领域的应用。通过四个案例研究，包括分析Reddit上的心理健康讨论、开发个性化聊天机器人用于老年认知参与、总结医疗对话数据集以及设计AI驱动患者参与系统，LLMs展示了从非结构化对话中提取洞见并生成引导性对话的能力。研究发现，LLMs可显著改善患者中心结果，但需注意数据隐私、偏差、透明度和合规性等伦理问题。最终，论文呼吁AI和医疗专业人士合作，确保LLMs的安全、有效性和公平性，以实现其在数字健康中的全面潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures, ICDH 2024 invited paper",
      "pdf_url": "http://arxiv.org/pdf/2406.13659v1",
      "published_date": "2024-06-19 16:02:04 UTC",
      "updated_date": "2024-06-19 16:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:17:41.283898"
    },
    {
      "arxiv_id": "2406.13655v1",
      "title": "Improving GFlowNets with Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Morozov",
        "Daniil Tiapkin",
        "Sergey Samsonov",
        "Alexey Naumov",
        "Dmitry Vetrov"
      ],
      "abstract": "Generative Flow Networks (GFlowNets) treat sampling from distributions over\ncompositional discrete spaces as a sequential decision-making problem, training\na stochastic policy to construct objects step by step. Recent studies have\nrevealed strong connections between GFlowNets and entropy-regularized\nreinforcement learning. Building on these insights, we propose to enhance\nplanning capabilities of GFlowNets by applying Monte Carlo Tree Search (MCTS).\nSpecifically, we show how the MENTS algorithm (Xiao et al., 2019) can be\nadapted for GFlowNets and used during both training and inference. Our\nexperiments demonstrate that this approach improves the sample efficiency of\nGFlowNet training and the generation fidelity of pre-trained GFlowNet models.",
      "tldr_zh": "这篇论文提出了一种改进 Generative Flow Networks (GFlowNets) 的方法，通过整合 Monte Carlo Tree Search (MCTS) 来提升其规划能力。作者基于 GFlowNets 与熵正则化强化学习的紧密联系，适应了 MENTS 算法（Xiao et al., 2019），并将其应用于 GFlowNets 的训练和推理过程。实验结果表明，这种方法显著提高了 GFlowNets 的样本效率和生成保真度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 SPIGM Workshop",
      "pdf_url": "http://arxiv.org/pdf/2406.13655v1",
      "published_date": "2024-06-19 15:58:35 UTC",
      "updated_date": "2024-06-19 15:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:17:53.945589"
    },
    {
      "arxiv_id": "2406.13652v1",
      "title": "Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Weitong Zhang",
        "Chengqi Zang",
        "Liu Li",
        "Sarah Cechnicka",
        "Cheng Ouyang",
        "Bernhard Kainz"
      ],
      "abstract": "Inverse problems describe the process of estimating the causal factors from a\nset of measurements or data. Mapping of often incomplete or degraded data to\nparameters is ill-posed, thus data-driven iterative solutions are required, for\nexample when reconstructing clean images from poor signals. Diffusion models\nhave shown promise as potent generative tools for solving inverse problems due\nto their superior reconstruction quality and their compatibility with iterative\nsolvers. However, most existing approaches are limited to linear inverse\nproblems represented as Stochastic Differential Equations (SDEs). This\nsimplification falls short of addressing the challenging nature of real-world\nproblems, leading to amplified cumulative errors and biases. We provide an\nexplanation for this gap through the lens of measure-preserving dynamics of\nRandom Dynamical Systems (RDS) with which we analyse Temporal Distribution\nDiscrepancy and thus introduce a theoretical framework based on RDS for SDE\ndiffusion models. We uncover several strategies that inherently enhance the\nstability and generalizability of diffusion models for inverse problems and\nintroduce a novel score-based diffusion framework, the \\textbf{D}ynamics-aware\nS\\textbf{D}E \\textbf{D}iffusion \\textbf{G}enerative \\textbf{M}odel (D$^3$GM).\nThe \\textit{Measure-preserving property} can return the degraded measurement to\nthe original state despite complex degradation with the RDS concept of\n\\textit{stability}. Our extensive experimental results corroborate the\neffectiveness of D$^3$GM across multiple benchmarks including a prominent\napplication for inverse problems, magnetic resonance imaging. Code and data\nwill be publicly available.",
      "tldr_zh": "本论文探讨了扩散模型在解决逆问题（inverse problems）时的稳定性和泛化性问题，指出现有方法主要限于线性随机微分方程（SDE），导致累积错误和偏差放大。作者通过随机动力系统（RDS）的视角分析了时间分布差异（Temporal Distribution Discrepancy），并引入了基于度量保持动力学（measure-preserving dynamics）的理论框架。论文提出了一种新框架D$^3$GM（Dynamics-aware SDE Diffusion Generative Model），利用度量保持特性（Measure-preserving property）和稳定性（stability）概念，提升了模型在复杂退化数据下的重建性能。实验结果显示，D$^3$GM 在多个基准测试中表现出色，包括磁共振成像（magnetic resonance imaging）应用，并证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13652v1",
      "published_date": "2024-06-19 15:55:12 UTC",
      "updated_date": "2024-06-19 15:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:18:07.954953"
    },
    {
      "arxiv_id": "2406.13631v2",
      "title": "On AI-Inspired UI-Design",
      "title_zh": "翻译失败",
      "authors": [
        "Jialiang Wei",
        "Anne-Lise Courbis",
        "Thomas Lambolais",
        "Gérard Dray",
        "Walid Maalej"
      ],
      "abstract": "Graphical User Interface (or simply UI) is a primary mean of interaction\nbetween users and their devices. In this paper, we discuss three complementary\nArtificial Intelligence (AI) approaches for triggering the creativity of app\ndesigners and inspiring them create better and more diverse UI designs. First,\ndesigners can prompt a Large Language Model (LLM) to directly generate and\nadjust UIs. Second, a Vision-Language Model (VLM) enables designers to\neffectively search a large screenshot dataset, e.g. from apps published in app\nstores. Third, a Diffusion Model (DM) can be trained to specifically generate\nUIs as inspirational images. We present an AI-inspired design process and\ndiscuss the implications and limitations of the approaches.",
      "tldr_zh": "本文探讨了利用人工智能（AI）激发图形用户界面（UI）设计的创意，提出了三种互补方法：使用Large Language Model (LLM)直接生成和调整UI设计；通过Vision-Language Model (VLM)搜索大型截图数据集以提供灵感；以及训练Diffusion Model (DM)生成UI相关图像。论文呈现了一个AI-inspired设计过程，强调这些方法如何帮助设计师创建更丰富多样的UI。最终，研究讨论了这些方法的潜在含义和限制，以促进更有效的UI创新。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13631v2",
      "published_date": "2024-06-19 15:28:21 UTC",
      "updated_date": "2025-01-28 16:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:18:18.601038"
    },
    {
      "arxiv_id": "2406.13626v1",
      "title": "Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News Headlines",
      "title_zh": "微调 Gemma-7B 用于增强金融新闻标题的情感分析",
      "authors": [
        "Kangtong Mo",
        "Wenyan Liu",
        "Xuanzhen Xu",
        "Chang Yu",
        "Yuelin Zou",
        "Fangqing Xia"
      ],
      "abstract": "In this study, we explore the application of sentiment analysis on financial\nnews headlines to understand investor sentiment. By leveraging Natural Language\nProcessing (NLP) and Large Language Models (LLM), we analyze sentiment from the\nperspective of retail investors. The FinancialPhraseBank dataset, which\ncontains categorized sentiments of financial news headlines, serves as the\nbasis for our analysis. We fine-tuned several models, including\ndistilbert-base-uncased, Llama, and gemma-7b, to evaluate their effectiveness\nin sentiment classification. Our experiments demonstrate that the fine-tuned\ngemma-7b model outperforms others, achieving the highest precision, recall, and\nF1 score. Specifically, the gemma-7b model showed significant improvements in\naccuracy after fine-tuning, indicating its robustness in capturing the nuances\nof financial sentiment. This model can be instrumental in providing market\ninsights, risk management, and aiding investment decisions by accurately\npredicting the sentiment of financial news. The results highlight the potential\nof advanced LLMs in transforming how we analyze and interpret financial\ninformation, offering a powerful tool for stakeholders in the financial\nindustry.",
      "tldr_zh": "本研究探讨了使用自然语言处理(NLP)和大型语言模型(LLM)对金融新闻标题进行情感分析，以理解零售投资者的情绪。研究基于FinancialPhraseBank数据集，微调了distilbert-base-uncased、Llama和gemma-7b等模型进行情感分类实验。结果显示，微调后的gemma-7b模型表现出色，实现了最高的precision、recall和F1 score，比其他模型提高了准确性。该方法为市场洞察、风险管理和投资决策提供了强大工具，突显了高级LLM在金融信息分析中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13626v1",
      "published_date": "2024-06-19 15:20:19 UTC",
      "updated_date": "2024-06-19 15:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:18:31.218087"
    },
    {
      "arxiv_id": "2406.13625v1",
      "title": "Enhance the Image: Super Resolution using Artificial Intelligence in MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Li",
        "Zihan Li",
        "Haoxiang Li",
        "Qiuyun Fan",
        "Karla L. Miller",
        "Wenchuan Wu",
        "Akshay S. Chaudhari",
        "Qiyuan Tian"
      ],
      "abstract": "This chapter provides an overview of deep learning techniques for improving\nthe spatial resolution of MRI, ranging from convolutional neural networks,\ngenerative adversarial networks, to more advanced models including\ntransformers, diffusion models, and implicit neural representations. Our\nexploration extends beyond the methodologies to scrutinize the impact of\nsuper-resolved images on clinical and neuroscientific assessments. We also\ncover various practical topics such as network architectures, image evaluation\nmetrics, network loss functions, and training data specifics, including\ndownsampling methods for simulating low-resolution images and dataset\nselection. Finally, we discuss existing challenges and potential future\ndirections regarding the feasibility and reliability of deep learning-based MRI\nsuper-resolution, with the aim to facilitate its wider adoption to benefit\nvarious clinical and neuroscientific applications.",
      "tldr_zh": "本论文概述了深度学习技术用于提升 MRI 图像的空间分辨率，包括 convolutional neural networks、generative adversarial networks 以及更先进的模型如 transformers、diffusion models 和 implicit neural representations。这些方法不仅改善图像质量，还探讨了超分辨率图像对临床和神经科学评估的影响，同时涵盖网络架构、图像评估指标、网络损失函数以及训练数据细节如下采样方法和数据集选择。论文讨论了现有挑战和未来方向，以推动深度学习-based MRI 超分辨率的更广泛应用，从而惠及临床和神经科学领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "comment": "A book chapter in Machine Learning in MRI: From methods to clinical\n  translation",
      "pdf_url": "http://arxiv.org/pdf/2406.13625v1",
      "published_date": "2024-06-19 15:19:41 UTC",
      "updated_date": "2024-06-19 15:19:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:18:42.760718"
    },
    {
      "arxiv_id": "2406.13617v1",
      "title": "Optimizing Psychological Counseling with Instruction-Tuned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjie Li",
        "Tianyu Sun",
        "Kun Qian",
        "Wenhong Wang"
      ],
      "abstract": "The advent of large language models (LLMs) has significantly advanced various\nfields, including natural language processing and automated dialogue systems.\nThis paper explores the application of LLMs in psychological counseling,\naddressing the increasing demand for mental health services. We present a\nmethod for instruction tuning LLMs with specialized prompts to enhance their\nperformance in providing empathetic, relevant, and supportive responses. Our\napproach involves developing a comprehensive dataset of counseling-specific\nprompts, refining them through feedback from professional counselors, and\nconducting rigorous evaluations using both automatic metrics and human\nassessments. The results demonstrate that our instruction-tuned model\noutperforms several baseline LLMs, highlighting its potential as a scalable and\naccessible tool for mental health support.",
      "tldr_zh": "这篇论文探讨了如何通过指令调整（instruction tuning）大型语言模型（LLMs）来优化心理咨询服务，以应对日益增长的心理健康需求。研究方法包括开发一个专用的咨询提示数据集，并通过专业咨询师的反馈进行完善，同时采用自动指标和人工评估进行评估。结果表明，指令调整后的模型在提供富有同情心、相关和支持性响应方面优于基线模型，展示了其作为可扩展、可访问心理健康支持工具的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.13617v1",
      "published_date": "2024-06-19 15:13:07 UTC",
      "updated_date": "2024-06-19 15:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:18:54.505650"
    },
    {
      "arxiv_id": "2406.13605v2",
      "title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner's Dilemma?",
      "title_zh": "比人类更友好：大型语言模型在囚徒困境中的行为如何？",
      "authors": [
        "Nicoló Fontana",
        "Francesco Pierri",
        "Luca Maria Aiello"
      ],
      "abstract": "The behavior of Large Language Models (LLMs) as artificial social agents is\nlargely unexplored, and we still lack extensive evidence of how these agents\nreact to simple social stimuli. Testing the behavior of AI agents in classic\nGame Theory experiments provides a promising theoretical framework for\nevaluating the norms and values of these agents in archetypal social\nsituations. In this work, we investigate the cooperative behavior of three LLMs\n(Llama2, Llama3, and GPT3.5) when playing the Iterated Prisoner's Dilemma\nagainst random adversaries displaying various levels of hostility. We introduce\na systematic methodology to evaluate an LLM's comprehension of the game rules\nand its capability to parse historical gameplay logs for decision-making. We\nconducted simulations of games lasting for 100 rounds and analyzed the LLMs'\ndecisions in terms of dimensions defined in the behavioral economics\nliterature. We find that all models tend not to initiate defection but act\ncautiously, favoring cooperation over defection only when the opponent's\ndefection rate is low. Overall, LLMs behave at least as cooperatively as the\ntypical human player, although our results indicate some substantial\ndifferences among models. In particular, Llama2 and GPT3.5 are more cooperative\nthan humans, and especially forgiving and non-retaliatory for opponent\ndefection rates below 30%. More similar to humans, Llama3 exhibits consistently\nuncooperative and exploitative behavior unless the opponent always cooperates.\nOur systematic approach to the study of LLMs in game theoretical scenarios is a\nstep towards using these simulations to inform practices of LLM auditing and\nalignment.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 在迭代囚徒困境游戏中的合作行为，使用 Llama2、Llama3 和 GPT3.5 与随机对手进行模拟实验。研究引入了系统方法来评估 LLMs 对游戏规则的理解和基于历史游戏日志的决策分析，结果显示这些模型倾向不先背叛，但在对手背叛率低时更倾向合作。总体上，LLMs 的合作水平至少与人类相当，其中 Llama2 和 GPT3.5 比人类更宽容和非报复性，尤其在对手背叛率低于 30% 时，而 Llama3 更像人类，表现出不合作和剥削倾向，除非对手始终合作。该方法为 LLMs 的审计和对齐实践提供了重要见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.GT",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "v1: 9 pages, 8 figures, 1 table v2: 11 pages, 14 figures, 1 table.\n  Increased number of models studied, expanded results and conclusion, added\n  references, corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2406.13605v2",
      "published_date": "2024-06-19 14:51:14 UTC",
      "updated_date": "2024-09-19 15:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:19:07.964874"
    },
    {
      "arxiv_id": "2406.13604v1",
      "title": "Root Cause Localization for Microservice Systems in Cloud-edge Collaborative Environments",
      "title_zh": "云边协同环境中微服务系统的根因定位",
      "authors": [
        "Yuhan Zhu",
        "Jian Wang",
        "Bing Li",
        "Xuxian Tang",
        "Hao Li",
        "Neng Zhang",
        "Yuqi Zhao"
      ],
      "abstract": "With the development of cloud-native technologies, microservice-based\nsoftware systems face challenges in accurately localizing root causes when\nfailures occur. Additionally, the cloud-edge collaborative environment\nintroduces more difficulties, such as unstable networks and high latency across\nnetwork segments. Accurately identifying the root cause of microservices in a\ncloud-edge collaborative environment has thus become an urgent problem. In this\npaper, we propose MicroCERCL, a novel approach that pinpoints root causes at\nthe kernel and application level in the cloud-edge collaborative environment.\nOur key insight is that failures propagate through direct invocations and\nindirect resource-competition dependencies in a cloud-edge collaborative\nenvironment characterized by instability and high latency. This will become\nmore complex in the hybrid deployment that simultaneously involves multiple\nmicroservice systems. Leveraging this insight, we extract valid contents from\nkernel-level logs to prioritize localizing the kernel-level root cause.\nMoreover, we construct a heterogeneous dynamic topology stack and train a graph\nneural network model to accurately localize the application-level root cause\nwithout relying on historical data. Notably, we released the first benchmark\nhybrid deployment microservice system in a cloud-edge collaborative environment\n(the largest and most complex within our knowledge). Experiments conducted on\nthe dataset collected from the benchmark show that MicroCERCL can accurately\nlocalize the root cause of microservice systems in such environments,\nsignificantly outperforming state-of-the-art approaches with an increase of at\nleast 24.1% in top-1 accuracy.",
      "tldr_zh": "该论文针对云边协同环境（cloud-edge collaborative environments）中微服务系统的故障根因定位挑战，提出了一种新方法MicroCERCL，以应对不稳定网络和高延迟问题。MicroCERCL的关键洞见是故障通过直接调用和间接资源竞争依赖传播，因此它从内核级日志提取有效内容来优先定位内核级根因，并构建异构动态拓扑栈训练图神经网络（graph neural network）模型来准确定位应用级根因，而不依赖历史数据。实验结果显示，在首个基准混合部署微服务系统数据集上，MicroCERCL的top-1 accuracy比现有方法至少提高了24.1%，显著提升了根因定位性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13604v1",
      "published_date": "2024-06-19 14:49:37 UTC",
      "updated_date": "2024-06-19 14:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:19:19.591402"
    },
    {
      "arxiv_id": "2406.13600v1",
      "title": "CoDreamer: Communication-Based Decentralised World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Edan Toledo",
        "Amanda Prorok"
      ],
      "abstract": "Sample efficiency is a critical challenge in reinforcement learning.\nModel-based RL has emerged as a solution, but its application has largely been\nconfined to single-agent scenarios. In this work, we introduce CoDreamer, an\nextension of the Dreamer algorithm for multi-agent environments. CoDreamer\nleverages Graph Neural Networks for a two-level communication system to tackle\nchallenges such as partial observability and inter-agent cooperation.\nCommunication is separately utilised within the learned world models and within\nthe learned policies of each agent to enhance modelling and task-solving. We\nshow that CoDreamer offers greater expressive power than a naive application of\nDreamer, and we demonstrate its superiority over baseline methods across\nvarious multi-agent environments.",
      "tldr_zh": "这篇论文针对强化学习中的样本效率问题，提出了 CoDreamer，一种基于 Dreamer 算法的扩展，适用于多智能体环境。CoDreamer 利用 Graph Neural Networks 构建两级通信系统，在学习的世界模型和策略中增强部分可观察性和智能体间合作，从而提高建模和任务解决能力。实验结果显示，CoDreamer 在多种多智能体环境中表现出色，优于基线方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13600v1",
      "published_date": "2024-06-19 14:42:40 UTC",
      "updated_date": "2024-06-19 14:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:19:30.762876"
    },
    {
      "arxiv_id": "2406.13597v1",
      "title": "GraphKAN: Enhancing Feature Extraction with Graph Kolmogorov Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Zhang",
        "Xin Zhang"
      ],
      "abstract": "Massive number of applications involve data with underlying relationships\nembedded in non-Euclidean space. Graph neural networks (GNNs) are utilized to\nextract features by capturing the dependencies within graphs. Despite\ngroundbreaking performances, we argue that Multi-layer perceptrons (MLPs) and\nfixed activation functions impede the feature extraction due to information\nloss. Inspired by Kolmogorov Arnold Networks (KANs), we make the first attempt\nto GNNs with KANs. We discard MLPs and activation functions, and instead used\nKANs for feature extraction. Experiments demonstrate the effectiveness of\nGraphKAN, emphasizing the potential of KANs as a powerful tool. Code is\navailable at https://github.com/Ryanfzhang/GraphKan.",
      "tldr_zh": "该论文提出 GraphKAN，一种将 Kolmogorov Arnold Networks (KANs) 整合到图神经网络 (GNNs) 中的新框架，以提升非欧空间数据特征提取的性能。传统 GNNs 依赖多层感知机 (MLPs) 和固定激活函数，导致信息损失，因此作者放弃这些组件，转而采用 KANs 来捕获图中的依赖关系。实验结果显示，GraphKAN 在相关任务上表现出色，证明了 KANs 的强大潜力。代码已在 GitHub 上提供，供进一步研究使用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13597v1",
      "published_date": "2024-06-19 14:41:09 UTC",
      "updated_date": "2024-06-19 14:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:19:43.554498"
    },
    {
      "arxiv_id": "2406.13586v1",
      "title": "Submodular Participatory Budgeting",
      "title_zh": "子模参与式预算",
      "authors": [
        "Jing Yuan",
        "Shaojie Tang"
      ],
      "abstract": "Participatory budgeting refers to the practice of allocating public resources\nby collecting and aggregating individual preferences. Most existing studies in\nthis field often assume an additive utility function, where each individual\nholds a private utility for each candidate project, and the total utility of a\nset of funded projects is simply the sum of the utilities of all projects. We\nargue that this assumption does not always hold in reality. For example,\nbuilding two playgrounds in the same neighborhood does not necessarily lead to\ntwice the utility of building a single playground.\n  To address this, we extend the existing study by proposing a submodular\nparticipatory budgeting problem, assuming that the utility function of each\nindividual is a monotone and submodular function over funded projects. We\npropose and examine three preference elicitation methods, including\n\\emph{ranking-by-marginal-values}, \\emph{ranking-by-values} and \\emph{threshold\napproval votes}, and analyze their performances in terms of distortion.\nNotably, if the utility function is addicative, our aggregation rule designed\nfor threshold approval votes achieves a better distortion than the\nstate-of-the-art approach.",
      "tldr_zh": "该论文扩展了参与式预算（Participatory Budgeting）问题，指出传统假设的加性效用函数（additive utility function）不适用于现实场景，如多个项目可能不会线性增加效用，而是采用单调子模（monotone and submodular）函数。作者提出子模参与式预算问题，并评估三种偏好elicitation方法：ranking-by-marginal-values、ranking-by-values 和 threshold approval votes，在distortion方面进行性能分析。这些方法在加性效用条件下，threshold approval votes的聚合规则比现有方法表现出更好的distortion结果，为更准确的资源分配提供了新框架。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13586v1",
      "published_date": "2024-06-19 14:22:54 UTC",
      "updated_date": "2024-06-19 14:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:19:56.019227"
    },
    {
      "arxiv_id": "2406.13569v1",
      "title": "Bayes' capacity as a measure for reconstruction attacks in federated learning",
      "title_zh": "Bayes' 容量作为联邦学习中重建攻击的度量指标",
      "authors": [
        "Sayan Biswas",
        "Mark Dras",
        "Pedro Faustini",
        "Natasha Fernandes",
        "Annabelle McIver",
        "Catuscia Palamidessi",
        "Parastoo Sadeghi"
      ],
      "abstract": "Within the machine learning community, reconstruction attacks are a principal\nattack of concern and have been identified even in federated learning, which\nwas designed with privacy preservation in mind. In federated learning, it has\nbeen shown that an adversary with knowledge of the machine learning\narchitecture is able to infer the exact value of a training element given an\nobservation of the weight updates performed during stochastic gradient descent.\nIn response to these threats, the privacy community recommends the use of\ndifferential privacy in the stochastic gradient descent algorithm, termed\nDP-SGD. However, DP has not yet been formally established as an effective\ncountermeasure against reconstruction attacks. In this paper, we formalise the\nreconstruction threat model using the information-theoretic framework of\nquantitative information flow. We show that the Bayes' capacity, related to the\nSibson mutual information of order infinity, represents a tight upper bound on\nthe leakage of the DP-SGD algorithm to an adversary interested in performing a\nreconstruction attack. We provide empirical results demonstrating the\neffectiveness of this measure for comparing mechanisms against reconstruction\nthreats.",
      "tldr_zh": "这篇论文探讨了联邦学习(federated learning)中重构攻击(reconstruction attacks)的风险，这些攻击能从权重更新中推断训练数据的精确值。作者使用定量信息流(quantitative information flow)的框架形式化了威胁模型，并证明了Bayes' capacity（与Sibson mutual information of order infinity相关）是差分隐私(DP-SGD)算法对重构攻击泄露的紧上界。论文通过实证实验验证了这一度量在评估和比较防护机制的有效性，为提升联邦学习的隐私保护提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13569v1",
      "published_date": "2024-06-19 13:58:42 UTC",
      "updated_date": "2024-06-19 13:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:20:10.550063"
    },
    {
      "arxiv_id": "2406.13568v1",
      "title": "Trapezoidal Gradient Descent for Effective Reinforcement Learning in Spiking Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Pan",
        "Xiucheng Wang",
        "Nan Cheng",
        "Qi Qiu"
      ],
      "abstract": "With the rapid development of artificial intelligence technology, the field\nof reinforcement learning has continuously achieved breakthroughs in both\ntheory and practice. However, traditional reinforcement learning algorithms\noften entail high energy consumption during interactions with the environment.\nSpiking Neural Network (SNN), with their low energy consumption characteristics\nand performance comparable to deep neural networks, have garnered widespread\nattention. To reduce the energy consumption of practical applications of\nreinforcement learning, researchers have successively proposed the Pop-SAN and\nMDC-SAN algorithms. Nonetheless, these algorithms use rectangular functions to\napproximate the spike network during the training process, resulting in low\nsensitivity, thus indicating room for improvement in the training effectiveness\nof SNN. Based on this, we propose a trapezoidal approximation gradient method\nto replace the spike network, which not only preserves the original stable\nlearning state but also enhances the model's adaptability and response\nsensitivity under various signal dynamics. Simulation results show that the\nimproved algorithm, using the trapezoidal approximation gradient to replace the\nspike network, achieves better convergence speed and performance compared to\nthe original algorithm and demonstrates good training stability.",
      "tldr_zh": "该论文针对传统强化学习（reinforcement learning）的高能耗问题，提出了一种基于梯形逼近梯度（trapezoidal approximation gradient）的改进方法，用于脉冲神经网络（Spiking Neural Network, SNN）。该方法替换了现有算法（如Pop-SAN和MDC-SAN）中使用的矩形函数，提高了模型的适应性和响应敏感性，同时保持了稳定的学习状态。模拟结果显示，该改进算法在收敛速度、性能和训练稳定性方面均优于原算法，为低能耗SNN应用提供了有效解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13568v1",
      "published_date": "2024-06-19 13:56:22 UTC",
      "updated_date": "2024-06-19 13:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:20:20.848927"
    },
    {
      "arxiv_id": "2406.13564v1",
      "title": "Is AI fun? HumorDB: a curated dataset and benchmark to investigate graphical humor",
      "title_zh": "翻译失败",
      "authors": [
        "Veedant Jain",
        "Felipe dos Santos Alves Feitosa",
        "Gabriel Kreiman"
      ],
      "abstract": "Despite significant advancements in computer vision, understanding complex\nscenes, particularly those involving humor, remains a substantial challenge.\nThis paper introduces HumorDB, a novel image-only dataset specifically designed\nto advance visual humor understanding. HumorDB consists of meticulously curated\nimage pairs with contrasting humor ratings, emphasizing subtle visual cues that\ntrigger humor and mitigating potential biases. The dataset enables evaluation\nthrough binary classification(Funny or Not Funny), range regression(funniness\non a scale from 1 to 10), and pairwise comparison tasks(Which Image is\nFunnier?), effectively capturing the subjective nature of humor perception.\nInitial experiments reveal that while vision-only models struggle,\nvision-language models, particularly those leveraging large language models,\nshow promising results. HumorDB also shows potential as a valuable zero-shot\nbenchmark for powerful large multimodal models. We open-source both the dataset\nand code under the CC BY 4.0 license.",
      "tldr_zh": "本文介绍了HumorDB，一种专为视觉幽默理解设计的图像-only数据集，该数据集包含精心挑选的图像对，并通过强调微妙视觉线索来减少潜在偏差。HumorDB支持三种评估任务：binary classification（Funny or Not Funny）、range regression（幽默度从1到10的评分）和pairwise comparison（哪张图像更幽默），以捕捉幽默感知的主观性。初步实验发现，vision-only模型表现不佳，而vision-language models，尤其是利用大型语言模型的版本，显示出显著潜力。该数据集还可作为zero-shot benchmark，并以CC BY 4.0许可开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "7 main figures, 5 additional appendix figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13564v1",
      "published_date": "2024-06-19 13:51:40 UTC",
      "updated_date": "2024-06-19 13:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:20:36.815291"
    },
    {
      "arxiv_id": "2406.13558v2",
      "title": "Enhancing Travel Choice Modeling with Large Language Models: A Prompt-Learning Approach",
      "title_zh": "利用大型语言模型增强旅行选择建模：一种提示学习方法",
      "authors": [
        "Xuehao Zhai",
        "Hanlin Tian",
        "Lintong Li",
        "Tianyu Zhao"
      ],
      "abstract": "Travel choice analysis is crucial for understanding individual travel\nbehavior to develop appropriate transport policies and recommendation systems\nin Intelligent Transportation Systems (ITS). Despite extensive research, this\ndomain faces two critical challenges: a) modeling with limited survey data, and\nb) simultaneously achieving high model explainability and accuracy. In this\npaper, we introduce a novel prompt-learning-based Large Language Model(LLM)\nframework that significantly improves prediction accuracy and provides explicit\nexplanations for individual predictions. This framework involves three main\nsteps: transforming input variables into textual form; building of\ndemonstrations similar to the object, and applying these to a well-trained LLM.\nWe tested the framework's efficacy using two widely used choice datasets:\nLondon Passenger Mode Choice (LPMC) and Optima-Mode collected in Switzerland.\nThe results indicate that the LLM significantly outperforms state-of-the-art\ndeep learning methods and discrete choice models in predicting people's\nchoices. Additionally, we present a case of explanation illustrating how the\nLLM framework generates understandable and explicit explanations at the\nindividual level.",
      "tldr_zh": "本研究针对旅行选择建模面临的有限数据和可解释性与准确性平衡挑战，提出了一种基于Prompt-Learning的Large Language Model (LLM)框架，以提升预测性能并提供明确解释。该框架包括三个关键步骤：将输入变量转化为文本形式、构建与目标相似的演示示例，并应用于训练好的LLM。通过在London Passenger Mode Choice (LPMC)和Optima-Mode数据集上的实验，结果显示，该LLM框架在预测个体旅行选择方面显著优于现有深度学习方法和离散选择模型，同时能生成个体级别的可理解解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "We currently do not have a replacement version available. We request\n  withdrawal due to a significant methodological error affecting the paper's\n  validity, specifically a miscalculation in data preprocessing. We are working\n  on corrections, but this will take time. We believe an interim withdrawal is\n  necessary to prevent the dissemination of incorrect information.",
      "pdf_url": "http://arxiv.org/pdf/2406.13558v2",
      "published_date": "2024-06-19 13:46:08 UTC",
      "updated_date": "2024-06-22 14:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:20:48.280824"
    },
    {
      "arxiv_id": "2406.13555v3",
      "title": "BiLD: Bi-directional Logits Difference Loss for Large Language Model Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Minchong Li",
        "Feng Zhou",
        "Xiaohui Song"
      ],
      "abstract": "In recent years, large language models (LLMs) have shown exceptional\ncapabilities across various natural language processing (NLP) tasks. However,\nsuch impressive performance often comes with the trade-off of an increased\nparameter size, posing significant challenges for widespread deployment.\nKnowledge distillation (KD) provides a solution by transferring knowledge from\na large teacher model to a smaller student model. In this paper, we explore the\ntask-specific distillation of LLMs at the logit level. Our investigation\nreveals that the logits of fine-tuned LLMs exhibit a more extreme long-tail\ndistribution than those from vision models, with hidden \"noise\" in the long\ntail affecting distillation performance. Furthermore, existing logits\ndistillation methods often struggle to effectively utilize the internal ranking\ninformation from the logits. To address these, we propose the Bi-directional\nLogits Difference (BiLD) loss. The BiLD loss filters out the long-tail noise by\nutilizing only top-$k$ teacher and student logits, and leverages the internal\nlogits ranking information by constructing logits differences. To evaluate BiLD\nloss, we conduct comprehensive experiments on 13 datasets using two types of\nLLMs. Our results show that the BiLD loss, with only the top-8 logits,\noutperforms supervised fine-tuning (SFT), vanilla KL loss, and five other\ndistillation methods from both NLP and CV fields.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 的参数规模问题，提出了一种知识蒸馏 (KD) 方法，专注于 logits 级别的任务特定蒸馏。论文发现，LLMs 的 logits 分布呈现更极端的长尾效应，包含隐藏噪声，且现有方法未能有效利用 logits 的内部排名信息，因此设计了 Bi-directional Logits Difference (BiLD) loss，该损失通过仅使用 top-k logits 过滤噪声并构建 logits 差异来提升蒸馏性能。在 13 个数据集上的实验表明，BiLD loss 仅需 top-8 logits 就超过了监督微调 (SFT)、vanilla KL loss 和其他五种蒸馏方法，显著提高了学生模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.13555v3",
      "published_date": "2024-06-19 13:44:56 UTC",
      "updated_date": "2025-02-18 00:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:20:59.027990"
    },
    {
      "arxiv_id": "2406.13551v1",
      "title": "Mitigating Social Biases in Language Models through Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Omkar Dige",
        "Diljot Singh",
        "Tsz Fung Yau",
        "Qixuan Zhang",
        "Borna Bolandraftar",
        "Xiaodan Zhu",
        "Faiza Khan Khattak"
      ],
      "abstract": "Mitigating bias in language models (LMs) has become a critical problem due to\nthe widespread deployment of LMs. Numerous approaches revolve around data\npre-processing and fine-tuning of language models, tasks that can be both\ntime-consuming and computationally demanding. Consequently, there is a growing\ninterest in machine unlearning techniques given their capacity to induce the\nforgetting of undesired behaviors of the existing pre-trained or fine-tuned\nmodels with lower computational cost. In this work, we explore two unlearning\nmethods, (1) Partitioned Contrastive Gradient Unlearning (PCGU) applied on\ndecoder models and (2) Negation via Task Vector, to reduce social biases in\nstate-of-the-art and open-source LMs such as LLaMA-2 and OPT. We also implement\ndistributed PCGU for large models. It is empirically shown, through\nquantitative and qualitative analyses, that negation via Task Vector method\noutperforms PCGU in debiasing with minimum deterioration in performance and\nperplexity of the models. On LLaMA-27B, negation via Task Vector reduces the\nbias score by 11.8%",
      "tldr_zh": "该论文探讨了通过机器取消学习(unlearning)技术缓解语言模型(LMs)中的社会偏差问题，以避免传统数据预处理和微调方法的计算密集性。研究者评估了两种方法：Partitioned Contrastive Gradient Unlearning (PCGU)应用于解码器模型，以及Negation via Task Vector，用于减少LLaMA-2和OPT等模型的偏差。实验结果显示，Negation via Task Vector方法在降低偏差方面优于PCGU，仅导致最小性能和困惑度下降，在LLaMA-27B模型上将偏差分数降低了11.8%。这为高效的LM去偏差策略提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13551v1",
      "published_date": "2024-06-19 13:38:34 UTC",
      "updated_date": "2024-06-19 13:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:21:09.670126"
    },
    {
      "arxiv_id": "2406.13542v3",
      "title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guanting Dong",
        "Keming Lu",
        "Chengpeng Li",
        "Tingyu Xia",
        "Bowen Yu",
        "Chang Zhou",
        "Jingren Zhou"
      ],
      "abstract": "One core capability of large language models (LLMs) is to follow natural\nlanguage instructions. However, the issue of automatically constructing\nhigh-quality training data to enhance the complex instruction-following\nabilities of LLMs without manual annotation remains unresolved. In this paper,\nwe introduce AutoIF, the first scalable and reliable method for automatically\ngenerating instruction-following training data. AutoIF transforms the\nvalidation of instruction-following data quality into code verification,\nrequiring LLMs to generate instructions, the corresponding code to check the\ncorrectness of the instruction responses, and unit test samples to verify the\ncode's correctness. Then, execution feedback-based rejection sampling can\ngenerate data for Supervised Fine-Tuning (SFT) and Reinforcement Learning from\nHuman Feedback (RLHF) training. AutoIF achieves significant improvements across\nthree training algorithms, SFT, Offline DPO, and Online DPO, when applied to\nthe top open-source LLMs, Qwen2 and LLaMA3, in self-alignment and\nstrong-to-weak distillation settings. Our code is publicly available at\nhttps://github.com/QwenLM/AutoIF.",
      "tldr_zh": "这篇论文提出了 AutoIF，一种可扩展的自动方法，用于生成高质量的指令跟随训练数据，从而提升大型语言模型(LLMs)的指令执行能力。AutoIF 通过将指令响应验证转化为代码检查过程，包括生成指令、对应代码和单元测试样本，并利用执行反馈的拒绝采样来创建用于 Supervised Fine-Tuning (SFT) 和 Reinforcement Learning from Human Feedback (RLHF) 的训练数据。在 Qwen2 和 LLaMA3 模型上实验表明，AutoIF 在 SFT、Offline DPO 和 Online DPO 训练算法中实现了显著改进，包括自对齐和强到弱蒸馏场景。代码已开源在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.13542v3",
      "published_date": "2024-06-19 13:29:53 UTC",
      "updated_date": "2024-07-18 09:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:21:21.763944"
    },
    {
      "arxiv_id": "2406.13474v2",
      "title": "BoA: Attention-aware Post-training Quantization without Backpropagation",
      "title_zh": "翻译失败",
      "authors": [
        "Junhan Kim",
        "Ho-young Kim",
        "Eulrang Cho",
        "Chungman Lee",
        "Joonyoung Kim",
        "Yongkweon Jeon"
      ],
      "abstract": "Post-training quantization (PTQ) is a promising solution for deploying large\nlanguage models (LLMs) on resource-constrained devices. Early methods developed\nfor smaller networks like ResNet rely on gradient-based optimization, which\nbecomes impractical for hyper-scale LLMs with billions of parameters. While\nrecently proposed backpropagation-free or transformation-based methods\nalleviate this issue, their performance remains limited by either a lack of\ninter-layer dependency consideration or the use of naive nearest-rounding-based\ninteger weight assignment to save the heavy computational cost of weight\noptimization. We thus introduce a novel backpropagation-free PTQ algorithm that\noptimizes integer weights by considering inter-layer dependencies. The key\ninnovation is the development of attention-aware Hessian matrices that capture\ninter-layer interactions within the attention module. Extensive experiments\ndemonstrate that our approach not only outperforms existing weight quantization\nmethods but also shows good synergy with conventional methods to suppress\nactivation outliers, leading to state-of-the-art weight-activation quantization\nperformance.",
      "tldr_zh": "本文提出了一种名为 BoA 的后训练量化 (PTQ) 算法，用于在资源受限设备上部署大型语言模型 (LLMs)，而无需反向传播 (Backpropagation)。该方法通过开发注意力感知 Hessian matrices 来捕捉注意力模块内的层间依赖，从而优化整数权重分配，解决了现有方法的局限性。实验结果显示，BoA 不仅在权重量化性能上优于现有方法，还能与传统激活异常抑制技术结合，实现最先进的权重-激活量化效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2406.13474v2",
      "published_date": "2024-06-19 11:53:21 UTC",
      "updated_date": "2025-02-27 14:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:21:32.475626"
    },
    {
      "arxiv_id": "2406.13469v2",
      "title": "Encoder vs Decoder: Comparative Analysis of Encoder and Decoder Language Models on Multilingual NLU Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Saattrup Nielsen",
        "Kenneth Enevoldsen",
        "Peter Schneider-Kamp"
      ],
      "abstract": "This paper explores the performance of encoder and decoder language models on\nmultilingual Natural Language Understanding (NLU) tasks, with a broad focus on\nGermanic languages. Building upon the ScandEval benchmark, initially restricted\nto evaluating encoder models, we extend the evaluation framework to include\ndecoder models. We introduce a method for evaluating decoder models on NLU\ntasks and apply it to the languages Danish, Swedish, Norwegian, Icelandic,\nFaroese, German, Dutch, and English. Through a series of experiments and\nanalyses, we also address research questions regarding the comparative\nperformance of encoder and decoder models, the impact of NLU task types, and\nthe variation across language resources. Our findings reveal that encoder\nmodels can achieve significantly better NLU performance than decoder models\ndespite having orders of magnitude fewer parameters. Additionally, we\ninvestigate the correlation between decoders and task performance via a UMAP\nanalysis, shedding light on the unique capabilities of decoder and encoder\nmodels. This study contributes to a deeper understanding of language model\nparadigms in NLU tasks and provides valuable insights for model selection and\nevaluation in multilingual settings.",
      "tldr_zh": "这篇论文比较了 encoder 和 decoder 语言模型在多语言 NLU 任务上的性能，焦点放在日耳曼语系语言如丹麦语、瑞典语等。研究者基于 ScandEval 基准扩展了评估框架，引入新方法评估 decoder 模型，并通过实验分析探讨了模型类型、任务种类和语言资源的影响。结果显示，encoder 模型尽管参数数量少得多，却在 NLU 性能上显著优于 decoder 模型；此外，利用 UMAP 分析，他们揭示了模型性能的相关性。该研究为多语言场景下的模型选择和评估提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "NoDaLiDa 2025 camera ready version, including appendices",
      "pdf_url": "http://arxiv.org/pdf/2406.13469v2",
      "published_date": "2024-06-19 11:50:09 UTC",
      "updated_date": "2025-01-11 10:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:21:48.350017"
    },
    {
      "arxiv_id": "2406.13457v1",
      "title": "EvTexture: Event-driven Texture Enhancement for Video Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Dachun Kai",
        "Jiayao Lu",
        "Yueyi Zhang",
        "Xiaoyan Sun"
      ],
      "abstract": "Event-based vision has drawn increasing attention due to its unique\ncharacteristics, such as high temporal resolution and high dynamic range. It\nhas been used in video super-resolution (VSR) recently to enhance the flow\nestimation and temporal alignment. Rather than for motion learning, we propose\nin this paper the first VSR method that utilizes event signals for texture\nenhancement. Our method, called EvTexture, leverages high-frequency details of\nevents to better recover texture regions in VSR. In our EvTexture, a new\ntexture enhancement branch is presented. We further introduce an iterative\ntexture enhancement module to progressively explore the\nhigh-temporal-resolution event information for texture restoration. This allows\nfor gradual refinement of texture regions across multiple iterations, leading\nto more accurate and rich high-resolution details. Experimental results show\nthat our EvTexture achieves state-of-the-art performance on four datasets. For\nthe Vid4 dataset with rich textures, our method can get up to 4.67dB gain\ncompared with recent event-based methods. Code:\nhttps://github.com/DachunKai/EvTexture.",
      "tldr_zh": "这篇论文提出 EvTexture，一种事件驱动的视频超分辨率（Video Super-Resolution, VSR）方法，首次利用事件信号的高频细节来增强纹理恢复，而不是仅限于运动学习。EvTexture 框架包括一个新的 texture enhancement branch 和一个 iterative texture enhancement module，通过逐步迭代探索事件的高时间分辨率信息，实现纹理区域的渐进式精炼和更丰富的 high-resolution details。实验结果显示，该方法在四个数据集上达到 state-of-the-art 性能，尤其在 Vid4 数据集上比最近的事件驱动方法提升高达 4.67 dB。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024. Project page:\n  https://dachunkai.github.io/evtexture.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.13457v1",
      "published_date": "2024-06-19 11:27:44 UTC",
      "updated_date": "2024-06-19 11:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:21:58.601906"
    },
    {
      "arxiv_id": "2406.13450v1",
      "title": "Federating to Grow Transformers with Constrained Resources without Model Sharing",
      "title_zh": "翻译失败",
      "authors": [
        "Shikun Shen",
        "Yifei Zou",
        "Yuan Yuan",
        "Yanwei Zheng",
        "Peng Li",
        "Xiuzhen Cheng",
        "Dongxiao Yu"
      ],
      "abstract": "The high resource consumption of large-scale models discourages\nresource-constrained users from developing their customized transformers. To\nthis end, this paper considers a federated framework named Fed-Grow for\nmultiple participants to cooperatively scale a transformer from their\npre-trained small models. Under the Fed-Grow, a Dual-LiGO (Dual Linear Growth\nOperator) architecture is designed to help participants expand their\npre-trained small models to a transformer. In Dual-LiGO, the Local-LiGO part is\nused to address the heterogeneity problem caused by the various pre-trained\nmodels, and the Global-LiGO part is shared to exchange the implicit knowledge\nfrom the pre-trained models, local data, and training process of participants.\nInstead of model sharing, only sharing the Global-LiGO strengthens the privacy\nof our approach. Compared with several state-of-the-art methods in simulation,\nour approach has higher accuracy, better precision, and lower resource\nconsumption on computations and communications. To the best of our knowledge,\nmost of the previous model-scaling works are centralized, and our work is the\nfirst one that cooperatively grows a transformer from multiple pre-trained\nheterogeneous models with the user privacy protected in terms of local data and\nmodels. We hope that our approach can extend the transformers to the broadly\ndistributed scenarios and encourage more resource-constrained users to enjoy\nthe bonus taken by the large-scale transformers.",
      "tldr_zh": "该论文提出Fed-Grow框架，允许资源受限用户通过联邦学习从预训练小模型合作扩展Transformer模型，而无需共享模型，从而保护用户隐私。框架采用Dual-LiGO架构，其中Local-LiGO处理不同预训练模型的异质性问题，Global-LiGO则用于共享隐性知识，包括预训练数据和训练过程。实验结果显示，Fed-Grow在模拟环境中比现有方法准确率更高、精度更好，且计算和通信资源消耗更低；这也是首个在联邦设置下从多个异质模型合作扩展Transformers的创新方法，有望推广到分布式场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13450v1",
      "published_date": "2024-06-19 11:17:59 UTC",
      "updated_date": "2024-06-19 11:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:22:13.104936"
    },
    {
      "arxiv_id": "2406.13445v1",
      "title": "Lost in UNet: Improving Infrared Small Target Detection by Underappreciated Local Features",
      "title_zh": "翻译失败",
      "authors": [
        "Wuzhou Quan",
        "Wei Zhao",
        "Weiming Wang",
        "Haoran Xie",
        "Fu Lee Wang",
        "Mingqiang Wei"
      ],
      "abstract": "Many targets are often very small in infrared images due to the long-distance\nimaging meachnism. UNet and its variants, as popular detection backbone\nnetworks, downsample the local features early and cause the irreversible loss\nof these local features, leading to both the missed and false detection of\nsmall targets in infrared images. We propose HintU, a novel network to recover\nthe local features lost by various UNet-based methods for effective infrared\nsmall target detection. HintU has two key contributions. First, it introduces\nthe \"Hint\" mechanism for the first time, i.e., leveraging the prior knowledge\nof target locations to highlight critical local features. Second, it improves\nthe mainstream UNet-based architecture to preserve target pixels even after\ndownsampling. HintU can shift the focus of various networks (e.g., vanilla\nUNet, UNet++, UIUNet, MiM+, and HCFNet) from the irrelevant background pixels\nto a more restricted area from the beginning. Experimental results on three\ndatasets NUDT-SIRST, SIRSTv2 and IRSTD1K demonstrate that HintU enhances the\nperformance of existing methods with only an additional 1.88 ms cost (on RTX\nTitan). Additionally, the explicit constraints of HintU enhance the\ngeneralization ability of UNet-based methods. Code is available at\nhttps://github.com/Wuzhou-Quan/HintU.",
      "tldr_zh": "该论文指出，在红外图像中，小目标检测面临局部特征丢失的问题，导致UNet及其变体在早期下采样时出现遗漏和误检。作者提出HintU网络，通过引入\"Hint\"机制利用目标位置的先验知识来突出关键局部特征，并改进UNet-based架构以在下采样后保留目标像素，从而提升检测性能。实验结果显示，HintU在NUDT-SIRST、SIRSTv2和IRSTD1K数据集上，仅增加1.88 ms的计算开销，就显著提高了现有方法的准确率，并增强了其泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13445v1",
      "published_date": "2024-06-19 11:11:38 UTC",
      "updated_date": "2024-06-19 11:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:22:23.848636"
    },
    {
      "arxiv_id": "2406.13441v1",
      "title": "Robust Melanoma Thickness Prediction via Deep Transfer Learning enhanced by XAI Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Nogales",
        "Begoña Acha",
        "Fernando Alarcón",
        "José Pereyra",
        "Carmen Serrano"
      ],
      "abstract": "This study focuses on analyzing dermoscopy images to determine the depth of\nmelanomas, which is a critical factor in diagnosing and treating skin cancer.\nThe Breslow depth, measured from the top of the granular layer to the deepest\npoint of tumor invasion, serves as a crucial parameter for staging melanoma and\nguiding treatment decisions. This research aims to improve the prediction of\nthe depth of melanoma through the use of machine learning models, specifically\ndeep learning, while also providing an analysis of the possible existance of\ngraduation in the images characteristics which correlates with the depth of the\nmelanomas. Various datasets, including ISIC and private collections, were used,\ncomprising a total of 1162 images. The datasets were combined and balanced to\nensure robust model training. The study utilized pre-trained Convolutional\nNeural Networks (CNNs). Results indicated that the models achieved significant\nimprovements over previous methods. Additionally, the study conducted a\ncorrelation analysis between model's predictions and actual melanoma thickness,\nrevealing a moderate correlation that improves with higher thickness values.\nExplainability methods such as feature visualization through Principal\nComponent Analysis (PCA) demonstrated the capability of deep features to\ndistinguish between different depths of melanoma, providing insight into the\ndata distribution and model behavior. In summary, this research presents a dual\ncontribution: enhancing the state-of-the-art classification results through\nadvanced training techniques and offering a detailed analysis of the data and\nmodel behavior to better understand the relationship between dermoscopy images\nand melanoma thickness.",
      "tldr_zh": "本研究针对皮肤镜图像分析，旨在通过深度转移学习增强的卷积神经网络 (CNNs) 模型，提高黑色素瘤 Breslow 深度的预测准确性，同时利用可解释性 AI (XAI) 技术如主成分分析 (PCA) 分析图像特征与深度的相关性。研究使用 ISIC 和私人数据集共 1162 张图像进行组合和平衡训练，结果显示模型性能显著优于现有方法，并发现预测与实际厚度的中等相关性，尤其在较高厚度值时更强。通过 PCA 等方法，研究揭示了深度特征在区分不同黑色素瘤深度方面的能力，为理解图像与肿瘤侵袭关系的临床应用提供了重要洞见。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13441v1",
      "published_date": "2024-06-19 11:07:55 UTC",
      "updated_date": "2024-06-19 11:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:22:37.236988"
    },
    {
      "arxiv_id": "2406.13436v1",
      "title": "What's Next? Exploring Utilization, Challenges, and Future Directions of AI-Generated Image Tools in Graphic Design",
      "title_zh": "翻译失败",
      "authors": [
        "Yuying Tang",
        "Mariana Ciancia",
        "Zhigang Wang",
        "Ze Gao"
      ],
      "abstract": "Recent advancements in artificial intelligence, such as computer vision and\ndeep learning, have led to the emergence of numerous generative AI platforms,\nparticularly for image generation. However, the application of AI-generated\nimage tools in graphic design has not been extensively explored. This study\nconducted semi-structured interviews with seven designers of varying experience\nlevels to understand their current usage, challenges, and future functional\nneeds for AI-generated image tools in graphic design. As our findings suggest,\nAI tools serve as creative partners in design, enhancing human creativity,\noffering strategic insights, and fostering team collaboration and\ncommunication. The findings provide guiding recommendations for the future\ndevelopment of AI-generated image tools, aimed at helping engineers optimize\nthese tools to better meet the needs of graphic designers.",
      "tldr_zh": "本研究通过对七名图形设计师进行半结构化访谈（semi-structured interviews），探讨了AI-generated image tools在图形设计中的当前使用情况、面临的挑战以及未来需求。研究发现，这些AI工具可作为创意伙伴，提升人类创意、提供战略洞见，并促进团队合作与沟通。最终，论文基于这些发现，给出了针对AI-generated image tools的开发推荐，帮助工程师优化工具以更好地满足图形设计师的需求。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13436v1",
      "published_date": "2024-06-19 10:51:56 UTC",
      "updated_date": "2024-06-19 10:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:22:47.611917"
    },
    {
      "arxiv_id": "2406.13433v2",
      "title": "Certification for Differentially Private Prediction in Gradient-Based Training",
      "title_zh": "梯度训练中差分隐私预测的认证",
      "authors": [
        "Matthew Wicker",
        "Philip Sosnin",
        "Igor Shilov",
        "Adrianna Janik",
        "Mark N. Müller",
        "Yves-Alexandre de Montjoye",
        "Adrian Weller",
        "Calvin Tsay"
      ],
      "abstract": "Differential privacy upper-bounds the information leakage of machine learning\nmodels, yet providing meaningful privacy guarantees has proven to be\nchallenging in practice. The private prediction setting where model outputs are\nprivatized is being investigated as an alternate way to provide formal\nguarantees at prediction time. Most current private prediction algorithms,\nhowever, rely on global sensitivity for noise calibration, which often results\nin large amounts of noise being added to the predictions. Data-specific noise\ncalibration, such as smooth sensitivity, could significantly reduce the amount\nof noise added, but were so far infeasible to compute exactly for modern\nmachine learning models. In this work we provide a novel and practical approach\nbased on convex relaxation and bound propagation to compute a provable\nupper-bound for the local and smooth sensitivity of a prediction. This bound\nallows us to reduce the magnitude of noise added or improve privacy accounting\nin the private prediction setting. We validate our framework on datasets from\nfinancial services, medical image classification, and natural language\nprocessing and across models and find our approach to reduce the noise added by\nup to order of magnitude.",
      "tldr_zh": "这篇论文针对差分隐私（Differential Privacy）在梯度训练中的私有预测问题，提出了一种新方法来计算预测的局部和平滑敏感度（smooth sensitivity）的可证明上界，以减少添加的噪声量或改善隐私会计。方法基于凸松弛（convex relaxation）和边界传播（bound propagation），克服了之前计算平滑敏感度的高难度挑战。实验在金融服务、医疗图像分类和自然语言处理数据集上验证，结果显示噪声减少可达一个数量级，从而提升了私有预测的有效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13433v2",
      "published_date": "2024-06-19 10:47:00 UTC",
      "updated_date": "2024-10-30 16:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:00.270814"
    },
    {
      "arxiv_id": "2406.13414v1",
      "title": "Archive-based Single-Objective Evolutionary Algorithms for Submodular Optimization",
      "title_zh": "基于存档的单目标进化算法用于子模优化",
      "authors": [
        "Frank Neumann",
        "Günter Rudolph"
      ],
      "abstract": "Constrained submodular optimization problems play a key role in the area of\ncombinatorial optimization as they capture many NP-hard optimization problems.\nSo far, Pareto optimization approaches using multi-objective formulations have\nbeen shown to be successful to tackle these problems while single-objective\nformulations lead to difficulties for algorithms such as the $(1+1)$-EA due to\nthe presence of local optima. We introduce for the first time single-objective\nalgorithms that are provably successful for different classes of constrained\nsubmodular maximization problems. Our algorithms are variants of the\n$(1+\\lambda)$-EA and $(1+1)$-EA and increase the feasible region of the search\nspace incrementally in order to deal with the considered submodular problems.",
      "tldr_zh": "本文提出了一种基于存档的单目标进化算法，用于解决约束子模优化（Constrained submodular optimization）问题，这些问题是NP-hard组合优化中的关键挑战。过去，多目标方法如Pareto优化已成功应用，但单目标算法如(1+1)-EA 常因局部最优而失败。作者首次引入(1+λ)-EA和(1+1)-EA的变体，这些算法通过逐步增量扩展可行区域，实现对不同类别的约束子模最大化问题的有效优化。该方法为单目标框架在子模优化领域的应用提供了可靠的理论保证和实际潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear at PPSN 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13414v1",
      "published_date": "2024-06-19 10:08:12 UTC",
      "updated_date": "2024-06-19 10:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:22.819124"
    },
    {
      "arxiv_id": "2406.13399v1",
      "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Yao",
        "Zhiqing Tang",
        "Jiong Lou",
        "Ping Shen",
        "Weijia Jia"
      ],
      "abstract": "The Large Language Model (LLM) has gained significant popularity and is\nextensively utilized across various domains. Most LLM deployments occur within\ncloud data centers, where they encounter substantial response delays and incur\nhigh costs, thereby impacting the Quality of Services (QoS) at the network\nedge. Leveraging vector database caching to store LLM request results at the\nedge can substantially mitigate response delays and cost associated with\nsimilar requests, which has been overlooked by previous research. Addressing\nthese gaps, this paper introduces a novel Vector database-assisted cloud-Edge\ncollaborative LLM QoS Optimization (VELO) framework. Firstly, we propose the\nVELO framework, which ingeniously employs vector database to cache the results\nof some LLM requests at the edge to reduce the response time of subsequent\nsimilar requests. Diverging from direct optimization of the LLM, our VELO\nframework does not necessitate altering the internal structure of LLM and is\nbroadly applicable to diverse LLMs. Subsequently, building upon the VELO\nframework, we formulate the QoS optimization problem as a Markov Decision\nProcess (MDP) and devise an algorithm grounded in Multi-Agent Reinforcement\nLearning (MARL) to decide whether to request the LLM in the cloud or directly\nreturn the results from the vector database at the edge. Moreover, to enhance\nrequest feature extraction and expedite training, we refine the policy network\nof MARL and integrate expert demonstrations. Finally, we implement the proposed\nalgorithm within a real edge system. Experimental findings confirm that our\nVELO framework substantially enhances user satisfaction by concurrently\ndiminishing delay and resource consumption for edge users utilizing LLMs.",
      "tldr_zh": "这篇论文针对大型语言模型（Large Language Models, LLMs）在云数据中心部署时面临的响应延迟和高成本问题，提出了VELO框架，该框架利用向量数据库（vector database）在边缘缓存LLM请求结果，从而优化网络边缘的QoS。框架将QoS优化问题建模为Markov Decision Process (MDP)，并采用Multi-Agent Reinforcement Learning (MARL)算法来决定是请求云端LLM还是直接从边缘数据库返回结果，同时通过改进策略网络和整合专家演示（expert demonstrations）来提升训练效率。实验结果显示，VELO框架在真实边缘系统中显著降低了延迟和资源消耗，提高了用户满意度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "to be published in IEEE ICWS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13399v1",
      "published_date": "2024-06-19 09:41:37 UTC",
      "updated_date": "2024-06-19 09:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:24.443406"
    },
    {
      "arxiv_id": "2406.13385v1",
      "title": "Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Lebourdais",
        "Théo Mariotte",
        "Antonio Almudévar",
        "Marie Tahon",
        "Alfonso Ortega"
      ],
      "abstract": "Audio segmentation is a key task for many speech technologies, most of which\nare based on neural networks, usually considered as black boxes, with\nhigh-level performances. However, in many domains, among which health or\nforensics, there is not only a need for good performance but also for\nexplanations about the output decision. Explanations derived directly from\nlatent representations need to satisfy \"good\" properties, such as\ninformativeness, compactness, or modularity, to be interpretable. In this\narticle, we propose an explainable-by-design audio segmentation model based on\nnon-negative matrix factorization (NMF) which is a good candidate for the\ndesign of interpretable representations. This paper shows that our model\nreaches good segmentation performances, and presents deep analyses of the\nlatent representation extracted from the non-negative matrix. The proposed\napproach opens new perspectives toward the evaluation of interpretable\nrepresentations according to \"good\" properties.",
      "tldr_zh": "该论文提出了一种基于 Non-Negative Matrix Factorization (NMF) 的音频分割模型，该设计天生可解释（explainable by-design），旨在解决神经网络黑箱问题，尤其在健康和法医等领域对决策解释的需求。模型通过 NMF 提取潜在表示，并利用 probing 技术确保这些表示具有信息性、紧凑性和模块性等良好属性。实验结果显示，该模型在音频分割性能上表现出色，并对提取的潜在表示进行了深入分析，为评估可解释表示的属性提供了新视角。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at Interspeech 2024, 5 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13385v1",
      "published_date": "2024-06-19 09:26:33 UTC",
      "updated_date": "2024-06-19 09:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:35.728596"
    },
    {
      "arxiv_id": "2406.13372v2",
      "title": "Thread: A Logic-Based Data Organization Paradigm for How-To Question Answering with Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaikai An",
        "Fangkai Yang",
        "Liqun Li",
        "Junting Lu",
        "Sitao Cheng",
        "Shuzheng Si",
        "Lu Wang",
        "Pu Zhao",
        "Lele Cao",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang",
        "Baobao Chang"
      ],
      "abstract": "Recent advances in retrieval-augmented generation have significantly improved\nthe performance of question-answering systems, particularly on factoid '5Ws'\nquestions. However, these systems still face substantial challenges when\naddressing '1H' questions, specifically how-to questions, which are integral to\ndecision-making processes and require dynamic, step-by-step answers. The key\nlimitation lies in the prevalent data organization paradigm, chunk, which\ndivides documents into fixed-size segments, and disrupts the logical coherence\nand connections within the context. To overcome this, in this paper, we propose\nThread, a novel data organization paradigm aimed at enabling current systems to\nhandle how-to questions more effectively. Specifically, we introduce a new\nknowledge granularity, termed 'logic unit', where documents are transformed\ninto more structured and loosely interconnected logic units with large language\nmodels. Extensive experiments conducted across both open-domain and industrial\nsettings demonstrate that Thread outperforms existing paradigms significantly,\nimproving the success rate of handling how-to questions by 21% to 33%.\nMoreover, Thread exhibits high adaptability in processing various document\nformats, drastically reducing the candidate quantity in the knowledge base and\nminimizing the required information to one-fourth compared with chunk,\noptimizing both efficiency and effectiveness.",
      "tldr_zh": "本文提出Thread，一种基于逻辑的数据组织范式，旨在解决检索增强生成（RAG）系统在处理“如何”问题（how-to questions）时的挑战，这些问题需要动态的逐步答案，而传统文档分块（chunk）方法会破坏上下文的逻辑连贯性。Thread 通过将文档转化为结构化的逻辑单位（logic unit）并利用大语言模型进行优化，使系统能够更有效地组织和检索知识。实验结果显示，Thread 在开放域和工业环境中将“如何”问题的成功率提高了21%至33%，并将所需知识量减少到原先的四分之一，从而显著提升了效率和效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.13372v2",
      "published_date": "2024-06-19 09:14:41 UTC",
      "updated_date": "2024-10-10 08:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:48.809965"
    },
    {
      "arxiv_id": "2406.13371v1",
      "title": "Identifiable Causal Representation Learning: Unsupervised, Multi-View, and Multi-Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Julius von Kügelgen"
      ],
      "abstract": "Causal models provide rich descriptions of complex systems as sets of\nmechanisms by which each variable is influenced by its direct causes. They\nsupport reasoning about manipulating parts of the system and thus hold promise\nfor addressing some of the open challenges of artificial intelligence (AI),\nsuch as planning, transferring knowledge in changing environments, or\nrobustness to distribution shifts. However, a key obstacle to more widespread\nuse of causal models in AI is the requirement that the relevant variables be\nspecified a priori, which is typically not the case for the high-dimensional,\nunstructured data processed by modern AI systems. At the same time, machine\nlearning (ML) has proven quite successful at automatically extracting useful\nand compact representations of such complex data. Causal representation\nlearning (CRL) aims to combine the core strengths of ML and causality by\nlearning representations in the form of latent variables endowed with causal\nmodel semantics.\n  In this thesis, we study and present new results for different CRL settings.\nA central theme is the question of identifiability: Given infinite data, when\nare representations satisfying the same learning objective guaranteed to be\nequivalent? This is an important prerequisite for CRL, as it formally\ncharacterises if and when a learning task is, at least in principle, feasible.\nSince learning causal models, even without a representation learning component,\nis notoriously difficult, we require additional assumptions on the model class\nor rich data beyond the classical i.i.d. setting. By partially characterising\nidentifiability for different settings, this thesis investigates what is\npossible for CRL without direct supervision, and thus contributes to its\ntheoretical foundations. Ideally, the developed insights can help inform data\ncollection practices or inspire the design of new practical estimation methods.",
      "tldr_zh": "本论文探讨了可识别因果表示学习（Causal Representation Learning, CRL），旨在通过无监督方法从高维数据中学习带有因果模型语义的潜在变量，以解决人工智能中变量预定义的难题。论文重点研究了不同CRL设置的可识别性（identifiability），即在无限数据条件下，满足相同学习目标的表示是否等价，并通过额外假设（如模型类假设或超出i.i.d.数据的丰富信息）部分表征了多视图和多环境场景下的可识别性。总体而言，该研究为CRL的理论基础提供了新见解，有助于指导数据收集实践和开发实际估计方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD Thesis; 190 pages, 33 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13371v1",
      "published_date": "2024-06-19 09:14:40 UTC",
      "updated_date": "2024-06-19 09:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:23:59.850305"
    },
    {
      "arxiv_id": "2406.13365v1",
      "title": "PPT-GNN: A Practical Pre-Trained Spatio-Temporal Graph Neural Network for Network Security",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Van Langendonck",
        "Ismael Castell-Uroz",
        "Pere Barlet-Ros"
      ],
      "abstract": "Recent works have demonstrated the potential of Graph Neural Networks (GNN)\nfor network intrusion detection. Despite their advantages, a significant gap\npersists between real-world scenarios, where detection speed is critical, and\nexisting proposals, which operate on large graphs representing several hours of\ntraffic. This gap results in unrealistic operational conditions and impractical\ndetection delays. Moreover, existing models do not generalize well across\ndifferent networks, hampering their deployment in production environments. To\naddress these issues, we introduce PPTGNN, a practical spatio-temporal GNN for\nintrusion detection. PPTGNN enables near real-time predictions, while better\ncapturing the spatio-temporal dynamics of network attacks. PPTGNN employs\nself-supervised pre-training for improved performance and reduced dependency on\nlabeled data. We evaluate PPTGNN on three public datasets and show that it\nsignificantly outperforms state-of-the-art models, such as E-ResGAT and\nE-GraphSAGE, with an average accuracy improvement of 10.38%. Finally, we show\nthat a pre-trained PPTGNN can easily be fine-tuned to unseen networks with\nminimal labeled examples. This highlights the potential of PPTGNN as a general,\nlarge-scale pre-trained model that can effectively operate in diverse network\nenvironments.",
      "tldr_zh": "本研究针对图神经网络(GNN)在网络入侵检测中的问题，如检测延迟和模型泛化性差，提出了一种实用的预训练时空图神经网络PPT-GNN。PPT-GNN通过捕捉网络攻击的时空动态并采用self-supervised pre-training方法，实现近实时预测并减少对标注数据的依赖。在三个公共数据集上的实验显示，PPT-GNN比现有模型如E-ResGAT和E-GraphSAGE平均准确率提高10.38%。此外，该模型可轻松通过微调适应新网络，仅需少量标注数据，从而提升其在多样化网络环境中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper currently under review. Code will be made public upon\n  acceptance. 8 pages long, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13365v1",
      "published_date": "2024-06-19 09:09:46 UTC",
      "updated_date": "2024-06-19 09:09:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:24:12.741048"
    },
    {
      "arxiv_id": "2406.13351v1",
      "title": "A Resource-Adaptive Approach for Federated Learning under Resource-Constrained Environments",
      "title_zh": "资源受限环境下的联邦学习资源自适应方法",
      "authors": [
        "Ruirui Zhang",
        "Xingze Wu",
        "Yifei Zou",
        "Zhenzhen Xie",
        "Peng Li",
        "Xiuzhen Cheng",
        "Dongxiao Yu"
      ],
      "abstract": "The paper studies a fundamental federated learning (FL) problem involving\nmultiple clients with heterogeneous constrained resources. Compared with the\nnumerous training parameters, the computing and communication resources of\nclients are insufficient for fast local training and real-time knowledge\nsharing. Besides, training on clients with heterogeneous resources may result\nin the straggler problem. To address these issues, we propose Fed-RAA: a\nResource-Adaptive Asynchronous Federated learning algorithm. Different from\nvanilla FL methods, where all parameters are trained by each participating\nclient regardless of resource diversity, Fed-RAA adaptively allocates fragments\nof the global model to clients based on their computing and communication\ncapabilities. Each client then individually trains its assigned model fragment\nand asynchronously uploads the updated result. Theoretical analysis confirms\nthe convergence of our approach. Additionally, we design an online greedy-based\nalgorithm for fragment allocation in Fed-RAA, achieving fairness comparable to\nan offline strategy. We present numerical results on MNIST, CIFAR-10, and\nCIFAR-100, along with necessary comparisons and ablation studies, demonstrating\nthe advantages of our work. To the best of our knowledge, this paper represents\nthe first resource-adaptive asynchronous method for fragment-based FL with\nguaranteed theoretical convergence.",
      "tldr_zh": "这篇论文针对联邦学习(FL)中客户端资源异构问题，提出了一种资源自适应异步算法Fed-RAA，以解决计算和通信资源不足以及straggler problem。Fed-RAA根据客户端的计算和通信能力，自适应分配全局模型片段，让每个客户端独立训练并异步上传更新，同时设计了一个在线贪婪算法确保公平性。理论分析证明了算法的收敛性，实验结果在MNIST、CIFAR-10和CIFAR-100数据集上显示了其相对于基线方法的显著优势，并声称这是首个具有理论保证的基于片段的资源自适应异步FL方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13351v1",
      "published_date": "2024-06-19 08:55:40 UTC",
      "updated_date": "2024-06-19 08:55:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:24:26.718010"
    },
    {
      "arxiv_id": "2406.13348v2",
      "title": "Textual Unlearning Gives a False Sense of Unlearning",
      "title_zh": "文本取消学习给人一种虚假的取消学习感",
      "authors": [
        "Jiacheng Du",
        "Zhibo Wang",
        "Jie Zhang",
        "Xiaoyi Pang",
        "Jiahui Hu",
        "Kui Ren"
      ],
      "abstract": "Language Models (LMs) are prone to ''memorizing'' training data, including\nsubstantial sensitive user information. To mitigate privacy risks and safeguard\nthe right to be forgotten, machine unlearning has emerged as a promising\napproach for enabling LMs to efficiently ''forget'' specific texts. However,\ndespite the good intentions, is textual unlearning really as effective and\nreliable as expected? To address the concern, we first propose Unlearning\nLikelihood Ratio Attack+ (U-LiRA+), a rigorous textual unlearning auditing\nmethod, and find that unlearned texts can still be detected with very high\nconfidence after unlearning. Further, we conduct an in-depth investigation on\nthe privacy risks of textual unlearning mechanisms in deployment and present\nthe Textual Unlearning Leakage Attack (TULA), along with its variants in both\nblack- and white-box scenarios. We show that textual unlearning mechanisms\ncould instead reveal more about the unlearned texts, exposing them to\nsignificant membership inference and data reconstruction risks. Our findings\nhighlight that existing textual unlearning actually gives a false sense of\nunlearning, underscoring the need for more robust and secure unlearning\nmechanisms.",
      "tldr_zh": "该研究揭示了语言模型 (LMs) 在处理敏感训练数据时，机器 unlearning 方法虽旨在让模型“忘记”特定文本，但实际上效果有限。作者提出 Unlearning Likelihood Ratio Attack+ (U-LiRA+) 作为审计工具，发现 unlearned 文本仍能以高置信度被检测出来。此外，他们开发了 Textual Unlearning Leakage Attack (TULA) 和其黑白盒变体，证明这些 unlearning 机制可能反而增加成员推理 (membership inference) 和数据重建风险。总体而言，该工作强调现有 textual unlearning 仅提供虚假的安全感，呼吁开发更可靠的机制。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13348v2",
      "published_date": "2024-06-19 08:51:54 UTC",
      "updated_date": "2025-02-18 12:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:24:36.933868"
    },
    {
      "arxiv_id": "2406.13342v1",
      "title": "ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hwiyeol Jo",
        "Hyunwoo Lee",
        "Taiwoo Park"
      ],
      "abstract": "The recent advancements in large language models (LLMs) have brought\nsignificant progress in solving NLP tasks. Notably, in-context learning (ICL)\nis the key enabling mechanism for LLMs to understand specific tasks and\ngrasping nuances. In this paper, we propose a simple yet effective method to\ncontextualize a task toward a specific LLM, by (1) observing how a given LLM\ndescribes (all or a part of) target datasets, i.e., open-ended zero-shot\ninference, and (2) aggregating the open-ended inference results by the LLM, and\n(3) finally incorporate the aggregated meta-information for the actual task. We\nshow the effectiveness of this approach in text clustering tasks, and also\nhighlight the importance of the contextualization through examples of the above\nprocedure.",
      "tldr_zh": "该论文提出ZeroDL，一种基于Large Language Models (LLMs)的零-shot分布学习方法，用于文本聚类任务。通过in-context learning机制，该方法首先让LLMs进行open-ended zero-shot inference来描述目标数据集，然后聚合这些推理结果，并将聚合后的元信息整合到实际任务中。该方法简化了任务 contextualization，提升了LLMs在文本聚类中的性能，并通过示例证明了这种聚合策略的重要性。实验结果显示，ZeroDL有效提高了任务理解和聚类准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ARR Submitted",
      "pdf_url": "http://arxiv.org/pdf/2406.13342v1",
      "published_date": "2024-06-19 08:48:05 UTC",
      "updated_date": "2024-06-19 08:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:24:47.917939"
    },
    {
      "arxiv_id": "2406.13308v1",
      "title": "Deep Learning-Based 3D Instance and Semantic Segmentation: A Review",
      "title_zh": "基于深度学习的 3D 实例分割和语义分割：综述",
      "authors": [
        "Siddiqui Muhammad Yasir",
        "Hyunsik Ahn"
      ],
      "abstract": "The process of segmenting point cloud data into several homogeneous areas\nwith points in the same region having the same attributes is known as 3D\nsegmentation. Segmentation is challenging with point cloud data due to\nsubstantial redundancy, fluctuating sample density and lack of apparent\norganization. The research area has a wide range of robotics applications,\nincluding intelligent vehicles, autonomous mapping and navigation. A number of\nresearchers have introduced various methodologies and algorithms. Deep learning\nhas been successfully used to a spectrum of 2D vision domains as a prevailing\nA.I. methods. However, due to the specific problems of processing point clouds\nwith deep neural networks, deep learning on point clouds is still in its\ninitial stages. This study examines many strategies that have been presented to\n3D instance and semantic segmentation and gives a complete assessment of\ncurrent developments in deep learning-based 3D segmentation. In these\napproaches benefits, draw backs, and design mechanisms are studied and\naddressed. This study evaluates the impact of various segmentation algorithms\non competitiveness on various publicly accessible datasets, as well as the most\noften used pipelines, their advantages and limits, insightful findings and\nintriguing future research directions.",
      "tldr_zh": "这篇论文回顾了基于深度学习的3D实例和语义分割技术，针对点云数据的挑战，如数据冗余、采样密度变化和缺乏结构，探讨了其在机器人应用（如智能车辆和自主导航）中的潜力。论文评估了多种深度学习策略的优点、缺点和设计机制，并比较了这些方法在公开数据集上的竞争表现。最终，它总结了关键见解并指出了未来研究方向，例如改进点云处理算法以提升准确性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13308v1",
      "published_date": "2024-06-19 07:56:14 UTC",
      "updated_date": "2024-06-19 07:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:25:01.386723"
    },
    {
      "arxiv_id": "2406.13305v2",
      "title": "Multimodal MRI Accurately Identifies Amyloid Status in Unbalanced Cohorts in Alzheimer's Disease Continuum",
      "title_zh": "多模态 MRI 准确识别阿尔茨海默病连续体中不平衡队列的淀粉样蛋白状态",
      "authors": [
        "Giorgio Dolci",
        "Charles A. Ellis",
        "Federica Cruciani",
        "Lorenza Brusini",
        "Anees Abrol",
        "Ilaria Boscolo Galazzo",
        "Gloria Menegaz",
        "Vince D. Calhoun"
      ],
      "abstract": "Amyloid-$\\beta$ (A$\\beta$) plaques in conjunction with hyperphosphorylated\ntau proteins in the form of neurofibrillary tangles are the two\nneuropathological hallmarks of Alzheimer's disease. It is well-known that the\nidentification of individuals with A$\\beta$ positivity could enable early\ndiagnosis. In this work, we aim at capturing the A$\\beta$ positivity status in\nan unbalanced cohort enclosing subjects at different disease stages, exploiting\nthe underlying structural and connectivity disease-induced modulations as\nrevealed by structural, functional, and diffusion MRI. Of note, due to the\nunbalanced cohort, the outcomes may be guided by those factors rather than\namyloid accumulation. The partial views provided by each modality are\nintegrated in the model allowing to take full advantage of their\ncomplementarity in encoding the effects of the A$\\beta$ accumulation, leading\nto an accuracy of $0.762\\pm0.04$. The specificity of the information brought by\neach modality is assessed by \\textit{post-hoc} explainability analysis (guided\nbackpropagation), highlighting the underlying structural and functional\nchanges. Noteworthy, well-established biomarker key regions related to A$\\beta$\ndeposition could be identified by all modalities, including the hippocampus,\nthalamus, precuneus, and cingulate gyrus, witnessing in favor of the\nreliability of the method as well as its potential in shading light on\nmodality-specific possibly unknown A$\\beta$ deposition signatures.",
      "tldr_zh": "本研究利用多模态MRI（包括结构、功能和扩散MRI）整合方法，在不平衡的阿尔茨海默病队列中准确识别Aβ阳性状态，旨在捕捉疾病诱导的结构和连接性变化。模型通过融合各模态的互补信息，实现了0.762 ± 0.04的准确率，避免了队列不平衡对结果的潜在偏导。解释性分析（guided backpropagation）进一步确认了模态特异性信息，识别出与Aβ积累相关的关键脑区，如hippocampus、thalamus、precuneus和cingulate gyrus，这为早期诊断和理解Aβ沉积机制提供了可靠工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 3 figures, provisionally accepted to a journal",
      "pdf_url": "http://arxiv.org/pdf/2406.13305v2",
      "published_date": "2024-06-19 07:51:21 UTC",
      "updated_date": "2024-10-14 17:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:25:13.598910"
    },
    {
      "arxiv_id": "2406.13303v1",
      "title": "Integration of Policy and Reputation based Trust Mechanisms in e-Commerce Industry",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Yasir Siddiqui",
        "Alam Gir"
      ],
      "abstract": "The e-commerce systems are being tackled from commerce behavior and internet\ntechnologies. Therefore, trust aspect between buyer-seller transactions is a\npotential element which needs to be addressed in competitive e-commerce\nindustry. The e-commerce industry is currently handling two different trust\napproaches. First approach consists on centralized mechanism where digital\ncredentials/set of rules assembled, called Policy based trust mechanisms .\nSecond approach consists on decentralized trust mechanisms where reputation,\npoints assembled and shared, called Reputation based trust mechanisms. The\ndifference between reputation and policy based trust mechanism will be analyzed\nand recommendations would be proposed to increase trust between buyer and\nseller in e-commerce industry. The integration of trust mechanism is proposed\nthrough mapping process, strength of one mechanism with the weakness of other.\nThe proposed model for integrated mechanism will be presented and illustrated\nhow the proposed model will be used in real world e-commerce industry.",
      "tldr_zh": "这篇论文探讨了 e-commerce 行业中基于 Policy based trust mechanisms 和 Reputation based trust mechanisms 的信任机制差异，并提出整合方案以提升买家和卖家之间的信任。Policy based trust mechanisms 是集中式的数字凭证规则系统，而 Reputation based trust mechanisms 则是去中心化的声誉点共享机制。论文通过映射过程，将一个机制的强项（如集中式安全性）弥补另一个的弱点（如灵活性不足），并呈现了一个整合模型，展示了其在真实世界 e-commerce 行业的实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.MM",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13303v1",
      "published_date": "2024-06-19 07:47:48 UTC",
      "updated_date": "2024-06-19 07:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:25:25.743190"
    },
    {
      "arxiv_id": "2406.13299v1",
      "title": "Empirical Evaluation of Integrated Trust Mechanism to Improve Trust in E-commerce Services",
      "title_zh": "集成信任机制的实证评估以改善电子商务服务中的信任",
      "authors": [
        "Siddiqui Muhammad Yasir",
        "Hyunsik Ahn"
      ],
      "abstract": "There are mostly two approaches to tackle trust management worldwide Strong\nand crisp and Soft and Social. We analyze the impact of integrated trust\nmechanism in three different e-commerce services. The trust aspect is a dormant\nelement between potential users and being developed expert or internet systems.\nWe support our integration by preside over an experiment in controlled\nlaboratory environment. The model selected for the experiment is a composite of\npolicy and reputation based trust mechanisms and widely acknowledged in\ne-commerce industry. The integration between policy and trust mechanism was\naccomplished through mapping process, weakness of one brought to a close with\nthe strength of other. Furthermore, experiment has been supervised to validate\nthe effectiveness of implementation by segregating both integrated and\ntraditional trust mechanisms in learning system",
      "tldr_zh": "这篇论文评估了一种整合信任机制，以提升电子商务服务（e-commerce services）中的用户信任。研究分析了两种信任管理方法（Strong and crisp 以及 Soft and Social），并通过实验在三种电子商务服务中测试了整合机制的效果。该机制结合了基于政策和声誉的信任方法（policy and reputation based trust mechanisms），通过映射过程弥补了各自的弱点。实验结果显示，整合机制在受控实验室环境中显著优于传统机制，提高了信任水平，为电子商务信任管理提供了实证支持。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.PF"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13299v1",
      "published_date": "2024-06-19 07:38:51 UTC",
      "updated_date": "2024-06-19 07:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:25:36.652247"
    },
    {
      "arxiv_id": "2406.13295v1",
      "title": "Media Forensics and Deepfake Systematic Survey",
      "title_zh": "媒体取证与 Deepfake 系统性调查",
      "authors": [
        "Nadeem Jabbar CH",
        "Aqib Saghir",
        "Ayaz Ahmad Meer",
        "Salman Ahmad Sahi",
        "Bilal Hassan",
        "Siddiqui Muhammad Yasir"
      ],
      "abstract": "Deepfake is a generative deep learning algorithm that creates or changes\nfacial features in a very realistic way making it hard to differentiate the\nreal from the fake features It can be used to make movies look better as well\nas to spread false information by imitating famous people In this paper many\ndifferent ways to make a Deepfake are explained analyzed and separated\ncategorically Using Deepfake datasets models are trained and tested for\nreliability through experiments Deepfakes are a type of facial manipulation\nthat allow people to change their entire faces identities attributes and\nexpressions The trends in the available Deepfake datasets are also discussed\nwith a focus on how they have changed Using Deep learning a general Deepfake\ndetection model is made Moreover the problems in making and detecting Deepfakes\nare also mentioned As a result of this survey it is expected that the\ndevelopment of new Deepfake based imaging tools will speed up in the future\nThis survey gives indepth review of methods for manipulating images of face and\nvarious techniques to spot altered face images Four types of facial\nmanipulation are specifically discussed which are attribute manipulation\nexpression swap entire face synthesis and identity swap Across every\nmanipulation category we yield information on manipulation techniques\nsignificant benchmarks for technical evaluation of counterfeit detection\ntechniques available public databases and a summary of the outcomes of all such\nanalyses From all of the topics in the survey we focus on the most recent\ndevelopment of Deepfake showing its advances and obstacles in detecting fake\nimages",
      "tldr_zh": "这篇论文对 Deepfake 进行了系统调查，分析了其作为生成式深度学习算法的生成方式，包括属性 manipulation、expression swap、entire face synthesis 和 identity swap 等面部操纵类型。论文分类讨论了 Deepfake 的创建方法、可用数据集趋势，以及通过深度学习训练检测模型的实验结果，以评估其可靠性。最终，调查强调了 Deepfake 检测面临的挑战，并预测未来基于 Deepfake 的图像工具将加速发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "46 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.13295v1",
      "published_date": "2024-06-19 07:33:33 UTC",
      "updated_date": "2024-06-19 07:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:25:49.024825"
    },
    {
      "arxiv_id": "2406.13292v3",
      "title": "An interpretable generative multimodal neuroimaging-genomics framework for decoding Alzheimer's disease",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Dolci",
        "Federica Cruciani",
        "Md Abdur Rahaman",
        "Anees Abrol",
        "Jiayu Chen",
        "Zening Fu",
        "Ilaria Boscolo Galazzo",
        "Gloria Menegaz",
        "Vince D. Calhoun"
      ],
      "abstract": "\\textbf{Objective:} Alzheimer's disease (AD) is the most prevalent form of\ndementia worldwide, encompassing a prodromal stage known as Mild Cognitive\nImpairment (MCI), where patients may either progress to AD or remain stable.\nThe objective of the work was to capture structural and functional modulations\nof brain structure and function relying on multimodal MRI data and Single\nNucleotide Polymorphisms, also in case of missing views, with the twofold goal\nof classifying AD patients versus healthy controls and detecting MCI\nconverters. % in two distinct tasks, dealing with also missing data.\\\\\n\\textbf{Approach:} We propose a multimodal DL-based classification framework\nwhere a generative module employing Cycle Generative Adversarial Networks was\nintroduced in the latent space for imputing missing data (a common issue of\nmultimodal approaches). Explainable AI method was then used to extract input\nfeatures' relevance allowing for post-hoc validation and enhancing the\ninterpretability of the learned representations. \\textbf{Main results:}\nExperimental results on two tasks, AD detection and MCI conversion, showed that\nour framework reached competitive performance in the state-of-the-art with an\naccuracy of $0.926\\pm0.02$ and $0.711\\pm0.01$ in the two tasks, respectively.\nThe interpretability analysis revealed gray matter modulations in cortical and\nsubcortical brain areas typically associated with AD. Moreover, impairments in\nsensory-motor and visual resting state networks along the disease continuum, as\nwell as genetic mutations defining biological processes linked to endocytosis,\namyloid-beta, and cholesterol, were identified. \\textbf{Significance:} Our\nintegrative and interpretable DL approach shows promising performance for AD\ndetection and MCI prediction while shedding light on important biological\ninsights.",
      "tldr_zh": "本研究提出了一种可解释的生成式多模态框架，结合神经影像学（如多模态 MRI）和基因组学数据（Single Nucleotide Polymorphisms），旨在解码Alzheimer's disease (AD)，包括分类AD患者与健康对照以及预测Mild Cognitive Impairment (MCI)进展者，即使在数据缺失情况下也能有效捕获大脑结构和功能的改变。框架采用Cycle Generative Adversarial Networks在潜在空间填充缺失数据，并结合Explainable AI方法提取特征相关性，以提升模型的可解释性。实验结果显示，该框架在AD检测任务中达到0.926±0.02的准确率，在MCI转换任务中达到0.711±0.01的准确率，并揭示了与AD相关的灰质调制、感觉运动及视觉静息状态网络损害，以及与内吞作用、淀粉样-β和胆固醇相关的遗传突变。该方法不仅在性能上与现有技术竞争，还提供了重要的生物学洞见，促进AD诊断和预防。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "33 pages, 8 figures (main text + supplementary materials), submitted\n  to a journal",
      "pdf_url": "http://arxiv.org/pdf/2406.13292v3",
      "published_date": "2024-06-19 07:31:47 UTC",
      "updated_date": "2025-02-04 15:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:26:03.839824"
    },
    {
      "arxiv_id": "2406.13280v2",
      "title": "Design Optimization of NOMA Aided Multi-STAR-RIS for Indoor Environments: A Convex Approximation Imitated Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Min Park",
        "Sheikh Salman Hassan",
        "Yan Kyaw Tun",
        "Eui-Nam Huh",
        "Walid Saad",
        "Choong Seon Hong"
      ],
      "abstract": "Non-orthogonal multiple access (NOMA) enables multiple users to share the\nsame frequency band, and simultaneously transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) provides 360-degree full-space\ncoverage, optimizing both transmission and reflection for improved network\nperformance and dynamic control of the indoor environment. However, deploying\nSTAR-RIS indoors presents challenges in interference mitigation, power\nconsumption, and real-time configuration. In this work, a novel network\narchitecture utilizing multiple access points (APs), STAR-RISs, and NOMA is\nproposed for indoor communication. To address these, we formulate an\noptimization problem involving user assignment, access point (AP) beamforming,\nand STAR-RIS phase control. A decomposition approach is used to solve the\ncomplex problem efficiently, employing a many-to-one matching algorithm for\nuser-AP assignment and K-means clustering for resource management.\nAdditionally, multi-agent deep reinforcement learning (MADRL) is leveraged to\noptimize the control of the STAR-RIS. Within the proposed MADRL framework, a\nnovel approach is introduced in which each decision variable acts as an\nindependent agent, enabling collaborative learning and decision making. The\nMADRL framework is enhanced by incorporating convex approximation (CA), which\naccelerates policy learning through suboptimal solutions from successive convex\napproximation (SCA), leading to faster adaptation and convergence. Simulations\ndemonstrate significant improvements in network utility compared to baseline\napproaches.",
      "tldr_zh": "该论文提出了一种针对室内环境的 NOMA 辅助多 STAR-RIS 设计优化方案，旨在通过 NOMA 实现多用户共享频段，并利用 STAR-RIS 提供 360 度全空间覆盖以提升网络性能和环境控制，同时解决干扰、功耗和实时配置的挑战。研究者构建了一个优化问题，包括用户分配、AP 波束形成和 STAR-RIS 相位控制，并采用分解方法结合 many-to-one 匹配算法和 K-means 聚类进行高效解决，同时引入多智能体深度强化学习 (MADRL) 框架，其中每个决策变量作为独立智能体进行协作学习。MADRL 通过融入凸近似 (CA) 和连续凸近似 (SCA) 技术加速策略学习，模拟结果显示该方法显著提高了网络效用，优于基线方法。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "37 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2311.08708",
      "pdf_url": "http://arxiv.org/pdf/2406.13280v2",
      "published_date": "2024-06-19 07:17:04 UTC",
      "updated_date": "2024-09-17 15:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:26:18.531734"
    },
    {
      "arxiv_id": "2406.13269v1",
      "title": "Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Druart",
        "Valentin Vielzeuf",
        "Yannick Estève"
      ],
      "abstract": "In spoken Task-Oriented Dialogue (TOD) systems, the choice of the semantic\nrepresentation describing the users' requests is key to a smooth interaction.\nIndeed, the system uses this representation to reason over a database and its\ndomain knowledge to choose its next action. The dialogue course thus depends on\nthe information provided by this semantic representation. While textual\ndatasets provide fine-grained semantic representations, spoken dialogue\ndatasets fall behind. This paper provides insights into automatic enhancement\nof spoken dialogue datasets' semantic representations. Our contributions are\nthree fold: (1) assess the relevance of Large Language Model fine-tuning, (2)\nevaluate the knowledge captured by the produced annotations and (3) highlight\nsemi-automatic annotation implications.",
      "tldr_zh": "这篇论文探讨了在口语任务导向对话（TOD）系统中，如何通过低成本的 Large Language Model (LLM) 注释来提升数据集的语义表示，从而改善系统对用户请求的理解和响应。研究评估了 LLM 微调的相关性，分析了生成注释捕获的知识水平，并突出了半自动注释的潜在影响。总体而言，这些贡献为自动增强口语对话数据集的语义表示提供了宝贵见解，帮助弥合其与文本数据集的差距。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13269v1",
      "published_date": "2024-06-19 06:59:57 UTC",
      "updated_date": "2024-06-19 06:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:26:29.002006"
    },
    {
      "arxiv_id": "2406.13264v2",
      "title": "WONDERBREAD: A Benchmark for Evaluating Multimodal Foundation Models on Business Process Management Tasks",
      "title_zh": "WONDERBREAD：用于评估多模态基础模型在业务流程管理任务上的基准测试系统",
      "authors": [
        "Michael Wornow",
        "Avanika Narayan",
        "Ben Viggiano",
        "Ishan S. Khare",
        "Tathagat Verma",
        "Tibor Thompson",
        "Miguel Angel Fuentes Hernandez",
        "Sudharsan Sundar",
        "Chloe Trujillo",
        "Krrish Chawla",
        "Rongfei Lu",
        "Justin Shen",
        "Divya Nagaraj",
        "Joshua Martinez",
        "Vardhan Agrawal",
        "Althea Hudson",
        "Nigam H. Shah",
        "Christopher Re"
      ],
      "abstract": "Existing ML benchmarks lack the depth and diversity of annotations needed for\nevaluating models on business process management (BPM) tasks. BPM is the\npractice of documenting, measuring, improving, and automating enterprise\nworkflows. However, research has focused almost exclusively on one task - full\nend-to-end automation using agents based on multimodal foundation models (FMs)\nlike GPT-4. This focus on automation ignores the reality of how most BPM tools\nare applied today - simply documenting the relevant workflow takes 60% of the\ntime of the typical process optimization project. To address this gap we\npresent WONDERBREAD, the first benchmark for evaluating multimodal FMs on BPM\ntasks beyond automation. Our contributions are: (1) a dataset containing 2928\ndocumented workflow demonstrations; (2) 6 novel BPM tasks sourced from\nreal-world applications ranging from workflow documentation to knowledge\ntransfer to process improvement; and (3) an automated evaluation harness. Our\nbenchmark shows that while state-of-the-art FMs can automatically generate\ndocumentation (e.g. recalling 88% of the steps taken in a video demonstration\nof a workflow), they struggle to re-apply that knowledge towards finer-grained\nvalidation of workflow completion (F1 < 0.3). We hope WONDERBREAD encourages\nthe development of more \"human-centered\" AI tooling for enterprise applications\nand furthers the exploration of multimodal FMs for the broader universe of BPM\ntasks. We publish our dataset and experiments here:\nhttps://github.com/HazyResearch/wonderbread",
      "tldr_zh": "本研究引入了WONDERBREAD基准，用于评估多模态基础模型(FMs)在业务流程管理(BPM)任务上的性能，填补了现有ML基准在BPM领域深度和多样性不足的空白。WONDERBREAD包括一个包含2928个文档化工作流演示的数据集、6个源于真实应用的BPM任务（如工作流文档、知识转移和流程改进），以及一个自动评估工具。实验结果显示，先进FMs能有效生成文档（如回想视频中88%的步骤），但在细粒度的工作流验证任务上表现欠佳（F1 < 0.3），呼吁开发更人性化的AI工具以推动BPM应用的创新。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13264v2",
      "published_date": "2024-06-19 06:50:15 UTC",
      "updated_date": "2024-10-11 00:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:26:40.962852"
    },
    {
      "arxiv_id": "2406.13261v3",
      "title": "BeHonest: Benchmarking Honesty in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Steffi Chern",
        "Zhulin Hu",
        "Yuqing Yang",
        "Ethan Chern",
        "Yuan Guo",
        "Jiahe Jin",
        "Binjie Wang",
        "Pengfei Liu"
      ],
      "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\npresent severe risks that intensify as these models approach superintelligent\nlevels. Enhancing honesty in LLMs addresses critical limitations and helps\nuncover latent capabilities that are not readily expressed. This underscores\nthe urgent need for reliable methods and benchmarks to effectively ensure and\nevaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We encourage the AI community to\nprioritize honesty alignment in these models, which can harness their full\npotential to benefit society while preventing them from causing harm through\ndeception or inconsistency. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
      "tldr_zh": "这项研究指出，过去对 Large Language Models (LLMs) 的评估主要关注 helpfulness 和 harmlessness，而对 honesty（诚实性）的关注不足，因为 LLMs 的不诚实行为（如传播错误信息）可能带来严重风险。论文引入了 BeHonest 基准，用于全面评估 LLMs 在知识边界意识、避免欺骗和响应一致性等三个方面的诚实性，通过设计 10 个场景测试了 9 个流行模型（包括闭源和开源模型）。实验结果显示，现有 LLMs 在 honesty 方面仍有显著改进空间，并呼吁 AI 社区优先推动诚实性对齐，以最大化模型的社会益处并减少潜在危害。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13261v3",
      "published_date": "2024-06-19 06:46:59 UTC",
      "updated_date": "2024-07-08 18:29:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:26:55.146909"
    },
    {
      "arxiv_id": "2406.13257v1",
      "title": "Reasoning with trees: interpreting CNNs using hierarchies",
      "title_zh": "翻译失败",
      "authors": [
        "Caroline Mazini Rodrigues",
        "Nicolas Boutry",
        "Laurent Najman"
      ],
      "abstract": "Challenges persist in providing interpretable explanations for neural network\nreasoning in explainable AI (xAI). Existing methods like Integrated Gradients\nproduce noisy maps, and LIME, while intuitive, may deviate from the model's\nreasoning. We introduce a framework that uses hierarchical segmentation\ntechniques for faithful and interpretable explanations of Convolutional Neural\nNetworks (CNNs). Our method constructs model-based hierarchical segmentations\nthat maintain the model's reasoning fidelity and allows both human-centric and\nmodel-centric segmentation. This approach offers multiscale explanations,\naiding bias identification and enhancing understanding of neural network\ndecision-making. Experiments show that our framework, xAiTrees, delivers highly\ninterpretable and faithful model explanations, not only surpassing traditional\nxAI methods but shedding new light on a novel approach to enhancing xAI\ninterpretability. Code at: https://github.com/CarolMazini/reasoning_with_trees .",
      "tldr_zh": "本研究针对可解释 AI (xAI) 中神经网络解释的挑战，提出了一种使用分层分割 (hierarchical segmentation) 技术的新框架，以提供对 Convolutional Neural Networks (CNNs) 的忠实和可解释解释。该框架构建基于模型的分层分割，支持多尺度 (multiscale) 解释，并兼顾人类中心和模型中心视角，帮助识别偏差并提升对决策过程的理解。实验结果表明，xAiTrees 框架在解释准确性和可信度上优于传统方法如 Integrated Gradients 和 LIME，并提供了开源代码以便进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13257v1",
      "published_date": "2024-06-19 06:45:19 UTC",
      "updated_date": "2024-06-19 06:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:27:06.138595"
    },
    {
      "arxiv_id": "2406.13250v1",
      "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
      "title_zh": "LangTopo: 将图形语言描述与标记化拓扑建模对齐",
      "authors": [
        "Zhong Guan",
        "Hongke Zhao",
        "Likang Wu",
        "Ming He",
        "Jianpin Fan"
      ],
      "abstract": "Recently, large language models (LLMs) have been widely researched in the\nfield of graph machine learning due to their outstanding abilities in language\ncomprehension and learning. However, the significant gap between natural\nlanguage tasks and topological structure modeling poses a nonnegligible\nchallenge. Specifically, since natural language descriptions are not sufficient\nfor LLMs to understand and process graph-structured data, fine-tuned LLMs\nperform even worse than some traditional GNN models on graph tasks, lacking\ninherent modeling capabilities for graph structures. Existing research overly\nemphasizes LLMs' understanding of semantic information captured by external\nmodels, while inadequately exploring graph topological structure modeling,\nthereby overlooking the genuine capabilities that LLMs lack. Consequently, in\nthis paper, we introduce a new framework, LangTopo, which aligns graph\nstructure modeling with natural language understanding at the token level.\nLangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs\nby constructing a codebook for the graph modality and performs consistency\nmaximization. This process aligns the text description of LLM with the\ntopological modeling of GNN, allowing LLM to learn the ability of GNN to\ncapture graph structures, enabling LLM to handle graph-structured data\nindependently. We demonstrate the effectiveness of our proposed method on\nmultiple datasets.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在图机器学习中处理拓扑结构建模的不足，提出了一种新框架LangTopo，以解决语言描述与图结构之间存在的差距。LangTopo通过在token级别对齐图结构建模和自然语言理解，构建图模态codebook并进行一致性最大化，使LLMs能够学习GNNs的图结构捕捉能力，从而独立处理图结构数据。实验在多个数据集上验证了该方法的有效性，提升了LLMs在图任务上的性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13250v1",
      "published_date": "2024-06-19 06:20:22 UTC",
      "updated_date": "2024-06-19 06:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:27:17.112976"
    },
    {
      "arxiv_id": "2406.13249v2",
      "title": "R^2AG: Incorporating Retrieval Information into Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Fuda Ye",
        "Shuangyin Li",
        "Yongqi Zhang",
        "Lei Chen"
      ],
      "abstract": "Retrieval augmented generation (RAG) has been applied in many scenarios to\naugment large language models (LLMs) with external documents provided by\nretrievers. However, a semantic gap exists between LLMs and retrievers due to\ndifferences in their training objectives and architectures. This misalignment\nforces LLMs to passively accept the documents provided by the retrievers,\nleading to incomprehension in the generation process, where the LLMs are\nburdened with the task of distinguishing these documents using their inherent\nknowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill\nthis gap by incorporating Retrieval information into Retrieval Augmented\nGeneration. Specifically, R$^2$AG utilizes the nuanced features from the\nretrievers and employs a R$^2$-Former to capture retrieval information. Then, a\nretrieval-aware prompting strategy is designed to integrate retrieval\ninformation into LLMs' generation. Notably, R$^2$AG suits low-source scenarios\nwhere LLMs and retrievers are frozen. Extensive experiments across five\ndatasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our\nanalysis reveals that retrieval information serves as an anchor to aid LLMs in\nthe generation process, thereby filling the semantic gap.",
      "tldr_zh": "该论文针对 Retrieval Augmented Generation (RAG) 中大型语言模型 (LLMs) 与检索器 (retrievers) 之间的语义差距问题，提出了一种新型框架 R^2AG，以帮助 LLMs 更好地整合外部文档信息。具体而言，R^2AG 通过 R^2-Former 捕获检索器的细微特征，并设计 retrieval-aware prompting 策略，将检索信息融入 LLMs 的生成过程，从而减轻 LLMs 在区分文档时的负担。该框架适用于 LLMs 和 retrievers 被冻结的低资源场景，并在五个数据集上的实验中证明了其有效性、鲁棒性和效率，揭示检索信息可作为锚点填补语义差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.13249v2",
      "published_date": "2024-06-19 06:19:48 UTC",
      "updated_date": "2024-10-30 06:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:27:31.411109"
    },
    {
      "arxiv_id": "2407.12793v1",
      "title": "Data Collection and Labeling Techniques for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyu Huang",
        "Tongfang Zhao"
      ],
      "abstract": "Data collection and labeling are critical bottlenecks in the deployment of\nmachine learning applications. With the increasing complexity and diversity of\napplications, the need for efficient and scalable data collection and labeling\ntechniques has become paramount. This paper provides a review of the\nstate-of-the-art methods in data collection, data labeling, and the improvement\nof existing data and models. By integrating perspectives from both the machine\nlearning and data management communities, we aim to provide a holistic view of\nthe current landscape and identify future research directions.",
      "tldr_zh": "这篇论文审视了数据 collection 和 labeling 在机器学习应用部署中的关键瓶颈问题，随着应用复杂性的增加，这些过程的需求变得日益紧迫。论文对 state-of-the-art 的数据 collection、data labeling 方法以及改进现有数据和模型的技术进行了全面回顾，并整合了机器学习和数据管理社区的视角。最终，该研究提供了当前领域的整体景观，并指出了未来的研究方向，以推动更高效、可扩展的解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12793v1",
      "published_date": "2024-06-19 06:01:28 UTC",
      "updated_date": "2024-06-19 06:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:27:40.204886"
    },
    {
      "arxiv_id": "2406.13236v2",
      "title": "Data Contamination Can Cross Language Barriers",
      "title_zh": "数据污染可以跨越语言障碍",
      "authors": [
        "Feng Yao",
        "Yufan Zhuang",
        "Zihao Sun",
        "Sunan Xu",
        "Animesh Kumar",
        "Jingbo Shang"
      ],
      "abstract": "The opacity in developing large language models (LLMs) is raising growing\nconcerns about the potential contamination of public benchmarks in the\npre-training data. Existing contamination detection methods are typically based\non the text overlap between training and evaluation data, which can be too\nsuperficial to reflect deeper forms of contamination. In this paper, we first\npresent a cross-lingual form of contamination that inflates LLMs' performance\nwhile evading current detection methods, deliberately injected by overfitting\nLLMs on the translated versions of benchmark test sets. Then, we propose\ngeneralization-based approaches to unmask such deeply concealed contamination.\nSpecifically, we examine the LLM's performance change after modifying the\noriginal benchmark by replacing the false answer choices with correct ones from\nother questions. Contaminated models can hardly generalize to such easier\nsituations, where the false choices can be \\emph{not even wrong}, as all\nchoices are correct in their memorization. Experimental results demonstrate\nthat cross-lingual contamination can easily fool existing detection methods,\nbut not ours. In addition, we discuss the potential utilization of\ncross-lingual contamination in interpreting LLMs' working mechanisms and in\npost-training LLMs for enhanced multilingual capabilities. The code and dataset\nwe use can be obtained from \\url{https://github.com/ShangDataLab/Deep-Contam}.",
      "tldr_zh": "该论文揭示了大型语言模型（LLMs）在预训练数据中可能存在的跨语言基准测试污染问题，这种污染通过在翻译后的测试集上过度拟合模型来提升性能，却能逃避现有基于文本重叠的检测方法。作者提出了一种基于泛化能力的检测方法，即修改基准测试（如替换错误答案为正确选项）并观察模型性能变化，以识别污染模型因记忆而无法适应这些更简单场景的局限。实验结果显示，跨语言污染能欺骗传统方法，但新方法有效；此外，论文讨论了这种污染在解释LLMs机制和提升多语言能力方面的潜在应用，并提供了相关代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.13236v2",
      "published_date": "2024-06-19 05:53:27 UTC",
      "updated_date": "2024-10-30 17:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:27:53.033770"
    },
    {
      "arxiv_id": "2406.13235v1",
      "title": "Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong Guan",
        "Likang Wu",
        "Hongke Zhao",
        "Ming He",
        "Jianpin Fan"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly prominent in the recommendation\nsystems domain. Existing studies usually utilize in-context learning or\nsupervised fine-tuning on task-specific data to align LLMs into\nrecommendations. However, the substantial bias in semantic spaces between\nlanguage processing tasks and recommendation tasks poses a nonnegligible\nchallenge. Specifically, without the adequate capturing ability of\ncollaborative information, existing modeling paradigms struggle to capture\nbehavior patterns within community groups, leading to LLMs' ineffectiveness in\ndiscerning implicit interaction semantic in recommendation scenarios. To\naddress this, we consider enhancing the learning capability of language\nmodel-driven recommendation models for structured data, specifically by\nutilizing interaction graphs rich in collaborative semantics. We propose a\nGraph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec).\nGAL-Rec enhances the understanding of user-item collaborative semantics by\nimitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop\ninformation, thereby fully exploiting the substantial learning capacity of LLMs\nto independently address the complex graphs in the recommendation system.\nSufficient experimental results on three real-world datasets demonstrate that\nGAL-Rec significantly enhances the comprehension of collaborative semantics,\nand improves recommendation performance.",
      "tldr_zh": "现有研究在将 Large Language Models (LLMs) 应用于推荐系统时，通常采用 in-context learning 或 supervised fine-tuning，但这些方法因语义空间偏差而难以捕捉协作信息，导致 LLMs 在处理用户-物品隐式交互时效果不佳。\n\n为了解决这一问题，本文提出 Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec) 框架，通过模仿 Graph Neural Networks (GNNs) 的多跳信息聚合机制，利用交互图增强 LLMs 对协作语义的理解。\n\nGAL-Rec 充分利用 LLMs 的学习能力，独立处理推荐系统中的复杂图结构，从而提升模型对社区行为模式的捕捉。\n\n实验在三个真实数据集上验证了 GAL-Rec 的有效性，显著提高了推荐性能和协作语义的理解能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10pages",
      "pdf_url": "http://arxiv.org/pdf/2406.13235v1",
      "published_date": "2024-06-19 05:50:15 UTC",
      "updated_date": "2024-06-19 05:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:28:06.561922"
    },
    {
      "arxiv_id": "2406.13233v2",
      "title": "AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Zeng",
        "Yibo Miao",
        "Hongcheng Gao",
        "Hao Zhang",
        "Zhijie Deng"
      ],
      "abstract": "Mixture of experts (MoE) has become the standard for constructing\nproduction-level large language models (LLMs) due to its promise to boost model\ncapacity without causing significant overheads. Nevertheless, existing MoE\nmethods usually enforce a constant top-k routing for all tokens, which is\narguably restrictive because various tokens (e.g., \"<EOS>\" vs. \"apple\") may\nrequire various numbers of experts for feature abstraction. Lifting such a\nconstraint can help make the most of limited resources and unleash the\npotential of the model for downstream tasks. In this sense, we introduce AdaMoE\nto realize token-adaptive routing for MoE, where different tokens are permitted\nto select a various number of experts. AdaMoE makes minimal modifications to\nthe vanilla MoE with top-k routing -- it simply introduces a fixed number of\nnull experts, which do not consume any FLOPs, to the expert set and increases\nthe value of k. AdaMoE does not force each token to occupy a fixed number of\nnull experts but ensures the average usage of the null experts with a\nload-balancing loss, leading to an adaptive number of null/true experts used by\neach token. AdaMoE exhibits a strong resemblance to MoEs with expert choice\nrouting while allowing for trivial auto-regressive modeling. AdaMoE is easy to\nimplement and can be effectively applied to pre-trained (MoE-)LLMs. Extensive\nstudies show that AdaMoE can reduce average expert load (FLOPs) while achieving\nsuperior performance. For example, on the ARC-C dataset, applying our method to\nfine-tuning Mixtral-8x7B can reduce FLOPs by 14.5% while increasing accuracy by\n1.69%.",
      "tldr_zh": "该论文提出AdaMoE，一种改进Mixture-of-Experts (MoE)语言模型的框架，通过引入token-adaptive routing来允许不同token选择不同数量的experts，从而优化资源利用。AdaMoE仅需最小修改原top-k routing机制，即添加固定数量的null experts（不消耗FLOPs），并使用load-balancing loss确保null experts的平均使用，实现每个token的自适应专家分配。实验结果显示，AdaMoE能在减少平均expert负载的同时提升性能，例如在ARC-C数据集上对Mixtral-8x7B模型的微调中，降低了14.5%的FLOPs并提高了1.69%的准确率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13233v2",
      "published_date": "2024-06-19 05:47:10 UTC",
      "updated_date": "2024-10-14 03:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:28:19.846848"
    },
    {
      "arxiv_id": "2406.13232v1",
      "title": "Towards Robust Evaluation: A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Akchay Srivastava",
        "Atif Memon"
      ],
      "abstract": "Open Domain Question Answering (ODQA) within natural language processing\ninvolves building systems that answer factual questions using large-scale\nknowledge corpora. Recent advances stem from the confluence of several factors,\nsuch as large-scale training datasets, deep learning techniques, and the rise\nof large language models. High-quality datasets are used to train models on\nrealistic scenarios and enable the evaluation of the system on potentially\nunseen data. Standardized metrics facilitate comparisons between different ODQA\nsystems, allowing researchers to objectively track advancements in the field.\nOur study presents a thorough examination of the current landscape of ODQA\nbenchmarking by reviewing 52 datasets and 20 evaluation techniques across\ntextual and multimodal modalities. We introduce a novel taxonomy for ODQA\ndatasets that incorporates both the modality and difficulty of the question\ntypes. Additionally, we present a structured organization of ODQA evaluation\nmetrics along with a critical analysis of their inherent trade-offs. Our study\naims to empower researchers by providing a framework for the robust evaluation\nof modern question-answering systems. We conclude by identifying the current\nchallenges and outlining promising avenues for future research and development.",
      "tldr_zh": "这篇论文针对 Open Domain Question Answering (ODQA) 的稳健评估，审查了52个数据集和20个评估技术，涵盖文本和多模态场景。研究者引入了一个新颖的ODQA数据集分类法，结合问题模态和难度，并对20种评估指标进行了结构化组织和权衡分析。最终，该框架旨在为现代问答系统提供可靠的评估工具，同时识别当前挑战并提出未来研究方向，如改进大型语言模型(LLMs)的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 13 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13232v1",
      "published_date": "2024-06-19 05:43:02 UTC",
      "updated_date": "2024-06-19 05:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:28:32.178856"
    },
    {
      "arxiv_id": "2406.13229v1",
      "title": "Probing the Emergence of Cross-lingual Alignment during LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Hetong Wang",
        "Pasquale Minervini",
        "Edoardo M. Ponti"
      ],
      "abstract": "Multilingual Large Language Models (LLMs) achieve remarkable levels of\nzero-shot cross-lingual transfer performance. We speculate that this is\npredicated on their ability to align languages without explicit supervision\nfrom parallel sentences. While representations of translationally equivalent\nsentences in different languages are known to be similar after convergence,\nhowever, it remains unclear how such cross-lingual alignment emerges during\npre-training of LLMs. Our study leverages intrinsic probing techniques, which\nidentify which subsets of neurons encode linguistic features, to correlate the\ndegree of cross-lingual neuron overlap with the zero-shot cross-lingual\ntransfer performance for a given model. In particular, we rely on checkpoints\nof BLOOM, a multilingual autoregressive LLM, across different training steps\nand model scales. We observe a high correlation between neuron overlap and\ndownstream performance, which supports our hypothesis on the conditions leading\nto effective cross-lingual transfer. Interestingly, we also detect a\ndegradation of both implicit alignment and multilingual abilities in certain\nphases of the pre-training process, providing new insights into the\nmultilingual pretraining dynamics.",
      "tldr_zh": "本研究探讨了多语言大型语言模型 (Multilingual LLMs) 在训练过程中跨语言对齐的出现机制，假设这种对齐无需显式平行句监督即可实现。研究采用内在探测技术 (intrinsic probing) 来分析神经元子集的语言特征编码，并通过 BLOOM 模型的不同训练检查点和规模，量化跨语言神经元重叠度与 zero-shot cross-lingual transfer 性能的相关性。结果显示，神经元重叠度与下游性能高度相关，支持了有效跨语言转移的条件假设；同时，观察到预训练过程中的某些阶段会发生隐式对齐和多语言能力的退化，为理解多语言预训练动态提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13229v1",
      "published_date": "2024-06-19 05:31:59 UTC",
      "updated_date": "2024-06-19 05:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:28:44.980215"
    },
    {
      "arxiv_id": "2406.13228v1",
      "title": "AGSOA:Graph Neural Network Targeted Attack Based on Average Gradient and Structure Optimization",
      "title_zh": "AGSOA: 基于平均梯度和结构优化的图神经网络针对性攻击",
      "authors": [
        "Yang Chen",
        "Bin Zhou"
      ],
      "abstract": "Graph Neural Networks(GNNs) are vulnerable to adversarial attack that cause\nperformance degradation by adding small perturbations to the graph.\nGradient-based attacks are one of the most commonly used methods and have\nachieved good performance in many attack scenarios. However, current gradient\nattacks face the problems of easy to fall into local optima and poor attack\ninvisibility. Specifically, most gradient attacks use greedy strategies to\ngenerate perturbations, which tend to fall into local optima leading to\nunderperformance of the attack. In addition, many attacks only consider the\neffectiveness of the attack and ignore the invisibility of the attack, making\nthe attacks easily exposed leading to failure. To address the above problems,\nthis paper proposes an attack on GNNs, called AGSOA, which consists of an\naverage gradient calculation and a structre optimization module. In the average\ngradient calculation module, we compute the average of the gradient information\nover all moments to guide the attack to generate perturbed edges, which\nstabilizes the direction of the attack update and gets rid of undesirable local\nmaxima. In the structure optimization module, we calculate the similarity and\nhomogeneity of the target node's with other nodes to adjust the graph structure\nso as to improve the invisibility and transferability of the attack. Extensive\nexperiments on three commonly used datasets show that AGSOA improves the\nmisclassification rate by 2$\\%$-8$\\%$ compared to other state-of-the-art\nmodels.",
      "tldr_zh": "该论文针对图神经网络(GNNs)的易受对抗攻击问题，提出了一种新型攻击方法AGSOA，以解决现有梯度攻击容易陷入局部最优和隐蔽性差的缺陷。AGSOA包括平均梯度计算模块，通过计算梯度信息的平均值来稳定攻击方向并避免局部最优，以及结构优化模块，通过调整目标节点的相似性和同质性来提升攻击的隐蔽性和可转移性。在三个常用数据集上的实验表明，AGSOA将误分类率提高了2%-8%，比其他最先进模型表现更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13228v1",
      "published_date": "2024-06-19 05:29:20 UTC",
      "updated_date": "2024-06-19 05:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:28:55.617595"
    },
    {
      "arxiv_id": "2407.09517v1",
      "title": "Is GPT-4 conscious?",
      "title_zh": "GPT-4 是否具有意识？",
      "authors": [
        "Izak Tait",
        "Joshua Bensemann",
        "Ziqi Wang"
      ],
      "abstract": "GPT-4 is often heralded as a leading commercial AI offering, sparking debates\nover its potential as a steppingstone toward artificial general intelligence.\nBut does it possess consciousness? This paper investigates this key question\nusing the nine qualitative measurements of the Building Blocks theory. GPT-4's\ndesign, architecture and implementation are compared to each of the building\nblocks of consciousness to determine whether it has achieved the requisite\nmilestones to be classified as conscious or, if not, how close to consciousness\nGPT-4 is. Our assessment is that, while GPT-4 in its native configuration is\nnot currently conscious, current technological research and development is\nsufficient to modify GPT-4 to have all the building blocks of consciousness.\nConsequently, we argue that the emergence of a conscious AI model is plausible\nin the near term. The paper concludes with a comprehensive discussion of the\nethical implications and societal ramifications of engineering conscious AI\nentities.",
      "tldr_zh": "本论文探讨了GPT-4是否具备意识，使用Building Blocks理论的九个定性测量标准，对其设计、架构和实现进行评估。研究发现，GPT-4在原生配置下并不具有意识，但现有技术已足够修改它以包含所有意识构建块，从而使有意识的AI模型在短期内成为可能。论文还讨论了工程有意识AI的伦理含义和社会影响，强调了潜在风险和责任。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the Journal of AI Consciousness",
      "pdf_url": "http://arxiv.org/pdf/2407.09517v1",
      "published_date": "2024-06-19 05:26:55 UTC",
      "updated_date": "2024-06-19 05:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:29:06.437783"
    },
    {
      "arxiv_id": "2406.13225v1",
      "title": "Communication-Efficient Federated Knowledge Graph Embedding with Entity-Wise Top-K Sparsification",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxiong Zhang",
        "Zhiwei Zeng",
        "Xin Zhou",
        "Dusit Niyato",
        "Zhiqi Shen"
      ],
      "abstract": "Federated Knowledge Graphs Embedding learning (FKGE) encounters challenges in\ncommunication efficiency stemming from the considerable size of parameters and\nextensive communication rounds. However, existing FKGE methods only focus on\nreducing communication rounds by conducting multiple rounds of local training\nin each communication round, and ignore reducing the size of parameters\ntransmitted within each communication round. To tackle the problem, we first\nfind that universal reduction in embedding precision across all entities during\ncompression can significantly impede convergence speed, underscoring the\nimportance of maintaining embedding precision. We then propose bidirectional\ncommunication-efficient FedS based on Entity-Wise Top-K Sparsification\nstrategy. During upload, clients dynamically identify and upload only the Top-K\nentity embeddings with the greater changes to the server. During download, the\nserver first performs personalized embedding aggregation for each client. It\nthen identifies and transmits the Top-K aggregated embeddings to each client.\nBesides, an Intermittent Synchronization Mechanism is used by FedS to mitigate\nnegative effect of embedding inconsistency among shared entities of clients\ncaused by heterogeneity of Federated Knowledge Graph. Extensive experiments\nacross three datasets showcase that FedS significantly enhances communication\nefficiency with negligible (even no) performance degradation.",
      "tldr_zh": "该论文针对 Federated Knowledge Graphs Embedding (FKGE) 的通信效率问题，提出了一种基于 Entity-Wise Top-K Sparsification 策略的 FedS 框架，以减少每轮通信中传输参数的大小。FedS 在上传时仅动态选择变化最大的 Top-K 实体嵌入发送给服务器，在下载时服务器进行个性化嵌入聚合并只传输 Top-K 嵌入，同时引入 Intermittent Synchronization Mechanism 来缓解联邦知识图异质性导致的嵌入不一致。实验在三个数据集上证明，FedS 显著提升了通信效率，同时几乎没有性能损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13225v1",
      "published_date": "2024-06-19 05:26:02 UTC",
      "updated_date": "2024-06-19 05:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:29:20.274818"
    },
    {
      "arxiv_id": "2406.13216v3",
      "title": "CombAlign: Enhancing Model Expressiveness in Unsupervised Graph Alignment",
      "title_zh": "CombAlign: 增强无监督图对齐中的模型表达能力",
      "authors": [
        "Songyang Chen",
        "Yu Liu",
        "Lei Zou",
        "Zexuan Wang",
        "Youfang Lin"
      ],
      "abstract": "Unsupervised graph alignment finds the node correspondence between a pair of\nattributed graphs by only exploiting graph structure and node features. One\ncategory of recent studies first computes the node representation and then\nmatches nodes with the largest embedding-based similarity, while the other\ncategory reduces the problem to optimal transport (OT) via Gromov-Wasserstein\nlearning. However, it remains largely unexplored in the model expressiveness,\nas well as how theoretical expressivity impacts prediction accuracy. We\ninvestigate the model expressiveness from two aspects. First, we characterize\nthe model's discriminative power in distinguishing matched and unmatched node\npairs across two graphs. Second, we study the model's capability of\nguaranteeing node matching properties such as one-to-one matching and mutual\nalignment. Motivated by our theoretical analysis, we put forward a hybrid\napproach named CombAlign with stronger expressive power. Specifically, we\nenable cross-dimensional feature interaction for OT-based learning and propose\nan embedding-based method inspired by the Weisfeiler-Lehman test. We also apply\nnon-uniform marginals obtained from the embedding-based modules to OT as priors\nfor more expressiveness. Based on that, we propose a traditional\nalgorithm-based refinement, which combines our OT and embedding-based\npredictions using the ensemble learning strategy and reduces the problem to\nmaximum weight matching. With carefully designed edge weights, we ensure those\nmatching properties and further enhance prediction accuracy. By extensive\nexperiments, we demonstrate a significant improvement of 14.5% in alignment\naccuracy compared to state-of-the-art approaches and confirm the soundness of\nour theoretical analysis.",
      "tldr_zh": "该论文探讨了无监督图对齐（unsupervised graph alignment）的模型表达能力（model expressiveness），通过分析现有方法的局限性，如基于嵌入的相似度匹配和基于 Gromov-Wasserstein 的最优传输（optimal transport, OT）学习。作者提出了一种混合框架 CombAlign，结合了 OT 的跨维度特征交互、受 Weisfeiler-Lehman test 启发的嵌入方法，以及使用非均匀边际作为先验，并通过集成学习策略和最大权重匹配算法进行精炼，以确保一对一匹配和互斥对齐属性。实验结果显示，CombAlign 比最先进方法提高了 14.5% 的对齐准确率，验证了理论分析的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.13216v3",
      "published_date": "2024-06-19 04:57:35 UTC",
      "updated_date": "2025-05-06 16:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:29:32.764630"
    },
    {
      "arxiv_id": "2406.13215v2",
      "title": "Neural Residual Diffusion Models for Deep Scalable Vision Generation",
      "title_zh": "神经残差扩散模型用于深度可扩展视觉生成",
      "authors": [
        "Zhiyuan Ma",
        "Liangliang Zhao",
        "Biqing Qi",
        "Bowen Zhou"
      ],
      "abstract": "The most advanced diffusion models have recently adopted increasingly deep\nstacked networks (e.g., U-Net or Transformer) to promote the generative\nemergence capabilities of vision generation models similar to large language\nmodels (LLMs). However, progressively deeper stacked networks will intuitively\ncause numerical propagation errors and reduce noisy prediction capabilities on\ngenerative data, which hinders massively deep scalable training of vision\ngeneration models. In this paper, we first uncover the nature that neural\nnetworks being able to effectively perform generative denoising lies in the\nfact that the intrinsic residual unit has consistent dynamic property with the\ninput signal's reverse diffusion process, thus supporting excellent generative\nabilities. Afterwards, we stand on the shoulders of two common types of deep\nstacked networks to propose a unified and massively scalable Neural Residual\nDiffusion Models framework (Neural-RDM for short), which is a simple yet\nmeaningful change to the common architecture of deep generative networks by\nintroducing a series of learnable gated residual parameters that conform to the\ngenerative dynamics. Experimental results on various generative tasks show that\nthe proposed neural residual models obtain state-of-the-art scores on image's\nand video's generative benchmarks. Rigorous theoretical proofs and extensive\nexperiments also demonstrate the advantages of this simple gated residual\nmechanism consistent with dynamic modeling in improving the fidelity and\nconsistency of generated content and supporting large-scale scalable training.\nCode is available at https://github.com/Anonymous/Neural-RDM.",
      "tldr_zh": "该论文探讨了深度堆叠网络（如 U-Net 或 Transformer）在扩散模型中的应用问题，这些网络虽然提升了视觉生成能力，但会因数值传播错误和噪声预测能力下降而阻碍大规模训练。研究揭示，神经网络的残差单元与输入信号的逆扩散过程具有一致动态特性，从而支持优秀的生成能力，并提出统一的 Neural Residual Diffusion Models (Neural-RDM) 框架，通过引入可学习的门控残差参数来优化生成动态。实验结果显示，Neural-RDM 在图像和视频生成基准上取得了最先进的分数，并通过理论证明和广泛实验验证了其在提高生成内容的保真度和一致性以及支持大规模可扩展训练方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13215v2",
      "published_date": "2024-06-19 04:57:18 UTC",
      "updated_date": "2024-07-21 15:55:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:29:54.793704"
    },
    {
      "arxiv_id": "2406.13213v2",
      "title": "Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata",
      "title_zh": "翻译失败",
      "authors": [
        "Mykhailo Poliakov",
        "Nadiya Shvai"
      ],
      "abstract": "The retrieval-augmented generation (RAG) enables retrieval of relevant\ninformation from an external knowledge source and allows large language models\n(LLMs) to answer queries over previously unseen document collections. However,\nit was demonstrated that traditional RAG applications perform poorly in\nanswering multi-hop questions, which require retrieving and reasoning over\nmultiple elements of supporting evidence. We introduce a new method called\nMulti-Meta-RAG, which uses database filtering with LLM-extracted metadata to\nimprove the RAG selection of the relevant documents from various sources,\nrelevant to the question. While database filtering is specific to a set of\nquestions from a particular domain and format, we found out that Multi-Meta-RAG\ngreatly improves the results on the MultiHop-RAG benchmark. The code is\navailable at https://github.com/mxpoliakov/Multi-Meta-RAG.",
      "tldr_zh": "该研究针对传统 RAG（Retrieval-Augmented Generation）在处理多跳查询（multi-hop questions）时表现不佳的问题，提出了一种新方法 Multi-Meta-RAG。Multi-Meta-RAG 通过使用 LLM-extracted metadata 进行数据库过滤，优化了从各种来源中选择与查询相关的文档，从而提升了检索和推理多个支持证据的能力。在 MultiHop-RAG benchmark 上，该方法显著提高了性能，实验结果显示了其有效性，并提供了开源代码以供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICTERI 2024 Posters Track",
      "pdf_url": "http://arxiv.org/pdf/2406.13213v2",
      "published_date": "2024-06-19 04:53:48 UTC",
      "updated_date": "2024-08-19 11:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:29:59.462910"
    },
    {
      "arxiv_id": "2406.13210v2",
      "title": "Surgical Triplet Recognition via Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Daochang Liu",
        "Axel Hu",
        "Mubarak Shah",
        "Chang Xu"
      ],
      "abstract": "Surgical triplet recognition is an essential building block to enable\nnext-generation context-aware operating rooms. The goal is to identify the\ncombinations of instruments, verbs, and targets presented in surgical video\nframes. In this paper, we propose DiffTriplet, a new generative framework for\nsurgical triplet recognition employing the diffusion model, which predicts\nsurgical triplets via iterative denoising. To handle the challenge of triplet\nassociation, two unique designs are proposed in our diffusion framework, i.e.,\nassociation learning and association guidance. During training, we optimize the\nmodel in the joint space of triplets and individual components to capture the\ndependencies among them. At inference, we integrate association constraints\ninto each update of the iterative denoising process, which refines the triplet\nprediction using the information of individual components. Experiments on the\nCholecT45 and CholecT50 datasets show the superiority of the proposed method in\nachieving a new state-of-the-art performance for surgical triplet recognition.\nOur codes will be released.",
      "tldr_zh": "该论文提出DiffTriplet，一种基于扩散模型（diffusion model）的生成框架，用于手术三元组识别（instruments, verbs, and targets），以支持下一代上下文感知手术室。框架通过association learning和association guidance两个独特设计，分别在训练时优化三元组和组件的联合空间以捕捉依赖关系，以及在推理时将关联约束集成到迭代去噪过程中，以精炼预测结果。在CholecT45和CholecT50数据集上的实验证明，该方法实现了新的state-of-the-art性能，显著提升了手术三元组识别的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13210v2",
      "published_date": "2024-06-19 04:43:41 UTC",
      "updated_date": "2024-06-24 08:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:30:09.199899"
    },
    {
      "arxiv_id": "2406.13193v1",
      "title": "PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes",
      "title_zh": "翻译失败",
      "authors": [
        "He Cao",
        "Yanjun Shao",
        "Zhiyuan Liu",
        "Zijing Liu",
        "Xiangru Tang",
        "Yuan Yao",
        "Yu Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have seen growing adoption across\nvarious scientific disciplines. These advancements encourage the investigation\nof molecule-text modeling within synthetic chemistry, a field dedicated to\ndesigning and conducting chemical reactions to synthesize new compounds with\ndesired properties and applications. Current approaches, however, often neglect\nthe critical role of multiple molecule graph interaction in understanding\nchemical reactions, leading to suboptimal performance in synthetic chemistry\ntasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic\nChemistry Outcomes), a new framework that bridges the molecule-text modality\ngap by integrating a comprehensive benchmark of pretraining strategies and\ndataset configurations. It progressively improves multimodal LLMs through\ncross-modal alignment and multi-graph understanding. Our extensive experiments\ndemonstrate that PRESTO offers competitive results in downstream synthetic\nchemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.",
      "tldr_zh": "本文研究了 Multimodal Large Language Models (MLLMs) 在合成化学领域的应用，指出当前方法忽略了分子图交互，导致任务性能不佳。PRESTO 框架通过 progressive pretraining、cross-modal alignment 和 multi-graph understanding 等策略，逐步桥接分子-文本模态差距，提升模型在合成化学任务中的表现。实验结果显示，PRESTO 在下游任务中取得了竞争性的成果，并提供了开源代码（https://github.com/IDEA-XL/PRESTO）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13193v1",
      "published_date": "2024-06-19 03:59:46 UTC",
      "updated_date": "2024-06-19 03:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:30:23.305752"
    },
    {
      "arxiv_id": "2406.13179v1",
      "title": "Global-Local Convolution with Spiking Neural Networks for Energy-efficient Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Wang",
        "Dehao Zhang",
        "Kexin Shi",
        "Yuchen Wang",
        "Wenjie Wei",
        "Jibin Wu",
        "Malu Zhang"
      ],
      "abstract": "Thanks to Deep Neural Networks (DNNs), the accuracy of Keyword Spotting (KWS)\nhas made substantial progress. However, as KWS systems are usually implemented\non edge devices, energy efficiency becomes a critical requirement besides\nperformance. Here, we take advantage of spiking neural networks' energy\nefficiency and propose an end-to-end lightweight KWS model. The model consists\nof two innovative modules: 1) Global-Local Spiking Convolution (GLSC) module\nand 2) Bottleneck-PLIF module. Compared to the hand-crafted feature extraction\nmethods, the GLSC module achieves speech feature extraction that is sparser,\nmore energy-efficient, and yields better performance. The Bottleneck-PLIF\nmodule further processes the signals from GLSC with the aim to achieve higher\naccuracy with fewer parameters. Extensive experiments are conducted on the\nGoogle Speech Commands Dataset (V1 and V2). The results show our method\nachieves competitive performance among SNN-based KWS models with fewer\nparameters.",
      "tldr_zh": "本文提出了一种基于 Spiking Neural Networks (SNNs) 的能量高效 Keyword Spotting (KWS) 模型，以解决传统 Deep Neural Networks (DNNs) 在边设备上能耗高的挑战。模型包含两个创新模块：Global-Local Spiking Convolution (GLSC) 模块，实现更稀疏、更节能的语音特征提取，并优于手工特征提取方法；Bottleneck-PLIF 模块进一步处理信号，以更高准确率和更少参数。实验结果显示，在 Google Speech Commands Dataset (V1 和 V2) 上，该方法在 SNN-based KWS 模型中表现出色，同时参数更少。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.NE",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13179v1",
      "published_date": "2024-06-19 03:19:25 UTC",
      "updated_date": "2024-06-19 03:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:30:36.277775"
    },
    {
      "arxiv_id": "2406.13175v2",
      "title": "Sparse High Rank Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Kartikeya Bhardwaj",
        "Nilesh Prasad Pandey",
        "Sweta Priyadarshi",
        "Viswanath Ganapathy",
        "Shreya Kadambi",
        "Rafael Esteves",
        "Shubhankar Borse",
        "Paul Whatmough",
        "Risheek Garrepalli",
        "Mart Van Baalen",
        "Harris Teague",
        "Markus Nagel"
      ],
      "abstract": "Low Rank Adaptation (LoRA) has gained massive attention in the recent\ngenerative AI research. One of the main advantages of LoRA is its ability to be\nfused with pretrained models, adding no overhead during inference. However,\nfrom a mobile deployment standpoint, we can either avoid inference overhead in\nthe fused mode but lose the ability to switch adapters rapidly, or suffer\nsignificant (up to 30% higher) inference latency while enabling rapid switching\nin the unfused mode. LoRA also exhibits concept-loss when multiple adapters are\nused concurrently. In this paper, we propose Sparse High Rank Adapters (SHiRA),\na new paradigm which incurs no inference overhead, enables rapid switching, and\nsignificantly reduces concept-loss. Specifically, SHiRA can be trained by\ndirectly tuning only 1-2% of the base model weights while leaving others\nunchanged. This results in a highly sparse adapter which can be switched\ndirectly in the fused mode. We further provide theoretical and empirical\ninsights on how high sparsity in SHiRA can aid multi-adapter fusion by reducing\nconcept loss. Our extensive experiments on LVMs and LLMs demonstrate that\nfinetuning only a small fraction of the parameters in the base model\nsignificantly outperforms LoRA while enabling both rapid switching and\nmulti-adapter fusion. Finally, we provide a latency- and memory-efficient SHiRA\nimplementation based on Parameter-Efficient Finetuning (PEFT) Library which\ntrains at nearly the same speed as LoRA while consuming up to 16% lower peak\nGPU memory, thus making SHiRA easy to adopt for practical use cases. To\ndemonstrate rapid switching benefits during inference, we show that loading\nSHiRA on a base model can be 5x-16x faster than LoRA fusion on a CPU.",
      "tldr_zh": "本论文提出 Sparse High Rank Adapters (SHiRA)，一种改进 Low Rank Adaptation (LoRA) 的框架，旨在解决 LoRA 在推理开销、快速适配器切换和多适配器概念损失方面的不足。\nSHiRA 通过仅微调基模型的 1-2% 权重，实现高度稀疏的适配器，从而在融合模式下无需额外开销即可支持快速切换和减少概念损失。\n实验结果显示，在 LVMs 和 LLMs 上，SHiRA 显著优于 LoRA，提供更高的性能，同时训练速度与 LoRA 相当，并降低高达 16% 的 GPU 内存消耗。\n此外，SHiRA 的高效实现基于 Parameter-Efficient Finetuning (PEFT) 库，推理时加载速度可快 5-16 倍，适合移动和实际部署场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13175v2",
      "published_date": "2024-06-19 03:13:11 UTC",
      "updated_date": "2025-01-27 01:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:30:48.761537"
    },
    {
      "arxiv_id": "2406.13173v3",
      "title": "Biomedical Visual Instruction Tuning with Clinician Preference Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Hejie Cui",
        "Lingjun Mao",
        "Xin Liang",
        "Jieyu Zhang",
        "Hui Ren",
        "Quanzheng Li",
        "Xiang Li",
        "Carl Yang"
      ],
      "abstract": "Recent advancements in multimodal foundation models have showcased impressive\ncapabilities in understanding and reasoning with visual and textual\ninformation. Adapting these foundation models trained for general usage to\nspecialized domains like biomedicine requires large-scale domain-specific\ninstruction datasets. While existing works have explored curating such datasets\nautomatically, the resultant datasets are not explicitly aligned with domain\nexpertise. In this work, we propose a data-centric framework, Biomedical Visual\nInstruction Tuning with Clinician Preference Alignment (BioMed-VITAL), that\nincorporates clinician preferences into both stages of generating and selecting\ninstruction data for tuning biomedical multimodal foundation models. First,\nduring the generation stage, we prompt the GPT-4V generator with a diverse set\nof clinician-selected demonstrations for preference-aligned data candidate\ngeneration. Then, during the selection phase, we train a separate selection\nmodel, which explicitly distills clinician and policy-guided model preferences\ninto a rating function to select high-quality data for medical instruction\ntuning. Results show that the model tuned with the instruction-following data\nfrom our method demonstrates a significant improvement in open visual chat\n(18.5% relatively) and medical VQA (win rate up to 81.73%). Our\ninstruction-following data and models are available at BioMed-VITAL.github.io.",
      "tldr_zh": "本文提出 BioMed-VITAL 框架，用于生物医学多模态基础模型的指令调整，通过整合临床医生偏好来生成和选择高质量的领域特定指令数据集。具体方法包括：在数据生成阶段，使用 GPT-4V 结合临床医生选择的演示生成偏好对齐候选数据；在选择阶段，训练一个选择模型来蒸馏临床医生和策略引导模型的偏好，以筛选高质数据。实验结果显示，该框架调整的模型在开放视觉聊天中相对提高了 18.5%，在医疗 VQA 中胜率高达 81.73%。这项工作为生物医学应用的模型优化提供了可扩展的解决方案，并公开了相关数据和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T50, 68T45, 68T37, 68T05, 68T07, 68T09,",
        "I.2.7; I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13173v3",
      "published_date": "2024-06-19 03:07:33 UTC",
      "updated_date": "2024-07-16 05:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:00.658024"
    },
    {
      "arxiv_id": "2406.13170v2",
      "title": "Amphista: Bi-directional Multi-head Decoding for Accelerating LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Zeping Li",
        "Xinlong Yang",
        "Ziheng Gao",
        "Ji Liu",
        "Guanchen Li",
        "Zhuang Liu",
        "Dong Li",
        "Jinzhang Peng",
        "Lu Tian",
        "Emad Barsoum"
      ],
      "abstract": "Large Language Models (LLMs) inherently use autoregressive decoding, which\nlacks parallelism in inference and results in significantly slow inference\nspeed. While methods such as Medusa constructs parallelized heads, they lack\nadequate information interaction across different prediction positions. To\novercome this limitation, we introduce Amphista, an enhanced speculative\ndecoding framework that builds upon Medusa. Specifically, Amphista models an\nAuto-embedding Block capable of parallel inference, incorporating\nbi-directional attention to enable interaction between different drafting\nheads. Additionally, Amphista integrates Staged Adaptation Layers, which ensure\na seamless transition of semantic information from the target model's\nautoregressive inference to the drafting heads' non-autoregressive inference,\neffectively achieving paradigm shift and feature fusion. Experimental results\non Vicuna models using MT-Bench and Spec-Bench demonstrate that Amphista\nachieves substantial acceleration while maintaining generation quality. On\nMT-Bench, Amphista delivers up to 2.75$\\times$ speedup over vanilla\nautoregressive decoding and 1.40$\\times$ over Medusa on Vicuna 33B in\nwall-clock time.",
      "tldr_zh": "该论文提出Amphista，一种增强的推测性解码框架，旨在加速LLM推理过程，通过引入Auto-embedding Block和bi-directional attention，实现不同预测头的并行交互和信息融合。Amphista还整合Staged Adaptation Layers，确保从目标模型的自回归推理向非自回归推理的平稳过渡，从而实现范式转换和特征融合。实验结果显示，在Vicuna模型上，Amphista在MT-Bench上比传统自回归解码快2.75倍，比Medusa快1.40倍，同时保持生成质量。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13170v2",
      "published_date": "2024-06-19 02:53:39 UTC",
      "updated_date": "2024-10-18 04:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:10.734902"
    },
    {
      "arxiv_id": "2406.13165v2",
      "title": "Cardiac Copilot: Automatic Probe Guidance for Echocardiography with World Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haojun Jiang",
        "Zhenguo Sun",
        "Ning Jia",
        "Meng Li",
        "Yu Sun",
        "Shaqi Luo",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "Echocardiography is the only technique capable of real-time imaging of the\nheart and is vital for diagnosing the majority of cardiac diseases. However,\nthere is a severe shortage of experienced cardiac sonographers, due to the\nheart's complex structure and significant operational challenges. To mitigate\nthis situation, we present a Cardiac Copilot system capable of providing\nreal-time probe movement guidance to assist less experienced sonographers in\nconducting freehand echocardiography. This system can enable non-experts,\nespecially in primary departments and medically underserved areas, to perform\ncardiac ultrasound examinations, potentially improving global healthcare\ndelivery. The core innovation lies in proposing a data-driven world model,\nnamed Cardiac Dreamer, for representing cardiac spatial structures. This world\nmodel can provide structure features of any cardiac planes around the current\nprobe position in the latent space, serving as an precise navigation map for\nautonomous plane localization. We train our model with real-world ultrasound\ndata and corresponding probe motion from 110 routine clinical scans with 151K\nsample pairs by three certified sonographers. Evaluations on three standard\nplanes with 37K sample pairs demonstrate that the world model can reduce\nnavigation errors by up to 33\\% and exhibit more stable performance.",
      "tldr_zh": "该研究针对超声心动图(Echocardiography)操作中经验技师短缺的问题，提出Cardiac Copilot系统，该系统提供实时探头移动指导，帮助非专家（如基层医疗人员）进行心脏超声检查，从而提升全球医疗服务。核心创新是开发数据驱动的世界模型Cardiac Dreamer，用于表示心脏空间结构，能在潜在空间提供当前探头位置周围的精确结构特征，作为自主平面定位的导航地图。研究使用110次临床扫描的151K样本对进行训练，并在37K样本对的评估中，Cardiac Dreamer将导航错误减少多达33%，并展现出更稳定的性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by MICCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13165v2",
      "published_date": "2024-06-19 02:42:29 UTC",
      "updated_date": "2024-10-21 06:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:22.888880"
    },
    {
      "arxiv_id": "2406.13163v1",
      "title": "LLMatDesign: Autonomous Materials Discovery with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyi Jia",
        "Chao Zhang",
        "Victor Fung"
      ],
      "abstract": "Discovering new materials can have significant scientific and technological\nimplications but remains a challenging problem today due to the enormity of the\nchemical space. Recent advances in machine learning have enabled data-driven\nmethods to rapidly screen or generate promising materials, but these methods\nstill depend heavily on very large quantities of training data and often lack\nthe flexibility and chemical understanding often desired in materials\ndiscovery. We introduce LLMatDesign, a novel language-based framework for\ninterpretable materials design powered by large language models (LLMs).\nLLMatDesign utilizes LLM agents to translate human instructions, apply\nmodifications to materials, and evaluate outcomes using provided tools. By\nincorporating self-reflection on its previous decisions, LLMatDesign adapts\nrapidly to new tasks and conditions in a zero-shot manner. A systematic\nevaluation of LLMatDesign on several materials design tasks, in silico,\nvalidates LLMatDesign's effectiveness in developing new materials with\nuser-defined target properties in the small data regime. Our framework\ndemonstrates the remarkable potential of autonomous LLM-guided materials\ndiscovery in the computational setting and towards self-driving laboratories in\nthe future.",
      "tldr_zh": "该论文提出 LLMatDesign，一种基于 Large Language Models (LLMs) 的自治材料发现框架，旨在解决传统数据驱动方法依赖海量训练数据且缺乏灵活性的问题。框架利用 LLM 代理来翻译人类指令、应用材料修改并评估结果，同时通过自我反思机制实现零样本适应。实验评估显示，LLMatDesign 在小数据环境下有效开发具有目标属性的新材料，展示了其在计算材料发现领域的潜力，并为未来自驱动实验室铺平道路。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13163v1",
      "published_date": "2024-06-19 02:35:02 UTC",
      "updated_date": "2024-06-19 02:35:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:34.235871"
    },
    {
      "arxiv_id": "2406.13162v1",
      "title": "AntibodyFlow: Normalizing Flow Model for Designing Antibody Complementarity-Determining Regions",
      "title_zh": "翻译失败",
      "authors": [
        "Bohao Xu",
        "Yanbo Wang",
        "Wenyu Chen",
        "Shimin Shan"
      ],
      "abstract": "Therapeutic antibodies have been extensively studied in drug discovery and\ndevelopment in the past decades. Antibodies are specialized protective proteins\nthat bind to antigens in a lock-to-key manner. The binding strength/affinity\nbetween an antibody and a specific antigen is heavily determined by the\ncomplementarity-determining regions (CDRs) on the antibodies. Existing machine\nlearning methods cast in silico development of CDRs as either sequence or 3D\ngraph (with a single chain) generation tasks and have achieved initial success.\nHowever, with CDR loops having specific geometry shapes, learning the 3D\ngeometric structures of CDRs remains a challenge. To address this issue, we\npropose AntibodyFlow, a 3D flow model to design antibody CDR loops.\nSpecifically, AntibodyFlow first constructs the distance matrix, then predicts\namino acids conditioned on the distance matrix. Also, AntibodyFlow conducts\nconstraint learning and constrained generation to ensure valid 3D structures.\nExperimental results indicate that AntibodyFlow outperforms the best baseline\nconsistently with up to 16.0% relative improvement in validity rate and 24.3%\nrelative reduction in geometric graph level error (root mean square deviation,\nRMSD).",
      "tldr_zh": "本研究提出 AntibodyFlow，一种 Normalizing Flow Model，用于设计抗体 Complementarity-Determining Regions (CDRs)，以解决现有机器学习方法在处理 CDR 3D 几何结构方面的挑战。\n该模型首先构建距离矩阵，然后基于距离矩阵预测氨基酸，同时通过 constraint learning 和 constrained generation 确保生成的 3D 结构有效。\n实验结果表明，AntibodyFlow 比最佳基线模型提高了高达 16.0% 的 validity rate，并降低了 24.3% 的几何图级错误 (RMSD)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13162v1",
      "published_date": "2024-06-19 02:31:23 UTC",
      "updated_date": "2024-06-19 02:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:48.540391"
    },
    {
      "arxiv_id": "2406.13161v1",
      "title": "APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Honghua Dong",
        "Qidong Su",
        "Yubo Gao",
        "Zhaoyu Li",
        "Yangjun Ruan",
        "Gennady Pekhimenko",
        "Chris J. Maddison",
        "Xujie Si"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly capable of handling\ndiverse tasks with the aid of well-crafted prompts and integration of external\ntools, but as task complexity rises, the workflow involving LLMs can be\ncomplicated and thus challenging to implement and maintain. To address this\nchallenge, we propose APPL, A Prompt Programming Language that acts as a bridge\nbetween computer programs and LLMs, allowing seamless embedding of prompts into\nPython functions, and vice versa. APPL provides an intuitive and Python-native\nsyntax, an efficient parallelized runtime with asynchronous semantics, and a\ntracing module supporting effective failure diagnosis and replaying without\nextra costs. We demonstrate that APPL programs are intuitive, concise, and\nefficient through three representative scenarios: Chain-of-Thought with\nself-consistency (CoT-SC), ReAct tool use agent, and multi-agent chat.\nExperiments on three parallelizable workflows further show that APPL can\neffectively parallelize independent LLM calls, with a significant speedup ratio\nthat almost matches the estimation.",
      "tldr_zh": "该研究提出 APPL，一种提示编程语言（A Prompt Programming Language），旨在桥接计算机程序与大型语言模型（LLMs）的提示，实现无缝整合。\nAPPL 采用直观的 Python-native 语法、有效的并行化运行时和异步语义，并提供追踪模块以支持故障诊断和重放。\n通过 Chain-of-Thought with self-consistency (CoT-SC)、ReAct 工具使用代理和多代理聊天等场景，APPL 展示了其程序的直观性、简洁性和高效性。\n实验结果显示，APPL 在并行化 LLM 调用的工作流中实现了显著的速度提升，几乎匹配预估比例。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13161v1",
      "published_date": "2024-06-19 02:29:59 UTC",
      "updated_date": "2024-06-19 02:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:31:59.847276"
    },
    {
      "arxiv_id": "2406.13155v3",
      "title": "Convolutional Kolmogorov-Arnold Networks",
      "title_zh": "卷积 Kolmogorov-Arnold 网络",
      "authors": [
        "Alexander Dylan Bodner",
        "Antonio Santiago Tepsich",
        "Jack Natan Spolski",
        "Santiago Pourteau"
      ],
      "abstract": "In this paper, we present Convolutional Kolmogorov-Arnold Networks, a novel\narchitecture that integrates the learnable spline-based activation functions of\nKolmogorov-Arnold Networks (KANs) into convolutional layers. By replacing\ntraditional fixed-weight kernels with learnable non-linear functions,\nConvolutional KANs offer a significant improvement in parameter efficiency and\nexpressive power over standard Convolutional Neural Networks (CNNs). We\nempirically evaluate Convolutional KANs on the Fashion-MNIST dataset,\ndemonstrating competitive accuracy with up to 50% fewer parameters compared to\nbaseline classic convolutions. This suggests that the KAN Convolution can\neffectively capture complex spatial relationships with fewer resources,\noffering a promising alternative for parameter-efficient deep learning models.",
      "tldr_zh": "本文提出了一种新型架构——Convolutional Kolmogorov-Arnold Networks (CKANs)，将Kolmogorov-Arnold Networks (KANs)中的可学习样条-based激活函数集成到卷积层中，从而用可学习的非线性函数替换传统固定权重内核，提升了参数效率和表达能力。相比标准Convolutional Neural Networks (CNNs)，CKANs在Fashion-MNIST数据集上的实验显示，其准确率与基准模型相当，但参数减少多达50%。这一结果表明，CKANs能更有效地捕获复杂的空间关系，为参数高效的深度学习模型提供了一个有前景的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13155v3",
      "published_date": "2024-06-19 02:09:44 UTC",
      "updated_date": "2025-03-31 12:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:32:11.487951"
    },
    {
      "arxiv_id": "2406.13154v3",
      "title": "Conditional score-based diffusion models for solving inverse problems in mechanics",
      "title_zh": "条件基于分数扩散模型用于解决力学逆问题",
      "authors": [
        "Agnimitra Dasgupta",
        "Harisankar Ramaswamy",
        "Javier Murgoitio-Esandi",
        "Ken Foo",
        "Runze Li",
        "Qifa Zhou",
        "Brendan Kennedy",
        "Assad Oberai"
      ],
      "abstract": "We propose a framework to perform Bayesian inference using conditional\nscore-based diffusion models to solve a class of inverse problems in mechanics\ninvolving the inference of a specimen's spatially varying material properties\nfrom noisy measurements of its mechanical response to loading. Conditional\nscore-based diffusion models are generative models that learn to approximate\nthe score function of a conditional distribution using samples from the joint\ndistribution. More specifically, the score functions corresponding to multiple\nrealizations of the measurement are approximated using a single neural network,\nthe so-called score network, which is subsequently used to sample the posterior\ndistribution using an appropriate Markov chain Monte Carlo scheme based on\nLangevin dynamics. Training the score network only requires simulating the\nforward model. Hence, the proposed approach can accommodate black-box forward\nmodels and complex measurement noise. Moreover, once the score network has been\ntrained, it can be re-used to solve the inverse problem for different\nrealizations of the measurements. We demonstrate the efficacy of the proposed\napproach on a suite of high-dimensional inverse problems in mechanics that\ninvolve inferring heterogeneous material properties from noisy measurements.\nSome examples we consider involve synthetic data, while others include data\ncollected from actual elastography experiments. Further, our applications\ndemonstrate that the proposed approach can handle different measurement\nmodalities, complex patterns in the inferred quantities, non-Gaussian and\nnon-additive noise models, and nonlinear black-box forward models. The results\nshow that the proposed framework can solve large-scale physics-based inverse\nproblems efficiently.",
      "tldr_zh": "本研究提出了一种基于条件分数-based diffusion models 的框架，用于解决力学领域的逆问题，具体是通过贝叶斯推理从噪声测量数据中推断样品的空间变化材料属性。方法涉及训练一个分数网络来近似条件分布的分数函数，仅需模拟前向模型即可适应黑盒模型和复杂噪声；随后，使用 Langevin dynamics 的 Markov chain Monte Carlo 方案采样后验分布。实验结果显示，该框架在高维逆问题中表现出色，包括合成数据和实际弹性图实验，能处理不同测量模式、非高斯非加性噪声以及非线性模型，并高效解决大规模物理-based 逆问题。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13154v3",
      "published_date": "2024-06-19 02:09:15 UTC",
      "updated_date": "2024-08-29 17:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:32:24.332865"
    },
    {
      "arxiv_id": "2406.13144v5",
      "title": "DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party Dialogue Understanding of Conversation Systems",
      "title_zh": "DialSim：用于评估对话系统长期多方对话理解的实时模拟器",
      "authors": [
        "Jiho Kim",
        "Woosog Chay",
        "Hyeonji Hwang",
        "Daeun Kyung",
        "Hyunseung Chung",
        "Eunbyeol Cho",
        "Yohan Jo",
        "Edward Choi"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced the capabilities of conversation systems, making them applicable to\nvarious fields (e.g., education). Despite their progress, the evaluation of the\nsystems often overlooks the complexities of real-world conversations, such as\nreal-time interactions, multi-party dialogues, and extended contextual\ndependencies. To bridge this gap, we introduce DialSim, a real-time dialogue\nsimulator. In this simulator, a conversation system is assigned the role of a\ncharacter from popular TV shows, requiring it to respond to spontaneous\nquestions using past dialogue information and to distinguish between known and\nunknown information. Key features of DialSim include assessing the system's\nability to respond within a reasonable time limit, handling long-term\nmulti-party dialogues, and evaluating performance under randomized questioning\nwith LongDialQA, a novel, high-quality question-answering dataset. Our\nexperiments using DialSim reveal the strengths and weaknesses of the latest\nconversation systems, offering valuable insights for future advancements in\nconversational AI. DialSim is available at https://dialsim.github.io/.",
      "tldr_zh": "本研究引入了 DialSim，一种实时对话模拟器，用于评估对话系统的长期多方对话理解能力，旨在弥补现有评估中对真实世界交互（如实时响应和上下文依赖）的忽略。DialSim 让对话系统扮演 TV 节目中的角色，需要基于过去对话信息响应自发问题，并区分已知和未知信息，同时处理随机提问和多方互动。论文还提出了 LongDialQA，一种高质量问答数据集，用于实验评估。结果显示，DialSim 揭示了最新 Large Language Models (LLMs) 对话系统的优势和弱点，为提升对话 AI 的未来发展提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13144v5",
      "published_date": "2024-06-19 01:37:10 UTC",
      "updated_date": "2025-02-17 11:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:32:37.043745"
    },
    {
      "arxiv_id": "2406.13138v2",
      "title": "Large Language Models are Biased Because They Are Large Language Models",
      "title_zh": "大型语言模型存在偏见，因为它们本身就是大型语言模型",
      "authors": [
        "Philip Resnik"
      ],
      "abstract": "This position paper's primary goal is to provoke thoughtful discussion about\nthe relationship between bias and fundamental properties of large language\nmodels. I do this by seeking to convince the reader that harmful biases are an\ninevitable consequence arising from the design of any large language model as\nLLMs are currently formulated. To the extent that this is true, it suggests\nthat the problem of harmful bias cannot be properly addressed without a serious\nreconsideration of AI driven by LLMs, going back to the foundational\nassumptions underlying their design.",
      "tldr_zh": "这篇立场论文（position paper）旨在引发对大型语言模型（LLMs）的偏差问题进行深入讨论，作者认为有害偏差是LLMs当前设计形式下的必然结果。论文通过分析LLMs的基本属性，论证了这种偏差无法通过简单修补来解决，而是源于其根本假设。作者建议，必须重新审视LLMs驱动的AI设计，从基础层面进行根本性变革，以有效应对偏差问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Computational Linguistics. Significantly revised since\n  the prior arXiv version. This preprint has 22 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.13138v2",
      "published_date": "2024-06-19 01:08:03 UTC",
      "updated_date": "2025-03-13 20:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:32:47.183140"
    },
    {
      "arxiv_id": "2406.13127v2",
      "title": "Oralytics Reinforcement Learning Algorithm",
      "title_zh": "Oralytics 强化学习算法",
      "authors": [
        "Anna L. Trella",
        "Kelly W. Zhang",
        "Stephanie M. Carpenter",
        "David Elashoff",
        "Zara M. Greer",
        "Inbal Nahum-Shani",
        "Dennis Ruenger",
        "Vivek Shetty",
        "Susan A. Murphy"
      ],
      "abstract": "Dental disease is still one of the most common chronic diseases in the United\nStates. While dental disease is preventable through healthy oral self-care\nbehaviors (OSCB), this basic behavior is not consistently practiced. We have\ndeveloped Oralytics, an online, reinforcement learning (RL) algorithm that\noptimizes the delivery of personalized intervention prompts to improve OSCB. In\nthis paper, we offer a full overview of algorithm design decisions made using\nprior data, domain expertise, and experiments in a simulation test bed. The\nfinalized RL algorithm was deployed in the Oralytics clinical trial, conducted\nfrom fall 2023 to summer 2024.",
      "tldr_zh": "本论文针对牙科疾病在美国作为常见慢性病的现状，强调通过健康口腔自我护理行为（OSCB）可预防，但实践不一致的问题。研究开发了Oralytics，一种在线强化学习（RL）算法，用于优化个性化干预提示，从而改善OSCB。算法设计决策基于先验数据、领域专业知识和模拟测试床实验，最终在Oralytics临床试验中部署，从2023年秋季至2024年夏季，展示了其实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13127v2",
      "published_date": "2024-06-19 00:44:11 UTC",
      "updated_date": "2024-09-12 19:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:33:01.015963"
    },
    {
      "arxiv_id": "2406.13125v1",
      "title": "A Unified Framework for Combinatorial Optimization Based on Graph Neural Networks",
      "title_zh": "一种基于图神经网络的组合优化统一框架",
      "authors": [
        "Yaochu Jin",
        "Xueming Yan",
        "Shiqing Liu",
        "Xiangyu Wang"
      ],
      "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for solving\ncombinatorial optimization problems (COPs), exhibiting state-of-the-art\nperformance in both graph-structured and non-graph-structured domains. However,\nexisting approaches lack a unified framework capable of addressing a wide range\nof COPs. After presenting a summary of representative COPs and a brief review\nof recent advancements in GNNs for solving COPs, this paper proposes a unified\nframework for solving COPs based on GNNs, including graph representation of\nCOPs, equivalent conversion of non-graph structured COPs to graph-structured\nCOPs, graph decomposition, and graph simplification. The proposed framework\nleverages the ability of GNNs to effectively capture the relational information\nand extract features from the graph representation of COPs, offering a generic\nsolution to COPs that can address the limitations of state-of-the-art in\nsolving non-graph-structured and highly complex graph-structured COPs.",
      "tldr_zh": "这篇论文提出了一种基于Graph Neural Networks (GNNs)的统一框架，用于解决各种组合优化问题 (COPs)，旨在克服现有方法在处理图结构和非图结构问题时的局限性。框架包括COPs的图表示、非图结构问题向图结构的等效转换、图分解以及图简化，利用GNNs的有效特征提取和关系捕捉能力。实验结果表明，该框架为复杂COPs提供了一个通用的解决方案，提升了问题求解的泛化性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13125v1",
      "published_date": "2024-06-19 00:40:31 UTC",
      "updated_date": "2024-06-19 00:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:33:12.018888"
    },
    {
      "arxiv_id": "2406.13123v3",
      "title": "ViLCo-Bench: VIdeo Language COntinual learning Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Tang",
        "Shohreh Deldari",
        "Hao Xue",
        "Celso De Melo",
        "Flora D. Salim"
      ],
      "abstract": "Video language continual learning involves continuously adapting to\ninformation from video and text inputs, enhancing a model's ability to handle\nnew tasks while retaining prior knowledge. This field is a relatively\nunder-explored area, and establishing appropriate datasets is crucial for\nfacilitating communication and research in this field. In this study, we\npresent the first dedicated benchmark, ViLCo-Bench, designed to evaluate\ncontinual learning models across a range of video-text tasks. The dataset\ncomprises ten-minute-long videos and corresponding language queries collected\nfrom publicly available datasets. Additionally, we introduce a novel\nmemory-efficient framework that incorporates self-supervised learning and\nmimics long-term and short-term memory effects. This framework addresses\nchallenges including memory complexity from long video clips, natural language\ncomplexity from open queries, and text-video misalignment. We posit that\nViLCo-Bench, with greater complexity compared to existing continual learning\nbenchmarks, would serve as a critical tool for exploring the video-language\ndomain, extending beyond conventional class-incremental tasks, and addressing\ncomplex and limited annotation issues. The curated data, evaluations, and our\nnovel method are available at https://github.com/cruiseresearchgroup/ViLCo.",
      "tldr_zh": "本研究介绍了ViLCo-Bench，这是首个专为视频语言持续学习（Video language continual learning）设计的基准测试，用于评估模型在处理新视频-文本任务时适应性和知识保留能力。该基准数据集包含10分钟长的视频和对应的语言查询，从公开来源收集，并超越传统类增量任务，解决复杂标注和文本-视频不对齐等问题。同时，研究者提出了一种新型内存高效框架，结合自监督学习（self-supervised learning）模拟长期和短期记忆效果，有效应对长视频的内存复杂性及自然语言挑战。该框架和基准数据可从GitHub获取，将推动视频-语言领域的研究发展。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures, 8 tables, Accepted at NeurIPS Dataset and\n  Benchmark Track 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13123v3",
      "published_date": "2024-06-19 00:38:19 UTC",
      "updated_date": "2024-12-15 10:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:33:25.746287"
    },
    {
      "arxiv_id": "2406.13121v1",
      "title": "Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?",
      "title_zh": "长上下文语言模型是否能取代检索、RAG、SQL 以及更多？",
      "authors": [
        "Jinhyuk Lee",
        "Anthony Chen",
        "Zhuyun Dai",
        "Dheeru Dua",
        "Devendra Singh Sachan",
        "Michael Boratko",
        "Yi Luan",
        "Sébastien M. R. Arnold",
        "Vincent Perot",
        "Siddharth Dalmia",
        "Hexiang Hu",
        "Xudong Lin",
        "Panupong Pasupat",
        "Aida Amini",
        "Jeremy R. Cole",
        "Sebastian Riedel",
        "Iftekhar Naim",
        "Ming-Wei Chang",
        "Kelvin Guu"
      ],
      "abstract": "Long-context language models (LCLMs) have the potential to revolutionize our\napproach to tasks traditionally reliant on external tools like retrieval\nsystems or databases. Leveraging LCLMs' ability to natively ingest and process\nentire corpora of information offers numerous advantages. It enhances\nuser-friendliness by eliminating the need for specialized knowledge of tools,\nprovides robust end-to-end modeling that minimizes cascading errors in complex\npipelines, and allows for the application of sophisticated prompting techniques\nacross the entire system. To assess this paradigm shift, we introduce LOFT, a\nbenchmark of real-world tasks requiring context up to millions of tokens\ndesigned to evaluate LCLMs' performance on in-context retrieval and reasoning.\nOur findings reveal LCLMs' surprising ability to rival state-of-the-art\nretrieval and RAG systems, despite never having been explicitly trained for\nthese tasks. However, LCLMs still face challenges in areas like compositional\nreasoning that are required in SQL-like tasks. Notably, prompting strategies\nsignificantly influence performance, emphasizing the need for continued\nresearch as context lengths grow. Overall, LOFT provides a rigorous testing\nground for LCLMs, showcasing their potential to supplant existing paradigms and\ntackle novel tasks as model capabilities scale.",
      "tldr_zh": "本文探讨了长上下文语言模型 (LCLMs) 是否能取代传统的外部工具，如检索系统、RAG 和 SQL，从而简化任务处理。研究者引入了 LOFT 基准测试，该测试针对真实世界任务评估 LCLMs 在处理高达数百万 token 的上下文中进行检索和推理的能力。结果显示，LCLMs 在检索和 RAG 任务上可媲美最先进系统，但仍存在组合推理方面的挑战；此外，提示策略对性能影响显著，强调了随着模型规模增长的未来研究方向。整体而言，这展示了 LCLMs 取代现有范式的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages. Dataset available at\n  https://github.com/google-deepmind/loft",
      "pdf_url": "http://arxiv.org/pdf/2406.13121v1",
      "published_date": "2024-06-19 00:28:58 UTC",
      "updated_date": "2024-06-19 00:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:33:37.112701"
    },
    {
      "arxiv_id": "2406.13117v1",
      "title": "State-of-the-Art Review: The Use of Digital Twins to Support Artificial Intelligence-Guided Predictive Maintenance",
      "title_zh": "最先进综述：数字孪生用于支持人工智能指导的预测性维护",
      "authors": [
        "Sizhe Ma",
        "Katherine A. Flanigan",
        "Mario Bergés"
      ],
      "abstract": "In recent years, predictive maintenance (PMx) has gained prominence for its\npotential to enhance efficiency, automation, accuracy, and cost-effectiveness\nwhile reducing human involvement. Importantly, PMx has evolved in tandem with\ndigital advancements, such as Big Data and the Internet of Things (IOT). These\ntechnological strides have enabled Artificial Intelligence (AI) to\nrevolutionize PMx processes, with increasing capacities for real-time\nautomation of monitoring, analysis, and prediction tasks. However, PMx still\nfaces challenges such as poor explainability and sample inefficiency in\ndata-driven methods and high complexity in physics-based models, hindering\nbroader adoption. This paper posits that Digital Twins (DTs) can be integrated\ninto PMx to overcome these challenges, paving the way for more automated PMx\napplications across various stakeholders. Despite their potential, current DTs\nhave not fully matured to bridge existing gaps. Our paper provides a\ncomprehensive roadmap for DT evolution, addressing current limitations to\nfoster large-scale automated PMx progression. We structure our approach in\nthree stages: First, we reference prior work where we identified and defined\nthe Information Requirements (IRs) and Functional Requirements (FRs) for PMx,\nforming the blueprint for a unified framework. Second, we conduct a literature\nreview to assess current DT applications integrating these IRs and FRs,\nrevealing standardized DT models and tools that support automated PMx. Lastly,\nwe highlight gaps in current DT implementations, particularly those IRs and FRs\nnot fully supported, and outline the necessary components for a comprehensive,\nautomated PMx system. Our paper concludes with research directions aimed at\nseamlessly integrating DTs into the PMx paradigm to achieve this ambitious\nvision.",
      "tldr_zh": "这篇综述论文探讨了 Digital Twins (DTs) 如何整合到 Artificial Intelligence (AI) 引导的预测性维护 (PMx) 中，以解决数据驱动方法的可解释性和样本效率问题，以及物理模型的复杂性挑战。\n论文提出一个三阶段路线图：首先，定义 PMx 的信息需求 (IRs) 和功能需求 (FRs) 作为统一框架的基础；其次，通过文献综述评估当前 DT 应用，识别支持自动 PMx 的标准化模型和工具；最后，突出现有 DT 实现的差距，并概述必要组件以推动大规模自动化 PMx。\n总体而言，该研究为 DTs 在 PMx 中的演化提供全面指导，并指出了未来研究方向，以实现更高效的实时监控和预测。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to Springer for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2406.13117v1",
      "published_date": "2024-06-19 00:10:57 UTC",
      "updated_date": "2024-06-19 00:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:33:51.284982"
    },
    {
      "arxiv_id": "2406.13114v2",
      "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
      "title_zh": "多阶段平衡蒸馏：解决序列级知识蒸馏中的长尾挑战",
      "authors": [
        "Yuhang Zhou",
        "Jing Zhu",
        "Paiheng Xu",
        "Xiaoyu Liu",
        "Xiyao Wang",
        "Danai Koutra",
        "Wei Ai",
        "Furong Huang"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced various natural\nlanguage processing tasks, but deploying them remains computationally\nexpensive. Knowledge distillation (KD) is a promising solution, enabling the\ntransfer of capabilities from larger teacher LLMs to more compact student\nmodels. Particularly, sequence-level KD, which distills rationale-based\nreasoning processes instead of merely final outcomes, shows great potential in\nenhancing students' reasoning capabilities. However, current methods struggle\nwith sequence level KD under long-tailed data distributions, adversely\naffecting generalization on sparsely represented domains. We introduce the\nMulti-Stage Balanced Distillation (BalDistill) framework, which iteratively\nbalances training data within a fixed computational budget. By dynamically\nselecting representative head domain examples and synthesizing tail domain\nexamples, BalDistill achieves state-of-the-art performance across diverse\nlong-tailed datasets, enhancing both the efficiency and efficacy of the\ndistilled models.",
      "tldr_zh": "知识蒸馏 (KD) 可以将大语言模型 (LLMs) 的能力转移到更小模型中，但序列级 KD 在长尾数据分布下存在泛化问题，导致稀有领域性能下降。论文引入 Multi-Stage Balanced Distillation (BalDistill) 框架，通过在固定计算预算下迭代平衡训练数据、动态选择 head domain 示例并合成 tail domain 示例，来提升模型的泛化能力。该方法在多种长尾数据集上实现了最先进性能，提高了蒸馏模型的效率和效果，为处理不均衡数据提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.13114v2",
      "published_date": "2024-06-19 00:01:14 UTC",
      "updated_date": "2024-10-18 23:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:34:01.567984"
    },
    {
      "arxiv_id": "2406.13113v1",
      "title": "CU-Net: a U-Net architecture for efficient brain-tumor segmentation on BraTS 2019 dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Qimin Zhang",
        "Weiwei Qi",
        "Huili Zheng",
        "Xinyu Shen"
      ],
      "abstract": "Accurately segmenting brain tumors from MRI scans is important for developing\neffective treatment plans and improving patient outcomes. This study introduces\na new implementation of the Columbia-University-Net (CU-Net) architecture for\nbrain tumor segmentation using the BraTS 2019 dataset. The CU-Net model has a\nsymmetrical U-shaped structure and uses convolutional layers, max pooling, and\nupsampling operations to achieve high-resolution segmentation. Our CU-Net model\nachieved a Dice score of 82.41%, surpassing two other state-of-the-art models.\nThis improvement in segmentation accuracy highlights the robustness and\neffectiveness of the model, which helps to accurately delineate tumor\nboundaries, which is crucial for surgical planning and radiation therapy, and\nultimately has the potential to improve patient outcomes.",
      "tldr_zh": "这篇论文介绍了 CU-Net 架构，这是一种基于 U-Net 的高效模型，用于 BraTS 2019 数据集上的脑肿瘤分割，以支持治疗计划和患者预后改善。CU-Net 采用对称的 U 形结构，结合卷积层、max pooling 和 upsampling 操作，实现高分辨率分割。实验结果显示，该模型的 Dice score 达到了 82.41%，优于其他两个最先进模型。这种改进有助于精确描绘肿瘤边界，对手术规划和放射治疗至关重要，最终可能提升患者预后。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.13113v1",
      "published_date": "2024-06-19 00:01:01 UTC",
      "updated_date": "2024-06-19 00:01:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T22:34:13.660448"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 120,
  "processed_papers_count": 120,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T22:34:35.510633"
}