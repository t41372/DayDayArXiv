[
  {
    "arxiv_id": "2412.19954v1",
    "title": "ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers",
    "authors": [
      "Chao Fan",
      "Qipei Mei",
      "Xiaonan Wang",
      "Xinming Li"
    ],
    "abstract": "In the construction sector, workers often endure prolonged periods of\nhigh-intensity physical work and prolonged use of tools, resulting in injuries\nand illnesses primarily linked to postural ergonomic risks, a longstanding\npredominant health concern. To mitigate these risks, researchers have applied\nvarious technological methods to identify the ergonomic risks that construction\nworkers face. However, traditional ergonomic risk assessment (ERA) techniques\ndo not offer interactive feedback. The rapidly developing vision-language\nmodels (VLMs), capable of generating textual descriptions or answering\nquestions about ergonomic risks based on image inputs, have not yet received\nwidespread attention. This research introduces an interactive visual query\nsystem tailored to assess the postural ergonomic risks of construction workers.\nThe system's capabilities include visual question answering (VQA), which\nresponds to visual queries regarding workers' exposure to postural ergonomic\nrisks, and image captioning (IC), which generates textual descriptions of these\nrisks from images. Additionally, this study proposes a dataset designed for\ntraining and testing such methodologies. Systematic testing indicates that the\nVQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using\nnine metrics for IC and assessments from human experts indicate that the\nproposed approach surpasses the performance of a method using the same\narchitecture trained solely on generic datasets. This study sets a new\ndirection for future developments in interactive ERA using generative\nartificial intelligence (AI) technologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "32 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19954v1",
    "published_date": "2024-12-27 23:25:51 UTC",
    "updated_date": "2024-12-27 23:25:51 UTC"
  },
  {
    "arxiv_id": "2501.00048v1",
    "title": "Stroke Prediction using Clinical and Social Features in Machine Learning",
    "authors": [
      "Aidan Chadha"
    ],
    "abstract": "Every year in the United States, 800,000 individuals suffer a stroke - one\nperson every 40 seconds, with a death occurring every four minutes. While\nindividual factors vary, certain predictors are more prevalent in determining\nstroke risk. As strokes are the second leading cause of death and disability\nworldwide, predicting stroke likelihood based on lifestyle factors is crucial.\nShowing individuals their stroke risk could motivate lifestyle changes, and\nmachine learning offers solutions to this prediction challenge. Neural networks\nexcel at predicting outcomes based on training features like lifestyle factors,\nhowever, they're not the only option. Logistic regression models can also\neffectively compute the likelihood of binary outcomes based on independent\nvariables, making them well-suited for stroke prediction. This analysis will\ncompare both neural networks (dense and convolutional) and logistic regression\nmodels for stroke prediction, examining their pros, cons, and differences to\ndevelop the most effective predictor that minimizes false negatives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00048v1",
    "published_date": "2024-12-27 23:05:16 UTC",
    "updated_date": "2024-12-27 23:05:16 UTC"
  },
  {
    "arxiv_id": "2412.19947v1",
    "title": "Standard-Deviation-Inspired Regularization for Improving Adversarial Robustness",
    "authors": [
      "Olukorede Fakorede",
      "Modeste Atsague",
      "Jin Tian"
    ],
    "abstract": "Adversarial Training (AT) has been demonstrated to improve the robustness of\ndeep neural networks (DNNs) against adversarial attacks. AT is a min-max\noptimization procedure where in adversarial examples are generated to train a\nmore robust DNN. The inner maximization step of AT increases the losses of\ninputs with respect to their actual classes. The outer minimization involves\nminimizing the losses on the adversarial examples obtained from the inner\nmaximization. This work proposes a standard-deviation-inspired (SDI)\nregularization term to improve adversarial robustness and generalization. We\nargue that the inner maximization in AT is similar to minimizing a modified\nstandard deviation of the model's output probabilities. Moreover, we suggest\nthat maximizing this modified standard deviation can complement the outer\nminimization of the AT framework. To support our argument, we experimentally\nshow that the SDI measure can be used to craft adversarial examples.\nAdditionally, we demonstrate that combining the SDI regularization term with\nexisting AT variants enhances the robustness of DNNs against stronger attacks,\nsuch as CW and Auto-attack, and improves generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19947v1",
    "published_date": "2024-12-27 22:59:21 UTC",
    "updated_date": "2024-12-27 22:59:21 UTC"
  },
  {
    "arxiv_id": "2412.19938v1",
    "title": "Towards Strong AI: Transformational Beliefs and Scientific Creativity",
    "authors": [
      "Samuel J. Eschker",
      "Chuanhai Liu"
    ],
    "abstract": "Strong artificial intelligence (AI) is envisioned to possess general\ncognitive abilities and scientific creativity comparable to human intelligence,\nencompassing both knowledge acquisition and problem-solving. While remarkable\nprogress has been made in weak AI, the realization of strong AI remains a topic\nof intense debate and critical examination. In this paper, we explore pivotal\ninnovations in the history of astronomy and physics, focusing on the discovery\nof Neptune and the concept of scientific revolutions as perceived by\nphilosophers of science. Building on these insights, we introduce a simple\ntheoretical and statistical framework of weak beliefs, termed the\nTransformational Belief (TB) framework, designed as a foundation for modeling\nscientific creativity. Through selected illustrative examples in statistical\nscience, we demonstrate the TB framework's potential as a promising foundation\nfor understanding, analyzing, and even fostering creativity -- paving the way\ntoward the development of strong AI. We conclude with reflections on future\nresearch directions and potential advancements.",
    "categories": [
      "stat.OT",
      "cs.AI"
    ],
    "primary_category": "stat.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19938v1",
    "published_date": "2024-12-27 22:02:36 UTC",
    "updated_date": "2024-12-27 22:02:36 UTC"
  },
  {
    "arxiv_id": "2412.19932v1",
    "title": "Hidformer: Transformer-Style Neural Network in Stock Price Forecasting",
    "authors": [
      "Kamil Ł. Szydłowski",
      "Jarosław A. Chudziak"
    ],
    "abstract": "This paper investigates the application of Transformer-based neural networks\nto stock price forecasting, with a special focus on the intersection of machine\nlearning techniques and financial market analysis. The evolution of Transformer\nmodels, from their inception to their adaptation for time series analysis in\nfinancial contexts, is reviewed and discussed. Central to our study is the\nexploration of the Hidformer model, which is currently recognized for its\npromising performance in time series prediction. The primary aim of this paper\nis to determine whether Hidformer will also prove itself in the task of stock\nprice prediction. This slightly modified model serves as the framework for our\nexperiments, integrating the principles of technical analysis with advanced\nmachine learning concepts to enhance stock price prediction accuracy. We\nconduct an evaluation of the Hidformer model's performance, using a set of\ncriteria to determine its efficacy. Our findings offer additional insights into\nthe practical application of Transformer architectures in financial time series\nforecasting, highlighting their potential to improve algorithmic trading\nstrategies, including human decision making.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG",
      "q-fin.CP"
    ],
    "primary_category": "cs.CE",
    "comment": "12 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19932v1",
    "published_date": "2024-12-27 21:34:44 UTC",
    "updated_date": "2024-12-27 21:34:44 UTC"
  },
  {
    "arxiv_id": "2412.19931v1",
    "title": "Pivoting B2B platform business models: From platform experimentation to multi-platform integration to ecosystem envelopment",
    "authors": [
      "Clara Filosa",
      "Marin Jovanovic",
      "Lara Agostini",
      "Anna Nosella"
    ],
    "abstract": "The landscape of digital servitization in the manufacturing sector is\nevolving, marked by a strategic shift from traditional product-centric to\nplatform business models (BMs). Manufacturing firms often employ a blend of\napproaches to develop business-to-business (B2B) platforms, leading to\nsignificant reconfigurations in their BMs. However, they frequently encounter\nfailures in their B2B platform development initiatives, leading them to abandon\ninitial efforts and pivot to alternative platform strategies. Therefore, this\nstudy, through an in-depth case study of a manufacturer in the energy sector,\narticulates a three-phase pivoting framework for B2B platform BMs, including\nplatform development and platform strategy. Initially, the manufacturer focused\non asset-based product sales supplemented by asset maintenance services and\nfollowed an emergent platformization strategy characterized by the rise of\nmultiple, independent B2B platforms catering to diverse functions. Next,\nfocusing on the imposed customer journey strategy, the firm shifted towards a\nstrategic multi-platform integration into an all-encompassing platform\nsupported by artificial intelligence (AI), signaling a maturation of the\nplatform BM to combine a wide range of services into an\nenergy-performance-based contract. Finally, the last step of the firm's\nplatform BM evolution consisted of a deliberate platform strategy open to\nexternal stakeholders and enveloping its data-driven offerings within a broader\nplatform ecosystem. This article advances B2B platform BMs and digital\nservitization literature, highlighting the efficacy of a progressive approach\nand strategic pivoting.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19931v1",
    "published_date": "2024-12-27 21:34:05 UTC",
    "updated_date": "2024-12-27 21:34:05 UTC"
  },
  {
    "arxiv_id": "2412.19927v1",
    "title": "Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with Test-time Refinement",
    "authors": [
      "Shengyu Chen",
      "Peyman Givi",
      "Can Zheng",
      "Xiaowei Jia"
    ],
    "abstract": "The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.19927v1",
    "published_date": "2024-12-27 21:22:18 UTC",
    "updated_date": "2024-12-27 21:22:18 UTC"
  },
  {
    "arxiv_id": "2412.19925v2",
    "title": "HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models",
    "authors": [
      "Ze Yang",
      "Yihong Jin",
      "Xinhe Xu"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nby understanding and generating human-like text. However, the increasing demand\nfor more sophisticated LLMs presents significant computational challenges due\nto their scale and complexity. This paper introduces Hardware Accelerated\nDecoding (HADES), a novel approach to enhance the performance and energy\nefficiency of LLMs. We address the design of an LLM accelerator with\nhardware-level speculative decoding support, a concept not previously explored\nin existing literature. Our work demonstrates how speculative decoding can\nsignificantly improve the efficiency of LLM operations, paving the way for more\nadvanced and practical applications of these models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICCEA 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19925v2",
    "published_date": "2024-12-27 21:19:01 UTC",
    "updated_date": "2025-01-13 04:33:01 UTC"
  },
  {
    "arxiv_id": "2412.19915v1",
    "title": "Identifying Cocoa Pollinators: A Deep Learning Dataset",
    "authors": [
      "Wenxiu Xu",
      "Saba Ghorbani Bazegar",
      "Dong Sheng",
      "Manuel Toledo-Hernandez",
      "ZhenZhong Lan",
      "Thomas Cherico Wanger"
    ],
    "abstract": "Cocoa is a multi-billion-dollar industry but research on improving yields\nthrough pollination remains limited. New embedded hardware and AI-based data\nanalysis is advancing information on cocoa flower visitors, their identity and\nimplications for yields. We present the first cocoa flower visitor dataset\ncontaining 5,792 images of Ceratopogonidae, Formicidae, Aphididae, Araneae, and\nEncyrtidae, and 1,082 background cocoa flower images. This dataset was curated\nfrom 23 million images collected over two years by embedded cameras in cocoa\nplantations in Hainan province, China. We exemplify the use of the dataset with\ndifferent sizes of YOLOv8 models and by progressively increasing the background\nimage ratio in the training set to identify the best-performing model. The\nmedium-sized YOLOv8 model achieved the best results with 8% background images\n(F1 Score of 0.71, mAP50 of 0.70). Overall, this dataset is useful to compare\nthe performance of deep learning model architectures on images with low\ncontrast images and difficult detection targets. The data can support future\nefforts to advance sustainable cocoa production through pollination monitoring\nprojects.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "The manuscript introduces the first cocoa pollination dataset and an\n  example analysis with YOLOv8 models",
    "pdf_url": "http://arxiv.org/pdf/2412.19915v1",
    "published_date": "2024-12-27 20:27:52 UTC",
    "updated_date": "2024-12-27 20:27:52 UTC"
  },
  {
    "arxiv_id": "2412.19913v1",
    "title": "Leveraging Scene Geometry and Depth Information for Robust Image Deraining",
    "authors": [
      "Ningning Xu",
      "Jidong J. Yang"
    ],
    "abstract": "Image deraining holds great potential for enhancing the vision of autonomous\nvehicles in rainy conditions, contributing to safer driving. Previous works\nhave primarily focused on employing a single network architecture to generate\nderained images. However, they often fail to fully exploit the rich prior\nknowledge embedded in the scenes. Particularly, most methods overlook the depth\ninformation that can provide valuable context about scene geometry and guide\nmore robust deraining. In this work, we introduce a novel learning framework\nthat integrates multiple networks: an AutoEncoder for deraining, an auxiliary\nnetwork to incorporate depth information, and two supervision networks to\nenforce feature consistency between rainy and clear scenes. This multi-network\ndesign enables our model to effectively capture the underlying scene structure,\nproducing clearer and more accurately derained images, leading to improved\nobject detection for autonomous vehicles. Extensive experiments on three\nwidely-used datasets demonstrated the effectiveness of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19913v1",
    "published_date": "2024-12-27 20:18:46 UTC",
    "updated_date": "2024-12-27 20:18:46 UTC"
  },
  {
    "arxiv_id": "2412.19906v1",
    "title": "Evaluate Summarization in Fine-Granularity: Auto Evaluation with LLM",
    "authors": [
      "Dong Yuan",
      "Eti Rastogi",
      "Fen Zhao",
      "Sagar Goyal",
      "Gautam Naik",
      "Sree Prasanna Rajagopal"
    ],
    "abstract": "Due to the exponential growth of information and the need for efficient\ninformation consumption the task of summarization has gained paramount\nimportance. Evaluating summarization accurately and objectively presents\nsignificant challenges, particularly when dealing with long and unstructured\ntexts rich in content. Existing methods, such as ROUGE (Lin, 2004) and\nembedding similarities, often yield scores that have low correlation with human\njudgements and are also not intuitively understandable, making it difficult to\ngauge the true quality of the summaries. LLMs can mimic human in giving\nsubjective reviews but subjective scores are hard to interpret and justify.\nThey can be easily manipulated by altering the models and the tones of the\nprompts. In this paper, we introduce a novel evaluation methodology and tooling\ndesigned to address these challenges, providing a more comprehensive, accurate\nand interpretable assessment of summarization outputs. Our method (SumAutoEval)\nproposes and evaluates metrics at varying granularity levels, giving objective\nscores on 4 key dimensions such as completeness, correctness, Alignment and\nreadability. We empirically demonstrate, that SumAutoEval enhances the\nunderstanding of output quality with better human correlation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19906v1",
    "published_date": "2024-12-27 19:42:25 UTC",
    "updated_date": "2024-12-27 19:42:25 UTC"
  },
  {
    "arxiv_id": "2412.19784v4",
    "title": "Can AI Help with Your Personal Finances?",
    "authors": [
      "Oudom Hean",
      "Utsha Saha",
      "Binita Saha"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have emerged as a\ntransformative development in artificial intelligence (AI), drawing significant\nattention from industry and academia. Trained on vast datasets, these\nsophisticated AI systems exhibit impressive natural language processing and\ncontent generation capabilities. This paper explores the potential of LLMs to\naddress key challenges in personal finance, focusing on the United States. We\nevaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini,\nAnthropic's Claude, and Meta's Llama, to assess their effectiveness in\nproviding accurate financial advice on topics such as mortgages, taxes, loans,\nand investments. Our findings show that while these models achieve an average\naccuracy rate of approximately 70%, they also display notable limitations in\ncertain areas. Specifically, LLMs struggle to provide accurate responses for\ncomplex financial queries, with performance varying significantly across\ndifferent topics. Despite these limitations, the analysis reveals notable\nimprovements in newer versions of these models, highlighting their growing\nutility for individuals and financial advisors. As these AI systems continue to\nevolve, their potential for advancing AI-driven applications in personal\nfinance becomes increasingly promising.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19784v4",
    "published_date": "2024-12-27 18:25:27 UTC",
    "updated_date": "2025-01-14 02:28:28 UTC"
  },
  {
    "arxiv_id": "2501.06201v1",
    "title": "A Novel Method for Pignistic Information Fusion in the View of Z-number",
    "authors": [
      "Yuanpeng He"
    ],
    "abstract": "How to properly fuse information from complex sources is still an open\nproblem. Lots of methods have been put forward to provide a effective solution\nin fusing intricate information. Among them, Dempster-Shafer evidences theory\n(DSET) is one of the representatives, it is widely used to handle uncertain\ninformation. Based on DSET, a completely new method to fuse information from\ndifferent sources based on pignistic transformation and Z-numbers is proposed\nin this paper which is able to handle separate situations of information and\nkeeps high accuracy in producing rational and correct judgments on actual\nsituations. Besides, in order to illustrate the superiority of the proposed\nmethod, some numerical examples and application are also provided to verify the\nvalidity and robustness of it.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06201v1",
    "published_date": "2024-12-27 18:17:28 UTC",
    "updated_date": "2024-12-27 18:17:28 UTC"
  },
  {
    "arxiv_id": "2412.19759v1",
    "title": "Enhancing Cognitive Diagnosis by Modeling Learner Cognitive Structure State",
    "authors": [
      "Zhifu Chen",
      "Hengnian Gu",
      "Jin Peng Zhou",
      "Dongdai Zhou"
    ],
    "abstract": "Cognitive diagnosis represents a fundamental research area within intelligent\neducation, with the objective of measuring the cognitive status of individuals.\nTheoretically, an individual's cognitive state is essentially equivalent to\ntheir cognitive structure state. Cognitive structure state comprises two key\ncomponents: knowledge state (KS) and knowledge structure state (KUS). The\nknowledge state reflects the learner's mastery of individual concepts, a widely\nstudied focus within cognitive diagnosis. In contrast, the knowledge structure\nstate-representing the learner's understanding of the relationships between\nconcepts-remains inadequately modeled. A learner's cognitive structure is\nessential for promoting meaningful learning and shaping academic performance.\nAlthough various methods have been proposed, most focus on assessing KS and\nfail to assess KUS. To bridge this gap, we propose an innovative and effective\nframework-CSCD (Cognitive Structure State-based Cognitive Diagnosis)-which\nintroduces a novel framework to modeling learners' cognitive structures in\ndiagnostic assessments, thereby offering new insights into cognitive structure\nmodeling. Specifically, we employ an edge-feature-based graph attention network\nto represent the learner's cognitive structure state, effectively integrating\nKS and KUS. Extensive experiments conducted on real datasets demonstrate the\nsuperior performance of this framework in terms of diagnostic accuracy and\ninterpretability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19759v1",
    "published_date": "2024-12-27 17:41:39 UTC",
    "updated_date": "2024-12-27 17:41:39 UTC"
  },
  {
    "arxiv_id": "2412.19755v2",
    "title": "\"Did my figure do justice to the answer?\" : Towards Multimodal Short Answer Grading with Feedback (MMSAF)",
    "authors": [
      "Pritam Sil",
      "Bhaskaran Raman",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Assessments play a vital role in a student's learning process by providing\nfeedback on a student's proficiency level in a subject. While assessments often\nmake use of short answer questions, it is often difficult to grade such\nquestions at a large scale. Moreover, such questions often involve students\ndrawing supporting diagrams along with their textual explanations. Such\nquestions often promote multimodal literacy and are aligned with\ncompetency-based questions, which demand a deeper cognitive processing ability\nfrom students. However, existing literature does not deal with the automatic\ngrading of such answers. Thus, to bridge this gap, we propose the Multimodal\nShort Answer Grading with Feedback (MMSAF) problem along with a dataset of 2197\ndata points. Additionally, we provide an automated framework for generating\nsuch datasets. Our evaluations on existing Large Language Models (LLMs) over\nthis dataset achieved an overall accuracy of 55% on the Level of Correctness\nlabels and 75% on Image Relevance labels. As per human experts, Pixtral was\nmore aligned towards human judgement and values for biology and ChatGPT for\nphysics and chemistry and achieved a score of 4 or more out of 5 in most\nparameters.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19755v2",
    "published_date": "2024-12-27 17:33:39 UTC",
    "updated_date": "2025-02-15 21:52:23 UTC"
  },
  {
    "arxiv_id": "2412.19754v3",
    "title": "Complement or substitute? How AI increases the demand for human skills",
    "authors": [
      "Elina Mäkelä",
      "Fabian Stephany"
    ],
    "abstract": "This paper examines whether artificial intelligence (AI) acts as a substitute\nor complement to human labour, drawing on 12 million online job vacancies from\nthe United States spanning 2018-2023. We adopt a two-pronged approach: first,\nanalysing \"internal effects\" within roles explicitly requiring AI, and second,\ninvestigating \"external effects\" that arise when industries, occupations, and\nregions experience increases in AI demand. Our focus centres on whether\ncomplementary skills-such as digital literacy, teamwork, resilience, agility,\nor analytical thinking-become more prevalent and valuable as AI adoption grows.\nResults show that AI-focused roles are nearly twice as likely to require skills\nlike resilience, agility, or analytical thinking compared to non-AI roles.\nFurthermore, these skills command a significant wage premium; data scientists,\nfor instance, are offered 5-10% higher salaries if they also possess resilience\nor ethics capabilities. We observe positive spillover effects: a doubling of\nAI-specific demand across industries correlates with a 5% increase in demand\nfor complementary skills, even outside AI-related roles. Conversely, tasks\nvulnerable to AI substitution, such as basic data skills or translation,\nexhibit modest declines in demand. However, the external effect is clearly net\npositive: Complementary effects are up to 1.7x larger than substitution\neffects. These results are consistent across economies, including the United\nKingdom and Australia. Our findings highlight the necessity of reskilling\nworkers in areas where human expertise remains increasingly valuable and\nensuring workers can effectively complement and leverage emerging AI\ntechnologies.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "69",
    "pdf_url": "http://arxiv.org/pdf/2412.19754v3",
    "published_date": "2024-12-27 17:26:30 UTC",
    "updated_date": "2025-02-26 11:30:39 UTC"
  },
  {
    "arxiv_id": "2412.19750v1",
    "title": "IMAGINE: An 8-to-1b 22nm FD-SOI Compute-In-Memory CNN Accelerator With an End-to-End Analog Charge-Based 0.15-8POPS/W Macro Featuring Distribution-Aware Data Reshaping",
    "authors": [
      "Adrian Kneip",
      "Martin Lefebvre",
      "Pol Maistriaux",
      "David Bol"
    ],
    "abstract": "Charge-domain compute-in-memory (CIM) SRAMs have recently become an enticing\ncompromise between computing efficiency and accuracy to process sub-8b\nconvolutional neural networks (CNNs) at the edge. Yet, they commonly make use\nof a fixed dot-product (DP) voltage swing, which leads to a loss in effective\nADC bits due to data-dependent clipping or truncation effects that waste\nprecious conversion energy and computing accuracy. To overcome this, we present\nIMAGINE, a workload-adaptive 1-to-8b CIM-CNN accelerator in 22nm FD-SOI. It\nintroduces a 1152x256 end-to-end charge-based macro with a multi-bit DP based\non an input-serial, weight-parallel accumulation that avoids power-hungry DACs.\nAn adaptive swing is achieved by combining a channel-wise DP array split with a\nlinear in-ADC implementation of analog batch-normalization (ABN), obtaining a\ndistribution-aware data reshaping. Critical design constraints are relaxed by\nincluding the post-silicon equivalent noise within a CIM-aware CNN training\nframework. Measurement results showcase an 8b system-level energy efficiency of\n40TOPS/W at 0.3/0.6V, with competitive accuracies on MNIST and CIFAR-10.\nMoreover, the peak energy and area efficiencies of the 187kB/mm2 macro\nrespectively reach up to 0.15-8POPS/W and 2.6-154TOPS/mm2, scaling with the\n8-to-1b computing precision. These results exceed previous charge-based designs\nby 3-to-5x while being the first work to provide linear in-memory rescaling.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "14 pages, 23 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2412.19750v1",
    "published_date": "2024-12-27 17:18:15 UTC",
    "updated_date": "2024-12-27 17:18:15 UTC"
  },
  {
    "arxiv_id": "2412.19747v1",
    "title": "Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning",
    "authors": [
      "Longwei Wang",
      "Navid Nayyem",
      "Abdullah Rakin"
    ],
    "abstract": "Adversarial attacks exploit the vulnerabilities of convolutional neural\nnetworks by introducing imperceptible perturbations that lead to\nmisclassifications, exposing weaknesses in feature representations and decision\nboundaries. This paper presents a novel framework combining supervised\ncontrastive learning and margin-based contrastive loss to enhance adversarial\nrobustness. Supervised contrastive learning improves the structure of the\nfeature space by clustering embeddings of samples within the same class and\nseparating those from different classes. Margin-based contrastive loss,\ninspired by support vector machines, enforces explicit constraints to create\nrobust decision boundaries with well-defined margins. Experiments on the\nCIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performance\nimprovements in adversarial accuracy under Fast Gradient Sign Method attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19747v1",
    "published_date": "2024-12-27 17:14:52 UTC",
    "updated_date": "2024-12-27 17:14:52 UTC"
  },
  {
    "arxiv_id": "2412.19737v1",
    "title": "Adaptive Context-Aware Multi-Path Transmission Control for VR/AR Content: A Deep Reinforcement Learning Approach",
    "authors": [
      "Shakil Ahmed",
      "Saifur Rahman Sabuj",
      "Ashfaq Khokhar"
    ],
    "abstract": "This paper introduces the Adaptive Context-Aware Multi-Path Transmission\nControl Protocol (ACMPTCP), an efficient approach designed to optimize the\nperformance of Multi-Path Transmission Control Protocol (MPTCP) for\ndata-intensive applications such as augmented and virtual reality (AR/VR)\nstreaming. ACMPTCP addresses the limitations of conventional MPTCP by\nleveraging deep reinforcement learning (DRL) for agile end-to-end path\nmanagement and optimal bandwidth allocation, facilitating path realignment\nacross diverse network environments.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19737v1",
    "published_date": "2024-12-27 16:56:12 UTC",
    "updated_date": "2024-12-27 16:56:12 UTC"
  },
  {
    "arxiv_id": "2412.19726v2",
    "title": "Position: Theory of Mind Benchmarks are Broken for Large Language Models",
    "authors": [
      "Matthew Riemer",
      "Zahra Ashktorab",
      "Djallel Bouneffouf",
      "Payel Das",
      "Miao Liu",
      "Justin D. Weisz",
      "Murray Campbell"
    ],
    "abstract": "This position paper argues that the majority of theory of mind benchmarks are\nbroken because of their inability to directly test how large language models\n(LLMs) adapt to new partners. This problem stems from the fact that theory of\nmind benchmarks for LLMs are overwhelmingly inspired by the methods used to\ntest theory of mind in humans and fall victim to a fallacy of attributing\nhuman-like qualities to AI agents. We expect that humans will engage in a\nconsistent reasoning process across various questions about a situation, but\nthis is known to not be the case for current LLMs. Most theory of mind\nbenchmarks only measure what we call literal theory of mind: the ability to\npredict the behavior of others. Measuring this kind of reasoning is very\ninformative in testing the ability of agents with self-consistent reasoning.\nHowever, it is important to note the distinction between this and what we\nactually care about when this self-consistency cannot be taken for granted. We\ncall this functional theory of mind: the ability to adapt to agents in-context\nfollowing a rational response to predictions about their behavior. We find that\ntop performing open source LLMs may display strong capabilities in literal\ntheory of mind, depending on how they are prompted, but seem to struggle with\nfunctional theory of mind -- even when partner policies are exceedingly simple.\nSimply put, strong literal theory of mind performance does not necessarily\nimply strong functional theory of mind performance. Achieving functional theory\nof mind, particularly over long interaction horizons with a partner, is a\nsignificant challenge deserving a prominent role in any meaningful LLM theory\nof mind evaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19726v2",
    "published_date": "2024-12-27 16:30:12 UTC",
    "updated_date": "2025-02-05 19:27:20 UTC"
  },
  {
    "arxiv_id": "2412.19723v2",
    "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
    "authors": [
      "Qiushi Sun",
      "Kanzhi Cheng",
      "Zichen Ding",
      "Chuanyang Jin",
      "Yian Wang",
      "Fangzhi Xu",
      "Zhenyu Wu",
      "Chengyou Jia",
      "Liheng Chen",
      "Zhoumianze Liu",
      "Ben Kao",
      "Guohao Li",
      "Junxian He",
      "Yu Qiao",
      "Zhiyong Wu"
    ],
    "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models\n(VLMs) have demonstrated human-like computer control capability. Despite their\nutility in advancing digital automation, a critical bottleneck persists:\ncollecting high-quality trajectory data for training. Common practices for\ncollecting such data rely on human supervision or synthetic data generation\nthrough executing pre-defined tasks, which are either resource-intensive or\nunable to guarantee data quality. Moreover, these methods suffer from limited\ndata diversity and significant gaps between synthetic data and real-world\nenvironments. To address these challenges, we propose OS-Genesis, a novel GUI\ndata synthesis pipeline that reverses the conventional trajectory collection\nprocess. Instead of relying on pre-defined tasks, OS-Genesis enables agents\nfirst to perceive environments and perform step-wise interactions, then\nretrospectively derive high-quality tasks to enable trajectory-level\nexploration. A trajectory reward model is then employed to ensure the quality\nof the generated trajectories. We demonstrate that training GUI agents with\nOS-Genesis significantly improves their performance on highly challenging\nonline benchmarks. In-depth analysis further validates OS-Genesis's efficiency\nand its superior data quality and diversity compared to existing synthesis\nmethods. Our codes, data, and checkpoints are available at\nhttps://qiushisun.github.io/OS-Genesis-Home/.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2412.19723v2",
    "published_date": "2024-12-27 16:21:58 UTC",
    "updated_date": "2025-04-30 08:23:50 UTC"
  },
  {
    "arxiv_id": "2412.19718v1",
    "title": "Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture",
    "authors": [
      "Pradeep Sain"
    ],
    "abstract": "The growing demand for dynamic, user-centric data analysis and visualization\nis evident across domains like healthcare, finance, and research. Traditional\nvisualization tools often fail to meet individual user needs due to their\nstatic and predefined nature. To address this gap, Text2Insight is introduced\nas an innovative solution that delivers customized data analysis and\nvisualizations based on user-defined natural language requirements. Leveraging\na multi-model architecture, Text2Insight transforms user inputs into actionable\ninsights and dynamic visualizations.\n  The methodology begins with analyzing the input dataset to extract structural\ndetails such as columns and values. A pre-trained Llama3 model converts the\nuser's natural language query into an SQL query, which is further refined using\na Named Entity Recognition (NER) model for accuracy. A chart predictor\ndetermines the most suitable visualization type, while the Llama3 model\ngenerates insights based on the SQL query's results. The output is a\nuser-friendly and visually informative chart. To enhance analysis capabilities,\nthe system integrates a question-answering model and a predictive model using\nthe BERT framework. These models provide insights into historical data and\npredict future trends.\n  Performance evaluation of Text2Insight demonstrates its effectiveness,\nachieving high accuracy (99%), precision (100%), recall (99%), and F1-score\n(99%), with a BLEU score of 0.5. The question-answering model attained an\naccuracy of 89% and the predictive model achieved 70% accuracy. These results\nvalidate Text2Insight as a robust and viable solution for transforming natural\nlanguage text into dynamic, user-specific data analysis and visualizations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19718v1",
    "published_date": "2024-12-27 16:17:22 UTC",
    "updated_date": "2024-12-27 16:17:22 UTC"
  },
  {
    "arxiv_id": "2412.19707v1",
    "title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback",
    "authors": [
      "Sijia Chen",
      "Baochun Li"
    ],
    "abstract": "Large language models (LLMs) have been routinely used to solve various tasks\nusing step-by-step reasoning. However, the structure of intermediate reasoning\nsteps, or thoughts, is rigid and unidirectional, such as chains, trees, or\nacyclic-directed graphs. Consequently, the resulting inflexible and\nforward-only reasoning may not address challenging tasks and fail when the LLM\nfrequently gives false responses, i.e., ``hallucinations''. This paper proposes\na new reasoning framework, called Thought Rollback (TR), allowing LLMs to\nadaptively build thought structure while maintaining effective reasoning toward\nproblem-solving under ``hallucinations''. The core mechanism of TR is rolling\nback thoughts, which allows LLMs to perform error analysis on thoughts, and\nthus roll back to any previously mistaken thought for revision. Subsequently,\nby including such trial-and-error in the prompt to guide the LLM, each rollback\nleads to one more reliable reasoning path. Therefore, starting with a simple\nprompt without human annotations, LLM with TR adaptively and gradually explores\nthoughts for a correct solution. Comprehensive experiments on mathematical\nproblems and multi-task reasoning demonstrate the state-of-the-art performance\nof TR in terms of problem-solving rate and interaction cost. For instance, the\nsolving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH\ndataset.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2024 camera-ready version with 24 pages and 12 figures. Code\n  repo with all prompts:\n  https://github.com/iQua/llmpebase/tree/main/examples/ThoughtRollback",
    "pdf_url": "http://arxiv.org/pdf/2412.19707v1",
    "published_date": "2024-12-27 16:02:34 UTC",
    "updated_date": "2024-12-27 16:02:34 UTC"
  },
  {
    "arxiv_id": "2412.19696v1",
    "title": "An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models",
    "authors": [
      "Arezoo Borji",
      "Hossam Haick",
      "Birgit Pohn",
      "Antonia Graf",
      "Jana Zakall",
      "S M Ragib Shahriar Islam",
      "Gernot Kronreif",
      "Daniel Kovatchki",
      "Heinz Strohmer",
      "Sepideh Hatamikia"
    ],
    "abstract": "In vitro fertilization (IVF) is a widely utilized assisted reproductive\ntechnology, yet predicting its success remains challenging due to the\nmultifaceted interplay of clinical, demographic, and procedural factors. This\nstudy develops a robust artificial intelligence (AI) pipeline aimed at\npredicting live birth outcomes in IVF treatments. The pipeline uses anonymized\ndata from 2010 to 2018, obtained from the Human Fertilization and Embryology\nAuthority (HFEA). We evaluated the prediction performance of live birth success\nas a binary outcome (success/failure) by integrating different feature\nselection methods, such as principal component analysis (PCA) and particle\nswarm optimization (PSO), with different traditional machine learning-based\nclassifiers including random forest (RF) and decision tree, as well as deep\nlearning-based classifiers including custom transformer-based model and a tab\ntransformer model with an attention mechanism. Our research demonstrated that\nthe best performance was achieved by combining PSO for feature selection with\nthe TabTransformer-based deep learning model, yielding an accuracy of 99.50%\nand an AUC of 99.96%, highlighting its significant performance to predict live\nbirths. This study establishes a highly accurate AI pipeline for predicting\nlive birth outcomes in IVF, demonstrating its potential to enhance personalized\nfertility treatments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19696v1",
    "published_date": "2024-12-27 15:46:59 UTC",
    "updated_date": "2024-12-27 15:46:59 UTC"
  },
  {
    "arxiv_id": "2412.19688v1",
    "title": "A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation",
    "authors": [
      "Jana Zakall",
      "Birgit Pohn",
      "Antonia Graf",
      "Daniel Kovatchki",
      "Arezoo Borji",
      "Ragib Shahriar Islam",
      "Hossam Haick",
      "Heinz Strohmer",
      "Sepideh Hatamikia"
    ],
    "abstract": "Artificial intelligence (AI) has emerged as a powerful tool to enhance\ndecision-making and optimize treatment protocols in in vitro fertilization\n(IVF). In particular, AI shows significant promise in supporting\ndecision-making during the ovarian stimulation phase of the IVF process. This\nreview evaluates studies focused on the applications of AI combined with\nmedical imaging in ovarian stimulation, examining methodologies, outcomes, and\ncurrent limitations. Our analysis of 13 studies on this topic reveals that,\nreveal that while AI algorithms demonstrated notable potential in predicting\noptimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the\nmedical imaging data utilized predominantly came from two-dimensional (2D)\nultrasound which mainly involved basic quantifications, such as follicle size\nand number, with limited use of direct feature extraction or advanced image\nanalysis techniques. This points to an underexplored opportunity where advanced\nimage analysis approaches, such as deep learning, and more diverse imaging\nmodalities, like three-dimensional (3D) ultrasound, could unlock deeper\ninsights. Additionally, the lack of explainable AI (XAI) in most studies raises\nconcerns about the transparency and traceability of AI-driven decisions - key\nfactors for clinical adoption and trust. Furthermore, many studies relied on\nsingle-center designs and small datasets, which limit the generalizability of\ntheir findings. This review highlights the need for integrating advanced\nimaging analysis techniques with explainable AI methodologies, as well as the\nimportance of leveraging multicenter collaborations and larger datasets.\nAddressing these gaps has the potential to enhance ovarian stimulation\nmanagement, paving the way for efficient, personalized, and data-driven\ntreatment pathways that improve IVF outcomes.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "29 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19688v1",
    "published_date": "2024-12-27 15:29:08 UTC",
    "updated_date": "2024-12-27 15:29:08 UTC"
  },
  {
    "arxiv_id": "2412.19685v1",
    "title": "A Large-scale Interpretable Multi-modality Benchmark for Facial Image Forgery Localization",
    "authors": [
      "Jingchun Lian",
      "Lingyu Liu",
      "Yaxiong Wang",
      "Yujiao Wu",
      "Li Zhu",
      "Zhedong Zheng"
    ],
    "abstract": "Image forgery localization, which centers on identifying tampered pixels\nwithin an image, has seen significant advancements. Traditional approaches\noften model this challenge as a variant of image segmentation, treating the\nbinary segmentation of forged areas as the end product. We argue that the basic\nbinary forgery mask is inadequate for explaining model predictions. It doesn't\nclarify why the model pinpoints certain areas and treats all forged pixels the\nsame, making it hard to spot the most fake-looking parts. In this study, we\nmitigate the aforementioned limitations by generating salient region-focused\ninterpretation for the forgery images. To support this, we craft a Multi-Modal\nTramper Tracing (MMTT) dataset, comprising facial images manipulated using\ndeepfake techniques and paired with manual, interpretable textual annotations.\nTo harvest high-quality annotation, annotators are instructed to meticulously\nobserve the manipulated images and articulate the typical characteristics of\nthe forgery regions. Subsequently, we collect a dataset of 128,303 image-text\npairs. Leveraging the MMTT dataset, we develop ForgeryTalker, an architecture\ndesigned for concurrent forgery localization and interpretation. ForgeryTalker\nfirst trains a forgery prompter network to identify the pivotal clues within\nthe explanatory text. Subsequently, the region prompter is incorporated into\nmultimodal large language model for finetuning to achieve the dual goals of\nlocalization and interpretation. Extensive experiments conducted on the MMTT\ndataset verify the superior performance of our proposed model. The dataset,\ncode as well as pretrained checkpoints will be made publicly available to\nfacilitate further research and ensure the reproducibility of our results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 4 figures, 4 tabels",
    "pdf_url": "http://arxiv.org/pdf/2412.19685v1",
    "published_date": "2024-12-27 15:23:39 UTC",
    "updated_date": "2024-12-27 15:23:39 UTC"
  },
  {
    "arxiv_id": "2412.19684v2",
    "title": "Boosting Private Domain Understanding of Efficient MLLMs: A Tuning-free, Adaptive, Universal Prompt Optimization Framework",
    "authors": [
      "Jiang Liu",
      "Bolin Li",
      "Haoyuan Li",
      "Tianwei Lin",
      "Wenqiao Zhang",
      "Tao Zhong",
      "Zhelun Yu",
      "Jinghao Wei",
      "Hao Cheng",
      "Wanggui He",
      "Fangxun Shu",
      "Hao Jiang",
      "Zheqi Lv",
      "Juncheng Li",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "abstract": "Efficient multimodal large language models (EMLLMs), in contrast to\nmultimodal large language models (MLLMs), reduce model size and computational\ncosts and are often deployed on resource-constrained devices. However, due to\ndata privacy concerns, existing open-source EMLLMs rarely have access to\nprivate domain-specific data during the pre-training process, making them\ndifficult to directly apply in device-specific domains, such as certain\nbusiness scenarios. To address this weakness, this paper focuses on the\nefficient adaptation of EMLLMs to private domains, specifically in two areas:\n1) how to reduce data requirements, and 2) how to avoid parameter fine-tuning.\nSpecifically, we propose a tun\\textbf{\\underline{I}}ng-free,\na\\textbf{\\underline{D}}aptiv\\textbf{\\underline{E}},\nunivers\\textbf{\\underline{AL}} \\textbf{\\underline{Prompt}} Optimization\nFramework, abbreviated as \\textit{\\textbf{\\ourmethod{}}} which consists of two\nstages: 1) Predefined Prompt, based on the reinforcement searching strategy,\ngenerate a prompt optimization strategy tree to acquire optimization priors; 2)\nPrompt Reflection initializes the prompt based on optimization priors, followed\nby self-reflection to further search and refine the prompt. By doing so,\n\\ourmethod{} elegantly generates the ``ideal prompts'' for processing private\ndomain-specific data. Note that our method requires no parameter fine-tuning\nand only a small amount of data to quickly adapt to the data distribution of\nprivate data. Extensive experiments across multiple tasks demonstrate that our\nproposed \\ourmethod{} significantly improves both efficiency and performance\ncompared to baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19684v2",
    "published_date": "2024-12-27 15:21:17 UTC",
    "updated_date": "2025-02-17 15:32:50 UTC"
  },
  {
    "arxiv_id": "2412.19663v1",
    "title": "CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs",
    "authors": [
      "Siyu Wang",
      "Cailian Chen",
      "Xinyi Le",
      "Qimin Xu",
      "Lei Xu",
      "Yanzhou Zhang",
      "Jie Yang"
    ],
    "abstract": "Computer-aided design (CAD) significantly enhances the efficiency, accuracy,\nand innovation of design processes by enabling precise 2D and 3D modeling,\nextensive analysis, and optimization. Existing methods for creating CAD models\nrely on latent vectors or point clouds, which are difficult to obtain and\ncostly to store. Recent advances in Multimodal Large Language Models (MLLMs)\nhave inspired researchers to use natural language instructions and images for\nCAD model construction. However, these models still struggle with inferring\naccurate 3D spatial location and orientation, leading to inaccuracies in\ndetermining the spatial 3D starting points and extrusion directions for\nconstructing geometries. This work introduces CAD-GPT, a CAD synthesis method\nwith spatial reasoning-enhanced MLLM that takes either a single image or a\ntextual description as input. To achieve precise spatial inference, our\napproach introduces a 3D Modeling Spatial Mechanism. This method maps 3D\nspatial positions and 3D sketch plane rotation angles into a 1D linguistic\nfeature space using a specialized spatial unfolding mechanism, while\ndiscretizing 2D sketch coordinates into an appropriate planar space to enable\nprecise determination of spatial starting position, sketch orientation, and 2D\nsketch coordinate translations. Extensive experiments demonstrate that CAD-GPT\nconsistently outperforms existing state-of-the-art methods in CAD model\nsynthesis, both quantitatively and qualitatively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19663v1",
    "published_date": "2024-12-27 14:19:36 UTC",
    "updated_date": "2024-12-27 14:19:36 UTC"
  },
  {
    "arxiv_id": "2412.19646v1",
    "title": "Chimera: A Block-Based Neural Architecture Search Framework for Event-Based Object Detection",
    "authors": [
      "Diego A. Silva",
      "Ahmed Elsheikh",
      "Kamilya Smagulova",
      "Mohammed E. Fouda",
      "Ahmed M. Eltawil"
    ],
    "abstract": "Event-based cameras are sensors that simulate the human eye, offering\nadvantages such as high-speed robustness and low power consumption. Established\nDeep Learning techniques have shown effectiveness in processing event data.\nChimera is a Block-Based Neural Architecture Search (NAS) framework\nspecifically designed for Event-Based Object Detection, aiming to create a\nsystematic approach for adapting RGB-domain processing methods to the event\ndomain. The Chimera design space is constructed from various macroblocks,\nincluding Attention blocks, Convolutions, State Space Models, and\nMLP-mixer-based architectures, which provide a valuable trade-off between local\nand global processing capabilities, as well as varying levels of complexity.\nThe results on the PErson Detection in Robotics (PEDRo) dataset demonstrated\nperformance levels comparable to leading state-of-the-art models, alongside an\naverage parameter reduction of 1.6 times.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19646v1",
    "published_date": "2024-12-27 13:50:44 UTC",
    "updated_date": "2024-12-27 13:50:44 UTC"
  },
  {
    "arxiv_id": "2412.19638v1",
    "title": "Xmodel-2 Technical Report",
    "authors": [
      "Wang Qun",
      "Liu Yang",
      "Lin Qingquan",
      "Qu Zhijiu",
      "Jiang Ling"
    ],
    "abstract": "Xmodel-2 is a 1.2-billion-parameter large language model designed\nspecifically for reasoning tasks. Its architecture enables different model\nscales to share a unified set of hyperparameters, allowing for extensive\nexperimentation on smaller models and seamless transfer of optimal\nconfigurations to larger models. To maximize training efficiency and stability,\nXmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on\n1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-art\nperformance in complex reasoning and agent-based tasks, while maintaining low\ntraining costs. These results highlight the potential of efficient model design\nand training strategies in advancing reasoning capabilities. Model checkpoints\nand code are publicly available on GitHub at\nhttps://github.com/XiaoduoAILab/Xmodel-2",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19638v1",
    "published_date": "2024-12-27 13:32:10 UTC",
    "updated_date": "2024-12-27 13:32:10 UTC"
  },
  {
    "arxiv_id": "2412.19616v2",
    "title": "Gradient Weight-normalized Low-rank Projection for Efficient LLM Training",
    "authors": [
      "Jia-Hong Huang",
      "Yixian Shen",
      "Hongyi Zhu",
      "Stevan Rudinac",
      "Evangelos Kanoulas"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable performance across various\ntasks, but the escalating demands on computational resources pose significant\nchallenges, particularly in the extensive utilization of full fine-tuning for\ndownstream tasks. To address this, parameter-efficient fine-tuning (PEFT)\nmethods have been developed, but they often underperform compared to full\nfine-tuning and struggle with memory efficiency. In this work, we introduce\nGradient Weight-Normalized Low-Rank Projection (GradNormLoRP), a novel approach\nthat enhances both parameter and memory efficiency while maintaining comparable\nperformance to full fine-tuning. GradNormLoRP normalizes the weight matrix to\nimprove gradient conditioning, facilitating better convergence during\noptimization. Additionally, it applies low-rank approximations to the weight\nand gradient matrices, significantly reducing memory usage during training.\nExtensive experiments demonstrate that our 8-bit GradNormLoRP reduces optimizer\nmemory usage by up to 89.5% and enables the pre-training of large LLMs, such as\nLLaMA 7B, on consumer-level GPUs like the NVIDIA RTX 4090, without additional\ninference costs. Moreover, GradNormLoRP outperforms existing low-rank methods\nin fine-tuning tasks. For instance, when fine-tuning the RoBERTa model on all\nGLUE tasks with a rank of 8, GradNormLoRP achieves an average score of 80.65,\nsurpassing LoRA's score of 79.23. These results underscore GradNormLoRP as a\npromising alternative for efficient LLM pre-training and fine-tuning. Source\ncode:\nhttps://github.com/Jhhuangkay/Gradient-Weight-normalized-Low-rank-Projection-for-Efficient-LLM-Training",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25) [Main Technical Track]",
    "pdf_url": "http://arxiv.org/pdf/2412.19616v2",
    "published_date": "2024-12-27 12:23:39 UTC",
    "updated_date": "2025-01-05 07:12:27 UTC"
  },
  {
    "arxiv_id": "2412.19609v1",
    "title": "Bidding Games on Markov Decision Processes with Quantitative Reachability Objectives",
    "authors": [
      "Guy Avni",
      "Martin Kurečka",
      "Kaushik Mallik",
      "Petr Novotný",
      "Suman Sadhukhan"
    ],
    "abstract": "Graph games are fundamental in strategic reasoning of multi-agent systems and\ntheir environments. We study a new family of graph games which combine\nstochastic environmental uncertainties and auction-based interactions among the\nagents, formalized as bidding games on (finite) Markov decision processes\n(MDP). Normally, on MDPs, a single decision-maker chooses a sequence of\nactions, producing a probability distribution over infinite paths. In bidding\ngames on MDPs, two players -- called the reachability and safety players -- bid\nfor the privilege of choosing the next action at each step. The reachability\nplayer's goal is to maximize the probability of reaching a target vertex,\nwhereas the safety player's goal is to minimize it. These games generalize\ntraditional bidding games on graphs, and the existing analysis techniques do\nnot extend. For instance, the central property of traditional bidding games is\nthe existence of a threshold budget, which is a necessary and sufficient budget\nto guarantee winning for the reachability player. For MDPs, the threshold\nbecomes a relation between the budgets and probabilities of reaching the\ntarget. We devise value-iteration algorithms that approximate thresholds and\noptimal policies for general MDPs, and compute the exact solutions for acyclic\nMDPs, and show that finding thresholds is at least as hard as solving\nsimple-stochastic games.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "To appear in AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19609v1",
    "published_date": "2024-12-27 12:10:00 UTC",
    "updated_date": "2024-12-27 12:10:00 UTC"
  },
  {
    "arxiv_id": "2412.19595v1",
    "title": "SocRATES: Towards Automated Scenario-based Testing of Social Navigation Algorithms",
    "authors": [
      "Shashank Rao Marpally",
      "Pranav Goyal",
      "Harold Soh"
    ],
    "abstract": "Current social navigation methods and benchmarks primarily focus on proxemics\nand task efficiency. While these factors are important, qualitative aspects\nsuch as perceptions of a robot's social competence are equally crucial for\nsuccessful adoption and integration into human environments. We propose a more\ncomprehensive evaluation of social navigation through scenario-based testing,\nwhere specific human-robot interaction scenarios can reveal key robot\nbehaviors. However, creating such scenarios is often labor-intensive and\ncomplex. In this work, we address this challenge by introducing a pipeline that\nautomates the generation of context-, and location-appropriate social\nnavigation scenarios, ready for simulation. Our pipeline transforms simple\nscenario metadata into detailed textual scenarios, infers pedestrian and robot\ntrajectories, and simulates pedestrian behaviors, which enables more controlled\nevaluation. We leverage the social reasoning and code-generation capabilities\nof Large Language Models (LLMs) to streamline scenario generation and\ntranslation. Our experiments show that our pipeline produces realistic\nscenarios and significantly improves scenario translation over naive LLM\nprompting. Additionally, we present initial feedback from a usability study\nwith social navigation experts and a case-study demonstrating a scenario-based\nevaluation of three navigation algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.19595v1",
    "published_date": "2024-12-27 11:33:19 UTC",
    "updated_date": "2024-12-27 11:33:19 UTC"
  },
  {
    "arxiv_id": "2412.19589v1",
    "title": "ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion",
    "authors": [
      "Minghui Li",
      "Zikang Guo",
      "Yang Wu",
      "Peijin Guo",
      "Yao Shi",
      "Shengshan Hu",
      "Wei Wan",
      "Shengqing Hu"
    ],
    "abstract": "Drug-target interaction is fundamental in understanding how drugs affect\nbiological systems, and accurately predicting drug-target affinity (DTA) is\nvital for drug discovery. Recently, deep learning methods have emerged as a\nsignificant approach for estimating the binding strength between drugs and\ntarget proteins. However, existing methods simply utilize the drug's local\ninformation from molecular topology rather than global information.\nAdditionally, the features of drugs and proteins are usually fused with a\nsimple concatenation operation, limiting their effectiveness. To address these\nchallenges, we proposed ViDTA, an enhanced DTA prediction framework. We\nintroduce virtual nodes into the Graph Neural Network (GNN)-based drug feature\nextraction network, which acts as a global memory to exchange messages more\nefficiently. By incorporating virtual graph nodes, we seamlessly integrate\nlocal and global features of drug molecular structures, expanding the GNN's\nreceptive field. Additionally, we propose an attention-based linear feature\nfusion network for better capturing the interaction information between drugs\nand proteins. Experimental results evaluated on various benchmarks including\nDavis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms the\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by International Conference on Bioinformatics and\n  Biomedicine (BIBM 24)",
    "pdf_url": "http://arxiv.org/pdf/2412.19589v1",
    "published_date": "2024-12-27 11:19:10 UTC",
    "updated_date": "2024-12-27 11:19:10 UTC"
  },
  {
    "arxiv_id": "2412.19583v1",
    "title": "A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models",
    "authors": [
      "Omar M. Safa",
      "Mahmoud M. Abdelaziz",
      "Mustafa Eltawy",
      "Mohamed Mamdouh",
      "Moamen Gharib",
      "Salaheldin Eltenihy",
      "Nagia M. Ghanem",
      "Mohamed M. Ismail"
    ],
    "abstract": "Machine Unlearning has emerged as a critical area in artificial intelligence,\naddressing the need to selectively remove learned data from machine learning\nmodels in response to data privacy regulations. This paper provides a\ncomprehensive comparative analysis of six state-of-theart unlearning techniques\napplied to image and text classification tasks. We evaluate their performance,\nefficiency, and compliance with regulatory requirements, highlighting their\nstrengths and limitations in practical scenarios. By systematically analyzing\nthese methods, we aim to provide insights into their applicability,\nchallenges,and tradeoffs, fostering advancements in the field of ethical and\nadaptable machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19583v1",
    "published_date": "2024-12-27 10:58:55 UTC",
    "updated_date": "2024-12-27 10:58:55 UTC"
  },
  {
    "arxiv_id": "2412.19578v1",
    "title": "Graph-attention-based Casual Discovery with Trust Region-navigated Clipping Policy Optimization",
    "authors": [
      "Shixuan Liu",
      "Yanghe Feng",
      "Keyu Wu",
      "Guangquan Cheng",
      "Jincai Huang",
      "Zhong Liu"
    ],
    "abstract": "In many domains of empirical sciences, discovering the causal structure\nwithin variables remains an indispensable task. Recently, to tackle with\nunoriented edges or latent assumptions violation suffered by conventional\nmethods, researchers formulated a reinforcement learning (RL) procedure for\ncausal discovery, and equipped REINFORCE algorithm to search for the\nbest-rewarded directed acyclic graph. The two keys to the overall performance\nof the procedure are the robustness of RL methods and the efficient encoding of\nvariables. However, on the one hand, REINFORCE is prone to local convergence\nand unstable performance during training. Neither trust region policy\noptimization, being computationally-expensive, nor proximal policy optimization\n(PPO), suffering from aggregate constraint deviation, is decent alternative for\ncombinatory optimization problems with considerable individual subactions. We\npropose a trust region-navigated clipping policy optimization method for causal\ndiscovery that guarantees both better search efficiency and steadiness in\npolicy optimization, in comparison with REINFORCE, PPO and our prioritized\nsampling-guided REINFORCE implementation. On the other hand, to boost the\nefficient encoding of variables, we propose a refined graph attention encoder\ncalled SDGAT that can grasp more feature information without priori\nneighbourhood information. With these improvements, the proposed method\noutperforms former RL method in both synthetic and benchmark datasets in terms\nof output results and optimization robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19578v1",
    "published_date": "2024-12-27 10:50:43 UTC",
    "updated_date": "2024-12-27 10:50:43 UTC"
  },
  {
    "arxiv_id": "2412.19562v1",
    "title": "Hindsight Planner: A Closed-Loop Few-Shot Planner for Embodied Instruction Following",
    "authors": [
      "Yuxiao Yang",
      "Shenao Zhang",
      "Zhihan Liu",
      "Huaxiu Yao",
      "Zhaoran Wang"
    ],
    "abstract": "This work focuses on building a task planner for Embodied Instruction\nFollowing (EIF) using Large Language Models (LLMs). Previous works typically\ntrain a planner to imitate expert trajectories, treating this as a supervised\ntask. While these methods achieve competitive performance, they often lack\nsufficient robustness. When a suboptimal action is taken, the planner may\nencounter an out-of-distribution state, which can lead to task failure. In\ncontrast, we frame the task as a Partially Observable Markov Decision Process\n(POMDP) and aim to develop a robust planner under a few-shot assumption. Thus,\nwe propose a closed-loop planner with an adaptation module and a novel\nhindsight method, aiming to use as much information as possible to assist the\nplanner. Our experiments on the ALFRED dataset indicate that our planner\nachieves competitive performance under a few-shot assumption. For the first\ntime, our few-shot agent's performance approaches and even surpasses that of\nthe full-shot supervised agent.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19562v1",
    "published_date": "2024-12-27 10:05:45 UTC",
    "updated_date": "2024-12-27 10:05:45 UTC"
  },
  {
    "arxiv_id": "2412.19550v1",
    "title": "Learning states enhanced knowledge tracing: Simulating the diversity in real-world learning process",
    "authors": [
      "Shanshan Wang",
      "Xueying Zhang",
      "Keyang Wang",
      "Xun Yang",
      "Xingyi Zhang"
    ],
    "abstract": "The Knowledge Tracing (KT) task focuses on predicting a learner's future\nperformance based on the historical interactions. The knowledge state plays a\nkey role in learning process. However, considering that the knowledge state is\ninfluenced by various learning factors in the interaction process, such as the\nexercises similarities, responses reliability and the learner's learning state.\nPrevious models still face two major limitations. First, due to the exercises\ndifferences caused by various complex reasons and the unreliability of\nresponses caused by guessing behavior, it is hard to locate the historical\ninteraction which is most relevant to the current answered exercise. Second,\nthe learning state is also a key factor to influence the knowledge state, which\nis always ignored by previous methods. To address these issues, we propose a\nnew method named Learning State Enhanced Knowledge Tracing (LSKT). Firstly, to\nsimulate the potential differences in interactions, inspired by Item Response\nTheory~(IRT) paradigm, we designed three different embedding methods ranging\nfrom coarse-grained to fine-grained views and conduct comparative analysis on\nthem. Secondly, we design a learning state extraction module to capture the\nchanging learning state during the learning process of the learner. In turn,\nwith the help of the extracted learning state, a more detailed knowledge state\ncould be captured. Experimental results on four real-world datasets show that\nour LSKT method outperforms the current state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19550v1",
    "published_date": "2024-12-27 09:41:25 UTC",
    "updated_date": "2024-12-27 09:41:25 UTC"
  },
  {
    "arxiv_id": "2412.19869v1",
    "title": "A Fully Hardware Implemented Accelerator Design in ReRAM Analog Computing without ADCs",
    "authors": [
      "Peng Dang",
      "Huawei Li",
      "Wei Wang"
    ],
    "abstract": "Emerging ReRAM-based accelerators process neural networks via analog\nComputing-in-Memory (CiM) for ultra-high energy efficiency. However,\nsignificant overhead in peripheral circuits and complex nonlinear activation\nmodes constrain system energy efficiency improvements. This work explores the\nhardware implementation of the Sigmoid and SoftMax activation functions of\nneural networks with stochastically binarized neurons by utilizing sampled\nnoise signals from ReRAM devices to achieve a stochastic effect. We propose a\ncomplete ReRAM-based Analog Computing Accelerator (RACA) that accelerates\nneural network computation by leveraging stochastically binarized neurons in\ncombination with ReRAM crossbars. The novel circuit design removes significant\nsources of energy/area efficiency degradation, i.e., the Digital-to-Analog and\nAnalog-to-Digital Converters (DACs and ADCs) as well as the components to\nexplicitly calculate the activation functions. Experimental results show that\nour proposed design outperforms traditional architectures across all overall\nperformance metrics without compromising inference accuracy.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19869v1",
    "published_date": "2024-12-27 09:38:19 UTC",
    "updated_date": "2024-12-27 09:38:19 UTC"
  },
  {
    "arxiv_id": "2412.19544v1",
    "title": "TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data",
    "authors": [
      "Xiang Huang",
      "Jiayu Shen",
      "Shanshan Huang",
      "Sitao Cheng",
      "Xiaxia Wang",
      "Yuzhong Qu"
    ],
    "abstract": "Semantic parsing, which converts natural language questions into logic forms,\nplays a crucial role in reasoning within structured environments. However,\nexisting methods encounter two significant challenges: reliance on extensive\nmanually annotated datasets and limited generalization capability to unseen\nexamples. To tackle these issues, we propose Targeted Synthetic Data Generation\n(TARGA), a practical framework that dynamically generates high-relevance\nsynthetic data without manual annotation. Starting from the pertinent entities\nand relations of a given question, we probe for the potential relevant queries\nthrough layer-wise expansion and cross-layer combination. Then we generate\ncorresponding natural language questions for these constructed queries to\njointly serve as the synthetic demonstrations for in-context learning.\nExperiments on multiple knowledge base question answering (KBQA) datasets\ndemonstrate that TARGA, using only a 7B-parameter model, substantially\noutperforms existing non-fine-tuned methods that utilize close-sourced model,\nachieving notable improvements in F1 scores on GrailQA(+7.7) and\nKBQA-Agent(+12.2). Furthermore, TARGA also exhibits superior sample efficiency,\nrobustness, and generalization capabilities under non-I.I.D. settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19544v1",
    "published_date": "2024-12-27 09:16:39 UTC",
    "updated_date": "2024-12-27 09:16:39 UTC"
  },
  {
    "arxiv_id": "2412.19542v2",
    "title": "Interacted Object Grounding in Spatio-Temporal Human-Object Interactions",
    "authors": [
      "Xiaoyang Liu",
      "Boran Wen",
      "Xinpeng Liu",
      "Zizheng Zhou",
      "Hongwei Fan",
      "Cewu Lu",
      "Lizhuang Ma",
      "Yulong Chen",
      "Yong-Lu Li"
    ],
    "abstract": "Spatio-temporal Human-Object Interaction (ST-HOI) understanding aims at\ndetecting HOIs from videos, which is crucial for activity understanding.\nHowever, existing whole-body-object interaction video benchmarks overlook the\ntruth that open-world objects are diverse, that is, they usually provide\nlimited and predefined object classes. Therefore, we introduce a new open-world\nbenchmark: Grounding Interacted Objects (GIO) including 1,098 interacted\nobjects class and 290K interacted object boxes annotation. Accordingly, an\nobject grounding task is proposed expecting vision systems to discover\ninteracted objects. Even though today's detectors and grounding methods have\nsucceeded greatly, they perform unsatisfactorily in localizing diverse and rare\nobjects in GIO. This profoundly reveals the limitations of current vision\nsystems and poses a great challenge. Thus, we explore leveraging\nspatio-temporal cues to address object grounding and propose a 4D\nquestion-answering framework (4D-QA) to discover interacted objects from\ndiverse videos. Our method demonstrates significant superiority in extensive\nexperiments compared to current baselines. Data and code will be publicly\navailable at https://github.com/DirtyHarryLYL/HAKE-AVA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in the Proceedings of AAAI 2025. The first three\n  authors contributed equally. Project:\n  https://github.com/DirtyHarryLYL/HAKE-AVA",
    "pdf_url": "http://arxiv.org/pdf/2412.19542v2",
    "published_date": "2024-12-27 09:08:46 UTC",
    "updated_date": "2025-02-23 10:03:47 UTC"
  },
  {
    "arxiv_id": "2412.19538v1",
    "title": "Scalable Hierarchical Reinforcement Learning for Hyper Scale Multi-Robot Task Planning",
    "authors": [
      "Xuan Zhou",
      "Xiang Shi",
      "Lele Zhang",
      "Chen Chen",
      "Hongbo Li",
      "Lin Ma",
      "Fang Deng",
      "Jie Chen"
    ],
    "abstract": "To improve the efficiency of warehousing system and meet huge customer\norders, we aim to solve the challenges of dimension disaster and dynamic\nproperties in hyper scale multi-robot task planning (MRTP) for robotic mobile\nfulfillment system (RMFS). Existing research indicates that hierarchical\nreinforcement learning (HRL) is an effective method to reduce these challenges.\nBased on that, we construct an efficient multi-stage HRL-based multi-robot task\nplanner for hyper scale MRTP in RMFS, and the planning process is represented\nwith a special temporal graph topology. To ensure optimality, the planner is\ndesigned with a centralized architecture, but it also brings the challenges of\nscaling up and generalization that require policies to maintain performance for\nvarious unlearned scales and maps. To tackle these difficulties, we first\nconstruct a hierarchical temporal attention network (HTAN) to ensure basic\nability of handling inputs with unfixed lengths, and then design multi-stage\ncurricula for hierarchical policy learning to further improve the scaling up\nand generalization ability while avoiding catastrophic forgetting.\nAdditionally, we notice that policies with hierarchical structure suffer from\nunfair credit assignment that is similar to that in multi-agent reinforcement\nlearning, inspired of which, we propose a hierarchical reinforcement learning\nalgorithm with counterfactual rollout baseline to improve learning performance.\nExperimental results demonstrate that our planner outperform other\nstate-of-the-art methods on various MRTP instances in both simulated and\nreal-world RMFS. Also, our planner can successfully scale up to hyper scale\nMRTP instances in RMFS with up to 200 robots and 1000 retrieval racks on\nunlearned maps while keeping superior performance over other methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19538v1",
    "published_date": "2024-12-27 09:07:11 UTC",
    "updated_date": "2024-12-27 09:07:11 UTC"
  },
  {
    "arxiv_id": "2412.19867v2",
    "title": "Data-Free Group-Wise Fully Quantized Winograd Convolution via Learnable Scales",
    "authors": [
      "Shuokai Pan",
      "Gerti Tuzi",
      "Sudarshan Sreeram",
      "Dibakar Gope"
    ],
    "abstract": "Despite the revolutionary breakthroughs of large-scale text-to-image\ndiffusion models for complex vision and downstream tasks, their extremely high\ncomputational and storage costs limit their usability. Quantization of\ndiffusion models has been explored in recent works to reduce compute costs and\nmemory bandwidth usage. To further improve inference time, fast convolution\nalgorithms such as Winograd can be used for convolution layers, which account\nfor a significant portion of computations in diffusion models. However, the\nsignificant quality loss of fully quantized Winograd using existing\ncoarser-grained post-training quantization methods, combined with the\ncomplexity and cost of finetuning the Winograd transformation matrices for such\nlarge models to recover quality, makes them unsuitable for large-scale\nfoundation models. Motivated by the presence of a large range of values in\nthem, we investigate the impact of finer-grained group-wise quantization in\nquantizing diffusion models. While group-wise quantization can largely handle\nthe fully quantized Winograd convolution, it struggles to deal with the large\ndistribution imbalance in a sizable portion of the Winograd domain computation.\nTo reduce range differences in the Winograd domain, we propose finetuning only\nthe scale parameters of the Winograd transform matrices without using any\ndomain-specific training data. Because our method does not depend on any\ntraining data, the generalization performance of quantized diffusion models is\nsafely guaranteed. For text-to-image generation task, the 8-bit fully-quantized\ndiffusion model with Winograd provides near-lossless quality (FID and CLIP\nscores) in comparison to the full-precision model. For image classification,\nour method outperforms the state-of-the-art Winograd PTQ method by 1.62% and\n2.56% in top-1 ImageNet accuracy on ResNet18 and ResNet-34, respectively, with\nWinograd F(6, 3).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19867v2",
    "published_date": "2024-12-27 09:05:48 UTC",
    "updated_date": "2025-04-01 03:31:42 UTC"
  },
  {
    "arxiv_id": "2412.19533v2",
    "title": "P3S-Diffusion:A Selective Subject-driven Generation Framework via Point Supervision",
    "authors": [
      "Junjie Hu",
      "Shuyong Gao",
      "Lingyi Hong",
      "Qishan Wang",
      "Yuzhou Zhao",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Recent research in subject-driven generation increasingly emphasizes the\nimportance of selective subject features. Nevertheless, accurately selecting\nthe content in a given reference image still poses challenges, especially when\nselecting the similar subjects in an image (e.g., two different dogs). Some\nmethods attempt to use text prompts or pixel masks to isolate specific\nelements. However, text prompts often fall short in precisely describing\nspecific content, and pixel masks are often expensive. To address this, we\nintroduce P3S-Diffusion, a novel architecture designed for context-selected\nsubject-driven generation via point supervision. P3S-Diffusion leverages\nminimal cost label (e.g., points) to generate subject-driven images. During\nfine-tuning, it can generate an expanded base mask from these points, obviating\nthe need for additional segmentation models. The mask is employed for\ninpainting and aligning with subject representation. The P3S-Diffusion\npreserves fine features of the subjects through Multi-layers Condition\nInjection. Enhanced by the Attention Consistency Loss for improved training,\nextensive experiments demonstrate its excellent feature preservation and image\ngeneration capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19533v2",
    "published_date": "2024-12-27 08:59:01 UTC",
    "updated_date": "2025-01-06 04:50:36 UTC"
  },
  {
    "arxiv_id": "2412.19531v1",
    "title": "Is Your Text-to-Image Model Robust to Caption Noise?",
    "authors": [
      "Weichen Yu",
      "Ziyan Yang",
      "Shanchuan Lin",
      "Qi Zhao",
      "Jianyi Wang",
      "Liangke Gui",
      "Matt Fredrikson",
      "Lu Jiang"
    ],
    "abstract": "In text-to-image (T2I) generation, a prevalent training technique involves\nutilizing Vision Language Models (VLMs) for image re-captioning. Even though\nVLMs are known to exhibit hallucination, generating descriptive content that\ndeviates from the visual reality, the ramifications of such caption\nhallucinations on T2I generation performance remain under-explored. Through our\nempirical investigation, we first establish a comprehensive dataset comprising\nVLM-generated captions, and then systematically analyze how caption\nhallucination influences generation outcomes. Our findings reveal that (1) the\ndisparities in caption quality persistently impact model outputs during\nfine-tuning. (2) VLMs confidence scores serve as reliable indicators for\ndetecting and characterizing noise-related patterns in the data distribution.\n(3) even subtle variations in caption fidelity have significant effects on the\nquality of learned representations. These findings collectively emphasize the\nprofound impact of caption quality on model performance and highlight the need\nfor more sophisticated robust training algorithm in T2I. In response to these\nobservations, we propose a approach leveraging VLM confidence score to mitigate\ncaption noise, thereby enhancing the robustness of T2I models against\nhallucination in caption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19531v1",
    "published_date": "2024-12-27 08:53:37 UTC",
    "updated_date": "2024-12-27 08:53:37 UTC"
  },
  {
    "arxiv_id": "2412.19524v1",
    "title": "PLN and NARS Often Yield Similar strength $\\times$ confidence Given Highly Uncertain Term Probabilities",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "We provide a comparative analysis of the deduction, induction, and abduction\nformulas used in Probabilistic Logic Networks (PLN) and the Non-Axiomatic\nReasoning System (NARS), two uncertain reasoning frameworks aimed at AGI. One\ndifference between the two systems is that, at the level of individual\ninference rules, PLN directly leverages both term and relationship\nprobabilities, whereas NARS only leverages relationship frequencies and has no\nsimple analogue of term probabilities. Thus we focus here on scenarios where\nthere is high uncertainty about term probabilities, and explore how this\nuncertainty influences the comparative inferential conclusions of the two\nsystems. We compare the product of strength and confidence ($s\\times c$) in PLN\nagainst the product of frequency and confidence ($f\\times c$) in NARS\n(quantities we refer to as measuring the \"power\" of an uncertain statement) in\ncases of high term probability uncertainty, using heuristic analyses and\nelementary numerical computations. We find that in many practical situations\nwith high term probability uncertainty, PLN and NARS formulas give very similar\nresults for the power of an inference conclusion, even though they sometimes\ncome to these similar numbers in quite different ways.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19524v1",
    "published_date": "2024-12-27 08:31:19 UTC",
    "updated_date": "2024-12-27 08:31:19 UTC"
  },
  {
    "arxiv_id": "2412.19523v1",
    "title": "Attribution for Enhanced Explanation with Transferable Adversarial eXploration",
    "authors": [
      "Zhiyu Zhu",
      "Jiayu Zhang",
      "Zhibo Jin",
      "Huaming Chen",
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "abstract": "The interpretability of deep neural networks is crucial for understanding\nmodel decisions in various applications, including computer vision.\nAttEXplore++, an advanced framework built upon AttEXplore, enhances attribution\nby incorporating transferable adversarial attack methods such as MIG and GRA,\nsignificantly improving the accuracy and robustness of model explanations. We\nconduct extensive experiments on five models, including CNNs (Inception-v3,\nResNet-50, VGG16) and vision transformers (MaxViT-T, ViT-B/16), using the\nImageNet dataset. Our method achieves an average performance improvement of\n7.57\\% over AttEXplore and 32.62\\% compared to other state-of-the-art\ninterpretability algorithms. Using insertion and deletion scores as evaluation\nmetrics, we show that adversarial transferability plays a vital role in\nenhancing attribution results. Furthermore, we explore the impact of\nrandomness, perturbation rate, noise amplitude, and diversity probability on\nattribution performance, demonstrating that AttEXplore++ provides more stable\nand reliable explanations across various models. We release our code at:\nhttps://anonymous.4open.science/r/ATTEXPLOREP-8435/",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19523v1",
    "published_date": "2024-12-27 08:27:53 UTC",
    "updated_date": "2024-12-27 08:27:53 UTC"
  },
  {
    "arxiv_id": "2412.19517v1",
    "title": "Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model",
    "authors": [
      "Hyunwoo Cho",
      "Sung Woong Cho",
      "Hyeontae Jo",
      "Hyung Ju Hwang"
    ],
    "abstract": "Differential equations (DEs) are crucial for modeling the evolution of\nnatural or engineered systems. Traditionally, the parameters in DEs are\nadjusted to fit data from system observations. However, in fields such as\npolitics, economics, and biology, available data are often independently\ncollected at distinct time points from different subjects (i.e., repeated\ncross-sectional (RCS) data). Conventional optimization techniques struggle to\naccurately estimate DE parameters when RCS data exhibit various\nheterogeneities, leading to a significant loss of information. To address this\nissue, we propose a new estimation method called the emulator-informed\ndeep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM\nintegrates a physics-informed neural network-based emulator that immediately\ngenerates DE solutions and a Wasserstein generative adversarial network-based\nparameter generator that can effectively mimic the RCS data. We evaluated EIDGM\non exponential growth, logistic population models, and the Lorenz system,\ndemonstrating its superior ability to accurately capture parameter\ndistributions. Additionally, we applied EIDGM to an experimental dataset of\nAmyloid beta 40 and beta 42, successfully capturing diverse parameter\ndistribution shapes. This shows that EIDGM can be applied to model a wide range\nof systems and extended to uncover the operating principles of systems based on\nlimited data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "q-bio.PE",
      "stat.ML",
      "62F30, 65Z05, 68T09",
      "G.1.7; I.2.m; J.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19517v1",
    "published_date": "2024-12-27 08:19:23 UTC",
    "updated_date": "2024-12-27 08:19:23 UTC"
  },
  {
    "arxiv_id": "2412.19509v2",
    "title": "MBQ: Modality-Balanced Quantization for Large Vision-Language Models",
    "authors": [
      "Shiyao Li",
      "Yingchun Hu",
      "Xuefei Ning",
      "Xihui Liu",
      "Ke Hong",
      "Xiaotao Jia",
      "Xiuhong Li",
      "Yaqi Yan",
      "Pei Ran",
      "Guohao Dai",
      "Shengen Yan",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "abstract": "Vision-Language Models (VLMs) have enabled a variety of real-world\napplications. The large parameter size of VLMs brings large memory and\ncomputation overhead which poses significant challenges for deployment.\nPost-Training Quantization (PTQ) is an effective technique to reduce the memory\nand computation overhead. Existing PTQ methods mainly focus on large language\nmodels (LLMs), without considering the differences across other modalities. In\nthis paper, we discover that there is a significant difference in sensitivity\nbetween language and vision tokens in large VLMs. Therefore, treating tokens\nfrom different modalities equally, as in existing PTQ methods, may\nover-emphasize the insensitive modalities, leading to significant accuracy\nloss. To deal with the above issue, we propose a simple yet effective method,\nModality-Balanced Quantization (MBQ), for large VLMs. Specifically, MBQ\nincorporates the different sensitivities across modalities during the\ncalibration process to minimize the reconstruction loss for better quantization\nparameters. Extensive experiments show that MBQ can significantly improve task\naccuracy by up to 4.4% and 11.6% under W3 and W4A8 quantization for 7B to 70B\nVLMs, compared to SOTA baselines. Additionally, we implement a W3 GPU kernel\nthat fuses the dequantization and GEMV operators, achieving a 1.4x speedup on\nLLaVA-onevision-7B on the RTX 4090. The code is available at\nhttps://github.com/thu-nics/MBQ.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19509v2",
    "published_date": "2024-12-27 07:55:36 UTC",
    "updated_date": "2025-03-21 06:01:23 UTC"
  },
  {
    "arxiv_id": "2412.19507v2",
    "title": "Hybrid Local Causal Discovery",
    "authors": [
      "Zhaolong Ling",
      "Honghui Peng",
      "Yiwen Zhang",
      "Debo Cheng",
      "Xingyu Wu",
      "Peng Zhou",
      "Kui Yu"
    ],
    "abstract": "Local causal discovery aims to learn and distinguish the direct causes and\neffects of a target variable from observed data. Existing constraint-based\nlocal causal discovery methods use AND or OR rules in constructing the local\ncausal skeleton, but using either rule alone is prone to produce cascading\nerrors in the learned local causal skeleton, and thus impacting the inference\nof local causal relationships. On the other hand, directly applying score-based\nglobal causal discovery methods to local causal discovery may randomly return\nincorrect results due to the existence of local equivalence classes. To address\nthe above issues, we propose a Hybrid Local Causal Discovery algorithm, called\nHLCD. Specifically, HLCD initially utilizes a constraint-based approach\ncombined with the OR rule to obtain a candidate skeleton and then employs a\nscore-based method to eliminate redundant portions in the candidate skeleton.\nFurthermore, during the local causal orientation phase, HLCD distinguishes\nbetween V-structures and equivalence classes by comparing the local structure\nscores between the two, thereby avoiding orientation interference caused by\nlocal equivalence classes. We conducted extensive experiments with seven\nstate-of-the-art competitors on 14 benchmark Bayesian network datasets, and the\nexperimental results demonstrate that HLCD significantly outperforms existing\nlocal causal discovery algorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted for publication in the Proceedings of\n  the 34th International Joint Conference on Artificial Intelligence (IJCAI\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.19507v2",
    "published_date": "2024-12-27 07:53:59 UTC",
    "updated_date": "2025-05-12 15:18:30 UTC"
  },
  {
    "arxiv_id": "2412.19496v2",
    "title": "Multi-P$^2$A: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models",
    "authors": [
      "Jie Zhang",
      "Xiangkui Cao",
      "Zhouyu Han",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive potential across\nvarious tasks but also face significant privacy risks, limiting their practical\napplications. Current researches on privacy assessment for LVLMs is limited in\nscope, with gaps in both assessment dimensions and privacy categories. To\nbridge this gap, we propose Multi-P$^2$A, a comprehensive benchmark for\nevaluating the privacy preservation capabilities of LVLMs in terms of privacy\nawareness and leakage. Privacy awareness measures the model's ability to\nrecognize the privacy sensitivity of input data, while privacy leakage assesses\nthe risk of the model unintentionally disclosing privacy information in its\noutput. We design a range of sub-tasks to thoroughly evaluate the model's\nprivacy protection offered by LVLMs. Multi-P$^2$A covers 26 categories of\npersonal privacy, 15 categories of trade secrets, and 18 categories of state\nsecrets, totaling 31,962 samples. Based on Multi-P$^2$A, we evaluate the\nprivacy preservation capabilities of 21 open-source and 2 closed-source LVLMs.\nOur results reveal that current LVLMs generally pose a high risk of\nfacilitating privacy breaches, with vulnerabilities varying across personal\nprivacy, trade secret, and state secret.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19496v2",
    "published_date": "2024-12-27 07:33:39 UTC",
    "updated_date": "2025-03-11 04:32:32 UTC"
  },
  {
    "arxiv_id": "2412.19495v2",
    "title": "Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases",
    "authors": [
      "Ioannis Bilionis",
      "Ricardo C. Berrios",
      "Luis Fernandez-Luque",
      "Carlos Castillo"
    ],
    "abstract": "Machine Learning (ML) algorithms are vital for supporting clinical\ndecision-making in biomedical informatics. However, their predictive\nperformance can vary across demographic groups, often due to the\nunderrepresentation of historically marginalized populations in training\ndatasets. The investigation reveals widespread sex- and age-related inequities\nin chronic disease datasets and their derived ML models. Thus, a novel\nanalytical framework is introduced, combining systematic arbitrariness with\ntraditional metrics like accuracy and data complexity. The analysis of data\nfrom over 25,000 individuals with chronic diseases revealed mild sex-related\ndisparities, favoring predictive accuracy for males, and significant\nage-related differences, with better accuracy for younger patients. Notably,\nolder patients showed inconsistent predictive accuracy across seven datasets,\nlinked to higher data complexity and lower model performance. This highlights\nthat representativeness in training data alone does not guarantee equitable\noutcomes, and model arbitrariness must be addressed before deploying models in\nclinical settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper will be presented in American Medical Informatics\n  Association (AMIA) Informatics Summit Conference 2025 (Pittsburgh, PA). 10\n  pages, 2 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19495v2",
    "published_date": "2024-12-27 07:31:14 UTC",
    "updated_date": "2025-03-03 16:05:29 UTC"
  },
  {
    "arxiv_id": "2412.19467v1",
    "title": "Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis",
    "authors": [
      "Vaikunth M",
      "Dejey D",
      "Vishaal C",
      "Balamurali S"
    ],
    "abstract": "Helmet detection is crucial for advancing protection levels in public road\ntraffic dynamics. This problem statement translates to an object detection\ntask. Therefore, this paper compares recent You Only Look Once (YOLO) models in\nthe context of helmet detection in terms of reliability and computational load.\nSpecifically, YOLOv8, YOLOv9, and the newly released YOLOv11 have been used.\nBesides, a modified architectural pipeline that remarkably improves the overall\nperformance has been proposed in this manuscript. This hybridized YOLO model\n(h-YOLO) has been pitted against the independent models for analysis that\nproves h-YOLO is preferable for helmet detection over plain YOLO models. The\nmodels were tested using a range of standard object detection benchmarks such\nas recall, precision, and mAP (Mean Average Precision). In addition, training\nand testing times were recorded to provide the overall scope of the models in a\nreal-time detection scenario.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19467v1",
    "published_date": "2024-12-27 05:26:12 UTC",
    "updated_date": "2024-12-27 05:26:12 UTC"
  },
  {
    "arxiv_id": "2412.19450v2",
    "title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models",
    "authors": [
      "Hyeonseok Moon",
      "Jaehyung Seo",
      "Seungyoon Lee",
      "Chanjun Park",
      "Heuiseok Lim"
    ],
    "abstract": "One of the key strengths of Large Language Models (LLMs) is their ability to\ninteract with humans by generating appropriate responses to given instructions.\nThis ability, known as instruction-following capability, has established a\nfoundation for the use of LLMs across various fields and serves as a crucial\nmetric for evaluating their performance. While numerous evaluation benchmarks\nhave been developed, most focus solely on clear and coherent instructions.\nHowever, we have noted that LLMs can become easily distracted by\ninstruction-formatted statements, which may lead to an oversight of their\ninstruction comprehension skills. To address this issue, we introduce the\nIntention of Instruction (IoInst) benchmark. This benchmark evaluates LLMs'\ncapacity to remain focused and understand instructions without being misled by\nextraneous instructions. The primary objective of this benchmark is to identify\nthe appropriate instruction that accurately guides the generation of a given\ncontext. Our findings suggest that even recently introduced state-of-the-art\nmodels still lack instruction understanding capability. Along with the\nproposition of IoInst in this study, we also present broad analyses of the\nseveral strategies potentially applicable to IoInst.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "NAACL25-Findings",
    "pdf_url": "http://arxiv.org/pdf/2412.19450v2",
    "published_date": "2024-12-27 04:37:39 UTC",
    "updated_date": "2025-01-23 00:45:55 UTC"
  },
  {
    "arxiv_id": "2412.19442v2",
    "title": "A Survey on Large Language Model Acceleration based on KV Cache Management",
    "authors": [
      "Haoyang Li",
      "Yiming Li",
      "Anxin Tian",
      "Tianhao Tang",
      "Zhanchao Xu",
      "Xuejia Chen",
      "Nicole Hu",
      "Wei Dong",
      "Qing Li",
      "Lei Chen"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized a wide range of domains such\nas natural language processing, computer vision, and multi-modal tasks due to\ntheir ability to comprehend context and perform logical reasoning. However, the\ncomputational and memory demands of LLMs, particularly during inference, pose\nsignificant challenges when scaling them to real-world, long-context, and\nreal-time applications. Key-Value (KV) cache management has emerged as a\ncritical optimization technique for accelerating LLM inference by reducing\nredundant computations and improving memory utilization. This survey provides a\ncomprehensive overview of KV cache management strategies for LLM acceleration,\ncategorizing them into token-level, model-level, and system-level\noptimizations. Token-level strategies include KV cache selection, budget\nallocation, merging, quantization, and low-rank decomposition, while\nmodel-level optimizations focus on architectural innovations and attention\nmechanisms to enhance KV reuse. System-level approaches address memory\nmanagement, scheduling, and hardware-aware designs to improve efficiency across\ndiverse computing environments. Additionally, the survey provides an overview\nof both text and multimodal datasets and benchmarks used to evaluate these\nstrategies. By presenting detailed taxonomies and comparative analyses, this\nwork aims to offer useful insights for researchers and practitioners to support\nthe development of efficient and scalable KV cache management techniques,\ncontributing to the practical deployment of LLMs in real-world applications.\nThe curated paper list for KV cache management is in:\n\\href{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19442v2",
    "published_date": "2024-12-27 04:17:57 UTC",
    "updated_date": "2025-01-02 03:40:15 UTC"
  },
  {
    "arxiv_id": "2412.19437v2",
    "title": "DeepSeek-V3 Technical Report",
    "authors": [
      "DeepSeek-AI",
      "Aixin Liu",
      "Bei Feng",
      "Bing Xue",
      "Bingxuan Wang",
      "Bochao Wu",
      "Chengda Lu",
      "Chenggang Zhao",
      "Chengqi Deng",
      "Chenyu Zhang",
      "Chong Ruan",
      "Damai Dai",
      "Daya Guo",
      "Dejian Yang",
      "Deli Chen",
      "Dongjie Ji",
      "Erhang Li",
      "Fangyun Lin",
      "Fucong Dai",
      "Fuli Luo",
      "Guangbo Hao",
      "Guanting Chen",
      "Guowei Li",
      "H. Zhang",
      "Han Bao",
      "Hanwei Xu",
      "Haocheng Wang",
      "Haowei Zhang",
      "Honghui Ding",
      "Huajian Xin",
      "Huazuo Gao",
      "Hui Li",
      "Hui Qu",
      "J. L. Cai",
      "Jian Liang",
      "Jianzhong Guo",
      "Jiaqi Ni",
      "Jiashi Li",
      "Jiawei Wang",
      "Jin Chen",
      "Jingchang Chen",
      "Jingyang Yuan",
      "Junjie Qiu",
      "Junlong Li",
      "Junxiao Song",
      "Kai Dong",
      "Kai Hu",
      "Kaige Gao",
      "Kang Guan",
      "Kexin Huang",
      "Kuai Yu",
      "Lean Wang",
      "Lecong Zhang",
      "Lei Xu",
      "Leyi Xia",
      "Liang Zhao",
      "Litong Wang",
      "Liyue Zhang",
      "Meng Li",
      "Miaojun Wang",
      "Mingchuan Zhang",
      "Minghua Zhang",
      "Minghui Tang",
      "Mingming Li",
      "Ning Tian",
      "Panpan Huang",
      "Peiyi Wang",
      "Peng Zhang",
      "Qiancheng Wang",
      "Qihao Zhu",
      "Qinyu Chen",
      "Qiushi Du",
      "R. J. Chen",
      "R. L. Jin",
      "Ruiqi Ge",
      "Ruisong Zhang",
      "Ruizhe Pan",
      "Runji Wang",
      "Runxin Xu",
      "Ruoyu Zhang",
      "Ruyi Chen",
      "S. S. Li",
      "Shanghao Lu",
      "Shangyan Zhou",
      "Shanhuang Chen",
      "Shaoqing Wu",
      "Shengfeng Ye",
      "Shengfeng Ye",
      "Shirong Ma",
      "Shiyu Wang",
      "Shuang Zhou",
      "Shuiping Yu",
      "Shunfeng Zhou",
      "Shuting Pan",
      "T. Wang",
      "Tao Yun",
      "Tian Pei",
      "Tianyu Sun",
      "W. L. Xiao",
      "Wangding Zeng",
      "Wanjia Zhao",
      "Wei An",
      "Wen Liu",
      "Wenfeng Liang",
      "Wenjun Gao",
      "Wenqin Yu",
      "Wentao Zhang",
      "X. Q. Li",
      "Xiangyue Jin",
      "Xianzu Wang",
      "Xiao Bi",
      "Xiaodong Liu",
      "Xiaohan Wang",
      "Xiaojin Shen",
      "Xiaokang Chen",
      "Xiaokang Zhang",
      "Xiaosha Chen",
      "Xiaotao Nie",
      "Xiaowen Sun",
      "Xiaoxiang Wang",
      "Xin Cheng",
      "Xin Liu",
      "Xin Xie",
      "Xingchao Liu",
      "Xingkai Yu",
      "Xinnan Song",
      "Xinxia Shan",
      "Xinyi Zhou",
      "Xinyu Yang",
      "Xinyuan Li",
      "Xuecheng Su",
      "Xuheng Lin",
      "Y. K. Li",
      "Y. Q. Wang",
      "Y. X. Wei",
      "Y. X. Zhu",
      "Yang Zhang",
      "Yanhong Xu",
      "Yanhong Xu",
      "Yanping Huang",
      "Yao Li",
      "Yao Zhao",
      "Yaofeng Sun",
      "Yaohui Li",
      "Yaohui Wang",
      "Yi Yu",
      "Yi Zheng",
      "Yichao Zhang",
      "Yifan Shi",
      "Yiliang Xiong",
      "Ying He",
      "Ying Tang",
      "Yishi Piao",
      "Yisong Wang",
      "Yixuan Tan",
      "Yiyang Ma",
      "Yiyuan Liu",
      "Yongqiang Guo",
      "Yu Wu",
      "Yuan Ou",
      "Yuchen Zhu",
      "Yuduan Wang",
      "Yue Gong",
      "Yuheng Zou",
      "Yujia He",
      "Yukun Zha",
      "Yunfan Xiong",
      "Yunxian Ma",
      "Yuting Yan",
      "Yuxiang Luo",
      "Yuxiang You",
      "Yuxuan Liu",
      "Yuyang Zhou",
      "Z. F. Wu",
      "Z. Z. Ren",
      "Zehui Ren",
      "Zhangli Sha",
      "Zhe Fu",
      "Zhean Xu",
      "Zhen Huang",
      "Zhen Zhang",
      "Zhenda Xie",
      "Zhengyan Zhang",
      "Zhewen Hao",
      "Zhibin Gou",
      "Zhicheng Ma",
      "Zhigang Yan",
      "Zhihong Shao",
      "Zhipeng Xu",
      "Zhiyu Wu",
      "Zhongyu Zhang",
      "Zhuoshu Li",
      "Zihui Gu",
      "Zijia Zhu",
      "Zijun Liu",
      "Zilin Li",
      "Ziwei Xie",
      "Ziyang Song",
      "Ziyi Gao",
      "Zizheng Pan"
    ],
    "abstract": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with\n671B total parameters with 37B activated for each token. To achieve efficient\ninference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent\nAttention (MLA) and DeepSeekMoE architectures, which were thoroughly validated\nin DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free\nstrategy for load balancing and sets a multi-token prediction training\nobjective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion\ndiverse and high-quality tokens, followed by Supervised Fine-Tuning and\nReinforcement Learning stages to fully harness its capabilities. Comprehensive\nevaluations reveal that DeepSeek-V3 outperforms other open-source models and\nachieves performance comparable to leading closed-source models. Despite its\nexcellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its\nfull training. In addition, its training process is remarkably stable.\nThroughout the entire training process, we did not experience any irrecoverable\nloss spikes or perform any rollbacks. The model checkpoints are available at\nhttps://github.com/deepseek-ai/DeepSeek-V3.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19437v2",
    "published_date": "2024-12-27 04:03:16 UTC",
    "updated_date": "2025-02-18 17:26:38 UTC"
  },
  {
    "arxiv_id": "2412.19433v1",
    "title": "Residual Feature-Reutilization Inception Network for Image Classification",
    "authors": [
      "Yuanpeng He",
      "Wenjie Song",
      "Lijian Li",
      "Tianxiang Zhan",
      "Wenpin Jiao"
    ],
    "abstract": "Capturing feature information effectively is of great importance in the field\nof computer vision. With the development of convolutional neural networks\n(CNNs), concepts like residual connection and multiple scales promote continual\nperformance gains in diverse deep learning vision tasks. In this paper, we\npropose a novel CNN architecture that it consists of residual\nfeature-reutilization inceptions (ResFRI) or split-residual\nfeature-reutilization inceptions (Split-ResFRI). And it is composed of four\nconvolutional combinations of different structures connected by specially\ndesigned information interaction passages, which are utilized to extract\nmulti-scale feature information and effectively increase the receptive field of\nthe model. Moreover, according to the network structure designed above,\nSplit-ResFRI can adjust the segmentation ratio of the input information,\nthereby reducing the number of parameters and guaranteeing the model\nperformance. Specifically, in experiments based on popular vision datasets,\nsuch as CIFAR10 ($97.94$\\%), CIFAR100 ($85.91$\\%) and Tiny Imagenet\n($70.54$\\%), we obtain state-of-the-art results compared with other modern\nmodels under the premise that the model size is approximate and no additional\ndata is used.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2301.00424",
    "pdf_url": "http://arxiv.org/pdf/2412.19433v1",
    "published_date": "2024-12-27 03:55:25 UTC",
    "updated_date": "2024-12-27 03:55:25 UTC"
  },
  {
    "arxiv_id": "2412.19425v1",
    "title": "A Self-Efficacy Theory-based Study on the Teachers Readiness to Teach Artificial Intelligence in Public Schools in Sri Lanka",
    "authors": [
      "Chathura Rajapakse",
      "Wathsala Ariyarathna",
      "Shanmugalingam Selvakan"
    ],
    "abstract": "This study investigates Sri Lankan ICT teachers' readiness to teach AI in\nschools, focusing on self-efficacy. A survey of over 1,300 teachers assessed\ntheir self-efficacy using a scale developed based on Bandura's theory. PLS-SEM\nanalysis revealed that teachers' self-efficacy was low, primarily influenced by\nemotional and physiological states and imaginary experiences related to AI\ninstruction. Mastery experiences had a lesser impact, and vicarious experiences\nand verbal persuasion showed no significant effect. The study highlights the\nneed for a systemic approach to teacher professional development, considering\nthe limitations in teachers' AI expertise and social capital. Further research\nis recommended to explore a socio-technical systems perspective for effective\nAI teacher training.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19425v1",
    "published_date": "2024-12-27 03:31:26 UTC",
    "updated_date": "2024-12-27 03:31:26 UTC"
  },
  {
    "arxiv_id": "2412.19423v1",
    "title": "Revisiting PCA for time series reduction in temporal dimension",
    "authors": [
      "Jiaxin Gao",
      "Wenbo Hu",
      "Yuntian Chen"
    ],
    "abstract": "Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao,\nWenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series\nanalysis (TSA), enabling the extraction of complex patterns for tasks like\nclassification, forecasting, and regression. Although dimensionality reduction\nhas traditionally focused on the variable space-achieving notable success in\nminimizing data redundancy and computational complexity-less attention has been\npaid to reducing the temporal dimension. In this study, we revisit Principal\nComponent Analysis (PCA), a classical dimensionality reduction technique, to\nexplore its utility in temporal dimension reduction for time series data. It is\ngenerally thought that applying PCA to the temporal dimension would disrupt\ntemporal dependencies, leading to limited exploration in this area. However,\nour theoretical analysis and extensive experiments demonstrate that applying\nPCA to sliding series windows not only maintains model performance, but also\nenhances computational efficiency. In auto-regressive forecasting, the temporal\nstructure is partially preserved through windowing, and PCA is applied within\nthese windows to denoise the time series while retaining their statistical\ninformation. By preprocessing time-series data with PCA, we reduce the temporal\ndimensionality before feeding it into TSA models such as Linear, Transformer,\nCNN, and RNN architectures. This approach accelerates training and inference\nand reduces resource consumption. Notably, PCA improves Informer training and\ninference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%,\nwithout sacrificing model accuracy. Comparative analysis against other\nreduction methods further highlights the effectiveness of PCA in improving the\nefficiency of TSA models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 5 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19423v1",
    "published_date": "2024-12-27 03:17:26 UTC",
    "updated_date": "2024-12-27 03:17:26 UTC"
  },
  {
    "arxiv_id": "2412.19422v2",
    "title": "De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning",
    "authors": [
      "Chen Li",
      "Yoshihiro Yamanishi"
    ],
    "abstract": "De novo generation of hit-like molecules is a challenging task in the drug\ndiscovery process. Most methods in previous studies learn the semantics and\nsyntax of molecular structures by analyzing molecular graphs or simplified\nmolecular input line entry system (SMILES) strings; however, they do not take\ninto account the drug responses of the biological systems consisting of genes\nand proteins. In this study we propose a hybrid neural network, HNN2Mol, which\nutilizes gene expression profiles to generate molecular structures with\ndesirable phenotypes for arbitrary target proteins. In the algorithm, a\nvariational autoencoder is employed as a feature extractor to learn the latent\nfeature distribution of the gene expression profiles. Then, a long short-term\nmemory is leveraged as the chemical generator to produce syntactically valid\nSMILES strings that satisfy the feature conditions of the gene expression\nprofile extracted by the feature extractor. Experimental results and case\nstudies demonstrate that the proposed HNN2Mol model can produce new molecules\nwith potential bioactivities and drug-like properties.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19422v2",
    "published_date": "2024-12-27 03:16:56 UTC",
    "updated_date": "2025-04-17 08:28:21 UTC"
  },
  {
    "arxiv_id": "2412.19419v1",
    "title": "Introduction to Graph Neural Networks: A Starting Point for Machine Learning Engineers",
    "authors": [
      "James H. Tanis",
      "Chris Giannella",
      "Adrian V. Mariano"
    ],
    "abstract": "Graph neural networks are deep neural networks designed for graphs with\nattributes attached to nodes or edges. The number of research papers in the\nliterature concerning these models is growing rapidly due to their impressive\nperformance on a broad range of tasks. This survey introduces graph neural\nnetworks through the encoder-decoder framework and provides examples of\ndecoders for a range of graph analytic tasks. It uses theory and numerous\nexperiments on homogeneous graphs to illustrate the behavior of graph neural\nnetworks for different training sizes and degrees of graph complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "E.1; I.2.4; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19419v1",
    "published_date": "2024-12-27 03:13:02 UTC",
    "updated_date": "2024-12-27 03:13:02 UTC"
  },
  {
    "arxiv_id": "2412.19418v1",
    "title": "Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head Attention for Weak-Supervised Temporal Action Localization",
    "authors": [
      "Yuanpeng He",
      "Lijian Li",
      "Tianxiang Zhan",
      "Wenpin Jiao",
      "Chi-Man Pun"
    ],
    "abstract": "Weakly supervised temporal action localization (WS-TAL) is a task of\ntargeting at localizing complete action instances and categorizing them with\nvideo-level labels. Action-background ambiguity, primarily caused by background\nnoise resulting from aggregation and intra-action variation, is a significant\nchallenge for existing WS-TAL methods. In this paper, we introduce a hybrid\nmulti-head attention (HMHA) module and generalized uncertainty-based evidential\nfusion (GUEF) module to address the problem. The proposed HMHA effectively\nenhances RGB and optical flow features by filtering redundant information and\nadjusting their feature distribution to better align with the WS-TAL task.\nAdditionally, the proposed GUEF adaptively eliminates the interference of\nbackground noise by fusing snippet-level evidences to refine uncertainty\nmeasurement and select superior foreground feature information, which enables\nthe model to concentrate on integral action instances to achieve better action\nlocalization and classification performance. Experimental results conducted on\nthe THUMOS14 dataset demonstrate that our method outperforms state-of-the-art\nmethods. Our code is available in\n\\url{https://github.com/heyuanpengpku/GUEF/tree/main}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19418v1",
    "published_date": "2024-12-27 03:04:57 UTC",
    "updated_date": "2024-12-27 03:04:57 UTC"
  },
  {
    "arxiv_id": "2412.19403v2",
    "title": "Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model",
    "authors": [
      "Fumiyasu Makinoshima",
      "Tatsuya Mitomi",
      "Fumiya Makihara",
      "Eigo Segawa"
    ],
    "abstract": "Discrete choice models are essential for modelling various decision-making\nprocesses in human behaviour. However, the specification of these models has\ndepended heavily on domain knowledge from experts, and the fully automated but\ninterpretable modelling of complex human behaviours has been a long-standing\nchallenge. In this paper, we introduce the differentiable discrete choice model\n(Diff-DCM), a fully data-driven method for the interpretable modelling,\nlearning, prediction, and control of complex human behaviours, which is\nrealised by differentiable programming. Solely from input features and choice\noutcomes without any prior knowledge, Diff-DCM can estimate interpretable\nclosed-form utility functions that reproduce observed behaviours. Comprehensive\nexperiments with both synthetic and real-world data demonstrate that Diff-DCM\ncan be applied to various types of data and requires only a small amount of\ncomputational resources for the estimations, which can be completed within tens\nof seconds on a laptop without any accelerators. In these experiments, we also\ndemonstrate that, using its differentiability, Diff-DCM can provide useful\ninsights into human behaviours, such as an optimal intervention path for\neffective behavioural changes. This study provides a strong basis for the fully\nautomated and reliable modelling, prediction, and control of human behaviours.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19403v2",
    "published_date": "2024-12-27 01:53:18 UTC",
    "updated_date": "2025-01-08 02:43:21 UTC"
  },
  {
    "arxiv_id": "2412.19396v1",
    "title": "Comparing Few to Rank Many: Active Human Preference Learning using Randomized Frank-Wolfe",
    "authors": [
      "Kiran Koshy Thekumparampil",
      "Gaurush Hiranandani",
      "Kousha Kalantari",
      "Shoham Sabach",
      "Branislav Kveton"
    ],
    "abstract": "We study learning of human preferences from a limited comparison feedback.\nThis task is ubiquitous in machine learning. Its applications such as\nreinforcement learning from human feedback, have been transformational. We\nformulate this problem as learning a Plackett-Luce model over a universe of $N$\nchoices from $K$-way comparison feedback, where typically $K \\ll N$. Our\nsolution is the D-optimal design for the Plackett-Luce objective. The design\ndefines a data logging policy that elicits comparison feedback for a small\ncollection of optimally chosen points from all ${N \\choose K}$ feasible\nsubsets. The main algorithmic challenge in this work is that even fast methods\nfor solving D-optimal designs would have $O({N \\choose K})$ time complexity. To\naddress this issue, we propose a randomized Frank-Wolfe (FW) algorithm that\nsolves the linear maximization sub-problems in the FW method on randomly chosen\nvariables. We analyze the algorithm, and evaluate it empirically on synthetic\nand open-source NLP datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to AISTATS 2025 on October 10, 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.19396v1",
    "published_date": "2024-12-27 01:10:17 UTC",
    "updated_date": "2024-12-27 01:10:17 UTC"
  },
  {
    "arxiv_id": "2412.19394v2",
    "title": "An Engorgio Prompt Makes Large Language Model Babble on",
    "authors": [
      "Jianshuo Dong",
      "Ziyuan Zhang",
      "Qingjie Zhang",
      "Tianwei Zhang",
      "Hao Wang",
      "Hewu Li",
      "Qi Li",
      "Chao Zhang",
      "Ke Xu",
      "Han Qiu"
    ],
    "abstract": "Auto-regressive large language models (LLMs) have yielded impressive\nperformance in many real-world tasks. However, the new paradigm of these LLMs\nalso exposes novel threats. In this paper, we explore their vulnerability to\ninference cost attacks, where a malicious user crafts Engorgio prompts to\nintentionally increase the computation cost and latency of the inference\nprocess. We design Engorgio, a novel methodology, to efficiently generate\nadversarial Engorgio prompts to affect the target LLM's service availability.\nEngorgio has the following two technical contributions. (1) We employ a\nparameterized distribution to track LLMs' prediction trajectory. (2) Targeting\nthe auto-regressive nature of LLMs' inference process, we propose novel loss\nfunctions to stably suppress the appearance of the <EOS> token, whose\noccurrence will interrupt the LLM's generation process. We conduct extensive\nexperiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B.\nThe results show that Engorgio prompts can successfully induce LLMs to generate\nabnormally long outputs (i.e., roughly 2-13$\\times$ longer to reach 90%+ of the\noutput length limit) in a white-box scenario and our real-world experiment\ndemonstrates Engergio's threat to LLM service with limited computing resources.\nThe code is released at: https://github.com/jianshuod/Engorgio-prompt.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.19394v2",
    "published_date": "2024-12-27 01:00:23 UTC",
    "updated_date": "2025-02-13 03:00:18 UTC"
  },
  {
    "arxiv_id": "2412.19391v2",
    "title": "An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification",
    "authors": [
      "Eugene Choi",
      "Julian Rodriguez",
      "Edmund Young"
    ],
    "abstract": "Domain adaptation is an active area of research driven by the growing demand\nfor robust machine learning models that perform well on real-world data.\nAdversarial learning for deep neural networks (DNNs) has emerged as a promising\napproach to improving generalization ability, particularly for image\nclassification. In this paper, we implement a specific adversarial learning\ntechnique known as Adversarial Discriminative Domain Adaptation (ADDA) and\nreplicate digit classification experiments from the original ADDA paper. We\nextend their findings by examining a broader range of domain shifts and provide\na detailed analysis of in-domain classification accuracy post-ADDA. Our results\ndemonstrate that ADDA significantly improves accuracy across certain domain\nshifts with minimal impact on in-domain performance. Furthermore, we provide\nqualitative analysis and propose potential explanations for ADDA's limitations\nin less successful domain shifts. Code is at\nhttps://github.com/eugenechoi2004/COS429_FINAL .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Replacement: Updated methodology section to include grayscale\n  preprocessing of SVHN data",
    "pdf_url": "http://arxiv.org/pdf/2412.19391v2",
    "published_date": "2024-12-27 00:36:40 UTC",
    "updated_date": "2025-01-07 03:15:49 UTC"
  }
]