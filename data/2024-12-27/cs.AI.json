{
  "date": "2024-12-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化（如 LLMs 的高效训练和推理）、计算机视觉（如图像生成和物体检测）、医疗 AI（如药物预测和 IVF 分析）等领域，其中 DeepSeek-V3 展示了大规模语言模型的高效训练策略，OS-Genesis 创新了 GUI 代理数据合成方法，而 HADES 则在 LLM 加速器设计上令人印象深刻；这些论文突出了 AI 在实际应用中的潜力。\n\n下面，我挑选并简要讨论了部分关键论文，先从影响力较大的 AI 优化和计算机视觉主题入手，再快速掠过其他领域的代表性或相关工作。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### AI 模型优化与 LLMs\n- **DeepSeek-V3 Technical Report** (中文: DeepSeek-V3 技术报告；英文: DeepSeek-V3 Technical Report)：这篇论文介绍了 DeepSeek-V3，一款 671B 参数的混合专家模型，通过 Multi-head Latent Attention 和无辅助损失负载平衡策略，实现高效训练和推理，在 14.8 万亿 tokens 上训练，性能媲美封闭源模型，同时仅需 2.788M H800 GPU 小时，显著降低了训练成本。\n- **HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models** (中文: HADES：用于高效推测的大语言模型硬件加速解码；英文: HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models)：论文提出 HADES 框架，利用硬件级推测解码提升 LLM 的性能和能效，首次探索了 LLM 加速器设计，支持更先进的应用，如自然语言处理。\n- **OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis** (中文: OS-Genesis：通过逆向任务合成自动构建 GUI 代理轨迹；英文: OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis)：这项工作创新性地逆转轨迹收集过程，使用 LLM 生成高质量合成数据，实现 GUI 代理的轨迹探索和轨迹奖励模型优化，提高了代理在复杂任务中的性能。\n- **Gradient Weight-normalized Low-rank Projection for Efficient LLM Training** (中文: 基于梯度权重归一化的低秩投影用于高效 LLM 训练；英文: Gradient Weight-normalized Low-rank Projection for Efficient LLM Training)：论文引入梯度归一化和低秩近似方法，减少 LLM 训练内存使用（最高减少 89.5%），并在预训练和微调中表现出色，如在 RoBERTa 上提升 GLUE 任务分数。\n- **Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture** (中文: Text2Insight：使用多模型架构无缝将自然语言文本转化为洞见；英文: Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture)：该方法结合 VAE 和 LSTM，将自然语言查询转化为 SQL 和可视化洞见，实现了高精度数据分析（准确率 99%），适用于动态数据可视化。\n\n### 计算机视觉与图像处理\n- **Hybrid Local Causal Discovery** (中文: 混合局部因果发现；英文: Hybrid Local Causal Discovery)：论文提出 HLCD 算法，结合约束和评分方法处理局部因果关系，显著提高了因果图的准确性和鲁棒性，在基准数据集上超越现有方法。\n- **ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion** (中文: ViDTA：通过虚拟图节点和注意力特征融合增强药物靶点亲和力预测；英文: ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion)：这项工作使用虚拟节点和注意力机制改进图神经网络，实现更准确的药物预测，在 Davis 和 KIBA 数据集上表现优异。\n- **Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis** (中文: 使用混合 YOLO 管道优化头盔检测：详细分析；英文: Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis)：论文比较 YOLOv8、v9 和 v11，提出混合 YOLO 模型，提升头盔检测的准确性和实时性，在标准基准上表现出色。\n- **A Fully Hardware Implemented Accelerator Design in ReRAM Analog Computing without ADCs** (中文: 无 ADC 的 ReRAM 模拟计算中完全硬件实现的加速器设计；英文: A Fully Hardware Implemented Accelerator Design in ReRAM Analog Computing without ADCs)：该设计利用 ReRAM 实现神经网络加速器，省略 ADC 组件，提高能效达 3-5 倍，同时保持推理准确性。\n\n### 医疗 AI 与生物应用\n- **An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models** (中文: 使用特征优化和 Transformer 模型的集成优化和深度学习管道预测 IVF 活产成功；英文: An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models)：论文构建 AI 管道结合 PSO 和 TabTransformer 模型，预测 IVF 活产率，准确率达 99.50%，为个性化生育治疗提供工具。\n- **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation** (中文: AI 与医疗成像在 IVF 卵巢刺激中的整合综述；英文: A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation)：这篇综述分析 AI 在 IVF 中的应用，强调高级图像分析（如 3D 超声）和可解释 AI 的潜力，指出多中心数据集的必要性以改善预测准确性。\n\n其他领域的论文，如强化学习（e.g., Adaptive Context-Aware Multi-Path Transmission Control for VR/AR Content）和因果发现（e.g., Graph-attention-based Casual Discovery），虽然有创新，但相对次要，这里仅快速提及：这些工作探索了 DRL 在 VR 传输和图注意力机制中的应用，优化了任务规划和因果推理，但影响力不如上述主题突出。\n\n总之，今天的论文展示了 AI 在优化和应用上的进展，值得关注高效模型设计和医疗领域的突破。如果您对特定主题感兴趣，建议查看 DeepSeek-V3 或 OS-Genesis 的完整论文！",
  "papers": [
    {
      "arxiv_id": "2412.19954v1",
      "title": "ErgoChat: a Visual Query System for the Ergonomic Risk Assessment of Construction Workers",
      "title_zh": "ErgoChat：建筑工人人体工程学风险评估的视觉查询系统",
      "authors": [
        "Chao Fan",
        "Qipei Mei",
        "Xiaonan Wang",
        "Xinming Li"
      ],
      "abstract": "In the construction sector, workers often endure prolonged periods of\nhigh-intensity physical work and prolonged use of tools, resulting in injuries\nand illnesses primarily linked to postural ergonomic risks, a longstanding\npredominant health concern. To mitigate these risks, researchers have applied\nvarious technological methods to identify the ergonomic risks that construction\nworkers face. However, traditional ergonomic risk assessment (ERA) techniques\ndo not offer interactive feedback. The rapidly developing vision-language\nmodels (VLMs), capable of generating textual descriptions or answering\nquestions about ergonomic risks based on image inputs, have not yet received\nwidespread attention. This research introduces an interactive visual query\nsystem tailored to assess the postural ergonomic risks of construction workers.\nThe system's capabilities include visual question answering (VQA), which\nresponds to visual queries regarding workers' exposure to postural ergonomic\nrisks, and image captioning (IC), which generates textual descriptions of these\nrisks from images. Additionally, this study proposes a dataset designed for\ntraining and testing such methodologies. Systematic testing indicates that the\nVQA functionality delivers an accuracy of 96.5%. Moreover, evaluations using\nnine metrics for IC and assessments from human experts indicate that the\nproposed approach surpasses the performance of a method using the same\narchitecture trained solely on generic datasets. This study sets a new\ndirection for future developments in interactive ERA using generative\nartificial intelligence (AI) technologies.",
      "tldr_zh": "本文提出ErgoChat，一种交互式视觉查询系统，用于评估建筑工人的姿势人体工程学风险（ERA），通过视觉问题回答(VQA)和图像描述(IC)功能，利用视觉语言模型(VLMs)提供即时反馈。系统针对工人暴露的风险进行查询响应和图像描述，并构建了一个专用数据集用于训练和测试。实验结果显示，VQA的准确率达到96.5%，而IC在九个指标上的表现优于仅使用通用数据集的基准方法。该研究为采用生成AI技术实现交互式ERA开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19954v1",
      "published_date": "2024-12-27 23:25:51 UTC",
      "updated_date": "2024-12-27 23:25:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:58:26.754570"
    },
    {
      "arxiv_id": "2501.00048v1",
      "title": "Stroke Prediction using Clinical and Social Features in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aidan Chadha"
      ],
      "abstract": "Every year in the United States, 800,000 individuals suffer a stroke - one\nperson every 40 seconds, with a death occurring every four minutes. While\nindividual factors vary, certain predictors are more prevalent in determining\nstroke risk. As strokes are the second leading cause of death and disability\nworldwide, predicting stroke likelihood based on lifestyle factors is crucial.\nShowing individuals their stroke risk could motivate lifestyle changes, and\nmachine learning offers solutions to this prediction challenge. Neural networks\nexcel at predicting outcomes based on training features like lifestyle factors,\nhowever, they're not the only option. Logistic regression models can also\neffectively compute the likelihood of binary outcomes based on independent\nvariables, making them well-suited for stroke prediction. This analysis will\ncompare both neural networks (dense and convolutional) and logistic regression\nmodels for stroke prediction, examining their pros, cons, and differences to\ndevelop the most effective predictor that minimizes false negatives.",
      "tldr_zh": "本研究探讨了使用临床和社会特征进行中风预测的重要性，中风是全球第二大致死和致残原因，每年在美国影响80万余人。研究比较了Neural Networks（包括Dense和Convolutional模型）和Logistic Regression模型的性能，评估它们在基于生活方式等因素预测中风风险时的优缺点。最终目标是开发最有效的预测模型，以最小化假阴性（false negatives），从而帮助个体了解风险并促使生活方式改变。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00048v1",
      "published_date": "2024-12-27 23:05:16 UTC",
      "updated_date": "2024-12-27 23:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:58:37.844736"
    },
    {
      "arxiv_id": "2412.19947v1",
      "title": "Standard-Deviation-Inspired Regularization for Improving Adversarial Robustness",
      "title_zh": "标准差启发的正则化用于提升对抗鲁棒性",
      "authors": [
        "Olukorede Fakorede",
        "Modeste Atsague",
        "Jin Tian"
      ],
      "abstract": "Adversarial Training (AT) has been demonstrated to improve the robustness of\ndeep neural networks (DNNs) against adversarial attacks. AT is a min-max\noptimization procedure where in adversarial examples are generated to train a\nmore robust DNN. The inner maximization step of AT increases the losses of\ninputs with respect to their actual classes. The outer minimization involves\nminimizing the losses on the adversarial examples obtained from the inner\nmaximization. This work proposes a standard-deviation-inspired (SDI)\nregularization term to improve adversarial robustness and generalization. We\nargue that the inner maximization in AT is similar to minimizing a modified\nstandard deviation of the model's output probabilities. Moreover, we suggest\nthat maximizing this modified standard deviation can complement the outer\nminimization of the AT framework. To support our argument, we experimentally\nshow that the SDI measure can be used to craft adversarial examples.\nAdditionally, we demonstrate that combining the SDI regularization term with\nexisting AT variants enhances the robustness of DNNs against stronger attacks,\nsuch as CW and Auto-attack, and improves generalization.",
      "tldr_zh": "本论文提出了一种标准-deviation-inspired (SDI) 正则化术语，以提升深度神经网络 (DNNs) 的对抗鲁棒性和泛化能力。作者认为，Adversarial Training (AT) 的内层最大化过程类似于最小化模型输出概率的修改标准偏差，因此通过最大化该标准偏差来补充AT框架，并实验证明SDI可用于生成对抗样本。结果显示，将SDI与现有AT变体结合后，DNNs对CW和Auto-attack等强攻击的鲁棒性提高了，并改善了整体泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19947v1",
      "published_date": "2024-12-27 22:59:21 UTC",
      "updated_date": "2024-12-27 22:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:58:50.995883"
    },
    {
      "arxiv_id": "2412.19938v1",
      "title": "Towards Strong AI: Transformational Beliefs and Scientific Creativity",
      "title_zh": "迈向强人工智能：变革信念和科学创造力",
      "authors": [
        "Samuel J. Eschker",
        "Chuanhai Liu"
      ],
      "abstract": "Strong artificial intelligence (AI) is envisioned to possess general\ncognitive abilities and scientific creativity comparable to human intelligence,\nencompassing both knowledge acquisition and problem-solving. While remarkable\nprogress has been made in weak AI, the realization of strong AI remains a topic\nof intense debate and critical examination. In this paper, we explore pivotal\ninnovations in the history of astronomy and physics, focusing on the discovery\nof Neptune and the concept of scientific revolutions as perceived by\nphilosophers of science. Building on these insights, we introduce a simple\ntheoretical and statistical framework of weak beliefs, termed the\nTransformational Belief (TB) framework, designed as a foundation for modeling\nscientific creativity. Through selected illustrative examples in statistical\nscience, we demonstrate the TB framework's potential as a promising foundation\nfor understanding, analyzing, and even fostering creativity -- paving the way\ntoward the development of strong AI. We conclude with reflections on future\nresearch directions and potential advancements.",
      "tldr_zh": "这篇论文探讨了强人工智能（Strong AI）的愿景，强调其需具备与人类相当的一般认知能力和科学创造力，包括知识获取和问题解决，同时对比了弱 AI 的进展。作者通过分析天文学和物理学历史上的关键创新（如海王星的发现和科学革命概念），引入了Transformational Belief (TB) 框架，这是一个简单的理论和统计框架，用于建模科学创造力。论文通过统计科学中的示例，展示了TB框架在理解、分析和促进创造力的潜力，并将其作为推进Strong AI 发展的基础。最后，作者反思了未来研究方向，以推动相关领域的进步。",
      "categories": [
        "stat.OT",
        "cs.AI"
      ],
      "primary_category": "stat.OT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19938v1",
      "published_date": "2024-12-27 22:02:36 UTC",
      "updated_date": "2024-12-27 22:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:59:03.235257"
    },
    {
      "arxiv_id": "2412.19932v1",
      "title": "Hidformer: Transformer-Style Neural Network in Stock Price Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Kamil Ł. Szydłowski",
        "Jarosław A. Chudziak"
      ],
      "abstract": "This paper investigates the application of Transformer-based neural networks\nto stock price forecasting, with a special focus on the intersection of machine\nlearning techniques and financial market analysis. The evolution of Transformer\nmodels, from their inception to their adaptation for time series analysis in\nfinancial contexts, is reviewed and discussed. Central to our study is the\nexploration of the Hidformer model, which is currently recognized for its\npromising performance in time series prediction. The primary aim of this paper\nis to determine whether Hidformer will also prove itself in the task of stock\nprice prediction. This slightly modified model serves as the framework for our\nexperiments, integrating the principles of technical analysis with advanced\nmachine learning concepts to enhance stock price prediction accuracy. We\nconduct an evaluation of the Hidformer model's performance, using a set of\ncriteria to determine its efficacy. Our findings offer additional insights into\nthe practical application of Transformer architectures in financial time series\nforecasting, highlighting their potential to improve algorithmic trading\nstrategies, including human decision making.",
      "tldr_zh": "本研究探讨了基于 Transformer 风格神经网络的 Hidformer 模型在股票价格预测中的应用，回顾了 Transformer 模型从起源到金融时间序列分析的演变。研究团队对 Hidformer 进行了轻微修改，结合技术分析和机器学习原理，以提升预测准确性，并通过实验评估其在股票价格预测任务中的表现。结果显示，Hidformer 模型表现出色，提供宝贵见解，有助于改进算法交易策略和人类决策过程。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "cs.CE",
      "comment": "12 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19932v1",
      "published_date": "2024-12-27 21:34:44 UTC",
      "updated_date": "2024-12-27 21:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:59:14.479946"
    },
    {
      "arxiv_id": "2412.19931v1",
      "title": "Pivoting B2B platform business models: From platform experimentation to multi-platform integration to ecosystem envelopment",
      "title_zh": "翻译失败",
      "authors": [
        "Clara Filosa",
        "Marin Jovanovic",
        "Lara Agostini",
        "Anna Nosella"
      ],
      "abstract": "The landscape of digital servitization in the manufacturing sector is\nevolving, marked by a strategic shift from traditional product-centric to\nplatform business models (BMs). Manufacturing firms often employ a blend of\napproaches to develop business-to-business (B2B) platforms, leading to\nsignificant reconfigurations in their BMs. However, they frequently encounter\nfailures in their B2B platform development initiatives, leading them to abandon\ninitial efforts and pivot to alternative platform strategies. Therefore, this\nstudy, through an in-depth case study of a manufacturer in the energy sector,\narticulates a three-phase pivoting framework for B2B platform BMs, including\nplatform development and platform strategy. Initially, the manufacturer focused\non asset-based product sales supplemented by asset maintenance services and\nfollowed an emergent platformization strategy characterized by the rise of\nmultiple, independent B2B platforms catering to diverse functions. Next,\nfocusing on the imposed customer journey strategy, the firm shifted towards a\nstrategic multi-platform integration into an all-encompassing platform\nsupported by artificial intelligence (AI), signaling a maturation of the\nplatform BM to combine a wide range of services into an\nenergy-performance-based contract. Finally, the last step of the firm's\nplatform BM evolution consisted of a deliberate platform strategy open to\nexternal stakeholders and enveloping its data-driven offerings within a broader\nplatform ecosystem. This article advances B2B platform BMs and digital\nservitization literature, highlighting the efficacy of a progressive approach\nand strategic pivoting.",
      "tldr_zh": "该研究探讨了制造业数字化服务化（digital servitization）中，从传统产品导向转向 B2B 平台商业模型（B2B platform business models）的战略演变，通过对能源行业制造商的深度案例研究，提出了一个三阶段转向框架：首先，从资产销售和维护服务开始，采用紧急平台化策略（emergent platformization）发展多个独立 B2B 平台；其次，转向多平台整合（multi-platform integration），利用人工智能（AI）构建一个全面平台，提供基于能效的合同；最后，扩展到生态系统包围（ecosystem envelopment），开放给外部利益相关者。研究强调了渐进式方法和战略转向的有效性，推进了 B2B 平台商业模型和数字化服务化领域的文献。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19931v1",
      "published_date": "2024-12-27 21:34:05 UTC",
      "updated_date": "2024-12-27 21:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:59:27.621832"
    },
    {
      "arxiv_id": "2412.19927v1",
      "title": "Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with Test-time Refinement",
      "title_zh": "基于测试时精炼的湍流连续时空动态建模",
      "authors": [
        "Shengyu Chen",
        "Peyman Givi",
        "Can Zheng",
        "Xiaowei Jia"
      ],
      "abstract": "The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
      "tldr_zh": "本论文探讨了湍流模拟在气候科学、淡水科学和能源制造等领域的重要性，并针对Large Eddy Simulation (LES) 的低分辨率局限性，提出了一种新型流体重建方法。该方法利用物理知识建模流体动力学，通过测试阶段的degradation-based refinement 策略，仅使用 LES 数据强制物理约束并减少累积重建错误，同时引入特征采样策略以支持不同分辨率的流体数据重建。实验结果显示，该方法在两个湍流数据集上有效重建高分辨率Direct Numerical Simulation (DNS) 数据，成功保留了流体传输的固有物理属性。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.19927v1",
      "published_date": "2024-12-27 21:22:18 UTC",
      "updated_date": "2024-12-27 21:22:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:59:39.187978"
    },
    {
      "arxiv_id": "2412.19925v2",
      "title": "HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ze Yang",
        "Yihong Jin",
        "Xinhe Xu"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nby understanding and generating human-like text. However, the increasing demand\nfor more sophisticated LLMs presents significant computational challenges due\nto their scale and complexity. This paper introduces Hardware Accelerated\nDecoding (HADES), a novel approach to enhance the performance and energy\nefficiency of LLMs. We address the design of an LLM accelerator with\nhardware-level speculative decoding support, a concept not previously explored\nin existing literature. Our work demonstrates how speculative decoding can\nsignificantly improve the efficiency of LLM operations, paving the way for more\nadvanced and practical applications of these models.",
      "tldr_zh": "本论文提出 HADES（Hardware Accelerated Decoding），一种创新方法，用于提升大型语言模型 (LLMs) 的性能和能效，以应对其规模和复杂性带来的计算挑战。HADES 通过设计支持硬件级投机解码 (speculative decoding) 的 LLM 加速器，实现对模型操作的优化，这在现有文献中尚未探索。实验结果显示，该方法显著提高了 LLMs 的运行效率，为更先进的应用铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICCEA 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19925v2",
      "published_date": "2024-12-27 21:19:01 UTC",
      "updated_date": "2025-01-13 04:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:59:50.397100"
    },
    {
      "arxiv_id": "2412.19915v1",
      "title": "Identifying Cocoa Pollinators: A Deep Learning Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxiu Xu",
        "Saba Ghorbani Bazegar",
        "Dong Sheng",
        "Manuel Toledo-Hernandez",
        "ZhenZhong Lan",
        "Thomas Cherico Wanger"
      ],
      "abstract": "Cocoa is a multi-billion-dollar industry but research on improving yields\nthrough pollination remains limited. New embedded hardware and AI-based data\nanalysis is advancing information on cocoa flower visitors, their identity and\nimplications for yields. We present the first cocoa flower visitor dataset\ncontaining 5,792 images of Ceratopogonidae, Formicidae, Aphididae, Araneae, and\nEncyrtidae, and 1,082 background cocoa flower images. This dataset was curated\nfrom 23 million images collected over two years by embedded cameras in cocoa\nplantations in Hainan province, China. We exemplify the use of the dataset with\ndifferent sizes of YOLOv8 models and by progressively increasing the background\nimage ratio in the training set to identify the best-performing model. The\nmedium-sized YOLOv8 model achieved the best results with 8% background images\n(F1 Score of 0.71, mAP50 of 0.70). Overall, this dataset is useful to compare\nthe performance of deep learning model architectures on images with low\ncontrast images and difficult detection targets. The data can support future\nefforts to advance sustainable cocoa production through pollination monitoring\nprojects.",
      "tldr_zh": "本文发布了一个新的可可花访客数据集，用于识别Ceratopogonidae、Formicidae、Aphididae、Araneae和Encyrtidae等昆虫，以提升可可产量和可持续生产。数据集包含5,792张昆虫图像和1,082张背景图像，源自中国海南省可可种植园的23百万张图像。研究者使用不同大小的YOLOv8模型进行测试，发现中等-sized模型在训练集8%背景图像时表现最佳（F1 Score 0.71，mAP50 0.70）。此数据集有助于评估深度学习模型在低对比度图像和难检测目标上的性能，并支持未来的授粉监测项目。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "The manuscript introduces the first cocoa pollination dataset and an\n  example analysis with YOLOv8 models",
      "pdf_url": "http://arxiv.org/pdf/2412.19915v1",
      "published_date": "2024-12-27 20:27:52 UTC",
      "updated_date": "2024-12-27 20:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:00:04.511793"
    },
    {
      "arxiv_id": "2412.19913v1",
      "title": "Leveraging Scene Geometry and Depth Information for Robust Image Deraining",
      "title_zh": "利用场景几何和深度信息实现鲁棒图像去雨",
      "authors": [
        "Ningning Xu",
        "Jidong J. Yang"
      ],
      "abstract": "Image deraining holds great potential for enhancing the vision of autonomous\nvehicles in rainy conditions, contributing to safer driving. Previous works\nhave primarily focused on employing a single network architecture to generate\nderained images. However, they often fail to fully exploit the rich prior\nknowledge embedded in the scenes. Particularly, most methods overlook the depth\ninformation that can provide valuable context about scene geometry and guide\nmore robust deraining. In this work, we introduce a novel learning framework\nthat integrates multiple networks: an AutoEncoder for deraining, an auxiliary\nnetwork to incorporate depth information, and two supervision networks to\nenforce feature consistency between rainy and clear scenes. This multi-network\ndesign enables our model to effectively capture the underlying scene structure,\nproducing clearer and more accurately derained images, leading to improved\nobject detection for autonomous vehicles. Extensive experiments on three\nwidely-used datasets demonstrated the effectiveness of our proposed method.",
      "tldr_zh": "本文提出一种新型图像去雨框架，通过整合场景几何和深度信息，提升自动驾驶车辆在雨天条件下的视觉表现。该框架包括一个AutoEncoder用于去雨处理、一个辅助网络整合深度信息，以及两个监督网络确保雨天和晴天场景特征一致，从而更有效地捕捉底层场景结构并生成更准确的去雨图像。在三个常用数据集上的广泛实验证明，该方法显著提高了对象检测性能，比传统单一网络方法更具鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19913v1",
      "published_date": "2024-12-27 20:18:46 UTC",
      "updated_date": "2024-12-27 20:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:00:15.029927"
    },
    {
      "arxiv_id": "2412.19906v1",
      "title": "Evaluate Summarization in Fine-Granularity: Auto Evaluation with LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Yuan",
        "Eti Rastogi",
        "Fen Zhao",
        "Sagar Goyal",
        "Gautam Naik",
        "Sree Prasanna Rajagopal"
      ],
      "abstract": "Due to the exponential growth of information and the need for efficient\ninformation consumption the task of summarization has gained paramount\nimportance. Evaluating summarization accurately and objectively presents\nsignificant challenges, particularly when dealing with long and unstructured\ntexts rich in content. Existing methods, such as ROUGE (Lin, 2004) and\nembedding similarities, often yield scores that have low correlation with human\njudgements and are also not intuitively understandable, making it difficult to\ngauge the true quality of the summaries. LLMs can mimic human in giving\nsubjective reviews but subjective scores are hard to interpret and justify.\nThey can be easily manipulated by altering the models and the tones of the\nprompts. In this paper, we introduce a novel evaluation methodology and tooling\ndesigned to address these challenges, providing a more comprehensive, accurate\nand interpretable assessment of summarization outputs. Our method (SumAutoEval)\nproposes and evaluates metrics at varying granularity levels, giving objective\nscores on 4 key dimensions such as completeness, correctness, Alignment and\nreadability. We empirically demonstrate, that SumAutoEval enhances the\nunderstanding of output quality with better human correlation.",
      "tldr_zh": "该论文针对总结化任务的评估挑战，指出现有方法如 ROUGE 和嵌入相似度与人类判断相关性低，且不易理解。作者提出了一种新方法 SumAutoEval，利用 LLM 进行自动评估，在细粒度级别上量化评估完整性、正确性、Alignment 和可读性等 4 个关键维度，提供更客观和可解释的分数。实验结果显示，SumAutoEval 显著提高了与人类判断的相关性，从而提升了对总结输出质量的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19906v1",
      "published_date": "2024-12-27 19:42:25 UTC",
      "updated_date": "2024-12-27 19:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:00:26.369921"
    },
    {
      "arxiv_id": "2412.19784v4",
      "title": "Can AI Help with Your Personal Finances?",
      "title_zh": "翻译失败",
      "authors": [
        "Oudom Hean",
        "Utsha Saha",
        "Binita Saha"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have emerged as a\ntransformative development in artificial intelligence (AI), drawing significant\nattention from industry and academia. Trained on vast datasets, these\nsophisticated AI systems exhibit impressive natural language processing and\ncontent generation capabilities. This paper explores the potential of LLMs to\naddress key challenges in personal finance, focusing on the United States. We\nevaluate several leading LLMs, including OpenAI's ChatGPT, Google's Gemini,\nAnthropic's Claude, and Meta's Llama, to assess their effectiveness in\nproviding accurate financial advice on topics such as mortgages, taxes, loans,\nand investments. Our findings show that while these models achieve an average\naccuracy rate of approximately 70%, they also display notable limitations in\ncertain areas. Specifically, LLMs struggle to provide accurate responses for\ncomplex financial queries, with performance varying significantly across\ndifferent topics. Despite these limitations, the analysis reveals notable\nimprovements in newer versions of these models, highlighting their growing\nutility for individuals and financial advisors. As these AI systems continue to\nevolve, their potential for advancing AI-driven applications in personal\nfinance becomes increasingly promising.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在美国个人财务领域的潜力，评估了 ChatGPT、Gemini、Claude 和 Llama 等模型在提供关于抵押贷款、税收、贷款和投资等主题的财务建议方面的表现。研究发现，这些模型的平均准确率约为 70%，但在处理复杂查询时存在显著局限性，表现因主题而异。尽管存在这些挑战，新版本的模型已显示出明显改进，突显了 LLMs 在个人财务管理和 AI 驱动应用中的日益潜力。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19784v4",
      "published_date": "2024-12-27 18:25:27 UTC",
      "updated_date": "2025-01-14 02:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:00:39.641002"
    },
    {
      "arxiv_id": "2501.06201v1",
      "title": "A Novel Method for Pignistic Information Fusion in the View of Z-number",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He"
      ],
      "abstract": "How to properly fuse information from complex sources is still an open\nproblem. Lots of methods have been put forward to provide a effective solution\nin fusing intricate information. Among them, Dempster-Shafer evidences theory\n(DSET) is one of the representatives, it is widely used to handle uncertain\ninformation. Based on DSET, a completely new method to fuse information from\ndifferent sources based on pignistic transformation and Z-numbers is proposed\nin this paper which is able to handle separate situations of information and\nkeeps high accuracy in producing rational and correct judgments on actual\nsituations. Besides, in order to illustrate the superiority of the proposed\nmethod, some numerical examples and application are also provided to verify the\nvalidity and robustness of it.",
      "tldr_zh": "这篇论文提出了一种新方法，用于融合复杂信息源的信息，基于 Dempster-Shafer evidences theory (DSET) 结合 pignistic transformation 和 Z-numbers，能够有效处理不确定性和分离信息情况，同时保持高准确性。\n该方法在实际场景中产生合理判断，并通过数值例子和应用案例验证了其有效性和鲁棒性。\n整体上，这为不确定信息融合提供了更可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06201v1",
      "published_date": "2024-12-27 18:17:28 UTC",
      "updated_date": "2024-12-27 18:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:00:50.423344"
    },
    {
      "arxiv_id": "2412.19759v1",
      "title": "Enhancing Cognitive Diagnosis by Modeling Learner Cognitive Structure State",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifu Chen",
        "Hengnian Gu",
        "Jin Peng Zhou",
        "Dongdai Zhou"
      ],
      "abstract": "Cognitive diagnosis represents a fundamental research area within intelligent\neducation, with the objective of measuring the cognitive status of individuals.\nTheoretically, an individual's cognitive state is essentially equivalent to\ntheir cognitive structure state. Cognitive structure state comprises two key\ncomponents: knowledge state (KS) and knowledge structure state (KUS). The\nknowledge state reflects the learner's mastery of individual concepts, a widely\nstudied focus within cognitive diagnosis. In contrast, the knowledge structure\nstate-representing the learner's understanding of the relationships between\nconcepts-remains inadequately modeled. A learner's cognitive structure is\nessential for promoting meaningful learning and shaping academic performance.\nAlthough various methods have been proposed, most focus on assessing KS and\nfail to assess KUS. To bridge this gap, we propose an innovative and effective\nframework-CSCD (Cognitive Structure State-based Cognitive Diagnosis)-which\nintroduces a novel framework to modeling learners' cognitive structures in\ndiagnostic assessments, thereby offering new insights into cognitive structure\nmodeling. Specifically, we employ an edge-feature-based graph attention network\nto represent the learner's cognitive structure state, effectively integrating\nKS and KUS. Extensive experiments conducted on real datasets demonstrate the\nsuperior performance of this framework in terms of diagnostic accuracy and\ninterpretability.",
      "tldr_zh": "本论文针对认知诊断领域的不足，提出了一种创新框架 CSCD，用于建模学习者的认知结构状态，该状态包括知识状态 (KS) 和知识结构状态 (KUS)，以更好地评估概念间关系对学习的影响。CSCD 框架采用基于边特征的图注意力网络 (graph attention network) 来整合 KS 和 KUS，从而提升诊断的准确性和可解释性。在真实数据集上的广泛实验表明，该框架显著提高了认知诊断的表现，为智能教育提供了新的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19759v1",
      "published_date": "2024-12-27 17:41:39 UTC",
      "updated_date": "2024-12-27 17:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:01:02.698633"
    },
    {
      "arxiv_id": "2412.19755v2",
      "title": "\"Did my figure do justice to the answer?\" : Towards Multimodal Short Answer Grading with Feedback (MMSAF)",
      "title_zh": "翻译失败",
      "authors": [
        "Pritam Sil",
        "Bhaskaran Raman",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Assessments play a vital role in a student's learning process by providing\nfeedback on a student's proficiency level in a subject. While assessments often\nmake use of short answer questions, it is often difficult to grade such\nquestions at a large scale. Moreover, such questions often involve students\ndrawing supporting diagrams along with their textual explanations. Such\nquestions often promote multimodal literacy and are aligned with\ncompetency-based questions, which demand a deeper cognitive processing ability\nfrom students. However, existing literature does not deal with the automatic\ngrading of such answers. Thus, to bridge this gap, we propose the Multimodal\nShort Answer Grading with Feedback (MMSAF) problem along with a dataset of 2197\ndata points. Additionally, we provide an automated framework for generating\nsuch datasets. Our evaluations on existing Large Language Models (LLMs) over\nthis dataset achieved an overall accuracy of 55% on the Level of Correctness\nlabels and 75% on Image Relevance labels. As per human experts, Pixtral was\nmore aligned towards human judgement and values for biology and ChatGPT for\nphysics and chemistry and achieved a score of 4 or more out of 5 in most\nparameters.",
      "tldr_zh": "该论文提出 Multimodal Short Answer Grading with Feedback (MMSAF) 问题，旨在自动评估学生短答题的文本解释和支持图表，以提供反馈并促进多模态素养。研究构建了一个包含 2197 数据点的数据集，并开发了一个自动生成此类数据集的框架。实验结果显示，现有的 Large Language Models (LLMs) 在数据集上实现了 Level of Correctness 标签的55%准确率和 Image Relevance 标签的75%准确率，其中 Pixtral 在生物学上更符合人类判断，而 ChatGPT 在物理和化学上表现更佳，大多数参数得分达到4分或以上（满分5分）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19755v2",
      "published_date": "2024-12-27 17:33:39 UTC",
      "updated_date": "2025-02-15 21:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:01:14.940269"
    },
    {
      "arxiv_id": "2412.19754v3",
      "title": "Complement or substitute? How AI increases the demand for human skills",
      "title_zh": "互补还是替代？AI 如何增加对人类技能的需求",
      "authors": [
        "Elina Mäkelä",
        "Fabian Stephany"
      ],
      "abstract": "This paper examines whether artificial intelligence (AI) acts as a substitute\nor complement to human labour, drawing on 12 million online job vacancies from\nthe United States spanning 2018-2023. We adopt a two-pronged approach: first,\nanalysing \"internal effects\" within roles explicitly requiring AI, and second,\ninvestigating \"external effects\" that arise when industries, occupations, and\nregions experience increases in AI demand. Our focus centres on whether\ncomplementary skills-such as digital literacy, teamwork, resilience, agility,\nor analytical thinking-become more prevalent and valuable as AI adoption grows.\nResults show that AI-focused roles are nearly twice as likely to require skills\nlike resilience, agility, or analytical thinking compared to non-AI roles.\nFurthermore, these skills command a significant wage premium; data scientists,\nfor instance, are offered 5-10% higher salaries if they also possess resilience\nor ethics capabilities. We observe positive spillover effects: a doubling of\nAI-specific demand across industries correlates with a 5% increase in demand\nfor complementary skills, even outside AI-related roles. Conversely, tasks\nvulnerable to AI substitution, such as basic data skills or translation,\nexhibit modest declines in demand. However, the external effect is clearly net\npositive: Complementary effects are up to 1.7x larger than substitution\neffects. These results are consistent across economies, including the United\nKingdom and Australia. Our findings highlight the necessity of reskilling\nworkers in areas where human expertise remains increasingly valuable and\nensuring workers can effectively complement and leverage emerging AI\ntechnologies.",
      "tldr_zh": "本研究调查了人工智能(AI)是否替代还是补充人类劳动力，通过分析2018-2023年美国的1200万在线职位空缺数据，采用内部效果(分析明确要求AI的角色)和外部效果(考察行业、职业和地区AI需求增长的影响)两种方法。结果显示，AI相关角色几乎是其他角色的两倍，可能需要技能如韧性、敏捷性或分析思维，这些技能不仅需求增加，还带来显著工资溢价，例如数据科学家具备韧性或道德能力可获得5-10%的薪资提升。外部效果总体净正面：行业AI需求翻倍会使补充技能需求增加5%，且补充效果比替代效果大1.7倍；在英国和澳大利亚等经济体中，这一趋势一致。研究强调，重新技能培训以提升数字素养和团队合作等人类专长，将有助于工人有效补充和利用AI技术。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "69",
      "pdf_url": "http://arxiv.org/pdf/2412.19754v3",
      "published_date": "2024-12-27 17:26:30 UTC",
      "updated_date": "2025-02-26 11:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:01:28.204042"
    },
    {
      "arxiv_id": "2412.19750v1",
      "title": "IMAGINE: An 8-to-1b 22nm FD-SOI Compute-In-Memory CNN Accelerator With an End-to-End Analog Charge-Based 0.15-8POPS/W Macro Featuring Distribution-Aware Data Reshaping",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian Kneip",
        "Martin Lefebvre",
        "Pol Maistriaux",
        "David Bol"
      ],
      "abstract": "Charge-domain compute-in-memory (CIM) SRAMs have recently become an enticing\ncompromise between computing efficiency and accuracy to process sub-8b\nconvolutional neural networks (CNNs) at the edge. Yet, they commonly make use\nof a fixed dot-product (DP) voltage swing, which leads to a loss in effective\nADC bits due to data-dependent clipping or truncation effects that waste\nprecious conversion energy and computing accuracy. To overcome this, we present\nIMAGINE, a workload-adaptive 1-to-8b CIM-CNN accelerator in 22nm FD-SOI. It\nintroduces a 1152x256 end-to-end charge-based macro with a multi-bit DP based\non an input-serial, weight-parallel accumulation that avoids power-hungry DACs.\nAn adaptive swing is achieved by combining a channel-wise DP array split with a\nlinear in-ADC implementation of analog batch-normalization (ABN), obtaining a\ndistribution-aware data reshaping. Critical design constraints are relaxed by\nincluding the post-silicon equivalent noise within a CIM-aware CNN training\nframework. Measurement results showcase an 8b system-level energy efficiency of\n40TOPS/W at 0.3/0.6V, with competitive accuracies on MNIST and CIFAR-10.\nMoreover, the peak energy and area efficiencies of the 187kB/mm2 macro\nrespectively reach up to 0.15-8POPS/W and 2.6-154TOPS/mm2, scaling with the\n8-to-1b computing precision. These results exceed previous charge-based designs\nby 3-to-5x while being the first work to provide linear in-memory rescaling.",
      "tldr_zh": "本研究提出IMAGINE，一种基于22nm FD-SOI的计算即内存(CIM) CNN加速器，针对子-8b神经网络处理问题，通过自适应电压摆幅和分布感知数据重塑技术（如模拟批归一化(ABN)）来避免数据依赖性截断，提高计算精度和能量效率。IMAGINE采用输入串行、权重并行累加的1152x256 charge-based宏，并将后硅等效噪声纳入CIM-aware CNN训练框架，以缓解关键设计约束。实验结果显示，该加速器在8b系统级别实现40TOPS/W的能量效率，并在MNIST和CIFAR-10数据集上保持竞争性准确率，同时宏的峰值效率达0.15-8POPS/W和2.6-154TOPS/mm2，比现有charge-based设计提高了3-5倍。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "14 pages, 23 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2412.19750v1",
      "published_date": "2024-12-27 17:18:15 UTC",
      "updated_date": "2024-12-27 17:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:01:41.063110"
    },
    {
      "arxiv_id": "2412.19747v1",
      "title": "Enhancing Adversarial Robustness of Deep Neural Networks Through Supervised Contrastive Learning",
      "title_zh": "通过监督对比学习增强深度神经网络的对抗鲁棒性",
      "authors": [
        "Longwei Wang",
        "Navid Nayyem",
        "Abdullah Rakin"
      ],
      "abstract": "Adversarial attacks exploit the vulnerabilities of convolutional neural\nnetworks by introducing imperceptible perturbations that lead to\nmisclassifications, exposing weaknesses in feature representations and decision\nboundaries. This paper presents a novel framework combining supervised\ncontrastive learning and margin-based contrastive loss to enhance adversarial\nrobustness. Supervised contrastive learning improves the structure of the\nfeature space by clustering embeddings of samples within the same class and\nseparating those from different classes. Margin-based contrastive loss,\ninspired by support vector machines, enforces explicit constraints to create\nrobust decision boundaries with well-defined margins. Experiments on the\nCIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performance\nimprovements in adversarial accuracy under Fast Gradient Sign Method attacks.",
      "tldr_zh": "本文提出一种新框架，通过监督对比学习（Supervised Contrastive Learning）和基于边界的对比损失（Margin-based Contrastive Loss）来提升深度神经网络的对抗鲁棒性（Adversarial Robustness），以应对微小扰动导致的误分类问题。该框架利用监督对比学习聚类相同类别的特征嵌入并分离不同类别，从而优化特征空间结构；同时，Margin-based Contrastive Loss 借鉴支持向量机（SVM）思想，强制创建具有明确边界的决策边界。在 CIFAR-100 数据集上使用 ResNet-18 模型的实验结果显示，该方法在 Fast Gradient Sign Method 攻击下显著提高了对抗准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19747v1",
      "published_date": "2024-12-27 17:14:52 UTC",
      "updated_date": "2024-12-27 17:14:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:01:52.284608"
    },
    {
      "arxiv_id": "2412.19737v1",
      "title": "Adaptive Context-Aware Multi-Path Transmission Control for VR/AR Content: A Deep Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Shakil Ahmed",
        "Saifur Rahman Sabuj",
        "Ashfaq Khokhar"
      ],
      "abstract": "This paper introduces the Adaptive Context-Aware Multi-Path Transmission\nControl Protocol (ACMPTCP), an efficient approach designed to optimize the\nperformance of Multi-Path Transmission Control Protocol (MPTCP) for\ndata-intensive applications such as augmented and virtual reality (AR/VR)\nstreaming. ACMPTCP addresses the limitations of conventional MPTCP by\nleveraging deep reinforcement learning (DRL) for agile end-to-end path\nmanagement and optimal bandwidth allocation, facilitating path realignment\nacross diverse network environments.",
      "tldr_zh": "这篇论文提出了 Adaptive Context-Aware Multi-Path Transmission Control Protocol (ACMPTCP)，旨在优化 Multi-Path Transmission Control Protocol (MPTCP) 在 AR/VR 流媒体等数据密集型应用中的性能。\nACMPTCP 利用 deep reinforcement learning (DRL) 进行灵活的端到端路径管理和最佳带宽分配，以适应多样化的网络环境。\n该方法解决了传统 MPTCP 的局限性，通过路径重新调整提升了传输效率和可靠性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19737v1",
      "published_date": "2024-12-27 16:56:12 UTC",
      "updated_date": "2024-12-27 16:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:02:02.845908"
    },
    {
      "arxiv_id": "2412.19726v2",
      "title": "Position: Theory of Mind Benchmarks are Broken for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Riemer",
        "Zahra Ashktorab",
        "Djallel Bouneffouf",
        "Payel Das",
        "Miao Liu",
        "Justin D. Weisz",
        "Murray Campbell"
      ],
      "abstract": "This position paper argues that the majority of theory of mind benchmarks are\nbroken because of their inability to directly test how large language models\n(LLMs) adapt to new partners. This problem stems from the fact that theory of\nmind benchmarks for LLMs are overwhelmingly inspired by the methods used to\ntest theory of mind in humans and fall victim to a fallacy of attributing\nhuman-like qualities to AI agents. We expect that humans will engage in a\nconsistent reasoning process across various questions about a situation, but\nthis is known to not be the case for current LLMs. Most theory of mind\nbenchmarks only measure what we call literal theory of mind: the ability to\npredict the behavior of others. Measuring this kind of reasoning is very\ninformative in testing the ability of agents with self-consistent reasoning.\nHowever, it is important to note the distinction between this and what we\nactually care about when this self-consistency cannot be taken for granted. We\ncall this functional theory of mind: the ability to adapt to agents in-context\nfollowing a rational response to predictions about their behavior. We find that\ntop performing open source LLMs may display strong capabilities in literal\ntheory of mind, depending on how they are prompted, but seem to struggle with\nfunctional theory of mind -- even when partner policies are exceedingly simple.\nSimply put, strong literal theory of mind performance does not necessarily\nimply strong functional theory of mind performance. Achieving functional theory\nof mind, particularly over long interaction horizons with a partner, is a\nsignificant challenge deserving a prominent role in any meaningful LLM theory\nof mind evaluation.",
      "tldr_zh": "这篇立场论文（Position Paper）指出，大多数Theory of Mind基准测试在评估大型语言模型（LLMs）时存在缺陷，因为它们无法直接测试LLMs适应新伙伴的能力，而是过度借鉴人类测试方法，导致将人类品质错误归因于AI。论文区分了两种理论思维：literal theory of mind（预测他人行为的字面能力）和functional theory of mind（根据预测在上下文中适应代理的能力）。研究发现，顶级开源LLMs在literal theory of mind上可能表现出色，取决于提示方式，但functional theory of mind表现较弱，尤其在简单伙伴策略或长互动中。作者强调，实现functional theory of mind是LLMs评估中的关键挑战，应在未来基准测试中占据重要地位。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19726v2",
      "published_date": "2024-12-27 16:30:12 UTC",
      "updated_date": "2025-02-05 19:27:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:02:15.160886"
    },
    {
      "arxiv_id": "2412.19723v2",
      "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Qiushi Sun",
        "Kanzhi Cheng",
        "Zichen Ding",
        "Chuanyang Jin",
        "Yian Wang",
        "Fangzhi Xu",
        "Zhenyu Wu",
        "Chengyou Jia",
        "Liheng Chen",
        "Zhoumianze Liu",
        "Ben Kao",
        "Guohao Li",
        "Junxian He",
        "Yu Qiao",
        "Zhiyong Wu"
      ],
      "abstract": "Graphical User Interface (GUI) agents powered by Vision-Language Models\n(VLMs) have demonstrated human-like computer control capability. Despite their\nutility in advancing digital automation, a critical bottleneck persists:\ncollecting high-quality trajectory data for training. Common practices for\ncollecting such data rely on human supervision or synthetic data generation\nthrough executing pre-defined tasks, which are either resource-intensive or\nunable to guarantee data quality. Moreover, these methods suffer from limited\ndata diversity and significant gaps between synthetic data and real-world\nenvironments. To address these challenges, we propose OS-Genesis, a novel GUI\ndata synthesis pipeline that reverses the conventional trajectory collection\nprocess. Instead of relying on pre-defined tasks, OS-Genesis enables agents\nfirst to perceive environments and perform step-wise interactions, then\nretrospectively derive high-quality tasks to enable trajectory-level\nexploration. A trajectory reward model is then employed to ensure the quality\nof the generated trajectories. We demonstrate that training GUI agents with\nOS-Genesis significantly improves their performance on highly challenging\nonline benchmarks. In-depth analysis further validates OS-Genesis's efficiency\nand its superior data quality and diversity compared to existing synthesis\nmethods. Our codes, data, and checkpoints are available at\nhttps://qiushisun.github.io/OS-Genesis-Home/.",
      "tldr_zh": "论文提出 OS-Genesis，一种通过逆向任务合成（Reverse Task Synthesis）自动构建 GUI 代理轨迹的创新管道，旨在解决基于 Vision-Language Models (VLMs) 的 GUI 代理训练数据收集面临的资源密集、数据多样性不足和真实性差距问题。该方法让代理先感知环境并进行逐步交互，然后逆向推导出高质量任务，并使用轨迹奖励模型（trajectory reward model）来确保生成轨迹的质量。实验结果显示，使用 OS-Genesis 训练的代理在在线基准测试中性能显著提升，且其数据质量、多样性和效率均优于现有合成方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.19723v2",
      "published_date": "2024-12-27 16:21:58 UTC",
      "updated_date": "2025-04-30 08:23:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:02:28.411554"
    },
    {
      "arxiv_id": "2412.19718v1",
      "title": "Text2Insight: Transform natural language text into insights seamlessly using multi-model architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Pradeep Sain"
      ],
      "abstract": "The growing demand for dynamic, user-centric data analysis and visualization\nis evident across domains like healthcare, finance, and research. Traditional\nvisualization tools often fail to meet individual user needs due to their\nstatic and predefined nature. To address this gap, Text2Insight is introduced\nas an innovative solution that delivers customized data analysis and\nvisualizations based on user-defined natural language requirements. Leveraging\na multi-model architecture, Text2Insight transforms user inputs into actionable\ninsights and dynamic visualizations.\n  The methodology begins with analyzing the input dataset to extract structural\ndetails such as columns and values. A pre-trained Llama3 model converts the\nuser's natural language query into an SQL query, which is further refined using\na Named Entity Recognition (NER) model for accuracy. A chart predictor\ndetermines the most suitable visualization type, while the Llama3 model\ngenerates insights based on the SQL query's results. The output is a\nuser-friendly and visually informative chart. To enhance analysis capabilities,\nthe system integrates a question-answering model and a predictive model using\nthe BERT framework. These models provide insights into historical data and\npredict future trends.\n  Performance evaluation of Text2Insight demonstrates its effectiveness,\nachieving high accuracy (99%), precision (100%), recall (99%), and F1-score\n(99%), with a BLEU score of 0.5. The question-answering model attained an\naccuracy of 89% and the predictive model achieved 70% accuracy. These results\nvalidate Text2Insight as a robust and viable solution for transforming natural\nlanguage text into dynamic, user-specific data analysis and visualizations.",
      "tldr_zh": "该研究提出Text2Insight系统，利用多模型架构，将用户自然语言查询无缝转化为自定义数据分析和动态可视化，解决传统工具的静态局限问题。系统首先通过预训练的Llama3模型将查询转换为SQL语句，并使用Named Entity Recognition (NER)模型进行精炼，同时结合图表预测器选择合适的可视化类型。Llama3模型基于SQL结果生成洞见，并整合BERT框架的问答模型和预测模型，以提供历史数据分析和未来趋势预测。实验结果显示，Text2Insight在准确率（99%）、精确率（100%）、召回率（99%）和F1分数（99%）上表现出色，问答模型准确率达89%，预测模型准确率达70%，证明其在用户化数据洞见方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19718v1",
      "published_date": "2024-12-27 16:17:22 UTC",
      "updated_date": "2024-12-27 16:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:02:39.736870"
    },
    {
      "arxiv_id": "2412.19707v1",
      "title": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback",
      "title_zh": "翻译失败",
      "authors": [
        "Sijia Chen",
        "Baochun Li"
      ],
      "abstract": "Large language models (LLMs) have been routinely used to solve various tasks\nusing step-by-step reasoning. However, the structure of intermediate reasoning\nsteps, or thoughts, is rigid and unidirectional, such as chains, trees, or\nacyclic-directed graphs. Consequently, the resulting inflexible and\nforward-only reasoning may not address challenging tasks and fail when the LLM\nfrequently gives false responses, i.e., ``hallucinations''. This paper proposes\na new reasoning framework, called Thought Rollback (TR), allowing LLMs to\nadaptively build thought structure while maintaining effective reasoning toward\nproblem-solving under ``hallucinations''. The core mechanism of TR is rolling\nback thoughts, which allows LLMs to perform error analysis on thoughts, and\nthus roll back to any previously mistaken thought for revision. Subsequently,\nby including such trial-and-error in the prompt to guide the LLM, each rollback\nleads to one more reliable reasoning path. Therefore, starting with a simple\nprompt without human annotations, LLM with TR adaptively and gradually explores\nthoughts for a correct solution. Comprehensive experiments on mathematical\nproblems and multi-task reasoning demonstrate the state-of-the-art performance\nof TR in terms of problem-solving rate and interaction cost. For instance, the\nsolving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH\ndataset.",
      "tldr_zh": "本论文针对大语言模型 (LLMs) 在步步为营推理中存在的结构僵硬和单向问题（如链或树状结构），导致容易出现 hallucinations（幻觉）并影响任务解决，提出了一种新框架 Thought Rollback (TR)。TR 的核心机制允许 LLMs 通过错误分析回滚到之前的错误思想进行修正，并在提示中加入试错过程，以适应性地构建更可靠的推理路径，从而逐步探索正确解决方案。实验结果显示，TR 在数学问题（如 MATH 数据集上 GPT-4 解决率提升 9%）和多任务推理中，实现了最先进的性能，提高了问题解决率并降低了交互成本。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2024 camera-ready version with 24 pages and 12 figures. Code\n  repo with all prompts:\n  https://github.com/iQua/llmpebase/tree/main/examples/ThoughtRollback",
      "pdf_url": "http://arxiv.org/pdf/2412.19707v1",
      "published_date": "2024-12-27 16:02:34 UTC",
      "updated_date": "2024-12-27 16:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:02:51.365025"
    },
    {
      "arxiv_id": "2412.19696v1",
      "title": "An Integrated Optimization and Deep Learning Pipeline for Predicting Live Birth Success in IVF Using Feature Optimization and Transformer-Based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Arezoo Borji",
        "Hossam Haick",
        "Birgit Pohn",
        "Antonia Graf",
        "Jana Zakall",
        "S M Ragib Shahriar Islam",
        "Gernot Kronreif",
        "Daniel Kovatchki",
        "Heinz Strohmer",
        "Sepideh Hatamikia"
      ],
      "abstract": "In vitro fertilization (IVF) is a widely utilized assisted reproductive\ntechnology, yet predicting its success remains challenging due to the\nmultifaceted interplay of clinical, demographic, and procedural factors. This\nstudy develops a robust artificial intelligence (AI) pipeline aimed at\npredicting live birth outcomes in IVF treatments. The pipeline uses anonymized\ndata from 2010 to 2018, obtained from the Human Fertilization and Embryology\nAuthority (HFEA). We evaluated the prediction performance of live birth success\nas a binary outcome (success/failure) by integrating different feature\nselection methods, such as principal component analysis (PCA) and particle\nswarm optimization (PSO), with different traditional machine learning-based\nclassifiers including random forest (RF) and decision tree, as well as deep\nlearning-based classifiers including custom transformer-based model and a tab\ntransformer model with an attention mechanism. Our research demonstrated that\nthe best performance was achieved by combining PSO for feature selection with\nthe TabTransformer-based deep learning model, yielding an accuracy of 99.50%\nand an AUC of 99.96%, highlighting its significant performance to predict live\nbirths. This study establishes a highly accurate AI pipeline for predicting\nlive birth outcomes in IVF, demonstrating its potential to enhance personalized\nfertility treatments.",
      "tldr_zh": "本研究开发了一个集成优化和深度学习的AI管道，用于预测IVF治疗的活产成功率，旨在处理临床、人口统计和程序因素的复杂交互。管道结合了特征选择方法如PCA和PSO，与传统机器学习分类器（如RF和决策树）以及深度学习模型（如自定义Transformer和TabTransformer）进行整合。实验使用2010-2018年HFEA匿名数据，结果显示PSO特征选择结合TabTransformer模型取得了99.50%的准确率和99.96%的AUC，显著优于其他组合。该管道展示了在个性化生育治疗中提升预测准确性的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19696v1",
      "published_date": "2024-12-27 15:46:59 UTC",
      "updated_date": "2024-12-27 15:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:03:03.674941"
    },
    {
      "arxiv_id": "2412.19688v1",
      "title": "A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation",
      "title_zh": "人工智能与医学影像在IVF卵巢刺激中的整合综述",
      "authors": [
        "Jana Zakall",
        "Birgit Pohn",
        "Antonia Graf",
        "Daniel Kovatchki",
        "Arezoo Borji",
        "Ragib Shahriar Islam",
        "Hossam Haick",
        "Heinz Strohmer",
        "Sepideh Hatamikia"
      ],
      "abstract": "Artificial intelligence (AI) has emerged as a powerful tool to enhance\ndecision-making and optimize treatment protocols in in vitro fertilization\n(IVF). In particular, AI shows significant promise in supporting\ndecision-making during the ovarian stimulation phase of the IVF process. This\nreview evaluates studies focused on the applications of AI combined with\nmedical imaging in ovarian stimulation, examining methodologies, outcomes, and\ncurrent limitations. Our analysis of 13 studies on this topic reveals that,\nreveal that while AI algorithms demonstrated notable potential in predicting\noptimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the\nmedical imaging data utilized predominantly came from two-dimensional (2D)\nultrasound which mainly involved basic quantifications, such as follicle size\nand number, with limited use of direct feature extraction or advanced image\nanalysis techniques. This points to an underexplored opportunity where advanced\nimage analysis approaches, such as deep learning, and more diverse imaging\nmodalities, like three-dimensional (3D) ultrasound, could unlock deeper\ninsights. Additionally, the lack of explainable AI (XAI) in most studies raises\nconcerns about the transparency and traceability of AI-driven decisions - key\nfactors for clinical adoption and trust. Furthermore, many studies relied on\nsingle-center designs and small datasets, which limit the generalizability of\ntheir findings. This review highlights the need for integrating advanced\nimaging analysis techniques with explainable AI methodologies, as well as the\nimportance of leveraging multicenter collaborations and larger datasets.\nAddressing these gaps has the potential to enhance ovarian stimulation\nmanagement, paving the way for efficient, personalized, and data-driven\ntreatment pathways that improve IVF outcomes.",
      "tldr_zh": "这篇综述探讨了人工智能（AI）与医疗成像在体外受精（IVF）卵巢刺激阶段的整合，分析了13个相关研究，强调AI在预测激素剂量、触发时机和卵子取出结果方面的潜力，但主要依赖二维（2D）超声的基本量化如卵泡大小和数量。研究发现，高级图像分析技术（如deep learning）和三维（3D）超声的使用不足，以及缺乏可解释AI（XAI）透明度，导致AI决策的可追溯性和临床可采用性受限。许多研究依赖单中心和小数据集，进一步限制了结果的泛化性。该综述建议整合高级图像分析、XAI方法以及多中心合作和大样本数据，以实现更高效、个性化的IVF治疗路径并改善整体效果。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "29 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19688v1",
      "published_date": "2024-12-27 15:29:08 UTC",
      "updated_date": "2024-12-27 15:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:03:16.248335"
    },
    {
      "arxiv_id": "2412.19685v1",
      "title": "A Large-scale Interpretable Multi-modality Benchmark for Facial Image Forgery Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Jingchun Lian",
        "Lingyu Liu",
        "Yaxiong Wang",
        "Yujiao Wu",
        "Li Zhu",
        "Zhedong Zheng"
      ],
      "abstract": "Image forgery localization, which centers on identifying tampered pixels\nwithin an image, has seen significant advancements. Traditional approaches\noften model this challenge as a variant of image segmentation, treating the\nbinary segmentation of forged areas as the end product. We argue that the basic\nbinary forgery mask is inadequate for explaining model predictions. It doesn't\nclarify why the model pinpoints certain areas and treats all forged pixels the\nsame, making it hard to spot the most fake-looking parts. In this study, we\nmitigate the aforementioned limitations by generating salient region-focused\ninterpretation for the forgery images. To support this, we craft a Multi-Modal\nTramper Tracing (MMTT) dataset, comprising facial images manipulated using\ndeepfake techniques and paired with manual, interpretable textual annotations.\nTo harvest high-quality annotation, annotators are instructed to meticulously\nobserve the manipulated images and articulate the typical characteristics of\nthe forgery regions. Subsequently, we collect a dataset of 128,303 image-text\npairs. Leveraging the MMTT dataset, we develop ForgeryTalker, an architecture\ndesigned for concurrent forgery localization and interpretation. ForgeryTalker\nfirst trains a forgery prompter network to identify the pivotal clues within\nthe explanatory text. Subsequently, the region prompter is incorporated into\nmultimodal large language model for finetuning to achieve the dual goals of\nlocalization and interpretation. Extensive experiments conducted on the MMTT\ndataset verify the superior performance of our proposed model. The dataset,\ncode as well as pretrained checkpoints will be made publicly available to\nfacilitate further research and ensure the reproducibility of our results.",
      "tldr_zh": "本研究针对图像篡改定位的局限性，提出了一种可解释的多模态基准，强调生成针对伪造区域的显著焦点解释，以弥补传统二进制伪造掩码的不足。研究者构建了Multi-Modal Tramper Tracing (MMTT)数据集，包含128,303对使用deepfake技术操纵的面部图像及其手动文本注释，旨在通过详细观察和描述伪造区域特征来提升可解释性。基于此数据集，他们开发了ForgeryTalker架构，该模型先训练forgery prompter网络识别解释文本的关键线索，然后将其整合到多模态大型语言模型中，实现伪造定位和解释的双重功能。实验结果显示，ForgeryTalker在MMTT数据集上表现出色，验证了其优越性能，且数据集、代码和预训练检查点将公开可用以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures, 4 tabels",
      "pdf_url": "http://arxiv.org/pdf/2412.19685v1",
      "published_date": "2024-12-27 15:23:39 UTC",
      "updated_date": "2024-12-27 15:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:03:28.462082"
    },
    {
      "arxiv_id": "2412.19684v2",
      "title": "Boosting Private Domain Understanding of Efficient MLLMs: A Tuning-free, Adaptive, Universal Prompt Optimization Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Jiang Liu",
        "Bolin Li",
        "Haoyuan Li",
        "Tianwei Lin",
        "Wenqiao Zhang",
        "Tao Zhong",
        "Zhelun Yu",
        "Jinghao Wei",
        "Hao Cheng",
        "Wanggui He",
        "Fangxun Shu",
        "Hao Jiang",
        "Zheqi Lv",
        "Juncheng Li",
        "Siliang Tang",
        "Yueting Zhuang"
      ],
      "abstract": "Efficient multimodal large language models (EMLLMs), in contrast to\nmultimodal large language models (MLLMs), reduce model size and computational\ncosts and are often deployed on resource-constrained devices. However, due to\ndata privacy concerns, existing open-source EMLLMs rarely have access to\nprivate domain-specific data during the pre-training process, making them\ndifficult to directly apply in device-specific domains, such as certain\nbusiness scenarios. To address this weakness, this paper focuses on the\nefficient adaptation of EMLLMs to private domains, specifically in two areas:\n1) how to reduce data requirements, and 2) how to avoid parameter fine-tuning.\nSpecifically, we propose a tun\\textbf{\\underline{I}}ng-free,\na\\textbf{\\underline{D}}aptiv\\textbf{\\underline{E}},\nunivers\\textbf{\\underline{AL}} \\textbf{\\underline{Prompt}} Optimization\nFramework, abbreviated as \\textit{\\textbf{\\ourmethod{}}} which consists of two\nstages: 1) Predefined Prompt, based on the reinforcement searching strategy,\ngenerate a prompt optimization strategy tree to acquire optimization priors; 2)\nPrompt Reflection initializes the prompt based on optimization priors, followed\nby self-reflection to further search and refine the prompt. By doing so,\n\\ourmethod{} elegantly generates the ``ideal prompts'' for processing private\ndomain-specific data. Note that our method requires no parameter fine-tuning\nand only a small amount of data to quickly adapt to the data distribution of\nprivate data. Extensive experiments across multiple tasks demonstrate that our\nproposed \\ourmethod{} significantly improves both efficiency and performance\ncompared to baselines.",
      "tldr_zh": "该研究针对高效多模态大语言模型(EMLLMs)难以直接应用于私有领域的问题，提出了一种tuning-free、adaptive、universal的提示优化框架（IDEAL Prompt）。该框架分为两个阶段：首先，通过强化搜索策略生成预定义提示（Predefined Prompt）优化策略树，以获取优化先验；其次，基于这些先验初始化提示，并通过自反省（Prompt Reflection）进一步搜索和精炼提示，从而高效处理私有领域数据。IDEAL Prompt 无需参数微调，仅需少量数据即可快速适应私有数据分布，并在多个任务上显著提升了效率和性能，优于基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19684v2",
      "published_date": "2024-12-27 15:21:17 UTC",
      "updated_date": "2025-02-17 15:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:03:39.804151"
    },
    {
      "arxiv_id": "2412.19663v1",
      "title": "CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Wang",
        "Cailian Chen",
        "Xinyi Le",
        "Qimin Xu",
        "Lei Xu",
        "Yanzhou Zhang",
        "Jie Yang"
      ],
      "abstract": "Computer-aided design (CAD) significantly enhances the efficiency, accuracy,\nand innovation of design processes by enabling precise 2D and 3D modeling,\nextensive analysis, and optimization. Existing methods for creating CAD models\nrely on latent vectors or point clouds, which are difficult to obtain and\ncostly to store. Recent advances in Multimodal Large Language Models (MLLMs)\nhave inspired researchers to use natural language instructions and images for\nCAD model construction. However, these models still struggle with inferring\naccurate 3D spatial location and orientation, leading to inaccuracies in\ndetermining the spatial 3D starting points and extrusion directions for\nconstructing geometries. This work introduces CAD-GPT, a CAD synthesis method\nwith spatial reasoning-enhanced MLLM that takes either a single image or a\ntextual description as input. To achieve precise spatial inference, our\napproach introduces a 3D Modeling Spatial Mechanism. This method maps 3D\nspatial positions and 3D sketch plane rotation angles into a 1D linguistic\nfeature space using a specialized spatial unfolding mechanism, while\ndiscretizing 2D sketch coordinates into an appropriate planar space to enable\nprecise determination of spatial starting position, sketch orientation, and 2D\nsketch coordinate translations. Extensive experiments demonstrate that CAD-GPT\nconsistently outperforms existing state-of-the-art methods in CAD model\nsynthesis, both quantitatively and qualitatively.",
      "tldr_zh": "本研究提出 CAD-GPT，一种基于空间推理增强的多模态大型语言模型（MLLMs），用于从单张图像或文本描述合成 CAD 模型构建序列，以解决现有方法在推断 3D 空间位置和方向上的不准确问题。CAD-GPT 引入 3D Modeling Spatial Mechanism，将 3D 空间位置和旋转角度映射到 1D 语言特征空间，并离散化 2D 草图坐标，以精确确定空间起始位置、草图方向和坐标转换。实验结果表明，CAD-GPT 在定量和定性方面均优于现有最先进方法，提升了 CAD 模型合成的效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19663v1",
      "published_date": "2024-12-27 14:19:36 UTC",
      "updated_date": "2024-12-27 14:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:03:51.844660"
    },
    {
      "arxiv_id": "2412.19646v1",
      "title": "Chimera: A Block-Based Neural Architecture Search Framework for Event-Based Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Diego A. Silva",
        "Ahmed Elsheikh",
        "Kamilya Smagulova",
        "Mohammed E. Fouda",
        "Ahmed M. Eltawil"
      ],
      "abstract": "Event-based cameras are sensors that simulate the human eye, offering\nadvantages such as high-speed robustness and low power consumption. Established\nDeep Learning techniques have shown effectiveness in processing event data.\nChimera is a Block-Based Neural Architecture Search (NAS) framework\nspecifically designed for Event-Based Object Detection, aiming to create a\nsystematic approach for adapting RGB-domain processing methods to the event\ndomain. The Chimera design space is constructed from various macroblocks,\nincluding Attention blocks, Convolutions, State Space Models, and\nMLP-mixer-based architectures, which provide a valuable trade-off between local\nand global processing capabilities, as well as varying levels of complexity.\nThe results on the PErson Detection in Robotics (PEDRo) dataset demonstrated\nperformance levels comparable to leading state-of-the-art models, alongside an\naverage parameter reduction of 1.6 times.",
      "tldr_zh": "该论文提出Chimera，一种基于块级的Neural Architecture Search (NAS) 框架，专门针对Event-Based Object Detection设计，以系统地将RGB域处理方法适应到事件域。Chimera的设计空间包括Attention blocks、Convolutions、State Space Models和MLP-mixer-based architectures等宏块，提供局部与全局处理能力的平衡以及不同复杂性水平。在PEDRo数据集上的实验结果显示，Chimera的性能与最先进模型相当，同时平均参数减少1.6倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19646v1",
      "published_date": "2024-12-27 13:50:44 UTC",
      "updated_date": "2024-12-27 13:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:05:56.538193"
    },
    {
      "arxiv_id": "2412.19638v1",
      "title": "Xmodel-2 Technical Report",
      "title_zh": "Xmodel-2 技术报告",
      "authors": [
        "Wang Qun",
        "Liu Yang",
        "Lin Qingquan",
        "Qu Zhijiu",
        "Jiang Ling"
      ],
      "abstract": "Xmodel-2 is a 1.2-billion-parameter large language model designed\nspecifically for reasoning tasks. Its architecture enables different model\nscales to share a unified set of hyperparameters, allowing for extensive\nexperimentation on smaller models and seamless transfer of optimal\nconfigurations to larger models. To maximize training efficiency and stability,\nXmodel-2 employs the WSD learning rate scheduler from MiniCPM. Pretrained on\n1.5 trillion tokens from diverse sources, Xmodel-2 achieves state-of-the-art\nperformance in complex reasoning and agent-based tasks, while maintaining low\ntraining costs. These results highlight the potential of efficient model design\nand training strategies in advancing reasoning capabilities. Model checkpoints\nand code are publicly available on GitHub at\nhttps://github.com/XiaoduoAILab/Xmodel-2",
      "tldr_zh": "Xmodel-2 是一个 1.2 亿参数的大型语言模型（LLM），专门设计用于推理任务，其架构支持不同规模模型共享统一超参数，从而便于在小模型上进行广泛实验并无缝转移到大模型。模型采用 WSD 学习率调度器进行训练，在 1.5 万亿 tokens 的多样化数据上预训练，确保了高效和稳定的训练过程。Xmodel-2 在复杂推理和代理任务上实现了 state-of-the-art 性能，同时保持了低训练成本，并已在 GitHub 上公开模型检查点和代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19638v1",
      "published_date": "2024-12-27 13:32:10 UTC",
      "updated_date": "2024-12-27 13:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:04:16.221177"
    },
    {
      "arxiv_id": "2412.19616v2",
      "title": "Gradient Weight-normalized Low-rank Projection for Efficient LLM Training",
      "title_zh": "梯度权重归一化的低秩投影用于高效LLM训练",
      "authors": [
        "Jia-Hong Huang",
        "Yixian Shen",
        "Hongyi Zhu",
        "Stevan Rudinac",
        "Evangelos Kanoulas"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable performance across various\ntasks, but the escalating demands on computational resources pose significant\nchallenges, particularly in the extensive utilization of full fine-tuning for\ndownstream tasks. To address this, parameter-efficient fine-tuning (PEFT)\nmethods have been developed, but they often underperform compared to full\nfine-tuning and struggle with memory efficiency. In this work, we introduce\nGradient Weight-Normalized Low-Rank Projection (GradNormLoRP), a novel approach\nthat enhances both parameter and memory efficiency while maintaining comparable\nperformance to full fine-tuning. GradNormLoRP normalizes the weight matrix to\nimprove gradient conditioning, facilitating better convergence during\noptimization. Additionally, it applies low-rank approximations to the weight\nand gradient matrices, significantly reducing memory usage during training.\nExtensive experiments demonstrate that our 8-bit GradNormLoRP reduces optimizer\nmemory usage by up to 89.5% and enables the pre-training of large LLMs, such as\nLLaMA 7B, on consumer-level GPUs like the NVIDIA RTX 4090, without additional\ninference costs. Moreover, GradNormLoRP outperforms existing low-rank methods\nin fine-tuning tasks. For instance, when fine-tuning the RoBERTa model on all\nGLUE tasks with a rank of 8, GradNormLoRP achieves an average score of 80.65,\nsurpassing LoRA's score of 79.23. These results underscore GradNormLoRP as a\npromising alternative for efficient LLM pre-training and fine-tuning. Source\ncode:\nhttps://github.com/Jhhuangkay/Gradient-Weight-normalized-Low-rank-Projection-for-Efficient-LLM-Training",
      "tldr_zh": "本研究提出了一种名为 Gradient Weight-Normalized Low-Rank Projection (GradNormLoRP) 的新方法，用于提升大型语言模型 (LLMs) 训练的效率，以解决全量微调 (full fine-tuning) 的高计算资源需求问题。GradNormLoRP 通过对权重矩阵进行归一化改善梯度条件，并应用低秩近似到权重和梯度矩阵，从而显著降低内存使用，同时保持与全量微调相当的性能。实验显示，8-bit GradNormLoRP 可将优化器内存使用减少高达89.5%，并在消费级 GPU 如 NVIDIA RTX 4090 上成功预训练 LLaMA 7B 模型；在微调任务中（如 GLUE 任务上 RoBERTa 模型的平均分数达80.65，高于 LoRA 的79.23），它超越了现有低秩方法，提供了一个高效的 LLM 预训练和微调替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25) [Main Technical Track]",
      "pdf_url": "http://arxiv.org/pdf/2412.19616v2",
      "published_date": "2024-12-27 12:23:39 UTC",
      "updated_date": "2025-01-05 07:12:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:06:09.195818"
    },
    {
      "arxiv_id": "2412.19609v1",
      "title": "Bidding Games on Markov Decision Processes with Quantitative Reachability Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Avni",
        "Martin Kurečka",
        "Kaushik Mallik",
        "Petr Novotný",
        "Suman Sadhukhan"
      ],
      "abstract": "Graph games are fundamental in strategic reasoning of multi-agent systems and\ntheir environments. We study a new family of graph games which combine\nstochastic environmental uncertainties and auction-based interactions among the\nagents, formalized as bidding games on (finite) Markov decision processes\n(MDP). Normally, on MDPs, a single decision-maker chooses a sequence of\nactions, producing a probability distribution over infinite paths. In bidding\ngames on MDPs, two players -- called the reachability and safety players -- bid\nfor the privilege of choosing the next action at each step. The reachability\nplayer's goal is to maximize the probability of reaching a target vertex,\nwhereas the safety player's goal is to minimize it. These games generalize\ntraditional bidding games on graphs, and the existing analysis techniques do\nnot extend. For instance, the central property of traditional bidding games is\nthe existence of a threshold budget, which is a necessary and sufficient budget\nto guarantee winning for the reachability player. For MDPs, the threshold\nbecomes a relation between the budgets and probabilities of reaching the\ntarget. We devise value-iteration algorithms that approximate thresholds and\noptimal policies for general MDPs, and compute the exact solutions for acyclic\nMDPs, and show that finding thresholds is at least as hard as solving\nsimple-stochastic games.",
      "tldr_zh": "这篇论文研究了在 Markov Decision Processes (MDP) 上基于竞标的游戏，结合了随机环境不确定性和代理互动，其中 reachability player 目标是最大化到达目标顶点的概率，而 safety player 目标是最小化该概率。论文扩展了传统 bidding games 的框架，将阈值预算转化为 budgets 和 probabilities 之间的关系，并开发了 value-iteration algorithms 来近似阈值和最优策略。针对 acyclic MDPs，该算法能精确计算解决方案。最后，论文证明了计算阈值的问题至少与解决 simple-stochastic games 一样困难，为多代理系统战略推理提供了新洞见。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "To appear in AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19609v1",
      "published_date": "2024-12-27 12:10:00 UTC",
      "updated_date": "2024-12-27 12:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:06:20.366830"
    },
    {
      "arxiv_id": "2412.19595v1",
      "title": "SocRATES: Towards Automated Scenario-based Testing of Social Navigation Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Rao Marpally",
        "Pranav Goyal",
        "Harold Soh"
      ],
      "abstract": "Current social navigation methods and benchmarks primarily focus on proxemics\nand task efficiency. While these factors are important, qualitative aspects\nsuch as perceptions of a robot's social competence are equally crucial for\nsuccessful adoption and integration into human environments. We propose a more\ncomprehensive evaluation of social navigation through scenario-based testing,\nwhere specific human-robot interaction scenarios can reveal key robot\nbehaviors. However, creating such scenarios is often labor-intensive and\ncomplex. In this work, we address this challenge by introducing a pipeline that\nautomates the generation of context-, and location-appropriate social\nnavigation scenarios, ready for simulation. Our pipeline transforms simple\nscenario metadata into detailed textual scenarios, infers pedestrian and robot\ntrajectories, and simulates pedestrian behaviors, which enables more controlled\nevaluation. We leverage the social reasoning and code-generation capabilities\nof Large Language Models (LLMs) to streamline scenario generation and\ntranslation. Our experiments show that our pipeline produces realistic\nscenarios and significantly improves scenario translation over naive LLM\nprompting. Additionally, we present initial feedback from a usability study\nwith social navigation experts and a case-study demonstrating a scenario-based\nevaluation of three navigation algorithms.",
      "tldr_zh": "该论文提出SocRATES框架，旨在通过基于场景的测试更全面评估社会导航算法，不仅关注proxemics和任务效率，还强调机器人社会能力的感知。研究引入一个自动化管道，利用Large Language Models (LLMs)的社会推理和代码生成能力，将简单场景元数据转换为详细文本场景、推断轨迹并模拟行人行为，从而简化场景生成过程。实验结果显示，该管道产生更真实的场景，并显著优于简单LLM提示方法；此外，通过专家可用性研究和案例分析，证明了其在评估多种导航算法中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19595v1",
      "published_date": "2024-12-27 11:33:19 UTC",
      "updated_date": "2024-12-27 11:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:06:32.675345"
    },
    {
      "arxiv_id": "2412.19589v1",
      "title": "ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes and Attention-based Feature Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Minghui Li",
        "Zikang Guo",
        "Yang Wu",
        "Peijin Guo",
        "Yao Shi",
        "Shengshan Hu",
        "Wei Wan",
        "Shengqing Hu"
      ],
      "abstract": "Drug-target interaction is fundamental in understanding how drugs affect\nbiological systems, and accurately predicting drug-target affinity (DTA) is\nvital for drug discovery. Recently, deep learning methods have emerged as a\nsignificant approach for estimating the binding strength between drugs and\ntarget proteins. However, existing methods simply utilize the drug's local\ninformation from molecular topology rather than global information.\nAdditionally, the features of drugs and proteins are usually fused with a\nsimple concatenation operation, limiting their effectiveness. To address these\nchallenges, we proposed ViDTA, an enhanced DTA prediction framework. We\nintroduce virtual nodes into the Graph Neural Network (GNN)-based drug feature\nextraction network, which acts as a global memory to exchange messages more\nefficiently. By incorporating virtual graph nodes, we seamlessly integrate\nlocal and global features of drug molecular structures, expanding the GNN's\nreceptive field. Additionally, we propose an attention-based linear feature\nfusion network for better capturing the interaction information between drugs\nand proteins. Experimental results evaluated on various benchmarks including\nDavis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms the\nstate-of-the-art baselines.",
      "tldr_zh": "本文提出 ViDTA 框架，以提升药物-靶点亲和力 (DTA) 预测的准确性，解决现有方法忽略药物分子全局信息和特征融合简单的问题。ViDTA 在 Graph Neural Network (GNN) 基于的药物特征提取网络中引入虚拟节点，作为全局记忆来整合局部和全局特征，从而扩展 GNN 的感受野。同时，该框架采用注意力-based 线性特征融合网络，更有效地捕捉药物和蛋白质之间的交互信息。在 Davis、Metz 和 KIBA 等基准数据集上的实验结果表明，ViDTA 优于现有最先进基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Conference on Bioinformatics and\n  Biomedicine (BIBM 24)",
      "pdf_url": "http://arxiv.org/pdf/2412.19589v1",
      "published_date": "2024-12-27 11:19:10 UTC",
      "updated_date": "2024-12-27 11:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:06:44.991468"
    },
    {
      "arxiv_id": "2412.19583v1",
      "title": "A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models",
      "title_zh": "翻译失败",
      "authors": [
        "Omar M. Safa",
        "Mahmoud M. Abdelaziz",
        "Mustafa Eltawy",
        "Mohamed Mamdouh",
        "Moamen Gharib",
        "Salaheldin Eltenihy",
        "Nagia M. Ghanem",
        "Mohamed M. Ismail"
      ],
      "abstract": "Machine Unlearning has emerged as a critical area in artificial intelligence,\naddressing the need to selectively remove learned data from machine learning\nmodels in response to data privacy regulations. This paper provides a\ncomprehensive comparative analysis of six state-of-theart unlearning techniques\napplied to image and text classification tasks. We evaluate their performance,\nefficiency, and compliance with regulatory requirements, highlighting their\nstrengths and limitations in practical scenarios. By systematically analyzing\nthese methods, we aim to provide insights into their applicability,\nchallenges,and tradeoffs, fostering advancements in the field of ethical and\nadaptable machine learning.",
      "tldr_zh": "本研究对六种最先进的Machine Unlearning技术进行了全面比较，这些技术应用于图像和文本分类模型，以应对数据隐私法规的要求。论文评估了这些方法的性能、效率和合规性，并分析了它们的优势、局限性以及实际应用中的权衡。最终，该工作提供了宝贵的见解，帮助推动Machine Unlearning领域的发展，促进更具道德性和适应性的机器学习实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19583v1",
      "published_date": "2024-12-27 10:58:55 UTC",
      "updated_date": "2024-12-27 10:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:06:55.727714"
    },
    {
      "arxiv_id": "2412.19578v1",
      "title": "Graph-attention-based Casual Discovery with Trust Region-navigated Clipping Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shixuan Liu",
        "Yanghe Feng",
        "Keyu Wu",
        "Guangquan Cheng",
        "Jincai Huang",
        "Zhong Liu"
      ],
      "abstract": "In many domains of empirical sciences, discovering the causal structure\nwithin variables remains an indispensable task. Recently, to tackle with\nunoriented edges or latent assumptions violation suffered by conventional\nmethods, researchers formulated a reinforcement learning (RL) procedure for\ncausal discovery, and equipped REINFORCE algorithm to search for the\nbest-rewarded directed acyclic graph. The two keys to the overall performance\nof the procedure are the robustness of RL methods and the efficient encoding of\nvariables. However, on the one hand, REINFORCE is prone to local convergence\nand unstable performance during training. Neither trust region policy\noptimization, being computationally-expensive, nor proximal policy optimization\n(PPO), suffering from aggregate constraint deviation, is decent alternative for\ncombinatory optimization problems with considerable individual subactions. We\npropose a trust region-navigated clipping policy optimization method for causal\ndiscovery that guarantees both better search efficiency and steadiness in\npolicy optimization, in comparison with REINFORCE, PPO and our prioritized\nsampling-guided REINFORCE implementation. On the other hand, to boost the\nefficient encoding of variables, we propose a refined graph attention encoder\ncalled SDGAT that can grasp more feature information without priori\nneighbourhood information. With these improvements, the proposed method\noutperforms former RL method in both synthetic and benchmark datasets in terms\nof output results and optimization robustness.",
      "tldr_zh": "该论文针对经验科学领域中因果结构发现的问题，提出了一种基于强化学习(RL)的框架，以解决传统方法如未定向边和潜在假设违反的挑战。论文引入Trust Region-navigated Clipping Policy Optimization方法，结合SDGAT图注意力编码器，提升了策略优化的效率和稳定性，同时无需先验邻居信息即可捕捉更多变量特征。在合成和基准数据集的实验中，该方法在输出结果和优化鲁棒性方面均优于REINFORCE和PPO等基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19578v1",
      "published_date": "2024-12-27 10:50:43 UTC",
      "updated_date": "2024-12-27 10:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:07:09.819286"
    },
    {
      "arxiv_id": "2412.19562v1",
      "title": "Hindsight Planner: A Closed-Loop Few-Shot Planner for Embodied Instruction Following",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiao Yang",
        "Shenao Zhang",
        "Zhihan Liu",
        "Huaxiu Yao",
        "Zhaoran Wang"
      ],
      "abstract": "This work focuses on building a task planner for Embodied Instruction\nFollowing (EIF) using Large Language Models (LLMs). Previous works typically\ntrain a planner to imitate expert trajectories, treating this as a supervised\ntask. While these methods achieve competitive performance, they often lack\nsufficient robustness. When a suboptimal action is taken, the planner may\nencounter an out-of-distribution state, which can lead to task failure. In\ncontrast, we frame the task as a Partially Observable Markov Decision Process\n(POMDP) and aim to develop a robust planner under a few-shot assumption. Thus,\nwe propose a closed-loop planner with an adaptation module and a novel\nhindsight method, aiming to use as much information as possible to assist the\nplanner. Our experiments on the ALFRED dataset indicate that our planner\nachieves competitive performance under a few-shot assumption. For the first\ntime, our few-shot agent's performance approaches and even surpasses that of\nthe full-shot supervised agent.",
      "tldr_zh": "这篇论文针对Embodied Instruction Following (EIF)任务，提出了一种闭环few-shot规划器Hindsight Planner，使用Large Language Models (LLMs)将任务建模为Partially Observable Markov Decision Process (POMDP)，以提升规划器的鲁棒性并减少对专家轨迹的依赖。该规划器引入了适应模块和一个新颖的hindsight方法，允许代理在执行过程中利用更多信息来纠正子优行动。在ALFRED数据集的实验中，该few-shot代理的性能首次接近甚至超过了full-shot监督代理，展示了其在资源有限场景下的竞争优势。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19562v1",
      "published_date": "2024-12-27 10:05:45 UTC",
      "updated_date": "2024-12-27 10:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:07:23.186922"
    },
    {
      "arxiv_id": "2412.19550v1",
      "title": "Learning states enhanced knowledge tracing: Simulating the diversity in real-world learning process",
      "title_zh": "学习状态增强知识追踪：模拟真实世界学习过程中的多样性",
      "authors": [
        "Shanshan Wang",
        "Xueying Zhang",
        "Keyang Wang",
        "Xun Yang",
        "Xingyi Zhang"
      ],
      "abstract": "The Knowledge Tracing (KT) task focuses on predicting a learner's future\nperformance based on the historical interactions. The knowledge state plays a\nkey role in learning process. However, considering that the knowledge state is\ninfluenced by various learning factors in the interaction process, such as the\nexercises similarities, responses reliability and the learner's learning state.\nPrevious models still face two major limitations. First, due to the exercises\ndifferences caused by various complex reasons and the unreliability of\nresponses caused by guessing behavior, it is hard to locate the historical\ninteraction which is most relevant to the current answered exercise. Second,\nthe learning state is also a key factor to influence the knowledge state, which\nis always ignored by previous methods. To address these issues, we propose a\nnew method named Learning State Enhanced Knowledge Tracing (LSKT). Firstly, to\nsimulate the potential differences in interactions, inspired by Item Response\nTheory~(IRT) paradigm, we designed three different embedding methods ranging\nfrom coarse-grained to fine-grained views and conduct comparative analysis on\nthem. Secondly, we design a learning state extraction module to capture the\nchanging learning state during the learning process of the learner. In turn,\nwith the help of the extracted learning state, a more detailed knowledge state\ncould be captured. Experimental results on four real-world datasets show that\nour LSKT method outperforms the current state-of-the-art methods.",
      "tldr_zh": "该论文针对知识追踪 (KT) 任务提出了一种新方法 Learning State Enhanced Knowledge Tracing (LSKT)，旨在模拟真实学习过程中的多样性，如练习相似性、响应可靠性和学习者状态的影响，以更准确预测学习者的未来表现。LSKT 受 Item Response Theory (IRT) 启发，设计了三种从粗到细粒度的嵌入方法来处理历史互动差异，并引入学习状态提取模块来捕获学习过程中的动态变化，从而获得更详细的知识状态。实验结果显示，在四个真实数据集上，LSKT 优于现有最先进方法，证明了其在提升 KT 准确性方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19550v1",
      "published_date": "2024-12-27 09:41:25 UTC",
      "updated_date": "2024-12-27 09:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:07:33.385581"
    },
    {
      "arxiv_id": "2412.19869v1",
      "title": "A Fully Hardware Implemented Accelerator Design in ReRAM Analog Computing without ADCs",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Dang",
        "Huawei Li",
        "Wei Wang"
      ],
      "abstract": "Emerging ReRAM-based accelerators process neural networks via analog\nComputing-in-Memory (CiM) for ultra-high energy efficiency. However,\nsignificant overhead in peripheral circuits and complex nonlinear activation\nmodes constrain system energy efficiency improvements. This work explores the\nhardware implementation of the Sigmoid and SoftMax activation functions of\nneural networks with stochastically binarized neurons by utilizing sampled\nnoise signals from ReRAM devices to achieve a stochastic effect. We propose a\ncomplete ReRAM-based Analog Computing Accelerator (RACA) that accelerates\nneural network computation by leveraging stochastically binarized neurons in\ncombination with ReRAM crossbars. The novel circuit design removes significant\nsources of energy/area efficiency degradation, i.e., the Digital-to-Analog and\nAnalog-to-Digital Converters (DACs and ADCs) as well as the components to\nexplicitly calculate the activation functions. Experimental results show that\nour proposed design outperforms traditional architectures across all overall\nperformance metrics without compromising inference accuracy.",
      "tldr_zh": "该研究提出了一种基于 ReRAM 的模拟计算加速器（RACA），通过利用 ReRAM 设备的采样噪声信号实现随机二值化神经元，从而处理神经网络的 Sigmoid 和 SoftMax 激活函数，而无需使用 ADCs 和 DACs 等组件。相比传统架构，该设计显著降低了外围电路开销，提高了能量和面积效率。实验结果显示，RACA 在所有整体性能指标上表现出色，同时不影响推理准确性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19869v1",
      "published_date": "2024-12-27 09:38:19 UTC",
      "updated_date": "2024-12-27 09:38:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:07:44.230783"
    },
    {
      "arxiv_id": "2412.19544v1",
      "title": "TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Huang",
        "Jiayu Shen",
        "Shanshan Huang",
        "Sitao Cheng",
        "Xiaxia Wang",
        "Yuzhong Qu"
      ],
      "abstract": "Semantic parsing, which converts natural language questions into logic forms,\nplays a crucial role in reasoning within structured environments. However,\nexisting methods encounter two significant challenges: reliance on extensive\nmanually annotated datasets and limited generalization capability to unseen\nexamples. To tackle these issues, we propose Targeted Synthetic Data Generation\n(TARGA), a practical framework that dynamically generates high-relevance\nsynthetic data without manual annotation. Starting from the pertinent entities\nand relations of a given question, we probe for the potential relevant queries\nthrough layer-wise expansion and cross-layer combination. Then we generate\ncorresponding natural language questions for these constructed queries to\njointly serve as the synthetic demonstrations for in-context learning.\nExperiments on multiple knowledge base question answering (KBQA) datasets\ndemonstrate that TARGA, using only a 7B-parameter model, substantially\noutperforms existing non-fine-tuned methods that utilize close-sourced model,\nachieving notable improvements in F1 scores on GrailQA(+7.7) and\nKBQA-Agent(+12.2). Furthermore, TARGA also exhibits superior sample efficiency,\nrobustness, and generalization capabilities under non-I.I.D. settings.",
      "tldr_zh": "本论文提出 TARGA，一种针对语义解析（semantic parsing）的合成数据生成框架，旨在解决现有方法依赖手动标注数据集和泛化能力不足的问题。TARGA 通过从给定问题的相关实体和关系出发，进行层-wise 扩展和跨层组合来动态生成高相关性合成数据，并为这些查询创建自然语言问题作为 in-context learning 的演示。实验结果显示，在多个知识库问答（KBQA）数据集上，使用仅 7B 参数模型的 TARGA 比非微调方法 F1 分数显著提升（如 GrailQA +7.7 和 KBQA-Agent +12.2），并表现出优异的样本效率、鲁棒性和非 I.I.D. 环境下的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19544v1",
      "published_date": "2024-12-27 09:16:39 UTC",
      "updated_date": "2024-12-27 09:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:07:58.329123"
    },
    {
      "arxiv_id": "2412.19542v2",
      "title": "Interacted Object Grounding in Spatio-Temporal Human-Object Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Liu",
        "Boran Wen",
        "Xinpeng Liu",
        "Zizheng Zhou",
        "Hongwei Fan",
        "Cewu Lu",
        "Lizhuang Ma",
        "Yulong Chen",
        "Yong-Lu Li"
      ],
      "abstract": "Spatio-temporal Human-Object Interaction (ST-HOI) understanding aims at\ndetecting HOIs from videos, which is crucial for activity understanding.\nHowever, existing whole-body-object interaction video benchmarks overlook the\ntruth that open-world objects are diverse, that is, they usually provide\nlimited and predefined object classes. Therefore, we introduce a new open-world\nbenchmark: Grounding Interacted Objects (GIO) including 1,098 interacted\nobjects class and 290K interacted object boxes annotation. Accordingly, an\nobject grounding task is proposed expecting vision systems to discover\ninteracted objects. Even though today's detectors and grounding methods have\nsucceeded greatly, they perform unsatisfactorily in localizing diverse and rare\nobjects in GIO. This profoundly reveals the limitations of current vision\nsystems and poses a great challenge. Thus, we explore leveraging\nspatio-temporal cues to address object grounding and propose a 4D\nquestion-answering framework (4D-QA) to discover interacted objects from\ndiverse videos. Our method demonstrates significant superiority in extensive\nexperiments compared to current baselines. Data and code will be publicly\navailable at https://github.com/DirtyHarryLYL/HAKE-AVA.",
      "tldr_zh": "本论文针对 Spatio-Temporal Human-Object Interactions (ST-HOI) 理解中的对象多样性问题，引入了一个新的开放世界基准 Grounding Interacted Objects (GIO)，包含1,098个互动对象类别和290K个对象框标注，并提出对象 grounding 任务以发现视频中的互动对象。论文探索利用时空线索，开发了4D Question-Answering (4D-QA) 框架，通过问题回答机制来定位多样化和稀有对象。实验结果显示，该方法在GIO基准上显著优于现有基线，数据和代码将在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the Proceedings of AAAI 2025. The first three\n  authors contributed equally. Project:\n  https://github.com/DirtyHarryLYL/HAKE-AVA",
      "pdf_url": "http://arxiv.org/pdf/2412.19542v2",
      "published_date": "2024-12-27 09:08:46 UTC",
      "updated_date": "2025-02-23 10:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:08:12.221172"
    },
    {
      "arxiv_id": "2412.19538v1",
      "title": "Scalable Hierarchical Reinforcement Learning for Hyper Scale Multi-Robot Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Zhou",
        "Xiang Shi",
        "Lele Zhang",
        "Chen Chen",
        "Hongbo Li",
        "Lin Ma",
        "Fang Deng",
        "Jie Chen"
      ],
      "abstract": "To improve the efficiency of warehousing system and meet huge customer\norders, we aim to solve the challenges of dimension disaster and dynamic\nproperties in hyper scale multi-robot task planning (MRTP) for robotic mobile\nfulfillment system (RMFS). Existing research indicates that hierarchical\nreinforcement learning (HRL) is an effective method to reduce these challenges.\nBased on that, we construct an efficient multi-stage HRL-based multi-robot task\nplanner for hyper scale MRTP in RMFS, and the planning process is represented\nwith a special temporal graph topology. To ensure optimality, the planner is\ndesigned with a centralized architecture, but it also brings the challenges of\nscaling up and generalization that require policies to maintain performance for\nvarious unlearned scales and maps. To tackle these difficulties, we first\nconstruct a hierarchical temporal attention network (HTAN) to ensure basic\nability of handling inputs with unfixed lengths, and then design multi-stage\ncurricula for hierarchical policy learning to further improve the scaling up\nand generalization ability while avoiding catastrophic forgetting.\nAdditionally, we notice that policies with hierarchical structure suffer from\nunfair credit assignment that is similar to that in multi-agent reinforcement\nlearning, inspired of which, we propose a hierarchical reinforcement learning\nalgorithm with counterfactual rollout baseline to improve learning performance.\nExperimental results demonstrate that our planner outperform other\nstate-of-the-art methods on various MRTP instances in both simulated and\nreal-world RMFS. Also, our planner can successfully scale up to hyper scale\nMRTP instances in RMFS with up to 200 robots and 1000 retrieval racks on\nunlearned maps while keeping superior performance over other methods.",
      "tldr_zh": "本文针对超大规模多机器人任务规划 (MRTP) 在机器人移动履行系统 (RMFS) 中的维度灾难和动态属性挑战，提出了一种基于分层强化学习 (HRL) 的多阶段任务规划器，利用特殊的时间图拓扑实现高效规划。创新点包括构建分层时间注意力网络 (HTAN) 以处理变长输入、设计多阶段课程学习提升扩展和泛化能力，以及引入反事实展开基线算法来解决不公平信用分配问题。实验结果显示，该规划器在模拟和真实 RMFS 环境中优于现有方法，并成功扩展到未学习过的地图上，支持多达 200 个机器人和 1000 个检索架的超大规模实例。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19538v1",
      "published_date": "2024-12-27 09:07:11 UTC",
      "updated_date": "2024-12-27 09:07:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:10:24.108789"
    },
    {
      "arxiv_id": "2412.19867v2",
      "title": "Data-Free Group-Wise Fully Quantized Winograd Convolution via Learnable Scales",
      "title_zh": "翻译失败",
      "authors": [
        "Shuokai Pan",
        "Gerti Tuzi",
        "Sudarshan Sreeram",
        "Dibakar Gope"
      ],
      "abstract": "Despite the revolutionary breakthroughs of large-scale text-to-image\ndiffusion models for complex vision and downstream tasks, their extremely high\ncomputational and storage costs limit their usability. Quantization of\ndiffusion models has been explored in recent works to reduce compute costs and\nmemory bandwidth usage. To further improve inference time, fast convolution\nalgorithms such as Winograd can be used for convolution layers, which account\nfor a significant portion of computations in diffusion models. However, the\nsignificant quality loss of fully quantized Winograd using existing\ncoarser-grained post-training quantization methods, combined with the\ncomplexity and cost of finetuning the Winograd transformation matrices for such\nlarge models to recover quality, makes them unsuitable for large-scale\nfoundation models. Motivated by the presence of a large range of values in\nthem, we investigate the impact of finer-grained group-wise quantization in\nquantizing diffusion models. While group-wise quantization can largely handle\nthe fully quantized Winograd convolution, it struggles to deal with the large\ndistribution imbalance in a sizable portion of the Winograd domain computation.\nTo reduce range differences in the Winograd domain, we propose finetuning only\nthe scale parameters of the Winograd transform matrices without using any\ndomain-specific training data. Because our method does not depend on any\ntraining data, the generalization performance of quantized diffusion models is\nsafely guaranteed. For text-to-image generation task, the 8-bit fully-quantized\ndiffusion model with Winograd provides near-lossless quality (FID and CLIP\nscores) in comparison to the full-precision model. For image classification,\nour method outperforms the state-of-the-art Winograd PTQ method by 1.62% and\n2.56% in top-1 ImageNet accuracy on ResNet18 and ResNet-34, respectively, with\nWinograd F(6, 3).",
      "tldr_zh": "该论文提出了一种无数据依赖的组-wise 全量化 Winograd 卷积方法，通过微调可学习缩放参数来优化 Winograd 变换矩阵，旨在减少大型扩散模型的计算和存储成本，同时解决量化过程中分布不平衡的问题。方法无需任何训练数据，即可实现高效的全量化卷积。实验结果显示，在文本到图像生成任务中，8-bit 量化模型与全精度模型的 FID 和 CLIP 分数几乎无损；在图像分类任务上，该方法使 ResNet18 和 ResNet34 的 top-1 ImageNet 准确率分别比最先进 Winograd PTQ 方法提高了 1.62% 和 2.56%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19867v2",
      "published_date": "2024-12-27 09:05:48 UTC",
      "updated_date": "2025-04-01 03:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:08:35.198153"
    },
    {
      "arxiv_id": "2412.19533v2",
      "title": "P3S-Diffusion:A Selective Subject-driven Generation Framework via Point Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Hu",
        "Shuyong Gao",
        "Lingyi Hong",
        "Qishan Wang",
        "Yuzhou Zhao",
        "Yan Wang",
        "Wenqiang Zhang"
      ],
      "abstract": "Recent research in subject-driven generation increasingly emphasizes the\nimportance of selective subject features. Nevertheless, accurately selecting\nthe content in a given reference image still poses challenges, especially when\nselecting the similar subjects in an image (e.g., two different dogs). Some\nmethods attempt to use text prompts or pixel masks to isolate specific\nelements. However, text prompts often fall short in precisely describing\nspecific content, and pixel masks are often expensive. To address this, we\nintroduce P3S-Diffusion, a novel architecture designed for context-selected\nsubject-driven generation via point supervision. P3S-Diffusion leverages\nminimal cost label (e.g., points) to generate subject-driven images. During\nfine-tuning, it can generate an expanded base mask from these points, obviating\nthe need for additional segmentation models. The mask is employed for\ninpainting and aligning with subject representation. The P3S-Diffusion\npreserves fine features of the subjects through Multi-layers Condition\nInjection. Enhanced by the Attention Consistency Loss for improved training,\nextensive experiments demonstrate its excellent feature preservation and image\ngeneration capabilities.",
      "tldr_zh": "该研究提出P3S-Diffusion框架，通过点监督（point supervision）实现选择性主体驱动图像生成，解决了现有方法（如文本提示或像素掩码）在精确选择相似主体时的局限性。该框架利用点标签自动生成扩展基本掩码，用于图像修复和主体表示对齐，同时通过Multi-layers Condition Injection保留主体的精细特征，并借助Attention Consistency Loss优化训练过程。实验结果显示，P3S-Diffusion在特征保留和图像生成能力上表现出色，显著提升了生成任务的效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19533v2",
      "published_date": "2024-12-27 08:59:01 UTC",
      "updated_date": "2025-01-06 04:50:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:08:46.747907"
    },
    {
      "arxiv_id": "2412.19531v1",
      "title": "Is Your Text-to-Image Model Robust to Caption Noise?",
      "title_zh": "翻译失败",
      "authors": [
        "Weichen Yu",
        "Ziyan Yang",
        "Shanchuan Lin",
        "Qi Zhao",
        "Jianyi Wang",
        "Liangke Gui",
        "Matt Fredrikson",
        "Lu Jiang"
      ],
      "abstract": "In text-to-image (T2I) generation, a prevalent training technique involves\nutilizing Vision Language Models (VLMs) for image re-captioning. Even though\nVLMs are known to exhibit hallucination, generating descriptive content that\ndeviates from the visual reality, the ramifications of such caption\nhallucinations on T2I generation performance remain under-explored. Through our\nempirical investigation, we first establish a comprehensive dataset comprising\nVLM-generated captions, and then systematically analyze how caption\nhallucination influences generation outcomes. Our findings reveal that (1) the\ndisparities in caption quality persistently impact model outputs during\nfine-tuning. (2) VLMs confidence scores serve as reliable indicators for\ndetecting and characterizing noise-related patterns in the data distribution.\n(3) even subtle variations in caption fidelity have significant effects on the\nquality of learned representations. These findings collectively emphasize the\nprofound impact of caption quality on model performance and highlight the need\nfor more sophisticated robust training algorithm in T2I. In response to these\nobservations, we propose a approach leveraging VLM confidence score to mitigate\ncaption noise, thereby enhancing the robustness of T2I models against\nhallucination in caption.",
      "tldr_zh": "本文研究了文本到图像 (T2I) 模型对 Vision Language Models (VLMs) 生成的标题噪声（hallucination）的影响，通过构建一个包含 VLM 生成标题的数据集进行系统分析。研究发现，标题质量差异会持续影响模型微调输出，VLMs 的置信度分数可作为可靠指标检测噪声模式，且即使标题保真度的细微变化也会显著降低学习表示的质量。这些发现强调了标题质量对模型性能的深远影响，并提出了一种基于置信度分数的鲁棒训练方法，以减轻标题噪声并提升 T2I 模型的整体鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19531v1",
      "published_date": "2024-12-27 08:53:37 UTC",
      "updated_date": "2024-12-27 08:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:08:58.862707"
    },
    {
      "arxiv_id": "2412.19524v1",
      "title": "PLN and NARS Often Yield Similar strength $\\times$ confidence Given Highly Uncertain Term Probabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Goertzel"
      ],
      "abstract": "We provide a comparative analysis of the deduction, induction, and abduction\nformulas used in Probabilistic Logic Networks (PLN) and the Non-Axiomatic\nReasoning System (NARS), two uncertain reasoning frameworks aimed at AGI. One\ndifference between the two systems is that, at the level of individual\ninference rules, PLN directly leverages both term and relationship\nprobabilities, whereas NARS only leverages relationship frequencies and has no\nsimple analogue of term probabilities. Thus we focus here on scenarios where\nthere is high uncertainty about term probabilities, and explore how this\nuncertainty influences the comparative inferential conclusions of the two\nsystems. We compare the product of strength and confidence ($s\\times c$) in PLN\nagainst the product of frequency and confidence ($f\\times c$) in NARS\n(quantities we refer to as measuring the \"power\" of an uncertain statement) in\ncases of high term probability uncertainty, using heuristic analyses and\nelementary numerical computations. We find that in many practical situations\nwith high term probability uncertainty, PLN and NARS formulas give very similar\nresults for the power of an inference conclusion, even though they sometimes\ncome to these similar numbers in quite different ways.",
      "tldr_zh": "本研究比较了Probabilistic Logic Networks (PLN)和Non-Axiomatic Reasoning System (NARS)这两个不确定推理框架在演绎、归纳和溯因公式方面的表现，焦点在于术语概率高度不确定时的差异。PLN直接利用术语概率和关系概率，而NARS仅依赖关系频率。研究通过启发式分析和基本数值计算发现，在许多实际场景中，PLN的strength × confidence与NARS的frequency × confidence（即推理结论的“power”）往往相似，尽管两者的计算路径不同。这表明在高不确定性条件下，这两个框架可能产生相似的推理结果，为AGI不确定推理的应用提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19524v1",
      "published_date": "2024-12-27 08:31:19 UTC",
      "updated_date": "2024-12-27 08:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:09:10.020616"
    },
    {
      "arxiv_id": "2412.19523v1",
      "title": "Attribution for Enhanced Explanation with Transferable Adversarial eXploration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Zhu",
        "Jiayu Zhang",
        "Zhibo Jin",
        "Huaming Chen",
        "Jianlong Zhou",
        "Fang Chen"
      ],
      "abstract": "The interpretability of deep neural networks is crucial for understanding\nmodel decisions in various applications, including computer vision.\nAttEXplore++, an advanced framework built upon AttEXplore, enhances attribution\nby incorporating transferable adversarial attack methods such as MIG and GRA,\nsignificantly improving the accuracy and robustness of model explanations. We\nconduct extensive experiments on five models, including CNNs (Inception-v3,\nResNet-50, VGG16) and vision transformers (MaxViT-T, ViT-B/16), using the\nImageNet dataset. Our method achieves an average performance improvement of\n7.57\\% over AttEXplore and 32.62\\% compared to other state-of-the-art\ninterpretability algorithms. Using insertion and deletion scores as evaluation\nmetrics, we show that adversarial transferability plays a vital role in\nenhancing attribution results. Furthermore, we explore the impact of\nrandomness, perturbation rate, noise amplitude, and diversity probability on\nattribution performance, demonstrating that AttEXplore++ provides more stable\nand reliable explanations across various models. We release our code at:\nhttps://anonymous.4open.science/r/ATTEXPLOREP-8435/",
      "tldr_zh": "该研究提出AttEXplore++框架，基于AttEXplore并整合可转移对抗攻击方法如MIG和GRA，提升深度神经网络在计算机视觉领域的解释准确性和鲁棒性。实验在五个模型（包括Inception-v3、ResNet-50、VGG16、MaxViT-T和ViT-B/16）上使用ImageNet数据集进行评估，平均性能较AttEXplore提高7.57%，较其他最先进算法提高32.62%。通过插入和删除分数等指标，论文证明对抗转移性对归因结果至关重要，并探讨了随机性、扰动率、噪声幅度和多样性概率等因素的影响，提供更稳定可靠的模型解释。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19523v1",
      "published_date": "2024-12-27 08:27:53 UTC",
      "updated_date": "2024-12-27 08:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:11:15.218892"
    },
    {
      "arxiv_id": "2412.19517v1",
      "title": "Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunwoo Cho",
        "Sung Woong Cho",
        "Hyeontae Jo",
        "Hyung Ju Hwang"
      ],
      "abstract": "Differential equations (DEs) are crucial for modeling the evolution of\nnatural or engineered systems. Traditionally, the parameters in DEs are\nadjusted to fit data from system observations. However, in fields such as\npolitics, economics, and biology, available data are often independently\ncollected at distinct time points from different subjects (i.e., repeated\ncross-sectional (RCS) data). Conventional optimization techniques struggle to\naccurately estimate DE parameters when RCS data exhibit various\nheterogeneities, leading to a significant loss of information. To address this\nissue, we propose a new estimation method called the emulator-informed\ndeep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM\nintegrates a physics-informed neural network-based emulator that immediately\ngenerates DE solutions and a Wasserstein generative adversarial network-based\nparameter generator that can effectively mimic the RCS data. We evaluated EIDGM\non exponential growth, logistic population models, and the Lorenz system,\ndemonstrating its superior ability to accurately capture parameter\ndistributions. Additionally, we applied EIDGM to an experimental dataset of\nAmyloid beta 40 and beta 42, successfully capturing diverse parameter\ndistribution shapes. This shows that EIDGM can be applied to model a wide range\nof systems and extended to uncover the operating principles of systems based on\nlimited data.",
      "tldr_zh": "本文提出了一种名为 Emulator-Informed Deep Generative Model (EIDGM) 的新方法，用于估计微分方程 (DEs) 的系统参数，特别是处理重复横断面 (RCS) 数据时面临的异质性挑战。EIDGM 结合了基于 Physics-Informed Neural Network 的 emulator 来快速生成 DE 解决方案，以及基于 Wasserstein Generative Adversarial Network 的参数生成器，以有效模拟 RCS 数据。实验结果显示，该方法在指数增长模型、Logistic 人口模型和 Lorenz 系统上显著提高了参数分布的准确捕捉能力。最终，EIDGM 被成功应用于 Amyloid beta 40 和 beta 42 的实验数据集，证明其能基于有限数据揭示广泛系统的运作原理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "q-bio.PE",
        "stat.ML",
        "62F30, 65Z05, 68T09",
        "G.1.7; I.2.m; J.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19517v1",
      "published_date": "2024-12-27 08:19:23 UTC",
      "updated_date": "2024-12-27 08:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:09:35.019871"
    },
    {
      "arxiv_id": "2412.19509v2",
      "title": "MBQ: Modality-Balanced Quantization for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyao Li",
        "Yingchun Hu",
        "Xuefei Ning",
        "Xihui Liu",
        "Ke Hong",
        "Xiaotao Jia",
        "Xiuhong Li",
        "Yaqi Yan",
        "Pei Ran",
        "Guohao Dai",
        "Shengen Yan",
        "Huazhong Yang",
        "Yu Wang"
      ],
      "abstract": "Vision-Language Models (VLMs) have enabled a variety of real-world\napplications. The large parameter size of VLMs brings large memory and\ncomputation overhead which poses significant challenges for deployment.\nPost-Training Quantization (PTQ) is an effective technique to reduce the memory\nand computation overhead. Existing PTQ methods mainly focus on large language\nmodels (LLMs), without considering the differences across other modalities. In\nthis paper, we discover that there is a significant difference in sensitivity\nbetween language and vision tokens in large VLMs. Therefore, treating tokens\nfrom different modalities equally, as in existing PTQ methods, may\nover-emphasize the insensitive modalities, leading to significant accuracy\nloss. To deal with the above issue, we propose a simple yet effective method,\nModality-Balanced Quantization (MBQ), for large VLMs. Specifically, MBQ\nincorporates the different sensitivities across modalities during the\ncalibration process to minimize the reconstruction loss for better quantization\nparameters. Extensive experiments show that MBQ can significantly improve task\naccuracy by up to 4.4% and 11.6% under W3 and W4A8 quantization for 7B to 70B\nVLMs, compared to SOTA baselines. Additionally, we implement a W3 GPU kernel\nthat fuses the dequantization and GEMV operators, achieving a 1.4x speedup on\nLLaVA-onevision-7B on the RTX 4090. The code is available at\nhttps://github.com/thu-nics/MBQ.",
      "tldr_zh": "本研究针对大型视觉语言模型（VLMs）的部署挑战，提出了一种模态平衡量化方法（Modality-Balanced Quantization, MBQ），以解决现有后训练量化（PTQ）方法忽略语言和视觉标记敏感度差异的问题。MBQ 通过在量化校准过程中考虑不同模态的敏感度，优化量化参数以最小化重建损失，从而显著提升模型性能。实验结果显示，MBQ 在 W3 和 W4A8 量化下，使 7B 到 70B VLMs 的任务准确率比最先进基线提高高达 4.4% 和 11.6%；此外，该方法还实现了 W3 GPU 内核加速，在 RTX 4090 上为 LLaVA-onevision-7B 带来 1.4 倍速度提升，并开源代码以便进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19509v2",
      "published_date": "2024-12-27 07:55:36 UTC",
      "updated_date": "2025-03-21 06:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:11:47.753810"
    },
    {
      "arxiv_id": "2412.19507v2",
      "title": "Hybrid Local Causal Discovery",
      "title_zh": "混合局部因果发现",
      "authors": [
        "Zhaolong Ling",
        "Honghui Peng",
        "Yiwen Zhang",
        "Debo Cheng",
        "Xingyu Wu",
        "Peng Zhou",
        "Kui Yu"
      ],
      "abstract": "Local causal discovery aims to learn and distinguish the direct causes and\neffects of a target variable from observed data. Existing constraint-based\nlocal causal discovery methods use AND or OR rules in constructing the local\ncausal skeleton, but using either rule alone is prone to produce cascading\nerrors in the learned local causal skeleton, and thus impacting the inference\nof local causal relationships. On the other hand, directly applying score-based\nglobal causal discovery methods to local causal discovery may randomly return\nincorrect results due to the existence of local equivalence classes. To address\nthe above issues, we propose a Hybrid Local Causal Discovery algorithm, called\nHLCD. Specifically, HLCD initially utilizes a constraint-based approach\ncombined with the OR rule to obtain a candidate skeleton and then employs a\nscore-based method to eliminate redundant portions in the candidate skeleton.\nFurthermore, during the local causal orientation phase, HLCD distinguishes\nbetween V-structures and equivalence classes by comparing the local structure\nscores between the two, thereby avoiding orientation interference caused by\nlocal equivalence classes. We conducted extensive experiments with seven\nstate-of-the-art competitors on 14 benchmark Bayesian network datasets, and the\nexperimental results demonstrate that HLCD significantly outperforms existing\nlocal causal discovery algorithms.",
      "tldr_zh": "本论文提出了一种Hybrid Local Causal Discovery (HLCD)算法，用于从观察数据中学习和区分目标变量的直接原因和效果。HLCD结合约束-based方法和OR规则来生成候选因果骨架，然后使用score-based方法去除冗余部分，以避免AND或OR规则单独使用导致的级联错误。论文还通过比较局部结构分数来区分V-structures和等价类，从而在局部因果方向阶段减少等价类干扰。实验结果显示，HLCD在14个基准Bayesian network数据集上显著优于七个最先进竞争者，证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted for publication in the Proceedings of\n  the 34th International Joint Conference on Artificial Intelligence (IJCAI\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.19507v2",
      "published_date": "2024-12-27 07:53:59 UTC",
      "updated_date": "2025-05-12 15:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:09:57.503866"
    },
    {
      "arxiv_id": "2412.19496v2",
      "title": "Multi-P$^2$A: A Multi-perspective Benchmark on Privacy Assessment for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Zhang",
        "Xiangkui Cao",
        "Zhouyu Han",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) exhibit impressive potential across\nvarious tasks but also face significant privacy risks, limiting their practical\napplications. Current researches on privacy assessment for LVLMs is limited in\nscope, with gaps in both assessment dimensions and privacy categories. To\nbridge this gap, we propose Multi-P$^2$A, a comprehensive benchmark for\nevaluating the privacy preservation capabilities of LVLMs in terms of privacy\nawareness and leakage. Privacy awareness measures the model's ability to\nrecognize the privacy sensitivity of input data, while privacy leakage assesses\nthe risk of the model unintentionally disclosing privacy information in its\noutput. We design a range of sub-tasks to thoroughly evaluate the model's\nprivacy protection offered by LVLMs. Multi-P$^2$A covers 26 categories of\npersonal privacy, 15 categories of trade secrets, and 18 categories of state\nsecrets, totaling 31,962 samples. Based on Multi-P$^2$A, we evaluate the\nprivacy preservation capabilities of 21 open-source and 2 closed-source LVLMs.\nOur results reveal that current LVLMs generally pose a high risk of\nfacilitating privacy breaches, with vulnerabilities varying across personal\nprivacy, trade secret, and state secret.",
      "tldr_zh": "大型视觉语言模型(LVLMs)在各种任务中表现出色，但面临严重的隐私风险，为此，本文提出Multi-P²A基准，用于多角度评估LVLMs的隐私保护能力，包括隐私 awareness（识别输入数据的隐私敏感性）和privacy leakage（无意中泄露隐私信息）。Multi-P²A涵盖26类个人隐私、15类商业秘密和18类国家秘密，共计31,962个样本，并对21个开源和2个闭源LVLMs进行了评估。结果表明，当前LVLMs普遍存在高隐私泄露风险，且在不同隐私类别中表现出差异，为提升模型的安全性提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19496v2",
      "published_date": "2024-12-27 07:33:39 UTC",
      "updated_date": "2025-03-11 04:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:11:59.375702"
    },
    {
      "arxiv_id": "2412.19495v2",
      "title": "Disparate Model Performance and Stability in Machine Learning Clinical Support for Diabetes and Heart Diseases",
      "title_zh": "机器学习临床支持中针对糖尿病",
      "authors": [
        "Ioannis Bilionis",
        "Ricardo C. Berrios",
        "Luis Fernandez-Luque",
        "Carlos Castillo"
      ],
      "abstract": "Machine Learning (ML) algorithms are vital for supporting clinical\ndecision-making in biomedical informatics. However, their predictive\nperformance can vary across demographic groups, often due to the\nunderrepresentation of historically marginalized populations in training\ndatasets. The investigation reveals widespread sex- and age-related inequities\nin chronic disease datasets and their derived ML models. Thus, a novel\nanalytical framework is introduced, combining systematic arbitrariness with\ntraditional metrics like accuracy and data complexity. The analysis of data\nfrom over 25,000 individuals with chronic diseases revealed mild sex-related\ndisparities, favoring predictive accuracy for males, and significant\nage-related differences, with better accuracy for younger patients. Notably,\nolder patients showed inconsistent predictive accuracy across seven datasets,\nlinked to higher data complexity and lower model performance. This highlights\nthat representativeness in training data alone does not guarantee equitable\noutcomes, and model arbitrariness must be addressed before deploying models in\nclinical settings.",
      "tldr_zh": "这篇论文探讨了 Machine Learning (ML) 模型在糖尿病和心脏病临床决策支持中的性能差异和稳定性问题，揭示了由于训练数据中边缘化人群的 underrepresented 而导致的性别和年龄相关不平等。研究引入了一个新分析框架，将 systematic arbitrariness 与传统指标如准确率和数据复杂度相结合，对超过 25,000 个慢性病患者的数据进行分析。结果显示，模型对男性的预测准确率略高，而年轻患者表现出显著更好的准确率，老年患者则因数据复杂度较高而出现不一致的性能。论文强调，仅靠训练数据的代表性不足以保证公平结果，在临床部署前必须解决模型的 arbitrariness。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper will be presented in American Medical Informatics\n  Association (AMIA) Informatics Summit Conference 2025 (Pittsburgh, PA). 10\n  pages, 2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19495v2",
      "published_date": "2024-12-27 07:31:14 UTC",
      "updated_date": "2025-03-03 16:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:12:12.870005"
    },
    {
      "arxiv_id": "2412.19467v1",
      "title": "Optimizing Helmet Detection with Hybrid YOLO Pipelines: A Detailed Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Vaikunth M",
        "Dejey D",
        "Vishaal C",
        "Balamurali S"
      ],
      "abstract": "Helmet detection is crucial for advancing protection levels in public road\ntraffic dynamics. This problem statement translates to an object detection\ntask. Therefore, this paper compares recent You Only Look Once (YOLO) models in\nthe context of helmet detection in terms of reliability and computational load.\nSpecifically, YOLOv8, YOLOv9, and the newly released YOLOv11 have been used.\nBesides, a modified architectural pipeline that remarkably improves the overall\nperformance has been proposed in this manuscript. This hybridized YOLO model\n(h-YOLO) has been pitted against the independent models for analysis that\nproves h-YOLO is preferable for helmet detection over plain YOLO models. The\nmodels were tested using a range of standard object detection benchmarks such\nas recall, precision, and mAP (Mean Average Precision). In addition, training\nand testing times were recorded to provide the overall scope of the models in a\nreal-time detection scenario.",
      "tldr_zh": "该论文探讨了使用混合 YOLO 管道优化头盔检测的重要性，以提升公共道路交通安全。研究比较了 YOLOv8、YOLOv9 和 YOLOv11 模型在可靠性和计算负载方面的表现，并提出了一种改进的混合 YOLO 模型 (h-YOLO)，通过修改架构显著提高了检测性能。实验结果显示，h-YOLO 在 recall、precision 和 mAP (Mean Average Precision) 等基准上优于独立模型，并在训练和测试时间方面更适合实时检测场景。总的来说，该方法为高效的头盔检测提供了可行的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19467v1",
      "published_date": "2024-12-27 05:26:12 UTC",
      "updated_date": "2024-12-27 05:26:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:12:23.114731"
    },
    {
      "arxiv_id": "2412.19450v2",
      "title": "Find the Intention of Instruction: Comprehensive Evaluation of Instruction Understanding for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonseok Moon",
        "Jaehyung Seo",
        "Seungyoon Lee",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "One of the key strengths of Large Language Models (LLMs) is their ability to\ninteract with humans by generating appropriate responses to given instructions.\nThis ability, known as instruction-following capability, has established a\nfoundation for the use of LLMs across various fields and serves as a crucial\nmetric for evaluating their performance. While numerous evaluation benchmarks\nhave been developed, most focus solely on clear and coherent instructions.\nHowever, we have noted that LLMs can become easily distracted by\ninstruction-formatted statements, which may lead to an oversight of their\ninstruction comprehension skills. To address this issue, we introduce the\nIntention of Instruction (IoInst) benchmark. This benchmark evaluates LLMs'\ncapacity to remain focused and understand instructions without being misled by\nextraneous instructions. The primary objective of this benchmark is to identify\nthe appropriate instruction that accurately guides the generation of a given\ncontext. Our findings suggest that even recently introduced state-of-the-art\nmodels still lack instruction understanding capability. Along with the\nproposition of IoInst in this study, we also present broad analyses of the\nseveral strategies potentially applicable to IoInst.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)的指令理解能力，指出现有基准主要关注清晰指令，而忽略了LLMs容易受无关指令格式干扰的问题。研究者引入了Intention of Instruction (IoInst)基准，通过测试模型在复杂场景中保持焦点并识别正确指导指令的能力，来全面评估instruction-following capability。结果显示，即使是最新模型仍存在显著不足，同时论文分析了多种潜在策略以提升指令理解性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL25-Findings",
      "pdf_url": "http://arxiv.org/pdf/2412.19450v2",
      "published_date": "2024-12-27 04:37:39 UTC",
      "updated_date": "2025-01-23 00:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:12:34.528774"
    },
    {
      "arxiv_id": "2412.19442v2",
      "title": "A Survey on Large Language Model Acceleration based on KV Cache Management",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Li",
        "Yiming Li",
        "Anxin Tian",
        "Tianhao Tang",
        "Zhanchao Xu",
        "Xuejia Chen",
        "Nicole Hu",
        "Wei Dong",
        "Qing Li",
        "Lei Chen"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized a wide range of domains such\nas natural language processing, computer vision, and multi-modal tasks due to\ntheir ability to comprehend context and perform logical reasoning. However, the\ncomputational and memory demands of LLMs, particularly during inference, pose\nsignificant challenges when scaling them to real-world, long-context, and\nreal-time applications. Key-Value (KV) cache management has emerged as a\ncritical optimization technique for accelerating LLM inference by reducing\nredundant computations and improving memory utilization. This survey provides a\ncomprehensive overview of KV cache management strategies for LLM acceleration,\ncategorizing them into token-level, model-level, and system-level\noptimizations. Token-level strategies include KV cache selection, budget\nallocation, merging, quantization, and low-rank decomposition, while\nmodel-level optimizations focus on architectural innovations and attention\nmechanisms to enhance KV reuse. System-level approaches address memory\nmanagement, scheduling, and hardware-aware designs to improve efficiency across\ndiverse computing environments. Additionally, the survey provides an overview\nof both text and multimodal datasets and benchmarks used to evaluate these\nstrategies. By presenting detailed taxonomies and comparative analyses, this\nwork aims to offer useful insights for researchers and practitioners to support\nthe development of efficient and scalable KV cache management techniques,\ncontributing to the practical deployment of LLMs in real-world applications.\nThe curated paper list for KV cache management is in:\n\\href{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}.",
      "tldr_zh": "这篇调查论文探讨了Large Language Models (LLMs) 在推理过程中面临的计算和内存挑战，并将KV Cache Management 作为关键优化技术，以减少冗余计算并提升内存利用率。论文将这些策略分类为token-level（如KV cache selection、budget allocation、merging、quantization 和 low-rank decomposition）、model-level（如architectural innovations 和 attention mechanisms 以增强KV reuse）以及system-level（如memory management、scheduling 和 hardware-aware designs）优化。作者还概述了用于评估的文本和多模态数据集与基准，并通过详细的分类和比较分析，提供insights 以支持高效、可扩展的KV Cache Management 技术开发，最终促进LLMs 在实际应用的部署。有关论文列表可参考提供的GitHub 链接。",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19442v2",
      "published_date": "2024-12-27 04:17:57 UTC",
      "updated_date": "2025-01-02 03:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:12:46.910502"
    },
    {
      "arxiv_id": "2412.19437v2",
      "title": "DeepSeek-V3 Technical Report",
      "title_zh": "DeepSeek-V3 技术报告",
      "authors": [
        "DeepSeek-AI",
        "Aixin Liu",
        "Bei Feng",
        "Bing Xue",
        "Bingxuan Wang",
        "Bochao Wu",
        "Chengda Lu",
        "Chenggang Zhao",
        "Chengqi Deng",
        "Chenyu Zhang",
        "Chong Ruan",
        "Damai Dai",
        "Daya Guo",
        "Dejian Yang",
        "Deli Chen",
        "Dongjie Ji",
        "Erhang Li",
        "Fangyun Lin",
        "Fucong Dai",
        "Fuli Luo",
        "Guangbo Hao",
        "Guanting Chen",
        "Guowei Li",
        "H. Zhang",
        "Han Bao",
        "Hanwei Xu",
        "Haocheng Wang",
        "Haowei Zhang",
        "Honghui Ding",
        "Huajian Xin",
        "Huazuo Gao",
        "Hui Li",
        "Hui Qu",
        "J. L. Cai",
        "Jian Liang",
        "Jianzhong Guo",
        "Jiaqi Ni",
        "Jiashi Li",
        "Jiawei Wang",
        "Jin Chen",
        "Jingchang Chen",
        "Jingyang Yuan",
        "Junjie Qiu",
        "Junlong Li",
        "Junxiao Song",
        "Kai Dong",
        "Kai Hu",
        "Kaige Gao",
        "Kang Guan",
        "Kexin Huang",
        "Kuai Yu",
        "Lean Wang",
        "Lecong Zhang",
        "Lei Xu",
        "Leyi Xia",
        "Liang Zhao",
        "Litong Wang",
        "Liyue Zhang",
        "Meng Li",
        "Miaojun Wang",
        "Mingchuan Zhang",
        "Minghua Zhang",
        "Minghui Tang",
        "Mingming Li",
        "Ning Tian",
        "Panpan Huang",
        "Peiyi Wang",
        "Peng Zhang",
        "Qiancheng Wang",
        "Qihao Zhu",
        "Qinyu Chen",
        "Qiushi Du",
        "R. J. Chen",
        "R. L. Jin",
        "Ruiqi Ge",
        "Ruisong Zhang",
        "Ruizhe Pan",
        "Runji Wang",
        "Runxin Xu",
        "Ruoyu Zhang",
        "Ruyi Chen",
        "S. S. Li",
        "Shanghao Lu",
        "Shangyan Zhou",
        "Shanhuang Chen",
        "Shaoqing Wu",
        "Shengfeng Ye",
        "Shengfeng Ye",
        "Shirong Ma",
        "Shiyu Wang",
        "Shuang Zhou",
        "Shuiping Yu",
        "Shunfeng Zhou",
        "Shuting Pan",
        "T. Wang",
        "Tao Yun",
        "Tian Pei",
        "Tianyu Sun",
        "W. L. Xiao",
        "Wangding Zeng",
        "Wanjia Zhao",
        "Wei An",
        "Wen Liu",
        "Wenfeng Liang",
        "Wenjun Gao",
        "Wenqin Yu",
        "Wentao Zhang",
        "X. Q. Li",
        "Xiangyue Jin",
        "Xianzu Wang",
        "Xiao Bi",
        "Xiaodong Liu",
        "Xiaohan Wang",
        "Xiaojin Shen",
        "Xiaokang Chen",
        "Xiaokang Zhang",
        "Xiaosha Chen",
        "Xiaotao Nie",
        "Xiaowen Sun",
        "Xiaoxiang Wang",
        "Xin Cheng",
        "Xin Liu",
        "Xin Xie",
        "Xingchao Liu",
        "Xingkai Yu",
        "Xinnan Song",
        "Xinxia Shan",
        "Xinyi Zhou",
        "Xinyu Yang",
        "Xinyuan Li",
        "Xuecheng Su",
        "Xuheng Lin",
        "Y. K. Li",
        "Y. Q. Wang",
        "Y. X. Wei",
        "Y. X. Zhu",
        "Yang Zhang",
        "Yanhong Xu",
        "Yanhong Xu",
        "Yanping Huang",
        "Yao Li",
        "Yao Zhao",
        "Yaofeng Sun",
        "Yaohui Li",
        "Yaohui Wang",
        "Yi Yu",
        "Yi Zheng",
        "Yichao Zhang",
        "Yifan Shi",
        "Yiliang Xiong",
        "Ying He",
        "Ying Tang",
        "Yishi Piao",
        "Yisong Wang",
        "Yixuan Tan",
        "Yiyang Ma",
        "Yiyuan Liu",
        "Yongqiang Guo",
        "Yu Wu",
        "Yuan Ou",
        "Yuchen Zhu",
        "Yuduan Wang",
        "Yue Gong",
        "Yuheng Zou",
        "Yujia He",
        "Yukun Zha",
        "Yunfan Xiong",
        "Yunxian Ma",
        "Yuting Yan",
        "Yuxiang Luo",
        "Yuxiang You",
        "Yuxuan Liu",
        "Yuyang Zhou",
        "Z. F. Wu",
        "Z. Z. Ren",
        "Zehui Ren",
        "Zhangli Sha",
        "Zhe Fu",
        "Zhean Xu",
        "Zhen Huang",
        "Zhen Zhang",
        "Zhenda Xie",
        "Zhengyan Zhang",
        "Zhewen Hao",
        "Zhibin Gou",
        "Zhicheng Ma",
        "Zhigang Yan",
        "Zhihong Shao",
        "Zhipeng Xu",
        "Zhiyu Wu",
        "Zhongyu Zhang",
        "Zhuoshu Li",
        "Zihui Gu",
        "Zijia Zhu",
        "Zijun Liu",
        "Zilin Li",
        "Ziwei Xie",
        "Ziyang Song",
        "Ziyi Gao",
        "Zizheng Pan"
      ],
      "abstract": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with\n671B total parameters with 37B activated for each token. To achieve efficient\ninference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent\nAttention (MLA) and DeepSeekMoE architectures, which were thoroughly validated\nin DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free\nstrategy for load balancing and sets a multi-token prediction training\nobjective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion\ndiverse and high-quality tokens, followed by Supervised Fine-Tuning and\nReinforcement Learning stages to fully harness its capabilities. Comprehensive\nevaluations reveal that DeepSeek-V3 outperforms other open-source models and\nachieves performance comparable to leading closed-source models. Despite its\nexcellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its\nfull training. In addition, its training process is remarkably stable.\nThroughout the entire training process, we did not experience any irrecoverable\nloss spikes or perform any rollbacks. The model checkpoints are available at\nhttps://github.com/deepseek-ai/DeepSeek-V3.",
      "tldr_zh": "我们介绍了 DeepSeek-V3，一款总参数 671B 的 Mixture-of-Experts (MoE) 语言模型，其中每个 token 只激活 37B 参数，以实现高效推理和成本优化。该模型采用 Multi-head Latent Attention (MLA) 和 DeepSeekMoE 架构，并创新性地使用辅助损失-free 策略进行负载均衡，以及多 token 预测训练目标，在 14.8 万亿高质量 token 上预训练，并通过 Supervised Fine-Tuning 和 Reinforcement Learning 进一步提升性能。实验结果显示，DeepSeek-V3 超越其他开源模型，与领先闭源模型相当，且仅需 2.788M H800 GPU 小时完成训练，过程异常稳定，无任何损失峰值。模型检查点可从 https://github.com/deepseek-ai/DeepSeek-V3 获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19437v2",
      "published_date": "2024-12-27 04:03:16 UTC",
      "updated_date": "2025-02-18 17:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:00.096388"
    },
    {
      "arxiv_id": "2412.19433v1",
      "title": "Residual Feature-Reutilization Inception Network for Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He",
        "Wenjie Song",
        "Lijian Li",
        "Tianxiang Zhan",
        "Wenpin Jiao"
      ],
      "abstract": "Capturing feature information effectively is of great importance in the field\nof computer vision. With the development of convolutional neural networks\n(CNNs), concepts like residual connection and multiple scales promote continual\nperformance gains in diverse deep learning vision tasks. In this paper, we\npropose a novel CNN architecture that it consists of residual\nfeature-reutilization inceptions (ResFRI) or split-residual\nfeature-reutilization inceptions (Split-ResFRI). And it is composed of four\nconvolutional combinations of different structures connected by specially\ndesigned information interaction passages, which are utilized to extract\nmulti-scale feature information and effectively increase the receptive field of\nthe model. Moreover, according to the network structure designed above,\nSplit-ResFRI can adjust the segmentation ratio of the input information,\nthereby reducing the number of parameters and guaranteeing the model\nperformance. Specifically, in experiments based on popular vision datasets,\nsuch as CIFAR10 ($97.94$\\%), CIFAR100 ($85.91$\\%) and Tiny Imagenet\n($70.54$\\%), we obtain state-of-the-art results compared with other modern\nmodels under the premise that the model size is approximate and no additional\ndata is used.",
      "tldr_zh": "本论文提出了一种新型 CNN 架构，名为 Residual Feature-Reutilization Inception Network (ResFRI) 和其变体 Split-ResFRI，用于图像分类任务。\n该架构通过四种不同结构的卷积组合和设计的信息交互通道，提取多尺度特征信息并增加模型的感受野；同时，Split-ResFRI 通过调整输入信息的分割比例，减少参数数量的同时保持性能。\n实验结果显示，在 CIFAR10 (97.94%)、CIFAR100 (85.91%) 和 Tiny Imagenet (70.54%) 等数据集上，该模型在模型大小相近且未使用额外数据的情况下，取得了优于其他现代模型的 state-of-the-art 结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2301.00424",
      "pdf_url": "http://arxiv.org/pdf/2412.19433v1",
      "published_date": "2024-12-27 03:55:25 UTC",
      "updated_date": "2024-12-27 03:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:12.991944"
    },
    {
      "arxiv_id": "2412.19425v1",
      "title": "A Self-Efficacy Theory-based Study on the Teachers Readiness to Teach Artificial Intelligence in Public Schools in Sri Lanka",
      "title_zh": "翻译失败",
      "authors": [
        "Chathura Rajapakse",
        "Wathsala Ariyarathna",
        "Shanmugalingam Selvakan"
      ],
      "abstract": "This study investigates Sri Lankan ICT teachers' readiness to teach AI in\nschools, focusing on self-efficacy. A survey of over 1,300 teachers assessed\ntheir self-efficacy using a scale developed based on Bandura's theory. PLS-SEM\nanalysis revealed that teachers' self-efficacy was low, primarily influenced by\nemotional and physiological states and imaginary experiences related to AI\ninstruction. Mastery experiences had a lesser impact, and vicarious experiences\nand verbal persuasion showed no significant effect. The study highlights the\nneed for a systemic approach to teacher professional development, considering\nthe limitations in teachers' AI expertise and social capital. Further research\nis recommended to explore a socio-technical systems perspective for effective\nAI teacher training.",
      "tldr_zh": "本研究基于 Bandura's Self-Efficacy 理论，调查了斯里兰卡超过1,300名 ICT 教师教授 AI 的准备情况，使用问卷和 PLS-SEM 分析评估他们的自我效能感。结果显示，教师的自我效能感整体较低，主要受情感和生理状态以及对 AI 教学的想象经验影响，而掌握经验的影响较小，vicarious experiences 和 verbal persuasion 则无显著效果。研究建议采用系统性教师专业发展方法，以应对教师在 AI 专业知识和社会资本方面的局限，并呼吁从 socio-technical systems 视角开展进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19425v1",
      "published_date": "2024-12-27 03:31:26 UTC",
      "updated_date": "2024-12-27 03:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:23.138620"
    },
    {
      "arxiv_id": "2412.19423v1",
      "title": "Revisiting PCA for time series reduction in temporal dimension",
      "title_zh": "重访 PCA 用于时间序列的时间维度降维",
      "authors": [
        "Jiaxin Gao",
        "Wenbo Hu",
        "Yuntian Chen"
      ],
      "abstract": "Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao,\nWenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series\nanalysis (TSA), enabling the extraction of complex patterns for tasks like\nclassification, forecasting, and regression. Although dimensionality reduction\nhas traditionally focused on the variable space-achieving notable success in\nminimizing data redundancy and computational complexity-less attention has been\npaid to reducing the temporal dimension. In this study, we revisit Principal\nComponent Analysis (PCA), a classical dimensionality reduction technique, to\nexplore its utility in temporal dimension reduction for time series data. It is\ngenerally thought that applying PCA to the temporal dimension would disrupt\ntemporal dependencies, leading to limited exploration in this area. However,\nour theoretical analysis and extensive experiments demonstrate that applying\nPCA to sliding series windows not only maintains model performance, but also\nenhances computational efficiency. In auto-regressive forecasting, the temporal\nstructure is partially preserved through windowing, and PCA is applied within\nthese windows to denoise the time series while retaining their statistical\ninformation. By preprocessing time-series data with PCA, we reduce the temporal\ndimensionality before feeding it into TSA models such as Linear, Transformer,\nCNN, and RNN architectures. This approach accelerates training and inference\nand reduces resource consumption. Notably, PCA improves Informer training and\ninference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%,\nwithout sacrificing model accuracy. Comparative analysis against other\nreduction methods further highlights the effectiveness of PCA in improving the\nefficiency of TSA models.",
      "tldr_zh": "本文重新审视 Principal Component Analysis (PCA) 在时间序列数据时序维度的降维应用，针对传统观点提出通过滑动窗口处理来保持时序依赖并减少冗余。研究方法包括在窗口内应用 PCA 进行去噪和统计信息保留，然后将处理后的数据输入 TSA 模型（如 Transformer、CNN 和 RNN），从而加速训练和推理过程。实验结果显示，该方法使 Informer 的训练和推理速度提高高达40%，并将 TimesNet 的 GPU 内存使用减少30%，而不牺牲模型准确性。与其他降维技术相比，PCA 在提升 TSA 模型效率方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 5 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.19423v1",
      "published_date": "2024-12-27 03:17:26 UTC",
      "updated_date": "2024-12-27 03:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:35.384305"
    },
    {
      "arxiv_id": "2412.19422v2",
      "title": "De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Li",
        "Yoshihiro Yamanishi"
      ],
      "abstract": "De novo generation of hit-like molecules is a challenging task in the drug\ndiscovery process. Most methods in previous studies learn the semantics and\nsyntax of molecular structures by analyzing molecular graphs or simplified\nmolecular input line entry system (SMILES) strings; however, they do not take\ninto account the drug responses of the biological systems consisting of genes\nand proteins. In this study we propose a hybrid neural network, HNN2Mol, which\nutilizes gene expression profiles to generate molecular structures with\ndesirable phenotypes for arbitrary target proteins. In the algorithm, a\nvariational autoencoder is employed as a feature extractor to learn the latent\nfeature distribution of the gene expression profiles. Then, a long short-term\nmemory is leveraged as the chemical generator to produce syntactically valid\nSMILES strings that satisfy the feature conditions of the gene expression\nprofile extracted by the feature extractor. Experimental results and case\nstudies demonstrate that the proposed HNN2Mol model can produce new molecules\nwith potential bioactivities and drug-like properties.",
      "tldr_zh": "该研究提出HNN2Mol模型，通过深度学习从基因表达配置文件生成具有理想表型的分子结构，旨在解决药物发现中从头生成类似命中分子的挑战。\n该模型结合变分自动编码器(VAE)作为特征提取器，学习基因表达的潜在特征分布，并使用长短时记忆网络(LSTM)生成语法正确的SMILES字符串，以满足这些特征条件。\n实验结果和案例研究显示，HNN2Mol能够产生具有潜在生物活性和药物样性质的新分子。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19422v2",
      "published_date": "2024-12-27 03:16:56 UTC",
      "updated_date": "2025-04-17 08:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:47.256010"
    },
    {
      "arxiv_id": "2412.19419v1",
      "title": "Introduction to Graph Neural Networks: A Starting Point for Machine Learning Engineers",
      "title_zh": "图神经网络介绍：机器学习工程师的起点",
      "authors": [
        "James H. Tanis",
        "Chris Giannella",
        "Adrian V. Mariano"
      ],
      "abstract": "Graph neural networks are deep neural networks designed for graphs with\nattributes attached to nodes or edges. The number of research papers in the\nliterature concerning these models is growing rapidly due to their impressive\nperformance on a broad range of tasks. This survey introduces graph neural\nnetworks through the encoder-decoder framework and provides examples of\ndecoders for a range of graph analytic tasks. It uses theory and numerous\nexperiments on homogeneous graphs to illustrate the behavior of graph neural\nnetworks for different training sizes and degrees of graph complexity.",
      "tldr_zh": "这篇论文介绍了Graph Neural Networks（图神经网络），作为机器学习工程师的入门指南，针对那些设计用于处理带有节点或边属性的图数据的深度神经网络。论文采用编码器-解码器框架来阐述GNNs的核心概念，并提供多种图分析任务的解码器示例，以展示其应用。作者通过理论分析和实验验证，展示了GNNs在同构图上面对不同训练规模和图复杂程度时的表现，帮助读者理解其行为和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "E.1; I.2.4; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19419v1",
      "published_date": "2024-12-27 03:13:02 UTC",
      "updated_date": "2024-12-27 03:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:13:58.498742"
    },
    {
      "arxiv_id": "2412.19418v1",
      "title": "Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head Attention for Weak-Supervised Temporal Action Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanpeng He",
        "Lijian Li",
        "Tianxiang Zhan",
        "Wenpin Jiao",
        "Chi-Man Pun"
      ],
      "abstract": "Weakly supervised temporal action localization (WS-TAL) is a task of\ntargeting at localizing complete action instances and categorizing them with\nvideo-level labels. Action-background ambiguity, primarily caused by background\nnoise resulting from aggregation and intra-action variation, is a significant\nchallenge for existing WS-TAL methods. In this paper, we introduce a hybrid\nmulti-head attention (HMHA) module and generalized uncertainty-based evidential\nfusion (GUEF) module to address the problem. The proposed HMHA effectively\nenhances RGB and optical flow features by filtering redundant information and\nadjusting their feature distribution to better align with the WS-TAL task.\nAdditionally, the proposed GUEF adaptively eliminates the interference of\nbackground noise by fusing snippet-level evidences to refine uncertainty\nmeasurement and select superior foreground feature information, which enables\nthe model to concentrate on integral action instances to achieve better action\nlocalization and classification performance. Experimental results conducted on\nthe THUMOS14 dataset demonstrate that our method outperforms state-of-the-art\nmethods. Our code is available in\n\\url{https://github.com/heyuanpengpku/GUEF/tree/main}.",
      "tldr_zh": "本论文针对弱监督时序动作定位（WS-TAL）任务，提出了一种解决动作背景模糊问题的创新方法，包括混合多头注意力（HMHA）模块和基于广义不确定性的证据融合（GUEF）模块。HMHA 通过过滤冗余信息并调整 RGB 和 optical flow 特征分布，提升了特征的针对性，以更好地适应 WS-TAL 需求；GUEF 则通过融合 snippet-level 证据，减少背景噪声干扰，精炼不确定性测量并选择关键前景特征，从而提高动作定位和分类性能。在 THUMOS14 数据集上的实验结果显示，该方法超过了现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19418v1",
      "published_date": "2024-12-27 03:04:57 UTC",
      "updated_date": "2024-12-27 03:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:14:11.283049"
    },
    {
      "arxiv_id": "2412.19403v2",
      "title": "Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model",
      "title_zh": "翻译失败",
      "authors": [
        "Fumiyasu Makinoshima",
        "Tatsuya Mitomi",
        "Fumiya Makihara",
        "Eigo Segawa"
      ],
      "abstract": "Discrete choice models are essential for modelling various decision-making\nprocesses in human behaviour. However, the specification of these models has\ndepended heavily on domain knowledge from experts, and the fully automated but\ninterpretable modelling of complex human behaviours has been a long-standing\nchallenge. In this paper, we introduce the differentiable discrete choice model\n(Diff-DCM), a fully data-driven method for the interpretable modelling,\nlearning, prediction, and control of complex human behaviours, which is\nrealised by differentiable programming. Solely from input features and choice\noutcomes without any prior knowledge, Diff-DCM can estimate interpretable\nclosed-form utility functions that reproduce observed behaviours. Comprehensive\nexperiments with both synthetic and real-world data demonstrate that Diff-DCM\ncan be applied to various types of data and requires only a small amount of\ncomputational resources for the estimations, which can be completed within tens\nof seconds on a laptop without any accelerators. In these experiments, we also\ndemonstrate that, using its differentiability, Diff-DCM can provide useful\ninsights into human behaviours, such as an optimal intervention path for\neffective behavioural changes. This study provides a strong basis for the fully\nautomated and reliable modelling, prediction, and control of human behaviours.",
      "tldr_zh": "本文提出Differentiable Discrete Choice Model (Diff-DCM)，一种完全数据驱动且可解释的方法，用于建模、学习、预测和控制复杂人类行为。该模型利用可微分编程，从输入特征和选择结果自动估计可解释的闭式效用函数，而无需依赖专家领域知识。实验结果显示，Diff-DCM适用于合成和真实数据，仅需少量计算资源（如在笔记本电脑上几秒内完成），并能提供行为洞见，例如优化干预路径以实现有效行为改变。该研究为人类行为的自动化建模、预测和控制奠定了可靠基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19403v2",
      "published_date": "2024-12-27 01:53:18 UTC",
      "updated_date": "2025-01-08 02:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:14:23.231076"
    },
    {
      "arxiv_id": "2412.19396v1",
      "title": "Comparing Few to Rank Many: Active Human Preference Learning using Randomized Frank-Wolfe",
      "title_zh": "翻译失败",
      "authors": [
        "Kiran Koshy Thekumparampil",
        "Gaurush Hiranandani",
        "Kousha Kalantari",
        "Shoham Sabach",
        "Branislav Kveton"
      ],
      "abstract": "We study learning of human preferences from a limited comparison feedback.\nThis task is ubiquitous in machine learning. Its applications such as\nreinforcement learning from human feedback, have been transformational. We\nformulate this problem as learning a Plackett-Luce model over a universe of $N$\nchoices from $K$-way comparison feedback, where typically $K \\ll N$. Our\nsolution is the D-optimal design for the Plackett-Luce objective. The design\ndefines a data logging policy that elicits comparison feedback for a small\ncollection of optimally chosen points from all ${N \\choose K}$ feasible\nsubsets. The main algorithmic challenge in this work is that even fast methods\nfor solving D-optimal designs would have $O({N \\choose K})$ time complexity. To\naddress this issue, we propose a randomized Frank-Wolfe (FW) algorithm that\nsolves the linear maximization sub-problems in the FW method on randomly chosen\nvariables. We analyze the algorithm, and evaluate it empirically on synthetic\nand open-source NLP datasets.",
      "tldr_zh": "这篇论文探讨了从有限的比较反馈中学习人类偏好的问题，旨在通过K-way比较（通常K远小于总选项N）来排名N个选择，并应用Plackett-Luce模型进行建模。研究提出了一种基于D-optimal design的解决方案，该设计定义了一个优化数据日志策略，仅从所有可行子集中的一小部分点收集反馈，以高效地获取信息。主要贡献是引入随机化的Frank-Wolfe算法来处理算法复杂度问题，通过在线性最大化子问题中随机选择变量来加速计算，并在合成和开源NLP数据集上的实验中证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to AISTATS 2025 on October 10, 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.19396v1",
      "published_date": "2024-12-27 01:10:17 UTC",
      "updated_date": "2024-12-27 01:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:14:35.517897"
    },
    {
      "arxiv_id": "2412.19394v2",
      "title": "An Engorgio Prompt Makes Large Language Model Babble on",
      "title_zh": "翻译失败",
      "authors": [
        "Jianshuo Dong",
        "Ziyuan Zhang",
        "Qingjie Zhang",
        "Tianwei Zhang",
        "Hao Wang",
        "Hewu Li",
        "Qi Li",
        "Chao Zhang",
        "Ke Xu",
        "Han Qiu"
      ],
      "abstract": "Auto-regressive large language models (LLMs) have yielded impressive\nperformance in many real-world tasks. However, the new paradigm of these LLMs\nalso exposes novel threats. In this paper, we explore their vulnerability to\ninference cost attacks, where a malicious user crafts Engorgio prompts to\nintentionally increase the computation cost and latency of the inference\nprocess. We design Engorgio, a novel methodology, to efficiently generate\nadversarial Engorgio prompts to affect the target LLM's service availability.\nEngorgio has the following two technical contributions. (1) We employ a\nparameterized distribution to track LLMs' prediction trajectory. (2) Targeting\nthe auto-regressive nature of LLMs' inference process, we propose novel loss\nfunctions to stably suppress the appearance of the <EOS> token, whose\noccurrence will interrupt the LLM's generation process. We conduct extensive\nexperiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B.\nThe results show that Engorgio prompts can successfully induce LLMs to generate\nabnormally long outputs (i.e., roughly 2-13$\\times$ longer to reach 90%+ of the\noutput length limit) in a white-box scenario and our real-world experiment\ndemonstrates Engergio's threat to LLM service with limited computing resources.\nThe code is released at: https://github.com/jianshuod/Engorgio-prompt.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)的脆弱性，特别针对推理成本攻击，其中攻击者使用Engorgio提示来故意增加模型的计算成本和延迟。研究提出Engorgio方法，通过参数化分布跟踪LLMs的预测轨迹，并设计新型损失函数来抑制<EOS>标记的出现，从而延长生成过程。实验在13个开源LLMs上验证了其有效性，结果显示Engorgio提示能使输出长度增加2-13倍，并在真实场景中证明了对资源有限的LLM服务的潜在威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19394v2",
      "published_date": "2024-12-27 01:00:23 UTC",
      "updated_date": "2025-02-13 03:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:14:47.583003"
    },
    {
      "arxiv_id": "2412.19391v2",
      "title": "An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Eugene Choi",
        "Julian Rodriguez",
        "Edmund Young"
      ],
      "abstract": "Domain adaptation is an active area of research driven by the growing demand\nfor robust machine learning models that perform well on real-world data.\nAdversarial learning for deep neural networks (DNNs) has emerged as a promising\napproach to improving generalization ability, particularly for image\nclassification. In this paper, we implement a specific adversarial learning\ntechnique known as Adversarial Discriminative Domain Adaptation (ADDA) and\nreplicate digit classification experiments from the original ADDA paper. We\nextend their findings by examining a broader range of domain shifts and provide\na detailed analysis of in-domain classification accuracy post-ADDA. Our results\ndemonstrate that ADDA significantly improves accuracy across certain domain\nshifts with minimal impact on in-domain performance. Furthermore, we provide\nqualitative analysis and propose potential explanations for ADDA's limitations\nin less successful domain shifts. Code is at\nhttps://github.com/eugenechoi2004/COS429_FINAL .",
      "tldr_zh": "本论文对 Adversarial Discriminative Domain Adaptation (ADDA) 在数字分类中的应用进行了深入分析，聚焦于通过对抗学习提升模型在域移位（domain shifts）下的泛化能力。研究者复制了原 ADDA 实验，并扩展到更广泛的域移位场景，评估了其对域内分类精度的影响。结果显示，ADDA 在某些域移位上显著提高了准确率，同时对域内性能的影响最小；此外，论文提供了定性分析，并探讨了 ADDA 在部分场景下表现不佳的潜在原因。代码已开源，可在 https://github.com/eugenechoi2004/COS429_FINAL 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Replacement: Updated methodology section to include grayscale\n  preprocessing of SVHN data",
      "pdf_url": "http://arxiv.org/pdf/2412.19391v2",
      "published_date": "2024-12-27 00:36:40 UTC",
      "updated_date": "2025-01-07 03:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T18:14:59.293463"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 66,
  "processed_papers_count": 66,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T18:15:18.127169"
}