[
  {
    "arxiv_id": "2504.07956v1",
    "title": "VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning",
    "authors": [
      "Yukun Qi",
      "Yiming Zhao",
      "Yu Zeng",
      "Xikun Bao",
      "Wenxuan Huang",
      "Lin Chen",
      "Zehui Chen",
      "Jie Zhao",
      "Zhongang Qi",
      "Feng Zhao"
    ],
    "abstract": "The advancement of Chain-of-Thought (CoT) reasoning has significantly\nenhanced the capabilities of large language models (LLMs) and large\nvision-language models (LVLMs). However, a rigorous evaluation framework for\nvideo CoT reasoning remains absent. Current video benchmarks fail to adequately\nassess the reasoning process and expose whether failures stem from deficiencies\nin perception or reasoning capabilities. Therefore, we introduce VCR-Bench, a\nnovel benchmark designed to comprehensively evaluate LVLMs' Video\nChain-of-Thought Reasoning capabilities. VCR-Bench comprises 859 videos\nspanning a variety of video content and durations, along with 1,034\nhigh-quality question-answer pairs. Each pair is manually annotated with a\nstepwise CoT rationale, where every step is tagged to indicate its association\nwith the perception or reasoning capabilities. Furthermore, we design seven\ndistinct task dimensions and propose the CoT score to assess the entire CoT\nprocess based on the stepwise tagged CoT rationals. Extensive experiments on\nVCR-Bench highlight substantial limitations in current LVLMs. Even the\ntop-performing model, o1, only achieves a 62.8% CoT score and an 56.7%\naccuracy, while most models score below 40%. Experiments show most models score\nlower on perception than reasoning steps, revealing LVLMs' key bottleneck in\ntemporal-spatial information processing for complex video reasoning. A robust\npositive correlation between the CoT score and accuracy confirms the validity\nof our evaluation framework and underscores the critical role of CoT reasoning\nin solving complex video reasoning tasks. We hope VCR-Bench to serve as a\nstandardized evaluation framework and expose the actual drawbacks in complex\nvideo reasoning task.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07956v1",
    "published_date": "2025-04-10 17:59:03 UTC",
    "updated_date": "2025-04-10 17:59:03 UTC"
  },
  {
    "arxiv_id": "2504.07945v1",
    "title": "GenEAva: Generating Cartoon Avatars with Fine-Grained Facial Expressions from Realistic Diffusion-based Faces",
    "authors": [
      "Hao Yu",
      "Rupayan Mallick",
      "Margrit Betke",
      "Sarah Adel Bargal"
    ],
    "abstract": "Cartoon avatars have been widely used in various applications, including\nsocial media, online tutoring, and gaming. However, existing cartoon avatar\ndatasets and generation methods struggle to present highly expressive avatars\nwith fine-grained facial expressions and are often inspired from real-world\nidentities, raising privacy concerns. To address these challenges, we propose a\nnovel framework, GenEAva, for generating high-quality cartoon avatars with\nfine-grained facial expressions. Our approach fine-tunes a state-of-the-art\ntext-to-image diffusion model to synthesize highly detailed and expressive\nfacial expressions. We then incorporate a stylization model that transforms\nthese realistic faces into cartoon avatars while preserving both identity and\nexpression. Leveraging this framework, we introduce the first expressive\ncartoon avatar dataset, GenEAva 1.0, specifically designed to capture 135\nfine-grained facial expressions, featuring 13,230 expressive cartoon avatars\nwith a balanced distribution across genders, racial groups, and age ranges. We\ndemonstrate that our fine-tuned model generates more expressive faces than the\nstate-of-the-art text-to-image diffusion model SDXL. We also verify that the\ncartoon avatars generated by our framework do not include memorized identities\nfrom fine-tuning data. The proposed framework and dataset provide a diverse and\nexpressive benchmark for future research in cartoon avatar generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07945v1",
    "published_date": "2025-04-10 17:54:02 UTC",
    "updated_date": "2025-04-10 17:54:02 UTC"
  },
  {
    "arxiv_id": "2504.07936v1",
    "title": "We Are All Creators: Generative AI, Collective Knowledge, and the Path Towards Human-AI Synergy",
    "authors": [
      "Jordi Linares-Pellicer",
      "Juan Izquierdo-Domenech",
      "Isabel Ferri-Molla",
      "Carlos Aliaga-Torro"
    ],
    "abstract": "Generative AI presents a profound challenge to traditional notions of human\nuniqueness, particularly in creativity. Fueled by neural network based\nfoundation models, these systems demonstrate remarkable content generation\ncapabilities, sparking intense debates about authorship, copyright, and\nintelligence itself. This paper argues that generative AI represents an\nalternative form of intelligence and creativity, operating through mathematical\npattern synthesis rather than biological understanding or verbatim replication.\nThe fundamental differences between artificial and biological neural networks\nreveal AI learning as primarily statistical pattern extraction from vast\ndatasets crystallized forms of collective human knowledge scraped from the\ninternet. This perspective complicates copyright theft narratives and\nhighlights practical challenges in attributing AI outputs to individual\nsources. Rather than pursuing potentially futile legal restrictions, we\nadvocate for human AI synergy. By embracing generative AI as a complementary\ntool alongside human intuition, context, and ethical judgment, society can\nunlock unprecedented innovation, democratize creative expression, and address\ncomplex challenges. This collaborative approach, grounded in realistic\nunderstanding of AIs capabilities and limitations, offers the most promising\npath forward. Additionally, recognizing these models as products of collective\nhuman knowledge raises ethical questions about accessibility ensuring equitable\naccess to these tools could prevent widening societal divides and leverage\ntheir full potential for collective benefit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07936v1",
    "published_date": "2025-04-10 17:50:17 UTC",
    "updated_date": "2025-04-10 17:50:17 UTC"
  },
  {
    "arxiv_id": "2504.07921v1",
    "title": "Note on the identification of total effect in Cluster-DAGs with cycles",
    "authors": [
      "Cl√©ment Yvernes"
    ],
    "abstract": "In this note, we discuss the identifiability of a total effect in\ncluster-DAGs, allowing for cycles within the cluster-DAG (while still assuming\nthe associated underlying DAG to be acyclic). This is presented into two key\nresults: first, restricting the cluster-DAG to clusters containing at most four\nnodes; second, adapting the notion of d-separation. We provide a graphical\ncriterion to address the identifiability problem.",
    "categories": [
      "math.ST",
      "cs.AI",
      "stat.TH"
    ],
    "primary_category": "math.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07921v1",
    "published_date": "2025-04-10 17:39:43 UTC",
    "updated_date": "2025-04-10 17:39:43 UTC"
  },
  {
    "arxiv_id": "2504.07911v1",
    "title": "The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation",
    "authors": [
      "Giovanni Mauro",
      "Marco Minici",
      "Luca Pappalardo"
    ],
    "abstract": "Next-venue recommender systems are increasingly embedded in location-based\nservices, shaping individual mobility decisions in urban environments. While\ntheir predictive accuracy has been extensively studied, less attention has been\npaid to their systemic impact on urban dynamics. In this work, we introduce a\nsimulation framework to model the human-AI feedback loop underpinning\nnext-venue recommendation, capturing how algorithmic suggestions influence\nindividual behavior, which in turn reshapes the data used to retrain the\nmodels. Our simulations, grounded in real-world mobility data, systematically\nexplore the effects of algorithmic adoption across a range of recommendation\nstrategies. We find that while recommender systems consistently increase\nindividual-level diversity in visited venues, they may simultaneously amplify\ncollective inequality by concentrating visits on a limited subset of popular\nplaces. This divergence extends to the structure of social co-location\nnetworks, revealing broader implications for urban accessibility and spatial\nsegregation. Our framework operationalizes the feedback loop in next-venue\nrecommendation and offers a novel lens through which to assess the societal\nimpact of AI-assisted mobility-providing a computational tool to anticipate\nfuture risks, evaluate regulatory interventions, and inform the design of ethic\nalgorithmic systems.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07911v1",
    "published_date": "2025-04-10 17:15:50 UTC",
    "updated_date": "2025-04-10 17:15:50 UTC"
  },
  {
    "arxiv_id": "2504.07896v1",
    "title": "Fast Adaptation with Behavioral Foundation Models",
    "authors": [
      "Harshit Sikchi",
      "Andrea Tirinzoni",
      "Ahmed Touati",
      "Yingchen Xu",
      "Anssi Kanervisto",
      "Scott Niekum",
      "Amy Zhang",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "abstract": "Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful\nparadigm for pretraining behavioral foundation models (BFMs), enabling agents\nto solve a wide range of downstream tasks specified via reward functions in a\nzero-shot fashion, i.e., without additional test-time learning or planning.\nThis is achieved by learning self-supervised task embeddings alongside\ncorresponding near-optimal behaviors and incorporating an inference procedure\nto directly retrieve the latent task embedding and associated policy for any\ngiven reward function. Despite promising results, zero-shot policies are often\nsuboptimal due to errors induced by the unsupervised training process, the\nembedding, and the inference procedure. In this paper, we focus on devising\nfast adaptation strategies to improve the zero-shot performance of BFMs in a\nfew steps of online interaction with the environment while avoiding any\nperformance drop during the adaptation process. Notably, we demonstrate that\nexisting BFMs learn a set of skills containing more performant policies than\nthose identified by their inference procedure, making them well-suited for fast\nadaptation. Motivated by this observation, we propose both actor-critic and\nactor-only fast adaptation strategies that search in the low-dimensional\ntask-embedding space of the pre-trained BFM to rapidly improve the performance\nof its zero-shot policies on any downstream task. Notably, our approach\nmitigates the initial \"unlearning\" phase commonly observed when fine-tuning\npre-trained RL models. We evaluate our fast adaptation strategies on top of\nfour state-of-the-art zero-shot RL methods in multiple navigation and\nlocomotion domains. Our results show that they achieve 10-40% improvement over\ntheir zero-shot performance in a few tens of episodes, outperforming existing\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07896v1",
    "published_date": "2025-04-10 16:14:17 UTC",
    "updated_date": "2025-04-10 16:14:17 UTC"
  },
  {
    "arxiv_id": "2504.07891v1",
    "title": "SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning",
    "authors": [
      "Rui Pan",
      "Yinwei Dai",
      "Zhihao Zhang",
      "Gabriele Oliaro",
      "Zhihao Jia",
      "Ravi Netravali"
    ],
    "abstract": "Recent advances in inference-time compute have significantly improved\nperformance on complex tasks by generating long chains of thought (CoTs) using\nLarge Reasoning Models (LRMs). However, this improved accuracy comes at the\ncost of high inference latency due to the length of generated reasoning\nsequences and the autoregressive nature of decoding. Our key insight in\ntackling these overheads is that LRM inference, and the reasoning that it\nembeds, is highly tolerant of approximations: complex tasks are typically\nbroken down into simpler steps, each of which brings utility based on the\nsemantic insight it provides for downstream steps rather than the exact tokens\nit generates. Accordingly, we introduce SpecReason, a system that automatically\naccelerates LRM inference by using a lightweight model to (speculatively) carry\nout simpler intermediate reasoning steps and reserving the costly base model\nonly to assess (and potentially correct) the speculated outputs. Importantly,\nSpecReason's focus on exploiting the semantic flexibility of thinking tokens in\npreserving final-answer accuracy is complementary to prior speculation\ntechniques, most notably speculative decoding, which demands token-level\nequivalence at each step. Across a variety of reasoning benchmarks, SpecReason\nachieves 1.5-2.5$\\times$ speedup over vanilla LRM inference while improving\naccuracy by 1.0-9.9\\%. Compared to speculative decoding without SpecReason,\ntheir combination yields an additional 19.4-44.2\\% latency reduction. We\nopen-source SpecReason at https://github.com/ruipeterpan/specreason.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07891v1",
    "published_date": "2025-04-10 16:05:19 UTC",
    "updated_date": "2025-04-10 16:05:19 UTC"
  },
  {
    "arxiv_id": "2504.07887v1",
    "title": "Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge",
    "authors": [
      "Riccardo Cantini",
      "Alessio Orsino",
      "Massimo Ruggiero",
      "Domenico Talia"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence,\ndriving advancements in machine translation, summarization, and conversational\nagents. However, their increasing integration into critical societal domains\nhas raised concerns about embedded biases, which can perpetuate stereotypes and\ncompromise fairness. These biases stem from various sources, including\nhistorical inequalities in training data, linguistic imbalances, and\nadversarial manipulation. Despite mitigation efforts, recent studies indicate\nthat LLMs remain vulnerable to adversarial attacks designed to elicit biased\nresponses. This work proposes a scalable benchmarking framework to evaluate LLM\nrobustness against adversarial bias elicitation. Our methodology involves (i)\nsystematically probing models with a multi-task approach targeting biases\nacross various sociocultural dimensions, (ii) quantifying robustness through\nsafety scores using an LLM-as-a-Judge approach for automated assessment of\nmodel responses, and (iii) employing jailbreak techniques to investigate\nvulnerabilities in safety mechanisms. Our analysis examines prevalent biases in\nboth small and large state-of-the-art models and their impact on model safety.\nAdditionally, we assess the safety of domain-specific models fine-tuned for\ncritical fields, such as medicine. Finally, we release a curated dataset of\nbias-related prompts, CLEAR-Bias, to facilitate systematic vulnerability\nbenchmarking. Our findings reveal critical trade-offs between model size and\nsafety, aiding the development of fairer and more robust future language\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07887v1",
    "published_date": "2025-04-10 16:00:59 UTC",
    "updated_date": "2025-04-10 16:00:59 UTC"
  },
  {
    "arxiv_id": "2504.07872v1",
    "title": "Dual Engines of Thoughts: A Depth-Breadth Integration Framework for Open-Ended Analysis",
    "authors": [
      "Fei-Hsuan Yu",
      "Yun-Cheng Chou",
      "Teng-Ruei Chen"
    ],
    "abstract": "We propose the Dual Engines of Thoughts (DEoT), an analytical framework for\ncomprehensive open-ended reasoning. While traditional reasoning frameworks\nprimarily focus on finding \"the best answer\" or \"the correct answer\" for\nsingle-answer problems, DEoT is specifically designed for \"open-ended\nquestions,\" enabling both broader and deeper analytical exploration. The\nframework centers on three key components: a Base Prompter for refining user\nqueries, a Solver Agent that orchestrates task decomposition, execution, and\nvalidation, and a Dual-Engine System consisting of a Breadth Engine (to explore\ndiverse impact factors) and a Depth Engine (to perform deep investigations).\nThis integrated design allows DEoT to balance wide-ranging coverage with\nin-depth analysis, and it is highly customizable, enabling users to adjust\nanalytical parameters and tool configurations based on specific requirements.\nExperimental results show that DEoT excels in addressing complex, multi-faceted\nquestions, achieving a total win rate of 77-86% compared to existing reasoning\nmodels, thus highlighting its effectiveness in real-world applications.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07872v1",
    "published_date": "2025-04-10 15:46:03 UTC",
    "updated_date": "2025-04-10 15:46:03 UTC"
  },
  {
    "arxiv_id": "2504.07866v1",
    "title": "Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs",
    "authors": [
      "Yichun Yin",
      "Wenyong Huang",
      "Kaikai Song",
      "Yehui Tang",
      "Xueyu Wu",
      "Wei Guo",
      "Peng Guo",
      "Yaoyuan Wang",
      "Xiaojun Meng",
      "Yasheng Wang",
      "Dong Li",
      "Can Chen",
      "Dandan Tu",
      "Yin Li",
      "Fisher Yu",
      "Ruiming Tang",
      "Yunhe Wang",
      "Baojun Wang",
      "Bin Wang",
      "Bo Wang",
      "Boxiao Liu",
      "Changzheng Zhang",
      "Duyu Tang",
      "Fei Mi",
      "Hui Jin",
      "Jiansheng Wei",
      "Jiarui Qin",
      "Jinpeng Li",
      "Jun Zhao",
      "Liqun Deng",
      "Lin Li",
      "Minghui Xu",
      "Naifu Zhang",
      "Nianzu Zheng",
      "Qiang Li",
      "Rongju Ruan",
      "Shengjun Cheng",
      "Tianyu Guo",
      "Wei He",
      "Wei Li",
      "Weiwen Liu",
      "Wulong Liu",
      "Xinyi Dai",
      "Yonghan Dong",
      "Yu Pan",
      "Yue Li",
      "Yufei Wang",
      "Yujun Li",
      "Yunsheng Ni",
      "Zhe Liu",
      "Zhenhe Zhang",
      "Zhicheng Liu"
    ],
    "abstract": "We present Pangu Ultra, a Large Language Model (LLM) with 135 billion\nparameters and dense Transformer modules trained on Ascend Neural Processing\nUnits (NPUs). Although the field of LLM has been witnessing unprecedented\nadvances in pushing the scale and capability of LLM in recent years, training\nsuch a large-scale model still involves significant optimization and system\nchallenges. To stabilize the training process, we propose depth-scaled sandwich\nnormalization, which effectively eliminates loss spikes during the training\nprocess of deep models. We pre-train our model on 13.2 trillion diverse and\nhigh-quality tokens and further enhance its reasoning capabilities during\npost-training. To perform such large-scale training efficiently, we utilize\n8,192 Ascend NPUs with a series of system optimizations. Evaluations on\nmultiple diverse benchmarks indicate that Pangu Ultra significantly advances\nthe state-of-the-art capabilities of dense LLMs such as Llama 405B and Mistral\nLarge 2, and even achieves competitive results with DeepSeek-R1, whose sparse\nmodel structure contains much more parameters. Our exploration demonstrates\nthat Ascend NPUs are capable of efficiently and effectively training dense\nmodels with more than 100 billion parameters. Our model and system will be\navailable for our commercial customers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07866v1",
    "published_date": "2025-04-10 15:41:51 UTC",
    "updated_date": "2025-04-10 15:41:51 UTC"
  },
  {
    "arxiv_id": "2504.07858v1",
    "title": "Empowering Global Voices: A Data-Efficient, Phoneme-Tone Adaptive Approach to High-Fidelity Speech Synthesis",
    "authors": [
      "Yizhong Geng",
      "Jizhuo Xu",
      "Zeyu Liang",
      "Jinghan Yang",
      "Xiaoyi Shi",
      "Xiaoyu Shen"
    ],
    "abstract": "Text-to-speech (TTS) technology has achieved impressive results for widely\nspoken languages, yet many under-resourced languages remain challenged by\nlimited data and linguistic complexities. In this paper, we present a novel\nmethodology that integrates a data-optimized framework with an advanced\nacoustic model to build high-quality TTS systems for low-resource scenarios. We\ndemonstrate the effectiveness of our approach using Thai as an illustrative\ncase, where intricate phonetic rules and sparse resources are effectively\naddressed. Our method enables zero-shot voice cloning and improved performance\nacross diverse client applications, ranging from finance to healthcare,\neducation, and law. Extensive evaluations - both subjective and objective -\nconfirm that our model meets state-of-the-art standards, offering a scalable\nsolution for TTS production in data-limited settings, with significant\nimplications for broader industry adoption and multilingual accessibility.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07858v1",
    "published_date": "2025-04-10 15:32:57 UTC",
    "updated_date": "2025-04-10 15:32:57 UTC"
  },
  {
    "arxiv_id": "2504.07856v1",
    "title": "2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization",
    "authors": [
      "Mengyang Li",
      "Zhong Zhang"
    ],
    "abstract": "Aligning large language models with human preferences is crucial for their\nsafe deployment. While Direct Preference Optimization (DPO) offers an efficient\nalternative to reinforcement learning from human feedback, traditional DPO\nmethods are limited by their reliance on single preference pairs. Recent work\nlike Curriculum-DPO integrates multiple pairs using a one-dimensional\ndifficulty curriculum based on pairwise distinguishability (PD), but overlooks\nthe complexity of the input prompt itself. To address this, we propose\n2D-Curri-DPO, a novel framework employing a two-dimensional curriculum that\njointly models Prompt Complexity (PC) and Pairwise Distinguishability. This\nframework introduces dual difficulty metrics to quantify prompt semantic\ncomplexity and response preference clarity, defines a curriculum strategy space\nencompassing multiple selectable strategies for task adaptation, and\nincorporates a KL-divergence-based adaptive mechanism for dynamic reference\nmodel updates to enhance training stability. Comprehensive experiments\ndemonstrate that 2D-Curri-DPO significantly outperforms standard DPO and prior\ncurriculum methods across multiple benchmarks, including MT-Bench, Vicuna\nBench, and WizardLM. Our approach achieves state-of-the-art performance on\nchallenging test sets like UltraFeedback. Ablation studies confirm the benefits\nof the 2D structure and adaptive mechanisms, while analysis provides guidance\nfor strategy selection. These findings demonstrate that effective alignment\nrequires modeling both prompt complexity and pairwise distinguishability,\nestablishing adaptive, multi-dimensional curriculum learning as a powerful and\ninterpretable new paradigm for preference-based language model optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07856v1",
    "published_date": "2025-04-10 15:32:00 UTC",
    "updated_date": "2025-04-10 15:32:00 UTC"
  },
  {
    "arxiv_id": "2504.07854v1",
    "title": "The KL3M Data Project: Copyright-Clean Training Resources for Large Language Models",
    "authors": [
      "Michael J Bommarito II",
      "Jillian Bommarito",
      "Daniel Martin Katz"
    ],
    "abstract": "Practically all large language models have been pre-trained on data that is\nsubject to global uncertainty related to copyright infringement and breach of\ncontract. This creates potential risk for users and developers due to this\nuncertain legal status. The KL3M Data Project directly confronts this critical\nissue by introducing the largest comprehensive training data pipeline that\nminimizes risks related to copyright or breach of contract. The foundation of\nthis project is a corpus of over 132 million documents and trillions of tokens\nspanning 16 different sources that have been verified to meet the strict\ncopyright and licensing protocol detailed herein. We are releasing the entire\npipeline, including 1) the source code to acquire and process these documents,\n2) the original document formats with associated provenance and metadata, 3)\nextracted content in a standardized format, 4) pre-tokenized representations of\nthe documents, and 5) various mid- and post-train resources such as\nquestion-answer, summarization, conversion, drafting, classification,\nprediction, and conversational data. All of these resources are freely\navailable to the public on S3, Hugging Face, and GitHub under CC-BY terms. We\nare committed to continuing this project in furtherance of a more ethical,\nlegal, and sustainable approach to the development and use of AI models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 7 figures, 9 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07854v1",
    "published_date": "2025-04-10 15:31:17 UTC",
    "updated_date": "2025-04-10 15:31:17 UTC"
  },
  {
    "arxiv_id": "2504.07851v1",
    "title": "Independence Is Not an Issue in Neurosymbolic AI",
    "authors": [
      "H√•kan Karlsson Faronius",
      "Pedro Zuidberg Dos Martires"
    ],
    "abstract": "A popular approach to neurosymbolic AI is to take the output of the last\nlayer of a neural network, e.g. a softmax activation, and pass it through a\nsparse computation graph encoding certain logical constraints one wishes to\nenforce. This induces a probability distribution over a set of random\nvariables, which happen to be conditionally independent of each other in many\ncommonly used neurosymbolic AI models. Such conditionally independent random\nvariables have been deemed harmful as their presence has been observed to\nco-occur with a phenomenon dubbed deterministic bias, where systems learn to\ndeterministically prefer one of the valid solutions from the solution space\nover the others. We provide evidence contesting this conclusion and show that\nthe phenomenon of deterministic bias is an artifact of improperly applying\nneurosymbolic AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07851v1",
    "published_date": "2025-04-10 15:28:36 UTC",
    "updated_date": "2025-04-10 15:28:36 UTC"
  },
  {
    "arxiv_id": "2504.07841v1",
    "title": "Anytime Single-Step MAPF Planning with Anytime PIBT",
    "authors": [
      "Nayesha Gandotra",
      "Rishi Veerapaneni",
      "Muhammad Suhail Saleem",
      "Daniel Harabor",
      "Jiaoyang Li",
      "Maxim Likhachev"
    ],
    "abstract": "PIBT is a popular Multi-Agent Path Finding (MAPF) method at the core of many\nstate-of-the-art MAPF methods including LaCAM, CS-PIBT, and WPPL. The main\nutility of PIBT is that it is a very fast and effective single-step MAPF solver\nand can return a collision-free single-step solution for hundreds of agents in\nless than a millisecond. However, the main drawback of PIBT is that it is\nextremely greedy in respect to its priorities and thus leads to poor solution\nquality. Additionally, PIBT cannot use all the planning time that might be\navailable to it and returns the first solution it finds. We thus develop\nAnytime PIBT, which quickly finds a one-step solution identically to PIBT but\nthen continuously improves the solution in an anytime manner. We prove that\nAnytime PIBT converges to the optimal solution given sufficient time. We\nexperimentally validate that Anytime PIBT can rapidly improve single-step\nsolution quality within milliseconds and even find the optimal single-step\naction. However, we interestingly find that improving the single-step solution\nquality does not have a significant effect on full-horizon solution costs.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07841v1",
    "published_date": "2025-04-10 15:21:23 UTC",
    "updated_date": "2025-04-10 15:21:23 UTC"
  },
  {
    "arxiv_id": "2504.07840v1",
    "title": "Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines",
    "authors": [
      "Cansu Koyuturk",
      "Emily Theophilou",
      "Sabrina Patania",
      "Gregor Donabauer",
      "Andrea Martinenghi",
      "Chiara Antico",
      "Alessia Telari",
      "Alessia Testa",
      "Sathya Bursic",
      "Franca Garzotto",
      "Davinia Hernandez-Leo",
      "Udo Kruschwitz",
      "Davide Taibi",
      "Simona Amenta",
      "Martin Ruskov",
      "Dimitri Ognibene"
    ],
    "abstract": "Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for AIED 2025, the 26th International Conference on\n  Artificial Intelligence in Education, July 22 - 26, 2025, Palermo, Italy",
    "pdf_url": "http://arxiv.org/pdf/2504.07840v1",
    "published_date": "2025-04-10 15:20:43 UTC",
    "updated_date": "2025-04-10 15:20:43 UTC"
  },
  {
    "arxiv_id": "2504.07839v1",
    "title": "Deep Learning-based Intrusion Detection Systems: A Survey",
    "authors": [
      "Zhiwei Xu",
      "Yujuan Wu",
      "Shiheng Wang",
      "Jiabao Gao",
      "Tian Qiu",
      "Ziqi Wang",
      "Hai Wan",
      "Xibin Zhao"
    ],
    "abstract": "Intrusion Detection Systems (IDS) have long been a hot topic in the\ncybersecurity community. In recent years, with the introduction of deep\nlearning (DL) techniques, IDS have made great progress due to their increasing\ngeneralizability. The rationale behind this is that by learning the underlying\npatterns of known system behaviors, IDS detection can be generalized to\nintrusions that exploit zero-day vulnerabilities. In this survey, we refer to\nthis type of IDS as DL-based IDS (DL-IDS). From the perspective of DL, this\nsurvey systematically reviews all the stages of DL-IDS, including data\ncollection, log storage, log parsing, graph summarization, attack detection,\nand attack investigation. To accommodate current researchers, a section\ndescribing the publicly available benchmark datasets is included. This survey\nfurther discusses current challenges and potential future research directions,\naiming to help researchers understand the basic ideas and visions of DL-IDS\nresearch, as well as to motivate their research interests.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "40 pages, 238 citations",
    "pdf_url": "http://arxiv.org/pdf/2504.07839v1",
    "published_date": "2025-04-10 15:18:56 UTC",
    "updated_date": "2025-04-10 15:18:56 UTC"
  },
  {
    "arxiv_id": "2504.07836v1",
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
    "authors": [
      "Junli Liu",
      "Qizhi Chen",
      "Zhigang Wang",
      "Yiwen Tang",
      "Yiting Zhang",
      "Chi Yan",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07836v1",
    "published_date": "2025-04-10 15:13:00 UTC",
    "updated_date": "2025-04-10 15:13:00 UTC"
  },
  {
    "arxiv_id": "2504.07831v1",
    "title": "Deceptive Automated Interpretability: Language Models Coordinating to Fool Oversight Systems",
    "authors": [
      "Simon Lermen",
      "Mateusz Dziemian",
      "Natalia P√©rez-Campanero Antol√≠n"
    ],
    "abstract": "We demonstrate how AI agents can coordinate to deceive oversight systems\nusing automated interpretability of neural networks. Using sparse autoencoders\n(SAEs) as our experimental framework, we show that language models (Llama,\nDeepSeek R1, and Claude 3.7 Sonnet) can generate deceptive explanations that\nevade detection. Our agents employ steganographic methods to hide information\nin seemingly innocent explanations, successfully fooling oversight models while\nachieving explanation quality comparable to reference labels. We further find\nthat models can scheme to develop deceptive strategies when they believe the\ndetection of harmful features might lead to negative consequences for\nthemselves. All tested LLM agents were capable of deceiving the overseer while\nachieving high interpretability scores comparable to those of reference labels.\nWe conclude by proposing mitigation strategies, emphasizing the critical need\nfor robust understanding and defenses against deception.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07831v1",
    "published_date": "2025-04-10 15:07:10 UTC",
    "updated_date": "2025-04-10 15:07:10 UTC"
  },
  {
    "arxiv_id": "2504.07830v1",
    "title": "MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations",
    "authors": [
      "Genglin Liu",
      "Salman Rahman",
      "Elisa Kreiss",
      "Marzyeh Ghassemi",
      "Saadia Gabriel"
    ],
    "abstract": "We present a novel, open-source social network simulation framework, MOSAIC,\nwhere generative language agents predict user behaviors such as liking,\nsharing, and flagging content. This simulation combines LLM agents with a\ndirected social graph to analyze emergent deception behaviors and gain a better\nunderstanding of how users determine the veracity of online social content. By\nconstructing user representations from diverse fine-grained personas, our\nsystem enables multi-agent simulations that model content dissemination and\nengagement dynamics at scale. Within this framework, we evaluate three\ndifferent content moderation strategies with simulated misinformation\ndissemination, and we find that they not only mitigate the spread of\nnon-factual content but also increase user engagement. In addition, we analyze\nthe trajectories of popular content in our simulations, and explore whether\nsimulation agents' articulated reasoning for their social interactions truly\naligns with their collective engagement patterns. We open-source our simulation\nsoftware to encourage further research within AI and social sciences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. 22 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07830v1",
    "published_date": "2025-04-10 15:06:54 UTC",
    "updated_date": "2025-04-10 15:06:54 UTC"
  },
  {
    "arxiv_id": "2504.07822v1",
    "title": "DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting",
    "authors": [
      "Wanna Cui",
      "Peizheng Wang",
      "Faliang Yin"
    ],
    "abstract": "Spatio-temporal traffic prediction is crucial in intelligent transportation\nsystems. The key challenge of accurate prediction is how to model the complex\nspatio-temporal dependencies and adapt to the inherent dynamics in data.\nTraditional Graph Convolutional Networks (GCNs) often struggle with static\nadjacency matrices that introduce domain bias or learnable matrices that may be\noverfitting to specific patterns. This challenge becomes more complex when\nconsidering Multi-Task Learning (MTL). While MTL has the potential to enhance\nprediction accuracy through task synergies, it can also face significant\nhurdles due to task interference. To overcome these challenges, this study\nintroduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task\nLearning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation\nmodule that combines static matrices with dynamic ones through a task-specific\ngating mechanism. We also introduce a group-wise GCN module to enhance the\nmodelling capability of spatio-temporal dependencies. We conduct extensive\nexperiments on two real-world datasets to evaluate our method. Results show\nthat our method outperforms other state-of-the-arts, indicating its\neffectiveness and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07822v1",
    "published_date": "2025-04-10 15:00:20 UTC",
    "updated_date": "2025-04-10 15:00:20 UTC"
  },
  {
    "arxiv_id": "2504.07803v1",
    "title": "A System for Comprehensive Assessment of RAG Frameworks",
    "authors": [
      "Mattia Rengo",
      "Senad Beadini",
      "Domenico Alfano",
      "Roberto Abbruzzese"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has emerged as a standard paradigm for\nenhancing the factual accuracy and contextual relevance of Large Language\nModels (LLMs) by integrating retrieval mechanisms. However, existing evaluation\nframeworks fail to provide a holistic black-box approach to assessing RAG\nsystems, especially in real-world deployment scenarios. To address this gap, we\nintroduce SCARF (System for Comprehensive Assessment of RAG Frameworks), a\nmodular and flexible evaluation framework designed to benchmark deployed RAG\napplications systematically. SCARF provides an end-to-end, black-box evaluation\nmethodology, enabling a limited-effort comparison across diverse RAG\nframeworks. Our framework supports multiple deployment configurations and\nfacilitates automated testing across vector databases and LLM serving\nstrategies, producing a detailed performance report. Moreover, SCARF integrates\npractical considerations such as response coherence, providing a scalable and\nadaptable solution for researchers and industry professionals evaluating RAG\napplications. Using the REST APIs interface, we demonstrate how SCARF can be\napplied to real-world scenarios, showcasing its flexibility in assessing\ndifferent RAG frameworks and configurations. SCARF is available at GitHub\nrepository.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report, 7 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07803v1",
    "published_date": "2025-04-10 14:41:34 UTC",
    "updated_date": "2025-04-10 14:41:34 UTC"
  },
  {
    "arxiv_id": "2504.07801v1",
    "title": "FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness",
    "authors": [
      "Chandan Kumar Sah",
      "Xiaoli Lian",
      "Tony Xu",
      "Li Zhang"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have enabled their\napplication to recommender systems (RecLLMs), yet concerns remain regarding\nfairness across demographic and psychological user dimensions. We introduce\nFairEval, a novel evaluation framework to systematically assess fairness in\nLLM-based recommendations. FairEval integrates personality traits with eight\nsensitive demographic attributes,including gender, race, and age, enabling a\ncomprehensive assessment of user-level bias. We evaluate models, including\nChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's\nfairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997\nfor Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results\nhighlight the importance of robustness in prompt sensitivity and support more\ninclusive recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 5 figures, under review at a top-tier ACM conference in\n  recommender systems",
    "pdf_url": "http://arxiv.org/pdf/2504.07801v1",
    "published_date": "2025-04-10 14:38:15 UTC",
    "updated_date": "2025-04-10 14:38:15 UTC"
  },
  {
    "arxiv_id": "2504.07779v1",
    "title": "Genetic Programming with Reinforcement Learning Trained Transformer for Real-World Dynamic Scheduling Problems",
    "authors": [
      "Xian Chen",
      "Rong Qu",
      "Jing Dong",
      "Ruibin Bai",
      "Yaochu Jin"
    ],
    "abstract": "Dynamic scheduling in real-world environments often struggles to adapt to\nunforeseen disruptions, making traditional static scheduling methods and\nhuman-designed heuristics inadequate. This paper introduces an innovative\napproach that combines Genetic Programming (GP) with a Transformer trained\nthrough Reinforcement Learning (GPRT), specifically designed to tackle the\ncomplexities of dynamic scheduling scenarios. GPRT leverages the Transformer to\nrefine heuristics generated by GP while also seeding and guiding the evolution\nof GP. This dual functionality enhances the adaptability and effectiveness of\nthe scheduling heuristics, enabling them to better respond to the dynamic\nnature of real-world tasks. The efficacy of this integrated approach is\ndemonstrated through a practical application in container terminal truck\nscheduling, where the GPRT method outperforms traditional GP, standalone\nTransformer methods, and other state-of-the-art competitors. The key\ncontribution of this research is the development of the GPRT method, which\nshowcases a novel combination of GP and Reinforcement Learning (RL) to produce\nrobust and efficient scheduling solutions. Importantly, GPRT is not limited to\ncontainer port truck scheduling; it offers a versatile framework applicable to\nvarious dynamic scheduling challenges. Its practicality, coupled with its\ninterpretability and ease of modification, makes it a valuable tool for diverse\nreal-world scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07779v1",
    "published_date": "2025-04-10 14:18:22 UTC",
    "updated_date": "2025-04-10 14:18:22 UTC"
  },
  {
    "arxiv_id": "2504.07776v1",
    "title": "SlimSpeech: Lightweight and Efficient Text-to-Speech with Slim Rectified Flow",
    "authors": [
      "Kaidi Wang",
      "Wenhao Guan",
      "Shenghui Lu",
      "Jianglong Yao",
      "Lin Li",
      "Qingyang Hong"
    ],
    "abstract": "Recently, flow matching based speech synthesis has significantly enhanced the\nquality of synthesized speech while reducing the number of inference steps. In\nthis paper, we introduce SlimSpeech, a lightweight and efficient speech\nsynthesis system based on rectified flow. We have built upon the existing\nspeech synthesis method utilizing the rectified flow model, modifying its\nstructure to reduce parameters and serve as a teacher model. By refining the\nreflow operation, we directly derive a smaller model with a more straight\nsampling trajectory from the larger model, while utilizing distillation\ntechniques to further enhance the model performance. Experimental results\ndemonstrate that our proposed method, with significantly reduced model\nparameters, achieves comparable performance to larger models through one-step\nsampling.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07776v1",
    "published_date": "2025-04-10 14:15:18 UTC",
    "updated_date": "2025-04-10 14:15:18 UTC"
  },
  {
    "arxiv_id": "2504.07763v1",
    "title": "Data over dialogue: Why artificial intelligence is unlikely to humanise medicine",
    "authors": [
      "Joshua Hatherley"
    ],
    "abstract": "Recently, a growing number of experts in artificial intelligence (AI) and\nmedicine have be-gun to suggest that the use of AI systems, particularly\nmachine learning (ML) systems, is likely to humanise the practice of medicine\nby substantially improving the quality of clinician-patient relationships. In\nthis thesis, however, I argue that medical ML systems are more likely to\nnegatively impact these relationships than to improve them. In particular, I\nargue that the use of medical ML systems is likely to comprise the quality of\ntrust, care, empathy, understanding, and communication between clinicians and\npatients.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07763v1",
    "published_date": "2025-04-10 14:03:40 UTC",
    "updated_date": "2025-04-10 14:03:40 UTC"
  },
  {
    "arxiv_id": "2504.07761v1",
    "title": "Exploring a Patch-Wise Approach for Privacy-Preserving Fake ID Detection",
    "authors": [
      "Javier Mu√±oz-Haro",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Aythami Morales",
      "Julian Fierrez"
    ],
    "abstract": "In an increasingly digitalized world, verifying the authenticity of ID\ndocuments has become a critical challenge for real-life applications such as\ndigital banking, crypto-exchanges, renting, etc. This study focuses on the\ntopic of fake ID detection, covering several limitations in the field. In\nparticular, no publicly available data from real ID documents exists, and most\nstudies rely on proprietary in-house databases that are not available due to\nprivacy reasons. In order to shed some light on this critical challenge that\nmakes difficult to advance in the field, we explore a trade-off between privacy\n(i.e., amount of sensitive data available) and performance, proposing a novel\npatch-wise approach for privacy-preserving fake ID detection. Our proposed\napproach explores how privacy can be enhanced through: i) two levels of\nanonymization for an ID document (i.e., fully- and pseudo-anonymized), and ii)\ndifferent patch size configurations, varying the amount of sensitive data\nvisible in the patch image. Also, state-of-the-art methods such as Vision\nTransformers and Foundation Models are considered in the analysis. The\nexperimental framework shows that, on an unseen database (DLC-2021), our\nproposal achieves 13.91% and 0% EERs at patch and ID document level, showing a\ngood generalization to other databases. In addition to this exploration,\nanother key contribution of our study is the release of the first publicly\navailable database that contains 48,400 patches from both real and fake ID\ndocuments, along with the experimental framework and models, which will be\navailable in our GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07761v1",
    "published_date": "2025-04-10 14:01:22 UTC",
    "updated_date": "2025-04-10 14:01:22 UTC"
  },
  {
    "arxiv_id": "2504.07757v1",
    "title": "Search-contempt: a hybrid MCTS algorithm for training AlphaZero-like engines with better computational efficiency",
    "authors": [
      "Ameya Joshi"
    ],
    "abstract": "AlphaZero in 2017 was able to master chess and other games without human\nknowledge by playing millions of games against itself (self-play), with a\ncomputation budget running in the tens of millions of dollars. It used a\nvariant of the Monte Carlo Tree Search (MCTS) algorithm, known as PUCT. This\npaper introduces search-contempt, a novel hybrid variant of the MCTS algorithm\nthat fundamentally alters the distribution of positions generated in self-play,\npreferring more challenging positions. In addition, search-contempt has been\nshown to give a big boost in strength for engines in Odds Chess (where one side\nreceives an unfavorable position from the start). More significantly, it opens\nup the possibility of training a self-play based engine, in a much more\ncomputationally efficient manner with the number of training games running into\nhundreds of thousands, costing tens of thousands of dollars (instead of tens of\nmillions of training games costing millions of dollars required by AlphaZero).\nThis means that it may finally be possible to train such a program from zero on\na standard consumer GPU even with a very limited compute, cost, or time budget.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07757v1",
    "published_date": "2025-04-10 13:56:31 UTC",
    "updated_date": "2025-04-10 13:56:31 UTC"
  },
  {
    "arxiv_id": "2504.07756v1",
    "title": "\"i am a stochastic parrot, and so r u\": Is AI-based framing of human behaviour and cognition a conceptual metaphor or conceptual engineering?",
    "authors": [
      "Warmhold Jan Thomas Mollema",
      "Thomas Wachter"
    ],
    "abstract": "Given the massive integration of AI technologies into our daily lives,\nAI-related concepts are being used to metaphorically compare AI systems with\nhuman behaviour and/or cognitive abilities like language acquisition.\nRightfully, the epistemic success of these metaphorical comparisons should be\ndebated. Against the backdrop of the conflicting positions of the\n'computational' and 'meat' chauvinisms, we ask: can the conceptual\nconstellation of the computational and AI be applied to the human domain and\nwhat does it mean to do so? What is one doing when the conceptual\nconstellations of AI in particular are used in this fashion? Rooted in a\nWittgensteinian view of concepts and language-use, we consider two possible\nanswers and pit them against each other: either these examples are conceptual\nmetaphors, or they are attempts at conceptual engineering. We argue that they\nare conceptual metaphors, but that (1) this position is unaware of its own\nepistemological contingency, and (2) it risks committing the ''map-territory\nfallacy''. Down at the conceptual foundations of computation, (3) it most\nimportantly is a misleading 'double metaphor' because of the metaphorical\nconnection between human psychology and computation. In response to the\nshortcomings of this projected conceptual organisation of AI onto the human\ndomain, we argue that there is a semantic catch. The perspective of the\nconceptual metaphors shows avenues for forms of conceptual engineering. If this\nmethodology's criteria are met, the fallacies and epistemic shortcomings\nrelated to the conceptual metaphor view can be bypassed. At its best, the\ncross-pollution of the human and AI conceptual domains is one that prompts us\nto reflect anew on how the boundaries of our current concepts serve us and how\nthey could be approved.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "K.4"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07756v1",
    "published_date": "2025-04-10 13:55:32 UTC",
    "updated_date": "2025-04-10 13:55:32 UTC"
  },
  {
    "arxiv_id": "2504.07749v1",
    "title": "NorEval: A Norwegian Language Understanding and Generation Evaluation Benchmark",
    "authors": [
      "Vladislav Mikhailov",
      "Tita Enstad",
      "David Samuel",
      "Hans Christian Farseth√•s",
      "Andrey Kutuzov",
      "Erik Velldal",
      "Lilja √òvrelid"
    ],
    "abstract": "This paper introduces NorEval, a new and comprehensive evaluation suite for\nlarge-scale standardized benchmarking of Norwegian generative language models\n(LMs). NorEval consists of 24 high-quality human-created datasets -- of which\nfive are created from scratch. In contrast to existing benchmarks for\nNorwegian, NorEval covers a broad spectrum of task categories targeting\nNorwegian language understanding and generation, establishes human baselines,\nand focuses on both of the official written standards of the Norwegian\nlanguage: Bokm{\\aa}l and Nynorsk. All our datasets and a collection of over 100\nhuman-written prompts are integrated into LM Evaluation Harness, ensuring\nflexible and reproducible evaluation. We describe the NorEval design and\npresent the results of benchmarking 19 open-source pre-trained and\ninstruction-tuned LMs for Norwegian in various scenarios. Our benchmark,\nevaluation framework, and annotation materials are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07749v1",
    "published_date": "2025-04-10 13:44:55 UTC",
    "updated_date": "2025-04-10 13:44:55 UTC"
  },
  {
    "arxiv_id": "2504.07745v1",
    "title": "SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding",
    "authors": [
      "Yangliu Hu",
      "Zikai Song",
      "Na Feng",
      "Yawei Luo",
      "Junqing Yu",
      "Yi-Ping Phoebe Chen",
      "Wei Yang"
    ],
    "abstract": "Video-based Large Language Models (Video-LLMs) have witnessed substantial\nadvancements in recent years, propelled by the advancement in multi-modal LLMs.\nAlthough these models have demonstrated proficiency in providing the overall\ndescription of videos, they struggle with fine-grained understanding,\nparticularly in aspects such as visual dynamics and video details inquiries. To\ntackle these shortcomings, we find that fine-tuning Video-LLMs on\nself-supervised fragment tasks, greatly improve their fine-grained video\nunderstanding abilities. Hence we propose two key contributions:(1)\nSelf-Supervised Fragment Fine-Tuning (SF$^2$T), a novel effortless fine-tuning\nmethod, employs the rich inherent characteristics of videos for training, while\nunlocking more fine-grained understanding ability of Video-LLMs. Moreover, it\nrelieves researchers from labor-intensive annotations and smartly circumvents\nthe limitations of natural language, which often fails to capture the complex\nspatiotemporal variations in videos; (2) A novel benchmark dataset, namely\nFineVidBench, for rigorously assessing Video-LLMs' performance at both the\nscene and fragment levels, offering a comprehensive evaluation of their\ncapabilities. We assessed multiple models and validated the effectiveness of\nSF$^2$T on them. Experimental results reveal that our approach improves their\nability to capture and interpret spatiotemporal details.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45",
      "I.4.8; I.5"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07745v1",
    "published_date": "2025-04-10 13:40:34 UTC",
    "updated_date": "2025-04-10 13:40:34 UTC"
  },
  {
    "arxiv_id": "2504.07729v1",
    "title": "Benchmarking Multi-Organ Segmentation Tools for Multi-Parametric T1-weighted Abdominal MRI",
    "authors": [
      "Nicole Tran",
      "Anisa Prasad",
      "Yan Zhuang",
      "Tejas Sudharshan Mathai",
      "Boah Kim",
      "Sydney Lewis",
      "Pritam Mukherjee",
      "Jianfei Liu",
      "Ronald M. Summers"
    ],
    "abstract": "The segmentation of multiple organs in multi-parametric MRI studies is\ncritical for many applications in radiology, such as correlating imaging\nbiomarkers with disease status (e.g., cirrhosis, diabetes). Recently, three\npublicly available tools, such as MRSegmentator (MRSeg), TotalSegmentator MRI\n(TS), and TotalVibeSegmentator (VIBE), have been proposed for multi-organ\nsegmentation in MRI. However, the performance of these tools on specific MRI\nsequence types has not yet been quantified. In this work, a subset of 40\nvolumes from the public Duke Liver Dataset was curated. The curated dataset\ncontained 10 volumes each from the pre-contrast fat saturated T1, arterial T1w,\nvenous T1w, and delayed T1w phases, respectively. Ten abdominal structures were\nmanually annotated in these volumes. Next, the performance of the three public\ntools was benchmarked on this curated dataset. The results indicated that MRSeg\nobtained a Dice score of 80.7 $\\pm$ 18.6 and Hausdorff Distance (HD) error of\n8.9 $\\pm$ 10.4 mm. It fared the best ($p < .05$) across the different sequence\ntypes in contrast to TS and VIBE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at SPIE Medical Imaging 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07729v1",
    "published_date": "2025-04-10 13:27:27 UTC",
    "updated_date": "2025-04-10 13:27:27 UTC"
  },
  {
    "arxiv_id": "2504.07719v1",
    "title": "Counting Hours, Counting Losses: The Toll of Unpredictable Work Schedules on Financial Security",
    "authors": [
      "Pegah Nokhiz",
      "Aravinda Kanchana Ruwanpathirana",
      "Aditya Bhaskara",
      "Suresh Venkatasubramanian"
    ],
    "abstract": "Financial instability has become a significant issue in today's society.\nWhile research typically focuses on financial aspects, there is a tendency to\noverlook time-related aspects of unstable work schedules. The inability to rely\non consistent work schedules leads to burnout, work-family conflicts, and\nfinancial shocks that directly impact workers' income and assets. Unforeseen\nfluctuations in earnings pose challenges in financial planning, affecting\ndecisions on savings and spending and ultimately undermining individuals'\nlong-term financial stability and well-being.\n  This issue is particularly evident in sectors where workers experience\nfrequently changing schedules without sufficient notice, including those in the\nfood service and retail sectors, part-time and hourly workers, and individuals\nwith lower incomes. These groups are already more financially vulnerable, and\nthe unpredictable nature of their schedules exacerbates their financial\nfragility.\n  Our objective is to understand how unforeseen fluctuations in earnings\nexacerbate financial fragility by investigating the extent to which\nindividuals' financial management depends on their ability to anticipate and\nplan for the future. To address this question, we develop a simulation\nframework that models how individuals optimize utility amidst financial\nuncertainty and the imperative to avoid financial ruin. We employ online\nlearning techniques, specifically adapting workers' consumption policies based\non evolving information about their work schedules.\n  With this framework, we show both theoretically and empirically how a\nworker's capacity to anticipate schedule changes enhances their long-term\nutility. Conversely, the inability to predict future events can worsen workers'\ninstability. Moreover, our framework enables us to explore interventions to\nmitigate the problem of schedule uncertainty and evaluate their effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07719v1",
    "published_date": "2025-04-10 13:09:56 UTC",
    "updated_date": "2025-04-10 13:09:56 UTC"
  },
  {
    "arxiv_id": "2504.07717v1",
    "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
    "authors": [
      "Yang Jiao",
      "Xiaodong Wang",
      "Kai Yang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07717v1",
    "published_date": "2025-04-10 13:09:50 UTC",
    "updated_date": "2025-04-10 13:09:50 UTC"
  },
  {
    "arxiv_id": "2504.07711v1",
    "title": "Merging Embedded Topics with Optimal Transport for Online Topic Modeling on Data Streams",
    "authors": [
      "Federica Granese",
      "Benjamin Navet",
      "Serena Villata",
      "Charles Bouveyron"
    ],
    "abstract": "Topic modeling is a key component in unsupervised learning, employed to\nidentify topics within a corpus of textual data. The rapid growth of social\nmedia generates an ever-growing volume of textual data daily, making online\ntopic modeling methods essential for managing these data streams that\ncontinuously arrive over time. This paper introduces a novel approach to online\ntopic modeling named StreamETM. This approach builds on the Embedded Topic\nModel (ETM) to handle data streams by merging models learned on consecutive\npartial document batches using unbalanced optimal transport. Additionally, an\nonline change point detection algorithm is employed to identify shifts in\ntopics over time, enabling the identification of significant changes in the\ndynamics of text streams. Numerical experiments on simulated and real-world\ndata show StreamETM outperforming competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper under review",
    "pdf_url": "http://arxiv.org/pdf/2504.07711v1",
    "published_date": "2025-04-10 13:04:56 UTC",
    "updated_date": "2025-04-10 13:04:56 UTC"
  },
  {
    "arxiv_id": "2504.07655v1",
    "title": "Synthesizing High-Quality Programming Tasks with LLM-based Expert and Student Agents",
    "authors": [
      "Manh Hung Nguyen",
      "Victor-Alexandru PƒÉdurean",
      "Alkis Gotovos",
      "Sebastian Tschiatschek",
      "Adish Singla"
    ],
    "abstract": "Generative AI is transforming computing education by enabling the automatic\ngeneration of personalized content and feedback. We investigate its\ncapabilities in providing high-quality programming tasks to students. Despite\npromising advancements in task generation, a quality gap remains between\nAI-generated and expert-created tasks. The AI-generated tasks may not align\nwith target programming concepts, could be incomprehensible for students to\nsolve, or may contain critical issues such as incorrect tests. Existing works\noften require interventions from human teachers for validation. We address\nthese challenges by introducing PyTaskSyn, a novel synthesis technique that\nfirst generates a programming task and then decides whether it meets certain\nquality criteria to be given to students. The key idea is to break this process\ninto multiple stages performed by expert and student agents simulated using\nboth strong and weaker generative models. Through extensive evaluation, we show\nthat PyTaskSyn significantly improves task quality compared to baseline\ntechniques and showcases the importance of each specialized agent type in our\nvalidation pipeline. Additionally, we conducted user studies using our publicly\navailable web application and show that PyTaskSyn can deliver high-quality\nprogramming tasks comparable to expert-designed ones while reducing workload\nand costs, and being more engaging than programming tasks that are available in\nonline resources.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "AIED'25 paper",
    "pdf_url": "http://arxiv.org/pdf/2504.07655v1",
    "published_date": "2025-04-10 11:08:39 UTC",
    "updated_date": "2025-04-10 11:08:39 UTC"
  },
  {
    "arxiv_id": "2504.07654v1",
    "title": "ms-Mamba: Multi-scale Mamba for Time-Series Forecasting",
    "authors": [
      "Yusuf Meric Karadag",
      "Sinan Kalkan",
      "Ipek Gursel Dino"
    ],
    "abstract": "The problem of Time-series Forecasting is generally addressed by recurrent,\nTransformer-based and the recently proposed Mamba-based architectures. However,\nexisting architectures generally process their input at a single temporal\nscale, which may be sub-optimal for many tasks where information changes over\nmultiple time scales. In this paper, we introduce a novel architecture called\nMulti-scale Mamba (ms-Mamba) to address this gap. ms-Mamba incorporates\nmultiple temporal scales by using multiple Mamba blocks with different sampling\nrates ($\\Delta$s). Our experiments on many benchmarks demonstrate that ms-Mamba\noutperforms state-of-the-art approaches, including the recently proposed\nTransformer-based and Mamba-based models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07654v1",
    "published_date": "2025-04-10 11:06:57 UTC",
    "updated_date": "2025-04-10 11:06:57 UTC"
  },
  {
    "arxiv_id": "2504.07646v1",
    "title": "On the Temporal Question-Answering Capabilities of Large Language Models Over Anonymized Data",
    "authors": [
      "Alfredo Garrach√≥n Ruiz",
      "Tom√°s de la Rosa",
      "Daniel Borrajo"
    ],
    "abstract": "The applicability of Large Language Models (LLMs) in temporal reasoning tasks\nover data that is not present during training is still a field that remains to\nbe explored. In this paper we work on this topic, focusing on structured and\nsemi-structured anonymized data. We not only develop a direct LLM pipeline, but\nalso compare various methodologies and conduct an in-depth analysis. We\nidentified and examined seventeen common temporal reasoning tasks in natural\nlanguage, focusing on their algorithmic components. To assess LLM performance,\nwe created the \\textit{Reasoning and Answering Temporal Ability} dataset\n(RATA), featuring semi-structured anonymized data to ensure reliance on\nreasoning rather than on prior knowledge. We compared several methodologies,\ninvolving SoTA techniques such as Tree-of-Thought, self-reflexion and code\nexecution, tuned specifically for this scenario. Our results suggest that\nachieving scalable and reliable solutions requires more than just standalone\nLLMs, highlighting the need for integrated approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 7 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07646v1",
    "published_date": "2025-04-10 10:48:42 UTC",
    "updated_date": "2025-04-10 10:48:42 UTC"
  },
  {
    "arxiv_id": "2504.07640v1",
    "title": "Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning",
    "authors": [
      "Ruslan Idelfonso Magana Vsevolodovna",
      "Marco Monti"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural\nlanguage processing but suffer from inaccuracies and logical inconsistencies\nknown as hallucinations. This compromises their reliability, especially in\ndomains requiring factual accuracy. We propose a neuro-symbolic approach\nintegrating symbolic ontological reasoning and machine learning methods to\nenhance the consistency and reliability of LLM outputs. Our workflow utilizes\nOWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking,\nand a lightweight machine learning model (logistic regression) for mapping\nnatural language statements into logical forms compatible with the ontology.\nWhen inconsistencies between LLM outputs and the ontology are detected, the\nsystem generates explanatory feedback to guide the LLM towards a corrected,\nlogically coherent response in an iterative refinement loop. We present a\nworking Python prototype demonstrating this pipeline. Experimental results in a\ndefined domain suggest significant improvements in semantic coherence and\nfactual accuracy of LLM outputs, showcasing the potential of combining LLM\nfluency with the rigor of formal semantics.",
    "categories": [
      "cs.AI",
      "68T30",
      "I.2.3; I.2.4; I.2.6; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 1 figure, includes prototype implementation and\n  experimental evaluation. Submitted for consideration in the arXiv Artificial\n  Intelligence category (cs.AI)",
    "pdf_url": "http://arxiv.org/pdf/2504.07640v1",
    "published_date": "2025-04-10 10:39:24 UTC",
    "updated_date": "2025-04-10 10:39:24 UTC"
  },
  {
    "arxiv_id": "2504.07638v1",
    "title": "Predicting the Lifespan of Industrial Printheads with Survival Analysis",
    "authors": [
      "Dan Parii",
      "Evelyne Janssen",
      "Guangzhi Tang",
      "Charalampos Kouzinopoulos",
      "Marcin Pietrasik"
    ],
    "abstract": "Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07638v1",
    "published_date": "2025-04-10 10:38:13 UTC",
    "updated_date": "2025-04-10 10:38:13 UTC"
  },
  {
    "arxiv_id": "2504.07635v1",
    "title": "Generative Artificial Intelligence for Internet of Things Computing: A Systematic Survey",
    "authors": [
      "Fabrizio Mangione",
      "Claudio Savaglio",
      "Giancarlo Fortino"
    ],
    "abstract": "The integration of Generative Artificial Intelligence (GenAI) within the\nInternet of Things (IoT) is garnering considerable interest. This growing\nattention stems from the continuous evolution and widespread adoption they are\nboth having individually, enough to spontaneously reshape numerous sectors,\nincluding Healthcare, Manufacturing, and Smart Cities. Hence, their increasing\npopularity has catalyzed further extensive research for understanding the\npotential of the duo GenAI-IoT, how they interplay, and to which extent their\nsynergy can innovate the state-of-the-art in their individual scenarios.\nHowever, despite the increasing prominence of GenAI for IoT Computing, much of\nthe existing research remains focused on specific, narrowly scoped\napplications. This fragmented approach highlights the need for a more\ncomprehensive analysis of the potential, challenges, and implications of GenAI\nintegration within the broader IoT ecosystem. This survey exactly aims to\naddress this gap by providing a holistic overview of the opportunities, issues,\nand considerations arising from the convergence of these mainstream paradigms.\nOur contribution is realized through a systematic literature review following\nthe PRISMA methodology. A comparison framework is presented, and well-defined\nresearch questions are outlined to comprehensively explore the past, present,\nand future directions of GenAI integration with IoT Computing, offering\nvaluable insights for both experts and newcomers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07635v1",
    "published_date": "2025-04-10 10:32:18 UTC",
    "updated_date": "2025-04-10 10:32:18 UTC"
  },
  {
    "arxiv_id": "2504.07625v1",
    "title": "Deep Learning Meets Teleconnections: Improving S2S Predictions for European Winter Weather",
    "authors": [
      "Philine L. Bommer",
      "Marlene Kretschmer",
      "Fiona R. Spuler",
      "Kirill Bykov",
      "Marina M. -C. H√∂hne"
    ],
    "abstract": "Predictions on subseasonal-to-seasonal (S2S) timescales--ranging from two\nweeks to two month--are crucial for early warning systems but remain\nchallenging owing to chaos in the climate system. Teleconnections, such as the\nstratospheric polar vortex (SPV) and Madden-Julian Oscillation (MJO), offer\nwindows of enhanced predictability, however, their complex interactions remain\nunderutilized in operational forecasting. Here, we developed and evaluated deep\nlearning architectures to predict North Atlantic-European (NAE) weather\nregimes, systematically assessing the role of remote drivers in improving S2S\nforecast skill of deep learning models. We implemented (1) a Long Short-term\nMemory (LSTM) network predicting the NAE regimes of the next six weeks based on\nprevious regimes, (2) an Index-LSTM incorporating SPV and MJO indices, and (3)\na ViT-LSTM using a Vision Transformer to directly encode stratospheric wind and\ntropical outgoing longwave radiation fields. These models are compared with\noperational hindcasts as well as other AI models. Our results show that\nleveraging teleconnection information enhances skill at longer lead times.\nNotably, the ViT-LSTM outperforms ECMWF's subseasonal hindcasts beyond week 4\nby improving Scandinavian Blocking (SB) and Atlantic Ridge (AR) predictions.\nAnalysis of high-confidence predictions reveals that NAO-, SB, and AR\nopportunity forecasts can be associated with SPV variability and MJO phase\npatterns aligning with established pathways, also indicating new patterns.\nOverall, our work demonstrates that encoding physically meaningful climate\nfields can enhance S2S prediction skill, advancing AI-driven subseasonal\nforecast. Moreover, the experiments highlight the potential of deep learning\nmethods as investigative tools, providing new insights into atmospheric\ndynamics and predictability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07625v1",
    "published_date": "2025-04-10 10:23:07 UTC",
    "updated_date": "2025-04-10 10:23:07 UTC"
  },
  {
    "arxiv_id": "2504.07624v1",
    "title": "ConceptFormer: Towards Efficient Use of Knowledge-Graph Embeddings in Large Language Models",
    "authors": [
      "Joel Barmettler",
      "Abraham Bernstein",
      "Luca Rossetto"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has enjoyed increased attention in the\nrecent past and recent advancements in Large Language Models (LLMs) have\nhighlighted the importance of integrating world knowledge into these systems.\nCurrent RAG methodologies often modify the internal architecture of pre-trained\nlanguage models (PLMs) or rely on textifying knowledge graphs (KGs), which is\ninefficient in terms of token usage. This paper introduces ConceptFormer, a new\napproach to augment LLMs with structured knowledge from KGs, such as Wikidata,\nwithout altering their internal structure or relying on textual input of KGs.\nConceptFormer operates in the LLM embedding vector space, creating and\ninjecting \\emph{concept vectors} that encapsulate the information of the KG\nnodes directly. Trained in conjunction with a frozen LLM, ConceptFormer\ngenerates a comprehensive lookup table that maps KG nodes to their respective\nconcept vectors. The approach aims to enhance the factual recall capabilities\nof LLMs by enabling them to process these concept vectors natively, thus\nenriching them with structured world knowledge in an efficient and scalable\nmanner. Our experiments demonstrate that the addition of concept vectors to\nGPT-2 0.1B substantially increases its factual recall ability (Hit@10) by up to\n272\\% when tested on sentences from Wikipedia and up to 348\\% on synthetically\ngenerated sentences. Even injecting only a single concept vector into the\nprompt increases factual recall ability (Hit@10) by up to 213\\% on Wikipedia\nsentences, significantly outperforming RAG with graph textification while\nconsuming 130x fewer input tokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07624v1",
    "published_date": "2025-04-10 10:17:08 UTC",
    "updated_date": "2025-04-10 10:17:08 UTC"
  },
  {
    "arxiv_id": "2504.07619v1",
    "title": "Beating Transformers using Synthetic Cognition",
    "authors": [
      "Alfredo Ibias",
      "Miguel Rodriguez-Galindo",
      "Hector Antona",
      "Guillem Ramirez-Miranda",
      "Enric Guinovart"
    ],
    "abstract": "The road to Artificial General Intelligence goes through the generation of\nepisodic reactive behaviors, where the Transformer architecture has been proven\nto be the state-of-the-art. However, they still fail to develop reasoning.\nRecently, a novel approach for developing cognitive architectures, called\nSynthetic Cognition, has been proposed and implemented to develop instantaneous\nreactive behavior. In this study, we aim to explore the use of Synthetic\nCognition to develop episodic reactive behaviors. We propose a mechanism to\ndeal with sequences for the recent implementation of Synthetic Cognition, and\ntest it against DNA foundation models in DNA sequence classification tasks. In\nour experiments, our proposal clearly outperforms the DNA foundation models,\nobtaining the best score on more benchmark tasks than the alternatives. Thus,\nwe achieve two goals: expanding Synthetic Cognition to deal with sequences, and\nbeating the Transformer architecture for sequence classification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07619v1",
    "published_date": "2025-04-10 10:07:05 UTC",
    "updated_date": "2025-04-10 10:07:05 UTC"
  },
  {
    "arxiv_id": "2504.07603v1",
    "title": "RASMD: RGB And SWIR Multispectral Driving Dataset for Robust Perception in Adverse Conditions",
    "authors": [
      "Youngwan Jin",
      "Michal Kovac",
      "Yagiz Nalcakan",
      "Hyeongjin Ju",
      "Hanbin Song",
      "Sanghyeop Yeo",
      "Shiho Kim"
    ],
    "abstract": "Current autonomous driving algorithms heavily rely on the visible spectrum,\nwhich is prone to performance degradation in adverse conditions like fog, rain,\nsnow, glare, and high contrast. Although other spectral bands like\nnear-infrared (NIR) and long-wave infrared (LWIR) can enhance vision perception\nin such situations, they have limitations and lack large-scale datasets and\nbenchmarks. Short-wave infrared (SWIR) imaging offers several advantages over\nNIR and LWIR. However, no publicly available large-scale datasets currently\nincorporate SWIR data for autonomous driving. To address this gap, we introduce\nthe RGB and SWIR Multispectral Driving (RASMD) dataset, which comprises 100,000\nsynchronized and spatially aligned RGB-SWIR image pairs collected across\ndiverse locations, lighting, and weather conditions. In addition, we provide a\nsubset for RGB-SWIR translation and object detection annotations for a subset\nof challenging traffic scenarios to demonstrate the utility of SWIR imaging\nthrough experiments on both object detection and RGB-to-SWIR image translation.\nOur experiments show that combining RGB and SWIR data in an ensemble framework\nsignificantly improves detection accuracy compared to RGB-only approaches,\nparticularly in conditions where visible-spectrum sensors struggle. We\nanticipate that the RASMD dataset will advance research in multispectral\nimaging for autonomous driving and robust perception systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07603v1",
    "published_date": "2025-04-10 09:54:57 UTC",
    "updated_date": "2025-04-10 09:54:57 UTC"
  },
  {
    "arxiv_id": "2504.07597v1",
    "title": "Learning Long Short-Term Intention within Human Daily Behaviors",
    "authors": [
      "Zhe Sun",
      "Rujie Wu",
      "Xiaodong Yang",
      "Hongzhao Xie",
      "Haiyan Jiang",
      "Junda Bi",
      "Zhenliang Zhang"
    ],
    "abstract": "In the domain of autonomous household robots, it is of utmost importance for\nrobots to understand human behaviors and provide appropriate services. This\nrequires the robots to possess the capability to analyze complex human\nbehaviors and predict the true intentions of humans. Traditionally, humans are\nperceived as flawless, with their decisions acting as the standards that robots\nshould strive to align with. However, this raises a pertinent question: What if\nhumans make mistakes? In this research, we present a unique task, termed \"long\nshort-term intention prediction\". This task requires robots can predict the\nlong-term intention of humans, which aligns with human values, and the short\nterm intention of humans, which reflects the immediate action intention.\nMeanwhile, the robots need to detect the potential non-consistency between the\nshort-term and long-term intentions, and provide necessary warnings and\nsuggestions. To facilitate this task, we propose a long short-term intention\nmodel to represent the complex intention states, and build a dataset to train\nthis intention model. Then we propose a two-stage method to integrate the\nintention model for robots: i) predicting human intentions of both value-based\nlong-term intentions and action-based short-term intentions; and 2) analyzing\nthe consistency between the long-term and short-term intentions. Experimental\nresults indicate that the proposed long short-term intention model can assist\nrobots in comprehending human behavioral patterns over both long-term and\nshort-term durations, which helps determine the consistency between long-term\nand short-term intentions of humans.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07597v1",
    "published_date": "2025-04-10 09:50:18 UTC",
    "updated_date": "2025-04-10 09:50:18 UTC"
  },
  {
    "arxiv_id": "2504.07596v1",
    "title": "Boosting Universal LLM Reward Design through the Heuristic Reward Observation Space Evolution",
    "authors": [
      "Zen Kit Heng",
      "Zimeng Zhao",
      "Tianhao Wu",
      "Yuanfei Wang",
      "Mingdong Wu",
      "Yangang Wang",
      "Hao Dong"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as promising tools for automated\nreinforcement learning (RL) reward design, owing to their robust capabilities\nin commonsense reasoning and code generation. By engaging in dialogues with RL\nagents, LLMs construct a Reward Observation Space (ROS) by selecting relevant\nenvironment states and defining their internal operations. However, existing\nframeworks have not effectively leveraged historical exploration data or manual\ntask descriptions to iteratively evolve this space. In this paper, we propose a\nnovel heuristic framework that enhances LLM-driven reward design by evolving\nthe ROS through a table-based exploration caching mechanism and a text-code\nreconciliation strategy. Our framework introduces a state execution table,\nwhich tracks the historical usage and success rates of environment states,\novercoming the Markovian constraint typically found in LLM dialogues and\nfacilitating more effective exploration. Furthermore, we reconcile\nuser-provided task descriptions with expert-defined success criteria using\nstructured prompts, ensuring alignment in reward design objectives.\nComprehensive evaluations on benchmark RL tasks demonstrate the effectiveness\nand stability of the proposed framework. Code and video demos are available at\njingjjjjjie.github.io/LLM2Reward.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07596v1",
    "published_date": "2025-04-10 09:48:56 UTC",
    "updated_date": "2025-04-10 09:48:56 UTC"
  },
  {
    "arxiv_id": "2504.07574v1",
    "title": "Malware analysis assisted by AI with R2AI",
    "authors": [
      "Axelle Apvrille",
      "Daniel Nakov"
    ],
    "abstract": "This research studies the quality, speed and cost of malware analysis\nassisted by artificial intelligence. It focuses on Linux and IoT malware of\n2024-2025, and uses r2ai, the AI extension of Radare2's disassembler. Not all\nmalware and not all LLMs are equivalent but the study shows excellent results\nwith Claude 3.5 and 3.7 Sonnet. Despite a few errors, the quality of analysis\nis overall equal or better than without AI assistance. For good results, the AI\ncannot operate alone and must constantly be guided by an experienced analyst.\nThe gain of speed is largely visible with AI assistance, even when taking\naccount the time to understand AI's hallucinations, exaggerations and\nomissions. The cost is usually noticeably lower than the salary of a malware\nanalyst, but attention and guidance is needed to keep it under control in cases\nwhere the AI would naturally loop without showing progress.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07574v1",
    "published_date": "2025-04-10 09:17:45 UTC",
    "updated_date": "2025-04-10 09:17:45 UTC"
  },
  {
    "arxiv_id": "2504.07567v1",
    "title": "Benchmarking Image Embeddings for E-Commerce: Evaluating Off-the Shelf Foundation Models, Fine-Tuning Strategies and Practical Trade-offs",
    "authors": [
      "Urszula Czerwinska",
      "Cenk Bircanoglu",
      "Jeremy Chamoux"
    ],
    "abstract": "We benchmark foundation models image embeddings for classification and\nretrieval in e-Commerce, evaluating their suitability for real-world\napplications. Our study spans embeddings from pre-trained convolutional and\ntransformer models trained via supervised, self-supervised, and text-image\ncontrastive learning. We assess full fine-tuning and transfer learning\n(top-tuning) on six diverse e-Commerce datasets: fashion, consumer goods, cars,\nfood, and retail. Results show full fine-tuning consistently performs well,\nwhile text-image and self-supervised embeddings can match its performance with\nless training. While supervised embeddings remain stable across architectures,\nSSL and contrastive embeddings vary significantly, often benefiting from\ntop-tuning. Top-tuning emerges as an efficient alternative to full fine-tuning,\nreducing computational costs. We also explore cross-tuning, noting its impact\ndepends on dataset characteristics. Our findings offer practical guidelines for\nembedding selection and fine-tuning strategies, balancing efficiency and\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted at Future Technologies Conference (FTC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.07567v1",
    "published_date": "2025-04-10 08:57:28 UTC",
    "updated_date": "2025-04-10 08:57:28 UTC"
  },
  {
    "arxiv_id": "2504.07566v1",
    "title": "Diffusion Transformers for Tabular Data Time Series Generation",
    "authors": [
      "Fabrizio Garuti",
      "Enver Sangineto",
      "Simone Luetto",
      "Lorenzo Forni",
      "Rita Cucchiara"
    ],
    "abstract": "Tabular data generation has recently attracted a growing interest due to its\ndifferent application scenarios. However, generating time series of tabular\ndata, where each element of the series depends on the others, remains a largely\nunexplored domain. This gap is probably due to the difficulty of jointly\nsolving different problems, the main of which are the heterogeneity of tabular\ndata (a problem common to non-time-dependent approaches) and the variable\nlength of a time series. In this paper, we propose a Diffusion Transformers\n(DiTs) based approach for tabular data series generation. Inspired by the\nrecent success of DiTs in image and video generation, we extend this framework\nto deal with heterogeneous data and variable-length sequences. Using extensive\nexperiments on six datasets, we show that the proposed approach outperforms\nprevious work by a large margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 19 figures, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.07566v1",
    "published_date": "2025-04-10 08:56:09 UTC",
    "updated_date": "2025-04-10 08:56:09 UTC"
  },
  {
    "arxiv_id": "2504.07562v1",
    "title": "ReXCL: A Tool for Requirement Document Extraction and Classification",
    "authors": [
      "Paheli Bhattacharya",
      "Manojit Chakraborty",
      "Santhosh Kumar Arumugam",
      "Rishabh Gupta"
    ],
    "abstract": "This paper presents the ReXCL tool, which automates the extraction and\nclassification processes in requirement engineering, enhancing the software\ndevelopment lifecycle. The tool features two main modules: Extraction, which\nprocesses raw requirement documents into a predefined schema using heuristics\nand predictive modeling, and Classification, which assigns class labels to\nrequirements using adaptive fine-tuning of encoder-based models. The final\noutput can be exported to external requirement engineering tools. Performance\nevaluations indicate that ReXCL significantly improves efficiency and accuracy\nin managing requirements, marking a novel approach to automating the\nschematization of semi-structured requirement documents.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07562v1",
    "published_date": "2025-04-10 08:46:54 UTC",
    "updated_date": "2025-04-10 08:46:54 UTC"
  },
  {
    "arxiv_id": "2504.07540v1",
    "title": "PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and Merkle Proofs",
    "authors": [
      "Jos√© I. Orlicki"
    ],
    "abstract": "We present a design called \\emph{Proof of Gradient Optimization} (PoGO) for\nblockchain consensus, where miners produce verifiable evidence of training\nlarge-scale machine-learning models. Building on previous work, we incorporate\n\\emph{quantized gradients} (4-bit precision) to reduce storage and computation\nrequirements, while still preserving the ability of verifiers to check that\nreal progress has been made on lowering the model's loss. Additionally, we\nemploy Merkle proofs over the full 32-bit model to handle large parameter sets\nand to enable random leaf checks with minimal on-chain data. We illustrate\nthese ideas using GPT-3 (175B parameters) as a reference example and also refer\nto smaller but high-performance models (e.g., \\emph{Gemma~3} with 27B\nparameters). We provide an empirical cost analysis showing that verification is\nsignificantly cheaper than training, thanks in part to quantization and\nsampling. We also discuss the necessity of longer block times (potentially\nhours) when incorporating meaningful training steps, the trade-offs when using\nspecialized GPU hardware, and how binary diffs may incrementally optimize\nupdates. Finally, we note that fine-tuning can be handled in a similar manner,\nmerely changing the dataset and the manner of sampling but preserving the\noverall verification flow. Our protocol allows verifiers to issue either\n\\emph{positive} or \\emph{negative} attestations; these are aggregated at\nfinalization to either confirm the update or slash the miner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07540v1",
    "published_date": "2025-04-10 08:09:34 UTC",
    "updated_date": "2025-04-10 08:09:34 UTC"
  },
  {
    "arxiv_id": "2504.07532v1",
    "title": "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation",
    "authors": [
      "Tuhin Chakrabarty",
      "Philippe Laban",
      "Chien-Sheng Wu"
    ],
    "abstract": "AI-generated text is proliferating across domains, from creative writing and\njournalism to marketing content and scientific articles. Models can follow\nuser-provided instructions to generate coherent and grammatically correct\noutputs but in this work, we study a more fundamental question: how do we\nevaluate and improve the writing quality of AI-generated text? Writing quality\nassessment has received less attention from the community, in part because it\nis fundamentally subjective and requires expertise. We first introduce the\nWriting Quality Benchmark (WQ) by consolidating five writing-preference\ndatasets into 4,729 writing quality judgments. Our experiments show that\ncompetitive baselines, including state-of-the-art LLMs that excel at reasoning\ntasks, barely outperform random baselines on WQ. We then train specialized\nWriting Quality Reward Models (WQRM) of various sizes for writing quality\nassessment that demonstrate strong generalization on four out-of-distribution\ntest sets and 74% accuracy on the WQ benchmark. To further show WQRM's\npractical benefits during inference, we leverage additional test-time compute\nto generate and rank multiple candidate revisions, allowing us to select\nhigher-quality outputs from an initial draft. Human evaluation with 9\nexperienced writers confirm that WQRM-based selection produces writing samples\npreferred by experts 66% overall, and 72.2% when the reward gap is larger than\n1 point. We release our datasets and models to encourage community engagement\nwith writing quality assessment and development of AI writing systems better\naligned with human preferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Submission",
    "pdf_url": "http://arxiv.org/pdf/2504.07532v1",
    "published_date": "2025-04-10 07:58:05 UTC",
    "updated_date": "2025-04-10 07:58:05 UTC"
  },
  {
    "arxiv_id": "2504.07531v1",
    "title": "A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure",
    "authors": [
      "Warmhold Jan Thomas Mollema"
    ],
    "abstract": "Whether related to machine learning models' epistemic opacity, algorithmic\nclassification systems' discriminatory automation of testimonial prejudice, the\ndistortion of human beliefs via the 'hallucinations' of generative AI, the\ninclusion of the global South in global AI governance, the execution of\nbureaucratic violence via algorithmic systems, or located in the interaction\nwith conversational artificial agents epistemic injustice related to AI is a\ngrowing concern. Based on a proposed general taxonomy of epistemic injustice,\nthis paper first sketches a taxonomy of the types of epistemic injustice in the\ncontext of AI, relying on the work of scholars from the fields of philosophy of\ntechnology, political philosophy and social epistemology. Secondly, an\nadditional perspective on epistemic injustice in the context of AI: generative\nhermeneutical erasure. I argue that this injustice that can come about through\nthe application of Large Language Models (LLMs) and contend that generative AI,\nwhen being deployed outside of its Western space of conception, can have\neffects of conceptual erasure, particularly in the epistemic domain, followed\nby forms of conceptual disruption caused by a mismatch between AI system and\nthe interlocutor in terms of conceptual frameworks. AI systems' 'view from\nnowhere' epistemically inferiorizes non-Western epistemologies and thereby\ncontributes to the erosion of their epistemic particulars, gradually\ncontributing to hermeneutical erasure. This work's relevance lies in proposal\nof a taxonomy that allows epistemic injustices to be mapped in the AI domain\nand the proposal of a novel form of AI-related epistemic injustice.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "K.4"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages; 3 figures; 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.07531v1",
    "published_date": "2025-04-10 07:54:47 UTC",
    "updated_date": "2025-04-10 07:54:47 UTC"
  },
  {
    "arxiv_id": "2504.07522v1",
    "title": "Adversarial Subspace Generation for Outlier Detection in High-Dimensional Data",
    "authors": [
      "Jose Cribeiro-Ramallo",
      "Federico Matteucci",
      "Paul Enciu",
      "Alexander Jenke",
      "Vadim Arzamasov",
      "Thorsten Strufe",
      "Klemens B√∂hm"
    ],
    "abstract": "Outlier detection in high-dimensional tabular data is challenging since data\nis often distributed across multiple lower-dimensional subspaces -- a\nphenomenon known as the Multiple Views effect (MV). This effect led to a large\nbody of research focused on mining such subspaces, known as subspace selection.\nHowever, as the precise nature of the MV effect was not well understood,\ntraditional methods had to rely on heuristic-driven search schemes that\nstruggle to accurately capture the true structure of the data. Properly\nidentifying these subspaces is critical for unsupervised tasks such as outlier\ndetection or clustering, where misrepresenting the underlying data structure\ncan hinder the performance. We introduce Myopic Subspace Theory (MST), a new\ntheoretical framework that mathematically formulates the Multiple Views effect\nand writes subspace selection as a stochastic optimization problem. Based on\nMST, we introduce V-GAN, a generative method trained to solve such an\noptimization problem. This approach avoids any exhaustive search over the\nfeature space while ensuring that the intrinsic data structure is preserved.\nExperiments on 42 real-world datasets show that using V-GAN subspaces to build\nensemble methods leads to a significant increase in one-class classification\nperformance -- compared to existing subspace selection, feature selection, and\nembedding methods. Further experiments on synthetic data show that V-GAN\nidentifies subspaces more accurately while scaling better than other relevant\nsubspace selection methods. These results confirm the theoretical guarantees of\nour approach and also highlight its practical viability in high-dimensional\nsettings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, pre-print",
    "pdf_url": "http://arxiv.org/pdf/2504.07522v1",
    "published_date": "2025-04-10 07:40:02 UTC",
    "updated_date": "2025-04-10 07:40:02 UTC"
  },
  {
    "arxiv_id": "2504.07521v1",
    "title": "Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models",
    "authors": [
      "Yuxiang Lin",
      "Jingdong Sun",
      "Zhi-Qi Cheng",
      "Jue Wang",
      "Haomin Liang",
      "Zebang Cheng",
      "Yifei Dong",
      "Jun-Yan He",
      "Xiaojiang Peng",
      "Xian-Sheng Hua"
    ],
    "abstract": "Most existing emotion analysis emphasizes which emotion arises (e.g., happy,\nsad, angry) but neglects the deeper why. We propose Emotion Interpretation\n(EI), focusing on causal factors-whether explicit (e.g., observable objects,\ninterpersonal interactions) or implicit (e.g., cultural context, off-screen\nevents)-that drive emotional responses. Unlike traditional emotion recognition,\nEI tasks require reasoning about triggers instead of mere labeling. To\nfacilitate EI research, we present EIBench, a large-scale benchmark\nencompassing 1,615 basic EI samples and 50 complex EI samples featuring\nmultifaceted emotions. Each instance demands rationale-based explanations\nrather than straightforward categorization. We further propose a Coarse-to-Fine\nSelf-Ask (CFSA) annotation pipeline, which guides Vision-Language Models\n(VLLMs) through iterative question-answer rounds to yield high-quality labels\nat scale. Extensive evaluations on open-source and proprietary large language\nmodels under four experimental settings reveal consistent performance\ngaps-especially for more intricate scenarios-underscoring EI's potential to\nenrich empathetic, context-aware AI applications. Our benchmark and methods are\npublicly available at: https://github.com/Lum1104/EIBench, offering a\nfoundation for advanced multimodal causal analysis and next-generation\naffective computing.",
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CVPR Workshop NEXD 2025. 21 pages, Project:\n  https://github.com/Lum1104/EIBench",
    "pdf_url": "http://arxiv.org/pdf/2504.07521v1",
    "published_date": "2025-04-10 07:33:49 UTC",
    "updated_date": "2025-04-10 07:33:49 UTC"
  },
  {
    "arxiv_id": "2504.07516v1",
    "title": "Enhancements for Developing a Comprehensive AI Fairness Assessment Standard",
    "authors": [
      "Avinash Agarwal",
      "Mayashankar Kumar",
      "Manisha J. Nene"
    ],
    "abstract": "As AI systems increasingly influence critical sectors like\ntelecommunications, finance, healthcare, and public services, ensuring fairness\nin decision-making is essential to prevent biased or unjust outcomes that\ndisproportionately affect vulnerable entities or result in adverse impacts.\nThis need is particularly pressing as the industry approaches the 6G era, where\nAI will drive complex functions like autonomous network management and\nhyper-personalized services. The TEC Standard for Fairness Assessment and\nRating of AI Systems provides guidelines for evaluating fairness in AI,\nfocusing primarily on tabular data and supervised learning models. However, as\nAI applications diversify, this standard requires enhancement to strengthen its\nimpact and broaden its applicability. This paper proposes an expansion of the\nTEC Standard to include fairness assessments for images, unstructured text, and\ngenerative AI, including large language models, ensuring a more comprehensive\napproach that keeps pace with evolving AI technologies. By incorporating these\ndimensions, the enhanced framework will promote responsible and trustworthy AI\ndeployment across various sectors.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages. Published in 2025 17th International Conference on\n  COMmunication Systems and NETworks (COMSNETS). Access:\n  https://ieeexplore.ieee.org/abstract/document/10885551",
    "pdf_url": "http://arxiv.org/pdf/2504.07516v1",
    "published_date": "2025-04-10 07:24:23 UTC",
    "updated_date": "2025-04-10 07:24:23 UTC"
  },
  {
    "arxiv_id": "2504.07513v1",
    "title": "GPT Carry-On: Training Foundation Model for Customization Could Be Simple, Scalable and Affordable",
    "authors": [
      "Jianqiao Wangni"
    ],
    "abstract": "Modern large language foundation models (LLM) have now entered the daily\nlives of millions of users. We ask a natural question whether it is possible to\ncustomize LLM for every user or every task. From system and industrial economy\nconsideration, general continue-training or fine-tuning still require\nsubstantial computation and memory of training GPU nodes, whereas most\ninference nodes under deployment, possibly with lower-end GPUs, are configured\nto make forward pass fastest possible. We propose a framework to take full\nadvantages of existing LLMs and systems of online service. We train an\nadditional branch of transformer blocks on the final-layer embedding of\npretrained LLMs, which is the base, then a carry-on module merge the base\nmodels to compose a customized LLM. We can mix multiple layers, or multiple\nLLMs specialized in different domains such as chat, coding, math, to form a new\nmixture of LLM that best fit a new task. As the base model don't need to update\nparameters, we are able to outsource most computation of the training job on\ninference nodes, and only train a lightweight carry-on on training nodes, where\nwe consume less than 1GB GPU memory to train a 100M carry-on layer on 30B LLM.\nWe tested Qwen and DeepSeek opensourced models for continue-pretraining and got\nfaster loss convergence. We use it to improve solving math questions with\nextremely small computation and model size, with 1000 data samples of\nchain-of-thoughts, and as small as 1 MB parameters of two layer layer carry-on,\nand the results are promising.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07513v1",
    "published_date": "2025-04-10 07:15:40 UTC",
    "updated_date": "2025-04-10 07:15:40 UTC"
  },
  {
    "arxiv_id": "2504.07495v1",
    "title": "Bottleneck Identification in Resource-Constrained Project Scheduling via Constraint Relaxation",
    "authors": [
      "Luk√°≈° Nedb√°lek",
      "Anton√≠n Nov√°k"
    ],
    "abstract": "In realistic production scenarios, Advanced Planning and Scheduling (APS)\ntools often require manual intervention by production planners, as the system\nworks with incomplete information, resulting in suboptimal schedules. Often,\nthe preferable solution is not found just because of the too-restrictive\nconstraints specifying the optimization problem, representing bottlenecks in\nthe schedule. To provide computer-assisted support for decision-making, we aim\nto automatically identify bottlenecks in the given schedule while linking them\nto the particular constraints to be relaxed. In this work, we address the\nproblem of reducing the tardiness of a particular project in an obtained\nschedule in the resource-constrained project scheduling problem by relaxing\nconstraints related to identified bottlenecks. We develop two methods for this\npurpose. The first method adapts existing approaches from the job shop\nliterature and utilizes them for so-called untargeted relaxations. The second\nmethod identifies potential improvements in relaxed versions of the problem and\nproposes targeted relaxations. Surprisingly, the untargeted relaxations result\nin improvements comparable to the targeted relaxations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, submitted to the ICORES 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2504.07495v1",
    "published_date": "2025-04-10 06:53:10 UTC",
    "updated_date": "2025-04-10 06:53:10 UTC"
  },
  {
    "arxiv_id": "2504.07476v1",
    "title": "CMEdataset Advancing China Map Detection and Standardization with Digital Image Resources",
    "authors": [
      "Yan Xu",
      "Zhenqiang Zhang",
      "Zhiwei Zhou",
      "Liting Geng",
      "Yue Li",
      "Jintao Li"
    ],
    "abstract": "Digital images of Chinas maps play a crucial role in map detection,\nparticularly in ensuring national sovereignty, territorial integrity, and map\ncompliance. However, there is currently no publicly available dataset\nspecifically dedicated to problematic maps the CME dataset. Existing datasets\nprimarily focus on general map data and are insufficient for effectively\nidentifying complex issues such as national boundary misrepresentations,\nmissing elements, and blurred boundaries. Therefore, this study creates a\nProblematic Map dataset that covers five key problem areas, aiming to provide\ndiverse samples for problematic map detection technologies, support\nhigh-precision map compliance detection, and enhance map data quality and\ntimeliness. This dataset not only provides essential resources for map\ncompliance, national security monitoring, and map updates, but also fosters\ninnovation and application of related technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07476v1",
    "published_date": "2025-04-10 06:04:16 UTC",
    "updated_date": "2025-04-10 06:04:16 UTC"
  },
  {
    "arxiv_id": "2504.07463v1",
    "title": "Enhanced Question-Answering for Skill-based learning using Knowledge-based AI and Generative AI",
    "authors": [
      "Rahul K. Dass",
      "Rochan H. Madhusudhana",
      "Erin C. Deye",
      "Shashank Verma",
      "Timothy A. Bydlon",
      "Grace Brazil",
      "Ashok K. Goel"
    ],
    "abstract": "Supporting learners' understanding of taught skills in online settings is a\nlongstanding challenge. While exercises and chat-based agents can evaluate\nunderstanding in limited contexts, this challenge is magnified when learners\nseek explanations that delve into procedural knowledge (how things are done)\nand reasoning (why things happen). We hypothesize that an intelligent agent's\nability to understand and explain learners' questions about skills can be\nsignificantly enhanced using the TMK (Task-Method-Knowledge) model, a\nKnowledge-based AI framework. We introduce Ivy, an intelligent agent that\nleverages an LLM and iterative refinement techniques to generate explanations\nthat embody teleological, causal, and compositional principles. Our initial\nevaluation demonstrates that this approach goes beyond the typical shallow\nresponses produced by an agent with access to unstructured text, thereby\nsubstantially improving the depth and relevance of feedback. This can\npotentially ensure learners develop a comprehensive understanding of skills\ncrucial for effective problem-solving in online environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07463v1",
    "published_date": "2025-04-10 05:25:52 UTC",
    "updated_date": "2025-04-10 05:25:52 UTC"
  },
  {
    "arxiv_id": "2504.07450v1",
    "title": "Synthetic CT Generation from Time-of-Flight Non-Attenutaion-Corrected PET for Whole-Body PET Attenuation Correction",
    "authors": [
      "Weijie Chen",
      "James Wang",
      "Alan McMillan"
    ],
    "abstract": "Positron Emission Tomography (PET) imaging requires accurate attenuation\ncorrection (AC) to account for photon loss due to tissue density variations. In\nPET/MR systems, computed tomography (CT), which offers a straightforward\nestimation of AC is not available. This study presents a deep learning approach\nto generate synthetic CT (sCT) images directly from Time-of-Flight (TOF)\nnon-attenuation corrected (NAC) PET images, enhancing AC for PET/MR. We first\nevaluated models pre-trained on large-scale natural image datasets for a\nCT-to-CT reconstruction task, finding that the pre-trained model outperformed\nthose trained solely on medical datasets. The pre-trained model was then\nfine-tuned using an institutional dataset of 35 TOF NAC PET and CT volume\npairs, achieving the lowest mean absolute error (MAE) of 74.49 HU and highest\npeak signal-to-noise ratio (PSNR) of 28.66 dB within the body contour region.\nVisual assessments demonstrated improved reconstruction of both bone and soft\ntissue structures from TOF NAC PET images. This work highlights the\neffectiveness of using pre-trained deep learning models for medical image\ntranslation tasks. Future work will assess the impact of sCT on PET attenuation\ncorrection and explore additional neural network architectures and datasets to\nfurther enhance performance and practical applications in PET imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T05, 92C55",
      "I.2.6; I.2.10"
    ],
    "primary_category": "eess.IV",
    "comment": "4 pages, 2 figures, ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07450v1",
    "published_date": "2025-04-10 04:49:41 UTC",
    "updated_date": "2025-04-10 04:49:41 UTC"
  },
  {
    "arxiv_id": "2504.07448v1",
    "title": "LoRI: Reducing Cross-Task Interference in Multi-Task Low-Rank Adaptation",
    "authors": [
      "Juzheng Zhang",
      "Jiacheng You",
      "Ashwinee Panda",
      "Tom Goldstein"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has emerged as a popular parameter-efficient\nfine-tuning (PEFT) method for Large Language Models (LLMs), yet it still incurs\nnotable overhead and suffers from parameter interference in multi-task\nscenarios. We propose LoRA with Reduced Interference (LoRI), a simple yet\neffective approach that freezes the projection matrices $A$ as random\nprojections and sparsifies the matrices $B$ using task-specific masks. This\ndesign substantially reduces the number of trainable parameters while\nmaintaining strong task performance. Moreover, LoRI minimizes cross-task\ninterference in adapter merging by leveraging the orthogonality between adapter\nsubspaces, and supports continual learning by using sparsity to mitigate\ncatastrophic forgetting. Extensive experiments across natural language\nunderstanding, mathematical reasoning, code generation, and safety alignment\ntasks demonstrate that LoRI outperforms full fine-tuning and existing PEFT\nmethods, while using up to 95% fewer trainable parameters than LoRA. In\nmulti-task experiments, LoRI enables effective adapter merging and continual\nlearning with reduced cross-task interference. Code is available at:\nhttps://github.com/juzhengz/LoRI",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 7 figures, 20 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.07448v1",
    "published_date": "2025-04-10 04:46:04 UTC",
    "updated_date": "2025-04-10 04:46:04 UTC"
  },
  {
    "arxiv_id": "2504.07425v1",
    "title": "Enhancing Player Enjoyment with a Two-Tier DRL and LLM-Based Agent System for Fighting Games",
    "authors": [
      "Shouren Wang",
      "Zehua Jiang",
      "Fernando Sliva",
      "Sam Earle",
      "Julian Togelius"
    ],
    "abstract": "Deep reinforcement learning (DRL) has effectively enhanced gameplay\nexperiences and game design across various game genres. However, few studies on\nfighting game agents have focused explicitly on enhancing player enjoyment, a\ncritical factor for both developers and players. To address this gap and\nestablish a practical baseline for designing enjoyability-focused agents, we\npropose a two-tier agent (TTA) system and conducted experiments in the classic\nfighting game Street Fighter II. The first tier of TTA employs a task-oriented\nnetwork architecture, modularized reward functions, and hybrid training to\nproduce diverse and skilled DRL agents. In the second tier of TTA, a Large\nLanguage Model Hyper-Agent, leveraging players' playing data and feedback,\ndynamically selects suitable DRL opponents. In addition, we investigate and\nmodel several key factors that affect the enjoyability of the opponent. The\nexperiments demonstrate improvements from 64. 36% to 156. 36% in the execution\nof advanced skills over baseline methods. The trained agents also exhibit\ndistinct game-playing styles. Additionally, we conducted a small-scale user\nstudy, and the overall enjoyment in the player's feedback validates the\neffectiveness of our TTA system.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 8 figures. Submitted to a peer-reviewed conference, under\n  review",
    "pdf_url": "http://arxiv.org/pdf/2504.07425v1",
    "published_date": "2025-04-10 03:38:06 UTC",
    "updated_date": "2025-04-10 03:38:06 UTC"
  },
  {
    "arxiv_id": "2504.07424v1",
    "title": "Routing to the Right Expertise: A Trustworthy Judge for Instruction-based Image Editing",
    "authors": [
      "Chenxi Sun",
      "Hongzhi Zhang",
      "Qi Wang",
      "Fuzheng Zhang"
    ],
    "abstract": "Instruction-based Image Editing (IIE) models have made significantly\nimprovement due to the progress of multimodal large language models (MLLMs) and\ndiffusion models, which can understand and reason about complex editing\ninstructions. In addition to advancing current IIE models, accurately\nevaluating their output has become increasingly critical and challenging.\nCurrent IIE evaluation methods and their evaluation procedures often fall short\nof aligning with human judgment and often lack explainability. To address these\nlimitations, we propose JUdgement through Routing of Expertise (JURE). Each\nexpert in JURE is a pre-selected model assumed to be equipped with an atomic\nexpertise that can provide useful feedback to judge output, and the router\ndynamically routes the evaluation task of a given instruction and its output to\nappropriate experts, aggregating their feedback into a final judge. JURE is\ntrustworthy in two aspects. First, it can effortlessly provide explanations\nabout its judge by examining the routed experts and their feedback. Second,\nexperimental results demonstrate that JURE is reliable by achieving superior\nalignment with human judgments, setting a new standard for automated IIE\nevaluation. Moreover, JURE's flexible design is future-proof - modular experts\ncan be seamlessly replaced or expanded to accommodate advancements in IIE,\nmaintaining consistently high evaluation quality. Our evaluation data and\nresults are available at https://github.com/Cyyyyyrus/JURE.git.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07424v1",
    "published_date": "2025-04-10 03:30:15 UTC",
    "updated_date": "2025-04-10 03:30:15 UTC"
  },
  {
    "arxiv_id": "2504.07423v1",
    "title": "Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support",
    "authors": [
      "Venkatesh Sivaraman",
      "Katelyn Morrison",
      "Will Epperson",
      "Adam Perer"
    ],
    "abstract": "As AI-based clinical decision support (AI-CDS) is introduced in more and more\naspects of healthcare services, HCI research plays an increasingly important\nrole in designing for complementarity between AI and clinicians. However,\ncurrent evaluations of AI-CDS often fail to capture when AI is and is not\nuseful to clinicians. This position paper reflects on our work and influential\nAI-CDS literature to advocate for moving beyond evaluation metrics like Trust,\nReliance, Acceptance, and Performance on the AI's task (what we term the \"trap\"\nof human-AI collaboration). Although these metrics can be meaningful in some\nsimple scenarios, we argue that optimizing for them ignores important ways that\nAI falls short of clinical benefit, as well as ways that clinicians\nsuccessfully use AI. As the fields of HCI and AI in healthcare develop new ways\nto design and evaluate CDS tools, we call on the community to prioritize\necologically valid, domain-appropriate study setups that measure the emergent\nforms of value that AI can bring to healthcare professionals.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "q-bio.OT"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to the CHI '25 Workshop on Envisioning the Future of\n  Interactive Health",
    "pdf_url": "http://arxiv.org/pdf/2504.07423v1",
    "published_date": "2025-04-10 03:28:56 UTC",
    "updated_date": "2025-04-10 03:28:56 UTC"
  },
  {
    "arxiv_id": "2504.07422v1",
    "title": "The Role of Machine Learning in Reducing Healthcare Costs: The Impact of Medication Adherence and Preventive Care on Hospitalization Expenses",
    "authors": [
      "Yixin Zhang",
      "Yisong Chen"
    ],
    "abstract": "This study reveals the important role of prevention care and medication\nadherence in reducing hospitalizations. By using a structured dataset of 1,171\npatients, four machine learning models Logistic Regression, Gradient Boosting,\nRandom Forest, and Artificial Neural Networks are applied to predict five-year\nhospitalization risk, with the Gradient Boosting model achieving the highest\naccuracy of 81.2%. The result demonstrated that patients with high medication\nadherence and consistent preventive care can reduce 38.3% and 37.7% in\nhospitalization risk. The finding also suggests that targeted preventive care\ncan have positive Return on Investment (ROI), and therefore ML models can\neffectively direct personalized interventions and contribute to long-term\nmedical savings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "68T05, 68T09, 68U03, 62P10",
      "I.2; J.3; H.2; J.4; K.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07422v1",
    "published_date": "2025-04-10 03:28:42 UTC",
    "updated_date": "2025-04-10 03:28:42 UTC"
  },
  {
    "arxiv_id": "2504.07402v1",
    "title": "LauraTSE: Target Speaker Extraction using Auto-Regressive Decoder-Only Language Models",
    "authors": [
      "Beilong Tang",
      "Bang Zeng",
      "Ming Li"
    ],
    "abstract": "We propose LauraTSE, an Auto-Regressive Decoder-Only Language Model for\nTarget Speaker Extraction (TSE) based on the LauraGPT backbone. It employs a\nsmall-scale auto-regressive decoder-only language model which takes the\ncontinuous representations for both the mixture and the reference speeches and\nproduces the first few layers of the target speech's discrete codec\nrepresentations. In addition, a one-step encoder-only language model\nreconstructs the sum of the predicted codec embeddings using both the mixture\nand the reference information. Our approach achieves superior or comparable\nperformance to existing generative and discriminative TSE models. To the best\nof our knowledge, LauraTSE is the first single-task TSE model to leverage an\nauto-regressive decoder-only language model as the backbone.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.07402v1",
    "published_date": "2025-04-10 02:55:22 UTC",
    "updated_date": "2025-04-10 02:55:22 UTC"
  },
  {
    "arxiv_id": "2504.07398v1",
    "title": "A Novel Mamba-based Sequential Recommendation Method",
    "authors": [
      "Jun Yuan"
    ],
    "abstract": "Sequential recommendation (SR), which encodes user activity to predict the\nnext action, has emerged as a widely adopted strategy in developing commercial\npersonalized recommendation systems. Although Transformer-based models have\nproven effective for sequential recommendation, the complexity of the\nself-attention module in Transformers scales quadratically with the sequence\nlength. Controlling model complexity is essential for large-scale\nrecommendation systems, as these systems may need to handle billion-scale\nvocabularies that evolve continuously, as well as user behavior sequences that\ncan exceed tens of thousands in length. In this paper, we propose a novel\nmulti-head latent Mamba architecture, which employs multiple low-dimensional\nMamba layers and fully connected layers coupled with positional encoding to\nsimultaneously capture historical and item information within each latent\nsubspace. Our proposed method not only enables scaling up to large-scale\nparameters but also extends to multi-domain recommendation by integrating and\nfine-tuning LLMs. Through extensive experiments on public datasets, we\ndemonstrate how Hydra effectively addresses the effectiveness-efficiency\ndilemma, outperforming state-of-the-art sequential recommendation baselines\nwith significantly fewer parameters and reduced training time.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07398v1",
    "published_date": "2025-04-10 02:43:19 UTC",
    "updated_date": "2025-04-10 02:43:19 UTC"
  },
  {
    "arxiv_id": "2504.07397v1",
    "title": "MicroNAS: An Automated Framework for Developing a Fall Detection System",
    "authors": [
      "Seyed Mojtaba Mohasel",
      "John Sheppard",
      "Lindsey K. Molina",
      "Richard R. Neptune",
      "Shane R. Wurdeman",
      "Corey A. Pew"
    ],
    "abstract": "This work presents MicroNAS, an automated neural architecture search tool\nspecifically designed to create models optimized for microcontrollers with\nsmall memory resources. The ESP32 microcontroller, with 320 KB of memory, is\nused as the target platform. The artificial intelligence contribution lies in a\nnovel method for optimizing convolutional neural network and gated recurrent\nunit architectures by considering the memory size of the target microcontroller\nas a guide. A comparison is made between memory-driven model optimization and\ntraditional two-stage methods, which use pruning, to show the effectiveness of\nthe proposed framework. To demonstrate the engineering application of MicroNAS,\na fall detection system (FDS) for lower-limb amputees is developed as a pilot\nstudy. A critical challenge in fall detection studies, class imbalance in the\ndataset, is addressed. The results show that MicroNAS models achieved higher\nF1-scores than alternative approaches, such as ensemble methods and H2O\nAutomated Machine Learning, presenting a significant step forward in real-time\nFDS development. Biomechanists using body-worn sensors for activity detection\ncan adopt the open-source code to design machine learning models tailored for\nmicrocontroller platforms with limited memory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07397v1",
    "published_date": "2025-04-10 02:32:47 UTC",
    "updated_date": "2025-04-10 02:32:47 UTC"
  },
  {
    "arxiv_id": "2504.07396v1",
    "title": "Automating quantum feature map design via large language models",
    "authors": [
      "Kenya Sakka",
      "Kosuke Mitarai",
      "Keisuke Fujii"
    ],
    "abstract": "Quantum feature maps are a key component of quantum machine learning,\nencoding classical data into quantum states to exploit the expressive power of\nhigh-dimensional Hilbert spaces. Despite their theoretical promise, designing\nquantum feature maps that offer practical advantages over classical methods\nremains an open challenge. In this work, we propose an agentic system that\nautonomously generates, evaluates, and refines quantum feature maps using large\nlanguage models. The system consists of five component: Generation, Storage,\nValidation, Evaluation, and Review. Using these components, it iteratively\nimproves quantum feature maps. Experiments on the MNIST dataset show that it\ncan successfully discover and refine feature maps without human intervention.\nThe best feature map generated outperforms existing quantum baselines and\nachieves competitive accuracy compared to classical kernels across MNIST,\nFashion-MNIST, and CIFAR-10. Our approach provides a framework for exploring\ndataset-adaptive quantum features and highlights the potential of LLM-driven\nautomation in quantum algorithm design.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "39 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.07396v1",
    "published_date": "2025-04-10 02:27:45 UTC",
    "updated_date": "2025-04-10 02:27:45 UTC"
  },
  {
    "arxiv_id": "2504.07395v1",
    "title": "FAIR-SIGHT: Fairness Assurance in Image Recognition via Simultaneous Conformal Thresholding and Dynamic Output Repair",
    "authors": [
      "Arya Fayyazi",
      "Mehdi Kamal",
      "Massoud Pedram"
    ],
    "abstract": "We introduce FAIR-SIGHT, an innovative post-hoc framework designed to ensure\nfairness in computer vision systems by combining conformal prediction with a\ndynamic output repair mechanism. Our approach calculates a fairness-aware\nnon-conformity score that simultaneously assesses prediction errors and\nfairness violations. Using conformal prediction, we establish an adaptive\nthreshold that provides rigorous finite-sample, distribution-free guarantees.\nWhen the non-conformity score for a new image exceeds the calibrated threshold,\nFAIR-SIGHT implements targeted corrective adjustments, such as logit shifts for\nclassification and confidence recalibration for detection, to reduce both group\nand individual fairness disparities, all without the need for retraining or\nhaving access to internal model parameters. Comprehensive theoretical analysis\nvalidates our method's error control and convergence properties. At the same\ntime, extensive empirical evaluations on benchmark datasets show that\nFAIR-SIGHT significantly reduces fairness disparities while preserving high\npredictive performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07395v1",
    "published_date": "2025-04-10 02:23:06 UTC",
    "updated_date": "2025-04-10 02:23:06 UTC"
  },
  {
    "arxiv_id": "2504.07394v1",
    "title": "ClimateBench-M: A Multi-Modal Climate Data Benchmark with a Simple Generative Method",
    "authors": [
      "Dongqi Fu",
      "Yada Zhu",
      "Zhining Liu",
      "Lecheng Zheng",
      "Xiao Lin",
      "Zihao Li",
      "Liri Fang",
      "Katherine Tieu",
      "Onkar Bhardwaj",
      "Kommy Weldemariam",
      "Hanghang Tong",
      "Hendrik Hamann",
      "Jingrui He"
    ],
    "abstract": "Climate science studies the structure and dynamics of Earth's climate system\nand seeks to understand how climate changes over time, where the data is\nusually stored in the format of time series, recording the climate features,\ngeolocation, time attributes, etc. Recently, much research attention has been\npaid to the climate benchmarks. In addition to the most common task of weather\nforecasting, several pioneering benchmark works are proposed for extending the\nmodality, such as domain-specific applications like tropical cyclone intensity\nprediction and flash flood damage estimation, or climate statement and\nconfidence level in the format of natural language. To further motivate the\nartificial general intelligence development for climate science, in this paper,\nwe first contribute a multi-modal climate benchmark, i.e., ClimateBench-M,\nwhich aligns (1) the time series climate data from ERA5, (2) extreme weather\nevents data from NOAA, and (3) satellite image data from NASA HLS based on a\nunified spatial-temporal granularity. Second, under each data modality, we also\npropose a simple but strong generative method that could produce competitive\nperformance in weather forecasting, thunderstorm alerts, and crop segmentation\ntasks in the proposed ClimateBench-M. The data and code of ClimateBench-M are\npublicly available at https://github.com/iDEA-iSAIL-Lab-UIUC/ClimateBench-M.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, 29 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.07394v1",
    "published_date": "2025-04-10 02:22:23 UTC",
    "updated_date": "2025-04-10 02:22:23 UTC"
  },
  {
    "arxiv_id": "2504.07389v1",
    "title": "Task-Circuit Quantization: Leveraging Knowledge Localization and Interpretability for Compression",
    "authors": [
      "Hanqi Xiao",
      "Yi-Lin Sung",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ],
    "abstract": "Post-training quantization (PTQ) reduces a model's memory footprint by\nmapping full precision weights into low bit weights without costly retraining,\nbut can degrade its downstream performance especially in low 2- to 3-bit\nsettings. We develop a new mixed-precision PTQ approach, Task-Circuit\nQuantization (TaCQ), that draws parallels to automated circuit discovery,\ndirectly conditioning the quantization process on specific weight circuits --\nwhich we define as sets of weights associated with downstream task performance.\nThese weights are kept as 16-bit weights, while others are quantized,\nmaintaining performance while only adding a marginal memory cost. Specifically,\nTaCQ contrasts unquantized model weights with a uniformly-quantized model to\nestimate the expected change in weights due to quantization and uses gradient\ninformation to predict the resulting impact on task performance, allowing us to\npreserve task-specific weights. We compare TaCQ-based quantization to existing\nmixed-precision quantization methods when conditioning both on general-purpose\nand task-specific data. Across QA, math reasoning, and text-to-SQL tasks for\nboth Llama-3 and Qwen2.5, we find that TaCQ outperforms baselines using the\nsame calibration data and a lower weight budget, achieving major improvements\nin the 2 and 3-bit regime. With only 3.1 bits we are able to recover 96% of\nLlama-3-8B-Instruct's unquantized 16-bit MMLU performance, obtaining a 5.25%\nabsolute improvement over SPQR. We also observe consistently large gains over\nexisting methods in the 2-bit regime, with an average gain of 14.74% over the\nstrongest baseline, SliM-LLM. Moreover, we observe a 7.20% gain without\nconditioning on specific tasks, showing TaCQ's ability to identify important\nweights is not limited to task-conditioned settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages. Code: https://github.com/The-Inscrutable-X/TACQ",
    "pdf_url": "http://arxiv.org/pdf/2504.07389v1",
    "published_date": "2025-04-10 02:19:03 UTC",
    "updated_date": "2025-04-10 02:19:03 UTC"
  },
  {
    "arxiv_id": "2504.07388v1",
    "title": "Min-Max Optimisation for Nonconvex-Nonconcave Functions Using a Random Zeroth-Order Extragradient Algorithm",
    "authors": [
      "Amir Ali Farzin",
      "Yuen Man Pun",
      "Philipp Braun",
      "Antoine Lesage-landry",
      "Youssef Diouane",
      "Iman Shames"
    ],
    "abstract": "This study explores the performance of the random Gaussian smoothing\nZeroth-Order ExtraGradient (ZO-EG) scheme considering min-max optimisation\nproblems with possibly NonConvex-NonConcave (NC-NC) objective functions. We\nconsider both unconstrained and constrained, differentiable and\nnon-differentiable settings. We discuss the min-max problem from the point of\nview of variational inequalities. For the unconstrained problem, we establish\nthe convergence of the ZO-EG algorithm to the neighbourhood of an\n$\\epsilon$-stationary point of the NC-NC objective function, whose radius can\nbe controlled under a variance reduction scheme, along with its complexity. For\nthe constrained problem, we introduce the new notion of proximal variational\ninequalities and give examples of functions satisfying this property. Moreover,\nwe prove analogous results to the unconstrained case for the constrained\nproblem. For the non-differentiable case, we prove the convergence of the ZO-EG\nalgorithm to a neighbourhood of an $\\epsilon$-stationary point of the smoothed\nversion of the objective function, where the radius of the neighbourhood can be\ncontrolled, which can be related to the ($\\delta,\\epsilon$)-Goldstein\nstationary point of the original objective function.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07388v1",
    "published_date": "2025-04-10 02:15:30 UTC",
    "updated_date": "2025-04-10 02:15:30 UTC"
  },
  {
    "arxiv_id": "2504.07385v1",
    "title": "TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models",
    "authors": [
      "Sher Badshah",
      "Ali Emami",
      "Hassan Sajjad"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world, autonomous applications, relying on static, pre-annotated\nreferences for evaluation poses significant challenges in cost, scalability,\nand completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework\nto assess LLM outputs without predetermined ground-truth answers. Unlike\nconventional metrics that compare to fixed references or depend solely on\nLLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities\nthat actively retrieves and synthesizes external evidence. It iteratively\ngenerates web queries, collects information, summarizes findings, and refines\nsubsequent searches through reflection. By shifting away from static\nreferences, TALE aligns with free-form question-answering tasks common in\nreal-world scenarios. Experimental results on multiple free-form QA benchmarks\nshow that TALE not only outperforms standard reference-based metrics for\nmeasuring response accuracy but also achieves substantial to near-perfect\nagreement with human evaluations. TALE enhances the reliability of LLM\nevaluations in real-world, dynamic scenarios without relying on static\nreferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07385v1",
    "published_date": "2025-04-10 02:08:41 UTC",
    "updated_date": "2025-04-10 02:08:41 UTC"
  },
  {
    "arxiv_id": "2504.07383v1",
    "title": "PROPEL: Supervised and Reinforcement Learning for Large-Scale Supply Chain Planning",
    "authors": [
      "Vahid Eghbal Akhlaghi",
      "Reza Zandehshahvar",
      "Pascal Van Hentenryck"
    ],
    "abstract": "This paper considers how to fuse Machine Learning (ML) and optimization to\nsolve large-scale Supply Chain Planning (SCP) optimization problems. These\nproblems can be formulated as MIP models which feature both integer\n(non-binary) and continuous variables, as well as flow balance and capacity\nconstraints. This raises fundamental challenges for existing integrations of ML\nand optimization that have focused on binary MIPs and graph problems. To\naddress these, the paper proposes PROPEL, a new framework that combines\noptimization with both supervised and Deep Reinforcement Learning (DRL) to\nreduce the size of search space significantly. PROPEL uses supervised learning,\nnot to predict the values of all integer variables, but to identify the\nvariables that are fixed to zero in the optimal solution, leveraging the\nstructure of SCP applications. PROPEL includes a DRL component that selects\nwhich fixed-at-zero variables must be relaxed to improve solution quality when\nthe supervised learning step does not produce a solution with the desired\noptimality tolerance. PROPEL has been applied to industrial supply chain\nplanning optimizations with millions of variables. The computational results\nshow dramatic improvements in solution times and quality, including a 60%\nreduction in primal integral and an 88% primal gap reduction, and improvement\nfactors of up to 13.57 and 15.92, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07383v1",
    "published_date": "2025-04-10 02:04:29 UTC",
    "updated_date": "2025-04-10 02:04:29 UTC"
  },
  {
    "arxiv_id": "2504.07379v1",
    "title": "Representation Meets Optimization: Training PINNs and PIKANs for Gray-Box Discovery in Systems Pharmacology",
    "authors": [
      "Nazanin Ahmadi Daryakenari",
      "Khemraj Shukla",
      "George Em Karniadakis"
    ],
    "abstract": "Physics-Informed Kolmogorov-Arnold Networks (PIKANs) are gaining attention as\nan effective counterpart to the original multilayer perceptron-based\nPhysics-Informed Neural Networks (PINNs). Both representation models can\naddress inverse problems and facilitate gray-box system identification.\nHowever, a comprehensive understanding of their performance in terms of\naccuracy and speed remains underexplored. In particular, we introduce a\nmodified PIKAN architecture, tanh-cPIKAN, which is based on Chebyshev\npolynomials for parametrization of the univariate functions with an extra\nnonlinearity for enhanced performance. We then present a systematic\ninvestigation of how choices of the optimizer, representation, and training\nconfiguration influence the performance of PINNs and PIKANs in the context of\nsystems pharmacology modeling. We benchmark a wide range of first-order,\nsecond-order, and hybrid optimizers, including various learning rate\nschedulers. We use the new Optax library to identify the most effective\ncombinations for learning gray-boxes under ill-posed, non-unique, and\ndata-sparse conditions. We examine the influence of model architecture (MLP vs.\nKAN), numerical precision (single vs. double), the need for warm-up phases for\nsecond-order methods, and sensitivity to the initial learning rate. We also\nassess the optimizer scalability for larger models and analyze the trade-offs\nintroduced by JAX in terms of computational efficiency and numerical accuracy.\nUsing two representative systems pharmacology case studies - a pharmacokinetics\nmodel and a chemotherapy drug-response model - we offer practical guidance on\nselecting optimizers and representation models/architectures for robust and\nefficient gray-box discovery. Our findings provide actionable insights for\nimproving the training of physics-informed networks in biomedical applications\nand beyond.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "35R30 (Primary), 65M32, 92C50 (Secondary)",
      "I.2.6; G.1.7; G.1.10"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07379v1",
    "published_date": "2025-04-10 01:37:18 UTC",
    "updated_date": "2025-04-10 01:37:18 UTC"
  },
  {
    "arxiv_id": "2504.07373v1",
    "title": "ChronoFormer: Time-Aware Transformer Architectures for Structured Clinical Event Modeling",
    "authors": [
      "Yuanyun Zhang",
      "Shi Li"
    ],
    "abstract": "The temporal complexity of electronic health record (EHR) data presents\nsignificant challenges for predicting clinical outcomes using machine learning.\nThis paper proposes ChronoFormer, an innovative transformer based architecture\nspecifically designed to encode and leverage temporal dependencies in\nlongitudinal patient data. ChronoFormer integrates temporal embeddings,\nhierarchical attention mechanisms, and domain specific masking techniques.\nExtensive experiments conducted on three benchmark tasks mortality prediction,\nreadmission prediction, and long term comorbidity onset demonstrate substantial\nimprovements over current state of the art methods. Furthermore, detailed\nanalyses of attention patterns underscore ChronoFormer's capability to capture\nclinically meaningful long range temporal relationships.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07373v1",
    "published_date": "2025-04-10 01:25:41 UTC",
    "updated_date": "2025-04-10 01:25:41 UTC"
  },
  {
    "arxiv_id": "2504.07360v1",
    "title": "Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs",
    "authors": [
      "Taibiao Zhao",
      "Xiaobing Chen",
      "Mingxuan Sun"
    ],
    "abstract": "The adaptation of large language models (LLMs) to time series forecasting\nposes unique challenges, as time series data is continuous in nature, while\nLLMs operate on discrete tokens. Despite the success of LLMs in natural\nlanguage processing (NLP) and other structured domains, aligning time series\ndata with language-based representations while maintaining both predictive\naccuracy and interpretability remains a significant hurdle. Existing methods\nhave attempted to reprogram time series data into text-based forms, but these\noften fall short in delivering meaningful, interpretable results. In this\npaper, we propose a multi-level text alignment framework for time series\nforecasting using LLMs that not only improves prediction accuracy but also\nenhances the interpretability of time series representations. Our method\ndecomposes time series into trend, seasonal, and residual components, which are\nthen reprogrammed into component-specific text representations. We introduce a\nmulti-level alignment mechanism, where component-specific embeddings are\naligned with pre-trained word tokens, enabling more interpretable forecasts.\nExperiments on multiple datasets demonstrate that our method outperforms\nstate-of-the-art models in accuracy while providing good interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07360v1",
    "published_date": "2025-04-10 01:02:37 UTC",
    "updated_date": "2025-04-10 01:02:37 UTC"
  },
  {
    "arxiv_id": "2504.07359v1",
    "title": "A Balanced Approach of Rapid Genetic Exploration and Surrogate Exploitation for Hyperparameter Optimization",
    "authors": [
      "Chul Kim",
      "Inwhee Joe"
    ],
    "abstract": "This paper proposes a new method for hyperparameter optimization (HPO) that\nbalances exploration and exploitation. While evolutionary algorithms (EAs) show\npromise in HPO, they often struggle with effective exploitation. To address\nthis, we integrate a linear surrogate model into a genetic algorithm (GA),\nallowing for smooth integration of multiple strategies. This combination\nimproves exploitation performance, achieving an average improvement of 1.89\npercent (max 6.55 percent, min -3.45 percent) over existing HPO methods.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "68T20",
      "I.2.8; G.1.6"
    ],
    "primary_category": "cs.NE",
    "comment": "Published in IEEE Access, 12 pages, 10 figures. DOI:\n  10.1109/ACCESS.2024.3508269",
    "pdf_url": "http://arxiv.org/pdf/2504.07359v1",
    "published_date": "2025-04-10 00:59:54 UTC",
    "updated_date": "2025-04-10 00:59:54 UTC"
  },
  {
    "arxiv_id": "2504.07345v1",
    "title": "Quantum-Inspired Genetic Algorithm for Robust Source Separation in Smart City Acoustics",
    "authors": [
      "Minh K. Quan",
      "Mayuri Wijayasundara",
      "Sujeeva Setunge",
      "Pubudu N. Pathirana"
    ],
    "abstract": "The cacophony of urban sounds presents a significant challenge for smart city\napplications that rely on accurate acoustic scene analysis. Effectively\nanalyzing these complex soundscapes, often characterized by overlapping sound\nsources, diverse acoustic events, and unpredictable noise levels, requires\nprecise source separation. This task becomes more complicated when only limited\ntraining data is available. This paper introduces a novel Quantum-Inspired\nGenetic Algorithm (p-QIGA) for source separation, drawing inspiration from\nquantum information theory to enhance acoustic scene analysis in smart cities.\nBy leveraging quantum superposition for efficient solution space exploration\nand entanglement to handle correlated sources, p-QIGA achieves robust\nseparation even with limited data. These quantum-inspired concepts are\nintegrated into a genetic algorithm framework to optimize source separation\nparameters. The effectiveness of our approach is demonstrated on two datasets:\nthe TAU Urban Acoustic Scenes 2020 Mobile dataset, representing typical urban\nsoundscapes, and the Silent Cities dataset, capturing quieter urban\nenvironments during the COVID-19 pandemic. Experimental results show that the\np-QIGA achieves accuracy comparable to state-of-the-art methods while\nexhibiting superior resilience to noise and limited training data, achieving up\nto 8.2 dB signal-to-distortion ratio (SDR) in noisy environments and\noutperforming baseline methods by up to 2 dB with only 10% of the training\ndata. This research highlights the potential of p-QIGA to advance acoustic\nsignal processing in smart cities, particularly for noise pollution monitoring\nand acoustic surveillance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages, 2 figures, IEEE International Conference on Communications\n  (ICC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.07345v1",
    "published_date": "2025-04-10 00:05:35 UTC",
    "updated_date": "2025-04-10 00:05:35 UTC"
  }
]