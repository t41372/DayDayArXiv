[
  {
    "arxiv_id": "2412.20622v2",
    "title": "Towards a Systematic Evaluation of Hallucinations in Large-Vision Language Models",
    "authors": [
      "Ashish Seth",
      "Dinesh Manocha",
      "Chirag Agarwal"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable performance\nin complex multimodal tasks. However, these models still suffer from\nhallucinations, particularly when required to implicitly recognize or infer\ndiverse visual entities from images for complex vision-language tasks. To\naddress this challenge, we propose HALLUCINOGEN, a novel visual question\nanswering (VQA) benchmark that employs contextual reasoning prompts as\nhallucination attacks to evaluate the extent of hallucination in\nstate-of-the-art LVLMs. Our benchmark provides a comprehensive study of the\nimplicit reasoning capabilities of these models by first categorizing visual\nentities based on the ease of recognition in an image as either salient\n(prominent, visibly recognizable objects such as a car) or latent entities\n(such as identifying a disease from a chest X-ray), which are not readily\nvisible and require domain knowledge or contextual reasoning for accurate\ninference. Next, we design hallucination attacks for both types of entities to\nassess hallucinations in LVLMs while performing various vision-language tasks,\nsuch as locating or reasoning about specific entities within an image, where\nmodels must perform implicit reasoning by verifying the existence of the\nqueried entity within the image before generating responses. Finally, our\nextensive evaluations of eleven LVLMs, including powerful open-source models\n(like LLaMA-3.2 and DeepSeek-V2), commercial models like Gemini, and two\nhallucination mitigation strategies across multiple datasets, demonstrate that\ncurrent LVLMs remain susceptible to hallucination attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20622v2",
    "published_date": "2024-12-29 23:56:01 UTC",
    "updated_date": "2025-03-13 23:10:24 UTC"
  },
  {
    "arxiv_id": "2412.20612v1",
    "title": "Towards Explaining Uncertainty Estimates in Point Cloud Registration",
    "authors": [
      "Ziyuan Qin",
      "Jongseok Lee",
      "Rudolph Triebel"
    ],
    "abstract": "Iterative Closest Point (ICP) is a commonly used algorithm to estimate\ntransformation between two point clouds. The key idea of this work is to\nleverage recent advances in explainable AI for probabilistic ICP methods that\nprovide uncertainty estimates. Concretely, we propose a method that can explain\nwhy a probabilistic ICP method produced a particular output. Our method is\nbased on kernel SHAP (SHapley Additive exPlanations). With this, we assign an\nimportance value to common sources of uncertainty in ICP such as sensor noise,\nocclusion, and ambiguous environments. The results of the experiment show that\nthis explanation method can reasonably explain the uncertainty sources,\nproviding a step towards robots that know when and why they failed in a human\ninterpretable manner",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20612v1",
    "published_date": "2024-12-29 23:03:44 UTC",
    "updated_date": "2024-12-29 23:03:44 UTC"
  },
  {
    "arxiv_id": "2412.20601v1",
    "title": "MATEY: multiscale adaptive foundation models for spatiotemporal physical systems",
    "authors": [
      "Pei Zhang",
      "M. Paul Laiu",
      "Matthew Norman",
      "Doug Stefanski",
      "John Gounley"
    ],
    "abstract": "Accurate representation of the multiscale features in spatiotemporal physical\nsystems using vision transformer (ViT) architectures requires extremely long,\ncomputationally prohibitive token sequences. To address this issue, we propose\ntwo adaptive tokenization schemes that dynamically adjust patch sizes based on\nlocal features: one ensures convergent behavior to uniform patch refinement,\nwhile the other offers better computational efficiency. Moreover, we present a\nset of spatiotemporal attention schemes, where the temporal or axial spatial\ndimensions are decoupled, and evaluate their computational and data\nefficiencies. We assess the performance of the proposed multiscale adaptive\nmodel, MATEY, in a sequence of experiments. The results show that adaptive\ntokenization schemes achieve improved accuracy without significantly increasing\nthe length of the token sequence. Compared to a full spatiotemporal attention\nscheme or a scheme that decouples only the temporal dimension, we find that\nfully decoupled axial attention is less efficient and expressive, requiring\nmore training time and model weights to achieve the same accuracy. Finally, we\ndemonstrate in two fine-tuning tasks featuring different physics that models\npretrained on PDEBench data outperform the ones trained from scratch,\nespecially in the low data regime with frozen attention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20601v1",
    "published_date": "2024-12-29 22:13:16 UTC",
    "updated_date": "2024-12-29 22:13:16 UTC"
  },
  {
    "arxiv_id": "2412.20595v1",
    "title": "Controlling Out-of-Domain Gaps in LLMs for Genre Classification and Generated Text Detection",
    "authors": [
      "Dmitri Roussinov",
      "Serge Sharoff",
      "Nadezhda Puchnina"
    ],
    "abstract": "This study demonstrates that the modern generation of Large Language Models\n(LLMs, such as GPT-4) suffers from the same out-of-domain (OOD) performance gap\nobserved in prior research on pre-trained Language Models (PLMs, such as BERT).\nWe demonstrate this across two non-topical classification tasks: 1) genre\nclassification and 2) generated text detection. Our results show that when\ndemonstration examples for In-Context Learning (ICL) come from one domain\n(e.g., travel) and the system is tested on another domain (e.g., history),\nclassification performance declines significantly.\n  To address this, we introduce a method that controls which predictive\nindicators are used and which are excluded during classification. For the two\ntasks studied here, this ensures that topical features are omitted, while the\nmodel is guided to focus on stylistic rather than content-based attributes.\nThis approach reduces the OOD gap by up to 20 percentage points in a few-shot\nsetup. Straightforward Chain-of-Thought (CoT) methods, used as the baseline,\nprove insufficient, while our approach consistently enhances domain transfer\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 31st International Conference on Computational Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2412.20595v1",
    "published_date": "2024-12-29 21:54:39 UTC",
    "updated_date": "2024-12-29 21:54:39 UTC"
  },
  {
    "arxiv_id": "2412.20588v2",
    "title": "Kryptonite-N: Machine Learning Strikes Back",
    "authors": [
      "Albus Li",
      "Nathan Bailey",
      "Will Sumerfield",
      "Kira Kim"
    ],
    "abstract": "Quinn et al propose challenge datasets in their work called ``Kryptonite-N\".\nThese datasets aim to counter the universal function approximation argument of\nmachine learning, breaking the notation that machine learning can ``approximate\nany continuous function\" \\cite{original_paper}. Our work refutes this claim and\nshows that universal function approximations can be applied successfully; the\nKryptonite datasets are constructed predictably, allowing logistic regression\nwith sufficient polynomial expansion and L1 regularization to solve for any\ndimension N.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20588v2",
    "published_date": "2024-12-29 21:23:09 UTC",
    "updated_date": "2025-01-26 18:22:57 UTC"
  },
  {
    "arxiv_id": "2412.20582v1",
    "title": "Bridging the Gap: A Decade Review of Time-Series Clustering Methods",
    "authors": [
      "John Paparrizos",
      "Fan Yang",
      "Haojun Li"
    ],
    "abstract": "Time series, as one of the most fundamental representations of sequential\ndata, has been extensively studied across diverse disciplines, including\ncomputer science, biology, geology, astronomy, and environmental sciences. The\nadvent of advanced sensing, storage, and networking technologies has resulted\nin high-dimensional time-series data, however, posing significant challenges\nfor analyzing latent structures over extended temporal scales. Time-series\nclustering, an established unsupervised learning strategy that groups similar\ntime series together, helps unveil hidden patterns in these complex datasets.\nIn this survey, we trace the evolution of time-series clustering methods from\nclassical approaches to recent advances in neural networks. While previous\nsurveys have focused on specific methodological categories, we bridge the gap\nbetween traditional clustering methods and emerging deep learning-based\nalgorithms, presenting a comprehensive, unified taxonomy for this research\narea. This survey highlights key developments and provides insights to guide\nfuture research in time-series clustering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20582v1",
    "published_date": "2024-12-29 21:04:35 UTC",
    "updated_date": "2024-12-29 21:04:35 UTC"
  },
  {
    "arxiv_id": "2412.20574v1",
    "title": "A Survey on Time-Series Distance Measures",
    "authors": [
      "John Paparrizos",
      "Haojun Li",
      "Fan Yang",
      "Kaize Wu",
      "Jens E. d'Hondt",
      "Odysseas Papapetrou"
    ],
    "abstract": "Distance measures have been recognized as one of the fundamental building\nblocks in time-series analysis tasks, e.g., querying, indexing, classification,\nclustering, anomaly detection, and similarity search. The vast proliferation of\ntime-series data across a wide range of fields has increased the relevance of\nevaluating the effectiveness and efficiency of these distance measures. To\nprovide a comprehensive view of this field, this work considers over 100\nstate-of-the-art distance measures, classified into 7 categories: lock-step\nmeasures, sliding measures, elastic measures, kernel measures, feature-based\nmeasures, model-based measures, and embedding measures. Beyond providing\ncomprehensive mathematical frameworks, this work also delves into the\ndistinctions and applications across these categories for both univariate and\nmultivariate cases. By providing comprehensive collections and insights, this\nstudy paves the way for the future development of innovative time-series\ndistance measures.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20574v1",
    "published_date": "2024-12-29 20:47:08 UTC",
    "updated_date": "2024-12-29 20:47:08 UTC"
  },
  {
    "arxiv_id": "2412.20573v1",
    "title": "The intrinsic motivation of reinforcement and imitation learning for sequential tasks",
    "authors": [
      "Sao Mai Nguyen"
    ],
    "abstract": "This work in the field of developmental cognitive robotics aims to devise a\nnew domain bridging between reinforcement learning and imitation learning, with\na model of the intrinsic motivation for learning agents to learn with guidance\nfrom tutors multiple tasks, including sequential tasks. The main contribution\nhas been to propose a common formulation of intrinsic motivation based on\nempirical progress for a learning agent to choose automatically its learning\ncurriculum by actively choosing its learning strategy for simple or sequential\ntasks: which task to learn, between autonomous exploration or imitation\nlearning, between low-level actions or task decomposition, between several\ntutors. The originality is to design a learner that benefits not only passively\nfrom data provided by tutors, but to actively choose when to request tutoring\nand what and whom to ask. The learner is thus more robust to the quality of the\ntutoring and learns faster with fewer demonstrations. We developed the\nframework of socially guided intrinsic motivation with machine learning\nalgorithms to learn multiple tasks by taking advantage of the generalisability\nproperties of human demonstrations in a passive manner or in an active manner\nthrough requests of demonstrations from the best tutor for simple and composing\nsubtasks. The latter relies on a representation of subtask composition proposed\nfor a construction process, which should be refined by representations used for\nobservational processes of analysing human movements and activities of daily\nliving. With the outlook of a language-like communication with the tutor, we\ninvestigated the emergence of a symbolic representation of the continuous\nsensorimotor space and of tasks using intrinsic motivation. We proposed within\nthe reinforcement learning framework, a reward function for interacting with\ntutors for automatic curriculum learning in multi-task learning.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.RO",
      "I.2.6; I.2.9"
    ],
    "primary_category": "cs.AI",
    "comment": "Habilitation thesis",
    "pdf_url": "http://arxiv.org/pdf/2412.20573v1",
    "published_date": "2024-12-29 20:44:59 UTC",
    "updated_date": "2024-12-29 20:44:59 UTC"
  },
  {
    "arxiv_id": "2412.20571v1",
    "title": "Segmentation of Muscularis Propria in Colon Histopathology Images Using Vision Transformers for Hirschsprung's Disease",
    "authors": [
      "Youssef Megahed",
      "Anthony Fuller",
      "Saleh Abou-Alwan",
      "Dina El Demellawy",
      "Adrian D. C. Chan"
    ],
    "abstract": "Hirschsprung's disease (HD) is a congenital birth defect diagnosed by\nidentifying the lack of ganglion cells within the colon's muscularis propria,\nspecifically within the myenteric plexus regions. There may be advantages for\nquantitative assessments of histopathology images of the colon, such as\ncounting the ganglion and assessing their spatial distribution; however, this\nwould be time-intensive for pathologists, costly, and subject to inter- and\nintra-rater variability. Previous research has demonstrated the potential for\ndeep learning approaches to automate histopathology image analysis, including\nsegmentation of the muscularis propria using convolutional neural networks\n(CNNs). Recently, Vision Transformers (ViTs) have emerged as a powerful deep\nlearning approach due to their self-attention. This study explores the\napplication of ViTs for muscularis propria segmentation in calretinin-stained\nhistopathology images and compares their performance to CNNs and shallow\nlearning methods. The ViT model achieved a DICE score of 89.9% and Plexus\nInclusion Rate (PIR) of 100%, surpassing the CNN (DICE score of 89.2%; PIR of\n96.0%) and k-means clustering method (DICE score of 80.7%; PIR 77.4%). Results\nassert that ViTs are a promising tool for advancing HD-related image analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "To be published in the CMBEC47/ACCES26 Joint Conference",
    "pdf_url": "http://arxiv.org/pdf/2412.20571v1",
    "published_date": "2024-12-29 20:43:43 UTC",
    "updated_date": "2024-12-29 20:43:43 UTC"
  },
  {
    "arxiv_id": "2412.20565v1",
    "title": "Enhancing autonomous vehicle safety in rain: a data-centric approach for clear vision",
    "authors": [
      "Mark A. Seferian",
      "Jidong J. Yang"
    ],
    "abstract": "Autonomous vehicles face significant challenges in navigating adverse\nweather, particularly rain, due to the visual impairment of camera-based\nsystems. In this study, we leveraged contemporary deep learning techniques to\nmitigate these challenges, aiming to develop a vision model that processes live\nvehicle camera feeds to eliminate rain-induced visual hindrances, yielding\nvisuals closely resembling clear, rain-free scenes. Using the Car Learning to\nAct (CARLA) simulation environment, we generated a comprehensive dataset of\nclear and rainy images for model training and testing. In our model, we\nemployed a classic encoder-decoder architecture with skip connections and\nconcatenation operations. It was trained using novel batching schemes designed\nto effectively distinguish high-frequency rain patterns from low-frequency\nscene features across successive image frames. To evaluate the model\nperformance, we integrated it with a steering module that processes front-view\nimages as input. The results demonstrated notable improvements in steering\naccuracy, underscoring the model's potential to enhance navigation safety and\nreliability in rainy weather conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 16 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.20565v1",
    "published_date": "2024-12-29 20:27:12 UTC",
    "updated_date": "2024-12-29 20:27:12 UTC"
  },
  {
    "arxiv_id": "2501.00070v2",
    "title": "ICLR: In-Context Learning of Representations",
    "authors": [
      "Core Francisco Park",
      "Andrew Lee",
      "Ekdeep Singh Lubana",
      "Yongyi Yang",
      "Maya Okawa",
      "Kento Nishi",
      "Martin Wattenberg",
      "Hidenori Tanaka"
    ],
    "abstract": "Recent work has demonstrated that semantics specified by pretraining data\ninfluence how representations of different concepts are organized in a large\nlanguage model (LLM). However, given the open-ended nature of LLMs, e.g., their\nability to in-context learn, we can ask whether models alter these pretraining\nsemantics to adopt alternative, context-specified ones. Specifically, if we\nprovide in-context exemplars wherein a concept plays a different role than what\nthe pretraining data suggests, do models reorganize their representations in\naccordance with these novel semantics? To answer this question, we take\ninspiration from the theory of conceptual role semantics and define a toy\n\"graph tracing\" task wherein the nodes of the graph are referenced via concepts\nseen during training (e.g., apple, bird, etc.) and the connectivity of the\ngraph is defined via some predefined structure (e.g., a square grid). Given\nexemplars that indicate traces of random walks on the graph, we analyze\nintermediate representations of the model and find that as the amount of\ncontext is scaled, there is a sudden re-organization from pretrained semantic\nrepresentations to in-context representations aligned with the graph structure.\nFurther, we find that when reference concepts have correlations in their\nsemantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure\nis still present in the representations, but is unable to dominate the\npretrained structure. To explain these results, we analogize our task to energy\nminimization for a predefined graph topology, providing evidence towards an\nimplicit optimization process to infer context-specified semantics. Overall,\nour findings indicate scaling context-size can flexibly re-organize model\nrepresentations, possibly unlocking novel capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.00070v2",
    "published_date": "2024-12-29 18:58:09 UTC",
    "updated_date": "2025-05-02 05:27:38 UTC"
  },
  {
    "arxiv_id": "2501.00069v1",
    "title": "Adversarial Negotiation Dynamics in Generative Language Models",
    "authors": [
      "Arinbjörn Kolbeinsson",
      "Benedikt Kolbeinsson"
    ],
    "abstract": "Generative language models are increasingly used for contract drafting and\nenhancement, creating a scenario where competing parties deploy different\nlanguage models against each other. This introduces not only a game-theory\nchallenge but also significant concerns related to AI safety and security, as\nthe language model employed by the opposing party can be unknown. These\ncompetitive interactions can be seen as adversarial testing grounds, where\nmodels are effectively red-teamed to expose vulnerabilities such as generating\nbiased, harmful or legally problematic text. Despite the importance of these\nchallenges, the competitive robustness and safety of these models in\nadversarial settings remain poorly understood. In this small study, we approach\nthis problem by evaluating the performance and vulnerabilities of major\nopen-source language models in head-to-head competitions, simulating real-world\ncontract negotiations. We further explore how these adversarial interactions\ncan reveal potential risks, informing the development of more secure and\nreliable models. Our findings contribute to the growing body of research on AI\nsafety, offering insights into model selection and optimisation in competitive\nlegal contexts and providing actionable strategies for mitigating risks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper at NeurIPS 2024 Workshop on Red Teaming GenAI",
    "pdf_url": "http://arxiv.org/pdf/2501.00069v1",
    "published_date": "2024-12-29 18:17:55 UTC",
    "updated_date": "2024-12-29 18:17:55 UTC"
  },
  {
    "arxiv_id": "2412.20529v1",
    "title": "Attacks on the neural network and defense methods",
    "authors": [
      "A. Korenev",
      "G. Belokrylov",
      "B. Lodonova",
      "A. Novokhrestov"
    ],
    "abstract": "This article will discuss the use of attacks on a neural network trained on\naudio data, as well as possible methods of protection against these attacks.\nFGSM, PGD and CW attacks, as well as data poisoning, will be considered. Within\nthe framework of protection, Art-IBM and advertorch libraries will be\nconsidered. The obtained accuracy metrics within the framework of attack\napplications are presented",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20529v1",
    "published_date": "2024-12-29 17:33:04 UTC",
    "updated_date": "2024-12-29 17:33:04 UTC"
  },
  {
    "arxiv_id": "2501.00067v1",
    "title": "Ensemble of classifiers for speech evaluation",
    "authors": [
      "G. Belokrylov",
      "A. Korenev",
      "B. Lodonova",
      "A. Novokhrestov"
    ],
    "abstract": "The article describes an attempt to apply an ensemble of binary classifiers\nto solve the problem of speech assessment in medicine. A dataset was compiled\nbased on quantitative and expert assessments of syllable pronunciation quality.\nQuantitative assessments of 7 selected metrics were used as features: dynamic\ntime warp distance, Minkowski distance, correlation coefficient, longest common\nsubsequence (LCSS), edit distance of real se-quence (EDR), edit distance with\nreal penalty (ERP), and merge split (MSM). Expert as-sessment of pronunciation\nquality was used as a class label: class 1 means high-quality speech, class 0\nmeans distorted. A comparison of training results was carried out for five\nclassification methods: logistic regression (LR), support vector machine (SVM),\nnaive Bayes (NB), decision trees (DT), and K-nearest neighbors (KNN). The\nresults of using the mixture method to build an ensemble of classifiers are\nalso presented. The use of an en-semble for the studied data sets allowed us to\nslightly increase the classification accuracy compared to the use of individual\nbinary classifiers.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00067v1",
    "published_date": "2024-12-29 17:28:32 UTC",
    "updated_date": "2024-12-29 17:28:32 UTC"
  },
  {
    "arxiv_id": "2502.15691v1",
    "title": "The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling",
    "authors": [
      "Chau-Jian Huang"
    ],
    "abstract": "Web crawling is a critical technique for extracting online data, yet it poses\nchallenges due to webpage diversity and anti-scraping mechanisms. This study\ninvestigates the integration of generative AI tools Claude AI (Sonnet 3.5) and\nChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts,\nPROMPT I (general inference, tested on Yahoo News) and PROMPT II\n(element-specific, tested on Coupons.com), we evaluate the code quality and\nperformance of AI-generated scripts. Claude AI consistently outperformed\nChatGPT-4.0 in script quality and adaptability, as confirmed by predefined\nevaluation metrics, including functionality, readability, modularity, and\nrobustness. Performance data were collected through manual testing and\nstructured scoring by three evaluators. Visualizations further illustrate\nClaude AI's superiority. Anti-scraping solutions, including\nundetected_chromedriver, Selenium, and fake_useragent, were incorporated to\nenhance performance. This paper demonstrates how generative AI combined with\nprompt engineering can simplify and improve web scraping workflows.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15691v1",
    "published_date": "2024-12-29 17:27:55 UTC",
    "updated_date": "2024-12-29 17:27:55 UTC"
  },
  {
    "arxiv_id": "2412.20523v1",
    "title": "Game Theory and Multi-Agent Reinforcement Learning : From Nash Equilibria to Evolutionary Dynamics",
    "authors": [
      "Neil De La Fuente",
      "Miquel Noguer i Alonso",
      "Guim Casadellà"
    ],
    "abstract": "This paper explores advanced topics in complex multi-agent systems building\nupon our previous work. We examine four fundamental challenges in Multi-Agent\nReinforcement Learning (MARL): non-stationarity, partial observability,\nscalability with large agent populations, and decentralized learning. The paper\nprovides mathematical formulations and analysis of recent algorithmic\nadvancements designed to address these challenges, with a particular focus on\ntheir integration with game-theoretic concepts. We investigate how Nash\nequilibria, evolutionary game theory, correlated equilibrium, and adversarial\ndynamics can be effectively incorporated into MARL algorithms to improve\nlearning outcomes. Through this comprehensive analysis, we demonstrate how the\nsynthesis of game theory and MARL can enhance the robustness and effectiveness\nof multi-agent systems in complex, dynamic environments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.20523v1",
    "published_date": "2024-12-29 17:15:40 UTC",
    "updated_date": "2024-12-29 17:15:40 UTC"
  },
  {
    "arxiv_id": "2412.20519v1",
    "title": "Goal-Conditioned Data Augmentation for Offline Reinforcement Learning",
    "authors": [
      "Xingshuai Huang",
      "Di Wu Member",
      "Benoit Boulet"
    ],
    "abstract": "Offline reinforcement learning (RL) enables policy learning from\npre-collected offline datasets, relaxing the need to interact directly with the\nenvironment. However, limited by the quality of offline datasets, it generally\nfails to learn well-qualified policies in suboptimal datasets. To address\ndatasets with insufficient optimal demonstrations, we introduce\nGoal-cOnditioned Data Augmentation (GODA), a novel goal-conditioned\ndiffusion-based method for augmenting samples with higher quality. Leveraging\nrecent advancements in generative modeling, GODA incorporates a novel\nreturn-oriented goal condition with various selection mechanisms. Specifically,\nwe introduce a controllable scaling technique to provide enhanced return-based\nguidance during data sampling. GODA learns a comprehensive distribution\nrepresentation of the original offline datasets while generating new data with\nselectively higher-return goals, thereby maximizing the utility of limited\noptimal demonstrations. Furthermore, we propose a novel adaptive gated\nconditioning method for processing noised inputs and conditions, enhancing the\ncapture of goal-oriented guidance. We conduct experiments on the D4RL benchmark\nand real-world challenges, specifically traffic signal control (TSC) tasks, to\ndemonstrate GODA's effectiveness in enhancing data quality and superior\nperformance compared to state-of-the-art data augmentation methods across\nvarious offline RL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20519v1",
    "published_date": "2024-12-29 16:42:30 UTC",
    "updated_date": "2024-12-29 16:42:30 UTC"
  },
  {
    "arxiv_id": "2412.20512v1",
    "title": "Dive into Time-Series Anomaly Detection: A Decade Review",
    "authors": [
      "Paul Boniol",
      "Qinghua Liu",
      "Mingyi Huang",
      "Themis Palpanas",
      "John Paparrizos"
    ],
    "abstract": "Recent advances in data collection technology, accompanied by the ever-rising\nvolume and velocity of streaming data, underscore the vital need for time\nseries analytics. In this regard, time-series anomaly detection has been an\nimportant activity, entailing various applications in fields such as cyber\nsecurity, financial markets, law enforcement, and health care. While\ntraditional literature on anomaly detection is centered on statistical\nmeasures, the increasing number of machine learning algorithms in recent years\ncall for a structured, general characterization of the research methods for\ntime-series anomaly detection. This survey groups and summarizes anomaly\ndetection existing solutions under a process-centric taxonomy in the time\nseries context. In addition to giving an original categorization of anomaly\ndetection methods, we also perform a meta-analysis of the literature and\noutline general trends in time-series anomaly detection research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20512v1",
    "published_date": "2024-12-29 16:11:46 UTC",
    "updated_date": "2024-12-29 16:11:46 UTC"
  },
  {
    "arxiv_id": "2412.20510v1",
    "title": "Stratify: Unifying Multi-Step Forecasting Strategies",
    "authors": [
      "Riku Green",
      "Grant Stevens",
      "Zahraa Abdallah",
      "Telmo M. Silva Filho"
    ],
    "abstract": "A key aspect of temporal domains is the ability to make predictions multiple\ntime steps into the future, a process known as multi-step forecasting (MSF). At\nthe core of this process is selecting a forecasting strategy, however, with no\nexisting frameworks to map out the space of strategies, practitioners are left\nwith ad-hoc methods for strategy selection. In this work, we propose Stratify,\na parameterised framework that addresses multi-step forecasting, unifying\nexisting strategies and introducing novel, improved strategies. We evaluate\nStratify on 18 benchmark datasets, five function classes, and short to long\nforecast horizons (10, 20, 40, 80). In over 84% of 1080 experiments, novel\nstrategies in Stratify improved performance compared to all existing ones.\nImportantly, we find that no single strategy consistently outperforms others in\nall task settings, highlighting the need for practitioners explore the Stratify\nspace to carefully search and select forecasting strategies based on\ntask-specific requirements. Our results are the most comprehensive benchmarking\nof known and novel forecasting strategies. We make code available to reproduce\nour results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 9 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2412.20510v1",
    "published_date": "2024-12-29 16:06:46 UTC",
    "updated_date": "2024-12-29 16:06:46 UTC"
  },
  {
    "arxiv_id": "2501.00066v1",
    "title": "On Adversarial Robustness of Language Models in Transfer Learning",
    "authors": [
      "Bohdan Turbal",
      "Anastasiia Mazur",
      "Jiaxu Zhao",
      "Mykola Pechenizkiy"
    ],
    "abstract": "We investigate the adversarial robustness of LLMs in transfer learning\nscenarios. Through comprehensive experiments on multiple datasets (MBIB Hate\nSpeech, MBIB Political Bias, MBIB Gender Bias) and various model architectures\n(BERT, RoBERTa, GPT-2, Gemma, Phi), we reveal that transfer learning, while\nimproving standard performance metrics, often leads to increased vulnerability\nto adversarial attacks. Our findings demonstrate that larger models exhibit\ngreater resilience to this phenomenon, suggesting a complex interplay between\nmodel size, architecture, and adaptation methods. Our work highlights the\ncrucial need for considering adversarial robustness in transfer learning\nscenarios and provides insights into maintaining model security without\ncompromising performance. These findings have significant implications for the\ndevelopment and deployment of LLMs in real-world applications where both\nperformance and robustness are paramount.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00066v1",
    "published_date": "2024-12-29 15:55:35 UTC",
    "updated_date": "2024-12-29 15:55:35 UTC"
  },
  {
    "arxiv_id": "2412.20505v1",
    "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning",
    "authors": [
      "Hang Ni",
      "Yuzhi Wang",
      "Hao Liu"
    ],
    "abstract": "Urban regeneration presents significant challenges within the context of\nurbanization, requiring adaptive approaches to tackle evolving needs.\nLeveraging advancements in large language models (LLMs), we propose Cyclical\nUrban Planning (CUP), a new paradigm that continuously generates, evaluates,\nand refines urban plans in a closed-loop. Specifically, our multi-agent\nLLM-based framework consists of three key components: (1) Planning, where LLM\nagents generate and refine urban plans based on contextual data; (2) Living,\nwhere agents simulate the behaviors and interactions of residents, modeling\nlife in the urban environment; and (3) Judging, which involves evaluating plan\neffectiveness and providing iterative feedback for improvement. The cyclical\nprocess enables a dynamic and responsive planning approach. Experiments on the\nreal-world dataset demonstrate the effectiveness of our framework as a\ncontinuous and adaptive planning process.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 2 figures, accepted by The 1st Workshop on AI for Urban\n  Planning (AAAI 2025's Workshop)",
    "pdf_url": "http://arxiv.org/pdf/2412.20505v1",
    "published_date": "2024-12-29 15:43:25 UTC",
    "updated_date": "2024-12-29 15:43:25 UTC"
  },
  {
    "arxiv_id": "2412.20495v1",
    "title": "A Multiparty Homomorphic Encryption Approach to Confidential Federated Kaplan Meier Survival Analysis",
    "authors": [
      "Narasimha Raghavan Veeraragavan",
      "Svetlana Boudko",
      "Jan Franz Nygård"
    ],
    "abstract": "The proliferation of healthcare data has expanded opportunities for\ncollaborative research, yet stringent privacy regulations hinder pooling\nsensitive patient records. We propose a \\emph{multiparty homomorphic\nencryption-based} framework for \\emph{privacy-preserving federated\nKaplan--Meier survival analysis}, offering native floating-point support, a\ntheoretical model, and explicit reconstruction-attack mitigation. Compared to\nprior work, our framework ensures encrypted federated survival estimates\nclosely match centralized outcomes, supported by formal utility-loss bounds\nthat demonstrate convergence as aggregation and decryption noise diminish.\nExtensive experiments on the NCCTG Lung Cancer and synthetic Breast Cancer\ndatasets confirm low \\emph{mean absolute error (MAE)} and \\emph{root mean\nsquared error (RMSE)}, indicating negligible deviations between encrypted and\nnon-encrypted survival curves. Log-rank and numerical accuracy tests reveal\n\\emph{no significant difference} between federated encrypted and non-encrypted\nanalyses, preserving statistical validity. A reconstruction-attack evaluation\nshows smaller federations (2--3 providers) with overlapping data between the\ninstitutions are vulnerable, a challenge mitigated by multiparty encryption.\nLarger federations (5--50 sites) degrade reconstruction accuracy further, with\nencryption improving confidentiality. Despite an 8--19$\\times$ computational\noverhead, threshold-based homomorphic encryption is \\emph{feasible for\nmoderate-scale deployments}, balancing security and runtime. By providing\nrobust privacy guarantees alongside high-fidelity survival estimates, our\nframework advances the state-of-the art in secure multi-institutional survival\nanalysis.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CR",
    "comment": "40 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.20495v1",
    "published_date": "2024-12-29 15:17:42 UTC",
    "updated_date": "2024-12-29 15:17:42 UTC"
  },
  {
    "arxiv_id": "2501.00065v1",
    "title": "Predicting Preschoolers' Externalizing Problems with Mother-Child Interaction Dynamics and Deep Learning",
    "authors": [
      "Xi Chen",
      "Yu Ji",
      "Cong Xia",
      "Wen Wu"
    ],
    "abstract": "Objective: Predicting children's future levels of externalizing problems\nhelps to identify children at risk and guide targeted prevention. Existing\nstudies have shown that mothers providing support in response to children's\ndysregulation was associated with children's lower levels of externalizing\nproblems. The current study aims to evaluate and improve the accuracy of\npredicting children's externalizing problems with mother-child interaction\ndynamics. Method: This study used mother-child interaction dynamics during a\nchallenging puzzle task to predict children's externalizing problems six months\nlater (N=101, 46 boys, Mage=57.41 months, SD=6.58). Performance of the Residual\nDynamic Structural Equation Model (RDSEM) was compared with the Attention-based\nSequential Behavior Interaction Modeling (ASBIM) model, developed using the\ndeep learning techniques. Results: The RDSEM revealed that children whose\nmothers provided more autonomy support after increases of child defeat had\nlower levels of externalizing problems. Five-fold cross-validation showed that\nthe RDSEM had good prediction accuracy. The ASBIM model further improved\nprediction accuracy, especially after including child inhibitory control as a\npersonalized individual feature. Conclusions: The dynamic process of\nmother-child interaction provides important information for predicting\nchildren's externalizing problems, especially maternal autonomy supportive\nresponse to child defeat. The deep learning model is a useful tool to further\nimprove prediction accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.00065v1",
    "published_date": "2024-12-29 14:22:48 UTC",
    "updated_date": "2024-12-29 14:22:48 UTC"
  },
  {
    "arxiv_id": "2501.01982v2",
    "title": "Is Your Image a Good Storyteller?",
    "authors": [
      "Xiujie Song",
      "Xiaoyi Pang",
      "Haifeng Tang",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "abstract": "Quantifying image complexity at the entity level is straightforward, but the\nassessment of semantic complexity has been largely overlooked. In fact, there\nare differences in semantic complexity across images. Images with richer\nsemantics can tell vivid and engaging stories and offer a wide range of\napplication scenarios. For example, the Cookie Theft picture is such a kind of\nimage and is widely used to assess human language and cognitive abilities due\nto its higher semantic complexity. Additionally, semantically rich images can\nbenefit the development of vision models, as images with limited semantics are\nbecoming less challenging for them. However, such images are scarce,\nhighlighting the need for a greater number of them. For instance, there is a\nneed for more images like Cookie Theft to cater to people from different\ncultural backgrounds and eras. Assessing semantic complexity requires human\nexperts and empirical evidence. Automatic evaluation of how semantically rich\nan image will be the first step of mining or generating more images with rich\nsemantics, and benefit human cognitive assessment, Artificial Intelligence, and\nvarious other applications. In response, we propose the Image Semantic\nAssessment (ISA) task to address this problem. We introduce the first ISA\ndataset and a novel method that leverages language to solve this vision\nproblem. Experiments on our dataset demonstrate the effectiveness of our\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.01982v2",
    "published_date": "2024-12-29 14:04:39 UTC",
    "updated_date": "2025-02-22 06:53:56 UTC"
  },
  {
    "arxiv_id": "2412.20468v2",
    "title": "A Comprehensive Framework for Reliable Legal AI: Combining Specialized Expert Systems and Adaptive Refinement",
    "authors": [
      "Sidra Nasir",
      "Qamar Abbas",
      "Samita Bai",
      "Rizwan Ahmed Khan"
    ],
    "abstract": "This article discusses the evolving role of artificial intelligence (AI) in\nthe legal profession, focusing on its potential to streamline tasks such as\ndocument review, research, and contract drafting. However, challenges persist,\nparticularly the occurrence of \"hallucinations\" in AI models, where they\ngenerate inaccurate or misleading information, undermining their reliability in\nlegal contexts. To address this, the article proposes a novel framework\ncombining a mixture of expert systems with a knowledge-based architecture to\nimprove the precision and contextual relevance of AI-driven legal services.\nThis framework utilizes specialized modules, each focusing on specific legal\nareas, and incorporates structured operational guidelines to enhance\ndecision-making. Additionally, it leverages advanced AI techniques like\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KG), and Reinforcement\nLearning from Human Feedback (RLHF) to improve the system's accuracy. The\nproposed approach demonstrates significant improvements over existing AI\nmodels, showcasing enhanced performance in legal tasks and offering a scalable\nsolution to provide more accessible and affordable legal services. The article\nalso outlines the methodology, system architecture, and promising directions\nfor future research in AI applications for the legal sector.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages and 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.20468v2",
    "published_date": "2024-12-29 14:00:11 UTC",
    "updated_date": "2025-03-05 04:32:02 UTC"
  },
  {
    "arxiv_id": "2412.20438v1",
    "title": "Integrating Natural Language Processing Techniques of Text Mining Into Financial System: Applications and Limitations",
    "authors": [
      "Denisa Millo",
      "Blerina Vika",
      "Nevila Baci"
    ],
    "abstract": "The financial sector, a pivotal force in economic development, increasingly\nuses the intelligent technologies such as natural language processing to\nenhance data processing and insight extraction. This research paper through a\nreview process of the time span of 2018-2023 explores the use of text mining as\nnatural language processing techniques in various components of the financial\nsystem including asset pricing, corporate finance, derivatives, risk\nmanagement, and public finance and highlights the need to address the specific\nproblems in the discussion section. We notice that most of the research\nmaterials combined probabilistic with vector-space models, and text-data with\nnumerical ones. The most used technique regarding information processing is the\ninformation classification technique and the most used algorithms include the\nlong-short term memory and bidirectional encoder models. The research noticed\nthat new specific algorithms are developed and the focus of the financial\nsystem is mainly on asset pricing component. The research also proposes a path\nfrom engineering perspective for researchers who need to analyze financial\ntext. The challenges regarding text mining perspective such as data quality,\ncontext-adaption and model interpretability need to be solved so to integrate\nadvanced natural language processing models and techniques in enhancing\nfinancial analysis and prediction. Keywords: Financial System (FS), Natural\nLanguage Processing (NLP), Software and Text Engineering, Probabilistic,\nVector-Space, Models, Techniques, TextData, Financial Analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2412.20438v1",
    "published_date": "2024-12-29 11:25:03 UTC",
    "updated_date": "2024-12-29 11:25:03 UTC"
  },
  {
    "arxiv_id": "2412.20429v3",
    "title": "Multi-Scenario Reasoning: Unlocking Cognitive Autonomy in Humanoid Robots for Multimodal Understanding",
    "authors": [
      "Libo Wang"
    ],
    "abstract": "To improve the cognitive autonomy of humanoid robots, this research proposes\na multi-scenario reasoning architecture to solve the technical shortcomings of\nmulti-modal understanding in this field. It draws on simulation based\nexperimental design that adopts multi-modal synthesis (visual, auditory,\ntactile) and builds a simulator \"Maha\" to perform the experiment. The findings\ndemonstrate the feasibility of this architecture in multimodal data. It\nprovides reference experience for the exploration of cross-modal interaction\nstrategies for humanoid robots in dynamic environments. In addition,\nmulti-scenario reasoning simulates the high-level reasoning mechanism of the\nhuman brain to humanoid robots at the cognitive level. This new concept\npromotes cross-scenario practical task transfer and semantic-driven action\nplanning. It heralds the future development of self-learning and autonomous\nbehavior of humanoid robots in changing scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "The main text is 5 pages, 2 figures, and 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.20429v3",
    "published_date": "2024-12-29 10:46:08 UTC",
    "updated_date": "2025-01-07 18:24:45 UTC"
  },
  {
    "arxiv_id": "2412.20414v1",
    "title": "Comparative Performance of Advanced NLP Models and LLMs in Multilingual Geo-Entity Detection",
    "authors": [
      "Kalin Kopanov"
    ],
    "abstract": "The integration of advanced Natural Language Processing (NLP) methodologies\nand Large Language Models (LLMs) has significantly enhanced the extraction and\nanalysis of geospatial data from multilingual texts, impacting sectors such as\nnational and international security. This paper presents a comprehensive\nevaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and\nLLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of\nmultilingual geo-entity detection. Utilizing datasets from Telegram channels in\nEnglish, Russian, and Arabic, we examine the performance of these models\nthrough metrics such as accuracy, precision, recall, and F1 scores, to assess\ntheir effectiveness in accurately identifying geospatial references. The\nanalysis exposes each model's distinct advantages and challenges, underscoring\nthe complexities involved in achieving precise geo-entity identification across\nvaried linguistic landscapes. The conclusions drawn from this experiment aim to\ndirect the enhancement and creation of more advanced and inclusive NLP tools,\nthus advancing the field of geospatial analysis and its application to global\nsecurity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 table, AICCONF '24: Cognitive Models and Artificial\n  Intelligence Conference, Istanbul, Turkey",
    "pdf_url": "http://arxiv.org/pdf/2412.20414v1",
    "published_date": "2024-12-29 09:47:14 UTC",
    "updated_date": "2024-12-29 09:47:14 UTC"
  },
  {
    "arxiv_id": "2412.20412v2",
    "title": "Multi-Objective Large Language Model Unlearning",
    "authors": [
      "Zibin Pan",
      "Shuwen Zhang",
      "Yuesheng Zheng",
      "Chi Li",
      "Yuheng Cheng",
      "Junhua Zhao"
    ],
    "abstract": "Machine unlearning in the domain of large language models (LLMs) has\nattracted great attention recently, which aims to effectively eliminate\nundesirable behaviors from LLMs without full retraining from scratch. In this\npaper, we explore the Gradient Ascent (GA) approach in LLM unlearning, which is\na proactive way to decrease the prediction probability of the model on the\ntarget data in order to remove their influence. We analyze two challenges that\nrender the process impractical: gradient explosion and catastrophic forgetting.\nTo address these issues, we propose Multi-Objective Large Language Model\nUnlearning (MOLLM) algorithm. We first formulate LLM unlearning as a\nmulti-objective optimization problem, in which the cross-entropy loss is\nmodified to the unlearning version to overcome the gradient explosion issue. A\ncommon descent update direction is then calculated, which enables the model to\nforget the target data while preserving the utility of the LLM. Our empirical\nresults verify that MoLLM outperforms the SOTA GA-based LLM unlearning methods\nin terms of unlearning effect and model utility preservation. The source code\nis available at https://github.com/zibinpan/MOLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in the Proceedings of 2025 IEEE International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP-2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.20412v2",
    "published_date": "2024-12-29 09:35:56 UTC",
    "updated_date": "2025-01-04 13:27:04 UTC"
  },
  {
    "arxiv_id": "2501.00063v1",
    "title": "\"Generative Models for Financial Time Series Data: Enhancing Signal-to-Noise Ratio and Addressing Data Scarcity in A-Share Market",
    "authors": [
      "Guangming Che"
    ],
    "abstract": "The financial industry is increasingly seeking robust methods to address the\nchallenges posed by data scarcity and low signal-to-noise ratios, which limit\nthe application of deep learning techniques in stock market analysis. This\npaper presents two innovative generative model-based approaches to synthesize\nstock data, specifically tailored for different scenarios within the A-share\nmarket in China. The first method, a sector-based synthesis approach, enhances\nthe signal-to-noise ratio of stock data by classifying the characteristics of\nstocks from various sectors in China's A-share market. This method employs an\nApproximate Non-Local Total Variation algorithm to smooth the generated data, a\nbandpass filtering method based on Fourier Transform to eliminate noise, and\nDenoising Diffusion Implicit Models to accelerate sampling speed. The second\nmethod, a recursive stock data synthesis approach based on pattern recognition,\nis designed to synthesize data for stocks with short listing periods and\nlimited comparable companies. It leverages pattern recognition techniques and\nMarkov models to learn and generate variable-length stock sequences, while\nintroducing a sub-time-level data augmentation method to alleviate data\nscarcity issues.We validate the effectiveness of these methods through\nextensive experiments on various datasets, including those from the main board,\nSTAR Market, Growth Enterprise Market Board, Beijing Stock Exchange, NASDAQ,\nNYSE, and AMEX. The results demonstrate that our synthesized data not only\nimprove the performance of predictive models but also enhance the\nsignal-to-noise ratio of individual stock signals in price trading strategies.\nFurthermore, the introduction of sub-time-level data significantly improves the\nquality of synthesized data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00063v1",
    "published_date": "2024-12-29 09:35:23 UTC",
    "updated_date": "2024-12-29 09:35:23 UTC"
  },
  {
    "arxiv_id": "2412.20382v1",
    "title": "Natural Language Fine-Tuning",
    "authors": [
      "Jia Liu",
      "Yue Wang",
      "Zhiqi Lin",
      "Min Chen",
      "Yixue Hao",
      "Long Hu"
    ],
    "abstract": "Large language model fine-tuning techniques typically depend on extensive\nlabeled data, external guidance, and feedback, such as human alignment, scalar\nrewards, and demonstration. However, in practical application, the scarcity of\nspecific knowledge poses unprecedented challenges to existing fine-tuning\ntechniques. In this paper, focusing on fine-tuning tasks in specific domains\nwith limited data, we introduce Natural Language Fine-Tuning (NLFT), which\nutilizes natural language for fine-tuning for the first time. By leveraging the\nstrong language comprehension capability of the target LM, NLFT attaches the\nguidance of natural language to the token-level outputs. Then, saliency tokens\nare identified with calculated probabilities. Since linguistic information is\neffectively utilized in NLFT, our proposed method significantly reduces\ntraining costs. It markedly enhances training efficiency, comprehensively\noutperforming reinforcement fine-tuning algorithms in accuracy, time-saving,\nand resource conservation. Additionally, on the macro level, NLFT can be viewed\nas a token-level fine-grained optimization of SFT, thereby efficiently\nreplacing the SFT process without the need for warm-up (as opposed to ReFT\nrequiring multiple rounds of warm-up with SFT). Compared to SFT, NLFT does not\nincrease the algorithmic complexity, maintaining O(n). Extensive experiments on\nthe GSM8K dataset demonstrate that NLFT, with only 50 data instances, achieves\nan accuracy increase that exceeds SFT by 219%. Compared to ReFT, the time\ncomplexity and space complexity of NLFT are reduced by 78.27% and 92.24%,\nrespectively. The superior technique of NLFT is paving the way for the\ndeployment of various innovative LLM fine-tuning applications when resources\nare limited at network edges.\n  Our code has been released at https://github.com/Julia-LiuJ/NLFT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20382v1",
    "published_date": "2024-12-29 07:02:45 UTC",
    "updated_date": "2024-12-29 07:02:45 UTC"
  },
  {
    "arxiv_id": "2412.20373v1",
    "title": "A Deep Subgrouping Framework for Precision Drug Repurposing via Emulating Clinical Trials on Real-world Patient Data",
    "authors": [
      "Seungyeon Lee",
      "Ruoqi Liu",
      "Feixiong Cheng",
      "Ping Zhang"
    ],
    "abstract": "Drug repurposing identifies new therapeutic uses for existing drugs, reducing\nthe time and costs compared to traditional de novo drug discovery. Most\nexisting drug repurposing studies using real-world patient data often treat the\nentire population as homogeneous, ignoring the heterogeneity of treatment\nresponses across patient subgroups. This approach may overlook promising drugs\nthat benefit specific subgroups but lack notable treatment effects across the\nentire population, potentially limiting the number of repurposable candidates\nidentified. To address this, we introduce STEDR, a novel drug repurposing\nframework that integrates subgroup analysis with treatment effect estimation.\nOur approach first identifies repurposing candidates by emulating multiple\nclinical trials on real-world patient data and then characterizes patient\nsubgroups by learning subgroup-specific treatment effects. We deploy \\model to\nAlzheimer's Disease (AD), a condition with few approved drugs and known\nheterogeneity in treatment responses. We emulate trials for over one thousand\nmedications on a large-scale real-world database covering over 8 million\npatients, identifying 14 drug candidates with beneficial effects to AD in\ncharacterized subgroups. Experiments demonstrate STEDR's superior capability in\nidentifying repurposing candidates compared to existing approaches.\nAdditionally, our method can characterize clinically relevant patient subgroups\nassociated with important AD-related risk factors, paving the way for precision\ndrug repurposing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "I.2.0; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.20373v1",
    "published_date": "2024-12-29 06:32:52 UTC",
    "updated_date": "2024-12-29 06:32:52 UTC"
  },
  {
    "arxiv_id": "2412.20372v2",
    "title": "LLM2: Let Large Language Models Harness System 2 Reasoning",
    "authors": [
      "Cheng Yang",
      "Chufan Shi",
      "Siheng Li",
      "Bo Shui",
      "Yujiu Yang",
      "Wai Lam"
    ],
    "abstract": "Large language models (LLMs) have exhibited impressive capabilities across a\nmyriad of tasks, yet they occasionally yield undesirable outputs. We posit that\nthese limitations are rooted in the foundational autoregressive architecture of\nLLMs, which inherently lacks mechanisms for differentiating between desirable\nand undesirable results. Drawing inspiration from the dual-process theory of\nhuman cognition, we introduce LLM2, a novel framework that combines an LLM\n(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is\nresponsible for generating plausible candidates, while the verifier provides\ntimely process-based feedback to distinguish desirable and undesirable outputs.\nThe verifier is trained with a pairwise comparison loss on synthetic\nprocess-supervision data generated through our token quality exploration\nstrategy. Empirical results on mathematical reasoning benchmarks substantiate\nthe efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8\n(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with\nself-consistency, LLM2 achieves additional improvements, boosting major@20\naccuracy from 56.2 to 70.2 (+14.0).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2412.20372v2",
    "published_date": "2024-12-29 06:32:36 UTC",
    "updated_date": "2025-02-28 13:06:02 UTC"
  },
  {
    "arxiv_id": "2412.20361v1",
    "title": "Safe Multiagent Coordination via Entropic Exploration",
    "authors": [
      "Ayhan Alp Aydeniz",
      "Enrico Marchesini",
      "Robert Loftin",
      "Christopher Amato",
      "Kagan Tumer"
    ],
    "abstract": "Many real-world multiagent learning problems involve safety concerns. In\nthese setups, typical safe reinforcement learning algorithms constrain agents'\nbehavior, limiting exploration -- a crucial component for discovering effective\ncooperative multiagent behaviors. Moreover, the multiagent literature typically\nmodels individual constraints for each agent and has yet to investigate the\nbenefits of using joint team constraints. In this work, we analyze these team\nconstraints from a theoretical and practical perspective and propose entropic\nexploration for constrained multiagent reinforcement learning (E2C) to address\nthe exploration issue. E2C leverages observation entropy maximization to\nincentivize exploration and facilitate learning safe and effective cooperative\nbehaviors. Experiments across increasingly complex domains show that E2C agents\nmatch or surpass common unconstrained and constrained baselines in task\nperformance while reducing unsafe behaviors by up to $50\\%$.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.20361v1",
    "published_date": "2024-12-29 05:50:19 UTC",
    "updated_date": "2024-12-29 05:50:19 UTC"
  },
  {
    "arxiv_id": "2412.20359v1",
    "title": "EmoReg: Directional Latent Vector Modeling for Emotional Intensity Regularization in Diffusion-based Voice Conversion",
    "authors": [
      "Ashishkumar Gudmalwar",
      "Ishan D. Biyani",
      "Nirmesh Shah",
      "Pankaj Wasnik",
      "Rajiv Ratn Shah"
    ],
    "abstract": "The Emotional Voice Conversion (EVC) aims to convert the discrete emotional\nstate from the source emotion to the target for a given speech utterance while\npreserving linguistic content. In this paper, we propose regularizing emotion\nintensity in the diffusion-based EVC framework to generate precise speech of\nthe target emotion. Traditional approaches control the intensity of an\nemotional state in the utterance via emotion class probabilities or intensity\nlabels that often lead to inept style manipulations and degradations in\nquality. On the contrary, we aim to regulate emotion intensity using\nself-supervised learning-based feature representations and unsupervised\ndirectional latent vector modeling (DVM) in the emotional embedding space\nwithin a diffusion-based framework. These emotion embeddings can be modified\nbased on the given target emotion intensity and the corresponding direction\nvector. Furthermore, the updated embeddings can be fused in the reverse\ndiffusion process to generate the speech with the desired emotion and\nintensity. In summary, this paper aims to achieve high-quality emotional\nintensity regularization in the diffusion-based EVC framework, which is the\nfirst of its kind work. The effectiveness of the proposed method has been shown\nacross state-of-the-art (SOTA) baselines in terms of subjective and objective\nevaluations for the English and Hindi languages \\footnote{Demo samples are\navailable at the following URL: \\url{https://nirmesh-sony.github.io/EmoReg/}}.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.20359v1",
    "published_date": "2024-12-29 05:30:06 UTC",
    "updated_date": "2024-12-29 05:30:06 UTC"
  },
  {
    "arxiv_id": "2501.00062v2",
    "title": "ELECTRA and GPT-4o: Cost-Effective Partners for Sentiment Analysis",
    "authors": [
      "James P. Beno"
    ],
    "abstract": "Bidirectional transformers excel at sentiment analysis, and Large Language\nModels (LLM) are effective zero-shot learners. Might they perform better as a\nteam? This paper explores collaborative approaches between ELECTRA and GPT-4o\nfor three-way sentiment classification. We fine-tuned (FT) four models (ELECTRA\nBase/Large, GPT-4o/4o-mini) using a mix of reviews from Stanford Sentiment\nTreebank (SST) and DynaSent. We provided input from ELECTRA to GPT as:\npredicted label, probabilities, and retrieved examples. Sharing ELECTRA Base FT\npredictions with GPT-4o-mini significantly improved performance over either\nmodel alone (82.50 macro F1 vs. 79.14 ELECTRA Base FT, 79.41 GPT-4o-mini) and\nyielded the lowest cost/performance ratio (\\$0.12/F1 point). However, when GPT\nmodels were fine-tuned, including predictions decreased performance. GPT-4o\nFT-M was the top performer (86.99), with GPT-4o-mini FT close behind (86.70) at\nmuch less cost (\\$0.38 vs. \\$1.59/F1 point). Our results show that augmenting\nprompts with predictions from fine-tuned encoders is an efficient way to boost\nperformance, and a fine-tuned GPT-4o-mini is nearly as good as GPT-4o FT at 76%\nless cost. Both are affordable options for projects with limited resources.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 4 figures. Source code and data available at\n  https://github.com/jbeno/sentiment",
    "pdf_url": "http://arxiv.org/pdf/2501.00062v2",
    "published_date": "2024-12-29 05:29:52 UTC",
    "updated_date": "2025-05-03 23:36:30 UTC"
  },
  {
    "arxiv_id": "2412.20357v1",
    "title": "HindiLLM: Large Language Model for Hindi",
    "authors": [
      "Sanjay Chouhan",
      "Shubha Brata Nath",
      "Aparajita Dutta"
    ],
    "abstract": "The advancements in the Large Language Model (LLM) have helped in solving\nseveral problems related to language processing. Most of the researches have\nfocused on the English language only, because of its popularity and abundance\non the internet. However, a high-performance language model for Hindi and other\nIndic languages is lacking in the literature. In this work, we have pre-trained\ntwo autoregressive LLM models for the Hindi language, namely HindiLLM-Small and\nHindiLLM-Medium. We use a two-step process comprising unsupervised pre-training\nand supervised fine-tuning. First, we create a large and high-quality text\ncorpus for unsupervised pre-training. Next, we train a Byte-Pair Encoding,\nnamed HindiLLM tokenizer, using the pre-training text data. We then perform\ntraining on the unlabeled data, known as the pre-training step, to get the\nHindiLLM base models. Furthermore, we perform fine-tuning of the HindiLLM base\nmodels for different tasks like sentiment analysis, text classification,\nnatural language inference, and multiple choice question-answer on popular\nlabeled datasets to measure the real-world performance. The evaluation shows\nthat the HindiLLM-based fine-tuned models outperform several models in most of\nthe language related tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20357v1",
    "published_date": "2024-12-29 05:28:15 UTC",
    "updated_date": "2024-12-29 05:28:15 UTC"
  },
  {
    "arxiv_id": "2501.00061v1",
    "title": "Training-free Heterogeneous Model Merging",
    "authors": [
      "Zhengqi Xu",
      "Han Zheng",
      "Jie Song",
      "Li Sun",
      "Mingli Song"
    ],
    "abstract": "Model merging has attracted significant attention as a powerful paradigm for\nmodel reuse, facilitating the integration of task-specific models into a\nsingular, versatile framework endowed with multifarious capabilities. Previous\nstudies, predominantly utilizing methods such as Weight Average (WA), have\nshown that model merging can effectively leverage pretrained models without the\nneed for laborious retraining. However, the inherent heterogeneity among models\nposes a substantial constraint on its applicability, particularly when\nconfronted with discrepancies in model architectures. To overcome this\nchallenge, we propose an innovative model merging framework designed for\nheterogeneous models, encompassing both depth and width heterogeneity. To\naddress depth heterogeneity, we introduce a layer alignment strategy that\nharmonizes model layers by segmenting deeper models, treating consecutive\nlayers with similar representations as a cohesive segment, thus enabling the\nseamless merging of models with differing layer depths. For width\nheterogeneity, we propose a novel elastic neuron zipping algorithm that\nprojects the weights from models of varying widths onto a common dimensional\nspace, eliminating the need for identical widths. Extensive experiments\nvalidate the efficacy of these proposed methods, demonstrating that the merging\nof structurally heterogeneous models can achieve performance levels comparable\nto those of homogeneous merging, across both vision and NLP tasks. Our code is\npublicly available at\nhttps://github.com/zju-vipa/training_free_heterogeneous_model_merging.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00061v1",
    "published_date": "2024-12-29 04:49:11 UTC",
    "updated_date": "2024-12-29 04:49:11 UTC"
  },
  {
    "arxiv_id": "2412.20340v2",
    "title": "Distilling Desired Comments for Enhanced Code Review with Large Language Models",
    "authors": [
      "Yongda Yu",
      "Lei Zhang",
      "Guoping Rong",
      "Haifeng Shen",
      "Jiahao Zhang",
      "Haoxiang Yan",
      "Guohao Shi",
      "Dong Shao",
      "Ruiqi Pan",
      "Yuan Li",
      "Qiushi Wang",
      "Zhao Tian"
    ],
    "abstract": "There has been a growing interest in using Large Language Models (LLMs) for\ncode review thanks to their proven proficiency in code comprehension. The\nprimary objective of most review scenarios is to generate desired review\ncomments (DRCs) that explicitly identify issues to trigger code fixes. However,\nexisting LLM-based solutions are not so effective in generating DRCs for\nvarious reasons such as hallucination. To enhance their code review ability,\nthey need to be fine-tuned with a customized dataset that is ideally full of\nDRCs. Nevertheless, such a dataset is not yet available, while manual\nannotation of DRCs is too laborious to be practical. In this paper, we propose\na dataset distillation method, Desiview, which can automatically construct a\ndistilled dataset by identifying DRCs from a code review dataset. Experiments\non the CodeReviewer dataset comprising more than 150K review entries show that\nDesiview achieves an impressive performance of 88.93%, 80.37%, 86.67%, and\n84.44% in terms of Precision, Recall, Accuracy, and F1, respectively,\nsurpassing state-of-the-art methods. To validate the effect of such a distilled\ndataset on enhancing LLMs' code review ability, we first fine-tune the latest\nLLaMA series (i.e., LLaMA 3 and LLaMA 3.1) to build model Desiview4FT. We then\nenhance the model training effect through KTO alignment by feeding those review\ncomments identified as non-DRCs to the LLMs, resulting in model Desiview4FA.\nVerification results indicate that Desiview4FA slightly outperforms\nDesiview4FT, while both models have significantly improved against the base\nmodels in terms of generating DRCs. Human evaluation confirms that both models\nidentify issues more accurately and tend to generate review comments that\nbetter describe the issues contained in the code than the base LLMs do.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.3; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.20340v2",
    "published_date": "2024-12-29 03:49:13 UTC",
    "updated_date": "2025-01-05 06:20:51 UTC"
  },
  {
    "arxiv_id": "2412.20338v1",
    "title": "Exploiting Hybrid Policy in Reinforcement Learning for Interpretable Temporal Logic Manipulation",
    "authors": [
      "Hao Zhang",
      "Hao Wang",
      "Xiucai Huang",
      "Wenrui Chen",
      "Zhen Kan"
    ],
    "abstract": "Reinforcement Learning (RL) based methods have been increasingly explored for\nrobot learning. However, RL based methods often suffer from low sampling\nefficiency in the exploration phase, especially for long-horizon manipulation\ntasks, and generally neglect the semantic information from the task level,\nresulted in a delayed convergence or even tasks failure. To tackle these\nchallenges, we propose a Temporal-Logic-guided Hybrid policy framework (HyTL)\nwhich leverages three-level decision layers to improve the agent's performance.\nSpecifically, the task specifications are encoded via linear temporal logic\n(LTL) to improve performance and offer interpretability. And a waypoints\nplanning module is designed with the feedback from the LTL-encoded task level\nas a high-level policy to improve the exploration efficiency. The middle-level\npolicy selects which behavior primitives to execute, and the low-level policy\nspecifies the corresponding parameters to interact with the environment. We\nevaluate HyTL on four challenging manipulation tasks, which demonstrate its\neffectiveness and interpretability. Our project is available at:\nhttps://sites.google.com/view/hytl-0257/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by IROS 2024. Code:https://github.com/Charlie0257/HyTL",
    "pdf_url": "http://arxiv.org/pdf/2412.20338v1",
    "published_date": "2024-12-29 03:34:53 UTC",
    "updated_date": "2024-12-29 03:34:53 UTC"
  },
  {
    "arxiv_id": "2412.20331v1",
    "title": "Mind the Data Gap: Bridging LLMs to Enterprise Data Integration",
    "authors": [
      "Moe Kayali",
      "Fabian Wenz",
      "Nesime Tatbul",
      "Çağatay Demiralp"
    ],
    "abstract": "Leading large language models (LLMs) are trained on public data. However,\nmost of the world's data is dark data that is not publicly accessible, mainly\nin the form of private organizational or enterprise data. We show that the\nperformance of methods based on LLMs seriously degrades when tested on\nreal-world enterprise datasets. Current benchmarks, based on public data,\noverestimate the performance of LLMs. We release a new benchmark dataset, the\nGOBY Benchmark, to advance discovery in enterprise data integration. Based on\nour experience with this enterprise benchmark, we propose techniques to uplift\nthe performance of LLMs on enterprise data, including (1) hierarchical\nannotation, (2) runtime class-learning, and (3) ontology synthesis. We show\nthat, once these techniques are deployed, the performance on enterprise data\nbecomes on par with that of public data. The Goby benchmark can be obtained at\nhttps://goby-benchmark.github.io/.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "CIDR'25",
    "pdf_url": "http://arxiv.org/pdf/2412.20331v1",
    "published_date": "2024-12-29 03:07:20 UTC",
    "updated_date": "2024-12-29 03:07:20 UTC"
  },
  {
    "arxiv_id": "2412.20329v1",
    "title": "Protein Structure Prediction in the 3D HP Model Using Deep Reinforcement Learning",
    "authors": [
      "Giovanny Espitia",
      "Yui Tik Pang",
      "James C. Gumbart"
    ],
    "abstract": "We address protein structure prediction in the 3D Hydrophobic-Polar lattice\nmodel through two novel deep learning architectures. For proteins under 36\nresidues, our hybrid reservoir-based model combines fixed random projections\nwith trainable deep layers, achieving optimal conformations with 25% fewer\ntraining episodes. For longer sequences, we employ a long short-term memory\nnetwork with multi-headed attention, matching best-known energy values. Both\narchitectures leverage a stabilized Deep Q-Learning framework with experience\nreplay and target networks, demonstrating consistent achievement of optimal\nconformations while significantly improving training efficiency compared to\nexisting methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.20329v1",
    "published_date": "2024-12-29 02:55:54 UTC",
    "updated_date": "2024-12-29 02:55:54 UTC"
  },
  {
    "arxiv_id": "2412.20321v1",
    "title": "Hypergraph-Based Dynamic Graph Node Classification",
    "authors": [
      "Xiaoxu Ma",
      "Chen Zhao",
      "Minglai Shao",
      "Yujie Lin"
    ],
    "abstract": "Node classification on static graphs has achieved significant success, but\nachieving accurate node classification on dynamic graphs where node topology,\nattributes, and labels change over time has not been well addressed. Existing\nmethods based on RNNs and self-attention only aggregate features of the same\nnode across different time slices, which cannot adequately address and capture\nthe diverse dynamic changes in dynamic graphs. Therefore, we propose a novel\nmodel named Hypergraph-Based Multi-granularity Dynamic Graph Node\nClassification (HYDG). After obtaining basic node representations for each\nslice through a GNN backbone, HYDG models the representations of each node in\nthe dynamic graph through two modules. The individual-level hypergraph captures\nthe spatio-temporal node representations between individual nodes, while the\ngroup-level hypergraph captures the multi-granularity group temporal\nrepresentations among nodes of the same class. Each hyperedge captures\ndifferent temporal dependencies of varying lengths by connecting multiple nodes\nwithin specific time ranges. More accurate representations are obtained through\nweighted information propagation and aggregation by the hypergraph neural\nnetwork. Extensive experiments on five real dynamic graph datasets using two\nGNN backbones demonstrate the superiority of our proposed framework.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted in ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.20321v1",
    "published_date": "2024-12-29 02:19:44 UTC",
    "updated_date": "2024-12-29 02:19:44 UTC"
  },
  {
    "arxiv_id": "2412.20302v2",
    "title": "EXAdam: The Power of Adaptive Cross-Moments",
    "authors": [
      "Ahmed M. Adly"
    ],
    "abstract": "This paper introduces EXAdam ($\\textbf{EX}$tended $\\textbf{Adam}$), a novel\noptimization algorithm that builds upon the widely-used Adam optimizer. EXAdam\nincorporates two key enhancements: (1) new debiasing terms for improved moment\nestimation and (2) a gradient-based acceleration mechanism for increased\nresponsiveness to the current loss landscape. These innovations work\nsynergistically to address limitations of the original Adam algorithm,\npotentially offering improved convergence properties, enhanced ability to\nescape saddle points, and potentially greater robustness to hyperparameter\nchoices, though this requires further investigation. We provide a theoretical\nanalysis of EXAdam's components and their interactions, highlighting the\nalgorithm's potential advantages in navigating complex optimization landscapes.\nEmpirical evaluations demonstrate EXAdam's superiority over Adam, achieving\n38.46% faster convergence and yielding improvements of 1.96%, 2.17%, and 1.17%\nin training, validation, and testing accuracies, respectively, when applied to\na CNN trained on the CIFAR-10 dataset. While these results are promising,\nfurther empirical validation across diverse tasks is essential to fully gauge\nEXAdam's efficacy. Nevertheless, EXAdam represents a significant advancement in\nadaptive optimization techniques, with promising implications for a wide range\nof machine learning applications. This work aims to contribute to the ongoing\ndevelopment of more efficient, adaptive, and universally applicable\noptimization methods in the field of machine learning and artificial\nintelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.20302v2",
    "published_date": "2024-12-29 00:11:54 UTC",
    "updated_date": "2025-05-16 08:00:28 UTC"
  }
]