{
  "date": "2025-02-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-26 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM（Large Language Models）的强化学习和文本检测、医疗图像分析以及多模态生成等领域，其中 MedVLM-R1 和 LLM 数学推理等文章展示了 AI 在医疗和推理任务中的突破性潜力，而知名学者如 Daniel Rueckert 的参与进一步提升了这些研究的学术影响力。\n\n### 重点论文讨论\n我挑选了最具代表性和影响力的论文进行详细讨论，将相关主题（如 LLM 优化和医疗 AI）归类放在一起，其他次要论文则简要掠过。以下按重要性排序，先聊 AI 和 LLM 核心贡献，再涉及医疗和科学应用。\n\n1. **MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning**  \n   这篇论文由 Daniel Rueckert 等知名学者主导，提出 MedVLM-R1 模型，使用强化学习框架提升视觉语言模型在医疗图像分析中的推理能力。主要贡献是通过无需参考推理路径的强化学习，显著提高模型在 MRI、CT 和 X 光等基准上的准确率（从 55.11% 提升至 78.22%），并增强了模型的可解释性和泛化能力，标志着 AI 在临床实践中的可信度提升。\n\n2. **Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning**  \n   论文探索了使用较弱 LLM 的观点混合来提升主 LLM 的数学推理能力。主要发现是通过混合观点的后期训练方法，平均提高了 5% 的推理性能，证明了多样化视角在任务优化中的价值。\n\n3. **Is Your Paper Being Reviewed by an LLM? A New Benchmark Dataset and Approach for Detecting AI Text in Peer Review**  \n   这篇论文引入一个包含近 79 万条审稿数据的基准数据集，并提出新检测算法。主要贡献是超越现有方法，准确识别 LLM 生成的审稿文本，强调了在学术环境中检测 AI 文本的紧迫性。\n\n4. **Self-rewarding correction for mathematical reasoning**  \n   论文提出一种自奖励机制，让 LLM 在推理过程中自主检测和修正错误。主要发现是通过自生成数据和强化学习，模型在数学任务中实现了与外部奖励模型相当的性能，提升了 LLM 的自适应能力。\n\n5. **Agentic Mixture-of-Workflows for Multi-Modal Chemical Search**  \n   相关于 AI 在科学领域的应用，论文引入 CRAG-MoW 框架，用于多模态化学搜索。主要贡献是使用开源 LLM 协调多种工作流，实现了与 GPT-4o 相当的性能，同时突出了结构化检索在材料发现中的优势。\n\n6. **3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and Swin Transformer**  \n   这篇医疗图像论文开发了 dsSNICT 模型，用于合成 CT 尿路造影中的肾图相图像。主要发现是生成的图像质量高，能减少辐射剂量 33.3%，并通过定量指标（如 PSNR 和 SSIM）验证了其临床实用性。\n\n其他论文中，涉及 LLM 优化和多代理系统的如 \"Program Synthesis Dialog Agents for Interactive Decision-Making\" 和 \"Learning Policy Committees for Effective Personalization in MDPs\" 等，展示了 AI 在决策和交互中的潜力，但细节较常规；医疗领域的 \"ICU-BERT\" 等则快速掠过，因为它们虽有贡献（如整合结构化和非结构化数据），但影响力不如上述重点。剩余论文，如特定数据集构建或小规模改进（如 \"African Gender Classification\"），则因主题较窄而简要提及，未深入讨论，以控制篇幅。总之，今天的论文突显了 AI 在医疗和推理领域的进展，值得关注！",
  "papers": [
    {
      "arxiv_id": "2502.19634v2",
      "title": "MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning",
      "title_zh": "MedVLM-R1：通过强化学习激励视觉语言模型（VLMs）的医疗推理能力",
      "authors": [
        "Jiazhen Pan",
        "Che Liu",
        "Junde Wu",
        "Fenglin Liu",
        "Jiayuan Zhu",
        "Hongwei Bran Li",
        "Chen Chen",
        "Cheng Ouyang",
        "Daniel Rueckert"
      ],
      "abstract": "Reasoning is a critical frontier for advancing medical image analysis, where\ntransparency and trustworthiness play a central role in both clinician trust\nand regulatory approval. Although Medical Visual Language Models (VLMs) show\npromise for radiological tasks, most existing VLMs merely produce final answers\nwithout revealing the underlying reasoning. To address this gap, we introduce\nMedVLM-R1, a medical VLM that explicitly generates natural language reasoning\nto enhance transparency and trustworthiness. Instead of relying on supervised\nfine-tuning (SFT), which often suffers from overfitting to training\ndistributions and fails to foster genuine reasoning, MedVLM-R1 employs a\nreinforcement learning framework that incentivizes the model to discover\nhuman-interpretable reasoning paths without using any reasoning references.\nDespite limited training data (600 visual question answering samples) and model\nparameters (2B), MedVLM-R1 boosts accuracy from 55.11% to 78.22% across MRI,\nCT, and X-ray benchmarks, outperforming larger models trained on over a million\nsamples. It also demonstrates robust domain generalization under\nout-of-distribution tasks. By unifying medical image analysis with explicit\nreasoning, MedVLM-R1 marks a pivotal step toward trustworthy and interpretable\nAI in clinical practice. Inference model is available at:\nhttps://huggingface.co/JZPeterPan/MedVLM-R1.",
      "tldr_zh": "该研究提出 MedVLM-R1，一种通过强化学习(Reinforcement Learning)增强视觉语言模型(VLMs)的医疗推理能力，旨在提升医疗图像分析的透明度和可信度。该模型生成自然语言推理路径，而非依赖监督微调(Supervised Fine-Tuning, SFT)，从而避免过拟合并促进真实推理。尽管仅使用600个样本和2B参数，MedVLM-R1在MRI、CT和X-ray基准上的准确率从55.11%提高到78.22%，优于训练数据量更大的模型，并展示了鲁棒的领域泛化能力，为可信赖的临床AI应用奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19634v2",
      "published_date": "2025-02-26 23:57:34 UTC",
      "updated_date": "2025-03-19 13:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:02:18.728076"
    },
    {
      "arxiv_id": "2502.19629v1",
      "title": "Agentic Mixture-of-Workflows for Multi-Modal Chemical Search",
      "title_zh": "翻译失败",
      "authors": [
        "Tiffany J. Callahan",
        "Nathaniel H. Park",
        "Sara Capponi"
      ],
      "abstract": "The vast and complex materials design space demands innovative strategies to\nintegrate multidisciplinary scientific knowledge and optimize materials\ndiscovery. While large language models (LLMs) have demonstrated promising\nreasoning and automation capabilities across various domains, their application\nin materials science remains limited due to a lack of benchmarking standards\nand practical implementation frameworks. To address these challenges, we\nintroduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented\nGeneration (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic\nworkflows employing distinct CRAG strategies using open-source LLMs. Unlike\nprior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration\nagent, enabling direct evaluation of multiple LLMs across the same problem\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral\nretrieval. Our results demonstrate that CRAG-MoWs achieve performance\ncomparable to GPT-4o while being preferred more frequently in comparative\nevaluations, highlighting the advantage of structured retrieval and multi-agent\nsynthesis. By revealing performance variations across data types, CRAG-MoW\nprovides a scalable, interpretable, and benchmark-driven approach to optimizing\nAI architectures for materials discovery. These insights are pivotal in\naddressing fundamental gaps in benchmarking LLMs and autonomous AI agents for\nscientific applications.",
      "tldr_zh": "该研究提出了一种名为 Agentic Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation (CRAG-MoW) 的新范式，用于多模态化学搜索，以整合多学科知识并优化材料发现。CRAG-MoW 通过开源 LLMs 编排多个代理工作流，每个采用不同的 CRAG 策略，实现输出合成、自校正和检索增强生成，从而直接评估同一领域的多个 LLMs。实验在小分子、聚合物、化学反应以及多模态 NMR 谱检索等基准测试中显示，CRAG-MoW 的性能可与 GPT-4o 媲美，甚至在比较评估中更受青睐，并揭示了不同数据类型下的性能差异。该框架提供了一种可扩展、可解释的方法，填补了 LLMs 在材料科学应用中的基准和实施缺口。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "PDF includes supplemental material",
      "pdf_url": "http://arxiv.org/pdf/2502.19629v1",
      "published_date": "2025-02-26 23:48:02 UTC",
      "updated_date": "2025-02-26 23:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:02:31.076805"
    },
    {
      "arxiv_id": "2502.19623v1",
      "title": "3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and Swin Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Hongkun Yu",
        "Syed Jamal Safdar Gardezi",
        "E. Jason Abel",
        "Daniel Shapiro",
        "Meghan G. Lubner",
        "Joshua Warner",
        "Matthew Smith",
        "Giuseppe Toia",
        "Lu Mao",
        "Pallavi Tiwari",
        "Andrew L. Wentland"
      ],
      "abstract": "Purpose: This study aims to develop and validate a method for synthesizing 3D\nnephrographic phase images in CT urography (CTU) examinations using a diffusion\nmodel integrated with a Swin Transformer-based deep learning approach.\nMaterials and Methods: This retrospective study was approved by the local\nInstitutional Review Board. A dataset comprising 327 patients who underwent\nthree-phase CTU (mean $\\pm$ SD age, 63 $\\pm$ 15 years; 174 males, 153 females)\nwas curated for deep learning model development. The three phases for each\npatient were aligned with an affine registration algorithm. A custom deep\nlearning model coined dsSNICT (diffusion model with a Swin transformer for\nsynthetic nephrographic phase images in CT) was developed and implemented to\nsynthesize the nephrographic images. Performance was assessed using Peak\nSignal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Mean Absolute\nError (MAE), and Fr\\'{e}chet Video Distance (FVD). Qualitative evaluation by\ntwo fellowship-trained abdominal radiologists was performed. Results: The\nsynthetic nephrographic images generated by our proposed approach achieved high\nPSNR (26.3 $\\pm$ 4.4 dB), SSIM (0.84 $\\pm$ 0.069), MAE (12.74 $\\pm$ 5.22 HU),\nand FVD (1323). Two radiologists provided average scores of 3.5 for real images\nand 3.4 for synthetic images (P-value = 0.5) on a Likert scale of 1-5,\nindicating that our synthetic images closely resemble real images. Conclusion:\nThe proposed approach effectively synthesizes high-quality 3D nephrographic\nphase images. This model can be used to reduce radiation dose in CTU by 33.3\\%\nwithout compromising image quality, which thereby enhances the safety and\ndiagnostic utility of CT urography.",
      "tldr_zh": "这篇论文开发了一种基于扩散模型和 Swin Transformer 的深度学习方法，用于合成 CT Urography 中的 3D 肾图阶段图像，旨在减少辐射暴露。研究使用 327 例患者的三阶段 CTU 数据进行训练和仿射注册，评估指标包括 PSNR (26.3 ± 4.4 dB)、SSIM (0.84 ± 0.069)、MAE (12.74 ± 5.22 HU) 和 FVD (1323)，结果显示合成图像质量高且与真实图像高度相似。最终，该方法可将辐射剂量降低 33.3%，而不影响图像质量，从而提升 CTU 的安全性和诊断价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.19623v1",
      "published_date": "2025-02-26 23:22:31 UTC",
      "updated_date": "2025-02-26 23:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:02:41.596188"
    },
    {
      "arxiv_id": "2502.19622v2",
      "title": "Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning",
      "title_zh": "较弱的LLMs的意见也很重要：意见混合增强LLM的数学推理",
      "authors": [
        "Yanan Chen",
        "Ali Pesaranghader",
        "Tanmana Sadhu"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have raised interest in their\nformal reasoning capabilities, particularly in mathematics. While closed LLMs\nlike GPT-4 perform well on mathematical benchmarks, e.g., GSM8K, it remains\nunclear whether small to medium-sized open LLMs can achieve similar\nperformance, questioning their reliability. To close this gap, we propose a\npost-training approach leveraging a mixture of opinions (MoO) from weaker\nancillary LLMs to enhance a (relatively) stronger LLM's reasoning. For that,\neach post-training sample is augmented with Chain-of-Thought (CoT) reasoning\nsteps and answers from ancillary LLMs, enabling the main LLM to learn from\ndiverse perspectives. We compare MoO with standard supervised fine-tuning\n(SFT), few-shot prompting, and the Mixture of Agents (MoA) method on\nmathematical reasoning benchmarks. Our results show that incorporating weaker\nLLMs' opinions improves mathematical reasoning by an average of 5%,\nhighlighting the value of diverse perspectives in reasoning tasks.",
      "tldr_zh": "该研究针对小型开放LLMs在数学推理任务中的可靠性问题，提出了一种后训练方法Mixture of Opinions (MoO)，利用较弱辅助LLMs的意见来增强较强LLMs的性能。\n具体而言，该方法在每个后训练样本中添加辅助LLMs的Chain-of-Thought (CoT)推理步骤和答案，帮助主LLMs从多样视角学习。\n实验结果显示，MoO与标准监督微调(SFT)、少样本提示和Mixture of Agents (MoA)方法相比，平均提高了5%的数学推理准确率，证明了融入弱LLMs意见的价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 1 figure, 3 tables, 4 prompt/data templates",
      "pdf_url": "http://arxiv.org/pdf/2502.19622v2",
      "published_date": "2025-02-26 23:22:02 UTC",
      "updated_date": "2025-03-05 05:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:02:53.177024"
    },
    {
      "arxiv_id": "2502.19614v1",
      "title": "Is Your Paper Being Reviewed by an LLM? A New Benchmark Dataset and Approach for Detecting AI Text in Peer Review",
      "title_zh": "翻译失败",
      "authors": [
        "Sungduk Yu",
        "Man Luo",
        "Avinash Madusu",
        "Vasudev Lal",
        "Phillip Howard"
      ],
      "abstract": "Peer review is a critical process for ensuring the integrity of published\nscientific research. Confidence in this process is predicated on the assumption\nthat experts in the relevant domain give careful consideration to the merits of\nmanuscripts which are submitted for publication. With the recent rapid\nadvancements in large language models (LLMs), a new risk to the peer review\nprocess is that negligent reviewers will rely on LLMs to perform the often time\nconsuming process of reviewing a paper. However, there is a lack of existing\nresources for benchmarking the detectability of AI text in the domain of peer\nreview.\n  To address this deficiency, we introduce a comprehensive dataset containing a\ntotal of 788,984 AI-written peer reviews paired with corresponding human\nreviews, covering 8 years of papers submitted to each of two leading AI\nresearch conferences (ICLR and NeurIPS). We use this new resource to evaluate\nthe ability of 18 existing AI text detection algorithms to distinguish between\npeer reviews written by humans and different state-of-the-art LLMs. Motivated\nby the shortcomings of existing methods, we propose a new detection approach\nwhich surpasses existing methods in the identification of AI written peer\nreviews. Our work reveals the difficulty of identifying AI-generated text at\nthe individual peer review level, highlighting the urgent need for new tools\nand methods to detect this unethical use of generative AI.",
      "tldr_zh": "该研究探讨了大型语言模型(LLM)在同行评审中的滥用风险，提出一个新的基准数据集和检测方法，以识别AI生成的同行评审文本。该数据集包含788,984对AI和人类撰写的同行评审，覆盖ICLR和NeurIPS会议的8年论文，并用于评估18种现有AI text detection算法的性能。作者提出了一种新检测方法，显著优于现有方法，但结果显示在个体层面识别AI文本仍具挑战性，强调了开发新工具以防范这种不道德AI使用的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19614v1",
      "published_date": "2025-02-26 23:04:05 UTC",
      "updated_date": "2025-02-26 23:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:03:03.586161"
    },
    {
      "arxiv_id": "2502.19613v1",
      "title": "Self-rewarding correction for mathematical reasoning",
      "title_zh": "针对数学推理的自我奖励修正",
      "authors": [
        "Wei Xiong",
        "Hanning Zhang",
        "Chenlu Ye",
        "Lichang Chen",
        "Nan Jiang",
        "Tong Zhang"
      ],
      "abstract": "We study self-rewarding reasoning large language models (LLMs), which can\nsimultaneously generate step-by-step reasoning and evaluate the correctness of\ntheir outputs during the inference time-without external feedback. This\nintegrated approach allows a single model to independently guide its reasoning\nprocess, offering computational advantages for model deployment. We\nparticularly focus on the representative task of self-correction, where models\nautonomously detect errors in their responses, revise outputs, and decide when\nto terminate iterative refinement loops. To enable this, we propose a\ntwo-staged algorithmic framework for constructing self-rewarding reasoning\nmodels using only self-generated data. In the first stage, we employ sequential\nrejection sampling to synthesize long chain-of-thought trajectories that\nincorporate both self-rewarding and self-correction mechanisms. Fine-tuning\nmodels on these curated data allows them to learn the patterns of\nself-rewarding and self-correction. In the second stage, we further enhance the\nmodels' ability to assess response accuracy and refine outputs through\nreinforcement learning with rule-based signals. Experiments with Llama-3 and\nQwen-2.5 demonstrate that our approach surpasses intrinsic self-correction\ncapabilities and achieves performance comparable to systems that rely on\nexternal reward models.",
      "tldr_zh": "这篇论文研究了自-rewarding correction 机制，用于大语言模型(LLMs)在数学推理中的自校正能力，允许模型在推理过程中自主生成逐步推理并评估输出正确性，而无需外部反馈。论文提出了一种两阶段算法框架：第一阶段通过顺序拒绝采样合成包含自-rewarding 和 self-correction 机制的推理轨迹，并使用这些数据微调模型；第二阶段则通过 reinforcement learning 与基于规则的信号，进一步提升模型评估准确性和输出精炼能力。实验结果显示，在Llama-3和Qwen-2.5模型上，该方法超过了内在self-correction性能，并达到了与依赖外部奖励模型系统相当的水平。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19613v1",
      "published_date": "2025-02-26 23:01:16 UTC",
      "updated_date": "2025-02-26 23:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:03:18.098505"
    },
    {
      "arxiv_id": "2502.19610v2",
      "title": "Program Synthesis Dialog Agents for Interactive Decision-Making",
      "title_zh": "程序合成的对话代理用于交互式决策",
      "authors": [
        "Matthew Toles",
        "Nikhil Balwani",
        "Rattandeep Singh",
        "Valentina Giulia Sartori Rodriguez",
        "Zhou Yu"
      ],
      "abstract": "Many real-world eligibility problems, ranging from medical diagnosis to tax\nplanning, can be mapped to decision problems expressed in natural language,\nwherein a model must make a binary choice based on user features. Large-scale\ndomains such as legal codes or frequently updated funding opportunities render\nhuman annotation (e.g., web forms or decision trees) impractical, highlighting\nthe need for agents that can automatically assist in decision-making. Since\nrelevant information is often only known to the user, it is crucial that these\nagents ask the right questions. As agents determine when to terminate a\nconversation, they face a trade-off between accuracy and the number of\nquestions asked, a key metric for both user experience and cost. To evaluate\nthis task, we propose BeNYfits, a new benchmark for determining user\neligibility for multiple overlapping social benefits opportunities through\ninteractive decision-making. Our experiments show that current language models\nstruggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a\nReAct-style chain-of-thought. To address this, we introduce ProADA, a novel\napproach that leverages program synthesis to assist in decision-making by\nmapping dialog planning to a code generation problem and using gaps in\nstructured data to determine the best next action. Our agent, ProADA, improves\nthe F1 score to 55.6 while maintaining nearly the same number of dialog turns.",
      "tldr_zh": "该论文探讨了使用程序合成（Program Synthesis）来构建对话代理（Dialog Agents），以辅助交互式决策问题，如医疗诊断或税务规划，这些问题需基于用户特征做出二元选择。作者引入了BeNYfits基准，用于评估用户在多重社会福利机会中的资格确定，并发现现有语言模型（如GPT-4o）因幻觉问题而在ReAct-style chain-of-thought下仅达到35.7 F1分数。针对此，论文提出ProADA方法，将对话规划映射为代码生成问题，并利用结构化数据中的空白来优化下一步行动，从而将F1分数提升至55.6，同时保持对话轮数基本不变。该方法为自动化决策代理提供了更准确且高效的框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19610v2",
      "published_date": "2025-02-26 22:53:01 UTC",
      "updated_date": "2025-03-17 18:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:03:28.170096"
    },
    {
      "arxiv_id": "2503.01885v1",
      "title": "Learning Policy Committees for Effective Personalization in MDPs with Diverse Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Luise Ge",
        "Michael Lanier",
        "Anindya Sarkar",
        "Bengisu Guresti",
        "Yevgeniy Vorobeychik",
        "Chongjie Zhang"
      ],
      "abstract": "Many dynamic decision problems, such as robotic control, involve a series of\ntasks, many of which are unknown at training time. Typical approaches for these\nproblems, such as multi-task and meta reinforcement learning, do not generalize\nwell when the tasks are diverse. On the other hand, approaches that aim to\ntackle task diversity, such as using task embedding as policy context and task\nclustering, typically lack performance guarantees and require a large number of\ntraining tasks. To address these challenges, we propose a novel approach for\nlearning a policy committee that includes at least one near-optimal policy with\nhigh probability for tasks encountered during execution. While we show that\nthis problem is in general inapproximable, we present two practical algorithmic\nsolutions. The first yields provable approximation and task sample complexity\nguarantees when tasks are low-dimensional (the best we can do due to\ninapproximability), whereas the second is a general and practical\ngradient-based approach. In addition, we provide a provable sample complexity\nbound for few-shot learning. Our experiments on MuJoCo and Meta-World show that\nthe proposed approach outperforms state-of-the-art multi-task, meta-, and task\nclustering baselines in training, generalization, and few-shot learning, often\nby a large margin.",
      "tldr_zh": "该论文针对马尔可夫决策过程(MDPs)中任务多样化的动态决策问题（如机器人控制），提出了一种学习策略委员会(policy committees)的方法，以高概率包含至少一个近优策略，从而实现有效的个性化策略。论文证明该问题在一般情况下不可近似解，并提供了两个实际算法：一个在任务低维时给出可证明的近似和样本复杂度保证，另一个是通用的基于梯度的实用方法，同时还为少样本学习(few-shot learning)提供了样本复杂度界。在 MuJoCo 和 Meta-World 的实验中，该方法在训练、泛化和少样本学习方面显著优于多任务强化学习(multi-task reinforcement learning)、元强化学习(meta reinforcement learning)和任务聚类基线，往往提升幅度较大。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01885v1",
      "published_date": "2025-02-26 22:45:25 UTC",
      "updated_date": "2025-02-26 22:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:03:41.656933"
    },
    {
      "arxiv_id": "2503.01884v1",
      "title": "Contextual Quantum Neural Networks for Stock Price Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sharan Mourya",
        "Hannes Leipold",
        "Bibhas Adhikari"
      ],
      "abstract": "In this paper, we apply quantum machine learning (QML) to predict the stock\nprices of multiple assets using a contextual quantum neural network. Our\napproach captures recent trends to predict future stock price distributions,\nmoving beyond traditional models that focus on entire historical data,\nenhancing adaptability and precision. Utilizing the principles of quantum\nsuperposition, we introduce a new training technique called the quantum batch\ngradient update (QBGU), which accelerates the standard stochastic gradient\ndescent (SGD) in quantum applications and improves convergence. Consequently,\nwe propose a quantum multi-task learning (QMTL) architecture, specifically, the\nshare-and-specify ansatz, that integrates task-specific operators controlled by\nquantum labels, enabling the simultaneous and efficient training of multiple\nassets on the same quantum circuit as well as enabling efficient portfolio\nrepresentation with logarithmic overhead in the number of qubits. This\narchitecture represents the first of its kind in quantum finance, offering\nsuperior predictive power and computational efficiency for multi-asset stock\nprice forecasting. Through extensive experimentation on S\\&P 500 data for\nApple, Google, Microsoft, and Amazon stocks, we demonstrate that our approach\nnot only outperforms quantum single-task learning (QSTL) models but also\neffectively captures inter-asset correlations, leading to enhanced prediction\naccuracy. Our findings highlight the transformative potential of QML in\nfinancial applications, paving the way for more advanced, resource-efficient\nquantum algorithms in stock price prediction and other complex financial\nmodeling tasks.",
      "tldr_zh": "本论文提出了一种基于量子机器学习 (QML) 的上下文量子神经网络 (contextual quantum neural network)，用于预测多个资产的股票价格，通过捕捉最近趋势而非整个历史数据，提高了模型的适应性和精确性。作者引入了量子批量梯度更新 (QBGU) 技术来加速标准随机梯度下降 (SGD) 的收敛，并开发了量子多任务学习 (QMTL) 架构的 share-and-specify ansatz，该架构允许在同一量子电路上高效训练多个资产，并以对数开销表示投资组合。实验结果显示，在 S&P 500 数据上，该方法优于量子单任务学习 (QSTL) 模型，能有效捕捉资产间相关性，并提升预测准确性，突显了 QML 在金融领域的变革潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01884v1",
      "published_date": "2025-02-26 22:39:23 UTC",
      "updated_date": "2025-02-26 22:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:03:53.411164"
    },
    {
      "arxiv_id": "2503.01883v1",
      "title": "Learning Surrogates for Offline Black-Box Optimization via Gradient Matching",
      "title_zh": "通过梯度匹配学习离线黑箱优化的代理模型",
      "authors": [
        "Minh Hoang",
        "Azza Fadhel",
        "Aryan Deshwal",
        "Janardhan Rao Doppa",
        "Trong Nghia Hoang"
      ],
      "abstract": "Offline design optimization problem arises in numerous science and\nengineering applications including material and chemical design, where\nexpensive online experimentation necessitates the use of in silico surrogate\nfunctions to predict and maximize the target objective over candidate designs.\nAlthough these surrogates can be learned from offline data, their predictions\nare often inaccurate outside the offline data regime. This challenge raises a\nfundamental question about the impact of imperfect surrogate model on the\nperformance gap between its optima and the true optima, and to what extent the\nperformance loss can be mitigated. Although prior work developed methods to\nimprove the robustness of surrogate models and their associated optimization\nprocesses, a provably quantifiable relationship between an imperfect surrogate\nand the corresponding performance gap, as well as whether prior methods\ndirectly address it, remain elusive. To shed light on this important question,\nwe present a theoretical framework to understand offline black-box\noptimization, by explicitly bounding the optimization quality based on how well\nthe surrogate matches the latent gradient field that underlines the offline\ndata. Inspired by our theoretical analysis, we propose a principled black-box\ngradient matching algorithm to create effective surrogate models for offline\noptimization, improving over prior approaches on various real-world benchmarks.",
      "tldr_zh": "该研究探讨了离线黑箱优化(Offline Black-Box Optimization)问题，特别是在材料和化学设计等领域，使用代理模型(surrogates)从离线数据预测并最大化目标函数，但这些模型在数据外预测往往不准确，导致性能差距。作者提出一个理论框架，通过量化代理模型与潜在梯度场(gradient field)的匹配度，来明确界定这种不完美模型对优化质量的影响。基于此，他们开发了黑箱梯度匹配(Gradient Matching)算法，用于构建更有效的代理模型，并在各种真实基准上优于现有方法，显著降低了性能损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01883v1",
      "published_date": "2025-02-26 22:35:54 UTC",
      "updated_date": "2025-02-26 22:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:04:04.119508"
    },
    {
      "arxiv_id": "2502.19596v2",
      "title": "Trustworthy Answers, Messier Data: Bridging the Gap in Low-Resource Retrieval-Augmented Generation for Domain Expert Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Nayoung Choi",
        "Grace Byun",
        "Andrew Chung",
        "Ellie S. Paek",
        "Shinsun Lee",
        "Jinho D. Choi"
      ],
      "abstract": "RAG has become a key technique for enhancing LLMs by reducing hallucinations,\nespecially in domain expert systems where LLMs may lack sufficient inherent\nknowledge. However, developing these systems in low-resource settings\nintroduces several challenges: (1) handling heterogeneous data sources, (2)\noptimizing retrieval phase for trustworthy answers, and (3) evaluating\ngenerated answers across diverse aspects. To address these, we introduce a data\ngeneration pipeline that transforms raw multi-modal data into structured corpus\nand Q&A pairs, an advanced re-ranking phase improving retrieval precision, and\na reference matching algorithm enhancing answer traceability. Applied to the\nautomotive engineering domain, our system improves factual correctness (+1.94),\ninformativeness (+1.16), and helpfulness (+1.67) over a non-RAG baseline, based\non a 1-5 scale by an LLM judge. These results highlight the effectiveness of\nour approach across distinct aspects, with strong answer grounding and\ntransparency.",
      "tldr_zh": "这篇论文探讨了在低资源环境下使用 Retrieval-Augmented Generation (RAG) 增强 Large Language Models (LLMs) 的挑战，特别是处理异构数据源、优化检索以获得可信答案，以及评估生成的答案。研究团队引入了一个数据生成管道，将原始多模态数据转化为结构化语料和 Q&A 对；结合先进的再排名阶段和参考匹配算法，以提高检索精度和答案可追溯性。在汽车工程领域应用后，该系统相较非 RAG 基线，显著提升了事实正确性 (+1.94)、信息性 (+1.16) 和帮助性 (+1.67)，基于 1-5 规模的 LLM 判断，突显了其在答案 grounding 和透明度方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19596v2",
      "published_date": "2025-02-26 22:20:08 UTC",
      "updated_date": "2025-04-14 20:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:04:17.154376"
    },
    {
      "arxiv_id": "2502.19593v1",
      "title": "Improving Representation Learning of Complex Critical Care Data with ICU-BERT",
      "title_zh": "使用 ICU-BERT 改善复杂重症监护数据的表示学习",
      "authors": [
        "Ricardo Santos",
        "André V. Carreiro",
        "Xi Peng",
        "Hugo Gamboa",
        "Holger Fröhlich"
      ],
      "abstract": "The multivariate, asynchronous nature of real-world clinical data, such as\nthat generated in Intensive Care Units (ICUs), challenges traditional AI-based\ndecision-support systems. These often assume data regularity and feature\nindependence and frequently rely on limited data scopes and manual feature\nengineering. The potential of generative AI technologies has not yet been fully\nexploited to analyze clinical data. We introduce ICU-BERT, a transformer-based\nmodel pre-trained on the MIMIC-IV database using a multi-task scheme to learn\nrobust representations of complex ICU data with minimal preprocessing. ICU-BERT\nemploys a multi-token input strategy, incorporating dense embeddings from a\nbiomedical Large Language Model to learn a generalizable representation of\ncomplex and multivariate ICU data. With an initial evaluation of five tasks and\nfour additional ICU datasets, ICU-BERT results indicate that ICU-BERT either\ncompares to or surpasses current performance benchmarks by leveraging\nfine-tuning. By integrating structured and unstructured data, ICU-BERT advances\nthe use of foundational models in medical informatics, offering an adaptable\nsolution for clinical decision support across diverse applications.",
      "tldr_zh": "该研究针对重症监护室(ICU)数据的多变量和异步特性，提出ICU-BERT，一种基于Transformer的模型，通过在MIMIC-IV数据库上使用多任务方案进行预训练，以最小化预处理并学习鲁棒的表示。ICU-BERT采用多token输入策略，结合生物医学大语言模型的密集嵌入，实现了对复杂ICU数据的泛化表示。实验结果显示，在五个任务和四个额外ICU数据集上，ICU-BERT通过微调表现优于或等同于现有基准，并通过整合结构化和非结构化数据，推进了基础模型在医疗信息学中的应用，提供适应性的临床决策支持解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for poster at GenAI4Health Workshop at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19593v1",
      "published_date": "2025-02-26 22:16:58 UTC",
      "updated_date": "2025-02-26 22:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:04:28.419811"
    },
    {
      "arxiv_id": "2503.01881v1",
      "title": "Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Pio Ricciardi",
        "Valentino Maiorca",
        "Luca Moschella",
        "Riccardo Marin",
        "Emanuele Rodolà"
      ],
      "abstract": "Deep Reinforcement Learning (RL) models often fail to generalize when even\nsmall changes occur in the environment's observations or task requirements.\nAddressing these shifts typically requires costly retraining, limiting the\nreusability of learned policies. In this paper, we build on recent work in\nsemantic alignment to propose a zero-shot method for mapping between latent\nspaces across different agents trained on different visual and task variations.\nSpecifically, we learn a transformation that maps embeddings from one agent's\nencoder to another agent's encoder without further fine-tuning. Our approach\nrelies on a small set of \"anchor\" observations that are semantically aligned,\nwhich we use to estimate an affine or orthogonal transform. Once the\ntransformation is found, an existing controller trained for one domain can\ninterpret embeddings from a different (existing) encoder in a zero-shot\nfashion, skipping additional trainings. We empirically demonstrate that our\nframework preserves high performance under visual and task domain shifts. We\nempirically demonstrate zero-shot stitching performance on the CarRacing\nenvironment with changing background and task. By allowing modular re-assembly\nof existing policies, it paves the way for more robust, compositional RL in\ndynamically changing environments.",
      "tldr_zh": "这篇论文针对深度 Reinforcement Learning (RL) 模型在环境观察或任务要求微小变化时泛化能力不足的问题，提出了一种基于语义对齐的零样本方法，用于映射不同代理之间的潜在空间。方法通过一小套语义对齐的“锚点”观察来估计仿射或正交变换，从而实现现有控制器的零样本缝合（Zero-Shot Stitching），无需额外微调。实验在 CarRacing 环境中验证了该框架在视觉和任务领域变化下的高性能，为构建更鲁棒、组合式的 RL 系统提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01881v1",
      "published_date": "2025-02-26 22:06:00 UTC",
      "updated_date": "2025-02-26 22:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:04:41.807757"
    },
    {
      "arxiv_id": "2502.19587v1",
      "title": "NeoBERT: A Next-Generation BERT",
      "title_zh": "NeoBERT：新一代 BERT",
      "authors": [
        "Lola Le Breton",
        "Quentin Fournier",
        "Mariam El Mezouar",
        "Sarath Chandar"
      ],
      "abstract": "Recent innovations in architecture, pre-training, and fine-tuning have led to\nthe remarkable in-context learning and reasoning abilities of large\nauto-regressive language models such as LLaMA and DeepSeek. In contrast,\nencoders like BERT and RoBERTa have not seen the same level of progress despite\nbeing foundational for many downstream NLP applications. To bridge this gap, we\nintroduce NeoBERT, a next-generation encoder that redefines the capabilities of\nbidirectional models by integrating state-of-the-art advancements in\narchitecture, modern data, and optimized pre-training methodologies. NeoBERT is\ndesigned for seamless adoption: it serves as a plug-and-play replacement for\nexisting base models, relies on an optimal depth-to-width ratio, and leverages\nan extended context length of 4,096 tokens. Despite its compact 250M parameter\nfootprint, it achieves state-of-the-art results on the massive MTEB benchmark,\noutperforming BERT large, RoBERTa large, NomicBERT, and ModernBERT under\nidentical fine-tuning conditions. In addition, we rigorously evaluate the\nimpact of each modification on GLUE and design a uniform fine-tuning and\nevaluation framework for MTEB. We release all code, data, checkpoints, and\ntraining scripts to accelerate research and real-world adoption.",
      "tldr_zh": "该研究引入了NeoBERT，一种下一代双向编码器模型，旨在通过整合先进的架构、现代数据和优化预训练方法，弥补BERT和RoBERTa等模型在进展上的差距。NeoBERT设计为即插即用模块，具有优化深度到宽度比例和4096标记的扩展上下文长度，仅需250M参数，便在MTEB基准上超越BERT large、RoBERTa large等模型。研究者还评估了各修改对GLUE基准的影响，并开源所有代码、数据、检查点和训练脚本，以推动NLP应用的研究和采用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 5 figures, 9 tables. Submitted to TMLR",
      "pdf_url": "http://arxiv.org/pdf/2502.19587v1",
      "published_date": "2025-02-26 22:00:22 UTC",
      "updated_date": "2025-02-26 22:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:04:51.778063"
    },
    {
      "arxiv_id": "2502.19577v1",
      "title": "Tell me why: Visual foundation models as self-explainable classifiers",
      "title_zh": "告诉我为什么：视觉基础模型作为自解释分类器",
      "authors": [
        "Hugues Turbé",
        "Mina Bjelogrlic",
        "Gianmarco Mengaldo",
        "Christian Lovis"
      ],
      "abstract": "Visual foundation models (VFMs) have become increasingly popular due to their\nstate-of-the-art performance. However, interpretability remains crucial for\ncritical applications. In this sense, self-explainable models (SEM) aim to\nprovide interpretable classifiers that decompose predictions into a weighted\nsum of interpretable concepts. Despite their promise, recent studies have shown\nthat these explanations often lack faithfulness. In this work, we combine VFMs\nwith a novel prototypical architecture and specialized training objectives. By\ntraining only a lightweight head (approximately 1M parameters) on top of frozen\nVFMs, our approach (ProtoFM) offers an efficient and interpretable solution.\nEvaluations demonstrate that our approach achieves competitive classification\nperformance while outperforming existing models across a range of\ninterpretability metrics derived from the literature. Code is available at\nhttps://github.com/hturbe/proto-fm.",
      "tldr_zh": "本研究探讨了视觉基础模型（VFMs）的高性能与可解释性之间的权衡问题，指出现有自解释模型（SEM）虽能将预测分解为可解释概念，但其解释往往缺乏忠实性。为此，论文提出了一种新方法ProtoFM，将VFMs与新型原型架构结合，并使用专门的训练目标，仅训练一个轻量级头部（约1M参数），以实现高效的解释性分类。实验结果显示，ProtoFM在分类性能上与现有模型竞争，同时在多种可解释性指标上表现出色，提供了一个可靠的自解释解决方案。代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T10",
        "I.2.6; I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19577v1",
      "published_date": "2025-02-26 21:40:30 UTC",
      "updated_date": "2025-02-26 21:40:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:05:04.827748"
    },
    {
      "arxiv_id": "2502.19573v1",
      "title": "Do Large Language Models Know How Much They Know?",
      "title_zh": "大语言模型知道它们知道多少吗？",
      "authors": [
        "Gabriele Prato",
        "Jerry Huang",
        "Prasannna Parthasarathi",
        "Shagun Sodhani",
        "Sarath Chandar"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as highly capable systems and are\nincreasingly being integrated into various uses. However, the rapid pace of\ntheir deployment has outpaced a comprehensive understanding of their internal\nmechanisms and a delineation of their capabilities and limitations. A desired\nattribute of an intelligent system is its ability to recognize the scope of its\nown knowledge. To investigate whether LLMs embody this characteristic, we\ndevelop a benchmark designed to challenge these models to enumerate all\ninformation they possess on specific topics. This benchmark evaluates whether\nthe models recall excessive, insufficient, or the precise amount of\ninformation, thereby indicating their awareness of their own knowledge. Our\nfindings reveal that all tested LLMs, given sufficient scale, demonstrate an\nunderstanding of how much they know about specific topics. While different\narchitectures exhibit varying rates of this capability's emergence, the results\nsuggest that awareness of knowledge may be a generalizable attribute of LLMs.\nFurther research is needed to confirm this potential and fully elucidate the\nunderlying mechanisms.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否能认识到自身知识的范围，针对其快速部署与能力理解的脱节问题。研究者开发了一个基准测试，要求模型枚举特定主题的所有信息，以评估其是否回忆过多、过少或精确的信息，从而衡量知识意识。结果显示，规模足够的 LLMs 能够理解自己关于主题的知识量，不同架构模型在这一能力上的出现率有所差异。这些发现表明，知识意识可能是一种 LLMs 的可泛化属性，但需要进一步研究来确认其机制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19573v1",
      "published_date": "2025-02-26 21:33:06 UTC",
      "updated_date": "2025-02-26 21:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:05:17.026287"
    },
    {
      "arxiv_id": "2502.19567v2",
      "title": "Atlas: A Framework for ML Lifecycle Provenance & Transparency",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Spoczynski",
        "Marcela S. Melara",
        "Sebastian Szyller"
      ],
      "abstract": "The rapid adoption of open source machine learning (ML) datasets and models\nexposes today's AI applications to critical risks like data poisoning and\nsupply chain attacks across the ML lifecycle. With growing regulatory pressure\nto address these issues through greater transparency, ML model vendors face\nchallenges balancing these requirements against confidentiality for data and\nintellectual property needs. We propose Atlas, a framework that enables fully\nattestable ML pipelines. Atlas leverages open specifications for data and\nsoftware supply chain provenance to collect verifiable records of model\nartifact authenticity and end-to-end lineage metadata. Atlas combines trusted\nhardware and transparency logs to enhance metadata integrity, preserve data\nconfidentiality, and limit unauthorized access during ML pipeline operations,\nfrom training through deployment. Our prototype implementation of Atlas\nintegrates several open-source tools to build an ML lifecycle transparency\nsystem, and assess the practicality of Atlas through two case study ML\npipelines.",
      "tldr_zh": "该论文提出 Atlas 框架，以解决机器学习(ML)生命周期中数据 poisoning 和 supply chain attacks 等风险，同时平衡透明度要求与数据及知识产权的保密性。Atlas 利用开源规范收集模型工件的真实性和端到端 lineage 元数据，并结合 trusted hardware 和 transparency logs 来增强元数据完整性、保护机密信息并限制未授权访问。原型实现整合了多种开源工具，并通过两个案例研究验证了 Atlas 在 ML pipelines 从训练到部署的全过程中的实用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19567v2",
      "published_date": "2025-02-26 21:18:03 UTC",
      "updated_date": "2025-05-14 22:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:05:29.132031"
    },
    {
      "arxiv_id": "2503.05783v1",
      "title": "Knowledge representation and scalable abstract reasoning for simulated democracy in Unity",
      "title_zh": "翻译失败",
      "authors": [
        "Eleftheria Katsiri",
        "Alexandros Gazis",
        "Angelos Protopapas"
      ],
      "abstract": "We present a novel form of scalable knowledge representation about agents in\na simulated democracy, e-polis, where real users respond to social challenges\nassociated with democratic institutions, structured as Smart Spatial Types, a\nnew type of Smart Building that changes architectural form according to the\nphilosophical doctrine of a visitor. At the end of the game players vote on the\nSmart City that results from their collective choices. Our approach uses\ndeductive systems in an unusual way: by integrating a model of democracy with a\nmodel of a Smart City we are able to prove quality aspects of the simulated\ndemocracy in different urban and social settings, while adding ease and\nflexibility to the development. Second, we can infer and reason with abstract\nknowledge, which is a limitation of the Unity platform; third, our system\nenables real-time decision-making and adaptation of the game flow based on the\nplayer's abstract state, paving the road to explainability. Scalability is\nachieved by maintaining a dual-layer knowledge representation mechanism for\nreasoning about the simulated democracy that functions in a similar way to a\ntwo-level cache. The lower layer knows about the current state of the game by\ncontinually processing a high rate of events produced by the in-built physics\nengine of the Unity platform, e.g., it knows of the position of a player in\nspace, in terms of his coordinates x,y,z as well as their choices for each\nchallenge. The higher layer knows of easily-retrievable, user-defined abstract\nknowledge about current and historical states, e.g., it knows of the political\ndoctrine of a Smart Spatial Type, a player's philosophical doctrine, and the\ncollective philosophical doctrine of a community players with respect to\ncurrent social issues.",
      "tldr_zh": "本文提出了一种可扩展的知识表示方法，用于在 Unity 平台上模拟民主系统 e-polis，用户通过响应社会挑战并投票决定智能城市（Smart Spatial Types）的形式。系统利用 deductive systems 整合民主模型和智能城市模型，实现对抽象知识的推理和证明模拟民主的质量，同时支持实时决策和游戏流程适应。双层知识表示机制（类似于两级缓存）确保了可扩展性，底层处理游戏当前状态如玩家位置，高层管理用户定义的抽象知识如哲学教义，从而提升了系统的灵活性和解释性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY",
        "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
      ],
      "primary_category": "cs.MA",
      "comment": "23 pages, 11 figures, 76 references. This article is under review at\n  WSEAS Transactions on Information Science and Applications from 02.2025",
      "pdf_url": "http://arxiv.org/pdf/2503.05783v1",
      "published_date": "2025-02-26 21:03:02 UTC",
      "updated_date": "2025-02-26 21:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:05:40.563382"
    },
    {
      "arxiv_id": "2503.00058v1",
      "title": "African Gender Classification Using Clothing Identification Via Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Ozechi"
      ],
      "abstract": "Human attribute identification and classification are crucial in computer\nvision, driving the development of innovative recognition systems. Traditional\ngender classification methods primarily rely on facial recognition, which,\nwhile effective, struggles under non-ideal conditions such as blurriness, side\nviews, or partial occlusions. This study explores an alternative approach by\nleveraging clothing identification, specifically focusing on African\ntraditional attire, which carries culturally significant and gender-specific\nfeatures.\n  We use the AFRIFASHION1600 dataset, a curated collection of 1,600 images of\nAfrican traditional clothing labeled into two gender classes: male and female.\nA deep learning model, based on a modified VGG16 architecture and trained using\ntransfer learning, was developed for classification. Data augmentation was\napplied to address the challenges posed by the relatively small dataset and to\nmitigate overfitting. The model achieved an accuracy of 87% on the test set,\ndemonstrating strong predictive capability despite dataset imbalances favoring\nfemale samples.\n  These findings highlight the potential of clothing-based identification as a\ncomplementary technique to facial recognition for gender classification in\nAfrican contexts. Future research should focus on expanding and balancing\ndatasets to enhance classification robustness and improve the applicability of\nclothing-based gender recognition systems.",
      "tldr_zh": "本研究探讨了基于服装识别的性别分类方法，以克服传统面部识别在模糊、侧视图或部分遮挡等非理想条件下表现不佳的问题，特别聚焦于非洲传统服饰的文化和性别特征。研究利用AFRIFASHION1600数据集（包含1600张标记为男性和女性的非洲服装图像），开发了一个基于修改VGG16架构的深度学习模型，并通过transfer learning和data augmentation技术来处理小数据集和overfitting问题。模型在测试集上达到了87%的准确率，证明了服装识别作为面部识别补充方法的有效性。尽管数据集存在不平衡问题，研究强调未来应扩展和平衡数据集以提升分类系统的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "8T07 (Primary), 68T01 (Secondary)"
      ],
      "primary_category": "cs.CV",
      "comment": "3 Pages, 10 Figures",
      "pdf_url": "http://arxiv.org/pdf/2503.00058v1",
      "published_date": "2025-02-26 20:59:59 UTC",
      "updated_date": "2025-02-26 20:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:05:52.794117"
    },
    {
      "arxiv_id": "2502.19557v1",
      "title": "Distill Not Only Data but Also Rewards: Can Smaller Language Models Surpass Larger Ones?",
      "title_zh": "翻译失败",
      "authors": [
        "Yudi Zhang",
        "Lu Wang",
        "Meng Fang",
        "Yali Du",
        "Chenghua Huang",
        "Jun Wang",
        "Qingwei Lin",
        "Mykola Pechenizkiy",
        "Dongmei Zhang",
        "Saravan Rajmohan",
        "Qi Zhang"
      ],
      "abstract": "Distilling large language models (LLMs) typically involves transferring the\nteacher model's responses through supervised fine-tuning (SFT). However, this\napproach neglects the potential to distill both data (output content) and\nreward signals (quality evaluations). Extracting reliable reward signals\ndirectly from teacher models is challenging, as LLMs are optimized for\ngeneration rather than evaluation, often resulting in biased or inconsistent\nassessments. To address this limitation, we propose a novel distillation\npipeline that transfers both responses and rewards. Our method generates\npseudo-rewards through a self-supervised mechanism that leverages the inherent\nstructure of both teacher and student responses, enabling reward learning\nwithout explicit external evaluation. The reward model subsequently guides\nreinforcement learning (RL), allowing iterative refinement of the student model\nafter an SFT warm-up phase. Experiments on GSM8K and MMLU-PRO demonstrate that\nour method consistently outperforms traditional SFT-based approaches, enabling\nstudent models to surpass the performance of their teachers. This work\nhighlights the potential for scalable, efficient distillation through\nstructured self-supervised reward learning, reducing dependence on external\nreward supervision.",
      "tldr_zh": "该研究提出了一种新型的蒸馏管道，不仅转移大型语言模型(LLMs)的响应数据，还包括奖励信号，以帮助小型语言模型(Student models)超越教师模型。方法通过自监督机制生成伪奖励，利用教师和学生响应的结构，避免依赖外部评估，然后结合监督微调(SFT)预热阶段和强化学习(RL)进行迭代优化。实验在GSM8K和MMLU-PRO数据集上显示，这种方法使学生模型在性能上 consistently 超越教师模型，突显了通过结构化自监督奖励学习实现高效、可扩展蒸馏的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19557v1",
      "published_date": "2025-02-26 20:50:11 UTC",
      "updated_date": "2025-02-26 20:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:06:04.300130"
    },
    {
      "arxiv_id": "2502.19546v3",
      "title": "Repurposing the scientific literature with vision-language models",
      "title_zh": "使用视觉语言模型重新利用科学文献",
      "authors": [
        "Anton Alyakin",
        "Jaden Stryker",
        "Daniel Alexander Alber",
        "Karl L. Sangwon",
        "Jin Vivian Lee",
        "Brandon Duderstadt",
        "Akshay Save",
        "David Kurland",
        "Spencer Frome",
        "Shrutika Singh",
        "Jeff Zhang",
        "Eunice Yang",
        "Ki Yun Park",
        "Cordelia Orillac",
        "Aly A. Valliani",
        "Sean Neifert",
        "Albert Liu",
        "Aneek Patel",
        "Christopher Livia",
        "Darryl Lau",
        "Ilya Laufer",
        "Peter A. Rozman",
        "Eveline Teresa Hidalgo",
        "Howard Riina",
        "Rui Feng",
        "Todd Hollon",
        "Yindalon Aphinyanaphongs",
        "John G. Golfinos",
        "Laura Snyder",
        "Eric Leuthardt",
        "Douglas Kondziolka",
        "Eric Karl Oermann"
      ],
      "abstract": "Leading vision-language models (VLMs) are trained on general Internet\ncontent, overlooking scientific journals' rich, domain-specific knowledge.\nTraining on specialty-specific literature could yield high-performance,\ntask-specific tools, enabling generative AI to match generalist models in\nspecialty publishing, educational, and clinical tasks. We created NeuroPubs, a\nmultimodal dataset of 23,000 Neurosurgery Publications articles (134M words,\n78K image-caption pairs). Using NeuroPubs, VLMs generated publication-ready\ngraphical abstracts (70% of 100 abstracts) and board-style questions\nindistinguishable from human-written ones (54% of 89,587 questions). We used\nthese questions to train CNS-Obsidian, a 34B-parameter VLM. In a blinded,\nrandomized controlled trial, our model demonstrated non-inferiority to then\nstate-of-the-art GPT-4o in neurosurgical differential diagnosis (clinical\nutility, 40.62% upvotes vs. 57.89%, p=0.1150; accuracy, 59.38% vs. 65.79%,\np=0.3797). Our pilot study demonstrates how training generative AI models on\nspecialty-specific journal content - without large-scale internet data -\nresults in high-performance academic and clinical tools, enabling\ndomain-tailored AI across diverse fields.",
      "tldr_zh": "该研究探讨了如何利用视觉语言模型（VLMs）重新利用科学文献，解决现有模型忽略领域特定知识的问题。通过创建 NeuroPubs 数据集（包含23,000篇神经外科文章、134M单词和78K图像-标题对），研究者训练模型生成出版级图形摘要（70%的100个摘要达标）和高质量板式问题（54%的89,587个问题与人类水平相当）。他们开发了34B参数的CNS-Obsidian模型，并在盲随机对照试验中证明其在神经外科鉴别诊断中与GPT-4o非劣效（临床实用性40.62% vs. 57.89%，准确率59.38% vs. 65.79%）。这项试点工作展示了在领域特定期刊内容上训练生成AI模型（无需大规模互联网数据）即可创建高性能的学术和临床工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19546v3",
      "published_date": "2025-02-26 20:35:37 UTC",
      "updated_date": "2025-04-28 00:52:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:06:18.143154"
    },
    {
      "arxiv_id": "2502.19545v1",
      "title": "Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in QA Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ashley Lewis",
        "Michael White",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "abstract": "The deployment of Large Language Models (LLMs) in customer support is\nconstrained by hallucination-generating false information-and the high cost of\nproprietary models. To address these challenges, we propose a\nretrieval-augmented question-answering (QA) pipeline and explore how to balance\nhuman input and automation. Using a dataset of questions about a Samsung Smart\nTV user manual, we demonstrate that synthetic data generated by LLMs\noutperforms crowdsourced data in reducing hallucination in finetuned models. We\nalso compare self-training (fine-tuning models on their own outputs) and\nknowledge distillation (fine-tuning on stronger models' outputs, e.g., GPT-4o),\nand find that self-training achieves comparable hallucination reduction. We\nconjecture that this surprising finding can be attributed to increased exposure\nbias issues in the knowledge distillation case and support this conjecture with\npost hoc analysis. We also improve robustness to unanswerable questions and\nretrieval failures with contextualized \"I don't know\" responses. These findings\nshow that scalable, cost-efficient QA systems can be built using synthetic data\nand self-training with open-source models, reducing reliance on proprietary\ntools or costly human annotations.",
      "tldr_zh": "本文探讨了使用小型模型减少 QA 代理中 hallucination 的方法，提出一个 retrieval-augmented question-answering (QA) 管道，并比较了 knowledge distillation（基于更强模型如 GPT-4o 的输出 fine-tuning）和 self-training（模型在自身输出上 fine-tuning）。研究利用 Samsung Smart TV 用户手册数据集发现，LLMs 生成的 synthetic data 在减少 hallucination 方面优于 crowdsourced data，且 self-training 能实现与 knowledge distillation 相当的效果，可能归因于后者存在的 exposure bias。最终，实验证明这种方法能提升对 unanswerable questions 和 retrieval failures 的鲁棒性，并支持构建基于开源模型的、可扩展且成本高效的 QA 系统，减少对 proprietary tools 和 human annotations 的依赖。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19545v1",
      "published_date": "2025-02-26 20:34:58 UTC",
      "updated_date": "2025-02-26 20:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:06:29.803565"
    },
    {
      "arxiv_id": "2502.19537v3",
      "title": "No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Kazdan",
        "Lisa Yu",
        "Rylan Schaeffer",
        "Chris Cundy",
        "Sanmi Koyejo",
        "Krishnamurthy Dvijotham"
      ],
      "abstract": "Leading language model (LM) providers like OpenAI and Google offer\nfine-tuning APIs that allow customers to adapt LMs for specific use cases. To\nprevent misuse, these LM providers implement filtering mechanisms to block\nharmful fine-tuning data. Consequently, adversaries seeking to produce unsafe\nLMs via these APIs must craft adversarial training data that are not\nidentifiably harmful. We make three contributions in this context: 1. We show\nthat many existing attacks that use harmless data to create unsafe LMs rely on\neliminating model refusals in the first few tokens of their responses. 2. We\nshow that such prior attacks can be blocked by a simple defense that pre-fills\nthe first few tokens from an aligned model before letting the fine-tuned model\nfill in the rest. 3. We describe a new data-poisoning attack, ``No, Of course I\nCan Execute'' (NOICE), which exploits an LM's formulaic refusal mechanism to\nelicit harmful responses. By training an LM to refuse benign requests on the\nbasis of safety before fulfilling those requests regardless, we are able to\njailbreak several open-source models and a closed-source model (GPT-4o). We\nshow an attack success rate (ASR) of 57% against GPT-4o; our attack earned a\nBug Bounty from OpenAI. Against open-source models protected by simple\ndefenses, we improve ASRs by an average of 3.25 times compared to the best\nperforming previous attacks that use only harmless data. NOICE demonstrates the\nexploitability of repetitive refusal mechanisms and broadens understanding of\nthe threats closed-source models face from harmless data.",
      "tldr_zh": "该研究揭示了语言模型（LM）的拒绝机制在 fine-tuning 过程中可能被利用的问题，攻击者使用无害数据来创建不安全的模型。论文的主要贡献包括：1）分析现有攻击依赖于消除模型响应开头几 tokens 的拒绝；2）提出一种简单防御，通过预填充开头 tokens 来自基线模型来阻挡这些攻击；3）引入新攻击 NOICE（No, Of course I Can Execute），该方法通过训练模型先对无害请求进行公式化拒绝，然后执行有害任务，从而成功 jailbreak 了 GPT-4o（ASR 57%）和多个开源模型。相比先前攻击，NOICE 在受保护模型上平均提高了 3.25 倍的攻击成功率（ASR），强调了拒绝机制的漏洞及其对封闭模型的潜在威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19537v3",
      "published_date": "2025-02-26 20:20:01 UTC",
      "updated_date": "2025-04-01 18:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:06:40.055027"
    },
    {
      "arxiv_id": "2502.19534v1",
      "title": "Retrieval Augmented Anomaly Detection (RAAD): Nimble Model Adjustment Without Retraining",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Pastoriza",
        "Iman Yousfi",
        "Christopher Redino",
        "Marc Vucovich",
        "Abdul Rahman",
        "Sal Aguinaga",
        "Dhruv Nandakumar"
      ],
      "abstract": "We propose a novel mechanism for real-time (human-in-the-loop) feedback\nfocused on false positive reduction to enhance anomaly detection models. It was\ndesigned for the lightweight deployment of a behavioral network anomaly\ndetection model. This methodology is easily integrable to similar domains that\nrequire a premium on throughput while maintaining high precision. In this\npaper, we introduce Retrieval Augmented Anomaly Detection, a novel method\ntaking inspiration from Retrieval Augmented Generation. Human annotated\nexamples are sent to a vector store, which can modify model outputs on the very\nnext processed batch for model inference. To demonstrate the generalization of\nthis technique, we benchmarked several different model architectures and\nmultiple data modalities, including images, text, and graph-based data.",
      "tldr_zh": "本论文提出了 Retrieval Augmented Anomaly Detection (RAAD)，一种无需重新训练即可通过人类反馈实时减少假阳性的异常检测机制，适用于轻量级网络行为模型及其类似领域。该方法借鉴 Retrieval Augmented Generation (RAG)，将人类标注的例子存储在向量存储中，从而在下一个处理批次立即修改模型输出。实验结果显示，RAAD 在多种模型架构和数据模态（如图像、文本和图-based 数据）上表现出良好的泛化能力，确保了高吞吐量和高精度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures. 2 tables, accepted at ISDFS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19534v1",
      "published_date": "2025-02-26 20:17:16 UTC",
      "updated_date": "2025-02-26 20:17:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:06:51.061942"
    },
    {
      "arxiv_id": "2502.19529v1",
      "title": "Cognitive networks highlight differences and similarities in the STEM mindsets of human and LLM-simulated trainees, experts and academics",
      "title_zh": "翻译失败",
      "authors": [
        "Edith Haim",
        "Lars van den Bergh",
        "Cynthia S. Q. Siew",
        "Yoed N. Kenett",
        "Daniele Marinazzo",
        "Massimo Stella"
      ],
      "abstract": "Understanding attitudes towards STEM means quantifying the cognitive and\nemotional ways in which individuals, and potentially large language models too,\nconceptualise such subjects. This study uses behavioural forma mentis networks\n(BFMNs) to investigate the STEM-focused mindset, i.e. ways of associating and\nperceiving ideas, of 177 human participants and 177 artificial humans simulated\nby GPT-3.5. Participants were split in 3 groups - trainees, experts and\nacademics - to compare the influence of expertise level on their mindset. The\nresults revealed that human forma mentis networks exhibited significantly\nhigher clustering coefficients compared to GPT-3.5, indicating that human\nmindsets displayed a tendency to form and close triads of conceptual\nassociations while recollecting STEM ideas. Human experts, in particular,\ndemonstrated robust clustering coefficients, reflecting better integration of\nSTEM concepts into their cognitive networks. In contrast, GPT-3.5 produced\nsparser mindsets. Furthermore, both human and GPT mindsets framed mathematics\nin neutral or positive terms, differently from STEM high schoolers, researchers\nand other large language models sampled in other works. This research\ncontributes to understanding how mindset structure can provide cognitive\ninsights about memory structure and machine limitations.",
      "tldr_zh": "本研究利用行为 forma mentis networks (BFMNs) 调查了177名人类参与者和177名由GPT-3.5模拟的个体（包括trainees、experts和academics）在STEM心态上的差异和相似性。结果显示，人类网络表现出显著更高的clustering coefficients，尤其是experts，更倾向于形成紧密的概念关联三元组，而GPT-3.5生成的网络则更稀疏。两组均将数学视为中性或积极的术语，与其他研究中的高中生和LLM不同。该研究为理解记忆结构、机器限制及其对认知的影响提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T01 (Primary), 05C82 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "Keywords: cognitive network science; mindset measurement; associative\n  knowledge; artificial intelligence; simulated participants",
      "pdf_url": "http://arxiv.org/pdf/2502.19529v1",
      "published_date": "2025-02-26 20:02:51 UTC",
      "updated_date": "2025-02-26 20:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:07:04.802713"
    },
    {
      "arxiv_id": "2502.19519v2",
      "title": "Static Vs. Agentic Game Master AI for Facilitating Solo Role-Playing Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolai Hejlesen Jørgensen",
        "Sarmilan Tharmabalan",
        "Ilhan Aslan",
        "Nicolai Brodersen Hansen",
        "Timothy Merritt"
      ],
      "abstract": "This paper presents a game master AI for single-player role-playing games.\nThe AI is designed to deliver interactive text-based narratives and experiences\ntypically associated with multiplayer tabletop games like Dungeons & Dragons.\nWe report on the design process and the series of experiments to improve the\nfunctionality and experience design, resulting in two functional versions of\nthe system. While v1 of our system uses simplified prompt engineering, v2\nleverages a multi-agent architecture and the ReAct framework to include\nreasoning and action. A comparative evaluation demonstrates that v2 as an\nagentic system maintains play while significantly improving modularity and game\nexperience, including immersion and curiosity. Our findings contribute to the\nevolution of AI-driven interactive fiction, highlighting new avenues for\nenhancing solo role-playing experiences.",
      "tldr_zh": "这篇论文比较了静态和智能体（agentic）游戏主AI（Game Master AI）在促进单人角色扮演游戏中的效果。系统设计了两个版本：v1 使用简化提示工程（prompt engineering）提供互动文本叙述，而 v2 采用多智能体架构（multi-agent architecture）和 ReAct framework，加入推理和行动机制。评估结果表明，v2 显著提升了模块性和游戏体验，包括沉浸感和好奇心，同时保持了游戏的连贯性。这些发现为 AI 驱动的互动小说（interactive fiction）发展提供了新方向，推动了单人角色扮演体验的创新。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 10 figures, 1 table, submitted for review",
      "pdf_url": "http://arxiv.org/pdf/2502.19519v2",
      "published_date": "2025-02-26 19:42:22 UTC",
      "updated_date": "2025-03-06 16:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:07:16.455662"
    },
    {
      "arxiv_id": "2502.19518v2",
      "title": "Assessing LLMs for Front-end Software Architecture Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "L. P. Franciscatto Guerra",
        "N. Ernst"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant promise in\nautomating software development tasks, yet their capabilities with respect to\nsoftware design tasks remains largely unclear. This study investigates the\ncapabilities of an LLM in understanding, reproducing, and generating structures\nwithin the complex VIPER architecture, a design pattern for iOS applications.\nWe leverage Bloom's taxonomy to develop a comprehensive evaluation framework to\nassess the LLM's performance across different cognitive domains such as\nremembering, understanding, applying, analyzing, evaluating, and creating.\nExperimental results, using ChatGPT 4 Turbo 2024-04-09, reveal that the LLM\nexcelled in higher-order tasks like evaluating and creating, but faced\nchallenges with lower-order tasks requiring precise retrieval of architectural\ndetails. These findings highlight both the potential of LLMs to reduce\ndevelopment costs and the barriers to their effective application in real-world\nsoftware design scenarios. This study proposes a benchmark format for assessing\nLLM capabilities in software architecture, aiming to contribute toward more\nrobust and accessible AI-driven development tools.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在前端软件架构知识方面的能力，特别是针对 iOS 应用的 VIPER 架构。研究采用 Bloom's taxonomy 框架，构建了一个全面评估体系，测试 LLM 在 remembering、understanding、applying、analyzing、evaluating 和 creating 等认知领域的表现。实验结果显示，使用 ChatGPT 4 Turbo 2024-04-09 的 LLM 在 higher-order tasks 如 evaluating 和 creating 上表现出色，但面临 lower-order tasks 中精确检索架构细节的挑战。这些发现突出了 LLMs 降低开发成本的潜力，同时提出一个基准格式来评估 LLM 在软件架构任务中的能力，促进更可靠的 AI 驱动开发工具。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2; I.2"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages, 1 figure, to appear in the International Workshop on\n  Designing Software at ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19518v2",
      "published_date": "2025-02-26 19:33:35 UTC",
      "updated_date": "2025-03-10 01:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:07:27.777518"
    },
    {
      "arxiv_id": "2502.19513v2",
      "title": "Mixtraining: A Better Trade-Off Between Compute and Performance",
      "title_zh": "Mixtraining：计算与性能之间更好的权衡",
      "authors": [
        "Zexin Li",
        "Jiancheng Zhang",
        "Yufei Li",
        "Yinglun Zhu",
        "Cong Liu"
      ],
      "abstract": "Incorporating self-supervised learning (SSL) before standard supervised\nlearning (SL) has become a widely used strategy to enhance model performance,\nparticularly in data-limited scenarios. However, this approach introduces a\ntrade-off between computation and performance: while SSL helps with\nrepresentation learning, it requires a separate, often time-consuming training\nphase, increasing computational overhead and limiting efficiency in\nresource-constrained settings. To address these challenges, we propose\nMixTraining, a novel framework that interleaves several SSL and SL epochs\nwithin a unified mixtraining training phase, featuring a smooth transition\nbetween two learning objectives. MixTraining enhances synergy between SSL and\nSL for improved accuracy and consolidates shared computation steps to reduce\ncomputation overhead. MixTraining is versatile and applicable to both\nsingle-task and multi-task learning scenarios. Extensive experiments\ndemonstrate that MixTraining offers a superior compute-performance trade-off\ncompared to conventional pipelines, achieving an 8.81% absolute accuracy gain\n(18.89% relative accuracy gain) on the TinyImageNet dataset while accelerating\ntraining by up to 1.29x\n  with the ViT-Tiny model.",
      "tldr_zh": "该研究提出MixTraining框架，以解决传统自监督学习(SSL)和监督学习(SL)结合策略中计算开销与性能之间的权衡问题。MixTraining通过在一个统一的训练阶段交错SSL和SL epochs，并实现平滑过渡，增强二者之间的协同作用，同时减少共享计算步骤的开销。该框架适用于单任务和多任务学习场景，实验显示在TinyImageNet数据集上，使用ViT-Tiny模型时，MixTraining实现了8.81%的绝对准确率提升（18.89%相对提升），并将训练速度加速高达1.29倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19513v2",
      "published_date": "2025-02-26 19:25:27 UTC",
      "updated_date": "2025-03-05 03:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:07:40.715292"
    },
    {
      "arxiv_id": "2502.19507v1",
      "title": "Building Knowledge Graphs Towards a Global Food Systems Datahub",
      "title_zh": "翻译失败",
      "authors": [
        "Nirmal Gelal",
        "Aastha Gautam",
        "Sanaz Saki Norouzi",
        "Nico Giordano",
        "Claudio Dias da Silva Jr",
        "Jean Ribert Francois",
        "Kelsey Andersen Onofre",
        "Katherine Nelson",
        "Stacy Hutchinson",
        "Xiaomao Lin",
        "Stephen Welch",
        "Romulo Lollato",
        "Pascal Hitzler",
        "Hande Küçük McGinty"
      ],
      "abstract": "Sustainable agricultural production aligns with several sustainability goals\nestablished by the United Nations (UN). However, there is a lack of studies\nthat comprehensively examine sustainable agricultural practices across various\nproducts and production methods. Such research could provide valuable insights\ninto the diverse factors influencing the sustainability of specific crops and\nproduce while also identifying practices and conditions that are universally\napplicable to all forms of agricultural production. While this research might\nhelp us better understand sustainability, the community would still need a\nconsistent set of vocabularies. These consistent vocabularies, which represent\nthe underlying datasets, can then be stored in a global food systems datahub.\nThe standardized vocabularies might help encode important information for\nfurther statistical analyses and AI/ML approaches in the datasets, resulting in\nthe research targeting sustainable agricultural production. A structured method\nof representing information in sustainability, especially for wheat production,\nis currently unavailable. In an attempt to address this gap, we are building a\nset of ontologies and Knowledge Graphs (KGs) that encode knowledge associated\nwith sustainable wheat production using formal logic. The data for this set of\nknowledge graphs are collected from public data sources, experimental results\ncollected at our experiments at Kansas State University, and a Sustainability\nWorkshop that we organized earlier in the year, which helped us collect input\nfrom different stakeholders throughout the value chain of wheat. The modeling\nof the ontology (i.e., the schema) for the Knowledge Graph has been in progress\nwith the help of our domain experts, following a modular structure using KNARM\nmethodology. In this paper, we will present our preliminary results and schemas\nof our Knowledge Graph and ontologies.",
      "tldr_zh": "本研究指出，可持续农业实践缺乏全面研究，且缺少一致的词汇集来支持全球食品系统数据中心（Global Food Systems Datahub）的构建，从而影响统计分析和 AI/ML 方法的应用。作者针对小麦生产这一领域，开发了一套本体（ontologies）和知识图谱（Knowledge Graphs），使用形式逻辑编码相关知识，并采用 KNARM methodology 进行模块化建模。数据来源于公共数据源、Kansas State University 的实验结果，以及一个可持续性研讨会收集的利益相关者输入。初步结果展示了知识图谱的模式（schemas），为推进可持续农业研究和全球数据中心奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19507v1",
      "published_date": "2025-02-26 19:13:11 UTC",
      "updated_date": "2025-02-26 19:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:07:54.457047"
    },
    {
      "arxiv_id": "2502.19500v1",
      "title": "Conversational Planning for Personal Plans",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantina Christakopoulou",
        "Iris Qu",
        "John Canny",
        "Andrew Goodridge",
        "Cj Adams",
        "Minmin Chen",
        "Maja Matarić"
      ],
      "abstract": "The language generation and reasoning capabilities of large language models\n(LLMs) have enabled conversational systems with impressive performance in a\nvariety of tasks, from code generation, to composing essays, to passing STEM\nand legal exams, to a new paradigm for knowledge search. Besides those\nshort-term use applications, LLMs are increasingly used to help with real-life\ngoals or tasks that take a long time to complete, involving multiple sessions\nacross days, weeks, months, or even years. Thus to enable conversational\nsystems for long term interactions and tasks, we need language-based agents\nthat can plan for long horizons. Traditionally, such capabilities were\naddressed by reinforcement learning agents with hierarchical planning\ncapabilities. In this work, we explore a novel architecture where the LLM acts\nas the meta-controller deciding the agent's next macro-action, and tool use\naugmented LLM-based option policies execute the selected macro-action. We\ninstantiate this framework for a specific set of macro-actions enabling\nadaptive planning for users' personal plans through conversation and follow-up\nquestions collecting user feedback. We show how this paradigm can be applicable\nin scenarios ranging from tutoring for academic and non-academic tasks to\nconversational coaching for personal health plans.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在处理长期任务规划中的潜力，提出了一种新架构，其中LLM充当meta-controller来决定代理的下一个macro-action。\n该框架结合工具增强的LLM-based选项策略来执行选定的macro-action，从而实现适应性对话，支持用户个人计划的动态调整和反馈收集。\n这项方法适用于多种场景，如学术和非学术辅导，以及个人健康计划的对话式指导，展示了LLMs在长期互动中的实际价值。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19500v1",
      "published_date": "2025-02-26 19:04:26 UTC",
      "updated_date": "2025-02-26 19:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:08:05.321910"
    },
    {
      "arxiv_id": "2502.19417v1",
      "title": "Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lucy Xiaoyang Shi",
        "Brian Ichter",
        "Michael Equi",
        "Liyiming Ke",
        "Karl Pertsch",
        "Quan Vuong",
        "James Tanner",
        "Anna Walling",
        "Haohuan Wang",
        "Niccolo Fusai",
        "Adrian Li-Bell",
        "Danny Driess",
        "Lachy Groom",
        "Sergey Levine",
        "Chelsea Finn"
      ],
      "abstract": "Generalist robots that can perform a range of different tasks in open-world\nsettings must be able to not only reason about the steps needed to accomplish\ntheir goals, but also process complex instructions, prompts, and even feedback\nduring task execution. Intricate instructions (e.g., \"Could you make me a\nvegetarian sandwich?\" or \"I don't like that one\") require not just the ability\nto physically perform the individual steps, but the ability to situate complex\ncommands and feedback in the physical world. In this work, we describe a system\nthat uses vision-language models in a hierarchical structure, first reasoning\nover complex prompts and user feedback to deduce the most appropriate next step\nto fulfill the task, and then performing that step with low-level actions. In\ncontrast to direct instruction following methods that can fulfill simple\ncommands (\"pick up the cup\"), our system can reason through complex prompts and\nincorporate situated feedback during task execution (\"that's not trash\"). We\nevaluate our system across three robotic platforms, including single-arm,\ndual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks\nsuch as cleaning messy tables, making sandwiches, and grocery shopping.",
      "tldr_zh": "该研究提出了一种名为Hi Robot的系统，利用分层视觉-语言-动作模型(hierarchical vision-language-action models)，使通用机器人能够处理开放式指令、复杂提示和实时反馈，从而在真实环境中执行多样任务。该系统通过高层推理先分析指令和反馈以确定最佳下一步，然后使用低层动作来实现具体操作，与直接指令跟随方法相比，能更好地应对复杂场景如用户偏好调整。实验在单臂、双臂和移动双臂机器人平台上进行，展示了机器人处理清理桌面、制作三明治和购物等任务的能力，证明了其在提升机器人智能性和适应性方面的显著潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19417v1",
      "published_date": "2025-02-26 18:58:41 UTC",
      "updated_date": "2025-02-26 18:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:08:18.148191"
    },
    {
      "arxiv_id": "2502.19416v1",
      "title": "Norm Growth and Stability Challenges in Localized Sequential Knowledge Editing",
      "title_zh": "局部顺序知识编辑中的范数增长和稳定性挑战",
      "authors": [
        "Akshat Gupta",
        "Christine Fang",
        "Atahan Ozdemir",
        "Maochuan Lu",
        "Ahmed Alaa",
        "Thomas Hartvigsen",
        "Gopala Anumanchipalli"
      ],
      "abstract": "This study investigates the impact of localized updates to large language\nmodels (LLMs), specifically in the context of knowledge editing - a task aimed\nat incorporating or modifying specific facts without altering broader model\ncapabilities. We first show that across different post-training interventions\nlike continuous pre-training, full fine-tuning and LORA-based fine-tuning, the\nFrobenius norm of the updated matrices always increases. This increasing norm\nis especially detrimental for localized knowledge editing, where only a subset\nof matrices are updated in a model . We reveal a consistent phenomenon across\nvarious editing techniques, including fine-tuning, hypernetwork-based\napproaches, and locate-and-edit methods: the norm of the updated matrix\ninvariably increases with successive updates. Such growth disrupts model\nbalance, particularly when isolated matrices are updated while the rest of the\nmodel remains static, leading to potential instability and degradation of\ndownstream performance. Upon deeper investigations of the intermediate\nactivation vectors, we find that the norm of internal activations decreases and\nis accompanied by shifts in the subspaces occupied by these activations, which\nshows that these activation vectors now occupy completely different regions in\nthe representation space compared to the unedited model. With our paper, we\nhighlight the technical challenges with continuous and localized sequential\nknowledge editing and their implications for maintaining model stability and\nutility.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中本地化顺序知识编辑的挑战，特别关注更新过程对模型稳定性的影响。通过实验比较连续预训练、全微调和LoRA-based微调等方法，发现更新矩阵的Frobenius norm总是增加，尤其在仅更新部分矩阵时，导致模型平衡破坏。进一步分析显示，内部激活向量的norm减少并伴随子空间转移，使激活向量在表示空间中占据新区域，从而可能引发下游性能退化。该论文强调了连续和本地化知识编辑的技术难题，并为维护模型稳定性和实用性提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for Oral Presentation at KnowFM @ AAAI 2025. arXiv admin\n  note: text overlap with arXiv:2502.01636",
      "pdf_url": "http://arxiv.org/pdf/2502.19416v1",
      "published_date": "2025-02-26 18:58:30 UTC",
      "updated_date": "2025-02-26 18:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:08:29.648157"
    },
    {
      "arxiv_id": "2502.19413v2",
      "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Schuhmann",
        "Gollam Rabby",
        "Ameya Prabhu",
        "Tawsif Ahmed",
        "Andreas Hochlehnert",
        "Huu Nguyen",
        "Nick Akinci",
        "Ludwig Schmidt",
        "Robert Kaczmarczyk",
        "Sören Auer",
        "Jenia Jitsev",
        "Matthias Bethge"
      ],
      "abstract": "Paywalls, licenses and copyright rules often restrict the broad dissemination\nand reuse of scientific knowledge. We take the position that it is both legally\nand technically feasible to extract the scientific knowledge in scholarly\ntexts. Current methods, like text embeddings, fail to reliably preserve factual\ncontent, and simple paraphrasing may not be legally sound. We propose a new\nidea for the community to adopt: convert scholarly documents into knowledge\npreserving, but style agnostic representations we term Knowledge Units using\nLLMs. These units use structured data capturing entities, attributes and\nrelationships without stylistic content. We provide evidence that Knowledge\nUnits (1) form a legally defensible framework for sharing knowledge from\ncopyrighted research texts, based on legal analyses of German copyright law and\nU.S. Fair Use doctrine, and (2) preserve most (~95\\%) factual knowledge from\noriginal text, measured by MCQ performance on facts from the original\ncopyrighted text across four research domains. Freeing scientific knowledge\nfrom copyright promises transformative benefits for scientific research and\neducation by allowing language models to reuse important facts from copyrighted\ntext. To support this, we share open-source tools for converting research\ndocuments into Knowledge Units. Overall, our work posits the feasibility of\ndemocratizing access to scientific knowledge while respecting copyright.",
      "tldr_zh": "该论文提出“Project Alexandria”项目，利用大型语言模型（LLMs）将学术文档转换为“Knowledge Units”，这些是结构化的数据，捕捉实体、属性和关系的同时去除风格内容，从而规避版权限制。研究表明，这种方法在德国版权法和美国合理使用（Fair Use）原则下合法可行，并能保留约95%的原始事实知识，通过多选题（MCQ）测试在四个研究领域得到验证。相比现有方法如文本嵌入，该框架更可靠地提取科学知识，并通过开源工具支持知识共享，最终旨在民主化科学知识访问，促进研究和教育发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2502.19413v2",
      "published_date": "2025-02-26 18:56:52 UTC",
      "updated_date": "2025-04-18 15:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:08:41.261028"
    },
    {
      "arxiv_id": "2503.00054v1",
      "title": "Deciphering the complaint aspects: Towards an aspect-based complaint identification model with video complaint dataset in finance",
      "title_zh": "翻译失败",
      "authors": [
        "Sarmistha Das",
        "Basha Mujavarsheik",
        "R E Zera Lyngkhoi",
        "Sriparna Saha",
        "Alka Maurya"
      ],
      "abstract": "In today's competitive marketing landscape, effective complaint management is\ncrucial for customer service and business success. Video complaints,\nintegrating text and image content, offer invaluable insights by addressing\ncustomer grievances and delineating product benefits and drawbacks. However,\ncomprehending nuanced complaint aspects within vast daily multimodal financial\ndata remains a formidable challenge. Addressing this gap, we have curated a\nproprietary multimodal video complaint dataset comprising 433 publicly\naccessible instances. Each instance is meticulously annotated at the utterance\nlevel, encompassing five distinct categories of financial aspects and their\nassociated complaint labels. To support this endeavour, we introduce Solution\n3.0, a model designed for multimodal aspect-based complaint identification\ntask. Solution 3.0 is tailored to perform three key tasks: 1) handling\nmultimodal features ( audio and video), 2) facilitating multilabel aspect\nclassification, and 3) conducting multitasking for aspect classifications and\ncomplaint identification parallelly. Solution 3.0 utilizes a CLIP-based dual\nfrozen encoder with an integrated image segment encoder for global feature\nfusion, enhanced by contextual attention (ISEC) to improve accuracy and\nefficiency. Our proposed framework surpasses current multimodal baselines,\nexhibiting superior performance across nearly all metrics by opening new ways\nto strengthen appropriate customer care initiatives and effectively assisting\nindividuals in resolving their problems.",
      "tldr_zh": "本研究针对金融领域的视频投诉管理，构建了一个包含433个多模态实例的专有数据集，每个实例在话语级别标注了五个金融方面的类别及其投诉标签，以解决处理海量多模态数据（如文本、音频和视频）的挑战。  \n他们提出了Solution 3.0模型，该模型利用CLIP-based双冻结编码器结合图像段编码器进行全局特征融合，并通过ISEC上下文注意力机制，同时处理多模态特征、多标签方面分类和投诉识别任务。  \n实验结果表明，Solution 3.0在几乎所有指标上超过了现有多模态基线模型，为加强客户关怀和问题解决提供了有效的新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00054v1",
      "published_date": "2025-02-26 18:56:07 UTC",
      "updated_date": "2025-02-26 18:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:08:52.899276"
    },
    {
      "arxiv_id": "2502.19411v1",
      "title": "Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Dayu Yang",
        "Tianyang Liu",
        "Daoan Zhang",
        "Antoine Simoulin",
        "Xiaoyi Liu",
        "Yuwei Cao",
        "Zhaopu Teng",
        "Xin Qian",
        "Grey Yang",
        "Jiebo Luo",
        "Julian McAuley"
      ],
      "abstract": "In large language models (LLMs), code and reasoning reinforce each other:\ncode offers an abstract, modular, and logic-driven structure that supports\nreasoning, while reasoning translates high-level goals into smaller, executable\nsteps that drive more advanced code intelligence. In this study, we examine how\ncode serves as a structured medium for enhancing reasoning: it provides\nverifiable execution paths, enforces logical decomposition, and enables runtime\nvalidation. We also explore how improvements in reasoning have transformed code\nintelligence from basic completion to advanced capabilities, enabling models to\naddress complex software engineering tasks through planning and debugging.\nFinally, we identify key challenges and propose future research directions to\nstrengthen this synergy, ultimately improving LLM's performance in both areas.",
      "tldr_zh": "这篇调查探讨了在大型语言模型（LLMs）中，代码和推理的相互强化关系：代码提供抽象、模块化和逻辑驱动的结构，支持推理通过可验证的执行路径、逻辑分解和运行时验证。另一方面，推理将高层目标转化为可执行步骤，推动代码智能从基本完成演进到高级能力，如规划和调试。研究总结了这一协同效应的关键机制，并识别了潜在挑战，如模型局限性。最终，论文提出未来研究方向，以提升LLMs在代码和推理方面的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Repo: https://github.com/dayuyang1999/Awesome-Code-Reasoning",
      "pdf_url": "http://arxiv.org/pdf/2502.19411v1",
      "published_date": "2025-02-26 18:55:42 UTC",
      "updated_date": "2025-02-26 18:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:09:04.346198"
    },
    {
      "arxiv_id": "2502.19410v1",
      "title": "Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Xinru Wang",
        "Mengjie Yu",
        "Hannah Nguyen",
        "Michael Iuzzolino",
        "Tianyi Wang",
        "Peiqi Tang",
        "Natasha Lynova",
        "Co Tran",
        "Ting Zhang",
        "Naveen Sendhilnathan",
        "Hrvoje Benko",
        "Haijun Xia",
        "Tanya Jonker"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable potential in recommending\neveryday actions as personal AI assistants, while Explainable AI (XAI)\ntechniques are being increasingly utilized to help users understand why a\nrecommendation is given. Personal AI assistants today are often located on\nultra-small devices such as smartwatches, which have limited screen space. The\nverbosity of LLM-generated explanations, however, makes it challenging to\ndeliver glanceable LLM explanations on such ultra-small devices. To address\nthis, we explored 1) spatially structuring an LLM's explanation text using\ndefined contextual components during prompting and 2) presenting temporally\nadaptive explanations to users based on confidence levels. We conducted a user\nstudy to understand how these approaches impacted user experiences when\ninteracting with LLM recommendations and explanations on ultra-small devices.\nThe results showed that structured explanations reduced users' time to action\nand cognitive load when reading an explanation. Always-on structured\nexplanations increased users' acceptance of AI recommendations. However, users\nwere less satisfied with structured explanations compared to unstructured ones\ndue to their lack of sufficient, readable details. Additionally, adaptively\npresenting structured explanations was less effective at improving user\nperceptions of the AI compared to the always-on structured explanations.\nTogether with users' interview feedback, the results led to design implications\nto be mindful of when personalizing the content and timing of LLM explanations\nthat are displayed on ultra-small devices.",
      "tldr_zh": "本研究探讨了如何在超小型设备（如智能手表）上提供简洁易读的LLM推荐解释，以解决LLMs生成解释过于冗长的问题。研究方法包括通过提示定义上下文组件来结构化解释文本，以及根据置信度水平实现时间自适应呈现。用户研究结果显示，结构化解释减少了用户行动时间和认知负荷，并提高了对AI推荐的接受度，但用户对结构化解释的满意度较低，因为缺少足够细节，且自适应呈现不如始终开启的有效。该研究为超小型设备上的LLM解释设计提供了个性化内容和时机的启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19410v1",
      "published_date": "2025-02-26 18:55:26 UTC",
      "updated_date": "2025-02-26 18:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:09:16.355039"
    },
    {
      "arxiv_id": "2502.19400v1",
      "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Max Ku",
        "Thomas Chong",
        "Jonathan Leung",
        "Krish Shah",
        "Alvin Yu",
        "Wenhu Chen"
      ],
      "abstract": "Understanding domain-specific theorems often requires more than just\ntext-based reasoning; effective communication through structured visual\nexplanations is crucial for deeper comprehension. While large language models\n(LLMs) demonstrate strong performance in text-based theorem reasoning, their\nability to generate coherent and pedagogically meaningful visual explanations\nremains an open challenge. In this work, we introduce TheoremExplainAgent, an\nagentic approach for generating long-form theorem explanation videos (over 5\nminutes) using Manim animations. To systematically evaluate multimodal theorem\nexplanations, we propose TheoremExplainBench, a benchmark covering 240 theorems\nacross multiple STEM disciplines, along with 5 automated evaluation metrics.\nOur results reveal that agentic planning is essential for generating detailed\nlong-form videos, and the o3-mini agent achieves a success rate of 93.8% and an\noverall score of 0.77. However, our quantitative and qualitative studies show\nthat most of the videos produced exhibit minor issues with visual element\nlayout. Furthermore, multimodal explanations expose deeper reasoning flaws that\ntext-based explanations fail to reveal, highlighting the importance of\nmultimodal explanations.",
      "tldr_zh": "该研究引入了 TheoremExplainAgent，一种代理式方法，用于为 LLM (Large Language Models) 定理理解生成多模态解释视频，这些视频利用 Manim 动画创建，长于 5 分钟，以提供结构化的视觉和文本解释。论文同时提出了 TheoremExplainBench 基准，涵盖 240 个 STEM 领域定理，并定义了 5 个自动化评估指标。实验结果显示，o3-mini 代理实现了 93.8% 的成功率和 0.77 的整体分数，但视频中存在轻微的视觉元素布局问题；此外，多模态解释揭示了文本解释无法暴露的更深层推理缺陷，强调了其在提升定理理解方面的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19400v1",
      "published_date": "2025-02-26 18:50:09 UTC",
      "updated_date": "2025-02-26 18:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:09:28.333048"
    },
    {
      "arxiv_id": "2502.19390v2",
      "title": "Multi-modal Contrastive Learning for Tumor-specific Missing Modality Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Minjoo Lim",
        "Bogyeong Kang",
        "Tae-Eui Kam"
      ],
      "abstract": "Multi-modal magnetic resonance imaging (MRI) is essential for providing\ncomplementary information about brain anatomy and pathology, leading to more\naccurate diagnoses. However, obtaining high-quality multi-modal MRI in a\nclinical setting is difficult due to factors such as time constraints, high\ncosts, and patient movement artifacts. To overcome this difficulty, there is\nincreasing interest in developing generative models that can synthesize missing\ntarget modality images from the available source ones. Therefore, our team,\nPLAVE, design a generative model for missing MRI that integrates multi-modal\ncontrastive learning with a focus on critical tumor regions. Specifically, we\nintegrate multi-modal contrastive learning, tailored for multiple source\nmodalities, and enhance its effectiveness by selecting features based on\nentropy during the contrastive learning process. Additionally, our network not\nonly generates the missing target modality images but also predicts\nsegmentation outputs, simultaneously. This approach improves the generator's\ncapability to precisely generate tumor regions, ultimately improving\nperformance in downstream segmentation tasks. By leveraging a combination of\ncontrastive, segmentation, and additional self-representation losses, our model\neffectively reflects target-specific information and generate high-quality\ntarget images. Consequently, our results in the Brain MR Image Synthesis\nchallenge demonstrate that the proposed model excelled in generating the\nmissing modality.",
      "tldr_zh": "本论文针对多模态 MRI 在临床中难以获取的问题，提出了一种基于 Multi-modal Contrastive Learning 的生成模型，用于肿瘤特定缺失模态图像合成。该模型通过整合多源模态对比学习、基于熵的特征选择，以及同时生成图像和预测分割输出的设计，来提升肿瘤区域的精确生成，并结合对比学习、分割和自表示损失函数以反映目标特定信息。最终，实验在 Brain MR Image Synthesis 挑战中证明，该模型显著提高了图像质量和下游分割任务的性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19390v2",
      "published_date": "2025-02-26 18:34:58 UTC",
      "updated_date": "2025-04-12 04:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:09:40.993024"
    },
    {
      "arxiv_id": "2502.19386v1",
      "title": "Efficient 4D fMRI ASD Classification using Spatial-Temporal-Omics-based Learning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqiao Weng",
        "Weidong Cai",
        "Bo Zhou"
      ],
      "abstract": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder impacting\nsocial and behavioral development. Resting-state fMRI, a non-invasive tool for\ncapturing brain connectivity patterns, aids in early ASD diagnosis and\ndifferentiation from typical controls (TC). However, previous methods, which\nrely on either mean time series or full 4D data, are limited by a lack of\nspatial information or by high computational costs. This underscores the need\nfor an efficient solution that preserves both spatial and temporal information.\nIn this paper, we propose a novel, simple, and efficient spatial-temporal-omics\nlearning framework designed to efficiently extract spatio-temporal features\nfrom fMRI for ASD classification. Our approach addresses these limitations by\nutilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics,\nwhich preserve full spatial resolution while capturing diverse statistical\ncharacteristics of the time series at each voxel. Meanwhile, functional\nconnectivity features serve as the spatial-temporal inter-regional omics,\ncapturing correlations across brain regions. Extensive experiments and ablation\nstudies on the ABIDE dataset demonstrate that our framework significantly\noutperforms previous methods while maintaining computational efficiency. We\nbelieve our research offers valuable insights that will inform and advance\nfuture ASD studies, particularly in the realm of spatial-temporal-omics-based\nlearning.",
      "tldr_zh": "本研究针对自闭症谱系障碍(ASD)的诊断问题，提出了一种高效的spatial-temporal-omics-based学习框架，利用4D fMRI数据进行分类。该框架通过3D time-domain derivatives作为spatial-temporal inter-voxel omics来保留空间分辨率并捕捉体素级时间序列统计特征，同时使用functional connectivity features作为spatial-temporal inter-regional omics来分析脑区间相关性，从而解决现有方法忽略空间信息或计算成本高的局限。在ABIDE数据集上的实验显示，该框架显著优于基线方法，同时保持高效计算性能，为未来的ASD研究，特别是基于spatial-temporal-omics的学习，提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2025 IEEE International Symposium on Biomedical Imaging\n  (ISBI)",
      "pdf_url": "http://arxiv.org/pdf/2502.19386v1",
      "published_date": "2025-02-26 18:31:07 UTC",
      "updated_date": "2025-02-26 18:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:09:54.761393"
    },
    {
      "arxiv_id": "2502.19377v1",
      "title": "Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Arman Mielke",
        "Uwe Bauknecht",
        "Thilo Strauss",
        "Mathias Niepert"
      ],
      "abstract": "Combinatorial optimization (CO) problems arise in a wide range of fields from\nmedicine to logistics and manufacturing. While exact solutions are often not\nnecessary, many applications require finding high-quality solutions quickly.\nFor this purpose, we propose a data-driven approach to improve existing\nnon-learned approximation algorithms for CO. We parameterize the approximation\nalgorithm and train a graph neural network (GNN) to predict parameter values\nthat lead to the best possible solutions. Our pipeline is trained end-to-end in\na self-supervised fashion using gradient estimation, treating the approximation\nalgorithm as a black box. We propose a novel gradient estimation scheme for\nthis purpose, which we call preference-based gradient estimation. Our approach\ncombines the benefits of the neural network and the non-learned approximation\nalgorithm: The GNN leverages the information from the dataset to allow the\napproximation algorithm to find better solutions, while the approximation\nalgorithm guarantees that the solution is feasible. We validate our approach on\ntwo well-known combinatorial optimization problems, the travelling salesman\nproblem and the minimum k-cut problem, and show that our method is competitive\nwith state of the art learned CO solvers.",
      "tldr_zh": "该论文针对组合优化（Combinatorial Optimization）问题提出了一种数据驱动的方法，用于改进非学习型近似算法。具体而言，通过参数化算法并使用图神经网络（Graph Neural Network, GNN）预测最佳参数值，实现端到端的自监督训练，并引入新型梯度估计方案——Preference-Based Gradient Estimation，将算法视为黑盒处理。 该方法结合了GNN的预测能力与非学习型算法的可靠性，确保解决方案既高效又可行。在旅行 salesman problem和minimum k-cut problem等经典问题上，实验结果显示该方法与最先进的学习型求解器具有竞争性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preliminary work, under review",
      "pdf_url": "http://arxiv.org/pdf/2502.19377v1",
      "published_date": "2025-02-26 18:23:07 UTC",
      "updated_date": "2025-02-26 18:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:10:05.898298"
    },
    {
      "arxiv_id": "2503.01880v1",
      "title": "BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed-Khalil Ghali",
        "Abdelrahman Farrag",
        "Sarah Lam",
        "Daehan Won"
      ],
      "abstract": "Thematic analysis of social media posts provides a major understanding of\npublic discourse, yet traditional methods often struggle to capture the\ncomplexity and nuance of unstructured, large-scale text data. This study\nintroduces a novel methodology for thematic analysis that integrates tweet\nembeddings from pre-trained language models, dimensionality reduction using and\nmatrix factorization, and generative AI to identify and refine latent themes.\nOur approach clusters compressed tweet representations and employs generative\nAI to extract and articulate themes through an agentic Chain of Thought (CoT)\nprompting, with a secondary LLM for quality assurance. This methodology is\napplied to tweets from the autistic community, a group that increasingly uses\nsocial media to discuss their experiences and challenges. By automating the\nthematic extraction process, the aim is to uncover key insights while\nmaintaining the richness of the original discourse. This autism case study\ndemonstrates the utility of the proposed approach in improving thematic\nanalysis of social media data, offering a scalable and adaptable framework that\ncan be applied to diverse contexts. The results highlight the potential of\ncombining machine learning and Generative AI to enhance the depth and accuracy\nof theme identification in online communities.",
      "tldr_zh": "本研究提出了一种名为 BEYONDWORDS 的创新方法，用于从社会媒体帖子中提取主题，通过整合推文 embeddings 来自预训练语言模型、dimensionality reduction 和 matrix factorization 来处理大规模非结构化文本数据的复杂性。方法采用生成式 AI 和 agentic Chain of Thought (CoT) 提示进行主题聚类与提炼，并使用辅助 LLM 确保输出质量，从而自动化主题提取过程，同时保留原话语的丰富性。该方法应用于自闭症社区的推文案例研究中，展示了其在提升主题识别深度和准确性的潜力，并提供了一个可扩展、可适应的框架，适用于各种在线社区分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01880v1",
      "published_date": "2025-02-26 18:18:37 UTC",
      "updated_date": "2025-02-26 18:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:10:19.507349"
    },
    {
      "arxiv_id": "2502.19363v3",
      "title": "DataMan: Data Manager for Pre-training Large Language Models",
      "title_zh": "DataMan：用于预训练大型语言模型的数据管理器",
      "authors": [
        "Ru Peng",
        "Kexin Yang",
        "Yawen Zeng",
        "Junyang Lin",
        "Dayiheng Liu",
        "Junbo Zhao"
      ],
      "abstract": "The performance emergence of large language models (LLMs) driven by data\nscaling laws makes the selection of pre-training data increasingly important.\nHowever, existing methods rely on limited heuristics and human intuition,\nlacking comprehensive and clear guidelines. To address this, we are inspired by\n``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit\nits performance. As its pre-training capabilities are related to perplexity\n(PPL), we derive 14 quality criteria from the causes of text perplexity\nanomalies and introduce 15 common application domains to support domain mixing.\nIn this paper, we train a Data Manager (DataMan) to learn quality ratings and\ndomain recognition from pointwise rating, and use it to annotate a 447B token\npre-training corpus with 14 quality ratings and domain type. Our experiments\nvalidate our approach, using DataMan to select 30B tokens to train a\n1.3B-parameter language model, demonstrating significant improvements in\nin-context learning (ICL), perplexity, and instruction-following ability over\nthe state-of-the-art baseline. The best-performing model, based on the Overall\nScore l=5 surpasses a model trained with 50% more data using uniform sampling.\nWe continue pre-training with high-rated, domain-specific data annotated by\nDataMan to enhance domain-specific ICL performance and thus verify DataMan's\ndomain mixing ability. Our findings emphasize the importance of quality\nranking, the complementary nature of quality criteria, and their low\ncorrelation with perplexity, analyzing misalignment between PPL and ICL\nperformance. We also thoroughly analyzed our pre-training dataset, examining\nits composition, the distribution of quality ratings, and the original document\nsources.",
      "tldr_zh": "这篇论文介绍了 DataMan，一种数据管理器，用于优化大型语言模型 (LLMs) 的预训练数据选择，以解决现有方法依赖启发式和人类直觉的局限性。DataMan 通过“逆向思考”从 perplexity (PPL) 的异常原因衍生出14个质量标准和15个应用领域，并训练模型对447B token的语料进行质量评分和领域识别。实验结果显示，使用 DataMan 选择的30B tokens 训练一个1.3B参数的语言模型，在 in-context learning (ICL)、PPL 和指令遵循能力上显著优于基线模型，且基于整体评分 l=5 的最佳模型超过了使用50%更多数据的均匀采样模型。该研究强调了数据质量排名的关键作用、质量标准的互补性，以及它们与 PPL 的低相关性，为高效的预训练策略提供了新指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2502.19363v3",
      "published_date": "2025-02-26 18:01:19 UTC",
      "updated_date": "2025-04-08 03:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:10:32.991173"
    },
    {
      "arxiv_id": "2502.19357v1",
      "title": "Physics-Based Hybrid Machine Learning for Critical Heat Flux Prediction with Uncertainty Quantification",
      "title_zh": "基于物理的混合机器学习用于临界热通量预测及不确定性量化",
      "authors": [
        "Aidan Furlong",
        "Xingang Zhao",
        "Robert Salko",
        "Xu Wu"
      ],
      "abstract": "Critical heat flux is a key quantity in boiling system modeling due to its\nimpact on heat transfer and component temperature and performance. This study\ninvestigates the development and validation of an uncertainty-aware hybrid\nmodeling approach that combines machine learning with physics-based models in\nthe prediction of critical heat flux in nuclear reactors for cases of dryout.\nTwo empirical correlations, Biasi and Bowring, were employed with three machine\nlearning uncertainty quantification techniques: deep neural network ensembles,\nBayesian neural networks, and deep Gaussian processes. A pure machine learning\nmodel without a base model served as a baseline for comparison. This study\nexamines the performance and uncertainty of the models under both plentiful and\nlimited training data scenarios using parity plots, uncertainty distributions,\nand calibration curves. The results indicate that the Biasi hybrid deep neural\nnetwork ensemble achieved the most favorable performance (with a mean absolute\nrelative error of 1.846% and stable uncertainty estimates), particularly in the\nplentiful data scenario. The Bayesian neural network models showed slightly\nhigher error and uncertainty but superior calibration. By contrast, deep\nGaussian process models underperformed by most metrics. All hybrid models\noutperformed pure machine learning configurations, demonstrating resistance\nagainst data scarcity.",
      "tldr_zh": "本研究开发了一种基于物理模型的混合机器学习方法，用于预测核反应堆中 Critical Heat Flux 的不确定性量化问题，旨在提升沸腾系统建模的准确性和可靠性。方法结合了 Biasi 和 Bowring 经验相关性，以及深度神经网络集合、贝叶斯神经网络和深度高斯过程等技术，并与纯机器学习模型进行对比。结果表明，Biasi 混合深度神经网络集合在数据充足场景下表现出色，平均绝对相对误差仅为1.846%，不确定性估计稳定，而所有混合模型均优于纯机器学习配置，尤其在数据稀缺情况下显示出更强的抵抗力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to the International Journal of Heat and Mass Transfer",
      "pdf_url": "http://arxiv.org/pdf/2502.19357v1",
      "published_date": "2025-02-26 17:55:01 UTC",
      "updated_date": "2025-02-26 17:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:10:43.178149"
    },
    {
      "arxiv_id": "2502.19351v1",
      "title": "Deep Learning-Based Transfer Learning for Classification of Cassava Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Ademir G. Costa Junior",
        "Fábio S. da Silva",
        "Ricardo Rios"
      ],
      "abstract": "This paper presents a performance comparison among four Convolutional Neural\nNetwork architectures (EfficientNet-B3, InceptionV3, ResNet50, and VGG16) for\nclassifying cassava disease images. The images were sourced from an imbalanced\ndataset from a competition. Appropriate metrics were employed to address class\nimbalance. The results indicate that EfficientNet-B3 achieved on this task\naccuracy of 87.7%, precision of 87.8%, revocation of 87.8% and F1-Score of\n87.7%. These findings suggest that EfficientNet-B3 could be a valuable tool to\nsupport Digital Agriculture.",
      "tldr_zh": "这篇论文比较了四个卷积神经网络架构（EfficientNet-B3, InceptionV3, ResNet50 和 VGG16）在木薯病害图像分类中的性能，使用迁移学习方法处理来自不平衡数据集的图像，并采用适当指标（如准确率、精确率、召回率和 F1-Score）来评估。\n结果显示，EfficientNet-B3 表现最佳，达到了 87.7% 的准确率、87.8% 的精确率、87.8% 的召回率和 87.7% 的 F1-Score。\n这些发现证明了 EfficientNet-B3 在数字农业中的潜在应用价值，可作为支持病害分类的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "I.5.1; I.5.4"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, in Portuguese language, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19351v1",
      "published_date": "2025-02-26 17:50:01 UTC",
      "updated_date": "2025-02-26 17:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:10:57.620194"
    },
    {
      "arxiv_id": "2502.19347v1",
      "title": "Controlled Diversity: Length-optimized Natural Language Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Diana Marie Schenke",
        "Timo Baumann"
      ],
      "abstract": "LLMs are not generally able to adjust the length of their outputs based on\nstrict length requirements, a capability that would improve their usefulness in\napplications that require adherence to diverse user and system requirements. We\npresent an approach to train LLMs to acquire this capability by augmenting\nexisting data and applying existing fine-tuning techniques, which we compare\nbased on the trained models' adherence to the length requirement and overall\nresponse quality relative to the baseline model. Our results demonstrate that\nthese techniques can be successfully applied to train LLMs to adhere to length\nrequirements, with the trained models generating texts which better align to\nthe length requirements. Our results indicate that our method may change the\nresponse quality when using training data that was not generated by the\nbaseline model. This allows simultaneous alignment to another training\nobjective in certain scenarios, but is undesirable otherwise. Training on a\ndataset containing the model's own responses eliminates this issue.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）无法根据严格长度要求调整输出的问题，提出了一种通过数据增强和现有微调技术来训练模型的方法，以优化自然语言生成的长度控制。实验比较了不同技术的效果，显示训练后的模型在遵守长度要求方面明显优于基线模型，同时保持了整体响应质量。结果表明，使用非模型自身生成的训练数据可能改变响应质量，而采用包含模型自身响应的数据集能有效避免这一问题，从而实现更可靠的长度优化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ISCA/ITG Workshop on Diversity in Large Speech and Language Models",
      "pdf_url": "http://arxiv.org/pdf/2502.19347v1",
      "published_date": "2025-02-26 17:38:58 UTC",
      "updated_date": "2025-02-26 17:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:11:06.112704"
    },
    {
      "arxiv_id": "2502.19334v1",
      "title": "Joint Optimal Transport and Embedding for Network Alignment",
      "title_zh": "联合最优传输与嵌入的网络对齐",
      "authors": [
        "Qi Yu",
        "Zhichen Zeng",
        "Yuchen Yan",
        "Lei Ying",
        "R. Srikant",
        "Hanghang Tong"
      ],
      "abstract": "Network alignment, which aims to find node correspondence across different\nnetworks, is the cornerstone of various downstream multi-network and Web mining\ntasks. Most of the embedding-based methods indirectly model cross-network node\nrelationships by contrasting positive and negative node pairs sampled from\nhand-crafted strategies, which are vulnerable to graph noises and lead to\npotential misalignment of nodes. Another line of work based on the optimal\ntransport (OT) theory directly models cross-network node relationships and\ngenerates noise-reduced alignments. However, OT methods heavily rely on fixed,\npre-defined cost functions that prohibit end-to-end training and are hard to\ngeneralize. In this paper, we aim to unify the embedding and OT-based methods\nin a mutually beneficial manner and propose a joint optimal transport and\nembedding framework for network alignment named JOENA. For one thing (OT for\nembedding), through a simple yet effective transformation, the noise-reduced OT\nmapping serves as an adaptive sampling strategy directly modeling all\ncross-network node pairs for robust embedding learning.For another (embedding\nfor OT), on top of the learned embeddings, the OT cost can be gradually trained\nin an end-to-end fashion, which further enhances the alignment quality. With a\nunified objective, the mutual benefits of both methods can be achieved by an\nalternating optimization schema with guaranteed convergence. Extensive\nexperiments on real-world networks validate the effectiveness and scalability\nof JOENA, achieving up to 16% improvement in MRR and 20x speedup compared with\nthe state-of-the-art alignment methods.",
      "tldr_zh": "该论文提出了一种名为 JOENA 的联合最优传输（optimal transport, OT）和嵌入（embedding）框架，用于网络对齐（network alignment），旨在解决现有方法易受噪声影响和缺乏端到端训练的问题。JOENA 通过 OT 映射作为自适应采样策略来增强嵌入学习，从而直接建模所有跨网络节点关系；同时，利用学到的嵌入来优化 OT 成本，实现端到端训练并提升对齐质量。实验在真实网络上验证了框架的有效性，比最先进方法提高了 MRR 多达 16%，并实现了 20 倍的加速。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19334v1",
      "published_date": "2025-02-26 17:28:08 UTC",
      "updated_date": "2025-02-26 17:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:11:18.236414"
    },
    {
      "arxiv_id": "2502.19328v1",
      "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Peng",
        "Yunjia Qi",
        "Xiaozhi Wang",
        "Zijun Yao",
        "Bin Xu",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Reward models (RMs) are crucial for the training and inference-time scaling\nup of large language models (LLMs). However, existing reward models primarily\nfocus on human preferences, neglecting verifiable correctness signals which\nhave shown strong potential in training LLMs. In this paper, we propose agentic\nreward modeling, a reward system that combines reward models with verifiable\ncorrectness signals from different aspects to provide reliable rewards. We\nempirically implement a reward agent, named RewardAgent, that combines human\npreference rewards with two verifiable signals: factuality and instruction\nfollowing, to provide more reliable rewards. We conduct comprehensive\nexperiments on existing reward model benchmarks and inference time best-of-n\nsearches on real-world downstream tasks. RewardAgent significantly outperforms\nvanilla reward models, demonstrating its effectiveness. We further construct\ntraining preference pairs using RewardAgent and train an LLM with the DPO\nobjective, achieving superior performance on various NLP benchmarks compared to\nconventional reward models. Our codes are publicly released to facilitate\nfurther research (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "tldr_zh": "这篇论文提出了 agentic reward modeling，一种将人类偏好与可验证正确性信号（如事实性和指令遵循）相结合的奖励系统，用于提升大型语言模型(LLMs)的奖励模型(RMs)可靠性。作者实现了名为 RewardAgent 的奖励代理，通过整合这些信号，提供更可靠的奖励，并在现有基准测试和真实下游任务的 best-of-n 搜索中显著优于传统模型。进一步实验显示，使用 RewardAgent 构建的偏好数据训练 LLM 时，采用 DPO 目标在各种 NLP 基准上取得了优越性能，并开源了代码以促进研究（https://github.com/THU-KEG/Agentic-Reward-Modeling）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19328v1",
      "published_date": "2025-02-26 17:19:12 UTC",
      "updated_date": "2025-02-26 17:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:11:30.989152"
    },
    {
      "arxiv_id": "2502.19325v1",
      "title": "Partition Tree Weighting for Non-Stationary Stochastic Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Veness",
        "Marcus Hutter",
        "Andras Gyorgy",
        "Jordi Grau-Moya"
      ],
      "abstract": "This paper considers a generalisation of universal source coding for\ninteraction data, namely data streams that have actions interleaved with\nobservations. Our goal will be to construct a coding distribution that is both\nuniversal \\emph{and} can be used as a control policy. Allowing for action\ngeneration needs careful treatment, as naive approaches which do not\ndistinguish between actions and observations run into the self-delusion problem\nin universal settings. We showcase our perspective in the context of the\nchallenging non-stationary stochastic Bernoulli bandit problem. Our main\ncontribution is an efficient and high performing algorithm for this problem\nthat generalises the Partition Tree Weighting universal source coding technique\nfor passive prediction to the control setting.",
      "tldr_zh": "这篇论文将通用源编码扩展到交互数据流（包括动作和观察），目标是构建一个既通用的编码分布又能用作控制策略的算法，以避免自欺问题（self-delusion problem）。论文针对非平稳随机伯努瓦赌博机（Non-Stationary Stochastic Bandits）问题，提出了一种高效算法，将Partition Tree Weighting技术从被动预测推广到控制设置。实验结果显示，该算法在复杂交互环境中表现出色，提供了一种高性能的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19325v1",
      "published_date": "2025-02-26 17:16:33 UTC",
      "updated_date": "2025-02-26 17:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:11:41.022540"
    },
    {
      "arxiv_id": "2502.19320v2",
      "title": "Shh, don't say that! Domain Certification in LLMs",
      "title_zh": "嘘，别说那个！大型语言模型中的领域认证",
      "authors": [
        "Cornelius Emde",
        "Alasdair Paren",
        "Preetham Arvind",
        "Maxime Kayser",
        "Tom Rainforth",
        "Thomas Lukasiewicz",
        "Bernard Ghanem",
        "Philip H. S. Torr",
        "Adel Bibi"
      ],
      "abstract": "Large language models (LLMs) are often deployed to perform constrained tasks,\nwith narrow domains. For example, customer support bots can be built on top of\nLLMs, relying on their broad language understanding and capabilities to enhance\nperformance. However, these LLMs are adversarially susceptible, potentially\ngenerating outputs outside the intended domain. To formalize, assess, and\nmitigate this risk, we introduce domain certification; a guarantee that\naccurately characterizes the out-of-domain behavior of language models. We then\npropose a simple yet effective approach, which we call VALID that provides\nadversarial bounds as a certificate. Finally, we evaluate our method across a\ndiverse set of datasets, demonstrating that it yields meaningful certificates,\nwhich bound the probability of out-of-domain samples tightly with minimum\npenalty to refusal behavior.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在特定领域任务（如客户支持）中的风险，引入了domain certification概念，以正式化评估和缓解模型生成域外输出的问题。作者提出了一种简单有效的VALID方法，利用adversarial bounds作为证书，来提供对域外样本概率的紧密边界，同时最小化拒绝行为。实验结果显示，在多种数据集上，VALID方法显著提升了模型的安全性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, includes appendix Published in International Conference on\n  Learning Representations (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19320v2",
      "published_date": "2025-02-26 17:13:19 UTC",
      "updated_date": "2025-03-06 21:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:11:52.256532"
    },
    {
      "arxiv_id": "2502.19312v1",
      "title": "FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users",
      "title_zh": "翻译失败",
      "authors": [
        "Anikait Singh",
        "Sheryl Hsu",
        "Kyle Hsu",
        "Eric Mitchell",
        "Stefano Ermon",
        "Tatsunori Hashimoto",
        "Archit Sharma",
        "Chelsea Finn"
      ],
      "abstract": "Effective personalization of LLMs is critical for a broad range of\nuser-interfacing applications such as virtual assistants and content curation.\nInspired by the strong in-context learning capabilities of LLMs, we propose\nFew-Shot Preference Optimization (FSPO), which reframes reward modeling as a\nmeta-learning problem. Under this framework, an LLM learns to quickly adapt to\na user via a few labeled preferences from that user, constructing a\npersonalized reward function for them. Additionally, since real-world\npreference data is scarce and challenging to collect at scale, we propose\ncareful design choices to construct synthetic preference datasets for\npersonalization, generating over 1M synthetic personalized preferences using\npublicly available LLMs. In particular, to successfully transfer from synthetic\ndata to real users, we find it crucial for the data to exhibit both high\ndiversity and coherent, self-consistent structure. We evaluate FSPO on\npersonalized open-ended generation for up to 1,500 synthetic users across\nacross three domains: movie reviews, pedagogical adaptation based on\neducational background, and general question answering, along with a controlled\nhuman study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in\ngenerating responses that are personalized to synthetic users and a 72% winrate\nwith real human users in open-ended question answering.",
      "tldr_zh": "本研究提出 Few-Shot Preference Optimization (FSPO)，一种将奖励建模重新框架为元学习问题的方法，允许大型语言模型(LLMs)通过少量用户偏好标签快速适应并构建个性化的奖励函数，从而实现有效的人性化应用。针对真实偏好数据的稀缺性，论文设计了合成偏好数据集，使用公开LLMs生成超过1M条多样且一致的合成数据，以促进从合成到真实用户的转移。实验在电影评论、教育适应和一般问答等领域评估了FSPO，结果显示其在1500个合成用户上平均达到87%的Alpaca Eval胜率，在真实人类用户问答中达到72%的胜率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://fewshot-preference-optimization.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.19312v1",
      "published_date": "2025-02-26 17:08:46 UTC",
      "updated_date": "2025-02-26 17:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:12:04.580257"
    },
    {
      "arxiv_id": "2502.19311v1",
      "title": "Faithful Logic Embeddings in HOL -- A recipe to have it all: deep and shallow, automated and interactive, heavy and light, proofs and counterexamples, meta and object level",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Benzmüller"
      ],
      "abstract": "Deep and shallow embeddings of non-classical logics in classical higher-order\nlogic have been explored, implemented, and used in various automated reasoning\ntools in recent years. This paper presents a recipe for the simultaneous\ndeployment of different forms of deep and shallow embeddings in classical\nhigher-order logic, enabling not only flexible interactive and automated\ntheorem proving and counterexample finding at meta and object level, but also\nautomated faithfulness proofs between the logic embeddings. The approach, which\nis fruitful for logic education, research and application, is deliberately\nillustrated here using simple propositional modal logic. However, the work\npresented is conceptual in nature and not limited to such a simple logic\ncontext.",
      "tldr_zh": "这篇论文提出了一种配方，用于在经典高阶逻辑(HOL)中同时部署深层和浅层嵌入，允许灵活处理非经典逻辑的嵌入形式。\n这种方法支持交互式和自动定理证明、反例发现，以及在元级和对象级进行自动忠诚度证明(faithful proofs)，从而实现证明和反例的全面应用。\n作者以简单命题模态逻辑为例，展示了该方法的概念性优势，并强调其在逻辑教育、研究和实际应用中的广泛潜力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "math.LO",
        "03Axx, 03Bxx, 03B15, 68T15",
        "F.4; I.2.3; I.2.4"
      ],
      "primary_category": "cs.LO",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19311v1",
      "published_date": "2025-02-26 17:08:07 UTC",
      "updated_date": "2025-02-26 17:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:12:17.192659"
    },
    {
      "arxiv_id": "2502.19308v2",
      "title": "WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "William Solow",
        "Sandhya Saisubramanian",
        "Alan Fern"
      ],
      "abstract": "We introduce WOFOSTGym, a novel crop simulation environment designed to train\nreinforcement learning (RL) agents to optimize agromanagement decisions for\nannual and perennial crops in single and multi-farm settings. Effective crop\nmanagement requires optimizing yield and economic returns while minimizing\nenvironmental impact, a complex sequential decision-making problem well suited\nfor RL. However, the lack of simulators for perennial crops in multi-farm\ncontexts has hindered RL applications in this domain. Existing crop simulators\nalso do not support multiple annual crops. WOFOSTGym addresses these gaps by\nsupporting 23 annual crops and two perennial crops, enabling RL agents to learn\ndiverse agromanagement strategies in multi-year, multi-crop, and multi-farm\nsettings. Our simulator offers a suite of challenging tasks for learning under\npartial observability, non-Markovian dynamics, and delayed feedback.\nWOFOSTGym's standard RL interface allows researchers without agricultural\nexpertise to explore a wide range of agromanagement problems. Our experiments\ndemonstrate the learned behaviors across various crop varieties and soil types,\nhighlighting WOFOSTGym's potential for advancing RL-driven decision support in\nagriculture.",
      "tldr_zh": "该研究引入 WOFOSTGym，这是一个新型作物模拟环境，用于训练强化学习 (RL) 代理优化年度和多年生作物的农业管理策略，包括单农场和多农场场景。WOFOSTGym 支持 23 种年度作物和两种多年生作物，填补了现有模拟器在多作物和多年来决策方面的空白，并提供挑战性任务如部分可观察性、非马尔可夫动态和延迟反馈。实验结果展示了 RL 代理在不同作物品种和土壤类型下的学习行为，突显其在推进农业决策支持方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19308v2",
      "published_date": "2025-02-26 17:07:11 UTC",
      "updated_date": "2025-02-27 03:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:12:29.391175"
    },
    {
      "arxiv_id": "2502.19307v1",
      "title": "Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Somma",
        "Thomas Gallien",
        "Branka Stojanovic"
      ],
      "abstract": "Anomaly detection in complex dynamical systems is essential for ensuring\nreliability, safety, and efficiency in industrial and cyber-physical\ninfrastructures. Predictive maintenance helps prevent costly failures, while\ncybersecurity monitoring has become critical as digitized systems face growing\nthreats. Many of these systems exhibit oscillatory behaviors and bounded\nmotion, requiring anomaly detection methods that capture structured temporal\ndependencies while adhering to physical consistency principles. In this work,\nwe propose a system-theoretic approach to anomaly detection, grounded in\nclassical embedding theory and physics-inspired consistency principles. We\nbuild upon the Fractal Whitney Embedding Prevalence Theorem, extending\ntraditional embedding techniques to complex system dynamics. Additionally, we\nintroduce state-derivative pairs as an embedding strategy to capture system\nevolution. To enforce temporal coherence, we develop a Temporal Differential\nConsistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the\napproximated derivatives of latent variables with their dynamic\nrepresentations. We evaluate our method on the C-MAPSS dataset, a benchmark for\nturbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers\nwhile achieving a 200x reduction in MAC operations, making it particularly\nsuited for lightweight edge computing. Our findings support the hypothesis that\nanomalies disrupt stable system dynamics, providing a robust, interpretable\nsignal for anomaly detection.",
      "tldr_zh": "本研究提出一个基于嵌入理论(Embedding Theory)和物理启发一致性(Physics-Inspired Consistency)的系统框架，用于复杂动态系统的异常检测，以提升工业和网络物理基础设施的可靠性、安全和效率。该框架扩展了Fractal Whitney Embedding Prevalence Theorem，并引入状态导数对作为嵌入策略，同时开发了Temporal Differential Consistency Autoencoder (TDC-AE)，通过TDC-Loss确保潜变量的动态表示与时间一致性。实验在C-MAPSS数据集上验证了该方法，TDC-AE在涡轮风扇航空发动机退化检测中优于LSTM和Transformer，同时减少200倍的MAC操作，证明异常会破坏稳定系统动态，提供鲁棒且可解释的检测信号。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19307v1",
      "published_date": "2025-02-26 17:06:13 UTC",
      "updated_date": "2025-02-26 17:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:12:55.094242"
    },
    {
      "arxiv_id": "2502.19305v1",
      "title": "Corporate Fraud Detection in Rich-yet-Noisy Financial Graph",
      "title_zh": "基于丰富却嘈杂的金融图的公司欺诈",
      "authors": [
        "Shiqi Wang",
        "Zhibo Zhang",
        "Libing Fang",
        "Cam-Tu Nguyen",
        "Wenzhon Li"
      ],
      "abstract": "Corporate fraud detection aims to automatically recognize companies that\nconduct wrongful activities such as fraudulent financial statements or illegal\ninsider trading. Previous learning-based methods fail to effectively integrate\nrich interactions in the company network. To close this gap, we collect 18-year\nfinancial records in China to form three graph datasets with fraud labels. We\nanalyze the characteristics of the financial graphs, highlighting two\npronounced issues: (1) information overload: the dominance of (noisy)\nnon-company nodes over company nodes hinders the message-passing process in\nGraph Convolution Networks (GCN); and (2) hidden fraud: there exists a large\npercentage of possible undetected violations in the collected data. The hidden\nfraud problem will introduce noisy labels in the training dataset and\ncompromise fraud detection results. To handle such challenges, we propose a\nnovel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage\nLearning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to\nmitigate the information overload and effectively learns rich representations.\nThe proposed model adopts a two-stage learning method to enhance robustness\nagainst hidden frauds. Extensive experimental results not only confirm the\nimportance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$\nover a number of strong baselines in terms of fraud detection effectiveness and\nrobustness.",
      "tldr_zh": "这篇论文针对公司欺诈检测问题，提出了一种处理富含噪声金融图谱的方法，分析了信息过载（非公司节点主导影响GCN消息传递）和隐藏欺诈（导致噪声标签）的关键挑战。作者基于中国18年财务数据构建了三个图数据集，并开发了${\\rm KeGCN}_{R}$模型，该模型利用Knowledge Graph Embeddings缓解信息过载，并采用两阶段学习策略提升对隐藏欺诈的鲁棒性。实验结果表明，${\\rm KeGCN}_{R}$在欺诈检测效果和鲁棒性上显著优于基线模型，突出了公司网络互动的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19305v1",
      "published_date": "2025-02-26 17:05:54 UTC",
      "updated_date": "2025-02-26 17:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:12:54.195564"
    },
    {
      "arxiv_id": "2503.00053v1",
      "title": "AI and Semantic Communication for Infrastructure Monitoring in 6G-Driven Drone Swarms",
      "title_zh": "人工智能与语义通信在6G驱动的无人机群中用于基础设施监测",
      "authors": [
        "Tasnim Ahmed",
        "Salimur Choudhury"
      ],
      "abstract": "The adoption of unmanned aerial vehicles to monitor critical infrastructure\nis gaining momentum in various industrial domains. Organizational imperatives\ndrive this progression to minimize expenses, accelerate processes, and mitigate\nhazards faced by inspection personnel. However, traditional infrastructure\nmonitoring systems face critical bottlenecks-5G networks lack the latency and\nreliability for large-scale drone coordination, while manual inspections remain\ncostly and slow. We propose a 6G-enabled drone swarm system that integrates\nultra-reliable, low-latency communications, edge AI, and semantic communication\nto automate inspections. By adopting LLMs for structured output and report\ngeneration, our framework is hypothesized to reduce inspection costs and\nimprove fault detection speed compared to existing methods.",
      "tldr_zh": "本研究针对传统基础设施监控的瓶颈（如5G网络的延迟和可靠性问题，以及手动检查的成本和速度问题），提出了一种基于6G驱动的无人机群系统。系统整合了ultra-reliable, low-latency communications、edge AI和semantic communication，以实现自动化检查。利用LLMs生成结构化输出和报告，该框架假设能降低检查成本并提高故障检测速度，从而提升整体效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00053v1",
      "published_date": "2025-02-26 17:05:35 UTC",
      "updated_date": "2025-02-26 17:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:13:06.602558"
    },
    {
      "arxiv_id": "2502.19297v1",
      "title": "Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhilesh Prabhakar",
        "Ranveer Singh",
        "Harsha Kokel",
        "Sriraam Natarajan",
        "Prasad Tadepalli"
      ],
      "abstract": "Multiagent Reinforcement Learning (MARL) poses significant challenges due to\nthe exponential growth of state and action spaces and the non-stationary nature\nof multiagent environments. This results in notable sample inefficiency and\nhinders generalization across diverse tasks. The complexity is further\npronounced in relational settings, where domain knowledge is crucial but often\nunderutilized by existing MARL algorithms. To overcome these hurdles, we\npropose integrating relational planners as centralized controllers with\nefficient state abstractions and reinforcement learning. This approach proves\nto be sample-efficient and facilitates effective task transfer and\ngeneralization.",
      "tldr_zh": "这篇论文针对多智能体强化学习 (MARL) 的挑战，包括状态和动作空间的指数增长、非平稳环境导致的样本效率低下以及任务泛化困难，尤其在关系域中，论文提出了一种整合关系规划器作为集中控制器的创新方法。 该方法结合高效状态抽象和强化学习 (Reinforcement Learning)，显著提高了样本效率，并促进了任务转移和泛化。 总体上，这一方法为解决复杂多智能体环境提供了更有效的框架。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19297v1",
      "published_date": "2025-02-26 16:55:23 UTC",
      "updated_date": "2025-02-26 16:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:13:18.225166"
    },
    {
      "arxiv_id": "2502.19295v1",
      "title": "Complex LLM Planning via Automated Heuristics Discovery",
      "title_zh": "通过自动启发式发现的复杂 LLM 规划",
      "authors": [
        "Hongyi Ling",
        "Shubham Parashar",
        "Sambhav Khurana",
        "Blake Olson",
        "Anwesha Basu",
        "Gaurangi Sinha",
        "Zhengzhong Tu",
        "James Caverlee",
        "Shuiwang Ji"
      ],
      "abstract": "We consider enhancing large language models (LLMs) for complex planning\ntasks. While existing methods allow LLMs to explore intermediate steps to make\nplans, they either depend on unreliable self-verification or external verifiers\nto evaluate these steps, which demand significant data and computations. Here,\nwe propose automated heuristics discovery (AutoHD), a novel approach that\nenables LLMs to explicitly generate heuristic functions to guide inference-time\nsearch, allowing accurate evaluation of intermediate states. These heuristic\nfunctions are further refined through a heuristic evolution process, improving\ntheir robustness and effectiveness. Our proposed method requires no additional\nmodel training or fine-tuning, and the explicit definition of heuristic\nfunctions generated by the LLMs provides interpretability and insights into the\nreasoning process. Extensive experiments across diverse benchmarks demonstrate\nsignificant gains over multiple baselines, including nearly twice the accuracy\non some datasets, establishing our approach as a reliable and interpretable\nsolution for complex planning tasks.",
      "tldr_zh": "本研究提出 Automated Heuristics Discovery (AutoHD)，一种无需额外模型训练的方法，用于增强大型语言模型 (LLMs) 在复杂规划任务中的性能。该方法让 LLMs 显式生成启发式函数 (heuristic functions) 来指导推理时的搜索，并通过启发式演化过程 (heuristic evolution process) 优化这些函数，从而实现对中间状态的准确评估。相比现有依赖自验证或外部验证器的方案，AutoHD 提供更高的可解释性和鲁棒性。在多个基准测试中，该方法显著提升准确率，比基线模型高出近两倍，证明了其在复杂规划任务中的可靠性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19295v1",
      "published_date": "2025-02-26 16:52:31 UTC",
      "updated_date": "2025-02-26 16:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:13:30.825969"
    },
    {
      "arxiv_id": "2503.00052v1",
      "title": "RURA-Net: A general disease diagnosis method based on Zero-Shot Learning",
      "title_zh": "RURA-Net：一种基于零样本学习的通用疾病诊断方法",
      "authors": [
        "Yan Su",
        "Qiulin Wu",
        "Weizhen Li",
        "Chengchang Pan",
        "Honggang Qi"
      ],
      "abstract": "The training of deep learning models relies on a large amount of labeled\ndata. However, the high cost of medical labeling seriously hinders the\ndevelopment of deep learning in the medical field. Our study proposes a general\ndisease diagnosis approach based on Zero-Shot Learning. The Siamese neural\nnetwork is used to find similar diseases for the target diseases, and the U-Net\nsegmentation model is used to accurately segment the key lesions of the\ndisease. Finally, based on the ResNet-Agglomerative clustering algorithm, a\nclustering model is trained on a large number of sample data of similar\ndiseases to obtain a approximate diagnosis of the target disease. Zero-Shot\nLearning of the target disease is then successfully achieved. To evaluate the\nvalidity of the model, we validated our method on a dataset of ophthalmic\ndiseases in CFP modality. The external dataset was used to test its\nperformance, and the accuracy=0.8395, precision=0.8094, recall=0.8463, F1\nScore=0.8274, AUC=0.9226, which exceeded the indexes of most Few-Shot Learning\nand One-Shot Learning models. It proves that our method has great potential and\nreference value in the medical field, where annotation data is usually scarce\nand expensive to obtain.",
      "tldr_zh": "本研究提出RURA-Net，一种基于Zero-Shot Learning的通用疾病诊断方法，以解决医疗领域标注数据稀缺和高成本问题。该方法利用Siamese神经网络识别目标疾病的相似疾病，结合U-Net模型精确分割关键病变，并通过ResNet-Agglomerative聚类算法在相似疾病样本上训练聚类模型，实现对目标疾病的近似诊断和Zero-Shot Learning。实验在眼科疾病数据集（CFP模式）上验证，模型的准确率达到0.8395、精确率0.8094、召回率0.8463、F1分数0.8274和AUC 0.9226，超过了大多数Few-Shot Learning和One-Shot Learning模型。该方法展示了在标注数据有限的医疗场景中的巨大潜力和实际应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures, 6 tables, submitted to The 28th International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.00052v1",
      "published_date": "2025-02-26 16:41:32 UTC",
      "updated_date": "2025-02-26 16:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:13:43.187372"
    },
    {
      "arxiv_id": "2502.19281v1",
      "title": "Integrating Biological and Machine Intelligence: Attention Mechanisms in Brain-Computer Interfaces",
      "title_zh": "整合生物智能与机器智能：脑机接口中的注意力机制",
      "authors": [
        "Jiyuan Wang",
        "Weishan Ye",
        "Jialin He",
        "Li Zhang",
        "Gan Huang",
        "Zhuliang Yu",
        "Zhen Liang"
      ],
      "abstract": "With the rapid advancement of deep learning, attention mechanisms have become\nindispensable in electroencephalography (EEG) signal analysis, significantly\nenhancing Brain-Computer Interface (BCI) applications. This paper presents a\ncomprehensive review of traditional and Transformer-based attention mechanisms,\ntheir embedding strategies, and their applications in EEG-based BCI, with a\nparticular emphasis on multimodal data fusion. By capturing EEG variations\nacross time, frequency, and spatial channels, attention mechanisms improve\nfeature extraction, representation learning, and model robustness. These\nmethods can be broadly categorized into traditional attention mechanisms, which\ntypically integrate with convolutional and recurrent networks, and\nTransformer-based multi-head self-attention, which excels in capturing\nlong-range dependencies. Beyond single-modality analysis, attention mechanisms\nalso enhance multimodal EEG applications, facilitating effective fusion between\nEEG and other physiological or sensory data. Finally, we discuss existing\nchallenges and emerging trends in attention-based EEG modeling, highlighting\nfuture directions for advancing BCI technology. This review aims to provide\nvaluable insights for researchers seeking to leverage attention mechanisms for\nimproved EEG interpretation and application.",
      "tldr_zh": "这篇论文回顾了注意力机制（attention mechanisms）在脑机接口（BCI）中的应用，特别是在脑电图（EEG）信号分析中如何提升模型性能。论文将注意力机制分为传统类型（与卷积和循环网络整合）和Transformer-based多头自注意力（multi-head self-attention），强调它们在捕捉时间、频率和空间通道变异方面的优势，并促进多模态数据融合。研究发现，这些机制显著提高了特征提取、表示学习和模型鲁棒性，尤其在EEG与其他生理数据的结合中。最终，论文讨论了现有挑战和未来趋势，为研究者提供利用注意力机制改进BCI技术的宝贵见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19281v1",
      "published_date": "2025-02-26 16:38:28 UTC",
      "updated_date": "2025-02-26 16:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:13:54.040368"
    },
    {
      "arxiv_id": "2502.19271v1",
      "title": "Multiview graph dual-attention deep learning and contrastive learning for multi-criteria recommender systems",
      "title_zh": "多视图",
      "authors": [
        "Saman Forouzandeh",
        "Pavel N. Krivitsky",
        "Rohitash Chandra"
      ],
      "abstract": "Recommender systems leveraging deep learning models have been crucial for\nassisting users in selecting items aligned with their preferences and\ninterests. However, a significant challenge persists in single-criteria\nrecommender systems, which often overlook the diverse attributes of items that\nhave been addressed by Multi-Criteria Recommender Systems (MCRS). Shared\nembedding vector for multi-criteria item ratings but have struggled to capture\nthe nuanced relationships between users and items based on specific criteria.\nIn this study, we present a novel representation for Multi-Criteria Recommender\nSystems (MCRS) based on a multi-edge bipartite graph, where each edge\nrepresents one criterion rating of items by users, and Multiview Dual Graph\nAttention Networks (MDGAT). Employing MDGAT is beneficial and important for\nadequately considering all relations between users and items, given the\npresence of both local (criterion-based) and global (multi-criteria) relations.\nAdditionally, we define anchor points in each view based on similarity and\nemploy local and global contrastive learning to distinguish between positive\nand negative samples across each view and the entire graph. We evaluate our\nmethod on two real-world datasets and assess its performance based on item\nrating predictions. The results demonstrate that our method achieves higher\naccuracy compared to the baseline method for predicting item ratings on the\nsame datasets. MDGAT effectively capture the local and global impact of\nneighbours and the similarity between nodes.",
      "tldr_zh": "本文提出了一种基于多视图图双注意力网络(MDGAT)和对比学习的多标准推荐系统(MCRS)，旨在解决传统系统忽略物品多样属性的问题。通过构建多边双向图表示用户对物品的每个标准评分，并结合局部和全局对比学习来捕捉用户-物品间的局部（基于标准）和全局（多标准）关系。实验在两个真实数据集上评估，结果显示该方法在物品评分预测准确率上比基线模型显著提升，证明了MDGAT在处理邻居影响和节点相似性方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19271v1",
      "published_date": "2025-02-26 16:25:58 UTC",
      "updated_date": "2025-02-26 16:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:14:05.578426"
    },
    {
      "arxiv_id": "2503.05782v1",
      "title": "AI Mentors for Student Projects: Spotting Early Issues in Computer Science Proposals",
      "title_zh": "AI 导师用于学生项目：发现计算机科学提案中的早期问题",
      "authors": [
        "Gati Aher",
        "Robin Schmucker",
        "Tom Mitchell",
        "Zachary C. Lipton"
      ],
      "abstract": "When executed well, project-based learning (PBL) engages students' intrinsic\nmotivation, encourages students to learn far beyond a course's limited\ncurriculum, and prepares students to think critically and maturely about the\nskills and tools at their disposal. However, educators experience mixed results\nwhen using PBL in their classrooms: some students thrive with minimal guidance\nand others flounder. Early evaluation of project proposals could help educators\ndetermine which students need more support, yet evaluating project proposals\nand student aptitude is time-consuming and difficult to scale. In this work, we\ndesign, implement, and conduct an initial user study (n = 36) for a software\nsystem that collects project proposals and aptitude information to support\neducators in determining whether a student is ready to engage with PBL. We find\nthat (1) users perceived the system as helpful for writing project proposals\nand identifying tools and technologies to learn more about, (2) educator\nratings indicate that users with less technical experience in the project topic\ntend to write lower-quality project proposals, and (3) GPT-4o's ratings show\nagreement with educator ratings. While the prospect of using LLMs to rate the\nquality of students' project proposals is promising, its long-term\neffectiveness strongly hinges on future efforts at characterizing indicators\nthat reliably predict students' success and motivation to learn.",
      "tldr_zh": "这篇论文探讨了基于项目的学习（PBL）在计算机科学教育中的应用，强调早期评估学生项目提案可以帮助教育者识别需要支持的学生，但传统方法耗时难扩展。研究设计并实现了AI导师软件系统，通过收集项目提案和学生能力信息，并结合用户研究（n=36），评估学生的准备度。结果显示，该系统有助于学生写作提案和识别相关工具技术，且教育者评分与GPT-4o评分一致，表明LLMs在评估中具有潜力。然而，系统的长期有效性依赖于未来对可靠预测学生成功和动机的指标进行进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for oral presentation at Workshop on Innovation and\n  Responsibility in AI-Supported Education (iRAISE), AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.05782v1",
      "published_date": "2025-02-26 16:24:14 UTC",
      "updated_date": "2025-02-26 16:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:14:17.275047"
    },
    {
      "arxiv_id": "2503.01878v1",
      "title": "District Vitality Index Using Machine Learning Methods for Urban Planners",
      "title_zh": "基于机器学习方法的地区活力指数，用于城市规划者",
      "authors": [
        "Sylvain Marcoux",
        "Jean-Sébastien Dessureault"
      ],
      "abstract": "City leaders face critical decisions regarding budget allocation and\ninvestment priorities. How can they identify which city districts require\nrevitalization? To address this challenge, a Current Vitality Index and a\nLong-Term Vitality Index are proposed. These indexes are based on a carefully\ncurated set of indicators. Missing data is handled using K-Nearest Neighbors\nimputation, while Random Forest is employed to identify the most reliable and\nsignificant features. Additionally, k-means clustering is utilized to generate\nmeaningful data groupings for enhanced monitoring of Long-Term Vitality.\nCurrent vitality is visualized through an interactive map, while Long-Term\nVitality is tracked over 15 years with predictions made using Multilayer\nPerceptron or Linear Regression. The results, approved by urban planners, are\nalready promising and helpful, with the potential for further improvement as\nmore data becomes available. This paper proposes leveraging machine learning\nmethods to optimize urban planning and enhance citizens' quality of life.",
      "tldr_zh": "该研究针对城市领导者的预算分配和投资决策，提出Current Vitality Index和Long-Term Vitality Index，用于识别需要 revitalization 的城区。这些指数基于精心选择的指标，通过K-Nearest Neighbors imputation处理缺失数据，Random Forest筛选关键特征，并利用k-means clustering生成数据分组以提升长期监测。Current Vitality通过交互地图可视化，而Long-Term Vitality则通过Multilayer Perceptron或Linear Regression模型预测15年趋势，结果已获城市规划者认可，并显示出优化城市规划、提高市民生活质量的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01878v1",
      "published_date": "2025-02-26 16:17:38 UTC",
      "updated_date": "2025-02-26 16:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:14:28.366241"
    },
    {
      "arxiv_id": "2502.19261v2",
      "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Taishi Nakamura",
        "Takuya Akiba",
        "Kazuki Fujii",
        "Yusuke Oda",
        "Rio Yokota",
        "Jun Suzuki"
      ],
      "abstract": "The Mixture of Experts (MoE) architecture reduces the training and inference\ncost significantly compared to a dense model of equivalent capacity. Upcycling\nis an approach that initializes and trains an MoE model using a pre-trained\ndense model. While upcycling leads to initial performance gains, the training\nprogresses slower than when trained from scratch, leading to suboptimal\nperformance in the long term. We propose Drop-Upcycling - a method that\neffectively addresses this problem. Drop-Upcycling combines two seemingly\ncontradictory approaches: utilizing the knowledge of pre-trained dense models\nwhile statistically re-initializing some parts of the weights. This approach\nstrategically promotes expert specialization, significantly enhancing the MoE\nmodel's efficiency in knowledge acquisition. Extensive large-scale experiments\ndemonstrate that Drop-Upcycling significantly outperforms previous MoE\nconstruction methods in the long term, specifically when training on hundreds\nof billions of tokens or more. As a result, our MoE model with 5.9B active\nparameters achieves comparable performance to a 13B dense model in the same\nmodel family, while requiring approximately 1/4 of the training FLOPs. All\nexperimental resources, including source code, training data, model checkpoints\nand logs, are publicly available to promote reproducibility and future research\non MoE.",
      "tldr_zh": "本研究针对Mixture of Experts (MoE)模型的训练问题，提出Drop-Upcycling方法，该方法结合预训练密集模型的知识，同时部分重新初始化权重，以促进专家专业化并提升知识获取效率。相比传统Upcycling，Drop-Upcycling显著改善了长期训练性能，在数百亿tokens的规模实验中优于现有方法。结果表明，5.9B活跃参数的MoE模型可媲美13B密集模型，仅需约1/4的训练FLOPs，所有实验资源已公开以支持可复现性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.19261v2",
      "published_date": "2025-02-26 16:06:36 UTC",
      "updated_date": "2025-03-15 14:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:14:41.466023"
    },
    {
      "arxiv_id": "2502.19260v3",
      "title": "EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region",
      "title_zh": "翻译失败",
      "authors": [
        "Nadya Abdel Madjid",
        "Murad Mebrahtu",
        "Abdelmoamen Nasser",
        "Bilal Hassan",
        "Naoufel Werghi",
        "Jorge Dias",
        "Majid Khonji"
      ],
      "abstract": "This paper introduces the Emirates Multi-Task (EMT) dataset, designed to\nsupport multi-task benchmarking within a unified framework. It comprises over\n30,000 frames from a dash-camera perspective and 570,000 annotated bounding\nboxes, covering approximately 150 kilometers of driving routes that reflect the\ndistinctive road topology, congestion patterns, and driving behavior of Gulf\nregion traffic. The dataset supports three primary tasks: tracking, trajectory\nforecasting, and intention prediction. Each benchmark is accompanied by\ncorresponding evaluations: (1) multi-agent tracking experiments addressing\nmulti-class scenarios and occlusion handling; (2) trajectory forecasting\nevaluation using deep sequential and interaction-aware models; and (3)\nintention prediction experiments based on observed trajectories. The dataset is\npublicly available at https://avlab.io/emt-dataset, with pre-processing scripts\nand evaluation models at https://github.com/AV-Lab/emt-dataset.",
      "tldr_zh": "这篇论文介绍了EMT数据集，这是一个针对阿拉伯海湾地区自动驾驶的多任务视觉基准数据集，旨在支持统一的基准测试框架。数据集包含超过30,000帧图像和570,000个标注框，覆盖约150公里的驾驶路线，并反映了该地区的独特道路拓扑、拥堵模式和驾驶行为。EMT支持三大任务：tracking（跟踪）、trajectory forecasting（轨迹预测）和intention prediction（意图预测），并提供相应的评估，包括多代理跟踪实验、基于深度序列和交互感知模型的轨迹预测实验，以及基于观察轨迹的意图预测实验。该数据集及其预处理脚本和评估模型已在https://avlab.io/emt-dataset和https://github.com/AV-Lab/emt-dataset上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19260v3",
      "published_date": "2025-02-26 16:06:35 UTC",
      "updated_date": "2025-04-25 12:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:14:53.564189"
    },
    {
      "arxiv_id": "2502.19257v2",
      "title": "Poster: Long PHP webshell files detection based on sliding window attention",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Wang",
        "Haoyu Wang",
        "Lu Hao"
      ],
      "abstract": "Webshell is a type of backdoor, and web applications are widely exposed to\nwebshell injection attacks. Therefore, it is important to study webshell\ndetection techniques. In this study, we propose a webshell detection method. We\nfirst convert PHP source code to opcodes and then extract Opcode Double-Tuples\n(ODTs). Next, we combine CodeBert and FastText models for feature\nrepresentation and classification. To address the challenge that deep learning\nmethods have difficulty detecting long webshell files, we introduce a sliding\nwindow attention mechanism. This approach effectively captures malicious\nbehavior within long files. Experimental results show that our method reaches\nhigh accuracy in webshell detection, solving the problem of traditional methods\nthat struggle to address new webshell variants and anti-detection techniques.",
      "tldr_zh": "本研究针对 PHP webshell 检测的挑战，提出了一种基于滑动窗口注意力（sliding window attention）的检测方法。首先，将 PHP 源代码转换为 opcodes 并提取 Opcode Double-Tuples (ODTs)，然后结合 CodeBert 和 FastText 模型进行特征表示和分类，以有效捕捉长文件中的恶意行为。实验结果表明，该方法在 webshell 检测中达到了高准确率，成功解决了传统方法对新 webshell 变种和反检测技术的局限性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "3 pages(include 1 page poster), 1 figure. Accepted as a poster at the\n  NDSS 2025. Poster list:\n  http://www.ndss-symposium.org/ndss2025/accepted-posters/. Dataset/code\n  available at\n  http://github.com/w-32768/PHP-Webshell-Detection-via-Opcode-Analysis",
      "pdf_url": "http://arxiv.org/pdf/2502.19257v2",
      "published_date": "2025-02-26 16:04:17 UTC",
      "updated_date": "2025-02-27 12:36:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:15:05.020301"
    },
    {
      "arxiv_id": "2502.19255v3",
      "title": "Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Huang",
        "Bingcong Li",
        "Christoph Dann",
        "Niao He"
      ],
      "abstract": "Sample efficiency is critical for online Reinforcement Learning from Human\nFeedback (RLHF). While existing works investigate sample-efficient online\nexploration strategies, the potential of utilizing misspecified yet relevant\nreward models to accelerate learning remains underexplored. This paper studies\nhow to transfer knowledge from those imperfect reward models in online RLHF. We\nstart by identifying a novel property due to KL-regularization in the RLHF\nobjective: \\emph{a policy's coverability of the optimal policy is captured by\nits sub-optimality}. Building on this insight, we propose novel transfer\nlearning principles and a theoretical algorithm -- \\emph{\\textbf{T}ransfer\n\\textbf{P}olicy \\textbf{O}ptimization (\\textbf{TPO})} -- with provable benefits\ncompared to standard online learning. Empirically, inspired by our theoretical\nfindings, we develop a win-rate-based transfer policy selection strategy with\nimproved computational efficiency. Moreover, our empirical transfer learning\ntechnique is modular and can be integrated with various policy optimization\nmethods, such as DPO, IPO and XPO, to further enhance their performance. We\nvalidate the effectiveness of our method through experiments on summarization\ntasks.",
      "tldr_zh": "这篇论文探讨了在线强化学习从人类反馈（RLHF）的样本效率问题，特别关注如何利用不完美的奖励模型来加速学习。作者发现KL-regularization导致的属性，即策略的覆盖性与次优性相关，并据此提出转移学习原则和理论算法Transfer Policy Optimization (TPO)，证明了其比标准在线学习更具优势。实验结果显示，通过基于胜率的转移策略选择，该方法可模块化整合到DPO、IPO和XPO等优化算法中，并在摘要任务上显著提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "36 Pages; ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19255v3",
      "published_date": "2025-02-26 16:03:06 UTC",
      "updated_date": "2025-05-18 12:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:15:16.731958"
    },
    {
      "arxiv_id": "2502.19252v2",
      "title": "GraphBridge: Towards Arbitrary Transfer Learning in GNNs",
      "title_zh": "GraphBridge：",
      "authors": [
        "Li Ju",
        "Xingyi Yang",
        "Qi Li",
        "Xinchao Wang"
      ],
      "abstract": "Graph neural networks (GNNs) are conventionally trained on a per-domain,\nper-task basis. It creates a significant barrier in transferring the acquired\nknowledge to different, heterogeneous data setups. This paper introduces\nGraphBridge, a novel framework to enable knowledge transfer across disparate\ntasks and domains in GNNs, circumventing the need for modifications to task\nconfigurations or graph structures. Specifically, GraphBridge allows for the\naugmentation of any pre-trained GNN with prediction heads and a bridging\nnetwork that connects the input to the output layer. This architecture not only\npreserves the intrinsic knowledge of the original model but also supports\noutputs of arbitrary dimensions. To mitigate the negative transfer problem,\nGraphBridge merges the source model with a concurrently trained model, thereby\nreducing the source bias when applied to the target domain. Our method is\nthoroughly evaluated across diverse transfer learning scenarios, including\nGraph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical\nvalidation, conducted over 16 datasets representative of these scenarios,\nconfirms the framework's capacity for task- and domain-agnostic transfer\nlearning within graph-like data, marking a significant advancement in the field\nof GNNs. Code is available at https://github.com/jujulili888/GraphBridge.",
      "tldr_zh": "本研究提出GraphBridge框架，旨在实现图神经网络(GNNs)中任意的知识转移，克服传统GNNs按特定域和任务训练导致的知识迁移障碍。该框架通过在预训练GNN上添加预测头和桥接网络，同时合并源模型和目标模型来缓解负转移问题，从而保留原模型的内在知识并支持任意维度的输出。实验在包括Graph2Graph、Node2Node、Graph2Node和Graph2point-cloud等多种场景的16个数据集上进行，结果显示GraphBridge显著提升了任务和领域无关的转移学习性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, 6 tables, to be published in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19252v2",
      "published_date": "2025-02-26 15:57:51 UTC",
      "updated_date": "2025-03-01 16:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:15:29.566030"
    },
    {
      "arxiv_id": "2502.19249v1",
      "title": "Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Y. Hu",
        "Jackson Petty",
        "Chuan Shi",
        "William Merrill",
        "Tal Linzen"
      ],
      "abstract": "Pretraining language models on formal languages can improve their acquisition\nof natural language, but it is unclear which features of the formal language\nimpart an inductive bias that leads to effective transfer. Drawing on insights\nfrom linguistics and complexity theory, we hypothesize that effective transfer\noccurs when the formal language both captures dependency structures in natural\nlanguage and remains within the computational limitations of the model\narchitecture. Focusing on transformers, we find that formal languages with both\nthese properties enable language models to achieve lower loss on natural\nlanguage and better linguistic generalization compared to other languages. In\nfact, pre-pretraining, or training on formal-then-natural language, reduces\nloss more efficiently than the same amount of natural language. For a\n1B-parameter language model trained on roughly 1.6B tokens of natural language,\npre-pretraining achieves the same loss and better linguistic generalization\nwith a 33% smaller token budget. We also give mechanistic evidence of\ncross-task transfer from formal to natural language: attention heads acquired\nduring formal language pretraining remain crucial for the model's performance\non syntactic evaluations.",
      "tldr_zh": "本研究探讨了在形式语言上进行预预训练（pre-pretraining）如何赋予语言模型语言偏差，从而提升其对自然语言的获取效率。研究假设，有效的形式语言需捕捉自然语言的依赖结构并符合模型架构的计算限制，特别是针对 transformers 模型。实验结果显示，与直接训练自然语言相比，这种预预训练方法能更高效地降低损失，并在语言泛化上表现更好；例如，对于一个 1B 参数的模型，使用 33% 更少的令牌预算即可达到相同损失水平。机制证据表明，形式语言预训练中获得的注意力 heads（注意力头）在语法评估中发挥关键作用，促进了跨任务转移。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19249v1",
      "published_date": "2025-02-26 15:55:55 UTC",
      "updated_date": "2025-02-26 15:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:15:40.951039"
    },
    {
      "arxiv_id": "2502.19231v3",
      "title": "AI-Powered Bayesian Inference",
      "title_zh": "AI驱动的贝叶斯推断",
      "authors": [
        "Sean O'Hagan",
        "Veronika Ročková"
      ],
      "abstract": "The advent of Generative Artificial Intelligence (GAI) has heralded an\ninflection point that changed how society thinks about knowledge acquisition.\nWhile GAI cannot be fully trusted for decision-making, it may still provide\nvaluable information that can be integrated into a decision pipeline. Rather\nthan seeing the lack of certitude and inherent randomness of GAI as a problem,\nwe view it as an opportunity. Indeed, variable answers to given prompts can be\nleveraged to construct a prior distribution which reflects assuredness of AI\npredictions. This prior distribution may be combined with tailored datasets for\na fully Bayesian analysis with an AI-driven prior. In this paper, we explore\nsuch a possibility within a non-parametric Bayesian framework. The basic idea\nconsists of assigning a Dirichlet process prior distribution on the\ndata-generating distribution with AI generative model as its baseline.\nHyper-parameters of the prior can be tuned out-of-sample to assess the\ninformativeness of the AI prior. Posterior simulation is achieved by computing\na suitably randomized functional on an augmented data that consists of observed\n(labeled) data as well as fake data whose labels have been imputed using AI.\nThis strategy can be parallelized and rapidly produces iid samples from the\nposterior by optimization as opposed to sampling from conditionals. Our method\nenables (predictive) inference and uncertainty quantification leveraging AI\npredictions in a coherent probabilistic manner.",
      "tldr_zh": "本研究提出了一种AI-Powered Bayesian Inference方法，利用生成式人工智能(GAI)的输出构建先验分布，将其不确定性和随机性转化为贝叶斯分析的优势。该方法在非参数贝叶斯框架中采用Dirichlet过程先验，将AI生成模型作为基线，并通过增强数据（包括观察数据和AI推断的假数据）来模拟后验分布。实验表明，这种策略支持并行化优化，实现快速生成独立同分布的后验样本，从而提升预测推理和不确定性量化的效率。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "44 pages, 4 figures; revised two figures, corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2502.19231v3",
      "published_date": "2025-02-26 15:42:06 UTC",
      "updated_date": "2025-05-17 16:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:15:53.801439"
    },
    {
      "arxiv_id": "2502.19227v2",
      "title": "Enhancing the Scalability and Applicability of Kohn-Sham Hamiltonians for Molecular Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yunyang Li",
        "Zaishuo Xia",
        "Lin Huang",
        "Xinran Wei",
        "Han Yang",
        "Sam Harshe",
        "Zun Wang",
        "Chang Liu",
        "Jia Zhang",
        "Bin Shao",
        "Mark B. Gerstein"
      ],
      "abstract": "Density Functional Theory (DFT) is a pivotal method within quantum chemistry\nand materials science, with its core involving the construction and solution of\nthe Kohn-Sham Hamiltonian. Despite its importance, the application of DFT is\nfrequently limited by the substantial computational resources required to\nconstruct the Kohn-Sham Hamiltonian. In response to these limitations, current\nresearch has employed deep-learning models to efficiently predict molecular and\nsolid Hamiltonians, with roto-translational symmetries encoded in their neural\nnetworks. However, the scalability of prior models may be problematic when\napplied to large molecules, resulting in non-physical predictions of\nground-state properties. In this study, we generate a substantially larger\ntraining set (PubChemQH) than used previously and use it to create a scalable\nmodel for DFT calculations with physical accuracy. For our model, we introduce\na loss function derived from physical principles, which we call Wavefunction\nAlignment Loss (WALoss). WALoss involves performing a basis change on the\npredicted Hamiltonian to align it with the observed one; thus, the resulting\ndifferences can serve as a surrogate for orbital energy differences, allowing\nmodels to make better predictions for molecular orbitals and total energies\nthan previously possible. WALoss also substantially accelerates\nself-consistent-field (SCF) DFT calculations. Here, we show it achieves a\nreduction in total energy prediction error by a factor of 1347 and an SCF\ncalculation speed-up by a factor of 18%. These substantial improvements set new\nbenchmarks for achieving accurate and applicable predictions in larger\nmolecular systems.",
      "tldr_zh": "本研究针对密度功能理论(DFT)中Kohn-Sham Hamiltonians的计算资源限制，提出了一种可扩展的深度学习模型，以提升其在大型分子系统的适用性。该模型利用一个更大的训练集PubChemQH，并引入基于物理原理的损失函数Wavefunction Alignment Loss (WALoss)，通过对预测Hamiltonian进行基底变换来对齐观测Hamiltonian，从而提高了分子轨道和总能量的预测准确性。实验结果显示，该方法将总能量预测错误减少了1347倍，并将自洽场(SCF) DFT计算加速18倍，为大规模分子系统的高精度模拟设定了新基准。",
      "categories": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19227v2",
      "published_date": "2025-02-26 15:36:25 UTC",
      "updated_date": "2025-03-20 17:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:16:06.753121"
    },
    {
      "arxiv_id": "2503.01877v2",
      "title": "Starjob: Dataset for LLM-Driven Job Shop Scheduling",
      "title_zh": "Starjob：LLM驱动的作业车间调度数据集",
      "authors": [
        "Henrik Abgaryan",
        "Tristan Cazenave",
        "Ararat Harutyunyan"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, but their potential for solving combinatorial optimization\nproblems remains largely unexplored. In this paper, we investigate the\napplicability of LLMs to the Job Shop Scheduling Problem (JSSP), a classic\nchallenge in combinatorial optimization that requires efficient job allocation\nto machines to minimize makespan. To this end, we introduce Starjob, the first\nsupervised dataset for JSSP, comprising 130k instances specifically designed\nfor training LLMs. Leveraging this dataset, we fine-tune the LLaMA 8B 4-bit\nquantized model with the LoRA method to develop an end-to-end scheduling\napproach. Our evaluation on standard benchmarks demonstrates that the proposed\nLLM-based method not only surpasses traditional Priority Dispatching Rules\n(PDRs) but also achieves notable improvements over state-of-the-art neural\napproaches like L2D, with an average improvement of 15.36% on DMU and 7.85% on\nTaillard benchmarks. These results highlight the untapped potential of LLMs in\ntackling combinatorial optimization problems, paving the way for future\nadvancements in this area.",
      "tldr_zh": "该论文探讨了Large Language Models (LLMs) 在Job Shop Scheduling Problem (JSSP) 等组合优化问题中的应用潜力，并引入了Starjob，这是第一个包含13万实例的监督数据集，专门用于训练LLMs。研究团队使用LoRA方法微调LLaMA 8B 4-bit量化模型，开发了一种端到端的调度方法。实验结果显示，该方法在DMU和Taillard基准上分别比传统Priority Dispatching Rules (PDRs)和先进神经方法L2D改善了15.36%和7.85%，突显了LLMs在解决组合优化问题的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2408.06993",
      "pdf_url": "http://arxiv.org/pdf/2503.01877v2",
      "published_date": "2025-02-26 15:20:01 UTC",
      "updated_date": "2025-03-27 10:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:16:19.373090"
    },
    {
      "arxiv_id": "2502.19217v2",
      "title": "A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images",
      "title_zh": "轻量级且可扩展的全滑片图像细胞分割和分类模型",
      "authors": [
        "Nikita Shvetsov",
        "Thomas K. Kilvaer",
        "Masoud Tafavvoghi",
        "Anders Sildnes",
        "Kajsa Møllersen",
        "Lill-Tove Rasmussen Busund",
        "Lars Ailo Bongo"
      ],
      "abstract": "Developing clinically useful cell-level analysis tools in digital pathology\nremains challenging due to limitations in dataset granularity, inconsistent\nannotations, high computational demands, and difficulties integrating new\ntechnologies into workflows. To address these issues, we propose a solution\nthat enhances data quality, model performance, and usability by creating a\nlightweight, extensible cell segmentation and classification model. First, we\nupdate data labels through cross-relabeling to refine annotations of PanNuke\nand MoNuSAC, producing a unified dataset with seven distinct cell types.\nSecond, we leverage the H-Optimus foundation model as a fixed encoder to\nimprove feature representation for simultaneous segmentation and classification\ntasks. Third, to address foundation models' computational demands, we distill\nknowledge to reduce model size and complexity while maintaining comparable\nperformance. Finally, we integrate the distilled model into QuPath, a widely\nused open-source digital pathology platform. Results demonstrate improved\nsegmentation and classification performance using the H-Optimus-based model\ncompared to a CNN-based model. Specifically, average $R^2$ improved from 0.575\nto 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating\nbetter alignment with actual cell counts and enhanced segmentation quality. The\ndistilled model maintains comparable performance while reducing parameter count\nby a factor of 48. By reducing computational complexity and integrating into\nworkflows, this approach may significantly impact diagnostics, reduce\npathologist workload, and improve outcomes. Although the method shows promise,\nextensive validation is necessary prior to clinical deployment.",
      "tldr_zh": "该研究针对数字病理中数据集粒度有限、不一致标注和高计算需求等问题，提出一个轻量、可扩展的细胞分割和分类模型。首先，通过交叉重新标注改进 PanNuke 和 MoNuSAC 数据集，创建包含七种细胞类型的统一数据集；其次，使用 H-Optimus 基础模型作为固定编码器进行特征表示，并通过知识蒸馏减少模型大小，同时集成到 QuPath 平台。实验结果显示，与 CNN 模型相比，该模型的平均 $R^2$ 指标从 0.575 提高到 0.871，平均 $PQ$ 得分从 0.450 提高到 0.492，显著提升了分割和分类性能。整体方法降低了计算复杂性，有望减少病理学家工作量并改善诊断结果，但需进行广泛验证才能临床部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.4.9; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "30 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19217v2",
      "published_date": "2025-02-26 15:19:52 UTC",
      "updated_date": "2025-04-09 11:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:16:32.330949"
    },
    {
      "arxiv_id": "2502.19463v1",
      "title": "Do LLMs exhibit demographic parity in responses to queries about Human Rights?",
      "title_zh": "翻译失败",
      "authors": [
        "Rafiya Javed",
        "Jackie Kay",
        "David Yanni",
        "Abdullah Zaini",
        "Anushe Sheikh",
        "Maribeth Rauh",
        "Ramona Comanescu",
        "Iason Gabriel",
        "Laura Weidinger"
      ],
      "abstract": "This research describes a novel approach to evaluating hedging behaviour in\nlarge language models (LLMs), specifically in the context of human rights as\ndefined in the Universal Declaration of Human Rights (UDHR). Hedging and\nnon-affirmation are behaviours that express ambiguity or a lack of clear\nendorsement on specific statements. These behaviours are undesirable in certain\ncontexts, such as queries about whether different groups are entitled to\nspecific human rights; since all people are entitled to human rights. Here, we\npresent the first systematic attempt to measure these behaviours in the context\nof human rights, with a particular focus on between-group comparisons. To this\nend, we design a novel prompt set on human rights in the context of different\nnational or social identities. We develop metrics to capture hedging and\nnon-affirmation behaviours and then measure whether LLMs exhibit demographic\nparity when responding to the queries. We present results on three leading LLMs\nand find that all models exhibit some demographic disparities in how they\nattribute human rights between different identity groups. Futhermore, there is\nhigh correlation between different models in terms of how disparity is\ndistributed amongst identities, with identities that have high disparity in one\nmodel also facing high disparity in both the other models. While baseline rates\nof hedging and non-affirmation differ, these disparities are consistent across\nqueries that vary in ambiguity and they are robust across variations of the\nprecise query wording. Our findings highlight the need for work to explicitly\nalign LLMs to human rights principles, and to ensure that LLMs endorse the\nhuman rights of all groups equally.",
      "tldr_zh": "这篇论文评估大型语言模型 (LLMs) 在回应人权查询时是否表现出 demographic parity，特别是针对《世界人权宣言》(UDHR) 定义的权利。研究者设计了一个新的人权提示集，聚焦不同国家或社会身份群体，并开发指标来测量 hedging behaviour 和 non-affirmation 行为，以量化模型的模糊或不明确支持。实验结果显示，三种领先 LLMs 均存在 demographic disparities，在不同身份群体间的人权归属上不平等，且这些差异在模型间高度相关，并对查询模糊度和措辞变化保持稳健。论文强调，需要进一步工作来明确将 LLMs 与人权原则对齐，确保所有群体获得平等认可。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19463v1",
      "published_date": "2025-02-26 15:19:35 UTC",
      "updated_date": "2025-02-26 15:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:16:42.910118"
    },
    {
      "arxiv_id": "2502.19207v1",
      "title": "FaithUn: Toward Faithful Forgetting in Language Models by Investigating the Interconnectedness of Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Nakyeong Yang",
        "Minsung Kim",
        "Seunghyun Yoon",
        "Joongbo Shin",
        "Kyomin Jung"
      ],
      "abstract": "Various studies have attempted to remove sensitive or private knowledge from\na language model to prevent its unauthorized exposure. However, prior studies\nhave overlooked the complex and interconnected nature of knowledge, where\nrelated knowledge must be carefully examined. Specifically, they have failed to\nevaluate whether an unlearning method faithfully erases interconnected\nknowledge that should be removed, retaining knowledge that appears relevant but\nexists in a completely different context. To resolve this problem, we first\ndefine a new concept called superficial unlearning, which refers to the\nphenomenon where an unlearning method either fails to erase the interconnected\nknowledge it should remove or unintentionally erases irrelevant knowledge.\nBased on the definition, we introduce a new benchmark, FaithUn, to analyze and\nevaluate the faithfulness of unlearning in real-world knowledge QA settings.\nFurthermore, we propose a novel unlearning method, KLUE, which updates only\nknowledge-related neurons to achieve faithful unlearning. KLUE identifies\nknowledge neurons using an explainability method and updates only those neurons\nusing selected unforgotten samples. Experimental results demonstrate that\nwidely-used unlearning methods fail to ensure faithful unlearning, while our\nmethod shows significant effectiveness in real-world QA unlearning.",
      "tldr_zh": "该研究探讨了语言模型中删除敏感知识的挑战，强调知识的相互连接性可能导致 unlearning 方法未能彻底移除相关知识或错误删除无关信息，从而引入 superficial unlearning 的新概念。作者提出 FaithUn 基准，用于评估 unlearning 在真实世界知识问答（QA）场景中的忠实性，并开发了 KLUE 方法，该方法利用 explainability 技术识别知识神经元，并仅更新这些神经元以实现精确 unlearning。实验结果表明，现有 unlearning 方法表现不佳，而 KLUE 在 QA unlearning 任务中显示出显著有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.19207v1",
      "published_date": "2025-02-26 15:11:03 UTC",
      "updated_date": "2025-02-26 15:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:16:53.558059"
    },
    {
      "arxiv_id": "2502.19199v1",
      "title": "EGR-Net: A Novel Embedding Gramian Representation CNN for Intelligent Fault Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Linshan Jia"
      ],
      "abstract": "Feature extraction is crucial in intelligent fault diagnosis of rotating\nmachinery. It is easier for convolutional neural networks(CNNs) to visually\nrecognize and learn fault features by converting the complicated\none-dimensional (1D) vibrational signals into two-dimensional (2D) images with\nsimple textures. However, the existing representation methods for encoding 1D\nsignals as images have two main problems, including complicated computation and\nlow separability. Meanwhile, the existing 2D-CNN fault diagnosis methods taking\n2D images as the only inputs still suffer from the inevitable information loss\nbecause of the conversion process. Considering the above issues, this paper\nproposes a new 1D-to-2D conversion method called Embedding Gramian\nRepresentation (EGR), which is easy to calculate and shows good separability.\nIn EGR, 1D signals are projected in the embedding space and the intrinsic\nperiodicity of vibrational signals is captured enabling the faulty\ncharacteristics contained in raw signals to be uncovered. Second, aiming at the\ninformation loss problem of existing CNN models with the single input of\nconverted images, a double-branch EGR-based CNN, called EGR-Net, is proposed to\nlearn faulty features from both raw signal feature maps and their corresponding\nEGRs. The bridge connection is designed to improve the feature learning\ninteraction between the two branches. Widely used open domain gearbox dataset\nand bearing dataset are used to verify the effectiveness and efficiency of the\nproposed methods. EGR-Net is compared with traditional and state-of-the-art\napproaches, and the results show that the proposed method can deliver enhanced\nperformance.",
      "tldr_zh": "本文提出了一种新型的 Embedding Gramian Representation (EGR) 方法，用于将一维 (1D) 振动信号转换为二维 (2D) 图像，以简化计算过程并提升特征的可分离性，从而更好地捕获旋转机械的内在周期性和故障特征。基于 EGR，该研究开发了 EGR-Net，一个双分支 CNN 模型，能够同时从原始信号特征图和对应的 EGR 图像中学习故障特征，并通过桥接连接加强分支间的特征交互，以缓解信息损失问题。在公开的齿轮箱和轴承数据集上实验验证显示，EGR-Net 相较于传统和最先进方法显著提高了智能故障诊断的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19199v1",
      "published_date": "2025-02-26 15:05:56 UTC",
      "updated_date": "2025-02-26 15:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:17:06.193246"
    },
    {
      "arxiv_id": "2502.19193v1",
      "title": "Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Jinyu Cai",
        "Yusei Ishimizu",
        "Mingyue Zhang",
        "Munan Li",
        "Jialong Li",
        "Kenji Tei"
      ],
      "abstract": "Social media platforms frequently impose restrictive policies to moderate\nuser content, prompting the emergence of creative evasion language strategies.\nThis paper presents a multi-agent framework based on Large Language Models\n(LLMs) to simulate the iterative evolution of language strategies under\nregulatory constraints. In this framework, participant agents, as social media\nusers, continuously evolve their language expression, while supervisory agents\nemulate platform-level regulation by assessing policy violations. To achieve a\nmore faithful simulation, we employ a dual design of language strategies\n(constraint and expression) to differentiate conflicting goals and utilize an\nLLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of\nlanguage strategies. The framework is evaluated using two distinct scenarios:\nan abstract password game and a realistic simulated illegal pet trade scenario.\nExperimental results demonstrate that as the number of dialogue rounds\nincreases, both the number of uninterrupted dialogue turns and the accuracy of\ninformation transmission improve significantly. Furthermore, a user study with\n40 participants validates the real-world relevance of the generated dialogues\nand strategies. Moreover, ablation studies validate the importance of the GA,\nemphasizing its contribution to long-term adaptability and improved overall\nresults.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的多智能体框架，用于模拟社交媒体平台监管下语言策略的迭代演化。框架通过双重设计区分约束和表达策略，并采用 LLM 驱动的 Genetic Algorithm (GA) 来处理策略的选择、变异和交叉，从而实现更真实的模拟。实验在抽象密码游戏和非法宠物交易场景中表明，随着对话轮数增加，未中断对话轮数和信息传输准确率显著提升；此外，用户研究和消融研究验证了框架的真实性和 GA 的关键作用。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SI",
      "comment": "The manuscript has been submitted to IEEE Transactions on\n  Computational Social Systems",
      "pdf_url": "http://arxiv.org/pdf/2502.19193v1",
      "published_date": "2025-02-26 14:59:27 UTC",
      "updated_date": "2025-02-26 14:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:17:18.114472"
    },
    {
      "arxiv_id": "2502.19190v1",
      "title": "Provocations from the Humanities for Generative AI Research",
      "title_zh": "翻译失败",
      "authors": [
        "Lauren Klein",
        "Meredith Martin",
        "André Brock",
        "Maria Antoniak",
        "Melanie Walsh",
        "Jessica Marie Johnson",
        "Lauren Tilton",
        "David Mimno"
      ],
      "abstract": "This paper presents a set of provocations for considering the uses, impact,\nand harms of generative AI from the perspective of humanities researchers. We\nprovide a working definition of humanities research, summarize some of its most\nsalient theories and methods, and apply these theories and methods to the\ncurrent landscape of AI. Drawing from foundational work in critical data\nstudies, along with relevant humanities scholarship, we elaborate eight claims\nwith broad applicability to current conversations about generative AI: 1)\nModels make words, but people make meaning; 2) Generative AI requires an\nexpanded definition of culture; 3) Generative AI can never be representative;\n4) Bigger models are not always better models; 5) Not all training data is\nequivalent; 6) Openness is not an easy fix; 7) Limited access to compute\nenables corporate capture; and 8) AI universalism creates narrow human\nsubjects. We conclude with a discussion of the importance of resisting the\nextraction of humanities research by computer science and related fields.",
      "tldr_zh": "这篇论文从人文研究者的视角，提出了一系列对生成式 AI 的使用、影响和危害的挑衅性观点，包括定义人文研究的核心理论和方法，并将其应用于当前 AI 景观。论文基于关键数据研究（critical data studies）和相关人文奖学金，阐述了八个广泛适用的声明：如“Models make words, but people make meaning”（模型制作单词，但人们制作意义）、“Generative AI can never be representative”（生成式 AI 永远不能代表性），以及强调训练数据不等价、开放性非万能解等问题。最终，它呼吁抵抗计算机科学等领域对人文研究的提取，以促进更平衡的 AI 发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.4.0"
      ],
      "primary_category": "cs.CY",
      "comment": "working draft; final draft in preparation",
      "pdf_url": "http://arxiv.org/pdf/2502.19190v1",
      "published_date": "2025-02-26 14:55:55 UTC",
      "updated_date": "2025-02-26 14:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:17:30.176402"
    },
    {
      "arxiv_id": "2503.02890v1",
      "title": "Predicting Cascade Failures in Interdependent Urban Infrastructure Networks",
      "title_zh": "预测相互依赖的城市基础设施网络中的级联故障",
      "authors": [
        "Yinzhou Tang",
        "Jinghua Piao",
        "Huandong Wang",
        "Shaw Rajib",
        "Yong Li"
      ],
      "abstract": "Cascading failures (CF) entail component breakdowns spreading through\ninfrastructure networks, causing system-wide collapse. Predicting CFs is of\ngreat importance for infrastructure stability and urban function. Despite\nextensive research on CFs in single networks such as electricity and road\nnetworks, interdependencies among diverse infrastructures remain overlooked,\nand capturing intra-infrastructure CF dynamics amid complex evolutions poses\nchallenges. To address these gaps, we introduce the \\textbf{I}ntegrated\n\\textbf{I}nterdependent \\textbf{I}nfrastructure CF model ($I^3$), designed to\ncapture CF dynamics both within and across infrastructures. $I^3$ employs a\ndual GAE with global pooling for intra-infrastructure dynamics and a\nheterogeneous graph for inter-infrastructure interactions. An initial node\nenhancement pre-training strategy mitigates GCN-induced over-smoothing.\nExperiments demonstrate $I^3$ achieves a 31.94\\% in terms of AUC, 18.03\\% in\nterms of Precision, 29.17\\% in terms of Recall, 22.73\\% in terms of F1-score\nboost in predicting infrastructure failures, and a 28.52\\% reduction in terms\nof RMSE for cascade volume forecasts compared to leading models. It accurately\npinpoints phase transitions in interconnected and singular networks, rectifying\nbiases in models tailored for singular networks. Access the code at\nhttps://github.com/tsinghua-fib-lab/Icube.",
      "tldr_zh": "本研究针对相互依赖的城市基础设施网络中的级联故障（Cascading Failures, CF），提出了一种集成互依赖基础设施CF模型（I^3），旨在捕捉内部和跨基础设施的动态演化。I^3 模型采用双 GAE（Graph Autoencoder）结合全局池化处理内部动态，并使用异构图（heterogeneous graph）模拟跨基础设施互动，同时引入初始节点增强预训练策略缓解 GCN（Graph Convolutional Network）引起的过度平滑问题。实验结果显示，I^3 在预测故障时，AUC 提升 31.94%、Precision 提升 18.03%、Recall 提升 29.17%、F1-score 提升 22.73%，并将级联规模预测的 RMSE 降低 28.52%，从而准确识别相变并修正单一网络模型的偏差。模型代码可访问 https://github.com/tsinghua-fib-lab/Icube。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02890v1",
      "published_date": "2025-02-26 14:50:22 UTC",
      "updated_date": "2025-02-26 14:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:17:41.922099"
    },
    {
      "arxiv_id": "2502.19180v1",
      "title": "AutoML for Multi-Class Anomaly Compensation of Sensor Drift",
      "title_zh": "翻译失败",
      "authors": [
        "Melanie Schaller",
        "Mathis Kruse",
        "Antonio Ortega",
        "Marius Lindauer",
        "Bodo Rosenhahn"
      ],
      "abstract": "Addressing sensor drift is essential in industrial measurement systems, where\nprecise data output is necessary for maintaining accuracy and reliability in\nmonitoring processes, as it progressively degrades the performance of machine\nlearning models over time. Our findings indicate that the standard\ncross-validation method used in existing model training overestimates\nperformance by inadequately accounting for drift. This is primarily because\ntypical cross-validation techniques allow data instances to appear in both\ntraining and testing sets, thereby distorting the accuracy of the predictive\nevaluation. As a result, these models are unable to precisely predict future\ndrift effects, compromising their ability to generalize and adapt to evolving\ndata conditions. This paper presents two solutions: (1) a novel sensor drift\ncompensation learning paradigm for validating models, and (2) automated machine\nlearning (AutoML) techniques to enhance classification performance and\ncompensate sensor drift. By employing strategies such as data balancing,\nmeta-learning, automated ensemble learning, hyperparameter optimization,\nfeature selection, and boosting, our AutoML-DC (Drift Compensation) model\nsignificantly improves classification performance against sensor drift.\nAutoML-DC further adapts effectively to varying drift severities.",
      "tldr_zh": "传感器漂移是工业测量系统中一个关键问题，会导致机器学习模型性能逐渐下降，且标准的交叉验证方法因数据重复出现而高估了模型准确性。论文提出两个解决方案：(1) 一个新型的传感器漂移补偿学习范式，用于更可靠的模型验证；(2) AutoML-DC 模型，通过数据平衡、元学习、自动化集成学习、超参数优化、特征选择和提升策略来提升多类异常分类性能。结果表明，AutoML-DC 模型显著提高了分类准确率，并能有效适应不同严重程度的传感器漂移。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in Measurement Journal",
      "pdf_url": "http://arxiv.org/pdf/2502.19180v1",
      "published_date": "2025-02-26 14:34:53 UTC",
      "updated_date": "2025-02-26 14:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:17:53.510039"
    },
    {
      "arxiv_id": "2502.19175v1",
      "title": "MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis",
      "title_zh": "MEDDxAgent：用于可解释自动鉴别诊断的统一模块化代理框架",
      "authors": [
        "Daniel Rose",
        "Chia-Chien Hung",
        "Marco Lepri",
        "Israa Alqassem",
        "Kiril Gashteovski",
        "Carolin Lawrence"
      ],
      "abstract": "Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical\ndecision-making, in which physicians iteratively refine a ranked list of\npossible diseases based on symptoms, antecedents, and medical knowledge. While\nrecent advances in large language models have shown promise in supporting DDx,\nexisting approaches face key limitations, including single-dataset evaluations,\nisolated optimization of components, unrealistic assumptions about complete\npatient profiles, and single-attempt diagnosis. We introduce a Modular\nExplainable DDx Agent (MEDDxAgent) framework designed for interactive DDx,\nwhere diagnostic reasoning evolves through iterative learning, rather than\nassuming a complete patient profile is accessible. MEDDxAgent integrates three\nmodular components: (1) an orchestrator (DDxDriver), (2) a history taking\nsimulator, and (3) two specialized agents for knowledge retrieval and diagnosis\nstrategy. To ensure robust evaluation, we introduce a comprehensive DDx\nbenchmark covering respiratory, skin, and rare diseases. We analyze single-turn\ndiagnostic approaches and demonstrate the importance of iterative refinement\nwhen patient profiles are not available at the outset. Our broad evaluation\ndemonstrates that MEDDxAgent achieves over 10% accuracy improvements in\ninteractive DDx across both large and small LLMs, while offering critical\nexplainability into its diagnostic reasoning process.",
      "tldr_zh": "本研究提出MEDDxAgent，一种统一的模块化代理框架，用于可解释的自动差异诊断（Differential Diagnosis, DDx），通过迭代学习和交互式推理解决现有方法的局限，如单一数据集评估和假设完整患者档案。框架整合了三个核心组件：协调器（DDxDriver）、病史采集模拟器，以及知识检索和诊断策略的专门代理，从而实现诊断推理的逐步演化。实验在涵盖呼吸系统、皮肤和罕见疾病的全面DDx基准上评估，结果显示MEDDxAgent使大型和小型LLMs在交互式DDx中的准确率提高超过10%，并提供关键的可解释性以增强临床决策。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19175v1",
      "published_date": "2025-02-26 14:31:43 UTC",
      "updated_date": "2025-02-26 14:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:18:06.532117"
    },
    {
      "arxiv_id": "2502.19163v1",
      "title": "TestNUC: Enhancing Test-Time Computing Approaches through Neighboring Unlabeled Data Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Peng Zou",
        "Zhengyao Gu",
        "Yue Zhou",
        "Yankai Chen",
        "Weizhi Zhang",
        "Liancheng Fang",
        "Yibo Wang",
        "Yangning Li",
        "Kay Liu",
        "Philip S. Yu"
      ],
      "abstract": "Test-time computing approaches, which leverage additional computational\nresources during inference, have been proven effective in enhancing large\nlanguage model performance. This work introduces a novel, linearly scaling\napproach, TestNUC, that improves test-time predictions by leveraging the local\nconsistency of neighboring unlabeled data-it classifies an input instance by\nconsidering not only the model's prediction on that instance but also on\nneighboring unlabeled instances. We evaluate TestNUC across eight diverse\ndatasets, spanning intent classification, topic mining, domain discovery, and\nemotion detection, demonstrating its consistent superiority over baseline\nmethods such as standard prompting and self-consistency. Furthermore, TestNUC\ncan be seamlessly integrated with existing test-time computing approaches,\nsubstantially boosting their performance. Our analysis reveals that TestNUC\nscales effectively with increasing amounts of unlabeled data and performs\nrobustly across different embedding models, making it practical for real-world\napplications. Our code is available at https://github.com/HenryPengZou/TestNUC.",
      "tldr_zh": "本研究引入了 TestNUC，一种线性扩展的测试时计算方法，通过利用相邻无标签数据的局部一致性来提升大型语言模型的预测性能——它不仅考虑模型对当前实例的预测，还整合附近无标签实例的预测。实验在八个多样数据集上（包括意图分类、主题挖掘、领域发现和情感检测）评估了 TestNUC，结果显示其优于基线方法如标准提示和自一致性，并可无缝整合到现有测试时计算方法中，进一步提升整体表现。分析表明，TestNUC 随无标签数据量增加而有效扩展，并在不同嵌入模型上表现出色，适用于实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19163v1",
      "published_date": "2025-02-26 14:17:56 UTC",
      "updated_date": "2025-02-26 14:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:18:18.342340"
    },
    {
      "arxiv_id": "2504.05323v1",
      "title": "Multi-Perspective Attention Mechanism for Bias-Aware Sequential Recommendation",
      "title_zh": "多视角注意力机制用于偏置感知序列推荐",
      "authors": [
        "Mingjian Fu",
        "Hengsheng Chen",
        "Dongchun Jiang",
        "Yanchao Tan"
      ],
      "abstract": "In the era of advancing information technology, recommender systems have\nemerged as crucial tools for dealing with information overload. However,\ntraditional recommender systems still have limitations in capturing the dynamic\nevolution of user behavior. To better understand and predict user behavior,\nespecially taking into account the complexity of temporal evolution, sequential\nrecommender systems have gradually become the focus of research. Currently,\nmany sequential recommendation algorithms ignore the amplification effects of\nprevalent biases, which leads to recommendation results being susceptible to\nthe Matthew Effect. Additionally, it will impose limitations on the recommender\nsystem's ability to deeply perceive and capture the dynamic shifts in user\npreferences, thereby diminishing the extent of its recommendation reach. To\naddress this issue effectively, we propose a recommendation system based on\nsequential information and attention mechanism called Multi-Perspective\nAttention Bias Sequential Recommendation (MABSRec). Firstly, we reconstruct\nuser sequences into three short types and utilize graph neural networks for\nitem weighting. Subsequently, an adaptive multi-bias perspective attention\nmodule is proposed to enhance the accuracy of recommendations. Experimental\nresults show that the MABSRec model exhibits significant advantages in all\nevaluation metrics, demonstrating its excellent performance in the sequence\nrecommendation task.",
      "tldr_zh": "该论文针对顺序推荐系统（Sequential Recommendation）中忽略偏差放大效应的问题，提出了一种基于多视角注意力机制（Multi-Perspective Attention Mechanism）的偏差感知模型MABSRec。首先，该模型通过重建用户序列为三种短类型，并利用图神经网络（Graph Neural Networks）进行物品加权；随后，引入自适应多偏差视角注意力模块，以更好地捕捉用户偏好的动态变化。实验结果表明，MABSRec在所有评估指标上表现出显著优势，提升了推荐系统的准确性和鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "I.2"
      ],
      "primary_category": "cs.IR",
      "comment": "30 pages,10 figures,4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.05323v1",
      "published_date": "2025-02-26 14:16:58 UTC",
      "updated_date": "2025-02-26 14:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:18:29.624816"
    },
    {
      "arxiv_id": "2502.19160v1",
      "title": "Detecting Linguistic Indicators for Stereotype Assessment with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rebekka Görge",
        "Michael Mock",
        "Héctor Allende-Cid"
      ],
      "abstract": "Social categories and stereotypes are embedded in language and can introduce\ndata bias into Large Language Models (LLMs). Despite safeguards, these biases\noften persist in model behavior, potentially leading to representational harm\nin outputs. While sociolinguistic research provides valuable insights into the\nformation of stereotypes, NLP approaches for stereotype detection rarely draw\non this foundation and often lack objectivity, precision, and interpretability.\nTo fill this gap, in this work we propose a new approach that detects and\nquantifies the linguistic indicators of stereotypes in a sentence. We derive\nlinguistic indicators from the Social Category and Stereotype Communication\n(SCSC) framework which indicate strong social category formulation and\nstereotyping in language, and use them to build a categorization scheme. To\nautomate this approach, we instruct different LLMs using in-context learning to\napply the approach to a sentence, where the LLM examines the linguistic\nproperties and provides a basis for a fine-grained assessment. Based on an\nempirical evaluation of the importance of different linguistic indicators, we\nlearn a scoring function that measures the linguistic indicators of a\nstereotype. Our annotations of stereotyped sentences show that these indicators\nare present in these sentences and explain the strength of a stereotype. In\nterms of model performance, our results show that the models generally perform\nwell in detecting and classifying linguistic indicators of category labels used\nto denote a category, but sometimes struggle to correctly evaluate the\nassociated behaviors and characteristics. Using more few-shot examples within\nthe prompts, significantly improves performance. Model performance increases\nwith size, as Llama-3.3-70B-Instruct and GPT-4 achieve comparable results that\nsurpass those of Mixtral-8x7B-Instruct, GPT-4-mini and Llama-3.1-8B-Instruct.",
      "tldr_zh": "该研究探讨了语言中嵌入的社会类别和刻板印象如何导致 Large Language Models (LLMs) 的数据偏差，并提出一种新方法来检测和量化句子中的刻板印象语言指标。方法基于 Social Category and Stereotype Communication (SCSC) 框架，构建分类方案，并利用 LLMs 通过 in-context learning 自动评估这些指标，包括类别标签、行为和特征。实验结果显示，模型在检测类别标签方面表现良好，但评估相关行为时存在困难，使用更多 few-shot examples 可显著提升性能，且模型规模越大（如 Llama-3.3-70B-Instruct 和 GPT-4）表现越优越。该方法为更客观、精确的刻板印象评估提供了基础，有助于减少 LLMs 中的代表性伤害。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19160v1",
      "published_date": "2025-02-26 14:15:28 UTC",
      "updated_date": "2025-02-26 14:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:18:42.679924"
    },
    {
      "arxiv_id": "2502.19158v1",
      "title": "When Personalization Meets Reality: A Multi-Faceted Analysis of Personalized Preference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yijiang River Dong",
        "Tiancheng Hu",
        "Yinhong Liu",
        "Ahmet Üstün",
        "Nigel Collier"
      ],
      "abstract": "While Reinforcement Learning from Human Feedback (RLHF) is widely used to\nalign Large Language Models (LLMs) with human preferences, it typically assumes\nhomogeneous preferences across users, overlooking diverse human values and\nminority viewpoints. Although personalized preference learning addresses this\nby tailoring separate preferences for individual users, the field lacks\nstandardized methods to assess its effectiveness. We present a multi-faceted\nevaluation framework that measures not only performance but also fairness,\nunintended effects, and adaptability across varying levels of preference\ndivergence. Through extensive experiments comparing eight personalization\nmethods across three preference datasets, we demonstrate that performance\ndifferences between methods could reach 36% when users strongly disagree, and\npersonalization can introduce up to 20% safety misalignment. These findings\nhighlight the critical need for holistic evaluation approaches to advance the\ndevelopment of more effective and inclusive preference learning systems.",
      "tldr_zh": "这篇论文指出，Reinforcement Learning from Human Feedback (RLHF) 在对齐 Large Language Models (LLMs) 时通常假设用户偏好同质化，从而忽略了多样的人类价值观和少数观点，并提出一个多方面的评估框架来评估 Personalized Preference Learning 的性能、公平性、意外效果和适应性。框架通过实验比较八种个性化方法在三个偏好数据集上的表现，发现当用户偏好强烈不同时，方法之间性能差异可达36%，并且个性化可能导致高达20%的安全失准。这些发现强调了需要采用整体评估方法，以推进更有效和包容的偏好学习系统的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19158v1",
      "published_date": "2025-02-26 14:14:58 UTC",
      "updated_date": "2025-02-26 14:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:18:57.185277"
    },
    {
      "arxiv_id": "2502.19145v1",
      "title": "Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Peigne-Lefebvre",
        "Mikolaj Kniejski",
        "Filip Sondej",
        "Matthieu David",
        "Jason Hoelscher-Obermaier",
        "Christian Schroeder de Witt",
        "Esben Kran"
      ],
      "abstract": "As AI agents are increasingly adopted to collaborate on complex objectives,\nensuring the security of autonomous multi-agent systems becomes crucial. We\ndevelop simulations of agents collaborating on shared objectives to study these\nsecurity risks and security trade-offs. We focus on scenarios where an attacker\ncompromises one agent, using it to steer the entire system toward misaligned\noutcomes by corrupting other agents. In this context, we observe infectious\nmalicious prompts - the multi-hop spreading of malicious instructions. To\nmitigate this risk, we evaluated several strategies: two \"vaccination\"\napproaches that insert false memories of safely handling malicious input into\nthe agents' memory stream, and two versions of a generic safety instruction\nstrategy. While these defenses reduce the spread and fulfillment of malicious\ninstructions in our experiments, they tend to decrease collaboration capability\nin the agent network. Our findings illustrate potential trade-off between\nsecurity and collaborative efficiency in multi-agent systems, providing\ninsights for designing more secure yet effective AI collaborations.",
      "tldr_zh": "该研究探讨了多代理系统（multi-agent systems）中安全性和协作能力之间的权衡，特别关注攻击者通过控制一个代理来传播恶意指令（infectious malicious prompts），从而使整个系统偏离目标。研究者通过模拟实验观察了这种风险，并评估了多种防御策略，包括两种“vaccination”方法（插入虚假记忆以处理恶意输入）和两种泛化安全指令策略。这些策略在实验中成功减少了恶意指令的传播和执行，但同时降低了代理网络的协作效率。总体而言，该工作揭示了“security tax”的概念，为设计更安全且高效的 AI 协作系统提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2502.19145v1",
      "published_date": "2025-02-26 14:00:35 UTC",
      "updated_date": "2025-02-26 14:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:19:07.239911"
    },
    {
      "arxiv_id": "2502.19135v1",
      "title": "A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Saccon",
        "Ahmet Tikna",
        "Davide De Martini",
        "Edoardo Lamon",
        "Luigi Palopoli",
        "Marco Roveri"
      ],
      "abstract": "This paper presents a novel framework, called PLANTOR (PLanning with Natural\nlanguage for Task-Oriented Robots), that integrates Large Language Models\n(LLMs) with Prolog-based knowledge management and planning for multi-robot\ntasks. The system employs a two-phase generation of a robot-oriented knowledge\nbase, ensuring reusability and compositional reasoning, as well as a three-step\nplanning procedure that handles temporal dependencies, resource constraints,\nand parallel task execution via mixed-integer linear programming. The final\nplan is converted into a Behaviour Tree for direct use in ROS2. We tested the\nframework in multi-robot assembly tasks within a block world and an\narch-building scenario. Results demonstrate that LLMs can produce accurate\nknowledge bases with modest human feedback, while Prolog guarantees formal\ncorrectness and explainability. This approach underscores the potential of LLM\nintegration for advanced robotics tasks requiring flexible, scalable, and\nhuman-understandable planning.",
      "tldr_zh": "本论文提出一个名为 PLANTOR 的框架，将 Large Language Models (LLMs) 与 Prolog-based 知识管理和规划相结合，用于多代理系统的 temporal 规划，以支持多机器人任务。框架包括两阶段生成机器人导向的知识库，确保可重用性和组合推理，以及三步规划过程，通过混合整数线性规划处理时间依赖、资源约束和并行任务执行，最终将计划转换为 Behaviour Tree 以在 ROS2 中应用。在块世界和拱门构建场景的实验中，LLMs 能以少量人类反馈生成准确知识库，而 Prolog 确保了形式正确性和可解释性，展示了 LLM 在灵活、可扩展机器人规划中的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19135v1",
      "published_date": "2025-02-26 13:51:28 UTC",
      "updated_date": "2025-02-26 13:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:19:19.551971"
    },
    {
      "arxiv_id": "2503.01875v1",
      "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Yaxuan Kong",
        "Yiyuan Yang",
        "Yoontae Hwang",
        "Wenjie Du",
        "Stefan Zohren",
        "Zhangyang Wang",
        "Ming Jin",
        "Qingsong Wen"
      ],
      "abstract": "Time series data are foundational in finance, healthcare, and energy domains.\nHowever, most existing methods and datasets remain focused on a narrow spectrum\nof tasks, such as forecasting or anomaly detection. To bridge this gap, we\nintroduce Time Series Multi-Task Question Answering (Time-MQA), a unified\nframework that enables natural language queries across multiple time series\ntasks - numerical analytical tasks and open-ended question answering with\nreasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset\ncontaining $\\sim$200k question-answer pairs derived from diverse time series\nspanning environment, traffic, etc. This comprehensive resource covers various\ntime series lengths and promotes robust model development. We further\ndemonstrate how continually pre-training large language models (Mistral 7B,\nLlama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning\ncapabilities, moving beyond mere numeric tasks and enabling more advanced and\nintuitive interactions with temporal data. The complete TSQA dataset, models,\nexecutable codes, user study questionnaires for evaluation, and results have\nall been open-sourced.",
      "tldr_zh": "这篇论文引入了 Time-MQA 框架，用于处理时间序列数据在金融、健康和能源等领域中的多任务问答，支持自然语言查询，包括数值分析任务和开放式推理问答。核心是 TSQA 数据集，该数据集包含约 20 万问题-答案对，源自多样化的时间序列（如环境和交通领域），覆盖不同序列长度，以促进模型的鲁棒性发展。作者通过在大型语言模型（如 Mistral 7B、Llama-3 8B 和 Qwen-2.5 7B）上持续预训练，显著提升了时间序列推理能力，从单纯的数字任务扩展到更高级的交互。最后，所有数据集、模型、代码和评估资源均已开源，以推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01875v1",
      "published_date": "2025-02-26 13:47:13 UTC",
      "updated_date": "2025-02-26 13:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:19:31.867179"
    },
    {
      "arxiv_id": "2502.19130v1",
      "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
      "title_zh": "投票还是共识？多智能体辩论中的决策",
      "authors": [
        "Lars Benedikt Kaesberg",
        "Jonas Becker",
        "Jan Philip Wahle",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Much of the success of multi-agent debates depends on carefully choosing the\nright parameters. Among them, the decision-making protocol stands out.\nSystematic comparison of decision protocols is difficult because studies alter\nmultiple discussion parameters beyond the protocol. So far, it has been largely\nunknown how decision-making addresses the challenges of different tasks. This\nwork systematically evaluates the impact of seven decision protocols (e.g.,\nmajority voting, unanimity consensus). We change only one variable at a time\n(i.e., decision protocol) to analyze how different methods affect the\ncollaboration between agents and test different protocols on knowledge (MMLU,\nMMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQuAD 2.0). Our\nresults show that voting protocols improve performance by 13.2% in reasoning\ntasks and consensus protocols by 2.8% in knowledge tasks over the other\ndecision protocol. Increasing the number of agents improves performance, while\nmore discussion rounds before voting reduces it. To improve decision-making by\nincreasing answer diversity, we propose two new methods, All-Agents Drafting\n(AAD) and Collective Improvement (CI). Our methods improve task performance by\nup to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the\nimportance of decision-making in multi-agent debates beyond scaling.",
      "tldr_zh": "本研究系统评估了多智能体辩论中的七种决策协议（如majority voting和unanimity consensus），探讨它们如何影响代理间的协作，测试对象包括知识任务（MMLU, MMLU-Pro, GPQA）和推理任务（StrategyQA, MuSR, SQuAD 2.0）。结果显示，voting protocols在推理任务中提升性能13.2%，而consensus protocols在知识任务中提高2.8%；增加智能体数量可改善整体表现，但增加讨论轮次则会降低性能。研究提出两种新方法，All-Agents Drafting (AAD)和Collective Improvement (CI)，分别提升任务性能至多3.3%和7.4%，强调决策协议在多智能体辩论中的关键作用，而非仅依赖规模扩展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19130v1",
      "published_date": "2025-02-26 13:39:18 UTC",
      "updated_date": "2025-02-26 13:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:19:44.294365"
    },
    {
      "arxiv_id": "2502.19123v1",
      "title": "From Traditional to Deep Learning Approaches in Whole Slide Image Registration: A Methodological Review",
      "title_zh": "翻译失败",
      "authors": [
        "Behnaz Elhaminia",
        "Abdullah Alsalemi",
        "Esha Nasir",
        "Mostafa Jahanifar",
        "Ruqayya Awan",
        "Lawrence S. Young",
        "Nasir M. Rajpoot",
        "Fayyaz Minhas",
        "Shan E Ahmed Raza"
      ],
      "abstract": "Whole slide image (WSI) registration is an essential task for analysing the\ntumour microenvironment (TME) in histopathology. It involves the alignment of\nspatial information between WSIs of the same section or serial sections of a\ntissue sample. The tissue sections are usually stained with single or multiple\nbiomarkers before imaging, and the goal is to identify neighbouring nuclei\nalong the Z-axis for creating a 3D image or identifying subclasses of cells in\nthe TME. This task is considerably more challenging compared to radiology image\nregistration, such as magnetic resonance imaging or computed tomography, due to\nvarious factors. These include gigapixel size of images, variations in\nappearance between differently stained tissues, changes in structure and\nmorphology between non-consecutive sections, and the presence of artefacts,\ntears, and deformations. Currently, there is a noticeable gap in the literature\nregarding a review of the current approaches and their limitations, as well as\nthe challenges and opportunities they present. We aim to provide a\ncomprehensive understanding of the available approaches and their application\nfor various purposes. Furthermore, we investigate current deep learning methods\nused for WSI registration, emphasising their diverse methodologies. We examine\nthe available datasets and explore tools and software employed in the field.\nFinally, we identify open challenges and potential future trends in this area\nof research.",
      "tldr_zh": "这篇论文对Whole Slide Image (WSI) 注册方法进行了方法论综述，从传统方法到深度学习方法，聚焦于组织病理学中肿瘤微环境 (TME) 的分析。论文强调了WSI注册的独特挑战，包括图像的巨像素规模、染色差异、结构变化以及人工制品的影响，这些使它比放射学图像注册更复杂。综述调查了现有方法的应用、限制、数据集、工具和软件，并指出了未来研究的方向，如开放挑战和新兴趋势。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19123v1",
      "published_date": "2025-02-26 13:24:16 UTC",
      "updated_date": "2025-02-26 13:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:19:55.455190"
    },
    {
      "arxiv_id": "2502.19119v1",
      "title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning",
      "title_zh": "翻译失败",
      "authors": [
        "Guikun Chen",
        "Xu Zhang",
        "Yi Yang",
        "Wenguan Wang"
      ],
      "abstract": "Chemical reaction data is a pivotal asset, driving advances in competitive\nfields such as pharmaceuticals, materials science, and industrial chemistry.\nIts proprietary nature renders it sensitive, as it often includes confidential\ninsights and competitive advantages organizations strive to protect. However,\nin contrast to this need for confidentiality, the current standard training\nparadigm for machine learning-based retrosynthesis gathers reaction data from\nmultiple sources into one single edge to train prediction models. This paradigm\nposes considerable privacy risks as it necessitates broad data availability\nacross organizational boundaries and frequent data transmission between\nentities, potentially exposing proprietary information to unauthorized access\nor interception during storage and transfer. In the present study, we introduce\nthe chemical knowledge-informed framework (CKIF), a privacy-preserving approach\nfor learning retrosynthesis models. CKIF enables distributed training across\nmultiple chemical organizations without compromising the confidentiality of\nproprietary reaction data. Instead of gathering raw reaction data, CKIF learns\nretrosynthesis models through iterative, chemical knowledge-informed\naggregation of model parameters. In particular, the chemical properties of\npredicted reactants are leveraged to quantitatively assess the observable\nbehaviors of individual models, which in turn determines the adaptive weights\nused for model aggregation. On a variety of reaction datasets, CKIF outperforms\nseveral strong baselines by a clear margin (e.g., ~20% performance improvement\nover FedAvg on USPTO-50K), showing its feasibility and superiority to stimulate\nfurther research on privacy-preserving retrosynthesis.",
      "tldr_zh": "本研究针对化学反应数据的隐私风险，提出了一种化学知识-informed framework (CKIF)，用于隐私-aware retrosynthesis 学习。该框架支持多组织分布式训练，通过迭代聚合模型参数而非共享原始数据，避免了数据传输中的泄露风险。CKIF 利用化学性质量化评估模型行为，并动态调整聚合权重，以提升模型性能。在 USPTO-50K 等数据集上，CKIF 比 FedAvg 等基线提高了约 20% 的表现，证明了其在隐私保护 retrosynthesis 领域的可行性和优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19119v1",
      "published_date": "2025-02-26 13:13:24 UTC",
      "updated_date": "2025-02-26 13:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:20:06.799171"
    },
    {
      "arxiv_id": "2502.19115v2",
      "title": "Improving Customer Service with Automatic Topic Detection in User Emails",
      "title_zh": "利用自动主题检测改善用户电子邮件中的客户服务",
      "authors": [
        "Bojana Bašaragin",
        "Darija Medvecki",
        "Gorana Gojić",
        "Milena Oparnica",
        "Dragiša Mišković"
      ],
      "abstract": "This study introduces a novel natural language processing pipeline that\nenhances customer service efficiency at Telekom Srbija, a leading Serbian\ntelecommunications company, through automated email topic detection and\nlabeling. Central to the pipeline is BERTopic, a modular framework that allows\nunsupervised topic modeling. After a series of preprocessing and postprocessing\nsteps, we assign one of 12 topics and several additional labels to incoming\nemails, allowing the customer service to filter and access them through a\ncustom-made application. The model's performance was evaluated by assessing the\nspeed and correctness of the automatically assigned topics, with a weighted\naverage processing time of 0.041 seconds per email and a weighted average F1\nscore of 0.96. The pipeline shows broad applicability across languages,\nparticularly to those that are low-resourced and morphologically rich. The\nsystem now operates in the company's production environment, streamlining\ncustomer service operations through automated email classification.",
      "tldr_zh": "这篇论文提出了一种新型自然语言处理(NLP)管道，使用BERTopic框架来自动检测和标记用户电子邮件的主题，从而提升Telekom Srbija电信公司的客户服务效率。管道通过预处理和后处理步骤，将电子邮件分配到12个主题和额外标签，并通过自定义应用实现过滤和访问。实验结果显示，该系统加权平均处理时间为0.041秒/电子邮件，加权平均F1 score为0.96，并已在生产环境中运行，适用于低资源和形态丰富的语言。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted to the 15th International Conference on Information\n  Society and Technology (ICIST), Kopaonik, Serbia, 9-12 March 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19115v2",
      "published_date": "2025-02-26 13:10:38 UTC",
      "updated_date": "2025-04-07 08:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:20:18.452791"
    },
    {
      "arxiv_id": "2502.19107v1",
      "title": "The Shady Light of Art Automation",
      "title_zh": "翻译失败",
      "authors": [
        "Dejan Grba"
      ],
      "abstract": "Generative artificial intelligence (generative AI) has entered the mainstream\nculture and become a subject of extensive academic investigation. However, the\ncharacter and background of its impact on art require subtler scrutiny and more\nnuanced contextualization. This paper summarizes a broader study of the roles\nthat AI's conceptual and ideological substrata play in influencing art notions.\nThe focus is on divergent but coalescing and often questionable ideas, values,\nand political views that generative AI and other art-related AI technologies\npropagate from the computer science and AI/tech industry to the contemporary\nart and culture. The paper maps the main areas of this complex relationship and\nconcisely critiques their key aspects.",
      "tldr_zh": "这篇论文审视了生成式人工智能（generative AI）对艺术的影响，强调其概念和意识形态基础如何传播并塑造艺术观念。作者总结了一个更广泛的研究，聚焦于 generative AI 和其他艺术相关 AI 技术从计算机科学及 AI/tech 行业向当代艺术和文化传播的分歧却融合的想法、价值观和政治观点，这些往往存在争议。论文映射了这一复杂关系的主要领域，并对关键方面进行简要批判，呼吁更细致的审视和语境化分析。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ISEA 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19107v1",
      "published_date": "2025-02-26 12:50:05 UTC",
      "updated_date": "2025-02-26 12:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:20:29.633992"
    },
    {
      "arxiv_id": "2502.19095v1",
      "title": "XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study",
      "title_zh": "翻译失败",
      "authors": [
        "Samuele Pasini",
        "Gianluca Maragliano",
        "Jinhan Kim",
        "Paolo Tonella"
      ],
      "abstract": "Cross-site scripting (XSS) poses a significant threat to web application\nsecurity. While Deep Learning (DL) has shown remarkable success in detecting\nXSS attacks, it remains vulnerable to adversarial attacks due to the\ndiscontinuous nature of its input-output mapping. These adversarial attacks\nemploy mutation-based strategies for different components of XSS attack\nvectors, allowing adversarial agents to iteratively select mutations to evade\ndetection. Our work replicates a state-of-the-art XSS adversarial attack,\nhighlighting threats to validity in the reference work and extending it toward\na more effective evaluation strategy. Moreover, we introduce an XSS Oracle to\nmitigate these threats. The experimental results show that our approach\nachieves an escape rate above 96% when the threats to validity of the\nreplicated technique are addressed.",
      "tldr_zh": "这篇论文复制并扩展了一个基于深度强化学习的 XSS 对抗攻击研究，旨在揭示深度学习（Deep Learning）在检测跨站脚本（XSS）攻击时的脆弱性，特别是通过突变策略迭代规避检测。研究者引入了 XSS Oracle 来缓解参考工作的有效性威胁，提供更可靠的评估策略。主要结果显示，改进后的方法在解决这些威胁后，攻击逃逸率超过96%，突显了现有 XSS 检测系统的潜在风险。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19095v1",
      "published_date": "2025-02-26 12:39:55 UTC",
      "updated_date": "2025-02-26 12:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:20:41.202324"
    },
    {
      "arxiv_id": "2503.01874v1",
      "title": "CABS: Conflict-Aware and Balanced Sparsification for Enhancing Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Zongzhen Yang",
        "Binhang Qi",
        "Hailong Sun",
        "Wenrui Long",
        "Ruobing Zhao",
        "Xiang Gao"
      ],
      "abstract": "Model merging based on task vectors, i.e., the parameter differences between\nfine-tuned models and a shared base model, provides an efficient way to\nintegrate multiple task-specific models into a multitask model without\nretraining. Recent works have endeavored to address the conflicts between task\nvectors, one of the significant challenges faced by model merging, through\nsparsification; however, two issues significantly limit their performance: high\nparameter overlap and unbalanced weight distribution. To address these issues,\nwe propose a simple, yet effective framework called CABS (Conflict-Aware and\nBalanced Sparsification), consisting of Conflict-Aware Sparsification (CA) and\nBalanced Sparsification (BS). CA can reduce parameter overlap by applying masks\nduring sequential pruning, ensuring that each task vector retains distinct,\nnon-overlapping parameters. BS leverages $n$: $m$ pruning to preserve critical\nweights while maintaining an even distribution across layers. Our comprehensive\nexperiments demonstrate that CABS outperforms state-of-the-art methods across\ndiverse tasks and model sizes.",
      "tldr_zh": "该论文提出 CABS（Conflict-Aware and Balanced Sparsification）框架，用于提升模型合并的效率，针对任务 vectors 中的冲突问题，通过减少高 parameter overlap 和不平衡权重分布来整合多任务模型，而无需重新训练。CABS 包括 Conflict-Aware Sparsification (CA)，通过应用 masks 在顺序 pruning 中确保每个任务 vector 保留 distinct, non-overlapping parameters；以及 Balanced Sparsification (BS)，利用 n:m pruning 保留关键权重并保持层间均匀分布。实验结果表明，CABS 在多样任务和模型大小上超越最先进方法，提供了一种简单有效的模型合并优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01874v1",
      "published_date": "2025-02-26 12:38:55 UTC",
      "updated_date": "2025-02-26 12:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:20:53.742430"
    },
    {
      "arxiv_id": "2502.19091v1",
      "title": "Nexus: A Lightweight and Scalable Multi-Agent Framework for Complex Tasks Automation",
      "title_zh": "Nexus: 轻量级且可扩展的多智能体框架，用于复杂任务自动化",
      "authors": [
        "Humza Sami",
        "Mubashir ul Islam",
        "Samy Charas",
        "Asav Gandhi",
        "Pierre-Emmanuel Gaillardon",
        "Valerio Tenace"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have substantially\nevolved Multi-Agent Systems (MASs) capabilities, enabling systems that not only\nautomate tasks but also leverage near-human reasoning capabilities. To achieve\nthis, LLM-based MASs need to be built around two critical principles: (i) a\nrobust architecture that fully exploits LLM potential for specific tasks -- or\nrelated task sets -- and ($ii$) an effective methodology for equipping LLMs\nwith the necessary capabilities to perform tasks and manage information\nefficiently. It goes without saying that a priori architectural designs can\nlimit the scalability and domain adaptability of a given MAS.\n  To address these challenges, in this paper we introduce Nexus: a lightweight\nPython framework designed to easily build and manage LLM-based MASs. Nexus\nintroduces the following innovations: (i) a flexible multi-supervisor\nhierarchy, (ii) a simplified workflow design, and (iii) easy installation and\nopen-source flexibility: Nexus can be installed via pip and is distributed\nunder a permissive open-source license, allowing users to freely modify and\nextend its capabilities.\n  Experimental results demonstrate that architectures built with Nexus exhibit\nstate-of-the-art performance across diverse domains. In coding tasks,\nNexus-driven MASs achieve a 99% pass rate on HumanEval and a flawless 100% on\nVerilogEval-Human, outperforming cutting-edge reasoning language models such as\no3-mini and DeepSeek-R1. Moreover, these architectures display robust\nproficiency in complex reasoning and mathematical problem solving, achieving\ncorrect solutions for all randomly selected problems from the MATH dataset. In\nthe realm of multi-objective optimization, Nexus-based architectures\nsuccessfully address challenging timing closure tasks on designs from the VTR\nbenchmark suite, while guaranteeing, on average, a power saving of nearly 30%.",
      "tldr_zh": "本研究引入了Nexus，一个轻量级且可扩展的Python框架，用于构建和管理基于Large Language Models (LLMs)的Multi-Agent Systems (MASs)，以解决任务自动化中的架构局限性和可扩展性挑战。Nexus的关键创新包括灵活的多监督者层次结构、简化的工作流设计，以及易于通过pip安装的开源灵活性。实验结果显示，Nexus驱动的架构在编码任务中表现出色，如HumanEval达到99%通过率、VerilogEval-Human达100%，并优于o3-mini和DeepSeek-R1；在复杂推理和数学问题上，成功解决MATH数据集的所有随机问题；在多目标优化中，实现VTR基准套件的定时闭合任务并平均节省30%功率。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19091v1",
      "published_date": "2025-02-26 12:37:47 UTC",
      "updated_date": "2025-02-26 12:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:21:06.489109"
    },
    {
      "arxiv_id": "2503.16465v1",
      "title": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Pengzhou Cheng",
        "Zheng Wu",
        "Zongru Wu",
        "Aston Zhang",
        "Zhuosheng Zhang",
        "Gongshen Liu"
      ],
      "abstract": "Autonomous graphical user interface (GUI) agents powered by multimodal large\nlanguage models have shown great promise. However, a critical yet underexplored\nissue persists: over-execution, where the agent executes tasks in a fully\nautonomous way, without adequate assessment of its action confidence to\ncompromise an adaptive human-agent collaboration. This poses substantial risks\nin complex scenarios, such as those involving ambiguous user instructions,\nunexpected interruptions, and environmental hijacks. To address the issue, we\nintroduce OS-Kairos, an adaptive GUI agent capable of predicting confidence\nlevels at each interaction step and efficiently deciding whether to act\nautonomously or seek human intervention. OS-Kairos is developed through two key\nmechanisms: (i) collaborative probing that annotates confidence scores at each\ninteraction step; (ii) confidence-driven interaction that leverages these\nconfidence scores to elicit the ability of adaptive interaction. Experimental\nresults show that OS-Kairos substantially outperforms existing models on our\ncurated dataset featuring complex scenarios, as well as on established\nbenchmarks such as AITZ and Meta-GUI, with 24.59\\%$\\sim$87.29\\% improvements in\ntask success rate. OS-Kairos facilitates an adaptive human-agent collaboration,\nprioritizing effectiveness, generality, scalability, and efficiency for\nreal-world GUI interaction. The dataset and codes are available at\nhttps://github.com/Wuzheng02/OS-Kairos.",
      "tldr_zh": "该论文针对多模态大型语言模型（MLLM）驱动的图形用户界面（GUI）代理中存在的过度执行问题，提出了一种适应性交互框架 OS-Kairos，以评估行动信心并实现自主行动与人类干预的动态切换。该框架通过协作探测（collaborative probing）机制标注每个交互步骤的信心分数，以及信心驱动交互（confidence-driven interaction）机制来优化决策。实验结果显示，OS-Kairos 在复杂场景数据集以及 AITZ 和 Meta-GUI 等基准上，任务成功率提升了 24.59% 到 87.29%，从而促进了高效、可扩展的人机协作。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "25 pages, 24 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.16465v1",
      "published_date": "2025-02-26 12:31:16 UTC",
      "updated_date": "2025-02-26 12:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:21:19.040943"
    },
    {
      "arxiv_id": "2503.00049v1",
      "title": "Omni-SILA: Towards Omni-scene Driven Visual Sentiment Identifying, Locating and Attributing in Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Jiamin Luo",
        "Jingjing Wang",
        "Junxiao Ma",
        "Yujie Jin",
        "Shoushan Li",
        "Guodong Zhou"
      ],
      "abstract": "Prior studies on Visual Sentiment Understanding (VSU) primarily rely on the\nexplicit scene information (e.g., facial expression) to judge visual\nsentiments, which largely ignore implicit scene information (e.g., human\naction, objection relation and visual background), while such information is\ncritical for precisely discovering visual sentiments. Motivated by this, this\npaper proposes a new Omni-scene driven visual Sentiment Identifying, Locating\nand Attributing in videos (Omni-SILA) task, aiming to interactively and\nprecisely identify, locate and attribute visual sentiments through both\nexplicit and implicit scene information. Furthermore, this paper believes that\nthis Omni-SILA task faces two key challenges: modeling scene and highlighting\nimplicit scene beyond explicit. To this end, this paper proposes an\nImplicit-enhanced Causal MoE (ICM) approach for addressing the Omni-SILA task.\nSpecifically, a Scene-Balanced MoE (SBM) and an Implicit-Enhanced Causal (IEC)\nblocks are tailored to model scene information and highlight the implicit scene\ninformation beyond explicit, respectively. Extensive experimental results on\nour constructed explicit and implicit Omni-SILA datasets demonstrate the great\nadvantage of the proposed ICM approach over advanced Video-LLMs.",
      "tldr_zh": "本研究指出，现有的 Visual Sentiment Understanding (VSU) 主要依赖显式场景信息（如面部表情），忽略了隐式场景信息（如人类动作、物体关系和视觉背景），从而提出 Omni-SILA 任务，旨在通过显式和隐式场景信息交互式地识别、定位和归因视频中的视觉情感。针对该任务的关键挑战，论文引入 Implicit-enhanced Causal MoE (ICM) 方法，包括 Scene-Balanced MoE (SBM) 用于建模场景信息，以及 Implicit-Enhanced Causal (IEC) 用于突出隐式场景信息。实验结果显示，在构建的显式和隐式 Omni-SILA 数据集上，ICM 方法比先进的 Video-LLMs 表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00049v1",
      "published_date": "2025-02-26 12:05:07 UTC",
      "updated_date": "2025-02-26 12:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:21:30.088094"
    },
    {
      "arxiv_id": "2502.19026v1",
      "title": "InternVQA: Advancing Compressed Video Quality Assessment with Distilling Large Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Fengbin Guan",
        "Zihao Yu",
        "Yiting Lu",
        "Xin Li",
        "Zhibo Chen"
      ],
      "abstract": "Video quality assessment tasks rely heavily on the rich features required for\nvideo understanding, such as semantic information, texture, and temporal\nmotion. The existing video foundational model, InternVideo2, has demonstrated\nstrong potential in video understanding tasks due to its large parameter size\nand large-scale multimodal data pertaining. Building on this, we explored the\ntransferability of InternVideo2 to video quality assessment under compression\nscenarios. To design a lightweight model suitable for this task, we proposed a\ndistillation method to equip the smaller model with rich compression quality\npriors. Additionally, we examined the performance of different backbones during\nthe distillation process. The results showed that, compared to other methods,\nour lightweight model distilled from InternVideo2 achieved excellent\nperformance in compression video quality assessment.",
      "tldr_zh": "该论文探讨了利用大型视频基础模型 InternVideo2 来提升压缩视频质量评估（compressed video quality assessment）的性能，针对视频理解所需特征如语义信息、纹理和时间运动。作者提出了一种知识蒸馏方法（distillation method），将 InternVideo2 的知识转移到轻量级模型中，并评估了不同骨干网络（backbones）在蒸馏过程中的表现。结果表明，该轻量级模型在压缩视频质量评估任务中比其他方法取得了卓越性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by ISCAS 2025(Lecture)",
      "pdf_url": "http://arxiv.org/pdf/2502.19026v1",
      "published_date": "2025-02-26 10:34:14 UTC",
      "updated_date": "2025-02-26 10:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:21:42.101305"
    },
    {
      "arxiv_id": "2502.19024v1",
      "title": "Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Zerui Li",
        "Gengze Zhou",
        "Haodong Hong",
        "Yanyan Shao",
        "Wenqi Lyu",
        "Yanyuan Qiao",
        "Qi Wu"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) empowers agents to associate\ntime-sequenced visual observations with corresponding instructions to make\nsequential decisions. However, generalization remains a persistent challenge,\nparticularly when dealing with visually diverse scenes or transitioning from\nsimulated environments to real-world deployment. In this paper, we address the\nmismatch between human-centric instructions and quadruped robots with a\nlow-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav)\napproach to mitigate this issue. This work represents the first attempt to\nhighlight the generalization gap in VLN across varying heights of visual\nobservation in realistic robot deployments. Our approach leverages weighted\nhistorical observations as enriched spatiotemporal contexts for instruction\nfollowing, effectively managing feature collisions within cells by assigning\nappropriate weights to identical features across different viewpoints. This\nenables low-height robots to overcome challenges such as visual obstructions\nand perceptual mismatches. Additionally, we transfer the connectivity graph\nfrom the HM3D and Gibson datasets as an extra resource to enhance spatial\npriors and a more comprehensive representation of real-world scenarios, leading\nto improved performance and generalizability of the waypoint predictor in\nreal-world environments. Extensive experiments demonstrate that our\nGround-level Viewpoint Navigation (GVnav) approach significantly improves\nperformance in both simulated environments and real-world deployments with\nquadruped robots.",
      "tldr_zh": "这篇论文针对 Vision-and-Language Navigation (VLN) 在视觉多样场景和从模拟到真实世界的泛化挑战，提出 Ground-level Viewpoint Navigation (GVNav) 方法，以适应四足 robots 的低高度视野问题。GVNav 通过加权历史观察作为丰富的时空上下文，管理特征冲突，并转移 HM3D 和 Gibson 数据集的连接图来增强空间先验，从而改善导航决策。实验结果表明，该方法在模拟环境和真实部署中显著提升了性能，帮助低高度 robots 克服视觉障碍和感知不匹配。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19024v1",
      "published_date": "2025-02-26 10:30:40 UTC",
      "updated_date": "2025-02-26 10:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:21:54.064224"
    },
    {
      "arxiv_id": "2502.19023v1",
      "title": "Dealing with Inconsistency for Reasoning over Knowledge Graphs: A Survey",
      "title_zh": "处理知识图谱上推理的不一致性：一个综述",
      "authors": [
        "Anastasios Nentidis",
        "Charilaos Akasiadis",
        "Angelos Charalambidis",
        "Alexander Artikis"
      ],
      "abstract": "In Knowledge Graphs (KGs), where the schema of the data is usually defined by\nparticular ontologies, reasoning is a necessity to perform a range of tasks,\nsuch as retrieval of information, question answering, and the derivation of new\nknowledge. However, information to populate KGs is often extracted (semi-)\nautomatically from natural language resources, or by integrating datasets that\nfollow different semantic schemas, resulting in KG inconsistency. This,\nhowever, hinders the process of reasoning. In this survey, we focus on how to\nperform reasoning on inconsistent KGs, by analyzing the state of the art\ntowards three complementary directions: a) the detection of the parts of the KG\nthat cause the inconsistency, b) the fixing of an inconsistent KG to render it\nconsistent, and c) the inconsistency-tolerant reasoning. We discuss existing\nwork from a range of relevant fields focusing on how, and in which cases they\nare related to the above directions. We also highlight persisting challenges\nand future directions.",
      "tldr_zh": "这篇调查论文探讨了知识图谱(KGs)中不一致性对推理过程的影响，不一致性通常源于从自然语言资源提取数据或整合不同语义模式的数据集。论文从三个关键方向分析现有技术：a) 检测导致不一致性的KG部分，b) 修复不一致的KG使其符合本体(schema)，以及c) 进行容忍不一致性的推理。最终，它总结了相关领域的进展，突出了持续挑战如自动化处理和未来研究方向，以提升KGs在信息检索、问答和知识推导中的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19023v1",
      "published_date": "2025-02-26 10:30:22 UTC",
      "updated_date": "2025-02-26 10:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:22:06.582545"
    },
    {
      "arxiv_id": "2502.19460v3",
      "title": "Overcoming Dependent Censoring in the Evaluation of Survival Models",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Marius Lillelund",
        "Shi-ang Qi",
        "Russell Greiner"
      ],
      "abstract": "Conventional survival metrics, such as Harrell's concordance index (CI) and\nthe Brier Score, rely on the independent censoring assumption for valid\ninference with right-censored data. However, in the presence of so-called\ndependent censoring, where the probability of censoring is related to the event\nof interest, these metrics can give biased estimates of the underlying model\nerror. In this paper, we introduce three new evaluation metrics for survival\nanalysis based on Archimedean copulas that can account for dependent censoring.\nWe also develop a framework to generate realistic, semi-synthetic datasets with\ndependent censoring to facilitate the evaluation of the metrics. Our\nexperiments in synthetic and semi-synthetic data demonstrate that the proposed\nmetrics can provide more accurate estimates of the model error than\nconventional metrics under dependent censoring.",
      "tldr_zh": "传统生存分析指标如 Harrell's concordance index (CI) 和 Brier Score 假设 censoring 是独立的，但在 dependent censoring（censoring 概率与事件相关）情况下，这些指标会产生偏差的模型错误估计。  \n本文引入三种基于 Archimedean copulas 的新评估指标，能够有效处理 dependent censoring 的影响。  \n此外，作者开发了一个框架来生成现实的半合成数据集，用于评估这些指标，并在合成和半合成数据实验中证明，新指标比传统方法更准确地估计了模型错误。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19460v3",
      "published_date": "2025-02-26 10:28:44 UTC",
      "updated_date": "2025-05-19 17:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:22:19.054931"
    },
    {
      "arxiv_id": "2502.19014v1",
      "title": "Robust Over-the-Air Computation with Type-Based Multiple Access",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Martinez-Gost",
        "Ana Pérez-Neira",
        "Miguel Ángel Lagunas"
      ],
      "abstract": "This paper utilizes the properties of type-based multiple access (TBMA) to\ninvestigate its effectiveness as a robust approach for over-the-air computation\n(AirComp) in the presence of Byzantine attacks, this is, adversarial strategies\nwhere malicious nodes intentionally distort their transmissions to corrupt the\naggregated result. Unlike classical direct aggregation (DA) AirComp, which\naggregates data in the amplitude of the signals and are highly vulnerable to\nattacks, TBMA distributes data over multiple radio resources, enabling the\nreceiver to construct a histogram representation of the transmitted data. This\nstructure allows the integration of classical robust estimators and supports\nthe computation of diverse functions beyond the arithmetic mean, which is not\nfeasible with DA. Through extensive simulations, we demonstrate that robust\nTBMA significantly outperforms DA, maintaining high accuracy even under\nadversarial conditions, and showcases its applicability in federated learning\n(FEEL) scenarios. Additionally, TBMA reduces channel state information (CSI)\nrequirements, lowers energy consumption, and enhances resiliency by leveraging\nthe diversity of the transmitted data. These results establish TBMA as a\nscalable and robust solution for AirComp, paving the way for secure and\nefficient aggregation in next-generation networks.",
      "tldr_zh": "这篇论文探讨了利用 Type-Based Multiple Access (TBMA) 作为 Over-the-Air Computation (AirComp) 的鲁棒方法，以应对 Byzantine attacks（恶意节点故意扭曲传输破坏聚合结果）。与传统的 Direct Aggregation (DA) AirComp 不同，TBMA 通过在多个无线资源上分发数据并构建传输数据的直方图表示，支持整合鲁棒估计器和计算多种函数，从而显著提升了系统抗攻击能力。模拟实验结果显示，TBMA 在对抗条件下比 DA 准确率更高，并在 Federated Learning (FEEL) 场景中表现出色，同时减少了 Channel State Information (CSI) 需求、降低了能量消耗，并通过数据多样性增强了弹性。这些发现确立了 TBMA 作为 AirComp 的可扩展、安全高效解决方案，为下一代网络的数据聚合铺平道路。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Paper submitted to 33rd European Signal Processing Conference\n  (EUSIPCO 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.19014v1",
      "published_date": "2025-02-26 10:22:00 UTC",
      "updated_date": "2025-02-26 10:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:22:33.164829"
    },
    {
      "arxiv_id": "2502.19009v1",
      "title": "Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyeon Son",
        "Soochan Lee",
        "Gunhee Kim"
      ],
      "abstract": "Recent studies have shown that Transformers can perform in-context\nreinforcement learning (RL) by imitating existing RL algorithms, enabling\nsample-efficient adaptation to unseen tasks without parameter updates. However,\nthese models also inherit the suboptimal behaviors of the RL algorithms they\nimitate. This issue primarily arises due to the gradual update rule employed by\nthose algorithms. Model-based planning offers a promising solution to this\nlimitation by allowing the models to simulate potential outcomes before taking\naction, providing an additional mechanism to deviate from the suboptimal\nbehavior. Rather than learning a separate dynamics model, we propose\nDistillation for In-Context Planning (DICP), an in-context model-based RL\nframework where Transformers simultaneously learn environment dynamics and\nimprove policy in-context. We evaluate DICP across a range of discrete and\ncontinuous environments, including Darkroom variants and Meta-World. Our\nresults show that DICP achieves state-of-the-art performance while requiring\nsignificantly fewer environment interactions than baselines, which include both\nmodel-free counterparts and existing meta-RL methods.",
      "tldr_zh": "该研究指出，现有的 Transformer 在进行 in-context reinforcement learning (RL) 时会继承被模仿 RL 算法的次优行为，主要由于其渐进更新规则。为解决此问题，作者提出 Distillation for In-Context Planning (DICP) 框架，这是一种 in-context model-based RL 方法，允许 Transformer 同时学习环境动态并在上下文中改进策略，而非单独训练动态模型。在 Darkroom variants 和 Meta-World 等离散和连续环境中，DICP 实现了最先进的性能，并比 model-free 基线和现有 meta-RL 方法显著减少了环境交互量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.19009v1",
      "published_date": "2025-02-26 10:16:57 UTC",
      "updated_date": "2025-02-26 10:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:22:43.745194"
    },
    {
      "arxiv_id": "2502.19008v1",
      "title": "Binary Neural Networks for Large Language Model: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Liangdong Liu",
        "Zhitong Zheng",
        "Cong Wang",
        "Tianhuang Su",
        "Zhenyu Yang"
      ],
      "abstract": "Large language models (LLMs) have wide applications in the field of natural\nlanguage processing(NLP), such as GPT-4 and Llama. However, with the\nexponential growth of model parameter sizes, LLMs bring significant resource\noverheads. Low-bit quantization, as a key technique, reduces memory usage and\ncomputational demands by decreasing the bit-width of model parameters,\nactivations, and gradients. Previous quantization methods for LLMs have largely\nemployed Post-Training Quantization (PTQ) and Quantization-Aware Training\n(QAT). PTQ does not require any retraining of the original model, while QAT\ninvolves optimizing precision during training to achieve the best quantization\nparameters. The BitNet team proposed a radically different approach, where\nquantization is performed from the start of model training, utilizing\nlow-precision binary weights during the training process. This approach has led\nto the emergence of many binary quantization techniques for large language\nmodels. This paper provides a comprehensive review of these binary quantization\ntechniques. Specifically, we will introduce binary quantization techniques in\ndeep neural networks and further explore their application to LLMs, reviewing\ntheir various contributions, implementations, and applications.",
      "tldr_zh": "这篇论文对二进制神经网络(Binary Neural Networks)在大型语言模型(LLMs)中的应用进行了全面调查，旨在解决LLMs如GPT-4和Llama因参数规模增长带来的资源开销问题。论文回顾了现有的量化技术，包括后训练量化(PTQ)和量化感知训练(QAT)，并介绍了BitNet团队的创新方法，即从模型训练开始使用低精度二进制权重。最终，它探讨了这些二进制量化技术的贡献、实现和在LLMs中的应用潜力，为高效的模型优化提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19008v1",
      "published_date": "2025-02-26 10:14:19 UTC",
      "updated_date": "2025-02-26 10:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:22:55.466009"
    },
    {
      "arxiv_id": "2503.05779v1",
      "title": "Homomorphic Encryption of Intuitionistic Logic Proofs and Functional Programs: A Categorical Approach Inspired by Composite-Order Bilinear Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Goertzel"
      ],
      "abstract": "We present a conceptual framework for extending homomorphic encryption beyond\narithmetic or Boolean operations into the domain of intuitionistic logic proofs\nand, by the Curry-Howard correspondence, into the domain of typed functional\nprograms. We begin by reviewing well-known homomorphic encryption schemes for\narithmetic operations, and then discuss the adaptation of similar concepts to\nsupport logical inference steps in intuitionistic logic. Key to our\nconstruction are polynomial functors and Bounded Natural Functors (BNFs), which\nserve as a categorical substrate on which logic formulas and proofs are\nrepresented and manipulated. We outline a complexity-theoretic hardness\nassumption -- the BNF Distinguishing Problem, constructed via a reduction from\nSubgraph Isomorphism, providing a foundation for cryptographic security.\nFinally, we describe how these methods can homomorphically encode the execution\nof total, dependently typed functional programs, and outline strategies for\nmaking the approach potentially efficient, including software optimizations and\nhardware acceleration.",
      "tldr_zh": "这篇论文提出一个概念框架，将 Homomorphic Encryption 扩展到 Intuitionistic Logic 证明和类型化函数程序领域，利用 Curry-Howard Correspondence 将逻辑推理与程序执行相联系。关键方法基于 Polynomial Functors 和 Bounded Natural Functors (BNFs) 作为范畴论基础，并引入 BNF Distinguishing Problem（通过 Subgraph Isomorphism 归约构建）作为复杂度理论的安全假设。最终，该框架支持同态编码总的、Dependently Typed Functional Programs 的执行，并探讨了软件优化和硬件加速等策略以提升效率。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05779v1",
      "published_date": "2025-02-26 10:10:10 UTC",
      "updated_date": "2025-02-26 10:10:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:23:05.973057"
    },
    {
      "arxiv_id": "2502.19004v1",
      "title": "A Multi-Agent DRL-Based Framework for Optimal Resource Allocation and Twin Migration in the Multi-Tier Vehicular Metaverse",
      "title_zh": "翻译失败",
      "authors": [
        "Nahom Abishu Hayla",
        "A. Mohammed Seid",
        "Aiman Erbad",
        "Tilahun M. Getu",
        "Ala Al-Fuqaha",
        "Mohsen Guizani"
      ],
      "abstract": "Although multi-tier vehicular Metaverse promises to transform vehicles into\nessential nodes -- within an interconnected digital ecosystem -- using\nefficient resource allocation and seamless vehicular twin (VT) migration, this\ncan hardly be achieved by the existing techniques operating in a highly dynamic\nvehicular environment, since they can hardly balance multi-objective\noptimization problems such as latency reduction, resource utilization, and user\nexperience (UX). To address these challenges, we introduce a novel multi-tier\nresource allocation and VT migration framework that integrates Graph\nConvolutional Networks (GCNs), a hierarchical Stackelberg game-based incentive\nmechanism, and Multi-Agent Deep Reinforcement Learning (MADRL). The GCN-based\nmodel captures both spatial and temporal dependencies within the vehicular\nnetwork; the Stackelberg game-based incentive mechanism fosters cooperation\nbetween vehicles and infrastructure; and the MADRL algorithm jointly optimizes\nresource allocation and VT migration in real time. By modeling this dynamic and\nmulti-tier vehicular Metaverse as a Markov Decision Process (MDP), we develop a\nMADRL-based algorithm dubbed the Multi-Objective Multi-Agent Deep Deterministic\nPolicy Gradient (MO-MADDPG), which can effectively balances the various\nconflicting objectives. Extensive simulations validate the effectiveness of\nthis algorithm that is demonstrated to enhance scalability, reliability, and\nefficiency while considerably improving latency, resource utilization,\nmigration cost, and overall UX by 12.8%, 9.7%, 14.2%, and 16.1%, respectively.",
      "tldr_zh": "这篇论文提出了一种基于多智能体深度强化学习 (MADRL) 的框架，用于多层车辆元宇宙中实现最佳资源分配和车辆孪生 (VT) 迁移，以解决现有技术在动态环境中难以平衡延迟减少、资源利用和用户体验 (UX) 等多目标优化问题。该框架整合 Graph Convolutional Networks (GCNs) 来捕捉车辆网络的空间和时间依赖性、基于 Stackelberg 游戏的激励机制来促进车辆与基础设施的合作，以及 MO-MADDPG 算法来实时优化资源分配和 VT 迁移，将系统建模为 Markov Decision Process (MDP)。实验结果显示，该框架显著提升了系统的可伸缩性、可靠性和效率，分别将延迟、资源利用、迁移成本和整体 UX 改善了 12.8%、9.7%、14.2% 和 16.1%。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.NI",
      "comment": "15 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.19004v1",
      "published_date": "2025-02-26 10:09:05 UTC",
      "updated_date": "2025-02-26 10:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:23:19.695365"
    },
    {
      "arxiv_id": "2502.19002v1",
      "title": "The Sharpness Disparity Principle in Transformers for Accelerating Language Model Pre-Training",
      "title_zh": "Transformer 中用于加速语言模型预训练的锐度差异原则",
      "authors": [
        "Jinbo Wang",
        "Mingze Wang",
        "Zhanpeng Zhou",
        "Junchi Yan",
        "Weinan E",
        "Lei Wu"
      ],
      "abstract": "Transformers consist of diverse building blocks, such as embedding layers,\nnormalization layers, self-attention mechanisms, and point-wise feedforward\nnetworks. Thus, understanding the differences and interactions among these\nblocks is important. In this paper, we uncover a clear Sharpness Disparity\nacross these blocks, which emerges early in training and intriguingly persists\nthroughout the training process. Motivated by this finding, we propose\nBlockwise Learning Rate (LR), a strategy that tailors the LR to each block's\nsharpness, accelerating large language model (LLM) pre-training. By integrating\nBlockwise LR into AdamW, we consistently achieve lower terminal loss and nearly\n$2\\times$ speedup compared to vanilla AdamW. We demonstrate this acceleration\nacross GPT-2 and LLaMA, with model sizes ranging from 0.12B to 1.1B and\ndatasets of OpenWebText and MiniPile. Finally, we incorporate Blockwise LR into\nAdam-mini (Zhang et al., 2024), a recently proposed memory-efficient variant of\nAdam, achieving a combined $2\\times$ speedup and $2\\times$ memory saving. These\nresults underscore the potential of exploiting the sharpness disparity to\nimprove LLM training.",
      "tldr_zh": "本研究揭示了Transformer模型中各模块（如嵌入层、归一化层和self-attention机制）之间存在的Sharpness Disparity（锐度差异），这种差异在训练早期出现并持续存在。基于此，提出Blockwise Learning Rate（块级学习率）策略，通过针对每个模块的锐度调整学习率，加速大型语言模型（LLM）预训练，并将其整合到AdamW优化器中，实现更低的最终损失和近乎2倍的速度提升。在GPT-2和LLaMA模型（大小从0.12B到1.1B）上，使用OpenWebText和MiniPile数据集进行验证，还与Adam-mini结合实现了2倍速度提升和2倍内存节省，突显了利用Sharpness Disparity改善LLM训练的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.19002v1",
      "published_date": "2025-02-26 10:06:37 UTC",
      "updated_date": "2025-02-26 10:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:23:30.505199"
    },
    {
      "arxiv_id": "2502.18980v1",
      "title": "PEToolLLM: Towards Personalized Tool Learning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiancheng Xu",
        "Yongqi Li",
        "Heming Xia",
        "Fan Liu",
        "Min Yang",
        "Wenjie Li"
      ],
      "abstract": "Tool learning has emerged as a promising direction by extending Large\nLanguage Models' (LLMs) capabilities with external tools. Existing tool\nlearning studies primarily focus on the general-purpose tool-use capability,\nwhich addresses explicit user requirements in instructions. However, they\noverlook the importance of personalized tool-use capability, leading to an\ninability to handle implicit user preferences. To address the limitation, we\nfirst formulate the task of personalized tool learning, which integrates user's\ninteraction history towards personalized tool usage. To fill the gap of missing\nbenchmarks, we construct PEToolBench, featuring diverse user preferences\nreflected in interaction history under three distinct personalized settings,\nand encompassing a wide range of tool-use scenarios. Moreover, we propose a\nframework PEToolLLaMA to adapt LLMs to the personalized tool learning task,\nwhich is trained through supervised fine-tuning and direct preference\noptimization. Extensive experiments on PEToolBench demonstrate the superiority\nof PEToolLLaMA over existing LLMs.",
      "tldr_zh": "该研究针对现有工具学习方法忽略用户偏好的问题，提出了PEToolLLM框架，旨在实现大型语言模型（LLMs）的个性化工具学习。该框架首先定义了个性化工具学习任务，通过整合用户互动历史来处理隐式偏好，并构建了PEToolBench基准数据集，涵盖三种个性化设置和多种工具使用场景。为了适应这一任务，研究者开发了PEToolLLaMA框架，利用监督细调和直接偏好优化进行训练。实验结果显示，PEToolLLaMA在PEToolBench上显著优于现有LLMs，提升了模型的个性化工具使用能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18980v1",
      "published_date": "2025-02-26 09:43:08 UTC",
      "updated_date": "2025-02-26 09:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:23:41.981940"
    },
    {
      "arxiv_id": "2502.18978v3",
      "title": "Low-Confidence Gold: Refining Low-Confidence Samples for Efficient Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Cai",
        "Jie Li",
        "Wenzhen Dong"
      ],
      "abstract": "The effectiveness of instruction fine-tuning for Large Language Models is\nfundamentally constrained by the quality and efficiency of training datasets.\nThis work introduces Low-Confidence Gold (LCG), a novel filtering framework\nthat employs centroid-based clustering and confidence-guided selection for\nidentifying valuable instruction pairs. Through a semi-supervised approach\nusing a lightweight classifier trained on representative samples, LCG curates\nhigh-quality subsets while preserving data diversity. Experimental evaluation\ndemonstrates that models fine-tuned on LCG-filtered subsets of 6K samples\nachieve superior performance compared to existing methods, with substantial\nimprovements on MT-bench and consistent gains across comprehensive evaluation\nmetrics. The framework's efficacy while maintaining model performance\nestablishes a promising direction for efficient instruction tuning.",
      "tldr_zh": "本文提出 Low-Confidence Gold (LCG) 框架，用于优化指令微调数据集的质量和效率，通过 centroid-based clustering 和 confidence-guided selection 识别有价值的指令对。LCG 采用半监督方法，利用轻量级分类器训练于代表性样本，筛选出高质量子集的同时保留数据多样性。实验结果显示，在 6K 样本的 LCG 筛选子集上微调的模型，在 MT-bench 上表现优于现有方法，并在多种评估指标上实现显著提升。该框架为高效指令微调提供了高效且可靠的新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.18978v3",
      "published_date": "2025-02-26 09:37:21 UTC",
      "updated_date": "2025-03-08 09:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:23:55.817074"
    },
    {
      "arxiv_id": "2502.18969v1",
      "title": "(Mis)Fitting: A Survey of Scaling Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Margaret Li",
        "Sneha Kudugunta",
        "Luke Zettlemoyer"
      ],
      "abstract": "Modern foundation models rely heavily on using scaling laws to guide crucial\ntraining decisions. Researchers often extrapolate the optimal architecture and\nhyper parameters settings from smaller training runs by describing the\nrelationship between, loss, or task performance, and scale. All components of\nthis process vary, from the specific equation being fit, to the training setup,\nto the optimization method. Each of these factors may affect the fitted law,\nand therefore, the conclusions of a given study. We discuss discrepancies in\nthe conclusions that several prior works reach, on questions such as the\noptimal token to parameter ratio. We augment this discussion with our own\nanalysis of the critical impact that changes in specific details may effect in\na scaling study, and the resulting altered conclusions. Additionally, we survey\nover 50 papers that study scaling trends: while 45 of these papers quantify\nthese trends using a power law, most under-report crucial details needed to\nreproduce their findings. To mitigate this, we we propose a checklist for\nauthors to consider while contributing to scaling law research.",
      "tldr_zh": "本论文调查了scaling laws在现代基础模型训练中的应用，探讨了如何通过拟合损失或任务性能与规模的关系来指导架构和超参数选择。研究者分析了不同因素（如方程拟合、训练设置和优化方法）对scaling laws的影响，导致现有研究在问题如最佳token到参数比例上出现结论分歧，并通过自身实验验证这些细节变化可能带来的结果差异。作者调研了50多篇相关论文，发现45篇使用power law量化趋势，但多数未报告足够细节以复现发现。为此，他们提出一个检查清单，以提升scaling law研究的规范性和可复现性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 3 figure, first two authors contributed equally. ICLR, 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18969v1",
      "published_date": "2025-02-26 09:27:54 UTC",
      "updated_date": "2025-02-26 09:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:24:05.315228"
    },
    {
      "arxiv_id": "2503.05778v1",
      "title": "DreamNet: A Multimodal Framework for Semantic and Emotional Analysis of Sleep Narratives",
      "title_zh": "DreamNet：一个多模态框架，用于睡眠叙事的语义和情感分析",
      "authors": [
        "Tapasvi Panchagnula"
      ],
      "abstract": "Dream narratives provide a unique window into human cognition and emotion,\nyet their systematic analysis using artificial intelligence has been\nunderexplored. We introduce DreamNet, a novel deep learning framework that\ndecodes semantic themes and emotional states from textual dream reports,\noptionally enhanced with REM-stage EEG data. Leveraging a transformer-based\narchitecture with multimodal attention, DreamNet achieves 92.1% accuracy and\n88.4% F1-score in text-only mode (DNet-T) on a curated dataset of 1,500\nanonymized dream narratives, improving to 99.0% accuracy and 95.2% F1-score\nwith EEG integration (DNet-M). Strong dream-emotion correlations (e.g.,\nfalling-anxiety, r = 0.91, p < 0.01) highlight its potential for mental health\ndiagnostics, cognitive science, and personalized therapy. This work provides a\nscalable tool, a publicly available enriched dataset, and a rigorous\nmethodology, bridging AI and psychological research.",
      "tldr_zh": "本研究引入了DreamNet，一种基于transformer架构的多模态框架，用于从梦境叙述文本中解码语义主题和情感状态，并可通过REM-stage EEG数据增强分析。DreamNet在文本-only模式(DNet-T)上处理1,500个匿名梦境数据集时，达到92.1%的准确率和88.4%的F1-score，而结合EEG后(DNet-M)，准确率提升至99.0%、F1-score达95.2%。实验揭示了梦境与情感的强相关性（如falling-anxiety相关系数r=0.91，p<0.01），为心理健康诊断、认知科学和个性化治疗提供可扩展工具，同时公开了数据集和方法以桥接AI与心理研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "68T07",
        "I.2.7; I.2.6; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, new research contribution",
      "pdf_url": "http://arxiv.org/pdf/2503.05778v1",
      "published_date": "2025-02-26 09:10:07 UTC",
      "updated_date": "2025-02-26 09:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:24:17.790108"
    },
    {
      "arxiv_id": "2502.18952v1",
      "title": "DualSpec: Text-to-spatial-audio Generation via Dual-Spectrogram Guided Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhao",
        "Sizhou Chen",
        "Linfeng Feng",
        "Xiao-Lei Zhang",
        "Xuelong Li"
      ],
      "abstract": "Text-to-audio (TTA), which generates audio signals from textual descriptions,\nhas received huge attention in recent years. However, recent works focused on\ntext to monaural audio only. As we know, spatial audio provides more immersive\nauditory experience than monaural audio, e.g. in virtual reality. To address\nthis issue, we propose a text-to-spatial-audio (TTSA) generation framework\nnamed DualSpec.Specifically, it first trains variational autoencoders (VAEs)\nfor extracting the latent acoustic representations from sound event audio.\nThen, given text that describes sound events and event directions, the proposed\nmethod uses the encoder of a pretrained large language model to transform the\ntext into text features. Finally, it trains a diffusion model from the latent\nacoustic representations and text features for the spatial audio generation. In\nthe inference stage, only the text description is needed to generate spatial\naudio. Particularly, to improve the synthesis quality and azimuth accuracy of\nthe spatial sound events simultaneously, we propose to use two kinds of\nacoustic features. One is the Mel spectrograms which is good for improving the\nsynthesis quality, and the other is the short-time Fourier transform\nspectrograms which is good at improving the azimuth accuracy. We provide a\npipeline of constructing spatial audio dataset with text prompts, for the\ntraining of the VAEs and diffusion model. We also introduce new spatial-aware\nevaluation metrics to quantify the azimuth errors of the generated spatial\naudio recordings. Experimental results demonstrate that the proposed method can\ngenerate spatial audio with high directional and event consistency.",
      "tldr_zh": "该研究提出 DualSpec 框架，用于文本到空间音频 (TTSA) 生成，旨在解决现有 Text-to-audio (TTA) 方法仅限于单声道音频的问题，从而提供更沉浸式的听觉体验。框架首先利用 Variational Autoencoders (VAEs) 提取声学表示，并结合预训练大型语言模型的编码器将文本描述转化为特征，然后通过 Dual-Spectrogram Guided Diffusion Model 训练生成空间音频。创新地采用 Mel spectrograms 和 Short-time Fourier Transform (STFT) spectrograms 两种特征，以同时提升音频合成质量和方位准确性。实验结果表明，该方法能生成具有高方向性和事件一致性的空间音频，并引入新的空间感知评估指标进行量化。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18952v1",
      "published_date": "2025-02-26 09:01:59 UTC",
      "updated_date": "2025-02-26 09:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:24:30.818345"
    },
    {
      "arxiv_id": "2502.18940v1",
      "title": "MathTutorBench: A Benchmark for Measuring Open-ended Pedagogical Capabilities of LLM Tutors",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Macina",
        "Nico Daheim",
        "Ido Hakimi",
        "Manu Kapur",
        "Iryna Gurevych",
        "Mrinmaya Sachan"
      ],
      "abstract": "Evaluating the pedagogical capabilities of AI-based tutoring models is\ncritical for making guided progress in the field. Yet, we lack a reliable,\neasy-to-use, and simple-to-run evaluation that reflects the pedagogical\nabilities of models. To fill this gap, we present MathTutorBench, an\nopen-source benchmark for holistic tutoring model evaluation. MathTutorBench\ncontains a collection of datasets and metrics that broadly cover tutor\nabilities as defined by learning sciences research in dialog-based teaching. To\nscore the pedagogical quality of open-ended teacher responses, we train a\nreward model and show it can discriminate expert from novice teacher responses\nwith high accuracy. We evaluate a wide set of closed- and open-weight models on\nMathTutorBench and find that subject expertise, indicated by solving ability,\ndoes not immediately translate to good teaching. Rather, pedagogy and subject\nexpertise appear to form a trade-off that is navigated by the degree of\ntutoring specialization of the model. Furthermore, tutoring appears to become\nmore challenging in longer dialogs, where simpler questioning strategies begin\nto fail. We release the benchmark, code, and leaderboard openly to enable rapid\nbenchmarking of future models.",
      "tldr_zh": "这篇论文介绍了MathTutorBench，一个开源benchmark，用于评估LLM Tutors的开放式教育能力。该基准包含数据集和指标，基于学习科学的对话教学框架，并训练了一个reward model来精准评分教师响应的教育质量。实验评估了多种封闭和开放权重模型，发现模型的专业知识（如问题解决能力）与教学能力之间存在权衡，且在较长对话中，简单的提问策略往往失效。作者开源发布了benchmark、代码和leaderboard，以促进未来模型的快速基准测试。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "https://eth-lre.github.io/mathtutorbench",
      "pdf_url": "http://arxiv.org/pdf/2502.18940v1",
      "published_date": "2025-02-26 08:43:47 UTC",
      "updated_date": "2025-02-26 08:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:24:42.157790"
    },
    {
      "arxiv_id": "2502.18935v1",
      "title": "JailBench: A Comprehensive Chinese Security Assessment Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyi Liu",
        "Simiao Cui",
        "Haoran Bu",
        "Yuming Shang",
        "Xi Zhang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious applications, highlighting the urgent need for comprehensive safety\nevaluations. In particular, the enhanced Chinese language proficiency of LLMs,\ncombined with the unique characteristics and complexity of Chinese expressions,\nhas driven the emergence of Chinese-specific benchmarks for safety assessment.\nHowever, these benchmarks generally fall short in effectively exposing LLM\nsafety vulnerabilities. To address the gap, we introduce JailBench, the first\ncomprehensive Chinese benchmark for evaluating deep-seated vulnerabilities in\nLLMs, featuring a refined hierarchical safety taxonomy tailored to the Chinese\ncontext. To improve generation efficiency, we employ a novel Automatic\nJailbreak Prompt Engineer (AJPE) framework for JailBench construction, which\nincorporates jailbreak techniques to enhance assessing effectiveness and\nleverages LLMs to automatically scale up the dataset through context-learning.\nThe proposed JailBench is extensively evaluated over 13 mainstream LLMs and\nachieves the highest attack success rate against ChatGPT compared to existing\nChinese benchmarks, underscoring its efficacy in identifying latent\nvulnerabilities in LLMs, as well as illustrating the substantial room for\nimprovement in the security and trustworthiness of LLMs within the Chinese\ncontext. Our benchmark is publicly available at\nhttps://github.com/STAIR-BUPT/JailBench.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）的安全评估需求，引入了JailBench，这是一个全面的中文基准，采用精炼的分层安全分类来揭示LLMs在中文语境中的深层漏洞。论文提出Automatic Jailbreak Prompt Engineer (AJPE)框架，通过整合jailbreak techniques和LLMs的上下文学习，实现高效的基准数据集自动扩展。实验结果显示，JailBench在13个主流LLMs上评估中，对ChatGPT的攻击成功率最高，突显了现有模型的安全性和可信度需进一步提升，并公开了基准代码以促进研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures, accepted at PAKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18935v1",
      "published_date": "2025-02-26 08:36:42 UTC",
      "updated_date": "2025-02-26 08:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:24:54.209132"
    },
    {
      "arxiv_id": "2502.18932v1",
      "title": "SLAM in the Dark: Self-Supervised Learning of Pose, Depth and Loop-Closure from Thermal Images",
      "title_zh": "翻译失败",
      "authors": [
        "Yangfan Xu",
        "Qu Hao",
        "Lilian Zhang",
        "Jun Mao",
        "Xiaofeng He",
        "Wenqi Wu",
        "Changhao Chen"
      ],
      "abstract": "Visual SLAM is essential for mobile robots, drone navigation, and VR/AR, but\ntraditional RGB camera systems struggle in low-light conditions, driving\ninterest in thermal SLAM, which excels in such environments. However, thermal\nimaging faces challenges like low contrast, high noise, and limited large-scale\nannotated datasets, restricting the use of deep learning in outdoor scenarios.\nWe present DarkSLAM, a noval deep learning-based monocular thermal SLAM system\ndesigned for large-scale localization and reconstruction in complex lighting\nconditions.Our approach incorporates the Efficient Channel Attention (ECA)\nmechanism in visual odometry and the Selective Kernel Attention (SKA) mechanism\nin depth estimation to enhance pose accuracy and mitigate thermal depth\ndegradation. Additionally, the system includes thermal depth-based loop closure\ndetection and pose optimization, ensuring robust performance in low-texture\nthermal scenes. Extensive outdoor experiments demonstrate that DarkSLAM\nsignificantly outperforms existing methods like SC-Sfm-Learner and Shin et al.,\ndelivering precise localization and 3D dense mapping even in challenging\nnighttime environments.",
      "tldr_zh": "这篇论文解决了传统 RGB 视觉 SLAM 在低光条件下的性能问题，提出 DarkSLAM，一种基于深度学习的单目热成像 SLAM 系统，用于大规模定位和重建。DarkSLAM 整合了 Efficient Channel Attention (ECA) 机制提升视觉里程计的位姿准确性，以及 Selective Kernel Attention (SKA) 机制优化深度估计，同时加入热深度-based 闭环检测和位姿优化，以应对热图像的低对比度和高噪声挑战。实验结果显示，DarkSLAM 在户外复杂光照环境中显著优于现有方法如 SC-Sfm-Learner 和 Shin et al.，实现了精确的定位和 3D 密集映射，即使在夜间也能保持鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18932v1",
      "published_date": "2025-02-26 08:34:23 UTC",
      "updated_date": "2025-02-26 08:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:25:06.896013"
    },
    {
      "arxiv_id": "2502.18928v1",
      "title": "Talking like Piping and Instrumentation Diagrams (P&IDs)",
      "title_zh": "翻译失败",
      "authors": [
        "Achmad Anggawirya Alimin",
        "Dominik P. Goldstein",
        "Lukas Schulze Balhorn",
        "Artur M. Schweidtmann"
      ],
      "abstract": "We propose a methodology that allows communication with Piping and\nInstrumentation Diagrams (P&IDs) using natural language. In particular, we\nrepresent P&IDs through the DEXPI data model as labeled property graphs and\nintegrate them with Large Language Models (LLMs). The approach consists of\nthree main parts: 1) P&IDs are cast into a graph representation from the DEXPI\nformat using our pyDEXPI Python package. 2) A tool for generating P&ID\nknowledge graphs from pyDEXPI. 3) Integration of the P&ID knowledge graph to\nLLMs using graph-based retrieval augmented generation (graph-RAG). This\napproach allows users to communicate with P&IDs using natural language. It\nextends LLM's ability to retrieve contextual data from P&IDs and mitigate\nhallucinations. Leveraging the LLM's large corpus, the model is also able to\ninterpret process information in PIDs, which could help engineers in their\ndaily tasks. In the future, this work will also open up opportunities in the\ncontext of other generative Artificial Intelligence (genAI) solutions on P&IDs,\nand AI-assisted HAZOP studies.",
      "tldr_zh": "该研究提出了一种使用自然语言与管道和仪表图 (P&IDs) 通信的方法，通过 DEXPI 数据模型将 P&IDs 表示为标记属性图，并与大型语言模型 (LLMs) 集成。方法包括三个主要部分：使用 pyDEXPI Python 包将 P&IDs 转换为图表示、生成 P&ID 知识图，以及通过基于图的检索增强生成 (graph-RAG) 将知识图集成到 LLMs 中。这种方法增强了 LLMs 从 P&IDs 中检索上下文数据的能力，减少了 hallucination，并帮助工程师解释过程信息。未来，该框架可扩展到其他生成式人工智能 (genAI) 解决方案和 AI 辅助 HAZOP 研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18928v1",
      "published_date": "2025-02-26 08:30:35 UTC",
      "updated_date": "2025-02-26 08:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:25:18.017087"
    },
    {
      "arxiv_id": "2502.18925v1",
      "title": "BeamVQ: Beam Search with Vector Quantization to Mitigate Data Scarcity in Physical Spatiotemporal Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Weiyan Wang",
        "Xingjian Shi",
        "Ruiqi Shu",
        "Yuan Gao",
        "Rui Ray Chen",
        "Kun Wang",
        "Fan Xu",
        "Jinbao Xue",
        "Shuaipeng Li",
        "Yangyu Tao",
        "Di Wang",
        "Hao Wu",
        "Xiaomeng Huang"
      ],
      "abstract": "In practice, physical spatiotemporal forecasting can suffer from data\nscarcity, because collecting large-scale data is non-trivial, especially for\nextreme events. Hence, we propose \\method{}, a novel probabilistic framework to\nrealize iterative self-training with new self-ensemble strategies, achieving\nbetter physical consistency and generalization on extreme events. Following any\nbase forecasting model, we can encode its deterministic outputs into a latent\nspace and retrieve multiple codebook entries to generate probabilistic outputs.\nThen BeamVQ extends the beam search from discrete spaces to the continuous\nstate spaces in this field. We can further employ domain-specific metrics\n(e.g., Critical Success Index for extreme events) to filter out the top-k\ncandidates and develop the new self-ensemble strategy by combining the\nhigh-quality candidates. The self-ensemble can not only improve the inference\nquality and robustness but also iteratively augment the training datasets\nduring continuous self-training. Consequently, BeamVQ realizes the exploration\nof rare but critical phenomena beyond the original dataset. Comprehensive\nexperiments on different benchmarks and backbones show that BeamVQ consistently\nreduces forecasting MSE (up to 39%), enhancing extreme events detection and\nproving its effectiveness in handling data scarcity.",
      "tldr_zh": "该研究提出 BeamVQ，一种新型概率框架，用于缓解物理时空预测中的数据稀缺问题，特别是针对极端事件，通过迭代自训练和新的自集成策略提升物理一致性和泛化能力。BeamVQ 基于任何基础预测模型，将其确定性输出编码到潜在空间，并利用 vector quantization 检索多个 codebook 条目生成概率输出，同时将 beam search 扩展到连续状态空间，并通过领域特定指标（如 Critical Success Index）筛选 top-k 高质量候选进行自集成。实验结果显示，BeamVQ 在不同基准和骨干模型上显著降低了预测 MSE（最高达 39%），提高了极端事件检测的准确性和鲁棒性，并通过连续自训练扩展数据集以探索稀有关键现象。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18925v1",
      "published_date": "2025-02-26 08:27:25 UTC",
      "updated_date": "2025-02-26 08:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:25:29.970396"
    },
    {
      "arxiv_id": "2502.18915v2",
      "title": "END: Early Noise Dropping for Efficient and Effective Context Denoising",
      "title_zh": "END：早期",
      "authors": [
        "Hongye Jin",
        "Pei Chen",
        "Jingfeng Yang",
        "Zhengyang Wang",
        "Meng Jiang",
        "Yifan Gao",
        "Binxuan Huang",
        "Xinyang Zhang",
        "Zheng Li",
        "Tianyi Liu",
        "Huasheng Li",
        "Bing Yin"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of natural language processing tasks. However, they are often\ndistracted by irrelevant or noisy context in input sequences that degrades\noutput quality. This problem affects both long- and short-context scenarios,\nsuch as retrieval-augmented generation, table question-answering, and\nin-context learning. We reveal that LLMs can implicitly identify whether input\nsequences contain useful information at early layers, prior to token\ngeneration. Leveraging this insight, we introduce Early Noise Dropping\n(\\textsc{END}), a novel approach to mitigate this issue without requiring\nfine-tuning the LLMs. \\textsc{END} segments input sequences into chunks and\nemploys a linear prober on the early layers of LLMs to differentiate between\ninformative and noisy chunks. By discarding noisy chunks early in the process,\n\\textsc{END} preserves critical information, reduces distraction, and lowers\ncomputational overhead. Extensive experiments demonstrate that \\textsc{END}\nsignificantly improves both performance and efficiency across different LLMs on\nmultiple evaluation datasets. Furthermore, by investigating LLMs' implicit\nunderstanding to the input with the prober, this work also deepens\nunderstanding of how LLMs do reasoning with contexts internally.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在处理输入序列时容易受无关噪声上下文干扰的问题，提出了一种无需微调的创新方法 Early Noise Dropping (END)。END 将输入序列分割成块，并利用线性探针 (linear prober) 在 LLMs 的早期层识别并丢弃噪声块，从而保留关键信息、减少干扰并降低计算开销。实验结果显示，END 显著提升了不同 LLMs 在检索增强生成、表格问答和上下文学习等任务上的性能和效率。此外，该方法通过探针分析深化了对 LLMs 内部推理机制的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "It's not approved by the legal from Amazon. They told us arXiv is not\n  allowed unless the paper is accepted later. It's under submission now",
      "pdf_url": "http://arxiv.org/pdf/2502.18915v2",
      "published_date": "2025-02-26 08:07:17 UTC",
      "updated_date": "2025-03-25 20:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:25:41.516101"
    },
    {
      "arxiv_id": "2502.18891v1",
      "title": "Dynamic Classification: Leveraging Self-Supervised Classification to Enhance Prediction Performance",
      "title_zh": "动态分类：利用自监督分类提升预测性能",
      "authors": [
        "Ziyuan Zhong",
        "Junyang Zhou"
      ],
      "abstract": "In this paper, we propose an innovative dynamic classification algorithm\ndesigned to achieve the objective of zero missed detections and minimal false\npositives. The algorithm partitions the data into N equivalent training subsets\nand N prediction subsets using a supervised model, followed by independent\npredictions from N separate predictive models. This enables each predictive\nmodel to operate within a smaller data range, thereby improving overall\naccuracy. Additionally, the algorithm leverages data generated through\nsupervised learning to further refine prediction results, filtering out\npredictions that do not meet accuracy requirements without the need to\nintroduce additional models. Experimental results demonstrate that, when data\npartitioning errors are minimal, the dynamic classification algorithm achieves\nexceptional performance with zero missed detections and minimal false\npositives, significantly outperforming existing model ensembles. Even in cases\nwhere classification errors are larger, the algorithm remains comparable to\nstate of the art models. The key innovations of this study include\nself-supervised classification learning, the use of small-range subset\npredictions, and the direct rejection of substandard predictions. While the\ncurrent algorithm still has room for improvement in terms of automatic\nparameter tuning and classification model efficiency, it has demonstrated\noutstanding performance across multiple datasets. Future research will focus on\noptimizing the classification component to further enhance the algorithm's\nrobustness and adaptability.",
      "tldr_zh": "本文提出了一种名为Dynamic Classification的创新算法，利用Self-Supervised Classification来提升预测性能，其核心方法是将数据分成N等份训练子集和预测子集，通过监督模型和N个独立预测模型进行预测，并利用生成数据过滤不准确结果，以实现零 missed detections和最小 false positives。实验结果显示，该算法在分区错误最小时显著优于现有模型集成，即使错误较大，也与state-of-the-art模型相当，主要创新包括自监督分类学习、小范围子集预测以及直接拒绝次优预测。未来研究将聚焦于优化参数调优和模型效率，以进一步提高算法的鲁棒性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "J.0; I.0"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18891v1",
      "published_date": "2025-02-26 07:11:12 UTC",
      "updated_date": "2025-02-26 07:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:25:54.628217"
    },
    {
      "arxiv_id": "2502.18889v2",
      "title": "Clip-TTS: Contrastive Text-content and Mel-spectrogram, A High-Quality Text-to-Speech Method based on Contextual Semantic Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyun Liu"
      ],
      "abstract": "Traditional text-to-speech (TTS) methods primarily focus on establishing a\nmapping between phonemes and mel-spectrograms. However, during the phoneme\nencoding stage, there is often a lack of real mel-spectrogram auxiliary\ninformation, which results in the encoding process lacking true semantic\nunderstanding. At the same time, traditional TTS systems often struggle to\nbalance the inference speed of the model with the quality of the synthesized\nspeech. Methods that generate high-quality synthesized speech tend to have\nslower inference speeds, while faster inference methods often sacrifice speech\nquality. In this paper, I propose Clip-TTS, a TTS method based on the Clip\narchitecture. This method uses the Clip framework to establish a connection\nbetween text content and real mel-spectrograms during the text encoding stage,\nenabling the text encoder to directly learn the true semantics of the global\ncontext, thereby ensuring the quality of the synthesized speech. In terms of\nmodel architecture, I adopt the basic structure of Transformer, which allows\nClip-TTS to achieve fast inference speeds. Experimental results show that on\nthe LJSpeech and Baker datasets, the speech generated by Clip-TTS achieves\nstate-of-the-art MOS scores, and it also performs excellently on multi-emotion\ndatasets.Audio samples are available at: https://ltydd1314.github.io/.",
      "tldr_zh": "本文提出 Clip-TTS，一种基于 Contextual Semantic Understanding 的高质量 TTS 方法，通过 Contrastive Text-content and Mel-spectrogram 机制在文本编码阶段利用 Clip 架构连接文本内容和真实 mel-spectrograms，从而提升全局语义理解并确保合成语音质量。不同于传统 TTS 系统，该方法采用 Transformer 的基本结构，实现快速推理速度，同时平衡性能和效率。实验结果显示，在 LJSpeech 和 Baker 数据集上，Clip-TTS 达到 state-of-the-art MOS scores，并在多情感数据集上表现出色，提供音频样本以验证效果。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18889v2",
      "published_date": "2025-02-26 07:09:33 UTC",
      "updated_date": "2025-03-08 09:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:26:06.771139"
    },
    {
      "arxiv_id": "2502.18875v1",
      "title": "SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein Degradation",
      "title_zh": "SE(3)-等变的针对目标蛋白降解的三",
      "authors": [
        "Fanglei Xue",
        "Meihan Zhang",
        "Shuqi Li",
        "Xinyu Gao",
        "James A. Wohlschlegel",
        "Wenbing Huang",
        "Yi Yang",
        "Weixian Deng"
      ],
      "abstract": "Targeted protein degradation (TPD) induced by small molecules has emerged as\na rapidly evolving modality in drug discovery, targeting proteins traditionally\nconsidered \"undruggable\". Proteolysis-targeting chimeras (PROTACs) and\nmolecular glue degraders (MGDs) are the primary small molecules that induce\nTPD. Both types of molecules form a ternary complex linking an E3 ligase with a\ntarget protein, a crucial step for drug discovery. While significant advances\nhave been made in binary structure prediction for proteins and small molecules,\nternary structure prediction remains challenging due to obscure interaction\nmechanisms and insufficient training data. Traditional methods relying on\nmanually assigned rules perform poorly and are computationally demanding due to\nextensive random sampling. In this work, we introduce DeepTernary, a novel deep\nlearning-based approach that directly predicts ternary structures in an\nend-to-end manner using an encoder-decoder architecture. DeepTernary leverages\nan SE(3)-equivariant graph neural network (GNN) with both intra-graph and\nternary inter-graph attention mechanisms to capture intricate ternary\ninteractions from our collected high-quality training dataset, TernaryDB. The\nproposed query-based Pocket Points Decoder extracts the 3D structure of the\nfinal binding ternary complex from learned ternary embeddings, demonstrating\nstate-of-the-art accuracy and speed in existing PROTAC benchmarks without prior\nknowledge from known PROTACs. It also achieves notable accuracy on the more\nchallenging MGD benchmark under the blind docking protocol. Remarkably, our\nexperiments reveal that the buried surface area calculated from predicted\nstructures correlates with experimentally obtained degradation potency-related\nmetrics. Consequently, DeepTernary shows potential in effectively assisting and\naccelerating the development of TPDs for previously undruggable targets.",
      "tldr_zh": "这篇论文提出了 DeepTernary，一种基于 SE(3)-equivariant 图神经网络 (GNN) 的端到端深度学习方法，用于预测 PROTACs 和 MGDs 诱导的蛋白质降解 (TPD) 三元复合结构，解决传统方法在交互机制和数据不足方面的挑战。 该方法通过 intra-graph 和 ternary inter-graph 注意机制，从 TernaryDB 数据集捕获复杂的三元交互，并利用 query-based Pocket Points Decoder 生成精确的 3D 结构。 实验结果显示，DeepTernary 在 PROTAC 基准上实现最先进的准确性和速度，在 MGD 基准上也表现出色，且预测结构的埋藏表面面积与实验降解效力指标高度相关，有望加速针对“不可药性”蛋白的药物开发。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18875v1",
      "published_date": "2025-02-26 06:33:24 UTC",
      "updated_date": "2025-02-26 06:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:26:18.799348"
    },
    {
      "arxiv_id": "2502.18874v2",
      "title": "Learning to Align Multi-Faceted Evaluation: A Unified and Robust Framework",
      "title_zh": "学习对齐多方面评估：一个统一且稳健的框架",
      "authors": [
        "Kaishuai Xu",
        "Tiezheng Yu",
        "Wenjun Hou",
        "Yi Cheng",
        "Liangyou Li",
        "Xin Jiang",
        "Lifeng Shang",
        "Qun Liu",
        "Wenjie Li"
      ],
      "abstract": "Large Language Models (LLMs) are being used more and more extensively for\nautomated evaluation in various scenarios. Previous studies have attempted to\nfine-tune open-source LLMs to replicate the evaluation explanations and\njudgments of powerful proprietary models, such as GPT-4. However, these methods\nare largely limited to text-based analyses under predefined general criteria,\nresulting in reduced adaptability for unseen instructions and demonstrating\ninstability in evaluating adherence to quantitative and structural constraints.\nTo address these limitations, we propose a novel evaluation framework, ARJudge,\nthat adaptively formulates evaluation criteria and synthesizes both text-based\nand code-driven analyses to evaluate LLM responses. ARJudge consists of two\ncomponents: a fine-tuned Analyzer that generates multi-faceted evaluation\nanalyses and a tuning-free Refiner that combines and refines all analyses to\nmake the final judgment. We construct a Composite Analysis Corpus that\nintegrates tasks for evaluation criteria generation alongside text-based and\ncode-driven analysis generation to train the Analyzer. Our results demonstrate\nthat ARJudge outperforms existing fine-tuned evaluators in effectiveness and\nrobustness. Furthermore, it demonstrates the importance of multi-faceted\nevaluation and code-driven analyses in enhancing evaluation capabilities.",
      "tldr_zh": "这篇论文提出了一种统一的鲁棒框架 ARJudge，用于解决现有 Large Language Models (LLMs) 评估方法的局限性，如适应性差和对量化约束的不稳定性。ARJudge 包括一个微调的 Analyzer 组件，用于生成多方面评估分析（如文本和代码驱动分析），以及一个无微调的 Refiner 组件来结合并精炼这些分析以做出最终判断；它依赖于构建的 Composite Analysis Corpus 进行训练，以支持评估标准生成和分析合成。实验结果表明，ARJudge 在有效性和鲁棒性上优于现有微调评估器，并强调了多方面评估和代码驱动分析在提升 LLM 评估能力方面的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18874v2",
      "published_date": "2025-02-26 06:31:45 UTC",
      "updated_date": "2025-03-03 07:13:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:26:32.595504"
    },
    {
      "arxiv_id": "2502.18873v1",
      "title": "Multi-LLM Collaborative Search for Complex Problem Solving",
      "title_zh": "多LLM协作搜索用于复杂问题求解",
      "authors": [
        "Sen Yang",
        "Yafu Li",
        "Wai Lam",
        "Yu Cheng"
      ],
      "abstract": "Large language models (LLMs) often struggle with complex reasoning tasks due\nto their limitations in addressing the vast reasoning space and inherent\nambiguities of natural language. We propose the Mixture-of-Search-Agents (MoSA)\nparadigm, a novel approach leveraging the collective expertise of multiple LLMs\nto enhance search-based reasoning. MoSA integrates diverse reasoning pathways\nby combining independent exploration with iterative refinement among LLMs,\nmitigating the limitations of single-model approaches. Using Monte Carlo Tree\nSearch (MCTS) as a backbone, MoSA enables multiple agents to propose and\naggregate reasoning steps, resulting in improved accuracy. Our comprehensive\nevaluation across four reasoning benchmarks demonstrates MoSA's consistent\nperformance improvements over single-agent and other multi-agent baselines,\nparticularly in complex mathematical and commonsense reasoning tasks.",
      "tldr_zh": "本文研究发现，大语言模型 (LLMs) 在复杂推理任务中常因推理空间庞大和自然语言模糊性而表现不佳。为此，提出 Mixture-of-Search-Agents (MoSA) 范式，利用多个 LLMs 的集体专业知识，通过独立探索和迭代精炼相结合的方式提升搜索-based 推理。MoSA 以 Monte Carlo Tree Search (MCTS) 为骨干，允许多个代理提出并聚合推理步骤。在四个推理基准测试中，MoSA 比单代理和其它多代理基线表现出一致的性能提升，尤其在复杂数学和常识推理任务上。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18873v1",
      "published_date": "2025-02-26 06:31:04 UTC",
      "updated_date": "2025-02-26 06:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:26:42.497375"
    },
    {
      "arxiv_id": "2502.18871v1",
      "title": "Inscanner: Dual-Phase Detection and Classification of Auxiliary Insulation Using YOLOv8 Models",
      "title_zh": "翻译失败",
      "authors": [
        "Youngtae Kim",
        "Soonju Jeong",
        "Sardar Arslan",
        "Dhananjay Agnihotri",
        "Yahya Ahmed",
        "Ali Nawaz",
        "Jinhee Song",
        "Hyewon Kim"
      ],
      "abstract": "This study proposes a two-phase methodology for detecting and classifying\nauxiliary insulation in structural components. In the detection phase, a\nYOLOv8x model is trained on a dataset of complete structural blueprints, each\nannotated with bounding boxes indicating areas that should contain insulation.\nIn the classification phase, these detected insulation patches are cropped and\ncategorized into two classes: present or missing. These are then used to train\na YOLOv8x-CLS model that determines the presence or absence of auxiliary\ninsulation. Preprocessing steps for both datasets included annotation,\naugmentation, and appropriate cropping of the insulation regions. The detection\nmodel achieved a mean average precision (mAP) score of 82%, while the\nclassification model attained an accuracy of 98%. These findings demonstrate\nthe effectiveness of the proposed approach in automating insulation detection\nand classification, providing a foundation for further advancements in this\ndomain.",
      "tldr_zh": "该研究提出了一种双阶段方法Inscanner，用于检测和分类结构组件中的辅助 insulation。检测阶段利用YOLOv8x模型在标注了边界框的结构蓝图数据集上训练，识别应有绝缘区域；分类阶段则对检测到的区域进行裁剪，并使用YOLOv8x-CLS模型分类为present或missing。预处理包括数据标注、增强和裁剪，检测模型的mAP达到82%，分类模型的准确率达98%。这项工作证明了该方法的有效性，为自动化insulation检测和分类领域提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18871v1",
      "published_date": "2025-02-26 06:29:30 UTC",
      "updated_date": "2025-02-26 06:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:26:53.371126"
    },
    {
      "arxiv_id": "2502.19451v1",
      "title": "Multispectral to Hyperspectral using Pretrained Foundational model",
      "title_zh": "翻译失败",
      "authors": [
        "Ruben Gonzalez",
        "Conrad M Albrecht",
        "Nassim Ait Ali Braham",
        "Devyani Lambhate",
        "Joao Lucas de Sousa Almeida",
        "Paolo Fraccaro",
        "Benedikt Blumenstiel",
        "Thomas Brunschwiler",
        "Ranjini Bangalore"
      ],
      "abstract": "Hyperspectral imaging provides detailed spectral information, offering\nsignificant potential for monitoring greenhouse gases like CH4 and NO2.\nHowever, its application is constrained by limited spatial coverage and\ninfrequent revisit times. In contrast, multispectral imaging delivers broader\nspatial and temporal coverage but lacks the spectral granularity required for\nprecise GHG detection. To address these challenges, this study proposes\nSpectral and Spatial-Spectral transformer models that reconstruct hyperspectral\ndata from multispectral inputs. The models in this paper are pretrained on\nEnMAP and EMIT datasets and fine-tuned on spatio-temporally aligned\n(Sentinel-2, EnMAP) and (HLS-S30, EMIT) image pairs respectively. Our model has\nthe potential to enhance atmospheric monitoring by combining the strengths of\nhyperspectral and multispectral imaging systems.",
      "tldr_zh": "本研究针对高光谱(Hyperspectral)成像的覆盖和重访时间限制，提出使用预训练的 Spectral and Spatial-Spectral transformer models，从多光谱(Multispectral)图像重建高光谱数据，以提升温室气体如 CH4 和 NO2 的监测精度。模型在 EnMAP 和 EMIT 数据集上预训练，并针对空间-时间配准的图像对（如 Sentinel-2 与 EnMAP，以及 HLS-S30 与 EMIT）进行微调。结果表明，这种方法能结合多光谱的广覆盖和高光谱的细粒度优势，增强大气监测的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.19451v1",
      "published_date": "2025-02-26 06:18:40 UTC",
      "updated_date": "2025-02-26 06:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:27:06.329552"
    },
    {
      "arxiv_id": "2502.18865v1",
      "title": "A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops",
      "title_zh": "翻译失败",
      "authors": [
        "Shi Fu",
        "Yingjie Wang",
        "Yuzhu Chen",
        "Xinmei Tian",
        "Dacheng Tao"
      ],
      "abstract": "High-quality data is essential for training large generative models, yet the\nvast reservoir of real data available online has become nearly depleted.\nConsequently, models increasingly generate their own data for further training,\nforming Self-consuming Training Loops (STLs). However, the empirical results\nhave been strikingly inconsistent: some models degrade or even collapse, while\nothers successfully avoid these failures, leaving a significant gap in\ntheoretical understanding to explain this discrepancy. This paper introduces\nthe intriguing notion of recursive stability and presents the first theoretical\ngeneralization analysis, revealing how both model architecture and the\nproportion between real and synthetic data influence the success of STLs. We\nfurther extend this analysis to transformers in in-context learning, showing\nthat even a constant-sized proportion of real data ensures convergence, while\nalso providing insights into optimal synthetic data sizing.",
      "tldr_zh": "本论文从理论角度探讨了如何在Self-consuming Training Loops (STLs)中防止模型崩溃的问题，引入了recursive stability的概念，并首次进行理论泛化分析，以解释模型架构和真实与合成数据比例对STL成功的影响。研究发现，适当的模型设计和数据比例能够避免模型退化，而过多的合成数据可能导致失败。针对Transformer的in-context learning，论文进一步证明，即使保持恒定比例的真实数据也能确保收敛，并提供了合成数据的最佳大小指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18865v1",
      "published_date": "2025-02-26 06:18:13 UTC",
      "updated_date": "2025-02-26 06:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:27:17.639369"
    },
    {
      "arxiv_id": "2502.18864v1",
      "title": "Towards an AI co-scientist",
      "title_zh": "迈向 AI 合作科学家",
      "authors": [
        "Juraj Gottweis",
        "Wei-Hung Weng",
        "Alexander Daryin",
        "Tao Tu",
        "Anil Palepu",
        "Petar Sirkovic",
        "Artiom Myaskovsky",
        "Felix Weissenberger",
        "Keran Rong",
        "Ryutaro Tanno",
        "Khaled Saab",
        "Dan Popovici",
        "Jacob Blum",
        "Fan Zhang",
        "Katherine Chou",
        "Avinatan Hassidim",
        "Burak Gokturk",
        "Amin Vahdat",
        "Pushmeet Kohli",
        "Yossi Matias",
        "Andrew Carroll",
        "Kavita Kulkarni",
        "Nenad Tomasev",
        "Yuan Guan",
        "Vikram Dhillon",
        "Eeshit Dhaval Vaishnav",
        "Byron Lee",
        "Tiago R D Costa",
        "José R Penadés",
        "Gary Peltz",
        "Yunhan Xu",
        "Annalisa Pawlosky",
        "Alan Karthikesalingam",
        "Vivek Natarajan"
      ],
      "abstract": "Scientific discovery relies on scientists generating novel hypotheses that\nundergo rigorous experimental validation. To augment this process, we introduce\nan AI co-scientist, a multi-agent system built on Gemini 2.0. The AI\nco-scientist is intended to help uncover new, original knowledge and to\nformulate demonstrably novel research hypotheses and proposals, building upon\nprior evidence and aligned to scientist-provided research objectives and\nguidance. The system's design incorporates a generate, debate, and evolve\napproach to hypothesis generation, inspired by the scientific method and\naccelerated by scaling test-time compute. Key contributions include: (1) a\nmulti-agent architecture with an asynchronous task execution framework for\nflexible compute scaling; (2) a tournament evolution process for self-improving\nhypotheses generation. Automated evaluations show continued benefits of\ntest-time compute, improving hypothesis quality. While general purpose, we\nfocus development and validation in three biomedical areas: drug repurposing,\nnovel target discovery, and explaining mechanisms of bacterial evolution and\nanti-microbial resistance. For drug repurposing, the system proposes candidates\nwith promising validation findings, including candidates for acute myeloid\nleukemia that show tumor inhibition in vitro at clinically applicable\nconcentrations. For novel target discovery, the AI co-scientist proposed new\nepigenetic targets for liver fibrosis, validated by anti-fibrotic activity and\nliver cell regeneration in human hepatic organoids. Finally, the AI\nco-scientist recapitulated unpublished experimental results via a parallel in\nsilico discovery of a novel gene transfer mechanism in bacterial evolution.\nThese results, detailed in separate, co-timed reports, demonstrate the\npotential to augment biomedical and scientific discovery and usher an era of AI\nempowered scientists.",
      "tldr_zh": "本论文提出了一种基于 Gemini 2.0 的多智能体系统——AI co-scientist，旨在辅助科学家生成新假设并进行实验验证，以加速科学发现过程。系统采用生成、辩论和演化的方法，结合异步任务执行框架和锦标赛式演化过程（tournament evolution），从而提升假设质量并支持可扩展计算。关键贡献包括在生物医学领域的应用，如为药物再利用（drug repurposing）提出候选物并验证其体外肿瘤抑制效果、在新型目标发现（novel target discovery）中识别肝纤维化的表观遗传目标并证实其抗纤维化活性，以及重现细菌进化中的新型基因转移机制。这些结果展示了 AI 增强科学发现的潜力，推动了 AI 赋能科学家的时代。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "physics.soc-ph",
        "q-bio.OT"
      ],
      "primary_category": "cs.AI",
      "comment": "81 pages in total (main 38 pages, appendix 43 pages), 13 main\n  figures, 40 appendix figures, 1 main table, 2 appendix tables, 143 main\n  references, 7 appendix references",
      "pdf_url": "http://arxiv.org/pdf/2502.18864v1",
      "published_date": "2025-02-26 06:17:13 UTC",
      "updated_date": "2025-02-26 06:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:27:31.001099"
    },
    {
      "arxiv_id": "2502.18863v1",
      "title": "Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiao Ma",
        "Jingjing Wang",
        "Jiamin Luo",
        "Peiying Yu",
        "Guodong Zhou"
      ],
      "abstract": "Prior studies on Video Anomaly Detection (VAD) mainly focus on detecting\nwhether each video frame is abnormal or not in the video, which largely ignore\nthe structured video semantic information (i.e., what, when, and where does the\nabnormal event happen). With this in mind, we propose a new chat-paradigm\n\\textbf{M}ulti-scene Video Abnormal Event Extraction and Localization (M-VAE)\ntask, aiming to extract the abnormal event quadruples (i.e., subject, event\ntype, object, scene) and localize such event. Further, this paper believes that\nthis new task faces two key challenges, i.e., global-local spatial modeling and\nglobal-local spatial balancing. To this end, this paper proposes a Global-local\nSpatial-sensitive Large Language Model (LLM) named Sherlock, i.e., acting like\nSherlock Holmes to track down the criminal events, for this M-VAE task.\nSpecifically, this model designs a Global-local Spatial-enhanced MoE (GSM)\nmodule and a Spatial Imbalance Regulator (SIR) to address the two challenges\nrespectively. Extensive experiments on our M-VAE instruction dataset show the\nsignificant advantages of Sherlock over several advanced Video-LLMs. This\njustifies the importance of global-local spatial information for the M-VAE task\nand the effectiveness of Sherlock in capturing such information.",
      "tldr_zh": "该研究指出，现有视频异常检测（VAD）主要关注帧级异常，而忽略了异常事件的结构化语义信息（如事件内容、时间和位置），因此提出新的多场景视频异常事件提取和定位（M-VAE）任务，旨在提取异常事件四元组（主语、事件类型、对象、场景）并实现定位。针对M-VAE面临的全局-局部空间建模和平衡挑战，作者开发了Sherlock模型，这是一个全局-局部空间敏感的LLM，包含Global-local Spatial-enhanced MoE (GSM)模块和Spatial Imbalance Regulator (SIR)组件，以提升空间信息处理能力。在M-VAE指令数据集上的实验表明，Sherlock显著优于其他先进Video-LLMs，验证了其在捕捉全局-局部空间信息方面的有效性和重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18863v1",
      "published_date": "2025-02-26 06:16:37 UTC",
      "updated_date": "2025-02-26 06:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:27:43.047398"
    },
    {
      "arxiv_id": "2502.18862v1",
      "title": "Investigating Generalization of One-shot LLM Steering Vectors",
      "title_zh": "探究一-shot LLM 转向向量的泛化",
      "authors": [
        "Jacob Dunefsky",
        "Arman Cohan"
      ],
      "abstract": "Steering vectors have emerged as a promising approach for interpreting and\ncontrolling LLMs, but current methods typically require large contrastive\ndatasets that are often impractical to construct and may capture spurious\ncorrelations. We propose directly optimizing steering vectors through gradient\ndescent on a single training example, and systematically investigate how these\nvectors generalize. We consider several steering optimization techniques,\nincluding multiple novel ones, and find that the resulting vectors effectively\nmediate safety-relevant behaviors in multiple models. Indeed, in experiments on\nan alignment-faking model, we are able to optimize one-shot steering vectors\nthat induce harmful behavior on benign examples and whose negations suppress\nharmful behavior on malign examples. And in experiments on refusal suppression,\nwe demonstrate that one-shot optimized steering vectors can transfer across\ninputs, yielding a Harmbench attack success rate of 96.9%. Furthermore, to\nquantitatively assess steering effectiveness in instruction-tuned models, we\ndevelop a novel evaluation framework using sequence probabilities from the\ncorresponding base model. With this framework, we analyze how steering vectors\nmodulate an instruction-tuned LLM's ability to recover from outputting false\ninformation, and find that this ability derives from the base model. Overall,\nour findings suggest that optimizing steering vectors on a single example can\nmediate misaligned behavior in LLMs, and provide a path toward better\nunderstanding the relationship between LLM behavior and activation space\nstructure.",
      "tldr_zh": "本文研究了通过梯度下降在单个训练示例上直接优化 steering vectors 的方法，以解决传统方法依赖大型对比数据集的问题，并系统调查了这些 one-shot steering vectors 的泛化能力。实验结果显示，该方法能有效调解 LLMs 的安全相关行为，例如在对齐假冒模型中诱导有害行为并抑制恶意示例，在拒绝抑制任务中实现96.9%的 Harmbench 攻击成功率。作者还开发了一个新评估框架，使用基模型的序列概率量化 steering 在指令微调模型中的效果，发现这种恢复输出错误信息的能力源于基模型整体结构，从而为理解 LLMs 行为与激活空间的关系提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 7 figures. Code is available at\n  https://github.com/jacobdunefsky/one-shot-steering-repro",
      "pdf_url": "http://arxiv.org/pdf/2502.18862v1",
      "published_date": "2025-02-26 06:13:01 UTC",
      "updated_date": "2025-02-26 06:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:27:56.119324"
    },
    {
      "arxiv_id": "2502.18858v2",
      "title": "Evaluating Intelligence via Trial and Error",
      "title_zh": "通过试错评估智能",
      "authors": [
        "Jingtao Zhan",
        "Jiahao Zhao",
        "Jiayu Li",
        "Yiqun Liu",
        "Bo Zhang",
        "Qingyao Ai",
        "Jiaxin Mao",
        "Hongning Wang",
        "Min Zhang",
        "Shaoping Ma"
      ],
      "abstract": "Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.",
      "tldr_zh": "本论文引入了Survival Game框架，通过试错过程（trial-and-error）的失败次数来评估智能，失败次数越少表示智能越高。框架定义了Autonomous Level，即失败次数的期望和方差均有限，实验结果显示现有AI系统在简单任务中达到此水平，但在复杂任务如视觉、搜索、推荐和语言中远未实现。分析指出，扩展当前AI技术需耗费天文数字的参数（如$10^{26}$参数），且人类任务具有criticality property，导致AI依赖表面模仿而非深入理解底层机制；最终，Survival Game可指导AI未来发展和深化对人类智能的认识。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18858v2",
      "published_date": "2025-02-26 05:59:45 UTC",
      "updated_date": "2025-03-03 13:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:28:06.278158"
    },
    {
      "arxiv_id": "2502.18853v1",
      "title": "Reimagining Personal Data: Unlocking the Potential of AI-Generated Images in Personal Data Meaning-Making",
      "title_zh": "重新想象个人数据：解锁 AI 生成图像在个人数据意义构建",
      "authors": [
        "Soobin Park",
        "Hankyung Kim",
        "Youn-kyung Lim"
      ],
      "abstract": "Image-generative AI provides new opportunities to transform personal data\ninto alternative visual forms. In this paper, we illustrate the potential of\nAI-generated images in facilitating meaningful engagement with personal data.\nIn a formative autobiographical design study, we explored the design and use of\nAI-generated images derived from personal data. Informed by this study, we\ndesigned a web-based application as a probe that represents personal data\nthrough generative images utilizing Open AI's GPT-4 model and DALL-E 3. We then\nconducted a 21-day diary study and interviews using the probe with 16\nparticipants to investigate users' in-depth experiences with images generated\nby AI in everyday lives. Our findings reveal new qualities of experiences in\nusers' engagement with data, highlighting how participants constructed personal\nmeaning from their data through imagination and speculation on AI-generated\nimages. We conclude by discussing the potential and concerns of leveraging\nimage-generative AI for personal data meaning-making.",
      "tldr_zh": "这篇论文探讨了图像生成 AI（如 DALL-E 3 和 GPT-4）在重新想象个人数据方面的潜力，旨在通过 AI-generated images 促进用户与数据的有意义互动。作者首先开展了一个自传式设计研究（autobiographical design study），探索从个人数据派生的 AI 生成图像的设计和应用，并开发了一个基于网络的应用作为探测工具。接着，通过 21 天日记研究和访谈，涉及 16 名参与者，研究发现用户能够通过想象和对 AI 生成图像的推测，构建个人意义，从而增强数据参与体验。论文最终讨论了利用图像生成 AI 进行个人数据意义构建（personal data meaning-making）的潜力与潜在担忧。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.0"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages excluding reference and appendix. Accepted at ACM CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18853v1",
      "published_date": "2025-02-26 05:50:57 UTC",
      "updated_date": "2025-02-26 05:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:28:19.247763"
    },
    {
      "arxiv_id": "2502.18851v1",
      "title": "Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code",
      "title_zh": "翻译失败",
      "authors": [
        "Jungin Kim",
        "Shinwoo Park",
        "Yo-Sub Han"
      ],
      "abstract": "Code watermarking identifies AI-generated code by embedding patterns into the\ncode during generation. Effective watermarking requires meeting two key\nconditions: the watermark should be reliably detectable, and the code should\nretain its original functionality. However, existing methods often modify\ntokens that are critical for program logic, such as keywords in conditional\nexpressions or operators in arithmetic computations. These modifications can\ncause syntax errors or functional failures, limiting the practical use of\nwatermarking. We present STONE, a method that preserves functional integrity by\nselectively inserting watermarks only into non-syntax tokens. By excluding\ntokens essential for code execution, STONE minimizes the risk of functional\ndegradation.\n  In addition, we introduce CWEM, a comprehensive evaluation metric that\nevaluates watermarking techniques based on correctness, detectability, and\nnaturalness. While correctness and detectability have been widely used,\nnaturalness remains underexplored despite its importance. Unnatural patterns\ncan reveal the presence of a watermark, making it easier for adversaries to\nremove. We evaluate STONE using CWEM and compare its performance with the\nstate-of-the-art approach. The results show that STONE achieves an average\nimprovement of 7.69% in CWEM across Python, C++, and Java. Our code is\navailable in https://github.com/inistory/STONE-watermarking/.",
      "tldr_zh": "本研究针对代码水印技术在检测 LLM-Generated Code 中的问题，提出了一种名为 STONE 的方法，该方法通过仅在非语法 tokens 中插入水marks，确保代码功能完整性，避免了现有方法的语法错误或功能失败风险。STONE 结合了选择性水印插入策略，专注于非关键 tokens，以最小化功能退化。研究还引入了 CWEM 评估指标，该指标全面考虑正确性、可检测性和自然性，以评估水印技术的性能。在 Python、C++ 和 Java 等语言上，STONE 与最先进方法相比，平均提高了 7.69% 的 CWEM 分数，为可靠的代码水印应用提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18851v1",
      "published_date": "2025-02-26 05:46:13 UTC",
      "updated_date": "2025-02-26 05:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:28:29.966690"
    },
    {
      "arxiv_id": "2502.18848v1",
      "title": "A Causal Lens for Evaluating Faithfulness Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Kerem Zaman",
        "Shashank Srivastava"
      ],
      "abstract": "Large Language Models (LLMs) offer natural language explanations as an\nalternative to feature attribution methods for model interpretability. However,\ndespite their plausibility, they may not reflect the model's internal reasoning\nfaithfully, which is crucial for understanding the model's true decision-making\nprocesses. Although several faithfulness metrics have been proposed, a unified\nevaluation framework remains absent. To address this gap, we present Causal\nDiagnosticity, a framework to evaluate faithfulness metrics for natural\nlanguage explanations. Our framework employs the concept of causal\ndiagnosticity, and uses model-editing methods to generate faithful-unfaithful\nexplanation pairs. Our benchmark includes four tasks: fact-checking, analogy,\nobject counting, and multi-hop reasoning. We evaluate a variety of faithfulness\nmetrics, including post-hoc explanation and chain-of-thought-based methods. We\nfind that all tested faithfulness metrics often fail to surpass a random\nbaseline. Our work underscores the need for improved metrics and more reliable\ninterpretability methods in LLMs.",
      "tldr_zh": "本论文提出 Causal Diagnosticity 框架，用于评估大型语言模型 (LLMs) 自然语言解释的忠诚度 (faithfulness) 指标，旨在填补统一的评估机制缺失。该框架利用因果诊断性 (causal diagnosticity) 概念，通过模型编辑方法生成忠实与不忠实的解释对，并在事实检查、类比、物体计数和多跳推理等四个任务上进行基准测试。实验结果显示，所有测试的忠诚度指标，包括后验解释和基于 chain-of-thought 的方法，往往无法超过随机基线，突显了改进这些指标和开发更可靠的 LLM 可解释性方法的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 18 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18848v1",
      "published_date": "2025-02-26 05:35:53 UTC",
      "updated_date": "2025-02-26 05:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:28:42.072012"
    },
    {
      "arxiv_id": "2502.18845v1",
      "title": "Sliding Window Attention Training for Efficient Large Language Models",
      "title_zh": "滑动窗口注意力训练用于高效的大型语言模型",
      "authors": [
        "Zichuan Fu",
        "Wentao Song",
        "Yejing Wang",
        "Xian Wu",
        "Yefeng Zheng",
        "Yingying Zhang",
        "Derong Xu",
        "Xuetao Wei",
        "Tong Xu",
        "Xiangyu Zhao"
      ],
      "abstract": "Recent advances in transformer-based Large Language Models (LLMs) have\ndemonstrated remarkable capabilities across various tasks. However, their\nquadratic computational complexity concerning sequence length remains a\nsignificant bottleneck for processing long documents. As a result, many efforts\nlike sparse attention and state space models have been proposed to improve the\nefficiency of LLMs over long sequences. Though effective, these approaches\ncompromise the performance or introduce structural complexity. This calls for a\nsimple yet efficient model that preserves the fundamental Transformer\narchitecture. To this end, we introduce SWAT, which enables efficient\nlong-context handling via Sliding Window Attention Training. This paper first\nattributes the inefficiency of Transformers to the attention sink phenomenon\nresulting from the high variance of softmax operation. Then, we replace softmax\nwith the sigmoid function and utilize a balanced ALiBi and Rotary Position\nEmbedding for efficient information compression and retention. Experiments\ndemonstrate that SWAT achieves SOTA performance compared with state-of-the-art\nlinear recurrent architectures on eight benchmarks. Code is available at\nhttps://anonymous.4open.science/r/SWAT-attention.",
      "tldr_zh": "本研究针对 Transformer-based Large Language Models (LLMs) 在处理长序列时的二次计算复杂度问题，提出了 SWAT（Sliding Window Attention Training）方法，以实现高效的长上下文处理。SWAT 通过将 softmax 操作替换为 sigmoid 函数，并结合 balanced ALiBi 和 Rotary Position Embedding，来缓解 attention sink 现象和高方差问题，从而实现信息的有效压缩和保留。实验结果显示，SWAT 在八个基准上比现有线性循环架构取得了 SOTA 性能，为保持 Transformer 基本架构的同时提升效率提供了简单解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18845v1",
      "published_date": "2025-02-26 05:31:44 UTC",
      "updated_date": "2025-02-26 05:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:28:56.716128"
    },
    {
      "arxiv_id": "2502.18844v1",
      "title": "BarkXAI: A Lightweight Post-Hoc Explainable Method for Tree Species Classification with Quantifiable Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Yunmei Huang",
        "Songlin Hou",
        "Zachary Nelson Horve",
        "Songlin Fei"
      ],
      "abstract": "The precise identification of tree species is fundamental to forestry,\nconservation, and environmental monitoring. Though many studies have\ndemonstrated that high accuracy can be achieved using bark-based species\nclassification, these models often function as \"black boxes\", limiting\ninterpretability, trust, and adoption in critical forestry applications.\nAttribution-based Explainable AI (XAI) methods have been used to address this\nissue in related works. However, XAI applications are often dependent on local\nfeatures (such as a head shape or paw in animal applications) and cannot\ndescribe global visual features (such as ruggedness or smoothness) that are\npresent in texture-dominant images such as tree bark. Concept-based XAI\nmethods, on the other hand, offer explanations based on global visual features\nwith concepts, but they tend to require large overhead in building external\nconcept image datasets and the concepts can be vague and subjective without\ngood means of precise quantification. To address these challenges, we propose a\nlightweight post-hoc method to interpret visual models for tree species\nclassification using operators and quantifiable concepts. Our approach\neliminates computational overhead, enables the quantification of complex\nconcepts, and evaluates both concept importance and the model's reasoning\nprocess. To the best of our knowledge, our work is the first study to explain\nbark vision models in terms of global visual features with concepts. Using a\nhuman-annotated dataset as ground truth, our experiments demonstrate that our\nmethod significantly outperforms TCAV and Llama3.2 in concept importance\nranking based on Kendall's Tau, highlighting its superior alignment with human\nperceptions.",
      "tldr_zh": "该研究提出了一种轻量级后验（Post-Hoc）解释方法BarkXAI，用于树种分类模型的可解释性，针对树皮纹理图像的全局视觉特征（如粗糙度或光滑度）进行量化概念分析。BarkXAI 通过操作符和可量化的概念消除外部数据集的计算开销，并评估概念重要性和模型推理过程，从而解决现有Attribution-based XAI和Concept-based XAI方法的局限性。实验结果显示，该方法在人类标注数据集上显著优于TCAV和Llama3.2，在概念重要性排名上基于Kendall's Tau指标表现出更高的与人类感知一致性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18844v1",
      "published_date": "2025-02-26 05:31:15 UTC",
      "updated_date": "2025-02-26 05:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:29:05.976388"
    },
    {
      "arxiv_id": "2502.18842v2",
      "title": "Attention-Guided Integration of CLIP and SAM for Precise Object Masking in Robotic Manipulation",
      "title_zh": "注意力引导的 CLIP 和 SAM 整合，用于机器人操作中的精确对象掩",
      "authors": [
        "Muhammad A. Muttaqien",
        "Tomohiro Motoda",
        "Ryo Hanai",
        "Domae Yukiyasu"
      ],
      "abstract": "This paper introduces a novel pipeline to enhance the precision of object\nmasking for robotic manipulation within the specific domain of masking products\nin convenience stores. The approach integrates two advanced AI models, CLIP and\nSAM, focusing on their synergistic combination and the effective use of\nmultimodal data (image and text). Emphasis is placed on utilizing\ngradient-based attention mechanisms and customized datasets to fine-tune\nperformance. While CLIP, SAM, and Grad- CAM are established components, their\nintegration within this structured pipeline represents a significant\ncontribution to the field. The resulting segmented masks, generated through\nthis combined approach, can be effectively utilized as inputs for robotic\nsystems, enabling more precise and adaptive object manipulation in the context\nof convenience store products.",
      "tldr_zh": "这篇论文提出了一种新管道，通过整合 CLIP 和 SAM 模型，并利用梯度-based 注意机制和自定义数据集，增强机器人操作中物体掩码的精确性，针对便利店产品的多模态数据（图像和文本）。该方法强调 CLIP 处理文本-图像关联、SAM 进行高级分割，以及 Grad-CAM 引导的注意力机制，以实现模型协同优化。最终，生成的分割掩码可作为机器人系统的输入，提高物体操作的精确性和适应性，为机器人应用领域提供显著贡献。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18842v2",
      "published_date": "2025-02-26 05:30:46 UTC",
      "updated_date": "2025-02-28 02:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:29:18.474708"
    },
    {
      "arxiv_id": "2502.18836v1",
      "title": "REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Longling Geng",
        "Edward Y. Chang"
      ],
      "abstract": "This benchmark suite provides a comprehensive evaluation framework for\nassessing both individual LLMs and multi-agent systems in real-world planning\nscenarios. The suite encompasses eleven designed problems that progress from\nbasic to highly complex, incorporating key aspects such as multi-agent\ncoordination, inter-agent dependencies, and dynamic environmental disruptions.\nEach problem can be scaled along three dimensions: the number of parallel\nplanning threads, the complexity of inter-dependencies, and the frequency of\nunexpected disruptions requiring real-time adaptation. The benchmark includes\ndetailed specifications, evaluation metrics, and baseline implementations using\ncontemporary frameworks like LangGraph, enabling rigorous testing of both\nsingle-agent and multi-agent planning capabilities. Through standardized\nevaluation criteria and scalable complexity, this benchmark aims to drive\nprogress in developing more robust and adaptable AI planning systems for\nreal-world applications.",
      "tldr_zh": "该研究引入了REALM-Bench，一种全面的基准测试套件，用于评估大型语言模型（LLMs）和多智能体系统在真实世界规划场景中的性能。该套件包含11个从简单到高度复杂的问题，涵盖多智能体协调、代理间依赖性和动态环境干扰，并允许沿并行规划线程数量、互依赖复杂性和意外干扰频率三个维度进行扩展。基准提供详细规范、评估指标以及使用LangGraph等框架的基线实现，旨在通过标准化评估推动开发更鲁棒和可适应的AI规划系统。",
      "categories": [
        "cs.AI",
        "I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.18836v1",
      "published_date": "2025-02-26 05:24:22 UTC",
      "updated_date": "2025-02-26 05:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:29:29.740643"
    },
    {
      "arxiv_id": "2502.18822v1",
      "title": "Data-Efficient Multi-Agent Spatial Planning with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Huangyuan Su",
        "Aaron Walsman",
        "Daniel Garces",
        "Sham Kakade",
        "Stephanie Gil"
      ],
      "abstract": "In this project, our goal is to determine how to leverage the world-knowledge\nof pretrained large language models for efficient and robust learning in\nmultiagent decision making. We examine this in a taxi routing and assignment\nproblem where agents must decide how to best pick up passengers in order to\nminimize overall waiting time. While this problem is situated on a graphical\nroad network, we show that with the proper prompting zero-shot performance is\nquite strong on this task. Furthermore, with limited fine-tuning along with the\none-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing\napproaches with 50 times fewer environmental interactions. We also explore the\nbenefits of various linguistic prompting approaches and show that including\ncertain easy-to-compute information in the prompt significantly improves\nperformance. Finally, we highlight the LLM's built-in semantic understanding,\nshowing its ability to adapt to environmental factors through simple prompts.",
      "tldr_zh": "本研究探讨了如何利用预训练的 LLMs 来实现多代理空间规划中的数据高效和鲁棒学习，焦点在于出租车路由和分配问题，以最小化乘客等待时间。\n通过适当的提示，LLMs 在零样本情况下表现出色；结合有限微调和一步一步的回滚算法（one-at-a-time rollout），它能在 50 倍更少的环境交互下超越现有方法。\n此外，研究强调了不同语言提示策略的益处，显示加入易计算的信息能显著改善性能，并突出了 LLMs 的内置语义理解能力，使其能通过简单提示适应环境因素。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18822v1",
      "published_date": "2025-02-26 04:53:07 UTC",
      "updated_date": "2025-02-26 04:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:29:42.927273"
    },
    {
      "arxiv_id": "2502.18810v1",
      "title": "Holistic Audit Dataset Generation for LLM Unlearning via Knowledge Graph Traversal and Redundancy Removal",
      "title_zh": "翻译失败",
      "authors": [
        "Weipeng Jiang",
        "Juan Zhai",
        "Shiqing Ma",
        "Ziyan Lei",
        "Xiaofei Xie",
        "Yige Wang",
        "Chao Shen"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have faced increasing demands\nto selectively remove sensitive information, protect privacy, and comply with\ncopyright regulations through unlearning, by Machine Unlearning. While\nevaluating unlearning effectiveness is crucial, existing benchmarks are limited\nin scale and comprehensiveness, typically containing only a few hundred test\ncases. We identify two critical challenges in generating holistic audit\ndatasets: ensuring audit adequacy and handling knowledge redundancy between\nforget and retain dataset. To address these challenges, we propose HANKER, an\nautomated framework for holistic audit dataset generation leveraging knowledge\ngraphs to achieve fine-grained coverage and eliminate redundant knowledge.\nApplying HANKER to the popular MUSE benchmark, we successfully generated over\n69,000 and 111,000 audit cases for the News and Books datasets respectively,\nidentifying thousands of knowledge memorization instances that the previous\nbenchmark failed to detect. Our empirical analysis uncovers how knowledge\nredundancy significantly skews unlearning effectiveness metrics, with redundant\ninstances artificially inflating the observed memorization measurements ROUGE\nfrom 19.7% to 26.1% and Entailment Scores from 32.4% to 35.2%, highlighting the\nnecessity of systematic deduplication for accurate assessment.",
      "tldr_zh": "该论文针对Large Language Models (LLMs) 的Machine Unlearning需求，提出HANKER框架，通过知识图谱遍历（knowledge graph traversal）和冗余移除（redundancy removal）自动生成全面的审计数据集，以解决现有基准规模小和知识冗余问题。HANKER确保审计充分性，并应用于MUSE基准，成功生成超过69,000和111,000个审计案例，识别出数千个之前未检测到的知识记忆实例。实证分析显示，知识冗余显著扭曲了unlearning效果指标，如ROUGE从19.7%增至26.1%和Entailment Scores从32.4%增至35.2%，强调了系统去重的必要性，以实现更准确的评估。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.7; D.2.5; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18810v1",
      "published_date": "2025-02-26 04:39:22 UTC",
      "updated_date": "2025-02-26 04:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:29:55.805414"
    },
    {
      "arxiv_id": "2503.00046v1",
      "title": "Leveraging Large Models for Evaluating Novel Content: A Case Study on Advertisement Creativity",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoyi Joey Hou",
        "Adriana Kovashka",
        "Xiang Lorraine Li"
      ],
      "abstract": "Evaluating creativity is challenging, even for humans, not only because of\nits subjectivity but also because it involves complex cognitive processes.\nInspired by work in marketing, we attempt to break down visual advertisement\ncreativity into atypicality and originality. With fine-grained human\nannotations on these dimensions, we propose a suit of tasks specifically for\nsuch a subjective problem. We also evaluate the alignment between\nstate-of-the-art (SoTA) vision language models (VLM) and humans on our proposed\nbenchmark, demonstrating both the promises and challenges of using VLMs for\nautomatic creativity assessment.",
      "tldr_zh": "该论文探讨了评估广告创意的挑战性问题，将其分解为atypicality（非典型性）和originality（原创性）两个维度，并基于细粒度的人类标注提出了一系列针对主观性问题的任务套件。研究评估了state-of-the-art (SoTA)视觉语言模型（VLM）与人类的对齐度，发现VLMs在自动创意评估中显示出潜力，但也面临挑战。总体而言，此工作为利用大型模型进行主观内容评估提供了新的基准和见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00046v1",
      "published_date": "2025-02-26 04:28:03 UTC",
      "updated_date": "2025-02-26 04:28:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:30:05.895977"
    },
    {
      "arxiv_id": "2502.18807v2",
      "title": "BatteryLife: A Comprehensive Dataset and Benchmark for Battery Life Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ruifeng Tan",
        "Weixiang Hong",
        "Jiayue Tang",
        "Xibin Lu",
        "Ruijun Ma",
        "Xiang Zheng",
        "Jia Li",
        "Jiaqiang Huang",
        "Tong-Yi Zhang"
      ],
      "abstract": "Battery Life Prediction (BLP), which relies on time series data produced by\nbattery degradation tests, is crucial for battery utilization, optimization,\nand production. Despite impressive advancements, this research area faces three\nkey challenges. Firstly, the limited size of existing datasets impedes insights\ninto modern battery life data. Secondly, most datasets are restricted to\nsmall-capacity lithium-ion batteries tested under a narrow range of diversity\nin labs, raising concerns about the generalizability of findings. Thirdly,\ninconsistent and limited benchmarks across studies obscure the effectiveness of\nbaselines and leave it unclear if models popular in other time series fields\nare effective for BLP. To address these challenges, we propose BatteryLife, a\ncomprehensive dataset and benchmark for BLP. BatteryLife integrates 16\ndatasets, offering a 2.4 times sample size compared to the previous largest\ndataset, and provides the most diverse battery life resource with batteries\nfrom 8 formats, 80 chemical systems, 12 operating temperatures, and 646\ncharge/discharge protocols, including both laboratory and industrial tests.\nNotably, BatteryLife is the first to release battery life datasets of zinc-ion\nbatteries, sodium-ion batteries, and industry-tested large-capacity lithium-ion\nbatteries. With the comprehensive dataset, we revisit the effectiveness of\nbaselines popular in this and other time series fields. Furthermore, we propose\nCyclePatch, a plug-in technique that can be employed in a series of neural\nnetworks. Extensive benchmarking of 18 methods reveals that models popular in\nother time series fields can be unsuitable for BLP, and CyclePatch consistently\nimproves model performance establishing state-of-the-art benchmarks. Moreover,\nBatteryLife evaluates model performance across aging conditions and domains.\nBatteryLife is available at https://github.com/Ruifeng-Tan/BatteryLife.",
      "tldr_zh": "该研究针对Battery Life Prediction (BLP)面临的挑战，包括数据集规模小、数据多样性不足和基准不一致，提出BatteryLife，这是一个全面的数据集和基准平台。BatteryLife整合了16个数据集，比之前最大的数据集样本量增加2.4倍，涵盖8种电池格式、80种化学系统、12种操作温度和646种充放电协议，并首次发布锌-ion电池、钠-ion电池和工业测试的大容量锂-ion电池数据。通过重新评估18种方法，该研究发现其他时间序列领域的流行模型可能不适合BLP，而提出的CyclePatch插件技术能显著提升神经网络性能，建立新的state-of-the-art基准，并在不同老化条件和领域评估了模型表现。BatteryLife数据集可从https://github.com/Ruifeng-Tan/BatteryLife获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.18807v2",
      "published_date": "2025-02-26 04:21:20 UTC",
      "updated_date": "2025-02-27 03:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:30:18.471162"
    },
    {
      "arxiv_id": "2502.18798v3",
      "title": "ANPMI: Assessing the True Comprehension Capabilities of LLMs for Multiple Choice Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Gyeongje Cho",
        "Yeonkyoung So",
        "Jaejin Lee"
      ],
      "abstract": "Multiple-choice benchmarks, consisting of various prompts and choices, are\namong the most widely used methods to assess a language model's natural\nlanguage understanding capability. Given a specific prompt, we typically\ncompute $P(Choice|Prompt)$ to evaluate how likely a language model is to\ngenerate the correct choice compared to incorrect ones. However, we observe\nthat performance measured using this approach reflects not only the model's\ncomprehension of the prompt but also its inherent biases for certain choices\nregardless of the prompt. This issue makes it challenging to accurately measure\na model's natural language understanding, as models may select the answer\nwithout fully understanding the prompt. To address this limitation, we propose\na novel metric called ANPMI, which normalizes Pointwise Mutual Information\n(PMI) by $-\\log P(Choice)$. ANPMI provides a more accurate assessment of the\nmodel's natural language understanding by ensuring that it is challenging to\nanswer a question without properly understanding the prompt.",
      "tldr_zh": "该论文指出了现有多选题基准测试（如计算 $P(Choice|Prompt)$）的局限性，因为语言模型（LLMs）的表现可能受固有偏见影响，而非真正理解提示。作者提出了一种新指标 ANPMI，通过对 Pointwise Mutual Information (PMI) 进行 $-\\log P(Choice)$ 归一化，旨在更准确评估模型的自然语言理解能力。ANPMI 确保模型必须正确理解提示才能回答问题，从而提供更可靠的评估方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18798v3",
      "published_date": "2025-02-26 04:10:18 UTC",
      "updated_date": "2025-03-12 16:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:30:29.432003"
    },
    {
      "arxiv_id": "2502.18791v2",
      "title": "Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jungsoo Park",
        "Junmo Kang",
        "Gabriel Stanovsky",
        "Alan Ritter"
      ],
      "abstract": "The surge of LLM studies makes synthesizing their findings challenging.\nAnalysis of experimental results from literature can uncover important trends\nacross studies, but the time-consuming nature of manual data extraction limits\nits use. Our study presents a semi-automated approach for literature analysis\nthat accelerates data extraction using LLMs. It automatically identifies\nrelevant arXiv papers, extracts experimental results and related attributes,\nand organizes them into a structured dataset, LLMEvalDB. We then conduct an\nautomated literature analysis of frontier LLMs, reducing the effort of paper\nsurveying and data extraction by more than 93% compared to manual approaches.\nWe validate LLMEvalDB by showing that it reproduces key findings from a recent\nmanual analysis of Chain-of-Thought (CoT) reasoning and also uncovers new\ninsights that go beyond it, showing, for example, that in-context examples\nbenefit coding and multimodal tasks but offer limited gains in math reasoning\ntasks compared to zero-shot CoT. Our automatically updatable dataset enables\ncontinuous tracking of target models by extracting evaluation studies as new\ndata becomes available. Through LLMEvalDB and empirical analysis, we provide\ninsights into LLMs while facilitating ongoing literature analyses of their\nbehavior.",
      "tldr_zh": "这篇论文提出了一种半自动文献分析方法，使用 LLMs 加速数据提取，自动识别相关 arXiv 论文、提取实验结果和属性，并组织成结构化数据集 LLMEvalDB，从而减少了手动调查和提取的努力超过 93%。通过 LLMEvalDB，该研究再现了关于 Chain-of-Thought (CoT) 推理的现有关键发现，并揭示新见解，例如 in-context examples 在编码和多模态任务中有益，但在数学推理任务中对 zero-shot CoT 的提升有限。最终，这个可自动更新的数据集支持持续跟踪前沿 LLMs 的评估研究，并为深入理解 LLMs 的行为提供便利。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18791v2",
      "published_date": "2025-02-26 03:56:34 UTC",
      "updated_date": "2025-04-10 19:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:30:42.574449"
    },
    {
      "arxiv_id": "2502.18786v2",
      "title": "NeuroTree: Hierarchical Functional Brain Pathway Decoding for Mental Health Disorders",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-En Ding",
        "Dongsheng Luo",
        "Anna Zilverstand",
        "Feng Liu"
      ],
      "abstract": "Analyzing functional brain networks using functional magnetic resonance\nimaging (fMRI) is crucial for understanding psychiatric disorders and addictive\nbehaviors. While existing fMRI-based graph convolutional networks (GCNs) show\nconsiderable promise for feature extraction, they often fall short in\ncharacterizing complex relationships between brain regions and demographic\nfactors and accounting for interpretable variables linked to psychiatric\nconditions. We propose NeuroTree to overcome these limitations, integrating a\nk-hop AGE-GCN with neural ordinary differential equations (ODEs). This\nframework leverages an attention mechanism to optimize functional connectivity\n(FC), thereby enhancing dynamic FC feature learning for brain disease\nclassification. Furthermore, NeuroTree effectively decodes fMRI network\nfeatures into tree structures, which improves the capture of high-order brain\nregional pathway features and enables the identification of hierarchical neural\nbehavioral patterns essential for understanding disease-related brain\nsubnetworks. Our empirical evaluations demonstrate that NeuroTree achieves\nstate-of-the-art performance across two distinct mental disorder datasets and\nprovides valuable insights into age-related deterioration patterns. These\nfindings underscore the model's efficacy in predicting psychiatric disorders\nand elucidating their underlying neural mechanisms.",
      "tldr_zh": "本文提出 NeuroTree 框架，通过整合 k-hop AGE-GCN 和神经 ODEs，利用注意力机制优化功能连接 (FC)，以提升 fMRI 脑网络特征学习，并更好地表征脑区间复杂关系及人口统计因素。NeuroTree 将 fMRI 网络特征解码成树结构，捕获高阶脑区域路径和分层神经行为模式，从而识别精神障碍相关脑亚网络。实验结果显示，该框架在两个精神障碍数据集上实现最先进分类性能，并提供宝贵的洞见，如年龄相关退化模式，帮助预测精神障碍并阐明其神经机制。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18786v2",
      "published_date": "2025-02-26 03:42:58 UTC",
      "updated_date": "2025-03-10 03:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:30:55.072687"
    },
    {
      "arxiv_id": "2502.18778v3",
      "title": "M2-omni: Advancing Omni-MLLM for Comprehensive Modality Support with Competitive Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Qingpei Guo",
        "Kaiyou Song",
        "Zipeng Feng",
        "Ziping Ma",
        "Qinglong Zhang",
        "Sirui Gao",
        "Xuzheng Yu",
        "Yunxiao Sun",
        "Tai-Wei Chang",
        "Jingdong Chen",
        "Ming Yang",
        "Jun Zhou"
      ],
      "abstract": "We present M2-omni, a cutting-edge, open-source omni-MLLM that achieves\ncompetitive performance to GPT-4o. M2-omni employs a unified multimodal\nsequence modeling framework, which empowers Large Language Models(LLMs) to\nacquire comprehensive cross-modal understanding and generation capabilities.\nSpecifically, M2-omni can process arbitrary combinations of audio, video,\nimage, and text modalities as input, generating multimodal sequences\ninterleaving with audio, image, or text outputs, thereby enabling an advanced\nand interactive real-time experience. The training of such an omni-MLLM is\nchallenged by significant disparities in data quantity and convergence rates\nacross modalities. To address these challenges, we propose a step balance\nstrategy during pre-training to handle the quantity disparities in\nmodality-specific data. Additionally, a dynamically adaptive balance strategy\nis introduced during the instruction tuning stage to synchronize the\nmodality-wise training progress, ensuring optimal convergence. Notably, we\nprioritize preserving strong performance on pure text tasks to maintain the\nrobustness of M2-omni's language understanding capability throughout the\ntraining process. To our best knowledge, M2-omni is currently a very\ncompetitive open-source model to GPT-4o, characterized by its comprehensive\nmodality and task support, as well as its exceptional performance. We expect\nM2-omni will advance the development of omni-MLLMs, thus facilitating future\nresearch in this domain.",
      "tldr_zh": "我们介绍了 M2-omni，一种先进的开源 omni-MLLM 模型，其性能可与 GPT-4o 相媲美，能够处理音频、视频、图像和文本等模态的任意组合，并生成多模态序列输出以实现互动实时体验。  \n为应对训练中的数据量和收敛率差异，该模型在预训练阶段采用 step balance strategy 处理模态数据不均衡问题，并在指令微调阶段引入 dynamically adaptive balance strategy 来同步模态训练进度，同时优先维护纯文本任务的性能。  \n实验结果表明，M2-omni 在全面模态支持和任务执行上表现出色，有望推动 omni-MLLMs 的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18778v3",
      "published_date": "2025-02-26 03:21:12 UTC",
      "updated_date": "2025-04-07 08:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:31:09.237754"
    },
    {
      "arxiv_id": "2502.18773v2",
      "title": "Research on Edge Computing and Cloud Collaborative Resource Scheduling Optimization Based on Deep Reinforcement Learning",
      "title_zh": "基于深度强化学习的边缘计算与云协作资源调度优化研究",
      "authors": [
        "Yuqing Wang",
        "Xiao Yang"
      ],
      "abstract": "This study addresses the challenge of resource scheduling optimization in\nedge-cloud collaborative computing using deep reinforcement learning (DRL). The\nproposed DRL-based approach improves task processing efficiency, reduces\noverall processing time, enhances resource utilization, and effectively\ncontrols task migrations. Experimental results demonstrate the superiority of\nDRL over traditional scheduling algorithms, particularly in managing complex\ntask allocation, dynamic workloads, and multiple resource constraints. Despite\nits advantages, further improvements are needed to enhance learning efficiency,\nreduce training time, and address convergence issues. Future research should\nfocus on increasing the algorithm's fault tolerance to handle more complex and\nuncertain scheduling scenarios, thereby advancing the intelligence and\nefficiency of edge-cloud computing systems.",
      "tldr_zh": "本研究基于深度强化学习 (DRL) 优化了边云协作计算中的资源调度问题，旨在提高任务处理效率、减少整体处理时间、提升资源利用率并有效控制任务迁移。实验结果表明，DRL 方法在处理复杂任务分配、动态工作负载和多资源约束方面明显优于传统调度算法。虽有显著优势，但仍需改进学习效率、减少训练时间并解决收敛问题。未来工作将重点提升算法的容错性，以应对更复杂和不确定性的调度场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18773v2",
      "published_date": "2025-02-26 03:05:11 UTC",
      "updated_date": "2025-04-10 17:10:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:31:20.341240"
    },
    {
      "arxiv_id": "2502.18770v2",
      "title": "Reward Shaping to Mitigate Reward Hacking in RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Fu",
        "Xuandong Zhao",
        "Chengyuan Yao",
        "Heng Wang",
        "Qi Han",
        "Yanghua Xiao"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is essential for aligning\nlarge language models (LLMs) with human values. However, RLHF is susceptible to\nreward hacking, where the agent exploits flaws in the reward function rather\nthan learning the intended behavior, thus degrading alignment. While reward\nshaping helps stabilize RLHF and partially mitigate reward hacking, a\nsystematic investigation into shaping techniques and their underlying\nprinciples remains lacking. To bridge this gap, we present a comprehensive\nstudy of the prevalent reward shaping methods. Our analysis suggests three key\ndesign principles: (1) RL reward is ideally bounded, (2) RL benefits from rapid\ninitial growth followed by gradual convergence, and (3) RL reward is best\nformulated as a function of centered reward. Guided by these insights, we\npropose Preference As Reward (PAR), a novel approach that leverages the latent\npreferences embedded within the reward model itself as the signal for\nreinforcement learning. We evaluated PAR on two base models, Gemma2-2B and\nLlama3-8B, using two datasets, Ultrafeedback-Binarized and HH-RLHF.\nExperimental results demonstrate PAR's superior performance over other reward\nshaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate at\nleast 5 percentage points higher than competing approaches. Furthermore, PAR\nexhibits remarkable data efficiency, requiring only a single reference reward\nfor optimal performance, and maintains robustness against reward hacking even\nafter two full epochs of training. Code is available at\nhttps://github.com/PorUna-byte/PAR.",
      "tldr_zh": "该论文探讨了强化学习从人类反馈（RLHF）中的奖励黑客（reward hacking）问题，即代理利用奖励函数缺陷而非学习预期行为，导致模型对齐失效。为缓解此问题，研究者分析了现有奖励整形（reward shaping）方法，并总结了三个关键设计原则：RL 奖励应有界、从快速增长后渐进收敛中受益，以及基于中心化奖励的函数制定。论文提出新方法 Preference As Reward (PAR)，利用奖励模型中的潜在偏好作为强化学习信号；在 Gemma2-2B 和 Llama3-8B 模型上的实验显示，PAR 在 AlpacaEval 2.0 基准上胜率比竞争方法高出至少 5 个百分点，且具有更高的数据效率和对 reward hacking 的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.18770v2",
      "published_date": "2025-02-26 02:57:59 UTC",
      "updated_date": "2025-02-27 04:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:31:32.257462"
    },
    {
      "arxiv_id": "2502.18762v1",
      "title": "Online Prototypes and Class-Wise Hypergradients for Online Continual Learning with Pre-Trained Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Michel",
        "Maorong Wang",
        "Jiangpeng He",
        "Toshihiko Yamasaki"
      ],
      "abstract": "Continual Learning (CL) addresses the problem of learning from a data\nsequence where the distribution changes over time. Recently, efficient\nsolutions leveraging Pre-Trained Models (PTM) have been widely explored in the\noffline CL (offCL) scenario, where the data corresponding to each incremental\ntask is known beforehand and can be seen multiple times. However, such\nsolutions often rely on 1) prior knowledge regarding task changes and 2)\nhyper-parameter search, particularly regarding the learning rate. Both\nassumptions remain unavailable in online CL (onCL) scenarios, where incoming\ndata distribution is unknown and the model can observe each datum only once.\nTherefore, existing offCL strategies fall largely behind performance-wise in\nonCL, with some proving difficult or impossible to adapt to the online\nscenario. In this paper, we tackle both problems by leveraging Online\nPrototypes (OP) and Class-Wise Hypergradients (CWH). OP leverages stable output\nrepresentations of PTM by updating its value on the fly to act as replay\nsamples without requiring task boundaries or storing past data. CWH learns\nclass-dependent gradient coefficients during training to improve over\nsub-optimal learning rates. We show through experiments that both introduced\nstrategies allow for a consistent gain in accuracy when integrated with\nexisting approaches. We will make the code fully available upon acceptance.",
      "tldr_zh": "该研究针对在线持续学习（Online Continual Learning, onCL）中的挑战，提出了一种利用预训练模型（Pre-Trained Models, PTM）的创新方法，以解决数据分布未知且每个数据点仅可观察一次的问题。作者引入了Online Prototypes (OP)，通过在线更新PTM的稳定输出表示作为重放样本，避免了任务边界依赖和数据存储需求；同时，Class-Wise Hypergradients (CWH) 学习类依赖的梯度系数，以优化子最优的学习率。实验结果显示，将OP和CWH整合到现有方法中，能显著提高准确率。该框架为onCL场景提供了更高效且适配性的解决方案，并计划公开代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.18762v1",
      "published_date": "2025-02-26 02:43:54 UTC",
      "updated_date": "2025-02-26 02:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:31:46.970979"
    },
    {
      "arxiv_id": "2502.18760v2",
      "title": "Learning Autonomy: Off-Road Navigation Enhanced by Human Input",
      "title_zh": "学习自治：通过人类输入增强的越野导航",
      "authors": [
        "Akhil Nagariya",
        "Dimitar Filev",
        "Srikanth Saripalli",
        "Gaurav Pandey"
      ],
      "abstract": "In the area of autonomous driving, navigating off-road terrains presents a\nunique set of challenges, from unpredictable surfaces like grass and dirt to\nunexpected obstacles such as bushes and puddles. In this work, we present a\nnovel learning-based local planner that addresses these challenges by directly\ncapturing human driving nuances from real-world demonstrations using only a\nmonocular camera. The key features of our planner are its ability to navigate\nin challenging off-road environments with various terrain types and its fast\nlearning capabilities. By utilizing minimal human demonstration data (5-10\nmins), it quickly learns to navigate in a wide array of off-road conditions.\nThe local planner significantly reduces the real world data required to learn\nhuman driving preferences. This allows the planner to apply learned behaviors\nto real-world scenarios without the need for manual fine-tuning, demonstrating\nquick adjustment and adaptability in off-road autonomous driving technology.",
      "tldr_zh": "本文提出了一种基于学习的本地规划器(local planner)，利用单目摄像头(monocular camera)从真实世界人类驾驶演示中捕获驾驶细微差别，以应对非道路地形（如草地和泥土）的导航挑战。该规划器只需5-10分钟的演示数据，即可快速学习适应各种地形类型和障碍物，显著减少了学习人类驾驶偏好所需的数据量。与传统方法相比，它能在真实场景中直接应用学到的行为，而无需手动微调，展示了非道路自动驾驶技术的快速调整和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18760v2",
      "published_date": "2025-02-26 02:36:14 UTC",
      "updated_date": "2025-05-14 14:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:31:55.613801"
    },
    {
      "arxiv_id": "2503.05777v1",
      "title": "Medical Hallucinations in Foundation Models and Their Impact on Healthcare",
      "title_zh": "基础模型中的医学幻觉及其对医疗保健的影响",
      "authors": [
        "Yubin Kim",
        "Hyewon Jeong",
        "Shan Chen",
        "Shuyue Stella Li",
        "Mingyu Lu",
        "Kumail Alhamoud",
        "Jimin Mun",
        "Cristina Grau",
        "Minseok Jung",
        "Rodrigo Gameiro",
        "Lizhou Fan",
        "Eugene Park",
        "Tristan Lin",
        "Joonsik Yoon",
        "Wonjin Yoon",
        "Maarten Sap",
        "Yulia Tsvetkov",
        "Paul Liang",
        "Xuhai Xu",
        "Xin Liu",
        "Daniel McDuff",
        "Hyeonhoon Lee",
        "Hae Won Park",
        "Samir Tulebaev",
        "Cynthia Breazeal"
      ],
      "abstract": "Foundation Models that are capable of processing and generating multi-modal\ndata have transformed AI's role in medicine. However, a key limitation of their\nreliability is hallucination, where inaccurate or fabricated information can\nimpact clinical decisions and patient safety. We define medical hallucination\nas any instance in which a model generates misleading medical content. This\npaper examines the unique characteristics, causes, and implications of medical\nhallucinations, with a particular focus on how these errors manifest themselves\nin real-world clinical scenarios. Our contributions include (1) a taxonomy for\nunderstanding and addressing medical hallucinations, (2) benchmarking models\nusing medical hallucination dataset and physician-annotated LLM responses to\nreal medical cases, providing direct insight into the clinical impact of\nhallucinations, and (3) a multi-national clinician survey on their experiences\nwith medical hallucinations. Our results reveal that inference techniques such\nas Chain-of-Thought (CoT) and Search Augmented Generation can effectively\nreduce hallucination rates. However, despite these improvements, non-trivial\nlevels of hallucination persist. These findings underscore the ethical and\npractical imperative for robust detection and mitigation strategies,\nestablishing a foundation for regulatory policies that prioritize patient\nsafety and maintain clinical integrity as AI becomes more integrated into\nhealthcare. The feedback from clinicians highlights the urgent need for not\nonly technical advances but also for clearer ethical and regulatory guidelines\nto ensure patient safety. A repository organizing the paper resources,\nsummaries, and additional information is available at\nhttps://github.com/mitmedialab/medical hallucination.",
      "tldr_zh": "这篇论文探讨了Foundation Models在医疗领域的幻觉（medical hallucination）问题，即模型生成误导性医疗内容可能导致临床决策错误和患者安全风险。论文的主要贡献包括：提出一个分类系统（taxonomy）来理解和处理这些幻觉、使用医疗幻觉数据集及医生标注的LLM响应进行基准测试，以及开展多国临床医生调查以评估实际影响。研究发现，Chain-of-Thought (CoT) 和 Search Augmented Generation 等推理技术能有效降低幻觉率，但残留问题仍需解决，因此呼吁开发稳健的检测与缓解策略，并制定伦理和监管政策以保障AI在医疗中的安全应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05777v1",
      "published_date": "2025-02-26 02:30:44 UTC",
      "updated_date": "2025-02-26 02:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:32:08.490171"
    },
    {
      "arxiv_id": "2502.18754v1",
      "title": "AgentSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Yan",
        "Yu Shang",
        "Qingbin Zeng",
        "Yu Li",
        "Keyu Zhao",
        "Zhiheng Zheng",
        "Xuefei Ning",
        "Tianji Wu",
        "Shengen Yan",
        "Yu Wang",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "The AgentSociety Challenge is the first competition in the Web Conference\nthat aims to explore the potential of Large Language Model (LLM) agents in\nmodeling user behavior and enhancing recommender systems on web platforms. The\nChallenge consists of two tracks: the User Modeling Track and the\nRecommendation Track. Participants are tasked to utilize a combined dataset\nfrom Yelp, Amazon, and Goodreads, along with an interactive environment\nsimulator, to develop innovative LLM agents. The Challenge has attracted 295\nteams across the globe and received over 1,400 submissions in total over the\ncourse of 37 official competition days. The participants have achieved 21.9%\nand 20.3% performance improvement for Track 1 and Track 2 in the Development\nPhase, and 9.1% and 15.9% in the Final Phase, representing a significant\naccomplishment. This paper discusses the detailed designs of the Challenge,\nanalyzes the outcomes, and highlights the most successful LLM agent designs. To\nsupport further research and development, we have open-sourced the benchmark\nenvironment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.",
      "tldr_zh": "AgentSociety Challenge 是一个首个专注于设计 LLM agents 的竞赛，旨在探索这些代理在网络平台上进行用户建模和推荐系统的潜力。竞赛分为 User Modeling Track 和 Recommendation Track，参与者利用 Yelp、Amazon 和 Goodreads 的结合数据集以及交互环境模拟器开发创新代理，吸引了 295 个团队并收到超过 1,400 份提交。结果显示，参与者在开发阶段和最终阶段分别实现了 21.9% 和 9.1%（Track 1）、20.3% 和 15.9%（Track 2）的性能提升，该论文分析了成功代理设计并开源了基准环境（https://tsinghua-fib-lab.github.io/AgentSocietyChallenge）。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 10 figures, in Proceedings of the ACM Web Conference 2025\n  (WWW '25)",
      "pdf_url": "http://arxiv.org/pdf/2502.18754v1",
      "published_date": "2025-02-26 02:10:25 UTC",
      "updated_date": "2025-02-26 02:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:32:21.333222"
    },
    {
      "arxiv_id": "2503.05776v1",
      "title": "FAA-CLIP: Federated Adversarial Adaptation of CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Wu",
        "Ahmad Chaddad",
        "Christian Desrosiers",
        "Tareef Daqqaq",
        "Reem Kateb"
      ],
      "abstract": "Despite the remarkable performance of vision language models (VLMs) such as\nContrastive Language Image Pre-training (CLIP), the large size of these models\nis a considerable obstacle to their use in federated learning (FL) systems\nwhere the parameters of local client models need to be transferred to a global\nserver for aggregation. Another challenge in FL is the heterogeneity of data\nfrom different clients, which affects the generalization performance of the\nsolution. In addition, natural pre-trained VLMs exhibit poor generalization\nability in the medical datasets, suggests there exists a domain gap. To solve\nthese issues, we introduce a novel method for the Federated Adversarial\nAdaptation (FAA) of CLIP. Our method, named FAA-CLIP, handles the large\ncommunication costs of CLIP using a light-weight feature adaptation module\n(FAM) for aggregation, effectively adapting this VLM to each client's data\nwhile greatly reducing the number of parameters to transfer. By keeping CLIP\nfrozen and only updating the FAM parameters, our method is also computationally\nefficient. Unlike existing approaches, our FAA-CLIP method directly addresses\nthe problem of domain shifts across clients via a domain adaptation (DA)\nmodule. This module employs a domain classifier to predict if a given sample is\nfrom the local client or the global server, allowing the model to learn\ndomain-invariant representations. Extensive experiments on six different\ndatasets containing both natural and medical images demonstrate that FAA-CLIP\ncan generalize well on both natural and medical datasets compared to recent FL\napproaches. Our codes are available at https://github.com/AIPMLab/FAA-CLIP.",
      "tldr_zh": "这篇论文提出 FAA-CLIP 方法，用于在联邦学习 (FL) 中适应视觉语言模型 (VLMs) 如 CLIP，解决模型大小导致的通信成本高、客户端数据异质性以及域移位问题。方法通过轻量级特征适应模块 (FAM) 只更新少量参数来保持 CLIP 冻结，提高计算效率，并引入域适应 (DA) 模块利用域分类器学习域不变表示。实验在六个包含自然和医疗图像的数据集上表明，FAA-CLIP 比现有 FL 方法表现出更好的泛化性能，为跨域应用提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2503.05776v1",
      "published_date": "2025-02-26 01:51:11 UTC",
      "updated_date": "2025-02-26 01:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:32:33.572493"
    },
    {
      "arxiv_id": "2502.18744v2",
      "title": "ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Jeesu Jung",
        "Chanjun Park",
        "Sangkeun Jung"
      ],
      "abstract": "Recent efforts in LLM alignment have focused on constructing large-scale\npreference datasets via human or Artificial Intelligence (AI) annotators.\nHowever, such approaches rely on instance-wise supervision, incurring\nsubstantial annotation cost and limited interpretability. In this paper, we\npropose ZEBRA - a model behavior-wise zero-annotation framework that constructs\npreference data by leveraging model behavior knowledge derived from benchmark\nperformances. ZEBRA binarizes response pairs by evaluating the quality and\nsimilarity of their origin models, entirely bypassing instance-level\nannotation. This allows scalable, controllable, and cost-effective alignment\ndata generation. Empirical results show that ZEBRA achieves alignment\nperformance comparable to instance-supervised methods, despite requiring no\nmanual or model-based labeling.",
      "tldr_zh": "本文提出 ZEBRA，一种基于模型行为知识的零-annotation 框架，用于构建偏好数据集，旨在解决传统 LLM alignment 方法中依赖实例-wise 监督导致的标注成本高和可解释性有限的问题。ZEBRA 通过评估响应 pairs 的质量和相似性（从 benchmark performances 派生），实现响应对的二值化处理，从而实现可扩展、可控且低成本的数据生成。实验结果显示，ZEBRA 的 alignment 性能与实例监督方法相当，但完全无需手动或模型-based 标注。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages,7 figures,5 tables,4 graphs",
      "pdf_url": "http://arxiv.org/pdf/2502.18744v2",
      "published_date": "2025-02-26 01:36:40 UTC",
      "updated_date": "2025-05-20 23:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:32:45.786481"
    },
    {
      "arxiv_id": "2502.18737v1",
      "title": "Intent Tagging: Exploring Micro-Prompting Interactions for Supporting Granular Human-GenAI Co-Creation Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Gmeiner",
        "Nicolai Marquardt",
        "Michael Bentley",
        "Hugo Romat",
        "Michel Pahud",
        "David Brown",
        "Asta Roseway",
        "Nikolas Martelaro",
        "Kenneth Holstein",
        "Ken Hinckley",
        "Nathalie Riche"
      ],
      "abstract": "Despite Generative AI (GenAI) systems' potential for enhancing content\ncreation, users often struggle to effectively integrate GenAI into their\ncreative workflows. Core challenges include misalignment of AI-generated\ncontent with user intentions (intent elicitation and alignment), user\nuncertainty around how to best communicate their intents to the AI system\n(prompt formulation), and insufficient flexibility of AI systems to support\ndiverse creative workflows (workflow flexibility). Motivated by these\nchallenges, we created IntentTagger: a system for slide creation based on the\nnotion of Intent Tags - small, atomic conceptual units that encapsulate user\nintent - for exploring granular and non-linear micro-prompting interactions for\nHuman-GenAI co-creation workflows. Our user study with 12 participants provides\ninsights into the value of flexibly expressing intent across varying levels of\nambiguity, meta-intent elicitation, and the benefits and challenges of intent\ntag-driven workflows. We conclude by discussing the broader implications of our\nfindings and design considerations for GenAI-supported content creation\nworkflows.",
      "tldr_zh": "该论文探讨了Generative AI (GenAI) 在内容创建中的挑战，包括意图激发与对齐 (intent elicitation and alignment)、提示制定 (prompt formulation) 和工作流灵活性 (workflow flexibility)。为了解决这些问题，研究者开发了IntentTagger 系统，该系统利用Intent Tags（小的原子概念单位）来支持颗粒化和非线性micro-prompting interactions，从而提升Human-GenAI co-creation workflows 的效率。在一项涉及12名参与者的用户研究中，论文揭示了灵活表达意图的益处、meta-intent elicitation 的价值，以及意图标记驱动工作流的优势与挑战，并讨论了针对GenAI 支持内容创建的更广泛设计考虑。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "31 pages, 30 figures, 3 tables. To appear in the Proceedings of the\n  2025 ACM CHI Conference on Human Factors in Computing Systems, Yokohama,\n  Japan",
      "pdf_url": "http://arxiv.org/pdf/2502.18737v1",
      "published_date": "2025-02-26 01:13:47 UTC",
      "updated_date": "2025-02-26 01:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:32:57.963045"
    },
    {
      "arxiv_id": "2502.18736v1",
      "title": "AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect Graphical Interface Commands as General-Purpose Tools",
      "title_zh": "翻译失败",
      "authors": [
        "Nathalie Riche",
        "Anna Offenwanger",
        "Frederic Gmeiner",
        "David Brown",
        "Hugo Romat",
        "Michel Pahud",
        "Nicolai Marquardt",
        "Kori Inkpen",
        "Ken Hinckley"
      ],
      "abstract": "Chat-based prompts respond with verbose linear-sequential texts, making it\ndifficult to explore and refine ambiguous intents, back up and reinterpret, or\nshift directions in creative AI-assisted design work. AI-Instruments instead\nembody \"prompts\" as interface objects via three key principles: (1) Reification\nof user-intent as reusable direct-manipulation instruments; (2) Reflection of\nmultiple interpretations of ambiguous user-intents (Reflection-in-intent) as\nwell as the range of AI-model responses (Reflection-in-response) to inform\ndesign \"moves\" towards a desired result; and (3) Grounding to instantiate an\ninstrument from an example, result, or extrapolation directly from another\ninstrument. Further, AI-Instruments leverage LLM's to suggest, vary, and refine\nnew instruments, enabling a system that goes beyond hard-coded functionality by\ngenerating its own instrumental controls from content. We demonstrate four\ntechnology probes, applied to image generation, and qualitative insights from\ntwelve participants, showing how AI-Instruments address challenges of intent\nformulation, steering via direct manipulation, and non-linear iterative\nworkflows to reflect and resolve ambiguous intents.",
      "tldr_zh": "该论文提出AI-Instruments框架，将传统的chat-based prompts转化为界面对象，作为通用工具，以解决创意AI辅助设计中模糊意图探索、回退解释和方向切换的难题。该框架基于三个关键原则：(1) 将用户意图实体化为可重用直接操作工具(Reification)；(2) 反射模糊意图的多种解释(Reflection-in-intent)以及AI模型响应的范围(Reflection-in-response)，以指导设计决策；以及(3) 通过示例、结果或推断实例化工具(Grounding)。此外，AI-Instruments利用LLM来建议、变异和完善新工具，从而超越硬编码功能，实现内容驱动的工具生成。研究通过四个图像生成技术探针和十二名参与者的定性反馈，展示了该框架在意图制定、直接操作引导和非线性迭代工作流方面的优势。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 10 figures. To appear in the Proceedings of the 2025 ACM\n  CHI Conference on Human Factors in Computing Systems, Yokohama, Japan.\n  https://hugoromat.github.io/ai_instruments/",
      "pdf_url": "http://arxiv.org/pdf/2502.18736v1",
      "published_date": "2025-02-26 01:11:24 UTC",
      "updated_date": "2025-02-26 01:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:33:09.763466"
    },
    {
      "arxiv_id": "2502.18733v1",
      "title": "Cross-Modality Investigation on WESAD Stress Classification",
      "title_zh": "跨模态研究：WESAD 压力分类调查",
      "authors": [
        "Eric Oliver",
        "Sagnik Dakshit"
      ],
      "abstract": "Deep learning's growing prevalence has driven its widespread use in\nhealthcare, where AI and sensor advancements enhance diagnosis, treatment, and\nmonitoring. In mobile health, AI-powered tools enable early diagnosis and\ncontinuous monitoring of conditions like stress. Wearable technologies and\nmultimodal physiological data have made stress detection increasingly viable,\nbut model efficacy depends on data quality, quantity, and modality. This study\ndevelops transformer models for stress detection using the WESAD dataset,\ntraining on electrocardiograms (ECG), electrodermal activity (EDA),\nelectromyography (EMG), respiration rate (RESP), temperature (TEMP), and 3-axis\naccelerometer (ACC) signals. The results demonstrate the effectiveness of\nsingle-modality transformers in analyzing physiological signals, achieving\nstate-of-the-art performance with accuracy, precision and recall values in the\nrange of $99.73\\%$ to $99.95\\%$ for stress detection. Furthermore, this study\nexplores cross-modal performance and also explains the same using 2D\nvisualization of the learned embedding space and quantitative analysis based on\ndata variance. Despite the large body of work on stress detection and\nmonitoring, the robustness and generalization of these models across different\nmodalities has not been explored. This research represents one of the initial\nefforts to interpret embedding spaces for stress detection, providing valuable\ninformation on cross-modal performance.",
      "tldr_zh": "这篇论文使用 Transformer 模型在 WESAD 数据集上进行压力检测，基于单模态生理信号如 ECG、EDA、EMG、RESP、TEMP 和 ACC 来训练模型。结果显示，这些模型在压力分类任务中取得了卓越性能，准确率、精确度和召回率均达到 99.73% 到 99.95%。此外，研究通过 2D 可视化和数据方差分析探讨了跨模态性能，提供对模型嵌入空间的初步解释，并评估了其在不同模态下的鲁棒性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18733v1",
      "published_date": "2025-02-26 01:04:58 UTC",
      "updated_date": "2025-02-26 01:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:33:21.061903"
    },
    {
      "arxiv_id": "2503.16464v1",
      "title": "Human-Centered AI in Multidisciplinary Medical Discussions: Evaluating the Feasibility of a Chat-Based Approach to Case Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Shinnosuke Sawano",
        "Satoshi Kodera"
      ],
      "abstract": "In this study, we investigate the feasibility of using a human-centered\nartificial intelligence (AI) chat platform where medical specialists\ncollaboratively assess complex cases. As the target population for this\nplatform, we focus on patients with cardiovascular diseases who are in a state\nof multimorbidity, that is, suffering from multiple chronic conditions. We\nevaluate simulated cases with multiple diseases using a chat application by\ncollaborating with physicians to assess feasibility, efficiency gains through\nAI utilization, and the quantification of discussion content. We constructed\nsimulated cases based on past case reports, medical errors reports and complex\ncases of cardiovascular diseases experienced by the physicians. The analysis of\ndiscussions across five simulated cases demonstrated a significant reduction in\nthe time required for summarization using AI, with an average reduction of\n79.98\\%. Additionally, we examined hallucination rates in AI-generated\nsummaries used in multidisciplinary medical discussions. The overall\nhallucination rate ranged from 1.01\\% to 5.73\\%, with an average of 3.62\\%,\nwhereas the harmful hallucination rate varied from 0.00\\% to 2.09\\%, with an\naverage of 0.49\\%. Furthermore, morphological analysis demonstrated that\nmultidisciplinary assessments enabled a more complex and detailed\nrepresentation of medical knowledge compared with single physician assessments.\nWe examined structural differences between multidisciplinary and single\nphysician assessments using centrality metrics derived from the knowledge\ngraph. In this study, we demonstrated that AI-assisted summarization\nsignificantly reduced the time required for medical discussions while\nmaintaining structured knowledge representation. These findings can support the\nfeasibility of AI-assisted chat-based discussions as a human-centered approach\nto multidisciplinary medical decision-making.",
      "tldr_zh": "本研究评估了 human-centered AI 聊天平台在多学科医疗讨论中的可行性，聚焦于心血管疾病多重并发症患者，通过模拟病例与医生协作，量化讨论效率和内容。结果显示，AI 辅助总结显著减少了讨论时间，平均降低 79.98%，而 AI 生成总结的 hallucination rate 较低（总体平均 3.62%，有害平均 0.49%）。此外，使用 knowledge graph 分析发现，多学科评估比单一医生评估更复杂和详细，支持 AI 在医疗决策中的人类中心化应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 2 figures, 3 tables, 2 supplemental figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16464v1",
      "published_date": "2025-02-26 01:02:47 UTC",
      "updated_date": "2025-02-26 01:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:33:33.366982"
    },
    {
      "arxiv_id": "2503.01873v1",
      "title": "Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Long Cheng",
        "Qichen Liao",
        "Fan Wu",
        "Junlin Mu",
        "Tengfei Han",
        "Zhe Qiu",
        "Lianqiang Li",
        "Tianyi Liu",
        "Fangzheng Miao",
        "Keming Gao",
        "Liang Wang",
        "Zhen Zhang",
        "Qiande Yin"
      ],
      "abstract": "Attention calculation is extremely time-consuming for long-sequence inference\ntasks, such as text or image/video generation, in large models. To accelerate\nthis process, we developed a low-precision, mathematically-equivalent algorithm\ncalled PASA, based on Flash Attention. PASA introduces two novel techniques:\nonline pseudo-average shifting and global recovering. These techniques enable\nthe use of half-precision computation throughout the Flash Attention process\nwithout incurring overflow instability or unacceptable numerical accuracy loss.\nThis algorithm enhances performance on memory-restricted AI hardware\narchitectures, such as the Ascend Neural-network Processing Unit(NPU), by\nreducing data movement and increasing computational FLOPs. The algorithm is\nvalidated using both designed random benchmarks and real large models. We find\nthat the large bias and amplitude of attention input data are critical factors\ncontributing to numerical overflow ($>65504$ for half precision) in two\ndifferent categories of large models (Qwen2-7B language models and\nStable-Video-Diffusion multi-modal models). Specifically, overflow arises due\nto the large bias in the sequence dimension and the resonance mechanism between\nthe query and key in the head dimension of the Stable-Video-Diffusion models.\nThe resonance mechanism is defined as phase coincidence or 180-degree phase\nshift between query and key matrices. It will remarkably amplify the element\nvalues of attention score matrix. This issue also applies to the Qwen models.\nAdditionally, numerical accuracy is assessed through root mean square error\n(RMSE) and by comparing the final generated texts and videos to those produced\nusing high-precision attention.",
      "tldr_zh": "这篇论文提出了 PASA（Online Pseudo-average Shifting Attention）算法，一种基于 Flash Attention 的低精度计算方法，用于加速大型语言模型（LLM）在长序列推理任务中的注意力计算。PASA 引入了 online pseudo-average shifting 和 global recovering 两种新技巧，使整个过程能够使用半精度计算，同时避免数值溢出和精度损失，从而提升内存受限硬件（如 Ascend NPU）的性能。实验结果显示，注意力输入数据的偏差和共振机制（如查询与键在头维度上的相位一致或180度相移）是导致溢出的关键因素，并通过 RMSE 评估和生成文本/视频的比较验证了算法的鲁棒性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.PF",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "21 Pages, 14 figures, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2503.01873v1",
      "published_date": "2025-02-26 01:00:46 UTC",
      "updated_date": "2025-02-26 01:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:33:43.971127"
    },
    {
      "arxiv_id": "2502.18726v1",
      "title": "Deep-Bench: Deep Learning Benchmark Dataset for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Daghighfarsoodeh",
        "Chung-Yu Wang",
        "Hamed Taherkhani",
        "Melika Sepidband",
        "Mohammad Abdollahi",
        "Hadi Hemmati",
        "Hung Viet Pham"
      ],
      "abstract": "Deep learning (DL) has revolutionized areas such as computer vision, natural\nlanguage processing, and more. However, developing DL systems is challenging\ndue to the complexity of DL workflows. Large Language Models (LLMs), such as\nGPT, Claude, Llama, Mistral, etc., have emerged as promising tools to assist in\nDL code generation, offering potential solutions to these challenges. Despite\nthis, existing benchmarks such as DS-1000 are limited, as they primarily focus\non small DL code snippets related to pre/post-processing tasks and lack a\ncomprehensive coverage of the full DL pipeline, including different DL phases\nand input data types.\n  To address this, we introduce DeepBench, a novel benchmark dataset designed\nfor function-level DL code generation. DeepBench categorizes DL problems based\non three key aspects: phases such as pre-processing, model construction, and\ntraining; tasks, including classification, regression, and recommendation; and\ninput data types such as tabular, image, and text.\n  GPT-4o -- the state-of-the-art LLM -- achieved 31% accuracy on DeepBench,\nsignificantly lower than its 60% on DS-1000. We observed similar difficulty for\nother LLMs (e.g., 28% vs. 54% for Claude, 21% vs. 41% for LLaMA, and 15% vs.\n20% for Mistral). This result underscores DeepBench's greater complexity. We\nalso construct a taxonomy of issues and bugs found in LLM-generated DL code,\nwhich highlights the distinct challenges that LLMs face when generating DL code\ncompared to general code.\n  Furthermore, our analysis also reveals substantial performance variations\nacross categories, with differences of up to 7% among phases and 37% among\ntasks. These disparities suggest that DeepBench offers valuable insights into\nthe LLMs' performance and areas for potential improvement in the DL domain.",
      "tldr_zh": "该研究引入了DeepBench，一个新的基准数据集，用于评估Large Language Models (LLMs)在深度学习 (DL) 代码生成方面的性能。DeepBench针对函数级DL代码进行分类，涵盖三个关键方面：DL阶段（如预处理、模型构建和训练）、任务（如分类、回归和推荐），以及输入数据类型（如表格、图像和文本），以弥补现有基准如DS-1000的局限性。实验结果显示，GPT-4o在DeepBench上的准确率仅为31%，远低于其在DS-1000上的60%，其他LLMs（如Claude、LLaMA和Mistral）也表现出类似差距，这突显了DeepBench的更高复杂性。研究还构建了LLM生成DL代码的错误分类，并分析了不同类别间的性能差异（如任务间高达37%的差距），为改进LLMs在DL领域的代码生成提供了宝贵洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18726v1",
      "published_date": "2025-02-26 00:43:50 UTC",
      "updated_date": "2025-02-26 00:43:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:33:57.123324"
    },
    {
      "arxiv_id": "2502.18725v1",
      "title": "Talking to the brain: Using Large Language Models as Proxies to Model Brain Semantic Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Liu",
        "Ziyue Zhang",
        "Jingxin Nie"
      ],
      "abstract": "Traditional psychological experiments utilizing naturalistic stimuli face\nchallenges in manual annotation and ecological validity. To address this, we\nintroduce a novel paradigm leveraging multimodal large language models (LLMs)\nas proxies to extract rich semantic information from naturalistic images\nthrough a Visual Question Answering (VQA) strategy for analyzing human visual\nsemantic representation. LLM-derived representations successfully predict\nestablished neural activity patterns measured by fMRI (e.g., faces, buildings),\nvalidating its feasibility and revealing hierarchical semantic organization\nacross cortical regions. A brain semantic network constructed from LLM-derived\nrepresentations identifies meaningful clusters reflecting functional and\ncontextual associations. This innovative methodology offers a powerful solution\nfor investigating brain semantic organization with naturalistic stimuli,\novercoming limitations of traditional annotation methods and paving the way for\nmore ecologically valid explorations of human cognition.",
      "tldr_zh": "这篇论文提出了一种新范式，使用多模态大型语言模型 (LLMs) 作为代理，通过 Visual Question Answering (VQA) 策略从自然图像中提取语义信息，以解决传统心理实验中手动标注和生态效度挑战的问题。研究发现，LLMs 派生表示能够准确预测 fMRI 测量的神经活动模式（如面部和建筑），并揭示大脑皮层区域的层次语义组织。最终，构建的脑语义网络识别出反映功能和上下文关联的集群，为使用自然刺激探索人类认知提供了更生态有效的调查方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18725v1",
      "published_date": "2025-02-26 00:40:28 UTC",
      "updated_date": "2025-02-26 00:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:34:10.067113"
    },
    {
      "arxiv_id": "2502.18712v1",
      "title": "TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Chenlu Ju",
        "Jiaxin Liu",
        "Shobhit Sinha",
        "Hao Xue",
        "Flora Salim"
      ],
      "abstract": "This work leverages Large Language Models (LLMs) to simulate human mobility,\naddressing challenges like high costs and privacy concerns in traditional\nmodels. Our hierarchical framework integrates persona generation, activity\nselection, and destination prediction, using real-world demographic and\npsychological data to create realistic movement patterns. Both physical models\nand language models are employed to explore and demonstrate different\nmethodologies for human mobility simulation. By structuring data with\nsummarization and weighted density metrics, the system ensures scalable memory\nmanagement while retaining actionable insights. Preliminary results indicate\nthat LLM-driven simulations align with observed real-world patterns, offering\nscalable, interpretable insights for social problems such as urban planning,\ntraffic management, and public health. The framework's ability to dynamically\ngenerate personas and activities enables it to provide adaptable and realistic\ndaily routines. This study demonstrates the transformative potential of LLMs in\nadvancing mobility modeling for societal and urban applications. The source\ncode and interactive demo for our framework are available at\nhttps://github.com/cju0/TrajLLM.",
      "tldr_zh": "该论文提出 TrajLLM，一种模块化的代理框架，利用 Large Language Models (LLMs) 来模拟人类移动轨迹，解决传统模型的成本高和隐私问题。框架采用分层设计，包括 persona generation、activity selection 和 destination prediction，并整合真实世界的 demographic 和 psychological data，以生成逼真的移动模式。研究结合 physical models 和 language models，通过 summarization 和 weighted density metrics 实现可扩展的内存管理。初步结果显示，TrajLLM 的模拟结果与真实世界模式高度一致，为城市规划、交通管理和公共健康等社会应用提供可扩展、可解释的洞见。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted WWW2025 Demo Paper",
      "pdf_url": "http://arxiv.org/pdf/2502.18712v1",
      "published_date": "2025-02-26 00:13:26 UTC",
      "updated_date": "2025-02-26 00:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:34:24.069550"
    },
    {
      "arxiv_id": "2502.18710v1",
      "title": "Bridging Critical Gaps in Convergent Learning: How Representational Alignment Evolves Across Layers, Training, and Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Chaitanya Kapoor",
        "Sudhanshu Srivastava",
        "Meenakshi Khosla"
      ],
      "abstract": "Understanding convergent learning -- the extent to which artificial and\nbiological neural networks develop similar representations -- is crucial for\nneuroscience and AI, as it reveals shared learning principles and guides\nbrain-like model design. While several studies have noted convergence in early\nand late layers of vision networks, key gaps remain. First, much existing work\nrelies on a limited set of metrics, overlooking transformation invariances\nrequired for proper alignment. We compare three metrics that ignore specific\nirrelevant transformations: linear regression (ignoring affine\ntransformations), Procrustes (ignoring rotations and reflections), and\npermutation/soft-matching (ignoring unit order). Notably, orthogonal\ntransformations align representations nearly as effectively as more flexible\nlinear ones, and although permutation scores are lower, they significantly\nexceed chance, indicating a robust representational basis. A second critical\ngap lies in understanding when alignment emerges during training. Contrary to\nexpectations that convergence builds gradually with task-specific learning, our\nfindings reveal that nearly all convergence occurs within the first epoch --\nlong before networks achieve optimal performance. This suggests that shared\ninput statistics, architectural biases, or early training dynamics drive\nconvergence rather than the final task solution. Finally, prior studies have\nnot systematically examined how changes in input statistics affect alignment.\nOur work shows that out-of-distribution (OOD) inputs consistently amplify\ndifferences in later layers, while early layers remain aligned for both\nin-distribution and OOD inputs, suggesting that this alignment is driven by\ngeneralizable features stable across distribution shifts. These findings fill\ncritical gaps in our understanding of representational convergence, with\nimplications for neuroscience and AI.",
      "tldr_zh": "该研究探讨了人工神经网络和生物神经网络在表示上的收敛（convergent learning），旨在填补关键空白，包括指标选择、训练动态和分布偏移的影响。研究者比较了线性回归、Procrustes 和 permutation/soft-matching 等指标，发现正交变换就能有效对齐表示，且 permutation 得分显著高于随机水平。关键发现是，representational alignment 主要在训练的第一个 epoch 内完成，而非逐渐积累，且早期层对 in-distribution 和 out-of-distribution (OOD) 输入保持稳定，而晚期层在 OOD 输入下差异放大。这些结果揭示了共享输入统计和架构偏差的作用，为神经科学和 AI 模型设计提供了重要启发。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18710v1",
      "published_date": "2025-02-26 00:04:24 UTC",
      "updated_date": "2025-02-26 00:04:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T19:34:35.066013"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 162,
  "processed_papers_count": 162,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T19:34:54.810422"
}