[
  {
    "arxiv_id": "2412.17189v1",
    "title": "Better Think with Tables: Leveraging Tables to Enhance Large Language Model Comprehension",
    "authors": [
      "Jio Oh",
      "Geon Heo",
      "Seungjun Oh",
      "Jindong Wang",
      "Xing Xie",
      "Steven Euijong Whang"
    ],
    "abstract": "Despite the recent advancement of Large Langauge Models (LLMs), they struggle\nwith complex queries often involving multiple conditions, common in real-world\nscenarios. We propose Thinking with Tables, a technique that assists LLMs to\nleverage tables for intermediate thinking aligning with human cognitive\nbehavior. By introducing a pre-instruction that triggers an LLM to organize\ninformation in tables, our approach achieves a 40.29\\% average relative\nperformance increase, higher robustness, and show generalizability to different\nrequests, conditions, or scenarios. We additionally show the influence of data\nstructuredness for the model by comparing results from four distinct\nstructuring levels that we introduce.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17189v1",
    "published_date": "2024-12-22 23:31:03 UTC",
    "updated_date": "2024-12-22 23:31:03 UTC"
  },
  {
    "arxiv_id": "2412.17188v1",
    "title": "Hierarchically Gated Experts for Efficient Online Continual Learning",
    "authors": [
      "Kevin Luong",
      "Michael Thielscher"
    ],
    "abstract": "Continual Learning models aim to learn a set of tasks under the constraint\nthat the tasks arrive sequentially with no way to access data from previous\ntasks. The Online Continual Learning framework poses a further challenge where\nthe tasks are unknown and instead the data arrives as a single stream. Building\non existing work, we propose a method for identifying these underlying tasks:\nthe Gated Experts (GE) algorithm, where a dynamically growing set of experts\nallows for new knowledge to be acquired without catastrophic forgetting.\nFurthermore, we extend GE to Hierarchically Gated Experts (HGE), a method which\nis able to efficiently select the best expert for each data sample by\norganising the experts into a hierarchical structure. On standard Continual\nLearning benchmarks, GE and HGE are able to achieve results comparable with\ncurrent methods, with HGE doing so more efficiently.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17188v1",
    "published_date": "2024-12-22 23:27:20 UTC",
    "updated_date": "2024-12-22 23:27:20 UTC"
  },
  {
    "arxiv_id": "2412.17180v1",
    "title": "COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations",
    "authors": [
      "Vanessa Su",
      "Nirmalya Thakur"
    ],
    "abstract": "This study presents a data-driven analysis of COVID-19 discourse on YouTube,\nexamining the sentiment, toxicity, and thematic patterns of video content\npublished between January 2023 and October 2024. The analysis involved applying\nadvanced natural language processing (NLP) techniques: sentiment analysis with\nVADER, toxicity detection with Detoxify, and topic modeling using Latent\nDirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of\nvideo descriptions were positive, 36.63% were neutral, and 14.05% were\nnegative, indicating a generally informative and supportive tone in\npandemic-related content. Toxicity analysis identified only 0.91% of content as\ntoxic, suggesting minimal exposure to toxic content. Topic modeling revealed\ntwo main themes, with 66.74% of the videos covering general health information\nand pandemic-related impacts and 33.26% focused on news and real-time updates,\nhighlighting the dual informational role of YouTube. A recommendation system\nwas also developed using TF-IDF vectorization and cosine similarity, refined by\nsentiment, toxicity, and topic filters to ensure relevant and context-aligned\nvideo recommendations. This system achieved 69% aggregate coverage, with\nmonthly coverage rates consistently above 85%, demonstrating robust performance\nand adaptability over time. Evaluation across recommendation sizes showed\ncoverage reaching 69% for five video recommendations and 79% for ten video\nrecommendations per video. In summary, this work presents a framework for\nunderstanding COVID-19 discourse on YouTube and a recommendation system that\nsupports user engagement while promoting responsible and relevant content\nrelated to COVID-19.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17180v1",
    "published_date": "2024-12-22 22:43:36 UTC",
    "updated_date": "2024-12-22 22:43:36 UTC"
  },
  {
    "arxiv_id": "2412.17175v1",
    "title": "DCC: Differentiable Cardinality Constraints for Partial Index Tracking",
    "authors": [
      "Wooyeon Jo",
      "Hyunsouk Cho"
    ],
    "abstract": "Index tracking is a popular passive investment strategy aimed at optimizing\nportfolios, but fully replicating an index can lead to high transaction costs.\nTo address this, partial replication have been proposed. However, the\ncardinality constraint renders the problem non-convex, non-differentiable, and\noften NP-hard, leading to the use of heuristic or neural network-based methods,\nwhich can be non-interpretable or have NP-hard complexity. To overcome these\nlimitations, we propose a Differentiable Cardinality Constraint\n($\\textbf{DCC}$) for index tracking and introduce a floating-point\nprecision-aware method ($\\textbf{DCC}_{fpp}$) to address implementation issues.\nWe theoretically prove our methods calculate cardinality accurately and enforce\nactual cardinality with polynomial time complexity. We propose the range of the\nhyperparameter $a$ ensures that $\\textbf{DCC}_{fpp}$ has no error in real\nimplementations, based on theoretical proof and experiment. Our method applied\nto mathematical method outperforms baseline methods across various datasets,\ndemonstrating the effectiveness of the identified hyperparameter $a$.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures, AAAI 2025 (accepted, but not published)",
    "pdf_url": "http://arxiv.org/pdf/2412.17175v1",
    "published_date": "2024-12-22 22:05:56 UTC",
    "updated_date": "2024-12-22 22:05:56 UTC"
  },
  {
    "arxiv_id": "2412.17165v1",
    "title": "Survey on Abstractive Text Summarization: Dataset, Models, and Metrics",
    "authors": [
      "Gospel Ozioma Nnadi",
      "Flavio Bertini"
    ],
    "abstract": "The advancements in deep learning, particularly the introduction of\ntransformers, have been pivotal in enhancing various natural language\nprocessing (NLP) tasks. These include text-to-text applications such as machine\ntranslation, text classification, and text summarization, as well as\ndata-to-text tasks like response generation and image-to-text tasks such as\ncaptioning. Transformer models are distinguished by their attention mechanisms,\npretraining on general knowledge, and fine-tuning for downstream tasks. This\nhas led to significant improvements, particularly in abstractive summarization,\nwhere sections of a source document are paraphrased to produce summaries that\nclosely resemble human expression.\n  The effectiveness of these models is assessed using diverse metrics,\nencompassing techniques like semantic overlap and factual correctness. This\nsurvey examines the state of the art in text summarization models, with a\nspecific focus on the abstractive summarization approach. It reviews various\ndatasets and evaluation metrics used to measure model performance.\nAdditionally, it includes the results of test cases using abstractive\nsummarization models to underscore the advantages and limitations of\ncontemporary transformer-based models. The source codes and the data are\navailable at https://github.com/gospelnnadi/Text-Summarization-SOTA-Experiment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17165v1",
    "published_date": "2024-12-22 21:18:40 UTC",
    "updated_date": "2024-12-22 21:18:40 UTC"
  },
  {
    "arxiv_id": "2412.17159v1",
    "title": "Semantic Web: Past, Present, and Future",
    "authors": [
      "Ansgar Scherp",
      "Gerd Groener",
      "Petr Škoda",
      "Katja Hose",
      "Maria-Esther Vidal"
    ],
    "abstract": "Ever since the vision was formulated, the Semantic Web has inspired many\ngenerations of innovations. Semantic technologies have been used to share vast\namounts of information on the Web, enhance them with semantics to give them\nmeaning, and enable inference and reasoning on them. Throughout the years,\nsemantic technologies, and in particular knowledge graphs, have been used in\nsearch engines, data integration, enterprise settings, and machine learning.\n  In this paper, we recap the classical concepts and foundations of the\nSemantic Web as well as modern and recent concepts and applications, building\nupon these foundations. The classical topics we cover include knowledge\nrepresentation, creating and validating knowledge on the Web, reasoning and\nlinking, and distributed querying. We enhance this classical view of the\nso-called ``Semantic Web Layer Cake'' with an update of recent concepts that\ninclude provenance, security and trust, as well as a discussion of practical\nimpacts from industry-led contributions. We conclude with an outlook on the\nfuture directions of the Semantic Web.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended Version 2024-12-13 of TGDK 2(1): 3:1-3:37 (2024) If you like\n  to contribute, please contact the first author and visit:\n  https://github.com/ascherp/semantic-web-primer Please cite this paper as, see\n  https://dblp.org/rec/journals/tgdk/ScherpG0HV24.html?view=bibtex",
    "pdf_url": "http://arxiv.org/pdf/2412.17159v1",
    "published_date": "2024-12-22 20:58:14 UTC",
    "updated_date": "2024-12-22 20:58:14 UTC"
  },
  {
    "arxiv_id": "2501.14753v1",
    "title": "ABACUS: A FinOps Service for Cloud Cost Optimization",
    "authors": [
      "Saurabh Deochake"
    ],
    "abstract": "In recent years, as more enterprises have moved their infrastructure to the\ncloud, significant challenges have emerged in achieving holistic cloud spend\nvisibility and cost optimization. FinOps practices provide a way for\nenterprises to achieve these business goals by optimizing cloud costs and\nbringing accountability to cloud spend. This paper presents ABACUS - Automated\nBudget Analysis and Cloud Usage Surveillance, a FinOps solution for optimizing\ncloud costs by setting budgets, enforcing those budgets through blocking new\ndeployments, and alerting appropriate teams if spending breaches a budget\nthreshold. ABACUS also leverages best practices like Infrastructure-as-Code to\nalert engineering teams of the expected cost of deployment before resources are\ndeployed in the cloud. Finally, future research directions are proposed to\nadvance the state of the art in this important field.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI",
      "cs.SE",
      "K.6; C.2.4; D.2.9; D.2.11; I.2.11"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14753v1",
    "published_date": "2024-12-22 20:26:54 UTC",
    "updated_date": "2024-12-22 20:26:54 UTC"
  },
  {
    "arxiv_id": "2412.17149v1",
    "title": "A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops",
    "authors": [
      "Kamer Ali Yuksel",
      "Hassan Sawaf"
    ],
    "abstract": "Agentic AI systems use specialized agents to handle tasks within complex\nworkflows, enabling automation and efficiency. However, optimizing these\nsystems often requires labor-intensive, manual adjustments to refine roles,\ntasks, and interactions. This paper introduces a framework for autonomously\noptimizing Agentic AI solutions across industries, such as NLP-driven\nenterprise applications. The system employs agents for Refinement, Execution,\nEvaluation, Modification, and Documentation, leveraging iterative feedback\nloops powered by an LLM (Llama 3.2-3B). The framework achieves optimal\nperformance without human input by autonomously generating and testing\nhypotheses to improve system configurations. This approach enhances scalability\nand adaptability, offering a robust solution for real-world applications in\ndynamic environments. Case studies across diverse domains illustrate the\ntransformative impact of this framework, showcasing significant improvements in\noutput quality, relevance, and actionability. All data for these case studies,\nincluding original and evolved agent codes, along with their outputs, are here:\nhttps://anonymous.4open.science/r/evolver-1D11/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17149v1",
    "published_date": "2024-12-22 20:08:04 UTC",
    "updated_date": "2024-12-22 20:08:04 UTC"
  },
  {
    "arxiv_id": "2412.17146v1",
    "title": "LLM Agent for Fire Dynamics Simulations",
    "authors": [
      "Leidong Xu",
      "Danyal Mohaddes",
      "Yi Wang"
    ],
    "abstract": "Significant advances have been achieved in leveraging foundation models, such\nas large language models (LLMs), to accelerate complex scientific workflows. In\nthis work we introduce FoamPilot, a proof-of-concept LLM agent designed to\nenhance the usability of FireFOAM, a specialized solver for fire dynamics and\nfire suppression simulations built using OpenFOAM, a popular open-source\ntoolbox for computational fluid dynamics (CFD). FoamPilot provides three core\nfunctionalities: code insight, case configuration and simulation evaluation.\nCode insight is an alternative to traditional keyword searching leveraging\nretrieval-augmented generation (RAG) and aims to enable efficient navigation\nand summarization of the FireFOAM source code for developers and experienced\nusers. For case configuration, the agent interprets user requests in natural\nlanguage and aims to modify existing simulation setups accordingly to support\nintermediate users. FoamPilot's job execution functionality seeks to manage the\nsubmission and execution of simulations in high-performance computing (HPC)\nenvironments and provide preliminary analysis of simulation results to support\nless experienced users. Promising results were achieved for each functionality,\nparticularly for simple tasks, and opportunities were identified for\nsignificant further improvement for more complex tasks. The integration of\nthese functionalities into a single LLM agent is a step aimed at accelerating\nthe simulation workflow for engineers and scientists employing FireFOAM for\ncomplex simulations critical for improving fire safety.",
    "categories": [
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Foundation Models for Science Workshop (38th Conference\n  on Neural Information Processing Systems). 12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17146v1",
    "published_date": "2024-12-22 20:03:35 UTC",
    "updated_date": "2024-12-22 20:03:35 UTC"
  },
  {
    "arxiv_id": "2412.17143v4",
    "title": "ASP-based Multi-shot Reasoning via DLV2 with Incremental Grounding",
    "authors": [
      "Francesco Calimeri",
      "Giovambattista Ianni",
      "Francesco Pacenza",
      "Simona Perri",
      "Jessica Zangari"
    ],
    "abstract": "DLV2 is an AI tool for Knowledge Representation and Reasoning which supports\nAnswer Set Programming (ASP) - a logic-based declarative formalism,\nsuccessfully used in both academic and industrial applications. Given a logic\nprogram modelling a computational problem, an execution of DLV2 produces the\nso-called answer sets that correspond one-to-one to the solutions to the\nproblem at hand. The computational process of DLV2 relies on the typical Ground\n& Solve approach where the grounding step transforms the input program into a\nnew, equivalent ground program, and the subsequent solving step applies\npropositional algorithms to search for the answer sets. Recently, emerging\napplications in contexts such as stream reasoning and event processing created\na demand for multi-shot reasoning: here, the system is expected to be reactive\nwhile repeatedly executed over rapidly changing data. In this work, we present\na new incremental reasoner obtained from the evolution of DLV2 towards iterated\nreasoning. Rather than restarting the computation from scratch, the system\nremains alive across repeated shots, and it incrementally handles the internal\ngrounding process. At each shot, the system reuses previous computations for\nbuilding and maintaining a large, more general ground program, from which a\nsmaller yet equivalent portion is determined and used for computing answer\nsets. Notably, the incremental process is performed in a completely transparent\nfashion for the user. We describe the system, its usage, its applicability and\nperformance in some practically relevant domains. Under consideration in Theory\nand Practice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI",
      "68T30",
      "I.2.1; I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2412.17143v4",
    "published_date": "2024-12-22 19:46:49 UTC",
    "updated_date": "2025-04-01 16:43:40 UTC"
  },
  {
    "arxiv_id": "2412.17142v1",
    "title": "AI-Based Teat Shape and Skin Condition Prediction for Dairy Management",
    "authors": [
      "Yuexing Hao",
      "Tiancheng Yuan",
      "Yuting Yang",
      "Aarushi Gupta",
      "Matthias Wieland",
      "Ken Birman",
      "Parminder S. Basran"
    ],
    "abstract": "Dairy owners spend significant effort to keep their animals healthy. There is\ngood reason to hope that technologies such as computer vision and artificial\nintelligence (AI) could reduce these costs, yet obstacles arise when adapting\nadvanced tools to farming environments. In this work, we adapt AI tools to\ndairy cow teat localization, teat shape, and teat skin condition\nclassifications. We also curate a data collection and analysis methodology for\na Machine Learning (ML) pipeline. The resulting teat shape prediction model\nachieves a mean Average Precision (mAP) of 0.783, and the teat skin condition\nmodel achieves a mean average precision of 0.828. Our work leverages existing\nML vision models to facilitate the individualized identification of teat health\nand skin conditions, applying AI to the dairy management industry.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17142v1",
    "published_date": "2024-12-22 19:37:07 UTC",
    "updated_date": "2024-12-22 19:37:07 UTC"
  },
  {
    "arxiv_id": "2412.17114v3",
    "title": "Decentralized Governance of Autonomous AI Agents",
    "authors": [
      "Tomer Jordi Chaffer",
      "Charles von Goins II",
      "Bayo Okusanya",
      "Dontrail Cotlage",
      "Justin Goldston"
    ],
    "abstract": "Autonomous AI agents present transformative opportunities and significant\ngovernance challenges. Existing frameworks, such as the EU AI Act and the NIST\nAI Risk Management Framework, fall short of addressing the complexities of\nthese agents, which are capable of independent decision-making, learning, and\nadaptation. To bridge these gaps, we propose the ETHOS (Ethical Technology and\nHolistic Oversight System) framework, a decentralized governance (DeGov) model\nleveraging Web3 technologies, including blockchain, smart contracts, and\ndecentralized autonomous organizations (DAOs). ETHOS establishes a global\nregistry for AI agents, enabling dynamic risk classification, proportional\noversight, and automated compliance monitoring through tools like soulbound\ntokens and zero-knowledge proofs. Furthermore, the framework incorporates\ndecentralized justice systems for transparent dispute resolution and introduces\nAI specific legal entities to manage limited liability, supported by mandatory\ninsurance to ensure financial accountability and incentivize ethical design. By\nintegrating philosophical principles of rationality, ethical grounding, and\ngoal alignment, ETHOS aims to create a robust research agenda for promoting\ntrust, transparency, and participatory governance. This innovative framework\noffers a scalable and inclusive strategy for regulating AI agents, balancing\ninnovation with ethical responsibility to meet the demands of an AI-driven\nfuture.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17114v3",
    "published_date": "2024-12-22 18:01:49 UTC",
    "updated_date": "2025-01-11 16:14:10 UTC"
  },
  {
    "arxiv_id": "2412.17107v3",
    "title": "Grams: Gradient Descent with Adaptive Momentum Scaling",
    "authors": [
      "Yang Cao",
      "Xiaoyu Li",
      "Zhao Song"
    ],
    "abstract": "We introduce $\\mathbf{G}$radient Descent with $\\mathbf{A}$daptive\n$\\mathbf{M}$omentum $\\mathbf{S}$caling ($\\mathbf{Grams}$), a novel optimization\nalgorithm that decouples the direction and magnitude of parameter updates in\ndeep learning. Unlike traditional optimizers that directly integrate momentum\ninto updates, Grams separates the update direction, derived from current\ngradients, from momentum, which is used solely for adaptive magnitude scaling.\nThis approach enables Grams to achieve improved loss descent compared to\nstate-of-the-art cautious and momentum-based optimizers. We theoretically\ndemonstrate that Grams descents faster than other state-of-the-art optimizers\nand establish a global convergence guarantee for Grams. We also validate its\neffectiveness through extensive empirical evaluations. The results demonstrate\nGrams' superior performance, including faster convergence and better\ngeneralization, compared to widely-used optimizers such as Adam, Lion, and\ntheir cautious variants. Our results highlight Grams' potential as a\ntransformative approach for efficiently training and fine-tuning large language\nmodels. Code is available at https://github.com/Gunale0926/Grams.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "SCOPE Workshop @ ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17107v3",
    "published_date": "2024-12-22 17:39:32 UTC",
    "updated_date": "2025-03-05 07:29:42 UTC"
  },
  {
    "arxiv_id": "2412.17094v2",
    "title": "Analysis on LLMs Performance for Code Summarization",
    "authors": [
      "Md. Ahnaf Akib",
      "Md. Muktadir Mazumder",
      "Salman Ahsan"
    ],
    "abstract": "Code summarization aims to generate concise natural language descriptions for\nsource code. Deep learning has been used more and more recently in software\nengineering, particularly for tasks like code creation and summarization.\nSpecifically, it appears that the most current Large Language Models with\ncoding perform well on these tasks. Large Language Models (LLMs) have\nsignificantly advanced the field of code summarization, providing sophisticated\nmethods for generating concise and accurate summaries of source code. This\nstudy aims to perform a comparative analysis of several open-source LLMs,\nnamely LLaMA-3, Phi-3, Mistral, and Gemma. These models' performance is\nassessed using important metrics such as BLEU\\textsubscript{3.1} and\nROUGE\\textsubscript{3.2}.\n  Through this analysis, we seek to identify the strengths and weaknesses of\neach model, offering insights into their applicability and effectiveness in\ncode summarization tasks. Our findings contribute to the ongoing development\nand refinement of LLMs, supporting their integration into tools that enhance\nsoftware development and maintenance processes.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17094v2",
    "published_date": "2024-12-22 17:09:34 UTC",
    "updated_date": "2025-01-24 08:46:41 UTC"
  },
  {
    "arxiv_id": "2412.17092v1",
    "title": "SAIL: Sample-Centric In-Context Learning for Document Information Extraction",
    "authors": [
      "Jinyu Zhang",
      "Zhiyuan You",
      "Jize Wang",
      "Xinyi Le"
    ],
    "abstract": "Document Information Extraction (DIE) aims to extract structured information\nfrom Visually Rich Documents (VRDs). Previous full-training approaches have\ndemonstrated strong performance but may struggle with generalization to unseen\ndata. In contrast, training-free methods leverage powerful pre-trained models\nlike Large Language Models (LLMs) to address various downstream tasks with only\na few examples. Nonetheless, training-free methods for DIE encounter two\nprimary challenges: (1) understanding the complex relationship between layout\nand textual elements in VRDs, and (2) providing accurate guidance to\npre-trained models. To address these challenges, we propose Sample-centric\nIn-context Learning (SAIL) for DIE. SAIL introduces a fine-grained entity-level\ntextual similarity to facilitate in-depth text analysis by LLMs and\nincorporates layout similarity to enhance the analysis of layouts in VRDs.\nAdditionally, SAIL formulates a unified In-Context Learning (ICL) prompt\ntemplate for various sample-centric examples, enabling tailored prompts that\ndeliver precise guidance to pre-trained models for each sample. Extensive\nexperiments on FUNSD, CORD, and SROIE benchmarks with various base models\n(e.g., LLMs) indicate that our method outperforms training-free baselines, even\ncloser to the full-training methods. The results show the superiority and\ngeneralization of our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17092v1",
    "published_date": "2024-12-22 16:58:59 UTC",
    "updated_date": "2024-12-22 16:58:59 UTC"
  },
  {
    "arxiv_id": "2412.17080v4",
    "title": "Aligning Graphical and Functional Causal Abstractions",
    "authors": [
      "Willem Schooltink",
      "Fabio Massimo Zennaro"
    ],
    "abstract": "Causal abstractions allow us to relate causal models on different levels of\ngranularity. To ensure that the models agree on cause and effect, frameworks\nfor causal abstractions define notions of consistency. Two distinct methods for\ncausal abstraction are common in the literature: (i) graphical abstractions,\nsuch as Cluster DAGs, which relate models on a structural level, and (ii)\nfunctional abstractions, like $\\alpha$-abstractions, which relate models by\nmaps between variables and their ranges. In this paper we will align the\nnotions of graphical and functional consistency and show an equivalence between\nthe class of Cluster DAGs, consistent $\\alpha$-abstractions with the range of\nabstracted variables mapped bijectively, and constructive $\\tau$-abstractions.\nFurthermore, we extend this alignment and the expressivity of graphical\nabstractions by introducing Partial Cluster DAGs. Our results provide a\nrigorous bridge between the functional and graphical frameworks and allow for\nadoption and transfer of results between them.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17080v4",
    "published_date": "2024-12-22 16:11:25 UTC",
    "updated_date": "2025-03-14 10:11:04 UTC"
  },
  {
    "arxiv_id": "2412.17077v1",
    "title": "SubstationAI: Multimodal Large Model-Based Approaches for Analyzing Substation Equipment Faults",
    "authors": [
      "Jinzhi Wang",
      "Qinfeng Song",
      "Lidong Qian",
      "Haozhou Li",
      "Qinke Peng",
      "Jiangbo Zhang"
    ],
    "abstract": "The reliability of substation equipment is crucial to the stability of power\nsystems, but traditional fault analysis methods heavily rely on manual\nexpertise, limiting their effectiveness in handling complex and large-scale\ndata. This paper proposes a substation equipment fault analysis method based on\na multimodal large language model (MLLM). We developed a database containing\n40,000 entries, including images, defect labels, and analysis reports, and used\nan image-to-video generation model for data augmentation. Detailed fault\nanalysis reports were generated using GPT-4. Based on this database, we\ndeveloped SubstationAI, the first model dedicated to substation fault analysis,\nand designed a fault diagnosis knowledge base along with knowledge enhancement\nmethods. Experimental results show that SubstationAI significantly outperforms\nexisting models, such as GPT-4, across various evaluation metrics,\ndemonstrating higher accuracy and practicality in fault cause analysis, repair\nsuggestions, and preventive measures, providing a more advanced solution for\nsubstation equipment fault analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17077v1",
    "published_date": "2024-12-22 15:59:07 UTC",
    "updated_date": "2024-12-22 15:59:07 UTC"
  },
  {
    "arxiv_id": "2412.17069v1",
    "title": "Optimizing Data Curation through Spectral Analysis and Joint Batch Selection (SALN)",
    "authors": [
      "Mohammadreza Sharifi"
    ],
    "abstract": "In modern deep learning models, long training times and large datasets\npresent significant challenges to both efficiency and scalability. Effective\ndata curation and sample selection are crucial for optimizing the training\nprocess of deep neural networks. This paper introduces SALN, a method designed\nto prioritize and select samples within each batch rather than from the entire\ndataset. By utilizing jointly selected batches, SALN enhances training\nefficiency compared to independent batch selection. The proposed method applies\na spectral analysis-based heuristic to identify the most informative data\npoints within each batch, improving both training speed and accuracy. The SALN\nalgorithm significantly reduces training time and enhances accuracy when\ncompared to traditional batch prioritization or standard training procedures.\nIt demonstrates up to an 8x reduction in training time and up to a 5\\% increase\nin accuracy over standard training methods. Moreover, SALN achieves better\nperformance and shorter training times compared to Google's JEST method\ndeveloped by DeepMind.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was presented at Machine Learning Knowledge Discovery\n  (MLKD2024) conference at Amirkabir University of Technology",
    "pdf_url": "http://arxiv.org/pdf/2412.17069v1",
    "published_date": "2024-12-22 15:38:36 UTC",
    "updated_date": "2024-12-22 15:38:36 UTC"
  },
  {
    "arxiv_id": "2412.17053v1",
    "title": "DR-Encoder: Encode Low-rank Gradients with Random Prior for Large Language Models Differentially Privately",
    "authors": [
      "Huiwen Wu",
      "Deyi Zhang",
      "Xiaohan Li",
      "Xiaogang Xu",
      "Jiafei Wu",
      "Zhe Liu"
    ],
    "abstract": "The emergence of the Large Language Model (LLM) has shown their superiority\nin a wide range of disciplines, including language understanding and\ntranslation, relational logic reasoning, and even partial differential\nequations solving. The transformer is the pervasive backbone architecture for\nthe foundation model construction. It is vital to research how to adjust the\nTransformer architecture to achieve an end-to-end privacy guarantee in LLM\nfine-tuning. In this paper, we investigate three potential information leakage\nduring a federated fine-tuning procedure for LLM (FedLLM). Based on the\npotential information leakage, we provide an end-to-end privacy guarantee\nsolution for FedLLM by inserting two-stage randomness. The first stage is to\ntrain a gradient auto-encoder with a Gaussian random prior based on the\nstatistical information of the gradients generated by local clients. The second\nstage is to fine-tune the overall LLM with a differential privacy guarantee by\nadopting appropriate Gaussian noises. We show the efficiency and accuracy gains\nof our proposed method with several foundation models and two popular\nevaluation benchmarks. Furthermore, we present a comprehensive privacy analysis\nwith Gaussian Differential Privacy (GDP) and Renyi Differential Privacy (RDP).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17053v1",
    "published_date": "2024-12-22 15:06:09 UTC",
    "updated_date": "2024-12-22 15:06:09 UTC"
  },
  {
    "arxiv_id": "2412.17052v3",
    "title": "VilBias: A Study of Bias Detection through Linguistic and Visual Cues , presenting Annotation Strategies, Evaluation, and Key Challenges",
    "authors": [
      "Shaina Raza",
      "Caesar Saleh",
      "Emrul Hasan",
      "Franklin Ogidi",
      "Maximus Powers",
      "Veronica Chatrath",
      "Marcelo Lotif",
      "Roya Javadi",
      "Anam Zahid",
      "Vahid Reza Khazaie"
    ],
    "abstract": "The integration of Large Language Models (LLMs) and Vision-Language Models\n(VLMs) opens new avenues for addressing complex challenges in multimodal\ncontent analysis, particularly in biased news detection. This study introduces\nVLBias, a framework that leverages state-of-the-art LLMs and VLMs to detect\nlinguistic and visual biases in news content. We present a multimodal dataset\ncomprising textual content and corresponding images from diverse news sources.\nWe propose a hybrid annotation framework that combines LLM-based annotations\nwith human review to ensure high-quality labeling while reducing costs and\nenhancing scalability. Our evaluation compares the performance of\nstate-of-the-art SLMs and LLMs for both modalities (text and images) and the\nresults reveal that while SLMs are computationally efficient, LLMs demonstrate\nsuperior accuracy in identifying subtle framing and text-visual\ninconsistencies. Furthermore, empirical analysis shows that incorporating\nvisual cues alongside textual data improves bias detection accuracy by 3 to 5%.\nThis study provides a comprehensive exploration of LLMs, SLMs, and VLMs as\ntools for detecting multimodal biases in news content and highlights their\nrespective strengths, limitations, and potential for future applications",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2412.17052v3",
    "published_date": "2024-12-22 15:05:30 UTC",
    "updated_date": "2025-02-18 22:01:51 UTC"
  },
  {
    "arxiv_id": "2412.17041v2",
    "title": "An OpenMind for 3D medical vision self-supervised learning",
    "authors": [
      "Tassilo Wald",
      "Constantin Ulrich",
      "Jonathan Suprijadi",
      "Sebastian Ziegler",
      "Michal Nohel",
      "Robin Peretzke",
      "Gregor Köhler",
      "Klaus H. Maier-Hein"
    ],
    "abstract": "The field of self-supervised learning (SSL) for 3D medical images lacks\nconsistency and standardization. While many methods have been developed, it is\nimpossible to identify the current state-of-the-art, due to i) varying and\nsmall pretraining datasets, ii) varying architectures, and iii) being evaluated\non differing downstream datasets. In this paper, we bring clarity to this field\nand lay the foundation for further method advancements through three key\ncontributions: We a) publish the largest publicly available pre-training\ndataset comprising 114k 3D brain MRI volumes, enabling all practitioners to\npre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised\nlearning methods on this dataset for a state-of-the-art CNN and Transformer\narchitecture, clarifying the state of 3D SSL pre-training. Among many findings,\nwe show that pre-trained methods can exceed a strong from-scratch nnU-Net\nResEnc-L baseline. Lastly, we c) publish the code of our pre-training and\nfine-tuning frameworks and provide the pre-trained models created during the\nbenchmarking process to facilitate rapid adoption and reproduction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Pre-Print; Dataset, Benchmark and Codebase available through\n  https://github.com/MIC-DKFZ/nnssl",
    "pdf_url": "http://arxiv.org/pdf/2412.17041v2",
    "published_date": "2024-12-22 14:38:28 UTC",
    "updated_date": "2025-04-18 13:14:59 UTC"
  },
  {
    "arxiv_id": "2412.17038v3",
    "title": "ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models",
    "authors": [
      "Sipeng Shen",
      "Yunming Zhang",
      "Dengpan Ye",
      "Xiuwen Shi",
      "Long Tang",
      "Haoran Duan",
      "Jiacheng Deng",
      "Ziyi Liu"
    ],
    "abstract": "While face recognition (FR) models have brought remarkable convenience in\nface verification and identification, they also pose substantial privacy risks\nto the public. Existing facial privacy protection schemes usually adopt\nadversarial examples to disrupt face verification of FR models. However, these\nschemes often suffer from weak transferability against black-box FR models and\npermanently damage the identifiable information that cannot fulfill the\nrequirements of authorized operations such as forensics and authentication. To\naddress these limitations, we propose ErasableMask, a robust and erasable\nprivacy protection scheme against black-box FR models. Specifically, via\nrethinking the inherent relationship between surrogate FR models, ErasableMask\nintroduces a novel meta-auxiliary attack, which boosts black-box\ntransferability by learning more general features in a stable and balancing\noptimization strategy. It also offers a perturbation erasion mechanism that\nsupports the erasion of semantic perturbations in protected face without\ndegrading image quality. To further improve performance, ErasableMask employs a\ncurriculum learning strategy to mitigate optimization conflicts between\nadversarial attack and perturbation erasion. Extensive experiments on the\nCelebA-HQ and FFHQ datasets demonstrate that ErasableMask achieves the\nstate-of-the-art performance in transferability, achieving over 72% confidence\non average in commercial FR systems. Moreover, ErasableMask also exhibits\noutstanding perturbation erasion performance, achieving over 90% erasion\nsuccess rate.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17038v3",
    "published_date": "2024-12-22 14:30:26 UTC",
    "updated_date": "2024-12-29 19:06:48 UTC"
  },
  {
    "arxiv_id": "2412.17031v1",
    "title": "A Reality Check on Context Utilisation for Retrieval-Augmented Generation",
    "authors": [
      "Lovisa Hagström",
      "Sara Vera Marjanović",
      "Haeun Yu",
      "Arnav Arora",
      "Christina Lioma",
      "Maria Maistro",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "abstract": "Retrieval-augmented generation (RAG) helps address the limitations of the\nparametric knowledge embedded within a language model (LM). However,\ninvestigations of how LMs utilise retrieved information of varying complexity\nin real-world scenarios have been limited to synthetic contexts. We introduce\nDRUID (Dataset of Retrieved Unreliable, Insufficient and\nDifficult-to-understand contexts) with real-world queries and contexts manually\nannotated for stance. The dataset is based on the prototypical task of\nautomated claim verification, for which automated retrieval of real-world\nevidence is crucial. We compare DRUID to synthetic datasets (CounterFact,\nConflictQA) and find that artificial datasets often fail to represent the\ncomplex and diverse real-world context settings. We show that synthetic\ndatasets exaggerate context characteristics rare in real retrieved data, which\nleads to inflated context utilisation results, as measured by our novel ACU\nscore. Moreover, while previous work has mainly focused on singleton context\ncharacteristics to explain context utilisation, correlations between singleton\ncontext properties and ACU on DRUID are surprisingly small compared to other\nproperties related to context source. Overall, our work underscores the need\nfor real-world aligned context utilisation studies to represent and improve\nperformance in real-world RAG settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "43 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17031v1",
    "published_date": "2024-12-22 14:16:38 UTC",
    "updated_date": "2024-12-22 14:16:38 UTC"
  },
  {
    "arxiv_id": "2412.17029v1",
    "title": "GraphAgent: Agentic Graph Language Assistant",
    "authors": [
      "Yuhao Yang",
      "Jiabin Tang",
      "Lianghao Xia",
      "Xingchen Zou",
      "Yuxuan Liang",
      "Chao Huang"
    ],
    "abstract": "Real-world data is represented in both structured (e.g., graph connections)\nand unstructured (e.g., textual, visual information) formats, encompassing\ncomplex relationships that include explicit links (such as social connections\nand user behaviors) and implicit interdependencies among semantic entities,\noften illustrated through knowledge graphs. In this work, we propose\nGraphAgent, an automated agent pipeline that addresses both explicit graph\ndependencies and implicit graph-enhanced semantic inter-dependencies, aligning\nwith practical data scenarios for predictive tasks (e.g., node classification)\nand generative tasks (e.g., text generation). GraphAgent comprises three key\ncomponents: (i) a Graph Generator Agent that builds knowledge graphs to reflect\ncomplex semantic dependencies; (ii) a Task Planning Agent that interprets\ndiverse user queries and formulates corresponding tasks through agentic\nself-planning; and (iii) a Task Execution Agent that efficiently executes\nplanned tasks while automating tool matching and invocation in response to user\nqueries. These agents collaborate seamlessly, integrating language models with\ngraph language models to uncover intricate relational information and data\nsemantic dependencies. Through extensive experiments on various graph-related\npredictive and text generative tasks on diverse datasets, we demonstrate the\neffectiveness of our GraphAgent across various settings. We have made our\nproposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17029v1",
    "published_date": "2024-12-22 14:13:32 UTC",
    "updated_date": "2024-12-22 14:13:32 UTC"
  },
  {
    "arxiv_id": "2412.17018v1",
    "title": "GAS: Generative Auto-bidding with Post-training Search",
    "authors": [
      "Yewen Li",
      "Shuai Mao",
      "Jingtong Gao",
      "Nan Jiang",
      "Yunjian Xu",
      "Qingpeng Cai",
      "Fei Pan",
      "Peng Jiang",
      "Bo An"
    ],
    "abstract": "Auto-bidding is essential in facilitating online advertising by automatically\nplacing bids on behalf of advertisers. Generative auto-bidding, which generates\nbids based on an adjustable condition using models like transformers and\ndiffusers, has recently emerged as a new trend due to its potential to learn\noptimal strategies directly from data and adjust flexibly to preferences.\nHowever, generative models suffer from low-quality data leading to a mismatch\nbetween condition, return to go, and true action value, especially in long\nsequential decision-making. Besides, the majority preference in the dataset may\nhinder models' generalization ability on minority advertisers' preferences.\nWhile it is possible to collect high-quality data and retrain multiple models\nfor different preferences, the high cost makes it unaffordable, hindering the\nadvancement of auto-bidding into the era of large foundation models. To address\nthis, we propose a flexible and practical Generative Auto-bidding scheme using\npost-training Search, termed GAS, to refine a base policy model's output and\nadapt to various preferences. We use weak-to-strong search alignment by\ntraining small critics for different preferences and an MCTS-inspired search to\nrefine the model's output. Specifically, a novel voting mechanism with\ntransformer-based critics trained with policy indications could enhance search\nalignment performance. Additionally, utilizing the search, we provide a\nfine-tuning method for high-frequency preference scenarios considering\ncomputational efficiency. Extensive experiments conducted on the real-world\ndataset and online A/B test on the Kuaishou advertising platform demonstrate\nthe effectiveness of GAS, achieving significant improvements, e.g., 1.554%\nincrement of target cost.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17018v1",
    "published_date": "2024-12-22 13:47:46 UTC",
    "updated_date": "2024-12-22 13:47:46 UTC"
  },
  {
    "arxiv_id": "2412.17008v1",
    "title": "Data value estimation on private gradients",
    "authors": [
      "Zijian Zhou",
      "Xinyi Xu",
      "Daniela Rus",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "For gradient-based machine learning (ML) methods commonly adopted in practice\nsuch as stochastic gradient descent, the de facto differential privacy (DP)\ntechnique is perturbing the gradients with random Gaussian noise. Data\nvaluation attributes the ML performance to the training data and is widely used\nin privacy-aware applications that require enforcing DP such as data pricing,\ncollaborative ML, and federated learning (FL). Can existing data valuation\nmethods still be used when DP is enforced via gradient perturbations? We show\nthat the answer is no with the default approach of injecting i.i.d.~random\nnoise to the gradients because the estimation uncertainty of the data value\nestimation paradoxically linearly scales with more estimation budget, producing\nestimates almost like random guesses. To address this issue, we propose to\ninstead inject carefully correlated noise to provably remove the linear scaling\nof estimation uncertainty w.r.t.~the budget. We also empirically demonstrate\nthat our method gives better data value estimates on various ML tasks and is\napplicable to use cases including dataset valuation and~FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17008v1",
    "published_date": "2024-12-22 13:15:51 UTC",
    "updated_date": "2024-12-22 13:15:51 UTC"
  },
  {
    "arxiv_id": "2412.17001v1",
    "title": "Solving Nonlinear Energy Supply and Demand System Using Physics-Informed Neural Networks",
    "authors": [
      "Van Truong Vo",
      "Samad Noeiaghdam",
      "Denis Sidorov",
      "Aliona Dreglea",
      "Liguo Wang"
    ],
    "abstract": "Nonlinear differential equations and systems play a crucial role in modeling\nsystems where time-dependent factors exhibit nonlinear characteristics. Due to\ntheir nonlinear nature, solving such systems often presents significant\ndifficulties and challenges. In this study, we propose a method utilizing\nPhysics-Informed Neural Networks (PINNs) to solve the nonlinear energy\nsupply-demand (ESD) system. We design a neural network with four outputs, where\neach output approximates a function that corresponds to one of the unknown\nfunctions in the nonlinear system of differential equations describing the\nfour-dimensional ESD problem. The neural network model is then trained and the\nparameters are identified, optimized to achieve a more accurate solution. The\nsolutions obtained from the neural network for this problem are equivalent when\nwe compare and evaluate them against the Runge-Kutta numerical method of order\n4/5 (RK45). However, the method utilizing neural networks is considered a\nmodern and promising approach, as it effectively exploits the superior\ncomputational power of advanced computer systems, especially in solving complex\nproblems. Another advantage is that the neural network model, after being\ntrained, can solve the nonlinear system of differential equations across a\ncontinuous domain. In other words, neural networks are not only trained to\napproximate the solution functions for the nonlinear ESD system but can also\nrepresent the complex dynamic relationships between the system's components.\nHowever, this approach requires significant time and computational power due to\nthe need for model training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "34A34 68T07",
      "G.1.7"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to Computation J",
    "pdf_url": "http://arxiv.org/pdf/2412.17001v1",
    "published_date": "2024-12-22 12:37:59 UTC",
    "updated_date": "2024-12-22 12:37:59 UTC"
  },
  {
    "arxiv_id": "2412.16984v1",
    "title": "LLM-Powered User Simulator for Recommender System",
    "authors": [
      "Zijian Zhang",
      "Shuchang Liu",
      "Ziru Liu",
      "Rui Zhong",
      "Qingpeng Cai",
      "Xiangyu Zhao",
      "Chunxu Zhang",
      "Qidong Liu",
      "Peng Jiang"
    ],
    "abstract": "User simulators can rapidly generate a large volume of timely user behavior\ndata, providing a testing platform for reinforcement learning-based recommender\nsystems, thus accelerating their iteration and optimization. However, prevalent\nuser simulators generally suffer from significant limitations, including the\nopacity of user preference modeling and the incapability of evaluating\nsimulation accuracy. In this paper, we introduce an LLM-powered user simulator\nto simulate user engagement with items in an explicit manner, thereby enhancing\nthe efficiency and effectiveness of reinforcement learning-based recommender\nsystems training. Specifically, we identify the explicit logic of user\npreferences, leverage LLMs to analyze item characteristics and distill user\nsentiments, and design a logical model to imitate real human engagement. By\nintegrating a statistical model, we further enhance the reliability of the\nsimulation, proposing an ensemble model that synergizes logical and statistical\ninsights for user interaction simulations. Capitalizing on the extensive\nknowledge and semantic generation capabilities of LLMs, our user simulator\nfaithfully emulates user behaviors and preferences, yielding high-fidelity\ntraining data that enrich the training of recommendation algorithms. We\nestablish quantifying and qualifying experiments on five datasets to validate\nthe simulator's effectiveness and stability across various recommendation\nscenarios.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16984v1",
    "published_date": "2024-12-22 12:00:04 UTC",
    "updated_date": "2024-12-22 12:00:04 UTC"
  },
  {
    "arxiv_id": "2412.16978v1",
    "title": "PromptDresser: Improving the Quality and Controllability of Virtual Try-On via Generative Textual Prompt and Prompt-aware Mask",
    "authors": [
      "Jeongho Kim",
      "Hoiyeong Jin",
      "Sunghyun Park",
      "Jaegul Choo"
    ],
    "abstract": "Recent virtual try-on approaches have advanced by fine-tuning the pre-trained\ntext-to-image diffusion models to leverage their powerful generative ability.\nHowever, the use of text prompts in virtual try-on is still underexplored. This\npaper tackles a text-editable virtual try-on task that changes the clothing\nitem based on the provided clothing image while editing the wearing style\n(e.g., tucking style, fit) according to the text descriptions. In the\ntext-editable virtual try-on, three key aspects exist: (i) designing rich text\ndescriptions for paired person-clothing data to train the model, (ii)\naddressing the conflicts where textual information of the existing person's\nclothing interferes the generation of the new clothing, and (iii) adaptively\nadjust the inpainting mask aligned with the text descriptions, ensuring proper\nediting areas while preserving the original person's appearance irrelevant to\nthe new clothing. To address these aspects, we propose PromptDresser, a\ntext-editable virtual try-on model that leverages large multimodal model (LMM)\nassistance to enable high-quality and versatile manipulation based on\ngenerative text prompts. Our approach utilizes LMMs via in-context learning to\ngenerate detailed text descriptions for person and clothing images\nindependently, including pose details and editing attributes using minimal\nhuman cost. Moreover, to ensure the editing areas, we adjust the inpainting\nmask depending on the text prompts adaptively. We found that our approach,\nutilizing detailed text prompts, not only enhances text editability but also\neffectively conveys clothing details that are difficult to capture through\nimages alone, thereby enhancing image quality. Our code is available at\nhttps://github.com/rlawjdghek/PromptDresser.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.16978v1",
    "published_date": "2024-12-22 11:38:04 UTC",
    "updated_date": "2024-12-22 11:38:04 UTC"
  },
  {
    "arxiv_id": "2412.16976v1",
    "title": "On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora",
    "authors": [
      "Tzu-Chieh Chen",
      "Wen-Yang Lin"
    ],
    "abstract": "Named Entity Recognition has traditionally been a key task in natural\nlanguage processing, aiming to identify and extract important terms from\nunstructured text data. However, a notable challenge for contemporary\ndeep-learning NER models has been identifying discontinuous entities, which are\noften fragmented within the text. To date, methods to address Discontinuous\nNamed Entity Recognition have not been explored using ensemble learning to the\nbest of our knowledge. Furthermore, the rise of large language models, such as\nChatGPT in recent years, has shown significant effectiveness across many NLP\ntasks. Most existing approaches, however, have primarily utilized ChatGPT as a\nproblem-solving tool rather than exploring its potential as an integrative\nelement within ensemble learning algorithms. In this study, we investigated the\nintegration of ChatGPT as an arbitrator within an ensemble method, aiming to\nenhance performance on DNER tasks. Our method combines five state-of-the-art\nNER models with ChatGPT using custom prompt engineering to assess the\nrobustness and generalization capabilities of the ensemble algorithm. We\nconducted experiments on three benchmark medical datasets, comparing our method\nagainst the five SOTA models, individual applications of GPT-3.5 and GPT-4, and\na voting ensemble method. The results indicate that our proposed fusion of\nChatGPT with the ensemble learning algorithm outperforms the SOTA results in\nthe CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance\nNLP applications in the healthcare domain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.16976v1",
    "published_date": "2024-12-22 11:26:49 UTC",
    "updated_date": "2024-12-22 11:26:49 UTC"
  },
  {
    "arxiv_id": "2412.16974v1",
    "title": "Cannot or Should Not? Automatic Analysis of Refusal Composition in IFT/RLHF Datasets and Refusal Behavior of Black-Box LLMs",
    "authors": [
      "Alexander von Recum",
      "Christoph Schnabl",
      "Gabor Hollbeck",
      "Silas Alberti",
      "Philip Blinde",
      "Marvin von Hagen"
    ],
    "abstract": "Refusals - instances where large language models (LLMs) decline or fail to\nfully execute user instructions - are crucial for both AI safety and AI\ncapabilities and the reduction of hallucinations in particular. These behaviors\nare learned during post-training, especially in instruction fine-tuning (IFT)\nand reinforcement learning from human feedback (RLHF). However, existing\ntaxonomies and evaluation datasets for refusals are inadequate, often focusing\nsolely on should-not-related (instead of cannot-related) categories, and\nlacking tools for auditing refusal content in black-box LLM outputs.\n  We present a comprehensive framework for classifying LLM refusals: (a) a\ntaxonomy of 16 refusal categories, (b) a human-annotated dataset of over 8,600\ninstances from publicly available IFT and RLHF datasets, (c) a synthetic\ndataset with 8,000 examples for each refusal category, and (d) classifiers\ntrained for refusal classification.\n  Our work enables precise auditing of refusal behaviors in black-box LLMs and\nautomatic analyses of refusal patterns in large IFT and RLHF datasets. This\nfacilitates the strategic adjustment of LLM refusals, contributing to the\ndevelopment of more safe and reliable LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Workshop SFLLM",
    "pdf_url": "http://arxiv.org/pdf/2412.16974v1",
    "published_date": "2024-12-22 11:16:53 UTC",
    "updated_date": "2024-12-22 11:16:53 UTC"
  },
  {
    "arxiv_id": "2412.16970v1",
    "title": "Environment Descriptions for Usability and Generalisation in Reinforcement Learning",
    "authors": [
      "Dennis J. N. J. Soemers",
      "Spyridon Samothrakis",
      "Kurt Driessens",
      "Mark H. M. Winands"
    ],
    "abstract": "The majority of current reinforcement learning (RL) research involves\ntraining and deploying agents in environments that are implemented by engineers\nin general-purpose programming languages and more advanced frameworks such as\nCUDA or JAX. This makes the application of RL to novel problems of interest\ninaccessible to small organisations or private individuals with insufficient\nengineering expertise. This position paper argues that, to enable more\nwidespread adoption of RL, it is important for the research community to shift\nfocus towards methodologies where environments are described in user-friendly\ndomain-specific or natural languages. Aside from improving the usability of RL,\nsuch language-based environment descriptions may also provide valuable context\nand boost the ability of trained agents to generalise to unseen environments\nwithin the set of all environments that can be described in any language of\nchoice.",
    "categories": [
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICAART 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16970v1",
    "published_date": "2024-12-22 11:02:13 UTC",
    "updated_date": "2024-12-22 11:02:13 UTC"
  },
  {
    "arxiv_id": "2412.16964v2",
    "title": "System-2 Mathematical Reasoning via Enriched Instruction Tuning",
    "authors": [
      "Huanqia Cai",
      "Yijun Yang",
      "Zhifeng Li"
    ],
    "abstract": "Solving complex mathematical problems via system-2 reasoning is a natural\nhuman skill, yet it remains a significant challenge for current large language\nmodels (LLMs). We identify the scarcity of deliberate multi-step reasoning data\nas a primary limiting factor. To this end, we introduce Enriched Instruction\nTuning (EIT), a method that enriches existing human-annotated mathematical\ndatasets by synergizing human and AI feedback to create fine-grained reasoning\ntrajectories. These datasets are then used to fine-tune open-source LLMs,\nenhancing their mathematical reasoning abilities without reliance on any\nsymbolic verification program. Concretely, EIT is composed of two critical\nsteps: Enriching with Reasoning Plan (ERP) and Enriching with Reasoning Step\n(ERS). The former generates a high-level plan that breaks down complex\ninstructions into a sequence of simpler objectives, while ERS fills in\nreasoning contexts often overlooked by human annotators, creating a smoother\nreasoning trajectory for LLM fine-tuning. Unlike existing CoT prompting methods\nthat generate reasoning chains only depending on LLM's internal knowledge, our\nmethod leverages human-annotated initial answers as ``meta-knowledge'' to help\nLLMs generate more detailed and precise reasoning processes, leading to a more\ntrustworthy LLM expert for complex mathematical problems. In experiments, EIT\nachieves an accuracy of 84.1% on GSM8K and 32.5% on MATH, surpassing\nstate-of-the-art fine-tuning and prompting methods, and even matching the\nperformance of tool-augmented methods.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16964v2",
    "published_date": "2024-12-22 10:49:27 UTC",
    "updated_date": "2024-12-24 11:43:25 UTC"
  },
  {
    "arxiv_id": "2412.16936v1",
    "title": "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering",
    "authors": [
      "Zhongjian Hu",
      "Peng Yang",
      "Bing Li",
      "Fengyuan Liu"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have been used for knowledge-based\nVisual Question Answering (VQA). Despite the encouraging results of previous\nstudies, prior methods prompt LLMs to predict answers directly, neglecting\nintermediate thought processes. We argue that prior methods do not sufficiently\nactivate the capacities of LLMs. We propose a framework called PLRH that\nPrompts LLMs with Rationale Heuristics for knowledge-based VQA. The PLRH\nprompts LLMs with Chain of Thought (CoT) to generate rationale heuristics,\ni.e., intermediate thought processes, and then leverages the rationale\nheuristics to inspire LLMs to predict answers. Experiments show that our\napproach outperforms the existing baselines by more than 2.2 and 2.1 on OK-VQA\nand A-OKVQA, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16936v1",
    "published_date": "2024-12-22 09:14:35 UTC",
    "updated_date": "2024-12-22 09:14:35 UTC"
  },
  {
    "arxiv_id": "2412.16934v1",
    "title": "Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation",
    "authors": [
      "Hanrui Zhang",
      "Yu Cheng",
      "Vincent Conitzer"
    ],
    "abstract": "We study equilibrium computation with extensive-form correlation in\ntwo-player turn-taking stochastic games. Our main results are two-fold: (1) We\ngive an algorithm for computing a Stackelberg extensive-form correlated\nequilibrium (SEFCE), which runs in time polynomial in the size of the game, as\nwell as the number of bits required to encode each input number. (2) We give an\nefficient algorithm for approximately computing an optimal extensive-form\ncorrelated equilibrium (EFCE) up to machine precision, i.e., the algorithm\nachieves approximation error $\\varepsilon$ in time polynomial in the size of\nthe game, as well as $\\log(1 / \\varepsilon)$.\n  Our algorithm for SEFCE is the first polynomial-time algorithm for\nequilibrium computation with commitment in such a general class of stochastic\ngames. Existing algorithms for SEFCE typically make stronger assumptions such\nas no chance moves, and are designed for extensive-form games in the less\nsuccinct tree form. Our algorithm for approximately optimal EFCE is, to our\nknowledge, the first algorithm that achieves 3 desiderata simultaneously:\napproximate optimality, polylogarithmic dependency on the approximation error,\nand compatibility with stochastic games in the more succinct graph form.\nExisting algorithms achieve at most 2 of these desiderata, often also relying\non additional technical assumptions.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "EC 2023",
    "pdf_url": "http://arxiv.org/pdf/2412.16934v1",
    "published_date": "2024-12-22 09:12:05 UTC",
    "updated_date": "2024-12-22 09:12:05 UTC"
  },
  {
    "arxiv_id": "2412.17874v2",
    "title": "Evaluating LLM Reasoning in the Operations Research Domain with ORQA",
    "authors": [
      "Mahdi Mostajabdaveh",
      "Timothy T. Yu",
      "Samarendra Chandan Bindu Dash",
      "Rindranirina Ramamonjison",
      "Jabo Serge Byusa",
      "Giuseppe Carenini",
      "Zirui Zhou",
      "Yong Zhang"
    ],
    "abstract": "In this paper, we introduce and apply Operations Research Question Answering\n(ORQA), a new benchmark designed to assess the generalization capabilities of\nLarge Language Models (LLMs) in the specialized technical domain of Operations\nResearch (OR). This benchmark evaluates whether LLMs can emulate the knowledge\nand reasoning skills of OR experts when confronted with diverse and complex\noptimization problems. The dataset, developed by OR experts, features\nreal-world optimization problems that demand multistep reasoning to construct\ntheir mathematical models. Our evaluations of various open source LLMs, such as\nLLaMA 3.1, DeepSeek, and Mixtral, reveal their modest performance, highlighting\na gap in their ability to generalize to specialized technical domains. This\nwork contributes to the ongoing discourse on LLMs generalization capabilities,\noffering valuable insights for future research in this area. The dataset and\nevaluation code are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 10 figures. Accepted and to be published in AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2412.17874v2",
    "published_date": "2024-12-22 09:10:34 UTC",
    "updated_date": "2025-02-09 16:39:50 UTC"
  },
  {
    "arxiv_id": "2412.16933v1",
    "title": "Towards a Unified Paradigm: Integrating Recommendation Systems as a New Language in Large Models",
    "authors": [
      "Kai Zheng",
      "Qingfeng Sun",
      "Can Xu",
      "Peng Yu",
      "Qingwei Guo"
    ],
    "abstract": "This paper explores the use of Large Language Models (LLMs) for sequential\nrecommendation, which predicts users' future interactions based on their past\nbehavior. We introduce a new concept, \"Integrating Recommendation Systems as a\nNew Language in Large Models\" (RSLLM), which combines the strengths of\ntraditional recommenders and LLMs. RSLLM uses a unique prompting method that\ncombines ID-based item embeddings from conventional recommendation models with\ntextual item features. It treats users' sequential behaviors as a distinct\nlanguage and aligns the ID embeddings with the LLM's input space using a\nprojector. We also propose a two-stage LLM fine-tuning framework that refines a\npretrained LLM using a combination of two contrastive losses and a language\nmodeling loss. The LLM is first fine-tuned using text-only prompts, followed by\ntarget domain fine-tuning with unified prompts. This trains the model to\nincorporate behavioral knowledge from the traditional sequential recommender\ninto the LLM. Our empirical results validate the effectiveness of our proposed\nframework.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16933v1",
    "published_date": "2024-12-22 09:08:46 UTC",
    "updated_date": "2024-12-22 09:08:46 UTC"
  },
  {
    "arxiv_id": "2412.16926v2",
    "title": "Revisiting In-Context Learning with Long Context Language Models",
    "authors": [
      "Jinheon Baek",
      "Sun Jae Lee",
      "Prakhar Gupta",
      "Geunseob Oh",
      "Siddharth Dalmia",
      "Prateek Kolhar"
    ],
    "abstract": "In-Context Learning (ICL) is a technique by which language models make\npredictions based on examples provided in their input context. Previously,\ntheir context window size imposed a limit on the number of examples that can be\nshown, making example selection techniques crucial for identifying the\nmaximally effective set of examples. However, the recent advent of Long Context\nLanguage Models (LCLMs) has significantly increased the number of examples that\ncan be included in context, raising an important question of whether ICL\nperformance in a many-shot regime is still sensitive to the method of sample\nselection. To answer this, we revisit these approaches in the context of LCLMs\nthrough extensive experiments on 18 datasets spanning 4 tasks. Surprisingly, we\nobserve that sophisticated example selection techniques do not yield\nsignificant improvements over a simple random sample selection method. Instead,\nwe find that the advent of LCLMs has fundamentally shifted the challenge of ICL\nfrom that of selecting the most effective examples to that of collecting\nsufficient examples to fill the context window. Specifically, in certain\ndatasets, including all available examples does not fully utilize the context\nwindow; however, by augmenting the examples in context with a simple data\naugmentation approach, we substantially improve ICL performance by 5%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16926v2",
    "published_date": "2024-12-22 08:55:19 UTC",
    "updated_date": "2025-01-06 08:45:06 UTC"
  },
  {
    "arxiv_id": "2412.16925v1",
    "title": "Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index",
    "authors": [
      "Nirmalya Thakur",
      "Kesha A. Patel",
      "Audrey Poon",
      "Shuqi Cui",
      "Nazif Azizi",
      "Rishika Shah",
      "Riyan Shah"
    ],
    "abstract": "This study introduces the Community Sentiment and Engagement Index (CSEI),\ndeveloped to capture nuanced public sentiment and engagement variations on\nsocial media, particularly in response to major events related to COVID-19.\nConstructed with diverse sentiment indicators, CSEI integrates features like\nengagement, daily post count, compound sentiment, fine-grain sentiments (fear,\nsurprise, joy, sadness, anger, disgust, and neutral), readability,\noffensiveness, and domain diversity. Each component is systematically weighted\nthrough a multi-step Principal Component Analysis (PCA)-based framework,\nprioritizing features according to their variance contributions across temporal\nsentiment shifts. This approach dynamically adjusts component importance,\nenabling CSEI to precisely capture high-sensitivity shifts in public sentiment.\nThe development of CSEI showed statistically significant correlations with its\nconstituent features, underscoring internal consistency and sensitivity to\nspecific sentiment dimensions. CSEI's responsiveness was validated using a\ndataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15\nmajor events, including the WHO's declaration of COVID-19 as a pandemic, the\nfirst reported cases of COVID-19 across different countries, national\nlockdowns, vaccine developments, and crucial public health measures. Cumulative\nchanges in CSEI revealed prominent peaks and valleys aligned with these events,\nindicating significant patterns in public sentiment across different phases of\nthe pandemic. Pearson correlation analysis further confirmed a statistically\nsignificant relationship between CSEI daily fluctuations and these events (p =\n0.0428), highlighting the capacity of CSEI to infer and interpret shifts in\npublic sentiment and engagement in response to major events related to\nCOVID-19.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16925v1",
    "published_date": "2024-12-22 08:52:12 UTC",
    "updated_date": "2024-12-22 08:52:12 UTC"
  },
  {
    "arxiv_id": "2412.16922v1",
    "title": "Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs",
    "authors": [
      "Bohan Jin",
      "Qianyou Sun",
      "Lihua Chen"
    ],
    "abstract": "In the current global economy, supply chain transparency plays a pivotal role\nin ensuring this security by enabling companies to monitor supplier performance\nand fostering accountability and responsibility. Despite the advancements in\nsupply chain relationship datasets like Bloomberg and FactSet, supply chain\ntransparency remains a significant challenge in emerging economies due to\nissues such as information asymmetry and institutional gaps in regulation. This\nstudy proposes a novel approach to enhance supply chain transparency in\nemerging economies by leveraging online content and large language models\n(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates\nadvanced LLMs with web crawler technology to automatically collect and analyze\nsupply chain information. The system's effectiveness is validated through a\ncase study focusing on the semiconductor supply chain, a domain that has\nrecently gained significant attention due to supply chain risks. Our results\ndemonstrate that the proposed system provides greater applicability for\nemerging economies, such as mainland China, complementing the data gaps in\nexisting datasets. However, challenges including the accurate estimation of\nmonetary and material flows, the handling of time series data, synonyms\ndisambiguation, and mitigating biases from online contents still remains.\nFuture research should focus on addressing these issues to further enhance the\nsystem's capabilities and broaden its application to other emerging economies\nand industries.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.16922v1",
    "published_date": "2024-12-22 08:46:16 UTC",
    "updated_date": "2024-12-22 08:46:16 UTC"
  },
  {
    "arxiv_id": "2412.16915v2",
    "title": "FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation",
    "authors": [
      "Tianyun Zhong",
      "Chao Liang",
      "Jianwen Jiang",
      "Gaojie Lin",
      "Jiaqi Yang",
      "Zhou Zhao"
    ],
    "abstract": "Diffusion-based audio-driven talking avatar methods have recently gained\nattention for their high-fidelity, vivid, and expressive results. However,\ntheir slow inference speed limits practical applications. Despite the\ndevelopment of various distillation techniques for diffusion models, we found\nthat naive diffusion distillation methods do not yield satisfactory results.\nDistilled models exhibit reduced robustness with open-set input images and a\ndecreased correlation between audio and video compared to teacher models,\nundermining the advantages of diffusion models. To address this, we propose\nFADA (Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG\nDistillation). We first designed a mixed-supervised loss to leverage data of\nvarying quality and enhance the overall model capability as well as robustness.\nAdditionally, we propose a multi-CFG distillation with learnable tokens to\nutilize the correlation between audio and reference image conditions, reducing\nthe threefold inference runs caused by multi-CFG with acceptable quality\ndegradation. Extensive experiments across multiple datasets show that FADA\ngenerates vivid videos comparable to recent diffusion model-based methods while\nachieving an NFE speedup of 4.17-12.5 times. Demos are available at our webpage\nhttp://fadavatar.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025, Homepage https://fadavatar.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.16915v2",
    "published_date": "2024-12-22 08:19:22 UTC",
    "updated_date": "2025-04-04 06:07:56 UTC"
  },
  {
    "arxiv_id": "2412.16908v2",
    "title": "Map Imagination Like Blind Humans: Group Diffusion Model for Robotic Map Generation",
    "authors": [
      "Qijin Song",
      "Weibang Bai"
    ],
    "abstract": "Can robots imagine or generate maps like humans do, especially when only\nlimited information can be perceived like blind people? To address this\nchallenging task, we propose a novel group diffusion model (GDM) based\narchitecture for robots to generate point cloud maps with very limited input\ninformation.Inspired from the blind humans' natural capability of imagining or\ngenerating mental maps, the proposed method can generate maps without visual\nperception data or depth data. With additional limited super-sparse spatial\npositioning data, like the extra contact-based positioning information the\nblind individuals can obtain, the map generation quality can be improved even\nmore.Experiments on public datasets are conducted, and the results indicate\nthat our method can generate reasonable maps solely based on path data, and\nproduce even more refined maps upon incorporating exiguous LiDAR data.Compared\nto conventional mapping approaches, our novel method significantly mitigates\nsensor dependency, enabling the robots to imagine and generate elementary maps\nwithout heavy onboard sensory devices.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16908v2",
    "published_date": "2024-12-22 07:54:21 UTC",
    "updated_date": "2025-01-13 04:11:53 UTC"
  },
  {
    "arxiv_id": "2412.16905v2",
    "title": "A Backdoor Attack Scheme with Invisible Triggers Based on Model Architecture Modification",
    "authors": [
      "Yuan Ma",
      "Xu Ma",
      "Jiankang Wei",
      "Jinmeng Tang",
      "Xiaoyu Zhang",
      "Yilun Lyu",
      "Kehao Chen",
      "Jingtong Huang"
    ],
    "abstract": "Machine learning systems are vulnerable to backdoor attacks, where attackers\nmanipulate model behavior through data tampering or architectural\nmodifications. Traditional backdoor attacks involve injecting malicious samples\nwith specific triggers into the training data, causing the model to produce\ntargeted incorrect outputs in the presence of the corresponding triggers. More\nsophisticated attacks modify the model's architecture directly, embedding\nbackdoors that are harder to detect as they evade traditional data-based\ndetection methods. However, the drawback of the architectural modification\nbased backdoor attacks is that the trigger must be visible in order to activate\nthe backdoor. To further strengthen the invisibility of the backdoor attacks, a\nnovel backdoor attack method is presented in the paper. To be more specific,\nthis method embeds the backdoor within the model's architecture and has the\ncapability to generate inconspicuous and stealthy triggers. The attack is\nimplemented by modifying pre-trained models, which are then redistributed,\nthereby posing a potential threat to unsuspecting users. Comprehensive\nexperiments conducted on standard computer vision benchmarks validate the\neffectiveness of this attack and highlight the stealthiness of its triggers,\nwhich remain undetectable through both manual visual inspection and advanced\ndetection tools.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16905v2",
    "published_date": "2024-12-22 07:39:43 UTC",
    "updated_date": "2025-01-06 14:42:37 UTC"
  },
  {
    "arxiv_id": "2412.16897v2",
    "title": "MVREC: A General Few-shot Defect Classification Model Using Multi-View Region-Context",
    "authors": [
      "Shuai Lyu",
      "Rongchen Zhang",
      "Zeqi Ma",
      "Fangjian Liao",
      "Dongmei Mo",
      "Waikeung Wong"
    ],
    "abstract": "Few-shot defect multi-classification (FSDMC) is an emerging trend in quality\ncontrol within industrial manufacturing. However, current FSDMC research often\nlacks generalizability due to its focus on specific datasets. Additionally,\ndefect classification heavily relies on contextual information within images,\nand existing methods fall short of effectively extracting this information. To\naddress these challenges, we propose a general FSDMC framework called MVREC,\nwhich offers two primary advantages: (1) MVREC extracts general features for\ndefect instances by incorporating the pre-trained AlphaCLIP model. (2) It\nutilizes a region-context framework to enhance defect features by leveraging\nmask region input and multi-view context augmentation. Furthermore, Few-shot\nZip-Adapter(-F) classifiers within the model are introduced to cache the visual\nfeatures of the support set and perform few-shot classification. We also\nintroduce MVTec-FS, a new FSDMC benchmark based on MVTec AD, which includes\n1228 defect images with instance-level mask annotations and 46 defect types.\nExtensive experiments conducted on MVTec-FS and four additional datasets\ndemonstrate its effectiveness in general defect classification and its ability\nto incorporate contextual information to improve classification performance.\nCode: https://github.com/ShuaiLYU/MVREC",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16897v2",
    "published_date": "2024-12-22 07:14:45 UTC",
    "updated_date": "2025-03-30 09:19:53 UTC"
  },
  {
    "arxiv_id": "2412.16893v1",
    "title": "Preventing Non-intrusive Load Monitoring Privacy Invasion: A Precise Adversarial Attack Scheme for Networked Smart Meters",
    "authors": [
      "Jialing He",
      "Jiacheng Wang",
      "Ning Wang",
      "Shangwei Guo",
      "Liehuang Zhu",
      "Dusit Niyato",
      "Tao Xiang"
    ],
    "abstract": "Smart grid, through networked smart meters employing the non-intrusive load\nmonitoring (NILM) technique, can considerably discern the usage patterns of\nresidential appliances. However, this technique also incurs privacy leakage. To\naddress this issue, we propose an innovative scheme based on adversarial attack\nin this paper. The scheme effectively prevents NILM models from violating\nappliance-level privacy, while also ensuring accurate billing calculation for\nusers. To achieve this objective, we overcome two primary challenges. First, as\nNILM models fall under the category of time-series regression models, direct\napplication of traditional adversarial attacks designed for classification\ntasks is not feasible. To tackle this issue, we formulate a novel adversarial\nattack problem tailored specifically for NILM and providing a theoretical\nfoundation for utilizing the Jacobian of the NILM model to generate\nimperceptible perturbations. Leveraging the Jacobian, our scheme can produce\nperturbations, which effectively misleads the signal prediction of NILM models\nto safeguard users' appliance-level privacy. The second challenge pertains to\nfundamental utility requirements, where existing adversarial attack schemes\nstruggle to achieve accurate billing calculation for users. To handle this\nproblem, we introduce an additional constraint, mandating that the sum of added\nperturbations within a billing period must be precisely zero. Experimental\nvalidation on real-world power datasets REDD and UK-DALE demonstrates the\nefficacy of our proposed solutions, which can significantly amplify the\ndiscrepancy between the output of the targeted NILM model and the actual power\nsignal of appliances, and enable accurate billing at the same time.\nAdditionally, our solutions exhibit transferability, making the generated\nperturbation signal from one target model applicable to other diverse NILM\nmodels.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16893v1",
    "published_date": "2024-12-22 07:06:46 UTC",
    "updated_date": "2024-12-22 07:06:46 UTC"
  },
  {
    "arxiv_id": "2412.16882v2",
    "title": "PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health",
    "authors": [
      "Huy Vu",
      "Huy Anh Nguyen",
      "Adithya V Ganesan",
      "Swanie Juhng",
      "Oscar N. E. Kjell",
      "Joao Sedoc",
      "Margaret L. Kern",
      "Ryan L. Boyd",
      "Lyle Ungar",
      "H. Andrew Schwartz",
      "Johannes C. Eichstaedt"
    ],
    "abstract": "Artificial intelligence-based language generators are now a part of most\npeople's lives. However, by default, they tend to generate \"average\" language\nwithout reflecting the ways in which people differ. Here, we propose a\nlightweight modification to the standard language model transformer\narchitecture - \"PsychAdapter\" - that uses empirically derived trait-language\npatterns to generate natural language for specified personality, demographic,\nand mental health characteristics (with or without prompting). We applied\nPsychAdapters to modify OpenAI's GPT-2, Google's Gemma, and Meta's Llama 3 and\nfound generated text to reflect the desired traits. For example, expert raters\nevaluated PsychAdapter's generated text output and found it matched intended\ntrait levels with 87.3% average accuracy for Big Five personalities, and 96.7%\nfor depression and life satisfaction. PsychAdapter is a novel method to\nintroduce psychological behavior patterns into language models at the\nfoundation level, independent of prompting, by influencing every transformer\nlayer. This approach can create chatbots with specific personality profiles,\nclinical training tools that mirror language associated with psychological\nconditionals, and machine translations that match an authors reading or\neducation level without taking up LLM context windows. PsychAdapter also allows\nfor the exploration psychological constructs through natural language\nexpression, extending the natural language processing toolkit to study human\npsychology.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16882v2",
    "published_date": "2024-12-22 06:22:40 UTC",
    "updated_date": "2025-01-01 03:13:03 UTC"
  },
  {
    "arxiv_id": "2412.16878v1",
    "title": "Online Preference-based Reinforcement Learning with Self-augmented Feedback from Large Language Model",
    "authors": [
      "Songjun Tu",
      "Jingbo Sun",
      "Qichao Zhang",
      "Xiangyuan Lan",
      "Dongbin Zhao"
    ],
    "abstract": "Preference-based reinforcement learning (PbRL) provides a powerful paradigm\nto avoid meticulous reward engineering by learning rewards based on human\npreferences. However, real-time human feedback is hard to obtain in online\ntasks. Most work suppose there is a \"scripted teacher\" that utilizes privileged\npredefined reward to provide preference feedback. In this paper, we propose a\nRL Self-augmented Large Language Model Feedback (RL-SaLLM-F) technique that\ndoes not rely on privileged information for online PbRL. RL-SaLLM-F leverages\nthe reflective and discriminative capabilities of LLM to generate\nself-augmented trajectories and provide preference labels for reward learning.\nFirst, we identify an failure issue in LLM-based preference discrimination,\nspecifically \"query ambiguity\", in online PbRL. Then LLM is employed to provide\npreference labels and generate self-augmented imagined trajectories that better\nachieve the task goal, thereby enhancing the quality and efficiency of\nfeedback. Additionally, a double-check mechanism is introduced to mitigate\nrandomness in the preference labels, improving the reliability of LLM feedback.\nThe experiment across multiple tasks in the MetaWorld benchmark demonstrates\nthe specific contributions of each proposed module in RL-SaLLM-F, and shows\nthat self-augmented LLM feedback can effectively replace the impractical\n\"scripted teacher\" feedback. In summary, RL-SaLLM-F introduces a new direction\nof feedback acquisition in online PbRL that does not rely on any online\nprivileged information, offering an efficient and lightweight solution with\nLLM-driven feedback.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, The 24th International Conference on Autonomous Agents and\n  Multi-Agent Systems (AAMAS25)",
    "pdf_url": "http://arxiv.org/pdf/2412.16878v1",
    "published_date": "2024-12-22 06:15:25 UTC",
    "updated_date": "2024-12-22 06:15:25 UTC"
  },
  {
    "arxiv_id": "2412.16874v4",
    "title": "A Multi-modal Approach to Dysarthria Detection and Severity Assessment Using Speech and Text Information",
    "authors": [
      "Anuprabha M",
      "Krishna Gurugubelli",
      "V Kesavaraj",
      "Anil Kumar Vuppala"
    ],
    "abstract": "Automatic detection and severity assessment of dysarthria are crucial for\ndelivering targeted therapeutic interventions to patients. While most existing\nresearch focuses primarily on speech modality, this study introduces a novel\napproach that leverages both speech and text modalities. By employing\ncross-attention mechanism, our method learns the acoustic and linguistic\nsimilarities between speech and text representations. This approach assesses\nspecifically the pronunciation deviations across different severity levels,\nthereby enhancing the accuracy of dysarthric detection and severity assessment.\nAll the experiments have been performed using UA-Speech dysarthric database.\nImproved accuracies of 99.53% and 93.20% in detection, and 98.12% and 51.97%\nfor severity assessment have been achieved when speaker-dependent and\nspeaker-independent, unseen and seen words settings are used. These findings\nsuggest that by integrating text information, which provides a reference\nlinguistic knowledge, a more robust framework has been developed for dysarthric\ndetection and assessment, thereby potentially leading to more effective\ndiagnoses.",
    "categories": [
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16874v4",
    "published_date": "2024-12-22 06:08:35 UTC",
    "updated_date": "2025-04-26 13:55:14 UTC"
  },
  {
    "arxiv_id": "2412.16859v2",
    "title": "Adversarially Domain-adaptive Latent Diffusion for Unsupervised Semantic Segmentation",
    "authors": [
      "Jongmin Yu",
      "Zhongtian Sun",
      "Chen Bene Chi",
      "Jinhong Yang",
      "Shan Luo"
    ],
    "abstract": "Semantic segmentation requires extensive pixel-level annotation, motivating\nunsupervised domain adaptation (UDA) to transfer knowledge from labelled source\ndomains to unlabelled or weakly labelled target domains. One of the most\nefficient strategies involves using synthetic datasets generated within\ncontrolled virtual environments, such as video games or traffic simulators,\nwhich can automatically generate pixel-level annotations. However, even when\nsuch datasets are available, learning a well-generalised representation that\ncaptures both domains remains challenging, owing to probabilistic and geometric\ndiscrepancies between the virtual world and real-world imagery. This work\nintroduces a semantic segmentation method based on latent diffusion models,\ntermed Inter-Coder Connected Latent Diffusion (ICCLD), alongside an\nunsupervised domain adaptation approach. The model employs an inter-coder\nconnection to enhance contextual understanding and preserve fine details, while\nadversarial learning aligns latent feature distributions across domains during\nthe latent diffusion process. Experiments on GTA5, Synthia, and Cityscapes\ndemonstrate that ICCLD outperforms state-of-the-art UDA methods, achieving mIoU\nscores of 74.4 (GTA5$\\rightarrow$Cityscapes) and 67.2\n(Synthia$\\rightarrow$Cityscapes).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted from CVPR 2025 Workshop PVUW",
    "pdf_url": "http://arxiv.org/pdf/2412.16859v2",
    "published_date": "2024-12-22 04:55:41 UTC",
    "updated_date": "2025-04-07 02:01:25 UTC"
  },
  {
    "arxiv_id": "2412.19834v1",
    "title": "RoboSignature: Robust Signature and Watermarking on Network Attacks",
    "authors": [
      "Aryaman Shaan",
      "Garvit Banga",
      "Raghav Mantri"
    ],
    "abstract": "Generative models have enabled easy creation and generation of images of all\nkinds given a single prompt. However, this has also raised ethical concerns\nabout what is an actual piece of content created by humans or cameras compared\nto model-generated content like images or videos. Watermarking data generated\nby modern generative models is a popular method to provide information on the\nsource of the content. The goal is for all generated images to conceal an\ninvisible watermark, allowing for future detection or identification. The\nStable Signature finetunes the decoder of Latent Diffusion Models such that a\nunique watermark is rooted in any image produced by the decoder. In this paper,\nwe present a novel adversarial fine-tuning attack that disrupts the model's\nability to embed the intended watermark, exposing a significant vulnerability\nin existing watermarking methods. To address this, we further propose a\ntamper-resistant fine-tuning algorithm inspired by methods developed for large\nlanguage models, tailored to the specific requirements of watermarking in LDMs.\nOur findings emphasize the importance of anticipating and defending against\npotential vulnerabilities in generative systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19834v1",
    "published_date": "2024-12-22 04:36:27 UTC",
    "updated_date": "2024-12-22 04:36:27 UTC"
  },
  {
    "arxiv_id": "2412.16849v1",
    "title": "OpenRFT: Adapting Reasoning Foundation Model for Domain-specific Tasks with Reinforcement Fine-Tuning",
    "authors": [
      "Yuxiang Zhang",
      "Yuqi Yang",
      "Jiangming Shu",
      "Yuhang Wang",
      "Jinlin Xiao",
      "Jitao Sang"
    ],
    "abstract": "OpenAI's recent introduction of Reinforcement Fine-Tuning (RFT) showcases the\npotential of reasoning foundation model and offers a new paradigm for\nfine-tuning beyond simple pattern imitation. This technical report presents\n\\emph{OpenRFT}, our attempt to fine-tune generalist reasoning models for\ndomain-specific tasks under the same settings as RFT. OpenRFT addresses two key\nchallenges of lacking reasoning step data and the limited quantity of training\nsamples, by leveraging the domain-specific samples in three ways: question\naugmentation, synthesizing reasoning-process data, and few-shot ICL. The\nevaluation is conducted on SciKnowEval, where OpenRFT achieves notable\nperformance gains with only $100$ domain-specific samples for each task. More\nexperimental results will be updated continuously in later versions. Source\ncodes, datasets, and models are disclosed at:\nhttps://github.com/ADaM-BJTU/OpenRFT",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16849v1",
    "published_date": "2024-12-22 04:21:30 UTC",
    "updated_date": "2024-12-22 04:21:30 UTC"
  },
  {
    "arxiv_id": "2412.16848v2",
    "title": "ACL-QL: Adaptive Conservative Level in Q-Learning for Offline Reinforcement Learning",
    "authors": [
      "Kun Wu",
      "Yinuo Zhao",
      "Zhiyuan Xu",
      "Zhengping Che",
      "Chengxiang Yin",
      "Chi Harold Liu",
      "Feiferi Feng",
      "Jian Tang"
    ],
    "abstract": "Offline Reinforcement Learning (RL), which operates solely on static datasets\nwithout further interactions with the environment, provides an appealing\nalternative to learning a safe and promising control policy. The prevailing\nmethods typically learn a conservative policy to mitigate the problem of\nQ-value overestimation, but it is prone to overdo it, leading to an overly\nconservative policy. Moreover, they optimize all samples equally with fixed\nconstraints, lacking the nuanced ability to control conservative levels in a\nfine-grained manner. Consequently, this limitation results in a performance\ndecline. To address the above two challenges in a united way, we propose a\nframework, Adaptive Conservative Level in Q-Learning (ACL-QL), which limits the\nQ-values in a mild range and enables adaptive control on the conservative level\nover each state-action pair, i.e., lifting the Q-values more for good\ntransitions and less for bad transitions. We theoretically analyze the\nconditions under which the conservative level of the learned Q-function can be\nlimited in a mild range and how to optimize each transition adaptively.\nMotivated by the theoretical analysis, we propose a novel algorithm, ACL-QL,\nwhich uses two learnable adaptive weight functions to control the conservative\nlevel over each transition. Subsequently, we design a monotonicity loss and\nsurrogate losses to train the adaptive weight functions, Q-function, and policy\nnetwork alternatively. We evaluate ACL-QL on the commonly used D4RL benchmark\nand conduct extensive ablation studies to illustrate the effectiveness and\nstate-of-the-art performance compared to existing offline DRL baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 4 figures, IEEE Transactions on Neural Networks and\n  Learning Systems (2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.16848v2",
    "published_date": "2024-12-22 04:18:02 UTC",
    "updated_date": "2025-03-17 06:25:26 UTC"
  },
  {
    "arxiv_id": "2412.16844v3",
    "title": "Sim911: Towards Effective and Equitable 9-1-1 Dispatcher Training with an LLM-Enabled Simulation",
    "authors": [
      "Zirong Chen",
      "Elizabeth Chason",
      "Noah Mladenovski",
      "Erin Wilson",
      "Kristin Mullen",
      "Stephen Martini",
      "Meiyi Ma"
    ],
    "abstract": "Emergency response services are vital for enhancing public safety by\nsafeguarding the environment, property, and human lives. As frontline members\nof these services, 9-1-1 dispatchers have a direct impact on response times and\nthe overall effectiveness of emergency operations. However, traditional\ndispatcher training methods, which rely on role-playing by experienced\npersonnel, are labor-intensive, time-consuming, and often neglect the specific\nneeds of underserved communities. To address these challenges, we introduce\nSim911, the first training simulation for 9-1-1 dispatchers powered by Large\nLanguage Models (LLMs). Sim911 enhances training through three key technical\ninnovations: (1) knowledge construction, which utilizes archived 9-1-1 call\ndata to generate simulations that closely mirror real-world scenarios; (2)\ncontext-aware controlled generation, which employs dynamic prompts and vector\nbases to ensure that LLM behavior aligns with training objectives; and (3)\nvalidation with looped correction, which filters out low-quality responses and\nrefines the system performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16844v3",
    "published_date": "2024-12-22 03:43:51 UTC",
    "updated_date": "2024-12-26 04:41:11 UTC"
  },
  {
    "arxiv_id": "2412.16842v1",
    "title": "Graph Learning-based Regional Heavy Rainfall Prediction Using Low-Cost Rain Gauges",
    "authors": [
      "Edwin Salcedo"
    ],
    "abstract": "Accurate and timely prediction of heavy rainfall events is crucial for\neffective flood risk management and disaster preparedness. By monitoring,\nanalysing, and evaluating rainfall data at a local level, it is not only\npossible to take effective actions to prevent any severe climate variation but\nalso to improve the planning of surface and underground hydrological resources.\nHowever, developing countries often lack the weather stations to collect data\ncontinuously due to the high cost of installation and maintenance. In light of\nthis, the contribution of the present paper is twofold: first, we propose a\nlow-cost IoT system for automatic recording, monitoring, and prediction of\nrainfall in rural regions. Second, we propose a novel approach to regional\nheavy rainfall prediction by implementing graph neural networks (GNNs), which\nare particularly well-suited for capturing the complex spatial dependencies\ninherent in rainfall patterns. The proposed approach was tested using a\nhistorical dataset spanning 72 months, with daily measurements, and\nexperimental results demonstrated the effectiveness of the proposed method in\npredicting heavy rainfall events, making this approach particularly attractive\nfor regions with limited resources or where traditional weather radar or\nstation coverage is sparse.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication in the proceedings of the 2024 Latin\n  American Conference on Computational Intelligence (IEEE LA-CCI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.16842v1",
    "published_date": "2024-12-22 03:40:16 UTC",
    "updated_date": "2024-12-22 03:40:16 UTC"
  },
  {
    "arxiv_id": "2412.17872v1",
    "title": "Joint Knowledge Editing for Information Enrichment and Probability Promotion",
    "authors": [
      "Wenhang Shi",
      "Yiren Chen",
      "Shuqing Bian",
      "Xinyi Zhang",
      "Zhe Zhao",
      "Pengfei Hu",
      "Wei Lu",
      "Xiaoyong Du"
    ],
    "abstract": "Knowledge stored in large language models requires timely updates to reflect\nthe dynamic nature of real-world information. To update the knowledge, most\nknowledge editing methods focus on the low layers, since recent probes into the\nknowledge recall process reveal that the answer information is enriched in low\nlayers. However, these probes only and could only reveal critical recall stages\nfor the original answers, while the goal of editing is to rectify model's\nprediction for the target answers. This inconsistency indicates that both the\nprobe approaches and the associated editing methods are deficient. To mitigate\nthe inconsistency and identify critical editing regions, we propose a\ncontrast-based probe approach, and locate two crucial stages where the model\nbehavior diverges between the original and target answers: Information\nEnrichment in low layers and Probability Promotion in high layers. Building\nupon the insights, we develop the Joint knowledge Editing for information\nEnrichment and probability Promotion (JEEP) method, which jointly edits both\nthe low and high layers to modify the two critical recall stages. Considering\nthe mutual interference and growing forgetting due to dual modifications, JEEP\nis designed to ensure that updates to distinct regions share the same\nobjectives and are complementary. We rigorously evaluate JEEP by editing up to\nthousands of facts on various models, i.e., GPT-J (6B) and LLaMA (7B), and\naddressing diverse editing objectives, i.e., adding factual and counterfactual\nknowledge. In all tested scenarios, JEEP achieves best performances, validating\nthe effectiveness of the revealings of our probe approach and the designs of\nour editing method. Our code and data are available at\nhttps://github.com/Eric8932/JEEP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17872v1",
    "published_date": "2024-12-22 03:16:49 UTC",
    "updated_date": "2024-12-22 03:16:49 UTC"
  },
  {
    "arxiv_id": "2412.16839v2",
    "title": "Human-Guided Image Generation for Expanding Small-Scale Training Image Datasets",
    "authors": [
      "Changjian Chen",
      "Fei Lv",
      "Yalong Guan",
      "Pengcheng Wang",
      "Shengjie Yu",
      "Yifan Zhang",
      "Zhuo Tang"
    ],
    "abstract": "The performance of computer vision models in certain real-world applications\n(e.g., rare wildlife observation) is limited by the small number of available\nimages. Expanding datasets using pre-trained generative models is an effective\nway to address this limitation. However, since the automatic generation process\nis uncontrollable, the generated images are usually limited in diversity, and\nsome of them are undesired. In this paper, we propose a human-guided image\ngeneration method for more controllable dataset expansion. We develop a\nmulti-modal projection method with theoretical guarantees to facilitate the\nexploration of both the original and generated images. Based on the\nexploration, users refine the prompts and re-generate images for better\nperformance. Since directly refining the prompts is challenging for novice\nusers, we develop a sample-level prompt refinement method to make it easier.\nWith this method, users only need to provide sample-level feedback (e.g., which\nsamples are undesired) to obtain better prompts. The effectiveness of our\nmethod is demonstrated through the quantitative evaluation of the multi-modal\nprojection method, improved model performance in the case study for both\nclassification and object detection tasks, and positive feedback from the\nexperts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TVCG2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16839v2",
    "published_date": "2024-12-22 03:15:39 UTC",
    "updated_date": "2024-12-24 01:53:54 UTC"
  },
  {
    "arxiv_id": "2412.16834v2",
    "title": "Online Learning from Strategic Human Feedback in LLM Fine-Tuning",
    "authors": [
      "Shugang Hao",
      "Lingjie Duan"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has become an essential\nstep in fine-tuning large language models (LLMs) to align them with human\npreferences. However, human labelers are selfish and have diverse preferences.\nThey may strategically misreport their online feedback to influence the\nsystem's aggregation towards their own preferences. Current practice simply\naverages labelers' feedback per time and fails to identify the most accurate\nhuman labeler, leading to linear regret $\\mathcal{O}(T)$ for $T$ time slots. To\nour best knowledge, we are the first to study online learning mechanisms\nagainst strategic human labelers in the LLM fine-tuning process. We formulate a\nnew dynamic Bayesian game and dynamically adjust human labelers' weights in the\npreference aggregation, ensuring their truthful feedback and sublinear regret\n$\\mathcal{O}(T^{1/2})$. Simulation results demonstrate our mechanism's great\nadvantages over the existing benchmark schemes.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16834v2",
    "published_date": "2024-12-22 02:43:07 UTC",
    "updated_date": "2024-12-24 02:17:41 UTC"
  },
  {
    "arxiv_id": "2412.16833v4",
    "title": "KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis",
    "authors": [
      "Kaiwen Zuo",
      "Yirui Jiang",
      "Fan Mo",
      "Pietro Lio"
    ],
    "abstract": "Integrating Large Language Models (LLMs) in healthcare diagnosis demands\nsystematic frameworks that can handle complex medical scenarios while\nmaintaining specialized expertise. We present KG4Diagnosis, a novel\nhierarchical multi-agent framework that combines LLMs with automated knowledge\ngraph construction, encompassing 362 common diseases across medical\nspecialties. Our framework mirrors real-world medical systems through a\ntwo-tier architecture: a general practitioner (GP) agent for initial assessment\nand triage, coordinating with specialized agents for in-depth diagnosis in\nspecific domains. The core innovation lies in our end-to-end knowledge graph\ngeneration methodology, incorporating: (1) semantic-driven entity and relation\nextraction optimized for medical terminology, (2) multi-dimensional decision\nrelationship reconstruction from unstructured medical texts, and (3)\nhuman-guided reasoning for knowledge expansion. KG4Diagnosis serves as an\nextensible foundation for specialized medical diagnosis systems, with\ncapabilities to incorporate new diseases and medical knowledge. The framework's\nmodular design enables seamless integration of domain-specific enhancements,\nmaking it valuable for developing targeted medical diagnosis systems. We\nprovide architectural guidelines and protocols to facilitate adoption across\nmedical contexts.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages,5 figures,published to AAAI-25 Bridge Program",
    "pdf_url": "http://arxiv.org/pdf/2412.16833v4",
    "published_date": "2024-12-22 02:40:59 UTC",
    "updated_date": "2025-03-28 23:31:57 UTC"
  },
  {
    "arxiv_id": "2412.16829v1",
    "title": "Visual Prompting with Iterative Refinement for Design Critique Generation",
    "authors": [
      "Peitong Duan",
      "Chin-Yi Chen",
      "Bjoern Hartmann",
      "Yang Li"
    ],
    "abstract": "Feedback is crucial for every design process, such as user interface (UI)\ndesign, and automating design critiques can significantly improve the\nefficiency of the design workflow. Although existing multimodal large language\nmodels (LLMs) excel in many tasks, they often struggle with generating\nhigh-quality design critiques -- a complex task that requires producing\ndetailed design comments that are visually grounded in a given design's image.\nBuilding on recent advancements in iterative refinement of text output and\nvisual prompting methods, we propose an iterative visual prompting approach for\nUI critique that takes an input UI screenshot and design guidelines and\ngenerates a list of design comments, along with corresponding bounding boxes\nthat map each comment to a specific region in the screenshot. The entire\nprocess is driven completely by LLMs, which iteratively refine both the text\noutput and bounding boxes using few-shot samples tailored for each step. We\nevaluated our approach using Gemini-1.5-pro and GPT-4o, and found that human\nexperts generally preferred the design critiques generated by our pipeline over\nthose by the baseline, with the pipeline reducing the gap from human\nperformance by 50% for one rating metric. To assess the generalizability of our\napproach to other multimodal tasks, we applied our pipeline to open-vocabulary\nobject and attribute detection, and experiments showed that our method also\noutperformed the baseline.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16829v1",
    "published_date": "2024-12-22 02:35:57 UTC",
    "updated_date": "2024-12-22 02:35:57 UTC"
  },
  {
    "arxiv_id": "2412.16822v2",
    "title": "Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers",
    "authors": [
      "Haoran You",
      "Connelly Barnes",
      "Yuqian Zhou",
      "Yan Kang",
      "Zhenbang Du",
      "Wei Zhou",
      "Lingzhi Zhang",
      "Yotam Nitzan",
      "Xiaoyang Liu",
      "Zhe Lin",
      "Eli Shechtman",
      "Sohrab Amirghodsi",
      "Yingyan Celine Lin"
    ],
    "abstract": "Diffusion Transformers (DiTs) have achieved state-of-the-art (SOTA) image\ngeneration quality but suffer from high latency and memory inefficiency, making\nthem difficult to deploy on resource-constrained devices. One major efficiency\nbottleneck is that existing DiTs apply equal computation across all regions of\nan image. However, not all image tokens are equally important, and certain\nlocalized areas require more computation, such as objects. To address this, we\npropose DiffCR, a dynamic DiT inference framework with differentiable\ncompression ratios, which automatically learns to dynamically route computation\nacross layers and timesteps for each image token, resulting in efficient DiTs.\nSpecifically, DiffCR integrates three features: (1) A token-level routing\nscheme where each DiT layer includes a router that is fine-tuned jointly with\nmodel weights to predict token importance scores. In this way, unimportant\ntokens bypass the entire layer's computation; (2) A layer-wise differentiable\nratio mechanism where different DiT layers automatically learn varying\ncompression ratios from a zero initialization, resulting in large compression\nratios in redundant layers while others remain less compressed or even\nuncompressed; (3) A timestep-wise differentiable ratio mechanism where each\ndenoising timestep learns its own compression ratio. The resulting pattern\nshows higher ratios for noisier timesteps and lower ratios as the image becomes\nclearer. Extensive experiments on text-to-image and inpainting tasks show that\nDiffCR effectively captures dynamism across token, layer, and timestep axes,\nachieving superior trade-offs between generation quality and efficiency\ncompared to prior works. The project website is available at\nhttps://www.haoranyou.com/diffcr.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16822v2",
    "published_date": "2024-12-22 02:04:17 UTC",
    "updated_date": "2025-03-27 15:42:18 UTC"
  },
  {
    "arxiv_id": "2412.16818v1",
    "title": "Unsupervised Discovery of Formulas for Mathematical Constants",
    "authors": [
      "Michael Shalyt",
      "Uri Seligmann",
      "Itay Beit Halachmi",
      "Ofir David",
      "Rotem Elimelech",
      "Ido Kaminer"
    ],
    "abstract": "Ongoing efforts that span over decades show a rise of AI methods for\naccelerating scientific discovery, yet accelerating discovery in mathematics\nremains a persistent challenge for AI. Specifically, AI methods were not\neffective in creation of formulas for mathematical constants because each such\nformula must be correct for infinite digits of precision, with \"near-true\"\nformulas providing no insight toward the correct ones. Consequently, formula\ndiscovery lacks a clear distance metric needed to guide automated discovery in\nthis realm.\n  In this work, we propose a systematic methodology for categorization,\ncharacterization, and pattern identification of such formulas. The key to our\nmethodology is introducing metrics based on the convergence dynamics of the\nformulas, rather than on the numerical value of the formula. These metrics\nenable the first automated clustering of mathematical formulas. We demonstrate\nthis methodology on Polynomial Continued Fraction formulas, which are\nubiquitous in their intrinsic connections to mathematical constants, and\ngeneralize many mathematical functions and structures.\n  We test our methodology on a set of 1,768,900 such formulas, identifying many\nknown formulas for mathematical constants, and discover previously unknown\nformulas for $\\pi$, $\\ln(2)$, Gauss', and Lemniscate's constants. The uncovered\npatterns enable a direct generalization of individual formulas to infinite\nfamilies, unveiling rich mathematical structures. This success paves the way\ntowards a generative model that creates formulas fulfilling specified\nmathematical properties, accelerating the rate of discovery of useful formulas.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.NT"
    ],
    "primary_category": "cs.AI",
    "comment": "8 figures, 5 tables, 28 pages including the supplementary\n  information. For a 5-minute video abstract see\n  https://recorder-v3.slideslive.com/#/share?share=97010&s=c47967e3-d585-453c-a4dd-a4fa7955dba3\n  . Code can be found at\n  https://github.com/RamanujanMachine/Blind-Delta-Algorithm",
    "pdf_url": "http://arxiv.org/pdf/2412.16818v1",
    "published_date": "2024-12-22 01:43:56 UTC",
    "updated_date": "2024-12-22 01:43:56 UTC"
  },
  {
    "arxiv_id": "2412.16814v1",
    "title": "An Exploration of Pattern Mining with ChatGPT",
    "authors": [
      "Michael Weiss"
    ],
    "abstract": "This paper takes an exploratory approach to examine the use of ChatGPT for\npattern mining. It proposes an eight-step collaborative process that combines\nhuman insight with AI capabilities to extract patterns from known uses. The\npaper offers a practical demonstration of this process by creating a pattern\nlanguage for integrating Large Language Models (LLMs) with data sources and\ntools. LLMs, such as ChatGPT, are a new class of AI models that have been\ntrained on large amounts of text, and can create new content, including text,\nimages, or video. The paper also argues for adding affordances of the\nunderlying components as a new element of pattern descriptions. The primary\naudience of the paper includes pattern writers interested in pattern mining\nusing LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is the author's version of the work. The definitive version of\n  record was published in 29th European Conference on Pattern Languages of\n  Programs, People, and Practices (EuroPLOP 2024), July 3-7, 2024, Irsee,\n  Germany, ACM",
    "pdf_url": "http://arxiv.org/pdf/2412.16814v1",
    "published_date": "2024-12-22 01:27:12 UTC",
    "updated_date": "2024-12-22 01:27:12 UTC"
  }
]