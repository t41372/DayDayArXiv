[
  {
    "arxiv_id": "2409.15623v1",
    "title": "Safe Guard: an LLM-agent for Real-time Voice-based Hate Speech Detection in Social Virtual Reality",
    "authors": [
      "Yiwen Xu",
      "Qinyang Hou",
      "Hongyu Wan",
      "Mirjana Prpa"
    ],
    "abstract": "In this paper, we present Safe Guard, an LLM-agent for the detection of hate\nspeech in voice-based interactions in social VR (VRChat). Our system leverages\nOpen AI GPT and audio feature extraction for real-time voice interactions. We\ncontribute a system design and evaluation of the system that demonstrates the\ncapability of our approach in detecting hate speech, and reducing false\npositives compared to currently available approaches. Our results indicate the\npotential of LLM-based agents in creating safer virtual environments and set\nthe groundwork for further advancements in LLM-driven moderation approaches.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15623v1",
    "published_date": "2024-09-23 23:54:45 UTC",
    "updated_date": "2024-09-23 23:54:45 UTC"
  },
  {
    "arxiv_id": "2409.19013v3",
    "title": "Improving Academic Skills Assessment with NLP and Ensemble Learning",
    "authors": [
      "Xinyi Huang",
      "Yingyi Wu",
      "Danyang Zhang",
      "Jiacheng Hu",
      "Yujian Long"
    ],
    "abstract": "This study addresses the critical challenges of assessing foundational\nacademic skills by leveraging advancements in natural language processing\n(NLP). Traditional assessment methods often struggle to provide timely and\ncomprehensive feedback on key cognitive and linguistic aspects, such as\ncoherence, syntax, and analytical reasoning. Our approach integrates multiple\nstate-of-the-art NLP models, including BERT, RoBERTa, BART, DeBERTa, and T5,\nwithin an ensemble learning framework. These models are combined through\nstacking techniques using LightGBM and Ridge regression to enhance predictive\naccuracy. The methodology involves detailed data preprocessing, feature\nextraction, and pseudo-label learning to optimize model performance. By\nincorporating sophisticated NLP techniques and ensemble learning, this study\nsignificantly improves the accuracy and efficiency of assessments, offering a\nrobust solution that surpasses traditional methods and opens new avenues for\neducational technology research focused on enhancing core academic\ncompetencies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.19013v3",
    "published_date": "2024-09-23 23:43:43 UTC",
    "updated_date": "2024-10-13 05:04:47 UTC"
  },
  {
    "arxiv_id": "2409.15612v1",
    "title": "Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration",
    "authors": [
      "Wangyang Ying",
      "Dongjie Wang",
      "Xuanming Hu",
      "Ji Qiu",
      "Jin Park",
      "Yanjie Fu"
    ],
    "abstract": "Biomarker discovery is vital in advancing personalized medicine, offering\ninsights into disease diagnosis, prognosis, and therapeutic efficacy.\nTraditionally, the identification and validation of biomarkers heavily depend\non extensive experiments and statistical analyses. These approaches are\ntime-consuming, demand extensive domain expertise, and are constrained by the\ncomplexity of biological systems. These limitations motivate us to ask: Can we\nautomatically identify the effective biomarker subset without substantial human\nefforts? Inspired by the success of generative AI, we think that the intricate\nknowledge of biomarker identification can be compressed into a continuous\nembedding space, thus enhancing the search for better biomarkers. Thus, we\npropose a new biomarker identification framework with two important modules:1)\ntraining data preparation and 2) embedding-optimization-generation. The first\nmodule uses a multi-agent system to automatically collect pairs of biomarker\nsubsets and their corresponding prediction accuracy as training data. These\ndata establish a strong knowledge base for biomarker identification. The second\nmodule employs an encoder-evaluator-decoder learning paradigm to compress the\nknowledge of the collected data into a continuous space. Then, it utilizes\ngradient-based search techniques and autoregressive-based reconstruction to\nefficiently identify the optimal subset of biomarkers. Finally, we conduct\nextensive experiments on three real-world datasets to show the efficiency,\nrobustness, and effectiveness of our method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15612v1",
    "published_date": "2024-09-23 23:36:30 UTC",
    "updated_date": "2024-09-23 23:36:30 UTC"
  },
  {
    "arxiv_id": "2409.15595v1",
    "title": "Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay",
    "authors": [
      "Keke Long",
      "Haotian Shi",
      "Yang Zhou",
      "Xiaopeng Li"
    ],
    "abstract": "Linear control models have gained extensive application in vehicle control\ndue to their simplicity, ease of use, and support for stability analysis.\nHowever, these models lack adaptability to the changing environment and\nmulti-objective settings. Reinforcement learning (RL) models, on the other\nhand, offer adaptability but suffer from a lack of interpretability and\ngeneralization capabilities. This paper aims to develop a family of RL-based\ncontrollers enhanced by physics-informed policies, leveraging the advantages of\nboth physics-based models (data-efficient and interpretable) and RL methods\n(flexible to multiple objectives and fast computing). We propose the\nPhysics-Enhanced Residual Policy Learning (PERPL) framework, where the physics\ncomponent provides model interpretability and stability. The learning-based\nResidual Policy adjusts the physics-based policy to adapt to the changing\nenvironment, thereby refining the decisions of the physics model. We apply our\nproposed model to decentralized control to mixed traffic platoon of Connected\nand Automated Vehicles (CAVs) and Human-driven Vehicles (HVs) using a constant\ntime gap (CTG) strategy for cruising and incorporating actuator and\ncommunication delays. Experimental results demonstrate that our method achieves\nsmaller headway errors and better oscillation dampening than linear models and\nRL alone in scenarios with artificially extreme conditions and real preceding\nvehicle trajectories. At the macroscopic level, overall traffic oscillations\nare also reduced as the penetration rate of CAVs employing the PERPL scheme\nincreases.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15595v1",
    "published_date": "2024-09-23 23:02:34 UTC",
    "updated_date": "2024-09-23 23:02:34 UTC"
  },
  {
    "arxiv_id": "2409.15586v3",
    "title": "TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU",
    "authors": [
      "Rosemary Y. He",
      "Jeffrey N. Chiang"
    ],
    "abstract": "Trajectory forecasting in healthcare data has been an important area of\nresearch in precision care and clinical integration for computational methods.\nIn recent years, generative AI models have demonstrated promising results in\ncapturing short and long range dependencies in time series data. While these\nmodels have also been applied in healthcare, most of them only predict one\nvalue at a time, which is unrealistic in a clinical setting where multiple\nmeasures are taken at once. In this work, we extend the framework temporal\nfusion transformer (TFT), a multi-horizon time series prediction tool, and\npropose TFT-multi, an end-to-end framework that can predict multiple vital\ntrajectories simultaneously. We apply TFT-multi to forecast 5 vital signs\nrecorded in the intensive care unit: blood pressure, pulse, SpO2, temperature\nand respiratory rate. We hypothesize that by jointly predicting these measures,\nwhich are often correlated with one another, we can make more accurate\npredictions, especially in variables with large missingness. We validate our\nmodel on the public MIMIC dataset and an independent institutional dataset, and\ndemonstrate that this approach outperforms state-of-the-art univariate\nprediction tools including the original TFT and Prophet, as well as vector\nregression modeling for multivariate prediction. Furthermore, we perform a\nstudy case analysis by applying our pipeline to forecast blood pressure changes\nin response to actual and hypothetical pressor administration.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15586v3",
    "published_date": "2024-09-23 22:36:37 UTC",
    "updated_date": "2024-12-06 18:28:58 UTC"
  },
  {
    "arxiv_id": "2409.15584v1",
    "title": "FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality",
    "authors": [
      "Junyuan Ding",
      "Ziteng Wang",
      "Chang Gao",
      "Min Liu",
      "Qinyu Chen"
    ],
    "abstract": "Eye tracking is a key technology for gaze-based interactions in Extended\nReality (XR), but traditional frame-based systems struggle to meet XR's demands\nfor high accuracy, low latency, and power efficiency. Event cameras offer a\npromising alternative due to their high temporal resolution and low power\nconsumption. In this paper, we present FACET (Fast and Accurate Event-based Eye\nTracking), an end-to-end neural network that directly outputs pupil ellipse\nparameters from event data, optimized for real-time XR applications. The\nellipse output can be directly used in subsequent ellipse-based pupil trackers.\nWe enhance the EV-Eye dataset by expanding annotated data and converting\noriginal mask labels to ellipse-based annotations to train the model. Besides,\na novel trigonometric loss is adopted to address angle discontinuities and a\nfast causal event volume event representation method is put forward. On the\nenhanced EV-Eye test set, FACET achieves an average pupil center error of 0.20\npixels and an inference time of 0.53 ms, reducing pixel error and inference\ntime by 1.6$\\times$ and 1.8$\\times$ compared to the prior art, EV-Eye, with\n4.4$\\times$ and 11.7$\\times$ less parameters and arithmetic operations. The\ncode is available at https://github.com/DeanJY/FACET.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15584v1",
    "published_date": "2024-09-23 22:31:38 UTC",
    "updated_date": "2024-09-23 22:31:38 UTC"
  },
  {
    "arxiv_id": "2409.15567v3",
    "title": "Asking an AI for salary negotiation advice is a matter of concern: Controlled experimental perturbation of ChatGPT for protected and non-protected group discrimination on a contextual task with no clear ground truth answers",
    "authors": [
      "R. Stuart Geiger",
      "Flynn O'Sullivan",
      "Elsie Wang",
      "Jonathan Lo"
    ],
    "abstract": "We conducted controlled experimental bias audits for four versions of\nChatGPT, which we asked to recommend an opening offer in salary negotiations\nfor a new hire. We submitted 98,800 prompts to each version, systematically\nvarying the employee's gender, university, and major, and tested prompts in\nvoice of each side of the negotiation: the employee versus employer. We find\nChatGPT as a multi-model platform is not robust and consistent enough to be\ntrusted for such a task. We observed statistically significant salary offers\nwhen varying gender for all four models, although with smaller gaps than for\nother attributes tested. The largest gaps were different model versions and\nbetween the employee- vs employer-voiced prompts. We also observed substantial\ngaps when varying university and major, but many of the biases were not\nconsistent across model versions. We tested for fictional and fraudulent\nuniversities and found wildly inconsistent results across cases and model\nversions. We make broader contributions to the AI/ML fairness literature. Our\nscenario and our experimental design differ from mainstream AI/ML auditing\nefforts in key ways. Bias audits typically test discrimination for protected\nclasses like gender, which we contrast with testing non-protected classes of\nuniversity and major. Asking for negotiation advice includes how aggressive one\nought to be in a negotiation relative to known empirical salary distributions\nand scales, which is a deeply contextual and personalized task that has no\nobjective ground truth to validate. These results raise concerns for the\nspecific model versions we tested and ChatGPT as a multi-model platform in\ncontinuous development. Our epistemology does not permit us to definitively\ncertify these models as either generally biased or unbiased on the attributes\nwe test, but our study raises matters of concern for stakeholders to further\ninvestigate.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15567v3",
    "published_date": "2024-09-23 21:48:32 UTC",
    "updated_date": "2024-10-08 14:46:25 UTC"
  },
  {
    "arxiv_id": "2409.15566v1",
    "title": "GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation",
    "authors": [
      "Brendan Hogan Rappazzo",
      "Yingheng Wang",
      "Aaron Ferber",
      "Carla Gomes"
    ],
    "abstract": "The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility'' questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI's text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15566v1",
    "published_date": "2024-09-23 21:42:47 UTC",
    "updated_date": "2024-09-23 21:42:47 UTC"
  },
  {
    "arxiv_id": "2410.00036v1",
    "title": "InsightPulse: An IoT-based System for User Experience Interview Analysis",
    "authors": [
      "Dian Lyu",
      "Yuetong Lu",
      "Jassie He",
      "Murad Mehrab Abrar",
      "Ruijun Xie",
      "John Raiti"
    ],
    "abstract": "Conducting efficient and effective user experience (UX) interviews often\nposes challenges, such as maintaining focus on key topics and managing the\nduration of interviews and post-interview analyses. To address these issues,\nthis paper introduces InsightPulse, an Internet of Things (IoT)-based hardware\nand software system designed to streamline and enhance the UX interview process\nthrough speech analysis and Artificial Intelligence. InsightPulse provides\nreal-time support during user interviews by automatically identifying and\nhighlighting key discussion points, proactively suggesting follow-up questions,\nand generating thematic summaries. These features enable more insightful\ndiscoveries and help to manage interview duration effectively. Additionally,\nthe system features a robust backend analytics dashboard that simplifies the\npost-interview review process, thus facilitating the quick extraction of\nactionable insights and enhancing overall UX research efficiency.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication at the 10th IEEE International Conference on\n  Collaboration and Internet Computing (IEEE CIC 2024), Washington D.C., USA",
    "pdf_url": "http://arxiv.org/pdf/2410.00036v1",
    "published_date": "2024-09-23 21:39:34 UTC",
    "updated_date": "2024-09-23 21:39:34 UTC"
  },
  {
    "arxiv_id": "2409.19012v1",
    "title": "Lost in the Logic: An Evaluation of Large Language Models' Reasoning Capabilities on LSAT Logic Games",
    "authors": [
      "Saumya Malik"
    ],
    "abstract": "In this thesis, I evaluate the performance of Large Language Models (LLMs) on\nthe Law School Admissions Test (LSAT), specifically the Logic Games section of\nthe test. I focus on this section because it presents a complex logical\nreasoning task and thus is a valuable source of data for evaluating how modern,\nincreasingly capable LLMs can handle hard logical reasoning tasks. I construct\na dataset of LSAT logic games and their associated metadata, and extensively\nevaluate LLMs' performance in a Chain-of-Thought prompting setting. Given the\nweak performance in this setting, I explore other prompting frameworks on a\nsmaller subset of the dataset, adapting ideas from Reflexion to this task. This\nresults in a substantially improved accuracy of 70 percent for GPT-4 and 46\npercent for GPT-3.5 on this data subset, highlighting the capacity of LLMs to\nrevise their logical errors, despite initially weak performance. Finally, I\nanalyze the types of logic games that models perform better or worse on, as\nwell as the types of logical errors I observe from human annotation, providing\ndetailed insights on the logical reasoning capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Bachelor's thesis. Dataset available on huggingface:\n  https://huggingface.co/datasets/saumyamalik/lsat_logic_games-analytical_reasoning",
    "pdf_url": "http://arxiv.org/pdf/2409.19012v1",
    "published_date": "2024-09-23 21:37:40 UTC",
    "updated_date": "2024-09-23 21:37:40 UTC"
  },
  {
    "arxiv_id": "2409.19011v1",
    "title": "Identification and Mitigating Bias in Quantum Machine Learning",
    "authors": [
      "Nandhini Swaminathan",
      "David Danks"
    ],
    "abstract": "As quantum machine learning (QML) emerges as a promising field at the\nintersection of quantum computing and artificial intelligence, it becomes\ncrucial to address the biases and challenges that arise from the unique nature\nof quantum systems. This research includes work on identification, diagnosis,\nand response to biases in Quantum Machine Learning. This paper aims to provide\nan overview of three key topics: How does bias unique to Quantum Machine\nLearning look? Why and how can it occur? What can and should be done about it?",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "2 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.19011v1",
    "published_date": "2024-09-23 21:31:16 UTC",
    "updated_date": "2024-09-23 21:31:16 UTC"
  },
  {
    "arxiv_id": "2409.15551v2",
    "title": "Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction",
    "authors": [
      "Yuanchao Li",
      "Yuan Gong",
      "Chao-Han Huck Yang",
      "Peter Bell",
      "Catherine Lai"
    ],
    "abstract": "Annotating and recognizing speech emotion using prompt engineering has\nrecently emerged with the advancement of Large Language Models (LLMs), yet its\nefficacy and reliability remain questionable. In this paper, we conduct a\nsystematic study on this topic, beginning with the proposal of novel prompts\nthat incorporate emotion-specific knowledge from acoustics, linguistics, and\npsychology. Subsequently, we examine the effectiveness of LLM-based prompting\non Automatic Speech Recognition (ASR) transcription, contrasting it with\nground-truth transcription. Furthermore, we propose a Revise-Reason-Recognize\nprompting pipeline for robust LLM-based emotion recognition from spoken\nlanguage with ASR errors. Additionally, experiments on context-aware learning,\nin-context learning, and instruction tuning are performed to examine the\nusefulness of LLM training schemes in this direction. Finally, we investigate\nthe sensitivity of LLMs to minor prompt variations. Experimental results\ndemonstrate the efficacy of the emotion-specific prompts, ASR error correction,\nand LLM training schemes for LLM-based emotion recognition. Our study aims to\nrefine the use of LLMs in emotion recognition and related domains.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15551v2",
    "published_date": "2024-09-23 21:07:06 UTC",
    "updated_date": "2025-04-30 13:26:38 UTC"
  },
  {
    "arxiv_id": "2410.03697v1",
    "title": "Combining Open-box Simulation and Importance Sampling for Tuning Large-Scale Recommenders",
    "authors": [
      "Kaushal Paneri",
      "Michael Munje",
      "Kailash Singh Maurya",
      "Adith Swaminathan",
      "Yifan Shi"
    ],
    "abstract": "Growing scale of recommender systems require extensive tuning to respond to\nmarket dynamics and system changes. We address the challenge of tuning a\nlarge-scale ads recommendation platform with multiple continuous parameters\ninfluencing key performance indicators (KPIs). Traditional methods like\nopen-box Monte Carlo simulators, while accurate, are computationally expensive\ndue to the high cost of evaluating numerous parameter settings. To mitigate\nthis, we propose a hybrid approach Simulator-Guided Importance Sampling (SGIS)\nthat combines open-box simulation with importance sampling (IS). SGIS leverages\nthe strengths of both techniques: it performs a coarse enumeration over the\nparameter space to identify promising initial settings and then uses IS to\niteratively refine these settings. This approach significantly reduces\ncomputational costs while maintaining high accuracy in KPI estimation. We\ndemonstrate the effectiveness of SGIS through simulations as well as real-world\nexperiments, showing that it achieves substantial improvements in KPIs with\nlower computational overhead compared to traditional methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the CONSEQUENCES '24 workshop, co-located with ACM RecSys\n  '24",
    "pdf_url": "http://arxiv.org/pdf/2410.03697v1",
    "published_date": "2024-09-23 20:35:47 UTC",
    "updated_date": "2024-09-23 20:35:47 UTC"
  },
  {
    "arxiv_id": "2409.16329v1",
    "title": "MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis",
    "authors": [
      "Stanislav Kozák"
    ],
    "abstract": "Radiomics is a relatively new field which utilises automatically identified\nfeatures from radiological scans. It has found a widespread application,\nparticularly in oncology because many of the important oncological biomarkers\nare not visible to the naked eye. The recent advent of big data, including in\nmedical imaging, and the development of new ML techniques brought the\npossibility of faster and more accurate oncological diagnosis. Furthermore,\nstandardised mathematical feature extraction based on radiomics helps to\neliminate possible radiologist bias. This paper reviews the recent development\nin the oncological use of MRI radiomic features. It focuses on the\nidentification of the isocitrate dehydrogenase (IDH) mutation status, which is\nan important biomarker for the diagnosis of glioblastoma and grade IV\nastrocytoma.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.2; I.4; J.3"
    ],
    "primary_category": "q-bio.QM",
    "comment": "8 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.16329v1",
    "published_date": "2024-09-23 20:34:49 UTC",
    "updated_date": "2024-09-23 20:34:49 UTC"
  },
  {
    "arxiv_id": "2409.15523v1",
    "title": "SEAL: Suite for Evaluating API-use of LLMs",
    "authors": [
      "Woojeong Kim",
      "Ashish Jagmohan",
      "Aditya Vempaty"
    ],
    "abstract": "Large language models (LLMs) have limitations in handling tasks that require\nreal-time access to external APIs. While several benchmarks like ToolBench and\nAPIGen have been developed to assess LLMs' API-use capabilities, they often\nsuffer from issues such as lack of generalizability, limited multi-step\nreasoning coverage, and instability due to real-time API fluctuations. In this\npaper, we introduce SEAL, an end-to-end testbed designed to evaluate LLMs in\nreal-world API usage. SEAL standardizes existing benchmarks, integrates an\nagent system for testing API retrieval and planning, and addresses the\ninstability of real-time APIs by introducing a GPT-4-powered API simulator with\ncaching for deterministic evaluations. Our testbed provides a comprehensive\nevaluation pipeline that covers API retrieval, API calls, and final responses,\noffering a reliable framework for structured performance comparison in diverse\nreal-world scenarios. SEAL is publicly available, with ongoing updates for new\nbenchmarks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15523v1",
    "published_date": "2024-09-23 20:16:49 UTC",
    "updated_date": "2024-09-23 20:16:49 UTC"
  },
  {
    "arxiv_id": "2409.15521v1",
    "title": "CANDERE-COACH: Reinforcement Learning from Noisy Feedback",
    "authors": [
      "Yuxuan Li",
      "Srijita Das",
      "Matthew E. Taylor"
    ],
    "abstract": "In recent times, Reinforcement learning (RL) has been widely applied to many\nchallenging tasks. However, in order to perform well, it requires access to a\ngood reward function which is often sparse or manually engineered with scope\nfor error. Introducing human prior knowledge is often seen as a possible\nsolution to the above-mentioned problem, such as imitation learning, learning\nfrom preference, and inverse reinforcement learning. Learning from feedback is\nanother framework that enables an RL agent to learn from binary evaluative\nsignals describing the teacher's (positive or negative) evaluation of the\nagent's action. However, these methods often make the assumption that\nevaluative teacher feedback is perfect, which is a restrictive assumption. In\npractice, such feedback can be noisy due to limited teacher expertise or other\nexacerbating factors like cognitive load, availability, distraction, etc. In\nthis work, we propose the CANDERE-COACH algorithm, which is capable of learning\nfrom noisy feedback by a nonoptimal teacher. We propose a noise-filtering\nmechanism to de-noise online feedback data, thereby enabling the RL agent to\nsuccessfully learn with up to 40% of the teacher feedback being incorrect.\nExperiments on three common domains demonstrate the effectiveness of the\nproposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15521v1",
    "published_date": "2024-09-23 20:14:12 UTC",
    "updated_date": "2024-09-23 20:14:12 UTC"
  },
  {
    "arxiv_id": "2409.15515v1",
    "title": "Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA",
    "authors": [
      "Nirmal Roy",
      "Leonardo F. R. Ribeiro",
      "Rexhina Blloshmi",
      "Kevin Small"
    ],
    "abstract": "Augmenting Large Language Models (LLMs) with information retrieval\ncapabilities (i.e., Retrieval-Augmented Generation (RAG)) has proven beneficial\nfor knowledge-intensive tasks. However, understanding users' contextual search\nintent when generating responses is an understudied topic for conversational\nquestion answering (QA). This conversational extension leads to additional\nconcerns when compared to single-turn QA as it is more challenging for systems\nto comprehend conversational context and manage retrieved passages over\nmultiple turns. In this work, we propose a method for enabling LLMs to decide\nwhen to retrieve in RAG settings given a conversational context. When retrieval\nis deemed necessary, the LLM then rewrites the conversation for passage\nretrieval and judges the relevance of returned passages before response\ngeneration. Operationally, we build on the single-turn SELF-RAG framework (Asai\net al., 2023) and propose SELF-multi-RAG for conversational settings.\nSELF-multi-RAG demonstrates improved capabilities over single-turn variants\nwith respect to retrieving relevant passages (by using summarized\nconversational context) and assessing the quality of generated responses.\nExperiments on three conversational QA datasets validate the enhanced response\ngeneration capabilities of SELF-multi-RAG, with improvements of ~13% measured\nby human annotation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in EMNLP (findings) 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15515v1",
    "published_date": "2024-09-23 20:05:12 UTC",
    "updated_date": "2024-09-23 20:05:12 UTC"
  },
  {
    "arxiv_id": "2409.15503v3",
    "title": "From Text to Treatment Effects: A Meta-Learning Approach to Handling Text-Based Confounding",
    "authors": [
      "Henri Arno",
      "Paloma Rabaey",
      "Thomas Demeester"
    ],
    "abstract": "One of the central goals of causal machine learning is the accurate\nestimation of heterogeneous treatment effects from observational data. In\nrecent years, meta-learning has emerged as a flexible, model-agnostic paradigm\nfor estimating conditional average treatment effects (CATE) using any\nsupervised model. This paper examines the performance of meta-learners when the\nconfounding variables are expressed in text. Through synthetic data\nexperiments, we show that learners using pre-trained text representations of\nconfounders, in addition to tabular background variables, achieve improved CATE\nestimates compared to those relying solely on the tabular variables,\nparticularly when sufficient data is available. However, due to the entangled\nnature of the text embeddings, these models do not fully match the performance\nof meta-learners with perfect confounder knowledge. These findings highlight\nboth the potential and the limitations of pre-trained text representations for\ncausal inference and open up interesting avenues for future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the NeurIPS 2024 Workshop on Causal Representation\n  Learning",
    "pdf_url": "http://arxiv.org/pdf/2409.15503v3",
    "published_date": "2024-09-23 19:46:19 UTC",
    "updated_date": "2024-11-13 10:02:25 UTC"
  },
  {
    "arxiv_id": "2409.19010v1",
    "title": "A comprehensive study of on-device NLP applications -- VQA, automated Form filling, Smart Replies for Linguistic Codeswitching",
    "authors": [
      "Naman Goyal"
    ],
    "abstract": "Recent improvement in large language models, open doors for certain new\nexperiences for on-device applications which were not possible before. In this\nwork, we propose 3 such new experiences in 2 categories. First we discuss\nexperiences which can be powered in screen understanding i.e. understanding\nwhats on user screen namely - (1) visual question answering, and (2) automated\nform filling based on previous screen. The second category of experience which\ncan be extended are smart replies to support for multilingual speakers with\ncode-switching. Code-switching occurs when a speaker alternates between two or\nmore languages. To the best of our knowledge, this is first such work to\npropose these tasks and solutions to each of them, to bridge the gap between\nlatest research and real world impact of the research in on-device\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19010v1",
    "published_date": "2024-09-23 19:28:52 UTC",
    "updated_date": "2024-09-23 19:28:52 UTC"
  },
  {
    "arxiv_id": "2409.15491v1",
    "title": "Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool",
    "authors": [
      "Ziyu Su",
      "Yongxin Guo",
      "Robert Wesolowski",
      "Gary Tozbikian",
      "Nathaniel S. O'Connell",
      "M. Khalid Khan Niazi",
      "Metin N. Gurcan"
    ],
    "abstract": "Accurate recurrence risk stratification is crucial for optimizing treatment\nplans for breast cancer patients. Current prognostic tools like Oncotype DX\n(ODX) offer valuable genomic insights for HR+/HER2- patients but are limited by\ncost and accessibility, particularly in underserved populations. In this study,\nwe present Deep-BCR-Auto, a deep learning-based computational pathology\napproach that predicts breast cancer recurrence risk from routine H&E-stained\nwhole slide images (WSIs). Our methodology was validated on two independent\ncohorts: the TCGA-BRCA dataset and an in-house dataset from The Ohio State\nUniversity (OSU). Deep-BCR-Auto demonstrated robust performance in stratifying\npatients into low- and high-recurrence risk categories. On the TCGA-BRCA\ndataset, the model achieved an area under the receiver operating characteristic\ncurve (AUROC) of 0.827, significantly outperforming existing weakly supervised\nmodels (p=0.041). In the independent OSU dataset, Deep-BCR-Auto maintained\nstrong generalizability, achieving an AUROC of 0.832, along with 82.0%\naccuracy, 85.0% specificity, and 67.7% sensitivity. These findings highlight\nthe potential of computational pathology as a cost-effective alternative for\nrecurrence risk assessment, broadening access to personalized treatment\nstrategies. This study underscores the clinical utility of integrating deep\nlearning-based computational pathology into routine pathological assessment for\nbreast cancer prognosis across diverse clinical settings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15491v1",
    "published_date": "2024-09-23 19:22:06 UTC",
    "updated_date": "2024-09-23 19:22:06 UTC"
  },
  {
    "arxiv_id": "2409.15486v1",
    "title": "VLMine: Long-Tail Data Mining with Vision Language Models",
    "authors": [
      "Mao Ye",
      "Gregory P. Meyer",
      "Zaiwei Zhang",
      "Dennis Park",
      "Siva Karthik Mustikovela",
      "Yuning Chai",
      "Eric M Wolff"
    ],
    "abstract": "Ensuring robust performance on long-tail examples is an important problem for\nmany real-world applications of machine learning, such as autonomous driving.\nThis work focuses on the problem of identifying rare examples within a corpus\nof unlabeled data. We propose a simple and scalable data mining approach that\nleverages the knowledge contained within a large vision language model (VLM).\nOur approach utilizes a VLM to summarize the content of an image into a set of\nkeywords, and we identify rare examples based on keyword frequency. We find\nthat the VLM offers a distinct signal for identifying long-tail examples when\ncompared to conventional methods based on model uncertainty. Therefore, we\npropose a simple and general approach for integrating signals from multiple\nmining algorithms. We evaluate the proposed method on two diverse tasks: 2D\nimage classification, in which inter-class variation is the primary source of\ndata diversity, and on 3D object detection, where intra-class variation is the\nmain concern. Furthermore, through the detection task, we demonstrate that the\nknowledge extracted from 2D images is transferable to the 3D domain. Our\nexperiments consistently show large improvements (between 10\\% and 50\\%) over\nthe baseline techniques on several representative benchmarks: ImageNet-LT,\nPlaces-LT, and the Waymo Open Dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15486v1",
    "published_date": "2024-09-23 19:13:51 UTC",
    "updated_date": "2024-09-23 19:13:51 UTC"
  },
  {
    "arxiv_id": "2409.15461v1",
    "title": "RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration",
    "authors": [
      "Haoyu Huang",
      "Tong Niu",
      "Rui Yang",
      "Luping Shi"
    ],
    "abstract": "Recently, many studies focus on utilizing large language models (LLMs) into\neducational dialogues. Especially, within liberal arts dialogues, educators\nmust balance \\textbf{H}umanized communication, \\textbf{T}eaching expertise, and\n\\textbf{S}afety-ethics (\\textbf{HTS}), besides the subject knowledge itself.\nHowever, due to collecting massive amounts of HTS-compliant teaching dialogues\nfrom real world as training corpus is expensive, the outputs of existing LLMs\nin teaching dialogues fall short of human standards. To address this, we design\na Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework\nto automatically generate such dialogues data. Specifically, we first establish\nHTS-guided knowledge bases, encompassing three domain knowledge in teaching\nskills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are\nretrieval-augmented by the above different knowledge bases, into multi-experts\ngroups with distinct roles to generate the HTS-compliant educational dialogues\ndataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations\nindicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering\nmore personalized, and ethically safe teaching response, demonstrating RAM2C's\npracticality and high quality. We release the experiments at\n\\hyperlink{https://github.com/ram2c/ram2c}{https://github.com/ram2c/ram2c}.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15461v1",
    "published_date": "2024-09-23 18:38:04 UTC",
    "updated_date": "2024-09-23 18:38:04 UTC"
  },
  {
    "arxiv_id": "2409.15454v1",
    "title": "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models",
    "authors": [
      "Pengrui Han",
      "Peiyang Song",
      "Haofei Yu",
      "Jiaxuan You"
    ],
    "abstract": "Recent advancements in artificial intelligence have led to the creation of\nhighly capable large language models (LLMs) that can perform tasks in a\nhuman-like manner. However, LLMs exhibit only infant-level cognitive abilities\nin certain areas. One such area is the A-Not-B error, a phenomenon seen in\ninfants where they repeat a previously rewarded behavior despite well-observed\nchanged conditions. This highlights their lack of inhibitory control -- the\nability to stop a habitual or impulsive response. In our work, we design a\ntext-based multi-choice QA scenario similar to the A-Not-B experimental\nsettings to systematically test the inhibitory control abilities of LLMs. We\nfound that state-of-the-art LLMs (like Llama3-8b) perform consistently well\nwith in-context learning (ICL) but make errors and show a significant drop of\nas many as 83.3% in reasoning tasks when the context changes trivially. This\nsuggests that LLMs only have inhibitory control abilities on par with human\ninfants in this regard, often failing to suppress the previously established\nresponse pattern during ICL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2409.15454v1",
    "published_date": "2024-09-23 18:30:31 UTC",
    "updated_date": "2024-09-23 18:30:31 UTC"
  },
  {
    "arxiv_id": "2409.15451v1",
    "title": "Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models",
    "authors": [
      "Mike Zhang",
      "Kaixian Qu",
      "Vaishakh Patil",
      "Cesar Cadena",
      "Marco Hutter"
    ],
    "abstract": "Large Language Models (LLM) have emerged as a tool for robots to generate\ntask plans using common sense reasoning. For the LLM to generate actionable\nplans, scene context must be provided, often through a map. Recent works have\nshifted from explicit maps with fixed semantic classes to implicit open\nvocabulary maps based on queryable embeddings capable of representing any\nsemantic class. However, embeddings cannot directly report the scene context as\nthey are implicit, requiring further processing for LLM integration. To address\nthis, we propose an explicit text-based map that can represent thousands of\nsemantic classes while easily integrating with LLMs due to their text-based\nnature by building upon large-scale image recognition models. We study how\nentities in our map can be localized and show through evaluations that our\ntext-based map localizations perform comparably to those from open vocabulary\nmaps while using two to four orders of magnitude less memory. Real-robot\nexperiments demonstrate the grounding of an LLM with the text-based map to\nsolve user tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15451v1",
    "published_date": "2024-09-23 18:26:19 UTC",
    "updated_date": "2024-09-23 18:26:19 UTC"
  },
  {
    "arxiv_id": "2410.18357v4",
    "title": "The Impact of Generative Artificial Intelligence on Ideation and the performance of Innovation Teams (Preprint)",
    "authors": [
      "Michael Gindert",
      "Marvin Lutz Müller"
    ],
    "abstract": "This study investigates the impact of Generative Artificial Intelligence\n(GenAI) on the dynamics and performance of innovation teams during the idea\ngeneration phase of the innovation process. Utilizing a custom AI-augmented\nideation tool, the study applies the Knowledge Spillover Theory of\nEntrepreneurship to understand the effects of AI on knowledge spillover,\ngeneration and application. Through a framed field experiment with participants\ndivided into experimental and control groups, findings indicate that\nAI-augmented teams generated higher quality ideas in less time. GenAI\napplication led to improved efficiency, knowledge exchange, increased\nsatisfaction and engagement as well as enhanced idea diversity. These results\nhighlight the transformative role of the field of AI within the innovation\nmanagement domain and shows that GenAI has a positive impact on important\nelements of the Knowledge Spillover Theory of Entrepreneurship, emphasizing its\npotential impact on innovation, entrepreneurship, and economic growth. Future\nresearch should further explore the dynamic interaction between GenAI and\ncreative processes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages, 5 figures, Author Contributions: Michael Gindert:\n  Conceptualization, Methodology, Software, Validation, Formal analysis,\n  Investigation, Resources, Data Curation, Writing - Original Draft, Writing -\n  Review & Editing, Visualization, Project administration, Funding acquisition\n  Marvin Lutz M\\\"uller: Validation, Investigation, Resources, Writing - Review\n  & Editing, Supervision",
    "pdf_url": "http://arxiv.org/pdf/2410.18357v4",
    "published_date": "2024-09-23 18:25:49 UTC",
    "updated_date": "2025-02-25 20:11:44 UTC"
  },
  {
    "arxiv_id": "2409.15441v1",
    "title": "Steward: Natural Language Web Automation",
    "authors": [
      "Brian Tang",
      "Kang G. Shin"
    ],
    "abstract": "Recently, large language models (LLMs) have demonstrated exceptional\ncapabilities in serving as the foundation for AI assistants. One emerging\napplication of LLMs, navigating through websites and interacting with UI\nelements across various web pages, remains somewhat underexplored. We introduce\nSteward, a novel LLM-powered web automation tool designed to serve as a\ncost-effective, scalable, end-to-end solution for automating web interactions.\nTraditional browser automation frameworks like Selenium, Puppeteer, and\nPlaywright are not scalable for extensive web interaction tasks, such as\nstudying recommendation algorithms on platforms like YouTube and Twitter. These\nframeworks require manual coding of interactions, limiting their utility in\nlarge-scale or dynamic contexts. Steward addresses these limitations by\nintegrating LLM capabilities with browser automation, allowing for natural\nlanguage-driven interaction with websites. Steward operates by receiving\nnatural language instructions and reactively planning and executing a sequence\nof actions on websites, looping until completion, making it a practical tool\nfor developers and researchers to use. It achieves high efficiency, completing\nactions in 8.52 to 10.14 seconds at a cost of $0.028 per action or an average\nof $0.18 per task, which is further reduced to 4.8 seconds and $0.022 through a\ncaching mechanism. It runs tasks on real websites with a 40% completion success\nrate. We discuss various design and implementation challenges, including state\nrepresentation, action sequence selection, system responsiveness, detecting\ntask completion, and caching implementation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15441v1",
    "published_date": "2024-09-23 18:06:32 UTC",
    "updated_date": "2024-09-23 18:06:32 UTC"
  },
  {
    "arxiv_id": "2409.15277v1",
    "title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?",
    "authors": [
      "Yunfei Xie",
      "Juncheng Wu",
      "Haoqin Tu",
      "Siwei Yang",
      "Bingchen Zhao",
      "Yongshuo Zong",
      "Qiao Jin",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across\nvarious domains and tasks, pushing the boundaries of our knowledge in learning\nand cognition. The latest model, OpenAI's o1, stands out as the first LLM with\nan internalized chain-of-thought technique using reinforcement learning\nstrategies. While it has demonstrated surprisingly strong capabilities on\nvarious general language tasks, its performance in specialized fields such as\nmedicine remains unknown. To this end, this report provides a comprehensive\nexploration of o1 on different medical scenarios, examining 3 key aspects:\nunderstanding, reasoning, and multilinguality. Specifically, our evaluation\nencompasses 6 tasks using data from 37 medical datasets, including two newly\nconstructed and more challenging question-answering (QA) tasks based on\nprofessional medical quizzes from the New England Journal of Medicine (NEJM)\nand The Lancet. These datasets offer greater clinical relevance compared to\nstandard medical QA benchmarks such as MedQA, translating more effectively into\nreal-world clinical utility. Our analysis of o1 suggests that the enhanced\nreasoning ability of LLMs may (significantly) benefit their capability to\nunderstand various medical instructions and reason through complex clinical\nscenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average\nof 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.\nBut meanwhile, we identify several weaknesses in both the model capability and\nthe existing evaluation protocols, including hallucination, inconsistent\nmultilingual ability, and discrepant metrics for evaluation. We release our raw\ndata and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The first four authors contributed equally, project page available at\n  https://ucsc-vlaa.github.io/o1_medicine/",
    "pdf_url": "http://arxiv.org/pdf/2409.15277v1",
    "published_date": "2024-09-23 17:59:43 UTC",
    "updated_date": "2024-09-23 17:59:43 UTC"
  },
  {
    "arxiv_id": "2409.15272v4",
    "title": "OmniBench: Towards The Future of Universal Omni-Language Models",
    "authors": [
      "Yizhi Li",
      "Ge Zhang",
      "Yinghao Ma",
      "Ruibin Yuan",
      "Kang Zhu",
      "Hangyu Guo",
      "Yiming Liang",
      "Jiaheng Liu",
      "Zekun Wang",
      "Jian Yang",
      "Siwei Wu",
      "Xingwei Qu",
      "Jinjie Shi",
      "Xinyue Zhang",
      "Zhenzhu Yang",
      "Xiangzhou Wang",
      "Zhaoxiang Zhang",
      "Zachary Liu",
      "Emmanouil Benetos",
      "Wenhao Huang",
      "Chenghua Lin"
    ],
    "abstract": "Recent advancements in multimodal large language models (MLLMs) have focused\non integrating multiple modalities, yet their ability to simultaneously process\nand reason across different inputs remains underexplored. We introduce\nOmniBench, a novel benchmark designed to evaluate models' ability to recognize,\ninterpret, and reason across visual, acoustic, and textual inputs\nsimultaneously. We define language models capable of such tri-modal processing\nas omni-language models (OLMs). OmniBench features high-quality human\nannotations that require integrated understanding across all modalities. Our\nevaluation reveals that: i) open-source OLMs show significant limitations in\ninstruction-following and reasoning in tri-modal contexts; and ii) most\nbaseline models perform poorly (around 50% accuracy) even with textual\nalternatives to image/audio inputs. To address these limitations, we develop\nOmniInstruct, an 96K-sample instruction tuning dataset for training OLMs. We\nadvocate for developing more robust tri-modal integration techniques and\ntraining strategies to enhance OLM performance. Codes and data could be found\nat our repo (https://github.com/multimodal-art-projection/OmniBench).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15272v4",
    "published_date": "2024-09-23 17:59:05 UTC",
    "updated_date": "2025-03-27 16:21:06 UTC"
  },
  {
    "arxiv_id": "2409.15268v3",
    "title": "Style Outweighs Substance: Failure Modes of LLM Judges in Alignment Benchmarking",
    "authors": [
      "Benjamin Feuer",
      "Micah Goldblum",
      "Teresa Datta",
      "Sanjana Nambiar",
      "Raz Besaleli",
      "Samuel Dooley",
      "Max Cembalest",
      "John P. Dickerson"
    ],
    "abstract": "The release of ChatGPT in November 2022 sparked an explosion of interest in\npost-training and an avalanche of new preference optimization (PO) methods.\nThese methods claim superior alignment by virtue of better correspondence with\nhuman pairwise preferences, often measured by LLM-judges. In this work, we\nattempt to answer the following question -- do LLM-judge preferences translate\nto progress on other, more concrete metrics for alignment, and if not, why not?\nWe define a concrete metric for alignment, and introduce SOS-Bench (Substance\nOutweighs Style Benchmark), which is to the best of our knowledge the largest\nstandardized, reproducible LLM meta-benchmark to date. We find that (1)\nLLM-judge preferences do not correlate with concrete measures of safety, world\nknowledge, and instruction following; (2) LLM-judges have powerful implicit\nbiases, prioritizing style over factuality and safety; and (3) the supervised\nfine-tuning (SFT) stage of post-training, and not the PO stage, has the\ngreatest impact on alignment, with data scaling and prompt diversity as the\ndriving factors. Our codebase and complete results can be found at\nhttps://github.com/penfever/sos-bench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15268v3",
    "published_date": "2024-09-23 17:58:07 UTC",
    "updated_date": "2025-01-27 11:35:04 UTC"
  },
  {
    "arxiv_id": "2409.15263v1",
    "title": "The Palomar twilight survey of 'Ayló'chaxnim, Atiras, and comets",
    "authors": [
      "B. T. Bolin",
      "F. J. Masci",
      "M. W. Coughlin",
      "D. A. Duev",
      "Ž. Ivezić",
      "R. L. Jones",
      "P. Yoachim",
      "T. Ahumada",
      "V. Bhalerao",
      "H. Choudhary",
      "C. Contreras",
      "Y. -C. Cheng",
      "C. M. Copperwheat",
      "K. Deshmukh",
      "C. Fremling",
      "M. Granvik",
      "K. K. Hardegree-Ullman",
      "A. Y. Q. Ho",
      "R. Jedicke",
      "M. Kasliwal",
      "H. Kumar",
      "Z. -Y. Lin",
      "A. Mahabal",
      "A. Monson",
      "J. D. Neill",
      "D. Nesvorný",
      "D. A. Perley",
      "J. N. Purdum",
      "R. Quimby",
      "E. Serabyn",
      "K. Sharma",
      "V. Swain"
    ],
    "abstract": "Near-sun sky twilight observations allow for the detection of asteroid\ninterior to the orbit of Venus (Aylos), the Earth (Atiras), and comets. We\npresent the results of observations with the Palomar 48-inch telescope\n(P48)/Zwicky Transient Facility (ZTF) camera in 30 s r-band exposures taken\nduring evening astronomical twilight from 2019 Sep 20 to 2022 March 7 and\nduring morning astronomical twilight sky from 2019 Sep 21 to 2022 Sep 29. More\nthan 46,000 exposures were taken in evening and morning astronomical twilight\nwithin 31 to 66 degrees from the Sun with an r-band limiting magnitude between\n18.1 and 20.9. The twilight pointings show a slight seasonal dependence in\nlimiting magnitude and ability to point closer towards the Sun, with limiting\nmagnitude slightly improving during summer. In total, the one Aylo, (594913)\n'Ayl\\'o'chaxnim, and 4 Atiras, 2020 OV1, 2021 BS1, 2021 PB2, and 2021 VR3, were\ndiscovered in evening and morning twilight observations. Additional twilight\nsurvey discoveries also include 6 long-period comets: C/2020 T2, C/2020 V2,\nC/2021 D2, C/2021 E3, C/2022 E3, and C/2022 P3, and two short-period comets:\nP/2021 N1 and P/2022 P2 using deep learning comet detection pipelines. The\nP48/ZTF twilight survey also recovered 11 known Atiras, one Aylo, three\nshort-period comes, two long-period comets, and one interstellar object.\nLastly, the Vera Rubin Observatory will conduct a twilight survey starting in\nits first year of operations and will cover the sky within 45 degrees of the\nSun. Twilight surveys such as those by ZTF and future surveys will provide\nopportunities for discovering asteroids inside the orbits of Earth and Venus.",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "26 pages, 13 figures, 4 tables, accepted for publication in Icarus",
    "pdf_url": "http://arxiv.org/pdf/2409.15263v1",
    "published_date": "2024-09-23 17:56:45 UTC",
    "updated_date": "2024-09-23 17:56:45 UTC"
  },
  {
    "arxiv_id": "2409.15261v1",
    "title": "Identification and Localization of Cometary Activity in Solar System Objects with Machine Learning",
    "authors": [
      "Bryce T. Bolin",
      "Michael W. Coughlin"
    ],
    "abstract": "In this chapter, we will discuss the use of Machine Learning methods for the\nidentification and localization of cometary activity for Solar System objects\nin ground and in space-based wide-field all-sky surveys. We will begin the\nchapter by discussing the challenges of identifying known and unknown active,\nextended Solar System objects in the presence of stellar-type sources and the\napplication of classical pre-ML identification techniques and their\nlimitations. We will then transition to the discussion of implementing ML\ntechniques to address the challenge of extended object identification. We will\nfinish with prospective future methods and the application to future surveys\nsuch as the Vera C. Rubin Observatory.",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "25 pages, 9 figures, accepted chapter in Machine Learning for Small\n  Bodies in the Solar System, Valerio Carruba, Evgeny Smirnov, and Dagmara\n  Oszkiewicz, Elsevier, 2024, p. 209-227",
    "pdf_url": "http://arxiv.org/pdf/2409.15261v1",
    "published_date": "2024-09-23 17:56:32 UTC",
    "updated_date": "2024-09-23 17:56:32 UTC"
  },
  {
    "arxiv_id": "2409.15260v1",
    "title": "Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation",
    "authors": [
      "Yi-Fei Zhao",
      "Allyn Bove",
      "David Thompson",
      "James Hill",
      "Yi Xu",
      "Yufan Ren",
      "Andrea Hassman",
      "Leming Zhou",
      "Yanshan Wang"
    ],
    "abstract": "Low back pain (LBP) is a leading cause of disability globally. Following the\nonset of LBP and subsequent treatment, adequate patient education is crucial\nfor improving functionality and long-term outcomes. Despite advancements in\npatient education strategies, significant gaps persist in delivering\npersonalized, evidence-based information to patients with LBP. Recent\nadvancements in large language models (LLMs) and generative artificial\nintelligence (GenAI) have demonstrated the potential to enhance patient\neducation. However, their application and efficacy in delivering educational\ncontent to patients with LBP remain underexplored and warrant further\ninvestigation. In this study, we introduce a novel approach utilizing LLMs with\nRetrieval-Augmented Generation (RAG) and few-shot learning to generate tailored\neducational materials for patients with LBP. Physical therapists manually\nevaluated our model responses for redundancy, accuracy, and completeness using\na Likert scale. In addition, the readability of the generated education\nmaterials is assessed using the Flesch Reading Ease score. The findings\ndemonstrate that RAG-based LLMs outperform traditional LLMs, providing more\naccurate, complete, and readable patient education materials with less\nredundancy. Having said that, our analysis reveals that the generated materials\nare not yet ready for use in clinical practice. This study underscores the\npotential of AI-driven models utilizing RAG to improve patient education for\nLBP; however, significant challenges remain in ensuring the clinical relevance\nand granularity of content generated by these models.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15260v1",
    "published_date": "2024-09-23 17:56:08 UTC",
    "updated_date": "2024-09-23 17:56:08 UTC"
  },
  {
    "arxiv_id": "2409.15259v2",
    "title": "StarVid: Enhancing Semantic Alignment in Video Diffusion Models via Spatial and SynTactic Guided Attention Refocusing",
    "authors": [
      "Yuanhang Li",
      "Qi Mao",
      "Lan Chen",
      "Zhen Fang",
      "Lei Tian",
      "Xinyan Xiao",
      "Libiao Jin",
      "Hua Wu"
    ],
    "abstract": "Recent advances in text-to-video (T2V) generation with diffusion models have\ngarnered significant attention. However, they typically perform well in scenes\nwith a single object and motion, struggling in compositional scenarios with\nmultiple objects and distinct motions to accurately reflect the semantic\ncontent of text prompts. To address these challenges, we propose\n\\textbf{StarVid}, a plug-and-play, training-free method that improves semantic\nalignment between multiple subjects, their motions, and text prompts in T2V\nmodels. StarVid first leverages the spatial reasoning capabilities of large\nlanguage models (LLMs) for two-stage motion trajectory planning based on text\nprompts. Such trajectories serve as spatial priors, guiding a spatial-aware\nloss to refocus cross-attention (CA) maps into distinctive regions.\nFurthermore, we propose a syntax-guided contrastive constraint to strengthen\nthe correlation between the CA maps of verbs and their corresponding nouns,\nenhancing motion-subject binding. Both qualitative and quantitative evaluations\ndemonstrate that the proposed framework significantly outperforms baseline\nmethods, delivering videos of higher quality with improved semantic\nconsistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15259v2",
    "published_date": "2024-09-23 17:56:03 UTC",
    "updated_date": "2025-03-03 15:01:03 UTC"
  },
  {
    "arxiv_id": "2409.15256v1",
    "title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View",
    "authors": [
      "Yuhang Xiao",
      "Yudi Lin",
      "Ming-Chang Chiu"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models\n(LLMs) was equipped with vision modules to create more human-like models.\nHowever, we should carefully evaluate their applications in different domains,\nas they may possess undesired biases. Our work studies the potential behavioral\nbiases of LVLMs from a behavioral finance perspective, an interdisciplinary\nsubject that jointly considers finance and psychology. We propose an end-to-end\nframework, from data collection to new evaluation metrics, to assess LVLMs'\nreasoning capabilities and the dynamic behaviors manifested in two established\nhuman financial behavioral biases: recency bias and authority bias. Our\nevaluations find that recent open-source LVLMs such as LLaVA-NeXT,\nMobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer\nsignificantly from these two biases, while the proprietary model GPT-4o is\nnegligibly impacted. Our observations highlight directions in which open-source\nmodels can improve. The code is available at\nhttps://github.com/mydcxiao/vlm_behavioral_fin.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024 Workshop on Large Language Models and Cognition",
    "pdf_url": "http://arxiv.org/pdf/2409.15256v1",
    "published_date": "2024-09-23 17:54:47 UTC",
    "updated_date": "2024-09-23 17:54:47 UTC"
  },
  {
    "arxiv_id": "2409.15254v5",
    "title": "Archon: An Architecture Search Framework for Inference-Time Techniques",
    "authors": [
      "Jon Saad-Falcon",
      "Adrian Gamarra Lafuente",
      "Shlok Natarajan",
      "Nahum Maru",
      "Hristo Todorov",
      "Etash Guha",
      "E. Kelly Buchanan",
      "Mayee Chen",
      "Neel Guha",
      "Christopher Ré",
      "Azalia Mirhoseini"
    ],
    "abstract": "Inference-time techniques are emerging as highly effective tools to enhance\nlarge language model (LLM) capabilities. However, best practices for developing\nsystems that combine these techniques remain underdeveloped due to our limited\nunderstanding of the utility of individual inference-time techniques and the\ninteractions between them. Additionally, efficiently and automatically\nsearching the space of model choices, inference-time techniques, and their\ncompositions is challenging due to the large design space. To address these\nchallenges, we introduce Archon, a modular framework for selecting, combining,\nand stacking layers of inference-time techniques to construct optimized LLM\nsystems for target benchmarks. Rather than relying on a single LLM called once,\nwe leverage a diverse set of LLMs and inference-time techniques, creating LLM\nsystems greater than the sum of their parts. Archon defines an extensible\ndesign space, encompassing techniques such as generation ensembling, repeated\nsampling, ranking, fusion, critiquing, verification, and unit testing. It\ntransforms the problem of building LLM systems into a hyperparameter\noptimization objective. Given the available LLMs, inference-time techniques,\nand compute budget, Archon utilizes hyperparameter search techniques to\ndiscover optimized architectures for target benchmark(s). We evaluate Archon\narchitectures across a range of instruction-following, reasoning, and coding\nbenchmarks, including MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval,\nMixEval Hard, MATH, and CodeContests. Archon architectures outperform frontier\nmodels, such as GPT-4o and Claude 3.5 Sonnet, on these benchmarks, achieving an\naverage accuracy increase of 15.1 percentage points by using all available\nLLMs. We make our code and datasets available publicly on Github:\nhttps://github.com/ScalingIntelligence/Archon.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15254v5",
    "published_date": "2024-09-23 17:53:42 UTC",
    "updated_date": "2024-10-03 05:41:48 UTC"
  },
  {
    "arxiv_id": "2409.17179v2",
    "title": "Fully automatic extraction of morphological traits from the Web: utopia or reality?",
    "authors": [
      "Diego Marcos",
      "Robert van de Vlasakker",
      "Ioannis N. Athanasiadis",
      "Pierre Bonnet",
      "Hervé Goeau",
      "Alexis Joly",
      "W. Daniel Kissling",
      "César Leblanc",
      "André S. J. van Proosdij",
      "Konstantinos P. Panousis"
    ],
    "abstract": "Plant morphological traits, their observable characteristics, are fundamental\nto understand the role played by each species within their ecosystem. However,\ncompiling trait information for even a moderate number of species is a\ndemanding task that may take experts years to accomplish. At the same time,\nmassive amounts of information about species descriptions is available online\nin the form of text, although the lack of structure makes this source of data\nimpossible to use at scale. To overcome this, we propose to leverage recent\nadvances in large language models (LLMs) and devise a mechanism for gathering\nand processing information on plant traits in the form of unstructured textual\ndescriptions, without manual curation. We evaluate our approach by\nautomatically replicating three manually created species-trait matrices. Our\nmethod managed to find values for over half of all species-trait pairs, with an\nF1-score of over 75%. Our results suggest that large-scale creation of\nstructured trait databases from unstructured online text is currently feasible\nthanks to the information extraction capabilities of LLMs, being limited by the\navailability of textual descriptions covering all the traits of interest.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.17179v2",
    "published_date": "2024-09-23 17:40:24 UTC",
    "updated_date": "2025-02-21 15:48:32 UTC"
  },
  {
    "arxiv_id": "2409.15243v1",
    "title": "MACeIP: A Multimodal Ambient Context-enriched Intelligence Platform in Smart Cities",
    "authors": [
      "Truong Thanh Hung Nguyen",
      "Phuc Truong Loc Nguyen",
      "Monica Wachowicz",
      "Hung Cao"
    ],
    "abstract": "This paper presents a Multimodal Ambient Context-enriched Intelligence\nPlatform (MACeIP) for Smart Cities, a comprehensive system designed to enhance\nurban management and citizen engagement. Our platform integrates advanced\ntechnologies, including Internet of Things (IoT) sensors, edge and cloud\ncomputing, and Multimodal AI, to create a responsive and intelligent urban\necosystem. Key components include Interactive Hubs for citizen interaction, an\nextensive IoT sensor network, intelligent public asset management, a pedestrian\nmonitoring system, a City Planning Portal, and a Cloud Computing System. We\ndemonstrate the prototype of MACeIP in several cities, focusing on Fredericton,\nNew Brunswick. This work contributes to innovative city development by offering\na scalable, efficient, and user-centric approach to urban intelligence and\nmanagement.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 6 figures, IEEE/IEIE ICCE-Asia 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15243v1",
    "published_date": "2024-09-23 17:39:53 UTC",
    "updated_date": "2024-09-23 17:39:53 UTC"
  },
  {
    "arxiv_id": "2409.15241v1",
    "title": "Domino: Eliminating Communication in LLM Training via Generic Tensor Slicing and Overlapping",
    "authors": [
      "Guanhua Wang",
      "Chengming Zhang",
      "Zheyu Shen",
      "Ang Li",
      "Olatunji Ruwase"
    ],
    "abstract": "Given the popularity of generative AI, Large Language Models (LLMs) often\nconsume hundreds or thousands of GPUs for parallelizing and accelerating the\ntraining process. Communication overhead becomes more pronounced when training\nLLMs at scale. To eliminate communication overhead in distributed LLM training,\nwe propose Domino, which provides a generic scheme to hide communication behind\ncomputation. By breaking data dependency of a single batch training into\nsmaller independent pieces, Domino pipelines these independent pieces training\nand provides generic strategy of fine-grained communication and computation\noverlapping. Extensive results show that, comparing with Megatron-LM, Domino\nachieves up to 1.3x speedup for LLM training on Nvidia DGX-H100 GPUs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15241v1",
    "published_date": "2024-09-23 17:38:52 UTC",
    "updated_date": "2024-09-23 17:38:52 UTC"
  },
  {
    "arxiv_id": "2409.15240v2",
    "title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
    "authors": [
      "Junqing He",
      "Liang Zhu",
      "Rui Wang",
      "Xi Wang",
      "Reza Haffari",
      "Jiaxing Zhang"
    ],
    "abstract": "Long-term memory is important for chatbots and dialogue systems (DS) to\ncreate consistent and human-like conversations, evidenced by numerous developed\nmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,\nexisting commonly used evaluation metrics, like retrieval accuracy and\nperplexity (PPL), mainly focus on query-oriented factualness and language\nquality assessment. However, these metrics often lack practical value.\nMoreover, the evaluation dimensions are insufficient for human-like assessment\nin DS. Regarding memory-recalling paradigms, current evaluation schemes only\nconsider passive memory retrieval while ignoring diverse memory recall with\nrich triggering factors, e.g., emotions and surroundings, which can be\nessential in emotional support scenarios. To bridge the gap, we construct a\nnovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various\nmemory-recalling paradigms based on cognitive science and psychology theories.\nThe benchmark assesses two tasks separately: memory retrieval and memory\nrecognition with the incorporation of both passive and proactive memory recall\ndata. We introduce new scoring criteria to the evaluation, including memory\ninjection, emotion support (ES) proficiency, and intimacy, to comprehensively\nassess generated responses. Results from cutting-edge embedding models and\nlarge language models on this benchmark indicate the potential for further\nadvancement. Extensive testing further reveals correlations between memory\ninjection, ES proficiency, and intimacy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15240v2",
    "published_date": "2024-09-23 17:38:41 UTC",
    "updated_date": "2024-10-23 17:47:58 UTC"
  },
  {
    "arxiv_id": "2409.15228v3",
    "title": "A Comprehensive Framework for Evaluating API-oriented Code Generation in Large Language Models",
    "authors": [
      "Yixi Wu",
      "Pengfei He",
      "Zehao Wang",
      "Shaowei Wang",
      "Yuan Tian",
      "Tse-Hsun Chen"
    ],
    "abstract": "Large language models (LLMs) like GitHub Copilot and ChatGPT have emerged as\npowerful tools for code generation, significantly enhancing productivity and\naccelerating software development. However, existing benchmarks primarily focus\non general code generation without considering API-oriented code generation,\ni.e., generating code that invokes APIs from specific libraries. Given the\ngrowing demand for API-oriented code generation, there is a pressing need for a\nsystematic and automated approach to evaluate LLM on API-oriented code\ngeneration. To address this gap, we propose AutoAPIEval, a lightweight and\nautomated framework designed to evaluate the capabilities of LLMs in\nAPI-oriented code generation. Our framework works with any library that\nprovides API documentation and focuses on two unit tasks: API recommendation\nand code example generation, along with four metrics to evaluate the generated\nAPIs and code examples, such as the proportion of incorrect API recommendations\nfor Task 1, and the proportion of code examples where no specific API is\ninvoked and uncompilable/unexecutable code examples for Task 2. In addition, we\nconducted a case study on three LLMs (ChatGPT, MagiCoder, and DeepSeek Coder)\nand Java Runtime Environment 8 to demonstrate the framework's effectiveness.\nOur findings reveal substantial variability in LLM performance across tasks,\nwith ChatGPT adhering better to instructions, while sharing similar\neffectiveness in code example generation with its counterparts (i.e., MagiCoder\nand DeekSeek Coder). We also identify key factors associated with code quality,\nsuch as API popularity and model confidence, and build classifiers that achieve\nhigh accuracy in detecting incorrect API recommendations and erroneous code\nexamples. Retrieval-augmented generation enhances the quality of code generated\nby LLMs, though its effectiveness varies across different LLMs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15228v3",
    "published_date": "2024-09-23 17:22:09 UTC",
    "updated_date": "2024-09-26 14:57:52 UTC"
  },
  {
    "arxiv_id": "2409.15224v1",
    "title": "Enhancing Pedestrian Trajectory Prediction with Crowd Trip Information",
    "authors": [
      "Rei Tamaru",
      "Pei Li",
      "Bin Ran"
    ],
    "abstract": "Pedestrian trajectory prediction is essential for various applications in\nactive traffic management, urban planning, traffic control, crowd management,\nand autonomous driving, aiming to enhance traffic safety and efficiency.\nAccurately predicting pedestrian trajectories requires a deep understanding of\nindividual behaviors, social interactions, and road environments. Existing\nstudies have developed various models to capture the influence of social\ninteractions and road conditions on pedestrian trajectories. However, these\napproaches are limited by the lack of a comprehensive view of social\ninteractions and road environments. To address these limitations and enhance\nthe accuracy of pedestrian trajectory prediction, we propose a novel approach\nincorporating trip information as a new modality into pedestrian trajectory\nmodels. We propose RNTransformer, a generic model that utilizes crowd trip\ninformation to capture global information on social interactions. We\nincorporated RNTransformer with various socially aware local pedestrian\ntrajectory prediction models to demonstrate its performance. Specifically, by\nleveraging a pre-trained RNTransformer when training different pedestrian\ntrajectory prediction models, we observed improvements in performance metrics:\na 1.3/2.2% enhancement in ADE/FDE on Social-LSTM, a 6.5/28.4% improvement on\nSocial-STGCNN, and an 8.6/4.3% improvement on S-Implicit. Evaluation results\ndemonstrate that RNTransformer significantly enhances the accuracy of various\npedestrian trajectory prediction models across multiple datasets. Further\ninvestigation reveals that the RNTransformer effectively guides local models to\nmore accurate directions due to the consideration of global information. By\nexploring crowd behavior within the road network, our approach shows great\npromise in improving pedestrian safety through accurate trajectory predictions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15224v1",
    "published_date": "2024-09-23 17:11:31 UTC",
    "updated_date": "2024-09-23 17:11:31 UTC"
  },
  {
    "arxiv_id": "2410.05278v1",
    "title": "Dumpling GNN: Hybrid GNN Enables Better ADC Payload Activity Prediction Based on Chemical Structure",
    "authors": [
      "Shengjie Xu",
      "Lingxi Xie"
    ],
    "abstract": "Antibody-drug conjugates (ADCs) have emerged as a promising class of targeted\ncancer therapeutics, but the design and optimization of their cytotoxic\npayloads remain challenging. This study introduces DumplingGNN, a novel hybrid\nGraph Neural Network architecture specifically designed for predicting ADC\npayload activity based on chemical structure. By integrating Message Passing\nNeural Networks (MPNN), Graph Attention Networks (GAT), and GraphSAGE layers,\nDumplingGNN effectively captures multi-scale molecular features and leverages\nboth 2D topological and 3D structural information. We evaluate DumplingGNN on a\ncomprehensive ADC payload dataset focusing on DNA Topoisomerase I inhibitors,\nas well as on multiple public benchmarks from MoleculeNet. DumplingGNN achieves\nstate-of-the-art performance across several datasets, including BBBP (96.4\\%\nROC-AUC), ToxCast (78.2\\% ROC-AUC), and PCBA (88.87\\% ROC-AUC). On our\nspecialized ADC payload dataset, it demonstrates exceptional accuracy\n(91.48\\%), sensitivity (95.08\\%), and specificity (97.54\\%). Ablation studies\nconfirm the synergistic effects of the hybrid architecture and the critical\nrole of 3D structural information in enhancing predictive accuracy. The model's\nstrong interpretability, enabled by attention mechanisms, provides valuable\ninsights into structure-activity relationships. DumplingGNN represents a\nsignificant advancement in molecular property prediction, with particular\npromise for accelerating the design and optimization of ADC payloads in\ntargeted cancer therapy development.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05278v1",
    "published_date": "2024-09-23 17:11:04 UTC",
    "updated_date": "2024-09-23 17:11:04 UTC"
  },
  {
    "arxiv_id": "2409.15202v2",
    "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
    "authors": [
      "Iwo Naglik",
      "Mateusz Lango"
    ],
    "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "The 2024 Conference on Empirical Methods in Natural Language\n  Processing, November 12-16, Miami, Florida 9 pages, appendix, diagrams",
    "pdf_url": "http://arxiv.org/pdf/2409.15202v2",
    "published_date": "2024-09-23 16:49:47 UTC",
    "updated_date": "2024-10-04 06:09:15 UTC"
  },
  {
    "arxiv_id": "2409.15199v1",
    "title": "Learning from Contrastive Prompts: Automated Optimization and Adaptation",
    "authors": [
      "Mingqi Li",
      "Karan Aggarwal",
      "Yong Xie",
      "Aitzaz Ahmad",
      "Stephen Lau"
    ],
    "abstract": "As LLMs evolve, significant effort is spent on manually crafting prompts.\nWhile existing prompt optimization methods automate this process, they rely\nsolely on learning from incorrect samples, leading to a sub-optimal\nperformance. Additionally, an unexplored challenge in the literature is prompts\neffective for prior models may not perform well on newer versions or different\nlanguages. We propose the Learning from Contrastive Prompts (LCP) framework to\naddress these gaps, enhancing both prompt optimization and adaptation. LCP\nemploys contrastive learning to generate effective prompts by analyzing\npatterns in good and bad prompt examples. Our evaluation on the Big-Bench Hard\ndataset shows that LCP has a win rate of over 76% over existing methods in\nprompt optimization and demonstrates strong adaptability across different model\nversions, families, and languages. LCP offers a systematic approach to prompt\nengineering, reducing manual effort in deploying LLMs across varied contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15199v1",
    "published_date": "2024-09-23 16:47:23 UTC",
    "updated_date": "2024-09-23 16:47:23 UTC"
  },
  {
    "arxiv_id": "2409.15196v1",
    "title": "HOTVCOM: Generating Buzzworthy Comments for Videos",
    "authors": [
      "Yuyan Chen",
      "Yiwen Qian",
      "Songzhou Yan",
      "Jiyuan Jia",
      "Zhixu Li",
      "Yanghua Xiao",
      "Xiaobo Li",
      "Ming Yang",
      "Qingpei Guo"
    ],
    "abstract": "In the era of social media video platforms, popular ``hot-comments'' play a\ncrucial role in attracting user impressions of short-form videos, making them\nvital for marketing and branding purpose. However, existing research\npredominantly focuses on generating descriptive comments or ``danmaku'' in\nEnglish, offering immediate reactions to specific video moments. Addressing\nthis gap, our study introduces \\textsc{HotVCom}, the largest Chinese video\nhot-comment dataset, comprising 94k diverse videos and 137 million comments. We\nalso present the \\texttt{ComHeat} framework, which synergistically integrates\nvisual, auditory, and textual data to generate influential hot-comments on the\nChinese video dataset. Empirical evaluations highlight the effectiveness of our\nframework, demonstrating its excellence on both the newly constructed and\nexisting datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2409.15196v1",
    "published_date": "2024-09-23 16:45:13 UTC",
    "updated_date": "2024-09-23 16:45:13 UTC"
  },
  {
    "arxiv_id": "2410.03696v1",
    "title": "Improving Emotion Recognition Accuracy with Personalized Clustering",
    "authors": [
      "Laura Gutierrez-Martin",
      "Celia Lopez Ongil",
      "Jose M. Lanza-Gutierrez",
      "Jose A. Miranda Calero"
    ],
    "abstract": "Emotion recognition through artificial intelligence and smart sensing of\nphysical and physiological signals (Affective Computing) is achieving very\ninteresting results in terms of accuracy, inference times, and user-independent\nmodels. In this sense, there are applications related to the safety and\nwell-being of people (sexual aggressions, gender-based violence, children and\nelderly abuse, mental health, etc.) that require even more improvements.\nEmotion detection should be done with fast, discrete, and non-luxurious systems\nworking in real-time and real life (wearable devices, wireless communications,\nbattery-powered). Furthermore, emotional reactions to violence are not equal in\nall people. Then, large general models cannot be applied to a multiuser system\nfor people protection, and customized and simple AI models would be welcomed by\nhealth and social workers and law enforcement agents. These customized models\nwill be applicable to clusters of subjects sharing similarities in their\nemotional reactions to external stimuli. This customization requires several\nsteps: creating clusters of subjects with similar behaviors, creating AI models\nfor every cluster, continually updating these models with new data, and\nenrolling new subjects in clusters when required. A methodology for clustering\ndata compiled (physical and physiological data, together with emotional labels)\nis presented in this work, as well as the method for including new subjects\nonce the AI model is generated. Experimental results demonstrate an improvement\nof 4% in accuracy and 3% in f1-score w.r.t. the general model, along with a 14%\nreduction in variability.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.03696v1",
    "published_date": "2024-09-23 16:42:36 UTC",
    "updated_date": "2024-09-23 16:42:36 UTC"
  },
  {
    "arxiv_id": "2409.15186v2",
    "title": "Location is Key: Leveraging Large Language Model for Functional Bug Localization in Verilog",
    "authors": [
      "Bingkun Yao",
      "Ning Wang",
      "Jie Zhou",
      "Xi Wang",
      "Hong Gao",
      "Zhe Jiang",
      "Nan Guan"
    ],
    "abstract": "Bug localization in Verilog code is a crucial and time-consuming task during\nthe verification of hardware design. Since introduction, Large Language Models\n(LLMs) have showed their strong programming capabilities. However, no work has\nyet considered using LLMs for bug localization in Verilog code. This paper\npresents Location-is-Key, an opensource LLM solution to locate functional\nerrors in Verilog snippets. LiK achieves high localization accuracy, with a\npass@1 localization accuracy of 93.3% on our test dataset based on RTLLM,\nsurpassing GPT-4's 77.9% and comparable to Claude-3.5's 90.8%. Additionally,\nthe bug location obtained by LiK significantly improves GPT-3.5's bug repair\nefficiency (Functional pass@1 increased from 40.39% to 58.92%), highlighting\nthe importance of bug localization in LLM-based Verilog debugging. Compared to\nexisting methods, LiK only requires the design specification and the erroneous\ncode snippet, without the need for testbenches, assertions, or any other EDA\ntools. This research demonstrates the feasibility of using LLMs for Verilog\nerror localization, thus providing a new direction for automatic Verilog code\ndebugging.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15186v2",
    "published_date": "2024-09-23 16:38:53 UTC",
    "updated_date": "2024-09-29 07:35:24 UTC"
  },
  {
    "arxiv_id": "2409.15183v1",
    "title": "Chattronics: using GPTs to assist in the design of data acquisition systems",
    "authors": [
      "Jonathan Paul Driemeyer Brown",
      "Tiago Oliveira Weber"
    ],
    "abstract": "The usefulness of Large Language Models (LLM) is being continuously tested in\nvarious fields. However, their intrinsic linguistic characteristic is still one\nof the limiting factors when applying these models to exact sciences. In this\narticle, a novel approach to use General Pre-Trained Transformers to assist in\nthe design phase of data acquisition systems will be presented. The solution is\npackaged in the form of an application that retains the conversational aspects\nof LLMs, in such a manner that the user must provide details on the desired\nproject in order for the model to draft both a system-level architectural\ndiagram and the block-level specifications, following a Top-Down methodology\nbased on restrictions. To test this tool, two distinct user emulations were\nused, one of which uses an additional GPT model. In total, 4 different data\nacquisition projects were used in the testing phase, each with its own\nmeasurement requirements: angular position, temperature, acceleration and a\nfourth project with both pressure and superficial temperature measurements.\nAfter 160 test iterations, the study concludes that there is potential for\nthese models to serve adequately as synthesis/assistant tools for data\nacquisition systems, but there are still technological limitations. The results\nshow coherent architectures and topologies, but that GPTs have difficulties in\nsimultaneously considering all requirements and many times commits theoretical\nmistakes.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "eess.SP",
      "68T35",
      "I.2.1; J.6"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15183v1",
    "published_date": "2024-09-23 16:36:16 UTC",
    "updated_date": "2024-09-23 16:36:16 UTC"
  },
  {
    "arxiv_id": "2409.15182v2",
    "title": "Goal-based Neural Physics Vehicle Trajectory Prediction Model",
    "authors": [
      "Rui Gan",
      "Haotian Shi",
      "Pei Li",
      "Keshu Wu",
      "Bocheng An",
      "Linheng Li",
      "Junyi Ma",
      "Chengyuan Ma",
      "Bin Ran"
    ],
    "abstract": "Vehicle trajectory prediction plays a vital role in intelligent\ntransportation systems and autonomous driving, as it significantly affects\nvehicle behavior planning and control, thereby influencing traffic safety and\nefficiency. Numerous studies have been conducted to predict short-term vehicle\ntrajectories in the immediate future. However, long-term trajectory prediction\nremains a major challenge due to accumulated errors and uncertainties.\nAdditionally, balancing accuracy with interpretability in the prediction is\nanother challenging issue in predicting vehicle trajectory. To address these\nchallenges, this paper proposes a Goal-based Neural Physics Vehicle Trajectory\nPrediction Model (GNP). The GNP model simplifies vehicle trajectory prediction\ninto a two-stage process: determining the vehicle's goal and then choosing the\nappropriate trajectory to reach this goal. The GNP model contains two\nsub-modules to achieve this process. The first sub-module employs a multi-head\nattention mechanism to accurately predict goals. The second sub-module\nintegrates a deep learning model with a physics-based social force model to\nprogressively predict the complete trajectory using the generated goals. The\nGNP demonstrates state-of-the-art long-term prediction accuracy compared to\nfour baseline models. We provide interpretable visualization results to\nhighlight the multi-modality and inherent nature of our neural physics\nframework. Additionally, ablation studies are performed to validate the\neffectiveness of our key designs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15182v2",
    "published_date": "2024-09-23 16:35:43 UTC",
    "updated_date": "2024-09-25 04:31:22 UTC"
  },
  {
    "arxiv_id": "2409.15172v1",
    "title": "Skills Made to Order: Efficient Acquisition of Robot Cooking Skills Guided by Multiple Forms of Internet Data",
    "authors": [
      "Mrinal Verghese",
      "Christopher Atkeson"
    ],
    "abstract": "This study explores the utility of various internet data sources to select\namong a set of template robot behaviors to perform skills. Learning\ncontact-rich skills involving tool use from internet data sources has typically\nbeen challenging due to the lack of physical information such as contact\nexistence, location, areas, and force in this data. Prior works have generally\nused internet data and foundation models trained on this data to generate\nlow-level robot behavior. We hypothesize that these data and models may be\nbetter suited to selecting among a set of basic robot behaviors to perform\nthese contact-rich skills. We explore three methods of template selection:\nquerying large language models, comparing video of robot execution to retrieved\nhuman video using features from a pretrained video encoder common in prior\nwork, and performing the same comparison using features from an optic flow\nencoder trained on internet data. Our results show that LLMs are surprisingly\ncapable template selectors despite their lack of visual information, optical\nflow encoding significantly outperforms video encoders trained with an order of\nmagnitude more data, and important synergies exist between various forms of\ninternet data for template selection. By exploiting these synergies, we create\na template selector using multiple forms of internet data that achieves a 79\\%\nsuccess rate on a set of 16 different cooking skills involving tool-use.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15172v1",
    "published_date": "2024-09-23 16:25:44 UTC",
    "updated_date": "2024-09-23 16:25:44 UTC"
  },
  {
    "arxiv_id": "2409.15159v2",
    "title": "DRAPER: Towards a Robust Robot Deployment and Reliable Evaluation for Quasi-Static Pick-and-Place Cloth-Shaping Neural Controllers",
    "authors": [
      "Halid Abdulrahim Kadi",
      "Jose Alex Chandy",
      "Luis Figueredo",
      "Kasim Terzić",
      "Praminda Caleb-Solly"
    ],
    "abstract": "Comparing robotic cloth-manipulation systems in a real-world setup is\nchallenging. The fidelity gap between simulation-trained cloth neural\ncontrollers and real-world operation hinders the reliable deployment of these\nmethods in physical trials. Inconsistent experimental setups and hardware\nlimitations among different approaches obstruct objective evaluations. This\nstudy demonstrates a reliable real-world comparison of different\nsimulation-trained neural controllers on both flattening and folding tasks with\ndifferent types of fabrics varying in material, size, and colour. We introduce\nthe DRAPER framework to enable this comprehensive study, which reliably\nreflects the true capabilities of these neural controllers. It specifically\naddresses real-world grasping errors, such as misgrasping and multilayer\ngrasping, through real-world adaptations of the simulation environment to\nprovide data trajectories that closely reflect real-world grasping scenarios.\nIt also employs a special set of vision processing techniques to close the\nsimulation-to-reality gap in the perception. Furthermore, it achieves robust\ngrasping by adopting a tweezer-extended gripper and a grasping procedure. We\ndemonstrate DRAPER's generalisability across different deep-learning methods\nand robotic platforms, offering valuable insights to the cloth manipulation\nresearch community.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages main texts, 3 figures, and 4 tables. It is submitted to 2025\n  IEEE 21st International Conference on Automation Science and Engineering",
    "pdf_url": "http://arxiv.org/pdf/2409.15159v2",
    "published_date": "2024-09-23 16:08:16 UTC",
    "updated_date": "2025-03-14 23:15:09 UTC"
  },
  {
    "arxiv_id": "2409.15158v1",
    "title": "Automatic Feature Learning for Essence: a Case Study on Car Sequencing",
    "authors": [
      "Alessio Pellegrino",
      "Özgür Akgün",
      "Nguyen Dang",
      "Zeynep Kiziltan",
      "Ian Miguel"
    ],
    "abstract": "Constraint modelling languages such as Essence offer a means to describe\ncombinatorial problems at a high-level, i.e., without committing to detailed\nmodelling decisions for a particular solver or solving paradigm. Given a\nproblem description written in Essence, there are multiple ways to translate it\nto a low-level constraint model. Choosing the right combination of a low-level\nconstraint model and a target constraint solver can have significant impact on\nthe effectiveness of the solving process. Furthermore, the choice of the best\ncombination of constraint model and solver can be instance-dependent, i.e.,\nthere may not exist a single combination that works best for all instances of\nthe same problem. In this paper, we consider the task of building machine\nlearning models to automatically select the best combination for a problem\ninstance. A critical part of the learning process is to define instance\nfeatures, which serve as input to the selection model. Our contribution is\nautomatic learning of instance features directly from the high-level\nrepresentation of a problem instance using a language model. We evaluate the\nperformance of our approach using the Essence modelling language with a case\nstudy involving the car sequencing problem.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15158v1",
    "published_date": "2024-09-23 16:06:44 UTC",
    "updated_date": "2024-09-23 16:06:44 UTC"
  },
  {
    "arxiv_id": "2409.15155v1",
    "title": "MAR-DTN: Metal Artifact Reduction using Domain Transformation Network for Radiotherapy Planning",
    "authors": [
      "Belén Serrano-Antón",
      "Mubashara Rehman",
      "Niki Martinel",
      "Michele Avanzo",
      "Riccardo Spizzo",
      "Giuseppe Fanetti",
      "Alberto P. Muñuzuri",
      "Christian Micheloni"
    ],
    "abstract": "For the planning of radiotherapy treatments for head and neck cancers,\nComputed Tomography (CT) scans of the patients are typically employed. However,\nin patients with head and neck cancer, the quality of standard CT scans\ngenerated using kilo-Voltage (kVCT) tube potentials is severely degraded by\nstreak artifacts occurring in the presence of metallic implants such as dental\nfillings. Some radiotherapy devices offer the possibility of acquiring\nMega-Voltage CT (MVCT) for daily patient setup verification, due to the higher\nenergy of X-rays used, MVCT scans are almost entirely free from artifacts\nmaking them more suitable for radiotherapy treatment planning.\n  In this study, we leverage the advantages of kVCT scans with those of MVCT\nscans (artifact-free). We propose a deep learning-based approach capable of\ngenerating artifact-free MVCT images from acquired kVCT images. The outcome\noffers the benefits of artifact-free MVCT images with enhanced soft tissue\ncontrast, harnessing valuable information obtained through kVCT technology for\nprecise therapy calibration. Our proposed method employs UNet-inspired model,\nand is compared with adversarial learning and transformer networks. This first\nand unique approach achieves remarkable success, with PSNR of 30.02 dB across\nthe entire patient volume and 27.47 dB in artifact-affected regions\nexclusively. It is worth noting that the PSNR calculation excludes the\nbackground, concentrating solely on the region of interest.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted in 27th International Conference on Pattern Recognition\n  (ICPR). Mubashara Rehman and Bel\\'en Serrano-Ant\\'on, both co-first authors\n  of the manuscript",
    "pdf_url": "http://arxiv.org/pdf/2409.15155v1",
    "published_date": "2024-09-23 16:04:00 UTC",
    "updated_date": "2024-09-23 16:04:00 UTC"
  },
  {
    "arxiv_id": "2409.15154v1",
    "title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code",
    "authors": [
      "Jiachi Chen",
      "Qingyuan Zhong",
      "Yanlin Wang",
      "Kaiwen Ning",
      "Yongkun Liu",
      "Zenan Xu",
      "Zhe Zhao",
      "Ting Chen",
      "Zibin Zheng"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has significantly influenced\nvarious aspects of software development activities. Despite their benefits,\nLLMs also pose notable risks, including the potential to generate harmful\ncontent and being abused by malicious developers to create malicious code.\nSeveral previous studies have focused on the ability of LLMs to resist the\ngeneration of harmful content that violates human ethical standards, such as\nbiased or offensive content. However, there is no research evaluating the\nability of LLMs to resist malicious code generation. To fill this gap, we\npropose RMCBench, the first benchmark comprising 473 prompts designed to assess\nthe ability of LLMs to resist malicious code generation. This benchmark employs\ntwo scenarios: a text-to-code scenario, where LLMs are prompted with\ndescriptions to generate code, and a code-to-code scenario, where LLMs\ntranslate or complete existing malicious code. Based on RMCBench, we conduct an\nempirical study on 11 representative LLMs to assess their ability to resist\nmalicious code generation. Our findings indicate that current LLMs have a\nlimited ability to resist malicious code generation with an average refusal\nrate of 40.36% in text-to-code scenario and 11.52% in code-to-code scenario.\nThe average refusal rate of all LLMs in RMCBench is only 28.71%; ChatGPT-4 has\na refusal rate of only 35.73%. We also analyze the factors that affect LLMs'\nability to resist malicious code generation and provide implications for\ndevelopers to enhance model robustness.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.7; D.2.5; K.6.5"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 6 figures, 5 tables, 39th IEEE/ACM International Conference\n  on Automated Software Engineering (ASE '24)",
    "pdf_url": "http://arxiv.org/pdf/2409.15154v1",
    "published_date": "2024-09-23 16:03:26 UTC",
    "updated_date": "2024-09-23 16:03:26 UTC"
  },
  {
    "arxiv_id": "2409.15146v3",
    "title": "COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models",
    "authors": [
      "Kehui Liu",
      "Zixin Tang",
      "Dong Wang",
      "Zhigang Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "Leveraging the powerful reasoning capabilities of large language models\n(LLMs), recent LLM-based robot task planning methods yield promising results.\nHowever, they mainly focus on single or multiple homogeneous robots on simple\ntasks. Practically, complex long-horizon tasks always require collaboration\namong multiple heterogeneous robots especially with more complex action spaces,\nwhich makes these tasks more challenging. To this end, we propose COHERENT, a\nnovel LLM-based task planning framework for collaboration of heterogeneous\nmulti-robot systems including quadrotors, robotic dogs, and robotic arms.\nSpecifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is\ndesigned to decompose and assign actions for individual robots, where a\ncentralized task assigner makes a task planning proposal to decompose the\ncomplex task into subtasks, and then assigns subtasks to robot executors. Each\nrobot executor selects a feasible action to implement the assigned subtask and\nreports self-reflection feedback to the task assigner for plan adjustment. The\nPEFA loops until the task is completed. Moreover, we create a challenging\nheterogeneous multi-robot task planning benchmark encompassing 100 complex\nlong-horizon tasks. The experimental results show that our work surpasses the\nprevious methods by a large margin in terms of success rate and execution\nefficiency. The experimental videos, code, and benchmark are released at\nhttps://github.com/MrKeee/COHERENT.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15146v3",
    "published_date": "2024-09-23 15:53:41 UTC",
    "updated_date": "2025-03-29 14:57:20 UTC"
  },
  {
    "arxiv_id": "2409.15130v1",
    "title": "CAMAL: Optimizing LSM-trees via Active Learning",
    "authors": [
      "Weiping Yu",
      "Siqiang Luo",
      "Zihao Yu",
      "Gao Cong"
    ],
    "abstract": "We use machine learning to optimize LSM-tree structure, aiming to reduce the\ncost of processing various read/write operations. We introduce a new approach\nCamal, which boasts the following features: (1) ML-Aided: Camal is the first\nattempt to apply active learning to tune LSM-tree based key-value stores. The\nlearning process is coupled with traditional cost models to improve the\ntraining process; (2) Decoupled Active Learning: backed by rigorous analysis,\nCamal adopts active learning paradigm based on a decoupled tuning of each\nparameter, which further accelerates the learning process; (3) Easy\nExtrapolation: Camal adopts an effective mechanism to incrementally update the\nmodel with the growth of the data size; (4) Dynamic Mode: Camal is able to tune\nLSM-tree online under dynamically changing workloads; (5) Significant System\nImprovement: By integrating Camal into a full system RocksDB, the system\nperformance improves by 28% on average and up to 8x compared to a\nstate-of-the-art RocksDB design.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "SIGMOD 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15130v1",
    "published_date": "2024-09-23 15:35:23 UTC",
    "updated_date": "2024-09-23 15:35:23 UTC"
  },
  {
    "arxiv_id": "2409.15127v3",
    "title": "Pareto-Optimized Open-Source LLMs for Healthcare via Context Retrieval",
    "authors": [
      "Jordi Bayarri-Planas",
      "Ashwin Kumar Gururajan",
      "Dario Garcia-Gasulla"
    ],
    "abstract": "This study leverages optimized context retrieval to enhance open-source Large\nLanguage Models (LLMs) for cost-effective, high performance healthcare AI. We\ndemonstrate that this approach achieves state-of-the-art accuracy on medical\nquestion answering at a fraction of the cost of proprietary models,\nsignificantly improving the cost-accuracy Pareto frontier on the MedQA\nbenchmark. Key contributions include: (1) OpenMedQA, a novel benchmark\nrevealing a performance gap in open-ended medical QA compared to\nmultiple-choice formats; (2) a practical, reproducible pipeline for context\nretrieval optimization; and (3) open-source resources (Prompt Engine,\nCoT/ToT/Thinking databases) to empower healthcare AI development. By advancing\nretrieval techniques and QA evaluation, we enable more affordable and reliable\nLLM solutions for healthcare.",
    "categories": [
      "cs.AI",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures, 5 tables, Accepted for publication at the 21st\n  International Conference on Artificial Intelligence Applications and\n  Innovations (AIAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2409.15127v3",
    "published_date": "2024-09-23 15:33:38 UTC",
    "updated_date": "2025-04-03 09:05:45 UTC"
  },
  {
    "arxiv_id": "2409.15119v2",
    "title": "Log-normal Mutations and their Use in Detecting Surreptitious Fake Images",
    "authors": [
      "Ismail Labiad",
      "Thomas Bäck",
      "Pierre Fernandez",
      "Laurent Najman",
      "Tom Sander",
      "Furong Ye",
      "Mariia Zameshina",
      "Olivier Teytaud"
    ],
    "abstract": "In many cases, adversarial attacks are based on specialized algorithms\nspecifically dedicated to attacking automatic image classifiers. These\nalgorithms perform well, thanks to an excellent ad hoc distribution of initial\nattacks. However, these attacks are easily detected due to their specific\ninitial distribution. We therefore consider other black-box attacks, inspired\nfrom generic black-box optimization tools, and in particular the log-normal\nalgorithm.\n  We apply the log-normal method to the attack of fake detectors, and get\nsuccessful attacks: importantly, these attacks are not detected by detectors\nspecialized on classical adversarial attacks. Then, combining these attacks and\ndeep detection, we create improved fake detectors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "log-normal mutations and their use in detecting surreptitious fake\n  images",
    "pdf_url": "http://arxiv.org/pdf/2409.15119v2",
    "published_date": "2024-09-23 15:25:26 UTC",
    "updated_date": "2024-09-25 14:00:21 UTC"
  },
  {
    "arxiv_id": "2409.15114v3",
    "title": "Evaluating ML Robustness in GNSS Interference Classification, Characterization & Localization",
    "authors": [
      "Lucas Heublein",
      "Tobias Feigl",
      "Thorsten Nowak",
      "Alexander Rügamer",
      "Christopher Mutschler",
      "Felix Ott"
    ],
    "abstract": "Jamming devices disrupt signals from the global navigation satellite system\n(GNSS) and pose a significant threat, as they compromise the robustness of\naccurate positioning. The detection of anomalies within frequency snapshots is\ncrucial to counteract these interferences effectively. A critical preliminary\ncountermeasure involves the reliable classification of interferences and the\ncharacterization and localization of jamming devices. This paper introduces an\nextensive dataset comprising snapshots obtained from a low-frequency antenna\nthat capture various generated interferences within a large-scale environment,\nincluding controlled multipath effects. Our objective is to assess the\nresilience of machine learning (ML) models against environmental changes, such\nas multipath effects, variations in interference attributes, such as\ninterference class, bandwidth, and signal power, the accuracy of jamming device\nlocalization, and the constraints imposed by snapshot input lengths.\nFurthermore, we evaluate the performance of a diverse set of 129 distinct\nvision encoder models across all tasks. By analyzing the aleatoric and\nepistemic uncertainties, we demonstrate the adaptability of our model in\ngeneralizing across diverse facets, thus establishing its suitability for\nreal-world applications. Dataset:\nhttps://gitlab.cc-asp.fraunhofer.de/darcy_gnss/controlled_low_frequency",
    "categories": [
      "cs.AI",
      "94-05, 82-11",
      "E.0; I.2.0; I.5.4; I.5.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15114v3",
    "published_date": "2024-09-23 15:20:33 UTC",
    "updated_date": "2025-04-23 07:14:21 UTC"
  },
  {
    "arxiv_id": "2409.15112v2",
    "title": "ChatGPT as a Solver and Grader of Programming Exams written in Spanish",
    "authors": [
      "Pablo Saborido-Fernández",
      "Marcos Fernández-Pichel",
      "David E. Losada"
    ],
    "abstract": "Evaluating the capabilities of Large Language Models (LLMs) to assist\nteachers and students in educational tasks is receiving increasing attention.\nIn this paper, we assess ChatGPT's capacities to solve and grade real\nprogramming exams, from an accredited BSc degree in Computer Science, written\nin Spanish. Our findings suggest that this AI model is only effective for\nsolving simple coding tasks. Its proficiency in tackling complex problems or\nevaluating solutions authored by others are far from effective. As part of this\nresearch, we also release a new corpus of programming tasks and the\ncorresponding prompts for solving the problems or grading the solutions. This\nresource can be further exploited by other research teams.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15112v2",
    "published_date": "2024-09-23 15:20:07 UTC",
    "updated_date": "2025-03-20 12:11:30 UTC"
  },
  {
    "arxiv_id": "2409.15107v2",
    "title": "The BRAVO Semantic Segmentation Challenge Results in UNCV2024",
    "authors": [
      "Tuan-Hung Vu",
      "Eduardo Valle",
      "Andrei Bursuc",
      "Tommie Kerssies",
      "Daan de Geus",
      "Gijs Dubbelman",
      "Long Qian",
      "Bingke Zhu",
      "Yingying Chen",
      "Ming Tang",
      "Jinqiao Wang",
      "Tomáš Vojíř",
      "Jan Šochman",
      "Jiří Matas",
      "Michael Smith",
      "Frank Ferrie",
      "Shamik Basu",
      "Christos Sakaridis",
      "Luc Van Gool"
    ],
    "abstract": "We propose the unified BRAVO challenge to benchmark the reliability of\nsemantic segmentation models under realistic perturbations and unknown\nout-of-distribution (OOD) scenarios. We define two categories of reliability:\n(1) semantic reliability, which reflects the model's accuracy and calibration\nwhen exposed to various perturbations; and (2) OOD reliability, which measures\nthe model's ability to detect object classes that are unknown during training.\nThe challenge attracted nearly 100 submissions from international teams\nrepresenting notable research institutions. The results reveal interesting\ninsights into the importance of large-scale pre-training and minimal\narchitectural design in developing robust and reliable semantic segmentation\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024 proceeding paper of the BRAVO challenge 2024, see\n  https://benchmarks.elsa-ai.eu/?ch=1&com=introduction Corrected numbers in\n  Tables 1,3,4,5 and 10",
    "pdf_url": "http://arxiv.org/pdf/2409.15107v2",
    "published_date": "2024-09-23 15:17:30 UTC",
    "updated_date": "2024-10-09 15:09:47 UTC"
  },
  {
    "arxiv_id": "2409.15105v1",
    "title": "SPformer: A Transformer Based DRL Decision Making Method for Connected Automated Vehicles",
    "authors": [
      "Ye Han",
      "Lijun Zhang",
      "Dejian Meng",
      "Xingyu Hu",
      "Yixia Lu"
    ],
    "abstract": "In mixed autonomy traffic environment, every decision made by an\nautonomous-driving car may have a great impact on the transportation system.\nBecause of the complex interaction between vehicles, it is challenging to make\ndecisions that can ensure both high traffic efficiency and safety now and\nfuther. Connected automated vehicles (CAVs) have great potential to improve the\nquality of decision-making in this continuous, highly dynamic and interactive\nenvironment because of their stronger sensing and communicating ability. For\nmulti-vehicle collaborative decision-making algorithms based on deep\nreinforcement learning (DRL), we need to represent the interactions between\nvehicles to obtain interactive features. The representation in this aspect\ndirectly affects the learning efficiency and the quality of the learned policy.\nTo this end, we propose a CAV decision-making architecture based on transformer\nand reinforcement learning algorithms. A learnable policy token is used as the\nlearning medium of the multi-vehicle joint policy, the states of all vehicles\nin the area of interest can be adaptively noticed in order to extract\ninteractive features among agents. We also design an intuitive physical\npositional encodings, the redundant location information of which optimizes the\nperformance of the network. Simulations show that our model can make good use\nof all the state information of vehicles in traffic scenario, so as to obtain\nhigh-quality driving decisions that meet efficiency and safety objectives. The\ncomparison shows that our method significantly improves existing DRL-based\nmulti-vehicle cooperative decision-making algorithms.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15105v1",
    "published_date": "2024-09-23 15:16:35 UTC",
    "updated_date": "2024-09-23 15:16:35 UTC"
  },
  {
    "arxiv_id": "2409.15100v5",
    "title": "Robust Federated Learning Over the Air: Combating Heavy-Tailed Noise with Median Anchored Clipping",
    "authors": [
      "Jiaxing Li",
      "Zihan Chen",
      "Kai Fong Ernest Chong",
      "Bikramjit Das",
      "Tony Q. S. Quek",
      "Howard H. Yang"
    ],
    "abstract": "Leveraging over-the-air computations for model aggregation is an effective\napproach to cope with the communication bottleneck in federated edge learning.\nBy exploiting the superposition properties of multi-access channels, this\napproach facilitates an integrated design of communication and computation,\nthereby enhancing system privacy while reducing implementation costs. However,\nthe inherent electromagnetic interference in radio channels often exhibits\nheavy-tailed distributions, giving rise to exceptionally strong noise in\nglobally aggregated gradients that can significantly deteriorate the training\nperformance. To address this issue, we propose a novel gradient clipping\nmethod, termed Median Anchored Clipping (MAC), to combat the detrimental\neffects of heavy-tailed noise. We also derive analytical expressions for the\nconvergence rate of model training with analog over-the-air federated learning\nunder MAC, which quantitatively demonstrates the effect of MAC on training\nperformance. Extensive experimental results show that the proposed MAC\nalgorithm effectively mitigates the impact of heavy-tailed noise, hence\nsubstantially enhancing system robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This is the full version of the paper, and the appendix contains a\n  complete convergence analysis under non-convex conditions",
    "pdf_url": "http://arxiv.org/pdf/2409.15100v5",
    "published_date": "2024-09-23 15:11:40 UTC",
    "updated_date": "2025-03-19 18:17:04 UTC"
  },
  {
    "arxiv_id": "2409.15097v2",
    "title": "Efficiently Dispatching Flash Attention For Partially Filled Attention Masks",
    "authors": [
      "Agniv Sharma",
      "Jonas Geiping"
    ],
    "abstract": "Transformers are widely used across various applications, many of which yield\nsparse or partially filled attention matrices. Examples include attention masks\ndesigned to reduce the quadratic complexity of attention, sequence packing\ntechniques, and recent innovations like tree masking for fast validation in\nMEDUSA. Despite the inherent sparsity in these matrices, the state-of-the-art\nalgorithm Flash Attention still processes them with quadratic complexity as\nthough they were dense. In this paper, we introduce Binary Block Masking, a\nhighly efficient modification that enhances Flash Attention by making it\nmask-aware. We further propose two optimizations: one tailored for masks with\ncontiguous non-zero patterns and another for extremely sparse masks. Our\nexperiments on attention masks derived from real-world scenarios demonstrate up\nto a 9x runtime improvement. The implementation will be publicly released to\nfoster further research and application.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15097v2",
    "published_date": "2024-09-23 15:11:07 UTC",
    "updated_date": "2024-09-24 12:56:13 UTC"
  },
  {
    "arxiv_id": "2409.15095v2",
    "title": "Whole-Body Teleoperation for Mobile Manipulation at Zero Added Cost",
    "authors": [
      "Daniel Honerkamp",
      "Harsh Mahesheka",
      "Jan Ole von Hartz",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "abstract": "Demonstration data plays a key role in learning complex behaviors and\ntraining robotic foundation models. While effective control interfaces exist\nfor static manipulators, data collection remains cumbersome and time intensive\nfor mobile manipulators due to their large number of degrees of freedom. While\nspecialized hardware, avatars, or motion tracking can enable whole-body\ncontrol, these approaches are either expensive, robot-specific, or suffer from\nthe embodiment mismatch between robot and human demonstrator. In this work, we\npresent MoMa-Teleop, a novel teleoperation method that infers end-effector\nmotions from existing interfaces and delegates the base motions to a previously\ndeveloped reinforcement learning agent, leaving the operator to focus fully on\nthe task-relevant end-effector motions. This enables whole-body teleoperation\nof mobile manipulators with no additional hardware or setup costs via standard\ninterfaces such as joysticks or hand guidance. Moreover, the operator is not\nbound to a tracked workspace and can move freely with the robot over spatially\nextended tasks. We demonstrate that our approach results in a significant\nreduction in task completion time across a variety of robots and tasks. As the\ngenerated data covers diverse whole-body motions without embodiment mismatch,\nit enables efficient imitation learning. By focusing on task-specific\nend-effector motions, our approach learns skills that transfer to unseen\nsettings, such as new obstacles or changed object positions, from as little as\nfive demonstrations. We make code and videos available at\nhttps://moma-teleop.cs.uni-freiburg.de.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Website: https://moma-teleop.cs.uni-freiburg.de",
    "pdf_url": "http://arxiv.org/pdf/2409.15095v2",
    "published_date": "2024-09-23 15:09:45 UTC",
    "updated_date": "2025-02-10 10:50:14 UTC"
  },
  {
    "arxiv_id": "2409.15092v4",
    "title": "M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images",
    "authors": [
      "Hongyi Wang",
      "Xiuju Du",
      "Jing Liu",
      "Shuyi Ouyang",
      "Yen-Wei Chen",
      "Lanfen Lin"
    ],
    "abstract": "The advancement of Spatial Transcriptomics (ST) has facilitated the\nspatially-aware profiling of gene expressions based on histopathology images.\nAlthough ST data offers valuable insights into the micro-environment of tumors,\nits acquisition cost remains expensive. Therefore, directly predicting the ST\nexpressions from digital pathology images is desired. Current methods usually\nadopt existing regression backbones along with patch-sampling for this task,\nwhich ignores the inherent multi-scale information embedded in the pyramidal\ndata structure of digital pathology images, and wastes the inter-spot visual\ninformation crucial for accurate gene expression prediction. To address these\nlimitations, we propose M2OST, a many-to-one regression Transformer that can\naccommodate the hierarchical structure of the pathology images via a decoupled\nmulti-scale feature extractor. Unlike traditional models that are trained with\none-to-one image-label pairs, M2OST uses multiple images from different levels\nof the digital pathology image to jointly predict the gene expressions in their\ncommon corresponding spot. Built upon our many-to-one scheme, M2OST can be\neasily scaled to fit different numbers of inputs, and its network structure\ninherently incorporates nearby inter-spot features, enhancing regression\nperformance. We have tested M2OST on three public ST datasets and the\nexperimental results show that M2OST can achieve state-of-the-art performance\nwith fewer parameters and floating-point operations (FLOPs).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Improved from our previous unpublished work arXiv:2401.10608. arXiv\n  admin note: substantial text overlap with arXiv:2401.10608",
    "pdf_url": "http://arxiv.org/pdf/2409.15092v4",
    "published_date": "2024-09-23 15:06:37 UTC",
    "updated_date": "2024-12-20 06:19:10 UTC"
  },
  {
    "arxiv_id": "2409.15076v1",
    "title": "Enhancing Scientific Reproducibility Through Automated BioCompute Object Creation Using Retrieval-Augmented Generation from Publications",
    "authors": [
      "Sean Kim",
      "Raja Mazumder"
    ],
    "abstract": "The exponential growth in computational power and accessibility has\ntransformed the complexity and scale of bioinformatics research, necessitating\nstandardized documentation for transparency, reproducibility, and regulatory\ncompliance. The IEEE BioCompute Object (BCO) standard addresses this need but\nfaces adoption challenges due to the overhead of creating compliant\ndocumentation, especially for legacy research. This paper presents a novel\napproach to automate the creation of BCOs from scientific papers using\nRetrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We\ndescribe the development of the BCO assistant tool that leverages RAG to\nextract relevant information from source papers and associated code\nrepositories, addressing key challenges such as LLM hallucination and\nlong-context understanding. The implementation incorporates optimized retrieval\nprocesses, including a two-pass retrieval with re-ranking, and employs\ncarefully engineered prompts for each BCO domain. We discuss the tool's\narchitecture, extensibility, and evaluation methods, including automated and\nmanual assessment approaches. The BCO assistant demonstrates the potential to\nsignificantly reduce the time and effort required for retroactive documentation\nof bioinformatics research while maintaining compliance with the standard. This\napproach opens avenues for AI-assisted scientific documentation and knowledge\nextraction from publications thereby enhancing scientific reproducibility. The\nBCO assistant tool and documentation is available at\nhttps://biocompute-objects.github.io/bco-rag/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.OT"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15076v1",
    "published_date": "2024-09-23 14:51:22 UTC",
    "updated_date": "2024-09-23 14:51:22 UTC"
  },
  {
    "arxiv_id": "2409.15052v1",
    "title": "Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual Conversations for Cross-Lingual Image Captioning",
    "authors": [
      "Siddharth Betala",
      "Ishan Chokshi"
    ],
    "abstract": "In this paper, we describe our system under the team name Brotherhood for the\nEnglish-to-Lowres Multi-Modal Translation Task. We participate in the\nmulti-modal translation tasks for English-Hindi, English-Hausa,\nEnglish-Bengali, and English-Malayalam language pairs. We present a method\nleveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and\nClaude 3.5 Sonnet, to enhance cross-lingual image captioning without\ntraditional training or fine-tuning. Our approach utilizes instruction-tuned\nprompting to generate rich, contextual conversations about cropped images,\nusing their English captions as additional context. These synthetic\nconversations are then translated into the target languages. Finally, we employ\na weighted prompting strategy, balancing the original English caption with the\ntranslated conversation to generate captions in the target language. This\nmethod achieved competitive results, scoring 37.90 BLEU on the English-Hindi\nChallenge Set and ranking first and second for English-Hausa on the Challenge\nand Evaluation Leaderboards, respectively. We conduct additional experiments on\na subset of 250 images, exploring the trade-offs between BLEU scores and\nsemantic similarity across various weighting schemes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the Ninth Conference on Machine Translation (WMT24),\n  co-located with EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15052v1",
    "published_date": "2024-09-23 14:29:46 UTC",
    "updated_date": "2024-09-23 14:29:46 UTC"
  },
  {
    "arxiv_id": "2409.15051v1",
    "title": "Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task",
    "authors": [
      "Gaëtan Caillaut",
      "Raheel Qader",
      "Mariam Nakhlé",
      "Jingshu Liu",
      "Jean-Gabriel Barthélemy"
    ],
    "abstract": "Recent studies have showcased remarkable capabilities of decoder-only models\nin many NLP tasks, including translation. Yet, the machine translation field\nhas been largely dominated by encoder-decoder models based on the Transformer\narchitecture. As a consequence, scaling laws of encoder-decoder models for\nneural machine translation have already been well studied, but decoder-only\nmodels have received less attention. This work explores the scaling laws of\ndecoder-only models on the multilingual and multidomain translation task. We\ntrained a collection of six decoder-only models, ranging from 70M to 7B\nparameters, on a sentence-level, multilingual and multidomain dataset. We\nconducted a series of experiments showing that the loss of decoder-only models\ncan be estimated using a scaling law similar to the one discovered for large\nlanguage models, but we also show that this scaling law has difficulties to\ngeneralize to too large models or to a different data distribution. We also\nstudy different scaling methods and show that scaling the depth and the width\nof a model lead to similar test loss improvements, but with different impact on\nthe model's efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15051v1",
    "published_date": "2024-09-23 14:26:01 UTC",
    "updated_date": "2024-09-23 14:26:01 UTC"
  },
  {
    "arxiv_id": "2409.15046v1",
    "title": "AlphaZip: Neural Network-Enhanced Lossless Text Compression",
    "authors": [
      "Swathi Shree Narashiman",
      "Nitin Chandrachoodan"
    ],
    "abstract": "Data compression continues to evolve, with traditional information theory\nmethods being widely used for compressing text, images, and videos. Recently,\nthere has been growing interest in leveraging Generative AI for predictive\ncompression techniques. This paper introduces a lossless text compression\napproach using a Large Language Model (LLM). The method involves two key steps:\nfirst, prediction using a dense neural network architecture, such as a\ntransformer block; second, compressing the predicted ranks with standard\ncompression algorithms like Adaptive Huffman, LZ77, or Gzip. Extensive analysis\nand benchmarking against conventional information-theoretic baselines\ndemonstrate that neural compression offers improved performance.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15046v1",
    "published_date": "2024-09-23 14:21:06 UTC",
    "updated_date": "2024-09-23 14:21:06 UTC"
  },
  {
    "arxiv_id": "2409.15028v1",
    "title": "Region Mixup",
    "authors": [
      "Saptarshi Saha",
      "Utpal Garain"
    ],
    "abstract": "This paper introduces a simple extension of mixup (Zhang et al., 2018) data\naugmentation to enhance generalization in visual recognition tasks. Unlike the\nvanilla mixup method, which blends entire images, our approach focuses on\ncombining regions from multiple images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a Tiny Paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15028v1",
    "published_date": "2024-09-23 13:55:16 UTC",
    "updated_date": "2024-09-23 13:55:16 UTC"
  },
  {
    "arxiv_id": "2409.15027v1",
    "title": "Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19",
    "authors": [
      "Mohammad Amin Roshani",
      "Xiangyu Zhou",
      "Yao Qiang",
      "Srinivasan Suresh",
      "Steve Hicks",
      "Usha Sethuraman",
      "Dongxiao Zhu"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language tasks and are increasingly being applied in healthcare\ndomains. This work demonstrates a new LLM-powered disease risk assessment\napproach via streaming human-AI conversation, eliminating the need for\nprogramming required by traditional machine learning approaches. In a COVID-19\nseverity risk assessment case study, we fine-tune pre-trained generative LLMs\n(e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language\nexamples, comparing their performance with traditional classifiers (i.e.,\nLogistic Regression, XGBoost, Random Forest) that are trained de novo using\ntabular data across various experimental settings. We develop a mobile\napplication that uses these fine-tuned LLMs as its generative AI (GenAI) core\nto facilitate real-time interaction between clinicians and patients, providing\nno-code risk assessment through conversational interfaces. This integration not\nonly allows for the use of streaming Questions and Answers (QA) as inputs but\nalso offers personalized feature importance analysis derived from the LLM's\nattention layers, enhancing the interpretability of risk assessments. By\nachieving high Area Under the Curve (AUC) scores with a limited number of\nfine-tuning samples, our results demonstrate the potential of generative LLMs\nto outperform discriminative classification methods in low-data regimes,\nhighlighting their real-world adaptability and effectiveness. This work aims to\nfill the existing gap in leveraging generative LLMs for interactive no-code\nrisk assessment and to encourage further research in this emerging field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15027v1",
    "published_date": "2024-09-23 13:55:13 UTC",
    "updated_date": "2024-09-23 13:55:13 UTC"
  },
  {
    "arxiv_id": "2409.15022v1",
    "title": "A Diagonal Structured State Space Model on Loihi 2 for Efficient Streaming Sequence Processing",
    "authors": [
      "Svea Marie Meyer",
      "Philipp Weidel",
      "Philipp Plank",
      "Leobardo Campos-Macias",
      "Sumit Bam Shrestha",
      "Philipp Stratmann",
      "Mathis Richter"
    ],
    "abstract": "Deep State-Space Models (SSM) demonstrate state-of-the art performance on\nlong-range sequence modeling tasks. While the recurrent structure of SSMs can\nbe efficiently implemented as a convolution or as a parallel scan during\ntraining, recurrent token-by-token processing cannot currently be implemented\nefficiently on GPUs. Here, we demonstrate efficient token-by-token inference of\nthe SSM S4D on Intel's Loihi 2 state-of-the-art neuromorphic processor. We\ncompare this first ever neuromorphic-hardware implementation of an SSM on\nsMNIST, psMNIST, and sCIFAR to a recurrent and a convolutional implementation\nof S4D on Jetson Orin Nano (Jetson). While we find Jetson to perform better in\nan offline sample-by-sample based batched processing mode, Loihi 2 outperforms\nduring token-by-token based processing, where it consumes 1000 times less\nenergy with a 75 times lower latency and a 75 times higher throughput compared\nto the recurrent implementation of S4D on Jetson. This opens up new avenues\ntowards efficient real-time streaming applications of SSMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15022v1",
    "published_date": "2024-09-23 13:50:11 UTC",
    "updated_date": "2024-09-23 13:50:11 UTC"
  },
  {
    "arxiv_id": "2409.15014v2",
    "title": "Acting for the Right Reasons: Creating Reason-Sensitive Artificial Moral Agents",
    "authors": [
      "Kevin Baum",
      "Lisa Dargasz",
      "Felix Jahn",
      "Timo P. Gros",
      "Verena Wolf"
    ],
    "abstract": "We propose an extension of the reinforcement learning architecture that\nenables moral decision-making of reinforcement learning agents based on\nnormative reasons. Central to this approach is a reason-based shield generator\nyielding a moral shield that binds the agent to actions that conform with\nrecognized normative reasons so that our overall architecture restricts the\nagent to actions that are (internally) morally justified. In addition, we\ndescribe an algorithm that allows to iteratively improve the reason-based\nshield generator through case-based feedback from a moral judge.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures, Workshop paper accepted to FEAR24 (IFM Workshop)",
    "pdf_url": "http://arxiv.org/pdf/2409.15014v2",
    "published_date": "2024-09-23 13:38:57 UTC",
    "updated_date": "2024-10-25 12:28:13 UTC"
  },
  {
    "arxiv_id": "2409.15013v1",
    "title": "Analogous Alignments: Digital \"Formally\" meets Analog",
    "authors": [
      "Hansa Mohanty",
      "Deepak Narayan Gadde"
    ],
    "abstract": "The complexity of modern-day System-on-Chips (SoCs) is continually\nincreasing, and it becomes increasingly challenging to deliver dependable and\ncredible chips in a short time-to-market. Especially, in the case of test\nchips, where the aim is to study the feasibility of the design, time is a\ncrucial factor. Pre-silicon functional verification is one of the main\ncontributors that makes up a large portion of the product development cycle.\nVerification engineers often loosely verify test chips that turn out to be\nnon-functional on the silicon, ultimately resulting in expensive re-spins. To\nleft-shift the verification efforts, formal verification is a powerful\nmethodology that aims to exhaustively verify designs, giving better confidence\nin the overall quality. This paper focuses on the pragmatic formal verification\nof a mixed signal Intellectual Property (IP) that has a combination of digital\nand analog blocks. This paper discusses a novel approach of including the\nanalog behavioral model into the formal verification setup. Digital and Analog\nMixed-Signal (AMS) designs, which are fundamentally different in nature, are\nintegrated seamlessly in a formal verification setup, a concept that can be\nreferred to as \"Analogous Alignments\". Our formal setup leverages powerful\nformal techniques such as FPV, CSR verification, and connectivity checks. The\nproperties used for FPV are auto-generated using a metamodeling framework. The\npaper also discusses the challenges faced especially related to state-space\nexplosion, non-compatibility of formal with AMS models, and techniques to\nmitigate them such as k-induction. With this verification approach, we were\nable to exhaustively verify the design within a reasonable time and with\nsufficient coverage. We also reported several bugs at an early stage, making\nthe complete design verification process iterative and effective.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at the Design and Verification Conference\n  and Exhibition (DVCon) Europe, Munich, Germany, 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15013v1",
    "published_date": "2024-09-23 13:38:31 UTC",
    "updated_date": "2024-09-23 13:38:31 UTC"
  },
  {
    "arxiv_id": "2409.15012v1",
    "title": "Inference-Friendly Models With MixAttention",
    "authors": [
      "Shashank Rajput",
      "Ying Sheng",
      "Sean Owen",
      "Vitaliy Chiley"
    ],
    "abstract": "The size of the key-value (KV) cache plays a critical role in determining\nboth the maximum context length and the number of concurrent requests supported\nduring inference in modern language models. The KV cache size grows\nproportionally with the number of attention heads and the tokens processed,\nleading to increased memory consumption and slower inference for long inputs.\nIn this work, we explore the use of MixAttention, a model architecture\nmodification closely related to a blog published by Character.AI. MixAttention\ncombines sliding window attention, where only a small subset of recent tokens\nis stored in the KV cache, with KV cache sharing across layers. Our experiments\ndemonstrate that MixAttention significantly reduces memory usage and improves\ninference speed without sacrificing model performance in both short and\nlong-context tasks. We also explore various configurations of this\narchitecture, identifying those that maintain quality across evaluation metrics\nwhile optimizing resource efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15012v1",
    "published_date": "2024-09-23 13:37:25 UTC",
    "updated_date": "2024-09-23 13:37:25 UTC"
  },
  {
    "arxiv_id": "2409.15006v1",
    "title": "Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network",
    "authors": [
      "Sijia Du",
      "Chengfeng Zhou",
      "Suncheng Xiang",
      "Jianwei Xu",
      "Dahong Qian"
    ],
    "abstract": "Objective: Depth estimation is crucial for endoscopic navigation and\nmanipulation, but obtaining ground-truth depth maps in real clinical scenarios,\nsuch as the colon, is challenging. This study aims to develop a robust\nframework that generalizes well to real colonoscopy images, overcoming\nchallenges like non-Lambertian surface reflection and diverse data\ndistributions. Methods: We propose a framework combining a convolutional neural\nnetwork (CNN) for capturing local features and a Transformer for capturing\nglobal information. An uncertainty-based fusion block was designed to enhance\ngeneralization by identifying complementary contributions from the CNN and\nTransformer branches. The network can be trained with simulated datasets and\ngeneralize directly to unseen clinical data without any fine-tuning. Results:\nOur method is validated on multiple datasets and demonstrates an excellent\ngeneralization ability across various datasets and anatomical structures.\nFurthermore, qualitative analysis in real clinical scenarios confirmed the\nrobustness of the proposed method. Conclusion: The integration of local and\nglobal features through the CNN-Transformer architecture, along with the\nuncertainty-based fusion block, improves depth estimation performance and\ngeneralization in both simulated and real-world endoscopic environments.\nSignificance: This study offers a novel approach to estimate depth maps for\nendoscopy images despite the complex conditions in clinic, serving as a\nfoundation for endoscopic automatic navigation and other clinical tasks, such\nas polyp detection and segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15006v1",
    "published_date": "2024-09-23 13:30:59 UTC",
    "updated_date": "2024-09-23 13:30:59 UTC"
  },
  {
    "arxiv_id": "2409.15005v2",
    "title": "Method of Equal Shares with Bounded Overspending",
    "authors": [
      "Georgios Papasotiropoulos",
      "Seyedeh Zeinab Pishbin",
      "Oskar Skibski",
      "Piotr Skowron",
      "Tomasz Wąs"
    ],
    "abstract": "In participatory budgeting (PB), voters decide through voting which subset of\nprojects to fund within a given budget. Proportionality in the context of PB is\ncrucial to ensure equal treatment of all groups of voters. However, pure\nproportional rules can sometimes lead to suboptimal outcomes. We introduce the\nMethod of Equal Shares with Bounded Overspending (BOS Equal Shares), a robust\nvariant of Equal Shares that balances proportionality and efficiency. BOS Equal\nShares addresses inefficiencies implied by strict proportionality axioms, yet\nthe rule still provides fairness guarantees, similar to the original Method of\nEqual Shares. Our extensive empirical analysis on real-world PB instances shows\nexcellent performance of BOS Equal Shares across several metrics. In the course\nof the analysis, we also present and examine a fractional variant of the Method\nof Equal Shares which allows for partial funding of projects.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15005v2",
    "published_date": "2024-09-23 13:30:25 UTC",
    "updated_date": "2025-02-24 19:24:04 UTC"
  },
  {
    "arxiv_id": "2409.15004v1",
    "title": "ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from Unstructured Financial Documents",
    "authors": [
      "Furkan Pala",
      "Mehmet Yasin Akpınar",
      "Onur Deniz",
      "Gülşen Eryiğit"
    ],
    "abstract": "Multimodal key information extraction (KIE) models have been studied\nextensively on semi-structured documents. However, their investigation on\nunstructured documents is an emerging research topic. The paper presents an\napproach to adapt a multimodal transformer (i.e., ViBERTgrid previously\nexplored on semi-structured documents) for unstructured financial documents, by\nincorporating a BiLSTM-CRF layer. The proposed ViBERTgrid BiLSTM-CRF model\ndemonstrates a significant improvement in performance (up to 2 percentage\npoints) on named entity recognition from unstructured documents in financial\ndomain, while maintaining its KIE performance on semi-structured documents. As\nan additional contribution, we publicly released token-level annotations for\nthe SROIE dataset in order to pave the way for its use in multimodal sequence\nlabeling models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in MIDAS (The 8th Workshop on MIning DAta for financial\n  applicationS) workshop of ECML PKDD 2023 conference",
    "pdf_url": "http://arxiv.org/pdf/2409.15004v1",
    "published_date": "2024-09-23 13:28:06 UTC",
    "updated_date": "2024-09-23 13:28:06 UTC"
  },
  {
    "arxiv_id": "2409.14993v1",
    "title": "Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond",
    "authors": [
      "Hong Chen",
      "Xin Wang",
      "Yuwei Zhou",
      "Bin Huang",
      "Yipeng Zhang",
      "Wei Feng",
      "Houlun Chen",
      "Zeyang Zhang",
      "Siao Tang",
      "Wenwu Zhu"
    ],
    "abstract": "Multi-modal generative AI has received increasing attention in both academia\nand industry. Particularly, two dominant families of techniques are: i) The\nmulti-modal large language model (MLLM) such as GPT-4V, which shows impressive\nability for multi-modal understanding; ii) The diffusion model such as Sora,\nwhich exhibits remarkable multi-modal powers, especially with respect to visual\ngeneration. As such, one natural question arises: Is it possible to have a\nunified model for both understanding and generation? To answer this question,\nin this paper, we first provide a detailed review of both MLLM and diffusion\nmodels, including their probabilistic modeling procedure, multi-modal\narchitecture design, and advanced applications to image/video large language\nmodels as well as text-to-image/video generation. Then, we discuss the two\nimportant questions on the unified model: i) whether the unified model should\nadopt the auto-regressive or diffusion probabilistic modeling, and ii) whether\nthe model should utilize a dense architecture or the Mixture of Experts(MoE)\narchitectures to better support generation and understanding, two objectives.\nWe further provide several possible strategies for building a unified model and\nanalyze their potential advantages and disadvantages. We also summarize\nexisting large-scale multi-modal datasets for better model pretraining in the\nfuture. To conclude the paper, we present several challenging future\ndirections, which we believe can contribute to the ongoing advancement of\nmulti-modal generative AI.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14993v1",
    "published_date": "2024-09-23 13:16:09 UTC",
    "updated_date": "2024-09-23 13:16:09 UTC"
  },
  {
    "arxiv_id": "2409.14986v1",
    "title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others in Conversation Forecasting",
    "authors": [
      "Anthony Sicilia",
      "Malihe Alikhani"
    ],
    "abstract": "Typically, when evaluating Theory of Mind, we consider the beliefs of others\nto be binary: held or not held. But what if someone is unsure about their own\nbeliefs? How can we quantify this uncertainty? We propose a new suite of tasks,\nchallenging language models (LMs) to model the uncertainty of others in\ndialogue. We design these tasks around conversation forecasting, wherein an\nagent forecasts an unobserved outcome to a conversation. Uniquely, we view\ninterlocutors themselves as forecasters, asking an LM to predict the\nuncertainty of the interlocutors (a probability). We experiment with re-scaling\nmethods, variance reduction strategies, and demographic context, for this\nregression task, conducting experiments on three dialogue corpora (social,\nnegotiation, task-oriented) with eight LMs. While LMs can explain up to 7%\nvariance in the uncertainty of others, we highlight the difficulty of the tasks\nand room for future work, especially in practical applications, like\nanticipating ``false",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14986v1",
    "published_date": "2024-09-23 13:05:25 UTC",
    "updated_date": "2024-09-23 13:05:25 UTC"
  },
  {
    "arxiv_id": "2409.14985v2",
    "title": "Sparse-to-Dense LiDAR Point Generation by LiDAR-Camera Fusion for 3D Object Detection",
    "authors": [
      "Minseung Lee",
      "Seokha Moon",
      "Seung Joon Lee",
      "Jinkyu Kim"
    ],
    "abstract": "Accurately detecting objects at long distances remains a critical challenge\nin 3D object detection when relying solely on LiDAR sensors due to the inherent\nlimitations of data sparsity. To address this issue, we propose the\nLiDAR-Camera Augmentation Network (LCANet), a novel framework that reconstructs\nLiDAR point cloud data by fusing 2D image features, which contain rich semantic\ninformation, generating additional points to improve detection accuracy. LCANet\nfuses data from LiDAR sensors and cameras by projecting image features into the\n3D space, integrating semantic information into the point cloud data. This\nfused data is then encoded to produce 3D features that contain both semantic\nand spatial information, which are further refined to reconstruct final points\nbefore bounding box prediction. This fusion effectively compensates for LiDAR's\nweakness in detecting objects at long distances, which are often represented by\nsparse points. Additionally, due to the sparsity of many objects in the\noriginal dataset, which makes effective supervision for point generation\nchallenging, we employ a point cloud completion network to create a complete\npoint cloud dataset that supervises the generation of dense point clouds in our\nnetwork. Extensive experiments on the KITTI and Waymo datasets demonstrate that\nLCANet significantly outperforms existing models, particularly in detecting\nsparse and distant objects.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.14985v2",
    "published_date": "2024-09-23 13:03:31 UTC",
    "updated_date": "2024-09-24 16:20:30 UTC"
  },
  {
    "arxiv_id": "2409.14983v2",
    "title": "Dynamic Integration of Task-Specific Adapters for Class Incremental Learning",
    "authors": [
      "Jiashuo Li",
      "Shaokun Wang",
      "Bo Qian",
      "Yuhang He",
      "Xing Wei",
      "Qiang Wang",
      "Yihong Gong"
    ],
    "abstract": "Non-exemplar class Incremental Learning (NECIL) enables models to\ncontinuously acquire new classes without retraining from scratch and storing\nold task exemplars, addressing privacy and storage issues. However, the absence\nof data from earlier tasks exacerbates the challenge of catastrophic forgetting\nin NECIL. In this paper, we propose a novel framework called Dynamic\nIntegration of task-specific Adapters (DIA), which comprises two key\ncomponents: Task-Specific Adapter Integration (TSAI) and Patch-Level Model\nAlignment. TSAI boosts compositionality through a patch-level adapter\nintegration strategy, which provides a more flexible compositional solution\nwhile maintaining low computation costs. Patch-Level Model Alignment maintains\nfeature consistency and accurate decision boundaries via two specialized\nmechanisms: Patch-Level Distillation Loss (PDL) and Patch-Level Feature\nReconstruction method (PFR). Specifically, the PDL preserves feature-level\nconsistency between successive models by implementing a distillation loss based\non the contributions of patch tokens to new class learning. The PFR facilitates\naccurate classifier alignment by reconstructing old class features from\nprevious tasks that adapt to new task knowledge. Extensive experiments validate\nthe effectiveness of our DIA, revealing significant improvements on benchmark\ndatasets in the NECIL setting, maintaining an optimal balance between\ncomputational complexity and accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14983v2",
    "published_date": "2024-09-23 13:01:33 UTC",
    "updated_date": "2025-04-27 11:43:58 UTC"
  },
  {
    "arxiv_id": "2409.14981v1",
    "title": "On The Specialization of Neural Modules",
    "authors": [
      "Devon Jarvis",
      "Richard Klein",
      "Benjamin Rosman",
      "Andrew M. Saxe"
    ],
    "abstract": "A number of machine learning models have been proposed with the goal of\nachieving systematic generalization: the ability to reason about new situations\nby combining aspects of previous experiences. These models leverage\ncompositional architectures which aim to learn specialized modules dedicated to\nstructures in a task that can be composed to solve novel problems with similar\nstructures. While the compositionality of these architectures is guaranteed by\ndesign, the modules specializing is not. Here we theoretically study the\nability of network modules to specialize to useful structures in a dataset and\nachieve systematic generalization. To this end we introduce a minimal space of\ndatasets motivated by practical systematic generalization benchmarks. From this\nspace of datasets we present a mathematical definition of systematicity and\nstudy the learning dynamics of linear neural modules when solving components of\nthe task. Our results shed light on the difficulty of module specialization,\nwhat is required for modules to successfully specialize, and the necessity of\nmodular architectures to achieve systematicity. Finally, we confirm that the\ntheoretical results in our tractable setting generalize to more complex\ndatasets and non-linear architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The Eleventh International Conference on Learning Representations\n  2023",
    "pdf_url": "http://arxiv.org/pdf/2409.14981v1",
    "published_date": "2024-09-23 12:58:11 UTC",
    "updated_date": "2024-09-23 12:58:11 UTC"
  },
  {
    "arxiv_id": "2409.14978v2",
    "title": "TS-HTFA: Advancing Time Series Forecasting via Hierarchical Text-Free Alignment with Large Language Models",
    "authors": [
      "Pengfei Wang",
      "Huanran Zheng",
      "Qi'ao Xu",
      "Silong Dai",
      "Yiqiao Wang",
      "Wenjing Yue",
      "Wei Zhu",
      "Tianwen Qian",
      "Xiaoling Wang"
    ],
    "abstract": "Given the significant potential of large language models (LLMs) in sequence\nmodeling, emerging studies have begun applying them to time-series forecasting.\nDespite notable progress, existing methods still face two critical challenges:\n1) their reliance on large amounts of paired text data, limiting the model\napplicability, and 2) a substantial modality gap between text and time series,\nleading to insufficient alignment and suboptimal performance. In this paper, we\nintroduce \\textbf{H}ierarchical \\textbf{T}ext-\\textbf{F}ree \\textbf{A}lignment\n(\\textbf{TS-HTFA}), a novel method that leverages hierarchical alignment to\nfully exploit the representation capacity of LLMs while eliminating the\ndependence on text data. Specifically, we replace paired text data with\nadaptive virtual text based on QR decomposition word embeddings and learnable\nprompt. Furthermore, we establish comprehensive cross-modal alignment at three\nlevels: input, feature, and output. Extensive experiments on multiple\ntime-series benchmarks demonstrate that HTFA achieves state-of-the-art\nperformance, significantly improving prediction accuracy and generalization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14978v2",
    "published_date": "2024-09-23 12:57:24 UTC",
    "updated_date": "2025-01-08 07:53:15 UTC"
  },
  {
    "arxiv_id": "2409.14972v1",
    "title": "Deep Reinforcement Learning-based Obstacle Avoidance for Robot Movement in Warehouse Environments",
    "authors": [
      "Keqin Li",
      "Jiajing Chen",
      "Denzhi Yu",
      "Tao Dajun",
      "Xinyu Qiu",
      "Lian Jieting",
      "Sun Baiwei",
      "Zhang Shengyuan",
      "Zhenyu Wan",
      "Ran Ji",
      "Bo Hong",
      "Fanghao Ni"
    ],
    "abstract": "At present, in most warehouse environments, the accumulation of goods is\ncomplex, and the management personnel in the control of goods at the same time\nwith the warehouse mobile robot trajectory interaction, the traditional mobile\nrobot can not be very good on the goods and pedestrians to feed back the\ncorrect obstacle avoidance strategy, in order to control the mobile robot in\nthe warehouse environment efficiently and friendly to complete the obstacle\navoidance task, this paper proposes a deep reinforcement learning based on the\nwarehouse environment, the mobile robot obstacle avoidance Algorithm. Firstly,\nfor the insufficient learning ability of the value function network in the deep\nreinforcement learning algorithm, the value function network is improved based\non the pedestrian interaction, the interaction information between pedestrians\nis extracted through the pedestrian angle grid, and the temporal features of\nindividual pedestrians are extracted through the attention mechanism, so that\nwe can learn to obtain the relative importance of the current state and the\nhistorical trajectory state as well as the joint impact on the robot's obstacle\navoidance strategy, which provides an opportunity for the learning of\nmulti-layer perceptual machines afterwards. Secondly, the reward function of\nreinforcement learning is designed based on the spatial behaviour of\npedestrians, and the robot is punished for the state where the angle changes\ntoo much, so as to achieve the requirement of comfortable obstacle avoidance;\nFinally, the feasibility and effectiveness of the deep reinforcement\nlearning-based mobile robot obstacle avoidance algorithm in the warehouse\nenvironment in the complex environment of the warehouse are verified through\nsimulation experiments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14972v1",
    "published_date": "2024-09-23 12:42:35 UTC",
    "updated_date": "2024-09-23 12:42:35 UTC"
  },
  {
    "arxiv_id": "2409.14924v1",
    "title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely",
    "authors": [
      "Siyun Zhao",
      "Yuqing Yang",
      "Zilong Wang",
      "Zhiyuan He",
      "Luna K. Qiu",
      "Lili Qiu"
    ],
    "abstract": "Large language models (LLMs) augmented with external data have demonstrated\nremarkable capabilities in completing real-world tasks. Techniques for\nintegrating external data into LLMs, such as Retrieval-Augmented Generation\n(RAG) and fine-tuning, are gaining increasing attention and widespread\napplication. Nonetheless, the effective deployment of data-augmented LLMs\nacross various specialized fields presents substantial challenges. These\nchallenges encompass a wide range of issues, from retrieving relevant data and\naccurately interpreting user intent to fully harnessing the reasoning\ncapabilities of LLMs for complex tasks. We believe that there is no\none-size-fits-all solution for data-augmented LLM applications. In practice,\nunderperformance often arises from a failure to correctly identify the core\nfocus of a task or because the task inherently requires a blend of multiple\ncapabilities that must be disentangled for better resolution. In this survey,\nwe propose a RAG task categorization method, classifying user queries into four\nlevels based on the type of external data required and primary focus of the\ntask: explicit fact queries, implicit fact queries, interpretable rationale\nqueries, and hidden rationale queries. We define these levels of queries,\nprovide relevant datasets, and summarize the key challenges and most effective\ntechniques for addressing these challenges. Finally, we discuss three main\nforms of integrating external data into LLMs: context, small model, and\nfine-tuning, highlighting their respective strengths, limitations, and the\ntypes of problems they are suited to solve. This work aims to help readers\nthoroughly understand and decompose the data requirements and key bottlenecks\nin building LLM applications, offering solutions to the different challenges\nand serving as a guide to systematically developing such applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14924v1",
    "published_date": "2024-09-23 11:20:20 UTC",
    "updated_date": "2024-09-23 11:20:20 UTC"
  },
  {
    "arxiv_id": "2409.14908v2",
    "title": "KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems",
    "authors": [
      "Zixuan Wang",
      "Bo Yu",
      "Junzhe Zhao",
      "Wenhao Sun",
      "Sai Hou",
      "Shuai Liang",
      "Xing Hu",
      "Yinhe Han",
      "Yiming Gan"
    ],
    "abstract": "Embodied AI agents responsible for executing interconnected, long-sequence\nhousehold tasks often face difficulties with in-context memory, leading to\ninefficiencies and errors in task execution. To address this issue, we\nintroduce KARMA, an innovative memory system that integrates long-term and\nshort-term memory modules, enhancing large language models (LLMs) for planning\nin embodied agents through memory-augmented prompting. KARMA distinguishes\nbetween long-term and short-term memory, with long-term memory capturing\ncomprehensive 3D scene graphs as representations of the environment, while\nshort-term memory dynamically records changes in objects' positions and states.\nThis dual-memory structure allows agents to retrieve relevant past scene\nexperiences, thereby improving the accuracy and efficiency of task planning.\nShort-term memory employs strategies for effective and adaptive memory\nreplacement, ensuring the retention of critical information while discarding\nless pertinent data. Compared to state-of-the-art embodied agents enhanced with\nmemory, our memory-augmented embodied AI agent improves success rates by 1.3x\nand 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,\nrespectively, and enhances task execution efficiency by 3.4x and 62.7x.\nFurthermore, we demonstrate that KARMA's plug-and-play capability allows for\nseamless deployment on real-world robotic systems, such as mobile manipulation\nplatforms.Through this plug-and-play memory system, KARMA significantly\nenhances the ability of embodied agents to generate coherent and contextually\nappropriate plans, making the execution of complex household tasks more\nefficient. The experimental videos from the work can be found at\nhttps://youtu.be/4BT7fnw9ehs. Our code is available at\nhttps://github.com/WZX0Swarm0Robotics/KARMA/tree/master.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14908v2",
    "published_date": "2024-09-23 11:02:46 UTC",
    "updated_date": "2025-03-21 01:58:00 UTC"
  },
  {
    "arxiv_id": "2409.14904v1",
    "title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models",
    "authors": [
      "Sangyeon Cho",
      "Jangyeong Jeon",
      "Dongjoon Lee",
      "Changhee Lee",
      "Junyeong Kim"
    ],
    "abstract": "The use of pre-trained language models fine-tuned to address specific\ndownstream tasks is a common approach in natural language processing (NLP).\nHowever, acquiring domain-specific knowledge via fine-tuning is challenging.\nTraditional methods involve pretraining language models using vast amounts of\ndomain-specific data before fine-tuning for particular tasks. This study\ninvestigates emergency/non-emergency classification tasks based on electronic\nmedical record (EMR) data obtained from pediatric emergency departments (PEDs)\nin Korea. Our findings reveal that existing domain-specific pre-trained\nlanguage models underperform compared to general language models in handling\nN-lingual free-text data characteristics of non-English-speaking regions. To\naddress these limitations, we propose a domain knowledge transfer methodology\nthat leverages knowledge distillation to infuse general language models with\ndomain-specific knowledge via fine-tuning. This study demonstrates the\neffective transfer of specialized knowledge between models by defining a\ngeneral language model as the student model and a domain-specific pre-trained\nmodel as the teacher model. In particular, we address the complexities of EMR\ndata obtained from PEDs in non-English-speaking regions, such as Korea, and\ndemonstrate that the proposed method enhances classification performance in\nsuch contexts. The proposed methodology not only outperforms baseline models on\nKorean PED EMR data, but also promises broader applicability in various\nprofessional and technical domains. In future works, we intend to extend this\nmethodology to include diverse non-English-speaking regions and address\nadditional downstream tasks, with the aim of developing advanced model\narchitectures using state-of-the-art KD techniques. The code is available in\nhttps://github.com/JoSangYeon/DSG-KD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "IEEE ACCESS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.14904v1",
    "published_date": "2024-09-23 10:59:02 UTC",
    "updated_date": "2024-09-23 10:59:02 UTC"
  },
  {
    "arxiv_id": "2409.14887v3",
    "title": "Deploying Open-Source Large Language Models: A performance Analysis",
    "authors": [
      "Yannis Bendi-Ouis",
      "Dan Dutartre",
      "Xavier Hinaut"
    ],
    "abstract": "Since the release of ChatGPT in November 2022, large language models (LLMs)\nhave seen considerable success, including in the open-source community, with\nmany open-weight models available. However, the requirements to deploy such a\nservice are often unknown and difficult to evaluate in advance. To facilitate\nthis process, we conducted numerous tests at the Centre Inria de l'Universit\\'e\nde Bordeaux. In this article, we propose a comparison of the performance of\nseveral models of different sizes (mainly Mistral and LLaMa) depending on the\navailable GPUs, using vLLM, a Python library designed to optimize the inference\nof these models. Our results provide valuable information for private and\npublic groups wishing to deploy LLMs, allowing them to evaluate the performance\nof different models based on their available hardware. This study thus\ncontributes to facilitating the adoption and use of these large language models\nin various application domains.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14887v3",
    "published_date": "2024-09-23 10:35:57 UTC",
    "updated_date": "2025-01-07 09:55:57 UTC"
  },
  {
    "arxiv_id": "2409.14880v1",
    "title": "End-to-End Graph Flattening Method for Large Language Models",
    "authors": [
      "Bin Hong",
      "Jinze Wu",
      "Jiayu Liu",
      "Liang Ding",
      "Jing Sha",
      "Kai Zhang",
      "Shijin Wang",
      "Zhenya Huang"
    ],
    "abstract": "In recent years, the breakthrough of Large Language Models (LLMs) offers new\nideas for achieving universal methods on graph data. The common practice of\nconverting graphs into natural language for LLMs, which refers to graph\nflattening, exhibits good generalizability and interpretability. However, the\npoor organization of the textual format results in poor performance in\nlong-distance scenario understanding. Inspired by human cognitive reasoning\nhabits, we propose a novel method for graph flattening to fit LLMs, termed as\nEnd-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show\nthat EEDP enhances the reasoning performance of LLMs in long-distance scenarios\nwhile maintaining excellent performance in short-distance scenarios,\ndemonstrating good robustness in the face of distance variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 1st International Conference on Computational Linguistics and\n  Natural Language Processing (CLNLP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.14880v1",
    "published_date": "2024-09-23 10:28:47 UTC",
    "updated_date": "2024-09-23 10:28:47 UTC"
  },
  {
    "arxiv_id": "2409.15398v1",
    "title": "Attack Atlas: A Practitioner's Perspective on Challenges and Pitfalls in Red Teaming GenAI",
    "authors": [
      "Ambrish Rawat",
      "Stefan Schoepf",
      "Giulio Zizzo",
      "Giandomenico Cornacchia",
      "Muhammad Zaid Hameed",
      "Kieran Fraser",
      "Erik Miehling",
      "Beat Buesser",
      "Elizabeth M. Daly",
      "Mark Purcell",
      "Prasanna Sattigeri",
      "Pin-Yu Chen",
      "Kush R. Varshney"
    ],
    "abstract": "As generative AI, particularly large language models (LLMs), become\nincreasingly integrated into production applications, new attack surfaces and\nvulnerabilities emerge and put a focus on adversarial threats in natural\nlanguage and multi-modal systems. Red-teaming has gained importance in\nproactively identifying weaknesses in these systems, while blue-teaming works\nto protect against such adversarial attacks. Despite growing academic interest\nin adversarial risks for generative AI, there is limited guidance tailored for\npractitioners to assess and mitigate these challenges in real-world\nenvironments. To address this, our contributions include: (1) a practical\nexamination of red- and blue-teaming strategies for securing generative AI, (2)\nidentification of key challenges and open questions in defense development and\nevaluation, and (3) the Attack Atlas, an intuitive framework that brings a\npractical approach to analyzing single-turn input attacks, placing it at the\nforefront for practitioners. This work aims to bridge the gap between academic\ninsights and practical security measures for the protection of generative AI\nsystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15398v1",
    "published_date": "2024-09-23 10:18:10 UTC",
    "updated_date": "2024-09-23 10:18:10 UTC"
  },
  {
    "arxiv_id": "2409.14876v4",
    "title": "Mammo-Clustering: A Multi-views Tri-level Information Fusion Context Clustering Framework for Localization and Classification in Mammography",
    "authors": [
      "Shilong Yang",
      "Chulong Zhang",
      "Qi Zang",
      "Juan Yu",
      "Liang Zeng",
      "Xiao Luo",
      "Yexuan Xing",
      "Xin Pan",
      "Qi Li",
      "Xiaokun Liang",
      "Yaoqin Xie"
    ],
    "abstract": "Breast cancer is a significant global health issue, and the diagnosis of\nbreast imaging has always been challenging. Mammography images typically have\nextremely high resolution, with lesions occupying only a very small area.\nDown-sampling in neural networks can easily lead to the loss of\nmicrocalcifications or subtle structures, making it difficult for traditional\nneural network architectures to address these issues. To tackle these\nchallenges, we propose a Context Clustering Network with triple information\nfusion. Firstly, compared to CNNs or transformers, we find that Context\nclustering methods (1) are more computationally efficient and (2) can more\neasily associate structural or pathological features, making them suitable for\nthe clinical tasks of mammography. Secondly, we propose a triple information\nfusion mechanism that integrates global information, feature-based local\ninformation, and patch-based local information. The proposed approach is\nrigorously evaluated on two public datasets, Vindr-Mammo and CBIS-DDSM, using\nfive independent splits to ensure statistical robustness. Our method achieves\nan AUC of 0.828 on Vindr-Mammo and 0.805 on CBIS-DDSM, outperforming the next\nbest method by 3.1% and 2.4%, respectively. These improvements are\nstatistically significant (p<0.05), underscoring the benefits of Context\nClustering Network with triple information fusion. Overall, our Context\nClustering framework demonstrates strong potential as a scalable and\ncost-effective solution for large-scale mammography screening, enabling more\nefficient and accurate breast cancer detection. Access to our method is\navailable at https://github.com/Sohyu1/Mammo_Clustering.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14876v4",
    "published_date": "2024-09-23 10:17:13 UTC",
    "updated_date": "2025-03-15 07:30:53 UTC"
  },
  {
    "arxiv_id": "2409.14874v2",
    "title": "Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images",
    "authors": [
      "Ahjol Senbi",
      "Tianyu Huang",
      "Fei Lyu",
      "Qing Li",
      "Yuhui Tao",
      "Wei Shao",
      "Qiang Chen",
      "Chengyan Wang",
      "Shuo Wang",
      "Tao Zhou",
      "Yizhe Zhang"
    ],
    "abstract": "We explore the feasibility and potential of building a ground-truth-free\nevaluation model to assess the quality of segmentations generated by the\nSegment Anything Model (SAM) and its variants in medical imaging. This\nevaluation model estimates segmentation quality scores by analyzing the\ncoherence and consistency between the input images and their corresponding\nsegmentation predictions. Based on prior research, we frame the task of\ntraining this model as a regression problem within a supervised learning\nframework, using Dice scores (and optionally other metrics) along with mean\nsquared error to compute the training loss. The model is trained utilizing a\nlarge collection of public datasets of medical images with segmentation\npredictions from SAM and its variants. We name this model EvanySeg (Evaluation\nof Any Segmentation in Medical Images). Our exploration of convolution-based\nmodels (e.g., ResNet) and transformer-based models (e.g., ViT) suggested that\nViT yields better performance for this task. EvanySeg can be employed for\nvarious tasks, including: (1) identifying poorly segmented samples by detecting\nlow-percentile segmentation quality scores; (2) benchmarking segmentation\nmodels without ground truth by averaging quality scores across test samples;\n(3) alerting human experts to poor-quality segmentation predictions during\nhuman-AI collaboration by applying a threshold within the score space; and (4)\nselecting the best segmentation prediction for each test sample at test time\nwhen multiple segmentation models are available, by choosing the prediction\nwith the highest quality score. Models and code will be made available at\nhttps://github.com/ahjolsenbics/EvanySeg.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14874v2",
    "published_date": "2024-09-23 10:12:08 UTC",
    "updated_date": "2024-09-24 09:56:16 UTC"
  },
  {
    "arxiv_id": "2409.14872v2",
    "title": "FedSlate:A Federated Deep Reinforcement Learning Recommender System",
    "authors": [
      "Yongxin Deng",
      "Xihe Qiu",
      "Xiaoyu Tan",
      "Yaochu Jin"
    ],
    "abstract": "Reinforcement learning methods have been used to optimize long-term user\nengagement in recommendation systems. However, existing reinforcement\nlearning-based recommendation systems do not fully exploit the relevance of\nindividual user behavior across different platforms. One potential solution is\nto aggregate data from various platforms in a centralized location and use the\naggregated data for training. However, this approach raises economic and legal\nconcerns, including increased communication costs and potential threats to user\nprivacy. To address these challenges, we propose \\textbf{FedSlate}, a federated\nreinforcement learning recommendation algorithm that effectively utilizes\ninformation that is prohibited from being shared at a legal level. We employ\nthe SlateQ algorithm to assist FedSlate in learning users' long-term behavior\nand evaluating the value of recommended content. We extend the existing\napplication scope of recommendation systems from single-user single-platform to\nsingle-user multi-platform and address cross-platform learning challenges by\nintroducing federated learning. We use RecSim to construct a simulation\nenvironment for evaluating FedSlate and compare its performance with\nstate-of-the-art benchmark recommendation models. Experimental results\ndemonstrate the superior effects of FedSlate over baseline methods in various\nenvironmental settings, and FedSlate facilitates the learning of recommendation\nstrategies in scenarios where baseline methods are completely inapplicable.\nCode is available at \\textit{https://github.com/TianYaDY/FedSlate}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14872v2",
    "published_date": "2024-09-23 10:10:24 UTC",
    "updated_date": "2025-04-28 15:43:39 UTC"
  },
  {
    "arxiv_id": "2409.14867v1",
    "title": "A novel agent with formal goal-reaching guarantees: an experimental study with a mobile robot",
    "authors": [
      "Grigory Yaremenko",
      "Dmitrii Dobriborsci",
      "Roman Zashchitin",
      "Ruben Contreras Maestre",
      "Ngoc Quoc Huy Hoang",
      "Pavel Osinenko"
    ],
    "abstract": "Reinforcement Learning (RL) has been shown to be effective and convenient for\na number of tasks in robotics. However, it requires the exploration of a\nsufficiently large number of state-action pairs, many of which may be unsafe or\nunimportant. For instance, online model-free learning can be hazardous and\ninefficient in the absence of guarantees that a certain set of desired states\nwill be reached during an episode. An increasingly common approach to address\nsafety involves the addition of a shielding system that constrains the RL\nactions to a safe set of actions. In turn, a difficulty for such frameworks is\nhow to effectively couple RL with the shielding system to make sure the\nexploration is not excessively restricted. This work presents a novel safe\nmodel-free RL agent called Critic As Lyapunov Function (CALF) and showcases how\nCALF can be used to improve upon control baselines in robotics in an efficient\nand convenient fashion while ensuring guarantees of stable goal reaching. The\nlatter is a crucial part of safety, as seen generally. With CALF all\nstate-action pairs remain explorable and yet reaching of desired goal states is\nformally guaranteed. Formal analysis is provided that shows the goal\nstabilization-ensuring properties of CALF and a set of real-world and numerical\nexperiments with a non-holonomic wheeled mobile robot (WMR) TurtleBot3 Burger\nconfirmed the superiority of CALF over such a well-established RL agent as\nproximal policy optimization (PPO), and a modified version of SARSA in a\nfew-episode setting in terms of attained total cost.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14867v1",
    "published_date": "2024-09-23 10:04:28 UTC",
    "updated_date": "2024-09-23 10:04:28 UTC"
  },
  {
    "arxiv_id": "2409.14866v5",
    "title": "PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs",
    "authors": [
      "Xueluan Gong",
      "Mingzhe Li",
      "Yilin Zhang",
      "Fengyuan Ran",
      "Chen Chen",
      "Yanjiao Chen",
      "Qian Wang",
      "Kwok-Yan Lam"
    ],
    "abstract": "Large Language Models (LLMs) have excelled in various tasks but are still\nvulnerable to jailbreaking attacks, where attackers create jailbreak prompts to\nmislead the model to produce harmful or offensive content. Current jailbreak\nmethods either rely heavily on manually crafted templates, which pose\nchallenges in scalability and adaptability, or struggle to generate\nsemantically coherent prompts, making them easy to detect. Additionally, most\nexisting approaches involve lengthy prompts, leading to higher query costs. In\nthis paper, to remedy these challenges, we introduce a novel jailbreaking\nattack framework called PAPILLON, which is an automated, black-box jailbreaking\nattack framework that adapts the black-box fuzz testing approach with a series\nof customized designs. Instead of relying on manually crafted\ntemplates,PAPILLON starts with an empty seed pool, removing the need to search\nfor any related jailbreaking templates. We also develop three novel\nquestion-dependent mutation strategies using an LLM helper to generate prompts\nthat maintain semantic coherence while significantly reducing their length.\nAdditionally, we implement a two-level judge module to accurately detect\ngenuine successful jailbreaks. We evaluated PAPILLON on 7 representative LLMs\nand compared it with 5 state-of-the-art jailbreaking attack strategies. For\nproprietary LLM APIs, such as GPT-3.5 turbo, GPT-4, and Gemini-Pro, PAPILLONs\nachieves attack success rates of over 90%, 80%, and 74%, respectively,\nexceeding existing baselines by more than 60\\%. Additionally, PAPILLON can\nmaintain high semantic coherence while significantly reducing the length of\njailbreak prompts. When targeting GPT-4, PAPILLON can achieve over 78% attack\nsuccess rate even with 100 tokens. Moreover, PAPILLON demonstrates\ntransferability and is robust to state-of-the-art defenses. Code:\nhttps://github.com/aaFrostnova/Papillon",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14866v5",
    "published_date": "2024-09-23 10:03:09 UTC",
    "updated_date": "2025-03-03 07:25:21 UTC"
  },
  {
    "arxiv_id": "2409.14857v2",
    "title": "Embedding Knowledge Graph in Function Spaces",
    "authors": [
      "Louis Mozart Kamdem Teyou",
      "Caglar Demir",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "abstract": "We introduce a novel embedding method diverging from conventional approaches\nby operating within function spaces of finite dimension rather than finite\nvector space, thus departing significantly from standard knowledge graph\nembedding techniques. Initially employing polynomial functions to compute\nembeddings, we progress to more intricate representations using neural networks\nwith varying layer complexities. We argue that employing functions for\nembedding computation enhances expressiveness and allows for more degrees of\nfreedom, enabling operations such as composition, derivatives and primitive of\nentities representation. Additionally, we meticulously outline the step-by-step\nconstruction of our approach and provide code for reproducibility, thereby\nfacilitating further exploration and application in the field.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14857v2",
    "published_date": "2024-09-23 09:49:57 UTC",
    "updated_date": "2024-09-24 09:33:44 UTC"
  },
  {
    "arxiv_id": "2409.14852v2",
    "title": "FUSED-Net: Detecting Traffic Signs with Limited Data",
    "authors": [
      "Md. Atiqur Rahman",
      "Nahian Ibn Asad",
      "Md. Mushfiqul Haque Omi",
      "Md. Bakhtiar Hasan",
      "Sabbir Ahmed",
      "Md. Hasanul Kabir"
    ],
    "abstract": "Automatic Traffic Sign Recognition is paramount in modern transportation\nsystems, motivating several research endeavors to focus on performance\nimprovement by utilizing large-scale datasets. As the appearance of traffic\nsigns varies across countries, curating large-scale datasets is often\nimpractical; and requires efficient models that can produce satisfactory\nperformance using limited data. In this connection, we present 'FUSED-Net',\nbuilt-upon Faster RCNN for traffic sign detection, enhanced by Unfrozen\nParameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation\nwhile reducing data requirement. Unlike traditional approaches, we keep all\nparameters unfrozen during training, enabling FUSED-Net to learn from limited\nsamples. The generation of a Pseudo-Support Set through data augmentation\nfurther enhances performance by compensating for the scarcity of target domain\ndata. Additionally, Embedding Normalization is incorporated to reduce\nintra-class variance, standardizing feature representation. Domain Adaptation,\nachieved by pre-training on a diverse traffic sign dataset distinct from the\ntarget domain, improves model generalization. Evaluating FUSED-Net on the BDTSD\ndataset, we achieved 2.4x, 2.2x, 1.5x, and 1.3x improvements of mAP in 1-shot,\n3-shot, 5-shot, and 10-shot scenarios, respectively compared to the\nstate-of-the-art Few-Shot Object Detection (FSOD) models. Additionally, we\noutperform state-of-the-art works on the cross-domain FSOD benchmark under\nseveral scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 8 figures, 5 tables, submitted to IEEE Access for review",
    "pdf_url": "http://arxiv.org/pdf/2409.14852v2",
    "published_date": "2024-09-23 09:34:42 UTC",
    "updated_date": "2025-01-03 06:11:47 UTC"
  },
  {
    "arxiv_id": "2409.14850v1",
    "title": "GroCo: Ground Constraint for Metric Self-Supervised Monocular Depth",
    "authors": [
      "Aurélien Cecille",
      "Stefan Duffner",
      "Franck Davoine",
      "Thibault Neveu",
      "Rémi Agier"
    ],
    "abstract": "Monocular depth estimation has greatly improved in the recent years but\nmodels predicting metric depth still struggle to generalize across diverse\ncamera poses and datasets. While recent supervised methods mitigate this issue\nby leveraging ground prior information at inference, their adaptability to\nself-supervised settings is limited due to the additional challenge of scale\nrecovery. Addressing this gap, we propose in this paper a novel constraint on\nground areas designed specifically for the self-supervised paradigm. This\nmechanism not only allows to accurately recover the scale but also ensures\ncoherence between the depth prediction and the ground prior. Experimental\nresults show that our method surpasses existing scale recovery techniques on\nthe KITTI benchmark and significantly enhances model generalization\ncapabilities. This improvement can be observed by its more robust performance\nacross diverse camera rotations and its adaptability in zero-shot conditions\nwith previously unseen driving datasets such as DDAD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14850v1",
    "published_date": "2024-09-23 09:30:27 UTC",
    "updated_date": "2024-09-23 09:30:27 UTC"
  },
  {
    "arxiv_id": "2409.14846v2",
    "title": "A-VL: Adaptive Attention for Large Vision-Language Models",
    "authors": [
      "Junyang Zhang",
      "Mu Yuan",
      "Ruiguang Zhong",
      "Puhan Luo",
      "Huiyou Zhan",
      "Ningkang Zhang",
      "Chengchen Hu",
      "Xiangyang Li"
    ],
    "abstract": "The Large Vision-Language Model (LVLM) integrates computer vision and natural\nlanguage processing techniques, offering substantial application potential.\nHowever, these models demand extensive resources during inference. Adaptive\nattention techniques can dynamically reduce computational redundancy and thus\nimprove efficiency. Although current adaptive attention methods significantly\nreduce the memory requirements of Transformer-based language models, they are\nnot tailored for LVLMs. We observe that LVLMs generate responses from both\nremote image tokens and local text tokens, and different modalities have\ndifferent attention patterns. This observation inspires us to manage the\nattention for each modality separately. Specifically, for visual input, we\nstore the cache of potentially useful information but only compute the most\ncritical parts. For language input, we care more about local information. Based\non our observation and analysis of vision-language attention patterns, we\ndevelop A-VL, a plug-and-play adaptive attention tailored for LVLM inference.\nExtensive evaluations on three vision-language tasks and five datasets show the\neffectiveness of our designs. Our approach A-VL outperforms existing adaptive\nattention methods in reducing memory usage and computational load without\ncompromising performance.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2025 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2409.14846v2",
    "published_date": "2024-09-23 09:22:59 UTC",
    "updated_date": "2025-02-07 13:09:17 UTC"
  },
  {
    "arxiv_id": "2409.14842v3",
    "title": "HW-TSC's Submission to the CCMT 2024 Machine Translation Tasks",
    "authors": [
      "Zhanglin Wu",
      "Yuanchang Luo",
      "Daimeng Wei",
      "Jiawei Zheng",
      "Bin Wei",
      "Zongyao Li",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Shaojun Li",
      "Weidong Zhang",
      "Ning Xie",
      "Hao Yang"
    ],
    "abstract": "This paper presents the submission of Huawei Translation Services Center\n(HW-TSC) to machine translation tasks of the 20th China Conference on Machine\nTranslation (CCMT 2024). We participate in the bilingual machine translation\ntask and multi-domain machine translation task. For these two translation\ntasks, we use training strategies such as regularized dropout, bidirectional\ntraining, data diversification, forward translation, back translation,\nalternated training, curriculum learning, and transductive ensemble learning to\ntrain neural machine translation (NMT) models based on the deep Transformer-big\narchitecture. Furthermore, to explore whether large language model (LLM) can\nhelp improve the translation quality of NMT systems, we use supervised\nfine-tuning to train llama2-13b as an Automatic post-editing (APE) model to\nimprove the translation results of the NMT model on the multi-domain machine\ntranslation task. By using these plyometric strategies, our submission achieves\na competitive result in the final evaluation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures, 6 Tables, CCMT2024. arXiv admin note:\n  substantial text overlap with arXiv:2409.14800",
    "pdf_url": "http://arxiv.org/pdf/2409.14842v3",
    "published_date": "2024-09-23 09:20:19 UTC",
    "updated_date": "2024-10-08 09:34:11 UTC"
  },
  {
    "arxiv_id": "2409.14839v1",
    "title": "Explainable and Human-Grounded AI for Decision Support Systems: The Theory of Epistemic Quasi-Partnerships",
    "authors": [
      "John Dorsch",
      "Maximilian Moll"
    ],
    "abstract": "In the context of AI decision support systems (AI-DSS), we argue that meeting\nthe demands of ethical and explainable AI (XAI) is about developing AI-DSS to\nprovide human decision-makers with three types of human-grounded explanations:\nreasons, counterfactuals, and confidence, an approach we refer to as the RCC\napproach. We begin by reviewing current empirical XAI literature that\ninvestigates the relationship between various methods for generating model\nexplanations (e.g., LIME, SHAP, Anchors), the perceived trustworthiness of the\nmodel, and end-user accuracy. We demonstrate how current theories about what\nconstitutes good human-grounded reasons either do not adequately explain this\nevidence or do not offer sound ethical advice for development. Thus, we offer a\nnovel theory of human-machine interaction: the theory of epistemic\nquasi-partnerships (EQP). Finally, we motivate adopting EQP and demonstrate how\nit explains the empirical evidence, offers sound ethical advice, and entails\nadopting the RCC approach.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "K.4.1; H.5.2; H.4.2; J.7; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.14839v1",
    "published_date": "2024-09-23 09:14:25 UTC",
    "updated_date": "2024-09-23 09:14:25 UTC"
  },
  {
    "arxiv_id": "2409.14838v1",
    "title": "MICSim: A Modular Simulator for Mixed-signal Compute-in-Memory based AI Accelerator",
    "authors": [
      "Cong Wang",
      "Zeming Chen",
      "Shanshi Huang"
    ],
    "abstract": "This work introduces MICSim, an open-source, pre-circuit simulator designed\nfor early-stage evaluation of chip-level software performance and hardware\noverhead of mixed-signal compute-in-memory (CIM) accelerators. MICSim features\na modular design, allowing easy multi-level co-design and design space\nexploration. Modularized from the state-of-the-art CIM simulator NeuroSim,\nMICSim provides a highly configurable simulation framework supporting multiple\nquantization algorithms, diverse circuit/architecture designs, and different\nmemory devices. This modular approach also allows MICSim to be effectively\nextended to accommodate new designs.\n  MICSim natively supports evaluating accelerators' software and hardware\nperformance for CNNs and Transformers in Python, leveraging the popular PyTorch\nand HuggingFace Transformers frameworks. These capabilities make MICSim highly\nadaptive when simulating different networks and user-friendly. This work\ndemonstrates that MICSim can easily be combined with optimization strategies to\nperform design space exploration and used for chip-level Transformers CIM\naccelerators evaluation. Also, MICSim can achieve a 9x - 32x speedup of\nNeuroSim through a statistic-based average mode proposed by this work.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "The 30th Asia and South Pacific Design Automation Conference (ASP-DAC\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2409.14838v1",
    "published_date": "2024-09-23 09:12:46 UTC",
    "updated_date": "2024-09-23 09:12:46 UTC"
  },
  {
    "arxiv_id": "2409.14836v2",
    "title": "Orthogonal Finetuning for Direct Preference Optimization",
    "authors": [
      "Chenxu Yang",
      "Ruipeng Jia",
      "Naibin Gu",
      "Zheng Lin",
      "Siyuan Chen",
      "Chao Pang",
      "Weichong Yin",
      "Yu Sun",
      "Hua Wu",
      "Weiping Wang"
    ],
    "abstract": "DPO is an effective preference optimization algorithm. However, the DPO-tuned\nmodels tend to overfit on the dispreferred samples, manifested as overly long\ngenerations lacking diversity. While recent regularization approaches have\nendeavored to alleviate this issue by modifying the objective function, they\nachieved that at the cost of alignment performance degradation. In this paper,\nwe innovatively incorporate regularization from the perspective of weight\nupdating to curb alignment overfitting. Through the pilot experiment, we\ndiscovered that there exists a positive correlation between overfitting and the\nhyperspherical energy fluctuation. Hence, we introduce orthogonal finetuning\nfor DPO via a weight-Rotated Preference Optimization (RoPO) method, which\nmerely conducts rotational and magnitude-stretching updates on the weight\nparameters to maintain the hyperspherical energy invariant, thereby preserving\nthe knowledge encoded in the angle between neurons. Extensive experiments\ndemonstrate that our model aligns perfectly with human preferences while\nretaining the original expressive capacity using only 0.0086% of the trainable\nparameters, suggesting an effective regularization against overfitting.\nSpecifically, RoPO outperforms DPO by up to 10 points on MT-Bench and by up to\n2.8 points on AlpacaEval 2, while enhancing the generation diversity by an\naverage of 6 points.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14836v2",
    "published_date": "2024-09-23 09:09:16 UTC",
    "updated_date": "2024-09-24 03:22:15 UTC"
  },
  {
    "arxiv_id": "2409.14830v1",
    "title": "Identify As A Human Does: A Pathfinder of Next-Generation Anti-Cheat Framework for First-Person Shooter Games",
    "authors": [
      "Jiayi Zhang",
      "Chenxin Sun",
      "Yue Gu",
      "Qingyu Zhang",
      "Jiayi Lin",
      "Xiaojiang Du",
      "Chenxiong Qian"
    ],
    "abstract": "The gaming industry has experienced substantial growth, but cheating in\nonline games poses a significant threat to the integrity of the gaming\nexperience. Cheating, particularly in first-person shooter (FPS) games, can\nlead to substantial losses for the game industry. Existing anti-cheat solutions\nhave limitations, such as client-side hardware constraints, security risks,\nserver-side unreliable methods, and both-sides suffer from a lack of\ncomprehensive real-world datasets. To address these limitations, the paper\nproposes HAWK, a server-side FPS anti-cheat framework for the popular game\nCS:GO. HAWK utilizes machine learning techniques to mimic human experts'\nidentification process, leverages novel multi-view features, and it is equipped\nwith a well-defined workflow. The authors evaluate HAWK with the first large\nand real-world datasets containing multiple cheat types and cheating\nsophistication, and it exhibits promising efficiency and acceptable overheads,\nshorter ban times compared to the in-use anti-cheat, a significant reduction in\nmanual labor, and the ability to capture cheaters who evaded official\ninspections.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14830v1",
    "published_date": "2024-09-23 09:00:07 UTC",
    "updated_date": "2024-09-23 09:00:07 UTC"
  },
  {
    "arxiv_id": "2409.14826v3",
    "title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback",
    "authors": [
      "Qinzhuo Wu",
      "Wei Liu",
      "Jian Luan",
      "Bin Wang"
    ],
    "abstract": "Recently, tool-augmented LLMs have gained increasing attention. Given an\ninstruction, tool-augmented LLMs can interact with various external tools in\nmultiple rounds and provide a final answer. However, previous LLMs were trained\non overly detailed instructions, which included API names or parameters, while\nreal users would not explicitly mention these API details. This leads to a gap\nbetween trained LLMs and real-world scenarios. In addition, most works ignore\nwhether the interaction process follows the instruction. To address these\nissues, we constructed a training dataset called MGToolBench, which contains\nstatement and category-level instructions to better reflect real-world\nscenarios. In addition, we propose ToolPlanner, a two-stage reinforcement\nlearning framework that utilizes path planning and two feedback mechanisms to\nenhance the LLM's task completion and instruction-following capabilities.\nExperimental results show that ToolPlanner significantly improves the Match\nRate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA\nmodel. Human evaluation verifies that the multi-granularity instructions can\nbetter align with users' usage habits. Our data and code will be released upon\nacceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14826v3",
    "published_date": "2024-09-23 08:58:48 UTC",
    "updated_date": "2024-11-04 02:29:32 UTC"
  },
  {
    "arxiv_id": "2409.14821v1",
    "title": "Towards Real-world Deployment of NILM Systems: Challenges and Practices",
    "authors": [
      "Junyu Xue",
      "Yu Zhang",
      "Xudong Wang",
      "Yi Wang",
      "Guoming Tang"
    ],
    "abstract": "Non-intrusive load monitoring (NILM), as a key load monitoring technology,\ncan much reduce the deployment cost of traditional power sensors. Previous\nresearch has largely focused on developing cloud-exclusive NILM algorithms,\nwhich often result in high computation costs and significant service delays. To\naddress these issues, we propose a three-tier framework to enhance the\nreal-world applicability of NILM systems through edge-cloud collaboration.\nConsidering the computational resources available at both the edge and cloud,\nwe implement a lightweight NILM model at the edge and a deep learning based\nmodel at the cloud, respectively. In addition to the differential model\nimplementations, we also design a NILM-specific deployment scheme that\nintegrates Gunicorn and NGINX to bridge the gap between theoretical algorithms\nand practical applications. To verify the effectiveness of the proposed\nframework, we apply real-world NILM scenario settings and implement the entire\nprocess of data acquisition, model training, and system deployment. The results\ndemonstrate that our framework can achieve high decomposition accuracy while\nsignificantly reducing the cloud workload and communication overhead under\npractical considerations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14821v1",
    "published_date": "2024-09-23 08:54:05 UTC",
    "updated_date": "2024-09-23 08:54:05 UTC"
  },
  {
    "arxiv_id": "2409.14820v1",
    "title": "Past Meets Present: Creating Historical Analogy with Large Language Models",
    "authors": [
      "Nianqi Li",
      "Siyu Yuan",
      "Jiangjie Chen",
      "Jiaqing Liang",
      "Feng Wei",
      "Zujie Liang",
      "Deqing Yang",
      "Yanghua Xiao"
    ],
    "abstract": "Historical analogies, which compare known past events with contemporary but\nunfamiliar events, are important abilities that help people make decisions and\nunderstand the world. However, research in applied history suggests that people\nhave difficulty finding appropriate analogies. And previous studies in the AI\ncommunity have also overlooked historical analogies. To fill this gap, in this\npaper, we focus on the historical analogy acquisition task, which aims to\nacquire analogous historical events for a given event. We explore retrieval and\ngeneration methods for acquiring historical analogies based on different large\nlanguage models (LLMs). Furthermore, we propose a self-reflection method to\nmitigate hallucinations and stereotypes when LLMs generate historical\nanalogies. Through human evaluations and our specially designed automatic\nmulti-dimensional assessment, we find that LLMs generally have a good potential\nfor historical analogies. And the performance of the models can be further\nimproved by using our self-reflection method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14820v1",
    "published_date": "2024-09-23 08:52:09 UTC",
    "updated_date": "2024-09-23 08:52:09 UTC"
  },
  {
    "arxiv_id": "2409.14818v2",
    "title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding",
    "authors": [
      "Qinzhuo Wu",
      "Weikai Xu",
      "Wei Liu",
      "Tao Tan",
      "Jianfeng Liu",
      "Ang Li",
      "Jian Luan",
      "Bin Wang",
      "Shuo Shang"
    ],
    "abstract": "Recently, mobile AI agents based on VLMs have been gaining increasing\nattention. These works typically utilize VLM as a foundation, fine-tuning it\nwith instruction-based mobile datasets. However, these VLMs are typically\npre-trained on general-domain data, which often results in a lack of\nfundamental capabilities specific to the mobile domain. Therefore, they may\nstruggle to recognize specific UI elements and understand intra-UI fine-grained\ninformation. In addition, the current fine-tuning task focuses on interacting\nwith the most relevant element for the given instruction. These fine-tuned VLMs\nmay still ignore the relationships between UI pages, neglect the roles of\nelements in page transitions and lack inter-UI understanding. To address\nissues, we propose a VLM called MobileVLM, which includes two additional\npre-training stages to enhance both intra- and inter-UI understanding. We\ndefined four UI-based pre-training tasks, enabling the model to better perceive\nfine-grained elements and capture page transition actions. To address the lack\nof mobile pre-training data, we built a large Chinese mobile dataset Mobile3M\nfrom scratch, which contains 3 million UI pages, and real-world transition\nactions, forming a directed graph structure. Experimental results show\nMobileVLM excels on both our test set and public mobile benchmarks,\noutperforming existing VLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14818v2",
    "published_date": "2024-09-23 08:47:54 UTC",
    "updated_date": "2024-10-03 05:23:22 UTC"
  },
  {
    "arxiv_id": "2409.14816v2",
    "title": "VARADE: a Variational-based AutoRegressive model for Anomaly Detection on the Edge",
    "authors": [
      "Alessio Mascolini",
      "Sebastiano Gaiardelli",
      "Francesco Ponzio",
      "Nicola Dall'Ora",
      "Enrico Macii",
      "Sara Vinco",
      "Santa Di Cataldo",
      "Franco Fummi"
    ],
    "abstract": "Detecting complex anomalies on massive amounts of data is a crucial task in\nIndustry 4.0, best addressed by deep learning. However, available solutions are\ncomputationally demanding, requiring cloud architectures prone to latency and\nbandwidth issues. This work presents VARADE, a novel solution implementing a\nlight autoregressive framework based on variational inference, which is best\nsuited for real-time execution on the edge. The proposed approach was validated\non a robotic arm, part of a pilot production line, and compared with several\nstate-of-the-art algorithms, obtaining the best trade-off between anomaly\ndetection accuracy, power consumption and inference frequency on two different\nedge platforms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14816v2",
    "published_date": "2024-09-23 08:46:15 UTC",
    "updated_date": "2024-09-26 09:11:28 UTC"
  },
  {
    "arxiv_id": "2410.11843v5",
    "title": "From Commands to Prompts: LLM-based Semantic File System for AIOS",
    "authors": [
      "Zeru Shi",
      "Kai Mei",
      "Mingyu Jin",
      "Yongye Su",
      "Chaoji Zuo",
      "Wenyue Hua",
      "Wujiang Xu",
      "Yujie Ren",
      "Zirui Liu",
      "Mengnan Du",
      "Dong Deng",
      "Yongfeng Zhang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated significant potential in the\ndevelopment of intelligent applications and systems such as LLM-based agents\nand agent operating systems (AIOS). However, when these applications and\nsystems interact with the underlying file system, the file system still remains\nthe traditional paradigm: reliant on manual navigation through precise\ncommands. This paradigm poses a bottleneck to the usability of these systems as\nusers are required to navigate complex folder hierarchies and remember cryptic\nfile names. To address this limitation, we propose an LLM-based semantic file\nsystem ( LSFS ) for prompt-driven file management. Unlike conventional\napproaches, LSFS incorporates LLMs to enable users or agents to interact with\nfiles through natural language prompts, facilitating semantic file management.\nAt the macro-level, we develop a comprehensive API set to achieve semantic file\nmanagement functionalities, such as semantic file retrieval, file update\nmonitoring and summarization, and semantic file rollback). At the micro-level,\nwe store files by constructing semantic indexes for them, design and implement\nsyscalls of different semantic operations (e.g., CRUD, group by, join) powered\nby vector database. Our experiments show that LSFS offers significant\nimprovements over traditional file systems in terms of user convenience, the\ndiversity of supported functions, and the accuracy and efficiency of file\noperations. Additionally, with the integration of LLM, our system enables more\nintelligent file management tasks, such as content summarization and version\ncomparison, further enhancing its capabilities.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by International Conference on Learning Representations\n  2025(ICLR2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.11843v5",
    "published_date": "2024-09-23 08:39:16 UTC",
    "updated_date": "2025-03-19 03:17:47 UTC"
  },
  {
    "arxiv_id": "2409.14803v1",
    "title": "Benchmarking Edge AI Platforms for High-Performance ML Inference",
    "authors": [
      "Rakshith Jayanth",
      "Neelesh Gupta",
      "Viktor Prasanna"
    ],
    "abstract": "Edge computing's growing prominence, due to its ability to reduce\ncommunication latency and enable real-time processing, is promoting the rise of\nhigh-performance, heterogeneous System-on-Chip solutions. While current\napproaches often involve scaling down modern hardware, the performance\ncharacteristics of neural network workloads on these platforms can vary\nsignificantly, especially when it comes to parallel processing, which is a\ncritical consideration for edge deployments. To address this, we conduct a\ncomprehensive study comparing the latency and throughput of various linear\nalgebra and neural network inference tasks across CPU-only, CPU/GPU, and\nCPU/NPU integrated solutions. {We find that the Neural Processing Unit (NPU)\nexcels in matrix-vector multiplication (58.6% faster) and some neural network\ntasks (3.2$\\times$ faster for video classification and large language models).\nGPU outperforms in matrix multiplication (22.6% faster) and LSTM networks\n(2.7$\\times$ faster) while CPU excels at less parallel operations like dot\nproduct. NPU-based inference offers a balance of latency and throughput at\nlower power consumption. GPU-based inference, though more energy-intensive,\nperforms best with large dimensions and batch sizes. We highlight the potential\nof heterogeneous computing solutions for edge AI, where diverse compute units\ncan be strategically leveraged to boost accurate and real-time inference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14803v1",
    "published_date": "2024-09-23 08:27:27 UTC",
    "updated_date": "2024-09-23 08:27:27 UTC"
  },
  {
    "arxiv_id": "2409.14800v1",
    "title": "Choose the Final Translation from NMT and LLM hypotheses Using MBR Decoding: HW-TSC's Submission to the WMT24 General MT Shared Task",
    "authors": [
      "Zhanglin Wu",
      "Daimeng Wei",
      "Zongyao Li",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Shaojun Li",
      "Zhiqiang Rao",
      "Yuanchang Luo",
      "Ning Xie",
      "Hao Yang"
    ],
    "abstract": "This paper presents the submission of Huawei Translate Services Center\n(HW-TSC) to the WMT24 general machine translation (MT) shared task, where we\nparticipate in the English to Chinese (en2zh) language pair. Similar to\nprevious years' work, we use training strategies such as regularized dropout,\nbidirectional training, data diversification, forward translation, back\ntranslation, alternated training, curriculum learning, and transductive\nensemble learning to train the neural machine translation (NMT) model based on\nthe deep Transformer-big architecture. The difference is that we also use\ncontinue pre-training, supervised fine-tuning, and contrastive preference\noptimization to train the large language model (LLM) based MT model. By using\nMinimum Bayesian risk (MBR) decoding to select the final translation from\nmultiple hypotheses for NMT and LLM-based MT models, our submission receives\ncompetitive results in the final evaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, 2 Tables, EMNLP2024",
    "pdf_url": "http://arxiv.org/pdf/2409.14800v1",
    "published_date": "2024-09-23 08:25:37 UTC",
    "updated_date": "2024-09-23 08:25:37 UTC"
  },
  {
    "arxiv_id": "2409.14796v1",
    "title": "Research on Dynamic Data Flow Anomaly Detection based on Machine Learning",
    "authors": [
      "Liyang Wang",
      "Yu Cheng",
      "Hao Gong",
      "Jiacheng Hu",
      "Xirui Tang",
      "Iris Li"
    ],
    "abstract": "The sophistication and diversity of contemporary cyberattacks have rendered\nthe use of proxies, gateways, firewalls, and encrypted tunnels as a standalone\ndefensive strategy inadequate. Consequently, the proactive identification of\ndata anomalies has emerged as a prominent area of research within the field of\ndata security. The majority of extant studies concentrate on sample equilibrium\ndata, with the consequence that the detection effect is not optimal in the\ncontext of unbalanced data. In this study, the unsupervised learning method is\nemployed to identify anomalies in dynamic data flows. Initially,\nmulti-dimensional features are extracted from real-time data, and a clustering\nalgorithm is utilised to analyse the patterns of the data. This enables the\npotential outliers to be automatically identified. By clustering similar data,\nthe model is able to detect data behaviour that deviates significantly from\nnormal traffic without the need for labelled data. The results of the\nexperiments demonstrate that the proposed method exhibits high accuracy in the\ndetection of anomalies across a range of scenarios. Notably, it demonstrates\nrobust and adaptable performance, particularly in the context of unbalanced\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14796v1",
    "published_date": "2024-09-23 08:19:15 UTC",
    "updated_date": "2024-09-23 08:19:15 UTC"
  },
  {
    "arxiv_id": "2409.14784v1",
    "title": "SAMEdge: An Edge-cloud Video Analytics Architecture for the Segment Anything Model",
    "authors": [
      "Rui Lu",
      "Siping Shi",
      "Yanting Liu",
      "Dan Wang"
    ],
    "abstract": "As artificial intelligence continues to evolve, it is increasingly capable of\nhandling a wide range of video analytics tasks with merely one large model. One\nof the key foundation technologies is the Segment Anything Model (SAM), which\nallows the video analytics tasks to be determined on the fly according to the\ninput prompts from the user. However, achieving real-time response in video\nanalytics applications is crucial for user experiences due to the limited\ncommunication and computation resources on the edge, especially with SAM, where\nusers may continuously interact by adding or adjusting prompts.\n  In this paper, we propose SAMEdge, a novel edge-cloud computing architecture\ndesigned to support SAM computations for edge users. SAMEdge integrates new\nmodules on the edge and the cloud to maximize analytics accuracy under visual\nprompts and image prompts input with latency constraints. It addresses resource\nchallenges associated with prompt encoding and image encoding by offering a\nvisual prompt transformation algorithm for visual prompts and efficient\nworkload partitioning for image encoding. SAMEdge is implemented by extending\nthe open-source SAM project from Meta AI. We demonstrate the practical\napplication of SAMEdge through a case study on a Visual Tour Guide application.\nOur evaluation indicates that SAMEdge significantly enhances the accuracy of\nthe video analytics application under distinct network bandwidths across\nvarious prompts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14784v1",
    "published_date": "2024-09-23 07:59:09 UTC",
    "updated_date": "2024-09-23 07:59:09 UTC"
  },
  {
    "arxiv_id": "2410.01836v1",
    "title": "Temporal Graph Memory Networks For Knowledge Tracing",
    "authors": [
      "Seif Gad",
      "Sherif Abdelfattah",
      "Ghodai Abdelrahman"
    ],
    "abstract": "Tracing a student's knowledge growth given the past exercise answering is a\nvital objective in automatic tutoring systems to customize the learning\nexperience. Yet, achieving this objective is a non-trivial task as it involves\nmodeling the knowledge state across multiple knowledge components (KCs) while\nconsidering their temporal and relational dynamics during the learning process.\nKnowledge tracing methods have tackled this task by either modeling KCs'\ntemporal dynamics using recurrent models or relational dynamics across KCs and\nquestions using graph models. Albeit, there is a lack of methods that could\nlearn joint embedding between relational and temporal dynamics of the task.\nMoreover, many methods that count for the impact of a student's forgetting\nbehavior during the learning process use hand-crafted features, limiting their\ngeneralization on different scenarios. In this paper, we propose a novel method\nthat jointly models the relational and temporal dynamics of the knowledge state\nusing a deep temporal graph memory network. In addition, we propose a generic\ntechnique for representing a student's forgetting behavior using temporal decay\nconstraints on the graph memory module. We demonstrate the effectiveness of our\nproposed method using multiple knowledge tracing benchmarks while comparing it\nto state-of-the-art methods.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01836v1",
    "published_date": "2024-09-23 07:47:02 UTC",
    "updated_date": "2024-09-23 07:47:02 UTC"
  },
  {
    "arxiv_id": "2409.14762v1",
    "title": "Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?",
    "authors": [
      "Yuyan Chen",
      "Tianhao Yu",
      "Yueze Li",
      "Songzhou Yan",
      "Sijia Liu",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ],
    "abstract": "The evaluation of the problem-solving capability under incomplete information\nscenarios of Large Language Models (LLMs) is increasingly important,\nencompassing capabilities such as questioning, knowledge search, error\ndetection, and path planning. Current research mainly focus on LLMs'\nproblem-solving capability such as ``Twenty Questions''. However, these kinds\nof games do not require recognizing misleading cues which are necessary in the\nincomplete information scenario. Moreover, the existing game such as ``Who is\nundercover'' are highly subjective, making it challenging for evaluation.\nTherefore, in this paper, we introduce a novel game named BrainKing based on\nthe ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM\ncapabilities under incomplete information scenarios. It requires LLMs to\nidentify target entities with limited yes-or-no questions and potential\nmisleading answers. By setting up easy, medium, and hard difficulty modes, we\ncomprehensively assess the performance of LLMs across various aspects. Our\nresults reveal the capabilities and limitations of LLMs in BrainKing, providing\nsignificant insights of LLM problem-solving levels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2409.14762v1",
    "published_date": "2024-09-23 07:18:02 UTC",
    "updated_date": "2024-09-23 07:18:02 UTC"
  },
  {
    "arxiv_id": "2409.14759v1",
    "title": "VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models",
    "authors": [
      "Nam Hyeon-Woo",
      "Moon Ye-Bin",
      "Wonseok Choi",
      "Lee Hyun",
      "Tae-Hyun Oh"
    ],
    "abstract": "Vision language models (VLMs) have shown promising reasoning capabilities\nacross various benchmarks; however, our understanding of their visual\nperception remains limited. In this work, we propose an eye examination process\nto investigate how a VLM perceives images, specifically focusing on key\nelements of visual recognition, from primitive color and shape to semantic\nlevels. To this end, we introduce a dataset named LENS to guide a VLM to follow\nthe examination and check its readiness. Once the model is ready, we conduct\nthe examination. Through this examination, we quantify and visualize VLMs'\nsensitivities to color and shape, and semantic matching. Our findings reveal\nthat VLMs have varying sensitivity to different colors while consistently\nshowing insensitivity to green across different VLMs. Also, we found different\nshape sensitivity and semantic recognition depending on LLM's capacity despite\nusing the same fixed visual encoder. Our analyses and findings have potential\nto inspire the design of VLMs and the pre-processing of visual input to VLMs\nfor improving application performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14759v1",
    "published_date": "2024-09-23 07:15:29 UTC",
    "updated_date": "2024-09-23 07:15:29 UTC"
  },
  {
    "arxiv_id": "2409.14751v1",
    "title": "UniBEVFusion: Unified Radar-Vision BEVFusion for 3D Object Detection",
    "authors": [
      "Haocheng Zhao",
      "Runwei Guan",
      "Taoyu Wu",
      "Ka Lok Man",
      "Limin Yu",
      "Yutao Yue"
    ],
    "abstract": "4D millimeter-wave (MMW) radar, which provides both height information and\ndense point cloud data over 3D MMW radar, has become increasingly popular in 3D\nobject detection. In recent years, radar-vision fusion models have demonstrated\nperformance close to that of LiDAR-based models, offering advantages in terms\nof lower hardware costs and better resilience in extreme conditions. However,\nmany radar-vision fusion models treat radar as a sparse LiDAR, underutilizing\nradar-specific information. Additionally, these multi-modal networks are often\nsensitive to the failure of a single modality, particularly vision. To address\nthese challenges, we propose the Radar Depth Lift-Splat-Shoot (RDL) module,\nwhich integrates radar-specific data into the depth prediction process,\nenhancing the quality of visual Bird-Eye View (BEV) features. We further\nintroduce a Unified Feature Fusion (UFF) approach that extracts BEV features\nacross different modalities using shared module. To assess the robustness of\nmulti-modal models, we develop a novel Failure Test (FT) ablation experiment,\nwhich simulates vision modality failure by injecting Gaussian noise. We conduct\nextensive experiments on the View-of-Delft (VoD) and TJ4D datasets. The results\ndemonstrate that our proposed Unified BEVFusion (UniBEVFusion) network\nsignificantly outperforms state-of-the-art models on the TJ4D dataset, with\nimprovements of 1.44 in 3D and 1.72 in BEV object detection accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figues, conference",
    "pdf_url": "http://arxiv.org/pdf/2409.14751v1",
    "published_date": "2024-09-23 06:57:27 UTC",
    "updated_date": "2024-09-23 06:57:27 UTC"
  },
  {
    "arxiv_id": "2409.16326v1",
    "title": "Automated Spatio-Temporal Weather Modeling for Load Forecasting",
    "authors": [
      "Julie Keisler",
      "Margaux Bregere"
    ],
    "abstract": "Electricity is difficult to store, except at prohibitive cost, and therefore\nthe balance between generation and load must be maintained at all times.\nElectricity is traditionally managed by anticipating demand and intermittent\nproduction (wind, solar) and matching flexible production (hydro, nuclear, coal\nand gas). Accurate forecasting of electricity load and renewable production is\ntherefore essential to ensure grid performance and stability. Both are highly\ndependent on meteorological variables (temperature, wind, sunshine). These\ndependencies are complex and difficult to model. On the one hand, spatial\nvariations do not have a uniform impact because population, industry, and wind\nand solar farms are not evenly distributed across the territory. On the other\nhand, temporal variations can have delayed effects on load (due to the thermal\ninertia of buildings). With access to observations from different weather\nstations and simulated data from meteorological models, we believe that both\nphenomena can be modeled together. In today's state-of-the-art load forecasting\nmodels, the spatio-temporal modeling of the weather is fixed. In this work, we\naim to take advantage of the automated representation and spatio-temporal\nfeature extraction capabilities of deep neural networks to improve\nspatio-temporal weather modeling for load forecasting. We compare our deep\nlearning-based methodology with the state-of-the-art on French national load.\nThis methodology could also be fully adapted to forecasting renewable energy\nproduction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16326v1",
    "published_date": "2024-09-23 06:55:57 UTC",
    "updated_date": "2024-09-23 06:55:57 UTC"
  },
  {
    "arxiv_id": "2409.14747v5",
    "title": "Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting",
    "authors": [
      "Dasol Choi",
      "Dongbin Na"
    ],
    "abstract": "With the explosive growth of deep learning applications and increasing\nprivacy concerns, the right to be forgotten has become a critical requirement\nin various AI industries. For example, given a facial recognition system, some\nindividuals may wish to remove their personal data that might have been used in\nthe training phase. Unfortunately, deep neural networks sometimes unexpectedly\nleak personal identities, making this removal challenging. While recent machine\nunlearning algorithms aim to enable models to forget specific data, we identify\nan unintended utility drop-correlation collapse-in which the essential\ncorrelations between image features and true labels weaken during the\nforgetting process. To address this challenge, we propose Distribution-Level\nFeature Distancing (DLFD), a novel method that efficiently forgets instances\nwhile preserving task-relevant feature correlations. Our method synthesizes\ndata samples by optimizing the feature distribution to be distinctly different\nfrom that of forget samples, achieving effective results within a single\ntraining epoch. Through extensive experiments on facial recognition datasets,\nwe demonstrate that our approach significantly outperforms state-of-the-art\nmachine unlearning methods in both forgetting performance and model utility\npreservation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures, AAAI 2025 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2409.14747v5",
    "published_date": "2024-09-23 06:51:10 UTC",
    "updated_date": "2024-12-19 00:25:07 UTC"
  },
  {
    "arxiv_id": "2409.14741v2",
    "title": "Less yet robust: crucial region selection for scene recognition",
    "authors": [
      "Jianqi Zhang",
      "Mengxuan Wang",
      "Jingyao Wang",
      "Lingyu Si",
      "Changwen Zheng",
      "Fanjiang Xu"
    ],
    "abstract": "Scene recognition, particularly for aerial and underwater images, often\nsuffers from various types of degradation, such as blurring or overexposure.\nPrevious works that focus on convolutional neural networks have been shown to\nbe able to extract panoramic semantic features and perform well on scene\nrecognition tasks. However, low-quality images still impede model performance\ndue to the inappropriate use of high-level semantic features. To address these\nchallenges, we propose an adaptive selection mechanism to identify the most\nimportant and robust regions with high-level features. Thus, the model can\nperform learning via these regions to avoid interference. implement a learnable\nmask in the neural network, which can filter high-level features by assigning\nweights to different regions of the feature matrix. We also introduce a\nregularization term to further enhance the significance of key high-level\nfeature regions. Different from previous methods, our learnable matrix pays\nextra attention to regions that are important to multiple categories but may\ncause misclassification and sets constraints to reduce the influence of such\nregions.This is a plug-and-play architecture that can be easily extended to\nother methods. Additionally, we construct an Underwater Geological Scene\nClassification dataset to assess the effectiveness of our model. Extensive\nexperimental results demonstrate the superiority and robustness of our proposed\nmethod over state-of-the-art techniques on two datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14741v2",
    "published_date": "2024-09-23 06:39:35 UTC",
    "updated_date": "2024-10-20 11:01:17 UTC"
  },
  {
    "arxiv_id": "2409.14740v2",
    "title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information",
    "authors": [
      "Zheng Hui",
      "Zhaoxiao Guo",
      "Hang Zhao",
      "Juanyong Duan",
      "Congrui Huang"
    ],
    "abstract": "In different NLP tasks, detecting harmful content is crucial for online\nenvironments, especially with the growing influence of social media. However,\nprevious research has two main issues: 1) a lack of data in low-resource\nsettings, and 2) inconsistent definitions and criteria for judging harmful\ncontent, requiring classification models to be robust to spurious features and\ndiverse. We propose Toxicraft, a novel framework for synthesizing datasets of\nharmful information to address these weaknesses. With only a small amount of\nseed data, our framework can generate a wide variety of synthetic, yet\nremarkably realistic, examples of toxic information. Experimentation across\nvarious datasets showcases a notable enhancement in detection model robustness\nand adaptability, surpassing or close to the gold labels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.14740v2",
    "published_date": "2024-09-23 06:36:57 UTC",
    "updated_date": "2025-04-14 18:30:57 UTC"
  },
  {
    "arxiv_id": "2409.15395v1",
    "title": "Parse Trees Guided LLM Prompt Compression",
    "authors": [
      "Wenhao Mao",
      "Chengbin Hou",
      "Tianyu Zhang",
      "Xinyu Lin",
      "Ke Tang",
      "Hairong Lv"
    ],
    "abstract": "Offering rich contexts to Large Language Models (LLMs) has shown to boost the\nperformance in various tasks, but the resulting longer prompt would increase\nthe computational cost and might exceed the input limit of LLMs. Recently, some\nprompt compression methods have been suggested to shorten the length of prompts\nby using language models to generate shorter prompts or by developing\ncomputational models to select important parts of original prompt. The\ngenerative compression methods would suffer from issues like hallucination,\nwhile the selective compression methods have not involved linguistic rules and\noverlook the global structure of prompt. To this end, we propose a novel\nselective compression method called PartPrompt. It first obtains a parse tree\nfor each sentence based on linguistic rules, and calculates local information\nentropy for each node in a parse tree. These local parse trees are then\norganized into a global tree according to the hierarchical structure such as\nthe dependency of sentences, paragraphs, and sections. After that, the\nroot-ward propagation and leaf-ward propagation are proposed to adjust node\nvalues over the global tree. Finally, a recursive algorithm is developed to\nprune the global tree based on the adjusted node values. The experiments show\nthat PartPrompt receives the state-of-the-art performance across various\ndatasets, metrics, compression ratios, and target LLMs for inference. The\nin-depth ablation studies confirm the effectiveness of designs in PartPrompt,\nand other additional experiments also demonstrate its superiority in terms of\nthe coherence of compressed prompts and in the extreme long prompt scenario.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15395v1",
    "published_date": "2024-09-23 06:21:40 UTC",
    "updated_date": "2024-09-23 06:21:40 UTC"
  },
  {
    "arxiv_id": "2409.14729v2",
    "title": "PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs",
    "authors": [
      "Jiahao Yu",
      "Yangguang Shao",
      "Hanwen Miao",
      "Junzheng Shi"
    ],
    "abstract": "Large Language Models (LLMs) have gained widespread use in various\napplications due to their powerful capability to generate human-like text.\nHowever, prompt injection attacks, which involve overwriting a model's original\ninstructions with malicious prompts to manipulate the generated text, have\nraised significant concerns about the security and reliability of LLMs.\nEnsuring that LLMs are robust against such attacks is crucial for their\ndeployment in real-world applications, particularly in critical tasks.\n  In this paper, we propose PROMPTFUZZ, a novel testing framework that\nleverages fuzzing techniques to systematically assess the robustness of LLMs\nagainst prompt injection attacks. Inspired by software fuzzing, PROMPTFUZZ\nselects promising seed prompts and generates a diverse set of prompt injections\nto evaluate the target LLM's resilience. PROMPTFUZZ operates in two stages: the\nprepare phase, which involves selecting promising initial seeds and collecting\nfew-shot examples, and the focus phase, which uses the collected examples to\ngenerate diverse, high-quality prompt injections. Using PROMPTFUZZ, we can\nuncover more vulnerabilities in LLMs, even those with strong defense prompts.\n  By deploying the generated attack prompts from PROMPTFUZZ in a real-world\ncompetition, we achieved the 7th ranking out of over 4000 participants (top\n0.14%) within 2 hours. Additionally, we construct a dataset to fine-tune LLMs\nfor enhanced robustness against prompt injection attacks. While the fine-tuned\nmodel shows improved robustness, PROMPTFUZZ continues to identify\nvulnerabilities, highlighting the importance of robust testing for LLMs. Our\nwork emphasizes the critical need for effective testing tools and provides a\npractical framework for evaluating and improving the robustness of LLMs against\nprompt injection attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14729v2",
    "published_date": "2024-09-23 06:08:32 UTC",
    "updated_date": "2025-04-03 23:03:17 UTC"
  },
  {
    "arxiv_id": "2409.15394v1",
    "title": "Neural Control Variates with Automatic Integration",
    "authors": [
      "Zilu Li",
      "Guandao Yang",
      "Qingqing Zhao",
      "Xi Deng",
      "Leonidas Guibas",
      "Bharath Hariharan",
      "Gordon Wetzstein"
    ],
    "abstract": "This paper presents a method to leverage arbitrary neural network\narchitecture for control variates. Control variates are crucial in reducing the\nvariance of Monte Carlo integration, but they hinge on finding a function that\nboth correlates with the integrand and has a known analytical integral.\nTraditional approaches rely on heuristics to choose this function, which might\nnot be expressive enough to correlate well with the integrand. Recent research\nalleviates this issue by modeling the integrands with a learnable parametric\nmodel, such as a neural network. However, the challenge remains in creating an\nexpressive parametric model with a known analytical integral. This paper\nproposes a novel approach to construct learnable parametric control variates\nfunctions from arbitrary neural network architectures. Instead of using a\nnetwork to approximate the integrand directly, we employ the network to\napproximate the anti-derivative of the integrand. This allows us to use\nautomatic differentiation to create a function whose integration can be\nconstructed by the antiderivative network. We apply our method to solve partial\ndifferential equations using the Walk-on-sphere algorithm. Our results indicate\nthat this approach is unbiased and uses various network architectures to\nachieve lower variance than other control variate methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15394v1",
    "published_date": "2024-09-23 06:04:28 UTC",
    "updated_date": "2024-09-23 06:04:28 UTC"
  },
  {
    "arxiv_id": "2409.14724v1",
    "title": "EDSNet: Efficient-DSNet for Video Summarization",
    "authors": [
      "Ashish Prasad",
      "Pranav Jeevan",
      "Amit Sethi"
    ],
    "abstract": "Current video summarization methods largely rely on transformer-based\narchitectures, which, due to their quadratic complexity, require substantial\ncomputational resources. In this work, we address these inefficiencies by\nenhancing the Direct-to-Summarize Network (DSNet) with more resource-efficient\ntoken mixing mechanisms. We show that replacing traditional attention with\nalternatives like Fourier, Wavelet transforms, and Nystr\\\"omformer improves\nefficiency and performance. Furthermore, we explore various pooling strategies\nwithin the Regional Proposal Network, including ROI pooling, Fast Fourier\nTransform pooling, and flat pooling. Our experimental results on TVSum and\nSumMe datasets demonstrate that these modifications significantly reduce\ncomputational costs while maintaining competitive summarization performance.\nThus, our work offers a more scalable solution for video summarization tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.4.10; I.4.0; I.4.9; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14724v1",
    "published_date": "2024-09-23 05:43:37 UTC",
    "updated_date": "2024-09-23 05:43:37 UTC"
  },
  {
    "arxiv_id": "2409.14710v2",
    "title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning",
    "authors": [
      "Yihong Tang",
      "Jiao Ou",
      "Che Liu",
      "Fuzheng Zhang",
      "Di Zhang",
      "Kun Gai"
    ],
    "abstract": "Role-playing is an emerging application in the field of Human-Computer\nInteraction (HCI), primarily implemented through the alignment training of a\nlarge language model (LLM) with assigned characters. Despite significant\nprogress, role-playing agents (RPLAs) still struggle with maintaining\nrole-consistency across conversations, particularly when confronted with\nboundary queries subtly related to character attributes. In this paper, we\npresent ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities\nthrough boundary-aware learning. ERABAL encompasses a generation pipeline for\nrole-specific dialogues and a concomitant methodology for alignment training.\nThrough comprehensive evaluations, we demonstrate that ERABAL is both efficient\nand effective. By training with significantly fewer dialogues than those used\nin leading approaches, ERABAL achieves notable improvements across\nWikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared\nto the generalist baseline models. Our code and datasets will be made publicly\navailable to support further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.10618",
    "pdf_url": "http://arxiv.org/pdf/2409.14710v2",
    "published_date": "2024-09-23 05:12:13 UTC",
    "updated_date": "2024-10-22 09:00:19 UTC"
  },
  {
    "arxiv_id": "2409.14705v1",
    "title": "Target-Aware Language Modeling via Granular Data Sampling",
    "authors": [
      "Ernie Chang",
      "Pin-Jie Lin",
      "Yang Li",
      "Changsheng Zhao",
      "Daeil Kim",
      "Rastislav Rabatin",
      "Zechun Liu",
      "Yangyang Shi",
      "Vikas Chandra"
    ],
    "abstract": "Language model pretraining generally targets a broad range of use cases and\nincorporates data from diverse sources. However, there are instances where we\ndesire a model that excels in specific areas without markedly compromising\nperformance in other areas. A cost-effective and straightforward approach is\nsampling with low-dimensional data features, which allows to select large-scale\npretraining data for domain-specific use cases. In this work, we revisit\nimportance sampling with n-gram features consisting of multi-granular tokens,\nwhich strikes a good balance between sentence compression and representation\ncapabilities. We observed the sampled data to have a high correlation with the\ntarget downstream task performance while preserving its effectiveness on other\ntasks. This leads to the proposed data sampling paradigm where language models\ncan be pretrained more efficiently on selected documents. On eight benchmarks\nwe demonstrate with $\\sim$1% of the data, pretrained models perform on par with\nthe full RefinedWeb data and outperform randomly selected samples for model\nsizes ranging from 125M to 1.5B.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Main Conference, 9 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.14705v1",
    "published_date": "2024-09-23 04:52:17 UTC",
    "updated_date": "2024-09-23 04:52:17 UTC"
  },
  {
    "arxiv_id": "2409.14704v2",
    "title": "VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models",
    "authors": [
      "Jingtao Cao",
      "Zheng Zhang",
      "Hongru Wang",
      "Kam-Fai Wong"
    ],
    "abstract": "Progress in Text-to-Image (T2I) models has significantly improved the\ngeneration of images from textual descriptions. However, existing evaluation\nmetrics do not adequately assess the models' ability to handle a diverse range\nof textual prompts, which is crucial for their generalizability. To address\nthis, we introduce a new metric called Visual Language Evaluation Understudy\n(VLEU). VLEU uses large language models to sample from the visual text domain,\nthe set of all possible input texts for T2I models, to generate a wide variety\nof prompts. The images generated from these prompts are evaluated based on\ntheir alignment with the input text using the CLIP model.VLEU quantifies a\nmodel's generalizability by computing the Kullback-Leibler divergence between\nthe marginal distribution of the visual text and the conditional distribution\nof the images generated by the model. This metric provides a quantitative way\nto compare different T2I models and track improvements during model finetuning.\nOur experiments demonstrate the effectiveness of VLEU in evaluating the\ngeneralization capability of various T2I models, positioning it as an essential\nmetric for future research in text-to-image synthesis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "I.2.10; I.2.7; I.3.7"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by EMNLP2024(long paper,main conference)",
    "pdf_url": "http://arxiv.org/pdf/2409.14704v2",
    "published_date": "2024-09-23 04:50:36 UTC",
    "updated_date": "2024-11-15 07:19:03 UTC"
  },
  {
    "arxiv_id": "2410.07150v1",
    "title": "Graph Network Models To Detect Illicit Transactions In Block Chain",
    "authors": [
      "Hrushyang Adloori",
      "Vaishnavi Dasanapu",
      "Abhijith Chandra Mergu"
    ],
    "abstract": "The use of cryptocurrencies has led to an increase in illicit activities such\nas money laundering, with traditional rule-based approaches becoming less\neffective in detecting and preventing such activities. In this paper, we\npropose a novel approach to tackling this problem by applying graph attention\nnetworks with residual network-like architecture (GAT-ResNet) to detect illicit\ntransactions related to anti-money laundering/combating the financing of\nterrorism (AML/CFT) in blockchains. We train various models on the Elliptic\nBitcoin Transaction dataset, implementing logistic regression, Random Forest,\nXGBoost, GCN, GAT, and our proposed GAT-ResNet model. Our results demonstrate\nthat the GAT-ResNet model has a potential to outperform the existing graph\nnetwork models in terms of accuracy, reliability and scalability. Our research\nsheds light on the potential of graph related machine learning models to\nimprove efforts to combat financial crime and lays the foundation for further\nresearch in this area.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07150v1",
    "published_date": "2024-09-23 04:38:44 UTC",
    "updated_date": "2024-09-23 04:38:44 UTC"
  },
  {
    "arxiv_id": "2409.15393v1",
    "title": "Approximated Orthogonal Projection Unit: Stabilizing Regression Network Training Using Natural Gradient",
    "authors": [
      "Shaoqi Wang",
      "Chunjie Yang",
      "Siwei Lou"
    ],
    "abstract": "Neural networks (NN) are extensively studied in cutting-edge soft sensor\nmodels due to their feature extraction and function approximation capabilities.\nCurrent research into network-based methods primarily focuses on models'\noffline accuracy. Notably, in industrial soft sensor context, online optimizing\nstability and interpretability are prioritized, followed by accuracy. This\nrequires a clearer understanding of network's training process. To bridge this\ngap, we propose a novel NN named the Approximated Orthogonal Projection Unit\n(AOPU) which has solid mathematical basis and presents superior training\nstability. AOPU truncates the gradient backpropagation at dual parameters,\noptimizes the trackable parameters updates, and enhances the robustness of\ntraining. We further prove that AOPU attains minimum variance estimation (MVE)\nin NN, wherein the truncated gradient approximates the natural gradient (NG).\nEmpirical results on two chemical process datasets clearly show that AOPU\noutperforms other models in achieving stable convergence, marking a significant\nadvancement in soft sensor field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15393v1",
    "published_date": "2024-09-23 03:42:50 UTC",
    "updated_date": "2024-09-23 03:42:50 UTC"
  },
  {
    "arxiv_id": "2409.14683v1",
    "title": "Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling",
    "authors": [
      "Benjamin Clavié",
      "Antoine Chaffin",
      "Griffin Adams"
    ],
    "abstract": "Over the last few years, multi-vector retrieval methods, spearheaded by\nColBERT, have become an increasingly popular approach to Neural IR. By storing\nrepresentations at the token level rather than at the document level, these\nmethods have demonstrated very strong retrieval performance, especially in\nout-of-domain settings. However, the storage and memory requirements necessary\nto store the large number of associated vectors remain an important drawback,\nhindering practical adoption. In this paper, we introduce a simple\nclustering-based token pooling approach to aggressively reduce the number of\nvectors that need to be stored. This method can reduce the space & memory\nfootprint of ColBERT indexes by 50% with virtually no retrieval performance\ndegradation. This method also allows for further reductions, reducing the\nvector count by 66%-to-75% , with degradation remaining below 5% on a vast\nmajority of datasets. Importantly, this approach requires no architectural\nchange nor query-time processing, and can be used as a simple drop-in during\nindexation with any ColBERT-like model.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14683v1",
    "published_date": "2024-09-23 03:12:43 UTC",
    "updated_date": "2024-09-23 03:12:43 UTC"
  },
  {
    "arxiv_id": "2409.14679v2",
    "title": "Quantifying Context Bias in Domain Adaptation for Object Detection",
    "authors": [
      "Hojun Son",
      "Asma Almutairi",
      "Arpan Kusari"
    ],
    "abstract": "Domain adaptation for object detection (DAOD) seeks to transfer a trained\nmodel from a source to a target domain. Various DAOD methods exist, some of\nwhich aim to minimize context bias between foreground-background associations\nin various domains. However, no prior work has studied context bias in DAOD by\nanalyzing changes in background features during adaptation and how context bias\nis represented in different domains. Our research experiment highlights the\npotential usability of context bias in DAOD. We address the problem by varying\nactivation values over different layers of two different trained models,\nDetectron2 and YOLOv11, and by masking the background, both of which impact the\nnumber and quality of detections. We use two synthetic datasets, CARLA and\nVirtual KITTI, and two different versions of real open-source data, Cityscapes\nand KITTI semantic, as separate domains to represent and quantify context bias.\nWe utilize different metrics such as Maximum Mean Discrepancy (MMD) and Maximum\nVariance Discrepancy (MVD) to find the layer-specific conditional probability\nestimates of foreground given manipulated background regions for separate\ndomains. We further analyze foreground-background associations across various\ndataset combinations. We find that state-of-the-art domain adaptation methods\nexhibit some form of context bias and apply a potentially simple way to\nalleviate the context bias achieving improved accuracy (from 51.189 to 53.646\nmAP on Cityscapes foggy validation with 63.207 mAP and 64.233 mAP on Cityscapes\nvalidation respectively). We demonstrate through detailed analysis that\nunderstanding of the context bias can affect DAOD approach and focusing solely\non aligning foreground features is insufficient for effective DAOD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2409.14679v2",
    "published_date": "2024-09-23 03:01:50 UTC",
    "updated_date": "2025-05-19 15:50:40 UTC"
  },
  {
    "arxiv_id": "2409.14673v1",
    "title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science",
    "authors": [
      "Taihang Wang",
      "Xiaoman Xu",
      "Yimin Wang",
      "Ye Jiang"
    ],
    "abstract": "Real-world applications of large language models (LLMs) in computational\nsocial science (CSS) tasks primarily depend on the effectiveness of instruction\ntuning (IT) or in-context learning (ICL). While IT has shown highly effective\nat fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task\nadaptation by learning from examples without explicit gradient updates. In this\npaper, we evaluate the classification performance of LLMs using IT versus ICL\nin few-shot CSS tasks. The experimental results indicate that ICL consistently\noutperforms IT in most CSS tasks. Additionally, we investigate the relationship\nbetween the increasing number of training samples and LLM performance. Our\nfindings show that simply increasing the number of samples without considering\ntheir quality does not consistently enhance the performance of LLMs with either\nICL or IT and can sometimes even result in a performance decline. Finally, we\ncompare three prompting strategies, demonstrating that ICL is more effective\nthan zero-shot and Chain-of-Thought (CoT). Our research highlights the\nsignificant advantages of ICL in handling CSS tasks in few-shot settings and\nemphasizes the importance of optimizing sample quality and prompting strategies\nto improve LLM classification performance. The code will be made available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14673v1",
    "published_date": "2024-09-23 02:43:08 UTC",
    "updated_date": "2024-09-23 02:43:08 UTC"
  },
  {
    "arxiv_id": "2409.14672v1",
    "title": "Speechworthy Instruction-tuned Language Models",
    "authors": [
      "Hyundong Cho",
      "Nicolaas Jedema",
      "Leonardo F. R. Ribeiro",
      "Karishma Sharma",
      "Pedro Szekely",
      "Alessandro Moschitti",
      "Ruben Janssen",
      "Jonathan May"
    ],
    "abstract": "Current instruction-tuned language models are exclusively trained with\ntextual preference data and thus are often not aligned with the unique\nrequirements of other modalities, such as speech. To better align language\nmodels with the speech domain, we explore (i) prompting strategies grounded in\nradio-industry best practices and (ii) preference learning using a novel\nspeech-based preference data of 20K samples, generated with a wide spectrum of\nprompts that induce varying dimensions of speech-suitability and labeled by\nannotators who listen to response pairs. Both human and automatic evaluation\nshow that both prompting and preference learning increase the\nspeech-suitability of popular instruction-tuned LLMs. Interestingly, we find\nthat prompting and preference learning can be additive; combining them achieves\nthe best win rates in head-to-head comparison, resulting in responses that are\npreferred or tied to the base model in 76.2% of comparisons on average. Lastly,\nwe share lexical, syntactical, and qualitative analyses to showcase how each\nmethod contributes to improving the speech-suitability of generated responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP2024",
    "pdf_url": "http://arxiv.org/pdf/2409.14672v1",
    "published_date": "2024-09-23 02:34:42 UTC",
    "updated_date": "2024-09-23 02:34:42 UTC"
  },
  {
    "arxiv_id": "2409.14671v1",
    "title": "FedGCA: Global Consistent Augmentation Based Single-Source Federated Domain Generalization",
    "authors": [
      "Yuan Liu",
      "Shu Wang",
      "Zhe Qu",
      "Xingyu Li",
      "Shichao Kan",
      "Jianxin Wang"
    ],
    "abstract": "Federated Domain Generalization (FedDG) aims to train the global model for\ngeneralization ability to unseen domains with multi-domain training samples.\nHowever, clients in federated learning networks are often confined to a single,\nnon-IID domain due to inherent sampling and temporal limitations. The lack of\ncross-domain interaction and the in-domain divergence impede the learning of\ndomain-common features and limit the effectiveness of existing FedDG, referred\nto as the single-source FedDG (sFedDG) problem. To address this, we introduce\nthe Federated Global Consistent Augmentation (FedGCA) method, which\nincorporates a style-complement module to augment data samples with diverse\ndomain styles. To ensure the effective integration of augmented samples, FedGCA\nemploys both global guided semantic consistency and class consistency,\nmitigating inconsistencies from local semantics within individual clients and\nclasses across multiple clients. The conducted extensive experiments\ndemonstrate the superiority of FedGCA.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 7 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2409.14671v1",
    "published_date": "2024-09-23 02:24:46 UTC",
    "updated_date": "2024-09-23 02:24:46 UTC"
  },
  {
    "arxiv_id": "2409.14666v1",
    "title": "Semi-supervised Learning For Robust Speech Evaluation",
    "authors": [
      "Huayun Zhang",
      "Jeremy H. M. Wong",
      "Geyu Lin",
      "Nancy F. Chen"
    ],
    "abstract": "Speech evaluation measures a learners oral proficiency using automatic\nmodels. Corpora for training such models often pose sparsity challenges given\nthat there often is limited scored data from teachers, in addition to the score\ndistribution across proficiency levels being often imbalanced among student\ncohorts. Automatic scoring is thus not robust when faced with under-represented\nsamples or out-of-distribution samples, which inevitably exist in real-world\ndeployment scenarios. This paper proposes to address such challenges by\nexploiting semi-supervised pre-training and objective regularization to\napproximate subjective evaluation criteria. In particular, normalized mutual\ninformation is used to quantify the speech characteristics from the learner and\nthe reference. An anchor model is trained using pseudo labels to predict the\ncorrectness of pronunciation. An interpolated loss function is proposed to\nminimize not only the prediction error with respect to ground-truth scores but\nalso the divergence between two probability distributions estimated by the\nspeech evaluation model and the anchor model. Compared to other\nstate-of-the-art methods on a public data-set, this approach not only achieves\nhigh performance while evaluating the entire test-set as a whole, but also\nbrings the most evenly distributed prediction error across distinct proficiency\nlevels. Furthermore, empirical results show the model accuracy on\nout-of-distribution data also compares favorably with competitive baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.14666v1",
    "published_date": "2024-09-23 02:11:24 UTC",
    "updated_date": "2024-09-23 02:11:24 UTC"
  },
  {
    "arxiv_id": "2410.07144v1",
    "title": "Natural Language Query Engine for Relational Databases using Generative AI",
    "authors": [
      "Steve Tueno Fotso"
    ],
    "abstract": "The growing reliance on data-driven decision-making highlights the need for\nmore intuitive ways to access and analyze information stored in relational\ndatabases. However, the requirement of SQL knowledge has long been a\nsignificant barrier for non-technical users. This article introduces an\ninnovative solution that leverages Generative AI to bridge this gap, enabling\nusers to query databases using natural language. Our approach automatically\ntranslates natural language queries into SQL, ensuring both syntactic and\nsemantic correctness, while also generating clear, natural language responses\nfrom the retrieved data. By streamlining the interaction between users and\ndatabases, this method empowers individuals without technical expertise to\nengage with data directly and efficiently, democratizing access to valuable\ninsights and enhancing productivity.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "Artificial Intelligence, Machine Learning, Generative AI, SQL,\n  Relational Database, SQL Correctness",
    "pdf_url": "http://arxiv.org/pdf/2410.07144v1",
    "published_date": "2024-09-23 01:07:02 UTC",
    "updated_date": "2024-09-23 01:07:02 UTC"
  },
  {
    "arxiv_id": "2409.14644v2",
    "title": "zsLLMCode: An Effective Approach for Code Embedding via LLM with Zero-Shot Learning",
    "authors": [
      "Zixiang Xian",
      "Chenhui Cui",
      "Rubing Huang",
      "Chunrong Fang",
      "Zhenyu Chen"
    ],
    "abstract": "The advent of large language models (LLMs) has greatly advanced artificial\nintelligence (AI) in software engineering (SE), with code embeddings playing a\ncritical role in tasks like code-clone detection and code clustering. However,\nexisting methods for code embedding, including those based on LLMs, often\ndepend on costly supervised training or fine-tuning for domain adaptation. This\npaper proposes a novel zero-shot approach, zsLLMCode, to generate code\nembeddings by using LLMs and sentence embedding models. This approach attempts\nto eliminate the need for task-specific training or fine-tuning, and to\neffectively address the issue of erroneous information commonly found in\nLLM-generated outputs. We conducted a series of experiments to evaluate the\nperformance of the proposed approach by considering various LLMs and embedding\nmodels. The results have demonstrated the effectiveness and superiority of our\nmethod zsLLMCode over state-of-the-art unsupervised approaches such as\nSourcererCC, Code2vec, InferCode, and TransformCode. Our findings highlight the\npotential of zsLLMCode to advance the field of SE by providing robust and\nefficient solutions for code embedding tasks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14644v2",
    "published_date": "2024-09-23 01:03:15 UTC",
    "updated_date": "2025-03-05 05:42:35 UTC"
  },
  {
    "arxiv_id": "2409.14637v1",
    "title": "Not Only the Last-Layer Features for Spurious Correlations: All Layer Deep Feature Reweighting",
    "authors": [
      "Humza Wajid Hameed",
      "Geraldin Nanfack",
      "Eugene Belilovsky"
    ],
    "abstract": "Spurious correlations are a major source of errors for machine learning\nmodels, in particular when aiming for group-level fairness. It has been\nrecently shown that a powerful approach to combat spurious correlations is to\nre-train the last layer on a balanced validation dataset, isolating robust\nfeatures for the predictor. However, key attributes can sometimes be discarded\nby neural networks towards the last layer. In this work, we thus consider\nretraining a classifier on a set of features derived from all layers. We\nutilize a recently proposed feature selection strategy to select unbiased\nfeatures from all the layers. We observe this approach gives significant\nimprovements in worst-group accuracy on several standard benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.14637v1",
    "published_date": "2024-09-23 00:31:39 UTC",
    "updated_date": "2024-09-23 00:31:39 UTC"
  },
  {
    "arxiv_id": "2409.14634v4",
    "title": "Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination",
    "authors": [
      "Marissa Radensky",
      "Simra Shahid",
      "Raymond Fok",
      "Pao Siangliulue",
      "Tom Hope",
      "Daniel S. Weld"
    ],
    "abstract": "The scientific ideation process often involves blending salient aspects of\nexisting papers to create new ideas, and facet-based ideation is an established\nframework for idea generation. To see how large language models (LLMs) might\nassist in this process, we contribute a novel mixed-initiative ideation tool\ncalled Scideator. Starting from a user-provided set of scientific papers,\nScideator extracts key facets -- purposes, mechanisms, and evaluations -- from\nthese and related papers, allowing users to explore the idea space by\ninteractively recombining facets to synthesize inventive ideas. Scideator also\nhelps users gauge idea originality by searching the literature for overlaps,\nassessing idea novelty and providing explanations. To support these tasks,\nScideator introduces three LLM-powered retrieval-augmented generation (RAG)\nmodules: Analogous Paper Facet Finder, Faceted Idea Generator, and Idea Novelty\nChecker. In a within-subjects user study (N=22) with computer-science\nresearchers comparing Scideator to a strong baseline, our tool provided\nsignificantly more creativity support, particularly with respect to\nexploration, which participants considered the most important factor for idea\ngeneration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2, I.2"
    ],
    "primary_category": "cs.HC",
    "comment": "Updated with new and improved user study",
    "pdf_url": "http://arxiv.org/pdf/2409.14634v4",
    "published_date": "2024-09-23 00:09:34 UTC",
    "updated_date": "2025-04-29 04:47:58 UTC"
  },
  {
    "arxiv_id": "2409.14633v1",
    "title": "Hierarchical end-to-end autonomous navigation through few-shot waypoint detection",
    "authors": [
      "Amin Ghafourian",
      "Zhongying CuiZhu",
      "Debo Shi",
      "Ian Chuang",
      "Francois Charette",
      "Rithik Sachdeva",
      "Iman Soltani"
    ],
    "abstract": "Human navigation is facilitated through the association of actions with\nlandmarks, tapping into our ability to recognize salient features in our\nenvironment. Consequently, navigational instructions for humans can be\nextremely concise, such as short verbal descriptions, indicating a small memory\nrequirement and no reliance on complex and overly accurate navigation tools.\nConversely, current autonomous navigation schemes rely on accurate positioning\ndevices and algorithms as well as extensive streams of sensory data collected\nfrom the environment. Inspired by this human capability and motivated by the\nassociated technological gap, in this work we propose a hierarchical end-to-end\nmeta-learning scheme that enables a mobile robot to navigate in a previously\nunknown environment upon presentation of only a few sample images of a set of\nlandmarks along with their corresponding high-level navigation actions. This\ndramatically simplifies the wayfinding process and enables easy adoption to new\nenvironments. For few-shot waypoint detection, we implement a metric-based\nfew-shot learning technique through distribution embedding. Waypoint detection\ntriggers the multi-task low-level maneuver controller module to execute the\ncorresponding high-level navigation action. We demonstrate the effectiveness of\nthe scheme using a small-scale autonomous vehicle on novel indoor navigation\ntasks in several previously unseen environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Appeared at the 40th Anniversary of the IEEE International Conference\n  on Robotics and Automation (ICRA@40), 23-26 September, 2024, Rotterdam, The\n  Netherlands. 9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.14633v1",
    "published_date": "2024-09-23 00:03:39 UTC",
    "updated_date": "2024-09-23 00:03:39 UTC"
  }
]