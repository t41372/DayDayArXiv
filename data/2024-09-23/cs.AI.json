{
  "date": "2024-09-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-23 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、应用和评估，特别是 LLMs 和 VLMs 在多模态任务、机器人导航和医疗领域的创新进展，令人印象深刻的作品包括 OpenAI o1 在医疗中的表现，以及 Carla Gomes 和 Marco Hutter 等学者的贡献，如 GEM-RAG 和 Tag Map 等。\n\n下面，我将逐一简要概述今日论文，先优先讨论重要、创新或有话题度的文章（如涉及 LLMs 优化、机器人和医疗），并将相关主题归类讨论。其他较常规或次要论文（如一些天文或基础算法改进）将快速掠过，只提核心点。\n\n### LLMs 和多模态模型优化\n- **Safe Guard: an LLM-agent for Real-time Voice-based Hate Speech Detection in Social Virtual Reality**（中文：安全守护：用于社交虚拟现实中实时语音仇恨言论检测的 LLM 代理）  \n  这篇论文提出 Safe Guard 系统，使用 OpenAI GPT 和音频特征提取实现实时仇恨言论检测。主要贡献是系统设计和评估，显著降低了误报率，为 LLM 驱动的虚拟环境 moderation 提供了基础。\n\n- **GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**（中文：GEM-RAG：用于检索增强生成的图形特征记忆）  \n  作者包括知名学者 Carla Gomes。该工作扩展 RAG 方法，通过图形嵌入和特征标记提升 LLM 的记忆和检索能力。主要发现是，在 QA 任务中，GEM-RAG 超过了现有 RAG 方法，提升了知识检索的鲁棒性。\n\n- **Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models**（中文：Tag Map：用于 LLM 空间推理和导航的基于文本地图）  \n  作者包括 Marco Hutter。该论文设计了一个文本-based 地图系统，帮助 LLM 处理空间任务。主要贡献是结合文本和视觉嵌入，实现高效的导航和推理，适用于机器人应用。\n\n- **o1 in Medicine: Are We Closer to an AI Doctor?**（中文：o1 在医疗中的应用：我们更接近 AI 医生了吗？）  \n  这篇讨论 OpenAI 的 o1 模型在医疗中的表现，通过多任务评估（理解、推理和多语性）。主要发现是 o1 在复杂医疗 QA 上优于 GPT-4，提升了 6.2% 的准确率，但仍存在幻觉和评估挑战。\n\n- **ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning**（中文：ERABAL：通过边界感知学习增强角色扮演代理）  \n  论文提出 ERABAL 框架，提升 LLM 在角色扮演中的一致性。主要贡献是通过边界查询处理和强化学习，显著提高了代理的鲁棒性。\n\n其他 LLMs 相关论文，如 Instruction Tuning 和 RAG 优化，多数聚焦细化技术，但整体影响不如上述，快速掠过：它们证实了 LLM 在偏好优化和检索上的改进，但未带来突破性。\n\n### 机器人和强化学习应用\n- **PERPL: Physics Enhanced Residual Policy Learning for safety cruising in mixed traffic platooning under actuator and communication delay**（中文：PERPL：物理增强残差策略学习，用于混合交通编队中的安全巡航）  \n  这篇论文结合物理模型和强化学习，提出 PERPL 框架，用于自动车辆控制。主要发现是，在延迟场景下，PERPL 比传统 RL 和线性模型更稳定，减少了交通震荡。\n\n- **FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality**（中文：FACET：基于椭圆建模的快速准确事件型眼动追踪，用于扩展现实）  \n  论文开发了 FACET 神经网络，用于 XR 中的眼动追踪。主要贡献是利用事件相机数据，实现 0.20 像素的瞳孔中心误差，速度比现有方法快 1.8 倍。\n\n- **COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models**（中文：COHERENT：使用 LLM 的异构多机器人系统协作）  \n  该工作使用 LLM 提升多机器人协作，提出 PEFA 机制。主要发现是，在复杂任务中，成功率提升 1.3 倍，展示了 LLM 在机器人规划中的潜力。\n\n其他机器人论文，如导航和轨迹预测，多数是技术迭代，快速掠过：它们验证了强化学习在动态环境中的效果，但未有重大创新。\n\n### 医疗和生物应用\n- **Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration**（中文：革新生物标记物发现：利用生成式 AI 进行生物知识嵌入的连续空间探索）  \n  论文提出一个生成 AI 框架，用于自动识别生物标记物。主要贡献是通过多代理系统和嵌入优化，在真实数据集上展示了高效性和鲁棒性。\n\n- **TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU**（中文：TFT-multi：ICU 中同时预测多重生命体征轨迹）  \n  该工作扩展 Temporal Fusion Transformer，实现多生命体征预测。主要发现是，在 MIMIC 数据集上，准确性优于单变量模型，提升了临床预测能力。\n\n其他医疗论文，如 MRI 分析和癌症预测，快速掠过：它们展示了 AI 在诊断中的应用，但核心在于数据融合和模型微调，未有颠覆性突破。\n\n### 其他领域快速掠过\n- 天文论文如 **The Palomar twilight survey** 和 **Identification and Localization of Cometary Activity**，主要贡献是使用机器学习检测天体活动，但主题较 niche，仅提其在 AI 辅助天文观察中的潜力。\n- 图像和视频生成论文，如 **StarVid** 和 **Style Outweighs Substance**，讨论了视觉模型的偏差和优化，但影响有限。\n- 一些基础算法论文，如 **Domino** 和 **CANDERE-COACH**，聚焦通信优化和强化学习，但未涉及高影响力领域，快速一带而过。\n\n总之，今天的 arXiv 论文突显了 AI 模型在实际应用中的潜力，尤其是 LLMs 在多模态和机器人领域的扩展。未来，关注模型鲁棒性和真实部署将是关键方向。更多细节可查阅特定论文！",
  "papers": [
    {
      "arxiv_id": "2409.15623v1",
      "title": "Safe Guard: an LLM-agent for Real-time Voice-based Hate Speech Detection in Social Virtual Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Xu",
        "Qinyang Hou",
        "Hongyu Wan",
        "Mirjana Prpa"
      ],
      "abstract": "In this paper, we present Safe Guard, an LLM-agent for the detection of hate\nspeech in voice-based interactions in social VR (VRChat). Our system leverages\nOpen AI GPT and audio feature extraction for real-time voice interactions. We\ncontribute a system design and evaluation of the system that demonstrates the\ncapability of our approach in detecting hate speech, and reducing false\npositives compared to currently available approaches. Our results indicate the\npotential of LLM-based agents in creating safer virtual environments and set\nthe groundwork for further advancements in LLM-driven moderation approaches.",
      "tldr_zh": "本文提出 Safe Guard，这是一个基于 LLM-agent 的系统，用于在社交虚拟现实（social VR）中实时检测语音互动中的仇恨言论（hate speech）。系统结合 OpenAI GPT 和音频特征提取技术，实现高效的实时监测，并通过评估证明其在检测准确性和减少假阳性方面优于现有方法。研究结果表明，LLM-based agents 有潜力提升虚拟环境的安全性，并为 LLM-driven moderation 提供新的发展基础。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15623v1",
      "published_date": "2024-09-23 23:54:45 UTC",
      "updated_date": "2024-09-23 23:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:31:35.511956"
    },
    {
      "arxiv_id": "2409.19013v3",
      "title": "Improving Academic Skills Assessment with NLP and Ensemble Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Huang",
        "Yingyi Wu",
        "Danyang Zhang",
        "Jiacheng Hu",
        "Yujian Long"
      ],
      "abstract": "This study addresses the critical challenges of assessing foundational\nacademic skills by leveraging advancements in natural language processing\n(NLP). Traditional assessment methods often struggle to provide timely and\ncomprehensive feedback on key cognitive and linguistic aspects, such as\ncoherence, syntax, and analytical reasoning. Our approach integrates multiple\nstate-of-the-art NLP models, including BERT, RoBERTa, BART, DeBERTa, and T5,\nwithin an ensemble learning framework. These models are combined through\nstacking techniques using LightGBM and Ridge regression to enhance predictive\naccuracy. The methodology involves detailed data preprocessing, feature\nextraction, and pseudo-label learning to optimize model performance. By\nincorporating sophisticated NLP techniques and ensemble learning, this study\nsignificantly improves the accuracy and efficiency of assessments, offering a\nrobust solution that surpasses traditional methods and opens new avenues for\neducational technology research focused on enhancing core academic\ncompetencies.",
      "tldr_zh": "这篇论文针对评估基础学术技能的挑战，利用 NLP 和集成学习（Ensemble Learning）来提供更及时全面的反馈，包括连贯性、语法和分析推理等方面。研究方法整合了多个先进 NLP 模型，如 BERT、RoBERTa、BART、DeBERTa 和 T5，通过 stacking 技术结合 LightGBM 和 Ridge regression，并采用数据预处理、特征提取和伪标签学习来优化性能。结果表明，该方法显著提高了评估的准确性和效率，超越传统方法，并为教育技术研究提供了新的途径以提升核心学术能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.19013v3",
      "published_date": "2024-09-23 23:43:43 UTC",
      "updated_date": "2024-10-13 05:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:31:48.571651"
    },
    {
      "arxiv_id": "2409.15612v1",
      "title": "Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Wangyang Ying",
        "Dongjie Wang",
        "Xuanming Hu",
        "Ji Qiu",
        "Jin Park",
        "Yanjie Fu"
      ],
      "abstract": "Biomarker discovery is vital in advancing personalized medicine, offering\ninsights into disease diagnosis, prognosis, and therapeutic efficacy.\nTraditionally, the identification and validation of biomarkers heavily depend\non extensive experiments and statistical analyses. These approaches are\ntime-consuming, demand extensive domain expertise, and are constrained by the\ncomplexity of biological systems. These limitations motivate us to ask: Can we\nautomatically identify the effective biomarker subset without substantial human\nefforts? Inspired by the success of generative AI, we think that the intricate\nknowledge of biomarker identification can be compressed into a continuous\nembedding space, thus enhancing the search for better biomarkers. Thus, we\npropose a new biomarker identification framework with two important modules:1)\ntraining data preparation and 2) embedding-optimization-generation. The first\nmodule uses a multi-agent system to automatically collect pairs of biomarker\nsubsets and their corresponding prediction accuracy as training data. These\ndata establish a strong knowledge base for biomarker identification. The second\nmodule employs an encoder-evaluator-decoder learning paradigm to compress the\nknowledge of the collected data into a continuous space. Then, it utilizes\ngradient-based search techniques and autoregressive-based reconstruction to\nefficiently identify the optimal subset of biomarkers. Finally, we conduct\nextensive experiments on three real-world datasets to show the efficiency,\nrobustness, and effectiveness of our method.",
      "tldr_zh": "本研究旨在解决传统生物标记物(biomarker)发现过程的耗时性和依赖性问题，通过生成式 AI 自动识别有效生物标记物子集。论文提出一个新框架，包括两个模块：1) 训练数据准备，使用多智能体(multi-agent system)系统自动收集生物标记物子集及其预测准确性的配对数据，建立知识基础；2) 嵌入-优化-生成(embedding-optimization-generation)模块，采用编码器-评估器-解码器(encoder-evaluator-decoder)学习范式，将知识压缩到连续空间，并通过基于梯度的搜索和自回归重建技术高效优化子集。在三个真实世界数据集上的实验验证了该方法的效率、鲁棒性和有效性，显著减少了人力需求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15612v1",
      "published_date": "2024-09-23 23:36:30 UTC",
      "updated_date": "2024-09-23 23:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:32:00.149707"
    },
    {
      "arxiv_id": "2409.15595v1",
      "title": "Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay",
      "title_zh": "翻译失败",
      "authors": [
        "Keke Long",
        "Haotian Shi",
        "Yang Zhou",
        "Xiaopeng Li"
      ],
      "abstract": "Linear control models have gained extensive application in vehicle control\ndue to their simplicity, ease of use, and support for stability analysis.\nHowever, these models lack adaptability to the changing environment and\nmulti-objective settings. Reinforcement learning (RL) models, on the other\nhand, offer adaptability but suffer from a lack of interpretability and\ngeneralization capabilities. This paper aims to develop a family of RL-based\ncontrollers enhanced by physics-informed policies, leveraging the advantages of\nboth physics-based models (data-efficient and interpretable) and RL methods\n(flexible to multiple objectives and fast computing). We propose the\nPhysics-Enhanced Residual Policy Learning (PERPL) framework, where the physics\ncomponent provides model interpretability and stability. The learning-based\nResidual Policy adjusts the physics-based policy to adapt to the changing\nenvironment, thereby refining the decisions of the physics model. We apply our\nproposed model to decentralized control to mixed traffic platoon of Connected\nand Automated Vehicles (CAVs) and Human-driven Vehicles (HVs) using a constant\ntime gap (CTG) strategy for cruising and incorporating actuator and\ncommunication delays. Experimental results demonstrate that our method achieves\nsmaller headway errors and better oscillation dampening than linear models and\nRL alone in scenarios with artificially extreme conditions and real preceding\nvehicle trajectories. At the macroscopic level, overall traffic oscillations\nare also reduced as the penetration rate of CAVs employing the PERPL scheme\nincreases.",
      "tldr_zh": "本文提出 Physics-Enhanced Residual Policy Learning (PERPL) 框架，旨在结合物理模型的解释性和 Reinforcement Learning (RL) 的适应性，解决线性控制模型在混合交通车队控制中的环境适应性不足问题。PERPL 通过物理组件提供稳定的基础策略，而 RL 残差策略则动态调整以应对环境变化，并在 actuator and communication delays 下应用 constant time gap (CTG) 策略进行安全巡航。实验结果表明，该方法在混合车队（包括 Connected and Automated Vehicles (CAVs) 和 Human-driven Vehicles (HVs)）中显著减少 headway errors 和交通震荡，且随着 CAVs 渗透率增加，整体交通稳定性进一步提升。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15595v1",
      "published_date": "2024-09-23 23:02:34 UTC",
      "updated_date": "2024-09-23 23:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:32:13.582127"
    },
    {
      "arxiv_id": "2409.15586v3",
      "title": "TFT-multi: simultaneous forecasting of vital sign trajectories in the ICU",
      "title_zh": "翻译失败",
      "authors": [
        "Rosemary Y. He",
        "Jeffrey N. Chiang"
      ],
      "abstract": "Trajectory forecasting in healthcare data has been an important area of\nresearch in precision care and clinical integration for computational methods.\nIn recent years, generative AI models have demonstrated promising results in\ncapturing short and long range dependencies in time series data. While these\nmodels have also been applied in healthcare, most of them only predict one\nvalue at a time, which is unrealistic in a clinical setting where multiple\nmeasures are taken at once. In this work, we extend the framework temporal\nfusion transformer (TFT), a multi-horizon time series prediction tool, and\npropose TFT-multi, an end-to-end framework that can predict multiple vital\ntrajectories simultaneously. We apply TFT-multi to forecast 5 vital signs\nrecorded in the intensive care unit: blood pressure, pulse, SpO2, temperature\nand respiratory rate. We hypothesize that by jointly predicting these measures,\nwhich are often correlated with one another, we can make more accurate\npredictions, especially in variables with large missingness. We validate our\nmodel on the public MIMIC dataset and an independent institutional dataset, and\ndemonstrate that this approach outperforms state-of-the-art univariate\nprediction tools including the original TFT and Prophet, as well as vector\nregression modeling for multivariate prediction. Furthermore, we perform a\nstudy case analysis by applying our pipeline to forecast blood pressure changes\nin response to actual and hypothetical pressor administration.",
      "tldr_zh": "本研究扩展了Temporal Fusion Transformer (TFT)框架，提出TFT-multi模型，用于同时预测ICU中多个生命体征轨迹，从而解决传统模型仅预测单一值的问题。TFT-multi采用端到端的多变量联合预测方法，应用于血压、脉搏、SpO2、体温和呼吸率等5个相关指标，假设这种联合预测能提升准确性，尤其在数据缺失严重的情况下。实验在公共MIMIC数据集和独立机构数据集上验证，TFT-multi优于单变量工具（如原TFT和Prophet）以及多变量回归模型；此外，通过案例分析，该框架成功预测了血压对加压药物反应的变化，为临床决策提供更可靠的支持。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15586v3",
      "published_date": "2024-09-23 22:36:37 UTC",
      "updated_date": "2024-12-06 18:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:32:24.840603"
    },
    {
      "arxiv_id": "2409.15584v1",
      "title": "FACET: Fast and Accurate Event-Based Eye Tracking Using Ellipse Modeling for Extended Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Junyuan Ding",
        "Ziteng Wang",
        "Chang Gao",
        "Min Liu",
        "Qinyu Chen"
      ],
      "abstract": "Eye tracking is a key technology for gaze-based interactions in Extended\nReality (XR), but traditional frame-based systems struggle to meet XR's demands\nfor high accuracy, low latency, and power efficiency. Event cameras offer a\npromising alternative due to their high temporal resolution and low power\nconsumption. In this paper, we present FACET (Fast and Accurate Event-based Eye\nTracking), an end-to-end neural network that directly outputs pupil ellipse\nparameters from event data, optimized for real-time XR applications. The\nellipse output can be directly used in subsequent ellipse-based pupil trackers.\nWe enhance the EV-Eye dataset by expanding annotated data and converting\noriginal mask labels to ellipse-based annotations to train the model. Besides,\na novel trigonometric loss is adopted to address angle discontinuities and a\nfast causal event volume event representation method is put forward. On the\nenhanced EV-Eye test set, FACET achieves an average pupil center error of 0.20\npixels and an inference time of 0.53 ms, reducing pixel error and inference\ntime by 1.6$\\times$ and 1.8$\\times$ compared to the prior art, EV-Eye, with\n4.4$\\times$ and 11.7$\\times$ less parameters and arithmetic operations. The\ncode is available at https://github.com/DeanJY/FACET.",
      "tldr_zh": "本研究提出 FACET，一种基于事件相机的事件眼动追踪系统，利用椭圆建模（ellipse modeling）实现快速且准确的眼部追踪，针对 Extended Reality (XR) 应用的需求优化。FACET 是一个端到端的神经网络，直接从事件数据输出瞳孔椭圆参数，并引入 trigonometric loss 处理角度不连续性，以及 fast causal event volume 方法提升效率；同时，研究者增强了 EV-Eye 数据集以支持模型训练。实验结果显示，FACET 在增强 EV-Eye 测试集上达到平均瞳孔中心误差 0.20 像素和推理时间 0.53 ms，比先前技术 EV-Eye 分别减少 1.6 倍像素误差和 1.8 倍推理时间，且参数和运算量大幅降低，为实时 XR 交互提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15584v1",
      "published_date": "2024-09-23 22:31:38 UTC",
      "updated_date": "2024-09-23 22:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:32:38.641796"
    },
    {
      "arxiv_id": "2409.15567v3",
      "title": "Asking an AI for salary negotiation advice is a matter of concern: Controlled experimental perturbation of ChatGPT for protected and non-protected group discrimination on a contextual task with no clear ground truth answers",
      "title_zh": "翻译失败",
      "authors": [
        "R. Stuart Geiger",
        "Flynn O'Sullivan",
        "Elsie Wang",
        "Jonathan Lo"
      ],
      "abstract": "We conducted controlled experimental bias audits for four versions of\nChatGPT, which we asked to recommend an opening offer in salary negotiations\nfor a new hire. We submitted 98,800 prompts to each version, systematically\nvarying the employee's gender, university, and major, and tested prompts in\nvoice of each side of the negotiation: the employee versus employer. We find\nChatGPT as a multi-model platform is not robust and consistent enough to be\ntrusted for such a task. We observed statistically significant salary offers\nwhen varying gender for all four models, although with smaller gaps than for\nother attributes tested. The largest gaps were different model versions and\nbetween the employee- vs employer-voiced prompts. We also observed substantial\ngaps when varying university and major, but many of the biases were not\nconsistent across model versions. We tested for fictional and fraudulent\nuniversities and found wildly inconsistent results across cases and model\nversions. We make broader contributions to the AI/ML fairness literature. Our\nscenario and our experimental design differ from mainstream AI/ML auditing\nefforts in key ways. Bias audits typically test discrimination for protected\nclasses like gender, which we contrast with testing non-protected classes of\nuniversity and major. Asking for negotiation advice includes how aggressive one\nought to be in a negotiation relative to known empirical salary distributions\nand scales, which is a deeply contextual and personalized task that has no\nobjective ground truth to validate. These results raise concerns for the\nspecific model versions we tested and ChatGPT as a multi-model platform in\ncontinuous development. Our epistemology does not permit us to definitively\ncertify these models as either generally biased or unbiased on the attributes\nwe test, but our study raises matters of concern for stakeholders to further\ninvestigate.",
      "tldr_zh": "本研究通过控制实验测试了四个版本的 ChatGPT 在薪资谈判建议中的偏见，共提交 98,800 个提示，系统变化员工的 gender、university 和 major，并从员工或雇主角度进行测试。结果显示，所有模型在 gender 方面存在统计显著的薪资差异，但幅度较小，而 university 和 major 的差异更大，且模型版本间不一致，尤其在虚构 university 的测试中结果高度波动。相比传统 AI/ML bias audits，该研究扩展了测试范围，包括非受保护类别的属性，并强调了此类任务的上下文性和缺乏客观 ground truth。总体而言，这引发了对 ChatGPT 作为多模型平台的可靠性和公平性担忧，建议相关利益方进一步调查。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15567v3",
      "published_date": "2024-09-23 21:48:32 UTC",
      "updated_date": "2024-10-08 14:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:32:49.077868"
    },
    {
      "arxiv_id": "2409.15566v1",
      "title": "GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Brendan Hogan Rappazzo",
        "Yingheng Wang",
        "Aaron Ferber",
        "Carla Gomes"
      ],
      "abstract": "The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility'' questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI's text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在记忆编码、存储和检索方面的不足，并提出 GEM-RAG 方法来提升 Retrieval Augmented Generation (RAG)。GEM-RAG 通过为文本块生成“utility”问题、基于文本和问题相似性构建图结构、并使用 eigendecomposition 创建高层总结节点，从而实现更有效的记忆处理和问答 (QA) 性能。实验结果显示，使用 UnifiedQA 和 GPT-3.5 Turbo 等模型，GEM-RAG 在标准 QA 任务上优于现有 RAG 方法，为 AI 代理的领域专业化和未来发展提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15566v1",
      "published_date": "2024-09-23 21:42:47 UTC",
      "updated_date": "2024-09-23 21:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:33:01.005839"
    },
    {
      "arxiv_id": "2410.00036v1",
      "title": "InsightPulse: An IoT-based System for User Experience Interview Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Dian Lyu",
        "Yuetong Lu",
        "Jassie He",
        "Murad Mehrab Abrar",
        "Ruijun Xie",
        "John Raiti"
      ],
      "abstract": "Conducting efficient and effective user experience (UX) interviews often\nposes challenges, such as maintaining focus on key topics and managing the\nduration of interviews and post-interview analyses. To address these issues,\nthis paper introduces InsightPulse, an Internet of Things (IoT)-based hardware\nand software system designed to streamline and enhance the UX interview process\nthrough speech analysis and Artificial Intelligence. InsightPulse provides\nreal-time support during user interviews by automatically identifying and\nhighlighting key discussion points, proactively suggesting follow-up questions,\nand generating thematic summaries. These features enable more insightful\ndiscoveries and help to manage interview duration effectively. Additionally,\nthe system features a robust backend analytics dashboard that simplifies the\npost-interview review process, thus facilitating the quick extraction of\nactionable insights and enhancing overall UX research efficiency.",
      "tldr_zh": "本论文介绍了InsightPulse，一种基于IoT的硬件和软件系统，旨在解决用户体验(UX)访谈中的挑战，如保持焦点和管理时长。系统通过语音分析和AI技术提供实时支持，包括自动识别关键讨论点、主动建议后续问题以及生成主题摘要，从而提升访谈效率和洞见发现。此外，InsightPulse配备了后端分析仪表板，简化了后续审查过程，便于快速提取可行动见解并提高整体UX研究效率。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication at the 10th IEEE International Conference on\n  Collaboration and Internet Computing (IEEE CIC 2024), Washington D.C., USA",
      "pdf_url": "http://arxiv.org/pdf/2410.00036v1",
      "published_date": "2024-09-23 21:39:34 UTC",
      "updated_date": "2024-09-23 21:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:33:12.000661"
    },
    {
      "arxiv_id": "2409.19012v1",
      "title": "Lost in the Logic: An Evaluation of Large Language Models' Reasoning Capabilities on LSAT Logic Games",
      "title_zh": "迷失在逻辑中：大型语言模型在LSAT逻辑游戏上的推理能力评估",
      "authors": [
        "Saumya Malik"
      ],
      "abstract": "In this thesis, I evaluate the performance of Large Language Models (LLMs) on\nthe Law School Admissions Test (LSAT), specifically the Logic Games section of\nthe test. I focus on this section because it presents a complex logical\nreasoning task and thus is a valuable source of data for evaluating how modern,\nincreasingly capable LLMs can handle hard logical reasoning tasks. I construct\na dataset of LSAT logic games and their associated metadata, and extensively\nevaluate LLMs' performance in a Chain-of-Thought prompting setting. Given the\nweak performance in this setting, I explore other prompting frameworks on a\nsmaller subset of the dataset, adapting ideas from Reflexion to this task. This\nresults in a substantially improved accuracy of 70 percent for GPT-4 and 46\npercent for GPT-3.5 on this data subset, highlighting the capacity of LLMs to\nrevise their logical errors, despite initially weak performance. Finally, I\nanalyze the types of logic games that models perform better or worse on, as\nwell as the types of logical errors I observe from human annotation, providing\ndetailed insights on the logical reasoning capabilities of LLMs.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在 LSAT Logic Games 部分的逻辑推理能力，构建了一个数据集并使用 Chain-of-Thought 提示进行初步测试，结果显示模型初始性能较弱。作者随后探索了其他提示框架，如对 Reflexion 的适应，在子数据集上显著提升准确率，GPT-4 达到 70%、GPT-3.5 达到 46%，突显 LLMs 修正逻辑错误的能力。最终，通过分析不同逻辑游戏类型和人类标注的错误类型，该论文提供了 LLMs 推理能力的详细洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Bachelor's thesis. Dataset available on huggingface:\n  https://huggingface.co/datasets/saumyamalik/lsat_logic_games-analytical_reasoning",
      "pdf_url": "http://arxiv.org/pdf/2409.19012v1",
      "published_date": "2024-09-23 21:37:40 UTC",
      "updated_date": "2024-09-23 21:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:33:24.202789"
    },
    {
      "arxiv_id": "2409.19011v1",
      "title": "Identification and Mitigating Bias in Quantum Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nandhini Swaminathan",
        "David Danks"
      ],
      "abstract": "As quantum machine learning (QML) emerges as a promising field at the\nintersection of quantum computing and artificial intelligence, it becomes\ncrucial to address the biases and challenges that arise from the unique nature\nof quantum systems. This research includes work on identification, diagnosis,\nand response to biases in Quantum Machine Learning. This paper aims to provide\nan overview of three key topics: How does bias unique to Quantum Machine\nLearning look? Why and how can it occur? What can and should be done about it?",
      "tldr_zh": "这篇论文探讨了量子机器学习 (QML) 中的偏置问题，包括识别、诊断和缓解策略，以应对量子系统独特特性带来的挑战。论文概述了 QML 特有的偏置形式、其发生原因（如量子计算的固有不确定性）和潜在解决方案。最终，该研究为减少偏置提供指导框架，促进 QML 的公平性和可靠性发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "2 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.19011v1",
      "published_date": "2024-09-23 21:31:16 UTC",
      "updated_date": "2024-09-23 21:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:33:36.299022"
    },
    {
      "arxiv_id": "2409.15551v2",
      "title": "Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanchao Li",
        "Yuan Gong",
        "Chao-Han Huck Yang",
        "Peter Bell",
        "Catherine Lai"
      ],
      "abstract": "Annotating and recognizing speech emotion using prompt engineering has\nrecently emerged with the advancement of Large Language Models (LLMs), yet its\nefficacy and reliability remain questionable. In this paper, we conduct a\nsystematic study on this topic, beginning with the proposal of novel prompts\nthat incorporate emotion-specific knowledge from acoustics, linguistics, and\npsychology. Subsequently, we examine the effectiveness of LLM-based prompting\non Automatic Speech Recognition (ASR) transcription, contrasting it with\nground-truth transcription. Furthermore, we propose a Revise-Reason-Recognize\nprompting pipeline for robust LLM-based emotion recognition from spoken\nlanguage with ASR errors. Additionally, experiments on context-aware learning,\nin-context learning, and instruction tuning are performed to examine the\nusefulness of LLM training schemes in this direction. Finally, we investigate\nthe sensitivity of LLMs to minor prompt variations. Experimental results\ndemonstrate the efficacy of the emotion-specific prompts, ASR error correction,\nand LLM training schemes for LLM-based emotion recognition. Our study aims to\nrefine the use of LLMs in emotion recognition and related domains.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型 (LLMs) 通过提示工程进行语音情感识别的系统研究，提出了整合声学、语言学和心理学知识的情感特定提示，以提升识别准确性。研究者设计了 Revise-Reason-Recognize 提示管道，用于修正自动语音识别 (ASR) 错误，从而实现更鲁棒的情感识别。实验结果显示，这些方法显著提高了 LLMs 的效能，并验证了上下文感知学习、在上下文学习和指令微调等训练方案的 usefulness。该研究旨在优化 LLMs 在情感识别及其相关领域的应用。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15551v2",
      "published_date": "2024-09-23 21:07:06 UTC",
      "updated_date": "2025-04-30 13:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:33:49.778590"
    },
    {
      "arxiv_id": "2410.03697v1",
      "title": "Combining Open-box Simulation and Importance Sampling for Tuning Large-Scale Recommenders",
      "title_zh": "翻译失败",
      "authors": [
        "Kaushal Paneri",
        "Michael Munje",
        "Kailash Singh Maurya",
        "Adith Swaminathan",
        "Yifan Shi"
      ],
      "abstract": "Growing scale of recommender systems require extensive tuning to respond to\nmarket dynamics and system changes. We address the challenge of tuning a\nlarge-scale ads recommendation platform with multiple continuous parameters\ninfluencing key performance indicators (KPIs). Traditional methods like\nopen-box Monte Carlo simulators, while accurate, are computationally expensive\ndue to the high cost of evaluating numerous parameter settings. To mitigate\nthis, we propose a hybrid approach Simulator-Guided Importance Sampling (SGIS)\nthat combines open-box simulation with importance sampling (IS). SGIS leverages\nthe strengths of both techniques: it performs a coarse enumeration over the\nparameter space to identify promising initial settings and then uses IS to\niteratively refine these settings. This approach significantly reduces\ncomputational costs while maintaining high accuracy in KPI estimation. We\ndemonstrate the effectiveness of SGIS through simulations as well as real-world\nexperiments, showing that it achieves substantial improvements in KPIs with\nlower computational overhead compared to traditional methods.",
      "tldr_zh": "本研究针对大规模推荐系统的调优挑战，提出了一种混合方法 Simulator-Guided Importance Sampling (SGIS)，它结合 open-box simulation 和 importance sampling，以减少评估多个连续参数对关键绩效指标 (KPIs) 的计算开销。SGIS 通过在参数空间进行粗略枚举来识别有前景的初始设置，然后利用 importance sampling 进行迭代精炼，从而维持高准确性同时降低计算成本。实验结果表明，该方法在模拟和真实场景中，比传统 open-box Monte Carlo 模拟器实现了 KPIs 的显著改善，并大幅减少了计算资源需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the CONSEQUENCES '24 workshop, co-located with ACM RecSys\n  '24",
      "pdf_url": "http://arxiv.org/pdf/2410.03697v1",
      "published_date": "2024-09-23 20:35:47 UTC",
      "updated_date": "2024-09-23 20:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:34:01.545882"
    },
    {
      "arxiv_id": "2409.16329v1",
      "title": "MRI Radiomics for IDH Genotype Prediction in Glioblastoma Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Stanislav Kozák"
      ],
      "abstract": "Radiomics is a relatively new field which utilises automatically identified\nfeatures from radiological scans. It has found a widespread application,\nparticularly in oncology because many of the important oncological biomarkers\nare not visible to the naked eye. The recent advent of big data, including in\nmedical imaging, and the development of new ML techniques brought the\npossibility of faster and more accurate oncological diagnosis. Furthermore,\nstandardised mathematical feature extraction based on radiomics helps to\neliminate possible radiologist bias. This paper reviews the recent development\nin the oncological use of MRI radiomic features. It focuses on the\nidentification of the isocitrate dehydrogenase (IDH) mutation status, which is\nan important biomarker for the diagnosis of glioblastoma and grade IV\nastrocytoma.",
      "tldr_zh": "本论文回顾了 MRI Radiomics 在肿瘤学中的最新应用，特别聚焦于利用放射扫描自动提取特征来预测胶质母细胞瘤（glioblastoma）和 IV 级星形细胞瘤的 IDH 基因型。Radiomics 通过标准化数学特征提取，帮助消除放射科医生的主观偏见，并结合大数据和机器学习（ML）技术，提高诊断的准确性和速度。作为一个新兴领域，该方法能识别肉眼不可见的肿瘤生物标志物，为更精确的肿瘤诊断提供重要支持。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.2; I.4; J.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.16329v1",
      "published_date": "2024-09-23 20:34:49 UTC",
      "updated_date": "2024-09-23 20:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:34:13.735649"
    },
    {
      "arxiv_id": "2409.15523v1",
      "title": "SEAL: Suite for Evaluating API-use of LLMs",
      "title_zh": "SEAL：用于评估大型语言模型 API 使用的套件",
      "authors": [
        "Woojeong Kim",
        "Ashish Jagmohan",
        "Aditya Vempaty"
      ],
      "abstract": "Large language models (LLMs) have limitations in handling tasks that require\nreal-time access to external APIs. While several benchmarks like ToolBench and\nAPIGen have been developed to assess LLMs' API-use capabilities, they often\nsuffer from issues such as lack of generalizability, limited multi-step\nreasoning coverage, and instability due to real-time API fluctuations. In this\npaper, we introduce SEAL, an end-to-end testbed designed to evaluate LLMs in\nreal-world API usage. SEAL standardizes existing benchmarks, integrates an\nagent system for testing API retrieval and planning, and addresses the\ninstability of real-time APIs by introducing a GPT-4-powered API simulator with\ncaching for deterministic evaluations. Our testbed provides a comprehensive\nevaluation pipeline that covers API retrieval, API calls, and final responses,\noffering a reliable framework for structured performance comparison in diverse\nreal-world scenarios. SEAL is publicly available, with ongoing updates for new\nbenchmarks.",
      "tldr_zh": "论文介绍了 SEAL，这是一个端到端测试平台，用于评估大型语言模型(LLMs)在 API 使用方面的能力，旨在解决现有基准如 ToolBench 和 APIGen 的泛化性不足、多步推理覆盖有限以及实时 API 不稳定性等问题。SEAL 通过标准化现有基准、集成代理系统进行 API 检索和规划，并引入由 GPT-4 驱动的 API 模拟器及缓存机制，确保评估过程的确定性和可靠性。该平台提供全面的评估管道，涵盖 API 检索、调用和最终响应，支持在多样真实场景中的结构化性能比较，并已公开可用以持续更新新基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15523v1",
      "published_date": "2024-09-23 20:16:49 UTC",
      "updated_date": "2024-09-23 20:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:34:27.664722"
    },
    {
      "arxiv_id": "2409.15521v1",
      "title": "CANDERE-COACH: Reinforcement Learning from Noisy Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Li",
        "Srijita Das",
        "Matthew E. Taylor"
      ],
      "abstract": "In recent times, Reinforcement learning (RL) has been widely applied to many\nchallenging tasks. However, in order to perform well, it requires access to a\ngood reward function which is often sparse or manually engineered with scope\nfor error. Introducing human prior knowledge is often seen as a possible\nsolution to the above-mentioned problem, such as imitation learning, learning\nfrom preference, and inverse reinforcement learning. Learning from feedback is\nanother framework that enables an RL agent to learn from binary evaluative\nsignals describing the teacher's (positive or negative) evaluation of the\nagent's action. However, these methods often make the assumption that\nevaluative teacher feedback is perfect, which is a restrictive assumption. In\npractice, such feedback can be noisy due to limited teacher expertise or other\nexacerbating factors like cognitive load, availability, distraction, etc. In\nthis work, we propose the CANDERE-COACH algorithm, which is capable of learning\nfrom noisy feedback by a nonoptimal teacher. We propose a noise-filtering\nmechanism to de-noise online feedback data, thereby enabling the RL agent to\nsuccessfully learn with up to 40% of the teacher feedback being incorrect.\nExperiments on three common domains demonstrate the effectiveness of the\nproposed approach.",
      "tldr_zh": "强化学习（Reinforcement Learning, RL）常常依赖于精确的奖励函数，但现实中反馈可能因教师非最优或外部因素而变得嘈杂，导致现有方法效果受限。  \n本文提出 CANDERE-COACH 算法，通过一个噪声过滤机制来处理在线反馈数据，使 RL 代理能够从高达 40% 错误反馈中成功学习。  \n实验在三个常见领域验证了该方法的有效性，展示了其在提升 RL 鲁棒性的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15521v1",
      "published_date": "2024-09-23 20:14:12 UTC",
      "updated_date": "2024-09-23 20:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:34:36.699261"
    },
    {
      "arxiv_id": "2409.15515v1",
      "title": "Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA",
      "title_zh": "翻译失败",
      "authors": [
        "Nirmal Roy",
        "Leonardo F. R. Ribeiro",
        "Rexhina Blloshmi",
        "Kevin Small"
      ],
      "abstract": "Augmenting Large Language Models (LLMs) with information retrieval\ncapabilities (i.e., Retrieval-Augmented Generation (RAG)) has proven beneficial\nfor knowledge-intensive tasks. However, understanding users' contextual search\nintent when generating responses is an understudied topic for conversational\nquestion answering (QA). This conversational extension leads to additional\nconcerns when compared to single-turn QA as it is more challenging for systems\nto comprehend conversational context and manage retrieved passages over\nmultiple turns. In this work, we propose a method for enabling LLMs to decide\nwhen to retrieve in RAG settings given a conversational context. When retrieval\nis deemed necessary, the LLM then rewrites the conversation for passage\nretrieval and judges the relevance of returned passages before response\ngeneration. Operationally, we build on the single-turn SELF-RAG framework (Asai\net al., 2023) and propose SELF-multi-RAG for conversational settings.\nSELF-multi-RAG demonstrates improved capabilities over single-turn variants\nwith respect to retrieving relevant passages (by using summarized\nconversational context) and assessing the quality of generated responses.\nExperiments on three conversational QA datasets validate the enhanced response\ngeneration capabilities of SELF-multi-RAG, with improvements of ~13% measured\nby human annotation.",
      "tldr_zh": "这篇论文提出了一种名为 SELF-multi-RAG 的方法，用于增强大型语言模型（LLMs）在对话式 QA 中的检索增强生成（RAG）能力，重点解决理解用户上下文意图和多轮对话管理的问题。该方法让 LLMs 决定何时进行检索，并在必要时重写对话以检索相关段落，同时评估返回段落的关联性后生成响应。相比单轮 SELF-RAG 框架，SELF-multi-RAG 通过使用总结的对话上下文提高了相关段落检索和响应质量，在三个对话式 QA 数据集上的实验显示了约 13% 的改进，通过人工标注验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP (findings) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15515v1",
      "published_date": "2024-09-23 20:05:12 UTC",
      "updated_date": "2024-09-23 20:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:34:50.035737"
    },
    {
      "arxiv_id": "2409.15503v3",
      "title": "From Text to Treatment Effects: A Meta-Learning Approach to Handling Text-Based Confounding",
      "title_zh": "翻译失败",
      "authors": [
        "Henri Arno",
        "Paloma Rabaey",
        "Thomas Demeester"
      ],
      "abstract": "One of the central goals of causal machine learning is the accurate\nestimation of heterogeneous treatment effects from observational data. In\nrecent years, meta-learning has emerged as a flexible, model-agnostic paradigm\nfor estimating conditional average treatment effects (CATE) using any\nsupervised model. This paper examines the performance of meta-learners when the\nconfounding variables are expressed in text. Through synthetic data\nexperiments, we show that learners using pre-trained text representations of\nconfounders, in addition to tabular background variables, achieve improved CATE\nestimates compared to those relying solely on the tabular variables,\nparticularly when sufficient data is available. However, due to the entangled\nnature of the text embeddings, these models do not fully match the performance\nof meta-learners with perfect confounder knowledge. These findings highlight\nboth the potential and the limitations of pre-trained text representations for\ncausal inference and open up interesting avenues for future research.",
      "tldr_zh": "该论文提出了一种基于元学习(meta-learning)的方法，用于从观察数据中估计异质治疗效果(heterogeneous treatment effects)，特别针对文本形式的混杂变量(confounding variables)。研究通过合成数据实验发现，使用预训练文本表示(pre-trained text representations)结合表格变量，能显著改善条件平均治疗效果(CATE)估计，尤其在数据充足的情况下。相比仅依赖表格变量的模型，这种方法提升了估计准确性，但由于文本嵌入的纠缠(entangled nature)，其性能仍未达到完美混杂变量知识的水平。该研究突出了预训练文本表示在因果推理中的潜力，并为未来相关研究开辟了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the NeurIPS 2024 Workshop on Causal Representation\n  Learning",
      "pdf_url": "http://arxiv.org/pdf/2409.15503v3",
      "published_date": "2024-09-23 19:46:19 UTC",
      "updated_date": "2024-11-13 10:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:35:00.857418"
    },
    {
      "arxiv_id": "2409.19010v1",
      "title": "A comprehensive study of on-device NLP applications -- VQA, automated Form filling, Smart Replies for Linguistic Codeswitching",
      "title_zh": "翻译失败",
      "authors": [
        "Naman Goyal"
      ],
      "abstract": "Recent improvement in large language models, open doors for certain new\nexperiences for on-device applications which were not possible before. In this\nwork, we propose 3 such new experiences in 2 categories. First we discuss\nexperiences which can be powered in screen understanding i.e. understanding\nwhats on user screen namely - (1) visual question answering, and (2) automated\nform filling based on previous screen. The second category of experience which\ncan be extended are smart replies to support for multilingual speakers with\ncode-switching. Code-switching occurs when a speaker alternates between two or\nmore languages. To the best of our knowledge, this is first such work to\npropose these tasks and solutions to each of them, to bridge the gap between\nlatest research and real world impact of the research in on-device\napplications.",
      "tldr_zh": "这篇论文全面研究了设备端NLP应用，提出三种新体验：视觉问答(VQA)、基于前一个屏幕的自动表单填充，以及支持语言代码切换(codeswitching)的智能回复。\n这些体验利用大型语言模型的进步，分为屏幕理解类别和智能回复类别，旨在提升用户界面交互和多语言支持。\n该工作首次提出这些任务及其解决方案，桥接了最新研究与设备端应用的实际影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19010v1",
      "published_date": "2024-09-23 19:28:52 UTC",
      "updated_date": "2024-09-23 19:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:35:13.515010"
    },
    {
      "arxiv_id": "2409.15491v1",
      "title": "Computational Pathology for Accurate Prediction of Breast Cancer Recurrence: Development and Validation of a Deep Learning-based Tool",
      "title_zh": "计算病理学用于准确预测乳腺癌复发：基于深度学习的工具的开发和验证",
      "authors": [
        "Ziyu Su",
        "Yongxin Guo",
        "Robert Wesolowski",
        "Gary Tozbikian",
        "Nathaniel S. O'Connell",
        "M. Khalid Khan Niazi",
        "Metin N. Gurcan"
      ],
      "abstract": "Accurate recurrence risk stratification is crucial for optimizing treatment\nplans for breast cancer patients. Current prognostic tools like Oncotype DX\n(ODX) offer valuable genomic insights for HR+/HER2- patients but are limited by\ncost and accessibility, particularly in underserved populations. In this study,\nwe present Deep-BCR-Auto, a deep learning-based computational pathology\napproach that predicts breast cancer recurrence risk from routine H&E-stained\nwhole slide images (WSIs). Our methodology was validated on two independent\ncohorts: the TCGA-BRCA dataset and an in-house dataset from The Ohio State\nUniversity (OSU). Deep-BCR-Auto demonstrated robust performance in stratifying\npatients into low- and high-recurrence risk categories. On the TCGA-BRCA\ndataset, the model achieved an area under the receiver operating characteristic\ncurve (AUROC) of 0.827, significantly outperforming existing weakly supervised\nmodels (p=0.041). In the independent OSU dataset, Deep-BCR-Auto maintained\nstrong generalizability, achieving an AUROC of 0.832, along with 82.0%\naccuracy, 85.0% specificity, and 67.7% sensitivity. These findings highlight\nthe potential of computational pathology as a cost-effective alternative for\nrecurrence risk assessment, broadening access to personalized treatment\nstrategies. This study underscores the clinical utility of integrating deep\nlearning-based computational pathology into routine pathological assessment for\nbreast cancer prognosis across diverse clinical settings.",
      "tldr_zh": "本研究开发了Deep-BCR-Auto，一种基于深度学习的计算病理学工具，用于从常规H&E-stained whole slide images (WSIs)准确预测乳腺癌复发风险，作为Oncotype DX (ODX)等现有工具的成本有效替代方案。研究在TCGA-BRCA数据集和俄亥俄州立大学(OSU)的独立队列上进行了验证，结果显示模型在TCGA-BRCA上达到AUROC 0.827，显著优于弱监督基线模型（p=0.041），而在OSU数据集上实现AUROC 0.832、准确率82.0%、特异性85.0%和敏感性67.7%。这些发现突出了将深度学习整合到常规病理评估中的临床潜力，有助于在多样化临床环境中扩展个性化治疗策略。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15491v1",
      "published_date": "2024-09-23 19:22:06 UTC",
      "updated_date": "2024-09-23 19:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:35:25.593709"
    },
    {
      "arxiv_id": "2409.15486v1",
      "title": "VLMine: Long-Tail Data Mining with Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mao Ye",
        "Gregory P. Meyer",
        "Zaiwei Zhang",
        "Dennis Park",
        "Siva Karthik Mustikovela",
        "Yuning Chai",
        "Eric M Wolff"
      ],
      "abstract": "Ensuring robust performance on long-tail examples is an important problem for\nmany real-world applications of machine learning, such as autonomous driving.\nThis work focuses on the problem of identifying rare examples within a corpus\nof unlabeled data. We propose a simple and scalable data mining approach that\nleverages the knowledge contained within a large vision language model (VLM).\nOur approach utilizes a VLM to summarize the content of an image into a set of\nkeywords, and we identify rare examples based on keyword frequency. We find\nthat the VLM offers a distinct signal for identifying long-tail examples when\ncompared to conventional methods based on model uncertainty. Therefore, we\npropose a simple and general approach for integrating signals from multiple\nmining algorithms. We evaluate the proposed method on two diverse tasks: 2D\nimage classification, in which inter-class variation is the primary source of\ndata diversity, and on 3D object detection, where intra-class variation is the\nmain concern. Furthermore, through the detection task, we demonstrate that the\nknowledge extracted from 2D images is transferable to the 3D domain. Our\nexperiments consistently show large improvements (between 10\\% and 50\\%) over\nthe baseline techniques on several representative benchmarks: ImageNet-LT,\nPlaces-LT, and the Waymo Open Dataset.",
      "tldr_zh": "本研究针对机器学习中长尾数据（long-tail examples）的识别问题，提出了一种简单可扩展的方法VLMine，利用Vision Language Models (VLM)从未标注图像中挖掘稀有样本。具体而言，该方法通过VLM将图像总结为关键词集，并基于关键词频率来识别长尾数据，同时发现VLM的信号优于传统基于模型不确定性的方法，并提出整合多算法信号的通用框架。在2D图像分类（如ImageNet-LT和Places-LT）和3D对象检测（如Waymo Open Dataset）任务上实验验证，该方法实现了10%至50%的性能提升，并证明了从2D到3D领域的知识转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15486v1",
      "published_date": "2024-09-23 19:13:51 UTC",
      "updated_date": "2024-09-23 19:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:35:39.206930"
    },
    {
      "arxiv_id": "2409.15461v1",
      "title": "RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration",
      "title_zh": "RAM2C：基于检索增强的多角色多专家协作的文科教育聊天机器人",
      "authors": [
        "Haoyu Huang",
        "Tong Niu",
        "Rui Yang",
        "Luping Shi"
      ],
      "abstract": "Recently, many studies focus on utilizing large language models (LLMs) into\neducational dialogues. Especially, within liberal arts dialogues, educators\nmust balance \\textbf{H}umanized communication, \\textbf{T}eaching expertise, and\n\\textbf{S}afety-ethics (\\textbf{HTS}), besides the subject knowledge itself.\nHowever, due to collecting massive amounts of HTS-compliant teaching dialogues\nfrom real world as training corpus is expensive, the outputs of existing LLMs\nin teaching dialogues fall short of human standards. To address this, we design\na Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework\nto automatically generate such dialogues data. Specifically, we first establish\nHTS-guided knowledge bases, encompassing three domain knowledge in teaching\nskills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are\nretrieval-augmented by the above different knowledge bases, into multi-experts\ngroups with distinct roles to generate the HTS-compliant educational dialogues\ndataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations\nindicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering\nmore personalized, and ethically safe teaching response, demonstrating RAM2C's\npracticality and high quality. We release the experiments at\n\\hyperlink{https://github.com/ram2c/ram2c}{https://github.com/ram2c/ram2c}.",
      "tldr_zh": "该论文针对人文教育对话中大型语言模型 (LLMs) 的不足，提出 Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) 框架，以自动生成符合 HTS (Humanized communication, Teaching expertise, and Safety-ethics) 的教育对话数据。框架首先构建 HTS-guided knowledge bases，包括教学技能、心理学和安全伦理等领域知识，然后通过检索增强的多专家组协作模拟不同角色生成高质量数据集，并以此微调 LLMs。实验结果显示，RAM2C 增强的 LLMs 在中文阅读教学中表现出色，提供更个性化和道德安全的教学响应，证明了框架的实用价值。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15461v1",
      "published_date": "2024-09-23 18:38:04 UTC",
      "updated_date": "2024-09-23 18:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:35:51.634260"
    },
    {
      "arxiv_id": "2409.15454v1",
      "title": "In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models",
      "title_zh": "上下文学习可能无法引发可信赖的推理：预训练语言模型中的 A-Not-B 错误",
      "authors": [
        "Pengrui Han",
        "Peiyang Song",
        "Haofei Yu",
        "Jiaxuan You"
      ],
      "abstract": "Recent advancements in artificial intelligence have led to the creation of\nhighly capable large language models (LLMs) that can perform tasks in a\nhuman-like manner. However, LLMs exhibit only infant-level cognitive abilities\nin certain areas. One such area is the A-Not-B error, a phenomenon seen in\ninfants where they repeat a previously rewarded behavior despite well-observed\nchanged conditions. This highlights their lack of inhibitory control -- the\nability to stop a habitual or impulsive response. In our work, we design a\ntext-based multi-choice QA scenario similar to the A-Not-B experimental\nsettings to systematically test the inhibitory control abilities of LLMs. We\nfound that state-of-the-art LLMs (like Llama3-8b) perform consistently well\nwith in-context learning (ICL) but make errors and show a significant drop of\nas many as 83.3% in reasoning tasks when the context changes trivially. This\nsuggests that LLMs only have inhibitory control abilities on par with human\ninfants in this regard, often failing to suppress the previously established\nresponse pattern during ICL.",
      "tldr_zh": "该研究探讨了预训练语言模型（LLMs）在 In-Context Learning（ICL）中的可信度问题，特别关注 A-Not-B errors，即模型重复先前奖励的行为而忽略微小变化，类似于婴儿的认知局限。研究者设计了一个文本-based 多选问答（QA）场景，模拟 A-Not-B 实验，以系统测试 LLMs 的抑制控制能力。结果显示，如 Llama3-8b 模型在 ICL 下表现良好，但当上下文发生微小改变时，错误率可能下降高达 83.3%。这表明 LLMs 在抑制先前响应模式方面仅相当于人类婴儿水平，突显了其认知能力的不足。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2409.15454v1",
      "published_date": "2024-09-23 18:30:31 UTC",
      "updated_date": "2024-09-23 18:30:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:36:03.730845"
    },
    {
      "arxiv_id": "2409.15451v1",
      "title": "Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mike Zhang",
        "Kaixian Qu",
        "Vaishakh Patil",
        "Cesar Cadena",
        "Marco Hutter"
      ],
      "abstract": "Large Language Models (LLM) have emerged as a tool for robots to generate\ntask plans using common sense reasoning. For the LLM to generate actionable\nplans, scene context must be provided, often through a map. Recent works have\nshifted from explicit maps with fixed semantic classes to implicit open\nvocabulary maps based on queryable embeddings capable of representing any\nsemantic class. However, embeddings cannot directly report the scene context as\nthey are implicit, requiring further processing for LLM integration. To address\nthis, we propose an explicit text-based map that can represent thousands of\nsemantic classes while easily integrating with LLMs due to their text-based\nnature by building upon large-scale image recognition models. We study how\nentities in our map can be localized and show through evaluations that our\ntext-based map localizations perform comparably to those from open vocabulary\nmaps while using two to four orders of magnitude less memory. Real-robot\nexperiments demonstrate the grounding of an LLM with the text-based map to\nsolve user tasks.",
      "tldr_zh": "该论文提出Tag Map，一种基于文本的显式地图，用于Large Language Models (LLMs)进行空间推理和导航，旨在解决传统隐式开放词汇地图在LLMs集成中的处理难题。Tag Map构建于大型图像识别模型之上，能高效表示数千种语义类，并简化了场景上下文的提供。实验结果显示，该地图的实体定位性能与open vocabulary maps相当，但内存使用减少2-4个数量级。实际机器人实验验证了Tag Map与LLMs的结合，能有效解决用户任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15451v1",
      "published_date": "2024-09-23 18:26:19 UTC",
      "updated_date": "2024-09-23 18:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:36:17.529958"
    },
    {
      "arxiv_id": "2410.18357v4",
      "title": "The Impact of Generative Artificial Intelligence on Ideation and the performance of Innovation Teams (Preprint)",
      "title_zh": "生成式人工智能对构思以及创新团队绩效的影响（预印本）",
      "authors": [
        "Michael Gindert",
        "Marvin Lutz Müller"
      ],
      "abstract": "This study investigates the impact of Generative Artificial Intelligence\n(GenAI) on the dynamics and performance of innovation teams during the idea\ngeneration phase of the innovation process. Utilizing a custom AI-augmented\nideation tool, the study applies the Knowledge Spillover Theory of\nEntrepreneurship to understand the effects of AI on knowledge spillover,\ngeneration and application. Through a framed field experiment with participants\ndivided into experimental and control groups, findings indicate that\nAI-augmented teams generated higher quality ideas in less time. GenAI\napplication led to improved efficiency, knowledge exchange, increased\nsatisfaction and engagement as well as enhanced idea diversity. These results\nhighlight the transformative role of the field of AI within the innovation\nmanagement domain and shows that GenAI has a positive impact on important\nelements of the Knowledge Spillover Theory of Entrepreneurship, emphasizing its\npotential impact on innovation, entrepreneurship, and economic growth. Future\nresearch should further explore the dynamic interaction between GenAI and\ncreative processes.",
      "tldr_zh": "这篇论文研究了Generative Artificial Intelligence (GenAI) 对创新团队在idea generation阶段的影响，采用自定义AI增强ideation工具并应用Knowledge Spillover Theory of Entrepreneurship，通过框架化的现场实验比较实验组和对照组。结果显示，GenAI增强团队在更短时间内生成更高质量的想法，同时提升了效率、知识交换、满意度、参与度和idea多样性。这些发现强调了GenAI在创新管理领域的变革潜力，并突出了其对创新、创业和经济增长的积极影响，建议未来研究进一步探索GenAI与创意过程的动态互动。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages, 5 figures, Author Contributions: Michael Gindert:\n  Conceptualization, Methodology, Software, Validation, Formal analysis,\n  Investigation, Resources, Data Curation, Writing - Original Draft, Writing -\n  Review & Editing, Visualization, Project administration, Funding acquisition\n  Marvin Lutz M\\\"uller: Validation, Investigation, Resources, Writing - Review\n  & Editing, Supervision",
      "pdf_url": "http://arxiv.org/pdf/2410.18357v4",
      "published_date": "2024-09-23 18:25:49 UTC",
      "updated_date": "2025-02-25 20:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:36:27.793338"
    },
    {
      "arxiv_id": "2409.15441v1",
      "title": "Steward: Natural Language Web Automation",
      "title_zh": "Steward: 自然语言网络自动化",
      "authors": [
        "Brian Tang",
        "Kang G. Shin"
      ],
      "abstract": "Recently, large language models (LLMs) have demonstrated exceptional\ncapabilities in serving as the foundation for AI assistants. One emerging\napplication of LLMs, navigating through websites and interacting with UI\nelements across various web pages, remains somewhat underexplored. We introduce\nSteward, a novel LLM-powered web automation tool designed to serve as a\ncost-effective, scalable, end-to-end solution for automating web interactions.\nTraditional browser automation frameworks like Selenium, Puppeteer, and\nPlaywright are not scalable for extensive web interaction tasks, such as\nstudying recommendation algorithms on platforms like YouTube and Twitter. These\nframeworks require manual coding of interactions, limiting their utility in\nlarge-scale or dynamic contexts. Steward addresses these limitations by\nintegrating LLM capabilities with browser automation, allowing for natural\nlanguage-driven interaction with websites. Steward operates by receiving\nnatural language instructions and reactively planning and executing a sequence\nof actions on websites, looping until completion, making it a practical tool\nfor developers and researchers to use. It achieves high efficiency, completing\nactions in 8.52 to 10.14 seconds at a cost of $0.028 per action or an average\nof $0.18 per task, which is further reduced to 4.8 seconds and $0.022 through a\ncaching mechanism. It runs tasks on real websites with a 40% completion success\nrate. We discuss various design and implementation challenges, including state\nrepresentation, action sequence selection, system responsiveness, detecting\ntask completion, and caching implementation.",
      "tldr_zh": "本文提出Steward，一种基于大型语言模型(LLMs)的网页自动化工具，用于通过自然语言指令实现高效、可扩展的网站交互，解决了传统框架如Selenium、Puppeteer和Playwright的手动编码限制。Steward通过整合LLMs与浏览器自动化，接收指令后动态规划和执行动作序列，直至任务完成。实验结果显示，它在真实网站上以8.52至10.14秒完成动作，成本仅为每动作$0.028或平均每任务$0.18，通过缓存机制进一步优化至4.8秒和$0.022，任务完成成功率达40%。此外，论文讨论了设计挑战，包括状态表示、动作序列选择、系统响应性和任务完成检测。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15441v1",
      "published_date": "2024-09-23 18:06:32 UTC",
      "updated_date": "2024-09-23 18:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:36:39.375972"
    },
    {
      "arxiv_id": "2409.15277v1",
      "title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?",
      "title_zh": "o1 在医学中的初步研究：我们是否更接近一个 AI 医生？",
      "authors": [
        "Yunfei Xie",
        "Juncheng Wu",
        "Haoqin Tu",
        "Siwei Yang",
        "Bingchen Zhao",
        "Yongshuo Zong",
        "Qiao Jin",
        "Cihang Xie",
        "Yuyin Zhou"
      ],
      "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across\nvarious domains and tasks, pushing the boundaries of our knowledge in learning\nand cognition. The latest model, OpenAI's o1, stands out as the first LLM with\nan internalized chain-of-thought technique using reinforcement learning\nstrategies. While it has demonstrated surprisingly strong capabilities on\nvarious general language tasks, its performance in specialized fields such as\nmedicine remains unknown. To this end, this report provides a comprehensive\nexploration of o1 on different medical scenarios, examining 3 key aspects:\nunderstanding, reasoning, and multilinguality. Specifically, our evaluation\nencompasses 6 tasks using data from 37 medical datasets, including two newly\nconstructed and more challenging question-answering (QA) tasks based on\nprofessional medical quizzes from the New England Journal of Medicine (NEJM)\nand The Lancet. These datasets offer greater clinical relevance compared to\nstandard medical QA benchmarks such as MedQA, translating more effectively into\nreal-world clinical utility. Our analysis of o1 suggests that the enhanced\nreasoning ability of LLMs may (significantly) benefit their capability to\nunderstand various medical instructions and reason through complex clinical\nscenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average\nof 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios.\nBut meanwhile, we identify several weaknesses in both the model capability and\nthe existing evaluation protocols, including hallucination, inconsistent\nmultilingual ability, and discrepant metrics for evaluation. We release our raw\ndata and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future\nresearch.",
      "tldr_zh": "本研究初步评估了 OpenAI 的 o1 模型在医学领域的性能，探讨是否更接近实现 AI 医生。研究聚焦 o1 的内部化 chain-of-thought 技术与 reinforcement learning 策略，评估其在理解、推理和多语言能力方面的表现，使用 37 个医学数据集（包括两个新构建的基于 NEJM 和 The Lancet 的复杂 QA 任务）。结果显示，o1 在 19 个数据集上比 GPT-4 准确率平均提高 6.2%，在新 QA 场景中提高 6.6%，证明其增强的推理能力显著提升了医学任务处理。然则，研究也指出了 o1 的弱点，如 hallucination、多语言能力不一致和评估指标差异，并发布了原始数据以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first four authors contributed equally, project page available at\n  https://ucsc-vlaa.github.io/o1_medicine/",
      "pdf_url": "http://arxiv.org/pdf/2409.15277v1",
      "published_date": "2024-09-23 17:59:43 UTC",
      "updated_date": "2024-09-23 17:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:36:49.956973"
    },
    {
      "arxiv_id": "2409.15272v4",
      "title": "OmniBench: Towards The Future of Universal Omni-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhi Li",
        "Ge Zhang",
        "Yinghao Ma",
        "Ruibin Yuan",
        "Kang Zhu",
        "Hangyu Guo",
        "Yiming Liang",
        "Jiaheng Liu",
        "Zekun Wang",
        "Jian Yang",
        "Siwei Wu",
        "Xingwei Qu",
        "Jinjie Shi",
        "Xinyue Zhang",
        "Zhenzhu Yang",
        "Xiangzhou Wang",
        "Zhaoxiang Zhang",
        "Zachary Liu",
        "Emmanouil Benetos",
        "Wenhao Huang",
        "Chenghua Lin"
      ],
      "abstract": "Recent advancements in multimodal large language models (MLLMs) have focused\non integrating multiple modalities, yet their ability to simultaneously process\nand reason across different inputs remains underexplored. We introduce\nOmniBench, a novel benchmark designed to evaluate models' ability to recognize,\ninterpret, and reason across visual, acoustic, and textual inputs\nsimultaneously. We define language models capable of such tri-modal processing\nas omni-language models (OLMs). OmniBench features high-quality human\nannotations that require integrated understanding across all modalities. Our\nevaluation reveals that: i) open-source OLMs show significant limitations in\ninstruction-following and reasoning in tri-modal contexts; and ii) most\nbaseline models perform poorly (around 50% accuracy) even with textual\nalternatives to image/audio inputs. To address these limitations, we develop\nOmniInstruct, an 96K-sample instruction tuning dataset for training OLMs. We\nadvocate for developing more robust tri-modal integration techniques and\ntraining strategies to enhance OLM performance. Codes and data could be found\nat our repo (https://github.com/multimodal-art-projection/OmniBench).",
      "tldr_zh": "本文引入 OmniBench 基准，用于评估 omni-language models (OLMs) 在视觉、声学和文本模态上同时处理和推理的能力，强调了现有多模态大型语言模型 (MLLMs) 的局限性。实验结果显示，开源 OLMs 在三模态指令遵循和推理中表现不佳，基线模型准确率仅约 50%。为了改进这些问题，作者开发了 OmniInstruct 数据集（包含 96K 样本），并倡导更 robust 的三模态集成技术和训练策略，以推动通用 OLM 的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15272v4",
      "published_date": "2024-09-23 17:59:05 UTC",
      "updated_date": "2025-03-27 16:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:37:03.539055"
    },
    {
      "arxiv_id": "2409.15268v3",
      "title": "Style Outweighs Substance: Failure Modes of LLM Judges in Alignment Benchmarking",
      "title_zh": "风格胜过实质：",
      "authors": [
        "Benjamin Feuer",
        "Micah Goldblum",
        "Teresa Datta",
        "Sanjana Nambiar",
        "Raz Besaleli",
        "Samuel Dooley",
        "Max Cembalest",
        "John P. Dickerson"
      ],
      "abstract": "The release of ChatGPT in November 2022 sparked an explosion of interest in\npost-training and an avalanche of new preference optimization (PO) methods.\nThese methods claim superior alignment by virtue of better correspondence with\nhuman pairwise preferences, often measured by LLM-judges. In this work, we\nattempt to answer the following question -- do LLM-judge preferences translate\nto progress on other, more concrete metrics for alignment, and if not, why not?\nWe define a concrete metric for alignment, and introduce SOS-Bench (Substance\nOutweighs Style Benchmark), which is to the best of our knowledge the largest\nstandardized, reproducible LLM meta-benchmark to date. We find that (1)\nLLM-judge preferences do not correlate with concrete measures of safety, world\nknowledge, and instruction following; (2) LLM-judges have powerful implicit\nbiases, prioritizing style over factuality and safety; and (3) the supervised\nfine-tuning (SFT) stage of post-training, and not the PO stage, has the\ngreatest impact on alignment, with data scaling and prompt diversity as the\ndriving factors. Our codebase and complete results can be found at\nhttps://github.com/penfever/sos-bench.",
      "tldr_zh": "该研究探讨了LLM-judges在对齐基准测试中的失败模式，发现LLM-judges的偏好无法转化为安全、世界知识和指令遵循等具体对齐指标。作者引入了SOS-Bench（Substance Outweighs Style Benchmark），这是目前最大的标准化、可重现的LLM元基准，用于评估这些指标。结果显示，LLM-judges存在强烈的隐性偏见，优先考虑风格而非事实性和安全；此外，后训练中的监督微调(SFT)阶段对对齐影响最大，主要取决于数据规模和提示多样性。该工作强调了改进LLM评判机制的必要性，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15268v3",
      "published_date": "2024-09-23 17:58:07 UTC",
      "updated_date": "2025-01-27 11:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:37:14.279761"
    },
    {
      "arxiv_id": "2409.15263v1",
      "title": "The Palomar twilight survey of 'Ayló'chaxnim, Atiras, and comets",
      "title_zh": "翻译失败",
      "authors": [
        "B. T. Bolin",
        "F. J. Masci",
        "M. W. Coughlin",
        "D. A. Duev",
        "Ž. Ivezić",
        "R. L. Jones",
        "P. Yoachim",
        "T. Ahumada",
        "V. Bhalerao",
        "H. Choudhary",
        "C. Contreras",
        "Y. -C. Cheng",
        "C. M. Copperwheat",
        "K. Deshmukh",
        "C. Fremling",
        "M. Granvik",
        "K. K. Hardegree-Ullman",
        "A. Y. Q. Ho",
        "R. Jedicke",
        "M. Kasliwal",
        "H. Kumar",
        "Z. -Y. Lin",
        "A. Mahabal",
        "A. Monson",
        "J. D. Neill",
        "D. Nesvorný",
        "D. A. Perley",
        "J. N. Purdum",
        "R. Quimby",
        "E. Serabyn",
        "K. Sharma",
        "V. Swain"
      ],
      "abstract": "Near-sun sky twilight observations allow for the detection of asteroid\ninterior to the orbit of Venus (Aylos), the Earth (Atiras), and comets. We\npresent the results of observations with the Palomar 48-inch telescope\n(P48)/Zwicky Transient Facility (ZTF) camera in 30 s r-band exposures taken\nduring evening astronomical twilight from 2019 Sep 20 to 2022 March 7 and\nduring morning astronomical twilight sky from 2019 Sep 21 to 2022 Sep 29. More\nthan 46,000 exposures were taken in evening and morning astronomical twilight\nwithin 31 to 66 degrees from the Sun with an r-band limiting magnitude between\n18.1 and 20.9. The twilight pointings show a slight seasonal dependence in\nlimiting magnitude and ability to point closer towards the Sun, with limiting\nmagnitude slightly improving during summer. In total, the one Aylo, (594913)\n'Ayl\\'o'chaxnim, and 4 Atiras, 2020 OV1, 2021 BS1, 2021 PB2, and 2021 VR3, were\ndiscovered in evening and morning twilight observations. Additional twilight\nsurvey discoveries also include 6 long-period comets: C/2020 T2, C/2020 V2,\nC/2021 D2, C/2021 E3, C/2022 E3, and C/2022 P3, and two short-period comets:\nP/2021 N1 and P/2022 P2 using deep learning comet detection pipelines. The\nP48/ZTF twilight survey also recovered 11 known Atiras, one Aylo, three\nshort-period comes, two long-period comets, and one interstellar object.\nLastly, the Vera Rubin Observatory will conduct a twilight survey starting in\nits first year of operations and will cover the sky within 45 degrees of the\nSun. Twilight surveys such as those by ZTF and future surveys will provide\nopportunities for discovering asteroids inside the orbits of Earth and Venus.",
      "tldr_zh": "该研究利用Palomar 48-inch望远镜和Zwicky Transient Facility (ZTF)相机，在2019年至2022年间进行黄昏观测，共拍摄超过46,000张r-band曝光照片，检测位于金星轨道内的小行星(Aylos)、地球轨道内的小行星(Atiras)以及彗星。观测结果显示，季节因素影响了观测极限星等，夏季表现略好，并成功发现了1个Ayló'chaxnim、4个Atiras和8个彗星，包括6个长周期彗星和2个短周期彗星，同时恢复了11个已知Atiras和其他天体。总体而言，此调查证明了黄昏观测在发现内太阳系天体的潜力，并为未来如Vera Rubin Observatory的类似项目提供重要参考。",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "26 pages, 13 figures, 4 tables, accepted for publication in Icarus",
      "pdf_url": "http://arxiv.org/pdf/2409.15263v1",
      "published_date": "2024-09-23 17:56:45 UTC",
      "updated_date": "2024-09-23 17:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:37:26.672279"
    },
    {
      "arxiv_id": "2409.15261v1",
      "title": "Identification and Localization of Cometary Activity in Solar System Objects with Machine Learning",
      "title_zh": "利用机器学习识别",
      "authors": [
        "Bryce T. Bolin",
        "Michael W. Coughlin"
      ],
      "abstract": "In this chapter, we will discuss the use of Machine Learning methods for the\nidentification and localization of cometary activity for Solar System objects\nin ground and in space-based wide-field all-sky surveys. We will begin the\nchapter by discussing the challenges of identifying known and unknown active,\nextended Solar System objects in the presence of stellar-type sources and the\napplication of classical pre-ML identification techniques and their\nlimitations. We will then transition to the discussion of implementing ML\ntechniques to address the challenge of extended object identification. We will\nfinish with prospective future methods and the application to future surveys\nsuch as the Vera C. Rubin Observatory.",
      "tldr_zh": "本文探讨了使用Machine Learning方法来识别和定位太阳系物体中的彗星活动，特别是在地面和空间宽视场全天巡天调查中。首先，它分析了在恒星型源干扰下识别已知和未知活跃扩展物体的挑战，以及传统识别技术的局限性。然后，引入Machine Learning技术来提升扩展物体识别的效率和准确性。最后，展望未来方法及其在Vera C. Rubin Observatory等调查中的潜在应用。",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "25 pages, 9 figures, accepted chapter in Machine Learning for Small\n  Bodies in the Solar System, Valerio Carruba, Evgeny Smirnov, and Dagmara\n  Oszkiewicz, Elsevier, 2024, p. 209-227",
      "pdf_url": "http://arxiv.org/pdf/2409.15261v1",
      "published_date": "2024-09-23 17:56:32 UTC",
      "updated_date": "2024-09-23 17:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:37:38.780459"
    },
    {
      "arxiv_id": "2409.15260v1",
      "title": "Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Fei Zhao",
        "Allyn Bove",
        "David Thompson",
        "James Hill",
        "Yi Xu",
        "Yufan Ren",
        "Andrea Hassman",
        "Leming Zhou",
        "Yanshan Wang"
      ],
      "abstract": "Low back pain (LBP) is a leading cause of disability globally. Following the\nonset of LBP and subsequent treatment, adequate patient education is crucial\nfor improving functionality and long-term outcomes. Despite advancements in\npatient education strategies, significant gaps persist in delivering\npersonalized, evidence-based information to patients with LBP. Recent\nadvancements in large language models (LLMs) and generative artificial\nintelligence (GenAI) have demonstrated the potential to enhance patient\neducation. However, their application and efficacy in delivering educational\ncontent to patients with LBP remain underexplored and warrant further\ninvestigation. In this study, we introduce a novel approach utilizing LLMs with\nRetrieval-Augmented Generation (RAG) and few-shot learning to generate tailored\neducational materials for patients with LBP. Physical therapists manually\nevaluated our model responses for redundancy, accuracy, and completeness using\na Likert scale. In addition, the readability of the generated education\nmaterials is assessed using the Flesch Reading Ease score. The findings\ndemonstrate that RAG-based LLMs outperform traditional LLMs, providing more\naccurate, complete, and readable patient education materials with less\nredundancy. Having said that, our analysis reveals that the generated materials\nare not yet ready for use in clinical practice. This study underscores the\npotential of AI-driven models utilizing RAG to improve patient education for\nLBP; however, significant challenges remain in ensuring the clinical relevance\nand granularity of content generated by these models.",
      "tldr_zh": "本研究探讨了生成式AI（Generative AI）在腰痛（LBP）患者教育中的应用潜力，强调其结合检索增强生成（Retrieval-Augmented Generation, RAG）和少样本学习（few-shot learning）的LLMs模型来生成个性化教育材料。研究方法包括由物理治疗师使用Likert scale评估材料的冗余、准确性和完整性，并通过Flesch Reading Ease score评估可读性。结果显示，RAG-based LLMs比传统LLMs提供更准确、完整和可读的内容，但整体上这些材料仍不适合临床使用，存在临床相关性和内容粒度方面的挑战。研究突出了AI驱动模型的潜力，同时提醒需要进一步改进以确保实际应用。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15260v1",
      "published_date": "2024-09-23 17:56:08 UTC",
      "updated_date": "2024-09-23 17:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:37:52.233761"
    },
    {
      "arxiv_id": "2409.15259v2",
      "title": "StarVid: Enhancing Semantic Alignment in Video Diffusion Models via Spatial and SynTactic Guided Attention Refocusing",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhang Li",
        "Qi Mao",
        "Lan Chen",
        "Zhen Fang",
        "Lei Tian",
        "Xinyan Xiao",
        "Libiao Jin",
        "Hua Wu"
      ],
      "abstract": "Recent advances in text-to-video (T2V) generation with diffusion models have\ngarnered significant attention. However, they typically perform well in scenes\nwith a single object and motion, struggling in compositional scenarios with\nmultiple objects and distinct motions to accurately reflect the semantic\ncontent of text prompts. To address these challenges, we propose\n\\textbf{StarVid}, a plug-and-play, training-free method that improves semantic\nalignment between multiple subjects, their motions, and text prompts in T2V\nmodels. StarVid first leverages the spatial reasoning capabilities of large\nlanguage models (LLMs) for two-stage motion trajectory planning based on text\nprompts. Such trajectories serve as spatial priors, guiding a spatial-aware\nloss to refocus cross-attention (CA) maps into distinctive regions.\nFurthermore, we propose a syntax-guided contrastive constraint to strengthen\nthe correlation between the CA maps of verbs and their corresponding nouns,\nenhancing motion-subject binding. Both qualitative and quantitative evaluations\ndemonstrate that the proposed framework significantly outperforms baseline\nmethods, delivering videos of higher quality with improved semantic\nconsistency.",
      "tldr_zh": "该研究针对文本到视频 (T2V) 生成模型在多对象多动作场景中的语义对齐问题，提出了一种即插即用、无需训练的框架StarVid，以提升视频扩散模型的性能。StarVid 利用大语言模型 (LLMs) 进行两阶段动作轨迹规划，作为空间先验，并结合空间感知损失函数重新聚焦跨注意力 (CA) 地图到不同区域，同时引入语法引导对比约束来加强动词与对应名词的关联，提升动作-主语绑定。定性和定量评估表明，StarVid 显著优于基线方法，生成视频质量更高且语义一致性更强。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15259v2",
      "published_date": "2024-09-23 17:56:03 UTC",
      "updated_date": "2025-03-03 15:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:38:03.849672"
    },
    {
      "arxiv_id": "2409.15256v1",
      "title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View",
      "title_zh": "视觉语言模型的行为偏差：行为金融视角",
      "authors": [
        "Yuhang Xiao",
        "Yudi Lin",
        "Ming-Chang Chiu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models\n(LLMs) was equipped with vision modules to create more human-like models.\nHowever, we should carefully evaluate their applications in different domains,\nas they may possess undesired biases. Our work studies the potential behavioral\nbiases of LVLMs from a behavioral finance perspective, an interdisciplinary\nsubject that jointly considers finance and psychology. We propose an end-to-end\nframework, from data collection to new evaluation metrics, to assess LVLMs'\nreasoning capabilities and the dynamic behaviors manifested in two established\nhuman financial behavioral biases: recency bias and authority bias. Our\nevaluations find that recent open-source LVLMs such as LLaVA-NeXT,\nMobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer\nsignificantly from these two biases, while the proprietary model GPT-4o is\nnegligibly impacted. Our observations highlight directions in which open-source\nmodels can improve. The code is available at\nhttps://github.com/mydcxiao/vlm_behavioral_fin.",
      "tldr_zh": "本文从行为金融学的视角探讨 Large Vision-Language Models (LVLMs) 的潜在行为偏差，旨在评估这些模型在金融决策中的可靠性。研究提出一个端到端框架，包括数据收集和新的评估指标，用于测试 LVLMs 在 recency bias（近因偏差）和 authority bias（权威偏差）上的推理能力和动态行为。实验发现，开源模型如 LLaVA-NeXT、MobileVLM-V2 和 Mini-Gemini 等显著受这些偏差影响，而专有模型 GPT-4o 几乎不受影响。该研究为开源模型的改进提供了关键方向，并公开了相关代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024 Workshop on Large Language Models and Cognition",
      "pdf_url": "http://arxiv.org/pdf/2409.15256v1",
      "published_date": "2024-09-23 17:54:47 UTC",
      "updated_date": "2024-09-23 17:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:38:16.414706"
    },
    {
      "arxiv_id": "2409.15254v5",
      "title": "Archon: An Architecture Search Framework for Inference-Time Techniques",
      "title_zh": "Archon：用于推理时技术的架构搜索框架",
      "authors": [
        "Jon Saad-Falcon",
        "Adrian Gamarra Lafuente",
        "Shlok Natarajan",
        "Nahum Maru",
        "Hristo Todorov",
        "Etash Guha",
        "E. Kelly Buchanan",
        "Mayee Chen",
        "Neel Guha",
        "Christopher Ré",
        "Azalia Mirhoseini"
      ],
      "abstract": "Inference-time techniques are emerging as highly effective tools to enhance\nlarge language model (LLM) capabilities. However, best practices for developing\nsystems that combine these techniques remain underdeveloped due to our limited\nunderstanding of the utility of individual inference-time techniques and the\ninteractions between them. Additionally, efficiently and automatically\nsearching the space of model choices, inference-time techniques, and their\ncompositions is challenging due to the large design space. To address these\nchallenges, we introduce Archon, a modular framework for selecting, combining,\nand stacking layers of inference-time techniques to construct optimized LLM\nsystems for target benchmarks. Rather than relying on a single LLM called once,\nwe leverage a diverse set of LLMs and inference-time techniques, creating LLM\nsystems greater than the sum of their parts. Archon defines an extensible\ndesign space, encompassing techniques such as generation ensembling, repeated\nsampling, ranking, fusion, critiquing, verification, and unit testing. It\ntransforms the problem of building LLM systems into a hyperparameter\noptimization objective. Given the available LLMs, inference-time techniques,\nand compute budget, Archon utilizes hyperparameter search techniques to\ndiscover optimized architectures for target benchmark(s). We evaluate Archon\narchitectures across a range of instruction-following, reasoning, and coding\nbenchmarks, including MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval,\nMixEval Hard, MATH, and CodeContests. Archon architectures outperform frontier\nmodels, such as GPT-4o and Claude 3.5 Sonnet, on these benchmarks, achieving an\naverage accuracy increase of 15.1 percentage points by using all available\nLLMs. We make our code and datasets available publicly on Github:\nhttps://github.com/ScalingIntelligence/Archon.",
      "tldr_zh": "这篇论文介绍了 Archon，一种用于优化大型语言模型(LLM)推理时技术的架构搜索框架，旨在解决技术效用和交互问题的不足。\nArchon 通过模块化设计选择、组合和堆叠推理时技术（如 generation ensembling、ranking 和 verification），并将其转化为超参数优化问题，利用多种 LLM 和计算资源搜索最佳系统架构。\n实验在多个基准上（如 MT-Bench、MATH 和 CodeContests）进行，结果显示 Archon 架构超越前沿模型如 GPT-4o 和 Claude 3.5 Sonnet，平均准确率提高了 15.1%。\n作者公开了代码和数据集，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15254v5",
      "published_date": "2024-09-23 17:53:42 UTC",
      "updated_date": "2024-10-03 05:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:38:29.091288"
    },
    {
      "arxiv_id": "2409.17179v2",
      "title": "Fully automatic extraction of morphological traits from the Web: utopia or reality?",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Marcos",
        "Robert van de Vlasakker",
        "Ioannis N. Athanasiadis",
        "Pierre Bonnet",
        "Hervé Goeau",
        "Alexis Joly",
        "W. Daniel Kissling",
        "César Leblanc",
        "André S. J. van Proosdij",
        "Konstantinos P. Panousis"
      ],
      "abstract": "Plant morphological traits, their observable characteristics, are fundamental\nto understand the role played by each species within their ecosystem. However,\ncompiling trait information for even a moderate number of species is a\ndemanding task that may take experts years to accomplish. At the same time,\nmassive amounts of information about species descriptions is available online\nin the form of text, although the lack of structure makes this source of data\nimpossible to use at scale. To overcome this, we propose to leverage recent\nadvances in large language models (LLMs) and devise a mechanism for gathering\nand processing information on plant traits in the form of unstructured textual\ndescriptions, without manual curation. We evaluate our approach by\nautomatically replicating three manually created species-trait matrices. Our\nmethod managed to find values for over half of all species-trait pairs, with an\nF1-score of over 75%. Our results suggest that large-scale creation of\nstructured trait databases from unstructured online text is currently feasible\nthanks to the information extraction capabilities of LLMs, being limited by the\navailability of textual descriptions covering all the traits of interest.",
      "tldr_zh": "该论文探讨了从网络文本中自动提取植物形态特征（morphological traits）的可行性，以解决手动收集这些特征的耗时问题。研究提出了一种利用大型语言模型（LLMs）的方法，从无结构化文本中收集和处理信息，从而自动生成物种-特征矩阵。实验结果显示，该方法成功为超过一半的物种-特征对提取值，F1-score超过75%，表明大规模创建结构化特征数据库已成为现实，但仍受限于相关文本描述的可用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.17179v2",
      "published_date": "2024-09-23 17:40:24 UTC",
      "updated_date": "2025-02-21 15:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:38:39.211967"
    },
    {
      "arxiv_id": "2409.15243v1",
      "title": "MACeIP: A Multimodal Ambient Context-enriched Intelligence Platform in Smart Cities",
      "title_zh": "翻译失败",
      "authors": [
        "Truong Thanh Hung Nguyen",
        "Phuc Truong Loc Nguyen",
        "Monica Wachowicz",
        "Hung Cao"
      ],
      "abstract": "This paper presents a Multimodal Ambient Context-enriched Intelligence\nPlatform (MACeIP) for Smart Cities, a comprehensive system designed to enhance\nurban management and citizen engagement. Our platform integrates advanced\ntechnologies, including Internet of Things (IoT) sensors, edge and cloud\ncomputing, and Multimodal AI, to create a responsive and intelligent urban\necosystem. Key components include Interactive Hubs for citizen interaction, an\nextensive IoT sensor network, intelligent public asset management, a pedestrian\nmonitoring system, a City Planning Portal, and a Cloud Computing System. We\ndemonstrate the prototype of MACeIP in several cities, focusing on Fredericton,\nNew Brunswick. This work contributes to innovative city development by offering\na scalable, efficient, and user-centric approach to urban intelligence and\nmanagement.",
      "tldr_zh": "本研究提出MACeIP，一种多模态环境上下文增强智能平台，用于提升智能城市中的城市管理和公民参与。该平台整合IoT传感器、edge computing、cloud computing以及Multimodal AI，构建一个响应式且智能的城市生态系统。关键组件包括互动中心、IoT传感器网络、智能公共资产管理、行人监测系统、城市规划门户和云计算系统，并在多个城市（如Fredericton, New Brunswick）进行原型演示。该平台提供可扩展、高效、以用户为中心的城市智能管理方法，助力创新城市发展。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 6 figures, IEEE/IEIE ICCE-Asia 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15243v1",
      "published_date": "2024-09-23 17:39:53 UTC",
      "updated_date": "2024-09-23 17:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:38:50.516295"
    },
    {
      "arxiv_id": "2409.15241v1",
      "title": "Domino: Eliminating Communication in LLM Training via Generic Tensor Slicing and Overlapping",
      "title_zh": "翻译失败",
      "authors": [
        "Guanhua Wang",
        "Chengming Zhang",
        "Zheyu Shen",
        "Ang Li",
        "Olatunji Ruwase"
      ],
      "abstract": "Given the popularity of generative AI, Large Language Models (LLMs) often\nconsume hundreds or thousands of GPUs for parallelizing and accelerating the\ntraining process. Communication overhead becomes more pronounced when training\nLLMs at scale. To eliminate communication overhead in distributed LLM training,\nwe propose Domino, which provides a generic scheme to hide communication behind\ncomputation. By breaking data dependency of a single batch training into\nsmaller independent pieces, Domino pipelines these independent pieces training\nand provides generic strategy of fine-grained communication and computation\noverlapping. Extensive results show that, comparing with Megatron-LM, Domino\nachieves up to 1.3x speedup for LLM training on Nvidia DGX-H100 GPUs.",
      "tldr_zh": "该论文提出Domino框架，旨在消除大型语言模型(LLM)训练中的通信开销，通过通用张量切片和重叠技术来实现计算与通信的重叠。Domino将单个批次训练分解为更小的独立部分，并采用流水线策略进行细粒度的处理，从而隐藏通信开销。实验结果显示，与Megatron-LM相比，Domino在Nvidia DGX-H100 GPUs上实现了高达1.3倍的训练速度提升。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15241v1",
      "published_date": "2024-09-23 17:38:52 UTC",
      "updated_date": "2024-09-23 17:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:39:02.189232"
    },
    {
      "arxiv_id": "2409.15240v2",
      "title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
      "title_zh": "MADial-Bench：面向真实世界评估的记忆增强对话生成",
      "authors": [
        "Junqing He",
        "Liang Zhu",
        "Rui Wang",
        "Xi Wang",
        "Reza Haffari",
        "Jiaxing Zhang"
      ],
      "abstract": "Long-term memory is important for chatbots and dialogue systems (DS) to\ncreate consistent and human-like conversations, evidenced by numerous developed\nmemory-augmented DS (MADS). To evaluate the effectiveness of such MADS,\nexisting commonly used evaluation metrics, like retrieval accuracy and\nperplexity (PPL), mainly focus on query-oriented factualness and language\nquality assessment. However, these metrics often lack practical value.\nMoreover, the evaluation dimensions are insufficient for human-like assessment\nin DS. Regarding memory-recalling paradigms, current evaluation schemes only\nconsider passive memory retrieval while ignoring diverse memory recall with\nrich triggering factors, e.g., emotions and surroundings, which can be\nessential in emotional support scenarios. To bridge the gap, we construct a\nnovel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various\nmemory-recalling paradigms based on cognitive science and psychology theories.\nThe benchmark assesses two tasks separately: memory retrieval and memory\nrecognition with the incorporation of both passive and proactive memory recall\ndata. We introduce new scoring criteria to the evaluation, including memory\ninjection, emotion support (ES) proficiency, and intimacy, to comprehensively\nassess generated responses. Results from cutting-edge embedding models and\nlarge language models on this benchmark indicate the potential for further\nadvancement. Extensive testing further reveals correlations between memory\ninjection, ES proficiency, and intimacy.",
      "tldr_zh": "该研究指出了现有评估指标（如检索准确性和困惑度PPL）在评估记忆增强对话系统（MADS）时存在的不足，无法全面反映实际应用价值和多样记忆回想（如情感和环境因素）。为了弥补这一差距，论文构建了MADial-Bench基准，该基准基于认知科学和心理学理论，涵盖被动和主动记忆回想范式，并评估记忆检索和记忆识别任务。新的评分标准包括记忆注入、情感支持（ES）熟练度和亲密度，这些指标有助于更全面地评估生成响应的人类化程度。实验结果显示，先进嵌入模型和大语言模型在该基准上仍有改进空间，并揭示了记忆注入、ES熟练度和亲密度之间的相关性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15240v2",
      "published_date": "2024-09-23 17:38:41 UTC",
      "updated_date": "2024-10-23 17:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:39:14.692903"
    },
    {
      "arxiv_id": "2409.15228v3",
      "title": "A Comprehensive Framework for Evaluating API-oriented Code Generation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yixi Wu",
        "Pengfei He",
        "Zehao Wang",
        "Shaowei Wang",
        "Yuan Tian",
        "Tse-Hsun Chen"
      ],
      "abstract": "Large language models (LLMs) like GitHub Copilot and ChatGPT have emerged as\npowerful tools for code generation, significantly enhancing productivity and\naccelerating software development. However, existing benchmarks primarily focus\non general code generation without considering API-oriented code generation,\ni.e., generating code that invokes APIs from specific libraries. Given the\ngrowing demand for API-oriented code generation, there is a pressing need for a\nsystematic and automated approach to evaluate LLM on API-oriented code\ngeneration. To address this gap, we propose AutoAPIEval, a lightweight and\nautomated framework designed to evaluate the capabilities of LLMs in\nAPI-oriented code generation. Our framework works with any library that\nprovides API documentation and focuses on two unit tasks: API recommendation\nand code example generation, along with four metrics to evaluate the generated\nAPIs and code examples, such as the proportion of incorrect API recommendations\nfor Task 1, and the proportion of code examples where no specific API is\ninvoked and uncompilable/unexecutable code examples for Task 2. In addition, we\nconducted a case study on three LLMs (ChatGPT, MagiCoder, and DeepSeek Coder)\nand Java Runtime Environment 8 to demonstrate the framework's effectiveness.\nOur findings reveal substantial variability in LLM performance across tasks,\nwith ChatGPT adhering better to instructions, while sharing similar\neffectiveness in code example generation with its counterparts (i.e., MagiCoder\nand DeekSeek Coder). We also identify key factors associated with code quality,\nsuch as API popularity and model confidence, and build classifiers that achieve\nhigh accuracy in detecting incorrect API recommendations and erroneous code\nexamples. Retrieval-augmented generation enhances the quality of code generated\nby LLMs, though its effectiveness varies across different LLMs.",
      "tldr_zh": "这篇论文提出AutoAPIEval框架，用于系统评估大型语言模型(LLMs)在API-oriented代码生成中的能力，填补了现有基准忽略特定库API调用的空白。框架支持任何提供API文档的库，聚焦于API推荐和代码示例生成两个任务，并引入四个指标（如API推荐错误比例和代码可编译性）进行评估。研究通过案例分析ChatGPT、MagiCoder和DeepSeek Coder等模型，揭示了LLMs在任务间的表现差异、影响代码质量的关键因素（如API流行度和模型置信度），并证明检索增强生成(Retrieval-augmented generation)能提升代码质量，但效果因模型而异。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15228v3",
      "published_date": "2024-09-23 17:22:09 UTC",
      "updated_date": "2024-09-26 14:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:39:28.862756"
    },
    {
      "arxiv_id": "2409.15224v1",
      "title": "Enhancing Pedestrian Trajectory Prediction with Crowd Trip Information",
      "title_zh": "翻译失败",
      "authors": [
        "Rei Tamaru",
        "Pei Li",
        "Bin Ran"
      ],
      "abstract": "Pedestrian trajectory prediction is essential for various applications in\nactive traffic management, urban planning, traffic control, crowd management,\nand autonomous driving, aiming to enhance traffic safety and efficiency.\nAccurately predicting pedestrian trajectories requires a deep understanding of\nindividual behaviors, social interactions, and road environments. Existing\nstudies have developed various models to capture the influence of social\ninteractions and road conditions on pedestrian trajectories. However, these\napproaches are limited by the lack of a comprehensive view of social\ninteractions and road environments. To address these limitations and enhance\nthe accuracy of pedestrian trajectory prediction, we propose a novel approach\nincorporating trip information as a new modality into pedestrian trajectory\nmodels. We propose RNTransformer, a generic model that utilizes crowd trip\ninformation to capture global information on social interactions. We\nincorporated RNTransformer with various socially aware local pedestrian\ntrajectory prediction models to demonstrate its performance. Specifically, by\nleveraging a pre-trained RNTransformer when training different pedestrian\ntrajectory prediction models, we observed improvements in performance metrics:\na 1.3/2.2% enhancement in ADE/FDE on Social-LSTM, a 6.5/28.4% improvement on\nSocial-STGCNN, and an 8.6/4.3% improvement on S-Implicit. Evaluation results\ndemonstrate that RNTransformer significantly enhances the accuracy of various\npedestrian trajectory prediction models across multiple datasets. Further\ninvestigation reveals that the RNTransformer effectively guides local models to\nmore accurate directions due to the consideration of global information. By\nexploring crowd behavior within the road network, our approach shows great\npromise in improving pedestrian safety through accurate trajectory predictions.",
      "tldr_zh": "本研究旨在提升行人轨迹预测的准确性，以改善交通安全和效率，通过整合人群出行信息作为新模态来解决现有模型对社会互动和道路环境的局限性。论文提出RNTransformer，这是一个通用模型，用于捕获全局社会互动信息，并将其与Social-LSTM、Social-STGCNN和S-Implicit等本地预测模型结合。实验结果显示，RNTransformer显著提升了性能：在Social-LSTM上ADE/FDE改善1.3%/2.2%，在Social-STGCNN上提升6.5%/28.4%，在S-Implicit上提升8.6%/4.3%。总体而言，该方法通过考虑全局信息有效指导本地模型，提供更精确的行人轨迹预测，从而增强人群行为分析和行人安全。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15224v1",
      "published_date": "2024-09-23 17:11:31 UTC",
      "updated_date": "2024-09-23 17:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:39:41.053711"
    },
    {
      "arxiv_id": "2410.05278v1",
      "title": "Dumpling GNN: Hybrid GNN Enables Better ADC Payload Activity Prediction Based on Chemical Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjie Xu",
        "Lingxi Xie"
      ],
      "abstract": "Antibody-drug conjugates (ADCs) have emerged as a promising class of targeted\ncancer therapeutics, but the design and optimization of their cytotoxic\npayloads remain challenging. This study introduces DumplingGNN, a novel hybrid\nGraph Neural Network architecture specifically designed for predicting ADC\npayload activity based on chemical structure. By integrating Message Passing\nNeural Networks (MPNN), Graph Attention Networks (GAT), and GraphSAGE layers,\nDumplingGNN effectively captures multi-scale molecular features and leverages\nboth 2D topological and 3D structural information. We evaluate DumplingGNN on a\ncomprehensive ADC payload dataset focusing on DNA Topoisomerase I inhibitors,\nas well as on multiple public benchmarks from MoleculeNet. DumplingGNN achieves\nstate-of-the-art performance across several datasets, including BBBP (96.4\\%\nROC-AUC), ToxCast (78.2\\% ROC-AUC), and PCBA (88.87\\% ROC-AUC). On our\nspecialized ADC payload dataset, it demonstrates exceptional accuracy\n(91.48\\%), sensitivity (95.08\\%), and specificity (97.54\\%). Ablation studies\nconfirm the synergistic effects of the hybrid architecture and the critical\nrole of 3D structural information in enhancing predictive accuracy. The model's\nstrong interpretability, enabled by attention mechanisms, provides valuable\ninsights into structure-activity relationships. DumplingGNN represents a\nsignificant advancement in molecular property prediction, with particular\npromise for accelerating the design and optimization of ADC payloads in\ntargeted cancer therapy development.",
      "tldr_zh": "本研究提出 Dumpling GNN，一种混合 Graph Neural Network (GNN) 架构，整合 Message Passing Neural Networks (MPNN)、Graph Attention Networks (GAT) 和 GraphSAGE 层，用于基于化学结构预测抗体药物偶联物 (ADC) 有效载荷的活性。该模型有效捕捉多尺度分子特征，并结合 2D 拓扑和 3D 结构信息，在多个数据集上表现出色，包括 BBBP (96.4% ROC-AUC)、ToxCast (78.2% ROC-AUC) 和 PCBA (88.87% ROC-AUC)。在专有的 ADC 有效载荷数据集上，Dumpling GNN 实现了 91.48% 的准确率、95.08% 的敏感性和 97.54% 的特异性。消融研究证实了混合架构的协同效应以及 3D 结构信息的关键作用，并通过注意力机制提供结构-活性关系的可解释洞见，从而加速 ADC 有效载荷的设计和优化。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05278v1",
      "published_date": "2024-09-23 17:11:04 UTC",
      "updated_date": "2024-09-23 17:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:39:56.303413"
    },
    {
      "arxiv_id": "2409.15202v2",
      "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Iwo Naglik",
        "Mateusz Lango"
      ],
      "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model.",
      "tldr_zh": "本文提出了一种新的 Aspect-Sentiment Triplet Extraction (ASTE) 方法，使用三个 Transformer 启发的层来建模短语之间的依赖关系以及分类器决策的相互关联，从而解决现有方法的独立决策问题。该方法首先提取文本片段，然后通过依赖建模来过滤和配对方面短语、意见短语，并分配情感极性。实验结果显示，在流行基准上，该方法的 F1 得分高于其他方法，且通过简单预训练技术进一步提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "The 2024 Conference on Empirical Methods in Natural Language\n  Processing, November 12-16, Miami, Florida 9 pages, appendix, diagrams",
      "pdf_url": "http://arxiv.org/pdf/2409.15202v2",
      "published_date": "2024-09-23 16:49:47 UTC",
      "updated_date": "2024-10-04 06:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:40:05.373630"
    },
    {
      "arxiv_id": "2409.15199v1",
      "title": "Learning from Contrastive Prompts: Automated Optimization and Adaptation",
      "title_zh": "从对比提示中学习：自动优化和适应",
      "authors": [
        "Mingqi Li",
        "Karan Aggarwal",
        "Yong Xie",
        "Aitzaz Ahmad",
        "Stephen Lau"
      ],
      "abstract": "As LLMs evolve, significant effort is spent on manually crafting prompts.\nWhile existing prompt optimization methods automate this process, they rely\nsolely on learning from incorrect samples, leading to a sub-optimal\nperformance. Additionally, an unexplored challenge in the literature is prompts\neffective for prior models may not perform well on newer versions or different\nlanguages. We propose the Learning from Contrastive Prompts (LCP) framework to\naddress these gaps, enhancing both prompt optimization and adaptation. LCP\nemploys contrastive learning to generate effective prompts by analyzing\npatterns in good and bad prompt examples. Our evaluation on the Big-Bench Hard\ndataset shows that LCP has a win rate of over 76% over existing methods in\nprompt optimization and demonstrates strong adaptability across different model\nversions, families, and languages. LCP offers a systematic approach to prompt\nengineering, reducing manual effort in deploying LLMs across varied contexts.",
      "tldr_zh": "这篇论文提出了 Learning from Contrastive Prompts (LCP) 框架，用于自动化优化和适应大型语言模型(LLMs)的提示设计，以解决现有方法仅从错误样本学习导致的性能不足问题。LCP 通过 contrastive learning 分析好坏提示示例的模式，生成更有效的提示，并处理提示在新模型版本、系列或语言上的适应性挑战。在 Big-Bench Hard 数据集上评估显示，LCP 在提示优化中胜率超过 76%，并展示了强大的跨模型适应能力。该框架提供系统化的提示工程方法，显著减少了手动努力，促进 LLMs 在多样化上下文中的部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15199v1",
      "published_date": "2024-09-23 16:47:23 UTC",
      "updated_date": "2024-09-23 16:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:40:17.838546"
    },
    {
      "arxiv_id": "2409.15196v1",
      "title": "HOTVCOM: Generating Buzzworthy Comments for Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyan Chen",
        "Yiwen Qian",
        "Songzhou Yan",
        "Jiyuan Jia",
        "Zhixu Li",
        "Yanghua Xiao",
        "Xiaobo Li",
        "Ming Yang",
        "Qingpei Guo"
      ],
      "abstract": "In the era of social media video platforms, popular ``hot-comments'' play a\ncrucial role in attracting user impressions of short-form videos, making them\nvital for marketing and branding purpose. However, existing research\npredominantly focuses on generating descriptive comments or ``danmaku'' in\nEnglish, offering immediate reactions to specific video moments. Addressing\nthis gap, our study introduces \\textsc{HotVCom}, the largest Chinese video\nhot-comment dataset, comprising 94k diverse videos and 137 million comments. We\nalso present the \\texttt{ComHeat} framework, which synergistically integrates\nvisual, auditory, and textual data to generate influential hot-comments on the\nChinese video dataset. Empirical evaluations highlight the effectiveness of our\nframework, demonstrating its excellence on both the newly constructed and\nexisting datasets.",
      "tldr_zh": "本研究针对社交媒体视频平台的热门评论（hot-comments）在吸引用户注意力和营销中的关键作用，填补了现有研究主要聚焦英文描述性评论或弹幕的空白。研究者构建了HOTVCOM，这是最大的中文视频热门评论数据集，包含94k个多样化视频和1.37亿条评论。提出了ComHeat框架，该框架协同整合视觉、听觉和文本数据，以生成具有影响力的热门评论。实验结果显示，ComHeat框架在新数据集和现有数据集上表现出色，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2409.15196v1",
      "published_date": "2024-09-23 16:45:13 UTC",
      "updated_date": "2024-09-23 16:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:40:30.406701"
    },
    {
      "arxiv_id": "2410.03696v1",
      "title": "Improving Emotion Recognition Accuracy with Personalized Clustering",
      "title_zh": "通过个性化聚类提高情感识别准确性",
      "authors": [
        "Laura Gutierrez-Martin",
        "Celia Lopez Ongil",
        "Jose M. Lanza-Gutierrez",
        "Jose A. Miranda Calero"
      ],
      "abstract": "Emotion recognition through artificial intelligence and smart sensing of\nphysical and physiological signals (Affective Computing) is achieving very\ninteresting results in terms of accuracy, inference times, and user-independent\nmodels. In this sense, there are applications related to the safety and\nwell-being of people (sexual aggressions, gender-based violence, children and\nelderly abuse, mental health, etc.) that require even more improvements.\nEmotion detection should be done with fast, discrete, and non-luxurious systems\nworking in real-time and real life (wearable devices, wireless communications,\nbattery-powered). Furthermore, emotional reactions to violence are not equal in\nall people. Then, large general models cannot be applied to a multiuser system\nfor people protection, and customized and simple AI models would be welcomed by\nhealth and social workers and law enforcement agents. These customized models\nwill be applicable to clusters of subjects sharing similarities in their\nemotional reactions to external stimuli. This customization requires several\nsteps: creating clusters of subjects with similar behaviors, creating AI models\nfor every cluster, continually updating these models with new data, and\nenrolling new subjects in clusters when required. A methodology for clustering\ndata compiled (physical and physiological data, together with emotional labels)\nis presented in this work, as well as the method for including new subjects\nonce the AI model is generated. Experimental results demonstrate an improvement\nof 4% in accuracy and 3% in f1-score w.r.t. the general model, along with a 14%\nreduction in variability.",
      "tldr_zh": "这篇论文针对情感计算(Affective Computing)中的情绪识别问题，提出了一种个性化聚类方法，以适应不同用户在外部刺激下的情感反应差异，从而提升多用户安全应用（如暴力预防和心理健康）的准确性。方法包括创建基于物理和生理信号的主体聚类、为每个聚类训练专属AI模型、持续更新模型以及动态加入新主体。实验结果显示，该方法相较于通用模型，准确率提高了4%，F1-score提高了3%，并将变异性降低了14%。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.03696v1",
      "published_date": "2024-09-23 16:42:36 UTC",
      "updated_date": "2024-09-23 16:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:40:43.415946"
    },
    {
      "arxiv_id": "2409.15186v2",
      "title": "Location is Key: Leveraging Large Language Model for Functional Bug Localization in Verilog",
      "title_zh": "翻译失败",
      "authors": [
        "Bingkun Yao",
        "Ning Wang",
        "Jie Zhou",
        "Xi Wang",
        "Hong Gao",
        "Zhe Jiang",
        "Nan Guan"
      ],
      "abstract": "Bug localization in Verilog code is a crucial and time-consuming task during\nthe verification of hardware design. Since introduction, Large Language Models\n(LLMs) have showed their strong programming capabilities. However, no work has\nyet considered using LLMs for bug localization in Verilog code. This paper\npresents Location-is-Key, an opensource LLM solution to locate functional\nerrors in Verilog snippets. LiK achieves high localization accuracy, with a\npass@1 localization accuracy of 93.3% on our test dataset based on RTLLM,\nsurpassing GPT-4's 77.9% and comparable to Claude-3.5's 90.8%. Additionally,\nthe bug location obtained by LiK significantly improves GPT-3.5's bug repair\nefficiency (Functional pass@1 increased from 40.39% to 58.92%), highlighting\nthe importance of bug localization in LLM-based Verilog debugging. Compared to\nexisting methods, LiK only requires the design specification and the erroneous\ncode snippet, without the need for testbenches, assertions, or any other EDA\ntools. This research demonstrates the feasibility of using LLMs for Verilog\nerror localization, thus providing a new direction for automatic Verilog code\ndebugging.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 来定位 Verilog 代码中的功能错误问题，这是一个硬件设计验证中的关键挑战。作者提出了开源工具 Location-is-Key (LiK)，该方法仅需设计规范和错误代码片段即可实现高效的 bug 定位，无需 testbenches 或其他 EDA 工具。实验结果显示，LiK 在测试数据集上达到了 93.3% 的 pass@1 准确率，优于 GPT-4 的 77.9%，并显著提升了 GPT-3.5 的 bug 修复效率（Functional pass@1 从 40.39% 增加到 58.92%）。这项研究证明了 LLMs 在 Verilog 错误定位的可行性，为自动硬件代码调试开辟了新方向。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15186v2",
      "published_date": "2024-09-23 16:38:53 UTC",
      "updated_date": "2024-09-29 07:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:40:56.284073"
    },
    {
      "arxiv_id": "2409.15183v1",
      "title": "Chattronics: using GPTs to assist in the design of data acquisition systems",
      "title_zh": "Chattronics: 使用 GPTs 辅助数据采集系统设计",
      "authors": [
        "Jonathan Paul Driemeyer Brown",
        "Tiago Oliveira Weber"
      ],
      "abstract": "The usefulness of Large Language Models (LLM) is being continuously tested in\nvarious fields. However, their intrinsic linguistic characteristic is still one\nof the limiting factors when applying these models to exact sciences. In this\narticle, a novel approach to use General Pre-Trained Transformers to assist in\nthe design phase of data acquisition systems will be presented. The solution is\npackaged in the form of an application that retains the conversational aspects\nof LLMs, in such a manner that the user must provide details on the desired\nproject in order for the model to draft both a system-level architectural\ndiagram and the block-level specifications, following a Top-Down methodology\nbased on restrictions. To test this tool, two distinct user emulations were\nused, one of which uses an additional GPT model. In total, 4 different data\nacquisition projects were used in the testing phase, each with its own\nmeasurement requirements: angular position, temperature, acceleration and a\nfourth project with both pressure and superficial temperature measurements.\nAfter 160 test iterations, the study concludes that there is potential for\nthese models to serve adequately as synthesis/assistant tools for data\nacquisition systems, but there are still technological limitations. The results\nshow coherent architectures and topologies, but that GPTs have difficulties in\nsimultaneously considering all requirements and many times commits theoretical\nmistakes.",
      "tldr_zh": "该论文提出Chattronics，一种利用GPTs辅助数据采集系统设计的新方法，通过对话式应用程序让用户提供项目细节，采用Top-Down methodology生成系统级架构图和块级规格。研究测试了4个不同项目（包括角度位置、温度、加速度以及压力和表面温度测量），共进行160次迭代，结果显示GPTs能创建连贯的架构拓扑，但难以同时考虑所有要求并可能出现理论错误。总体而言，该方法证明了LLM在工程辅助中的潜力，但仍需克服技术限制以提升准确性。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "eess.SP",
        "68T35",
        "I.2.1; J.6"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15183v1",
      "published_date": "2024-09-23 16:36:16 UTC",
      "updated_date": "2024-09-23 16:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:41:05.896728"
    },
    {
      "arxiv_id": "2409.15182v2",
      "title": "Goal-based Neural Physics Vehicle Trajectory Prediction Model",
      "title_zh": "基于目标的神经物理车辆轨迹预测模型",
      "authors": [
        "Rui Gan",
        "Haotian Shi",
        "Pei Li",
        "Keshu Wu",
        "Bocheng An",
        "Linheng Li",
        "Junyi Ma",
        "Chengyuan Ma",
        "Bin Ran"
      ],
      "abstract": "Vehicle trajectory prediction plays a vital role in intelligent\ntransportation systems and autonomous driving, as it significantly affects\nvehicle behavior planning and control, thereby influencing traffic safety and\nefficiency. Numerous studies have been conducted to predict short-term vehicle\ntrajectories in the immediate future. However, long-term trajectory prediction\nremains a major challenge due to accumulated errors and uncertainties.\nAdditionally, balancing accuracy with interpretability in the prediction is\nanother challenging issue in predicting vehicle trajectory. To address these\nchallenges, this paper proposes a Goal-based Neural Physics Vehicle Trajectory\nPrediction Model (GNP). The GNP model simplifies vehicle trajectory prediction\ninto a two-stage process: determining the vehicle's goal and then choosing the\nappropriate trajectory to reach this goal. The GNP model contains two\nsub-modules to achieve this process. The first sub-module employs a multi-head\nattention mechanism to accurately predict goals. The second sub-module\nintegrates a deep learning model with a physics-based social force model to\nprogressively predict the complete trajectory using the generated goals. The\nGNP demonstrates state-of-the-art long-term prediction accuracy compared to\nfour baseline models. We provide interpretable visualization results to\nhighlight the multi-modality and inherent nature of our neural physics\nframework. Additionally, ablation studies are performed to validate the\neffectiveness of our key designs.",
      "tldr_zh": "本研究针对车辆轨迹预测中的长期预测挑战（如累积错误和不确定性）及准确性与可解释性的平衡问题，提出了一种基于目标的神经物理车辆轨迹预测模型（GNP）。GNP 将预测过程分为两阶段：首先使用多头注意力机制（multi-head attention mechanism）精确预测车辆目标，其次结合深度学习模型和基于物理的社会力模型（social force model）生成完整的轨迹。实验结果显示，GNP 在长期预测准确性上优于四个基线模型，并通过可解释的可视化结果和消融研究验证了其多模态框架的有效性和固有特性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15182v2",
      "published_date": "2024-09-23 16:35:43 UTC",
      "updated_date": "2024-09-25 04:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:41:17.443696"
    },
    {
      "arxiv_id": "2409.15172v1",
      "title": "Skills Made to Order: Efficient Acquisition of Robot Cooking Skills Guided by Multiple Forms of Internet Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mrinal Verghese",
        "Christopher Atkeson"
      ],
      "abstract": "This study explores the utility of various internet data sources to select\namong a set of template robot behaviors to perform skills. Learning\ncontact-rich skills involving tool use from internet data sources has typically\nbeen challenging due to the lack of physical information such as contact\nexistence, location, areas, and force in this data. Prior works have generally\nused internet data and foundation models trained on this data to generate\nlow-level robot behavior. We hypothesize that these data and models may be\nbetter suited to selecting among a set of basic robot behaviors to perform\nthese contact-rich skills. We explore three methods of template selection:\nquerying large language models, comparing video of robot execution to retrieved\nhuman video using features from a pretrained video encoder common in prior\nwork, and performing the same comparison using features from an optic flow\nencoder trained on internet data. Our results show that LLMs are surprisingly\ncapable template selectors despite their lack of visual information, optical\nflow encoding significantly outperforms video encoders trained with an order of\nmagnitude more data, and important synergies exist between various forms of\ninternet data for template selection. By exploiting these synergies, we create\na template selector using multiple forms of internet data that achieves a 79\\%\nsuccess rate on a set of 16 different cooking skills involving tool-use.",
      "tldr_zh": "本研究探讨了利用多种互联网数据来源（如大型语言模型LLMs和视频编码器）来高效选择模板机器人行为，从而指导机器人学习接触丰富的烹饪技能。该方法解决了互联网数据中缺乏物理信息（如接触位置和力）的问题，通过三种模板选择策略进行实验：查询LLMs、使用预训练视频编码器比较机器人和人类视频，以及采用光学流编码器进行类似比较。结果显示，LLMs即使缺少视觉信息也能有效选择模板，光学流编码器显著优于使用更多数据的视频编码器，且不同数据形式间存在协同效应，最终开发的整合系统在16种涉及工具的烹饪技能上实现了79%的成功率，为机器人技能获取提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15172v1",
      "published_date": "2024-09-23 16:25:44 UTC",
      "updated_date": "2024-09-23 16:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:41:29.984770"
    },
    {
      "arxiv_id": "2409.15159v2",
      "title": "DRAPER: Towards a Robust Robot Deployment and Reliable Evaluation for Quasi-Static Pick-and-Place Cloth-Shaping Neural Controllers",
      "title_zh": "翻译失败",
      "authors": [
        "Halid Abdulrahim Kadi",
        "Jose Alex Chandy",
        "Luis Figueredo",
        "Kasim Terzić",
        "Praminda Caleb-Solly"
      ],
      "abstract": "Comparing robotic cloth-manipulation systems in a real-world setup is\nchallenging. The fidelity gap between simulation-trained cloth neural\ncontrollers and real-world operation hinders the reliable deployment of these\nmethods in physical trials. Inconsistent experimental setups and hardware\nlimitations among different approaches obstruct objective evaluations. This\nstudy demonstrates a reliable real-world comparison of different\nsimulation-trained neural controllers on both flattening and folding tasks with\ndifferent types of fabrics varying in material, size, and colour. We introduce\nthe DRAPER framework to enable this comprehensive study, which reliably\nreflects the true capabilities of these neural controllers. It specifically\naddresses real-world grasping errors, such as misgrasping and multilayer\ngrasping, through real-world adaptations of the simulation environment to\nprovide data trajectories that closely reflect real-world grasping scenarios.\nIt also employs a special set of vision processing techniques to close the\nsimulation-to-reality gap in the perception. Furthermore, it achieves robust\ngrasping by adopting a tweezer-extended gripper and a grasping procedure. We\ndemonstrate DRAPER's generalisability across different deep-learning methods\nand robotic platforms, offering valuable insights to the cloth manipulation\nresearch community.",
      "tldr_zh": "该论文介绍了DRAPER框架，旨在解决机器人布料操作中模拟训练神经控制器与现实部署的差距问题，通过适应模拟环境处理现实抓取错误（如misgrasping和multilayer grasping），并采用视觉处理技术和鲁棒抓取程序（如tweezer-extended gripper）。DRAPER框架支持对不同布料材料、尺寸和颜色的展平和折叠任务进行可靠比较，并在多种深度学习方法和机器人平台上展示通用性。实验结果为布料操作研究社区提供了宝贵的见解，提升了神经控制器的真实世界性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages main texts, 3 figures, and 4 tables. It is submitted to 2025\n  IEEE 21st International Conference on Automation Science and Engineering",
      "pdf_url": "http://arxiv.org/pdf/2409.15159v2",
      "published_date": "2024-09-23 16:08:16 UTC",
      "updated_date": "2025-03-14 23:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:41:44.809138"
    },
    {
      "arxiv_id": "2409.15158v1",
      "title": "Automatic Feature Learning for Essence: a Case Study on Car Sequencing",
      "title_zh": "针对 Essence 的自动特征学习：汽车排序问题的案例研究",
      "authors": [
        "Alessio Pellegrino",
        "Özgür Akgün",
        "Nguyen Dang",
        "Zeynep Kiziltan",
        "Ian Miguel"
      ],
      "abstract": "Constraint modelling languages such as Essence offer a means to describe\ncombinatorial problems at a high-level, i.e., without committing to detailed\nmodelling decisions for a particular solver or solving paradigm. Given a\nproblem description written in Essence, there are multiple ways to translate it\nto a low-level constraint model. Choosing the right combination of a low-level\nconstraint model and a target constraint solver can have significant impact on\nthe effectiveness of the solving process. Furthermore, the choice of the best\ncombination of constraint model and solver can be instance-dependent, i.e.,\nthere may not exist a single combination that works best for all instances of\nthe same problem. In this paper, we consider the task of building machine\nlearning models to automatically select the best combination for a problem\ninstance. A critical part of the learning process is to define instance\nfeatures, which serve as input to the selection model. Our contribution is\nautomatic learning of instance features directly from the high-level\nrepresentation of a problem instance using a language model. We evaluate the\nperformance of our approach using the Essence modelling language with a case\nstudy involving the car sequencing problem.",
      "tldr_zh": "该论文探讨了使用约束建模语言（如 Essence）在高层次描述组合问题时，如何自动选择最佳低级约束模型和求解器组合，以提升求解效率。研究提出了一种机器学习方法，通过语言模型直接从问题实例的高级表示中自动学习实例特征，作为选择模型的输入。实验以汽车序列问题（car sequencing）为例，评估了该方法的性能，展示了其在实例相关优化方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15158v1",
      "published_date": "2024-09-23 16:06:44 UTC",
      "updated_date": "2024-09-23 16:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:41:54.359725"
    },
    {
      "arxiv_id": "2409.15155v1",
      "title": "MAR-DTN: Metal Artifact Reduction using Domain Transformation Network for Radiotherapy Planning",
      "title_zh": "MAR-DTN：利用域变换网络减少金属伪影的放射治疗规划",
      "authors": [
        "Belén Serrano-Antón",
        "Mubashara Rehman",
        "Niki Martinel",
        "Michele Avanzo",
        "Riccardo Spizzo",
        "Giuseppe Fanetti",
        "Alberto P. Muñuzuri",
        "Christian Micheloni"
      ],
      "abstract": "For the planning of radiotherapy treatments for head and neck cancers,\nComputed Tomography (CT) scans of the patients are typically employed. However,\nin patients with head and neck cancer, the quality of standard CT scans\ngenerated using kilo-Voltage (kVCT) tube potentials is severely degraded by\nstreak artifacts occurring in the presence of metallic implants such as dental\nfillings. Some radiotherapy devices offer the possibility of acquiring\nMega-Voltage CT (MVCT) for daily patient setup verification, due to the higher\nenergy of X-rays used, MVCT scans are almost entirely free from artifacts\nmaking them more suitable for radiotherapy treatment planning.\n  In this study, we leverage the advantages of kVCT scans with those of MVCT\nscans (artifact-free). We propose a deep learning-based approach capable of\ngenerating artifact-free MVCT images from acquired kVCT images. The outcome\noffers the benefits of artifact-free MVCT images with enhanced soft tissue\ncontrast, harnessing valuable information obtained through kVCT technology for\nprecise therapy calibration. Our proposed method employs UNet-inspired model,\nand is compared with adversarial learning and transformer networks. This first\nand unique approach achieves remarkable success, with PSNR of 30.02 dB across\nthe entire patient volume and 27.47 dB in artifact-affected regions\nexclusively. It is worth noting that the PSNR calculation excludes the\nbackground, concentrating solely on the region of interest.",
      "tldr_zh": "该研究针对头颈部癌症放射治疗规划中，kVCT 扫描因金属植入物（如牙齿填充物）导致的条纹伪影问题，提出 MAR-DTN 方法——一种基于 Domain Transformation Network 的深度学习框架。该方法利用 MVCT 扫描的无伪影优势，从 kVCT 图像生成高质量的伪影免费 MVCT 图像，同时保留 kVCT 的软组织对比度以提升治疗校准精度。MAR-DTN 采用 UNet 启发模型，并与对抗学习和 transformer 网络进行比较，结果显示整体 PSNR 达到 30.02 dB，在受伪影影响区域为 27.47 dB，显著提高了图像质量和治疗规划准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted in 27th International Conference on Pattern Recognition\n  (ICPR). Mubashara Rehman and Bel\\'en Serrano-Ant\\'on, both co-first authors\n  of the manuscript",
      "pdf_url": "http://arxiv.org/pdf/2409.15155v1",
      "published_date": "2024-09-23 16:04:00 UTC",
      "updated_date": "2024-09-23 16:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:42:08.352710"
    },
    {
      "arxiv_id": "2409.15154v1",
      "title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachi Chen",
        "Qingyuan Zhong",
        "Yanlin Wang",
        "Kaiwen Ning",
        "Yongkun Liu",
        "Zenan Xu",
        "Zhe Zhao",
        "Ting Chen",
        "Zibin Zheng"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has significantly influenced\nvarious aspects of software development activities. Despite their benefits,\nLLMs also pose notable risks, including the potential to generate harmful\ncontent and being abused by malicious developers to create malicious code.\nSeveral previous studies have focused on the ability of LLMs to resist the\ngeneration of harmful content that violates human ethical standards, such as\nbiased or offensive content. However, there is no research evaluating the\nability of LLMs to resist malicious code generation. To fill this gap, we\npropose RMCBench, the first benchmark comprising 473 prompts designed to assess\nthe ability of LLMs to resist malicious code generation. This benchmark employs\ntwo scenarios: a text-to-code scenario, where LLMs are prompted with\ndescriptions to generate code, and a code-to-code scenario, where LLMs\ntranslate or complete existing malicious code. Based on RMCBench, we conduct an\nempirical study on 11 representative LLMs to assess their ability to resist\nmalicious code generation. Our findings indicate that current LLMs have a\nlimited ability to resist malicious code generation with an average refusal\nrate of 40.36% in text-to-code scenario and 11.52% in code-to-code scenario.\nThe average refusal rate of all LLMs in RMCBench is only 28.71%; ChatGPT-4 has\na refusal rate of only 35.73%. We also analyze the factors that affect LLMs'\nability to resist malicious code generation and provide implications for\ndevelopers to enhance model robustness.",
      "tldr_zh": "该研究提出 RMCBench，这是一个包含 473 个提示的基准，用于评估 Large Language Models (LLMs) 抵抗恶意代码生成的 ability，以填补现有研究的空白。基准设计了两种场景：text-to-code（基于描述生成代码）和 code-to-code（翻译或完成现有恶意代码），并对 11 个代表性 LLMs 进行了实证评估。结果显示，LLMs 的平均拒绝率仅为 28.71%，其中 text-to-code 场景为 40.36%，code-to-code 场景为 11.52%，ChatGPT-4 的拒绝率也仅为 35.73%。论文分析了影响因素，并为提升模型的 robustness 提供了开发建议。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.7; D.2.5; K.6.5"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 6 figures, 5 tables, 39th IEEE/ACM International Conference\n  on Automated Software Engineering (ASE '24)",
      "pdf_url": "http://arxiv.org/pdf/2409.15154v1",
      "published_date": "2024-09-23 16:03:26 UTC",
      "updated_date": "2024-09-23 16:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:42:20.590879"
    },
    {
      "arxiv_id": "2409.15146v3",
      "title": "COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models",
      "title_zh": "COHERENT：异构多机器人系统的协作与大型语言模型",
      "authors": [
        "Kehui Liu",
        "Zixin Tang",
        "Dong Wang",
        "Zhigang Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "abstract": "Leveraging the powerful reasoning capabilities of large language models\n(LLMs), recent LLM-based robot task planning methods yield promising results.\nHowever, they mainly focus on single or multiple homogeneous robots on simple\ntasks. Practically, complex long-horizon tasks always require collaboration\namong multiple heterogeneous robots especially with more complex action spaces,\nwhich makes these tasks more challenging. To this end, we propose COHERENT, a\nnovel LLM-based task planning framework for collaboration of heterogeneous\nmulti-robot systems including quadrotors, robotic dogs, and robotic arms.\nSpecifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is\ndesigned to decompose and assign actions for individual robots, where a\ncentralized task assigner makes a task planning proposal to decompose the\ncomplex task into subtasks, and then assigns subtasks to robot executors. Each\nrobot executor selects a feasible action to implement the assigned subtask and\nreports self-reflection feedback to the task assigner for plan adjustment. The\nPEFA loops until the task is completed. Moreover, we create a challenging\nheterogeneous multi-robot task planning benchmark encompassing 100 complex\nlong-horizon tasks. The experimental results show that our work surpasses the\nprevious methods by a large margin in terms of success rate and execution\nefficiency. The experimental videos, code, and benchmark are released at\nhttps://github.com/MrKeee/COHERENT.",
      "tldr_zh": "该论文提出 COHERENT，一种基于 Large Language Models (LLMs) 的任务规划框架，用于异构多机器人系统（如四旋翼无人机、机器人狗和机械臂）的协作，针对复杂长时任务。框架引入 Proposal-Execution-Feedback-Adjustment (PEFA) 机制，由集中式任务分配器分解任务为子任务并分配给机器人执行器，每个执行器完成子任务后提供反馈以调整计划，直至任务完成。作者创建了一个包含 100 个挑战性长时任务的基准，实验结果显示 COHERENT 在成功率和执行效率上大幅优于现有方法，并开源了代码和基准。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15146v3",
      "published_date": "2024-09-23 15:53:41 UTC",
      "updated_date": "2025-03-29 14:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:42:31.425013"
    },
    {
      "arxiv_id": "2409.15130v1",
      "title": "CAMAL: Optimizing LSM-trees via Active Learning",
      "title_zh": "CAMAL：通过主动学习优化 LSM 树",
      "authors": [
        "Weiping Yu",
        "Siqiang Luo",
        "Zihao Yu",
        "Gao Cong"
      ],
      "abstract": "We use machine learning to optimize LSM-tree structure, aiming to reduce the\ncost of processing various read/write operations. We introduce a new approach\nCamal, which boasts the following features: (1) ML-Aided: Camal is the first\nattempt to apply active learning to tune LSM-tree based key-value stores. The\nlearning process is coupled with traditional cost models to improve the\ntraining process; (2) Decoupled Active Learning: backed by rigorous analysis,\nCamal adopts active learning paradigm based on a decoupled tuning of each\nparameter, which further accelerates the learning process; (3) Easy\nExtrapolation: Camal adopts an effective mechanism to incrementally update the\nmodel with the growth of the data size; (4) Dynamic Mode: Camal is able to tune\nLSM-tree online under dynamically changing workloads; (5) Significant System\nImprovement: By integrating Camal into a full system RocksDB, the system\nperformance improves by 28% on average and up to 8x compared to a\nstate-of-the-art RocksDB design.",
      "tldr_zh": "这篇论文提出 CAMAL 方法，通过主动学习（Active Learning）优化 LSM-trees 结构，以降低各种读写操作的成本。CAMAL 结合机器学习与传统成本模型，采用解耦参数调优（Decoupled Active Learning）、增量模型更新（Easy Extrapolation）和在线动态调优（Dynamic Mode）等机制，加速学习过程并适应变化的工作负载。实验结果显示，将 CAMAL 集成到 RocksDB 中后，系统性能平均提升 28%，最高可达 8 倍。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "SIGMOD 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15130v1",
      "published_date": "2024-09-23 15:35:23 UTC",
      "updated_date": "2024-09-23 15:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:42:42.544803"
    },
    {
      "arxiv_id": "2409.15127v3",
      "title": "Pareto-Optimized Open-Source LLMs for Healthcare via Context Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Jordi Bayarri-Planas",
        "Ashwin Kumar Gururajan",
        "Dario Garcia-Gasulla"
      ],
      "abstract": "This study leverages optimized context retrieval to enhance open-source Large\nLanguage Models (LLMs) for cost-effective, high performance healthcare AI. We\ndemonstrate that this approach achieves state-of-the-art accuracy on medical\nquestion answering at a fraction of the cost of proprietary models,\nsignificantly improving the cost-accuracy Pareto frontier on the MedQA\nbenchmark. Key contributions include: (1) OpenMedQA, a novel benchmark\nrevealing a performance gap in open-ended medical QA compared to\nmultiple-choice formats; (2) a practical, reproducible pipeline for context\nretrieval optimization; and (3) open-source resources (Prompt Engine,\nCoT/ToT/Thinking databases) to empower healthcare AI development. By advancing\nretrieval techniques and QA evaluation, we enable more affordable and reliable\nLLM solutions for healthcare.",
      "tldr_zh": "这项研究通过优化上下文检索技术，提升开源大语言模型（LLMs）在医疗领域的性能，实现高准确率和低成本表现。在MedQA基准上，该方法达到了最先进水平，比专有模型的成本低得多，并显著改善了成本-准确率Pareto前沿。关键贡献包括：引入OpenMedQA基准以揭示开源模型在开放式医疗问答中的性能差距、提供一个可复制的上下文检索优化管道，以及开源资源如Prompt Engine和CoT/ToT/Thinking数据库，从而推动更经济可靠的医疗AI发展。",
      "categories": [
        "cs.AI",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figures, 5 tables, Accepted for publication at the 21st\n  International Conference on Artificial Intelligence Applications and\n  Innovations (AIAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.15127v3",
      "published_date": "2024-09-23 15:33:38 UTC",
      "updated_date": "2025-04-03 09:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:42:55.341647"
    },
    {
      "arxiv_id": "2409.15119v2",
      "title": "Log-normal Mutations and their Use in Detecting Surreptitious Fake Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ismail Labiad",
        "Thomas Bäck",
        "Pierre Fernandez",
        "Laurent Najman",
        "Tom Sander",
        "Furong Ye",
        "Mariia Zameshina",
        "Olivier Teytaud"
      ],
      "abstract": "In many cases, adversarial attacks are based on specialized algorithms\nspecifically dedicated to attacking automatic image classifiers. These\nalgorithms perform well, thanks to an excellent ad hoc distribution of initial\nattacks. However, these attacks are easily detected due to their specific\ninitial distribution. We therefore consider other black-box attacks, inspired\nfrom generic black-box optimization tools, and in particular the log-normal\nalgorithm.\n  We apply the log-normal method to the attack of fake detectors, and get\nsuccessful attacks: importantly, these attacks are not detected by detectors\nspecialized on classical adversarial attacks. Then, combining these attacks and\ndeep detection, we create improved fake detectors.",
      "tldr_zh": "该论文探讨了对抗攻击(adversarial attacks)对图像分类器的威胁，这些攻击虽有效但易于通过特定初始分布被检测。作者引入log-normal算法作为一种黑盒攻击(black-box attacks)方法，成功攻击假图像检测器，且这些攻击不易被经典检测器识别。最终，通过结合log-normal攻击和深度检测(deep detection)，论文开发了改进的假图像检测器，提升了其鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "log-normal mutations and their use in detecting surreptitious fake\n  images",
      "pdf_url": "http://arxiv.org/pdf/2409.15119v2",
      "published_date": "2024-09-23 15:25:26 UTC",
      "updated_date": "2024-09-25 14:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:43:05.283784"
    },
    {
      "arxiv_id": "2409.15114v3",
      "title": "Evaluating ML Robustness in GNSS Interference Classification, Characterization & Localization",
      "title_zh": "在 GNSS 干扰分类、表征与定位中评估 ML 鲁棒性",
      "authors": [
        "Lucas Heublein",
        "Tobias Feigl",
        "Thorsten Nowak",
        "Alexander Rügamer",
        "Christopher Mutschler",
        "Felix Ott"
      ],
      "abstract": "Jamming devices disrupt signals from the global navigation satellite system\n(GNSS) and pose a significant threat, as they compromise the robustness of\naccurate positioning. The detection of anomalies within frequency snapshots is\ncrucial to counteract these interferences effectively. A critical preliminary\ncountermeasure involves the reliable classification of interferences and the\ncharacterization and localization of jamming devices. This paper introduces an\nextensive dataset comprising snapshots obtained from a low-frequency antenna\nthat capture various generated interferences within a large-scale environment,\nincluding controlled multipath effects. Our objective is to assess the\nresilience of machine learning (ML) models against environmental changes, such\nas multipath effects, variations in interference attributes, such as\ninterference class, bandwidth, and signal power, the accuracy of jamming device\nlocalization, and the constraints imposed by snapshot input lengths.\nFurthermore, we evaluate the performance of a diverse set of 129 distinct\nvision encoder models across all tasks. By analyzing the aleatoric and\nepistemic uncertainties, we demonstrate the adaptability of our model in\ngeneralizing across diverse facets, thus establishing its suitability for\nreal-world applications. Dataset:\nhttps://gitlab.cc-asp.fraunhofer.de/darcy_gnss/controlled_low_frequency",
      "tldr_zh": "本论文评估了机器学习（ML）模型在全球导航卫星系统（GNSS）干扰分类、特征化和定位方面的鲁棒性，针对干扰设备对定位准确性的威胁。研究引入了一个包含低频天线快照的大规模数据集，涵盖各种干扰类型、带宽、信号功率以及受控多径效应等环境变化。作者测试了129个视觉编码器模型的表现，并通过分析aleatoric and epistemic uncertainties，证明了模型在干扰属性变化、设备定位准确性和输入长度限制下的适应性和泛化能力，为实际应用中的GNSS干扰应对提供了可靠基础。",
      "categories": [
        "cs.AI",
        "94-05, 82-11",
        "E.0; I.2.0; I.5.4; I.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15114v3",
      "published_date": "2024-09-23 15:20:33 UTC",
      "updated_date": "2025-04-23 07:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:43:19.294707"
    },
    {
      "arxiv_id": "2409.15112v2",
      "title": "ChatGPT as a Solver and Grader of Programming Exams written in Spanish",
      "title_zh": "ChatGPT 作为西班牙语编写的编程考试的求解器和评分器",
      "authors": [
        "Pablo Saborido-Fernández",
        "Marcos Fernández-Pichel",
        "David E. Losada"
      ],
      "abstract": "Evaluating the capabilities of Large Language Models (LLMs) to assist\nteachers and students in educational tasks is receiving increasing attention.\nIn this paper, we assess ChatGPT's capacities to solve and grade real\nprogramming exams, from an accredited BSc degree in Computer Science, written\nin Spanish. Our findings suggest that this AI model is only effective for\nsolving simple coding tasks. Its proficiency in tackling complex problems or\nevaluating solutions authored by others are far from effective. As part of this\nresearch, we also release a new corpus of programming tasks and the\ncorresponding prompts for solving the problems or grading the solutions. This\nresource can be further exploited by other research teams.",
      "tldr_zh": "这篇论文评估了 ChatGPT 在解决和评分西班牙语编程考试中的能力，针对真实计算机科学学士学位 (BSc degree) 考试进行测试。研究发现，ChatGPT 仅在简单编码任务上表现出色，但在处理复杂问题或评估他人解决方案时效果有限。作者还发布了一个新的编程任务语料库及其对应提示，作为资源供其他研究团队进一步利用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15112v2",
      "published_date": "2024-09-23 15:20:07 UTC",
      "updated_date": "2025-03-20 12:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:43:29.473867"
    },
    {
      "arxiv_id": "2409.15107v2",
      "title": "The BRAVO Semantic Segmentation Challenge Results in UNCV2024",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan-Hung Vu",
        "Eduardo Valle",
        "Andrei Bursuc",
        "Tommie Kerssies",
        "Daan de Geus",
        "Gijs Dubbelman",
        "Long Qian",
        "Bingke Zhu",
        "Yingying Chen",
        "Ming Tang",
        "Jinqiao Wang",
        "Tomáš Vojíř",
        "Jan Šochman",
        "Jiří Matas",
        "Michael Smith",
        "Frank Ferrie",
        "Shamik Basu",
        "Christos Sakaridis",
        "Luc Van Gool"
      ],
      "abstract": "We propose the unified BRAVO challenge to benchmark the reliability of\nsemantic segmentation models under realistic perturbations and unknown\nout-of-distribution (OOD) scenarios. We define two categories of reliability:\n(1) semantic reliability, which reflects the model's accuracy and calibration\nwhen exposed to various perturbations; and (2) OOD reliability, which measures\nthe model's ability to detect object classes that are unknown during training.\nThe challenge attracted nearly 100 submissions from international teams\nrepresenting notable research institutions. The results reveal interesting\ninsights into the importance of large-scale pre-training and minimal\narchitectural design in developing robust and reliable semantic segmentation\nmodels.",
      "tldr_zh": "本文介绍了 BRAVO 语义分割挑战，这是 UNCV2024 中的一个基准测试，用于评估语义分割模型在现实扰动和未知分布外（OOD）场景下的可靠性。挑战定义了两种可靠性类别：语义可靠性（反映模型在各种扰动下的准确性和校准），以及 OOD 可靠性（测量模型检测训练中未知对象类别的能力）。该挑战吸引了近100个国际团队的提交，结果揭示了大规模预训练和最小架构设计在开发鲁棒可靠语义分割模型中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 proceeding paper of the BRAVO challenge 2024, see\n  https://benchmarks.elsa-ai.eu/?ch=1&com=introduction Corrected numbers in\n  Tables 1,3,4,5 and 10",
      "pdf_url": "http://arxiv.org/pdf/2409.15107v2",
      "published_date": "2024-09-23 15:17:30 UTC",
      "updated_date": "2024-10-09 15:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:43:46.050907"
    },
    {
      "arxiv_id": "2409.15105v1",
      "title": "SPformer: A Transformer Based DRL Decision Making Method for Connected Automated Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Han",
        "Lijun Zhang",
        "Dejian Meng",
        "Xingyu Hu",
        "Yixia Lu"
      ],
      "abstract": "In mixed autonomy traffic environment, every decision made by an\nautonomous-driving car may have a great impact on the transportation system.\nBecause of the complex interaction between vehicles, it is challenging to make\ndecisions that can ensure both high traffic efficiency and safety now and\nfuther. Connected automated vehicles (CAVs) have great potential to improve the\nquality of decision-making in this continuous, highly dynamic and interactive\nenvironment because of their stronger sensing and communicating ability. For\nmulti-vehicle collaborative decision-making algorithms based on deep\nreinforcement learning (DRL), we need to represent the interactions between\nvehicles to obtain interactive features. The representation in this aspect\ndirectly affects the learning efficiency and the quality of the learned policy.\nTo this end, we propose a CAV decision-making architecture based on transformer\nand reinforcement learning algorithms. A learnable policy token is used as the\nlearning medium of the multi-vehicle joint policy, the states of all vehicles\nin the area of interest can be adaptively noticed in order to extract\ninteractive features among agents. We also design an intuitive physical\npositional encodings, the redundant location information of which optimizes the\nperformance of the network. Simulations show that our model can make good use\nof all the state information of vehicles in traffic scenario, so as to obtain\nhigh-quality driving decisions that meet efficiency and safety objectives. The\ncomparison shows that our method significantly improves existing DRL-based\nmulti-vehicle cooperative decision-making algorithms.",
      "tldr_zh": "本研究针对混合自治交通环境中车辆互动的复杂性，提出了一种基于Transformer和深度强化学习(DRL)的决策方法，名为SPformer，用于Connected Automated Vehicles (CAVs)的多车辆协作决策。该方法引入可学习策略令牌(learnable policy token)作为多车辆联合策略的学习媒介，并使用自适应注意机制提取车辆间的互动特征，同时设计了直观的物理位置编码来优化网络性能。模拟实验结果显示，SPformer能有效利用交通场景中的所有车辆状态信息，生成高效且安全的驾驶决策，与现有DRL-based算法相比，显著提高了决策质量和整体性能。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15105v1",
      "published_date": "2024-09-23 15:16:35 UTC",
      "updated_date": "2024-09-23 15:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:43:53.998792"
    },
    {
      "arxiv_id": "2409.15100v5",
      "title": "Robust Federated Learning Over the Air: Combating Heavy-Tailed Noise with Median Anchored Clipping",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxing Li",
        "Zihan Chen",
        "Kai Fong Ernest Chong",
        "Bikramjit Das",
        "Tony Q. S. Quek",
        "Howard H. Yang"
      ],
      "abstract": "Leveraging over-the-air computations for model aggregation is an effective\napproach to cope with the communication bottleneck in federated edge learning.\nBy exploiting the superposition properties of multi-access channels, this\napproach facilitates an integrated design of communication and computation,\nthereby enhancing system privacy while reducing implementation costs. However,\nthe inherent electromagnetic interference in radio channels often exhibits\nheavy-tailed distributions, giving rise to exceptionally strong noise in\nglobally aggregated gradients that can significantly deteriorate the training\nperformance. To address this issue, we propose a novel gradient clipping\nmethod, termed Median Anchored Clipping (MAC), to combat the detrimental\neffects of heavy-tailed noise. We also derive analytical expressions for the\nconvergence rate of model training with analog over-the-air federated learning\nunder MAC, which quantitatively demonstrates the effect of MAC on training\nperformance. Extensive experimental results show that the proposed MAC\nalgorithm effectively mitigates the impact of heavy-tailed noise, hence\nsubstantially enhancing system robustness.",
      "tldr_zh": "本研究针对联邦边缘学习中的通信瓶颈，提出利用过无线传输（Over-the-Air）计算进行模型聚合，以整合通信和计算、提升隐私和降低成本。然而，无线通道的电磁干扰往往呈现重尾分布（Heavy-Tailed Noise），导致梯度聚合性能下降。为此，引入了一种新颖的梯度剪切方法Median Anchored Clipping (MAC)，有效对抗重尾噪声的影响。研究还推导了在MAC下的模拟Over-the-Air联邦学习模型训练收敛率表达式，并通过实验验证，该方法显著提高了系统的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the full version of the paper, and the appendix contains a\n  complete convergence analysis under non-convex conditions",
      "pdf_url": "http://arxiv.org/pdf/2409.15100v5",
      "published_date": "2024-09-23 15:11:40 UTC",
      "updated_date": "2025-03-19 18:17:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:44:07.944078"
    },
    {
      "arxiv_id": "2409.15097v2",
      "title": "Efficiently Dispatching Flash Attention For Partially Filled Attention Masks",
      "title_zh": "翻译失败",
      "authors": [
        "Agniv Sharma",
        "Jonas Geiping"
      ],
      "abstract": "Transformers are widely used across various applications, many of which yield\nsparse or partially filled attention matrices. Examples include attention masks\ndesigned to reduce the quadratic complexity of attention, sequence packing\ntechniques, and recent innovations like tree masking for fast validation in\nMEDUSA. Despite the inherent sparsity in these matrices, the state-of-the-art\nalgorithm Flash Attention still processes them with quadratic complexity as\nthough they were dense. In this paper, we introduce Binary Block Masking, a\nhighly efficient modification that enhances Flash Attention by making it\nmask-aware. We further propose two optimizations: one tailored for masks with\ncontiguous non-zero patterns and another for extremely sparse masks. Our\nexperiments on attention masks derived from real-world scenarios demonstrate up\nto a 9x runtime improvement. The implementation will be publicly released to\nfoster further research and application.",
      "tldr_zh": "本论文针对Transformer模型中稀疏或部分填充的注意矩阵问题，提出了一种高效的Binary Block Masking修改方案，以提升Flash Attention算法的性能，使其能够感知掩码并减少二次复杂度。研究进一步引入两个优化：一个针对连续非零模式的掩码，另一个针对极度稀疏的掩码。实验结果显示，在真实场景的注意矩阵上，该方法实现了高达9倍的运行时改进，并计划公开实现以促进进一步应用和发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15097v2",
      "published_date": "2024-09-23 15:11:07 UTC",
      "updated_date": "2024-09-24 12:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:44:19.172426"
    },
    {
      "arxiv_id": "2409.15095v2",
      "title": "Whole-Body Teleoperation for Mobile Manipulation at Zero Added Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Honerkamp",
        "Harsh Mahesheka",
        "Jan Ole von Hartz",
        "Tim Welschehold",
        "Abhinav Valada"
      ],
      "abstract": "Demonstration data plays a key role in learning complex behaviors and\ntraining robotic foundation models. While effective control interfaces exist\nfor static manipulators, data collection remains cumbersome and time intensive\nfor mobile manipulators due to their large number of degrees of freedom. While\nspecialized hardware, avatars, or motion tracking can enable whole-body\ncontrol, these approaches are either expensive, robot-specific, or suffer from\nthe embodiment mismatch between robot and human demonstrator. In this work, we\npresent MoMa-Teleop, a novel teleoperation method that infers end-effector\nmotions from existing interfaces and delegates the base motions to a previously\ndeveloped reinforcement learning agent, leaving the operator to focus fully on\nthe task-relevant end-effector motions. This enables whole-body teleoperation\nof mobile manipulators with no additional hardware or setup costs via standard\ninterfaces such as joysticks or hand guidance. Moreover, the operator is not\nbound to a tracked workspace and can move freely with the robot over spatially\nextended tasks. We demonstrate that our approach results in a significant\nreduction in task completion time across a variety of robots and tasks. As the\ngenerated data covers diverse whole-body motions without embodiment mismatch,\nit enables efficient imitation learning. By focusing on task-specific\nend-effector motions, our approach learns skills that transfer to unseen\nsettings, such as new obstacles or changed object positions, from as little as\nfive demonstrations. We make code and videos available at\nhttps://moma-teleop.cs.uni-freiburg.de.",
      "tldr_zh": "该论文提出 MoMa-Teleop，一种零额外成本的全身遥操作方法，用于移动机械臂操作，解决了传统数据收集的复杂性和体型不匹配问题。该方法通过现有接口（如操纵杆或手引导）推断末端执行器动作，并将底座动作委托给预训练的强化学习代理，让操作者专注于任务相关部分。实验结果显示，该方法显著缩短任务完成时间，支持高效模仿学习，从仅5个演示中学习可转移技能，如适应新障碍或对象位置。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Website: https://moma-teleop.cs.uni-freiburg.de",
      "pdf_url": "http://arxiv.org/pdf/2409.15095v2",
      "published_date": "2024-09-23 15:09:45 UTC",
      "updated_date": "2025-02-10 10:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:44:31.254135"
    },
    {
      "arxiv_id": "2409.15092v4",
      "title": "M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images",
      "title_zh": "M2OST：用于从数字病理图像预测空间转录组学的多对一回归",
      "authors": [
        "Hongyi Wang",
        "Xiuju Du",
        "Jing Liu",
        "Shuyi Ouyang",
        "Yen-Wei Chen",
        "Lanfen Lin"
      ],
      "abstract": "The advancement of Spatial Transcriptomics (ST) has facilitated the\nspatially-aware profiling of gene expressions based on histopathology images.\nAlthough ST data offers valuable insights into the micro-environment of tumors,\nits acquisition cost remains expensive. Therefore, directly predicting the ST\nexpressions from digital pathology images is desired. Current methods usually\nadopt existing regression backbones along with patch-sampling for this task,\nwhich ignores the inherent multi-scale information embedded in the pyramidal\ndata structure of digital pathology images, and wastes the inter-spot visual\ninformation crucial for accurate gene expression prediction. To address these\nlimitations, we propose M2OST, a many-to-one regression Transformer that can\naccommodate the hierarchical structure of the pathology images via a decoupled\nmulti-scale feature extractor. Unlike traditional models that are trained with\none-to-one image-label pairs, M2OST uses multiple images from different levels\nof the digital pathology image to jointly predict the gene expressions in their\ncommon corresponding spot. Built upon our many-to-one scheme, M2OST can be\neasily scaled to fit different numbers of inputs, and its network structure\ninherently incorporates nearby inter-spot features, enhancing regression\nperformance. We have tested M2OST on three public ST datasets and the\nexperimental results show that M2OST can achieve state-of-the-art performance\nwith fewer parameters and floating-point operations (FLOPs).",
      "tldr_zh": "这篇论文提出 M2OST，一种 many-to-one 回归 Transformer，用于从数字病理图像预测 Spatial Transcriptomics (ST) 表达，以解决现有方法忽略图像多尺度信息和点间视觉细节的问题。M2OST 采用解耦的多尺度特征提取器和多图像联合预测方案，能够整合不同级别图像的层次结构，并增强回归性能。实验结果显示，该模型在三个公共 ST 数据集上达到了最先进性能，同时参数和 FLOPs 更少，为高效的基因表达预测提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Improved from our previous unpublished work arXiv:2401.10608. arXiv\n  admin note: substantial text overlap with arXiv:2401.10608",
      "pdf_url": "http://arxiv.org/pdf/2409.15092v4",
      "published_date": "2024-09-23 15:06:37 UTC",
      "updated_date": "2024-12-20 06:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:44:44.241146"
    },
    {
      "arxiv_id": "2409.15076v1",
      "title": "Enhancing Scientific Reproducibility Through Automated BioCompute Object Creation Using Retrieval-Augmented Generation from Publications",
      "title_zh": "通过从出版物中利用检索增强生成自动创建 BioCompute Object 来提升科学可重复性",
      "authors": [
        "Sean Kim",
        "Raja Mazumder"
      ],
      "abstract": "The exponential growth in computational power and accessibility has\ntransformed the complexity and scale of bioinformatics research, necessitating\nstandardized documentation for transparency, reproducibility, and regulatory\ncompliance. The IEEE BioCompute Object (BCO) standard addresses this need but\nfaces adoption challenges due to the overhead of creating compliant\ndocumentation, especially for legacy research. This paper presents a novel\napproach to automate the creation of BCOs from scientific papers using\nRetrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We\ndescribe the development of the BCO assistant tool that leverages RAG to\nextract relevant information from source papers and associated code\nrepositories, addressing key challenges such as LLM hallucination and\nlong-context understanding. The implementation incorporates optimized retrieval\nprocesses, including a two-pass retrieval with re-ranking, and employs\ncarefully engineered prompts for each BCO domain. We discuss the tool's\narchitecture, extensibility, and evaluation methods, including automated and\nmanual assessment approaches. The BCO assistant demonstrates the potential to\nsignificantly reduce the time and effort required for retroactive documentation\nof bioinformatics research while maintaining compliance with the standard. This\napproach opens avenues for AI-assisted scientific documentation and knowledge\nextraction from publications thereby enhancing scientific reproducibility. The\nBCO assistant tool and documentation is available at\nhttps://biocompute-objects.github.io/bco-rag/.",
      "tldr_zh": "这篇论文提出了一种利用 Retrieval-Augmented Generation (RAG) 和 Large Language Models (LLMs) 从科学论文自动生成 BioCompute Object (BCO) 的方法，以提升生物信息学研究的透明性、可重复性和合规性。研究开发了 BCO assistant 工具，通过两轮检索和重新排序机制从论文及代码仓库提取关键信息，并设计针对性提示来解决 LLM hallucination 和长上下文理解等挑战。实验结果表明，该工具显著减少了回顾性文档化的时间和努力，同时确保合规性，为 AI 辅助的科学文档化和知识提取提供了新途径。工具及其文档可在 https://biocompute-objects.github.io/bco-rag/ 获得。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.OT"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15076v1",
      "published_date": "2024-09-23 14:51:22 UTC",
      "updated_date": "2024-09-23 14:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:44:56.086905"
    },
    {
      "arxiv_id": "2409.15052v1",
      "title": "Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual Conversations for Cross-Lingual Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Betala",
        "Ishan Chokshi"
      ],
      "abstract": "In this paper, we describe our system under the team name Brotherhood for the\nEnglish-to-Lowres Multi-Modal Translation Task. We participate in the\nmulti-modal translation tasks for English-Hindi, English-Hausa,\nEnglish-Bengali, and English-Malayalam language pairs. We present a method\nleveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and\nClaude 3.5 Sonnet, to enhance cross-lingual image captioning without\ntraditional training or fine-tuning. Our approach utilizes instruction-tuned\nprompting to generate rich, contextual conversations about cropped images,\nusing their English captions as additional context. These synthetic\nconversations are then translated into the target languages. Finally, we employ\na weighted prompting strategy, balancing the original English caption with the\ntranslated conversation to generate captions in the target language. This\nmethod achieved competitive results, scoring 37.90 BLEU on the English-Hindi\nChallenge Set and ranking first and second for English-Hausa on the Challenge\nand Evaluation Leaderboards, respectively. We conduct additional experiments on\na subset of 250 images, exploring the trade-offs between BLEU scores and\nsemantic similarity across various weighting schemes.",
      "tldr_zh": "这篇论文介绍了Brotherhood团队在WMT 2024英语到低资源语言多模态翻译任务中的方法，使用多模态LLM（如GPT-4o和Claude 3.5 Sonnet）生成上下文对话来提升跨语言图像描述，而无需传统训练或微调。方法涉及通过指令调整的提示创建合成对话、将其翻译到目标语言（如印地语、豪萨语、孟加拉语和马拉雅拉姆语），并采用加权提示策略平衡原始英语标题和翻译对话以生成目标语言标题。实验结果显示，该方法在英语-印地语挑战集上取得37.90 BLEU分数，并在英语-豪萨语上排名第一和第二；此外，通过对250张图像的子集实验，探讨了不同加权方案在BLEU分数和语义相似性之间的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the Ninth Conference on Machine Translation (WMT24),\n  co-located with EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15052v1",
      "published_date": "2024-09-23 14:29:46 UTC",
      "updated_date": "2024-09-23 14:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:45:09.296753"
    },
    {
      "arxiv_id": "2409.15051v1",
      "title": "Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task",
      "title_zh": "仅解码器模型在多语言机器翻译任务上的缩放定律",
      "authors": [
        "Gaëtan Caillaut",
        "Raheel Qader",
        "Mariam Nakhlé",
        "Jingshu Liu",
        "Jean-Gabriel Barthélemy"
      ],
      "abstract": "Recent studies have showcased remarkable capabilities of decoder-only models\nin many NLP tasks, including translation. Yet, the machine translation field\nhas been largely dominated by encoder-decoder models based on the Transformer\narchitecture. As a consequence, scaling laws of encoder-decoder models for\nneural machine translation have already been well studied, but decoder-only\nmodels have received less attention. This work explores the scaling laws of\ndecoder-only models on the multilingual and multidomain translation task. We\ntrained a collection of six decoder-only models, ranging from 70M to 7B\nparameters, on a sentence-level, multilingual and multidomain dataset. We\nconducted a series of experiments showing that the loss of decoder-only models\ncan be estimated using a scaling law similar to the one discovered for large\nlanguage models, but we also show that this scaling law has difficulties to\ngeneralize to too large models or to a different data distribution. We also\nstudy different scaling methods and show that scaling the depth and the width\nof a model lead to similar test loss improvements, but with different impact on\nthe model's efficiency.",
      "tldr_zh": "本文探讨了decoder-only models在多语言机器翻译任务上的scaling laws，通过训练从70M到7B参数的六种模型，基于一个句子级、多语言和多领域数据集进行实验。研究发现，decoder-only models的损失可以用类似于大型语言模型的scaling law来估计，但此规律在应用于过大模型或不同数据分布时难以泛化。此外，扩展模型深度和宽度可带来相似的测试损失改善，但对模型效率的影响各不相同。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15051v1",
      "published_date": "2024-09-23 14:26:01 UTC",
      "updated_date": "2024-09-23 14:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:45:19.308124"
    },
    {
      "arxiv_id": "2409.15046v1",
      "title": "AlphaZip: Neural Network-Enhanced Lossless Text Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Swathi Shree Narashiman",
        "Nitin Chandrachoodan"
      ],
      "abstract": "Data compression continues to evolve, with traditional information theory\nmethods being widely used for compressing text, images, and videos. Recently,\nthere has been growing interest in leveraging Generative AI for predictive\ncompression techniques. This paper introduces a lossless text compression\napproach using a Large Language Model (LLM). The method involves two key steps:\nfirst, prediction using a dense neural network architecture, such as a\ntransformer block; second, compressing the predicted ranks with standard\ncompression algorithms like Adaptive Huffman, LZ77, or Gzip. Extensive analysis\nand benchmarking against conventional information-theoretic baselines\ndemonstrate that neural compression offers improved performance.",
      "tldr_zh": "该论文介绍了 AlphaZip，一种基于神经网络的无损文本压缩方法，利用 Large Language Model (LLM) 提升压缩效率。方法包括两个关键步骤：首先，使用密集神经网络架构（如 transformer block）进行预测；其次，将预测的 ranks 应用标准压缩算法（如 Adaptive Huffman、LZ77 或 Gzip）进行编码。与传统信息理论方法相比，实验基准测试显示 AlphaZip 提供了更好的压缩性能。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15046v1",
      "published_date": "2024-09-23 14:21:06 UTC",
      "updated_date": "2024-09-23 14:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:45:29.538023"
    },
    {
      "arxiv_id": "2409.15028v1",
      "title": "Region Mixup",
      "title_zh": "翻译失败",
      "authors": [
        "Saptarshi Saha",
        "Utpal Garain"
      ],
      "abstract": "This paper introduces a simple extension of mixup (Zhang et al., 2018) data\naugmentation to enhance generalization in visual recognition tasks. Unlike the\nvanilla mixup method, which blends entire images, our approach focuses on\ncombining regions from multiple images.",
      "tldr_zh": "本论文提出了一种名为Region Mixup的简单扩展，基于原mixup（Zhang et al., 2018）的数据augmentation方法，用于提升视觉识别任务的泛化能力。与传统mixup不同，该方法专注于结合多个图像的特定区域，而不是混合整个图像。通过这种区域级别的混合策略，论文旨在帮助模型更好地处理复杂视觉场景。实验结果表明，此方法能有效改善模型的泛化性能，尽管具体数据未在摘要中详述。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a Tiny Paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15028v1",
      "published_date": "2024-09-23 13:55:16 UTC",
      "updated_date": "2024-09-23 13:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:45:41.979968"
    },
    {
      "arxiv_id": "2409.15027v1",
      "title": "Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19",
      "title_zh": "生成式 LLM 驱动的对话式 AI 应用，用于个性化风险评估：COVID-19 的一个案例研究",
      "authors": [
        "Mohammad Amin Roshani",
        "Xiangyu Zhou",
        "Yao Qiang",
        "Srinivasan Suresh",
        "Steve Hicks",
        "Usha Sethuraman",
        "Dongxiao Zhu"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language tasks and are increasingly being applied in healthcare\ndomains. This work demonstrates a new LLM-powered disease risk assessment\napproach via streaming human-AI conversation, eliminating the need for\nprogramming required by traditional machine learning approaches. In a COVID-19\nseverity risk assessment case study, we fine-tune pre-trained generative LLMs\n(e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language\nexamples, comparing their performance with traditional classifiers (i.e.,\nLogistic Regression, XGBoost, Random Forest) that are trained de novo using\ntabular data across various experimental settings. We develop a mobile\napplication that uses these fine-tuned LLMs as its generative AI (GenAI) core\nto facilitate real-time interaction between clinicians and patients, providing\nno-code risk assessment through conversational interfaces. This integration not\nonly allows for the use of streaming Questions and Answers (QA) as inputs but\nalso offers personalized feature importance analysis derived from the LLM's\nattention layers, enhancing the interpretability of risk assessments. By\nachieving high Area Under the Curve (AUC) scores with a limited number of\nfine-tuning samples, our results demonstrate the potential of generative LLMs\nto outperform discriminative classification methods in low-data regimes,\nhighlighting their real-world adaptability and effectiveness. This work aims to\nfill the existing gap in leveraging generative LLMs for interactive no-code\nrisk assessment and to encourage further research in this emerging field.",
      "tldr_zh": "该研究提出了一种基于生成式LLM（如Llama2-7b和Flan-t5-xl）的对话式AI应用，用于个性化COVID-19风险评估，通过流式人类-AI互动实现无代码评估。研究者通过少量自然语言示例微调这些LLM，并与传统分类器（如Logistic Regression、XGBoost和Random Forest）进行比较，开发了一个移动应用，支持实时问题回答和基于LLM注意力层的特征重要性分析。实验结果显示，在低数据环境下，微调后的LLM模型取得了较高的AUC分数，超过了传统方法，突显了其在真实世界风险评估中的适应性和潜力，并鼓励进一步探索此领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15027v1",
      "published_date": "2024-09-23 13:55:13 UTC",
      "updated_date": "2024-09-23 13:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:05.794916"
    },
    {
      "arxiv_id": "2409.15022v1",
      "title": "A Diagonal Structured State Space Model on Loihi 2 for Efficient Streaming Sequence Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Svea Marie Meyer",
        "Philipp Weidel",
        "Philipp Plank",
        "Leobardo Campos-Macias",
        "Sumit Bam Shrestha",
        "Philipp Stratmann",
        "Mathis Richter"
      ],
      "abstract": "Deep State-Space Models (SSM) demonstrate state-of-the art performance on\nlong-range sequence modeling tasks. While the recurrent structure of SSMs can\nbe efficiently implemented as a convolution or as a parallel scan during\ntraining, recurrent token-by-token processing cannot currently be implemented\nefficiently on GPUs. Here, we demonstrate efficient token-by-token inference of\nthe SSM S4D on Intel's Loihi 2 state-of-the-art neuromorphic processor. We\ncompare this first ever neuromorphic-hardware implementation of an SSM on\nsMNIST, psMNIST, and sCIFAR to a recurrent and a convolutional implementation\nof S4D on Jetson Orin Nano (Jetson). While we find Jetson to perform better in\nan offline sample-by-sample based batched processing mode, Loihi 2 outperforms\nduring token-by-token based processing, where it consumes 1000 times less\nenergy with a 75 times lower latency and a 75 times higher throughput compared\nto the recurrent implementation of S4D on Jetson. This opens up new avenues\ntowards efficient real-time streaming applications of SSMs.",
      "tldr_zh": "本研究在 Intel 的 Loihi 2 神经形态处理器上实现了 S4D 模型，这是一种基于对角结构的状态空间模型 (SSMs)，旨在实现高效的流式序列处理。论文比较了 S4D 在 Loihi 2 和 Jetson Orin Nano 上的性能，包括 token-by-token 推理与批处理模式。结果显示，Loihi 2 在 token-by-token 处理中表现出色，能量消耗比 Jetson 的循环实现低 1000 倍，延迟和吞吐量均高出 75 倍。总体而言，此实现为 SSMs 的实时流式应用开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15022v1",
      "published_date": "2024-09-23 13:50:11 UTC",
      "updated_date": "2024-09-23 13:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:05.865666"
    },
    {
      "arxiv_id": "2409.15014v2",
      "title": "Acting for the Right Reasons: Creating Reason-Sensitive Artificial Moral Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Baum",
        "Lisa Dargasz",
        "Felix Jahn",
        "Timo P. Gros",
        "Verena Wolf"
      ],
      "abstract": "We propose an extension of the reinforcement learning architecture that\nenables moral decision-making of reinforcement learning agents based on\nnormative reasons. Central to this approach is a reason-based shield generator\nyielding a moral shield that binds the agent to actions that conform with\nrecognized normative reasons so that our overall architecture restricts the\nagent to actions that are (internally) morally justified. In addition, we\ndescribe an algorithm that allows to iteratively improve the reason-based\nshield generator through case-based feedback from a moral judge.",
      "tldr_zh": "本论文提出了一种强化学习（Reinforcement Learning）的扩展架构，使代理能够基于规范性原因（Normative Reasons）进行道德决策，从而创建对理由敏感的人工道德代理。\n核心组件是reason-based shield generator，它生成moral shield来限制代理仅采取内部道德上合理的行动。\n此外，论文描述了一个算法，通过来自moral judge的案例反馈来迭代改进该shield generator，确保代理决策的持续优化。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, Workshop paper accepted to FEAR24 (IFM Workshop)",
      "pdf_url": "http://arxiv.org/pdf/2409.15014v2",
      "published_date": "2024-09-23 13:38:57 UTC",
      "updated_date": "2024-10-25 12:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:17.512865"
    },
    {
      "arxiv_id": "2409.15013v1",
      "title": "Analogous Alignments: Digital \"Formally\" meets Analog",
      "title_zh": "翻译失败",
      "authors": [
        "Hansa Mohanty",
        "Deepak Narayan Gadde"
      ],
      "abstract": "The complexity of modern-day System-on-Chips (SoCs) is continually\nincreasing, and it becomes increasingly challenging to deliver dependable and\ncredible chips in a short time-to-market. Especially, in the case of test\nchips, where the aim is to study the feasibility of the design, time is a\ncrucial factor. Pre-silicon functional verification is one of the main\ncontributors that makes up a large portion of the product development cycle.\nVerification engineers often loosely verify test chips that turn out to be\nnon-functional on the silicon, ultimately resulting in expensive re-spins. To\nleft-shift the verification efforts, formal verification is a powerful\nmethodology that aims to exhaustively verify designs, giving better confidence\nin the overall quality. This paper focuses on the pragmatic formal verification\nof a mixed signal Intellectual Property (IP) that has a combination of digital\nand analog blocks. This paper discusses a novel approach of including the\nanalog behavioral model into the formal verification setup. Digital and Analog\nMixed-Signal (AMS) designs, which are fundamentally different in nature, are\nintegrated seamlessly in a formal verification setup, a concept that can be\nreferred to as \"Analogous Alignments\". Our formal setup leverages powerful\nformal techniques such as FPV, CSR verification, and connectivity checks. The\nproperties used for FPV are auto-generated using a metamodeling framework. The\npaper also discusses the challenges faced especially related to state-space\nexplosion, non-compatibility of formal with AMS models, and techniques to\nmitigate them such as k-induction. With this verification approach, we were\nable to exhaustively verify the design within a reasonable time and with\nsufficient coverage. We also reported several bugs at an early stage, making\nthe complete design verification process iterative and effective.",
      "tldr_zh": "本论文探讨了现代System-on-Chips (SoCs)设计中测试芯片验证的挑战，提出了一种名为“Analogous Alignments”的创新方法，将数字和模拟混合信号(Analog Mixed-Signal, AMS)设计无缝整合到formal verification框架中。该方法通过将模拟行为模型纳入formal setup，并利用FPV、CSR verification和连接性检查等技术自动生成验证属性，有效应对状态空间爆炸和模型非兼容性问题，如采用k-induction缓解。实验结果显示，该方法实现了彻底设计验证、提升覆盖率，并在早期阶段发现多个错误，从而缩短产品开发周期并提高可靠性。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at the Design and Verification Conference\n  and Exhibition (DVCon) Europe, Munich, Germany, 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15013v1",
      "published_date": "2024-09-23 13:38:31 UTC",
      "updated_date": "2024-09-23 13:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:29.756844"
    },
    {
      "arxiv_id": "2409.15012v1",
      "title": "Inference-Friendly Models With MixAttention",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Rajput",
        "Ying Sheng",
        "Sean Owen",
        "Vitaliy Chiley"
      ],
      "abstract": "The size of the key-value (KV) cache plays a critical role in determining\nboth the maximum context length and the number of concurrent requests supported\nduring inference in modern language models. The KV cache size grows\nproportionally with the number of attention heads and the tokens processed,\nleading to increased memory consumption and slower inference for long inputs.\nIn this work, we explore the use of MixAttention, a model architecture\nmodification closely related to a blog published by Character.AI. MixAttention\ncombines sliding window attention, where only a small subset of recent tokens\nis stored in the KV cache, with KV cache sharing across layers. Our experiments\ndemonstrate that MixAttention significantly reduces memory usage and improves\ninference speed without sacrificing model performance in both short and\nlong-context tasks. We also explore various configurations of this\narchitecture, identifying those that maintain quality across evaluation metrics\nwhile optimizing resource efficiency.",
      "tldr_zh": "该论文探讨了语言模型中 KV cache 的大小导致的内存消耗增加和推理速度变慢问题，提出 MixAttention 架构作为优化方案。MixAttention 结合 sliding window attention（仅存储最近 token 子集）和 KV cache sharing across layers，有效减少缓存需求。实验结果表明，该方法在短和长上下文任务中显著降低内存使用并提升推理速度，同时保持模型性能，并在各种配置中优化了资源效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15012v1",
      "published_date": "2024-09-23 13:37:25 UTC",
      "updated_date": "2024-09-23 13:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:42.369095"
    },
    {
      "arxiv_id": "2409.15006v1",
      "title": "Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network",
      "title_zh": "翻译失败",
      "authors": [
        "Sijia Du",
        "Chengfeng Zhou",
        "Suncheng Xiang",
        "Jianwei Xu",
        "Dahong Qian"
      ],
      "abstract": "Objective: Depth estimation is crucial for endoscopic navigation and\nmanipulation, but obtaining ground-truth depth maps in real clinical scenarios,\nsuch as the colon, is challenging. This study aims to develop a robust\nframework that generalizes well to real colonoscopy images, overcoming\nchallenges like non-Lambertian surface reflection and diverse data\ndistributions. Methods: We propose a framework combining a convolutional neural\nnetwork (CNN) for capturing local features and a Transformer for capturing\nglobal information. An uncertainty-based fusion block was designed to enhance\ngeneralization by identifying complementary contributions from the CNN and\nTransformer branches. The network can be trained with simulated datasets and\ngeneralize directly to unseen clinical data without any fine-tuning. Results:\nOur method is validated on multiple datasets and demonstrates an excellent\ngeneralization ability across various datasets and anatomical structures.\nFurthermore, qualitative analysis in real clinical scenarios confirmed the\nrobustness of the proposed method. Conclusion: The integration of local and\nglobal features through the CNN-Transformer architecture, along with the\nuncertainty-based fusion block, improves depth estimation performance and\ngeneralization in both simulated and real-world endoscopic environments.\nSignificance: This study offers a novel approach to estimate depth maps for\nendoscopy images despite the complex conditions in clinic, serving as a\nfoundation for endoscopic automatic navigation and other clinical tasks, such\nas polyp detection and segmentation.",
      "tldr_zh": "该研究针对结肠镜图像的深度估计问题，提出了一种基于不确定性（uncertainty-based）的全局和局部融合网络框架，以提升模型在真实临床场景中的泛化能力，克服非朗伯表面反射（non-Lambertian surface reflection）和数据分布多样性等挑战。方法结合卷积神经网络（CNN）捕捉局部特征、Transformer捕捉全局信息，并通过不确定性融合块（uncertainty-based fusion block）整合两者的互补优势，使网络仅使用模拟数据集训练即可直接泛化到未见临床数据，无需微调。实验结果显示，该框架在多个数据集上表现出色的泛化能力，并在真实临床场景中通过定性分析验证了其鲁棒性。总体而言，此方法提高了内窥镜图像深度估计的性能，为内窥镜自动导航（endoscopic automatic navigation）以及临床任务如息肉检测和分割奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15006v1",
      "published_date": "2024-09-23 13:30:59 UTC",
      "updated_date": "2024-09-23 13:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:46:55.785150"
    },
    {
      "arxiv_id": "2409.15005v2",
      "title": "Method of Equal Shares with Bounded Overspending",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Papasotiropoulos",
        "Seyedeh Zeinab Pishbin",
        "Oskar Skibski",
        "Piotr Skowron",
        "Tomasz Wąs"
      ],
      "abstract": "In participatory budgeting (PB), voters decide through voting which subset of\nprojects to fund within a given budget. Proportionality in the context of PB is\ncrucial to ensure equal treatment of all groups of voters. However, pure\nproportional rules can sometimes lead to suboptimal outcomes. We introduce the\nMethod of Equal Shares with Bounded Overspending (BOS Equal Shares), a robust\nvariant of Equal Shares that balances proportionality and efficiency. BOS Equal\nShares addresses inefficiencies implied by strict proportionality axioms, yet\nthe rule still provides fairness guarantees, similar to the original Method of\nEqual Shares. Our extensive empirical analysis on real-world PB instances shows\nexcellent performance of BOS Equal Shares across several metrics. In the course\nof the analysis, we also present and examine a fractional variant of the Method\nof Equal Shares which allows for partial funding of projects.",
      "tldr_zh": "本研究针对参与式预算（Participatory Budgeting, PB），引入了 Method of Equal Shares with Bounded Overspending (BOS Equal Shares)，这是一个 Equal Shares 的稳健变体，旨在平衡比例性（Proportionality）和效率，避免严格比例规则导致的次优结果。BOS Equal Shares 保留了原方法的公平保证，同时通过限制超支来提升整体表现。实证分析显示，该方法在真实 PB 实例上表现出色，在多个指标上优于基线。论文还探讨了 Equal Shares 的分数变体，允许部分资助项目，以进一步扩展其适用性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15005v2",
      "published_date": "2024-09-23 13:30:25 UTC",
      "updated_date": "2025-02-24 19:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:47:07.152573"
    },
    {
      "arxiv_id": "2409.15004v1",
      "title": "ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from Unstructured Financial Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Furkan Pala",
        "Mehmet Yasin Akpınar",
        "Onur Deniz",
        "Gülşen Eryiğit"
      ],
      "abstract": "Multimodal key information extraction (KIE) models have been studied\nextensively on semi-structured documents. However, their investigation on\nunstructured documents is an emerging research topic. The paper presents an\napproach to adapt a multimodal transformer (i.e., ViBERTgrid previously\nexplored on semi-structured documents) for unstructured financial documents, by\nincorporating a BiLSTM-CRF layer. The proposed ViBERTgrid BiLSTM-CRF model\ndemonstrates a significant improvement in performance (up to 2 percentage\npoints) on named entity recognition from unstructured documents in financial\ndomain, while maintaining its KIE performance on semi-structured documents. As\nan additional contribution, we publicly released token-level annotations for\nthe SROIE dataset in order to pave the way for its use in multimodal sequence\nlabeling models.",
      "tldr_zh": "该论文提出了一种名为 ViBERTgrid BiLSTM-CRF 的模型，用于从非结构化金融文档中进行 Multimodal Key Information Extraction (KIE)，通过在原有 ViBERTgrid 基础上添加 BiLSTM-CRF 层来适应这一场景。实验结果显示，该模型在非结构化文档的 Named Entity Recognition (NER) 任务上性能提升了最多 2 百分点，同时保持了对半结构化文档的 KIE 性能。作者还公开了 SROIE 数据集的 token-level 注解，以促进多模态序列标记模型的应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in MIDAS (The 8th Workshop on MIning DAta for financial\n  applicationS) workshop of ECML PKDD 2023 conference",
      "pdf_url": "http://arxiv.org/pdf/2409.15004v1",
      "published_date": "2024-09-23 13:28:06 UTC",
      "updated_date": "2024-09-23 13:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:47:18.867762"
    },
    {
      "arxiv_id": "2409.14993v1",
      "title": "Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Chen",
        "Xin Wang",
        "Yuwei Zhou",
        "Bin Huang",
        "Yipeng Zhang",
        "Wei Feng",
        "Houlun Chen",
        "Zeyang Zhang",
        "Siao Tang",
        "Wenwu Zhu"
      ],
      "abstract": "Multi-modal generative AI has received increasing attention in both academia\nand industry. Particularly, two dominant families of techniques are: i) The\nmulti-modal large language model (MLLM) such as GPT-4V, which shows impressive\nability for multi-modal understanding; ii) The diffusion model such as Sora,\nwhich exhibits remarkable multi-modal powers, especially with respect to visual\ngeneration. As such, one natural question arises: Is it possible to have a\nunified model for both understanding and generation? To answer this question,\nin this paper, we first provide a detailed review of both MLLM and diffusion\nmodels, including their probabilistic modeling procedure, multi-modal\narchitecture design, and advanced applications to image/video large language\nmodels as well as text-to-image/video generation. Then, we discuss the two\nimportant questions on the unified model: i) whether the unified model should\nadopt the auto-regressive or diffusion probabilistic modeling, and ii) whether\nthe model should utilize a dense architecture or the Mixture of Experts(MoE)\narchitectures to better support generation and understanding, two objectives.\nWe further provide several possible strategies for building a unified model and\nanalyze their potential advantages and disadvantages. We also summarize\nexisting large-scale multi-modal datasets for better model pretraining in the\nfuture. To conclude the paper, we present several challenging future\ndirections, which we believe can contribute to the ongoing advancement of\nmulti-modal generative AI.",
      "tldr_zh": "本论文审视了多模态生成 AI 的发展，重点回顾了 Multi-modal LLM（如 GPT-4V）在多模态理解方面的能力，以及 Diffusion Model（如 Sora）在视觉生成上的优势。论文探讨了构建统一模型的可能性，包括采用自回归建模还是扩散建模，以及使用密集架构还是 Mixture of Experts (MoE) 架构来平衡理解和生成任务，并分析了多种策略的优缺点。作者还总结了现有的大规模多模态数据集，并提出未来挑战，如模型预训练和创新方向，以推动多模态生成 AI 的进步。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14993v1",
      "published_date": "2024-09-23 13:16:09 UTC",
      "updated_date": "2024-09-23 13:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:47:30.728920"
    },
    {
      "arxiv_id": "2409.14986v1",
      "title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others in Conversation Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Sicilia",
        "Malihe Alikhani"
      ],
      "abstract": "Typically, when evaluating Theory of Mind, we consider the beliefs of others\nto be binary: held or not held. But what if someone is unsure about their own\nbeliefs? How can we quantify this uncertainty? We propose a new suite of tasks,\nchallenging language models (LMs) to model the uncertainty of others in\ndialogue. We design these tasks around conversation forecasting, wherein an\nagent forecasts an unobserved outcome to a conversation. Uniquely, we view\ninterlocutors themselves as forecasters, asking an LM to predict the\nuncertainty of the interlocutors (a probability). We experiment with re-scaling\nmethods, variance reduction strategies, and demographic context, for this\nregression task, conducting experiments on three dialogue corpora (social,\nnegotiation, task-oriented) with eight LMs. While LMs can explain up to 7%\nvariance in the uncertainty of others, we highlight the difficulty of the tasks\nand room for future work, especially in practical applications, like\nanticipating ``false",
      "tldr_zh": "这篇论文扩展了 Theory of Mind 的评估框架，聚焦于预测他人信念的不确定性，而不是传统的二元持有或不持有模式。研究者提出一套新任务，挑战语言模型 (LMs) 在对话预测 (conversation forecasting) 中量化对话参与者的不确定性概率。方法包括采用 re-scaling 方法、variance reduction 策略和 demographic context，在社交、谈判和任务导向的三个对话语料上测试八个 LMs。结果显示，LMs 能解释高达 7% 的他人不确定性方差，但任务难度较高，强调了未来在实际应用（如预测虚假信息）中的改进潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14986v1",
      "published_date": "2024-09-23 13:05:25 UTC",
      "updated_date": "2024-09-23 13:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:47:43.969766"
    },
    {
      "arxiv_id": "2409.14985v2",
      "title": "Sparse-to-Dense LiDAR Point Generation by LiDAR-Camera Fusion for 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Minseung Lee",
        "Seokha Moon",
        "Seung Joon Lee",
        "Jinkyu Kim"
      ],
      "abstract": "Accurately detecting objects at long distances remains a critical challenge\nin 3D object detection when relying solely on LiDAR sensors due to the inherent\nlimitations of data sparsity. To address this issue, we propose the\nLiDAR-Camera Augmentation Network (LCANet), a novel framework that reconstructs\nLiDAR point cloud data by fusing 2D image features, which contain rich semantic\ninformation, generating additional points to improve detection accuracy. LCANet\nfuses data from LiDAR sensors and cameras by projecting image features into the\n3D space, integrating semantic information into the point cloud data. This\nfused data is then encoded to produce 3D features that contain both semantic\nand spatial information, which are further refined to reconstruct final points\nbefore bounding box prediction. This fusion effectively compensates for LiDAR's\nweakness in detecting objects at long distances, which are often represented by\nsparse points. Additionally, due to the sparsity of many objects in the\noriginal dataset, which makes effective supervision for point generation\nchallenging, we employ a point cloud completion network to create a complete\npoint cloud dataset that supervises the generation of dense point clouds in our\nnetwork. Extensive experiments on the KITTI and Waymo datasets demonstrate that\nLCANet significantly outperforms existing models, particularly in detecting\nsparse and distant objects.",
      "tldr_zh": "该论文针对 LiDAR 传感器在长距离 3D 物体检测中因数据稀疏性而导致的准确性问题，提出了一种新型框架 LiDAR-Camera Augmentation Network (LCANet)。该方法通过融合 LiDAR 点云和相机图像特征，将 2D 语义信息投影到 3D 空间，并使用点云完成网络生成密集点云，以补偿 LiDAR 的弱点。实验结果显示，在 KITTI 和 Waymo 数据集上，LCANet 在检测稀疏和远距离物体时比现有模型性能提升显著。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.14985v2",
      "published_date": "2024-09-23 13:03:31 UTC",
      "updated_date": "2024-09-24 16:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:47:55.682686"
    },
    {
      "arxiv_id": "2409.14983v2",
      "title": "Dynamic Integration of Task-Specific Adapters for Class Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiashuo Li",
        "Shaokun Wang",
        "Bo Qian",
        "Yuhang He",
        "Xing Wei",
        "Qiang Wang",
        "Yihong Gong"
      ],
      "abstract": "Non-exemplar class Incremental Learning (NECIL) enables models to\ncontinuously acquire new classes without retraining from scratch and storing\nold task exemplars, addressing privacy and storage issues. However, the absence\nof data from earlier tasks exacerbates the challenge of catastrophic forgetting\nin NECIL. In this paper, we propose a novel framework called Dynamic\nIntegration of task-specific Adapters (DIA), which comprises two key\ncomponents: Task-Specific Adapter Integration (TSAI) and Patch-Level Model\nAlignment. TSAI boosts compositionality through a patch-level adapter\nintegration strategy, which provides a more flexible compositional solution\nwhile maintaining low computation costs. Patch-Level Model Alignment maintains\nfeature consistency and accurate decision boundaries via two specialized\nmechanisms: Patch-Level Distillation Loss (PDL) and Patch-Level Feature\nReconstruction method (PFR). Specifically, the PDL preserves feature-level\nconsistency between successive models by implementing a distillation loss based\non the contributions of patch tokens to new class learning. The PFR facilitates\naccurate classifier alignment by reconstructing old class features from\nprevious tasks that adapt to new task knowledge. Extensive experiments validate\nthe effectiveness of our DIA, revealing significant improvements on benchmark\ndatasets in the NECIL setting, maintaining an optimal balance between\ncomputational complexity and accuracy.",
      "tldr_zh": "本论文针对 Non-exemplar Class Incremental Learning (NECIL) 的挑战，提出了一种名为 Dynamic Integration of task-specific Adapters (DIA) 的框架，以缓解模型在没有旧数据情况下出现的灾难性遗忘问题。DIA 包括 Task-Specific Adapter Integration (TSAI)，通过 patch-level 适配器整合策略提升模型的组合性和灵活性，同时保持低计算成本；以及 Patch-Level Model Alignment，利用 Patch-Level Distillation Loss (PDL) 和 Patch-Level Feature Reconstruction (PFR) 来维护特征一致性和决策边界准确性。实验结果表明，DIA 在 NECIL 设置下的基准数据集上实现了显著的准确率提升，并在计算复杂性和性能之间取得了最佳平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14983v2",
      "published_date": "2024-09-23 13:01:33 UTC",
      "updated_date": "2025-04-27 11:43:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:48:08.450825"
    },
    {
      "arxiv_id": "2409.14981v1",
      "title": "On The Specialization of Neural Modules",
      "title_zh": "翻译失败",
      "authors": [
        "Devon Jarvis",
        "Richard Klein",
        "Benjamin Rosman",
        "Andrew M. Saxe"
      ],
      "abstract": "A number of machine learning models have been proposed with the goal of\nachieving systematic generalization: the ability to reason about new situations\nby combining aspects of previous experiences. These models leverage\ncompositional architectures which aim to learn specialized modules dedicated to\nstructures in a task that can be composed to solve novel problems with similar\nstructures. While the compositionality of these architectures is guaranteed by\ndesign, the modules specializing is not. Here we theoretically study the\nability of network modules to specialize to useful structures in a dataset and\nachieve systematic generalization. To this end we introduce a minimal space of\ndatasets motivated by practical systematic generalization benchmarks. From this\nspace of datasets we present a mathematical definition of systematicity and\nstudy the learning dynamics of linear neural modules when solving components of\nthe task. Our results shed light on the difficulty of module specialization,\nwhat is required for modules to successfully specialize, and the necessity of\nmodular architectures to achieve systematicity. Finally, we confirm that the\ntheoretical results in our tractable setting generalize to more complex\ndatasets and non-linear architectures.",
      "tldr_zh": "这篇论文探讨了神经模块（neural modules）的专门化问题，以实现系统化泛化（systematic generalization），即通过组合先前经验来推理新情况。作者引入了一个最小数据集空间，并提供了系统性（systematicity）的数学定义，分析了线性神经模块在任务组件中的学习动态。研究发现，模块专门化面临挑战，需要特定条件和组合式架构（compositional architectures）作为基础，方能有效处理类似任务。最终，这些理论结果扩展到更复杂的数据集和非线性架构中，强调了模块化设计在实现系统性泛化的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The Eleventh International Conference on Learning Representations\n  2023",
      "pdf_url": "http://arxiv.org/pdf/2409.14981v1",
      "published_date": "2024-09-23 12:58:11 UTC",
      "updated_date": "2024-09-23 12:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:48:20.011756"
    },
    {
      "arxiv_id": "2409.14978v2",
      "title": "TS-HTFA: Advancing Time Series Forecasting via Hierarchical Text-Free Alignment with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Wang",
        "Huanran Zheng",
        "Qi'ao Xu",
        "Silong Dai",
        "Yiqiao Wang",
        "Wenjing Yue",
        "Wei Zhu",
        "Tianwen Qian",
        "Xiaoling Wang"
      ],
      "abstract": "Given the significant potential of large language models (LLMs) in sequence\nmodeling, emerging studies have begun applying them to time-series forecasting.\nDespite notable progress, existing methods still face two critical challenges:\n1) their reliance on large amounts of paired text data, limiting the model\napplicability, and 2) a substantial modality gap between text and time series,\nleading to insufficient alignment and suboptimal performance. In this paper, we\nintroduce \\textbf{H}ierarchical \\textbf{T}ext-\\textbf{F}ree \\textbf{A}lignment\n(\\textbf{TS-HTFA}), a novel method that leverages hierarchical alignment to\nfully exploit the representation capacity of LLMs while eliminating the\ndependence on text data. Specifically, we replace paired text data with\nadaptive virtual text based on QR decomposition word embeddings and learnable\nprompt. Furthermore, we establish comprehensive cross-modal alignment at three\nlevels: input, feature, and output. Extensive experiments on multiple\ntime-series benchmarks demonstrate that HTFA achieves state-of-the-art\nperformance, significantly improving prediction accuracy and generalization.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在时间序列预测中的应用，解决了现有方法对配对文本数据的依赖和模态间差距问题，提出了一种创新方法TS-HTFA（Hierarchical Text-Free Alignment）。\nTS-HTFA通过基于QR分解的适应性虚拟文本和可学习提示，在输入、特征和输出三个层面建立全面跨模态对齐，从而充分利用LLMs的表示能力，而无需实际文本数据。\n实验结果显示，在多个时间序列基准上，TS-HTFA实现了最先进性能，显著提高了预测准确性和模型泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14978v2",
      "published_date": "2024-09-23 12:57:24 UTC",
      "updated_date": "2025-01-08 07:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:48:32.863787"
    },
    {
      "arxiv_id": "2409.14972v1",
      "title": "Deep Reinforcement Learning-based Obstacle Avoidance for Robot Movement in Warehouse Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Keqin Li",
        "Jiajing Chen",
        "Denzhi Yu",
        "Tao Dajun",
        "Xinyu Qiu",
        "Lian Jieting",
        "Sun Baiwei",
        "Zhang Shengyuan",
        "Zhenyu Wan",
        "Ran Ji",
        "Bo Hong",
        "Fanghao Ni"
      ],
      "abstract": "At present, in most warehouse environments, the accumulation of goods is\ncomplex, and the management personnel in the control of goods at the same time\nwith the warehouse mobile robot trajectory interaction, the traditional mobile\nrobot can not be very good on the goods and pedestrians to feed back the\ncorrect obstacle avoidance strategy, in order to control the mobile robot in\nthe warehouse environment efficiently and friendly to complete the obstacle\navoidance task, this paper proposes a deep reinforcement learning based on the\nwarehouse environment, the mobile robot obstacle avoidance Algorithm. Firstly,\nfor the insufficient learning ability of the value function network in the deep\nreinforcement learning algorithm, the value function network is improved based\non the pedestrian interaction, the interaction information between pedestrians\nis extracted through the pedestrian angle grid, and the temporal features of\nindividual pedestrians are extracted through the attention mechanism, so that\nwe can learn to obtain the relative importance of the current state and the\nhistorical trajectory state as well as the joint impact on the robot's obstacle\navoidance strategy, which provides an opportunity for the learning of\nmulti-layer perceptual machines afterwards. Secondly, the reward function of\nreinforcement learning is designed based on the spatial behaviour of\npedestrians, and the robot is punished for the state where the angle changes\ntoo much, so as to achieve the requirement of comfortable obstacle avoidance;\nFinally, the feasibility and effectiveness of the deep reinforcement\nlearning-based mobile robot obstacle avoidance algorithm in the warehouse\nenvironment in the complex environment of the warehouse are verified through\nsimulation experiments.",
      "tldr_zh": "这篇论文针对仓库环境的复杂性，提出了一种基于深度强化学习的移动机器人避障算法，以解决传统机器人对货物和行人交互的不足。算法通过改进价值函数网络，利用行人角度网格提取交互信息，并结合注意力机制学习当前状态、历史轨迹对避障策略的联合影响，同时设计基于行人空间行为的奖励函数来惩罚角度变化过大的状态，确保避障过程更舒适。最后，通过模拟实验验证了该算法在仓库复杂环境中的可行性和有效性，提高了机器人的避障性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14972v1",
      "published_date": "2024-09-23 12:42:35 UTC",
      "updated_date": "2024-09-23 12:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:48:42.889235"
    },
    {
      "arxiv_id": "2409.14924v1",
      "title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely",
      "title_zh": "翻译失败",
      "authors": [
        "Siyun Zhao",
        "Yuqing Yang",
        "Zilong Wang",
        "Zhiyuan He",
        "Luna K. Qiu",
        "Lili Qiu"
      ],
      "abstract": "Large language models (LLMs) augmented with external data have demonstrated\nremarkable capabilities in completing real-world tasks. Techniques for\nintegrating external data into LLMs, such as Retrieval-Augmented Generation\n(RAG) and fine-tuning, are gaining increasing attention and widespread\napplication. Nonetheless, the effective deployment of data-augmented LLMs\nacross various specialized fields presents substantial challenges. These\nchallenges encompass a wide range of issues, from retrieving relevant data and\naccurately interpreting user intent to fully harnessing the reasoning\ncapabilities of LLMs for complex tasks. We believe that there is no\none-size-fits-all solution for data-augmented LLM applications. In practice,\nunderperformance often arises from a failure to correctly identify the core\nfocus of a task or because the task inherently requires a blend of multiple\ncapabilities that must be disentangled for better resolution. In this survey,\nwe propose a RAG task categorization method, classifying user queries into four\nlevels based on the type of external data required and primary focus of the\ntask: explicit fact queries, implicit fact queries, interpretable rationale\nqueries, and hidden rationale queries. We define these levels of queries,\nprovide relevant datasets, and summarize the key challenges and most effective\ntechniques for addressing these challenges. Finally, we discuss three main\nforms of integrating external data into LLMs: context, small model, and\nfine-tuning, highlighting their respective strengths, limitations, and the\ntypes of problems they are suited to solve. This work aims to help readers\nthoroughly understand and decompose the data requirements and key bottlenecks\nin building LLM applications, offering solutions to the different challenges\nand serving as a guide to systematically developing such applications.",
      "tldr_zh": "这篇调查论文全面探讨了如何让大型语言模型(LLMs)更有效地使用外部数据，包括Retrieval-Augmented Generation (RAG)和微调等技术。论文提出了一种RAG任务分类方法，将用户查询分为四个级别：explicit fact queries、implicit fact queries、interpretable rationale queries和hidden rationale queries，并总结了相关数据集、关键挑战和应对策略。同时，它讨论了整合外部数据的三种主要形式——context、small model和fine-tuning——并分析了它们的优势、局限性及适用场景。该工作旨在帮助开发者理解数据需求、分解瓶颈，并系统地构建LLM应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14924v1",
      "published_date": "2024-09-23 11:20:20 UTC",
      "updated_date": "2024-09-23 11:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:48:56.995091"
    },
    {
      "arxiv_id": "2409.14908v2",
      "title": "KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Wang",
        "Bo Yu",
        "Junzhe Zhao",
        "Wenhao Sun",
        "Sai Hou",
        "Shuai Liang",
        "Xing Hu",
        "Yinhe Han",
        "Yiming Gan"
      ],
      "abstract": "Embodied AI agents responsible for executing interconnected, long-sequence\nhousehold tasks often face difficulties with in-context memory, leading to\ninefficiencies and errors in task execution. To address this issue, we\nintroduce KARMA, an innovative memory system that integrates long-term and\nshort-term memory modules, enhancing large language models (LLMs) for planning\nin embodied agents through memory-augmented prompting. KARMA distinguishes\nbetween long-term and short-term memory, with long-term memory capturing\ncomprehensive 3D scene graphs as representations of the environment, while\nshort-term memory dynamically records changes in objects' positions and states.\nThis dual-memory structure allows agents to retrieve relevant past scene\nexperiences, thereby improving the accuracy and efficiency of task planning.\nShort-term memory employs strategies for effective and adaptive memory\nreplacement, ensuring the retention of critical information while discarding\nless pertinent data. Compared to state-of-the-art embodied agents enhanced with\nmemory, our memory-augmented embodied AI agent improves success rates by 1.3x\nand 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,\nrespectively, and enhances task execution efficiency by 3.4x and 62.7x.\nFurthermore, we demonstrate that KARMA's plug-and-play capability allows for\nseamless deployment on real-world robotic systems, such as mobile manipulation\nplatforms.Through this plug-and-play memory system, KARMA significantly\nenhances the ability of embodied agents to generate coherent and contextually\nappropriate plans, making the execution of complex household tasks more\nefficient. The experimental videos from the work can be found at\nhttps://youtu.be/4BT7fnw9ehs. Our code is available at\nhttps://github.com/WZX0Swarm0Robotics/KARMA/tree/master.",
      "tldr_zh": "该论文提出 KARMA，一种创新的记忆系统，用于增强 Embodied AI agents 的长-term memory 和 short-term memory 能力，以解决执行长序列家庭任务时的记忆不足问题。KARMA 通过 memory-augmented prompting 整合 LLMs 规划，long-term memory 使用 3D scene graphs 捕获环境表示，而 short-term memory 动态记录对象位置和状态变化，并采用适应性记忆替换策略以保留关键信息。实验结果显示，在 AI2-THOR 模拟器中，KARMA 使代理成功率分别提高 1.3 倍和 2.3 倍（针对 Composite Tasks 和 Complex Tasks），并提升任务执行效率 3.4 倍和 62.7 倍。该系统具备 plug-and-play 特性，便于部署到真实机器人平台，提高复杂任务的准确性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14908v2",
      "published_date": "2024-09-23 11:02:46 UTC",
      "updated_date": "2025-03-21 01:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:49:12.573947"
    },
    {
      "arxiv_id": "2409.14904v1",
      "title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sangyeon Cho",
        "Jangyeong Jeon",
        "Dongjoon Lee",
        "Changhee Lee",
        "Junyeong Kim"
      ],
      "abstract": "The use of pre-trained language models fine-tuned to address specific\ndownstream tasks is a common approach in natural language processing (NLP).\nHowever, acquiring domain-specific knowledge via fine-tuning is challenging.\nTraditional methods involve pretraining language models using vast amounts of\ndomain-specific data before fine-tuning for particular tasks. This study\ninvestigates emergency/non-emergency classification tasks based on electronic\nmedical record (EMR) data obtained from pediatric emergency departments (PEDs)\nin Korea. Our findings reveal that existing domain-specific pre-trained\nlanguage models underperform compared to general language models in handling\nN-lingual free-text data characteristics of non-English-speaking regions. To\naddress these limitations, we propose a domain knowledge transfer methodology\nthat leverages knowledge distillation to infuse general language models with\ndomain-specific knowledge via fine-tuning. This study demonstrates the\neffective transfer of specialized knowledge between models by defining a\ngeneral language model as the student model and a domain-specific pre-trained\nmodel as the teacher model. In particular, we address the complexities of EMR\ndata obtained from PEDs in non-English-speaking regions, such as Korea, and\ndemonstrate that the proposed method enhances classification performance in\nsuch contexts. The proposed methodology not only outperforms baseline models on\nKorean PED EMR data, but also promises broader applicability in various\nprofessional and technical domains. In future works, we intend to extend this\nmethodology to include diverse non-English-speaking regions and address\nadditional downstream tasks, with the aim of developing advanced model\narchitectures using state-of-the-art KD techniques. The code is available in\nhttps://github.com/JoSangYeon/DSG-KD.",
      "tldr_zh": "本研究探讨了在自然语言处理中，将领域特定知识转移到通用语言模型的挑战，提出DSG-KD方法，使用Knowledge Distillation将领域特定预训练模型作为教师模型，向通用语言模型（作为学生模型）注入知识。针对韩国儿科急诊部门（PEDs）的电子病历（EMR）数据，该方法应用于紧急/非紧急分类任务，并发现它在处理非英语地区多语言自由文本时，显著优于现有领域特定模型。实验结果显示，DSG-KD在韩国EMR数据上提升了分类性能，并展示了在各种专业领域的潜在适用性。未来，该方法计划扩展到更多非英语地区和下游任务，并结合先进的KD技术优化模型架构。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "IEEE ACCESS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.14904v1",
      "published_date": "2024-09-23 10:59:02 UTC",
      "updated_date": "2024-09-23 10:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:49:20.688306"
    },
    {
      "arxiv_id": "2409.14887v3",
      "title": "Deploying Open-Source Large Language Models: A performance Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yannis Bendi-Ouis",
        "Dan Dutartre",
        "Xavier Hinaut"
      ],
      "abstract": "Since the release of ChatGPT in November 2022, large language models (LLMs)\nhave seen considerable success, including in the open-source community, with\nmany open-weight models available. However, the requirements to deploy such a\nservice are often unknown and difficult to evaluate in advance. To facilitate\nthis process, we conducted numerous tests at the Centre Inria de l'Universit\\'e\nde Bordeaux. In this article, we propose a comparison of the performance of\nseveral models of different sizes (mainly Mistral and LLaMa) depending on the\navailable GPUs, using vLLM, a Python library designed to optimize the inference\nof these models. Our results provide valuable information for private and\npublic groups wishing to deploy LLMs, allowing them to evaluate the performance\nof different models based on their available hardware. This study thus\ncontributes to facilitating the adoption and use of these large language models\nin various application domains.",
      "tldr_zh": "这篇论文分析了部署开源 Large Language Models (LLMs) 的性能，重点比较了不同规模的 Mistral 和 LLaMa 模型在各种 GPUs 上的表现。研究团队使用 vLLM 库进行了优化测试，帮助评估硬件资源对模型推理效率的影响。结果显示，这些测试数据为私有和公共团体提供了宝贵信息，便于根据可用设备选择合适的模型，从而促进 LLMs 在多领域应用的采用。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.PF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14887v3",
      "published_date": "2024-09-23 10:35:57 UTC",
      "updated_date": "2025-01-07 09:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:49:30.716041"
    },
    {
      "arxiv_id": "2409.14880v1",
      "title": "End-to-End Graph Flattening Method for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Hong",
        "Jinze Wu",
        "Jiayu Liu",
        "Liang Ding",
        "Jing Sha",
        "Kai Zhang",
        "Shijin Wang",
        "Zhenya Huang"
      ],
      "abstract": "In recent years, the breakthrough of Large Language Models (LLMs) offers new\nideas for achieving universal methods on graph data. The common practice of\nconverting graphs into natural language for LLMs, which refers to graph\nflattening, exhibits good generalizability and interpretability. However, the\npoor organization of the textual format results in poor performance in\nlong-distance scenario understanding. Inspired by human cognitive reasoning\nhabits, we propose a novel method for graph flattening to fit LLMs, termed as\nEnd-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show\nthat EEDP enhances the reasoning performance of LLMs in long-distance scenarios\nwhile maintaining excellent performance in short-distance scenarios,\ndemonstrating good robustness in the face of distance variations.",
      "tldr_zh": "本论文提出了一种End-to-End DAG-Path prompting (EEDP)方法，用于将图数据扁平化以适应Large Language Models (LLMs)，以解决传统方法在长距离场景理解上的表现不足。EEDP 灵感来源于人类认知推理习惯，通过端到端的路径提示优化图数据的文本组织，提升了LLMs的整体推理能力。实验结果显示，在真实数据集上，EEDP 显著提高了长距离场景的推理性能，同时保持了短距离场景的优秀表现，并展示了良好的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 1st International Conference on Computational Linguistics and\n  Natural Language Processing (CLNLP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.14880v1",
      "published_date": "2024-09-23 10:28:47 UTC",
      "updated_date": "2024-09-23 10:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:49:44.503247"
    },
    {
      "arxiv_id": "2409.15398v1",
      "title": "Attack Atlas: A Practitioner's Perspective on Challenges and Pitfalls in Red Teaming GenAI",
      "title_zh": "翻译失败",
      "authors": [
        "Ambrish Rawat",
        "Stefan Schoepf",
        "Giulio Zizzo",
        "Giandomenico Cornacchia",
        "Muhammad Zaid Hameed",
        "Kieran Fraser",
        "Erik Miehling",
        "Beat Buesser",
        "Elizabeth M. Daly",
        "Mark Purcell",
        "Prasanna Sattigeri",
        "Pin-Yu Chen",
        "Kush R. Varshney"
      ],
      "abstract": "As generative AI, particularly large language models (LLMs), become\nincreasingly integrated into production applications, new attack surfaces and\nvulnerabilities emerge and put a focus on adversarial threats in natural\nlanguage and multi-modal systems. Red-teaming has gained importance in\nproactively identifying weaknesses in these systems, while blue-teaming works\nto protect against such adversarial attacks. Despite growing academic interest\nin adversarial risks for generative AI, there is limited guidance tailored for\npractitioners to assess and mitigate these challenges in real-world\nenvironments. To address this, our contributions include: (1) a practical\nexamination of red- and blue-teaming strategies for securing generative AI, (2)\nidentification of key challenges and open questions in defense development and\nevaluation, and (3) the Attack Atlas, an intuitive framework that brings a\npractical approach to analyzing single-turn input attacks, placing it at the\nforefront for practitioners. This work aims to bridge the gap between academic\ninsights and practical security measures for the protection of generative AI\nsystems.",
      "tldr_zh": "随着生成式 AI（如大型语言模型 LLMs）的广泛应用，新的攻击面和漏洞不断涌现，红-teaming（红队测试）在识别这些系统中的弱点方面变得日益重要，而 blue-teaming（蓝队测试）则专注于防御。该论文从从业者视角审视红队和蓝队策略，识别了防御开发和评估中的关键挑战以及开放问题，并提出了 Attack Atlas 框架，这是一个直观的工具，用于分析单轮输入攻击。通过这些贡献，该工作桥接了学术洞见与实际安全措施，帮助保护生成式 AI 系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15398v1",
      "published_date": "2024-09-23 10:18:10 UTC",
      "updated_date": "2024-09-23 10:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:49:55.977307"
    },
    {
      "arxiv_id": "2409.14876v4",
      "title": "Mammo-Clustering: A Multi-views Tri-level Information Fusion Context Clustering Framework for Localization and Classification in Mammography",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Yang",
        "Chulong Zhang",
        "Qi Zang",
        "Juan Yu",
        "Liang Zeng",
        "Xiao Luo",
        "Yexuan Xing",
        "Xin Pan",
        "Qi Li",
        "Xiaokun Liang",
        "Yaoqin Xie"
      ],
      "abstract": "Breast cancer is a significant global health issue, and the diagnosis of\nbreast imaging has always been challenging. Mammography images typically have\nextremely high resolution, with lesions occupying only a very small area.\nDown-sampling in neural networks can easily lead to the loss of\nmicrocalcifications or subtle structures, making it difficult for traditional\nneural network architectures to address these issues. To tackle these\nchallenges, we propose a Context Clustering Network with triple information\nfusion. Firstly, compared to CNNs or transformers, we find that Context\nclustering methods (1) are more computationally efficient and (2) can more\neasily associate structural or pathological features, making them suitable for\nthe clinical tasks of mammography. Secondly, we propose a triple information\nfusion mechanism that integrates global information, feature-based local\ninformation, and patch-based local information. The proposed approach is\nrigorously evaluated on two public datasets, Vindr-Mammo and CBIS-DDSM, using\nfive independent splits to ensure statistical robustness. Our method achieves\nan AUC of 0.828 on Vindr-Mammo and 0.805 on CBIS-DDSM, outperforming the next\nbest method by 3.1% and 2.4%, respectively. These improvements are\nstatistically significant (p<0.05), underscoring the benefits of Context\nClustering Network with triple information fusion. Overall, our Context\nClustering framework demonstrates strong potential as a scalable and\ncost-effective solution for large-scale mammography screening, enabling more\nefficient and accurate breast cancer detection. Access to our method is\navailable at https://github.com/Sohyu1/Mammo_Clustering.",
      "tldr_zh": "本文提出Mammo-Clustering框架，这是一种基于Context Clustering的多视图三层信息融合方法，旨在解决乳腺X光图像中病变区域小和下采样导致结构丢失的诊断挑战。该框架通过整合全局信息、feature-based局部信息和patch-based局部信息，比传统CNNs或transformers更高效地关联结构和病理特征。在Vindr-Mammo和CBIS-DDSM数据集上进行五次独立分割评估，结果显示AUC分别达到0.828和0.805，较最佳方法提升3.1%和2.4%，统计显著（p<0.05）。总体上，该框架为大规模乳腺癌筛查提供了一个可扩展、成本有效的准确检测解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14876v4",
      "published_date": "2024-09-23 10:17:13 UTC",
      "updated_date": "2025-03-15 07:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:50:09.090740"
    },
    {
      "arxiv_id": "2409.14874v2",
      "title": "Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ahjol Senbi",
        "Tianyu Huang",
        "Fei Lyu",
        "Qing Li",
        "Yuhui Tao",
        "Wei Shao",
        "Qiang Chen",
        "Chengyan Wang",
        "Shuo Wang",
        "Tao Zhou",
        "Yizhe Zhang"
      ],
      "abstract": "We explore the feasibility and potential of building a ground-truth-free\nevaluation model to assess the quality of segmentations generated by the\nSegment Anything Model (SAM) and its variants in medical imaging. This\nevaluation model estimates segmentation quality scores by analyzing the\ncoherence and consistency between the input images and their corresponding\nsegmentation predictions. Based on prior research, we frame the task of\ntraining this model as a regression problem within a supervised learning\nframework, using Dice scores (and optionally other metrics) along with mean\nsquared error to compute the training loss. The model is trained utilizing a\nlarge collection of public datasets of medical images with segmentation\npredictions from SAM and its variants. We name this model EvanySeg (Evaluation\nof Any Segmentation in Medical Images). Our exploration of convolution-based\nmodels (e.g., ResNet) and transformer-based models (e.g., ViT) suggested that\nViT yields better performance for this task. EvanySeg can be employed for\nvarious tasks, including: (1) identifying poorly segmented samples by detecting\nlow-percentile segmentation quality scores; (2) benchmarking segmentation\nmodels without ground truth by averaging quality scores across test samples;\n(3) alerting human experts to poor-quality segmentation predictions during\nhuman-AI collaboration by applying a threshold within the score space; and (4)\nselecting the best segmentation prediction for each test sample at test time\nwhen multiple segmentation models are available, by choosing the prediction\nwith the highest quality score. Models and code will be made available at\nhttps://github.com/ahjolsenbics/EvanySeg.",
      "tldr_zh": "本文提出EvanySeg，一种无需ground truth的评估模型，用于评估Segment Anything Model (SAM)及其变体在医疗图像中的分割质量。该模型通过监督学习回归框架（如使用Dice scores和均方误差），分析输入图像与分割预测的连贯性，并发现Vision Transformer (ViT)比卷积模型（如ResNet）表现出色。EvanySeg的应用包括识别低质量分割样本、基准测试分割模型、在人机协作中警报专家，以及从多个模型中选择最佳预测，为医疗图像处理提供高效工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14874v2",
      "published_date": "2024-09-23 10:12:08 UTC",
      "updated_date": "2024-09-24 09:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:50:19.527229"
    },
    {
      "arxiv_id": "2409.14872v2",
      "title": "FedSlate:A Federated Deep Reinforcement Learning Recommender System",
      "title_zh": "FedSlate：联邦深度强化学习推荐系统",
      "authors": [
        "Yongxin Deng",
        "Xihe Qiu",
        "Xiaoyu Tan",
        "Yaochu Jin"
      ],
      "abstract": "Reinforcement learning methods have been used to optimize long-term user\nengagement in recommendation systems. However, existing reinforcement\nlearning-based recommendation systems do not fully exploit the relevance of\nindividual user behavior across different platforms. One potential solution is\nto aggregate data from various platforms in a centralized location and use the\naggregated data for training. However, this approach raises economic and legal\nconcerns, including increased communication costs and potential threats to user\nprivacy. To address these challenges, we propose \\textbf{FedSlate}, a federated\nreinforcement learning recommendation algorithm that effectively utilizes\ninformation that is prohibited from being shared at a legal level. We employ\nthe SlateQ algorithm to assist FedSlate in learning users' long-term behavior\nand evaluating the value of recommended content. We extend the existing\napplication scope of recommendation systems from single-user single-platform to\nsingle-user multi-platform and address cross-platform learning challenges by\nintroducing federated learning. We use RecSim to construct a simulation\nenvironment for evaluating FedSlate and compare its performance with\nstate-of-the-art benchmark recommendation models. Experimental results\ndemonstrate the superior effects of FedSlate over baseline methods in various\nenvironmental settings, and FedSlate facilitates the learning of recommendation\nstrategies in scenarios where baseline methods are completely inapplicable.\nCode is available at \\textit{https://github.com/TianYaDY/FedSlate}.",
      "tldr_zh": "本研究提出FedSlate，一种基于联邦深度强化学习的推荐系统，旨在解决现有强化学习推荐算法在跨平台用户行为利用上的局限，同时避免数据集中式处理带来的隐私和经济问题。FedSlate采用SlateQ算法来学习用户的长期行为并评估推荐内容价值，通过联邦学习框架扩展推荐系统从单用户单平台到单用户多平台的应用，并有效处理跨平台学习挑战。实验在RecSim模拟环境中进行，结果显示FedSlate在各种设置下优于基准模型，并在基准方法无效的场景中表现出色，代码已在GitHub开源。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14872v2",
      "published_date": "2024-09-23 10:10:24 UTC",
      "updated_date": "2025-04-28 15:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:50:31.206877"
    },
    {
      "arxiv_id": "2409.14867v1",
      "title": "A novel agent with formal goal-reaching guarantees: an experimental study with a mobile robot",
      "title_zh": "翻译失败",
      "authors": [
        "Grigory Yaremenko",
        "Dmitrii Dobriborsci",
        "Roman Zashchitin",
        "Ruben Contreras Maestre",
        "Ngoc Quoc Huy Hoang",
        "Pavel Osinenko"
      ],
      "abstract": "Reinforcement Learning (RL) has been shown to be effective and convenient for\na number of tasks in robotics. However, it requires the exploration of a\nsufficiently large number of state-action pairs, many of which may be unsafe or\nunimportant. For instance, online model-free learning can be hazardous and\ninefficient in the absence of guarantees that a certain set of desired states\nwill be reached during an episode. An increasingly common approach to address\nsafety involves the addition of a shielding system that constrains the RL\nactions to a safe set of actions. In turn, a difficulty for such frameworks is\nhow to effectively couple RL with the shielding system to make sure the\nexploration is not excessively restricted. This work presents a novel safe\nmodel-free RL agent called Critic As Lyapunov Function (CALF) and showcases how\nCALF can be used to improve upon control baselines in robotics in an efficient\nand convenient fashion while ensuring guarantees of stable goal reaching. The\nlatter is a crucial part of safety, as seen generally. With CALF all\nstate-action pairs remain explorable and yet reaching of desired goal states is\nformally guaranteed. Formal analysis is provided that shows the goal\nstabilization-ensuring properties of CALF and a set of real-world and numerical\nexperiments with a non-holonomic wheeled mobile robot (WMR) TurtleBot3 Burger\nconfirmed the superiority of CALF over such a well-established RL agent as\nproximal policy optimization (PPO), and a modified version of SARSA in a\nfew-episode setting in terms of attained total cost.",
      "tldr_zh": "该研究针对强化学习（RL）在机器人任务中的安全和效率问题，提出了一种新型安全无模型 RL 代理——Critic As Lyapunov Function (CALF)。CALF 通过利用 Lyapunov 函数确保所有状态-动作对可探索，同时正式保证目标状态的稳定达到，从而避免了传统屏蔽系统对探索的过度限制。实验结果显示，在 TurtleBot3 Burger 移动机器人的实世界和数值测试中，CALF 在少 episode 设置下比 proximal policy optimization (PPO) 和 SARSA 代理在总成本方面表现出显著优势，为机器人控制提供了可靠的保证。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.DS",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14867v1",
      "published_date": "2024-09-23 10:04:28 UTC",
      "updated_date": "2024-09-23 10:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:50:43.570861"
    },
    {
      "arxiv_id": "2409.14866v5",
      "title": "PAPILLON: Efficient and Stealthy Fuzz Testing-Powered Jailbreaks for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xueluan Gong",
        "Mingzhe Li",
        "Yilin Zhang",
        "Fengyuan Ran",
        "Chen Chen",
        "Yanjiao Chen",
        "Qian Wang",
        "Kwok-Yan Lam"
      ],
      "abstract": "Large Language Models (LLMs) have excelled in various tasks but are still\nvulnerable to jailbreaking attacks, where attackers create jailbreak prompts to\nmislead the model to produce harmful or offensive content. Current jailbreak\nmethods either rely heavily on manually crafted templates, which pose\nchallenges in scalability and adaptability, or struggle to generate\nsemantically coherent prompts, making them easy to detect. Additionally, most\nexisting approaches involve lengthy prompts, leading to higher query costs. In\nthis paper, to remedy these challenges, we introduce a novel jailbreaking\nattack framework called PAPILLON, which is an automated, black-box jailbreaking\nattack framework that adapts the black-box fuzz testing approach with a series\nof customized designs. Instead of relying on manually crafted\ntemplates,PAPILLON starts with an empty seed pool, removing the need to search\nfor any related jailbreaking templates. We also develop three novel\nquestion-dependent mutation strategies using an LLM helper to generate prompts\nthat maintain semantic coherence while significantly reducing their length.\nAdditionally, we implement a two-level judge module to accurately detect\ngenuine successful jailbreaks. We evaluated PAPILLON on 7 representative LLMs\nand compared it with 5 state-of-the-art jailbreaking attack strategies. For\nproprietary LLM APIs, such as GPT-3.5 turbo, GPT-4, and Gemini-Pro, PAPILLONs\nachieves attack success rates of over 90%, 80%, and 74%, respectively,\nexceeding existing baselines by more than 60\\%. Additionally, PAPILLON can\nmaintain high semantic coherence while significantly reducing the length of\njailbreak prompts. When targeting GPT-4, PAPILLON can achieve over 78% attack\nsuccess rate even with 100 tokens. Moreover, PAPILLON demonstrates\ntransferability and is robust to state-of-the-art defenses. Code:\nhttps://github.com/aaFrostnova/Papillon",
      "tldr_zh": "这篇论文提出了 PAPILLON，一种高效且隐秘的越狱攻击框架，针对大型语言模型 (LLMs) 的漏洞，利用黑盒模糊测试 (fuzz testing) 技术从空种子池开始，避免依赖手动模板。框架引入三种新颖的问题依赖变异策略和两级判断模块，以生成语义连贯且更短的提示语，提升攻击的隐蔽性和可扩展性。实验结果显示，PAPILLON 在 GPT-3.5 turbo、GPT-4 和 Gemini-Pro 等模型上实现超过 90%、80% 和 74% 的攻击成功率，比现有基线高出 60%以上，同时证明了其可转移性和对防御措施的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14866v5",
      "published_date": "2024-09-23 10:03:09 UTC",
      "updated_date": "2025-03-03 07:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:50:56.305692"
    },
    {
      "arxiv_id": "2409.14857v2",
      "title": "Embedding Knowledge Graph in Function Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Mozart Kamdem Teyou",
        "Caglar Demir",
        "Axel-Cyrille Ngonga Ngomo"
      ],
      "abstract": "We introduce a novel embedding method diverging from conventional approaches\nby operating within function spaces of finite dimension rather than finite\nvector space, thus departing significantly from standard knowledge graph\nembedding techniques. Initially employing polynomial functions to compute\nembeddings, we progress to more intricate representations using neural networks\nwith varying layer complexities. We argue that employing functions for\nembedding computation enhances expressiveness and allows for more degrees of\nfreedom, enabling operations such as composition, derivatives and primitive of\nentities representation. Additionally, we meticulously outline the step-by-step\nconstruction of our approach and provide code for reproducibility, thereby\nfacilitating further exploration and application in the field.",
      "tldr_zh": "该论文提出了一种新型知识图嵌入方法，将知识图嵌入到有限维函数空间中，而不是传统的有限向量空间，从而提升了嵌入的表达性和灵活度。方法从使用多项式函数开始计算嵌入，并扩展到基于神经 networks 的复杂表示，支持实体表示的操作如 composition、derivatives 和 primitive。论文详细阐述了方法的构建过程，并提供可重现代码，以促进该领域的进一步探索和应用。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14857v2",
      "published_date": "2024-09-23 09:49:57 UTC",
      "updated_date": "2024-09-24 09:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:51:06.782716"
    },
    {
      "arxiv_id": "2409.14852v2",
      "title": "FUSED-Net: Detecting Traffic Signs with Limited Data",
      "title_zh": "FUSED-Net：使用有限数据的交通标志检测",
      "authors": [
        "Md. Atiqur Rahman",
        "Nahian Ibn Asad",
        "Md. Mushfiqul Haque Omi",
        "Md. Bakhtiar Hasan",
        "Sabbir Ahmed",
        "Md. Hasanul Kabir"
      ],
      "abstract": "Automatic Traffic Sign Recognition is paramount in modern transportation\nsystems, motivating several research endeavors to focus on performance\nimprovement by utilizing large-scale datasets. As the appearance of traffic\nsigns varies across countries, curating large-scale datasets is often\nimpractical; and requires efficient models that can produce satisfactory\nperformance using limited data. In this connection, we present 'FUSED-Net',\nbuilt-upon Faster RCNN for traffic sign detection, enhanced by Unfrozen\nParameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation\nwhile reducing data requirement. Unlike traditional approaches, we keep all\nparameters unfrozen during training, enabling FUSED-Net to learn from limited\nsamples. The generation of a Pseudo-Support Set through data augmentation\nfurther enhances performance by compensating for the scarcity of target domain\ndata. Additionally, Embedding Normalization is incorporated to reduce\nintra-class variance, standardizing feature representation. Domain Adaptation,\nachieved by pre-training on a diverse traffic sign dataset distinct from the\ntarget domain, improves model generalization. Evaluating FUSED-Net on the BDTSD\ndataset, we achieved 2.4x, 2.2x, 1.5x, and 1.3x improvements of mAP in 1-shot,\n3-shot, 5-shot, and 10-shot scenarios, respectively compared to the\nstate-of-the-art Few-Shot Object Detection (FSOD) models. Additionally, we\noutperform state-of-the-art works on the cross-domain FSOD benchmark under\nseveral scenarios.",
      "tldr_zh": "本论文提出 FUSED-Net，一种基于 Faster RCNN 的交通标志检测模型，旨在在数据有限场景下提升性能，通过 Unfrozen Parameters、Pseudo-Support Sets、Embedding Normalization 和 Domain Adaptation 等技术优化训练过程。具体而言，该模型保持所有参数 unfrozen 以从少量样本中学习，并利用数据增强生成 Pseudo-Support Sets 补偿数据稀缺，同时通过 Embedding Normalization 减少类内方差和 Domain Adaptation 提高泛化能力。在 BDTSD 数据集上，FUSED-Net 在 1-shot、3-shot、5-shot 和 10-shot 场景下分别实现了 mAP 的 2.4x、2.2x、1.5x 和 1.3x 提升，并优于现有 Few-Shot Object Detection (FSOD) 模型，在跨域基准上也表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 8 figures, 5 tables, submitted to IEEE Access for review",
      "pdf_url": "http://arxiv.org/pdf/2409.14852v2",
      "published_date": "2024-09-23 09:34:42 UTC",
      "updated_date": "2025-01-03 06:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:51:21.664887"
    },
    {
      "arxiv_id": "2409.14850v1",
      "title": "GroCo: Ground Constraint for Metric Self-Supervised Monocular Depth",
      "title_zh": "GroCo：用于度量自监督单目深度的地面约束",
      "authors": [
        "Aurélien Cecille",
        "Stefan Duffner",
        "Franck Davoine",
        "Thibault Neveu",
        "Rémi Agier"
      ],
      "abstract": "Monocular depth estimation has greatly improved in the recent years but\nmodels predicting metric depth still struggle to generalize across diverse\ncamera poses and datasets. While recent supervised methods mitigate this issue\nby leveraging ground prior information at inference, their adaptability to\nself-supervised settings is limited due to the additional challenge of scale\nrecovery. Addressing this gap, we propose in this paper a novel constraint on\nground areas designed specifically for the self-supervised paradigm. This\nmechanism not only allows to accurately recover the scale but also ensures\ncoherence between the depth prediction and the ground prior. Experimental\nresults show that our method surpasses existing scale recovery techniques on\nthe KITTI benchmark and significantly enhances model generalization\ncapabilities. This improvement can be observed by its more robust performance\nacross diverse camera rotations and its adaptability in zero-shot conditions\nwith previously unseen driving datasets such as DDAD.",
      "tldr_zh": "本论文提出 GroCo，一种针对自监督单目深度估计的地面约束机制（Ground Constraint），旨在解决模型在不同相机姿态和数据集上预测度量深度的泛化问题。该机制通过在自监督范式中利用地面先验信息，不仅准确恢复深度尺度，还确保深度预测与地面先验保持一致。实验结果显示，GroCo 在 KITTI 基准上超越现有尺度恢复技术，并在各种相机旋转以及零样本数据集（如 DDAD）上显著提升模型的鲁棒性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14850v1",
      "published_date": "2024-09-23 09:30:27 UTC",
      "updated_date": "2024-09-23 09:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:51:30.592343"
    },
    {
      "arxiv_id": "2409.14846v2",
      "title": "A-VL: Adaptive Attention for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junyang Zhang",
        "Mu Yuan",
        "Ruiguang Zhong",
        "Puhan Luo",
        "Huiyou Zhan",
        "Ningkang Zhang",
        "Chengchen Hu",
        "Xiangyang Li"
      ],
      "abstract": "The Large Vision-Language Model (LVLM) integrates computer vision and natural\nlanguage processing techniques, offering substantial application potential.\nHowever, these models demand extensive resources during inference. Adaptive\nattention techniques can dynamically reduce computational redundancy and thus\nimprove efficiency. Although current adaptive attention methods significantly\nreduce the memory requirements of Transformer-based language models, they are\nnot tailored for LVLMs. We observe that LVLMs generate responses from both\nremote image tokens and local text tokens, and different modalities have\ndifferent attention patterns. This observation inspires us to manage the\nattention for each modality separately. Specifically, for visual input, we\nstore the cache of potentially useful information but only compute the most\ncritical parts. For language input, we care more about local information. Based\non our observation and analysis of vision-language attention patterns, we\ndevelop A-VL, a plug-and-play adaptive attention tailored for LVLM inference.\nExtensive evaluations on three vision-language tasks and five datasets show the\neffectiveness of our designs. Our approach A-VL outperforms existing adaptive\nattention methods in reducing memory usage and computational load without\ncompromising performance.",
      "tldr_zh": "该研究针对 Large Vision-Language Models (LVLM) 在推理过程中资源密集的问题，提出了一种自适应注意力机制 A-VL，以动态减少计算冗余。\nA-VL 基于对视觉和语言模态不同注意力模式的观察，分别管理图像 tokens（仅计算最关键部分）和文本 tokens（关注本地信息），实现 plug-and-play 的优化设计。\n实验结果显示，在三个视觉语言任务和五个数据集上，A-VL 比现有自适应注意力方法更有效地降低内存使用和计算负载，同时不影响模型性能。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2409.14846v2",
      "published_date": "2024-09-23 09:22:59 UTC",
      "updated_date": "2025-02-07 13:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:51:44.496761"
    },
    {
      "arxiv_id": "2409.14842v3",
      "title": "HW-TSC's Submission to the CCMT 2024 Machine Translation Tasks",
      "title_zh": "HW-TSC 提交给 CCMT 2024 机器翻译任务的论文",
      "authors": [
        "Zhanglin Wu",
        "Yuanchang Luo",
        "Daimeng Wei",
        "Jiawei Zheng",
        "Bin Wei",
        "Zongyao Li",
        "Hengchao Shang",
        "Jiaxin Guo",
        "Shaojun Li",
        "Weidong Zhang",
        "Ning Xie",
        "Hao Yang"
      ],
      "abstract": "This paper presents the submission of Huawei Translation Services Center\n(HW-TSC) to machine translation tasks of the 20th China Conference on Machine\nTranslation (CCMT 2024). We participate in the bilingual machine translation\ntask and multi-domain machine translation task. For these two translation\ntasks, we use training strategies such as regularized dropout, bidirectional\ntraining, data diversification, forward translation, back translation,\nalternated training, curriculum learning, and transductive ensemble learning to\ntrain neural machine translation (NMT) models based on the deep Transformer-big\narchitecture. Furthermore, to explore whether large language model (LLM) can\nhelp improve the translation quality of NMT systems, we use supervised\nfine-tuning to train llama2-13b as an Automatic post-editing (APE) model to\nimprove the translation results of the NMT model on the multi-domain machine\ntranslation task. By using these plyometric strategies, our submission achieves\na competitive result in the final evaluation.",
      "tldr_zh": "这项论文介绍了华为翻译服务中心(HW-TSC)提交给CCMT 2024机器翻译任务的方案，包括双语机器翻译和多领域机器翻译任务。研究团队基于deep Transformer-big架构训练Neural Machine Translation (NMT)模型，采用多种策略如regularized dropout、bidirectional training、data diversification、forward translation、back translation、alternated training、curriculum learning和transductive ensemble learning来提升模型性能。此外，他们通过supervised fine-tuning对llama2-13b进行训练，作为Automatic Post-Editing (APE)模型，以进一步改善多领域翻译质量。最终，这些策略帮助他们的提交在最终评估中取得了竞争性的结果。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures, 6 Tables, CCMT2024. arXiv admin note:\n  substantial text overlap with arXiv:2409.14800",
      "pdf_url": "http://arxiv.org/pdf/2409.14842v3",
      "published_date": "2024-09-23 09:20:19 UTC",
      "updated_date": "2024-10-08 09:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:51:55.766916"
    },
    {
      "arxiv_id": "2409.14839v1",
      "title": "Explainable and Human-Grounded AI for Decision Support Systems: The Theory of Epistemic Quasi-Partnerships",
      "title_zh": "翻译失败",
      "authors": [
        "John Dorsch",
        "Maximilian Moll"
      ],
      "abstract": "In the context of AI decision support systems (AI-DSS), we argue that meeting\nthe demands of ethical and explainable AI (XAI) is about developing AI-DSS to\nprovide human decision-makers with three types of human-grounded explanations:\nreasons, counterfactuals, and confidence, an approach we refer to as the RCC\napproach. We begin by reviewing current empirical XAI literature that\ninvestigates the relationship between various methods for generating model\nexplanations (e.g., LIME, SHAP, Anchors), the perceived trustworthiness of the\nmodel, and end-user accuracy. We demonstrate how current theories about what\nconstitutes good human-grounded reasons either do not adequately explain this\nevidence or do not offer sound ethical advice for development. Thus, we offer a\nnovel theory of human-machine interaction: the theory of epistemic\nquasi-partnerships (EQP). Finally, we motivate adopting EQP and demonstrate how\nit explains the empirical evidence, offers sound ethical advice, and entails\nadopting the RCC approach.",
      "tldr_zh": "本论文针对 AI 决策支持系统 (AI-DSS)，提出通过提供理由 (reasons)、反事实 (counterfactuals) 和置信度 (confidence) 的 RCC 方法，来实现可解释 AI (XAI) 和伦理要求。作者回顾了现有 XAI 文献（如 LIME、SHAP 和 Anchors），指出当前理论无法充分解释经验证据或提供可靠道德指导。论文引入新型理论——认识论准伙伴关系 (EQP)，该理论能解释实证数据、给出合理的伦理建议，并支持采用 RCC 方法，从而提升 AI-DSS 的可信度和决策准确性。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "K.4.1; H.5.2; H.4.2; J.7; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.14839v1",
      "published_date": "2024-09-23 09:14:25 UTC",
      "updated_date": "2024-09-23 09:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:52:08.397567"
    },
    {
      "arxiv_id": "2409.14838v1",
      "title": "MICSim: A Modular Simulator for Mixed-signal Compute-in-Memory based AI Accelerator",
      "title_zh": "MICSim：混合信号内存计算AI加速器的模块化模拟器",
      "authors": [
        "Cong Wang",
        "Zeming Chen",
        "Shanshi Huang"
      ],
      "abstract": "This work introduces MICSim, an open-source, pre-circuit simulator designed\nfor early-stage evaluation of chip-level software performance and hardware\noverhead of mixed-signal compute-in-memory (CIM) accelerators. MICSim features\na modular design, allowing easy multi-level co-design and design space\nexploration. Modularized from the state-of-the-art CIM simulator NeuroSim,\nMICSim provides a highly configurable simulation framework supporting multiple\nquantization algorithms, diverse circuit/architecture designs, and different\nmemory devices. This modular approach also allows MICSim to be effectively\nextended to accommodate new designs.\n  MICSim natively supports evaluating accelerators' software and hardware\nperformance for CNNs and Transformers in Python, leveraging the popular PyTorch\nand HuggingFace Transformers frameworks. These capabilities make MICSim highly\nadaptive when simulating different networks and user-friendly. This work\ndemonstrates that MICSim can easily be combined with optimization strategies to\nperform design space exploration and used for chip-level Transformers CIM\naccelerators evaluation. Also, MICSim can achieve a 9x - 32x speedup of\nNeuroSim through a statistic-based average mode proposed by this work.",
      "tldr_zh": "这篇论文介绍了MICSim，一个开源的模块化模拟器，用于早期评估混合信号计算存储(CIM)加速器的芯片级软件性能和硬件开销。MICSim基于NeuroSim开发，支持多种量化算法、电路/架构设计和内存设备，并允许轻松扩展以适应新设计，同时原生集成PyTorch和HuggingFace Transformers框架，便于评估CNNs和Transformers的性能。实验结果显示，MICSim通过提出的统计-based平均模式，比NeuroSim实现9x-32x的速度提升，并可与优化策略结合进行设计空间探索，为AI加速器设计提供高效工具。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "The 30th Asia and South Pacific Design Automation Conference (ASP-DAC\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.14838v1",
      "published_date": "2024-09-23 09:12:46 UTC",
      "updated_date": "2024-09-23 09:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:52:19.334217"
    },
    {
      "arxiv_id": "2409.14836v2",
      "title": "Orthogonal Finetuning for Direct Preference Optimization",
      "title_zh": "正交微调用于直接偏好优化",
      "authors": [
        "Chenxu Yang",
        "Ruipeng Jia",
        "Naibin Gu",
        "Zheng Lin",
        "Siyuan Chen",
        "Chao Pang",
        "Weichong Yin",
        "Yu Sun",
        "Hua Wu",
        "Weiping Wang"
      ],
      "abstract": "DPO is an effective preference optimization algorithm. However, the DPO-tuned\nmodels tend to overfit on the dispreferred samples, manifested as overly long\ngenerations lacking diversity. While recent regularization approaches have\nendeavored to alleviate this issue by modifying the objective function, they\nachieved that at the cost of alignment performance degradation. In this paper,\nwe innovatively incorporate regularization from the perspective of weight\nupdating to curb alignment overfitting. Through the pilot experiment, we\ndiscovered that there exists a positive correlation between overfitting and the\nhyperspherical energy fluctuation. Hence, we introduce orthogonal finetuning\nfor DPO via a weight-Rotated Preference Optimization (RoPO) method, which\nmerely conducts rotational and magnitude-stretching updates on the weight\nparameters to maintain the hyperspherical energy invariant, thereby preserving\nthe knowledge encoded in the angle between neurons. Extensive experiments\ndemonstrate that our model aligns perfectly with human preferences while\nretaining the original expressive capacity using only 0.0086% of the trainable\nparameters, suggesting an effective regularization against overfitting.\nSpecifically, RoPO outperforms DPO by up to 10 points on MT-Bench and by up to\n2.8 points on AlpacaEval 2, while enhancing the generation diversity by an\naverage of 6 points.",
      "tldr_zh": "本研究针对直接偏好优化(DPO)算法的过度拟合问题——即模型在不喜欢的样本上过度适应，导致生成内容过长且缺乏多样性——提出了一种正交微调方法。作者引入weight-Rotated Preference Optimization (RoPO)，通过仅对权重参数进行旋转和幅度拉伸更新来保持超球面能量不变，从而保留神经元之间的角度知识，同时作为有效的正则化策略。实验结果显示，RoPO 在 MT-Bench 上比 DPO 高出 10 分、在 AlpacaEval 2 上高出 2.8 分，并提高了生成多样性平均 6 分，同时仅使用 0.0086% 的可训练参数，实现了更好的偏好对齐和知识保留。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14836v2",
      "published_date": "2024-09-23 09:09:16 UTC",
      "updated_date": "2024-09-24 03:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:52:31.991722"
    },
    {
      "arxiv_id": "2409.14830v1",
      "title": "Identify As A Human Does: A Pathfinder of Next-Generation Anti-Cheat Framework for First-Person Shooter Games",
      "title_zh": "像人类一样识别：下一代反作弊框架的探路者，用于第一人称射击游戏",
      "authors": [
        "Jiayi Zhang",
        "Chenxin Sun",
        "Yue Gu",
        "Qingyu Zhang",
        "Jiayi Lin",
        "Xiaojiang Du",
        "Chenxiong Qian"
      ],
      "abstract": "The gaming industry has experienced substantial growth, but cheating in\nonline games poses a significant threat to the integrity of the gaming\nexperience. Cheating, particularly in first-person shooter (FPS) games, can\nlead to substantial losses for the game industry. Existing anti-cheat solutions\nhave limitations, such as client-side hardware constraints, security risks,\nserver-side unreliable methods, and both-sides suffer from a lack of\ncomprehensive real-world datasets. To address these limitations, the paper\nproposes HAWK, a server-side FPS anti-cheat framework for the popular game\nCS:GO. HAWK utilizes machine learning techniques to mimic human experts'\nidentification process, leverages novel multi-view features, and it is equipped\nwith a well-defined workflow. The authors evaluate HAWK with the first large\nand real-world datasets containing multiple cheat types and cheating\nsophistication, and it exhibits promising efficiency and acceptable overheads,\nshorter ban times compared to the in-use anti-cheat, a significant reduction in\nmanual labor, and the ability to capture cheaters who evaded official\ninspections.",
      "tldr_zh": "这篇论文针对在线FPS（First-Person Shooter）游戏中的作弊问题，提出了一种下一代反作弊框架HAWK，以解决现有解决方案的局限性，如客户端硬件限制、安全风险和服务端不可靠方法。HAWK采用机器学习技术模仿人类专家的识别过程，结合新型多视图特征和明确的工作流程，实现服务端部署并针对CS:GO游戏进行优化。实验结果显示，HAWK在首个大型真实数据集上表现出色，显著提高了检测效率、缩短了封禁时间、减少了手动劳动，并能捕捉官方检查漏网的作弊者。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14830v1",
      "published_date": "2024-09-23 09:00:07 UTC",
      "updated_date": "2024-09-23 09:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:52:43.883214"
    },
    {
      "arxiv_id": "2409.14826v3",
      "title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Qinzhuo Wu",
        "Wei Liu",
        "Jian Luan",
        "Bin Wang"
      ],
      "abstract": "Recently, tool-augmented LLMs have gained increasing attention. Given an\ninstruction, tool-augmented LLMs can interact with various external tools in\nmultiple rounds and provide a final answer. However, previous LLMs were trained\non overly detailed instructions, which included API names or parameters, while\nreal users would not explicitly mention these API details. This leads to a gap\nbetween trained LLMs and real-world scenarios. In addition, most works ignore\nwhether the interaction process follows the instruction. To address these\nissues, we constructed a training dataset called MGToolBench, which contains\nstatement and category-level instructions to better reflect real-world\nscenarios. In addition, we propose ToolPlanner, a two-stage reinforcement\nlearning framework that utilizes path planning and two feedback mechanisms to\nenhance the LLM's task completion and instruction-following capabilities.\nExperimental results show that ToolPlanner significantly improves the Match\nRate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA\nmodel. Human evaluation verifies that the multi-granularity instructions can\nbetter align with users' usage habits. Our data and code will be released upon\nacceptance.",
      "tldr_zh": "该论文针对工具增强型 LLMs 在处理真实指令时的局限性（如用户不明确指定 API 细节和交互过程不遵循指令），构建了 MGToolBench 数据集，该数据集包含 statement 和 category-level 指令以更好地模拟实际场景。论文提出 ToolPlanner，一种两阶段强化学习框架，结合 path planning 和两种反馈机制，提升了 LLMs 的任务完成和指令遵循能力。实验结果显示，ToolPlanner 相比 SOTA 模型提高了 Match Rate 26.8%、Pass Rate 20.2% 和 Win Rate 5.6%，并通过人类评估证实了多粒度指令更符合用户习惯。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14826v3",
      "published_date": "2024-09-23 08:58:48 UTC",
      "updated_date": "2024-11-04 02:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:52:55.470733"
    },
    {
      "arxiv_id": "2409.14821v1",
      "title": "Towards Real-world Deployment of NILM Systems: Challenges and Practices",
      "title_zh": "迈向 NILM 系统的真实世界部署：挑战和实践",
      "authors": [
        "Junyu Xue",
        "Yu Zhang",
        "Xudong Wang",
        "Yi Wang",
        "Guoming Tang"
      ],
      "abstract": "Non-intrusive load monitoring (NILM), as a key load monitoring technology,\ncan much reduce the deployment cost of traditional power sensors. Previous\nresearch has largely focused on developing cloud-exclusive NILM algorithms,\nwhich often result in high computation costs and significant service delays. To\naddress these issues, we propose a three-tier framework to enhance the\nreal-world applicability of NILM systems through edge-cloud collaboration.\nConsidering the computational resources available at both the edge and cloud,\nwe implement a lightweight NILM model at the edge and a deep learning based\nmodel at the cloud, respectively. In addition to the differential model\nimplementations, we also design a NILM-specific deployment scheme that\nintegrates Gunicorn and NGINX to bridge the gap between theoretical algorithms\nand practical applications. To verify the effectiveness of the proposed\nframework, we apply real-world NILM scenario settings and implement the entire\nprocess of data acquisition, model training, and system deployment. The results\ndemonstrate that our framework can achieve high decomposition accuracy while\nsignificantly reducing the cloud workload and communication overhead under\npractical considerations.",
      "tldr_zh": "该论文探讨了非入侵式负载监控（NILM）系统的实际部署挑战，提出一个三层边云协作框架，以解决传统云端独占算法带来的高计算成本和服务延迟问题。该框架在边端部署轻量级NILM模型，在云端使用基于深度学习的模型，并设计了整合Gunicorn和NGINX的特定部署方案，实现算法与实际应用的无缝连接。通过真实场景测试，包括数据采集、模型训练和系统部署，结果显示该框架在保持高分解准确性的同时，显著降低了云端工作负载和通信开销。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14821v1",
      "published_date": "2024-09-23 08:54:05 UTC",
      "updated_date": "2024-09-23 08:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:53:07.499138"
    },
    {
      "arxiv_id": "2409.14820v1",
      "title": "Past Meets Present: Creating Historical Analogy with Large Language Models",
      "title_zh": "过去遇见现在：使用大型语言模型创建历史类比",
      "authors": [
        "Nianqi Li",
        "Siyu Yuan",
        "Jiangjie Chen",
        "Jiaqing Liang",
        "Feng Wei",
        "Zujie Liang",
        "Deqing Yang",
        "Yanghua Xiao"
      ],
      "abstract": "Historical analogies, which compare known past events with contemporary but\nunfamiliar events, are important abilities that help people make decisions and\nunderstand the world. However, research in applied history suggests that people\nhave difficulty finding appropriate analogies. And previous studies in the AI\ncommunity have also overlooked historical analogies. To fill this gap, in this\npaper, we focus on the historical analogy acquisition task, which aims to\nacquire analogous historical events for a given event. We explore retrieval and\ngeneration methods for acquiring historical analogies based on different large\nlanguage models (LLMs). Furthermore, we propose a self-reflection method to\nmitigate hallucinations and stereotypes when LLMs generate historical\nanalogies. Through human evaluations and our specially designed automatic\nmulti-dimensional assessment, we find that LLMs generally have a good potential\nfor historical analogies. And the performance of the models can be further\nimproved by using our self-reflection method.",
      "tldr_zh": "本论文探讨了使用大型语言模型(LLMs)创建历史类比的问题，该方法通过比较已知历史事件与当代事件，帮助人们决策和理解世界。研究引入了历史类比获取任务，探索了基于LLMs的检索和生成方法，并提出自反(self-reflection)方法来减轻模型的幻觉和刻板印象。通过人类评估和自动多维度评估，结果显示LLMs在历史类比方面具有良好潜力，且自反方法显著提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14820v1",
      "published_date": "2024-09-23 08:52:09 UTC",
      "updated_date": "2024-09-23 08:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:53:20.128087"
    },
    {
      "arxiv_id": "2409.14818v2",
      "title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Qinzhuo Wu",
        "Weikai Xu",
        "Wei Liu",
        "Tao Tan",
        "Jianfeng Liu",
        "Ang Li",
        "Jian Luan",
        "Bin Wang",
        "Shuo Shang"
      ],
      "abstract": "Recently, mobile AI agents based on VLMs have been gaining increasing\nattention. These works typically utilize VLM as a foundation, fine-tuning it\nwith instruction-based mobile datasets. However, these VLMs are typically\npre-trained on general-domain data, which often results in a lack of\nfundamental capabilities specific to the mobile domain. Therefore, they may\nstruggle to recognize specific UI elements and understand intra-UI fine-grained\ninformation. In addition, the current fine-tuning task focuses on interacting\nwith the most relevant element for the given instruction. These fine-tuned VLMs\nmay still ignore the relationships between UI pages, neglect the roles of\nelements in page transitions and lack inter-UI understanding. To address\nissues, we propose a VLM called MobileVLM, which includes two additional\npre-training stages to enhance both intra- and inter-UI understanding. We\ndefined four UI-based pre-training tasks, enabling the model to better perceive\nfine-grained elements and capture page transition actions. To address the lack\nof mobile pre-training data, we built a large Chinese mobile dataset Mobile3M\nfrom scratch, which contains 3 million UI pages, and real-world transition\nactions, forming a directed graph structure. Experimental results show\nMobileVLM excels on both our test set and public mobile benchmarks,\noutperforming existing VLMs.",
      "tldr_zh": "该论文提出 MobileVLM，一种视觉语言模型（VLMs），旨在解决现有模型在移动领域中 intra-UI（页面内部）和 inter-UI（页面间）理解的不足问题。MobileVLM 通过添加两个预训练阶段和定义四个 UI-based 预训练任务，提升了对细粒度 UI 元素的感知和页面过渡动作的捕捉，并构建了大规模中文数据集 Mobile3M（包含 3 百万 UI 页面和真实过渡动作，形成有向图结构）。实验结果表明，MobileVLM 在自有测试集和公共移动基准上表现出色，优于现有 VLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14818v2",
      "published_date": "2024-09-23 08:47:54 UTC",
      "updated_date": "2024-10-03 05:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:53:31.907740"
    },
    {
      "arxiv_id": "2409.14816v2",
      "title": "VARADE: a Variational-based AutoRegressive model for Anomaly Detection on the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Alessio Mascolini",
        "Sebastiano Gaiardelli",
        "Francesco Ponzio",
        "Nicola Dall'Ora",
        "Enrico Macii",
        "Sara Vinco",
        "Santa Di Cataldo",
        "Franco Fummi"
      ],
      "abstract": "Detecting complex anomalies on massive amounts of data is a crucial task in\nIndustry 4.0, best addressed by deep learning. However, available solutions are\ncomputationally demanding, requiring cloud architectures prone to latency and\nbandwidth issues. This work presents VARADE, a novel solution implementing a\nlight autoregressive framework based on variational inference, which is best\nsuited for real-time execution on the edge. The proposed approach was validated\non a robotic arm, part of a pilot production line, and compared with several\nstate-of-the-art algorithms, obtaining the best trade-off between anomaly\ndetection accuracy, power consumption and inference frequency on two different\nedge platforms.",
      "tldr_zh": "这篇论文提出了VARADE，一种基于variational inference的轻量级autoregressive模型，用于工业4.0环境中边缘计算的异常检测，以解决现有深度学习方法计算密集且依赖云架构导致的延迟问题。该模型设计为实时执行，并通过在机器人臂试点生产线上的实验进行验证。与多种最先进算法相比，VARADE在两个不同边缘平台上实现了异常检测准确率、功耗和推理频率的最佳权衡平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14816v2",
      "published_date": "2024-09-23 08:46:15 UTC",
      "updated_date": "2024-09-26 09:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:53:43.755898"
    },
    {
      "arxiv_id": "2410.11843v5",
      "title": "From Commands to Prompts: LLM-based Semantic File System for AIOS",
      "title_zh": "翻译失败",
      "authors": [
        "Zeru Shi",
        "Kai Mei",
        "Mingyu Jin",
        "Yongye Su",
        "Chaoji Zuo",
        "Wenyue Hua",
        "Wujiang Xu",
        "Yujie Ren",
        "Zirui Liu",
        "Mengnan Du",
        "Dong Deng",
        "Yongfeng Zhang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant potential in the\ndevelopment of intelligent applications and systems such as LLM-based agents\nand agent operating systems (AIOS). However, when these applications and\nsystems interact with the underlying file system, the file system still remains\nthe traditional paradigm: reliant on manual navigation through precise\ncommands. This paradigm poses a bottleneck to the usability of these systems as\nusers are required to navigate complex folder hierarchies and remember cryptic\nfile names. To address this limitation, we propose an LLM-based semantic file\nsystem ( LSFS ) for prompt-driven file management. Unlike conventional\napproaches, LSFS incorporates LLMs to enable users or agents to interact with\nfiles through natural language prompts, facilitating semantic file management.\nAt the macro-level, we develop a comprehensive API set to achieve semantic file\nmanagement functionalities, such as semantic file retrieval, file update\nmonitoring and summarization, and semantic file rollback). At the micro-level,\nwe store files by constructing semantic indexes for them, design and implement\nsyscalls of different semantic operations (e.g., CRUD, group by, join) powered\nby vector database. Our experiments show that LSFS offers significant\nimprovements over traditional file systems in terms of user convenience, the\ndiversity of supported functions, and the accuracy and efficiency of file\noperations. Additionally, with the integration of LLM, our system enables more\nintelligent file management tasks, such as content summarization and version\ncomparison, further enhancing its capabilities.",
      "tldr_zh": "本研究针对传统文件系统依赖手动命令的局限性，提出了一种基于大型语言模型(LLM)的语义文件系统(LSFS)，旨在为智能代理和代理操作系统(AIOS)提供通过自然语言提示进行文件管理的便利方案。LSFS 在宏观层面开发了全面的 API 集，支持语义文件检索、文件更新监控和总结以及语义文件回滚；在微观层面，通过构建语义索引和利用向量数据库实现各种语义操作（如 CRUD、group by、join）。实验结果显示，LSFS 在用户便利性、功能多样性、操作准确性和效率上显著优于传统文件系统，并通过集成 LLM 实现了更高级的任务，如内容总结和版本比较。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by International Conference on Learning Representations\n  2025(ICLR2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.11843v5",
      "published_date": "2024-09-23 08:39:16 UTC",
      "updated_date": "2025-03-19 03:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:53:56.470745"
    },
    {
      "arxiv_id": "2409.14803v1",
      "title": "Benchmarking Edge AI Platforms for High-Performance ML Inference",
      "title_zh": "针对高性能机器学习推理的边缘 AI 平台基准测试",
      "authors": [
        "Rakshith Jayanth",
        "Neelesh Gupta",
        "Viktor Prasanna"
      ],
      "abstract": "Edge computing's growing prominence, due to its ability to reduce\ncommunication latency and enable real-time processing, is promoting the rise of\nhigh-performance, heterogeneous System-on-Chip solutions. While current\napproaches often involve scaling down modern hardware, the performance\ncharacteristics of neural network workloads on these platforms can vary\nsignificantly, especially when it comes to parallel processing, which is a\ncritical consideration for edge deployments. To address this, we conduct a\ncomprehensive study comparing the latency and throughput of various linear\nalgebra and neural network inference tasks across CPU-only, CPU/GPU, and\nCPU/NPU integrated solutions. {We find that the Neural Processing Unit (NPU)\nexcels in matrix-vector multiplication (58.6% faster) and some neural network\ntasks (3.2$\\times$ faster for video classification and large language models).\nGPU outperforms in matrix multiplication (22.6% faster) and LSTM networks\n(2.7$\\times$ faster) while CPU excels at less parallel operations like dot\nproduct. NPU-based inference offers a balance of latency and throughput at\nlower power consumption. GPU-based inference, though more energy-intensive,\nperforms best with large dimensions and batch sizes. We highlight the potential\nof heterogeneous computing solutions for edge AI, where diverse compute units\ncan be strategically leveraged to boost accurate and real-time inference.",
      "tldr_zh": "这篇论文对边缘 AI 平台进行了基准测试，评估了 CPU-only、CPU/GPU 和 CPU/NPU 等异构系统在高性能机器学习（ML）推理任务中的延迟和吞吐量。研究比较了线性代数操作（如矩阵-向量乘法和矩阵乘法）和神经网络任务（如视频分类、大语言模型和 LSTM 网络），发现 NPU 在矩阵-向量乘法上比其他方案快 58.6%，并在某些神经网络任务上提升 3.2 倍。GPU 在矩阵乘法和 LSTM 网络上表现出色，分别快 22.6% 和 2.7 倍，而 CPU 更适合非并行操作如点积。总体结论是，异构计算解决方案能优化延迟、吞吐量和功耗，提供更高效的边缘 AI 实时推理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14803v1",
      "published_date": "2024-09-23 08:27:27 UTC",
      "updated_date": "2024-09-23 08:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:54:10.978946"
    },
    {
      "arxiv_id": "2409.14800v1",
      "title": "Choose the Final Translation from NMT and LLM hypotheses Using MBR Decoding: HW-TSC's Submission to the WMT24 General MT Shared Task",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanglin Wu",
        "Daimeng Wei",
        "Zongyao Li",
        "Hengchao Shang",
        "Jiaxin Guo",
        "Shaojun Li",
        "Zhiqiang Rao",
        "Yuanchang Luo",
        "Ning Xie",
        "Hao Yang"
      ],
      "abstract": "This paper presents the submission of Huawei Translate Services Center\n(HW-TSC) to the WMT24 general machine translation (MT) shared task, where we\nparticipate in the English to Chinese (en2zh) language pair. Similar to\nprevious years' work, we use training strategies such as regularized dropout,\nbidirectional training, data diversification, forward translation, back\ntranslation, alternated training, curriculum learning, and transductive\nensemble learning to train the neural machine translation (NMT) model based on\nthe deep Transformer-big architecture. The difference is that we also use\ncontinue pre-training, supervised fine-tuning, and contrastive preference\noptimization to train the large language model (LLM) based MT model. By using\nMinimum Bayesian risk (MBR) decoding to select the final translation from\nmultiple hypotheses for NMT and LLM-based MT models, our submission receives\ncompetitive results in the final evaluation.",
      "tldr_zh": "本论文介绍了华为翻译服务中心（HW-TSC）对 WMT24 通用机器翻译共享任务的提交，针对英语到中文（en2zh）语对，结合神经机器翻译 (NMT) 和大型语言模型 (LLM) 的假设生成最终翻译。研究团队使用多种训练策略训练 NMT 模型，包括 regularized dropout、bidirectional training、back translation 和 curriculum learning 等，同时通过 continue pre-training、supervised fine-tuning 和 contrastive preference optimization 训练 LLM 模型。最终，通过 Minimum Bayesian risk (MBR) decoding 从多个假设中选择最佳翻译，该系统在最终评估中取得了竞争性的性能表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, 2 Tables, EMNLP2024",
      "pdf_url": "http://arxiv.org/pdf/2409.14800v1",
      "published_date": "2024-09-23 08:25:37 UTC",
      "updated_date": "2024-09-23 08:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:54:20.717521"
    },
    {
      "arxiv_id": "2409.14796v1",
      "title": "Research on Dynamic Data Flow Anomaly Detection based on Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Liyang Wang",
        "Yu Cheng",
        "Hao Gong",
        "Jiacheng Hu",
        "Xirui Tang",
        "Iris Li"
      ],
      "abstract": "The sophistication and diversity of contemporary cyberattacks have rendered\nthe use of proxies, gateways, firewalls, and encrypted tunnels as a standalone\ndefensive strategy inadequate. Consequently, the proactive identification of\ndata anomalies has emerged as a prominent area of research within the field of\ndata security. The majority of extant studies concentrate on sample equilibrium\ndata, with the consequence that the detection effect is not optimal in the\ncontext of unbalanced data. In this study, the unsupervised learning method is\nemployed to identify anomalies in dynamic data flows. Initially,\nmulti-dimensional features are extracted from real-time data, and a clustering\nalgorithm is utilised to analyse the patterns of the data. This enables the\npotential outliers to be automatically identified. By clustering similar data,\nthe model is able to detect data behaviour that deviates significantly from\nnormal traffic without the need for labelled data. The results of the\nexperiments demonstrate that the proposed method exhibits high accuracy in the\ndetection of anomalies across a range of scenarios. Notably, it demonstrates\nrobust and adaptable performance, particularly in the context of unbalanced\ndata.",
      "tldr_zh": "本研究针对现代网络攻击的复杂性和多样性，指出传统防御措施（如代理、防火墙和加密隧道）不足，并强调主动识别数据异常的重要性。现有方法多聚焦于样本平衡数据，导致在不平衡数据上检测效果不佳；为此，该研究采用无监督学习方法，从实时数据中提取多维特征，并利用聚类算法分析数据模式，以自动识别潜在异常。实验结果显示，该方法在各种场景下表现出高准确率，尤其在不平衡数据环境中具有出色适应性和鲁棒性，从而提升了动态数据流异常检测的效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14796v1",
      "published_date": "2024-09-23 08:19:15 UTC",
      "updated_date": "2024-09-23 08:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:54:32.949675"
    },
    {
      "arxiv_id": "2409.14784v1",
      "title": "SAMEdge: An Edge-cloud Video Analytics Architecture for the Segment Anything Model",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Lu",
        "Siping Shi",
        "Yanting Liu",
        "Dan Wang"
      ],
      "abstract": "As artificial intelligence continues to evolve, it is increasingly capable of\nhandling a wide range of video analytics tasks with merely one large model. One\nof the key foundation technologies is the Segment Anything Model (SAM), which\nallows the video analytics tasks to be determined on the fly according to the\ninput prompts from the user. However, achieving real-time response in video\nanalytics applications is crucial for user experiences due to the limited\ncommunication and computation resources on the edge, especially with SAM, where\nusers may continuously interact by adding or adjusting prompts.\n  In this paper, we propose SAMEdge, a novel edge-cloud computing architecture\ndesigned to support SAM computations for edge users. SAMEdge integrates new\nmodules on the edge and the cloud to maximize analytics accuracy under visual\nprompts and image prompts input with latency constraints. It addresses resource\nchallenges associated with prompt encoding and image encoding by offering a\nvisual prompt transformation algorithm for visual prompts and efficient\nworkload partitioning for image encoding. SAMEdge is implemented by extending\nthe open-source SAM project from Meta AI. We demonstrate the practical\napplication of SAMEdge through a case study on a Visual Tour Guide application.\nOur evaluation indicates that SAMEdge significantly enhances the accuracy of\nthe video analytics application under distinct network bandwidths across\nvarious prompts.",
      "tldr_zh": "该研究提出SAMEdge，一种边缘-云端视频分析架构，针对Segment Anything Model (SAM)优化实时响应问题，以应对边缘设备资源限制和用户互动需求。SAMEdge通过在边缘和云端添加新模块，包括视觉提示转换算法和高效工作负载分区，实现最大化分析准确性同时满足延迟约束。基于Meta AI的开源SAM项目扩展，实验结果显示SAMEdge在不同网络带宽下显著提升视频分析应用的准确性，并通过视觉导游应用案例验证其实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14784v1",
      "published_date": "2024-09-23 07:59:09 UTC",
      "updated_date": "2024-09-23 07:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:54:44.107114"
    },
    {
      "arxiv_id": "2410.01836v1",
      "title": "Temporal Graph Memory Networks For Knowledge Tracing",
      "title_zh": "翻译失败",
      "authors": [
        "Seif Gad",
        "Sherif Abdelfattah",
        "Ghodai Abdelrahman"
      ],
      "abstract": "Tracing a student's knowledge growth given the past exercise answering is a\nvital objective in automatic tutoring systems to customize the learning\nexperience. Yet, achieving this objective is a non-trivial task as it involves\nmodeling the knowledge state across multiple knowledge components (KCs) while\nconsidering their temporal and relational dynamics during the learning process.\nKnowledge tracing methods have tackled this task by either modeling KCs'\ntemporal dynamics using recurrent models or relational dynamics across KCs and\nquestions using graph models. Albeit, there is a lack of methods that could\nlearn joint embedding between relational and temporal dynamics of the task.\nMoreover, many methods that count for the impact of a student's forgetting\nbehavior during the learning process use hand-crafted features, limiting their\ngeneralization on different scenarios. In this paper, we propose a novel method\nthat jointly models the relational and temporal dynamics of the knowledge state\nusing a deep temporal graph memory network. In addition, we propose a generic\ntechnique for representing a student's forgetting behavior using temporal decay\nconstraints on the graph memory module. We demonstrate the effectiveness of our\nproposed method using multiple knowledge tracing benchmarks while comparing it\nto state-of-the-art methods.",
      "tldr_zh": "这篇论文针对知识追踪（Knowledge Tracing）任务，提出了一种新方法来联合建模学生知识状态的 temporal 和 relational dynamics，从而更好地跟踪学习过程。作者开发了深层时间图记忆网络（Temporal Graph Memory Networks），它整合了图模型和时间序列建模，以处理知识组件（KCs）的动态关系。论文还引入了时间衰减约束（temporal decay constraints）来泛化表示学生的遗忘行为，并在多个知识追踪基准上实验证明，该方法比现有最先进方法表现出色。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01836v1",
      "published_date": "2024-09-23 07:47:02 UTC",
      "updated_date": "2024-09-23 07:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:54:56.531970"
    },
    {
      "arxiv_id": "2409.14762v1",
      "title": "Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?",
      "title_zh": "大语言模型在不完整信息场景下是否具有问题解决能力？",
      "authors": [
        "Yuyan Chen",
        "Tianhao Yu",
        "Yueze Li",
        "Songzhou Yan",
        "Sijia Liu",
        "Jiaqing Liang",
        "Yanghua Xiao"
      ],
      "abstract": "The evaluation of the problem-solving capability under incomplete information\nscenarios of Large Language Models (LLMs) is increasingly important,\nencompassing capabilities such as questioning, knowledge search, error\ndetection, and path planning. Current research mainly focus on LLMs'\nproblem-solving capability such as ``Twenty Questions''. However, these kinds\nof games do not require recognizing misleading cues which are necessary in the\nincomplete information scenario. Moreover, the existing game such as ``Who is\nundercover'' are highly subjective, making it challenging for evaluation.\nTherefore, in this paper, we introduce a novel game named BrainKing based on\nthe ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM\ncapabilities under incomplete information scenarios. It requires LLMs to\nidentify target entities with limited yes-or-no questions and potential\nmisleading answers. By setting up easy, medium, and hard difficulty modes, we\ncomprehensively assess the performance of LLMs across various aspects. Our\nresults reveal the capabilities and limitations of LLMs in BrainKing, providing\nsignificant insights of LLM problem-solving levels.",
      "tldr_zh": "本研究评估大型语言模型（LLMs）在不完整信息场景下的问题解决能力，包括提问、知识搜索、错误检测和路径规划等方面。论文引入了一个新游戏BrainKing，结合“Twenty Questions”和“Who is Undercover”，要求LLMs通过有限的“是或否”问题识别目标实体，同时处理潜在误导性答案，并设置易、中、难模式进行全面评估。结果显示，LLMs在BrainKing中表现出一定的能力，但也暴露了显著局限性，为理解其问题解决水平提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2409.14762v1",
      "published_date": "2024-09-23 07:18:02 UTC",
      "updated_date": "2024-09-23 07:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:55:08.038582"
    },
    {
      "arxiv_id": "2409.14759v1",
      "title": "VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nam Hyeon-Woo",
        "Moon Ye-Bin",
        "Wonseok Choi",
        "Lee Hyun",
        "Tae-Hyun Oh"
      ],
      "abstract": "Vision language models (VLMs) have shown promising reasoning capabilities\nacross various benchmarks; however, our understanding of their visual\nperception remains limited. In this work, we propose an eye examination process\nto investigate how a VLM perceives images, specifically focusing on key\nelements of visual recognition, from primitive color and shape to semantic\nlevels. To this end, we introduce a dataset named LENS to guide a VLM to follow\nthe examination and check its readiness. Once the model is ready, we conduct\nthe examination. Through this examination, we quantify and visualize VLMs'\nsensitivities to color and shape, and semantic matching. Our findings reveal\nthat VLMs have varying sensitivity to different colors while consistently\nshowing insensitivity to green across different VLMs. Also, we found different\nshape sensitivity and semantic recognition depending on LLM's capacity despite\nusing the same fixed visual encoder. Our analyses and findings have potential\nto inspire the design of VLMs and the pre-processing of visual input to VLMs\nfor improving application performance.",
      "tldr_zh": "该研究通过提出“眼部检查”过程和LENS数据集，评估视觉语言模型(VLMs)的视觉感知能力，从基本颜色、形状到语义水平进行系统调查。实验结果显示，VLMs对不同颜色的敏感度存在差异，但普遍对绿色不敏感，且形状敏感度和语义识别取决于LLM的容量，即使使用相同的视觉编码器。最终，这些分析为改进VLMs的设计和视觉输入预处理提供了宝贵启发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14759v1",
      "published_date": "2024-09-23 07:15:29 UTC",
      "updated_date": "2024-09-23 07:15:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:55:21.403803"
    },
    {
      "arxiv_id": "2409.14751v1",
      "title": "UniBEVFusion: Unified Radar-Vision BEVFusion for 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Haocheng Zhao",
        "Runwei Guan",
        "Taoyu Wu",
        "Ka Lok Man",
        "Limin Yu",
        "Yutao Yue"
      ],
      "abstract": "4D millimeter-wave (MMW) radar, which provides both height information and\ndense point cloud data over 3D MMW radar, has become increasingly popular in 3D\nobject detection. In recent years, radar-vision fusion models have demonstrated\nperformance close to that of LiDAR-based models, offering advantages in terms\nof lower hardware costs and better resilience in extreme conditions. However,\nmany radar-vision fusion models treat radar as a sparse LiDAR, underutilizing\nradar-specific information. Additionally, these multi-modal networks are often\nsensitive to the failure of a single modality, particularly vision. To address\nthese challenges, we propose the Radar Depth Lift-Splat-Shoot (RDL) module,\nwhich integrates radar-specific data into the depth prediction process,\nenhancing the quality of visual Bird-Eye View (BEV) features. We further\nintroduce a Unified Feature Fusion (UFF) approach that extracts BEV features\nacross different modalities using shared module. To assess the robustness of\nmulti-modal models, we develop a novel Failure Test (FT) ablation experiment,\nwhich simulates vision modality failure by injecting Gaussian noise. We conduct\nextensive experiments on the View-of-Delft (VoD) and TJ4D datasets. The results\ndemonstrate that our proposed Unified BEVFusion (UniBEVFusion) network\nsignificantly outperforms state-of-the-art models on the TJ4D dataset, with\nimprovements of 1.44 in 3D and 1.72 in BEV object detection accuracy.",
      "tldr_zh": "本文提出 UniBEVFusion，一种统一的雷达-视觉 BEV 融合框架，用于提升 3D 对象检测性能，针对现有模型对 4D MMW radar 特定信息利用不足和对视觉模态失败敏感的问题。关键创新包括 Radar Depth Lift-Splat-Shoot (RDL) 模块，将雷达数据整合到深度预测中优化 BEV 特征，以及 Unified Feature Fusion (UFF) 方法，通过共享模块提取多模态特征；此外，引入 Failure Test (FT) 实验模拟视觉失败以评估鲁棒性。在 VoD 和 TJ4D 数据集上的实验表明，UniBEVFusion 显著优于现有模型，在 TJ4D 上将 3D 对象检测准确率提高 1.44，并将 BEV 准确率提高 1.72。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figues, conference",
      "pdf_url": "http://arxiv.org/pdf/2409.14751v1",
      "published_date": "2024-09-23 06:57:27 UTC",
      "updated_date": "2024-09-23 06:57:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:55:35.285753"
    },
    {
      "arxiv_id": "2409.16326v1",
      "title": "Automated Spatio-Temporal Weather Modeling for Load Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Julie Keisler",
        "Margaux Bregere"
      ],
      "abstract": "Electricity is difficult to store, except at prohibitive cost, and therefore\nthe balance between generation and load must be maintained at all times.\nElectricity is traditionally managed by anticipating demand and intermittent\nproduction (wind, solar) and matching flexible production (hydro, nuclear, coal\nand gas). Accurate forecasting of electricity load and renewable production is\ntherefore essential to ensure grid performance and stability. Both are highly\ndependent on meteorological variables (temperature, wind, sunshine). These\ndependencies are complex and difficult to model. On the one hand, spatial\nvariations do not have a uniform impact because population, industry, and wind\nand solar farms are not evenly distributed across the territory. On the other\nhand, temporal variations can have delayed effects on load (due to the thermal\ninertia of buildings). With access to observations from different weather\nstations and simulated data from meteorological models, we believe that both\nphenomena can be modeled together. In today's state-of-the-art load forecasting\nmodels, the spatio-temporal modeling of the weather is fixed. In this work, we\naim to take advantage of the automated representation and spatio-temporal\nfeature extraction capabilities of deep neural networks to improve\nspatio-temporal weather modeling for load forecasting. We compare our deep\nlearning-based methodology with the state-of-the-art on French national load.\nThis methodology could also be fully adapted to forecasting renewable energy\nproduction.",
      "tldr_zh": "本研究针对电力负载预测的挑战，强调了气象变量（如温度、风速、日照）对需求和可再生能源生产的复杂空间-时间依赖性，这些依赖性因人口分布和建筑热惰性等因素而难以建模。作者提出了一种基于深度神经网络的自动时空气象建模方法，利用观测数据和模拟数据来提取特征，从而改进负载预测的准确性。实验结果显示，该方法在法国国家负载预测中优于现有技术，并可轻松适应可再生能源生产的预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16326v1",
      "published_date": "2024-09-23 06:55:57 UTC",
      "updated_date": "2024-09-23 06:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:55:47.536753"
    },
    {
      "arxiv_id": "2409.14747v5",
      "title": "Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Dasol Choi",
        "Dongbin Na"
      ],
      "abstract": "With the explosive growth of deep learning applications and increasing\nprivacy concerns, the right to be forgotten has become a critical requirement\nin various AI industries. For example, given a facial recognition system, some\nindividuals may wish to remove their personal data that might have been used in\nthe training phase. Unfortunately, deep neural networks sometimes unexpectedly\nleak personal identities, making this removal challenging. While recent machine\nunlearning algorithms aim to enable models to forget specific data, we identify\nan unintended utility drop-correlation collapse-in which the essential\ncorrelations between image features and true labels weaken during the\nforgetting process. To address this challenge, we propose Distribution-Level\nFeature Distancing (DLFD), a novel method that efficiently forgets instances\nwhile preserving task-relevant feature correlations. Our method synthesizes\ndata samples by optimizing the feature distribution to be distinctly different\nfrom that of forget samples, achieving effective results within a single\ntraining epoch. Through extensive experiments on facial recognition datasets,\nwe demonstrate that our approach significantly outperforms state-of-the-art\nmachine unlearning methods in both forgetting performance and model utility\npreservation.",
      "tldr_zh": "随着深度学习应用增长和隐私担忧日益突出，机器遗忘(Machine Unlearning)技术变得至关重要，但现有方法在遗忘特定数据时往往导致模型效用下降，即图像特征与真实标签的相关性减弱。为此，本文提出Distribution-Level Feature Distancing (DLFD)，一种新颖方法，通过合成数据样本并优化特征分布使其与遗忘样本明显不同，从而在单次训练周期内高效实现数据遗忘同时保留任务相关特征。通过在面部识别数据集上的广泛实验，DLFD在遗忘性能和模型效用保留方面显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures, AAAI 2025 camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2409.14747v5",
      "published_date": "2024-09-23 06:51:10 UTC",
      "updated_date": "2024-12-19 00:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:00.772444"
    },
    {
      "arxiv_id": "2409.14741v2",
      "title": "Less yet robust: crucial region selection for scene recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqi Zhang",
        "Mengxuan Wang",
        "Jingyao Wang",
        "Lingyu Si",
        "Changwen Zheng",
        "Fanjiang Xu"
      ],
      "abstract": "Scene recognition, particularly for aerial and underwater images, often\nsuffers from various types of degradation, such as blurring or overexposure.\nPrevious works that focus on convolutional neural networks have been shown to\nbe able to extract panoramic semantic features and perform well on scene\nrecognition tasks. However, low-quality images still impede model performance\ndue to the inappropriate use of high-level semantic features. To address these\nchallenges, we propose an adaptive selection mechanism to identify the most\nimportant and robust regions with high-level features. Thus, the model can\nperform learning via these regions to avoid interference. implement a learnable\nmask in the neural network, which can filter high-level features by assigning\nweights to different regions of the feature matrix. We also introduce a\nregularization term to further enhance the significance of key high-level\nfeature regions. Different from previous methods, our learnable matrix pays\nextra attention to regions that are important to multiple categories but may\ncause misclassification and sets constraints to reduce the influence of such\nregions.This is a plug-and-play architecture that can be easily extended to\nother methods. Additionally, we construct an Underwater Geological Scene\nClassification dataset to assess the effectiveness of our model. Extensive\nexperimental results demonstrate the superiority and robustness of our proposed\nmethod over state-of-the-art techniques on two datasets.",
      "tldr_zh": "本研究针对场景识别（scene recognition）中航空和水下图像的退化问题（如模糊或过曝），提出了一种自适应选择机制，通过识别最重要的鲁棒区域来提升模型性能。方法包括在神经网络中使用可学习的掩码（learnable mask）来过滤高层次特征，并引入正则化项（regularization term）以增强关键区域的重要性，同时减少对多个类别的关键但可能导致误分类的区域影响。该框架是一个即插即用的（plug-and-play）架构，并在新构建的水下地质场景分类数据集（Underwater Geological Scene Classification dataset）上进行实验，结果显示该方法在两个数据集上优于现有最先进技术，显著提高了模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14741v2",
      "published_date": "2024-09-23 06:39:35 UTC",
      "updated_date": "2024-10-20 11:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:15.119973"
    },
    {
      "arxiv_id": "2409.14740v2",
      "title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information",
      "title_zh": "ToxiCraft：一种新型框架，用于有害信息的合成生成",
      "authors": [
        "Zheng Hui",
        "Zhaoxiao Guo",
        "Hang Zhao",
        "Juanyong Duan",
        "Congrui Huang"
      ],
      "abstract": "In different NLP tasks, detecting harmful content is crucial for online\nenvironments, especially with the growing influence of social media. However,\nprevious research has two main issues: 1) a lack of data in low-resource\nsettings, and 2) inconsistent definitions and criteria for judging harmful\ncontent, requiring classification models to be robust to spurious features and\ndiverse. We propose Toxicraft, a novel framework for synthesizing datasets of\nharmful information to address these weaknesses. With only a small amount of\nseed data, our framework can generate a wide variety of synthetic, yet\nremarkably realistic, examples of toxic information. Experimentation across\nvarious datasets showcases a notable enhancement in detection model robustness\nand adaptability, surpassing or close to the gold labels.",
      "tldr_zh": "该研究针对 NLP 任务中检测有害内容面临的挑战，包括低资源设置下数据不足和有害内容定义不一致的问题，提出了一种新框架 ToxiCraft。ToxiCraft 通过少量种子数据合成多样且高度真实的毒性信息数据集，从而增强模型对虚假特征(spurious features)的鲁棒性。实验结果显示，该框架显著提高了检测模型的鲁棒性和适应性，在多个数据集上表现优于或接近黄金标准(gold labels)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.14740v2",
      "published_date": "2024-09-23 06:36:57 UTC",
      "updated_date": "2025-04-14 18:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:22.502823"
    },
    {
      "arxiv_id": "2409.15395v1",
      "title": "Parse Trees Guided LLM Prompt Compression",
      "title_zh": "基于解析树的 LLM 提示压缩",
      "authors": [
        "Wenhao Mao",
        "Chengbin Hou",
        "Tianyu Zhang",
        "Xinyu Lin",
        "Ke Tang",
        "Hairong Lv"
      ],
      "abstract": "Offering rich contexts to Large Language Models (LLMs) has shown to boost the\nperformance in various tasks, but the resulting longer prompt would increase\nthe computational cost and might exceed the input limit of LLMs. Recently, some\nprompt compression methods have been suggested to shorten the length of prompts\nby using language models to generate shorter prompts or by developing\ncomputational models to select important parts of original prompt. The\ngenerative compression methods would suffer from issues like hallucination,\nwhile the selective compression methods have not involved linguistic rules and\noverlook the global structure of prompt. To this end, we propose a novel\nselective compression method called PartPrompt. It first obtains a parse tree\nfor each sentence based on linguistic rules, and calculates local information\nentropy for each node in a parse tree. These local parse trees are then\norganized into a global tree according to the hierarchical structure such as\nthe dependency of sentences, paragraphs, and sections. After that, the\nroot-ward propagation and leaf-ward propagation are proposed to adjust node\nvalues over the global tree. Finally, a recursive algorithm is developed to\nprune the global tree based on the adjusted node values. The experiments show\nthat PartPrompt receives the state-of-the-art performance across various\ndatasets, metrics, compression ratios, and target LLMs for inference. The\nin-depth ablation studies confirm the effectiveness of designs in PartPrompt,\nand other additional experiments also demonstrate its superiority in terms of\nthe coherence of compressed prompts and in the extreme long prompt scenario.",
      "tldr_zh": "本研究针对大语言模型（LLMs）的提示压缩问题，提出了一种新型选择式方法PartPrompt，以解决现有生成式方法（如幻觉问题）和选择式方法（如忽略语言规则和全局结构）的不足。该方法首先为每个句子构建解析树（parse tree），计算节点局部信息熵，然后将局部树组织成全局树，并通过根向传播（root-ward propagation）和叶向传播（leaf-ward propagation）调整节点值，最后使用递归算法修剪全局树以生成简洁提示。实验结果显示，PartPrompt在各种数据集、指标、压缩比率和目标LLMs上实现了最先进性能，并在消融研究中证明了其设计的有效性，尤其在压缩提示的连贯性和极端长提示场景中表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15395v1",
      "published_date": "2024-09-23 06:21:40 UTC",
      "updated_date": "2024-09-23 06:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:36.582230"
    },
    {
      "arxiv_id": "2409.14729v2",
      "title": "PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Yu",
        "Yangguang Shao",
        "Hanwen Miao",
        "Junzheng Shi"
      ],
      "abstract": "Large Language Models (LLMs) have gained widespread use in various\napplications due to their powerful capability to generate human-like text.\nHowever, prompt injection attacks, which involve overwriting a model's original\ninstructions with malicious prompts to manipulate the generated text, have\nraised significant concerns about the security and reliability of LLMs.\nEnsuring that LLMs are robust against such attacks is crucial for their\ndeployment in real-world applications, particularly in critical tasks.\n  In this paper, we propose PROMPTFUZZ, a novel testing framework that\nleverages fuzzing techniques to systematically assess the robustness of LLMs\nagainst prompt injection attacks. Inspired by software fuzzing, PROMPTFUZZ\nselects promising seed prompts and generates a diverse set of prompt injections\nto evaluate the target LLM's resilience. PROMPTFUZZ operates in two stages: the\nprepare phase, which involves selecting promising initial seeds and collecting\nfew-shot examples, and the focus phase, which uses the collected examples to\ngenerate diverse, high-quality prompt injections. Using PROMPTFUZZ, we can\nuncover more vulnerabilities in LLMs, even those with strong defense prompts.\n  By deploying the generated attack prompts from PROMPTFUZZ in a real-world\ncompetition, we achieved the 7th ranking out of over 4000 participants (top\n0.14%) within 2 hours. Additionally, we construct a dataset to fine-tune LLMs\nfor enhanced robustness against prompt injection attacks. While the fine-tuned\nmodel shows improved robustness, PROMPTFUZZ continues to identify\nvulnerabilities, highlighting the importance of robust testing for LLMs. Our\nwork emphasizes the critical need for effective testing tools and provides a\npractical framework for evaluating and improving the robustness of LLMs against\nprompt injection attacks.",
      "tldr_zh": "该论文提出PROMPTFUZZ框架，利用fuzzing技术系统测试LLMs对prompt injection attacks的鲁棒性，以解决模型安全问题。框架分为两个阶段：prepare phase选择种子提示并收集few-shot例子，以及focus phase生成多样化的prompt injections，从而评估和发现LLMs的漏洞。实验结果显示，在真实竞赛中，PROMPTFUZZ帮助团队在4000多名参与者中排名第7（前0.14%），并通过构建数据集微调LLMs提升了鲁棒性，但框架仍能识别剩余漏洞，强调了有效测试工具在LLMs部署中的关键作用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14729v2",
      "published_date": "2024-09-23 06:08:32 UTC",
      "updated_date": "2025-04-03 23:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:58.919967"
    },
    {
      "arxiv_id": "2409.15394v1",
      "title": "Neural Control Variates with Automatic Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Zilu Li",
        "Guandao Yang",
        "Qingqing Zhao",
        "Xi Deng",
        "Leonidas Guibas",
        "Bharath Hariharan",
        "Gordon Wetzstein"
      ],
      "abstract": "This paper presents a method to leverage arbitrary neural network\narchitecture for control variates. Control variates are crucial in reducing the\nvariance of Monte Carlo integration, but they hinge on finding a function that\nboth correlates with the integrand and has a known analytical integral.\nTraditional approaches rely on heuristics to choose this function, which might\nnot be expressive enough to correlate well with the integrand. Recent research\nalleviates this issue by modeling the integrands with a learnable parametric\nmodel, such as a neural network. However, the challenge remains in creating an\nexpressive parametric model with a known analytical integral. This paper\nproposes a novel approach to construct learnable parametric control variates\nfunctions from arbitrary neural network architectures. Instead of using a\nnetwork to approximate the integrand directly, we employ the network to\napproximate the anti-derivative of the integrand. This allows us to use\nautomatic differentiation to create a function whose integration can be\nconstructed by the antiderivative network. We apply our method to solve partial\ndifferential equations using the Walk-on-sphere algorithm. Our results indicate\nthat this approach is unbiased and uses various network architectures to\nachieve lower variance than other control variate methods.",
      "tldr_zh": "本文提出了一种名为“Neural Control Variates with Automatic Integration”的方法，利用任意神经网络架构作为控制变量，以降低 Monte Carlo integration 的方差。该方法通过让神经网络近似积分函数的反导数（anti-derivative），并借助自动微分（automatic differentiation）构建可集成的函数，从而克服传统控制变量在表达性和解析积分方面的局限。实验结果显示，该方法在解决 partial differential equations 时，通过 Walk-on-sphere 算法实现了无偏估计，并比其他控制变量方法取得了更低的方差，为高效数值积分提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GR",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15394v1",
      "published_date": "2024-09-23 06:04:28 UTC",
      "updated_date": "2024-09-23 06:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:56:59.881667"
    },
    {
      "arxiv_id": "2409.14724v1",
      "title": "EDSNet: Efficient-DSNet for Video Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Prasad",
        "Pranav Jeevan",
        "Amit Sethi"
      ],
      "abstract": "Current video summarization methods largely rely on transformer-based\narchitectures, which, due to their quadratic complexity, require substantial\ncomputational resources. In this work, we address these inefficiencies by\nenhancing the Direct-to-Summarize Network (DSNet) with more resource-efficient\ntoken mixing mechanisms. We show that replacing traditional attention with\nalternatives like Fourier, Wavelet transforms, and Nystr\\\"omformer improves\nefficiency and performance. Furthermore, we explore various pooling strategies\nwithin the Regional Proposal Network, including ROI pooling, Fast Fourier\nTransform pooling, and flat pooling. Our experimental results on TVSum and\nSumMe datasets demonstrate that these modifications significantly reduce\ncomputational costs while maintaining competitive summarization performance.\nThus, our work offers a more scalable solution for video summarization tasks.",
      "tldr_zh": "本研究针对视频摘要中基于 transformer 架构的高计算复杂度问题，提出了一种高效的 EDSNet 模型，该模型是对 Direct-to-Summarize Network (DSNet) 的增强版本，使用更高效的 token mixing 机制如 Fourier、Wavelet transforms 和 Nyströformer 来替代传统 attention。论文还探索了多种 pooling 策略，包括 ROI pooling、Fast Fourier Transform pooling 和 flat pooling，以优化资源利用。实验结果显示，在 TVSum 和 SumMe 数据集上，EDSNet 显著降低了计算成本，同时保持了与基线模型相当的摘要性能，从而为视频摘要任务提供了一个更可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.4.10; I.4.0; I.4.9; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14724v1",
      "published_date": "2024-09-23 05:43:37 UTC",
      "updated_date": "2024-09-23 05:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:57:12.460922"
    },
    {
      "arxiv_id": "2409.14710v2",
      "title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning",
      "title_zh": "ERABAL：通过边界感知学习增强角色扮演代理",
      "authors": [
        "Yihong Tang",
        "Jiao Ou",
        "Che Liu",
        "Fuzheng Zhang",
        "Di Zhang",
        "Kun Gai"
      ],
      "abstract": "Role-playing is an emerging application in the field of Human-Computer\nInteraction (HCI), primarily implemented through the alignment training of a\nlarge language model (LLM) with assigned characters. Despite significant\nprogress, role-playing agents (RPLAs) still struggle with maintaining\nrole-consistency across conversations, particularly when confronted with\nboundary queries subtly related to character attributes. In this paper, we\npresent ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities\nthrough boundary-aware learning. ERABAL encompasses a generation pipeline for\nrole-specific dialogues and a concomitant methodology for alignment training.\nThrough comprehensive evaluations, we demonstrate that ERABAL is both efficient\nand effective. By training with significantly fewer dialogues than those used\nin leading approaches, ERABAL achieves notable improvements across\nWikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared\nto the generalist baseline models. Our code and datasets will be made publicly\navailable to support further research.",
      "tldr_zh": "该论文针对角色扮演代理(RPLAs)在处理与角色属性相关的边界查询时，难以维持角色一致性的问题，提出ERABAL框架，通过边界感知学习(Boundary-Aware Learning)来提升RPLAs的能力。该框架包括一个生成角色特定对话的管道和相应的对齐训练方法，使训练过程更高效。实验结果显示，ERABAL在使用显著更少对话的情况下，在WikiRoleEval、CharacterEval和MT-Bench的角色扮演子集上，比通用基线模型取得了显著改善，并计划公开代码和数据集以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.10618",
      "pdf_url": "http://arxiv.org/pdf/2409.14710v2",
      "published_date": "2024-09-23 05:12:13 UTC",
      "updated_date": "2024-10-22 09:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:57:24.730157"
    },
    {
      "arxiv_id": "2409.14705v1",
      "title": "Target-Aware Language Modeling via Granular Data Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Ernie Chang",
        "Pin-Jie Lin",
        "Yang Li",
        "Changsheng Zhao",
        "Daeil Kim",
        "Rastislav Rabatin",
        "Zechun Liu",
        "Yangyang Shi",
        "Vikas Chandra"
      ],
      "abstract": "Language model pretraining generally targets a broad range of use cases and\nincorporates data from diverse sources. However, there are instances where we\ndesire a model that excels in specific areas without markedly compromising\nperformance in other areas. A cost-effective and straightforward approach is\nsampling with low-dimensional data features, which allows to select large-scale\npretraining data for domain-specific use cases. In this work, we revisit\nimportance sampling with n-gram features consisting of multi-granular tokens,\nwhich strikes a good balance between sentence compression and representation\ncapabilities. We observed the sampled data to have a high correlation with the\ntarget downstream task performance while preserving its effectiveness on other\ntasks. This leads to the proposed data sampling paradigm where language models\ncan be pretrained more efficiently on selected documents. On eight benchmarks\nwe demonstrate with $\\sim$1% of the data, pretrained models perform on par with\nthe full RefinedWeb data and outperform randomly selected samples for model\nsizes ranging from 125M to 1.5B.",
      "tldr_zh": "该研究提出了一种基于粒度数据采样的目标感知语言建模方法（Target-Aware Language Modeling），旨在让语言模型在特定领域表现出色，同时不显著影响其他领域的性能。方法通过 importance sampling 与多粒度 token 的 n-gram 特征相结合，实现数据采样，从而在句子压缩和表示能力之间取得平衡。实验结果显示，采样的数据与目标下游任务性能高度相关，使用约1%的 RefinedWeb 数据即可使模型在八个基准测试中达到与全数据集相当的水平，并优于随机采样，适用于从125M到1.5B的模型大小。总之，这种高效预训练范式提升了语言模型的针对性和资源利用效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main Conference, 9 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.14705v1",
      "published_date": "2024-09-23 04:52:17 UTC",
      "updated_date": "2024-09-23 04:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:57:36.545231"
    },
    {
      "arxiv_id": "2409.14704v2",
      "title": "VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models",
      "title_zh": "VLEU：",
      "authors": [
        "Jingtao Cao",
        "Zheng Zhang",
        "Hongru Wang",
        "Kam-Fai Wong"
      ],
      "abstract": "Progress in Text-to-Image (T2I) models has significantly improved the\ngeneration of images from textual descriptions. However, existing evaluation\nmetrics do not adequately assess the models' ability to handle a diverse range\nof textual prompts, which is crucial for their generalizability. To address\nthis, we introduce a new metric called Visual Language Evaluation Understudy\n(VLEU). VLEU uses large language models to sample from the visual text domain,\nthe set of all possible input texts for T2I models, to generate a wide variety\nof prompts. The images generated from these prompts are evaluated based on\ntheir alignment with the input text using the CLIP model.VLEU quantifies a\nmodel's generalizability by computing the Kullback-Leibler divergence between\nthe marginal distribution of the visual text and the conditional distribution\nof the images generated by the model. This metric provides a quantitative way\nto compare different T2I models and track improvements during model finetuning.\nOur experiments demonstrate the effectiveness of VLEU in evaluating the\ngeneralization capability of various T2I models, positioning it as an essential\nmetric for future research in text-to-image synthesis.",
      "tldr_zh": "本研究提出了一种新指标Visual Language Evaluation Understudy (VLEU)，用于自动评估Text-to-Image (T2I) 模型的泛化能力，因为现有评估指标无法充分处理模型对多样化文本提示的适应性。VLEU 利用大型语言模型从视觉文本域采样生成各种提示，然后通过CLIP模型评估生成的图像与输入文本的alignment，并计算Kullback-Leibler divergence来量化模型的泛化性，即比较视觉文本的边缘分布与模型生成图像的条件分布。这种方法为比较不同T2I模型和跟踪微调过程提供了量化工具。实验结果证明，VLEU 有效地评估了多种T2I模型的泛化能力，成为文本到图像合成领域未来研究的重要指标。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "I.2.10; I.2.7; I.3.7"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by EMNLP2024(long paper,main conference)",
      "pdf_url": "http://arxiv.org/pdf/2409.14704v2",
      "published_date": "2024-09-23 04:50:36 UTC",
      "updated_date": "2024-11-15 07:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:57:49.084602"
    },
    {
      "arxiv_id": "2410.07150v1",
      "title": "Graph Network Models To Detect Illicit Transactions In Block Chain",
      "title_zh": "图网络模型用于检测区块链中的非法交易",
      "authors": [
        "Hrushyang Adloori",
        "Vaishnavi Dasanapu",
        "Abhijith Chandra Mergu"
      ],
      "abstract": "The use of cryptocurrencies has led to an increase in illicit activities such\nas money laundering, with traditional rule-based approaches becoming less\neffective in detecting and preventing such activities. In this paper, we\npropose a novel approach to tackling this problem by applying graph attention\nnetworks with residual network-like architecture (GAT-ResNet) to detect illicit\ntransactions related to anti-money laundering/combating the financing of\nterrorism (AML/CFT) in blockchains. We train various models on the Elliptic\nBitcoin Transaction dataset, implementing logistic regression, Random Forest,\nXGBoost, GCN, GAT, and our proposed GAT-ResNet model. Our results demonstrate\nthat the GAT-ResNet model has a potential to outperform the existing graph\nnetwork models in terms of accuracy, reliability and scalability. Our research\nsheds light on the potential of graph related machine learning models to\nimprove efforts to combat financial crime and lays the foundation for further\nresearch in this area.",
      "tldr_zh": "本论文针对加密货币引发的非法活动（如洗钱），提出了一种基于图注意力网络与残差网络架构（GAT-ResNet）的图网络模型，用于检测区块链中的非法交易，特别是与反洗钱/反恐融资（AML/CFT）相关。研究者在Elliptic Bitcoin Transaction数据集上训练了多种模型，包括logistic regression、Random Forest、XGBoost、GCN、GAT和GAT-ResNet，并进行比较。结果显示，GAT-ResNet模型在准确性、可靠性和可扩展性方面优于现有图网络模型。该研究强调了图相关机器学习模型在打击金融犯罪方面的潜力，并为未来研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07150v1",
      "published_date": "2024-09-23 04:38:44 UTC",
      "updated_date": "2024-09-23 04:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:58:02.344000"
    },
    {
      "arxiv_id": "2409.15393v1",
      "title": "Approximated Orthogonal Projection Unit: Stabilizing Regression Network Training Using Natural Gradient",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoqi Wang",
        "Chunjie Yang",
        "Siwei Lou"
      ],
      "abstract": "Neural networks (NN) are extensively studied in cutting-edge soft sensor\nmodels due to their feature extraction and function approximation capabilities.\nCurrent research into network-based methods primarily focuses on models'\noffline accuracy. Notably, in industrial soft sensor context, online optimizing\nstability and interpretability are prioritized, followed by accuracy. This\nrequires a clearer understanding of network's training process. To bridge this\ngap, we propose a novel NN named the Approximated Orthogonal Projection Unit\n(AOPU) which has solid mathematical basis and presents superior training\nstability. AOPU truncates the gradient backpropagation at dual parameters,\noptimizes the trackable parameters updates, and enhances the robustness of\ntraining. We further prove that AOPU attains minimum variance estimation (MVE)\nin NN, wherein the truncated gradient approximates the natural gradient (NG).\nEmpirical results on two chemical process datasets clearly show that AOPU\noutperforms other models in achieving stable convergence, marking a significant\nadvancement in soft sensor field.",
      "tldr_zh": "本研究针对神经网络（NN）在软传感器模型中的训练稳定性问题，提出了一种新颖的Approximated Orthogonal Projection Unit (AOPU)，旨在通过截断梯度反向传播并优化可追踪的参数更新来提升训练鲁棒性。AOPU 基于坚实的数学基础，证明其实现了神经网络中的最小方差估计 (MVE)，其中截断梯度近似于自然梯度 (NG)。在两个化学过程数据集上的实证结果显示，AOPU 比其他模型实现了更稳定的收敛性能，推动了软传感器领域的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15393v1",
      "published_date": "2024-09-23 03:42:50 UTC",
      "updated_date": "2024-09-23 03:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:58:15.993135"
    },
    {
      "arxiv_id": "2409.14683v1",
      "title": "Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Clavié",
        "Antoine Chaffin",
        "Griffin Adams"
      ],
      "abstract": "Over the last few years, multi-vector retrieval methods, spearheaded by\nColBERT, have become an increasingly popular approach to Neural IR. By storing\nrepresentations at the token level rather than at the document level, these\nmethods have demonstrated very strong retrieval performance, especially in\nout-of-domain settings. However, the storage and memory requirements necessary\nto store the large number of associated vectors remain an important drawback,\nhindering practical adoption. In this paper, we introduce a simple\nclustering-based token pooling approach to aggressively reduce the number of\nvectors that need to be stored. This method can reduce the space & memory\nfootprint of ColBERT indexes by 50% with virtually no retrieval performance\ndegradation. This method also allows for further reductions, reducing the\nvector count by 66%-to-75% , with degradation remaining below 5% on a vast\nmajority of datasets. Importantly, this approach requires no architectural\nchange nor query-time processing, and can be used as a simple drop-in during\nindexation with any ColBERT-like model.",
      "tldr_zh": "这篇论文针对 multi-vector retrieval 方法（如 ColBERT）在 Neural IR 中的高存储和内存需求问题，提出了一种基于聚类的 token pooling 技术，以大幅减少存储向量数量。该方法能在索引过程中简单应用，无需修改模型架构或查询时处理，就能将 ColBERT 索引的存储占用减少 50%，几乎不影响检索性能。进一步优化后，可将向量数量减少 66% 到 75%，在大多数数据集上性能下降不到 5%，从而提升了 multi-vector retrieval 的实际可采用性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14683v1",
      "published_date": "2024-09-23 03:12:43 UTC",
      "updated_date": "2024-09-23 03:12:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:58:24.973248"
    },
    {
      "arxiv_id": "2409.14679v2",
      "title": "Quantifying Context Bias in Domain Adaptation for Object Detection",
      "title_zh": "量化对象检测领域适应中的上下文偏差",
      "authors": [
        "Hojun Son",
        "Asma Almutairi",
        "Arpan Kusari"
      ],
      "abstract": "Domain adaptation for object detection (DAOD) seeks to transfer a trained\nmodel from a source to a target domain. Various DAOD methods exist, some of\nwhich aim to minimize context bias between foreground-background associations\nin various domains. However, no prior work has studied context bias in DAOD by\nanalyzing changes in background features during adaptation and how context bias\nis represented in different domains. Our research experiment highlights the\npotential usability of context bias in DAOD. We address the problem by varying\nactivation values over different layers of two different trained models,\nDetectron2 and YOLOv11, and by masking the background, both of which impact the\nnumber and quality of detections. We use two synthetic datasets, CARLA and\nVirtual KITTI, and two different versions of real open-source data, Cityscapes\nand KITTI semantic, as separate domains to represent and quantify context bias.\nWe utilize different metrics such as Maximum Mean Discrepancy (MMD) and Maximum\nVariance Discrepancy (MVD) to find the layer-specific conditional probability\nestimates of foreground given manipulated background regions for separate\ndomains. We further analyze foreground-background associations across various\ndataset combinations. We find that state-of-the-art domain adaptation methods\nexhibit some form of context bias and apply a potentially simple way to\nalleviate the context bias achieving improved accuracy (from 51.189 to 53.646\nmAP on Cityscapes foggy validation with 63.207 mAP and 64.233 mAP on Cityscapes\nvalidation respectively). We demonstrate through detailed analysis that\nunderstanding of the context bias can affect DAOD approach and focusing solely\non aligning foreground features is insufficient for effective DAOD.",
      "tldr_zh": "本文研究了物体检测领域适应（DAOD）中的上下文偏差（context bias），通过分析背景特征变化和前景-背景关联，量化了其在不同领域的影响。方法包括使用Detectron2和YOLOv11模型改变激活值、遮罩背景，并应用Maximum Mean Discrepancy (MMD)和Maximum Variance Discrepancy (MVD)指标，在CARLA、Virtual KITTI、Cityscapes和KITTI数据集上进行实验。结果显示，现有DAOD方法存在context bias，通过简单缓解策略，准确率从51.189 mAP提升到53.646 mAP。研究强调，理解context bias并关注前景-背景关联至关重要，仅对齐前景特征不足以实现有效领域适应。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.14679v2",
      "published_date": "2024-09-23 03:01:50 UTC",
      "updated_date": "2025-05-19 15:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:58:37.793169"
    },
    {
      "arxiv_id": "2409.14673v1",
      "title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science",
      "title_zh": "翻译失败",
      "authors": [
        "Taihang Wang",
        "Xiaoman Xu",
        "Yimin Wang",
        "Ye Jiang"
      ],
      "abstract": "Real-world applications of large language models (LLMs) in computational\nsocial science (CSS) tasks primarily depend on the effectiveness of instruction\ntuning (IT) or in-context learning (ICL). While IT has shown highly effective\nat fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task\nadaptation by learning from examples without explicit gradient updates. In this\npaper, we evaluate the classification performance of LLMs using IT versus ICL\nin few-shot CSS tasks. The experimental results indicate that ICL consistently\noutperforms IT in most CSS tasks. Additionally, we investigate the relationship\nbetween the increasing number of training samples and LLM performance. Our\nfindings show that simply increasing the number of samples without considering\ntheir quality does not consistently enhance the performance of LLMs with either\nICL or IT and can sometimes even result in a performance decline. Finally, we\ncompare three prompting strategies, demonstrating that ICL is more effective\nthan zero-shot and Chain-of-Thought (CoT). Our research highlights the\nsignificant advantages of ICL in handling CSS tasks in few-shot settings and\nemphasizes the importance of optimizing sample quality and prompting strategies\nto improve LLM classification performance. The code will be made available.",
      "tldr_zh": "本论文比较了在少样本计算社会科学（CSS）任务中，Instruction Tuning (IT) 与 In-Context Learning (ICL) 对大型语言模型（LLMs）的分类性能影响。实验结果显示，ICL 在大多数 CSS 任务中优于 IT，且简单增加训练样本数量并不能 consistently 提升性能，有时甚至导致下降。研究进一步比较了三种提示策略，发现 ICL 比 zero-shot 和 Chain-of-Thought (CoT) 更有效，并强调优化样本质量和提示策略的重要性，以提高 LLMs 在少样本设置下的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14673v1",
      "published_date": "2024-09-23 02:43:08 UTC",
      "updated_date": "2024-09-23 02:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:58:51.508712"
    },
    {
      "arxiv_id": "2409.14672v1",
      "title": "Speechworthy Instruction-tuned Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyundong Cho",
        "Nicolaas Jedema",
        "Leonardo F. R. Ribeiro",
        "Karishma Sharma",
        "Pedro Szekely",
        "Alessandro Moschitti",
        "Ruben Janssen",
        "Jonathan May"
      ],
      "abstract": "Current instruction-tuned language models are exclusively trained with\ntextual preference data and thus are often not aligned with the unique\nrequirements of other modalities, such as speech. To better align language\nmodels with the speech domain, we explore (i) prompting strategies grounded in\nradio-industry best practices and (ii) preference learning using a novel\nspeech-based preference data of 20K samples, generated with a wide spectrum of\nprompts that induce varying dimensions of speech-suitability and labeled by\nannotators who listen to response pairs. Both human and automatic evaluation\nshow that both prompting and preference learning increase the\nspeech-suitability of popular instruction-tuned LLMs. Interestingly, we find\nthat prompting and preference learning can be additive; combining them achieves\nthe best win rates in head-to-head comparison, resulting in responses that are\npreferred or tied to the base model in 76.2% of comparisons on average. Lastly,\nwe share lexical, syntactical, and qualitative analyses to showcase how each\nmethod contributes to improving the speech-suitability of generated responses.",
      "tldr_zh": "本研究针对当前基于文本偏好数据训练的instruction-tuned language models，提出方法以提升其语音模态适用性。研究探索了基于广播行业最佳实践的提示策略，以及利用20K语音偏好样本进行preference learning，这些样本通过多样提示生成并由聆听者标注。实验结果显示，人类和自动评估均表明提示策略和偏好学习能显著提高模型的语音适用性，且二者结合可使响应在76.2%的比较中优于或持平基线模型。最后，通过词汇、句法和定性分析，论文展示了这些方法如何增强生成的响应在语音领域的适应性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP2024",
      "pdf_url": "http://arxiv.org/pdf/2409.14672v1",
      "published_date": "2024-09-23 02:34:42 UTC",
      "updated_date": "2024-09-23 02:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:59:10.655849"
    },
    {
      "arxiv_id": "2409.14671v1",
      "title": "FedGCA: Global Consistent Augmentation Based Single-Source Federated Domain Generalization",
      "title_zh": "FedGCA：基于全局一致性增强的单源联邦域泛化",
      "authors": [
        "Yuan Liu",
        "Shu Wang",
        "Zhe Qu",
        "Xingyu Li",
        "Shichao Kan",
        "Jianxin Wang"
      ],
      "abstract": "Federated Domain Generalization (FedDG) aims to train the global model for\ngeneralization ability to unseen domains with multi-domain training samples.\nHowever, clients in federated learning networks are often confined to a single,\nnon-IID domain due to inherent sampling and temporal limitations. The lack of\ncross-domain interaction and the in-domain divergence impede the learning of\ndomain-common features and limit the effectiveness of existing FedDG, referred\nto as the single-source FedDG (sFedDG) problem. To address this, we introduce\nthe Federated Global Consistent Augmentation (FedGCA) method, which\nincorporates a style-complement module to augment data samples with diverse\ndomain styles. To ensure the effective integration of augmented samples, FedGCA\nemploys both global guided semantic consistency and class consistency,\nmitigating inconsistencies from local semantics within individual clients and\nclasses across multiple clients. The conducted extensive experiments\ndemonstrate the superiority of FedGCA.",
      "tldr_zh": "本论文针对单源 Federated Domain Generalization (sFedDG) 问题，提出 FedGCA 方法，以解决联邦学习中客户端数据单一、非独立同分布 (non-IID) 导致的领域通用特征学习困难。FedGCA 引入 style-complement module 来增强数据样本，生成多样领域风格，同时通过 global guided semantic consistency 和 class consistency 确保增强样本的语义和类别一致性，减少本地和跨客户端的不一致。实验结果显示，FedGCA 在广泛测试中表现出优越性，提高了模型对未见领域的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 7 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2409.14671v1",
      "published_date": "2024-09-23 02:24:46 UTC",
      "updated_date": "2024-09-23 02:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:59:13.016630"
    },
    {
      "arxiv_id": "2409.14666v1",
      "title": "Semi-supervised Learning For Robust Speech Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Huayun Zhang",
        "Jeremy H. M. Wong",
        "Geyu Lin",
        "Nancy F. Chen"
      ],
      "abstract": "Speech evaluation measures a learners oral proficiency using automatic\nmodels. Corpora for training such models often pose sparsity challenges given\nthat there often is limited scored data from teachers, in addition to the score\ndistribution across proficiency levels being often imbalanced among student\ncohorts. Automatic scoring is thus not robust when faced with under-represented\nsamples or out-of-distribution samples, which inevitably exist in real-world\ndeployment scenarios. This paper proposes to address such challenges by\nexploiting semi-supervised pre-training and objective regularization to\napproximate subjective evaluation criteria. In particular, normalized mutual\ninformation is used to quantify the speech characteristics from the learner and\nthe reference. An anchor model is trained using pseudo labels to predict the\ncorrectness of pronunciation. An interpolated loss function is proposed to\nminimize not only the prediction error with respect to ground-truth scores but\nalso the divergence between two probability distributions estimated by the\nspeech evaluation model and the anchor model. Compared to other\nstate-of-the-art methods on a public data-set, this approach not only achieves\nhigh performance while evaluating the entire test-set as a whole, but also\nbrings the most evenly distributed prediction error across distinct proficiency\nlevels. Furthermore, empirical results show the model accuracy on\nout-of-distribution data also compares favorably with competitive baselines.",
      "tldr_zh": "这篇论文针对演讲评估中的数据稀疏性和不平衡问题，提出了一种基于 semi-supervised learning 的鲁棒方法，以提升模型在 underrepresented 和 out-of-distribution 样本上的性能。具体而言，该方法利用 normalized mutual information 量化学习者和参考的语音特征，训练一个 anchor model 通过伪标签预测发音正确性，并引入 interpolated loss function 来最小化预测错误和两个概率分布的差异。与现有 SOTA 方法相比，该方法在公共数据集上实现了更高的整体准确率，并在不同熟练度水平上预测错误分布更均匀，同时在 out-of-distribution 数据上表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.14666v1",
      "published_date": "2024-09-23 02:11:24 UTC",
      "updated_date": "2024-09-23 02:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:59:25.370952"
    },
    {
      "arxiv_id": "2410.07144v1",
      "title": "Natural Language Query Engine for Relational Databases using Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Tueno Fotso"
      ],
      "abstract": "The growing reliance on data-driven decision-making highlights the need for\nmore intuitive ways to access and analyze information stored in relational\ndatabases. However, the requirement of SQL knowledge has long been a\nsignificant barrier for non-technical users. This article introduces an\ninnovative solution that leverages Generative AI to bridge this gap, enabling\nusers to query databases using natural language. Our approach automatically\ntranslates natural language queries into SQL, ensuring both syntactic and\nsemantic correctness, while also generating clear, natural language responses\nfrom the retrieved data. By streamlining the interaction between users and\ndatabases, this method empowers individuals without technical expertise to\nengage with data directly and efficiently, democratizing access to valuable\ninsights and enhancing productivity.",
      "tldr_zh": "该论文提出了一种基于 Generative AI 的自然语言查询引擎，用于关系数据库，帮助非技术用户绕过 SQL 知识障碍。系统通过自动将自然语言查询翻译成语法和语义正确的 SQL 语句，并从检索的数据生成清晰的自然语言响应，从而简化用户与数据库的互动。该方法民主化了数据访问，提升了生产力和决策效率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "Artificial Intelligence, Machine Learning, Generative AI, SQL,\n  Relational Database, SQL Correctness",
      "pdf_url": "http://arxiv.org/pdf/2410.07144v1",
      "published_date": "2024-09-23 01:07:02 UTC",
      "updated_date": "2024-09-23 01:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:59:36.398287"
    },
    {
      "arxiv_id": "2409.14644v2",
      "title": "zsLLMCode: An Effective Approach for Code Embedding via LLM with Zero-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zixiang Xian",
        "Chenhui Cui",
        "Rubing Huang",
        "Chunrong Fang",
        "Zhenyu Chen"
      ],
      "abstract": "The advent of large language models (LLMs) has greatly advanced artificial\nintelligence (AI) in software engineering (SE), with code embeddings playing a\ncritical role in tasks like code-clone detection and code clustering. However,\nexisting methods for code embedding, including those based on LLMs, often\ndepend on costly supervised training or fine-tuning for domain adaptation. This\npaper proposes a novel zero-shot approach, zsLLMCode, to generate code\nembeddings by using LLMs and sentence embedding models. This approach attempts\nto eliminate the need for task-specific training or fine-tuning, and to\neffectively address the issue of erroneous information commonly found in\nLLM-generated outputs. We conducted a series of experiments to evaluate the\nperformance of the proposed approach by considering various LLMs and embedding\nmodels. The results have demonstrated the effectiveness and superiority of our\nmethod zsLLMCode over state-of-the-art unsupervised approaches such as\nSourcererCC, Code2vec, InferCode, and TransformCode. Our findings highlight the\npotential of zsLLMCode to advance the field of SE by providing robust and\nefficient solutions for code embedding tasks.",
      "tldr_zh": "本研究提出了一种名为 zsLLMCode 的新方法，利用大型语言模型（LLMs）和句子嵌入模型，通过 zero-shot learning 生成代码嵌入，避免了传统方法依赖的监督训练或微调。zsLLMCode 旨在解决 LLMs 输出中常见错误信息的问题，并在代码克隆检测和代码聚类等任务中表现出色。实验结果显示，该方法比现有无监督方法如 SourcererCC、Code2vec、InferCode 和 TransformCode 等更优越，为软件工程（SE）领域提供了高效、鲁棒的代码嵌入解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14644v2",
      "published_date": "2024-09-23 01:03:15 UTC",
      "updated_date": "2025-03-05 05:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T02:59:50.530732"
    },
    {
      "arxiv_id": "2409.14637v1",
      "title": "Not Only the Last-Layer Features for Spurious Correlations: All Layer Deep Feature Reweighting",
      "title_zh": "翻译失败",
      "authors": [
        "Humza Wajid Hameed",
        "Geraldin Nanfack",
        "Eugene Belilovsky"
      ],
      "abstract": "Spurious correlations are a major source of errors for machine learning\nmodels, in particular when aiming for group-level fairness. It has been\nrecently shown that a powerful approach to combat spurious correlations is to\nre-train the last layer on a balanced validation dataset, isolating robust\nfeatures for the predictor. However, key attributes can sometimes be discarded\nby neural networks towards the last layer. In this work, we thus consider\nretraining a classifier on a set of features derived from all layers. We\nutilize a recently proposed feature selection strategy to select unbiased\nfeatures from all the layers. We observe this approach gives significant\nimprovements in worst-group accuracy on several standard benchmarks.",
      "tldr_zh": "本论文针对机器学习模型中的Spurious correlations问题，提出了一种All Layer Deep Feature Reweighting方法，以提升群体公平性。传统方法仅重新训练最后一层的特征，但本文扩展到所有层，使用一个最近提出的特征选择策略来选择无偏特征，从而保留关键属性。实验结果显示，该方法在多个标准基准上显著提高了worst-group accuracy。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.14637v1",
      "published_date": "2024-09-23 00:31:39 UTC",
      "updated_date": "2024-09-23 00:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:00:00.514050"
    },
    {
      "arxiv_id": "2409.14634v4",
      "title": "Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination",
      "title_zh": "翻译失败",
      "authors": [
        "Marissa Radensky",
        "Simra Shahid",
        "Raymond Fok",
        "Pao Siangliulue",
        "Tom Hope",
        "Daniel S. Weld"
      ],
      "abstract": "The scientific ideation process often involves blending salient aspects of\nexisting papers to create new ideas, and facet-based ideation is an established\nframework for idea generation. To see how large language models (LLMs) might\nassist in this process, we contribute a novel mixed-initiative ideation tool\ncalled Scideator. Starting from a user-provided set of scientific papers,\nScideator extracts key facets -- purposes, mechanisms, and evaluations -- from\nthese and related papers, allowing users to explore the idea space by\ninteractively recombining facets to synthesize inventive ideas. Scideator also\nhelps users gauge idea originality by searching the literature for overlaps,\nassessing idea novelty and providing explanations. To support these tasks,\nScideator introduces three LLM-powered retrieval-augmented generation (RAG)\nmodules: Analogous Paper Facet Finder, Faceted Idea Generator, and Idea Novelty\nChecker. In a within-subjects user study (N=22) with computer-science\nresearchers comparing Scideator to a strong baseline, our tool provided\nsignificantly more creativity support, particularly with respect to\nexploration, which participants considered the most important factor for idea\ngeneration.",
      "tldr_zh": "本研究开发了 Scideator，一种混合式互动工具，结合 Human-LLM 框架，通过研究论文的 facet recombination（包括 purposes, mechanisms 和 evaluations）来辅助科学构想生成。工具利用三个 RAG 模块——Analogous Paper Facet Finder、Faceted Idea Generator 和 Idea Novelty Checker——从用户提供的论文中提取关键方面，支持用户互动重组 facets 以探索新想法，并评估想法的原创性。在一项涉及22名计算机科学研究者的用户研究中，Scideator 比基线工具显著提升了创意支持，尤其在探索方面。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.2, I.2"
      ],
      "primary_category": "cs.HC",
      "comment": "Updated with new and improved user study",
      "pdf_url": "http://arxiv.org/pdf/2409.14634v4",
      "published_date": "2024-09-23 00:09:34 UTC",
      "updated_date": "2025-04-29 04:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:00:17.215821"
    },
    {
      "arxiv_id": "2409.14633v1",
      "title": "Hierarchical end-to-end autonomous navigation through few-shot waypoint detection",
      "title_zh": "通过少样本航路点检测实现的层次化端到端自主导航",
      "authors": [
        "Amin Ghafourian",
        "Zhongying CuiZhu",
        "Debo Shi",
        "Ian Chuang",
        "Francois Charette",
        "Rithik Sachdeva",
        "Iman Soltani"
      ],
      "abstract": "Human navigation is facilitated through the association of actions with\nlandmarks, tapping into our ability to recognize salient features in our\nenvironment. Consequently, navigational instructions for humans can be\nextremely concise, such as short verbal descriptions, indicating a small memory\nrequirement and no reliance on complex and overly accurate navigation tools.\nConversely, current autonomous navigation schemes rely on accurate positioning\ndevices and algorithms as well as extensive streams of sensory data collected\nfrom the environment. Inspired by this human capability and motivated by the\nassociated technological gap, in this work we propose a hierarchical end-to-end\nmeta-learning scheme that enables a mobile robot to navigate in a previously\nunknown environment upon presentation of only a few sample images of a set of\nlandmarks along with their corresponding high-level navigation actions. This\ndramatically simplifies the wayfinding process and enables easy adoption to new\nenvironments. For few-shot waypoint detection, we implement a metric-based\nfew-shot learning technique through distribution embedding. Waypoint detection\ntriggers the multi-task low-level maneuver controller module to execute the\ncorresponding high-level navigation action. We demonstrate the effectiveness of\nthe scheme using a small-scale autonomous vehicle on novel indoor navigation\ntasks in several previously unseen environments.",
      "tldr_zh": "这篇论文受人类导航方式启发，提出了一种分层端到端的元学习方案（hierarchical end-to-end meta-learning scheme），让移动机器人仅通过少数样本图像和对应的高级导航动作，就能高效导航未知环境，从而简化传统依赖精确定位和大量感测数据的复杂过程。对于少样本航路点检测（few-shot waypoint detection），论文采用基于度量的少样本学习（few-shot learning）通过分布嵌入（distribution embedding）来实现，并触发多任务低级操控控制器（multi-task low-level maneuver controller）执行相应动作。实验在小型自主车辆上验证了该方案的有效性，展示了其在多个未见室内环境的适应性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Appeared at the 40th Anniversary of the IEEE International Conference\n  on Robotics and Automation (ICRA@40), 23-26 September, 2024, Rotterdam, The\n  Netherlands. 9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.14633v1",
      "published_date": "2024-09-23 00:03:39 UTC",
      "updated_date": "2024-09-23 00:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:00:25.084994"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 144,
  "processed_papers_count": 144,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T03:00:50.786565"
}