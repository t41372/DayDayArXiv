[
  {
    "arxiv_id": "2505.06469v1",
    "title": "KCluster: An LLM-based Clustering Approach to Knowledge Component Discovery",
    "authors": [
      "Yumou Wei",
      "Paulo Carvalho",
      "John Stamper"
    ],
    "abstract": "Educators evaluate student knowledge using knowledge component (KC) models\nthat map assessment questions to KCs. Still, designing KC models for large\nquestion banks remains an insurmountable challenge for instructors who need to\nanalyze each question by hand. The growing use of Generative AI in education is\nexpected only to aggravate this chronic deficiency of expert-designed KC\nmodels, as course engineers designing KCs struggle to keep up with the pace at\nwhich questions are generated. In this work, we propose KCluster, a novel KC\ndiscovery algorithm based on identifying clusters of congruent questions\naccording to a new similarity metric induced by a large language model (LLM).\nWe demonstrate in three datasets that an LLM can create an effective metric of\nquestion similarity, which a clustering algorithm can use to create KC models\nfrom questions with minimal human effort. Combining the strengths of LLM and\nclustering, KCluster generates descriptive KC labels and discovers KC models\nthat predict student performance better than the best expert-designed models\navailable. In anticipation of future work, we illustrate how KCluster can\nreveal insights into difficult KCs and suggest improvements to instruction.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Educational Data Mining (EDM) 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2505.06469v1",
    "published_date": "2025-05-09 23:47:58 UTC",
    "updated_date": "2025-05-09 23:47:58 UTC"
  },
  {
    "arxiv_id": "2505.15825v1",
    "title": "Multilinear subspace learning for person re-identification based fusion of high order tensor features",
    "authors": [
      "Ammar Chouchane",
      "Mohcene Bessaoudi",
      "Hamza Kheddar",
      "Abdelmalik Ouamane",
      "Tiago Vieira",
      "Mahmoud Hassaballah"
    ],
    "abstract": "Video surveillance image analysis and processing is a challenging field in\ncomputer vision, with one of its most difficult tasks being Person\nRe-Identification (PRe-ID). PRe-ID aims to identify and track target\nindividuals who have already been detected in a network of cameras, using a\nrobust description of their pedestrian images. The success of recent research\nin person PRe-ID is largely due to effective feature extraction and\nrepresentation, as well as the powerful learning of these features to reliably\ndiscriminate between pedestrian images. To this end, two powerful features,\nConvolutional Neural Networks (CNN) and Local Maximal Occurrence (LOMO), are\nmodeled on multidimensional data using the proposed method, High-Dimensional\nFeature Fusion (HDFF). Specifically, a new tensor fusion scheme is introduced\nto leverage and combine these two types of features in a single tensor, even\nthough their dimensions are not identical. To enhance the system's accuracy, we\nemploy Tensor Cross-View Quadratic Analysis (TXQDA) for multilinear subspace\nlearning, followed by cosine similarity for matching. TXQDA efficiently\nfacilitates learning while reducing the high dimensionality inherent in\nhigh-order tensor data. The effectiveness of our approach is verified through\nexperiments on three widely-used PRe-ID datasets: VIPeR, GRID, and PRID450S.\nExtensive experiments demonstrate that our approach outperforms recent\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.15825v1",
    "published_date": "2025-05-09 23:39:27 UTC",
    "updated_date": "2025-05-09 23:39:27 UTC"
  },
  {
    "arxiv_id": "2505.06464v1",
    "title": "Opening the Scope of Openness in AI",
    "authors": [
      "Tamara Paris",
      "AJung Moon",
      "Jin Guo"
    ],
    "abstract": "The concept of openness in AI has so far been heavily inspired by the\ndefinition and community practice of open source software. This positions\nopenness in AI as having positive connotations; it introduces assumptions of\ncertain advantages, such as collaborative innovation and transparency. However,\nthe practices and benefits of open source software are not fully transferable\nto AI, which has its own challenges. Framing a notion of openness tailored to\nAI is crucial to addressing its growing societal implications, risks, and\ncapabilities. We argue that considering the fundamental scope of openness in\ndifferent disciplines will broaden discussions, introduce important\nperspectives, and reflect on what openness in AI should mean. Toward this goal,\nwe qualitatively analyze 98 concepts of openness discovered from topic\nmodeling, through which we develop a taxonomy of openness. Using this taxonomy\nas an instrument, we situate the current discussion on AI openness, identify\ngaps and highlight links with other disciplines. Our work contributes to the\nrecent efforts in framing openness in AI by reflecting principles and practices\nof openness beyond open source software and calls for a more holistic view of\nopenness in terms of actions, system properties, and ethical objectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06464v1",
    "published_date": "2025-05-09 23:16:44 UTC",
    "updated_date": "2025-05-09 23:16:44 UTC"
  },
  {
    "arxiv_id": "2505.06459v1",
    "title": "Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles",
    "authors": [
      "Pablo Flores",
      "Olga Graf",
      "Pavlos Protopapas",
      "Karim Pichara"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) have been widely used to obtain\nsolutions to various physical phenomena modeled as Differential Equations. As\nPINNs are not naturally equipped with mechanisms for Uncertainty\nQuantification, some work has been done to quantify the different uncertainties\nthat arise when dealing with PINNs. In this paper, we use a two-step procedure\nto train Bayesian Neural Networks that provide uncertainties over the solutions\nto differential equation systems provided by PINNs. We use available error\nbounds over PINNs to formulate a heteroscedastic variance that improves the\nuncertainty estimation. Furthermore, we solve forward problems and utilize the\nobtained uncertainties when doing parameter estimation in inverse problems in\ncosmology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06459v1",
    "published_date": "2025-05-09 22:40:39 UTC",
    "updated_date": "2025-05-09 22:40:39 UTC"
  },
  {
    "arxiv_id": "2505.06438v1",
    "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming",
    "authors": [
      "Yankai Zeng",
      "Gopal Gupta"
    ],
    "abstract": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI)\nbots became popular, people realized their strong potential in Task-Oriented\nDialogue (TOD). However, bots relying wholly on LLMs are unreliable in their\nknowledge, and whether they can finally produce a correct result for the task\nis not guaranteed. The collaboration among these agents also remains a\nchallenge, since the necessary information to convey is unclear, and the\ninformation transfer is by prompts -- unreliable, and malicious knowledge is\neasy to inject. With the help of logic programming tools such as Answer Set\nProgramming (ASP), conversational agents can be built safely and reliably, and\ncommunication among the agents made more efficient and secure. We proposed an\nAdministrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots\nshare the same knowledge base and complete their tasks independently, while the\ninformation can be passed by a Collaborative Rule Set (CRS). The knowledge and\ninformation conveyed are encapsulated and invisible to the users, ensuring the\nsecurity of information transmission. We have constructed AutoManager, a\ndual-agent system for managing the drive-through window of a fast-food\nrestaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes\nthe customer's order while the administrator bot manages the menu and food\nsupply. We evaluated our AutoManager and compared it with the real-world Taco\nBell Drive-Thru AI Order Taker, and the results show that our method is more\nreliable.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.06438v1",
    "published_date": "2025-05-09 21:14:32 UTC",
    "updated_date": "2025-05-09 21:14:32 UTC"
  },
  {
    "arxiv_id": "2505.06436v1",
    "title": "My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing",
    "authors": [
      "Jingrui He",
      "Andrew Stephen McGough"
    ],
    "abstract": "Generative Adversarial Network approaches such as StyleGAN/2 provide two key\nbenefits: the ability to generate photo-realistic face images and possessing a\nsemantically structured latent space from which these images are created. Many\napproaches have emerged for editing images derived from vectors in the latent\nspace of a pre-trained StyleGAN/2 models by identifying semantically meaningful\ndirections (e.g., gender or age) in the latent space. By moving the vector in a\nspecific direction, the ideal result would only change the target feature while\npreserving all the other features. Providing an ideal data augmentation\napproach for gesture research as it could be used to generate numerous image\nvariations whilst keeping the facial expressions intact. However, entanglement\nissues, where changing one feature inevitably affects other features, impacts\nthe ability to preserve facial expressions. To address this, we propose the use\nof an addition to the loss function of a Facial Keypoint Detection model to\nrestrict changes to the facial expressions. Building on top of an existing\nmodel, adding the proposed Human Face Landmark Detection (HFLD) loss, provided\nby a pre-trained Facial Keypoint Detection model, to the original loss\nfunction. We quantitatively and qualitatively evaluate the existing and our\nextended model, showing the effectiveness of our approach in addressing the\nentanglement issue and maintaining the facial expression. Our approach achieves\nup to 49% reduction in the change of emotion in our experiments. Moreover, we\nshow the benefit of our approach by comparing with state-of-the-art models. By\nincreasing the ability to preserve the facial gesture and expression during\nfacial transformation, we present a way to create human face images with fixed\nexpression but different appearances, making it a reliable data augmentation\napproach for Facial Gesture and Expression research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to 2nd International Workshop on Synthetic Data for Face\n  and Gesture Analysis at IEEE FG 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06436v1",
    "published_date": "2025-05-09 21:10:27 UTC",
    "updated_date": "2025-05-09 21:10:27 UTC"
  },
  {
    "arxiv_id": "2505.06428v1",
    "title": "What Do People Want to Know About Artificial Intelligence (AI)? The Importance of Answering End-User Questions to Explain Autonomous Vehicle (AV) Decisions",
    "authors": [
      "Somayeh Molaei",
      "Lionel P. Robert",
      "Nikola Banovic"
    ],
    "abstract": "Improving end-users' understanding of decisions made by autonomous vehicles\n(AVs) driven by artificial intelligence (AI) can improve utilization and\nacceptance of AVs. However, current explanation mechanisms primarily help AI\nresearchers and engineers in debugging and monitoring their AI systems, and may\nnot address the specific questions of end-users, such as passengers, about AVs\nin various scenarios. In this paper, we conducted two user studies to\ninvestigate questions that potential AV passengers might pose while riding in\nan AV and evaluate how well answers to those questions improve their\nunderstanding of AI-driven AV decisions. Our initial formative study identified\na range of questions about AI in autonomous driving that existing explanation\nmechanisms do not readily address. Our second study demonstrated that\ninteractive text-based explanations effectively improved participants'\ncomprehension of AV decisions compared to simply observing AV decisions. These\nfindings inform the design of interactions that motivate end-users to engage\nwith and inquire about the reasoning behind AI-driven AV decisions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to the Proceedings of the ACM on Human-Computer Interaction,\n  CSCW, October 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06428v1",
    "published_date": "2025-05-09 20:57:34 UTC",
    "updated_date": "2025-05-09 20:57:34 UTC"
  },
  {
    "arxiv_id": "2505.06413v1",
    "title": "Natural Reflection Backdoor Attack on Vision Language Model for Autonomous Driving",
    "authors": [
      "Ming Liu",
      "Siyuan Liang",
      "Koushik Howlader",
      "Liwen Wang",
      "Dacheng Tao",
      "Wensheng Zhang"
    ],
    "abstract": "Vision-Language Models (VLMs) have been integrated into autonomous driving\nsystems to enhance reasoning capabilities through tasks such as Visual Question\nAnswering (VQA). However, the robustness of these systems against backdoor\nattacks remains underexplored. In this paper, we propose a natural\nreflection-based backdoor attack targeting VLM systems in autonomous driving\nscenarios, aiming to induce substantial response delays when specific visual\ntriggers are present. We embed faint reflection patterns, mimicking natural\nsurfaces such as glass or water, into a subset of images in the DriveLM\ndataset, while prepending lengthy irrelevant prefixes (e.g., fabricated stories\nor system update notifications) to the corresponding textual labels. This\nstrategy trains the model to generate abnormally long responses upon\nencountering the trigger. We fine-tune two state-of-the-art VLMs, Qwen2-VL and\nLLaMA-Adapter, using parameter-efficient methods. Experimental results\ndemonstrate that while the models maintain normal performance on clean inputs,\nthey exhibit significantly increased inference latency when triggered,\npotentially leading to hazardous delays in real-world autonomous driving\ndecision-making. Further analysis examines factors such as poisoning rates,\ncamera perspectives, and cross-view transferability. Our findings uncover a new\nclass of attacks that exploit the stringent real-time requirements of\nautonomous driving, posing serious challenges to the security and reliability\nof VLM-augmented driving systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06413v1",
    "published_date": "2025-05-09 20:28:17 UTC",
    "updated_date": "2025-05-09 20:28:17 UTC"
  },
  {
    "arxiv_id": "2505.06411v1",
    "title": "MAGE:A Multi-stage Avatar Generator with Sparse Observations",
    "authors": [
      "Fangyu Du",
      "Yang Yang",
      "Xuehao Gao",
      "Hongye Hou"
    ],
    "abstract": "Inferring full-body poses from Head Mounted Devices, which capture only\n3-joint observations from the head and wrists, is a challenging task with wide\nAR/VR applications. Previous attempts focus on learning one-stage motion\nmapping and thus suffer from an over-large inference space for unobserved body\njoint motions. This often leads to unsatisfactory lower-body predictions and\npoor temporal consistency, resulting in unrealistic or incoherent motion\nsequences. To address this, we propose a powerful Multi-stage Avatar GEnerator\nnamed MAGE that factorizes this one-stage direct motion mapping learning with a\nprogressive prediction strategy. Specifically, given initial 3-joint motions,\nMAGE gradually inferring multi-scale body part poses at different abstract\ngranularity levels, starting from a 6-part body representation and gradually\nrefining to 22 joints. With decreasing abstract levels step by step, MAGE\nintroduces more motion context priors from former prediction stages and thus\nimproves realistic motion completion with richer constraint conditions and less\nambiguity. Extensive experiments on large-scale datasets verify that MAGE\nsignificantly outperforms state-of-the-art methods with better accuracy and\ncontinuity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06411v1",
    "published_date": "2025-05-09 20:21:00 UTC",
    "updated_date": "2025-05-09 20:21:00 UTC"
  },
  {
    "arxiv_id": "2505.06409v1",
    "title": "Engineering Risk-Aware, Security-by-Design Frameworks for Assurance of Large-Scale Autonomous AI Models",
    "authors": [
      "Krti Tallam"
    ],
    "abstract": "As AI models scale to billions of parameters and operate with increasing\nautonomy, ensuring their safe, reliable operation demands engineering-grade\nsecurity and assurance frameworks. This paper presents an enterprise-level,\nrisk-aware, security-by-design approach for large-scale autonomous AI systems,\nintegrating standardized threat metrics, adversarial hardening techniques, and\nreal-time anomaly detection into every phase of the development lifecycle. We\ndetail a unified pipeline - from design-time risk assessments and secure\ntraining protocols to continuous monitoring and automated audit logging - that\ndelivers provable guarantees of model behavior under adversarial and\noperational stress. Case studies in national security, open-source model\ngovernance, and industrial automation demonstrate measurable reductions in\nvulnerability and compliance overhead. Finally, we advocate cross-sector\ncollaboration - uniting engineering teams, standards bodies, and regulatory\nagencies - to institutionalize these technical safeguards within a resilient,\nend-to-end assurance ecosystem for the next generation of AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06409v1",
    "published_date": "2025-05-09 20:14:53 UTC",
    "updated_date": "2025-05-09 20:14:53 UTC"
  },
  {
    "arxiv_id": "2505.06402v1",
    "title": "Camera Control at the Edge with Language Models for Scene Understanding",
    "authors": [
      "Alexiy Buynitsky",
      "Sina Ehsani",
      "Bhanu Pallakonda",
      "Pragyana Mishra"
    ],
    "abstract": "In this paper, we present Optimized Prompt-based Unified System (OPUS), a\nframework that utilizes a Large Language Model (LLM) to control Pan-Tilt-Zoom\n(PTZ) cameras, providing contextual understanding of natural environments. To\nachieve this goal, the OPUS system improves cost-effectiveness by generating\nkeywords from a high-level camera control API and transferring knowledge from\nlarger closed-source language models to smaller ones through Supervised\nFine-Tuning (SFT) on synthetic data. This enables efficient edge deployment\nwhile maintaining performance comparable to larger models like GPT-4. OPUS\nenhances environmental awareness by converting data from multiple cameras into\ntextual descriptions for language models, eliminating the need for specialized\nsensory tokens. In benchmark testing, our approach significantly outperformed\nboth traditional language model techniques and more complex prompting methods,\nachieving a 35% improvement over advanced techniques and a 20% higher task\naccuracy compared to closed-source models like Gemini Pro. The system\ndemonstrates OPUS's capability to simplify PTZ camera operations through an\nintuitive natural language interface. This approach eliminates the need for\nexplicit programming and provides a conversational method for interacting with\ncamera systems, representing a significant advancement in how users can control\nand utilize PTZ camera technology.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 6 figures. This work was presented and published at the 11th\n  IEEE International Conference on Control, Automation and Robotics (ICCAR) in\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06402v1",
    "published_date": "2025-05-09 20:00:29 UTC",
    "updated_date": "2025-05-09 20:00:29 UTC"
  },
  {
    "arxiv_id": "2505.07871v1",
    "title": "Evaluating Financial Sentiment Analysis with Annotators Instruction Assisted Prompting: Enhancing Contextual Interpretation and Stock Prediction Accuracy",
    "authors": [
      "A M Muntasir Rahman",
      "Ajim Uddin",
      "Guiling \"Grace\" Wang"
    ],
    "abstract": "Financial sentiment analysis (FSA) presents unique challenges to LLMs that\nsurpass those in typical sentiment analysis due to the nuanced language used in\nfinancial contexts. The prowess of these models is often undermined by the\ninherent subjectivity of sentiment classifications in existing benchmark\ndatasets like Financial Phrasebank. These datasets typically feature undefined\nsentiment classes that reflect the highly individualized perspectives of\nannotators, leading to significant variability in annotations. This variability\nresults in an unfair expectation for LLMs during benchmarking, where they are\ntasked to conjecture the subjective viewpoints of human annotators without\nsufficient context. In this paper, we introduce the Annotators' Instruction\nAssisted Prompt, a novel evaluation prompt designed to redefine the task\ndefinition of FSA for LLMs. By integrating detailed task instructions\noriginally intended for human annotators into the LLMs' prompt framework, AIAP\naims to standardize the understanding of sentiment across both human and\nmachine interpretations, providing a fair and context-rich foundation for\nsentiment analysis. We utilize a new dataset, WSBS, derived from the\nWallStreetBets subreddit to demonstrate how AIAP significantly enhances LLM\nperformance by aligning machine operations with the refined task definitions.\nExperimental results demonstrate that AIAP enhances LLM performance\nsignificantly, with improvements up to 9.08. This context-aware approach not\nonly yields incremental gains in performance but also introduces an innovative\nsentiment-indexing method utilizing model confidence scores. This method\nenhances stock price prediction models and extracts more value from the\nfinancial sentiment analysis, underscoring the significance of WSB as a\ncritical source of financial text. Our research offers insights into both\nimproving FSA through better evaluation methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07871v1",
    "published_date": "2025-05-09 19:44:04 UTC",
    "updated_date": "2025-05-09 19:44:04 UTC"
  },
  {
    "arxiv_id": "2505.06394v1",
    "title": "Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers",
    "authors": [
      "Massimiliano Albanese",
      "Xinming Ou",
      "Kevin Lybarger",
      "Daniel Lende",
      "Dmitry Goldgof"
    ],
    "abstract": "Security Operations Centers (SOCs) face growing challenges in managing\ncybersecurity threats due to an overwhelming volume of alerts, a shortage of\nskilled analysts, and poorly integrated tools. Human-AI collaboration offers a\npromising path to augment the capabilities of SOC analysts while reducing their\ncognitive overload. To this end, we introduce an AI-driven human-machine\nco-teaming paradigm that leverages large language models (LLMs) to enhance\nthreat intelligence, alert triage, and incident response workflows. We present\na vision in which LLM-based AI agents learn from human analysts the tacit\nknowledge embedded in SOC operations, enabling the AI agents to improve their\nperformance on SOC tasks through this co-teaming. We invite SOCs to collaborate\nwith us to further develop this process and uncover replicable patterns where\nhuman-AI co-teaming yields measurable improvements in SOC productivity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06394v1",
    "published_date": "2025-05-09 19:38:26 UTC",
    "updated_date": "2025-05-09 19:38:26 UTC"
  },
  {
    "arxiv_id": "2505.06380v1",
    "title": "Offensive Security for AI Systems: Concepts, Practices, and Applications",
    "authors": [
      "Josh Harguess",
      "Chris M. Ward"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly adopted across\nsectors, the need for robust, proactive security strategies is paramount.\nTraditional defensive measures often fall short against the unique and evolving\nthreats facing AI-driven technologies, making offensive security an essential\napproach for identifying and mitigating risks. This paper presents a\ncomprehensive framework for offensive security in AI systems, emphasizing\nproactive threat simulation and adversarial testing to uncover vulnerabilities\nthroughout the AI lifecycle. We examine key offensive security techniques,\nincluding weakness and vulnerability assessment, penetration testing, and red\nteaming, tailored specifically to address AI's unique susceptibilities. By\nsimulating real-world attack scenarios, these methodologies reveal critical\ninsights, informing stronger defensive strategies and advancing resilience\nagainst emerging threats. This framework advances offensive AI security from\ntheoretical concepts to practical, actionable methodologies that organizations\ncan implement to strengthen their AI systems against emerging threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06380v1",
    "published_date": "2025-05-09 18:58:56 UTC",
    "updated_date": "2025-05-09 18:58:56 UTC"
  },
  {
    "arxiv_id": "2505.06378v1",
    "title": "Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks",
    "authors": [
      "Yuxiang Wei",
      "Zhuoqi Zeng",
      "Yue Zhong",
      "Jiawen Kang",
      "Ryan Wen Liu",
      "M. Shamim Hossain"
    ],
    "abstract": "With the advancement of large language models and embodied Artificial\nIntelligence (AI) in the intelligent transportation scenarios, the combination\nof them in intelligent transportation spawns the Vehicular Embodied AI Network\n(VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local\nadvanced AI applications are defined as vehicular embodied AI agents, enabling\ncapabilities such as environment perception and multi-agent collaboration. Due\nto computation latency and resource constraints, the local AI applications and\nservices running on vehicular embodied AI agents need to be migrated, and\nsubsequently referred to as vehicular embodied AI agent twins, which drive the\nadvancement of vehicular embodied AI networks to offload intensive tasks to\nRoadside Units (RSUs), mitigating latency problems while maintaining service\nquality. Recognizing workload imbalance among RSUs in traditional approaches,\nwe model AV-RSU interactions as a Stackelberg game to optimize bandwidth\nresource allocation for efficient migration. A Tiny Multi-Agent Bidirectional\nLSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to\napproximate the Stackelberg equilibrium through decentralized coordination.\nFurthermore, a personalized neural network pruning algorithm based on Path\neXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities\nby identifying task-critical parameters in trained models, reducing model\ncomplexity with less performance degradation. Experimental validation confirms\nthe algorithm's effectiveness in balancing system load and minimizing delays,\ndemonstrating significant improvements in vehicular embodied AI agent\ndeployment.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06378v1",
    "published_date": "2025-05-09 18:52:26 UTC",
    "updated_date": "2025-05-09 18:52:26 UTC"
  },
  {
    "arxiv_id": "2505.06371v1",
    "title": "The ML.ENERGY Benchmark: Toward Automated Inference Energy Measurement and Optimization",
    "authors": [
      "Jae-Won Chung",
      "Jiachen Liu",
      "Jeff J. Ma",
      "Ruofan Wu",
      "Oh Jun Kweon",
      "Yuxuan Xia",
      "Zhiyu Wu",
      "Mosharaf Chowdhury"
    ],
    "abstract": "As the adoption of Generative AI in real-world services grow explosively,\nenergy has emerged as a critical bottleneck resource. However, energy remains a\nmetric that is often overlooked, under-explored, or poorly understood in the\ncontext of building ML systems. We present the ML.ENERGY Benchmark, a benchmark\nsuite and tool for measuring inference energy consumption under realistic\nservice environments, and the corresponding ML.ENERGY Leaderboard, which have\nserved as a valuable resource for those hoping to understand and optimize the\nenergy consumption of their generative AI services. In this paper, we explain\nfour key design principles for benchmarking ML energy we have acquired over\ntime, and then describe how they are implemented in the ML.ENERGY Benchmark. We\nthen highlight results from the latest iteration of the benchmark, including\nenergy measurements of 40 widely used model architectures across 6 different\ntasks, case studies of how ML design choices impact energy consumption, and how\nautomated optimization recommendations can lead to significant (sometimes more\nthan 40%) energy savings without changing what is being computed by the model.\nThe ML.ENERGY Benchmark is open-source and can be easily extended to various\ncustomized models and application scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Leaderboard: https://ml.energy/leaderboard",
    "pdf_url": "http://arxiv.org/pdf/2505.06371v1",
    "published_date": "2025-05-09 18:27:32 UTC",
    "updated_date": "2025-05-09 18:27:32 UTC"
  },
  {
    "arxiv_id": "2505.06363v1",
    "title": "Learning Sequential Kinematic Models from Demonstrations for Multi-Jointed Articulated Objects",
    "authors": [
      "Anmol Gupta",
      "Weiwei Gu",
      "Omkar Patil",
      "Jun Ki Lee",
      "Nakul Gopalan"
    ],
    "abstract": "As robots become more generalized and deployed in diverse environments, they\nmust interact with complex objects, many with multiple independent joints or\ndegrees of freedom (DoF) requiring precise control. A common strategy is object\nmodeling, where compact state-space models are learned from real-world\nobservations and paired with classical planning. However, existing methods\noften rely on prior knowledge or focus on single-DoF objects, limiting their\napplicability. They also fail to handle occluded joints and ignore the\nmanipulation sequences needed to access them. We address this by learning\nobject models from human demonstrations. We introduce Object Kinematic Sequence\nMachines (OKSMs), a novel representation capturing both kinematic constraints\nand manipulation order for multi-DoF objects. To estimate these models from\npoint cloud data, we present Pokenet, a deep neural network trained on human\ndemonstrations. We validate our approach on 8,000 simulated and 1,600\nreal-world annotated samples. Pokenet improves joint axis and state estimation\nby over 20 percent on real-world data compared to prior methods. Finally, we\ndemonstrate OKSMs on a Sawyer robot using inverse kinematics-based planning to\nmanipulate multi-DoF objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06363v1",
    "published_date": "2025-05-09 18:09:06 UTC",
    "updated_date": "2025-05-09 18:09:06 UTC"
  },
  {
    "arxiv_id": "2505.06347v1",
    "title": "Quantum State Preparation via Large-Language-Model-Driven Evolution",
    "authors": [
      "Qing-Hong Cao",
      "Zong-Yue Hou",
      "Ying-Ying Li",
      "Xiaohui Liu",
      "Zhuo-Yang Song",
      "Liang-Qi Zhang",
      "Shutao Zhang",
      "Ke Zhao"
    ],
    "abstract": "We propose an automated framework for quantum circuit design by integrating\nlarge-language models (LLMs) with evolutionary optimization to overcome the\nrigidity, scalability limitations, and expert dependence of traditional ones in\nvariational quantum algorithms. Our approach (FunSearch) autonomously discovers\nhardware-efficient ans\\\"atze with new features of scalability and\nsystem-size-independent number of variational parameters entirely from scratch.\nDemonstrations on the Ising and XY spin chains with n = 9 qubits yield circuits\ncontaining 4 parameters, achieving near-exact energy extrapolation across\nsystem sizes. Implementations on quantum hardware (Zuchongzhi chip) validate\npracticality, where two-qubit quantum gate noises can be effectively mitigated\nvia zero-noise extrapolations for a spin chain system as large as 20 sites.\nThis framework bridges algorithmic design and experimental constraints,\ncomplementing contemporary quantum architecture search frameworks to advance\nscalable quantum simulations.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "hep-lat",
      "hep-ph"
    ],
    "primary_category": "quant-ph",
    "comment": "6 + 4 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.06347v1",
    "published_date": "2025-05-09 18:00:02 UTC",
    "updated_date": "2025-05-09 18:00:02 UTC"
  },
  {
    "arxiv_id": "2505.06218v1",
    "title": "Let Humanoids Hike! Integrative Skill Development on Complex Trails",
    "authors": [
      "Kwan-Yee Lin",
      "Stella X. Yu"
    ],
    "abstract": "Hiking on complex trails demands balance, agility, and adaptive\ndecision-making over unpredictable terrain. Current humanoid research remains\nfragmented and inadequate for hiking: locomotion focuses on motor skills\nwithout long-term goals or situational awareness, while semantic navigation\noverlooks real-world embodiment and local terrain variability. We propose\ntraining humanoids to hike on complex trails, driving integrative skill\ndevelopment across visual perception, decision making, and motor execution. We\ndevelop a learning framework, LEGO-H, that enables a vision-equipped humanoid\nrobot to hike complex trails autonomously. We introduce two technical\ninnovations: 1) A temporal vision transformer variant - tailored into\nHierarchical Reinforcement Learning framework - anticipates future local goals\nto guide movement, seamlessly integrating locomotion with goal-directed\nnavigation. 2) Latent representations of joint movement patterns, combined with\nhierarchical metric learning - enhance Privileged Learning scheme - enable\nsmooth policy transfer from privileged training to onboard execution. These\ncomponents allow LEGO-H to handle diverse physical and environmental challenges\nwithout relying on predefined motion patterns. Experiments across varied\nsimulated trails and robot morphologies highlight LEGO-H's versatility and\nrobustness, positioning hiking as a compelling testbed for embodied autonomy\nand LEGO-H as a baseline for future humanoid development.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "CVPR 2025. Project page:\n  https://lego-h-humanoidrobothiking.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.06218v1",
    "published_date": "2025-05-09 17:53:02 UTC",
    "updated_date": "2025-05-09 17:53:02 UTC"
  },
  {
    "arxiv_id": "2505.07870v1",
    "title": "Efficient Fairness Testing in Large Language Models: Prioritizing Metamorphic Relations for Bias Detection",
    "authors": [
      "Suavis Giramata",
      "Madhusudan Srinivasan",
      "Venkat Naidu Gudivada",
      "Upulee Kanewala"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in various\napplications, raising critical concerns about fairness and potential biases in\ntheir outputs. This paper explores the prioritization of metamorphic relations\n(MRs) in metamorphic testing as a strategy to efficiently detect fairness\nissues within LLMs. Given the exponential growth of possible test cases,\nexhaustive testing is impractical; therefore, prioritizing MRs based on their\neffectiveness in detecting fairness violations is crucial. We apply a sentence\ndiversity-based approach to compute and rank MRs to optimize fault detection.\nExperimental results demonstrate that our proposed prioritization approach\nimproves fault detection rates by 22% compared to random prioritization and 12%\ncompared to distance-based prioritization, while reducing the time to the first\nfailure by 15% and 8%, respectively. Furthermore, our approach performs within\n5% of fault-based prioritization in effectiveness, while significantly reducing\nthe computational cost associated with fault labeling. These results validate\nthe effectiveness of diversity-based MR prioritization in enhancing fairness\ntesting for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07870v1",
    "published_date": "2025-05-09 17:48:34 UTC",
    "updated_date": "2025-05-09 17:48:34 UTC"
  },
  {
    "arxiv_id": "2505.06335v1",
    "title": "Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients",
    "authors": [
      "Jinsheng Yuan",
      "Yuhang Hao",
      "Weisi Guo",
      "Yun Wu",
      "Chongyan Gu"
    ],
    "abstract": "Federated Learning (FL) has the potential for simultaneous global learning\namongst a large number of parallel agents, enabling emerging AI such as LLMs to\nbe trained across demographically diverse data. Central to this being efficient\nis the ability for FL to perform sparse gradient updates and remote direct\nmemory access at the central server. Most of the research in FL security\nfocuses on protecting data privacy at the edge client or in the communication\nchannels between the client and server. Client-facing attacks on the server are\nless well investigated as the assumption is that a large collective of clients\noffer resilience.\n  Here, we show that by attacking certain clients that lead to a high frequency\nrepetitive memory update in the server, we can remote initiate a rowhammer\nattack on the server memory. For the first time, we do not need backdoor access\nto the server, and a reinforcement learning (RL) attacker can learn how to\nmaximize server repetitive memory updates by manipulating the client's sensor\nobservation. The consequence of the remote rowhammer attack is that we are able\nto achieve bit flips, which can corrupt the server memory. We demonstrate the\nfeasibility of our attack using a large-scale FL automatic speech recognition\n(ASR) systems with sparse updates, our adversarial attacking agent can achieve\naround 70\\% repeated update rate (RUR) in the targeted server model,\neffectively inducing bit flips on server DRAM. The security implications are\nthat can cause disruptions to learning or may inadvertently cause elevated\nprivilege. This paves the way for further research on practical mitigation\nstrategies in FL and hardware design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06335v1",
    "published_date": "2025-05-09 17:27:17 UTC",
    "updated_date": "2025-05-09 17:27:17 UTC"
  },
  {
    "arxiv_id": "2505.06191v1",
    "title": "Neuro-Symbolic Concepts",
    "authors": [
      "Jiayuan Mao",
      "Joshua B. Tenenbaum",
      "Jiajun Wu"
    ],
    "abstract": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Communications of the ACM",
    "pdf_url": "http://arxiv.org/pdf/2505.06191v1",
    "published_date": "2025-05-09 17:02:51 UTC",
    "updated_date": "2025-05-09 17:02:51 UTC"
  },
  {
    "arxiv_id": "2505.06186v2",
    "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies",
    "authors": [
      "Massimiliano Pronesti",
      "Joao Bettencourt-Silva",
      "Paul Flanagan",
      "Alessandra Pascale",
      "Oisin Redmond",
      "Anya Belz",
      "Yufang Hou"
    ],
    "abstract": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06186v2",
    "published_date": "2025-05-09 16:55:06 UTC",
    "updated_date": "2025-05-13 10:50:45 UTC"
  },
  {
    "arxiv_id": "2505.06333v1",
    "title": "NSF-MAP: Neurosymbolic Multimodal Fusion for Robust and Interpretable Anomaly Prediction in Assembly Pipelines",
    "authors": [
      "Chathurangi Shyalika",
      "Renjith Prasad",
      "Fadi El Kalach",
      "Revathy Venkataramanan",
      "Ramtin Zand",
      "Ramy Harik",
      "Amit Sheth"
    ],
    "abstract": "In modern assembly pipelines, identifying anomalies is crucial in ensuring\nproduct quality and operational efficiency. Conventional single-modality\nmethods fail to capture the intricate relationships required for precise\nanomaly prediction in complex predictive environments with abundant data and\nmultiple modalities. This paper proposes a neurosymbolic AI and fusion-based\napproach for multimodal anomaly prediction in assembly pipelines. We introduce\na time series and image-based fusion model that leverages decision-level fusion\ntechniques. Our research builds upon three primary novel approaches in\nmultimodal learning: time series and image-based decision-level fusion\nmodeling, transfer learning for fusion, and knowledge-infused learning. We\nevaluate the novel method using our derived and publicly available multimodal\ndataset and conduct comprehensive ablation studies to assess the impact of our\npreprocessing techniques and fusion model compared to traditional baselines.\nThe results demonstrate that a neurosymbolic AI-based fusion approach that uses\ntransfer learning can effectively harness the complementary strengths of time\nseries and image data, offering a robust and interpretable approach for anomaly\nprediction in assembly pipelines with enhanced performance. \\noindent The\ndatasets, codes to reproduce the results, supplementary materials, and demo are\navailable at https://github.com/ChathurangiShyalika/NSF-MAP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 7 figures, 2 tables, IJCAI 2025 (International Joint\n  Conferences on Artificial Intelligence) Special Track on AI4Tech: AI Enabling\n  Critical Technologies",
    "pdf_url": "http://arxiv.org/pdf/2505.06333v1",
    "published_date": "2025-05-09 16:50:42 UTC",
    "updated_date": "2025-05-09 16:50:42 UTC"
  },
  {
    "arxiv_id": "2505.06175v1",
    "title": "Turbo-ICL: In-Context Learning-Based Turbo Equalization",
    "authors": [
      "Zihang Song",
      "Matteo Zecchin",
      "Bipin Rajendran",
      "Osvaldo Simeone"
    ],
    "abstract": "This paper introduces a novel in-context learning (ICL) framework, inspired\nby large language models (LLMs), for soft-input soft-output channel\nequalization in coded multiple-input multiple-output (MIMO) systems. The\nproposed approach learns to infer posterior symbol distributions directly from\na prompt of pilot signals and decoder feedback. A key innovation is the use of\nprompt augmentation to incorporate extrinsic information from the decoder\noutput as additional context, enabling the ICL model to refine its symbol\nestimates iteratively across turbo decoding iterations. Two model variants,\nbased on Transformer and state-space architectures, are developed and\nevaluated. Extensive simulations demonstrate that, when traditional linear\nassumptions break down, e.g., in the presence of low-resolution quantization,\nICL equalizers consistently outperform conventional model-based baselines, even\nwhen the latter are provided with perfect channel state information. Results\nalso highlight the advantage of Transformer-based models under limited training\ndiversity, as well as the efficiency of state-space models in\nresource-constrained scenarios.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06175v1",
    "published_date": "2025-05-09 16:29:29 UTC",
    "updated_date": "2025-05-09 16:29:29 UTC"
  },
  {
    "arxiv_id": "2505.06152v1",
    "title": "MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks",
    "authors": [
      "Wenqi Zeng",
      "Yuqi Sun",
      "Chenxi Ma",
      "Weimin Tan",
      "Bo Yan"
    ],
    "abstract": "Medical vision-language models (VLMs) have shown promise as clinical\nassistants across various medical fields. However, specialized dermatology VLM\ncapable of delivering professional and detailed diagnostic analysis remains\nunderdeveloped, primarily due to less specialized text descriptions in current\ndermatology multimodal datasets. To address this issue, we propose MM-Skin, the\nfirst large-scale multimodal dermatology dataset that encompasses 3 imaging\nmodalities, including clinical, dermoscopic, and pathological and nearly 10k\nhigh-quality image-text pairs collected from professional textbooks. In\naddition, we generate over 27k diverse, instruction-following vision question\nanswering (VQA) samples (9 times the size of current largest dermatology VQA\ndataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a\ndermatology-specific VLM designed for precise and nuanced skin disease\ninterpretation. Comprehensive benchmark evaluations of SkinVL on VQA,\nsupervised fine-tuning (SFT) and zero-shot classification tasks across 8\ndatasets, reveal its exceptional performance for skin diseases in comparison to\nboth general and medical VLM models. The introduction of MM-Skin and SkinVL\noffers a meaningful contribution to advancing the development of clinical\ndermatology VLM assistants. MM-Skin is available at\nhttps://github.com/ZwQ803/MM-Skin",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06152v1",
    "published_date": "2025-05-09 16:03:47 UTC",
    "updated_date": "2025-05-09 16:03:47 UTC"
  },
  {
    "arxiv_id": "2505.06150v1",
    "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets",
    "authors": [
      "Ryan Lagasse",
      "Aidan Kiernans",
      "Avijit Ghosh",
      "Shiri Dori-Hacohen"
    ],
    "abstract": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06150v1",
    "published_date": "2025-05-09 16:02:23 UTC",
    "updated_date": "2025-05-09 16:02:23 UTC"
  },
  {
    "arxiv_id": "2505.06331v1",
    "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks",
    "authors": [
      "Feilong Jiang",
      "Xiaonan Hou",
      "Jianqiao Ye",
      "Min Xia"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) are a class of deep learning models\ndesigned to solve partial differential equations by incorporating physical laws\ndirectly into the loss function. However, the internal covariate shift, which\nhas been largely overlooked, hinders the effective utilization of neural\nnetwork capacity in PINNs. To this end, we propose Mask-PINNs, a novel\narchitecture designed to address this issue in PINNs. Unlike traditional\nnormalization methods such as BatchNorm or LayerNorm, we introduce a learnable,\nnonlinear mask function that constrains the feature distributions without\nviolating underlying physics. The experimental results show that the proposed\nmethod significantly improves feature distribution stability, accuracy, and\nrobustness across various activation functions and PDE benchmarks. Furthermore,\nit enables the stable and efficient training of wider networks a capability\nthat has been largely overlooked in PINNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06331v1",
    "published_date": "2025-05-09 15:38:52 UTC",
    "updated_date": "2025-05-09 15:38:52 UTC"
  },
  {
    "arxiv_id": "2505.06330v2",
    "title": "Prompting Large Language Models for Training-Free Non-Intrusive Load Monitoring",
    "authors": [
      "Junyu Xue",
      "Xudong Wang",
      "Xiaoling He",
      "Shicheng Liu",
      "Yi Wang",
      "Guoming Tang"
    ],
    "abstract": "Non-intrusive load monitoring (NILM) aims to disaggregate aggregate household\nelectricity consumption into individual appliance usage and thus enables more\neffective energy management. While deep learning has advanced NILM, it remains\nlimited by its dependence on labeled data, restricted generalization, and lack\nof explainability. This paper introduces the first prompt-based NILM framework\nthat leverages large language models (LLMs) with in-context learning. We design\nand evaluate prompt strategies that integrate appliance features, timestamps\nand contextual information, as well as representative time-series examples on\nwidely used open datasets. With optimized prompts, LLMs achieve competitive\nstate detection accuracy and demonstrate robust generalization without the need\nfor fine-tuning. LLMs also enhance explainability by providing clear,\nhuman-readable explanations for their predictions. Our results show that LLMs\ncan reduce data requirements, improve adaptability, and provide transparent\nenergy disaggregation in NILM applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06330v2",
    "published_date": "2025-05-09 15:35:11 UTC",
    "updated_date": "2025-05-20 12:43:04 UTC"
  },
  {
    "arxiv_id": "2505.06123v1",
    "title": "Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena",
    "authors": [
      "Philip Naumann",
      "Jacob Kauffmann",
      "Grgoire Montavon"
    ],
    "abstract": "Wasserstein distances provide a powerful framework for comparing data\ndistributions. They can be used to analyze processes over time or to detect\ninhomogeneities within data. However, simply calculating the Wasserstein\ndistance or analyzing the corresponding transport map (or coupling) may not be\nsufficient for understanding what factors contribute to a high or low\nWasserstein distance. In this work, we propose a novel solution based on\nExplainable AI that allows us to efficiently and accurately attribute\nWasserstein distances to various data components, including data subgroups,\ninput features, or interpretable subspaces. Our method achieves high accuracy\nacross diverse datasets and Wasserstein distance specifications, and its\npractical utility is demonstrated in two use cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06123v1",
    "published_date": "2025-05-09 15:26:38 UTC",
    "updated_date": "2025-05-09 15:26:38 UTC"
  },
  {
    "arxiv_id": "2505.06118v1",
    "title": "The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review",
    "authors": [
      "Jingguo Qu",
      "Xinyang Han",
      "Man-Lik Chui",
      "Yao Pu",
      "Simon Takadiyi Gunda",
      "Ziman Chen",
      "Jing Qin",
      "Ann Dorothy King",
      "Winnie Chiu-Wing Chu",
      "Jing Cai",
      "Michael Tin-Cheung Ying"
    ],
    "abstract": "Automatic lymph node segmentation is the cornerstone for advances in computer\nvision tasks for early detection and staging of cancer. Traditional\nsegmentation methods are constrained by manual delineation and variability in\noperator proficiency, limiting their ability to achieve high accuracy. The\nintroduction of deep learning technologies offers new possibilities for\nimproving the accuracy of lymph node image analysis. This study evaluates the\napplication of deep learning in lymph node segmentation and discusses the\nmethodologies of various deep learning architectures such as convolutional\nneural networks, encoder-decoder networks, and transformers in analyzing\nmedical imaging data across different modalities. Despite the advancements, it\nstill confronts challenges like the shape diversity of lymph nodes, the\nscarcity of accurately labeled datasets, and the inadequate development of\nmethods that are robust and generalizable across different imaging modalities.\nTo the best of our knowledge, this is the first study that provides a\ncomprehensive overview of the application of deep learning techniques in lymph\nnode segmentation task. Furthermore, this study also explores potential future\nresearch directions, including multimodal fusion techniques, transfer learning,\nand the use of large-scale pre-trained models to overcome current limitations\nwhile enhancing cancer diagnosis and treatment planning strategies.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06118v1",
    "published_date": "2025-05-09 15:17:00 UTC",
    "updated_date": "2025-05-09 15:17:00 UTC"
  },
  {
    "arxiv_id": "2505.06111v2",
    "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
    "authors": [
      "Qingwen Bu",
      "Yanting Yang",
      "Jisong Cai",
      "Shenyuan Gao",
      "Guanghui Ren",
      "Maoqing Yao",
      "Ping Luo",
      "Hongyang Li"
    ],
    "abstract": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to RSS 2025. Code is available at\n  https://github.com/OpenDriveLab/UniVLA",
    "pdf_url": "http://arxiv.org/pdf/2505.06111v2",
    "published_date": "2025-05-09 15:11:13 UTC",
    "updated_date": "2025-05-15 10:31:45 UTC"
  },
  {
    "arxiv_id": "2505.06110v1",
    "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models",
    "authors": [
      "Jugal Gajjar",
      "Kaustik Ranaware"
    ],
    "abstract": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, 5 tables, and 19 references",
    "pdf_url": "http://arxiv.org/pdf/2505.06110v1",
    "published_date": "2025-05-09 15:10:57 UTC",
    "updated_date": "2025-05-09 15:10:57 UTC"
  },
  {
    "arxiv_id": "2505.08800v1",
    "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features",
    "authors": [
      "Olivia Nocentini",
      "Marta Lagomarsino",
      "Gokhan Solak",
      "Younggeol Cho",
      "Qiyi Tong",
      "Marta Lorenzini",
      "Arash Ajoudani"
    ],
    "abstract": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.08800v1",
    "published_date": "2025-05-09 15:06:19 UTC",
    "updated_date": "2025-05-09 15:06:19 UTC"
  },
  {
    "arxiv_id": "2505.06108v3",
    "title": "LLMs Outperform Experts on Challenging Biology Benchmarks",
    "authors": [
      "Lennart Justen"
    ],
    "abstract": "This study systematically evaluates 27 frontier Large Language Models on\neight biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with OpenAI's o3 now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including the biology subsets of GPQA and WMDP and\nLAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06108v3",
    "published_date": "2025-05-09 15:05:57 UTC",
    "updated_date": "2025-05-21 20:34:27 UTC"
  },
  {
    "arxiv_id": "2505.06096v1",
    "title": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs",
    "authors": [
      "Sam Bush",
      "Matthew DeLorenzo",
      "Phat Tieu",
      "Jeyavijayan Rajendran"
    ],
    "abstract": "Limitations in Large Language Model (LLM) capabilities for hardware design\ntasks, such as generating functional Verilog codes, have motivated various\nfine-tuning optimizations utilizing curated hardware datasets from open-source\nrepositories. However, these datasets remain limited in size and contain\nminimal checks on licensing for reuse, resulting in potential copyright\nviolations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to\nestimate the risk of Verilog-trained LLMs to generate copyright-protected\ncodes. To minimize this risk, we present an open-source Verilog dataset,\nFreeSet, containing over 220k files, along with the automated dataset curation\nframework utilized to provide additional guarantees of fair-use Verilog data.\nWe then execute an LLM fine-tuning framework consisting of continual\npre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our\nresults indicate that FreeV demonstrates the smallest risk of\ncopyright-infringement among prior works, with only a 3% violation rate.\nFurthermore, experimental results demonstrate improvements in Verilog\ngeneration functionality over its baseline model, improving VerilogEval pass@10\nrates by over 10%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at DAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06096v1",
    "published_date": "2025-05-09 14:44:07 UTC",
    "updated_date": "2025-05-09 14:44:07 UTC"
  },
  {
    "arxiv_id": "2505.06091v1",
    "title": "UniSymNet: A Unified Symbolic Network Guided by Transformer",
    "authors": [
      "Xinxin Li",
      "Juan Zhang",
      "Da Li",
      "Xingyu Liu",
      "Jin Xu",
      "Junping Yin"
    ],
    "abstract": "Symbolic Regression (SR) is a powerful technique for automatically\ndiscovering mathematical expressions from input data. Mainstream SR algorithms\nsearch for the optimal symbolic tree in a vast function space, but the\nincreasing complexity of the tree structure limits their performance. Inspired\nby neural networks, symbolic networks have emerged as a promising new paradigm.\nHowever, most existing symbolic networks still face certain challenges: binary\nnonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to\nmultivariate operators, and training with fixed architecture often leads to\nhigher complexity and overfitting. In this work, we propose a Unified Symbolic\nNetwork that unifies nonlinear binary operators into nested unary operators and\ndefine the conditions under which UniSymNet can reduce complexity. Moreover, we\npre-train a Transformer model with a novel label encoding method to guide\nstructural selection, and adopt objective-specific optimization strategies to\nlearn the parameters of the symbolic network. UniSymNet shows high fitting\naccuracy, excellent symbolic solution rate, and relatively low expression\ncomplexity, achieving competitive performance on low-dimensional Standard\nBenchmarks and high-dimensional SRBench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06091v1",
    "published_date": "2025-05-09 14:38:25 UTC",
    "updated_date": "2025-05-09 14:38:25 UTC"
  },
  {
    "arxiv_id": "2505.06085v2",
    "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities",
    "authors": [
      "Hiari Pizzini Cavagna",
      "Daniele Cesarini",
      "Andrea Bartolini"
    ],
    "abstract": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.PF",
    "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2505.06085v2",
    "published_date": "2025-05-09 14:29:37 UTC",
    "updated_date": "2025-05-15 13:07:31 UTC"
  },
  {
    "arxiv_id": "2505.06049v1",
    "title": "Seqret: Mining Rule Sets from Event Sequences",
    "authors": [
      "Aleena Siji",
      "Joscha Cppers",
      "Osman Ali Mian",
      "Jilles Vreeken"
    ],
    "abstract": "Summarizing event sequences is a key aspect of data mining. Most existing\nmethods neglect conditional dependencies and focus on discovering sequential\npatterns only. In this paper, we study the problem of discovering both\nconditional and unconditional dependencies from event sequence data. We do so\nby discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are\nsequential patterns. Rules like these are simple to understand and provide a\nclear description of the relation between the antecedent and the consequent. To\ndiscover succinct and non-redundant sets of rules we formalize the problem in\nterms of the Minimum Description Length principle. As the search space is\nenormous and does not exhibit helpful structure, we propose the Seqret method\nto discover high-quality rule sets in practice. Through extensive empirical\nevaluation we show that unlike the state of the art, Seqret ably recovers the\nground truth on synthetic datasets and finds useful rules from real datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06049v1",
    "published_date": "2025-05-09 13:44:15 UTC",
    "updated_date": "2025-05-09 13:44:15 UTC"
  },
  {
    "arxiv_id": "2505.06047v1",
    "title": "PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks",
    "authors": [
      "Francesco Spinnato",
      "Cristiano Landi"
    ],
    "abstract": "Irregular temporal data, characterized by varying recording frequencies,\ndiffering observation durations, and missing values, presents significant\nchallenges across fields like mobility, healthcare, and environmental science.\nExisting research communities often overlook or address these challenges in\nisolation, leading to fragmented tools and methods. To bridge this gap, we\nintroduce a unified framework, and the first standardized dataset repository\nfor irregular time series classification, built on a common array format to\nenhance interoperability. This repository comprises 34 datasets on which we\nbenchmark 12 classifier models from diverse domains and communities. This work\naims to centralize research efforts and enable a more robust evaluation of\nirregular temporal data analysis methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06047v1",
    "published_date": "2025-05-09 13:43:43 UTC",
    "updated_date": "2025-05-09 13:43:43 UTC"
  },
  {
    "arxiv_id": "2505.06030v1",
    "title": "Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects",
    "authors": [
      "Tobias Preintner",
      "Weixuan Yuan",
      "Qi Huang",
      "Adrian Knig",
      "Thomas Bck",
      "Elena Raponi",
      "Niki van Stein"
    ],
    "abstract": "Combining natural language and geometric shapes is an emerging research area\nwith multiple applications in robotics and language-assisted design. A crucial\ntask in this domain is object referent identification, which involves selecting\na 3D object given a textual description of the target. Variability in language\ndescriptions and spatial relationships of 3D objects makes this a complex task,\nincreasing the need to better understand the behavior of neural network models\nin this domain. However, limited research has been conducted in this area.\nSpecifically, when a model makes an incorrect prediction despite being provided\nwith a seemingly correct object description, practitioners are left wondering:\n\"Why is the model wrong?\". In this work, we present a method answering this\nquestion by generating counterfactual examples. Our method takes a\nmisclassified sample, which includes two objects and a text description, and\ngenerates an alternative yet similar formulation that would have resulted in a\ncorrect prediction by the model. We have evaluated our approach with data from\nthe ShapeTalk dataset along with three distinct models. Our counterfactual\nexamples maintain the structure of the original description, are semantically\nsimilar and meaningful. They reveal weaknesses in the description, model bias\nand enhance the understanding of the models behavior. Theses insights help\npractitioners to better interact with systems as well as engineers to improve\nmodels.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06030v1",
    "published_date": "2025-05-09 13:24:44 UTC",
    "updated_date": "2025-05-09 13:24:44 UTC"
  },
  {
    "arxiv_id": "2505.06023v1",
    "title": "Universal Approximation Theorem for Deep Q-Learning via FBSDE System",
    "authors": [
      "Qian Qi"
    ],
    "abstract": "The approximation capabilities of Deep Q-Networks (DQNs) are commonly\njustified by general Universal Approximation Theorems (UATs) that do not\nleverage the intrinsic structural properties of the optimal Q-function, the\nsolution to a Bellman equation. This paper establishes a UAT for a class of\nDQNs whose architecture is designed to emulate the iterative refinement process\ninherent in Bellman updates. A central element of our analysis is the\npropagation of regularity: while the transformation induced by a single Bellman\noperator application exhibits regularity, for which Backward Stochastic\nDifferential Equations (BSDEs) theory provides analytical tools, the uniform\nregularity of the entire sequence of value iteration iterates--specifically,\ntheir uniform Lipschitz continuity on compact domains under standard Lipschitz\nassumptions on the problem data--is derived from finite-horizon dynamic\nprogramming principles. We demonstrate that layers of a deep residual network,\nconceived as neural operators acting on function spaces, can approximate the\naction of the Bellman operator. The resulting approximation theorem is thus\nintrinsically linked to the control problem's structure, offering a proof\ntechnique wherein network depth directly corresponds to iterations of value\nfunction refinement, accompanied by controlled error propagation. This\nperspective reveals a dynamic systems view of the network's operation on a\nspace of value functions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06023v1",
    "published_date": "2025-05-09 13:11:55 UTC",
    "updated_date": "2025-05-09 13:11:55 UTC"
  },
  {
    "arxiv_id": "2505.06020v1",
    "title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding",
    "authors": [
      "Shuai Wang",
      "Ivona Najdenkoska",
      "Hongyi Zhu",
      "Stevan Rudinac",
      "Monika Kackovic",
      "Nachoem Wijnberg",
      "Marcel Worring"
    ],
    "abstract": "Understanding visual art requires reasoning across multiple perspectives --\ncultural, historical, and stylistic -- beyond mere object recognition. While\nrecent multimodal large language models (MLLMs) perform well on general image\ncaptioning, they often fail to capture the nuanced interpretations that fine\nart demands. We propose ArtRAG, a novel, training-free framework that combines\nstructured knowledge with retrieval-augmented generation (RAG) for\nmulti-perspective artwork explanation. ArtRAG automatically constructs an Art\nContext Knowledge Graph (ACKG) from domain-specific textual sources, organizing\nentities such as artists, movements, themes, and historical events into a rich,\ninterpretable graph. At inference time, a multi-granular structured retriever\nselects semantically and topologically relevant subgraphs to guide generation.\nThis enables MLLMs to produce contextually grounded, culturally informed art\ndescriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG\noutperforms several heavily trained baselines. Human evaluations further\nconfirm that ArtRAG generates coherent, insightful, and culturally enriched\ninterpretations.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06020v1",
    "published_date": "2025-05-09 13:08:27 UTC",
    "updated_date": "2025-05-09 13:08:27 UTC"
  },
  {
    "arxiv_id": "2505.05988v1",
    "title": "Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned",
    "authors": [
      "Jrgen Villadsen"
    ],
    "abstract": "MiniCalc is a web app for teaching first-order logic based on a minimal\nsequent calculus. As an option the proofs can be verified in the Isabelle proof\nassistant. We present the lessons learned using the tool in recent years at our\nuniversity.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4; I.2.3; K.3.1"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings ThEdu24, arXiv:2505.04677",
    "pdf_url": "http://arxiv.org/pdf/2505.05988v1",
    "published_date": "2025-05-09 12:18:17 UTC",
    "updated_date": "2025-05-09 12:18:17 UTC"
  },
  {
    "arxiv_id": "2505.05976v1",
    "title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs",
    "authors": [
      "Chico Sundermann",
      "Stefan Vill",
      "Elias Kuiter",
      "Sebastian Krieter",
      "Thomas Thm",
      "Matthias Tichy"
    ],
    "abstract": "Configurable systems typically consist of reusable assets that have\ndependencies between each other. To specify such dependencies, feature models\nare commonly used. As feature models in practice are often complex, automated\nreasoning is typically employed to analyze the dependencies. Here, the de facto\nstandard is translating the feature model to conjunctive normal form (CNF) to\nenable employing off-the-shelf tools, such as SAT or #SAT solvers. However,\nmodern feature-modeling dialects often contain constructs, such as cardinality\nconstraints, that are ill-suited for conversion to CNF. This mismatch between\nthe input of reasoning engines and the available feature-modeling dialects\nlimits the applicability of the more expressive constructs. In this work, we\nshorten this gap between expressive constructs and scalable automated\nreasoning. Our contribution is twofold: First, we provide a pseudo-Boolean\nencoding for feature models, which facilitates smaller representations of\ncommonly employed constructs compared to Boolean encoding. Second, we propose a\nnovel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the\ncompiled d-DNNFs, we can resort to a plethora of efficient analyses already\nused in feature modeling. Our empirical evaluation shows that our proposal\nsubstantially outperforms the state-of-the-art based on CNF inputs for\nexpressive constructs. For every considered dataset representing different\nfeature models and feature-modeling constructs, the feature models can be\nsignificantly faster translated to pseudo-Boolean than to CNF. Overall,\nderiving d-DNNFs from a feature model with the targeted expressive constraints\ncan be substantially accelerated using our pseudo-Boolean approach.\nFurthermore, our approach is competitive on feature models with only basic\nconstructs.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05976v1",
    "published_date": "2025-05-09 12:00:43 UTC",
    "updated_date": "2025-05-09 12:00:43 UTC"
  },
  {
    "arxiv_id": "2505.05965v1",
    "title": "A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection",
    "authors": [
      "Abdelfateh Bekkair",
      "Slimane Bellaouar",
      "Slimane Oulad-Naoui"
    ],
    "abstract": "Community detection in networks with overlapping structures remains a\nsignificant challenge, particularly in noisy real-world environments where\nintegrating topology, node attributes, and prior information is critical. To\naddress this, we propose a semi-supervised graph autoencoder that combines\ngraph multi-head attention and modularity maximization to robustly detect\noverlapping communities. The model learns semantic representations by fusing\nstructural, attribute, and prior knowledge while explicitly addressing noise in\nnode features. Key innovations include a noise-resistant architecture and a\nsemantic semi-supervised design optimized for community quality through\nmodularity constraints. Experiments demonstrate superior performance the model\noutperforms state-of-the-art methods in overlapping community detection\n(improvements in NMI and F1-score) and exhibits exceptional robustness to\nattribute noise, maintaining stable performance under 60\\% feature corruption.\nThese results highlight the importance of integrating attribute semantics and\nstructural patterns for accurate community discovery in complex networks.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05965v1",
    "published_date": "2025-05-09 11:34:07 UTC",
    "updated_date": "2025-05-09 11:34:07 UTC"
  },
  {
    "arxiv_id": "2505.05946v1",
    "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2",
    "authors": [
      "Vytenis liogeris",
      "Povilas Daniuis",
      "Artras Nakvosas"
    ],
    "abstract": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.05946v1",
    "published_date": "2025-05-09 10:43:37 UTC",
    "updated_date": "2025-05-09 10:43:37 UTC"
  },
  {
    "arxiv_id": "2505.05943v1",
    "title": "Achieving 3D Attention via Triplet Squeeze and Excitation Block",
    "authors": [
      "Maan Alhazmi",
      "Abdulrahman Altahhan"
    ],
    "abstract": "The emergence of ConvNeXt and its variants has reaffirmed the conceptual and\nstructural suitability of CNN-based models for vision tasks, re-establishing\nthem as key players in image classification in general, and in facial\nexpression recognition (FER) in particular. In this paper, we propose a new set\nof models that build on these advancements by incorporating a new set of\nattention mechanisms that combines Triplet attention with\nSqueeze-and-Excitation (TripSE) in four different variants. We demonstrate the\neffectiveness of these variants by applying them to the ResNet18, DenseNet and\nConvNext architectures to validate their versatility and impact. Our study\nshows that incorporating a TripSE block in these CNN models boosts their\nperformances, particularly for the ConvNeXt architecture, indicating its\nutility. We evaluate the proposed mechanisms and associated models across four\ndatasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where\nConvNext with TripSE achieves state-of-the-art results with an accuracy of\n\\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05943v1",
    "published_date": "2025-05-09 10:36:30 UTC",
    "updated_date": "2025-05-09 10:36:30 UTC"
  },
  {
    "arxiv_id": "2505.06328v1",
    "title": "A Grounded Memory System For Smart Personal Assistants",
    "authors": [
      "Felix Ocker",
      "Jrg Deigmller",
      "Pavel Smirnov",
      "Julian Eggert"
    ],
    "abstract": "A wide variety of agentic AI applications - ranging from cognitive assistants\nfor dementia patients to robotics - demand a robust memory system grounded in\nreality. In this paper, we propose such a memory system consisting of three\ncomponents. First, we combine Vision Language Models for image captioning and\nentity disambiguation with Large Language Models for consistent information\nextraction during perception. Second, the extracted information is represented\nin a memory consisting of a knowledge graph enhanced by vector embeddings to\nefficiently manage relational information. Third, we combine semantic search\nand graph query generation for question answering via Retrieval Augmented\nGeneration. We illustrate the system's working and potential using a real-world\nexample.",
    "categories": [
      "cs.AI",
      "H.3.3; H.3.4; I.2.1; I.2.5; I.2.7; I.2.10; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop",
    "pdf_url": "http://arxiv.org/pdf/2505.06328v1",
    "published_date": "2025-05-09 10:08:22 UTC",
    "updated_date": "2025-05-09 10:08:22 UTC"
  },
  {
    "arxiv_id": "2505.05916v1",
    "title": "IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction",
    "authors": [
      "Yifan Zhou",
      "Yibo Wang",
      "Chao Shang"
    ],
    "abstract": "Many real-world datasets are time series that are sequentially collected and\ncontain rich temporal information. Thus, a common interest in practice is to\ncapture dynamics of time series and predict their future evolutions. To this\nend, the recurrent neural network (RNN) has been a prevalent and effective\nmachine learning option, which admits a nonlinear state-space model\nrepresentation. Motivated by the resemblance between RNN and Kalman filter (KF)\nfor linear state-space models, we propose in this paper Innovation-driven RNN\n(IRNN), a novel RNN architecture tailored to time-series data modeling and\nprediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past\nprediction errors are adopted as additional input signals to update hidden\nstates of RNN and boost prediction performance. Since innovation data depend on\nnetwork parameters, existing training algorithms for RNN do not apply to IRNN\nstraightforwardly. Thus, a tailored training algorithm dubbed input\nupdating-based back-propagation through time (IU-BPTT) is further proposed,\nwhich alternates between updating innovations and optimizing network parameters\nvia gradient descent. Experiments on real-world benchmark datasets show that\nthe integration of innovations into various forms of RNN leads to remarkably\nimproved prediction accuracy of IRNN without increasing the training cost\nsubstantially.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05916v1",
    "published_date": "2025-05-09 09:43:40 UTC",
    "updated_date": "2025-05-09 09:43:40 UTC"
  },
  {
    "arxiv_id": "2505.05901v2",
    "title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection",
    "authors": [
      "Hanzhe Liang",
      "Aoran Wang",
      "Jie Zhou",
      "Xin Jin",
      "Can Gao",
      "Jinbao Wang"
    ],
    "abstract": "In this paper, we explore a novel approach to 3D anomaly detection (AD) that\ngoes beyond merely identifying anomalies based on structural characteristics.\nOur primary perspective is that most anomalies arise from unpredictable\ndefective forces originating from both internal and external sources. To\naddress these anomalies, we seek out opposing forces that can help correct\nthem. Therefore, we introduce the Mechanics Complementary Model-based Framework\nfor the 3D-AD task (MC4AD), which generates internal and external corrective\nforces for each point. We first propose a Diverse Anomaly-Generation (DA-Gen)\nmodule designed to simulate various types of anomalies. Next, we present the\nCorrective Force Prediction Network (CFP-Net), which uses complementary\nrepresentations for point-level analysis to simulate the different\ncontributions from internal and external corrective forces. To ensure the\ncorrective forces are constrained effectively, we have developed a combined\nloss function that includes a new symmetric loss and an overall loss. Notably,\nwe implement a Hierarchical Quality Control (HQC) strategy based on a three-way\ndecision process and contribute a dataset titled Anomaly-IntraVariance, which\nincorporates intraclass variance to evaluate our model. As a result, the\nproposed MC4AD has been proven effective through theory and experimentation.\nThe experimental results demonstrate that our approach yields nine\nstate-of-the-art performances, achieving optimal results with minimal\nparameters and the fastest inference speed across five existing datasets, in\naddition to the proposed Anomaly-IntraVariance dataset. The source is available\nat https://github.com/hzzzzzhappy/MC4AD",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.05901v2",
    "published_date": "2025-05-09 09:09:08 UTC",
    "updated_date": "2025-05-15 15:46:43 UTC"
  },
  {
    "arxiv_id": "2505.05895v1",
    "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI",
    "authors": [
      "Benjamin Raphael Ernhofer",
      "Daniil Prokhorov",
      "Jannica Langner",
      "Dominik Bollmann"
    ],
    "abstract": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.2% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.4% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05895v1",
    "published_date": "2025-05-09 09:01:52 UTC",
    "updated_date": "2025-05-09 09:01:52 UTC"
  },
  {
    "arxiv_id": "2505.05893v1",
    "title": "LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization",
    "authors": [
      "Seunghee Han",
      "Soongyu Choi",
      "Joo-Young Kim"
    ],
    "abstract": "Recent advances in Protein Structure Prediction Models (PPMs), such as\nAlphaFold2 and ESMFold, have revolutionized computational biology by achieving\nunprecedented accuracy in predicting three-dimensional protein folding\nstructures. However, these models face significant scalability challenges,\nparticularly when processing proteins with long amino acid sequences (e.g.,\nsequence length > 1,000). The primary bottleneck that arises from the\nexponential growth in activation sizes is driven by the unique data structure\nin PPM, which introduces an additional dimension that leads to substantial\nmemory and computational demands. These limitations have hindered the effective\nscaling of PPM for real-world applications, such as analyzing large proteins or\ncomplex multimers with critical biological and pharmaceutical relevance.\n  In this paper, we present LightNobel, the first hardware-software co-designed\naccelerator developed to overcome scalability limitations on the sequence\nlength in PPM. At the software level, we propose Token-wise Adaptive Activation\nQuantization (AAQ), which leverages unique token-wise characteristics, such as\ndistogram patterns in PPM activations, to enable fine-grained quantization\ntechniques without compromising accuracy. At the hardware level, LightNobel\nintegrates the multi-precision reconfigurable matrix processing unit (RMPU) and\nversatile vector processing unit (VVPU) to enable the efficient execution of\nAAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup\nand 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100\nGPUs, respectively, while maintaining negligible accuracy loss. It also reduces\nthe peak memory requirement up to 120.05x in PPM, enabling scalable processing\nfor proteins with long sequences.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "q-bio.BM",
      "B.7; I.2; J.3"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear in the Proceedings of the 52nd IEEE/ACM International\n  Symposium on Computer Architecture (ISCA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.05893v1",
    "published_date": "2025-05-09 09:01:10 UTC",
    "updated_date": "2025-05-09 09:01:10 UTC"
  },
  {
    "arxiv_id": "2505.05880v1",
    "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams",
    "authors": [
      "Bettina Fazzinga",
      "Sergio Flesca",
      "Filippo Furfaro",
      "Luigi Pontieri",
      "Francesco Scala"
    ],
    "abstract": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05880v1",
    "published_date": "2025-05-09 08:45:07 UTC",
    "updated_date": "2025-05-09 08:45:07 UTC"
  },
  {
    "arxiv_id": "2505.05877v2",
    "title": "Multi-Modal Molecular Representation Learning via Structure Awareness",
    "authors": [
      "Rong Yin",
      "Ruyue Liu",
      "Xiaoshuai Hao",
      "Xingrui Zhou",
      "Yong Liu",
      "Can Ma",
      "Weiping Wang"
    ],
    "abstract": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE Transactions on Image Processing (TIP) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.05877v2",
    "published_date": "2025-05-09 08:37:29 UTC",
    "updated_date": "2025-05-12 01:15:32 UTC"
  },
  {
    "arxiv_id": "2505.05870v1",
    "title": "Towards Facial Image Compression with Consistency Preserving Diffusion Prior",
    "authors": [
      "Yimin Zhou",
      "Yichong Xia",
      "Bin Chen",
      "Baoyi An",
      "Haoqian Wang",
      "Zhi Wang",
      "Yaowei Wang",
      "Zikun Zhou"
    ],
    "abstract": "With the widespread application of facial image data across various domains,\nthe efficient storage and transmission of facial images has garnered\nsignificant attention. However, the existing learned face image compression\nmethods often produce unsatisfactory reconstructed image quality at low bit\nrates. Simply adapting diffusion-based compression methods to facial\ncompression tasks results in reconstructed images that perform poorly in\ndownstream applications due to insufficient preservation of high-frequency\ninformation. To further explore the diffusion prior in facial image\ncompression, we propose Facial Image Compression with a Stable Diffusion Prior\n(FaSDiff), a method that preserves consistency through frequency enhancement.\nFaSDiff employs a high-frequency-sensitive compressor in an end-to-end\nframework to capture fine image details and produce robust visual prompts.\nAdditionally, we introduce a hybrid low-frequency enhancement module that\ndisentangles low-frequency facial semantics and stably modulates the diffusion\nprior alongside visual prompts. The proposed modules allow FaSDiff to leverage\ndiffusion priors for superior human visual perception while minimizing\nperformance loss in machine vision due to semantic inconsistency. Extensive\nexperiments show that FaSDiff outperforms state-of-the-art methods in balancing\nhuman visual quality and machine vision accuracy. The code will be released\nafter the paper is accepted.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05870v1",
    "published_date": "2025-05-09 08:13:51 UTC",
    "updated_date": "2025-05-09 08:13:51 UTC"
  },
  {
    "arxiv_id": "2505.05869v1",
    "title": "Generative Discovery of Partial Differential Equations by Learning from Math Handbooks",
    "authors": [
      "Hao Xu",
      "Yuntian Chen",
      "Rui Cao",
      "Tianning Tang",
      "Mengge Du",
      "Jian Li",
      "Adrian H. Callaghan",
      "Dongxiao Zhang"
    ],
    "abstract": "Data driven discovery of partial differential equations (PDEs) is a promising\napproach for uncovering the underlying laws governing complex systems. However,\npurely data driven techniques face the dilemma of balancing search space with\noptimization efficiency. This study introduces a knowledge guided approach that\nincorporates existing PDEs documented in a mathematical handbook to facilitate\nthe discovery process. These PDEs are encoded as sentence like structures\ncomposed of operators and basic terms, and used to train a generative model,\ncalled EqGPT, which enables the generation of free form PDEs. A loop of\ngeneration evaluation optimization is constructed to autonomously identify the\nmost suitable PDE. Experimental results demonstrate that this framework can\nrecover a variety of PDE forms with high accuracy and computational efficiency,\nparticularly in cases involving complex temporal derivatives or intricate\nspatial terms, which are often beyond the reach of conventional methods. The\napproach also exhibits generalizability to irregular spatial domains and higher\ndimensional settings. Notably, it succeeds in discovering a previously\nunreported PDE governing strongly nonlinear surface gravity waves propagating\ntoward breaking, based on real world experimental data, highlighting its\napplicability to practical scenarios and its potential to support scientific\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05869v1",
    "published_date": "2025-05-09 08:09:21 UTC",
    "updated_date": "2025-05-09 08:09:21 UTC"
  },
  {
    "arxiv_id": "2505.05863v1",
    "title": "Evolutionary ecology of words",
    "authors": [
      "Reiji Suzuki",
      "Takaya Arita"
    ],
    "abstract": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species.",
    "categories": [
      "q-bio.PE",
      "cs.AI",
      "cs.CL",
      "92B20"
    ],
    "primary_category": "q-bio.PE",
    "comment": "8 pages, 5 figures. Preprint of the paper published in Proceedings of\n  2025 IEEE Symposium on Computational Intelligence in Artificial Life and\n  Cooperative Intelligent Systems (ALIFE-CIS)",
    "pdf_url": "http://arxiv.org/pdf/2505.05863v1",
    "published_date": "2025-05-09 07:57:10 UTC",
    "updated_date": "2025-05-09 07:57:10 UTC"
  },
  {
    "arxiv_id": "2505.07866v1",
    "title": "Computationally Efficient Diffusion Models in Medical Imaging: A Comprehensive Review",
    "authors": [
      "Abdullah",
      "Tao Huang",
      "Ickjai Lee",
      "Euijoon Ahn"
    ],
    "abstract": "The diffusion model has recently emerged as a potent approach in computer\nvision, demonstrating remarkable performances in the field of generative\nartificial intelligence. Capable of producing high-quality synthetic images,\ndiffusion models have been successfully applied across a range of applications.\nHowever, a significant challenge remains with the high computational cost\nassociated with training and generating these models. This study focuses on the\nefficiency and inference time of diffusion-based generative models,\nhighlighting their applications in both natural and medical imaging. We present\nthe most recent advances in diffusion models by categorizing them into three\nkey models: the Denoising Diffusion Probabilistic Model (DDPM), the Latent\nDiffusion Model (LDM), and the Wavelet Diffusion Model (WDM). These models play\na crucial role in medical imaging, where producing fast, reliable, and\nhigh-quality medical images is essential for accurate analysis of abnormalities\nand disease diagnosis. We first investigate the general framework of DDPM, LDM,\nand WDM and discuss the computational complexity gap filled by these models in\nnatural and medical imaging. We then discuss the current limitations of these\nmodels as well as the opportunities and future research directions in medical\nimaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "pages 36, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.07866v1",
    "published_date": "2025-05-09 07:56:04 UTC",
    "updated_date": "2025-05-09 07:56:04 UTC"
  },
  {
    "arxiv_id": "2505.06326v1",
    "title": "Enterprise Architecture as a Dynamic Capability for Scalable and Sustainable Generative AI adoption: Bridging Innovation and Governance in Large Organisations",
    "authors": [
      "Alexander Ettinger"
    ],
    "abstract": "Generative Artificial Intelligence is a powerful new technology with the\npotential to boost innovation and reshape governance in many industries.\nNevertheless, organisations face major challenges in scaling GenAI, including\ntechnology complexity, governance gaps and resource misalignments. This study\nexplores how Enterprise Architecture Management can meet the complex\nrequirements of GenAI adoption within large enterprises. Based on a systematic\nliterature review and the qualitative analysis of 16 semi-structured interviews\nwith experts, it examines the relationships between EAM, dynamic capabilities\nand GenAI adoption. The review identified key limitations in existing EA\nframeworks, particularly their inability to fully address the unique\nrequirements of GenAI. The interviews, analysed using the Gioia methodology,\nrevealed critical enablers and barriers to GenAI adoption across industries.\nThe findings indicate that EAM, when theorised as sensing, seizing and\ntransforming dynamic capabilities, can enhance GenAI adoption by improving\nstrategic alignment, governance frameworks and organisational agility. However,\nthe study also highlights the need to tailor EA frameworks to GenAI-specific\nchallenges, including low data governance maturity and the balance between\ninnovation and compliance. Several conceptual frameworks are proposed to guide\nEA leaders in aligning GenAI maturity with organisational readiness. The work\ncontributes to academic understanding and industry practice by clarifying the\nrole of EA in bridging innovation and governance in disruptive technology\nenvironments.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "82 pages excluding appendix",
    "pdf_url": "http://arxiv.org/pdf/2505.06326v1",
    "published_date": "2025-05-09 07:41:33 UTC",
    "updated_date": "2025-05-09 07:41:33 UTC"
  },
  {
    "arxiv_id": "2505.05849v2",
    "title": "AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents",
    "authors": [
      "Zhun Wang",
      "Vincent Siu",
      "Zhe Ye",
      "Tianneng Shi",
      "Yuzhou Nie",
      "Xuandong Zhao",
      "Chenguang Wang",
      "Wenbo Guo",
      "Dawn Song"
    ],
    "abstract": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05849v2",
    "published_date": "2025-05-09 07:40:17 UTC",
    "updated_date": "2025-05-21 05:34:08 UTC"
  },
  {
    "arxiv_id": "2505.07865v1",
    "title": "CellVerse: Do Large Language Models Really Understand Cell Biology?",
    "authors": [
      "Fan Zhang",
      "Tianyu Liu",
      "Zhihong Zhu",
      "Hao Wu",
      "Haixin Wang",
      "Donghao Zhou",
      "Yefeng Zheng",
      "Kun Wang",
      "Xian Wu",
      "Pheng-Ann Heng"
    ],
    "abstract": "Recent studies have demonstrated the feasibility of modeling single-cell data\nas natural languages and the potential of leveraging powerful large language\nmodels (LLMs) for understanding cell biology. However, a comprehensive\nevaluation of LLMs' performance on language-driven single-cell analysis tasks\nstill remains unexplored. Motivated by this challenge, we introduce CellVerse,\na unified language-centric question-answering benchmark that integrates four\ntypes of single-cell multi-omics data and encompasses three hierarchical levels\nof single-cell analysis tasks: cell type annotation (cell-level), drug response\nprediction (drug-level), and perturbation analysis (gene-level). Going beyond\nthis, we systematically evaluate the performance across 14 open-source and\nclosed-source LLMs ranging from 160M to 671B on CellVerse. Remarkably, the\nexperimental results reveal: (1) Existing specialist models (C2S-Pythia) fail\nto make reasonable decisions across all sub-tasks within CellVerse, while\ngeneralist models such as Qwen, Llama, GPT, and DeepSeek family models exhibit\npreliminary understanding capabilities within the realm of cell biology. (2)\nThe performance of current LLMs falls short of expectations and has substantial\nroom for improvement. Notably, in the widely studied drug response prediction\ntask, none of the evaluated LLMs demonstrate significant performance\nimprovement over random guessing. CellVerse offers the first large-scale\nempirical demonstration that significant challenges still remain in applying\nLLMs to cell biology. By introducing CellVerse, we lay the foundation for\nadvancing cell biology through natural languages and hope this paradigm could\nfacilitate next-generation single-cell analysis.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CL",
      "q-bio.CB"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07865v1",
    "published_date": "2025-05-09 06:47:23 UTC",
    "updated_date": "2025-05-09 06:47:23 UTC"
  },
  {
    "arxiv_id": "2505.06325v1",
    "title": "Human in the Latent Loop (HILL): Interactively Guiding Model Training Through Human Intuition",
    "authors": [
      "Daniel Geissler",
      "Lars Krupp",
      "Vishal Banwari",
      "David Habusch",
      "Bo Zhou",
      "Paul Lukowicz",
      "Jakob Karolus"
    ],
    "abstract": "Latent space representations are critical for understanding and improving the\nbehavior of machine learning models, yet they often remain obscure and\nintricate. Understanding and exploring the latent space has the potential to\ncontribute valuable human intuition and expertise about respective domains. In\nthis work, we present HILL, an interactive framework allowing users to\nincorporate human intuition into the model training by interactively reshaping\nlatent space representations. The modifications are infused into the model\ntraining loop via a novel approach inspired by knowledge distillation, treating\nthe user's modifications as a teacher to guide the model in reshaping its\nintrinsic latent representation. The process allows the model to converge more\neffectively and overcome inefficiencies, as well as provide beneficial insights\nto the user. We evaluated HILL in a user study tasking participants to train an\noptimal model, closely observing the employed strategies. The results\ndemonstrated that human-guided latent space modifications enhance model\nperformance while maintaining generalization, yet also revealing the risks of\nincluding user biases. Our work introduces a novel human-AI interaction\nparadigm that infuses human intuition into model training and critically\nexamines the impact of human intervention on training strategies and potential\nbiases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06325v1",
    "published_date": "2025-05-09 06:17:46 UTC",
    "updated_date": "2025-05-09 06:17:46 UTC"
  },
  {
    "arxiv_id": "2505.05799v1",
    "title": "MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design",
    "authors": [
      "Haojie Duanmu",
      "Xiuhong Li",
      "Zhihang Yuan",
      "Size Zheng",
      "Jiangfei Duan",
      "Xingcheng Zhang",
      "Dahua Lin"
    ],
    "abstract": "Mixture-of-Experts (MoE) models face deployment challenges due to their large\nparameter counts and computational demands. We explore quantization for MoE\nmodels and highlight two key insights: 1) linear blocks exhibit varying\nquantization sensitivity, and 2) divergent expert activation frequencies create\nheterogeneous computational characteristics. Based on these observations, we\nintroduce MxMoE, a mixed-precision optimization framework for MoE models that\nconsiders both algorithmic and system perspectives. MxMoE navigates the design\nspace defined by parameter sensitivity, expert activation dynamics, and\nhardware resources to derive efficient mixed-precision configurations.\nAdditionally, MxMoE automatically generates optimized mixed-precision GroupGEMM\nkernels, enabling parallel execution of GEMMs with different precisions.\nEvaluations show that MxMoE outperforms existing methods, achieving 2.4 lower\nWikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup\nover full precision, as well as up to 29.4% speedup over uniform quantization\nat equivalent accuracy with 5-bit weight-activation quantization. Our code is\navailable at https://github.com/cat538/MxMoE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05799v1",
    "published_date": "2025-05-09 05:32:21 UTC",
    "updated_date": "2025-05-09 05:32:21 UTC"
  },
  {
    "arxiv_id": "2505.05796v1",
    "title": "Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency",
    "authors": [
      "Xinyu Liang",
      "Frits de Nijs",
      "Buser Say",
      "Hao Wang"
    ],
    "abstract": "Heating, Ventilation, and Air Conditioning (HVAC) systems account for\napproximately 38% of building energy consumption globally, making them one of\nthe most energy-intensive services. The increasing emphasis on energy\nefficiency and sustainability, combined with the need for enhanced occupant\ncomfort, presents a significant challenge for traditional HVAC systems. These\nsystems often fail to dynamically adjust to real-time changes in electricity\nmarket rates or individual comfort preferences, leading to increased energy\ncosts and reduced comfort. In response, we propose a Human-in-the-Loop (HITL)\nArtificial Intelligence framework that optimizes HVAC performance by\nincorporating real-time user feedback and responding to fluctuating electricity\nprices. Unlike conventional systems that require predefined information about\noccupancy or comfort levels, our approach learns and adapts based on ongoing\nuser input. By integrating the occupancy prediction model with reinforcement\nlearning, the system improves operational efficiency and reduces energy costs\nin line with electricity market dynamics, thereby contributing to demand\nresponse initiatives. Through simulations, we demonstrate that our method\nachieves significant cost reductions compared to baseline approaches while\nmaintaining or enhancing occupant comfort. This feedback-driven approach\nensures personalized comfort control without the need for predefined settings,\noffering a scalable solution that balances individual preferences with economic\nand environmental goals.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "ACM e-Energy 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.05796v1",
    "published_date": "2025-05-09 05:23:37 UTC",
    "updated_date": "2025-05-09 05:23:37 UTC"
  },
  {
    "arxiv_id": "2505.05794v1",
    "title": "What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips",
    "authors": [
      "Renjie Li",
      "Wenjie Wei",
      "Qi Xin",
      "Xiaoli Liu",
      "Sixuan Mao",
      "Erik Ma",
      "Zijian Chen",
      "Malu Zhang",
      "Haizhou Li",
      "Zhaoyu Zhang"
    ],
    "abstract": "Large language models (LLMs) are rapidly pushing the limits of contemporary\ncomputing hardware. For example, training GPT-3 has been estimated to consume\naround 1300 MWh of electricity, and projections suggest future models may\nrequire city-scale (gigawatt) power budgets. These demands motivate exploration\nof computing paradigms beyond conventional von Neumann architectures. This\nreview surveys emerging photonic hardware optimized for next-generation\ngenerative AI computing. We discuss integrated photonic neural network\narchitectures (e.g., Mach-Zehnder interferometer meshes, lasers,\nwavelength-multiplexed microring resonators) that perform ultrafast matrix\noperations. We also examine promising alternative neuromorphic devices,\nincluding spiking neural network circuits and hybrid spintronic-photonic\nsynapses, which combine memory and processing. The integration of\ntwo-dimensional materials (graphene, TMDCs) into silicon photonic platforms is\nreviewed for tunable modulators and on-chip synaptic elements.\nTransformer-based LLM architectures (self-attention and feed-forward layers)\nare analyzed in this context, identifying strategies and challenges for mapping\ndynamic matrix multiplications onto these novel hardware substrates. We then\ndissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and\nLLaMA, highlighting their architectural similarities and differences. We\nsynthesize state-of-the-art components, algorithms, and integration methods,\nhighlighting key advances and open issues in scaling such systems to mega-sized\nLLM models. We find that photonic computing systems could potentially surpass\nelectronic processors by orders of magnitude in throughput and energy\nefficiency, but require breakthroughs in memory, especially for long-context\nwindows and long token sequences, and in storage of ultra-large datasets.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "36 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.05794v1",
    "published_date": "2025-05-09 05:19:14 UTC",
    "updated_date": "2025-05-09 05:19:14 UTC"
  },
  {
    "arxiv_id": "2505.05784v3",
    "title": "FlowHFT: Imitation Learning via Flow Matching Policy for Optimal High-Frequency Trading under Diverse Market Conditions",
    "authors": [
      "Yang Li",
      "Zhi Chen",
      "Steve Yang"
    ],
    "abstract": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.TR",
    "comment": "16 pages, 6 figures, 7 tables, 2 algorithms",
    "pdf_url": "http://arxiv.org/pdf/2505.05784v3",
    "published_date": "2025-05-09 04:58:14 UTC",
    "updated_date": "2025-05-22 04:48:37 UTC"
  },
  {
    "arxiv_id": "2505.06324v1",
    "title": "Document Attribution: Examining Citation Relationships using Large Language Models",
    "authors": [
      "Vipula Rawte",
      "Ryan A. Rossi",
      "Franck Dernoncourt",
      "Nedim Lipka"
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly applied to document-based\ntasks - such as document summarization, question answering, and information\nextraction - where user requirements focus on retrieving information from\nprovided documents rather than relying on the model's parametric knowledge,\nensuring the trustworthiness and interpretability of these systems has become a\ncritical concern. A central approach to addressing this challenge is\nattribution, which involves tracing the generated outputs back to their source\ndocuments. However, since LLMs can produce inaccurate or imprecise responses,\nit is crucial to assess the reliability of these citations.\n  To tackle this, our work proposes two techniques. (1) A zero-shot approach\nthat frames attribution as a straightforward textual entailment task. Our\nmethod using flan-ul2 demonstrates an improvement of 0.27% and 2.4% over the\nbest baseline of ID and OOD sets of AttributionBench, respectively. (2) We also\nexplore the role of the attention mechanism in enhancing the attribution\nprocess. Using a smaller LLM, flan-t5-small, the F1 scores outperform the\nbaseline across almost all layers except layer 4 and layers 8 through 11.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06324v1",
    "published_date": "2025-05-09 04:40:11 UTC",
    "updated_date": "2025-05-09 04:40:11 UTC"
  },
  {
    "arxiv_id": "2505.05777v1",
    "title": "PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection",
    "authors": [
      "Domenico Cotroneo",
      "Giuseppe De Rosa",
      "Pietro Liguori"
    ],
    "abstract": "This paper presents PyResBugs, a curated dataset of residual bugs, i.e.,\ndefects that persist undetected during traditional testing but later surface in\nproduction, collected from major Python frameworks. Each bug in the dataset is\npaired with its corresponding fault-free (fixed) version and annotated with\nmulti-level natural language (NL) descriptions. These NL descriptions enable\nnatural language-driven fault injection, offering a novel approach to\nsimulating real-world faults in software systems. By bridging the gap between\nsoftware fault injection techniques and real-world representativeness,\nPyResBugs provides researchers with a high-quality resource for advancing\nAI-driven automated testing in Python systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05777v1",
    "published_date": "2025-05-09 04:39:09 UTC",
    "updated_date": "2025-05-09 04:39:09 UTC"
  },
  {
    "arxiv_id": "2505.07864v1",
    "title": "Arrow-Guided VLM: Enhancing Flowchart Understanding via Arrow Direction Encoding",
    "authors": [
      "Takamitsu Omasa",
      "Ryo Koshihara",
      "Masumi Morishige"
    ],
    "abstract": "Flowcharts are indispensable tools in software design and business-process\nanalysis, yet current vision-language models (VLMs) frequently misinterpret the\ndirectional arrows and graph topology that set these diagrams apart from\nnatural images. We introduce a seven-stage pipeline grouped into three broader\nprocesses: (1) arrow-aware detection of nodes and arrow endpoints; (2) optical\ncharacter recognition (OCR) to extract node text; and (3) construction of a\nstructured prompt that guides the VLMs. Tested on a 90-question benchmark\ndistilled from 30 annotated flowcharts, the method raises overall accuracy from\n80 % to 89 % (+9 percentage points) without any task-specific fine-tuning. The\ngain is most pronounced for next-step queries (25/30 -> 30/30; 100 %, +17 pp);\nbranch-result questions improve more modestly, and before-step questions remain\ndifficult. A parallel evaluation with an LLM-as-a-Judge protocol shows the same\ntrends, reinforcing the advantage of explicit arrow encoding. Limitations\ninclude dependence on detector and OCR precision, the small evaluation set, and\nresidual errors at nodes with multiple incoming edges. Future work will enlarge\nthe benchmark with synthetic and handwritten flowcharts and assess the approach\non Business Process Model and Notation (BPMN) and Unified Modeling Language\n(UML).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 1 figures,",
    "pdf_url": "http://arxiv.org/pdf/2505.07864v1",
    "published_date": "2025-05-09 04:27:36 UTC",
    "updated_date": "2025-05-09 04:27:36 UTC"
  },
  {
    "arxiv_id": "2505.05768v1",
    "title": "Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition",
    "authors": [
      "Weiyi Zhang",
      "Peranut Chotcomwongse",
      "Yinwen Li",
      "Pusheng Xu",
      "Ruijie Yao",
      "Lianhao Zhou",
      "Yuxuan Zhou",
      "Hui Feng",
      "Qiping Zhou",
      "Xinyue Wang",
      "Shoujin Huang",
      "Zihao Jin",
      "Florence H. T. Chung",
      "Shujun Wang",
      "Yalin Zheng",
      "Mingguang He",
      "Danli Shi",
      "Paisan Ruamviboonsuk"
    ],
    "abstract": "Diabetic macular edema (DME) significantly contributes to visual impairment\nin diabetic patients. Treatment responses to intravitreal therapies vary,\nhighlighting the need for patient stratification to predict therapeutic\nbenefits and enable personalized strategies. To our knowledge, this study is\nthe first to explore pre-treatment stratification for predicting DME treatment\nresponses. To advance this research, we organized the 2nd Asia-Pacific\nTele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The\ncompetition focused on improving predictive accuracy for anti-VEGF therapy\nresponses using ophthalmic OCT images. We provided a dataset containing tens of\nthousands of OCT images from 2,000 patients with labels across four sub-tasks.\nThis paper details the competition's structure, dataset, leading methods, and\nevaluation metrics. The competition attracted strong scientific community\nparticipation, with 170 teams initially registering and 41 reaching the final\nround. The top-performing team achieved an AUC of 80.06%, highlighting the\npotential of AI in personalized DME treatment and clinical decision-making.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "42 pages,5 tables, 12 figures, challenge report",
    "pdf_url": "http://arxiv.org/pdf/2505.05768v1",
    "published_date": "2025-05-09 04:12:05 UTC",
    "updated_date": "2025-05-09 04:12:05 UTC"
  },
  {
    "arxiv_id": "2505.05762v1",
    "title": "Multi-Agent Systems for Robotic Autonomy with LLMs",
    "authors": [
      "Junhong Chen",
      "Ziqi Yang",
      "Haoyuan G Xu",
      "Dandan Zhang",
      "George Mylonas"
    ],
    "abstract": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "11 pages, 2 figures, 5 tables, submitted for publication",
    "pdf_url": "http://arxiv.org/pdf/2505.05762v1",
    "published_date": "2025-05-09 03:52:37 UTC",
    "updated_date": "2025-05-09 03:52:37 UTC"
  },
  {
    "arxiv_id": "2505.05758v2",
    "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning",
    "authors": [
      "Azim Ospanov",
      "Farzan Farnia",
      "Roozbeh Yousefzadeh"
    ],
    "abstract": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05758v2",
    "published_date": "2025-05-09 03:38:31 UTC",
    "updated_date": "2025-05-12 08:03:49 UTC"
  },
  {
    "arxiv_id": "2505.05756v1",
    "title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms",
    "authors": [
      "Antonio Jimeno Yepes",
      "Pieter Barnard"
    ],
    "abstract": "Large Language Models (LLMs) have unveiled remarkable capabilities in\nunderstanding and generating both natural language and code, but LLM reasoning\nis prone to hallucination and struggle with complex, novel scenarios, often\ngetting stuck on partial or incorrect solutions. However, the inherent ability\nof Evolutionary Algorithms (EAs) to explore extensive and complex search spaces\nmakes them particularly effective in scenarios where traditional optimization\nmethodologies may falter. However, EAs explore a vast search space when applied\nto complex problems.\n  To address the computational bottleneck of evaluating large populations,\nparticularly crucial for complex evolutionary tasks, we introduce a highly\nefficient evaluation framework. This implementation maintains compatibility\nwith existing primitive definitions, ensuring the generation of valid\nindividuals.\n  Using LLMs, we propose an enhanced evolutionary search strategy that enables\na more focused exploration of expansive solution spaces. LLMs facilitate the\ngeneration of superior candidate solutions, as evidenced by empirical results\ndemonstrating their efficacy in producing improved outcomes.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05756v1",
    "published_date": "2025-05-09 03:32:18 UTC",
    "updated_date": "2025-05-09 03:32:18 UTC"
  },
  {
    "arxiv_id": "2505.05753v1",
    "title": "Towards Embodiment Scaling Laws in Robot Locomotion",
    "authors": [
      "Bo Ai",
      "Liu Dai",
      "Nico Bohlinger",
      "Dichen Li",
      "Tongzhou Mu",
      "Zhanxin Wu",
      "K. Fay",
      "Henrik I. Christensen",
      "Jan Peters",
      "Hao Su"
    ],
    "abstract": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "32 pages. Project website: https://embodiment-scaling-laws.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.05753v1",
    "published_date": "2025-05-09 03:25:43 UTC",
    "updated_date": "2025-05-09 03:25:43 UTC"
  },
  {
    "arxiv_id": "2505.06321v2",
    "title": "Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Representation Learning",
    "authors": [
      "Hang Gao",
      "Chenhao Zhang",
      "Tie Wang",
      "Junsuo Zhao",
      "Fengge Wu",
      "Changwen Zheng",
      "Huaping Liu"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across various\ndomains. However, they still face significant challenges, including high\ncomputational costs for training and limitations in solving complex reasoning\nproblems. Although existing methods have extended the reasoning capabilities of\nLLMs through structured paradigms, these approaches often rely on task-specific\nprompts and predefined reasoning processes, which constrain their flexibility\nand generalizability. To address these limitations, we propose a novel\nframework that leverages graph learning to enable more flexible and adaptive\nreasoning capabilities for LLMs. Specifically, this approach models the\nreasoning process of a problem as a graph and employs LLM-based graph learning\nto guide the adaptive generation of each reasoning step. To further enhance the\nadaptability of the model, we introduce a Graph Neural Network (GNN) module to\nperform representation learning on the generated reasoning process, enabling\nreal-time adjustments to both the model and the prompt. Experimental results\ndemonstrate that this method significantly improves reasoning performance\nacross multiple tasks without requiring additional training or task-specific\nprompt design. Code can be found in https://github.com/zch65458525/L2T.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.06321v2",
    "published_date": "2025-05-09 02:51:22 UTC",
    "updated_date": "2025-05-17 00:10:14 UTC"
  },
  {
    "arxiv_id": "2505.05738v1",
    "title": "Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering",
    "authors": [
      "Yiming Niu",
      "Jinliang Deng",
      "Lulu Zhang",
      "Zimu Zhou",
      "Yongxin Tong"
    ],
    "abstract": "Accurate and efficient multivariate time series (MTS) forecasting is\nessential for applications such as traffic management and weather prediction,\nwhich depend on capturing long-range temporal dependencies and interactions\nbetween entities. Existing methods, particularly those based on Transformer\narchitectures, compute pairwise dependencies across all time steps, leading to\na computational complexity that scales quadratically with the length of the\ninput. To overcome these challenges, we introduce the Forecaster with Offline\nClustering Using Segments (FOCUS), a novel approach to MTS forecasting that\nsimplifies long-range dependency modeling through the use of prototypes\nextracted via offline clustering. These prototypes encapsulate high-level\nevents in the real-world system underlying the data, summarizing the key\ncharacteristics of similar time segments. In the online phase, FOCUS\ndynamically adapts these patterns to the current input and captures\ndependencies between the input segment and high-level events, enabling both\naccurate and efficient forecasting. By identifying prototypes during the\noffline clustering phase, FOCUS reduces the computational complexity of\nmodeling long-range dependencies in the online phase to linear scaling.\nExtensive experiments across diverse benchmarks demonstrate that FOCUS achieves\nstate-of-the-art accuracy while significantly reducing computational costs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05738v1",
    "published_date": "2025-05-09 02:34:06 UTC",
    "updated_date": "2025-05-09 02:34:06 UTC"
  },
  {
    "arxiv_id": "2505.05710v1",
    "title": "HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder",
    "authors": [
      "Wooyoung Jeong",
      "Hyun Jae Park",
      "Seonghun Jeong",
      "Jong Wook Jang",
      "Tae Hoon Lim",
      "Dae Seoung Kim"
    ],
    "abstract": "Hyperspectral imagery provides rich spectral detail but poses unique\nchallenges because of its high dimensionality in both spatial and spectral\ndomains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation\nmodel for hyperspectral data that employs a \\textit{dual masking} strategy:\nduring pre-training we randomly occlude 50\\% of spatial patches and 50\\% of\nspectral bands. This forces the model to learn representations capable of\nreconstructing missing information across both dimensions. To encode spectral\norder, we introduce learnable harmonic Fourier positional embeddings based on\nwavelength. The reconstruction objective combines mean-squared error (MSE) with\nthe spectral angle mapper (SAM) to balance pixel-level accuracy and\nspectral-shape fidelity.\n  The resulting model contains about $1.8\\times10^{8}$ parameters and produces\n768-dimensional embeddings, giving it sufficient capacity for transfer\nlearning. We pre-trained HyperspectralMAE on two large hyperspectral corpora --\nNASA EO-1 Hyperion ($\\sim$1\\,600 scenes, $\\sim$$3\\times10^{11}$ pixel spectra)\nand DLR EnMAP Level-0 ($\\sim$1\\,300 scenes, $\\sim$$3\\times10^{11}$ pixel\nspectra) -- and fine-tuned it for land-cover classification on the Indian Pines\nbenchmark. HyperspectralMAE achieves state-of-the-art transfer-learning\naccuracy on Indian Pines, confirming that masked dual-dimensional pre-training\nyields robust spectral-spatial representations. These results demonstrate that\ndual masking and wavelength-aware embeddings advance hyperspectral image\nreconstruction and downstream analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05710v1",
    "published_date": "2025-05-09 01:16:42 UTC",
    "updated_date": "2025-05-09 01:16:42 UTC"
  },
  {
    "arxiv_id": "2505.05704v1",
    "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models",
    "authors": [
      "Julia Shuieh",
      "Prasann Singhal",
      "Apaar Shanker",
      "John Heyer",
      "George Pu",
      "Samuel Denton"
    ],
    "abstract": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning",
    "pdf_url": "http://arxiv.org/pdf/2505.05704v1",
    "published_date": "2025-05-09 00:39:43 UTC",
    "updated_date": "2025-05-09 00:39:43 UTC"
  },
  {
    "arxiv_id": "2505.05701v1",
    "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning",
    "authors": [
      "Jongchan Park",
      "Mingyu Park",
      "Donghwan Lee"
    ],
    "abstract": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05701v1",
    "published_date": "2025-05-09 00:26:01 UTC",
    "updated_date": "2025-05-09 00:26:01 UTC"
  }
]