{
  "date": "2024-06-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文主要聚焦于大型语言模型 (LLM) 的优化、安全应用和多模态理解等领域，强调了 LLM 在数学推理、文本生成和灾害管理中的潜力，同时探讨了其风险和鲁棒性。令人印象深刻的包括使用扩散模型的 Out-of-Distribution (OOD) 检测方法，以及 LLM 风险评估和多代理系统在实际场景中的创新应用；知名学者如 Yejin Choi 和 Bill Yuchen Lin 参与的 WildVision 基准也值得关注。\n\n下面，我将逐一简要介绍部分关键论文，先优先讨论 LLM 相关和创新性强的文章，再快速掠过其他领域的内容，以控制篇幅。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### LLM 优化与应用\n- **利用扩散模型进行异常分布检测（Exploiting Diffusion Prior for Out-of-Distribution Detection）**  \n  这篇论文提出了一种新方法，使用扩散模型和 CLIP 进行 OOD 检测，通过图像重建差异识别异常样本。主要贡献是无需特定标签数据即可实现鲁棒检测，在基准数据集上显著提升了准确性，适用于安全关键领域。\n\n- **使用 LLM 评估大规模在线课程（Grading Massive Open Online Courses Using Large Language Models）**  \n  作者探索了 LLM（如 GPT-4）在 MOOC 作业评估中的潜力，通过零-shot chain-of-thought 提示生成更可靠的评分。发现结合教师答案和评分标准可提升评分与人工一致性，论文已接受 COLING 2025，具有实际教育应用潜力。\n\n- **基于指令微调的 LLM 用于灾害文本多标签分类（CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for Multi-label Social Media Text Classification in Disaster Informatics）**  \n  该工作微调 LLM 处理灾害相关社交媒体文本，支持多标签分类（如事件类型和援助需求）。主要发现是提升了紧急响应中的情境感知能力，并提供了开源代码和数据集，适用于真实灾害管理。\n\n- **LLM 风险与防护措施（Current state of LLM Risks and AI Guardrails）**  \n  论文系统分析了 LLM 的偏置、安全风险和防护策略，包括分层保护模型和公平性指标。主要贡献是强调了在实际部署中平衡准确性和隐私的重要性，提供实用指导。\n\n- **LLM 在抽象推理中的局限性（A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners）**  \n  作者通过假设测试框架评估 LLM 的逻辑推理偏置，发现 LLM 依赖表层模式而非真正推理。核心发现是 LLM 在复杂任务中易出错，已接受 EMNLP 2024，揭示了 LLM 泛化能力的挑战。\n\n- **多代理 LLM 用于软件开发（AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology）**  \n  这篇工作构建了基于敏捷方法的 LLM 多代理系统，包括产品经理和开发者角色。贡献在于通过动态代码图优化协作，提高了软件开发效率，超越了现有基准。\n\n- **LLM 在数学推理中的错误处理（Step-level Value Preference Optimization for Mathematical Reasoning）**  \n  论文提出 SVPO 方法，通过 Monte Carlo Tree Search 优化 LLM 的数学推理步骤。主要发现是提升了多步推理的准确性，在推理基准上达到 SOTA。\n\n### 多模态和计算机视觉\n- **评估 VLMs 的真实世界偏好（WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences）**  \n  由 Yejin Choi 和 Bill Yuchen Lin 等知名学者参与，构建了 WV-Bench 数据集，使用 GPT-4 评估 VLMs 的泛化能力。核心贡献是揭示 VLMs 在空间推理和领域知识上的不足，提供公开数据促进研究。\n\n- **扩散模型在音频空间中的应用（SPEAR: Receiver-to-Receiver Acoustic Neural Warping Field）**  \n  该论文引入了音频变形场，用于预测空间音频效果。主要发现是无需先验知识即可高效处理音频传播，适用于机器人任务。\n\n快速掠过其他领域：剩余论文涉及图像生成、数据质量管理、医疗诊断和优化算法等。其中，**医疗图像分类优化（Boosting Medical Image Classification with Segmentation Foundation Model）** 使用 SAM 模型增强分类性能，贡献在于减少标注需求；**知识图嵌入（Ontology Embedding: A Survey of Methods, Applications and Resources）** 综述了本体嵌入方法，强调其在机器学习中的作用；其他如晶体结构求解和不确定性量化等论文虽有技术创新，但影响力较小，仅在特定领域有应用价值。\n\n今天的 arXiv 更新展示了 LLM 和 AI 领域的快速进展，但也暴露了模型的局限性，如偏置和泛化问题。感兴趣的读者可关注相关开源代码，以探索更多细节！",
  "papers": [
    {
      "arxiv_id": "2406.11105v2",
      "title": "Exploiting Diffusion Prior for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Armando Zhu",
        "Jiabei Liu",
        "Keqin Li",
        "Shuying Dai",
        "Bo Hong",
        "Peng Zhao",
        "Changsong Wei"
      ],
      "abstract": "Out-of-distribution (OOD) detection is crucial for deploying robust machine\nlearning models, especially in areas where security is critical. However,\ntraditional OOD detection methods often fail to capture complex data\ndistributions from large scale date. In this paper, we present a novel approach\nfor OOD detection that leverages the generative ability of diffusion models and\nthe powerful feature extraction capabilities of CLIP. By using these features\nas conditional inputs to a diffusion model, we can reconstruct the images after\nencoding them with CLIP. The difference between the original and reconstructed\nimages is used as a signal for OOD identification. The practicality and\nscalability of our method is increased by the fact that it does not require\nclass-specific labeled ID data, as is the case with many other methods.\nExtensive experiments on several benchmark datasets demonstrates the robustness\nand effectiveness of our method, which have significantly improved the\ndetection accuracy.",
      "tldr_zh": "这篇论文提出了一种新颖的 Out-of-Distribution (OOD) 检测方法，利用扩散模型的生成能力（generative ability）和 CLIP 的特征提取能力（feature extraction capabilities）。具体而言，该方法将 CLIP 提取的图像特征作为条件输入到扩散模型中进行图像重建，然后通过原始图像与重建图像之间的差异作为 OOD 识别信号。相比传统方法，该方法无需类特定的标记 ID 数据，从而提升了实用性和可扩展性。在多个基准数据集上的广泛实验证明，该方法显著提高了检测准确率，并展示了其鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11105v2",
      "published_date": "2024-06-16 23:55:25 UTC",
      "updated_date": "2024-08-21 17:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:39:45.957874"
    },
    {
      "arxiv_id": "2406.11102v2",
      "title": "Grading Massive Open Online Courses Using Large Language Models",
      "title_zh": "使用大型语言模型对大规模在线开放课程进行评分",
      "authors": [
        "Shahriar Golchin",
        "Nikhil Garuda",
        "Christopher Impey",
        "Matthew Wenger"
      ],
      "abstract": "Massive open online courses (MOOCs) offer free education globally. Despite\nthis democratization of learning, the massive enrollment in these courses makes\nit impractical for an instructor to assess every student's writing assignment.\nAs a result, peer grading, often guided by a straightforward rubric, is the\nmethod of choice. While convenient, peer grading often falls short in terms of\nreliability and validity. In this study, we explore the feasibility of using\nlarge language models (LLMs) to replace peer grading in MOOCs. To this end, we\nadapt the zero-shot chain-of-thought (ZCoT) prompting technique to automate the\nfeedback process once the LLM assigns a score to an assignment. Specifically,\nto instruct LLMs for grading, we use three distinct prompts based on ZCoT: (1)\nZCoT with instructor-provided correct answers, (2) ZCoT with both\ninstructor-provided correct answers and rubrics, and (3) ZCoT with\ninstructor-provided correct answers and LLM-generated rubrics. We tested these\nprompts in 18 different scenarios using two LLMs, GPT-4 and GPT-3.5, across\nthree MOOCs: Introductory Astronomy, Astrobiology, and the History and\nPhilosophy of Astronomy. Our results show that ZCoT, when augmented with\ninstructor-provided correct answers and rubrics, produces grades that are more\naligned with those assigned by instructors compared to peer grading. Finally,\nour findings indicate a promising potential for automated grading systems in\nMOOCs, especially in subjects with well-defined rubrics, to improve the\nlearning experience for millions of online learners worldwide.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)来自动评估Massive Open Online Courses (MOOCs)中的写作作业，以解决同行评级在可靠性和有效性方面的不足。研究者改进了zero-shot chain-of-thought (ZCoT)提示技术，设计了三种提示方式：结合教师提供的正确答案、rubrics，或LLM生成的rubrics，以自动化评分和反馈过程。实验在Introductory Astronomy、Astrobiology和History and Philosophy of Astronomy等三门MOOCs上进行，使用GPT-4和GPT-3.5，结果显示ZCoT结合正确答案和rubrics的版本，评分结果更接近教师评估，比同行评级更准确。最后，该方法为MOOCs的自动评分系统提供了潜力，尤其在有明确rubrics的科目中，提升了全球在线学习者的体验。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Final version; accepted at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.11102v2",
      "published_date": "2024-06-16 23:42:11 UTC",
      "updated_date": "2024-12-16 06:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:00.443400"
    },
    {
      "arxiv_id": "2406.15477v2",
      "title": "CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for Multi-label Social Media Text Classification in Disaster Informatics",
      "title_zh": "CrisisSense-LLM：基于指令微调的大型语言模型，用于灾害信息学中的多标签社交媒体文本分类",
      "authors": [
        "Kai Yin",
        "Chengkai Liu",
        "Ali Mostafavi",
        "Xia Hu"
      ],
      "abstract": "In the field of crisis/disaster informatics, social media is increasingly\nbeing used for improving situational awareness to inform response and relief\nefforts. Efficient and accurate text classification tools have been a focal\narea of investigation in crisis informatics. However, current methods mostly\nrely on single-label text classification models, which fails to capture\ndifferent insights embedded in dynamic and multifaceted disaster-related social\nmedia data. This study introduces a novel approach to disaster text\nclassification by enhancing a pre-trained Large Language Model (LLM) through\ninstruction fine-tuning targeted for multi-label classification of\ndisaster-related tweets. Our methodology involves creating a comprehensive\ninstruction dataset from disaster-related tweets, which is then used to\nfine-tune an open-source LLM, thereby embedding it with disaster-specific\nknowledge. This fine-tuned model can classify multiple aspects of\ndisaster-related information simultaneously, such as the type of event,\ninformativeness, and involvement of human aid, significantly improving the\nutility of social media data for situational awareness in disasters. The\nresults demonstrate that this approach enhances the categorization of critical\ninformation from social media posts, thereby facilitating a more effective\ndeployment for situational awareness during emergencies. This research paves\nthe way for more advanced, adaptable, and robust disaster management tools,\nleveraging the capabilities of LLMs to improve real-time situational awareness\nand response strategies in disaster scenarios.",
      "tldr_zh": "该研究提出CrisisSense-LLM，一种通过指令微调(instruction fine-tuning)增强的Large Language Model (LLM)，用于灾害信息学(disaster informatics)中社会媒体文本的多标签分类(multi-label classification)。方法涉及从灾害相关推文(tweets)创建全面的指令数据集，并以此微调开源LLM，使其嵌入灾害特定知识，从而同时分类多个方面，如事件类型、信息性和人道援助参与。实验结果显示，该模型显著提高了社会媒体数据的分类准确性，提升了紧急情况下的situational awareness；这项工作为先进的灾害管理工具铺平道路，利用LLM提升实时响应策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Relevant source code and data is available:\n  https://github.com/KaiYin97/CrsisLLM",
      "pdf_url": "http://arxiv.org/pdf/2406.15477v2",
      "published_date": "2024-06-16 23:01:10 UTC",
      "updated_date": "2025-01-16 03:26:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:09.516311"
    },
    {
      "arxiv_id": "2406.11097v2",
      "title": "InstructCMP: Length Control in Sentence Compression through Instruction-based Large Language Models",
      "title_zh": "InstructCMP：通过基于指令的大型语言模型在句子压缩",
      "authors": [
        "Juseon-Do",
        "Jingun Kwon",
        "Hidetaka Kamigaito",
        "Manabu Okumura"
      ],
      "abstract": "Extractive summarization can produce faithful summaries but often requires\nadditional constraints such as a desired summary length. Traditional sentence\ncompression models do not typically consider the constraints because of their\nrestricted model abilities, which require model modifications for coping with\nthem. To bridge this gap, we propose Instruction-based Compression\n(InstructCMP), an approach to the sentence compression task that can consider\nthe length constraint through instructions by leveraging the zero-shot\ntask-solving abilities of Large Language Models (LLMs). For this purpose, we\ncreated new evaluation datasets by transforming traditional sentence\ncompression datasets into an instruction format. By using the datasets, we\nfirst reveal that the current LLMs still face challenges in accurately\ncontrolling the length for a compressed text. To address this issue, we propose\nan approach named \"length priming,\" that incorporates additional length\ninformation into the instructions without external resources. While the length\npriming effectively works in a zero-shot setting, a training dataset with the\ninstructions would further improve the ability of length control. Thus, we\nadditionally created a training dataset in an instruction format to fine-tune\nthe model on it. Experimental results and analysis show that applying the\nlength priming significantly improves performances of InstructCMP in both\nzero-shot and fine-tuning settings without the need of any model modifications.",
      "tldr_zh": "这篇论文提出了 InstructCMP，一种基于指令的大型语言模型(LLMs)方法，用于句子压缩任务，能够通过指令格式轻松考虑长度约束，从而生成符合要求的摘要。作者创建了新的评估和训练数据集，将传统数据集转化为指令形式，并发现当前 LLMs 在精确控制压缩文本长度方面存在挑战。为此，他们引入了“length priming”技术，通过在指令中添加额外长度信息来提升性能，而无需外部资源或模型修改。实验结果显示，该方法在零样本和微调设置下显著提高了压缩任务的准确性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, accepted to ACL 2024 Findings (Long Paper)",
      "pdf_url": "http://arxiv.org/pdf/2406.11097v2",
      "published_date": "2024-06-16 23:00:47 UTC",
      "updated_date": "2024-06-18 18:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:21.576673"
    },
    {
      "arxiv_id": "2406.11087v5",
      "title": "DP-MemArc: Differential Privacy Transfer Learning for Memory Efficient Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Yuwei Zhang",
        "Xiaolan Ke",
        "Songhang Deng",
        "Jiannan Cao",
        "Chen Ma",
        "Mengchen Fu",
        "Tianyu Du",
        "Sheng Cheng",
        "Xun Wang",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "abstract": "Large language models have repeatedly shown outstanding performance across\ndiverse applications. However, deploying these models can inadvertently risk\nuser privacy. The significant memory demands during training pose a major\nchallenge in terms of resource consumption. This substantial size places a\nheavy load on memory resources, raising considerable practical concerns. In\nthis paper, we introduce DP-MemArc, a novel training framework aimed at\nreducing the memory costs of large language models while emphasizing the\nprotection of user data privacy. DP-MemArc incorporates side network or\nreversible network designs to support a variety of differential privacy\nmemory-efficient fine-tuning schemes. Our approach not only achieves about 2.5\ntimes in memory optimization but also ensures robust privacy protection,\nkeeping user data secure and confidential. Extensive experiments have\ndemonstrated that DP-MemArc effectively provides differential privacy-efficient\nfine-tuning across different task scenarios.",
      "tldr_zh": "这篇论文介绍了 DP-MemArc，一种创新的训练框架，针对大型语言模型（Large Language Models）的内存需求和用户隐私风险问题，结合差分隐私（Differential Privacy）和迁移学习进行优化。框架通过 side network 或 reversible network 设计，支持多种内存高效的微调方案，从而显著降低资源消耗。实验结果显示，DP-MemArc 实现了约 2.5 倍的内存优化，同时确保了 robust 隐私保护，并在不同任务场景中表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Fix metadata error",
      "pdf_url": "http://arxiv.org/pdf/2406.11087v5",
      "published_date": "2024-06-16 22:11:41 UTC",
      "updated_date": "2025-02-20 07:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:34.463139"
    },
    {
      "arxiv_id": "2406.12934v1",
      "title": "Current state of LLM Risks and AI Guardrails",
      "title_zh": "LLM 风险的现状与 AI 防护措施",
      "authors": [
        "Suriya Ganesh Ayyamperumal",
        "Limin Ge"
      ],
      "abstract": "Large language models (LLMs) have become increasingly sophisticated, leading\nto widespread deployment in sensitive applications where safety and reliability\nare paramount. However, LLMs have inherent risks accompanying them, including\nbias, potential for unsafe actions, dataset poisoning, lack of explainability,\nhallucinations, and non-reproducibility. These risks necessitate the\ndevelopment of \"guardrails\" to align LLMs with desired behaviors and mitigate\npotential harm.\n  This work explores the risks associated with deploying LLMs and evaluates\ncurrent approaches to implementing guardrails and model alignment techniques.\nWe examine intrinsic and extrinsic bias evaluation methods and discuss the\nimportance of fairness metrics for responsible AI development. The safety and\nreliability of agentic LLMs (those capable of real-world actions) are explored,\nemphasizing the need for testability, fail-safes, and situational awareness.\n  Technical strategies for securing LLMs are presented, including a layered\nprotection model operating at external, secondary, and internal levels. System\nprompts, Retrieval-Augmented Generation (RAG) architectures, and techniques to\nminimize bias and protect privacy are highlighted.\n  Effective guardrail design requires a deep understanding of the LLM's\nintended use case, relevant regulations, and ethical considerations. Striking a\nbalance between competing requirements, such as accuracy and privacy, remains\nan ongoing challenge. This work underscores the importance of continuous\nresearch and development to ensure the safe and responsible use of LLMs in\nreal-world applications.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）的当前风险，包括偏见、不安全行为、数据集污染、缺乏可解释性、幻觉和不可复现性，并强调了开发AI守卫措施（guardrails）的必要性，以对齐模型行为并减少潜在危害。作者评估了现有的守卫策略，如内在和外在偏见评估方法、公平性指标，以及针对代理LLMs的安全技术，包括分层保护模型（外部、次要和内部级别）、系统提示和Retrieval-Augmented Generation (RAG)架构，以提升测试性、故障安全和隐私保护。论文指出，设计有效守卫需考虑使用场景、法规和伦理因素，同时平衡准确性和隐私等挑战，并呼吁持续研究以确保LLMs在实际应用中的安全可靠。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "Independent study, Exploring LLMs, Deploying LLMs and their Risks",
      "pdf_url": "http://arxiv.org/pdf/2406.12934v1",
      "published_date": "2024-06-16 22:04:10 UTC",
      "updated_date": "2024-06-16 22:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:46.374547"
    },
    {
      "arxiv_id": "2406.11916v1",
      "title": "Enhanced Elephant Herding Optimization for Large Scale Information Access on Social Media",
      "title_zh": "增强型 Elephant Herding Optimization 用于社交媒体上的大规模信息访问",
      "authors": [
        "Yassine Drias",
        "Habiba Drias",
        "Ilyes Khennak"
      ],
      "abstract": "In this article, we present a novel information access approach inspired by\nthe information foraging theory (IFT) and elephant herding optimization (EHO).\nFirst, we propose a model for information access on social media based on the\nIFT. We then elaborate an adaptation of the original EHO algorithm to apply it\nto the information access problem. The combination of the IFT and EHO\nconstitutes a good opportunity to find relevant information on social media.\nHowever, when dealing with voluminous data, the performance undergoes a sharp\ndrop. To overcome this issue, we developed an enhanced version of EHO for large\nscale information access. We introduce new operators to the algorithm,\nincluding territories delimitation and clan migration using clustering. To\nvalidate our work, we created a dataset of more than 1.4 million tweets, on\nwhich we carried out extensive experiments. The outcomes reveal the ability of\nour approach to find relevant information in an effective and efficient way.\nThey also highlight the advantages of the improved version of EHO over the\noriginal algorithm regarding different aspects. Furthermore, we undertook a\ncomparative study with two other metaheuristic-based information foraging\napproaches, namely ant colony system and particle swarm optimization. Overall,\nthe results are very promising.",
      "tldr_zh": "本研究提出了一种基于信息觅食理论(IFT)和大象群优化(EHO)的社交媒体信息访问方法，通过改编原始EHO算法来优化信息检索过程。针对大规模数据带来的性能下降问题，该方法引入了新操作符，如领地划分和族群迁移使用聚类，显著提升了算法的效率和准确性。实验在超过140万推文的数据集上验证，结果显示增强版EHO在信息获取方面优于原始算法，并比蚁群系统和粒子群优化等方法更具优势。总的来说，这一方法为大规模社交媒体信息访问提供了高效解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11916v1",
      "published_date": "2024-06-16 21:48:41 UTC",
      "updated_date": "2024-06-16 21:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:40:59.728379"
    },
    {
      "arxiv_id": "2406.11915v2",
      "title": "miniCodeProps: a Minimal Benchmark for Proving Code Properties",
      "title_zh": "miniCodeProps：证明代码属性的最小基准",
      "authors": [
        "Evan Lohn",
        "Sean Welleck"
      ],
      "abstract": "AI agents have shown initial promise in automating mathematical theorem\nproving in proof assistants such as Lean. The same proof assistants can be used\nto verify the correctness of code by pairing code with specifications and\nproofs that the specifications hold. Automating the writing of code,\nspecifications, and proofs could lower the cost of verification, or,\nambitiously, enable an AI agent to output safe, provably correct code. However,\nit remains unclear whether current neural theorem provers can automatically\nverify even relatively simple programs. We present miniCodeProps, a benchmark\nof 201 program specifications in the Lean proof assistant, aimed at the\nsubproblem of automatically generating a proof for a provided program and\nspecification. miniCodeProps contains specifications about simple,\nself-contained programs (e.g., lists, natural numbers, binary trees) with\nvaried proof difficulty. Despite its simplicity, miniCodeProps is sufficient to\nbreak current LLM-based provers, with state-of-the-art methods showing promise\non the easy properties in miniCodeProps, yet failing to prove nearly all of the\nmedium and hard properties. We publicly release miniCodeProps as a benchmark\nfor furthering automated theorem proving in the context of formally verified\ncode.",
      "tldr_zh": "这篇论文引入了 miniCodeProps，一个包含 201 个程序规范的最小基准，用于评估 AI 代理在 Lean 证明助手中自动生成证明代码属性的能力。基准聚焦于简单程序（如 lists、natural numbers 和 binary trees），以不同难度水平测试证明任务。实验发现，当前最先进的 LLM-based provers 仅能在易级属性上表现出色，而在中高难度属性上几乎完全失败。通过公开发布 miniCodeProps，论文旨在推动自动定理证明在形式验证代码领域的进展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11915v2",
      "published_date": "2024-06-16 21:11:23 UTC",
      "updated_date": "2024-10-10 16:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:41:10.940719"
    },
    {
      "arxiv_id": "2406.11069v1",
      "title": "WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Lu",
        "Dongfu Jiang",
        "Wenhu Chen",
        "William Yang Wang",
        "Yejin Choi",
        "Bill Yuchen Lin"
      ],
      "abstract": "Recent breakthroughs in vision-language models (VLMs) emphasize the necessity\nof benchmarking human preferences in real-world multimodal interactions. To\naddress this gap, we launched WildVision-Arena (WV-Arena), an online platform\nthat collects human preferences to evaluate VLMs. We curated WV-Bench by\nselecting 500 high-quality samples from 8,000 user submissions in WV-Arena.\nWV-Bench uses GPT-4 as the judge to compare each VLM with Claude-3-Sonnet,\nachieving a Spearman correlation of 0.94 with the WV-Arena Elo. This\nsignificantly outperforms other benchmarks like MMVet, MMMU, and MMStar.\n  Our comprehensive analysis of 20K real-world interactions reveals important\ninsights into the failure cases of top-performing VLMs. For example, we find\nthat although GPT-4V surpasses many other models like Reka-Flash, Opus, and\nYi-VL-Plus in simple visual recognition and reasoning tasks, it still faces\nchallenges with subtle contextual cues, spatial reasoning, visual imagination,\nand expert domain knowledge. Additionally, current VLMs exhibit issues with\nhallucinations and safety when intentionally provoked. We are releasing our\nchat and feedback data to further advance research in the field of VLMs.",
      "tldr_zh": "该研究推出了 WildVision-Arena 平台和 WV-Bench 基准，用于评估视觉语言模型 (VLMs) 在真实世界多模态互动中的性能，通过收集人类偏好数据来填补现有基准的不足。WV-Bench 选取了 500 个高质量样本，使用 GPT-4 作为裁判与 Claude-3-Sonnet 比较模型，达到了 0.94 的 Spearman 相关性，显著优于 MMVet、MMMU 和 MMStar 等基准。分析 20K 真实互动数据发现，顶级 VLMs 如 GPT-4V 在简单视觉识别和推理任务中表现出色，但仍存在微妙上下文线索、空间推理、视觉想象和专业领域知识的挑战，以及幻觉和安全问题。该研究还发布了聊天和反馈数据，以推动 VLMs 领域的研究进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "link: https://hf.co/spaces/WildVision/vision-arena",
      "pdf_url": "http://arxiv.org/pdf/2406.11069v1",
      "published_date": "2024-06-16 20:53:25 UTC",
      "updated_date": "2024-06-16 20:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:41:22.241049"
    },
    {
      "arxiv_id": "2406.11068v1",
      "title": "A Unified View of Abstract Visual Reasoning Problems",
      "title_zh": "抽象视觉推理问题的统一视角",
      "authors": [
        "Mikołaj Małkiński",
        "Jacek Mańdziuk"
      ],
      "abstract": "The field of Abstract Visual Reasoning (AVR) encompasses a wide range of\nproblems, many of which are inspired by human IQ tests. The variety of AVR\ntasks has resulted in state-of-the-art AVR methods being task-specific\napproaches. Furthermore, contemporary methods consider each AVR problem\ninstance not as a whole, but in the form of a set of individual panels with\nparticular locations and roles (context vs. answer panels) pre-assigned\naccording to the task-specific arrangements. While these highly specialized\napproaches have recently led to significant progress in solving particular AVR\ntasks, considering each task in isolation hinders the development of universal\nlearning systems in this domain. In this paper, we introduce a unified view of\nAVR tasks, where each problem instance is rendered as a single image, with no a\npriori assumptions about the number of panels, their location, or role. The\nmain advantage of the proposed unified view is the ability to develop universal\nlearning models applicable to various AVR tasks. What is more, the proposed\napproach inherently facilitates transfer learning in the AVR domain, as various\ntypes of problems share a common representation. The experiments conducted on\nfour AVR datasets with Raven's Progressive Matrices and Visual Analogy\nProblems, and one real-world visual analogy dataset show that the proposed\nunified representation of AVR tasks poses a challenge to state-of-the-art Deep\nLearning (DL) AVR models and, more broadly, contemporary DL image recognition\nmethods. In order to address this challenge, we introduce the Unified Model for\nAbstract Visual Reasoning (UMAVR) capable of dealing with various types of AVR\nproblems in a unified manner. UMAVR outperforms existing AVR methods in\nselected single-task learning experiments, and demonstrates effective knowledge\nreuse in transfer learning and curriculum learning setups.",
      "tldr_zh": "这篇论文提出了一种统一视图(unified view)来处理抽象视觉推理(Abstract Visual Reasoning, AVR)问题，旨在克服现有任务特定方法的分裂性，通过将每个问题实例渲染为单个图像，而不依赖于面板位置或角色的先验假设。这样的方法支持开发通用的学习模型，并促进AVR领域的转移学习(transfer learning)，使不同类型的问题共享共同表示。论文引入了Unified Model for Abstract Visual Reasoning (UMAVR)模型，能够统一处理多种AVR任务，包括Raven's Progressive Matrices和Visual Analogy Problems。实验在四个AVR数据集和一个真实世界视觉类比数据集上表明，UMAVR在单任务学习、转移学习和课程学习(curriculum learning)设置中优于现有Deep Learning (DL)方法，展示了其有效性和知识重用潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11068v1",
      "published_date": "2024-06-16 20:52:44 UTC",
      "updated_date": "2024-06-16 20:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:41:36.072230"
    },
    {
      "arxiv_id": "2406.16935v1",
      "title": "Benchmarking Out-of-Distribution Generalization Capabilities of DNN-based Encoding Models for the Ventral Visual Cortex",
      "title_zh": "翻译失败",
      "authors": [
        "Spandan Madan",
        "Will Xiao",
        "Mingran Cao",
        "Hanspeter Pfister",
        "Margaret Livingstone",
        "Gabriel Kreiman"
      ],
      "abstract": "We characterized the generalization capabilities of DNN-based encoding models\nwhen predicting neuronal responses from the visual cortex. We collected\n\\textit{MacaqueITBench}, a large-scale dataset of neural population responses\nfrom the macaque inferior temporal (IT) cortex to over $300,000$ images,\ncomprising $8,233$ unique natural images presented to seven monkeys over $109$\nsessions. Using \\textit{MacaqueITBench}, we investigated the impact of\ndistribution shifts on models predicting neural activity by dividing the images\ninto Out-Of-Distribution (OOD) train and test splits. The OOD splits included\nseveral different image-computable types including image contrast, hue,\nintensity, temperature, and saturation. Compared to the performance on\nin-distribution test images -- the conventional way these models have been\nevaluated -- models performed worse at predicting neuronal responses to\nout-of-distribution images, retaining as little as $20\\%$ of the performance on\nin-distribution test images. The generalization performance under OOD shifts\ncan be well accounted by a simple image similarity metric -- the cosine\ndistance between image representations extracted from a pre-trained object\nrecognition model is a strong predictor of neural predictivity under different\ndistribution shifts. The dataset of images, neuronal firing rate recordings,\nand computational benchmarks are hosted publicly at: https://bit.ly/3zeutVd.",
      "tldr_zh": "本文评估了基于 DNN-based encoding models 在预测猕猴下颞叶 (inferior temporal, IT) 皮层神经元响应的 Out-of-Distribution (OOD) 泛化能力，使用新构建的 MacaqueITBench 数据集，该数据集包含超过 30 万张图像的神经响应记录。研究者通过将图像分为 OOD 训练和测试集（如图像对比度、色调等分布偏移类型），发现模型在 OOD 测试图像上的性能显著下降，仅保留了分布内测试性能的 20%。他们进一步证明，图像表示的余弦距离（从预训练对象识别模型提取）可以有效预测神经预测性。该工作提供了公开数据集和基准，促进了视觉神经编码模型的进一步研究。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16935v1",
      "published_date": "2024-06-16 20:33:57 UTC",
      "updated_date": "2024-06-16 20:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:41:53.732834"
    },
    {
      "arxiv_id": "2406.11061v1",
      "title": "Generalization and Knowledge Transfer in Abstract Visual Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mikołaj Małkiński",
        "Jacek Mańdziuk"
      ],
      "abstract": "We study generalization and knowledge reuse capabilities of deep neural\nnetworks in the domain of abstract visual reasoning (AVR), employing Raven's\nProgressive Matrices (RPMs), a recognized benchmark task for assessing AVR\nabilities. Two knowledge transfer scenarios referring to the I-RAVEN dataset\nare investigated. Firstly, inspired by generalization assessment capabilities\nof the PGM dataset and popularity of I-RAVEN, we introduce\nAttributeless-I-RAVEN, a benchmark with four generalization regimes that allow\nto test generalization of abstract rules applied to held-out attributes.\nSecondly, we construct I-RAVEN-Mesh, a dataset that enriches RPMs with a novel\ncomponent structure comprising line-based patterns, facilitating assessment of\nprogressive knowledge acquisition in transfer learning setting. The developed\nbenchmarks reveal shortcomings of the contemporary deep learning models, which\nwe partly address with Pathways of Normalized Group Convolution (PoNG) model, a\nnovel neural architecture for solving AVR tasks. PoNG excels in both presented\nchallenges, as well as the standard I-RAVEN and PGM setups.",
      "tldr_zh": "本研究探讨了深度神经网络在抽象视觉推理 (AVR) 中的泛化能力和知识转移，采用 Raven's Progressive Matrices (RPMs) 作为基准任务。论文引入了 Attributeless-I-RAVEN 基准，该基准包含四个泛化模式，用于测试模型对未见属性的抽象规则应用能力；同时构建了 I-RAVEN-Mesh 数据集，通过添加基于线的模式结构评估转移学习中的渐进知识获取。结果揭示了当代深度学习模型的不足，并提出了一种新架构 Pathways of Normalized Group Convolution (PoNG)，该模型在 Attributeless-I-RAVEN、I-RAVEN-Mesh 以及标准 I-RAVEN 和 PGM 设置中表现出色。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11061v1",
      "published_date": "2024-06-16 20:26:38 UTC",
      "updated_date": "2024-06-16 20:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:42:04.062971"
    },
    {
      "arxiv_id": "2406.11050v2",
      "title": "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jiang",
        "Yangxinyu Xie",
        "Zhuoqun Hao",
        "Xiaomeng Wang",
        "Tanwi Mallick",
        "Weijie J. Su",
        "Camillo J. Taylor",
        "Dan Roth"
      ],
      "abstract": "This study introduces a hypothesis-testing framework to assess whether large\nlanguage models (LLMs) possess genuine reasoning abilities or primarily depend\non token bias. We go beyond evaluating LLMs on accuracy; rather, we aim to\ninvestigate their token bias in solving logical reasoning tasks. Specifically,\nwe develop carefully controlled synthetic datasets, featuring conjunction\nfallacy and syllogistic problems. Our framework outlines a list of hypotheses\nwhere token biases are readily identifiable, with all null hypotheses assuming\ngenuine reasoning capabilities of LLMs. The findings in this study suggest,\nwith statistical guarantee, that most LLMs still struggle with logical\nreasoning. While they may perform well on classic problems, their success\nlargely depends on recognizing superficial patterns with strong token bias,\nthereby raising concerns about their actual reasoning and generalization\nabilities. Codes and data are open-sourced at\nhttps://github.com/bowen-upenn/llm_token_bias.",
      "tldr_zh": "本研究提出一个假设测试框架，用于评估大型语言模型 (LLMs) 是否具备真正的推理能力，还是主要依赖于 token bias。该框架通过开发严格控制的合成数据集，包括 conjunction fallacy 和 syllogistic problems，来测试一系列假设，其中所有零假设均假定 LLMs 具有真实推理能力。结果显示，大多数 LLMs 在逻辑推理任务上表现不佳，其成功更多依赖于识别表面模式和 token bias，而不是真正的推理，这引发了对 LLMs 泛化能力的担忧；相关代码和数据已开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11050v2",
      "published_date": "2024-06-16 19:22:53 UTC",
      "updated_date": "2024-10-04 04:40:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:42:14.245025"
    },
    {
      "arxiv_id": "2406.11047v1",
      "title": "Enhancing Supermarket Robot Interaction: A Multi-Level LLM Conversational Interface for Handling Diverse Customer Intents",
      "title_zh": "翻译失败",
      "authors": [
        "Chandran Nandkumar",
        "Luka Peternel"
      ],
      "abstract": "This paper presents the design and evaluation of a novel multi-level LLM\ninterface for supermarket robots to assist customers. The proposed interface\nallows customers to convey their needs through both generic and specific\nqueries. While state-of-the-art systems like OpenAI's GPTs are highly adaptable\nand easy to build and deploy, they still face challenges such as increased\nresponse times and limitations in strategic control of the underlying model for\ntailored use-case and cost optimization. Driven by the goal of developing\nfaster and more efficient conversational agents, this paper advocates for using\nmultiple smaller, specialized LLMs fine-tuned to handle different user queries\nbased on their specificity and user intent. We compare this approach to a\nspecialized GPT model powered by GPT-4 Turbo, using the Artificial Social Agent\nQuestionnaire (ASAQ) and qualitative participant feedback in a counterbalanced\nwithin-subjects experiment. Our findings show that our multi-LLM chatbot\narchitecture outperformed the benchmarked GPT model across all 13 measured\ncriteria, with statistically significant improvements in four key areas:\nperformance, user satisfaction, user-agent partnership, and self-image\nenhancement. The paper also presents a method for supermarket robot navigation\nby mapping the final chatbot response to correct shelf numbers, enabling the\nrobot to sequentially navigate towards the respective products, after which\nlower-level robot perception, control, and planning can be used for automated\nobject retrieval. We hope this work encourages more efforts into using\nmultiple, specialized smaller models instead of relying on a single powerful,\nbut more expensive and slower model.",
      "tldr_zh": "本论文提出了一种多级 LLM 接口设计，用于提升超市机器人的对话互动能力，该接口通过多个较小、专门化的 LLM 模型，根据用户查询的具体性和意图进行微调，以解决传统系统如 GPT-4 Turbo 的响应时间长和战略控制有限等问题。实验采用 Artificial Social Agent Questionnaire (ASAQ) 和定性反馈进行比较，结果显示多 LLM 架构在 13 个标准中全面优于基准模型，尤其在性能、用户满意度、用户-代理伙伴关系和自我形象提升四个关键领域取得统计显著改善。论文还介绍了将聊天机器人响应映射到货架编号的导航方法，实现机器人顺畅导航和对象检索，呼吁更多采用多个专门化小模型来构建高效对话代理。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11047v1",
      "published_date": "2024-06-16 19:13:01 UTC",
      "updated_date": "2024-06-16 19:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:42:31.026963"
    },
    {
      "arxiv_id": "2406.11044v2",
      "title": "Evaluating the Performance of Large Language Models via Debates",
      "title_zh": "通过辩论评估大语言模型的性能",
      "authors": [
        "Behrad Moniri",
        "Hamed Hassani",
        "Edgar Dobriban"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly evolving and impacting various\nfields, necessitating the development of effective methods to evaluate and\ncompare their performance. Most current approaches for performance evaluation\nare either based on fixed, domain-specific questions that lack the flexibility\nrequired in many real-world applications, or rely on human input, making them\nunscalable. To address these issues, we propose an automated benchmarking\nframework based on debates between LLMs, judged by another LLM. This method\nassesses not only domain knowledge, but also skills such as argumentative\nreasoning and inconsistency recognition. We evaluate the performance of various\nstate-of-the-art LLMs using the debate framework and achieve rankings that\nalign closely with popular rankings based on human input, eliminating the need\nfor costly human crowdsourcing.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLMs)辩论的自动基准测试框架，用于评估和比较LLMs的性能，以解决现有方法（如固定问题缺乏灵活性或依赖人类输入导致不可扩展）的局限性。该框架通过让LLMs进行辩论，并由另一个LLMs担任裁判，不仅评估领域知识，还测试论证推理和不一致性识别等技能。实验结果显示，该框架的性能排名与基于人类输入的流行排名高度一致，同时消除了昂贵的人力众包需求，为高效的LLMs评估提供了可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11044v2",
      "published_date": "2024-06-16 19:02:31 UTC",
      "updated_date": "2025-02-07 21:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:42:38.451042"
    },
    {
      "arxiv_id": "2406.11039v2",
      "title": "Dynamic Normativity: Necessary and Sufficient Conditions for Value Alignment",
      "title_zh": "动态规范性：价值对齐的必要和充分条件",
      "authors": [
        "Nicholas Kluge Corrêa"
      ],
      "abstract": "The critical inquiry pervading the realm of Philosophy, and perhaps extending\nits influence across all Humanities disciplines, revolves around the\nintricacies of morality and normativity. Surprisingly, in recent years, this\nthematic thread has woven its way into an unexpected domain, one not\nconventionally associated with pondering \"what ought to be\": the field of\nartificial intelligence (AI) research. Central to morality and AI, we find\n\"alignment\", a problem related to the challenges of expressing human goals and\nvalues in a manner that artificial systems can follow without leading to\nunwanted adversarial effects. More explicitly and with our current paradigm of\nAI development in mind, we can think of alignment as teaching human values to\nnon-anthropomorphic entities trained through opaque, gradient-based learning\ntechniques. This work addresses alignment as a technical-philosophical problem\nthat requires solid philosophical foundations and practical implementations\nthat bring normative theory to AI system development. To accomplish this, we\npropose two sets of necessary and sufficient conditions that, we argue, should\nbe considered in any alignment process. While necessary conditions serve as\nmetaphysical and metaethical roots that pertain to the permissibility of\nalignment, sufficient conditions establish a blueprint for aligning AI systems\nunder a learning-based paradigm. After laying such foundations, we present\nimplementations of this approach by using state-of-the-art techniques and\nmethods for aligning general-purpose language systems. We call this framework\nDynamic Normativity. Its central thesis is that any alignment process under a\nlearning paradigm that cannot fulfill its necessary and sufficient conditions\nwill fail in producing aligned systems.",
      "tldr_zh": "这篇论文探讨了AI中的“value alignment”问题，即如何让AI系统准确遵循人类目标和价值观，而避免负面影响，将其视为一个技术-哲学交叉领域。作者提出两套“necessary and sufficient conditions”：必要条件作为形而上学和元伦理基础，确立alignment的许可性；充分条件则为基于学习的AI系统提供实际蓝图。论文引入“Dynamic Normativity”框架，通过结合哲学理论和前沿语言模型技术来实现alignment，并论证如果这些条件未被满足，任何alignment过程都将失败，从而为AI伦理发展奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11039v2",
      "published_date": "2024-06-16 18:37:31 UTC",
      "updated_date": "2024-06-18 12:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:42:50.298705"
    },
    {
      "arxiv_id": "2406.11033v2",
      "title": "HAIChart: Human and AI Paired Visualization System",
      "title_zh": "HAIChart：人类与AI配对的可视化系统",
      "authors": [
        "Yupeng Xie",
        "Yuyu Luo",
        "Guoliang Li",
        "Nan Tang"
      ],
      "abstract": "The growing importance of data visualization in business intelligence and\ndata science emphasizes the need for tools that can efficiently generate\nmeaningful visualizations from large datasets. Existing tools fall into two\nmain categories: human-powered tools (e.g., Tableau and PowerBI), which require\nintensive expert involvement, and AI-powered automated tools (e.g., Draco and\nTable2Charts), which often fall short of guessing specific user needs. In this\npaper, we aim to achieve the best of both worlds. Our key idea is to initially\nauto-generate a set of high-quality visualizations to minimize manual effort,\nthen refine this process iteratively with user feedback to more closely align\nwith their needs. To this end, we present HAIChart, a reinforcement\nlearning-based framework designed to iteratively recommend good visualizations\nfor a given dataset by incorporating user feedback. Specifically, we propose a\nMonte Carlo Graph Search-based visualization generation algorithm paired with a\ncomposite reward function to efficiently explore the visualization space and\nautomatically generate good visualizations. We devise a visualization hints\nmechanism to actively incorporate user feedback, thus progressively refining\nthe visualization generation module. We further prove that the top-k\nvisualization hints selection problem is NP-hard and design an efficient\nalgorithm. We conduct both quantitative evaluations and user studies, showing\nthat HAIChart significantly outperforms state-of-the-art human-powered tools\n(21% better at Recall and 1.8 times faster) and AI-powered automatic tools\n(25.1% and 14.9% better in terms of Hit@3 and R10@30, respectively).",
      "tldr_zh": "本研究针对数据可视化工具的局限性，提出 HAIChart，这是一个结合人类和 AI 的交互式系统，旨在通过初始自动生成高质量可视化并迭代融入用户反馈来优化结果。HAIChart 采用强化学习框架，包括 Monte Carlo Graph Search 算法和复合奖励函数来探索可视化空间，并通过可视化提示机制主动整合反馈；此外，证明了 top-k 可视化提示选择问题是 NP-hard，并设计了高效算法。实验结果显示，HAIChart 比人类驱动工具（如 Tableau）在 Recall 上提升 21% 并快 1.8 倍，比 AI 驱动工具（如 Draco）在 Hit@3 和 R10@30 上分别提升 25.1% 和 14.9%，显著提高了可视化效率和准确性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "VLDB 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11033v2",
      "published_date": "2024-06-16 18:04:47 UTC",
      "updated_date": "2024-09-07 13:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:43:04.899996"
    },
    {
      "arxiv_id": "2406.11912v2",
      "title": "AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Huynh Nguyen",
        "Thang Phan Chau",
        "Phong X. Nguyen",
        "Nghi D. Q. Bui"
      ],
      "abstract": "Software agents have emerged as promising tools for addressing complex\nsoftware engineering tasks. Existing works, on the other hand, frequently\noversimplify software development workflows, despite the fact that such\nworkflows are typically more complex in the real world. Thus, we propose\nAgileCoder, a multi agent system that integrates Agile Methodology (AM) into\nthe framework. This system assigns specific AM roles - such as Product Manager,\nDeveloper, and Tester to different agents, who then collaboratively develop\nsoftware based on user inputs. AgileCoder enhances development efficiency by\norganizing work into sprints, focusing on incrementally developing software\nthrough sprints. Additionally, we introduce Dynamic Code Graph Generator, a\nmodule that creates a Code Dependency Graph dynamically as updates are made to\nthe codebase. This allows agents to better comprehend the codebase, leading to\nmore precise code generation and modifications throughout the software\ndevelopment process. AgileCoder surpasses existing benchmarks, like ChatDev and\nMetaGPT, establishing a new standard and showcasing the capabilities of multi\nagent systems in advanced software engineering environments.",
      "tldr_zh": "论文提出 AgileCoder，一种基于 Agile Methodology 的多智能体系统，用于处理复杂软件开发任务。该系统分配特定角色如 Product Manager、Developer 和 Tester，让代理协同工作，通过 sprints 组织增量开发，并引入 Dynamic Code Graph Generator 动态创建 Code Dependency Graph，以提升代码理解和修改精度。相比现有基准如 ChatDev 和 MetaGPT，AgileCoder 在软件工程环境中表现出色，显著提高了开发效率并设定了新标准。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2406.11912v2",
      "published_date": "2024-06-16 17:57:48 UTC",
      "updated_date": "2024-07-14 09:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:43:15.522223"
    },
    {
      "arxiv_id": "2406.11026v1",
      "title": "Boosting Medical Image Classification with Segmentation Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Gu",
        "Zihan Zhao",
        "Hongxiao Wang",
        "Yaopeng Peng",
        "Yizhe Zhang",
        "Nishchal Sapkota",
        "Chaoli Wang",
        "Danny Z. Chen"
      ],
      "abstract": "The Segment Anything Model (SAM) exhibits impressive capabilities in\nzero-shot segmentation for natural images. Recently, SAM has gained a great\ndeal of attention for its applications in medical image segmentation. However,\nto our best knowledge, no studies have shown how to harness the power of SAM\nfor medical image classification. To fill this gap and make SAM a true\n``foundation model'' for medical image analysis, it is highly desirable to\ncustomize SAM specifically for medical image classification. In this paper, we\nintroduce SAMAug-C, an innovative augmentation method based on SAM for\naugmenting classification datasets by generating variants of the original\nimages. The augmented datasets can be used to train a deep learning\nclassification model, thereby boosting the classification performance.\nFurthermore, we propose a novel framework that simultaneously processes raw and\nSAMAug-C augmented image input, capitalizing on the complementary information\nthat is offered by both. Experiments on three public datasets validate the\neffectiveness of our new approach.",
      "tldr_zh": "本文提出了一种基于Segment Anything Model (SAM)的方法，以提升医疗图像分类性能。首先，作者引入SAMAug-C，一种创新的图像增强技术，利用SAM生成原始图像的变体，从而扩充分类数据集并训练深度学习模型。其次，提出一个新框架，该框架同时处理原始图像和SAMAug-C增强图像，充分利用二者的互补信息。实验在三个公共数据集上验证了这一方法的有效性，显著提高了分类准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11026v1",
      "published_date": "2024-06-16 17:54:49 UTC",
      "updated_date": "2024-06-16 17:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:43:26.355600"
    },
    {
      "arxiv_id": "2406.11023v1",
      "title": "Physics-Informed Deep Learning and Partial Transfer Learning for Bearing Fault Diagnosis in the Presence of Highly Missing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadreza Kavianpour",
        "Parisa Kavianpour",
        "Amin Ramezani"
      ],
      "abstract": "One of the most significant obstacles in bearing fault diagnosis is a lack of\nlabeled data for various fault types. Also, sensor-acquired data frequently\nlack labels and have a large amount of missing data. This paper tackles these\nissues by presenting the PTPAI method, which uses a physics-informed deep\nlearning-based technique to generate synthetic labeled data. Labeled synthetic\ndata makes up the source domain, whereas unlabeled data with missing data is\npresent in the target domain. Consequently, imbalanced class problems and\npartial-set fault diagnosis hurdles emerge. To address these challenges, the\nRF-Mixup approach is used to handle imbalanced classes. As domain adaptation\nstrategies, the MK-MMSD and CDAN are employed to mitigate the disparity in\ndistribution between synthetic and actual data. Furthermore, the partial-set\nchallenge is tackled by applying weighting methods at the class and instance\nlevels. Experimental outcomes on the CWRU and JNU datasets indicate that the\nproposed approach effectively addresses these problems.",
      "tldr_zh": "该研究针对轴承故障诊断中数据缺失和标签不足的问题，提出了一种PTPAI方法，利用Physics-Informed Deep Learning技术生成合成标记数据，以补充源域数据。针对不平衡类和部分集故障诊断挑战，该方法采用RF-Mixup处理类不平衡，结合MK-MMSD和CDAN作为域适应策略减少合成数据与实际数据分布差异，并通过类级和实例级权重方法解决部分集问题。实验在CWRU和JNU数据集上验证了该方法的有效性，显著提升了诊断性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11023v1",
      "published_date": "2024-06-16 17:36:53 UTC",
      "updated_date": "2024-06-16 17:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:43:39.062840"
    },
    {
      "arxiv_id": "2406.11014v1",
      "title": "Latent Communication in Artificial Neural Networks",
      "title_zh": "人工神经网络中的潜在通信",
      "authors": [
        "Luca Moschella"
      ],
      "abstract": "As NNs permeate various scientific and industrial domains, understanding the\nuniversality and reusability of their representations becomes crucial. At their\ncore, these networks create intermediate neural representations, indicated as\nlatent spaces, of the input data and subsequently leverage them to perform\nspecific downstream tasks. This dissertation focuses on the universality and\nreusability of neural representations. Do the latent representations crafted by\na NN remain exclusive to a particular trained instance, or can they generalize\nacross models, adapting to factors such as randomness during training, model\narchitecture, or even data domain? This adaptive quality introduces the notion\nof Latent Communication -- a phenomenon that describes when representations can\nbe unified or reused across neural spaces. A salient observation from our\nresearch is the emergence of similarities in latent representations, even when\nthese originate from distinct or seemingly unrelated NNs. By exploiting a\npartial correspondence between the two data distributions that establishes a\nsemantic link, we found that these representations can either be projected into\na universal representation, coined as Relative Representation, or be directly\ntranslated from one space to another. Latent Communication allows for a bridge\nbetween independently trained NN, irrespective of their training regimen,\narchitecture, or the data modality they were trained on -- as long as the data\nsemantic content stays the same (e.g., images and their captions). This holds\ntrue for both generation, classification and retrieval downstream tasks; in\nsupervised, weakly supervised, and unsupervised settings; and spans various\ndata modalities including images, text, audio, and graphs -- showcasing the\nuniversality of the Latent Communication phenomenon. [...]",
      "tldr_zh": "本论文探讨了人工神经网络中潜在表示（latent representations）的通用性和可重用性，焦点在于这些表示是否能跨不同模型、训练随机性、架构或数据域进行共享。作者引入了Latent Communication概念，通过建立部分数据分布对应关系，实现表示的统一或翻译，例如投影到通用Relative Representation或直接转换。研究发现，这种现象在生成、分类和检索任务中普遍存在，适用于监督、非监督设置，并跨越图像、文本、音频和图等模态，只要语义内容相同，从而证明了潜在表示的广泛可移植性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Doctoral Thesis: https://iris.uniroma1.it/handle/11573/1711827",
      "pdf_url": "http://arxiv.org/pdf/2406.11014v1",
      "published_date": "2024-06-16 17:13:58 UTC",
      "updated_date": "2024-06-16 17:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:43:52.988825"
    },
    {
      "arxiv_id": "2406.11012v7",
      "title": "Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs Using the New York Times Connections Word Game",
      "title_zh": "连接点成线：使用《纽约时报》Connections 文字游戏评估大型语言模型的抽象推理能力",
      "authors": [
        "Prisha Samadarshi",
        "Mariam Mustafa",
        "Anushka Kulkarni",
        "Raven Rothkopf",
        "Tuhin Chakrabarty",
        "Smaranda Muresan"
      ],
      "abstract": "The New York Times Connections game has emerged as a popular and challenging\npursuit for word puzzle enthusiasts. We collect 438 Connections games to\nevaluate the performance of state-of-the-art large language models (LLMs)\nagainst expert and novice human players. Our results show that even the best\nperforming LLM, Claude 3.5 Sonnet, which has otherwise shown impressive\nreasoning abilities on a wide variety of benchmarks, can only fully solve 18%\nof the games. Novice and expert players perform better than Claude 3.5 Sonnet,\nwith expert human players significantly outperforming it. We create a taxonomy\nof the knowledge types required to successfully cluster and categorize words in\nthe Connections game. We find that while LLMs perform relatively well on\ncategorizing words based on semantic relations they struggle with other types\nof knowledge such as Encyclopedic Knowledge, Multiword Expressions or knowledge\nthat combines both Word Form and Meaning. Our results establish the New York\nTimes Connections game as a challenging benchmark for evaluating abstract\nreasoning capabilities in AI systems.",
      "tldr_zh": "本研究使用 New York Times Connections 单词游戏评估大型语言模型 (LLMs) 的抽象推理能力，收集了 438 场游戏并比较了 LLMs（如 Claude 3.5 Sonnet）与人类玩家的表现。结果显示，Claude 3.5 Sonnet 仅能完全解决 18% 的游戏，而初学者和专家人类玩家均表现出色，尤其是在非语义关系类别上。研究创建了一个知识类型分类，发现 LLMs 在语义关系上表现较好，但挣扎于 Encyclopedic Knowledge、多词表达 (Multiword Expressions) 或结合词形和意义的知识。该游戏被确立为评估 AI 系统抽象推理能力的具有挑战性的基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11012v7",
      "published_date": "2024-06-16 17:10:32 UTC",
      "updated_date": "2024-10-14 03:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:44:08.243990"
    },
    {
      "arxiv_id": "2406.11911v3",
      "title": "A Notion of Complexity for Theory of Mind via Discrete World Models",
      "title_zh": "翻译失败",
      "authors": [
        "X. Angelo Huang",
        "Emanuele La Malfa",
        "Samuele Marro",
        "Andrea Asperti",
        "Anthony Cohn",
        "Michael Wooldridge"
      ],
      "abstract": "Theory of Mind (ToM) can be used to assess the capabilities of Large Language\nModels (LLMs) in complex scenarios where social reasoning is required. While\nthe research community has proposed many ToM benchmarks, their hardness varies\ngreatly, and their complexity is not well defined. This work proposes a\nframework inspired by cognitive load theory to measure the complexity of ToM\ntasks. We quantify a problem's complexity as the number of states necessary to\nsolve it correctly. Our complexity measure also accounts for spurious states of\na ToM problem designed to make it apparently harder. We use our method to\nassess the complexity of five widely adopted ToM benchmarks. On top of this\nframework, we design a prompting technique that augments the information\navailable to a model with a description of how the environment changes with the\nagents' interactions. We name this technique Discrete World Models (DWM) and\nshow how it elicits superior performance on ToM tasks.",
      "tldr_zh": "本研究提出一个基于认知负荷理论的框架，用于衡量 Theory of Mind (ToM) 任务的复杂度，将复杂度定义为解决问题的必要状态数，并考虑虚假状态以避免任务难度被夸大。作者评估了五个广泛采用的 ToM 基准，展示了该框架在量化任务难度方面的有效性。此外，设计了 Discrete World Models (DWM) 提示技术，通过描述代理互动如何改变环境来增强模型可用信息，从而显著提升 Large Language Models (LLMs) 在 ToM 任务上的表现。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted EMNLP 2024, Website\n  https://flecart.github.io/complexity-tom-dwm",
      "pdf_url": "http://arxiv.org/pdf/2406.11911v3",
      "published_date": "2024-06-16 16:46:55 UTC",
      "updated_date": "2024-10-09 06:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:44:19.143947"
    },
    {
      "arxiv_id": "2406.11006v1",
      "title": "SPEAR: Receiver-to-Receiver Acoustic Neural Warping Field",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang He",
        "Shitong Xu",
        "Jia-Xing Zhong",
        "Sangyun Shin",
        "Niki Trigoni",
        "Andrew Markham"
      ],
      "abstract": "We present SPEAR, a continuous receiver-to-receiver acoustic neural warping\nfield for spatial acoustic effects prediction in an acoustic 3D space with a\nsingle stationary audio source. Unlike traditional source-to-receiver modelling\nmethods that require prior space acoustic properties knowledge to rigorously\nmodel audio propagation from source to receiver, we propose to predict by\nwarping the spatial acoustic effects from one reference receiver position to\nanother target receiver position, so that the warped audio essentially\naccommodates all spatial acoustic effects belonging to the target position.\nSPEAR can be trained in a data much more readily accessible manner, in which we\nsimply ask two robots to independently record spatial audio at different\npositions. We further theoretically prove the universal existence of the\nwarping field if and only if one audio source presents. Three physical\nprinciples are incorporated to guide SPEAR network design, leading to the\nlearned warping field physically meaningful. We demonstrate SPEAR superiority\non both synthetic, photo-realistic and real-world dataset, showing the huge\npotential of SPEAR to various down-stream robotic tasks.",
      "tldr_zh": "本研究提出 SPEAR，一种连续的接收器到接收器的声学神经扭曲场（neural warping field），用于在单一固定音频源的声学 3D 空间中预测空间声学效果（spatial acoustic effects）。与传统的源到接收器建模方法不同，SPEAR 通过将声学效果从参考接收器位置扭曲到目标位置，从而高效捕捉目标位置的所有声学特性，且仅需两个机器人分别记录不同位置的音频即可训练。研究理论证明了这种扭曲场的普遍存在，当且仅当存在一个音频源时，并通过融入三个物理原则确保扭曲场具有物理意义。在合成、照片级真实和真实世界数据集上，SPEAR 展现出优越性能，具有巨大的潜力应用于下游机器人任务。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, 5 figures in main paper",
      "pdf_url": "http://arxiv.org/pdf/2406.11006v1",
      "published_date": "2024-06-16 16:40:26 UTC",
      "updated_date": "2024-06-16 16:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:44:31.716542"
    },
    {
      "arxiv_id": "2406.11003v1",
      "title": "3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments",
      "title_zh": "3D 注视跟踪用于研究混合现实环境中的协作互动",
      "authors": [
        "Eduardo Davalos",
        "Yike Zhang",
        "Ashwin T. S.",
        "Joyce H. Fonteles",
        "Umesh Timalsina",
        "Guatam Biswas"
      ],
      "abstract": "This study presents a novel framework for 3D gaze tracking tailored for\nmixed-reality settings, aimed at enhancing joint attention and collaborative\nefforts in team-based scenarios. Conventional gaze tracking, often limited by\nmonocular cameras and traditional eye-tracking apparatus, struggles with\nsimultaneous data synchronization and analysis from multiple participants in\ngroup contexts. Our proposed framework leverages state-of-the-art computer\nvision and machine learning techniques to overcome these obstacles, enabling\nprecise 3D gaze estimation without dependence on specialized hardware or\ncomplex data fusion. Utilizing facial recognition and deep learning, the\nframework achieves real-time, tracking of gaze patterns across several\nindividuals, addressing common depth estimation errors, and ensuring spatial\nand identity consistency within the dataset. Empirical results demonstrate the\naccuracy and reliability of our method in group environments. This provides\nmechanisms for significant advances in behavior and interaction analysis in\neducational and professional training applications in dynamic and unstructured\nenvironments.",
      "tldr_zh": "本研究提出一个新型框架，用于混合现实环境中的3D gaze tracking，以提升团队协作场景中的联合注意力和互动效率。该框架采用先进的computer vision和machine learning技术，实现实时多参与者注视跟踪，避免依赖专业硬件，并通过面部识别和深度学习解决深度估计错误，确保空间和身份一致性。实验结果证明了该方法的准确性和可靠性，为教育及专业培训中的行为互动分析提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 8 figures, conference, submitted to ICMI 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11003v1",
      "published_date": "2024-06-16 16:30:56 UTC",
      "updated_date": "2024-06-16 16:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:44:41.812241"
    },
    {
      "arxiv_id": "2406.10999v5",
      "title": "Balancing Rigor and Utility: Mitigating Cognitive Biases in Large Language Models for Multiple-Choice Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyang Zhong",
        "Liman Wang",
        "Wenting Cao",
        "Zeyuan Sun"
      ],
      "abstract": "This paper examines the role of cognitive biases in the decision-making\nprocesses of large language models (LLMs), challenging the conventional goal of\neliminating all biases. When properly balanced, we show that certain cognitive\nbiases can enhance decision-making efficiency through rational deviations and\nheuristic shortcuts. By introducing heuristic moderation and an abstention\noption, which allows LLMs to withhold responses when uncertain, we reduce error\nrates, improve decision accuracy, and optimize decision rates. Using the\nBalance Rigor and Utility (BRU) dataset, developed through expert\ncollaboration, our findings demonstrate that targeted inspection of cognitive\nbiases aligns LLM decisions more closely with human reasoning, enhancing\nreliability and suggesting strategies for future improvements. This approach\noffers a novel way to leverage cognitive biases to improve the practical\nutility of LLMs across various applications.",
      "tldr_zh": "本论文探讨了认知偏差在大型语言模型 (LLMs) 决策过程中的作用，挑战了完全消除偏差的传统目标，并证明适当平衡这些偏差可通过合理的偏差和启发式捷径提升决策效率。研究引入了启发式调节 (heuristic moderation) 和弃权选项 (abstention option)，允许 LLMs 在不确定时不作回应，从而使用 Balance Rigor and Utility (BRU) 数据集减少错误率、提高决策准确性和优化决策率。结果表明，这种方法使 LLMs 的决策更接近人类推理，提升了可靠性，并为 LLMs 在各种应用中的实际效用提供了新策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This work has been accepted as a full paper at the 2025 Annual\n  Conference of the Cognitive Science Society (CogSci 2025) and will be\n  presented in the form of a poster. The dataset and project website are\n  available at: https://hanyangzhong.github.io/BRU-website/",
      "pdf_url": "http://arxiv.org/pdf/2406.10999v5",
      "published_date": "2024-06-16 16:25:22 UTC",
      "updated_date": "2025-04-13 13:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:44:56.020914"
    },
    {
      "arxiv_id": "2406.15474v1",
      "title": "WundtGPT: Shaping Large Language Models To Be An Empathetic, Proactive Psychologist",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Ren",
        "Yazhou Zhang",
        "Daihai He",
        "Jing Qin"
      ],
      "abstract": "Large language models (LLMs) are raging over the medical domain, and their\nmomentum has carried over into the mental health domain, leading to the\nemergence of few mental health LLMs. Although such mental health LLMs could\nprovide reasonable suggestions for psychological counseling, how to develop an\nauthentic and effective doctor-patient relationship (DPR) through LLMs is still\nan important problem. To fill this gap, we dissect DPR into two key attributes,\ni.e., the psychologist's empathy and proactive guidance. We thus present\nWundtGPT, an empathetic and proactive mental health large language model that\nis acquired by fine-tuning it with instruction and real conversation between\npsychologists and patients. It is designed to assist psychologists in diagnosis\nand help patients who are reluctant to communicate face-to-face understand\ntheir psychological conditions. Its uniqueness lies in that it could not only\npose purposeful questions to guide patients in detailing their symptoms but\nalso offer warm emotional reassurance. In particular, WundtGPT incorporates\nCollection of Questions, Chain of Psychodiagnosis, and Empathy Constraints into\na comprehensive prompt for eliciting LLMs' questions and diagnoses.\nAdditionally, WundtGPT proposes a reward model to promote alignment with\nempathetic mental health professionals, which encompasses two key factors:\ncognitive empathy and emotional empathy. We offer a comprehensive evaluation of\nour proposed model. Based on these outcomes, we further conduct the manual\nevaluation based on proactivity, effectiveness, professionalism and coherence.\nWe notice that WundtGPT can offer professional and effective consultation. The\nmodel is available at huggingface.",
      "tldr_zh": "本研究提出 WundtGPT，一种通过微调 Large Language Models (LLMs) 使其具备移情和主动指导属性的心理健康模型，旨在构建真实的 Doctor-Patient Relationship (DPR)。该模型利用指令、真实心理对话进行训练，并整合 Collection of Questions、Chain of Psychodiagnosis 和 Empathy Constraints 等组件，以及一个奖励模型来提升认知移情和情感移情。WundtGPT 能主动提出有针对性的问题，提供情感支持，并辅助诊断，帮助患者理解心理状态。实验评估显示，该模型在主动性、专业性和有效性方面表现出色，并已在 Hugging Face 上公开。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15474v1",
      "published_date": "2024-06-16 16:06:38 UTC",
      "updated_date": "2024-06-16 16:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:45:09.910800"
    },
    {
      "arxiv_id": "2406.10989v1",
      "title": "Predicting the Understandability of Computational Notebooks through Code Metrics Analysis",
      "title_zh": "通过代码指标分析预测计算笔记本的可理解性",
      "authors": [
        "Mojtaba Mostafavi Ghahfarokhi",
        "Alireza Asadi",
        "Arash Asgari",
        "Bardia Mohammadi",
        "Masih Beigi Rizi",
        "Abbas Heydarnoori"
      ],
      "abstract": "Computational notebooks have become the primary coding environment for data\nscientists. However, research on their code quality is still emerging, and the\ncode shared is often of poor quality. Given the importance of maintenance and\nreusability, understanding the metrics that affect notebook code\ncomprehensibility is crucial. Code understandability, a qualitative variable,\nis closely tied to user opinions. Traditional approaches to measuring it either\nuse limited questionnaires to review a few code pieces or rely on metadata such\nas likes and votes in software repositories. Our approach enhances the\nmeasurement of Jupyter notebook understandability by leveraging user comments\nrelated to code understandability. As a case study, we used 542,051 Kaggle\nJupyter notebooks from our previous research, named DistilKaggle. We employed a\nfine-tuned DistilBERT transformer to identify user comments associated with\ncode understandability. We established a criterion called User Opinion Code\nUnderstandability (UOCU), which considers the number of relevant comments,\nupvotes on those comments, total notebook views, and total notebook upvotes.\nUOCU proved to be more effective than previous methods. Furthermore, we trained\nmachine learning models to predict notebook code understandability based solely\non their metrics. We collected 34 metrics for 132,723 final notebooks as\nfeatures in our dataset, using UOCU as the label. Our predictive model, using\nthe Random Forest classifier, achieved 89% accuracy in predicting the\nunderstandability levels of computational notebooks.",
      "tldr_zh": "本文研究通过代码指标分析预测计算笔记本（Computational Notebooks）的可理解性，针对数据科学家常用环境如 Jupyter 笔记本的代码质量问题。研究者使用 fine-tuned DistilBERT 模型分析用户评论，定义了 User Opinion Code Understandability (UOCU) 标准，该标准整合相关评论数、点赞、浏览量和总点赞，比传统方法更有效。最终，他们基于 132,723 个笔记本的 34 个指标训练 Random Forest 分类器，实现了 89% 的预测准确率，为提升代码可维护性和可重用性提供了新工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10989v1",
      "published_date": "2024-06-16 15:58:40 UTC",
      "updated_date": "2024-06-16 15:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:45:29.388611"
    },
    {
      "arxiv_id": "2406.10977v1",
      "title": "Toward Optimal LLM Alignments Using Two-Player Games",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Zheng",
        "Hongyi Guo",
        "Zhihan Liu",
        "Xiaoying Zhang",
        "Yuanshun Yao",
        "Xiaojun Xu",
        "Zhaoran Wang",
        "Zhiheng Xi",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang",
        "Hang Li",
        "Yang Liu"
      ],
      "abstract": "The standard Reinforcement Learning from Human Feedback (RLHF) framework\nprimarily focuses on optimizing the performance of large language models using\npre-collected prompts. However, collecting prompts that provide comprehensive\ncoverage is both tedious and challenging, and often fails to include scenarios\nthat LLMs need to improve on the most. In this paper, we investigate alignment\nthrough the lens of two-agent games, involving iterative interactions between\nan adversarial and a defensive agent. The adversarial agent's task at each step\nis to generate prompts that expose the weakness of the defensive agent. In\nreturn, the defensive agent seeks to improve its responses to these newly\nidentified prompts it struggled with, based on feedback from the reward model.\nWe theoretically demonstrate that this iterative reinforcement learning\noptimization converges to a Nash Equilibrium for the game induced by the\nagents. Experimental results in safety scenarios demonstrate that learning in\nsuch a competitive environment not only fully trains agents but also leads to\npolicies with enhanced generalization capabilities for both adversarial and\ndefensive agents.",
      "tldr_zh": "该论文针对标准RLHF（Reinforcement Learning from Human Feedback）框架的局限性，提出了一种基于两智能体游戏的方法来优化LLM（Large Language Models）的对齐过程。方法涉及对抗代理生成暴露防御代理弱点的提示，而防御代理则基于奖励模型的反馈迭代改进其响应，从而实现更全面的训练。理论上，该迭代强化学习优化过程被证明会收敛到Nash Equilibrium；实验在安全场景中显示，这种竞争环境不仅提升了代理的全面性，还显著增强了其泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68"
      ],
      "primary_category": "cs.CL",
      "comment": "Our code is released at https://github.com/ruizheng20/gpo",
      "pdf_url": "http://arxiv.org/pdf/2406.10977v1",
      "published_date": "2024-06-16 15:24:50 UTC",
      "updated_date": "2024-06-16 15:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:45:30.829842"
    },
    {
      "arxiv_id": "2406.10974v3",
      "title": "Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?",
      "title_zh": "翻译失败",
      "authors": [
        "T. Y. S. S Santosh",
        "Kevin D. Ashley",
        "Katie Atkinson",
        "Matthias Grabmair"
      ],
      "abstract": "Modeling legal reasoning and argumentation justifying decisions in cases has\nalways been central to AI & Law, yet contemporary developments in legal NLP\nhave increasingly focused on statistically classifying legal conclusions from\ntext. While conceptually simpler, these approaches often fall short in\nproviding usable justifications connecting to appropriate legal concepts. This\npaper reviews both traditional symbolic works in AI & Law and recent advances\nin legal NLP, and distills possibilities of integrating expert-informed\nknowledge to strike a balance between scalability and explanation in symbolic\nvs. data-driven approaches. We identify open challenges and discuss the\npotential of modern NLP models and methods that integrate",
      "tldr_zh": "该论文探讨了使用 NLP 支持法律论证的问题，质疑是否仅靠更多数据就能解决核心挑战。作者回顾了 AI & Law 中的传统符号方法和现代数据驱动的法律 NLP 技术，指出后者虽能分类法律结论，但往往缺乏对适当法律概念的解释和理由。论文主张通过整合专家知识来平衡符号方法的可解释性和数据驱动方法的可扩展性，并识别了开放挑战，同时讨论了现代 NLP 模型在提升法律推理潜力方面的前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NLLP Workshop, EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10974v3",
      "published_date": "2024-06-16 15:15:44 UTC",
      "updated_date": "2024-10-15 15:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:45:41.421956"
    },
    {
      "arxiv_id": "2406.10973v3",
      "title": "ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts",
      "title_zh": "ExPLoRA：参数高效的扩展预训练以适应领域偏移下的视觉Transformer",
      "authors": [
        "Samar Khanna",
        "Medhanie Irgau",
        "David B. Lobell",
        "Stefano Ermon"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) techniques such as low-rank adaptation\n(LoRA) can effectively adapt large pre-trained foundation models to downstream\ntasks using only a small fraction (0.1%-10%) of the original trainable weights.\nAn under-explored question of PEFT is in extending the pre-training phase\nwithout supervised labels; that is, can we adapt a pre-trained foundation model\nto a new domain via efficient self-supervised pre-training on this new domain?\nIn this work, we introduce ExPLoRA, a highly effective technique to improve\ntransfer learning of pre-trained vision transformers (ViTs) under domain\nshifts. Initializing a ViT with pre-trained weights on large, natural-image\ndatasets such as from DinoV2 or MAE, ExPLoRA continues the unsupervised\npre-training objective on a new domain, unfreezing 1-2 pre-trained ViT blocks\nand tuning all other layers with LoRA. We then fine-tune the resulting model\nonly with LoRA on this new domain for supervised learning. Our experiments\ndemonstrate state-of-the-art results on satellite imagery, even outperforming\nfully pre-training and fine-tuning ViTs. Using the DinoV2 training objective,\nwe demonstrate up to 8% improvement in linear probing top-1 accuracy on\ndownstream tasks while using <10% of the number of parameters that are used in\nprior fully-tuned state-of-the art approaches. Our ablation studies confirm the\nefficacy of our approach over other baselines, including PEFT and unfreezing\nmore ViT blocks. Code is available on the project website:\nhttps://samar-khanna.github.io/ExPLoRA/",
      "tldr_zh": "本研究引入ExPLoRA，一种参数高效的扩展预训练技术，用于提升预训练的Vision Transformers (ViTs) 在领域转移下的迁移学习性能。ExPLoRA方法在新的领域上继续无监督预训练，只解冻1-2个ViT块并用Low-rank adaptation (LoRA) 调整其他层，随后仅用LoRA进行监督微调。实验结果显示，该方法在卫星图像任务上超越了完全预训练和微调的基线模型，使用DinoV2目标提高了8%的线性探测top-1准确率，同时仅使用不到10%的参数，证明了其高效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10973v3",
      "published_date": "2024-06-16 15:14:56 UTC",
      "updated_date": "2025-02-17 00:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:45:58.118925"
    },
    {
      "arxiv_id": "2406.10964v3",
      "title": "Ontology Embedding: A Survey of Methods, Applications and Resources",
      "title_zh": "本体嵌入：方法、应用和资源的调查",
      "authors": [
        "Jiaoyan Chen",
        "Olga Mashkova",
        "Fernando Zhapa-Camacho",
        "Robert Hoehndorf",
        "Yuan He",
        "Ian Horrocks"
      ],
      "abstract": "Ontologies are widely used for representing domain knowledge and meta data,\nplaying an increasingly important role in Information Systems, the Semantic\nWeb, Bioinformatics and many other domains. However, logical reasoning that\nontologies can directly support are quite limited in learning, approximation\nand prediction. One straightforward solution is to integrate statistical\nanalysis and machine learning. To this end, automatically learning vector\nrepresentation for knowledge of an ontology i.e., ontology embedding has been\nwidely investigated. Numerous papers have been published on ontology embedding,\nbut a lack of systematic reviews hinders researchers from gaining a\ncomprehensive understanding of this field. To bridge this gap, we write this\nsurvey paper, which first introduces different kinds of semantics of ontologies\nand formally defines ontology embedding as well as its property of\nfaithfulness. Based on this, it systematically categorizes and analyses a\nrelatively complete set of over 80 papers, according to the ontologies they aim\nat and their technical solutions including geometric modeling, sequence\nmodeling and graph propagation. This survey also introduces the applications of\nontology embedding in ontology engineering, machine learning augmentation and\nlife sciences, presents a new library mOWL and discusses the challenges and\nfuture directions.",
      "tldr_zh": "这篇调查论文探讨了本体嵌入（Ontology Embedding）的各种方法、应用和资源，旨在弥合本体在逻辑推理方面的局限性与统计分析、机器学习的整合。论文首先定义了本体语义并正式阐述本体嵌入及其保真性（faithfulness），随后系统分析了超过80篇相关文献，按几何建模（geometric modeling）、序列建模（sequence modeling）和图传播（graph propagation）等技术方案进行分类。最终，它介绍了本体嵌入在本体工程（ontology engineering）、机器学习增强（machine learning augmentation）和生命科学（life sciences）中的实际应用，推出了新库 mOWL，并讨论了面临的挑战和未来发展方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)",
      "pdf_url": "http://arxiv.org/pdf/2406.10964v3",
      "published_date": "2024-06-16 14:49:19 UTC",
      "updated_date": "2025-04-07 11:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:46:08.440881"
    },
    {
      "arxiv_id": "2406.10961v1",
      "title": "Open-Vocabulary X-ray Prohibited Item Detection via Fine-tuning CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyang Lin",
        "Tong Jia",
        "Hao Wang",
        "Bowen Ma",
        "Mingyuan Li",
        "Dongyue Chen"
      ],
      "abstract": "X-ray prohibited item detection is an essential component of security check\nand categories of prohibited item are continuously increasing in accordance\nwith the latest laws. Previous works all focus on close-set scenarios, which\ncan only recognize known categories used for training and often require\ntime-consuming as well as labor-intensive annotations when learning novel\ncategories, resulting in limited real-world applications. Although the success\nof vision-language models (e.g. CLIP) provides a new perspectives for open-set\nX-ray prohibited item detection, directly applying CLIP to X-ray domain leads\nto a sharp performance drop due to domain shift between X-ray data and general\ndata used for pre-training CLIP. To address aforementioned challenges, in this\npaper, we introduce distillation-based open-vocabulary object detection (OVOD)\ntask into X-ray security inspection domain by extending CLIP to learn visual\nrepresentations in our specific X-ray domain, aiming to detect novel prohibited\nitem categories beyond base categories on which the detector is trained.\nSpecifically, we propose X-ray feature adapter and apply it to CLIP within OVOD\nframework to develop OVXD model. X-ray feature adapter containing three adapter\nsubmodules of bottleneck architecture, which is simple but can efficiently\nintegrate new knowledge of X-ray domain with original knowledge, further bridge\ndomain gap and promote alignment between X-ray images and textual concepts.\nExtensive experiments conducted on PIXray and PIDray datasets demonstrate that\nproposed method performs favorably against other baseline OVOD methods in\ndetecting novel categories in X-ray scenario. It outperforms previous best\nresult by 15.2 AP50 and 1.5 AP50 on PIXray and PIDray with achieving 21.0 AP50\nand 27.8 AP50 respectively.",
      "tldr_zh": "本文提出了一种开放词汇X-ray禁止物品检测方法，通过微调CLIP模型来解决传统封闭集方法无法识别新类别的问题。作者设计了X-ray feature adapter（包括三个瓶颈架构子模块），在蒸馏-based OVOD框架中整合X-ray领域知识，桥接领域偏移并提升图像与文本概念的 alignment。实验在PIXray和PIDray数据集上表明，该方法比基线模型提高了15.2 AP50和1.5 AP50，分别达到21.0 AP50和27.8 AP50，为X-ray安全检查中检测新型禁止物品提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10961v1",
      "published_date": "2024-06-16 14:42:52 UTC",
      "updated_date": "2024-06-16 14:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:46:20.855742"
    },
    {
      "arxiv_id": "2406.11909v4",
      "title": "Mixture-of-Subspaces in Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Taiqiang Wu",
        "Jiahao Wang",
        "Zhe Zhao",
        "Ngai Wong"
      ],
      "abstract": "In this paper, we introduce a subspace-inspired Low-Rank Adaptation (LoRA)\nmethod, which is computationally efficient, easy to implement, and readily\napplicable to large language, multimodal, and diffusion models. Initially, we\nequivalently decompose the weights of LoRA into two subspaces, and find that\nsimply mixing them can enhance performance. To study such a phenomenon, we\nrevisit it through a fine-grained subspace lens, showing that such modification\nis equivalent to employing a fixed mixer to fuse the subspaces. To be more\nflexible, we jointly learn the mixer with the original LoRA weights, and term\nthe method Mixture-of-Subspaces LoRA (MoSLoRA). MoSLoRA consistently\noutperforms LoRA on tasks in different modalities, including commonsense\nreasoning, visual instruction tuning, and subject-driven text-to-image\ngeneration, demonstrating its effectiveness and robustness. Codes are available\nat https://github.com/wutaiqiang/MoSLoRA.",
      "tldr_zh": "本文提出了一种基于子空间的 Low-Rank Adaptation (LoRA) 方法，旨在提升大型语言模型、多模态模型和扩散模型的计算效率和性能。该方法首先将 LoRA 权重分解成两个子空间，并发现简单混合它们即可改善表现；进一步，通过联合学习混合器，开发出 Mixture-of-Subspaces LoRA (MoSLoRA)，使其更灵活和有效。实验结果显示，MoSLoRA 在常识推理、视觉指令微调和主体驱动的文本到图像生成等任务上 consistently outperforms 标准 LoRA，展示了其鲁棒性。代码已在 GitHub 上提供，方便进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024 Main, Oral",
      "pdf_url": "http://arxiv.org/pdf/2406.11909v4",
      "published_date": "2024-06-16 14:19:49 UTC",
      "updated_date": "2025-03-02 08:40:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:46:35.428110"
    },
    {
      "arxiv_id": "2406.10948v1",
      "title": "Incorporating uncertainty quantification into travel mode choice modeling: a Bayesian neural network (BNN) approach and an uncertainty-guided active survey framework",
      "title_zh": "翻译失败",
      "authors": [
        "Shuwen Zheng",
        "Zhou Fang",
        "Liang Zhao"
      ],
      "abstract": "Existing deep learning approaches for travel mode choice modeling fail to\ninform modelers about their prediction uncertainty. Even when facing scenarios\nthat are out of the distribution of training data, which implies high\nprediction uncertainty, these approaches still provide deterministic answers,\npotentially leading to misguidance. To address this limitation, this study\nintroduces the concept of uncertainty from the field of explainable artificial\nintelligence into travel mode choice modeling. We propose a Bayesian neural\nnetwork-based travel mode prediction model (BTMP) that quantifies the\nuncertainty of travel mode predictions, enabling the model itself to \"know\" and\n\"tell\" what it doesn't know. With BTMP, we further propose an\nuncertainty-guided active survey framework, which dynamically formulates survey\nquestions representing travel mode choice scenarios with high prediction\nuncertainty. Through iterative collection of responses to these dynamically\ntailored survey questions, BTMP is iteratively trained to achieve the desired\naccuracy faster with fewer questions, thereby reducing survey costs.\nExperimental validation using synthetic datasets confirms the effectiveness of\nBTMP in quantifying prediction uncertainty. Furthermore, experiments, utilizing\nboth synthetic and real-world data, demonstrate that the BTMP model, trained\nwith the uncertainty-guided active survey framework, requires 20% to 50% fewer\nsurvey responses to match the performance of the model trained on randomly\ncollected survey data. Overall, the proposed BTMP model and active survey\nframework innovatively incorporate uncertainty quantification into travel mode\nchoice modeling, providing model users with essential insights into prediction\nreliability while optimizing data collection for deep learning model training\nin a cost-efficient manner.",
      "tldr_zh": "本研究针对现有深度学习方法在旅行模式选择建模中忽略预测不确定性的问题，提出了一种基于 Bayesian Neural Network (BNN) 的 BTMP 模型，能够量化预测不确定性，从而让模型识别并报告未知场景。BTMP 进一步结合不确定性引导的主动调查框架，该框架动态生成针对高不确定性场景的调查问题，通过迭代收集响应实现更高效的模型训练，从而降低调查成本。实验结果显示，使用合成和真实数据，采用该框架的 BTMP 模型只需随机收集数据的 20% 到 50% 的响应即可达到相同性能，创新性地提升了旅行模式选择建模的可靠性和数据效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10948v1",
      "published_date": "2024-06-16 14:05:47 UTC",
      "updated_date": "2024-06-16 14:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:46:46.766660"
    },
    {
      "arxiv_id": "2406.10942v4",
      "title": "Effective Generative AI: The Human-Algorithm Centaur",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush Saghafian",
        "Lihi Idan"
      ],
      "abstract": "Advanced analytics science methods have enabled combining the power of\nartificial and human intelligence, creating \\textit{centaurs} that allow\nsuperior decision-making. Centaurs are hybrid human-algorithm models that\ncombine both formal analytics and human intuition in a symbiotic manner within\ntheir learning and reasoning process. We argue that the future of AI\ndevelopment and use in many domains needs to focus more on centaurs as opposed\nto other AI approaches. This paradigm shift towards centaur-based AI methods\nraises some fundamental questions: How are centaurs different from other\nhuman-in-the-loop methods? What are the most effective methods for creating\ncentaurs? When should centaurs be used, and when should the lead be given to\npure AI models? Doesn't the incorporation of human intuition -- which at times\ncan be misleading -- in centaurs' decision-making process degrade its\nperformance compared to pure AI methods? This work aims to address these\nfundamental questions, focusing on recent advancements in generative AI, and\nespecially in Large Language Models (LLMs), as a main case study to illustrate\ncentaurs' critical essentiality to future AI endeavors.",
      "tldr_zh": "本研究提出“centaurs”概念，即人类-算法混合模型，通过结合正式分析和人类直觉，实现优越的决策能力。论文主张，未来AI发展应优先采用centaurs，而非其他AI方法，以提升学习和推理过程的共生性。作者探讨了centaurs与传统人类参与方法的区别、最有效的创建策略、适用场景，以及是否会因人类直觉的潜在误导而降低性能。针对生成式AI，尤其是Large Language Models (LLMs)，该工作强调centaurs在未来AI应用中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "To Appear in SI: Future Shock, Harvard Data Science Review\n  (https://hdsr.mitpress.mit.edu/specialissue5)",
      "pdf_url": "http://arxiv.org/pdf/2406.10942v4",
      "published_date": "2024-06-16 13:44:41 UTC",
      "updated_date": "2024-12-16 05:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:46:56.057822"
    },
    {
      "arxiv_id": "2406.10940v2",
      "title": "Towards AI-Augmented Data Quality Management: From Data Quality for AI to AI for Data Quality Management",
      "title_zh": "翻译失败",
      "authors": [
        "Heidi Carolina Tamm",
        "Anastasija Nikiforova"
      ],
      "abstract": "In the contemporary data-driven landscape, ensuring data quality (DQ) is\ncrucial for deriving actionable insights from vast data repositories. The\nobjective of this study is to explore the potential for automating data quality\nmanagement within data warehouses as data repository commonly used by large\norganizations. By conducting a systematic review of existing DQ tools available\nin the market and academic literature, the study assesses their capability to\nautomatically detect and enforce data quality rules. The review encompassed 151\ntools from various sources, revealing that most current tools focus on data\ncleansing and fixing in domain-specific databases rather than data warehouses.\nOnly a limited number of tools, specifically ten, demonstrated the capability\nto detect DQ rules, not to mention implementing this in data warehouses. The\nfindings underscore a significant gap in the market and academic research\nregarding AI-augmented DQ rule detection in data warehouses. This paper\nadvocates for further development in this area to enhance the efficiency of DQ\nmanagement processes, reduce human workload, and lower costs. The study\nhighlights the necessity of advanced tools for automated DQ rule detection,\npaving the way for improved practices in data quality management tailored to\ndata warehouse environments. The study can guide organizations in selecting\ndata quality tool that would meet their requirements most.",
      "tldr_zh": "本研究探讨了利用 AI 增强数据质量 (DQ) 管理，特别是从数据质量用于 AI 到 AI 用于 DQ 管理的转变，重点关注数据仓库环境。研究通过系统审查市场和学术文献中的 151 个 DQ 工具，发现大多数工具仅专注于特定领域的数据库清洗和修复，而仅有 10 个工具具备检测 DQ 规则的能力，且在数据仓库中的应用有限。结果突显了 AI-augmented DQ 规则检测的显著空白，并倡导进一步开发先进工具，以提高 DQ 管理效率、减少人力工作量和降低成本，最终指导组织选择合适的 DQ 工具。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CE",
        "cs.ET"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10940v2",
      "published_date": "2024-06-16 13:43:04 UTC",
      "updated_date": "2025-03-29 18:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:47:07.782920"
    },
    {
      "arxiv_id": "2406.10937v2",
      "title": "Understanding Understanding: A Pragmatic Framework Motivated by Large Language Models",
      "title_zh": "理解理解：一个受大型语言模型启发的实用框架",
      "authors": [
        "Kevin Leyton-Brown",
        "Yoav Shoham"
      ],
      "abstract": "Motivated by the rapid ascent of Large Language Models (LLMs) and debates\nabout the extent to which they possess human-level qualities, we propose a\nframework for testing whether any agent (be it a machine or a human)\nunderstands a subject matter. In Turing-test fashion, the framework is based\nsolely on the agent's performance, and specifically on how well it answers\nquestions. Elements of the framework include circumscribing the set of\nquestions (the \"scope of understanding\"), requiring general competence\n(\"passing grade\"), avoiding \"ridiculous answers\", but still allowing wrong and\n\"I don't know\" answers to some questions. Reaching certainty about these\nconditions requires exhaustive testing of the questions which is impossible for\nnontrivial scopes, but we show how high confidence can be achieved via random\nsampling and the application of probabilistic confidence bounds. We also show\nthat accompanying answers with explanations can improve the sample complexity\nrequired to achieve acceptable bounds, because an explanation of an answer\nimplies the ability to answer many similar questions. According to our\nframework, current LLMs cannot be said to understand nontrivial domains, but as\nthe framework provides a practical recipe for testing understanding, it thus\nalso constitutes a tool for building AI agents that do understand.",
      "tldr_zh": "这篇论文受大型语言模型（LLMs）的快速发展启发，提出一个实用框架，用于测试任何代理（如机器或人类）是否理解特定主题，该框架基于代理回答问题的表现，类似于Turing-test。框架的关键元素包括定义问题集（理解范围）、要求一般能力（passing grade）、避免荒谬答案，并通过随机采样和概率置信区间（probabilistic confidence bounds）来实现高置信度评估；此外，提供答案解释可以降低样本复杂度，因为解释表明代理能处理类似问题。研究发现，当前LLMs无法理解非平凡领域，但该框架为构建真正理解的AI代理提供了实用工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10937v2",
      "published_date": "2024-06-16 13:37:08 UTC",
      "updated_date": "2024-06-19 08:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:47:22.505093"
    },
    {
      "arxiv_id": "2406.10932v3",
      "title": "Imperceptible Rhythm Backdoor Attacks: Exploring Rhythm Transformation for Embedding Undetectable Vulnerabilities on Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhan Yao",
        "Jiangkun Yang",
        "Yongqiang He",
        "Jia Liu",
        "Weiping Wen"
      ],
      "abstract": "Speech recognition is an essential start ring of human-computer interaction,\nand recently, deep learning models have achieved excellent success in this\ntask. However, when the model training and private data provider are always\nseparated, some security threats that make deep neural networks (DNNs) abnormal\ndeserve to be researched. In recent years, the typical backdoor attacks have\nbeen researched in speech recognition systems. The existing backdoor methods\nare based on data poisoning. The attacker adds some incorporated changes to\nbenign speech spectrograms or changes the speech components, such as pitch and\ntimbre. As a result, the poisoned data can be detected by human hearing or\nautomatic deep algorithms. To improve the stealthiness of data poisoning, we\npropose a non-neural and fast algorithm called Random Spectrogram Rhythm\nTransformation (RSRT) in this paper. The algorithm combines four steps to\ngenerate stealthy poisoned utterances. From the perspective of rhythm component\ntransformation, our proposed trigger stretches or squeezes the mel spectrograms\nand recovers them back to signals. The operation keeps timbre and content\nunchanged for good stealthiness. Our experiments are conducted on two kinds of\nspeech recognition tasks, including testing the stealthiness of poisoned\nsamples by speaker verification and automatic speech recognition. The results\nshow that our method has excellent effectiveness and stealthiness. The rhythm\ntrigger needs a low poisoning rate and gets a very high attack success rate.",
      "tldr_zh": "该论文探讨了语音识别系统中的后门攻击，提出了一种名为 Random Spectrogram Rhythm Transformation (RSRT) 的算法，通过拉伸或挤压 mel spectrograms 的节奏组件来嵌入不可检测的漏洞，同时保持语音的音色和内容不变，以提升攻击的隐蔽性。RSRT 算法采用非神经网络的快速方法，仅需四步即可生成隐秘的毒化语音，避免了传统数据毒化的可检测性。实验结果显示，该方法在语音识别任务中表现出色隐蔽性，仅需低毒性率即可实现高攻击成功率，并在说话者验证和自动语音识别测试中验证了其有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Neurocomputing",
      "pdf_url": "http://arxiv.org/pdf/2406.10932v3",
      "published_date": "2024-06-16 13:29:21 UTC",
      "updated_date": "2024-10-18 03:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:47:32.022737"
    },
    {
      "arxiv_id": "2406.10928v2",
      "title": "Make Your Home Safe: Time-aware Unsupervised User Behavior Anomaly Detection in Smart Homes via Loss-guided Mask",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Xiao",
        "Zhiyao Xu",
        "Qingsong Zou",
        "Qing Li",
        "Dan Zhao",
        "Dong Fang",
        "Ruoyu Li",
        "Wenxin Tang",
        "Kang Li",
        "Xudong Zuo",
        "Penghui Hu",
        "Yong Jiang",
        "Zixuan Weng",
        "Michael R. Lyv"
      ],
      "abstract": "Smart homes, powered by the Internet of Things, offer great convenience but\nalso pose security concerns due to abnormal behaviors, such as improper\noperations of users and potential attacks from malicious attackers. Several\nbehavior modeling methods have been proposed to identify abnormal behaviors and\nmitigate potential risks. However, their performance often falls short because\nthey do not effectively learn less frequent behaviors, consider temporal\ncontext, or account for the impact of noise in human behaviors. In this paper,\nwe propose SmartGuard, an autoencoder-based unsupervised user behavior anomaly\ndetection framework. First, we design a Loss-guided Dynamic Mask Strategy\n(LDMS) to encourage the model to learn less frequent behaviors, which are often\noverlooked during learning. Second, we propose a Three-level Time-aware\nPosition Embedding (TTPE) to incorporate temporal information into positional\nembedding to detect temporal context anomaly. Third, we propose a Noise-aware\nWeighted Reconstruction Loss (NWRL) that assigns different weights for routine\nbehaviors and noise behaviors to mitigate the interference of noise behaviors\nduring inference. Comprehensive experiments on three datasets with ten types of\nanomaly behaviors demonstrates that SmartGuard consistently outperforms\nstate-of-the-art baselines and also offers highly interpretable results.",
      "tldr_zh": "本研究针对智能家居中用户行为异常（如不当操作或恶意攻击）带来的安全风险，提出了一种基于 autoencoder 的无监督检测框架 SmartGuard，以解决现有方法在学习不频繁行为、忽略时间上下文和处理噪声方面的不足。框架的关键创新包括 Loss-guided Dynamic Mask Strategy (LDMS) 用于强化对不频繁行为的学习、Three-level Time-aware Position Embedding (TTPE) 用于整合时间信息检测异常，以及 Noise-aware Weighted Reconstruction Loss (NWRL) 用于减轻噪声干扰。实验在三个数据集上测试十种异常行为类型，结果显示 SmartGuard 显著优于现有基线模型，并提供高度可解释的结果。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10928v2",
      "published_date": "2024-06-16 13:23:21 UTC",
      "updated_date": "2024-06-18 11:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:47:44.313091"
    },
    {
      "arxiv_id": "2406.10922v1",
      "title": "Generating Tables from the Parametric Knowledge of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yevgeni Berkovitch",
        "Oren Glickman",
        "Amit Somech",
        "Tomer Wolfson"
      ],
      "abstract": "We explore generating factual and accurate tables from the parametric\nknowledge of large language models (LLMs). While LLMs have demonstrated\nimpressive capabilities in recreating knowledge bases and generating free-form\ntext, we focus on generating structured tabular data, which is crucial in\ndomains like finance and healthcare. We examine the table generation abilities\nof four state-of-the-art LLMs: GPT-3.5, GPT-4, Llama2-13B, and Llama2-70B,\nusing three prompting methods for table generation: (a) full-table, (b)\nrow-by-row; (c) cell-by-cell. For evaluation, we introduce a novel benchmark,\nWikiTabGen which contains 100 curated Wikipedia tables. Tables are further\nprocessed to ensure their factual correctness and manually annotated with short\nnatural language descriptions. Our findings reveal that table generation\nremains a challenge, with GPT-4 reaching the highest accuracy at 19.6%. Our\ndetailed analysis sheds light on how various table properties, such as size,\ntable popularity, and numerical content, influence generation performance. This\nwork highlights the unique challenges in LLM-based table generation and\nprovides a solid evaluation framework for future research. Our code, prompts\nand data are all publicly available:\nhttps://github.com/analysis-bots/WikiTabGen",
      "tldr_zh": "本研究探讨从大型语言模型 (LLMs) 的参数知识中生成事实准确的表格数据，这在金融和医疗等领域至关重要。研究者测试了 GPT-3.5、GPT-4、Llama2-13B 和 Llama2-70B 等四种先进模型，使用完整表格、逐行和逐单元格三种提示方法进行生成，并引入了新基准 WikiTabGen（包含100个精选的 Wikipedia 表格）来评估准确性。结果显示，表格生成仍面临挑战，GPT-4 的最高准确率仅为19.6%，且因素如表格大小、流行度和数字内容会影响性能。该工作提供了公开的代码和数据框架，促进未来 LLM-based 表格生成研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10922v1",
      "published_date": "2024-06-16 12:55:55 UTC",
      "updated_date": "2024-06-16 12:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:47:59.527312"
    },
    {
      "arxiv_id": "2406.10920v1",
      "title": "Hamilton-Jacobi Based Policy-Iteration via Deep Operator Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jae Yong Lee",
        "Yeoneung Kim"
      ],
      "abstract": "The framework of deep operator network (DeepONet) has been widely exploited\nthanks to its capability of solving high dimensional partial differential\nequations. In this paper, we incorporate DeepONet with a recently developed\npolicy iteration scheme to numerically solve optimal control problems and the\ncorresponding Hamilton--Jacobi--Bellman (HJB) equations. A notable feature of\nour approach is that once the neural network is trained, the solution to the\noptimal control problem and HJB equations with different terminal functions can\nbe inferred quickly thanks to the unique feature of operator learning.\nFurthermore, a quantitative analysis of the accuracy of the algorithm is\ncarried out via comparison principles of viscosity solutions. The effectiveness\nof the method is verified with various examples, including 10-dimensional\nlinear quadratic regulator problems (LQRs).",
      "tldr_zh": "这篇论文提出了一种基于 Hamilton-Jacobi 的政策迭代方法，通过 Deep Operator Network (DeepONet) 来数值求解最优控制问题和对应的 Hamilton--Jacobi--Bellman (HJB) 方程。方法的关键优势在于，训练好神经网络后，可快速推断不同终端函数下的解决方案，利用 operator learning 的特性提升效率。同时，通过 viscosity solutions 的比较原则进行定量准确性分析，并在包括 10 维线性二次调节器问题 (LQRs) 在内的各种例子中验证了方法的有效性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA",
        "68T20, 68U07, 35F21, 49L12, 49L25"
      ],
      "primary_category": "math.OC",
      "comment": "24 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10920v1",
      "published_date": "2024-06-16 12:53:17 UTC",
      "updated_date": "2024-06-16 12:53:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:48:11.946273"
    },
    {
      "arxiv_id": "2406.10918v5",
      "title": "Multi-LLM QA with Embodied Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Bhrij Patel",
        "Vishnu Sashank Dorbala",
        "Amrit Singh Bedi",
        "Dinesh Manocha"
      ],
      "abstract": "Large language models (LLMs) have grown in popularity due to their natural\nlanguage interface and pre trained knowledge, leading to rapidly increasing\nsuccess in question-answering (QA) tasks. More recently, multi-agent systems\nwith LLM-based agents (Multi-LLM) have been utilized increasingly more for QA.\nIn these scenarios, the models may each answer the question and reach a\nconsensus or each model is specialized to answer different domain questions.\nHowever, most prior work dealing with Multi-LLM QA has focused on scenarios\nwhere the models are asked in a zero-shot manner or are given information\nsources to extract the answer. For question answering of an unknown\nenvironment, embodied exploration of the environment is first needed to answer\nthe question. This skill is necessary for personalizing embodied AI to\nenvironments such as households. There is a lack of insight into whether a\nMulti-LLM system can handle question-answering based on observations from\nembodied exploration. In this work, we address this gap by investigating the\nuse of Multi-Embodied LLM Explorers (MELE) for QA in an unknown environment.\nMultiple LLM-based agents independently explore and then answer queries about a\nhousehold environment. We analyze different aggregation methods to generate a\nsingle, final answer for each query: debating, majority voting, and training a\ncentral answer module (CAM). Using CAM, we observe a $46\\%$ higher accuracy\ncompared against the other non-learning-based aggregation methods. We provide\ncode and the query dataset for further research.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在未知环境下的问答(QA) 任务，引入Multi-Embodied LLM Explorers (MELE) 系统，让多个LLM-based agents 通过embodied exploration 独立探索环境（如家庭）并回答查询。研究比较了三种答案聚合方法：debating、majority voting 和训练central answer module (CAM)，以生成最终答案。结果显示，使用CAM 的准确率比其他非学习方法提高了46%。论文还提供了代码和查询数据集，以促进相关研究的深入。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 9 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2406.10918v5",
      "published_date": "2024-06-16 12:46:40 UTC",
      "updated_date": "2024-10-18 12:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:48:25.268850"
    },
    {
      "arxiv_id": "2406.10893v1",
      "title": "Development and Validation of Fully Automatic Deep Learning-Based Algorithms for Immunohistochemistry Reporting of Invasive Breast Ductal Carcinoma",
      "title_zh": "翻译失败",
      "authors": [
        "Sumit Kumar Jha",
        "Purnendu Mishra",
        "Shubham Mathur",
        "Gursewak Singh",
        "Rajiv Kumar",
        "Kiran Aatre",
        "Suraj Rengarajan"
      ],
      "abstract": "Immunohistochemistry (IHC) analysis is a well-accepted and widely used method\nfor molecular subtyping, a procedure for prognosis and targeted therapy of\nbreast carcinoma, the most common type of tumor affecting women. There are four\nmolecular biomarkers namely progesterone receptor (PR), estrogen receptor (ER),\nantigen Ki67, and human epidermal growth factor receptor 2 (HER2) whose\nassessment is needed under IHC procedure to decide prognosis as well as\npredictors of response to therapy. However, IHC scoring is based on subjective\nmicroscopic examination of tumor morphology and suffers from poor\nreproducibility, high subjectivity, and often incorrect scoring in low-score\ncases. In this paper, we present, a deep learning-based semi-supervised\ntrained, fully automatic, decision support system (DSS) for IHC scoring of\ninvasive ductal carcinoma. Our system automatically detects the tumor region\nremoving artifacts and scores based on Allred standard. The system is developed\nusing 3 million pathologist-annotated image patches from 300 slides, fifty\nthousand in-house cell annotations, and forty thousand pixels marking of HER2\nmembrane. We have conducted multicentric trials at four centers with three\ndifferent types of digital scanners in terms of percentage agreement with\ndoctors. And achieved agreements of 95, 92, 88 and 82 percent for Ki67, HER2,\nER, and PR stain categories, respectively. In addition to overall accuracy, we\nfound that there is 5 percent of cases where pathologist have changed their\nscore in favor of algorithm score while reviewing with detailed algorithmic\nanalysis. Our approach could improve the accuracy of IHC scoring and subsequent\ntherapy decisions, particularly where specialist expertise is unavailable. Our\nsystem is highly modular. The proposed algorithm modules can be used to develop\nDSS for other cancer types.",
      "tldr_zh": "这篇论文开发了一个基于深度学习的完全自动决策支持系统 (DSS)，用于侵袭性乳腺导管癌的 Immunohistochemistry (IHC) 评分，以解决传统主观微观检查的再现性差和高主观性问题。系统采用半监督训练方法，利用300万病理学家标注图像补丁、5万内部细胞标注和4万HER2膜像素标记，自动检测肿瘤区域、去除伪影，并基于Allred standard进行PR、ER、Ki67和HER2生物标记物的评分。在多中心试验中，该系统与医生达成协议率分别为Ki67 95%、HER2 92%、ER 88%和PR 82%，并在5%的病例中促使病理学家调整评分。该方法提高了IHC评分的准确性，尤其在专家资源不足的地区，并可模块化扩展到其他癌症类型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.QM",
        "q-bio.TO"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10893v1",
      "published_date": "2024-06-16 10:52:38 UTC",
      "updated_date": "2024-06-16 10:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:48:38.810173"
    },
    {
      "arxiv_id": "2406.10890v1",
      "title": "RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoran Jin",
        "Pengfei Cao",
        "Chenhao Wang",
        "Zhitao He",
        "Hongbang Yuan",
        "Jiachun Li",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Large language models (LLMs) inevitably memorize sensitive, copyrighted, and\nharmful knowledge from the training corpus; therefore, it is crucial to erase\nthis knowledge from the models. Machine unlearning is a promising solution for\nefficiently removing specific knowledge by post hoc modifying models. In this\npaper, we propose a Real-World Knowledge Unlearning benchmark (RWKU) for LLM\nunlearning. RWKU is designed based on the following three key factors: (1) For\nthe task setting, we consider a more practical and challenging unlearning\nsetting, where neither the forget corpus nor the retain corpus is accessible.\n(2) For the knowledge source, we choose 200 real-world famous people as the\nunlearning targets and show that such popular knowledge is widely present in\nvarious LLMs. (3) For the evaluation framework, we design the forget set and\nthe retain set to evaluate the model's capabilities across various real-world\napplications. Regarding the forget set, we provide four four membership\ninference attack (MIA) methods and nine kinds of adversarial attack probes to\nrigorously test unlearning efficacy. Regarding the retain set, we assess\nlocality and utility in terms of neighbor perturbation, general ability,\nreasoning ability, truthfulness, factuality, and fluency. We conduct extensive\nexperiments across two unlearning scenarios, two models and six baseline\nmethods and obtain some meaningful findings. We release our benchmark and code\npublicly at http://rwku-bench.github.io for future work.",
      "tldr_zh": "本研究提出RWKU基准，用于评估大型语言模型(LLMs)中真实世界知识的删除效果，针对模型记忆敏感、版权和有害知识的问题。RWKU采用更实际的unlearning设置，其中无法访问forget corpus或retain corpus，并以200位名人知识作为删除目标，展示这些知识在各种LLMs中的广泛存在。评估框架包括forget set（使用四种membership inference attack (MIA)方法和九种adversarial attack probes测试删除效能）和retain set（评估邻域扰动、一般能力、推理能力、真实性、事实性和流畅性）。实验在两种unlearning场景、两种模型和六种基线方法上进行，揭示了有意义的发现，并公开了基准和代码以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "48 pages, 7 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.10890v1",
      "published_date": "2024-06-16 10:47:21 UTC",
      "updated_date": "2024-06-16 10:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:48:47.415878"
    },
    {
      "arxiv_id": "2406.10889v2",
      "title": "VELOCITI: Benchmarking Video-Language Compositional Reasoning with Strict Entailment",
      "title_zh": "VELOCITI：使用严格蕴涵对视频语言组合推理进行基准测试",
      "authors": [
        "Darshana Saravanan",
        "Varun Gupta",
        "Darshan Singh",
        "Zeeshan Khan",
        "Vineet Gandhi",
        "Makarand Tapaswi"
      ],
      "abstract": "A fundamental aspect of compositional reasoning in a video is associating\npeople and their actions across time. Recent years have seen great progress in\ngeneral-purpose vision or video models and a move towards long-video\nunderstanding. While exciting, we take a step back and ask: are current models\ngood at compositional reasoning on short videos? To this end, we introduce\nVELOCITI, a benchmark to study Video-LLMs by disentangling and assessing the\ncomprehension of agents, actions, and their associations across multiple\nevents. We adopt the Video-Language Entailment setup and propose StrictVLE that\nrequires correct classification (rather than ranking) of the positive and\nnegative caption. We evaluate several models and observe that even the best,\nLLaVA-OneVision (44.5%) and Gemini-1.5-Pro (49.3%), are far from human accuracy\nat 93.0%. Results show that action understanding lags behind agents, and\nnegative captions created using entities appearing in the video perform worse\nthan those obtained from pure text manipulation. We also present challenges\nwith ClassicVLE and multiple-choice (MC) evaluation, strengthening our\npreference for StrictVLE. Finally, we validate that our benchmark requires\nvisual inputs of multiple frames making it ideal to study video-language\ncompositional reasoning.",
      "tldr_zh": "该论文引入了 VELOCITI 基准，用于评估 Video-LLMs 在短视频组合推理方面的能力，特别是理解代理（agents）、动作（actions）及其关联。研究者提出了 StrictVLE 方法，通过要求正确分类正面和负面标题，而不是简单排名，来更严格地测试模型性能。实验结果显示，即使是表现最好的模型如 LLaVA-OneVision (44.5%) 和 Gemini-1.5-Pro (49.3%)，其准确率远低于人类的 93.0%，且动作理解明显落后于代理理解，同时使用视频中实体创建的负面标题效果更差。该基准强调了多帧视觉输入的必要性，为改进视频语言组合推理提供了关键挑战和评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025. Project Page, see\n  https://katha-ai.github.io/projects/velociti",
      "pdf_url": "http://arxiv.org/pdf/2406.10889v2",
      "published_date": "2024-06-16 10:42:21 UTC",
      "updated_date": "2025-03-30 14:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:49:00.368604"
    },
    {
      "arxiv_id": "2406.10878v1",
      "title": "Demonstration Notebook: Finding the Most Suited In-Context Learning Example from Interactions",
      "title_zh": "演示笔记本：从互动中找到最适合的上下文学习示例",
      "authors": [
        "Yiming Tang",
        "Bin Dong"
      ],
      "abstract": "Large language models (LLMs) benefit greatly from prompt engineering, with\nin-context learning standing as a pivital technique. While former approaches\nhave provided various ways to construct the demonstrations used for in-context\nlearning, they often ignore the inherent heterogeneity within datasets,\napplying the same demonstrations to all reasoning questions. We observed that\nthe effectiveness of demonstrations varies depending on the specific question.\nThis motivates our exploration of using prompt engineering to select\nappropriate demonstrations. To address the challenge of automatically creating\nand choosing demonstrations tailored to each question, we propose a novel\nprompt engineering workflow built around a novel object called the\n\"demonstration notebook.\" This notebook helps identify the most suitable\nin-context learning example for a question by gathering and reusing information\nfrom the LLM's past interactions. Our experiments show that this approach\noutperforms all existing methods for automatic demonstration construction and\nselection (as far as we know), achieving state-of-the-art results on serveral\nreasoning benchmarks. The method's versatility is further demonstrated by its\nsuccess in text summarization and prompt compression tasks. Additionally, we\ncontribute a rigorous analysis method to reveal the \"demonstrative regime\" of a\ndemonstration, providing valuable insights into how demonstrations relate to\ndifferent question types within a dataset.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的上下文学习（in-context learning），指出现有方法忽略了数据集的异质性，导致演示（demonstrations）无法针对特定问题优化。作者提出了一种新型提示工程工作流，使用“demonstration notebook”对象，通过收集和重用LLM的过去交互信息，自动创建并选择最适合的演示示例。实验结果显示，该方法在多个推理基准上超越现有技术，并成功应用于文本摘要和提示压缩任务；此外，研究还贡献了分析方法来揭示演示的“demonstrative regime”，即演示如何与不同问题类型相关联。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10878v1",
      "published_date": "2024-06-16 10:02:20 UTC",
      "updated_date": "2024-06-16 10:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:49:10.537024"
    },
    {
      "arxiv_id": "2406.10873v1",
      "title": "Optimizing Automatic Speech Assessment: W-RankSim Regularization and Hybrid Feature Fusion Strategies",
      "title_zh": "优化自动语音评估：W-RankSim 正则化和混合特征融合策略",
      "authors": [
        "Chung-Wen Wu",
        "Berlin Chen"
      ],
      "abstract": "Automatic Speech Assessment (ASA) has seen notable advancements with the\nutilization of self-supervised features (SSL) in recent research. However, a\nkey challenge in ASA lies in the imbalanced distribution of data, particularly\nevident in English test datasets. To address this challenge, we approach ASA as\nan ordinal classification task, introducing Weighted Vectors Ranking Similarity\n(W-RankSim) as a novel regularization technique. W-RankSim encourages closer\nproximity of weighted vectors in the output layer for similar classes, implying\nthat feature vectors with similar labels would be gradually nudged closer to\neach other as they converge towards corresponding weighted vectors. Extensive\nexperimental evaluations confirm the effectiveness of our approach in improving\nordinal classification performance for ASA. Furthermore, we propose a hybrid\nmodel that combines SSL and handcrafted features, showcasing how the inclusion\nof handcrafted features enhances performance in an ASA system.",
      "tldr_zh": "本文针对 Automatic Speech Assessment (ASA) 的数据分布不平衡问题（如英语测试数据集），将其视为 ordinal classification 任务，并引入 Weighted Vectors Ranking Similarity (W-RankSim) 作为新型正则化技术，以使相似类别的加权向量更接近，从而提升特征向量的聚类效果。实验评估证实，W-RankSim 显著提高了 ASA 的 ordinal classification 性能。此外，该研究提出一个混合模型，结合 self-supervised features (SSL) 和 handcrafted features，进一步增强了 ASA 系统的整体表现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10873v1",
      "published_date": "2024-06-16 09:55:21 UTC",
      "updated_date": "2024-06-16 09:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:49:22.953574"
    },
    {
      "arxiv_id": "2406.10858v2",
      "title": "Step-level Value Preference Optimization for Mathematical Reasoning",
      "title_zh": "针对数学推理的步骤级别价值偏好优化",
      "authors": [
        "Guoxin Chen",
        "Minpeng Liao",
        "Chengxi Li",
        "Kai Fan"
      ],
      "abstract": "Direct Preference Optimization (DPO) using an implicit reward model has\nproven to be an effective alternative to reinforcement learning from human\nfeedback (RLHF) for fine-tuning preference aligned large language models\n(LLMs). However, the overall preference annotations of responses do not fully\ncapture the fine-grained quality of model outputs in complex multi-step\nreasoning tasks, such as mathematical reasoning. To address this limitation, we\nintroduce a novel algorithm called Step-level Value Preference Optimization\n(SVPO). Our approach employs Monte Carlo Tree Search (MCTS) to automatically\nannotate step-level preferences for multi-step reasoning. Furthermore, from the\nperspective of learning-to-rank, we train an explicit value model to replicate\nthe behavior of the implicit reward model, complementing standard preference\noptimization. This value model enables the LLM to generate higher reward\nresponses with minimal cost during inference. Experimental results demonstrate\nthat our method achieves state-of-the-art performance on both in-domain and\nout-of-domain mathematical reasoning benchmarks. Our code is available at\n\\url{https://github.com/MARIO-Math-Reasoning/Super_MARIO}.",
      "tldr_zh": "本研究针对直接偏好优化(DPO)算法在多步推理任务（如数学推理）中的局限性，提出了一种新型算法Step-level Value Preference Optimization (SVPO)。SVPO利用Monte Carlo Tree Search (MCTS)自动注解多步推理中的步级偏好，并训练一个显式价值模型来模拟隐式奖励模型的行为，从而帮助大型语言模型(LLMs)在推理过程中生成更高奖励的响应，同时降低成本。实验结果显示，该方法在领域内和领域外数学推理基准上实现了最先进性能，为细粒度偏好优化提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera ready version for EMNLP2024-Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.10858v2",
      "published_date": "2024-06-16 09:06:17 UTC",
      "updated_date": "2024-09-27 08:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:49:34.926826"
    },
    {
      "arxiv_id": "2406.10855v1",
      "title": "ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model",
      "title_zh": "翻译失败",
      "authors": [
        "Song Zhang",
        "Qingzhong Wang",
        "Junyi Liu",
        "Haoyi Xiong"
      ],
      "abstract": "In the fast-growing field of Remote Sensing (RS) image analysis, the gap\nbetween massive unlabeled datasets and the ability to fully utilize these\ndatasets for advanced RS analytics presents a significant challenge. To fill\nthe gap, our work introduces an innovative auto-labeling framework named ALPS\n(Automatic Labeling for Pre-training in Segmentation), leveraging the Segment\nAnything Model (SAM) to predict precise pseudo-labels for RS images without\nnecessitating prior annotations or additional prompts. The proposed pipeline\nsignificantly reduces the labor and resource demands traditionally associated\nwith annotating RS datasets. By constructing two comprehensive pseudo-labeled\nRS datasets via ALPS for pre-training purposes, our approach enhances the\nperformance of downstream tasks across various benchmarks, including iSAID and\nISPRS Potsdam. Experiments demonstrate the effectiveness of our framework,\nshowcasing its ability to generalize well across multiple tasks even under the\nscarcity of extensively annotated datasets, offering a scalable solution to\nautomatic segmentation and annotation challenges in the field. In addition, the\nproposed a pipeline is flexible and can be applied to medical image\nsegmentation, remarkably boosting the performance. Note that ALPS utilizes\npre-trained SAM to semi-automatically annotate RS images without additional\nmanual annotations. Though every component in the pipeline has bee well\nexplored, integrating clustering algorithms with SAM and novel pseudo-label\nalignment significantly enhances RS segmentation, as an off-the-shelf tool for\npre-training data preparation. Our source code is available at:\nhttps://github.com/StriveZs/ALPS.",
      "tldr_zh": "该研究提出ALPS框架，一种基于Segment Anything Model (SAM)的自动标注和预训练方案，用于遥感 (RS) 图像分割任务。该框架无需先验标注或额外提示，通过SAM预测精确的伪标签，并结合聚类算法和伪标签对齐技术，构建了两个全面的伪标签RS数据集，从而提升下游任务（如iSAID和ISPRS Potsdam基准）的性能。实验结果显示，ALPS在数据标注稀缺的情况下表现出色，提高了模型的泛化能力，并可灵活应用于医疗图像分割领域，提供了一个可扩展的自动分割解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10855v1",
      "published_date": "2024-06-16 09:02:01 UTC",
      "updated_date": "2024-06-16 09:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:49:46.812292"
    },
    {
      "arxiv_id": "2406.10852v1",
      "title": "IG2: Integrated Gradient on Iterative Gradient Path for Feature Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Zhuo",
        "Zhiqiang Ge"
      ],
      "abstract": "Feature attribution explains Artificial Intelligence (AI) at the instance\nlevel by providing importance scores of input features' contributions to model\nprediction. Integrated Gradients (IG) is a prominent path attribution method\nfor deep neural networks, involving the integration of gradients along a path\nfrom the explained input (explicand) to a counterfactual instance (baseline).\nCurrent IG variants primarily focus on the gradient of explicand's output.\nHowever, our research indicates that the gradient of the counterfactual output\nsignificantly affects feature attribution as well. To achieve this, we propose\nIterative Gradient path Integrated Gradients (IG2), considering both gradients.\nIG2 incorporates the counterfactual gradient iteratively into the integration\npath, generating a novel path (GradPath) and a novel baseline (GradCF). These\ntwo novel IG components effectively address the issues of attribution noise and\narbitrary baseline choice in earlier IG methods. IG2, as a path method,\nsatisfies many desirable axioms, which are theoretically justified in the\npaper. Experimental results on XAI benchmark, ImageNet, MNIST, TREC questions\nanswering, wafer-map failure patterns, and CelebA face attributes validate that\nIG2 delivers superior feature attributions compared to the state-of-the-art\ntechniques. The code is released at: https://github.com/JoeZhuo-ZY/IG2.",
      "tldr_zh": "该论文提出 IG2，一种改进的 Integrated Gradients (IG) 方法，用于增强特征归因解释 AI 模型预测。IG2 通过迭代地将 counterfactual 输出梯度融入积分路径，生成新的 GradPath 和 GradCF，从而解决了现有 IG 方法中的 attribution noise 和 arbitrary baseline choice 问题，并满足多项 desirable axioms 的理论要求。实验在 XAI benchmark、ImageNet、MNIST、TREC 问答、wafer-map 故障模式和 CelebA 面部属性数据集上验证，IG2 比 state-of-the-art 技术提供更优的特征归因准确性。代码已在 GitHub 公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "in IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10852v1",
      "published_date": "2024-06-16 08:48:03 UTC",
      "updated_date": "2024-06-16 08:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:50:02.846456"
    },
    {
      "arxiv_id": "2406.10847v2",
      "title": "TorchOpera: A Compound AI System for LLM Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Shanshan Han",
        "Zijian Hu",
        "Alay Dilipbhai Shah",
        "Han Jin",
        "Yuhang Yao",
        "Dimitris Stripelis",
        "Zhaozhuo Xu",
        "Chaoyang He"
      ],
      "abstract": "We introduce TorchOpera, a compound AI system for enhancing the safety and\nquality of prompts and responses for Large Language Models. TorchOpera ensures\nthat all user prompts are safe, contextually grounded, and effectively\nprocessed, while enhancing LLM responses to be relevant and high quality.\nTorchOpera utilizes the vector database for contextual grounding, rule-based\nwrappers for flexible modifications, and specialized mechanisms for detecting\nand adjusting unsafe or incorrect content. We also provide a view of the\ncompound AI system to reduce the computational cost. Extensive experiments show\nthat TorchOpera ensures the safety, reliability, and applicability of LLMs in\nreal-world settings while maintaining the efficiency of LLM responses.",
      "tldr_zh": "本研究引入了 TorchOpera，一种复合 AI 系统，旨在提升大型语言模型 (LLMs) 的提示和响应安全及质量，确保用户提示安全、基于上下文并有效处理，同时使响应更相关和高质。系统利用向量数据库 (vector database) 进行上下文 grounding、基于规则的包装器 (rule-based wrappers) 进行灵活修改，以及专门机制 (specialized mechanisms) 检测和调整不安全或不正确内容，同时提供视图以降低计算成本。实验结果表明，TorchOpera 在实际场景中显著提高了 LLMs 的安全、可靠性和适用性，同时保持响应效率。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10847v2",
      "published_date": "2024-06-16 08:39:19 UTC",
      "updated_date": "2024-10-27 07:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:50:12.371765"
    },
    {
      "arxiv_id": "2406.10842v1",
      "title": "Large Language Models for Automatic Milestone Detection in Group Discussions",
      "title_zh": "大语言模型在团体讨论中的自动里程碑检测",
      "authors": [
        "Zhuoxu Duan",
        "Zhengye Yang",
        "Samuel Westby",
        "Christoph Riedl",
        "Brooke Foucault Welles",
        "Richard J. Radke"
      ],
      "abstract": "Large language models like GPT have proven widely successful on natural\nlanguage understanding tasks based on written text documents. In this paper, we\ninvestigate an LLM's performance on recordings of a group oral communication\ntask in which utterances are often truncated or not well-formed. We propose a\nnew group task experiment involving a puzzle with several milestones that can\nbe achieved in any order. We investigate methods for processing transcripts to\ndetect if, when, and by whom a milestone has been completed. We demonstrate\nthat iteratively prompting GPT with transcription chunks outperforms semantic\nsimilarity search methods using text embeddings, and further discuss the\nquality and randomness of GPT responses under different context window sizes.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）如 GPT 在处理群组口头讨论中的里程碑自动检测性能，这些讨论常涉及不完整或不规范的表述。研究者设计了一个新实验，涉及一个可任意顺序完成的谜题任务，并比较了迭代提示 GPT 处理转录片段的方法与基于文本嵌入的语义相似性搜索方法。结果显示，迭代提示方法在检测里程碑的时机、地点和参与者方面表现更优，并分析了不同上下文窗口大小对 GPT 响应质量和随机性的影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10842v1",
      "published_date": "2024-06-16 08:32:22 UTC",
      "updated_date": "2024-06-16 08:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:50:24.254013"
    },
    {
      "arxiv_id": "2406.11906v2",
      "title": "NovoBench: Benchmarking Deep Learning-based De Novo Peptide Sequencing Methods in Proteomics",
      "title_zh": "翻译失败",
      "authors": [
        "Jingbo Zhou",
        "Shaorong Chen",
        "Jun Xia",
        "Sizhe Liu",
        "Tianze Ling",
        "Wenjie Du",
        "Yue Liu",
        "Jianwei Yin",
        "Stan Z. Li"
      ],
      "abstract": "Tandem mass spectrometry has played a pivotal role in advancing proteomics,\nenabling the high-throughput analysis of protein composition in biological\ntissues. Many deep learning methods have been developed for \\emph{de novo}\npeptide sequencing task, i.e., predicting the peptide sequence for the observed\nmass spectrum. However, two key challenges seriously hinder the further\nadvancement of this important task. Firstly, since there is no consensus for\nthe evaluation datasets, the empirical results in different research papers are\noften not comparable, leading to unfair comparison. Secondly, the current\nmethods are usually limited to amino acid-level or peptide-level precision and\nrecall metrics. In this work, we present the first unified benchmark NovoBench\nfor \\emph{de novo} peptide sequencing, which comprises diverse mass spectrum\ndata, integrated models, and comprehensive evaluation metrics. Recent\nimpressive methods, including DeepNovo, PointNovo, Casanovo, InstaNovo, AdaNovo\nand $\\pi$-HelixNovo are integrated into our framework. In addition to amino\nacid-level and peptide-level precision and recall, we evaluate the models'\nperformance in terms of identifying post-tranlational modifications (PTMs),\nefficiency and robustness to peptide length, noise peaks and missing fragment\nratio, which are important influencing factors while seldom be considered.\nLeveraging this benchmark, we conduct a large-scale study of current methods,\nreport many insightful findings that open up new possibilities for future\ndevelopment.",
      "tldr_zh": "该研究针对深度学习在蛋白质组学中的 de novo 肽序列预测任务，指出现有方法面临数据集不一致和评估指标有限的挑战。作者提出首个统一基准 NovoBench，包括多样化的质谱数据、集成模型（如 DeepNovo、PointNovo 和 Casanovo 等）以及全面评估指标。NovoBench 不仅评估氨基酸级和肽级的精度与召回率，还考察了识别翻译后修饰 (PTMs)、效率以及对肽长度、噪声峰和缺失碎片比例的鲁棒性。通过大规模实验，该基准揭示了许多关键洞见，为未来 de novo 肽序列方法的发展提供了新方向。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "NeurIPS 2024 D&B track",
      "pdf_url": "http://arxiv.org/pdf/2406.11906v2",
      "published_date": "2024-06-16 08:23:21 UTC",
      "updated_date": "2024-10-31 08:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:50:36.851713"
    },
    {
      "arxiv_id": "2406.10840v3",
      "title": "CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Haitao Lin",
        "Guojiang Zhao",
        "Odin Zhang",
        "Yufei Huang",
        "Lirong Wu",
        "Zicheng Liu",
        "Siyuan Li",
        "Cheng Tan",
        "Zhifeng Gao",
        "Stan Z. Li"
      ],
      "abstract": "Structure-based drug design (SBDD) aims to generate potential drugs that can\nbind to a target protein and is greatly expedited by the aid of AI techniques\nin generative models. However, a lack of systematic understanding persists due\nto the diverse settings, complex implementation, difficult reproducibility, and\ntask singularity. Firstly, the absence of standardization can lead to unfair\ncomparisons and inconclusive insights. To address this dilemma, we propose\nCBGBench, a comprehensive benchmark for SBDD, that unifies the task as a\ngenerative heterogeneous graph completion, analogous to fill-in-the-blank of\nthe 3D complex binding graph. By categorizing existing methods based on their\nattributes, CBGBench facilitates a modular and extensible framework that\nimplements various cutting-edge methods. Secondly, a single task on \\textit{de\nnovo} molecule generation can hardly reflect their capabilities. To broaden the\nscope, we have adapted these models to a range of tasks essential in drug\ndesign, which are considered sub-tasks within the graph fill-in-the-blank\ntasks. These tasks include the generative designation of \\textit{de novo}\nmolecules, linkers, fragments, scaffolds, and sidechains, all conditioned on\nthe structures of protein pockets. Our evaluations are conducted with fairness,\nencompassing comprehensive perspectives on interaction, chemical properties,\ngeometry authenticity, and substructure validity. We further provide the\npre-trained versions of the state-of-the-art models and deep insights with\nanalysis from empirical studies. The codebase for CBGBench is publicly\naccessible at \\url{https://github.com/Edapinenut/CBGBench}.",
      "tldr_zh": "该研究提出 CBGBench，一个用于结构基础药物设计 (SBDD) 的综合基准，旨在解决现有方法缺乏标准化和任务单一的问题，将 SBDD 任务统一为生成异构图完成任务，类似于填充 3D 蛋白-分子复合物结合图的空白。CBGBench 通过分类现有方法并构建模块化框架，扩展了任务范围，包括生成 de novo 分子、连接器、片段、支架和侧链等子任务，这些均基于蛋白口袋结构进行条件生成。评估采用公平的多角度方法，涵盖交互、化学属性、几何真实性和子结构有效性，并提供预训练的最新模型、经验分析以及公开代码库（https://github.com/Edapinenut/CBGBench）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages main context",
      "pdf_url": "http://arxiv.org/pdf/2406.10840v3",
      "published_date": "2024-06-16 08:20:24 UTC",
      "updated_date": "2024-10-10 11:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:50:52.062938"
    },
    {
      "arxiv_id": "2406.10834v1",
      "title": "Exposing the Achilles' Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Joykirat Singh",
        "Akshay Nambi",
        "Vibhav Vineet"
      ],
      "abstract": "Large Language Models (LLMs) have been applied to Math Word Problems (MWPs)\nwith transformative impacts, revolutionizing how these complex problems are\napproached and solved in various domains including educational settings.\nHowever, the evaluation of these models often prioritizes final accuracy,\noverlooking the crucial aspect of reasoning capabilities. This work addresses\nthis gap by focusing on the ability of LLMs to detect and correct reasoning\nmistakes. We introduce a novel dataset MWP-MISTAKE, incorporating MWPs with\nboth correct and incorrect reasoning steps generated through rule-based methods\nand smaller language models. Our comprehensive benchmarking reveals significant\ninsights into the strengths and weaknesses of state-of-the-art models, such as\nGPT-4o, GPT-4, GPT-3.5Turbo, and others. We highlight GPT-$o's superior\nperformance in mistake detection and rectification and the persistent\nchallenges faced by smaller models. Additionally, we identify issues related to\ndata contamination and memorization, impacting the reliability of LLMs in\nreal-world applications. Our findings emphasize the importance of rigorous\nevaluation of reasoning processes and propose future directions to enhance the\ngeneralization and robustness of LLMs in mathematical problem-solving.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在处理数学文字问题 (MWPs) 时检测和纠正推理错误的能力，揭示了当前评估方法过度关注最终准确率而忽略推理过程的缺陷。研究者引入了新数据集 MWP-MISTAKE，通过规则-based 方法和较小语言模型生成包含正确和错误推理步骤的样本，并对 GPT-4o、GPT-4 和 GPT-3.5Turbo 等模型进行了全面基准测试。结果显示，GPT-4o 在错误检测和修正方面表现出色，而较小模型面临显著挑战，并暴露了数据污染和记忆化问题影响模型可靠性的风险。该研究强调了强化推理过程评估的重要性，并为提升 LLMs 在数学问题解决中的泛化和鲁棒性提出未来改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10834v1",
      "published_date": "2024-06-16 08:06:05 UTC",
      "updated_date": "2024-06-16 08:06:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:51:01.633033"
    },
    {
      "arxiv_id": "2406.10831v1",
      "title": "Design and Optimization of Hierarchical Gradient Coding for Distributed Learning at Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Weiheng Tang",
        "Jingyi Li",
        "Lin Chen",
        "Xu Chen"
      ],
      "abstract": "Edge computing has recently emerged as a promising paradigm to boost the\nperformance of distributed learning by leveraging the distributed resources at\nedge nodes. Architecturally, the introduction of edge nodes adds an additional\nintermediate layer between the master and workers in the original distributed\nlearning systems, potentially leading to more severe straggler effect.\nRecently, coding theory-based approaches have been proposed for stragglers\nmitigation in distributed learning, but the majority focus on the conventional\nworkers-master architecture. In this paper, along a different line, we\ninvestigate the problem of mitigating the straggler effect in hierarchical\ndistributed learning systems with an additional layer composed of edge nodes.\nTechnically, we first derive the fundamental trade-off between the\ncomputational loads of workers and the stragglers tolerance. Then, we propose a\nhierarchical gradient coding framework, which provides better stragglers\nmitigation, to achieve the derived computational trade-off. To further improve\nthe performance of our framework in heterogeneous scenarios, we formulate an\noptimization problem with the objective of minimizing the expected execution\ntime for each iteration in the learning process. We develop an efficient\nalgorithm to mathematically solve the problem by outputting the optimum\nstrategy. Extensive simulation results demonstrate the superiority of our\nschemes compared with conventional solutions.",
      "tldr_zh": "这篇论文针对边缘设备分布式学习中的 straggler effect 问题，设计了层次化梯度编码框架，以缓解引入边缘节点后导致的系统延迟。作者首先推导了工作者计算负载与 straggler 容忍度之间的基本权衡，并通过该框架实现更好的 straggler 缓解。针对异构场景，他们制定了最小化迭代预期执行时间的优化问题，并开发了高效算法来求解；模拟结果表明，该方案比传统方法表现出色。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NI",
      "comment": "The paper has been accepted by IEEE Transactions on Communications",
      "pdf_url": "http://arxiv.org/pdf/2406.10831v1",
      "published_date": "2024-06-16 07:52:12 UTC",
      "updated_date": "2024-06-16 07:52:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:51:14.949715"
    },
    {
      "arxiv_id": "2406.10827v1",
      "title": "Algorithm Selection for Optimal Multi-Agent Path Finding via Graph Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Carmel Shabalin",
        "Omri Kaduri",
        "Roni Stern"
      ],
      "abstract": "Multi-agent path finding (MAPF) is the problem of finding paths for multiple\nagents such that they do not collide. This problem manifests in numerous\nreal-world applications such as controlling transportation robots in automated\nwarehouses, moving characters in video games, and coordinating self-driving\ncars in intersections. Finding optimal solutions to MAPF is NP-Hard, yet modern\noptimal solvers can scale to hundreds of agents and even thousands in some\ncases. Different solvers employ different approaches, and there is no single\nstate-of-the-art approach for all problems. Furthermore, there are no clear,\nprovable, guidelines for choosing when each optimal MAPF solver to use. Prior\nwork employed Algorithm Selection (AS) techniques to learn such guidelines from\npast data. A major challenge when employing AS for choosing an optimal MAPF\nalgorithm is how to encode the given MAPF problem. Prior work either used\nhand-crafted features or an image representation of the problem. We explore\ngraph-based encodings of the MAPF problem and show how they can be used\non-the-fly with a modern graph embedding algorithm called FEATHER. Then, we\nshow how this encoding can be effectively joined with existing encodings,\nresulting in a novel AS method we call MAPF Algorithm selection via Graph\nembedding (MAG). An extensive experimental evaluation of MAG on several MAPF\nalgorithm selection tasks reveals that it is either on-par or significantly\nbetter than existing methods.",
      "tldr_zh": "本研究针对多智能体路径寻找(Multi-Agent Path Finding, MAPF)问题，提出了一种基于图嵌入(Graph Embedding)的算法选择(Algorithm Selection, AS)方法，以优化多个代理的无碰撞路径规划。该方法使用现代图嵌入算法FEATHER对MAPF问题进行图-based编码，并将其与现有编码相结合，形成了新型AS框架MAG，以从历史数据中学习最佳算法选择指导。实验结果显示，MAG在多个MAPF算法选择任务上与现有方法相当或显著优越，证明了其有效性。",
      "categories": [
        "cs.AI",
        "68T20",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10827v1",
      "published_date": "2024-06-16 07:41:58 UTC",
      "updated_date": "2024-06-16 07:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:51:24.686773"
    },
    {
      "arxiv_id": "2406.10819v2",
      "title": "GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Dongping Chen",
        "Yue Huang",
        "Siyuan Wu",
        "Jingyu Tang",
        "Liuyi Chen",
        "Yilin Bai",
        "Zhigang He",
        "Chenlong Wang",
        "Huichi Zhou",
        "Yiqiang Li",
        "Tianshuo Zhou",
        "Yue Yu",
        "Chujie Gao",
        "Qihui Zhang",
        "Yi Gui",
        "Zhen Li",
        "Yao Wan",
        "Pan Zhou",
        "Jianfeng Gao",
        "Lichao Sun"
      ],
      "abstract": "Recently, Multimodal Large Language Models (MLLMs) have been used as agents\nto control keyboard and mouse inputs by directly perceiving the Graphical User\nInterface (GUI) and generating corresponding commands. However, current agents\nprimarily demonstrate strong understanding capabilities in static environments\nand are mainly applied to relatively simple domains, such as Web or mobile\ninterfaces. We argue that a robust GUI agent should be capable of perceiving\ntemporal information on the GUI, including dynamic Web content and multi-step\ntasks. Additionally, it should possess a comprehensive understanding of various\nGUI scenarios, including desktop software and multi-window interactions. To\nthis end, this paper introduces a new dataset, termed GUI-World, which features\nmeticulously crafted Human-MLLM annotations, extensively covering six GUI\nscenarios and eight types of GUI-oriented questions in three formats. We\nevaluate the capabilities of current state-of-the-art MLLMs, including Image\nLLMs and Video LLMs, in understanding various types of GUI content, especially\ndynamic and sequential content. Our findings reveal that current models\nstruggle with dynamic GUI content without manually annotated keyframes or\noperation history. On the other hand, Video LLMs fall short in all GUI-oriented\ntasks given the sparse GUI video dataset. Therefore, we take the initial step\nof leveraging a fine-tuned Video LLM, GUI-Vid, as a GUI-oriented assistant,\ndemonstrating an improved understanding of various GUI tasks. However, due to\nthe limitations in the performance of base LLMs, we conclude that using video\nLLMs as GUI agents remains a significant challenge. We believe our work\nprovides valuable insights for future research in dynamic GUI content\nunderstanding. All the dataset and code are publicly available at:\nhttps://gui-world.github.io.",
      "tldr_zh": "这篇论文引入了 GUI-World 数据集和视频基准，用于评估多模态大语言模型 (MLLMs) 在图形用户界面 (GUI) 理解方面的能力，涵盖六种 GUI 场景、八种问题类型和三种格式，包括动态内容和多步骤任务。研究发现，当前先进的图像 LLMs 和视频 LLMs 在处理动态 GUI 内容时表现不佳，尤其缺乏关键帧或操作历史支持。作者通过微调视频 LLM 开发了 GUI-Vid 模型，展示了改进的 GUI 任务理解，但强调使用视频 LLMs 作为 GUI 代理仍面临重大挑战，并公开提供了数据集和代码以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.10819v2",
      "published_date": "2024-06-16 06:56:53 UTC",
      "updated_date": "2025-03-24 11:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:51:40.840294"
    },
    {
      "arxiv_id": "2406.10816v1",
      "title": "Optimization of Armv9 architecture general large language model inference performance based on Llama.cpp",
      "title_zh": "翻译失败",
      "authors": [
        "Longhao Chen",
        "Yina Zhao",
        "Qiangjun Xie",
        "Qinghua Sheng"
      ],
      "abstract": "This article optimizes the inference performance of the Qwen-1.8B model by\nperforming Int8 quantization, vectorizing some operators in llama.cpp, and\nmodifying the compilation script to improve the compiler optimization level. On\nthe Yitian 710 experimental platform, the prefill performance is increased by\n1.6 times, the decoding performance is increased by 24 times, the memory usage\nis reduced to 1/5 of the original, and the accuracy loss is almost negligible.",
      "tldr_zh": "本研究基于 Llama.cpp 优化了 Armv9 架构上大语言模型的推理性能，主要通过 Int8 量化、向量化某些操作符以及修改编译脚本以提升编译器优化级别。针对 Qwen-1.8B 模型，在 Yitian 710 实验平台上，该优化使 prefill 性能提高 1.6 倍、decoding 性能提高 24 倍，并将内存使用量减少到原来的 1/5，同时准确性损失几乎可以忽略不计。整体改进为大语言模型在特定硬件上的高效部署提供了实用方案。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.AR",
        "cs.PF"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10816v1",
      "published_date": "2024-06-16 06:46:25 UTC",
      "updated_date": "2024-06-16 06:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:51:49.853135"
    },
    {
      "arxiv_id": "2406.10815v1",
      "title": "On the Effectiveness of Supervision in Asymmetric Non-Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongheon Oh",
        "Kibok Lee"
      ],
      "abstract": "Supervised contrastive representation learning has been shown to be effective\nin various transfer learning scenarios. However, while asymmetric\nnon-contrastive learning (ANCL) often outperforms its contrastive learning\ncounterpart in self-supervised representation learning, the extension of ANCL\nto supervised scenarios is less explored. To bridge the gap, we study ANCL for\nsupervised representation learning, coined SupSiam and SupBYOL, leveraging\nlabels in ANCL to achieve better representations. The proposed supervised ANCL\nframework improves representation learning while avoiding collapse. Our\nanalysis reveals that providing supervision to ANCL reduces intra-class\nvariance, and the contribution of supervision should be adjusted to achieve the\nbest performance. Experiments demonstrate the superiority of supervised ANCL\nacross various datasets and tasks. The code is available at:\nhttps://github.com/JH-Oh-23/Sup-ANCL.",
      "tldr_zh": "该论文探讨了在监督场景下Asymmetric Non-Contrastive Learning (ANCL)的有效性，提出SupSiam和SupBYOL等方法，将标签整合到ANCL框架中以提升表示学习质量。研究发现，监督机制能减少类内方差并避免表示学习的崩溃问题，但需调整监督贡献以实现最佳性能。实验结果表明，该监督ANCL方法在多种数据集和任务上优于传统对比学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10815v1",
      "published_date": "2024-06-16 06:43:15 UTC",
      "updated_date": "2024-06-16 06:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:52:03.466914"
    },
    {
      "arxiv_id": "2406.10811v1",
      "title": "LLMFactor: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Meiyun Wang",
        "Kiyoshi Izumi",
        "Hiroki Sakaji"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have attracted significant attention\nfor their exceptional performance across a broad range of tasks, particularly\nin text analysis. However, the finance sector presents a distinct challenge due\nto its dependence on time-series data for complex forecasting tasks. In this\nstudy, we introduce a novel framework called LLMFactor, which employs\nSequential Knowledge-Guided Prompting (SKGP) to identify factors that influence\nstock movements using LLMs. Unlike previous methods that relied on keyphrases\nor sentiment analysis, this approach focuses on extracting factors more\ndirectly related to stock market dynamics, providing clear explanations for\ncomplex temporal changes. Our framework directs the LLMs to create background\nknowledge through a fill-in-the-blank strategy and then discerns potential\nfactors affecting stock prices from related news. Guided by background\nknowledge and identified factors, we leverage historical stock prices in\ntextual format to predict stock movement. An extensive evaluation of the\nLLMFactor framework across four benchmark datasets from both the U.S. and\nChinese stock markets demonstrates its superiority over existing\nstate-of-the-art methods and its effectiveness in financial time-series\nforecasting.",
      "tldr_zh": "本文提出 LLMFactor 框架，利用 Sequential Knowledge-Guided Prompting (SKGP) 通过提示提取与股票动态直接相关的盈利因素，实现可解释的股票运动预测。不同于以往依赖关键词或情感分析的方法，该框架引导 LLMs 通过填空策略创建背景知识，从相关新闻中辨别影响股价的潜在因素，并结合历史股票价格的文本格式进行预测。在四个基准数据集（包括美股和A股）上的广泛评估显示，LLMFactor 优于现有最先进方法，提升了金融时间序列预测的准确性和解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL(Findings)2024",
      "pdf_url": "http://arxiv.org/pdf/2406.10811v1",
      "published_date": "2024-06-16 06:20:50 UTC",
      "updated_date": "2024-06-16 06:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:52:16.604013"
    },
    {
      "arxiv_id": "2406.10809v1",
      "title": "Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonna Jang",
        "Suhyune Son",
        "Jeongwoo Lee",
        "Junyoung Son",
        "Yuna Hur",
        "Jungwoo Lim",
        "Hyeonseok Moon",
        "Kisu Yang",
        "Heuiseok Lim"
      ],
      "abstract": "Despite the striking advances in recent language generation performance,\nmodel-generated responses have suffered from the chronic problem of\nhallucinations that are either untrue or unfaithful to a given source.\nEspecially in the task of knowledge grounded conversation, the models are\nrequired to generate informative responses, but hallucinated utterances lead to\nmiscommunication. In particular, entity-level hallucination that causes\ncritical misinformation and undesirable conversation is one of the major\nconcerns. To address this issue, we propose a post-hoc refinement method called\nREM. It aims to enhance the quality and faithfulness of hallucinated utterances\nby refining them based on the source knowledge. If the generated utterance has\na low source-faithfulness score with the given knowledge, REM mines the key\nentities in the knowledge and implicitly uses them for refining the utterances.\nWe verify that our method reduces entity hallucination in the utterance. Also,\nwe show the adaptability and efficacy of REM with extensive experiments and\ngenerative results. Our code is available at https://github.com/YOONNAJANG/REM.",
      "tldr_zh": "该研究针对知识基础对话中语言生成模型的实体级幻觉问题（如 entity-level hallucination），提出了一种后处理方法Post-hoc Utterance Refining Method（REM）。REM 通过评估生成的对话与源知识的忠实度（source-faithfulness score），如果得分较低，则挖掘知识中的关键实体并隐式用于改进对话内容，从而提升对话的质量和真实性。实验结果显示，该方法显著减少了实体幻觉，并在广泛测试中证明了其适应性和有效性，相关代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2023",
      "pdf_url": "http://arxiv.org/pdf/2406.10809v1",
      "published_date": "2024-06-16 06:12:47 UTC",
      "updated_date": "2024-06-16 06:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:52:26.890960"
    },
    {
      "arxiv_id": "2406.10807v2",
      "title": "Bayesian Networks and Machine Learning for COVID-19 Severity Explanation and Demographic Symptom Classification",
      "title_zh": "贝叶斯网络和机器学习用于 COVID-19 严重程度解释及人口统计学症状分类",
      "authors": [
        "Oluwaseun T. Ajayi",
        "Yu Cheng"
      ],
      "abstract": "With the prevailing efforts to combat the coronavirus disease 2019 (COVID-19)\npandemic, there are still uncertainties that are yet to be discovered about its\nspread, future impact, and resurgence. In this paper, we present a three-stage\ndata-driven approach to distill the hidden information about COVID-19. The\nfirst stage employs a Bayesian network structure learning method to identify\nthe causal relationships among COVID-19 symptoms and their intrinsic\ndemographic variables. As a second stage, the output from the Bayesian network\nstructure learning, serves as a useful guide to train an unsupervised machine\nlearning (ML) algorithm that uncovers the similarities in patients' symptoms\nthrough clustering. The final stage then leverages the labels obtained from\nclustering to train a demographic symptom identification (DSID) model which\npredicts a patient's symptom class and the corresponding demographic\nprobability distribution. We applied our method on the COVID-19 dataset\nobtained from the Centers for Disease Control and Prevention (CDC) in the\nUnited States. Results from the experiments show a testing accuracy of 99.99%,\nas against the 41.15% accuracy of a heuristic ML method. This strongly reveals\nthe viability of our Bayesian network and ML approach in understanding the\nrelationship between the virus symptoms, and providing insights on patients'\nstratification towards reducing the severity of the virus.",
      "tldr_zh": "该研究提出了一种三阶段数据驱动方法，利用 Bayesian networks 结构学习来识别 COVID-19 症状与人口统计变量之间的因果关系。接着，通过 unsupervised machine learning 算法（如聚类）分析患者症状的相似性，并基于聚类结果训练 demographic symptom identification (DSID) 模型，以预测患者的症状类别和相应的人口统计概率分布。在美国 CDC 的 COVID-19 数据集上实验，该方法实现了 99.99% 的测试准确率，远超 heuristic ML 方法的 41.15%，为理解病毒症状关系和患者分层提供重要见解，从而有助于降低疫情严重性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10807v2",
      "published_date": "2024-06-16 05:43:24 UTC",
      "updated_date": "2024-06-18 02:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:52:40.175681"
    },
    {
      "arxiv_id": "2406.10806v2",
      "title": "ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language",
      "title_zh": "翻译失败",
      "authors": [
        "Marcos Piau",
        "Roberto Lotufo",
        "Rodrigo Nogueira"
      ],
      "abstract": "Despite advancements in Natural Language Processing (NLP) and the growing\navailability of pretrained models, the English language remains the primary\nfocus of model development. Continued pretraining on language-specific corpora\nprovides a practical solution for adapting models to other languages. However,\nthe impact of different pretraining settings on downstream tasks remains\nunderexplored. This work introduces $\\texttt{ptt5-v2}$, investigating the\ncontinued pretraining of T5 models for Portuguese. We first develop a baseline\nset of settings and pretrain models with sizes up to 3B parameters. Finetuning\non three Portuguese downstream tasks (assin2 STS, assin2 RTE, and TweetSentBR)\nyields SOTA results on the latter two. We then explore the effects of different\npretraining configurations, including pretraining data quality, optimization\nstrategies, and multi-epoch pretraining. Perhaps surprisingly, their impact\nremains subtle compared to our baseline. We release $\\texttt{ptt5-v2}$\npretrained checkpoints and their MonoT5-based finetuned $\\texttt{MonoPTT5}$\nrerankers on HuggingFace in their respective collections at\n\\url{https://huggingface.co/unicamp-dl}.",
      "tldr_zh": "本研究介绍了 ptt5-v2，一种针对葡萄牙语的 T5 模型持续预训练方法，以解决 NLP 模型主要聚焦英语的问题。研究者开发了基线预训练设置，并训练了不同规模的模型（最高达 3B 参数），在 assin2 STS、assin2 RTE 和 TweetSentBR 等下游任务上进行微调，取得了 assin2 RTE 和 TweetSentBR 的 SOTA 结果。进一步探索预训练配置（如数据质量、优化策略和多轮预训练）的影响发现，这些因素的影响相对微妙，并发布了 ptt5-v2 预训练检查点及其 MonoT5 微调版本在 HuggingFace 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10806v2",
      "published_date": "2024-06-16 05:17:56 UTC",
      "updated_date": "2024-11-18 02:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:52:53.066865"
    },
    {
      "arxiv_id": "2406.10803v1",
      "title": "HiddenTables & PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies",
      "title_zh": "翻译失败",
      "authors": [
        "William Watson",
        "Nicole Cho",
        "Tucker Balch",
        "Manuela Veloso"
      ],
      "abstract": "A myriad of different Large Language Models (LLMs) face a common challenge in\ncontextually analyzing table question-answering tasks. These challenges are\nengendered from (1) finite context windows for large tables, (2) multi-faceted\ndiscrepancies amongst tokenization patterns against cell boundaries, and (3)\nvarious limitations stemming from data confidentiality in the process of using\nexternal models such as gpt-3.5-turbo. We propose a cooperative game dubbed\n\"HiddenTables\" as a potential resolution to this challenge. In essence,\n\"HiddenTables\" is played between the code-generating LLM \"Solver\" and the\n\"Oracle\" which evaluates the ability of the LLM agents to solve Table QA tasks.\nThis game is based on natural language schemas and importantly, ensures the\nsecurity of the underlying data. We provide evidential experiments on a diverse\nset of tables that demonstrate an LLM's collective inability to generalize and\nperform on complex queries, handle compositional dependencies, and align\nnatural language to programmatic commands when concrete table schemas are\nprovided. Unlike encoder-based models, we have pushed the boundaries of\n\"HiddenTables\" to not be limited by the number of rows - therefore we exhibit\nimproved efficiency in prompt and completion tokens. Our infrastructure has\nspawned a new dataset \"PyQTax\" that spans across 116,671 question-table-answer\ntriplets and provides additional fine-grained breakdowns & labels for varying\nquestion taxonomies. Therefore, in tandem with our academic contributions\nregarding LLMs' deficiency in TableQA tasks, \"HiddenTables\" is a tactile\nmanifestation of how LLMs can interact with massive datasets while ensuring\ndata security and minimizing generation costs.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）在表型问题回答（TableQA）任务中的挑战，包括有限上下文窗口、标记化模式差异以及数据保密性问题，提出了一种合作游戏“HiddenTables”和数据集“PyQTax”。在“HiddenTables”游戏中，代码生成LLM“Solver”与“Oracle”互动，通过自然语言模式处理TableQA，而不暴露底层数据，实验显示LLMs在复杂查询、组合依赖和自然语言到程序命令的映射上存在泛化不足。PyQTax数据集包含116,671个问题-表-答案三元组，并提供细粒度标签，支持跨多种分类的分析；总体上，该框架提升了效率，确保数据安全并最小化生成成本。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings of the 2023 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2023)",
      "pdf_url": "http://arxiv.org/pdf/2406.10803v1",
      "published_date": "2024-06-16 04:53:29 UTC",
      "updated_date": "2024-06-16 04:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:53:05.594430"
    },
    {
      "arxiv_id": "2406.10802v1",
      "title": "KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs",
      "title_zh": "KGPA：通过跨域知识图谱进行的大语言模型鲁棒性评估",
      "authors": [
        "Aihua Pei",
        "Zehua Yang",
        "Shunan Zhu",
        "Ruoxi Cheng",
        "Ju Jia",
        "Lina Wang"
      ],
      "abstract": "Existing frameworks for assessing robustness of large language models (LLMs)\noverly depend on specific benchmarks, increasing costs and failing to evaluate\nperformance of LLMs in professional domains due to dataset limitations. This\npaper proposes a framework that systematically evaluates the robustness of LLMs\nunder adversarial attack scenarios by leveraging knowledge graphs (KGs). Our\nframework generates original prompts from the triplets of knowledge graphs and\ncreates adversarial prompts by poisoning, assessing the robustness of LLMs\nthrough the results of these adversarial attacks. We systematically evaluate\nthe effectiveness of this framework and its modules. Experiments show that\nadversarial robustness of the ChatGPT family ranks as GPT-4-turbo > GPT-4o >\nGPT-3.5-turbo, and the robustness of large language models is influenced by the\nprofessional domains in which they operate.",
      "tldr_zh": "本研究提出 KGPA 框架，通过跨领域知识图谱 (KGs) 系统评估大型语言模型 (LLMs) 的鲁棒性，以解决现有基准依赖性高和专业领域评估不足的问题。框架从 KGs 的三元组生成原始提示，并通过对抗攻击（如 poisoning）创建对抗提示，从而测试 LLMs 在这些场景下的性能。实验结果显示，ChatGPT 家族的鲁棒性排名为 GPT-4-turbo > GPT-4o > GPT-3.5-turbo，且 LLMs 的鲁棒性受专业领域的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10802v1",
      "published_date": "2024-06-16 04:48:43 UTC",
      "updated_date": "2024-06-16 04:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:53:18.303720"
    },
    {
      "arxiv_id": "2406.10796v2",
      "title": "Ab Initio Structure Solutions from Nanocrystalline Powder Diffraction Data",
      "title_zh": "从纳米晶粉末衍射数据中获得的 Ab Initio 结构求解",
      "authors": [
        "Gabe Guo",
        "Tristan Saidi",
        "Maxwell Terban",
        "Michele Valsecchi",
        "Simon JL Billinge",
        "Hod Lipson"
      ],
      "abstract": "A major challenge in materials science is the determination of the structure\nof nanometer sized objects. Here we present a novel approach that uses a\ngenerative machine learning model based on diffusion processes that is trained\non 45,229 known structures. The model factors both the measured diffraction\npattern as well as relevant statistical priors on the unit cell of atomic\ncluster structures. Conditioned only on the chemical formula and the\ninformation-scarce finite-size broadened powder diffraction pattern, we find\nthat our model, PXRDnet, can successfully solve simulated nanocrystals as small\nas 10 angstroms across 200 materials of varying symmetry and complexity,\nincluding structures from all seven crystal systems. We show that our model can\nsuccessfully and verifiably determine structural candidates four out of five\ntimes, with average error among these candidates being only 7% (as measured by\npost-Rietveld refinement R-factor). Furthermore, PXRDnet is capable of solving\nstructures from noisy diffraction patterns gathered in real-world experiments.\nWe suggest that data driven approaches, bootstrapped from theoretical\nsimulation, will ultimately provide a path towards determining the structure of\npreviously unsolved nano-materials.",
      "tldr_zh": "本论文提出了一种新方法，使用基于diffusion processes的generative machine learning model，从纳米晶粉末衍射数据中实现从头结构求解。模型PXRDnet在45,229个已知结构上训练，结合测量的衍射模式和原子簇结构的统计先验，仅需化学公式和有限大小加宽的粉末衍射模式，即可成功求解模拟纳米晶（最小10埃），覆盖200种材料和所有七个晶系。实验结果显示，PXRDnet的成功率达80%，求解候选结构的平均误差仅7%（通过post-Rietveld refinement R-factor测量），并能处理真实实验中的噪声数据。该方法证明了数据驱动的模拟引导策略，为求解未解决的纳米材料结构提供了新路径。",
      "categories": [
        "physics.comp-ph",
        "cond-mat.mes-hall",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10796v2",
      "published_date": "2024-06-16 03:45:03 UTC",
      "updated_date": "2024-10-31 17:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:53:28.310742"
    },
    {
      "arxiv_id": "2407.12007v2",
      "title": "People will agree what I think: Investigating LLM's False Consensus Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Junhyuk Choi",
        "Yeseon Hong",
        "Bugeun Kim"
      ],
      "abstract": "Large Language Models (LLMs) have been recently adopted in interactive\nsystems requiring communication. As the false belief in a model can harm the\nusability of such systems, LLMs should not have cognitive biases that humans\nhave. Psychologists especially focus on the False Consensus Effect (FCE), a\ncognitive bias where individuals overestimate the extent to which others share\ntheir beliefs or behaviors, because FCE can distract smooth communication by\nposing false beliefs. However, previous studies have less examined FCE in LLMs\nthoroughly, which needs more consideration of confounding biases, general\nsituations, and prompt changes. Therefore, in this paper, we conduct two\nstudies to examine the FCE phenomenon in LLMs. In Study 1, we investigate\nwhether LLMs have FCE. In Study 2, we explore how various prompting styles\naffect the demonstration of FCE. As a result of these studies, we identified\nthat popular LLMs have FCE. Also, the result specifies the conditions when FCE\nbecomes more or less prevalent compared to normal usage.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 是否存在 False Consensus Effect (FCE)，一种人类认知偏差，即高估他人共享自身信念或行为的程度，这可能影响互动系统的可用性。研究者通过两个实验进行分析：Study 1 验证了 LLMs 是否表现出 FCE，Study 2 探讨了不同提示风格对 FCE 的影响。结果表明，流行 LLMs 确实具有 FCE，并识别了特定条件（如提示变化）使该效应更显著或减轻，为减少 LLMs 认知偏差提供重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2407.12007v2",
      "published_date": "2024-06-16 03:29:28 UTC",
      "updated_date": "2025-02-08 09:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:53:39.451939"
    },
    {
      "arxiv_id": "2406.10787v3",
      "title": "Evidential Uncertainty Sets in Deep Classifiers Using Conformal Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Karimi",
        "Reza Samavi"
      ],
      "abstract": "In this paper, we propose Evidential Conformal Prediction (ECP) method for\nimage classifiers to generate the conformal prediction sets. Our method is\ndesigned based on a non-conformity score function that has its roots in\nEvidential Deep Learning (EDL) as a method of quantifying model (epistemic)\nuncertainty in DNN classifiers. We use evidence that are derived from the logit\nvalues of target labels to compute the components of our non-conformity score\nfunction: the heuristic notion of uncertainty in CP, uncertainty surprisal, and\nexpected utility. Our extensive experimental evaluation demonstrates that ECP\noutperforms three state-of-the-art methods for generating CP sets, in terms of\ntheir set sizes and adaptivity while maintaining the coverage of true labels.",
      "tldr_zh": "本文提出 Evidential Conformal Prediction (ECP) 方法，用于图像分类器的预测集生成，通过基于 Evidential Deep Learning (EDL) 的非一致性分数函数量化模型的不确定性 (epistemic uncertainty)。该函数利用目标标签的 logit 值派生的证据，计算不确定性、uncertainty surprisal 和 expected utility，以优化预测集的大小和适应性。实验结果显示，ECP 在保持真实标签覆盖率的同时，优于三种最先进方法，提高了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 13th Symposium on Conformal and Probabilistic Prediction\n  with Applications (COPA2024). To be published in the Proceedings of Machine\n  Learning Research (PMLR), vol. 230, 2024 (25 Pages)",
      "pdf_url": "http://arxiv.org/pdf/2406.10787v3",
      "published_date": "2024-06-16 03:00:16 UTC",
      "updated_date": "2024-07-30 04:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:53:51.469713"
    },
    {
      "arxiv_id": "2406.10786v2",
      "title": "Exploring the Zero-Shot Capabilities of LLMs Handling Multiple Problems at once",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengxiang Wang",
        "Jordan Kodner",
        "Owen Rambow"
      ],
      "abstract": "Recent studies have proposed placing multiple problems in a single prompt to\nimprove input token utilization for a more efficient LLM inference. We call\nthis MPP, in contrast to conventional SPP that prompts an LLM with a single\nproblem at a time. While MPP has been shown to work comparably well or even\nbetter than SPP under few-shot settings, its zero-shot performance is\nunderexplored, which better reveals the innate multiple problem handling\ncapabilities of LLMs. To address that, we study the zero-shot MPP performance\nof various LLMs on 6 classification and 12 reasoning benchmarks and confirm\nthat LLMs are competent zero-shot multi-problem solvers. We also examine the\nconditions of effectiveness of zero-shot MPP and explore several model-level\nfactors that may enable MPP. We observe that LLMs consistently perform worse\nwith selecting indices of texts of a given class label and with multiple\nmixed-source reasoning problems, indicating a lack of true understanding. We\nalso find that instruction tuning is an important factor than enhances MPP.",
      "tldr_zh": "本文研究了大语言模型（LLMs）在 zero-shot 设置下处理多个问题（MPP）的能力，与传统的单个问题提示（SPP）相比，探讨了如何通过一个提示提高输入 token 利用率。研究者通过测试各种 LLMs 在 6 个分类和 12 个推理基准上的表现，确认 LLMs 是 competent zero-shot multi-problem solvers，但发现模型在选择文本索引和混合来源推理任务上表现较差，缺乏真正理解。最终，instruction tuning 被证明是提升 zero-shot MPP 有效性的重要因素。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 11 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.10786v2",
      "published_date": "2024-06-16 02:52:32 UTC",
      "updated_date": "2024-10-21 04:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:54:06.911814"
    },
    {
      "arxiv_id": "2406.10785v1",
      "title": "ShareLoRA: Parameter Efficient and Robust Large Language Model Fine-tuning via Shared Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Yurun Song",
        "Junchen Zhao",
        "Ian G. Harris",
        "Sangeetha Abdu Jyothi"
      ],
      "abstract": "This study introduces an approach to optimize Parameter Efficient Fine Tuning\n(PEFT) for Pretrained Language Models (PLMs) by implementing a Shared Low Rank\nAdaptation (ShareLoRA). By strategically deploying ShareLoRA across different\nlayers and adapting it for the Query, Key, and Value components of\nself-attention layers, we achieve a substantial reduction in the number of\ntraining parameters and memory usage. Importantly, ShareLoRA not only maintains\nmodel performance but also exhibits robustness in both classification and\ngeneration tasks across a variety of models, including RoBERTa, GPT-2, LLaMA\nand LLaMA2. It demonstrates superior transfer learning capabilities compared to\nstandard LoRA applications and mitigates overfitting by sharing weights across\nlayers. Our findings affirm that ShareLoRA effectively boosts parameter\nefficiency while ensuring scalable and high-quality performance across\ndifferent language model architectures.",
      "tldr_zh": "本研究提出ShareLoRA，一种参数高效且鲁棒的微调方法，用于预训练语言模型(PLMs)，通过共享低秩适配(Shared Low-Rank Adaptation)在不同层部署，并应用于自注意力层的Query、Key和Value组件，从而大幅减少训练参数和内存使用。ShareLoRA不仅维持了模型在分类和生成任务上的性能，还在RoBERTa、GPT-2、LLaMA和LLaMA2等模型中展现出优越的迁移学习能力，并通过跨层共享权重缓解过拟合问题。与标准LoRA相比，它显著提升了参数效率和可扩展性。实验结果证实，ShareLoRA在各种任务中实现了高品质性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10785v1",
      "published_date": "2024-06-16 02:52:28 UTC",
      "updated_date": "2024-06-16 02:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:54:18.794105"
    },
    {
      "arxiv_id": "2406.10775v2",
      "title": "A Rate-Distortion View of Uncertainty Quantification",
      "title_zh": "不确定性量化的码率失真视角",
      "authors": [
        "Ifigeneia Apostolopoulou",
        "Benjamin Eysenbach",
        "Frank Nielsen",
        "Artur Dubrawski"
      ],
      "abstract": "In supervised learning, understanding an input's proximity to the training\ndata can help a model decide whether it has sufficient evidence for reaching a\nreliable prediction. While powerful probabilistic models such as Gaussian\nProcesses naturally have this property, deep neural networks often lack it. In\nthis paper, we introduce Distance Aware Bottleneck (DAB), i.e., a new method\nfor enriching deep neural networks with this property. Building on prior\ninformation bottleneck approaches, our method learns a codebook that stores a\ncompressed representation of all inputs seen during training. The distance of a\nnew example from this codebook can serve as an uncertainty estimate for the\nexample. The resulting model is simple to train and provides deterministic\nuncertainty estimates by a single forward pass. Finally, our method achieves\nbetter out-of-distribution (OOD) detection and misclassification prediction\nthan prior methods, including expensive ensemble methods, deep kernel Gaussian\nProcesses, and approaches based on the standard information bottleneck.",
      "tldr_zh": "本文从率失真视角探讨不确定性量化问题，针对深度神经网络在监督学习中缺乏输入与训练数据接近度评估的不足，提出了一种新方法 Distance Aware Bottleneck (DAB)。DAB 基于信息瓶颈方法，学习一个 codebook 来存储训练输入的压缩表示，并使用新输入与 codebook 的距离作为不确定性估计，使模型通过单次前向传播即可提供简单、确定性的不确定性评估。实验结果显示，DAB 在 out-of-distribution (OOD) 检测和误分类预测上优于现有方法，包括集成方法、Gaussian Processes 和标准信息瓶颈方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10775v2",
      "published_date": "2024-06-16 01:33:22 UTC",
      "updated_date": "2024-06-18 12:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:54:30.598874"
    },
    {
      "arxiv_id": "2406.10773v1",
      "title": "Quantifying Generative Media Bias with a Corpus of Real-world and Generated News Articles",
      "title_zh": "利用真实世界和生成新闻文章语料库量化生成式媒体偏见",
      "authors": [
        "Filip Trhlik",
        "Pontus Stenetorp"
      ],
      "abstract": "Large language models (LLMs) are increasingly being utilised across a range\nof tasks and domains, with a burgeoning interest in their application within\nthe field of journalism. This trend raises concerns due to our limited\nunderstanding of LLM behaviour in this domain, especially with respect to\npolitical bias. Existing studies predominantly focus on LLMs undertaking\npolitical questionnaires, which offers only limited insights into their biases\nand operational nuances. To address this gap, our study establishes a new\ncurated dataset that contains 2,100 human-written articles and utilises their\ndescriptions to generate 56,700 synthetic articles using nine LLMs. This\nenables us to analyse shifts in properties between human-authored and\nmachine-generated articles, with this study focusing on political bias,\ndetecting it using both supervised models and LLMs. Our findings reveal\nsignificant disparities between base and instruction-tuned LLMs, with\ninstruction-tuned models exhibiting consistent political bias. Furthermore, we\nare able to study how LLMs behave as classifiers, observing their display of\npolitical bias even in this role. Overall, for the first time within the\njournalistic domain, this study outlines a framework and provides a structured\ndataset for quantifiable experiments, serving as a foundation for further\nresearch into LLM political bias and its implications.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在新闻领域的应用及其政治偏见问题，构建了一个包含2100篇人类撰写的文章和基于其描述生成的56700篇合成文章的新数据集，使用九个LLMs进行生成。研究方法涉及比较人类和机器生成文章的属性，通过监督模型和LLMs检测政治偏见，结果显示指令微调过的LLMs表现出一致的政治偏见，而LLMs作为分类器时也存在类似问题。该框架首次在新闻领域提供可量化的实验基础，帮助进一步探索LLMs的政治偏见及其影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.10773v1",
      "published_date": "2024-06-16 01:32:04 UTC",
      "updated_date": "2024-06-16 01:32:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T20:54:41.494892"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 74,
  "processed_papers_count": 74,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T20:55:06.580189"
}