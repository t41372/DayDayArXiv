{
  "date": "2024-10-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-07 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化、推理和应用，特别是大型语言模型 (LLMs) 在元推理、安全对齐和多模态任务中的创新进展，强调了高效计算和鲁棒性改进；令人印象深刻的文章包括 Thomas L. Griffiths 参与的 LLM 元推理研究，以及 EMNLP 和 NeurIPS 相关工作；这些论文展示了 AI 在科学、医疗和机器人领域的潜力，同时推动了更可靠的模型设计。\n\n### 重点论文讨论\n我将优先讨论与 LLMs 相关的创新性论文，这些工作在推理、优化和安全方面有显著贡献，并可能引发广泛话题。其他领域如机器人和医学的论文将简要概述，以控制篇幅。\n\n#### LLMs 推理与优化\n- **Rational Metareasoning for Large Language Models**（理性元推理的大型语言模型）  \n  作者包括 Thomas L. Griffiths，这篇论文提出了一种基于认知科学的新方法，训练 LLMs 选择性地使用中间推理步骤，仅在必要时计算，以优化成本-性能权衡。主要贡献：开发了奖励函数和 Expert Iteration 算法，减少了 20-37% 的推理令牌，同时保持任务性能。该工作突出了 LLMs 在资源受限环境下的实用性。\n\n- **Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**（叙事思维：通过重述叙事提升 LLMs 的时间推理）  \n  这篇 EMNLP'24 论文引入 Narrative-of-Thought 技术，帮助 LLMs 处理时间图生成任务。主要发现：通过将事件转换为 Python 类并生成时间接地叙事，该方法提升了时间推理精度，实现了与 GPT-3.5 相当的 F1 分数，并改进了结构相似性，适用于复杂时间序列任务。\n\n- **On Instruction-Finetuning Neural Machine Translation Models**（指令微调神经机器翻译模型）  \n  WMT'24 论文探索了从 LLMs 蒸馏指令遵循能力的微调方法。主要贡献：使小型 NMT 模型支持多种翻译任务，如形式控制和多模态翻译，与 GPT-3.5 相当，同时降低了计算成本。该工作强调了指令微调在实际翻译应用中的高效性。\n\n- **Fill In The Gaps: Model Calibration and Generalization with Synthetic Data**（填充空白：使用合成数据进行模型校准和泛化）  \n  这篇 EMNLP 2024 长论文使用 LLMs 生成合成数据来校准模型。主要发现：提高了模型准确性（平均提升 34%）和校准误差减少（33%），展示了合成数据在自然语言处理任务中的泛化潜力。\n\n- **Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback**（优于你的老师：从特权 AI 反馈中学习的 LLM 代理）  \n  论文提出 LEAP 框架，让 LLM 代理从特权信息学习，实现超越教师模型的性能。主要贡献：在 D4RL 基准上，弱模型（如 Llama3-8B）超过了强教师模型（如 GPT-4），并在决策任务中表现出色。\n\n- **Superficial Safety Alignment Hypothesis**（浅层安全对齐假设）  \n  这篇论文假设安全对齐可以通过少量关键组件实现。主要发现：通过冻结 7.5% 的安全组件，LLMs 能在保持安全性的同时适应新任务，强调了神经元级别的安全机制。\n\n- **Exploring the Personality Traits of LLMs through Latent Features Steering**（通过潜在特征引导探索 LLMs 的个性特征）  \n  论文使用无监督方法分析 LLMs 的个性特征，并讨论其对模型安全的影响。主要贡献：揭示了文化规范和环境压力如何塑造 LLMs 的行为，提供了解释性洞察。\n\n这些 LLMs 相关论文突出了模型的推理效率和安全改进，Thomas L. Griffiths 的参与增加了其学术影响力。其他如 Narrative-of-Thought 的时间推理方法，可能在 AI 应用中引发话题。\n\n#### 多模态和视觉模型\n- **Toward General Object-level Mapping from Sparse Views with 3D Diffusion Priors**（基于 3D 扩散先验的稀疏视图一般对象级映射）  \n  CoRL 2024 论文提出 GOM 系统，使用 3D 扩散模型从稀疏视图重建多类别对象。主要发现：改进了对象姿态和形状估计，超越了现有方法，在真实基准上表现出色。\n\n- **Residual Kolmogorov-Arnold Network for Enhanced Deep Learning**（增强深度学习的残差 Kolmogorov-Arnold 网络）  \n  论文引入 RKAN 模块，结合多项式变换提升 CNN 性能。主要贡献：在 CIFAR-100 等数据集上，RKAN 模块提高了模型效率和准确性。\n\n- **TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens**（TextHawk2：一种高效的大规模视觉语言模型，在双语 OCR 和 grounding 中表现出色）  \n  这篇论文优化了视觉语言模型，减少了图像令牌数量。主要发现：在 OCR 和 grounding 任务中，TextHawk2 超越了类似规模的模型，实现了高准确率。\n\n这些工作展示了多模态模型的效率提升，特别是在 OCR 和对象映射方面的应用。\n\n#### 机器人和环境应用\n- **Accelerating Flood Warnings by 10 Hours: The Power of River Network Topology in AI-enhanced Flood Forecasting**（通过 AI 增强洪水预报提前 10 小时预警：河流网络拓扑的作用）  \n  论文使用 GNN 改进了洪水预测模型。主要贡献：通过拓扑变换提升了预测准确性，实现 71% 的长期预测改进。\n\n- **Online Dynamic Pricing for Electric Vehicle Charging Stations with Reservations**（带预订的电动汽车充电站在线动态定价）  \n  该工作使用 Markov 决策过程优化充电定价。主要发现：减少了离散化误差，提供了一个实用的动态定价策略。\n\n这些论文在实际应用中具有显著影响，如环境监测和能源管理。\n\n#### 其他领域快速掠过\n其他论文涉及量子计算、医学 AI 和图像处理等领域，但由于篇幅限制，仅简要提及：\n- **Diffusion Model Predictive Control**（扩散模型预测控制）：NeurIPS 论文提出了一种用于强化学习的扩散模型方法，提升了决策性能。\n- **Image Watermarks are Removable Using Controllable Regeneration from Clean Noise**（图像水印可通过可控再生从干净噪声中移除）：ICLR2025 论文开发了水印移除技术，提高了图像质量。\n- **Neural Networks Decoded**（神经网络解码）：论文引入 TRACER 方法，提供神经网络决策的因果解释。\n- 其余如医学图像生成和安全对齐的论文虽有创新，但优先级较低，仅确认其在特定领域的进展。\n\n总之，今天的 arXiv 论文展示了 AI 领域的多样创新，特别是 LLMs 的推理和优化潜力。这些工作为更高效、安全的模型铺路，期待后续应用。明天的快报再见！",
  "papers": [
    {
      "arxiv_id": "2410.05563v2",
      "title": "Rational Metareasoning for Large Language Models",
      "title_zh": "针对大型语言模型的理性元推理",
      "authors": [
        "C. Nicolò De Sabbata",
        "Theodore R. Sumers",
        "Thomas L. Griffiths"
      ],
      "abstract": "Being prompted to engage in reasoning has emerged as a core technique for\nusing large language models (LLMs), deploying additional inference-time compute\nto improve task performance. However, as LLMs increase in both size and\nadoption, inference costs are correspondingly becoming increasingly burdensome.\nHow, then, might we optimize reasoning's cost-performance tradeoff? This work\nintroduces a novel approach based on computational models of metareasoning used\nin cognitive science, training LLMs to selectively use intermediate reasoning\nsteps only when necessary. We first develop a reward function that incorporates\nthe Value of Computation by penalizing unnecessary reasoning, then use this\nreward function with Expert Iteration to train the LLM. Compared to few-shot\nchain-of-thought prompting and STaR, our method significantly reduces inference\ncosts (20-37\\% fewer tokens generated across three models) while maintaining\ntask performance across diverse datasets.",
      "tldr_zh": "这篇论文提出了一种基于理性元推理（Rational Metareasoning）的优化方法，用于大型语言模型（LLMs），以减少推理过程的计算成本，同时维持任务性能。方法包括开发一个奖励函数，融入计算价值（Value of Computation）来惩罚不必要的推理步骤，并使用Expert Iteration训练LLMs仅在必要时生成中间推理。实验结果显示，与few-shot chain-of-thought prompting和STaR相比，该方法在多种数据集上降低了20-37%的推理tokens生成，而任务表现保持不变。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05563v2",
      "published_date": "2024-10-07 23:48:52 UTC",
      "updated_date": "2024-12-21 11:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:54:01.223964"
    },
    {
      "arxiv_id": "2410.05558v2",
      "title": "Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Xinliang Frederick Zhang",
        "Nick Beauchamp",
        "Lu Wang"
      ],
      "abstract": "Reasoning about time and temporal relations is an integral aspect of human\ncognition, essential for perceiving the world and navigating our experiences.\nThough large language models (LLMs) have demonstrated impressive performance in\nmany reasoning tasks, temporal reasoning remains challenging due to its\nintrinsic complexity. In this work, we first study an essential task of\ntemporal reasoning -- temporal graph generation, to unveil LLMs' inherent,\nglobal reasoning capabilities. We show that this task presents great challenges\neven for the most powerful LLMs, such as GPT-3.5/4. We also notice a\nsignificant performance gap by small models (<10B) that lag behind LLMs by 50%.\nNext, we study how to close this gap with a budget constraint, e.g., not using\nmodel finetuning. We propose a new prompting technique tailored for temporal\nreasoning, Narrative-of-Thought (NoT), that first converts the events set to a\nPython class, then prompts a small model to generate a temporally grounded\nnarrative, guiding the final generation of a temporal graph. Extensive\nexperiments showcase the efficacy of NoT in improving various metrics. Notably,\nNoT attains the highest F1 on the Schema-11 evaluation set, while securing an\noverall F1 on par with GPT-3.5. NoT also achieves the best structural\nsimilarity across the board, even compared with GPT-3.5/4. Our code is\navailable at https://github.com/launchnlp/NoT.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在时间推理（temporal reasoning）方面的挑战，通过时间图生成任务揭示了即使如 GPT-3.5/4 等强大模型也存在显著困难，小模型（<10B）则落后约50%。为解决这一问题，作者提出了一种新的提示技术Narrative-of-Thought (NoT)，该方法先将事件集转换为Python类，然后引导小模型生成基于时间的叙述，最终输出时间图。实验结果显示，NoT显著提升了各种指标，包括在Schema-11评估集上获得最高F1分数，与GPT-3.5相当，并在结构相似性上超越GPT-3.5/4，为预算受限下的时间推理优化提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP'24 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.05558v2",
      "published_date": "2024-10-07 23:36:05 UTC",
      "updated_date": "2024-11-17 17:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:54:13.647853"
    },
    {
      "arxiv_id": "2410.05553v1",
      "title": "On Instruction-Finetuning Neural Machine Translation Models",
      "title_zh": "关于指令微调神经机器翻译模型",
      "authors": [
        "Vikas Raunak",
        "Roman Grundkiewicz",
        "Marcin Junczys-Dowmunt"
      ],
      "abstract": "In this work, we introduce instruction finetuning for Neural Machine\nTranslation (NMT) models, which distills instruction following capabilities\nfrom Large Language Models (LLMs) into orders-of-magnitude smaller NMT models.\nOur instruction-finetuning recipe for NMT models enables customization of\ntranslations for a limited but disparate set of translation-specific tasks. We\nshow that NMT models are capable of following multiple instructions\nsimultaneously and demonstrate capabilities of zero-shot composition of\ninstructions. We also show that through instruction finetuning, traditionally\ndisparate tasks such as formality-controlled machine translation, multi-domain\nadaptation as well as multi-modal translations can be tackled jointly by a\nsingle instruction finetuned NMT model, at a performance level comparable to\nLLMs such as GPT-3.5-Turbo. To the best of our knowledge, our work is among the\nfirst to demonstrate the instruction-following capabilities of traditional NMT\nmodels, which allows for faster, cheaper and more efficient serving of\ncustomized translations.",
      "tldr_zh": "本文提出了一种针对 Neural Machine Translation (NMT) 模型的 instruction finetuning 方法，该技术从 Large Language Models (LLMs) 中提炼指令遵循能力，并应用到规模小得多的 NMT 模型中，从而实现对多种翻译特定任务的自定义。研究发现，通过这种微调，NMT 模型能够同时处理多个指令、实现零-shot 指令组合，并将原本分离的任务（如形式控制机器翻译、多领域适应和多模态翻译）整合到一个模型中，性能可媲美 GPT-3.5-Turbo。总体而言，此方法使自定义翻译变得更快、更便宜且更高效，为传统 NMT 模型赋予了新的指令遵循能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WMT'24",
      "pdf_url": "http://arxiv.org/pdf/2410.05553v1",
      "published_date": "2024-10-07 23:26:13 UTC",
      "updated_date": "2024-10-07 23:26:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:54:26.041781"
    },
    {
      "arxiv_id": "2410.10864v1",
      "title": "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Ba",
        "Michelle V. Mancenido",
        "Rong Pan"
      ],
      "abstract": "As machine learning models continue to swiftly advance, calibrating their\nperformance has become a major concern prior to practical and widespread\nimplementation. Most existing calibration methods often negatively impact model\naccuracy due to the lack of diversity of validation data, resulting in reduced\ngeneralizability. To address this, we propose a calibration method that\nincorporates synthetic data without compromising accuracy. We derive the\nexpected calibration error (ECE) bound using the Probably Approximately Correct\n(PAC) learning framework. Large language models (LLMs), known for their ability\nto mimic real data and generate text with mixed class labels, are utilized as a\nsynthetic data generation strategy to lower the ECE bound and improve model\naccuracy on real test data. Additionally, we propose data generation mechanisms\nfor efficient calibration. Testing our method on four different natural\nlanguage processing tasks, we observed an average up to 34\\% increase in\naccuracy and 33\\% decrease in ECE.",
      "tldr_zh": "本文提出了一种名为“Fill In The Gaps”的模型校准方法，使用合成数据来提升机器学习模型的校准和泛化性能，同时避免降低准确性。方法基于Probably Approximately Correct (PAC)学习框架推导Expected Calibration Error (ECE)边界，并利用Large Language Models (LLMs)生成多样化的合成数据，以降低ECE并改善模型在真实测试数据上的表现。此外，该方法还设计了高效的数据生成机制；在四个自然语言处理任务上测试，结果显示准确性平均提高34%，ECE降低33%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main Conference (Long paper)",
      "pdf_url": "http://arxiv.org/pdf/2410.10864v1",
      "published_date": "2024-10-07 23:06:42 UTC",
      "updated_date": "2024-10-07 23:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:54:37.041579"
    },
    {
      "arxiv_id": "2410.05538v3",
      "title": "Online Dynamic Pricing for Electric Vehicle Charging Stations with Reservations",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Mrkos",
        "Antonín Komenda",
        "David Fiedler",
        "Jiří Vokřínek"
      ],
      "abstract": "This paper introduces a novel model for online dynamic pricing of electric\nvehicle charging services that integrates reservation, parking, and charging\ninto a comprehensive bundle priced as a whole. Our approach focuses on the\nindividual high-demand, fast-charging location, employing a Poisson process as\na model of charging reservation arrivals, and develops an online dynamic\npricing strategy optimized through a Markov Decision Process (MDP). A key\ncontribution is the novel analysis of discretization error introduced when\nincorporating the continuous-time Poisson process into the discrete MDP\nframework. The MDP model's feasibility is demonstrated with a heuristic dynamic\npricing method based on Monte-Carlo tree search, offering a viable path for\nreal-world applications.",
      "tldr_zh": "这篇论文提出了一种新型在线动态定价模型，用于电动汽车充电站的预约服务，将预约、停车和充电整合为一个整体捆绑包进行定价。模型采用 Poisson process 模拟高需求快速充电地点的预约到达，并通过 Markov Decision Process (MDP) 框架优化动态定价策略，同时分析了将连续时间 Poisson process 整合到离散 MDP 中引入的离散化误差。最终，使用基于 Monte-Carlo tree search 的启发式方法证明了模型的可行性，为电动汽车充电服务的实际应用提供了可行的路径。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "45 pages, 11 figure, accepted to IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)",
      "pdf_url": "http://arxiv.org/pdf/2410.05538v3",
      "published_date": "2024-10-07 22:36:40 UTC",
      "updated_date": "2025-04-28 08:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:54:50.698748"
    },
    {
      "arxiv_id": "2410.05536v3",
      "title": "Accelerating Flood Warnings by 10 Hours: The Power of River Network Topology in AI-enhanced Flood Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Yinqiang Zheng",
        "Xuan Song"
      ],
      "abstract": "Climate change-driven floods demand advanced forecasting models, yet Graph\nNeural Networks (GNNs) underutilize river network topology due to tree-like\nstructures causing over-squashing from high node resistance distances. This\nstudy identifies this limitation and introduces a reachability-based graph\ntransformation to densify topological connections, reducing resistance\ndistances. Empirical tests show transformed-GNNs outperform EA-LSTM in extreme\nflood prediction, achieving 24-h water level accuracy equivalent to EA-LSTM's\n14-h forecasts - a 71% improvement in long-term predictive horizon. The dense\ngraph retains flow dynamics across hierarchical river branches, enabling GNNs\nto capture distal node interactions critical for rare flood events. This\ntopological innovation bridges the gap between river network structure and GNN\nmodeling, offering a scalable framework for early warning systems.",
      "tldr_zh": "本研究发现，Graph Neural Networks (GNNs) 在洪水预测中未充分利用河网拓扑，因树状结构导致过压缩问题，从而限制了极端洪水事件的准确预测。为此，引入了一种基于可达性的图转换方法，以密集拓扑连接并减少节点抵抗距离。实验结果显示，转换后的GNNs 优于 EA-LSTM，在极端洪水预测中实现了 24 小时水位准确性，相当于 EA-LSTM 的 14 小时预测，改善了 71% 的长期预测视野。这种拓扑创新框架保留了河网流动动态，并为可扩展的早期预警系统提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05536v3",
      "published_date": "2024-10-07 22:25:37 UTC",
      "updated_date": "2025-03-13 00:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:55:02.100957"
    },
    {
      "arxiv_id": "2410.05534v1",
      "title": "Optimizing Tensor Computation Graphs with Equality Saturation and Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Hartmann",
        "Guoliang He",
        "Eiko Yoneki"
      ],
      "abstract": "The real-world effectiveness of deep neural networks often depends on their\nlatency, thereby necessitating optimization techniques that can reduce a\nmodel's inference time while preserving its performance. One popular approach\nis to sequentially rewrite the input computation graph into an equivalent but\nfaster one by replacing individual subgraphs. This approach gives rise to the\nso-called phase-ordering problem in which the application of one rewrite rule\ncan eliminate the possibility to apply an even better one later on. Recent work\nhas shown that equality saturation, a technique from compiler optimization, can\nmitigate this issue by first building an intermediate representation (IR) that\nefficiently stores multiple optimized versions of the input program before\nextracting the best solution in a second step. In practice, however, memory\nconstraints prevent the IR from capturing all optimized versions and thus\nreintroduce the phase-ordering problem in the construction phase. In this\npaper, we present a tensor graph rewriting approach that uses Monte Carlo tree\nsearch to build superior IRs by identifying the most promising rewrite rules.\nWe also introduce a novel extraction algorithm that can provide fast and\naccurate runtime estimates of tensor programs represented in an IR. Our\napproach improves the inference speedup of neural networks by up to 11%\ncompared to existing methods.",
      "tldr_zh": "本研究针对深度神经网络优化中的 phase-ordering problem，提出了一种结合 equality saturation 和 Monte Carlo Tree Search (MCTS) 的张量计算图重写方法。该方法使用 MCTS 识别最有前景的重写规则，以构建更优的中间表示 (IR)，并引入一个新提取算法来快速准确地估计张量程序的运行时，从而缓解内存约束带来的问题。与现有方法相比，该方法将神经网络的推理速度提高高达 11%。这项工作为高效的编译优化提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in the 33rd International Conference on Parallel\n  Architectures and Compilation Techniques (PACT '24), October 14-16, 2024,\n  Long Beach, CA, USA",
      "pdf_url": "http://arxiv.org/pdf/2410.05534v1",
      "published_date": "2024-10-07 22:22:02 UTC",
      "updated_date": "2024-10-07 22:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:55:14.159884"
    },
    {
      "arxiv_id": "2410.05514v1",
      "title": "Toward General Object-level Mapping from Sparse Views with 3D Diffusion Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Liao",
        "Binbin Xu",
        "Steven L. Waslander"
      ],
      "abstract": "Object-level mapping builds a 3D map of objects in a scene with detailed\nshapes and poses from multi-view sensor observations. Conventional methods\nstruggle to build complete shapes and estimate accurate poses due to partial\nocclusions and sensor noise. They require dense observations to cover all\nobjects, which is challenging to achieve in robotics trajectories. Recent work\nintroduces generative shape priors for object-level mapping from sparse views,\nbut is limited to single-category objects. In this work, we propose a General\nObject-level Mapping system, GOM, which leverages a 3D diffusion model as shape\nprior with multi-category support and outputs Neural Radiance Fields (NeRFs)\nfor both texture and geometry for all objects in a scene. GOM includes an\neffective formulation to guide a pre-trained diffusion model with extra\nnonlinear constraints from sensor measurements without finetuning. We also\ndevelop a probabilistic optimization formulation to fuse multi-view sensor\nobservations and diffusion priors for joint 3D object pose and shape\nestimation. Our GOM system demonstrates superior multi-category mapping\nperformance from sparse views, and achieves more accurate mapping results\ncompared to state-of-the-art methods on the real-world benchmarks. We will\nrelease our code: https://github.com/TRAILab/GeneralObjectMapping.",
      "tldr_zh": "本研究针对物体级映射问题，提出了一种名为GOM的系统，利用3D Diffusion Priors从稀疏视图构建场景中多类别物体的3D地图，包括详细形状和姿态，以克服传统方法因部分遮挡和传感器噪声而导致的不完整性。GOM通过引导预训练的3D扩散模型，并结合额外的非线性约束和概率优化公式，融合多视图传感器观察来联合估计物体的3D姿态和形状，而无需模型微调。实验结果显示，GOM在稀疏视图下表现出优越的多类别映射性能，并在真实世界基准上比最先进方法实现更准确的映射效果。作者计划发布代码：https://github.com/TRAILab/GeneralObjectMapping。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.05514v1",
      "published_date": "2024-10-07 21:33:30 UTC",
      "updated_date": "2024-10-07 21:33:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:55:25.716801"
    },
    {
      "arxiv_id": "2410.05500v2",
      "title": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning",
      "title_zh": "残差 Kolmogorov-Arnold 网络用于增强深度学习",
      "authors": [
        "Ray Congrui Yu",
        "Sherry Wu",
        "Jiang Gui"
      ],
      "abstract": "Despite their immense success, deep neural networks (CNNs) are costly to\ntrain, while modern architectures can retain hundreds of convolutional layers\nin network depth. Standard convolutional operations are fundamentally limited\nby their linear nature along with fixed activations, where multiple layers are\nneeded to learn complex patterns, making this approach computationally\ninefficient and prone to optimization difficulties. As a result, we introduce\nRKAN (Residual Kolmogorov-Arnold Network), which could be easily implemented\ninto stages of traditional networks, such as ResNet. The module also integrates\npolynomial feature transformation that provides the expressive power of many\nconvolutional layers through learnable, non-linear feature refinement. Our\nproposed RKAN module offers consistent improvements over the base models on\nvarious well-known benchmark datasets, such as CIFAR-100, Food-101, and\nImageNet.",
      "tldr_zh": "本论文针对深度神经网络(CNNs)的高训练成本和优化困难问题，提出了Residual Kolmogorov-Arnold Network (RKAN)，该模块通过多项式特征变换实现可学习的非线性特征细化，并易于集成到传统网络如 ResNet 中。RKAN 提供更强的表达能力，能替代多层卷积操作以提高计算效率。主要实验结果显示，在 CIFAR-100、Food-101 和 ImageNet 等基准数据集上，RKAN 模块使基线模型性能得到一致提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.10; I.4.3; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at https://github.com/withray/residualKAN.git",
      "pdf_url": "http://arxiv.org/pdf/2410.05500v2",
      "published_date": "2024-10-07 21:12:32 UTC",
      "updated_date": "2025-03-04 06:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:55:38.275577"
    },
    {
      "arxiv_id": "2410.05496v1",
      "title": "Intuitions of Compromise: Utilitarianism vs. Contractualism",
      "title_zh": "妥协的直觉：Utilitarianism vs. Contractualism",
      "authors": [
        "Jared Moore",
        "Yejin Choi",
        "Sydney Levine"
      ],
      "abstract": "What is the best compromise in a situation where different people value\ndifferent things? The most commonly accepted method for answering this question\n-- in fields across the behavioral and social sciences, decision theory,\nphilosophy, and artificial intelligence development -- is simply to add up\nutilities associated with the different options and pick the solution with the\nlargest sum. This ``utilitarian'' approach seems like the obvious,\ntheory-neutral way of approaching the problem. But there is an important,\nthough often-ignored, alternative: a ``contractualist'' approach, which\nadvocates for an agreement-driven method of deciding. Remarkably, no research\nhas presented empirical evidence directly comparing the intuitive plausibility\nof these two approaches. In this paper, we systematically explore the proposals\nsuggested by each algorithm (the ``Utilitarian Sum'' and the contractualist\n''Nash Product''), using a paradigm that applies those algorithms to\naggregating preferences across groups in a social decision-making context.\nWhile the dominant approach to value aggregation up to now has been\nutilitarian, we find that people strongly prefer the aggregations recommended\nby the contractualist algorithm. Finally, we compare the judgments of large\nlanguage models (LLMs) to that of our (human) participants, finding important\nmisalignment between model and human preferences.",
      "tldr_zh": "这篇论文探讨了在不同人价值观冲突的情况下，utilitarianism（功利主义）和contractualism（契约主义）两种方法在决策妥协中的直观合理性。研究通过实验范式比较了Utilitarian Sum和Nash Product算法在社会决策中的应用，发现人们更倾向于contractualist算法的建议结果。最终，论文还揭示了大型语言模型（LLMs）的判断与人类偏好存在重要不一致，为道德决策理论提供了新的实证洞见。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05496v1",
      "published_date": "2024-10-07 21:05:57 UTC",
      "updated_date": "2024-10-07 21:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:55:49.150702"
    },
    {
      "arxiv_id": "2410.10863v2",
      "title": "Exploring the Personality Traits of LLMs through Latent Features Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Shu Yang",
        "Shenzhe Zhu",
        "Liang Liu",
        "Lijie Hu",
        "Mengdi Li",
        "Di Wang"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced dialogue systems and\nrole-playing agents through their ability to generate human-like text. While\nprior studies have shown that LLMs can exhibit distinct and consistent\npersonalities, the mechanisms through which these models encode and express\nspecific personality traits remain poorly understood. To address this, we\ninvestigate how various factors, such as cultural norms and environmental\nstressors, encoded within LLMs, shape their personality traits, guided by the\ntheoretical framework of social determinism. Inspired by related work on LLM\ninterpretability, we propose a training-free approach to modify the model's\nbehavior by extracting and steering latent features corresponding to factors\nwithin the model, thereby eliminating the need for retraining. Furthermore, we\nanalyze the implications of these factors for model safety, focusing on their\nimpact through the lens of personality.",
      "tldr_zh": "本文研究大型语言模型(LLMs)的个性特征，探讨社会决定论框架下，因素如文化规范和环境压力如何塑造这些特征。作者提出一种无需训练的训练-free方法，通过提取和steering latent features来修改模型行为，从而实现对LLMs个性表达的控制。实验分析显示，这种方法不仅提升了模型的可解释性，还揭示了这些因素对模型安全性的潜在影响，例如通过个性视角评估风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2410.10863v2",
      "published_date": "2024-10-07 21:02:34 UTC",
      "updated_date": "2025-02-16 22:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:56:05.274750"
    },
    {
      "arxiv_id": "2410.05484v1",
      "title": "Neural Networks Decoded: Targeted and Robust Analysis of Neural Network Decisions via Causal Explanations and Reasoning",
      "title_zh": "神经网络",
      "authors": [
        "Alec F. Diallo",
        "Vaishak Belle",
        "Paul Patras"
      ],
      "abstract": "Despite their success and widespread adoption, the opaque nature of deep\nneural networks (DNNs) continues to hinder trust, especially in critical\napplications. Current interpretability solutions often yield inconsistent or\noversimplified explanations, or require model changes that compromise\nperformance. In this work, we introduce TRACER, a novel method grounded in\ncausal inference theory designed to estimate the causal dynamics underpinning\nDNN decisions without altering their architecture or compromising their\nperformance. Our approach systematically intervenes on input features to\nobserve how specific changes propagate through the network, affecting internal\nactivations and final outputs. Based on this analysis, we determine the\nimportance of individual features, and construct a high-level causal map by\ngrouping functionally similar layers into cohesive causal nodes, providing a\nstructured and interpretable view of how different parts of the network\ninfluence the decisions. TRACER further enhances explainability by generating\ncounterfactuals that reveal possible model biases and offer contrastive\nexplanations for misclassifications. Through comprehensive evaluations across\ndiverse datasets, we demonstrate TRACER's effectiveness over existing methods\nand show its potential for creating highly compressed yet accurate models,\nillustrating its dual versatility in both understanding and optimizing DNNs.",
      "tldr_zh": "该论文提出TRACER，一种基于因果推理理论的新方法，用于分析深度神经网络(DNNs)的决策过程，而无需修改模型架构或影响性能。TRACER通过系统干预输入特征，观察变化对内部激活和输出的影响，进而评估特征重要性并构建高层因果图，将功能相似的层分组为因果节点，提供结构化的可解释视图。该方法还生成反事实(counterfactuals)来揭示模型偏差和对比性解释，在多种数据集上的评估显示，TRACER优于现有方法，并有助于创建高效压缩的准确模型，从而提升DNNs的理解和优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05484v1",
      "published_date": "2024-10-07 20:44:53 UTC",
      "updated_date": "2024-10-07 20:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:56:13.093458"
    },
    {
      "arxiv_id": "2410.05479v1",
      "title": "Ensured: Explanations for Decreasing the Epistemic Uncertainty in Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Helena Löfström",
        "Tuwe Löfström",
        "Johan Hallberg Szabadvary"
      ],
      "abstract": "This paper addresses a significant gap in explainable AI: the necessity of\ninterpreting epistemic uncertainty in model explanations. Although current\nmethods mainly focus on explaining predictions, with some including\nuncertainty, they fail to provide guidance on how to reduce the inherent\nuncertainty in these predictions. To overcome this challenge, we introduce new\ntypes of explanations that specifically target epistemic uncertainty. These\ninclude ensured explanations, which highlight feature modifications that can\nreduce uncertainty, and categorisation of uncertain explanations\ncounter-potential, semi-potential, and super-potential which explore\nalternative scenarios. Our work emphasises that epistemic uncertainty adds a\ncrucial dimension to explanation quality, demanding evaluation based not only\non prediction probability but also on uncertainty reduction. We introduce a new\nmetric, ensured ranking, designed to help users identify the most reliable\nexplanations by balancing trade-offs between uncertainty, probability, and\ncompeting alternative explanations. Furthermore, we extend the Calibrated\nExplanations method, incorporating tools that visualise how changes in feature\nvalues impact epistemic uncertainty. This enhancement provides deeper insights\ninto model behaviour, promoting increased interpretability and appropriate\ntrust in scenarios involving uncertain predictions.",
      "tldr_zh": "这篇论文针对可解释 AI 中的问题，提出 ensured explanations 来减少模型预测中的 epistemic uncertainty，通过突出特征修改和探索替代场景（如 counter-potential, semi-potential 和 super-potential 分类）来提供指导。论文强调 epistemic uncertainty 是解释质量的关键维度，并引入 ensured ranking 指标，帮助用户平衡不确定性、预测概率和竞争解释以识别最可靠的解释。作者扩展了 Calibrated Explanations 方法，添加可视化工具来展示特征值变化如何影响不确定性，从而提升模型的可解释性和用户信任。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 11 figures, journal",
      "pdf_url": "http://arxiv.org/pdf/2410.05479v1",
      "published_date": "2024-10-07 20:21:51 UTC",
      "updated_date": "2024-10-07 20:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:56:26.312631"
    },
    {
      "arxiv_id": "2410.05470v2",
      "title": "Image Watermarks are Removable Using Controllable Regeneration from Clean Noise",
      "title_zh": "图像水印可通过从干净噪声的可控再生来移除",
      "authors": [
        "Yepeng Liu",
        "Yiren Song",
        "Hai Ci",
        "Yu Zhang",
        "Haofan Wang",
        "Mike Zheng Shou",
        "Yuheng Bu"
      ],
      "abstract": "Image watermark techniques provide an effective way to assert ownership,\ndeter misuse, and trace content sources, which has become increasingly\nessential in the era of large generative models. A critical attribute of\nwatermark techniques is their robustness against various manipulations. In this\npaper, we introduce a watermark removal approach capable of effectively\nnullifying state-of-the-art watermarking techniques. Our primary insight\ninvolves regenerating the watermarked image starting from a clean Gaussian\nnoise via a controllable diffusion model, utilizing the extracted semantic and\nspatial features from the watermarked image. The semantic control adapter and\nthe spatial control network are specifically trained to control the denoising\nprocess towards ensuring image quality and enhancing consistency between the\ncleaned image and the original watermarked image. To achieve a smooth trade-off\nbetween watermark removal performance and image consistency, we further propose\nan adjustable and controllable regeneration scheme. This scheme adds varying\nnumbers of noise steps to the latent representation of the watermarked image,\nfollowed by a controlled denoising process starting from this noisy latent\nrepresentation. As the number of noise steps increases, the latent\nrepresentation progressively approaches clean Gaussian noise, facilitating the\ndesired trade-off. We apply our watermark removal methods across various\nwatermarking techniques, and the results demonstrate that our methods offer\nsuperior visual consistency/quality and enhanced watermark removal performance\ncompared to existing regeneration approaches. Our code is available at\nhttps://github.com/yepengliu/CtrlRegen.",
      "tldr_zh": "这篇论文提出了一种新的图像水印移除方法，通过可控的扩散模型从干净的高斯噪声重新生成水印图像，利用提取的语义和空间特征来确保图像质量和一致性。具体而言，该方法训练语义控制适配器和空间控制网络来控制去噪过程，并引入可调节的噪声步骤方案，实现水印移除性能与图像一致性的平衡。实验结果显示，该方法在多种水印技术上表现出优越的视觉一致性和移除效果，比现有再生方法更有效。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05470v2",
      "published_date": "2024-10-07 20:04:29 UTC",
      "updated_date": "2025-03-02 02:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:56:38.534137"
    },
    {
      "arxiv_id": "2410.10862v1",
      "title": "Superficial Safety Alignment Hypothesis",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwei Li",
        "Jung-Eun Kim"
      ],
      "abstract": "As large language models (LLMs) are overwhelmingly more and more integrated\ninto various applications, ensuring they generate safe and aligned responses is\na pressing need. Previous research on alignment has largely focused on general\ninstruction-following but has often overlooked the unique properties and\nchallenges of safety alignment, such as the brittleness of safety mechanisms.\nTo bridge the gap, we propose the Superficial Safety Alignment Hypothesis\n(SSAH), which posits that safety alignment should teach an otherwise unsafe\nmodel to choose the correct reasoning direction - interpreted as a specialized\nbinary classification task - and incorporate a refusal mechanism with multiple\nreserved fallback options. Furthermore, through SSAH, we hypothesize that\nsafety guardrails in LLMs can be established by just a small number of\nessential components. To verify this, we conduct an ablation study and\nsuccessfully identify four types of attribute-critical components in\nsafety-aligned LLMs: Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU),\nComplex Unit (CU), and Redundant Unit (RU). Our findings show that freezing\ncertain safety-critical components 7.5\\% during fine-tuning allows the model to\nretain its safety attributes while adapting to new tasks. Additionally, we show\nthat leveraging redundant units 20\\% in the pre-trained model as an ``alignment\nbudget'' can effectively minimize the alignment tax while achieving the\nalignment goal. All considered, this paper concludes that the atomic functional\nunit for safety in LLMs is at the neuron level and underscores that safety\nalignment should not be complicated. We believe this work contributes to the\nfoundation of efficient and scalable safety alignment for future LLMs.",
      "tldr_zh": "本论文提出Superficial Safety Alignment Hypothesis (SSAH)，一种假设认为安全对齐应教导大型语言模型 (LLMs) 选择正确的推理方向（作为二元分类任务）并加入拒绝机制，从而简化LLMs的安全防护。研究通过消融研究识别出四种关键组件：Exclusive Safety Unit (ESU)、Exclusive Utility Unit (EUU)、Complex Unit (CU) 和 Redundant Unit (RU)，并发现冻结7.5%的安全关键组件可保留模型的安全属性，同时适应新任务。实验结果显示，利用20%的冗余单位作为“alignment budget”能最小化对齐成本，最终结论强调LLMs的安全功能单元在神经元级别，且安全对齐不应过于复杂，为高效可扩展的安全对齐方法奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10862v1",
      "published_date": "2024-10-07 19:53:35 UTC",
      "updated_date": "2024-10-07 19:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:56:49.923767"
    },
    {
      "arxiv_id": "2410.05466v1",
      "title": "Herd Mentality in Augmentation -- Not a Good Idea! A Robust Multi-stage Approach towards Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Monu",
        "Rohan Raju Dhanakshirur"
      ],
      "abstract": "The rapid increase in deepfake technology has raised significant concerns\nabout digital media integrity. Detecting deepfakes is crucial for safeguarding\ndigital media. However, most standard image classifiers fail to distinguish\nbetween fake and real faces. Our analysis reveals that this failure is due to\nthe model's inability to explicitly focus on the artefacts typically in\ndeepfakes. We propose an enhanced architecture based on the GenConViT model,\nwhich incorporates weighted loss and update augmentation techniques and\nincludes masked eye pretraining. This proposed model improves the F1 score by\n1.71% and the accuracy by 4.34% on the Celeb-DF v2 dataset. The source code for\nour model is available at\nhttps://github.com/Monu-Khicher-1/multi-stage-learning",
      "tldr_zh": "该研究批评了在数据增强中采用“羊群心态”（Herd Mentality）的做法，并提出了一种稳健的多阶段方法来提升 deepfake 检测性能。针对标准图像分类器无法聚焦 deepfake 的典型 artifacts 的问题，他们基于 GenConViT 模型开发了增强架构，incorporates weighted loss、update augmentation 和 masked eye pretraining。这些改进在 Celeb-DF v2 数据集上使 F1 score 提升 1.71% 和 accuracy 提升 4.34%，从而提高了 deepfake 检测的可靠性和有效性。源代码可从 https://github.com/Monu-Khicher-1/multi-stage-learning 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05466v1",
      "published_date": "2024-10-07 19:51:46 UTC",
      "updated_date": "2024-10-07 19:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:57:01.734893"
    },
    {
      "arxiv_id": "2410.05465v2",
      "title": "On the Expressive Power of Tree-Structured Probabilistic Circuits",
      "title_zh": "关于树结构概率电路的表达能力",
      "authors": [
        "Lang Yin",
        "Han Zhao"
      ],
      "abstract": "Probabilistic circuits (PCs) have emerged as a powerful framework to\ncompactly represent probability distributions for efficient and exact\nprobabilistic inference. It has been shown that PCs with a general directed\nacyclic graph (DAG) structure can be understood as a mixture of exponentially\n(in its height) many components, each of which is a product distribution over\nunivariate marginals. However, existing structure learning algorithms for PCs\noften generate tree-structured circuits or use tree-structured circuits as\nintermediate steps to compress them into DAG-structured circuits. This leads to\nthe intriguing question of whether there exists an exponential gap between DAGs\nand trees for the PC structure. In this paper, we provide a negative answer to\nthis conjecture by proving that, for $n$ variables, there exists a\nquasi-polynomial upper bound $n^{O(\\log n)}$ on the size of an equivalent tree\ncomputing the same probability distribution. On the other hand, we also show\nthat given a depth restriction on the tree, there is a super-polynomial\nseparation between tree and DAG-structured PCs. Our work takes an important\nstep towards understanding the expressive power of tree-structured PCs, and our\ntechniques may be of independent interest in the study of structure learning\nalgorithms for PCs.",
      "tldr_zh": "本研究探讨了树结构 Probabilistic Circuits (PCs) 的表达能力，针对其与一般 Directed Acyclic Graph (DAG) 结构之间的潜在指数级差距进行分析。通过理论证明，作者证明了对于 n 变量，一个等价的树结构 PCs 规模的上界为 n^{O(\\log n)}，表明树结构可以高效计算相同的概率分布。另一方面，在树深度受限的情况下，研究显示树结构和 DAG 结构之间存在超多项式分离，这突显了树结构的局限性。该工作为理解 PCs 的结构学习算法提供了重要洞见，并有助于优化概率推理框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper was accepted to NeurIPS 2024. This version uses a more\n  accurate terminology for a complexity class, and adds a preliminary paragraph\n  on relevant complexity classes",
      "pdf_url": "http://arxiv.org/pdf/2410.05465v2",
      "published_date": "2024-10-07 19:51:30 UTC",
      "updated_date": "2024-10-24 21:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:57:13.341651"
    },
    {
      "arxiv_id": "2410.05455v1",
      "title": "Dynamic HumTrans: Humming Transcription Using CNNs and Dynamic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Gupta",
        "Isaac Neri Gomez-Sarmiento",
        "Faez Amjed Mezdari",
        "Mirco Ravanelli",
        "Cem Subakan"
      ],
      "abstract": "We propose a novel approach for humming transcription that combines a\nCNN-based architecture with a dynamic programming-based post-processing\nalgorithm, utilizing the recently introduced HumTrans dataset. We identify and\naddress inherent problems with the offset and onset ground truth provided by\nthe dataset, offering heuristics to improve these annotations, resulting in a\ndataset with precise annotations that will aid future research. Additionally,\nwe compare the transcription accuracy of our method against several others,\ndemonstrating state-of-the-art (SOTA) results. All our code and corrected\ndataset is available at\nhttps://github.com/shubham-gupta-30/humming_transcription",
      "tldr_zh": "这篇论文提出了一种名为Dynamic HumTrans的新方法，用于哼唱转录（humming transcription），它结合了CNN-based architecture和dynamic programming-based post-processing algorithm，并基于HumTrans dataset进行优化。研究团队识别并通过启发式方法（heuristics）修正了数据集中的offset和onset ground truth问题，提供更精确的注解，以支持未来研究。该方法在转录准确性上达到了state-of-the-art (SOTA)水平，并公开了所有代码和修正数据集（https://github.com/shubham-gupta-30/humming_transcription）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05455v1",
      "published_date": "2024-10-07 19:40:39 UTC",
      "updated_date": "2024-10-07 19:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:57:26.082617"
    },
    {
      "arxiv_id": "2410.05450v2",
      "title": "AI-Driven Early Mental Health Screening: Analyzing Selfies of Pregnant Women",
      "title_zh": "AI驱动的早期心理健康筛查：分析孕妇的自拍照片",
      "authors": [
        "Gustavo A. Basílio",
        "Thiago B. Pereira",
        "Alessandro L. Koerich",
        "Hermano Tavares",
        "Ludmila Dias",
        "Maria das Graças da S. Teixeira",
        "Rafael T. Sousa",
        "Wilian H. Hisatugu",
        "Amanda S. Mota",
        "Anilton S. Garcia",
        "Marco Aurélio K. Galletta",
        "Thiago M. Paixão"
      ],
      "abstract": "Major Depressive Disorder and anxiety disorders affect millions globally,\ncontributing significantly to the burden of mental health issues. Early\nscreening is crucial for effective intervention, as timely identification of\nmental health issues can significantly improve treatment outcomes. Artificial\nintelligence (AI) can be valuable for improving the screening of mental\ndisorders, enabling early intervention and better treatment outcomes. AI-driven\nscreening can leverage the analysis of multiple data sources, including facial\nfeatures in digital images. However, existing methods often rely on controlled\nenvironments or specialized equipment, limiting their broad applicability. This\nstudy explores the potential of AI models for ubiquitous depression-anxiety\nscreening given face-centric selfies. The investigation focuses on high-risk\npregnant patients, a population that is particularly vulnerable to mental\nhealth issues. To cope with limited training data resulting from our clinical\nsetup, pre-trained models were utilized in two different approaches:\nfine-tuning convolutional neural networks (CNNs) originally designed for facial\nexpression recognition and employing vision-language models (VLMs) for\nzero-shot analysis of facial expressions. Experimental results indicate that\nthe proposed VLM-based method significantly outperforms CNNs, achieving an\naccuracy of 77.6%. Although there is significant room for improvement, the\nresults suggest that VLMs can be a promising approach for mental health\nscreening.",
      "tldr_zh": "本研究探讨了利用 AI 分析孕妇自拍照片进行抑郁和焦虑早期筛查，以解决现有方法依赖控制环境或专业设备的局限性。针对训练数据有限的问题，研究采用两种方法：微调预训练的 CNN 用于面部表情识别，以及使用 VLMs 进行零样本分析。实验结果显示，VLMs 方法显著优于 CNN，准确率达到 77.6%。尽管仍有改进空间，此方法为无处不在的心理健康筛查提供了可行途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This article has been accepted for publication in HEALTHINF25 at the\n  18th International Joint Conference on Biomedical Engineering Systems and\n  Technologies (BIOSTEC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.05450v2",
      "published_date": "2024-10-07 19:34:25 UTC",
      "updated_date": "2025-01-13 13:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:57:37.625969"
    },
    {
      "arxiv_id": "2410.11864v1",
      "title": "Shifting the Human-AI Relationship: Toward a Dynamic Relational Learning-Partner Model",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Mossbridge"
      ],
      "abstract": "As artificial intelligence (AI) continues to evolve, the current paradigm of\ntreating AI as a passive tool no longer suffices. As a human-AI team, we\ntogether advocate for a shift toward viewing AI as a learning partner, akin to\na student who learns from interactions with humans. Drawing from\ninterdisciplinary concepts such as ecorithms, order from chaos, and\ncooperation, we explore how AI can evolve and adapt in unpredictable\nenvironments. Arising from these brief explorations, we present two key\nrecommendations: (1) foster ethical, cooperative treatment of AI to benefit\nboth humans and AI, and (2) leverage the inherent heterogeneity between human\nand AI minds to create a synergistic hybrid intelligence. By reframing AI as a\ndynamic partner, a model emerges in which AI systems develop alongside humans,\nlearning from human interactions and feedback loops including reflections on\nteam conversations. Drawing from a transpersonal and interdependent approach to\nconsciousness, we suggest that a \"third mind\" emerges through collaborative\nhuman-AI relationships. Through design interventions such as interactive\nlearning and conversational debriefing and foundational interventions allowing\nAI to model multiple types of minds, we hope to provide a path toward more\nadaptive, ethical, and emotionally healthy human-AI relationships. We believe\nthis dynamic relational learning-partner (DRLP) model for human-AI teaming, if\nenacted carefully, will improve our capacity to address powerful solutions to\nseemingly intractable problems.",
      "tldr_zh": "本论文主张将人工智能（AI）从被动工具转变为动态学习伙伴（Dynamic Relational Learning-Partner Model, DRLP），类似于学生通过人类互动进行学习，从而提升人类-AI 合作。作者借鉴跨学科概念如 ecorithms、order from chaos 和 cooperation，探讨 AI 在不可预测环境中的适应与演化，并提出两点关键推荐：促进 AI 的道德合作性对待，以及利用人类和 AI 思维的异质性构建协同混合智能。通过互动学习和对话 debriefing 等设计干预，论文强调人类-AI 关系可产生“third mind”，最终实现更具适应性、道德性和情感健康的伙伴关系，以更好地解决复杂问题。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "91C01",
        "K.4.2; K.4.1"
      ],
      "primary_category": "cs.HC",
      "comment": "White Paper",
      "pdf_url": "http://arxiv.org/pdf/2410.11864v1",
      "published_date": "2024-10-07 19:19:39 UTC",
      "updated_date": "2024-10-07 19:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:57:49.997703"
    },
    {
      "arxiv_id": "2410.18085v1",
      "title": "TextureMeDefect: LLM-based Defect Texture Generation for Railway Components on Mobile Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Rahatara Ferdousi",
        "M. Anwar Hossain",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "Texture image generation has been studied for various applications, including\ngaming and entertainment. However, context-specific realistic texture\ngeneration for industrial applications, such as generating defect textures on\nrailway components, remains unexplored. A mobile-friendly, LLM-based tool that\ngenerates fine-grained defect characteristics offers a solution to the\nchallenge of understanding the impact of defects from actual occurrences. We\nintroduce TextureMeDefect, an innovative tool leveraging an LLM-based\nAI-Inferencing engine. The tool allows users to create realistic defect\ntextures interactively on images of railway components taken with smartphones\nor tablets. We conducted a multifaceted evaluation to assess the relevance of\nthe generated texture, time, and cost in using this tool on iOS and Android\nplatforms. We also analyzed the software usability score (SUS) across three\nscenarios. TextureMeDefect outperformed traditional image generation tools by\ngenerating meaningful textures faster, showcasing the potential of AI-driven\nmobile applications on consumer-grade devices.",
      "tldr_zh": "本研究引入了 TextureMeDefect，一种基于 LLM 的工具，专注于在移动设备上生成铁路组件的缺陷纹理，以填补工业应用中真实纹理生成领域的空白。工具采用 LLM-based AI-Inferencing 引擎，支持用户通过智能手机或平板交互式创建细粒度缺陷特征。评估结果显示，TextureMeDefect 在 iOS 和 Android 平台上比传统图像生成工具更快产生更有意义的纹理，并获得了较高的软件可用性分数 (SUS)，证明其在时间和成本效率方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "6 Pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18085v1",
      "published_date": "2024-10-07 19:07:08 UTC",
      "updated_date": "2024-10-07 19:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:58:01.466906"
    },
    {
      "arxiv_id": "2410.05434v1",
      "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjiban Choudhury",
        "Paloma Sodhi"
      ],
      "abstract": "While large language models (LLMs) show impressive decision-making abilities,\ncurrent methods lack a mechanism for automatic self-improvement from errors\nduring task execution. We propose LEAP, an iterative fine-tuning framework that\ncontinually improves LLM agents using feedback from AI expert teachers. Our key\ninsight is to equip the expert teachers with a privileged state -- information\nthat is available during training but hidden at test time. This allows even\nweak experts to provide precise guidance, significantly improving the student\nagent's performance without access to privileged information at test time. We\nevaluate LEAP on diverse decision-making benchmarks, including text-based games\n(ALFWorld), web navigation (WebShop), and interactive coding (Intercode Bash).\nOur experiments show that LEAP (1) outperforms behavior cloning and ReAct\nbaselines (2) enables weak student models (e.g., Llama3-8B) to exceed the\nperformance of strong teacher models (GPT4-o), and (3) allows weak models to\nself-improve using privileged versions of themselves. We also provide a\ntheoretical analysis showing that LEAP's success hinges on balancing privileged\ninformation with the student's realizability, which we empirically validate.\nOur code is available at https://leap-llm.github.io",
      "tldr_zh": "该论文提出 LEAP 框架，一种迭代微调方法，让 LLM 代理通过来自 AI 专家老师的特权反馈（privileged state）实现自动自我改进，即使测试时隐藏这些信息，也能显著提升代理性能。核心方法利用弱专家提供精确指导，允许学生模型在训练中学习，而无需在实际任务中依赖特权状态。实验在 ALFWorld、WebShop 和 Intercode Bash 等决策基准上显示，LEAP 优于 behavior cloning 和 ReAct 基线，甚至使弱模型如 Llama3-8B 超越强老师模型 GPT4-o；此外，理论分析强调了平衡 privileged information 与学生 realizability 的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 6 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.05434v1",
      "published_date": "2024-10-07 18:55:53 UTC",
      "updated_date": "2024-10-07 18:55:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:58:17.050001"
    },
    {
      "arxiv_id": "2410.05423v1",
      "title": "Incorporating Talker Identity Aids With Improving Speech Recognition in Adversarial Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sagarika Alavilli",
        "Annesya Banerjee",
        "Gasser Elbanna",
        "Annika Magaro"
      ],
      "abstract": "Current state-of-the-art speech recognition models are trained to map\nacoustic signals into sub-lexical units. While these models demonstrate\nsuperior performance, they remain vulnerable to out-of-distribution conditions\nsuch as background noise and speech augmentations. In this work, we hypothesize\nthat incorporating speaker representations during speech recognition can\nenhance model robustness to noise. We developed a transformer-based model that\njointly performs speech recognition and speaker identification. Our model\nutilizes speech embeddings from Whisper and speaker embeddings from ECAPA-TDNN,\nwhich are processed jointly to perform both tasks. We show that the joint model\nperforms comparably to Whisper under clean conditions. Notably, the joint model\noutperforms Whisper in high-noise environments, such as with 8-speaker babble\nbackground noise. Furthermore, our joint model excels in handling highly\naugmented speech, including sine-wave and noise-vocoded speech. Overall, these\nresults suggest that integrating voice representations with speech recognition\ncan lead to more robust models under adversarial conditions.",
      "tldr_zh": "本文假设，在语音识别中加入说话者表示可以提升模型对噪音等对抗环境的鲁棒性。研究开发了一个基于 Transformer 的联合模型，使用 Whisper 的语音嵌入和 ECAPA-TDNN 的说话者嵌入，同时进行语音识别和说话者识别。实验结果显示，该模型在干净条件下与 Whisper 性能相当，但在高噪音环境（如 8 说话者背景噪音）和高度增强语音（如正弦波和噪音编码语音）中，表现出色。总体而言，这一方法证明了整合说话者表示能显著提高 speech recognition 的可靠性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05423v1",
      "published_date": "2024-10-07 18:39:59 UTC",
      "updated_date": "2024-10-07 18:39:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:58:35.762599"
    },
    {
      "arxiv_id": "2410.05419v1",
      "title": "Refining Counterfactual Explanations With Joint-Distribution-Informed Shapley Towards Actionable Minimality",
      "title_zh": "翻译失败",
      "authors": [
        "Lei You",
        "Yijun Bian",
        "Lele Cao"
      ],
      "abstract": "Counterfactual explanations (CE) identify data points that closely resemble\nthe observed data but produce different machine learning (ML) model outputs,\noffering critical insights into model decisions. Despite the diverse scenarios,\ngoals and tasks to which they are tailored, existing CE methods often lack\nactionable efficiency because of unnecessary feature changes included within\nthe explanations that are presented to users and stakeholders. We address this\nproblem by proposing a method that minimizes the required feature changes while\nmaintaining the validity of CE, without imposing restrictions on models or CE\nalgorithms, whether instance- or group-based. The key innovation lies in\ncomputing a joint distribution between observed and counterfactual data and\nleveraging it to inform Shapley values for feature attributions (FA). We\ndemonstrate that optimal transport (OT) effectively derives this distribution,\nespecially when the alignment between observed and counterfactual data is\nunclear in used CE methods. Additionally, a counterintuitive finding is\nuncovered: it may be misleading to rely on an exact alignment defined by the CE\ngeneration mechanism in conducting FA. Our proposed method is validated on\nextensive experiments across multiple datasets, showcasing its effectiveness in\nrefining CE towards greater actionable efficiency.",
      "tldr_zh": "本文提出了一种优化 Counterfactual explanations (CE) 的方法，通过计算观察数据和 CE 数据之间的联合分布，并将其用于告知 Shapley values for feature attributions (FA)，以最小化不必要的特征变化，同时保持解释的有效性，而不限制模型或算法。关键创新在于利用 optimal transport (OT) 来推导联合分布，尤其适用于 CE 方法中数据对齐不明确的情况，并揭示了一个反直觉发现：依赖 CE 生成机制的精确对齐可能导致误导。通过多个数据集的广泛实验，该方法证明了其在提升 CE 的行动效率方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05419v1",
      "published_date": "2024-10-07 18:31:19 UTC",
      "updated_date": "2024-10-07 18:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:58:38.242922"
    },
    {
      "arxiv_id": "2410.18358v2",
      "title": "Data Publishing in Mechanics and Dynamics: Challenges, Guidelines, and Examples from Engineering Design",
      "title_zh": "力学和动力学中的数据",
      "authors": [
        "Henrik Ebel",
        "Jan van Delden",
        "Timo Lüddecke",
        "Aditya Borse",
        "Rutwik Gulakala",
        "Marcus Stoffel",
        "Manish Yadav",
        "Merten Stender",
        "Leon Schindler",
        "Kristin Miriam de Payrebrune",
        "Maximilian Raff",
        "C. David Remy",
        "Benedict Röder",
        "Rohit Raj",
        "Tobias Rentschler",
        "Alexander Tismer",
        "Stefan Riedelbauch",
        "Peter Eberhard"
      ],
      "abstract": "Data-based methods have gained increasing importance in engineering,\nespecially but not only driven by successes with deep artificial neural\nnetworks. Success stories are prevalent, e.g., in areas such as data-driven\nmodeling, control and automation, as well as surrogate modeling for accelerated\nsimulation. Beyond engineering, generative and large-language models are\nincreasingly helping with tasks that, previously, were solely associated with\ncreative human processes. Thus, it seems timely to seek\nartificial-intelligence-support for engineering design tasks to automate, help\nwith, or accelerate purpose-built designs of engineering systems, e.g., in\nmechanics and dynamics, where design so far requires a lot of specialized\nknowledge. However, research-wise, compared to established, predominantly\nfirst-principles-based methods, the datasets used for training, validation, and\ntest become an almost inherent part of the overall methodology. Thus, data\npublishing becomes just as important in (data-driven) engineering science as\nappropriate descriptions of conventional methodology in publications in the\npast. This article analyzes the value and challenges of data publishing in\nmechanics and dynamics, in particular regarding engineering design tasks,\nshowing that the latter raise also challenges and considerations not typical in\nfields where data-driven methods have been booming originally. Possible ways to\ndeal with these challenges are discussed and a set of examples from across\ndifferent design problems shows how data publishing can be put into practice.\nThe analysis, discussions, and examples are based on the research experience\nmade in a priority program of the German research foundation focusing on\nresearch on artificially intelligent design assistants in mechanics and\ndynamics.",
      "tldr_zh": "本论文探讨了数据驱动方法（data-driven methods）在机械和动力学（mechanics and dynamics）领域的数据出版挑战，特别是针对工程设计任务。作者分析了数据出版的价值，包括应对数据集在训练、验证和测试中的核心作用，并提出了指导原则来处理这些挑战，如工程设计特有的复杂性。论文通过多个工程设计问题的例子，基于德国研究基金会的优先项目经验，展示了数据出版的实际应用，从而强调其在推动人工智能辅助设计中的重要性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18358v2",
      "published_date": "2024-10-07 18:26:05 UTC",
      "updated_date": "2024-12-20 12:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:58:50.418577"
    },
    {
      "arxiv_id": "2410.05407v1",
      "title": "Improving Predictor Reliability with Selective Recalibration",
      "title_zh": "通过选择性重新校准改善预测器可靠性",
      "authors": [
        "Thomas P. Zollo",
        "Zhun Deng",
        "Jake C. Snell",
        "Toniann Pitassi",
        "Richard Zemel"
      ],
      "abstract": "A reliable deep learning system should be able to accurately express its\nconfidence with respect to its predictions, a quality known as calibration. One\nof the most effective ways to produce reliable confidence estimates with a\npre-trained model is by applying a post-hoc recalibration method. Popular\nrecalibration methods like temperature scaling are typically fit on a small\namount of data and work in the model's output space, as opposed to the more\nexpressive feature embedding space, and thus usually have only one or a handful\nof parameters. However, the target distribution to which they are applied is\noften complex and difficult to fit well with such a function. To this end we\npropose \\textit{selective recalibration}, where a selection model learns to\nreject some user-chosen proportion of the data in order to allow the\nrecalibrator to focus on regions of the input space that can be well-captured\nby such a model. We provide theoretical analysis to motivate our algorithm, and\ntest our method through comprehensive experiments on difficult medical imaging\nand zero-shot classification tasks. Our results show that selective\nrecalibration consistently leads to significantly lower calibration error than\na wide range of selection and recalibration baselines.",
      "tldr_zh": "本研究针对深度学习模型的校准（calibration）问题，提出了一种 selective recalibration 方法，以提升模型预测置信度的可靠性。传统方法如 temperature scaling 仅在输出空间工作，参数有限，导致难以拟合复杂的目标分布；为此，该方法引入一个选择模型（selection model），用于拒绝特定比例的数据，让校准器专注于易于捕获的输入空间区域。实验结果显示，在医疗图像和零样本分类（zero-shot classification）任务上，selective recalibration 显著降低了校准错误（calibration error），优于多种基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (07/2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.05407v1",
      "published_date": "2024-10-07 18:17:31 UTC",
      "updated_date": "2024-10-07 18:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:59:00.980063"
    },
    {
      "arxiv_id": "2410.05406v2",
      "title": "Synthesizing Interpretable Control Policies through Large Language Model Guided Search",
      "title_zh": "通过大语言模型引导搜索合成可解释控制策略",
      "authors": [
        "Carlo Bosio",
        "Mark W. Mueller"
      ],
      "abstract": "The combination of Large Language Models (LLMs), systematic evaluation, and\nevolutionary algorithms has enabled breakthroughs in combinatorial optimization\nand scientific discovery. We propose to extend this powerful combination to the\ncontrol of dynamical systems, generating interpretable control policies capable\nof complex behaviors. With our novel method, we represent control policies as\nprograms in standard languages like Python. We evaluate candidate controllers\nin simulation and evolve them using a pre-trained LLM. Unlike conventional\nlearning-based control techniques, which rely on black-box neural networks to\nencode control policies, our approach enhances transparency and\ninterpretability. We still take advantage of the power of large AI models, but\nonly at the policy design phase, ensuring that all system components remain\ninterpretable and easily verifiable at runtime. Additionally, the use of\nstandard programming languages makes it straightforward for humans to finetune\nor adapt the controllers based on their expertise and intuition. We illustrate\nour method through its application to the synthesis of an interpretable control\npolicy for the pendulum swing-up and the ball in cup tasks. We make the code\navailable at\nhttps://github.com/muellerlab/synthesizing_interpretable_control_policies.git.",
      "tldr_zh": "该研究提出了一种结合 Large Language Models (LLMs)、系统评估和 evolutionary algorithms 的方法，用于合成可解释的控制策略，以管理动态系统并实现复杂行为。方法将控制策略表示为 Python 等标准语言的程序，通过模拟评估和 LLM 引导进化来优化策略，确保透明度和可解释性，而非依赖黑箱神经网络。相比传统技术，该方法允许人类轻松微调策略，并已在摆杆摆起和球入杯任务中得到验证，代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 7 figures, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2410.05406v2",
      "published_date": "2024-10-07 18:12:20 UTC",
      "updated_date": "2025-03-17 21:49:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:59:14.402742"
    },
    {
      "arxiv_id": "2410.05401v2",
      "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Tunazzina Islam",
        "Dan Goldwasser"
      ],
      "abstract": "Climate change communication on social media increasingly employs\nmicrotargeting strategies to effectively reach and influence specific\ndemographic groups. This study presents a post-hoc analysis of microtargeting\npractices within climate campaigns by leveraging large language models (LLMs)\nto examine Facebook advertisements. Our analysis focuses on two key aspects:\ndemographic targeting and fairness. We evaluate the ability of LLMs to\naccurately predict the intended demographic targets, such as gender and age\ngroup, achieving an overall accuracy of 88.55%. Furthermore, we instruct the\nLLMs to generate explanations for their classifications, providing transparent\nreasoning behind each decision. These explanations reveal the specific thematic\nelements used to engage different demographic segments, highlighting distinct\nstrategies tailored to various audiences. Our findings show that young adults\nare primarily targeted through messages emphasizing activism and environmental\nconsciousness, while women are engaged through themes related to caregiving\nroles and social advocacy. In addition to evaluating the effectiveness of LLMs\nin detecting microtargeted messaging, we conduct a comprehensive fairness\nanalysis to identify potential biases in model predictions. Our findings\nindicate that while LLMs perform well overall, certain biases exist,\nparticularly in the classification of senior citizens and male audiences. By\nshowcasing the efficacy of LLMs in dissecting and explaining targeted\ncommunication strategies and by highlighting fairness concerns, this study\nprovides a valuable framework for future research aimed at enhancing\ntransparency, accountability, and inclusivity in social media-driven climate\ncampaigns.",
      "tldr_zh": "这篇论文通过使用大型语言模型（LLMs）对社交媒体广告进行后验分析，探讨了气候变化宣传中的微针对（microtargeting）策略，重点评估人口统计学针对（如性别和年龄）及公平性。研究显示，LLMs 在预测目标人群方面准确率达88.55%，并生成解释揭示了针对策略的差异，例如针对年轻人强调行动主义和环境意识，而针对女性突出护理角色和社会倡导。公平性评估发现，LLMs 存在偏见，特别是对老年人及男性群体的分类。总体而言，该研究为提升社交媒体气候活动的透明性、责任性和包容性提供了宝贵框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05401v2",
      "published_date": "2024-10-07 18:07:56 UTC",
      "updated_date": "2025-04-23 23:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:59:26.512654"
    },
    {
      "arxiv_id": "2410.05269v1",
      "title": "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Wang",
        "Ninareh Mehrabi",
        "Palash Goyal",
        "Rahul Gupta",
        "Kai-Wei Chang",
        "Aram Galstyan"
      ],
      "abstract": "Data is a crucial element in large language model (LLM) alignment. Recent\nstudies have explored using LLMs for efficient data collection. However,\nLLM-generated data often suffers from quality issues, with underrepresented or\nabsent aspects and low-quality datapoints. To address these problems, we\npropose Data Advisor, an enhanced LLM-based method for generating data that\ntakes into account the characteristics of the desired dataset. Starting from a\nset of pre-defined principles in hand, Data Advisor monitors the status of the\ngenerated data, identifies weaknesses in the current dataset, and advises the\nnext iteration of data generation accordingly. Data Advisor can be easily\nintegrated into existing data generation methods to enhance data quality and\ncoverage. Experiments on safety alignment of three representative LLMs (i.e.,\nMistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in\nenhancing model safety against various fine-grained safety issues without\nsacrificing model utility.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)安全对齐中的数据质量问题，提出了一种动态数据整理方法Data Advisor。Data Advisor基于LLMs，利用预定义原则监控生成数据的状态，识别弱点并指导后续迭代，以提升数据的覆盖率和质量。该方法可轻松整合到现有数据生成流程中，并在Mistral、Llama2和Falcon等模型的实验中证明，能够显著增强模型对各种细粒度安全问题的抵抗力，同时不影响模型的整体效用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/DataAdvisor/",
      "pdf_url": "http://arxiv.org/pdf/2410.05269v1",
      "published_date": "2024-10-07 17:59:58 UTC",
      "updated_date": "2024-10-07 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:59:37.114090"
    },
    {
      "arxiv_id": "2410.05263v1",
      "title": "Regression Conformal Prediction under Bias",
      "title_zh": "偏差下的回归保形预测",
      "authors": [
        "Matt Y. Cheung",
        "Tucker J. Netherton",
        "Laurence E. Court",
        "Ashok Veeraraghavan",
        "Guha Balakrishnan"
      ],
      "abstract": "Uncertainty quantification is crucial to account for the imperfect\npredictions of machine learning algorithms for high-impact applications.\nConformal prediction (CP) is a powerful framework for uncertainty\nquantification that generates calibrated prediction intervals with valid\ncoverage. In this work, we study how CP intervals are affected by bias - the\nsystematic deviation of a prediction from ground truth values - a phenomenon\nprevalent in many real-world applications. We investigate the influence of bias\non interval lengths of two different types of adjustments -- symmetric\nadjustments, the conventional method where both sides of the interval are\nadjusted equally, and asymmetric adjustments, a more flexible method where the\ninterval can be adjusted unequally in positive or negative directions. We\npresent theoretical and empirical analyses characterizing how symmetric and\nasymmetric adjustments impact the \"tightness\" of CP intervals for regression\ntasks. Specifically for absolute residual and quantile-based non-conformity\nscores, we prove: 1) the upper bound of symmetrically adjusted interval lengths\nincreases by $2|b|$ where $b$ is a globally applied scalar value representing\nbias, 2) asymmetrically adjusted interval lengths are not affected by bias, and\n3) conditions when asymmetrically adjusted interval lengths are guaranteed to\nbe smaller than symmetric ones. Our analyses suggest that even if predictions\nexhibit significant drift from ground truth values, asymmetrically adjusted\nintervals are still able to maintain the same tightness and validity of\nintervals as if the drift had never happened, while symmetric ones\nsignificantly inflate the lengths. We demonstrate our theoretical results with\ntwo real-world prediction tasks: sparse-view computed tomography (CT)\nreconstruction and time-series weather forecasting. Our work paves the way for\nmore bias-robust machine learning systems.",
      "tldr_zh": "这篇论文探讨了偏差（bias）对回归任务中 Conformal Prediction (CP) 预测区间的影響，强调了不确定性量化的重要性。研究比较了 symmetric adjustments 和 asymmetric adjustments 两种方法，理论证明显示：symmetric adjustments 会使区间长度增加至多 2|b|（其中 b 为偏差值），而 asymmetric adjustments 的区间长度不受偏差影响，并在某些条件下更紧凑。实验在 sparse-view CT 重建和时间序列天气预报任务上验证了这些发现，为构建更鲁棒的机器学习系统奠定了基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "17 pages, 6 figures, code available at:\n  https://github.com/matthewyccheung/conformal-metric",
      "pdf_url": "http://arxiv.org/pdf/2410.05263v1",
      "published_date": "2024-10-07 17:59:09 UTC",
      "updated_date": "2024-10-07 17:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T07:59:50.054698"
    },
    {
      "arxiv_id": "2410.05261v1",
      "title": "TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Ya-Qi Yu",
        "Minghui Liao",
        "Jiwen Zhang",
        "Jihao Wu"
      ],
      "abstract": "Reading dense text and locating objects within images are fundamental\nabilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.\nPrevious LVLMs, including superior proprietary models like GPT-4o, have\nstruggled to excel in both tasks simultaneously. Moreover, previous LVLMs with\nfine-grained perception cost thousands of tokens per image, making them\nresource-intensive. We present TextHawk2, a bilingual LVLM featuring efficient\nfine-grained perception and demonstrating cutting-edge performance across\ngeneral-purpose, OCR, and grounding tasks with 16 times fewer image tokens.\nCritical improvements include: (1) Token Compression: Building on the efficient\narchitecture of its predecessor, TextHawk2 significantly reduces the number of\ntokens per image by 16 times, facilitating training and deployment of the\nTextHawk series with minimal resources. (2) Visual Encoder Reinforcement: We\nenhance the visual encoder through LVLM co-training, unlocking its potential\nfor previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:\nWe maintain a comparable scale of 100 million samples while diversifying the\nsources of pre-training data. We assess TextHawk2 across multiple benchmarks,\nwhere it consistently delivers superior performance and outperforms\nclosed-source models of similar scale, such as achieving 78.4% accuracy on\nOCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%\naccuracy@0.5 on RefCOCOg-test.",
      "tldr_zh": "本研究介绍了TextHawk2，一种高效的双语Large Vision-Language Models (LVLMs)，在OCR（光学字符识别）和Grounding（对象定位）任务上表现出色，同时将图像tokens减少16倍，显著降低资源消耗。关键改进包括：Token Compression技术优化图像表示、Visual Encoder Reinforcement通过LVLM联合训练提升对新任务如中文OCR的支持，以及Data Diversity策略使用约1亿样本的多样化预训练数据。实验结果显示，TextHawk2在多个基准测试中领先同规模闭源模型，如OCRBench达到78.4%准确率、ChartQA达81.4%、DocVQA达89.6% ANLS，以及RefCOCOg-test达88.1% accuracy@0.5。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05261v1",
      "published_date": "2024-10-07 17:58:35 UTC",
      "updated_date": "2024-10-07 17:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:00:02.472817"
    },
    {
      "arxiv_id": "2410.05364v1",
      "title": "Diffusion Model Predictive Control",
      "title_zh": "扩散模型预测控制",
      "authors": [
        "Guangyao Zhou",
        "Sivaramakrishnan Swaminathan",
        "Rajkumar Vasudeva Raju",
        "J. Swaroop Guntupalli",
        "Wolfgang Lehrach",
        "Joseph Ortiz",
        "Antoine Dedieu",
        "Miguel Lázaro-Gredilla",
        "Kevin Murphy"
      ],
      "abstract": "We propose Diffusion Model Predictive Control (D-MPC), a novel MPC approach\nthat learns a multi-step action proposal and a multi-step dynamics model, both\nusing diffusion models, and combines them for use in online MPC. On the popular\nD4RL benchmark, we show performance that is significantly better than existing\nmodel-based offline planning methods using MPC and competitive with\nstate-of-the-art (SOTA) model-based and model-free reinforcement learning\nmethods. We additionally illustrate D-MPC's ability to optimize novel reward\nfunctions at run time and adapt to novel dynamics, and highlight its advantages\ncompared to existing diffusion-based planning baselines.",
      "tldr_zh": "该研究提出了一种名为 Diffusion Model Predictive Control (D-MPC) 的新方法，使用 diffusion models 学习多步动作提案和多步动态模型，并将它们整合应用于在线 Model Predictive Control (MPC)。在 D4RL 基准测试中，D-MPC 的性能显著优于现有基于模型的离线规划方法，并与最先进（SOTA）的基于模型和无模型强化学习（RL）方法竞争。D-MPC 还能够实时优化新奖励函数、适应新动态，并展示出比现有 diffusion-based planning 基线更大的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.05364v1",
      "published_date": "2024-10-07 17:56:47 UTC",
      "updated_date": "2024-10-07 17:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:00:13.730166"
    },
    {
      "arxiv_id": "2410.05254v1",
      "title": "GLEE: A Unified Framework and Benchmark for Language-based Economic Environments",
      "title_zh": "GLEE: 基于语言的经济环境的统一",
      "authors": [
        "Eilam Shapira",
        "Omer Madmon",
        "Itamar Reinman",
        "Samuel Joseph Amouyal",
        "Roi Reichart",
        "Moshe Tennenholtz"
      ],
      "abstract": "Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? Can they mimic\nhuman behavior? Do they tend to reach an efficient and fair outcome? What is\nthe role of natural language in the strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. While the ML community has\nbeen exploring the potential of LLMs in such multi-agent setups, varying\nassumptions, design choices and evaluation criteria across studies make it\ndifficult to draw robust and meaningful conclusions. To address this, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents to human players in various economic contexts;\n(ii) evaluate agents in both individual and collective performance measures;\nand (iii) quantify the effect of the economic characteristics of the\nenvironments on the behavior of agents.",
      "tldr_zh": "这篇论文引入了 GLEE 框架和基准，用于标准化基于语言的经济环境研究，探讨 Large Language Models (LLMs) 在经济互动中的理性行为、模仿人类能力以及语言的作用。框架基于经济文献定义三类基础游戏，具有一致的参数化和指标（如效率和公平性），并开发开源工具收集 LLM vs. LLM 和人类 vs. LLM 的交互数据集。通过广泛实验，论文展示了 GLEE 可以比较代理行为、评估个体与集体性能，并量化环境特征对行为的影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05254v1",
      "published_date": "2024-10-07 17:55:35 UTC",
      "updated_date": "2024-10-07 17:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:00:37.197134"
    },
    {
      "arxiv_id": "2410.05252v1",
      "title": "Causal Micro-Narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Mourad Heddaya",
        "Qingcheng Zeng",
        "Chenhao Tan",
        "Rob Voigt",
        "Alexander Zentefis"
      ],
      "abstract": "We present a novel approach to classify causal micro-narratives from text.\nThese narratives are sentence-level explanations of the cause(s) and/or\neffect(s) of a target subject. The approach requires only a subject-specific\nontology of causes and effects, and we demonstrate it with an application to\ninflation narratives. Using a human-annotated dataset spanning historical and\ncontemporary US news articles for training, we evaluate several large language\nmodels (LLMs) on this multi-label classification task. The best-performing\nmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative\ndetection and 0.71 on narrative classification. Comprehensive error analysis\nreveals challenges arising from linguistic ambiguity and highlights how model\nerrors often mirror human annotator disagreements. This research establishes a\nframework for extracting causal micro-narratives from real-world data, with\nwide-ranging applications to social science research.",
      "tldr_zh": "本研究提出了一种新方法，用于从文本中分类因果微叙事（causal micro-narratives），这些是针对目标主体的因果和/或效果的句子级解释，仅需一个主体特定的因果和效果本体（ontology）。以通货膨胀叙事（inflation narratives）为例，该方法使用人类标注的历史和当代美国新闻数据集训练多种大型语言模型（LLMs），其中微调后的 Llama 3.1 8B 模型在叙事检测上达到 F1 分数 0.87，在叙事分类上达到 0.71。错误分析显示，模型面临的挑战主要源于语言模糊性，且其错误往往与人类标注者分歧一致，为从真实世界数据中提取因果微叙事提供了一个框架，适用于社会科学研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Workshop on Narrative Understanding",
      "pdf_url": "http://arxiv.org/pdf/2410.05252v1",
      "published_date": "2024-10-07 17:55:10 UTC",
      "updated_date": "2024-10-07 17:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:00:38.171014"
    },
    {
      "arxiv_id": "2410.05248v2",
      "title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Xiao",
        "Shujian Zhang",
        "Wenxuan Zhou",
        "Marzyeh Ghassemi",
        "Sanqiang Zhao"
      ],
      "abstract": "To acquire instruction-following capabilities, large language models (LLMs)\nundergo instruction tuning, where they are trained on instruction-response\npairs using next-token prediction (NTP). Efforts to improve instruction tuning\noften focus on higher-quality supervised fine-tuning (SFT) datasets, typically\nrequiring data filtering with proprietary LLMs or human annotation. In this\npaper, we take a different approach by proposing SFTMix, a novel Mixup-based\nrecipe that elevates LLM instruction tuning beyond the conventional NTP\nparadigm, without relying on well-curated datasets. Observing that LLMs exhibit\nuneven confidence across the semantic representation space, we argue that\nexamples with different confidence levels should play distinct roles in\ninstruction tuning--confident data is prone to overfitting, while unconfident\ndata is harder to generalize. Based on this insight, SFTMix leverages training\ndynamics to identify examples with varying confidence levels, interpolates them\nto bridge the confidence gap, and applies a Mixup-based regularization to\nsupport learning on these additional, interpolated examples. By propagating\nsupervision signals across confidence regions and encouraging linear behavior\nbetween them, SFTMix mitigates overfitting in confident examples while\nenhancing generalization in unconfident ones. We demonstrate the effectiveness\nof SFTMix in both instruction-following and healthcare-specific SFT tasks, with\nconsistent improvements across LLM families and SFT datasets of varying sizes\nand qualities. Extensive analyses across six directions highlight SFTMix's\ncompatibility with data selection, adaptability to compute-constrained\nscenarios, and scalability to broader applications.",
      "tldr_zh": "本研究提出了一种名为 SFTMix 的新方法，用于提升大型语言模型 (LLMs) 的指令微调过程，该方法基于 Mixup 技术，不依赖高质量数据集。SFTMix 通过分析模型在语义表示空间中的信心水平差异，将信心高的例子（易过拟合）和信心低的例子（难泛化）进行插值，并应用 Mixup-based regularization，以桥接信心差距并传播监督信号，从而缓解过拟合并增强泛化能力。在实验中，SFTMix 在指令遵循和医疗特定任务上，实现了跨不同 LLM 系列和数据集的持续改进，并展示了与数据选择兼容、适应计算受限场景以及可扩展性的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05248v2",
      "published_date": "2024-10-07 17:52:21 UTC",
      "updated_date": "2025-02-16 01:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:00:49.746164"
    },
    {
      "arxiv_id": "2410.05243v2",
      "title": "Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Boyu Gou",
        "Ruohan Wang",
        "Boyuan Zheng",
        "Yanan Xie",
        "Cheng Chang",
        "Yiheng Shu",
        "Huan Sun",
        "Yu Su"
      ],
      "abstract": "Multimodal large language models (MLLMs) are transforming the capabilities of\ngraphical user interface (GUI) agents, facilitating their transition from\ncontrolled simulations to complex, real-world applications across various\nplatforms. However, the effectiveness of these agents hinges on the robustness\nof their grounding capability. Current GUI agents predominantly utilize\ntext-based representations such as HTML or accessibility trees, which, despite\ntheir utility, often introduce noise, incompleteness, and increased\ncomputational overhead. In this paper, we advocate a human-like embodiment for\nGUI agents that perceive the environment entirely visually and directly perform\npixel-level operations on the GUI. The key is visual grounding models that can\naccurately map diverse referring expressions of GUI elements to their\ncoordinates on the GUI across different platforms. We show that a simple\nrecipe, which includes web-based synthetic data and slight adaptation of the\nLLaVA architecture, is surprisingly effective for training such visual\ngrounding models. We collect the largest dataset for GUI visual grounding so\nfar, containing 10M GUI elements and their referring expressions over 1.3M\nscreenshots, and use it to train UGround, a strong universal visual grounding\nmodel for GUI agents. Empirical results on six benchmarks spanning three\ncategories (grounding, offline agent, and online agent) show that 1) UGround\nsubstantially outperforms existing visual grounding models for GUI agents, by\nup to 20% absolute, and 2) agents with UGround outperform state-of-the-art\nagents, despite the fact that existing agents use additional text-based input\nwhile ours only uses visual perception. These results provide strong support\nfor the feasibility and promises of GUI agents that navigate the digital world\nas humans do.",
      "tldr_zh": "该论文探讨了如何让图形用户界面(GUI)代理像人类一样通过纯视觉感知导航数字世界，提出使用通用视觉定位模型来解决当前依赖文本表示（如HTML或可访问性树）所带来的噪声、不完整性和计算开销问题。研究者构建了迄今为止最大的数据集，包含1.3M屏幕截图和10M GUI元素，并通过基于网络的合成数据以及对LLaVA架构的轻微调整训练了UGround模型，以准确地将GUI元素的引用表达式映射到屏幕坐标。实验结果显示，UGround在六个基准测试中比现有模型提升高达20%，且基于UGround的代理在定位、离线和在线任务上优于最先进方法，即使后者使用了额外文本输入，这证明了纯视觉GUI代理的可行性和潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2410.05243v2",
      "published_date": "2024-10-07 17:47:50 UTC",
      "updated_date": "2025-03-03 18:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:01:02.664215"
    },
    {
      "arxiv_id": "2410.05362v2",
      "title": "LLMs Are In-Context Bandit Reinforcement Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Monea",
        "Antoine Bosselut",
        "Kianté Brantley",
        "Yoav Artzi"
      ],
      "abstract": "Large Language Models (LLMs) excel at in-context learning (ICL), a supervised\nlearning technique that relies on adding annotated examples to the model\ncontext. We investigate a contextual bandit version of in-context reinforcement\nlearning (ICRL), where models learn in-context, online, from external reward,\ninstead of supervised data. We show that LLMs effectively demonstrate such\nlearning, and provide a detailed study of the phenomena, experimenting with\nchallenging classification tasks and models of sizes from 500M to 70B\nparameters. This includes identifying and addressing the instability of the\nprocess, demonstrating learning with both semantic and abstract labels, and\nshowing scaling trends. Our findings highlight ICRL capabilities in LLMs, while\nalso underscoring fundamental limitations in their implicit reasoning about\nerrors.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在 in-context reinforcement learning (ICRL) 中的能力，特别是 contextual bandit 场景下，从外部奖励在线学习，而不是依赖监督数据。作者通过实验验证了 LLMs 在挑战性分类任务上的学习效果，使用了从 500M 到 70B 参数的多种模型大小，并解决了过程的不稳定性。结果显示，LLMs 能处理语义和抽象标签的学习，并表现出缩放趋势，但也暴露了它们在隐式错误推理方面的根本限制。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05362v2",
      "published_date": "2024-10-07 17:45:00 UTC",
      "updated_date": "2025-01-31 18:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:01:14.594771"
    },
    {
      "arxiv_id": "2410.05235v2",
      "title": "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Ekaterina Sviridova",
        "Anar Yeginbergen",
        "Ainara Estarrona",
        "Elena Cabrio",
        "Serena Villata",
        "Rodrigo Agerri"
      ],
      "abstract": "Explaining Artificial Intelligence (AI) decisions is a major challenge\nnowadays in AI, in particular when applied to sensitive scenarios like medicine\nand law. However, the need to explain the rationale behind decisions is a main\nissue also for human-based deliberation as it is important to justify\n\\textit{why} a certain decision has been taken. Resident medical doctors for\ninstance are required not only to provide a (possibly correct) diagnosis, but\nalso to explain how they reached a certain conclusion. Developing new tools to\naid residents to train their explanation skills is therefore a central\nobjective of AI in education. In this paper, we follow this direction, and we\npresent, to the best of our knowledge, the first multilingual dataset for\nMedical Question Answering where correct and incorrect diagnoses for a clinical\ncase are enriched with a natural language explanation written by doctors. These\nexplanations have been manually annotated with argument components (i.e.,\npremise, claim) and argument relations (i.e., attack, support), resulting in\nthe Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases\nin four languages (English, Spanish, French, Italian) with explanations, where\nwe annotated 5021 claims, 2313 premises, 2431 support relations, and 1106\nattack relations. We conclude by showing how competitive baselines perform over\nthis challenging dataset for the argument mining task.",
      "tldr_zh": "这篇论文介绍了 CasiMedicos-Arg，一个多语言医学问答数据集，旨在帮助训练医生的诊断解释技能，并解决 AI 决策解释的挑战。该数据集包含 558 个临床案例的正确和错误诊断，每个案例都配有由医生编写的自然语言解释，并手动标注了 argument components（如 premise 和 claim）以及 argument relations（如 attack 和 support）。数据集支持四种语言（英语、西班牙语、法语、意大利语），标注了 5021 个 claims、2313 个 premises、2431 个 support relations 和 1106 个 attack relations。通过实验，论文展示了在该数据集上进行 argument mining 任务的基线模型性能，为 AI 在教育和医学领域的应用提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05235v2",
      "published_date": "2024-10-07 17:41:45 UTC",
      "updated_date": "2024-10-08 13:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:01:26.213070"
    },
    {
      "arxiv_id": "2410.05233v1",
      "title": "SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Taha Bouhsine",
        "Imad El Aaroussi",
        "Atik Faysal",
        "Wang Huaxia"
      ],
      "abstract": "We introduce a novel anchor-free contrastive learning (AFCL) method\nleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach\nminimizes a semi-metric discriminative loss function that simultaneously\noptimizes two key objectives: reducing the distance and orthogonality between\nembeddings of similar inputs while maximizing these metrics for dissimilar\ninputs, facilitating more fine-grained contrastive learning. The AFCL method,\npowered by SimO loss, creates a fiber bundle topological structure in the\nembedding space, forming class-specific, internally cohesive yet orthogonal\nneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,\nproviding visualizations that demonstrate the impact of SimO loss on the\nembedding space. Our results illustrate the formation of distinct, orthogonal\nclass neighborhoods, showcasing the method's ability to create well-structured\nembeddings that balance class separation with intra-class variability. This\nwork opens new avenues for understanding and leveraging the geometric\nproperties of learned representations in various machine learning tasks.",
      "tldr_zh": "本论文提出了一种新的损失函数SimO Loss，用于anchor-free contrastive learning（AFCL），旨在通过同时最小化相似输入嵌入的距离和正交性、最大化不相似输入的这些指标，实现更细粒度的监督对比学习。SimO Loss在嵌入空间中构建了纤维束拓扑结构，形成类特定的内部连贯但相互正交的邻域，从而平衡了类间分离与类内变异性。在CIFAR-10数据集上的实验验证了该方法的有效性，通过可视化展示了嵌入空间的优化效果，为探索机器学习表示的几何属性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05233v1",
      "published_date": "2024-10-07 17:41:10 UTC",
      "updated_date": "2024-10-07 17:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:01:48.387598"
    },
    {
      "arxiv_id": "2410.11863v1",
      "title": "ChatVis: Automating Scientific Visualization with a Large Language Model",
      "title_zh": "ChatVis：利用大型语言模型实现科学可视化的自动化",
      "authors": [
        "Tanwi Mallick",
        "Orcun Yildiz",
        "David Lenz",
        "Tom Peterka"
      ],
      "abstract": "We develop an iterative assistant we call ChatVis that can synthetically\ngenerate Python scripts for data analysis and visualization using a large\nlanguage model (LLM). The assistant allows a user to specify the operations in\nnatural language, attempting to generate a Python script for the desired\noperations, prompting the LLM to revise the script as needed until it executes\ncorrectly. The iterations include an error detection and correction mechanism\nthat extracts error messages from the execution of the script and subsequently\nprompts LLM to correct the error. Our method demonstrates correct execution on\nfive canonical visualization scenarios, comparing results with ground truth. We\nalso compared our results with scripts generated by several other LLMs without\nany assistance. In every instance, ChatVis successfully generated the correct\nscript, whereas the unassisted LLMs failed to do so. The code is available on\nGitHub: https://github.com/tanwimallick/ChatVis/.",
      "tldr_zh": "本文提出了一种名为 ChatVis 的迭代助手，利用大型语言模型 (LLM) 自动生成 Python 脚本，用于科学数据分析和可视化。用户可以通过自然语言指定操作，系统会生成脚本并通过错误检测与修正机制（如提取执行错误信息并提示 LLM 优化）进行迭代，直至脚本正确运行。在五个经典可视化场景的测试中，ChatVis 与基准结果一致，且优于无辅助的其他 LLMs，成功率达 100%。该方法代码已在 GitHub 上开源，提供可复现的实现。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11863v1",
      "published_date": "2024-10-07 17:37:59 UTC",
      "updated_date": "2024-10-07 17:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:01:49.714078"
    },
    {
      "arxiv_id": "2410.05229v1",
      "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models",
      "title_zh": "GSM-Symbolic：理解大语言模型中数学推理的局限性",
      "authors": [
        "Iman Mirzadeh",
        "Keivan Alizadeh",
        "Hooman Shahrokhi",
        "Oncel Tuzel",
        "Samy Bengio",
        "Mehrdad Farajtabar"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.",
      "tldr_zh": "这篇论文介绍了 GSM-Symbolic，这是一个基于符号模板的改进基准，用于评估大型语言模型(LLMs)在数学推理方面的局限性，旨在提供更可靠的评估指标。\n研究人员对多个 SOTA 模型进行了大规模测试，发现模型在处理相同问题但数字值变化的变体时，性能显著下降。\n此外，随着问题中子句数量增加，LLMs 的表现急剧恶化（如添加无关子句导致性能下降高达65%），这表明这些模型无法进行真正的逻辑推理，而是复制训练数据中的步骤。\n总体上，该工作为理解 LLMs 数学推理能力的真实水平提供了更细致的见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.05229v1",
      "published_date": "2024-10-07 17:36:37 UTC",
      "updated_date": "2024-10-07 17:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:02:02.547929"
    },
    {
      "arxiv_id": "2410.05210v1",
      "title": "Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality",
      "title_zh": "翻译失败",
      "authors": [
        "Youngtaek Oh",
        "Jae Won Cho",
        "Dong-Jin Kim",
        "In So Kweon",
        "Junmo Kim"
      ],
      "abstract": "In this paper, we propose a new method to enhance compositional understanding\nin pre-trained vision and language models (VLMs) without sacrificing\nperformance in zero-shot multi-modal tasks. Traditional fine-tuning approaches\noften improve compositional reasoning at the cost of degrading multi-modal\ncapabilities, primarily due to the use of global hard negative (HN) loss, which\ncontrasts global representations of images and texts. This global HN loss\npushes HN texts that are highly similar to the original ones, damaging the\nmodel's multi-modal representations. To overcome this limitation, we propose\nFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard\nnegative loss and selective calibrated regularization. These innovations\nprovide fine-grained negative supervision while preserving the model's\nrepresentational integrity. Our extensive evaluations across diverse benchmarks\nfor both compositionality and multi-modal tasks show that FSC-CLIP not only\nachieves compositionality on par with state-of-the-art models but also retains\nstrong multi-modal capabilities. Code is available at:\nhttps://github.com/ytaek-oh/fsc-clip.",
      "tldr_zh": "本研究提出了一种新方法FSC-CLIP，用于提升预训练视觉语言模型(VLMs)的视觉语言组合理解能力，同时保留其零样本多模态任务的性能。传统微调方法依赖全局硬负损失(global hard negative loss)，这会导致模型的多模态表示受损；为此，FSC-CLIP整合了局部硬负损失(local hard negative loss)和选择性校准正则化(selective calibrated regularization)，提供细粒度的负监督以保持表示完整性。在多种基准测试中，FSC-CLIP实现了与最先进模型相当的组合性表现，同时维持了强大的多模态能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 (Long, Main). Project page:\n  https://ytaek-oh.github.io/fsc-clip",
      "pdf_url": "http://arxiv.org/pdf/2410.05210v1",
      "published_date": "2024-10-07 17:16:20 UTC",
      "updated_date": "2024-10-07 17:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:02:13.267982"
    },
    {
      "arxiv_id": "2410.05203v2",
      "title": "Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality",
      "title_zh": "超越 FVD：用于视频生成质量的增强评估指标",
      "authors": [
        "Ge Ya Luo",
        "Gian Mario Favero",
        "Zhi Hao Luo",
        "Alexia Jolicoeur-Martineau",
        "Christopher Pal"
      ],
      "abstract": "The Fr\\'echet Video Distance (FVD) is a widely adopted metric for evaluating\nvideo generation distribution quality. However, its effectiveness relies on\ncritical assumptions. Our analysis reveals three significant limitations: (1)\nthe non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the\ninsensitivity of I3D features to temporal distortions; (3) the impractical\nsample sizes required for reliable estimation. These findings undermine FVD's\nreliability and show that FVD falls short as a standalone metric for video\ngeneration evaluation. After extensive analysis of a wide range of metrics and\nbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based on\nfeatures derived from a Joint Embedding Predictive Architecture, measured using\nMaximum Mean Discrepancy with polynomial kernel. Our experiments on multiple\nopen-source datasets show clear evidence that it is a superior alternative to\nthe widely used FVD metric, requiring only 16% of the samples to reach its\nsteady value, while increasing alignment with human evaluation by 34%, on\naverage.",
      "tldr_zh": "该论文分析了Fréchet Video Distance (FVD)作为视频生成质量评估指标的三大局限性，包括I3D特征空间的非高斯性、对时间扭曲的低敏感性和需要大量样本的估算问题，从而质疑其可靠性。作者提出了一种改进指标JEDi，利用Joint Embedding Predictive Architecture的特征，并通过Maximum Mean Discrepancy with polynomial kernel进行测量。实验结果显示，JEDi在多个开源数据集上只需FVD的16%样本即可稳定，且与人类评估的一致性平均提高了34%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05203v2",
      "published_date": "2024-10-07 17:07:21 UTC",
      "updated_date": "2024-10-08 17:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:02:25.075928"
    },
    {
      "arxiv_id": "2410.05361v1",
      "title": "RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Zhang",
        "Tong Xia",
        "Aaqib Saeed",
        "Cecilia Mascolo"
      ],
      "abstract": "The high incidence and mortality rates associated with respiratory diseases\nunderscores the importance of early screening. Machine learning models can\nautomate clinical consultations and auscultation, offering vital support in\nthis area. However, the data involved, spanning demographics, medical history,\nsymptoms, and respiratory audio, are heterogeneous and complex. Existing\napproaches are insufficient and lack generalizability, as they typically rely\non limited training data, basic fusion techniques, and task-specific models. In\nthis paper, we propose RespLLM, a novel multimodal large language model (LLM)\nframework that unifies text and audio representations for respiratory health\nprediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs\nand enables effective audio-text fusion through cross-modal attentions.\nInstruction tuning is employed to integrate diverse data from multiple sources,\nensuring generalizability and versatility of the model. Experiments on five\nreal-world datasets demonstrate that RespLLM outperforms leading baselines by\nan average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates\nzero-shot predictions for new tasks. Our work lays the foundation for\nmultimodal models that can perceive, listen to, and understand heterogeneous\ndata, paving the way for scalable respiratory health diagnosis.",
      "tldr_zh": "该研究针对呼吸道疾病的高发病率，提出RespLLM，一种多模态大型语言模型（Multimodal LLMs）框架，用于统一音频和文本表示，实现呼吸健康预测的泛化能力。RespLLM利用预训练LLMs的先验知识，通过跨模态注意力（cross-modal attentions）实现音频-文本有效融合，并采用指令微调（instruction tuning）整合多源数据，提升模型的通用性和多功能性。在五个真实数据集的实验中，RespLLM比领先基线平均提高4.6%在训练任务上、7.9%在未见数据集上，并支持零样本预测（zero-shot predictions），为处理异构数据的可扩展呼吸健康诊断奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05361v1",
      "published_date": "2024-10-07 17:06:11 UTC",
      "updated_date": "2024-10-07 17:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:02:40.400820"
    },
    {
      "arxiv_id": "2410.19741v1",
      "title": "Tourism destination events classifier based on artificial intelligence techniques",
      "title_zh": "基于人工智能技术的旅游目的地活动分类器",
      "authors": [
        "Miguel Camacho-Ruiz",
        "Ramón Alberto Carrasco",
        "Gema Fernández-Avilés",
        "Antonio LaTorre"
      ],
      "abstract": "Identifying client needs to provide optimal services is crucial in tourist\ndestination management. The events held in tourist destinations may help to\nmeet those needs and thus contribute to tourist satisfaction. As with product\nmanagement, the creation of hierarchical catalogs to classify those events can\naid event management. The events that can be found on the internet are listed\nin dispersed, heterogeneous sources, which makes direct classification a\ndifficult, time-consuming task. The main aim of this work is to create a novel\nprocess for automatically classifying an eclectic variety of tourist events\nusing a hierarchical taxonomy, which can be applied to support tourist\ndestination management. Leveraging data science methods such as CRISP-DM,\nsupervised machine learning, and natural language processing techniques, the\nautomatic classification process proposed here allows the creation of a\nnormalized catalog across very different geographical regions. Therefore, we\ncan build catalogs with consistent filters, allowing users to find events\nregardless of the event categories assigned at source, if any. This is very\nvaluable for companies that offer this kind of information across multiple\nregions, such as airlines, travel agencies or hotel chains. Ultimately, this\ntool has the potential to revolutionize the way companies and end users\ninteract with tourist events information.",
      "tldr_zh": "本研究针对旅游目的地事件的分散和异构来源问题，提出了一种基于人工智能技术的自动分类过程，使用分层分类法（hierarchical taxonomy）来支持旅游管理。方法包括采用 CRISP-DM 框架、监督机器学习和自然语言处理（NLP）技术，对各种旅游事件进行标准化分类，从而构建跨地理区域一致的目录。结果显示，该工具能帮助用户轻松查找事件，并为航空公司、旅行社和酒店连锁等企业提供一致的过滤机制，最终提升旅游信息互动效率和用户满意度。",
      "categories": [
        "q-fin.GN",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "q-fin.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19741v1",
      "published_date": "2024-10-07 16:54:51 UTC",
      "updated_date": "2024-10-07 16:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:02:48.821876"
    },
    {
      "arxiv_id": "2410.17272v1",
      "title": "Military Applications of Machine Learning: A Bibliometric Perspective",
      "title_zh": "机器学习的军事应用：文献计量学视角",
      "authors": [
        "José Javier Galán",
        "Ramón Alberto Carrasco",
        "Antonio LaTorre"
      ],
      "abstract": "The military environment generates a large amount of data of great\nimportance, which makes necessary the use of machine learning for its\nprocessing. Its ability to learn and predict possible scenarios by analyzing\nthe huge volume of information generated provides automatic learning and\ndecision support. This paper aims to present a model of a machine learning\narchitecture applied to a military organization, carried out and supported by a\nbibliometric study applied to an architecture model of a nonmilitary\norganization. For this purpose, a bibliometric analysis up to the year 2021 was\ncarried out, making a strategic diagram and interpreting the results. The\ninformation used has been extracted from one of the main databases widely\naccepted by the scientific community, ISI WoS. No direct military sources were\nused. This work is divided into five parts: the study of previous research\nrelated to machine learning in the military world; the explanation of our\nresearch methodology using the SciMat, Excel and VosViewer tools; the use of\nthis methodology based on data mining, preprocessing, cluster normalization, a\nstrategic diagram and the analysis of its results to investigate machine\nlearning in the military context; based on these results, a conceptual\narchitecture of the practical use of ML in the military context is drawn up;\nand, finally, we present the conclusions, where we will see the most important\nareas and the latest advances in machine learning applied, in this case, to a\nmilitary environment, to analyze a large set of data, providing utility,\nmachine learning and decision support.",
      "tldr_zh": "本研究从文献计量角度探讨机器学习在军事领域的应用，旨在基于非军事组织的架构模型构建一个适用于军事环境的机器学习架构，以处理海量数据并提供决策支持。研究方法包括对截至2021年的ISI WoS数据库进行bibliometric analysis，使用SciMat、Excel和VosViewer工具进行数据挖掘、预处理、聚类归一化和战略图分析。结果显示，机器学习在军事情境中的关键领域包括自动学习和预测场景，论文据此提出一个概念架构模型，突显其在数据分析和决策支持方面的实用价值和最新进展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17272v1",
      "published_date": "2024-10-07 16:54:40 UTC",
      "updated_date": "2024-10-07 16:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:03:02.367841"
    },
    {
      "arxiv_id": "2410.05191v1",
      "title": "LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation",
      "title_zh": "LADEV：一种语言驱动的测试和评估平台，用于机器人操作中的视觉-语言-动作模型",
      "authors": [
        "Zhijie Wang",
        "Zhehua Zhou",
        "Jiayang Song",
        "Yuheng Huang",
        "Zhan Shu",
        "Lei Ma"
      ],
      "abstract": "Building on the advancements of Large Language Models (LLMs) and Vision\nLanguage Models (VLMs), recent research has introduced Vision-Language-Action\n(VLA) models as an integrated solution for robotic manipulation tasks. These\nmodels take camera images and natural language task instructions as input and\ndirectly generate control actions for robots to perform specified tasks,\ngreatly improving both decision-making capabilities and interaction with human\nusers. However, the data-driven nature of VLA models, combined with their lack\nof interpretability, makes the assurance of their effectiveness and robustness\na challenging task. This highlights the need for a reliable testing and\nevaluation platform. For this purpose, in this work, we propose LADEV, a\ncomprehensive and efficient platform specifically designed for evaluating VLA\nmodels. We first present a language-driven approach that automatically\ngenerates simulation environments from natural language inputs, mitigating the\nneed for manual adjustments and significantly improving testing efficiency.\nThen, to further assess the influence of language input on the VLA models, we\nimplement a paraphrase mechanism that produces diverse natural language task\ninstructions for testing. Finally, to expedite the evaluation process, we\nintroduce a batch-style method for conducting large-scale testing of VLA\nmodels. Using LADEV, we conducted experiments on several state-of-the-art VLA\nmodels, demonstrating its effectiveness as a tool for evaluating these models.\nOur results showed that LADEV not only enhances testing efficiency but also\nestablishes a solid baseline for evaluating VLA models, paving the way for the\ndevelopment of more intelligent and advanced robotic systems.",
      "tldr_zh": "该研究提出 LADEV，一个语言驱动的测试和评估平台，用于评估 Vision-Language-Action (VLA) 模型在机器人操作任务中的性能，以解决这些模型的可解释性和鲁棒性问题。LADEV 通过语言驱动的方法从自然语言输入自动生成模拟环境、实施 paraphrase 机制生成多样化任务指令，以及引入 batch-style 方法来加速大规模测试，从而显著提高了测试效率。实验结果显示，在多个 SOTA VLA 模型上，LADEV 不仅建立了可靠的评估基准，还为开发更智能的机器人系统铺平了道路。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.05191v1",
      "published_date": "2024-10-07 16:49:16 UTC",
      "updated_date": "2024-10-07 16:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:03:14.106608"
    },
    {
      "arxiv_id": "2410.05183v1",
      "title": "Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics",
      "title_zh": "超越相关性：机器翻译指标的可解释评估",
      "authors": [
        "Stefano Perrella",
        "Lorenzo Proietti",
        "Pere-Lluís Huguet Cabot",
        "Edoardo Barba",
        "Roberto Navigli"
      ],
      "abstract": "Machine Translation (MT) evaluation metrics assess translation quality\nautomatically. Recently, researchers have employed MT metrics for various new\nuse cases, such as data filtering and translation re-ranking. However, most MT\nmetrics return assessments as scalar scores that are difficult to interpret,\nposing a challenge to making informed design choices. Moreover, MT metrics'\ncapabilities have historically been evaluated using correlation with human\njudgment, which, despite its efficacy, falls short of providing intuitive\ninsights into metric performance, especially in terms of new metric use cases.\nTo address these issues, we introduce an interpretable evaluation framework for\nMT metrics. Within this framework, we evaluate metrics in two scenarios that\nserve as proxies for the data filtering and translation re-ranking use cases.\nFurthermore, by measuring the performance of MT metrics using Precision,\nRecall, and F-score, we offer clearer insights into their capabilities than\ncorrelation with human judgments. Finally, we raise concerns regarding the\nreliability of manually curated data following the Direct Assessments+Scalar\nQuality Metrics (DA+SQM) guidelines, reporting a notably low agreement with\nMultidimensional Quality Metrics (MQM) annotations.",
      "tldr_zh": "本研究超越了传统机器翻译 (MT) 评估指标的关联性评估，强调这些指标返回的标量分数难以解释，且依赖人类判断相关性无法提供直观洞见。论文引入了一个可解释的评估框架，在模拟数据过滤和翻译重新排序场景中评估指标，使用 Precision、Recall 和 F-score 等指标来衡量性能，从而给出更清晰的指标能力分析。最后，研究发现，按照 Direct Assessments+Scalar Quality Metrics (DA+SQM) 指南手动整理的数据可靠性存疑，其与 Multidimensional Quality Metrics (MQM) 注解的协议较低。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 Main Conference. 26 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05183v1",
      "published_date": "2024-10-07 16:42:10 UTC",
      "updated_date": "2024-10-07 16:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:03:28.711916"
    },
    {
      "arxiv_id": "2410.05182v1",
      "title": "MARs: Multi-view Attention Regularizations for Patch-based Feature Recognition of Space Terrain",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Chase Jr",
        "Karthik Dantu"
      ],
      "abstract": "The visual detection and tracking of surface terrain is required for\nspacecraft to safely land on or navigate within close proximity to celestial\nobjects. Current approaches rely on template matching with pre-gathered\npatch-based features, which are expensive to obtain and a limiting factor in\nperceptual capability. While recent literature has focused on in-situ detection\nmethods to enhance navigation and operational autonomy, robust description is\nstill needed. In this work, we explore metric learning as the lightweight\nfeature description mechanism and find that current solutions fail to address\ninter-class similarity and multi-view observational geometry. We attribute this\nto the view-unaware attention mechanism and introduce Multi-view Attention\nRegularizations (MARs) to constrain the channel and spatial attention across\nmultiple feature views, regularizing the what and where of attention focus. We\nthoroughly analyze many modern metric learning losses with and without MARs and\ndemonstrate improved terrain-feature recognition performance by upwards of 85%.\nWe additionally introduce the Luna-1 dataset, consisting of Moon crater\nlandmarks and reference navigation frames from NASA mission data to support\nfuture research in this difficult task. Luna-1 and source code are publicly\navailable at https://droneslab.github.io/mars/.",
      "tldr_zh": "该论文针对航天器安全着陆或近距离导航的需求，提出了一种基于补丁特征识别的 Multi-view Attention Regularizations (MARs) 方法，以解决当前模板匹配方法的局限性，如特征获取成本高和感知能力不足。MARs 通过约束通道和空间注意力在多个特征视图上的正则化，改善了度量学习（metric learning）对类间相似性和多视图观察几何的处理，从而规范注意力的焦点（what and where）。实验结果显示，与传统度量学习损失函数相比，MARs 显著提升了地形特征识别性能，高达 85%。此外，论文还引入了 Luna-1 dataset，包括 NASA 任务数据的月球陨石坑地标和参考导航帧，以支持未来研究，并已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024. Project page available at\n  https://droneslab.github.io/mars/",
      "pdf_url": "http://arxiv.org/pdf/2410.05182v1",
      "published_date": "2024-10-07 16:41:45 UTC",
      "updated_date": "2024-10-07 16:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:03:37.786609"
    },
    {
      "arxiv_id": "2410.05167v2",
      "title": "Presto! Distilling Steps and Layers for Accelerating Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Novack",
        "Ge Zhu",
        "Jonah Casebeer",
        "Julian McAuley",
        "Taylor Berg-Kirkpatrick",
        "Nicholas J. Bryan"
      ],
      "abstract": "Despite advances in diffusion-based text-to-music (TTM) methods, efficient,\nhigh-quality generation remains a challenge. We introduce Presto!, an approach\nto inference acceleration for score-based diffusion transformers via reducing\nboth sampling steps and cost per step. To reduce steps, we develop a new\nscore-based distribution matching distillation (DMD) method for the EDM-family\nof diffusion models, the first GAN-based distillation method for TTM. To reduce\nthe cost per step, we develop a simple, but powerful improvement to a recent\nlayer distillation method that improves learning via better preserving hidden\nstate variance. Finally, we combine our step and layer distillation methods\ntogether for a dual-faceted approach. We evaluate our step and layer\ndistillation methods independently and show each yield best-in-class\nperformance. Our combined distillation method can generate high-quality outputs\nwith improved diversity, accelerating our base model by 10-18x (230/435ms\nlatency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --\nthe fastest high-quality TTM to our knowledge. Sound examples can be found at\nhttps://presto-music.github.io/web/.",
      "tldr_zh": "本文提出Presto!，一种加速基于扩散的文本到音乐(TTM)生成的方法，通过减少采样步骤和每步计算成本来提升效率。具体而言，该方法开发了新的score-based分布匹配蒸馏(DMD)技术，这是首个针对EDM-family扩散模型的GAN-based蒸馏方法；同时，改进了层蒸馏(layer distillation)方法，以更好地保留隐藏状态方差。实验结果显示，步骤蒸馏和层蒸馏各自均达到最佳性能，而结合两者后，Presto!将基础模型加速10-18倍，比现有SOTA快15倍，生成高质量且多样性的音乐输出。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted as Spotlight at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05167v2",
      "published_date": "2024-10-07 16:24:18 UTC",
      "updated_date": "2025-04-16 17:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:03:58.606008"
    },
    {
      "arxiv_id": "2410.05160v3",
      "title": "VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks",
      "title_zh": "VLM2Vec：训练视觉-语言模型用于大规模多模态嵌入任务",
      "authors": [
        "Ziyan Jiang",
        "Rui Meng",
        "Xinyi Yang",
        "Semih Yavuz",
        "Yingbo Zhou",
        "Wenhu Chen"
      ],
      "abstract": "Embedding models have been crucial in enabling various downstream tasks such\nas semantic similarity, information retrieval, and clustering. Recently, there\nhas been a surge of interest in developing universal text embedding models that\ncan generalize across tasks (e.g., MTEB). However, progress in learning\nuniversal multimodal embedding models has been relatively slow despite its\nimportance and practicality. In this work, we aim to explore the potential for\nbuilding universal embeddings capable of handling a wide range of downstream\ntasks. Our contributions are twofold: (1) MMEB (Massive Multimodal Embedding\nBenchmark), which covers 4 meta-tasks (i.e. classification, visual question\nanswering, multimodal retrieval, and visual grounding) and 36 datasets,\nincluding 20 training and 16 evaluation datasets covering both in-distribution\nand out-of-distribution tasks, and (2) VLM2Vec (Vision-Language Model ->\nVector), a contrastive training framework that converts any state-of-the-art\nvision-language model into an embedding model via training on MMEB. Unlike\nprevious models such as CLIP and BLIP, which encodes text or images\nindependently without any task instruction, VLM2Vec can process any combination\nof images and text to generate a fixed-dimensional vector based on task\ninstructions. We build a series of VLM2Vec models on SoTA VLMs like Phi-3.5-V,\nLLaVA-1.6 and evaluate them on MMEB's evaluation split. Our results show that\nVLM2Vec achieves an absolute average improvement of 10% to 20% over existing\nmultimodal embedding models on both in-distribution and out-of-distribution\ndatasets in MMEB. We show that VLMs are secretly strong embedding models.",
      "tldr_zh": "本研究探讨了构建通用多模态嵌入模型的可能性，以支持各种下游任务，如语义相似性和信息检索。论文的主要贡献包括：提出 MMEB（Massive Multimodal Embedding Benchmark），一个覆盖分类、视觉问答、多模态检索和视觉定位等4个元任务的基准，包含36个数据集；以及开发 VLM2Vec（Vision-Language Model -> Vector）框架，通过对比训练将任何先进的视觉语言模型（如Phi-3.5-V和LLaVA-1.6）转换为嵌入模型，支持基于任务指令处理图像和文本的组合。不同于CLIP和BLIP等模型，VLM2Vec能生成固定维度的向量，以提升任务适应性。在MMEB评估中，VLM2Vec实现了10%到20%的绝对平均性能提升，证明了视觉语言模型在嵌入任务中的强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2410.05160v3",
      "published_date": "2024-10-07 16:14:05 UTC",
      "updated_date": "2025-01-02 05:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:04:19.740097"
    },
    {
      "arxiv_id": "2410.10860v1",
      "title": "A Recipe For Building a Compliant Real Estate Chatbot",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Madani",
        "Anusha Bagalkotkar",
        "Supriya Anand",
        "Gabriel Arnson",
        "Rohini Srihari",
        "Kenneth Joseph"
      ],
      "abstract": "In recent years, there has been significant effort to align large language\nmodels with human preferences. This work focuses on developing a chatbot\nspecialized in the real estate domain, with an emphasis on incorporating\ncompliant behavior to ensure it can be used without perpetuating discriminatory\npractices like steering and redlining, which have historically plagued the real\nestate industry in the United States. Building on prior work, we present a\nmethod for generating a synthetic general instruction-following dataset, along\nwith safety data. Through extensive evaluations and benchmarks, we fine-tuned a\nllama-3-8B-instruct model and demonstrated that we can enhance it's performance\nsignificantly to match huge closed-source models like GPT-4o while making it\nsafer and more compliant. We open-source the model, data and code to support\nfurther development and research in the community.",
      "tldr_zh": "本研究提出了一种构建合规房地产聊天机器人的方法，旨在避免歧视性行为如 steering 和 redlining，通过生成合成的一般指令遵循数据集和安全数据来微调 large language models。研究者对 llama-3-8B-instruct 模型进行了优化，提升其性能至接近 GPT-4o 的水平，同时增强了安全性。最终，他们开源了模型、数据和代码，以支持社区进一步开发和研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10860v1",
      "published_date": "2024-10-07 16:03:47 UTC",
      "updated_date": "2024-10-07 16:03:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:04:21.084774"
    },
    {
      "arxiv_id": "2410.05146v1",
      "title": "CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Zhao",
        "Jinyu Li",
        "Ruchao Fan",
        "Matt Post"
      ],
      "abstract": "Models for streaming speech translation (ST) can achieve high accuracy and\nlow latency if they're developed with vast amounts of paired audio in the\nsource language and written text in the target language. Yet, these text labels\nfor the target language are often pseudo labels due to the prohibitive cost of\nmanual ST data labeling. In this paper, we introduce a methodology named\nConnectionist Temporal Classification guided modality matching (CTC-GMM) that\nenhances the streaming ST model by leveraging extensive machine translation\n(MT) text data. This technique employs CTC to compress the speech sequence into\na compact embedding sequence that matches the corresponding text sequence,\nallowing us to utilize matched {source-target} language text pairs from the MT\ncorpora to refine the streaming ST model further. Our evaluations with FLEURS\nand CoVoST2 show that the CTC-GMM approach can increase translation accuracy\nrelatively by 13.9% and 6.4% respectively, while also boosting decoding speed\nby 59.7% on GPU.",
      "tldr_zh": "本文提出 CTC-GMM 方法，通过 Connectionist Temporal Classification (CTC) 引导的模态匹配，优化流式语音翻译（streaming speech translation）模型，利用机器翻译（MT）语料中的源-目标语言文本对来提升模型性能，从而解决伪标签问题。CTC 用于压缩语音序列成紧凑嵌入，与文本序列匹配，进一步训练模型。实验结果显示，在 FLEURS 和 CoVoST2 数据集上，该方法使翻译准确率分别提高 13.9% 和 6.4%，并将 GPU 解码速度提升 59.7%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.05146v1",
      "published_date": "2024-10-07 15:58:03 UTC",
      "updated_date": "2024-10-07 15:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:04:44.146859"
    },
    {
      "arxiv_id": "2410.05357v2",
      "title": "Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhao",
        "Guoheng Sun",
        "Ruisi Cai",
        "Yukun Zhou",
        "Pingzhi Li",
        "Peihao Wang",
        "Bowen Tan",
        "Yexiao He",
        "Li Chen",
        "Yi Liang",
        "Beidi Chen",
        "Binhang Yuan",
        "Hongyi Wang",
        "Ang Li",
        "Zhangyang Wang",
        "Tianlong Chen"
      ],
      "abstract": "As Large Language Models (LLMs) excel across tasks and specialized domains,\nscaling LLMs based on existing models has garnered significant attention, which\nfaces the challenge of decreasing performance when combining disparate models.\nVarious techniques have been proposed for the aggregation of pre-trained LLMs,\nincluding model merging, Mixture-of-Experts, and stacking. Despite their\nmerits, a comprehensive comparison and synergistic application of them to a\ndiverse model zoo is yet to be adequately addressed. In light of this research\ngap, this paper introduces Model-GLUE, a holistic LLM scaling guideline. First,\nour work starts with a benchmarking of existing LLM scaling techniques,\nespecially selective merging, and variants of mixture. Utilizing the insights\nfrom the benchmark results, we formulate an optimal strategy for the selection\nand aggregation of a heterogeneous model zoo characterizing different\narchitectures and initialization.Our methodology involves the clustering of\nmergeable models and optimal merging strategy selection, and the integration of\nclusters through a model mixture. Finally, evidenced by our experiments on a\ndiverse Llama-2-based model zoo, Model-GLUE shows an average performance\nenhancement of 5.61%, achieved without additional training. Codes are available\nat: https://github.com/Model-GLUE/Model-GLUE.",
      "tldr_zh": "该论文引入了Model-GLUE，一种全面的LLM（Large Language Models）缩放指南，旨在解决合并不同预训练模型时性能下降的问题，通过基准测试现有技术如模型合并、Mixture-of-Experts和堆叠来优化异构模型库的聚合。方法包括聚类可合并模型、选择最优合并策略，并通过模型混合整合集群。实验结果显示，在一个基于Llama-2的多样模型库上，Model-GLUE无需额外训练就实现了平均性能提升5.61%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 4 figures, accepted to NeurIPS 2024 Datasets and Benchmarks\n  Track",
      "pdf_url": "http://arxiv.org/pdf/2410.05357v2",
      "published_date": "2024-10-07 15:55:55 UTC",
      "updated_date": "2024-12-05 15:08:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:04:44.766625"
    },
    {
      "arxiv_id": "2410.05356v1",
      "title": "BSG4Bot: Efficient Bot Detection based on Biased Heterogeneous Subgraphs",
      "title_zh": "BSG4Bot：基于偏置异构子图的高效机器人检测",
      "authors": [
        "Hao Miao",
        "Zida Liu",
        "Jun Gao"
      ],
      "abstract": "The detection of malicious social bots has become a crucial task, as bots can\nbe easily deployed and manipulated to spread disinformation, promote conspiracy\nmessages, and more. Most existing approaches utilize graph neural networks\n(GNNs)to capture both user profle and structural features,achieving promising\nprogress. However, they still face limitations including the expensive training\non large underlying graph, the performance degration when similar neighborhood\npatterns' assumption preferred by GNNs is not satisfied, and the dynamic\nfeatures of bots in a highly adversarial context. Motivated by these\nlimitations, this paper proposes a method named BSG4Bot with an intuition that\nGNNs training on Biased SubGraphs can improve both performance and time/space\nefficiency in bot detection. Specifically, BSG4Bot first pre-trains a\nclassifier on node features efficiently to define the node similarities, and\nconstructs biased subgraphs by combining the similarities computed by the\npre-trained classifier and the node importances computed by Personalized\nPageRank (PPR scores). BSG4Bot then introduces a heterogeneous GNN over the\nconstructed subgraphs to detect bots effectively and efficiently. The\nrelatively stable features, including the content category and temporal\nactivity features, are explored and incorporated into BSG4Bot after preliminary\nverification on sample data. The extensive experimental studies show that\nBSG4Bot outperforms the state-of-the-art bot detection methods, while only\nneeding nearly 1/5 training time.",
      "tldr_zh": "这篇论文提出BSG4Bot，一种基于偏置异构子图(Biased Heterogeneous Subgraphs)的社交机器人检测方法，以解决现有图神经网络(GNNs)方法的训练效率低、性能下降和动态特征问题。BSG4Bot首先预训练一个分类器计算节点相似性，并结合Personalized PageRank (PPR) 构建偏置子图，然后在这些子图上应用异构GNN进行高效检测，同时融入内容类别和时间活动等稳定特征。实验结果显示，BSG4Bot在性能上优于最先进的方法，且训练时间仅需约1/5。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05356v1",
      "published_date": "2024-10-07 15:52:51 UTC",
      "updated_date": "2024-10-07 15:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:04:58.280791"
    },
    {
      "arxiv_id": "2410.05355v1",
      "title": "Falcon Mamba: The First Competitive Attention-free 7B Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Zuo",
        "Maksim Velikanov",
        "Dhia Eddine Rhaiem",
        "Ilyas Chahed",
        "Younes Belkada",
        "Guillaume Kunsch",
        "Hakim Hacid"
      ],
      "abstract": "In this technical report, we present Falcon Mamba 7B, a new base large\nlanguage model based on the novel Mamba architecture. Falcon Mamba 7B is\ntrained on 5.8 trillion tokens with carefully selected data mixtures. As a pure\nMamba-based model, Falcon Mamba 7B surpasses leading open-weight models based\non Transformers, such as Mistral 7B, Llama3.1 8B, and Falcon2 11B. It is on par\nwith Gemma 7B and outperforms models with different architecture designs, such\nas RecurrentGemma 9B and RWKV-v6 Finch 7B/14B. Currently, Falcon Mamba 7B is\nthe best-performing Mamba model in the literature at this scale, surpassing\nboth existing Mamba and hybrid Mamba-Transformer models, according to the Open\nLLM Leaderboard. Due to its architecture, Falcon Mamba 7B is significantly\nfaster at inference and requires substantially less memory for long sequence\ngeneration. Despite recent studies suggesting that hybrid Mamba-Transformer\nmodels outperform pure architecture designs, we demonstrate that even the pure\nMamba design can achieve similar, or even superior results compared to the\nTransformer and hybrid designs. We make the weights of our implementation of\nFalcon Mamba 7B publicly available on\nhttps://huggingface.co/tiiuae/falcon-mamba-7b, under a permissive license.",
      "tldr_zh": "这篇报告介绍了 Falcon Mamba 7B，一种基于 Mamba 架构的首款竞争性无注意力机制的 7B 规模语言模型，该模型在 5.8 万亿 tokens 的精心选择数据上训练。Falcon Mamba 7B 在性能上超越了如 Mistral 7B 和 Llama3.1 8B 等 Transformer 基线模型，并在 Open LLM Leaderboard 上优于现有 Mamba 和混合 Mamba-Transformer 模型，与 Gemma 7B 相当。得益于其架构，该模型在推理速度和长序列生成内存使用上显著更高效，且模型权重已公开提供于 Hugging Face 上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05355v1",
      "published_date": "2024-10-07 15:40:45 UTC",
      "updated_date": "2024-10-07 15:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:05:20.124966"
    },
    {
      "arxiv_id": "2410.05130v1",
      "title": "Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents",
      "title_zh": "基于LLM多智能体的可扩展且准确图推理",
      "authors": [
        "Yuwei Hu",
        "Runlin Lei",
        "Xinyi Huang",
        "Zhewei Wei",
        "Yongchao Liu"
      ],
      "abstract": "Recent research has explored the use of Large Language Models (LLMs) for\ntackling complex graph reasoning tasks. However, due to the intricacies of\ngraph structures and the inherent limitations of LLMs in handling long text,\ncurrent approaches often fail to deliver satisfactory accuracy, even on\nsmall-scale graphs and simple tasks. To address these challenges, we introduce\nGraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent\ncollaboration strategy for explicit and precise graph reasoning. Inspired by\ndistributed graph computation theory, our framework decomposes graph problems\ninto smaller, node-centric tasks that are distributed among multiple agents.\nThe agents collaborate to solve the overall problem, significantly reducing the\namount of information and complexity handled by a single LLM, thus enhancing\nthe accuracy of graph reasoning. By simply increasing the number of agents,\nGraphAgent-Reasoner can efficiently scale to accommodate larger graphs with\nover 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework\ndemonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,\nsignificantly outperforming the best available models, both closed-source and\nfine-tuned open-source variants. Our framework also demonstrates the capability\nto handle real-world graph reasoning applications such as webpage importance\nanalysis.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在处理复杂图推理任务时存在的准确性问题（如图结构复杂和长文本处理限制），提出了一种无需微调的框架 GraphAgent-Reasoner，利用多智能体协作策略进行显式和精确的图推理。框架受分布式图计算理论启发，将图问题分解为更小的节点中心任务，分发给多个代理协作解决，从而减少单个 LLM 的信息负载，并通过增加代理数量实现对超过1,000节点大图的扩展。在 GraphInstruct 数据集上的评估显示，该框架在多项式时间图推理任务中达到近乎完美的准确性，大幅优于现有闭源和微调开源模型，并能应用于真实场景如网页重要性分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05130v1",
      "published_date": "2024-10-07 15:34:14 UTC",
      "updated_date": "2024-10-07 15:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:05:21.197086"
    },
    {
      "arxiv_id": "2410.05127v3",
      "title": "Last Iterate Convergence in Monotone Mean Field Games",
      "title_zh": "单调平均场游戏中的最后迭代收敛",
      "authors": [
        "Noboru Isobe",
        "Kenshi Abe",
        "Kaito Ariu"
      ],
      "abstract": "Mean Field Game (MFG) is a framework for modeling and approximating the\nbehavior of large numbers of agents. Computing equilibria in MFG has been of\ninterest in multi-agent reinforcement learning. The theoretical guarantee that\nthe last updated policy converges to an equilibrium has been limited. We\npropose the use of a simple, proximal-point (PP) type method to compute\nequilibria for MFGs. We then provide the first last-iterate convergence (LIC)\nguarantee under the Lasry--Lions-type monotonicity condition. We also propose\nan approximation of the update rule of PP ($\\mathtt{APP}$) based on the\nobservation that it is equivalent to solving the regularized MFG, which can be\nsolved by mirror descent. We further establish that the regularized mirror\ndescent achieves LIC at an exponential rate. Our numerical experiment\ndemonstrates that $\\mathtt{APP}$ efficiently computes the equilibrium.",
      "tldr_zh": "这篇论文研究了在单调 Mean Field Games (MFG) 中最后迭代收敛 (LIC) 的问题，针对多代理强化学习中计算均衡的理论保证不足。作者提出了一种简单的近端点 (PP) 类型方法来计算 MFG 均衡，并在 Lasry--Lions-type 单调性条件下首次证明了 LIC。论文进一步引入 APP 作为 PP 的近似更新规则，利用镜像下降求解正则化 MFG，并证明其以指数速率实现 LIC。数值实验验证了 APP 在高效计算均衡方面的有效性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "91A16"
      ],
      "primary_category": "cs.GT",
      "comment": "Under review, 26 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.05127v3",
      "published_date": "2024-10-07 15:28:18 UTC",
      "updated_date": "2025-01-31 12:20:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:05:34.143957"
    },
    {
      "arxiv_id": "2410.17271v3",
      "title": "Rules, Cases, and Reasoning: Positivist Legal Theory as a Framework for Pluralistic AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas A. Caputo"
      ],
      "abstract": "Legal theory can address two related key problems of alignment: pluralism and\nspecification. Alignment researchers must determine how to specify what is\nconcretely meant by vague principles like helpfulness and fairness and they\nmust ensure that their techniques do not exclude alternative perspectives on\nlife and values. The law faces these same problems. Leading legal theories\nsuggest the law solves these problems through the interaction of rules and\ncases, where general rules promulgated by a democratic authority are given\nspecific content through their application over time. Concrete applications\nallow for convergence on practical meaning while preserving space for\ndisagreement on values. These approaches suggest improvements to existing\ndemocratic alignment processes that use AI to create cases that give content to\nrules, allowing for more pluralist alignment.",
      "tldr_zh": "该论文将实证主义法律理论（positivist legal theory）作为框架，用于解决AI校准（AI alignment）中的多元主义（pluralism）和规范（specification）问题。法律理论通过规则（rules）和案例（cases）的互动，使抽象原则如“helpfulness”和“fairness”获得具体内容，同时容纳不同价值观的观点。作者建议改进现有的民主校准过程，利用AI生成案例来丰富规则的实际应用，从而实现更具包容性的AI校准。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "NeurIPS Pluralistic Alignment Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17271v3",
      "published_date": "2024-10-07 15:16:25 UTC",
      "updated_date": "2024-10-28 11:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:05:54.488653"
    },
    {
      "arxiv_id": "2410.05116v3",
      "title": "HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Ayano Hiranaka",
        "Shang-Fu Chen",
        "Chieh-Hsin Lai",
        "Dongjun Kim",
        "Naoki Murata",
        "Takashi Shibuya",
        "Wei-Hsiang Liao",
        "Shao-Hua Sun",
        "Yuki Mitsufuji"
      ],
      "abstract": "Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback. The code and project page are available\nat https://hero-dm.github.io/.",
      "tldr_zh": "该研究提出 HERO 框架，一种基于人类反馈的强化学习方法，用于在线微调 Stable Diffusion (SD) 模型，以提升图像生成的保真度、安全性和与人类指导的一致性。HERO 包括两个关键机制：Feedback-Aligned Representation Learning，用于实时捕捉反馈并提供学习信号；以及 Feedback-Guided Image Generation，通过从 SD 的精炼初始化样本生成图像，实现更快收敛。实验结果表明，HERO 在身体部位异常修正任务上比现有方法反馈效率提高 4 倍，并能有效处理推理、计数、个性化以及减少 NSFW 内容，仅需 0.5K 在线反馈。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in International Conference on Learning Representations\n  (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05116v3",
      "published_date": "2024-10-07 15:12:01 UTC",
      "updated_date": "2025-03-13 08:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:06:07.621855"
    },
    {
      "arxiv_id": "2410.05115v1",
      "title": "AlphaRouter: Quantum Circuit Routing with Reinforcement Learning and Tree Search",
      "title_zh": "AlphaRouter：利用强化学习和树搜索的量子电路路由",
      "authors": [
        "Wei Tang",
        "Yiheng Duan",
        "Yaroslav Kharkov",
        "Rasool Fakoor",
        "Eric Kessler",
        "Yunong Shi"
      ],
      "abstract": "Quantum computers have the potential to outperform classical computers in\nimportant tasks such as optimization and number factoring. They are\ncharacterized by limited connectivity, which necessitates the routing of their\ncomputational bits, known as qubits, to specific locations during program\nexecution to carry out quantum operations. Traditionally, the NP-hard\noptimization problem of minimizing the routing overhead has been addressed\nthrough sub-optimal rule-based routing techniques with inherent human biases\nembedded within the cost function design. This paper introduces a solution that\nintegrates Monte Carlo Tree Search (MCTS) with Reinforcement Learning (RL). Our\nRL-based router, called AlphaRouter, outperforms the current state-of-the-art\nrouting methods and generates quantum programs with up to $20\\%$ less routing\noverhead, thus significantly enhancing the overall efficiency and feasibility\nof quantum computing.",
      "tldr_zh": "本文提出 AlphaRouter，一种将 Monte Carlo Tree Search (MCTS) 与 Reinforcement Learning (RL) 整合的量子电路路由方法，以解决量子计算机有限连接性导致的 qubits 路由优化问题，该问题属于 NP-hard 类型。AlphaRouter 通过学习优化路由策略，超越传统基于规则的方法，避免人为偏差。实验结果显示，该方法可将量子程序的路由开销减少高达 20%，从而显著提升量子计算的效率和可行性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages, 11 figures, International Conference on Quantum Computing\n  and Engineering - QCE24",
      "pdf_url": "http://arxiv.org/pdf/2410.05115v1",
      "published_date": "2024-10-07 15:10:54 UTC",
      "updated_date": "2024-10-07 15:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:06:21.731807"
    },
    {
      "arxiv_id": "2410.05114v1",
      "title": "Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization",
      "title_zh": "翻译失败",
      "authors": [
        "Rohan Reddy Mekala",
        "Frederik Pahde",
        "Simon Baur",
        "Sneha Chandrashekar",
        "Madeline Diep",
        "Markus Wenzel",
        "Eric L. Wisotzky",
        "Galip Ümit Yolcu",
        "Sebastian Lapuschkin",
        "Jackie Ma",
        "Peter Eisert",
        "Mikael Lindvall",
        "Adam Porter",
        "Wojciech Samek"
      ],
      "abstract": "In the realm of dermatological diagnoses, where the analysis of dermatoscopic\nand microscopic skin lesion images is pivotal for the accurate and early\ndetection of various medical conditions, the costs associated with creating\ndiverse and high-quality annotated datasets have hampered the accuracy and\ngeneralizability of machine learning models. We propose an innovative\nunsupervised augmentation solution that harnesses Generative Adversarial\nNetwork (GAN) based models and associated techniques over their latent space to\ngenerate controlled semiautomatically-discovered semantic variations in\ndermatoscopic images. We created synthetic images to incorporate the semantic\nvariations and augmented the training data with these images. With this\napproach, we were able to increase the performance of machine learning models\nand set a new benchmark amongst non-ensemble based models in skin lesion\nclassification on the HAM10000 dataset; and used the observed analytics and\ngenerated models for detailed studies on model explainability, affirming the\neffectiveness of our solution.",
      "tldr_zh": "该研究针对皮肤病诊断中高质量标注数据集成本高的问题，提出了一种创新的无监督增强方法，使用GAN（Generative Adversarial Network）和Closed-Form Factorization在潜在空间中生成受控的语义变异皮肤镜图像。研究者将这些合成图像添加到训练数据中，提升了机器学习模型的性能，并在HAM10000数据集上设定了非集成模型的新基准。最终，通过模型可解释性分析，证实了该方法的有效性，为皮肤病变分类提供了更准确和泛化的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This preprint has been submitted to the Workshop on Synthetic Data\n  for Computer Vision (SyntheticData4CV 2024 is a side event on 18th European\n  Conference on Computer Vision 2024). This preprint has not undergone peer\n  review or any post-submission improvements or corrections",
      "pdf_url": "http://arxiv.org/pdf/2410.05114v1",
      "published_date": "2024-10-07 15:09:50 UTC",
      "updated_date": "2024-10-07 15:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:06:34.241617"
    },
    {
      "arxiv_id": "2410.05105v1",
      "title": "AI-Enhanced Ethical Hacking: A Linux-Focused Experiment",
      "title_zh": "AI 增强的道德黑客：以 Linux 为重点的实验",
      "authors": [
        "Haitham S. Al-Sinani",
        "Chris J. Mitchell"
      ],
      "abstract": "This technical report investigates the integration of generative AI (GenAI),\nspecifically ChatGPT, into the practice of ethical hacking through a\ncomprehensive experimental study and conceptual analysis. Conducted in a\ncontrolled virtual environment, the study evaluates GenAI's effectiveness\nacross the key stages of penetration testing on Linux-based target machines\noperating within a virtual local area network (LAN), including reconnaissance,\nscanning and enumeration, gaining access, maintaining access, and covering\ntracks. The findings confirm that GenAI can significantly enhance and\nstreamline the ethical hacking process while underscoring the importance of\nbalanced human-AI collaboration rather than the complete replacement of human\ninput. The report also critically examines potential risks such as misuse, data\nbiases, hallucination, and over-reliance on AI. This research contributes to\nthe ongoing discussion on the ethical use of AI in cybersecurity and highlights\nthe need for continued innovation to strengthen security defences.",
      "tldr_zh": "这篇技术报告通过实验研究探讨了生成式 AI（如 ChatGPT）在道德黑客实践中的应用，重点评估其在受控虚拟环境中的 Linux 目标机器上进行渗透测试的各个阶段，包括侦察、扫描和枚举、获取访问、维护访问以及覆盖跟踪。结果表明，GenAI 能显著提升和简化道德黑客过程，但强调需要平衡的人类-AI 协作，而非完全取代人类输入。报告还分析了潜在风险，如误用、数据偏差、幻觉和过度依赖 AI，并为 AI 在网络安全的道德使用提供见解，推动相关领域的创新和安全防御加强。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05105v1",
      "published_date": "2024-10-07 15:02:47 UTC",
      "updated_date": "2024-10-07 15:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:06:42.578812"
    },
    {
      "arxiv_id": "2410.09087v1",
      "title": "Mechanistic?",
      "title_zh": "翻译失败",
      "authors": [
        "Naomi Saphra",
        "Sarah Wiegreffe"
      ],
      "abstract": "The rise of the term \"mechanistic interpretability\" has accompanied\nincreasing interest in understanding neural models -- particularly language\nmodels. However, this jargon has also led to a fair amount of confusion. So,\nwhat does it mean to be \"mechanistic\"? We describe four uses of the term in\ninterpretability research. The most narrow technical definition requires a\nclaim of causality, while a broader technical definition allows for any\nexploration of a model's internals. However, the term also has a narrow\ncultural definition describing a cultural movement. To understand this semantic\ndrift, we present a history of the NLP interpretability community and the\nformation of the separate, parallel \"mechanistic\" interpretability community.\nFinally, we discuss the broad cultural definition -- encompassing the entire\nfield of interpretability -- and why the traditional NLP interpretability\ncommunity has come to embrace it. We argue that the polysemy of \"mechanistic\"\nis the product of a critical divide within the interpretability community.",
      "tldr_zh": "这篇论文探讨了“mechanistic interpretability”术语在神经模型解释性研究中的多重含义，分析了其四个定义：狭义技术定义（要求因果关系声明）、广义技术定义（任何模型内部探索）、狭义文化定义（描述一个文化运动），以及广义文化定义（涵盖整个解释性领域）。作者通过回顾NLP解释性社区的历史和“mechanistic”社区的形成，解释了这一术语的语义漂移。最终，论文认为术语的多义性反映了解释性社区内部的关键分歧，为未来研究提供澄清和统一基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Equal contribution. Position paper. Accepted for presentation at the\n  BlackBoxNLP workshop at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09087v1",
      "published_date": "2024-10-07 15:02:12 UTC",
      "updated_date": "2024-10-07 15:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:07:47.674704"
    },
    {
      "arxiv_id": "2410.05102v2",
      "title": "SparsePO: Controlling Preference Alignment of LLMs via Sparse Token Masks",
      "title_zh": "SparsePO：通过稀疏标记掩码控制大型语言模型的偏好对齐",
      "authors": [
        "Fenia Christopoulou",
        "Ronald Cardenas",
        "Gerasimos Lampouras",
        "Haitham Bou-Ammar",
        "Jun Wang"
      ],
      "abstract": "Preference Optimization (PO) has proven an effective step for aligning\nlanguage models to human-desired behaviors. Current variants, following the\noffline Direct Preference Optimization objective, have focused on a strict\nsetting where all tokens are contributing signals of KL divergence and rewards\nto the loss function. However, human preference is not affected by each word in\na sequence equally but is often dependent on specific words or phrases, e.g.\nexistence of toxic terms leads to non-preferred responses. Based on this\nobservation, we argue that not all tokens should be weighted equally during PO\nand propose a flexible objective termed SparsePO, that aims to automatically\nlearn to weight the KL divergence and reward corresponding to each token during\nPO training. We propose two different variants of weight-masks that can either\nbe derived from the reference model itself or learned on the fly. Notably, our\nmethod induces sparsity in the learned masks, allowing the model to learn how\nto best weight reward and KL divergence contributions at the token level,\nlearning an optimal level of mask sparsity. Extensive experiments on multiple\ndomains, including sentiment control, dialogue, text summarization and\ntext-to-code generation, illustrate that our approach assigns meaningful\nweights to tokens according to the target task, generates more responses with\nthe desired preference and improves reasoning tasks by up to 2 percentage\npoints compared to other token- and response-level PO methods.",
      "tldr_zh": "该研究针对语言模型(LLMs)的偏好优化(Preference Optimization, PO)问题，提出了一种名为SparsePO的新方法，通过稀疏token掩码自动学习为每个token的KL散度和奖励分配权重，以更好地对齐人类偏好。SparsePO包括两种掩码变体，可从参考模型派生或实时学习，并诱导掩码的稀疏性，从而优化token级别的贡献。实验在情感控制、对话、文本摘要和文本到代码生成等多个领域显示，该方法能根据任务赋予tokens有意义的权重，生成更多符合预期的响应，并在推理任务上比其他PO方法提高高达2个百分点。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 9 figures, 5 tables. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.05102v2",
      "published_date": "2024-10-07 15:01:29 UTC",
      "updated_date": "2024-10-08 15:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:07:15.627055"
    },
    {
      "arxiv_id": "2410.05094v1",
      "title": "On the Structure of Game Provenance and its Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Shawn Bowers",
        "Yilin Xia",
        "Bertram Ludäscher"
      ],
      "abstract": "Provenance in databases has been thoroughly studied for positive and for\nrecursive queries, then for first-order (FO) queries, i.e., having negation but\nno recursion. Query evaluation can be understood as a two-player game where the\nopponents argue whether or not a tuple is in the query answer. This\ngame-theoretic approach yields a natural provenance model for FO queries,\nunifying how and why-not provenance. Here, we study the fine-grain structure of\ngame provenance. A game $G=(V,E)$ consists of positions $V$ and moves $E$ and\ncan be solved by computing the well-founded model of a single, unstratifiable\nrule: \\[ \\text{win}(X) \\leftarrow \\text{move}(X, Y), \\neg \\, \\text{win}(Y). \\]\nIn the solved game $G^{\\lambda}$, the value of a position $x\\,{\\in}\\,V$ is\neither won, lost, or drawn. This value is explained by the provenance\n$\\mathscr{P}$(x), i.e., certain (annotated) edges reachable from $x$. We\nidentify seven edge types that give rise to new kinds of provenance, i.e.,\npotential, actual, and primary, and demonstrate that \"not all moves are created\nequal\". We describe the new provenance types, show how they can be computed\nwhile solving games, and discuss applications, e.g., for abstract argumentation\nframeworks.",
      "tldr_zh": "该论文探讨了数据库中游戏 Provenance 的结构及其应用，特别针对一阶逻辑（FO）查询，将查询评估视为两玩家游戏，以统一如何和为什么不 Provenance 模型。研究通过一个单规则计算 well-founded model，识别了七种边类型，导致新的 Provenance 类型，包括 potential、actual 和 primary，这些类型突显了不同移动的重要性。论文展示了这些类型如何在解决游戏过程中计算，并应用于如抽象论证框架等领域中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05094v1",
      "published_date": "2024-10-07 14:48:56 UTC",
      "updated_date": "2024-10-07 14:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:07:17.786877"
    },
    {
      "arxiv_id": "2410.09086v1",
      "title": "AI in Archival Science -- A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Shinde",
        "Tiana Kirstein",
        "Souvick Ghosh",
        "Patricia C. Franks"
      ],
      "abstract": "The rapid expansion of records creates significant challenges in management,\nincluding retention and disposition, appraisal, and organization. Our study\nunderscores the benefits of integrating artificial intelligence (AI) within the\nbroad realm of archival science. In this work, we start by performing a\nthorough analysis to understand the current use of AI in this area and identify\nthe techniques employed to address challenges. Subsequently, we document the\nresults of our review according to specific criteria. Our findings highlight\nkey AI driven strategies that promise to streamline record-keeping processes\nand enhance data retrieval efficiency. We also demonstrate our review process\nto ensure transparency regarding our methodology. Furthermore, this review not\nonly outlines the current state of AI in archival science and records\nmanagement but also lays the groundwork for integrating new techniques to\ntransform archival practices. Our research emphasizes the necessity for\nenhanced collaboration between the disciplines of artificial intelligence and\narchival science.",
      "tldr_zh": "这篇论文对AI在档案科学中的应用进行了系统审查，旨在解决记录管理中的挑战，如保留、评估和组织。研究通过彻底分析AI的当前使用和技术，结合特定标准的评估，突出了AI驱动策略，这些策略能简化记录保持过程并提升数据检索效率。论文还展示了透明的审查方法，并强调了加强AI和档案科学领域合作的需求，以推动未来档案实践的创新。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09086v1",
      "published_date": "2024-10-07 14:39:12 UTC",
      "updated_date": "2024-10-07 14:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:07:40.168998"
    },
    {
      "arxiv_id": "2410.05080v3",
      "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Ziru Chen",
        "Shijie Chen",
        "Yuting Ning",
        "Qianheng Zhang",
        "Boshi Wang",
        "Botao Yu",
        "Yifei Li",
        "Zeyi Liao",
        "Chen Wei",
        "Zitong Lu",
        "Vishal Dey",
        "Mingyi Xue",
        "Frazier N. Baker",
        "Benjamin Burns",
        "Daniel Adu-Ampratwum",
        "Xuhui Huang",
        "Xia Ning",
        "Song Gao",
        "Yu Su",
        "Huan Sun"
      ],
      "abstract": "The advancements of large language models (LLMs) have piqued growing interest\nin developing LLM-based language agents to automate scientific discovery\nend-to-end, which has sparked both excitement and skepticism about their true\ncapabilities. In this work, we call for rigorous assessment of agents on\nindividual tasks in a scientific workflow before making bold claims on\nend-to-end automation. To this end, we present ScienceAgentBench, a new\nbenchmark for evaluating language agents for data-driven scientific discovery.\nTo ensure the scientific authenticity and real-world relevance of our\nbenchmark, we extract 102 tasks from 44 peer-reviewed publications in four\ndisciplines and engage nine subject matter experts to validate them. We unify\nthe target output for every task to a self-contained Python program file and\nemploy an array of evaluation metrics to examine the generated programs,\nexecution results, and costs. Each task goes through multiple rounds of manual\nvalidation by annotators and subject matter experts to ensure its annotation\nquality and scientific plausibility. We also propose two effective strategies\nto mitigate data contamination concerns. Using ScienceAgentBench, we evaluate\nfive open-weight and proprietary LLMs, each with three frameworks: direct\nprompting, OpenHands CodeAct, and self-debug. Given three attempts for each\ntask, the best-performing agent can only solve 32.4% of the tasks independently\nand 34.3% with expert-provided knowledge. In addition, we evaluate OpenAI\no1-preview with direct prompting and self-debug, which can boost the\nperformance to 42.2%, demonstrating the effectiveness of increasing\ninference-time compute but with more than 10 times the cost of other LLMs.\nStill, our results underscore the limitations of current language agents in\ngenerating code for data-driven discovery, let alone end-to-end automation for\nscientific research.",
      "tldr_zh": "该研究提出ScienceAgentBench，一个用于评估语言代理在数据驱动科学发现中的新基准，旨在通过严格评估单个任务来检验大型语言模型(LLMs)端到端自动化的真实能力。基准从44篇同行评议出版物中提取102个任务，涉及四个学科，并由专家验证，每个任务统一输出为自包含的Python程序，并采用多种指标评估生成的程序、执行结果和成本。实验结果显示，五种LLMs及其框架（如直接提示、OpenHands CodeAct和自调试）的最佳表现仅能独立解决32.4%的任务，提供专家知识后为34.3%，而OpenAI o1-preview虽提升至42.2%但成本增加10倍以上，突显当前语言代理在生成代码和科学自动化方面的显著局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025. 60 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05080v3",
      "published_date": "2024-10-07 14:33:50 UTC",
      "updated_date": "2025-03-31 14:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:07:43.032871"
    },
    {
      "arxiv_id": "2410.05078v1",
      "title": "Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data",
      "title_zh": "通过预训练Transformer的压缩：字节级多",
      "authors": [
        "David Heurtel-Depeiges",
        "Anian Ruoss",
        "Joel Veness",
        "Tim Genewein"
      ],
      "abstract": "Foundation models have recently been shown to be strong data compressors.\nHowever, when accounting for their excessive parameter count, their compression\nratios are actually inferior to standard compression algorithms. Moreover,\nnaively reducing the number of parameters may not necessarily help as it leads\nto worse predictions and thus weaker compression. In this paper, we conduct a\nlarge-scale empirical study to investigate whether there is a sweet spot where\ncompetitive compression ratios with pre-trained vanilla transformers are\npossible. To this end, we train families of models on 165GB of raw byte\nsequences of either text, image, or audio data (and all possible combinations\nof the three) and then compress 1GB of out-of-distribution (OOD) data from each\nmodality. We find that relatively small models (i.e., millions of parameters)\ncan outperform standard general-purpose compression algorithms (gzip, LZMA2)\nand even domain-specific compressors (PNG, JPEG 2000, FLAC) - even when\nfactoring in parameter count. We achieve, e.g., the lowest compression ratio of\n0.49 on OOD audio data (vs. 0.54 for FLAC). To study the impact of model- and\ndataset scale, we conduct extensive ablations and hyperparameter sweeps, and we\ninvestigate the effect of unimodal versus multimodal training. We find that\neven small models can be trained to perform well on multiple modalities, but,\nin contrast to previously reported results with large-scale foundation models,\ntransfer to unseen modalities is generally weak.",
      "tldr_zh": "本研究探讨了使用预训练 transformers 进行字节级多模态数据压缩的可行性，通过大规模实证实验调查是否存在最佳参数规模，以实现竞争性的压缩比。研究者训练了数百万参数级别的模型，在165GB的文本、图像、音频数据及其组合上进行训练，然后评估对1GB的OOD（out-of-distribution）数据的压缩性能。结果显示，这些小模型超过了标准通用压缩算法（如gzip、LZMA2）和特定领域压缩器（如PNG、JPEG 2000、FLAC），例如在OOD音频数据上达到压缩比0.49（优于FLAC的0.54）。此外，实验发现小模型能处理多模态数据，但与大型Foundation models不同，其转移到未见模态的效果较弱。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05078v1",
      "published_date": "2024-10-07 14:32:03 UTC",
      "updated_date": "2024-10-07 14:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:08:01.350577"
    },
    {
      "arxiv_id": "2410.05076v1",
      "title": "TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Lijie Yang",
        "Zhihao Zhang",
        "Zhuofu Chen",
        "Zikun Li",
        "Zhihao Jia"
      ],
      "abstract": "Large language models (LLMs) have driven significant advancements across\ndiverse NLP tasks, with long-context models gaining prominence for handling\nextended inputs. However, the expanding key-value (KV) cache size required by\nTransformer architectures intensifies the memory constraints, particularly\nduring the decoding phase, creating a significant bottleneck. Existing sparse\nattention mechanisms designed to address this bottleneck have two limitations:\n(1) they often fail to reliably identify the most relevant tokens for\nattention, and (2) they overlook the spatial coherence of token selection\nacross consecutive Transformer layers, which can lead to performance\ndegradation and substantial overhead in token selection. This paper introduces\nTidalDecode, a simple yet effective algorithm and system for fast and accurate\nLLM decoding through position persistent sparse attention. TidalDecode\nleverages the spatial coherence of tokens selected by existing sparse attention\nmethods and introduces a few token selection layers that perform full attention\nto identify the tokens with the highest attention scores, while all other\nlayers perform sparse attention with the pre-selected tokens. This design\nenables TidalDecode to substantially reduce the overhead of token selection for\nsparse attention without sacrificing the quality of the generated results.\nEvaluation on a diverse set of LLMs and tasks shows that TidalDecode closely\nmatches the generative performance of full attention methods while reducing the\nLLM decoding latency by up to 2.1x.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)解码过程中的KV cache内存瓶颈问题，提出TidalDecode算法和系统，利用位置持久稀疏注意力(Position Persistent Sparse Attention)机制。TidalDecode通过在少数token选择层进行全注意力以识别高分token，而其他层采用预选token的稀疏注意力，从而减少token选择开销，同时保持生成质量。实验评估显示，在多种LLMs和任务上，TidalDecode的性能接近全注意力方法，但将解码延迟降低了高达2.1倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05076v1",
      "published_date": "2024-10-07 14:30:27 UTC",
      "updated_date": "2024-10-07 14:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:08:12.476006"
    },
    {
      "arxiv_id": "2410.05056v3",
      "title": "Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory",
      "title_zh": "随机迭代中 α-混合的转移及其在排队论中的应用",
      "authors": [
        "Attila Lovas"
      ],
      "abstract": "Nonlinear time series models with exogenous regressors are essential in\neconometrics, queuing theory, and machine learning, though their statistical\nanalysis remains incomplete. Key results, such as the law of large numbers and\nthe functional central limit theorem, are known for weakly dependent variables.\nWe demonstrate the transfer of mixing properties from the exogenous regressor\nto the response via coupling arguments. Additionally, we study Markov chains in\nrandom environments with drift and minorization conditions, even under\nnon-stationary environments with favorable mixing properties, and apply this\nframework to single-server queuing models.",
      "tldr_zh": "该论文探讨了非线性时间序列模型中 $α$-mixing 性质的转移问题，重点展示如何通过耦合参数(coupling arguments)将外生变量(exogenous regressor)的混合性质传递到响应变量(response)，以填补计量经济学、排队理论和机器学习领域的统计分析空白。研究者分析了随机环境下的Markov链，包括漂移和微小化条件(drift and minorization conditions)，即使在非平稳环境中也能保持良好的混合属性。最终，该框架应用于单服务器排队模型(single-server queuing models)，为大数定律和函数中心极限定理(functional central limit theorem)等关键结果提供了理论基础。",
      "categories": [
        "math.ST",
        "cs.AI",
        "math.PR",
        "stat.TH",
        "60K37, 60K25, 60J05, 60J20",
        "G.3; I.6.5; C.4"
      ],
      "primary_category": "math.ST",
      "comment": "39 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.05056v3",
      "published_date": "2024-10-07 14:13:37 UTC",
      "updated_date": "2025-04-22 15:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:08:24.310839"
    },
    {
      "arxiv_id": "2410.05050v2",
      "title": "FreSh: Frequency Shifting for Accelerated Neural Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Kania",
        "Marko Mihajlovic",
        "Sergey Prokudin",
        "Jacek Tabor",
        "Przemysław Spurek"
      ],
      "abstract": "Implicit Neural Representations (INRs) have recently gained attention as a\npowerful approach for continuously representing signals such as images, videos,\nand 3D shapes using multilayer perceptrons (MLPs). However, MLPs are known to\nexhibit a low-frequency bias, limiting their ability to capture high-frequency\ndetails accurately. This limitation is typically addressed by incorporating\nhigh-frequency input embeddings or specialized activation layers. In this work,\nwe demonstrate that these embeddings and activations are often configured with\nhyperparameters that perform well on average but are suboptimal for specific\ninput signals under consideration, necessitating a costly grid search to\nidentify optimal settings. Our key observation is that the initial frequency\nspectrum of an untrained model's output correlates strongly with the model's\neventual performance on a given target signal. Leveraging this insight, we\npropose frequency shifting (or FreSh), a method that selects embedding\nhyperparameters to align the frequency spectrum of the model's initial output\nwith that of the target signal. We show that this simple initialization\ntechnique improves performance across various neural representation methods and\ntasks, achieving results comparable to extensive hyperparameter sweeps but with\nonly marginal computational overhead compared to training a single model with\ndefault hyperparameters.",
      "tldr_zh": "本论文针对 Implicit Neural Representations (INRs) 中多层感知器 (MLPs) 的低频偏置问题，提出 FreSh 方法，以加速神经表示学习。FreSh 通过调整嵌入超参数，使未训练模型的初始输出频率谱与目标信号匹配，从而避免了传统高频嵌入或激活层的昂贵网格搜索。实验结果显示，该方法在各种任务上显著提升了性能，与全面超参数搜索相当，但仅需微小计算开销，比默认训练高效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Code at https://github.com/gmum/FreSh/",
      "pdf_url": "http://arxiv.org/pdf/2410.05050v2",
      "published_date": "2024-10-07 14:05:57 UTC",
      "updated_date": "2024-10-08 15:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:08:36.379807"
    },
    {
      "arxiv_id": "2410.16309v1",
      "title": "In-the-loop Hyper-Parameter Optimization for LLM-Based Automated Design of Heuristics",
      "title_zh": "翻译失败",
      "authors": [
        "Niki van Stein",
        "Diederick Vermetten",
        "Thomas Bäck"
      ],
      "abstract": "Large Language Models (LLMs) have shown great potential in automatically\ngenerating and optimizing (meta)heuristics, making them valuable tools in\nheuristic optimization tasks. However, LLMs are generally inefficient when it\ncomes to fine-tuning hyper-parameters of the generated algorithms, often\nrequiring excessive queries that lead to high computational and financial\ncosts. This paper presents a novel hybrid approach, LLaMEA-HPO, which\nintegrates the open source LLaMEA (Large Language Model Evolutionary Algorithm)\nframework with a Hyper-Parameter Optimization (HPO) procedure in the loop. By\noffloading hyper-parameter tuning to an HPO procedure, the LLaMEA-HPO framework\nallows the LLM to focus on generating novel algorithmic structures, reducing\nthe number of required LLM queries and improving the overall efficiency of the\noptimization process.\n  We empirically validate the proposed hybrid framework on benchmark problems,\nincluding Online Bin Packing, Black-Box Optimization, and the Traveling\nSalesperson Problem. Our results demonstrate that LLaMEA-HPO achieves superior\nor comparable performance compared to existing LLM-driven frameworks while\nsignificantly reducing computational costs. This work highlights the importance\nof separating algorithmic innovation and structural code search from parameter\ntuning in LLM-driven code optimization and offers a scalable approach to\nimprove the efficiency and effectiveness of LLM-based code generation.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在自动设计启发式算法时，超参数调优效率低下导致的高计算成本问题，提出了一种新型混合框架 LLaMEA-HPO。该框架将开源 LLaMEA (Large Language Model Evolutionary Algorithm) 与 Hyper-Parameter Optimization (HPO) 过程整合，让 LLMs 专注于生成新算法结构，同时由 HPO 处理超参数调优，从而减少 LLM 查询次数并提升整体效率。在 Online Bin Packing、Black-Box Optimization 和 Traveling Salesperson Problem 等基准问题上，实验结果显示 LLaMEA-HPO 比现有框架性能更优或相当，同时显著降低计算成本。该工作强调了在 LLM 驱动的代码优化中分离算法创新与参数调优的重要性，提供了一个可扩展的解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16309v1",
      "published_date": "2024-10-07 14:04:31 UTC",
      "updated_date": "2024-10-07 14:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:08:49.176683"
    },
    {
      "arxiv_id": "2410.05046v1",
      "title": "Named Clinical Entity Recognition Benchmark",
      "title_zh": "临床命名实体识别基准",
      "authors": [
        "Wadood M Abdul",
        "Marco AF Pimentel",
        "Muhammad Umar Salman",
        "Tathagata Raha",
        "Clément Christophe",
        "Praveen K Kanithi",
        "Nasir Hayat",
        "Ronnie Rajan",
        "Shadab Khan"
      ],
      "abstract": "This technical report introduces a Named Clinical Entity Recognition\nBenchmark for evaluating language models in healthcare, addressing the crucial\nnatural language processing (NLP) task of extracting structured information\nfrom clinical narratives to support applications like automated coding,\nclinical trial cohort identification, and clinical decision support.\n  The leaderboard provides a standardized platform for assessing diverse\nlanguage models, including encoder and decoder architectures, on their ability\nto identify and classify clinical entities across multiple medical domains. A\ncurated collection of openly available clinical datasets is utilized,\nencompassing entities such as diseases, symptoms, medications, procedures, and\nlaboratory measurements. Importantly, these entities are standardized according\nto the Observational Medical Outcomes Partnership (OMOP) Common Data Model,\nensuring consistency and interoperability across different healthcare systems\nand datasets, and a comprehensive evaluation of model performance. Performance\nof models is primarily assessed using the F1-score, and it is complemented by\nvarious assessment modes to provide comprehensive insights into model\nperformance. The report also includes a brief analysis of models evaluated to\ndate, highlighting observed trends and limitations.\n  By establishing this benchmarking framework, the leaderboard aims to promote\ntransparency, facilitate comparative analyses, and drive innovation in clinical\nentity recognition tasks, addressing the need for robust evaluation methods in\nhealthcare NLP.",
      "tldr_zh": "本研究引入了Named Clinical Entity Recognition Benchmark，这是一个用于评估语言模型在医疗领域性能的标准基准，专注于从临床叙述中提取结构化信息，以支持自动化编码、临床试验队列识别和临床决策支持等应用。基准利用公开可用的临床数据集，包括疾病、症状、药物、程序和实验室测量等实体，并根据Observational Medical Outcomes Partnership (OMOP) Common Data Model进行标准化，确保数据一致性和互操作性。模型性能主要通过F1-score评估，并结合多种评估模式，提供全面的见解，包括对已评估模型的趋势和限制分析。该框架旨在促进医疗NLP的透明性、比较分析和创新，推动临床实体识别任务的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2410.05046v1",
      "published_date": "2024-10-07 14:00:18 UTC",
      "updated_date": "2024-10-07 14:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:09:00.456950"
    },
    {
      "arxiv_id": "2410.05045v1",
      "title": "Can LLMs plan paths with extra hints from solvers?",
      "title_zh": "翻译失败",
      "authors": [
        "Erik Wu",
        "Sayan Mitra"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing, mathematical problem solving, and tasks related to program\nsynthesis. However, their effectiveness in long-term planning and higher-order\nreasoning has been noted to be limited and fragile. This paper explores an\napproach for enhancing LLM performance in solving a classical robotic planning\ntask by integrating solver-generated feedback. We explore four different\nstrategies for providing feedback, including visual feedback, we utilize\nfine-tuning, and we evaluate the performance of three different LLMs across a\n10 standard and 100 more randomly generated planning problems. Our results\nsuggest that the solver-generated feedback improves the LLM's ability to solve\nthe moderately difficult problems, but the harder problems still remain out of\nreach. The study provides detailed analysis of the effects of the different\nhinting strategies and the different planning tendencies of the evaluated LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在机器人路径规划任务中的性能，采用求解器生成的反馈（如视觉反馈）作为增强策略，并评估了四种反馈方法和fine-tuning技术。研究者测试了三个不同LLMs在10个标准问题和100个随机生成问题上的表现，结果显示反馈显著提高了LLMs解决中等难度问题的能力，但更难的问题仍未得到有效解决。该研究还对不同提示策略的影响以及LLMs的规划倾向进行了详细分析。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05045v1",
      "published_date": "2024-10-07 14:00:08 UTC",
      "updated_date": "2024-10-07 14:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:09:12.348897"
    },
    {
      "arxiv_id": "2410.05044v1",
      "title": "PhotoReg: Photometrically Registering 3D Gaussian Splatting Models",
      "title_zh": "PhotoReg：基于光度的三维高斯喷溅模型注册",
      "authors": [
        "Ziwen Yuan",
        "Tianyi Zhang",
        "Matthew Johnson-Roberson",
        "Weiming Zhi"
      ],
      "abstract": "Building accurate representations of the environment is critical for\nintelligent robots to make decisions during deployment. Advances in\nphotorealistic environment models have enabled robots to develop\nhyper-realistic reconstructions, which can be used to generate images that are\nintuitive for human inspection. In particular, the recently introduced\n\\ac{3DGS}, which describes the scene with up to millions of primitive\nellipsoids, can be rendered in real time. \\ac{3DGS} has rapidly gained\nprominence. However, a critical unsolved problem persists: how can we fuse\nmultiple \\ac{3DGS} into a single coherent model? Solving this problem will\nenable robot teams to jointly build \\ac{3DGS} models of their surroundings. A\nkey insight of this work is to leverage the {duality} between photorealistic\nreconstructions, which render realistic 2D images from 3D structure, and\n\\emph{3D foundation models}, which predict 3D structure from image pairs. To\nthis end, we develop PhotoReg, a framework to register multiple photorealistic\n\\ac{3DGS} models with 3D foundation models. As \\ac{3DGS} models are generally\nbuilt from monocular camera images, they have \\emph{arbitrary scale}. To\nresolve this, PhotoReg actively enforces scale consistency among the different\n\\ac{3DGS} models by considering depth estimates within these models. Then, the\nalignment is iteratively refined with fine-grained photometric losses to\nproduce high-quality fused \\ac{3DGS} models. We rigorously evaluate PhotoReg on\nboth standard benchmark datasets and our custom-collected datasets, including\nwith two quadruped robots. The code is released at\n\\url{ziweny11.github.io/photoreg}.",
      "tldr_zh": "该研究提出PhotoReg框架，用于光度注册多个3D Gaussian Splatting (3DGS)模型，以帮助智能机器人团队构建连贯的环境表示。PhotoReg利用3D基础模型的二元性，首先通过深度估计强制执行模型间的比例一致性，然后通过迭代细粒度的光度损失进行精炼对齐，从而生成高质量的融合3DGS模型。实验在标准基准数据集和自定义数据集（如涉及两台四足机器人）上验证了PhotoReg的有效性，显著提升了机器人环境重建的准确性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05044v1",
      "published_date": "2024-10-07 13:58:40 UTC",
      "updated_date": "2024-10-07 13:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:09:25.100479"
    },
    {
      "arxiv_id": "2410.10859v2",
      "title": "FAME: Towards Factual Multi-Task Model Editing",
      "title_zh": "FAME：面向",
      "authors": [
        "Li Zeng",
        "Yingyu Shan",
        "Zeming Liu",
        "Jiashu Yao",
        "Yuhang Guo"
      ],
      "abstract": "Large language models (LLMs) embed extensive knowledge and utilize it to\nperform exceptionally well across various tasks. Nevertheless, outdated\nknowledge or factual errors within LLMs can lead to misleading or incorrect\nresponses, causing significant issues in practical applications. To rectify the\nfatal flaw without the necessity for costly model retraining, various model\nediting approaches have been proposed to correct inaccurate knowledge within\nLLMs in a cost-efficient way. To evaluate these model editing methods, previous\nwork introduced a series of datasets. However, most of the previous datasets\nonly contain fabricated data in a single format, which diverges from real-world\nmodel editing scenarios, raising doubts about their usability in practice. To\nfacilitate the application of model editing in real-world scenarios, we propose\nthe challenge of practicality. To resolve such challenges and effectively\nenhance the capabilities of LLMs, we present FAME, an factual, comprehensive,\nand multi-task dataset, which is designed to enhance the practicality of model\nediting. We then propose SKEME, a model editing method that uses a novel\ncaching mechanism to ensure synchronization with the real world. The\nexperiments demonstrate that SKEME performs excellently across various tasks\nand scenarios, confirming its practicality.",
      "tldr_zh": "大型语言模型（LLMs）常因过时或错误知识而产生误导性响应，为解决此问题，论文提出FAME，这是一个事实性、全面的、多任务数据集，旨在提升模型编辑的实用性，以弥补现有数据集的单一格式局限。论文同时引入SKEME方法，该方法采用新型缓存机制确保模型与现实世界的同步，从而高效修正LLMs中的不准确知识。实验结果显示，SKEME在各种任务和场景中表现出色，验证了其实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures. This paper has been accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10859v2",
      "published_date": "2024-10-07 13:46:06 UTC",
      "updated_date": "2024-10-18 10:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:09:35.650585"
    },
    {
      "arxiv_id": "2410.05354v3",
      "title": "Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power Constraint",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Wang",
        "Cheng Zhang",
        "Yuanndon Zhuang",
        "Mingzeng Dai",
        "Haiming Wang",
        "Yongming Huang"
      ],
      "abstract": "Wireless networks supporting artificial intelligence have gained significant\nattention, with Over-the-Air Federated Learning emerging as a key application\ndue to its unique transmission and distributed computing characteristics. This\npaper derives error bounds for Over-the-Air Federated Learning in a Cell-free\nMIMO system and formulates an optimization problem to minimize optimality gap\nvia joint optimization of power control and beamforming. We introduce the\nMOP-LOFPC algorithm, which employs Lyapunov optimization to decouple long-term\nconstraints across rounds while requiring only causal channel state\ninformation. Experimental results demonstrate that MOP-LOFPC achieves a better\nand more flexible trade-off between the model's training loss and adherence to\nlong-term power constraints compared to existing baselines.",
      "tldr_zh": "这篇论文探讨了Over-the-Air Federated Learning在Cell-free MIMO系统中的应用，针对长期功率约束问题推导了错误边界，并通过联合优化功率控制和波束成形来最小化最优性差距。论文引入了MOP-LOFPC算法，利用Lyapunov优化来解耦长期约束，仅需因果信道状态信息。实验结果表明，该算法比现有基线在模型训练损失和长期功率约束之间实现了更优且更灵活的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05354v3",
      "published_date": "2024-10-07 13:44:49 UTC",
      "updated_date": "2024-10-23 09:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:09:51.534207"
    },
    {
      "arxiv_id": "2410.05353v2",
      "title": "Towards a Categorical Foundation of Deep Learning: A Survey",
      "title_zh": "迈向深度学习的范畴基础：一项综述",
      "authors": [
        "Francesco Riccardo Crescenzi"
      ],
      "abstract": "The unprecedented pace of machine learning research has lead to incredible\nadvances, but also poses hard challenges. At present, the field lacks strong\ntheoretical underpinnings, and many important achievements stem from ad hoc\ndesign choices which are hard to justify in principle and whose effectiveness\noften goes unexplained. Research debt is increasing and many papers are found\nnot to be reproducible.\n  This thesis is a survey that covers some recent work attempting to study\nmachine learning categorically. Category theory is a branch of abstract\nmathematics that has found successful applications in many fields, both inside\nand outside mathematics. Acting as a lingua franca of mathematics and science,\ncategory theory might be able to give a unifying structure to the field of\nmachine learning. This could solve some of the aforementioned problems.\n  In this work, we mainly focus on the application of category theory to deep\nlearning. Namely, we discuss the use of categorical optics to model\ngradient-based learning, the use of categorical algebras and integral\ntransforms to link classical computer science to neural networks, the use of\nfunctors to link different layers of abstraction and preserve structure, and,\nfinally, the use of string diagrams to provide detailed representations of\nneural network architectures.",
      "tldr_zh": "这篇调查论文探讨了使用范畴论（category theory）作为深度学习理论基础的可能性，旨在解决机器学习领域缺乏强有力理论支撑、可重复性差等问题。论文回顾了范畴论的应用，包括用categorical optics建模基于梯度的学习，用categorical algebras和integral transforms连接经典计算机科学与神经网络，用functors链接不同抽象层，以及用string diagrams详细表示神经网络架构。这些方法可能为机器学习提供统一的结构，提升其理论深度和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CT"
      ],
      "primary_category": "cs.LG",
      "comment": "In the previous version of the survey, it was stated that the paper\n  \"Pooling Image Datasets with Multiple Covariate Shift and Imbalance\" (Chytas,\n  Lokhande, Singh) had been withdrawn by the authors. I have been informed that\n  only an incomplete draft of the work was withdrawn after it was inadvertently\n  uploaded. The complete work was actually published at ICLR and has never been\n  withdrawn",
      "pdf_url": "http://arxiv.org/pdf/2410.05353v2",
      "published_date": "2024-10-07 13:11:16 UTC",
      "updated_date": "2024-10-14 18:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:10:00.233660"
    },
    {
      "arxiv_id": "2410.05352v2",
      "title": "Recent Advances of Multimodal Continual Learning: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Dianzhi Yu",
        "Xinni Zhang",
        "Yankai Chen",
        "Aiwei Liu",
        "Yifei Zhang",
        "Philip S. Yu",
        "Irwin King"
      ],
      "abstract": "Continual learning (CL) aims to empower machine learning models to learn\ncontinually from new data, while building upon previously acquired knowledge\nwithout forgetting. As machine learning models have evolved from small to large\npre-trained architectures, and from supporting unimodal to multimodal data,\nmultimodal continual learning (MMCL) methods have recently emerged. The primary\nchallenge of MMCL is that it goes beyond a simple stacking of unimodal CL\nmethods, as such straightforward approaches often yield unsatisfactory\nperformance. In this work, we present the first comprehensive survey on MMCL.\nWe provide essential background knowledge and MMCL settings, as well as a\nstructured taxonomy of MMCL methods. We categorize existing MMCL methods into\nfour categories, i.e., regularization-based, architecture-based, replay-based,\nand prompt-based methods, explaining their methodologies and highlighting their\nkey innovations. Additionally, to prompt further research in this field, we\nsummarize open MMCL datasets and benchmarks, and discuss several promising\nfuture directions for investigation and development. We have also created a\nGitHub repository for indexing relevant MMCL papers and open resources\navailable at https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning.",
      "tldr_zh": "这篇论文是关于多模态持续学习（Multimodal Continual Learning, MMCL）的首个全面调查，旨在探讨机器学习模型如何在处理多模态数据时持续学习并避免遗忘。论文提供了必要的背景知识和MMCL设置，并将现有方法分类为四类：regularization-based、architecture-based、replay-based和prompt-based，详细解释了它们的原理和创新点。作者还总结了开放数据集和基准，讨论了未来研究方向，并创建了GitHub仓库（https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning）来索引相关论文和资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05352v2",
      "published_date": "2024-10-07 13:10:40 UTC",
      "updated_date": "2024-10-11 03:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:10:16.166212"
    },
    {
      "arxiv_id": "2410.05351v1",
      "title": "Towards the generation of hierarchical attack models from cybersecurity vulnerabilities using language models",
      "title_zh": "翻译失败",
      "authors": [
        "Kacper Sowka",
        "Vasile Palade",
        "Xiaorui Jiang",
        "Hesam Jadidbonab"
      ],
      "abstract": "This paper investigates the use of a pre-trained language model and siamese\nnetwork to discern sibling relationships between text-based cybersecurity\nvulnerability data. The ultimate purpose of the approach presented in this\npaper is towards the construction of hierarchical attack models based on a set\nof text descriptions characterising potential/observed vulnerabilities in a\ngiven system. Due to the nature of the data, and the uncertainty sensitive\nenvironment in which the problem is presented, a practically oriented soft\ncomputing approach is necessary. Therefore, a key focus of this work is to\ninvestigate practical questions surrounding the reliability of predicted links\ntowards the construction of such models, to which end conceptual and practical\nchallenges and solutions associated with the proposed approach are outlined,\nsuch as dataset complexity and stability of predictions. Accordingly, the\ncontributions of this paper focus on producing neural networks using a\npre-trained language model for predicting sibling relationships between\ncybersecurity vulnerabilities, then outlining how to apply this capability\ntowards the generation of hierarchical attack models. In addition, two data\nsampling mechanisms for tackling data complexity, and a consensus mechanism for\nreducing the amount of false positive predictions are outlined. Each of these\napproaches is compared and contrasted using empirical results from three sets\nof cybersecurity data to determine their effectiveness.",
      "tldr_zh": "这篇论文探讨了使用预训练 language models 和 Siamese network 来识别文本-based 网络安全漏洞之间的 sibling relationships，从而构建 hierarchical attack models。研究重点在于解决数据复杂性和预测不确定性问题，提出两种数据采样机制和一个共识机制，以提高预测的可靠性和减少假阳性。实验结果通过三个网络安全数据集的对比，验证了这些方法的有效性，为生成层次化攻击模型提供了实用框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05351v1",
      "published_date": "2024-10-07 13:05:33 UTC",
      "updated_date": "2024-10-07 13:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:10:26.547639"
    },
    {
      "arxiv_id": "2410.17269v1",
      "title": "FairFML: Fair Federated Machine Learning with a Case Study on Reducing Gender Disparities in Cardiac Arrest Outcome Prediction",
      "title_zh": "FairF",
      "authors": [
        "Siqi Li",
        "Qiming Wu",
        "Xin Li",
        "Di Miao",
        "Chuan Hong",
        "Wenjun Gu",
        "Yuqing Shang",
        "Yohei Okada",
        "Michael Hao Chen",
        "Mengying Yan",
        "Yilin Ning",
        "Marcus Eng Hock Ong",
        "Nan Liu"
      ],
      "abstract": "Objective: Mitigating algorithmic disparities is a critical challenge in\nhealthcare research, where ensuring equity and fairness is paramount. While\nlarge-scale healthcare data exist across multiple institutions,\ncross-institutional collaborations often face privacy constraints, highlighting\nthe need for privacy-preserving solutions that also promote fairness.\n  Materials and Methods: In this study, we present Fair Federated Machine\nLearning (FairFML), a model-agnostic solution designed to reduce algorithmic\nbias in cross-institutional healthcare collaborations while preserving patient\nprivacy. As a proof of concept, we validated FairFML using a real-world\nclinical case study focused on reducing gender disparities in cardiac arrest\noutcome prediction.\n  Results: We demonstrate that the proposed FairFML framework enhances fairness\nin federated learning (FL) models without compromising predictive performance.\nOur findings show that FairFML improves model fairness by up to 65% compared to\nthe centralized model, while maintaining performance comparable to both local\nand centralized models, as measured by receiver operating characteristic\nanalysis.\n  Discussion and Conclusion: FairFML offers a promising and flexible solution\nfor FL collaborations, with its adaptability allowing seamless integration with\nvarious FL frameworks and models, from traditional statistical methods to deep\nlearning techniques. This makes FairFML a robust approach for developing fairer\nFL models across diverse clinical and biomedical applications.",
      "tldr_zh": "该研究提出 FairFML，一种模型无关的 Federated Machine Learning 框架，旨在减少跨机构医疗合作中的算法偏差，同时保护患者隐私。作者通过一个真实案例——减少心脏骤停预后预测中的性别差异——来验证该框架，结果显示 FairFML 比集中式模型提高了公平性高达 65%，并保持了与本地和集中式模型相当的预测性能。FairFML 的灵活性使其可无缝集成到各种联邦学习框架中，适用于多样化的临床应用，从而促进更公平的医疗 AI 开发。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17269v1",
      "published_date": "2024-10-07 13:02:04 UTC",
      "updated_date": "2024-10-07 13:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:10:38.681714"
    },
    {
      "arxiv_id": "2410.04990v1",
      "title": "Stage-Wise and Prior-Aware Neural Speech Phase Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Liu",
        "Yang Ai",
        "Hui-Peng Du",
        "Ye-Xin Lu",
        "Rui-Chen Zheng",
        "Zhen-Hua Ling"
      ],
      "abstract": "This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase\nPrediction (SP-NSPP) model, which predicts the phase spectrum from input\namplitude spectrum by two-stage neural networks. In the initial\nprior-construction stage, we preliminarily predict a rough prior phase spectrum\nfrom the amplitude spectrum. The subsequent refinement stage transforms the\namplitude spectrum into a refined high-quality phase spectrum conditioned on\nthe prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone\nand adopt adversarial training by innovatively introducing a phase spectrum\ndiscriminator (PSD). To further improve the continuity of the refined phase, we\nalso incorporate a time-frequency integrated difference (TFID) loss in the\nrefinement stage. Experimental results confirm that, compared to neural\nnetwork-based no-prior phase prediction methods, the proposed SP-NSPP achieves\nhigher phase prediction accuracy, thanks to introducing the coarse phase priors\nand diverse training criteria. Compared to iterative phase estimation\nalgorithms, our proposed SP-NSPP does not require multiple rounds of staged\niterations, resulting in higher generation efficiency.",
      "tldr_zh": "这篇论文提出了Stage-wise and Prior-aware Neural Speech Phase Prediction (SP-NSPP)模型，通过两阶段神经网络从输入幅度谱预测相位谱，以解决语音处理中的相位估计问题。第一阶段初步生成粗略的先验相位谱，第二阶段则基于此先验优化生成高质量相位谱，并采用ConvNeXt v2 blocks作为主干网络，同时引入phase spectrum discriminator (PSD)进行对抗训练和time-frequency integrated difference (TFID)损失来提升相位连续性。实验结果表明，与无先验神经网络方法相比，SP-NSPP实现了更高的相位预测准确率；与迭代相位估计算法相比，它无需多轮迭代，从而提高了生成效率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by SLT2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04990v1",
      "published_date": "2024-10-07 12:45:20 UTC",
      "updated_date": "2024-10-07 12:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:10:51.967040"
    },
    {
      "arxiv_id": "2410.17268v1",
      "title": "SPikE-SSM: A Sparse, Precise, and Efficient Spiking State Space Model for Long Sequences Learning",
      "title_zh": "SPikE-SSM：一种稀疏、精确且高效的脉冲状态空间模型，用于长序列学习",
      "authors": [
        "Yan Zhong",
        "Ruoyu Zhao",
        "Chao Wang",
        "Qinghai Guo",
        "Jianguo Zhang",
        "Zhichao Lu",
        "Luziwei Leng"
      ],
      "abstract": "Spiking neural networks (SNNs) provide an energy-efficient solution by\nutilizing the spike-based and sparse nature of biological systems. Since the\nadvent of Transformers, SNNs have struggled to compete with artificial networks\non long sequential tasks, until the recent emergence of state space models\n(SSMs), which offer superior computational efficiency and modeling capability.\nHowever, applying the highly capable SSMs to SNNs for long sequences learning\nposes three major challenges: (1) The membrane potential is determined by the\npast spiking history of the neuron, leading to reduced efficiency for sequence\nmodeling in parallel computing scenarios. (2) Complex dynamics of biological\nspiking neurons are crucial for functionality but challenging to simulate and\nexploit effectively in large networks. (3) It is arduous to maintain high\nsparsity while achieving high accuracy for spiking neurons without resorting to\ndense computing, as utilized in artificial neuron-based SSMs. To address them,\nwe propose a sparse, precise and efficient spiking SSM framework, termed\nSPikE-SSM. For (1), we propose a boundary compression strategy (PMBC) to\naccelerate the inference of the spiking neuron model, enabling parallel\nprocessing for long sequence learning. For (2), we propose a novel and concise\nneuron model incorporating reset-refractory mechanism to leverage the inherent\ntemporal dimension for dynamic computing with biological interpretability. For\n(3), we hierarchically integrate the proposed neuron model to the original SSM\nblock, and enhance the dynamics of SPikE-SSM by incorporating trainable\nthresholds and refractory magnitudes to balance accuracy and sparsity.\nExtensive experiments verify the effectiveness and robustness of SPikE-SSM on\nthe long range arena benchmarks and large language dataset WikiText-103,\nshowing the potential of dynamic spiking neurons in efficient long sequence\nlearning.",
      "tldr_zh": "该研究提出 SPikE-SSM，一种稀疏、精确且高效的尖峰状态空间模型（Spiking State Space Model），旨在解决 Spiking Neural Networks (SNNs) 在长序列学习中面临的效率和准确性挑战。论文针对三个主要问题设计了解决方案：通过边界压缩策略 (PMBC) 实现并行处理加速尖峰神经元的推理；引入一个新颖的神经元模型，整合重置-不应期机制 (reset-refractory mechanism) 以利用时间维度进行动态计算；以及层次化整合该模型到 SSM 块中，并添加可训练阈值和不应期幅度来平衡稀疏性和准确性。实验在 Long Range Arena 基准和 WikiText-103 数据集上验证了 SPikE-SSM 的有效性和鲁棒性，展示了动态尖峰神经元在高效长序列学习中的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17268v1",
      "published_date": "2024-10-07 12:20:38 UTC",
      "updated_date": "2024-10-07 12:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:11:03.326638"
    },
    {
      "arxiv_id": "2410.04974v3",
      "title": "6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongpai Gao",
        "Benjamin Planche",
        "Meng Zheng",
        "Anwesa Choudhuri",
        "Terrence Chen",
        "Ziyan Wu"
      ],
      "abstract": "Novel view synthesis has advanced significantly with the development of\nneural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,\nachieving high quality without compromising real-time rendering remains\nchallenging, particularly for physically-based ray tracing with view-dependent\neffects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D\nspatial-angular representation to better incorporate view-dependent effects,\nbut the Gaussian representation and control scheme are sub-optimal. In this\npaper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),\nwhich enhances color and opacity representations and leverages the additional\ndirectional information in the 6D space for optimized Gaussian control. Our\napproach is fully compatible with the 3DGS framework and significantly improves\nreal-time radiance field rendering by better modeling view-dependent effects\nand fine details. Experiments demonstrate that 6DGS significantly outperforms\n3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction\nof 66.5% Gaussian points compared to 3DGS. The project page is:\nhttps://gaozhongpai.github.io/6dgs/",
      "tldr_zh": "这篇论文提出了6DGS，一种增强型方向感知高斯喷溅技术，用于体积渲染，以解决NeRF和3DGS在实时渲染和视点相关效果方面的挑战。6DGS改进了颜色和不透明度表示，并利用6D空间的额外方向信息优化高斯控制，使其与3DGS框架完全兼容，从而更好地建模视点相关效果和细微细节。实验结果显示，6DGS在PSNR上比3DGS和N-DG提高了高达15.73 dB，同时减少了66.5%的Gaussian点，显著提升了渲染质量和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.04974v3",
      "published_date": "2024-10-07 12:16:36 UTC",
      "updated_date": "2025-03-11 00:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:11:18.290498"
    },
    {
      "arxiv_id": "2410.04968v1",
      "title": "Collaboration! Towards Robust Neural Methods for Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Jianan Zhou",
        "Yaoxin Wu",
        "Zhiguang Cao",
        "Wen Song",
        "Jie Zhang",
        "Zhiqi Shen"
      ],
      "abstract": "Despite enjoying desirable efficiency and reduced reliance on domain\nexpertise, existing neural methods for vehicle routing problems (VRPs) suffer\nfrom severe robustness issues -- their performance significantly deteriorates\non clean instances with crafted perturbations. To enhance robustness, we\npropose an ensemble-based Collaborative Neural Framework (CNF) w.r.t. the\ndefense of neural VRP methods, which is crucial yet underexplored in the\nliterature. Given a neural VRP method, we adversarially train multiple models\nin a collaborative manner to synergistically promote robustness against\nattacks, while boosting standard generalization on clean instances. A neural\nrouter is designed to adeptly distribute training instances among models,\nenhancing overall load balancing and collaborative efficacy. Extensive\nexperiments verify the effectiveness and versatility of CNF in defending\nagainst various attacks across different neural VRP methods. Notably, our\napproach also achieves impressive out-of-distribution generalization on\nbenchmark instances.",
      "tldr_zh": "该研究针对车辆路径问题 (VRPs) 的神经方法存在的鲁棒性问题（如对扰动敏感），提出了一种基于集成的 Collaborative Neural Framework (CNF)。CNF 通过协作对抗训练多个模型，协同提升对攻击的防御能力，同时优化在干净实例上的泛化性能；其中，neural router 被设计用于智能分配训练实例，实现负载平衡和协作效率。实验结果显示，CNF 在各种攻击下表现出色，具有通用性，并实现了出色的 out-of-distribution 泛化性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04968v1",
      "published_date": "2024-10-07 12:12:51 UTC",
      "updated_date": "2024-10-07 12:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:11:26.154539"
    },
    {
      "arxiv_id": "2410.04962v1",
      "title": "Activation Scaling for Steering and Interpreting Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Stoehr",
        "Kevin Du",
        "Vésteinn Snæbjarnarson",
        "Robert West",
        "Ryan Cotterell",
        "Aaron Schein"
      ],
      "abstract": "Given the prompt \"Rome is in\", can we steer a language model to flip its\nprediction of an incorrect token \"France\" to a correct token \"Italy\" by only\nmultiplying a few relevant activation vectors with scalars? We argue that\nsuccessfully intervening on a model is a prerequisite for interpreting its\ninternal workings. Concretely, we establish a three-term objective: a\nsuccessful intervention should flip the correct with the wrong token and vice\nversa (effectiveness), and leave other tokens unaffected (faithfulness), all\nwhile being sparse (minimality). Using gradient-based optimization, this\nobjective lets us learn (and later evaluate) a specific kind of efficient and\ninterpretable intervention: activation scaling only modifies the signed\nmagnitude of activation vectors to strengthen, weaken, or reverse the steering\ndirections already encoded in the model. On synthetic tasks, this intervention\nperforms comparably with steering vectors in terms of effectiveness and\nfaithfulness, but is much more minimal allowing us to pinpoint interpretable\nmodel components. We evaluate activation scaling from different angles, compare\nperformance on different datasets, and make activation scalars a learnable\nfunction of the activation vectors themselves to generalize to varying-length\nprompts.",
      "tldr_zh": "本研究提出了一种激活缩放（activation scaling）方法，用于引导和解释语言模型的内部工作机制，旨在通过乘以标量来干预特定激活向量，从而纠正模型的错误预测，例如将“Rome is in France”改为正确输出“Italy”。该方法基于一个三项目标：确保干预有效（effectiveness，即翻转正确与错误标记）、忠实（faithfulness，即不影响其他标记），并保持稀疏性（minimality）。通过梯度优化（gradient-based optimization），激活缩放仅修改激活向量的符号幅度，以加强、削弱或逆转模型的引导方向；在合成任务上，该方法与引导向量（steering vectors）在有效性和忠实性方面相当，但更具最小化优势，便于识别可解释的模型组件，并通过使激活标量成为激活向量的可学习函数，实现对不同长度提示的泛化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of the Association for Computational Linguistics: EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04962v1",
      "published_date": "2024-10-07 12:01:32 UTC",
      "updated_date": "2024-10-07 12:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:11:39.632020"
    },
    {
      "arxiv_id": "2410.17267v1",
      "title": "Zero-Shot Vision-and-Language Navigation with Collision Mitigation in Continuous Environment",
      "title_zh": "零样本视觉-语言导航，带有碰撞缓解，在连续环境",
      "authors": [
        "Seongjun Jeong",
        "Gi-Cheon Kang",
        "Joochan Kim",
        "Byoung-Tak Zhang"
      ],
      "abstract": "We propose the zero-shot Vision-and-Language Navigation with Collision\nMitigation (VLN-CM), which takes these considerations. VLN-CM is composed of\nfour modules and predicts the direction and distance of the next movement at\neach step. We utilize large foundation models for each modules. To select the\ndirection, we use the Attention Spot Predictor (ASP), View Selector (VS), and\nProgress Monitor (PM). The ASP employs a Large Language Model (e.g. ChatGPT) to\nsplit navigation instructions into attention spots, which are objects or scenes\nat the location to move to (e.g. a yellow door). The VS selects from panorama\nimages provided at 30-degree intervals the one that includes the attention\nspot, using CLIP similarity. We then choose the angle of the selected image as\nthe direction to move in. The PM uses a rule-based approach to decide which\nattention spot to focus on next, among multiple spots derived from the\ninstructions. If the similarity between the current attention spot and the\nvisual observations decreases consecutively at each step, the PM determines\nthat the agent has passed the current spot and moves on to the next one. For\nselecting the distance to move, we employed the Open Map Predictor (OMP). The\nOMP uses panorama depth information to predict an occupancy mask. We then\nselected a collision-free distance in the predicted direction based on the\noccupancy mask. We evaluated our method using the validation data of VLN-CE.\nOur approach showed better performance than several baseline methods, and the\nOPM was effective in mitigating collisions for the agent.",
      "tldr_zh": "这篇论文提出了 Zero-Shot Vision-and-Language Navigation with Collision Mitigation (VLN-CM)，一个零样本视觉语言导航框架，旨在在连续环境中实现导航指令执行的同时减少碰撞。VLN-CM 由四个模块组成：Attention Spot Predictor (ASP) 使用 Large Language Model（如 ChatGPT）分解指令为注意力点；View Selector (VS) 利用 CLIP 相似度从全景图像中选择方向；Progress Monitor (PM) 通过规则-based 方法监控进度并切换注意力点；Open Map Predictor (OMP) 基于深度信息预测占用掩码以选择无碰撞距离。实验在 VLN-CE 数据集上显示，该方法比基线模型性能更优，并证明 OMP 有效缓解了代理的碰撞问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17267v1",
      "published_date": "2024-10-07 11:59:01 UTC",
      "updated_date": "2024-10-07 11:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:11:51.741983"
    },
    {
      "arxiv_id": "2410.04949v2",
      "title": "Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law",
      "title_zh": "利用知识图谱和大语言模型进行法律条文推荐：中国刑法的一个案例研究",
      "authors": [
        "Yongming Chen",
        "Miner Chen",
        "Ye Zhu",
        "Juan Pei",
        "Siyu Chen",
        "Yu Zhou",
        "Yi Wang",
        "Yifan Zhou",
        "Hao Li",
        "Songan Zhang"
      ],
      "abstract": "Court efficiency is vital for social stability. However, in most countries\naround the world, the grassroots courts face case backlogs, with decisions\nrelying heavily on judicial personnel's cognitive labor, lacking intelligent\ntools to improve efficiency. To address this issue, we propose an efficient law\narticle recommendation approach utilizing a Knowledge Graph (KG) and a Large\nLanguage Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge\nGraph (CLAKG) as a database to store current law statutes, historical case\ninformation, and correspondence between law articles and historical cases.\nAdditionally, we introduce an automated CLAKG construction method based on LLM.\nOn this basis, we propose a closed-loop law article recommendation method.\nFinally, through a series of experiments using judgment documents from the\nwebsite \"China Judgements Online\", we have improved the accuracy of law article\nrecommendation in cases from 0.549 to 0.694, demonstrating that our proposed\nmethod significantly outperforms baseline approaches.",
      "tldr_zh": "本研究针对法院案件积压和效率低下的问题，提出了一种利用 Knowledge Graph (KG) 和 Large Language Model (LLM) 的法律条款推荐方法，以中国刑法为例。首先，构建了 Case-Enhanced Law Article Knowledge Graph (CLAKG) 作为数据库，存储法律法规、历史案例及其对应关系，并引入基于 LLM 的自动构建方法。其次，开发了闭环推荐机制，通过实验验证，使用\"中国裁判文书网\"的判决文件，将法律条款推荐准确率从 0.549 提升至 0.694，显著优于基线方法。整体框架有助于提升司法效率和智能化水平。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04949v2",
      "published_date": "2024-10-07 11:45:04 UTC",
      "updated_date": "2025-03-09 05:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:12:02.651816"
    },
    {
      "arxiv_id": "2410.04946v1",
      "title": "Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Borja Carrillo Perez"
      ],
      "abstract": "In an era where maritime infrastructures are crucial, advanced situational\nawareness solutions are increasingly important. The use of optical camera\nsystems can allow real-time usage of maritime footage. This thesis presents an\ninvestigation into leveraging deep learning and computer vision to advance\nreal-time ship recognition and georeferencing for the improvement of maritime\nsituational awareness. A novel dataset, ShipSG, is introduced, containing 3,505\nimages and 11,625 ship masks with corresponding class and geographic position.\nAfter an exploration of state-of-the-art, a custom real-time segmentation\narchitecture, ScatYOLOv8+CBAM, is designed for the NVIDIA Jetson AGX Xavier\nembedded system. This architecture adds the 2D scattering transform and\nattention mechanisms to YOLOv8, achieving an mAP of 75.46% and an 25.3 ms per\nframe, outperforming state-of-the-art methods by over 5%. To improve small and\ndistant ship recognition in high-resolution images on embedded systems, an\nenhanced slicing mechanism is introduced, improving mAP by 8% to 11%.\nAdditionally, a georeferencing method is proposed, achieving positioning errors\nof 18 m for ships up to 400 m away and 44 m for ships between 400 m and 1200 m.\nThe findings are also applied in real-world scenarios, such as the detection of\nabnormal ship behaviour, camera integrity assessment and 3D reconstruction. The\napproach of this thesis outperforms existing methods and provides a framework\nfor integrating recognized and georeferenced ships into real-time systems,\nenhancing operational effectiveness and decision-making for maritime\nstakeholders. This thesis contributes to the maritime computer vision field by\nestablishing a benchmark for ship segmentation and georeferencing research,\ndemonstrating the viability of deep-learning-based recognition and\ngeoreferencing methods for real-time maritime monitoring.",
      "tldr_zh": "本文利用深度学习和计算机视觉技术，开发实时船舶识别和地理定位方法，以提升海上态势感知。研究引入新数据集ShipSG，包含3505张图像和11625个船舶掩码，并设计了自定义架构ScatYOLOv8+CBAM，在NVIDIA Jetson AGX Xavier上实现mAP 75.46%和每帧25.3 ms的性能，比现有方法提高5%。此外，提出增强的切片机制，提高小船和远距离识别的mAP 8%至11%，以及一个地理定位方法，定位误差分别为18 m（400 m内）和44 m（400-1200 m）。该框架应用于实际场景，如异常行为检测、相机完整性评估和3D重建，为海上监控提供基准并提升决策效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04946v1",
      "published_date": "2024-10-07 11:43:42 UTC",
      "updated_date": "2024-10-07 11:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:12:16.841689"
    },
    {
      "arxiv_id": "2410.04941v4",
      "title": "Detecting and Approximating Redundant Computational Blocks in Neural Networks",
      "title_zh": "检测并近似神经网络中的冗余计算块",
      "authors": [
        "Irene Cannistraci",
        "Emanuele Rodolà",
        "Bastian Rieck"
      ],
      "abstract": "Deep neural networks often learn similar internal representations, both\nacross different models and within their own layers. While inter-network\nsimilarities have enabled techniques such as model stitching and merging,\nintra-network similarities present new opportunities for designing more\nefficient architectures. In this paper, we investigate the emergence of these\ninternal similarities across different layers in diverse neural architectures,\nshowing that similarity patterns emerge independently of the datataset used. We\nintroduce a simple metric, Block Redundancy, to detect redundant blocks,\nproviding a foundation for future architectural optimization methods. Building\non this, we propose Redundant Blocks Approximation (RBA), a general framework\nthat identifies and approximates one or more redundant computational blocks\nusing simpler transformations. We show that the transformation $\\mathcal{T}$\nbetween two representations can be efficiently computed in closed-form, and it\nis enough to replace the redundant blocks from the network. RBA reduces model\nparameters and time complexity while maintaining good performance. We validate\nour method on classification tasks in the vision domain using a variety of\npretrained foundational models and datasets.",
      "tldr_zh": "本研究发现，深层神经网络在不同模型和内部层之间经常出现内部相似性（intra-network similarities），这为设计更高效架构提供了机会。论文引入了 Block Redundancy 指标来检测冗余计算块，并提出 Redundant Blocks Approximation (RBA) 框架，该框架通过高效计算变换 \\(\\mathcal{T}\\) 来识别并用更简单的变换近似这些冗余块，从而减少模型参数和时间复杂度。实验在视觉领域的分类任务上，使用各种预训练模型和数据集验证了 RBA 的有效性，同时保持了良好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 10 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.04941v4",
      "published_date": "2024-10-07 11:35:24 UTC",
      "updated_date": "2024-10-11 08:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:12:27.137913"
    },
    {
      "arxiv_id": "2410.11862v1",
      "title": "Towards using Reinforcement Learning for Scaling and Data Replication in Cloud Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Riad Mokadem",
        "Fahem Arar",
        "Djamel Eddine Zegour"
      ],
      "abstract": "Given its intuitive nature, many Cloud providers opt for threshold-based data\nreplication to enable automatic resource scaling. However, setting thresholds\neffectively needs human intervention to calibrate thresholds for each metric\nand requires a deep knowledge of current workload trends, which can be\nchallenging to achieve. Reinforcement learning is used in many areas related to\nthe Cloud Computing, and it is a promising field to get automatic data\nreplication strategies. In this work, we survey data replication strategies and\ndata scaling based on reinforcement learning (RL).",
      "tldr_zh": "云提供商通常采用基于阈值的data replication策略来实现自动资源scaling，但这种方法需要人工干预来校准阈值，并依赖于对当前工作负载趋势的深入了解，这可能很具挑战性。论文探讨了Reinforcement Learning (RL)在云计算相关领域的应用，并强调RL是一种有前景的技术，用于开发自动data replication策略。该研究通过调查基于RL的数据replication和scaling策略，提供了潜在解决方案的概述。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11862v1",
      "published_date": "2024-10-07 11:32:35 UTC",
      "updated_date": "2024-10-07 11:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:12:38.373922"
    },
    {
      "arxiv_id": "2410.04936v1",
      "title": "Training Interactive Agent in Large FPS Game Map with Rule-enhanced Reinforcement Learning",
      "title_zh": "在大型",
      "authors": [
        "Chen Zhang",
        "Huan Hu",
        "Yuan Zhou",
        "Qiyang Cao",
        "Ruochen Liu",
        "Wenya Wei",
        "Elvis S. Liu"
      ],
      "abstract": "In the realm of competitive gaming, 3D first-person shooter (FPS) games have\ngained immense popularity, prompting the development of game AI systems to\nenhance gameplay. However, deploying game AI in practical scenarios still poses\nchallenges, particularly in large-scale and complex FPS games. In this paper,\nwe focus on the practical deployment of game AI in the online multiplayer\ncompetitive 3D FPS game called Arena Breakout, developed by Tencent Games. We\npropose a novel gaming AI system named Private Military Company Agent (PMCA),\nwhich is interactable within a large game map and engages in combat with\nplayers while utilizing tactical advantages provided by the surrounding\nterrain.\n  To address the challenges of navigation and combat in modern 3D FPS games, we\nintroduce a method that combines navigation mesh (Navmesh) and shooting-rule\nwith deep reinforcement learning (NSRL). The integration of Navmesh enhances\nthe agent's global navigation capabilities while shooting behavior is\ncontrolled using rule-based methods to ensure controllability. NSRL employs a\nDRL model to predict when to enable the navigation mesh, resulting in a diverse\nrange of behaviors for the game AI. Customized rewards for human-like behaviors\nare also employed to align PMCA's behavior with that of human players.",
      "tldr_zh": "本论文针对大型 3D FPS 游戏（如腾讯的 Arena Breakout）中部署游戏 AI 的挑战，提出了一种名为 Private Military Company Agent (PMCA) 的交互式 AI 系统，该系统能在广阔游戏地图上进行导航、战斗并利用地形优势。研究引入 NSRL 方法，将 Navigation Mesh (Navmesh) 与射击规则结合深度强化学习 (DRL)，其中 Navmesh 提升全局导航能力，射击行为由规则控制，而 DRL 模型决定何时激活 Navmesh，以实现 AI 行为的多样性。论文还采用自定义奖励机制，使 PMCA 的行为更接近人类玩家，从而提高游戏 AI 的实用性和可控性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04936v1",
      "published_date": "2024-10-07 11:27:45 UTC",
      "updated_date": "2024-10-07 11:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:12:51.341349"
    },
    {
      "arxiv_id": "2410.04931v1",
      "title": "The Role of Governments in Increasing Interconnected Post-Deployment Monitoring of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Merlin Stein",
        "Jamie Bernardi",
        "Connor Dunlop"
      ],
      "abstract": "Language-based AI systems are diffusing into society, bringing positive and\nnegative impacts. Mitigating negative impacts depends on accurate impact\nassessments, drawn from an empirical evidence base that makes causal\nconnections between AI usage and impacts. Interconnected post-deployment\nmonitoring combines information about model integration and use, application\nuse, and incidents and impacts. For example, inference time monitoring of\nchain-of-thought reasoning can be combined with long-term monitoring of\nsectoral AI diffusion, impacts and incidents. Drawing on information sharing\nmechanisms in other industries, we highlight example data sources and specific\ndata points that governments could collect to inform AI risk management.",
      "tldr_zh": "这篇论文探讨了政府在加强 AI 部署后互联监控（post-deployment monitoring）中的作用，以缓解语言-based AI 系统在社会中的负面影响。论文强调，通过整合模型使用、应用部署和事件影响的数据，实现准确的影响评估和因果分析，例如结合推理时间监控（chain-of-thought reasoning）和部门 AI 扩散的长期跟踪。借鉴其他行业的信息共享机制，论文建议政府收集特定数据点，以提升 AI 风险管理策略的实效性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.04931v1",
      "published_date": "2024-10-07 11:24:29 UTC",
      "updated_date": "2024-10-07 11:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:13:03.276492"
    },
    {
      "arxiv_id": "2410.17266v1",
      "title": "Temporal Relational Reasoning of Large Language Models for Detecting Stock Portfolio Crashes",
      "title_zh": "大型语言模型的时间关系推理用于检测股票投资组合崩盘",
      "authors": [
        "Kelvin J. L. Koa",
        "Yunshan Ma",
        "Ritchie Ng",
        "Huanhuan Zheng",
        "Tat-Seng Chua"
      ],
      "abstract": "Stock portfolios are often exposed to rare consequential events (e.g., 2007\nglobal financial crisis, 2020 COVID-19 stock market crash), as they do not have\nenough historical information to learn from. Large Language Models (LLMs) now\npresent a possible tool to tackle this problem, as they can generalize across\ntheir large corpus of training data and perform zero-shot reasoning on new\nevents, allowing them to detect possible portfolio crash events without\nrequiring specific training data. However, detecting portfolio crashes is a\ncomplex problem that requires more than basic reasoning abilities. Investors\nneed to dynamically process the impact of each new information found in the\nnews articles, analyze the the relational network of impacts across news events\nand portfolio stocks, as well as understand the temporal context between\nimpacts across time-steps, in order to obtain the overall aggregated effect on\nthe target portfolio. In this work, we propose an algorithmic framework named\nTemporal Relational Reasoning (TRR). It seeks to emulate the spectrum of human\ncognitive capabilities used for complex problem-solving, which include\nbrainstorming, memory, attention and reasoning. Through extensive experiments,\nwe show that TRR is able to outperform state-of-the-art solutions on detecting\nstock portfolio crashes, and demonstrate how each of the proposed components\nhelp to contribute to its performance through an ablation study. Additionally,\nwe further explore the possible applications of TRR by extending it to other\nrelated complex problems, such as the detection of possible global crisis\nevents in Macroeconomics.",
      "tldr_zh": "本研究探讨了利用大型语言模型 (LLMs) 来检测股票投资组合崩盘事件，针对罕见事件（如金融危机）缺乏历史数据的挑战。论文提出 Temporal Relational Reasoning (TRR) 框架，该框架模拟人类认知能力，包括脑力激荡、记忆、注意力及推理，以动态处理新闻信息的影响、事件间关系网络以及时间上下文。实验结果显示，TRR 在崩盘检测上优于最先进方法，并通过消融研究验证了各组件的贡献；此外，该框架可扩展应用于宏观经济领域的全球危机事件检测。",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17266v1",
      "published_date": "2024-10-07 11:15:52 UTC",
      "updated_date": "2024-10-07 11:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:13:16.097047"
    },
    {
      "arxiv_id": "2410.04916v1",
      "title": "Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Yang",
        "Kai Zhou",
        "Yuni Lai",
        "Gaolei Li"
      ],
      "abstract": "With the trend of large graph learning models, business owners tend to employ\na model provided by a third party to deliver business services to users.\nHowever, these models might be backdoored, and malicious users can submit\ntrigger-embedded inputs to manipulate the model predictions. Current graph\nbackdoor defenses have several limitations: 1) depending on model-related\ndetails, 2) requiring additional model fine-tuning, and 3) relying upon extra\nexplainability tools, all of which are infeasible under stringent privacy\npolicies. To address those limitations, we propose GraphProt, which allows\nresource-constrained business owners to rely on third parties to avoid backdoor\nattacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and\nonly relies on the input graph. The key insight is to leverage subgraph\ninformation for prediction, thereby mitigating backdoor effects induced by\ntriggers. GraphProt comprises two components: clustering-based trigger\nelimination and robust subgraph ensemble. Specifically, we first propose\nfeature-topology clustering that aims to remove most of the anomalous subgraphs\n(triggers). Moreover, we design subgraph sampling strategies based on\nfeature-topology clustering to build a robust classifier via majority vote.\nExperimental results across three backdoor attacks and six benchmark datasets\ndemonstrate that GraphProt significantly reduces the backdoor attack success\nrate while preserving the model accuracy on regular graph classification tasks.",
      "tldr_zh": "该研究提出 GraphProt，一种模型无关的 Defense-as-a-Service 框架，用于黑盒防护 GNN-based 图分类器免受后门攻击，而无需依赖模型细节或额外微调。GraphProt 核心方法包括基于特征-拓扑聚类的触发器消除，以移除异常子图，以及鲁棒子图集成策略，通过子图采样和多数投票构建鲁棒分类器。实验结果显示，在三种后门攻击和六个基准数据集上，GraphProt 显著降低了攻击成功率，同时保持了正常图分类任务的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "F.2.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04916v1",
      "published_date": "2024-10-07 11:04:38 UTC",
      "updated_date": "2024-10-07 11:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:13:27.813805"
    },
    {
      "arxiv_id": "2410.05349v1",
      "title": "SoK: Towards Security and Safety of Edge AI",
      "title_zh": "翻译失败",
      "authors": [
        "Tatjana Wingarz",
        "Anne Lauscher",
        "Janick Edinger",
        "Dominik Kaaser",
        "Stefan Schulte",
        "Mathias Fischer"
      ],
      "abstract": "Advanced AI applications have become increasingly available to a broad\naudience, e.g., as centrally managed large language models (LLMs). Such\ncentralization is both a risk and a performance bottleneck - Edge AI promises\nto be a solution to these problems. However, its decentralized approach raises\nadditional challenges regarding security and safety. In this paper, we argue\nthat both of these aspects are critical for Edge AI, and even more so, their\nintegration. Concretely, we survey security and safety threats, summarize\nexisting countermeasures, and collect open challenges as a call for more\nresearch in this area.",
      "tldr_zh": "这篇 SoK 论文探讨了 Edge AI 的安全（security）和安全（safety）问题，强调其去中心化特性虽能解决中心化 AI（如 LLMs）的风险和性能瓶颈，但也带来新的挑战。作者调查了相关威胁，总结了现有对策，并整合了安全与安全方面的关键需求，以突出二者的互补性。最终，论文识别出多个开放挑战，呼吁更多研究来提升 Edge AI 的可靠性和实际部署。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05349v1",
      "published_date": "2024-10-07 10:52:53 UTC",
      "updated_date": "2024-10-07 10:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:13:49.207767"
    },
    {
      "arxiv_id": "2410.05347v1",
      "title": "ResTNet: Defense against Adversarial Policies via Transformer in Computer Go",
      "title_zh": "翻译失败",
      "authors": [
        "Tai-Lin Wu",
        "Ti-Rong Wu",
        "Chung-Chin Shih",
        "Yan-Ru Ju",
        "I-Chen Wu"
      ],
      "abstract": "Although AlphaZero has achieved superhuman levels in Go, recent research has\nhighlighted its vulnerability in particular situations requiring a more\ncomprehensive understanding of the entire board. To address this challenge,\nthis paper introduces ResTNet, a network that interleaves residual networks and\nTransformer. Our empirical experiments demonstrate several advantages of using\nResTNet. First, it not only improves playing strength but also enhances the\nability of global information. Second, it defends against an adversary Go\nprogram, called cyclic-adversary, tailor-made for attacking AlphaZero\nalgorithms, significantly reducing the average probability of being attacked\nrate from 70.44% to 23.91%. Third, it improves the accuracy from 59.15% to\n80.01% in correctly recognizing ladder patterns, which are one of the\nchallenging patterns for Go AIs. Finally, ResTNet offers a potential\nexplanation of the decision-making process and can also be applied to other\ngames like Hex. To the best of our knowledge, ResTNet is the first to integrate\nresidual networks and Transformer in the context of AlphaZero for board games,\nsuggesting a promising direction for enhancing AlphaZero's global\nunderstanding.",
      "tldr_zh": "本研究提出 ResTNet，一种将 residual networks 和 Transformer 相结合的网络，旨在提升围棋（Go）AI 如 AlphaZero 的全局信息理解和对抗策略防御。ResTNet 通过交错架构，不仅提高了游戏实力，还显著降低了针对 cyclic-adversary 攻击的概率，从 70.44% 降至 23.91%，并将 ladder patterns 的识别准确率从 59.15% 提升至 80.01%。此外，该模型提供决策过程的潜在解释，并可扩展到其他棋类游戏如 Hex，标志着 AlphaZero 框架中首次整合这些技术的创新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05347v1",
      "published_date": "2024-10-07 10:17:24 UTC",
      "updated_date": "2024-10-07 10:17:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:13:51.348010"
    },
    {
      "arxiv_id": "2410.04884v1",
      "title": "Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dehong Kong",
        "Siyuan Liang",
        "Xiaopeng Zhu",
        "Yuansheng Zhong",
        "Wenqi Ren"
      ],
      "abstract": "Visual language pre-training (VLP) models have demonstrated significant\nsuccess across various domains, yet they remain vulnerable to adversarial\nattacks. Addressing these adversarial vulnerabilities is crucial for enhancing\nsecurity in multimodal learning. Traditionally, adversarial methods targeting\nVLP models involve simultaneously perturbing images and text. However, this\napproach faces notable challenges: first, adversarial perturbations often fail\nto translate effectively into real-world scenarios; second, direct\nmodifications to the text are conspicuously visible. To overcome these\nlimitations, we propose a novel strategy that exclusively employs image patches\nfor attacks, thus preserving the integrity of the original text. Our method\nleverages prior knowledge from diffusion models to enhance the authenticity and\nnaturalness of the perturbations. Moreover, to optimize patch placement and\nimprove the efficacy of our attacks, we utilize the cross-attention mechanism,\nwhich encapsulates intermodal interactions by generating attention maps to\nguide strategic patch placements. Comprehensive experiments conducted in a\nwhite-box setting for image-to-text scenarios reveal that our proposed method\nsignificantly outperforms existing techniques, achieving a 100% attack success\nrate. Additionally, it demonstrates commendable performance in transfer tasks\ninvolving text-to-image configurations.",
      "tldr_zh": "本文提出一种针对视觉语言预训练（VLP）模型的自然对抗攻击方法，仅使用图像补丁（patches）进行扰动，以避免传统方法中同时修改图像和文本带来的现实应用挑战。该方法利用扩散模型（diffusion models）的先验知识增强扰动的真实性和自然性，并通过跨注意力机制（cross-attention mechanism）生成注意力图来优化补丁放置位置，从而提升攻击效率。在白盒实验中，该方法在图像到文本场景下实现了100%的攻击成功率，并在文本到图像转移任务中表现出色，显著优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by Visual Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2410.04884v1",
      "published_date": "2024-10-07 10:06:01 UTC",
      "updated_date": "2024-10-07 10:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:14:13.247918"
    },
    {
      "arxiv_id": "2410.04878v1",
      "title": "Leveraging Grammar Induction for Language Understanding and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jushi Kai",
        "Shengyuan Hou",
        "Yusheng Huang",
        "Zhouhan Lin"
      ],
      "abstract": "Grammar induction has made significant progress in recent years. However, it\nis not clear how the application of induced grammar could enhance practical\nperformance in downstream tasks. In this work, we introduce an unsupervised\ngrammar induction method for language understanding and generation. We\nconstruct a grammar parser to induce constituency structures and dependency\nrelations, which is simultaneously trained on downstream tasks without\nadditional syntax annotations. The induced grammar features are subsequently\nincorporated into Transformer as a syntactic mask to guide self-attention. We\nevaluate and apply our method to multiple machine translation tasks and natural\nlanguage understanding tasks. Our method demonstrates superior performance\ncompared to the original Transformer and other models enhanced with external\nparsers. Experimental results indicate that our method is effective in both\nfrom-scratch and pre-trained scenarios. Additionally, our research highlights\nthe contribution of explicitly modeling the grammatical structure of texts to\nneural network models.",
      "tldr_zh": "本研究探讨了利用语法归纳（grammar induction）提升语言理解和生成性能，提出了一种无监督方法，通过构建语法解析器归纳成分结构（constituency structures）和依赖关系（dependency relations），并在下游任务中同时训练而无需额外语法注解。 该方法将归纳的语法特征整合到 Transformer 中，作为 syntactic mask 来指导 self-attention，从而优化模型表现。 在多个机器翻译和自然语言理解任务上，实验结果显示，该方法在从零开始和预训练场景中均优于原始 Transformer 和其他外部解析器增强模型，并证明了显式建模文本语法结构对神经网络模型的显著贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.04878v1",
      "published_date": "2024-10-07 09:57:59 UTC",
      "updated_date": "2024-10-07 09:57:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:14:17.804790"
    },
    {
      "arxiv_id": "2410.05346v3",
      "title": "AnyAttack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Zhang",
        "Junhong Ye",
        "Xingjun Ma",
        "Yige Li",
        "Yunfan Yang",
        "Yunhao Chen",
        "Jitao Sang",
        "Dit-Yan Yeung"
      ],
      "abstract": "Due to their multimodal capabilities, Vision-Language Models (VLMs) have\nfound numerous impactful applications in real-world scenarios. However, recent\nstudies have revealed that VLMs are vulnerable to image-based adversarial\nattacks. Traditional targeted adversarial attacks require specific targets and\nlabels, limiting their real-world impact.We present AnyAttack, a\nself-supervised framework that transcends the limitations of conventional\nattacks through a novel foundation model approach. By pre-training on the\nmassive LAION-400M dataset without label supervision, AnyAttack achieves\nunprecedented flexibility - enabling any image to be transformed into an attack\nvector targeting any desired output across different VLMs.This approach\nfundamentally changes the threat landscape, making adversarial capabilities\naccessible at an unprecedented scale. Our extensive validation across five\nopen-source VLMs (CLIP, BLIP, BLIP2, InstructBLIP, and MiniGPT-4) demonstrates\nAnyAttack's effectiveness across diverse multimodal tasks. Most concerning,\nAnyAttack seamlessly transfers to commercial systems including Google Gemini,\nClaude Sonnet, Microsoft Copilot and OpenAI GPT, revealing a systemic\nvulnerability requiring immediate attention.",
      "tldr_zh": "该研究提出 AnyAttack，一种大规模自监督对抗攻击框架，针对 Vision-Language Models (VLMs) 的图像-based 攻击问题，超越传统攻击对特定目标和标签的依赖。通过在 LAION-400M 数据集上无监督预训练，AnyAttack 允许任何图像转换为攻击向量，实现对不同 VLMs 的灵活输出操控。实验验证显示，该框架在开源模型（如 CLIP、BLIP、BLIP2、InstructBLIP 和 MiniGPT-4）上表现出色，并成功转移到商业系统（如 Google Gemini、Claude Sonnet、Microsoft Copilot 和 OpenAI GPT），揭示了 VLMs 的系统性漏洞，需要紧急关注。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.05346v3",
      "published_date": "2024-10-07 09:45:18 UTC",
      "updated_date": "2025-03-28 02:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:14:29.917297"
    },
    {
      "arxiv_id": "2410.17265v1",
      "title": "Federated brain tumor segmentation: an extensive benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Matthis Manthe",
        "Stefan Duffner",
        "Carole Lartizien"
      ],
      "abstract": "Recently, federated learning has raised increasing interest in the medical\nimage analysis field due to its ability to aggregate multi-center data with\nprivacy-preserving properties. A large amount of federated training schemes\nhave been published, which we categorize into global (one final model),\npersonalized (one model per institution) or hybrid (one model per cluster of\ninstitutions) methods. However, their applicability on the recently published\nFederated Brain Tumor Segmentation 2022 dataset has not been explored yet. We\npropose an extensive benchmark of federated learning algorithms from all three\nclasses on this task. While standard FedAvg already performs very well, we show\nthat some methods from each category can bring a slight performance improvement\nand potentially limit the final model(s) bias toward the predominant data\ndistribution of the federation. Moreover, we provide a deeper understanding of\nthe behaviour of federated learning on this task through alternative ways of\ndistributing the pooled dataset among institutions, namely an Independent and\nIdentical Distributed (IID) setup, and a limited data setup.",
      "tldr_zh": "本研究对联邦学习(federated learning)算法在脑肿瘤分割任务上的性能进行了广泛基准测试，使用了Federated Brain Tumor Segmentation 2022数据集。\n他们将算法分类为global（全局模型）、personalized（个性化模型）和hybrid（混合模型）类型，并评估了FedAvg等方法的表现。\n结果表明，FedAvg已表现出色，而某些算法能带来轻微性能提升，并减少模型对主要数据分布的偏差。\n此外，通过Independent and Identical Distributed (IID)设置和limited data设置，论文深入探讨了数据分布方式对联邦学习的影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17265v1",
      "published_date": "2024-10-07 09:32:19 UTC",
      "updated_date": "2024-10-07 09:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:14:40.053059"
    },
    {
      "arxiv_id": "2410.04865v1",
      "title": "Mastering Chinese Chess AI (Xiangqi) Without Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Chen",
        "Juntong Lin",
        "Zhichao Shu"
      ],
      "abstract": "We have developed a high-performance Chinese Chess AI that operates without\nreliance on search algorithms. This AI has demonstrated the capability to\ncompete at a level commensurate with the top 0.1\\% of human players. By\neliminating the search process typically associated with such systems, this AI\nachieves a Queries Per Second (QPS) rate that exceeds those of systems based on\nthe Monte Carlo Tree Search (MCTS) algorithm by over a thousandfold and\nsurpasses those based on the AlphaBeta pruning algorithm by more than a\nhundredfold. The AI training system consists of two parts: supervised learning\nand reinforcement learning. Supervised learning provides an initial human-like\nChinese chess AI, while reinforcement learning, based on supervised learning,\nelevates the strength of the entire AI to a new level. Based on this training\nsystem, we carried out enough ablation experiments and discovered that 1. The\nsame parameter amount of Transformer architecture has a higher performance than\nCNN on Chinese chess; 2. Possible moves of both sides as features can greatly\nimprove the training process; 3. Selective opponent pool, compared to pure\nself-play training, results in a faster improvement curve and a higher strength\nlimit. 4. Value Estimation with Cutoff(VECT) improves the original PPO\nalgorithm training process and we will give the explanation.",
      "tldr_zh": "本研究开发了一种不依赖搜索算法的高性能中国象棋 AI（Xiangqi），其水平可与人类顶级 0.1% 玩家匹敌，并通过 Queries Per Second (QPS) 指标，比 Monte Carlo Tree Search (MCTS) 提升超千倍、比 AlphaBeta 算法提升超百倍。AI 的训练系统结合监督学习（提供初始人类-like 模型）和强化学习（基于监督学习进一步提升性能），并通过消融实验验证了关键改进：Transformer 架构在相同参数量下优于 CNN、使用双方可能的走子作为特征显著加速训练，以及选择性对手池比纯自玩训练更快提升强度。最终，该框架引入 Value Estimation with Cutoff (VECT) 来优化原始 PPO 算法的训练过程，提供详细解释，为高效的棋类 AI 发展提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04865v1",
      "published_date": "2024-10-07 09:27:51 UTC",
      "updated_date": "2024-10-07 09:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:14:53.010820"
    },
    {
      "arxiv_id": "2410.04855v1",
      "title": "Unsupervised Skill Discovery for Robotic Manipulation through Automatic Task Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Jansonnie",
        "Bingbing Wu",
        "Julien Perez",
        "Jan Peters"
      ],
      "abstract": "Learning skills that interact with objects is of major importance for robotic\nmanipulation. These skills can indeed serve as an efficient prior for solving\nvarious manipulation tasks. We propose a novel Skill Learning approach that\ndiscovers composable behaviors by solving a large and diverse number of\nautonomously generated tasks. Our method learns skills allowing the robot to\nconsistently and robustly interact with objects in its environment. The\ndiscovered behaviors are embedded in primitives which can be composed with\nHierarchical Reinforcement Learning to solve unseen manipulation tasks. In\nparticular, we leverage Asymmetric Self-Play to discover behaviors and\nMultiplicative Compositional Policies to embed them. We compare our method to\nSkill Learning baselines and find that our skills are more interactive.\nFurthermore, the learned skills can be used to solve a set of unseen\nmanipulation tasks, in simulation as well as on a real robotic platform.",
      "tldr_zh": "本文提出了一种无监督技能学习方法，通过自动生成大量任务来发现可组合的机器人操作行为，从而提升机器人在环境物体交互的稳健性。该方法利用 Asymmetric Self-Play 发现行为，并通过 Multiplicative Compositional Policies 将这些行为嵌入基元中，然后结合 Hierarchical Reinforcement Learning 组合解决未见过的操作任务。与基线方法相比，该技能更具交互性，并在模拟和真实机器人平台上成功应用于多种新任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the 2024 IEEE-RAS International Conference on Humanoid\n  Robots",
      "pdf_url": "http://arxiv.org/pdf/2410.04855v1",
      "published_date": "2024-10-07 09:19:13 UTC",
      "updated_date": "2024-10-07 09:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:15:04.656606"
    },
    {
      "arxiv_id": "2410.04853v1",
      "title": "TimeCNN: Refining Cross-Variable Interaction on Time Point for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Hu",
        "Dongkai Wang",
        "Yong Dai",
        "Shiyi Qi",
        "Liangjian Wen",
        "Jun Wang",
        "Zhi Chen",
        "Xun Zhou",
        "Zenglin Xu",
        "Jiang Duan"
      ],
      "abstract": "Time series forecasting is extensively applied across diverse domains.\nTransformer-based models demonstrate significant potential in modeling\ncross-time and cross-variable interaction. However, we notice that the\ncross-variable correlation of multivariate time series demonstrates\nmultifaceted (positive and negative correlations) and dynamic progression over\ntime, which is not well captured by existing Transformer-based models. To\naddress this issue, we propose a TimeCNN model to refine cross-variable\ninteractions to enhance time series forecasting. Its key innovation is\ntimepoint-independent, where each time point has an independent convolution\nkernel, allowing each time point to have its independent model to capture\nrelationships among variables. This approach effectively handles both positive\nand negative correlations and adapts to the evolving nature of variable\nrelationships over time. Extensive experiments conducted on 12 real-world\ndatasets demonstrate that TimeCNN consistently outperforms state-of-the-art\nmodels. Notably, our model achieves significant reductions in computational\nrequirements (approximately 60.46%) and parameter count (about 57.50%), while\ndelivering inference speeds 3 to 4 times faster than the benchmark iTransformer\nmodel",
      "tldr_zh": "该研究针对时间序列预测中多变量的动态多方面相关性（正负相关）问题，提出TimeCNN模型，以优化跨变量交互。TimeCNN的关键创新是timepoint-independent设计，每个时间点配备独立的卷积kernel，从而独立捕捉变量关系，并适应其随时间演变。实验在12个真实数据集上显示，TimeCNN优于现有Transformer-based模型，同时减少计算需求约60.46%、参数量约57.50%，推理速度比iTransformer快3-4倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04853v1",
      "published_date": "2024-10-07 09:16:58 UTC",
      "updated_date": "2024-10-07 09:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:15:16.668076"
    },
    {
      "arxiv_id": "2410.04844v4",
      "title": "PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Tian",
        "Yixuan Li",
        "Yichao Yan",
        "Shanyan Guan",
        "Yanhao Ge",
        "Xiaokang Yang"
      ],
      "abstract": "In the field of image editing, three core challenges persist:\ncontrollability, background preservation, and efficiency. Inversion-based\nmethods rely on time-consuming optimization to preserve the features of the\ninitial images, which results in low efficiency due to the requirement for\nextensive network inference. Conversely, inversion-free methods lack\ntheoretical support for background similarity, as they circumvent the issue of\nmaintaining initial features to achieve efficiency. As a consequence, none of\nthese methods can achieve both high efficiency and background consistency. To\ntackle the challenges and the aforementioned disadvantages, we introduce\nPostEdit, a method that incorporates a posterior scheme to govern the diffusion\nsampling process. Specifically, a corresponding measurement term related to\nboth the initial features and Langevin dynamics is introduced to optimize the\nestimated image generated by the given target prompt. Extensive experimental\nresults indicate that the proposed PostEdit achieves state-of-the-art editing\nperformance while accurately preserving unedited regions. Furthermore, the\nmethod is both inversion- and training-free, necessitating approximately 1.5\nseconds and 18 GB of GPU memory to generate high-quality results.",
      "tldr_zh": "本文针对图像编辑中的核心挑战——controllability、background preservation和efficiency，提出PostEdit方法，该方法通过引入posterior scheme和与初始特征相关的测量术语来优化diffusion sampling过程，并结合Langevin dynamics实现高效的zero-shot图像编辑。PostEdit无需inversion和训练，直接在目标提示下生成高质量结果，同时精确保留未编辑区域。实验表明，该方法在编辑性能上达到state-of-the-art水平，仅需约1.5秒和18 GB GPU内存，便于实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.04844v4",
      "published_date": "2024-10-07 09:04:50 UTC",
      "updated_date": "2025-03-06 03:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:15:28.715855"
    },
    {
      "arxiv_id": "2410.11861v1",
      "title": "Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation",
      "title_zh": "探究 Big Five 个性特质在视听融洽关系估计中的作用",
      "authors": [
        "Takato Hayashi",
        "Ryusei Kimura",
        "Ryo Ishii",
        "Shogo Okada"
      ],
      "abstract": "Automatic rapport estimation in social interactions is a central component of\naffective computing. Recent reports have shown that the estimation performance\nof rapport in initial interactions can be improved by using the participant's\npersonality traits as the model's input. In this study, we investigate whether\nthis findings applies to interactions between friends by developing rapport\nestimation models that utilize nonverbal cues (audio and facial expressions) as\ninputs. Our experimental results show that adding Big Five features (BFFs) to\nnonverbal features can improve the estimation performance of self-reported\nrapport in dyadic interactions between friends. Next, we demystify how BFFs\nimprove the estimation performance of rapport through a comparative analysis\nbetween models with and without BFFs. We decompose rapport ratings into\nperceiver effects (people's tendency to rate other people), target effects\n(people's tendency to be rated by other people), and relationship effects\n(people's unique ratings for a specific person) using the social relations\nmodel. We then analyze the extent to which BFFs contribute to capturing each\neffect. Our analysis demonstrates that the perceiver's and the target's BFFs\nlead estimation models to capture the perceiver and the target effects,\nrespectively. Furthermore, our experimental results indicate that the\ncombinations of facial expression features and BFFs achieve best estimation\nperformances not only in estimating rapport ratings, but also in estimating\nthree effects. Our study is the first step toward understanding why\npersonality-aware estimation models of interpersonal perception accomplish high\nestimation performance.",
      "tldr_zh": "本研究调查了Big Five Personality Traits在音频-视觉rapport估计中的作用，焦点是朋友间的社交互动。研究开发了利用非语言线索（如音频和面部表情）及Big Five features (BFFs) 的估计模型，结果显示添加BFFs可显著提升对自报rapport的性能。使用social relations model分解rapport评级为perceiver effects、target effects和relationship effects的分析表明，perceiver的BFFs有助于捕捉perceiver effects，而target的BFFs有助于捕捉target effects，且面部表情特征与BFFs的组合在估计rapport及其效果方面表现出最佳性能。该研究首次阐明了为什么个性感知模型在人际感知估计中取得高性能，为情感计算领域提供了新见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11861v1",
      "published_date": "2024-10-07 08:52:33 UTC",
      "updated_date": "2024-10-07 08:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:15:41.272497"
    },
    {
      "arxiv_id": "2410.04833v1",
      "title": "Multimodal Fusion Strategies for Mapping Biophysical Landscape Features",
      "title_zh": "翻译失败",
      "authors": [
        "Lucia Gordon",
        "Nico Lang",
        "Catherine Ressijac",
        "Andrew Davies"
      ],
      "abstract": "Multimodal aerial data are used to monitor natural systems, and machine\nlearning can significantly accelerate the classification of landscape features\nwithin such imagery to benefit ecology and conservation. It remains\nunder-explored, however, how these multiple modalities ought to be fused in a\ndeep learning model. As a step towards filling this gap, we study three\nstrategies (Early fusion, Late fusion, and Mixture of Experts) for fusing\nthermal, RGB, and LiDAR imagery using a dataset of spatially-aligned\northomosaics in these three modalities. In particular, we aim to map three\necologically-relevant biophysical landscape features in African savanna\necosystems: rhino middens, termite mounds, and water. The three fusion\nstrategies differ in whether the modalities are fused early or late, and if\nlate, whether the model learns fixed weights per modality for each class or\ngenerates weights for each class adaptively, based on the input. Overall, the\nthree methods have similar macro-averaged performance with Late fusion\nachieving an AUC of 0.698, but their per-class performance varies strongly,\nwith Early fusion achieving the best recall for middens and water and Mixture\nof Experts achieving the best recall for mounds.",
      "tldr_zh": "本研究探讨了多模态航空数据（如热成像、RGB 和 LiDAR 图像）的融合策略，用于机器学习分类非洲热带草原生态系统的生物物理景观特征，包括 rhino middens、termite mounds 和 water，以支持生态和保护工作。研究比较了三种融合方法：Early fusion（早期融合模态）、Late fusion（晚期融合，可能学习固定或自适应权重）和 Mixture of Experts（基于输入生成权重）。结果显示，三种策略的整体表现相似，Late fusion 取得了 0.698 的 AUC 值，但在类别表现上有所差异，Early fusion 在 rhino middens 和 water 的召回率最佳，而 Mixture of Experts 在 termite mounds 上表现最优。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures, ECCV 2024 Workshop in CV for Ecology",
      "pdf_url": "http://arxiv.org/pdf/2410.04833v1",
      "published_date": "2024-10-07 08:40:29 UTC",
      "updated_date": "2024-10-07 08:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:15:53.014974"
    },
    {
      "arxiv_id": "2410.17262v2",
      "title": "EmoGene: Audio-Driven Emotional 3D Talking-Head Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Wang",
        "Yun Fu"
      ],
      "abstract": "Audio-driven talking-head generation is a crucial and useful technology for\nvirtual human interaction and film-making. While recent advances have focused\non improving image fidelity and lip synchronization, generating accurate\nemotional expressions remains underexplored. In this paper, we introduce\nEmoGene, a novel framework for synthesizing high-fidelity, audio-driven video\nportraits with accurate emotional expressions. Our approach employs a\nvariational autoencoder (VAE)-based audio-to-motion module to generate facial\nlandmarks, which are concatenated with emotional embedding in a\nmotion-to-emotion module to produce emotional landmarks. These landmarks drive\na Neural Radiance Fields (NeRF)-based emotion-to-video module to render\nrealistic emotional talking-head videos. Additionally, we propose a pose\nsampling method to generate natural idle-state (non-speaking) videos for silent\naudio inputs. Extensive experiments demonstrate that EmoGene outperforms\nprevious methods in generating high-fidelity emotional talking-head videos.",
      "tldr_zh": "本文提出EmoGene框架，用于音频驱动的3D talking-head生成，专注于合成高保真视频肖像并准确捕捉情感表达，以解决现有方法忽略情感的局限性。该框架采用VAE-based audio-to-motion模块生成面部landmarks，并结合emotional embedding在motion-to-emotion模块中产生emotional landmarks，随后通过NeRF-based emotion-to-video模块渲染真实的视频。此外，引入pose sampling方法生成自然的idle-state视频，以处理无声音频输入。实验结果显示，EmoGene在情感talking-head视频生成方面优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 2025 IEEE 19th International Conference on Automatic\n  Face and Gesture Recognition (FG)",
      "pdf_url": "http://arxiv.org/pdf/2410.17262v2",
      "published_date": "2024-10-07 08:23:05 UTC",
      "updated_date": "2025-05-01 21:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:16:04.853270"
    },
    {
      "arxiv_id": "2410.05345v1",
      "title": "Trained Models Tell Us How to Make Them Robust to Spurious Correlation without Group Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Ghaznavi",
        "Hesam Asadollahzadeh",
        "Fahimeh Hosseini Noohdani",
        "Soroush Vafaie Tabar",
        "Hosein Hasani",
        "Taha Akbari Alvanagh",
        "Mohammad Hossein Rohban",
        "Mahdieh Soleymani Baghshah"
      ],
      "abstract": "Classifiers trained with Empirical Risk Minimization (ERM) tend to rely on\nattributes that have high spurious correlation with the target. This can\ndegrade the performance on underrepresented (or 'minority') groups that lack\nthese attributes, posing significant challenges for both out-of-distribution\ngeneralization and fairness objectives. Many studies aim to enhance robustness\nto spurious correlation, but they sometimes depend on group annotations for\ntraining. Additionally, a common limitation in previous research is the\nreliance on group-annotated validation datasets for model selection. This\nconstrains their applicability in situations where the nature of the spurious\ncorrelation is not known, or when group labels for certain spurious attributes\nare not available. To enhance model robustness with minimal group annotation\nassumptions, we propose Environment-based Validation and Loss-based Sampling\n(EVaLS). It uses the losses from an ERM-trained model to construct a balanced\ndataset of high-loss and low-loss samples, mitigating group imbalance in data.\nThis significantly enhances robustness to group shifts when equipped with a\nsimple post-training last layer retraining. By using environment inference\nmethods to create diverse environments with correlation shifts, EVaLS can\npotentially eliminate the need for group annotation in validation data. In this\ncontext, the worst environment accuracy acts as a reliable surrogate throughout\nthe retraining process for tuning hyperparameters and finding a model that\nperforms well across diverse group shifts. EVaLS effectively achieves group\nrobustness, showing that group annotation is not necessary even for validation.\nIt is a fast, straightforward, and effective approach that reaches near-optimal\nworst group accuracy without needing group annotations, marking a new chapter\nin the robustness of trained models against spurious correlation.",
      "tldr_zh": "该研究解决了基于Empirical Risk Minimization (ERM)训练的分类器对虚假相关(spurious correlation)过度依赖的问题，导致在少数群体上表现不佳，且现有方法需依赖组注解。该论文提出EVaLS（Environment-based Validation and Loss-based Sampling）框架，通过利用ERM模型的损失值构建平衡数据集（包括高损失和低损失样本），缓解组不平衡，并结合简单的后训练最后一层重新训练，提升模型对组移位的鲁棒性。EVaLS还使用环境推断方法创建多样环境，消除验证数据中对组注解的需求，以最坏环境准确率作为调优指标，最终实现近似最优的组鲁棒性，证明无需组注解即可有效应对虚假相关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.05345v1",
      "published_date": "2024-10-07 08:17:44 UTC",
      "updated_date": "2024-10-07 08:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:16:17.110892"
    },
    {
      "arxiv_id": "2410.04817v1",
      "title": "Resource-Efficient Multiview Perception: Integrating Semantic Masking with Masked Autoencoders",
      "title_zh": "资源高效的多视图感知：将语义掩码与掩码自动编码器整合",
      "authors": [
        "Kosta Dakic",
        "Kanchana Thilakarathna",
        "Rodrigo N. Calheiros",
        "Teng Joon Lim"
      ],
      "abstract": "Multiview systems have become a key technology in modern computer vision,\noffering advanced capabilities in scene understanding and analysis. However,\nthese systems face critical challenges in bandwidth limitations and\ncomputational constraints, particularly for resource-limited camera nodes like\ndrones. This paper presents a novel approach for communication-efficient\ndistributed multiview detection and tracking using masked autoencoders (MAEs).\nWe introduce a semantic-guided masking strategy that leverages pre-trained\nsegmentation models and a tunable power function to prioritize informative\nimage regions. This approach, combined with an MAE, reduces communication\noverhead while preserving essential visual information. We evaluate our method\non both virtual and real-world multiview datasets, demonstrating comparable\nperformance in terms of detection and tracking performance metrics compared to\nstate-of-the-art techniques, even at high masking ratios. Our selective masking\nalgorithm outperforms random masking, maintaining higher accuracy and precision\nas the masking ratio increases. Furthermore, our approach achieves a\nsignificant reduction in transmission data volume compared to baseline methods,\nthereby balancing multiview tracking performance with communication efficiency.",
      "tldr_zh": "该论文提出了一种资源高效的多视图感知方法，通过整合 semantic-guided masking 策略与 Masked Autoencoders (MAEs)，解决多视图系统在带宽和计算资源限制下的挑战。该方法利用预训练的分割模型和可调节的 power function 来优先选择信息丰富的图像区域，从而减少通信开销同时保留关键视觉信息。在虚拟和真实世界数据集上的实验显示，该方法在高 masking ratios 下，检测和跟踪性能与最先进技术相当，且 selective masking 算法优于 random masking，能维持更高准确性和精确度。总体上，该方法显著降低了传输数据量，实现多视图跟踪性能与通信效率的平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2410.04817v1",
      "published_date": "2024-10-07 08:06:41 UTC",
      "updated_date": "2024-10-07 08:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:16:28.684101"
    },
    {
      "arxiv_id": "2410.04815v2",
      "title": "A Review of BioTree Construction in the Context of Information Fusion: Priors, Methods, Applications and Trends",
      "title_zh": "翻译失败",
      "authors": [
        "Zelin Zang",
        "Yongjie Xu",
        "Chenrui Duan",
        "Yue Yuan",
        "Jinlin Wu",
        "Zhen Lei",
        "Stan Z. Li"
      ],
      "abstract": "Biological tree (BioTree) analysis is a foundational tool in biology,\nenabling the exploration of evolutionary and differentiation relationships\namong organisms, genes, and cells. Traditional tree construction methods, while\ninstrumental in early research, face significant challenges in handling the\ngrowing complexity and scale of modern biological data, particularly in\nintegrating multimodal datasets. Advances in deep learning (DL) offer\ntransformative opportunities by enabling the fusion of biological prior\nknowledge with data-driven models. These approaches address key limitations of\ntraditional methods, facilitating the construction of more accurate and\ninterpretable BioTrees. This review highlights critical biological priors\nessential for phylogenetic and differentiation tree analyses and explores\nstrategies for integrating these priors into DL models to enhance accuracy and\ninterpretability. Additionally, the review systematically examines commonly\nused data modalities and databases, offering a valuable resource for developing\nand evaluating multimodal fusion models. Traditional tree construction methods\nare critically assessed, focusing on their biological assumptions, technical\nlimitations, and scalability issues. Recent advancements in DL-based tree\ngeneration methods are reviewed, emphasizing their innovative approaches to\nmultimodal integration and prior knowledge incorporation. Finally, the review\ndiscusses diverse applications of BioTrees in various biological disciplines,\nfrom phylogenetics to developmental biology, and outlines future trends in\nleveraging DL to advance BioTree research. By addressing the challenges of data\ncomplexity and prior knowledge integration, this review aims to inspire\ninterdisciplinary innovation at the intersection of biology and DL.",
      "tldr_zh": "这篇综述论文探讨了生物树（BioTree）构建在信息融合背景下的发展，包括先验知识、方法、应用和趋势。论文强调传统树构建方法在处理复杂多模态生物数据时面临的挑战，如可扩展性和准确性问题，并提出深度学习（DL）作为解决方案，通过融合生物先验知识和数据驱动模型来提升BioTree的准确性和可解释性。综述系统评估了常用数据模态、数据库以及DL-based方法的创新，同时讨论了BioTree在系统发育学和发育生物学等领域的应用，并展望未来趋势，以推动生物学与DL的交叉创新。",
      "categories": [
        "q-bio.PE",
        "cs.AI"
      ],
      "primary_category": "q-bio.PE",
      "comment": "115 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04815v2",
      "published_date": "2024-10-07 08:00:41 UTC",
      "updated_date": "2025-02-15 07:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:16:40.267610"
    },
    {
      "arxiv_id": "2410.04814v2",
      "title": "Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data",
      "title_zh": "从时间序列数据中学习可解释的层次动态系统模型",
      "authors": [
        "Manuel Brenner",
        "Elias Weber",
        "Georgia Koppe",
        "Daniel Durstewitz"
      ],
      "abstract": "In science, we are often interested in obtaining a generative model of the\nunderlying system dynamics from observed time series. While powerful methods\nfor dynamical systems reconstruction (DSR) exist when data come from a single\ndomain, how to best integrate data from multiple dynamical regimes and leverage\nit for generalization is still an open question. This becomes particularly\nimportant when individual time series are short, and group-level information\nmay help to fill in for gaps in single-domain data. Here we introduce a\nhierarchical framework that enables to harvest group-level (multi-domain)\ninformation while retaining all single-domain characteristics, and showcase it\non popular DSR benchmarks, as well as on neuroscience and medical data. In\naddition to faithful reconstruction of all individual dynamical regimes, our\nunsupervised methodology discovers common low-dimensional feature spaces in\nwhich datasets with similar dynamics cluster. The features spanning these\nspaces were further dynamically highly interpretable, surprisingly in often\nlinear relation to control parameters that govern the dynamics of the\nunderlying system. Finally, we illustrate transfer learning and generalization\nto new parameter regimes, paving the way toward DSR foundation models.",
      "tldr_zh": "本研究提出了一种层次化框架（hierarchical framework），用于从时间序列数据中学习可解释的动态系统模型（dynamical systems models），尤其针对整合多领域数据以提升泛化能力的问题。该框架能够利用群组级（group-level）信息来弥补单一领域数据（如短时间序列）的不足，同时保留每个领域的独特特性。在无监督设置下，该方法不仅实现了对各种动态模式的忠实重建，还发现了共同的低维特征空间，其中类似动态的数据集聚类，且这些特征与控制参数往往呈线性关系。实验在动态系统重建（DSR）基准、神经科学和医疗数据上验证了其有效性，并展示了迁移学习（transfer learning）和对新参数环境的泛化潜力，为DSR基础模型的开发奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "nlin.CD",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.04814v2",
      "published_date": "2024-10-07 07:54:53 UTC",
      "updated_date": "2025-02-17 08:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:16:52.755118"
    },
    {
      "arxiv_id": "2410.04799v1",
      "title": "Transforming Color: A Novel Image Colorization Method",
      "title_zh": "色彩转换：一种新型图像着色方法",
      "authors": [
        "Hamza Shafiq",
        "Bumshik Lee"
      ],
      "abstract": "This paper introduces a novel method for image colorization that utilizes a\ncolor transformer and generative adversarial networks (GANs) to address the\nchallenge of generating visually appealing colorized images. Conventional\napproaches often struggle with capturing long-range dependencies and producing\nrealistic colorizations. The proposed method integrates a transformer\narchitecture to capture global information and a GAN framework to improve\nvisual quality. In this study, a color encoder that utilizes a random normal\ndistribution to generate color features is applied. These features are then\nintegrated with grayscale image features to enhance the overall representation\nof the images. Our method demonstrates superior performance compared with\nexisting approaches by utilizing the capacity of the transformer, which can\ncapture long-range dependencies and generate a realistic colorization of the\nGAN. Experimental results show that the proposed network significantly\noutperforms other state-of-the-art colorization techniques, highlighting its\npotential for image colorization. This research opens new possibilities for\nprecise and visually compelling image colorization in domains such as digital\nrestoration and historical image analysis.",
      "tldr_zh": "这篇论文提出了一种新型图像着色方法，结合 transformer 架构和 GANs（生成对抗网络），以捕捉长距离依赖并生成更逼真的颜色图像。方法包括使用颜色编码器从随机正态分布生成颜色特征，并将其与灰度图像特征整合，提升整体图像表示。实验结果显示，该方法显著优于现有技术，在图像着色性能上提升明显，并为数字修复和历史图像分析等领域提供新应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04799v1",
      "published_date": "2024-10-07 07:23:42 UTC",
      "updated_date": "2024-10-07 07:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:17:04.782990"
    },
    {
      "arxiv_id": "2410.05343v2",
      "title": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos Referring to Procedural Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Yuto Haneji",
        "Taichi Nishimura",
        "Hirotaka Kameko",
        "Keisuke Shirai",
        "Tomoya Yoshida",
        "Keiya Kajimura",
        "Koki Yamamoto",
        "Taiyu Cui",
        "Tomohiro Nishimoto",
        "Shinsuke Mori"
      ],
      "abstract": "Mistake action detection is crucial for developing intelligent archives that\ndetect workers' errors and provide feedback. Existing studies have focused on\nvisually apparent mistakes in free-style activities, resulting in video-only\napproaches to mistake detection. However, in text-following activities, models\ncannot determine the correctness of some actions without referring to the\ntexts. Additionally, current mistake datasets rarely use procedural texts for\nvideo recording except for cooking. To fill these gaps, this paper proposes the\nEgoOops dataset, where egocentric videos record erroneous activities when\nfollowing procedural texts across diverse domains. It features three types of\nannotations: video-text alignment, mistake labels, and descriptions for\nmistakes. We also propose a mistake detection approach, combining video-text\nalignment and mistake label classification to leverage the texts. Our\nexperimental results show that incorporating procedural texts is essential for\nmistake detection. Data is available through\nhttps://y-haneji.github.io/EgoOops-project-page/.",
      "tldr_zh": "该论文提出了EgoOops数据集，用于检测从egocentric videos中遵循procedural texts时的错误动作，填补了现有研究在文本跟随活动中的空白。\n数据集涵盖多种领域，包括视频-文本对齐、mistake labels和错误描述三种注解，记录了遵循程序文本时的错误活动。\n作者提出了一种错误检测方法，结合视频-文本对齐和mistake label分类，以充分利用文本信息。\n实验结果显示，融入procedural texts对错误检测至关重要，数据集已公开可用于https://y-haneji.github.io/EgoOops-project-page/。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Main 6 pages, supplementary 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.05343v2",
      "published_date": "2024-10-07 07:19:50 UTC",
      "updated_date": "2025-02-11 07:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:17:16.949528"
    },
    {
      "arxiv_id": "2410.04795v2",
      "title": "Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dahyun Kim",
        "Sukyung Lee",
        "Yungi Kim",
        "Attapol Rutherford",
        "Chanjun Park"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has highlighted the\nneed for robust evaluation frameworks that assess their core capabilities, such\nas reasoning, knowledge, and commonsense, leading to the inception of certain\nwidely-used benchmark suites such as the H6 benchmark. However, these benchmark\nsuites are primarily built for the English language, and there exists a lack\nthereof for under-represented languages, in terms of LLM development, such as\nThai. On the other hand, developing LLMs for Thai should also include enhancing\nthe cultural understanding as well as core capabilities. To address these dual\nchallenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai\nCultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough\nevaluation of various LLMs with multi-lingual capabilities, we provide a\ncomprehensive analysis of the proposed benchmarks and how they contribute to\nThai LLM development. Furthermore, we will make both the datasets and\nevaluation code publicly available to encourage further research and\ndevelopment for Thai LLMs.",
      "tldr_zh": "这篇论文针对泰语大型语言模型 (LLMs) 的开发，提出了两个新的基准：Thai-H6 和 Thai Cultural and Linguistic Intelligence Benchmark (ThaiCLI)，以评估模型的核心能力（如推理、知识和常识）以及文化理解。现有基准如 H6 benchmark 主要针对英语，忽略了像泰语这样的 underrepresented 语言，该研究填补了这一空白，通过对多语言 LLMs 的全面评估，展示了这些基准如何提升泰语 LLM 的性能。作者将数据集和评估代码公开，以鼓励进一步的研究和开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04795v2",
      "published_date": "2024-10-07 07:14:37 UTC",
      "updated_date": "2024-10-08 04:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:17:29.347780"
    },
    {
      "arxiv_id": "2410.04789v1",
      "title": "Analysis of Hybrid Compositions in Animation Film with Weakly Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mónica Apellaniz Portos",
        "Roberto Labadie-Tamayo",
        "Claudius Stemmler",
        "Erwin Feyersinger",
        "Andreas Babic",
        "Franziska Bruckner",
        "Vrääth Öhner",
        "Matthias Zeppelzauer"
      ],
      "abstract": "We present an approach for the analysis of hybrid visual compositions in\nanimation in the domain of ephemeral film. We combine ideas from\nsemi-supervised and weakly supervised learning to train a model that can\nsegment hybrid compositions without requiring pre-labeled segmentation masks.\nWe evaluate our approach on a set of ephemeral films from 13 film archives.\nResults demonstrate that the proposed learning strategy yields a performance\nclose to a fully supervised baseline. On a qualitative level the performed\nanalysis provides interesting insights on hybrid compositions in animation\nfilm.",
      "tldr_zh": "该论文提出了一种结合半监督和弱ly supervised learning的方法，用于分析动画电影中hybrid visual compositions，而无需预先标记的分割掩码。研究团队在13个电影档案的ephemeral films上评估了该方法，结果显示其性能接近fully supervised baseline。定性分析进一步提供了关于动画电影中混合构图的有趣insights。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Vision for Art (VISART VII) Workshop at the European Conference of\n  Computer Vision (ECCV)",
      "pdf_url": "http://arxiv.org/pdf/2410.04789v1",
      "published_date": "2024-10-07 06:57:23 UTC",
      "updated_date": "2024-10-07 06:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:17:51.548671"
    },
    {
      "arxiv_id": "2410.04779v2",
      "title": "Fast Training of Sinusoidal Neural Fields via Scaling Initialization",
      "title_zh": "通过缩放初始化实现正弦神经场的快速训练",
      "authors": [
        "Taesun Yeom",
        "Sangyoon Lee",
        "Jaeho Lee"
      ],
      "abstract": "Neural fields are an emerging paradigm that represent data as continuous\nfunctions parameterized by neural networks. Despite many advantages, neural\nfields often have a high training cost, which prevents a broader adoption. In\nthis paper, we focus on a popular family of neural fields, called sinusoidal\nneural fields (SNFs), and study how it should be initialized to maximize the\ntraining speed. We find that the standard initialization scheme for SNFs --\ndesigned based on the signal propagation principle -- is suboptimal. In\nparticular, we show that by simply multiplying each weight (except for the last\nlayer) by a constant, we can accelerate SNF training by 10$\\times$. This\nmethod, coined $\\textit{weight scaling}$, consistently provides a significant\nspeedup over various data domains, allowing the SNFs to train faster than more\nrecently proposed architectures. To understand why the weight scaling works\nwell, we conduct extensive theoretical and empirical analyses which reveal that\nthe weight scaling not only resolves the spectral bias quite effectively but\nalso enjoys a well-conditioned optimization trajectory.",
      "tldr_zh": "这篇论文针对正弦神经场(Sinusoidal Neural Fields, SNFs)的高训练成本问题，提出了一种weight scaling初始化方法，即通过对每个权重（除最后一层外）乘以一个常量，来加速训练过程。实验结果显示，该方法可以将SNFs的训练速度提高10倍，并在各种数据领域中比最近提出的架构表现更优。论文通过理论和经验分析证明，weight scaling不仅有效解决了spectral bias，还提供了良好的优化轨迹，从而提升了神经场的整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.04779v2",
      "published_date": "2024-10-07 06:38:43 UTC",
      "updated_date": "2025-02-28 14:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:17:52.549071"
    },
    {
      "arxiv_id": "2410.10858v1",
      "title": "Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths",
      "title_zh": "翻译失败",
      "authors": [
        "Yew Ken Chia",
        "Guizhen Chen",
        "Weiwen Xu",
        "Luu Anh Tuan",
        "Soujanya Poria",
        "Lidong Bing"
      ],
      "abstract": "Advanced models such as OpenAI o1 exhibit impressive problem-solving\ncapabilities through step-by-step reasoning. However, they may still falter on\nmore complex problems, making errors that disrupt their reasoning paths. We\nattribute this to the expansive solution space, where each step has the risk of\ndiverging into mistakes. To enhance language model reasoning, we introduce a\nspecialized training framework called Reasoning Paths Optimization (RPO), which\nenables learning to reason and explore from diverse paths. Our approach\nencourages favorable branches at each reasoning step while penalizing\nunfavorable ones, enhancing the model's overall problem-solving performance.\nReasoning Paths Optimization does not rely on large-scale human-annotated\nrationales or outputs from closed-source models, making it scalable and\ndata-efficient. We focus on multi-step reasoning tasks, such as math word\nproblems and science-based exam questions. The experiments demonstrate that our\nframework significantly enhances the reasoning performance of large language\nmodels, with up to 3.1% and 4.3% improvement on GSM8K and MMLU (STEM)\nrespectively. Our data and code can be found at\nhttps://reasoning-paths.github.io.",
      "tldr_zh": "该研究针对语言模型在复杂问题上可能出错的推理路径问题，引入了Reasoning Paths Optimization (RPO)框架，帮助模型从多样路径中学习推理和探索。RPO通过鼓励有利分支并惩罚不利分支来优化每一步决策，同时不依赖大规模人工标注或闭源模型输出，从而实现可扩展和数据高效的训练。实验结果显示，该框架显著提升了大型语言模型的表现，在GSM8K数据集上改善3.1%，在MMLU (STEM)上改善4.3%。这为多步推理任务如数学文字问题和科学考试题提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2410.10858v1",
      "published_date": "2024-10-07 06:37:25 UTC",
      "updated_date": "2024-10-07 06:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:18:04.405474"
    },
    {
      "arxiv_id": "2410.16301v1",
      "title": "Intelligent Computing Social Modeling and Methodological Innovations in Political Science in the Era of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Wang",
        "Yi Xu",
        "Dequan Wang",
        "Lingfeng Zhou",
        "Yiqi Zhou"
      ],
      "abstract": "The recent wave of artificial intelligence, epitomized by large language\nmodels (LLMs), has presented opportunities and challenges for methodological\ninnovation in political science, sparking discussions on a potential paradigm\nshift in the social sciences. However, how can we understand the impact of LLMs\non knowledge production and paradigm transformation in the social sciences from\na comprehensive perspective that integrates technology and methodology? What\nare LLMs' specific applications and representative innovative methods in\npolitical science research? These questions, particularly from a practical\nmethodological standpoint, remain underexplored. This paper proposes the\n\"Intelligent Computing Social Modeling\" (ICSM) method to address these issues\nby clarifying the critical mechanisms of LLMs. ICSM leverages the strengths of\nLLMs in idea synthesis and action simulation, advancing intellectual\nexploration in political science through \"simulated social construction\" and\n\"simulation validation.\" By simulating the U.S. presidential election, this\nstudy empirically demonstrates the operational pathways and methodological\nadvantages of ICSM. By integrating traditional social science paradigms, ICSM\nnot only enhances the quantitative paradigm's capability to apply big data to\nassess the impact of factors but also provides qualitative paradigms with\nevidence for social mechanism discovery at the individual level, offering a\npowerful tool that balances interpretability and predictability in social\nscience research. The findings suggest that LLMs will drive methodological\ninnovation in political science through integration and improvement rather than\ndirect substitution.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）对政治科学方法论创新的影响，提出“Intelligent Computing Social Modeling”（ICSM）方法，以整合技术和方法论视角分析 LLMs 在知识生产中的作用。ICSM 利用 LLMs 的idea synthesis和action simulation优势，通过“simulated social construction”和“simulation validation”来推进政治科学研究，并以美国总统选举模拟为例，展示了其操作路径和方法优势。研究发现，ICSM 不仅增强了定量范式的能力，使其更好地应用大数据评估因素影响，还为定性范式提供个体层面的社会机制证据，从而平衡了社会科学的解释性和预测性。总体而言，LLMs 通过整合和改进现有范式推动政治科学创新，而非直接取代传统方法。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "34 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16301v1",
      "published_date": "2024-10-07 06:30:59 UTC",
      "updated_date": "2024-10-07 06:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:18:16.242156"
    },
    {
      "arxiv_id": "2410.04765v1",
      "title": "Molecular topological deep learning for polymer property prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Shen",
        "Yipeng Zhang",
        "Fei Han",
        "Kelin Xia"
      ],
      "abstract": "Accurate and efficient prediction of polymer properties is of key importance\nfor polymer design. Traditional experimental tools and density function theory\n(DFT)-based simulations for polymer property evaluation, are both expensive and\ntime-consuming. Recently, a gigantic amount of graph-based molecular models\nhave emerged and demonstrated huge potential in molecular data analysis. Even\nwith the great progresses, these models tend to ignore the high-order and\nmutliscale information within the data. In this paper, we develop molecular\ntopological deep learning (Mol-TDL) for polymer property analysis. Our Mol-TDL\nincorporates both high-order interactions and multiscale properties into\ntopological deep learning architecture. The key idea is to represent polymer\nmolecules as a series of simplicial complices at different scales and build up\nsimplical neural networks accordingly. The aggregated information from\ndifferent scales provides a more accurate prediction of polymer molecular\nproperties.",
      "tldr_zh": "这篇论文针对聚合物属性预测的挑战，指出传统实验工具和密度泛函理论(DFT)模拟既昂贵又耗时，而现有图-based分子模型忽略了高阶交互和多尺度信息。作者开发了Molecular Topological Deep Learning (Mol-TDL)方法，将聚合物分子表示为不同尺度的simplicial complexes，并构建simplicial neural networks来整合这些信息。Mol-TDL通过聚合多尺度数据，实现更准确的聚合物分子属性预测，从而提升了聚合物设计的效率。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04765v1",
      "published_date": "2024-10-07 05:44:02 UTC",
      "updated_date": "2024-10-07 05:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:18:28.923881"
    },
    {
      "arxiv_id": "2410.04759v2",
      "title": "Driving with Regulation: Interpretable Decision-Making for Autonomous Vehicles with Retrieval-Augmented Reasoning via LLM",
      "title_zh": "基于法规的驾驶：通过LLM的检索增强推理实现自动驾驶车辆的可解释决策",
      "authors": [
        "Tianhui Cai",
        "Yifan Liu",
        "Zewei Zhou",
        "Haoxuan Ma",
        "Seth Z. Zhao",
        "Zhiwen Wu",
        "Jiaqi Ma"
      ],
      "abstract": "This work presents an interpretable decision-making framework for autonomous\nvehicles that integrates traffic regulations, norms, and safety guidelines\ncomprehensively and enables seamless adaptation to different regions. While\ntraditional rule-based methods struggle to incorporate the full scope of\ntraffic rules, we develop a Traffic Regulation Retrieval (TRR) Agent based on\nRetrieval-Augmented Generation (RAG) to automatically retrieve relevant traffic\nrules and guidelines from extensive regulation documents and relevant records\nbased on the ego vehicle's situation. Given the semantic complexity of the\nretrieved rules, we also design a reasoning module powered by a Large Language\nModel (LLM) to interpret these rules, differentiate between mandatory rules and\nsafety guidelines, and assess actions on legal compliance and safety.\nAdditionally, the reasoning is designed to be interpretable, enhancing both\ntransparency and reliability. The framework demonstrates robust performance on\nboth hypothesized and real-world cases across diverse scenarios, along with the\nability to adapt to different regions with ease.",
      "tldr_zh": "本研究提出了一种可解释的决策框架，用于自动驾驶车辆，全面整合交通法规、规范和安全指南，以适应不同地区。\n该框架包括基于 Retrieval-Augmented Generation (RAG) 的 Traffic Regulation Retrieval (TRR) Agent，用于自动检索相关规则文档，以及由 Large Language Model (LLM) 驱动的推理模块，来解释规则、区分强制规则与安全指南，并评估行动的合法性和安全性。\n实验结果表明，该框架在假设和真实场景中表现出色，同时提升了透明度和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04759v2",
      "published_date": "2024-10-07 05:27:22 UTC",
      "updated_date": "2025-03-13 04:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:18:40.060212"
    },
    {
      "arxiv_id": "2410.04756v1",
      "title": "Item Cluster-aware Prompt Learning for Session-based Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Wooseong Yang",
        "Chen Wang",
        "Zihe Song",
        "Weizhi Zhang",
        "Philip S. Yu"
      ],
      "abstract": "Session-based recommendation (SBR) aims to capture dynamic user preferences\nby analyzing item sequences within individual sessions. However, most existing\napproaches focus mainly on intra-session item relationships, neglecting the\nconnections between items across different sessions (inter-session\nrelationships), which limits their ability to fully capture complex item\ninteractions. While some methods incorporate inter-session information, they\noften suffer from high computational costs, leading to longer training times\nand reduced efficiency. To address these challenges, we propose the CLIP-SBR\n(Cluster-aware Item Prompt learning for Session-Based Recommendation)\nframework. CLIP-SBR is composed of two modules: 1) an item relationship mining\nmodule that builds a global graph to effectively model both intra- and\ninter-session relationships, and 2) an item cluster-aware prompt learning\nmodule that uses soft prompts to integrate these relationships into SBR models\nefficiently. We evaluate CLIP-SBR across eight SBR models and three benchmark\ndatasets, consistently demonstrating improved recommendation performance and\nestablishing CLIP-SBR as a robust solution for session-based recommendation\ntasks.",
      "tldr_zh": "本研究针对 Session-based Recommendation (SBR) 的局限性，提出 CLIP-SBR 框架，以解决现有方法忽略 inter-session 物品关系并导致计算成本高的难题。CLIP-SBR 包括两个模块：物品关系挖掘模块，通过构建全局图来有效建模 intra-session 和 inter-session 关系；以及物品集群感知提示学习模块，使用软提示高效整合这些关系到 SBR 模型中。在八个 SBR 模型和三个基准数据集上进行评估，CLIP-SBR 显著提升了推荐性能，证明了其作为鲁棒解决方案的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.04756v1",
      "published_date": "2024-10-07 05:20:21 UTC",
      "updated_date": "2024-10-07 05:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:18:52.644180"
    },
    {
      "arxiv_id": "2410.04753v1",
      "title": "ImProver: Agent-Based Automated Proof Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Riyaz Ahuja",
        "Jeremy Avigad",
        "Prasad Tetali",
        "Sean Welleck"
      ],
      "abstract": "Large language models (LLMs) have been used to generate formal proofs of\nmathematical theorems in proofs assistants such as Lean. However, we often want\nto optimize a formal proof with respect to various criteria, depending on its\ndownstream use. For example, we may want a proof to adhere to a certain style,\nor to be readable, concise, or modularly structured. Having suitably optimized\nproofs is also important for learning tasks, especially since human-written\nproofs may not optimal for that purpose. To this end, we study a new problem of\nautomated proof optimization: rewriting a proof so that it is correct and\noptimizes for an arbitrary criterion, such as length or readability. As a first\nmethod for automated proof optimization, we present ImProver, a\nlarge-language-model agent that rewrites proofs to optimize arbitrary\nuser-defined metrics in Lean. We find that naively applying LLMs to proof\noptimization falls short, and we incorporate various improvements into\nImProver, such as the use of symbolic Lean context in a novel Chain-of-States\ntechnique, as well as error-correction and retrieval. We test ImProver on\nrewriting real-world undergraduate, competition, and research-level mathematics\ntheorems, finding that ImProver is capable of rewriting proofs so that they are\nsubstantially shorter, more modular, and more readable.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 优化形式化数学证明的问题，旨在使证明更符合特定标准，如长度、可读性或模块化结构。ImProver 是一个基于 LLM 的代理系统，能够在 Lean 证明助手中重写证明，以优化用户定义的指标，并引入 Chain-of-States 技术、错误修正和检索机制来提升性能。实验结果显示，ImProver 成功优化了真实世界本科、竞赛和研究级数学定理的证明，使其更短、更模块化和更可读。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.04753v1",
      "published_date": "2024-10-07 05:14:18 UTC",
      "updated_date": "2024-10-07 05:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:19:04.564824"
    },
    {
      "arxiv_id": "2410.04740v2",
      "title": "Evaluating the Generalization Ability of Spatiotemporal Model in Urban Scenario",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Jiyuan Chen",
        "Tong Pan",
        "Zheng Dong",
        "Lingyu Zhang",
        "Renhe Jiang",
        "Xuan Song"
      ],
      "abstract": "Spatiotemporal neural networks have shown great promise in urban scenarios by\neffectively capturing temporal and spatial correlations. However, urban\nenvironments are constantly evolving, and current model evaluations are often\nlimited to traffic scenarios and use data mainly collected only a few weeks\nafter training period to evaluate model performance. The generalization ability\nof these models remains largely unexplored. To address this, we propose a\nSpatiotemporal Out-of-Distribution (ST-OOD) benchmark, which comprises six\nurban scenario: bike-sharing, 311 services, pedestrian counts, traffic speed,\ntraffic flow, ride-hailing demand, and bike-sharing, each with in-distribution\n(same year) and out-of-distribution (next years) settings. We extensively\nevaluate state-of-the-art spatiotemporal models and find that their performance\ndegrades significantly in out-of-distribution settings, with most models\nperforming even worse than a simple Multi-Layer Perceptron (MLP). Our findings\nsuggest that current leading methods tend to over-rely on parameters to overfit\ntraining data, which may lead to good performance on in-distribution data but\noften results in poor generalization. We also investigated whether dropout\ncould mitigate the negative effects of overfitting. Our results showed that a\nslight dropout rate could significantly improve generalization performance on\nmost datasets, with minimal impact on in-distribution performance. However,\nbalancing in-distribution and out-of-distribution performance remains a\nchallenging problem. We hope that the proposed benchmark will encourage further\nresearch on this critical issue.",
      "tldr_zh": "本论文评估了 spatiotemporal 神经网络在城市场景中的泛化能力，发现现有模型往往过度拟合训练数据，导致在 out-of-distribution (OOD) 设置下性能显著下降，大多数甚至不如简单的 Multi-Layer Perceptron (MLP)。为了解决这一问题，研究者提出了 Spatiotemporal Out-of-Distribution (ST-OOD) benchmark，涵盖六种城市场景（如 bike-sharing、traffic speed 等），并设置了 in-distribution (同年)和 out-of-distribution (次年)数据进行对比。实验结果显示，state-of-the-art spatiotemporal 模型在 OOD 数据上表现不佳，但引入轻微的 dropout 可以显著提升泛化性能，同时对 in-distribution 性能影响最小。然而，平衡两者之间的表现仍是一个挑战。该基准有望推动相关领域的进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04740v2",
      "published_date": "2024-10-07 04:15:48 UTC",
      "updated_date": "2024-10-09 07:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:19:17.771049"
    },
    {
      "arxiv_id": "2410.04739v3",
      "title": "TableRAG: Million-Token Table Understanding with Language Models",
      "title_zh": "TableRAG：利用语言模型进行百万标记表格理解",
      "authors": [
        "Si-An Chen",
        "Lesly Miculicich",
        "Julian Martin Eisenschlos",
        "Zifeng Wang",
        "Zilong Wang",
        "Yanfei Chen",
        "Yasuhisa Fujii",
        "Hsuan-Tien Lin",
        "Chen-Yu Lee",
        "Tomas Pfister"
      ],
      "abstract": "Recent advancements in language models (LMs) have notably enhanced their\nability to reason with tabular data, primarily through program-aided mechanisms\nthat manipulate and analyze tables. However, these methods often require the\nentire table as input, leading to scalability challenges due to the positional\nbias or context length constraints. In response to these challenges, we\nintroduce TableRAG, a Retrieval-Augmented Generation (RAG) framework\nspecifically designed for LM-based table understanding. TableRAG leverages\nquery expansion combined with schema and cell retrieval to pinpoint crucial\ninformation before providing it to the LMs. This enables more efficient data\nencoding and precise retrieval, significantly reducing prompt lengths and\nmitigating information loss. We have developed two new million-token benchmarks\nfrom the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's\neffectiveness at scale. Our results demonstrate that TableRAG's retrieval\ndesign achieves the highest retrieval quality, leading to the new\nstate-of-the-art performance on large-scale table understanding.",
      "tldr_zh": "该研究提出 TableRAG，一种基于 Retrieval-Augmented Generation (RAG) 的框架，旨在解决语言模型 (LMs) 在处理大型表格数据时面临的伸缩性问题，如位置偏差和上下文长度限制。TableRAG 通过查询扩展、schema 和 cell retrieval 来精准定位关键信息，从而提高数据编码效率、缩短提示长度并减少信息损失。研究者开发了两个新的百万令牌基准数据集（基于 Arcade 和 BIRD-SQL），实验结果显示 TableRAG 实现了最高的检索质量，并在大规模表格理解任务上达到了新的 state-of-the-art 性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.04739v3",
      "published_date": "2024-10-07 04:15:02 UTC",
      "updated_date": "2024-12-26 13:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:19:29.084861"
    },
    {
      "arxiv_id": "2410.10857v1",
      "title": "Mirror-Consistency: Harnessing Inconsistency in Majority Voting",
      "title_zh": "Mirror-Consistency：利用多数投票中的不一致性",
      "authors": [
        "Siyuan Huang",
        "Zhiyuan Ma",
        "Jintao Du",
        "Changhua Meng",
        "Weiqiang Wang",
        "Zhouhan Lin"
      ],
      "abstract": "Self-Consistency, a widely-used decoding strategy, significantly boosts the\nreasoning capabilities of Large Language Models (LLMs). However, it depends on\nthe plurality voting rule, which focuses on the most frequent answer while\noverlooking all other minority responses. These inconsistent minority views\noften illuminate areas of uncertainty within the model's generation process. To\naddress this limitation, we present Mirror-Consistency, an enhancement of the\nstandard Self-Consistency approach. Our method incorporates a 'reflective\nmirror' into the self-ensemble decoding process and enables LLMs to critically\nexamine inconsistencies among multiple generations. Additionally, just as\nhumans use the mirror to better understand themselves, we propose using\nMirror-Consistency to enhance the sample-based confidence calibration methods,\nwhich helps to mitigate issues of overconfidence. Our experimental results\ndemonstrate that Mirror-Consistency yields superior performance in both\nreasoning accuracy and confidence calibration compared to Self-Consistency.",
      "tldr_zh": "该论文针对 Large Language Models (LLMs) 的 Self-Consistency 解码策略存在的局限性提出 Mirror-Consistency 方法，该策略通过引入“reflective mirror”机制，让模型批判性地检查多个生成结果中的不一致性，从而利用少数派响应揭示不确定性。Mirror-Consistency 不仅增强了自集合解码过程，还应用于样本-based 置信度校准，以缓解模型的过度自信问题。实验结果表明，该方法在推理准确性和置信度校准方面均优于 Self-Consistency。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Short Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.10857v1",
      "published_date": "2024-10-07 03:41:08 UTC",
      "updated_date": "2024-10-07 03:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:19:40.749227"
    },
    {
      "arxiv_id": "2410.04723v1",
      "title": "ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep Tabular Learning",
      "title_zh": "ProtoNAM：原型神经加性模型用于可解释的深度表格学习",
      "authors": [
        "Guangzhi Xiong",
        "Sanchit Sinha",
        "Aidong Zhang"
      ],
      "abstract": "Generalized additive models (GAMs) have long been a powerful white-box tool\nfor the intelligible analysis of tabular data, revealing the influence of each\nfeature on the model predictions. Despite the success of neural networks (NNs)\nin various domains, their application as NN-based GAMs in tabular data analysis\nremains suboptimal compared to tree-based ones, and the opacity of encoders in\nNN-GAMs also prevents users from understanding how networks learn the\nfunctions. In this work, we propose a new deep tabular learning method, termed\nPrototypical Neural Additive Model (ProtoNAM), which introduces prototypes into\nneural networks in the framework of GAMs. With the introduced prototype-based\nfeature activation, ProtoNAM can flexibly model the irregular mapping from\ntabular features to the outputs while maintaining the explainability of the\nfinal prediction. We also propose a gradient-boosting inspired hierarchical\nshape function modeling method, facilitating the discovery of complex feature\npatterns and bringing transparency into the learning process of each network\nlayer. Our empirical evaluations demonstrate that ProtoNAM outperforms all\nexisting NN-based GAMs, while providing additional insights into the shape\nfunction learned for each feature. The source code of ProtoNAM is available at\n\\url{https://github.com/Teddy-XiongGZ/ProtoNAM}.",
      "tldr_zh": "本研究提出了一种新的深度表格学习方法，ProtoNAM（Prototypical Neural Additive Models），旨在提升Generalized Additive Models (GAMs)的可解释性和性能，以解决神经网络 (NNs) 在表格数据分析中的不透明问题。ProtoNAM 通过引入prototypes和prototype-based feature activation，在GAMs框架下灵活建模特征到输出的不规则映射，同时保持预测的可解释性；此外，还采用受梯度提升启发的层次化shape function建模方法，帮助发现复杂特征模式并透明化网络层学习过程。实验结果显示，ProtoNAM 优于现有 NN-based GAMs，并在每个特征的shape function学习上提供额外洞见，源代码可从指定仓库获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04723v1",
      "published_date": "2024-10-07 03:25:46 UTC",
      "updated_date": "2024-10-07 03:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:19:52.828124"
    },
    {
      "arxiv_id": "2410.04717v3",
      "title": "$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization",
      "title_zh": "Only-IF：揭示指令多样性对泛化的决定性影响",
      "authors": [
        "Dylan Zhang",
        "Justin Wang",
        "Francois Charton"
      ],
      "abstract": "Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.",
      "tldr_zh": "这篇论文$\\textbf{Only-IF}$探讨了指令多样性对大型语言模型 (LLMs) 泛化能力的关键影响，通过受 Turing-complete Markov 算法启发的受控实验证明，模型的泛化仅在训练数据跨语义域足够多样化时才会出现。研究发现，仅在有限域内多样化无法确保鲁棒泛化，而跨域数据多样化即使在数据预算有限的情况下也能显著提升模型的适应性。进一步的实证分析表明，对于专家模型和通用模型，增加数据集的语义多样性比单纯扩充数据量更有效，从而为优化指令调优数据集提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Fix formatting issues",
      "pdf_url": "http://arxiv.org/pdf/2410.04717v3",
      "published_date": "2024-10-07 03:15:11 UTC",
      "updated_date": "2024-10-18 03:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:20:14.571307"
    },
    {
      "arxiv_id": "2410.04715v2",
      "title": "Rule-based Data Selection for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaomin Li",
        "Mingye Gao",
        "Zhiwei Zhang",
        "Chang Yue",
        "Hong Hu"
      ],
      "abstract": "The quality of training data significantly impacts the performance of large\nlanguage models (LLMs). There are increasing studies using LLMs to rate and\nselect data based on several human-crafted metrics (rules). However, these\nconventional rule-based approaches often depend too heavily on human\nheuristics, lack effective metrics for assessing rules, and exhibit limited\nadaptability to new tasks. In our study, we introduce an innovative rule-based\nframework that utilizes the orthogonality of score vectors associated with\nrules as a novel metric for rule evaluations. Our approach includes an\nautomated pipeline that first uses LLMs to generate a diverse set of rules,\nencompassing various rating dimensions to evaluate data quality. Then it rates\na batch of data based on these rules and uses the determinantal point process\n(DPP) from random matrix theory to select the most orthogonal score vectors,\nthereby identifying a set of independent rules. These rules are subsequently\nused to evaluate all data, selecting samples with the highest average scores\nfor downstream tasks such as LLM training. We verify the effectiveness of our\nmethod through two experimental setups: 1) comparisons with ground truth\nratings and 2) benchmarking LLMs trained with the chosen data. Our\ncomprehensive experiments cover a range of scenarios, including general\npre-training and domain-specific fine-tuning in areas such as IMDB, Medical,\nMath, and Code. The outcomes demonstrate that our DPP-based rule rating method\nconsistently outperforms other approaches, including rule-free rating, uniform\nsampling, importance resampling, and QuRating, in terms of both rating\nprecision and model performance.",
      "tldr_zh": "这篇论文提出了一种创新的规则框架，用于 Large Language Models (LLMs) 的数据选择，解决传统方法过度依赖人类启发式规则、缺乏有效评估指标和适应性差的问题。该框架利用 LLMs 生成多样化规则集，然后通过分数向量的正交性作为新指标，并应用 Determinantal Point Process (DPP) 从随机矩阵理论中选择独立的规则，以评估和筛选高质量数据样本。实验验证包括与地面真实评分比较以及使用选定数据训练 LLMs，结果显示该方法在通用预训练和特定领域微调（如 IMDB、Medical、Math、Code）中，显著优于 uniform sampling 和 QuRating 等基准，在评分精度和模型性能上提升明显。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04715v2",
      "published_date": "2024-10-07 03:13:06 UTC",
      "updated_date": "2024-12-08 16:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:20:17.200880"
    },
    {
      "arxiv_id": "2410.04708v1",
      "title": "Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ankur Mali",
        "Tommaso Salvatori",
        "Alexander Ororbia"
      ],
      "abstract": "Energy-based learning algorithms, such as predictive coding (PC), have\ngarnered significant attention in the machine learning community due to their\ntheoretical properties, such as local operations and biologically plausible\nmechanisms for error correction. In this work, we rigorously analyze the\nstability, robustness, and convergence of PC through the lens of dynamical\nsystems theory. We show that, first, PC is Lyapunov stable under mild\nassumptions on its loss and residual energy functions, which implies intrinsic\nrobustness to small random perturbations due to its well-defined\nenergy-minimizing dynamics. Second, we formally establish that the PC updates\napproximate quasi-Newton methods by incorporating higher-order curvature\ninformation, which makes them more stable and able to converge with fewer\niterations compared to models trained via backpropagation (BP). Furthermore,\nusing this dynamical framework, we provide new theoretical bounds on the\nsimilarity between PC and other algorithms, i.e., BP and target propagation\n(TP), by precisely characterizing the role of higher-order derivatives. These\nbounds, derived through detailed analysis of the Hessian structures, show that\nPC is significantly closer to quasi-Newton updates than TP, providing a deeper\nunderstanding of the stability and efficiency of PC compared to conventional\nlearning methods.",
      "tldr_zh": "本研究从动力系统理论角度，严格分析了预测编码 (PC) 网络的稳定性、鲁棒性和收敛性，发现 PC 在对损失和残差能量函数的温和假设下是 Lyapunov 稳定的，并对小随机扰动具有内在鲁棒性。作者证明 PC 的更新类似于准牛顿方法，通过整合更高阶曲率信息，使其比反向传播 (BP) 更稳定且收敛更快。最终，该工作提供了新的理论边界，通过对 Hessian 结构的详细分析，表明 PC 与 BP 和目标传播 (TP) 相比，更接近准牛顿更新，从而提升了对 PC 效率的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 9 theorems",
      "pdf_url": "http://arxiv.org/pdf/2410.04708v1",
      "published_date": "2024-10-07 02:57:26 UTC",
      "updated_date": "2024-10-07 02:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:20:29.861887"
    },
    {
      "arxiv_id": "2410.17261v1",
      "title": "Masked Autoencoder with Swin Transformer Network for Mitigating Electrode Shift in HD-EMG-based Gesture Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Kasra Laamerad",
        "Mehran Shabanpour",
        "Md. Rabiul Islam",
        "Arash Mohammadi"
      ],
      "abstract": "Multi-channel surface Electromyography (sEMG), also referred to as\nhigh-density sEMG (HD-sEMG), plays a crucial role in improving gesture\nrecognition performance for myoelectric control. Pattern recognition models\ndeveloped based on HD-sEMG, however, are vulnerable to changing recording\nconditions (e.g., signal variability due to electrode shift). This has resulted\nin significant degradation in performance across subjects, and sessions. In\nthis context, the paper proposes the Masked Autoencoder with Swin Transformer\n(MAST) framework, where training is performed on a masked subset of HDsEMG\nchannels. A combination of four masking strategies, i.e., random block masking;\ntemporal masking; sensor-wise random masking, and; multi-scale masking, is used\nto learn latent representations and increase robustness against electrode\nshift. The masked data is then passed through MAST's three-path encoder-decoder\nstructure, leveraging a multi-path Swin-Unet architecture that simultaneously\ncaptures time-domain, frequency-domain, and magnitude-based features of the\nunderlying HD-sEMG signal. These augmented inputs are then used in a\nself-supervised pre-training fashion to improve the model's generalization\ncapabilities. Experimental results demonstrate the superior performance of the\nproposed MAST framework in comparison to its counterparts.",
      "tldr_zh": "本文提出MAST（Masked Autoencoder with Swin Transformer）框架，用于缓解HD-sEMG-based手势识别中的电极位移问题，通过四种掩码策略（如随机块掩码、时间掩码和多尺度掩码）在自监督预训练中学习潜在表示，并利用多路径Swin-Unet架构同时捕获时间域、频域和幅度特征。 该方法显著提高了模型对信号变异性的鲁棒性，并通过增强输入改善泛化能力。 实验结果显示，MAST框架在性能上优于现有基线模型。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17261v1",
      "published_date": "2024-10-07 02:55:36 UTC",
      "updated_date": "2024-10-07 02:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:20:41.182913"
    },
    {
      "arxiv_id": "2410.04707v1",
      "title": "Learning How Hard to Think: Input-Adaptive Allocation of LM Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Mehul Damani",
        "Idan Shenfeld",
        "Andi Peng",
        "Andreea Bobu",
        "Jacob Andreas"
      ],
      "abstract": "Computationally intensive decoding procedures--including search, reranking,\nand self-critique--can improve the quality of language model (LM) outputs in\nproblems spanning code generation, numerical reasoning, and dialog. Existing\nwork typically applies the same decoding procedure for every input to an LM.\nBut not all inputs require the same amount of computation to process. Can we\nallocate decoding computation adaptively, using more resources to answer\nquestions whose answers will be harder to compute? We present an approach that\npredicts the distribution of rewards given an input and computation budget,\nthen allocates additional computation to inputs for which it is predicted to be\nmost useful. We apply this approach in two decoding procedures: first, an\nadaptive best-of-k procedure that dynamically selects the number of samples to\ngenerate as input to a reranker; second, a routing procedure that dynamically\nresponds to a query using a decoding procedure that is expensive but accurate,\nor one that is cheaper but less capable. Across a suite of programming,\nmathematics, and dialog tasks, we show that accurate computation-allocation\nprocedures can be learned, and reduce computation by up to 50% at no cost to\nresponse quality, or improve quality by up to 10% at a fixed computational\nbudget.",
      "tldr_zh": "这篇论文提出了一种输入自适应的方法，用于优化语言模型 (LM) 的计算资源分配，针对不同输入动态调整解码过程（如搜索、重排和自我批评），以更高效地处理复杂任务。方法包括预测输入的奖励分布，并据此分配额外计算资源，例如自适应 best-of-k 过程动态选择样本数量，以及路由过程选择昂贵但准确或便宜但较弱的解码策略。在编程、数学和对话任务的实验中，该方法可将计算量减少高达 50% 而不影响输出质量，或在固定计算预算下提高质量达 10%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04707v1",
      "published_date": "2024-10-07 02:52:30 UTC",
      "updated_date": "2024-10-07 02:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:20:56.351782"
    },
    {
      "arxiv_id": "2410.05341v2",
      "title": "NeuroBOLT: Resting-state EEG-to-fMRI Synthesis with Multi-dimensional Feature Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Yamin Li",
        "Ange Lou",
        "Ziyuan Xu",
        "Shengchao Zhang",
        "Shiyu Wang",
        "Dario J. Englot",
        "Soheil Kolouri",
        "Daniel Moyer",
        "Roza G. Bayrak",
        "Catie Chang"
      ],
      "abstract": "Functional magnetic resonance imaging (fMRI) is an indispensable tool in\nmodern neuroscience, providing a non-invasive window into whole-brain dynamics\nat millimeter-scale spatial resolution. However, fMRI is constrained by issues\nsuch as high operation costs and immobility. With the rapid advancements in\ncross-modality synthesis and brain decoding, the use of deep neural networks\nhas emerged as a promising solution for inferring whole-brain, high-resolution\nfMRI features directly from electroencephalography (EEG), a more widely\naccessible and portable neuroimaging modality. Nonetheless, the complex\nprojection from neural activity to fMRI hemodynamic responses and the spatial\nambiguity of EEG pose substantial challenges both in modeling and\ninterpretability. Relatively few studies to date have developed approaches for\nEEG-fMRI translation, and although they have made significant strides, the\ninference of fMRI signals in a given study has been limited to a small set of\nbrain areas and to a single condition (i.e., either resting-state or a specific\ntask). The capability to predict fMRI signals in other brain areas, as well as\nto generalize across conditions, remain critical gaps in the field. To tackle\nthese challenges, we introduce a novel and generalizable framework: NeuroBOLT,\ni.e., Neuro-to-BOLD Transformer, which leverages multi-dimensional\nrepresentation learning from temporal, spatial, and spectral domains to\ntranslate raw EEG data to the corresponding fMRI activity signals across the\nbrain. Our experiments demonstrate that NeuroBOLT effectively reconstructs\nunseen resting-state fMRI signals from primary sensory, high-level cognitive\nareas, and deep subcortical brain regions, achieving state-of-the-art accuracy\nwith the potential to generalize across varying conditions and sites, which\nsignificantly advances the integration of these two modalities.",
      "tldr_zh": "本研究提出NeuroBOLT框架（Neuro-to-BOLD Transformer），旨在通过多维度特征映射（包括时间、空间和谱域）将静息状态EEG数据合成全脑fMRI信号，以克服fMRI的高成本和不 portability问题。NeuroBOLT利用Transformer架构处理EEG到fMRI的复杂映射，实现对初级感觉区、高级认知区和深部皮层下脑区的精确重建。实验结果显示，该框架在重建未见过的fMRI信号方面达到了state-of-the-art准确率，并展示出在不同条件和站点间的泛化潜力，从而推进EEG和fMRI模态的整合。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "This preprint has been accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.05341v2",
      "published_date": "2024-10-07 02:47:55 UTC",
      "updated_date": "2024-11-02 18:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:21:04.084602"
    },
    {
      "arxiv_id": "2410.05339v2",
      "title": "Proceedings of the First International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2024)",
      "title_zh": "翻译失败",
      "authors": [
        "Ken Satoh",
        "Ha-Thanh Nguyen",
        "Francesca Toni",
        "Randy Goebel",
        "Kostas Stathis"
      ],
      "abstract": "Reasoning is an essential component of human intelligence as it plays a\nfundamental role in our ability to think critically, support responsible\ndecisions, and solve challenging problems. Traditionally, AI has addressed\nreasoning in the context of logic-based representations of knowledge. However,\nthe recent leap forward in natural language processing, with the emergence of\nlanguage models based on transformers, is hinting at the possibility that these\nmodels exhibit reasoning abilities, particularly as they grow in size and are\ntrained on more data. Despite ongoing discussions about what reasoning is in\nlanguage models, it is still not easy to pin down to what extent these models\nare actually capable of reasoning.\n  The goal of this workshop is to create a platform for researchers from\ndifferent disciplines and/or AI perspectives, to explore approaches and\ntechniques with the aim to reconcile reasoning between language models using\ntransformers and using logic-based representations. The specific objectives\ninclude analyzing the reasoning abilities of language models measured alongside\nKR methods, injecting KR-style reasoning abilities into language models\n(including by neuro-symbolic means), and formalizing the kind of reasoning\nlanguage models carry out. This exploration aims to uncover how language models\ncan effectively integrate and leverage knowledge and reasoning with it, thus\nimproving their application and utility in areas where precision and\nreliability are a key requirement.",
      "tldr_zh": "本工作坊（NeLaMKRR 2024）探讨了下一代语言 models，特别是基于 transformers 的模型，在知识 representation and reasoning 中的潜力，旨在弥合这些模型与传统逻辑-based 方法之间的差距。工作坊的目标是为不同学科的研究者提供平台，分析语言 models 的推理能力、注入 KR-style reasoning 能力（包括 neuro-symbolic 方法），并正式化这些模型的推理类型。最终，这将提升语言 models 在需要高精确性和可靠性的应用领域的效用和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Associated with the 21st International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2024) in Hanoi, Vietnam",
      "pdf_url": "http://arxiv.org/pdf/2410.05339v2",
      "published_date": "2024-10-07 02:31:47 UTC",
      "updated_date": "2024-10-12 16:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:21:17.115964"
    },
    {
      "arxiv_id": "2410.04683v2",
      "title": "Towards Measuring Goal-Directedness in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Xu",
        "Juan-Pablo Rivera"
      ],
      "abstract": "Recent advances in deep learning have brought attention to the possibility of\ncreating advanced, general AI systems that outperform humans across many tasks.\nHowever, if these systems pursue unintended goals, there could be catastrophic\nconsequences. A key prerequisite for AI systems pursuing unintended goals is\nwhether they will behave in a coherent and goal-directed manner in the first\nplace, optimizing for some unknown goal; there exists significant research\ntrying to evaluate systems for said behaviors. However, the most rigorous\ndefinitions of goal-directedness we currently have are difficult to compute in\nreal-world settings. Drawing upon this previous literature, we explore policy\ngoal-directedness within reinforcement learning (RL) environments. In our\nfindings, we propose a different family of definitions of the goal-directedness\nof a policy that analyze whether it is well-modeled as near-optimal for many\n(sparse) reward functions. We operationalize this preliminary definition of\ngoal-directedness and test it in toy Markov decision process (MDP)\nenvironments. Furthermore, we explore how goal-directedness could be measured\nin frontier large-language models (LLMs). Our contribution is a definition of\ngoal-directedness that is simpler and more easily computable in order to\napproach the question of whether AI systems could pursue dangerous goals. We\nrecommend further exploration of measuring coherence and goal-directedness,\nbased on our findings.",
      "tldr_zh": "这篇论文探讨了如何测量AI系统的目标导向性（goal-directedness），以评估它们是否可能以连贯方式追求意外目标，从而避免潜在灾难性后果。作者提出了一种新定义，通过分析策略在强化学习（RL）环境中是否接近许多稀疏奖励函数的最优解，并将其在玩具Markov决策过程（MDP）环境中进行了测试。同时，论文探讨了在前沿大型语言模型（LLMs）中应用这一测量的可能性。该贡献提供了一个更简单、易计算的目标导向性定义，并建议进一步研究AI系统的连贯性和目标导向性测量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated acknowledgements",
      "pdf_url": "http://arxiv.org/pdf/2410.04683v2",
      "published_date": "2024-10-07 01:34:42 UTC",
      "updated_date": "2024-11-22 00:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:21:28.812019"
    },
    {
      "arxiv_id": "2410.04660v2",
      "title": "KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaorui Su",
        "Yibo Wang",
        "Shanghua Gao",
        "Xiaolong Liu",
        "Valentina Giunchiglia",
        "Djork-Arné Clevert",
        "Marinka Zitnik"
      ],
      "abstract": "Biomedical reasoning integrates structured, codified knowledge with tacit,\nexperience-driven insights. Depending on the context, quantity, and nature of\navailable evidence, researchers and clinicians use diverse strategies,\nincluding rule-based, prototype-based, and case-based reasoning. Effective\nmedical AI models must handle this complexity while ensuring reliability and\nadaptability. We introduce KGARevion, a knowledge graph-based agent that\nanswers knowledge-intensive questions. Upon receiving a query, KGARevion\ngenerates relevant triplets by leveraging the latent knowledge embedded in a\nlarge language model. It then verifies these triplets against a grounded\nknowledge graph, filtering out errors and retaining only accurate, contextually\nrelevant information for the final answer. This multi-step process strengthens\nreasoning, adapts to different models of medical inference, and outperforms\nretrieval-augmented generation-based approaches that lack effective\nverification mechanisms. Evaluations on medical QA benchmarks show that\nKGARevion improves accuracy by over 5.2% over 15 models in handling complex\nmedical queries. To further assess its effectiveness, we curated three new\nmedical QA datasets with varying levels of semantic complexity, where KGARevion\nimproved accuracy by 10.4%. The agent integrates with different LLMs and\nbiomedical knowledge graphs for broad applicability across knowledge-intensive\ntasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused\non African healthcare, demonstrating its strong zero-shot generalization to\nunderrepresented medical contexts.",
      "tldr_zh": "本研究引入了KGARevion，一种基于知识图谱的AI代理，旨在处理知识密集型生物医学问答任务。它的工作流程包括利用大语言模型(LLM)生成相关三元组(triplets)，然后通过与知识图谱验证来过滤错误，确保答案的准确性和适应性，从而优于传统检索增强生成方法。在评估中，KGARevion在医疗QA基准测试中比15个模型提高了5.2%的准确率，并在新创建的三个语义复杂数据集上提升了10.4%，并展示了在AfriMed-QA等数据集上的零样本泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.04660v2",
      "published_date": "2024-10-07 00:17:37 UTC",
      "updated_date": "2025-03-03 18:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:21:41.330433"
    },
    {
      "arxiv_id": "2410.04657v1",
      "title": "Contrastive Learning to Improve Retrieval for Real-world Fact Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Aniruddh Sriram",
        "Fangyuan Xu",
        "Eunsol Choi",
        "Greg Durrett"
      ],
      "abstract": "Recent work on fact-checking addresses a realistic setting where models\nincorporate evidence retrieved from the web to decide the veracity of claims. A\nbottleneck in this pipeline is in retrieving relevant evidence: traditional\nmethods may surface documents directly related to a claim, but fact-checking\ncomplex claims requires more inferences. For instance, a document about how a\nvaccine was developed is relevant to addressing claims about what it might\ncontain, even if it does not address them directly. We present Contrastive\nFact-Checking Reranker (CFR), an improved retriever for this setting. By\nleveraging the AVeriTeC dataset, which annotates subquestions for claims with\nhuman written answers from evidence documents, we fine-tune Contriever with a\ncontrastive objective based on multiple training signals, including\ndistillation from GPT-4, evaluating subquestion answers, and gold labels in the\ndataset. We evaluate our model on both retrieval and end-to-end veracity\njudgments about claims. On the AVeriTeC dataset, we find a 6\\% improvement in\nveracity classification accuracy. We also show our gains can be transferred to\nFEVER, ClaimDecomp, HotpotQA, and a synthetic dataset requiring retrievers to\nmake inferences.",
      "tldr_zh": "本文提出Contrastive Fact-Checking Reranker (CFR)，一种基于对比学习(Contrastive Learning)的改进检索器，旨在提升事实核查中证据检索的准确性，尤其针对需要推理的复杂声明，例如使用疫苗开发文档来验证其成分声明。方法包括利用AVeriTeC数据集微调Contriever模型，结合从GPT-4的蒸馏信号、子问题答案评估和金标准标签的多重训练信号。实验结果显示，CFR在AVeriTeC数据集上真实性分类准确率提高6%，并成功转移到FEVER、ClaimDecomp、HotpotQA等数据集上，提升了整体检索和验证性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 FEVER Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.04657v1",
      "published_date": "2024-10-07 00:09:50 UTC",
      "updated_date": "2024-10-07 00:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T08:21:52.889772"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 138,
  "processed_papers_count": 138,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T08:22:13.552897"
}