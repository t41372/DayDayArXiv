[
  {
    "arxiv_id": "2410.05563v2",
    "title": "Rational Metareasoning for Large Language Models",
    "authors": [
      "C. Nicolò De Sabbata",
      "Theodore R. Sumers",
      "Thomas L. Griffiths"
    ],
    "abstract": "Being prompted to engage in reasoning has emerged as a core technique for\nusing large language models (LLMs), deploying additional inference-time compute\nto improve task performance. However, as LLMs increase in both size and\nadoption, inference costs are correspondingly becoming increasingly burdensome.\nHow, then, might we optimize reasoning's cost-performance tradeoff? This work\nintroduces a novel approach based on computational models of metareasoning used\nin cognitive science, training LLMs to selectively use intermediate reasoning\nsteps only when necessary. We first develop a reward function that incorporates\nthe Value of Computation by penalizing unnecessary reasoning, then use this\nreward function with Expert Iteration to train the LLM. Compared to few-shot\nchain-of-thought prompting and STaR, our method significantly reduces inference\ncosts (20-37\\% fewer tokens generated across three models) while maintaining\ntask performance across diverse datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05563v2",
    "published_date": "2024-10-07 23:48:52 UTC",
    "updated_date": "2024-12-21 11:08:42 UTC"
  },
  {
    "arxiv_id": "2410.05558v2",
    "title": "Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives",
    "authors": [
      "Xinliang Frederick Zhang",
      "Nick Beauchamp",
      "Lu Wang"
    ],
    "abstract": "Reasoning about time and temporal relations is an integral aspect of human\ncognition, essential for perceiving the world and navigating our experiences.\nThough large language models (LLMs) have demonstrated impressive performance in\nmany reasoning tasks, temporal reasoning remains challenging due to its\nintrinsic complexity. In this work, we first study an essential task of\ntemporal reasoning -- temporal graph generation, to unveil LLMs' inherent,\nglobal reasoning capabilities. We show that this task presents great challenges\neven for the most powerful LLMs, such as GPT-3.5/4. We also notice a\nsignificant performance gap by small models (<10B) that lag behind LLMs by 50%.\nNext, we study how to close this gap with a budget constraint, e.g., not using\nmodel finetuning. We propose a new prompting technique tailored for temporal\nreasoning, Narrative-of-Thought (NoT), that first converts the events set to a\nPython class, then prompts a small model to generate a temporally grounded\nnarrative, guiding the final generation of a temporal graph. Extensive\nexperiments showcase the efficacy of NoT in improving various metrics. Notably,\nNoT attains the highest F1 on the Schema-11 evaluation set, while securing an\noverall F1 on par with GPT-3.5. NoT also achieves the best structural\nsimilarity across the board, even compared with GPT-3.5/4. Our code is\navailable at https://github.com/launchnlp/NoT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP'24 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.05558v2",
    "published_date": "2024-10-07 23:36:05 UTC",
    "updated_date": "2024-11-17 17:00:11 UTC"
  },
  {
    "arxiv_id": "2410.05553v1",
    "title": "On Instruction-Finetuning Neural Machine Translation Models",
    "authors": [
      "Vikas Raunak",
      "Roman Grundkiewicz",
      "Marcin Junczys-Dowmunt"
    ],
    "abstract": "In this work, we introduce instruction finetuning for Neural Machine\nTranslation (NMT) models, which distills instruction following capabilities\nfrom Large Language Models (LLMs) into orders-of-magnitude smaller NMT models.\nOur instruction-finetuning recipe for NMT models enables customization of\ntranslations for a limited but disparate set of translation-specific tasks. We\nshow that NMT models are capable of following multiple instructions\nsimultaneously and demonstrate capabilities of zero-shot composition of\ninstructions. We also show that through instruction finetuning, traditionally\ndisparate tasks such as formality-controlled machine translation, multi-domain\nadaptation as well as multi-modal translations can be tackled jointly by a\nsingle instruction finetuned NMT model, at a performance level comparable to\nLLMs such as GPT-3.5-Turbo. To the best of our knowledge, our work is among the\nfirst to demonstrate the instruction-following capabilities of traditional NMT\nmodels, which allows for faster, cheaper and more efficient serving of\ncustomized translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "WMT'24",
    "pdf_url": "http://arxiv.org/pdf/2410.05553v1",
    "published_date": "2024-10-07 23:26:13 UTC",
    "updated_date": "2024-10-07 23:26:13 UTC"
  },
  {
    "arxiv_id": "2410.10864v1",
    "title": "Fill In The Gaps: Model Calibration and Generalization with Synthetic Data",
    "authors": [
      "Yang Ba",
      "Michelle V. Mancenido",
      "Rong Pan"
    ],
    "abstract": "As machine learning models continue to swiftly advance, calibrating their\nperformance has become a major concern prior to practical and widespread\nimplementation. Most existing calibration methods often negatively impact model\naccuracy due to the lack of diversity of validation data, resulting in reduced\ngeneralizability. To address this, we propose a calibration method that\nincorporates synthetic data without compromising accuracy. We derive the\nexpected calibration error (ECE) bound using the Probably Approximately Correct\n(PAC) learning framework. Large language models (LLMs), known for their ability\nto mimic real data and generate text with mixed class labels, are utilized as a\nsynthetic data generation strategy to lower the ECE bound and improve model\naccuracy on real test data. Additionally, we propose data generation mechanisms\nfor efficient calibration. Testing our method on four different natural\nlanguage processing tasks, we observed an average up to 34\\% increase in\naccuracy and 33\\% decrease in ECE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Main Conference (Long paper)",
    "pdf_url": "http://arxiv.org/pdf/2410.10864v1",
    "published_date": "2024-10-07 23:06:42 UTC",
    "updated_date": "2024-10-07 23:06:42 UTC"
  },
  {
    "arxiv_id": "2410.05538v3",
    "title": "Online Dynamic Pricing for Electric Vehicle Charging Stations with Reservations",
    "authors": [
      "Jan Mrkos",
      "Antonín Komenda",
      "David Fiedler",
      "Jiří Vokřínek"
    ],
    "abstract": "This paper introduces a novel model for online dynamic pricing of electric\nvehicle charging services that integrates reservation, parking, and charging\ninto a comprehensive bundle priced as a whole. Our approach focuses on the\nindividual high-demand, fast-charging location, employing a Poisson process as\na model of charging reservation arrivals, and develops an online dynamic\npricing strategy optimized through a Markov Decision Process (MDP). A key\ncontribution is the novel analysis of discretization error introduced when\nincorporating the continuous-time Poisson process into the discrete MDP\nframework. The MDP model's feasibility is demonstrated with a heuristic dynamic\npricing method based on Monte-Carlo tree search, offering a viable path for\nreal-world applications.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "45 pages, 11 figure, accepted to IEEE Transactions on Intelligent\n  Transportation Systems (T-ITS)",
    "pdf_url": "http://arxiv.org/pdf/2410.05538v3",
    "published_date": "2024-10-07 22:36:40 UTC",
    "updated_date": "2025-04-28 08:51:51 UTC"
  },
  {
    "arxiv_id": "2410.05536v3",
    "title": "Accelerating Flood Warnings by 10 Hours: The Power of River Network Topology in AI-enhanced Flood Forecasting",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Yinqiang Zheng",
      "Xuan Song"
    ],
    "abstract": "Climate change-driven floods demand advanced forecasting models, yet Graph\nNeural Networks (GNNs) underutilize river network topology due to tree-like\nstructures causing over-squashing from high node resistance distances. This\nstudy identifies this limitation and introduces a reachability-based graph\ntransformation to densify topological connections, reducing resistance\ndistances. Empirical tests show transformed-GNNs outperform EA-LSTM in extreme\nflood prediction, achieving 24-h water level accuracy equivalent to EA-LSTM's\n14-h forecasts - a 71% improvement in long-term predictive horizon. The dense\ngraph retains flow dynamics across hierarchical river branches, enabling GNNs\nto capture distal node interactions critical for rare flood events. This\ntopological innovation bridges the gap between river network structure and GNN\nmodeling, offering a scalable framework for early warning systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05536v3",
    "published_date": "2024-10-07 22:25:37 UTC",
    "updated_date": "2025-03-13 00:58:05 UTC"
  },
  {
    "arxiv_id": "2410.05534v1",
    "title": "Optimizing Tensor Computation Graphs with Equality Saturation and Monte Carlo Tree Search",
    "authors": [
      "Jakob Hartmann",
      "Guoliang He",
      "Eiko Yoneki"
    ],
    "abstract": "The real-world effectiveness of deep neural networks often depends on their\nlatency, thereby necessitating optimization techniques that can reduce a\nmodel's inference time while preserving its performance. One popular approach\nis to sequentially rewrite the input computation graph into an equivalent but\nfaster one by replacing individual subgraphs. This approach gives rise to the\nso-called phase-ordering problem in which the application of one rewrite rule\ncan eliminate the possibility to apply an even better one later on. Recent work\nhas shown that equality saturation, a technique from compiler optimization, can\nmitigate this issue by first building an intermediate representation (IR) that\nefficiently stores multiple optimized versions of the input program before\nextracting the best solution in a second step. In practice, however, memory\nconstraints prevent the IR from capturing all optimized versions and thus\nreintroduce the phase-ordering problem in the construction phase. In this\npaper, we present a tensor graph rewriting approach that uses Monte Carlo tree\nsearch to build superior IRs by identifying the most promising rewrite rules.\nWe also introduce a novel extraction algorithm that can provide fast and\naccurate runtime estimates of tensor programs represented in an IR. Our\napproach improves the inference speedup of neural networks by up to 11%\ncompared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in the 33rd International Conference on Parallel\n  Architectures and Compilation Techniques (PACT '24), October 14-16, 2024,\n  Long Beach, CA, USA",
    "pdf_url": "http://arxiv.org/pdf/2410.05534v1",
    "published_date": "2024-10-07 22:22:02 UTC",
    "updated_date": "2024-10-07 22:22:02 UTC"
  },
  {
    "arxiv_id": "2410.05514v1",
    "title": "Toward General Object-level Mapping from Sparse Views with 3D Diffusion Priors",
    "authors": [
      "Ziwei Liao",
      "Binbin Xu",
      "Steven L. Waslander"
    ],
    "abstract": "Object-level mapping builds a 3D map of objects in a scene with detailed\nshapes and poses from multi-view sensor observations. Conventional methods\nstruggle to build complete shapes and estimate accurate poses due to partial\nocclusions and sensor noise. They require dense observations to cover all\nobjects, which is challenging to achieve in robotics trajectories. Recent work\nintroduces generative shape priors for object-level mapping from sparse views,\nbut is limited to single-category objects. In this work, we propose a General\nObject-level Mapping system, GOM, which leverages a 3D diffusion model as shape\nprior with multi-category support and outputs Neural Radiance Fields (NeRFs)\nfor both texture and geometry for all objects in a scene. GOM includes an\neffective formulation to guide a pre-trained diffusion model with extra\nnonlinear constraints from sensor measurements without finetuning. We also\ndevelop a probabilistic optimization formulation to fuse multi-view sensor\nobservations and diffusion priors for joint 3D object pose and shape\nestimation. Our GOM system demonstrates superior multi-category mapping\nperformance from sparse views, and achieves more accurate mapping results\ncompared to state-of-the-art methods on the real-world benchmarks. We will\nrelease our code: https://github.com/TRAILab/GeneralObjectMapping.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.05514v1",
    "published_date": "2024-10-07 21:33:30 UTC",
    "updated_date": "2024-10-07 21:33:30 UTC"
  },
  {
    "arxiv_id": "2410.05500v2",
    "title": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning",
    "authors": [
      "Ray Congrui Yu",
      "Sherry Wu",
      "Jiang Gui"
    ],
    "abstract": "Despite their immense success, deep neural networks (CNNs) are costly to\ntrain, while modern architectures can retain hundreds of convolutional layers\nin network depth. Standard convolutional operations are fundamentally limited\nby their linear nature along with fixed activations, where multiple layers are\nneeded to learn complex patterns, making this approach computationally\ninefficient and prone to optimization difficulties. As a result, we introduce\nRKAN (Residual Kolmogorov-Arnold Network), which could be easily implemented\ninto stages of traditional networks, such as ResNet. The module also integrates\npolynomial feature transformation that provides the expressive power of many\nconvolutional layers through learnable, non-linear feature refinement. Our\nproposed RKAN module offers consistent improvements over the base models on\nvarious well-known benchmark datasets, such as CIFAR-100, Food-101, and\nImageNet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.10; I.4.3; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at https://github.com/withray/residualKAN.git",
    "pdf_url": "http://arxiv.org/pdf/2410.05500v2",
    "published_date": "2024-10-07 21:12:32 UTC",
    "updated_date": "2025-03-04 06:34:37 UTC"
  },
  {
    "arxiv_id": "2410.05496v1",
    "title": "Intuitions of Compromise: Utilitarianism vs. Contractualism",
    "authors": [
      "Jared Moore",
      "Yejin Choi",
      "Sydney Levine"
    ],
    "abstract": "What is the best compromise in a situation where different people value\ndifferent things? The most commonly accepted method for answering this question\n-- in fields across the behavioral and social sciences, decision theory,\nphilosophy, and artificial intelligence development -- is simply to add up\nutilities associated with the different options and pick the solution with the\nlargest sum. This ``utilitarian'' approach seems like the obvious,\ntheory-neutral way of approaching the problem. But there is an important,\nthough often-ignored, alternative: a ``contractualist'' approach, which\nadvocates for an agreement-driven method of deciding. Remarkably, no research\nhas presented empirical evidence directly comparing the intuitive plausibility\nof these two approaches. In this paper, we systematically explore the proposals\nsuggested by each algorithm (the ``Utilitarian Sum'' and the contractualist\n''Nash Product''), using a paradigm that applies those algorithms to\naggregating preferences across groups in a social decision-making context.\nWhile the dominant approach to value aggregation up to now has been\nutilitarian, we find that people strongly prefer the aggregations recommended\nby the contractualist algorithm. Finally, we compare the judgments of large\nlanguage models (LLMs) to that of our (human) participants, finding important\nmisalignment between model and human preferences.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05496v1",
    "published_date": "2024-10-07 21:05:57 UTC",
    "updated_date": "2024-10-07 21:05:57 UTC"
  },
  {
    "arxiv_id": "2410.10863v2",
    "title": "Exploring the Personality Traits of LLMs through Latent Features Steering",
    "authors": [
      "Shu Yang",
      "Shenzhe Zhu",
      "Liang Liu",
      "Lijie Hu",
      "Mengdi Li",
      "Di Wang"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced dialogue systems and\nrole-playing agents through their ability to generate human-like text. While\nprior studies have shown that LLMs can exhibit distinct and consistent\npersonalities, the mechanisms through which these models encode and express\nspecific personality traits remain poorly understood. To address this, we\ninvestigate how various factors, such as cultural norms and environmental\nstressors, encoded within LLMs, shape their personality traits, guided by the\ntheoretical framework of social determinism. Inspired by related work on LLM\ninterpretability, we propose a training-free approach to modify the model's\nbehavior by extracting and steering latent features corresponding to factors\nwithin the model, thereby eliminating the need for retraining. Furthermore, we\nanalyze the implications of these factors for model safety, focusing on their\nimpact through the lens of personality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.10863v2",
    "published_date": "2024-10-07 21:02:34 UTC",
    "updated_date": "2025-02-16 22:19:15 UTC"
  },
  {
    "arxiv_id": "2410.05484v1",
    "title": "Neural Networks Decoded: Targeted and Robust Analysis of Neural Network Decisions via Causal Explanations and Reasoning",
    "authors": [
      "Alec F. Diallo",
      "Vaishak Belle",
      "Paul Patras"
    ],
    "abstract": "Despite their success and widespread adoption, the opaque nature of deep\nneural networks (DNNs) continues to hinder trust, especially in critical\napplications. Current interpretability solutions often yield inconsistent or\noversimplified explanations, or require model changes that compromise\nperformance. In this work, we introduce TRACER, a novel method grounded in\ncausal inference theory designed to estimate the causal dynamics underpinning\nDNN decisions without altering their architecture or compromising their\nperformance. Our approach systematically intervenes on input features to\nobserve how specific changes propagate through the network, affecting internal\nactivations and final outputs. Based on this analysis, we determine the\nimportance of individual features, and construct a high-level causal map by\ngrouping functionally similar layers into cohesive causal nodes, providing a\nstructured and interpretable view of how different parts of the network\ninfluence the decisions. TRACER further enhances explainability by generating\ncounterfactuals that reveal possible model biases and offer contrastive\nexplanations for misclassifications. Through comprehensive evaluations across\ndiverse datasets, we demonstrate TRACER's effectiveness over existing methods\nand show its potential for creating highly compressed yet accurate models,\nillustrating its dual versatility in both understanding and optimizing DNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05484v1",
    "published_date": "2024-10-07 20:44:53 UTC",
    "updated_date": "2024-10-07 20:44:53 UTC"
  },
  {
    "arxiv_id": "2410.05479v1",
    "title": "Ensured: Explanations for Decreasing the Epistemic Uncertainty in Predictions",
    "authors": [
      "Helena Löfström",
      "Tuwe Löfström",
      "Johan Hallberg Szabadvary"
    ],
    "abstract": "This paper addresses a significant gap in explainable AI: the necessity of\ninterpreting epistemic uncertainty in model explanations. Although current\nmethods mainly focus on explaining predictions, with some including\nuncertainty, they fail to provide guidance on how to reduce the inherent\nuncertainty in these predictions. To overcome this challenge, we introduce new\ntypes of explanations that specifically target epistemic uncertainty. These\ninclude ensured explanations, which highlight feature modifications that can\nreduce uncertainty, and categorisation of uncertain explanations\ncounter-potential, semi-potential, and super-potential which explore\nalternative scenarios. Our work emphasises that epistemic uncertainty adds a\ncrucial dimension to explanation quality, demanding evaluation based not only\non prediction probability but also on uncertainty reduction. We introduce a new\nmetric, ensured ranking, designed to help users identify the most reliable\nexplanations by balancing trade-offs between uncertainty, probability, and\ncompeting alternative explanations. Furthermore, we extend the Calibrated\nExplanations method, incorporating tools that visualise how changes in feature\nvalues impact epistemic uncertainty. This enhancement provides deeper insights\ninto model behaviour, promoting increased interpretability and appropriate\ntrust in scenarios involving uncertain predictions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 11 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2410.05479v1",
    "published_date": "2024-10-07 20:21:51 UTC",
    "updated_date": "2024-10-07 20:21:51 UTC"
  },
  {
    "arxiv_id": "2410.05470v2",
    "title": "Image Watermarks are Removable Using Controllable Regeneration from Clean Noise",
    "authors": [
      "Yepeng Liu",
      "Yiren Song",
      "Hai Ci",
      "Yu Zhang",
      "Haofan Wang",
      "Mike Zheng Shou",
      "Yuheng Bu"
    ],
    "abstract": "Image watermark techniques provide an effective way to assert ownership,\ndeter misuse, and trace content sources, which has become increasingly\nessential in the era of large generative models. A critical attribute of\nwatermark techniques is their robustness against various manipulations. In this\npaper, we introduce a watermark removal approach capable of effectively\nnullifying state-of-the-art watermarking techniques. Our primary insight\ninvolves regenerating the watermarked image starting from a clean Gaussian\nnoise via a controllable diffusion model, utilizing the extracted semantic and\nspatial features from the watermarked image. The semantic control adapter and\nthe spatial control network are specifically trained to control the denoising\nprocess towards ensuring image quality and enhancing consistency between the\ncleaned image and the original watermarked image. To achieve a smooth trade-off\nbetween watermark removal performance and image consistency, we further propose\nan adjustable and controllable regeneration scheme. This scheme adds varying\nnumbers of noise steps to the latent representation of the watermarked image,\nfollowed by a controlled denoising process starting from this noisy latent\nrepresentation. As the number of noise steps increases, the latent\nrepresentation progressively approaches clean Gaussian noise, facilitating the\ndesired trade-off. We apply our watermark removal methods across various\nwatermarking techniques, and the results demonstrate that our methods offer\nsuperior visual consistency/quality and enhanced watermark removal performance\ncompared to existing regeneration approaches. Our code is available at\nhttps://github.com/yepengliu/CtrlRegen.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05470v2",
    "published_date": "2024-10-07 20:04:29 UTC",
    "updated_date": "2025-03-02 02:07:21 UTC"
  },
  {
    "arxiv_id": "2410.10862v1",
    "title": "Superficial Safety Alignment Hypothesis",
    "authors": [
      "Jianwei Li",
      "Jung-Eun Kim"
    ],
    "abstract": "As large language models (LLMs) are overwhelmingly more and more integrated\ninto various applications, ensuring they generate safe and aligned responses is\na pressing need. Previous research on alignment has largely focused on general\ninstruction-following but has often overlooked the unique properties and\nchallenges of safety alignment, such as the brittleness of safety mechanisms.\nTo bridge the gap, we propose the Superficial Safety Alignment Hypothesis\n(SSAH), which posits that safety alignment should teach an otherwise unsafe\nmodel to choose the correct reasoning direction - interpreted as a specialized\nbinary classification task - and incorporate a refusal mechanism with multiple\nreserved fallback options. Furthermore, through SSAH, we hypothesize that\nsafety guardrails in LLMs can be established by just a small number of\nessential components. To verify this, we conduct an ablation study and\nsuccessfully identify four types of attribute-critical components in\nsafety-aligned LLMs: Exclusive Safety Unit (ESU), Exclusive Utility Unit (EUU),\nComplex Unit (CU), and Redundant Unit (RU). Our findings show that freezing\ncertain safety-critical components 7.5\\% during fine-tuning allows the model to\nretain its safety attributes while adapting to new tasks. Additionally, we show\nthat leveraging redundant units 20\\% in the pre-trained model as an ``alignment\nbudget'' can effectively minimize the alignment tax while achieving the\nalignment goal. All considered, this paper concludes that the atomic functional\nunit for safety in LLMs is at the neuron level and underscores that safety\nalignment should not be complicated. We believe this work contributes to the\nfoundation of efficient and scalable safety alignment for future LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10862v1",
    "published_date": "2024-10-07 19:53:35 UTC",
    "updated_date": "2024-10-07 19:53:35 UTC"
  },
  {
    "arxiv_id": "2410.05466v1",
    "title": "Herd Mentality in Augmentation -- Not a Good Idea! A Robust Multi-stage Approach towards Deepfake Detection",
    "authors": [
      "Monu",
      "Rohan Raju Dhanakshirur"
    ],
    "abstract": "The rapid increase in deepfake technology has raised significant concerns\nabout digital media integrity. Detecting deepfakes is crucial for safeguarding\ndigital media. However, most standard image classifiers fail to distinguish\nbetween fake and real faces. Our analysis reveals that this failure is due to\nthe model's inability to explicitly focus on the artefacts typically in\ndeepfakes. We propose an enhanced architecture based on the GenConViT model,\nwhich incorporates weighted loss and update augmentation techniques and\nincludes masked eye pretraining. This proposed model improves the F1 score by\n1.71% and the accuracy by 4.34% on the Celeb-DF v2 dataset. The source code for\nour model is available at\nhttps://github.com/Monu-Khicher-1/multi-stage-learning",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05466v1",
    "published_date": "2024-10-07 19:51:46 UTC",
    "updated_date": "2024-10-07 19:51:46 UTC"
  },
  {
    "arxiv_id": "2410.05465v2",
    "title": "On the Expressive Power of Tree-Structured Probabilistic Circuits",
    "authors": [
      "Lang Yin",
      "Han Zhao"
    ],
    "abstract": "Probabilistic circuits (PCs) have emerged as a powerful framework to\ncompactly represent probability distributions for efficient and exact\nprobabilistic inference. It has been shown that PCs with a general directed\nacyclic graph (DAG) structure can be understood as a mixture of exponentially\n(in its height) many components, each of which is a product distribution over\nunivariate marginals. However, existing structure learning algorithms for PCs\noften generate tree-structured circuits or use tree-structured circuits as\nintermediate steps to compress them into DAG-structured circuits. This leads to\nthe intriguing question of whether there exists an exponential gap between DAGs\nand trees for the PC structure. In this paper, we provide a negative answer to\nthis conjecture by proving that, for $n$ variables, there exists a\nquasi-polynomial upper bound $n^{O(\\log n)}$ on the size of an equivalent tree\ncomputing the same probability distribution. On the other hand, we also show\nthat given a depth restriction on the tree, there is a super-polynomial\nseparation between tree and DAG-structured PCs. Our work takes an important\nstep towards understanding the expressive power of tree-structured PCs, and our\ntechniques may be of independent interest in the study of structure learning\nalgorithms for PCs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was accepted to NeurIPS 2024. This version uses a more\n  accurate terminology for a complexity class, and adds a preliminary paragraph\n  on relevant complexity classes",
    "pdf_url": "http://arxiv.org/pdf/2410.05465v2",
    "published_date": "2024-10-07 19:51:30 UTC",
    "updated_date": "2024-10-24 21:15:42 UTC"
  },
  {
    "arxiv_id": "2410.05455v1",
    "title": "Dynamic HumTrans: Humming Transcription Using CNNs and Dynamic Programming",
    "authors": [
      "Shubham Gupta",
      "Isaac Neri Gomez-Sarmiento",
      "Faez Amjed Mezdari",
      "Mirco Ravanelli",
      "Cem Subakan"
    ],
    "abstract": "We propose a novel approach for humming transcription that combines a\nCNN-based architecture with a dynamic programming-based post-processing\nalgorithm, utilizing the recently introduced HumTrans dataset. We identify and\naddress inherent problems with the offset and onset ground truth provided by\nthe dataset, offering heuristics to improve these annotations, resulting in a\ndataset with precise annotations that will aid future research. Additionally,\nwe compare the transcription accuracy of our method against several others,\ndemonstrating state-of-the-art (SOTA) results. All our code and corrected\ndataset is available at\nhttps://github.com/shubham-gupta-30/humming_transcription",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05455v1",
    "published_date": "2024-10-07 19:40:39 UTC",
    "updated_date": "2024-10-07 19:40:39 UTC"
  },
  {
    "arxiv_id": "2410.05450v2",
    "title": "AI-Driven Early Mental Health Screening: Analyzing Selfies of Pregnant Women",
    "authors": [
      "Gustavo A. Basílio",
      "Thiago B. Pereira",
      "Alessandro L. Koerich",
      "Hermano Tavares",
      "Ludmila Dias",
      "Maria das Graças da S. Teixeira",
      "Rafael T. Sousa",
      "Wilian H. Hisatugu",
      "Amanda S. Mota",
      "Anilton S. Garcia",
      "Marco Aurélio K. Galletta",
      "Thiago M. Paixão"
    ],
    "abstract": "Major Depressive Disorder and anxiety disorders affect millions globally,\ncontributing significantly to the burden of mental health issues. Early\nscreening is crucial for effective intervention, as timely identification of\nmental health issues can significantly improve treatment outcomes. Artificial\nintelligence (AI) can be valuable for improving the screening of mental\ndisorders, enabling early intervention and better treatment outcomes. AI-driven\nscreening can leverage the analysis of multiple data sources, including facial\nfeatures in digital images. However, existing methods often rely on controlled\nenvironments or specialized equipment, limiting their broad applicability. This\nstudy explores the potential of AI models for ubiquitous depression-anxiety\nscreening given face-centric selfies. The investigation focuses on high-risk\npregnant patients, a population that is particularly vulnerable to mental\nhealth issues. To cope with limited training data resulting from our clinical\nsetup, pre-trained models were utilized in two different approaches:\nfine-tuning convolutional neural networks (CNNs) originally designed for facial\nexpression recognition and employing vision-language models (VLMs) for\nzero-shot analysis of facial expressions. Experimental results indicate that\nthe proposed VLM-based method significantly outperforms CNNs, achieving an\naccuracy of 77.6%. Although there is significant room for improvement, the\nresults suggest that VLMs can be a promising approach for mental health\nscreening.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This article has been accepted for publication in HEALTHINF25 at the\n  18th International Joint Conference on Biomedical Engineering Systems and\n  Technologies (BIOSTEC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.05450v2",
    "published_date": "2024-10-07 19:34:25 UTC",
    "updated_date": "2025-01-13 13:54:31 UTC"
  },
  {
    "arxiv_id": "2410.11864v1",
    "title": "Shifting the Human-AI Relationship: Toward a Dynamic Relational Learning-Partner Model",
    "authors": [
      "Julia Mossbridge"
    ],
    "abstract": "As artificial intelligence (AI) continues to evolve, the current paradigm of\ntreating AI as a passive tool no longer suffices. As a human-AI team, we\ntogether advocate for a shift toward viewing AI as a learning partner, akin to\na student who learns from interactions with humans. Drawing from\ninterdisciplinary concepts such as ecorithms, order from chaos, and\ncooperation, we explore how AI can evolve and adapt in unpredictable\nenvironments. Arising from these brief explorations, we present two key\nrecommendations: (1) foster ethical, cooperative treatment of AI to benefit\nboth humans and AI, and (2) leverage the inherent heterogeneity between human\nand AI minds to create a synergistic hybrid intelligence. By reframing AI as a\ndynamic partner, a model emerges in which AI systems develop alongside humans,\nlearning from human interactions and feedback loops including reflections on\nteam conversations. Drawing from a transpersonal and interdependent approach to\nconsciousness, we suggest that a \"third mind\" emerges through collaborative\nhuman-AI relationships. Through design interventions such as interactive\nlearning and conversational debriefing and foundational interventions allowing\nAI to model multiple types of minds, we hope to provide a path toward more\nadaptive, ethical, and emotionally healthy human-AI relationships. We believe\nthis dynamic relational learning-partner (DRLP) model for human-AI teaming, if\nenacted carefully, will improve our capacity to address powerful solutions to\nseemingly intractable problems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "91C01",
      "K.4.2; K.4.1"
    ],
    "primary_category": "cs.HC",
    "comment": "White Paper",
    "pdf_url": "http://arxiv.org/pdf/2410.11864v1",
    "published_date": "2024-10-07 19:19:39 UTC",
    "updated_date": "2024-10-07 19:19:39 UTC"
  },
  {
    "arxiv_id": "2410.18085v1",
    "title": "TextureMeDefect: LLM-based Defect Texture Generation for Railway Components on Mobile Devices",
    "authors": [
      "Rahatara Ferdousi",
      "M. Anwar Hossain",
      "Abdulmotaleb El Saddik"
    ],
    "abstract": "Texture image generation has been studied for various applications, including\ngaming and entertainment. However, context-specific realistic texture\ngeneration for industrial applications, such as generating defect textures on\nrailway components, remains unexplored. A mobile-friendly, LLM-based tool that\ngenerates fine-grained defect characteristics offers a solution to the\nchallenge of understanding the impact of defects from actual occurrences. We\nintroduce TextureMeDefect, an innovative tool leveraging an LLM-based\nAI-Inferencing engine. The tool allows users to create realistic defect\ntextures interactively on images of railway components taken with smartphones\nor tablets. We conducted a multifaceted evaluation to assess the relevance of\nthe generated texture, time, and cost in using this tool on iOS and Android\nplatforms. We also analyzed the software usability score (SUS) across three\nscenarios. TextureMeDefect outperformed traditional image generation tools by\ngenerating meaningful textures faster, showcasing the potential of AI-driven\nmobile applications on consumer-grade devices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "6 Pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.18085v1",
    "published_date": "2024-10-07 19:07:08 UTC",
    "updated_date": "2024-10-07 19:07:08 UTC"
  },
  {
    "arxiv_id": "2410.05434v1",
    "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback",
    "authors": [
      "Sanjiban Choudhury",
      "Paloma Sodhi"
    ],
    "abstract": "While large language models (LLMs) show impressive decision-making abilities,\ncurrent methods lack a mechanism for automatic self-improvement from errors\nduring task execution. We propose LEAP, an iterative fine-tuning framework that\ncontinually improves LLM agents using feedback from AI expert teachers. Our key\ninsight is to equip the expert teachers with a privileged state -- information\nthat is available during training but hidden at test time. This allows even\nweak experts to provide precise guidance, significantly improving the student\nagent's performance without access to privileged information at test time. We\nevaluate LEAP on diverse decision-making benchmarks, including text-based games\n(ALFWorld), web navigation (WebShop), and interactive coding (Intercode Bash).\nOur experiments show that LEAP (1) outperforms behavior cloning and ReAct\nbaselines (2) enables weak student models (e.g., Llama3-8B) to exceed the\nperformance of strong teacher models (GPT4-o), and (3) allows weak models to\nself-improve using privileged versions of themselves. We also provide a\ntheoretical analysis showing that LEAP's success hinges on balancing privileged\ninformation with the student's realizability, which we empirically validate.\nOur code is available at https://leap-llm.github.io",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 6 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.05434v1",
    "published_date": "2024-10-07 18:55:53 UTC",
    "updated_date": "2024-10-07 18:55:53 UTC"
  },
  {
    "arxiv_id": "2410.05423v1",
    "title": "Incorporating Talker Identity Aids With Improving Speech Recognition in Adversarial Environments",
    "authors": [
      "Sagarika Alavilli",
      "Annesya Banerjee",
      "Gasser Elbanna",
      "Annika Magaro"
    ],
    "abstract": "Current state-of-the-art speech recognition models are trained to map\nacoustic signals into sub-lexical units. While these models demonstrate\nsuperior performance, they remain vulnerable to out-of-distribution conditions\nsuch as background noise and speech augmentations. In this work, we hypothesize\nthat incorporating speaker representations during speech recognition can\nenhance model robustness to noise. We developed a transformer-based model that\njointly performs speech recognition and speaker identification. Our model\nutilizes speech embeddings from Whisper and speaker embeddings from ECAPA-TDNN,\nwhich are processed jointly to perform both tasks. We show that the joint model\nperforms comparably to Whisper under clean conditions. Notably, the joint model\noutperforms Whisper in high-noise environments, such as with 8-speaker babble\nbackground noise. Furthermore, our joint model excels in handling highly\naugmented speech, including sine-wave and noise-vocoded speech. Overall, these\nresults suggest that integrating voice representations with speech recognition\ncan lead to more robust models under adversarial conditions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05423v1",
    "published_date": "2024-10-07 18:39:59 UTC",
    "updated_date": "2024-10-07 18:39:59 UTC"
  },
  {
    "arxiv_id": "2410.05419v1",
    "title": "Refining Counterfactual Explanations With Joint-Distribution-Informed Shapley Towards Actionable Minimality",
    "authors": [
      "Lei You",
      "Yijun Bian",
      "Lele Cao"
    ],
    "abstract": "Counterfactual explanations (CE) identify data points that closely resemble\nthe observed data but produce different machine learning (ML) model outputs,\noffering critical insights into model decisions. Despite the diverse scenarios,\ngoals and tasks to which they are tailored, existing CE methods often lack\nactionable efficiency because of unnecessary feature changes included within\nthe explanations that are presented to users and stakeholders. We address this\nproblem by proposing a method that minimizes the required feature changes while\nmaintaining the validity of CE, without imposing restrictions on models or CE\nalgorithms, whether instance- or group-based. The key innovation lies in\ncomputing a joint distribution between observed and counterfactual data and\nleveraging it to inform Shapley values for feature attributions (FA). We\ndemonstrate that optimal transport (OT) effectively derives this distribution,\nespecially when the alignment between observed and counterfactual data is\nunclear in used CE methods. Additionally, a counterintuitive finding is\nuncovered: it may be misleading to rely on an exact alignment defined by the CE\ngeneration mechanism in conducting FA. Our proposed method is validated on\nextensive experiments across multiple datasets, showcasing its effectiveness in\nrefining CE towards greater actionable efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05419v1",
    "published_date": "2024-10-07 18:31:19 UTC",
    "updated_date": "2024-10-07 18:31:19 UTC"
  },
  {
    "arxiv_id": "2410.18358v2",
    "title": "Data Publishing in Mechanics and Dynamics: Challenges, Guidelines, and Examples from Engineering Design",
    "authors": [
      "Henrik Ebel",
      "Jan van Delden",
      "Timo Lüddecke",
      "Aditya Borse",
      "Rutwik Gulakala",
      "Marcus Stoffel",
      "Manish Yadav",
      "Merten Stender",
      "Leon Schindler",
      "Kristin Miriam de Payrebrune",
      "Maximilian Raff",
      "C. David Remy",
      "Benedict Röder",
      "Rohit Raj",
      "Tobias Rentschler",
      "Alexander Tismer",
      "Stefan Riedelbauch",
      "Peter Eberhard"
    ],
    "abstract": "Data-based methods have gained increasing importance in engineering,\nespecially but not only driven by successes with deep artificial neural\nnetworks. Success stories are prevalent, e.g., in areas such as data-driven\nmodeling, control and automation, as well as surrogate modeling for accelerated\nsimulation. Beyond engineering, generative and large-language models are\nincreasingly helping with tasks that, previously, were solely associated with\ncreative human processes. Thus, it seems timely to seek\nartificial-intelligence-support for engineering design tasks to automate, help\nwith, or accelerate purpose-built designs of engineering systems, e.g., in\nmechanics and dynamics, where design so far requires a lot of specialized\nknowledge. However, research-wise, compared to established, predominantly\nfirst-principles-based methods, the datasets used for training, validation, and\ntest become an almost inherent part of the overall methodology. Thus, data\npublishing becomes just as important in (data-driven) engineering science as\nappropriate descriptions of conventional methodology in publications in the\npast. This article analyzes the value and challenges of data publishing in\nmechanics and dynamics, in particular regarding engineering design tasks,\nshowing that the latter raise also challenges and considerations not typical in\nfields where data-driven methods have been booming originally. Possible ways to\ndeal with these challenges are discussed and a set of examples from across\ndifferent design problems shows how data publishing can be put into practice.\nThe analysis, discussions, and examples are based on the research experience\nmade in a priority program of the German research foundation focusing on\nresearch on artificially intelligent design assistants in mechanics and\ndynamics.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "cs.ET",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY",
    "comment": "25 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.18358v2",
    "published_date": "2024-10-07 18:26:05 UTC",
    "updated_date": "2024-12-20 12:58:09 UTC"
  },
  {
    "arxiv_id": "2410.05407v1",
    "title": "Improving Predictor Reliability with Selective Recalibration",
    "authors": [
      "Thomas P. Zollo",
      "Zhun Deng",
      "Jake C. Snell",
      "Toniann Pitassi",
      "Richard Zemel"
    ],
    "abstract": "A reliable deep learning system should be able to accurately express its\nconfidence with respect to its predictions, a quality known as calibration. One\nof the most effective ways to produce reliable confidence estimates with a\npre-trained model is by applying a post-hoc recalibration method. Popular\nrecalibration methods like temperature scaling are typically fit on a small\namount of data and work in the model's output space, as opposed to the more\nexpressive feature embedding space, and thus usually have only one or a handful\nof parameters. However, the target distribution to which they are applied is\noften complex and difficult to fit well with such a function. To this end we\npropose \\textit{selective recalibration}, where a selection model learns to\nreject some user-chosen proportion of the data in order to allow the\nrecalibrator to focus on regions of the input space that can be well-captured\nby such a model. We provide theoretical analysis to motivate our algorithm, and\ntest our method through comprehensive experiments on difficult medical imaging\nand zero-shot classification tasks. Our results show that selective\nrecalibration consistently leads to significantly lower calibration error than\na wide range of selection and recalibration baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (07/2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.05407v1",
    "published_date": "2024-10-07 18:17:31 UTC",
    "updated_date": "2024-10-07 18:17:31 UTC"
  },
  {
    "arxiv_id": "2410.05406v2",
    "title": "Synthesizing Interpretable Control Policies through Large Language Model Guided Search",
    "authors": [
      "Carlo Bosio",
      "Mark W. Mueller"
    ],
    "abstract": "The combination of Large Language Models (LLMs), systematic evaluation, and\nevolutionary algorithms has enabled breakthroughs in combinatorial optimization\nand scientific discovery. We propose to extend this powerful combination to the\ncontrol of dynamical systems, generating interpretable control policies capable\nof complex behaviors. With our novel method, we represent control policies as\nprograms in standard languages like Python. We evaluate candidate controllers\nin simulation and evolve them using a pre-trained LLM. Unlike conventional\nlearning-based control techniques, which rely on black-box neural networks to\nencode control policies, our approach enhances transparency and\ninterpretability. We still take advantage of the power of large AI models, but\nonly at the policy design phase, ensuring that all system components remain\ninterpretable and easily verifiable at runtime. Additionally, the use of\nstandard programming languages makes it straightforward for humans to finetune\nor adapt the controllers based on their expertise and intuition. We illustrate\nour method through its application to the synthesis of an interpretable control\npolicy for the pendulum swing-up and the ball in cup tasks. We make the code\navailable at\nhttps://github.com/muellerlab/synthesizing_interpretable_control_policies.git.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 7 figures, conference paper",
    "pdf_url": "http://arxiv.org/pdf/2410.05406v2",
    "published_date": "2024-10-07 18:12:20 UTC",
    "updated_date": "2025-03-17 21:49:35 UTC"
  },
  {
    "arxiv_id": "2410.05401v2",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "abstract": "Climate change communication on social media increasingly employs\nmicrotargeting strategies to effectively reach and influence specific\ndemographic groups. This study presents a post-hoc analysis of microtargeting\npractices within climate campaigns by leveraging large language models (LLMs)\nto examine Facebook advertisements. Our analysis focuses on two key aspects:\ndemographic targeting and fairness. We evaluate the ability of LLMs to\naccurately predict the intended demographic targets, such as gender and age\ngroup, achieving an overall accuracy of 88.55%. Furthermore, we instruct the\nLLMs to generate explanations for their classifications, providing transparent\nreasoning behind each decision. These explanations reveal the specific thematic\nelements used to engage different demographic segments, highlighting distinct\nstrategies tailored to various audiences. Our findings show that young adults\nare primarily targeted through messages emphasizing activism and environmental\nconsciousness, while women are engaged through themes related to caregiving\nroles and social advocacy. In addition to evaluating the effectiveness of LLMs\nin detecting microtargeted messaging, we conduct a comprehensive fairness\nanalysis to identify potential biases in model predictions. Our findings\nindicate that while LLMs perform well overall, certain biases exist,\nparticularly in the classification of senior citizens and male audiences. By\nshowcasing the efficacy of LLMs in dissecting and explaining targeted\ncommunication strategies and by highlighting fairness concerns, this study\nprovides a valuable framework for future research aimed at enhancing\ntransparency, accountability, and inclusivity in social media-driven climate\ncampaigns.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05401v2",
    "published_date": "2024-10-07 18:07:56 UTC",
    "updated_date": "2025-04-23 23:04:25 UTC"
  },
  {
    "arxiv_id": "2410.05269v1",
    "title": "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models",
    "authors": [
      "Fei Wang",
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Rahul Gupta",
      "Kai-Wei Chang",
      "Aram Galstyan"
    ],
    "abstract": "Data is a crucial element in large language model (LLM) alignment. Recent\nstudies have explored using LLMs for efficient data collection. However,\nLLM-generated data often suffers from quality issues, with underrepresented or\nabsent aspects and low-quality datapoints. To address these problems, we\npropose Data Advisor, an enhanced LLM-based method for generating data that\ntakes into account the characteristics of the desired dataset. Starting from a\nset of pre-defined principles in hand, Data Advisor monitors the status of the\ngenerated data, identifies weaknesses in the current dataset, and advises the\nnext iteration of data generation accordingly. Data Advisor can be easily\nintegrated into existing data generation methods to enhance data quality and\ncoverage. Experiments on safety alignment of three representative LLMs (i.e.,\nMistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in\nenhancing model safety against various fine-grained safety issues without\nsacrificing model utility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/DataAdvisor/",
    "pdf_url": "http://arxiv.org/pdf/2410.05269v1",
    "published_date": "2024-10-07 17:59:58 UTC",
    "updated_date": "2024-10-07 17:59:58 UTC"
  },
  {
    "arxiv_id": "2410.05263v1",
    "title": "Regression Conformal Prediction under Bias",
    "authors": [
      "Matt Y. Cheung",
      "Tucker J. Netherton",
      "Laurence E. Court",
      "Ashok Veeraraghavan",
      "Guha Balakrishnan"
    ],
    "abstract": "Uncertainty quantification is crucial to account for the imperfect\npredictions of machine learning algorithms for high-impact applications.\nConformal prediction (CP) is a powerful framework for uncertainty\nquantification that generates calibrated prediction intervals with valid\ncoverage. In this work, we study how CP intervals are affected by bias - the\nsystematic deviation of a prediction from ground truth values - a phenomenon\nprevalent in many real-world applications. We investigate the influence of bias\non interval lengths of two different types of adjustments -- symmetric\nadjustments, the conventional method where both sides of the interval are\nadjusted equally, and asymmetric adjustments, a more flexible method where the\ninterval can be adjusted unequally in positive or negative directions. We\npresent theoretical and empirical analyses characterizing how symmetric and\nasymmetric adjustments impact the \"tightness\" of CP intervals for regression\ntasks. Specifically for absolute residual and quantile-based non-conformity\nscores, we prove: 1) the upper bound of symmetrically adjusted interval lengths\nincreases by $2|b|$ where $b$ is a globally applied scalar value representing\nbias, 2) asymmetrically adjusted interval lengths are not affected by bias, and\n3) conditions when asymmetrically adjusted interval lengths are guaranteed to\nbe smaller than symmetric ones. Our analyses suggest that even if predictions\nexhibit significant drift from ground truth values, asymmetrically adjusted\nintervals are still able to maintain the same tightness and validity of\nintervals as if the drift had never happened, while symmetric ones\nsignificantly inflate the lengths. We demonstrate our theoretical results with\ntwo real-world prediction tasks: sparse-view computed tomography (CT)\nreconstruction and time-series weather forecasting. Our work paves the way for\nmore bias-robust machine learning systems.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "17 pages, 6 figures, code available at:\n  https://github.com/matthewyccheung/conformal-metric",
    "pdf_url": "http://arxiv.org/pdf/2410.05263v1",
    "published_date": "2024-10-07 17:59:09 UTC",
    "updated_date": "2024-10-07 17:59:09 UTC"
  },
  {
    "arxiv_id": "2410.05261v1",
    "title": "TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens",
    "authors": [
      "Ya-Qi Yu",
      "Minghui Liao",
      "Jiwen Zhang",
      "Jihao Wu"
    ],
    "abstract": "Reading dense text and locating objects within images are fundamental\nabilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.\nPrevious LVLMs, including superior proprietary models like GPT-4o, have\nstruggled to excel in both tasks simultaneously. Moreover, previous LVLMs with\nfine-grained perception cost thousands of tokens per image, making them\nresource-intensive. We present TextHawk2, a bilingual LVLM featuring efficient\nfine-grained perception and demonstrating cutting-edge performance across\ngeneral-purpose, OCR, and grounding tasks with 16 times fewer image tokens.\nCritical improvements include: (1) Token Compression: Building on the efficient\narchitecture of its predecessor, TextHawk2 significantly reduces the number of\ntokens per image by 16 times, facilitating training and deployment of the\nTextHawk series with minimal resources. (2) Visual Encoder Reinforcement: We\nenhance the visual encoder through LVLM co-training, unlocking its potential\nfor previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:\nWe maintain a comparable scale of 100 million samples while diversifying the\nsources of pre-training data. We assess TextHawk2 across multiple benchmarks,\nwhere it consistently delivers superior performance and outperforms\nclosed-source models of similar scale, such as achieving 78.4% accuracy on\nOCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%\naccuracy@0.5 on RefCOCOg-test.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05261v1",
    "published_date": "2024-10-07 17:58:35 UTC",
    "updated_date": "2024-10-07 17:58:35 UTC"
  },
  {
    "arxiv_id": "2410.05364v1",
    "title": "Diffusion Model Predictive Control",
    "authors": [
      "Guangyao Zhou",
      "Sivaramakrishnan Swaminathan",
      "Rajkumar Vasudeva Raju",
      "J. Swaroop Guntupalli",
      "Wolfgang Lehrach",
      "Joseph Ortiz",
      "Antoine Dedieu",
      "Miguel Lázaro-Gredilla",
      "Kevin Murphy"
    ],
    "abstract": "We propose Diffusion Model Predictive Control (D-MPC), a novel MPC approach\nthat learns a multi-step action proposal and a multi-step dynamics model, both\nusing diffusion models, and combines them for use in online MPC. On the popular\nD4RL benchmark, we show performance that is significantly better than existing\nmodel-based offline planning methods using MPC and competitive with\nstate-of-the-art (SOTA) model-based and model-free reinforcement learning\nmethods. We additionally illustrate D-MPC's ability to optimize novel reward\nfunctions at run time and adapt to novel dynamics, and highlight its advantages\ncompared to existing diffusion-based planning baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.05364v1",
    "published_date": "2024-10-07 17:56:47 UTC",
    "updated_date": "2024-10-07 17:56:47 UTC"
  },
  {
    "arxiv_id": "2410.05254v1",
    "title": "GLEE: A Unified Framework and Benchmark for Language-based Economic Environments",
    "authors": [
      "Eilam Shapira",
      "Omer Madmon",
      "Itamar Reinman",
      "Samuel Joseph Amouyal",
      "Roi Reichart",
      "Moshe Tennenholtz"
    ],
    "abstract": "Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? Can they mimic\nhuman behavior? Do they tend to reach an efficient and fair outcome? What is\nthe role of natural language in the strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. While the ML community has\nbeen exploring the potential of LLMs in such multi-agent setups, varying\nassumptions, design choices and evaluation criteria across studies make it\ndifficult to draw robust and meaningful conclusions. To address this, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents to human players in various economic contexts;\n(ii) evaluate agents in both individual and collective performance measures;\nand (iii) quantify the effect of the economic characteristics of the\nenvironments on the behavior of agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05254v1",
    "published_date": "2024-10-07 17:55:35 UTC",
    "updated_date": "2024-10-07 17:55:35 UTC"
  },
  {
    "arxiv_id": "2410.05252v1",
    "title": "Causal Micro-Narratives",
    "authors": [
      "Mourad Heddaya",
      "Qingcheng Zeng",
      "Chenhao Tan",
      "Rob Voigt",
      "Alexander Zentefis"
    ],
    "abstract": "We present a novel approach to classify causal micro-narratives from text.\nThese narratives are sentence-level explanations of the cause(s) and/or\neffect(s) of a target subject. The approach requires only a subject-specific\nontology of causes and effects, and we demonstrate it with an application to\ninflation narratives. Using a human-annotated dataset spanning historical and\ncontemporary US news articles for training, we evaluate several large language\nmodels (LLMs) on this multi-label classification task. The best-performing\nmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative\ndetection and 0.71 on narrative classification. Comprehensive error analysis\nreveals challenges arising from linguistic ambiguity and highlights how model\nerrors often mirror human annotator disagreements. This research establishes a\nframework for extracting causal micro-narratives from real-world data, with\nwide-ranging applications to social science research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Workshop on Narrative Understanding",
    "pdf_url": "http://arxiv.org/pdf/2410.05252v1",
    "published_date": "2024-10-07 17:55:10 UTC",
    "updated_date": "2024-10-07 17:55:10 UTC"
  },
  {
    "arxiv_id": "2410.05248v2",
    "title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe",
    "authors": [
      "Yuxin Xiao",
      "Shujian Zhang",
      "Wenxuan Zhou",
      "Marzyeh Ghassemi",
      "Sanqiang Zhao"
    ],
    "abstract": "To acquire instruction-following capabilities, large language models (LLMs)\nundergo instruction tuning, where they are trained on instruction-response\npairs using next-token prediction (NTP). Efforts to improve instruction tuning\noften focus on higher-quality supervised fine-tuning (SFT) datasets, typically\nrequiring data filtering with proprietary LLMs or human annotation. In this\npaper, we take a different approach by proposing SFTMix, a novel Mixup-based\nrecipe that elevates LLM instruction tuning beyond the conventional NTP\nparadigm, without relying on well-curated datasets. Observing that LLMs exhibit\nuneven confidence across the semantic representation space, we argue that\nexamples with different confidence levels should play distinct roles in\ninstruction tuning--confident data is prone to overfitting, while unconfident\ndata is harder to generalize. Based on this insight, SFTMix leverages training\ndynamics to identify examples with varying confidence levels, interpolates them\nto bridge the confidence gap, and applies a Mixup-based regularization to\nsupport learning on these additional, interpolated examples. By propagating\nsupervision signals across confidence regions and encouraging linear behavior\nbetween them, SFTMix mitigates overfitting in confident examples while\nenhancing generalization in unconfident ones. We demonstrate the effectiveness\nof SFTMix in both instruction-following and healthcare-specific SFT tasks, with\nconsistent improvements across LLM families and SFT datasets of varying sizes\nand qualities. Extensive analyses across six directions highlight SFTMix's\ncompatibility with data selection, adaptability to compute-constrained\nscenarios, and scalability to broader applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05248v2",
    "published_date": "2024-10-07 17:52:21 UTC",
    "updated_date": "2025-02-16 01:41:33 UTC"
  },
  {
    "arxiv_id": "2410.05243v2",
    "title": "Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents",
    "authors": [
      "Boyu Gou",
      "Ruohan Wang",
      "Boyuan Zheng",
      "Yanan Xie",
      "Cheng Chang",
      "Yiheng Shu",
      "Huan Sun",
      "Yu Su"
    ],
    "abstract": "Multimodal large language models (MLLMs) are transforming the capabilities of\ngraphical user interface (GUI) agents, facilitating their transition from\ncontrolled simulations to complex, real-world applications across various\nplatforms. However, the effectiveness of these agents hinges on the robustness\nof their grounding capability. Current GUI agents predominantly utilize\ntext-based representations such as HTML or accessibility trees, which, despite\ntheir utility, often introduce noise, incompleteness, and increased\ncomputational overhead. In this paper, we advocate a human-like embodiment for\nGUI agents that perceive the environment entirely visually and directly perform\npixel-level operations on the GUI. The key is visual grounding models that can\naccurately map diverse referring expressions of GUI elements to their\ncoordinates on the GUI across different platforms. We show that a simple\nrecipe, which includes web-based synthetic data and slight adaptation of the\nLLaVA architecture, is surprisingly effective for training such visual\ngrounding models. We collect the largest dataset for GUI visual grounding so\nfar, containing 10M GUI elements and their referring expressions over 1.3M\nscreenshots, and use it to train UGround, a strong universal visual grounding\nmodel for GUI agents. Empirical results on six benchmarks spanning three\ncategories (grounding, offline agent, and online agent) show that 1) UGround\nsubstantially outperforms existing visual grounding models for GUI agents, by\nup to 20% absolute, and 2) agents with UGround outperform state-of-the-art\nagents, despite the fact that existing agents use additional text-based input\nwhile ours only uses visual perception. These results provide strong support\nfor the feasibility and promises of GUI agents that navigate the digital world\nas humans do.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2410.05243v2",
    "published_date": "2024-10-07 17:47:50 UTC",
    "updated_date": "2025-03-03 18:39:16 UTC"
  },
  {
    "arxiv_id": "2410.05362v2",
    "title": "LLMs Are In-Context Bandit Reinforcement Learners",
    "authors": [
      "Giovanni Monea",
      "Antoine Bosselut",
      "Kianté Brantley",
      "Yoav Artzi"
    ],
    "abstract": "Large Language Models (LLMs) excel at in-context learning (ICL), a supervised\nlearning technique that relies on adding annotated examples to the model\ncontext. We investigate a contextual bandit version of in-context reinforcement\nlearning (ICRL), where models learn in-context, online, from external reward,\ninstead of supervised data. We show that LLMs effectively demonstrate such\nlearning, and provide a detailed study of the phenomena, experimenting with\nchallenging classification tasks and models of sizes from 500M to 70B\nparameters. This includes identifying and addressing the instability of the\nprocess, demonstrating learning with both semantic and abstract labels, and\nshowing scaling trends. Our findings highlight ICRL capabilities in LLMs, while\nalso underscoring fundamental limitations in their implicit reasoning about\nerrors.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05362v2",
    "published_date": "2024-10-07 17:45:00 UTC",
    "updated_date": "2025-01-31 18:58:24 UTC"
  },
  {
    "arxiv_id": "2410.05235v2",
    "title": "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures",
    "authors": [
      "Ekaterina Sviridova",
      "Anar Yeginbergen",
      "Ainara Estarrona",
      "Elena Cabrio",
      "Serena Villata",
      "Rodrigo Agerri"
    ],
    "abstract": "Explaining Artificial Intelligence (AI) decisions is a major challenge\nnowadays in AI, in particular when applied to sensitive scenarios like medicine\nand law. However, the need to explain the rationale behind decisions is a main\nissue also for human-based deliberation as it is important to justify\n\\textit{why} a certain decision has been taken. Resident medical doctors for\ninstance are required not only to provide a (possibly correct) diagnosis, but\nalso to explain how they reached a certain conclusion. Developing new tools to\naid residents to train their explanation skills is therefore a central\nobjective of AI in education. In this paper, we follow this direction, and we\npresent, to the best of our knowledge, the first multilingual dataset for\nMedical Question Answering where correct and incorrect diagnoses for a clinical\ncase are enriched with a natural language explanation written by doctors. These\nexplanations have been manually annotated with argument components (i.e.,\npremise, claim) and argument relations (i.e., attack, support), resulting in\nthe Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases\nin four languages (English, Spanish, French, Italian) with explanations, where\nwe annotated 5021 claims, 2313 premises, 2431 support relations, and 1106\nattack relations. We conclude by showing how competitive baselines perform over\nthis challenging dataset for the argument mining task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.05235v2",
    "published_date": "2024-10-07 17:41:45 UTC",
    "updated_date": "2024-10-08 13:12:04 UTC"
  },
  {
    "arxiv_id": "2410.05233v1",
    "title": "SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised Contrastive Learning",
    "authors": [
      "Taha Bouhsine",
      "Imad El Aaroussi",
      "Atik Faysal",
      "Wang Huaxia"
    ],
    "abstract": "We introduce a novel anchor-free contrastive learning (AFCL) method\nleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach\nminimizes a semi-metric discriminative loss function that simultaneously\noptimizes two key objectives: reducing the distance and orthogonality between\nembeddings of similar inputs while maximizing these metrics for dissimilar\ninputs, facilitating more fine-grained contrastive learning. The AFCL method,\npowered by SimO loss, creates a fiber bundle topological structure in the\nembedding space, forming class-specific, internally cohesive yet orthogonal\nneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,\nproviding visualizations that demonstrate the impact of SimO loss on the\nembedding space. Our results illustrate the formation of distinct, orthogonal\nclass neighborhoods, showcasing the method's ability to create well-structured\nembeddings that balance class separation with intra-class variability. This\nwork opens new avenues for understanding and leveraging the geometric\nproperties of learned representations in various machine learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05233v1",
    "published_date": "2024-10-07 17:41:10 UTC",
    "updated_date": "2024-10-07 17:41:10 UTC"
  },
  {
    "arxiv_id": "2410.11863v1",
    "title": "ChatVis: Automating Scientific Visualization with a Large Language Model",
    "authors": [
      "Tanwi Mallick",
      "Orcun Yildiz",
      "David Lenz",
      "Tom Peterka"
    ],
    "abstract": "We develop an iterative assistant we call ChatVis that can synthetically\ngenerate Python scripts for data analysis and visualization using a large\nlanguage model (LLM). The assistant allows a user to specify the operations in\nnatural language, attempting to generate a Python script for the desired\noperations, prompting the LLM to revise the script as needed until it executes\ncorrectly. The iterations include an error detection and correction mechanism\nthat extracts error messages from the execution of the script and subsequently\nprompts LLM to correct the error. Our method demonstrates correct execution on\nfive canonical visualization scenarios, comparing results with ground truth. We\nalso compared our results with scripts generated by several other LLMs without\nany assistance. In every instance, ChatVis successfully generated the correct\nscript, whereas the unassisted LLMs failed to do so. The code is available on\nGitHub: https://github.com/tanwimallick/ChatVis/.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11863v1",
    "published_date": "2024-10-07 17:37:59 UTC",
    "updated_date": "2024-10-07 17:37:59 UTC"
  },
  {
    "arxiv_id": "2410.05229v1",
    "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models",
    "authors": [
      "Iman Mirzadeh",
      "Keivan Alizadeh",
      "Hooman Shahrokhi",
      "Oncel Tuzel",
      "Samy Bengio",
      "Mehrdad Farajtabar"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.05229v1",
    "published_date": "2024-10-07 17:36:37 UTC",
    "updated_date": "2024-10-07 17:36:37 UTC"
  },
  {
    "arxiv_id": "2410.05210v1",
    "title": "Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality",
    "authors": [
      "Youngtaek Oh",
      "Jae Won Cho",
      "Dong-Jin Kim",
      "In So Kweon",
      "Junmo Kim"
    ],
    "abstract": "In this paper, we propose a new method to enhance compositional understanding\nin pre-trained vision and language models (VLMs) without sacrificing\nperformance in zero-shot multi-modal tasks. Traditional fine-tuning approaches\noften improve compositional reasoning at the cost of degrading multi-modal\ncapabilities, primarily due to the use of global hard negative (HN) loss, which\ncontrasts global representations of images and texts. This global HN loss\npushes HN texts that are highly similar to the original ones, damaging the\nmodel's multi-modal representations. To overcome this limitation, we propose\nFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard\nnegative loss and selective calibrated regularization. These innovations\nprovide fine-grained negative supervision while preserving the model's\nrepresentational integrity. Our extensive evaluations across diverse benchmarks\nfor both compositionality and multi-modal tasks show that FSC-CLIP not only\nachieves compositionality on par with state-of-the-art models but also retains\nstrong multi-modal capabilities. Code is available at:\nhttps://github.com/ytaek-oh/fsc-clip.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "EMNLP 2024 (Long, Main). Project page:\n  https://ytaek-oh.github.io/fsc-clip",
    "pdf_url": "http://arxiv.org/pdf/2410.05210v1",
    "published_date": "2024-10-07 17:16:20 UTC",
    "updated_date": "2024-10-07 17:16:20 UTC"
  },
  {
    "arxiv_id": "2410.05203v2",
    "title": "Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality",
    "authors": [
      "Ge Ya Luo",
      "Gian Mario Favero",
      "Zhi Hao Luo",
      "Alexia Jolicoeur-Martineau",
      "Christopher Pal"
    ],
    "abstract": "The Fr\\'echet Video Distance (FVD) is a widely adopted metric for evaluating\nvideo generation distribution quality. However, its effectiveness relies on\ncritical assumptions. Our analysis reveals three significant limitations: (1)\nthe non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the\ninsensitivity of I3D features to temporal distortions; (3) the impractical\nsample sizes required for reliable estimation. These findings undermine FVD's\nreliability and show that FVD falls short as a standalone metric for video\ngeneration evaluation. After extensive analysis of a wide range of metrics and\nbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based on\nfeatures derived from a Joint Embedding Predictive Architecture, measured using\nMaximum Mean Discrepancy with polynomial kernel. Our experiments on multiple\nopen-source datasets show clear evidence that it is a superior alternative to\nthe widely used FVD metric, requiring only 16% of the samples to reach its\nsteady value, while increasing alignment with human evaluation by 34%, on\naverage.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05203v2",
    "published_date": "2024-10-07 17:07:21 UTC",
    "updated_date": "2024-10-08 17:46:12 UTC"
  },
  {
    "arxiv_id": "2410.05361v1",
    "title": "RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction",
    "authors": [
      "Yuwei Zhang",
      "Tong Xia",
      "Aaqib Saeed",
      "Cecilia Mascolo"
    ],
    "abstract": "The high incidence and mortality rates associated with respiratory diseases\nunderscores the importance of early screening. Machine learning models can\nautomate clinical consultations and auscultation, offering vital support in\nthis area. However, the data involved, spanning demographics, medical history,\nsymptoms, and respiratory audio, are heterogeneous and complex. Existing\napproaches are insufficient and lack generalizability, as they typically rely\non limited training data, basic fusion techniques, and task-specific models. In\nthis paper, we propose RespLLM, a novel multimodal large language model (LLM)\nframework that unifies text and audio representations for respiratory health\nprediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs\nand enables effective audio-text fusion through cross-modal attentions.\nInstruction tuning is employed to integrate diverse data from multiple sources,\nensuring generalizability and versatility of the model. Experiments on five\nreal-world datasets demonstrate that RespLLM outperforms leading baselines by\nan average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates\nzero-shot predictions for new tasks. Our work lays the foundation for\nmultimodal models that can perceive, listen to, and understand heterogeneous\ndata, paving the way for scalable respiratory health diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05361v1",
    "published_date": "2024-10-07 17:06:11 UTC",
    "updated_date": "2024-10-07 17:06:11 UTC"
  },
  {
    "arxiv_id": "2410.19741v1",
    "title": "Tourism destination events classifier based on artificial intelligence techniques",
    "authors": [
      "Miguel Camacho-Ruiz",
      "Ramón Alberto Carrasco",
      "Gema Fernández-Avilés",
      "Antonio LaTorre"
    ],
    "abstract": "Identifying client needs to provide optimal services is crucial in tourist\ndestination management. The events held in tourist destinations may help to\nmeet those needs and thus contribute to tourist satisfaction. As with product\nmanagement, the creation of hierarchical catalogs to classify those events can\naid event management. The events that can be found on the internet are listed\nin dispersed, heterogeneous sources, which makes direct classification a\ndifficult, time-consuming task. The main aim of this work is to create a novel\nprocess for automatically classifying an eclectic variety of tourist events\nusing a hierarchical taxonomy, which can be applied to support tourist\ndestination management. Leveraging data science methods such as CRISP-DM,\nsupervised machine learning, and natural language processing techniques, the\nautomatic classification process proposed here allows the creation of a\nnormalized catalog across very different geographical regions. Therefore, we\ncan build catalogs with consistent filters, allowing users to find events\nregardless of the event categories assigned at source, if any. This is very\nvaluable for companies that offer this kind of information across multiple\nregions, such as airlines, travel agencies or hotel chains. Ultimately, this\ntool has the potential to revolutionize the way companies and end users\ninteract with tourist events information.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "q-fin.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19741v1",
    "published_date": "2024-10-07 16:54:51 UTC",
    "updated_date": "2024-10-07 16:54:51 UTC"
  },
  {
    "arxiv_id": "2410.17272v1",
    "title": "Military Applications of Machine Learning: A Bibliometric Perspective",
    "authors": [
      "José Javier Galán",
      "Ramón Alberto Carrasco",
      "Antonio LaTorre"
    ],
    "abstract": "The military environment generates a large amount of data of great\nimportance, which makes necessary the use of machine learning for its\nprocessing. Its ability to learn and predict possible scenarios by analyzing\nthe huge volume of information generated provides automatic learning and\ndecision support. This paper aims to present a model of a machine learning\narchitecture applied to a military organization, carried out and supported by a\nbibliometric study applied to an architecture model of a nonmilitary\norganization. For this purpose, a bibliometric analysis up to the year 2021 was\ncarried out, making a strategic diagram and interpreting the results. The\ninformation used has been extracted from one of the main databases widely\naccepted by the scientific community, ISI WoS. No direct military sources were\nused. This work is divided into five parts: the study of previous research\nrelated to machine learning in the military world; the explanation of our\nresearch methodology using the SciMat, Excel and VosViewer tools; the use of\nthis methodology based on data mining, preprocessing, cluster normalization, a\nstrategic diagram and the analysis of its results to investigate machine\nlearning in the military context; based on these results, a conceptual\narchitecture of the practical use of ML in the military context is drawn up;\nand, finally, we present the conclusions, where we will see the most important\nareas and the latest advances in machine learning applied, in this case, to a\nmilitary environment, to analyze a large set of data, providing utility,\nmachine learning and decision support.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17272v1",
    "published_date": "2024-10-07 16:54:40 UTC",
    "updated_date": "2024-10-07 16:54:40 UTC"
  },
  {
    "arxiv_id": "2410.05191v1",
    "title": "LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation",
    "authors": [
      "Zhijie Wang",
      "Zhehua Zhou",
      "Jiayang Song",
      "Yuheng Huang",
      "Zhan Shu",
      "Lei Ma"
    ],
    "abstract": "Building on the advancements of Large Language Models (LLMs) and Vision\nLanguage Models (VLMs), recent research has introduced Vision-Language-Action\n(VLA) models as an integrated solution for robotic manipulation tasks. These\nmodels take camera images and natural language task instructions as input and\ndirectly generate control actions for robots to perform specified tasks,\ngreatly improving both decision-making capabilities and interaction with human\nusers. However, the data-driven nature of VLA models, combined with their lack\nof interpretability, makes the assurance of their effectiveness and robustness\na challenging task. This highlights the need for a reliable testing and\nevaluation platform. For this purpose, in this work, we propose LADEV, a\ncomprehensive and efficient platform specifically designed for evaluating VLA\nmodels. We first present a language-driven approach that automatically\ngenerates simulation environments from natural language inputs, mitigating the\nneed for manual adjustments and significantly improving testing efficiency.\nThen, to further assess the influence of language input on the VLA models, we\nimplement a paraphrase mechanism that produces diverse natural language task\ninstructions for testing. Finally, to expedite the evaluation process, we\nintroduce a batch-style method for conducting large-scale testing of VLA\nmodels. Using LADEV, we conducted experiments on several state-of-the-art VLA\nmodels, demonstrating its effectiveness as a tool for evaluating these models.\nOur results showed that LADEV not only enhances testing efficiency but also\nestablishes a solid baseline for evaluating VLA models, paving the way for the\ndevelopment of more intelligent and advanced robotic systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.05191v1",
    "published_date": "2024-10-07 16:49:16 UTC",
    "updated_date": "2024-10-07 16:49:16 UTC"
  },
  {
    "arxiv_id": "2410.05183v1",
    "title": "Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics",
    "authors": [
      "Stefano Perrella",
      "Lorenzo Proietti",
      "Pere-Lluís Huguet Cabot",
      "Edoardo Barba",
      "Roberto Navigli"
    ],
    "abstract": "Machine Translation (MT) evaluation metrics assess translation quality\nautomatically. Recently, researchers have employed MT metrics for various new\nuse cases, such as data filtering and translation re-ranking. However, most MT\nmetrics return assessments as scalar scores that are difficult to interpret,\nposing a challenge to making informed design choices. Moreover, MT metrics'\ncapabilities have historically been evaluated using correlation with human\njudgment, which, despite its efficacy, falls short of providing intuitive\ninsights into metric performance, especially in terms of new metric use cases.\nTo address these issues, we introduce an interpretable evaluation framework for\nMT metrics. Within this framework, we evaluate metrics in two scenarios that\nserve as proxies for the data filtering and translation re-ranking use cases.\nFurthermore, by measuring the performance of MT metrics using Precision,\nRecall, and F-score, we offer clearer insights into their capabilities than\ncorrelation with human judgments. Finally, we raise concerns regarding the\nreliability of manually curated data following the Direct Assessments+Scalar\nQuality Metrics (DA+SQM) guidelines, reporting a notably low agreement with\nMultidimensional Quality Metrics (MQM) annotations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 Main Conference. 26 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.05183v1",
    "published_date": "2024-10-07 16:42:10 UTC",
    "updated_date": "2024-10-07 16:42:10 UTC"
  },
  {
    "arxiv_id": "2410.05182v1",
    "title": "MARs: Multi-view Attention Regularizations for Patch-based Feature Recognition of Space Terrain",
    "authors": [
      "Timothy Chase Jr",
      "Karthik Dantu"
    ],
    "abstract": "The visual detection and tracking of surface terrain is required for\nspacecraft to safely land on or navigate within close proximity to celestial\nobjects. Current approaches rely on template matching with pre-gathered\npatch-based features, which are expensive to obtain and a limiting factor in\nperceptual capability. While recent literature has focused on in-situ detection\nmethods to enhance navigation and operational autonomy, robust description is\nstill needed. In this work, we explore metric learning as the lightweight\nfeature description mechanism and find that current solutions fail to address\ninter-class similarity and multi-view observational geometry. We attribute this\nto the view-unaware attention mechanism and introduce Multi-view Attention\nRegularizations (MARs) to constrain the channel and spatial attention across\nmultiple feature views, regularizing the what and where of attention focus. We\nthoroughly analyze many modern metric learning losses with and without MARs and\ndemonstrate improved terrain-feature recognition performance by upwards of 85%.\nWe additionally introduce the Luna-1 dataset, consisting of Moon crater\nlandmarks and reference navigation frames from NASA mission data to support\nfuture research in this difficult task. Luna-1 and source code are publicly\navailable at https://droneslab.github.io/mars/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024. Project page available at\n  https://droneslab.github.io/mars/",
    "pdf_url": "http://arxiv.org/pdf/2410.05182v1",
    "published_date": "2024-10-07 16:41:45 UTC",
    "updated_date": "2024-10-07 16:41:45 UTC"
  },
  {
    "arxiv_id": "2410.05167v2",
    "title": "Presto! Distilling Steps and Layers for Accelerating Music Generation",
    "authors": [
      "Zachary Novack",
      "Ge Zhu",
      "Jonah Casebeer",
      "Julian McAuley",
      "Taylor Berg-Kirkpatrick",
      "Nicholas J. Bryan"
    ],
    "abstract": "Despite advances in diffusion-based text-to-music (TTM) methods, efficient,\nhigh-quality generation remains a challenge. We introduce Presto!, an approach\nto inference acceleration for score-based diffusion transformers via reducing\nboth sampling steps and cost per step. To reduce steps, we develop a new\nscore-based distribution matching distillation (DMD) method for the EDM-family\nof diffusion models, the first GAN-based distillation method for TTM. To reduce\nthe cost per step, we develop a simple, but powerful improvement to a recent\nlayer distillation method that improves learning via better preserving hidden\nstate variance. Finally, we combine our step and layer distillation methods\ntogether for a dual-faceted approach. We evaluate our step and layer\ndistillation methods independently and show each yield best-in-class\nperformance. Our combined distillation method can generate high-quality outputs\nwith improved diversity, accelerating our base model by 10-18x (230/435ms\nlatency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --\nthe fastest high-quality TTM to our knowledge. Sound examples can be found at\nhttps://presto-music.github.io/web/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted as Spotlight at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05167v2",
    "published_date": "2024-10-07 16:24:18 UTC",
    "updated_date": "2025-04-16 17:37:06 UTC"
  },
  {
    "arxiv_id": "2410.05160v3",
    "title": "VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks",
    "authors": [
      "Ziyan Jiang",
      "Rui Meng",
      "Xinyi Yang",
      "Semih Yavuz",
      "Yingbo Zhou",
      "Wenhu Chen"
    ],
    "abstract": "Embedding models have been crucial in enabling various downstream tasks such\nas semantic similarity, information retrieval, and clustering. Recently, there\nhas been a surge of interest in developing universal text embedding models that\ncan generalize across tasks (e.g., MTEB). However, progress in learning\nuniversal multimodal embedding models has been relatively slow despite its\nimportance and practicality. In this work, we aim to explore the potential for\nbuilding universal embeddings capable of handling a wide range of downstream\ntasks. Our contributions are twofold: (1) MMEB (Massive Multimodal Embedding\nBenchmark), which covers 4 meta-tasks (i.e. classification, visual question\nanswering, multimodal retrieval, and visual grounding) and 36 datasets,\nincluding 20 training and 16 evaluation datasets covering both in-distribution\nand out-of-distribution tasks, and (2) VLM2Vec (Vision-Language Model ->\nVector), a contrastive training framework that converts any state-of-the-art\nvision-language model into an embedding model via training on MMEB. Unlike\nprevious models such as CLIP and BLIP, which encodes text or images\nindependently without any task instruction, VLM2Vec can process any combination\nof images and text to generate a fixed-dimensional vector based on task\ninstructions. We build a series of VLM2Vec models on SoTA VLMs like Phi-3.5-V,\nLLaVA-1.6 and evaluate them on MMEB's evaluation split. Our results show that\nVLM2Vec achieves an absolute average improvement of 10% to 20% over existing\nmultimodal embedding models on both in-distribution and out-of-distribution\ndatasets in MMEB. We show that VLMs are secretly strong embedding models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2410.05160v3",
    "published_date": "2024-10-07 16:14:05 UTC",
    "updated_date": "2025-01-02 05:26:47 UTC"
  },
  {
    "arxiv_id": "2410.10860v1",
    "title": "A Recipe For Building a Compliant Real Estate Chatbot",
    "authors": [
      "Navid Madani",
      "Anusha Bagalkotkar",
      "Supriya Anand",
      "Gabriel Arnson",
      "Rohini Srihari",
      "Kenneth Joseph"
    ],
    "abstract": "In recent years, there has been significant effort to align large language\nmodels with human preferences. This work focuses on developing a chatbot\nspecialized in the real estate domain, with an emphasis on incorporating\ncompliant behavior to ensure it can be used without perpetuating discriminatory\npractices like steering and redlining, which have historically plagued the real\nestate industry in the United States. Building on prior work, we present a\nmethod for generating a synthetic general instruction-following dataset, along\nwith safety data. Through extensive evaluations and benchmarks, we fine-tuned a\nllama-3-8B-instruct model and demonstrated that we can enhance it's performance\nsignificantly to match huge closed-source models like GPT-4o while making it\nsafer and more compliant. We open-source the model, data and code to support\nfurther development and research in the community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10860v1",
    "published_date": "2024-10-07 16:03:47 UTC",
    "updated_date": "2024-10-07 16:03:47 UTC"
  },
  {
    "arxiv_id": "2410.05146v1",
    "title": "CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation",
    "authors": [
      "Rui Zhao",
      "Jinyu Li",
      "Ruchao Fan",
      "Matt Post"
    ],
    "abstract": "Models for streaming speech translation (ST) can achieve high accuracy and\nlow latency if they're developed with vast amounts of paired audio in the\nsource language and written text in the target language. Yet, these text labels\nfor the target language are often pseudo labels due to the prohibitive cost of\nmanual ST data labeling. In this paper, we introduce a methodology named\nConnectionist Temporal Classification guided modality matching (CTC-GMM) that\nenhances the streaming ST model by leveraging extensive machine translation\n(MT) text data. This technique employs CTC to compress the speech sequence into\na compact embedding sequence that matches the corresponding text sequence,\nallowing us to utilize matched {source-target} language text pairs from the MT\ncorpora to refine the streaming ST model further. Our evaluations with FLEURS\nand CoVoST2 show that the CTC-GMM approach can increase translation accuracy\nrelatively by 13.9% and 6.4% respectively, while also boosting decoding speed\nby 59.7% on GPU.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.05146v1",
    "published_date": "2024-10-07 15:58:03 UTC",
    "updated_date": "2024-10-07 15:58:03 UTC"
  },
  {
    "arxiv_id": "2410.05357v2",
    "title": "Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild",
    "authors": [
      "Xinyu Zhao",
      "Guoheng Sun",
      "Ruisi Cai",
      "Yukun Zhou",
      "Pingzhi Li",
      "Peihao Wang",
      "Bowen Tan",
      "Yexiao He",
      "Li Chen",
      "Yi Liang",
      "Beidi Chen",
      "Binhang Yuan",
      "Hongyi Wang",
      "Ang Li",
      "Zhangyang Wang",
      "Tianlong Chen"
    ],
    "abstract": "As Large Language Models (LLMs) excel across tasks and specialized domains,\nscaling LLMs based on existing models has garnered significant attention, which\nfaces the challenge of decreasing performance when combining disparate models.\nVarious techniques have been proposed for the aggregation of pre-trained LLMs,\nincluding model merging, Mixture-of-Experts, and stacking. Despite their\nmerits, a comprehensive comparison and synergistic application of them to a\ndiverse model zoo is yet to be adequately addressed. In light of this research\ngap, this paper introduces Model-GLUE, a holistic LLM scaling guideline. First,\nour work starts with a benchmarking of existing LLM scaling techniques,\nespecially selective merging, and variants of mixture. Utilizing the insights\nfrom the benchmark results, we formulate an optimal strategy for the selection\nand aggregation of a heterogeneous model zoo characterizing different\narchitectures and initialization.Our methodology involves the clustering of\nmergeable models and optimal merging strategy selection, and the integration of\nclusters through a model mixture. Finally, evidenced by our experiments on a\ndiverse Llama-2-based model zoo, Model-GLUE shows an average performance\nenhancement of 5.61%, achieved without additional training. Codes are available\nat: https://github.com/Model-GLUE/Model-GLUE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 4 figures, accepted to NeurIPS 2024 Datasets and Benchmarks\n  Track",
    "pdf_url": "http://arxiv.org/pdf/2410.05357v2",
    "published_date": "2024-10-07 15:55:55 UTC",
    "updated_date": "2024-12-05 15:08:56 UTC"
  },
  {
    "arxiv_id": "2410.05356v1",
    "title": "BSG4Bot: Efficient Bot Detection based on Biased Heterogeneous Subgraphs",
    "authors": [
      "Hao Miao",
      "Zida Liu",
      "Jun Gao"
    ],
    "abstract": "The detection of malicious social bots has become a crucial task, as bots can\nbe easily deployed and manipulated to spread disinformation, promote conspiracy\nmessages, and more. Most existing approaches utilize graph neural networks\n(GNNs)to capture both user profle and structural features,achieving promising\nprogress. However, they still face limitations including the expensive training\non large underlying graph, the performance degration when similar neighborhood\npatterns' assumption preferred by GNNs is not satisfied, and the dynamic\nfeatures of bots in a highly adversarial context. Motivated by these\nlimitations, this paper proposes a method named BSG4Bot with an intuition that\nGNNs training on Biased SubGraphs can improve both performance and time/space\nefficiency in bot detection. Specifically, BSG4Bot first pre-trains a\nclassifier on node features efficiently to define the node similarities, and\nconstructs biased subgraphs by combining the similarities computed by the\npre-trained classifier and the node importances computed by Personalized\nPageRank (PPR scores). BSG4Bot then introduces a heterogeneous GNN over the\nconstructed subgraphs to detect bots effectively and efficiently. The\nrelatively stable features, including the content category and temporal\nactivity features, are explored and incorporated into BSG4Bot after preliminary\nverification on sample data. The extensive experimental studies show that\nBSG4Bot outperforms the state-of-the-art bot detection methods, while only\nneeding nearly 1/5 training time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05356v1",
    "published_date": "2024-10-07 15:52:51 UTC",
    "updated_date": "2024-10-07 15:52:51 UTC"
  },
  {
    "arxiv_id": "2410.05355v1",
    "title": "Falcon Mamba: The First Competitive Attention-free 7B Language Model",
    "authors": [
      "Jingwei Zuo",
      "Maksim Velikanov",
      "Dhia Eddine Rhaiem",
      "Ilyas Chahed",
      "Younes Belkada",
      "Guillaume Kunsch",
      "Hakim Hacid"
    ],
    "abstract": "In this technical report, we present Falcon Mamba 7B, a new base large\nlanguage model based on the novel Mamba architecture. Falcon Mamba 7B is\ntrained on 5.8 trillion tokens with carefully selected data mixtures. As a pure\nMamba-based model, Falcon Mamba 7B surpasses leading open-weight models based\non Transformers, such as Mistral 7B, Llama3.1 8B, and Falcon2 11B. It is on par\nwith Gemma 7B and outperforms models with different architecture designs, such\nas RecurrentGemma 9B and RWKV-v6 Finch 7B/14B. Currently, Falcon Mamba 7B is\nthe best-performing Mamba model in the literature at this scale, surpassing\nboth existing Mamba and hybrid Mamba-Transformer models, according to the Open\nLLM Leaderboard. Due to its architecture, Falcon Mamba 7B is significantly\nfaster at inference and requires substantially less memory for long sequence\ngeneration. Despite recent studies suggesting that hybrid Mamba-Transformer\nmodels outperform pure architecture designs, we demonstrate that even the pure\nMamba design can achieve similar, or even superior results compared to the\nTransformer and hybrid designs. We make the weights of our implementation of\nFalcon Mamba 7B publicly available on\nhttps://huggingface.co/tiiuae/falcon-mamba-7b, under a permissive license.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05355v1",
    "published_date": "2024-10-07 15:40:45 UTC",
    "updated_date": "2024-10-07 15:40:45 UTC"
  },
  {
    "arxiv_id": "2410.05130v1",
    "title": "Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents",
    "authors": [
      "Yuwei Hu",
      "Runlin Lei",
      "Xinyi Huang",
      "Zhewei Wei",
      "Yongchao Liu"
    ],
    "abstract": "Recent research has explored the use of Large Language Models (LLMs) for\ntackling complex graph reasoning tasks. However, due to the intricacies of\ngraph structures and the inherent limitations of LLMs in handling long text,\ncurrent approaches often fail to deliver satisfactory accuracy, even on\nsmall-scale graphs and simple tasks. To address these challenges, we introduce\nGraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent\ncollaboration strategy for explicit and precise graph reasoning. Inspired by\ndistributed graph computation theory, our framework decomposes graph problems\ninto smaller, node-centric tasks that are distributed among multiple agents.\nThe agents collaborate to solve the overall problem, significantly reducing the\namount of information and complexity handled by a single LLM, thus enhancing\nthe accuracy of graph reasoning. By simply increasing the number of agents,\nGraphAgent-Reasoner can efficiently scale to accommodate larger graphs with\nover 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework\ndemonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,\nsignificantly outperforming the best available models, both closed-source and\nfine-tuned open-source variants. Our framework also demonstrates the capability\nto handle real-world graph reasoning applications such as webpage importance\nanalysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05130v1",
    "published_date": "2024-10-07 15:34:14 UTC",
    "updated_date": "2024-10-07 15:34:14 UTC"
  },
  {
    "arxiv_id": "2410.05127v3",
    "title": "Last Iterate Convergence in Monotone Mean Field Games",
    "authors": [
      "Noboru Isobe",
      "Kenshi Abe",
      "Kaito Ariu"
    ],
    "abstract": "Mean Field Game (MFG) is a framework for modeling and approximating the\nbehavior of large numbers of agents. Computing equilibria in MFG has been of\ninterest in multi-agent reinforcement learning. The theoretical guarantee that\nthe last updated policy converges to an equilibrium has been limited. We\npropose the use of a simple, proximal-point (PP) type method to compute\nequilibria for MFGs. We then provide the first last-iterate convergence (LIC)\nguarantee under the Lasry--Lions-type monotonicity condition. We also propose\nan approximation of the update rule of PP ($\\mathtt{APP}$) based on the\nobservation that it is equivalent to solving the regularized MFG, which can be\nsolved by mirror descent. We further establish that the regularized mirror\ndescent achieves LIC at an exponential rate. Our numerical experiment\ndemonstrates that $\\mathtt{APP}$ efficiently computes the equilibrium.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "91A16"
    ],
    "primary_category": "cs.GT",
    "comment": "Under review, 26 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.05127v3",
    "published_date": "2024-10-07 15:28:18 UTC",
    "updated_date": "2025-01-31 12:20:20 UTC"
  },
  {
    "arxiv_id": "2410.17271v3",
    "title": "Rules, Cases, and Reasoning: Positivist Legal Theory as a Framework for Pluralistic AI Alignment",
    "authors": [
      "Nicholas A. Caputo"
    ],
    "abstract": "Legal theory can address two related key problems of alignment: pluralism and\nspecification. Alignment researchers must determine how to specify what is\nconcretely meant by vague principles like helpfulness and fairness and they\nmust ensure that their techniques do not exclude alternative perspectives on\nlife and values. The law faces these same problems. Leading legal theories\nsuggest the law solves these problems through the interaction of rules and\ncases, where general rules promulgated by a democratic authority are given\nspecific content through their application over time. Concrete applications\nallow for convergence on practical meaning while preserving space for\ndisagreement on values. These approaches suggest improvements to existing\ndemocratic alignment processes that use AI to create cases that give content to\nrules, allowing for more pluralist alignment.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "NeurIPS Pluralistic Alignment Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.17271v3",
    "published_date": "2024-10-07 15:16:25 UTC",
    "updated_date": "2024-10-28 11:38:09 UTC"
  },
  {
    "arxiv_id": "2410.05116v3",
    "title": "HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning",
    "authors": [
      "Ayano Hiranaka",
      "Shang-Fu Chen",
      "Chieh-Hsin Lai",
      "Dongjun Kim",
      "Naoki Murata",
      "Takashi Shibuya",
      "Wei-Hsiang Liao",
      "Shao-Hua Sun",
      "Yuki Mitsufuji"
    ],
    "abstract": "Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback. The code and project page are available\nat https://hero-dm.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in International Conference on Learning Representations\n  (ICLR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05116v3",
    "published_date": "2024-10-07 15:12:01 UTC",
    "updated_date": "2025-03-13 08:12:07 UTC"
  },
  {
    "arxiv_id": "2410.05115v1",
    "title": "AlphaRouter: Quantum Circuit Routing with Reinforcement Learning and Tree Search",
    "authors": [
      "Wei Tang",
      "Yiheng Duan",
      "Yaroslav Kharkov",
      "Rasool Fakoor",
      "Eric Kessler",
      "Yunong Shi"
    ],
    "abstract": "Quantum computers have the potential to outperform classical computers in\nimportant tasks such as optimization and number factoring. They are\ncharacterized by limited connectivity, which necessitates the routing of their\ncomputational bits, known as qubits, to specific locations during program\nexecution to carry out quantum operations. Traditionally, the NP-hard\noptimization problem of minimizing the routing overhead has been addressed\nthrough sub-optimal rule-based routing techniques with inherent human biases\nembedded within the cost function design. This paper introduces a solution that\nintegrates Monte Carlo Tree Search (MCTS) with Reinforcement Learning (RL). Our\nRL-based router, called AlphaRouter, outperforms the current state-of-the-art\nrouting methods and generates quantum programs with up to $20\\%$ less routing\noverhead, thus significantly enhancing the overall efficiency and feasibility\nof quantum computing.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "quant-ph",
    "comment": "11 pages, 11 figures, International Conference on Quantum Computing\n  and Engineering - QCE24",
    "pdf_url": "http://arxiv.org/pdf/2410.05115v1",
    "published_date": "2024-10-07 15:10:54 UTC",
    "updated_date": "2024-10-07 15:10:54 UTC"
  },
  {
    "arxiv_id": "2410.05114v1",
    "title": "Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization",
    "authors": [
      "Rohan Reddy Mekala",
      "Frederik Pahde",
      "Simon Baur",
      "Sneha Chandrashekar",
      "Madeline Diep",
      "Markus Wenzel",
      "Eric L. Wisotzky",
      "Galip Ümit Yolcu",
      "Sebastian Lapuschkin",
      "Jackie Ma",
      "Peter Eisert",
      "Mikael Lindvall",
      "Adam Porter",
      "Wojciech Samek"
    ],
    "abstract": "In the realm of dermatological diagnoses, where the analysis of dermatoscopic\nand microscopic skin lesion images is pivotal for the accurate and early\ndetection of various medical conditions, the costs associated with creating\ndiverse and high-quality annotated datasets have hampered the accuracy and\ngeneralizability of machine learning models. We propose an innovative\nunsupervised augmentation solution that harnesses Generative Adversarial\nNetwork (GAN) based models and associated techniques over their latent space to\ngenerate controlled semiautomatically-discovered semantic variations in\ndermatoscopic images. We created synthetic images to incorporate the semantic\nvariations and augmented the training data with these images. With this\napproach, we were able to increase the performance of machine learning models\nand set a new benchmark amongst non-ensemble based models in skin lesion\nclassification on the HAM10000 dataset; and used the observed analytics and\ngenerated models for detailed studies on model explainability, affirming the\neffectiveness of our solution.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This preprint has been submitted to the Workshop on Synthetic Data\n  for Computer Vision (SyntheticData4CV 2024 is a side event on 18th European\n  Conference on Computer Vision 2024). This preprint has not undergone peer\n  review or any post-submission improvements or corrections",
    "pdf_url": "http://arxiv.org/pdf/2410.05114v1",
    "published_date": "2024-10-07 15:09:50 UTC",
    "updated_date": "2024-10-07 15:09:50 UTC"
  },
  {
    "arxiv_id": "2410.05105v1",
    "title": "AI-Enhanced Ethical Hacking: A Linux-Focused Experiment",
    "authors": [
      "Haitham S. Al-Sinani",
      "Chris J. Mitchell"
    ],
    "abstract": "This technical report investigates the integration of generative AI (GenAI),\nspecifically ChatGPT, into the practice of ethical hacking through a\ncomprehensive experimental study and conceptual analysis. Conducted in a\ncontrolled virtual environment, the study evaluates GenAI's effectiveness\nacross the key stages of penetration testing on Linux-based target machines\noperating within a virtual local area network (LAN), including reconnaissance,\nscanning and enumeration, gaining access, maintaining access, and covering\ntracks. The findings confirm that GenAI can significantly enhance and\nstreamline the ethical hacking process while underscoring the importance of\nbalanced human-AI collaboration rather than the complete replacement of human\ninput. The report also critically examines potential risks such as misuse, data\nbiases, hallucination, and over-reliance on AI. This research contributes to\nthe ongoing discussion on the ethical use of AI in cybersecurity and highlights\nthe need for continued innovation to strengthen security defences.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05105v1",
    "published_date": "2024-10-07 15:02:47 UTC",
    "updated_date": "2024-10-07 15:02:47 UTC"
  },
  {
    "arxiv_id": "2410.09087v1",
    "title": "Mechanistic?",
    "authors": [
      "Naomi Saphra",
      "Sarah Wiegreffe"
    ],
    "abstract": "The rise of the term \"mechanistic interpretability\" has accompanied\nincreasing interest in understanding neural models -- particularly language\nmodels. However, this jargon has also led to a fair amount of confusion. So,\nwhat does it mean to be \"mechanistic\"? We describe four uses of the term in\ninterpretability research. The most narrow technical definition requires a\nclaim of causality, while a broader technical definition allows for any\nexploration of a model's internals. However, the term also has a narrow\ncultural definition describing a cultural movement. To understand this semantic\ndrift, we present a history of the NLP interpretability community and the\nformation of the separate, parallel \"mechanistic\" interpretability community.\nFinally, we discuss the broad cultural definition -- encompassing the entire\nfield of interpretability -- and why the traditional NLP interpretability\ncommunity has come to embrace it. We argue that the polysemy of \"mechanistic\"\nis the product of a critical divide within the interpretability community.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Equal contribution. Position paper. Accepted for presentation at the\n  BlackBoxNLP workshop at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09087v1",
    "published_date": "2024-10-07 15:02:12 UTC",
    "updated_date": "2024-10-07 15:02:12 UTC"
  },
  {
    "arxiv_id": "2410.05102v2",
    "title": "SparsePO: Controlling Preference Alignment of LLMs via Sparse Token Masks",
    "authors": [
      "Fenia Christopoulou",
      "Ronald Cardenas",
      "Gerasimos Lampouras",
      "Haitham Bou-Ammar",
      "Jun Wang"
    ],
    "abstract": "Preference Optimization (PO) has proven an effective step for aligning\nlanguage models to human-desired behaviors. Current variants, following the\noffline Direct Preference Optimization objective, have focused on a strict\nsetting where all tokens are contributing signals of KL divergence and rewards\nto the loss function. However, human preference is not affected by each word in\na sequence equally but is often dependent on specific words or phrases, e.g.\nexistence of toxic terms leads to non-preferred responses. Based on this\nobservation, we argue that not all tokens should be weighted equally during PO\nand propose a flexible objective termed SparsePO, that aims to automatically\nlearn to weight the KL divergence and reward corresponding to each token during\nPO training. We propose two different variants of weight-masks that can either\nbe derived from the reference model itself or learned on the fly. Notably, our\nmethod induces sparsity in the learned masks, allowing the model to learn how\nto best weight reward and KL divergence contributions at the token level,\nlearning an optimal level of mask sparsity. Extensive experiments on multiple\ndomains, including sentiment control, dialogue, text summarization and\ntext-to-code generation, illustrate that our approach assigns meaningful\nweights to tokens according to the target task, generates more responses with\nthe desired preference and improves reasoning tasks by up to 2 percentage\npoints compared to other token- and response-level PO methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 9 figures, 5 tables. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.05102v2",
    "published_date": "2024-10-07 15:01:29 UTC",
    "updated_date": "2024-10-08 15:53:22 UTC"
  },
  {
    "arxiv_id": "2410.05094v1",
    "title": "On the Structure of Game Provenance and its Applications",
    "authors": [
      "Shawn Bowers",
      "Yilin Xia",
      "Bertram Ludäscher"
    ],
    "abstract": "Provenance in databases has been thoroughly studied for positive and for\nrecursive queries, then for first-order (FO) queries, i.e., having negation but\nno recursion. Query evaluation can be understood as a two-player game where the\nopponents argue whether or not a tuple is in the query answer. This\ngame-theoretic approach yields a natural provenance model for FO queries,\nunifying how and why-not provenance. Here, we study the fine-grain structure of\ngame provenance. A game $G=(V,E)$ consists of positions $V$ and moves $E$ and\ncan be solved by computing the well-founded model of a single, unstratifiable\nrule: \\[ \\text{win}(X) \\leftarrow \\text{move}(X, Y), \\neg \\, \\text{win}(Y). \\]\nIn the solved game $G^{\\lambda}$, the value of a position $x\\,{\\in}\\,V$ is\neither won, lost, or drawn. This value is explained by the provenance\n$\\mathscr{P}$(x), i.e., certain (annotated) edges reachable from $x$. We\nidentify seven edge types that give rise to new kinds of provenance, i.e.,\npotential, actual, and primary, and demonstrate that \"not all moves are created\nequal\". We describe the new provenance types, show how they can be computed\nwhile solving games, and discuss applications, e.g., for abstract argumentation\nframeworks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05094v1",
    "published_date": "2024-10-07 14:48:56 UTC",
    "updated_date": "2024-10-07 14:48:56 UTC"
  },
  {
    "arxiv_id": "2410.09086v1",
    "title": "AI in Archival Science -- A Systematic Review",
    "authors": [
      "Gaurav Shinde",
      "Tiana Kirstein",
      "Souvick Ghosh",
      "Patricia C. Franks"
    ],
    "abstract": "The rapid expansion of records creates significant challenges in management,\nincluding retention and disposition, appraisal, and organization. Our study\nunderscores the benefits of integrating artificial intelligence (AI) within the\nbroad realm of archival science. In this work, we start by performing a\nthorough analysis to understand the current use of AI in this area and identify\nthe techniques employed to address challenges. Subsequently, we document the\nresults of our review according to specific criteria. Our findings highlight\nkey AI driven strategies that promise to streamline record-keeping processes\nand enhance data retrieval efficiency. We also demonstrate our review process\nto ensure transparency regarding our methodology. Furthermore, this review not\nonly outlines the current state of AI in archival science and records\nmanagement but also lays the groundwork for integrating new techniques to\ntransform archival practices. Our research emphasizes the necessity for\nenhanced collaboration between the disciplines of artificial intelligence and\narchival science.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09086v1",
    "published_date": "2024-10-07 14:39:12 UTC",
    "updated_date": "2024-10-07 14:39:12 UTC"
  },
  {
    "arxiv_id": "2410.05080v3",
    "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery",
    "authors": [
      "Ziru Chen",
      "Shijie Chen",
      "Yuting Ning",
      "Qianheng Zhang",
      "Boshi Wang",
      "Botao Yu",
      "Yifei Li",
      "Zeyi Liao",
      "Chen Wei",
      "Zitong Lu",
      "Vishal Dey",
      "Mingyi Xue",
      "Frazier N. Baker",
      "Benjamin Burns",
      "Daniel Adu-Ampratwum",
      "Xuhui Huang",
      "Xia Ning",
      "Song Gao",
      "Yu Su",
      "Huan Sun"
    ],
    "abstract": "The advancements of large language models (LLMs) have piqued growing interest\nin developing LLM-based language agents to automate scientific discovery\nend-to-end, which has sparked both excitement and skepticism about their true\ncapabilities. In this work, we call for rigorous assessment of agents on\nindividual tasks in a scientific workflow before making bold claims on\nend-to-end automation. To this end, we present ScienceAgentBench, a new\nbenchmark for evaluating language agents for data-driven scientific discovery.\nTo ensure the scientific authenticity and real-world relevance of our\nbenchmark, we extract 102 tasks from 44 peer-reviewed publications in four\ndisciplines and engage nine subject matter experts to validate them. We unify\nthe target output for every task to a self-contained Python program file and\nemploy an array of evaluation metrics to examine the generated programs,\nexecution results, and costs. Each task goes through multiple rounds of manual\nvalidation by annotators and subject matter experts to ensure its annotation\nquality and scientific plausibility. We also propose two effective strategies\nto mitigate data contamination concerns. Using ScienceAgentBench, we evaluate\nfive open-weight and proprietary LLMs, each with three frameworks: direct\nprompting, OpenHands CodeAct, and self-debug. Given three attempts for each\ntask, the best-performing agent can only solve 32.4% of the tasks independently\nand 34.3% with expert-provided knowledge. In addition, we evaluate OpenAI\no1-preview with direct prompting and self-debug, which can boost the\nperformance to 42.2%, demonstrating the effectiveness of increasing\ninference-time compute but with more than 10 times the cost of other LLMs.\nStill, our results underscore the limitations of current language agents in\ngenerating code for data-driven discovery, let alone end-to-end automation for\nscientific research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025. 60 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.05080v3",
    "published_date": "2024-10-07 14:33:50 UTC",
    "updated_date": "2025-03-31 14:39:44 UTC"
  },
  {
    "arxiv_id": "2410.05078v1",
    "title": "Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data",
    "authors": [
      "David Heurtel-Depeiges",
      "Anian Ruoss",
      "Joel Veness",
      "Tim Genewein"
    ],
    "abstract": "Foundation models have recently been shown to be strong data compressors.\nHowever, when accounting for their excessive parameter count, their compression\nratios are actually inferior to standard compression algorithms. Moreover,\nnaively reducing the number of parameters may not necessarily help as it leads\nto worse predictions and thus weaker compression. In this paper, we conduct a\nlarge-scale empirical study to investigate whether there is a sweet spot where\ncompetitive compression ratios with pre-trained vanilla transformers are\npossible. To this end, we train families of models on 165GB of raw byte\nsequences of either text, image, or audio data (and all possible combinations\nof the three) and then compress 1GB of out-of-distribution (OOD) data from each\nmodality. We find that relatively small models (i.e., millions of parameters)\ncan outperform standard general-purpose compression algorithms (gzip, LZMA2)\nand even domain-specific compressors (PNG, JPEG 2000, FLAC) - even when\nfactoring in parameter count. We achieve, e.g., the lowest compression ratio of\n0.49 on OOD audio data (vs. 0.54 for FLAC). To study the impact of model- and\ndataset scale, we conduct extensive ablations and hyperparameter sweeps, and we\ninvestigate the effect of unimodal versus multimodal training. We find that\neven small models can be trained to perform well on multiple modalities, but,\nin contrast to previously reported results with large-scale foundation models,\ntransfer to unseen modalities is generally weak.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05078v1",
    "published_date": "2024-10-07 14:32:03 UTC",
    "updated_date": "2024-10-07 14:32:03 UTC"
  },
  {
    "arxiv_id": "2410.05076v1",
    "title": "TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention",
    "authors": [
      "Lijie Yang",
      "Zhihao Zhang",
      "Zhuofu Chen",
      "Zikun Li",
      "Zhihao Jia"
    ],
    "abstract": "Large language models (LLMs) have driven significant advancements across\ndiverse NLP tasks, with long-context models gaining prominence for handling\nextended inputs. However, the expanding key-value (KV) cache size required by\nTransformer architectures intensifies the memory constraints, particularly\nduring the decoding phase, creating a significant bottleneck. Existing sparse\nattention mechanisms designed to address this bottleneck have two limitations:\n(1) they often fail to reliably identify the most relevant tokens for\nattention, and (2) they overlook the spatial coherence of token selection\nacross consecutive Transformer layers, which can lead to performance\ndegradation and substantial overhead in token selection. This paper introduces\nTidalDecode, a simple yet effective algorithm and system for fast and accurate\nLLM decoding through position persistent sparse attention. TidalDecode\nleverages the spatial coherence of tokens selected by existing sparse attention\nmethods and introduces a few token selection layers that perform full attention\nto identify the tokens with the highest attention scores, while all other\nlayers perform sparse attention with the pre-selected tokens. This design\nenables TidalDecode to substantially reduce the overhead of token selection for\nsparse attention without sacrificing the quality of the generated results.\nEvaluation on a diverse set of LLMs and tasks shows that TidalDecode closely\nmatches the generative performance of full attention methods while reducing the\nLLM decoding latency by up to 2.1x.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05076v1",
    "published_date": "2024-10-07 14:30:27 UTC",
    "updated_date": "2024-10-07 14:30:27 UTC"
  },
  {
    "arxiv_id": "2410.05056v3",
    "title": "Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory",
    "authors": [
      "Attila Lovas"
    ],
    "abstract": "Nonlinear time series models with exogenous regressors are essential in\neconometrics, queuing theory, and machine learning, though their statistical\nanalysis remains incomplete. Key results, such as the law of large numbers and\nthe functional central limit theorem, are known for weakly dependent variables.\nWe demonstrate the transfer of mixing properties from the exogenous regressor\nto the response via coupling arguments. Additionally, we study Markov chains in\nrandom environments with drift and minorization conditions, even under\nnon-stationary environments with favorable mixing properties, and apply this\nframework to single-server queuing models.",
    "categories": [
      "math.ST",
      "cs.AI",
      "math.PR",
      "stat.TH",
      "60K37, 60K25, 60J05, 60J20",
      "G.3; I.6.5; C.4"
    ],
    "primary_category": "math.ST",
    "comment": "39 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.05056v3",
    "published_date": "2024-10-07 14:13:37 UTC",
    "updated_date": "2025-04-22 15:01:48 UTC"
  },
  {
    "arxiv_id": "2410.05050v2",
    "title": "FreSh: Frequency Shifting for Accelerated Neural Representation Learning",
    "authors": [
      "Adam Kania",
      "Marko Mihajlovic",
      "Sergey Prokudin",
      "Jacek Tabor",
      "Przemysław Spurek"
    ],
    "abstract": "Implicit Neural Representations (INRs) have recently gained attention as a\npowerful approach for continuously representing signals such as images, videos,\nand 3D shapes using multilayer perceptrons (MLPs). However, MLPs are known to\nexhibit a low-frequency bias, limiting their ability to capture high-frequency\ndetails accurately. This limitation is typically addressed by incorporating\nhigh-frequency input embeddings or specialized activation layers. In this work,\nwe demonstrate that these embeddings and activations are often configured with\nhyperparameters that perform well on average but are suboptimal for specific\ninput signals under consideration, necessitating a costly grid search to\nidentify optimal settings. Our key observation is that the initial frequency\nspectrum of an untrained model's output correlates strongly with the model's\neventual performance on a given target signal. Leveraging this insight, we\npropose frequency shifting (or FreSh), a method that selects embedding\nhyperparameters to align the frequency spectrum of the model's initial output\nwith that of the target signal. We show that this simple initialization\ntechnique improves performance across various neural representation methods and\ntasks, achieving results comparable to extensive hyperparameter sweeps but with\nonly marginal computational overhead compared to training a single model with\ndefault hyperparameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Code at https://github.com/gmum/FreSh/",
    "pdf_url": "http://arxiv.org/pdf/2410.05050v2",
    "published_date": "2024-10-07 14:05:57 UTC",
    "updated_date": "2024-10-08 15:21:20 UTC"
  },
  {
    "arxiv_id": "2410.16309v1",
    "title": "In-the-loop Hyper-Parameter Optimization for LLM-Based Automated Design of Heuristics",
    "authors": [
      "Niki van Stein",
      "Diederick Vermetten",
      "Thomas Bäck"
    ],
    "abstract": "Large Language Models (LLMs) have shown great potential in automatically\ngenerating and optimizing (meta)heuristics, making them valuable tools in\nheuristic optimization tasks. However, LLMs are generally inefficient when it\ncomes to fine-tuning hyper-parameters of the generated algorithms, often\nrequiring excessive queries that lead to high computational and financial\ncosts. This paper presents a novel hybrid approach, LLaMEA-HPO, which\nintegrates the open source LLaMEA (Large Language Model Evolutionary Algorithm)\nframework with a Hyper-Parameter Optimization (HPO) procedure in the loop. By\noffloading hyper-parameter tuning to an HPO procedure, the LLaMEA-HPO framework\nallows the LLM to focus on generating novel algorithmic structures, reducing\nthe number of required LLM queries and improving the overall efficiency of the\noptimization process.\n  We empirically validate the proposed hybrid framework on benchmark problems,\nincluding Online Bin Packing, Black-Box Optimization, and the Traveling\nSalesperson Problem. Our results demonstrate that LLaMEA-HPO achieves superior\nor comparable performance compared to existing LLM-driven frameworks while\nsignificantly reducing computational costs. This work highlights the importance\nof separating algorithmic innovation and structural code search from parameter\ntuning in LLM-driven code optimization and offers a scalable approach to\nimprove the efficiency and effectiveness of LLM-based code generation.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16309v1",
    "published_date": "2024-10-07 14:04:31 UTC",
    "updated_date": "2024-10-07 14:04:31 UTC"
  },
  {
    "arxiv_id": "2410.05046v1",
    "title": "Named Clinical Entity Recognition Benchmark",
    "authors": [
      "Wadood M Abdul",
      "Marco AF Pimentel",
      "Muhammad Umar Salman",
      "Tathagata Raha",
      "Clément Christophe",
      "Praveen K Kanithi",
      "Nasir Hayat",
      "Ronnie Rajan",
      "Shadab Khan"
    ],
    "abstract": "This technical report introduces a Named Clinical Entity Recognition\nBenchmark for evaluating language models in healthcare, addressing the crucial\nnatural language processing (NLP) task of extracting structured information\nfrom clinical narratives to support applications like automated coding,\nclinical trial cohort identification, and clinical decision support.\n  The leaderboard provides a standardized platform for assessing diverse\nlanguage models, including encoder and decoder architectures, on their ability\nto identify and classify clinical entities across multiple medical domains. A\ncurated collection of openly available clinical datasets is utilized,\nencompassing entities such as diseases, symptoms, medications, procedures, and\nlaboratory measurements. Importantly, these entities are standardized according\nto the Observational Medical Outcomes Partnership (OMOP) Common Data Model,\nensuring consistency and interoperability across different healthcare systems\nand datasets, and a comprehensive evaluation of model performance. Performance\nof models is primarily assessed using the F1-score, and it is complemented by\nvarious assessment modes to provide comprehensive insights into model\nperformance. The report also includes a brief analysis of models evaluated to\ndate, highlighting observed trends and limitations.\n  By establishing this benchmarking framework, the leaderboard aims to promote\ntransparency, facilitate comparative analyses, and drive innovation in clinical\nentity recognition tasks, addressing the need for robust evaluation methods in\nhealthcare NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2410.05046v1",
    "published_date": "2024-10-07 14:00:18 UTC",
    "updated_date": "2024-10-07 14:00:18 UTC"
  },
  {
    "arxiv_id": "2410.05045v1",
    "title": "Can LLMs plan paths with extra hints from solvers?",
    "authors": [
      "Erik Wu",
      "Sayan Mitra"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing, mathematical problem solving, and tasks related to program\nsynthesis. However, their effectiveness in long-term planning and higher-order\nreasoning has been noted to be limited and fragile. This paper explores an\napproach for enhancing LLM performance in solving a classical robotic planning\ntask by integrating solver-generated feedback. We explore four different\nstrategies for providing feedback, including visual feedback, we utilize\nfine-tuning, and we evaluate the performance of three different LLMs across a\n10 standard and 100 more randomly generated planning problems. Our results\nsuggest that the solver-generated feedback improves the LLM's ability to solve\nthe moderately difficult problems, but the harder problems still remain out of\nreach. The study provides detailed analysis of the effects of the different\nhinting strategies and the different planning tendencies of the evaluated LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05045v1",
    "published_date": "2024-10-07 14:00:08 UTC",
    "updated_date": "2024-10-07 14:00:08 UTC"
  },
  {
    "arxiv_id": "2410.05044v1",
    "title": "PhotoReg: Photometrically Registering 3D Gaussian Splatting Models",
    "authors": [
      "Ziwen Yuan",
      "Tianyi Zhang",
      "Matthew Johnson-Roberson",
      "Weiming Zhi"
    ],
    "abstract": "Building accurate representations of the environment is critical for\nintelligent robots to make decisions during deployment. Advances in\nphotorealistic environment models have enabled robots to develop\nhyper-realistic reconstructions, which can be used to generate images that are\nintuitive for human inspection. In particular, the recently introduced\n\\ac{3DGS}, which describes the scene with up to millions of primitive\nellipsoids, can be rendered in real time. \\ac{3DGS} has rapidly gained\nprominence. However, a critical unsolved problem persists: how can we fuse\nmultiple \\ac{3DGS} into a single coherent model? Solving this problem will\nenable robot teams to jointly build \\ac{3DGS} models of their surroundings. A\nkey insight of this work is to leverage the {duality} between photorealistic\nreconstructions, which render realistic 2D images from 3D structure, and\n\\emph{3D foundation models}, which predict 3D structure from image pairs. To\nthis end, we develop PhotoReg, a framework to register multiple photorealistic\n\\ac{3DGS} models with 3D foundation models. As \\ac{3DGS} models are generally\nbuilt from monocular camera images, they have \\emph{arbitrary scale}. To\nresolve this, PhotoReg actively enforces scale consistency among the different\n\\ac{3DGS} models by considering depth estimates within these models. Then, the\nalignment is iteratively refined with fine-grained photometric losses to\nproduce high-quality fused \\ac{3DGS} models. We rigorously evaluate PhotoReg on\nboth standard benchmark datasets and our custom-collected datasets, including\nwith two quadruped robots. The code is released at\n\\url{ziweny11.github.io/photoreg}.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05044v1",
    "published_date": "2024-10-07 13:58:40 UTC",
    "updated_date": "2024-10-07 13:58:40 UTC"
  },
  {
    "arxiv_id": "2410.10859v2",
    "title": "FAME: Towards Factual Multi-Task Model Editing",
    "authors": [
      "Li Zeng",
      "Yingyu Shan",
      "Zeming Liu",
      "Jiashu Yao",
      "Yuhang Guo"
    ],
    "abstract": "Large language models (LLMs) embed extensive knowledge and utilize it to\nperform exceptionally well across various tasks. Nevertheless, outdated\nknowledge or factual errors within LLMs can lead to misleading or incorrect\nresponses, causing significant issues in practical applications. To rectify the\nfatal flaw without the necessity for costly model retraining, various model\nediting approaches have been proposed to correct inaccurate knowledge within\nLLMs in a cost-efficient way. To evaluate these model editing methods, previous\nwork introduced a series of datasets. However, most of the previous datasets\nonly contain fabricated data in a single format, which diverges from real-world\nmodel editing scenarios, raising doubts about their usability in practice. To\nfacilitate the application of model editing in real-world scenarios, we propose\nthe challenge of practicality. To resolve such challenges and effectively\nenhance the capabilities of LLMs, we present FAME, an factual, comprehensive,\nand multi-task dataset, which is designed to enhance the practicality of model\nediting. We then propose SKEME, a model editing method that uses a novel\ncaching mechanism to ensure synchronization with the real world. The\nexperiments demonstrate that SKEME performs excellently across various tasks\nand scenarios, confirming its practicality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures. This paper has been accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10859v2",
    "published_date": "2024-10-07 13:46:06 UTC",
    "updated_date": "2024-10-18 10:02:03 UTC"
  },
  {
    "arxiv_id": "2410.05354v3",
    "title": "Over-the-Air Federated Learning in Cell-Free MIMO with Long-term Power Constraint",
    "authors": [
      "Yifan Wang",
      "Cheng Zhang",
      "Yuanndon Zhuang",
      "Mingzeng Dai",
      "Haiming Wang",
      "Yongming Huang"
    ],
    "abstract": "Wireless networks supporting artificial intelligence have gained significant\nattention, with Over-the-Air Federated Learning emerging as a key application\ndue to its unique transmission and distributed computing characteristics. This\npaper derives error bounds for Over-the-Air Federated Learning in a Cell-free\nMIMO system and formulates an optimization problem to minimize optimality gap\nvia joint optimization of power control and beamforming. We introduce the\nMOP-LOFPC algorithm, which employs Lyapunov optimization to decouple long-term\nconstraints across rounds while requiring only causal channel state\ninformation. Experimental results demonstrate that MOP-LOFPC achieves a better\nand more flexible trade-off between the model's training loss and adherence to\nlong-term power constraints compared to existing baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05354v3",
    "published_date": "2024-10-07 13:44:49 UTC",
    "updated_date": "2024-10-23 09:51:11 UTC"
  },
  {
    "arxiv_id": "2410.05353v2",
    "title": "Towards a Categorical Foundation of Deep Learning: A Survey",
    "authors": [
      "Francesco Riccardo Crescenzi"
    ],
    "abstract": "The unprecedented pace of machine learning research has lead to incredible\nadvances, but also poses hard challenges. At present, the field lacks strong\ntheoretical underpinnings, and many important achievements stem from ad hoc\ndesign choices which are hard to justify in principle and whose effectiveness\noften goes unexplained. Research debt is increasing and many papers are found\nnot to be reproducible.\n  This thesis is a survey that covers some recent work attempting to study\nmachine learning categorically. Category theory is a branch of abstract\nmathematics that has found successful applications in many fields, both inside\nand outside mathematics. Acting as a lingua franca of mathematics and science,\ncategory theory might be able to give a unifying structure to the field of\nmachine learning. This could solve some of the aforementioned problems.\n  In this work, we mainly focus on the application of category theory to deep\nlearning. Namely, we discuss the use of categorical optics to model\ngradient-based learning, the use of categorical algebras and integral\ntransforms to link classical computer science to neural networks, the use of\nfunctors to link different layers of abstraction and preserve structure, and,\nfinally, the use of string diagrams to provide detailed representations of\nneural network architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CT"
    ],
    "primary_category": "cs.LG",
    "comment": "In the previous version of the survey, it was stated that the paper\n  \"Pooling Image Datasets with Multiple Covariate Shift and Imbalance\" (Chytas,\n  Lokhande, Singh) had been withdrawn by the authors. I have been informed that\n  only an incomplete draft of the work was withdrawn after it was inadvertently\n  uploaded. The complete work was actually published at ICLR and has never been\n  withdrawn",
    "pdf_url": "http://arxiv.org/pdf/2410.05353v2",
    "published_date": "2024-10-07 13:11:16 UTC",
    "updated_date": "2024-10-14 18:35:08 UTC"
  },
  {
    "arxiv_id": "2410.05352v2",
    "title": "Recent Advances of Multimodal Continual Learning: A Comprehensive Survey",
    "authors": [
      "Dianzhi Yu",
      "Xinni Zhang",
      "Yankai Chen",
      "Aiwei Liu",
      "Yifei Zhang",
      "Philip S. Yu",
      "Irwin King"
    ],
    "abstract": "Continual learning (CL) aims to empower machine learning models to learn\ncontinually from new data, while building upon previously acquired knowledge\nwithout forgetting. As machine learning models have evolved from small to large\npre-trained architectures, and from supporting unimodal to multimodal data,\nmultimodal continual learning (MMCL) methods have recently emerged. The primary\nchallenge of MMCL is that it goes beyond a simple stacking of unimodal CL\nmethods, as such straightforward approaches often yield unsatisfactory\nperformance. In this work, we present the first comprehensive survey on MMCL.\nWe provide essential background knowledge and MMCL settings, as well as a\nstructured taxonomy of MMCL methods. We categorize existing MMCL methods into\nfour categories, i.e., regularization-based, architecture-based, replay-based,\nand prompt-based methods, explaining their methodologies and highlighting their\nkey innovations. Additionally, to prompt further research in this field, we\nsummarize open MMCL datasets and benchmarks, and discuss several promising\nfuture directions for investigation and development. We have also created a\nGitHub repository for indexing relevant MMCL papers and open resources\navailable at https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05352v2",
    "published_date": "2024-10-07 13:10:40 UTC",
    "updated_date": "2024-10-11 03:50:05 UTC"
  },
  {
    "arxiv_id": "2410.05351v1",
    "title": "Towards the generation of hierarchical attack models from cybersecurity vulnerabilities using language models",
    "authors": [
      "Kacper Sowka",
      "Vasile Palade",
      "Xiaorui Jiang",
      "Hesam Jadidbonab"
    ],
    "abstract": "This paper investigates the use of a pre-trained language model and siamese\nnetwork to discern sibling relationships between text-based cybersecurity\nvulnerability data. The ultimate purpose of the approach presented in this\npaper is towards the construction of hierarchical attack models based on a set\nof text descriptions characterising potential/observed vulnerabilities in a\ngiven system. Due to the nature of the data, and the uncertainty sensitive\nenvironment in which the problem is presented, a practically oriented soft\ncomputing approach is necessary. Therefore, a key focus of this work is to\ninvestigate practical questions surrounding the reliability of predicted links\ntowards the construction of such models, to which end conceptual and practical\nchallenges and solutions associated with the proposed approach are outlined,\nsuch as dataset complexity and stability of predictions. Accordingly, the\ncontributions of this paper focus on producing neural networks using a\npre-trained language model for predicting sibling relationships between\ncybersecurity vulnerabilities, then outlining how to apply this capability\ntowards the generation of hierarchical attack models. In addition, two data\nsampling mechanisms for tackling data complexity, and a consensus mechanism for\nreducing the amount of false positive predictions are outlined. Each of these\napproaches is compared and contrasted using empirical results from three sets\nof cybersecurity data to determine their effectiveness.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05351v1",
    "published_date": "2024-10-07 13:05:33 UTC",
    "updated_date": "2024-10-07 13:05:33 UTC"
  },
  {
    "arxiv_id": "2410.17269v1",
    "title": "FairFML: Fair Federated Machine Learning with a Case Study on Reducing Gender Disparities in Cardiac Arrest Outcome Prediction",
    "authors": [
      "Siqi Li",
      "Qiming Wu",
      "Xin Li",
      "Di Miao",
      "Chuan Hong",
      "Wenjun Gu",
      "Yuqing Shang",
      "Yohei Okada",
      "Michael Hao Chen",
      "Mengying Yan",
      "Yilin Ning",
      "Marcus Eng Hock Ong",
      "Nan Liu"
    ],
    "abstract": "Objective: Mitigating algorithmic disparities is a critical challenge in\nhealthcare research, where ensuring equity and fairness is paramount. While\nlarge-scale healthcare data exist across multiple institutions,\ncross-institutional collaborations often face privacy constraints, highlighting\nthe need for privacy-preserving solutions that also promote fairness.\n  Materials and Methods: In this study, we present Fair Federated Machine\nLearning (FairFML), a model-agnostic solution designed to reduce algorithmic\nbias in cross-institutional healthcare collaborations while preserving patient\nprivacy. As a proof of concept, we validated FairFML using a real-world\nclinical case study focused on reducing gender disparities in cardiac arrest\noutcome prediction.\n  Results: We demonstrate that the proposed FairFML framework enhances fairness\nin federated learning (FL) models without compromising predictive performance.\nOur findings show that FairFML improves model fairness by up to 65% compared to\nthe centralized model, while maintaining performance comparable to both local\nand centralized models, as measured by receiver operating characteristic\nanalysis.\n  Discussion and Conclusion: FairFML offers a promising and flexible solution\nfor FL collaborations, with its adaptability allowing seamless integration with\nvarious FL frameworks and models, from traditional statistical methods to deep\nlearning techniques. This makes FairFML a robust approach for developing fairer\nFL models across diverse clinical and biomedical applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17269v1",
    "published_date": "2024-10-07 13:02:04 UTC",
    "updated_date": "2024-10-07 13:02:04 UTC"
  },
  {
    "arxiv_id": "2410.04990v1",
    "title": "Stage-Wise and Prior-Aware Neural Speech Phase Prediction",
    "authors": [
      "Fei Liu",
      "Yang Ai",
      "Hui-Peng Du",
      "Ye-Xin Lu",
      "Rui-Chen Zheng",
      "Zhen-Hua Ling"
    ],
    "abstract": "This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase\nPrediction (SP-NSPP) model, which predicts the phase spectrum from input\namplitude spectrum by two-stage neural networks. In the initial\nprior-construction stage, we preliminarily predict a rough prior phase spectrum\nfrom the amplitude spectrum. The subsequent refinement stage transforms the\namplitude spectrum into a refined high-quality phase spectrum conditioned on\nthe prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone\nand adopt adversarial training by innovatively introducing a phase spectrum\ndiscriminator (PSD). To further improve the continuity of the refined phase, we\nalso incorporate a time-frequency integrated difference (TFID) loss in the\nrefinement stage. Experimental results confirm that, compared to neural\nnetwork-based no-prior phase prediction methods, the proposed SP-NSPP achieves\nhigher phase prediction accuracy, thanks to introducing the coarse phase priors\nand diverse training criteria. Compared to iterative phase estimation\nalgorithms, our proposed SP-NSPP does not require multiple rounds of staged\niterations, resulting in higher generation efficiency.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by SLT2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04990v1",
    "published_date": "2024-10-07 12:45:20 UTC",
    "updated_date": "2024-10-07 12:45:20 UTC"
  },
  {
    "arxiv_id": "2410.17268v1",
    "title": "SPikE-SSM: A Sparse, Precise, and Efficient Spiking State Space Model for Long Sequences Learning",
    "authors": [
      "Yan Zhong",
      "Ruoyu Zhao",
      "Chao Wang",
      "Qinghai Guo",
      "Jianguo Zhang",
      "Zhichao Lu",
      "Luziwei Leng"
    ],
    "abstract": "Spiking neural networks (SNNs) provide an energy-efficient solution by\nutilizing the spike-based and sparse nature of biological systems. Since the\nadvent of Transformers, SNNs have struggled to compete with artificial networks\non long sequential tasks, until the recent emergence of state space models\n(SSMs), which offer superior computational efficiency and modeling capability.\nHowever, applying the highly capable SSMs to SNNs for long sequences learning\nposes three major challenges: (1) The membrane potential is determined by the\npast spiking history of the neuron, leading to reduced efficiency for sequence\nmodeling in parallel computing scenarios. (2) Complex dynamics of biological\nspiking neurons are crucial for functionality but challenging to simulate and\nexploit effectively in large networks. (3) It is arduous to maintain high\nsparsity while achieving high accuracy for spiking neurons without resorting to\ndense computing, as utilized in artificial neuron-based SSMs. To address them,\nwe propose a sparse, precise and efficient spiking SSM framework, termed\nSPikE-SSM. For (1), we propose a boundary compression strategy (PMBC) to\naccelerate the inference of the spiking neuron model, enabling parallel\nprocessing for long sequence learning. For (2), we propose a novel and concise\nneuron model incorporating reset-refractory mechanism to leverage the inherent\ntemporal dimension for dynamic computing with biological interpretability. For\n(3), we hierarchically integrate the proposed neuron model to the original SSM\nblock, and enhance the dynamics of SPikE-SSM by incorporating trainable\nthresholds and refractory magnitudes to balance accuracy and sparsity.\nExtensive experiments verify the effectiveness and robustness of SPikE-SSM on\nthe long range arena benchmarks and large language dataset WikiText-103,\nshowing the potential of dynamic spiking neurons in efficient long sequence\nlearning.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17268v1",
    "published_date": "2024-10-07 12:20:38 UTC",
    "updated_date": "2024-10-07 12:20:38 UTC"
  },
  {
    "arxiv_id": "2410.04974v3",
    "title": "6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering",
    "authors": [
      "Zhongpai Gao",
      "Benjamin Planche",
      "Meng Zheng",
      "Anwesa Choudhuri",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "abstract": "Novel view synthesis has advanced significantly with the development of\nneural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,\nachieving high quality without compromising real-time rendering remains\nchallenging, particularly for physically-based ray tracing with view-dependent\neffects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D\nspatial-angular representation to better incorporate view-dependent effects,\nbut the Gaussian representation and control scheme are sub-optimal. In this\npaper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),\nwhich enhances color and opacity representations and leverages the additional\ndirectional information in the 6D space for optimized Gaussian control. Our\napproach is fully compatible with the 3DGS framework and significantly improves\nreal-time radiance field rendering by better modeling view-dependent effects\nand fine details. Experiments demonstrate that 6DGS significantly outperforms\n3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction\nof 66.5% Gaussian points compared to 3DGS. The project page is:\nhttps://gaozhongpai.github.io/6dgs/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.04974v3",
    "published_date": "2024-10-07 12:16:36 UTC",
    "updated_date": "2025-03-11 00:47:21 UTC"
  },
  {
    "arxiv_id": "2410.04968v1",
    "title": "Collaboration! Towards Robust Neural Methods for Routing Problems",
    "authors": [
      "Jianan Zhou",
      "Yaoxin Wu",
      "Zhiguang Cao",
      "Wen Song",
      "Jie Zhang",
      "Zhiqi Shen"
    ],
    "abstract": "Despite enjoying desirable efficiency and reduced reliance on domain\nexpertise, existing neural methods for vehicle routing problems (VRPs) suffer\nfrom severe robustness issues -- their performance significantly deteriorates\non clean instances with crafted perturbations. To enhance robustness, we\npropose an ensemble-based Collaborative Neural Framework (CNF) w.r.t. the\ndefense of neural VRP methods, which is crucial yet underexplored in the\nliterature. Given a neural VRP method, we adversarially train multiple models\nin a collaborative manner to synergistically promote robustness against\nattacks, while boosting standard generalization on clean instances. A neural\nrouter is designed to adeptly distribute training instances among models,\nenhancing overall load balancing and collaborative efficacy. Extensive\nexperiments verify the effectiveness and versatility of CNF in defending\nagainst various attacks across different neural VRP methods. Notably, our\napproach also achieves impressive out-of-distribution generalization on\nbenchmark instances.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04968v1",
    "published_date": "2024-10-07 12:12:51 UTC",
    "updated_date": "2024-10-07 12:12:51 UTC"
  },
  {
    "arxiv_id": "2410.04962v1",
    "title": "Activation Scaling for Steering and Interpreting Language Models",
    "authors": [
      "Niklas Stoehr",
      "Kevin Du",
      "Vésteinn Snæbjarnarson",
      "Robert West",
      "Ryan Cotterell",
      "Aaron Schein"
    ],
    "abstract": "Given the prompt \"Rome is in\", can we steer a language model to flip its\nprediction of an incorrect token \"France\" to a correct token \"Italy\" by only\nmultiplying a few relevant activation vectors with scalars? We argue that\nsuccessfully intervening on a model is a prerequisite for interpreting its\ninternal workings. Concretely, we establish a three-term objective: a\nsuccessful intervention should flip the correct with the wrong token and vice\nversa (effectiveness), and leave other tokens unaffected (faithfulness), all\nwhile being sparse (minimality). Using gradient-based optimization, this\nobjective lets us learn (and later evaluate) a specific kind of efficient and\ninterpretable intervention: activation scaling only modifies the signed\nmagnitude of activation vectors to strengthen, weaken, or reverse the steering\ndirections already encoded in the model. On synthetic tasks, this intervention\nperforms comparably with steering vectors in terms of effectiveness and\nfaithfulness, but is much more minimal allowing us to pinpoint interpretable\nmodel components. We evaluate activation scaling from different angles, compare\nperformance on different datasets, and make activation scalars a learnable\nfunction of the activation vectors themselves to generalize to varying-length\nprompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of the Association for Computational Linguistics: EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04962v1",
    "published_date": "2024-10-07 12:01:32 UTC",
    "updated_date": "2024-10-07 12:01:32 UTC"
  },
  {
    "arxiv_id": "2410.17267v1",
    "title": "Zero-Shot Vision-and-Language Navigation with Collision Mitigation in Continuous Environment",
    "authors": [
      "Seongjun Jeong",
      "Gi-Cheon Kang",
      "Joochan Kim",
      "Byoung-Tak Zhang"
    ],
    "abstract": "We propose the zero-shot Vision-and-Language Navigation with Collision\nMitigation (VLN-CM), which takes these considerations. VLN-CM is composed of\nfour modules and predicts the direction and distance of the next movement at\neach step. We utilize large foundation models for each modules. To select the\ndirection, we use the Attention Spot Predictor (ASP), View Selector (VS), and\nProgress Monitor (PM). The ASP employs a Large Language Model (e.g. ChatGPT) to\nsplit navigation instructions into attention spots, which are objects or scenes\nat the location to move to (e.g. a yellow door). The VS selects from panorama\nimages provided at 30-degree intervals the one that includes the attention\nspot, using CLIP similarity. We then choose the angle of the selected image as\nthe direction to move in. The PM uses a rule-based approach to decide which\nattention spot to focus on next, among multiple spots derived from the\ninstructions. If the similarity between the current attention spot and the\nvisual observations decreases consecutively at each step, the PM determines\nthat the agent has passed the current spot and moves on to the next one. For\nselecting the distance to move, we employed the Open Map Predictor (OMP). The\nOMP uses panorama depth information to predict an occupancy mask. We then\nselected a collision-free distance in the predicted direction based on the\noccupancy mask. We evaluated our method using the validation data of VLN-CE.\nOur approach showed better performance than several baseline methods, and the\nOPM was effective in mitigating collisions for the agent.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17267v1",
    "published_date": "2024-10-07 11:59:01 UTC",
    "updated_date": "2024-10-07 11:59:01 UTC"
  },
  {
    "arxiv_id": "2410.04949v2",
    "title": "Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law",
    "authors": [
      "Yongming Chen",
      "Miner Chen",
      "Ye Zhu",
      "Juan Pei",
      "Siyu Chen",
      "Yu Zhou",
      "Yi Wang",
      "Yifan Zhou",
      "Hao Li",
      "Songan Zhang"
    ],
    "abstract": "Court efficiency is vital for social stability. However, in most countries\naround the world, the grassroots courts face case backlogs, with decisions\nrelying heavily on judicial personnel's cognitive labor, lacking intelligent\ntools to improve efficiency. To address this issue, we propose an efficient law\narticle recommendation approach utilizing a Knowledge Graph (KG) and a Large\nLanguage Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge\nGraph (CLAKG) as a database to store current law statutes, historical case\ninformation, and correspondence between law articles and historical cases.\nAdditionally, we introduce an automated CLAKG construction method based on LLM.\nOn this basis, we propose a closed-loop law article recommendation method.\nFinally, through a series of experiments using judgment documents from the\nwebsite \"China Judgements Online\", we have improved the accuracy of law article\nrecommendation in cases from 0.549 to 0.694, demonstrating that our proposed\nmethod significantly outperforms baseline approaches.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04949v2",
    "published_date": "2024-10-07 11:45:04 UTC",
    "updated_date": "2025-03-09 05:10:23 UTC"
  },
  {
    "arxiv_id": "2410.04946v1",
    "title": "Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness",
    "authors": [
      "Borja Carrillo Perez"
    ],
    "abstract": "In an era where maritime infrastructures are crucial, advanced situational\nawareness solutions are increasingly important. The use of optical camera\nsystems can allow real-time usage of maritime footage. This thesis presents an\ninvestigation into leveraging deep learning and computer vision to advance\nreal-time ship recognition and georeferencing for the improvement of maritime\nsituational awareness. A novel dataset, ShipSG, is introduced, containing 3,505\nimages and 11,625 ship masks with corresponding class and geographic position.\nAfter an exploration of state-of-the-art, a custom real-time segmentation\narchitecture, ScatYOLOv8+CBAM, is designed for the NVIDIA Jetson AGX Xavier\nembedded system. This architecture adds the 2D scattering transform and\nattention mechanisms to YOLOv8, achieving an mAP of 75.46% and an 25.3 ms per\nframe, outperforming state-of-the-art methods by over 5%. To improve small and\ndistant ship recognition in high-resolution images on embedded systems, an\nenhanced slicing mechanism is introduced, improving mAP by 8% to 11%.\nAdditionally, a georeferencing method is proposed, achieving positioning errors\nof 18 m for ships up to 400 m away and 44 m for ships between 400 m and 1200 m.\nThe findings are also applied in real-world scenarios, such as the detection of\nabnormal ship behaviour, camera integrity assessment and 3D reconstruction. The\napproach of this thesis outperforms existing methods and provides a framework\nfor integrating recognized and georeferenced ships into real-time systems,\nenhancing operational effectiveness and decision-making for maritime\nstakeholders. This thesis contributes to the maritime computer vision field by\nestablishing a benchmark for ship segmentation and georeferencing research,\ndemonstrating the viability of deep-learning-based recognition and\ngeoreferencing methods for real-time maritime monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04946v1",
    "published_date": "2024-10-07 11:43:42 UTC",
    "updated_date": "2024-10-07 11:43:42 UTC"
  },
  {
    "arxiv_id": "2410.04941v4",
    "title": "Detecting and Approximating Redundant Computational Blocks in Neural Networks",
    "authors": [
      "Irene Cannistraci",
      "Emanuele Rodolà",
      "Bastian Rieck"
    ],
    "abstract": "Deep neural networks often learn similar internal representations, both\nacross different models and within their own layers. While inter-network\nsimilarities have enabled techniques such as model stitching and merging,\nintra-network similarities present new opportunities for designing more\nefficient architectures. In this paper, we investigate the emergence of these\ninternal similarities across different layers in diverse neural architectures,\nshowing that similarity patterns emerge independently of the datataset used. We\nintroduce a simple metric, Block Redundancy, to detect redundant blocks,\nproviding a foundation for future architectural optimization methods. Building\non this, we propose Redundant Blocks Approximation (RBA), a general framework\nthat identifies and approximates one or more redundant computational blocks\nusing simpler transformations. We show that the transformation $\\mathcal{T}$\nbetween two representations can be efficiently computed in closed-form, and it\nis enough to replace the redundant blocks from the network. RBA reduces model\nparameters and time complexity while maintaining good performance. We validate\nour method on classification tasks in the vision domain using a variety of\npretrained foundational models and datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 10 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.04941v4",
    "published_date": "2024-10-07 11:35:24 UTC",
    "updated_date": "2024-10-11 08:43:56 UTC"
  },
  {
    "arxiv_id": "2410.11862v1",
    "title": "Towards using Reinforcement Learning for Scaling and Data Replication in Cloud Systems",
    "authors": [
      "Riad Mokadem",
      "Fahem Arar",
      "Djamel Eddine Zegour"
    ],
    "abstract": "Given its intuitive nature, many Cloud providers opt for threshold-based data\nreplication to enable automatic resource scaling. However, setting thresholds\neffectively needs human intervention to calibrate thresholds for each metric\nand requires a deep knowledge of current workload trends, which can be\nchallenging to achieve. Reinforcement learning is used in many areas related to\nthe Cloud Computing, and it is a promising field to get automatic data\nreplication strategies. In this work, we survey data replication strategies and\ndata scaling based on reinforcement learning (RL).",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11862v1",
    "published_date": "2024-10-07 11:32:35 UTC",
    "updated_date": "2024-10-07 11:32:35 UTC"
  },
  {
    "arxiv_id": "2410.04936v1",
    "title": "Training Interactive Agent in Large FPS Game Map with Rule-enhanced Reinforcement Learning",
    "authors": [
      "Chen Zhang",
      "Huan Hu",
      "Yuan Zhou",
      "Qiyang Cao",
      "Ruochen Liu",
      "Wenya Wei",
      "Elvis S. Liu"
    ],
    "abstract": "In the realm of competitive gaming, 3D first-person shooter (FPS) games have\ngained immense popularity, prompting the development of game AI systems to\nenhance gameplay. However, deploying game AI in practical scenarios still poses\nchallenges, particularly in large-scale and complex FPS games. In this paper,\nwe focus on the practical deployment of game AI in the online multiplayer\ncompetitive 3D FPS game called Arena Breakout, developed by Tencent Games. We\npropose a novel gaming AI system named Private Military Company Agent (PMCA),\nwhich is interactable within a large game map and engages in combat with\nplayers while utilizing tactical advantages provided by the surrounding\nterrain.\n  To address the challenges of navigation and combat in modern 3D FPS games, we\nintroduce a method that combines navigation mesh (Navmesh) and shooting-rule\nwith deep reinforcement learning (NSRL). The integration of Navmesh enhances\nthe agent's global navigation capabilities while shooting behavior is\ncontrolled using rule-based methods to ensure controllability. NSRL employs a\nDRL model to predict when to enable the navigation mesh, resulting in a diverse\nrange of behaviors for the game AI. Customized rewards for human-like behaviors\nare also employed to align PMCA's behavior with that of human players.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04936v1",
    "published_date": "2024-10-07 11:27:45 UTC",
    "updated_date": "2024-10-07 11:27:45 UTC"
  },
  {
    "arxiv_id": "2410.04931v1",
    "title": "The Role of Governments in Increasing Interconnected Post-Deployment Monitoring of AI",
    "authors": [
      "Merlin Stein",
      "Jamie Bernardi",
      "Connor Dunlop"
    ],
    "abstract": "Language-based AI systems are diffusing into society, bringing positive and\nnegative impacts. Mitigating negative impacts depends on accurate impact\nassessments, drawn from an empirical evidence base that makes causal\nconnections between AI usage and impacts. Interconnected post-deployment\nmonitoring combines information about model integration and use, application\nuse, and incidents and impacts. For example, inference time monitoring of\nchain-of-thought reasoning can be combined with long-term monitoring of\nsectoral AI diffusion, impacts and incidents. Drawing on information sharing\nmechanisms in other industries, we highlight example data sources and specific\ndata points that governments could collect to inform AI risk management.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.04931v1",
    "published_date": "2024-10-07 11:24:29 UTC",
    "updated_date": "2024-10-07 11:24:29 UTC"
  },
  {
    "arxiv_id": "2410.17266v1",
    "title": "Temporal Relational Reasoning of Large Language Models for Detecting Stock Portfolio Crashes",
    "authors": [
      "Kelvin J. L. Koa",
      "Yunshan Ma",
      "Ritchie Ng",
      "Huanhuan Zheng",
      "Tat-Seng Chua"
    ],
    "abstract": "Stock portfolios are often exposed to rare consequential events (e.g., 2007\nglobal financial crisis, 2020 COVID-19 stock market crash), as they do not have\nenough historical information to learn from. Large Language Models (LLMs) now\npresent a possible tool to tackle this problem, as they can generalize across\ntheir large corpus of training data and perform zero-shot reasoning on new\nevents, allowing them to detect possible portfolio crash events without\nrequiring specific training data. However, detecting portfolio crashes is a\ncomplex problem that requires more than basic reasoning abilities. Investors\nneed to dynamically process the impact of each new information found in the\nnews articles, analyze the the relational network of impacts across news events\nand portfolio stocks, as well as understand the temporal context between\nimpacts across time-steps, in order to obtain the overall aggregated effect on\nthe target portfolio. In this work, we propose an algorithmic framework named\nTemporal Relational Reasoning (TRR). It seeks to emulate the spectrum of human\ncognitive capabilities used for complex problem-solving, which include\nbrainstorming, memory, attention and reasoning. Through extensive experiments,\nwe show that TRR is able to outperform state-of-the-art solutions on detecting\nstock portfolio crashes, and demonstrate how each of the proposed components\nhelp to contribute to its performance through an ablation study. Additionally,\nwe further explore the possible applications of TRR by extending it to other\nrelated complex problems, such as the detection of possible global crisis\nevents in Macroeconomics.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17266v1",
    "published_date": "2024-10-07 11:15:52 UTC",
    "updated_date": "2024-10-07 11:15:52 UTC"
  },
  {
    "arxiv_id": "2410.04916v1",
    "title": "Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models",
    "authors": [
      "Xiao Yang",
      "Kai Zhou",
      "Yuni Lai",
      "Gaolei Li"
    ],
    "abstract": "With the trend of large graph learning models, business owners tend to employ\na model provided by a third party to deliver business services to users.\nHowever, these models might be backdoored, and malicious users can submit\ntrigger-embedded inputs to manipulate the model predictions. Current graph\nbackdoor defenses have several limitations: 1) depending on model-related\ndetails, 2) requiring additional model fine-tuning, and 3) relying upon extra\nexplainability tools, all of which are infeasible under stringent privacy\npolicies. To address those limitations, we propose GraphProt, which allows\nresource-constrained business owners to rely on third parties to avoid backdoor\nattacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and\nonly relies on the input graph. The key insight is to leverage subgraph\ninformation for prediction, thereby mitigating backdoor effects induced by\ntriggers. GraphProt comprises two components: clustering-based trigger\nelimination and robust subgraph ensemble. Specifically, we first propose\nfeature-topology clustering that aims to remove most of the anomalous subgraphs\n(triggers). Moreover, we design subgraph sampling strategies based on\nfeature-topology clustering to build a robust classifier via majority vote.\nExperimental results across three backdoor attacks and six benchmark datasets\ndemonstrate that GraphProt significantly reduces the backdoor attack success\nrate while preserving the model accuracy on regular graph classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "F.2.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04916v1",
    "published_date": "2024-10-07 11:04:38 UTC",
    "updated_date": "2024-10-07 11:04:38 UTC"
  },
  {
    "arxiv_id": "2410.05349v1",
    "title": "SoK: Towards Security and Safety of Edge AI",
    "authors": [
      "Tatjana Wingarz",
      "Anne Lauscher",
      "Janick Edinger",
      "Dominik Kaaser",
      "Stefan Schulte",
      "Mathias Fischer"
    ],
    "abstract": "Advanced AI applications have become increasingly available to a broad\naudience, e.g., as centrally managed large language models (LLMs). Such\ncentralization is both a risk and a performance bottleneck - Edge AI promises\nto be a solution to these problems. However, its decentralized approach raises\nadditional challenges regarding security and safety. In this paper, we argue\nthat both of these aspects are critical for Edge AI, and even more so, their\nintegration. Concretely, we survey security and safety threats, summarize\nexisting countermeasures, and collect open challenges as a call for more\nresearch in this area.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05349v1",
    "published_date": "2024-10-07 10:52:53 UTC",
    "updated_date": "2024-10-07 10:52:53 UTC"
  },
  {
    "arxiv_id": "2410.05347v1",
    "title": "ResTNet: Defense against Adversarial Policies via Transformer in Computer Go",
    "authors": [
      "Tai-Lin Wu",
      "Ti-Rong Wu",
      "Chung-Chin Shih",
      "Yan-Ru Ju",
      "I-Chen Wu"
    ],
    "abstract": "Although AlphaZero has achieved superhuman levels in Go, recent research has\nhighlighted its vulnerability in particular situations requiring a more\ncomprehensive understanding of the entire board. To address this challenge,\nthis paper introduces ResTNet, a network that interleaves residual networks and\nTransformer. Our empirical experiments demonstrate several advantages of using\nResTNet. First, it not only improves playing strength but also enhances the\nability of global information. Second, it defends against an adversary Go\nprogram, called cyclic-adversary, tailor-made for attacking AlphaZero\nalgorithms, significantly reducing the average probability of being attacked\nrate from 70.44% to 23.91%. Third, it improves the accuracy from 59.15% to\n80.01% in correctly recognizing ladder patterns, which are one of the\nchallenging patterns for Go AIs. Finally, ResTNet offers a potential\nexplanation of the decision-making process and can also be applied to other\ngames like Hex. To the best of our knowledge, ResTNet is the first to integrate\nresidual networks and Transformer in the context of AlphaZero for board games,\nsuggesting a promising direction for enhancing AlphaZero's global\nunderstanding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05347v1",
    "published_date": "2024-10-07 10:17:24 UTC",
    "updated_date": "2024-10-07 10:17:24 UTC"
  },
  {
    "arxiv_id": "2410.04884v1",
    "title": "Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models",
    "authors": [
      "Dehong Kong",
      "Siyuan Liang",
      "Xiaopeng Zhu",
      "Yuansheng Zhong",
      "Wenqi Ren"
    ],
    "abstract": "Visual language pre-training (VLP) models have demonstrated significant\nsuccess across various domains, yet they remain vulnerable to adversarial\nattacks. Addressing these adversarial vulnerabilities is crucial for enhancing\nsecurity in multimodal learning. Traditionally, adversarial methods targeting\nVLP models involve simultaneously perturbing images and text. However, this\napproach faces notable challenges: first, adversarial perturbations often fail\nto translate effectively into real-world scenarios; second, direct\nmodifications to the text are conspicuously visible. To overcome these\nlimitations, we propose a novel strategy that exclusively employs image patches\nfor attacks, thus preserving the integrity of the original text. Our method\nleverages prior knowledge from diffusion models to enhance the authenticity and\nnaturalness of the perturbations. Moreover, to optimize patch placement and\nimprove the efficacy of our attacks, we utilize the cross-attention mechanism,\nwhich encapsulates intermodal interactions by generating attention maps to\nguide strategic patch placements. Comprehensive experiments conducted in a\nwhite-box setting for image-to-text scenarios reveal that our proposed method\nsignificantly outperforms existing techniques, achieving a 100% attack success\nrate. Additionally, it demonstrates commendable performance in transfer tasks\ninvolving text-to-image configurations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by Visual Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2410.04884v1",
    "published_date": "2024-10-07 10:06:01 UTC",
    "updated_date": "2024-10-07 10:06:01 UTC"
  },
  {
    "arxiv_id": "2410.04878v1",
    "title": "Leveraging Grammar Induction for Language Understanding and Generation",
    "authors": [
      "Jushi Kai",
      "Shengyuan Hou",
      "Yusheng Huang",
      "Zhouhan Lin"
    ],
    "abstract": "Grammar induction has made significant progress in recent years. However, it\nis not clear how the application of induced grammar could enhance practical\nperformance in downstream tasks. In this work, we introduce an unsupervised\ngrammar induction method for language understanding and generation. We\nconstruct a grammar parser to induce constituency structures and dependency\nrelations, which is simultaneously trained on downstream tasks without\nadditional syntax annotations. The induced grammar features are subsequently\nincorporated into Transformer as a syntactic mask to guide self-attention. We\nevaluate and apply our method to multiple machine translation tasks and natural\nlanguage understanding tasks. Our method demonstrates superior performance\ncompared to the original Transformer and other models enhanced with external\nparsers. Experimental results indicate that our method is effective in both\nfrom-scratch and pre-trained scenarios. Additionally, our research highlights\nthe contribution of explicitly modeling the grammatical structure of texts to\nneural network models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.04878v1",
    "published_date": "2024-10-07 09:57:59 UTC",
    "updated_date": "2024-10-07 09:57:59 UTC"
  },
  {
    "arxiv_id": "2410.05346v3",
    "title": "AnyAttack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models",
    "authors": [
      "Jiaming Zhang",
      "Junhong Ye",
      "Xingjun Ma",
      "Yige Li",
      "Yunfan Yang",
      "Yunhao Chen",
      "Jitao Sang",
      "Dit-Yan Yeung"
    ],
    "abstract": "Due to their multimodal capabilities, Vision-Language Models (VLMs) have\nfound numerous impactful applications in real-world scenarios. However, recent\nstudies have revealed that VLMs are vulnerable to image-based adversarial\nattacks. Traditional targeted adversarial attacks require specific targets and\nlabels, limiting their real-world impact.We present AnyAttack, a\nself-supervised framework that transcends the limitations of conventional\nattacks through a novel foundation model approach. By pre-training on the\nmassive LAION-400M dataset without label supervision, AnyAttack achieves\nunprecedented flexibility - enabling any image to be transformed into an attack\nvector targeting any desired output across different VLMs.This approach\nfundamentally changes the threat landscape, making adversarial capabilities\naccessible at an unprecedented scale. Our extensive validation across five\nopen-source VLMs (CLIP, BLIP, BLIP2, InstructBLIP, and MiniGPT-4) demonstrates\nAnyAttack's effectiveness across diverse multimodal tasks. Most concerning,\nAnyAttack seamlessly transfers to commercial systems including Google Gemini,\nClaude Sonnet, Microsoft Copilot and OpenAI GPT, revealing a systemic\nvulnerability requiring immediate attention.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.05346v3",
    "published_date": "2024-10-07 09:45:18 UTC",
    "updated_date": "2025-03-28 02:55:23 UTC"
  },
  {
    "arxiv_id": "2410.17265v1",
    "title": "Federated brain tumor segmentation: an extensive benchmark",
    "authors": [
      "Matthis Manthe",
      "Stefan Duffner",
      "Carole Lartizien"
    ],
    "abstract": "Recently, federated learning has raised increasing interest in the medical\nimage analysis field due to its ability to aggregate multi-center data with\nprivacy-preserving properties. A large amount of federated training schemes\nhave been published, which we categorize into global (one final model),\npersonalized (one model per institution) or hybrid (one model per cluster of\ninstitutions) methods. However, their applicability on the recently published\nFederated Brain Tumor Segmentation 2022 dataset has not been explored yet. We\npropose an extensive benchmark of federated learning algorithms from all three\nclasses on this task. While standard FedAvg already performs very well, we show\nthat some methods from each category can bring a slight performance improvement\nand potentially limit the final model(s) bias toward the predominant data\ndistribution of the federation. Moreover, we provide a deeper understanding of\nthe behaviour of federated learning on this task through alternative ways of\ndistributing the pooled dataset among institutions, namely an Independent and\nIdentical Distributed (IID) setup, and a limited data setup.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17265v1",
    "published_date": "2024-10-07 09:32:19 UTC",
    "updated_date": "2024-10-07 09:32:19 UTC"
  },
  {
    "arxiv_id": "2410.04865v1",
    "title": "Mastering Chinese Chess AI (Xiangqi) Without Search",
    "authors": [
      "Yu Chen",
      "Juntong Lin",
      "Zhichao Shu"
    ],
    "abstract": "We have developed a high-performance Chinese Chess AI that operates without\nreliance on search algorithms. This AI has demonstrated the capability to\ncompete at a level commensurate with the top 0.1\\% of human players. By\neliminating the search process typically associated with such systems, this AI\nachieves a Queries Per Second (QPS) rate that exceeds those of systems based on\nthe Monte Carlo Tree Search (MCTS) algorithm by over a thousandfold and\nsurpasses those based on the AlphaBeta pruning algorithm by more than a\nhundredfold. The AI training system consists of two parts: supervised learning\nand reinforcement learning. Supervised learning provides an initial human-like\nChinese chess AI, while reinforcement learning, based on supervised learning,\nelevates the strength of the entire AI to a new level. Based on this training\nsystem, we carried out enough ablation experiments and discovered that 1. The\nsame parameter amount of Transformer architecture has a higher performance than\nCNN on Chinese chess; 2. Possible moves of both sides as features can greatly\nimprove the training process; 3. Selective opponent pool, compared to pure\nself-play training, results in a faster improvement curve and a higher strength\nlimit. 4. Value Estimation with Cutoff(VECT) improves the original PPO\nalgorithm training process and we will give the explanation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04865v1",
    "published_date": "2024-10-07 09:27:51 UTC",
    "updated_date": "2024-10-07 09:27:51 UTC"
  },
  {
    "arxiv_id": "2410.04855v1",
    "title": "Unsupervised Skill Discovery for Robotic Manipulation through Automatic Task Generation",
    "authors": [
      "Paul Jansonnie",
      "Bingbing Wu",
      "Julien Perez",
      "Jan Peters"
    ],
    "abstract": "Learning skills that interact with objects is of major importance for robotic\nmanipulation. These skills can indeed serve as an efficient prior for solving\nvarious manipulation tasks. We propose a novel Skill Learning approach that\ndiscovers composable behaviors by solving a large and diverse number of\nautonomously generated tasks. Our method learns skills allowing the robot to\nconsistently and robustly interact with objects in its environment. The\ndiscovered behaviors are embedded in primitives which can be composed with\nHierarchical Reinforcement Learning to solve unseen manipulation tasks. In\nparticular, we leverage Asymmetric Self-Play to discover behaviors and\nMultiplicative Compositional Policies to embed them. We compare our method to\nSkill Learning baselines and find that our skills are more interactive.\nFurthermore, the learned skills can be used to solve a set of unseen\nmanipulation tasks, in simulation as well as on a real robotic platform.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at the 2024 IEEE-RAS International Conference on Humanoid\n  Robots",
    "pdf_url": "http://arxiv.org/pdf/2410.04855v1",
    "published_date": "2024-10-07 09:19:13 UTC",
    "updated_date": "2024-10-07 09:19:13 UTC"
  },
  {
    "arxiv_id": "2410.04853v1",
    "title": "TimeCNN: Refining Cross-Variable Interaction on Time Point for Time Series Forecasting",
    "authors": [
      "Ao Hu",
      "Dongkai Wang",
      "Yong Dai",
      "Shiyi Qi",
      "Liangjian Wen",
      "Jun Wang",
      "Zhi Chen",
      "Xun Zhou",
      "Zenglin Xu",
      "Jiang Duan"
    ],
    "abstract": "Time series forecasting is extensively applied across diverse domains.\nTransformer-based models demonstrate significant potential in modeling\ncross-time and cross-variable interaction. However, we notice that the\ncross-variable correlation of multivariate time series demonstrates\nmultifaceted (positive and negative correlations) and dynamic progression over\ntime, which is not well captured by existing Transformer-based models. To\naddress this issue, we propose a TimeCNN model to refine cross-variable\ninteractions to enhance time series forecasting. Its key innovation is\ntimepoint-independent, where each time point has an independent convolution\nkernel, allowing each time point to have its independent model to capture\nrelationships among variables. This approach effectively handles both positive\nand negative correlations and adapts to the evolving nature of variable\nrelationships over time. Extensive experiments conducted on 12 real-world\ndatasets demonstrate that TimeCNN consistently outperforms state-of-the-art\nmodels. Notably, our model achieves significant reductions in computational\nrequirements (approximately 60.46%) and parameter count (about 57.50%), while\ndelivering inference speeds 3 to 4 times faster than the benchmark iTransformer\nmodel",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04853v1",
    "published_date": "2024-10-07 09:16:58 UTC",
    "updated_date": "2024-10-07 09:16:58 UTC"
  },
  {
    "arxiv_id": "2410.04844v4",
    "title": "PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing",
    "authors": [
      "Feng Tian",
      "Yixuan Li",
      "Yichao Yan",
      "Shanyan Guan",
      "Yanhao Ge",
      "Xiaokang Yang"
    ],
    "abstract": "In the field of image editing, three core challenges persist:\ncontrollability, background preservation, and efficiency. Inversion-based\nmethods rely on time-consuming optimization to preserve the features of the\ninitial images, which results in low efficiency due to the requirement for\nextensive network inference. Conversely, inversion-free methods lack\ntheoretical support for background similarity, as they circumvent the issue of\nmaintaining initial features to achieve efficiency. As a consequence, none of\nthese methods can achieve both high efficiency and background consistency. To\ntackle the challenges and the aforementioned disadvantages, we introduce\nPostEdit, a method that incorporates a posterior scheme to govern the diffusion\nsampling process. Specifically, a corresponding measurement term related to\nboth the initial features and Langevin dynamics is introduced to optimize the\nestimated image generated by the given target prompt. Extensive experimental\nresults indicate that the proposed PostEdit achieves state-of-the-art editing\nperformance while accurately preserving unedited regions. Furthermore, the\nmethod is both inversion- and training-free, necessitating approximately 1.5\nseconds and 18 GB of GPU memory to generate high-quality results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.04844v4",
    "published_date": "2024-10-07 09:04:50 UTC",
    "updated_date": "2025-03-06 03:03:07 UTC"
  },
  {
    "arxiv_id": "2410.11861v1",
    "title": "Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation",
    "authors": [
      "Takato Hayashi",
      "Ryusei Kimura",
      "Ryo Ishii",
      "Shogo Okada"
    ],
    "abstract": "Automatic rapport estimation in social interactions is a central component of\naffective computing. Recent reports have shown that the estimation performance\nof rapport in initial interactions can be improved by using the participant's\npersonality traits as the model's input. In this study, we investigate whether\nthis findings applies to interactions between friends by developing rapport\nestimation models that utilize nonverbal cues (audio and facial expressions) as\ninputs. Our experimental results show that adding Big Five features (BFFs) to\nnonverbal features can improve the estimation performance of self-reported\nrapport in dyadic interactions between friends. Next, we demystify how BFFs\nimprove the estimation performance of rapport through a comparative analysis\nbetween models with and without BFFs. We decompose rapport ratings into\nperceiver effects (people's tendency to rate other people), target effects\n(people's tendency to be rated by other people), and relationship effects\n(people's unique ratings for a specific person) using the social relations\nmodel. We then analyze the extent to which BFFs contribute to capturing each\neffect. Our analysis demonstrates that the perceiver's and the target's BFFs\nlead estimation models to capture the perceiver and the target effects,\nrespectively. Furthermore, our experimental results indicate that the\ncombinations of facial expression features and BFFs achieve best estimation\nperformances not only in estimating rapport ratings, but also in estimating\nthree effects. Our study is the first step toward understanding why\npersonality-aware estimation models of interpersonal perception accomplish high\nestimation performance.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11861v1",
    "published_date": "2024-10-07 08:52:33 UTC",
    "updated_date": "2024-10-07 08:52:33 UTC"
  },
  {
    "arxiv_id": "2410.04833v1",
    "title": "Multimodal Fusion Strategies for Mapping Biophysical Landscape Features",
    "authors": [
      "Lucia Gordon",
      "Nico Lang",
      "Catherine Ressijac",
      "Andrew Davies"
    ],
    "abstract": "Multimodal aerial data are used to monitor natural systems, and machine\nlearning can significantly accelerate the classification of landscape features\nwithin such imagery to benefit ecology and conservation. It remains\nunder-explored, however, how these multiple modalities ought to be fused in a\ndeep learning model. As a step towards filling this gap, we study three\nstrategies (Early fusion, Late fusion, and Mixture of Experts) for fusing\nthermal, RGB, and LiDAR imagery using a dataset of spatially-aligned\northomosaics in these three modalities. In particular, we aim to map three\necologically-relevant biophysical landscape features in African savanna\necosystems: rhino middens, termite mounds, and water. The three fusion\nstrategies differ in whether the modalities are fused early or late, and if\nlate, whether the model learns fixed weights per modality for each class or\ngenerates weights for each class adaptively, based on the input. Overall, the\nthree methods have similar macro-averaged performance with Late fusion\nachieving an AUC of 0.698, but their per-class performance varies strongly,\nwith Early fusion achieving the best recall for middens and water and Mixture\nof Experts achieving the best recall for mounds.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures, ECCV 2024 Workshop in CV for Ecology",
    "pdf_url": "http://arxiv.org/pdf/2410.04833v1",
    "published_date": "2024-10-07 08:40:29 UTC",
    "updated_date": "2024-10-07 08:40:29 UTC"
  },
  {
    "arxiv_id": "2410.17262v2",
    "title": "EmoGene: Audio-Driven Emotional 3D Talking-Head Generation",
    "authors": [
      "Wenqing Wang",
      "Yun Fu"
    ],
    "abstract": "Audio-driven talking-head generation is a crucial and useful technology for\nvirtual human interaction and film-making. While recent advances have focused\non improving image fidelity and lip synchronization, generating accurate\nemotional expressions remains underexplored. In this paper, we introduce\nEmoGene, a novel framework for synthesizing high-fidelity, audio-driven video\nportraits with accurate emotional expressions. Our approach employs a\nvariational autoencoder (VAE)-based audio-to-motion module to generate facial\nlandmarks, which are concatenated with emotional embedding in a\nmotion-to-emotion module to produce emotional landmarks. These landmarks drive\na Neural Radiance Fields (NeRF)-based emotion-to-video module to render\nrealistic emotional talking-head videos. Additionally, we propose a pose\nsampling method to generate natural idle-state (non-speaking) videos for silent\naudio inputs. Extensive experiments demonstrate that EmoGene outperforms\nprevious methods in generating high-fidelity emotional talking-head videos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the 2025 IEEE 19th International Conference on Automatic\n  Face and Gesture Recognition (FG)",
    "pdf_url": "http://arxiv.org/pdf/2410.17262v2",
    "published_date": "2024-10-07 08:23:05 UTC",
    "updated_date": "2025-05-01 21:31:16 UTC"
  },
  {
    "arxiv_id": "2410.05345v1",
    "title": "Trained Models Tell Us How to Make Them Robust to Spurious Correlation without Group Annotation",
    "authors": [
      "Mahdi Ghaznavi",
      "Hesam Asadollahzadeh",
      "Fahimeh Hosseini Noohdani",
      "Soroush Vafaie Tabar",
      "Hosein Hasani",
      "Taha Akbari Alvanagh",
      "Mohammad Hossein Rohban",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Classifiers trained with Empirical Risk Minimization (ERM) tend to rely on\nattributes that have high spurious correlation with the target. This can\ndegrade the performance on underrepresented (or 'minority') groups that lack\nthese attributes, posing significant challenges for both out-of-distribution\ngeneralization and fairness objectives. Many studies aim to enhance robustness\nto spurious correlation, but they sometimes depend on group annotations for\ntraining. Additionally, a common limitation in previous research is the\nreliance on group-annotated validation datasets for model selection. This\nconstrains their applicability in situations where the nature of the spurious\ncorrelation is not known, or when group labels for certain spurious attributes\nare not available. To enhance model robustness with minimal group annotation\nassumptions, we propose Environment-based Validation and Loss-based Sampling\n(EVaLS). It uses the losses from an ERM-trained model to construct a balanced\ndataset of high-loss and low-loss samples, mitigating group imbalance in data.\nThis significantly enhances robustness to group shifts when equipped with a\nsimple post-training last layer retraining. By using environment inference\nmethods to create diverse environments with correlation shifts, EVaLS can\npotentially eliminate the need for group annotation in validation data. In this\ncontext, the worst environment accuracy acts as a reliable surrogate throughout\nthe retraining process for tuning hyperparameters and finding a model that\nperforms well across diverse group shifts. EVaLS effectively achieves group\nrobustness, showing that group annotation is not necessary even for validation.\nIt is a fast, straightforward, and effective approach that reaches near-optimal\nworst group accuracy without needing group annotations, marking a new chapter\nin the robustness of trained models against spurious correlation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.05345v1",
    "published_date": "2024-10-07 08:17:44 UTC",
    "updated_date": "2024-10-07 08:17:44 UTC"
  },
  {
    "arxiv_id": "2410.04817v1",
    "title": "Resource-Efficient Multiview Perception: Integrating Semantic Masking with Masked Autoencoders",
    "authors": [
      "Kosta Dakic",
      "Kanchana Thilakarathna",
      "Rodrigo N. Calheiros",
      "Teng Joon Lim"
    ],
    "abstract": "Multiview systems have become a key technology in modern computer vision,\noffering advanced capabilities in scene understanding and analysis. However,\nthese systems face critical challenges in bandwidth limitations and\ncomputational constraints, particularly for resource-limited camera nodes like\ndrones. This paper presents a novel approach for communication-efficient\ndistributed multiview detection and tracking using masked autoencoders (MAEs).\nWe introduce a semantic-guided masking strategy that leverages pre-trained\nsegmentation models and a tunable power function to prioritize informative\nimage regions. This approach, combined with an MAE, reduces communication\noverhead while preserving essential visual information. We evaluate our method\non both virtual and real-world multiview datasets, demonstrating comparable\nperformance in terms of detection and tracking performance metrics compared to\nstate-of-the-art techniques, even at high masking ratios. Our selective masking\nalgorithm outperforms random masking, maintaining higher accuracy and precision\nas the masking ratio increases. Furthermore, our approach achieves a\nsignificant reduction in transmission data volume compared to baseline methods,\nthereby balancing multiview tracking performance with communication efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2410.04817v1",
    "published_date": "2024-10-07 08:06:41 UTC",
    "updated_date": "2024-10-07 08:06:41 UTC"
  },
  {
    "arxiv_id": "2410.04815v2",
    "title": "A Review of BioTree Construction in the Context of Information Fusion: Priors, Methods, Applications and Trends",
    "authors": [
      "Zelin Zang",
      "Yongjie Xu",
      "Chenrui Duan",
      "Yue Yuan",
      "Jinlin Wu",
      "Zhen Lei",
      "Stan Z. Li"
    ],
    "abstract": "Biological tree (BioTree) analysis is a foundational tool in biology,\nenabling the exploration of evolutionary and differentiation relationships\namong organisms, genes, and cells. Traditional tree construction methods, while\ninstrumental in early research, face significant challenges in handling the\ngrowing complexity and scale of modern biological data, particularly in\nintegrating multimodal datasets. Advances in deep learning (DL) offer\ntransformative opportunities by enabling the fusion of biological prior\nknowledge with data-driven models. These approaches address key limitations of\ntraditional methods, facilitating the construction of more accurate and\ninterpretable BioTrees. This review highlights critical biological priors\nessential for phylogenetic and differentiation tree analyses and explores\nstrategies for integrating these priors into DL models to enhance accuracy and\ninterpretability. Additionally, the review systematically examines commonly\nused data modalities and databases, offering a valuable resource for developing\nand evaluating multimodal fusion models. Traditional tree construction methods\nare critically assessed, focusing on their biological assumptions, technical\nlimitations, and scalability issues. Recent advancements in DL-based tree\ngeneration methods are reviewed, emphasizing their innovative approaches to\nmultimodal integration and prior knowledge incorporation. Finally, the review\ndiscusses diverse applications of BioTrees in various biological disciplines,\nfrom phylogenetics to developmental biology, and outlines future trends in\nleveraging DL to advance BioTree research. By addressing the challenges of data\ncomplexity and prior knowledge integration, this review aims to inspire\ninterdisciplinary innovation at the intersection of biology and DL.",
    "categories": [
      "q-bio.PE",
      "cs.AI"
    ],
    "primary_category": "q-bio.PE",
    "comment": "115 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04815v2",
    "published_date": "2024-10-07 08:00:41 UTC",
    "updated_date": "2025-02-15 07:20:42 UTC"
  },
  {
    "arxiv_id": "2410.04814v2",
    "title": "Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data",
    "authors": [
      "Manuel Brenner",
      "Elias Weber",
      "Georgia Koppe",
      "Daniel Durstewitz"
    ],
    "abstract": "In science, we are often interested in obtaining a generative model of the\nunderlying system dynamics from observed time series. While powerful methods\nfor dynamical systems reconstruction (DSR) exist when data come from a single\ndomain, how to best integrate data from multiple dynamical regimes and leverage\nit for generalization is still an open question. This becomes particularly\nimportant when individual time series are short, and group-level information\nmay help to fill in for gaps in single-domain data. Here we introduce a\nhierarchical framework that enables to harvest group-level (multi-domain)\ninformation while retaining all single-domain characteristics, and showcase it\non popular DSR benchmarks, as well as on neuroscience and medical data. In\naddition to faithful reconstruction of all individual dynamical regimes, our\nunsupervised methodology discovers common low-dimensional feature spaces in\nwhich datasets with similar dynamics cluster. The features spanning these\nspaces were further dynamically highly interpretable, surprisingly in often\nlinear relation to control parameters that govern the dynamics of the\nunderlying system. Finally, we illustrate transfer learning and generalization\nto new parameter regimes, paving the way toward DSR foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.CD",
      "physics.data-an"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.04814v2",
    "published_date": "2024-10-07 07:54:53 UTC",
    "updated_date": "2025-02-17 08:53:28 UTC"
  },
  {
    "arxiv_id": "2410.04799v1",
    "title": "Transforming Color: A Novel Image Colorization Method",
    "authors": [
      "Hamza Shafiq",
      "Bumshik Lee"
    ],
    "abstract": "This paper introduces a novel method for image colorization that utilizes a\ncolor transformer and generative adversarial networks (GANs) to address the\nchallenge of generating visually appealing colorized images. Conventional\napproaches often struggle with capturing long-range dependencies and producing\nrealistic colorizations. The proposed method integrates a transformer\narchitecture to capture global information and a GAN framework to improve\nvisual quality. In this study, a color encoder that utilizes a random normal\ndistribution to generate color features is applied. These features are then\nintegrated with grayscale image features to enhance the overall representation\nof the images. Our method demonstrates superior performance compared with\nexisting approaches by utilizing the capacity of the transformer, which can\ncapture long-range dependencies and generate a realistic colorization of the\nGAN. Experimental results show that the proposed network significantly\noutperforms other state-of-the-art colorization techniques, highlighting its\npotential for image colorization. This research opens new possibilities for\nprecise and visually compelling image colorization in domains such as digital\nrestoration and historical image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04799v1",
    "published_date": "2024-10-07 07:23:42 UTC",
    "updated_date": "2024-10-07 07:23:42 UTC"
  },
  {
    "arxiv_id": "2410.05343v2",
    "title": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos Referring to Procedural Texts",
    "authors": [
      "Yuto Haneji",
      "Taichi Nishimura",
      "Hirotaka Kameko",
      "Keisuke Shirai",
      "Tomoya Yoshida",
      "Keiya Kajimura",
      "Koki Yamamoto",
      "Taiyu Cui",
      "Tomohiro Nishimoto",
      "Shinsuke Mori"
    ],
    "abstract": "Mistake action detection is crucial for developing intelligent archives that\ndetect workers' errors and provide feedback. Existing studies have focused on\nvisually apparent mistakes in free-style activities, resulting in video-only\napproaches to mistake detection. However, in text-following activities, models\ncannot determine the correctness of some actions without referring to the\ntexts. Additionally, current mistake datasets rarely use procedural texts for\nvideo recording except for cooking. To fill these gaps, this paper proposes the\nEgoOops dataset, where egocentric videos record erroneous activities when\nfollowing procedural texts across diverse domains. It features three types of\nannotations: video-text alignment, mistake labels, and descriptions for\nmistakes. We also propose a mistake detection approach, combining video-text\nalignment and mistake label classification to leverage the texts. Our\nexperimental results show that incorporating procedural texts is essential for\nmistake detection. Data is available through\nhttps://y-haneji.github.io/EgoOops-project-page/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Main 6 pages, supplementary 13 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.05343v2",
    "published_date": "2024-10-07 07:19:50 UTC",
    "updated_date": "2025-02-11 07:17:37 UTC"
  },
  {
    "arxiv_id": "2410.04795v2",
    "title": "Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models",
    "authors": [
      "Dahyun Kim",
      "Sukyung Lee",
      "Yungi Kim",
      "Attapol Rutherford",
      "Chanjun Park"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has highlighted the\nneed for robust evaluation frameworks that assess their core capabilities, such\nas reasoning, knowledge, and commonsense, leading to the inception of certain\nwidely-used benchmark suites such as the H6 benchmark. However, these benchmark\nsuites are primarily built for the English language, and there exists a lack\nthereof for under-represented languages, in terms of LLM development, such as\nThai. On the other hand, developing LLMs for Thai should also include enhancing\nthe cultural understanding as well as core capabilities. To address these dual\nchallenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai\nCultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough\nevaluation of various LLMs with multi-lingual capabilities, we provide a\ncomprehensive analysis of the proposed benchmarks and how they contribute to\nThai LLM development. Furthermore, we will make both the datasets and\nevaluation code publicly available to encourage further research and\ndevelopment for Thai LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04795v2",
    "published_date": "2024-10-07 07:14:37 UTC",
    "updated_date": "2024-10-08 04:05:18 UTC"
  },
  {
    "arxiv_id": "2410.04789v1",
    "title": "Analysis of Hybrid Compositions in Animation Film with Weakly Supervised Learning",
    "authors": [
      "Mónica Apellaniz Portos",
      "Roberto Labadie-Tamayo",
      "Claudius Stemmler",
      "Erwin Feyersinger",
      "Andreas Babic",
      "Franziska Bruckner",
      "Vrääth Öhner",
      "Matthias Zeppelzauer"
    ],
    "abstract": "We present an approach for the analysis of hybrid visual compositions in\nanimation in the domain of ephemeral film. We combine ideas from\nsemi-supervised and weakly supervised learning to train a model that can\nsegment hybrid compositions without requiring pre-labeled segmentation masks.\nWe evaluate our approach on a set of ephemeral films from 13 film archives.\nResults demonstrate that the proposed learning strategy yields a performance\nclose to a fully supervised baseline. On a qualitative level the performed\nanalysis provides interesting insights on hybrid compositions in animation\nfilm.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Vision for Art (VISART VII) Workshop at the European Conference of\n  Computer Vision (ECCV)",
    "pdf_url": "http://arxiv.org/pdf/2410.04789v1",
    "published_date": "2024-10-07 06:57:23 UTC",
    "updated_date": "2024-10-07 06:57:23 UTC"
  },
  {
    "arxiv_id": "2410.04779v2",
    "title": "Fast Training of Sinusoidal Neural Fields via Scaling Initialization",
    "authors": [
      "Taesun Yeom",
      "Sangyoon Lee",
      "Jaeho Lee"
    ],
    "abstract": "Neural fields are an emerging paradigm that represent data as continuous\nfunctions parameterized by neural networks. Despite many advantages, neural\nfields often have a high training cost, which prevents a broader adoption. In\nthis paper, we focus on a popular family of neural fields, called sinusoidal\nneural fields (SNFs), and study how it should be initialized to maximize the\ntraining speed. We find that the standard initialization scheme for SNFs --\ndesigned based on the signal propagation principle -- is suboptimal. In\nparticular, we show that by simply multiplying each weight (except for the last\nlayer) by a constant, we can accelerate SNF training by 10$\\times$. This\nmethod, coined $\\textit{weight scaling}$, consistently provides a significant\nspeedup over various data domains, allowing the SNFs to train faster than more\nrecently proposed architectures. To understand why the weight scaling works\nwell, we conduct extensive theoretical and empirical analyses which reveal that\nthe weight scaling not only resolves the spectral bias quite effectively but\nalso enjoys a well-conditioned optimization trajectory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.04779v2",
    "published_date": "2024-10-07 06:38:43 UTC",
    "updated_date": "2025-02-28 14:20:04 UTC"
  },
  {
    "arxiv_id": "2410.10858v1",
    "title": "Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths",
    "authors": [
      "Yew Ken Chia",
      "Guizhen Chen",
      "Weiwen Xu",
      "Luu Anh Tuan",
      "Soujanya Poria",
      "Lidong Bing"
    ],
    "abstract": "Advanced models such as OpenAI o1 exhibit impressive problem-solving\ncapabilities through step-by-step reasoning. However, they may still falter on\nmore complex problems, making errors that disrupt their reasoning paths. We\nattribute this to the expansive solution space, where each step has the risk of\ndiverging into mistakes. To enhance language model reasoning, we introduce a\nspecialized training framework called Reasoning Paths Optimization (RPO), which\nenables learning to reason and explore from diverse paths. Our approach\nencourages favorable branches at each reasoning step while penalizing\nunfavorable ones, enhancing the model's overall problem-solving performance.\nReasoning Paths Optimization does not rely on large-scale human-annotated\nrationales or outputs from closed-source models, making it scalable and\ndata-efficient. We focus on multi-step reasoning tasks, such as math word\nproblems and science-based exam questions. The experiments demonstrate that our\nframework significantly enhances the reasoning performance of large language\nmodels, with up to 3.1% and 4.3% improvement on GSM8K and MMLU (STEM)\nrespectively. Our data and code can be found at\nhttps://reasoning-paths.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2410.10858v1",
    "published_date": "2024-10-07 06:37:25 UTC",
    "updated_date": "2024-10-07 06:37:25 UTC"
  },
  {
    "arxiv_id": "2410.16301v1",
    "title": "Intelligent Computing Social Modeling and Methodological Innovations in Political Science in the Era of Large Language Models",
    "authors": [
      "Zhenyu Wang",
      "Yi Xu",
      "Dequan Wang",
      "Lingfeng Zhou",
      "Yiqi Zhou"
    ],
    "abstract": "The recent wave of artificial intelligence, epitomized by large language\nmodels (LLMs), has presented opportunities and challenges for methodological\ninnovation in political science, sparking discussions on a potential paradigm\nshift in the social sciences. However, how can we understand the impact of LLMs\non knowledge production and paradigm transformation in the social sciences from\na comprehensive perspective that integrates technology and methodology? What\nare LLMs' specific applications and representative innovative methods in\npolitical science research? These questions, particularly from a practical\nmethodological standpoint, remain underexplored. This paper proposes the\n\"Intelligent Computing Social Modeling\" (ICSM) method to address these issues\nby clarifying the critical mechanisms of LLMs. ICSM leverages the strengths of\nLLMs in idea synthesis and action simulation, advancing intellectual\nexploration in political science through \"simulated social construction\" and\n\"simulation validation.\" By simulating the U.S. presidential election, this\nstudy empirically demonstrates the operational pathways and methodological\nadvantages of ICSM. By integrating traditional social science paradigms, ICSM\nnot only enhances the quantitative paradigm's capability to apply big data to\nassess the impact of factors but also provides qualitative paradigms with\nevidence for social mechanism discovery at the individual level, offering a\npowerful tool that balances interpretability and predictability in social\nscience research. The findings suggest that LLMs will drive methodological\ninnovation in political science through integration and improvement rather than\ndirect substitution.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "34 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16301v1",
    "published_date": "2024-10-07 06:30:59 UTC",
    "updated_date": "2024-10-07 06:30:59 UTC"
  },
  {
    "arxiv_id": "2410.04765v1",
    "title": "Molecular topological deep learning for polymer property prediction",
    "authors": [
      "Cong Shen",
      "Yipeng Zhang",
      "Fei Han",
      "Kelin Xia"
    ],
    "abstract": "Accurate and efficient prediction of polymer properties is of key importance\nfor polymer design. Traditional experimental tools and density function theory\n(DFT)-based simulations for polymer property evaluation, are both expensive and\ntime-consuming. Recently, a gigantic amount of graph-based molecular models\nhave emerged and demonstrated huge potential in molecular data analysis. Even\nwith the great progresses, these models tend to ignore the high-order and\nmutliscale information within the data. In this paper, we develop molecular\ntopological deep learning (Mol-TDL) for polymer property analysis. Our Mol-TDL\nincorporates both high-order interactions and multiscale properties into\ntopological deep learning architecture. The key idea is to represent polymer\nmolecules as a series of simplicial complices at different scales and build up\nsimplical neural networks accordingly. The aggregated information from\ndifferent scales provides a more accurate prediction of polymer molecular\nproperties.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04765v1",
    "published_date": "2024-10-07 05:44:02 UTC",
    "updated_date": "2024-10-07 05:44:02 UTC"
  },
  {
    "arxiv_id": "2410.04759v2",
    "title": "Driving with Regulation: Interpretable Decision-Making for Autonomous Vehicles with Retrieval-Augmented Reasoning via LLM",
    "authors": [
      "Tianhui Cai",
      "Yifan Liu",
      "Zewei Zhou",
      "Haoxuan Ma",
      "Seth Z. Zhao",
      "Zhiwen Wu",
      "Jiaqi Ma"
    ],
    "abstract": "This work presents an interpretable decision-making framework for autonomous\nvehicles that integrates traffic regulations, norms, and safety guidelines\ncomprehensively and enables seamless adaptation to different regions. While\ntraditional rule-based methods struggle to incorporate the full scope of\ntraffic rules, we develop a Traffic Regulation Retrieval (TRR) Agent based on\nRetrieval-Augmented Generation (RAG) to automatically retrieve relevant traffic\nrules and guidelines from extensive regulation documents and relevant records\nbased on the ego vehicle's situation. Given the semantic complexity of the\nretrieved rules, we also design a reasoning module powered by a Large Language\nModel (LLM) to interpret these rules, differentiate between mandatory rules and\nsafety guidelines, and assess actions on legal compliance and safety.\nAdditionally, the reasoning is designed to be interpretable, enhancing both\ntransparency and reliability. The framework demonstrates robust performance on\nboth hypothesized and real-world cases across diverse scenarios, along with the\nability to adapt to different regions with ease.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04759v2",
    "published_date": "2024-10-07 05:27:22 UTC",
    "updated_date": "2025-03-13 04:00:16 UTC"
  },
  {
    "arxiv_id": "2410.04756v1",
    "title": "Item Cluster-aware Prompt Learning for Session-based Recommendation",
    "authors": [
      "Wooseong Yang",
      "Chen Wang",
      "Zihe Song",
      "Weizhi Zhang",
      "Philip S. Yu"
    ],
    "abstract": "Session-based recommendation (SBR) aims to capture dynamic user preferences\nby analyzing item sequences within individual sessions. However, most existing\napproaches focus mainly on intra-session item relationships, neglecting the\nconnections between items across different sessions (inter-session\nrelationships), which limits their ability to fully capture complex item\ninteractions. While some methods incorporate inter-session information, they\noften suffer from high computational costs, leading to longer training times\nand reduced efficiency. To address these challenges, we propose the CLIP-SBR\n(Cluster-aware Item Prompt learning for Session-Based Recommendation)\nframework. CLIP-SBR is composed of two modules: 1) an item relationship mining\nmodule that builds a global graph to effectively model both intra- and\ninter-session relationships, and 2) an item cluster-aware prompt learning\nmodule that uses soft prompts to integrate these relationships into SBR models\nefficiently. We evaluate CLIP-SBR across eight SBR models and three benchmark\ndatasets, consistently demonstrating improved recommendation performance and\nestablishing CLIP-SBR as a robust solution for session-based recommendation\ntasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.04756v1",
    "published_date": "2024-10-07 05:20:21 UTC",
    "updated_date": "2024-10-07 05:20:21 UTC"
  },
  {
    "arxiv_id": "2410.04753v1",
    "title": "ImProver: Agent-Based Automated Proof Optimization",
    "authors": [
      "Riyaz Ahuja",
      "Jeremy Avigad",
      "Prasad Tetali",
      "Sean Welleck"
    ],
    "abstract": "Large language models (LLMs) have been used to generate formal proofs of\nmathematical theorems in proofs assistants such as Lean. However, we often want\nto optimize a formal proof with respect to various criteria, depending on its\ndownstream use. For example, we may want a proof to adhere to a certain style,\nor to be readable, concise, or modularly structured. Having suitably optimized\nproofs is also important for learning tasks, especially since human-written\nproofs may not optimal for that purpose. To this end, we study a new problem of\nautomated proof optimization: rewriting a proof so that it is correct and\noptimizes for an arbitrary criterion, such as length or readability. As a first\nmethod for automated proof optimization, we present ImProver, a\nlarge-language-model agent that rewrites proofs to optimize arbitrary\nuser-defined metrics in Lean. We find that naively applying LLMs to proof\noptimization falls short, and we incorporate various improvements into\nImProver, such as the use of symbolic Lean context in a novel Chain-of-States\ntechnique, as well as error-correction and retrieval. We test ImProver on\nrewriting real-world undergraduate, competition, and research-level mathematics\ntheorems, finding that ImProver is capable of rewriting proofs so that they are\nsubstantially shorter, more modular, and more readable.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.04753v1",
    "published_date": "2024-10-07 05:14:18 UTC",
    "updated_date": "2024-10-07 05:14:18 UTC"
  },
  {
    "arxiv_id": "2410.04740v2",
    "title": "Evaluating the Generalization Ability of Spatiotemporal Model in Urban Scenario",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Tong Pan",
      "Zheng Dong",
      "Lingyu Zhang",
      "Renhe Jiang",
      "Xuan Song"
    ],
    "abstract": "Spatiotemporal neural networks have shown great promise in urban scenarios by\neffectively capturing temporal and spatial correlations. However, urban\nenvironments are constantly evolving, and current model evaluations are often\nlimited to traffic scenarios and use data mainly collected only a few weeks\nafter training period to evaluate model performance. The generalization ability\nof these models remains largely unexplored. To address this, we propose a\nSpatiotemporal Out-of-Distribution (ST-OOD) benchmark, which comprises six\nurban scenario: bike-sharing, 311 services, pedestrian counts, traffic speed,\ntraffic flow, ride-hailing demand, and bike-sharing, each with in-distribution\n(same year) and out-of-distribution (next years) settings. We extensively\nevaluate state-of-the-art spatiotemporal models and find that their performance\ndegrades significantly in out-of-distribution settings, with most models\nperforming even worse than a simple Multi-Layer Perceptron (MLP). Our findings\nsuggest that current leading methods tend to over-rely on parameters to overfit\ntraining data, which may lead to good performance on in-distribution data but\noften results in poor generalization. We also investigated whether dropout\ncould mitigate the negative effects of overfitting. Our results showed that a\nslight dropout rate could significantly improve generalization performance on\nmost datasets, with minimal impact on in-distribution performance. However,\nbalancing in-distribution and out-of-distribution performance remains a\nchallenging problem. We hope that the proposed benchmark will encourage further\nresearch on this critical issue.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04740v2",
    "published_date": "2024-10-07 04:15:48 UTC",
    "updated_date": "2024-10-09 07:03:50 UTC"
  },
  {
    "arxiv_id": "2410.04739v3",
    "title": "TableRAG: Million-Token Table Understanding with Language Models",
    "authors": [
      "Si-An Chen",
      "Lesly Miculicich",
      "Julian Martin Eisenschlos",
      "Zifeng Wang",
      "Zilong Wang",
      "Yanfei Chen",
      "Yasuhisa Fujii",
      "Hsuan-Tien Lin",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ],
    "abstract": "Recent advancements in language models (LMs) have notably enhanced their\nability to reason with tabular data, primarily through program-aided mechanisms\nthat manipulate and analyze tables. However, these methods often require the\nentire table as input, leading to scalability challenges due to the positional\nbias or context length constraints. In response to these challenges, we\nintroduce TableRAG, a Retrieval-Augmented Generation (RAG) framework\nspecifically designed for LM-based table understanding. TableRAG leverages\nquery expansion combined with schema and cell retrieval to pinpoint crucial\ninformation before providing it to the LMs. This enables more efficient data\nencoding and precise retrieval, significantly reducing prompt lengths and\nmitigating information loss. We have developed two new million-token benchmarks\nfrom the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's\neffectiveness at scale. Our results demonstrate that TableRAG's retrieval\ndesign achieves the highest retrieval quality, leading to the new\nstate-of-the-art performance on large-scale table understanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.04739v3",
    "published_date": "2024-10-07 04:15:02 UTC",
    "updated_date": "2024-12-26 13:58:31 UTC"
  },
  {
    "arxiv_id": "2410.10857v1",
    "title": "Mirror-Consistency: Harnessing Inconsistency in Majority Voting",
    "authors": [
      "Siyuan Huang",
      "Zhiyuan Ma",
      "Jintao Du",
      "Changhua Meng",
      "Weiqiang Wang",
      "Zhouhan Lin"
    ],
    "abstract": "Self-Consistency, a widely-used decoding strategy, significantly boosts the\nreasoning capabilities of Large Language Models (LLMs). However, it depends on\nthe plurality voting rule, which focuses on the most frequent answer while\noverlooking all other minority responses. These inconsistent minority views\noften illuminate areas of uncertainty within the model's generation process. To\naddress this limitation, we present Mirror-Consistency, an enhancement of the\nstandard Self-Consistency approach. Our method incorporates a 'reflective\nmirror' into the self-ensemble decoding process and enables LLMs to critically\nexamine inconsistencies among multiple generations. Additionally, just as\nhumans use the mirror to better understand themselves, we propose using\nMirror-Consistency to enhance the sample-based confidence calibration methods,\nwhich helps to mitigate issues of overconfidence. Our experimental results\ndemonstrate that Mirror-Consistency yields superior performance in both\nreasoning accuracy and confidence calibration compared to Self-Consistency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Short Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.10857v1",
    "published_date": "2024-10-07 03:41:08 UTC",
    "updated_date": "2024-10-07 03:41:08 UTC"
  },
  {
    "arxiv_id": "2410.04723v1",
    "title": "ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep Tabular Learning",
    "authors": [
      "Guangzhi Xiong",
      "Sanchit Sinha",
      "Aidong Zhang"
    ],
    "abstract": "Generalized additive models (GAMs) have long been a powerful white-box tool\nfor the intelligible analysis of tabular data, revealing the influence of each\nfeature on the model predictions. Despite the success of neural networks (NNs)\nin various domains, their application as NN-based GAMs in tabular data analysis\nremains suboptimal compared to tree-based ones, and the opacity of encoders in\nNN-GAMs also prevents users from understanding how networks learn the\nfunctions. In this work, we propose a new deep tabular learning method, termed\nPrototypical Neural Additive Model (ProtoNAM), which introduces prototypes into\nneural networks in the framework of GAMs. With the introduced prototype-based\nfeature activation, ProtoNAM can flexibly model the irregular mapping from\ntabular features to the outputs while maintaining the explainability of the\nfinal prediction. We also propose a gradient-boosting inspired hierarchical\nshape function modeling method, facilitating the discovery of complex feature\npatterns and bringing transparency into the learning process of each network\nlayer. Our empirical evaluations demonstrate that ProtoNAM outperforms all\nexisting NN-based GAMs, while providing additional insights into the shape\nfunction learned for each feature. The source code of ProtoNAM is available at\n\\url{https://github.com/Teddy-XiongGZ/ProtoNAM}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04723v1",
    "published_date": "2024-10-07 03:25:46 UTC",
    "updated_date": "2024-10-07 03:25:46 UTC"
  },
  {
    "arxiv_id": "2410.04717v3",
    "title": "$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization",
    "authors": [
      "Dylan Zhang",
      "Justin Wang",
      "Francois Charton"
    ],
    "abstract": "Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Fix formatting issues",
    "pdf_url": "http://arxiv.org/pdf/2410.04717v3",
    "published_date": "2024-10-07 03:15:11 UTC",
    "updated_date": "2024-10-18 03:18:50 UTC"
  },
  {
    "arxiv_id": "2410.04715v2",
    "title": "Rule-based Data Selection for Large Language Models",
    "authors": [
      "Xiaomin Li",
      "Mingye Gao",
      "Zhiwei Zhang",
      "Chang Yue",
      "Hong Hu"
    ],
    "abstract": "The quality of training data significantly impacts the performance of large\nlanguage models (LLMs). There are increasing studies using LLMs to rate and\nselect data based on several human-crafted metrics (rules). However, these\nconventional rule-based approaches often depend too heavily on human\nheuristics, lack effective metrics for assessing rules, and exhibit limited\nadaptability to new tasks. In our study, we introduce an innovative rule-based\nframework that utilizes the orthogonality of score vectors associated with\nrules as a novel metric for rule evaluations. Our approach includes an\nautomated pipeline that first uses LLMs to generate a diverse set of rules,\nencompassing various rating dimensions to evaluate data quality. Then it rates\na batch of data based on these rules and uses the determinantal point process\n(DPP) from random matrix theory to select the most orthogonal score vectors,\nthereby identifying a set of independent rules. These rules are subsequently\nused to evaluate all data, selecting samples with the highest average scores\nfor downstream tasks such as LLM training. We verify the effectiveness of our\nmethod through two experimental setups: 1) comparisons with ground truth\nratings and 2) benchmarking LLMs trained with the chosen data. Our\ncomprehensive experiments cover a range of scenarios, including general\npre-training and domain-specific fine-tuning in areas such as IMDB, Medical,\nMath, and Code. The outcomes demonstrate that our DPP-based rule rating method\nconsistently outperforms other approaches, including rule-free rating, uniform\nsampling, importance resampling, and QuRating, in terms of both rating\nprecision and model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04715v2",
    "published_date": "2024-10-07 03:13:06 UTC",
    "updated_date": "2024-12-08 16:44:57 UTC"
  },
  {
    "arxiv_id": "2410.04708v1",
    "title": "Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks",
    "authors": [
      "Ankur Mali",
      "Tommaso Salvatori",
      "Alexander Ororbia"
    ],
    "abstract": "Energy-based learning algorithms, such as predictive coding (PC), have\ngarnered significant attention in the machine learning community due to their\ntheoretical properties, such as local operations and biologically plausible\nmechanisms for error correction. In this work, we rigorously analyze the\nstability, robustness, and convergence of PC through the lens of dynamical\nsystems theory. We show that, first, PC is Lyapunov stable under mild\nassumptions on its loss and residual energy functions, which implies intrinsic\nrobustness to small random perturbations due to its well-defined\nenergy-minimizing dynamics. Second, we formally establish that the PC updates\napproximate quasi-Newton methods by incorporating higher-order curvature\ninformation, which makes them more stable and able to converge with fewer\niterations compared to models trained via backpropagation (BP). Furthermore,\nusing this dynamical framework, we provide new theoretical bounds on the\nsimilarity between PC and other algorithms, i.e., BP and target propagation\n(TP), by precisely characterizing the role of higher-order derivatives. These\nbounds, derived through detailed analysis of the Hessian structures, show that\nPC is significantly closer to quasi-Newton updates than TP, providing a deeper\nunderstanding of the stability and efficiency of PC compared to conventional\nlearning methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 9 theorems",
    "pdf_url": "http://arxiv.org/pdf/2410.04708v1",
    "published_date": "2024-10-07 02:57:26 UTC",
    "updated_date": "2024-10-07 02:57:26 UTC"
  },
  {
    "arxiv_id": "2410.17261v1",
    "title": "Masked Autoencoder with Swin Transformer Network for Mitigating Electrode Shift in HD-EMG-based Gesture Recognition",
    "authors": [
      "Kasra Laamerad",
      "Mehran Shabanpour",
      "Md. Rabiul Islam",
      "Arash Mohammadi"
    ],
    "abstract": "Multi-channel surface Electromyography (sEMG), also referred to as\nhigh-density sEMG (HD-sEMG), plays a crucial role in improving gesture\nrecognition performance for myoelectric control. Pattern recognition models\ndeveloped based on HD-sEMG, however, are vulnerable to changing recording\nconditions (e.g., signal variability due to electrode shift). This has resulted\nin significant degradation in performance across subjects, and sessions. In\nthis context, the paper proposes the Masked Autoencoder with Swin Transformer\n(MAST) framework, where training is performed on a masked subset of HDsEMG\nchannels. A combination of four masking strategies, i.e., random block masking;\ntemporal masking; sensor-wise random masking, and; multi-scale masking, is used\nto learn latent representations and increase robustness against electrode\nshift. The masked data is then passed through MAST's three-path encoder-decoder\nstructure, leveraging a multi-path Swin-Unet architecture that simultaneously\ncaptures time-domain, frequency-domain, and magnitude-based features of the\nunderlying HD-sEMG signal. These augmented inputs are then used in a\nself-supervised pre-training fashion to improve the model's generalization\ncapabilities. Experimental results demonstrate the superior performance of the\nproposed MAST framework in comparison to its counterparts.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17261v1",
    "published_date": "2024-10-07 02:55:36 UTC",
    "updated_date": "2024-10-07 02:55:36 UTC"
  },
  {
    "arxiv_id": "2410.04707v1",
    "title": "Learning How Hard to Think: Input-Adaptive Allocation of LM Computation",
    "authors": [
      "Mehul Damani",
      "Idan Shenfeld",
      "Andi Peng",
      "Andreea Bobu",
      "Jacob Andreas"
    ],
    "abstract": "Computationally intensive decoding procedures--including search, reranking,\nand self-critique--can improve the quality of language model (LM) outputs in\nproblems spanning code generation, numerical reasoning, and dialog. Existing\nwork typically applies the same decoding procedure for every input to an LM.\nBut not all inputs require the same amount of computation to process. Can we\nallocate decoding computation adaptively, using more resources to answer\nquestions whose answers will be harder to compute? We present an approach that\npredicts the distribution of rewards given an input and computation budget,\nthen allocates additional computation to inputs for which it is predicted to be\nmost useful. We apply this approach in two decoding procedures: first, an\nadaptive best-of-k procedure that dynamically selects the number of samples to\ngenerate as input to a reranker; second, a routing procedure that dynamically\nresponds to a query using a decoding procedure that is expensive but accurate,\nor one that is cheaper but less capable. Across a suite of programming,\nmathematics, and dialog tasks, we show that accurate computation-allocation\nprocedures can be learned, and reduce computation by up to 50% at no cost to\nresponse quality, or improve quality by up to 10% at a fixed computational\nbudget.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04707v1",
    "published_date": "2024-10-07 02:52:30 UTC",
    "updated_date": "2024-10-07 02:52:30 UTC"
  },
  {
    "arxiv_id": "2410.05341v2",
    "title": "NeuroBOLT: Resting-state EEG-to-fMRI Synthesis with Multi-dimensional Feature Mapping",
    "authors": [
      "Yamin Li",
      "Ange Lou",
      "Ziyuan Xu",
      "Shengchao Zhang",
      "Shiyu Wang",
      "Dario J. Englot",
      "Soheil Kolouri",
      "Daniel Moyer",
      "Roza G. Bayrak",
      "Catie Chang"
    ],
    "abstract": "Functional magnetic resonance imaging (fMRI) is an indispensable tool in\nmodern neuroscience, providing a non-invasive window into whole-brain dynamics\nat millimeter-scale spatial resolution. However, fMRI is constrained by issues\nsuch as high operation costs and immobility. With the rapid advancements in\ncross-modality synthesis and brain decoding, the use of deep neural networks\nhas emerged as a promising solution for inferring whole-brain, high-resolution\nfMRI features directly from electroencephalography (EEG), a more widely\naccessible and portable neuroimaging modality. Nonetheless, the complex\nprojection from neural activity to fMRI hemodynamic responses and the spatial\nambiguity of EEG pose substantial challenges both in modeling and\ninterpretability. Relatively few studies to date have developed approaches for\nEEG-fMRI translation, and although they have made significant strides, the\ninference of fMRI signals in a given study has been limited to a small set of\nbrain areas and to a single condition (i.e., either resting-state or a specific\ntask). The capability to predict fMRI signals in other brain areas, as well as\nto generalize across conditions, remain critical gaps in the field. To tackle\nthese challenges, we introduce a novel and generalizable framework: NeuroBOLT,\ni.e., Neuro-to-BOLD Transformer, which leverages multi-dimensional\nrepresentation learning from temporal, spatial, and spectral domains to\ntranslate raw EEG data to the corresponding fMRI activity signals across the\nbrain. Our experiments demonstrate that NeuroBOLT effectively reconstructs\nunseen resting-state fMRI signals from primary sensory, high-level cognitive\nareas, and deep subcortical brain regions, achieving state-of-the-art accuracy\nwith the potential to generalize across varying conditions and sites, which\nsignificantly advances the integration of these two modalities.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "This preprint has been accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.05341v2",
    "published_date": "2024-10-07 02:47:55 UTC",
    "updated_date": "2024-11-02 18:31:34 UTC"
  },
  {
    "arxiv_id": "2410.05339v2",
    "title": "Proceedings of the First International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2024)",
    "authors": [
      "Ken Satoh",
      "Ha-Thanh Nguyen",
      "Francesca Toni",
      "Randy Goebel",
      "Kostas Stathis"
    ],
    "abstract": "Reasoning is an essential component of human intelligence as it plays a\nfundamental role in our ability to think critically, support responsible\ndecisions, and solve challenging problems. Traditionally, AI has addressed\nreasoning in the context of logic-based representations of knowledge. However,\nthe recent leap forward in natural language processing, with the emergence of\nlanguage models based on transformers, is hinting at the possibility that these\nmodels exhibit reasoning abilities, particularly as they grow in size and are\ntrained on more data. Despite ongoing discussions about what reasoning is in\nlanguage models, it is still not easy to pin down to what extent these models\nare actually capable of reasoning.\n  The goal of this workshop is to create a platform for researchers from\ndifferent disciplines and/or AI perspectives, to explore approaches and\ntechniques with the aim to reconcile reasoning between language models using\ntransformers and using logic-based representations. The specific objectives\ninclude analyzing the reasoning abilities of language models measured alongside\nKR methods, injecting KR-style reasoning abilities into language models\n(including by neuro-symbolic means), and formalizing the kind of reasoning\nlanguage models carry out. This exploration aims to uncover how language models\ncan effectively integrate and leverage knowledge and reasoning with it, thus\nimproving their application and utility in areas where precision and\nreliability are a key requirement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Associated with the 21st International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2024) in Hanoi, Vietnam",
    "pdf_url": "http://arxiv.org/pdf/2410.05339v2",
    "published_date": "2024-10-07 02:31:47 UTC",
    "updated_date": "2024-10-12 16:01:16 UTC"
  },
  {
    "arxiv_id": "2410.04683v2",
    "title": "Towards Measuring Goal-Directedness in AI Systems",
    "authors": [
      "Dylan Xu",
      "Juan-Pablo Rivera"
    ],
    "abstract": "Recent advances in deep learning have brought attention to the possibility of\ncreating advanced, general AI systems that outperform humans across many tasks.\nHowever, if these systems pursue unintended goals, there could be catastrophic\nconsequences. A key prerequisite for AI systems pursuing unintended goals is\nwhether they will behave in a coherent and goal-directed manner in the first\nplace, optimizing for some unknown goal; there exists significant research\ntrying to evaluate systems for said behaviors. However, the most rigorous\ndefinitions of goal-directedness we currently have are difficult to compute in\nreal-world settings. Drawing upon this previous literature, we explore policy\ngoal-directedness within reinforcement learning (RL) environments. In our\nfindings, we propose a different family of definitions of the goal-directedness\nof a policy that analyze whether it is well-modeled as near-optimal for many\n(sparse) reward functions. We operationalize this preliminary definition of\ngoal-directedness and test it in toy Markov decision process (MDP)\nenvironments. Furthermore, we explore how goal-directedness could be measured\nin frontier large-language models (LLMs). Our contribution is a definition of\ngoal-directedness that is simpler and more easily computable in order to\napproach the question of whether AI systems could pursue dangerous goals. We\nrecommend further exploration of measuring coherence and goal-directedness,\nbased on our findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "Updated acknowledgements",
    "pdf_url": "http://arxiv.org/pdf/2410.04683v2",
    "published_date": "2024-10-07 01:34:42 UTC",
    "updated_date": "2024-11-22 00:52:08 UTC"
  },
  {
    "arxiv_id": "2410.04660v2",
    "title": "KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA",
    "authors": [
      "Xiaorui Su",
      "Yibo Wang",
      "Shanghua Gao",
      "Xiaolong Liu",
      "Valentina Giunchiglia",
      "Djork-Arné Clevert",
      "Marinka Zitnik"
    ],
    "abstract": "Biomedical reasoning integrates structured, codified knowledge with tacit,\nexperience-driven insights. Depending on the context, quantity, and nature of\navailable evidence, researchers and clinicians use diverse strategies,\nincluding rule-based, prototype-based, and case-based reasoning. Effective\nmedical AI models must handle this complexity while ensuring reliability and\nadaptability. We introduce KGARevion, a knowledge graph-based agent that\nanswers knowledge-intensive questions. Upon receiving a query, KGARevion\ngenerates relevant triplets by leveraging the latent knowledge embedded in a\nlarge language model. It then verifies these triplets against a grounded\nknowledge graph, filtering out errors and retaining only accurate, contextually\nrelevant information for the final answer. This multi-step process strengthens\nreasoning, adapts to different models of medical inference, and outperforms\nretrieval-augmented generation-based approaches that lack effective\nverification mechanisms. Evaluations on medical QA benchmarks show that\nKGARevion improves accuracy by over 5.2% over 15 models in handling complex\nmedical queries. To further assess its effectiveness, we curated three new\nmedical QA datasets with varying levels of semantic complexity, where KGARevion\nimproved accuracy by 10.4%. The agent integrates with different LLMs and\nbiomedical knowledge graphs for broad applicability across knowledge-intensive\ntasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused\non African healthcare, demonstrating its strong zero-shot generalization to\nunderrepresented medical contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.04660v2",
    "published_date": "2024-10-07 00:17:37 UTC",
    "updated_date": "2025-03-03 18:23:47 UTC"
  },
  {
    "arxiv_id": "2410.04657v1",
    "title": "Contrastive Learning to Improve Retrieval for Real-world Fact Checking",
    "authors": [
      "Aniruddh Sriram",
      "Fangyuan Xu",
      "Eunsol Choi",
      "Greg Durrett"
    ],
    "abstract": "Recent work on fact-checking addresses a realistic setting where models\nincorporate evidence retrieved from the web to decide the veracity of claims. A\nbottleneck in this pipeline is in retrieving relevant evidence: traditional\nmethods may surface documents directly related to a claim, but fact-checking\ncomplex claims requires more inferences. For instance, a document about how a\nvaccine was developed is relevant to addressing claims about what it might\ncontain, even if it does not address them directly. We present Contrastive\nFact-Checking Reranker (CFR), an improved retriever for this setting. By\nleveraging the AVeriTeC dataset, which annotates subquestions for claims with\nhuman written answers from evidence documents, we fine-tune Contriever with a\ncontrastive objective based on multiple training signals, including\ndistillation from GPT-4, evaluating subquestion answers, and gold labels in the\ndataset. We evaluate our model on both retrieval and end-to-end veracity\njudgments about claims. On the AVeriTeC dataset, we find a 6\\% improvement in\nveracity classification accuracy. We also show our gains can be transferred to\nFEVER, ClaimDecomp, HotpotQA, and a synthetic dataset requiring retrievers to\nmake inferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 FEVER Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.04657v1",
    "published_date": "2024-10-07 00:09:50 UTC",
    "updated_date": "2024-10-07 00:09:50 UTC"
  }
]